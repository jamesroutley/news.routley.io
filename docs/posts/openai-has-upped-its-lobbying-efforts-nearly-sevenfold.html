<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.technologyreview.com/2025/01/21/1110260/openai-ups-its-lobbying-efforts-nearly-seven-fold/">Original</a>
    <h1>OpenAI has upped its lobbying efforts nearly sevenfold</h1>
    
    <div id="readability-page-1" class="page"><div><div><div> <p>OpenAI spent $1.76 million on government lobbying in 2024 and $510,000 in the last three months of the year alone, according to a new disclosure filed on January 22—a significant jump from 2023, when the company spent just $260,000 on Capitol Hill. </p>  <p>The company also disclosed a new in-house lobbyist, Meghan Dorn, who worked for five years for Senator Lindsey Graham and started at OpenAI in October. The filing also shows activity related to two new pieces of legislation in the final months of the year: the <a href="https://www.congress.gov/bill/118th-congress/house-bill/9497/text">House’s</a> AI Advancement and Reliability Act, which would set up a government center for AI research, and the <a href="https://www.congress.gov/bill/118th-congress/senate-bill/4178/text">Senate’s</a> Future of Artificial Intelligence Innovation Act, which would create shared benchmark tests for AI models. </p> </div></div><div><div> <p>OpenAI did not respond to questions about its lobbying efforts.</p>  <p>But perhaps more important, the disclosure is a clear signal of the company’s arrival as a political player, as its first year of serious lobbying ends and Republican control of Washington begins. While OpenAI’s lobbying spending is still dwarfed by its peers’—Meta tops the list of Big Tech spenders, with more than $24 million in 2024—the uptick comes as it and other AI companies have helped redraw the shape of AI policy. </p> 
 <p>For the past few years, AI policy has been something like a whack-a-mole response to the risks posed by deepfakes and misinformation. But over the last year, AI companies have started to position the success of the technology as pivotal to national security and American competitiveness, arguing that the government must therefore support the industry’s growth. As a result, OpenAI and others now seem poised to gain access to cheaper energy, lucrative national security contracts, and a more lax regulatory environment that’s unconcerned with the minutiae of AI safety.</p>  <p>While the big players seem more or less aligned on this grand narrative, messy divides on other issues are still threatening to break through the harmony on display at President Trump’s inauguration this week.</p> 
 <p>AI regulation really began in earnest after ChatGPT launched in November 2022. At that point, “a lot of the conversation was about responsibility,” says Liana Keesing, campaigns manager for technology reform at Issue One, a democracy nonprofit that tracks Big Tech’s influence. </p>  <p>Companies were asked what they’d do about sexually abusive <a href="https://www.technologyreview.com/2022/12/13/1064810/how-it-feels-to-be-sexually-objectified-by-an-ai/">deepfake images</a> and <a href="https://www.technologyreview.com/2023/05/15/1073019/catching-bad-content-in-the-age-of-ai/">election disinformation</a>. “Sam Altman did a very good job coming in and painting himself early as a supporter of that process,” Keesing says. </p>  <p>OpenAI started its official lobbying effort around October 2023, hiring Chan Park—a onetime Senate Judiciary Committee counsel and Microsoft lobbyist—to lead the effort. Lawmakers, particularly then Senate majority leader Chuck Schumer, were vocal about wanting to curb these particular harms; OpenAI hired Schumer’s former legal counsel, Reginald Babin, as a lobbyist, according to data from OpenSecrets. This past summer, <a href="https://www.nytimes.com/2024/08/30/technology/openai-chris-lehane.html">the company hired the veteran political operative Chris Lehane</a> as its head of global policy. </p>  <p>OpenAI’s previous disclosures confirm that the company’s lobbyists subsequently focused much of last year on legislation like the No Fakes Act and the Protect Elections from Deceptive AI Act. The bills did not materialize into law. But as the year went on, the regulatory goals of AI companies began to change. “One of the biggest shifts that we’ve seen,” Keesing says, “is that they’ve really started to focus on energy.” </p> </div></div><div><div> <p>In September, Altman, along with leaders from Nvidia, Anthropic, and Google, visited the White House and pitched the vision that US competitiveness in AI will depend on subsidized energy infrastructure to train the best models. Altman proposed to the Biden administration the construction of multiple five-gigawatt data centers, which would each consume as much electricity as New York City. </p>  <p>Around the same time, companies like Meta and Microsoft started to say that nuclear energy will provide the path forward for AI, announcing deals aimed at <a href="https://www.technologyreview.com/2025/01/16/1110016/new-nuclear-power/">firing up new nuclear power plants</a>. </p>  <p>It seems likely OpenAI’s policy team was already planning for this particular shift. In April, the company hired lobbyist Matthew Rimkunas, who worked for Bill Gates’s sustainable energy effort Breakthrough Energies and, before that, spent 16 years working for Senator Graham; the South Carolina Republican serves on the Senate subcommittee that manages nuclear safety. </p> </div></div><div><div> <p>This new AI energy race is inseparable from the positioning of AI as essential for national security and <a href="https://www.technologyreview.com/2025/01/21/1110269/there-can-be-no-winners-in-a-us-china-ai-arms-race/">US competitiveness</a> with China. OpenAI laid out its position in a blog post in October, writing, “AI is a transformational technology that can be used to strengthen democratic values or to undermine them. That’s why we believe democracies should continue to take the lead in AI development.” Then in December, the company went a step further and reversed its policy against working with the military, <a href="https://www.technologyreview.com/2024/12/04/1107897/openais-new-defense-contract-completes-its-military-pivot/">announcing</a> it would develop AI models with the defense-tech company Anduril to help take down drones around military bases. </p> 

 <p>That same month, Sam Altman said during an <a href="https://www.thefp.com/p/sam-altman-openai-feud-with-elon">interview</a> with<em> The Free Press</em> that the Biden administration was “not that effective” in shepherding AI: “The things that I think should have been the administration’s priorities, and I hope will be the next administration’s priorities, are building out massive AI infrastructure in the US, having a supply chain in the US, things like that.”</p>  <p>That characterization glosses over the CHIPS Act, a $52 billion stimulus to the domestic chips industry that is, at least on paper, aligned with Altman’s vision. (It also preceded an executive order Biden issued just last week, to lease federal land to host the type of gigawatt-scale data centers that Altman had been asking for.)</p>  <p>Intentionally or not, Altman’s posture aligned him with the growing camaraderie between President Trump and Silicon Valley. Mark Zuckerberg, Elon Musk, Jeff Bezos, and Sundar Pichai all sat directly behind Trump’s family at the inauguration on Monday, and Altman also attended. Many of them had also made sizable donations to Trump’s inaugural fund, with Altman personally <a href="https://apnews.com/article/sam-altman-donald-trump-openai-3b7a87037f3718eb3edc73e94be8a61a">throwing</a> in $1 million.</p>  <p>It’s easy to view the inauguration as evidence that these tech leaders are aligned with each other, and with other players in Trump’s orbit. But there are still some key dividing lines that will be worth watching. Notably, there’s the clash over H-1B visas, which allow many noncitizen AI researchers to work in the US. Musk and Vivek Ramaswamy (who is, as of this week, <a href="https://www.politico.com/news/2025/01/20/doge-musk-helped-eject-ramaswamy-00199487">no longer</a> a part of the so-called Department of Government Efficiency) have been pushing for that visa program to be expanded. This sparked backlash from some allies of the Trump administration, perhaps most loudly <a href="https://www.theguardian.com/us-news/2025/jan/10/h-1b-visas-bannon-sanders-musk-trump">Steve Bannon</a>. </p> </div></div><div><div><p>Another fault line is the battle between open- and closed-source AI. Google and OpenAI prevent anyone from knowing exactly what’s in their most powerful models, often arguing that this keeps them from being used improperly by bad actors. Musk has sued OpenAI and Microsoft over the issue, alleging that closed-source models are antithetical to OpenAI’s hybrid nonprofit structure. Meta, whose Llama <a href="https://www.technologyreview.com/2023/07/18/1076479/metas-latest-ai-model-is-free-for-all/">model</a> is open-source, recently <a href="https://www.wsj.com/tech/ai/elon-musk-open-ai-lawsuit-response-c1f415f8">sided</a> with Musk in that lawsuit. Venture capitalist and Trump ally Marc Andreessen echoed these criticisms of OpenAI on <a href="https://x.com/pmarca/status/1881614440174678339">X</a> just hours after the inauguration. (Andreessen has also <a href="https://www.schumer.senate.gov/imo/media/doc/Marc%20Andreessen.pdf">said</a> that making AI models open-source “makes overbearing regulations unnecessary.”) </p>  <p>Finally, there are the battles over bias and free speech. The vastly different approaches that social media companies have taken to moderating content—including Meta’s recent <a href="https://www.technologyreview.com/2025/01/13/1109954/mark-zuckerberg-and-the-power-of-the-media/">announcement</a> that it would end its US fact-checking program—raise questions about whether the way AI models are moderated will continue to splinter too. Musk has lamented what he calls the “wokeness” of many leading models, and Andreessen said on Tuesday that “Chinese LLMs are much less censored than American LLMs” (though that’s not quite true, given that many Chinese AI models have government-mandated <a href="https://huggingface.co/blog/leonardlin/chinese-llm-censorship-analysis">censorship</a> in place that forbids particular topics). Altman has been more equivocal: “No two people are ever going to agree that one system is perfectly unbiased,” he told <em>The Free Press.</em></p>  <p>It’s only the start of a new era in Washington, but the White House has been busy. It has repealed many executive orders signed by President Biden, including the <a href="https://www.technologyreview.com/2023/10/30/1082678/three-things-to-know-about-the-white-houses-executive-order-on-ai/">landmark order on AI</a> that imposed rules for government use of the technology (while it appears to have kept Biden’s order on leasing land for more data centers). Altman is busy as well. OpenAI, Oracle, and SoftBank <a href="https://www.cbsnews.com/news/trump-announces-private-sector-ai-infrastructure-investment/">reportedly</a> plan to spend up to $500 billion on a joint venture for new data centers; the project was announced by President Trump, with Altman standing alongside. And according to <a href="https://www.axios.com/2025/01/19/ai-superagent-openai-meta"><em>Axios</em></a>, Altman will also be part of a closed-door briefing with government officials on January 30, reportedly about OpenAI’s development of a powerful new AI agent.<svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 1091.84 1091.84" aria-hidden="true"><polygon fill="#6d6e71" points="363.95 0 363.95 1091.84 727.89 1091.84 727.89 363.95 363.95 0"></polygon><polygon fill="#939598" points="363.95 0 728.24 365.18 1091.84 364.13 1091.84 0 363.95 0"></polygon><polygon fill="#414042" points="0 0 0 0.03 0 363.95 363.95 363.95 363.95 0 0 0"></polygon></svg> </p></div></div></div></div>
  </body>
</html>
