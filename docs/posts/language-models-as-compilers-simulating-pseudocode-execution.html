<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://arxiv.org/abs/2404.02575">Original</a>
    <h1>Language models as compilers: Simulating pseudocode execution</h1>
    
    <div id="readability-page-1" class="page"><div id="content-inner">
  <div id="abs">
    
    
    <div><p><span>Authors:</span><a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chae,+H">Hyungjoo Chae</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim,+Y">Yeonghyeon Kim</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim,+S">Seungone Kim</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ong,+K+T">Kai Tzu-iunn Ong</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kwak,+B">Beong-woo Kwak</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim,+M">Moohyeon Kim</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kim,+S">Seonghwan Kim</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kwon,+T">Taeyoon Kwon</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chung,+J">Jiwan Chung</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yu,+Y">Youngjae Yu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Yeo,+J">Jinyoung Yeo</a></p></div>            
    <p><a href="https://arxiv.org/pdf/2404.02575">View PDF</a></p><blockquote>
            <span>Abstract:</span>Algorithmic reasoning refers to the ability to understand the complex patterns behind the problem and decompose them into a sequence of reasoning steps towards the solution. Such nature of algorithmic reasoning makes it a challenge for large language models (LLMs), even though they have demonstrated promising performance in other reasoning tasks. Within this context, some recent studies use programming languages (e.g., Python) to express the necessary logic for solving a given instance/question (e.g., Program-of-Thought) as inspired by their strict and precise syntaxes. However, it is non-trivial to write an executable code that expresses the correct logic on the fly within a single inference call. Also, the code generated specifically for an instance cannot be reused for others, even if they are from the same task and might require identical logic to solve. This paper presents Think-and-Execute, a novel framework that decomposes the reasoning process of language models into two steps. (1) In Think, we discover a task-level logic that is shared across all instances for solving a given task and then express the logic with pseudocode; (2) In Execute, we further tailor the generated pseudocode to each instance and simulate the execution of the code. With extensive experiments on seven algorithmic reasoning tasks, we demonstrate the effectiveness of Think-and-Execute. Our approach better improves LMs&#39; reasoning compared to several strong baselines performing instance-specific reasoning (e.g., CoT and PoT), suggesting the helpfulness of discovering task-level logic. Also, we show that compared to natural language, pseudocode can better guide the reasoning of LMs, even though they are trained to follow natural language instructions.
    </blockquote>

    <!--CONTEXT-->
    
  </div>
</div><div>
      <h2>Submission history</h2><p> From: Hyungjoo Chae [<a href="https://arxiv.org/show-email/ded24a23/2404.02575">view email</a>]      </p></div></div>
  </body>
</html>
