<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://wiki.archiveteam.org/index.php/Blogger">Original</a>
    <h1>ArchiveTeam is downloading and saving content from Blogger</h1>
    
    <div id="readability-page-1" class="page"><div id="mw-content-text" lang="en" dir="ltr"><div>
<p><b>Blogger</b> is a blog hosting service. On February 23, 2015, they announced that &#34;sexually explicit&#34; blogs would be restricted from public access in a month. But soon they withdrew their plan, and said they wouldn&#39;t change their existing policies.<sup id="cite_ref-1"><a href="#cite_note-1">[1]</a></sup>  In 2019, Google <a href="https://wiki.archiveteam.org/index.php/Google_Plus_Comments_on_Blogspot" title="Google Plus Comments on Blogspot">removed Google+ comments placed on Blogger blogs</a>. In May 2020, Blogger announced a redesign of their on their <a rel="nofollow" href="https://blogger.googleblog.com/">official blog</a>, and posted <a rel="nofollow" href="https://support.google.com/blogger/thread/71956466">weekly updates on their community support forum</a> in August and September 2020. This redesign covered most of the Blogger experience, but pages related to user profiles, following blogs, cookie management, video management, and classic-style blog widget management still use the old Blogger design. No updates to Blogger have been documented since September 2020. Google has also moved away from Blogger for their own company blogs. For these reasons, Blogger may be at risk of shutting down.
</p><p>In May 2023, Google announced that inactive accounts would be deleted starting on <span title="2023-12-01">2023-12-01</span> across their platform, including Blogger blogs.
</p><p>Archive Team did a discovery between February and May 2015, but did not begin downloading actual content until November 2023.
</p>


<h2><span id="Strategy">Strategy</span></h2>
<p>Find as many <a rel="nofollow" href="http://foobar.blogspot.com">http://foobar.blogspot.com</a> domains as possible and download them. <a rel="nofollow" href="https://archive.org/details/all_blogger_subdomains">Here is a full list</a> (as of February 2020) and a new list can be generated with <a href="https://wiki.archiveteam.org/index.php/User:Trumad" title="User:Trumad">these instructions</a>. Otherwise, manual discovery can be attempted. Blogs often link to other blogs, which will help, so each individual blog saved will help discover others. Also a small-scale crawl of Blogger profiles (e.g. http://www.blogger.com/profile/{random number up to 35217655}) will provide links to blogs authored by each user (e.g. <a rel="nofollow" href="https://www.blogger.com/profile/5618947">https://www.blogger.com/profile/5618947</a> links to <a rel="nofollow" href="http://hintergedanke.blogspot.com/">http://hintergedanke.blogspot.com/</a>) - Although note that this does not cover ALL bloggers or ALL blogs, and is merely a starting point for further discovery.
</p><p>Another strategy is to scrape Blogspot sites from Blogger profiles and vice versa (<a rel="nofollow" href="https://transfer.archivete.am/RAiXa/archive-blogspot.sh">example script</a>) and you will get an almost ever-expanding list. There will be captchas to deal with though, so you may need to distribute the scraping. There is <a rel="nofollow" href="https://transfer.archivete.am/XWpXt/blogspot.com-blogs.txt">a list</a> of blogs discovered using this method.
</p>
<h2><span id="How_to_help_if_you_have_lists_of_URLs">How to help if you have lists of URLs</span></h2>
<p>This project requires lists of URLs for content on the target website. If you have a source of URLs, please:
</p>
<ol><li>Use the regular expression <code>\S+\.(blogspot|blogger)\.\S+</code> for filtering.
<ul><li>Note that this regex is intentionally broad to cover many different URL formats. Please do not try to use a more narrow pattern as it may miss valid URLs. We can always filter or transform the results as needed later.</li>
<li>If you use <code>grep</code>, remember to include the <code>-a</code> (aka <code>--text</code> on GNU grep) option to ensure it will continue searching for matches when encountering binary data.</li>
<li>Example command (GNU grep): <code>grep -Pahoi &#39;\S+\.(blogspot|blogger)\.\S+&#39; FILENAME FILENAME...</code></li></ul></li>
<li>If the output exceeds a few megabytes, please compress it, preferably using <code>zstd -10</code>.</li>
<li>Upload the file to <a rel="nofollow" href="https://transfer.archivete.am/">https://transfer.archivete.am/</a>.</li>
<li>Share the resulting URL in the project IRC channel.
<ul><li>If you would like to keep the list non-public instead, e.g. for privacy reasons or for not wanting to be publicly associated with it, please get in touch with a channel op (e.g. <a href="https://wiki.archiveteam.org/index.php/User:Arkiver" title="User:Arkiver">arkiver</a> or <a href="https://wiki.archiveteam.org/index.php/User:JustAnotherArchivist" title="User:JustAnotherArchivist">JustAnotherArchivist</a>). Note that the items generated from your list would still be processed publicly, of course, but they would be mixed with everything else.</li></ul></li></ol>
<p>See also <a href="https://wiki.archiveteam.org/index.php/Category:Projects_requiring_URL_lists" title="Category:Projects requiring URL lists">Category:Projects requiring URL lists</a> for other ArchiveTeam projects that necessitate URL lists.
</p>
<h2><span id="Country_Redirect">Country Redirect</span></h2>
<p>Accessing <a rel="nofollow" href="http://whatever.blogspot.com">http://whatever.blogspot.com</a> used to redirect to a country-specific subdomain depending on your IP address (e.g. whatever.blogspot.co.uk, whatever.blogspot.in, etc) which in some cases may be censored or edited to meet local laws and standards - this can be bypassed by requesting <a rel="nofollow" href="http://whatever.blogspot.com/ncr">http://whatever.blogspot.com/ncr</a> as the root URL.<sup id="cite_ref-2"><a href="#cite_note-2">[2]</a></sup> <sup id="cite_ref-3"><a href="#cite_note-3">[3]</a></sup> <a rel="nofollow" href="https://blogger.googleblog.com/2018/05/its-spring-cleaning-time-for-blogger.html">As of May 2018, all international Blogger domains now redirect to blogspot.com</a>.
</p>
<h2><span id="Downloading_a_single_blog_with_Wget">Downloading a single blog with Wget</span></h2>
<p>These Wget parameters can download a BlogSpot blog, including comments and any on-site dependencies.  It should also reject redundant pages such as the /search/ directory and any multiple occurrences of the same page but with different query strings.  It has only be tested on blogs using a Blogger subdomain (e.g. <a rel="nofollow" href="http://foobar.blogspot.com">http://foobar.blogspot.com</a>), not custom domains (e.g. <a rel="nofollow" href="http://foobar.com">http://foobar.com</a>).  Both instances of [URL] should be replaced with the same URL.  A simple Perl wrapper is available <a rel="nofollow" href="http://pastebin.com/2QUuH26L">here</a>.
</p><p><tt>wget --recursive --level=2 --no-clobber --no-parent --page-requisites --continue --convert-links --user-agent=&#34;&#34; -e robots=off --reject &#34;*\\?*,*@*&#34; --exclude-directories=&#34;/search,/feeds&#34; --referer=&#34;[URL]&#34; --wait 1 [URL]</tt>
</p><p><b>UPDATE</b>:
</p><p>Use this improved bash script instead, in order to bypass the adult content confirmation. BLOGURL should be in <code>http://someblog.blogspot.com</code> format.
</p>
<pre>#!/bin/bash
blogspoturl=&#34;BLOGURL&#34;
wget -O - &#34;blogger.com/blogin.g?blogspotURL=$blogspoturl&#34; | grep guestAuth | cut -d&#39;&#34;&#39; -f 4 | wget -i - --save-cookies cookies.txt --keep-session-cookies
wget --load-cookies cookies.txt --recursive --level=2 --no-clobber --no-parent --page-requisites --continue --convert-links --user-agent=&#34;&#34; -e robots=off --reject &#34;*\\?*,*@*&#34; --exclude-directories=&#34;/search,/feeds&#34; --referer=&#34;$blogspoturl&#34; --wait 1 $blogspoturl
</pre>
<h2><span id="Export_XML_trick">Export XML trick</span></h2>
<p>Add this to a blog url and it will download the most recent 499 posts (that is the limit): /atom.xml?redirect=false&amp;max-results=
</p>
<h2><span id="Your_own_blogs">Your own blogs</span></h2>
<p>Download them at <a rel="nofollow" href="https://takeout.google.com/settings/takeout">https://takeout.google.com/settings/takeout</a>
</p><p>We&#39;ve not tested whether the output is suitable for importing in any other software such as Wordpress.
</p>
<h2><span id="External_links">External links</span></h2>
<ul><li><span><a rel="nofollow" href="http://www.blogger.com/">Blogger</a></span><sup><span title="Internet Archive – Wayback Machine">[<a rel="nofollow" href="https://web.archive.org/web/*/http://www.blogger.com/">IA</a></span>•<span title="WebCitation.org"><a rel="nofollow" href="https://webcitation.org/query?url=http://www.blogger.com/">Wcite</a></span>•<span title="Archive.Today webpage capture."><a rel="nofollow" href="https://archive.today/http://www.blogger.com/">.today</a></span>•<span title="MementoWeb TimeTravel"><a rel="nofollow" href="https://timetravel.mementoweb.org/reconstruct/http://www.blogger.com/">MemWeb</a>]</span></sup></li></ul>
<h2><span id="References">References</span></h2>

<!-- 
NewPP limit report
Cached time: 20231125055309
Cache expiry: 86400
Reduced expiry: false
Complications: []
CPU time usage: 0.036 seconds
Real time usage: 0.042 seconds
Preprocessor visited node count: 335/1000000
Post‐expand include size: 6607/2097152 bytes
Template argument size: 1514/2097152 bytes
Highest expansion depth: 13/40
Expensive parser function count: 0/100
Unstrip recursion depth: 0/20
Unstrip post‐expand size: 1872/5000000 bytes
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%   25.859      1 -total
 59.94%   15.501      1 Template:Infobox_project
 15.41%    3.985      1 Template:Endangered
 14.10%    3.645      1 Template:In_progress
 12.69%    3.281      1 Template:IRC
 10.12%    2.617      1 Template:Orange
  9.31%    2.408      1 Template:Datetime
  6.47%    1.673      1 Template:CTA_URL_lists
  5.53%    1.430      1 Template:Url
  5.36%    1.387      1 Template:IRC_channel
-->

<!-- Saved in parser cache with key archivet_archiveteamwiki-wiki_:pcache:idhash:791-0!dateformat=default and timestamp 20231125055327 and revision id 51188. Serialized with JSON.
 -->
</div>
</div></div>
  </body>
</html>
