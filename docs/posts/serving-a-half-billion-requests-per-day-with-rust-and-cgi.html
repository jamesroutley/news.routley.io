<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://jacob.gold/posts/serving-half-billion-requests-with-rust-cgi/">Original</a>
    <h1>Serving a half billion requests per day with Rust and CGI</h1>
    
    <div id="readability-page-1" class="page"><div>

<article>
   
  <div><p>In my previous post <a target="_blank" href="https://jacob.gold/posts/serving-200-million-requests-with-cgi-bin/">Serving 200 million requests per day with a cgi-bin</a>, I did some quick performance testing of CGI using a program written in Go.</p>
<p>Go works excellently for CGI programs, for many of the same reasons it works so well for CLI programs and system daemons.</p>
<p>But, out of curiosity, I decided to do a bit more CGI testing with other languages.</p>
<h2 id="cgi-is-good-technology-actually">CGI is good technology, actually</h2>
<p>There’s a misconception that because CGI is old or because many CGI scripts had security vulnerabilities, CGI itself is somehow insecure or bad.</p>
<p>That’s just not the case. CGI is a simple protocol that works very well.</p>
<p>It’s not any more or less difficult to write secure CGI programs than it is to write any other kind of HTTP handler code.</p>
<p>The common alternatives to CGI, FastCGI and reverse proxies, aren’t a free lunch and have their own security complications.</p>
<h2 id="the-benchmarking-server">The benchmarking server</h2>
<p>This time I used an AMD Genoa-based 60 vCPU / 240 GB RAM virtual machine to serve as a reasonable medium-sized machine.</p>
<p>Running benchmarks in VMs isn’t ideal because of noisy neighbor problems and other sources of variable performance.</p>
<p>However, when doing macrobenchmarking, it’s less of a concern and the results are fairly consistent. This is even more true when using a larger VM, where there are fewer neighbors on the host.</p>
<p>Still, I do always prefer bare metal, but sometimes you leave your servers behind for other people to enjoy.</p>
<center>
<blockquote data-bluesky-uri="at://did:plc:tpg43qhh4lw4ksiffs4nbda3/app.bsky.feed.post/3lasi5f3w6c2n" data-bluesky-cid="bafyreigvaecwktl6ahj7myl3pdo6i55ipvtsr7rijv53nvy3jc5hyf6344" data-bluesky-embed-color-mode="dark"><p lang="en">I miss “my” beautiful servers but they’re in good hands and at least I can still post to them and visualize the disk and network IO and CPU usage, which isn’t creepy to do, it’s actually perfectly normal.
</p><p>I do not miss Nandos in DC and their unrefrigerated sauces!</p>— Jake Gold (<a href="https://bsky.app/profile/did:plc:tpg43qhh4lw4ksiffs4nbda3?ref_src=embed">@jacob.gold</a>) <a href="https://bsky.app/profile/did:plc:tpg43qhh4lw4ksiffs4nbda3/post/3lasi5f3w6c2n?ref_src=embed">November 12, 2024 at 8:11 PM</a></blockquote>
</center>
<h2 id="standard-benchmarking-disclaimer">Standard benchmarking disclaimer</h2>
<p>Benchmarking of any kind is fraught, and it’s easy to make mistakes, which is why there’s no substitute for real-world testing in your own environment.</p>
<ul>
<li>The CGI programs written in each language are broadly similar but their implementations do vary. Some use well-tested libraries while others do manual parsing and are minor abominations.</li>
<li>The HTTP load testing tool <a target="_blank" href="https://github.com/tsenart/vegeta">vegeta</a> was used this time for improved accuracy.</li>
<li>Only <code>gohttpd</code> webserver was used this time because getting Apache to stop being the bottleneck proved somewhat difficult.</li>
<li>The updated code and Dockerfiles are on GitHub <a target="_blank" href="https://github.com/Jacob2161/cgi-bin"></a><a href="https://github.com/Jacob2161/cgi-bin">https://github.com/Jacob2161/cgi-bin</a></li>
</ul>
<h2 id="benchmarking-bash-guestbook-shcgi">Benchmarking Bash <code>guestbook-sh.cgi</code></h2>
<p>No one should ever run a Bash script under CGI. It’s almost impossible to do so securely, and performance is terrible.</p>
<p>But it’s kind of funny to see that it does actually work.</p>
<p>Bash reached just 40 requests per second before saturating all available CPUs.</p>
<p><a target="_blank" href="https://jacob.gold/images/cgi-bin-performance/sh-writes.png"><img alt="cgi-bin writes Bash benchmark" loading="lazy" src="https://jacob.gold/images/cgi-bin-performance/sh-writes.png"/></a></p>
<div><pre tabindex="0"><code data-lang="text"><span><span>Requests      [total, rate, throughput]         600, 40.07, 36.34
</span></span><span><span>Duration      [total, attack, wait]             16.509s, 14.975s, 1.534s
</span></span><span><span>Latencies     [min, mean, 50, 90, 95, 99, max]  838.76ms, 1.908s, 1.924s, 2.48s, 2.547s, 2.655s, 2.77s
</span></span><span><span>Bytes In      [total, mean]                     6756600, 11261.00
</span></span><span><span>Bytes Out     [total, mean]                     31200, 52.00
</span></span><span><span>Success       [ratio]                           100.00%
</span></span><span><span>Status Codes  [code:count]                      200:600  
</span></span><span><span>Error Set:
</span></span></code></pre></div><h2 id="benchmarking-perl-guestbook-plcgi">Benchmarking Perl <code>guestbook-pl.cgi</code></h2>
<p>Perl shows decent performance for a scripting language, managing 500 requests per second. The latency distribution is quite consistent.</p>
<p><a target="_blank" href="https://jacob.gold/images/cgi-bin-performance/pl-writes.png"><img alt="cgi-bin writes Perl benchmark" loading="lazy" src="https://jacob.gold/images/cgi-bin-performance/pl-writes.png"/></a></p>
<div><pre tabindex="0"><code data-lang="text"><span><span>Requests      [total, rate, throughput]         7500, 500.04, 497.25
</span></span><span><span>Duration      [total, attack, wait]             15.083s, 14.999s, 84.166ms
</span></span><span><span>Latencies     [min, mean, 50, 90, 95, 99, max]  72.106ms, 96.842ms, 98.021ms, 102.438ms, 103.292ms, 104.728ms, 113.681ms
</span></span><span><span>Bytes In      [total, mean]                     81585000, 10878.00
</span></span><span><span>Bytes Out     [total, mean]                     390000, 52.00
</span></span><span><span>Success       [ratio]                           100.00%
</span></span><span><span>Status Codes  [code:count]                      200:7500  
</span></span><span><span>Error Set:
</span></span></code></pre></div><h2 id="benchmarking-javascript-guestbook-jscgi">Benchmarking JavaScript <code>guestbook-js.cgi</code></h2>
<p>JavaScript with Node.js surprised me a lot by performing much better than I would have expected in a CGI environment, hitting 600 requests per second with very consistent latencies.</p>
<p><a target="_blank" href="https://jacob.gold/images/cgi-bin-performance/js-writes.png"><img alt="cgi-bin writes JavaScript benchmark" loading="lazy" src="https://jacob.gold/images/cgi-bin-performance/js-writes.png"/></a></p>
<div><pre tabindex="0"><code data-lang="text"><span><span>Requests      [total, rate, throughput]         9000, 600.07, 597.56
</span></span><span><span>Duration      [total, attack, wait]             15.061s, 14.998s, 62.961ms
</span></span><span><span>Latencies     [min, mean, 50, 90, 95, 99, max]  57.999ms, 76.306ms, 76.271ms, 78.824ms, 79.563ms, 80.983ms, 84.569ms
</span></span><span><span>Bytes In      [total, mean]                     96858000, 10762.00
</span></span><span><span>Bytes Out     [total, mean]                     468000, 52.00
</span></span><span><span>Success       [ratio]                           100.00%
</span></span><span><span>Status Codes  [code:count]                      200:9000  
</span></span><span><span>Error Set:
</span></span></code></pre></div><h2 id="benchmarking-python-guestbook-pycgi">Benchmarking Python <code>guestbook-py.cgi</code></h2>
<p>Python manages 700 requests per second, which seems respectable.</p>
<p><a target="_blank" href="https://jacob.gold/images/cgi-bin-performance/py-writes.png"><img alt="cgi-bin writes Python benchmark" loading="lazy" src="https://jacob.gold/images/cgi-bin-performance/py-writes.png"/></a></p>
<div><pre tabindex="0"><code data-lang="text"><span><span>Requests      [total, rate, throughput]         10500, 700.11, 695.36
</span></span><span><span>Duration      [total, attack, wait]             15.1s, 14.998s, 102.49ms
</span></span><span><span>Latencies     [min, mean, 50, 90, 95, 99, max]  44.186ms, 66.602ms, 62.544ms, 78.77ms, 93.006ms, 142.416ms, 590.895ms
</span></span><span><span>Bytes In      [total, mean]                     113001000, 10762.00
</span></span><span><span>Bytes Out     [total, mean]                     546000, 52.00
</span></span><span><span>Success       [ratio]                           100.00%
</span></span><span><span>Status Codes  [code:count]                      200:10500  
</span></span><span><span>Error Set:
</span></span></code></pre></div><h2 id="benchmarking-go-guestbook-gocgi">Benchmarking Go <code>guestbook-go.cgi</code></h2>
<p>Even though Go is a very fast compiled language, it does have a runtime that must be initialized on startup.</p>
<p>Despite this initialization overhead, Go reached 3,400 requests per second with low latencies, which still places it in the “very fast” tier of languages.</p>
<p><a target="_blank" href="https://jacob.gold/images/cgi-bin-performance/go-writes.png"><img alt="cgi-bin writes Go benchmark" loading="lazy" src="https://jacob.gold/images/cgi-bin-performance/go-writes.png"/></a></p>
<div><pre tabindex="0"><code data-lang="text"><span><span>Requests      [total, rate, throughput]         51000, 3399.39, 3396.04
</span></span><span><span>Duration      [total, attack, wait]             15.017s, 15.003s, 14.786ms
</span></span><span><span>Latencies     [min, mean, 50, 90, 95, 99, max]  10.456ms, 21.817ms, 20.458ms, 29.03ms, 33.001ms, 43.833ms, 202.566ms
</span></span><span><span>Bytes In      [total, mean]                     559062000, 10962.00
</span></span><span><span>Bytes Out     [total, mean]                     2652000, 52.00
</span></span><span><span>Success       [ratio]                           100.00%
</span></span><span><span>Status Codes  [code:count]                      200:51000  
</span></span><span><span>Error Set:
</span></span></code></pre></div><h2 id="benchmarking-rust-guestbook-rscgi">Benchmarking Rust <code>guestbook-rs.cgi</code></h2>
<p>Rust hits nearly 5,700 requests per second!</p>
<p>The tail latency appears oddly high (probably SQLite database contention?), but the median latency is extremely good.</p>
<p><a target="_blank" href="https://jacob.gold/images/cgi-bin-performance/rs-writes.png"><img alt="cgi-bin writes Rust benchmark" loading="lazy" src="https://jacob.gold/images/cgi-bin-performance/rs-writes.png"/></a></p>
<div><pre tabindex="0"><code data-lang="text"><span><span>Requests      [total, rate, throughput]         85493, 5699.52, 5660.27
</span></span><span><span>Duration      [total, attack, wait]             15.104s, 15s, 103.997ms
</span></span><span><span>Latencies     [min, mean, 50, 90, 95, 99, max]  4.35ms, 26.28ms, 15.223ms, 47.883ms, 79.299ms, 186.667ms, 1.444s
</span></span><span><span>Bytes In      [total, mean]                     928624966, 10862.00
</span></span><span><span>Bytes Out     [total, mean]                     4445636, 52.00
</span></span><span><span>Success       [ratio]                           100.00%
</span></span><span><span>Status Codes  [code:count]                      200:85493  
</span></span><span><span>Error Set:
</span></span></code></pre></div><h2 id="benchmarking-c-guestbook-ccgi">Benchmarking C <code>guestbook-c.cgi</code></h2>
<p>C performance is very similar to Rust, just slightly better, which is the natural order of things.</p>
<p><a target="_blank" href="https://jacob.gold/images/cgi-bin-performance/c-writes.png"><img alt="cgi-bin writes C benchmark" loading="lazy" src="https://jacob.gold/images/cgi-bin-performance/c-writes.png"/></a></p>
<div><pre tabindex="0"><code data-lang="text"><span><span>Requests      [total, rate, throughput]         87000, 5799.88, 5750.31
</span></span><span><span>Duration      [total, attack, wait]             15.13s, 15s, 129.309ms
</span></span><span><span>Latencies     [min, mean, 50, 90, 95, 99, max]  3.741ms, 26.052ms, 14.375ms, 47.567ms, 84.977ms, 196.932ms, 1.547s
</span></span><span><span>Bytes In      [total, mean]                     946125000, 10875.00
</span></span><span><span>Bytes Out     [total, mean]                     4524000, 52.00
</span></span><span><span>Success       [ratio]                           100.00%
</span></span><span><span>Status Codes  [code:count]                      200:87000  
</span></span><span><span>Error Set:
</span></span></code></pre></div><h2 id="my-takeaways">My takeaways</h2>
<p>It’s clear that CGI is fast enough with compiled languages that it can be used for real work, even if it’s almost never going to be the highest performance option.</p>
<p>It was also very fun to see the relative performance of the different languages play out in the now uncommon environment of CGI.</p>
<p>I love elegant, simple, and powerful technologies like CGI!</p>
<h2 id="links">Links</h2>
<ul>
<li>Find me <a target="_blank" href="https://bsky.app/profile/jacob.gold">@jacob.gold on Bluesky</a></li>
</ul>


  </div>

  
</article>
    </div></div>
  </body>
</html>
