<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://thmsmlr.com/cheap-infra">Original</a>
    <h1>Glory is only 11MB/sec away (2023)</h1>
    
    <div id="readability-page-1" class="page"><div phx-hook="ScrollTracker" id="post">
  <p>
One thing is certain in life: if you’re getting something for a steal, someone
is getting screwed, and it’s probably you elsewhere. This isn’t an
anti-capitalist rant, it’s just the truth. Companies don’t exist if they don’t
make money. Unless there’s some innovation, rest assured that you’re overpaying
somewhere else.</p>
<p>
Last week, I was reminded of this when I saw something on Amazon for cheaper than it was listed at Costco. Costco has the lowest cost structure in the industry. It doesn’t make sense. However, this post isn’t about $3 mosquito repellent and loss leaders. This is a post about AWS and the cloud.</p>
<p>
It’s well known that Amazon makes the majority of its profits from AWS, and yet so many people talk about how the cloud is so cheap. That cannot be so. You are getting screwed.</p>
<p>
<strong>Here’s some math.</strong></p>
<h3>
From First Principles</h3>
<p>
Suppose you’re relatively ambitious. You want to create a top 1000 website on
the internet, say <a href="https://www.businessinsider.com/">businessinsider.com</a> for
example. According to
<a href="https://www.similarweb.com/website/businessinsider.com">SimilarWeb</a> at the time
of writing they are a global top 1000 website (587 to be exact) and get around
200M visitors a month. Each visitor does on average 2 pages per visit, so 400M
HTML documents are needed to be served every month. Sampling a few stories on
Business Insider it looks like the standard HTML document for a story is on the
order of 75KB compressed. Multiply those together and you 30TB of bandwidth just
for the HTML.</p>
<p>
That sounds like a lot, but consider that we’re not assuming a CDN for the HTML,
because your website might not be a news website. Your HTML might be dynamically
served for each request. Consider still that Business Insider articles have a
bunch of inline javascript that can probably be shipped off to a CDN in your
superior implementation. 75KB of compressed HTML is A LOT. Desipte that,
30TB/month is only 11MB/sec, and in Business insider’s case that’s only about
150 request/sec.</p>
<p>
Reduce the HTML size, increase the number of requests, either way, with a CDN
serving your JS, CSS, and images, you can have a top 1000 website if your app
code can produce 11MB/sec of HTML. That’s an incredibly low bar. Even the
slowest interpreted language can do 10x that on modern hardware.</p>
<p>
The latest AMD server processors have 64 cores and 128 theads. Their newest Zen
5, Turin server processors are rumored to have 192 cores. On a dual socket
server you’ll be up near the 400 core count range with 768 threads. <strong>You can
serve the world from a single box.</strong> Why do we need Docker, serverless,
horizontal scalability again?</p>
<p>
You might be thinking, that’s some clever bit of math there, but what about
latency? You can’t deny the speed of light, Thomas, the fundamental physics of
the universe! That’s what the marketing department of these cloud vendors are
going on about these days right? You need to be on the edge, they say. Be close
to your users. Minimize latency. It’s true, and we believe in physics in this
household, but the specifics are a bit more interesting.</p>
<h3>
Edging feels good, but doesn’t deliver the goods</h3>
<p>
Let’s get a grounding on the lower limits of latency. At the speed of light
it would require 200ms to do a roundtrip across the globe. However, in practice
this generally ends up being about 300ms to a good data center on the other side
of the planet.</p>
<p>
Now once again, let’s assume you have your JS, CSS, and media being delivered
from a CDN, then <strong>the real question is if you can shave 300ms off your server
processing in the initial render, you’ve effectively moved your server across
the world next to your user.</strong></p>
<p>
Given this framing, the edge technologies start to not look so good. While yes
there has been huge strides in second generation serverless technology to solve
the coldboot problem which used to easily eat up that 300ms latency budget,
there is still the problem of databases.</p>
<p>
No matter how you design your site, SPA, SSR, some hybrid in between you can’t
get around that if there is at least one database query involved in rendering
your page, you have to go back to your database in us-east-1. Thereby shifting
the latency from user to origin server, to edge server to origin server. </p>
<p>
Some might argue that inter-data center connections are faster than user-data
center connections, and that may or may not be true, but doesn’t mean you can’t
put your website behind something like Cloudfront and get all those benefits
without “running on the edge”.</p>
<p>
Worse still, most sufficiently complicated pages require 5+ database queries to
render. Most web frameworks are single threaded where each of those queries are
running in series back and forth to us-east-1 making latency worse than just
going there once and having all the database queries be data-center local.</p>
<p>
You notice how all of Vercel’s edge demos only display the time? It’s because
that’s about the only useful information on the edge.</p>
<p>
<em>Nobody ever thinks about the database.</em></p>
<p>
A good rule of thumb is that inter-datacenter communication is 10x slower than
intra-datacenter communication which is 10x slower than on-device communication.
Given those 192 core AMD servers, SQlite is looking pretty nice. Makes up for a
good bit of those 300ms.</p>
<h3>
And we haven’t even talked about cost</h3>
<p>
<a href="https://www.hetzner.com/cloud">Hetzner.com</a>. Just look at this site and tell me
you aren’t being robbed.</p>
<p>
For a 16 core server with 64GB of RAM and an NVM drive, Hetzner charges
$0.34/hr. An equivalent x86 server on AWS EC2 is the m5a.4xlarge at $0.68/hr.
Not only that, for bandwidth Hetzner gives you 20TB of data for free then
charges $1.5/TB there after. AWS only gives you 100GB for free and charges a
ridiculous $90/TB.</p>
<p>
If you’re using one of the edge cloud vendors, prices are even more ridiculous.
Vercel for instance charges $200/TB over the first free TB of bandwidth. These
cloud vendors give you tons of stuff for free to lock you in, just to kill you
when you scale as if you need it, but as we established before, you probably
don’t.</p>
<h3>
The reality of the situation</h3>
<p>
Unless you have some specific usecase for the cloud. Maybe you’re transcoding
video, running your own AI models, or doing something that legitimately stresses
a system, your website or SaaS can probably run off a single server. It’ll be
cheaper and simpler to maintain. Plop one in Virginia and you can get the
English speaking world in under 100ms of latency.</p>
<p>
Use SQLite locally on the box, you don’t need a managed database. Use
<a href="https://github.com/benbjohnson/litestream">Litestream</a> to continuously back it
up. Get a CDN to cache your CSS, JS and images. Server render your page close to
your SQLite to minimize back and forths, increasing performance.  </p>
<p>
Your CI can just SCP your code to the box, NGINX supports zero downtime deploys.
Don’t bother with docker and virtualization and all that nonsense, it just slows
down your code and slows down your CI/CD.</p>
<p>
They say you’ll need it to scale. Most likely you don’t. Tales of horizontal
scalability is the most anti-moore’s law thing our industry has ever espoused.</p>
<p>
The reality is servers are getting more capable faster than the internet is
growing. If you really care about latency, throw a server in Germany, and one in
California, route your writes to your primary, use your local read replica for
reads.</p>
<p>
It’ll scale just fine, be way less complex to manage, and considerably cheaper.
11MB/sec doesn’t have to be so hard.</p>

</div></div>
  </body>
</html>
