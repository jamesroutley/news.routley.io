<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/apple/ml-ferret">Original</a>
    <h1>Ferret: A Multimodal Large Language Model</h1>
    
    <div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text">

<p dir="auto"><em>An End-to-End MLLM that Accept Any-Form Referring and Ground Anything in Response.</em> [<a href="https://arxiv.org/abs/2310.07704" rel="nofollow">Paper</a>]</p>
<p dir="auto"><a href="https://hxyou.github.io/" rel="nofollow">Haoxuan You*</a>, <a href="https://haotian-zhang.github.io/" rel="nofollow">Haotian Zhang*</a>, <a href="https://zhegan27.github.io/" rel="nofollow">Zhe Gan</a>, <a href="https://scholar.google.com/citations?user=l1hP40AAAAAJ&amp;hl=en" rel="nofollow">Xianzhi Du</a>, <a href="https://zbwglory.github.io/" rel="nofollow">Bowen Zhang</a>, <a href="https://www.cs.cmu.edu/~ziruiw/" rel="nofollow">Zirui Wang</a>, <a href="http://llcao.net/" rel="nofollow">Liangliang Cao</a>, <a href="https://www.ee.columbia.edu/~sfchang/" rel="nofollow">Shih-Fu Chang</a>, <a href="https://sites.google.com/site/yinfeiyang/" rel="nofollow">Yinfei Yang</a>
[*: equal contribution]</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-overview" aria-hidden="true" tabindex="-1" href="#overview"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Overview</h2>
<p dir="auto">
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/apple/ml-ferret/blob/main/figs/ferret_fig_diagram_v2.png"><img src="https://github.com/apple/ml-ferret/raw/main/figs/ferret_fig_diagram_v2.png" width="100%"/></a> </p>
<p dir="auto">Key Contributions:</p>
<ul dir="auto">
<li>Ferret Model - <strong>Hybrid Region Representation + Spatial-aware Visual Sampler</strong> enable fine-grained and open-vocabulary referring and grounding in MLLM.</li>
<li>GRIT Dataset (~1.1M) - A <strong>Large-scale, Hierarchical, Robust</strong> ground-and-refer instruction tuning dataset.</li>
<li>Ferret-Bench - A multimodal evaluation benchmark that jointly requires <strong>Referring/Grounding, Semantics, Knowledge, and Reasoning</strong>.</li>
</ul>
<h2 tabindex="-1" dir="auto"><a id="user-content-release" aria-hidden="true" tabindex="-1" href="#release"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Release</h2>
<ul dir="auto">
<li>[12/14] ðŸ”¥ We released the <a href="#checkpoints">checkpoints(7B, 13B)</a>.</li>
<li>[10/30] ðŸ”¥ We released the code of <strong>FERRET</strong> model and <a href="https://github.com/apple/ml-ferret/blob/main/ferret/eval/ferret_gpt4_data">Ferret-Bench</a>.</li>
</ul>
<p dir="auto"><strong>Usage and License Notices</strong>: The data, and code is intended and licensed for research use only. They are also restricted to uses that follow the license agreement of LLaMA, Vicuna and GPT-4. The dataset is CC BY NC 4.0 (allowing only non-commercial use) and models trained using the dataset should not be used outside of research purposes.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-contents" aria-hidden="true" tabindex="-1" href="#contents"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Contents</h2>
<ul dir="auto">
<li><a href="#install">Install</a></li>
<li><a href="#train">Train</a></li>
<li><a href="#evaluation">Evaluation</a></li>
<li><a href="#demo">Demo</a></li>
</ul>
<h2 tabindex="-1" dir="auto"><a id="user-content-install" aria-hidden="true" tabindex="-1" href="#install"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Install</h2>
<ol dir="auto">
<li>Clone this repository and navigate to FERRET folder</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/apple/ml-ferret
cd ml-ferret"><pre>git clone https://github.com/apple/ml-ferret
<span>cd</span> ml-ferret</pre></div>
<ol start="2" dir="auto">
<li>Install Package</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="conda create -n ferret python=3.10 -y
conda activate ferret
pip install --upgrade pip  # enable PEP 660 support
pip install -e .
pip install pycocotools
pip install protobuf==3.20.0"><pre>conda create -n ferret python=3.10 -y
conda activate ferret
pip install --upgrade pip  <span><span>#</span> enable PEP 660 support</span>
pip install -e <span>.</span>
pip install pycocotools
pip install protobuf==3.20.0</pre></div>
<ol start="3" dir="auto">
<li>Install additional packages for training cases</li>
</ol>
<div data-snippet-clipboard-copy-content="pip install ninja
pip install flash-attn --no-build-isolation"><pre><code>pip install ninja
pip install flash-attn --no-build-isolation
</code></pre></div>
<h2 tabindex="-1" dir="auto"><a id="user-content-train" aria-hidden="true" tabindex="-1" href="#train"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Train</h2>
<p dir="auto">FERRET is trained on 8 A100 GPUs with 80GB memory. To train on fewer GPUs, you can reduce the <code>per_device_train_batch_size</code> and increase the <code>gradient_accumulation_steps</code> accordingly. Always keep the global batch size the same: <code>per_device_train_batch_size</code> x <code>gradient_accumulation_steps</code> x <code>num_gpus</code>.</p>
<h3 tabindex="-1" dir="auto"><a id="user-content-hyperparameters" aria-hidden="true" tabindex="-1" href="#hyperparameters"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Hyperparameters</h3>
<p dir="auto">We use a similar set of hyperparameters as LLaVA(Vicuna) in finetuning.</p>
<table>
<thead>
<tr>
<th>Hyperparameter</th>
<th>Global Batch Size</th>
<th>Learning rate</th>
<th>Epochs</th>
<th>Max length</th>
<th>Weight decay</th>
</tr>
</thead>
<tbody>
<tr>
<td>FERRET-7B</td>
<td>128</td>
<td>2e-5</td>
<td>3</td>
<td>2048</td>
<td>0</td>
</tr>
<tr>
<td>FERRET-13B</td>
<td>128</td>
<td>2e-5</td>
<td>3</td>
<td>2048</td>
<td>0</td>
</tr>
</tbody>
</table>
<h3 tabindex="-1" dir="auto"><a id="user-content-prepare-vicuna-checkpoint-and-llavas-projector" aria-hidden="true" tabindex="-1" href="#prepare-vicuna-checkpoint-and-llavas-projector"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Prepare Vicuna checkpoint and LLaVA&#39;s projector</h3>
<p dir="auto">Before you start, prepare our base model Vicuna, which is an instruction-tuned chatbot. Please download its weights following the instructions <a href="https://github.com/lm-sys/FastChat#model-weights">here</a>. Vicuna v1.3 is used in FERRET.</p>
<p dir="auto">Then download LLaVA&#39;s first-stage pre-trained projector weight (<a href="https://huggingface.co/liuhaotian/llava-336px-pretrain-vicuna-7b-v1.3" rel="nofollow">7B</a>, <a href="https://huggingface.co/liuhaotian/llava-336px-pretrain-vicuna-13b-v1.3" rel="nofollow">13B</a>).</p>
<h3 tabindex="-1" dir="auto"><a id="user-content-ferret-training" aria-hidden="true" tabindex="-1" href="#ferret-training"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>FERRET Training</h3>
<p dir="auto">The scripts are provided (<a href="https://github.com/apple/ml-ferret/blob/main/experiments/ferret_7b_train.sh">7B</a>, <a href="https://github.com/apple/ml-ferret/blob/main/experiments/ferret_13b_train.sh">13B</a>).</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-evaluation" aria-hidden="true" tabindex="-1" href="#evaluation"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Evaluation</h2>
<p dir="auto">Please see this <a href="https://github.com/apple/ml-ferret/blob/main/EVAL.md">doc</a> for the details.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-checkpoints" aria-hidden="true" tabindex="-1" href="#checkpoints"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Checkpoints</h2>
<p dir="auto">We extracted the <code>delta</code> between our pre-trained model and Vicuna. Please first download weights of Vicuna following the <a href="#prepare-vicuna-checkpoint-and-llavas-projector">previous instruction</a>. Then download our prepared offsets of weights: <a href="https://docs-assets.developer.apple.com/ml-research/models/ferret/ferret-7b/ferret-7b-delta.zip" rel="nofollow">7B</a>, <a href="https://docs-assets.developer.apple.com/ml-research/models/ferret/ferret-13b/ferret-13b-delta.zip" rel="nofollow">13B</a> using <code>wget</code> or <code>curl</code>, and unzip the downloaded offsets. Lastly, apply the offset to the Vicuna&#39;s weight by running the following script:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# 7B
python3 -m ferret.model.apply_delta \
    --base ./model/vicuna-7b-v1-3 \
    --target ./model/ferret-7b-v1-3 \
    --delta path/to/ferret-7b-delta
# 13B
python3 -m ferret.model.apply_delta \
    --base ./model/vicuna-13b-v1-3 \
    --target ./model/ferret-13b-v1-3 \
    --delta path/to/ferret-13b-delta"><pre><span><span>#</span> 7B</span>
python3 -m ferret.model.apply_delta \
    --base ./model/vicuna-7b-v1-3 \
    --target ./model/ferret-7b-v1-3 \
    --delta path/to/ferret-7b-delta
<span><span>#</span> 13B</span>
python3 -m ferret.model.apply_delta \
    --base ./model/vicuna-13b-v1-3 \
    --target ./model/ferret-13b-v1-3 \
    --delta path/to/ferret-13b-delta</pre></div>
<p dir="auto"><strong>Notices</strong>: Apple&#39;s rights in the attached weight differentials are hereby licensed under the CC-BY-NC license. Apple makes no representations with regards to LLaMa or any other third party software, which are subject to their own terms.</p>
<p dir="auto">Please refer to the next section about how to set up a local demo with pre-trained weight.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-demo" aria-hidden="true" tabindex="-1" href="#demo"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Demo</h2>
<p dir="auto">To run our demo, you need to train FERRET and use the checkpoints locally. Gradio web UI is used. Please run the following commands one by one.</p>
<h4 tabindex="-1" dir="auto"><a id="user-content-launch-a-controller" aria-hidden="true" tabindex="-1" href="#launch-a-controller"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Launch a controller</h4>
<div dir="auto" data-snippet-clipboard-copy-content="python -m ferret.serve.controller --host 0.0.0.0 --port 10000"><pre>python -m ferret.serve.controller --host 0.0.0.0 --port 10000</pre></div>
<h4 tabindex="-1" dir="auto"><a id="user-content-launch-a-gradio-web-server" aria-hidden="true" tabindex="-1" href="#launch-a-gradio-web-server"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Launch a gradio web server.</h4>
<div dir="auto" data-snippet-clipboard-copy-content="python -m ferret.serve.gradio_web_server --controller http://localhost:10000 --model-list-mode reload --add_region_feature"><pre>python -m ferret.serve.gradio_web_server --controller http://localhost:10000 --model-list-mode reload --add_region_feature</pre></div>
<h4 tabindex="-1" dir="auto"><a id="user-content-launch-a-model-worker" aria-hidden="true" tabindex="-1" href="#launch-a-model-worker"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Launch a model worker</h4>
<p dir="auto">This is the worker that load the ckpt and do the inference on the GPU.  Each worker is responsible for a single model specified in <code>--model-path</code>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="CUDA_VISIBLE_DEVICES=0 python -m ferret.serve.model_worker --host 0.0.0.0 --controller http://localhost:10000 --port 40000 --worker http://localhost:40000 --model-path ./checkpoints/FERRET-13B-v0 --add_region_feature"><pre>CUDA_VISIBLE_DEVICES=0 python -m ferret.serve.model_worker --host 0.0.0.0 --controller http://localhost:10000 --port 40000 --worker http://localhost:40000 --model-path ./checkpoints/FERRET-13B-v0 --add_region_feature</pre></div>
<p dir="auto">Wait until the process finishes loading the model and you see &#34;Uvicorn running on ...&#34;.  Now, refresh your Gradio web UI, and you will see the model you just launched in the model list.</p>
<p dir="auto">
    <a target="_blank" rel="noopener noreferrer" href="https://github.com/apple/ml-ferret/blob/main/figs/ferret_demo.png"><img src="https://github.com/apple/ml-ferret/raw/main/figs/ferret_demo.png" width="105%"/></a> </p>
<h2 tabindex="-1" dir="auto"><a id="user-content-citation" aria-hidden="true" tabindex="-1" href="#citation"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Citation</h2>
<p dir="auto">If you find Ferret useful, please cite using this BibTeX:</p>
<div dir="auto" data-snippet-clipboard-copy-content="@article{you2023ferret,
  title={Ferret: Refer and Ground Anything Anywhere at Any Granularity},
  author={You, Haoxuan and Zhang, Haotian and Gan, Zhe and Du, Xianzhi and Zhang, Bowen and Wang, Zirui and Cao, Liangliang and Chang, Shih-Fu and Yang, Yinfei},
  journal={arXiv preprint arXiv:2310.07704},
  year={2023}
}"><pre><span>@article</span>{<span>you2023ferret</span>,
  <span>title</span>=<span><span>{</span>Ferret: Refer and Ground Anything Anywhere at Any Granularity<span>}</span></span>,
  <span>author</span>=<span><span>{</span>You, Haoxuan and Zhang, Haotian and Gan, Zhe and Du, Xianzhi and Zhang, Bowen and Wang, Zirui and Cao, Liangliang and Chang, Shih-Fu and Yang, Yinfei<span>}</span></span>,
  <span>journal</span>=<span><span>{</span>arXiv preprint arXiv:2310.07704<span>}</span></span>,
  <span>year</span>=<span><span>{</span>2023<span>}</span></span>
}</pre></div>
<h2 tabindex="-1" dir="auto"><a id="user-content-acknowledgement" aria-hidden="true" tabindex="-1" href="#acknowledgement"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Acknowledgement</h2>
<ul dir="auto">
<li><a href="https://github.com/haotian-liu/LLaVA">LLaVA</a>: the codebase we built upon.</li>
<li><a href="https://github.com/lm-sys/FastChat">Vicuna</a>: the LLM codebase.</li>
</ul>
</article>
          </div></div>
  </body>
</html>
