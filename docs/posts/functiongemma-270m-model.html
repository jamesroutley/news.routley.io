<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.google/technology/developers/functiongemma/">Original</a>
    <h1>FunctionGemma 270M Model</h1>
    
    <div id="readability-page-1" class="page"><article>

    
    


<section>
  
</section>


    

    
      








<div data-analytics-module="{
    &#34;module_name&#34;: &#34;Hero Menu&#34;,
    &#34;section_header&#34;: &#34;FunctionGemma: Bringing bespoke function calling to the edge&#34;
  }">
  
  <div>
    <div>
      
      
        <p>
          We’re releasing a specialized version of our Gemma 3 270M model fine-tuned for function calling and a training recipe for users to specialize for even better performance.
        </p>
      
    </div>
  </div>
  
  <div>
    <div>
      
        


  
  
    
  

  
  
    <div>
      
  

<div>
  <p>Ravin Kumar</p>
  
    <p>
      Research Engineer
    </p>
  
  
</div>

    </div>
  


      

      
      
    </div>
    
      
    
    
  </div>
</div>

    

    
      










<div>
  <div>
    <figure>
      <div>
        <p><img alt="FunctionGemma Logo text" data-component="uni-progressive-image" fetchpriority="high" height="150px" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/FunctionGemma-Keyword_RD1-V01.width-200.format-webp.webp" width="360px" data-sizes="(max-width: 1023px) 100vw,(min-width: 1024px and max-width: 1259) 80vw, 1046px" data-srcset="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/FunctionGemma-Keyword_RD1-V01.width-800.format-webp.webp 800w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/FunctionGemma-Keyword_RD1-V01.width-1200.format-webp.webp 1200w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/FunctionGemma-Keyword_RD1-V01.width-1600.format-webp.webp 1600w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/FunctionGemma-Keyword_RD1-V01.width-2200.format-webp.webp 2200w"/>
        </p>
      </div>
      
    </figure>
  </div>
</div>






    

    
    <section>
      <div>
        
          
          
          <div data-reading-time="true" data-component="uni-article-body">

            
  
    
    
    
    

    <uni-article-speakable page-title="FunctionGemma: Bringing bespoke function calling to the edge" listen-to-article="Listen to article" data-date-modified="2025-12-18T18:00:59.275665+00:00" data-tracking-ids="G-HGNBTNCHCQ,G-6NKTLKV14N" data-voice-list="en.ioh-pngnat:Cyan,en.usb-pngnat:Lime" data-script-src="https://www.gstatic.com/readaloud/player/web/api/js/api.js" data-highlight-mode="word-over-paragraph"></uni-article-speakable>
  





            
            
<!--article text-->

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;FunctionGemma: Bringing bespoke function calling to the edge&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><p data-block-key="8nk5z">It has been a transformative year for the Gemma family of models. In 2025, we have grown from 100 million to over 300 million downloads while demonstrating the <a href="https://blog.google/technology/developers/developers-changing-lives-with-gemma-3n/">transformative potential of open models</a>, from defining state-of-the-art single-accelerator performance with <a href="https://blog.google/technology/developers/gemma-3/">Gemma 3</a> to advancing cancer research through <a href="https://blog.google/technology/ai/google-gemma-ai-cancer-therapy-discovery/">the C2S Scale initiative</a>.</p><p data-block-key="7i58b">Since launching the <a href="https://developers.googleblog.com/en/introducing-gemma-3-270m/">Gemma 3 270M model,</a> the number one request we’ve received from developers is for native function calling capabilities. We listened, recognizing that as the industry shifts from purely conversational interfaces to active agents, models need to do more than just talk — they need to act. This is particularly compelling on-device, where agents can automate complex, multi-step workflows, from setting reminders to toggling system settings. To enable this at the edge, models must be lightweight enough to run locally and specialized enough to be reliable.</p><p data-block-key="fmj55">Today, we are releasing FunctionGemma, a specialized version of our <a href="https://developers.googleblog.com/en/introducing-gemma-3-270m/">Gemma 3 270M</a> model tuned for function calling. It is designed as a strong base for further training into custom, fast, private, local agents that translate natural language into executable API actions.</p><p data-block-key="9qs74">FunctionGemma acts as a fully independent agent for private, offline tasks, or as an intelligent traffic controller for larger connected systems. In this role, it can handle common commands instantly at the edge, while routing more complex tasks to models like Gemma 3 27B.</p></div>
      </div>
    </div>
  

  
    
  
    




  <uni-youtube-player-article index="2" thumbnail-alt="Introducing FunctionGemma" video-id="-Tgc_9uYJLI" video-type="video">
  </uni-youtube-player-article>











  


  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;FunctionGemma: Bringing bespoke function calling to the edge&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><h3 data-block-key="iv8ay">What makes FunctionGemma unique</h3><ul><li data-block-key="49q82"><b>Unified action and chat:</b> FunctionGemma knows how to talk to both computers and humans. It can generate structured function calls to execute tools, then switch context to summarize the results in natural language for the user.</li><li data-block-key="ebirk"><b>Built for customization:</b> FunctionGemma is designed to be molded, not just prompted. In our &#34;Mobile Actions&#34; evaluation, fine-tuning transformed the model’s reliability, boosting accuracy from a 58% baseline to 85%. This confirms that for edge agents, a dedicated, trained specialist is an efficient path to production-grade performance.</li><li data-block-key="7rblf"><b>Engineered for the edge:</b> Small enough to run on edge devices like the <a href="https://www.jetson-ai-lab.com/models/functiongemma">NVIDIA Jetson Nano</a> and mobile phones, the model uses Gemma’s 256k vocabulary to efficiently tokenize JSON and multilingual inputs. This makes it a strong base for fine-tuning in specific domains, reducing sequence length to ensure minimum latency and total user privacy.</li><li data-block-key="b5v5"><b>Broad ecosystem support:</b> The model is supported by popular tools across the entire workflow: fine-tune with <a href="https://huggingface.co/collections/google/functiongemma">Hugging Face Transformers</a>, <a href="https://docs.unsloth.ai/models/function-gemma">Unsloth</a>, Keras or <a href="https://github.com/NVIDIA-NeMo/Automodel/blob/main/examples/llm_finetune/gemma/functiongemma_xlam.yaml">NVIDIA NeMo</a> and deploy using <a href="https://github.com/google-ai-edge/LiteRT-LM/blob/main/README.md">LiteRT-LM</a>, vLLM, <a href="https://huggingface.co/collections/mlx-community/functiongemma">MLX</a>, <a href="https://huggingface.co/ggml-org/functiongemma-270m-it-GGUF">Llama.cpp</a>, <a href="https://ollama.com/library/functiongemma">Ollama</a>, <a href="https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/functiongemma">Vertex AI</a> or <a href="https://lmstudio.ai/models/functiongemma">LM Studio</a>.</li></ul></div>
      </div>
    </div>
  

  
    














<uni-image-full-width alignment="full" alt-text="Bar Graph of FunctionGemma Accuracy on Mobile Actions before and after fine-tuning" external-image="" or-mp4-video-title="" or-mp4-video-url="" section-header="FunctionGemma: Bringing bespoke function calling to the edge" custom-class="image-full-width--constrained-width uni-component-spacing">
  
    <div slot="caption-slot">
      <p data-block-key="al249">FunctionGemma accuracy on Mobile Actions dataset before and after <a href="https://github.com/google-gemini/gemma-cookbook/blob/main/FunctionGemma/%5BFunctionGemma%5DFinetune_FunctionGemma_270M_for_Mobile_Actions_with_Hugging_Face.ipynb">fine-tuning</a> on a held out eval set.</p>
    </div>
  
  
    <p><img alt="Bar Graph of FunctionGemma Accuracy on Mobile Actions before and after fine-tuning" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/FunctionGemma_Chart_RD1_V01_1.width-100.format-webp.webp" loading="lazy" data-loading="{
            &#34;mobile&#34;: &#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/FunctionGemma_Chart_RD1_V01_1.width-500.format-webp.webp&#34;,
            &#34;desktop&#34;: &#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/FunctionGemma_Chart_RD1_V01_1.width-1000.format-webp.webp&#34;
          }"/>
    </p>
  
</uni-image-full-width>


  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;FunctionGemma: Bringing bespoke function calling to the edge&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><h2 data-block-key="8nk5z">When to choose FunctionGemma</h2><p data-block-key="1n8kk">FunctionGemma is the bridge between natural language and software execution. It is the right tool if:</p><ul><li data-block-key="53sff"><b>You have a defined API surface:</b> Your application has a defined set of actions (e.g., smart home, media, navigation).</li><li data-block-key="9jgn5"><b>You are ready to fine-tune:</b> You need the consistent, deterministic behavior that comes from fine-tuning on specific data, rather than the variability of zero-shot prompting.</li><li data-block-key="8i36a"><b>You prioritize local-first deployment:</b> Your application requires near-instant latency and total data privacy, running efficiently within the compute and battery limits of edge devices.</li><li data-block-key="8u7fp"><b>You are building compound systems:</b> You need a lightweight edge model to handle local actions, allowing your system to process common commands on-device and only query larger models (like Gemma 3 27B) for more complex tasks.</li></ul><h2 data-block-key="44eug">How to see it in action</h2><p data-block-key="f8k26">Let&#39;s look at how these models transform actual user experiences. You can explore these capabilities in the <a href="https://play.google.com/store/apps/details?id=com.google.ai.edge.gallery&amp;pcampaignid=web_share">Google AI Edge Gallery app</a> through two distinct experiences: an interactive game and a developer challenge.</p><h3 data-block-key="cqdag">Mobile Actions fine tuning</h3><p data-block-key="adj9l">This demo reimagines assistant interaction as a fully offline capability. Whether it’s &#34;<i>Create a calendar event for lunch tomorrow,</i>&#34; &#34;<i>Add John to my contacts</i>&#34; or &#34;<i>Turn on the flashlight,</i>&#34; the model parses the natural language and identifies the correct OS tool to execute the command. To unlock this agent, developers are invited to use our <a href="https://github.com/google-gemini/gemma-cookbook/blob/main/FunctionGemma/%5BFunctionGemma%5DFinetune_FunctionGemma_270M_for_Mobile_Actions_with_Hugging_Face.ipynb">fine-tuning cookbook</a> to build the model and load it onto their mobile device.</p></div>
      </div>
    </div>
  

  
    














<uni-image-full-width alignment="full" alt-text="Mobile Action demo that reimagines assistant interaction as a fully offline capability." external-image="" or-mp4-video-title="Mobile Action" or-mp4-video-url="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/01_MobileActions.mp4" section-header="FunctionGemma: Bringing bespoke function calling to the edge" custom-class="image-full-width--constrained-width uni-component-spacing">
  
  
</uni-image-full-width>


  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;FunctionGemma: Bringing bespoke function calling to the edge&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><h3 data-block-key="8nk5z">TinyGarden game demo</h3><p data-block-key="cg11h">In this interactive mini-game, players use voice commands to manage a virtual plot of land. You might say, &#34;Plant sunflowers in the top row and water them,&#34; and the model decomposes this into specific app functions like plantCrop or waterCrop targeting specific grid coordinates. This proves that a 270M model can handle multi-turn logic to drive custom game mechanics, on a mobile phone, without ever pinging a server.</p></div>
      </div>
    </div>
  

  
    














<uni-image-full-width alignment="full" alt-text="Tini Garden mini-game that shows players using voice commands to manage a virtual plot of land." external-image="" or-mp4-video-title="Tiny Garden" or-mp4-video-url="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/02_TinyGarden.mp4" section-header="FunctionGemma: Bringing bespoke function calling to the edge" custom-class="image-full-width--constrained-width uni-component-spacing">
  
  
</uni-image-full-width>


  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;FunctionGemma: Bringing bespoke function calling to the edge&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><h3 data-block-key="oa3cj">FunctionGemma Physics Playground</h3><p data-block-key="1a2c8">Use natural language to solve fun physics simulation puzzles in <a href="https://huggingface.co/spaces/webml-community/FunctionGemma-Physics-Playground">a game that runs 100% locally in your browser</a>, powered by FunctionGemma and Transformers.js!</p><p data-block-key="4r89e">Credit: @xenovacom on X</p></div>
      </div>
    </div>
  

  
    














<uni-image-full-width alignment="full" alt-text="FunctionGemma Physics Playground" external-image="" or-mp4-video-title="FunctionGemma Physics Playground" or-mp4-video-url="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/FG3_-_SD_480p.mov" section-header="FunctionGemma: Bringing bespoke function calling to the edge" custom-class="image-full-width--constrained-width uni-component-spacing">
  
  
</uni-image-full-width>


  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;FunctionGemma: Bringing bespoke function calling to the edge&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><h2 data-block-key="oa3cj">How to try FunctionGemma today</h2><p data-block-key="fasnq">We are moving from an era of chatbots to an era of action. With FunctionGemma, that power now fits in your pocket.</p><ul><li data-block-key="a26e8"><b>Download:</b> Get the model on <a href="https://huggingface.co/google/functiongemma-270m-it">Hugging Face</a> or <a href="https://www.kaggle.com/models/google/functiongemma">Kaggle</a>.</li><li data-block-key="7pnnc"><b>Learn:</b> Check out the <a href="https://ai.google.dev/gemma/docs/functiongemma">guides</a> on <a href="https://ai.google.dev/gemma/docs/functiongemma/formatting-and-best-practices">function calling templates</a>, <a href="https://ai.google.dev/gemma/docs/functiongemma/full-function-calling-sequence-with-functiongemma">how to sequence the model with function responses</a> and <a href="https://ai.google.dev/gemma/docs/functiongemma/finetuning-with-functiongemma">fine-tuning</a>.</li><li data-block-key="e52a8"><b>Explore:</b> Download the updated <a href="https://play.google.com/store/apps/details?id=com.google.ai.edge.gallery&amp;pcampaignid=web_share">Google AI Edge Gallery</a> to try the demos.</li><li data-block-key="7u17r"><b>Build:</b> Access the Mobile Actions <a href="https://ai.google.dev/gemma/docs/functiongemma/mobile-actions">guide</a> with a <a href="https://github.com/google-gemini/gemma-cookbook/blob/main/FunctionGemma/%5BFunctionGemma%5DFinetune_FunctionGemma_270M_for_Mobile_Actions_with_Hugging_Face.ipynb">Colab notebook</a> and <a href="https://huggingface.co/datasets/google/mobile-actions">dataset</a> to train your own specialized agent.</li><li data-block-key="42kb9"><b>Deploy:</b> Easily publish your own models onto mobile devices using <a href="https://github.com/google-ai-edge/LiteRT-LM">LiteRT-LM</a> or use alongside larger models on Vertex AI or NVIDIA devices like RTX PRO and DGX Spark.</li></ul><p data-block-key="2bqvk">We can’t wait to see the unique, private, and ultra-fast experiences you unlock on-device.</p></div>
      </div>
    </div>
  


            
            

            
              




            
          </div>
        
      </div>
    </section>
  </article></div>
  </body>
</html>
