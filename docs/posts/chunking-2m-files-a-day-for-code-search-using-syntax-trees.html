<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://docs.sweep.dev/blogs/chunking-2m-files">Original</a>
    <h1>Chunking 2M files a day for code search using syntax trees</h1>
    
    <div id="readability-page-1" class="page"><article><main><div><p>üìù Blogs</p><svg fill="none" viewBox="0 0 24 24" stroke="currentColor"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M9 5l7 7-7 7"></path></svg><p>üç™ Chunking 2M+ files a day for Code Search using Syntax Trees</p></div>
<p><strong>Kevin Lu</strong> - July 30th, 2023</p>
<p><em>Update: This algorithm is now publicly available in LlamaIndex at <a href="https://github.com/jerryjliu/llama_index/blob/e567e6a20cf89bfdc7e1c62fd456648cc59d7480/llama_index/langchain_helpers/text_splitter.py#L476-L559C1" target="_blank" rel="noreferrer">https://github.com/jerryjliu/llama_index/blob/e567e6a20cf89bfdc7e1c62fd456648cc59d7480/llama_index/langchain_helpers/text_splitter.py#L476-L559C1<span> (opens in a new tab)</span></a>!</em></p>
<hr/>
<p>Initializing any vector store requires chunking large documents for effective search.</p>
<p>Why can&#39;t we just embed entire files? Let&#39;s consider the file of our main API <a href="https://github.com/sweepai/sweep/blob/b267b613d4c706eaf959fe6789f11e9a856521d1/sweepai/api.py" target="_blank" rel="noreferrer">endpoint<span> (opens in a new tab)</span></a>:</p>
<ol>
<li>Imports</li>
<li>Constants declarations</li>
<li>Helper functions</li>
<li>Business logic for each webhook endpoint</li>
</ol>
<p>If I search for ‚ÄúGitHub Action run‚Äù, it should match the section corresponding to the <a href="https://github.com/sweepai/sweep/blob/b267b613d4c706eaf959fe6789f11e9a856521d1/sweepai/api.py#L295-L313" target="_blank" rel="noreferrer">switch case block<span> (opens in a new tab)</span></a> that checks for the ‚Äúcheck_runs completed‚Äù event. However, this is only 20 lines of code out of 400+ lines, so even a perfect search algorithm would only consider this a 5% match. However, if we chunk the 400 lines into 20 chunks of 20 lines each, it would match the correct switch case block.</p>
<p>How do we create 20-line chunks? One naive approach is to evenly break up the 400-line file into 20-line chunks.</p>
<p>However, this approach does not work. Semantically similar code will not stay together, and we&#39;ll lost context. For instance, function headers could be separated from their implementation details and the docstrings.</p>
<p>Our current code chunking algorithm processes <strong>2M+ files a day</strong> and is <a href="https://github.com/sweepai/sweep/blob/b267b613d4c706eaf959fe6789f11e9a856521d1/sweepai/utils/utils.py#L48-L126" target="_blank" rel="noreferrer">open-source<span> (opens in a new tab)</span></a>!</p>
<h2>Constraints üöß<span id="constraints-"></span><a href="#constraints-" aria-label="Permalink for this section"></a></h2>
<p>Most chunkers for RAG-based (retrieval augmented generation) agents cap by token count. For simplicity, we decided to use character count, with a max of 1500.</p>
<p>This is because the average token to character ratio for code is ~1:5(300 tokens), and embeddings models are capped at 512 tokens. Further, 1500 characters correspond approximately to 40 lines, roughly equivalent to a small to medium sized function or class.</p>
<p>The challenge is getting as close to 1500 characters as possible, while ensuring the chunks are semantically similar and the relevant context is connected.</p>
<h2>Out of the Box Solution üì¶<span id="out-of-the-box-solution-"></span><a href="#out-of-the-box-solution-" aria-label="Permalink for this section"></a></h2>
<p>The easiest out-of-the-box solution for code chunking is <a href="https://js.langchain.com/docs/modules/data_connection/document_transformers/text_splitters/code_splitter" target="_blank" rel="noreferrer">Langchain‚Äôs recursive chunker<span> (opens in a new tab)</span></a>. At a high level:</p>
<ol>
<li>Break the text using the top-level delimiter (firstly using classes, then function definitions, then function methods etc.)</li>
<li>Loop through each section and greedily concatenate them until it breaks the character limit. For chunks that are too big, recursively chunk the section starting with the next-level delimiter.</li>
</ol>
<div><pre data-language="python" data-theme="default"><code dir="ltr" data-language="python" data-theme="default"><span><span>delimiters </span><span>=</span><span> [</span><span>&#34;\nclass &#34;</span><span>,</span><span> </span><span>&#34;\ndef &#34;</span><span>,</span><span> </span><span>&#34;\n\tdef &#34;</span><span>,</span><span> </span><span>&#34;\n\n&#34;</span><span>,</span><span> </span><span>&#34;\n&#34;</span><span>,</span><span> </span><span>&#34; &#34;</span><span>,</span><span> </span><span>&#34;&#34;</span><span>]</span></span>
<span><span>def</span><span> </span><span>chunk</span><span>(</span><span>text</span><span>:</span><span> </span><span>str</span><span>,</span><span> </span><span>delimiter_index</span><span>:</span><span> </span><span>int</span><span> </span><span>=</span><span> </span><span>0</span><span>,</span><span> </span><span>MAX_CHARS</span><span>:</span><span> </span><span>int</span><span> </span><span>=</span><span> </span><span>1500</span><span>) </span><span>-&gt;</span><span> list</span><span>[</span><span>str</span><span>]</span><span>:</span></span>
<span><span>	delimiter </span><span>=</span><span> delimiters</span><span>[</span><span>delimiter_index</span><span>]</span></span>
<span><span>	new_chunks </span><span>=</span><span> []</span></span>
<span><span>	current_chunk </span><span>=</span><span> </span><span>&#34;&#34;</span></span>
<span><span>	</span><span>for</span><span> section </span><span>in</span><span> text</span><span>.</span><span>split</span><span>(delimiter):</span></span>
<span><span>		</span><span>if</span><span> </span><span>len</span><span>(section)</span><span> </span><span>&gt;</span><span> MAX_CHARS</span><span>:</span></span>
<span><span>			</span><span># Section is too big, recursively chunk this section</span></span>
<span><span>			new_chunks</span><span>.</span><span>append</span><span>(current_chunk)</span></span>
<span><span>			current_chunk </span><span>=</span><span> </span><span>&#34;&#34;</span></span>
<span><span>			new_chunks</span><span>.</span><span>extend</span><span>(</span><span>chunk</span><span>(section, delimiter_index </span><span>+</span><span> </span><span>1</span><span>, MAX_CHARS)</span></span>
<span><span>		</span><span>elif</span><span> </span><span>len</span><span>(current_chunk) </span><span>+</span><span> </span><span>len</span><span>(section) </span><span>&gt;</span><span> MAX_CHARS:</span></span>
<span><span>			</span><span># Current chunk is max size</span></span>
<span><span>			new_chunks.</span><span>append</span><span>(current_chunk)</span></span>
<span><span>			current_chunk </span><span>=</span><span> section</span></span>
<span><span>		</span><span>else</span><span>:</span></span>
<span><span>			</span><span># Concatenate section to current_chunk</span></span>
<span><span>			current_chunk </span><span>+=</span><span> section</span></span>
<span><span>	</span><span>return</span><span> new_chunks</span></span></code></pre></div>
<p>For each language, we would also use different delimiters.</p>
<h3>Examples<span id="examples"></span><a href="#examples" aria-label="Permalink for this section"></a></h3>
<p>For full files of the examples, see <a href="https://gist.github.com/kevinlu1248/ded3ea33dcd8a9bd08078f4c64eb9268" target="_blank" rel="noreferrer">https://gist.github.com/kevinlu1248/ded3ea33dcd8a9bd08078f4c64eb9268<span> (opens in a new tab)</span></a>.</p>
<h4>Example #1<span id="example-1"></span><a href="#example-1" aria-label="Permalink for this section"></a></h4>
<p>Based on our <code dir="ltr">on_check_suite.py</code> file for handling GitHub Action runs. A bad split separating a string concatenation declaration from it‚Äôs contents. ‚ùå</p>
<div><pre data-language="python" data-theme="default"><code dir="ltr" data-language="python" data-theme="default"><span><span>...</span></span>
<span> </span>
<span><span>def</span><span> </span><span>on_check_suite</span><span>(</span><span>request</span><span>:</span><span> CheckRunCompleted):</span></span>
<span><span>    logger</span><span>.</span><span>info</span><span>(</span><span>f</span><span>&#34;Received check run completed event for </span><span>{</span><span>request.repository.full_name</span><span>}</span><span>&#34;</span><span>)</span></span>
<span><span>    g </span><span>=</span><span> </span><span>get_github_client</span><span>(request.installation.id)</span></span>
<span><span>    repo </span><span>=</span><span> g</span><span>.</span><span>get_repo</span><span>(request.repository.full_name)</span></span>
<span><span>    </span><span>if</span><span> </span><span>not</span><span> </span><span>get_gha_enabled</span><span>(repo):</span></span>
<span><span>        logger</span><span>.</span><span>info</span><span>(</span><span>f</span><span>&#34;Skipping github action for </span><span>{</span><span>request.repository.full_name</span><span>}</span><span> because it is not enabled&#34;</span><span>)</span></span>
<span><span>        </span><span>return</span><span> </span><span>None</span></span>
<span><span>    pr </span><span>=</span><span> repo</span><span>.</span><span>get_pull</span><span>(request.check_run.pull_requests[</span><span>0</span><span>].number)</span></span>
<span><span>    num_pr_commits </span><span>=</span><span> </span><span>len</span><span>(</span><span>list</span><span>(pr.</span><span>get_commits</span><span>()))</span></span>
<span><span>    </span><span>if</span><span> num_pr_commits </span><span>&gt;</span><span> </span><span>20</span><span>:</span></span>
<span><span>        logger</span><span>.</span><span>info</span><span>(</span><span>f</span><span>&#34;Skipping github action for PR with </span><span>{</span><span>num_pr_commits</span><span>}</span><span> commits&#34;</span><span>)</span></span>
<span><span>        </span><span>return</span><span> </span><span>None</span></span>
<span><span>    logger</span><span>.</span><span>info</span><span>(</span><span>f</span><span>&#34;Running github action for PR with </span><span>{</span><span>num_pr_commits</span><span>}</span><span> commits&#34;</span><span>)</span></span>
<span><span>    logs </span><span>=</span><span> </span><span>download_logs</span><span>(</span></span>
<span><span>        request.repository.full_name,</span></span>
<span><span>        request.check_run.run_id,</span></span>
<span><span>        request.installation.id</span></span>
<span><span>    )</span></span>
<span><span>    </span><span>if</span><span> </span><span>not</span><span> logs</span><span>:</span></span>
<span><span>        </span><span>return</span><span> </span><span>None</span></span>
<span><span>    logs </span><span>=</span><span> </span><span>clean_logs</span><span>(logs)</span></span>
<span><span>    extractor </span><span>=</span><span> </span><span>GHAExtractor</span><span>()</span></span>
<span><span>    logger</span><span>.</span><span>info</span><span>(</span><span>f</span><span>&#34;Extracting logs from </span><span>{</span><span>request.repository.full_name</span><span>}</span><span>, logs: </span><span>{</span><span>logs</span><span>}</span><span>&#34;</span><span>)</span></span>
<span><span>    problematic_logs </span><span>=</span><span> extractor</span><span>.</span><span>gha_extract</span><span>(logs)</span></span>
<span><span>    </span><span>if</span><span> problematic_logs</span><span>.</span><span>count</span><span>(</span><span>&#34;</span></span>
<span><span>&#34;) &gt; 15:</span></span>
<span><span>        problematic_logs </span><span>+=</span><span> </span><span>&#34;</span></span>
<span> </span>
<span><span>========================================</span></span>
<span> </span>
<span><span>There are a lot of errors. This </span><span>is</span><span> likely a larger issue </span><span>with</span><span> the PR </span><span>and</span><span> </span><span>not</span><span> a small linting</span><span>/</span><span>type</span><span>-</span><span>checking issue.</span><span>&#34;</span></span>
<span><span>    comments </span><span>=</span><span> </span><span>list</span><span>(pr.</span><span>get_issue_comments</span><span>())</span></span>
<span><span>    </span><span>if</span><span> </span><span>len</span><span>(comments) </span><span>&gt;=</span><span> </span><span>2</span><span> </span><span>and</span><span> problematic_logs </span><span>==</span><span> comments[</span><span>-</span><span>1</span><span>].body </span><span>and</span><span> comments[</span><span>-</span><span>2</span><span>].body </span><span>==</span><span> comments[</span><span>-</span><span>1</span><span>].body:</span></span>
<span><span>        comment </span><span>=</span><span> pr.</span><span>as_issue</span><span>().</span><span>create_comment</span><span>(log_message.</span><span>format</span><span>(error_logs</span><span>=</span><span>problematic_logs) </span><span>+</span><span> </span><span>&#34;</span></span>
<span> </span>
<span><span>I</span><span>&#39;m getting the same errors 3 times in a row, so I will stop working on fixing this PR.&#34;)</span></span>
<span><span>        logger.</span><span>warning</span><span>(</span><span>&#34;Skipping logs because it is duplicated&#34;</span><span>)</span></span>
<span><span>        </span><span>raise</span><span> </span><span>Exception</span><span>(</span><span>&#34;Duplicate error logs&#34;</span><span>)</span></span>
<span><span>    </span><span>print</span><span>(problematic_logs)</span></span>
<span><span>    comment </span><span>=</span><span> pr.</span><span>as_issue</span><span>().</span><span>create_comment</span><span>(log_message.</span><span>format</span><span>(error_logs</span><span>=</span><span>problematic_logs))</span></span>
<span><span>    </span><span>on_comment</span><span>(</span></span>
<span><span>        repo_full_name</span><span>=</span><span>request.repository.full_name,</span></span>
<span><span>        repo_description</span><span>=</span><span>request.repository.description,</span></span>
<span><span>        comment</span><span>=</span><span>problematic_logs,</span></span>
<span><span>        pr_path</span><span>=</span><span>None</span><span>,</span></span>
<span><span>        pr_line_position</span><span>=</span><span>None</span><span>,</span></span>
<span><span>        username</span><span>=</span><span>request.sender.login,</span></span>
<span><span>        installation_id</span><span>=</span><span>request.installation.id,</span></span>
<span><span>        pr_number</span><span>=</span><span>request.check_run.pull_requests[</span><span>0</span><span>].number,</span></span>
<span><span>        comment_id</span><span>=</span><span>comment.id,</span></span>
<span><span>        repo</span><span>=</span><span>repo,</span></span>
<span><span>    )</span></span>
<span><span>    </span><span>return</span><span> {</span><span>&#34;success&#34;</span><span>: </span><span>True</span><span>}</span></span></code></pre></div>
<h4>Example #2<span id="example-2"></span><a href="#example-2" aria-label="Permalink for this section"></a></h4>
<p>Based on <code dir="ltr">BaseIndex.ts</code> file from LlamaIndex declaring the ABC for vector stores. A bad split separates a class method from its header. ‚ùå</p>
<div><pre data-language="tsx" data-theme="default"><code dir="ltr" data-language="tsx" data-theme="default"><span><span>...</span></span>
<span> </span>
<span><span>export</span><span> </span><span>class</span><span> </span><span>IndexDict</span><span> </span><span>extends</span><span> </span><span>IndexStruct</span><span> {</span></span>
<span><span>  nodesDict</span><span>:</span><span> </span><span>Record</span><span>&lt;</span><span>string</span><span>,</span><span> </span><span>BaseNode</span><span>&gt; </span><span>=</span><span> {};</span></span>
<span><span>  docStore</span><span>:</span><span> </span><span>Record</span><span>&lt;</span><span>string</span><span>,</span><span> </span><span>Document</span><span>&gt; </span><span>=</span><span> {}; </span><span>// FIXME: this should be implemented in storageContext</span></span>
<span><span>  type</span><span>:</span><span> </span><span>IndexStructType</span><span> </span><span>=</span><span> </span><span>IndexStructType</span><span>.</span><span>SIMPLE_DICT</span><span>;</span></span>
<span> </span>
<span><span>========================================</span></span>
<span> </span>
<span><span>getSummary</span><span>()</span><span>:</span><span> </span><span>string</span><span> {</span></span>
<span><span>    </span><span>if</span><span> (</span><span>this</span><span>.summary </span><span>===</span><span> </span><span>undefined</span><span>) {</span></span>
<span><span>      </span><span>throw</span><span> </span><span>new</span><span> </span><span>Error</span><span>(</span><span>&#34;summary field of the index dict is not set&#34;</span><span>);</span></span>
<span><span>    }</span></span>
<span><span>    </span><span>return</span><span> </span><span>this</span><span>.summary;</span></span>
<span><span>  }</span></span>
<span> </span>
<span><span>  </span><span>addNode</span><span>(node</span><span>:</span><span> </span><span>BaseNode</span><span>,</span><span> textId</span><span>?:</span><span> </span><span>string</span><span>) {</span></span>
<span><span>    </span><span>const</span><span> </span><span>vectorId</span><span> </span><span>=</span><span> textId </span><span>??</span><span> </span><span>node</span><span>.id_;</span></span>
<span><span>    </span><span>this</span><span>.nodesDict[vectorId] </span><span>=</span><span> node;</span></span>
<span><span>  }</span></span>
<span> </span>
<span><span>  </span><span>toJson</span><span>()</span><span>:</span><span> </span><span>Record</span><span>&lt;</span><span>string</span><span>,</span><span> </span><span>unknown</span><span>&gt; {</span></span>
<span><span>    </span><span>return</span><span> {</span></span>
<span><span>      </span><span>...</span><span>super.toJson</span><span>()</span><span>,</span></span>
<span><span>      nodesDict</span><span>:</span><span> </span><span>this</span><span>.nodesDict</span><span>,</span></span>
<span><span>      type</span><span>:</span><span> </span><span>this</span><span>.type</span><span>,</span></span>
<span><span>    };</span></span>
<span><span>  }</span></span>
<span><span>}</span></span>
<span> </span>
<span><span>...</span></span></code></pre></div>
<h3>Problems ü§î<span id="problems-"></span><a href="#problems-" aria-label="Permalink for this section"></a></h3>
<p>However, it comes with some major problems:</p>
<ol>
<li>This chunker decently for Python but breaks curly-bracket-heavy languages like JS and XML-based languages like HTML in unexpected ways.<!-- -->
<ul>
<li>Further, <code dir="ltr">str.split</code> does not work well for these more complex syntaxes like JS and HTML.</li>
<li>E.g. Even for Python, it broke the problematic logs line by splitting <code dir="ltr">problematic_logs += \&#34;</code> and the rest of the string</li>
</ul>
</li>
<li>Only 16 languages are currently supported, without support for JSX, Typescript, EJS and C#.<!-- -->
<ul>
<li>JSX/TSX makes up the majority of our userbase</li>
</ul>
</li>
<li>Langchain deletes important delimiters such as ‚Äúdef‚Äù and ‚Äúclass‚Äù.</li>
</ol>
<h2>Our Solution üß†<span id="our-solution-"></span><a href="#our-solution-" aria-label="Permalink for this section"></a></h2>
<p>The inherent problem is that iterative <code dir="ltr">str.split</code> with different delimiters is a primitive method for approximating concrete syntax trees (CST).</p>
<p>To solve this, we decided to just use CST parsers. But how do we get CST parsers for a large number of languages? Thankfully, the library <a href="https://tree-sitter.github.io/" target="_blank" rel="noreferrer">tree-sitter<span> (opens in a new tab)</span></a> provides a standardized way to access 113 CST-parsers for programming languages and is fast (written in C) and dependency-free.</p>
<p>The new algorithm is fairly similar to the Langchain algorithm and is as follows:</p>
<ol>
<li>To chunk a parent node, we iterate through its children and greedily bundle them together. For each child node:<!-- -->
<ol>
<li>If the current chunk is too big, we add that to our list of chunks and empty the bundle</li>
<li>If the next child node is too big, we recursively chunk the child node and add it to the list of chunks</li>
<li>Otherwise, concatenate the current chunk with the child node</li>
</ol>
</li>
<li>Post-process the final result by combining single-line chunks with the next chunk.<!-- -->
<ol>
<li>This guarantees that there are no chunks that are too small since they yield less meaningful results</li>
</ol>
</li>
</ol>
<div><pre data-language="python" data-theme="default"><code dir="ltr" data-language="python" data-theme="default"><span><span>from</span><span> tree_sitter </span><span>import</span><span> Node</span></span>
<span> </span>
<span><span>def</span><span> </span><span>chunk_node</span><span>(</span><span>node</span><span>:</span><span> Node</span><span>,</span><span> </span><span>text</span><span>:</span><span> </span><span>str</span><span>,</span><span> </span><span>MAX_CHARS</span><span>:</span><span> </span><span>int</span><span> </span><span>=</span><span> </span><span>1500</span><span>) </span><span>-&gt;</span><span> list</span><span>[</span><span>str</span><span>]</span><span>:</span></span>
<span><span>	new_chunks </span><span>=</span><span> []</span></span>
<span><span>	current_chunk </span><span>=</span><span> </span><span>&#34;&#34;</span></span>
<span><span>	</span><span>for</span><span> child </span><span>in</span><span> node</span><span>.</span><span>children</span><span>:</span></span>
<span><span>		</span><span>if</span><span> child</span><span>.</span><span>end_byte </span><span>-</span><span> child</span><span>.</span><span>start_byte </span><span>&gt;</span><span> MAX_CHARS</span><span>:</span></span>
<span><span>			new_chunks</span><span>.</span><span>append</span><span>(current_chunk)</span></span>
<span><span>			current_chunk </span><span>=</span><span> </span><span>&#34;&#34;</span></span>
<span><span>			new_chunks</span><span>.</span><span>extend</span><span>(</span><span>chunk_node</span><span>(child, text, MAX_CHARS)</span></span>
<span><span>		</span><span>elif</span><span>  </span><span>&gt;</span><span> MAX_CHARS:</span></span>
<span><span>			new_chunks.</span><span>append</span><span>(current_chunk)</span></span>
<span><span>			current_chunk </span><span>=</span><span> text[node.start_byte:node.end_byte]</span></span>
<span><span>		</span><span>else</span><span>:</span></span>
<span><span>			current_chunk </span><span>+=</span><span> text[node.start_byte:node.end_byte]</span></span>
<span><span>	</span><span>return</span><span> new_chunks</span></span></code></pre></div>
<h3>Example<span id="example"></span><a href="#example" aria-label="Permalink for this section"></a></h3>
<p>Full chunks can be found at <a href="https://gist.github.com/kevinlu1248/49a72a1978868775109c5627677dc512" target="_blank" rel="noreferrer">https://gist.github.com/kevinlu1248/49a72a1978868775109c5627677dc512<span> (opens in a new tab)</span></a></p>
<h4>Example #1<span id="example-1-1"></span><a href="#example-1-1" aria-label="Permalink for this section"></a></h4>
<p>Based on our <code dir="ltr">on_check_suite.py</code> file for handling GitHub Action runs. Correct splitting, also splitting before an if statement instead of separating the if-statement from the body. ‚úÖ</p>
<div><pre data-language="python" data-theme="default"><code dir="ltr" data-language="python" data-theme="default"><span><span>...</span></span>
<span> </span>
<span><span>def</span><span> </span><span>on_check_suite</span><span>(</span><span>request</span><span>:</span><span> CheckRunCompleted):</span></span>
<span><span>    logger</span><span>.</span><span>info</span><span>(</span><span>f</span><span>&#34;Received check run completed event for </span><span>{</span><span>request.repository.full_name</span><span>}</span><span>&#34;</span><span>)</span></span>
<span><span>    g </span><span>=</span><span> </span><span>get_github_client</span><span>(request.installation.id)</span></span>
<span><span>    repo </span><span>=</span><span> g</span><span>.</span><span>get_repo</span><span>(request.repository.full_name)</span></span>
<span><span>    </span><span>if</span><span> </span><span>not</span><span> </span><span>get_gha_enabled</span><span>(repo):</span></span>
<span><span>        logger</span><span>.</span><span>info</span><span>(</span><span>f</span><span>&#34;Skipping github action for </span><span>{</span><span>request.repository.full_name</span><span>}</span><span> because it is not enabled&#34;</span><span>)</span></span>
<span><span>        </span><span>return</span><span> </span><span>None</span></span>
<span><span>    pr </span><span>=</span><span> repo</span><span>.</span><span>get_pull</span><span>(request.check_run.pull_requests[</span><span>0</span><span>].number)</span></span>
<span><span>    num_pr_commits </span><span>=</span><span> </span><span>len</span><span>(</span><span>list</span><span>(pr.</span><span>get_commits</span><span>()))</span></span>
<span><span>    </span><span>if</span><span> num_pr_commits </span><span>&gt;</span><span> </span><span>20</span><span>:</span></span>
<span><span>        logger</span><span>.</span><span>info</span><span>(</span><span>f</span><span>&#34;Skipping github action for PR with </span><span>{</span><span>num_pr_commits</span><span>}</span><span> commits&#34;</span><span>)</span></span>
<span><span>        </span><span>return</span><span> </span><span>None</span></span>
<span><span>    logger</span><span>.</span><span>info</span><span>(</span><span>f</span><span>&#34;Running github action for PR with </span><span>{</span><span>num_pr_commits</span><span>}</span><span> commits&#34;</span><span>)</span></span>
<span><span>    logs </span><span>=</span><span> </span><span>download_logs</span><span>(</span></span>
<span><span>        request.repository.full_name,</span></span>
<span><span>        request.check_run.run_id,</span></span>
<span><span>        request.installation.id</span></span>
<span><span>    )</span></span>
<span><span>    </span><span>if</span><span> </span><span>not</span><span> logs</span><span>:</span></span>
<span><span>        </span><span>return</span><span> </span><span>None</span></span>
<span><span>    logs </span><span>=</span><span> </span><span>clean_logs</span><span>(logs)</span></span>
<span><span>    extractor </span><span>=</span><span> </span><span>GHAExtractor</span><span>()</span></span>
<span><span>    logger</span><span>.</span><span>info</span><span>(</span><span>f</span><span>&#34;Extracting logs from </span><span>{</span><span>request.repository.full_name</span><span>}</span><span>, logs: </span><span>{</span><span>logs</span><span>}</span><span>&#34;</span><span>)</span></span>
<span><span>    problematic_logs </span><span>=</span><span> extractor</span><span>.</span><span>gha_extract</span><span>(logs)</span></span>
<span><span>    </span><span>if</span><span> problematic_logs</span><span>.</span><span>count</span><span>(</span><span>&#34;\n&#34;</span><span>)</span><span> </span><span>&gt;</span><span> </span><span>15</span><span>:</span></span>
<span><span>        problematic_logs </span><span>+=</span><span> </span><span>&#34;\n\nThere are a lot of errors. This is likely a larger issue with the PR and not a small linting/type-checking issue.&#34;</span></span>
<span><span>    comments </span><span>=</span><span> </span><span>list</span><span>(pr.</span><span>get_issue_comments</span><span>())</span></span>
<span> </span>
<span><span>==========</span></span>
<span> </span>
<span><span>    </span><span>if</span><span> </span><span>len</span><span>(comments)</span><span> </span><span>&gt;=</span><span> </span><span>2</span><span> </span><span>and</span><span> problematic_logs </span><span>==</span><span> comments</span><span>[</span><span>-</span><span>1</span><span>].</span><span>body </span><span>and</span><span> comments</span><span>[</span><span>-</span><span>2</span><span>].</span><span>body </span><span>==</span><span> comments</span><span>[</span><span>-</span><span>1</span><span>].</span><span>body</span><span>:</span></span>
<span><span>        comment </span><span>=</span><span> pr</span><span>.</span><span>as_issue</span><span>().</span><span>create_comment</span><span>(log_message.</span><span>format</span><span>(error_logs</span><span>=</span><span>problematic_logs) </span><span>+</span><span> </span><span>&#34;\n\nI&#39;m getting the same errors 3 times in a row, so I will stop working on fixing this PR.&#34;</span><span>)</span></span>
<span><span>        logger</span><span>.</span><span>warning</span><span>(</span><span>&#34;Skipping logs because it is duplicated&#34;</span><span>)</span></span>
<span><span>        </span><span>raise</span><span> </span><span>Exception</span><span>(</span><span>&#34;Duplicate error logs&#34;</span><span>)</span></span>
<span><span>    </span><span>print</span><span>(problematic_logs)</span></span>
<span><span>    comment </span><span>=</span><span> pr</span><span>.</span><span>as_issue</span><span>().</span><span>create_comment</span><span>(log_message.</span><span>format</span><span>(error_logs</span><span>=</span><span>problematic_logs))</span></span>
<span><span>    </span><span>on_comment</span><span>(</span></span>
<span><span>        repo_full_name</span><span>=</span><span>request.repository.full_name,</span></span>
<span><span>        repo_description</span><span>=</span><span>request.repository.description,</span></span>
<span><span>        comment</span><span>=</span><span>problematic_logs,</span></span>
<span><span>        pr_path</span><span>=</span><span>None</span><span>,</span></span>
<span><span>        pr_line_position</span><span>=</span><span>None</span><span>,</span></span>
<span><span>        username</span><span>=</span><span>request.sender.login,</span></span>
<span><span>        installation_id</span><span>=</span><span>request.installation.id,</span></span>
<span><span>        pr_number</span><span>=</span><span>request.check_run.pull_requests[</span><span>0</span><span>].number,</span></span>
<span><span>        comment_id</span><span>=</span><span>comment.id,</span></span>
<span><span>        repo</span><span>=</span><span>repo,</span></span>
<span><span>    )</span></span></code></pre></div>
<h4>Example #2<span id="example-2-1"></span><a href="#example-2-1" aria-label="Permalink for this section"></a></h4>
<p>Based on <code dir="ltr">BaseIndex.ts</code> file from LlamaIndex declaring the ABC for vector stores. Our chunker correctly splits between exported classes and functions. ‚úÖ</p>
<div><pre data-language="tsx" data-theme="default"><code dir="ltr" data-language="tsx" data-theme="default"><span><span>...</span></span>
<span> </span>
<span><span>export</span><span> </span><span>class</span><span> </span><span>IndexDict</span><span> </span><span>extends</span><span> </span><span>IndexStruct</span><span> {</span></span>
<span><span>  nodesDict</span><span>:</span><span> </span><span>Record</span><span>&lt;</span><span>string</span><span>,</span><span> </span><span>BaseNode</span><span>&gt; </span><span>=</span><span> {};</span></span>
<span><span>  docStore</span><span>:</span><span> </span><span>Record</span><span>&lt;</span><span>string</span><span>,</span><span> </span><span>Document</span><span>&gt; </span><span>=</span><span> {}; </span><span>// FIXME: this should be implemented in storageContext</span></span>
<span><span>  type</span><span>:</span><span> </span><span>IndexStructType</span><span> </span><span>=</span><span> </span><span>IndexStructType</span><span>.</span><span>SIMPLE_DICT</span><span>;</span></span>
<span> </span>
<span><span>  </span><span>getSummary</span><span>()</span><span>:</span><span> </span><span>string</span><span> {</span></span>
<span><span>    </span><span>if</span><span> (</span><span>this</span><span>.summary </span><span>===</span><span> </span><span>undefined</span><span>) {</span></span>
<span><span>      </span><span>throw</span><span> </span><span>new</span><span> </span><span>Error</span><span>(</span><span>&#34;summary field of the index dict is not set&#34;</span><span>);</span></span>
<span><span>    }</span></span>
<span><span>    </span><span>return</span><span> </span><span>this</span><span>.summary;</span></span>
<span><span>  }</span></span>
<span> </span>
<span><span>  </span><span>addNode</span><span>(node</span><span>:</span><span> </span><span>BaseNode</span><span>,</span><span> textId</span><span>?:</span><span> </span><span>string</span><span>) {</span></span>
<span><span>    </span><span>const</span><span> </span><span>vectorId</span><span> </span><span>=</span><span> textId </span><span>??</span><span> </span><span>node</span><span>.id_;</span></span>
<span><span>    </span><span>this</span><span>.nodesDict[vectorId] </span><span>=</span><span> node;</span></span>
<span><span>  }</span></span>
<span> </span>
<span><span>  </span><span>toJson</span><span>()</span><span>:</span><span> </span><span>Record</span><span>&lt;</span><span>string</span><span>,</span><span> </span><span>unknown</span><span>&gt; {</span></span>
<span><span>    </span><span>return</span><span> {</span></span>
<span><span>      </span><span>...</span><span>super.toJson</span><span>()</span><span>,</span></span>
<span><span>      nodesDict</span><span>:</span><span> </span><span>this</span><span>.nodesDict</span><span>,</span></span>
<span><span>      type</span><span>:</span><span> </span><span>this</span><span>.type</span><span>,</span></span>
<span><span>    };</span></span>
<span><span>  }</span></span>
<span><span>}</span></span>
<span> </span>
<span><span>========================================</span></span>
<span> </span>
<span><span>export</span><span> </span><span>function</span><span> </span><span>jsonToIndexStruct</span><span>(json</span><span>:</span><span> </span><span>any</span><span>)</span><span>:</span><span> </span><span>IndexStruct</span><span> {</span></span>
<span><span>  </span><span>if</span><span> (</span><span>json</span><span>.type </span><span>===</span><span> </span><span>IndexStructType</span><span>.</span><span>LIST</span><span>) {</span></span>
<span><span>    </span><span>const</span><span> </span><span>indexList</span><span> </span><span>=</span><span> </span><span>new</span><span> </span><span>IndexList</span><span>(</span><span>json</span><span>.indexId</span><span>,</span><span> </span><span>json</span><span>.summary);</span></span>
<span><span>    </span><span>indexList</span><span>.nodes </span><span>=</span><span> </span><span>json</span><span>.nodes;</span></span>
<span><span>    </span><span>return</span><span> indexList;</span></span>
<span><span>  } </span><span>else</span><span> </span><span>if</span><span> (</span><span>json</span><span>.type </span><span>===</span><span> </span><span>IndexStructType</span><span>.</span><span>SIMPLE_DICT</span><span>) {</span></span>
<span><span>    </span><span>const</span><span> </span><span>indexDict</span><span> </span><span>=</span><span> </span><span>new</span><span> </span><span>IndexDict</span><span>(</span><span>json</span><span>.indexId</span><span>,</span><span> </span><span>json</span><span>.summary);</span></span>
<span><span>    </span><span>indexDict</span><span>.nodesDict </span><span>=</span><span> </span><span>json</span><span>.nodesDict;</span></span>
<span><span>    </span><span>return</span><span> indexDict;</span></span>
<span><span>  } </span><span>else</span><span> {</span></span>
<span><span>    </span><span>throw</span><span> </span><span>new</span><span> </span><span>Error</span><span>(</span><span>`Unknown index struct type: </span><span>${</span><span>json</span><span>.type</span><span>}</span><span>`</span><span>);</span></span>
<span><span>  }</span></span>
<span><span>}</span></span>
<span> </span>
<span><span>...</span></span></code></pre></div>
<h3>Rest of the Algorithm ü§ñ<span id="rest-of-the-algorithm-"></span><a href="#rest-of-the-algorithm-" aria-label="Permalink for this section"></a></h3>
<ol>
<li>Iterate through the list of languages until one of them successfully parses the code</li>
<li>Chunk the code‚Äôs syntax tree root node</li>
<li>If none of the languages hit, we use a naive chunker that takes 40 lines at a time with 15 lines of overlap in between (0.1% of cases)</li>
</ol>
<div><pre data-language="python" data-theme="default"><code dir="ltr" data-language="python" data-theme="default"><span><span>language_names </span><span>=</span><span> [</span><span>&#34;python&#34;</span><span>,</span><span> </span><span>&#34;java&#34;</span><span>,</span><span> </span><span>&#34;cpp&#34;</span><span>,</span><span> </span><span>&#34;go&#34;</span><span>,</span><span> </span><span>&#34;rust&#34;</span><span>,</span><span> </span><span>&#34;ruby&#34;</span><span>,</span><span> </span><span>&#34;php&#34;</span><span>] </span><span># and more</span></span>
<span> </span>
<span><span># Installing the parsers</span></span>
<span><span>languages </span><span>=</span><span> </span><span>{}</span><span> </span></span>
<span><span>for</span><span> language </span><span>in</span><span> LANGUAGE_NAMES</span><span>:</span></span>
<span><span>   subprocess</span><span>.</span><span>run</span><span>(</span><span>f</span><span>&#34;git clone https://github.com/tree-sitter/tree-sitter-</span><span>{</span><span>language</span><span>}</span><span> cache/tree-sitter-</span><span>{</span><span>language</span><span>}</span><span>&#34;</span><span>, shell</span><span>=</span><span>True</span><span>)</span></span>
<span><span>  </span><span>for</span><span> language </span><span>in</span><span> LANGUAGE_NAMES</span><span>:</span></span>
<span><span>      Language</span><span>.</span><span>build_library</span><span>(</span><span>f</span><span>&#39;cache/build/</span><span>{</span><span>language</span><span>}</span><span>.so&#39;</span><span>, [</span><span>f</span><span>&#34;cache/tree-sitter-</span><span>{</span><span>language</span><span>}</span><span>&#34;</span><span>])</span></span>
<span><span>  self</span><span>.</span><span>languages </span><span>=</span><span> </span><span>{</span><span>language</span><span>:</span><span> </span><span>Language</span><span>(</span><span>f</span><span>&#34;cache/build/</span><span>{</span><span>language</span><span>}</span><span>.so&#34;</span><span>, language)</span><span> </span><span>for</span><span> language </span><span>in</span><span> LANGUAGE_NAMES</span><span>}</span></span>
<span> </span>
<span><span>def</span><span> </span><span>chunk</span><span>(</span><span>text</span><span>:</span><span> </span><span>str</span><span>,</span><span> </span><span>MAX_CHARS</span><span>:</span><span> </span><span>int</span><span> </span><span>=</span><span> </span><span>1500</span><span>) </span><span>-&gt;</span><span> list</span><span>[</span><span>str</span><span>]</span><span>:</span></span>
<span><span>	</span><span># Determining the language</span></span>
<span><span>	</span><span>for</span><span> language_name </span><span>in</span><span> language_names</span><span>:</span></span>
<span><span>    language </span><span>=</span><span> languages</span><span>[</span><span>language_name</span><span>]</span></span>
<span><span>    parser </span><span>=</span><span> </span><span>Parser</span><span>()</span></span>
<span><span>    parser</span><span>.</span><span>set_language</span><span>(language)</span></span>
<span><span>    tree </span><span>=</span><span> parser</span><span>.</span><span>parse</span><span>(</span><span>bytes</span><span>(text, </span><span>&#34;utf-8&#34;</span><span>))</span></span>
<span><span>    </span><span>if</span><span> </span><span>not</span><span> tree</span><span>.</span><span>root_node</span><span>.</span><span>children </span><span>or</span><span> tree</span><span>.</span><span>root_node</span><span>.</span><span>children</span><span>[</span><span>0</span><span>].</span><span>type </span><span>!=</span><span> </span><span>&#34;ERROR&#34;</span><span>:</span></span>
<span><span>        file_language </span><span>=</span><span> language</span></span>
<span><span>        </span><span>break</span></span>
<span><span>    logger</span><span>.</span><span>warning</span><span>(</span><span>f</span><span>&#34;Not language </span><span>{</span><span>language_name</span><span>}</span><span>&#34;</span><span>)</span></span>
<span> </span>
<span><span>	</span><span># Smart chunker</span></span>
<span><span>	</span><span>if</span><span> file_language</span><span>:</span></span>
<span><span>      </span><span>return</span><span> </span><span>chunk_node</span><span>(tree.root_node, text, max_chunk_size)</span></span>
<span> </span>
<span><span>	</span><span># Naive algorithm</span></span>
<span><span>  source_lines </span><span>=</span><span> file_content</span><span>.</span><span>split</span><span>(</span><span>&#39;\n&#39;</span><span>)</span></span>
<span><span>  num_lines </span><span>=</span><span> </span><span>len</span><span>(source_lines)</span></span>
<span><span>  logger</span><span>.</span><span>info</span><span>(</span><span>f</span><span>&#34;Number of lines: </span><span>{</span><span>num_lines</span><span>}</span><span>&#34;</span><span>)</span></span>
<span><span>  chunks </span><span>=</span><span> []</span></span>
<span><span>  start_line </span><span>=</span><span> </span><span>0</span></span>
<span><span>  </span><span>while</span><span> start_line </span><span>&lt;</span><span> num_lines </span><span>and</span><span> num_lines </span><span>&gt;</span><span> overlap</span><span>:</span></span>
<span><span>      end_line </span><span>=</span><span> </span><span>min</span><span>(start_line </span><span>+</span><span> chunk_size, num_lines)</span></span>
<span><span>      chunk </span><span>=</span><span> </span><span>&#39;\n&#39;</span><span>.</span><span>join</span><span>(source_lines[start_line:end_line])</span></span>
<span><span>      chunks</span><span>.</span><span>append</span><span>(chunk)</span></span>
<span><span>      start_line </span><span>+=</span><span> chunk_size </span><span>-</span><span> overlap</span></span>
<span><span>	</span><span>return</span><span> chunks</span></span></code></pre></div>
<p>At Sweep, we currently installed Python, Java, C++, Go, Rust, Ruby, PHP, C#, Embedded Template (ERB &amp; EJS), Markdown, Vue, and TSX. Also, note that C++ covers C and TSX covers JS, JSX and TS.</p>
<h2>Pitfalls üï≥Ô∏è<span id="pitfalls-Ô∏è"></span><a href="#pitfalls-Ô∏è" aria-label="Permalink for this section"></a></h2>
<p>Unfortunately, <code dir="ltr">tree-sitter</code> is unreliable at times and many of the parsers are community-driven:</p>
<ul>
<li>The TSX parser hangs when it doesn‚Äôt parse instead of returning an error</li>
<li>Further, the base language is written in C. Running it in production on our serverless architecture involves a convoluted method of caching C-compiled executables, moving it to executable directories and using a Python wrapper to call them.</li>
<li>Some parsers leave gaps in between children nodes. We solved this by coalescing</li>
<li>None of the parsers error out when they parse the wrong language and yield errors in different ways<!-- -->
<ul>
<li>Some of them have root nodes that are ‚ÄúERROR‚Äù nodes while others have that as the first child</li>
</ul>
</li>
</ul>
<p>We worked around this by always defaulting to the naive chunker in cases of errors like these and prioritizing TSX last. We also prioritize the language corresponding to the file extension.</p>
<h2>Future üîÆ<span id="future-"></span><a href="#future-" aria-label="Permalink for this section"></a></h2>
<p><del>This algorithm is currently embedded into our codebase but can be open-sourced as a standalone project or as part of Langchain. Although we lack the time to undertake this task, we are more than willing to help anyone interested in implementing it.</del></p>
<p>Edit: This algorithm is now integrated into LlamaIndex via <a href="https://github.com/jerryjliu/llama_index/pull/7100" target="_blank" rel="noreferrer">https://github.com/jerryjliu/llama_index/pull/7100<span> (opens in a new tab)</span></a>.</p>
<p>Another problem is that code snippets far apart (in lines) may still need to share context. For example, a class method may need the context of the class header and long functions also need their function signatures. A possible improvement would be to somehow use a format like:</p>
<div><pre data-language="python" data-theme="default"><code dir="ltr" data-language="python" data-theme="default"><span><span>class</span><span> </span><span>Foo</span><span>:</span></span>
<span><span>  ...</span></span>
<span><span>  </span><span>def</span><span> </span><span>bar</span><span>(</span><span>self</span><span>):</span></span>
<span><span>      </span><span>pass</span></span></code></pre></div>
<p>We can consider using universal ctags or the like for simpler and more universal parsing or train a custom spaCy sentencizer on manually annotated chunks, but that might be a bit over-engineered.</p></main></article></div>
  </body>
</html>
