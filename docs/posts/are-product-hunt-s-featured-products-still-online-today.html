<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.scrapingbee.com/blog/producthunt-cemetery/">Original</a>
    <h1>Are Product Hunt&#39;s featured products still online today?</h1>
    
    <div id="readability-page-1" class="page"><div>
                <p>Releasing any new product these days is a competitive business. Mountains of new products appear daily, complete with well produced intro videos with every new competitor bearing a striking resemblance to one other. But how many of the products of the past stood out from the crowd and continue to remain online today?</p>
<p>In this article I&#39;ll be showing how to query the Product Hunt API to collect data. We collected information from all the featured products from Product Hunts 8-year history to determine how many of them still exist online or have disappeared into the tech wilderness. Along the way we&#39;ll also discover other interesting insights into the dataset.</p>
<h2 id="introduction">Introduction</h2>
<p>The source of all the data I talk about here is from the Product Hunt API. I&#39;ve queried it to return details of all their featured products over its history from December 2013 to the end of January 2022, which totals over 90,000 products.</p>
<p>Product Hunt has two versions of their API currently available, one a standard REST based interface (deprecated) and v2 being based on GraphQL. I&#39;ve used their older API as it returns much more data per query (50 posts with all data vs 20 posts with limited data) enabling us to get the full dataset to work with in just a few hours.</p>
<h3 id="collecting-the-data">Collecting the Data</h3>
<p>Getting all the data necessary for this analysis was a 3 stage process. We illustrate this with a simplified query of a single product below. I&#39;m using Python and <a href="https://www.python-httpx.org/">HTTPX</a> to make my queries, but you can use any language and library you&#39;re familiar with.</p>
<p>First, we query the Product Hunt API to return pages of product details as JSON, ensuring to return as large a dataset as possible with the <code>&#34;per_page&#34;</code> param. In order to query any data, you also need to set an AUTH Bearer token. Our first query to the API is therefore as follows:</p>
<div><pre tabindex="0"><code data-lang="python"><span>import</span> httpx
<span>import</span> os

PRODUCTHUNT_DEV_TOKEN <span>=</span> os<span>.</span>environ<span>.</span>get(<span>&#34;PRODUCTHUNT_DEV_TOKEN&#34;</span>)

headers <span>=</span> {<span>&#34;Authorization&#34;</span>: <span>f</span><span>&#34;Bearer </span><span>{</span>PRODUCTHUNT_DEV_TOKEN<span>}</span><span>&#34;</span>}

<span>with</span> httpx<span>.</span>Client(headers<span>=</span>headers) <span>as</span> client:
    r <span>=</span> client<span>.</span>get(
        <span>&#34;https://api.producthunt.com/v1/posts/all&#34;</span>,
        params<span>=</span>{<span>&#34;per_page&#34;</span>: <span>50</span>},
        timeout<span>=</span><span>20</span>,
    )
    redirect_urls <span>=</span> [p[<span>&#39;redirect_url&#39;</span>] <span>for</span> p <span>in</span> r<span>.</span>json()]
</code></pre></div><p>NB. In our actual code, we would need to consider the <code>&#39;x-rate-limit-remaining&#39;</code> and <code>&#39;x-rate-limit-reset&#39;</code> header values returned from the API response while making multiple subsequent queries. This tells us how many responses we have remaining and when the rate will reset again. To allow for this, when we reach the limit, we add a delay which matches when our request resets.</p>
<p>Product Hunt only exposes redirect urls for each product so as a second step it&#39;s also necessary to make a HEAD request to each of these to find each products original url.</p>
<div><pre tabindex="0"><code data-lang="python"><span>try</span>:
    r2 <span>=</span> client<span>.</span>head(redirect_url, timeout<span>=</span><span>20</span>)
    <span>if</span> r2<span>.</span>status_code <span>==</span> <span>301</span>:
        original_url <span>=</span> r2<span>.</span>headers[<span>&#34;Location&#34;</span>]
        print(<span>f</span><span>&#34;</span><span>{</span>redirect_url<span>}</span><span> -&gt; </span><span>{</span>original_url<span>}</span><span>&#34;</span>)
<span>except</span> <span>Exception</span> <span>as</span> e:
    print(<span>f</span><span>&#34;</span><span>{</span>redirect_url<span>}</span><span> - </span><span>{</span>e<span>}</span><span>&#34;</span>)
</code></pre></div><p>Finally, equipped with the actual product url, we can make a HEAD request to determine each products current status and collect other useful header data.</p>
<div><pre tabindex="0"><code data-lang="python"><span>try</span>:
    r3 <span>=</span> client<span>.</span>head(original_url, timeout<span>=</span><span>20</span>)
    print(<span>f</span><span>&#34;Status Code: </span><span>{</span>r3<span>.</span>status_code<span>}</span><span>&#34;</span>)
    <span>for</span> k, v <span>in</span> r3<span>.</span>headers<span>.</span>items():
        print(<span>f</span><span>&#34;</span><span>{</span>k<span>}</span><span> - </span><span>{</span>v<span>}</span><span>&#34;</span>)
<span>except</span> <span>Exception</span> <span>as</span> e:
    print(<span>f</span><span>&#34;</span><span>{</span>original_url<span>}</span><span> - </span><span>{</span>e<span>}</span><span>&#34;</span>)
</code></pre></div><p>In total therefore it&#39;s necessary to make 2 additional queries for each of the over 90k products available in the API. That could take a long time - but an added benefit of using HTTPX over something like <a href="https://blog.plover.com/blog/web-scraping-101-with-python/#requests">Requests</a> for this is that each of our HEAD requests above can be returned asynchronously and speed up the entire process of making over 180k HEAD requests(!) required to enrich the Product Hunt API data in this way.</p>
<h2 id="results">Results</h2>
<p>Next, we look at the data retrieved against a variety of attributes we gathered. Firstly, lets consider the entire set of products as a whole.</p>
<h3 id="number-of-products">Number of Products</h3>






















<div>
    <svg width="1790" height="1189" aria-hidden="true" style="background-color:white"></svg>
    <p><img data-sizes="auto" data-srcset="
    
      , https://d33wubrfki0l68.cloudfront.net/d9492a188764f62c9cf662bfe4f873c9a162f57d/812c6/blog/producthunt-cemetery/no_of_featured_products_huab160bba4ce456683617d8c69e2caa98_103983_825x0_resize_catmullrom_3.png 825w
    
    
      , https://d33wubrfki0l68.cloudfront.net/fa56ceba6b9535f6fdc8c82cee3e959988b10dd6/c6be3/blog/producthunt-cemetery/no_of_featured_products_huab160bba4ce456683617d8c69e2caa98_103983_1200x0_resize_catmullrom_3.png 1200w
    
    
      , https://d33wubrfki0l68.cloudfront.net/45ec7374283ecba5d41b01bb9fd274f40821b327/2eb4f/blog/producthunt-cemetery/no_of_featured_products_huab160bba4ce456683617d8c69e2caa98_103983_1500x0_resize_catmullrom_3.png 1500w 
    " data-src="https://d33wubrfki0l68.cloudfront.net/54661e9a5b653f3e312531ef3c083ebcf2148445/a8291/blog/producthunt-cemetery/no_of_featured_products.png" width="1790" height="1189" alt="Number of Featured Products vs Time"/>
    
</p></div>

</div></div>
  </body>
</html>
