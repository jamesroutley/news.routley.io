<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://together.ai/blog/redpajama-data-v2">Original</a>
    <h1>RedPajama v2 Open Dataset with 30T Tokens for Training LLMs</h1>
    
    <div id="readability-page-1" class="page"><div id="page" role="main">
        
          
<article id="sections" data-page-sections="6358d155bd7bbd5929470f3f">
  
  
    
    


  


<section data-test="page-section" data-section-theme="white" data-section-id="6358d155bd7bbd5929470f41" data-controller="SectionWrapperController" data-current-styles="{
&#34;imageOverlayOpacity&#34;: 0.15,
&#34;backgroundWidth&#34;: &#34;background-width--full-bleed&#34;,
&#34;sectionHeight&#34;: &#34;section-height--medium&#34;,
&#34;horizontalAlignment&#34;: &#34;horizontal-alignment--center&#34;,
&#34;verticalAlignment&#34;: &#34;vertical-alignment--middle&#34;,
&#34;contentWidth&#34;: &#34;content-width--wide&#34;,
&#34;sectionTheme&#34;: &#34;white&#34;,
&#34;sectionAnimation&#34;: &#34;none&#34;,
&#34;backgroundMode&#34;: &#34;image&#34;
}" data-current-context="{
&#34;video&#34;: {
&#34;playbackSpeed&#34;: 0.5,
&#34;filter&#34;: 1,
&#34;filterStrength&#34;: 0,
&#34;zoom&#34;: 0,
&#34;videoSourceProvider&#34;: &#34;none&#34;
},
&#34;backgroundImageId&#34;: null,
&#34;backgroundMediaEffect&#34;: null,
&#34;divider&#34;: null,
&#34;typeName&#34;: &#34;blog-basic-grid&#34;
}" data-animation="none">
  
  <div>
    <div>
      
      
      
      
      
      
      <div data-content-field="main-content" data-item-id="">
  <article id="article-">
  
    <div>
      

      <div>
        <div><div data-layout-label="Post Body" data-type="item" id="item-653fcd044516ae2c146247c8"><div><div><div data-block-type="2" id="block-e96c46a09961732b7c75"><div>

<div>
  <p>Today, we’re releasing a new version of the RedPajama dataset, with 30 trillion filtered and deduplicated tokens (100+ trillions raw) from 84 CommonCrawl dumps covering 5 languages, along with 40+ pre-computed data quality annotations that can be used for further filtering and weighting. </p><p>Over the last half a year, we have been pleased to see that RedPajama-1T, which we released in March, has ignited the creation of many new language models. So many people from the community have downloaded this 5TB dataset---more than 190,000 times and have been using them <a href="https://huggingface.co/search/full-text?q=redpajama"><span>in such creative ways</span></a>! RedPajama-1T consists of 1 trillion high-quality English tokens, but it was only the first step. Today, with the release of RedPajama-V2, we are making a further step towards the development of open datasets by releasing a massive, 30 trillion token web dataset. This is, to our best knowledge, the largest public dataset released specifically for LLM training. Even more excitingly, we include 40+ pre-computed quality annotations, allowing the community to further filter and weigh the data. Specifically, this release includes:</p><ul data-rte-list="default"><li><p>Over 100 billion text documents with 100+ trillion raw tokens from 84 CommonCrawl dumps;</p></li><li><p>40+ of the most widely used quality annotations pre-computed for a deduplicated 30 trillion tokens subset;</p></li><li><p>Five languages: English, French, Spanish, German, and Italian</p></li><li><p>All data processing scripts are open source and available on <a href="https://github.com/togethercomputer/RedPajama-Data"><span>GitHub</span></a>; all data are available on <a href="https://huggingface.co/datasets/togethercomputer/RedPajama-Data-V2"><span>HuggingFace</span></a>.</p></li></ul><h2>Why RedPajama-Data-v2 and How to Use it?</h2><p>A central ingredient to state-of-the-art open LLMs like Llama, Mistral, Falcon, MPT, and the RedPajama models is the large amounts of high-quality data that these models are trained on. For example, Llama 2 is trained on 2.4 trillion carefully curated tokens. The most prominent data sources are the crawls made publicly available by <a href="https://commoncrawl.org/"><span>CommonCrawl</span></a>. However, this data is crude and is not ideal for direct use for LLM training due to artifacts arising from the conversion of HTML to plain text, sources of generally low quality, and biases inherent to the distribution of content on the web. Getting the right dataset and data mixture is painful and any LLM developer has to go through the laborious, time-consuming, energy-intensive and expensive steps of processing and filtering this crude data. Although there have been several community projects around this effort, such as <a href="https://arxiv.org/abs/1910.10683"><span>C4</span></a>, <a href="https://huggingface.co/datasets/togethercomputer/RedPajama-Data-1T"><span>RedPajama-1T,</span></a> <a href="https://huggingface.co/datasets/tiiuae/falcon-refinedweb"><span>Refinedweb (Falcon)</span></a>, <a href="https://github.com/allenai/dolma"><span>Dolma (AI2)</span></a> and <a href="https://huggingface.co/datasets/cerebras/SlimPajama-627B"><span>SlimPajama</span></a>, many of them only cover a small portion of the CommonCrawl crawls; moreover, they represent a very specific way in which data are filtered.</p><p>With RedPajama-Data-v2, our goal is to lift this burden off the community and provide a pool of web data serving as a base from which high quality datasets for LLM training can be extracted and based on which LLM training data can be thoroughly researched. It provides, to our best knowledge, the most complete coverage on CommonCrawl (with 84 dumps processed). More importantly, we provide 40+ quality annotations — the result of different ML classifiers on data quality, minhash results that can be used for fuzzy deduplication, or heuristics such as “the fraction of words that contain no alphabetical character”. We provide our best effort implementations of quality annotations used in <a href="https://arxiv.org/abs/1910.10683"><span>C4</span></a>, <a href="https://arxiv.org/abs/2112.11446"><span>Gopher</span></a>, <a href="https://arxiv.org/abs/2305.13169"><span>Pretrainer’s Guide</span></a>, <a href="https://arxiv.org/abs/2306.01116"><span>RefinedWeb</span></a> and <a href="https://arxiv.org/abs/2302.03169"><span>Data Selection for Language Models via Importance Resampling</span></a>. These annotations provide a way for an LLM developer to easily slice and filter the data, combining these into a new data quality pipeline to create their own pre-training dataset.</p><p>Here are some examples! The following code snippets show how one can implement commonly used filtering rules in combination with the RedPajama-V2 dataset. For example, implementing the Gopher rules and use these to filter out documents that do not comply with the Gopher rules is as easy as:</p>
</div>



</div></div><div data-block-type="44" id="block-yui_3_17_2_1_1698681423568_26784"><div><pre><code>def gopher_rules_pass(sample) -&gt; bool:
    &#34;&#34;&#34; function returns True if the sample complies with Gopher rules &#34;&#34;&#34;
    signals = json.loads(sample[&#34;quality_signals&#34;])

    # rule 1: number of words between 50 and 10&#39;000
    word_count = signals[&#34;rps_doc_word_count&#34;][0][2]
    if word_count &lt; 50 or word_count &gt; 10_000:
        return False

    # rule 2: mean word length between 3 and 10
    mean_word_length = signals[&#34;rps_doc_mean_word_length&#34;][0][2]
    if mean_word_length &lt; 3 or mean_word_length &gt; 10:
        return False

    # rule 2: symbol to word ratio below 0.1
    symbol_word_ratio = signals[&#34;rps_doc_symbol_to_word_ratio&#34;][0][2]
    if  symbol_word_ratio &gt; 0.1:
        return False

    # rule 3: 90% of lines need to start without a bullet point
    n_lines = signals[&#34;ccnet_nlines&#34;][0][2]
    n_lines_bulletpoint_start = sum(map(lambda ln: ln[2], signals[&#34;rps_lines_start_with_bulletpoint&#34;]))
    if n_lines_bulletpoint_start / n_lines &gt; 0.9:
        return False

    # rule 4: the ratio between characters in the most frequent 2-gram and the total number 
    # of characters must be below 0.2
    top_2_gram_frac = signals[&#34;rps_doc_frac_chars_top_2gram&#34;][0][2]
    if top_2_gram_frac &gt; 0.2:
        return False

    # rule 5: ...


    return True

ds = load_dataset(&#34;togethercomputer/RedPajama-Data-V2&#34;, name=&#34;sample&#34;)
filtered_dataset = list(filter(gopher_rules_pass, ds[&#34;train&#34;]))</code></pre>

</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1698681423568_28590"><div>

<p>In the above snippet, we have used the “sample” config to load just a subset of the dataset. In case you want to load the full dataset for, e.g., snapshot 2023-14 in English, you can run: </p>



</div></div><div data-block-type="44" id="block-yui_3_17_2_1_1698681423568_30060"><div><pre><code>ds_iterator = load_dataset(
    &#34;togethercomputer/RedPajama-Data-V2&#34;, 
    partition=&#34;head_middle&#34;,
    snapshots=[&#34;2023-14&#34;], 
    languages=[&#34;en&#34;], 
    name=&#34;default&#34;
)</code></pre>

</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1698681423568_30693"><div>

<p>We can also use the rules used in RedPajama-v1 or C4:</p>



</div></div><div data-block-type="44" id="block-yui_3_17_2_1_1698681423568_32118"><div>
<pre><code>def rpv1_rules_pass(sample) -&gt; bool:
    &#34;&#34;&#34; function returns True if the sample complies with the filtering rules used in RP-V1 &#34;&#34;&#34;
    signals = json.loads(sample[&#34;quality_signals&#34;])

    # rule 1: the wikipedia reference classifier score must be higher than 0.25
    wikiref_score = signals[&#34;rps_doc_ml_wikiref_score&#34;][0][2]
    if wikiref_score &lt; 0.25:
        return False

    return True</code></pre>
<pre><code>def c4_rules_pass(sample) -&gt; bool:
    &#34;&#34;&#34; function returns True if the sample complies with the filtering rules used in C4 &#34;&#34;&#34;
    signals = json.loads(sample[&#34;quality_signals&#34;])

    # rule 1: at least 3 sentences
    num_sentences = signals[&#34;rps_doc_num_sentences&#34;][0][2]
    if num_sentences &lt; 3:
        return False

    # rule 2: page may not contain bad words
    n_bad_words = signals[&#34;rps_doc_ldnoobw_words&#34;][0][2]
    if n_bad_words &gt; 0:
        return False

    # rule 3: page may not contain placeholder &#34;lorem ipsum&#34; text
    lorem_ipsum = signals[&#34;rps_doc_lorem_ipsum&#34;][0][2]
    if lorem_ipsum &gt; 0:
        return False

    # rule 4: ...

    return True</code></pre>
</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1698681423568_32890"><div>

<div>
  <p>In the current release, we include 40+ quality annotations, but we very much view this as a “living” project where new additions will be made over time as the field moves towards a better understanding of LLM training data. We hope the community provides feedback, and we are looking forward to continuing to enrich our current pool of annotations.</p><h3>Data Processing Steps</h3><p>RedPajama-V2 focuses on CommonCrawl. Other data sources such as Wikipedia are available in <a href="https://huggingface.co/datasets/togethercomputer/RedPajama-Data-1T"><span>RedPajama-V1</span></a>. We also encourage you to enrich your data mixture with the <a href="https://huggingface.co/datasets/bigcode/the-stack"><span>Stack</span></a> (by BigScience) for code and <a href="https://allenai.org/data/s2orc"><span>s2orc</span></a> (by AI2) for scientific articles. RedPajama-V2 is built from the ground up based on publicly available web data, consisting of 84 crawls provided by CommonCrawl. The core components that this dataset is made of, are the source data (plain text), 40+ quality annotations, and deduplication clusters.</p><h3>Creating the Source Data</h3><p>The first processing step in building this dataset is to pass each CommonCrawl snapshot through the <a href="https://aclanthology.org/2020.lrec-1.494/"><span>CCNet pipeline</span></a>. We choose this pipeline due to its light processing, aligning with our guiding principle of preserving as much information in the raw dataset as possible and allowing downstream model developers to filter or reweight the dataset. We use the language filter in CCNet and keep five languages in this release: English, French, Spanish, German and Italian. This processing step produces 100 billion individual text documents. </p><h3>Quality Annotations</h3><p>In addition to the text documents processed by CCNet, we compute over 40 of the most widely used quality annotations for the “head” and “middle” buckets. The primary purpose of these annotations is to allow downstream model developers to filter or reweight the dataset based on their criteria, and to foster research into how these annotations should be used. In addition, we also plan, with the help of the community, to include more quality signals over time. With this release, we publish a first set of quality annotations, which consists of our implementations of the most common quality annotations that are described in <a href="https://arxiv.org/abs/1910.10683"><span>C4</span></a>, <a href="https://arxiv.org/abs/2112.11446"><span>Gopher</span></a>, <a href="https://arxiv.org/abs/2305.13169"><span>Pretrainer’s Guide</span></a>, <a href="https://arxiv.org/abs/2306.01116"><span>RefinedWeb</span></a>, in addition to several signals described in <a href="https://arxiv.org/abs/2302.03169"><span>other papers</span></a>. These annotations fall into the following categories:</p><ul data-rte-list="default"><li><p>Quality signals indicating how <strong>natural</strong> a given piece of text is. This includes simple heuristic measures such as the number of sentences, the number of words, the fraction of all-caps words, among others.</p></li><li><p>Quality signals indicating how <strong>repetitive</strong> a given piece of text is. Here follow the Gopher rules (<a href="https://arxiv.org/abs/2112.11446"><span>Rae et al.</span></a>) and compute the fraction of characters that appear in duplicated word n-grams and the fraction of characters in the most frequent word n-gram appearing in the documents.</p></li><li><p><strong>Content-based</strong> quality signals are comprised of signals that take the content into account such as the density of words appearing in a list of blocked words (similar to C4), or documents which come from a list of domains flagged as containing potentially harmful or otherwise offensive content. </p></li><li><p><strong>ML-based</strong> quality signals revolve around the idea of measuring how similar a given text is to a high-quality domain. Here we use fasttext classifiers trained on various high quality domains such as Wikipedia, as well as importance weights as proposed by <a href="https://arxiv.org/abs/2302.03169"><span>Xie et al</span></a>.</p></li><li><p><strong>Deduplication</strong> signals with pre-computed Minhash signatures (with 128 permutations) which can be used for fuzzy deduplication at different degrees.</p></li></ul>
</div>



</div></div><div data-block-type="23" id="block-yui_3_17_2_1_1698681423568_42292"><div>






  <table>
    <colgroup>
<col/>
<col/>
<col/>
<col/>
</colgroup>

<thead>
<tr>
<th>
<p><strong>Annotation Tag</strong></p>
</th>
<th>
<p><strong>Description</strong></p>
</th>
<th>
<p><strong>Category</strong></p>
</th>
<th>
<p><strong>Reference</strong></p>
</th>
</tr>
<tr>
<td>
<p>ccnet_bucket</p>
</td>
<td>
<p>head, middle or tail bucket of the perplexity score</p>
</td>
<td>
<p>CCNet</p>
</td>
<td>
<p><a href="https://aclanthology.org/2020.lrec-1.494/" target="_blank" rel="noopener">CCNet</a></p>
</td>
</tr>
<tr>
<td>
<p>ccnet_language_score</p>
</td>
<td>
<p>score of the language identification model</p>
</td>
<td>
<p>CCNet</p>
</td>
<td>
<p><a href="https://aclanthology.org/2020.lrec-1.494/" target="_blank" rel="noopener">CCNet</a></p>
</td>
</tr>
<tr>
<td>
<p>ccnet_length</p>
</td>
<td>
<p>number of characters</p>
</td>
<td>
<p>CCNet</p>
</td>
<td>
<p><a href="https://aclanthology.org/2020.lrec-1.494/" target="_blank" rel="noopener">CCNet</a></p>
</td>
</tr>
<tr>
<td>
<p>ccnet_nlines</p>
</td>
<td>
<p>number of lines</p>
</td>
<td>
<p>CCNet</p>
</td>
<td>
<p><a href="https://aclanthology.org/2020.lrec-1.494/" target="_blank" rel="noopener">CCNet</a></p>
</td>
</tr>
<tr>
<td>
<p>ccnet_original_length</p>
</td>
<td>
<p>number of characters before in-document line deduplication</p>
</td>
<td>
<p>CCNet</p>
</td>
<td>
<p><a href="https://aclanthology.org/2020.lrec-1.494/" target="_blank" rel="noopener">CCNet</a></p>
</td>
</tr>
<tr>
<td>
<p>ccnet_original_nlines</p>
</td>
<td>
<p>number of lines before in-document line deduplication</p>
</td>
<td>
<p>CCNet</p>
</td>
<td>
<p><a href="https://aclanthology.org/2020.lrec-1.494/" target="_blank" rel="noopener">CCNet</a></p>
</td>
</tr>
<tr>
<td>
<p>ccnet_perplexity</p>
</td>
<td>
<p>perplexity of an LM trained on Wikipedia</p>
</td>
<td>
<p>CCNet</p>
</td>
<td>
<p><a href="https://aclanthology.org/2020.lrec-1.494/" target="_blank" rel="noopener">CCNet</a></p>
</td>
</tr>
<tr>
<td>
<p>rps_doc_books_importance</p>
</td>
<td>
<p>Given a bag of {1,2}-wordgram model trained on Books p, and a model trained on the source domain q, This is the logarithm of the ratio p(doc)/q(doc).</p>
</td>
<td>
<p>ML Heuristics</p>
</td>
<td>
<p><a href="https://arxiv.org/abs/2302.03169" target="_blank" rel="noopener">Importance Resampling (Xie et al.)</a></p>
</td>
</tr>
<tr>
<td>
<p>rps_doc_openwebtext_importance</p>
</td>
<td>
<p>Given a bag of {1,2}-wordgram model trained on OpenWebText p, and a model trained on the source domain q, this is the logarithm of the ratio p(doc)/q(doc).</p>
</td>
<td>
<p>ML Heuristics</p>
</td>
<td>
<p><a href="https://arxiv.org/abs/2302.03169" target="_blank" rel="noopener">Importance Resampling (Xie et al.)</a></p>
</td>
</tr>
<tr>
<td>
<p>rps_doc_wikipedia_importance</p>
</td>
<td>
<p>Given a bag of {1,2}-wordgram model trained on Wikipedia articles p, and a model trained on the source domain q, this is the logarithm of the ratio p(doc)/q(doc).</p>
</td>
<td>
<p>ML Heuristics</p>
</td>
<td>
<p><a href="https://arxiv.org/abs/2302.03169" target="_blank" rel="noopener">Importance Resampling (Xie et al.)</a></p>
</td>
</tr>
</thead>
<tbody>
<tr>
<td>rps_doc_ml_wikiref_score</td>
<td>Fasttext classifier prediction for the document being a Wikipedia reference. This is the same fasttext model used in the RedPajama-1T dataset. Only applies to English data..</td>
<td>ML Heuristics</td>
<td><a href="https://arxiv.org/abs/2302.13971" target="_blank" rel="noopener">LLaMA</a>, <a href="https://huggingface.co/datasets/togethercomputer/RedPajama-Data-1T" target="_blank" rel="noopener">RedPajama-1T</a></td>
</tr>
<tr>
<td>rps_doc_ml_palm_score</td>
<td>Fasttext classifier prediction for the document being a Wikipedia article, OpenWebText sample or a RedPajama-V1 book. Only for English data.</td>
<td>ML Heuristics</td>
<td><a href="https://arxiv.org/abs/2204.02311" target="_blank" rel="noopener">PaLM</a>, <a href="https://arxiv.org/abs/2112.06905" target="_blank" rel="noopener">GLaM</a></td>
</tr>
<tr>
<td>rps_doc_ml_wikipedia_score</td>
<td>Fasttext classifier prediction for the document being a Wikipedia article. This is used for non-English data</td>
<td>ML Heuristics</td>
<td>-</td>
</tr>
<tr>
<td>rps_doc_curly_bracket</td>
<td>The ratio between the number of occurrences of &#39;{&#39; or &#39;}&#39; and the number of characters in the raw text.</td>
<td>Natural Language</td>
<td><a href="https://arxiv.org/abs/1910.10683" target="_blank" rel="noopener">C4</a></td>
</tr>
<tr>
<td>rps_doc_frac_all_caps_words</td>
<td>The fraction of words in the content that only consist of uppercase letters. This is based on the raw content.</td>
<td>Natural Language</td>
<td><a href="https://arxiv.org/abs/2305.13169" target="_blank" rel="noopener">Pretrainer’s Guide</a></td>
</tr>
<tr>
<td>rps_doc_frac_lines_end_with_ellipsis</td>
<td>The fraction of lines that end with an ellipsis, where an ellipsis is defined as either &#34;...&#34; or &#34;…&#34;.</td>
<td>Natural Language</td>
<td><a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a>,<a href="https://arxiv.org/abs/2112.11446" target="_blank" rel="noopener">Gopher</a></td>
</tr>
<tr>
<td>rps_doc_frac_no_alph_words</td>
<td>The fraction of words that contain no alphabetical character.</td>
<td>Natural Language</td>
<td><a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a>,<a href="https://arxiv.org/abs/2112.11446" target="_blank" rel="noopener">Gopher</a></td>
</tr>
<tr>
<td>rps_doc_lorem_ipsum</td>
<td>The ratio between the number of occurrences of &#39;lorem ipsum&#39; and the number of characters in the content after normalisation.</td>
<td>Natural Language</td>
<td><a href="https://arxiv.org/abs/1910.10683" target="_blank" rel="noopener">C4</a></td>
</tr>
<tr>
<td>rps_doc_mean_word_length</td>
<td>The mean length of words in the content after normalisation.</td>
<td>Natural Language</td>
<td><a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a>,<a href="https://arxiv.org/abs/2112.11446" target="_blank" rel="noopener">Gopher</a></td>
</tr>
<tr>
<td>rps_doc_stop_word_fraction</td>
<td>The ratio between the number of stop words and the number of words in the document. Stop words are obtained from<a href="https://github.com/6/stopwords-json" target="_blank" rel="noopener"> https://github.com/6/stopwords-json</a>.</td>
<td>Natural Language</td>
<td><a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a>,<a href="https://arxiv.org/abs/2112.11446" target="_blank" rel="noopener">Gopher</a></td>
</tr>
<tr>
<td>rps_doc_symbol_to_word_ratio</td>
<td>The ratio of symbols to words in the content.. Symbols are defined &#34;#&#34;, &#34;...&#34;, and &#34;…&#34;.</td>
<td>Natural Language</td>
<td><a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a>,<a href="https://arxiv.org/abs/2112.11446" target="_blank" rel="noopener">Gopher</a></td>
</tr>
<tr>
<td>rps_doc_frac_unique_words</td>
<td>The fraction of unique words in the content. This is also known as the degeneracy of a text sample. Calculated based on the normalised content.</td>
<td>Natural Language</td>
<td><a href="https://arxiv.org/abs/2305.13169" target="_blank" rel="noopener">Pretrainer’s Guide</a></td>
</tr>
<tr>
<td>rps_doc_unigram_entropy</td>
<td>The entropy of the unigram distribution of the content. This measures the diversity of the content and is computed using sum(-x / total * log(x / total)) where the sum is taken over counts of unique words in the normalised content.</td>
<td>Natural Language</td>
<td>-</td>
</tr>
<tr>
<td>rps_doc_word_count</td>
<td>The number of words in the content after normalisation.</td>
<td>Natural Language</td>
<td><a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a>,<a href="https://arxiv.org/abs/2112.11446" target="_blank" rel="noopener">Gopher</a></td>
</tr>
<tr>
<td>rps_lines_ending_with_terminal_punctution_mark</td>
<td>Indicates whether a line ends with a terminal punctuation mark. A terminal punctuation mark is defined as one o: &#34;.&#34;, &#34;!&#34;, &#34;?&#34;, &#34;”&#34;.</td>
<td>Natural Language</td>
<td><a href="https://arxiv.org/abs/1910.10683" target="_blank" rel="noopener">C4</a></td>
</tr>
<tr>
<td>rps_lines_javascript_counts</td>
<td>The number of occurrences of the word &#34;javascript&#34; in each line.</td>
<td>Natural Language</td>
<td><a href="https://arxiv.org/abs/1910.10683" target="_blank" rel="noopener">C4</a></td>
</tr>
<tr>
<td>rps_lines_num_words</td>
<td>The number of words in each line. This is computed based on the normalised text.</td>
<td>Natural Language</td>
<td><a href="https://arxiv.org/abs/1910.10683" target="_blank" rel="noopener">C4</a>, <a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a></td>
</tr>
<tr>
<td>rps_lines_numerical_chars_fraction</td>
<td>The ratio between number of numerical characters and total number of characters in each line. This is based on the normalised content.</td>
<td>Natural Language</td>
<td><a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a></td>
</tr>
<tr>
<td>rps_lines_start_with_bulletpoint</td>
<td>Whether the lines that start with a bullet point symbol. The following set of unicodes are considered a bullet point: \u2022 (bullet point), \u2023 (triangular bullet point), \u25B6 (black right pointing triangle), \u25C0 (black left pointing triangle), \u25E6 (white bullet point), \u25A0 (black square), \u25A1 (white square), \u25AA (black small square), \u25AB (white small square), \u2013 (en dash).</td>
<td>Natural Language</td>
<td><a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a>,<a href="https://arxiv.org/abs/2112.11446" target="_blank" rel="noopener">Gopher</a></td>
</tr>
<tr>
<td>rps_lines_uppercase_letter_fraction</td>
<td>The ratio between number of uppercase letters and total number of characters in each line. This is based on the raw text.</td>
<td>Natural Language</td>
<td><a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a></td>
</tr>
<tr>
<td>rps_doc_num_sentences</td>
<td>The number of sentences in the content. This is calculated using the regular expression r&#39;\b[^.!?]+[.!?]*&#39;.</td>
<td>Natural Language</td>
<td><a href="https://arxiv.org/abs/1910.10683" target="_blank" rel="noopener">C4</a></td>
</tr>
<tr>
<td>rps_doc_frac_chars_dupe_10grams</td>
<td>The fraction of characters in duplicate word 10grams. </td>
<td>Repetitiveness</td>
<td><a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a>,<a href="https://arxiv.org/abs/2112.11446" target="_blank" rel="noopener">Gopher</a></td>
</tr>
<tr>
<td>rps_doc_frac_chars_dupe_5grams</td>
<td>The fraction of characters in duplicate word 5grams. </td>
<td>Repetitiveness</td>
<td><a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a>,<a href="https://arxiv.org/abs/2112.11446" target="_blank" rel="noopener">Gopher</a></td>
</tr>
<tr>
<td>rps_doc_frac_chars_dupe_6grams</td>
<td>The fraction of characters in duplicate word 6grams.</td>
<td>Repetitiveness</td>
<td><a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a>,<a href="https://arxiv.org/abs/2112.11446" target="_blank" rel="noopener">Gopher</a></td>
</tr>
<tr>
<td>rps_doc_frac_chars_dupe_7grams</td>
<td>The fraction of characters in duplicate word 7grams.</td>
<td>Repetitiveness</td>
<td><a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a>,<a href="https://arxiv.org/abs/2112.11446" target="_blank" rel="noopener">Gopher</a></td>
</tr>
<tr>
<td>rps_doc_frac_chars_dupe_8grams</td>
<td>The fraction of characters in duplicate word 8grams.</td>
<td>Repetitiveness</td>
<td><a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a>,<a href="https://arxiv.org/abs/2112.11446" target="_blank" rel="noopener">Gopher</a></td>
</tr>
<tr>
<td>rps_doc_frac_chars_dupe_9grams</td>
<td>The fraction of characters in duplicate word 9grams. </td>
<td>Repetitiveness</td>
<td><a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a>,<a href="https://arxiv.org/abs/2112.11446" target="_blank" rel="noopener">Gopher</a></td>
</tr>
<tr>
<td>rps_doc_frac_chars_top_2gram</td>
<td>The fraction of characters in the top word 2gram.</td>
<td>Repetitiveness</td>
<td><a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a>,<a href="https://arxiv.org/abs/2112.11446" target="_blank" rel="noopener">Gopher</a></td>
</tr>
<tr>
<td>rps_doc_frac_chars_top_3gram</td>
<td>The fraction of characters in the top word 3gram.</td>
<td>Repetitiveness</td>
<td><a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a>,<a href="https://arxiv.org/abs/2112.11446" target="_blank" rel="noopener">Gopher</a></td>
</tr>
<tr>
<td>rps_doc_frac_chars_top_4gram</td>
<td>The fraction of characters in the top word 4gram.</td>
<td>Repetitiveness</td>
<td><a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a>,<a href="https://arxiv.org/abs/2112.11446" target="_blank" rel="noopener">Gopher</a></td>
</tr>
<tr>
<td>rps_doc_ldnoobw_words</td>
<td>The number of sequences of words that are contained in the List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words blocklist. The blocklist is obtained from<a href="https://github.com/LDNOOBW/List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words" target="_blank" rel="noopener"> https://github.com/LDNOOBW/List-of-Dirty-Naughty-Obscene-and-Otherwise-Bad-Words</a></td>
<td>Sensitive / toxic content</td>
<td><a href="https://arxiv.org/abs/1910.10683" target="_blank" rel="noopener">C4</a></td>
</tr>
<tr>
<td>rps_doc_ut1_blacklist</td>
<td>A categorical id corresponding to the list of categories of the domain of the document. Categories are obtained from the UT1 blacklist. The list is obtained from<a href="https://dsi.ut-capitole.fr/blacklists/" target="_blank" rel="noopener"> https://dsi.ut-capitole.fr/blacklists/</a></td>
<td>Sensitive / toxic content</td>
<td><a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a></td>
</tr>
<tr>
<td>minhash_signature_0.7</td>
<td>Banded minhash signature of the document, for fuzzy deduplication at Jaccard similarity 0.7. The signature is based on 128 hash functions and grouped into 14 bands and 9 rows for LSH.</td>
<td>Deduplication</td>
<td><a href="https://huggingface.co/datasets/cerebras/SlimPajama-627B" target="_blank" rel="noopener">SlimPajama</a>,<a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a></td>
</tr>
<tr>
<td>minhash_signature_0.8</td>
<td>Banded minhash signature of the document, for fuzzy deduplication at Jaccard similarity 0.8. The signature is based on 128 hash functions and grouped into 9 bands and 13 rows for LSH.</td>
<td>Deduplication</td>
<td><a href="https://huggingface.co/datasets/cerebras/SlimPajama-627B" target="_blank" rel="noopener">SlimPajama</a>,<a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a></td>
</tr>
<tr>
<td>minhash_signature_0.9</td>
<td>Banded minhash signature of the document, for fuzzy deduplication at Jaccard similarity 0.9. The signature is based on 128 hash functions and grouped into 5 bands and 25 rows for LSH..</td>
<td>Deduplication</td>
<td><a href="https://huggingface.co/datasets/cerebras/SlimPajama-627B" target="_blank" rel="noopener">SlimPajama</a>,<a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a></td>
</tr>
<tr>
<td>minhash_signature_1.0</td>
<td>Banded minhash signature of the document, for fuzzy deduplication at Jaccard similarity 1.0. The signature is based on 128 hash functions and grouped into 1 band and 128 rows for LSH.</td>
<td>Deduplication</td>
<td><a href="https://huggingface.co/datasets/cerebras/SlimPajama-627B" target="_blank" rel="noopener">SlimPajama</a>,<a href="https://arxiv.org/abs/2306.01116" target="_blank" rel="noopener">RefinedWeb</a></td>
</tr>
</tbody>
</table>
</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1698681423568_42372"><div>

<div>
  <p>In addition to these minhash signatures, we conduct exact deduplication with a Bloom filter over the sha1 hash-digest of the document. These are stored as a separate quality annotation file to allow the original non-duplicated distribution to be recovered to facilitate research in this direction.</p><h3>Dataset Statistics</h3><p>RedPajama-v2 processed 84 CommonCrawl crawls and consists of 113B documents in the five languages (English, German, French, Spanish, and Italian). While we keep the tail partition of the resulting data, consisting of an estimated 80B documents, we also compute the number of documents and tokens for the head and middle partitions (before and after deduplication). Interestingly, while this reduces the token count by 60%, the number of documents decreases disproportionately more by 71%, indicating that the tail documents are generally shorter.</p>
</div>



</div></div><div data-block-type="23" id="block-yui_3_17_2_1_1698683165778_15314"><div>






<table>
  <colgroup>
<col/>
<col/>
<col/>
</colgroup>

  <tbody><tr>
    <th>Partition</th>
    <th># Documents</th>
    <th>Estimated Token Count</th>
  </tr>
  <tr>
    <td>head + middle + tail</td>
    <td>113.3B</td>
    <td>123.7T</td>
  </tr>
  <tr>
    <td>head + middle</td>
    <td>32.8B</td>
    <td>50.7T</td>
  </tr>
  <tr>
    <td>head + middle (deduplicated)</td>
    <td>20.8B</td>
    <td>30.4T</td>
  </tr>
</tbody></table>


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1698683165778_15386"><div>

<p>We further deduplicated the head+middle documents using a Bloom filter, which leads to a reduction in the dataset size by roughly 40%. In the following figure, we show the development of the number of documents in the head+middle partition, as a function of the point in time of the crawl. What stands out here is that there is a relatively stable number until 2018, and a significantly smaller number of documents between 2014 and 2016 (up to 10x for, e.g., German). It is also worth noting how the number of unique documents over time develops. Specifically, since we ran the deduplication from the newest snapshot to the oldest, one expects an increasingly smaller number of unique documents in the corpus, which can be observed from the figure below (note the log-scale). However, it is worth pointing out the sudden drop in unique documents occurring for the crawls between 2014 and 2017. We believe that this can be explained from a different list of seeds used by the CommonCrawl web crawler during that period. </p>



</div></div><div data-block-type="5" id="block-yui_3_17_2_1_1698683165778_33695"><div>









































  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/f4a00f65-e85c-489c-9a1d-0d556cbdb3e5/ccsnapshot.png" data-image="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/f4a00f65-e85c-489c-9a1d-0d556cbdb3e5/ccsnapshot.png" data-image-dimensions="1600x500" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/f4a00f65-e85c-489c-9a1d-0d556cbdb3e5/ccsnapshot.png" width="1600" height="500" alt="" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/f4a00f65-e85c-489c-9a1d-0d556cbdb3e5/ccsnapshot.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/f4a00f65-e85c-489c-9a1d-0d556cbdb3e5/ccsnapshot.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/f4a00f65-e85c-489c-9a1d-0d556cbdb3e5/ccsnapshot.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/f4a00f65-e85c-489c-9a1d-0d556cbdb3e5/ccsnapshot.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/f4a00f65-e85c-489c-9a1d-0d556cbdb3e5/ccsnapshot.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/f4a00f65-e85c-489c-9a1d-0d556cbdb3e5/ccsnapshot.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/f4a00f65-e85c-489c-9a1d-0d556cbdb3e5/ccsnapshot.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs"/>
                
            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1698683165778_34046"><div>

<p>In the next figure, we show the distribution of the number of tokens per document, for the tail and the head+middle partitions. With a median per-document token count of 380, the tail documents are considerably shorter than the head+middle documents where the median is 741.</p>



</div></div><div data-block-type="5" id="block-yui_3_17_2_1_1698683165778_36781"><div>









































  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/4d71048e-7502-4c9f-bf35-6351607a7e91/image9.png" data-image="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/4d71048e-7502-4c9f-bf35-6351607a7e91/image9.png" data-image-dimensions="800x500" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/4d71048e-7502-4c9f-bf35-6351607a7e91/image9.png" width="800" height="500" alt="" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/4d71048e-7502-4c9f-bf35-6351607a7e91/image9.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/4d71048e-7502-4c9f-bf35-6351607a7e91/image9.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/4d71048e-7502-4c9f-bf35-6351607a7e91/image9.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/4d71048e-7502-4c9f-bf35-6351607a7e91/image9.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/4d71048e-7502-4c9f-bf35-6351607a7e91/image9.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/4d71048e-7502-4c9f-bf35-6351607a7e91/image9.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/4d71048e-7502-4c9f-bf35-6351607a7e91/image9.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs"/>
                
            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1698683165778_37132"><div>

<p>While the raw documents provide the basis for the RedPajama-V2 corpus, a further central component are the quality signals which we have computed for all documents in the head+middle partition. In the figure below, we show the distribution of the quality signals computed for documents from the 2023-06 snapshot.</p>



</div></div><div data-block-type="5" id="block-yui_3_17_2_1_1698683165778_39354"><div>









































  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/9821b312-cd22-4a39-9c48-200384da9cd8/image8.png" data-image="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/9821b312-cd22-4a39-9c48-200384da9cd8/image8.png" data-image-dimensions="1500x700" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/9821b312-cd22-4a39-9c48-200384da9cd8/image8.png" width="1500" height="700" alt="" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/9821b312-cd22-4a39-9c48-200384da9cd8/image8.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/9821b312-cd22-4a39-9c48-200384da9cd8/image8.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/9821b312-cd22-4a39-9c48-200384da9cd8/image8.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/9821b312-cd22-4a39-9c48-200384da9cd8/image8.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/9821b312-cd22-4a39-9c48-200384da9cd8/image8.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/9821b312-cd22-4a39-9c48-200384da9cd8/image8.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/9821b312-cd22-4a39-9c48-200384da9cd8/image8.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs"/>
                
            </p>
          </div>
        
          
        

        
          
          <figcaption>
            <p>Histograms of CCNet quality Signals for English documents from the 2023-06 snapshot.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="5" id="block-yui_3_17_2_1_1698683165778_43389"><div>









































  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/d4d54f27-72e9-417a-b1e3-526cbdddd13b/image10.png" data-image="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/d4d54f27-72e9-417a-b1e3-526cbdddd13b/image10.png" data-image-dimensions="1500x700" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/d4d54f27-72e9-417a-b1e3-526cbdddd13b/image10.png" width="1500" height="700" alt="" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/d4d54f27-72e9-417a-b1e3-526cbdddd13b/image10.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/d4d54f27-72e9-417a-b1e3-526cbdddd13b/image10.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/d4d54f27-72e9-417a-b1e3-526cbdddd13b/image10.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/d4d54f27-72e9-417a-b1e3-526cbdddd13b/image10.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/d4d54f27-72e9-417a-b1e3-526cbdddd13b/image10.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/d4d54f27-72e9-417a-b1e3-526cbdddd13b/image10.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/d4d54f27-72e9-417a-b1e3-526cbdddd13b/image10.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs"/>
                
            </p>
          </div>
        
          
        

        
          
          <figcaption>
            <p>Histograms of ML heuristics quality Signals for English documents from the 2023-06 snapshot.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="5" id="block-yui_3_17_2_1_1698683165778_46468"><div>









































  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/7e4cacb1-0822-4f89-aa83-c3ae0c52a38b/image6.png" data-image="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/7e4cacb1-0822-4f89-aa83-c3ae0c52a38b/image6.png" data-image-dimensions="1429x1999" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/7e4cacb1-0822-4f89-aa83-c3ae0c52a38b/image6.png" width="1429" height="1999" alt="" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/7e4cacb1-0822-4f89-aa83-c3ae0c52a38b/image6.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/7e4cacb1-0822-4f89-aa83-c3ae0c52a38b/image6.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/7e4cacb1-0822-4f89-aa83-c3ae0c52a38b/image6.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/7e4cacb1-0822-4f89-aa83-c3ae0c52a38b/image6.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/7e4cacb1-0822-4f89-aa83-c3ae0c52a38b/image6.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/7e4cacb1-0822-4f89-aa83-c3ae0c52a38b/image6.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/7e4cacb1-0822-4f89-aa83-c3ae0c52a38b/image6.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs"/>
                
            </p>
          </div>
        
          
        

        
          
          <figcaption>
            <p>Histograms of natural language quality Signals for English documents from the 2023-06 snapshot.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="5" id="block-yui_3_17_2_1_1698683165778_49611"><div>









































  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/8efd8ad6-8e29-4b8d-b9cd-21d66c1035d6/image4.png" data-image="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/8efd8ad6-8e29-4b8d-b9cd-21d66c1035d6/image4.png" data-image-dimensions="1500x1050" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/8efd8ad6-8e29-4b8d-b9cd-21d66c1035d6/image4.png" width="1500" height="1050" alt="" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/8efd8ad6-8e29-4b8d-b9cd-21d66c1035d6/image4.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/8efd8ad6-8e29-4b8d-b9cd-21d66c1035d6/image4.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/8efd8ad6-8e29-4b8d-b9cd-21d66c1035d6/image4.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/8efd8ad6-8e29-4b8d-b9cd-21d66c1035d6/image4.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/8efd8ad6-8e29-4b8d-b9cd-21d66c1035d6/image4.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/8efd8ad6-8e29-4b8d-b9cd-21d66c1035d6/image4.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/8efd8ad6-8e29-4b8d-b9cd-21d66c1035d6/image4.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs"/>
                
            </p>
          </div>
        
          
        

        
          
          <figcaption>
            <p>Histograms of quality signals measuring the repetitiveness of a text document. For English documents from the 2023-06 snapshot.</p>
          </figcaption>
        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1698683165778_39713"><div>

<div>
  <h3>Dataset Structure</h3><p>The core of the dataset is composed of the text documents, accompanied by the quality annotations and deduplication clusters. The structure largely follows the one defined by CCNet. Specifically, the documents for a given CommonCrawl snapshot (say, e.g., 2018-43) are partitioned into 5k shards where the key indicates the shard, language of the document, and the perplexity bucket (partition). The quality annotations and duplicates follow the same logic and “mirror” the source filenames:</p>
</div>



</div></div><div data-block-type="5" id="block-yui_3_17_2_1_1698683165778_85785"><div>









































  

    
  
    <div data-test="image-block-inline-outer-wrapper">

      

      
        <figure>
          
        
        

        
          
            
          <div data-animation-role="image">
            <p><img data-stretch="false" data-src="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/d88d8402-b8ca-4251-9c38-2617b7e7fbc1/image12.png" data-image="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/d88d8402-b8ca-4251-9c38-2617b7e7fbc1/image12.png" data-image-dimensions="1200x1468" data-image-focal-point="0.5,0.5" alt="" data-load="false" src="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/d88d8402-b8ca-4251-9c38-2617b7e7fbc1/image12.png" width="1200" height="1468" alt="" sizes="100vw" srcset="https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/d88d8402-b8ca-4251-9c38-2617b7e7fbc1/image12.png?format=100w 100w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/d88d8402-b8ca-4251-9c38-2617b7e7fbc1/image12.png?format=300w 300w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/d88d8402-b8ca-4251-9c38-2617b7e7fbc1/image12.png?format=500w 500w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/d88d8402-b8ca-4251-9c38-2617b7e7fbc1/image12.png?format=750w 750w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/d88d8402-b8ca-4251-9c38-2617b7e7fbc1/image12.png?format=1000w 1000w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/d88d8402-b8ca-4251-9c38-2617b7e7fbc1/image12.png?format=1500w 1500w, https://images.squarespace-cdn.com/content/v1/6358bea282189a0adf57fe16/d88d8402-b8ca-4251-9c38-2617b7e7fbc1/image12.png?format=2500w 2500w" loading="lazy" decoding="async" data-loader="sqs"/>
                
            </p>
          </div>
        
          
        

        
      
        </figure>
      

    </div>
  


  


</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1698683165778_86135"><div>

<p>The document files are left untouched and correspond 1-to-1 to the CCNet output, including the metadata fields. The quality signals, on the other hand, include document ids, metadata, and the quality signals themselves:</p>



</div></div><div data-block-type="44" id="block-yui_3_17_2_1_1698683165778_61898"><div><pre><code>{
  &#34;id&#34;: &#34;2018-43/0000/en_head.json.gz/0&#34;, 
  &#34;id_int&#34;: 7972430436813205988, 
  &#34;metadata&#34;:{
    &#34;cc_segment&#34;: &#34;crawl-data/...&#34;,
    &#34;cc_net_source&#34;: &#34;2018-43/0000/en_head.json.gz&#34;,
    &#34;url&#34;: &#34;...&#34;,
    &#34;source_domain&#34;: &#34;...&#34;,
    &#34;language&#34;: &#34;en&#34;,
    &#34;snapshot_id&#34;: &#34;2018-43&#34;
  },
  &#34;quality_signals&#34;: {
    &#34;ccnet_original_length&#34;: [[0, 7033, 8711.0]],
    &#34;...&#34;: &#34;...&#34;,
    &#34;rps_doc_stop_word_fraction&#34;: [[0, 7033, 0.45121107]],
    &#34;rps_lines_num_words&#34;: [[0, 25, 2], ..., [6980, 7033, 10]]
  }
}</code></pre>

</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1698683165778_61964"><div>

<div>
  <p>Since we have quality signals that can characterise the quality on a line level (e.g., whether a line ends in a terminal punctuation mark), or on a document level we choose the logic used by <a href="https://github.com/allenai/dolma"><span>Dolma</span></a>, allowing for a unified representation of different types of signals. Specifically, each score corresponds to an array of tuples `(start, end, score)` where start and end correspond to the span in the document string where the score “applies”.</p><h3>A “Living” Dataset</h3><p>We envision the release of this dataset to be the start of a larger, community-driven development of large-scale datasets for LLMs. Along the data axis, we hope to continuously grow this pool and enrich it with additional domains and new snapshots over time. Along the data quality side, we view the current set of quality signals as an initial base set of signals that we hope to grow with new additions. In that sense, RedPajama-v2 should be seen as a pool that grows over time as the community learns more about harnessing the data for training performant language models. In the future, we plan to add more quality annotations such as: Contamination annotations against popular LLM benchmarks, topic modelling and classification annotations for each document, and other annotations that the community is excited about!</p><h3>Model Building at Together</h3><p>Together is building open models based on RedPajama-Dataset-V2, and we also help companies and organizations build custom models built with principled mixes of open and their proprietary datasets. If you are evaluating solutions to build models, please contact us here. </p><h2>Acknowledgments</h2><p>We are appreciative to so many partners and collaborators that together are pushing forward the frontier of open LLM models. </p><ul data-rte-list="default"><li><p>Thank you to the OLMo team at <a href="https://allenai.org/"><span>AI2</span></a> and friends at <a href="https://opengpt-x.de/en/"><span>OpenGPT-X</span></a> for the insightful discussions about datasets and data quality! Also for everyone who builds on the RedPajama dataset, including <a href="https://www.cerebras.net">Cerebras</a> for their SlimPajama efforts, and the over 500 models built on RedPajama to date by the open-source AI community.</p></li><li><p>We are grateful to the great team at <a href="https://www.eleuther.ai/"><span>EleutherAI</span></a> for paving the path on open training datasets with The Pile and for open-sourcing code we use in training some of the RedPajama models. </p></li><li><p>Thank you to our partners of RedPajama-v1, including <a href="https://github.com/togethercomputer/RedPajama-Data/blob/main/Ontocord.ai"><span>Ontocord.ai</span></a>, <a href="https://mila.quebec/en/"><span>MILA Québec AI Institute</span></a>, <a href="https://ds3lab.inf.ethz.ch/"><span>ETH DS3Lab</span></a>, <a href="https://www.umontreal.ca/"><span>Université de Montréal</span></a>, <a href="https://crfm.stanford.edu/"><span>Stanford Center for Research on Foundation Models (CRFM)</span></a>, <a href="https://hazyresearch.stanford.edu/"><span>Stanford Hazy Research research group</span></a> and <a href="https://laion.ai/"><span>LAION</span></a>.</p></li></ul>
</div>



</div></div></div></div></div></div>

        

        
        
          
        
      </div>

      
    </div>
  
</article>

</div>
    </div>
  
  </div>
  
</section>

  
</article>


          

          
            
              

            
          
        
      </div></div>
  </body>
</html>
