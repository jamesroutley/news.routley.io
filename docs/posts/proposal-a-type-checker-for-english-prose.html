<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="http://iafisher.com/blog/2024/05/proposal-english-typechecker">Original</a>
    <h1>Proposal: A type-checker for English prose</h1>
    
    <div id="readability-page-1" class="page"><div class="page">
  
  

  <p>I would like to have a command-line tool that checks the <em>grammatical correctness</em> of English-language prose. Such a tool could be run on code documentation as part of a pre-commit pipeline, on blog posts before publication, or anywhere else that the automated checking of English grammar is desirable. What I have in mind has a similar interface to <a href="https://vale.sh/">Vale</a>, but while Vale is a <em>linter</em> that catches <em>stylistic</em> errors, I want a <em>type-checker</em> that catches <em>grammatical</em> errors.^[Vale also catches some grammatical and spelling errors, but fundamentally it is a tool for matching style rules to text, not for comprehensive grammatical analysis.]</p>
<p>I believe that the best way to write such a tool is using a rule-based approach – meaning that it will have pre-programmed and explicit knowledge of English grammar. Let&#39;s call this a <em>rules engine</em>.</p>
<p>The alternative would be a machine-learning model that classifies sentences as grammatical or ungrammatical. In 2024, machine learning is perhaps the more obvious choice, but I think a rules engine is more appropriate, for two reasons:</p>
<ul>
<li><em>Error rate</em>: A type-checker must make few mistakes to be useful. If a grammar checker constantly gives spurious errors, I will simply stop using it. This is unlike other machine-learning tasks like speech processing or optical character recognition, where a reasonably low error rate is tolerable. A &#34;rules engine&#34; is really just a regular program, and bugs can be fixed by editing the code; but a machine-learning algorithm is an opaque blob of numeric parameters, and fixing individual errors may be difficult or impossible.</li>
<li><em>Interpretability</em>: The grammar checker needs to report <em>why</em> it thinks a sentence is incorrect. A rules engine can be programmed to produce helpful error messages, but a machine-learning model&#39;s reasoning is opaque and not easily interpreted.</li>
</ul>
<p>I&#39;m open to using statistical methods for subsystems of the grammar checker, but I suspect it will be easier to embed them within the rules engine than to retrofit formal rules onto a statistical system.</p>
<p>I am aware that this goes against the <a href="https://norvig.com/chomsky.html">orthodoxy</a>, so let me respond preemptively to some possible objections:</p>
<p><em>Formal rules don&#39;t work for natural-language processing; experience has shown that statistical methods are always better</em>. This may well turn out to be the case, but as I&#39;ve outlined above, I have good pragmatic reasons to favor my approach.</p>
<p><em>Real natural-language prose is too flexible for a formal grammar.</em> First, to clarify, I&#39;m proposing to write a program, not a grammar. I&#39;m under no illusions that English can be parsed with a tidy formalism like a context-free grammar. Second, my goal is to check the grammatical correctness of (relatively) formal, written English. Colloquial speech, literary writing, dialogue etc. are out of scope. I think that this constrains the problem enough that it is realistically solvable – but it might turn out that it&#39;s impossible to thread the needle between &#34;it&#39;s too permissive and misses too many mistakes&#34; and &#34;it&#39;s too strict and disallows too many correct sentences.&#34;</p>
<p><em>Grammaticality isn&#39;t a binary. Some sentences are &#34;borderline&#34;, or might be grammatical or not depending on context.</em> This is probably true, but may not be important in practice. I suspect that many borderline sentences are inappropriate in formal writing even if they are technically grammatical.</p>
<p><em>Parsing the syntax of a natural language is computationally intractable.</em> Again, this might be theoretically true, but my wager is that if I approach the problem with an <em>engineering</em> mindset rather than an <em>academic one</em>, then theoretical difficulties may prove to be surmountable.</p>
<p><em>Full syntactic analysis requires semantic analysis.</em> For instance, a typo might produce a rare word that is syntactically valid but semantically nonsensical, and the only way to detect such an error would be to understand the meaning of the sentence. Cases like these are good candidates for integrating statistical methods into the rules engine.</p>
<p>It&#39;s possible that some or all of these objections will turn out to be valid. But the only way to know for sure is to try.</p>
<p>At the time of writing (May 2024), I&#39;m doing a coding retreat at <a href="https://recurse.com">Recurse Center</a>. I plan to set aside some time to work on this project, so expect more blog posts in the near future.</p>
<p>If you read this post and you think I&#39;m wrong, please send me an email at \<my name=""> @ \<this domain="" name="">. I&#39;d be happy to hear about it. ∎</this></my></p>

  

  <hr/>
  <p><strong>Disclaimer:</strong> I occasionally make corrections and changes to posts after I publish them. You can view
    the full history of this post <a href="https://github.com/iafisher/blog/commits/master/2024-05-proposal-english-typechecker.md">on
    GitHub</a>.
  </p>
</div></div>
  </body>
</html>
