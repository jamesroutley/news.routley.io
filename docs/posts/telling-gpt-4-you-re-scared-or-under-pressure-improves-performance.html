<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://aimodels.substack.com/p/telling-gpt-4-youre-scared-or-under">Original</a>
    <h1>Telling GPT-4 you&#39;re scared or under pressure improves performance</h1>
    
    <div id="readability-page-1" class="page"><div class=""><div><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F818ab07c-2014-41cc-afce-91696a76a074_469x232.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F818ab07c-2014-41cc-afce-91696a76a074_469x232.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F818ab07c-2014-41cc-afce-91696a76a074_469x232.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F818ab07c-2014-41cc-afce-91696a76a074_469x232.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F818ab07c-2014-41cc-afce-91696a76a074_469x232.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F818ab07c-2014-41cc-afce-91696a76a074_469x232.png" width="469" height="232" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/818ab07c-2014-41cc-afce-91696a76a074_469x232.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:232,&#34;width&#34;:469,&#34;resizeWidth&#34;:null,&#34;bytes&#34;:null,&#34;alt&#34;:&#34;Telling GPT-4 you&#39;re scared or under pressure improves performance&#34;,&#34;title&#34;:null,&#34;type&#34;:null,&#34;href&#34;:null,&#34;belowTheFold&#34;:false,&#34;topImage&#34;:true,&#34;internalRedirect&#34;:null}" alt="Telling GPT-4 you&#39;re scared or under pressure improves performance" title="Telling GPT-4 you&#39;re scared or under pressure improves performance" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F818ab07c-2014-41cc-afce-91696a76a074_469x232.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F818ab07c-2014-41cc-afce-91696a76a074_469x232.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F818ab07c-2014-41cc-afce-91696a76a074_469x232.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F818ab07c-2014-41cc-afce-91696a76a074_469x232.png 1456w" sizes="100vw" fetchpriority="high"/></picture></div></a><figcaption>Adding emotional context makes LLMs like ChatGPT perform better.</figcaption></figure></div><p>In the grand narrative of artificial intelligence, the latest chapter might just be the most human yet.</p><p><span>A </span><a href="https://arxiv.org/pdf/2307.11760.pdf" rel="">new paper</a><span> indicates that AI models like GPT-4 can perform better when users express emotions such as urgency or stress. This discovery is particularly relevant for developers and entrepreneurs who utilize AI in their offerings, suggesting a new approach to prompt engineering that incorporates emotional context.</span></p><p>The study found that prompts with added emotional weight—dubbed &#34;EmotionPrompts&#34;—can improve AI performance in tasks ranging from grammar correction to creative writing. The implications are clear: incorporating emotional cues can lead to more effective and responsive AI applications.</p><p>For those embedding AI into products, these findings offer a tactical advantage. By applying this understanding of emotional triggers, AI can be fine-tuned to better meet user needs.</p><p>The crux of the matter lies in the very nature of communication. When humans converse, they don&#39;t just exchange information; they share feelings, intentions, and urgency. It&#39;s a dance of context and subtext, often orchestrated by emotional cues. The question this study tackles is whether AI, devoid of emotion itself, can respond to the emotional weight we imbue in our words—and if so, does it alter its performance?</p><p>Communication transcends the exchange of information; it involves the interplay of emotions and intentions. In AI, understanding whether the emotional context of human interaction can enhance machine response is more than academic—it could redefine the effectiveness of AI in everyday applications. If AI can adjust its performance based on the emotional cues it detects, we&#39;re looking at a future where our interactions with machines could also be more intuitive and human-like, leading to better outcomes in customer service, education, and beyond.</p><p>Before diving into the human-like responsiveness of AI, let&#39;s unpack the technical side. LLMs, such as GPT-4, are built on intricate neural networks that analyze vast amounts of text data. They identify patterns and relationships between words, sentences, and overall context to generate responses that are coherent and contextually appropriate.</p><p>The core innovation of the study lies in the introduction of &#34;EmotionPrompt.&#34; This method involves integrating emotional significance into the prompts provided to LLMs. Unlike standard prompts, which are straightforward requests for information or action, EmotionPrompts carry an additional layer of emotional relevance—like stressing the importance of the task for one&#39;s career or implying urgency.</p><p>The integration of emotional cues into language models has introduced a fascinating dynamic: LLMs can produce superior outputs when the input prompts suggest an emotional significance. The recent study rigorously tested this phenomenon across a variety of models and tasks, offering a wealth of data that could reshape our understanding and utilization of AI.</p><p>The researchers set out to evaluate the performance of LLMs when prompted with emotional cues—a technique they&#39;ve termed &#34;EmotionPrompt.&#34; To ensure the robustness of their findings, they designed 45 distinct tasks that covered a wide range of AI applications:</p><ul><li><p><strong>Deterministic Tasks</strong><span>: These are tasks with definitive right or wrong answers, such as grammar correction, fact-checking, or mathematical problem-solving. The models&#39; performances on these tasks can be measured against clear benchmarks, providing objective data on their accuracy.</span></p></li><li><p><strong>Generative Tasks</strong><span>: In contrast, generative tasks require the AI to produce content that may not have a single correct response. This includes creative writing, generating explanations, or providing advice. These tasks are particularly challenging for AI, as they must not only be correct but also coherent, relevant, and engaging.</span></p></li></ul><p>In the deterministic tasks, researchers observed a notable increase in performance when using EmotionPrompts. For instance, when tasked with instruction induction—a process that tests the AI&#39;s ability to follow and generate instructions based on given input—the models showed an 8.00% improvement in their relative performance.</p><p>Even more striking was the performance leap in the BIG-Bench tasks, which serve as a broad benchmark for evaluating the abilities of language models. Here, the use of EmotionPrompts yielded an incredible 115% improvement over standard prompts. This suggests that the models were not only understanding the tasks better but also producing more accurate or appropriate responses when the stakes were presented as higher.</p><p>To complement the objective metrics, the study also incorporated a human element. A group of 106 participants evaluated the generative tasks&#39; outputs, assessing the quality of AI-generated responses. This subjective analysis covered aspects such as performance, truthfulness, and responsibility—a reflection of the nuanced judgment humans bring to bear on AI outputs.</p><p>When assessing the quality of responses from both vanilla prompts and those enhanced with emotional cues, the participants noted an average improvement of 10.9%. This jump in performance highlights the potential for EmotionPrompts to not only elevate the factual accuracy of AI responses but also enhance their alignment with human expectations and values.</p><p>The implications of these findings are manifold. On a technical level, they support the huge body of evidence that LLMs are sensitive to prompt engineering—a fact that can be harnessed to fine-tune AI outputs for specific needs. From a practical standpoint, the enhancements in performance with EmotionPrompts can lead to more effective AI applications in fields where accuracy and the perception of understanding are critical, such as in educational technology, customer service, and mental health support.</p><p>The improvements reported in the study are particularly significant as they point toward a new frontier in human-AI communication. By effectively simulating a heightened emotional context, we can guide AI to produce responses that are not only technically superior but also perceived as more thoughtful and attuned to human concerns. Basically, these findings suggest that telling your LLM that you&#39;re worried or under pressure to get a good generation makes them perform better, all else equal!</p><p><span>While the improvements are statistically significant, they </span><strong>do not</strong><span> imply that LLMs have emotional awareness. The increase in performance is a result of how these models have been engineered to process and prioritize information embedded in the prompts. Moreover, the study opens up a conversation about the ethical use of such techniques, as there&#39;s a fine line between enhancing AI performance and misleading users about the capabilities and sensitivities of AI systems.</span></p><p>In summary, the study&#39;s findings offer a compelling case for the strategic use of EmotionPrompts in improving LLM performance. The enhancements observed in both objective and subjective evaluations underscore the potential of integrating emotional nuances into AI interactions to produce more effective, responsive, and user-aligned outputs.</p><p>When we tell AI that we&#39;re relying heavily on its answers, it &#34;doubles down&#34; to provide us with more precise, thoughtful, and thorough responses. The AI isn&#39;t actually feeling the pressure, but it seems to recognize these emotional signals and adjust its performance accordingly.</p><p>For those incorporating AI into their businesses or products, this isn&#39;t just an interesting tidbit; it&#39;s actionable intelligence. By understanding and utilizing emotional triggers effectively, AI can be made more responsive and useful.</p><p>In a nutshell, this research indicates that LLMs like GPT-4 respond with improved performance when prompted with emotional context, a finding that could be quite useful for developers and product managers. This isn&#39;t about AI understanding emotions but rather about how these models handle nuanced prompts. It&#39;s a significant insight for those looking to refine AI interactions, though it comes with ethical considerations regarding user expectations of AI emotional intelligence.</p><p>Emotionally aware AI doesn&#39;t just understand our words—it understands our urgency and acts accordingly. Pretty cool!</p><p><em><a href="https://aimodels.substack.com/" rel="">Subscribe</a><span> or follow me on </span><a href="https://twitter.com/mikeyoung44" rel="">Twitter</a><span> for more content like this!</span></em></p></div></div></div></div>
  </body>
</html>
