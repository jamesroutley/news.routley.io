<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/winkjs/wink-nlp">Original</a>
    <h1>Show HN: WinkNLP delivers 600k tokens/second speed on browsers (MBP M1)</h1>
    
    <div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text">
<h3 dir="auto"><a id="user-content------" aria-hidden="true" href="#-----"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><a href="https://travis-ci.com/github/winkjs/wink-nlp" rel="nofollow"><img src="https://camo.githubusercontent.com/091904ba876b789c62a0197555923e6ac933db60fb941dcacad1cc9e2cbfbcd3/68747470733a2f2f7472617669732d63692e636f6d2f77696e6b6a732f77696e6b2d6e6c702e7376673f6272616e63683d6d6173746572" alt="Build Status" data-canonical-src="https://travis-ci.com/winkjs/wink-nlp.svg?branch=master"/></a> <a href="https://coveralls.io/github/winkjs/wink-nlp?branch=master" rel="nofollow"><img src="https://camo.githubusercontent.com/229d574fc4919346df131eb69c8539f8331ee79b73177d4107a84dd67d5486d6/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f77696e6b6a732f77696e6b2d6e6c702f62616467652e7376673f6272616e63683d6d6173746572" alt="Coverage Status" data-canonical-src="https://coveralls.io/repos/github/winkjs/wink-nlp/badge.svg?branch=master"/></a> <a href="https://snyk.io/test/github/winkjs/wink-nlp" rel="nofollow"><img src="https://camo.githubusercontent.com/e2c16b3f4855dfd2b1990edeac4914c9174df97d2f47104099c2efff60378af3/68747470733a2f2f736e796b2e696f2f746573742f6769746875622f77696e6b6a732f77696e6b2d6e6c702f62616467652e737667" alt="Known Vulnerabilities" data-canonical-src="https://snyk.io/test/github/winkjs/wink-nlp/badge.svg"/></a> <a href="https://bestpractices.coreinfrastructure.org/projects/6035" rel="nofollow"><img src="https://camo.githubusercontent.com/310609f5f42cf3ee8860487dac2b7e7fd8779c6651efa49f64ddccdad91ba9be/68747470733a2f2f626573747072616374696365732e636f7265696e6672617374727563747572652e6f72672f70726f6a656374732f363033352f6261646765" alt="CII Best Practices" data-canonical-src="https://bestpractices.coreinfrastructure.org/projects/6035/badge"/></a> <a href="https://gitter.im/winkjs/Lobby" rel="nofollow"><img src="https://camo.githubusercontent.com/9847ff4337174c20e5fe5d125928134dca305514e5c0b554013c3839992c9cf2/68747470733a2f2f696d672e736869656c64732e696f2f6769747465722f726f6f6d2f6e776a732f6e772e6a732e737667" alt="Gitter" data-canonical-src="https://img.shields.io/gitter/room/nwjs/nw.js.svg"/></a> <a href="https://twitter.com/winkjs_org" rel="nofollow"><img src="https://camo.githubusercontent.com/ec9cacf1fda8964cab69398f86231bb6a8ce2e20232d65de203b20464631ec5d/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f77696e6b6a735f6f72673f7374796c653d736f6369616c" alt="Follow on Twitter" data-canonical-src="https://img.shields.io/twitter/follow/winkjs_org?style=social"/></a></h3>
<h2 dir="auto"><a id="user-content-developer-friendly-natural-language-processing-" aria-hidden="true" href="#developer-friendly-natural-language-processing-"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Developer friendly Natural Language Processing <g-emoji alias="sparkles" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png">‚ú®</g-emoji></h2>
<p dir="auto"><a href="https://winkjs.org/" rel="nofollow"><img src="https://camo.githubusercontent.com/9c873cf618730561b75546b8f27b14daa143b4828c328d6379c37364b22d74a9/68747470733a2f2f64656369736976656c792e6769746875622e696f2f77696e6b2d6c6f676f732f6c6f676f2d7469746c652e706e67" width="100px" data-canonical-src="https://decisively.github.io/wink-logos/logo-title.png"/></a></p>
<p dir="auto">WinkNLP is a JavaScript library for Natural Language Processing (NLP). Designed specifically to make development of NLP applications <strong>easier</strong> and <strong>faster</strong>, winkNLP is optimized for the right balance of performance and accuracy.</p>
<p dir="auto">It is built ground up with a lean code base that has <a href="https://snyk.io/test/github/winkjs/wink-nlp?tab=dependencies" rel="nofollow">no external dependency</a>. A test coverage of <a href="https://coveralls.io/github/winkjs/wink-nlp?branch=master" rel="nofollow">~100%</a> and compliance with the <a href="https://bestpractices.coreinfrastructure.org/en/projects/6035" rel="nofollow">Open Source Security Foundation best practices</a> make winkNLP the ideal tool for building production grade systems with confidence.</p>
<p dir="auto">WinkNLP with full <a href="https://github.com/winkjs/wink-nlp/blob/master/types/index.d.ts">Typescript support</a>, runs on Node.js and browsers.</p>
<h2 dir="auto"><a id="user-content-build-amazing-apps-quickly" aria-hidden="true" href="#build-amazing-apps-quickly"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Build amazing apps quickly</h2>
<table>
<thead>
<tr>
<th><a href="https://winkjs.org/showcase-timeline/" rel="nofollow">Wikipedia article timeline</a></th>
<th><a href="https://observablehq.com/@winkjs/how-to-create-a-context-aware-word-cloud" rel="nofollow">Context aware word cloud</a></th>
<th><a href="https://observablehq.com/@winkjs/how-to-visualize-key-sentences-in-a-document" rel="nofollow">Key sentences detection</a></th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://winkjs.org/showcase-timeline/" rel="nofollow"><img src="https://user-images.githubusercontent.com/29990/202497363-19c30578-8146-4f36-9c4b-4de613610837.png"/></a></td>
<td><a href="https://observablehq.com/@winkjs/how-to-create-a-context-aware-word-cloud" rel="nofollow"><img src="https://user-images.githubusercontent.com/29990/202506181-1a926ee0-788f-4aa1-aeac-a097f09fe747.png"/></a></td>
<td><a href="https://observablehq.com/@winkjs/how-to-visualize-key-sentences-in-a-document" rel="nofollow"><img src="https://user-images.githubusercontent.com/29990/202506490-7f999d12-8319-4969-b92b-0649559ffbe6.png"/></a></td>
</tr>
</tbody>
</table>
<p dir="auto">Head to  <a href="https://winkjs.org/examples.html" rel="nofollow">live examples</a> to explore further.</p>
<h2 dir="auto"><a id="user-content-blazing-fast" aria-hidden="true" href="#blazing-fast"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Blazing fast</h2>
<p dir="auto">WinkNLP can easily process large amount of raw text at speeds over <strong>650,000 tokens/second</strong>¬† on a M1 Macbook Pro in both browser and Node.js environments. It even runs smoothly on a low-end smartphone&#39;s browser.</p>
<table>
<thead>
<tr>
<th>Environment</th>
<th>Benchmarking Command</th>
</tr>
</thead>
<tbody>
<tr>
<td>Node.js</td>
<td><a href="https://github.com/winkjs/wink-nlp/tree/master/benchmark">node benchmark/run</a></td>
</tr>
<tr>
<td>Browser</td>
<td><a href="https://observablehq.com/@winkjs/how-to-measure-winknlps-speed-on-browsers" rel="nofollow">How to measure winkNLP&#39;s speed on browsers?</a></td>
</tr>
</tbody>
</table>
<h2 dir="auto"><a id="user-content-features" aria-hidden="true" href="#features"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Features</h2>
<p dir="auto">WinkNLP has a <a href="https://winkjs.org/wink-nlp/processing-pipeline.html" rel="nofollow">comprehensive natural language processing (NLP) pipeline</a> covering tokenization, sentence boundary detection (sbd), negation handling, sentiment analysis, part-of-speech (pos) tagging, named entity recognition (ner), custom entities recognition (cer). It offers a rich feature set:</p>
<table>
<tbody><tr><td><g-emoji alias="racehorse" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f40e.png">üêé</g-emoji> Fast, lossless &amp; multilingual tokenizer </td><td>For example, the multilingual text string <b><code>&#34;¬°Hola! ‡§®‡§Æ‡§∏‡•ç‡§ï‡§æ‡§∞! Hi! Bonjour ch√©ri&#34;</code></b>  is tokenized as <code>[&#34;¬°&#34;, &#34;Hola&#34;, &#34;!&#34;, &#34;‡§®‡§Æ‡§∏‡•ç‡§ï‡§æ‡§∞&#34;, &#34;!&#34;, &#34;Hi&#34;, &#34;!&#34;, &#34;Bonjour&#34;, &#34;ch√©ri&#34;]</code>.  The tokenizer processes text at a speed close to <b>4 million</b> tokens/second on a M1 MBP&#39;s browser.</td></tr>
<tr><td><g-emoji alias="sparkles" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2728.png">‚ú®</g-emoji> Developer friendly and intuitive <a href="https://winkjs.org/wink-nlp/getting-started.html" rel="nofollow">API</a></td><td>With winkNLP, process any text using a simple, declarative syntax; most <a href="https://observablehq.com/@winkjs/how-to-build-a-naive-wikification-tool?collection=@winkjs/winknlp-recipes" rel="nofollow">live examples</a> have <b>30-40</b> lines of code.</td></tr>
<tr><td><g-emoji alias="framed_picture" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f5bc.png">üñº</g-emoji> Best-in-class <a href="https://winkjs.org/wink-nlp/visualizing-markup.html" rel="nofollow">text visualization</a></td><td>Programmatically <b><a href="https://winkjs.org/wink-nlp/markup.html" rel="nofollow">mark</a></b> tokens, sentences, entities, etc. using HTML mark or any other tag of your choice.</td></tr>
<tr><td><g-emoji alias="recycle" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/267b.png">‚ôªÔ∏è</g-emoji> Extensive text processing features</td><td>Remove and/or retain tokens with specific attributes such as part-of-speech, named entity type, token type, stop word, shape and many more; compute Flesch reading ease score; generate n-grams; normalize, lemmatise or stem. Checkout how with the right kind of text preprocessing, even <a href="https://github.com/winkjs/wink-naive-bayes-text-classifier#readme">Naive Bayes classifier</a> achieves <b>impressive (‚â•90%)</b> accuracy in sentiment analysis and chatbot intent classification tasks.</td></tr>
<tr><td><g-emoji alias="capital_abcd" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f520.png">üî†</g-emoji> Pre-trained <a href="https://winkjs.org/wink-nlp/language-models.html" rel="nofollow">language models</a></td><td>Compact sizes starting from <b>&lt;3MB</b> ‚Äì reduced model loading time drastically.</td></tr>
<tr><td><g-emoji alias="briefcase" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4bc.png">üíº</g-emoji> Host of <a href="https://winkjs.org/wink-nlp/its-as-helper.html" rel="nofollow">utilities &amp; tools</a></td><td>BM25 vectorizer; Several similarity methods ‚Äì Cosine, Tversky, S√∏rensen-Dice, Otsuka-Ochiai; Helpers to get bag of words, frequency table, lemma/stem, stop word removal and many more.</td></tr>
</tbody></table>
<blockquote>
<p dir="auto">WinkJS also has packages like <a href="https://github.com/winkjs/wink-naive-bayes-text-classifier">Naive Bayes classifier</a>, <a href="https://github.com/winkjs/wink-perceptron">multi-class averaged perceptron</a> and <a href="https://github.com/winkjs/wink-distance">popular token and string distance methods</a>, which complement winkNLP.</p>
</blockquote>
<h2 dir="auto"><a id="user-content-documentation" aria-hidden="true" href="#documentation"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Documentation</h2>
<ul dir="auto">
<li><a href="https://winkjs.org/wink-nlp/getting-started.html" rel="nofollow">Concepts</a> ‚Äî everything you need to know to get started.</li>
<li><a href="https://winkjs.org/wink-nlp/read-doc.html" rel="nofollow">API Reference</a> ‚Äî explains usage of APIs with examples.</li>
<li><a href="https://github.com/winkjs/wink-nlp/blob/master/CHANGELOG.md">Change log</a> ‚Äî version history along with the details of breaking changes, if any.</li>
<li><a href="https://winkjs.org/examples.html" rel="nofollow">Examples</a> ‚Äî live examples with code to give you a head start.</li>
</ul>
<h2 dir="auto"><a id="user-content-installation" aria-hidden="true" href="#installation"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Installation</h2>
<p dir="auto">Use <a href="https://www.npmjs.com/package/wink-nlp" rel="nofollow">npm</a> install:</p>
<div dir="auto" data-snippet-clipboard-copy-content="npm install wink-nlp --save"><pre>npm install wink-nlp --save</pre></div>
<p dir="auto">In order to use winkNLP after its installation, you also need to install a language model according to the node version used. The table below outlines the version specific installation command:</p>
<table>
<thead>
<tr>
<th>Node.js Version</th>
<th>Installation</th>
</tr>
</thead>
<tbody>
<tr>
<td>16 or 18</td>
<td><code>npm install wink-eng-lite-web-model --save</code></td>
</tr>
<tr>
<td>14 or 12</td>
<td><code>node -e &#34;require(&#39;wink-nlp/models/install&#39;)&#34;</code></td>
</tr>
</tbody>
</table>
<p dir="auto">The <a href="https://github.com/winkjs/wink-eng-lite-web-model">wink-eng-lite-web-model</a> is designed to work with Node.js version 16 or 18. It can also work on browsers as described in the next section. This is the <strong>recommended</strong> model.</p>
<p dir="auto">The second command installs the <a href="https://github.com/winkjs/wink-eng-lite-model">wink-eng-lite-model</a>, which works with Node.js version 14 or 12.</p>
<h3 dir="auto"><a id="user-content-how-to-install-for-web-browser" aria-hidden="true" href="#how-to-install-for-web-browser"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>How to install for Web Browser</h3>
<p dir="auto">If you‚Äôre using winkNLP in the browser use the <a href="https://www.npmjs.com/package/wink-eng-lite-web-model" rel="nofollow">wink-eng-lite-web-model</a>. Learn about its installation and usage in our <a href="https://winkjs.org/wink-nlp/wink-nlp-in-browsers.html" rel="nofollow">guide to using winkNLP in the browser</a>. Explore <strong><a href="https://observablehq.com/collection/@winkjs/winknlp-recipes" rel="nofollow">winkNLP recipes</a></strong> on <a href="https://observablehq.com/" rel="nofollow">Observable</a> for live browser based examples.</p>
<h3 dir="auto"><a id="user-content-get-started" aria-hidden="true" href="#get-started"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Get started</h3>
<p dir="auto">Here is the &#34;Hello World!&#34; of winkNLP:</p>
<div dir="auto" data-snippet-clipboard-copy-content="// Load wink-nlp package.
const winkNLP = require( &#39;wink-nlp&#39; );
// Load english language model.
const model = require( &#39;wink-eng-lite-web-model&#39; );
// Instantiate winkNLP.
const nlp = winkNLP( model );
// Obtain &#34;its&#34; helper to extract item properties.
const its = nlp.its;
// Obtain &#34;as&#34; reducer helper to reduce a collection.
const as = nlp.as;
 
// NLP Code.
const text = &#39;Hello   Worldüåé! How are you?&#39;;
const doc = nlp.readDoc( text );
 
console.log( doc.out() );
// -&gt; Hello   Worldüåé! How are you?
 
console.log( doc.sentences().out() );
// -&gt; [ &#39;Hello   Worldüåé!&#39;, &#39;How are you?&#39; ]
 
console.log( doc.entities().out( its.detail ) );
// -&gt; [ { value: &#39;üåé&#39;, type: &#39;EMOJI&#39; } ]
 
console.log( doc.tokens().out() );
// -&gt; [ &#39;Hello&#39;, &#39;World&#39;, &#39;üåé&#39;, &#39;!&#39;, &#39;How&#39;, &#39;are&#39;, &#39;you&#39;, &#39;?&#39; ]
 
console.log( doc.tokens().out( its.type, as.freqTable ) );
// -&gt; [ [ &#39;word&#39;, 5 ], [ &#39;punctuation&#39;, 2 ], [ &#39;emoji&#39;, 1 ] ]"><pre><span>// Load wink-nlp package.</span>
<span>const</span> <span>winkNLP</span> <span>=</span> <span>require</span><span>(</span> <span>&#39;wink-nlp&#39;</span> <span>)</span><span>;</span>
<span>// Load english language model.</span>
<span>const</span> <span>model</span> <span>=</span> <span>require</span><span>(</span> <span>&#39;wink-eng-lite-web-model&#39;</span> <span>)</span><span>;</span>
<span>// Instantiate winkNLP.</span>
<span>const</span> <span>nlp</span> <span>=</span> <span>winkNLP</span><span>(</span> <span>model</span> <span>)</span><span>;</span>
<span>// Obtain &#34;its&#34; helper to extract item properties.</span>
<span>const</span> <span>its</span> <span>=</span> <span>nlp</span><span>.</span><span>its</span><span>;</span>
<span>// Obtain &#34;as&#34; reducer helper to reduce a collection.</span>
<span>const</span> <span>as</span> <span>=</span> <span>nlp</span><span>.</span><span>as</span><span>;</span>
 
<span>// NLP Code.</span>
<span>const</span> <span>text</span> <span>=</span> <span>&#39;Hello   Worldüåé! How are you?&#39;</span><span>;</span>
<span>const</span> <span>doc</span> <span>=</span> <span>nlp</span><span>.</span><span>readDoc</span><span>(</span> <span>text</span> <span>)</span><span>;</span>
 
<span>console</span><span>.</span><span>log</span><span>(</span> <span>doc</span><span>.</span><span>out</span><span>(</span><span>)</span> <span>)</span><span>;</span>
<span>// -&gt; Hello   Worldüåé! How are you?</span>
 
<span>console</span><span>.</span><span>log</span><span>(</span> <span>doc</span><span>.</span><span>sentences</span><span>(</span><span>)</span><span>.</span><span>out</span><span>(</span><span>)</span> <span>)</span><span>;</span>
<span>// -&gt; [ &#39;Hello   Worldüåé!&#39;, &#39;How are you?&#39; ]</span>
 
<span>console</span><span>.</span><span>log</span><span>(</span> <span>doc</span><span>.</span><span>entities</span><span>(</span><span>)</span><span>.</span><span>out</span><span>(</span> <span>its</span><span>.</span><span>detail</span> <span>)</span> <span>)</span><span>;</span>
<span>// -&gt; [ { value: &#39;üåé&#39;, type: &#39;EMOJI&#39; } ]</span>
 
<span>console</span><span>.</span><span>log</span><span>(</span> <span>doc</span><span>.</span><span>tokens</span><span>(</span><span>)</span><span>.</span><span>out</span><span>(</span><span>)</span> <span>)</span><span>;</span>
<span>// -&gt; [ &#39;Hello&#39;, &#39;World&#39;, &#39;üåé&#39;, &#39;!&#39;, &#39;How&#39;, &#39;are&#39;, &#39;you&#39;, &#39;?&#39; ]</span>
 
<span>console</span><span>.</span><span>log</span><span>(</span> <span>doc</span><span>.</span><span>tokens</span><span>(</span><span>)</span><span>.</span><span>out</span><span>(</span> <span>its</span><span>.</span><span>type</span><span>,</span> <span>as</span><span>.</span><span>freqTable</span> <span>)</span> <span>)</span><span>;</span>
<span>// -&gt; [ [ &#39;word&#39;, 5 ], [ &#39;punctuation&#39;, 2 ], [ &#39;emoji&#39;, 1 ] ]</span></pre></div>
<p dir="auto">Experiment with winkNLP on <a href="https://npm.runkit.com/wink-nlp" rel="nofollow">RunKit</a>.</p>
<h2 dir="auto"><a id="user-content-speed--accuracy" aria-hidden="true" href="#speed--accuracy"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Speed &amp; Accuracy</h2>
<p dir="auto">The <a href="https://winkjs.org/wink-nlp/" rel="nofollow">winkNLP</a> processes raw text at <strong>~650,000 tokens per second</strong> with its <a href="https://github.com/winkjs/wink-eng-lite-web-model">wink-eng-lite-web-model</a>, when <a href="https://github.com/bestiejs/benchmark.js">benchmarked</a> using &#34;Ch 13 of Ulysses by James Joyce&#34; on a M1 Macbook Pro machine with 16GB RAM. The processing included the entire NLP pipeline ‚Äî tokenization, sentence boundary detection, negation handling, sentiment analysis, part-of-speech tagging, and named entity extraction. This speed is way ahead of the prevailing speed benchmarks.</p>
<p dir="auto">The benchmark was conducted on <a href="https://nodejs.org/en/about/releases/" rel="nofollow">Node.js versions 16, and 18</a>.</p>
<p dir="auto">It pos tags a subset of WSJ corpus with an accuracy of <strong>~94.7%</strong> ‚Äî this includes <em>tokenization of raw text prior to pos tagging</em>. The present state-of-the-art is at ~97% accuracy but at lower speeds and is generally computed using gold standard pre-tokenized corpus.</p>
<p dir="auto">Its general purpose sentiment analysis delivers a <a href="https://en.wikipedia.org/wiki/F1_score" rel="nofollow">f-score</a> of <strong>~84.5%</strong>, when validated using Amazon Product Review <a href="https://archive.ics.uci.edu/ml/machine-learning-databases/00331/" rel="nofollow">Sentiment Labelled Sentences Data Set</a> at <a href="https://archive.ics.uci.edu/ml/index.php" rel="nofollow">UCI Machine Learning Repository</a>. The current benchmark accuracy for <strong>specifically trained</strong> models can range around 95%.</p>
<h2 dir="auto"><a id="user-content-memory-requirement" aria-hidden="true" href="#memory-requirement"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Memory Requirement</h2>
<p dir="auto">Wink NLP delivers this performance with the minimal load on RAM. For example, it processes the entire <a href="https://en.wikisource.org/wiki/History_of_India/Volume_1" rel="nofollow">History of India Volume I</a> with a total peak memory requirement of under <strong>80MB</strong>. The book has around 350 pages which translates to over 125,000 tokens.</p>
<h2 dir="auto"><a id="user-content-need-help" aria-hidden="true" href="#need-help"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Need Help?</h2>
<h3 dir="auto"><a id="user-content-usage-query-" aria-hidden="true" href="#usage-query-"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Usage query üë©üèΩ‚Äçüíª</h3>
<p dir="auto">Please ask at <a href="https://stackoverflow.com/" rel="nofollow">Stack Overflow</a> or discuss at <a href="https://github.com/winkjs/wink-nlp/discussions">Wink JS GitHub Discussions</a> or chat with us at <a href="https://gitter.im/winkjs/Lobby" rel="nofollow">Wink JS Gitter Lobby</a>.</p>
<h3 dir="auto"><a id="user-content-bug-report-" aria-hidden="true" href="#bug-report-"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Bug report <g-emoji alias="bug" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f41b.png">üêõ</g-emoji></h3>
<p dir="auto">If you spot a bug and the same has not yet been reported, raise a new <a href="https://github.com/winkjs/wink-nlp/issues">issue</a> or consider fixing it and sending a PR.</p>
<h3 dir="auto"><a id="user-content-new-feature-" aria-hidden="true" href="#new-feature-"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>New feature <g-emoji alias="star2" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f31f.png">üåü</g-emoji></h3>
<p dir="auto">Looking for a new feature, request it via the <a href="https://github.com/winkjs/wink-nlp/discussions/categories/new-features-ideas">new features &amp; ideas</a> discussion forum  or consider becoming a <a href="https://github.com/winkjs/wink-nlp/blob/master/CONTRIBUTING.md">contributor</a>.</p>
<h2 dir="auto"><a id="user-content-about-winkjs" aria-hidden="true" href="#about-winkjs"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>About winkJS</h2>
<p dir="auto"><a href="https://winkjs.org/" rel="nofollow">WinkJS</a> is a family of open source packages for <strong>Natural Language Processing</strong>, <strong>Machine Learning</strong>, and <strong>Statistical Analysis</strong> in NodeJS. The code is <strong>thoroughly documented</strong> for easy human comprehension and has a <strong>test coverage of ~100%</strong> for reliability to build production grade solutions.</p>
<h2 dir="auto"><a id="user-content-copyright--license" aria-hidden="true" href="#copyright--license"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Copyright &amp; License</h2>
<p dir="auto"><strong>Wink NLP</strong> is copyright 2017-22 <a href="https://graype.in/" rel="nofollow">GRAYPE Systems Private Limited</a>.</p>
<p dir="auto">It is licensed under the terms of the MIT License.</p>
</article>
          </div></div>
  </body>
</html>
