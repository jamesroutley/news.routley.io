<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.cerebras.ai/press-release/series-g">Original</a>
    <h1>Cerebras systems raises $1.1B Series G</h1>
    
    <div id="readability-page-1" class="page"><div data-sanity="id=cbc365b9-f2ce-421e-971f-addf7e5f717b;type=pressRelease;path=slices;base=https%3A%2F%2Fwww.cerebras.ai"><section data-slicetype="articleText" data-sanity="id=cbc365b9-f2ce-421e-971f-addf7e5f717b;type=pressRelease;path=slices:e26ae3172f73;base=https%3A%2F%2Fwww.cerebras.ai"><div><div><div><div><div><div><p><em>Fidelity Management &amp; Research Company Anchors Investment with an All-Star Consortium of Investors</em></p><p>Sunnyvale, CA – September 30, 2025 – Cerebras Systems, makers of the fastest AI infrastructure in the industry, today announced the completion of an over subscribed$1.1 billion Series G funding round at $8.1 billion post-money valuation. The round was led by Fidelity Management &amp; Research Company and Atreides Management. The round included significant participation from Tiger Global, Valor Equity Partners, and 1789 Capital, as well as existing investors Altimeter, Alpha Wave, and Benchmark.</p><p>As the fastest inference provider in the world, Cerebras will use these funds to expand its pioneering technology portfolio with continued inventions in AI processor design, packaging, system design and AI supercomputers. In addition, it will expand its U.S. manufacturing capacity and its U.S. data center capacity to keep pace with the explosive demand for Cerebras products and services.</p><p>&#34;From our inception we have been backed by the most knowledgeable investors in the industry. They have seen the historic opportunity that is AI and have chosen to invest in Cerebras,” said Andrew Feldman, co-founder and CEO, Cerebras. &#34;We are proud to expand our consortium of best-in-world investors.”</p><h3>Inference Momentum as AI Industry Leaders Choose Cerebras</h3><p>Cerebras has experienced extraordinary growth since launching its inference service in late 2024. Over the past year, Cerebras has held the performance crown every single day, routinely demonstrating speeds more than 20X faster than Nvidia GPUs on open-source and closed source models.</p><p>&#34;Since our founding, we have tested every AI inference provider across hundreds of models. Cerebras is consistently the fastest,” said Micah Hill-Smith, CEO of leading benchmarking firm Artificial Analysis.</p><!--$!--><template data-dgst="BAILOUT_TO_CLIENT_SIDE_RENDERING"></template><!--/$--><p>Cerebras’ performance advantage has led to massive demand. New real-time use cases – including code generation, reasoning, and agentic work – have increased the benefits from speed and the increased the cost of being slow, driving customers to Cerebras. Today, Cerebras is serving trillions of tokens per month, in its own cloud, on its customers premises, and across leading partner platforms.</p><p>In 2025, AI leaders including AWS, Meta, IBM, Mistral, Cognition, AlphaSense, Notion and hundreds more have chosen Cerebras, joining enterprises and governments, including GlaxoSmithKline, Mayo Clinic, the US Department of Energy, the US Department of Defense. Individual developers have also chosen Cerebras for their AI work. On Hugging Face, the leading AI hub for developers, Cerebras is the #1 inference provider with over 5 million monthly requests.</p><p>Citigroup and Barclays Capital acted as joint placement agents for the transaction.</p><h3>About Cerebras Systems</h3><p>Cerebras Systems builds the fastest AI infrastructure in the world. We are a team of pioneering computer architects, computer scientists, AI researchers, and engineers of all types. We have come together to make AI blisteringly fast through innovation and invention because we believe that when AI is fast it will change the world. Our flagship technology, the Wafer Scale Engine 3 (WSE-3) is the world’s largest and fastest AI processor.56 times larger than the largest GPU, the WSE uses a fraction of the power per unit compute while delivering inference and training more than 20 times faster than the competition.Leading corporations, research institutes and governments on four continents chose Cerebras to run their AI workloads. Cerebras solutions are available on premise and in the cloud, for further information, visit cerebras.ai or follow us on LinkedIn, X and/or Threads.</p><p>Media Contact</p><p><a href="mailto:PR@zmcommunications.com">PR@zmcommunications.com</a></p></div></div></div></div></div></div></section></div></div>
  </body>
</html>
