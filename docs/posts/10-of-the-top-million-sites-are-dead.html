<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://ccampbell.io/posts/10-percent-of-top-million-sites-are-dead/">Original</a>
    <h1>10% of the top million sites are dead</h1>
    
    <div id="readability-page-1" class="page"><article>
    <header>
      
        <ol>
  
  
    
  
    
  
  <li>
    <a href="https://ccampbell.io/">Craig Campbell</a><span>/</span>
  </li>

  
  <li>
    <a href="https://ccampbell.io/posts/">Posts</a><span>/</span>
  </li>

  
  <li>
    <a href="https://ccampbell.io/posts/10-percent-of-top-million-sites-are-dead/">10% of the Top 1 Million Sites are Dead</a><span>/</span>
  </li>

</ol>


      
      
      
    </header>
    <section>
      
      <div>
        <p>As part of ongoing series of research I’m doing as I dabble with building a new kind of search engine (more on this later), I decided to take a dive into understanding the top websites that represent the internet as of 2022. For my purposes, <a href="https://majestic.com/reports/majestic-million" target="_blank">the Majestic Million dataset</a> felt like the perfect fit as it is ranked by the number of links that point to that domain (as well as taking into account diversity of the origin domains as well). Additionally, it contains subdomains as well as root domains which is a better fit for my particular research angle.</p>
<p>Spoilers: the Majestic Million has some data issues, always verify before using it blindly</p>
<h2 id="first-lets-get-the-data-and-understand-the-format">First: let’s get the data and understand the format <span><a href="#first-lets-get-the-data-and-understand-the-format" aria-label="Anchor">#</a></span></h2>
<p>This is simple, Majestic has kindly provided <a href="https://downloads.majestic.com/majestic_million.csv" target="_blank">a free download</a> of the top million domains as a csv.
After downloading, let’s take a quick peek at the file and verify base assumptions by loading it up in DuckDB.</p>
<p><span>
    

  <span>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentColor" d="M256 32C114.6 32 .0272 125.1 .0272 240c0 49.63 21.35 94.98 56.97 130.7c-12.5 50.37-54.27 95.27-54.77 95.77c-2.25 2.25-2.875 5.734-1.5 8.734C1.979 478.2 4.75 480 8 480c66.25 0 115.1-31.76 140.6-51.39C181.2 440.9 217.6 448 256 448c141.4 0 255.1-93.13 255.1-208S397.4 32 256 32z"></path></svg>

  </span>


  </span>
  <span>I love <a href="https://duckdb.org/">DuckDB</a> and will write a proper love letter to it in a future post. Easily 20x faster vs SQLite in my testing</span>
</p>

<div><pre tabindex="0"><code data-lang="shell"><span><span>$ duckdb
</span></span><span><span>v0.4.0 da9ee490d
</span></span><span><span>Enter <span>&#34;.help&#34;</span> <span>for</span> usage hints.
</span></span><span><span>Connected to a transient in-memory database.
</span></span><span><span>Use <span>&#34;.open FILENAME&#34;</span> to reopen on a persistent database.
</span></span><span><span>
</span></span><span><span>D describe <span>select</span> * from <span>&#39;majestic_million.csv&#39;</span><span>;</span> 
</span></span><span><span>┌────────────────┬─────────────┬──────┬─────┬─────────┬───────┐
</span></span><span><span>│  column_name   │ column_type │ null │ key │ default │ extra │
</span></span><span><span>├────────────────┼─────────────┼──────┼─────┼─────────┼───────┤
</span></span><span><span>│ GlobalRank     │ INTEGER     │ YES  │     │         │       │
</span></span><span><span>│ TldRank        │ INTEGER     │ YES  │     │         │       │
</span></span><span><span>│ Domain         │ VARCHAR     │ YES  │     │         │       │
</span></span><span><span>│ TLD            │ VARCHAR     │ YES  │     │         │       │
</span></span><span><span>│ RefSubNets     │ INTEGER     │ YES  │     │         │       │
</span></span><span><span>│ RefIPs         │ INTEGER     │ YES  │     │         │       │
</span></span><span><span>│ IDN_Domain     │ VARCHAR     │ YES  │     │         │       │
</span></span><span><span>│ IDN_TLD        │ VARCHAR     │ YES  │     │         │       │
</span></span><span><span>│ PrevGlobalRank │ INTEGER     │ YES  │     │         │       │
</span></span><span><span>│ PrevTldRank    │ INTEGER     │ YES  │     │         │       │
</span></span><span><span>│ PrevRefSubNets │ INTEGER     │ YES  │     │         │       │
</span></span><span><span>│ PrevRefIPs     │ INTEGER     │ YES  │     │         │       │
</span></span><span><span>└────────────────┴─────────────┴──────┴─────┴─────────┴───────┘
</span></span><span><span>D <span>select</span> count<span>(</span>distinct domain<span>)</span> from <span>&#39;majestic_million.csv&#39;</span><span>;</span>
</span></span><span><span>┌──────────────────────────┐
</span></span><span><span>│ count<span>(</span>DISTINCT <span>&#34;domain&#34;</span><span>)</span> │
</span></span><span><span>├──────────────────────────┤
</span></span><span><span>│ <span>1000000</span>                  │
</span></span><span><span>└──────────────────────────┘
</span></span><span><span>D <span>select</span> globalrank, domain from <span>&#39;majestic_million.csv&#39;</span> limit 5<span>;</span>
</span></span><span><span>┌────────────┬───────────────┐
</span></span><span><span>│ GlobalRank │    Domain     │
</span></span><span><span>├────────────┼───────────────┤
</span></span><span><span>│ <span>1</span>          │ google.com    │
</span></span><span><span>│ <span>2</span>          │ facebook.com  │
</span></span><span><span>│ <span>3</span>          │ youtube.com   │
</span></span><span><span>│ <span>4</span>          │ twitter.com   │
</span></span><span><span>│ <span>5</span>          │ instagram.com │
</span></span><span><span>└────────────┴───────────────┘
</span></span></code></pre></div><p>Yes, it really is that easy thanks to DuckDB doing all the heavy lifting. And the data quality looks good with this 2 second peek: we do indeed have 1 million unique domains, and the top ones look reasonable.</p>
<p>Perfect. Everything looks great. End of post. Right?</p>
<h2 id="second-verifying-domain-normalization-or-where-we-find-our-first-problem">Second: verifying domain normalization, or where we find our first problem <span><a href="#second-verifying-domain-normalization-or-where-we-find-our-first-problem" aria-label="Anchor">#</a></span></h2>
<p>Domain normalization is a bitch. I’ve worked on it in the past as part of my time building Facebook Search, and it’s a tricky thing to get right. One example of a super simple but commonly overlooked case is parsing out the <em>sometimes</em> optional <code>www</code> prefix.</p>
<p>As a concrete example, for the purpose of identifying top unique domains from a large corpus of scraped content you’d ideally want to normalize both <code>www.google.com</code> and <code>google.com</code> to the same row. Simple enough, so obviously Majestic does this right?</p>
<div><pre tabindex="0"><code data-lang="sql"><span><span><span>D</span><span> </span><span>select</span><span> </span><span>count</span><span>(</span><span>*</span><span>)</span><span> </span><span>from</span><span> </span><span>&#39;majestic_million.csv&#39;</span><span> </span><span>where</span><span> </span><span>domain</span><span> </span><span>glob</span><span> </span><span>&#39;www.*&#39;</span><span>;</span><span>
</span></span></span><span><span><span></span><span>┌──────────────┐</span><span>
</span></span></span><span><span><span></span><span>│</span><span> </span><span>count_star</span><span>()</span><span> </span><span>│</span><span>
</span></span></span><span><span><span></span><span>├──────────────┤</span><span>
</span></span></span><span><span><span></span><span>│</span><span> </span><span>410</span><span>          </span><span>│</span><span>
</span></span></span><span><span><span></span><span>└──────────────┘</span><span>
</span></span></span><span><span><span></span><span>D</span><span> </span><span>select</span><span> </span><span>globalrank</span><span>,</span><span> </span><span>domain</span><span> </span><span>from</span><span> </span><span>&#39;majestic_million.csv&#39;</span><span> </span><span>where</span><span> </span><span>domain</span><span> </span><span>glob</span><span> </span><span>&#39;www.*&#39;</span><span> </span><span>limit</span><span> </span><span>5</span><span>;</span><span>
</span></span></span><span><span><span></span><span>┌────────────┬───────────────────────┐</span><span>
</span></span></span><span><span><span></span><span>│</span><span> </span><span>GlobalRank</span><span> </span><span>│</span><span>        </span><span>Domain</span><span>         </span><span>│</span><span>
</span></span></span><span><span><span></span><span>├────────────┼───────────────────────┤</span><span>
</span></span></span><span><span><span></span><span>│</span><span> </span><span>61</span><span>         </span><span>│</span><span> </span><span>www</span><span>.</span><span>ncbi</span><span>.</span><span>nlm</span><span>.</span><span>nih</span><span>.</span><span>gov</span><span>  </span><span>│</span><span>
</span></span></span><span><span><span></span><span>│</span><span> </span><span>130</span><span>        </span><span>│</span><span> </span><span>www</span><span>.</span><span>gov</span><span>.</span><span>uk</span><span>            </span><span>│</span><span>
</span></span></span><span><span><span></span><span>│</span><span> </span><span>275</span><span>        </span><span>│</span><span> </span><span>www</span><span>.</span><span>beian</span><span>.</span><span>miit</span><span>.</span><span>gov</span><span>.</span><span>cn</span><span> </span><span>│</span><span>
</span></span></span><span><span><span></span><span>│</span><span> </span><span>516</span><span>        </span><span>│</span><span> </span><span>www</span><span>.</span><span>nhs</span><span>.</span><span>uk</span><span>            </span><span>│</span><span>
</span></span></span><span><span><span></span><span>│</span><span> </span><span>642</span><span>        </span><span>│</span><span> </span><span>www</span><span>.</span><span>gov</span><span>.</span><span>cn</span><span>            </span><span>│</span><span>
</span></span></span><span><span><span></span><span>└────────────┴───────────────────────┘</span><span>
</span></span></span></code></pre></div><p>Uh oh. Errant domains with the <code>www</code> prefix not parsed out, and a quick peek confirms that these are not in the longtail of the list either.</p>
<p>Let’s check if any of these non-normalized domains have duplicates in the list.</p>
<div><pre tabindex="0"><code data-lang="sql"><span><span><span>D</span><span> </span><span>select</span><span> </span><span>count</span><span>(</span><span>*</span><span>)</span><span> </span><span>from</span><span> </span><span>(</span><span>select</span><span> </span><span>a</span><span>.</span><span>globalrank</span><span>,</span><span> </span><span>a</span><span>.</span><span>domain</span><span>,</span><span> </span><span>b</span><span>.</span><span>globalrank</span><span>,</span><span> </span><span>b</span><span>.</span><span>domain</span><span> </span><span>from</span><span> </span><span>&#39;majestic_million.csv&#39;</span><span> </span><span>as</span><span> </span><span>a</span><span> </span><span>inner</span><span> </span><span>join</span><span> </span><span>(</span><span>select</span><span> </span><span>globalrank</span><span>,</span><span> </span><span>domain</span><span>,</span><span> </span><span>regexp_replace</span><span>(</span><span>domain</span><span>,</span><span> </span><span>&#39;^www\.&#39;</span><span>,</span><span> </span><span>&#39;&#39;</span><span>)</span><span> </span><span>as</span><span> </span><span>norm_domain</span><span> </span><span>from</span><span> </span><span>&#39;majestic_million.csv&#39;</span><span> </span><span>where</span><span> </span><span>domain</span><span> </span><span>glob</span><span> </span><span>&#39;www.*&#39;</span><span> </span><span>order</span><span> </span><span>by</span><span> </span><span>globalrank</span><span>)</span><span> </span><span>as</span><span> </span><span>b</span><span> </span><span>on</span><span> </span><span>a</span><span>.</span><span>domain</span><span> </span><span>=</span><span> </span><span>b</span><span>.</span><span>norm_domain</span><span>);</span><span>
</span></span></span><span><span><span></span><span>┌──────────────┐</span><span>
</span></span></span><span><span><span></span><span>│</span><span> </span><span>count_star</span><span>()</span><span> </span><span>│</span><span>
</span></span></span><span><span><span></span><span>├──────────────┤</span><span>
</span></span></span><span><span><span></span><span>│</span><span> </span><span>221</span><span>          </span><span>│</span><span>
</span></span></span><span><span><span></span><span>└──────────────┘</span><span>
</span></span></span><span><span><span></span><span>D</span><span> </span><span>select</span><span> </span><span>a</span><span>.</span><span>globalrank</span><span>,</span><span> </span><span>a</span><span>.</span><span>domain</span><span>,</span><span> </span><span>b</span><span>.</span><span>globalrank</span><span>,</span><span> </span><span>b</span><span>.</span><span>domain</span><span> </span><span>from</span><span> </span><span>&#39;majestic_million.csv&#39;</span><span> </span><span>as</span><span> </span><span>a</span><span> </span><span>inner</span><span> </span><span>join</span><span> </span><span>(</span><span>select</span><span> </span><span>globalrank</span><span>,</span><span> </span><span>domain</span><span>,</span><span> </span><span>regexp_replace</span><span>(</span><span>domain</span><span>,</span><span> </span><span>&#39;^www\.&#39;</span><span>,</span><span> </span><span>&#39;&#39;</span><span>)</span><span> </span><span>as</span><span> </span><span>norm_domain</span><span> </span><span>from</span><span> </span><span>&#39;majestic_million.csv&#39;</span><span> </span><span>where</span><span> </span><span>domain</span><span> </span><span>glob</span><span> </span><span>&#39;www.*&#39;</span><span> </span><span>order</span><span> </span><span>by</span><span> </span><span>globalrank</span><span>)</span><span> </span><span>as</span><span> </span><span>b</span><span> </span><span>on</span><span> </span><span>a</span><span>.</span><span>domain</span><span> </span><span>=</span><span> </span><span>b</span><span>.</span><span>norm_domain</span><span> </span><span>limit</span><span> </span><span>5</span><span>;</span><span> 
</span></span></span><span><span><span></span><span>┌────────────┬───────────────────┬────────────┬───────────────────────┐</span><span>
</span></span></span><span><span><span></span><span>│</span><span> </span><span>GlobalRank</span><span> </span><span>│</span><span>      </span><span>Domain</span><span>       </span><span>│</span><span> </span><span>GlobalRank</span><span> </span><span>│</span><span>        </span><span>Domain</span><span>         </span><span>│</span><span>
</span></span></span><span><span><span></span><span>├────────────┼───────────────────┼────────────┼───────────────────────┤</span><span>
</span></span></span><span><span><span></span><span>│</span><span> </span><span>72</span><span>         </span><span>│</span><span> </span><span>beian</span><span>.</span><span>miit</span><span>.</span><span>gov</span><span>.</span><span>cn</span><span> </span><span>│</span><span> </span><span>275</span><span>        </span><span>│</span><span> </span><span>www</span><span>.</span><span>beian</span><span>.</span><span>miit</span><span>.</span><span>gov</span><span>.</span><span>cn</span><span> </span><span>│</span><span>
</span></span></span><span><span><span></span><span>│</span><span> </span><span>1926</span><span>       </span><span>│</span><span> </span><span>bl</span><span>.</span><span>uk</span><span>             </span><span>│</span><span> </span><span>1840</span><span>       </span><span>│</span><span> </span><span>www</span><span>.</span><span>bl</span><span>.</span><span>uk</span><span>             </span><span>│</span><span>
</span></span></span><span><span><span></span><span>│</span><span> </span><span>2393</span><span>       </span><span>│</span><span> </span><span>parliament</span><span>.</span><span>uk</span><span>     </span><span>│</span><span> </span><span>2376</span><span>       </span><span>│</span><span> </span><span>www</span><span>.</span><span>parliament</span><span>.</span><span>uk</span><span>     </span><span>│</span><span>
</span></span></span><span><span><span></span><span>│</span><span> </span><span>5845</span><span>       </span><span>│</span><span> </span><span>royal</span><span>.</span><span>uk</span><span>          </span><span>│</span><span> </span><span>5535</span><span>       </span><span>│</span><span> </span><span>www</span><span>.</span><span>royal</span><span>.</span><span>uk</span><span>          </span><span>│</span><span>
</span></span></span><span><span><span></span><span>│</span><span> </span><span>6421</span><span>       </span><span>│</span><span> </span><span>gov</span><span>.</span><span>wales</span><span>         </span><span>│</span><span> </span><span>553656</span><span>     </span><span>│</span><span> </span><span>www</span><span>.</span><span>gov</span><span>.</span><span>wales</span><span>         </span><span>│</span><span>
</span></span></span><span><span><span></span><span>└────────────┴───────────────────┴────────────┴───────────────────────┘</span><span>
</span></span></span></code></pre></div><p>Damn, 211 duplicate domains. <b>The Majestic Million is officially the Majestic 999,789</b>.</p>
<p>My faith was shaken. Just how much of this list could I really trust?</p>
<h2 id="third-into-the-abyss-aka-rapidly-crawling-a-million-domains-on-my-macbook-pro">Third: Into the abyss, aka rapidly crawling a million domains on my macbook pro <span><a href="#third-into-the-abyss-aka-rapidly-crawling-a-million-domains-on-my-macbook-pro" aria-label="Anchor">#</a></span></h2>
<p>I decided a better quality filter step was needed to really understand this list. After some thought, I decided that a very reasonable but basic check would be to check each domain and verify that it was online and responsive to http requests. With only a million domains, this could be run from my own computer relatively simply and it would give us a very quick temperature check on whether the list truly was representative of the “top sites on the internet”.</p>
<p>So, let’s crack out our handy-dandy terminal and whip up a quick parallelized domain checker:</p>
<ol>
<li>Simple line output first</li>
</ol>
<div><pre tabindex="0"><code data-lang="shell"><span><span>$ cat majestic_million.csv
</span></span><span><span>GlobalRank,TldRank,Domain,TLD,RefSubNets,RefIPs,IDN_Domain,IDN_TLD,PrevGlobalRank,PrevTldRank,PrevRefSubNets,PrevRefIPs
</span></span><span><span>1,1,google.com,com,492783,2480253,google.com,com,1,1,493554,2490230
</span></span><span><span>2,2,facebook.com,com,491683,2636952,facebook.com,com,2,2,492662,2648135
</span></span><span><span>...
</span></span></code></pre></div><ol start="2">
<li>Using awk: regex to ignore header and only grab domain from each row</li>
</ol>
<div><pre tabindex="0"><code data-lang="shell"><span><span>$ cat majestic_million.csv <span>|</span> <span>\
</span></span></span><span><span><span></span>  awk <span>&#39;/^[0-9]+,.+/ { split($0, a, &#34;,&#34;); print a[3] }&#39;</span>
</span></span><span><span>google.com
</span></span><span><span>facebook.com
</span></span><span><span>youtube.com
</span></span><span><span>...
</span></span></code></pre></div><ol start="3">
<li>Set up parallelization to fully use all CPU cores (8 for me) for url processing</li>
</ol>
<div><pre tabindex="0"><code data-lang="shell"><span><span>$ cat majestic_million.csv <span>|</span> <span>\
</span></span></span><span><span><span></span>  awk <span>&#39;/^[0-9]+,.+/ { split($0, a, &#34;,&#34;); print a[3] }&#39;</span> <span>|</span> <span>\
</span></span></span><span><span><span></span>  xargs -n1 -P8 sh -c <span>&#39;echo &#34;<a href="https://ccampbell.io/cdn-cgi/l/email-protection" data-cfemail="bd99fd">[email protected]</a>&#34;&#39;</span> _
</span></span><span><span>google.com
</span></span><span><span>facebook.com
</span></span><span><span>youtube.com
</span></span><span><span>...
</span></span></code></pre></div><ol start="4">
<li>And now perform the actual curl request in each sub-process. We use a simple head request since we really just care about the status code and use a 60 second timeout. We also simplify the output format to <code>{url},{http_code}</code> to make analysis easy</li>
</ol>
<div><pre tabindex="0"><code data-lang="shell"><span><span>$ cat majestic_million.csv <span>|</span> <span>\
</span></span></span><span><span><span></span>  awk <span>&#39;/^[0-9]+,.+/ { split($0, a, &#34;,&#34;); print a[3] }&#39;</span> <span>|</span> <span>\
</span></span></span><span><span><span></span>  xargs -n1 -P8 sh -c <span>\
</span></span></span><span><span><span></span>  <span>&#39;curl -LI -s -o /dev/null -w &#34;%{url},%{http_code}\n&#34; -A &#34;Mozilla/5.0 (X11; Linux x86_64; rv:60.0) Gecko/20100101 Firefox/81.0&#34; --max-time 60 &#34;<a href="https://ccampbell.io/cdn-cgi/l/email-protection" data-cfemail="9abeda">[email protected]</a>&#34;&#39;</span> _
</span></span><span><span>google.com,200
</span></span><span><span>twitter.com,200
</span></span><span><span>facebook.com,200
</span></span><span><span>...
</span></span></code></pre></div><ol start="5">
<li>Output results to a single file. I also went ahead and piped stdout to /dev/null since this actually caused my terminal to OOM thanks to my endless history setting (whoops!). Note: we use <code>tee -a</code> as it provides an atomic append operation that works across many threads/processes</li>
</ol>
<div><pre tabindex="0"><code data-lang="shell"><span><span>$ cat majestic_million.csv <span>|</span> <span>\
</span></span></span><span><span><span></span>  awk <span>&#39;/^[0-9]+,.+/ { split($0, a, &#34;,&#34;); print a[3] }&#39;</span> <span>|</span> <span>\
</span></span></span><span><span><span></span>  xargs -n1 -P8 sh -c <span>\
</span></span></span><span><span><span></span>  <span>&#39;curl -LI -s -o /dev/null -w &#34;%{url},%{http_code}\n&#34; -A &#34;Mozilla/5.0 (X11; Linux x86_64; rv:60.0) Gecko/20100101 Firefox/81.0&#34; --max-time 60 &#34;<a href="https://ccampbell.io/cdn-cgi/l/email-protection" data-cfemail="ac88ec">[email protected]</a>&#34; | \
</span></span></span><span><span><span>   tee -a http_codes.csv &gt; /dev/null&#39;</span> _
</span></span></code></pre></div><ol start="6">
<li>Now we crank up the parallelization for the final run - the network was always going to be the main bottleneck for something like this instead of CPU. I found that my local system could easily handle 512 parallel processes, with my CPU @ ~35% utilization, 2GB of RAM usage, and a constant 1.5MB down on the network. Obviously YMMV depending on your system so I suggest doing your own tuning if you’re following along. We simply have to modify the <code>-P</code> argument on xargs to do this. Final command:</li>
</ol>
<div><pre tabindex="0"><code data-lang="shell"><span><span>$ cat majestic_million.csv <span>|</span> <span>\
</span></span></span><span><span><span></span>  awk <span>&#39;/^[0-9]+,.+/ { split($0, a, &#34;,&#34;); print a[3] }&#39;</span> <span>|</span> <span>\
</span></span></span><span><span><span></span>  xargs -n1 -P512 sh -c <span>\
</span></span></span><span><span><span></span>  <span>&#39;curl -LI -s -o /dev/null -w &#34;%{url},%{http_code}\n&#34; -A &#34;Mozilla/5.0 (X11; Linux x86_64; rv:60.0) Gecko/20100101 Firefox/81.0&#34; --max-time 60 &#34;<a href="https://ccampbell.io/cdn-cgi/l/email-protection" data-cfemail="f2d6b2">[email protected]</a>&#34; | \
</span></span></span><span><span><span>   tee -a http_codes.csv &gt; /dev/null&#39;</span> _
</span></span></code></pre></div><p>Easy peasy. Now we wait… (you can use <code>cat http_codes.csv | wc -l</code> to verify run status)</p>
<figure>
      <img srcset="
          /images/one_hour_later_hud7476bb0c6b01d60b30ac468d990ae6f_615478_330x0_resize_q75_box.jpg 330w,
          /images/one_hour_later_hud7476bb0c6b01d60b30ac468d990ae6f_615478_660x0_resize_q75_box.jpg 660w,
          /images/one_hour_later_hud7476bb0c6b01d60b30ac468d990ae6f_615478_1024x0_resize_q75_box.jpg 1024w,
          /images/one_hour_later_hud7476bb0c6b01d60b30ac468d990ae6f_615478_1320x0_resize_q75_box.jpg 2x" src="https://ccampbell.io/images/one_hour_later_hud7476bb0c6b01d60b30ac468d990ae6f_615478_660x0_resize_q75_box.jpg" alt=""/>
      
    </figure>
  


<p>And in one short hour (technically ~50 minutes for me), we have a fresh shiny output file with the http response codes of the Majestic Million domains.</p>
<p>So now the moment of truth, let’s use our trusty friend DuckDB to check the top 5 most common response codes for the Majestic Million:</p>
<div><pre tabindex="0"><code data-lang="sql"><span><span><span>D</span><span> </span><span>select</span><span> </span><span>count</span><span>(</span><span>*</span><span>)</span><span> </span><span>as</span><span> </span><span>num</span><span>,</span><span> </span><span>column1</span><span> </span><span>as</span><span> </span><span>http_code</span><span> </span><span>from</span><span> </span><span>&#39;http_codes_majestic_million.csv&#39;</span><span> </span><span>group</span><span> </span><span>by</span><span> </span><span>column1</span><span> </span><span>order</span><span> </span><span>by</span><span> </span><span>count</span><span>(</span><span>*</span><span>)</span><span> </span><span>desc</span><span> </span><span>limit</span><span> </span><span>5</span><span>;</span><span> 
</span></span></span><span><span><span></span><span>┌────────┬───────────┐</span><span>
</span></span></span><span><span><span></span><span>│</span><span>  </span><span>num</span><span>   </span><span>│</span><span> </span><span>http_code</span><span> </span><span>│</span><span>
</span></span></span><span><span><span></span><span>├────────┼───────────┤</span><span>
</span></span></span><span><span><span></span><span>│</span><span> </span><span>815669</span><span> </span><span>│</span><span> </span><span>200</span><span>       </span><span>│</span><span>
</span></span></span><span><span><span></span><span>│</span><span> </span><span>107776</span><span> </span><span>│</span><span> </span><span>0</span><span>         </span><span>│</span><span> </span><span>&lt;</span><span>-- this is the one we care about
</span></span></span><span><span><span></span><span>│</span><span> </span><span>18140</span><span>  </span><span>│</span><span> </span><span>403</span><span>       </span><span>│</span><span>
</span></span></span><span><span><span></span><span>│</span><span> </span><span>14183</span><span>  </span><span>│</span><span> </span><span>404</span><span>       </span><span>│</span><span>
</span></span></span><span><span><span></span><span>│</span><span> </span><span>10353</span><span>  </span><span>│</span><span> </span><span>301</span><span>       </span><span>│</span><span>
</span></span></span><span><span><span></span><span>└────────┴───────────┘</span><span>
</span></span></span></code></pre></div><p>107,776 domains could not even be connected to. That’s 10.7% of the full list, which is pretty bad if you ask me. On top of that, there’s a longtail of sites that had a variety of non-200 reponse codes but just to be conservative we’ll assume that they are all valid anyways and maybe our curl was simply hitting some kind of Cloudflare check or a blanket block on HEAD requests. But straight connection errors to the domain homepages? Very suspect.</p>
<h2 id="conclusion-the-majestic-smillions-892013">Conclusion: The Majestic <s>Million</s> 892,013 <span><a href="#conclusion-the-majestic-smillions-892013" aria-label="Anchor">#</a></span></h2>
<p>While I had expected some cleanliness issues, I wasn’t expecting to see this level of quality problems from a dataset that I’ve seen referenced pretty extensively across the web (and this is me being very conservative with knocking domains out).</p>
<p>One big caveat that I’m well aware of is that I only crawled the domain homepages, and it very well could be that many of these domains are solely configured to respond to specific endpoints. Even so, this feels iffy to me and really doesn’t indicate that this is a high-quality site worthy of placement on this kind of list. Another potential source of problems could be a misconfigured DNS or reverse-proxy where non-SSL or non-WWW requests aren’t being redirected properly. Potential follow-up for anyone interested in further digging.</p>
<p>As one more potential follow-up, I’m curious how alternative top domain lists (such as the <a href="https://tranco-list.eu/">Tranco</a> and <a href="https://s3-us-west-1.amazonaws.com/umbrella-static/index.html">Cisco Umbrella</a>) fair against these quality checks, but I’ll leave that for another day.</p>
<p>Here’s the full CSV of all http response codes pulled using the above method for those who’d like to dive in more: <a href="https://ccampbell.io/downloads/http_codes_majestic_million.csv.gz">http_codes_majestic_million.csv.gz</a></p>
<p>Have comments? <a href="https://twitter.com/craig_campbell" target="_blank">Tweet at me</a></p>

      </div>
    </section>
    
    
  </article></div>
  </body>
</html>
