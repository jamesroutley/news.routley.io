<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.noemamag.com/the-exploited-labor-behind-artificial-intelligence/">Original</a>
    <h1>The exploited labor behind artificial intelligence (2022)</h1>
    
    <div id="readability-page-1" class="page"><div role="article">

        <div role="group">
    <p>Credits</p>
    <p>Adrienne Williams and Milagros Miceli are researchers at the Distributed AI Research (DAIR) Institute. Timnit Gebru is the institute’s founder and executive director. She was previously co-lead of the Ethical AI research team at Google.</p>
</div>

<p>The public’s understanding of artificial intelligence (AI) is largely shaped by pop culture — by blockbuster movies like “The Terminator” and their doomsday scenarios of machines going rogue and destroying humanity. This kind of AI narrative is also what grabs the attention of news outlets: a Google engineer <a href="https://www.washingtonpost.com/technology/2022/06/11/google-ai-lamda-blake-lemoine/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">claiming</a> that its chatbot was sentient was among the most discussed AI-related news in recent months, even reaching <a href="https://www.youtube.com/watch?v=aERTSAFGEUM" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">Stephen Colbert</a>’s millions of viewers. But the idea of superintelligent machines with their own agency and decision-making power is not only far from reality — it distracts us from the real risks to human lives surrounding the development and deployment of AI systems. While the public is distracted by the specter of nonexistent sentient machines, an army of precarized workers stands behind the supposed accomplishments of artificial intelligence systems today.</p>



<p>Many of these systems are developed by multinational corporations located in Silicon Valley, which have been consolidating power at a scale that, journalist Gideon Lewis-Kraus<a href="https://www.nytimes.com/2016/12/14/magazine/the-great-ai-awakening.html" data-wpel-link="external" target="_blank" rel="external noopener noreferrer"><strong> </strong></a><a href="https://www.nytimes.com/2016/12/14/magazine/the-great-ai-awakening.html" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">notes</a>, is likely unprecedented in human history. They are striving to create autonomous systems that can one day perform all of the tasks that people can do and more, without the required salaries, benefits or other costs associated with employing humans. While this corporate executives’ utopia is far from reality, the march to attempt its realization has created a global underclass, performing what anthropologist Mary L. Gray and computational social scientist Siddharth Suri call <a href="https://marylgray.org/bio/on-demand/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">ghost work</a>: the downplayed human labor driving “AI”.</p>



<p>Tech companies that have branded themselves “AI first” depend on heavily surveilled gig workers like data labelers, delivery drivers and content moderators. Startups are even hiring people to <a href="https://journals.sagepub.com/doi/pdf/10.1177/2053951720919776" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">impersonate AI systems</a> like chatbots, due to the pressure by venture capitalists to incorporate so-called AI into their products. In fact, London-based venture capital firm MMC Ventures surveyed 2,830 AI startups in the EU and found that <a href="https://www.forbes.com/sites/parmyolson/2019/03/04/nearly-half-of-all-ai-startups-are-cashing-in-on-hype/?sh=7538b814d022" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">40% of them</a> didn’t use AI in a meaningful way.</p>



<p>Far from the sophisticated, sentient machines portrayed in media and pop culture, so-called AI systems are fueled by <a href="https://www.gigeconomydata.org/basics/how-many-gig-workers-are-there" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">millions</a> of underpaid workers around the world, performing repetitive tasks under precarious labor conditions. And unlike the “AI researchers” paid six-figure salaries in Silicon Valley corporations, these exploited workers are often recruited out of impoverished populations and paid as little as <a href="https://time.com/6147458/facebook-africa-content-moderation-employee-treatment/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">$1.46/hour</a> after tax. Yet despite this, labor exploitation is not central to the discourse surrounding the ethical development and deployment of AI systems. In this article, we give examples of the labor exploitation driving so-called AI systems and argue that supporting transnational worker organizing efforts should be a priority in discussions pertaining to AI ethics.</p>



<p>We write this as people intimately connected to AI-related work. Adrienne is a former Amazon delivery driver and organizer who has experienced the harms of surveillance and unrealistic quotas established by automated systems. Milagros is a researcher who has worked closely with data workers, especially data annotators in Syria, Bulgaria and Argentina. And Timnit is a researcher who has faced retaliation for uncovering and communicating the harms of AI systems.</p>



<h5 id="h-treating-workers-like-machines"><strong>Treating Workers Like Machines</strong></h5>



<p>Much of what is currently described as AI is a system based on statistical machine learning, and more specifically, deep learning via artificial neural networks, a methodology that requires enormous amounts of data to “learn” from. But around 15 years ago, before the proliferation of gig work, deep learning systems were considered merely an academic curiosity, confined to a few interested researchers.</p>



<p>In 2009, however, Jia Deng and his collaborators <a href="https://ieeexplore.ieee.org/abstract/document/5206848" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">released</a> the ImageNet dataset, the largest labeled image dataset at the time, consisting of images scraped from the internet and labeled through Amazon’s newly introduced <a href="https://www.economist.com/technology-quarterly/2006/06/10/artificial-artificial-intelligence?story_id=7001738" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">Mechanical Turk</a> platform. Amazon Mechanical Turk, with the motto “artificial artificial intelligence,” popularized the phenomenon of “crowd work”: large volumes of time-consuming work broken down into smaller tasks that can quickly be completed by millions of people around the world. With the introduction of Mechanical Turk, intractable tasks were suddenly made feasible; for example, hand-labeling one million images could be automatically executed by a thousand anonymous people working in parallel, each labeling only a thousand images. What’s more, it was at a price even a university could afford: crowdworkers were paid per task completed, which could amount to <a href="https://www.nytimes.com/interactive/2019/11/15/nyregion/amazon-mechanical-turk.html" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">merely a few cents</a>.</p>


<!-- Quote Block Template -->

<div>

  <div>

    <p>
      “So-called AI systems are fueled by millions of underpaid workers around the world, performing repetitive tasks under precarious labor conditions.”    </p>

    
    
  </div>
</div>




<p>The ImageNet dataset was followed by the <a href="https://www.image-net.org/challenges/LSVRC/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">ImageNet Large Scale Visual Recognition Challenge</a><strong>, </strong>where researchers used the dataset to train and test models performing a variety of tasks like image recognition: annotating an image with the type of object in the image, such as a tree or a cat. While non-deep-learning-based models performed these tasks with the highest accuracy at the time, in 2012, <a href="https://proceedings.neurips.cc/paper/2012/file/c399862d3b9d6b76c8436e924a68c45b-Paper.pdf" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">a deep-learning-based architecture</a> informally dubbed <a href="https://en.wikipedia.org/wiki/AlexNet" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">AlexNet</a> scored higher than all other models by a wide margin. This catapulted deep-learning-based models into the mainstream, and brought us to today, where models requiring lots of data, labeled by low-wage gig workers around the world, are proliferated by multinational corporations. In addition to labeling data scraped from the internet, some jobs have gig workers supply the data itself, requiring them to upload selfies, pictures of friends and family or images of the objects around them.</p>



<p>Unlike in 2009, when the main crowdworking platform was Amazon’s Mechanical Turk, there is currently <a href="https://www.grandviewresearch.com/industry-analysis/data-labeling-solution-services-market-report" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">an explosion</a> of data labeling companies. These companies are raising <a href="https://techcrunch.com/2022/05/18/2314708/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">tens</a> to <a href="https://www.crunchbase.com/organization/scale-2/company_financials" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">hundreds</a> of millions in venture capital funding while the data labelers have been estimated to make an average of <a href="https://www.cis.upenn.edu/~ccb/publications/data-driven-analysis-of-workers-earnings-on-amazon-mechanical-turk.pdf" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">$1.77 per task</a>. Data labeling interfaces have <a href="https://arxiv.org/abs/2205.11963" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">evolved</a> to treat crowdworkers like machines, often prescribing them highly repetitive tasks, surveilling their movements and punishing deviation through automated tools. Today, far from an academic challenge, large corporations claiming to be “AI first” are fueled by this army of underpaid gig workers, such as data laborers, content moderators, warehouse workers and delivery drivers.</p>



<p>Content moderators, for example, are responsible for finding and flagging content deemed inappropriate for a given platform. Not only are they essential workers, without whom social media platforms would be completely unusable, their work flagging different types of content is also used to train automated systems aiming to flag texts and imagery containing hate speech, fake news, violence or other types of content that violates platforms’ policies. In spite of the crucial role that content moderators play in both keeping online communities safe and training AI systems, they are often <a href="https://www.businessinsider.com/tiktoks-african-factory-line-of-terrors-2022-7" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">paid miserable wages</a> while working for tech giants and forced to perform traumatic tasks while being closely surveilled.</p>



<p>Every murder, suicide, sexual assault or child abuse video that does not make it onto a platform <a href="https://www.behindthescreen-book.com/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">has been </a><a href="https://www.behindthescreen-book.com/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">viewed and flagged</a> by a content moderator or an automated system trained by data most likely supplied by a content moderator. Employees performing these tasks <a href="https://www.theverge.com/2019/2/25/18229714/cognizant-facebook-content-moderator-interviews-trauma-working-conditions-arizona" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">suffer</a> from anxiety, depression and post-traumatic stress disorder due to constant exposure to this horrific content.</p>



<p>Besides experiencing a traumatic work environment with nonexistent or insufficient mental health support, these workers are monitored and punished if they deviate from their prescribed repetitive tasks. For instance, Sama content moderators contracted by Meta in Kenya are <a href="https://time.com/6147458/facebook-africa-content-moderation-employee-treatment/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">monitored</a> through surveillance software to ensure that they make decisions about violence in videos within 50 seconds, regardless of the length of the video or how disturbing it is. Some content moderators <a href="https://time.com/6147458/facebook-africa-content-moderation-employee-treatment/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">fear</a> that failure to do so could result in termination after a few violations. “Through its prioritization of speed and efficiency above all else,” Time Magazine <a href="https://time.com/6147458/facebook-africa-content-moderation-employee-treatment/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">reported</a>, “this policy might explain why videos containing hate speech and incitement to violence have remained on Facebook’s platform in Ethiopia.”</p>



<p>Similar to social media platforms which would not function without content moderators, e-commerce conglomerates like Amazon are run by armies of warehouse workers and delivery drivers, among others. Like content moderators, these workers both keep the platforms functional <em>and</em> supply data for AI systems that Amazon may one day use to replace them: robots that stock packages in warehouses and self-driving cars that deliver these packages to customers. In the meantime, these workers must <a href="https://www.businessinsider.in/tech/news/amazon-warehouse-workers-suffer-muscle-and-joint-injuries-at-a-rate-4-times-higher-than-industry-peers/articleshow/90404991.cms" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">perform repetitive tasks</a> under the pressure of constant surveillance — tasks that, at times, put their lives at risk and often <a href="https://thesoc.org/what-we-do/the-injury-machine-how-amazons-production-system-hurts-workers/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">result</a> in serious musculoskeletal injuries.</p>


<!-- Quote Block Template -->

<div>

  <div>

    <p>
      “Data labeling interfaces have evolved to treat crowdworkers like machines, often prescribing them highly repetitive tasks, surveilling their movements and punishing deviation through automated tools.”    </p>

    
    
  </div>
</div>




<p>Amazon warehouse employees are<a href="https://fortune.com/2022/05/24/amazon-warehouse-employee-annual-shareholders-meeting-investing-labor-movement-frontline-workers-daniel-olayiwola/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer"> </a><a href="https://fortune.com/2022/05/24/amazon-warehouse-employee-annual-shareholders-meeting-investing-labor-movement-frontline-workers-daniel-olayiwola/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">tracked</a> via cameras and their inventory scanners, and their performance is<a href="https://www.wsj.com/articles/the-way-amazon-uses-tech-to-squeeze-performance-out-of-workers-deserves-its-own-name-bezosism-11631332821" data-wpel-link="external" target="_blank" rel="external noopener noreferrer"> </a><a href="https://www.wsj.com/articles/the-way-amazon-uses-tech-to-squeeze-performance-out-of-workers-deserves-its-own-name-bezosism-11631332821" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">measured</a> against the times managers determine every task should take, based on aggregate data from everyone working at the same facility. Time away from their assigned tasks is tracked and<a href="https://www.vice.com/en/article/5dgn73/internal-documents-show-amazons-dystopian-system-for-tracking-workers-every-minute-of-their-shifts" data-wpel-link="external" target="_blank" rel="external noopener noreferrer"> </a><a href="https://www.vice.com/en/article/5dgn73/internal-documents-show-amazons-dystopian-system-for-tracking-workers-every-minute-of-their-shifts" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">used to discipline workers</a>.
          </p><p>
            Noema is hiring a senior editor who will work with us in LA or remotely. The salary range is $110,000 - $160,000, and candidates should have at least five years experience editing. Apply
            <a target="http://noemamag.com/careers" href="http://noemamag.com/careers" data-wpel-link="internal">here.</a>
            
          </p>
        



<p>Like warehouse workers, Amazon delivery drivers are also monitored through automated surveillance systems: an app called <em>Mentor</em> <a href="https://www.cnbc.com/2021/02/12/amazon-mentor-app-tracks-and-disciplines-delivery-drivers.html" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">tallies scores</a> based on so-called violations. Amazon’s unrealistic delivery time expectations push many drivers to <a href="https://www.vice.com/en/article/xgxx54/amazon-drivers-are-instructed-to-drive-recklessly-to-meet-delivery-quotas" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">take risky measures</a> to ensure that they deliver the number of packages assigned to them for the day. For instance, the time it takes someone to fasten and unfasten their seatbelt some 90-300 times a day is <a href="https://www.google.com/url?q=https://www.youtube.com/watch?v%3DiSDQeGxnXyY&amp;sa=D&amp;source=docs&amp;ust=1665510275758922&amp;usg=AOvVaw0gbYxsLIPFxQ12k7ydEht0" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">enough</a> to put them behind schedule on their route. Adrienne and many of her colleagues <a href="https://www.vice.com/en/article/5dg3wb/amazon-delivery-drivers-say-they-sacrifice-their-safety-to-meet-holiday-rush" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">buckled</a> their seat belts behind their backs, so that the surveillance systems registered that they were driving with a belt on, without getting slowed down by actually driving with a belt on.</p>



<p>In 2020, Amazon drivers in the U.S. were injured at a nearly <a href="https://www.cbsnews.com/news/amazon-injury-rate-highest-among-warehouses-worker-groups-allege/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">50% higher rate</a> than their United Parcel Service counterparts. In 2021, Amazon drivers were injured at a rate of <a href="https://thesoc.org/wp-content/uploads/2022/05/The-Worst-Mile.pdf" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">18.3 per 100 drivers</a>, up nearly 40% from the previous year. These conditions aren’t only dangerous for delivery drivers — <a href="https://www.cbsnews.com/losangeles/news/2-riverside-county-sheriffs-deputies-recovering-after-being-struck-by-delivery-van-2-pedestrians-killed/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">pedestrians</a> and <a href="https://www.nytimes.com/2019/09/05/us/amazon-delivery-drivers-accidents.html#:~:text=Among%20those%20killed%20in%20the%20Amazon%20delivery%20crashes,grandmother%20hit%20in%20front%20of%20an%20Outback%20Steakhouse." data-wpel-link="external" target="_blank" rel="external noopener noreferrer">car passengers</a> have been killed and <a href="https://www.businessinsider.com/amazon-van-crash-diver-surveillance-evidence-liability-lawsuit-2021-11" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">injured</a> in accidents involving Amazon delivery drivers. Some drivers in Japan recently <a href="https://finance.yahoo.com/news/amazon-ai-sending-delivery-drivers-081829474.html?guccounter=1&amp;guce_referrer=aHR0cHM6Ly93d3cuZ29vZ2xlLmNvbS8&amp;guce_referrer_sig=AQAAAAC9OTtaz3fnfS1cimfjt7lc8mWdzAE3KGPeU1uY1vOaAxHMRbyIzAqdVgVXmGZAFr5uzA8HH-HhfTdLRQQdH6vfjJdLfylxndo_vjhAtCcS5A3d-rYcMLZEBS7RvpyNzPobEknkD-ygTwB2bpgnLCGBXMEYQaU7wRg4CHeWaZ7O" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">quit in protest </a>because they say Amazon’s software sent them on “impossible routes,” leading to “unreasonable demands and long hours.” In spite of these clear harms, however, Amazon continues to treat its workers like machines.</p>



<p>In addition to tracking its workers through scanners and cameras, last year, the company required delivery drivers in the U.S. to sign a “<a href="https://www.vice.com/en/article/dy8n3j/amazon-delivery-drivers-forced-to-sign-biometric-consent-form-or-lose-job" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">biometric consent</a>” form, granting Amazon permission to use AI-powered cameras to monitor drivers’ movements — supposedly to cut down on distracted driving or speeding and ensure seatbelt usage. It’s only reasonable for workers to fear that facial recognition and other biometric data could be used to perfect worker-surveillance tools or further train AI — which could one day replace them. The vague wording in the consent <a href="https://amzl-dsp-bgc-docs.s3.amazonaws.com/Vehicle+Technology+and+Biometric+Consent.pdf" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">forms</a> leaves the precise purpose open for interpretation, and workers have <a href="https://pnw.ai/article/amazon-and-microsoft-claim-not-to-have-used-ai-training-data-they-re-being-sued-f/122729412" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">suspected</a> unwanted uses of their data before (though Amazon denied it).</p>



<p>The “AI” industry runs on the backs of these low-wage workers, who are kept in precarious positions, making it hard, in the absence of unionization, to push back on unethical practices or demand better working conditions for fear of losing jobs they can’t afford to lose. Companies make sure to hire people from poor and underserved communities, such as <a href="https://restofworld.org/2021/refugees-machine-learning-big-tech/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">refugees</a>, <a href="https://www.theverge.com/2019/3/28/18285572/prison-labor-finland-artificial-intelligence-data-tagging-vainu" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">incarcerated people</a> and <a href="https://srinstitute.utoronto.ca/news/the-data-production-dispositif" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">others with few job options</a>, often hiring them through third party firms as <a href="https://www.technologyreview.com/2022/04/20/1050392/ai-industry-appen-scale-data-labels/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">contractors</a> rather than as full time employees. While more employers should hire from vulnerable groups like these, it is unacceptable to do it in a predatory manner, with no protections.</p>


<!-- Quote Block Template -->

<div>

  <div>

    <p>
      “AI ethics researchers should analyze harmful AI systems as both causes and consequences of unjust labor conditions in the industry.”    </p>

    
    
  </div>
</div>




<p>Data labeling jobs are often performed far from the Silicon Valley headquarters of “AI first” multinational corporations — from <a href="https://www.technologyreview.com/2019/08/22/65375/venezuela-crisis-platform-work-trains-self-driving-car-ai-data/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">Venezuela</a>, where workers label data for the image recognition systems in self-driving vehicles, to <a href="https://dl.acm.org/doi/pdf/10.1145/3415186" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">Bulgaria</a>, where Syrian refugees fuel facial recognition systems with selfies labeled according to race, gender, and age categories. These tasks are often <a href="https://mitpress.mit.edu/9780262535892/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">outsourced</a> to precarious workers in countries like India, Kenya, the Philippines or Mexico. Workers often do not speak English but are provided instructions in English, and <a href="https://arxiv.org/abs/2205.11963" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">face termination</a> or banning from crowdwork platforms if they do not fully understand the rules.</p>



<p>These corporations know that increased worker power would slow down their march toward proliferating “AI” systems requiring vast amounts of data, deployed without adequately studying and mitigating their harms. Talk of sentient machines only distracts us from holding them accountable for the exploitative labor practices that power the “AI” industry.</p>



<h5><strong>An Urgent Priority For AI Ethics</strong></h5>



<p>While researchers in ethical AI, AI for social good, or human-centered AI have mostly focused on “debiasing” data and fostering transparency and model fairness, here we argue that stopping the exploitation of labor in the AI industry should be at the heart of such initiatives. If corporations are not allowed to exploit labor from Kenya to the U.S., for example, they will not be able to proliferate harmful technologies as quickly — their market calculations would simply dissuade them from doing so.</p>



<p>Thus, we advocate for funding of research and public initiatives that aim to uncover issues at the intersection of labor and AI systems. AI ethics researchers should analyze harmful AI systems as both causes and consequences of unjust labor conditions in the industry. Researchers and practitioners in AI should reflect on their use of crowdworkers to advance their own careers, while the crowdworkers remain in precarious conditions. Instead, the AI ethics community should work on initiatives that <a href="https://media.nature.com/original/magazine-assets/d41586-020-02003-2/d41586-020-02003-2.pdf" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">shift power</a> into the hands of workers. Examples include co-creating research agendas with workers based on their needs, supporting cross-geographical labor organizing efforts and ensuring that research findings are easily accessed by workers rather than confined to academic publications. The <a href="https://dl.acm.org/doi/abs/10.1145/2470654.2470742" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">Turkopticon platform </a>created by Lilly Irani and M. Six Silberman, “an activist system that allows workers to publicize and evaluate their relationships with employers,” is a great example of this.</p>



<p>Journalists, artists, and scientists can help by drawing clear the connection between labor exploitation and harmful AI products in our everyday lives, fostering solidarity with and support for gig workers and other vulnerable worker populations. Journalists and commentators can show the general public why they should care about the <a href="https://arxiv.org/abs/2207.04958" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">data annotator in Syria</a> or the hypersurveilled Amazon delivery driver in the U.S. Shame does work in certain circumstances and, for corporations, the public’s sentiment of “shame on you” can sometimes equal a <a href="https://variety.com/2022/digital/news/spotify-2-billion-market-cap-neil-young-joe-rogan-1235166798/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">loss in revenue</a> and help move the needle toward accountability.</p>



<p>Supporting transnational worker organizing should be at the center of the fight for “ethical AI.” While each workplace and geographical context has its own idiosyncrasies, knowing how workers in other locations circumvented similar issues can serve as inspiration for local organizing and unionizing efforts. For example, data labelers in Argentina could learn from the recent <a href="https://time.com/6175026/facebook-sama-kenya-lawsuit/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">unionizing efforts</a> of content moderators in Kenya, or Amazon Mechanical Turk workers <a href="https://blog.turkopticon.net/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">organizing</a> in the U.S., and vice versa. Furthermore, unionized workers in one geographic location can advocate for their more precarious counterparts in another, as in the case of the <a href="https://alphabetworkersunion.org/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">Alphabet Workers Union</a>, which includes both high paid employees in Silicon Valley and outsourced low wage contractors in more rural areas.</p>


<!-- Quote Block Template -->

<div>

  <div>

    <p>
      “This type of solidarity between highly-paid tech workers and their lower-paid counterparts — who vastly outnumber them — is a tech CEO’s nightmare.”    </p>

    
    
  </div>
</div>




<p>This type of solidarity between highly-paid tech workers and their lower-paid counterparts — who vastly outnumber them — is a tech CEO’s nightmare. While corporations often treat their low-income workers as disposable, they’re more hesitant to lose their high-income employees who can quickly snap up jobs with competitors. Thus, the high-paid employees are allowed a far longer leash when organizing, unionizing, and voicing their disappointment with company culture and policies. They can use this increased security to advocate <em>with</em> their lower-paid counterparts working at warehouses, delivering packages or labeling data. As a result, corporations seem to use every tool at their disposal to isolate these groups from each other.</p>



<p>Emily Cunningham and Maren Costa created the type of cross-worker solidarity that scares tech CEOs. Both women worked as user experience designers at Amazon’s Seattle headquarters cumulatively for 21 years. Along with other Amazon corporate workers, they co-founded the <a href="https://amazonemployees4climatejustice.medium.com/" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">Amazon Employees for Climate Justice (AECJ)</a>. In 2019, over 8,700 Amazon workers publicly signed their names to an open letter addressed to Jeff Bezos and the company’s board of directors demanding climate leadership and concrete steps the company needed to implement to be aligned with climate science and protect workers. Later that year, AECJ organized the first walkout of corporate workers in Amazon’s history. The group says over 3,000 Amazon workers walked out across the world in solidarity with a youth-led Global Climate Strike.</p>



<p>Amazon responded by announcing its <a href="https://www.theclimatepledge.com" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">Climate Pledge</a>, a commitment to achieve net-zero carbon by 2040 — 10 years ahead of the Paris Climate Agreement. Cunningham and Costa say they were both disciplined and <a href="https://www.cnbc.com/2020/01/02/amazon-threatens-to-fire-employees-who-speak-out-on-climate-change.html" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">threatened with termination</a> after the climate strike — but it wasn’t until AECJ organized actions to foster solidarity with low-wage workers that they were actually fired. Hours after another AECJ member sent out a calendar invite inviting corporate workers to listen to a panel of warehouse workers discussing the dire working conditions they were facing at the beginning of the pandemic, Amazon fired Costa and Cunningham. The National Labor Relations Board found their firings were <a href="https://www.nytimes.com/2021/04/05/technology/amazon-nlrb-activist-workers.html" data-wpel-link="external" target="_blank" rel="external noopener noreferrer">illegal</a>, and the company later settled with both women for undisclosed amounts. This case illustrates where executives’ fears lie: the unflinching solidarity of high-income employees who see low-income employees as their comrades.</p>



<p>In this light, we urge researchers and journalists to also center low-income workers’ contributions in running the engine of “AI” and to stop misleading the public with narratives of fully autonomous machines with human-like agency. These machines are built by armies of underpaid laborers around the world. With a clear understanding of the labor exploitation behind the current proliferation of harmful AI systems, the public can advocate for stronger labor protections and real consequences for entities who break them.</p>

          
        
      </div></div>
  </body>
</html>
