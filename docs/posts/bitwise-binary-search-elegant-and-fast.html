<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://orlp.net/blog/bitwise-binary-search/">Original</a>
    <h1>Bitwise Binary Search: Elegant and Fast</h1>
    
    <div id="readability-page-1" class="page"><article>

<time datetime="2023-05-16">2023-05-16</time>
<p>I recently read the article <a href="https://probablydance.com/2023/04/27/beautiful-branchless-binary-search/"><em>Beautiful Branchless Binary Search</em></a>
by Malte Skarupke. In it they discuss the merits of the following snippet of
C++ code implementing a <a href="https://en.wikipedia.org/wiki/Binary_search_algorithm">binary search</a>:</p>
<pre data-lang="cpp"><code data-lang="cpp"><span>template</span><span>&lt;</span><span>typename</span><span> It, </span><span>typename</span><span> T, </span><span>typename</span><span> Cmp&gt;
</span><span>It lower_bound_skarupke(It begin, It end, const T&amp; value, Cmp comp) {
</span><span>    size_t length = end - begin;
</span><span>    </span><span>if </span><span>(length == </span><span>0</span><span>) </span><span>return</span><span> end;
</span><span>
</span><span>    size_t step = bit_floor(length);
</span><span>    </span><span>if </span><span>(step != length &amp;&amp; comp(begin[step], value)) {
</span><span>        length -= step + </span><span>1</span><span>;
</span><span>        </span><span>if </span><span>(length == </span><span>0</span><span>) </span><span>return</span><span> end;
</span><span>        step = bit_ceil(length);
</span><span>        begin = end - step;
</span><span>    }
</span><span>
</span><span>    </span><span>for </span><span>(step /= </span><span>2</span><span>; step != </span><span>0</span><span>; step /= </span><span>2</span><span>) {
</span><span>        </span><span>if </span><span>(comp(begin[step], value)) begin += step;
</span><span>    }
</span><span>
</span><span>    </span><span>return</span><span> begin + comp(*begin, value);
</span><span>}
</span></code></pre>
<p>Frankly, while the ideas behind the algorithm are beautiful, I find the
implementation complex and hard to understand or prove correct. This is not
meant as a jab at Malte Skarupke, I find almost all binary search
implementations hard to understand or prove correct.</p>

<p>In this article I will provide an alternative implementation based on similar
ideas but with a very different <em>interpretation</em> that is (in my opinion)
incredibly elegant and clear to understand, at least as far as binary searches
go. The resulting implementation also saves a comparison in almost every case
and ends up quite a bit smaller.</p>
<h3 id="a-brief-history-lesson"><a href="#a-brief-history-lesson" aria-label="Anchor link for: a-brief-history-lesson">A brief history lesson</a></h3>
<p>Feel free to <a href="https://orlp.net/blog/bitwise-binary-search/#lower-bounds">skip</a> this section if you are not interested in history, but I had
to find out whose shoulders we are standing on. This is not only to give credit
where credit is due, but also to see if any useful details were lost in
translation.</p>
<p>Malte Skarupke says they learned about the above algorithm from
Alex Muscar in <a href="https://muscar.eu/shar-binary-search-meta.html">their blog post</a>.
Alex says they found the algorithm while reading <a href="https://en.wikipedia.org/wiki/Jon_Bentley_(computer_scientist)">Jon L. Bentley’s</a> book
<em>Writing Efficient Programs</em> (ISBN 0-13-970244-X). Jon Bentley writes:</p>
<blockquote>
<p>If we need more speed then we should consult Knuth’s [1973] definitive treatise on
searching. Section 6.2.1 discusses binary search, and Exercise 6.2.1-11 describes
an extremely efficient binary search program; […]</p>
</blockquote>
<p>I own the referenced book hardcopy, Donald Knuth’s <a href="https://en.wikipedia.org/wiki/The_Art_of_Computer_Programming">The Art of Computer Programming</a>
(also known as TAOCP), volume 3 Sorting and Searching. Exercise 6.2.1-11 is not
the correct exercise in my edition, but 12 and 13 are, which are exercises
referring to “Shar’s method”.</p>
<p>We have to scan chapter 6.2.1 to find the mentioned method. Finally, we find it
on page 416. First as context, Knuth uses the following notation for binary search:</p>
<blockquote>
<p><strong>Algorithm U</strong> (<em>Uniform binary search</em>). Given a table of records
$R_1, R_2, \dots, R_N$ whose keys are in increasing order $K_1 &lt; K_2 &lt; \cdots &lt; K_N$,
this algorithm searches for a given argument $K$. If $N$ is even, the
algorithm will sometimes refer to a dummy key $K_0$ that should be set to $-\infty$.
We assume that $N \geq 1$.</p>
</blockquote>
<p>Now we can finally see Shar’s method:</p>
<blockquote>
<p>Another modification of binary search, suggested in 1971 by L. E. Shar,
will be still faster on some computers, because it is uniform after the first
step, and it requires no table.
The first step is to compare $K$ with $K_i$, where $i = 2^k$, $k = \lfloor \lg N\rfloor$.
If $K$ &lt; $K_i$, we use a uniform search with the $\delta$‘s equal to $2^{k-1},
2^{k-2}, \dots, 1, 0$. On the other hand, if $K &gt; K_i$ we reset $i$ to $i’ = N + 1 - 2^l$
where $l = \lceil\lg(N - 2^k + 1)\rceil$, and pretend that the first
comparison was actually $K &gt; K_{i’},$ using a uniform search with the
$\delta$’s equal to $2^{l-1}, 2^{l-2}, \dots, 1, 0$.</p>
</blockquote>
<p>The $\delta$’s the first paragraph refers to can be understood as the ‘step’
variable in the above C++ code. Overall Skarupke’s C++ code seems a fairly
faithful implementation of Shar’s method as described by Knuth, except that
Knuth uses one-based indexing which Skarupke’s method does not take into account.
Knuth goes on to describe that Shar’s method never makes more than $\lfloor \lg
N \rfloor + 1$ comparisons, which is one more than the minimum possible number
of comparisons.</p>

<p>To finish the history lesson, I did look on Google Scholar, but I could not find a 1971 paper by L. E. Shar.
I assume the modification was described in private communication with Knuth.</p>
<h2 id="lower-bounds"><a href="#lower-bounds" aria-label="Anchor link for: lower-bounds">Lower bounds</a></h2>
<p>Let us assume that we have a zero-indexed array $A$ of length $n$ that is in
ascending order: $A[0] \leq A[1] \leq \cdots \leq A[n-1]$. We want to find the
<em>lower bound</em> of some element $x$ in this array. This is the leftmost position
we could insert $x$ into the array while keeping it sorted. Alternatively
phrased, this is the number of elements strictly less than $x$ in the array.</p>
<p>A traditional binary search algorithm finds this number by keeping a range of
possible solutions, repeatedly cutting that range in two pieces and
selecting the only piece which contains the solution. This tends to be tricky
to get right, as you must avoid overflows while computing the midpoint, and
are dealing with multiple boundary conditions, both in your code as well as
in your correctness invariant.</p>
<p>Before we begin with our solution that avoids this, we have to take a moment and
understand an important aspect of binary search. With each comparison we can
distinguish between two sets of outcomes. Thus with $k$ comparisons, we can
distinguish between $2^k$ total outcomes. However, for $n$ elements, there are
$n+1$ outcomes! For example, for an array of 7 elements there are 8 positions in
which $x$ could be sorted: <img src="https://orlp.net/blog/bitwise-binary-search/full-binary-tree-7.png" alt="A full binary search tree of size 7."/></p>
<p>Thus the natural array size for binary search is $2^k - 1$, and
not $2^k$.</p>
<h2 id="a-bitwise-approach"><a href="#a-bitwise-approach" aria-label="Anchor link for: a-bitwise-approach">A bitwise approach</a></h2>
<p>Let’s take a look at the sixteen possible 4-bit integers in binary:</p>
<pre><code><span> 0 = 0000      8 = 1000 
</span><span> 1 = 0001      9 = 1001 
</span><span> 2 = 0010     10 = 1010 
</span><span> 3 = 0011     11 = 1011 
</span><span> 4 = 0100     12 = 1100 
</span><span> 5 = 0101     13 = 1101 
</span><span> 6 = 0110     14 = 1110 
</span><span> 7 = 0111     15 = 1111 
</span></code></pre>
<p>Notice how if the top bit of the integer is set, it remains set for all larger
integers. And within each group with the same top bit, when the second most
significant bit is set, it remains set for larger integers within that group.
And so on for the third bit within each group with the same top two bits, ad
infinitum. <strong>In binary, within each group with identical top $t$ bits set, the
value of the $t+1$th bit is monotonically increasing.</strong></p>
<p>Since our desired solution is the number of elements strictly less than $x,$
we can rephrase it as finding the largest number $b$ such that ${A[b-1] &lt; x},$
or $b = 0$ if no elements are less than $x$.
We can find the unique $b$ very efficiently by constructing it <strong>directly</strong>, bit-by-bit,
using the above observation.</p>
<p>Let’s assume that $A$ has length $n = 2^k - 1$. Then any possible answer $b$
fits exactly in $k$ bits. Since $A$ is sorted, if we find that $A[i-1] &lt; x$, we
know that ${b \geq i}$. Conversely, if that comparison fails, we know that ${b &lt;
i}.$ Thus, using the above observation we can figure out if the top bit of $b$
is set simply by testing $A[i-1] &lt; x$ with $i = 2^{k-1}$.</p>
<p>Now we know what the top bit should be and set it accordingly, never changing it
again. Using the above observation, this time within the group of
integers with a given top bit, we know that if we set the second bit and find
that $A[i-1] &lt; x$ still holds, that the second bit must be set, and if not it
must be zero. We repeat this process bit-by-bit until we have figured out all
bits of $b$, giving our answer!</p>
<p>Perhaps you are like me, and you are a visual thinker. Let us flip our
earlier tree on its side and visually associate associate a binary $b$
value with each gap between the elements of our array:</p>
<p><img src="https://orlp.net/blog/bitwise-binary-search/binary-gap-indices.png" alt="A full binary search tree of size 7 with binary indices for the gaps between them."/></p>
<p>The small red arrows indicate which element $A[b-1] &lt; x$ would test
for a given guess of $b$. Note that no element is associated with $b = 0$,
as we can only end up with this value if all other tests failed, and thus
we never have to test this value. A search for $5$ would end up testing
${b = {\color{red}1}00_2}$ (success, set bit), ${b = 1{\color{red}1}0_2}$ (fail, do not set bit) and ${b = 10{\color{red}1}_2}$ (success, set bit).</p>

<p>In C++ we would get the following:</p>
<pre data-lang="cpp"><code data-lang="cpp"><span>// Only works for n = 2^k - 1.
</span><span>template</span><span>&lt;</span><span>typename</span><span> It, </span><span>typename</span><span> T, </span><span>typename</span><span> Cmp&gt;
</span><span>It lower_bound_2k1(It begin, It end, const T&amp; value, Cmp comp) {
</span><span>    size_t two_k = (end - begin) + </span><span>1</span><span>;
</span><span>    size_t b = </span><span>0</span><span>;
</span><span>    </span><span>for </span><span>(size_t bit = two_k &gt;&gt; </span><span>1</span><span>; bit != </span><span>0</span><span>; bit &gt;&gt;= </span><span>1</span><span>) {
</span><span>        </span><span>if </span><span>(comp(begin[(b | bit) - </span><span>1</span><span>], value)) b |= bit;
</span><span>    }
</span><span>    </span><span>return</span><span> begin + b;
</span><span>}
</span></code></pre>
<p>Note that we always do exactly $k$ comparisons, which is optimal.</p>
<h2 id="generalizing-to-other-sizes"><a href="#generalizing-to-other-sizes" aria-label="Anchor link for: generalizing-to-other-sizes">Generalizing to other sizes</a></h2>
<p>However, there is a glaring issue: our original array might not have length
$2^k - 1$. The simplest way to solve this is to add elements with value
$\infty$ to the end, to pad the array out to $2^k - 1$ elements. 
Instead of physically adding $\infty$ elements the array, we can simply
check if the index lies in the original array, and if not skip our test
entirely, as it would fail (we’d be testing if $\infty &lt; x$).</p>
<p>To pad our array out we want to find the smallest integer $k$ such that $2^k - 1 \geq n$,
which means $k \geq \log_2(n + 1)$, which after rounding up gives
$$k = \lceil \log_2(n + 1) \rceil = \lfloor \log_2(n) \rfloor + 1.$$</p>
<p>Alternatively and definitely more enlightening is that this can be understood as
initializing <code>bit</code> in our loop to the highest set bit in $n$:</p>
<pre data-lang="cpp"><code data-lang="cpp"><span>template</span><span>&lt;</span><span>typename</span><span> It, </span><span>typename</span><span> T, </span><span>typename</span><span> Cmp&gt;
</span><span>It lower_bound_pad(It begin, It end, const T&amp; value, Cmp comp) {
</span><span>    size_t n = end - begin;
</span><span>    size_t b = </span><span>0</span><span>;
</span><span>    </span><span>for </span><span>(size_t bit = std::bit_floor(n); bit != </span><span>0</span><span>; bit &gt;&gt;= </span><span>1</span><span>) {
</span><span>        size_t i = (b | bit) - </span><span>1</span><span>;
</span><span>        </span><span>if </span><span>(i &lt; n &amp;&amp; comp(begin[i], value)) b |= bit;
</span><span>    }
</span><span>    </span><span>return</span><span> begin + b;
</span><span>}
</span></code></pre>
<p>In my opinion this is the most elegant binary search implementation there is.</p>
<hr/>
<h2 id="making-it-branchless"><a href="#making-it-branchless" aria-label="Anchor link for: making-it-branchless">Making it branchless</a></h2>
<p>The above works well, but introduces an index check before each array access.
This means the compiler can not eliminate the
<a href="https://en.wikipedia.org/wiki/Branch_(computer_science)">branch</a> here, lest we
access out-of-bounds memory.</p>
<p>To solve this problem we use a similar trick as L. E. Shar: we do an initial
comparison with the middle element, then either look at $2^k - 1$ elements at
the start, or $2^k - 1$ elements at the end of the array. If the array size
itself isn’t of the form $2^k - 1$, these two subslices overlap in the middle.
To completely cover our array (together with the element we initially compare
with) we must have $$(2^k - 1) + (2^k - 1) + 1 = 2^{k+1} - 1 \geq n$$ and thus
we choose $k = \lceil \log_2(n + 1) - 1 \rceil = \lfloor \log_2 (n) \rfloor$ :</p>
<pre data-lang="cpp"><code data-lang="cpp"><span>template</span><span>&lt;</span><span>typename</span><span> It, </span><span>typename</span><span> T, </span><span>typename</span><span> Cmp&gt;
</span><span>It lower_bound_overlap(It begin, It end, const T&amp; value, Cmp comp) {
</span><span>    size_t n = end - begin;
</span><span>    </span><span>if </span><span>(n == </span><span>0</span><span>) </span><span>return</span><span> begin;
</span><span>
</span><span>    size_t two_k = std::bit_floor(n);
</span><span>    </span><span>if </span><span>(comp(begin[n / </span><span>2</span><span>], value)) begin = end - (two_k - </span><span>1</span><span>);
</span><span>    
</span><span>    size_t b = </span><span>0</span><span>;
</span><span>    </span><span>for </span><span>(size_t bit = two_k &gt;&gt; </span><span>1</span><span>; bit != </span><span>0</span><span>; bit &gt;&gt;= </span><span>1</span><span>) {
</span><span>        </span><span>if </span><span>(comp(begin[(b | bit) - </span><span>1</span><span>], value)) b |= bit;
</span><span>    }
</span><span>    </span><span>return</span><span> begin + b;
</span><span>}
</span></code></pre>
<h3 id="improving-the-efficiency"><a href="#improving-the-efficiency" aria-label="Anchor link for: improving-the-efficiency">Improving the efficiency</a></h3>
<p>If our array doesn’t have size $2^{k+1} - 1$, the subarrays overlap in the
middle. This means that part of the subarrays already eliminated by the initial
comparison $A[n / 2] &lt; x$ are being unnecessarily searched. Can we improve on
this?</p>
<p>We can, if we choose two different sizes $2^l - 1$ and $2^r - 1$ for when
we are respectively searching at the start (left) or end (right) of the array.
Again, in combination with the initial element we compare with (which is now
$A[2^l - 1] &lt; x$) we find that we must have</p>
<p>$$(2^l - 1) + (2^r - 1) + 1 = 2^l + 2^r - 1 \geq n$$</p>
<p>to be able to handle an arbitrary size $n$. And of course, we must have
$2^l - 1 \leq n$ and $2^r - 1 \leq n$ for our subarrays to fit. Let’s find the
optimal choice for $l, r$—which is not trivial.</p>
<h4 id="cost-analysis"><a href="#cost-analysis" aria-label="Anchor link for: cost-analysis">Cost analysis</a></h4>
<p>What is the cost of a certain choice of $l, r$, assuming a uniform distribution
over the $n + 1$ possible outcomes of the binary search? We know that after
the initial comparison, for $2^l$ of those outcomes we use $l$ comparisons,
and thus the rest must use $r$ comparisons for an expected cost of</p>
<p>$$C = 1 + \frac{2^l}{n + 1}\cdot l + \frac{n + 1 - 2^l}{n + 1}\cdot r$$</p>
<p>We only really care about minimizing this cost, so we can throw out the additional
constant $+1$ and the factor $1/(n+1)$ as it does not change the relative order:</p>
<p>$$C’ = 2^l\cdot l + (n + 1 - 2^l)\cdot r$$</p>
<h4 id="optimizing-r"><a href="#optimizing-r" aria-label="Anchor link for: optimizing-r">Optimizing $r$</a></h4>
<p>Compare cost $C’$ to the expression $2^l \cdot l + 2^{r}\cdot r$. In this case
the expression is entirely symmetrical, so we could freely swap $l$ and $r$. But
we know from our earlier array size inequality that $n + 1 - 2^l \leq 2^{r}$.
Thus we can conclude that $l$ has a greater weight in the cost than $r$ and
therefore we can safely assume that $l \leq r$ is minimal.</p>
<p>From this plus the fact that $2^l + 2^{r} - 1 \geq n$
we can immediately deduce that $2^{r} \geq (n + 1) / 2$ by weakening the
inequality with $2^l \to 2^r$, and thus rounding up to the nearest integer gives
\begin{align*}
r &amp;= \lceil\log_2(n+1) - 1\rceil = \lfloor\log_2(n)\rfloor
\end{align*}</p>
<p>Note that we can’t choose $r$ any larger, nor smaller, and thus we’ve
determined the optimal value for $r$.</p>

<h4 id="optimizing-l"><a href="#optimizing-l" aria-label="Anchor link for: optimizing-l">Optimizing $l$</a></h4>
<p>Let’s reorder our relative cost $C’$ a bit:</p>
<p>$$C’ = 2^l\cdot (l - r) + (n + 1)\cdot r$$</p>
<p>We can ignore the second term as a constant, as we’re now trying to optimize $l$
given the optimal $r$. The function</p>
<p>$$f(l) = 2^x(l - r)$$
has derivative w.r.t. $l$
$$f’(l) = 2^l(\ln(2)(l - r) + 1)$$
with a single zero corresponding to the global minimum at $r - \frac{1}{\ln(2)} \approx r - 1.4427$.
Let’s plug in the two integers closest to this minimum in $f$:</p>
<p>$$f(r - 1) = 2^{r - 1}(r - 1 - r) = - 2^{r-1}$$
$$f(r - 2) = 2^{r - 2}(r - 2 - r) = - 2^{r-1}$$</p>
<p>Thus we find that both $l = r - 1$ or $l = r - 2$ have optimal cost. For
simplicity we can just limit ourselves to $l = r - 1$ as it is equal but easier
to satisfy $2^l + 2^r - 1 \geq n$ with. Speaking of that inequality,
we can’t always choose $l = r - 1$ as we are sometimes forced to choose $l = r$
by it.</p>
<h3 id="putting-it-together"><a href="#putting-it-together" aria-label="Anchor link for: putting-it-together">Putting it together</a></h3>
<p>We found that $r = \lfloor \log2(n) \rfloor$, and that</p>
<p>$$l = \begin{cases}
r-1&amp;\text{if }2^r + 2^{r-1} - 1 \geq n\\
r&amp;\text{otherwise}
\end{cases}.$$</p>

<p>The condition $2^r + 2^{r-1} - 1 \geq n$ can be seen to be equivalent to “the
$r-1$th bit of $n$ is not set”. And as $2^r - 2^{r-1} = 2^{r-1}$ we can isolate
that bit, negate it, and subtract it from <code>two_r</code> to get our <code>two_l</code>:</p>
<pre data-lang="cpp"><code data-lang="cpp"><span>template</span><span>&lt;</span><span>typename</span><span> It, </span><span>typename</span><span> T, </span><span>typename</span><span> Cmp&gt;
</span><span>It lower_bound_opt(It begin, It end, const T&amp; value, Cmp comp) {
</span><span>    size_t n = end - begin;
</span><span>    </span><span>if </span><span>(n == </span><span>0</span><span>) </span><span>return</span><span> begin;
</span><span>
</span><span>    size_t two_r = std::bit_floor(n);
</span><span>    size_t two_l = two_r - ((two_r &gt;&gt; </span><span>1</span><span>) &amp; ~n);
</span><span>    </span><span>bool</span><span> use_r = comp(begin[two_l - </span><span>1</span><span>], value);
</span><span>    size_t two_k = use_r ? two_r : two_l;
</span><span>    begin = use_r ? end - (two_r - </span><span>1</span><span>) : begin;
</span><span>
</span><span>    size_t b = </span><span>0</span><span>;
</span><span>    </span><span>for </span><span>(size_t bit = two_k &gt;&gt; </span><span>1</span><span>; bit != </span><span>0</span><span>; bit &gt;&gt;= </span><span>1</span><span>) {
</span><span>        </span><span>if </span><span>(comp(begin[(b | bit) - </span><span>1</span><span>], value)) b |= bit;
</span><span>    }
</span><span>    </span><span>return</span><span> begin + b;
</span><span>}
</span></code></pre>
<p>The somewhat odd use of ternary statements and <code>use_r</code> is to convince the
compiler to generate branchless code. We certainly lost some of the elegance we
had before, but at least now we do the minimal number of comparisons we can do
with our bitwise binary search while being branchless. And it is in fact better
than than L. E. Shar’s original method, whose initial comparison $A[i - 1] &lt; x$
uses $i = \left\lfloor \log_2 (n) \right\rfloor$, which is suboptimal as we’ve
seen.</p>
<h2 id="micro-optimizations"><a href="#micro-optimizations" aria-label="Anchor link for: micro-optimizations">Micro-optimizations</a></h2>
<p>For some reason the standard implementation of
<a href="https://en.cppreference.com/w/cpp/numeric/bit_floor"><code>std::bit_floor</code></a>… sucks
a bit. E.g. on <a href="https://gcc.godbolt.org/z/4dsK1Tanj">x86-64 Clang 16.0</a> with
<code>-O2</code> we compile this:</p>
<pre data-lang="cpp"><code data-lang="cpp"><span>size_t bit_floor(size_t n) {
</span><span>    </span><span>if </span><span>(n == </span><span>0</span><span>) </span><span>return </span><span>0</span><span>;
</span><span>    </span><span>return </span><span>std::bit_floor(n);
</span><span>}
</span><span>
</span><span>size_t bit_floor_manual(size_t n) {
</span><span>    </span><span>if </span><span>(n == </span><span>0</span><span>) </span><span>return </span><span>0</span><span>;
</span><span>    </span><span>return </span><span>size_t(</span><span>1</span><span>) &lt;&lt; (std::bit_width(n) - </span><span>1</span><span>);
</span><span>}
</span></code></pre>
<p>to this:</p>
<pre data-lang="asm"><code data-lang="asm"><span>bit_floor(unsigned long):
</span><span>        </span><span>test    </span><span>rdi, rdi
</span><span>        </span><span>je      </span><span>.LBB0_1
</span><span>        </span><span>shr     </span><span>rdi
</span><span>        </span><span>je      </span><span>.LBB0_3
</span><span>        </span><span>bsr     </span><span>rcx, rdi
</span><span>        </span><span>xor     </span><span>rcx, </span><span>63
</span><span>        </span><span>jmp     </span><span>.LBB0_5
</span><span>.LBB0_1:
</span><span>        </span><span>xor     </span><span>eax, eax
</span><span>        </span><span>ret
</span><span>.LBB0_3:
</span><span>        </span><span>mov     </span><span>ecx, </span><span>64
</span><span>.LBB0_5:
</span><span>        </span><span>neg     </span><span>cl
</span><span>        </span><span>mov     </span><span>eax, </span><span>1
</span><span>        </span><span>shl     </span><span>rax, cl
</span><span>        </span><span>ret
</span><span>
</span><span>bit_floor_manual(unsigned long):
</span><span>        </span><span>bsr     </span><span>rcx, rdi
</span><span>        </span><span>mov     </span><span>eax, </span><span>1
</span><span>        </span><span>shl     </span><span>rax, cl
</span><span>        </span><span>test    </span><span>rdi, rdi
</span><span>        </span><span>cmove   </span><span>rax, rdi
</span><span>        </span><span>ret
</span></code></pre>
<p>Yikes. Manual computation it is!</p>
<h3 id="optimizing-the-tight-loop"><a href="#optimizing-the-tight-loop" aria-label="Anchor link for: optimizing-the-tight-loop">Optimizing the tight loop</a></h3>
<p>The astute observer might have noticed that in the following loop, we only
ever set each bit in <code>b</code> at most once:</p>
<pre data-lang="cpp"><code data-lang="cpp"><span>size_t b = </span><span>0</span><span>;
</span><span>for </span><span>(size_t bit = two_k &gt;&gt; </span><span>1</span><span>; bit != </span><span>0</span><span>; bit &gt;&gt;= </span><span>1</span><span>) {
</span><span>    </span><span>if </span><span>(comp(begin[(b | bit) - </span><span>1</span><span>], value)) b |= bit;
</span><span>}
</span><span>return</span><span> begin + b;
</span></code></pre>
<p>This means we could change the binary OR to simple addition, which might
optimize better in pointer calculations.</p>

<p>For the bitwise version we see the following tight loop for the above,
in <code>x86-64</code> with GCC:</p>
<pre data-lang="asm"><code data-lang="asm"><span>.L7:
</span><span>        </span><span>mov     </span><span>rsi, rdx
</span><span>        </span><span>or      </span><span>rsi, rcx
</span><span>        </span><span>cmp     </span><span>DWORD PTR [rax-</span><span>4</span><span>+rsi*</span><span>4</span><span>], r8d
</span><span>        </span><span>cmovb   </span><span>rcx, rsi
</span><span>        </span><span>shr     </span><span>rdx
</span><span>        </span><span>jne     </span><span>.L7
</span></code></pre>
<p>With addition we see the following:</p>
<pre data-lang="asm"><code data-lang="asm"><span>.L7:
</span><span>        </span><span>lea     </span><span>rsi, [rdx+rcx]
</span><span>        </span><span>cmp     </span><span>DWORD PTR [rax-</span><span>4</span><span>+rsi*</span><span>4</span><span>], r8d
</span><span>        </span><span>cmovb   </span><span>rcx, rsi
</span><span>        </span><span>shr     </span><span>rdx
</span><span>        </span><span>jne     </span><span>.L7
</span></code></pre>
<p>In fact, when using addition we could eliminate variable $b$ entirely,
and directly add to <code>begin</code> (similar to Skarupke’s original version that sparked
this article):</p>
<pre data-lang="cpp"><code data-lang="cpp"><span>for </span><span>(size_t bit = two_k &gt;&gt; </span><span>1</span><span>; bit != </span><span>0</span><span>; bit &gt;&gt;= </span><span>1</span><span>) {
</span><span>    </span><span>if </span><span>(comp(begin[bit - </span><span>1</span><span>], value)) begin += bit;
</span><span>}
</span><span>return</span><span> begin;
</span></code></pre>
<p>However, I’ve found that some compilers, e.g. GCC on x86-64 will refuse to make
this variant branchless. I hate how fickle compilers can be sometimes, and I
wish compilers exposed not just the
<a href="https://en.cppreference.com/w/cpp/language/attributes/likely"><code>likely</code>/<code>unlikely</code></a>
attributes, but also an attribute that allows you to mark something as <code>unpredictable</code>
to nudge the compiler towards using branchless techniques like CMOV’s.</p>
<p>Instead of eliminating <code>b</code>, we can optimize the loop to only do a single addition
explicitly, by moving the <code>-1</code> into the value of <code>b</code> itself:</p>
<pre data-lang="cpp"><code data-lang="cpp"><span>size_t b = -</span><span>1</span><span>;
</span><span>for </span><span>(size_t bit = two_k &gt;&gt; </span><span>1</span><span>; bit != </span><span>0</span><span>; bit &gt;&gt;= </span><span>1</span><span>) {
</span><span>    </span><span>if </span><span>(comp(begin[b + bit], value)) b += bit;
</span><span>}
</span><span>return</span><span> begin + (b + </span><span>1</span><span>);
</span></code></pre>
<p>Yay for two’s complement and integer overflow! This generated the best code on
all platforms I’ve looked at, so I applied this pattern to all my
implementations in the benchmark.</p>

<h2 id="results"><a href="#results" aria-label="Anchor link for: results">Results</a></h2>
<p>Let’s compare all the variants we’ve made, both in comparisons and actual
runtime. The latter I will test on my Apple M1 2021 Macbook Pro which is an ARM
machine. Your mileage <strong>will</strong> vary on different machines, especially x86-64
machines, but I want this article to focus more on the algorithmic side of
things rather than become an extensive study on the exact characteristics of
branch mispredictions, cache misses, and how to get the compiler to generate
branchless code for a variety of platforms.</p>
<p>The code for the below benchmark is available on <a href="https://github.com/orlp/bitwise-binary-search/">my Github</a>.</p>
<h3 id="comparisons"><a href="#comparisons" aria-label="Anchor link for: comparisons">Comparisons</a></h3>
<p>To test the average number of comparisons for size $n$ we can simply query for
each of the $n + 1$ outcomes how many comparisons it takes to get that outcome.
We then average over all these for a given $n$. The result is the following
graph:</p>
<p><img src="https://orlp.net/blog/bitwise-binary-search/comparisons.svg" alt="Comparison count graph."/></p>
<p>We see that <code>lower_bound_opt</code> does in fact do the fewest comparisons of
all the branchless methods, following the optimal <code>lower_bound_std</code>
more closely than <code>lower_bound_pad</code> or <code>lower_bound_skarupke</code>.</p>
<p>Across all sizes less than 256 we see the following average comparison counts,
minus the optimal comparison count:</p>
<table><thead><tr><th>Algorithm</th><th>Comparisons above optimal</th></tr></thead><tbody>
<tr><td><code>lower_bound_skarupke</code></td><td>1.17835</td></tr>
<tr><td><code>lower_bound_overlap</code></td><td>0.37250</td></tr>
<tr><td><code>lower_bound_pad</code></td><td>0.17668</td></tr>
<tr><td><code>lower_bound_opt</code></td><td>0.17238</td></tr>
<tr><td><code>lower_bound_std</code></td><td>0.00000</td></tr>
</tbody></table>
<p>All our hard work finding the optimal split into subarrays only saved us ~0.2
comparisons on average on <code>lower_bound_opt</code> versus the much simpler
<code>lower_bound_overlap</code>.</p>
<h3 id="runtime-32-bit-integers"><a href="#runtime-32-bit-integers" aria-label="Anchor link for: runtime-32-bit-integers">Runtime (32-bit integers)</a></h3>
<p>To benchmark runtime for a certain size $n$ I pre-generated one million random
integers in the range $[0, n + 1]$. Then I record the time it takes to look them
all up using our lower bound routine of interest, and calculate the average. As
I’ve found that eliminating <code>b</code> in our tight loop as mentioned above can either
gain or hurt performance depending on the compiler / architecture, so I have
benchmarked both variants.</p>

<p>Using clang 13.0.0 with <code>g++ -O2 -std=c++20</code> we get the following:</p>
<p><img src="https://orlp.net/blog/bitwise-binary-search/runtime.svg" alt="Performance graph."/></p>
<p>I think this graph gives a fascinating insight into the branch predictor on the
Apple M1. Most striking is the relatively poor performance of <code>lower_bound_opt</code>.
Within each bracket of sizes $[2^k, 2^{k+1})$ it performs much worse
than <code>lower_bound_overlap</code>, with a size-dependent slope, before suddenly dropping to a
consistently good performance.</p>
<p>This puzzled me for a while, and I triple-checked to see that <code>lower_bound_opt</code>
was really being compiled with branchless instructions. Only then did I realize
there was a hidden branch all along: the loop exit condition.
<code>lower_bound_overlap</code> always performs the same number of loop iterations,
allowing the CPU to always correctly predict the loop exit, whereas
<code>lower_bound_opt</code> tries to reduce the number of iterations it does to save
comparisons. It turns out that for integers the cost of an extra iteration is
much lower than risking a mispredict on the loop condition on the Apple M1.</p>
<p>If we also look at larger inputs we see that the above pattern keeps up
for quite a while until we start hitting sizes where cache effects become
a factor:</p>
<p><img src="https://orlp.net/blog/bitwise-binary-search/runtime-large.svg" alt="Larger performance graph."/></p>
<p>We also note that it truly is important for a binary search benchmark to look at
a variety of sizes, as you might reach rather different conclusions in
performance at $n = 2^{12}$ versus $n = 2^{12} \cdot 1.5$.</p>

<p>A commonly heard advice is to not use binary search for small arrays, but to
use a linear search instead. I find that not to be true on the Apple M1 for integers,
at least compared to my branchless binary search, when searching a runtime-sized
but otherwise fixed size array:</p>
<p><img src="https://orlp.net/blog/bitwise-binary-search/runtime-small.svg" alt="Smaller performance graph with linear search."/></p>
<p>Note that a linear search must always incur at least one branch misprediction:
on the loop exit condition. For a fixed size array <code>lower_bound_overlap</code> has
zero branch mispredictions, including the loop exit.</p>
<h3 id="runtime-strings"><a href="#runtime-strings" aria-label="Anchor link for: runtime-strings">Runtime (strings)</a></h3>
<p>To benchmark the performance on strings I copied the above benchmark, except
that I convert all integers to strings, zero-padded to a length of four.
I also reduced the number of samples to 300,000 per size, as the string
benchmark was significantly slower.</p>
<p>Using clang 13.0.0 with <code>g++ -O2 -std=c++20</code> we get the following:</p>
<p><img src="https://orlp.net/blog/bitwise-binary-search/runtime-str-large.svg" alt="Large performance graph for strings."/></p>
<p>Strings are a lot less interesting than integers in this case, as most of the
branchless optimizations are moot. We find that initially the branchless
versions are only slightly slower than <code>std::lower_bound</code> due to the extra
comparisons needed. However once we get to the larger-than-cache sizes
<code>std::lower_bound</code> becomes significantly better as it can do speculative loads
to reduce cache misses.</p>
<p><img src="https://orlp.net/blog/bitwise-binary-search/runtime-str-small.svg" alt="Smaller performance graph with linear search for strings."/></p>
<p>It seems that for strings the advice to use linear searches for small input
arrays doesn’t help that much, but doesn’t hurt either for $n \leq 9$,
on the Apple M1.</p>
<h2 id="conclusion"><a href="#conclusion" aria-label="Anchor link for: conclusion">Conclusion</a></h2>
<p>In my opinion the bitwise binary search is an elegant alternative to the
traditional binary search method, at the cost of ~0.17 to ~0.37 extra comparisons
on average. It can be implemented in a branchless manner, which can be
significantly faster when searching elements with a branchless comparison
operator.</p>
<p>In this article we found the following implementation to perform the best
on Apple M1 after all micro-optimizations are applied:</p>
<pre data-lang="cpp"><code data-lang="cpp"><span>template</span><span>&lt;</span><span>typename</span><span> It, </span><span>typename</span><span> T, </span><span>typename</span><span> Cmp&gt;
</span><span>It lower_bound(It begin, It end, const T&amp; value, Cmp comp) {
</span><span>    size_t n = end - begin;
</span><span>    </span><span>if </span><span>(n == </span><span>0</span><span>) </span><span>return</span><span> begin;
</span><span>
</span><span>    size_t two_k = size_t(</span><span>1</span><span>) &lt;&lt; (std::bit_width(n) - </span><span>1</span><span>);
</span><span>    size_t b = comp(begin[n / </span><span>2</span><span>], value) ? n - two_k : -</span><span>1</span><span>;
</span><span>    </span><span>for </span><span>(size_t bit = two_k &gt;&gt; </span><span>1</span><span>; bit != </span><span>0</span><span>; bit &gt;&gt;= </span><span>1</span><span>) {
</span><span>        </span><span>if </span><span>(comp(begin[b + bit], value)) b += bit;
</span><span>    }
</span><span>    </span><span>return</span><span> begin + (b + </span><span>1</span><span>);
</span><span>}
</span></code></pre>
<p>However, when it comes to clarity and elegance I still find the following
method the most beautiful:</p>
<pre data-lang="cpp"><code data-lang="cpp"><span>template</span><span>&lt;</span><span>typename</span><span> It, </span><span>typename</span><span> T, </span><span>typename</span><span> Cmp&gt;
</span><span>It lower_bound(It begin, It end, const T&amp; value, Cmp comp) {
</span><span>    size_t n = end - begin;
</span><span>    size_t b = </span><span>0</span><span>;
</span><span>    </span><span>for </span><span>(size_t bit = std::bit_floor(n); bit != </span><span>0</span><span>; bit &gt;&gt;= </span><span>1</span><span>) {
</span><span>        size_t i = (b | bit) - </span><span>1</span><span>;
</span><span>        </span><span>if </span><span>(i &lt; n &amp;&amp; comp(begin[i], value)) b |= bit;
</span><span>    }
</span><span>    </span><span>return</span><span> begin + b;
</span><span>}
</span></code></pre>

</article></div>
  </body>
</html>
