<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://rendiment.io/postgresql/2026/01/21/pgtrgm-pgvector-music.html">Original</a>
    <h1>Find &#39;Abbey Road when type &#39;Beatles abbey rd&#39;: Fuzzy/Semantic search in Postgres</h1>
    
    <div id="readability-page-1" class="page"><article id="maincontent">
			
<p>If you’ve ever built a search feature, you know the pain. Your database has a beautifully curated catalog of albums:</p>
<div><div><pre><code>Abbey Road
The Dark Side of the Moon
OK Computer
</code></pre></div></div>
<p>But users type things like:</p>
<div><div><pre><code>beatles abbey rd
dark side moon pink floyd
ok computer radiohead 1997
</code></pre></div></div>
<p>How do you match these? A simple <code>WHERE name = ?</code> won’t cut it. You need something smarter.</p>
<p>I recently worked on a classification system that needed to match messy invoice line items to a product catalog. The patterns I learned there apply perfectly to music, books, or any catalog matching problem. I ended up using two PostgreSQL extensions: <strong>pg_trgm</strong> for fuzzy text matching and <strong>pgvector</strong> for semantic similarity search.</p>
<p>In this post, I’ll walk you through both approaches using a real dataset: <strong>114,000 Spotify tracks</strong> from Hugging Face. You’ll be able to follow along with actual data.</p>
<hr/>

<p>We’ll use the <a href="https://huggingface.co/datasets/maharshipandya/spotify-tracks-dataset">Spotify Tracks Dataset</a> from Hugging Face. It contains 114,000+ tracks across 125 genres, with album names, artists, and popularity scores. It’s CC0 licensed (public domain), so you can use it freely.</p>
<p>The dataset has real-world messiness: album names like “Abbey Road (Remastered)”, “The Dark Side of the Moon (2011 Remaster)”, and “OK Computer OKNOTOK 1997 2017”. Perfect for testing our matching approaches.</p>
<hr/>

<table>
<thead>
   <tr>
     <th>Approach</th>
     <th>Extension</th>
     <th>What it does</th>
     <th>Best for</th>
   </tr>
 </thead>
 <tbody>
   <tr>
     <td><strong>Fuzzy matching</strong></td>
     <td><code>pg_trgm</code></td>
     <td>Compares character sequences (trigrams)</td>
     <td>Typos, abbreviations, word order</td>
   </tr>
   <tr>
     <td><strong>Semantic search</strong></td>
     <td><code>pgvector</code></td>
     <td>Compares meaning via embeddings</td>
     <td>Synonyms, paraphrasing, conceptual similarity</td>
   </tr>
 </tbody>
</table>
<p><strong>pg_trgm</strong> breaks text into 3-character sequences and measures overlap. “Abbey Road” becomes <code>{&#34; ab&#34;, &#34;abb&#34;, &#34;bbe&#34;, &#34;bey&#34;, &#34;ey &#34;, &#34; ro&#34;, &#34;roa&#34;, &#34;oad&#34;, &#34;ad &#34;}</code>. If two strings share many trigrams, they’re similar.</p>
<p><strong>pgvector</strong> stores vector embeddings—numerical representations of meaning generated by machine learning models. “Abbey Road” and “The Beatles final album” might have similar vectors even though they share no words.</p>
<p>Let’s set them up.</p>
<hr/>

<h2 id="extensions-and-table">Extensions and Table</h2>
<div><div><pre><code><span>-- Enable extensions</span>
<span>CREATE</span> <span>EXTENSION</span> <span>IF</span> <span>NOT</span> <span>EXISTS</span> <span>pg_trgm</span><span>;</span>
<span>CREATE</span> <span>EXTENSION</span> <span>IF</span> <span>NOT</span> <span>EXISTS</span> <span>vector</span><span>;</span>

<span>-- Create the catalog table</span>
<span>CREATE</span> <span>TABLE</span> <span>album_catalog</span> <span>(</span>
    <span>id</span> <span>SERIAL</span> <span>PRIMARY</span> <span>KEY</span><span>,</span>
    <span>track_id</span> <span>VARCHAR</span><span>(</span><span>50</span><span>),</span>
    <span>track_name</span> <span>VARCHAR</span><span>(</span><span>500</span><span>)</span> <span>NOT</span> <span>NULL</span><span>,</span>
    <span>artists</span> <span>VARCHAR</span><span>(</span><span>500</span><span>),</span>
    <span>album_name</span> <span>VARCHAR</span><span>(</span><span>500</span><span>),</span>
    <span>popularity</span> <span>INTEGER</span><span>,</span>
    <span>album_normalized</span> <span>VARCHAR</span><span>(</span><span>500</span><span>),</span>       <span>-- Cleaned version for fuzzy matching</span>
    <span>album_embedding</span> <span>vector</span><span>(</span><span>768</span><span>)</span>          <span>-- For semantic search</span>
<span>);</span>
</code></pre></div></div>
<h2 id="loading-the-spotify-dataset">Loading the Spotify Dataset</h2>
<p>First, download the dataset and load it into PostgreSQL:</p>
<div><div><pre><code><span># load_spotify_data.py
</span><span>from</span> <span>datasets</span> <span>import</span> <span>load_dataset</span>
<span>import</span> <span>psycopg2</span>

<span># Download from Hugging Face (about 50MB)
</span><span>print</span><span>(</span><span>&#34;Downloading Spotify dataset from Hugging Face...&#34;</span><span>)</span>
<span>dataset</span> <span>=</span> <span>load_dataset</span><span>(</span><span>&#34;maharshipandya/spotify-tracks-dataset&#34;</span><span>,</span> <span>split</span><span>=</span><span>&#34;train&#34;</span><span>)</span>

<span># Connect to PostgreSQL
</span><span>conn</span> <span>=</span> <span>psycopg2</span><span>.</span><span>connect</span><span>(</span>
    <span>host</span><span>=</span><span>&#39;localhost&#39;</span><span>,</span>
    <span>database</span><span>=</span><span>&#39;music_catalog&#39;</span><span>,</span>
    <span>user</span><span>=</span><span>&#39;your_user&#39;</span><span>,</span>
    <span>password</span><span>=</span><span>&#39;your_password&#39;</span>
<span>)</span>
<span>cursor</span> <span>=</span> <span>conn</span><span>.</span><span>cursor</span><span>()</span>

<span>print</span><span>(</span><span>f</span><span>&#34;Loading </span><span>{</span><span>len</span><span>(</span><span>dataset</span><span>)</span><span>}</span><span> tracks into PostgreSQL...&#34;</span><span>)</span>

<span># Insert tracks (deduplicate by album_name + artists)
</span><span>seen_albums</span> <span>=</span> <span>set</span><span>()</span>
<span>inserted</span> <span>=</span> <span>0</span>

<span>for</span> <span>row</span> <span>in</span> <span>dataset</span><span>:</span>
    <span>album_key</span> <span>=</span> <span>(</span><span>row</span><span>[</span><span>&#39;album_name&#39;</span><span>],</span> <span>row</span><span>[</span><span>&#39;artists&#39;</span><span>])</span>
    <span>if</span> <span>album_key</span> <span>in</span> <span>seen_albums</span><span>:</span>
        <span>continue</span>
    <span>seen_albums</span><span>.</span><span>add</span><span>(</span><span>album_key</span><span>)</span>
    
    <span>cursor</span><span>.</span><span>execute</span><span>(</span><span>&#34;&#34;&#34;
        INSERT INTO album_catalog (track_id, track_name, artists, album_name, popularity)
        VALUES (%s, %s, %s, %s, %s)
    &#34;&#34;&#34;</span><span>,</span> <span>(</span><span>row</span><span>[</span><span>&#39;track_id&#39;</span><span>],</span> <span>row</span><span>[</span><span>&#39;track_name&#39;</span><span>],</span> <span>row</span><span>[</span><span>&#39;artists&#39;</span><span>],</span> <span>row</span><span>[</span><span>&#39;album_name&#39;</span><span>],</span> <span>row</span><span>[</span><span>&#39;popularity&#39;</span><span>]))</span>
    
    <span>inserted</span> <span>+=</span> <span>1</span>
    <span>if</span> <span>inserted</span> <span>%</span> <span>5000</span> <span>==</span> <span>0</span><span>:</span>
        <span>print</span><span>(</span><span>f</span><span>&#34;  Inserted </span><span>{</span><span>inserted</span><span>}</span><span> albums...&#34;</span><span>)</span>

<span>conn</span><span>.</span><span>commit</span><span>()</span>
<span>print</span><span>(</span><span>f</span><span>&#34;Done! Loaded </span><span>{</span><span>inserted</span><span>}</span><span> unique albums.&#34;</span><span>)</span>
<span>conn</span><span>.</span><span>close</span><span>()</span>
</code></pre></div></div>
<p>Run it:</p>
<div><div><pre><code>pip <span>install </span>datasets psycopg2-binary
python load_spotify_data.py
</code></pre></div></div>
<p>This gives you around <strong>50,000 unique albums</strong> to work with—plenty for testing both approaches.</p>
<h2 id="indexes">Indexes</h2>
<p>This is where the magic happens. Without proper indexes, both approaches would require full table scans.</p>
<div><div><pre><code><span>-- GIN index for trigram similarity (pg_trgm)</span>
<span>CREATE</span> <span>INDEX</span> <span>idx_album_name_trgm</span> 
<span>ON</span> <span>album_catalog</span> 
<span>USING</span> <span>gin</span> <span>(</span><span>album_normalized</span> <span>gin_trgm_ops</span><span>);</span>

<span>-- IVFFlat index for vector similarity (pgvector)</span>
<span>CREATE</span> <span>INDEX</span> <span>idx_album_embedding</span> 
<span>ON</span> <span>album_catalog</span> 
<span>USING</span> <span>ivfflat</span> <span>(</span><span>album_embedding</span> <span>vector_cosine_ops</span><span>)</span>
<span>WITH</span> <span>(</span><span>lists</span> <span>=</span> <span>100</span><span>);</span>
</code></pre></div></div>
<p>A note on the <code>lists</code> parameter for IVFFlat: it controls how many clusters the index creates. More lists = faster queries but less accurate. The rule of thumb is <code>lists = sqrt(rows)</code> for small tables, or <code>lists = rows / 1000</code> for larger ones. For a catalog of 50,000 albums, 100 lists is reasonable.</p>
<hr/>

<h2 id="basic-similarity-query">Basic Similarity Query</h2>
<div><div><pre><code><span>SELECT</span> 
    <span>album_name</span><span>,</span>
    <span>artists</span><span>,</span>
    <span>similarity</span><span>(</span><span>&#39;abbey rd beatles&#39;</span><span>,</span> <span>album_name</span><span>)</span> <span>AS</span> <span>score</span>
<span>FROM</span> <span>album_catalog</span>
<span>WHERE</span> <span>similarity</span><span>(</span><span>&#39;abbey rd beatles&#39;</span><span>,</span> <span>album_name</span><span>)</span> <span>&gt;</span> <span>0</span><span>.</span><span>3</span>
<span>ORDER</span> <span>BY</span> <span>score</span> <span>DESC</span>
<span>LIMIT</span> <span>5</span><span>;</span>
</code></pre></div></div>
<p>Result:</p>
<table>
<thead>
   <tr>
     <th>album_name</th>
     <th>artists</th>
     <th>score</th>
   </tr>
 </thead>
 <tbody>
   <tr>
     <td>Abbey Road (Remastered)</td>
     <td>The Beatles</td>
     <td>0.48</td>
   </tr>
 </tbody>
</table>
<p>The <code>similarity()</code> function returns a value between 0 and 1. I typically use <strong>0.3 as a minimum threshold</strong> to filter noise, but this depends on your data.</p>
<h2 id="using-the-index-with-the--operator">Using the Index with the % Operator</h2>
<p>The <code>similarity()</code> function doesn’t use the GIN index directly. For indexed queries, use the <code>%</code> operator:</p>
<div><div><pre><code><span>-- Set the similarity threshold</span>
<span>SET</span> <span>pg_trgm</span><span>.</span><span>similarity_threshold</span> <span>=</span> <span>0</span><span>.</span><span>3</span><span>;</span>

<span>-- This query uses the index</span>
<span>SELECT</span> <span>album_name</span><span>,</span> <span>artists</span><span>,</span> <span>similarity</span><span>(</span><span>&#39;abbey rd&#39;</span><span>,</span> <span>album_normalized</span><span>)</span> <span>AS</span> <span>score</span>
<span>FROM</span> <span>album_catalog</span>
<span>WHERE</span> <span>album_normalized</span> <span>%</span> <span>&#39;abbey rd&#39;</span>
<span>ORDER</span> <span>BY</span> <span>score</span> <span>DESC</span><span>;</span>
</code></pre></div></div>
<h2 id="strengths-and-weaknesses">Strengths and Weaknesses</h2>
<p><strong>pg_trgm works well for:</strong></p>
<ul>
 <li>Typos: “Abey Road” → “Abbey Road”</li>
 <li>Abbreviations: “abbey rd” → “Abbey Road”</li>
 <li>Missing words: “Dark Side Moon” → “The Dark Side of the Moon”</li>
 <li>Word order variations: “Computer OK Radiohead” → “OK Computer”</li>
</ul>
<p><strong>pg_trgm struggles with:</strong></p>
<ul>
 <li>Synonyms: “The Beatles last album” won’t match “Abbey Road”</li>
 <li>Conceptual queries: “90s grunge Seattle” won’t match “Nevermind”</li>
 <li>Completely different phrasing: “Floyd’s prism album” vs “The Dark Side of the Moon”</li>
</ul>
<p>This is where semantic search comes in.</p>
<hr/>

<h2 id="generating-embeddings">Generating Embeddings</h2>
<p>Before you can search, you need to generate embeddings for your catalog. I use <strong>sentence-transformers</strong> with the <code>all-mpnet-base-v2</code> model—it’s free, runs locally, and produces 768-dimensional embeddings.</p>
<div><div><pre><code><span># generate_embeddings.py
</span><span>from</span> <span>sentence_transformers</span> <span>import</span> <span>SentenceTransformer</span>
<span>import</span> <span>psycopg2</span>

<span># Load the model (downloads ~420MB on first run)
</span><span>print</span><span>(</span><span>&#34;Loading embedding model...&#34;</span><span>)</span>
<span>model</span> <span>=</span> <span>SentenceTransformer</span><span>(</span><span>&#39;all-mpnet-base-v2&#39;</span><span>)</span>

<span># Connect to your database
</span><span>conn</span> <span>=</span> <span>psycopg2</span><span>.</span><span>connect</span><span>(</span>
    <span>host</span><span>=</span><span>&#39;localhost&#39;</span><span>,</span>
    <span>database</span><span>=</span><span>&#39;music_catalog&#39;</span><span>,</span>
    <span>user</span><span>=</span><span>&#39;your_user&#39;</span><span>,</span>
    <span>password</span><span>=</span><span>&#39;your_password&#39;</span>
<span>)</span>
<span>cursor</span> <span>=</span> <span>conn</span><span>.</span><span>cursor</span><span>()</span>

<span># Fetch albums without embeddings
</span><span>cursor</span><span>.</span><span>execute</span><span>(</span><span>&#34;&#34;&#34;
    SELECT id, album_name, artists 
    FROM album_catalog 
    WHERE album_embedding IS NULL
&#34;&#34;&#34;</span><span>)</span>
<span>albums</span> <span>=</span> <span>cursor</span><span>.</span><span>fetchall</span><span>()</span>

<span>print</span><span>(</span><span>f</span><span>&#34;Generating embeddings for </span><span>{</span><span>len</span><span>(</span><span>albums</span><span>)</span><span>}</span><span> albums...&#34;</span><span>)</span>

<span>batch_size</span> <span>=</span> <span>100</span>
<span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>0</span><span>,</span> <span>len</span><span>(</span><span>albums</span><span>),</span> <span>batch_size</span><span>):</span>
    <span>batch</span> <span>=</span> <span>albums</span><span>[</span><span>i</span><span>:</span><span>i</span> <span>+</span> <span>batch_size</span><span>]</span>
    
    <span># Combine album and artist for richer context
</span>    <span>texts</span> <span>=</span> <span>[</span><span>f</span><span>&#34;</span><span>{</span><span>album</span><span>}</span><span> by </span><span>{</span><span>artist</span><span>}</span><span>&#34;</span> <span>if</span> <span>artist</span> <span>else</span> <span>album</span> 
             <span>for</span> <span>_</span><span>,</span> <span>album</span><span>,</span> <span>artist</span> <span>in</span> <span>batch</span><span>]</span>
    
    <span># Generate embeddings in batch (much faster)
</span>    <span>embeddings</span> <span>=</span> <span>model</span><span>.</span><span>encode</span><span>(</span><span>texts</span><span>)</span>
    
    <span># Store in database
</span>    <span>for</span> <span>j</span><span>,</span> <span>(</span><span>album_id</span><span>,</span> <span>album_name</span><span>,</span> <span>_</span><span>)</span> <span>in</span> <span>enumerate</span><span>(</span><span>batch</span><span>):</span>
        <span>cursor</span><span>.</span><span>execute</span><span>(</span><span>&#34;&#34;&#34;
            UPDATE album_catalog 
            SET album_embedding = %s 
            WHERE id = %s
        &#34;&#34;&#34;</span><span>,</span> <span>(</span><span>embeddings</span><span>[</span><span>j</span><span>].</span><span>tolist</span><span>(),</span> <span>album_id</span><span>))</span>
    
    <span>conn</span><span>.</span><span>commit</span><span>()</span>
    <span>print</span><span>(</span><span>f</span><span>&#34;  Processed </span><span>{</span><span>min</span><span>(</span><span>i</span> <span>+</span> <span>batch_size</span><span>,</span> <span>len</span><span>(</span><span>albums</span><span>))</span><span>}</span><span>/</span><span>{</span><span>len</span><span>(</span><span>albums</span><span>)</span><span>}</span><span> albums&#34;</span><span>)</span>

<span>conn</span><span>.</span><span>close</span><span>()</span>
<span>print</span><span>(</span><span>&#34;Done!&#34;</span><span>)</span>
</code></pre></div></div>
<p>Run it:</p>
<div><div><pre><code>pip <span>install </span>sentence-transformers
python generate_embeddings.py
</code></pre></div></div>
<p>On a decent CPU, this processes about 500 albums per minute. For 50,000 albums, expect around 90 minutes. Go grab a coffee.</p>
<p><strong>Important:</strong> Run this once to populate your catalog. Embeddings are expensive to generate, so you don’t want to do it on every query.</p>
<h2 id="searching-with-embeddings">Searching with Embeddings</h2>
<div><div><pre><code><span>def</span> <span>search_by_embedding</span><span>(</span><span>query</span><span>,</span> <span>cursor</span><span>,</span> <span>model</span><span>,</span> <span>threshold</span><span>=</span><span>0.6</span><span>):</span>
    <span>&#34;&#34;&#34;Search using semantic similarity&#34;&#34;&#34;</span>
    <span># Generate embedding for the query
</span>    <span>query_embedding</span> <span>=</span> <span>model</span><span>.</span><span>encode</span><span>(</span><span>query</span><span>).</span><span>tolist</span><span>()</span>
    
    <span>cursor</span><span>.</span><span>execute</span><span>(</span><span>&#34;&#34;&#34;
        SELECT 
            album_name,
            artists,
            1 - (album_embedding &lt;=&gt; %s::vector) AS similarity
        FROM album_catalog
        WHERE album_embedding IS NOT NULL
          AND 1 - (album_embedding &lt;=&gt; %s::vector) &gt; %s
        ORDER BY similarity DESC
        LIMIT 5
    &#34;&#34;&#34;</span><span>,</span> <span>(</span><span>query_embedding</span><span>,</span> <span>query_embedding</span><span>,</span> <span>threshold</span><span>))</span>
    
    <span>return</span> <span>cursor</span><span>.</span><span>fetchall</span><span>()</span>

<span># Example
</span><span>results</span> <span>=</span> <span>search_by_embedding</span><span>(</span><span>&#34;Beatles final studio album&#34;</span><span>,</span> <span>cursor</span><span>,</span> <span>model</span><span>)</span>
<span># Returns: Abbey Road (even though the query shares few words with the album name)
</span></code></pre></div></div>
<p>The <code>&lt;=&gt;</code> operator calculates cosine distance. Since we want similarity (not distance), we use <code>1 - distance</code>.</p>
<h2 id="strengths-and-weaknesses-1">Strengths and Weaknesses</h2>
<p><strong>pgvector works well for:</strong></p>
<ul>
 <li>Synonyms and paraphrasing: “Beatles final album” → “Abbey Road”</li>
 <li>Conceptual queries: “Pink Floyd concept album about madness” → “The Wall”</li>
 <li>Natural language: “that Radiohead album from the late 90s” → “OK Computer”</li>
</ul>
<p><strong>pgvector struggles with:</strong></p>
<ul>
 <li>Exact matches: It might rank a semantically similar but wrong album higher</li>
 <li>Abbreviations: The model might not understand “rd” = “Road”</li>
 <li>Domain-specific jargon: Unless the model was trained on it</li>
</ul>
<hr/>

<p>Here’s what I learned the hard way: <strong>both approaches work better with clean input</strong>. Raw user input is full of noise that hurts matching accuracy. And the Spotify dataset is full of real-world messiness—album names like “The Dark Side of the Moon (2011 Remaster)” or “OK Computer OKNOTOK 1997 2017”.</p>
<h2 id="the-normalization-pipeline">The Normalization Pipeline</h2>
<div><div><pre><code><span>import</span> <span>re</span>

<span># Common abbreviations in music/media
</span><span>ABBREVIATIONS</span> <span>=</span> <span>{</span>
    <span>r</span><span>&#39;\bfeat\.?\b&#39;</span><span>:</span> <span>&#39;featuring&#39;</span><span>,</span>
    <span>r</span><span>&#39;\bft\.?\b&#39;</span><span>:</span> <span>&#39;featuring&#39;</span><span>,</span>
    <span>r</span><span>&#39;\bvol\.?\b&#39;</span><span>:</span> <span>&#39;volume&#39;</span><span>,</span>
    <span>r</span><span>&#39;\bpt\.?\b&#39;</span><span>:</span> <span>&#39;part&#39;</span><span>,</span>
    <span>r</span><span>&#39;\bv\.?\s*(\d)&#39;</span><span>:</span> <span>r</span><span>&#39;volume \1&#39;</span><span>,</span>
    <span>r</span><span>&#39;\bst\.?\b&#39;</span><span>:</span> <span>&#39;saint&#39;</span><span>,</span>
    <span>r</span><span>&#39;\b&amp;\b&#39;</span><span>:</span> <span>&#39;and&#39;</span><span>,</span>
<span>}</span>

<span># Noise patterns to remove (common in Spotify data)
</span><span>NOISE_PATTERNS</span> <span>=</span> <span>[</span>
    <span>r</span><span>&#39;\(remaster(ed)?\s*\d*\)&#39;</span><span>,</span>            <span># (Remastered 2023)
</span>    <span>r</span><span>&#39;\(\d{4}\s*remaster(ed)?\)&#39;</span><span>,</span>          <span># (2011 Remaster)
</span>    <span>r</span><span>&#39;\[deluxe(\s+edition)?\]&#39;</span><span>,</span>             <span># [Deluxe Edition]
</span>    <span>r</span><span>&#39;\(deluxe(\s+edition)?\)&#39;</span><span>,</span>             <span># (Deluxe Edition)
</span>    <span>r</span><span>&#39;\s*-\s*single\b&#39;</span><span>,</span>                     <span># - Single
</span>    <span>r</span><span>&#39;\s*\[\d+[-/]\d+\]&#39;</span><span>,</span>                   <span># [Disc 1/2]
</span>    <span>r</span><span>&#39;\(anniversary(\s+edition)?\)&#39;</span><span>,</span>        <span># (Anniversary Edition)
</span>    <span>r</span><span>&#39;\(expanded(\s+edition)?\)&#39;</span><span>,</span>           <span># (Expanded Edition)
</span>    <span>r</span><span>&#39;\(bonus\s+track.*?\)&#39;</span><span>,</span>                <span># (Bonus Track Version)
</span>    <span>r</span><span>&#39;\(super\s+deluxe\)&#39;</span><span>,</span>                  <span># (Super Deluxe)
</span>    <span>r</span><span>&#39;\(\d{4}\s+re-?issue\)&#39;</span><span>,</span>               <span># (2021 Reissue)
</span>    <span>r</span><span>&#39;\s+OKNOTOK\s+\d{4}\s+\d{4}&#39;</span><span>,</span>          <span># OKNOTOK 1997 2017
</span>    <span>r</span><span>&#39;\s*\(original\s+motion\s+picture.*?\)&#39;</span><span>,</span> <span># (Original Motion Picture Soundtrack)
</span><span>]</span>

<span># Articles to strip from the beginning
</span><span>LEADING_ARTICLES</span> <span>=</span> <span>[</span><span>&#39;the&#39;</span><span>,</span> <span>&#39;a&#39;</span><span>,</span> <span>&#39;an&#39;</span><span>]</span>


<span>def</span> <span>normalize_album</span><span>(</span><span>text</span><span>):</span>
    <span>&#34;&#34;&#34;
    Clean and normalize an album name for better matching.
    Works for both catalog entries and user queries.
    &#34;&#34;&#34;</span>
    <span>if</span> <span>not</span> <span>text</span><span>:</span>
        <span>return</span> <span>&#39;&#39;</span>
    
    <span># Lowercase everything
</span>    <span>cleaned</span> <span>=</span> <span>text</span><span>.</span><span>lower</span><span>().</span><span>strip</span><span>()</span>
    
    <span># Remove noise patterns
</span>    <span>for</span> <span>pattern</span> <span>in</span> <span>NOISE_PATTERNS</span><span>:</span>
        <span>cleaned</span> <span>=</span> <span>re</span><span>.</span><span>sub</span><span>(</span><span>pattern</span><span>,</span> <span>&#39;&#39;</span><span>,</span> <span>cleaned</span><span>,</span> <span>flags</span><span>=</span><span>re</span><span>.</span><span>IGNORECASE</span><span>)</span>
    
    <span># Expand abbreviations
</span>    <span>for</span> <span>pattern</span><span>,</span> <span>replacement</span> <span>in</span> <span>ABBREVIATIONS</span><span>.</span><span>items</span><span>():</span>
        <span>cleaned</span> <span>=</span> <span>re</span><span>.</span><span>sub</span><span>(</span><span>pattern</span><span>,</span> <span>replacement</span><span>,</span> <span>cleaned</span><span>,</span> <span>flags</span><span>=</span><span>re</span><span>.</span><span>IGNORECASE</span><span>)</span>
    
    <span># Remove leading articles for better matching
</span>    <span># &#34;The Dark Side&#34; and &#34;Dark Side&#34; should match
</span>    <span>for</span> <span>article</span> <span>in</span> <span>LEADING_ARTICLES</span><span>:</span>
        <span>if</span> <span>cleaned</span><span>.</span><span>startswith</span><span>(</span><span>article</span> <span>+</span> <span>&#39; &#39;</span><span>):</span>
            <span>cleaned</span> <span>=</span> <span>cleaned</span><span>[</span><span>len</span><span>(</span><span>article</span><span>)</span> <span>+</span> <span>1</span><span>:]</span>
            <span>break</span>
    
    <span># Normalize whitespace
</span>    <span>cleaned</span> <span>=</span> <span>re</span><span>.</span><span>sub</span><span>(</span><span>r</span><span>&#39;\s+&#39;</span><span>,</span> <span>&#39; &#39;</span><span>,</span> <span>cleaned</span><span>).</span><span>strip</span><span>()</span>
    
    <span># Remove punctuation except alphanumeric and spaces
</span>    <span>cleaned</span> <span>=</span> <span>re</span><span>.</span><span>sub</span><span>(</span><span>r</span><span>&#39;[^\w\s]&#39;</span><span>,</span> <span>&#39;&#39;</span><span>,</span> <span>cleaned</span><span>)</span>
    
    <span>return</span> <span>cleaned</span>


<span># Examples from the Spotify dataset
</span><span>print</span><span>(</span><span>normalize_album</span><span>(</span><span>&#34;The Dark Side of the Moon (2011 Remaster)&#34;</span><span>))</span>
<span># Output: &#34;dark side of moon&#34;
</span>
<span>print</span><span>(</span><span>normalize_album</span><span>(</span><span>&#34;OK Computer OKNOTOK 1997 2017&#34;</span><span>))</span>
<span># Output: &#34;ok computer&#34;
</span>
<span>print</span><span>(</span><span>normalize_album</span><span>(</span><span>&#34;Abbey Road (Remastered)&#34;</span><span>))</span>
<span># Output: &#34;abbey road&#34;
</span>
<span>print</span><span>(</span><span>normalize_album</span><span>(</span><span>&#34;Sgt. Pepper&#39;s Lonely Hearts Club Band (Deluxe Edition)&#34;</span><span>))</span>
<span># Output: &#34;sgt peppers lonely hearts club band&#34;
</span></code></pre></div></div>
<h2 id="populating-the-normalized-column">Populating the Normalized Column</h2>
<div><div><pre><code><span># normalize_albums.py
</span><span>import</span> <span>re</span>
<span>import</span> <span>psycopg2</span>

<span># ... (normalize_album function from above) ...
</span>
<span>conn</span> <span>=</span> <span>psycopg2</span><span>.</span><span>connect</span><span>(</span>
    <span>host</span><span>=</span><span>&#39;localhost&#39;</span><span>,</span>
    <span>database</span><span>=</span><span>&#39;music_catalog&#39;</span><span>,</span>
    <span>user</span><span>=</span><span>&#39;your_user&#39;</span><span>,</span>
    <span>password</span><span>=</span><span>&#39;your_password&#39;</span>
<span>)</span>
<span>cursor</span> <span>=</span> <span>conn</span><span>.</span><span>cursor</span><span>()</span>

<span># Update all catalog entries with normalized album names
</span><span>cursor</span><span>.</span><span>execute</span><span>(</span><span>&#34;SELECT id, album_name FROM album_catalog&#34;</span><span>)</span>
<span>albums</span> <span>=</span> <span>cursor</span><span>.</span><span>fetchall</span><span>()</span>

<span>print</span><span>(</span><span>f</span><span>&#34;Normalizing </span><span>{</span><span>len</span><span>(</span><span>albums</span><span>)</span><span>}</span><span> albums...&#34;</span><span>)</span>
<span>for</span> <span>album_id</span><span>,</span> <span>album_name</span> <span>in</span> <span>albums</span><span>:</span>
    <span>normalized</span> <span>=</span> <span>normalize_album</span><span>(</span><span>album_name</span><span>)</span>
    <span>cursor</span><span>.</span><span>execute</span><span>(</span><span>&#34;&#34;&#34;
        UPDATE album_catalog 
        SET album_normalized = %s 
        WHERE id = %s
    &#34;&#34;&#34;</span><span>,</span> <span>(</span><span>normalized</span><span>,</span> <span>album_id</span><span>))</span>

<span>conn</span><span>.</span><span>commit</span><span>()</span>
<span>conn</span><span>.</span><span>close</span><span>()</span>
<span>print</span><span>(</span><span>&#34;Done!&#34;</span><span>)</span>
</code></pre></div></div>
<p>Now your fuzzy matches compare apples to apples. “Abbey Road (Remastered)” and “abbey rd” both normalize to something comparable.</p>
<hr/>

<p>The best results come from using both methods together. My strategy:</p>
<ol>
 <li><strong>Try fuzzy matching first</strong> (fast, uses index)</li>
 <li><strong>If score is low, fall back to embeddings</strong> (slower, more accurate for hard cases)</li>
 <li><strong>Use the better result</strong></li>
</ol>
<div><div><pre><code><span>def</span> <span>search_catalog</span><span>(</span><span>query</span><span>,</span> <span>cursor</span><span>,</span> <span>model</span><span>,</span> <span>fuzzy_threshold</span><span>=</span><span>0.3</span><span>,</span> <span>embedding_threshold</span><span>=</span><span>0.6</span><span>):</span>
    <span>&#34;&#34;&#34;
    Hybrid search: fuzzy first, embeddings as fallback
    &#34;&#34;&#34;</span>
    <span>normalized_query</span> <span>=</span> <span>normalize_album</span><span>(</span><span>query</span><span>)</span>
    
    <span># Step 1: Try fuzzy matching
</span>    <span>cursor</span><span>.</span><span>execute</span><span>(</span><span>&#34;&#34;&#34;
        SELECT 
            id, album_name, artists,
            similarity(%s, album_normalized) AS score,
            &#39;fuzzy&#39; AS method
        FROM album_catalog
        WHERE similarity(%s, album_normalized) &gt; %s
        ORDER BY score DESC
        LIMIT 1
    &#34;&#34;&#34;</span><span>,</span> <span>(</span><span>normalized_query</span><span>,</span> <span>normalized_query</span><span>,</span> <span>fuzzy_threshold</span><span>))</span>
    
    <span>fuzzy_result</span> <span>=</span> <span>cursor</span><span>.</span><span>fetchone</span><span>()</span>
    
    <span># If fuzzy score is high enough, return it
</span>    <span>if</span> <span>fuzzy_result</span> <span>and</span> <span>fuzzy_result</span><span>[</span><span>3</span><span>]</span> <span>&gt;=</span> <span>0.65</span><span>:</span>
        <span>return</span> <span>fuzzy_result</span>
    
    <span># Step 2: Try semantic search
</span>    <span>query_embedding</span> <span>=</span> <span>model</span><span>.</span><span>encode</span><span>(</span><span>query</span><span>).</span><span>tolist</span><span>()</span>
    
    <span>cursor</span><span>.</span><span>execute</span><span>(</span><span>&#34;&#34;&#34;
        SELECT 
            id, album_name, artists,
            1 - (album_embedding &lt;=&gt; %s::vector) AS score,
            &#39;embedding&#39; AS method
        FROM album_catalog
        WHERE album_embedding IS NOT NULL
          AND 1 - (album_embedding &lt;=&gt; %s::vector) &gt; %s
        ORDER BY score DESC
        LIMIT 1
    &#34;&#34;&#34;</span><span>,</span> <span>(</span><span>query_embedding</span><span>,</span> <span>query_embedding</span><span>,</span> <span>embedding_threshold</span><span>))</span>
    
    <span>embedding_result</span> <span>=</span> <span>cursor</span><span>.</span><span>fetchone</span><span>()</span>
    
    <span># Return the better result
</span>    <span>if</span> <span>not</span> <span>fuzzy_result</span><span>:</span>
        <span>return</span> <span>embedding_result</span>
    <span>if</span> <span>not</span> <span>embedding_result</span><span>:</span>
        <span>return</span> <span>fuzzy_result</span>
    
    <span># Both have results - return the one with higher confidence
</span>    <span>return</span> <span>fuzzy_result</span> <span>if</span> <span>fuzzy_result</span><span>[</span><span>3</span><span>]</span> <span>&gt;=</span> <span>embedding_result</span><span>[</span><span>3</span><span>]</span> <span>else</span> <span>embedding_result</span>


<span># Examples
</span><span>print</span><span>(</span><span>search_catalog</span><span>(</span><span>&#34;abbey rd&#34;</span><span>,</span> <span>cursor</span><span>,</span> <span>model</span><span>))</span>
<span># → Fuzzy match: Abbey Road (Remastered) | The Beatles (score: 0.71)
</span>
<span>print</span><span>(</span><span>search_catalog</span><span>(</span><span>&#34;beatles last studio album&#34;</span><span>,</span> <span>cursor</span><span>,</span> <span>model</span><span>))</span>
<span># → Embedding match: Abbey Road (Remastered) | The Beatles (score: 0.73)
</span>
<span>print</span><span>(</span><span>search_catalog</span><span>(</span><span>&#34;that radiohead album with paranoid android&#34;</span><span>,</span> <span>cursor</span><span>,</span> <span>model</span><span>))</span>
<span># → Embedding match: OK Computer | Radiohead (score: 0.68)
</span></code></pre></div></div>
<hr/>

<h2 id="pg_trgm">pg_trgm</h2>
<ul>
 <li><strong>Index type:</strong> GIN is recommended over GiST for read-heavy workloads</li>
 <li><strong>Index size:</strong> Roughly 2-3x the size of the indexed column</li>
 <li><strong>Query speed:</strong> Sub-millisecond for most queries with proper indexes</li>
 <li><strong>Maintenance:</strong> Indexes update automatically on INSERT/UPDATE</li>
</ul>
<div><div><pre><code><span>-- Check index size</span>
<span>SELECT</span> <span>pg_size_pretty</span><span>(</span><span>pg_relation_size</span><span>(</span><span>&#39;idx_album_name_trgm&#39;</span><span>));</span>
</code></pre></div></div>
<h2 id="pgvector">pgvector</h2>
<ul>
 <li><strong>Index type:</strong> IVFFlat is faster but approximate; HNSW is more accurate but uses more memory</li>
 <li><strong>Embedding generation:</strong> ~50ms per text with <code>all-mpnet-base-v2</code> on CPU (~500 albums/minute in batch)</li>
 <li><strong>Query speed:</strong> 1-10ms depending on table size and index parameters</li>
 <li><strong>Maintenance:</strong> Re-index if you add many new rows (&gt;10% of original size)</li>
</ul>
<div><div><pre><code><span>-- Check if index needs rebuilding</span>
<span>SELECT</span> <span>reltuples</span> <span>FROM</span> <span>pg_class</span> <span>WHERE</span> <span>relname</span> <span>=</span> <span>&#39;album_catalog&#39;</span><span>;</span>
<span>-- If this is significantly higher than when you created the index, rebuild it</span>
</code></pre></div></div>
<hr/>

<table>
<thead>
   <tr>
     <th>Scenario</th>
     <th>Recommended Approach</th>
   </tr>
 </thead>
 <tbody>
   <tr>
     <td>Typo correction</td>
     <td>pg_trgm</td>
   </tr>
   <tr>
     <td>Abbreviation expansion</td>
     <td>pg_trgm (with normalization)</td>
   </tr>
   <tr>
     <td>Natural language queries</td>
     <td>pgvector</td>
   </tr>
   <tr>
     <td>“Find similar items”</td>
     <td>pgvector</td>
   </tr>
   <tr>
     <td>Autocomplete/typeahead</td>
     <td>pg_trgm</td>
   </tr>
   <tr>
     <td>Multi-language support</td>
     <td>pgvector (with multilingual model)</td>
   </tr>
   <tr>
     <td>Limited compute resources</td>
     <td>pg_trgm</td>
   </tr>
   <tr>
     <td>Cold data (no ML model loaded)</td>
     <td>pg_trgm</td>
   </tr>
 </tbody>
</table>
<p>For most real-world applications, <strong>start with pg_trgm</strong>. It’s simpler, faster, and handles the majority of cases. Add pgvector when you need semantic understanding or when fuzzy matching isn’t cutting it.</p>
<hr/>

<p>I used <code>all-mpnet-base-v2</code> because it’s a solid general-purpose model. But the choice matters:</p>
<table>
<thead>
   <tr>
     <th>Model</th>
     <th>Dimensions</th>
     <th>Speed</th>
     <th>Quality</th>
     <th>Use Case</th>
   </tr>
 </thead>
 <tbody>
   <tr>
     <td><code>all-MiniLM-L6-v2</code></td>
     <td>384</td>
     <td>Fast</td>
     <td>Good</td>
     <td>Large catalogs, autocomplete</td>
   </tr>
   <tr>
     <td><code>all-mpnet-base-v2</code></td>
     <td>768</td>
     <td>Medium</td>
     <td>Better</td>
     <td>General purpose</td>
   </tr>
   <tr>
     <td>Domain-specific models</td>
     <td>Varies</td>
     <td>Varies</td>
     <td>Best for domain</td>
     <td>Medical, legal, scientific</td>
   </tr>
 </tbody>
</table>
<p>For example, if you were matching pharmaceutical products, you might use <strong>SapBERT</strong> (<code>cambridgeltl/SapBERT-from-PubMedBERT-fulltext</code>)—a model specifically trained on biomedical terminology.</p>
<p>Browse models at <a href="https://huggingface.co/sentence-transformers">Hugging Face sentence-transformers</a>.</p>
<hr/>

<p>Matching messy input to clean catalogs is a solved problem in PostgreSQL—you just need the right tools:</p>
<ul>
 <li><strong>pg_trgm</strong> for fast, character-level fuzzy matching</li>
 <li><strong>pgvector</strong> for semantic, meaning-based similarity</li>
 <li><strong>Text normalization</strong> to clean up noise before matching</li>
 <li><strong>Hybrid approach</strong> for the best of both worlds</li>
</ul>
<p>We tested this with 50,000 real albums from the Spotify dataset, and the patterns here work for music catalogs, book databases, product matching, or any scenario where users type imprecise queries against structured data.</p>
<p>All the code in this post runs on standard PostgreSQL with two extensions. No external search engines, no Elasticsearch, no complex infrastructure. Just your database doing what databases do best.</p>
<p>The full code is available as a set of Python scripts you can run against your own PostgreSQL instance. Download the Spotify dataset from Hugging Face, load it up, and start experimenting.</p>
<hr/>
<p><em>Have questions or want to share your own catalog matching war stories? Drop a comment below.</em></p>
</article></div>
  </body>
</html>
