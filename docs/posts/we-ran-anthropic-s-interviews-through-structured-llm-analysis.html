<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.playbookatlas.com/research/ai-adoption-explorer">Original</a>
    <h1>We ran Anthropic’s interviews through structured LLM analysis</h1>
    
    <div id="readability-page-1" class="page"><div><div><section><div><div><p>Anthropic released 1,250 interviews about AI at work.</p><p>Their headline?</p></div><blockquote>&#34;Predominantly positive sentiments about AI&#39;s impact on their professional activities&#34;</blockquote><p>We ran the same interviews through structured LLM analysis.</p><p>1,250 conversations. 47 dimensions per interview. 58,750 data points.</p><p>Not negative. Not positive. <span>Stuck.</span> <!-- -->They haven&#39;t resolved how they feel about AI. They&#39;re just using it anyway. And one group is struggling more than everyone else.</p><div><div><p>72%</p><p>of creatives face identity threat</p></div><div><p>85.7%</p><p>tensions remain unresolved</p></div><div><p>6.4%</p><p>of scientists feel meaning disruption</p></div></div></div></section><section><div><p>01 — THE FINDING NOBODY EXPECTED</p><h2>There are three tribes. One is in crisis.</h2><p>The data revealed three distinct psychological profiles. Scientists are thriving. The workforce is managing. But creatives? They&#39;re experiencing something closer to an existential reckoning.</p><div><div><div><div><h3>Creatives</h3><p>The Existential Crisis</p></div></div><div><p>THE PARADOX</p><p><span>71.7<!-- -->%</span> face identity threat, yet<!-- --> <span>74.6<!-- -->%</span> are <em>increasing</em> AI use. They&#39;re struggling the most and adopting the fastest.</p></div><div><div><p>identity threat</p><p>high + moderate</p></div></div><div><p>TOP ARCHETYPES</p><p><span>Reluctant Adopter (23.9%)</span><span>Cautious Experimenter (17.2%)</span><span>Conflicted User (16.4%)</span></p></div><div><p>FROM THE INTERVIEWS</p><div><div><div><blockquote>&#34;<!-- -->One thing I will never use AI for is getting it to write or re-write a section of text for me as that&#39;s no better than employing a ghost writer and I&#39;d feel a fraud.<!-- -->&#34;</blockquote><p><span>Creative Professional, Interview #847</span><span>authenticity</span></p></div></div></div></div></div><div><p>Struggle score combines identity threat, skill anxiety, meaning disruption, guilt/shame, unresolved tensions, and ethical concerns (0-10 scale).</p></div></div></div></section><section><div><div><p>Here&#39;s what makes this bizarre:</p><p>Creatives have the <span>highest struggle scores</span> <!-- -->and the <span>highest adoption rates</span>.</p><p>74.6% are <em>increasing</em> their AI use. Meanwhile, 44.8% experience &#34;meaning disruption.&#34; That&#39;s a fancy way of saying they&#39;re questioning whether their work matters anymore.</p><p>They&#39;re not avoiding AI because it hurts. They&#39;re running toward it<!-- --> <em>despite</em> the pain.</p></div></div></section><section><div><p>02 — THE MOST IMPORTANT NUMBER</p><h2>85.7% haven&#39;t figured it out yet.</h2><p>The interviews revealed deep tensions. Internal conflicts about AI. &#34;Efficiency vs. Quality.&#34; &#34;Convenience vs. Skill.&#34; &#34;Speed vs. Depth.&#34; Almost everyone has them. Almost no one has resolved them.</p><div><p><span>This is the most important finding.</span> <!-- -->People aren&#39;t resolving their AI tensions. They&#39;re living with them. Cognitive dissonance is the norm, not the exception. They don&#39;t need resolution to adopt. They adopt<!-- --> <em>despite</em> the unresolved conflict.</p><div><div><div><blockquote>&#34;<!-- -->AI saves me hours, but sometimes I wonder if I&#39;m losing something in the process.<!-- -->&#34;</blockquote><p><span>Marketing Manager, Interview #234</span><span>efficiency vs. quality</span></p></div></div></div><div><p>WHAT THEY&#39;RE TORN ABOUT</p><div><div><p>01</p><div><p><span>Efficiency vs. Quality</span><span>(<!-- -->238<!-- -->)</span></p></div></div><div><p>02</p><div><p><span>Efficiency vs. Authenticity</span><span>(<!-- -->196<!-- -->)</span></p></div></div><div><p>03</p><div><p><span>Convenience vs. Skill</span><span>(<!-- -->127<!-- -->)</span></p></div></div><div><p>04</p><div><p><span>Automation vs. Control</span><span>(<!-- -->98<!-- -->)</span></p></div></div><div><p>05</p><div><p><span>Productivity vs. Creativity</span><span>(<!-- -->86<!-- -->)</span></p></div></div><div><p>07</p><div><p><span>Assistance vs. Dependence</span><span>(<!-- -->68<!-- -->)</span></p></div></div><div><p>08</p><div><p><span>Innovation vs. Tradition</span><span>(<!-- -->54<!-- -->)</span></p></div></div></div></div><div><p>THE PATTERN</p><p>Every major tension follows the same structure: <span>short-term benefit</span> <!-- -->vs. <span>long-term concern</span>. AI delivers immediate value (speed, efficiency, convenience) while creating unresolved anxiety about the future (quality, authenticity, skill, control).</p></div></div></div></section><section><div><div><p>Think about what this means.</p><p>We&#39;ve been told AI adoption is about <span>capability</span>. Can people use it? Will they learn? Do they have access?</p><p>But 85.7% of people aren&#39;t stuck on capability. They&#39;re stuck on<!-- --> <span>meaning</span>. They&#39;re using AI every day while simultaneously feeling conflicted about using it.</p><p>Cognitive dissonance isn&#39;t a barrier to adoption. It&#39;s the <em>default state</em>.</p></div></div></section><section><div><p>03 — WHAT DESTROYS TRUST</p><h2>The #1 trust killer isn&#39;t what you&#39;d expect.</h2><p>Our analysis cataloged every trust driver and distrust driver across 1,250 interviews. The top trust destroyer? Not &#34;errors.&#34; Not &#34;inaccuracy.&#34; It&#39;s <span>hallucinations</span>. Specifically, the<!-- --> <em>confidence</em> with which AI gets things wrong.</p><div><div><p>#1 TRUST DESTROYER</p><p><span>Hallucinations</span><span>121 mentions</span></p><p>Not &#34;inaccuracy.&#34; Not &#34;errors.&#34; <span>Hallucinations.</span> <!-- -->The <em>confidence</em> with which AI makes mistakes is more damaging than the mistakes themselves. It&#39;s the confident wrongness that destroys trust.</p><div><div><div><blockquote>&#34;<!-- -->I always assume the AI is lying to me.<!-- -->&#34;</blockquote><p><span>Analyst, Interview #342</span><span>verification mindset</span></p></div></div></div></div><div><p>TRUST LEVEL BY GROUP</p><div><p>Group</p><p>Low/Cautious</p><p>Moderate</p><p>High</p></div></div></div></div></section><section><div><p>04 — WHY CREATIVES FEEL GUILTY</p><h2>They think they&#39;re cheating at being themselves.</h2><p>52% of creatives frame AI use through &#34;authenticity.&#34; Not harm, not fairness, but whether using AI makes them <em>less real</em>. The moral language they use tells the whole story: &#34;cheating,&#34; &#34;lazy,&#34; &#34;shortcut.&#34;</p><div><div><div><p>CREATIVES&#39; ETHICAL FRAME</p><p><span>52.2%</span><span>cite authenticity</span></p><p>vs. 24.6% workforce, 13.7% scientists</p></div><div><p>GUILT/SHAME CORRELATION</p><p><span>83%</span><span>of guilt-expressers</span></p><p>cite &#34;authenticity&#34; as their ethical frame</p></div></div><p><span>This explains everything.</span> <!-- -->Creatives don&#39;t frame AI use through &#34;harm&#34; or &#34;fairness.&#34; They frame it through<!-- --> <em>authenticity</em>. Using AI feels like cheating at being themselves. The moral vocabulary centers on what AI use says about <em>them</em>, not its impact on others.</p><div><div><div><blockquote>&#34;<!-- -->One thing I will never use AI for is getting it to write or re-write a section of text for me as that&#39;s no better than employing a ghost writer and I&#39;d feel a fraud.<!-- -->&#34;</blockquote><p><span>Creative Professional, Interview #847</span><span>fraud feeling</span></p></div></div></div><div><p>THE MORAL VOCABULARY OF AI USE</p><p>The vocabulary centers on <span>effort</span> and<!-- --> <span>authenticity</span>, not on AI&#39;s impact on others.</p></div><div><p>WHAT PREDICTS GUILT/SHAME?</p></div><div><div><p>DISCLOSURE PATTERNS</p><div><p><span>Selective (tell some, not others)</span><span>57.4<!-- -->%</span></p><p><span>Open (tell everyone)</span><span>33<!-- -->%</span></p><p><span>Hidden (tell no one)</span><span>9.6<!-- -->%</span></p></div></div><div><p>HIDING → GUILT CONNECTION</p><div><div><p><span>Those who hide AI use</span><span>18.3<!-- -->% guilt</span></p></div><div><p><span>Transparent users</span><span>6.2<!-- -->% guilt</span></p></div></div><p><span>3x higher guilt</span> among those who hide their AI use.</p></div></div></div></div></section><section><div><div><p>Look at that moral vocabulary again.</p><p>&#34;Cheating.&#34; &#34;Lazy.&#34; &#34;Shortcut.&#34;</p><p>These aren&#39;t words about AI&#39;s impact on <em>others</em>. They&#39;re words about what AI use says about <em>you</em>.</p><p>This isn&#39;t ethics in the philosophical sense. It&#39;s<!-- --> <span>moral identity</span>. Using AI feels like violating who they&#39;re supposed to be.</p></div></div></section><section><div><p>05 — THE HEALTHY BASELINE</p><h2>Scientists figured something out.</h2><div><div><p>63.2%</p><p>have LOW identity threat</p><p>vs. 36.4% workforce, 22.4% creatives</p></div><div><p>6.4%</p><p>experience meaning disruption</p><p>vs. 13.9% workforce, 44.8% creatives</p></div></div><div><p>Scientists have the <span>lowest &#34;high trust&#34; rate</span> (8.8%) but also the <span>lowest anxiety</span>. How?</p><p>They treat AI as a <span>tool</span>, not a collaborator. They verify everything (52.9% always verify). They keep psychological distance. Their identity depends on their <em>method</em>, not their output.</p><p>Scientists trust through verification, not faith. That makes all the difference.</p></div><p><span>The lesson:</span> <!-- -->Healthy AI adoption means building verification into your process. Keep your identity separate from AI&#39;s output. Scientists do this naturally. Others can learn.</p><div><p>FROM SCIENTISTS</p><div><div><div><blockquote>&#34;<!-- -->I only use the AI when it&#39;s not going to be publishable work, i.e. I&#39;m writing a method, make a list of steps and then ask the AI to clean it up.<!-- -->&#34;</blockquote><p><span>Research Scientist, Interview #1198</span><span>task boundaries</span></p></div></div></div></div></div></section><section><div><p>06 — WHAT EMERGED</p><h2>After 1,250 conversations, these rules emerged.</h2><p>Nobody wrote them down. But almost everyone follows them.</p><div><div><div><h3>The unwritten rules</h3><p>Patterns that emerged across 1,250 conversations</p></div></div><p>Nobody wrote these rules down. Nobody taught them. They&#39;re the <span>unspoken constitution</span> of AI at work— emerging organically from thousands of individual experiences.</p></div></div></section><section><div><p>07 — IN THEIR WORDS</p><h2>The quotes that stuck with us.</h2><p>Some voices you don&#39;t forget.</p><div><div><div><h3>In their own words</h3><p>Direct quotes from interview transcripts</p></div></div><div><blockquote><p>&#34;<!-- -->I am not quite trusting enough in AI yet to allow any communications to leave my desk in my name that are not first reviewed and approved by me directly.<!-- -->&#34;</p></blockquote></div></div></div></section><section><div><p>08 — SO WHAT?</p><h2>What this means for you.</h2><div><p>Anthropic&#39;s headline was &#34;predominantly positive.&#34; They weren&#39;t wrong. People <em>do</em>see benefits. But benefits don&#39;t equal resolution.</p><p>85.7% of people are using AI while simultaneously feeling unresolved about it. That&#39;s <span>cognitive debt</span>. And like all debt, it compounds.</p><p>If you&#39;re a creative feeling like AI is eroding your sense of self, you&#39;re not alone. You&#39;re in the majority. The path forward is<!-- --> <span>conscious adoption</span>: understanding what you&#39;re trading, what you&#39;re protecting, and why it matters to you.</p><p>The scientists figured it out: verify everything, keep your identity separate, treat AI as a tool rather than a collaborator. That&#39;s resilience.</p></div></div></section><section><div><div><div><div><p>Analysis Method</p><p>GPT-4o-mini with structured outputs (Pydantic schema). Each interview analyzed across 47 dimensions including identity threat, trust drivers, emotional triggers, ethical frames, and tension patterns.</p></div><div><p>Cost &amp; Efficiency</p><p>1,250 analyses completed. 72.7% prompt cache hit rate. Total cost: $0.58. 100% success rate.</p></div></div><div><div><p>Schema Design</p><p>Comprehensive qualitative analysis schema including: AI conceptualization, emotional state, task boundaries, workplace context, trust profile, identity dimension, adaptation journey, ethical dimension, tensions, key quotes, and emergent themes.</p></div><div><p>Limitations</p><p>LLM interpretation introduces potential bias. Sample sizes vary (scientists n=51 is small). &#34;Struggle score&#34; is a composite index we created, not a validated psychological measure. Results should be viewed as exploratory.</p></div><div><p>Reproducibility</p><p>Dataset is public. Analysis code and full results available on request. We encourage independent verification.</p></div></div></div></div></section><section><div><div><div><p>Analysis by Playbook Atlas</p><p>Data: Anthropic Interviewer Dataset (MIT License)</p></div></div></div></section></div><!--$--><!--/$--></div></div>
  </body>
</html>
