<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://mark.engineer/2023/11/speed-up-a-program-for-50-years-old-processor-by-180000/">Original</a>
    <h1>Speeding up a program for a 50 year old processor</h1>
    
    <div id="readability-page-1" class="page"><div>
<p>In the previous year, I wrote the program, running on Intel’s first microprocessor – 4004, that <a href="https://mark.engineer/2022/04/calculating-pi-digits-on-first-intel-microprocessor-intel-4004/">computes the first 255 digits of π</a>. But, unfortunately, I was not able to beat ENIAC’s achievement with 2035 computed digits <sup id="fnref-120-1"><a title="Read footnote." href="#fn-120-1">1</a></sup>. So let’s continue our journey. I picked the successor of 4004 – Intel’s 4040. This CPU is very similar to the 4004 and extends the instruction set a bit. To make my challenge a bit more spicy, I decided to follow these rules:</p>
<ol>
<li>We should compute at least 2035 digits of π faster than ENIAC did. According to the original article <sup id="fnref-120-2"><a title="Read footnote." href="#fn-120-2">2</a></sup> it took 70 hours of machine running time. So our goal is 69 hours, 59 minutes, 59 seconds or fewer.</li>
<li>We can’t use extra I/O ports to expand CPU restrictions. For instance, it means that I can’t have any external RAM/ROM bank switchers controlled by I/O ports.</li>
<li>It should be pure computation, with no pre-computed data tables in RAM, not even a simple multiplication table.</li>
<li>Our code should support arbitrary values for the amount of computed digits, while this value is less than or equal to a high boundary. This restriction causes avoidance of any fine-tuning for results. The solution should be generic.</li>
</ol>
<p><em>Please, take into account that this article is structured by chapters, while actual optimizations and changes have been done in another order. For example, I have optimized modular multiplication, then switched to general algorithm improvements and, because it has not been enough, I have returned to work on multiplication. However, in the article, all optimization steps for modular multiplication will be explained in the same section.</em></p>

<p>Even if I chose a fresher processor, it still inherits the majority of origin’s limitations:</p>
<ul>
<li>The CPU clock rate is 740kHz, but the instruction cycle takes 8 or 16 ticks, so we have up to 92500 instructions per second.</li>
<li>Very limited instruction set. We don’t have multiplications, divisions, or easy memory operations. Nuff said, we don’t even have shift instructions – only rotate operations.</li>
<li>RAM is 1280 bytes only. Even if the datasheet contains information about lower numbers, there were real systems with 1280 bytes on board without any complex memory switch logic <sup id="fnref-120-3"><a title="Read footnote." href="#fn-120-3">3</a></sup>.</li>
</ul>
<p>But the good news is that we got some new features with 4040 <sup id="fnref-120-11"><a title="Read footnote." href="#fn-120-11">4</a></sup>:</p>
<ul>
<li>Now we have AND/OR instructions. You read it right, 4004 had not them. Unfortunatelly, these instructions are not perfect – they perform a binary operation with an accumulator and a specific register (<code>rr6</code> or <code>rr7</code> for the <code>AND</code> operation, for instance).</li>
<li>The call stack grew from 3 nested subroutine calls to 7, so we can better organize our program. Still, it’s a pretty low value and at some point, I exceeded it.</li>
<li>Increased the amount of general-purpose registers from 16 to 24. Intel added a second bank with 8 registers. Because the ISA is the basically same and the register index is still encoded as a 4-bit number, for access to extra registers we need to switch between index register banks by executing specific instructions: <code>SB0</code> / <code>SB1</code>, which adds some inconvenience.</li>
<li>ROM space has been extended as well. Now we have 2 banks of ROM with 4KiB each. Again, switching between banks is not transparent, you need to call the <code>DB0</code> / <code>DB1</code> instruction at a specific moment.</li>
</ul>
<p>There are other changes brought by 4040, but they are not that profitable for my purpose: interrupts, single-step debugging, and separate voltage sources to reduce power consumption.</p>

<h2>Algorithm choice</h2>
<p>Let’s re-evaluate what algorithms for π calculation exist.</p>
<ul>
<li><strong>Spigot algorithm</strong> <sup id="fnref-120-4"><a title="Read footnote." href="#fn-120-4">5</a></sup>. I have already described that algorithm in my previous article. It requires keeping an array of digits in memory. The length of the array is proportional to the amount of computed digits. To have 2000+ digits, we need much more RAM.</li>
<li><a href="https://en.wikipedia.org/wiki/Machin-like_formula"><strong>Machin-like formulae</strong></a>. Good choice, but again memory limits us. We need to perform long arithmetic and the amount of digits for operands is comparable with the desired amount of π digits. Maybe it would be possible to compute 700 or 800 digits, but there is no way we can reach our target value.</li>
<li><strong>Improved spigot algorithm</strong> <sup id="fnref-120-5"><a title="Read footnote." href="#fn-120-5">6</a></sup>. We don’t need to keep any arrays, but we have similar considerations as for Machin-like formulas – due to computations we work with several big numbers. I was not lazy and checked how big they were – just for 255 digits of π, the algorithm requires 7KiB of RAM.</li>
<li><strong>Bailey–Borwein–Plouffe formula</strong> <sup id="fnref-120-6"><a title="Read footnote." href="#fn-120-6">7</a></sup>. Interesting idea, but it computes π digits in base 16 or base 2. We need base 10.</li>
<li><strong>Plouffe’s algorithm</strong> <sup id="fnref-120-7"><a title="Read footnote." href="#fn-120-7">8</a></sup>. The original algorithm is not very practical (too slow).</li>
<li><strong>Fabrice Bellard’s algorithm is based on the same formula for π</strong> <sup id="fnref-120-8"><a title="Read footnote." href="#fn-120-8">9</a></sup>. Simple and straightforward. Not the fastest, but much better than the version of Simon Plouffe.</li>
<li><strong>Xavier Gourdon’s algorithm</strong> <sup id="fnref-120-9"><a title="Read footnote." href="#fn-120-9">10</a></sup>. It’s even faster than Bellard’s idea, but it’s more complex and requires more code to be written, which is problematic with our poor ISA and limited program size (less than 8000 instructions).</li>
</ul>
<p>From the list above, Fabrice Bellard’s algorithm looks like an obvious choice, so let’s research how we can write the program, based on his short paper.</p>
<h2>Original formula</h2>
<p>A very interesting formula has been used as a basis for Plouffe’s algorithm:</p>
<p><span data-katex-display="true">

\pi+3=\sum_{k=1}^{+\infty}\frac{k2^{k}}{\left(\begin{array}{c}2k\\ k\end{array}\right)}

</span></p><p>You can check out a proof (and other fascinating equations) in Lehmer’s article. <sup id="fnref-120-10"><a title="Read footnote." href="#fn-120-10">11</a></sup></p>
<p>The round brackets expression is a <a href="https://planetmath.org/CentralBinomialCoefficient">central binomial coefficient</a> and could be specified as:</p>
<p><span data-katex-display="true">

\left(\begin{array}{c}2n\\ n\end{array}\right)=\frac{2^n(2n-1)!!}{n!},\:n!!=n \cdot (n-2) \cdots 3 \cdot 1

</span></p><p>So the final numerical series to work with would be:</p>
<p><span data-katex-display="true">

\pi+3=\sum_{k=1}^{+\infty}\frac{k2^{k}}{\left(\begin{array}{c}2k\\ k\end{array}\right)}=\sum_{k=1}^{+\infty}\frac{k \cdot k!}{(2k-1)!!}

</span></p><h2>Computation of the nth digit for a fraction</h2>
<p>Let’s start with the simplified problem. We have the fraction <span data-katex-display="false">s = \frac{b}{A}</span>, and we want to find its nth digit. How would we do that?</p>
<p>At first, we express <span data-katex-display="false">A</span> as prime factorization:</p>
<p><span data-katex-display="true">

A=\prod_{i=1}^{m}a_{i},\:i \neq j \Rightarrow gcd(a_i,a_j)=1

</span></p><p>Then we can declare a few variables:</p>
<p><span data-katex-display="true">

b_i = b \bmod a_i;\ A_i = \frac{A}{a_i};\ A_i^{-1} = \frac{1}{A_i} \bmod a_i

</span></p><p>By applying a <a href="https://en.wikipedia.org/wiki/Chinese_remainder_theorem#Existence_(direct_construction)">Chinese remainder theorem</a>, we got:</p>
<p><span data-katex-display="true">

b’ = \left( \sum_{i=1}^{m} b_i A_i A_i^{-1} \right) \bmod{A}

</span></p><p>Introduce another variable <span data-katex-display="false">f_i = b_i \cdot A_i^{-1} \bmod a_i</span>:</p>
<p><span data-katex-display="true">

b’ = \left( \sum_{i=1}^{m} f_i A_i \right) \bmod{A}

</span></p><p>Because <span data-katex-display="false">b’ = b \bmod A</span>, we can use it for the fractional part of <span data-katex-display="false">s</span>:</p>
<p><span data-katex-display="true">

\{s\} = \frac{b’}{A} = \frac{\left( \sum_{i=1}^{m} \frac{f_i}{a_i} A \right) \bmod{A}}{A} \stackrel{(1)}{=} \left\lbrace \frac{\sum_{i=1}^{m} \frac{f_i}{a_i} A}{A} \right\rbrace = \left\lbrace \sum_{i=1}^{m} \frac{f_i}{a_i} \right\rbrace

</span></p><p>It should be obvious how (1) works, but for completeness, the short proof is here:</p>
<p><span data-katex-display="true">

\frac{x \bmod N}{N} = \frac{x – N \lfloor \frac{x}{N} \rfloor}{N} = \frac{x}{N} – \lfloor \frac{x}{N} \rfloor = \{\frac{x}{N}\}

</span></p><p>Ok, now we can write the formula to find digits of <span data-katex-display="false">s</span> from position <span data-katex-display="false">n</span>:</p>
<p><span data-katex-display="true">

D_n = \{s \cdot 10^n\} = \left\lbrace \sum_{i=1}^m \frac {f_i \cdot 10^n}{a_i} \right\rbrace \stackrel{(2)}{=} \left\lbrace \sum_{i=1}^m \frac {f_i \cdot 10^n \bmod {a_i}}{a_i} \right\rbrace

</span></p><p>Transition (2) is here just to simplify computations: we need just the fractional part, so to avoid big numbers (and <span data-katex-display="false">10^n</span> could be very big) we can take modulus by denominator for each fractional addend.</p>
<p>As you can notice, this formula is not recurrent: each term in the sum is independent and can be computed separately, so we need to store just the current intermediate result. And because of modular arithmetic, the length of variables is relatively small, hence couple of dozens of bytes is enough to keep all data.</p>
<h2>Computation of the nth digit for a numerical series</h2>
<p>But the formula for π is not a regular fraction, it is represented as a numerical series, so we need to adapt math manipulations from above to another form – the partial sum of positive finite series. We have one more complication: <span data-katex-display="false">A_k</span> (denominator of series) would be factorized to prime factors with multiplicity that could be more than 1.</p>
<p>Let’s declare a set of prime factors <span data-katex-display="false">(a_1, a_2, …,a_m)</span> that have all potential factors of <span data-katex-display="false">A_k</span> and for some <span data-katex-display="false">(k, i)</span> multiplicity of <span data-katex-display="false">a_i</span> in the factorization of <span data-katex-display="false">A_k</span> could be 0 (that particular number from the set is not a factor for particular <span data-katex-display="false">A_k</span>). Also, we introduce <span data-katex-display="false">v_i^{max}</span> – the maximal multiplicity of <span data-katex-display="false">a_i</span> between all factorizations of <span data-katex-display="false">A_k</span>.</p>
<p><span data-katex-display="true">

S_N=\sum_{k=1}^N\frac{b_k}{A_k}, A_k=\prod_{i=1}^{m}a_i^{v_{i,k}}, 0 \leq v_{i,k} \leq v_i^{max},\:i \neq j \Rightarrow gcd(a_i,a_j)=1, v_{i,k} &gt; 0 \Rightarrow a_i \nmid b_k

</span></p><p>Declare variables, similar to the previous chapter:</p>
<p><span data-katex-display="true">

A_{i,k} = \frac {A_k}{a_i^{v_{i,k}}}\\

A_{i,k}^{-1} = \frac{1}{A_{i,k}} \bmod a_i^{v_{i,k}}\\

f_{i,k} =

\begin{cases}

0 &amp; \text{if }v_{i,k}=0\\

b_k \cdot A_{i,k}^{-1} \bmod a_i^{v_{i,k}} &amp; \text{if }v_{i,k} &gt; 0\\

\end{cases}

</span></p><p>You can notice that we are using <span data-katex-display="false">b_k</span> instead of <span data-katex-display="false">b_k \bmod a_i^{v_{i,k}}</span>, which are not equal even with modular multiplication. But we can do that because at the end we need just the fractional part of a number, so any integer parts we can drop early and work with numbers by modulus <span data-katex-display="false">a_i^{v_{i,k}}</span>.</p>
<p>By repeating logic from the previous section with the Chinese remainder theorem, we got the expression for the term of series and the whole partial sum:</p>
<p><span data-katex-display="true">

\frac{b_k}{A_k} = \left\lbrace \sum_{i=1}^{m} \frac{f_{i,k}}{a_i^{v_{i,k}}} \right\rbrace \\[15px]

S_N = \left\lbrace \sum_{k=1}^N \sum_{i=1}^{m} \frac{f_{i,k}}{a_i^{v_{i,k}}} \right\rbrace = \left\lbrace \sum_{i=1}^{m} \sum_{k=1}^N \frac{f_{i,k}}{a_i^{v_{i,k}}} \right\rbrace

</span></p><p>Next step is to use common divisor <span data-katex-display="false">a_i^{v_i^{max}}</span>, that is independent from <span data-katex-display="false">k</span>:</p>
<p><span data-katex-display="true">

f’_{i,k} = f_{i,k} \cdot a_i^{v_i^{max}-v_{i,k}} \\[15px]

S_N

= \left\{ \sum_{i=1}^{m} \sum_{k=1}^N \frac{f’_{i,k}}{a_i^{v_{i,k}} \cdot a_i^{v_i^{max}-v_{i,k}}} \right\}

= \left\{ \sum_{i=1}^{m} \sum_{k=1}^N \frac{f’_{i,k}}{a_i^{v_i^{max}}} \right\} \\[15px]

S_N = \left\{ \sum_{i=1}^m \frac{f_i}{a_i^{v_i^{max}}}\right\}, f_i=\left( \sum_{k=1}^N {f’_{i,k}} \right) \bmod a_i^{v_i^{max}}

</span></p><p>The same trick again – because the integer part is not important, we can use numbers from residue class modulo <span data-katex-display="false">a_i^{v_i^{max}}</span>, which are not that large.</p>
<p>Now important moment – we can deduce that every <span data-katex-display="false">f’_{i,k}</span> also belongs to the same residue class modulo <span data-katex-display="false">a_i^{v_i^{max}}</span>, even if it’s not that obvious. We can prove that with a simplified example:</p>
<p><span data-katex-display="true">

(x \bmod n^p) \cdot n^{q-p} = (x – n^p \cdot \lfloor \frac{x}{n^p} \rfloor) \cdot n^{q-p} = x \cdot n^{q-p} – n^q \cdot \lfloor \frac{x}{n^p} \rfloor \\

(x \cdot n^{q-p}) \bmod n^q = x \cdot n^{q-p} – n^q \cdot \lfloor \frac{x \cdot n^{q-p}}{n^q} \rfloor = x \cdot n^{q-p} – n^q \cdot \lfloor \frac{x}{n^p} \rfloor

</span></p><p>Based on that, we can write <span data-katex-display="false">f_i</span> as (by expanding and applying reasoning above to <span data-katex-display="false">f’_{i,k}</span> expression):</p>
<p><span data-katex-display="true">

f’_{i,k} = b_k \cdot A_{i,k}^{-1} \bmod a_i^{v_{i,k}} \cdot a_i^{v_i^{max}-v_{i,k}} = b_k \cdot A_{i,k}^{-1} \cdot a_i^{v_i^{max}-v_{i,k}} \bmod a_i^{v_i^{max}}\\[15px]

f_i=\sum_{k=1}^Nb_k\left(\frac{A_k}{a_i^{v_{i,k}}}\right)^{-1}a_i^{v_i^{max}-v_{i,k}}\bmod a_i^{v_i^{max}}

</span></p><p>And finally, we can derive a formula for digits of partial sum, starting from position <span data-katex-display="false">n</span>:</p>
<p><span data-katex-display="true">

D_n=\left\{ \sum_{i=1}^m\frac{f_i \cdot 10^n \bmod a_i^{v_i^{max}}}{a_i^{v_i^{max}}} \right\}

</span></p><h2>Determining maximum multiplicity of a prime number in <span data-katex-display="false">A_k</span></h2>
<p>We can assign values to variables into the formula for digits of partial sum (you can notice that <span data-katex-display="false">k</span> factor has been extracted from <span data-katex-display="false">b_k</span> calculation, it’s done for easier algorithm computation):</p>
<p><span data-katex-display="true">

b_k = k! \\

A_k = (2k-1)!!\\

v_{i,k} = v_{a_i}({A_k})\\

u_{i,k} = v_{a_i}({b_k})\\

f_i=\sum_{k=1}^N k\cdot \left( \frac{b_k}{a_i^{u_{i,k}}} \right) \cdot \left( \frac{A_k}{a_i^{v_{i,k}}} \right)^{-1} \cdot a_i^{v_i^{max}-v_{i,k}+u_{i,k}} \bmod a_i^{v_i^{max}}

</span></p><p>The interesting question is how we would find the value of <span data-katex-display="false">v_i^{max}</span> for particular <span data-katex-display="false">a_i</span>. From the problem definition from the previous section, we declare that <span data-katex-display="false">a_i</span> does not divide <span data-katex-display="false">b_k</span>, but it’s not true for our case, because <span data-katex-display="false">k!</span> can be divisible by <span data-katex-display="false">a_i</span> very easily. Fortunately, it affects only <span data-katex-display="false">v_i^{max}</span> value. So to determine it, we need to find:</p>
<p><span data-katex-display="true">

v_{a_i}\left(\frac{A_k}{b_k} \right) = v_{a_i}\left(\frac{(2N – 1)!!}{N!}\right)

</span></p><p><span data-katex-display="false">v_{a_i}</span> is <a href="https://en.wikipedia.org/wiki/P-adic_valuation">function of multiplicity</a>. We can <a href="https://en.wikipedia.org/wiki/Double_factorial#Relation_to_the_factorial">expand double factorial</a> and use <a href="https://en.wikipedia.org/wiki/Legendre%27s_formula">Legendre’s formula</a> to calculate it:</p>
<p><span data-katex-display="true">

v_{a_i}\left(\frac{(2N – 1)!!}{N!}\right)

= v_{a_i}\left( \frac{(2N)!}{2^N \cdot N! \cdot N!} \right)

= v_{a_i}\left( \frac{(2N)!}{N! \cdot N!} \right)

= \sum_{t=1}^L \lfloor \frac{2N}{a_i^t} \rfloor – 2\sum_{t=1}^L \lfloor \frac{N}{a_i^t} \rfloor

= \sum_{t=1}^L \left( \lfloor \frac{2N}{a_i^t} \rfloor – 2 \lfloor \frac{N}{a_i^t} \rfloor \right)

</span></p><p>We could drop <span data-katex-display="false">2^N</span> because it’s divisible only by 2. And if we examine terms of that sum, then we can see that each particular term is 0 or 1:</p>
<p><span data-katex-display="true">

\lfloor \frac{2N}{a_i^t} \rfloor – 2 \lfloor \frac{N}{a_i^t} \rfloor

= \lfloor \frac{N}{a_i^t} \rfloor + \lfloor \frac{N}{a_i^t} + \frac{1}{2} \rfloor – 2 \lfloor \frac{N}{a_i^t} \rfloor

= \lfloor \frac{N}{a_i^t} + \frac{1}{2} \rfloor – \lfloor \frac{N}{a_i^t} \rfloor

\leq 1

</span></p><p>Because we have <span data-katex-display="false">L = \lfloor log_{a_i}{2N} \rfloor</span>, then <span data-katex-display="false">v_i^{max} \leq \lfloor log_{a_i}{2N} \rfloor</span>.</p>
<h2>Find the upper limit for the partial sum of π series</h2>
<p>The next question is what particular <span data-katex-display="false">N</span> should we use for the partial sum to get the desired fractional digits. We can formalize our demand:</p>
<p><span data-katex-display="true">

\frac{b_M}{A_M} \cdot 10^n &lt; 1

</span></p><p>Because we pick only fractional part, then we need to take into account terms of series, which are lower than 1 when they are multiplied by <span data-katex-display="false">10^n</span>. Let’s try to solve that inequality. We would use another formula for the central binomial coefficient (it’s easy to derive it from the original statement):</p>
<p><span data-katex-display="true">

\left(\begin{array}{c}2n\\ n\end{array}\right)=\frac{4^n(2n-1)!!}{(2n)!!}

</span></p><p>And based on that, we can transform our π series term:</p>
<p><span data-katex-display="true">

\frac{M \cdot 2^M}{\left(\begin{array}{c}2M\\ M\end{array}\right)} \cdot 10^n

= \frac{M \cdot 2^M}{\left( \frac{4^M \cdot (2M – 1)!!}{2M!!} \right)} \cdot 10^n

= \frac{M \cdot 2M!!}{2^M \cdot (2M – 1)!!} \cdot 10^n

</span></p><p>We can limit part of the fraction:</p>
<p><span data-katex-display="true">

1 &lt; \frac{2M!!}{(2M – 1)!!} \leq M

</span></p><p>If you recall the definition of <span data-katex-display="false">x!!</span> operator, it would be straightforward to see why that part is less than <span data-katex-display="false">M</span> with a couple of exceptions (when <span data-katex-display="false">M</span> is less than 4). Soon enough we would switch to logarithms, so let’s use degrees:</p>
<p><span data-katex-display="true">

1 &lt; r \leq 2 \\[15px]

\frac{M^{r} \cdot 10^n}{2^M} &lt; 1

</span></p><p>Now we can calculate an estimation of <span data-katex-display="false">M</span>:</p>
<p><span data-katex-display="true">

\frac{M^r \cdot 10^n}{2^M} &lt; 1

\Rightarrow M^r \cdot 10^n &lt; 2^M

\Rightarrow log_{2}{M^r} + log_{2}{10^n} &lt; M

\Rightarrow r \cdot log_{2}{M} + n \cdot log_{2}{10} &lt; M

</span></p><p>It’s possible to solve it, but we don’t need to do that, because anyway, we need to have some <span data-katex-display="false">\epsilon</span> to retrieve more digits than 1 and to make sure that the fractional part has the necessary precision. So we can just add <span data-katex-display="false">r \cdot log_{2}{M}</span> to that <span data-katex-display="false">\epsilon</span>. For our requirements (<span data-katex-display="false">n \leq 2048</span>), that addition could be a small number, and whole <span data-katex-display="false">\epsilon</span> could be as small as 50. I picked 70 to have some spare room for imprecision in calculations with float numbers.</p>
<h2>Algorithm</h2>
<p>Just implement two loops: outer loop over prime numbers and inner loop to calculate <span data-katex-display="false">f_i</span> for particular <span data-katex-display="false">a_i</span>. There is important optimization – instead of computing factorials on each iteration, we use recurrent formulas: <span data-katex-display="false">A_k = (A_{k-1} \cdot (2k – 1)) \bmod m</span> and <span data-katex-display="false">b_k = (b_{k-1} \cdot k) \bmod m</span>. Also, we track current information about how many times we divide <span data-katex-display="false">A_k</span> and <span data-katex-display="false">b_k</span> by <span data-katex-display="false">a_i</span> to know the value of <span data-katex-display="false">v_{i,k}</span> and <span data-katex-display="false">u_{i,k}</span> that would be used for exponentiation of <span data-katex-display="false">a_i</span>.</p>
<p><span data-katex-display="true">

\begin{align*}

&amp;\begin{aligned}

&amp;N&amp;&amp;=\lfloor(n+\epsilon) \cdot log_{2}{10}\rfloor\\

&amp;D_n&amp;&amp;=0\\

\end{aligned}\\

&amp;for\:(a \in \mathbb{P} | 2 &lt; a &lt;2N)\:\{\\

&amp;\quad\begin{aligned}

&amp;vmax &amp;&amp;=\lfloor \log_{a}{2N} \rfloor \\

&amp;m&amp;&amp;=a^{vmax}\\

&amp;v&amp;&amp;=0\\

&amp;u&amp;&amp;=0\\

&amp;f&amp;&amp;=0\\

&amp;A&amp;&amp;=1\\

&amp;b&amp;&amp;=1\\

\end{aligned}\\

&amp;\quad for\:(k=2..N)\:\{\\

&amp;\quad\quad\begin{aligned}

&amp;b &amp;&amp;= \left( \frac{k}{a^{v(a,k)}} \cdot b \right) \bmod m\\

&amp;A &amp;&amp;= \left( \frac{2k-1}{a^{v(a,2k-1)}} \cdot A \right) \bmod m\\

&amp;u &amp;&amp;= u + v(a, k)\\

&amp;v &amp;&amp;= v + v(a, 2k-1)\\

\end{aligned}\\

&amp;\quad\quad if\:(v – u &gt; 0)\:\{\\

&amp;\quad\quad\quad f = (f + k \cdot b \cdot A^{-1} \cdot a^{vmax-v+u}) \bmod m\\

&amp;\quad\quad \}\\

&amp;\quad \}\\

&amp;\quad\begin{aligned}

&amp;d&amp;&amp;=(f \cdot 10^n) \bmod m\\

&amp;D&amp;&amp;=\left\{ D + \frac{d}{m} \right\} \\

\end{aligned}\\

&amp;\}

\end{align*}

</span></p><p>I am using JavaScript for a reference implementation because it’s easier to translate the working HLL code to assembly, rather than writing it from scratch:</p>
<pre data-enlighter-language="js" data-enlighter-theme="droide" data-enlighter-linenumbers="false">const getNinePiDigits = (n) =&gt; {
  const N = Math.trunc((n + 20) * Math.log(10) / Math.log(2));

  let digits = 0;
  for (const a of primes.filter((prime) =&gt; prime &gt; 2 &amp;&amp; prime &lt; 2 * N)) {
    const vmax = Math.trunc(Math.log(2 * N) / Math.log(a));
    const m = a ** vmax;

    let f = 0, A = 1, b = 1, v = 0, u = 0;
    for (let k = 2; k &lt;= N; k++) { 
      b = (b * (k / (a ** multiplicity(a, k)))) % m; 
      A = (A * ((2 * k - 1) / (a ** multiplicity(a, 2 * k - 1)))) % m; 
      u += multiplicity(a, k); 
      v += multiplicity(a, 2 * k - 1); 
      if (v - u &gt; 0) {
        f = (f + (k * b * modularInverse(A, m) * (a ** (vmax - v + u)))) % m;
      }
    }

    d = (f * modularPower(10, n, m)) % m;
    digits = (digits + (d / m)) % 1;
  }

  return Math.trunc(digits * 1e9).toString().padStart(9, &#39;0&#39;);
};
</pre>

<p>It has been enough to have just a compiler from assembly to bytecode for the relatively simple program from <a href="https://mark.engineer/2022/04/calculating-pi-digits-on-first-intel-microprocessor-intel-4004/">my previous article</a>. But from some point, it became more and more tedious to develop code. So I had to improve my dev experience and extend the <a href="https://github.com/markablov/i40xx">intel 40xx tool stack</a> with a few more tools.</p>
<h2>Pre-processor</h2>
<p>I wanted to have two features:</p>
<ul>
<li>ability to split source code by sub-modules</li>
<li>variables substitutions (a-la macroses)</li>
</ul>
<p>To support that I have added special directives and a pre-processor that searches only for those directives and outputs a single file with source code, that could be used by the compiler (and that could be pasted to the emulator UI).</p>
<p>Here is an example of a module, that implements some function (<code>foo.i4040</code>):</p>
<pre data-enlighter-language="asm" data-enlighter-theme="droide" data-enlighter-linenumbers="false">%define FOO_PARAM1_VAL1 0x5
%define FOO_PARAM1_VAL2 0xA
%define FOO_PARAM2_VAL1 D

foo:
  ...
  BBL 0
</pre>
<p>And module, that uses function <code>foo</code>:</p>
<pre data-enlighter-language="asm" data-enlighter-theme="droide" data-enlighter-linenumbers="false">%include &#34;foo.i4040&#34;

bar:
  FIM r0, $FOO_PARAM1_VAL1 . $FOO_PARAM2_VAL1
  JMS foo
  FIM r0, $FOO_PARAM1_VAL2 . 0
  JMS foo
  BBL 0
</pre>
<p>Macroses were very useful for memory organization. I have re-arranged the memory layout several times and changed variable placements in memory (for example, moved a variable that keeps <span data-katex-display="false">N</span> from memory register #5 to register #9). Without pre-processor I would have to search for numerical values and check if it’s related to memory operation or just regular numeral literal.</p>
<h2>Compiler and linker</h2>
<p>The first version of the compiler was very simple – sequentially picks an instruction, encodes it to bytecode, and appends it to the ROM image. When the whole bytecode is formed, the compiler updates references for jump instruction if labels have been used (here and later jump instructions include call instruction). But the Intel 40xx CPU has a few peculiarities about bytecode layout:</p>
<ul>
<li>Some jump instructions are short jumps. It means that they can only jump to locations, that are inside the same ROM page (0x100 bytes) as the instruction itself. For example, it’s possible to use such instructions for jumps from <code>0x2AA</code> to <code>0x255</code>, but not possible to <code>0x655</code>.</li>
<li>Short jumps have another specialty – they should not be placed at the last bytes of the ROM page. If the jump instruction is located at address <code>0x7FF</code> or <code>0x7FE</code> and tries to perform a short jump to <code>0x7BB</code>, the actual jump would be done to <code>0x8BB</code> because of how the CPU works.</li>
</ul>
<p>With the initial compiler, I solved those problems either by manual arrangement of routines or by padding problematic functions with <code>NOP</code> instructions to fix misalignments. It worked while the code size was not that large, but the code bloated, and doing all those refinements became a nightmare.</p>
<p>Other considerations for better multi-stage compilation were:</p>
<ul>
<li>Intel 4040 started to support two ROMs, and for big programs, we want to use both banks.</li>
<li>Need to be able to put particular routines to specific locations.</li>
</ul>
<p>Going to spend some time and dig into details about that two features, required from the compiler.</p>
<p>As I have mentioned before, it’s not that simple to jump from one ROM bank to another. You should do something like that:</p>
<pre data-enlighter-language="asm" data-enlighter-theme="droide" data-enlighter-linenumbers="false">__location(0x0:0x00)
entrypoint:
  JMS output
  DB1
  JMS foo
  HLT

output:
  LDM 0xF
  WMP
  BBL 0

__rom_bank(0x1)
foo:
  JMS output
  DB0
  NOP
  BBL 0
</pre>
<p>We can see here:</p>
<ul>
<li><code>entrypoint</code> is placed at bank #0, at location <code>0x000</code>, it’s the actual first instruction, that would be executed by the CPU after RESET</li>
<li><code>foo</code> is placed at bank #1 at a non-specified location, the linker would choose the best place for that block.</li>
<li>The <code>output</code> routine is shared between banks. Linker would have to duplicate that routine in both banks.</li>
<li><code>NOP</code> instruction before <code>BBL</code>. <code>DBx</code> instruction switches bank on the 3rd cycle, so we need to spend an extra cycle before the actual flow control instruction.</li>
</ul>
<p>We want to be able to specify location not only for entry point but for switch tables. The Intel 40xx ISA has instruction <code>JIN rX</code>, which jumps to address, contained by a register pair. It allows me to execute different code blocks, based on register value without necessary to have many comparisons. I have used that trick in several places, here is an example of optimized 4bit by 4bit division, when we have special routines to divide operands by 1, 2, 3, …:</p>
<pre data-enlighter-language="asm" data-enlighter-theme="droide" data-enlighter-linenumbers="false">__location(00:0x10)
div4x4_1:
  XCH rr12
  LDM 0x0
  XCH rr13
  BBL 0

# INPUT:
#   acc - dividend
#   rr10 - divisor
#   rr11 - 0x0
# OUTPUT:
#   rr12 - quotient
#   rr13 - reminder
__location(00:0x18)
div4x4:
  JIN r5

__location(00:0x20)
div4x4_2:
  RAR
  XCH rr12
  TCC
  XCH rr13
  BBL 0

...
</pre>
<p>The compilation pipeline from source code to ROM image has 4 stages:</p>
<ol>
<li>Preprocessing. Have described that stage in the previous paragraph.</li>
<li>Parses a source code using simple grammar and produces a list of encoded instructions with metadata (like the type of instruction or source code line number) and a list of references: if the instruction has a reference to the location of another instruction (jumps by label, for example), then we need to know that to update the reference in the final image.</li>
<li>Unites instructions into code blocks. These blocks are not always whole functions, but they could be smaller pieces of code. Even if instructions are semantically linked (implement the same function), they could be spread into the ROM and don’t have to be placed nearby. So the block is the smallest set of instructions that could be executed sequentially without a guaranteed jump (program counter change).</li>
<li>Now we have a list of blocks and references between blocks. Based on that, we form superblocks – a set of blocks which has short jumps to each other. They should be considered together, because we have extra limitations for their placements, while blocks with long references are untangled and could be placed in any relative locations from each other. Unfortunately, we can’t apply an algorithm that solves the classical <a href="https://en.wikipedia.org/wiki/Bin_packing_problem">bin packing problem</a>, because superblocks can cross ROM page boundaries, despite that they have short jumps:</li>
</ol>
<p><img decoding="async" src="https://i0.wp.com/mark.engineer/wp-content/uploads/2023/11/rom_layout.png?resize=210%2C266&amp;ssl=1" alt="" width="210" height="266" data-recalc-dims="1"/></p>
<p>That’s why I chose a simple and naive way – we have a cursor, that points to the ROM location and goes forward to the end of ROM. On each iteration, I try to insert some superblock at that cursor (and increase the cursor by superblock size), and if we can’t do it for any superblock, then move the cursor by 1 byte forward. Few notes:</p>
<ul>
<li>Blocks with fixed locations could be placed instantly, without any extra analysis.</li>
<li>Try to fit the biggest superblock first, usually, it’s harder to fit large routines.</li>
<li>There could be gaps between fixed blocks, so even if the ROM cursor is moving forward only, we can try to fill gaps with small blocks, before performing the main arrangement loop.</li>
</ul>
<p>The order of blocks inside the superblock also could vary and can affect the possibility of placement. So we need to check all permutations of blocks inside the superblock.</p>
<p>The amount of permutations is <span data-katex-display="false">n!</span> and the superblock could have 10+ blocks, hence checking all variants is a heavy operation that could take minutes. That’s why I have added a compilation cache – we know the best position and permutation for superblock. If it has not been changed, then we can reuse that stored information.</p>
<h2>Emulator and profiler</h2>
<p>I need a way to debug the program and its parts. It’s much easier to do with proper tools. I already had a simple Intel 4004 emulator, but I had to extend it a bit:</p>
<ul>
<li>Important to be able to use the emulator outside the browser. I wrote a bunch of tests to validate that even basic functions work correctly.</li>
<li>Added support of Intel 4040 features: new instructions, extended registers bank, multiple ROM banks.</li>
<li>Some tests require pre-defined RAM snapshots, so we need to be able to pass some initial RAM state, instead of clean RAM banks.</li>
<li>Another important feature was profiling. I wanted to understand, what functions consume a majority of the time. With emulation, it’s possible to have instruction-based profiles, but for me it was good enough to have function scope.</li>
<li>GUI started to support source maps. We want to be able to determine the source code line, based on the ROM address of currently executed instruction. Because the ROM layout is not that flat anymore, the linker should produce a source map.</li>
<li>Also I have added watchers to the GUI – you can declare variables for debug purposes, and watch how they are changing live. For instance, we can have a 2-digit number, with a lower digit in rr5, and a high digit placed in status character #0 from memory register #1. Even if it’s possible to find out the value of that number with registers and RAM panels, it could be not very easy. So you can specify watcher <code>[71]:s0,rr5</code> and see the value of that number while debugging the program.</li>
</ul>
<p><a href="https://i0.wp.com/mark.engineer/wp-content/uploads/2023/11/emulator.png?ssl=1"><img decoding="async" loading="lazy" src="https://i0.wp.com/mark.engineer/wp-content/uploads/2023/11/emulator.png?resize=1024%2C615&amp;ssl=1" alt="" width="1024" height="615" srcset="https://i0.wp.com/mark.engineer/wp-content/uploads/2023/11/emulator.png?resize=1024%2C615&amp;ssl=1 1024w, https://i0.wp.com/mark.engineer/wp-content/uploads/2023/11/emulator.png?resize=300%2C180&amp;ssl=1 300w, https://i0.wp.com/mark.engineer/wp-content/uploads/2023/11/emulator.png?resize=768%2C461&amp;ssl=1 768w, https://i0.wp.com/mark.engineer/wp-content/uploads/2023/11/emulator.png?resize=1536%2C923&amp;ssl=1 1536w, https://i0.wp.com/mark.engineer/wp-content/uploads/2023/11/emulator.png?resize=2048%2C1231&amp;ssl=1 2048w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"/></a></p>

<p>To be honest, I underestimated the computation complexity of the task. So my first implementation was relatively dumb and had almost no optimizations. But there are still a few points to mention.</p>
<h2>Preparation</h2>
<h4>Number limits</h4>
<p>At first, I determined the bit depth for numbers. The highest <span data-katex-display="false">n</span> is 2043, then <span data-katex-display="false">N</span> is less than 7000, and modulus <span data-katex-display="false">m</span> is no more than 14000. It means that for the majority of operations 14 bits (2^14 gives a high boundary as 16384 for numbers) are enough. But of course, I want to work with CPU words, so our target bit-width is 16 bits for almost all variables. That’s good because it fits to status characters of memory registers.</p>
<p>Let me remind you of the structure of RAM in Intel 40xx systems. We have up to 8 RAM banks. Each RAM bank consists of 16 memory registers. Each memory register is split into two parts: 16 main 4-bit characters and 4 status 4-bit characters. An important difference is how memory access is organized for different kinds of characters. In most cases, access to main characters is slower:</p>
<pre data-enlighter-language="asm" data-enlighter-theme="droide" data-enlighter-linenumbers="false">FIM r0, 0xF0   # loads 0xF0 to r0
SRC r0         # selects register F and main character 0
RDM            # loads the selected main character to the accumulator
XCH rr2        # rr2 = accumulator
FIM r0, 0xF1   # loads 0xF1 to r0
SRC r0         # selects register F and main character 1
RDM            # loads the selected main character to the accumulator
ADD rr2        # accumulator = main character 0 + main character 1
</pre>
<p>Status character registers could be accessed by a special set of instructions without necessary to select a new character every time:</p>
<pre data-enlighter-language="asm" data-enlighter-theme="droide" data-enlighter-linenumbers="false">FIM r0, 0xF0  # loads 0xF0 to r0
SRC r0        # selects register F and main character 0
RD0           # loads status character 0 to the accumulator
XCH rr2       # rr2 = accumulator
RD1           # loads status character 1 to the accumulator
ADD rr2       # accumulator = status character 0 + status character 1
</pre>
<p>That’s why storing variables inside status characters is better than storing them in main characters.</p>
<p>OK, now I know bit-depth and can make other estimations. Prime numbers could be computed once, using <a href="https://en.wikipedia.org/wiki/Sieve_of_Eratosthenes">sieve of Eratosthenes</a>. The rough estimate for the amount of prime digits below <span data-katex-display="false">2N</span> is 2000. How are we going to store them? We can use bitmap: if the bit on position <span data-katex-display="false">x</span> in RAM is set to 1, it means that <span data-katex-display="false">x</span> is prime. We have 10240 bits in RAM, while we need 14000 (high boundary for <span data-katex-display="false">2N</span>). But we don’t care about even numbers, they are never prime, except 2, which is out of our interest. Hence, we need just 7000 bits.</p>
<h4>Logarithms and float numbers</h4>
<p>What are the other tricky parts? Logarithms… I need to know <span data-katex-display="false">log_{2}{10}</span> for <span data-katex-display="false">N</span> computation. Even if I can calculate it just once, taking a logarithm is still a very hard operation for the CPU without float numbers and native division. Yes, I can just use a pre-calculated exact constant, but it would be against the rules. Instead of that, I use approximation: <span data-katex-display="false">\log_2{10}\approx\frac{93}{28}</span>. Precision should be enough. We are not afraid of overshooting <span data-katex-display="false">N</span>, it would just add more work, but would not affect correctness.</p>
<p>Another logarithm to evaluate is <span data-katex-display="false">log_{a}{2N}</span>. But, fortunately, we need just the integer part, so we can have a simple loop <span data-katex-display="false">v^{max} = \max {v: a^v &lt; 2N}</span>.</p>
<p>As I have mentioned, we don’t have float numbers, but <span data-katex-display="false">D</span> is the fractional part of the float number. I solved it by keeping that number in simple fixed decimal point form – just multiply every <span data-katex-display="false">d</span> by <span data-katex-display="false">10^{15}</span> to have 15 fractional digits. 9 digits would be our result and 6 digits to preserve precision to avoid cumulative rounding errors.</p>
<h4>Modular arithmetic</h4>
<p>Time to think about modular arithmetic. The simplest way would be just to perform an operation (multiplication/exponentiation) and then divide it by modulus to get a reminder. But I decided to do it a bit smarter – by using the binary method. There is a multiplication property of modular arithmetic:</p>
<p><span data-katex-display="true">

(a \cdot b) \bmod m=(a \bmod m \cdot b \bmod m) \bmod m

</span></p><p>Knowing that, we can write such recursive equation for <span data-katex-display="false">f(x, y) = (a \cdot b) \bmod m</span>:</p>
<p><span data-katex-display="true">

f(x, y) =

\begin{cases}

0 &amp; \text{if }b = 0\\

f(2 \cdot a \bmod m, b / 2) &amp; \text{if } b \text{ is even}\\

(a + f(a, b – 1)) \bmod m &amp; \text{if } b \text{ is odd}\\

\end{cases}

</span></p><p>A similar idea we can use for <a href="https://en.wikipedia.org/wiki/Modular_arithmetic#Example_implementations">modular exponentiation</a>:</p>
<p><span data-katex-display="true">

a^b \bmod m =

\begin{cases}

1 &amp; \text{if $b = 0$}\\

(a^\frac{b}{2})^2 \bmod m &amp; \text{if } b \text{ is even}\\

((a^\frac{b-1}{2})^2 \cdot a) \bmod m &amp; \text{if } b \text{ is odd}\\

\end{cases}

</span></p><p>The last operation is modular inversion. Because we can be sure that <span data-katex-display="false">A</span> and <span data-katex-display="false">m</span> are co-prime numbers, we can use <a href="https://en.wikipedia.org/wiki/Euler%27s_theorem">Euler’s theorem</a>:</p>
<p><span data-katex-display="true">

A^{\phi(m)} \equiv 1 \pmod m\\

A^{\phi(m)-1} \equiv A^{-1} \pmod m

</span></p><p>From definition <span data-katex-display="false">m = a^{vmax}</span>, so we can calculate Euler’s totient function easily:</p>
<p><span data-katex-display="true">

\phi(m) = \phi(a^{vmax}) = a^{vmax} – a^{vmax – 1}

</span></p><h2>Results</h2>
<p>How close that code would be to target 70 hours? Very, very far. I was not able to finish the emulation, but I used polynomial fit after computing ~800 digits to get some estimation. And it was oppressive <strong>14.5 years</strong>. Looks like I started a long journey to improve that time.</p>

<h2>Algorithm improvements</h2>
<h3>“Concurrent” computations</h3>
<p>Before digging into low-level optimizations, I wanted to examine the algorithm more scrupulously. I had no huge expectations because Fabrice Bellard has a brilliant mind and chances that he missed some obvious point were low. But he solved another problem than me – to determine the <em>nth</em> digit of π, while I was looking for <em>n</em> digits of π. Maybe we can reuse some computation results before runs? In-memory memoization cache could not be large: just around 300 entries if we are using 16bit numbers as cache keys and cache values. We need to do something smarter. The key observation is that <span data-katex-display="false">N</span> has no high limit for particular <span data-katex-display="false">n</span>. It just adds more precision, but <span data-katex-display="false">D</span> still would be correct. So we can compute common <span data-katex-display="false">f_i</span> for all digit positions below <span data-katex-display="false">n</span>, with <span data-katex-display="false">N</span> computed for highest required <span data-katex-display="false">n</span>. And only specific operation for different digit positions would be <span data-katex-display="false">D =\left\lbrace D + \frac{(f_i \cdot 10^{digitPosition}) \bmod m}{m} \right\rbrace</span>.</p>
<p>Because we still would compute <span data-katex-display="false">f_i</span> for high <span data-katex-display="false">N</span> at some point, then extra work would be just that unnecessary <span data-katex-display="false">D</span> updates for low digit positions when we don’t need such precision. We keep intermediate values for <span data-katex-display="false">D</span> as fixed-precision numbers with up to 15 digits after the decimal point and they need more space to be kept – whole 16 words (8 bytes). Hence, in the best case, we can keep 160 such numbers while we need 2052 / 9 = 228 entries. It’s not a big deal, because we can split computation into two intervals (0, 1026) and (1026, 2052). Of course, it would be better to run that loop just once, but memory limitations hit us again.</p>
<p>Small change is required for HLL implementation:</p>
<pre data-enlighter-language="js" data-enlighter-theme="droide" data-enlighter-linenumbers="false">    for (let i = 0; i &lt; digits.length; i++) {
      d = (f * modularPower(10, startingPosition + i * 9, m)) % m;
      digits[i] = (digits[i] + (d / m)) % 1;
    }
</pre>
<p>After applying that idea to my assembly code I have been pleased with <strong>85x</strong> improvement – <strong>64 days</strong> instead of many years. But still need to make it 20x times faster!</p>
<h3>Memory layout for prime numbers</h3>
<p>We started to store 100+ 8-byte numbers in memory and now we are running out of memory for our prime numbers bitmap. Let’s revisit it then.</p>
<p>Instead of a regular sieve, we can use <a href="https://en.wikipedia.org/wiki/Sieve_of_Eratosthenes#Segmented_sieve">segmented sieve</a>. The idea is to have an initial segment of prime numbers lower than <span data-katex-display="false">\sqrt{2N}</span> (let’s call it segment size) and be able to generate the following segments based on that initial data. Segment size equals 118, so we know two facts about the initial prime segment: 1) prime numbers fits 1 byte (2 words), and 2) there is less than 30 prime number lower than 118. Based on that, we need just 30 bytes for the initial segment.</p>
<p>The following prime segments can be organized in a very compact manner as well. The difference between the first and last prime numbers in the following segment is no more than segment size by definition. Hence, we can keep the lowest value of the segment as is (16bit number) and have a bitmap for 59 entries (again we don’t need even numbers to be represented in our map). So even if we spent the whole word for bitmap value it would take only 32 bytes in total.</p>
<h3>Fixed-precision numbers format</h3>
<p>We don’t keep <span data-katex-display="false">D</span> in BCD format (for example, in that format <code>1234</code> would be represented as <code>0x1234</code> in memory instead of <code>0x4D2</code>) because of memory limitations. So it makes less sense to have a decimal point instead of a hexadecimal point. Hence, instead of multiplying <span data-katex-display="false">D</span> by <span data-katex-display="false">10^{15}</span>, we can multiply it by <span data-katex-display="false">2^{50}</span>, which is just bit shift operation.</p>
<h3>Fast path for big primes</h3>
<p>I was still skeptical about the possibility of reaching such performance gain only with code optimizations, so I continued to investigate the basis of the algorithm. And quickly discovered that for primes bigger than <span data-katex-display="false">\sqrt{2N}</span> we have <span data-katex-display="false">v^{max} = 1</span>. It allowed me to cut a lot of edges. <span data-katex-display="false">v</span> for that case has a binary nature – it is either 0 or 1, but more exciting is that <span data-katex-display="false">v</span> alternates between two states with continuous sequences. <span data-katex-display="false">v</span> switches to 1 when <span data-katex-display="false">a_i | 2k-1</span> and then switches back to 0 when <span data-katex-display="false">a_i | k</span>. Here is a simple visualization of alternation.</p>
<p><img decoding="async" loading="lazy" src="https://i0.wp.com/mark.engineer/wp-content/uploads/2023/11/v_switch.png?resize=759%2C102&amp;ssl=1" alt="" width="759" height="102" srcset="https://i0.wp.com/mark.engineer/wp-content/uploads/2023/11/v_switch.png?w=759&amp;ssl=1 759w, https://i0.wp.com/mark.engineer/wp-content/uploads/2023/11/v_switch.png?resize=300%2C40&amp;ssl=1 300w" sizes="(max-width: 759px) 100vw, 759px" data-recalc-dims="1"/></p>
<p>The basic HLL code would look like that:</p>
<pre data-enlighter-language="js" data-enlighter-theme="droide" data-enlighter-linenumbers="false">  do {
    // iterate until next k, that satisfies (2 * k - 1) % a === 0
    for (; (2 * k - 1) % a !== 0; k++) {
      b = (b * k) % a;
      A = (A * (2 * k - 1)) % a;
    }

    // v becomes 1 here
    b = (b * k) % a;
    A = (A * ((2 * k - 1) / a)) % a;
    f = (f + modularInverse(A, a) * b * k) % a;
    k++;

    // iterate until next k, that satisfies k % a === 0
    for (; (k % a) !== 0; k++) {
      b = (b * k) % a;
      A = (A * (2 * k - 1)) % a;
      f = (f + modularInverse(A, a) * b * k) % a;
    }

    // now v becomes 0
    b = (b * (k / a)) % a;
    A = (A * (2 * k - 1)) % a;
    k++;
  } while (k &lt;= N);
</pre>
<p>We already excluded exponentiation of <span data-katex-display="false">a</span> and many unnecessary comparisons, but we can do better than that:</p>
<ul>
<li>We can get rid of division. The outer loop step is <span data-katex-display="false">a</span>, so <code>k / a</code> and <code>(2 * k - 1) / a</code> increments by 1 and 2 correspondingly for each outer loop iteration.</li>
<li>We don’t need exact values of <span data-katex-display="false">k</span> for computations, we can use <span data-katex-display="false">k \bmod a</span> to have faster modular multiplication with lower numbers.</li>
<li>At the beginning of outer loop we know that <span data-katex-display="false">k \bmod a = 1</span>, hence we have constant sequence of multiplications for <span data-katex-display="false">b</span> with <span data-katex-display="false">v = 0</span>. It could be calculated outside loop: <span data-katex-display="false">b_{v=0} = (\frac{a – 1}{2} + 1)! \bmod a</span>. Starting from <span data-katex-display="false">k \bmod a = \frac{a-1}{2} + 1</span> we are switching <span data-katex-display="false">v</span> to be 1.</li>
</ul>
<p>The improved (by performance, not by readability) version is:</p>
<pre data-enlighter-language="js" data-enlighter-theme="droide" data-enlighter-linenumbers="false">  let multiplierForZeroV = factorial(((a - 1) / 2) + 1) % a;
  let k = ((a - 1) / 2) + 1;
  let reducedCoefA = 3;

  do {
    // iterate until next k, that satisfies (2 * k - 1) % a === 0
    for (reducedCoefB = 2; reducedCoefB &lt;= (a - 1) / 2; reducedCoefB++) {
      A = (A * reducedCoefA) % a, reducedCoefA += 2;
    }
    b = (b * multiplierForZeroV) % a;

    // v becomes 1 here
    A = (A * multiplierA) % a, multiplierA += 2;
    f = (f + modularInverse(A, a) * b * reducedCoefB) % a;
    k++, reducedCoefB++;

    // iterate until next k, that satisfies k % a === 0
    reducedCoefA = 2;
    for (; reducedCoefB &lt; a; k++, reducedCoefB++) { 
      A = (A * reducedCoefA) % a, reducedCoefA += 2; 
      b = (b * reducedCoefB) % a; 
      f = (f + modularInverse(A, a) * b * reducedCoefB) % a; 
    } 
    // have a check of the loop boundary now to avoid redundant first loop 
    k += (a + 1) / 2; 
    // now v becomes 0 
    b = (b * multiplierB) % a, multiplierB++; 
    A = (A * reducedCoefA) % a, reducedCoefA += 2; 
    // try to keep the factor lower than &#34;a&#34; 
    if (reducedCoefA &gt; a) {
      // factor is incremented by 2, so it could be bigger than &#34;a&#34; just by 1
      reducedCoefA = 1;
    } else {
      A = (A * reducedCoefA) % a;
      reducedCoefA += 2;
    }
  } while (k &lt;= N);
</pre>
<p>It was a good observation, but it gave me just dozens of percents as a performance gain, while I need thousands. Time to look into basic operations.</p>
<h3>Profiling</h3>
<p>Usually, when you have performance problems you want to determine bottle-necks and hot code. So I started with gathering information about typical execution profiles for heavy computation routines. It was easy enough to produce stack traces, compatible with <a href="https://github.com/brendangregg/FlameGraph">flamegraph</a> tool.</p>
<p><a href="https://i0.wp.com/mark.engineer/wp-content/uploads/2023/11/flamegraph_noopt.png?ssl=1"><img decoding="async" loading="lazy" src="https://i0.wp.com/mark.engineer/wp-content/uploads/2023/11/flamegraph_noopt.png?resize=1024%2C158&amp;ssl=1" alt="" width="1024" height="158" srcset="https://i0.wp.com/mark.engineer/wp-content/uploads/2023/11/flamegraph_noopt.png?resize=1024%2C158&amp;ssl=1 1024w, https://i0.wp.com/mark.engineer/wp-content/uploads/2023/11/flamegraph_noopt.png?resize=300%2C46&amp;ssl=1 300w, https://i0.wp.com/mark.engineer/wp-content/uploads/2023/11/flamegraph_noopt.png?resize=768%2C119&amp;ssl=1 768w, https://i0.wp.com/mark.engineer/wp-content/uploads/2023/11/flamegraph_noopt.png?resize=1536%2C238&amp;ssl=1 1536w, https://i0.wp.com/mark.engineer/wp-content/uploads/2023/11/flamegraph_noopt.png?w=1900&amp;ssl=1 1900w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"/></a></p>
<p>Now I have a starting point. After each optimization, I re-evaluated the profile to determine target functions, that are worth checking.</p>
<h2>Modular inversion</h2>
<p>From the first flamegraph, it was very clear that I needed to do something with modular inversion. Looks like a “fast” implementation based on Euler’s theorem is not that fast. After I changed the algorithm to regular division-based <a href="https://en.wikipedia.org/wiki/Extended_Euclidean_algorithm#Modular_integers">extended Euclidean</a>, I got very promising numbers. But then I thought about <a href="https://en.wikipedia.org/wiki/Binary_GCD_algorithm">binary version</a> of the same algorithm. High-level code is simple:</p>
<pre data-enlighter-language="js" data-enlighter-theme="droide" data-enlighter-linenumbers="false">const modularInverse = (a, m) =&gt; {
  if (a === 1) {
    return 1;
  }

  let rx = a, ry = m;
  let v = 1, u = 0;

  while (rx % 2 === 0) {
    rx = rx &gt;&gt; 1;
    v = (v % 2 === 0) ? (v &gt;&gt; 1) : (v + m) &gt;&gt; 1;
  }

  while (ry &gt; 1) {
    if (ry % 2 === 0) {
      ry = ry &gt;&gt; 1;
    } else {
      if (ry &lt; rx) { 
        [rx, ry] = [ry, rx]; 
        [v, u] = [u, v]; 
      } 
      ry = (ry - rx) &gt;&gt; 1;
      u = (u - v) % m;
    }

    u = (u % 2 === 0) ? (u &gt;&gt; 1) : ((u + m) &gt;&gt; 1);
  }

  return u &lt; 0 ? (u + m) : u;
}
</pre>
<p>Translation to assembly was also straightforward. Maybe just one interesting point was about the halving negative numbers (all other functions operate only with positives). Surprisingly, it was more efficient in i40xx assembly than I thought:</p>
<pre data-enlighter-language="asm" data-enlighter-theme="droide" data-enlighter-linenumbers="false">  LD rr3       # load highest word of number
  RAL          # put sign bit to carry to be able to shift negative numbers
  LD rr3       # again load the highest word of the number
  RAR          # shift it right, but because carry stores sign a bit
               # it would be propagated back to the highest bit of word
  XCH rr3      # save updated word
  ...
</pre>
<p>I have not continued to develop a faster version even if it was possible by using <a href="https://www.researchgate.net/publication/304417579_Modular_Inverse_Algorithms_Without_Multiplications_for_Cryptographic_Applications">various tricks</a>. Some of them was easy enough to be implemented even with i40xx ISA.</p>
<h2>Modular exponentiation</h2>
<p>We are using that function in two places: to compute <span data-katex-display="false">10^x</span> when updating <span data-katex-display="false">D</span> and to compute <span data-katex-display="false">a^{v^{max} – v + u}</span>. Because we know that <span data-katex-display="false">x</span> is increasing by 9 at every iteration, we can avoid exponentiation with just 3 modular multiplication by 1000 (because our multiplication routine is working with 16bit numbers we can’t multiply by <span data-katex-display="false">10^9</span>):</p>
<pre data-enlighter-language="js" data-enlighter-theme="droide" data-enlighter-linenumbers="false">    let powered10 = modularPower(10, startingPosition, m);
    for (let i = 0; i &lt; digits.length; i++) {
      const d = (powered10 * f) % m;
      digits[i] = (digits[i] + (d / m)) % 1;
      powered10 = (powered10 * 1000 * 1000 * 1000) % m;
    }
</pre>
<p>Exponentiation also is used in cases when <span data-katex-display="false">v^{max} &gt; 1</span>. Even if now we know that there are not so many such cases we can improve it as well. We can limit <span data-katex-display="false">v^{max} &lt; \lfloor log_{a_0}{2N} \rfloor</span>, hence we have a power value no more than 7. Moreover, <span data-katex-display="false">a^{v^{max} – v + u} &lt; a^{v^{max}}</span>, so we don’t need <em>modular</em> exponentiation at all. And because we have just a maximum 7 values of <span data-katex-display="false">a^t</span>, we can store them into a small cache table.</p>
<h2>Division</h2>
<p>After I had added special flow for <span data-katex-display="false">v^{max} = 1</span>, amount of divisions decreased drastically, but I did division optimization before that change, so I left it in place.</p>
<h3>4bit x 4bit division</h3>
<p>The foundation of multi-word division is a 4bit x 4bit routine. Even naive code with a subtraction loop was not that slow:</p>
<pre data-enlighter-language="asm" data-enlighter-theme="droide" data-enlighter-linenumbers="false">div4x4:
  FIM r6, 0x00
div4x4_loop:
  SUB rr11
  JCN nc, div4x4_return
  CLC
  ISZ rr12, div4x4_loop
div4x4_return:
  ADD rr11
  XCH rr13
  CLC
  BBL 0
</pre>
<p>17 cycles on average for all combinations of dividend and divisor.</p>
<p>In the chapter, related to compiler and linker, I have shown an approach with 15 specific code blocks for 15 divisors (divide by 0?!). Some blocks were not able to fit in 0x10 bytes (the gap between two addresses in our switch table), but because of conditional jumps inside them, it was possible to arrange all cases on the same ROM page. That optimization cut 6 cycles from each function call. Not much, but it’s a 35% performance gain for that small routine.</p>
<h3>4bit x 4bit multiplication</h3>
<p>Another building block for division is 4bit x 4bit -&gt; 8bit multiplication. A naive implementation of 4×4 division was fast, but we can’t say the same for basic 4×4 multiplication. The addition of the first term in the loop, counted by the second term was not very efficient (~70 cycles on average). Then it is worth spending memory on the multiplication table! We are going to use a similar trick with the switch table to have 16 code blocks for 16 multipliers. Most of them would fetch data from memory, but we can implement cases for 0/1/2/8 multipliers by regular code to save some RAM.</p>
<pre data-enlighter-language="asm" data-enlighter-theme="droide" data-enlighter-linenumbers="false">__location(01:0x00)
mul4x4_0:
  FIM r6, 0x00                                         # low, high = 0
  BBL $BANK_WITH_VARIABLES

# INPUT:
#   acc - first factor (a)
#   rr10 - second factor (b)
#   rr11 - 0x0
# OUTPUT:
#   rr12 - low word of product
#   rr13 - high word of product
__location(01:0x08)
mul4x4:
  JIN r5

__location(01:0x10)
mul4x4_1:
  XCH rr12                                              # low  = a
  LDM 0x0
  XCH rr13                                              # high = 0
  BBL $BANK_WITH_VARIABLES

__location(01:0x20)
mul4x4_2:
  RAL
  XCH rr12
  TCC
  XCH rr13
  BBL $BANK_WITH_VARIABLES

__location(01:0x30)
mul4x4_3:
  XCH rr12
  LDM $BANK_WITH_MUL_TABLE_FOR_FACTOR_3
  DCL
  SRC r6
  RD2
  XCH rr12                                              # low
  RD3
  XCH rr13                                              # high
  BBL $BANK_WITH_VARIABLES
</pre>
<h3>16bit x 16bit division</h3>
<p>For multi-word division I have used well-known Knuth’s Algorithm <sup id="fnref-120-12"><a title="Read footnote." href="#fn-120-12">12</a></sup>. But I can make it more specific and have different code paths for combinations of dividend and divisor sizes. For instance, there is a case when both divisor and dividend are 3 words long or the dividend is 2 words long, but the divisor is just 1 word. We have just 10 combinations (divisor is always lower than dividend) and only 3 of them would require to follow Algorithm D: 16×8, 16×12, and 12×8 divisions. In all other cases, we can cut edges and perform more efficient calculations, without speculating over estimated quotient digits.</p>
<h2>Modular multiplication</h2>
<p>After all the improvements from previous chapters, modular multiplication became the main computation abyss – it occupied more than 60% of execution time. And I spent a lot of time polishing that operation. I have tried several approaches and some optimizations have been replaced by more efficient alternatives. I would describe the final form of that function.</p>
<h3>Algorithm</h3>
<p>There is a temptation to use the <a href="https://en.wikipedia.org/wiki/Montgomery_modular_multiplication">Montgomery form</a> to perform modular multiplications, especially because we can keep that form for our inner loop over <span data-katex-display="false">k</span> and perform conversion back just before computing chunks of digits. But due to Montgomery modular multiplication, we are doing 3 regular multiplications, and even with optimizations you would have to perform <span data-katex-display="false">\frac{13n^2}{8} + n</span> single-word multiplications<sup id="fnref-120-13"><a title="Read footnote." href="#fn-120-13">13</a></sup>, where <span data-katex-display="false">n</span> is the amount of words in number (<span data-katex-display="false">n = 4</span> in our case). So it means 30 4×4 multiplications, and each costs 12 cycles, which gives us an estimation for 360 cycles only for multiplications, and with 150 additions (formula from the same paper) it under-performs the current solution.</p>
<p>What about straightforward fast multiplication with modular reduction? It still requires at least 16 calls to 4×4 multiplication routines <sup id="fnref-120-14"><a title="Read footnote." href="#fn-120-14">14</a></sup> only for the multiplication step. And the reduction is much more costly. Not a solution. This paper also uses the Karatsuba algorithm for multiplication, but only for big numbers – for small values, this algorithm is worse than just regular scanning multiplication.</p>
<p>So we are going to use just regular binary multiplication, but with a bunch of low-level hacks:</p>
<pre data-enlighter-language="js" data-enlighter-theme="droide" data-enlighter-linenumbers="false">const modularMultiply = (a, b, m) =&gt; {
  let multipliedFactor = a;
  let result = 0;

  for (let shiftedFactor = b; shiftedFactor &gt; 0; shiftedFactor = shiftedFactor &gt;&gt; 1) {
    if (shiftedFactor &amp; 0x1 === 0x1) {
      result = (result + multipliedFactor) % m;
    }

    multipliedFactor = (multipliedFactor + multipliedFactor) % m;
  }

  return result;
};
</pre>
<h3>Lazy modular reduction</h3>
<p>The idea is that we don’t need to have a <code>result</code> to belong to the least residue system modulo <span data-katex-display="false">m</span> before returning the final value. It means that we don’t need to do modular reduction on each step. But we still need to perform that operation to prevent integer overflow (we operate with 16-bit numbers). Initially, modular reduction after each addition could be done with single subtraction: <code>a = a &gt; m ? a - m : a</code>, because each addend was less than <span data-katex-display="false">m</span>. With a lazy approach, it’s not true anymore and we have to do proper modular reduction. But we can do it a bit smarter – overflow could potentially happen with 4-word numbers only, so we can create a lookup table with pre-computed multipliers for <span data-katex-display="false">m</span>, that could be subtracted from the reduced number to make it smaller and still keep it positive and congruent. Of course, that reduction would not be perfect, but it’s good enough to prevent overflows. LUT is very simple:</p>
<p><span data-katex-display="true">

x = \overline{x_3 x_2 x_1 x_0}, x_3 \rightarrow \lfloor \frac{x_3 \cdot 16^{3}}{m} \rfloor \cdot m

</span></p><p>That correction would give us a rough value. But for a small modulus, it could be still a big divergence. We don’t want to create more LUTs (memory is not infinite), but we can keep one more number:</p>
<p><span data-katex-display="true">

\lfloor \frac{F00_{16}}{m} \rfloor \cdot m

</span></p><p>If the reduced number, even after subtracting the value from LUT is still more than <code>0x1000</code>, we can reduce it by that constant. It allows us to always have 3-word numbers after rough reduction.</p>
<p>By that moment in the article, I have described all caches and tables that would be kept in RAM, so I can show you the final memory layout:</p>
<p><img decoding="async" loading="lazy" src="https://i0.wp.com/mark.engineer/wp-content/uploads/2023/11/memory_3.png?resize=711%2C341&amp;ssl=1" alt="" width="711" height="341" srcset="https://i0.wp.com/mark.engineer/wp-content/uploads/2023/11/memory_3.png?w=711&amp;ssl=1 711w, https://i0.wp.com/mark.engineer/wp-content/uploads/2023/11/memory_3.png?resize=300%2C144&amp;ssl=1 300w" sizes="(max-width: 711px) 100vw, 711px" data-recalc-dims="1"/></p>
<p>Coloring legend:</p>
<ul>
<li>Green section is values for <span data-katex-display="false">D_n</span>. 114 registers.</li>
<li>Purple section – that LUT for modulus multipliers.</li>
<li>Red section – multiplication tables. Remind you, that we need just 2 words for table entry, so each RAM bank can have a table for 2 multipliers. 6 banks = 12 multipliers, we excluded tables 0, 1, 2, and 8 because we compute the result of multiplication by that factors in the code.</li>
<li>Orange section – table with pre-computed exponents for current prime number. Can keep up to 8 4-digit entries.</li>
<li>Yellow section – primeness map for the current segment, we use it to iterate through prime numbers.</li>
<li>Blue section – the initial segment of prime numbers. Can have up to 32 2-digit numbers.</li>
<li>White regions – free to use for variables.</li>
</ul>
<p>Pretty dense layout, but still better than in my previous work.</p>
<h3>Extend laziness for the whole computation routine</h3>
<p>Then I thought about the moment when we need to have the exact value from the least residue system modulo <span data-katex-display="false">m</span>. And looks like we need it only on the very last step – before calculating <span data-katex-display="false">\frac{d}{m}</span>. All other computations could be done with congruent numbers because they are performed via modular arithmetic. It reminds me of Montgomery form a bit – when you convert input values to that form, do different operations, and just before returning the final result you need to convert it back.</p>
<p>Not having exact values would affect performance in some way – values would be bigger than they could, so more unnecessary logic to execute. But overall benefit from avoiding proper modular reduction is much greater.</p>
<h3>Addition instead of subtraction</h3>
<p>Maybe it would sound strange, but addition requires fewer instructions than subtraction, because of the inverted carry flag (borrow for subtraction). When you subtract one number from another, the borrow flag would be set if there is <em>no borrow</em>. So if you are doing subtraction of multi-word numbers you need to inverse borrow flag by using extra instruction <code>CMC</code> to let the subsequent call of <code>SUB</code> use the right information about borrow from the previous digit:</p>
<pre data-enlighter-language="asm" data-enlighter-theme="droide" data-enlighter-linenumbers="false"># compute [rr0, rr1] = [rr0, rr1] - [rr2, rr3]
LD rr0
SUB rr2    # acc = rr0 - rr2, borrow flag is 0, if there was borrow
CMC        # inverse borrow flag
XCH rr0
LD rr1
SUB rr3    # acc = rr1 - rr3 - borrow, borrow flag is 0, if there was borrow
CMC        # inverse borrow flag
XCH rr3
</pre>
<p>Addition does not require to correct carry flag:</p>
<pre data-enlighter-language="asm" data-enlighter-theme="droide" data-enlighter-linenumbers="false"># compute [rr0, rr1] = [rr0, rr1] + [rr2, rr3]
LD rr0
ADD rr2    # acc = rr0 + rr2, carry flag is 1, if there was carry
XCH rr0
LD rr1
ADD rr3    # acc = rr1 + rr3 + carry, carry flag is 1, if there was carry
XCH rr3
</pre>
<p>We can replace the subtraction of <span data-katex-display="false">x</span> with the addition of <span data-katex-display="false">16^3 – x</span> (<a href="https://en.wikipedia.org/wiki/Two%27s_complement">two’s complement</a> for <span data-katex-display="false">x</span>) for 4-word numbers and the result would be the same but with less amount of instructions. It’s a generic observation, but it’s most profitable for modular multiplication because of how many times this operation is performed.</p>
<h3>Switch tables again</h3>
<p>We have no more than 16 loop iterations, so we can unroll the loop body and check each bit of the 2nd factor:</p>
<pre data-enlighter-language="asm" data-enlighter-theme="droide" data-enlighter-linenumbers="false">  # assume that rr6 has b[0]
  LDM 0x1
  AN6
  JCN z, mulMod_skipMultiplierBit0       # if ((b &gt;&gt; 0) &amp; 0x1)
  JMS mulMod_updateResult                #   res = res + multipliedFactor
mulMod_skipMultiplierBit0:
  JMS mulMod_updateMultipliedFactor      # multipliedFactor = multipliedFactor * 2

  LDM 0x2
  AN6
  JCN z, mulMod_skipMultiplierBit1       # if ((b &gt;&gt; 1) &amp; 0x1)
  JMS mulMod_updateResult                #   res = res + multipliedFactor
mulMod_skipMultiplierBit1:
  JMS mulMod_updateMultipliedFactor      # multipliedFactor = multipliedFactor * 2

  # ... 14 more checks for particular bits
</pre>
<p>But we can go further and for specific 4-bit words we know the sequence of operations. For instance here are <code>res</code> and <code>multpliedFactor</code> updates, when the current digit of factor is 5:</p>
<pre data-enlighter-language="asm" data-enlighter-theme="droide" data-enlighter-linenumbers="false">__location(0x2:0x50)
mulMod_processNibble_5:                   # 0b0101
  JMS mulMod_updateResult
  JMS mulMod_updateMultipliedFactor
  JMS mulMod_updateMultipliedFactor
  JMS mulMod_updateResult
  JMS mulMod_updateMultipliedFactor
  JUN mulMod_updateMultipliedFactor
</pre>
<p>We can extend that idea and have another switch table for the last digit because we don’t need to sustain <code>multpliedFactor</code> after we process the highest non-zero bit:</p>
<pre data-enlighter-language="asm" data-enlighter-theme="droide" data-enlighter-linenumbers="false">__location(0x3:0x50)
mulMod_processLastNibble_5:                   # 0b0101
  JMS mulMod_updateResult
  JMS mulMod_updateMultipliedFactor
  JMS mulMod_updateMultipliedFactor
  JUN mulMod_updateResultLast
</pre>
<h3>Perform 3 or 4 consequential multiplied factor updates as a single operation</h3>
<p>The last optimization was trivial – we can compute <code>16 * multipliedFactor</code> and <code>8 * multipliedFactor</code> by using word or bit shifts. But need to check that we would not overflow 16bit. If there is such risk, then we need to do a fallback and call <code>mulMod_updateMultipliedFactor</code> several times.</p>
<h3>Merge subroutines</h3>
<p>Often after the temporal result update, we need to update the multiplied factor and in the code we have such snippets:</p>
<pre data-enlighter-language="asm" data-enlighter-theme="droide" data-enlighter-linenumbers="false">  JMS mulMod_updateResult
  JMS mulMod_updateMultipliedFactor
</pre>
<p>The idea is to have a single routine <code>mulMod_updateResultAndFactor</code> that has combined code from <code>mulMod_updateResult</code> and <code>mulMod_updateMultipliedFactor</code>. But why it’s better? Math is simple – we had 2 subroutine calls and 2 returns from them, with that change we would have 1 subroutine call and 1 return. It allows us to save 3 cycles for each such case. It could sound like a very marginal number, but please take into account that <code>mulMod</code> takes 60% of the whole execution time and it’s a relatively small function, so every non-executed instruction wins us several minutes.</p>
<h3>Faster check about potential overflow of multiplied factor</h3>
<p>As I have mentioned before, we reduce the multiplied factor only if it could overflow our 16-bit variable. To check potential overflow, a very simple reasoning is used: because the multiplied factor is doubled, we can check that the highest nibble is always less than <code>0x8</code></p>
<pre data-enlighter-language="asm" data-enlighter-theme="droide" data-enlighter-linenumbers="false">  XCH rr2                                           # multipliedFactor = multipliedFactor + multipliedFactor
  AN7                                               # check if previous value of multipliedFactor[3] &lt; 4, then new multipliedFactor[3] &lt; 8
  JCN z, mulMod_updateResultAndFactor_return        # if (multipliedFactor[3] &lt; 0x8)
</pre>
<p>This is a small and efficient check – just 3 cycles (<code>JCN</code> instruction takes 2 machine cycles to execute). But every cycle matters, that’s why another trick I have used – replace the <code>AN7/JCN</code> pair with single instruction <code>JIN</code>. We occupy another ROM page with a switch table. <code>JIN r0</code> jumps to address, encoded in <code>r0</code>, and if <code>rr0</code> represents the most significant digit of multiplied factor, then we can split code execution into two paths: when <code>rr0 &lt; 0x8</code> and <code>rr0 &gt;= 0x8</code>. Of course, it&#39;s very inefficient in terms of ROM space, but we still had some room.</p>
<pre data-enlighter-language="asm" data-enlighter-theme="droide" data-enlighter-linenumbers="false">  JIN r1

__location(0x4:0x00)
mulMod_updateMultipliedFactor_factor0:
  BBL 0

__location(0x4:0x10)
mulMod_updateMultipliedFactor_factor1:
  BBL 0

...

__location(0x4:0x80)
mulMod_updateMultipliedFactor_factor8:
  SRC r1
  RD0
  ADD rr0
  XCH rr0
  RD1
  ADD rr1
  XCH rr1
  RD2
  ADD rr4
  XCH rr4
  RD3
  ADD rr2
  XCH rr2
  CLC
  BBL 0

...
</pre>
<h3>Optimizations that have been removed from the final code</h3>
<p>There were few working ideas, but because of different reasons that are not present in the code (mostly because other optimizations were better and because of ROM space):</p>
<ul>
<li>Special code path for 12-bit modulus. Because at some moment I have stopped to keep variables less than <span data-katex-display="false">m</span>, this separation by modulus size became useless.</li>
<li>Rough comparison of numbers with modulus. Before lazy reduction, we wanted to check if a number is bigger than <span data-katex-display="false">m</span> to do subtraction. This comparison was costly (because it was subtraction itself and if the operand was lower than <span data-katex-display="false">m</span>, this operation was just a waste of time). To perform a rough comparison we could use another lookup table:</li>
</ul>
<pre data-enlighter-language="asm" data-enlighter-theme="droide" data-enlighter-linenumbers="false">SRC rX      # first register in register pair contains the address of LUT, second register - multipliedFactor[3]
RDM         # read isLessThanModulus = LUT[multipliedFactor[3]]
JCN z, ret  # return if (isLessThanModulus)
</pre>
<p>But with lazy reduction, we don&#39;t care anymore if the number would be higher than the modulus.</p>
<ul>
<li>Another idea was to avoid unnecessary subtractions was to keep temporal result as negative. We can easily detect a sign of the number, and if it becomes positive, then just subtract the modulus. Before returning, always add <span data-katex-display="false">m</span>.</li>
<li>The amount of performed operations depends on the most significant one bit of 2nd factor. So we want to use the lowest factor as the shift factor. It requires swapping operands if 2nd factor is bigger than 1st. It is good optimization, but the results were marginal - it was hard to choose multiplications that could use these features.</li>
<li>We could have a bit finer reduction even for the lazy version - add another lookup table for numbers less than <code>0x1000</code>. But it requires more RAM and helped a lot only with a small modulus.</li>
</ul>
<h2>Results on emulator</h2>
<p>After all that jiggery-pockery, the whole program finished by 69h 29m 02s and I even got the right digits for π. Great success. Here is one of the latest flamegraphs.</p>
<p><a href="https://i0.wp.com/mark.engineer/wp-content/uploads/2023/11/flamegraph_final.png?ssl=1"><img decoding="async" loading="lazy" src="https://i0.wp.com/mark.engineer/wp-content/uploads/2023/11/flamegraph_final.png?resize=1024%2C158&amp;ssl=1" alt="" width="1024" height="158" srcset="https://i0.wp.com/mark.engineer/wp-content/uploads/2023/11/flamegraph_final.png?resize=1024%2C158&amp;ssl=1 1024w, https://i0.wp.com/mark.engineer/wp-content/uploads/2023/11/flamegraph_final.png?resize=300%2C46&amp;ssl=1 300w, https://i0.wp.com/mark.engineer/wp-content/uploads/2023/11/flamegraph_final.png?resize=768%2C119&amp;ssl=1 768w, https://i0.wp.com/mark.engineer/wp-content/uploads/2023/11/flamegraph_final.png?resize=1536%2C238&amp;ssl=1 1536w, https://i0.wp.com/mark.engineer/wp-content/uploads/2023/11/flamegraph_final.png?w=1900&amp;ssl=1 1900w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"/></a></p>
<p>Now it&#39;s time to run it on real hardware.</p>

<p>I used almost the <a href="https://github.com/markablov/i4040-sbc/tree/main/schematic">same schematic</a> as for my previous project. The main differences are:</p>
<ul>
<li>Solder the stm32 chip in place with all necessary auxiliary components, instead of using a stm32 board, plugged in a DIP socket into the main board.</li>
<li>Single USB-based power source instead of external 15V.</li>
<li>Replace the UART interface with USB.</li>
</ul>
<p>Other than that design is almost identical: LM339 and CD40109 are used as level shifters.</p>
<p><a href="https://i0.wp.com/mark.engineer/wp-content/uploads/2023/11/schematic.png?ssl=1"><img decoding="async" loading="lazy" src="https://i0.wp.com/mark.engineer/wp-content/uploads/2023/11/schematic.png?resize=1024%2C710&amp;ssl=1" alt="" width="1024" height="710" srcset="https://i0.wp.com/mark.engineer/wp-content/uploads/2023/11/schematic.png?resize=1024%2C710&amp;ssl=1 1024w, https://i0.wp.com/mark.engineer/wp-content/uploads/2023/11/schematic.png?resize=300%2C208&amp;ssl=1 300w, https://i0.wp.com/mark.engineer/wp-content/uploads/2023/11/schematic.png?resize=768%2C533&amp;ssl=1 768w, https://i0.wp.com/mark.engineer/wp-content/uploads/2023/11/schematic.png?resize=1536%2C1065&amp;ssl=1 1536w, https://i0.wp.com/mark.engineer/wp-content/uploads/2023/11/schematic.png?resize=2048%2C1420&amp;ssl=1 2048w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"/></a></p>

<p>Again, the <a href="https://github.com/markablov/i4040-sbc/tree/main/firmware">core of firmware</a> has been inherited from the original i4004-sbc board, but I had to make a few corrections.</p>
<p>Intel 4040 memory interface is a bit more complex and has an extra pin to select the ROM bank. That&#39;s why we have to do more stuff in between cycles. Additionally, the i4004-sbc board was configured to run on the lowest specified clock boundary of the Intel 4004 CPU - 625kHz, while I need the highest possible frequency (740kHz) to fit into my tight target timing.</p>
<p>At some moment I found out that I couldn&#39;t use the clocking timer (stm32 timer that produces clocks for the CPU) interrupt, because of latencies. I switched to a simple pin polling inside the main loop:</p>
<pre data-enlighter-language="c" data-enlighter-theme="droide" data-enlighter-linenumbers="false">  while ((OUT_4040_PHI1_GPIO_Port-&gt;IDR &amp; OUT_4040_PHI1_Pin) == OUT_4040_PHI1_Pin);

  OUT_TEST1_GPIO_Port-&gt;ODR ^= OUT_TEST1_Pin;
  handleCyclePhi1Falling();
  OUT_TEST1_GPIO_Port-&gt;ODR ^= OUT_TEST1_Pin;
</pre>
<p>Pin toggling is here to track how much time the stm32 spends inside a subcycle.</p>
<p>Another consideration was the USB interface instead of UART. Interrupts had to be disabled due i4004 program run, because of very accurate timings - each subcycle is 1350ns long, and stm32 had to fit into that window. With 168Mhz frequency for the stm32 core, we have just 200 spare stm32 cycles to read pins, perform necessary calculations, and set output pins.</p>
<p>So all interaction with the PC is frozen after the <code>START</code> command with ROM dump is received. I/O instructions from intel 4040 are tracked and logged into the in-memory buffer. When the CPU reaches a halt state (new <code>HLT</code> instruction), we send the accumulated buffer with output to the controlling program on the PC.</p>

<p>After fixing all issues with hardware and firmware, I was able to run i4040 programs. At first, I found out that I made a heart-breaking mistake in my calculations due to tests on the emulator - I used the wrong coefficient to compute the estimated running time, based on cycle count: <code>95000 cycles/sec</code> instead of <code>92500 cycles/sec</code>. It meant that the real running time on the real i4040 was just a bit more than the target 70 hours, so I had to return to the source code and find even trickier optimizations.</p>
<p>Out of interest, I started with the smaller task: computation of the first 255 digits of π.</p>
<pre data-enlighter-language="raw" data-enlighter-theme="droide" data-enlighter-linenumbers="false">[2023-10-31T12:08:05.527Z] START command has been received, RAM dump size is 8192 bytes
[2023-10-31T13:13:08.988Z] Program has been finished
[2023-10-31T13:13:08.994Z] Instruction cycles processed = 00000000158651E4
[2023-10-31T13:13:08.995Z] Output from i4040 (263 nibbles):
[2023-10-31T13:13:08.995Z] 3 1 4 1 5 9 2 6 5 3 5 8 9 7 9 3 2 3 8 4 6 2 6 4 3 3 8 3 2 7 9 5 0 2 8 8 4 1 9 7 1 6 9 3 9 9 3 7 5 1 0 5 8 2 0 9 7 4 9 4 4 5 9 2 3 0 7 8 1 6 4 0 6 2 8 6 2 0 8 9 9 8 6 2 8 0 3 4 8 2 5 3 4 2 1 1 7 0 6 7
[2023-10-31T13:13:08.995Z] 9 8 2 1 4 8 0 8 6 5 1 3 2 8 2 3 0 6 6 4 7 0 9 3 8 4 4 6 0 9 5 5 0 5 8 2 2 3 1 7 2 5 3 5 9 4 0 8 1 2 8 4 8 1 1 1 7 4 5 0 2 8 4 1 0 2 7 0 1 9 3 8 5 2 1 1 0 5 5 5 9 6 4 4 6 2 2 9 4 8 9 5 4 9 3 0 3 8 1 9
[2023-10-31T13:13:08.995Z] 6 4 4 2 8 8 1 0 9 7 5 6 6 5 9 3 3 4 4 6 1 2 8 4 7 5 6 4 8 2 3 3 7 8 6 7 8 3 1 6 5 2 7 1 2 0 1 9 0 9 1 4 5 6 4 8 5 6 6 9 2 3 F
</pre>
<p>As you can see, it took 01hr 05m 03s in comparison with 03hr 31m 13s from the run of the spigot algorithm on i4004. That&#39;s not a fair comparison of any kind, because CPU frequencies have been different, and more importantly is that I spent no time on optimization in the previous project. But still was kinda curious to see that numbers.</p>
<p>And finally, I started computation of 2048+ digits with ETA as a bit less than 70hrs. I have prepared an Intel 4040 CPU with a couple of tiny radiators and it successfully finished the job:</p>
<p><a href="https://i0.wp.com/mark.engineer/wp-content/uploads/2023/11/final_output.png?ssl=1"><img decoding="async" loading="lazy" src="https://i0.wp.com/mark.engineer/wp-content/uploads/2023/11/final_output.png?resize=1024%2C228&amp;ssl=1" alt="" width="1024" height="228" srcset="https://i0.wp.com/mark.engineer/wp-content/uploads/2023/11/final_output.png?resize=1024%2C228&amp;ssl=1 1024w, https://i0.wp.com/mark.engineer/wp-content/uploads/2023/11/final_output.png?resize=300%2C67&amp;ssl=1 300w, https://i0.wp.com/mark.engineer/wp-content/uploads/2023/11/final_output.png?resize=768%2C171&amp;ssl=1 768w, https://i0.wp.com/mark.engineer/wp-content/uploads/2023/11/final_output.png?resize=1536%2C342&amp;ssl=1 1536w, https://i0.wp.com/mark.engineer/wp-content/uploads/2023/11/final_output.png?resize=2048%2C456&amp;ssl=1 2048w, https://i0.wp.com/mark.engineer/wp-content/uploads/2023/11/final_output.png?w=3000&amp;ssl=1 3000w" sizes="(max-width: 1000px) 100vw, 1000px" data-recalc-dims="1"/></a></p>
<p>The final time is 69h 28m 31s and my journey completes here.</p>
<p>PS: The attentive reader could notice that the time from the hardware run is different from the emulator, even if the amount of executed cycles is close. It&#39;s because the clock signal, generated from stm32 timers is not 100% accurate, and the output frequency is about 740.1kHz, which is higher than the specified 740kHz. So I would say that the Intel 4040 even got overclocked.</p>


</div></div>
  </body>
</html>
