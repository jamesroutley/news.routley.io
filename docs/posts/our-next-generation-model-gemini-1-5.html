<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.google/technology/ai/google-gemini-next-generation-model-february-2024/">Original</a>
    <h1>Our next-generation model: Gemini 1.5</h1>
    
    <div id="readability-page-1" class="page"><article ng-init="drawerToggle = {&#39;open&#39;: true}">

    
    


<section data-analytics-module="{
  &#34;module_name&#34;: &#34;Article Hero&#34;,
  &#34;section_header&#34;: &#34;Our next\u002Dgeneration model: Gemini 1.5&#34;
}">
  
</section>


    

    
      

<div data-analytics-module="{
    &#34;module_name&#34;: &#34;Hero Menu&#34;,
    &#34;section_header&#34;: &#34;Our next\u002Dgeneration model: Gemini 1.5&#34;
  }">
  <div>
    <div>
      
      
        <p>
          The model delivers dramatically enhanced performance, with a breakthrough in long-context understanding across modalities.
        </p>
      
    </div>
  </div>
  
</div>

    

    
      







<div>
  <div>
    <figure>
      <div>
  <p><img srcset="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/final_gemini_1.5_blog_header_2096x1182-1.gif 600w, https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/final_gemini_1.5_blog_header_2096x1182-1.gif 1200w, https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/final_gemini_1.5_blog_header_2096x1182-1.gif 1600w" sizes="(max-width: 599px) 100vw, (max-width: 1023px) 600px, 1024px" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_images/final_gemini_1.5_blog_header_2096x1182-1.gif" fetchpriority="high" alt="The word “Gemini 1.5” appears in a blue gradient against a black background."/>
  </p>
</div>

      
    </figure>
  </div>
</div>


    

    
    <section>
      <div>
        
          
            
          
          
          <div data-reading-time="true" data-component="uni-drop-cap|uni-tombstone">

            
              


<google-read-aloud-player data-analytics-module="{
        &#34;event&#34;: &#34;module_impression&#34;,
        &#34;module_name&#34;: &#34;ai_audio&#34;,
        &#34;section_header&#34;: &#34;Our next\u002Dgeneration model: Gemini 1.5&#34;
    }" data-date-modified="2024-02-15T15:43:59.395802+00:00" data-progress-bar-style="half-wave" data-api-key="AIzaSyBLT6VkYe-x7sWLZI2Ep26-fNkBKgND-Ac" data-article-style="style9" data-tracking-ids="G-HGNBTNCHCQ,G-6NKTLKV14N" data-voice-list="en.ioh-pngnat:Cyan,en.usb-pngnat:Lime" data-layout-style="style1" data-highlight-mode="word-over-paragraph" data-highlight-text-color="#000000" data-highlight-word-background="#8AB4F8" data-highlight-paragraph-background="#D2E3FC" data-background="linear-gradient(180deg, #F1F3F4 0%, #F8F9FA 100%)" data-foreground-color="#202124" data-font="600 16px Google Sans, sans-serif" data-box-shadow="0px 1px 3px 1px rgba(60, 64, 67, 0.15)">
</google-read-aloud-player>




            

            
            
<!--article text-->

  
    

  

  
    <div data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Our next\u002Dgeneration model: Gemini 1.5&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><p data-block-key="k1g9k"><i>A note from Google and Alphabet CEO Sundar Pichai:</i></p><p data-block-key="43i75">Last week, we rolled out our most capable model, Gemini 1.0 Ultra, and took a significant step forward in making Google products more helpful, starting with <a href="https://blog.google/technology/ai/google-gemini-update-sundar-pichai-2024/" rt-link-type="external">Gemini Advanced</a>. Today, developers and Cloud customers can begin building with 1.0 Ultra too — with our Gemini API in <a href="https://aistudio.google.com/" rt-link-type="external">AI Studio</a> and in <a href="https://cloud.google.com/vertex-ai" rt-link-type="external">Vertex AI</a>.</p><p data-block-key="ebks5">Our teams continue pushing the frontiers of our latest models with safety at the core. They are making rapid progress. In fact, we’re ready to introduce the next generation: Gemini 1.5. It shows dramatic improvements across a number of dimensions and 1.5 Pro achieves comparable quality to 1.0 Ultra, while using less compute.</p><p data-block-key="aa73f">This new generation also delivers a breakthrough in long-context understanding. We’ve been able to significantly increase the amount of information our models can process — running up to 1 million tokens consistently, achieving the longest context window of any large-scale foundation model yet.</p><p data-block-key="31sii">Longer context windows show us the promise of what is possible. They will enable entirely new capabilities and help developers build much more useful models and applications. We’re excited to offer a limited preview of this experimental feature to developers and enterprise customers. Demis shares more on capabilities, safety and availability below.</p><p data-block-key="5ecmf">— Sundar</p></div>
      </div>
    </div>
  

  
    

  

  
    <div data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Our next\u002Dgeneration model: Gemini 1.5&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><h2 data-block-key="k1g9k">Introducing Gemini 1.5</h2><p data-block-key="f3142"><i>By Demis Hassabis, CEO of Google DeepMind, on behalf of the Gemini team</i></p><p data-block-key="chshj">This is an exciting time for AI. New advances in the field have the potential to make AI more helpful for billions of people over the coming years. Since <a href="https://blog.google/technology/ai/google-gemini-ai/" rt-link-type="external">introducing Gemini 1.0</a>, we’ve been testing, refining and enhancing its capabilities.</p><p data-block-key="bpk1l">Today, we’re announcing our next-generation model: Gemini 1.5.</p><p data-block-key="cq31g">Gemini 1.5 delivers dramatically enhanced performance. It represents a step change in our approach, building upon research and engineering innovations across nearly every part of our foundation model development and infrastructure. This includes making Gemini 1.5 more efficient to train and serve, with a new <a href="https://arxiv.org/abs/1701.06538" rt-link-type="external">Mixture-of-Experts</a> (MoE) architecture.</p><p data-block-key="ei3s7">The first Gemini 1.5 model we’re releasing for early testing is Gemini 1.5 Pro. It’s a mid-size multimodal model, optimized for scaling across a wide-range of tasks, and <a href="https://goo.gle/GeminiV1-5" rt-link-type="external">performs at a similar level to 1.0 Ultra</a>, our largest model to date. It also introduces a breakthrough experimental feature in long-context understanding.</p><p data-block-key="73fdi">Gemini 1.5 Pro comes with a standard 128,000 token context window. But starting today, a limited group of developers and enterprise customers can try it with a context window of up to 1 million tokens via <a href="https://aistudio.google.com/" rt-link-type="external">AI Studio</a> and <a href="https://cloud.google.com/vertex-ai" rt-link-type="external">Vertex AI</a> in private preview.</p><p data-block-key="2n70l">As we roll out the full 1 million token context window, we’re actively working on optimizations to improve latency, reduce computational requirements and enhance the user experience. We’re excited for people to try this breakthrough capability, and we share more details on future availability below.</p><p data-block-key="3k946">These continued advances in our next-generation models will open up new possibilities for people, developers and enterprises to create, discover and build using AI.</p></div>
      </div>
    </div>
  

  
    







  
      <div data-analytics-module="{
          &#34;module_name&#34;: &#34;Inline Images&#34;,
          &#34;section_header&#34;: &#34;Our next\u002Dgeneration model: Gemini 1.5&#34;
        }">
  

  <p>

      
      
        
          <video tabindex="0" autoplay="" loop="" muted="" playsinline="" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/final_tokens_scale_animated_3840x2300.mp4" type="video/mp4" title="Animation comparing the context lengths of leading foundation models, listing Gemini 1.0 Pro at 32,000 tokens, GPT-4 Turbo at 128,000 tokens, Claude 2.1 at 200,000 tokens, and Gemini 1.5 Pro at 1 million tokens and up to 10 million tokens tested in research." alt="final tokens animation">
            Video format not supported
          </video>
        
      
    
    </p>
    
      <figcaption><p data-block-key="vi55e">Context lengths of leading foundation models</p></figcaption>
    
  
    </div>
  



  

  
    

  

  
    <div data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Our next\u002Dgeneration model: Gemini 1.5&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><h2 data-block-key="k1g9k">Highly efficient architecture</h2><p data-block-key="5l1m">Gemini 1.5 is built upon our leading research on <a href="https://blog.research.google/2017/08/transformer-novel-neural-network.html" rt-link-type="external">Transformer</a> and <a href="https://arxiv.org/abs/1701.06538" rt-link-type="external">MoE</a> architecture. While a traditional Transformer functions as one large neural network, MoE models are divided into smaller &#34;expert” neural networks.</p><p data-block-key="bofgb">Depending on the type of input given, MoE models learn to selectively activate only the most relevant expert pathways in its neural network. This specialization massively enhances the model’s efficiency. Google has been an early adopter and pioneer of the MoE technique for deep learning through research such as <a href="https://arxiv.org/abs/1701.06538" rt-link-type="external">Sparsely-Gated MoE</a>, <a href="https://arxiv.org/abs/2006.16668" rt-link-type="external">GShard-Transformer</a>, <a href="https://arxiv.org/abs/2101.03961" rt-link-type="external">Switch-Transformer,</a> <a href="https://blog.research.google/2019/10/exploring-massively-multilingual.html" rt-link-type="external">M4</a> and more.</p><p data-block-key="829je">Our latest innovations in model architecture allow Gemini 1.5 to learn complex tasks more quickly and maintain quality, while being more efficient to train and serve. These efficiencies are helping our teams iterate, train and deliver more advanced versions of Gemini faster than ever before, and we’re working on further optimizations.</p></div>
      </div>
    </div>
  

  
    

  

  
    <div data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Our next\u002Dgeneration model: Gemini 1.5&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><h2 data-block-key="k1g9k">Greater context, more helpful capabilities</h2><p data-block-key="4m4dc">An AI model’s “context window” is made up of tokens, which are the building blocks used for processing information. Tokens can be entire parts or subsections of words, images, videos, audio or code. The bigger a model’s context window, the more information it can take in and process in a given prompt — making its output more consistent, relevant and useful.</p><p data-block-key="7l6jt">Through a series of machine learning innovations, we’ve increased 1.5 Pro’s context window capacity far beyond the original 32,000 tokens for Gemini 1.0. We can now run up to 1 million tokens in production.</p><p data-block-key="djuni">This means 1.5 Pro can process vast amounts of information in one go — including 1 hour of video, 11 hours of audio, codebases with over 30,000 lines of code or over 700,000 words. In our research, we’ve also successfully tested up to 10 million tokens.</p><h3 data-block-key="9id65">Complex reasoning about vast amounts of information</h3><p data-block-key="572lb">1.5 Pro can seamlessly analyze, classify and summarize large amounts of content within a given prompt. For example, when given the 402-page transcripts from Apollo 11’s mission to the moon, it can reason about conversations, events and details found across the document.</p></div>
      </div>
    </div>
  

  
    
  
    


<div data-analytics-module="{
    &#34;module_name&#34;: &#34;Youtube Video&#34;,
    &#34;section_header&#34;: &#34;undefined&#34;
  }">

  <div>

    <div data-component="uni-article-yt-player" data-page-title="Our next-generation model: Gemini 1.5" data-video-id="LHKL_210CcU" data-index-id="10">

    

    <a role="video" tabindex="0">
      <div>
        
          
          <p><img alt="Reasoning across a 402-page transcript: Gemini 1.5 Pro Demo" src="https://i.ytimg.com/vi_webp/LHKL_210CcU/default.webp" loading="lazy" data-loading="{
                &#34;mobile&#34;: &#34;//i.ytimg.com/vi_webp/LHKL_210CcU/sddefault.webp&#34;,
                &#34;desktop&#34;: &#34;//i.ytimg.com/vi_webp/LHKL_210CcU/maxresdefault.webp&#34;
              }"/></p>

        
        <svg role="presentation">
          
          <use xlink:href="/static/blogv2/images/icons.svg?version=pr20240131-1733#yt_video_play_button_no_hole"></use>
          
        </svg>
        <svg role="img">
          
          <use xlink:href="/static/blogv2/images/icons.svg?version=pr20240131-1733#yt_video_play_button"></use>
          
        </svg>

        
        
        
        
      </div>
    </a>

    
      <p>Gemini 1.5 Pro can understand, reason about and identify curious details in the 402-page transcripts from Apollo 11’s mission to the moon.</p>
    

    
  </div>

  </div>

</div>

  


  

  
    <div data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Our next\u002Dgeneration model: Gemini 1.5&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><h3 data-block-key="k1g9k">Better understanding and reasoning across modalities</h3><p data-block-key="6atnh">1.5 Pro can perform highly-sophisticated understanding and reasoning tasks for different modalities, including video. For instance, when given a 44-minute silent <a href="https://www.youtube.com/watch?v=rOVtjJkqtiA" rt-link-type="external">Buster Keaton movie</a>, the model can accurately analyze various plot points and events, and even reason about small details in the movie that could easily be missed.</p></div>
      </div>
    </div>
  

  
    
  
    


<div data-analytics-module="{
    &#34;module_name&#34;: &#34;Youtube Video&#34;,
    &#34;section_header&#34;: &#34;undefined&#34;
  }">

  <div>

    <div data-component="uni-article-yt-player" data-page-title="Our next-generation model: Gemini 1.5" data-video-id="wa0MT8OwHuk" data-index-id="12">

    

    <a role="video" tabindex="0">
      <div>
        
          
          <p><img alt="Multimodal prompting with a 44-minute movie: Gemini 1.5 Pro Demo" src="https://i.ytimg.com/vi_webp/wa0MT8OwHuk/default.webp" loading="lazy" data-loading="{
                &#34;mobile&#34;: &#34;//i.ytimg.com/vi_webp/wa0MT8OwHuk/sddefault.webp&#34;,
                &#34;desktop&#34;: &#34;//i.ytimg.com/vi_webp/wa0MT8OwHuk/maxresdefault.webp&#34;
              }"/></p>

        
        <svg role="presentation">
          
          <use xlink:href="/static/blogv2/images/icons.svg?version=pr20240131-1733#yt_video_play_button_no_hole"></use>
          
        </svg>
        <svg role="img">
          
          <use xlink:href="/static/blogv2/images/icons.svg?version=pr20240131-1733#yt_video_play_button"></use>
          
        </svg>

        
        
        
        
      </div>
    </a>

    
      <p>Gemini 1.5 Pro can identify a scene in a 44-minute silent Buster Keaton movie when given a simple line drawing as reference material for a real-life object.</p>
    

    
  </div>

  </div>

</div>

  


  

  
    <div data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Our next\u002Dgeneration model: Gemini 1.5&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><h3 data-block-key="l4f5z">Relevant problem-solving with longer blocks of code</h3><p data-block-key="6p94l">1.5 Pro can perform more relevant problem-solving tasks across longer blocks of code. When given a prompt with more than 100,000 lines of code, it can better reason across examples, suggest helpful modifications and give explanations about how different parts of the code works.</p></div>
      </div>
    </div>
  

  
    
  
    


<div data-analytics-module="{
    &#34;module_name&#34;: &#34;Youtube Video&#34;,
    &#34;section_header&#34;: &#34;undefined&#34;
  }">

  <div>

    <div data-component="uni-article-yt-player" data-page-title="Our next-generation model: Gemini 1.5" data-video-id="SSnsmqIj1MI" data-index-id="14">

    

    <a role="video" tabindex="0">
      <div>
        
          
          <p><img alt="Problem solving across 100,633 lines of code | Gemini 1.5 Pro Demo" src="https://i.ytimg.com/vi_webp/SSnsmqIj1MI/default.webp" loading="lazy" data-loading="{
                &#34;mobile&#34;: &#34;//i.ytimg.com/vi_webp/SSnsmqIj1MI/sddefault.webp&#34;,
                &#34;desktop&#34;: &#34;//i.ytimg.com/vi_webp/SSnsmqIj1MI/maxresdefault.webp&#34;
              }"/></p>

        
        <svg role="presentation">
          
          <use xlink:href="/static/blogv2/images/icons.svg?version=pr20240131-1733#yt_video_play_button_no_hole"></use>
          
        </svg>
        <svg role="img">
          
          <use xlink:href="/static/blogv2/images/icons.svg?version=pr20240131-1733#yt_video_play_button"></use>
          
        </svg>

        
        
        
        
      </div>
    </a>

    
      <p>Gemini 1.5 Pro can reason across 100,000 lines of code giving helpful solutions, modifications and explanations.</p>
    

    
  </div>

  </div>

</div>

  


  

  
    

  

  
    <div data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Our next\u002Dgeneration model: Gemini 1.5&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><h2 data-block-key="k1g9k">Enhanced performance</h2><p data-block-key="6peis">When tested on a comprehensive panel of text, code, image, audio and video evaluations, 1.5 Pro outperforms 1.0 Pro on 87% of the benchmarks used for developing our large language models (LLMs). And when compared to 1.0 Ultra on the same benchmarks, it performs at a broadly similar level.</p><p data-block-key="2m8o3">Gemini 1.5 Pro maintains high levels of performance even as its context window increases. In the <a href="https://github.com/gkamradt/LLMTest_NeedleInAHaystack" rt-link-type="external">Needle In A Haystack</a> (NIAH) evaluation, where a small piece of text containing a particular fact or statement is purposely placed within a long block of text, 1.5 Pro found the embedded text 99% of the time, in blocks of data as long as 1 million tokens.</p><p data-block-key="cq31">Gemini 1.5 Pro also shows impressive “in-context learning” skills, meaning that it can learn a new skill from information given in a long prompt, without needing additional fine-tuning. We tested this skill on the <a href="https://arxiv.org/abs/2309.16575" rt-link-type="external">Machine Translation from One Book</a> (MTOB) benchmark, which shows how well the model learns from information it’s never seen before. When given a <a href="https://langsci-press.org/catalog/book/344" rt-link-type="external">grammar manual</a> for <a href="https://endangeredlanguages.com/lang/1891?hl=en" rt-link-type="external">Kalamang</a>, a language with fewer than 200 speakers worldwide, the model learns to translate English to Kalamang at a similar level to a person learning from the same content.<br/></p><p data-block-key="7op9s">As 1.5 Pro’s long context window is the first of its kind among large-scale models, we’re continuously developing new evaluations and benchmarks for testing its novel capabilities.</p><p data-block-key="b6eqt">For more details, see our <a href="https://goo.gle/GeminiV1-5" rt-link-type="external">Gemini 1.5 Pro technical report</a>.</p></div>
      </div>
    </div>
  

  
    

  

  
    <div data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Our next\u002Dgeneration model: Gemini 1.5&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><h2 data-block-key="k1g9k">Extensive ethics and safety testing</h2><p data-block-key="a3s4a">In line with our <a href="https://ai.google/responsibility/principles/" rt-link-type="external">AI Principles</a> and robust safety policies, we’re ensuring our models undergo extensive ethics and safety tests. We then integrate these research learnings into our governance processes and model development and evaluations to continuously improve our AI systems.</p><p data-block-key="3r93h">Since introducing 1.0 Ultra in December, our teams have continued refining the model, making it safer for a wider release. We’ve also conducted <a href="https://goo.gle/GeminiPaper" rt-link-type="external">novel research on safety risks</a> and developed red-teaming techniques to test for a range of potential harms.</p><p data-block-key="2pmdm">In advance of releasing 1.5 Pro, we&#39;ve taken the same approach to responsible deployment as we did for our Gemini 1.0 models, <a href="https://goo.gle/GeminiV1-5" rt-link-type="external">conducting extensive evaluations</a> across areas including content safety and representational harms, and will continue to expand this testing. Beyond this, we’re developing further tests that account for the novel long-context capabilities of 1.5 Pro.</p></div>
      </div>
    </div>
  

  
    

  

  
    <div data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Our next\u002Dgeneration model: Gemini 1.5&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><h2 data-block-key="k1g9k">Build and experiment with Gemini models</h2><p data-block-key="94van">We’re committed to bringing each new generation of Gemini models to billions of people, developers and enterprises around the world responsibly.</p><p data-block-key="9uot9">Starting today, we’re offering a limited preview of 1.5 Pro to developers and enterprise customers via <a href="https://aistudio.google.com/" rt-link-type="external">AI Studio</a> and <a href="https://cloud.google.com/vertex-ai" rt-link-type="external">Vertex AI</a>. Read more about this on our <a href="https://developers.googleblog.com/2024/02/gemini-15-available-for-private-preview-in-google-ai-studio.html" rt-link-type="external">Google for Developers blog</a> and <a href="https://cloud.google.com/blog/products/ai-machine-learning/gemini-on-vertex-ai-expands" rt-link-type="external">Google Cloud blog</a>.</p><p data-block-key="55ddh">We’ll introduce 1.5 Pro with a standard 128,000 token context window when the model is ready for a wider release. Coming soon, we plan to introduce pricing tiers that start at the standard 128,000 context window and scale up to 1 million tokens, as we improve the model.</p><p data-block-key="3h3jn">Early testers can try the 1 million token context window at no cost during the testing period, though they should expect longer latency times with this experimental feature. Significant improvements in speed are also on the horizon.</p><p data-block-key="e52dh">Developers interested in testing 1.5 Pro can <a href="https://aistudio.google.com/app/waitlist/97445851" rt-link-type="external">sign up now</a> in AI Studio, while enterprise customers can reach out to their Vertex AI account team.</p><p data-block-key="bpauc">Learn more about <a href="https://deepmind.google/technologies/gemini" rt-link-type="external">Gemini’s capabilities and see how it works</a>.</p></div>
      </div>
    </div>
  

  
    

  
    






<div role="form" aria-label="Sign up to receive weekly news and stories from Google." data-component="uni-subscribe" data-analytics-module="{
    &#34;module_name&#34;: &#34;Newsletter&#34;,
    &#34;section_header&#34;: &#34;Get more stories from Google in your inbox.&#34;
  }">
  <div>
    
    
    <div id="newsletter-form--form">
      <form data-method="POST" data-action="https://services.google.com/fb/submissions/thekeywordnewsletterprodv2/">
        <h3 id="subscribe_box_label" aria-hidden="true">
          Get more <span>stories from Google</span> in your inbox.
        </h3>
        
      </form>
    </div>
    
    <div>
      <div>
        <p aria-hidden="true">Done. Just one step more.</p>
        <p tabindex="-1" aria-label="Done. Just one step more, Check your inbox to confirm your subscription." role="status" aria-live="off" aria-atomic="false">
          <span aria-hidden="true">Check your inbox to confirm your subscription.</span>
        </p>
        <p>You are already subscribed to our newsletter.</p>
      </div>
      <p>
        <span aria-hidden="true">
          You can also subscribe with a
        </span>
        
        <span aria-hidden="true">
        .
        </span>
      </p>
    </div>
  </div>
</div>

  

  


            
            

            
              




            
          </div>
        
      </div>
    </section>
  </article></div>
  </body>
</html>
