<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://dagshub.com/blog/reverse-engineering-google-colab/">Original</a>
    <h1>Reverse Engineering Google Colab</h1>
    
    <div id="readability-page-1" class="page"><div>
              
              <p><a href="https://colab.research.google.com/">Google Colaboratory</a>, better known as &#34;Colab&#34; by data scientists around the world, is a free cloud Jupyter notebook platform. In addition to providing an environment for users to run Python and R notebooks, Colab generously allows users to share free access to a limited number of GPUs and TPUs.</p><p><a href="https://dagshub.com/docs/integration_guide/google_colab/">Colab has quickly become the defacto environment</a> among data scientists for coding inside Jupyter notebooks. However, it&#39;s incredibly difficult to harness the compute power of Colab for anything beyond Jupyter notebooks. For Machine Learning engineers that want to <a href="https://dagshub.com/blog/notebook-to-production-ready-machine-learning/">productionize their models and bring them out of the notebook stage</a>, this is a particularly relevant issue; notebooks, while perfect for exploration, don&#39;t play well with more advanced MLOps tools that codify the training process into a formal pipeline.</p><p>I was in this position a few days ago, and I decided that instead of morphing my workflow around the restrictions of Colab, I would try to morph Colab around my workflow!</p><p>For that reason, today we will take a peek into the internals of Google Colab, and discover how we can bend the rules of Colab a little. To be clear, nothing we do here will cause any harm to Colab or to users of the service, we’re only exploring behind the scenes.</p><p>Colab’s secret sauce lies in its backend: the Google servers providing the infrastructure to let you run your code with a snap of your fingers and the press of a button. Thus, our first step is to analyze that backend API. The easiest way to do this is to inspect the API calls made by Colab during its normal operation. To do so, we launch Chrome’s Developer Tools and find the Network tab, then try to run a cell of code. DevTools starts recording every request made by Colab, and almost immediately we find something interesting.</p><figure><img src="https://dagshub.com/blog/content/images/2022/06/socketiorequest-1.gif" alt="socketio request.gif"/></figure><figure><img src="https://dagshub.com/blog/content/images/2022/06/socketiorequest-1.png" alt="socketio request.png" srcset="https://dagshub.com/blog/content/images/size/w600/2022/06/socketiorequest-1.png 600w, https://dagshub.com/blog/content/images/size/w1000/2022/06/socketiorequest-1.png 1000w, https://dagshub.com/blog/content/images/2022/06/socketiorequest-1.png 1020w" sizes="(min-width: 720px) 720px"/></figure><p>It looks like this URL (<code>/tun/m/&lt;id&gt;/socket.io</code>) is a proxy to the Jupyter socket running on the remote machine.</p><p>If we launch the Files pane (which shows the <code>/content</code> directory by default) from the left pane of the Colab UI, we get another interesting request:</p><figure><img src="https://dagshub.com/blog/content/images/2022/06/filespane-1.gif" alt="filespane.gif"/></figure><figure><img src="https://dagshub.com/blog/content/images/2022/06/filespanerequest-1.png" alt="filespane request.png" srcset="https://dagshub.com/blog/content/images/size/w600/2022/06/filespanerequest-1.png 600w, https://dagshub.com/blog/content/images/2022/06/filespanerequest-1.png 701w"/></figure><p>This time, the response body is JSON enumerating the files on the remote host. It appears that the URL (<code>/tun/m/&lt;id&gt;/api/contents/</code>) points to a service that provides file metadata.</p><figure><img src="https://dagshub.com/blog/content/images/2022/06/filespanejson-1.png" alt="filespane json.png" srcset="https://dagshub.com/blog/content/images/size/w600/2022/06/filespanejson-1.png 600w, https://dagshub.com/blog/content/images/2022/06/filespanejson-1.png 676w"/></figure><p>Double-clicking on a file in the Files pane causes Colab to download and display it. If we try to click on <code>/content/sample_data/README.md</code>, we notice a request to <code>/tun/m/&lt;id&gt;/files/</code> that returns the contents of that file.</p><figure><img src="https://dagshub.com/blog/content/images/2022/06/filecontent-1.png" alt="filecontent.png" srcset="https://dagshub.com/blog/content/images/size/w600/2022/06/filecontent-1.png 600w, https://dagshub.com/blog/content/images/2022/06/filecontent-1.png 801w" sizes="(min-width: 720px) 720px"/></figure><figure><img src="https://dagshub.com/blog/content/images/2022/06/filecontentresponse-1.png" alt="filecontent response.png" srcset="https://dagshub.com/blog/content/images/size/w600/2022/06/filecontentresponse-1.png 600w, https://dagshub.com/blog/content/images/size/w1000/2022/06/filecontentresponse-1.png 1000w, https://dagshub.com/blog/content/images/2022/06/filecontentresponse-1.png 1055w" sizes="(min-width: 720px) 720px"/></figure><p>It&#39;s clear that <code>https://colab.research.google.com/tun/m/&lt;id&gt;/</code> is a reverse proxy to the server running our Colab instance, which provides the <code>/socket.io</code>, <code>/files</code>, and <code>/api/contents</code> endpoints.</p><p>Let&#39;s try to see if any of these services are running inside the Colab container instance itself. The <code>lsof</code> program is installed inside Colab, so we run <code>lsof -iTCP -sTCP:LISTEN</code> to list all processes that are listening on a TCP port for network requests.</p><figure><img src="https://dagshub.com/blog/content/images/2022/06/lsof-1.png" alt="lsof.png" srcset="https://dagshub.com/blog/content/images/size/w600/2022/06/lsof-1.png 600w, https://dagshub.com/blog/content/images/2022/06/lsof-1.png 747w" sizes="(min-width: 720px) 720px"/></figure><p>Aha! <code>colab-fileshim</code>, <code>node</code>, and <code>jupyter-notebook</code> all look like promising surfaces to explore. Since we&#39;ve played with the Files pane already, let’s look at <code>colab-fileshim</code> first. It has PID 28, so we check the <code>/proc</code> filesystem to look at the full command line of the process:</p><figure><img src="https://dagshub.com/blog/content/images/2022/06/fileshimcmdline-1.png" alt="fileshim cmdline.png"/></figure><p>The next step is to investigate <code>/usr/local/bin/colab-fileshim.py</code>. Ironically, we can do this by browsing to it in the Files pane itself. The program seems mostly like an uninteresting fileserver, and we don&#39;t learn much from it other than that the server itself responds to <code>localhost:3453/files</code> (with actual file contents) and <code>localhost:3453/api/contents</code> (with JSON metadata). This means that Colab forwards those requests from the tunnel URL to port 3453 on the instance itself.</p><p>From the Network tab of the Chrome DevTools, we can right click a request to copy the cURL command to reproduce it. For instance, here is the cURL command for viewing the README.md file:</p><pre><code>$ curl &#39;https://colab.research.google.com/tun/m/m-s-3oy94z70yrj59/files/content/sample_data/README.md?authuser=0&#39; \
  -H &#39;authority: colab.research.google.com&#39; \
  -H &#39;x-colab-tunnel: Google&#39; \
  -H &#39;accept: */*&#39; \
  -H &#39;dnt: 1&#39; \
  -H &#39;accept-language: en-US,en;q=0.9&#39; \
  -H &#39;sec-fetch-site: same-origin&#39; \
  -H &#39;sec-fetch-mode: cors&#39; \
  -H &#39;sec-fetch-dest: empty&#39; \
  -H &#39;referer: https://colab.research.google.com/&#39; \
  -H &#39;cookie: &lt;&lt;READACTED&gt;&gt;&#39; \
  -H &#39;range: bytes=0-930&#39; \
  --compressed</code></pre><p>If we run this command on our local computer’s terminal, we get the contents of that README file printed to our terminal. With a little bit of trial and error, we see that we can trim down most of those headers, leaving behind only</p><pre><code>$ curl &#39;https://colab.research.google.com/tun/m/m-s-3oy94z70yrj59/files/content/sample_data/README.md?authuser=0&#39; \
  -H &#39;x-colab-tunnel: Google&#39; \
  -H &#39;cookie: &lt;&lt;READACTED&gt;&gt;&#39;
</code></pre><p>The <code>x-colab-tunnel</code> header is there to prevent us (or evil attackers) from making these requests from regular browser tabs, ostensibly to stop XSS attacks. The <code>cookie</code> header provides authentication to Google to prove we have access to the notebook instance. Because the cookie is long and unwieldy to work with, we will store it into the shell variable <code>$COLAB_COOKIE</code> for the remainder of this article.</p><pre><code>$ COLAB_COOKIE=&#34;&lt;&lt;PREVIOUSLY REDACTED VALUE&gt;&gt;&#34;
# Usage: $ curl ... -H &#34;cookie: $COLAB_COOKIE&#34;
</code></pre><p>Now that we have discovered Colab’s reverse proxy, let’s see if we can use it to tunnel our own requests!</p><p>Instead of trying to mess with the existing <code>colab-fileshim.py</code> server, we could simply replace the process with a server of our own! We run <code>pkill -f colab-fileshim</code> to kill it, so we can then start our own server on the same port.</p><p>For a short and simple demo, we will launch python’s default HTTP server to serve our own files at <code>localhost:3453/files</code>.</p><figure><img src="https://dagshub.com/blog/content/images/2022/06/newfileshim.png" alt="new fileshim.png" srcset="https://dagshub.com/blog/content/images/size/w600/2022/06/newfileshim.png 600w, https://dagshub.com/blog/content/images/2022/06/newfileshim.png 675w"/></figure><p>Voila! We can now change the cURL command to download our own files!</p><pre><code>$ curl &#39;https://colab.research.google.com/tun/m/m-s-3oy94z70yrj59/files/message.txt?authuser=0&#39; \
  -H &#34;x-colab-tunnel: Google&#34; -H &#34;cookie: $COLAB_COOKIE&#34;
Hi! You&#39;ve reached our own file server!
</code></pre><pre><code>$ curl &#39;https://colab.research.google.com/tun/m/m-s-3oy94z70yrj59/files/shadow?authuser=0&#39; \
  -H &#34;x-colab-tunnel: Google&#34; -H &#34;cookie: $COLAB_COOKIE&#34;
root:*:18585:0:99999:7:::
daemon:*:18585:0:99999:7:::
bin:*:18585:0:99999:7:::
sys:*:18585:0:99999:7:::
sync:*:18585:0:99999:7:::
# ...
</code></pre><p>Notice the log line in the Colab cell proving that our server handled the request:</p><pre><code>Serving HTTP on 0.0.0.0 port 3453 (http://0.0.0.0:3453/) ...
172.28.0.1 - - [22/Jun/2022 16:43:10] &#34;GET /files/message.txt HTTP/1.1&#34; 200 -
172.28.0.1 - - [22/Jun/2022 16:43:16] &#34;GET /files/shadow HTTP/1.1&#34; 200 -
</code></pre><p>Sadly, because of the required <code>x-colab-tunnel: Google</code> header, we can&#39;t easily access the server from the browser.</p><p>Let’s continue investigating, this time by taking a look at the other interesting process we identified earlier, <code>node</code>. If we check <code>/proc/7/cmdline</code>, we see that the process is running <code>/datalab/web/app.js</code>.</p><p>Once we jump there and read that code, we find that <code>/datalab/web</code> contains a fairly standard NodeJS application. Along with the previously seen <code>/socketio/</code> route, it also exposes a <code>/_proxy/{port}/</code> route. Aha! This should let us access <em>any</em> URL from <em>any</em> port on the Colab instance!</p><p>Let’s launch a quick server and test.</p><figure><img src="https://dagshub.com/blog/content/images/2022/06/httpserver.png" alt="httpserver.png" srcset="https://dagshub.com/blog/content/images/size/w600/2022/06/httpserver.png 600w, https://dagshub.com/blog/content/images/2022/06/httpserver.png 867w" sizes="(min-width: 720px) 720px"/></figure><pre><code>$ curl &#39;https://colab.research.google.com/tun/m/m-s-3oy94z70yrj59/_proxy/1234/some/path?authuser=0&#39; \
  -H &#34;x-colab-tunnel: Google&#34; -H &#34;cookie: $COLAB_COOKIE&#34;
&lt;html&gt;&lt;head&gt;&lt;title&gt;Colab Forwarded Server!&lt;/title&gt;&lt;/head&gt;&lt;body&gt;&lt;h1&gt;Hi from Colab!&lt;/h1&gt;&lt;h2&gt;path=/some/path&lt;/h2&gt;&lt;/body&gt;&lt;/html&gt;%
</code></pre><p>If only we could view this HTML page from a browser tab. Unfortunately, Colab refuses to proxy any requests unless they have the  <code>x-colab-tunnel: Google</code> header set. If we attempt to visit these URLs from the browser, we are met with a generic HTTP 400 Client Error page:</p><figure><img src="https://dagshub.com/blog/content/images/2022/06/400error.png" alt="400error.png" srcset="https://dagshub.com/blog/content/images/size/w600/2022/06/400error.png 600w, https://dagshub.com/blog/content/images/2022/06/400error.png 847w" sizes="(min-width: 720px) 720px"/></figure><p>Fortunately, we can use <a href="https://chrome.google.com/webstore/detail/modheader/idgpnmonknjnojddfkpgkljpfnnfcklj?src=dagshub">a Chrome Extension to insert HTTP headers into browser requests on-the-fly</a>. We set it up to send the <code>x-colab-tunnel: Google</code> header on all requests:</p><figure><img src="https://dagshub.com/blog/content/images/2022/06/modheader.png" alt="modheader.png" srcset="https://dagshub.com/blog/content/images/size/w600/2022/06/modheader.png 600w, https://dagshub.com/blog/content/images/2022/06/modheader.png 618w"/></figure><p>We can then launch the tunneled URLs in our browser!</p><figure><img src="https://dagshub.com/blog/content/images/2022/06/lookma.png" alt="lookma.png" srcset="https://dagshub.com/blog/content/images/size/w600/2022/06/lookma.png 600w, https://dagshub.com/blog/content/images/size/w1000/2022/06/lookma.png 1000w, https://dagshub.com/blog/content/images/2022/06/lookma.png 1080w" sizes="(min-width: 720px) 720px"/></figure><p>Finally, let’s take a look at the third and final interesting process from above, <code>jupyter-notebook</code>, which listens on port <code>9000</code>.</p><p>We can first try to visit the port from the browser using our proxy and header trick from earlier by visiting <code>/tun/m/&lt;id&gt;/_proxy/9000</code>. Sadly, we are met with an HTTP 500 Server Error page instead of the desired Jupyter UI.</p><p>Strange. We try to diagnose that by running <code>!curl -i localhost:9000</code> from the Colab notebook itself, but we still get an error message:</p><figure><img src="https://dagshub.com/blog/content/images/2022/06/curlfail.png" alt="curlfail.png" srcset="https://dagshub.com/blog/content/images/size/w600/2022/06/curlfail.png 600w, https://dagshub.com/blog/content/images/2022/06/curlfail.png 735w" sizes="(min-width: 720px) 720px"/></figure><p>The output of <code>lsof</code> from earlier gives us a clue: instead of listening on <code>0.0.0.0</code>/<code>::</code> (all IPs over all interfaces), Jupyter is only listening on the private IP given to the Colab instance. This is presumably in order to avoid exposing the Jupyter interface to us.</p><p>Google certainly didn’t try hard enough to hide it though, and there’s a quick fix.</p><p>In order to bypass the listening address restriction, we need to create a process that listens on all interfaces and IPs and forwards all the traffic it gets to the specific IP address that Jupyter is listening on. We can install the socket proxy tool <code>socat</code> (”Socket Cat”) to do so. We will use <code>socat</code> to forward traffic from <code>localhost:9000</code> to <code>$HOSTNAME:9000</code> and back:</p><figure><img src="https://dagshub.com/blog/content/images/2022/06/socat.png" alt="socat.png" srcset="https://dagshub.com/blog/content/images/size/w600/2022/06/socat.png 600w, https://dagshub.com/blog/content/images/2022/06/socat.png 739w" sizes="(min-width: 720px) 720px"/></figure><p>This is a start! If we reload the URL in the browser, we see fragments of the Jupyter UI, but it&#39;s clearly broken.</p><figure><img src="https://dagshub.com/blog/content/images/2022/06/brokenjupyter.png" alt="brokenjupyter.png" srcset="https://dagshub.com/blog/content/images/size/w600/2022/06/brokenjupyter.png 600w, https://dagshub.com/blog/content/images/2022/06/brokenjupyter.png 919w" sizes="(min-width: 720px) 720px"/></figure><p>This is because Jupyter expects to be accessed at the root of a domain (the URL path <code>/</code>), but our Colab tunnel has a path of <code>/tun/m/&lt;id&gt;/_proxy/9000</code>, messing up any absolute paths to resources such as CSS and JS files.</p><p>There&#39;s no easy solution here—we would need an entire (sub)domain to forward traffic to our Jupyter server.</p><p>Thankfully, Colab does have a well-hidden but official solution to port forwarding that does provide an entire subdomain! Funnily enough, it&#39;s so well-hidden that it took longer for me to find than it did to discover the internal reverse proxy!</p><p>To find out how to use Colab&#39;s official port forwarding, you need to open the Code Snippets tab from the left sidebar, and find the Output Handling snippet. Click &#34;View Source Notebook,&#34; and you&#39;re taken to <code>advanced_outputs.ipynb</code>, <a href="https://colab.research.google.com/notebooks/snippets/advanced_outputs.ipynb">Colab&#39;s garden of poweruser snippets showcasing scarecely-documented features of the platform</a>. The specific snippet we need can be found under the heading &#34;Browsing to servers executing on the kernel.&#34;</p><p>We can use this snippet to expose the Jupyter UI as a subdomain.</p><figure><img src="https://dagshub.com/blog/content/images/2022/06/officialproxy.png" alt="officialproxy.png" srcset="https://dagshub.com/blog/content/images/size/w600/2022/06/officialproxy.png 600w, https://dagshub.com/blog/content/images/2022/06/officialproxy.png 741w" sizes="(min-width: 720px) 720px"/></figure><p>Now, we can click the link (and append <code>/tree</code> to the URL to appease Jupyter), and see the fully-working* Jupyter UI!</p><figure><img src="https://dagshub.com/blog/content/images/2022/06/workingjupyter.png" alt="workingjupyter.png" srcset="https://dagshub.com/blog/content/images/size/w600/2022/06/workingjupyter.png 600w, https://dagshub.com/blog/content/images/2022/06/workingjupyter.png 923w" sizes="(min-width: 720px) 720px"/></figure><p><em>* Well, almost fully working. Google seems to have limited the official proxy to only GET requests, allowing us to view, but not run, notebooks.</em></p><p>Congrats, you made it to the end! I hope this was valuable in showing you things you didn’t know about how Colab works, as well as learning a semi-structured approach to reverse-engineering tools in general. I also hope that this has inspired you to take a deeper look at the internals of the tools and products you use every day!</p><hr/><blockquote>If you’re a data scientist looking to take your organization’s data and machine learning processes to the next level, check out <a href="https://dagshub.com/?utm_source=internal_blog_post_cta">DagsHub</a>. Our collaborative platform allows you to develop reproducible data pipelines, track model experimentation, and collect training data, annotations, and trained models throughout the machine learning lifecycle.</blockquote>
                <section>
                  
                  <ul>
                      <li>
                        <a href="https://dagshub.com/blog/tag/open-source-data-science-tools/" title="Open Source Data Science Tools">Open Source Data Science Tools</a>
                      </li>
                      <li>
                        <a href="https://dagshub.com/blog/404/" title="Google Colab">Google Colab</a>
                      </li>
                  </ul>
                </section>
            </div></div>
  </body>
</html>
