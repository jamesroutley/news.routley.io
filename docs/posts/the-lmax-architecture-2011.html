<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://martinfowler.com/articles/lmax.html">Original</a>
    <h1>The LMAX Architecture (2011)</h1>
    
    <div id="readability-page-1" class="page"><div>
<p>Over the last few years we keep hearing that &#34;the free lunch is over&#34; - we can&#39;t expect increases in individual CPU
speed. So to write fast code we need to explicitly use multiple
processors with concurrent software. This is not good news - writing
concurrent code is very hard. Locks and semaphores are hard to reason
about and hard to test - meaning we are spending more time worrying
about satisfying the computer than we are solving the domain
problem. Various concurrency models, such as Actors and Software Transactional
Memory, aim to make this easier - but there is still a burden that
introduces bugs and complexity.</p>



<p>So I was fascinated to hear about a talk at QCon London in March
last year from LMAX. LMAX is a new retail financial trading
platform. Its business innovation is that it is a <i>retail</i>
platform - allowing anyone to trade in a range of financial derivative
products. A trading platform like this needs very low latency - trades have
to be processed quickly because the market is moving rapidly. A retail
platform adds complexity because it has to do this for lots of
people. So the result is more users, with
lots of trades, all of which need to be processed quickly.</p>





<p>Given the shift to multi-core thinking, this kind of demanding
performance would naturally suggest an explicitly concurrent
programming model - and indeed this was their starting point. But the
thing that got people&#39;s attention at QCon was that this wasn&#39;t where
they ended up. In fact they ended up by doing all the business logic
for their platform: all trades, from all customers, in all markets - on
a single thread. A thread that will process 6 million orders per
second 
 using commodity hardware.</p>



<p>Processing lots of transactions with low-latency and none of the
complexities of concurrent code - how can I resist digging into that?
Fortunately another difference LMAX has to other financial companies
is that they are quite happy to talk about their technological
decisions. So now LMAX has been in production for a while it&#39;s time to
explore their fascinating design.</p>

<section id="OverallStructure">
<h2>Overall Structure</h2>

<div id="images_lmax_arch-summary.png"><p><img src="https://olu.online/weeknotes-12-week-32-2024/images/lmax/arch-summary.png"/></p><p>Figure 1: LMAX&#39;s architecture in three blobs</p>
</div>



<p>At a top level, the architecture has three parts</p>

<ul>
<li>business logic processor</li>



<li>input disruptor</li>

<li>output disruptors</li>
</ul>

<p>As its name implies, the business logic processor handles all the
  business logic in the application. As I indicated above, it does
  this as a single-threaded java program which reacts to method calls
  and produces output events. Consequently it&#39;s a simple
  java program that doesn&#39;t require any platform frameworks to run
  other than the JVM itself, which allows it to be easily run in test
  environments.</p>

<p>Although the Business Logic Processor can run in a simple
  environment for testing, there is rather more involved choreography
  to get it to run in a production setting. Input messages need to be
  taken off a network gateway and unmarshaled, replicated and
  journaled. Output messages need to be marshaled for the
  network. These tasks are handled by the input and output
  disruptors. Unlike the Business Logic Processor, these are
  concurrent components, since they involve IO operations which are
  both slow and independent. They were designed and built especially
  for LMAX, but they (like the overall architecture) are applicable
  elsewhere.</p>
</section>

<section id="BusinessLogicProcessor">
<h2>Business Logic Processor</h2>

<section id="KeepingItAllInMemory">
<h3>Keeping it all in memory</h3>

<p>The Business Logic Processor takes input messages sequentially
  (in the form of a method invocation), runs business logic on it, and
  emits output events. It operates entirely in-memory, there is no
  database or other persistent store. Keeping all data in-memory has
  two important benefits. Firstly it&#39;s fast - there&#39;s no database to
  provide slow IO to access, nor is there any transactional behavior
  to execute since all the processing is done sequentially. The second
  advantage is that it simplifies programming - there&#39;s no
  object/relational mapping to do. All the code can be written using
  Java&#39;s object model without having to make any compromises for the
  mapping to a database.</p>

<p>Using an in-memory structure has an important consequence - what
  happens if everything crashes? Even the most resilient systems are
  vulnerable to someone pulling the power. The heart of dealing with
  this is <a href="https://olu.online/eaaDev/EventSourcing.html">Event Sourcing</a> - which means that the
  current state of the Business Logic Processor is entirely derivable
  by processing the input events. As long as the input event stream is
  kept in a durable store (which is one of the jobs of the input
  disruptor) you can always recreate the current state of the business
  logic engine by replaying the events.</p>

<p>A good way to understand this is to think of a version control
  system. Version control systems are a sequence of commits, at any
  time you can build a working copy by applying those commits. VCSs
  are more complicated than the Business Logic Processor because they must
  support branching, while the Business Logic Processor is a simple
  sequence.</p>

<p>So, in theory, you can always rebuild the state of the Business
  Logic Processor by reprocessing all the events. In practice,
  however, that would take too long should you need to spin one
  up. So, just as with version control systems, LMAX can make
  snapshots of the Business Logic Processor state and restore from the
  snapshots. They take a snapshot every night during periods of low
  activity. Restarting the Business Logic Processor is fast, a full
  restart - including restarting the JVM, loading a recent snapshot,
  and replaying a days worth of journals - takes less than a
  minute.</p>

<p>Snapshots make starting up a new Business Logic Processor faster,
  but not quickly enough should a Business Logic Processor crash at
  2pm. As a result LMAX keeps multiple Business Logic Processors
  running all the time. Each input event is
  processed by multiple processors, but all but one processor has its
  output ignored. Should the live processor fail, the system switches
  to another one. This ability to handle fail-over is another benefit
  of using Event Sourcing. </p>



<p>By event sourcing into replicas they can switch between
  processors in a matter of micro-seconds. As well as taking snapshots
  every night, they also restart the Business Logic Processors every
  night. The replication allows them to do this with no downtime, so
  they continue to process trades 24/7. </p>



<p>Event Sourcing is valuable because it allows the processor to run
  entirely in-memory, but it has another considerable advantage for
  diagnostics. If some unexpected behavior occurs, the team copies the
  sequence of events to their development environment and replays them
  there. This allows them to examine what happened much more easily
  than is possible in most environments.</p>

<p>This diagnostic capability extends to
  business diagnostics. There are some business tasks, such as in risk
  management, that require significant computation that isn&#39;t needed
  for processing orders. An example is getting a list of the top 20
  customers by risk profile based on their current trading
  positions. The team handles this by spinning up a replicate domain
  model and carrying out the computation there, where it won&#39;t
  interfere with the core order processing. These analysis domain
  models can have variant data models, keep different data sets in
  memory, and run on different machines.</p>
</section>

<section id="TuningPerformance">
<h3>Tuning performance</h3>

<p>So far I&#39;ve explained that the key to the speed of the Business
  Logic Processor is doing everything sequentially,
  in-memory. Just doing this (and nothing really stupid) allows
  developers to write code that can process 10K TPS. They then found that concentrating on the simple
  elements of good code could bring this up into the 100K TPS
  range. This just needs well-factored code and small methods -
  essentially this allows Hotspot to do a better job of optimizing and
  for CPUs to be more efficient in caching the
  code as it&#39;s running.</p>



<p>It took a bit more cleverness to go up another order of
  magnitude. There are several things that the LMAX team found helpful
  to get there. One was to write custom implementations of the java
  collections that were designed to be cache-friendly and careful with
  garbage. An example of this is using primitive java longs as hashmap
  keys with a specially written array backed Map implementation
  (<code>LongToObjectHashMap</code>). In general they&#39;ve found that
  choice of data structures often makes a big difference, Most
  programmers just grab whatever List they used last time rather than
  thinking which implementation is the right one for this context.</p>





<p>Another technique to reach that top level of performance is
  putting attention into performance testing. I&#39;ve long noticed that
  people talk a lot about techniques to improve performance, but the
  one thing that really makes a difference is to test it. Even good
  programmers are very good at constructing performance arguments that
  end up being wrong, so the best programmers prefer profilers and
  test cases to speculation. The LMAX
  team has also found that writing tests first is a very effective
  discipline for performance tests.</p>


</section>

<section id="ProgrammingModel">
<h3>Programming Model</h3>

<p>This style of processing does introduce some constraints into the
  way you write and organize the business logic. The first of these is
  that you have to tease out any interaction with external
  services. An external service call is going to be slow, and with a
  single thread will halt the entire order processing machine. As a
  result you can&#39;t make calls to external services within the business
  logic. Instead you need to finish that interaction with an output
  event, and wait for another input event to pick it back up again.</p>

<p>I&#39;ll use a simple non-LMAX example to illustrate. Imagine you are
  making an order for jelly beans by credit card. A simple retailing
  system would take your order information, use a credit card
  validation service to check your credit card number, and then
  confirm your order - all within a single operation. The thread
  processing your order would block while waiting for the credit card
  to be checked, but that block wouldn&#39;t be very long for the user,
  and the server can always run another thread on the processor while
  it&#39;s waiting.</p>

<p>In the LMAX architecture, you would split this operation into
  two. The first operation would capture the order information and
  finish by outputting an event (credit card validation requested) to
  the credit card company. The Business Logic Processor would then
  carry on processing events for other customers until it received a
  credit-card-validated event in its input event stream. On
  processing that event it would carry out the confirmation tasks for
  that order.</p>

<p>Working in this kind of event-driven, asynchronous style, is
  somewhat unusual - although using asynchrony to improve the
  responsiveness of an application is a familiar technique. It also
  helps the business process be more resilient, as you have to be more
  explicit in thinking about the different things that can happen with
  the remote application.</p>

<p>A second feature of the programming model lies in error
  handling. The traditional model of sessions and database
  transactions provides a helpful error handling capability. Should
  anything go wrong, it&#39;s easy to throw away everything that happened
  so far in the interaction. Session data is transient, and can be
  discarded, at the cost of some irritation to the user if in the
  middle of something complicated. If an error occurs on the database
  side you can rollback the transaction.</p>

<p>LMAX&#39;s in-memory structures are persistent across input events,
  so if there is an error it&#39;s important to not leave that memory in
  an inconsistent state. However there&#39;s no automated rollback
  facility. As a consequence the LMAX team puts a lot of attention
  into ensuring the input events are fully valid before doing any
  mutation of the in-memory persistent state. They have found that
  testing is a key tool in flushing out these kinds of problems before
  going into production.</p>
</section>
</section>

<section id="InputAndOutputDisruptors">
<h2>Input and Output Disruptors</h2>

<p>Although the business logic occurs in a single thread, there are
  a number tasks to be done before we can invoke a business object
  method. The original input for processing comes off the wire in the
  form of a message, this message needs to be unmarshaled into a form
  convenient for Business Logic Processor to use. Event Sourcing
  relies on keeping a durable journal of all the input events, so
  each input message needs to be journaled onto a durable
  store. Finally the architecture relies on a cluster of Business
  Logic Processors, so we have to replicate the input messages across
  this cluster. Similarly on the output side, the output events need to be
  marshaled for transmission over the network. </p>

<div id="images_lmax_input-activity.png"><p><img src="https://olu.online/weeknotes-12-week-32-2024/images/lmax/input-activity.png"/></p><p>Figure 2: The activities done by the input
  disruptor (using UML activity diagram notation)</p>
</div>



<p>The replicator and journaler involve IO and therefore are relatively
  slow. After all the central idea of Business Logic Processor is that
  it avoids doing any IO. Also these three tasks are relatively
  independent, all of them need to be done before the Business Logic
  Processor works on a message, but they can done in any order. So
  unlike with the Business Logic Processor, where each trade changes
  the market for subsequent trades, there is a natural fit for
  concurrency.</p>

<p>To handle this concurrency the LMAX team developed a special
  concurrency component, which they call a
  <b>Disruptor</b>.</p>





<p>At a crude level you can think of a Disruptor as a multicast graph
  of queues where producers put objects on it that are sent to all the
  consumers for parallel consumption through separate downstream
  queues. When you look inside you see that this network of queues is
  really a single data structure - a ring buffer. Each producer and
  consumer has a sequence counter to indicate which slot in the buffer
  it&#39;s currently working on. Each producer/consumer writes its own
  sequence counter but can read the others&#39; sequence counters. This
  way the producer can read the consumers&#39; counters to ensure the slot
  it wants to write in is available without any locks on the
  counters. Similarly a consumer can ensure it only processes messages
  once another consumer is done with it by watching the counters.</p>

<div id="images_lmax_disruptor.png"><p><img src="https://olu.online/weeknotes-12-week-32-2024/images/lmax/disruptor.png"/></p><p>Figure 3: The input disruptor coordinates one
  producer and four consumers</p>
</div>



<p>Output disruptors are similar but they only have two sequential
  consumers for marshaling and output.
  Output events are organized into several topics, so that messages
  can be sent to only the receivers who are interested in them. Each topic
  has its own disruptor.</p>



<p>The disruptors I&#39;ve described are used in a style with one producer and
  multiple consumers, but this isn&#39;t a limitation of the design of the
  disruptor. The disruptor can work with multiple producers too, in
  this case it still doesn&#39;t need locks.</p>



<p>A benefit of the disruptor design is that it makes it easier for
  consumers to catch up quickly if they run into a problem and fall
  behind. If the unmarshaler has a problem when processing on slot
  15 and returns when the receiver is on slot 31, it can read data
  from slots 16-30 in one batch to catch up. This batch read of the
  data from the disruptor makes it easier for lagging consumers to
  catch up quickly, thus reducing overall latency.</p>

<p>I&#39;ve described things here, with one each of the journaler,
  replicator, and unmarshaler - this indeed is what LMAX does. But the
  design would allow multiple of these components to run. If you ran
  two journalers then one would take the even slots and the other
  journaler would take the odd
  slots. This allows further concurrency of these IO operations should
  this become necessary.</p>

<p>The ring buffers are large: 20 million slots for input buffer and
  4 million slots for each of the output buffers. The sequence
  counters are 64bit long integers that increase monotonically even as
  the ring slots wrap. The buffer is set
  to a size that&#39;s a power of two so the compiler can do an efficient
  modulus operation to map from the sequence counter number to the
  slot number. Like the rest of the system, the disruptors are bounced
  overnight. This bounce is mainly done to wipe memory so that there
  is less chance of an expensive garbage collection event during
  trading. (I also think it&#39;s a good habit to regularly restart, so
  that you rehearse how to do it for emergencies.)</p>



<p>The journaler&#39;s job is to store all the events in a durable form,
  so that they can be replayed should anything go wrong. LMAX does not
  use a database for this, just the file system. They stream the
  events onto the disk. In modern terms,
  mechanical disks are horribly slow for random access, but very fast
  for streaming - hence the tag-line &#34;disk is the new tape&#34;.</p>



<p>Earlier on I mentioned that LMAX runs
  multiple copies of its system in a cluster to support rapid
  failover. The replicator keeps these nodes in sync. All
  communication in LMAX uses IP multicasting, so clients don&#39;t need to
  know which IP address is the leader node. Only the leader node
  listens directly to input events and runs a replicator. The
  replicator broadcasts the input events to the follower nodes.  Should
  the leader node go down, it&#39;s lack of heartbeat will be noticed,
  another node becomes leader, starts processing input events, and
  starts its replicator.  Each node has its own input disruptor and
  thus has its own journal and does its own unmarshaling.</p>

<p>Even with IP multicasting, replication is still needed because
  IP messages can arrive in a different order on different nodes. The
  leader node provides a deterministic sequence for the rest of the
  processing.</p>

<p>The unmarshaler turns the event data from
  the wire into a java object that can be used to invoke behavior on
  the Business Logic Processor. Therefore, unlike the other consumers,
  it needs to modify the data in the ring buffer so it can store this
  unmarshaled object. The rule here is that consumers are permitted to
  write to the ring buffer, but each writable field can only have one
  parallel consumer that&#39;s allowed to write to it. This preserves the
  principle of only having a single writer. </p>



<div id="images_lmax_arch-full.png"><p><img src="https://olu.online/weeknotes-12-week-32-2024/images/lmax/arch-full.png"/></p><p>Figure 4: The LMAX architecture with the disruptors expanded</p>
</div>



<p>The disruptor is a general purpose component that can be used
  outside of the LMAX system. Usually financial companies are very
  secretive about their systems, keeping quiet even about items that
  aren&#39;t germane to their business. Not just has LMAX been open about
  its overall architecture, they have open-sourced the disruptor code
  - an act that makes me very happy. Not just will this allow other
  organizations to make use of the disruptor, it will also allow for
  more testing of its concurrency properties.</p>
</section>

<section id="QueuesAndTheirLackOfMechanicalSympathy">
<h2>Queues and their lack of mechanical sympathy</h2>

<p>The LMAX architecture caught people&#39;s attention because it&#39;s a
  very different way of approaching a high performance system to what
  most people are thinking about. So far I&#39;ve talked about how it
  works, but haven&#39;t delved too much into why it was developed this
  way. This tale is interesting in itself, because this architecture
  didn&#39;t just appear. It took a long time of trying more conventional
  alternatives, and realizing where they were flawed, before the team
  settled on this one.</p>

<p>Most business systems these days have a core architecture that
  relies on multiple active sessions coordinated through a
  transactional database. The LMAX team were familiar with this
  approach, and confident that it wouldn&#39;t work for LMAX. This
  assessment was founded in the experiences of Betfair - the parent
  company who set up LMAX. Betfair is a betting site that allows
  people to bet on sporting events. It handles very high volumes of
  traffic with a lot of contention - sports bets tend to burst around
  particular events. To make this work they have one of the hottest
  database installations around and have had to do many unnatural acts
  in order to make it work. Based on this experience they knew how
  difficult it was to maintain Betfair&#39;s performance and were sure
  that this kind of architecture would not work for the very low
  latency that a trading site would require. As a result they had to
  find a different approach.</p>

<p>Their initial approach was to follow what so many are saying
  these days - that to get high performance you need to use explicit
  concurrency. For this scenario, this means allowing orders to be
  processed by multiple threads in parallel. However, as is often the
  case with concurrency, the difficulty comes because these threads
  have to communicate with each other. Processing an order changes
  market conditions and these conditions need to be communicated.</p>

<p>The approach they explored early on was the Actor model and its
  cousin SEDA. The Actor model relies on independent, active objects
  with their own thread that communicate with each other via
  queues. Many people find this kind of concurrency model much easier
  to deal with than trying to do something based on locking primitives.</p>

<p>The team built a prototype exchange using the actor model and did
  performance tests on it. What they found was that the processors
  spent more time managing queues than doing the real logic of
  the application. Queue access was a bottleneck.</p>

<p>When pushing performance like this, it starts to become important
  to take account of the way modern hardware is constructed. The
  phrase Martin Thompson likes to use is &#34;mechanical sympathy&#34;. The
  term comes from race car driving and it reflects the driver having
  an innate feel for the car, so they are able to feel how to get the
  best out of it. Many programmers, and I confess I fall into this
  camp, don&#39;t have much mechanical sympathy for how programming
  interacts with hardware. What&#39;s worse is that many programmers think
  they have mechanical sympathy, but it&#39;s built on notions of how
  hardware used to work that are now many years out of date.</p>

<p>One of the dominant factors with modern CPUs that affects
  latency, is how the CPU interacts with memory. These days going to
  main memory is a very slow operation in CPU-terms. CPUs have
  multiple levels of cache, each of which of is significantly
  faster. So to increase speed you want to get your code and data
  in those caches.</p>

<p>At one level, the actor model helps here. You can think of an
  actor as its own object that clusters code and data, which is a
  natural unit for caching. But actors need to communicate, which they
  do through queues - and the LMAX team observed that it&#39;s the queues
  that interfere with caching.</p>

<p>The explanation runs like this: in order to
  put some data on a queue, you need to write to that
  queue. Similarly, to take data off the queue, you need to write to
  the queue to perform the removal. This is write contention - more
  than one client may need to write to the same data structure. To
  deal with the write contention a queue often uses locks. But if a
  lock is used, that can cause a context switch to the kernel. When
  this happens the processor involved is likely to lose the data in its
  caches.</p>

<p>The conclusion they came to was that to get the best caching
  behavior, you need a design that has only one core writing to any
  memory location. Multiple readers
  are fine, processors often use special high-speed links between
  their caches. But queues fail the one-writer principle.</p>



<p>This analysis led the LMAX team to a couple of
  conclusions. Firstly it led to the design of the disruptor, which
  determinedly follows the single-writer constraint. Secondly it led to
  idea of exploring the single-threaded business logic approach,
  asking the question of how fast a single thread can go if it&#39;s freed
  of concurrency management.</p>

<p>The essence of working on a single thread, is to ensure that you
  have one thread running on one core, the caches warm up, and as much
  memory access as possible goes to the caches rather than to main
  memory. This means that both the code and the working set of data
  needs to be as consistently accessed as possible. Also keeping small
  objects with code and data together allows them to be swapped
  between the caches as a unit, simplifying the cache management and
  again improving performance.</p>

<p>An essential part of the path to the LMAX architecture was the
  use of performance testing. The consideration and abandonment of an
  actor-based approach came from building and performance testing a
  prototype. Similarly much of the steps in improving the performance
  of the various components were enabled by performance
  tests. Mechanical sympathy is very valuable - it helps to form
  hypotheses about what improvements you can make, and guides you to
  forward steps rather than backward ones - but in the end it&#39;s the
  testing gives you the convincing evidence. </p>

<p>Performance testing in this style, however, is not a
  well-understood topic. Regularly the LMAX team stresses that coming up with
  meaningful performance tests is often harder than developing the
  production code. Again mechanical sympathy is important to
  developing the right tests. Testing a low level concurrency
  component is meaningless unless you take into account the caching
  behavior of the CPU.</p>

<p>One particular lesson is the importance of writing tests against
  null components to ensure the performance test is fast enough to
  really measure what real components are doing. Writing fast test
  code is no easier than writing fast production code and it&#39;s too easy to get
  false results because the test isn&#39;t as fast as the component it&#39;s
  trying to measure.</p>
</section>

<section id="ShouldYouUseThisArchitecture">
<h2>Should you use this architecture?</h2>

<p>At first glance, this architecture appears to be for a very small
  niche. After all the driver that led to it was to be able to run
  lots of complex transactions with very low latency - most
  applications don&#39;t need to run at 6 million TPS.</p>

<p>But the thing that fascinates me about this application, is that
  they have ended up with a design which removes much of the
  programming complexity that plagues many software projects. The
  traditional model of concurrent sessions surrounding a transactional
  database isn&#39;t free of hassles. There&#39;s usually a non-trivial effort
  that goes into the relationship with the database. Object/relational
  mapping tools can help much of the pain of dealing with a database,
  but it doesn&#39;t deal with it all. Most performance tuning of enterprise
  applications involves futzing around with SQL.</p>

<p>These days, you can get more main memory into your servers than
  us old guys could get as disk space. More and more applications are
  quite capable of putting all their working set in main memory - thus
  eliminating a source of both complexity and sluggishness. Event
  Sourcing provides a way to solve the durability problem for an
  in-memory system, running everything in a single thread solves the
  concurrency issue. The LMAX experience suggests that as long as you
  need less than a few million TPS, you&#39;ll have enough performance headroom.</p>

<p>There is a considerable overlap here with the growing interest in
  <a href="https://olu.online/bliki/CQRS.html">CQRS</a>. An event sourced, in-memory processor is a
  natural choice for the command-side of a CQRS system. (Although the
  LMAX team does not currently use CQRS.)</p>

<p>So what indicates you shouldn&#39;t go down this path? This is always
  a tricky questions for little-known techniques like this, since the
  profession needs more time to explore its boundaries. A starting
  point, however, is to think of the characteristics that encourage
  the architecture.</p>

<p>One characteristic is that this is a connected domain where processing one
  transaction always has the potential to change how following ones are
  processed. With transactions that are more independent of each
  other, there&#39;s less need to coordinate, so using separate processors
  running in parallel becomes more attractive.</p>

<p>LMAX concentrates on figuring the consequences of how events
  change the world. Many sites are more about taking an existing store
  of information and rendering various combinations of that
  information to as many eyeballs as they can find - eg think of any
  media site. Here the architectural challenge often centers on
  getting your caches right.</p>

<p>Another characteristic of LMAX is that this is a
  backend system, so it&#39;s reasonable to consider how applicable it
  would be for something acting in an interactive mode. Increasingly
  web application are helping us get used to server systems that react
  to requests, an aspect that does fit in well with this
  architecture. Where this architecture goes further than most such systems is
  its absolute use of asynchronous communications, resulting in the
  changes to the programming model that I outlined earlier. </p>

<p>These changes will take some getting used to for most teams. Most
  people tend to think of programming in synchronous terms and are not
  used to dealing with asynchrony. Yet it&#39;s long been true that
  asynchronous communication is an essential tool for
  responsiveness. It will be interesting to see if the wider use of
  asynchronous communication in the javascript world, with AJAX and
  node.js, will encourage more people to investigate this style. The
  LMAX team found that while it took a bit of time to adjust to
  asynchronous style, it soon became natural and often easier. In
  particular error handling was much easier to deal with under this
  approach.</p>

<p>The LMAX team certainly feels that the days of the coordinating
  transactional database are numbered. The fact that you can write
  software more easily using this kind of architecture and that it
  runs more quickly removes much of the justification for the traditional
  central database.</p>

<p>For my part, I find this a very exciting story. Much of my goal
  is to concentrate on software that models complex domains. An
  architecture like this provides good separation of concerns,
  allowing people to focus on Domain-Driven Design and keeping much of
  the platform complexity well separated. The close coupling between
  domain objects and databases has always been an irritation -
  approaches like this suggest a way out.</p>
</section>

<hr/>
</div></div>
  </body>
</html>
