<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.bryanbraun.com/2023/05/17/augmented-development-with-ai/">Original</a>
    <h1>Augmented Development with AI</h1>
    
    <div id="readability-page-1" class="page"><div>
<p>The Nintendo GameBoy is an exceptionally well-documented system, perfect for anybody who’d like to take a crack at emulation. Publicly-maintained resources like the <a href="https://gbdev.io/pandocs/">Pan Docs</a> make it both approachable and convenient to get an overview of the GameBoy’s address space layout, to understand the mechanics of hardware peripherals, and to learn about various edge-case behaviors that some games depend on.</p>
<p>Over the past three weeks, I’ve been writing a GameBoy emulator my very own. This is not a unique project! I was inspired by the blog post of another adventurer doing the same thing. What’s the special sauce of this post, then? Rather than stopping at writing an emulator alone, I threw an extra requirement into the mix: The emulator should run and be playable under axle, my from-scratch and home-grown operating system.
Before I dive into the nitty-gritty, it’s worth asking: is this even feasible in axle’s present state?</p>
<video controls="" preload="auto" width="100%" playsinline="">
<source src="/writing-axles-gameboy-emulator/legend_of_zelda_in_axle.mp4" type="video/mp4"/>
<span>Your browser doesn&#39;t support embedded videos, but don&#39;t worry, you can <a href="https://www.bryanbraun.com/writing-axles-gameboy-emulator/legend_of_zelda_in_axle.mp4">download it</a> and watch it with your favorite video player!</span>
</video>
<p>Ah! Well then, off we go.</p>
<hr/>
<p>axle doesn’t (yet!) have the debugging facilities and development niceties that make modern software development possible, let alone pleasant. Therefore, we’ll have to work with some kind of dual-approach: it should be easy to both run the emulator on my macOS machine, for quick iteration, and to run it under axle when we’re ready to test the whole shebang.</p>
<p>Most software I develop for axle gets the simple only-runnable-within-axle approach, in part because most software that runs within axle uses axle-specific platform APIs for things like window/event-loop management and message passing. However, I’ve chosen the multi-platform approach for more complicated bits of software: the first one where this dual-pronged approach paid off was axle’s first iteration of a browser.</p>
<figure><img src="https://www.bryanbraun.com/2023/05/17/augmented-development-with-ai/desktop_with_browser.jpg" alt="axle desktop with browser visiting axleos.com, April 2021"/><figcaption>
<p><em>axle desktop with browser visiting <a href="https://axleos.com">axleos.com</a>, April 2021</em></p>
</figcaption>
</figure>
<p>Okay, let’s get started! I’m not totally new to emulation - I’ve written a fairly comprehensive AArch64 simulator - but one thing that’s new to me is emulating an entire system, complete with hardware peripherals, rather than just CPU and memory. Nevertheless, the beating heart (and great starting point!) of any emulator will be the CPU implementation. Let’s have a think about what our goals are here.</p>
<h2 id="the-cpu">The CPU</h2>
<p>All CPUs operate via the same fundamental cycle: fetch, decode, execute. Modern CPUs throw some spectacularly complicated wrenches into the mix, but for our purposes we’ll keep it simple.</p>
<p>Let’s break it down.</p>
<p>The fundamental data type of a computer is a fixed-size integer (these days, 64 bits). Again - we’re going to gloss over details like SIMD and hardware floating-point. If you know more, think of this as your moment to feel smug. Every song you’ve ever digitally consumed, PDF you’ve browsed, game you’ve played, or message you’ve sent boils down to streams of these numbers. This is not a particularly esoteric idea! What’s slightly more interesting, though, is that the <em>code</em> that’s facilitating these tasks is also just a stream of numbers.</p>
<p>Where is this <em>code</em> and <em>data</em> stored? In some kind of memory, typically RAM, that the CPU can access and operate on.</p>
<p>Let’s take a concrete example. Say our RAM contains some numbers like the following (expressed in hexadecimal):</p>
<pre tabindex="0"><code>48 65 6c 6c 6f 2c 20 77 6f 72 6c 64 21
</code></pre><p>The meaning of these numbers is <em>entirely</em> contextual! It could be some kind of data, yes: a piece of encoded text, a few encoded pixels within an image, a list of salaries (let’s hope not!), etc. Or, it could also be <em>code</em>: raw instructions that the CPU knows how to interpret to perform an operation. The way the bytes are interpreted, and therefore the meaning that gets derived from them, depends on the context in which the bytes are used.</p>
<p>In the example above, those bytes are the result of me encoding some <em>data</em> - in particular, the string “Hello, world!” - character-by-character into numbers, using the ASCII character encoding. Let’s take another example:</p>
<pre tabindex="0"><code>48 8b 04 25 00 00 00
</code></pre><p>Again, there’s no absolute meaning to these bytes, but the context in which I intend for them to be understood is as a piece of <em>code</em> to be run on an x86_64 CPU. An x86_64 CPU would understand that this sequence of bytes is telling it to move a number from one <em>register</em> to another. Another way of expressing the same thing as those bytes would be to write <code>mov $rax, $rbp</code>, but the details aren’t particularly important right now.</p>
<p>We could even have a sequence of bytes that can be understood as a perfectly valid sequence as either <em>code</em> or <em>data</em>:</p>
<pre tabindex="0"><code>6a 6b
</code></pre><p>If an x86_64 CPU tried to interpret this sequence of bytes as an instruction, it’d understand it a directive (or <em>instruction</em>) to “push 0x6b to the stack”. If we tried to interpret it as ASCII-encoded text, we’d instead understand this sequence as the text “jk”.</p>
<p>These mappings are entirely conventional! Why does <code>6a</code> correspond to <code>j</code> when interpreted as ASCII text? There’s no ‘fundamental’ reason. Through accidents of history, one particular way of mapping bytes to English characters proliferated enough for everybody to agree to formalize the mapping into a ‘dictionary’ called ASCII<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>. Similarly, how does an x86_64 CPU “know” that <code>6a</code> should mean <code>PUSH</code>? Just the same, AMD and Intel defined what an x86_64 CPU should be able to understand. When an assembler is generating code for this platform, it knows to emit this byte when it wants the CPU to run a <code>PUSH</code> instruction. When CPUs are manufactured in their <a href="https://en.wikipedia.org/wiki/Semiconductor_fabrication_plant">billion-dollar fabrication plants</a>, circuitry is lasered into the silicon that ensures that when the CPU reads the <code>6a</code> byte from memory, the CPU will do the corresponding operations associated with what we’d expect <code>PUSH</code> to do.</p>
<p>Okay, where were we going with this? Yes! CPU’s like to fetch, decode, and execute. The fundamental loop of a CPU is:</p>
<ol>
<li>
<p><em>Fetch</em> the next byte from memory.</p>
</li>
<li>
<p><em>Decode</em> the byte, interpreting it as an instruction the CPU knows how to understand.</p>
</li>
<li>
<p><em>Execute</em> the instruction, updating the system with the result of the operation indicated by the instruction.</p>
</li>
</ol>
<p>How does the CPU know where to <em>fetch</em> from? All CPUs contain an <em>instruction pointer</em><sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup> denoting where it’s currently fetching a byte from. This pointer would otherwise move along in a linear fashion, but one of the central tricks of computers is that this pointer can also be redirected, jumping backwards and forwards as the logic of the code dictates. This enables some neat use cases, such as <a href="https://en.wikipedia.org/wiki/Cryptanalysis_of_the_Enigma">winning WWII</a>.</p>
<p>Back to the GameBoy. It’s got a CPU, so we know it’ll be running a fetch, decode, execute loop. But what is it fetching its code <em>from</em>? The game cartridge slotted into the device! This cartridge will hold all the code <em>and</em> data necessary to run the game.</p>
<p>Hold on a second. We know that the <em>Fetch</em> stage gets the <em>next</em> byte from memory. What about the very <em>first</em> byte? How is the CPU going to start running code located in the game cartridge at all?</p>
<h2 id="the-boot-process">The boot process</h2>
<p>Earlier, I mentioned that code and data is stored in memory, <em>typically</em> RAM. Not always. There are special cases that vary based on the system - whether it be a GameBoy, a UEFI-based computer, an iPhone, etc.</p>
<p>When a device <em>first</em> boots, systems need some way to set themselves up enough to move on to something more advanced: this next step might be loading an operating system, handing off control to a game cartridge, or something else. This piece of code is purpose-built for the <em>boot</em> process, and it’s also typically etched into the silicon of the system when it’s manufactured. In other words, it’s <em>read only memory</em>, or ROM. Thus, this piece of code is generally referred to as the <em>boot ROM</em>.<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup></p>
<p>Hrm. We’ve established that the boot ROM is the first thing that runs, but really we’ve just pushed our question further back a bit. How does the CPU begin running the boot ROM when the system first starts up?</p>
<p>When the CPU is initialized, the aforementioned instruction pointer will contain the value 0. That is, the CPU will kick off its fetch-decode-execute lifecycle using whatever bytes are at the very beginning of memory.</p>
<p>So, our system needs some way to arrange things such that when the CPU reads byte# 00, it gets the first byte contained within the boot ROM, and so on for byte# 01, byte# 02, etc.</p>
<p>Enter the MMU. One way to think about memory is as a big list of bytes. Reading byte# 00 is equivalent to reading the first element of the list, while reading byte# 100 is equivalent to reading the 100<sub>16</sub>th<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> element of the list. Pretty straightforward. These byte indexes are alternatively called ‘addresses’, and the list itself is alternatively called a ‘space’<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup>. Thus, we get the term <em>address space</em>.</p>
<p>The CPU can read (or write, sometimes!) to each of these addresses, but where is the “other end”? Where is the data at these addresses <em>stored</em>? A first guess might be RAM, which is certainly on the right track. That said, it’s not the whole story.</p>
<p>The MMU, or <em>memory management unit</em>, mediates the CPU’s access to different hardware peripherals that are connected to the <a href="https://en.wikipedia.org/wiki/Bus_(computing)#Address_bus">address bus</a>, of which RAM is just one. When the CPU tries to access a given address, it’s the MMU’s job to determine which piece of underlying hardware that particular address belongs to, and to forward the access to that device as appropriate. The MMU even handles when the CPU tries to access a piece of memory that <em>no</em> device is providing. Different systems implement different behavior when something like this happens - some will generate an internal event that invalid memory was accessed (<a href="https://en.wikipedia.org/wiki/Page_fault">x86_64 does this</a>), some will have the MMU return all zeroes or all ones when an invalid address is read (the GameBoy does something like this).</p>
<p>With that knowledge in hand, it gets a lot easier to answer our question about how the boot ROM is executed: the MMU on the GameBoy has things set up such that when the CPU reads address 0, it will receive the first of the boot ROM’s bytes that were etched into the silicon when the GameBoy was manufactured.</p>
<p>Okay! Long walk for a short drink of water, but this knowledge will serve us well. Let’s track the sequence of events so far:</p>
<ol>
<li>
<p>The GameBoy receives power</p>
</li>
<li>
<p>The CPU sets its instruction pointer to 0</p>
</li>
<li>
<p>The CPU fetches the byte at the address indicated by its instruction pointer</p>
</li>
<li>
<p>The MMU routes the read of address 0 to the boot ROM</p>
</li>
<li>
<p>The first byte of the boot ROM is returned to the CPU</p>
</li>
<li>
<p>(We are here!) The CPU decodes the byte into an instruction</p>
</li>
</ol>
<p>Great! Our understanding has leveled-up from <em>Fetch</em> to the next stage, <em>Decode</em>.</p>
<h2 id="instruction-decoding">Instruction decoding</h2>
<p>Like we discussed, the correspondence of a number to its meaning when decoded as a directive to the CPU is contextual and dependent on the CPU in question. That said, there is a necessary level of shared understanding: the CPU itself <em>and</em> code that’s intended to run on that kind of CPU must agree on what each byte should mean. If we tried to run bytes compiled for x86_64 on a CPU manufactured to run AArch64, things would get very weird very quick because the semantic meaning of our code has been lost. This correspondence of numeric bytes to the directives or operations they’re associated with is termed the <em>set</em> of <em>instructions</em> that the CPU knows how to run, or the CPU’s <em>instruction set</em>.</p>
<p>The GameBoy’s instruction set is derived from that of the <a href="https://en.wikipedia.org/wiki/Zilog_Z80">Zilog Z80</a>. The lineage isn’t as important as the inheritance: like the Z80 it’s derived from, the GameBoy CPU runs an 8-bit instruction set. That is, instead of the fundamental data-type being the 64-bit integer we touched on above, the fundamental type is instead an 8-bit integer.</p>
<p>Each instruction starts off with an <em>opcode</em>, a 8-bit<sup id="fnref:6"><a href="#fn:6" role="doc-noteref">6</a></sup> value (or <em>code</em>) denoting what <em>op</em>eration the CPU should perform.</p>
<p>For example, say the CPU fetches this opcode:</p>
<p><code>76</code></p>
<p>What’s the contextual meaning for the GameBoy CPU of this opcode? The answer to this question is technically defined by the circuitry etched into every GameBoy CPU, but people have also come up with great visualizations of the GameBoy CPU’s instruction set to aid emulator writers. Here’s an opcode table from a <a href="https://meganesulli.com/generate-gb-opcodes/">great resource</a> I used while writing my emulator:</p>
<figure><img src="https://www.bryanbraun.com/2023/05/17/augmented-development-with-ai/opcode_table1.png" alt="8-bit GameBoy CPU opcodes"/><figcaption>
<p><em>8-bit GameBoy CPU opcodes</em></p>
</figcaption>
</figure>
<p>By following the ‘7’ row on the left and the ‘6’ column across the top, we can see that the opcode <code>76</code> corresponds to an instruction called <code>HALT</code>. When the CPU fetches this opcode, it will <em>decode</em> the byte and understand that it refers to the HALT instruction, then will run the operation associated with HALT (we’ll get there, don’t worry!)</p>
<figure><img src="https://www.bryanbraun.com/2023/05/17/augmented-development-with-ai/opcode_table1_halt_highlight.png" alt="HALT instruction within opcode table"/><figcaption>
<p><em>HALT instruction within opcode table</em></p>
</figcaption>
</figure>
<p>Some instructions can’t make do with just a single byte, but need some extra data to describe more details of their operation. For example, say the GameBoy CPU contained an <code>ADD Register A, u8</code> instruction<sup id="fnref:7"><a href="#fn:7" role="doc-noteref">7</a></sup>. The operation associated with this instruction would be to take the 8-bit value (the <code>u8</code>), and add it to the 8-bit value stored in <code>Register A</code>, then to store the result of the addition in <code>Register A</code>. Clearly, this is going to take more than a byte to store, because we need to know <em>what</em> 8-bit value to add to <code>Register A</code>. The 8-bit value will be stored directly following the opcode itself. Therefore, some instructions take up more than just one byte: we’ve got one byte for the opcode, plus either no data, 1 byte of data, or 2 bytes of data.</p>
<p>This <em>technically</em> makes the GameBoy CPU’s instruction set a <a href="https://en.wikipedia.org/wiki/Instruction_set_architecture#Variable_length"><em>variable-length encoding</em></a>, where the number of bytes it takes to <em>store</em> each instruction is dependent on what the instruction <em>does</em>. Some more contemporary instruction sets (particularly x86_64, another descendent of the 8080 lineage that the Z80 itself is descended from) get a lot more wacky with this, but thankfully the GameBoy CPU caps the maximum instruction size at three bytes.</p>
<p>Armed with the knowledge that an instruction can span multiple bytes, let’s take a look at the full GameBoy CPU opcode tables:</p>
<figure><img src="https://www.bryanbraun.com/2023/05/17/augmented-development-with-ai/opcode_table1.png" alt="8-bit GameBoy CPU opcodes"/><figcaption>
<p><em>8-bit GameBoy CPU opcodes</em></p>
</figcaption>
</figure>
<figure><img src="https://www.bryanbraun.com/2023/05/17/augmented-development-with-ai/opcode_table2.png" alt="16-bit GameBoy CPU opcodes"/><figcaption>
<p><em>16-bit GameBoy CPU opcodes</em></p>
</figcaption>
</figure>

<p>Whoa, did you catch that? Table<em>s</em>! Plural!</p>
<p>This is interesting, and shows where our digression about multi-byte instructions comes from: if every instruction took up exactly one byte, then there would be a maximum limit of 256 instructions in the instruction set, since a byte (equivalent to 8 bits) is capable of storing any number from 0<sub>10</sub> (<code>00000000</code><sub>2</sub>) to 255<sub>10</sub> (<code>11111111</code><sub>2</sub>)<sup id="fnref:8"><a href="#fn:8" role="doc-noteref">8</a></sup>. Thanks to the encoding scheme, it’s possible for the instruction set to define more than this. The GameBoy CPU ended up defining exactly 500 instructions<sup id="fnref:9"><a href="#fn:9" role="doc-noteref">9</a></sup>.</p>
<p>While some of these instructions are multi-byte because they contain an extra byte of <em>data</em> (like our <code>ADD Register A, u8</code> example), some of them are multi-byte because they contain an extra byte of <em>code</em>. Specifically, every instruction in the blue table has an initial opcode byte of <code>cb</code>, followed by a second opcode byte whose meaning is given by the table. I’ve seen this set referred to as the <em>cb opcodes</em><sup id="fnref:10"><a href="#fn:10" role="doc-noteref">10</a></sup>.</p>
<p>So! We’ve got our opcode, plus perhaps an extra byte or two that it needs to do its work. It’s time to <em>execute</em> the instruction, updating the system state by performing the operation indicated by the opcode.</p>
<p>There’s an important point here: we have multiple opcodes because each opcode <em>does something different</em> to the system. Each unique opcode maps to a unique operation that the CPU knows how to perform, and our fledgling CPU emulator will need to know how to apply every one of them to our emulated system.</p>
<h2 id="getting-clever-with-our-implementation">Getting clever with our implementation</h2>
<p>Thankfully, the task isn’t really so daunting as “implement 500 unique operations”. Many of the opcodes are variations on a theme. For example, let’s take a closer look at a snippet of the instruction tables from above:</p>
<figure><img src="https://www.bryanbraun.com/2023/05/17/augmented-development-with-ai/sub_instructions.png" alt="SUB instructions"/><figcaption>
<p><em><code>SUB</code> instructions</em></p>
</figcaption>
</figure>
<p>Each of these instructions starts off with <code>SUB</code>, then has a different letter it operates with. Looking at these opcodes as a whole, these are the possible letters that a <code>SUB</code> instruction may contain:</p>
<p><code>B, C, D, E, H, L, (HL), A</code></p>
<p>Each of these ’letters’, of course, mean something very specific in the context of the system: the GameBoy CPU, like <a href="https://en.wikipedia.org/wiki/Von_Neumann_architecture">any CPU</a>, computes with the help of <em>registers</em>. While 8-bit integers are the fundamental <em>data type</em> of the CPU, the register is the fundamental <em>data storage</em> of the CPU. Almost any time a CPU operates on an 8-bit number, it’s doing so by interacting with the contents of a register. When we want the CPU to read an 8-bit number, we use an instruction to load the byte located at a memory address into a given register. When we want to perform arithmetic, we specify the registers containing the numbers we want to operate on.</p>
<p>The GameBoy CPU has exactly eight registers. The names are arbitrary, but the GameBoy itself and our CPU table sheets call them:</p>
<p><code>B, C, D, E, H, L, A, F</code></p>
<p>Perfect! These exactly match up with what we saw in the variants of the <code>SUB</code> instruction, so each <code>SUB</code> instruction is clearly a slightly different version that performs a subtraction using the register on the right hand side.</p>
<p>…</p>
<p><em>Oh</em>.</p>
<p>Let’s see ’em side-by-side.</p>
<pre tabindex="0"><code>SUB operands:
B, C, D, E, H, L, (HL), A
CPU registers:
B, C, D, E, H, L, A, F
</code></pre><p>Well, that’s a complication. The possible <code>SUB</code> operands are <em>very similar</em>, but not identical, to the available CPU registers. And what <em>is</em> that <code>(HL)</code> doing there, anyway? Clearly, we’ve got some talking to do.</p>
<p>While what I said before is true, that the CPU mostly performs computations via loading data into registers, it’s not the full story. The CPU is also able to perform computations by talking directly to memory, without needing to involve an extra load/store with a register.</p>
<p>The GameBoy CPU provides exactly one way to do such a thing. With some instructions, the GameBoy CPU knows how to take the values in the H and L 8-registers, stick them side-by-side to create a 16-bit number, then read the value at the address indicated by the 16-bit number from memory. This operation of “reading the value at an address” is indicated by the <code>()</code> surrounding the <code>HL</code>, and is more generally referred to as <em>dereferencing</em> the address. We’ll see more of it later. But first! An example of what this would look like in practice<sup id="fnref:11"><a href="#fn:11" role="doc-noteref">11</a></sup>:</p>
<pre tabindex="0"><code>H: aa
L: bb
(HL): The byte currently stored at address aabb
</code></pre><p>Okay, sure, along with the 8-bit registers we can also perform some operands by dereferencing the value in <code>HL</code>, or <code>(HL)</code> for short. Is that all?</p>
<p>Back to our <code>SUB</code> operands and available CPU registers, there’s another glaring omission: we can see that the CPU contains an <code>F</code> register, but there’s no <code>SUB</code> variant that supports it. What gives?</p>
<p>Well, the <code>F</code> register is special: rather than being a general-purpose 8-bit register like the rest, it instead serves as the special-purpose <a href="https://en.wikipedia.org/wiki/FLAGS_register"><em>flags</em> register</a>. That is, over the course of execution of an instruction, the system might want to note some resulting state for further processing. For example, if the result of the <code>SUB</code> instruction is exactly zero, the <code>Z</code> bit in the flags register will be set. The CPU then has other instructions that do different things based on whether a particular flag is set or not. The <code>F</code> register isn’t directly accessible to the programmer; its various bits can be set as side-effects of running instructions, and its status can be implicitly read by running instructions that do different things based on its contents.</p>
<p>Right. We’ve got our <code>SUB</code> operands. When we fetch the opcode indicated by the instruction pointer, how will we know which <code>SUB</code> instruction to execute?</p>
<figure><img src="https://www.bryanbraun.com/2023/05/17/augmented-development-with-ai/opcode_table1_sub_instructions.png" alt="SUB instructions with opcodes"/><figcaption>
<p><em>SUB instructions with opcodes</em></p>
</figcaption>
</figure>
<p>Of course, one way to do this is in a slightly brain-dead “if the opcode is 90 do this, if the opcode is 91 do that, …”, but I think we can do a bit better. Let’s write out all the <code>SUB</code> opcodes and see if we can spot anything:</p>
<p><code>90 91 92 93 94 95 96 97</code></p>
<p>There’s a nice and simple property staring us in the face - it’s also quite visible from looking directly at the opcode table above. The <code>SUB</code> instructions start at <code>90</code>, and increment by 1 for each right-side operand. Let’s take a look at the binary representation of each opcode:</p>
<pre tabindex="0"><code>90: 10010000
91: 10010001
92: 10010010
93: 10010011
94: 10010100
95: 10010101
96: 10010110
97: 10010111
</code></pre><p>We can see that each <code>SUB</code> opcode starts with the same pattern in the most significant bit: <code>10010___</code>, followed by a sequence that counts up by 1 for each variant: <code>000</code>, <code>001</code>, <code>010</code>, <code>011</code>, <code>100</code>, <code>101</code>, <code>110</code>, <code>111</code>. This is convenient for us! It means we can do some pattern matching on whatever opcode byte we’ve fetched. If the high bits match the <code>10010</code> pattern that all <code>SUB</code> instructions follow, we know that we’ve fetched a <code>SUB</code> instruction, and all that’s needed is to take those lower 3 bits as an index into the table that will tell us which register to subtract with.</p>
<figure><img src="https://www.bryanbraun.com/2023/05/17/augmented-development-with-ai/sub_incrementing_index.png" alt="Incrementing index in SUB opcode encoding"/><figcaption>
<p><em>Incrementing index in <code>SUB</code> opcode encoding</em></p>
</figcaption>
</figure>
<p>Er. Not always a register - our friend <code>(HL)</code> is still around, ready to fetch memory at a moment’s notice.</p>
<p>This is really nice! With one fell swoop, we’ve managed to knock out <em>eight</em> instructions with <em>one</em> implementation.</p>
<p>One minor point I’ve glossed over up to know: We’ve got a <code>SUB</code> instruction, we’ve decided what register it’s subtracting <em>with</em>, but what is it going to subtract <em>from</em>? And where does the result of the subtraction <em>go</em> once we’ve performed it?</p>
<p>We’ve got another register with privileged status to discuss: the <code>A</code>, or <a href="https://en.wikipedia.org/wiki/Accumulator_(computing)#Accumulator_machines"><em>accumulator</em> register</a>. A common concept among instruction sets, the <code>A</code> register is both an implicit operand to, and implicit destination of, <code>SUB</code> instructions (and many other instructions!) In other words, while the <code>SUB</code> instruction only mentions one operand on the tin, it actually performs an operation something like the following:</p>
<p><code>A = A - Operand</code></p>
<p>Again, this isn’t the whole picture: executing this instruction may also update various status bits in the <code>F</code> register, such as whether the result was exactly zero, whether the subtraction underflowed, and a few other conditions.</p>
<p>Let’s look at another instruction!</p>
<figure><img src="https://www.bryanbraun.com/2023/05/17/augmented-development-with-ai/opcode_table1_dec_instructions.png" alt="DEC instructions"/><figcaption>
<p><em><code>DEC</code> instructions</em></p>
</figcaption>
</figure>
<p>The <code>DEC</code> instructions subtracts 1 from the operand and places the result back into the operand’s storage. In other words, it performs this operation:</p>
<p><code>Operand = Operand - 1</code></p>
<p>This is straightforward in the case where the operand is a register, and requires just a hair more thought when the operand in question is <code>(HL)</code>. Sketching out what that might look like, we get:</p>
<pre tabindex="0"><code>H = 11
L = 22
HL = 1122
</code></pre><p>In this case, we’ll be running <code>DEC</code> with the <em>dereferenced</em> value of <code>HL</code>, or the byte stored at address 1122. Let’s pretend this address already contains some value:</p>
<pre tabindex="0"><code>(1122) = 77
</code></pre><p>When we run the <code>DEC (HL)</code> instruction, we’ll read the current value of <code>(HL)</code>: first, we conjoin the 8-bit values of <code>H</code> and <code>L</code>, <code>11</code> and <code>22</code>, to yield a 16-bit address, <code>1122</code>. Then, we’ll ask the MMU to read the byte at address <code>1122</code>, and we’ll get <code>77</code> back. Finally, we’ll subtract <code>1</code> from that value, and store the result back into the byte stored at address <code>1122</code>. Nothing too snazzy here, but we’ll want to keep it in mind when designing our routines that can execute an instruction given any of its operand variants. Early on, I had to rework my first implementation so that it could reuse the same code to handle both plain registers and <code>(HL)</code>.</p>
<p>The <code>DEC</code> family sounds straightforward enough. Can we do the same trick we pulled with <code>SUB</code>, in which we implement a bunch of similar instruction variants with a single implementation?</p>
<p>With <code>SUB</code>, things were pretty simple: the operand we were supposed to work with was clear, with a one-to-one correspondence starting from opcode <code>90</code>. With <code>DEC</code>, things are looking a bit shakier: the various opcodes are on entirely different sides of the table, and certainly aren’t incrementing by one from one variant to the next.</p>
<p>Can we spot anything if we write out the <code>DEC</code> variants’ hexadecimal representations?</p>
<pre tabindex="0"><code>05
0d
15
1d
25
2d
35
3d
</code></pre><p>Hmm… There’s certainly a pattern here, but it’s not clear to me how we’d take a look at an opcode and immediately see both that it’s a <code>DEC</code>, and which variant it is. Maybe looking at the binary representations of each opcode will shed some light?</p>
<pre tabindex="0"><code>00000101
00001101
00010101
00011101
00100101
00101101
00110101
00111101
</code></pre><p>Yes! We’ve got the same pattern of three bits counting up one-by-one to describe what variant the opcode refers to, except this time around those three bits are <em>sandwiched in the middle of the opcode</em>! We can identify a <code>DEC</code> by checking whether the opcode matches <code>00___101</code>, and those three bits in the middle tell us what operand we’ll be working with in the same counting-by-one fashion as before. I find this really interesting, because this pattern isn’t apparent at all when looking at how the opcodes are visually laid out in the table, but it’s <em>really clear</em> when writing out the binary representations of the opcodes!</p>
<figure><img src="https://www.bryanbraun.com/2023/05/17/augmented-development-with-ai/dec_incrementing_index.png" alt="Incrementing index in DEC opcode encoding"/><figcaption>
<p><em>Incrementing index in <code>DEC</code> opcode encoding</em></p>
</figcaption>
</figure>
<p>That should be a pretty good foundation to get us going writing our emulated CPU in software. The thing about a CPU, though, especially when writing a virtual one, is that it gets a lot more useful when you’ve got some code you’d like to execute on it!</p>
<h2 id="running-a-program">Running a program</h2>
<p>We’ve got <em>hundreds</em> of opcodes to implement, and some kind of plan to divide-and-conquer will be vital to implementing this thing in an approachable way. If we pick an existing program that we’d like to run on our fledgling CPU, it’ll provide us with a great system for knocking out segments of the instruction set:</p>
<ol>
<li>
<p>Load the program into our virtual environment</p>
</li>
<li>
<p>Kick off the CPU on its fetch/decode/execute lifecycle</p>
</li>
<li>
<p>Keep going until the CPU fetches an opcode it doesn’t yet support</p>
</li>
<li>
<p>Implement the missing opcode (and its relatives, if any)</p>
</li>
<li>
<p>Repeat!</p>
</li>
</ol>
<p>But what program to pick? Ideally we’d want something that’s approachable in size (so we don’t have to implement every opcode under the sun before we see results), that’s well-understood (so we can check whether our emulated CPU is doing the right thing), and that’d be useful code to run anyway.</p>
<p>A great candidate here might be the boot ROM that executes every time the GameBoy boots! Let’s see:</p>
<ol>
<li>
<p>Approachable in size? Yep, the boot ROM fits in just 256 bytes.</p>
</li>
<li>
<p>Well-understood? Undoubtedly - people have annotated the boot ROM’s instructions line-by-line.</p>
</li>
<li>
<p>Useful in its own right? The boot ROM is responsible for showing the classic <code>Nintendo</code> logo on startup, so I’d go as far to say this is <em>essential</em>.</p>
</li>
</ol>
<p>That last point is a real classic, and very familiar to anyone who’s played a GameBoy: the scrolling logo is the start to every session! This means that the boot ROM both a functional program, and an iconic part of the GameBoy experience.</p>
<p>Now, it’s useful to understand what the boot ROM is <em>doing</em> exactly, so we know the shape of things to expect. We know that <em>in general</em> the boot ROM’s responsibility is things like initializing the rest of the system in such a way that later code can run in a known state, but the boot ROM can have other responsibilities, too. One of these responsibilities, both in the case of the GameBoy and many other systems, is verifying the integrity of the rest of the code the system will execute.</p>
<h2 id="trusting-trust">Trusting trust</h2>
<p>This leads to a concept called the <em>chain of trust</em>. The boot ROM, as we know, is <em>read-only</em>, so if we <em>trust</em> the boot ROM and the <em>boot ROM</em> trusts whatever it loads next, we’ve established a <em>chain</em> ensuring that any code that the system runs is ‘safe’. The definition of ‘safe’ varies: it might mean that the code has been signed with a cryptographic signature, for example, assuring that the program has been verified and authorized by the platform vendor, or it might validate that the code hasn’t been tampered with after compilation.</p>
<p>The GameBoy, however, does no such cryptographic validation of the next piece of code to run after the boot ROM. Released in 1989, I am not sure whether this is down to cryptographic validation being too taxing for the constrained hardware that the GameBoy packs, whether the contemporary techniques for code signing had not been developed to a sufficient degree to enable Nintendo to cryptographically secure the games of third party developers, whether they simply weren’t able to pack enough code into the boot ROM to do cryptographic validation while balancing other tradeoffs, or some other reason. Nevertheless, the case remains that the boot ROM performs no such thing. That said, Nintendo still wanted some measure of control over the system! With any entertainment platform, there is a palpable propensity for end-user control and modification. The consequences of this can range from the outright cool (hobbyist games and demoscenes), to the explicitly negative for Nintendo and games publishers (pirated games redistributed without paying the developers).</p>
<p>Without any way to <em>technologically</em> enforce that all software running on the GameBoy must be authorized by Nintendo, is there some <em>other</em> way to enforce this?</p>
<p>Yes indeed! Nintendo did something very clever here. Remember the classic <code>Nintendo</code> logo that scrolls down from the top of the screen when the boot ROM executes? Rather than including the Nintendo logo data in the boot ROM and loading it into the video RAM data directly, Nintendo <em>required</em> that every game cartridge contained its own copy of the Nintendo logo.</p>
<p>Do you see the trick here?</p>
<p>…</p>
<p>It’s a threat.</p>
<p>Nintendo is staving off pirates and unauthorized redistributions by threatening them with copyright law. To ship an unauthorized or pirated game, the pirate is forced to distribute the Nintendo logo too. Clever!</p>
<p>One interesting consequence of this is that <em>every GameBoy cartridge ever manufactured</em> contains the same redundant copy of the Nintendo logo, over and over again in duplicated silicon counted in millions, all to threaten would-be pirates.</p>
<p>Except… how does the boot ROM know that the logo stored in the cartridge is the correct logo at all? Couldn’t we just put anything in there and allow the boot ROM to display it?</p>
<p>Well, yes!</p>
<p>We can stick anything we’d like in the cartridge memory that’s supposed to contain the Nintendo logo. Here’s what the boot screen looks like if we don’t initialize the cartridge logo memory at all<sup id="fnref:12"><a href="#fn:12" role="doc-noteref">12</a></sup>:</p>
<figure><img src="https://www.bryanbraun.com/2023/05/17/augmented-development-with-ai/empty_cartridge_logo.png" alt="Invalid Nintendo boot logo"/><figcaption>
<p><em>Invalid Nintendo boot logo</em></p>
</figcaption>
</figure>
<p>Seems like a pretty simple circumvention for Nintendo’s litigative DRM, no? Unfortunately, when I called the cartridge logo redundant, I <em>really</em> meant it: the boot ROM contains its <em>own</em> copy of the Nintendo logo, too. It doesn’t display it, though: it reads the logo data from the cartridge, displays it, <em>then</em> checks it against the copy of the logo stored in the boot ROM itself. If there’s any kind of mismatch, the boot ROM will lock up the system to prevent any further use.</p>
<p>Going back to the task at hand: we want to run the boot ROM code as a tool to help move us along our CPU implementation, but to <em>run</em> the program we’ll first need to <em>have</em> the program in the first place. How do we know what code the boot ROM contains?</p>
<h2 id="acquiring-the-boot-rom">Acquiring the boot ROM</h2>
<p>This might seem straightforward at first glance: the boot ROM program has been etched into the silicon of every GameBoy ever produced, so can’t we just… read it?</p>
<p>Well, yes, in theory we can. Practically, though, <em>reading</em> data from a physical medium measured in micrometers is no small feat. In fact, it took <em>14 years</em> before <a href="https://gbdev.gg8.se/wiki/articles/Gameboy_Bootstrap_ROM#The_DMG_bootstrap">someone managed</a> to do it, armed with no less than a powerful microscope, a GameBoy CPU with the plastic housing chemically dissolved away, and a whole lot of gumption.</p>
<p>Thanks to their work, copies of the boot ROM, both in ready-to-run compiled bytes and annotated assembly, are floating ‘round on the net - waiting for any intrepid emulator developer who’s ready to take them on.</p>
<p>Hrm. Hang on a second. <em>14 years</em> to read the boot ROM? Couldn’t a game just, like, read out the contents of the boot ROM addresses when the game starts running, then display the data on the screen or something?</p>
<p>Well, yes. That’s why Nintendo included one more trick in the jam-packed 256 bytes of code in the boot ROM. Recall our earlier digression on the MMU:</p>
<p>When the CPU accesses an address, the MMU will route the access to the peripheral that ‘owns’ that address. Say the CPU reads address <code>#00</code>. This is within the boot ROM, so the first byte of the boot ROM will be accessed. What about address <code>#ff</code>? Still within the boot ROM, so the MMU will route the access there. And address <code>#100</code>? The boot ROM takes exactly 256 bytes to store, so this is <em>just</em> outside the boot ROM’s address space. Instead, the MMU will route this access to a different peripheral: the game cartridge.</p>
<p>With our idea above, the game cartridge would read addresses <code>#00</code> through <code>#ff</code>, storing or displaying their contents so that a human could read the boot ROM data. Why doesn’t this work?</p>
<p>As its <em>final</em> flourish, the last 4 bytes in the 256-byte boot ROM encode the following 2 instructions:</p>
<pre tabindex="0"><code>Address: #00fc    Byte(s): 3e 01    Description: Load Register A with 01
Address: #00fe    Byte(s): e0 50    Description: Load (ff50) with Register A
</code></pre><p>Feeling enlightened? Me neither. Let’s head to the <a href="https://gbdev.io/pandocs/Memory_Map.html?highlight=ff50#io-ranges">Pan Docs</a> to see what’s so special about the address <code>#ff50</code>.</p>
<figure><img src="https://www.bryanbraun.com/2023/05/17/augmented-development-with-ai/mmio_ranges.png" alt="Memory-mapped IO descriptions"/><figcaption>
<p><em>Memory-mapped IO descriptions</em></p>
</figcaption>
</figure>
<p>Ah ha! Similarly to how the MMU will redirect any accesses to the boot ROM address range to the boot ROM itself, the MMU also implements some special addresses: accessing them (via reads or writes, depending) triggers special system behavior. Writing a value of <code>1</code> to address <code>#ff50</code>, in particular, causes the MMU to effectively <em>disable</em> the boot ROM! After this value has been written, the MMU won’t forward any accesses in the address range <code>#00 - #ff</code> to the boot ROM any longer. Instead, the MMU will direct these accesses to the game cartridge. There’s also <em>no way</em> to disable this behavior once enabled, short of rebooting the system!</p>
<p>In other words, the <em>very last thing</em> the boot ROM does, <em>just</em> at the cusp of the instruction pointer iterating past the <code>#00 - #ff</code> range, is write a special value that’ll cause the MMU to disable any and all ability to reach the boot ROM data via memory access. This is spectacularly well-timed, as the <em>moment</em> the CPU is finished running this instruction, its instruction pointer reaches <code>#100</code> and it leaves the <code>#00 - #ff</code> range it was previously running within. The game that’s been loaded has no way to talk to the boot ROM, <em>but</em> there is the bonus that the game is free to use the <code>#00 - #ff</code> range for its own purposes<sup id="fnref:13"><a href="#fn:13" role="doc-noteref">13</a></sup>.</p>
<p>OK, acid and microscopes it is. Let’s recap the major functions of the boot ROM program:</p>
<ol>
<li>
<p>Initialize the system</p>
</li>
<li>
<p>Load the Nintendo logo from the game cartridge</p>
</li>
<li>
<p>Scroll the logo onto the screen</p>
</li>
<li>
<p>Validate the logo’s validity</p>
</li>
<li>
<p>Disable the boot ROM and allow the cartridge to begin running its code</p>
</li>
</ol>
<p>The nice thing about writing an emulator is we <em>don’t need to know</em> exactly how the emulated program does each of these things! All we really need to do is provide the environment that the program expects itself to be running within, and to run its code faithfully. The program will do the rest. This is a really powerful idea: it means that we can write an emulator that runs popular games, without us ever needing to know how those games work under the hood. In fact, our emulator is <a href="https://en.wikipedia.org/wiki/Turing_completeness#Non-mathematical_usage">theoretically</a> equivalent to <em>any</em> computer. That is, <em>anything</em> that can be computed can be computed in our emulated environment (modulo resource constraints). I wouldn’t go porting a desktop environment to the GameBoy anytime soon, but the magic is in the idea that you <em>could</em>: our emulated CPU will be underneath, dutifully chugging along, facilitating someone else’s program to carry out its logic without really needing to know anything about what’s going on at the higher level.</p>
<p>Back to our earlier idea, and boot ROM dump in-hand, let’s fashion ourselves an emulator workshop. We’ll run the boot ROM within our virtual system, over and over again, pressing on just a bit further in execution each time as we implement more of the opcodes the program relies on to execute. To keep track of my progress, I colored in each set of opcodes as I finished their implementation, leaving me with a nice and neat time-lapse of how it went. I only allowed myself to color in an instruction once I’d finished both the implementation and associated unit tests, which kept me disciplined. It’s hard to overstate how satisfying it was to watch this table grow more and more occluded!</p>
<figure><img src="https://www.bryanbraun.com/2023/05/17/augmented-development-with-ai/main_opcode_progress.gif" alt="8-bit opcode table time-lapse"/><figcaption>
<p><em>8-bit opcode table time-lapse</em></p>
</figcaption>
</figure>
<figure><img src="https://www.bryanbraun.com/2023/05/17/augmented-development-with-ai/cb_opcode_progress.gif" alt="16-bit opcode table time-lapse"/><figcaption>
<p><em>16-bit opcode table time-lapse</em></p>
</figcaption>
</figure>
<h2 id="next-steps">Next steps</h2>
<p>Of course, all the instructions in the world won’t do us much good without a way to observe their side-effects. We know the boot ROM is supposed to be scrolling a logo, but where would we <em>see</em> that? It’s time to move on to our next system component, a particularly formidable beast: the PPU.</p>

</div></div>
  </body>
</html>
