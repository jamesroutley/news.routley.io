<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://database.dev">Original</a>
    <h1>dbdev - The Database Package Manager for PostgreSQL Trusted Language Extensions</h1>
    
    <div id="readability-page-1" class="page"><div>
	
<h2>11 April 2023</h2>
<h3>It&#39;s not actually that hard!</h3>
<h5>(tldr check out my <a href="#list" target="" rel="">list</a> of vetted introductory graphics resources)
</h5>
<p>So, I&#39;m finally getting around to writing up what it is I actually spent the past three months at <a href="https://www.recurse.com/" target="" rel="">Recurse</a>
	working on. For the most part, I&#39;ve been dabbling in graphicsey stuff in Rust, and it&#39;s been an absolute
	blast! Well. Mostly. Except for the whole part where nearly everything in Rust graphics world is pre-1.0
	release and therefore often limited-scope and buggy. And the part with all the
	<a href="https://wiki.archlinux.org/title/Wayland" target="" rel="">Wayland-</a> and Linux NVIDIA-
	specific bugs in common low-level graphics crates, causing me at one point to give in and install i3
	(an X11 WM) just to get
	<a href="https://nannou.cc/" target="" rel="">nannou</a>
	running at all. Aand the part where I still can&#39;t get
	<a href="https://www.w3.org/TR/webgpu/" target="" rel="">WebGPU</a>, the shiny new browser
	graphics API, working in Firefox Nightly or Chrome Canary on Arch.<a href="#webgpu">^</a><span id="webgpu-note"></span></p>
<p>But we&#39;re not here to talk about any of that today! Instead, I&#39;ll bring you back with me to late
	January. Back before I had ever heard of &#34;padding my buffers&#34; <a href="https://github.com/gfx-rs/wgpu/issues/2832" target="" rel="">(. . .)</a>
	or encountered <span>&#39;Error in Surface::configure: parent device is lost&#39;</span>
	<a href="https://github.com/gfx-rs/wgpu/issues/2519" target="" rel="">(. . .)</a> or seen deeply
	nested closures used to recreate the CSS box model in Rust
	<a href="https://github.com/jmgisele/double-slit/blob/main/src/ui.rs#L145" target="" rel="">(. . .)</a>.
</p>
<p>No, for today we&#39;re going back to the &#34;childlike delight&#34; stage of my new hobby. Shortly after
	<a href="https://www.blog.jamesgisele.com/blog/hello_world/" target="" rel="">writing about</a> how much I missed math, but was
	entirely unsure what kind of &#34;math&#34; I wanted to be doing, I discovered
	<a href="https://www.youtube.com/watch?v=jvPPXbo87ds&amp;t=2726s" target="" rel="">this video</a> by
	Freya Holm√©r on splines and was like &#34;oh, cool, making pretty pictures happen on screen involves lots
	of math. Let&#39;s do that!&#34;
</p>
<h3>baby&#39;s first MVP (model view projection)</h3>
<p>For my first Rust project and my first graphicsey project, I decided to write a software renderer.
	I was inspired by <a href="https://www.youtube.com/watch?v=ih20l3pJoeU&amp;t=1667s" target="" rel="">this fantastic series</a>
	by youtuber javidx9 on creating a 3D graphics engine using C++, Visual Studio, and the Windows console.
	I had no interest in learning C++ or reinstalling Windows, however, so I decided to port the engine
	to Rust.
</p>
<h4>a lesson in choosing your degrees of freedom (potential sources of bugginess)</h4>
<p>Porting an existing codebase was a
	<i>very</i>
	good first project! Graphics is <i>hard</i>. I was coming from the web development world
	primarily, where the browser does a lot of the heavy lifting for you in so, so many domains, from
	memory management to multiplatform support to &#34;how render font&#34; (a perhaps
	<a href="https://faultlore.com/blah/text-hates-you/" target="" rel="">surprisingly difficult</a> problem!). Picking up Rust is also hard if you&#39;re coming from exclusively high-level languages; you
	have to spend a while macerating in borrow-checker soup to get any sort of intuition for Rust&#39;s memory
	model. Choosing a project where I had a source-of-truth for what something should look like was
	<i>extremely</i> helpful; it helped narrow down which bugs were due to (my incomprehension of) which
	tech.
</p>
<p>javidx9&#39;s series has WIP files on github for each video, which was invaluable in making sure my
	renderer was having the &#34;right&#34; issues at each point in its iteration. Graphics programming
	generally involves a &#34;pipeline&#34; with various coordinate systems and transformations/calculations
	associated with each step in this pipeline. For an experienced graphics dev, it&#39;s often evident
	what stage the issue is happening in based on what the symptoms are: screwy shapes = vertex or
	projection issue, screwy colors = fragment or lighting issue, to drastically oversimplify. For a
	newb, it&#39;s difficult to figure out what each phase even
	<i>does</i> spatially, let alone figure out which stage is causing which problem. So, a project where
	there was a well-defined SOT was invaluable.
</p>
<h4>shaders are cool and also they are hard</h4>
<p>javidx9&#39;s series was also fantastic because it ignored much of the tech that makes graphics
	programming powerful and also notoriously difficult to learn --- talking to the GPU --- in favor
	of explaining how 3D rendering works conceptually. By making a software renderer, I got to learn
	about the basics of 3D graphics --- model/world/view/clip coordinates, projection, clipping,
	cameras, z buffers, light sources, painting textures --- without having to worry about the
	particularities of talking to the GPU. Programs that run on the GPU (aka shaders) are notoriously
	difficult to debug for important performance-related reasons; building an intuition for how this
	stuff &#34;works&#34; while the Rust compiler had my back was very helpful for when i moved on to shader
	programming and had fewer <span>print</span> statements to rely on.
</p>
<p>But simultaneously. . .there&#39;s, like, a reason people made GPUs, lol. There are only so many
	performance gains to be made and only so many vertices one can render when using the CPU
	exclusively to carry out all the many calculations required to paint a 3D frame. The renderer I
	wrote is moderately performant only for low-poly .obj files; if I eventually add in textures, it
	will be even less performant. Writing a software renderer was both very satisfying and also not
	something I can seriously build on after a certain point.
</p>
<h3>ok but like. what is it. how does it work</h3>
<h5>what follows is a very high level overview of what my engine implements, glossing over some
	details. if you&#39;re here more for a list of stuff that I found helpful, scroll to the <a href="#list" target="" rel="">end!</a></h5>
<h4>first things first: stuff i didn&#39;t do</h4>
<p>I decided I did not want to deal with implementing &#34;make window happen cross-platform&#34; or &#34;listen
	for user keypresses,&#34; so I used <a href="https://github.com/emoon/minifb" target="" rel="">minifb</a> for that.
	<a href="https://github.com/rust-windowing/winit" target="" rel="">Winit</a> seems to be the standard
	for Rust, but at the time its current release had a NVIDIA-Wayland bug that required patching manually,
	and I decided I&#39;d just use a crate that worked as-is, thanks.
</p>
<p>Controversially perhaps, I also decided I did not want to deal with figuring out how to draw a
	line between two points. (If that interests you, check <a href="https://rust-tutorials.github.io/triangle-from-scratch/" target="" rel="">this project</a>
	out!) I messed around trying to get several Rust graphics crates hooked up (there are a LOT to choose
	from), but <a href="https://github.com/jrmuizel/raqote" target="" rel="">raqote</a>&#39;s API was
	simple and it can draw lines real good, which is what I needed. If you&#39;re trying to decide which
	graphics crate to use, first of all--- good luck! there are so many! Second of all maybe take a
	look at
	<a href="https://wiki.alopex.li/AGuideToRustGraphicsLibraries2019" target="" rel="">this post</a> if you&#39;re doing something serious, it&#39;s got a good overview though it&#39;s a couple years old. Also,
	this
	<a href="https://github.com/ocboogie/rust-graphics-crates" target="" rel="">github</a>
	readme. Also,
	<a href="https://www.reddit.com/r/rust/comments/gggirx/getting_started_into_graphics_programming_where/" target="" rel="">this</a>
	reddit thread. Like I said, there&#39;s a lot! (Trivia: One of the core
	<a href="https://raphlinus.github.io/rust/graphics/2018/10/11/2d-graphics.html" target="" rel="">people behind</a>
	<a href="https://github.com/linebender/piet" target="" rel="">piet</a>
	is a Recurser I recently learned, which is pretty cool!)
</p>
<h4>so we&#39;ve got a window and a framebuffer. now what</h4>
<p>Oh, you <b>know</b> what&#39;s next! It&#39;s <i>triangles</i> time baybee!</p>
<p>Turns out that if you can draw triangles that form a rotating cube, you&#39;re like, halfway to
	implementing skyrim.<a href="#skyrim">^</a><span id="skyrim-note"></span>
	The math is roughly the same because almost everything in computer graphics is represented as triangles,
	points, and lines, which was kinda shocking to me originally tbh. Ok, probably there are <a href="https://developer.nvidia.com/gpugems/gpugems/part-vi-beyond-triangles" target="" rel="">huge exceptions to this rule</a> but polygon-based rendering is extremely common.
</p>
<p>So, you&#39;ve got a list of triangles representing a shape (say, a cube), stored in an .obj file as a
	simple list of vertices and faces. And you&#39;d like them to show up on a screen and resemble that
	shape (say, a cube). Unfortunately for you, the cube is represented in three-dimensional space
	(it&#39;s a cube, not a square!) and your screen is two-dimensional. So, we
</p>
<h4>project to 2D</h4>
<p><img src="https://www.blog.jamesgisele.com/_app/immutable/assets/two_d.e6e27bde.png" alt="a cube projected to two dimensions, that looks more like a square"/></p>
<p>So, that looks pretty nice. Two obvious problems, though: the cube isn&#39;t centered very well, and
	you can&#39;t actually tell it&#39;s a cube. From the angle we&#39;re at, it looks like more of a square.
	Wouldn&#39;t it be nice if we could change where we&#39;re positioned with respect to the cube, so we can
	get a nice viewport? We could even use a nifty name for the matrix math we use to get there,
	something intuitive, maybe
</p>
<h4>a camera system</h4>
<p><img src="https://www.blog.jamesgisele.com/_app/immutable/assets/camera.ec25d7ab.png" alt="a cube projected to two dimensions, centered and looking cubely"/></p>
<p>Ahh, that&#39;s more like it! I don&#39;t feel like going into the math, so <a href="https://www.3dgep.com/understanding-the-view-matrix/" target="" rel="">here</a> is a great link if that&#39;s what you&#39;re into. TLDR-- in the real world, you generally move cameras
	around the scene to get different viewing angles, look at different objects, etc. With this engine
	(as with many others), you actually do the reverse -- you &#34;move&#34; the vertexes representing your scene
	around the camera, defined at the origin of this coordinate system, to &#34;look at&#34; different parts of
	the scene. You define where your camera is (the origin), which direction you&#39;re looking, how near and
	far you can &#34;see&#34; objects, and a frame of view -- and then rotate the world so its coordinates are
	relative to this coordinate system. I promise it makes more sense with the math!
</p>
<p>So this is great. Except....Things look a little flat, don&#39;t they? Every face of the cube is
	shaded the same. In the real world, things look a little more dimensional. To get that dimension
	from our engine, we&#39;ll have to add in some
</p>
<h4>light</h4>
<p><img src="https://www.blog.jamesgisele.com/_app/immutable/assets/light.bec265be.png" alt="a cube, with different colors on different faces of the cube to simulate light"/></p>
<p>Okay lol, so that doesn&#39;t actually look fantastic, but we&#39;re getting somewhere! The lightsource
	here is modeled as a uniform directional light &#34;behind&#34; the camera, so it&#39;s adding light based on
	how much this lightsource is &#34;shining&#34; on the surface. This calculation is done using normal
	vectors to each triangle&#39;s surface, producing &#34;flat&#34; shading with a basic directional light. A
	more realistic form of shading for round surfaces could be implemented by using the normal at each
	vertex and interpolating across them for each triangle face, and a more realistic one by taking
	into account the width of a potential lightsource rather than modeling it as a single vector. If
	you&#39;re excited by that math, have another <a href="https://cglearn.codelight.eu/pub/computer-graphics/shading-and-lighting" target="" rel="">link</a> to some fun different lighting strategies.
</p>
<p>Okay, so we&#39;re looking pretty good! Let&#39;s try and graduate to something a little more complex.
	Say. . . a spaceship? Nabbed directly from the excellent javidx9 series github?
</p>
<p><img src="https://www.blog.jamesgisele.com/_app/immutable/assets/no_order.32d49025.png" alt="a basic spaceship mesh, with some weird/inaccurate shapes on the wings as an artifact of unsophisticated rendering strategies"/></p>
<p>Alright alright. So our light source is definitely working. But clearly we&#39;ve got some new
	problems. If we take a look at the wings of our spaceship, you see all sorts of chaos. There are a
	few things still off about this engine, so we&#39;ll take them one at a time.
</p>
<h4>z-buffer ordering</h4>
<p>One of the things causing the weirdnesses seen above is the fact that we&#39;re not drawing our
	triangles in any particular order at the moment. Our engine draws all triangles at whatever order
	they&#39;re fed into it by the code. As it is, a triangle waaay at the &#34;back&#34; of the spaceship (aka
	one with large z-values in view space) can be drawn after a triangle at the &#34;front&#34; of the
	spaceship, replacing its pixels with its own and causing weird artifacts such as the one seen on
	the left wing.
</p>
<p>Z-buffer ordering algorithms in modern GPUs have to be relatively sophisticated (consider if
	triangle A is &#34;in front&#34; of half of triangle B, but &#34;behind&#34; the other half of it?), but for now
	we&#39;ll stick with ordering by a simple average of Z-values. This gets us something a lot nicer
	looking:
</p>
<p><img src="https://www.blog.jamesgisele.com/_app/immutable/assets/with_order.8d4851cd.png" alt="a basic spaceship mesh, which is mostly clear of obvious visual artifacts due to z-buffer ordering"/></p>
<p>A lot better. There&#39;s still one triangle on the right wing with the issue mentioned above, where
	half the triangle should be rendered &#34;above&#34; and the other half &#34;below&#34; another triangle; but this
	is looking a lot better.
</p>
<p>Let&#39;s take a closer look, to make sure everything is actually working as intended.</p>
<p><img src="https://www.blog.jamesgisele.com/_app/immutable/assets/chaos.9fec9032.png" alt="a basic spaceship mesh, except you can&#39;t tell because all you see are horrible janky overlapping triangles"/></p>
<p>Haha. Oh no</p>
<h4>clipping</h4>
<p>So, what&#39;s happened here is actually not that complicated, though it&#39;s a slightly more
	sophisticated fix than simply re-ordering our triangle painting.
</p>
<p>The first thing you&#39;ll notice with the engine at this point is that it starts sloooowing down as
	you (the camera) get closer to the polygon. One day I&#39;ll do a WASM port and update this post so
	you can see for yourself, but for now, imagine about 1 frame per second update rate.
</p>
<p>When an object goes off screen or gets too close to the camera, the matrix math we&#39;re currently
	using means that the object&#39;s coordinates get verrry large. For objects close to the camera, the
	reason behind this is pretty intuitive. Hold your hand up directly in front of your eyes.
	Hopefully, your hand looks big. Now put your hand behind your head. How big does your hand look?
	&#34;What kind of question is that,&#34; you say, &#34;I can&#39;t see it!&#34;
</p>
<p>Same goes for the view matrix, albeit in a math-ey way - objects too close to or behind the camera
	have unwanted behavior. In the process of projecting the triangles, you divide by their z distance
	from the camera. When this z distance gets very small, the numbers get very large, and it&#39;s a lot
	slower to do tons of calculations on very large numbers. (This is where you start to get memory
	problems as well, which for this program manifested in crashes due to attempted overflow of f32s.)
	Also - why should we even be doing calculations on vertices that are off-screen anyway?
</p>
<p>This is where clipping comes in. We only want to be rendering things that are within our view
	volume. But in order to do that, we&#39;ll have to do a bunch of math, because currently all we can
	render with our engine is <i>triangles</i>. What do you get when you chop a triangle with a plane
	or two?
</p>
<p><img src="https://www.blog.jamesgisele.com/_app/immutable/assets/not_triangle.a2131ba8.png" alt="cube mesh, slightly off-center so that the window clips the triangles forming the cube into quadrilaterals"/></p>
<h5>not a triangle</h5>
<p>Again, I&#39;m skipping over the math, but there are several algorithms you can use to detect whether
	a vertex needs to be clipped and then turn the remaining vertices into new triangles by adding
	vertices to the mix. The math can be found <a href="https://gabrielgambetta.com/computer-graphics-from-scratch/11-clipping.html" target="" rel="">here</a>, if you&#39;re interested. Let&#39;s see how things are performing with clipping for both the front view
	plane (close to camera) and the window edges:
</p>
<p><img src="https://www.blog.jamesgisele.com/_app/immutable/assets/clipped.613ddb12.png" alt="cube mesh, slightly off-center so that the window clips the triangles, with added triangles so that every shape in the mesh is represented as a triangle"/></p>
<p>There we go! We&#39;re back to triangles, and our performance issues have disappeared -- our
	application is positively snappy.
</p>

<h4>final touches</h4>
<p>As a final touch, let&#39;s render something a little fancier. Mesh courtesy of <a href="https://graphics.stanford.edu/courses/cs148-10-summer/as3/code/as3/teapot.obj" target="" rel="">Stanford:</a></p>
<p><img src="https://www.blog.jamesgisele.com/_app/immutable/assets/teapot.25b75cc8.png" alt="impeccably rendered mesh of utah teapot"/></p>
<p>and to really seal the deal, I&#39;ll turn off the polygon lines, add a little rotation, and get you a
	gif:
</p>
<p><img src="https://www.blog.jamesgisele.com/_app/immutable/assets/long_teapot.40dd4ad8.gif" alt="impeccably rendered mesh of utah teapot, now rotating!"/></p>

<p>Beautiful! We&#39;ve still got a few glitches around the corners and the lid, but that looks about
	right. ~cue fanfare~
</p>
<h3 id="list">shortlist of absolute beginners&#39; graphics resources i enjoyed</h3>
<p>In making this engine as well as starting out with GPU programming, I ran through a bunch of
	different resources. Some were helpful. Some were less so. Here&#39;s a roundup of the ones I can
	remember in this moment!
</p>
<ul><li><h6>javidx9</h6>
		<p>the original <a href="https://www.youtube.com/watch?v=ih20l3pJoeU&amp;t=1667s" target="" rel="">javidx9</a> series that got me started. all his videos are really great!
		</p></li>
	<li><h6>Computer Graphics From Scratch</h6>
		<p>alternately - <a href="https://www.gabrielgambetta.com/computer-graphics-from-scratch/" target="" rel="">Computer Graphics From Scratch</a> I&#39;ve heard great things about, and it covers largely the same material, if you&#39;re more of a books
			learner than a videos learner. It&#39;s in pseudocode which saves you the stress if you (like me) don&#39;t
			know C++, don&#39;t currently want to, and are struggling through C-dialect-heavy graphics resources.
		</p></li>
	<li><h6>math refresh - 3blue1brown&#39;s linear algebra</h6>
		<p>for a linear algebra refresh - 3blue1brown&#39;s linear algebra <a href="https://www.youtube.com/watch?v=kjBOesZCoqc&amp;list=PL0-GT3co4r2y2YErbmuJw2L5tW4Ew2O5B" target="" rel="">series</a> is hard to beat.
		</p></li>
	<li><h6>shader school</h6>
		<p>A <a href="https://github.com/stackgl/shader-school" target="" rel="">10-years-but-still-running</a> GLSL shader interactive course. Really really good, and you can still get it running on local!
			Don&#39;t try to get rid of the broken node dependency loops tho that way lies madness. Thank you to
			a fellow Recurser (you know who you are!) for putting me onto this when I was trying and failing
			to brute force my way into understanding shaders.
		</p></li>
	<li><h6>shader toy</h6>
		<p>A <a href="https://www.shadertoy.com/" target="" rel="">really excellent website</a> to see
			the bonkers things people can do with shaders and hope one day you too can be that crazy skilled.
		</p></li>
	<li><h6>learn wgpu</h6>
		<p><a href="https://sotrh.github.io/learn-wgpu/#what-is-wgpu" target="" rel="">learn wgpu.</a>
			honestly, this one&#39;s probably best if you&#39;re coming in with some graphics background. i tried moving
			to this right after writing the software renderer but found it confusing/buggy in places and entirely
			copy-this-boilerplate-ey in others. by the end i could change the sea of stone cubes in the tutorial
			to a sea of dancing kate bushes (see below), but not much else--- everything i&#39;d written felt pretty
			opaque and difficult to reason about.
			<a href="https://www.youtube.com/watch?v=knmuobQFNmM&amp;list=PLWtPciJ1UMuBs_3G-jFrMJnM5ZMKgl37H" target="" rel="">chris biscardi has a good series</a> walking through most of learn wgpu, but it seems even they bailed before reaching the end lol.
		</p></li>
	<li><h6>x11 fun</h6>
		<p>someone linked <a href="https://magcius.github.io/xplain/article/index.html" target="" rel="">this fun
			</a> interactive book-tutorial on the X11 window system in the Recurse chat. It has a
			bunch of fun demos that helped me understand what aliasing/anti-aliasing are and why they occur,
			and has a bunch of fun legacy Linux stuff. Shoutout to whoever linked this!
		</p></li></ul>
<h3>bonus for those who got this far</h3>





		
	<hr/>
		<ul><li><a href="https://www.blog.jamesgisele.com/blog/rss" target="_blank" rel="noopener noreferrer"></a></li>
	<li><a href="https://github.com/jmgisele/" target="_blank" rel="noopener noreferrer"></a></li>

	<li><a href="https://www.linkedin.com/in/james-gisele/" target="_blank" rel="noopener noreferrer"></a></li>

	<li></li>
	<li></li>
</ul>
		
</div></div>
  </body>
</html>
