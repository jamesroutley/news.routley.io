<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.jeffgeerling.com/blog/2025/dells-version-dgx-spark-fixes-pain-points">Original</a>
    <h1>Dell&#39;s version of the DGX Spark fixes pain points</h1>
    
    <div id="readability-page-1" class="page"><div><p>Dell sent me two of their GB10 mini workstations to test:</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/dell-pro-max-gb10-two.jpeg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-91c249ce-34c4-4690-9afb-7b2dbf8552e7" data-insert-attach="{&#34;id&#34;:&#34;91c249ce-34c4-4690-9afb-7b2dbf8552e7&#34;,&#34;attributes&#34;:{&#34;alt&#34;:[&#34;alt&#34;,&#34;description&#34;],&#34;title&#34;:[&#34;title&#34;]}}" alt="Dell Pro Max with GB10"/></p>

<p>In this blog post, I&#39;ll cover the base system, just one of the two nodes. Cluster testing is ongoing, and I&#39;ll cover things like AI model training and networking more in depth next year, likely with comparisons to the <a href="https://www.jeffgeerling.com/blog/2025/i-clustered-four-framework-mainboards-test-huge-llms">Framework Desktop cluster</a> and <a href="https://www.jeffgeerling.com/blog/2025/15-tb-vram-on-mac-studio-rdma-over-thunderbolt-5">Mac Studio cluster</a> I&#39;ve also been testing.</p>

<p>But many of the same caveats of the DGX Spark (namely, price to performance is not great if you just want to run LLMs on a small desktop) apply to Dell&#39;s GB10 box as well.</p>

<p>It costs a little <em>more</em> than the DGX Spark, but does solve a couple pain points people experienced on the DGX Spark:</p>

<ul>
<li>It has a power LED (seriously, why does the DGX Spark <em>not</em> have one?!)</li>
<li>The included power supply is 280W instead of 240W for a little more headroom</li>
<li>The thermal design (front-to-back airflow) seems less restricted, so is quieter and capable of keeping the GB10 &#39;AI Superchip&#39; from thermal throttling</li>
</ul>

<p>But if this isn&#39;t a mini PC to compete with a Mac mini, nor a good value for huge LLMs like a Mac Studio, or AMD&#39;s Ryzen AI Max+ 395 machines, what is it and who is it for?</p>

<p>Well, it&#39;s a $4,000+ box built specifically for developers in Nvidia&#39;s ecosystem, deploying code to Nvidia servers that cost <a href="https://wccftech.com/nvidia-blackwell-dgx-b200-price-half-a-million-dollars-top-of-the-line-ai-hardware/">half a million dollars</a> <em>each</em>. A major part of the selling point are these built-in 200 gigabit QSFP ports, which would cost $1,500 or so to add on to another system, assuming you have the available PCIe bandwidth:</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/dell-pro-max-gb10-qsfp-200gbps.jpeg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-9914275f-3916-4ac0-a4de-0c22aca075c8" data-insert-attach="{&#34;id&#34;:&#34;9914275f-3916-4ac0-a4de-0c22aca075c8&#34;,&#34;attributes&#34;:{&#34;alt&#34;:[&#34;alt&#34;,&#34;description&#34;],&#34;title&#34;:[&#34;title&#34;]}}" alt="Dell Pro Max with GB10 Cluster - QSFP cables"/></p>

<p>Those ports can&#39;t achieve 400 Gbps, but they <em>do</em> hit over 200 Gbps in the right conditions, configured for Infiniband / RDMA. And they hit over 100 Gbps for Ethernet (though only when running multiple TCP streams).</p>

<p>So it may seem a little bit of an odd duck for me, since I&#39;m not an &#39;Nvidia developer&#39; and I don&#39;t deploy code to Nvidia&#39;s &#39;AI factories&#39;.</p>

<p>If I&#39;m being honest, I&#39;m <em>more</em> interested in the &#39;Grace&#39; part of the GB10 (or &#39;Grace Blackwell 10&#39;) &#39;AI Superchip. It&#39;s a big.LITTLE Arm CPU co-designed by Mediatek, with 10 Cortex-X925 cores and 10 Cortex-A725 cores.</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/grace-blackwell-gb10-ai-superchip-nvidia.jpg" width="700" height="436" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-fc7a15f1-de59-4034-a0f3-37fb075bf485" data-insert-attach="{&#34;id&#34;:&#34;fc7a15f1-de59-4034-a0f3-37fb075bf485&#34;,&#34;attributes&#34;:{&#34;alt&#34;:[&#34;alt&#34;,&#34;description&#34;],&#34;title&#34;:[&#34;title&#34;]}}" alt="Nvidia GB10 Grace CPU diagram 20 cores"/></p>

<p>The chip is united to the Blackwell GPU, and shares the same 128 GB pool of LPDDR5X memory. And it&#39;s a pretty snappy Arm CPU—just stuck in a $4,000+ system.</p>

<p>But like I said, Dell sent me these boxes to test. They aren&#39;t paying for this blog post and have no control over what I say.</p>

<p>In fact, one of the main things they said was &#34;this is isn&#39;t a gaming machine, so don&#39;t focus on that.&#34;</p>

<p>But that got me thinking. What if... I <em>did</em>.</p>

<h2>Gaming on Arm Linux</h2>

<p>Valve just announced the Steam Frame, and it <a href="https://www.windowscentral.com/hardware/virtual-reality/valve-announce-steam-frame-snapdragon-xr-headset-steam-os-arm-support">runs on Arm</a>.</p>

<p>Steam Frame will use <a href="https://fex-emu.com">FEX</a> for its x86-Arm translation layer, and <a href="https://www.codeweavers.com/blog/mjohnson/2025/11/6/twist-our-arm64-heres-the-latest-crossover-preview">CodeWeavers&#39; Crossover Preview for Arm64</a> was just released, so I thought I&#39;d give that a try on DGX OS (Nvidia&#39;s Linux OS, currently based on Ubuntu 24.04).</p>

<p>I was able to quickly install Steam, and through that, games like Cyberpunk 2077, Doom Eternal, and Ultimate Epic Battle Simulator II.</p>

<p>I&#39;ll leave the full experience and test results for you to see in this video:</p>

<div>
<p><iframe src="https://www.youtube.com/embed/FjRKvKC4ntw" frameborder="0" allowfullscreen=""></iframe></p>
</div>

<p>But bottom line, the Windows games I typically test on Arm systems through Steam/Proton played very well here, with no stuttering, and decent frame rates (100 fps in Cyberpunk 2077 at 1080p with low settings).</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/dell-pro-max-gb10-gaming-doom-eternal.jpeg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-063e7f60-d443-4905-aa50-596163130fc9" data-insert-attach="{&#34;id&#34;:&#34;063e7f60-d443-4905-aa50-596163130fc9&#34;,&#34;attributes&#34;:{&#34;alt&#34;:[&#34;alt&#34;,&#34;description&#34;],&#34;title&#34;:[&#34;title&#34;]}}" alt="Doom Eternal 200 fps Dell Pro Max GB10"/></p>

<p>But no, I agree with Dell, this box should <em>not</em> be evaluated as a gaming machine. While it performs admirably for an Arm linux box, you could do a lot better with half the budget if you just wanted to build a dedicated gaming rig. Even with RAM prices as they are today.</p>

<h2>General Purpose Arm Workstation (with tons of VRAM)</h2>

<p>This machine is built for AI development, but it just so happens to have a very good Arm CPU and tons of RAM, so I wanted to test it for both running LLMs, and as a general Arm Linux workstation.</p>

<p>The video above has more depth, and you can find <a href="https://github.com/geerlingguy/sbc-reviews/issues/92">all my benchmark data here</a>, but I wanted to focus on a few things in particular.</p>

<h2>Software</h2>

<p>Before we get to benchmarks, I wanted to mention Nvidia&#39;s <a href="https://docs.nvidia.com/dgx/dgx-spark/dgx-os.html#release-cadence">DGX OS</a>. Based on Ubuntu Linux, it&#39;s the only supported Linux distribution for GB10 systems. Regular Ubuntu LTS versions are supported for 5 years, with optional Pro support extending that out to 10 or even 15 years. But <a href="https://docs.nvidia.com/dgx/dgx-spark/dgx-os.html#release-cadence">DGX OS only guarantees updates for two years</a>, though Nvidia doesn&#39;t really offer guarantees for its hardware support.</p>

<p>Their track record for ongoing support for their hardware is <a href="https://developer.nvidia.com/embedded/jetson-linux-archive">decidedly mixed</a>, and in the absence of any guarantees, I wouldn&#39;t expect them to continue supporting the Spark or other GB10 systems beyond a few years.</p>

<p><a href="https://forums.developer.nvidia.com/t/has-anyone-tried-an-alternative-linux-distro/349124">Some people have had luck getting other distros running</a>, but they&#39;re still running <a href="https://github.com/NVIDIA/NV-Kernels">Nvidia&#39;s kernel</a>. So if you buy one of these, know there&#39;s no guarantees for ongoing support.</p>

<p>Running things on DGX OS, I&#39;ve found most server/headless software runs great, but there are still desktop tools that are more of a hassle. Like Blender doesn&#39;t have a stable release that uses GPU acceleration on Arm. But if you <a href="https://github.com/CoconutMacaroon/blender-arm64/">compile it from source</a>like GitHub user CoconutMacaroon did, you can get full acceleration.</p>

<p>Just using this box as a little workstation, it is plenty fast for all the things I do, from coding, to browsing the web, to media editing. (Though media workflows are still rough on Linux in general, even on x86.)</p>

<h2>CPU benchmarks</h2>

<p>The Grace CPU is a 20-core Arm chip <a href="https://www.mediatek.com/press-room/newly-launched-nvidia-dgx-spark-features-gb10-superchip-co-designed-by-mediatek">co-designed by Mediatek</a>, fused together with the Blackwell GPU.</p>

<p>There must be some inefficiency there, though, because the system&#39;s idle power draw is a bit higher than I&#39;m used to for Arm, coming in around 30 watts. A lot higher than Apple&#39;s M3 Ultra with 512GB of RAM, or even AMD&#39;s Ryzen AI Max+ 395 (these names just roll right off the tongue, don&#39;t they?).</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/gb10-benchmark-power-idle.jpeg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-1cfaa4e4-84f2-48dd-a1f5-1c265c2a0345" data-insert-attach="{&#34;id&#34;:&#34;1cfaa4e4-84f2-48dd-a1f5-1c265c2a0345&#34;,&#34;attributes&#34;:{&#34;alt&#34;:[&#34;alt&#34;,&#34;description&#34;],&#34;title&#34;:[&#34;title&#34;]}}" alt="Dell Pro Max with GB10 - Idle power draw comparison"/></p>

<p>In my testing, it seems the CPU itself maxes out around 140 watts, leaving another 140 watts of headroom for the GPU, network, and USB-C ports with PD.</p>

<p>Geekbench 6 was a little unstable, which was weird, but when I did get it to run, it was about on par with the AMD Ryzen AI Max+ 395 system I tested earlier this year, the Framework Desktop.</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/gb10-benchmark-geekbench6.jpeg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-0a825788-077c-4a54-971e-947415dbeef3" data-insert-attach="{&#34;id&#34;:&#34;0a825788-077c-4a54-971e-947415dbeef3&#34;,&#34;attributes&#34;:{&#34;alt&#34;:[&#34;alt&#34;,&#34;description&#34;],&#34;title&#34;:[&#34;title&#34;]}}" alt="Dell Pro Max with GB10 - Geekbench 6 comparison"/></p>

<p>Apple&#39;s 2-generation-old M3 Ultra Mac studio beats both, but it does cost quite a bit more, so that&#39;s to be expected.</p>

<p>And testing with High Performance Linpack, the Dell Pro Max gets about 675 Gflops:</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/gb10-benchmark-hpl.jpeg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-639ede2a-de04-4ad0-b703-8c2d776bb676" data-insert-attach="{&#34;id&#34;:&#34;639ede2a-de04-4ad0-b703-8c2d776bb676&#34;,&#34;attributes&#34;:{&#34;alt&#34;:[&#34;alt&#34;,&#34;description&#34;],&#34;title&#34;:[&#34;title&#34;]}}" alt="Dell Pro Max with GB10 - HPL comparison"/></p>

<p>NVIDIA&#39;s marketing said the GB10 <a href="https://nvidianews.nvidia.com/news/nvidia-puts-grace-blackwell-on-every-desk-and-at-every-ai-developers-fingertips">&#34;offers a petaflop of AI computing performance&#34;</a>—a <em>thousand</em> teraflops! This thing can&#39;t even hit <em>one</em>...</p>

<p>But in the fine print, NVIDIA says it&#39;s a petaflop at <em>FP4 precision</em>. HPL tests FP64, aka double precision, which is more used in scientific computing. <a href="https://bsky.app/profile/fclc.bsky.social/post/3lc4qpte3ys2o">A FLOP is not always a FLOP</a>, and even the &#39;petaflop&#39; claim seems disputed, at least if I&#39;m reading <a href="https://x.com/ID_AA_Carmack/status/1982831774850748825">John Carmack&#39;s tweets correctly</a>.</p>

<p>But at least for FP64 on the CPU, the GB10 is fairly efficient, at least compared to x86 systems I&#39;ve tested:</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/gb10-benchmark-hpl-efficiency.jpeg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-479f4c08-0b47-4303-b90d-317d04312f80" data-insert-attach="{&#34;id&#34;:&#34;479f4c08-0b47-4303-b90d-317d04312f80&#34;,&#34;attributes&#34;:{&#34;alt&#34;:[&#34;alt&#34;,&#34;description&#34;],&#34;title&#34;:[&#34;title&#34;]}}" alt="Dell Pro Max with GB10 - HPL efficiency comparison"/></p>

<h2>Networking Performance</h2>

<p>A huge part of the value is the built-in ConnectX-7 networking. I tested that, and it&#39;s fast. But also a bit odd. Here&#39;s the maximum TCP performance I was able to get through the fastest interface on each of the three systems I&#39;ve been comparing:</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/gb10-benchmark-network.jpeg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-ce70cde6-7dfe-4ef8-adc3-27d566ad6079" data-insert-attach="{&#34;id&#34;:&#34;ce70cde6-7dfe-4ef8-adc3-27d566ad6079&#34;,&#34;attributes&#34;:{&#34;alt&#34;:[&#34;alt&#34;,&#34;description&#34;],&#34;title&#34;:[&#34;title&#34;]}}" alt="Dell Pro Max with GB10 - Ethernet bandwidth"/></p>

<p>But 106 Gigabits isn&#39;t 200, is NVIDIA lying?</p>

<p>Well, no... it&#39;s a little complicated. For full details, I&#39;ll refer you to the ServeTheHome article <a href="https://www.servethehome.com/the-nvidia-gb10-connectx-7-200gbe-networking-is-really-different/">The NVIDIA GB10 ConnectX-7 200GbE Networking is Really Different</a>.</p>

<p>Because the ports are each connected to a x4 PCIe Gen 5 link—which isn&#39;t enough bandwidth for 200 Gbps per port. To get a full 200 Gbps, you have to use Infiniband/RDMA and carefully configure the network topology. You won&#39;t get more than about 206 Gbps, maximum, in real world throughput, no matter how you set it up.</p>

<p>That&#39;s still honestly pretty good, but it&#39;s not the same as getting 400 Gbps of networking for AI clustering, like I think some of us expected reading the initial press releases in early 2025...</p>

<p>From the perspective of someone replicating NVIDIA&#39;s networking stack locally, though, having ConnectX ports built in is a boon. If you want replicate this kind of developer setup on AMD, you&#39;d have to spend around the same amount of money, for the Max+ 395 plus a Connect-X 7 card.</p>

<p>Many people don&#39;t care about clustering use cases, or RDMA or Infiniband, but that doesn&#39;t mean it&#39;s not extremely useful for the people who <em>do</em>. This stuff&#39;s expensive, but to some people, it&#39;s not a bad value.</p>

<h2>AI Performance</h2>

<p>For now I&#39;m just running two models, both of them with llama.cpp, optimized for each architecture.</p>

<p>And for a small model that requires a decent amount of CPU to keep up with the GPU, the GB10 does pretty well, almost hitting 100 tokens/s for inference, which is second to the M3 Ultra:</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/gb10-benchmark-ai-llama32-3b.jpeg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-0b422ea5-d743-4a99-b3df-1fa67a9698af" data-insert-attach="{&#34;id&#34;:&#34;0b422ea5-d743-4a99-b3df-1fa67a9698af&#34;,&#34;attributes&#34;:{&#34;alt&#34;:[&#34;alt&#34;,&#34;description&#34;],&#34;title&#34;:[&#34;title&#34;]}}" alt="Dell Pro Max with GB10 - AI llama small"/></p>

<p>But for prompt processing, which is important for how quickly you start seeing a response from AI models, the GB10 chip is the winner, despite costing less than half the M3 Ultra.</p>

<p>And it&#39;s a similar story for a huge &#39;dense&#39; model, Llama 3.1 70B, except here, it gets beat just a little by AMD&#39;s Strix Halo in the Framework Desktop:</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/gb10-benchmark-ai-llama31-70b.jpeg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-c19de866-eb76-4092-a0af-e080da4c8f24" data-insert-attach="{&#34;id&#34;:&#34;c19de866-eb76-4092-a0af-e080da4c8f24&#34;,&#34;attributes&#34;:{&#34;alt&#34;:[&#34;alt&#34;,&#34;description&#34;],&#34;title&#34;:[&#34;title&#34;]}}" alt="Dell Pro Max with GB10 - AI llama large"/></p>

<p>Prompt processing is a strong selling point for these boxes. That&#39;s the reason Exo teased <a href="https://blog.exolabs.net/nvidia-dgx-spark/">running a DGX Spark as the compute node</a> for a Mac Studio cluster.</p>

<p>You can have the Spark, or one of these Dell&#39;s, handle the thing <em>it&#39;s</em> best at, prompt processing, while the Mac Studios handle the thing <em>they&#39;re</em> best at, memory bandwidth for token generation.</p>

<p>Anyway, these are just two quick AI benchmarks, and I have <a href="https://github.com/geerlingguy/ai-benchmarks/issues/34">a lot more in the Dell Pro Max with GB10 issue in my ai-benchmarks repository</a>. I&#39;m doing a lot more testing, including model training and how I clustered two of these things in a tiny mini rack, but you&#39;ll have to wait until next year for that.</p>

<p><img src="https://www.jeffgeerling.com/sites/default/files/images/dell-pro-max-gb10-cluster-display.jpeg" width="700" height="394" data-insert-type="image" data-entity-type="file" data-entity-uuid="insert-image-072256d9-4ae0-4da0-ae24-40d07ca37c01" data-insert-attach="{&#34;id&#34;:&#34;072256d9-4ae0-4da0-ae24-40d07ca37c01&#34;,&#34;attributes&#34;:{&#34;alt&#34;:[&#34;alt&#34;,&#34;description&#34;],&#34;title&#34;:[&#34;title&#34;]}}" alt="Dell Pro Max with GB10 mini cluster"/></p></div></div>
  </body>
</html>
