<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://lwn.net/Articles/961868/">Original</a>
    <h1>Open-Source AI at FOSDEM</h1>
    
    <div id="readability-page-1" class="page"><div>
<center>
           <div><b>Benefits for LWN subscribers</b><p>The primary benefit from <a href="https://lwn.net/subscribe/">subscribing to LWN</a>
       is helping to keep us publishing, but, beyond that, subscribers get
       immediate access to all site content and access to a number of extra
       site features.  Please sign up today!</p></div>
           </center>
           
<p>At <a href="https://fosdem.org/2024/">FOSDEM 2024</a> in Brussels, the
<a href="https://fosdem.org/2024/schedule/track/ai_ml/">AI and Machine
Learning devroom</a> hosted several talks about open-source AI models. With
talks about a definition of open-source AI, &#34;ethical&#34; restrictions in
licenses, and the importance of open data sets, in particular for
non-English languages, the devroom provided an overview of the current state
of the domain. 
</p>

<p>An AI model is a program that has been trained on a data set to
recognize patterns, mimic the learned data in its output, or to make some
kinds of decisions autonomously. Most
notably, large language models (LLMs), which are extensive neural networks
capable of 
generating human-like text, were a recurrent subject at FOSDEM. This report
comes from the live-streams of the talks, as the flu unfortunately prevented me
from attending FOSDEM in-person this year. 
</p>

<p>Characteristically, an LLM incorporates up to several hundred
billion &#34;weights&#34;, which are floating-point numbers that are also referred
to as &#34;parameters&#34;. Companies developing large 
language models are not inclined to release their models and
the code to 
run them as open source, since training the models requires significant
computing power 
and financial investment. However, that doesn&#39;t stop various organizations
from developing open-source LLMs. Last year, LWN  looked at <a href="https://lwn.net/Articles/931853/">open-source language models</a>. 
</p>

<h4>License restrictions</h4>

<p>Niharika Singhal, project manager at the <a href="https://fsfe.org">Free
Software Foundation Europe</a> (FSFE), talked about the trend of <a href="https://fosdem.org/2024/schedule/event/fosdem-2024-2750-codes-bound-by-ethics-the-rising-tide-of-non-free-software-licenses-in-ai-ecosystems/">imposing
ethical restrictions on AI models through licensing</a>. Singhal provided
several instances of added restrictions of that sort, related to field
of endeavor, behavior, or commercial practices. One is the <a href="https://firstdonoharm.dev">Hippocratic License</a>, which restricts
the licensee from executing numerous actions deemed harmful based 
on various &#34;<q>international agreements and authorities on fundamental
human rights norms</q>&#34;. There&#39;s also the <a href="https://ai.meta.com/llama/use-policy/">Llama 2 v2 use policy</a>,
which prohibits use of the LLM for violent or terrorist activities, as well
as &#34;any other criminal activity&#34;. Similarly, BigScience&#39;s <a href="https://bigscience.huggingface.co/blog/bigscience-openrail-m">OpenRAIL-M
License</a> imposes restrictions on the use of models for various harmful
activities. 
</p>

<p>According to Singhal, these additional restrictions have serious
implications: &#34;They create barriers against the use and reuse of the
models, which also makes it more difficult to adapt and improve the
models.&#34; She believes that to preserve &#34;openness&#34; in AI, the licenses of AI
models must be interoperable with free-software licenses, which isn&#39;t the
case with these restrictions. She concludes that licenses can&#39;t be a
substitute for regulation: &#34;Restrictive practices to comply with ethical
rules shouldn&#39;t be in licenses: these belong to the domain of regulations.&#34; 
</p>

<h4>A definition of open-source AI</h4>

<p>Stefano Maffulli, executive director of the <a href="https://opensource.org">Open Source Initiative</a> (OSI), described
OSI&#39;s efforts to <a href="https://fosdem.org/2024/schedule/event/fosdem-2024-2805-moving-a-step-closer-to-defining-open-source-ai/">define
open-source AI</a>. In 2022, the OSI started contacting researchers, other
&#34;open&#34; organizations, technology companies, and civil-rights organizations,
to ask them about their ideas for an open-source AI system. 
</p>

<p>As a general principle, Maffulli maintains that the <a href="https://www.gnu.org/gnu/manifesto.html">GNU Manifesto</a>&#39;s Golden
Rule should be applicable to AI: &#34;If I like an AI system, I must be free to
share it with other people.&#34; For an AI system to be categorized as
open-source, it needs to grant us adaptations of the four basic freedoms
applicable to open-source software: to use, study, modify, and share.
</p><blockquote>
We need
to be able to use the system for any purpose and without having to ask for
permission. We need to be able to study how the system works and inspect
its components. We need to be able to modify the system to change its
recommendations, predictions, or decisions to adapt to our needs. And we
need to be able to share the system with or without modifications, for any
purpose.
</blockquote>


<p>According to Maffulli, a pertinent question to pose in this context is:
&#34;What is the preferred form to make modifications to an AI system?&#34; To get
an answer to this question, OSI has created small working groups to analyze
some popular AI systems. &#34;We&#39;re starting with <a href="https://llama.meta.com">Llama 2</a> and <a href="https://www.eleuther.ai/papers-blog/pythia-a-suite-for-analyzing-large-language-modelsacross-training-and-scaling">Pythia</a>,
two LLMs. After this, we&#39;ll repeat the same exercise with <a href="https://bigscience.huggingface.co/blog/bloom">BLOOM</a>, <a href="https://opencv.org">OpenCV</a>, <a href="https://docs.mistral.ai">Mistral</a>, <a href="https://www.microsoft.com/en-us/research/blog/phi-2-the-surprising-power-of-small-language-models/">Phi-2</a>,
and <a href="https://allenai.org/olmo">OLMo</a>.&#34; For each of these AI
systems, the working group will identify the requirements to guarantee the
four basic freedoms. For example, understanding why, given an input, you
get a particular output, is necessary to being able to study an AI system.
</p>

<p>In 2024, the OSI will release a new <a href="https://opensource.org/deepdive/drafts/">draft of the open-source AI
definition</a> monthly, based on bi-weekly virtual public town halls. &#34;Our
goal is to have a 1.0 release by the end of October&#34;,
Maffulli said. Everyone is welcome to partake in the discussions regarding the
drafts in OSI&#39;s <a href="https://discuss.opensource.org">public forum</a>. 
</p>

<p>According to Maffulli, there can&#39;t be a spectrum when it comes to
open-source AI: either an AI system is open source, or it
isn&#39;t. Nevertheless, many players within the domain of large language
models misuse the term &#34;open source&#34;. For example, one of the most popular
&#34;open&#34; LLMs is Meta&#39;s Llama 2. When Meta&#39;s Yann LeCun <a href="https://twitter.com/ylecun/status/1681336284453781505">announced this
model on Twitter</a> last year, he wrote: &#34;<q>This is huge: Llama-v2 is open
source, with a license that authorizes commercial use!</q>&#34;. However, the <a href="https://github.com/facebookresearch/llama/blob/main/LICENSE">Llama 2
license</a> has limitations on its commercial use that are based on the number of
active users. It also forbids using Meta&#39;s model to improve other
LLMs. Both limitations are at odds with the OSI&#39;s Open Source Definition. 
</p>

<h4>Open data sets</h4>

<p>Julie Hunter, a research engineer at the French software company <a href="https://www.linagora.com">Linagora</a>, discussed <a href="https://fosdem.org/2024/schedule/event/fosdem-2024-2591-building-open-source-language-models/">building
open-source language models</a>. According to Hunter, the LLMs developed by
Meta, as well as those by <a href="https://www.mosaicml.com">MosaicML</a>
and the <a href="https://www.tii.ae/">Technology Innovation Institute</a>&#39;s
Falcon models, are so-called &#34;open-weight models&#34;: the weights of the neural
networks are published. This allows a choice of how the model is run
and the model can be fine-tuned by adapting the weights with
additional training. However, the weights don&#39;t explain why something works
or doesn&#39;t work. &#34;Without access to the data the model is trained on, it
leaves a lot open to guesswork&#34;, Hunter said. 
</p>

<p>There has been a push for open training data and, as a result, a lot of
data sets have been added to web sites like the one run by <a href="https://huggingface.co">Hugging Face</a>. &#34;Anyone can train their new
LLM on these data sets&#34;, Hunter said. &#34;However, there are several problems with
many of these data sets. They are often crawled from the web, packed with
personal information, toxic language, and low-quality
sentences. Furthermore, they are predominantly English.&#34; 
</p>

<p>The <a href="https://www.openllm-france.fr">OpenLLM France</a>
consortium aims to build open-source AI models and technologies for the
French language. For its first model, Claire, the main goal was to create a
French data set with traceable licenses. The <a href="https://arxiv.org/abs/2311.16840">Claire French Dialogue Dataset</a>
is a corpus containing 140-million words from transcripts and stage plays
in French, as well as from parliamentary discussions. This data set, <a href="https://huggingface.co/datasets/OpenLLM-France/Claire-Dialogue-French-0.1">Claire-Dialogue-French-0.1</a>,
is mostly using the <a href="https://creativecommons.org/licenses/by-nc-sa/4.0/">Creative Commons
Attribution-NonCommercial-ShareAlike 4.0 International</a> license,
though some parts have other (traceable) licenses. 
</p>

<p>The data set was used to fine-tune an open-weights model, <a href="https://huggingface.co/tiiuae/falcon-7b">Falcon-7B</a>. &#34;The main
purpose of this approach was to evaluate the impact of a good data set on
the performance of the model&#34;, Hunter said. Michel-Marie Maudet, Linagora&#39;s
general manager, added that the company&#39;s idea of developing a language
model based on a small and high-quality corpus of data was inspired by
Microsoft Research&#39;s paper &#34;<a href="https://arxiv.org/abs/2306.11644">Textbooks Are All You
Need</a>&#34;. He continued:
</p><blockquote>
The quality of a data set is more important than its quantity. A
small and high-quality corpus results in a compact, specialized model with
superior control over its responses in terms of interpretability and
reliability. It also makes training faster, which allows us to continuously
update it.
</blockquote>


<p>
In October 2023, the model <a href="https://huggingface.co/OpenLLM-France/Claire-7B-0.1">Claire-7B-0.1</a>
was published on Hugging Face. The <a href="https://github.com/OpenLLM-France/Lit-Claire">code to train the
model</a> was also made public, under the AGPLv3. 
</p>

<h4>Beyond English</h4>

<p>OpenLLM France is now working on a 100% open-source language model,
Lucie, slated for release in April 2024. Maudet explained: &#34;This model is
trained with 100% open-source data sets of French, English, German,
Spanish, and Italian texts, as well as some computer code.&#34; The data sets
include the archives of the French national library and academic
publications with open access. 
</p>

<p>Maudet&#39;s <a href="https://fosdem.org/2024/schedule/event/fosdem-2024-2629-from-openllm-france-to-openllm-europe-paving-the-way-to-sovereign-and-open-source-ai/">talk</a>
presented some details about OpenLLM France and its mission. The community,
which started in July 2023, boasts over 450 active members,
ranging from 
academic institutions to companies. Why is a France-focused LLM consortium
required? Maudet explained that an exploration into the geographical
distribution of LLMs with more than a billion parameters since 2018 reveals
that nearly 70% of them are created in North America, and only 7.5% in
Europe. Upon examining the language distribution in Llama 2&#39;s training
data, the figures seem even more dismal: &#34;While English comprises almost 90% of the data, European languages such as German and French account for
just 0.17% and 0.16% of the data, respectively.&#34; Because European languages
are underrepresented in their data sets, models like Llama 2 exhibit subpar
performance in these languages. 
</p>

<p>There have been similar initiatives in other parts of Europe to build a
European-language open-source LLM, such as <a href="https://laion.ai">LAION</a> and <a href="https://opengpt-x.de/en/">openGPT-X</a> in Germany and <a href="https://github.com/RSTLess-research/Fauno-Italian-LLM">Fauno</a> in
Italy. At FOSDEM, Maudet announced that OpenLLM France is renaming itself
to <a href="http://openllm-europe.org">OpenLLM Europe</a> (though the web site
is not available yet). &#34;Our mission is to develop an
open-source LLM for each European language.&#34; 
</p>

<h4>Conclusion</h4>

<p>The fact that organizations call their AI systems &#34;open source&#34; even if
their license is at odds with the four basic freedoms is a sign that we
really need to have a clear definition of 
open-source AI. Hopefully, OSI&#39;s definition—expected by the end
of 2024—will also help stop the proliferation of licenses with various
well-meant 
but detrimental ethical restrictions. Beyond that, it would be beneficial
for a consortium
such as OpenLLM Europe to attract enough members to build powerful
open-source LLMs beyond English. 
</p></div></div>
  </body>
</html>
