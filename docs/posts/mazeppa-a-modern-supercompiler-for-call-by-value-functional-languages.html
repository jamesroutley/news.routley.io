<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/mazeppa-dev/mazeppa">Original</a>
    <h1>Mazeppa: A modern supercompiler for call-by-value functional languages</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto"><a href="https://github.com/mazeppa-dev/mazeppa/actions"><img src="https://github.com/mazeppa-dev/mazeppa/workflows/OCaml%20CI/badge.svg" alt="CI"/></a></p>
<p dir="auto">Supercompilation <sup><a href="#user-content-fn-turchin-concept-54d94b7e3b1e11d354471762690aaa27" id="user-content-fnref-turchin-concept-54d94b7e3b1e11d354471762690aaa27" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup> is a program transformation technique that symbolically evaluates a given program, with run-time values as unknowns. In doing so, it discovers execution patterns of the original program and synthesizes them into standalone functions; the result of supercompilation is a more efficient residual program. In terms of transformational power, supercompilation subsumes both deforestation <sup><a href="#user-content-fn-deforestation-54d94b7e3b1e11d354471762690aaa27" id="user-content-fnref-deforestation-54d94b7e3b1e11d354471762690aaa27" data-footnote-ref="" aria-describedby="footnote-label">2</a></sup> and partial evaluation <sup><a href="#user-content-fn-partial-evaluation-54d94b7e3b1e11d354471762690aaa27" id="user-content-fnref-partial-evaluation-54d94b7e3b1e11d354471762690aaa27" data-footnote-ref="" aria-describedby="footnote-label">3</a></sup>, and even exhibits certain capabilities of theorem proving.</p>
<p dir="auto"><em>Mazeppa</em> is a modern supercompiler intended to be a compilation target for call-by-value functional languages. Unlike previous supercompilers, Mazeppa 1) provides the full set of primitive data types, 2) supports manual control of function unfolding, 3) is fully transparent in terms of what decisions it takes during transformation, and 4) is designed with efficiency in mind from the very beginning.</p>

<p dir="auto">First, install the OCaml system on your machine:</p>
<div data-snippet-clipboard-copy-content="$ bash -c &#34;sh &lt;(curl -fsSL https://raw.githubusercontent.com/ocaml/opam/master/shell/install.sh)&#34;
$ opam init --auto-setup"><pre><code>$ bash -c &#34;sh &lt;(curl -fsSL https://raw.githubusercontent.com/ocaml/opam/master/shell/install.sh)&#34;
$ opam init --auto-setup
</code></pre></div>
<p dir="auto">Then clone the repository and install Mazeppa:</p>
<div data-snippet-clipboard-copy-content="$ git clone https://github.com/mazeppa-dev/mazeppa.git
$ cd mazeppa
$ ./scripts/install.sh"><pre><code>$ git clone https://github.com/mazeppa-dev/mazeppa.git
$ cd mazeppa
$ ./scripts/install.sh
</code></pre></div>
<p dir="auto">Type <code>mazeppa --help</code> to confirm the installation.</p>

<p dir="auto">You can play with Mazeppa without actually installing it. Having OCaml installed and the repository cloned (as above), run the following command from the root directory:</p>

<p dir="auto">(Graphviz is required: <code>sudo apt install graphviz</code>.)</p>
<p dir="auto">This will launch Mazeppa with <code>--inspect</code> on <code>playground/main.mz</code> and visualize the process graph in <code>target/graph.svg</code>. The latter can be viewed in VS Code by the <a href="https://marketplace.visualstudio.com/items?itemName=SimonSiefke.svg-preview" rel="nofollow">Svg Preview</a> extension.</p>
<p dir="auto"><code>./scripts/play.sh</code> will automatically recompile the sources in OCaml, if anything is changed.</p>
<div dir="auto"><h2 tabindex="-1" dir="auto">Supercompilation by example</h2><a id="user-content-supercompilation-by-example" aria-label="Permalink: Supercompilation by example" href="#supercompilation-by-example"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">The best way to understand how supercompilation works is by example. Consider the following function that takes a list and computes a sum of its squared elements:</p>
<p dir="auto">[<a href="https://www.scattered-thoughts.net/mazeppa-dev/mazeppa/blob/master/examples/sum-squares/main.mz"><code>examples/sum-squares/main.mz</code></a>]</p>
<div data-snippet-clipboard-copy-content="main(xs) := sum(mapSq(xs));

sum(xs) := match xs {
    Nil() -&gt; 0i32,
    Cons(x, xs) -&gt; +(x, sum(xs))
};

mapSq(xs) := match xs {
    Nil() -&gt; Nil(),
    Cons(x, xs) -&gt; Cons(*(x, x), mapSq(xs))
};"><pre><code>main(xs) := sum(mapSq(xs));

sum(xs) := match xs {
    Nil() -&gt; 0i32,
    Cons(x, xs) -&gt; +(x, sum(xs))
};

mapSq(xs) := match xs {
    Nil() -&gt; Nil(),
    Cons(x, xs) -&gt; Cons(*(x, x), mapSq(xs))
};
</code></pre></div>
<p dir="auto">This program is written in the idiomatic, <em>listful</em> functional style. Every function does only one thing, and does it well. However, there is a serious problem here: <code>mapSq</code> essentially constructs a list that will be immediately deconstructed by <code>sum</code>, meaning that we 1) we need to allocate extra memory for the intermediate list, and 2) we need two passes of computation instead of one. The solution to this problem is called <em>deforestation</em> <sup><a href="#user-content-fn-deforestation-54d94b7e3b1e11d354471762690aaa27" id="user-content-fnref-deforestation-2-54d94b7e3b1e11d354471762690aaa27" data-footnote-ref="" aria-describedby="footnote-label">2</a></sup>, which is a special case of supercompilation.</p>
<p dir="auto">Let us see what Mazeppa does with this program:</p>
<div data-snippet-clipboard-copy-content="$ mkdir sum-squares
$ cd sum-squares
# Copy-paste the program above.
$ nano main.mz
$ mazeppa run --inspect"><pre><code>$ mkdir sum-squares
$ cd sum-squares
# Copy-paste the program above.
$ nano main.mz
$ mazeppa run --inspect
</code></pre></div>
<p dir="auto">The <code>--inspect</code> flag tells Mazeppa to give a detailed report on the transformation process. The <code>sum-squares/target/</code> directory will contain the following files:</p>
<div data-snippet-clipboard-copy-content="target
├── graph.dot
├── nodes.json
├── output.mz
└── program.json"><pre><code>target
├── graph.dot
├── nodes.json
├── output.mz
└── program.json
</code></pre></div>
<ul dir="auto">
<li><code>graph.dot</code> contains the complete <em>process graph</em> for our program. You can obtain a picture of the graph by running <code>dot -Tsvg target/graph.dot &gt; target/graph.svg</code>.</li>
<li><code>nodes.json</code> contains the <em>contents</em> of all nodes in the graph. Without this file, you would not be able to understand much from the graph alone.</li>
<li><code>program.json</code> contains the initial program in <em>Mazeppa IR</em>: our supercompiler works with this particular representation instead of the original program.</li>
<li><code>output.mz</code> contains the final residual program.</li>
</ul>
<p dir="auto"><code>output.mz</code> will contain the following code:</p>
<p dir="auto">[<a href="https://www.scattered-thoughts.net/mazeppa-dev/mazeppa/blob/master/examples/sum-squares/target/output.mz"><code>examples/sum-squares/target/output.mz</code></a>]</p>
<div data-snippet-clipboard-copy-content="main(xs) := f0(xs);

f0(x0) := match x0 {
    Cons(x1, x2) -&gt; +(*(x1, x1), f0(x2)),
    Nil() -&gt; 0i32
};"><pre><code>main(xs) := f0(xs);

f0(x0) := match x0 {
    Cons(x1, x2) -&gt; +(*(x1, x1), f0(x2)),
    Nil() -&gt; 0i32
};
</code></pre></div>
<p dir="auto">The supercompiler has successfully merged <code>sum</code> and <code>mapSq</code> into a single function, <code>f0</code>! Unlike the original program, <code>f0</code> works in a single pass, without having to allocate any extra memory.</p>
<p dir="auto">How did the supercompiler got to this point? Let us see the generated process graph:</p>
<p><a target="_blank" rel="noopener noreferrer" href="https://www.scattered-thoughts.net/mazeppa-dev/mazeppa/blob/master/media/sum-squares.svg"><img src="https://www.scattered-thoughts.net/mazeppa-dev/mazeppa/raw/master/media/sum-squares.svg" width="500px"/></a>
</p>
<p dir="auto">For reference, <code>nodes.json</code> contains the following data in JSON:</p>
<div dir="auto" data-snippet-clipboard-copy-content="[
  [ &#34;n0&#34;, &#34;main(xs)&#34; ],
  [ &#34;n1&#34;, &#34;sum(mapSq(xs))&#34; ],
  [ &#34;n2&#34;, &#34;sum(.g1(xs))&#34; ],
  [ &#34;n3&#34;, &#34;xs&#34; ],
  [ &#34;n4&#34;, &#34;sum(Cons(*(.v0, .v0), mapSq(.v1)))&#34; ],
  [ &#34;n5&#34;, &#34;.g0(Cons(*(.v0, .v0), mapSq(.v1)))&#34; ],
  [ &#34;n6&#34;, &#34;+(*(.v0, .v0), sum(mapSq(.v1)))&#34; ],
  [ &#34;n7&#34;, &#34;+(*(.v0, .v0), sum(.g1(.v1)))&#34; ],
  [ &#34;n8&#34;, &#34;*(.v0, .v0)&#34; ],
  [ &#34;n9&#34;, &#34;.v0&#34; ],
  [ &#34;n10&#34;, &#34;.v0&#34; ],
  [ &#34;n11&#34;, &#34;sum(.g1(.v1))&#34; ],
  [ &#34;n12&#34;, &#34;.v1&#34; ],
  [ &#34;n13&#34;, &#34;+(.v3, .v4)&#34; ],
  [ &#34;n14&#34;, &#34;.v3&#34; ],
  [ &#34;n15&#34;, &#34;.v4&#34; ],
  [ &#34;n16&#34;, &#34;sum(Nil())&#34; ],
  [ &#34;n17&#34;, &#34;.g0(Nil())&#34; ],
  [ &#34;n18&#34;, &#34;0i32&#34; ]
]"><pre>[
  [ <span><span>&#34;</span>n0<span>&#34;</span></span>, <span><span>&#34;</span>main(xs)<span>&#34;</span></span> ],
  [ <span><span>&#34;</span>n1<span>&#34;</span></span>, <span><span>&#34;</span>sum(mapSq(xs))<span>&#34;</span></span> ],
  [ <span><span>&#34;</span>n2<span>&#34;</span></span>, <span><span>&#34;</span>sum(.g1(xs))<span>&#34;</span></span> ],
  [ <span><span>&#34;</span>n3<span>&#34;</span></span>, <span><span>&#34;</span>xs<span>&#34;</span></span> ],
  [ <span><span>&#34;</span>n4<span>&#34;</span></span>, <span><span>&#34;</span>sum(Cons(*(.v0, .v0), mapSq(.v1)))<span>&#34;</span></span> ],
  [ <span><span>&#34;</span>n5<span>&#34;</span></span>, <span><span>&#34;</span>.g0(Cons(*(.v0, .v0), mapSq(.v1)))<span>&#34;</span></span> ],
  [ <span><span>&#34;</span>n6<span>&#34;</span></span>, <span><span>&#34;</span>+(*(.v0, .v0), sum(mapSq(.v1)))<span>&#34;</span></span> ],
  [ <span><span>&#34;</span>n7<span>&#34;</span></span>, <span><span>&#34;</span>+(*(.v0, .v0), sum(.g1(.v1)))<span>&#34;</span></span> ],
  [ <span><span>&#34;</span>n8<span>&#34;</span></span>, <span><span>&#34;</span>*(.v0, .v0)<span>&#34;</span></span> ],
  [ <span><span>&#34;</span>n9<span>&#34;</span></span>, <span><span>&#34;</span>.v0<span>&#34;</span></span> ],
  [ <span><span>&#34;</span>n10<span>&#34;</span></span>, <span><span>&#34;</span>.v0<span>&#34;</span></span> ],
  [ <span><span>&#34;</span>n11<span>&#34;</span></span>, <span><span>&#34;</span>sum(.g1(.v1))<span>&#34;</span></span> ],
  [ <span><span>&#34;</span>n12<span>&#34;</span></span>, <span><span>&#34;</span>.v1<span>&#34;</span></span> ],
  [ <span><span>&#34;</span>n13<span>&#34;</span></span>, <span><span>&#34;</span>+(.v3, .v4)<span>&#34;</span></span> ],
  [ <span><span>&#34;</span>n14<span>&#34;</span></span>, <span><span>&#34;</span>.v3<span>&#34;</span></span> ],
  [ <span><span>&#34;</span>n15<span>&#34;</span></span>, <span><span>&#34;</span>.v4<span>&#34;</span></span> ],
  [ <span><span>&#34;</span>n16<span>&#34;</span></span>, <span><span>&#34;</span>sum(Nil())<span>&#34;</span></span> ],
  [ <span><span>&#34;</span>n17<span>&#34;</span></span>, <span><span>&#34;</span>.g0(Nil())<span>&#34;</span></span> ],
  [ <span><span>&#34;</span>n18<span>&#34;</span></span>, <span><span>&#34;</span>0i32<span>&#34;</span></span> ]
]</pre></div>
<p dir="auto">(We will not need to inspect <code>program.json</code> for this tiny example, but feel free to look at it: it is not too complicated.)</p>
<p dir="auto">The supercompiler starts with node <code>n0</code> containing <code>main(xs)</code>. After two steps of function unfolding, we reach node <code>n2</code> containing <code>sum(.g1(xs))</code>, where <code>.g1</code> is the IR function that corresponds to our <code>mapSq</code>. At this point, we have no other choice than to <em>analyze</em> the call <code>.g1(xs)</code> by conjecturing what values <code>xs</code> might take at run-time. Since our <code>mapSq</code> only accepts the constructors <code>Nil</code> and <code>Cons</code>, it is sufficient to consider the cases <code>xs=Cons(.v0, .v1)</code> and <code>xs=Nil()</code> only.</p>
<p dir="auto">Node <code>n4</code> is what happens after we substitute <code>Cons(.v0, .v1)</code> for <code>xs</code>, where <code>.v0</code> and <code>.v1</code> are fresh variables. After three more function unfoldings, we arrive at <code>n7</code>. This is the first time we have to <em>split</em> the call <code>+(*(.v0, .v0), sum(.g1(.v1)))</code> into <code>.v3=*(.v0, .v0)</code> (<code>n8</code>) and <code>.v4=sum(.g1(.v1))</code> (<code>n11</code>) and proceed supercompiling <code>+(.v3, .v4)</code> (<code>n13</code>); the reason for doing so is that a previous node (<code>n2</code>) is structurally embedded in <code>n7</code>, so supercompilation might otherwise continue forever. Now, what happens with <code>sum(.g1(.v1))</code> (<code>n11</code>)? We have seen it earlier! Recall that <code>n2</code> contains <code>sum(.g1(xs))</code>, which is just a renaming of <code>sum(.g1(.v1))</code>; so we decide to <em>fold</em> <code>n11</code> into <code>n2</code>, because it makes no sense to supercompile the same thing twice. The other branches of <code>n7</code>, namely <code>n13</code> and <code>n8</code>, are <em>decomposed</em>, meaning that we simply proceed transforming their arguments.</p>
<p dir="auto">As for the other branch of <code>n2</code>, <code>sum(Nil())</code> (<code>n16</code>), it is enough to merely unfold this call to <code>0i32</code> (<code>n18</code>).</p>
<p dir="auto">After the process graph is completed, residualization converts it to a final program. During this stage, dynamic execution patterns become functions -- node <code>n2</code> now becomes the function <code>f0</code>, inasmuch as some other node (<code>n11</code>) points to it. In any residual program, there will be exactly as many functions as there are nodes with incoming dashed lines, plus <code>main</code>.</p>
<p dir="auto">In summary, supercompilation consists of 1) unfolding function definitions, 2) analyzing calls that pattern-match an unknown variable, 3) breaking down computation into smaller parts, 4) folding repeated computations, and 5) decomposing calls that cannot be unfolded, such as <code>+(.v3, .v4)</code> (<code>n13</code>) in our example. The whole supercompilation process is guaranteed to terminate, because when some computation is becoming dangerously bigger and bigger, we break it down into subproblems and solve them in isolation.</p>
<p dir="auto">There are a plenty of other interesting examples of deforestation in the <a href="https://www.scattered-thoughts.net/mazeppa-dev/mazeppa/blob/master/examples"><code>examples/</code></a> folder, including tree-like data structures. In fact, we have reimplemented all samples from the previous work on higher-order call-by-value supercompilation by Peter A. Jonsson and Johan Nordlander <sup><a href="#user-content-fn-CbV-supercomp-54d94b7e3b1e11d354471762690aaa27" id="user-content-fnref-cbv-supercomp-54d94b7e3b1e11d354471762690aaa27" data-footnote-ref="" aria-describedby="footnote-label">4</a></sup> <sup><a href="#user-content-fn-CbV-supercomp-next-54d94b7e3b1e11d354471762690aaa27" id="user-content-fnref-cbv-supercomp-next-54d94b7e3b1e11d354471762690aaa27" data-footnote-ref="" aria-describedby="footnote-label">5</a></sup>; in all cases, Mazeppa has performed similarly or better.</p>
<div dir="auto"><h2 tabindex="-1" dir="auto">Specializing the power function</h2><a id="user-content-specializing-the-power-function" aria-label="Permalink: Specializing the power function" href="#specializing-the-power-function"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Now consider another example, this time involving partial evaluation:</p>
<p dir="auto">[<a href="https://www.scattered-thoughts.net/mazeppa-dev/mazeppa/blob/master/examples/power-sq/main.mz"><code>examples/power-sq/main.mz</code></a>]</p>
<div data-snippet-clipboard-copy-content="main(a) := powerSq(a, 7u8);

powerSq(a, x) := match =(x, 0u8) {
    T() -&gt; 1i32,
    F() -&gt; match =(%(x, 2u8), 0u8) {
        T() -&gt; square(powerSq(a, /(x, 2u8))),
        F() -&gt; *(a, powerSq(a, -(x, 1u8)))
    }
};

square(a) := *(a, a);"><pre><code>main(a) := powerSq(a, 7u8);

powerSq(a, x) := match =(x, 0u8) {
    T() -&gt; 1i32,
    F() -&gt; match =(%(x, 2u8), 0u8) {
        T() -&gt; square(powerSq(a, /(x, 2u8))),
        F() -&gt; *(a, powerSq(a, -(x, 1u8)))
    }
};

square(a) := *(a, a);
</code></pre></div>
<p dir="auto"><code>powerSq</code> implements the famous <a href="https://en.wikipedia.org/wiki/Exponentiation_by_squaring" rel="nofollow">exponentiation-by-squaring</a> algorithm. The original program is inefficient: it recursively examines the <code>x</code> parameter of <code>powerSq</code>, although it is perfectly known at compile-time. Running Mazeppa on <code>main(a)</code> will yield the following residual program:</p>
<p dir="auto">[<a href="https://www.scattered-thoughts.net/mazeppa-dev/mazeppa/blob/master/examples/power-sq/target/output.mz"><code>examples/power-sq/target/output.mz</code></a>]</p>
<div data-snippet-clipboard-copy-content="main(a) := *(a, let x0 := *(a, *(a, a)); *(x0, x0));"><pre><code>main(a) := *(a, let x0 := *(a, *(a, a)); *(x0, x0));
</code></pre></div>
<p dir="auto">The whole <code>powerSq</code> function has been eliminated, thus achieving the effect of partial evaluation. (If we consider <code>powerSq</code> to be an interpreter for a program <code>x</code> and input data <code>a</code>, then it is the first Futamura projection: specializing an interpreter to obtain an efficient target program.) Also, notice how the supercompiler has managed to <em>share</em> the argument <code>*(a, *(a, a))</code> twice, so that it is not recomputed each time anew. The residual program indeed reflects exponentiation by squaring.</p>
<div dir="auto"><h2 tabindex="-1" dir="auto">Synthesizing the KMP algorithm</h2><a id="user-content-synthesizing-the-kmp-algorithm" aria-label="Permalink: Synthesizing the KMP algorithm" href="#synthesizing-the-kmp-algorithm"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Let us go beyond deforestation and partial evaluation. Consider a function <code>matches(p, s)</code> of two strings, which returns <code>T()</code> if <code>s</code> contains <code>p</code> and <code>F()</code> otherwise. The naive implementation in Mazeppa would be the following, where <code>p</code> is specialized to <code>&#34;aab&#34;</code>:</p>
<p dir="auto">[<a href="https://www.scattered-thoughts.net/mazeppa-dev/mazeppa/blob/master/examples/kmp-test/main.mz"><code>examples/kmp-test/main.mz</code></a>]</p>
<div data-snippet-clipboard-copy-content="main(s) := matches(Cons(&#39;a&#39;, Cons(&#39;a&#39;, Cons(&#39;b&#39;, Nil()))), s);

matches(p, s) := go(p, s, p, s);

go(pp, ss, op, os) := match pp {
    Nil() -&gt; T(),
    Cons(p, pp) -&gt; goFirst(p, pp, ss, op, os)
};

goFirst(p, pp, ss, op, os) := match ss {
    Nil() -&gt; F(),
    Cons(s, ss) -&gt; match =(p, s) {
        T() -&gt; go(pp, ss, op, os),
        F() -&gt; failover(op, os)
    }
};

failover(op, os) := match os {
    Nil() -&gt; F(),
    Cons(_s, ss) -&gt; matches(op, ss)
};"><pre><code>main(s) := matches(Cons(&#39;a&#39;, Cons(&#39;a&#39;, Cons(&#39;b&#39;, Nil()))), s);

matches(p, s) := go(p, s, p, s);

go(pp, ss, op, os) := match pp {
    Nil() -&gt; T(),
    Cons(p, pp) -&gt; goFirst(p, pp, ss, op, os)
};

goFirst(p, pp, ss, op, os) := match ss {
    Nil() -&gt; F(),
    Cons(s, ss) -&gt; match =(p, s) {
        T() -&gt; go(pp, ss, op, os),
        F() -&gt; failover(op, os)
    }
};

failover(op, os) := match os {
    Nil() -&gt; F(),
    Cons(_s, ss) -&gt; matches(op, ss)
};
</code></pre></div>
<p dir="auto">(Here we represent strings as lists of characters for simplicity, but do not worry, Mazeppa provides built-in strings as well.)</p>
<p dir="auto">The algorithm is correct but inefficient. Consider what happens when <code>&#34;aa&#34;</code> is successfully matched, but <code>&#39;b&#39;</code> is not. The algorithm will start matching <code>&#34;aab&#34;</code> once again from the second character of <code>s</code>, although it can already be said that the second character of <code>s</code> is <code>&#39;a&#39;</code>. The deterministic finite automaton built by the <a href="https://en.wikipedia.org/wiki/Knuth%E2%80%93Morris%E2%80%93Pratt_algorithm" rel="nofollow">Knuth-Morris-Pratt algorithm (KMP)</a> <sup><a href="#user-content-fn-kmp-54d94b7e3b1e11d354471762690aaa27" id="user-content-fnref-kmp-54d94b7e3b1e11d354471762690aaa27" data-footnote-ref="" aria-describedby="footnote-label">6</a></sup> is an alternative way to solve this problem.</p>
<p dir="auto">By running Mazeppa on the above sample, we can obtain an efficient string matching algorithm for <code>p=&#34;aab&#34;</code> that reflects KMP in action:</p>
<p dir="auto">[<a href="https://www.scattered-thoughts.net/mazeppa-dev/mazeppa/blob/master/examples/kmp-test/target/output.mz"><code>examples/kmp-test/target/output.mz</code></a>]</p>
<div data-snippet-clipboard-copy-content="main(s) := f0(s);

f0(x0) := match x0 {
    Cons(x1, x2) -&gt; match =(97u8, x1) {
        F() -&gt; f1(x2),
        T() -&gt; f2(x2)
    },
    Nil() -&gt; F()
};

f1(x0) := f0(x0);

f2(x0) := match x0 {
    Cons(x1, x2) -&gt; match =(97u8, x1) {
        F() -&gt; f1(x2),
        T() -&gt; f4(x2)
    },
    Nil() -&gt; F()
};

f3(x0) := f2(x0);

f4(x0) := match x0 {
    Cons(x1, x2) -&gt; match =(98u8, x1) {
        F() -&gt; match =(97u8, x1) {
            F() -&gt; f1(x2),
            T() -&gt; f4(x2)
        },
        T() -&gt; T()
    },
    Nil() -&gt; F()
};"><pre><code>main(s) := f0(s);

f0(x0) := match x0 {
    Cons(x1, x2) -&gt; match =(97u8, x1) {
        F() -&gt; f1(x2),
        T() -&gt; f2(x2)
    },
    Nil() -&gt; F()
};

f1(x0) := f0(x0);

f2(x0) := match x0 {
    Cons(x1, x2) -&gt; match =(97u8, x1) {
        F() -&gt; f1(x2),
        T() -&gt; f4(x2)
    },
    Nil() -&gt; F()
};

f3(x0) := f2(x0);

f4(x0) := match x0 {
    Cons(x1, x2) -&gt; match =(98u8, x1) {
        F() -&gt; match =(97u8, x1) {
            F() -&gt; f1(x2),
            T() -&gt; f4(x2)
        },
        T() -&gt; T()
    },
    Nil() -&gt; F()
};
</code></pre></div>
<p dir="auto">The naive algorithm that we wrote has been automatically transformed into a well-known efficient version!</p>
<p dir="auto">Synthesizing KMP is a standard example that showcases the power of supercompilation with respect to other techniques (e.g., see <sup><a href="#user-content-fn-perfect-process-tree-54d94b7e3b1e11d354471762690aaa27" id="user-content-fnref-perfect-process-tree-54d94b7e3b1e11d354471762690aaa27" data-footnote-ref="" aria-describedby="footnote-label">7</a></sup> and <sup><a href="#user-content-fn-positive-supercomp-54d94b7e3b1e11d354471762690aaa27" id="user-content-fnref-positive-supercomp-54d94b7e3b1e11d354471762690aaa27" data-footnote-ref="" aria-describedby="footnote-label">8</a></sup>). Obtaining KMP by partial evaluation is not possible without changing the original definition of <code>matches</code> <sup><a href="#user-content-fn-partial-evaluation-matches-1-54d94b7e3b1e11d354471762690aaa27" id="user-content-fnref-partial-evaluation-matches-1-54d94b7e3b1e11d354471762690aaa27" data-footnote-ref="" aria-describedby="footnote-label">9</a></sup> <sup><a href="#user-content-fn-partial-evaluation-matches-2-54d94b7e3b1e11d354471762690aaa27" id="user-content-fnref-partial-evaluation-matches-2-54d94b7e3b1e11d354471762690aaa27" data-footnote-ref="" aria-describedby="footnote-label">10</a></sup>.</p>

<p dir="auto"><a href="https://en.wikipedia.org/wiki/Valentin_Turchin" rel="nofollow">Valentin Turchin</a>, the inventor of supercompilation, describes the concept of <a href="http://pespmc1.vub.ac.be/MST.html" rel="nofollow"><em>metasystem transition</em></a> in the following way <sup><a href="#user-content-fn-turchin-mst-scp-54d94b7e3b1e11d354471762690aaa27" id="user-content-fnref-turchin-mst-scp-54d94b7e3b1e11d354471762690aaa27" data-footnote-ref="" aria-describedby="footnote-label">11</a></sup> <sup><a href="#user-content-fn-turchin-transformation-54d94b7e3b1e11d354471762690aaa27" id="user-content-fnref-turchin-transformation-54d94b7e3b1e11d354471762690aaa27" data-footnote-ref="" aria-describedby="footnote-label">12</a></sup> <sup><a href="#user-content-fn-turchin-dialogue-54d94b7e3b1e11d354471762690aaa27" id="user-content-fnref-turchin-dialogue-54d94b7e3b1e11d354471762690aaa27" data-footnote-ref="" aria-describedby="footnote-label">13</a></sup>:</p>
<blockquote>
<p dir="auto">Consider a system <em>S</em> of any kind. Suppose that there is a way to make some number of copies from it, possibly with variations. Suppose that these systems are united into a new system <em>S&#39;</em> which has the systems of the <em>S</em> type as its subsystems, and includes also an additional mechanism which controls the behavior and production of the <em>S</em>-subsystems. Then we call <em>S&#39;</em> a metasystem with respect to <em>S</em>, and the creation of <em>S&#39;</em> a metasystem transition. As a result of consecutive metasystem transitions a multilevel structure of control arises, which allows complicated forms of behavior.</p>
</blockquote>
<p dir="auto">Thus, supercompilation can be readily seen as a metasystem transition: there is an object program in Mazeppa, and there is the Mazeppa supercompiler which controls and supervises execution of the object program. However, we can go further and perform any number of metasystem transitions within the realm of the object program itself, as the next example demonstrates.</p>
<p dir="auto">We will be using the code from <a href="https://www.scattered-thoughts.net/mazeppa-dev/mazeppa/blob/master/examples/lambda-calculus"><code>examples/lambda-calculus/</code></a>. Below is a standard <a href="https://davidchristiansen.dk/tutorials/nbe/" rel="nofollow">normalization-by-evaluation</a> procedure for obtaining beta normal forms of untyped lambda calculus terms:</p>
<div data-snippet-clipboard-copy-content="indexEnv(env, idx) := match env {
    Nil() -&gt; Panic(++(&#34;the variable is unbound: &#34;, string(idx))),
    Cons(value, xs) -&gt; match =(idx, 0u64) {
        T() -&gt; value,
        F() -&gt; indexEnv(xs, -(idx, 1u64))
    }
};

normalize(lvl, env, t) := quote(lvl, eval(env, t));

normalizeAt(lvl, env, t) := normalize(+(lvl, 1u64), Cons(vvar(lvl), env), t);

vvar(lvl) := Neutral(NVar(lvl));

eval(env, t) := match t {
    Var(idx) -&gt; indexEnv(env, idx),
    Lam(body) -&gt; Closure(env, body),
    Appl(m, n) -&gt;
        let mVal := eval(env, m);
        let nVal := eval(env, n);
        match mVal {
            Closure(env, body) -&gt; eval(Cons(nVal, env), body),
            Neutral(nt) -&gt; Neutral(NAppl(nt, nVal))
        }
};

quote(lvl, v) := match v {
    Closure(env, body) -&gt; Lam(normalizeAt(lvl, env, body)),
    Neutral(nt) -&gt; quoteNeutral(lvl, nt)
};

quoteNeutral(lvl, nt) := match nt {
    NVar(var) -&gt; Var(-(-(lvl, var), 1u64)),
    NAppl(nt, nVal) -&gt; Appl(quoteNeutral(lvl, nt), quote(lvl, nVal))
};"><pre><code>indexEnv(env, idx) := match env {
    Nil() -&gt; Panic(++(&#34;the variable is unbound: &#34;, string(idx))),
    Cons(value, xs) -&gt; match =(idx, 0u64) {
        T() -&gt; value,
        F() -&gt; indexEnv(xs, -(idx, 1u64))
    }
};

normalize(lvl, env, t) := quote(lvl, eval(env, t));

normalizeAt(lvl, env, t) := normalize(+(lvl, 1u64), Cons(vvar(lvl), env), t);

vvar(lvl) := Neutral(NVar(lvl));

eval(env, t) := match t {
    Var(idx) -&gt; indexEnv(env, idx),
    Lam(body) -&gt; Closure(env, body),
    Appl(m, n) -&gt;
        let mVal := eval(env, m);
        let nVal := eval(env, n);
        match mVal {
            Closure(env, body) -&gt; eval(Cons(nVal, env), body),
            Neutral(nt) -&gt; Neutral(NAppl(nt, nVal))
        }
};

quote(lvl, v) := match v {
    Closure(env, body) -&gt; Lam(normalizeAt(lvl, env, body)),
    Neutral(nt) -&gt; quoteNeutral(lvl, nt)
};

quoteNeutral(lvl, nt) := match nt {
    NVar(var) -&gt; Var(-(-(lvl, var), 1u64)),
    NAppl(nt, nVal) -&gt; Appl(quoteNeutral(lvl, nt), quote(lvl, nVal))
};
</code></pre></div>
<p dir="auto">(<code>eval</code>/<code>quote</code> are sometimes called <code>reflect</code>/<code>reify</code>.)</p>
<p dir="auto">This is essentially a big-step machine for efficient capture-avoiding substitution: instead of reconstructing terms on each beta reduction, we maintain an <em>environment</em> of values. <code>eval</code> projects a term to the &#34;semantic domain&#34;, while <code>quote</code> does the opposite; <code>normalize</code> is simply the composition of <code>quote</code> and <code>eval</code>. To avoid bothering with fresh name generation, we put De Bruijn <em>indices</em> in the <code>Var</code> constructor and De Bruijn <em>levels</em> in <code>NVar</code>; the latter is converted into the former in <code>quoteNeutral</code>.</p>
<p dir="auto">Now let us compute something with this machine:</p>
<div data-snippet-clipboard-copy-content="main() := normalize(0u64, Nil(), example());

example() := Lam(pow(Var(0u64), seven()));

seven() := Lam(Lam(
    Appl(Var(1u64), Appl(Var(1u64), Appl(Var(1u64),
    Appl(Var(1u64), Appl(Var(1u64), Appl(Var(1u64),
    Appl(Var(1u64), Var(0u64))))))))));

pow(a, x) := Appl(x, a);"><pre><code>main() := normalize(0u64, Nil(), example());

example() := Lam(pow(Var(0u64), seven()));

seven() := Lam(Lam(
    Appl(Var(1u64), Appl(Var(1u64), Appl(Var(1u64),
    Appl(Var(1u64), Appl(Var(1u64), Appl(Var(1u64),
    Appl(Var(1u64), Var(0u64))))))))));

pow(a, x) := Appl(x, a);
</code></pre></div>
<p dir="auto">The body of <code>main</code> is a lambda term that normalizes a lambda abstraction that takes a <a href="https://en.wikipedia.org/wiki/Church_encoding#Church_numerals" rel="nofollow">Church numeral</a> and multiplies it seven times.</p>
<p dir="auto">By supercompiling <code>main()</code>, we obtain the following residual program:</p>
<p dir="auto">[<a href="https://www.scattered-thoughts.net/mazeppa-dev/mazeppa/blob/master/examples/lambda-calculus/target/output.mz"><code>examples/lambda-calculus/target/output.mz</code></a>]</p>
<div data-snippet-clipboard-copy-content="main() := Lam(Lam(Appl(Var(1u64), Appl(Var(1u64), Appl(Var(1u64), Appl(Var(1u64)
    , Appl(Var(1u64), Appl(Var(1u64), Appl(Var(1u64), Var(0u64))))))))));"><pre><code>main() := Lam(Lam(Appl(Var(1u64), Appl(Var(1u64), Appl(Var(1u64), Appl(Var(1u64)
    , Appl(Var(1u64), Appl(Var(1u64), Appl(Var(1u64), Var(0u64))))))))));
</code></pre></div>
<p dir="auto">The lambda calculus interpreter has been completely annihilated!</p>
<p dir="auto">In this example, we have just seen a two-level <em>metasystem stairway</em> (in Turchin&#39;s terminology <sup><a href="#user-content-fn-turchin-metavariables-54d94b7e3b1e11d354471762690aaa27" id="user-content-fnref-turchin-metavariables-54d94b7e3b1e11d354471762690aaa27" data-footnote-ref="" aria-describedby="footnote-label">14</a></sup>): on level 0, we have the Mazeppa supercompiler transforming the object program, while on level 1, we have the object program normalizing lambda calculus terms. There can be an arbitrary number of interpretation levels, and Mazeppa can be used to collapse them all. This general behaviour of supercompilation was explored by Turchin himself in <sup><a href="#user-content-fn-turchin-concept-54d94b7e3b1e11d354471762690aaa27" id="user-content-fnref-turchin-concept-2-54d94b7e3b1e11d354471762690aaa27" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup> (section 7), where he was able to supercompile two interpretable programs, one Fortran-like and one in Lisp, to obtain a speedup factor of 40 in both cases.</p>
<p dir="auto">The lambda normalizer also shows us how to incarnate higher-order functions into a first-order language. In Mazeppa, we cannot treat functions as values, but it does not mean that we cannot simulate them! <strong>By performing a metasystem transition, we can efficiently implement higher-order functions in a first-order language.</strong> Along with defunctionalization and closure conversion, this technique can be used for compilation of higher-order languages into efficient first-order code.</p>
<p dir="auto">Related example: <a href="https://www.scattered-thoughts.net/mazeppa-dev/mazeppa/blob/master/examples/imperative-vm"><code>examples/imperative-vm/</code></a>.</p>
<div dir="auto"><h2 tabindex="-1" dir="auto">Restricting supercompilation</h2><a id="user-content-restricting-supercompilation" aria-label="Permalink: Restricting supercompilation" href="#restricting-supercompilation"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">In retrospect, the major problem that prevented widespread adoption of supercompilation is its unpredictability -- the dark side of its power. To get a sense of what it means, consider how can we solve any SAT problem <a href="https://hirrolot.github.io/posts/sat-supercompilation.html" rel="nofollow">&#34;on the fly&#34;</a>:</p>
<p dir="auto">[<a href="https://www.scattered-thoughts.net/mazeppa-dev/mazeppa/blob/master/examples/sat-solver/main.mz"><code>examples/sat-solver/main.mz</code></a>]</p>
<div data-snippet-clipboard-copy-content="main(a, b, c, d, e, f, g) := solve(formula(a, b, c, d, e, f, g));

formula(a, b, c, d, e, f, g) :=
    and(or(Var(a), or(Not(b), or(Not(c), F()))),
    and(or(Not(f), or(Var(e), or(Not(g), F()))),
    and(or(Var(e), or(Not(g), or(Var(f), F()))),
    and(or(Not(g), or(Var(c), or(Var(d), F()))),
    and(or(Var(a), or(Not(b), or(Not(c), F()))),
    and(or(Not(f), or(Not(e), or(Var(g), F()))),
    and(or(Var(a), or(Var(a), or(Var(c), F()))),
    and(or(Not(g), or(Not(d), or(Not(b), F()))),
    T()))))))));

or(x, rest) := match x {
    Var(x) -&gt; If(x, T(), rest),
    Not(x) -&gt; If(x, rest, T())
};

and(clause, rest) := match clause {
    If(x, m, n) -&gt; If(x, and(m, rest), and(n, rest)),
    T() -&gt; rest,
    F() -&gt; F()
};

solve(formula) := match formula {
    If(x, m, n) -&gt; analyze(x, m, n),
    T() -&gt; T(),
    F() -&gt; F()
};

analyze(x, m, n) := match x {
    T() -&gt; solve(m),
    F() -&gt; solve(n)
};"><pre><code>main(a, b, c, d, e, f, g) := solve(formula(a, b, c, d, e, f, g));

formula(a, b, c, d, e, f, g) :=
    and(or(Var(a), or(Not(b), or(Not(c), F()))),
    and(or(Not(f), or(Var(e), or(Not(g), F()))),
    and(or(Var(e), or(Not(g), or(Var(f), F()))),
    and(or(Not(g), or(Var(c), or(Var(d), F()))),
    and(or(Var(a), or(Not(b), or(Not(c), F()))),
    and(or(Not(f), or(Not(e), or(Var(g), F()))),
    and(or(Var(a), or(Var(a), or(Var(c), F()))),
    and(or(Not(g), or(Not(d), or(Not(b), F()))),
    T()))))))));

or(x, rest) := match x {
    Var(x) -&gt; If(x, T(), rest),
    Not(x) -&gt; If(x, rest, T())
};

and(clause, rest) := match clause {
    If(x, m, n) -&gt; If(x, and(m, rest), and(n, rest)),
    T() -&gt; rest,
    F() -&gt; F()
};

solve(formula) := match formula {
    If(x, m, n) -&gt; analyze(x, m, n),
    T() -&gt; T(),
    F() -&gt; F()
};

analyze(x, m, n) := match x {
    T() -&gt; solve(m),
    F() -&gt; solve(n)
};
</code></pre></div>
<p dir="auto">There are two things wrong with this perfectly correct code: 1) the supercompiler will expand the formula in exponential space, and 2) the supercompiler will try to solve the expanded formula in exponential time. Sometimes, we just do not want to evaluate everything at compile-time.</p>
<p dir="auto">However, despair not: we provide a solution for this problem. Let us first consider how to postpone solving the formula until run-time. It turns out that the only thing we need to do is to annotate the function <code>formula</code> with <code>@extract</code> as follows:</p>
<div data-snippet-clipboard-copy-content="@extract
formula(a, b, c, d, e, f, g) :=
    // Everything is the same."><pre><code>@extract
formula(a, b, c, d, e, f, g) :=
    // Everything is the same.
</code></pre></div>
<p dir="auto">When Mazeppa sees <code>solve(formula(a, b, c, d, e, f, g))</code>, it extracts the call to <code>formula</code> into a fresh variable <code>.v0</code> and proceeds supercompiling the extracted call and <code>solve(.v0)</code> in isolation. The latter call will just reproduce the original SAT solver.</p>
<p dir="auto">But supercompiling the call to <code>formula</code> will still result in an exponential blowup. Let us examine why this happens. Our original formula consists of calls to <code>or</code> and <code>and</code>; while <code>or</code> is obviously not dangerous, <code>and</code> propagates the <code>rest</code> parameter to <em>both</em> branches of <code>If</code> (the first <code>match</code> case) -- this is the exact place where the blowup occurs. So let us mark <code>and</code> with <code>@extract</code> as well:</p>
<div data-snippet-clipboard-copy-content="@extract
and(clause, rest) := match clause {
    // Everything is the same.
};"><pre><code>@extract
and(clause, rest) := match clause {
    // Everything is the same.
};
</code></pre></div>
<p dir="auto">That is it! When <code>and</code> is to be transformed, Mazeppa will extract the call out of its surrounding context and supercompile it in isolation. By adding two annotations at appropriate places, we have solved both the problem of code blowup and exponential running time of supercompilation. In general, whenever Mazeppa sees <code>ctx[f(t1, ..., tN)]</code>, where <code>f</code> is marked <code>@extract</code> and <code>ctx[.]</code> is a non-empty surrounding context with <code>.</code> in a <em>redex position</em>, it will plug a fresh variable <code>v</code> into <code>ctx</code> and proceed transforming the following nodes separately: <code>f(t1, ..., tN)</code> and <code>ctx[v]</code>.</p>
<p dir="auto">Finally, note that <code>@extract</code> is only a low-level mechanism; a compiler front-end must carry out additional machinery to tell Mazeppa which functions to extract. This can be done in two ways:</p>
<ul dir="auto">
<li>By static analysis of your object language/Mazeppa code. For example, parameter linearity analysis would mark both <code>formula</code> and <code>and</code> as extractable, leaving all other functions untouched.</li>
<li>By source code annotations, in a manner similar to <a href="https://okmij.org/ftp/ML/MetaOCaml.html" rel="nofollow">staged compilation</a>.</li>
</ul>
<p dir="auto">Both methods can be combined to achieve a desired effect.</p>
<hr/>
<p dir="auto">There are many more examples of supercompilation (including some simple theorem proving!) in the <a href="https://www.scattered-thoughts.net/mazeppa-dev/mazeppa/blob/master/examples"><code>examples</code></a> folder. Feel free to explore them all and ask us questions, if you have any.</p>

<p dir="auto">After running <code>./scripts/install.sh</code>, Mazeppa is available as an OCaml library!</p>
<p dir="auto">Set up a new Dune project as follows:</p>
<div data-snippet-clipboard-copy-content="$ dune init project my_compiler"><pre><code>$ dune init project my_compiler
</code></pre></div>
<p dir="auto">Add <code>mazeppa</code> as a third-party library into your <code>bin/dune</code>:</p>
<div data-snippet-clipboard-copy-content="(executable
 (public_name my_compiler)
 (name main)
 (libraries my_compiler mazeppa))"><pre><code>(executable
 (public_name my_compiler)
 (name main)
 (libraries my_compiler mazeppa))
</code></pre></div>
<p dir="auto">Paste the following code into <code>bin/main.ml</code> (this is <a href="https://www.scattered-thoughts.net/mazeppa-dev/mazeppa/blob/master/examples/sum-squares/main.mz"><code>examples/sum-squares/main.mz</code></a> encoded in OCaml):</p>
<div dir="auto" data-snippet-clipboard-copy-content="open Mazeppa

let input : Raw_program.t =
    let sym = Symbol.of_string in
    let open Raw_term in
    let open Checked_oint in
    [ [], sym &#34;main&#34;, [ sym &#34;xs&#34; ], call (&#34;sum&#34;, [ call (&#34;mapSq&#34;, [ var &#34;xs&#34; ]) ])
    ; ( []
      , sym &#34;sum&#34;
      , [ sym &#34;xs&#34; ]
      , Match
          ( var &#34;xs&#34;
          , [ (sym &#34;Nil&#34;, []), int (I32 (I32.of_int_exn 0))
            ; ( (sym &#34;Cons&#34;, [ sym &#34;x&#34;; sym &#34;xs&#34; ])
              , call (&#34;+&#34;, [ var &#34;x&#34;; call (&#34;sum&#34;, [ var &#34;xs&#34; ]) ]) )
            ] ) )
    ; ( []
      , sym &#34;mapSq&#34;
      , [ sym &#34;xs&#34; ]
      , Match
          ( var &#34;xs&#34;
          , [ (sym &#34;Nil&#34;, []), call (&#34;Nil&#34;, [])
            ; ( (sym &#34;Cons&#34;, [ sym &#34;x&#34;; sym &#34;xs&#34; ])
              , call
                  ( &#34;Cons&#34;
                  , [ call (&#34;*&#34;, [ var &#34;x&#34;; var &#34;x&#34; ]); call (&#34;mapSq&#34;, [ var &#34;xs&#34; ]) ] ) )
            ] ) )
    ]
;;

let () =
    try
      let output = Mazeppa.supercompile input in
      Printf.printf &#34;%s\n&#34; (Raw_program.show output)
    with
    | Mazeppa.Panic msg -&gt;
      Printf.eprintf &#34;Something went wrong: %s\n&#34; msg;
      exit 1
;;"><pre><span>open</span> <span>Mazeppa</span>

<span>let</span> <span>input</span> : <span>Raw_program.t </span><span>=</span>
    <span>let</span> sym <span>=</span> <span>Symbol.</span>of_string <span>in</span>
    <span>let</span> <span>open</span> <span>Raw_term</span> <span>in</span>
    <span>let</span> <span>open</span> <span>Checked_oint</span> <span>in</span>
    [ [], sym <span><span>&#34;</span>main<span>&#34;</span></span>, [ sym <span><span>&#34;</span>xs<span>&#34;</span></span> ], call (<span><span>&#34;</span>sum<span>&#34;</span></span>, [ call (<span><span>&#34;</span>mapSq<span>&#34;</span></span>, [ var <span><span>&#34;</span>xs<span>&#34;</span></span> ]) ])
    ; ( <span>[]</span>
      , sym <span><span>&#34;</span>sum<span>&#34;</span></span>
      , [ sym <span><span>&#34;</span>xs<span>&#34;</span></span> ]
      , <span>Match</span>
          ( var <span><span>&#34;</span>xs<span>&#34;</span></span>
          , [ (sym <span><span>&#34;</span>Nil<span>&#34;</span></span>, <span>[]</span>), <span>int</span> (<span>I32</span> (<span>I32.</span>of_int_exn <span>0</span>))
            ; ( (sym <span><span>&#34;</span>Cons<span>&#34;</span></span>, [ sym <span><span>&#34;</span>x<span>&#34;</span></span>; sym <span><span>&#34;</span>xs<span>&#34;</span></span> ])
              , call (<span><span>&#34;</span>+<span>&#34;</span></span>, [ var <span><span>&#34;</span>x<span>&#34;</span></span>; call (<span><span>&#34;</span>sum<span>&#34;</span></span>, [ var <span><span>&#34;</span>xs<span>&#34;</span></span> ]) ]) )
            ] ) )
    ; ( <span>[]</span>
      , sym <span><span>&#34;</span>mapSq<span>&#34;</span></span>
      , [ sym <span><span>&#34;</span>xs<span>&#34;</span></span> ]
      , <span>Match</span>
          ( var <span><span>&#34;</span>xs<span>&#34;</span></span>
          , [ (sym <span><span>&#34;</span>Nil<span>&#34;</span></span>, <span>[]</span>), call (<span><span>&#34;</span>Nil<span>&#34;</span></span>, <span>[]</span>)
            ; ( (sym <span><span>&#34;</span>Cons<span>&#34;</span></span>, [ sym <span><span>&#34;</span>x<span>&#34;</span></span>; sym <span><span>&#34;</span>xs<span>&#34;</span></span> ])
              , call
                  ( <span><span>&#34;</span>Cons<span>&#34;</span></span>
                  , [ call (<span><span>&#34;</span>*<span>&#34;</span></span>, [ var <span><span>&#34;</span>x<span>&#34;</span></span>; var <span><span>&#34;</span>x<span>&#34;</span></span> ]); call (<span><span>&#34;</span>mapSq<span>&#34;</span></span>, [ var <span><span>&#34;</span>xs<span>&#34;</span></span> ]) ] ) )
            ] ) )
    ]
;;

<span>let</span> <span>()</span> <span>=</span>
    <span>try</span>
      <span>let</span> output <span>=</span> <span>Mazeppa.</span>supercompile input <span>in</span>
      <span>Printf.</span>printf <span><span>&#34;</span>%s<span>\n</span><span>&#34;</span></span> (<span>Raw_program.</span>show output)
    <span>with</span><span></span>
    <span>|</span> <span>Mazeppa.</span><span>Panic</span> <span>msg</span> -&gt;
      <span>Printf.</span>eprintf <span><span>&#34;</span>Something went wrong: %s<span>\n</span><span>&#34;</span></span> msg;
      exit <span>1</span>
;;</pre></div>
<p dir="auto">Run <code>dune exec my_compiler</code> to see the desired residual program:</p>
<div data-snippet-clipboard-copy-content="[([], &#34;main&#34;, [&#34;xs&#34;], (Raw_term.Call (&#34;f0&#34;, [(Raw_term.Var &#34;xs&#34;)])));
  ([], &#34;f0&#34;, [&#34;x0&#34;],
   (Raw_term.Match ((Raw_term.Var &#34;x0&#34;),
      [((&#34;Cons&#34;, [&#34;x1&#34;; &#34;x2&#34;]),
        (Raw_term.Call (&#34;+&#34;,
           [(Raw_term.Call (&#34;*&#34;, [(Raw_term.Var &#34;x1&#34;); (Raw_term.Var &#34;x1&#34;)]));
             (Raw_term.Call (&#34;f0&#34;, [(Raw_term.Var &#34;x2&#34;)]))]
           )));
        ((&#34;Nil&#34;, []), (Raw_term.Const (Const.Int (Checked_oint.I32 0))))]
      )))
  ]"><pre><code>[([], &#34;main&#34;, [&#34;xs&#34;], (Raw_term.Call (&#34;f0&#34;, [(Raw_term.Var &#34;xs&#34;)])));
  ([], &#34;f0&#34;, [&#34;x0&#34;],
   (Raw_term.Match ((Raw_term.Var &#34;x0&#34;),
      [((&#34;Cons&#34;, [&#34;x1&#34;; &#34;x2&#34;]),
        (Raw_term.Call (&#34;+&#34;,
           [(Raw_term.Call (&#34;*&#34;, [(Raw_term.Var &#34;x1&#34;); (Raw_term.Var &#34;x1&#34;)]));
             (Raw_term.Call (&#34;f0&#34;, [(Raw_term.Var &#34;x2&#34;)]))]
           )));
        ((&#34;Nil&#34;, []), (Raw_term.Const (Const.Int (Checked_oint.I32 0))))]
      )))
  ]
</code></pre></div>
<p dir="auto">You can call Mazeppa as many times as you want, including in parallel. Note that we expose a limited interface that can only transform a value of type <code>Raw_program.t</code> into an optimized <code>Raw_program.t</code>, and nothing more.</p>

<ul dir="auto">
<li>Consider building Mazeppa with an <a href="https://ocaml.org/manual/latest/flambda.html" rel="nofollow">Flambda</a>-enabled OCaml compiler; to check, run <code>ocamlopt -config | grep flambda</code>.</li>
<li>Forget about <code>--inspect</code> in a real environment: use it only for debugging purposes.</li>
<li>Supercompiling a whole user program is not a good idea. Instead, consider supercompiling separate modules and then linking them together (the exact way you do so depends on your situation).
<ul dir="auto">
<li>Although Mazeppa is itself not parallel, supercompiling separate modules can be done in parallel.</li>
</ul>
</li>
<li>It is <em>much</em> better if recursive functions reduce at least one argument structurally, just as in total functional programming. Otherwise, termination checking will not work well.</li>
</ul>

<p dir="auto">Mazeppa employs several interesting design choices (ranked by importance):</p>
<ul dir="auto">
<li>
<p dir="auto"><strong>First-order code.</strong> Max Bolingbroke and Simon Peyton Jones <sup><a href="#user-content-fn-supercomp-by-eval-54d94b7e3b1e11d354471762690aaa27" id="user-content-fnref-supercomp-by-eval-54d94b7e3b1e11d354471762690aaa27" data-footnote-ref="" aria-describedby="footnote-label">15</a></sup> report that for one particular example, their higher-order supercompiler for a subset of Haskell spent 42% of execution time on managing names and renaming. While it is true that simplistic evaluation models, such as normalization of lambda terms, permit us to avoid significant overhead of capture avoidance, supercompilation is more complicated. For example, besides doing symbolic computation, supercompilation needs to analyze previously computed results to make informed decisions about further transformation: consider term instance tests, homeomorphic embedding tests, most specific generalizations, etc. Introducing higher-order functions inevitably complicates all these analyses, making supercompilation slower, more memory-consuming, and harder to reason about. In Mazeppa, we stick with the philosophy of gradual improvements: instead of trying to handle many fancy features at the same time, we 1) fix the <em>core</em> language for convenient manipulation by a machine, 2) perform as many metasystem transitions as necessary to make the core language better for human.</p>
</li>
<li>
<p dir="auto"><strong>Lazy constructors.</strong> It is a well-known observation that call-by-value languages are hard for proper deforestation. It is still possible to deforest them, but not without additional analysis <sup><a href="#user-content-fn-CbV-supercomp-54d94b7e3b1e11d354471762690aaa27" id="user-content-fnref-cbv-supercomp-2-54d94b7e3b1e11d354471762690aaa27" data-footnote-ref="" aria-describedby="footnote-label">4</a></sup> <sup><a href="#user-content-fn-CbV-supercomp-next-54d94b7e3b1e11d354471762690aaa27" id="user-content-fnref-cbv-supercomp-next-2-54d94b7e3b1e11d354471762690aaa27" data-footnote-ref="" aria-describedby="footnote-label">5</a></sup>. However, if constructors are lazy (i.e., they do not evaluate their arguments), deforestation <em>just works</em>. Turchin made it work by normal-order transformation of a call-by-value language, but the result is that residual code may terminate more often. In Mazeppa, we have call-by-value functions and call-by-name (call-by-need) constructors, which 1) makes deforestation possible and 2) preserves the original semantics of code.</p>
<ul dir="auto">
<li>Incidentally, lazy constructors are also adopted by eager functional languages outside of supercompilation. See <a href="https://www.type-driven.org.uk/edwinb/why-is-idris-2-so-much-faster-than-idris-1.html" rel="nofollow"><em>&#34;Why is Idris 2 so much faster than Idris 1?&#34;</em></a> and <em>&#34;CONS Should Not Evaluate its Arguments&#34;</em> <sup><a href="#user-content-fn-cons-lazy-alloc-54d94b7e3b1e11d354471762690aaa27" id="user-content-fnref-cons-lazy-alloc-54d94b7e3b1e11d354471762690aaa27" data-footnote-ref="" aria-describedby="footnote-label">16</a></sup>.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Term-free process graphs.</strong> In Mazeppa, process graphs do not contain any references to terms: residualization can work without them. As a result, the garbage collector can deallocate terms that were used during construction of a subgraph. In addition ot that, this policy has several other important advantages: 1) the graph is still there for inspection with <code>--inspect</code>, 2) when it is drawn, it only reveals information about the <em>decisions</em> the supercompiler has taken, which makes it much easier to look at. Several existing supercompilers refrain from proper process graphs (e.g., Neil Mitchell&#39;s Supero <sup><a href="#user-content-fn-mitchell-supero-54d94b7e3b1e11d354471762690aaa27" id="user-content-fnref-mitchell-supero-54d94b7e3b1e11d354471762690aaa27" data-footnote-ref="" aria-describedby="footnote-label">17</a></sup> and the aforementioned <sup><a href="#user-content-fn-supercomp-by-eval-54d94b7e3b1e11d354471762690aaa27" id="user-content-fnref-supercomp-by-eval-2-54d94b7e3b1e11d354471762690aaa27" data-footnote-ref="" aria-describedby="footnote-label">15</a></sup>), but as a result, 1) they are less capable of inspection by a user, 2) the algorithms become cluttered with code generation details.</p>
</li>
<li>
<p dir="auto"><strong>Two-dimensional configuration analysis.</strong> Usually a supercompiler keeps a &#34;history&#34; of a subset of all ancestors while transforming a node; if this node is &#34;close enough&#34; to one of its ancestors, it is time to break the term into smaller parts to guarantee termination. In Mazeppa, we keep two separate data structures instead: the one containing a subset of node&#39;s ancestors and the one containing a subset of fully transformed nodes. The former data structure is used to guarantee termination (as usual), while the latter is used to enhance <em>sharing of functions</em> in residual code. Specifically, if the current node (of special kind) is an instance of some previously transformed node, we fold the current node into this previous node. This way, Mazeppa performs both <em>vertical</em> and <em>horizontal</em> analysis of configurations, which makes residual code more compact and supercompilation more efficient.</p>
</li>
<li>
<p dir="auto"><strong>Smart histories.</strong> Instead of blindly comparing a current node with all its ancestors, we employ a more fine-grained control, that is: 1) global nodes (the ones that analyze an unknown variable) are compared with global nodes only, 2) local nodes (the ones that reduce linearly in a single step) are compared with local nodes only up to the latest global node, but not including it, and 3) trivial nodes (the ones that break down terms into smaller components) are not compared with anything else. Besides a more economic approach to termination checking, this scheme allows Mazeppa to discover more optimization opportunities; see <sup><a href="#user-content-fn-metric-space-54d94b7e3b1e11d354471762690aaa27" id="user-content-fnref-metric-space-54d94b7e3b1e11d354471762690aaa27" data-footnote-ref="" aria-describedby="footnote-label">18</a></sup>, sections 4.6 and 4.7. Termination of supercompilation is guaranteed by the fact that homeomorphic embedding is still tested on all potentially infinite subsequences of global and local terms (there cannot exist an infinite sequence of trivial terms only).</p>
</li>
<li>
<p dir="auto"><strong>Normalization during unfolding.</strong> When a function call is unfolded, we substitute the parameters and normalize the body as much as possible (i.e., without further unfoldings, to guarantee termination). To see why, consider the factorial function <code>f(n)</code>; with simple unfolding, we would trap in an unpleasant situation where <code>f(1u32)</code> is embedded into <code>*(1u32, f(-(1u32, 1u32)))</code>, causing <em>over-generalization</em>. In reality, Mazeppa would unfold <code>f(1u32)</code> to <code>*(1u32, f(0u32))</code>, making the latter a candidate for further unfolding. This approach was suggested in <sup><a href="#user-content-fn-supercomp-code-explosion-54d94b7e3b1e11d354471762690aaa27" id="user-content-fnref-supercomp-code-explosion-54d94b7e3b1e11d354471762690aaa27" data-footnote-ref="" aria-describedby="footnote-label">19</a></sup>, section 4.5. Its other merits are: 1) less work for future driving steps, 2) less &#34;banal&#34; computation in process graphs, 3) reduced amount of expensive homeomorphic embedding tests.</p>
<ul dir="auto">
<li>Besides folding constants, we also perform algebraic simplification such as <em>+(t, 0), +(0, t) -&gt; t</em>, <em>-(t, 0) -&gt; t</em>, <em>*(t, 0), *(0, t) -&gt; 0</em>, etc. These can be seen as axioms for built-in types.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Implementation in OCaml.</strong> Mazeppa is implemented using a combination of functional and imperative programming styles, which is very natural to do in OCaml. Exceptions are used not only for &#34;exceptional&#34; situations, mutability inside functions is common. Although we do not have a similar supercompiler written in e.g. Haskell or Rust for comparison, we believe that it is OCaml that gave us a working implementation without having to quarrel with the language and never finishing work.</p>
</li>
</ul>
<p dir="auto">While none of the above is particularly novel, we believe that the combination of these features makes Mazeppa a more practical alternative than its predecessors.</p>

<ul dir="auto">
<li>Can supercompilation be used to erase unnecessary information from dependently typed programs <sup><a href="#user-content-fn-dependent-types-erasure-54d94b7e3b1e11d354471762690aaa27" id="user-content-fnref-dependent-types-erasure-54d94b7e3b1e11d354471762690aaa27" data-footnote-ref="" aria-describedby="footnote-label">20</a></sup>?</li>
<li>Is it possible to devise heuristics that would guarantee predictability of supercompilation? (E.g., by dynamically marking misbehaving functions as extractable.)</li>
<li>What if we <a href="https://ocaml.org/manual/latest/flambda.html" rel="nofollow">partially evaluate</a> the supercompiler based on a set of function definitions (e.g., some fixed interpreter)? This could make supercompilation significantly more efficient.</li>
<li><em>Equality indices</em> <sup><a href="#user-content-fn-equality-indices-54d94b7e3b1e11d354471762690aaa27" id="user-content-fnref-equality-indices-54d94b7e3b1e11d354471762690aaa27" data-footnote-ref="" aria-describedby="footnote-label">21</a></sup> can enhance dynamic sharing of arguments. Would it be beneficial to implement them in Mazeppa?</li>
<li>Suppose that there exists a dirty language <em>L</em>, a pure interpreter <em>I</em> for <em>L</em>, and a fixed program <em>P</em> in <em>L</em>. By supercompiling <em>I(P, data)</em>, where <em>data</em> is unknown, we should be able to automatically <em>purify</em> the program <em>P</em>! Likewise, we should be able to purify not only all programs in <em>L</em>, but also all dirty languages with interpretive definitions in Mazeppa.</li>
</ul>
<div dir="auto"><h2 tabindex="-1" dir="auto">A note about built-in panics</h2><a id="user-content-a-note-about-built-in-panics" aria-label="Permalink: A note about built-in panics" href="#a-note-about-built-in-panics"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Some built-in operations raise a panic on certain conditions. Consider the following program:</p>
<div data-snippet-clipboard-copy-content="main(x) := ignore(+(x, 100u8));

ignore(_x) := 5u8;"><pre><code>main(x) := ignore(+(x, 100u8));

ignore(_x) := 5u8;
</code></pre></div>
<p dir="auto">It will be supercompiled as follows:</p>

<p dir="auto">These two programs are not semantically equivalent! Whereas the former one raises a panic if <code>x</code> is <code>200u8</code>, the latter does not. In general, Mazeppa can remove some built-in panics from the original program, or make them happen at some later point.</p>
<p dir="auto">Is this an appropriate behaviour?</p>
<p dir="auto">We believe it is. Take the semantics of Rust for example: when the code is compiled in the debug mode, integer overflow/underflow operations raise a panic, but in the release mode, they do not (modular arithmetic is used instead). The reason is that checked arithmetic introduces an overhead, and so application testing should detect those panics. The Rust compiler essentially changes the semantics of code depending on a compilation mode; as a result, some release programs may execute longer and terminate more often.</p>
<p dir="auto">In practice, this scheme usually works well. While it is theoretically possible to preserve even built-in panics at the cost of additional analyses, we decide to keep the current behaviour as it is.</p>


<p dir="auto">A <em>symbol</em> <code>&lt;SYMBOL&gt;</code> is a sequence of letters (<code>a</code>, <em>...</em>, <code>z</code> and <code>A</code>, <em>...</em>, <code>Z</code>) and digits (<code>0</code>, <em>...</em>, <code>9</code>), followed by an optional question mark (<code>?</code>), followed by an optional sequence of <code>&#39;</code> characters. The underscore character (<code>_</code>) may be the first character of a symbol, which may informally indicate that the value or function being defined is not used; otherwise, the first character must be a letter. The following sequences of characters are also permitted as symbols: <code>~</code>, <code>#</code>, <code>+</code>, <code>-</code>, <code>*</code>, <code>/</code>, <code>%</code>, <code>|</code>, <code>&amp;</code>, <code>^</code>, <code>&lt;&lt;</code>, <code>&gt;&gt;</code>, <code>=</code>, <code>!=</code>, <code>&gt;</code>, <code>&gt;=</code>, <code>&lt;</code>, <code>&lt;=</code>, <code>++</code>. The following are <em>reserved words</em> that may <strong>not</strong> be used as symbols: <code>match</code>, <code>let</code>.</p>
<p dir="auto">There are four classes of <em>unsigned integer constants</em>:</p>
<ul dir="auto">
<li>Binary: <code>0b</code> (<code>0B</code>) followed by a non-empty sequence of binary digits <code>0</code> and <code>1</code>.</li>
<li>Octal: <code>0o</code> (<code>0O</code>) followed by a non-empty sequence of octal digits <code>0</code>, <em>...</em>, <code>7</code>.</li>
<li>Decimal: a non-empty sequence of decimal digits <code>0</code>, <em>...</em>, <code>9</code>.</li>
<li>Hexadecimal: <code>0x</code> (<code>0X</code>) followed by a non-empty sequence of decimal digits <code>0</code>, <em>...</em>, <code>9</code> and letters <code>a</code>, <em>...</em>, <code>f</code> (<code>A</code>, <em>...</em>, <code>F</code>).</li>
</ul>
<p dir="auto">Notes:</p>
<ul dir="auto">
<li>For convenience of reading, each unsigned integer constant may contain underscore characters (<code>_</code>) except for the first position in the sequence of digits.</li>
<li>For each unsigned integer constant, there is a <em>negated integer constant</em> formed by the negation character (<code>-</code>) placed right before the sequence of digits and underscore characters.</li>
<li>For each unsigned and negated integer constant, there is a <em>typed integer constant</em> <code>&lt;INT&gt;</code> produced by appending an integer type <code>&lt;INT-TY&gt;</code> (<code>u8</code>, <code>u16</code>, <code>u32</code>, <code>u64</code>, <code>u128</code>, <code>i8</code>, <code>i16</code>, <code>i32</code>, <code>i64</code>, <code>i128</code>) right after the original integer constant. For example, the constants <code>123i8</code>, <code>123u16</code>, and <code>123i32</code> all belong to the set <code>&lt;INT&gt;</code>.</li>
</ul>
<p dir="auto">A <em>string constant</em> <code>&lt;STRING&gt;</code> is a sequence, between double quotes (<code>&#34;</code>), of zero or more printable characters (we refer to printable characters as those numbered 33-126 in the ASCII character set), spaces, or <em>string escape sequences</em>:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Escape sequence</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>\f</code></td>
<td>Form feed (ASCII 12)</td>
</tr>
<tr>
<td><code>\n</code></td>
<td>Line feed (ASCII 10)</td>
</tr>
<tr>
<td><code>\r</code></td>
<td>Carriage return (ASCII 13)</td>
</tr>
<tr>
<td><code>\t</code></td>
<td>Horizontal tab (ASCII 9)</td>
</tr>
<tr>
<td><code>\v</code></td>
<td>Vertical tab (ASCII 11)</td>
</tr>
<tr>
<td><code>\xhh</code></td>
<td>ASCII code in hexadecimal</td>
</tr>
<tr>
<td><code>\&#34;</code></td>
<td><code>&#34;</code></td>
</tr>
<tr>
<td><code>\\</code></td>
<td><code>\</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">where <code>h</code> is either <code>0</code>, <em>...</em>, <code>9</code> or <code>a</code>, <em>...</em>, <code>f</code> or <code>A</code>, <em>...</em>, <code>F</code>.</p>
<p dir="auto">A <em>character constant</em> <code>&lt;CHAR&gt;</code> is either a sole character enclosed in single quotes (<code>&#39;</code>) or a <em>character escape sequence</em> enclosed in single quotes. The character escape sequence is the same as for strings, except that <code>\&#34;</code> is replaced by <code>\&#39;</code>.</p>
<p dir="auto">There are no other constants in Mazeppa.</p>
<p dir="auto">A <em>comment</em> <code>&lt;COMMENT&gt;</code> is any sequence of characters after <code>//</code>, which is terminated by a newline character. (We only allow single-line comments for simplicity.)</p>

<p dir="auto">The entry point <code>&lt;program&gt;</code> is defined by the following rules:</p>
<ul dir="auto">
<li><code>&lt;def-attr-list&gt;</code> <code>&lt;SYMBOL&gt;</code> <code>(</code> <code>&lt;SYMBOL&gt;</code>, <em>...</em>, <code>&lt;SYMBOL&gt;</code> <code>)</code> <code>:=</code> <code>&lt;term&gt;</code> <code>;</code> <code>&lt;program&gt;</code></li>
<li><code>&lt;COMMENT&gt;</code> <code>&lt;program&gt;</code></li>
<li>(Empty string.)</li>
</ul>
<p dir="auto">where <code>&lt;def-attr-list&gt;</code> is a whitespace-separated sequence of <em>function attributes</em> (the same attribute can occur multiple times). Right now, the only allowed function attribute is <code>@extract</code>.</p>
<p dir="auto"><code>&lt;term&gt;</code> is defined as follows:</p>
<ul dir="auto">
<li><code>&lt;SYMBOL&gt;</code> (a variable)</li>
<li><code>&lt;const&gt;</code> (a constant)</li>
<li><code>&lt;SYMBOL&gt;</code> <code>(</code> <code>&lt;term&gt;</code>, <em>...</em>, <code>&lt;term&gt;</code> <code>)</code> (a function call)</li>
<li><code>match</code> <code>&lt;term&gt;</code> <code>{</code> <code>&lt;match-case&gt;</code>, <em>...</em>, <code>&lt;match-case&gt;</code> <code>}</code> (pattern matching)</li>
<li><code>let</code> <code>&lt;SYMBOL&gt;</code> <code>:=</code> <code>&lt;term&gt;</code> <code>;</code> <code>&lt;term&gt;</code> (a let-binding)</li>
<li><code>let</code> <code>&lt;pattern&gt;</code> <code>:=</code> <code>&lt;term&gt;</code> <code>;</code> <code>&lt;term&gt;</code> (a pattern let-binding)</li>
<li><code>&lt;COMMENT&gt;</code> <code>&lt;term&gt;</code> (a comment)</li>
</ul>
<p dir="auto">The rest of the auxiliary rules are:</p>
<p dir="auto"><code>&lt;const&gt;</code>:</p>
<ul dir="auto">
<li>Either <code>&lt;INT&gt;</code> or <code>&lt;STRING&gt;</code> or <code>&lt;CHAR&gt;</code>.</li>
</ul>
<p dir="auto"><code>&lt;match-case&gt;</code>:</p>
<ul dir="auto">
<li><code>&lt;pattern&gt;</code> <code>-&gt;</code> <code>&lt;term&gt;</code></li>
</ul>
<p dir="auto"><code>&lt;pattern&gt;</code>:</p>
<ul dir="auto">
<li><code>&lt;SYMBOL&gt;</code> <code>(</code> <code>&lt;SYMBOL&gt;</code>, <em>...</em>, <code>&lt;SYMBOL&gt;</code> <code>)</code>.</li>
</ul>
<p dir="auto">In Mazeppa, primitive operations employ the same syntax as that of ordinary function calls. To distinguish between the two, we define <code>&lt;op1&gt;</code> and <code>&lt;op2&gt;</code> to be the following sets of symbols:</p>
<ul dir="auto">
<li><code>&lt;op1&gt;</code> is one of <code>~</code>, <code>#</code>, <code>length</code>, <code>string</code>, <code>&lt;INT-TY&gt;</code>.</li>
<li><code>&lt;op2&gt;</code> is one of <code>+</code>, <code>-</code>, <code>*</code>, <code>/</code>, <code>%</code>, <code>|</code>, <code>&amp;</code>, <code>^</code>, <code>&lt;&lt;</code>, <code>&gt;&gt;</code>, <code>=</code>, <code>!=</code>, <code>&gt;</code>, <code>&gt;=</code>, <code>&lt;</code>, <code>&lt;=</code>, <code>++</code>, <code>get</code>.</li>
</ul>
<p dir="auto">Furthermore, <code>&lt;op2&gt;</code> has the following subclasses:</p>
<ul dir="auto">
<li><code>&lt;arith-op2&gt;</code> is one of <code>+</code>, <code>-</code>, <code>*</code>, <code>/</code>, <code>%</code>, <code>|</code>, <code>&amp;</code>, <code>^</code>, <code>&lt;&lt;</code>, <code>&gt;&gt;</code>.</li>
<li><code>&lt;cmp-op2&gt;</code> is one of <code>=</code>, <code>!=</code>, <code>&gt;</code>, <code>&gt;=</code>, <code>&lt;</code>, <code>&lt;=</code>.</li>
</ul>

<ul dir="auto">
<li><strong>Per-program:</strong> 1) No symbol can be called with a different number of arguments. 2) If some function is defined with <em>N</em> parameters, it must be called with exactly <em>N</em> arguments. 3) No two functions can define the same symbol.</li>
<li><strong>Per-function:</strong> 1) No function can redefine a primitive operator <code>&lt;op1&gt;</code> or <code>&lt;op2&gt;</code>. 2) A function must define a symbol starting with a lowercase letter. 3) No duplicate symbols can occur among function parameters. 4) Every free variable inside a function body must be bound by a corresponding parameter in the function definition.</li>
<li><strong>Per-term:</strong> 1) The sequence of cases in <code>match { ... }</code> must not be empty. 2) No duplicate constructors can occur among case patterns in <code>match { ... }</code>. 3) No duplicate symbols can occur among pattern parameters <code>C(x1, ..., xN)</code>. 4) No let-binding can bind <code>&lt;op1&gt;</code> or <code>&lt;op2&gt;</code>. 5) <code>Panic</code> must be called with only one argument; <code>T</code> and <code>F</code> with zero arguments.</li>
</ul>
<p dir="auto">If a program, function, or term conforms to these restrictions, we call it <em>well-formed</em>.</p>

<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Original form</th>
<th>Desugared form</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>// ...</code> <code>rest</code></td>
<td><code>rest</code></td>
<td><code>rest</code> is in <code>&lt;program&gt;</code> or <code>&lt;term&gt;</code></td>
</tr>
<tr>
<td><code>let p := t; u</code></td>
<td><code>match t { p -&gt; u }</code></td>
<td><code>p</code> is in <code>&lt;pattern&gt;</code></td>
</tr>
<tr>
<td><code>c</code></td>
<td><em>ASCII(c)</em></td>
<td><code>c</code> is in <code>&lt;CHAR&gt;</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">where <em>ASCII(c)</em> is an appropriate <code>u8</code> integer constant, according to the ASCII table; for example, <em>ASCII(<code>&#39;a&#39;</code>)</em> is <code>97u8</code>.</p>

<p dir="auto">Suppose that <em>t</em> is a well-formed term closed under environment <em>env</em> (defined below) and <em>program</em> is a well-formed program. Then the evaluation of <em>t</em> is governed by the following big-step environment machine:</p>
<ul dir="auto">
<li><code>eval(env, x) = env(x)</code></li>
<li><code>eval(env, const) = const</code>, where <code>const</code> is in <code>&lt;const&gt;</code>.</li>
<li><code>eval(env, f(t1, ..., tN)) =</code>
<ul dir="auto">
<li><code>t1Val ^= eval(env, t1)</code></li>
<li><em>...</em></li>
<li><code>tNVal ^= eval(env, tN)</code></li>
<li><code>eval(env[x1 -&gt; t1Val, ..., xN -&gt; tNVal], body)</code>, where <code>f(x1, ..., xN) := body;</code> is in <em>program</em>.</li>
</ul>
</li>
<li><code>eval(env, C(t1, ..., tN)) = C(t1[env], ..., tN[env])</code>, where <code>C</code> starts with an uppercase letter.</li>
<li><code>eval(env, op(t)) =</code>
<ul dir="auto">
<li><code>tVal ^= eval(env, t)</code></li>
<li><code>evalOp1(op, tVal)</code>, where <code>op</code> is in <code>&lt;op1&gt;</code>.</li>
</ul>
</li>
<li><code>eval(env, op(t1, t2)) =</code>
<ul dir="auto">
<li><code>t1Val ^= eval(env, t1)</code></li>
<li><code>t2Val ^= eval(env, t2)</code></li>
<li><code>evalOp2(t1Val, op, t2Val)</code>, where <code>op</code> is in <code>&lt;op2&gt;</code>.</li>
</ul>
</li>
<li><code>eval(env, let x := t; u) =</code>
<ul dir="auto">
<li><code>tVal ^= eval(env, t)</code></li>
<li><code>eval(env[x -&gt; tVal], u)</code></li>
</ul>
</li>
<li><code>eval(env, match t { p1 -&gt; t1, ..., pN -&gt; tN }) =</code>
<ul dir="auto">
<li><code>Ci(s1, ..., sN) ^= eval(env, t)</code></li>
<li><code>eval(env&#39;, tI)</code>, where
<ul dir="auto">
<li><code>Ci(x1, ..., xN) -&gt; tI</code> is among the rules in <code>match t { ... }</code>, and</li>
<li><code>env&#39;</code> is <code>env[x1 -&gt; s1, ..., xN -&gt; sN]</code>.</li>
</ul>
</li>
</ul>
</li>
</ul>
<p dir="auto">Notation:</p>
<ul dir="auto">
<li><code>env</code> is a <em>total environment</em> over <em>t</em>, whose general form is <code>{ x1 -&gt; t1, ..., xN -&gt; tN }</code>. Each <code>tI</code> term must be closed and well-formed; this property is preserved by <code>eval</code>.</li>
<li><code>env(x)</code> is <code>tI</code>, where <code>x -&gt; tI</code> is in <code>env</code>.</li>
<li><code>env[x1 -&gt; t1, ..., xN -&gt; tN]</code> is the environment <code>env</code> extended with new bindings <code>x1 -&gt; t1</code>, <em>...</em>, <code>xN -&gt; tN</code>. If some <code>xI</code> is already bound in <code>env</code>, it is rebound.</li>
<li><code>t[env]</code> denotes a <em>simultaneous substitution</em> of all free variables in <code>t</code> by their bound values in <code>env</code>.</li>
<li><code>tVal ^= eval(env, t)</code> evaluates <code>t</code> under <code>env</code>; then:
<ul dir="auto">
<li>If it is <code>Panic(t&#39;)</code>, the result of the <em>whole</em> evaluation rule is <code>Panic(t&#39;)</code>.</li>
<li>Otherwise, <code>tVal</code> is available for the next clauses.</li>
</ul>
</li>
</ul>
<p dir="auto">(Note that <code>eval</code> is a partial function, so evaluation of <em>t</em> can &#34;get stuck&#34; without a superimposed type system.)</p>
<p dir="auto">In what follows, 1) signed integers are represented in two&#39;s complement notation, 2) <em>panic</em> denotes <code>Panic(s)</code>, where <code>s</code> is some (possibly varying) implementation-defined string constant.</p>
<p dir="auto"><code>evalOp1</code> takes care of the unary operators for primitive types (<code>x</code> is in <code>&lt;INT&gt;</code>, <code>s</code> is in <code>&lt;STRING&gt;</code>):</p>
<ul dir="auto">
<li><code>evalOp1(~, x)</code> is the bitwise negation of <code>x</code> of the same type.</li>
<li><code>evalOp1(string, x)</code> is the string representation of <code>x</code> (in decimal).</li>
<li><code>evalOp1(ty, x)</code>, where <code>ty</code> is in <code>&lt;INT-TY&gt;</code>, is <code>x</code> converted to an integer of type <code>ty</code>.
<ul dir="auto">
<li>If <code>x</code> is not in the range of <code>ty</code>, the result is <em>panic</em>.</li>
</ul>
</li>
<li><code>evalOp1(#, x)</code>, where <code>x</code> is a <code>u8</code> integer, is a string containing only the ASCII character of <code>x</code>.
<ul dir="auto">
<li>If <code>x</code> is not printable, the result takes the form <code>&#34;\xhh&#34;</code>.</li>
</ul>
</li>
<li><code>evalOp1(length, s)</code> is a <code>u64</code> integer denoting the length of <code>s</code>.</li>
<li><code>evalOp1(string, s)</code> is <code>s</code>.</li>
</ul>
<p dir="auto">Likewise, <code>evalOp2</code> takes care of the binary operators for primitive types:</p>
<ul dir="auto">
<li><code>evalOp2(x, op, y)</code>, where <code>x</code> and <code>y</code> have the same integer type and <code>op</code> is in <code>&lt;arith-op2&gt;</code>, performs a corresponding arithmetic operation on <code>x</code> and <code>y</code>, yielding a value of the same type as that of <code>x</code> and <code>y</code>.
<ul dir="auto">
<li>If the value is not representable in that type, the result is <em>panic</em>.</li>
</ul>
</li>
<li><code>evalOp2(x, op, y)</code>, where <code>x</code> and <code>y</code> have the same integer type and <code>op</code> is in <code>&lt;cmp-op2&gt;</code>, performs a corresponding comparison operation on <code>x</code> and <code>y</code>, yielding either <code>T()</code> or <code>F()</code>.</li>
<li><code>evalOp2(s1, op, s2)</code>, where <code>s1</code> and <code>s2</code> are strings and <code>op</code> is in <code>&lt;cmp-op2&gt;</code>, performs a corresponding lexicographical comparison on <code>s1</code> and <code>s2</code>, yielding either <code>T()</code> or <code>F()</code>.</li>
<li><code>evalOp2(s1, ++, s2)</code> is the concatenation of <code>s1</code> and <code>s2</code>.</li>
<li><code>evalOp2(s, get, idx)</code>, where <code>idx</code> is a <code>u64</code> integer, is the <code>idx</code>-th character (of type <code>u8</code>) of <code>s</code>.
<ul dir="auto">
<li>If <code>idx</code> is out of bounds, the result is <em>panic</em>.</li>
</ul>
</li>
</ul>
<p dir="auto">The definition of <code>eval</code> is now complete.</p>

<ol dir="auto">
<li>Update the <code>version</code> field in <code>dune-project</code> and <code>bin/main.ml</code>.</li>
<li>Type <code>dune build</code> to generate <code>mazeppa.opam</code>.</li>
<li>Update <code>CHANGELOG.md</code>.</li>
<li>Release the project in <a href="https://github.com/mazeppa-dev/mazeppa/releases">GitHub Releases</a>.</li>
</ol>

<div dir="auto"><h3 tabindex="-1" dir="auto">Is Mazeppa production-ready?</h3><a id="user-content-is-mazeppa-production-ready" aria-label="Permalink: Is Mazeppa production-ready?" href="#is-mazeppa-production-ready"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Not yet, we need to battle-test Mazeppa on some actual programming language. Our long-term goal is to <a href="https://github.com/mazeppa-dev/mazeppa/issues/2" data-hovercard-type="issue" data-hovercard-url="/mazeppa-dev/mazeppa/issues/2/hovercard">find suitable heuristics</a> to profitably supercompile <em>any</em> source file under 10&#39;000 LoC (in Mazeppa).</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">How can I execute programs in Mazeppa?</h3><a id="user-content-how-can-i-execute-programs-in-mazeppa" aria-label="Permalink: How can I execute programs in Mazeppa?" href="#how-can-i-execute-programs-in-mazeppa"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">It is completely up to you. You can compile Mazeppa to machine code, write a high-level interpreter for it, compile it to bytecode for execution by a virtual machine -- anything you want.</p>
<p dir="auto">We are working on a default <a href="https://github.com/mazeppa-dev/mazeppa/issues/1" data-hovercard-type="issue" data-hovercard-url="/mazeppa-dev/mazeppa/issues/1/hovercard">Mazeppa-to-C translator</a> for easy setup.</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">How can I perform I/O in Mazeppa?</h3><a id="user-content-how-can-i-perform-io-in-mazeppa" aria-label="Permalink: How can I perform I/O in Mazeppa?" href="#how-can-i-perform-io-in-mazeppa"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Since Mazeppa is a purely functional language, the only way to implement I/O is as in Haskell <sup><a href="#user-content-fn-awkward-squad-54d94b7e3b1e11d354471762690aaa27" id="user-content-fnref-awkward-squad-54d94b7e3b1e11d354471762690aaa27" data-footnote-ref="" aria-describedby="footnote-label">22</a></sup>: having a pure program that performs computation and a dirty runtime that performs side effects issued by the program. There are no plans to introduce direct I/O into Mazeppa: it will only make everything more complicated.</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">Will Mazeppa have a type system?</h3><a id="user-content-will-mazeppa-have-a-type-system" aria-label="Permalink: Will Mazeppa have a type system?" href="#will-mazeppa-have-a-type-system"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">No, we do not think that a type system is necessary at this point. It is the responsibility of a front-end compiler to ensure that programs do not &#34;go wrong&#34;.</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">Where can I learn more about supercompilation?</h3><a id="user-content-where-can-i-learn-more-about-supercompilation" aria-label="Permalink: Where can I learn more about supercompilation?" href="#where-can-i-learn-more-about-supercompilation"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">For the English audience, the following paper presents a decent introduction into supercompilation:</p>
<ul dir="auto">
<li><a href="https://themonadreader.wordpress.com/wp-content/uploads/2014/04/super-final.pdf" rel="nofollow"><em>&#34;Supercompilation: Ideas and Methods&#34;</em></a> <sup><a href="#user-content-fn-supercomp-ideas-and-methods-54d94b7e3b1e11d354471762690aaa27" id="user-content-fnref-supercomp-ideas-and-methods-54d94b7e3b1e11d354471762690aaa27" data-footnote-ref="" aria-describedby="footnote-label">23</a></sup></li>
</ul>
<p dir="auto">However, the following papers in Russian describe a supercompilation model that is closer the majority of existing supercompilers, including Mazeppa:</p>
<ul dir="auto">
<li><a href="https://keldysh.ru/papers/2018/prep2018_111.pdf" rel="nofollow"><em>&#34;Supercompilation: main principles and basic concepts&#34;</em></a> <sup><a href="#user-content-fn-supercomp-main-principles-54d94b7e3b1e11d354471762690aaa27" id="user-content-fnref-supercomp-main-principles-54d94b7e3b1e11d354471762690aaa27" data-footnote-ref="" aria-describedby="footnote-label">24</a></sup></li>
<li><a href="https://keldysh.ru/papers/2018/prep2018_209.pdf" rel="nofollow"><em>&#34;Supercompilation: homeomorphic embedding, call-by-name, partial
evaluation&#34;</em></a> <sup><a href="#user-content-fn-supercomp-homeomorphic-54d94b7e3b1e11d354471762690aaa27" id="user-content-fnref-supercomp-homeomorphic-54d94b7e3b1e11d354471762690aaa27" data-footnote-ref="" aria-describedby="footnote-label">25</a></sup></li>
</ul>
<p dir="auto">Mazeppa itself is inspired by this excellent paper (in English):</p>
<ul dir="auto">
<li><em>&#34;A Roadmap to Metacomputation by Supercompilation&#34;</em> <sup><a href="#user-content-fn-metacomp-by-supercomp-54d94b7e3b1e11d354471762690aaa27" id="user-content-fnref-metacomp-by-supercomp-54d94b7e3b1e11d354471762690aaa27" data-footnote-ref="" aria-describedby="footnote-label">26</a></sup></li>
</ul>
<div dir="auto"><h3 tabindex="-1" dir="auto">Can supercompilation be even more powerful?</h3><a id="user-content-can-supercompilation-be-even-more-powerful" aria-label="Permalink: Can supercompilation be even more powerful?" href="#can-supercompilation-be-even-more-powerful"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Several approaches can lead to <em>superlinear speedup</em> of non-esoteric programs by supercompilation:</p>
<ul dir="auto">
<li><em>Jungle driving</em> (appeared 2001) <sup><a href="#user-content-fn-jungle-driving-54d94b7e3b1e11d354471762690aaa27" id="user-content-fnref-jungle-driving-54d94b7e3b1e11d354471762690aaa27" data-footnote-ref="" aria-describedby="footnote-label">27</a></sup> uses <em>jungle evaluation</em> <sup><a href="#user-content-fn-jungle-evaluation-54d94b7e3b1e11d354471762690aaa27" id="user-content-fnref-jungle-evaluation-54d94b7e3b1e11d354471762690aaa27" data-footnote-ref="" aria-describedby="footnote-label">28</a></sup> as an advanced driving strategy for first-order positive supercompilation. The key idea behind jungle evaluation is to share as much computation as theoretically possible by reducing graphs (jungles) instead of terms. Consider that the structure of a supercompiled program reflects the way it will be executed at run-time; in turn, the strategy of driving is what affects the structure. Driving jungles instead of terms can therefore lead to <em>exponentially</em> more efficient residual programs, but the (seemingly inevitable) cost of managing jungles remains at compile-time!</li>
<li><em>Distillation</em> (appeared 2007) <sup><a href="#user-content-fn-distillation-54d94b7e3b1e11d354471762690aaa27" id="user-content-fnref-distillation-54d94b7e3b1e11d354471762690aaa27" data-footnote-ref="" aria-describedby="footnote-label">29</a></sup> <sup><a href="#user-content-fn-distillation-essence-54d94b7e3b1e11d354471762690aaa27" id="user-content-fnref-distillation-essence-54d94b7e3b1e11d354471762690aaa27" data-footnote-ref="" aria-describedby="footnote-label">30</a></sup> <sup><a href="#user-content-fn-distillation-graphs-54d94b7e3b1e11d354471762690aaa27" id="user-content-fnref-distillation-graphs-54d94b7e3b1e11d354471762690aaa27" data-footnote-ref="" aria-describedby="footnote-label">31</a></sup> <sup><a href="#user-content-fn-distillation-lts-54d94b7e3b1e11d354471762690aaa27" id="user-content-fnref-distillation-lts-54d94b7e3b1e11d354471762690aaa27" data-footnote-ref="" aria-describedby="footnote-label">32</a></sup> is an upgraded version of higher-order positive supercompilation. The main difference is that generalization and folding are performed with respect to graphs instead of terms, thus allowing the <a href="https://github.com/poitin/Distiller">distiller</a> to make more insightful decisions about program transformation.
<ul dir="auto">
<li>Furthermore, distillation can be employed to define a <a href="https://github.com/poitin/Higher-Level-Transformer"><em>hierarchy of program transformers</em></a> <sup><a href="#user-content-fn-hamilton-700-54d94b7e3b1e11d354471762690aaa27" id="user-content-fnref-hamilton-700-54d94b7e3b1e11d354471762690aaa27" data-footnote-ref="" aria-describedby="footnote-label">33</a></sup>, where each higher-level transformer is progressively more powerful than lower-level ones.</li>
</ul>
</li>
<li><em>Higher-level supercompilation</em> <sup><a href="#user-content-fn-higher-level-supercomp-54d94b7e3b1e11d354471762690aaa27" id="user-content-fnref-higher-level-supercomp-54d94b7e3b1e11d354471762690aaa27" data-footnote-ref="" aria-describedby="footnote-label">34</a></sup> utilizes lower-level supercompilers to discover lemmas about term equivalences, which are then used by higher-level supercompilers for insightful term rewriting. However, to the best of our knowledge, no fully automatic procedure for discovering (and applying) lemmas in the infinite search space has been proposed yet.</li>
</ul>
<p dir="auto">None of the above is planned to be implemented in Mazeppa, because 1) we think that writing asymptotically good programs is the responsibility of the programmer, not the optimizer, and 2) predictability of supercompilation is of greater importance to us. However, for those who are interested in this topic, the references may be helpful.</p>

<p dir="auto">Just fork the repository, work in your own branch, and submit a pull request. Prefer rebasing when introducing changes to keep the commit history as clean as possible.</p>

<section data-footnotes="">
<ol dir="auto">
<li id="user-content-fn-turchin-concept-54d94b7e3b1e11d354471762690aaa27">
<p dir="auto">Valentin F. Turchin. 1986. The concept of a supercompiler. ACM Trans. Program. Lang. Syst. 8, 3 (July 1986), 292–325. <a href="https://doi.org/10.1145/5956.5957">https://doi.org/10.1145/5956.5957</a> <a href="#user-content-fnref-turchin-concept-54d94b7e3b1e11d354471762690aaa27" data-footnote-backref="" aria-label="Back to reference 1">↩</a> <a href="#user-content-fnref-turchin-concept-2-54d94b7e3b1e11d354471762690aaa27" data-footnote-backref="" aria-label="Back to reference 1-2">↩<sup>2</sup></a></p>
</li>
<li id="user-content-fn-deforestation-54d94b7e3b1e11d354471762690aaa27">
<p dir="auto">Philip Wadler. 1988. Deforestation: transforming programs to eliminate trees. Theor. Comput. Sci. 73, 2 (June 22, 1990), 231–248. <a href="https://doi.org/10.1016/0304-3975(90)90147-A">https://doi.org/10.1016/0304-3975(90)90147-A</a> <a href="#user-content-fnref-deforestation-54d94b7e3b1e11d354471762690aaa27" data-footnote-backref="" aria-label="Back to reference 2">↩</a> <a href="#user-content-fnref-deforestation-2-54d94b7e3b1e11d354471762690aaa27" data-footnote-backref="" aria-label="Back to reference 2-2">↩<sup>2</sup></a></p>
</li>
<li id="user-content-fn-partial-evaluation-54d94b7e3b1e11d354471762690aaa27">
<p dir="auto">Futamura, Y. (1983). Partial computation of programs. In: Goto, E., Furukawa, K., Nakajima, R., Nakata, I., Yonezawa, A. (eds) RIMS Symposia on Software Science and Engineering. Lecture Notes in Computer Science, vol 147. Springer, Berlin, Heidelberg. <a href="https://doi.org/10.1007/3-540-11980-9_13">https://doi.org/10.1007/3-540-11980-9_13</a> <a href="#user-content-fnref-partial-evaluation-54d94b7e3b1e11d354471762690aaa27" data-footnote-backref="" aria-label="Back to reference 3">↩</a></p>
</li>
<li id="user-content-fn-CbV-supercomp-54d94b7e3b1e11d354471762690aaa27">
<p dir="auto">Peter A. Jonsson and Johan Nordlander. 2009. Positive supercompilation for a higher order call-by-value language. SIGPLAN Not. 44, 1 (January 2009), 277–288. <a href="https://doi.org/10.1145/1594834.1480916">https://doi.org/10.1145/1594834.1480916</a> <a href="#user-content-fnref-CbV-supercomp-54d94b7e3b1e11d354471762690aaa27" data-footnote-backref="" aria-label="Back to reference 4">↩</a> <a href="#user-content-fnref-CbV-supercomp-2-54d94b7e3b1e11d354471762690aaa27" data-footnote-backref="" aria-label="Back to reference 4-2">↩<sup>2</sup></a></p>
</li>
<li id="user-content-fn-CbV-supercomp-next-54d94b7e3b1e11d354471762690aaa27">
<p dir="auto">Jonsson, Peter &amp; Nordlander, Johan. (2010). Strengthening supercompilation for call-by-value languages. <a href="#user-content-fnref-CbV-supercomp-next-54d94b7e3b1e11d354471762690aaa27" data-footnote-backref="" aria-label="Back to reference 5">↩</a> <a href="#user-content-fnref-CbV-supercomp-next-2-54d94b7e3b1e11d354471762690aaa27" data-footnote-backref="" aria-label="Back to reference 5-2">↩<sup>2</sup></a></p>
</li>
<li id="user-content-fn-kmp-54d94b7e3b1e11d354471762690aaa27">
<p dir="auto">D. E. Knuth, J. H. Morris, and V. R. Pratt. Fast pattern matching in strings. SIAM Journal on Computing, 6:page 323 (1977). <a href="#user-content-fnref-kmp-54d94b7e3b1e11d354471762690aaa27" data-footnote-backref="" aria-label="Back to reference 6">↩</a></p>
</li>
<li id="user-content-fn-perfect-process-tree-54d94b7e3b1e11d354471762690aaa27">
<p dir="auto">Glück, R., Klimov, A.V. (1993). Occam&#39;s razor in metacomputation: the notion of a perfect process tree. In: Cousot, P., Falaschi, M., Filé, G., Rauzy, A. (eds) Static Analysis. WSA 1993. Lecture Notes in Computer Science, vol 724. Springer, Berlin, Heidelberg. <a href="https://doi.org/10.1007/3-540-57264-3_34">https://doi.org/10.1007/3-540-57264-3_34</a> <a href="#user-content-fnref-perfect-process-tree-54d94b7e3b1e11d354471762690aaa27" data-footnote-backref="" aria-label="Back to reference 7">↩</a></p>
</li>
<li id="user-content-fn-positive-supercomp-54d94b7e3b1e11d354471762690aaa27">
<p dir="auto">Sørensen MH, Glück R, Jones ND. A positive supercompiler. Journal of Functional Programming. 1996;6(6):811-838. doi:10.1017/S0956796800002008 <a href="#user-content-fnref-positive-supercomp-54d94b7e3b1e11d354471762690aaa27" data-footnote-backref="" aria-label="Back to reference 8">↩</a></p>
</li>
<li id="user-content-fn-partial-evaluation-matches-1-54d94b7e3b1e11d354471762690aaa27">
<p dir="auto">Consel, Charles, and Olivier Danvy. &#34;Partial evaluation of pattern matching in strings.&#34; Information Processing Letters 30.2 (1989): 79-86. <a href="#user-content-fnref-partial-evaluation-matches-1-54d94b7e3b1e11d354471762690aaa27" data-footnote-backref="" aria-label="Back to reference 9">↩</a></p>
</li>
<li id="user-content-fn-partial-evaluation-matches-2-54d94b7e3b1e11d354471762690aaa27">
<p dir="auto">Jones, Neil &amp; Gomard, Carsten &amp; Sestoft, Peter. (1993). Partial Evaluation and Automatic Program Generation. <a href="#user-content-fnref-partial-evaluation-matches-2-54d94b7e3b1e11d354471762690aaa27" data-footnote-backref="" aria-label="Back to reference 10">↩</a></p>
</li>
<li id="user-content-fn-turchin-mst-scp-54d94b7e3b1e11d354471762690aaa27">
<p dir="auto">Turchin, V.F. (1996). Metacomputation: Metasystem transitions plus supercompilation. In: Danvy, O., Glück, R., Thiemann, P. (eds) Partial Evaluation. Lecture Notes in Computer Science, vol 1110. Springer, Berlin, Heidelberg. <a href="https://doi.org/10.1007/3-540-61580-6_24">https://doi.org/10.1007/3-540-61580-6_24</a> <a href="#user-content-fnref-turchin-mst-scp-54d94b7e3b1e11d354471762690aaa27" data-footnote-backref="" aria-label="Back to reference 11">↩</a></p>
</li>
<li id="user-content-fn-turchin-transformation-54d94b7e3b1e11d354471762690aaa27">
<p dir="auto">Turchin, Valentin F. &#34;Program transformation with metasystem transitions.&#34; Journal of Functional Programming 3.3 (1993): 283-313. <a href="#user-content-fnref-turchin-transformation-54d94b7e3b1e11d354471762690aaa27" data-footnote-backref="" aria-label="Back to reference 12">↩</a></p>
</li>
<li id="user-content-fn-turchin-dialogue-54d94b7e3b1e11d354471762690aaa27">
<p dir="auto">Turchin, Valentin F.. “A dialogue on Metasystem transition.” World Futures 45 (1995): 5-57. <a href="#user-content-fnref-turchin-dialogue-54d94b7e3b1e11d354471762690aaa27" data-footnote-backref="" aria-label="Back to reference 13">↩</a></p>
</li>
<li id="user-content-fn-turchin-metavariables-54d94b7e3b1e11d354471762690aaa27">
<p dir="auto">Turchin, V., and A. Nemytykh. Metavariables: Their implementation and use in Program Transformation. CCNY Technical Report CSc TR-95-012, 1995. <a href="#user-content-fnref-turchin-metavariables-54d94b7e3b1e11d354471762690aaa27" data-footnote-backref="" aria-label="Back to reference 14">↩</a></p>
</li>
<li id="user-content-fn-supercomp-by-eval-54d94b7e3b1e11d354471762690aaa27">
<p dir="auto">Maximilian Bolingbroke and Simon Peyton Jones. 2010. Supercompilation by evaluation. In Proceedings of the third ACM Haskell symposium on Haskell (Haskell &#39;10). Association for Computing Machinery, New York, NY, USA, 135–146. <a href="https://doi.org/10.1145/1863523.1863540">https://doi.org/10.1145/1863523.1863540</a> <a href="#user-content-fnref-supercomp-by-eval-54d94b7e3b1e11d354471762690aaa27" data-footnote-backref="" aria-label="Back to reference 15">↩</a> <a href="#user-content-fnref-supercomp-by-eval-2-54d94b7e3b1e11d354471762690aaa27" data-footnote-backref="" aria-label="Back to reference 15-2">↩<sup>2</sup></a></p>
</li>
<li id="user-content-fn-cons-lazy-alloc-54d94b7e3b1e11d354471762690aaa27">
<p dir="auto">Friedman, Daniel P. and David S. Wise. “CONS Should Not Evaluate its Arguments.” International Colloquium on Automata, Languages and Programming (1976). <a href="#user-content-fnref-cons-lazy-alloc-54d94b7e3b1e11d354471762690aaa27" data-footnote-backref="" aria-label="Back to reference 16">↩</a></p>
</li>
<li id="user-content-fn-mitchell-supero-54d94b7e3b1e11d354471762690aaa27">
<p dir="auto">Mitchell, Neil. “Rethinking supercompilation.” ACM SIGPLAN International Conference on Functional Programming (2010). <a href="#user-content-fnref-mitchell-supero-54d94b7e3b1e11d354471762690aaa27" data-footnote-backref="" aria-label="Back to reference 17">↩</a></p>
</li>
<li id="user-content-fn-metric-space-54d94b7e3b1e11d354471762690aaa27">
<p dir="auto">Sørensen, M.H.B. (1998). Convergence of program transformers in the metric space of trees. In: Jeuring, J. (eds) Mathematics of Program Construction. MPC 1998. Lecture Notes in Computer Science, vol 1422. Springer, Berlin, Heidelberg. <a href="https://doi.org/10.1007/BFb0054297">https://doi.org/10.1007/BFb0054297</a> <a href="#user-content-fnref-metric-space-54d94b7e3b1e11d354471762690aaa27" data-footnote-backref="" aria-label="Back to reference 18">↩</a></p>
</li>
<li id="user-content-fn-supercomp-code-explosion-54d94b7e3b1e11d354471762690aaa27">
<p dir="auto">Jonsson, Peter &amp; Nordlander, Johan. (2011). Taming code explosion in supercompilation. PERM&#39;11 - Proceedings of the 20th ACM SIGPLAN Workshop on Partial Evaluation and Program Manipulation. 33-42. 10.1145/1929501.1929507. <a href="#user-content-fnref-supercomp-code-explosion-54d94b7e3b1e11d354471762690aaa27" data-footnote-backref="" aria-label="Back to reference 19">↩</a></p>
</li>
<li id="user-content-fn-dependent-types-erasure-54d94b7e3b1e11d354471762690aaa27">
<p dir="auto">Tejiščák, Matúš. Erasure in dependently typed programming. Diss. University of St Andrews, 2020. <a href="#user-content-fnref-dependent-types-erasure-54d94b7e3b1e11d354471762690aaa27" data-footnote-backref="" aria-label="Back to reference 20">↩</a></p>
</li>
<li id="user-content-fn-equality-indices-54d94b7e3b1e11d354471762690aaa27">
<p dir="auto">Glück, Robert, Andrei Klimov, and Antonina Nepeivoda. &#34;Nonlinear Configurations for Superlinear Speedup by Supercompilation.&#34; Fifth International Valentin Turchin Workshop on Metacomputation. 2016. <a href="#user-content-fnref-equality-indices-54d94b7e3b1e11d354471762690aaa27" data-footnote-backref="" aria-label="Back to reference 21">↩</a></p>
</li>
<li id="user-content-fn-awkward-squad-54d94b7e3b1e11d354471762690aaa27">
<p dir="auto">Peyton Jones, Simon. (2002). Tackling the Awkward Squad: monadic input/output, concurrency, exceptions, and foreign-language calls in Haskell. <a href="#user-content-fnref-awkward-squad-54d94b7e3b1e11d354471762690aaa27" data-footnote-backref="" aria-label="Back to reference 22">↩</a></p>
</li>
<li id="user-content-fn-supercomp-ideas-and-methods-54d94b7e3b1e11d354471762690aaa27">
<p dir="auto">Klyuchnikov, Ilya, and Dimitur Krustev. &#34;Supercompilation: Ideas and methods.&#34; The Monad. Reader Issue 23 (2014): 17. <a href="#user-content-fnref-supercomp-ideas-and-methods-54d94b7e3b1e11d354471762690aaa27" data-footnote-backref="" aria-label="Back to reference 23">↩</a></p>
</li>
<li id="user-content-fn-supercomp-main-principles-54d94b7e3b1e11d354471762690aaa27">
<p dir="auto">Klimov, Andrei &amp; Romanenko, Sergei. (2018). Supercompilation: main principles and basic concepts. Keldysh Institute Preprints. 1-36. 10.20948/prepr-2018-111. <a href="#user-content-fnref-supercomp-main-principles-54d94b7e3b1e11d354471762690aaa27" data-footnote-backref="" aria-label="Back to reference 24">↩</a></p>
</li>
<li id="user-content-fn-supercomp-homeomorphic-54d94b7e3b1e11d354471762690aaa27">
<p dir="auto">Romanenko, Sergei. (2018). Supercompilation: homeomorphic embedding, call-by-name, partial evaluation. Keldysh Institute Preprints. 1-32. 10.20948/prepr-2018-209. <a href="#user-content-fnref-supercomp-homeomorphic-54d94b7e3b1e11d354471762690aaa27" data-footnote-backref="" aria-label="Back to reference 25">↩</a></p>
</li>
<li id="user-content-fn-metacomp-by-supercomp-54d94b7e3b1e11d354471762690aaa27">
<p dir="auto">Robert Glück and Morten Heine Sørensen. 1996. A Roadmap to Metacomputation by Supercompilation. In Selected Papers from the International Seminar on Partial Evaluation. Springer-Verlag, Berlin, Heidelberg, 137–160. <a href="#user-content-fnref-metacomp-by-supercomp-54d94b7e3b1e11d354471762690aaa27" data-footnote-backref="" aria-label="Back to reference 26">↩</a></p>
</li>
<li id="user-content-fn-jungle-driving-54d94b7e3b1e11d354471762690aaa27">
<p dir="auto">Secher, J.P. (2001). Driving in the Jungle. In: Danvy, O., Filinski, A. (eds) Programs as Data Objects. PADO 2001. Lecture Notes in Computer Science, vol 2053. Springer, Berlin, Heidelberg. <a href="https://doi.org/10.1007/3-540-44978-7_12">https://doi.org/10.1007/3-540-44978-7_12</a> <a href="#user-content-fnref-jungle-driving-54d94b7e3b1e11d354471762690aaa27" data-footnote-backref="" aria-label="Back to reference 27">↩</a></p>
</li>
<li id="user-content-fn-jungle-evaluation-54d94b7e3b1e11d354471762690aaa27">
<p dir="auto">Hoffmann, B., Plump, D. (1988). Jungle evaluation for efficient term rewriting. In: Grabowski, J., Lescanne, P., Wechler, W. (eds) Algebraic and Logic Programming. ALP 1988. Lecture Notes in Computer Science, vol 343. Springer, Berlin, Heidelberg. <a href="https://doi.org/10.1007/3-540-50667-5_71">https://doi.org/10.1007/3-540-50667-5_71</a> <a href="#user-content-fnref-jungle-evaluation-54d94b7e3b1e11d354471762690aaa27" data-footnote-backref="" aria-label="Back to reference 28">↩</a></p>
</li>
<li id="user-content-fn-distillation-54d94b7e3b1e11d354471762690aaa27">
<p dir="auto">Hamilton, Geoff. (2007). Distillation: Extracting the essence of programs. Proceedings of the ACM SIGPLAN Symposium on Partial Evaluation and Semantics-Based Program Manipulation. 61-70. 10.1145/1244381.1244391. <a href="#user-content-fnref-distillation-54d94b7e3b1e11d354471762690aaa27" data-footnote-backref="" aria-label="Back to reference 29">↩</a></p>
</li>
<li id="user-content-fn-distillation-essence-54d94b7e3b1e11d354471762690aaa27">
<p dir="auto">Hamilton, G.W. (2010). Extracting the Essence of Distillation. In: Pnueli, A., Virbitskaite, I., Voronkov, A. (eds) Perspectives of Systems Informatics. PSI 2009. Lecture Notes in Computer Science, vol 5947. Springer, Berlin, Heidelberg. <a href="https://doi.org/10.1007/978-3-642-11486-1_13">https://doi.org/10.1007/978-3-642-11486-1_13</a> <a href="#user-content-fnref-distillation-essence-54d94b7e3b1e11d354471762690aaa27" data-footnote-backref="" aria-label="Back to reference 30">↩</a></p>
</li>
<li id="user-content-fn-distillation-graphs-54d94b7e3b1e11d354471762690aaa27">
<p dir="auto">Hamilton, Geoff &amp; Mendel-Gleason, Gavin. (2010). A Graph-Based Definition of Distillation. <a href="#user-content-fnref-distillation-graphs-54d94b7e3b1e11d354471762690aaa27" data-footnote-backref="" aria-label="Back to reference 31">↩</a></p>
</li>
<li id="user-content-fn-distillation-lts-54d94b7e3b1e11d354471762690aaa27">
<p dir="auto">Hamilton, Geoff &amp; Jones, Neil. (2012). Distillation with labelled transition systems. Conference Record of the Annual ACM Symposium on Principles of Programming Languages. 15-24. 10.1145/2103746.2103753. <a href="#user-content-fnref-distillation-lts-54d94b7e3b1e11d354471762690aaa27" data-footnote-backref="" aria-label="Back to reference 32">↩</a></p>
</li>
<li id="user-content-fn-hamilton-700-54d94b7e3b1e11d354471762690aaa27">
<p dir="auto">Hamilton, Geoff. &#34;The Next 700 Program Transformers.&#34; International Symposium on Logic-Based Program Synthesis and Transformation. Cham: Springer International Publishing, 2021. <a href="#user-content-fnref-hamilton-700-54d94b7e3b1e11d354471762690aaa27" data-footnote-backref="" aria-label="Back to reference 33">↩</a></p>
</li>
<li id="user-content-fn-higher-level-supercomp-54d94b7e3b1e11d354471762690aaa27">
<p dir="auto">Klyuchnikov, Ilya, and Sergei Romanenko. &#34;Towards higher-level supercompilation.&#34; Second International Workshop on Metacomputation in Russia. Vol. 2. No. 4.2. 2010. <a href="#user-content-fnref-higher-level-supercomp-54d94b7e3b1e11d354471762690aaa27" data-footnote-backref="" aria-label="Back to reference 34">↩</a></p>
</li>
</ol>
</section>
</article></div></div>
  </body>
</html>
