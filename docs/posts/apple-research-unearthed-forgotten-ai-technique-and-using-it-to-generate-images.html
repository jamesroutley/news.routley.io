<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://9to5mac.com/2025/06/23/apple-ai-image-model-research-tarflow-starflow/">Original</a>
    <h1>Apple Research unearthed forgotten AI technique and using it to generate images</h1>
    
    <div id="readability-page-1" class="page"><div>
					
<figure>
	<img width="1600" height="800" src="https://9to5mac.com/wp-content/uploads/sites/6/2025/06/starflow.jpg?quality=82&amp;strip=all&amp;w=1600" alt="" srcset="https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2025/06/starflow.jpg?w=320&amp;quality=82&amp;strip=all&amp;ssl=1 320w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2025/06/starflow.jpg?w=640&amp;quality=82&amp;strip=all&amp;ssl=1 640w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2025/06/starflow.jpg?w=1024&amp;quality=82&amp;strip=all&amp;ssl=1 1024w, https://i0.wp.com/9to5mac.com/wp-content/uploads/sites/6/2025/06/starflow.jpg?w=1500&amp;quality=82&amp;strip=all&amp;ssl=1 1500w" decoding="async" fetchpriority="high"/></figure>

<p>Today, most generative image models basically fall into two main categories: diffusion models, like Stable Diffusion, or autoregressive models, like OpenAI’s GPT-4o. But Apple just released two papers that show how there might be room for a third, forgotten technique: Normalizing Flows. And with a dash of Transformers on top, they might be more capable than previously thought.</p>



<h2 id="h-first-things-first-what-are-normalizing-flows">First things first: What are Normalizing Flows?</h2>



<p>Normalizing Flows (NFs) are a type of AI model that works by learning how to mathematically transform real-world data (like images) into structured noise, and then reverse that process to generate new samples.</p>



<p>The big advantage is that they can calculate the exact likelihood of each image they generate, a property that diffusion models can’t do. This makes flows especially appealing for tasks where understanding the probability of an outcome really matters.</p>



<p>But there’s a reason most people haven’t heard much about them lately: Early flow-based models produced images that looked blurry or lacked the detail and diversity offered by diffusion and transformer-based systems.</p>



<h2 id="h-study-1-tarflow">Study #1: TarFlow</h2>



<p>In the paper “<a href="https://machinelearning.apple.com/research/normalizing-flows">Normalizing Flows are Capable Generative Models</a>”, Apple introduces a new model called TarFlow, short for Transformer AutoRegressive Flow.</p>



<p>At its core, TarFlow replaces the old, handcrafted layers used in previous flow models with Transformer blocks. Basically, it splits images into small patches, and generates them in blocks, with each block predicted based on all the ones that came before. That’s what’s called autoregressive, which is the same underlying method that OpenAI currently uses for image generation.</p>



<figure><img decoding="async" height="384" width="1024" src="https://9to5mac.com/wp-content/uploads/sites/6/2025/06/tarflow-samples.jpg?quality=82&amp;strip=all&amp;w=1024" alt="Image: Apple" srcset="https://9to5mac.com/wp-content/uploads/sites/6/2025/06/tarflow-samples.jpg 1500w, https://9to5mac.com/wp-content/uploads/sites/6/2025/06/tarflow-samples.jpg?resize=155,58 155w, https://9to5mac.com/wp-content/uploads/sites/6/2025/06/tarflow-samples.jpg?resize=655,246 655w, https://9to5mac.com/wp-content/uploads/sites/6/2025/06/tarflow-samples.jpg?resize=768,288 768w, https://9to5mac.com/wp-content/uploads/sites/6/2025/06/tarflow-samples.jpg?resize=1024,384 1024w, https://9to5mac.com/wp-content/uploads/sites/6/2025/06/tarflow-samples.jpg?resize=350,131 350w, https://9to5mac.com/wp-content/uploads/sites/6/2025/06/tarflow-samples.jpg?resize=140,53 140w, https://9to5mac.com/wp-content/uploads/sites/6/2025/06/tarflow-samples.jpg?resize=150,56 150w" sizes="(max-width: 1024px) 100vw, 1024px"/><figcaption>Images of various resolutions generated by TarFlow models. From left to right, top to bottom: 256×256 images on AFHQ, 128×128 and 64×64 images on ImageNet. Source: <a href="https://arxiv.org/html/2412.06329v3">Normalizing Flows are Capable Generative Models</a></figcaption></figure>



<p>The key difference is that while OpenAI generates discrete tokens, treating images like long sequences of text-like symbols, Apple’s TarFlow generates pixel values directly, without tokenizing the image first. It’s a small, but significant difference because it lets Apple avoid the quality loss and rigidity that often come with compressing images into a fixed vocabulary of tokens.</p>



<p>Still, there were limitations, especially when it came to scaling up to larger, high-res images. And that’s where the second study comes in.</p>



<h2 id="h-study-2-starflow">Study #2: STARFlow</h2>



<p>In the paper “<a href="https://machinelearning.apple.com/research/starflow">STARFlow: Scaling Latent Normalizing Flows for High-resolution Image Synthesis</a>”, Apple builds directly on TarFlow and presents STARFlow (Scalable Transformer AutoRegressive Flow), with key upgrades.</p>



<p>The biggest change: STARFlow no longer generates images directly in pixel space. Instead, it basically works on a compressed version of the image, and then hands things off to a decoder that upsamples everything back to full resolution at the final step.</p>



<figure><img loading="lazy" decoding="async" height="513" width="1024" src="https://9to5mac.com/wp-content/uploads/sites/6/2025/06/starflow-sample.jpg?quality=82&amp;strip=all&amp;w=1024" alt="Image: Apple" srcset="https://9to5mac.com/wp-content/uploads/sites/6/2025/06/starflow-sample.jpg 1500w, https://9to5mac.com/wp-content/uploads/sites/6/2025/06/starflow-sample.jpg?resize=155,78 155w, https://9to5mac.com/wp-content/uploads/sites/6/2025/06/starflow-sample.jpg?resize=655,328 655w, https://9to5mac.com/wp-content/uploads/sites/6/2025/06/starflow-sample.jpg?resize=768,385 768w, https://9to5mac.com/wp-content/uploads/sites/6/2025/06/starflow-sample.jpg?resize=1024,513 1024w, https://9to5mac.com/wp-content/uploads/sites/6/2025/06/starflow-sample.jpg?resize=350,175 350w, https://9to5mac.com/wp-content/uploads/sites/6/2025/06/starflow-sample.jpg?resize=140,70 140w, https://9to5mac.com/wp-content/uploads/sites/6/2025/06/starflow-sample.jpg?resize=290,145 290w, https://9to5mac.com/wp-content/uploads/sites/6/2025/06/starflow-sample.jpg?resize=150,75 150w" sizes="auto, (max-width: 1024px) 100vw, 1024px"/><figcaption>Random samples of STARFlow on ImageNet 256 ×256 and 512 ×512. Source: <a href="https://arxiv.org/pdf/2506.06276">STARFlow: Scaling Latent Normalizing Flows for High-resolution Image Synthesis</a></figcaption></figure>



<p>This shift to what is called latent space means STARFlow doesn’t need to predict millions of pixels directly. It can focus on the broader image structure first, leaving fine texture detail to the decoder.</p>



<p>Apple also reworked how the model handles text prompts. Instead of building a separate text encoder, STARFlow can plug in existing language models (like Google’s small language model Gemma, which in theory could run on-device) to handle language understanding when the user prompts the model to create the image. This keeps the image generation side of the model focused on refining visual details.</p>



<h2 id="h-how-starflow-compares-with-openai-s-4o-image-generator">How STARFlow compares with OpenAI’s 4o image generator</h2>



<p>While Apple is rethinking flows, OpenAI has also recently moved beyond diffusion with its GPT-4o model. But their approach is fundamentally different.</p>



<p>GPT-4o treats images as sequences of discrete tokens, much like words in a sentence. When you ask ChatGPT to generate an image, the model predicts one image token at a time, building the picture piece by piece. This gives OpenAI enormous flexibility: the same model can generate text, images, and audio within a single, unified token stream.</p>



<p>The tradeoff? Token-by-token generation can be slow, especially for large or high-resolution images. And it’s extremely computationally expensive. But since GPT-4o runs entirely in the cloud, OpenAI isn’t as constrained by latency or power use.</p>



<p>In short: both Apple and OpenAI are moving beyond diffusion, but while OpenAI is building for its data centers, Apple is clearly building for our pockets.</p>
	
	<div><p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://9to5mac.com/about/#affiliate">More.</a></p><p><a href="https://bit.ly/4k3qtZw"><img src="https://9to5mac.com/wp-content/uploads/sites/6/2025/06/trmnl.gif" alt="" width="1024" height="205"/></a></p></div>				</div></div>
  </body>
</html>
