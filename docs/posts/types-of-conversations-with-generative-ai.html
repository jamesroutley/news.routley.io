<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.nngroup.com/articles/AI-conversation-types/">Original</a>
    <h1>Types of Conversations with Generative AI</h1>
    
    <div id="readability-page-1" class="page"><div>
        <section>
          <p><strong>Summary:</strong> When interacting with generative-AI bots, users engage in six types of conversations, depending on their skill levels and their information needs. Interfaces for UI bots should support and accommodate this diversity of conversation styles.</p>
        </section>

        <section>
          <div>
            
              <div>
                <p><strong>By </strong><span id="gaDataAuthors" aria-hidden="true">Raluca Budiu, Feifei Liu, Emma Cionca, Amy Zhang</span>
</p>
                
                <ul>
                  
                    <li><a href="https://www.nngroup.com/articles/author/raluca-budiu/">Raluca Budiu</a>, </li>
                  
                    <li><a href="https://www.nngroup.com/articles/author/feifei-liu/">Feifei Liu</a>, </li>
                  
                    <li><a href="https://www.nngroup.com/articles/author/emma-cionca/">Emma Cionca</a>, and</li>
                  
                    <li><a href="https://www.nngroup.com/articles/author/amy-zhang/">Amy Zhang</a></li>
                  
                </ul>
                
                
                  <p>
                      on
                      
                        <span id="gaDataPubDate" aria-hidden="true">2023-11-10</span>

                        November 10, 2023
                      
                    </p>
                
              </div>
            

            
              <div>
                <p><strong>Topics:</strong></p>
                
                <p><span id="gaDataAllTopics" aria-hidden="true">Artificial Intelligence</span></p><ul>
                  
                    <li><span id="gaDataTopic" aria-hidden="true">Artificial Intelligence</span>
<a href="https://www.nngroup.com/topic/ai/">Artificial Intelligence</a></li>
                  
                </ul>
              </div>
            
          </div>
          <div>
            
          </div>
        </section>

        <section id="articleBody"><p>Through analyzing 425 interactions with generative-AI bots like ChatGPT, Bing Chat, and Bard, we&#39;ve discovered that conversations could involve many vague, underspecified prompts or few, razor-sharp ones. Why does this matter? First, <strong>different conversation types serve distinct information needs and demand varied UI designs</strong>. Second, <strong>there is no one optimal conversation length</strong> — both short and long conversations can be helpful, as they might support different user goals.</p>
<h3>On This Page:</h3>
<ul>
<li><a href="#Our Research">Our Research</a></li>
<li><a href="#Types of Conversations">Types of Conversations</a></li>
<li><a href="#conversation-length">Conversation Length Is Not a Success Indicator</a></li>
<li><a href="#tips-for-users">Tips for Using Text-Based Generative AI Bots</a></li>
<li><a href="#recommendations-for-designers">Recommendations for Designing the UX of Generative AI</a></li>
</ul>
<h2><a id="Our Research" name="Our Research"></a>Our Research</h2>
<p>In May and June 2023, we conducted a 2-week diary study involving 18 participants who used ChatGPT 4.0, Bard, and Bing Chat. Participants logged a total of 425 conversations and rated each for helpfulness and trustworthiness. At the end of the study, we conducted in-depth interviews with 14 participants.</p>
<p>The findings of this study are reported in several articles:</p>
<ul>
<li><a href="https://www.nngroup.com/articles/generative-ai-diary/">Information foraging with generative AI</a>: how AI bots change the process of finding information</li>
<li><a href="https://www.nngroup.com/articles/ai-bot-comparison/">Differences in helpfulness and trustworthiness among ChatGPT, Bing Chat, and Bard</a></li>
<li>Different types of conversations with AI bots (this article)</li>
<li>Prompt structure in AI conversation (forthcoming)</li>
</ul>
<h2><a id="Types of Conversations" name="Types of Conversations"></a>Types of Conversations</h2>
<p>Several types of conversations emerged from our analysis:</p>
<ul>
<li>Search queries</li>
<li>Funneling conversations</li>
<li>Exploring conversations</li>
<li>Chiseling conversations</li>
<li>Expanding conversations</li>
<li>Pinpointing conversations</li>
</ul>
<p>Some conversations involved several prompts and reformulations, whereas others were relatively short.</p>
<figure><img alt="" height="683" loading="lazy" src="https://media.nngroup.com/media/editor/2023/11/09/ai-convos_icon-metaphors.png" width="692"/>
<figcaption><em>6 types of conversation with generative AI</em></figcaption>
</figure>
<p>In what follows, we discuss each of these 6 types of conversations; for each, we provide tips for both users and interface designers of generative AI chatbots.</p>
<h3>Search Query</h3>
<p>These conversations are <strong>one-prompt, simple queries that are not followed by any refinements</strong>. The prompt usually includes the question with no framing or format specification.</p>
<p>In our diary study, the intent behind search-query conversations was the same as for a web search: users were trying to locate a specific piece of information. These conversations were common when people were still trying to understand what the bots could do for them and what they were best at. In such situations, it is likely that users were simply transferring their search <a href="https://www.nngroup.com/articles/mental-models/">mental models</a> to the AI bots.</p>
<p>Examples of search-query conversations from our diary study include:</p>
<ul>
<li><em>Rosie Odonnell</em></li>
<li><em>Concert dates for Toby Keith</em></li>
<li><em>What is a Chaffle?</em></li>
</ul>
<p>When these search-query conversations involved Bing, participants often clicked on the suggested links and visited the sites, as they normally would have done when using a search engine.</p>
<p>While short keyword phrases like <em>Rosie Odonnell </em>might work well for search, they lack enough context to help AI chatbots understand what the user is asking for. Sometimes users realized that a search engine would be better suited for such queries and quit the bot.</p>
<figure>
<video controls="controls" poster="https://media.nngroup.com/media/editor/2023/11/09/bingchat_july4ththemedfood_thumbnail.jpg" src="https://media.nngroup.com/media/editor/2023/11/09/bingchat_july4ththemedfood_compressed.mp4" title="" width="350"> </video>
<figcaption><em>Upon seeing the results of </em>her Independence Day themed foods<em> query in Bing Chat, the participant clicked on the thumbs-down button; she said</em>: I decided to turn to Google, for the results, and upon entering the same search, I was given pictures and recipes for Independence Day-themed foods and even party favors.<em> (The video was played at 1.5x speed.)</em></figcaption>
</figure>
<p>Both users and designers need to consider what the best tool is for a given information need. Sometimes, it could be that an AI chatbot won’t do a job as good as a search engine.</p>
<h4>Tips for Users of AI Bots</h4>
<p>Avoid using this type of prompt when working with AI bots like ChatGPT. While search engines perform best with keywords, AI bots need more context to understand what kind of response or output you’re looking for.</p>
<p><strong>Search engines might (for now) give you as good if not better results as AI bots</strong> if:</p>
<ul>
<li>You are looking for an answer to a very specific, factual question about an event, a date, a location, or a person.</li>
<li>You need to inspect a lot of options before selecting a particular one.</li>
</ul>
<h4>Tips for Designers of AI Bots</h4>
<p>Consider <strong>allowing users to easily switch to a search-engine mode or access search-engine results<em>, </em></strong>like Bard does.</p>
<figure><img alt="" height="553" loading="lazy" src="https://media.nngroup.com/media/editor/2023/11/07/bard-higher-res.jpg" width="692"/>
<figcaption><em>Bard: Users can perform a Google search based on the query they entered, by selecting one of the blue topics at the bottom of the answer.</em></figcaption>
</figure>
<h3>Funneling Conversations</h3>
<p>In funneling conversations, <strong>the user starts with an underspecified, sometimes too vague query and then narrows it down with subsequent questions that specify additional constraints.</strong> Often, the user doesn’t realize that they need to be more specific until they receive an unsatisfactory response from the bot.</p>
<p>For example, here is a sequence of queries asked by one user who was trying to find a recipe:</p>
<ol>
<li><em>i am looking for a appetizer to serve pool side on memorial day weekend. i do not want to use pork and i want something fairly easy to make that can sit outside</em></li>
<li><em>how about an easier appetizer that can be passed around 30 people or so</em></li>
<li><em>anything other than skewers? i was thinking some sort of dip?</em></li>
</ol>
<p>If the user had anticipated all of these requirements, she could’ve achieved her desired result with a single prompt:</p>
<blockquote>
<p><em>I want an easy appetizer recipe for 30 people to serve poolside on Memorial Day Weekend. I’m thinking of some sort of dip. I don’t want to use pork and the appetizer needs to be able to sit outside in the heat.</em></p>
</blockquote>
<p>However, she likely did not consider this full set of constraints until she received the bot’s initial suggestions.</p>
<p>Funneling conversations are often long, as the user might need to input several prompts to refine their query. Sometimes they start with best-of prompts or other basic prompts that lack details. For example, here’s a sequence of prompts from a user interested in figuring out how to prevent her migraines:</p>
<ol>
<li><em>What are the best cures for a migraine?</em></li>
<li><em>What do you think would be the most effective cure for a migraine?</em></li>
<li><em>I experience migraines 2-3 times a week, is there a likely cause for this?</em></li>
<li><em>I normally have 2-3 cups of coffee per day and on days when I don&#39;t consume any, I usually get migraines. Can a lack of caffeine contribute to migraines?</em></li>
<li><em>How many milligrams of caffeine are typically in a 12 oz cup of coffee?</em></li>
</ol>
<p>Note that, <strong>in funneling conversations, the user’s information need is usually specific and well-defined, but poorly articulated</strong>. In other words, the user will likely recognize a correct response, but will not be able (or sometimes will not be bothered) to say what that correct response should look like. However, <strong>the bot can facilitate query articulation by asking the user helping questions</strong>.</p>
<p>In some of the conversations we studied, the bot did ask for clarification. For example, one participant started the conversation with <em>Issue with swimming pool cleaner.</em> ChatGPT asked for specific information about the cleaner and the issue, expediting the funneling process.</p>
<figure><img alt="" height="422" loading="lazy" src="https://media.nngroup.com/media/editor/2023/11/07/pool-cleaner.jpg" width="692"/>
<figcaption><em>ChatGPT helped the user focus his funneling conversation by asking for a set of details relevant to providing an answer.</em></figcaption>
</figure>
<h4>Tips for Using AI Bots</h4>
<p>Consider <strong>explicitly telling the AI bot to ask helping questions</strong> to improve its output. For example, you may add phrasing such as <em>Ask me questions if you need additional information</em>, to get the bot to help you articulate the different constraints that you may be working with.</p>
<h4>Tips for Designing AI Bots</h4>
<p>To reduce the articulation load in funneling conversations, the <strong>bot should ask helping questions that narrow down underspecified queries</strong>.</p>
<h3>Exploring Conversations</h3>
<p>In exploring conversations, the user starts with a general, less-defined query (usually lacking context or output-format specifications) and then <strong>uses the AI to understand the information space and get ideas for new queries. </strong></p>
<p>Exploring conversations differ from funneling conversations in that, in the beginning, the user is not able to formulate a specific enough query <strong>because they have a less-defined information need and lack the necessary vocabulary or knowledge</strong> (rather than because they did not spend the time to think of all the requirements for their information need). The bot’s responses help the user learn about the structure of the information space and give them new terminology and ideas about what to ask next.</p>
<p>An exploring conversation often <strong>feels like a conversation with a real teacher;</strong> the user acts as a student <strong>learning by</strong> <strong>acquiring depth into a topic</strong> and asking questions as they learn. The user is building queries based on the information received from the bot.</p>
<p>For example, one user asked <em>What is the meaning of life?</em> The bot talked about various kinds of views, including philosophical, religious, and absurdist views. The user then asked to know more about one of these — absurdism. When the bot mentioned the book “The Myth of Sisyphus” by Albert Camus, the user asked for other works by the same author.</p>
<figure>
<video controls="controls" poster="https://media.nngroup.com/media/editor/2023/11/08/sids-thumbnail.jpg" src="https://media.nngroup.com/media/editor/2023/11/08/bingchat-sids_compressed.mp4" title="" width="692"> </video>
<figcaption><em>A study participant started by asking </em>what are some safe sleeping habits for newborns<em>. When the bot mentioned sudden infant death syndrome (SIDS), which the user did not know of, he selected the suggested query </em>What is SIDS?<em> Bing was good at offering suggested followup prompts that allowed the user to further explore the subject. (The video was played at 1.5x speed.)</em></figcaption>
</figure>
<p>In exploring conversations, users can be supported with <strong>suggested followup prompts that naturally build upon the information presented in the bot’s answer.</strong></p>
<h4>Tips for Designing AI Bots</h4>
<p>If the user’s information need is broad and the bot’s response is complex, containing jargon and domain-specific facts or concepts, <strong>offer a list of suggested followup prompts</strong> that build upon these details.</p>
<p>The followup prompts can include:</p>
<ul>
<li>Definitions for domain-specific words (e.g., <em>What is …</em>?)</li>
<li>Additional information about any of the facts or concepts included in the response (e.g., W<em>hy…?, What caused …?, How can one do …?</em>)</li>
</ul>
<p>However, detail-oriented suggested followup prompts do not need to be included in all conversations.<strong> Conversations with well-defined information needs (such as pinpointing conversations — see below) rarely benefit from such followup prompts. </strong>For example, a user rewriting her resume said:</p>
<blockquote>
<p><em>if I&#39;m asking you to put something in my resume, like, I do research in […] B-cell malignancies, I don&#39;t necessarily need to ask ‘what are B-cell malignancies.’</em></p>
</blockquote>
<h3>Chiseling Conversations</h3>
<p>In chiseling conversations, the user asks <strong>about different facets of the same topic, fleshing it out from a variety of angles </strong>like a sculptor chisels a sculpture from a piece of stone. Chiseling conversations cast a wide net over a topic to acquire <strong>breadth</strong>. They can feel like research on a specific topic, but the research is person-driven rather than driven by the bot’s answers.</p>
<p>Here is a sequence of questions asked in the same chiseling conversation about ADHD:</p>
<ol>
<li><em>What are some tips for people with ADHD to remember daily tasks more effectively?</em></li>
<li><em>who are some famously successful people who have ADHD</em></li>
<li><em>is ADHD considered a disability?</em></li>
</ol>
<p>While these questions are all related to ADHD, they cover various aspects of ADHD and do not explore any one of these in depth. It feels as if the respondent is trying to learn many facts about the topic, without focusing on the logical relationship between these facts.</p>
<p>Another user was doing research on the company Insperity. She asked multiple questions related to different aspects of the company:</p>
<ol>
<li><em>What does insperity do?</em></li>
<li><em>How does Insperity make money?</em></li>
<li><em>What percentage of revenue comes from each area?</em></li>
<li><em>How is Insperity&#39;s revenue broken down? (reformulation of previous question)</em></li>
<li><em>What are some goals of Insperity?</em></li>
<li><em>What are executive priorities at Insperity?</em></li>
<li><em>How is Insperity&#39;s stock doing?</em></li>
<li><em>Do you have access to analyst reports? for example analysts from Morgan Stanley?</em></li>
</ol>
<p><strong>Both exploring and chiseling conversations correspond to less-defined information needs and imply learning about a topic</strong>. But, while in exploring conversations, the learning involves acquiring depth into the topic, in chiseling conversations the learning is carried out through breadth.</p>
<figure><img alt="" height="482" loading="lazy" src="https://media.nngroup.com/media/editor/2023/11/08/ai-convos_ex_ch.png" width="692"/>
<figcaption><em>Exploring conversations explore a topic in depth; chiseling conversations favor breadth by examining different facets of the same topic.</em></figcaption>
</figure>
<p>Tips for Designing AI Bots</p>
<p>Like exploring conversations, chiseling conversations benefit from suggested followup queries. However, for chiseling conversations, <strong>suggested followup prompts should be broad, inquiring about multiple facets of the same topic or about related topics (e.g., <em>How about…?)</em></strong>.</p>
<p>In contrast, for exploring conversations, these prompts should go in <strong>depth</strong>, delving into details about a particular concept or fact in the answer.</p>
<h3>Pinpointing Conversations</h3>
<p>In pinpointing conversations, the user has a defined topic in mind and <strong>creates a very specific prompt from the very beginning</strong>. The prompt often includes context and a format specification.</p>
<blockquote>
<p><em>Summer Cocktail Party: My wife and I are hosting a small cocktail and dinner party welcoming my daughter&#39;s future in-laws for a visit to California in late July. The party will be indoors and outdoors by the pool, and we will be grilling something no doubt for the meal. It will be hot in late July so drinks that are refreshing would be order. I am not a professional bartender, but I have been studying &#34;mixology&#34; for the past year and do have all of the bar tools. I know how to make all of the classic cocktails. I would like a summer-themed cocktail menu of four to five drinks with clever names. I will put them on a framed menu on the counter in my outdoor kitchen and bar areas where I will make the drinks.</em></p>
</blockquote>
<p>Sometimes the query might also include pasted text from another source or some other supporting documentation, like in the prompt below, which quoted a previous email chain (names were changed for privacy):</p>
<blockquote>
<p><em>I would like to reach out to Bob to ask if he can do some part-time work for the […] school site visits for my department starting in August through the end of September. Here is some background from an email exchange last year:</em></p>
<p><em>You bet! We’ll keep you posted, Bob!</em></p>
<p><em>John Smith, Ed.D. Department Administrator College &amp; Career | Leadership Support Services</em></p>
<p><em>From: Bob Jones</em></p>
<p><em>Date: Monday, September 12, 2022 at 9:50 AM</em></p>
<p><em>To: John Smith</em></p>
<p><em>Subject: Re: Thank you!</em></p>
<p><em>Thank you John! I enjoyed the time I was able to spend with school leaders and with Andrew. With the new requirements and the possibility of more schools added to the three year cohort I would be available next year if you think I could help. Thank you for your confidence!</em></p>
<p><em>Bob Jones</em></p>
<p><em>Sent from my iPhone</em></p>
<p><em>On Sep 12, 2022, at 9:38 AM, John Smith wrote: ﻿</em></p>
<p><em>Good Morning, Bob, I wanted to thank you for your support of the [school] visits this year. Your expertise and experience as a former district leader really benefited the process. Even with some new requirements, it was one of our smoothest years ever with your help! I hope you enjoyed this work, too, and will consider leading visits again next year if you’re available. Thanks again for lending us your time in this area!</em></p>
<p><em>John</em></p>
</blockquote>
<p><strong>Pinpointing conversations require great effort from the user,</strong> who needs to provide all the information necessary for a comprehensive response. They often contain well-specified, “engineered” prompts. However, unlike with other conversation types, the user rarely needs to spend time on query refinements and the result is a shorter, straight-to-the-point exchange.</p>
<p>Funneling conversations can sometimes be converted into pinpointing conversations if the bot asks the user detailed questions about their query, inviting them to specify all those details in their next prompt.</p>
<h4>Tips for Designing AI Bots</h4>
<p>Ask the user for <strong>specific details</strong> about their question, as well as about the format of the answer.</p>
<p>Consider giving users <strong>examples of the information they could provide</strong> in a prompt if the prompt is too vague or underspecified.</p>
<h3>Expanding Conversations</h3>
<p>The expanding conversation usually starts with a <strong>narrow topic that gets expanded</strong>, often because the results from the original prompt were unsatisfactory (e.g., not up to date) or because the user decides they need more detail.</p>
<p>For example, in the following sequence, the user expanded his original query twice.</p>
<table>
<tbody>
<tr>
<th colspan="2">
<p><strong>Example of Expanded Conversation</strong></p>
</th>
</tr>
<tr>
<td>
<p>Start prompt</p>
</td>
<td>
<ol>
<li><em>What is the cheapest airport to fly between Japan and Hong Kong?</em></li>
</ol>
</td>
</tr>
<tr>
<td>
<p>Expanded prompt:</p>
</td>
<td>
<ol start="2">
<li><em>What is the cheapest airline that flies between Japan and Hong Kong?</em></li>
</ol>
</td>
</tr>
<tr>
<td>
<p>Expanded prompt:</p>
</td>
<td>
<ol start="3">
<li><em>Can you provide the full list of budget airlines between Hong Kong and Japan?</em></li>
</ol>
</td>
</tr>
</tbody>
</table>
<p>When the expanding conversations involved Bing, the expansions were usually selected from the suggested followup queries.</p>
<figure><img alt="" height="839" loading="lazy" src="https://media.nngroup.com/media/editor/2023/11/07/bingchat_expanding.jpg" width="350"/>
<figcaption><em>Bing could not provide a response to the query </em>Who is running on the independent ticket for president<em>, so the participant broadened it by selecting a suggested followup question, </em>Who are the potential candidates for the 2024 presidential election?</figcaption>
</figure>
<p>Expanding conversations remind us of what happens when people get zero search results for a search query: they often try to remove one of the criteria of their query in the hope that they will get something good enough. In such situations, <a href="https://www.nngroup.com/articles/filters-vs-facets/"><strong>search facets</strong></a> have been shown to help people by guiding them to ask queries that have one or more results.</p>
<p>Similarly, in the context of expanding conversations with AI, suggested followup prompts can show the user how to expand their question to get a meaningful answer. However, such <strong>broader suggested followup prompts should have a different answer than the original question.</strong></p>
<p>For instance, one study participant used Bing Chat to look for <em>free events happening in Nashville this weekend</em>. Unsatisfied with the response she received, she expanded her query using a suggested followup <em>What are some popular free events in Nashville</em>. Disappointingly, she found the results were very similar. She commented:</p>
<blockquote>
<p><em>I used one of the suggested follow up questions as the chatbot was not providing very specific information regarding Nashville events. It yielded pretty much identical results to the question I had posed. While it was nice to have the prompts below, I feel that they should maybe pose newer information.</em></p>
</blockquote>
<h4>Tips for Designers of AI Bots</h4>
<p>When the bot is not able to provide an answer to the user’s query, <strong>provide suggested followup prompts that relax some of the criteria in the user’s original question and return an answer</strong>.</p>
<h3>Combinations of Several Types</h3>
<p>Some conversations start as one type and then morph into a different one. For example, chiseling conversations may also have exploratory elements that build upon something that the bot has said.</p>
<p>One user had the following exchanges with ChatGPT; they combined chiseling and exploring conversations.</p>
<table>
<tbody>
<tr>
<th colspan="2">
<p><strong>A Conversation Combining Chiseling and Exploring Prompts</strong></p>
</th>
</tr>
<tr>
<td rowspan="3">
<p>Chiseling prompts:</p>
</td>
<td>
<ol>
<li><em>Tell me how to do well in day trading?</em></li>
</ol>
</td>
</tr>
<tr>
<td>
<ol start="2">
<li><em>Are there courses on day trading?</em></li>
</ol>
</td>
</tr>
<tr>
<td>
<ol start="3">
<li><em>Define day trading</em></li>
</ol>
</td>
</tr>
<tr>
<td>
<p>Exploring prompt:</p>
</td>
<td>
<ol start="4">
<li><em>define the various techniques and tools mentioned [in answer to question #3]</em></li>
</ol>
</td>
</tr>
<tr>
<td>
<p>Exploring prompt:</p>
</td>
<td>
<ol start="5">
<li><em>how much do trading platforms and software [mentioned in answer to question #4] typically cost</em></li>
</ol>
</td>
</tr>
<tr>
<td>
<p>Chiseling prompt:</p>
</td>
<td>
<ol start="6">
<li><em>What are popular blogs about day trading?</em></li>
</ol>
</td>
</tr>
</tbody>
</table>
<h2><a id="conversation-length" name="conversation-length"></a>Conversation Length Is Not a Success Indicator</h2>
<p>On average, <strong>a conversation in our diary study included 3.6 participant-generated prompts</strong> (95% confidence interval: 3.3–3.9); the median length was 3.</p>
<p>In general, the higher the number of attempts to do a task, the worse the usability. (For example, if the average number of submit attempts on a form was 3.6, that would mean that the form was pretty bad.)</p>
<p>However, with AI conversations, it is not the case that longer conversations necessarily represent more strenuous attempts at getting information from the bots<strong>. In fact, there was no correlation between the length of the conversation and its helpfulness or trustworthiness ratings, </strong>as collected from our study<strong>.</strong></p>
<p>For certain types of conversations like funneling and pinpointing,<strong> the length indicates how well-articulated the initial prompt was. </strong>Long funneling chats start with vague prompts that need more detail. Short pinpointing chats begin with detailed prompts that already lay out all the requirements for an acceptable answer. In both such conversations, the user’s information need is constrained and fairly narrow — they need a specific piece of information or a specific output.</p>
<p><strong>For exploring and chiseling conversations, length is part of the conversation’s nature</strong> and serves the user’s less well-defined information need. Exploring conversations require a back-and-forth between the bot and the human, with the human learning from the bot and choosing to go deeper and build upon the bot’s response. Chiseling conversations are also long because the goal is to acquire breadth in a subject, therefore requiring the user to ask multiple, loosely related questions about different aspects of given topic. In both these types of conversations, the goal is learning about a topic, and the conversation serves to define the user’s information need.</p>
<p>A special type of short conversation is the search query. This type of conversation was usually more likely to occur when people were still exploring the range of tasks that the AI bot could do for them.</p>
<p>Search queries were common with Bard; that is likely why <strong>conversations with Bard were shorter than conversations with ChatGPT (p &lt;0.001) or Bing (p&lt;0.001). </strong>It could be that Bard participants were primed by the prominence of Google as a search engine and tended to use Bard as a proxy for Google search.</p>
<figure><img alt="" height="563" loading="lazy" src="https://media.nngroup.com/media/editor/2023/11/08/ai-convos_convo-length.png" width="692"/>
<figcaption><em>Conversations with Bard were shorter than conversations with other bots. These differences were statistically significant. Many of the Bard conversations were one-prompt search queries.</em></figcaption>
</figure>
<p>A final word about the length of expanding conversations: they can be long or short, depending on how successful the user is in finding a satisfactory prompt that the bot can answer. They can also evolve in other kinds of conversations once the user finds the right way of formulating their query.</p>
<table>
<tbody>
<tr>
<th colspan="2">
<p><strong>Taxonomy of AI Conversations by Information Need</strong></p>
</th>
</tr>
<tr>
<th>
<p><strong>Narrow, Well-Defined Information Need</strong></p>
</th>
<th>
<p><strong>Broad, Undefined Information Need </strong></p>
</th>
</tr>
<tr>
<td>
<p>Funneling</p>
<p>Pinpointing</p>
<p>Exploring</p>
<p>Search queries</p>
</td>
<td>
<p>Exploring conversations: acquiring depth of knowledge</p>
<p>Chiseling conversations: acquiring breadth of knowledge</p>
</td>
</tr>
</tbody>
</table>
<h2><a id="tips-for-users" name="tips-for-users"></a>Tips for Using Text-Based Generative-AI Bots</h2>
<p>There is no ideal length for all conversations. If the user has a clear, well-defined information need, then a good, detailed, pinpointing prompt will get them what they need fast.</p>
<p>But if the user’s goal is broad and less well-defined, then a single exchange will likely not be enough. The user can use the bot’s responses to learn — either through breadth or depth.</p>
<ul>
<li>Specific information needs benefit from detailed, pinpointing prompts.</li>
<li>Adding phrasing such as <em>Ask me questions if you need additional information</em> at the end of the user’s prompts can get the bot to help articulate the different constraints that the user may be working with.</li>
<li>For factual queries, users may (for now) be better off using a search engine instead of generative AI.</li>
</ul>
<h2><a id="recommendations-for-designers" name="recommendations-for-designers"></a>Recommendations for Designing the UX of Generative AI</h2>
<p>The structure of the generative-AI conversations is teaching us about what designers can do to improve the overall experience of generative AI and allow users to efficiently address their information needs.</p>
<p>Bots should attempt to use the length and the structure of the user’s prompt, as well as the complexity of the answer to<strong> determine the conversation type early in the exchange and adjust behavior accordingly. </strong>That is because different conversation types address different information needs and the support provided by the bot needs to be tailored to each need.</p>
<p>Specifically:</p>
<ul>
<li><strong>Search queries</strong> (i.e., prompts that are short, often incomplete sentences) can indicate that users are inexperienced with AI. These conversations can be treated as funneling conversations; the user can be asked further questions so that the bot can provide a satisfactory response. Alternatively, the bot can also offer the user the option to access search results for the same question.</li>
<li><strong>When bots receive vague, underspecified prompts (as in funneling conversations), </strong>they should ask the user questions to <strong>help them narrow down the conversation topic</strong>. For example, for a prompt such as <em>best Mother’s Day gifts</em>, the bot can ask for specific information (e.g., age, hobbies, location) about the gift recipient. The bot can also offer example pinpointing prompts to help inexperienced users learn to use the AI.</li>
<li>In broad conversations (such as exploring or chiseling conversations) that require long or complex and nuanced responses, <strong>suggested followup prompts should help the user learn</strong>. While it may be difficult to establish what kind of intent the user has from a first prompt, bots could offer both depth-focused and breadth-focused suggested followup prompts.</li>
<li>In <strong>expanding conversations,</strong> which usually map onto situations when the bot was not able to provide an answer, the suggested followup prompts need to be slightly broader refinements that allow the user to find something useful, even if they will not precisely match their original need.</li>
</ul></section>

        

        

        
      </div></div>
  </body>
</html>
