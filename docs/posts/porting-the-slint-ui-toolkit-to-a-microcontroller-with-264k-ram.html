<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://slint-ui.com/blog/porting-slint-to-microcontrollers.html">Original</a>
    <h1>Porting the Slint UI Toolkit to a Microcontroller with 264K RAM</h1>
    
    <div id="readability-page-1" class="page"><div>
        



<section>

<figure>
        <img src="https://slint-ui.com/blog/porting-slint-to-microcontrollers/rp-pico_and_screen.jpg" alt="The Raspberry Pi Pico and the screen"/>
        <figcaption>The Raspberry Pi Pico and the screen (upside down)</figcaption>
  </figure>

<p>
  Our vision with <a href="https://slint-ui.com/">Slint</a> as a cross-platform native UI toolkit is to provide user interfaces for any device.
  Initially we focused on running on desktop-class machines and embedded devices that support OpenGL ES.
  A few months ago we started porting Slint to microcontrollers (MCUs), and this blog post describes how we achieved that.
</p>

<h3>Goal: Our Printer Demo on a Raspberry Pi Pico</h3>

<figure>
        <video autoplay="" loop="" muted="" playsinline="" src="/thisweek/2022-03-21/printerdemo_mcu_pico.mp4"></video>
        <figcaption>The printerdemo_mcu running on a Raspberry Pi Pico (RP2040 with 264K of RAM)</figcaption>
  </figure>


<p>We chose the <a href="https://www.raspberrypi.com/products/raspberry-pi-pico">Raspberry Pi Pico</a> as the first
board to support. It&#39;s equipped with Raspberry Pi&#39;s first self-made microcontroller, the <em>RP2040</em>,
a Cortex-M0 class processor, with <em>264KB of RAM</em> and 2M of flash. This board is open-source-friendly and it costs <em>less than 4â‚¬</em>.</p>

<p>
This hardware combination costs less than 20â‚¬ online, which provides a low barrier of entry
for enthusiasts and hobbyists.</p>

<p>Based on this video, it&#39;s safe to say that we succeeded. ðŸŽ‰</p>

<h3><code>#![no_std]</code></h3>

<p>We&#39;re working on what is called <em>bare metal</em>: There is no operating system between us
and the hardware. Our runtime is written entirely in <em>Rust</em>, which requires using the
 <a href="https://doc.rust-lang.org/reference/names/preludes.html#the-no_std-attribute"><code>#![no_std]</code></a>
 attribute to run on bare metal. This attribute
disables the Rust Standard Library which requires an operating system. Even if we tried to enable it, the Standard
Library is not available for the <code>thumbv6m-none-eabi</code> target, which the RP2040 uses.</p>

<p>The first step was to compile our core library for <code>thumbv6m-none-eabi</code>.
We needed to gate anything that used the Standard Library behind a <code>&#34;std&#34;</code> feature gate.
Thankfully, we&#39;re not using much of standard library, and we had already established the habit of using
<code>core::</code> instead of <code>std::</code> for types from the Rust Core Library. All types
that require memory allocation are in the alloc crate, so we had to introduce that in a few places.</p>

<p>Then we hit the problem that the architecture has neither atomic compare and swap instructions nor
a hardware floating point unit. This means that the Rust Core Library disables some features of the
atomic module, which are used by crates we depend on. So in addition to making sure that each of our
dependencies supports <code>#![no_std]</code>, we also needed to make some of them use the
<a href="https://lib.rs/crates/atomic-polyfill">atomic_polyfill</a> crate to work around the missing atomic functionality.
For the lack of hardware floating point support, we use the <a href="https://lib.rs/crates/libm">libm</a> crate
(via <a href="https://lib.rs/crates/num-traits">num-traits</a>), which provides software floating point support for
the operations that we use.
</p>

<h4>Hardware Abstraction</h4>

<p>So far we&#39;ve dealt with general issues that apply to all constrained embedded environments. The RP2040 microcontroller
  that we&#39;re starting with is placed on the Pico board, but there are other boards available as well with the same chip.
  Some are equipped with additional peripherals such as LEDs or more flash storage. An operating system typically provides
  drivers for the boards and peripherals, and provides an abstraction over those combinations to applications. We do not
  have an operating system to do that for us, but we do not have to start from scratch either: Fortunately the Rust
  ecosystem provides crates that make it relatively easy to get started in these bare metal environments. We&#39;re using crates
  from the RP2040 <a href="https://github.com/rp-rs/rp-hal">rp2040-hal</a> project, as well as helper crates from the
  <a href="https://github.com/rust-embedded">Rust Embedded</a> project.
</p>

<h3>Framebuffer?</h3>

<p>264KB of RAM is not much memory. Typically, when a screen is connected directly
to the memory, a framebuffer is used to store one full screen in memory. We would
render into the framebuffer and blend the UI before passing it on to the display. Actually, we&#39;d allocate two of them so
that we can render into one while the other one is being displayed.
But with 16-bit colors (two bytes per pixel), that&#39;s 240 Ã— 280 Ã— 2 = 134.4kB per framebuffer.
That would be half of our available memory gone, or the whole of it if we want double-buffering which needs two framebuffers,
leaving us with very little space for code implementing the actual UI.</p>

<p>We solved this with a different approach: The display has its own on-chip memory, which is big
  enough to represent the screen. We can write into that memory by sending commands over the SPI
  bus, that contain the address and the color. So, instead of rendering the whole screen into our own framebuffer,
  we&#39;ve designed our software renderer to render a smaller part in a smaller buffer. We decided to render
  one line at a time, so we allocate two buffers, each the size of one line only. We can render one line into
  one buffer on the CPU and then use <a href="https://en.wikipedia.org/wiki/Direct_memory_access">DMA</a>
  to upload the pixels to the display. Indeed, the RP2040 has a few DMA units, capable of reading
  main memory and transmitting it over the SPI bus to peripherals, like the screen. This happens completely
  without any CPU involvement. We can instruct the CPU to render the next line while the first is still being
  sent to the screen.</p>

<p>Unfortunately, we do not support DMA yet. This is
challenging, because the DMA support for the RP2040 in Rust is still <a href="https://github.com/rp-rs/rp-hal/pull/209">work in progress</a>,
and support requires changes deep down in the driver. Currently, the driver we use for the screen only supports passing an iterator of pixels to draw. But
if we want to support DMA, we need to give it a specific <code>&amp;&#39;static</code> buffer. Since the screen driver owns the SPI pins,
we would need to fork it, or at least re-implement the part that sends control command. This is totally doable, but not something
we wanted to spend time on at this point.</p>

<p><u>Update:</u> <a href="https://github.com/slint-ui/slint/pull/1344">DMA support has now been implemented</a>.
The screen updates are now much faster, see this <a href="https://www.youtube.com/watch?v=dkBwNocItGs">updated video</a></p>

<h3>Line By Line Software Rendering</h3>

<p>Microcontrollers typically don&#39;t come with a GPU that supports OpenGL. We had to create a software renderer
  that runs entirely on the CPU, dividing the rendering into the following steps:
  </p><ol>
   <li>Visit the scene and create one or more primitive rendering commands for each item. For example, we have
     a primitive command to fill a rectangle with a color, or to blend a portion of an image to a certain location on
     the screen.</li>
    <li>Sort the commands by their <em>y</em> position.</li>
    <li>For each line, collect the commands that affect this line. This is done by merging the commands from the previous
      line that spans into the new line with the new commands in the <em>y</em>-sorted list of commands computed in the
      previous step.
    </li>
    <li>Draw each command into the buffer for the current line back to front.</li>
  </ol>

<p>On the Pico board we don&#39;t have a file system from which to load images or fonts. Therefore, the Slint compiler loads and pre-renders
  images and glyphs at compile time, and embeds them raw into the program binary.
</p>

<h3>Partial Rendering</h3>

<p>Here&#39;s a breakdown of the cumulative times the individual steps take to render the entire scene of the printer demo:</p>
  <table>
    <thead>
      <tr><td>Step</td><td>Duration</td></tr>
    </thead>
    <tbody><tr>
      <td>Visit scene, create rendering commands &amp; sort by <em>y</em> position</td>
      <td>55ms</td>
    </tr>
    <tr>
      <td>Collect commands for current line</td>
      <td>7ms</td>
    </tr>
    <tr>
      <td>Draw commands for current line into buffer</td>
      <td>59ms</td>
    </tr>
    <tr>
      <td>Send pixels to the screen over SPI</td>
      <td>111ms</td>
    </tr>
  </tbody></table>
<p>The above table shows that most of the time is spent in uploading pixels over the SPI bus to the screen.
  Consequently, the fewer pixels we upload, the faster the screen updates. When an animation runs in one part of the screen, we do
  not want to re-render other parts of the screen that remain unchanged. Our property
  system allows us to find out, on a very detailed level, which items in the scene are changing. We determine their
  location on the screen and collect them as dirty regions. When drawing a new frame,
  we can then limit our efforts to the dirty regions and send only newly rendered pixels to the screen.
</p>


<h3>Panic Handler</h3>

<figure>
  <img src="https://slint-ui.com/thisweek/2022-02-21/rp-pico-panic-handler.jpg"/>
        <figcaption>Our panic handler prints the message to the screen</figcaption>
</figure>

<p>When Rust code panics, the default behavior is to stop the program with a message printed to the console explaining the reason.
With <code>no_std</code> there is no console and you need to manually set a panic handler function. Custom panic handlers are available on crates.io,
which can send the panic message over UART or <a href="https://defmt.ferrous-systems.com/">defmt</a> to your development machine. Since
we&#39;re connected to a screen, we thought we might use it and print the panic message there.</p>

<p>Our panic handler <a href="https://docs.rs/cortex-m/0.7.4/cortex_m/peripheral/struct.Peripherals.html#method.steal">steals</a>
the <code>Peripherals</code> object, and resets the screen state, before using a custom implementation of the
<a href="https://doc.rust-lang.org/stable/core/fmt/trait.Write.html"><code>Write</code> trait</a>
to display the message on screen. Then we spin an infinite loop, until the user resets the device.</p>

<p>We used our Slint blue color as a background. Any resemblance with crash screens that you may have seen in other operating systems
   is purely coincidental. ðŸ¤£</p>

<h3>Board Support and Customization</h3>

<p>
  We strive to keep our examples, as well as your application code, as simple as possible, regardless whether
  the target platform is a desktop system, a web browser, or now an MCU. This requires abstracting over
  various differences such as the application entry point (<code>fn main()</code>), how the build system is invoked,
  or for example combinations of supported peripherals installed on the board the MCU runs on.
</p>

<p>
 For the boards that we support directly, we collect as much of the board specific code in our MCU crate. This is usually boilerplate code to initialize pins, power on
 peripherals, or screen drivers, which would otherwise be duplicated into each of our examples. However we recognize the need for customization.
 You might want to use Slint with a board that we&#39;re not familiar with. We want to provide a low-level API with traits, so that you
 can combine your own low-level device specific code with Slint. With these traits you can then provide the buffers for line-by-line pixel
 rendering, report the system time, and other hardware capabilities that we need.
</p>

<h3>Run it yourself</h3>

<p>If you have a Pico with the screen that we&#39;re using, check out our
   <a href="https://github.com/slint-ui/slint/tree/master/examples/mcu-board-support">README</a>
for instructions on how to run the code yourself.</p>

<h3>What&#39;s next</h3>

<p>At this point, our printer demo works on the Raspberry Pi Pico. This is proof that Slint runs on low-end devices. Next, we will port to
  another board, polish our APIs, and release a version of Slint that can be used directly from crates.io with MCUs.
</p>

</section>

    </div></div>
  </body>
</html>
