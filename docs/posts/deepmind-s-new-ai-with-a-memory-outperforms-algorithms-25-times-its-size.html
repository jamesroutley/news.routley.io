<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://singularityhub.com/2021/12/20/biggers-not-always-better-deepminds-new-language-ai-is-small-but-mighty/">Original</a>
    <h1>DeepMind’s new AI with a memory outperforms algorithms 25 times its size</h1>
    
    <div id="readability-page-1" class="page"><div>
                <p><span lang="en-US">Bigger is better—</span><span lang="en-US">or </span><span lang="en-US">at least that’s been the attitude of those designing AI language models in recent years. But now DeepMind is questioning th</span><span lang="en-US">is</span><span lang="en-US"> rationale, and says </span><span lang="en-US">giving an AI a memory</span><span lang="en-US"> can help it compete with models 25 times it</span><span lang="en-US">s</span><span lang="en-US"> size.</span></p>
<p><span lang="en-GB">When OpenAI <a href="https://singularityhub.com/2020/06/18/openais-new-text-generator-writes-even-more-like-a-human/">released it</a><a href="https://singularityhub.com/2020/06/18/openais-new-text-generator-writes-even-more-like-a-human/">s GPT-3</a> model last June, it rewrote the rulebook for language AIs. The lab’s researchers showed that simply scaling up the size of a neural network and the data it was trained on could significantly boost performance on a wide variety of language tasks.</span></p>
<p><span lang="en-GB">Since then, a host of other tech companies have jumped on the bandwagon, developing their own <a href="https://singularityhub.com/2021/10/13/microsofts-massive-new-language-ai-is-triple-the-size-of-openais-gpt-3/">large language models</a> and achieving similar boosts in performance. But despite the successes, concerns have been raised about the approach, </span><a href="https://www.technologyreview.com/2020/12/04/1013294/google-ai-ethics-research-paper-forced-out-timnit-gebru/"><span lang="en-GB">most notably by former Google researcher Timnit Gebru</span></a><span lang="en-GB">.</span></p>
<p><span lang="en-GB">In the paper that led to her being forced out of the company, Gebru and colleagues highlighted that the sheer size of these models and their datasets makes them even more inscrutable than your average neural network, which are already </span><span lang="en-GB">known</span><span lang="en-GB"> for being <a href="https://singularityhub.com/2021/10/25/not-so-mysterious-after-all-researchers-show-how-to-crack-ais-black-box/">black boxes</a>. This is likely to make detect</span><span lang="en-GB">ing</span><span lang="en-GB"> and mitigating bias in th</span><span lang="en-GB">e</span><span lang="en-GB">s</span><span lang="en-GB">e</span><span lang="en-GB"> models even harder.</span></p>
<p><span lang="en-GB">Perhaps an even bigger problem they identify is the fact that relying on ever more computing power to make progress in AI means that the cutting-edge of the field lies out of reach for all but the most well-resourced commercial labs. The seductively simple proposition that </span><span lang="en-GB">just</span><span lang="en-GB"> scaling models up can lead to continual progress also means that fewer resources go into looking for <a href="https://singularityhub.com/2021/01/31/new-liquid-ai-learns-as-it-experiences-the-world-in-real-time/">promising alternatives</a>.</span></p>
<p><span lang="en-GB">But in new research, DeepMind has shown that ther</span><span lang="en-GB">e</span><span lang="en-GB"> might be another way. In </span><span lang="en-GB"><a href="https://deepmind.com/blog/article/language-modelling-at-scale">a series of papers</a>,</span><span lang="en-GB"> the team </span><span lang="en-GB">explains how they</span><span lang="en-GB"> first built their own large language model, called Gopher, which is more than 60 percent larger than GPT-3. Then they showed that a far smaller model imbued with the ability to look up information in a database could go toe-to-toe with Gopher and other large language models.</span></p>
<p><span lang="en-GB">The researchers have dubbed the smaller model RETRO, which stands for </span><span lang="en-GB">Retrieval-Enhanced Transformer. Transformers are the specific type of neural network used in most large language models; </span><span lang="en-GB">they</span><span lang="en-GB"> train on large amounts of data to predict how to reply to questions or prompts from a human user.</span></p>
<p><span lang="en-GB">RETRO also relies on a transformer, but it has been given a crucial augmen</span><span lang="en-GB">ta</span><span lang="en-GB">tion. As well </span><span lang="en-GB">as</span><span lang="en-GB"> making predictions about what text should come next based on its training, </span><span lang="en-GB">the model</span><span lang="en-GB"> can search through a database of two trillion chunks of text to look for passages using similar language that could improve its predictions.</span></p>
<p><span lang="en-GB">The researchers found that a RETRO model that had just 7 billion parameters could outperform the 178 billion parameter <a href="https://www.ai21.com/blog/announcing-ai21-studio-and-jurassic-1">Jur</a><a href="https://www.ai21.com/blog/announcing-ai21-studio-and-jurassic-1">a</a></span><a href="https://www.ai21.com/blog/announcing-ai21-studio-and-jurassic-1"><span lang="en-GB">s</span><span lang="en-GB">sic-1 transformer</span></a><span lang="en-GB"> made by AI21 Labs on a wide variety of language tasks, and even did better than the 280 billion-parameter Gopher model on most.</span></p>
<p><span lang="en-GB">As well as cutting down the amount of training required, the researchers point out that the ability to see which chunks of text the model consulted when making predictions could make it easier to explain how it reached its conclusions. The reliance on a database also opens up opportunities for updating the model’s knowledge without retraining it, or even modifying the corpus to elim</span><span lang="en-GB">i</span><span lang="en-GB">nate sources of bias.</span></p>
<p><span lang="en-GB">Interestingly, the researchers showed that they can take an existing transformer and retro-fit it to work with a database by retraining a small section of its network. These models easily outperformed the original, and even got close to the performance of RETRO models trained from scratch.</span></p>
<p><span lang="en-GB">It’s important to remember, though, that RETRO is </span><span lang="en-GB">still </span><span lang="en-GB">a large model by most standards; </span><span lang="en-GB">it’s</span><span lang="en-GB"> nearly five times larger than GPT-3’s predecessor, <a href="https://singularityhub.com/2019/03/07/openais-eerily-realistic-new-text-generator-writes-like-a-human/">GPT-2</a>. And it seems likely that people will want to see what’s possible with an even bigger RETRO model with a larger database.</span></p>
<p><span lang="en-GB">DeepMind certainly thinks further scaling is a promising avenue. In the Gopher paper they found that while increasing model size didn’t significantly improve performance in </span><span lang="en-GB">logical reasoning and common-sense tasks, in things like reading comprehension and fact-checking the benefits were clear.</span></p>
<p><span lang="en-GB">Perhaps the most important lesson from RETRO is that scaling models isn’t the only—or even the fastest—route to better performance. While size does matter, innovation in AI models </span><span lang="en-GB">is</span><span lang="en-GB"> also crucial.</span></p>
<p><em>Image Credit: <a href="https://deepmind.com/blog/article/language-modelling-at-scale">DeepMind</a></em></p>
    </div></div>
  </body>
</html>
