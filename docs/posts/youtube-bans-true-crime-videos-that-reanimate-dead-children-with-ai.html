<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://gizmodo.com/youtube-bans-ai-reanimated-dead-kids-true-crime-videos-1851150159">Original</a>
    <h1>YouTube Bans True Crime Videos That Reanimate Dead Children with AI</h1>
    
    <div id="readability-page-1" class="page"><div><figure data-id="a84650f5170f4eac8f72dda2efa88937" data-recommend-id="image://a84650f5170f4eac8f72dda2efa88937" data-format="jpg" data-width="905" data-height="509" data-lightbox="true" data-alt="A finger hitting play on a keyboard, superimposed over a YouTube video" data-recommended="true" data-hide="false" contenteditable="false" draggable="false"><div contenteditable="false" data-alt="A finger hitting play on a keyboard, superimposed over a YouTube video" data-link-reference="" data-link-target="" data-syndicationrights="true" data-imagerights="shutterstock" data-hide="false" data-hidecredit="false"><p><span><div><picture><source media="(max-width: 37.31em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_645/a84650f5170f4eac8f72dda2efa88937.jpg"/><source media="(min-width: 37.37em)" type="image/jpeg" srcset="https://i.kinja-img.com/image/upload/c_fit,q_60,w_1315/a84650f5170f4eac8f72dda2efa88937.jpg"/><img alt="A finger hitting play on a keyboard, superimposed over a YouTube video" data-chomp-id="a84650f5170f4eac8f72dda2efa88937" data-format="jpg" data-alt="A finger hitting play on a keyboard, superimposed over a YouTube video" data-anim-src="" src="https://i.kinja-img.com/image/upload/c_fit,q_60,w_645/a84650f5170f4eac8f72dda2efa88937.jpg"/></picture></div></span></p><p><figcaption>Photo<!-- -->: <!-- -->Dilok Klaisataporn / Shutterstock.com<!-- --> (<!-- -->Shutterstock<!-- -->)</figcaption></p></div><span data-id="a84650f5170f4eac8f72dda2efa88937" data-recommend-id="image://a84650f5170f4eac8f72dda2efa88937" data-format="jpg" data-width="905" data-height="509" data-lightbox="true" data-alt="A finger hitting play on a keyboard, superimposed over a YouTube video" data-recommended="true" data-hide="false"></span></figure><div><p>When <span><a data-ga="[[&#34;Embedded Url&#34;,&#34;Internal link&#34;,&#34;https://gizmodo.com/travel-back-to-1990-with-the-original-world-wide-web-br-1832730788&#34;,{&#34;metric25&#34;:1}]]" href="https://gizmodo.com/travel-back-to-1990-with-the-original-world-wide-web-br-1832730788">Tim Berners-Lee invented the World Wide Web back in 1989</a></span>, he probably didn’t imagine that his new system would be the repository for all of humanity’s worst impulses, but here we are. The latest example from the internet horror show comes from YouTube, where the company was forced to update its policies to say that no, you’re not allowed to make AI videos of dead kids for your true crime content.<br/></p><div><div><div><div data-playlist="192859,190985,191427" data-current="192859"><div><div><div data-video-id="192859" data-monetizable="true" data-position="sidebar" data-video-title="Twitter Verification is a Hot Mess" data-video-blog-id="4" data-video-network="gizmodo" data-video-duration="163"><div><p>Twitter Verification is a Hot Mess</p></div><video disablepictureinpicture="" muted="" playsinline="" width="100%" height="100%" crossorigin="anonymous" preload="none"><source data-src="https://vid.kinja.com/prod/192859/192859_240p.mp4" label="240p" type="video/mp4"/><source data-src="https://vid.kinja.com/prod/192859/192859_480p.mp4" label="480p" type="video/mp4"/><source data-src="https://vid.kinja.com/prod/192859/192859_720p.mp4" label="720p" type="video/mp4"/><source data-src="https://vid.kinja.com/prod/192859/192859_1080p.mp4" label="1080p" type="video/mp4"/><track kind="captions" label="English" src="https://kinja.com/api/videoupload/caption/18322.vtt" srclang="en"/></video></div></div></div></div></div></div></div><p>YouTube described the change in a <span><a data-ga="[[&#34;Embedded Url&#34;,&#34;External link&#34;,&#34;https://support.google.com/youtube/answer/10008196&#34;,{&#34;metric25&#34;:1}]]" href="https://support.google.com/youtube/answer/10008196" target="_blank" rel="noopener noreferrer">post</a></span> on its Help Center. “On January 16, we’ll begin striking content that realistically simulates deceased minors or victims of deadly or well-documented major violent events describing their death or violence experienced,” the company wrote. </p><p>The update comes in response to a disturbing genre of videos that generated millions of views on social media with the simulated voices of real child murder victims describing their own gruesome deaths, as reported by <span><a data-ga="[[&#34;Embedded Url&#34;,&#34;External link&#34;,&#34;https://www.theverge.com/2024/1/8/24030107/youtube-ai-deepfakes-true-crime-victims-minors&#34;,{&#34;metric25&#34;:1}]]" href="https://www.theverge.com/2024/1/8/24030107/youtube-ai-deepfakes-true-crime-victims-minors" target="_blank" rel="noopener noreferrer">the Verge</a></span> Monday. </p><p>“Grandma locked me in an oven at 230 degrees when I was just 21 months old,” an animated baby said in one viral TikTok video, before identifying itself as Rody Marie Floyd, a real murder victim. “Please follow me so more people know my true story.” Similar videos sparked <span><a data-ga="[[&#34;Embedded Url&#34;,&#34;External link&#34;,&#34;https://www.rollingstone.com/culture/culture-features/true-crime-tiktok-ai-deepfake-victims-children-1234743895/&#34;,{&#34;metric25&#34;:1}]]" href="https://www.rollingstone.com/culture/culture-features/true-crime-tiktok-ai-deepfake-victims-children-1234743895/" target="_blank" rel="noopener noreferrer">widespread attention</a></span> on YouTube. <br/></p><p>TikTok already has policies that address this class of internet obscenity. The platform requires labels on AI-created videos and prohibits deepfakes  of people under 18 or any adult who isn’t a public figure. <br/></p><p>The videos aren’t just disturbing for viewers, they’re painful for survivors. Denise Fergus, whose son James Bulger was abducted and killed in 1993, called the AI videos featuring her child “disgusting” in an interview with the <span><a data-ga="[[&#34;Embedded Url&#34;,&#34;External link&#34;,&#34;https://www.mirror.co.uk/news/uk-news/james-bulgers-mums-fury-sick-30580334&#34;,{&#34;metric25&#34;:1}]]" href="https://www.mirror.co.uk/news/uk-news/james-bulgers-mums-fury-sick-30580334" target="_blank" rel="noopener noreferrer">Mirror</a></span>. “It is bringing a dead child back to life,” Fergus said. “It is beyond sick.”</p><p>Time and again we’ve seen there’s nothing so depraved that someone won’t try to monetize it online. You could blame the people making this creep show content, but it’s also a logical consequence of a system that incentivizes creators to hijack our attention.</p></div></div></div>
  </body>
</html>
