<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://docs.z.ai/guides/llm/glm-4.5">Original</a>
    <h1>GLM 4.5 with Claude Code</h1>
    
    <div id="readability-page-1" class="page"><div data-page-title="GLM-4.5" data-page-href="/guides/llm/glm-4.5"><h2 id="overview"><span><svg style="-webkit-mask-image:url(https://d3gk2c5xim1je2.cloudfront.net/v6.6.0/solid/rectangle-list.svg);-webkit-mask-repeat:no-repeat;-webkit-mask-position:center;mask-image:url(https://d3gk2c5xim1je2.cloudfront.net/v6.6.0/solid/rectangle-list.svg);mask-repeat:no-repeat;mask-position:center;background-color:#ffffff;width:36px;height:36px;display:inline-block;vertical-align:middle"></svg>   Overview</span></h2>

<p><span data-as="p">GLM-4.5 and GLM-4.5-Air are our latest flagship models, purpose-built as foundational models for agent-oriented applications. Both leverage a Mixture-of-Experts (MoE) architecture. GLM-4.5 has a total parameter count of 355B with 32B active parameters per forward pass, while GLM-4.5-Air adopts a more streamlined design with 106B total parameters and 12B active parameters.</span>
<span data-as="p">Both models share a similar training pipeline: an initial pretraining phase on 15 trillion tokens of general-domain data, followed by targeted fine-tuning on datasets covering code, reasoning, and agent-specific tasks. The context length has been extended to 128k tokens, and reinforcement learning was applied to further enhance reasoning, coding, and agent performance.</span>
<span data-as="p">GLM-4.5 and GLM-4.5-Air are optimized for tool invocation, web browsing, software engineering, and front-end development. They can be integrated into code-centric agents such as Claude Code and Roo Code, and also support arbitrary agent applications through tool invocation APIs.</span>
<span data-as="p">Both models support hybrid reasoning modes, offering two execution modes: Thinking Mode for complex reasoning and tool usage, and Non-Thinking Mode for instant responses. These modes can be toggled via the <code>thinking.type</code>parameter (with <code>enabled</code> and <code>disabled</code> settings), and dynamic thinking is enabled by default.</span></p>
<h2 id="glm-4-5-serials"><span><svg style="-webkit-mask-image:url(https://d3gk2c5xim1je2.cloudfront.net/v6.6.0/solid/list-ol.svg);-webkit-mask-repeat:no-repeat;-webkit-mask-position:center;mask-image:url(https://d3gk2c5xim1je2.cloudfront.net/v6.6.0/solid/list-ol.svg);mask-repeat:no-repeat;mask-position:center;background-color:#ffffff;width:36px;height:36px;display:inline-block;vertical-align:middle"></svg>   GLM-4.5 Serials</span></h2>

<h2 id="capability"><span><svg style="-webkit-mask-image:url(https://d3gk2c5xim1je2.cloudfront.net/v6.6.0/solid/table-cells.svg);-webkit-mask-repeat:no-repeat;-webkit-mask-position:center;mask-image:url(https://d3gk2c5xim1je2.cloudfront.net/v6.6.0/solid/table-cells.svg);mask-repeat:no-repeat;mask-position:center;background-color:#ffffff;width:36px;height:36px;display:inline-block;vertical-align:middle"></svg>   Capability</span></h2>

<h2 id="introducting-glm-4-5"><span><svg style="-webkit-mask-image:url(https://d3gk2c5xim1je2.cloudfront.net/v6.6.0/solid/arrow-down-from-line.svg);-webkit-mask-repeat:no-repeat;-webkit-mask-position:center;mask-image:url(https://d3gk2c5xim1je2.cloudfront.net/v6.6.0/solid/arrow-down-from-line.svg);mask-repeat:no-repeat;mask-position:center;background-color:#ffffff;width:36px;height:36px;display:inline-block;vertical-align:middle"></svg>   Introducting GLM-4.5</span></h2>
<h3 id="overview-2"><span>Overview</span></h3>
<p><span data-as="p">The first-principle measure of AGI lies in integrating more general intelligence capabilities without compromising existing functions. GLM-4.5 represents our first complete realization of this concept. It combines advanced reasoning, coding, and agent capabilities within a single model, achieving a significant technological breakthrough by natively fusing reasoning, coding, and agent abilities to meet the complex demands of agent-based applications.</span>
<span data-as="p">To comprehensively evaluate the model’s general intelligence, we selected 12 of the most representative benchmark suites, including MMLU Pro, AIME24, MATH 500, SciCode, GPQA, HLE, LiveCodeBench, SWE-Bench, Terminal-bench, TAU-Bench, BFCL v3, and BrowseComp. Based on the aggregated average scores, GLM-4.5 ranks second globally among all models, first among domestic models, and first among open-source models.</span>
<span aria-owns="rmiz-modal-" data-rmiz=""><span data-rmiz-content="not-found"><picture><img data-path="resource/benchmark-0.png" src="https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark-0.png?fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=d565bc82527cd77841a018a7e9fe2df0" alt="Description" width="1280" height="519" decoding="async" sizes="(max-width: 840px) 100vw, (max-width: 1100px) 50vw, 33vw" srcset="https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark-0.png?w=280&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=7365968bdde0823d47d300cc47513784 280w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark-0.png?w=560&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=148a0bf8b7521d83038120f905dd6405 560w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark-0.png?w=840&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=cdd09f501f000d35951a58d40bd4df64 840w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark-0.png?w=1100&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=13c5518e6b936b26576417406e13b126 1100w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark-0.png?w=1650&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=e0fac97416d648104e20863f6df4e7b3 1650w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark-0.png?w=2500&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=fbf4e15b30ce23327b31afadddfb3efa 2500w" data-optimize="true"/></picture></span></span>
<span aria-owns="rmiz-modal-" data-rmiz=""><span data-rmiz-content="not-found"><picture><img data-path="resource/benchmark-1.png" src="https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark-1.png?fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=a296f62a9517735d7af5b0580094065b" alt="Description" width="1280" height="338" decoding="async" sizes="(max-width: 840px) 100vw, (max-width: 1100px) 50vw, 33vw" srcset="https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark-1.png?w=280&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=7081c526e679395aa8dee0e9913da019 280w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark-1.png?w=560&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=6cbaf319c9f8da2ed44676b778b2f5ed 560w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark-1.png?w=840&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=cae5d25fb5c262fd222636e46da12130 840w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark-1.png?w=1100&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=272ffdfd95d6f3c2c12f0bd146c7a3a9 1100w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark-1.png?w=1650&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=ed785a2a6b7c309d9ec2554144d92201 1650w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark-1.png?w=2500&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=c20fdadadb52a4a60fa0fe9e6fbcdfaf 2500w" data-optimize="true"/></picture></span></span></p><h3 id="higher-parameter-efficiency"><span><strong>Higher Parameter Efficiency</strong></span></h3>
<p><span data-as="p">GLM-4.5 has half the number of parameters of DeepSeek-R1 and one-third that of Kimi-K2, yet it outperforms them on multiple standard benchmark tests. This is attributed to the higher parameter efficiency of GLM architecture. Notably, GLM-4.5-Air, with 106 billion total parameters and 12 billion active parameters, achieves a significant breakthrough—surpassing models such as Gemini 2.5 Flash, Qwen3-235B, and Claude 4 Opus on reasoning benchmarks like Artificial Analysis, ranking among the top three domestic models in performance.</span>
<span data-as="p">On charts such as SWE-Bench Verified, the GLM-4.5 series lies on the Pareto frontier for performance-to-parameter ratio, demonstrating that at the same scale, the GLM-4.5 series delivers optimal performance.</span>
<span aria-owns="rmiz-modal-" data-rmiz=""><span data-rmiz-content="not-found"><picture><img data-path="resource/benchmark-2.png" src="https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark-2.png?fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=0ab97aeb6f7d4cef4e2b33fcb76231b4" alt="Description" width="1280" height="777" decoding="async" sizes="(max-width: 840px) 100vw, (max-width: 1100px) 50vw, 33vw" srcset="https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark-2.png?w=280&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=e5462bd8ceb960fc00833ad31277cc71 280w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark-2.png?w=560&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=affcf850f56f6592379fb9577bd59d00 560w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark-2.png?w=840&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=ba573ed2e9c7995afda5ff2b4fa114f3 840w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark-2.png?w=1100&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=2cb08db672a6d9695d1cbf94f63cb5aa 1100w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark-2.png?w=1650&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=a0b96f5aa3489394465c341141076bcc 1650w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark-2.png?w=2500&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=e2114df239206110bf9cb0a6d4270023 2500w" data-optimize="true"/></picture></span></span></p><h3 id="low-cost%2C-high-speed"><span><strong>Low Cost, High Speed</strong></span></h3>
<p><span data-as="p">Beyond performance optimization, the GLM-4.5 series also achieves breakthroughs in cost and efficiency, resulting in pricing far lower than mainstream models: API call costs are as low as $0.2 per million input tokens and $1.1 per million output tokens.</span>
<span data-as="p">At the same time, the high-speed version demonstrates a generation speed exceeding 100 tokens per second in real-world tests, supporting low-latency and high-concurrency deployment scenarios—balancing cost-effectiveness with user interaction experience.</span>
<span aria-owns="rmiz-modal-" data-rmiz=""><span data-rmiz-content="not-found"><picture><img data-path="resource/benchmark2.png" src="https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark2.png?fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=d39c7575956dbe42a1c437e3cf14279f" alt="Description" width="990" height="305" decoding="async" sizes="(max-width: 840px) 100vw, (max-width: 1100px) 50vw, 33vw" srcset="https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark2.png?w=280&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=36ded49da55eee897a3c75da1cf8a462 280w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark2.png?w=560&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=a66679e1487639408b67b6e09c3c3567 560w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark2.png?w=840&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=1bcb41a8f67aad17e947d332bc4fb851 840w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark2.png?w=1100&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=91584a7f2d33cadd159b991cf0bec447 1100w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark2.png?w=1650&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=aabc285869f2becb3cb49e474fc72837 1650w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/benchmark2.png?w=2500&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=92553133a8200bd6a6adf57ce447e250 2500w" data-optimize="true"/></picture></span></span></p><h3 id="real-world-evaluation"><span><strong>Real-World Evaluation</strong></span></h3>
<p><span data-as="p">Real-world performance matters more than leaderboard rankings. To evaluate GLM-4.5’s effectiveness in practical Agent Coding scenarios, we integrated it into Claude Code and benchmarked it against Claude 4 Sonnet, Kimi-K2, and Qwen3-Coder.</span>
<span data-as="p">The evaluation consisted of 52 programming and development tasks spanning six major domains, executed in isolated container environments with multi-turn interaction tests.</span>
<span data-as="p">As shown in the results (below), GLM-4.5 demonstrates a strong competitive advantage over other open-source models, particularly in tool invocation reliability and task completion rate. While there remains room for improvement compared to Claude 4 Sonnet, GLM-4.5 delivers a largely comparable experience in most scenarios.</span>
<span data-as="p">To ensure transparency, we have released all <a href="https://huggingface.co/datasets/zai-org/CC-Bench-trajectories" target="_blank" rel="noreferrer">52 test problems along with full agent trajectories</a> for industry validation and reproducibility.</span>
<span aria-owns="rmiz-modal-" data-rmiz=""><span data-rmiz-content="not-found"><picture><img data-path="resource/expr1.jpeg" src="https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/expr1.jpeg?fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=f8b051792b065926cf99bed4648197e0" alt="Description" width="1280" height="564" decoding="async" sizes="(max-width: 840px) 100vw, (max-width: 1100px) 50vw, 33vw" srcset="https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/expr1.jpeg?w=280&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=26e0bf74011f877a3b7fa71a75236a13 280w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/expr1.jpeg?w=560&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=793e94d145f933d9684b39a145ca814f 560w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/expr1.jpeg?w=840&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=451457ec301347d9f1a6dc48dbf51032 840w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/expr1.jpeg?w=1100&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=b27b4502c1a38d9745d07c3052dbeb6c 1100w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/expr1.jpeg?w=1650&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=776abd81fff1c5f0bf70ad16f540eb34 1650w, https://mintcdn.com/zhipu-32152247/fQm1SxNtD2jBDQ3i/resource/expr1.jpeg?w=2500&amp;fit=max&amp;auto=format&amp;n=fQm1SxNtD2jBDQ3i&amp;q=85&amp;s=32403d412a1c80d552ce0fe2dbd96fad 2500w" data-optimize="true"/></picture></span></span></p><h2 id="usage"><span><svg style="-webkit-mask-image:url(https://d3gk2c5xim1je2.cloudfront.net/v6.6.0/solid/list.svg);-webkit-mask-repeat:no-repeat;-webkit-mask-position:center;mask-image:url(https://d3gk2c5xim1je2.cloudfront.net/v6.6.0/solid/list.svg);mask-repeat:no-repeat;mask-position:center;background-color:#ffffff;width:36px;height:36px;display:inline-block;vertical-align:middle"></svg>   Usage</span></h2>
<div id="web-development"><ul data-component-part="tabs-list"><li id="web-development"></li><li id="ai-assistant"></li><li id="smart-office"></li><li id="intelligent-question-answering"></li><li id="complex-text-translation"></li><li id="content-creation"></li><li id="virtual-characters"></li></ul><div data-component-part="tab-content"><p><span data-as="p"><strong>Core Capability:</strong> <u>Coding Skills</u> → Intelligent code generation | Real-time code completion | Automated bug fixing</span></p><ul>
<li>Supports major languages including Python, JavaScript, and Java.</li>
<li>Generates well-structured, scalable, high-quality code based on natural language instructions.</li>
<li>Focuses on real-world development needs, avoiding templated or generic outputs.</li>
</ul><p><span data-as="p"><strong>Use Case:</strong> Complete refactoring-level tasks within 1 hour; generate full product prototypes in 5 minutes.</span></p><video src="https://cdn.bigmodel.cn/agent-demos/lark/113123.mov" controls=""></video></div></div>
<h2 id="resources"><span><svg style="-webkit-mask-image:url(https://d3gk2c5xim1je2.cloudfront.net/v6.6.0/solid/bars-sort.svg);-webkit-mask-repeat:no-repeat;-webkit-mask-position:center;mask-image:url(https://d3gk2c5xim1je2.cloudfront.net/v6.6.0/solid/bars-sort.svg);mask-repeat:no-repeat;mask-position:center;background-color:#ffffff;width:36px;height:36px;display:inline-block;vertical-align:middle"></svg>   Resources</span></h2>
<ul>
<li><a href="https://docs.z.ai/api-reference/llm/chat-completion">API Documentation</a>: Learn how to call the API.</li>
</ul>
<h2 id="quick-start"><span><svg style="-webkit-mask-image:url(https://d3gk2c5xim1je2.cloudfront.net/v6.6.0/solid/rectangle-code.svg);-webkit-mask-repeat:no-repeat;-webkit-mask-position:center;mask-image:url(https://d3gk2c5xim1je2.cloudfront.net/v6.6.0/solid/rectangle-code.svg);mask-repeat:no-repeat;mask-position:center;background-color:#ffffff;width:36px;height:36px;display:inline-block;vertical-align:middle"></svg>    Quick Start</span></h2>
<h3 id="thinking-mode"><span>Thinking Mode</span></h3>
<p><span data-as="p">GLM-4.5 offers a “Deep Thinking Mode” that users can enable or disable by setting the <code>thinking.type</code> parameter. This parameter supports two values: <code>enabled</code> (enabled) and <code>disabled</code> (disabled). By default, dynamic thinking is enabled.</span></p><ul>
<li><strong>Simple Tasks (No Thinking Required):</strong> For straightforward requests that do not require complex reasoning (e.g., fact retrieval or classification), thinking is unnecessary. Examples include:<!-- -->
<ul>
<li>When was Z.AI founded?</li>
<li>Translate the sentence “I love you” into Chinese.</li>
</ul>
</li>
<li><strong>Moderate Tasks (Default/Some Thinking Required):</strong> Many common requests require stepwise processing or deeper understanding. The GLM-4.5 series can flexibly apply thinking capabilities to handle tasks such as:<!-- -->
<ul>
<li>Why does Jupiter have more moons than Saturn, despite Saturn being larger?</li>
<li>Compare the advantages and disadvantages of flying versus taking the high-speed train from Beijing to Shanghai.</li>
</ul>
</li>
</ul>
<p><span data-as="p"><strong>Difficult Tasks (Maximum Thinking Capacity):</strong> For truly complex challenges—such as solving advanced math problems, network-related questions, or coding issues—these tasks require the model to fully engage its reasoning and planning abilities, often involving many internal steps before arriving at an answer. Examples include:</span></p><ul>
<li>Explain in detail how different experts in a Mixture-of-Experts (MoE) model collaborate.</li>
<li>Based on the recent week’s fluctuations of the Shanghai Composite Index and current political information, should I invest in a stock index ETF? Why?</li>
</ul>
<h3 id="samples-code"><span>Samples Code</span></h3>
<div id="curl"><ul data-component-part="tabs-list"><li id="curl"></li><li id="official-python-sdk"></li><li id="official-java-sdk"></li><li id="openai-python-sdk"></li></ul><div data-component-part="tab-content"><p><span data-as="p"><strong>Basic Call</strong></span></p><div numberoflines="25" language="shellscript"><div data-component-part="code-block-root"><div><pre language="shellscript"><code language="shellscript" numberoflines="25"><span><span>curl</span><span> -X</span><span> POST</span><span> &#34;https://api.z.ai/api/paas/v4/chat/completions&#34;</span><span> \</span></span>
<span><span>  -H</span><span> &#34;Content-Type: application/json&#34;</span><span> \</span></span>
<span><span>  -H</span><span> &#34;Authorization: Bearer your-api-key&#34;</span><span> \</span></span>
<span><span>  -d</span><span> &#39;{</span></span>
<span><span>    &#34;model&#34;: &#34;glm-4.5&#34;,</span></span>
<span><span>    &#34;messages&#34;: [</span></span>
<span><span>      {</span></span>
<span><span>        &#34;role&#34;: &#34;user&#34;,</span></span>
<span><span>        &#34;content&#34;: &#34;As a marketing expert, please create an attractive slogan for my product.&#34;</span></span>
<span><span>      },</span></span>
<span><span>      {</span></span>
<span><span>        &#34;role&#34;: &#34;assistant&#34;,</span></span>
<span><span>        &#34;content&#34;: &#34;Sure, to craft a compelling slogan, please tell me more about your product.&#34;</span></span>
<span><span>      },</span></span>
<span><span>      {</span></span>
<span><span>        &#34;role&#34;: &#34;user&#34;,</span></span>
<span><span>        &#34;content&#34;: &#34;Z.AI Open Platform&#34;</span></span>
<span><span>      }</span></span>
<span><span>    ],</span></span>
<span><span>    &#34;thinking&#34;: {</span></span>
<span><span>      &#34;type&#34;: &#34;enabled&#34;</span></span>
<span><span>    },</span></span>
<span><span>    &#34;max_tokens&#34;: 4096,</span></span>
<span><span>    &#34;temperature&#34;: 0.6</span></span>
<span><span>  }&#39;</span></span>
</code></pre></div></div></div><p><span data-as="p"><strong>Streaming Call</strong></span></p><div numberoflines="26" language="shellscript"><div data-component-part="code-block-root"><div><pre language="shellscript"><code language="shellscript" numberoflines="26"><span><span>curl</span><span> -X</span><span> POST</span><span> &#34;https://api.z.ai/api/paas/v4/chat/completions&#34;</span><span> \</span></span>
<span><span>  -H</span><span> &#34;Content-Type: application/json&#34;</span><span> \</span></span>
<span><span>  -H</span><span> &#34;Authorization: Bearer your-api-key&#34;</span><span> \</span></span>
<span><span>  -d</span><span> &#39;{</span></span>
<span><span>    &#34;model&#34;: &#34;glm-4.5&#34;,</span></span>
<span><span>    &#34;messages&#34;: [</span></span>
<span><span>      {</span></span>
<span><span>        &#34;role&#34;: &#34;user&#34;,</span></span>
<span><span>        &#34;content&#34;: &#34;As a marketing expert, please create an attractive slogan for my product.&#34;</span></span>
<span><span>      },</span></span>
<span><span>      {</span></span>
<span><span>        &#34;role&#34;: &#34;assistant&#34;,</span></span>
<span><span>        &#34;content&#34;: &#34;Sure, to craft a compelling slogan, please tell me more about your product.&#34;</span></span>
<span><span>      },</span></span>
<span><span>      {</span></span>
<span><span>        &#34;role&#34;: &#34;user&#34;,</span></span>
<span><span>        &#34;content&#34;: &#34;Z.AI Open Platform&#34;</span></span>
<span><span>      }</span></span>
<span><span>    ],</span></span>
<span><span>    &#34;thinking&#34;: {</span></span>
<span><span>      &#34;type&#34;: &#34;enabled&#34;</span></span>
<span><span>    },</span></span>
<span><span>    &#34;stream&#34;: true,</span></span>
<span><span>    &#34;max_tokens&#34;: 4096,</span></span>
<span><span>    &#34;temperature&#34;: 0.6</span></span>
<span><span>  }&#39;</span></span>
</code></pre></div></div></div></div></div></div></div>
  </body>
</html>
