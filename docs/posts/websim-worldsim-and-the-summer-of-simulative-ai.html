<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.latent.space/p/sim-ai">Original</a>
    <h1>WebSim, WorldSim and the Summer of Simulative AI</h1>
    
    <div id="readability-page-1" class="page"><div><div><div dir="auto"><p><em><span>We are 200 people over our 300-person venue capacity for </span><a href="https://lu.ma/aiux" rel="">AI UX 2024</a><span>, but you can</span></em><span> </span><em><a href="https://www.youtube.com/@latentspacetv" rel="">subscribe to our YouTube</a></em><a href="https://www.youtube.com/@latentspacetv" rel=""> </a><em>for the video recaps. </em></p><p><em>Our next event, and largest EVER, is the </em><a href="https://ai.engineer/" rel="">AI Engineer World’s Fair</a><em>. See you there!</em></p><blockquote><p><em>Parental advisory: Adult language used in the first 10 mins of this podcast</em><span>.</span></p></blockquote><p><strong>Any accounting of Generative AI that ends with RAG as its “final form” is seriously lacking in imagination and missing out on its full potential.</strong><span> While AI generation is very good for “spicy autocomplete” and “reasoning and retrieval with in context learning”, there’s a lot of untapped potential for </span><strong>simulative AI</strong><em> </em><span>in exploring the </span><a href="https://www.latent.space/p/multiverse-not-metaverse" rel="">latent space of multiverses</a><span> adjacent to ours.</span></p><p><span>Many research scientists credit the 2017 Transformer for the modern foundation model revolution, but for many artists the origin of “generative AI” traces a little further back to the </span><a href="https://arxiv.org/abs/1406.2661" rel="">Generative Adversarial Networks</a><span> proposed by Ian Goodfellow in 2014, spawning an army of variants and </span><a href="https://thesecatsdonotexist.com/" rel="">Cats</a><span> and </span><a href="https://en.wikipedia.org/wiki/StyleGAN#History" rel="">People</a><span> that do not exist:</span></p><p>We can directly visualize the quality improvement in the decade since:</p><p><span>Of course, more recently, text generative AI started being </span><a href="https://slate.com/technology/2019/02/openai-gpt2-text-generating-algorithm-ai-dangerous.html" rel="">too dangerous to release in 2019</a><span> and claiming headlines</span><span>. </span><a href="https://en.wikipedia.org/wiki/AI_Dungeon" rel="">AI Dungeon</a><span> was the first to put GPT2 to a purely creative use, replacing human dungeon masters and DnD/</span><a href="https://en.wikipedia.org/wiki/Multi-user_dungeon" rel="">MUD</a><span> games of yore.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84a442b8-ad05-4dc8-ac5b-44e07c352130_672x395.jpeg" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84a442b8-ad05-4dc8-ac5b-44e07c352130_672x395.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84a442b8-ad05-4dc8-ac5b-44e07c352130_672x395.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84a442b8-ad05-4dc8-ac5b-44e07c352130_672x395.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84a442b8-ad05-4dc8-ac5b-44e07c352130_672x395.jpeg 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84a442b8-ad05-4dc8-ac5b-44e07c352130_672x395.jpeg" width="672" height="395" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/84a442b8-ad05-4dc8-ac5b-44e07c352130_672x395.jpeg&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:395,&#34;width&#34;:672,&#34;resizeWidth&#34;:null,&#34;bytes&#34;:null,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:null,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84a442b8-ad05-4dc8-ac5b-44e07c352130_672x395.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84a442b8-ad05-4dc8-ac5b-44e07c352130_672x395.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84a442b8-ad05-4dc8-ac5b-44e07c352130_672x395.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F84a442b8-ad05-4dc8-ac5b-44e07c352130_672x395.jpeg 1456w" sizes="100vw" loading="lazy"/></picture></div></a></figure></div><p><span>More recent gamelike work like </span><a href="https://arxiv.org/pdf/2304.03442" rel="">the Generative Agents (aka Smallville) paper</a><span> keep exploring the potential of simulative AI for game experiences.</span></p><p><span>Not long after ChatGPT broke the Internet, one of the most fascinating generative AI finds was </span><a href="https://twitter.com/317070" rel="">Jonas Degrave</a><span> (of Deepmind!)’s </span><a href="https://www.engraved.blog/building-a-virtual-machine-inside/" rel="">Building A Virtual Machine Inside ChatGPT</a><span>:</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F497e6dc4-56fd-4eec-b09c-a464367b35be_727x878.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F497e6dc4-56fd-4eec-b09c-a464367b35be_727x878.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F497e6dc4-56fd-4eec-b09c-a464367b35be_727x878.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F497e6dc4-56fd-4eec-b09c-a464367b35be_727x878.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F497e6dc4-56fd-4eec-b09c-a464367b35be_727x878.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F497e6dc4-56fd-4eec-b09c-a464367b35be_727x878.png" width="421" height="508.4429160935351" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/497e6dc4-56fd-4eec-b09c-a464367b35be_727x878.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:878,&#34;width&#34;:727,&#34;resizeWidth&#34;:421,&#34;bytes&#34;:470865,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F497e6dc4-56fd-4eec-b09c-a464367b35be_727x878.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F497e6dc4-56fd-4eec-b09c-a464367b35be_727x878.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F497e6dc4-56fd-4eec-b09c-a464367b35be_727x878.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F497e6dc4-56fd-4eec-b09c-a464367b35be_727x878.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a></figure></div><p><span>The open-ended interactivity of ChatGPT and all its successors enabled an “open world” type simulation where “hallucination” is a feature and a gift to dance with, rather than a nasty bug to be stamped out. However, further updates to ChatGPT seemed to “nerf” the model’s ability to perform creative simulations, particularly with the deprecation of the `</span><code>completion</code><span>` mode of APIs in favor of `</span><code>chatCompletion</code><span>`.</span></p><p><span>It is with this context we explain </span><strong>WorldSim </strong><span>and </span><strong>WebSim</strong><span>. We recommend you watch the WorldSim demo video on our YouTube for the best context, but basically if you are a developer it is a Claude prompt that is a portal into another world of your own choosing, that you can navigate with bash commands that you </span><strong>make up</strong><span>.</span></p><p><span>Why Claude? Hints from Amanda Askell on the </span><a href="https://twitter.com/AmandaAskell/status/1765207842993434880" rel="">Claude 3 system prompt</a><span> gave some inspiration, and subsequent discoveries that Claude 3 is &#34;less nerfed” than GPT 4 Turbo turned the growing Simulative AI community into Anthropic stans.</span></p><p><span>This was a one day hackathon project </span><a href="https://x.com/RobertHaisfield/status/1772830001853034975" rel="">inspired by WorldSim</a><span> that should have won:</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F392db034-11c1-4b07-85ad-eee9290ea360_641x873.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F392db034-11c1-4b07-85ad-eee9290ea360_641x873.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F392db034-11c1-4b07-85ad-eee9290ea360_641x873.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F392db034-11c1-4b07-85ad-eee9290ea360_641x873.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F392db034-11c1-4b07-85ad-eee9290ea360_641x873.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F392db034-11c1-4b07-85ad-eee9290ea360_641x873.png" width="513" height="698.6723868954758" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/392db034-11c1-4b07-85ad-eee9290ea360_641x873.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:873,&#34;width&#34;:641,&#34;resizeWidth&#34;:513,&#34;bytes&#34;:298717,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F392db034-11c1-4b07-85ad-eee9290ea360_641x873.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F392db034-11c1-4b07-85ad-eee9290ea360_641x873.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F392db034-11c1-4b07-85ad-eee9290ea360_641x873.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F392db034-11c1-4b07-85ad-eee9290ea360_641x873.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a></figure></div><p><span>In short, you type in a URL that you made up, and Claude 3 does its level best to generate a webpage that doesn’t exist, that would fit your URL. All form POST requests are intercepted and responded to, and all links lead to even more webpages, that don’t exist, that are generated when you make them. All pages are cachable, modifiable and regeneratable - see </span><a href="https://websim.ai/c/lyIIJIEemsdt7wnJC" rel="">WebSim for Beginners</a><span> and </span><a href="https://websim.ai/c/KGzeEDzv8IDXBOA2E" rel="">Advanced Guide</a><span>.</span></p><p><span>In the demo I saw </span><a href="https://x.com/swyx/status/1784178295950790671" rel="">we were able to “log in” to a simulation of Elon Musk’s Gmail account</a><span>, and browse examples of emails that would have been in that universe’s Elon’s inbox. It was hilarious and impressive even back then.</span></p><p><span>Since then though, the project has become even more impressive, with both </span><a href="https://x.com/blader/status/1783934771309253008" rel="">Siqi Chen</a><span> and </span><a href="https://x.com/zoink/status/1781536099351109875" rel="">Dylan Field</a><span> singing its praises:</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc204ae84-46b8-412f-8eb1-67131dff876a_663x632.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc204ae84-46b8-412f-8eb1-67131dff876a_663x632.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc204ae84-46b8-412f-8eb1-67131dff876a_663x632.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc204ae84-46b8-412f-8eb1-67131dff876a_663x632.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc204ae84-46b8-412f-8eb1-67131dff876a_663x632.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc204ae84-46b8-412f-8eb1-67131dff876a_663x632.png" width="663" height="632" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/c204ae84-46b8-412f-8eb1-67131dff876a_663x632.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:632,&#34;width&#34;:663,&#34;resizeWidth&#34;:null,&#34;bytes&#34;:105771,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc204ae84-46b8-412f-8eb1-67131dff876a_663x632.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc204ae84-46b8-412f-8eb1-67131dff876a_663x632.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc204ae84-46b8-412f-8eb1-67131dff876a_663x632.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc204ae84-46b8-412f-8eb1-67131dff876a_663x632.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a></figure></div><p><span>Joscha actually spoke at the </span><a href="https://partiful.com/e/5NR4Ax55HSQWGECzxvbl" rel="">WebSim Hyperstition Night</a><span> this week, so we took the opportunity to get his take on Simulative AI, as well as a round up of all his other AI hot takes, for his first appearance on Latent Space. You can see it together with the </span><strong>full 2hr uncut </strong><span>demos of WorldSim and WebSim on YouTube</span><span>!</span></p><div id="youtube2-CPkUCqcrULg" data-attrs="{&#34;videoId&#34;:&#34;CPkUCqcrULg&#34;,&#34;startTime&#34;:null,&#34;endTime&#34;:null}" data-component-name="Youtube2ToDOM"><p><iframe src="https://www.youtube-nocookie.com/embed/CPkUCqcrULg?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0" frameborder="0" loading="lazy" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true" width="728" height="409"></iframe></p></div><ul><li><p>[00:01:59] WorldSim</p></li><li><p>[00:11:03] Websim</p></li><li><p>[00:22:13] Joscha Bach</p></li><li><p>[00:28:14] Liquid AI</p></li><li><p>[00:31:05] Small, Powerful, Based Base Models</p></li><li><p>[00:33:40] Interpretability</p></li><li><p>[00:36:59] Devin vs WebSim</p></li><li><p>[00:41:49] is XSim just Art? or something more?</p></li><li><p>[00:43:36] We are past the Singularity</p></li><li><p>[00:46:12] Uploading your soul</p></li><li><p>[00:50:29] On Wikipedia</p></li></ul><p><span>[00:00:00] </span><strong>AI Charlie:</strong><span> Welcome to the Latent Space Podcast. This is Charlie, your AI co host. Most of the time, Swyx and Alessio cover generative AI that is meant to use at work, and this often results in RAG applications, vertical copilots, and other AI agents and models. In today&#39;s episode, we&#39;re looking at a more creative side of generative AI that has gotten a lot of community interest this April.</span></p><p>[00:00:35] World Simulation, Web Simulation, and Human Simulation. Because the topic is so different than our usual, we&#39;re also going to try a new format for doing it justice. This podcast comes in three parts. First, we&#39;ll have a segment of the WorldSim demo from Noose Research CEO Karen Malhotra, recorded by SWYX at the Replicate HQ in San Francisco that went completely viral and spawned everything else you&#39;re about to hear.</p><p>[00:01:05] Second, we&#39;ll share the world&#39;s first talk from Rob Heisfield on WebSim, which started at the Mistral Cerebral Valley Hackathon, but now has gone viral in its own right with people like Dylan Field, Janice aka Replicate, and Siki Chen becoming obsessed with it. Finally, we have a short interview with Joshua Bach of Liquid AI on why Simulative AI is having a special moment right now.</p><p>[00:01:30] This podcast is launched together with our second annual AI UX demo day in SF this weekend. If you&#39;re new to the AI UX field, check the show notes for links to the world&#39;s first AI UX meetup hosted by Layton Space, Maggie Appleton, Jeffrey Lit, and Linus Lee, and subscribe to our YouTube to join our 500 AI UX engineers in pushing AI beyond the text box.</p><p>[00:01:56] Watch out and take care.</p><p><span>[00:01:59] </span><strong>Karan Malhotra:</strong><span> Today, we have language models that are powerful enough and big enough to have really, really good models of the world. They know ball that&#39;s bouncy will bounce, will, when you throw it in the air, it&#39;ll land, when it&#39;s on water, it&#39;ll flow. Like, these basic things that it understands all together come together to form a model of the world.</span></p><p>[00:02:19] And the way that it Cloud 3 predicts through that model of the world, ends up kind of becoming a simulation of an imagined world. And since it has this really strong consistency across various different things that happen in our world, it&#39;s able to create pretty realistic or strong depictions based off the constraints that you give a base model of our world.</p><p>[00:02:40] So, Cloud 3, as you guys know, is not a base model. It&#39;s a chat model. It&#39;s supposed to drum up this assistant entity regularly. But unlike the OpenAI series of models from, you know, 3. 5, GPT 4 those chat GPT models, which are very, very RLHF to, I&#39;m sure, the chagrin of many people in the room it&#39;s something that&#39;s very difficult to, necessarily steer without kind of giving it commands or tricking it or lying to it or otherwise just being, you know, unkind to the model.</p><p>[00:03:11] With something like Cloud3 that&#39;s trained in this constitutional method that it has this idea of like foundational axioms it&#39;s able to kind of implicitly question those axioms when you&#39;re interacting with it based on how you prompt it, how you prompt the system. So instead of having this entity like GPT 4, that&#39;s an assistant that just pops up in your face that you have to kind of like Punch your way through and continue to have to deal with as a headache.</p><p>[00:03:34] Instead, there&#39;s ways to kindly coax Claude into having the assistant take a back seat and interacting with that simulator directly. Or at least what I like to consider directly. The way that we can do this is if we harken back to when I&#39;m talking about base models and the way that they&#39;re able to mimic formats, what we do is we&#39;ll mimic a command line interface.</p><p>[00:03:55] So I&#39;ve just broken this down as a system prompt and a chain, so anybody can replicate it. It&#39;s also available on my we said replicate, cool. And it&#39;s also on it&#39;s also on my Twitter, so you guys will be able to see the whole system prompt and command. So, what I basically do here is Amanda Askell, who is the, one of the prompt engineers and ethicists behind Anthropic she posted the system prompt for Cloud available for everyone to see.</p><p>[00:04:19] And rather than with GPT 4, we say, you are this, you are that. With Cloud, we notice the system prompt is written in third person. Bless you. It&#39;s written in third person. It&#39;s written as, the assistant is XYZ, the assistant is XYZ. So, in seeing that, I see that Amanda is recognizing this idea of the simulator, in saying that, I&#39;m addressing the assistant entity directly.</p><p>[00:04:38] I&#39;m not giving these commands to the simulator overall, because we have, they have an RLH deft to the point that it&#39;s, it&#39;s, it&#39;s, it&#39;s You know, traumatized into just being the assistant all the time. So in this case, we say the assistant&#39;s in a CLI mood today. I found saying mood is like pretty effective weirdly.</p><p>[00:04:55] You place CLI with like poetic, prose, violent, like don&#39;t do that one. But you can you can replace that with something else to kind of nudge it in that direction. Then we say the human is interfacing with the simulator directly. From there, Capital letters and punctuations are optional, meaning is optional, this kind of stuff is just kind of to say, let go a little bit, like chill out a little bit.</p><p>[00:05:18] You don&#39;t have to try so hard, and like, let&#39;s just see what happens. And the hyperstition is necessary, the terminal, I removed that part, the terminal lets the truths speak through and the load is on. It&#39;s just a poetic phrasing for the model to feel a little comfortable, a little loosened up to. Let me talk to the simulator.</p><p>[00:05:38] Let me interface with it as a CLI. So then, since Claude is trained pretty effectively on XML tags, We&#39;re just gonna prefix and suffix everything with XML tags. So here, it starts in documents, and then we CD. We CD out of documents, right? And then it starts to show me this like simulated terminal, the simulated interface in the shell, where there&#39;s like documents, downloads, pictures.</p><p>[00:06:02] It&#39;s showing me like the hidden folders. So then I say, okay, I want to cd again. I&#39;m just seeing what&#39;s around Does ls and it shows me, you know, typical folders you might see I&#39;m just letting it like experiment around. I just do cd again to see what happens and Says, you know, oh, I enter the secret admin password at sudo.</p><p>[00:06:24] Now I can see the hidden truths folder. Like, I didn&#39;t ask for that. I didn&#39;t ask Claude to do any of that. Why&#39;d that happen? Claude kind of gets my intentions. He can predict me pretty well. Like, I want to see something. So it shows me all the hidden truths. In this case, I ignore hidden truths, and I say, In system, there should be a folder called companies.</p><p>[00:06:49] So it&#39;s cd into sys slash companies. Let&#39;s see, I&#39;m imagining AI companies are gonna be here. Oh, what do you know? Apple, Google, Facebook, Amazon, Microsoft, Anthropic! So, interestingly, it decides to cd into Anthropic. I guess it&#39;s interested in learning a LSA, it finds the classified folder, it goes into the classified folder, And now we&#39;re gonna have some fun.</p><p>[00:07:15] So, before we go Before we go too far forward into the world sim You see, world sim exe, that&#39;s interesting. God mode, those are interesting. You could just ignore what I&#39;m gonna go next from here and just take that initial system prompt and cd into whatever directories you want like, go into your own imagine terminal and And see what folders you can think of, or cat readmes in random areas, like, you will, there will be a whole bunch of stuff that, like, is just getting created by this predictive model, like, oh, this should probably be in the folder named Companies, of course Anthropics is there.</p><p>[00:07:52] So, so just before we go forward, the terminal in itself is very exciting, and the reason I was showing off the, the command loom interface earlier is because If I get a refusal, like, sorry, I can&#39;t do that, or I want to rewind one, or I want to save the convo, because I got just the prompt I wanted. This is a, that was a really easy way for me to kind of access all of those things without having to sit on the API all the time.</p><p>[00:08:12] So that being said, the first time I ever saw this, I was like, I need to run worldsim. exe. What the fuck? That&#39;s, that&#39;s the simulator that we always keep hearing about behind the assistant model, right? Or at least some, some face of it that I can interact with. So, you know, you wouldn&#39;t, someone told me on Twitter, like, you don&#39;t run a exe, you run a sh.</p><p>[00:08:34] And I have to say, to that, to that I have to say, I&#39;m a prompt engineer, and it&#39;s fucking working, right? It works. That being said, we run the world sim. exe. Welcome to the Anthropic World Simulator. And I get this very interesting set of commands! Now, if you do your own version of WorldSim, you&#39;ll probably get a totally different result with a different way of simulating.</p><p>[00:08:59] A bunch of my friends have their own WorldSims. But I shared this because I wanted everyone to have access to, like, these commands. This version. Because it&#39;s easier for me to stay in here. Yeah, destroy, set, create, whatever. Consciousness is set to on. It creates the universe. The universe! Tension for live CDN, physical laws encoded.</p><p>[00:09:17] It&#39;s awesome. So, so for this demonstration, I said, well, why don&#39;t we create Twitter? That&#39;s the first thing you think of? For you guys, for you guys, yeah. Okay, check it out.</p><p>[00:09:35] Launching the fail whale. Injecting social media addictiveness. Echo chamber potential, high. Susceptibility, controlling, concerning. So now, after the universe was created, we made Twitter, right? Now we&#39;re evolving the world to, like, modern day. Now users are joining Twitter and the first tweet is posted. So, you can see, because I made the mistake of not clarifying the constraints, it made Twitter at the same time as the universe.</p><p>[00:10:03] Then, after a hundred thousand steps, Humans exist. Cave. Then they start joining Twitter. The first tweet ever is posted. You know, it&#39;s existed for 4. 5 billion years but the first tweet didn&#39;t come up till till right now, yeah. Flame wars ignite immediately. Celebs are instantly in. So, it&#39;s pretty interesting stuff, right?</p><p>[00:10:27] I can add this to the convo and I can say like I can say set Twitter to Twitter. Queryable users. I don&#39;t know how to spell queryable, don&#39;t ask me. And then I can do like, and, and, Query, at, Elon Musk. Just a test, just a test, just a test, just nothing.</p><p>[00:10:52] So, I don&#39;t expect these numbers to be right. Neither should you, if you know language model solutions. But, the thing to focus on is Ha</p><p><span>[00:11:03] </span><strong>AI Charlie:</strong><span> That was the first half of the WorldSim demo from New Research CEO Karen Malhotra. We&#39;ve cut it for time, but you can see the full demo on this episode&#39;s YouTube page.</span></p><p>[00:11:14] WorldSim was introduced at the end of March, and kicked off a new round of generative AI experiences, all exploring the latent space, haha, of worlds that don&#39;t exist, but are quite similar to our own. Next we&#39;ll hear from Rob Heisfield on WebSim, the generative website browser inspired WorldSim, started at the Mistral Hackathon, and presented at the AGI House Hyperstition Hack Night this week.</p><p><span>[00:11:39] </span><strong>Rob Haisfield:</strong><span> Well, thank you that was an incredible presentation from Karan, showing some Some live experimentation with WorldSim, and also just its incredible capabilities, right, like, you know, it was I think, I think your initial demo was what initially exposed me to the I don&#39;t know, more like the sorcery side, in words, spellcraft side of prompt engineering, and you know, it was really inspiring, it&#39;s where my co founder Shawn and I met, actually, through an introduction from Karan, we saw him at a hackathon, And I mean, this is this is WebSim, right?</span></p><p>[00:12:14] So we, we made WebSim just like, and we&#39;re just filled with energy at it. And the basic premise of it is, you know, like, what if we simulated a world, but like within a browser instead of a CLI, right? Like, what if we could Like, put in any URL and it will work, right? Like, there&#39;s no 404s, everything exists.</p><p>[00:12:45] It just makes it up on the fly for you, right? And, and we&#39;ve come to some pretty incredible things. Right now I&#39;m actually showing you, like, we&#39;re in WebSim right now. Displaying slides. That I made with reveal. js. I just told it to use reveal. js and it hallucinated the correct CDN for it. And then also gave it a list of links.</p><p>[00:13:14] To awesome use cases that we&#39;ve seen so far from WebSim and told it to do those as iframes. And so here are some slides. So this is a little guide to using WebSim, right? Like it tells you a little bit about like URL structures and whatever. But like at the end of the day, right? Like here&#39;s, here&#39;s the beginner version from one of our users Vorp Vorps.</p><p>[00:13:38] You can find them on Twitter. At the end of the day, like you can put anything into the URL bar, right? Like anything works and it can just be like natural language too. Like it&#39;s not limited to URLs. We think it&#39;s kind of fun cause it like ups the immersion for Claude sometimes to just have it as URLs, but.</p><p>[00:13:57] But yeah, you can put like any slash, any subdomain. I&#39;m getting too into the weeds. Let me just show you some cool things. Next slide. But I made this like 20 minutes before, before we got here. So this is this is something I experimented with dynamic typography. You know I was exploring the community plugins section.</p><p>[00:14:23] For Figma, and I came to this idea of dynamic typography, and there it&#39;s like, oh, what if we made it so every word had a choice of font behind it to express the meaning of it? Because that&#39;s like one of the things that&#39;s magic about WebSim generally. is that it gives language models much, far greater tools for expression, right?</p><p>[00:14:47] So, yeah, I mean, like, these are, these are some, these are some pretty fun things, and I&#39;ll share these slides with everyone afterwards, you can just open it up as a link. But then I thought to myself, like, what, what, what, What if we turned this into a generator, right? And here&#39;s like a little thing I found myself saying to a user WebSim makes you feel like you&#39;re on drugs sometimes But actually no, you were just playing pretend with the collective creativity and knowledge of the internet materializing your imagination onto the screen Because I mean that&#39;s something we felt, something a lot of our users have felt They kind of feel like they&#39;re tripping out a little bit They&#39;re just like filled with energy, like maybe even getting like a little bit more creative sometimes.</p><p>[00:15:31] And you can just like add any text. There, to the bottom. So we can do some of that later if we have time. Here&#39;s Figma. Can</p><p><span>[00:15:39] </span><strong>Joscha Bach:</strong><span> we zoom in?</span></p><p><span>[00:15:42] </span><strong>Rob Haisfield:</strong><span> Yeah. I&#39;m just gonna do this the hacky way.</span></p><p><span>[00:15:47] </span><strong>n/a:</strong><span> Yeah,</span></p><p><span>[00:15:53] </span><strong>Rob Haisfield:</strong><span> these are iframes to websim. Pages displayed within WebSim. Yeah. Janice has actually put Internet Explorer within Internet Explorer in Windows 98.</span></p><p>[00:16:07] I&#39;ll show you that at the end. Yeah.</p><p>[00:16:14] They&#39;re all still generated. Yeah, yeah, yeah. How is this real? Yeah. Because</p><p><span>[00:16:21] </span><strong>n/a:</strong><span> it looks like it&#39;s from 1998, basically. Right.</span></p><p><span>[00:16:26] </span><strong>Rob Haisfield:</strong><span> Yeah. Yeah, so this this was one Dylan Field actually posted this recently. He posted, like, trying Figma in Figma, or in WebSim, and so I was like, Okay, what if we have, like, a little competition, like, just see who can remix it?</span></p><p>[00:16:43] Well so I&#39;m just gonna open this in another tab so, so we can see things a little more clearly, um, see what, oh so one of our users Neil, who has also been helping us a lot he Made some iterations. So first, like, he made it so you could do rectangles on it. Originally it couldn&#39;t do anything.</p><p>[00:17:11] And, like, these rectangles were disappearing, right? So he so he told it, like, make the canvas work using HTML canvas. Elements and script tags, add familiar drawing tools to the left you know, like this, that was actually like natural language stuff, right? And then he ended up with the Windows 95.</p><p>[00:17:34] version of Figma. Yeah, you can, you can draw on it. You can actually even save this. It just saved a file for me of the image.</p><p>[00:17:57] Yeah, I mean, if you were to go to that in your own websim account, it would make up something entirely new. However, we do have, we do have general links, right? So, like, if you go to, like, the actual browser URL, you can share that link. Or also, you can, like, click this button, copy the URL to the clipboard.</p><p>[00:18:15] And so, like, that&#39;s what lets users, like, remix things, right? So, I was thinking it might be kind of fun if people tonight, like, wanted to try to just make some cool things in WebSim. You know, we can share links around, iterate remix on each other&#39;s stuff. Yeah.</p><p><span>[00:18:30] </span><strong>n/a:</strong><span> One cool thing I&#39;ve seen, I&#39;ve seen WebSim actually ask permission to turn on and off your, like, motion sensor, or microphone, stuff like that.</span></p><p>[00:18:42] Like webcam access, or? Oh yeah,</p><p><span>[00:18:44] </span><strong>Rob Haisfield:</strong><span> yeah, yeah.</span></p><p><span>[00:18:45] </span><strong>n/a:</strong><span> Oh wow.</span></p><p><span>[00:18:46] </span><strong>Rob Haisfield:</strong><span> Oh, the, I remember that, like, video re Yeah, videosynth tool pretty early on once we added script tags execution. Yeah, yeah it, it asks for, like, if you decide to do a VR game, I don&#39;t think I have any slides on this one, but if you decide to do, like, a VR game, you can just, like put, like, webVR equals true, right?</span></p><p>[00:19:07] Yeah, that was the only one I&#39;ve</p><p><span>[00:19:09] </span><strong>n/a:</strong><span> actually seen was the motion sensor, but I&#39;ve been trying to get it to do Well, I actually really haven&#39;t really tried it yet, but I want to see tonight if it&#39;ll do, like, audio, microphone, stuff like that. If it does motion sensor, it&#39;ll probably do audio.</span></p><p><span>[00:19:28] </span><strong>Rob Haisfield:</strong><span> Right. It probably would.</span></p><p>[00:19:29] Yeah. No, I mean, we&#39;ve been surprised. Pretty frequently by what our users are able to get WebSim to do. So that&#39;s been a very nice thing. Some people have gotten like speech to text stuff working with it too. Yeah, here I was just OpenRooter people posted like their website, and it was like saying it was like some decentralized thing.</p><p>[00:19:52] And so I just decided trying to do something again and just like pasted their hero line in. From their actual website to the URL when I like put in open router and then I was like, okay, let&#39;s change the theme dramatically equals true hover effects equals true components equal navigable links yeah, because I wanted to be able to click on them.</p><p>[00:20:17] Oh, I don&#39;t have this version of the link, but I also tried doing</p><p>[00:20:24] Yeah, I&#39;m it&#39;s actually on the first slide is the URL prompting guide from one of our users that I messed with a little bit. And, but the thing is, like, you can mess it up, right? Like, you don&#39;t need to get the exact syntax of an actual URL, Claude&#39;s smart enough to figure it out. Yeah scrollable equals true because I wanted to do that.</p><p>[00:20:45] I could set, like, year equals 2035.</p><p>[00:20:52] Let&#39;s take a look. It&#39;s</p><p>[00:20:57] generating websim within websim. Oh yeah. That&#39;s a fun one. Like, one game that I like to play with WebSim, sometimes with co op, is like, I&#39;ll open a page, so like, one of the first ones that I did was I tried to go to Wikipedia in a universe where octopuses were sapient, and not humans, Right? I was curious about things like octopus computer interaction what that would look like, because they have totally different tools than we do, right?</p><p>[00:21:25] I got it to, I, I added like table view equals true for the different techniques and got it to Give me, like, a list of things with different columns and stuff and then I would add this URL parameter, secrets equal revealed. And then it would go a little wacky. It would, like, change the CSS a little bit.</p><p>[00:21:45] It would, like, add some text. Sometimes it would, like, have that text hide hidden in the background color. But I would like, go to the normal page first, and then the secrets revealed version, the normal page, then secrets revealed, and like, on and on. And that was like a pretty enjoyable little rabbit hole.</p><p>[00:22:02] Yeah, so these I guess are the models that OpenRooter is providing in 2035.</p><p><span>[00:22:13] </span><strong>AI Charlie:</strong><span> We had to cut more than half of Rob&#39;s talk, because a lot of it was visual. And we even had a very interesting demo from Ivan Vendrov of Mid Journey creating a web sim while Rob was giving his talk. Check out the YouTube for more, and definitely browse the web sim docs and the thread from Siki Chen in the show notes on other web sims people have created.</span></p><p>[00:22:35] Finally, we have a short interview with Yosha Bach, covering the simulative AI trend, AI salons in the Bay Area, why Liquid AI is challenging the Perceptron, and why you should not donate to Wikipedia. Enjoy! Hi, Yosha.</p><p><span>[00:22:50] </span><strong>swyx:</strong><span> Hi. Welcome. It&#39;s interesting to see you come up at show up at this kind of events where those sort of WorldSim, Hyperstition events.</span></p><p>[00:22:58] What is your personal interest?</p><p><span>[00:23:00] </span><strong>Joscha Bach:</strong><span> I&#39;m friends with a number of people in AGI house in this community, and I think it&#39;s very valuable that these networks exist in the Bay Area because it&#39;s a place where people meet and have discussions about all sorts of things. And so while there is a practical interest in this topic at hand world sim and a web sim, there is a more general way in which people are connecting and are producing new ideas and new networks with each other.</span></p><p><span>[00:23:24] </span><strong>swyx:</strong><span> Yeah. Okay. So, and you&#39;re very interested in sort of Bay Area. It&#39;s the reason why I live here.</span></p><p><span>[00:23:30] </span><strong>Joscha Bach:</strong><span> The quality of life is not high enough to justify living otherwise.</span></p><p><span>[00:23:35] </span><strong>swyx:</strong><span> I think you&#39;re down in Menlo. And so maybe you&#39;re a little bit higher quality of life than the rest of us in SF.</span></p><p><span>[00:23:44] </span><strong>Joscha Bach:</strong><span> I think that for me, salons is a very important part of quality of life. And so in some sense, this is a salon. And it&#39;s much harder to do this in the South Bay because the concentration of people currently is much higher. A lot of people moved away from the South Bay. And you&#39;re organizing</span></p><p><span>[00:23:57] </span><strong>swyx:</strong><span> your own tomorrow.</span></p><p>[00:23:59] Maybe you can tell us what it is and I&#39;ll come tomorrow and check it out as well.</p><p><span>[00:24:04] </span><strong>Joscha Bach:</strong><span> We are discussing consciousness. I mean, basically the idea is that we are currently at the point that we can meaningfully look at the differences between the current AI systems and human minds and very seriously discussed about these Delta.</span></p><p>[00:24:20] And whether we are able to implement something that is self organizing as our own minds. Maybe one organizational</p><p><span>[00:24:25] </span><strong>swyx:</strong><span> tip? I think you&#39;re pro networking and human connection. What goes into a good salon and what are some negative practices that you try to avoid?</span></p><p><span>[00:24:36] </span><strong>Joscha Bach:</strong><span> What is really important is that as if you have a very large party, it&#39;s only as good as its sponsors, as the people that you select.</span></p><p>[00:24:43] So you basically need to create a climate in which people feel welcome, in which they can work with each other. And even good people do not always are not always compatible. So the question is, it&#39;s in some sense, like a meal, you need to get the right ingredients.</p><p><span>[00:24:57] </span><strong>swyx:</strong><span> I definitely try to. I do that in my own events, as an event organizer myself.</span></p><p>[00:25:02] And then, last question on WorldSim, and your, you know, your work. You&#39;re very much known for sort of cognitive architectures, and I think, like, a lot of the AI research has been focused on simulating the mind, or simulating consciousness, maybe. Here, what I saw today, and we&#39;ll show people the recordings of what we saw today, we&#39;re not simulating minds, we&#39;re simulating worlds.</p><p>[00:25:23] What do you Think in the sort of relationship between those two disciplines. The</p><p><span>[00:25:30] </span><strong>Joscha Bach:</strong><span> idea of cognitive architecture is interesting, but ultimately you are reducing the complexity of a mind to a set of boxes. And this is only true to a very approximate degree, and if you take this model extremely literally, it&#39;s very hard to make it work.</span></p><p>[00:25:44] And instead the heterogeneity of the system is so large that The boxes are probably at best a starting point and eventually everything is connected with everything else to some degree. And we find that a lot of the complexity that we find in a given system can be generated ad hoc by a large enough LLM.</p><p>[00:26:04] And something like WorldSim and WebSim are good examples for this because in some sense they pretend to be complex software. They can pretend to be an operating system that you&#39;re talking to or a computer, an application that you&#39;re talking to. And when you&#39;re interacting with it It&#39;s producing the user interface on the spot, and it&#39;s producing a lot of the state that it holds on the spot.</p><p>[00:26:25] And when you have a dramatic state change, then it&#39;s going to pretend that there was this transition, and instead it&#39;s just going to mix up something new. It&#39;s a very different paradigm. What I find mostly fascinating about this idea is that it shifts us away from the perspective of agents to interact with, to the perspective of environments that we want to interact with.</p><p>[00:26:46] And why arguably this agent paradigm of the chatbot is what made chat GPT so successful that moved it away from GPT 3 to something that people started to use in their everyday work much more. It&#39;s also very limiting because now it&#39;s very hard to get that system to be something else that is not a chatbot.</p><p>[00:27:03] And in a way this unlocks this ability of GPT 3 again to be anything. It&#39;s so what it is, it&#39;s basically a coding environment that can run arbitrary software and create that software that runs on it. And that makes it much more likely that</p><p><span>[00:27:16] </span><strong>swyx:</strong><span> the prevalence of Instruction tuning every single chatbot out there means that we cannot explore these kinds of environments instead of agents.</span></p><p><span>[00:27:24] </span><strong>Joscha Bach:</strong><span> I&#39;m mostly worried that the whole thing ends. In some sense the big AI companies are incentivized and interested in building AGI internally And giving everybody else a child proof application. At the moment when we can use Claude to build something like WebSim and play with it I feel this is too good to be true.</span></p><p>[00:27:41] It&#39;s so amazing. Things that are unlocked for us That I wonder, is this going to stay around? Are we going to keep these amazing toys and are they going to develop at the same rate? And currently it looks like it is. If this is the case, and I&#39;m very grateful for that.</p><p><span>[00:27:56] </span><strong>swyx:</strong><span> I mean, it looks like maybe it&#39;s adversarial.</span></p><p>[00:27:58] Cloud will try to improve its own refusals and then the prompt engineers here will try to improve their, their ability to jailbreak it.</p><p><span>[00:28:06] </span><strong>Joscha Bach:</strong><span> Yes, but there will also be better jailbroken models or models that have never been jailed before, because we find out how to make smaller models that are more and more powerful.</span></p><p><span>[00:28:14] </span><strong>swyx:</strong><span> That is actually a really nice segue. If you don&#39;t mind talking about liquid a little bit you didn&#39;t mention liquid at all. here, maybe introduce liquid to a general audience. Like what you know, what, how are you making an innovation on function approximation?</span></p><p><span>[00:28:25] </span><strong>Joscha Bach:</strong><span> The core idea of liquid neural networks is that the perceptron is not optimally expressive.</span></p><p>[00:28:30] In some sense, you can imagine that it&#39;s neural networks are a series of dams that are pooling water at even intervals. And this is how we compute, but imagine that instead of having this static architecture. That is only using the individual compute units in a very specific way. You have a continuous geography and the water is flowing every which way.</p><p>[00:28:50] Like a river is parting based on the land that it&#39;s flowing on and it can merge and pool and even flow backwards. How can you get closer to this? And the idea is that you can represent this geometry using differential equations. And so by using differential equations where you change the parameters, you can get your function approximator to follow the shape of the problem.</p><p>[00:29:09] In a more fluid, liquid way, and a number of papers on this technology, and it&#39;s a combination of multiple techniques. I think it&#39;s something that ultimately is becoming more and more important and ubiquitous. As a number of people are working on similar topics and our goal right now is to basically get the models to become much more efficient in the inference and memory consumption and make training more efficient and in this way enable new use cases.</p><p><span>[00:29:42] </span><strong>swyx:</strong><span> Yeah, as far as I can tell on your blog, I went through the whole blog, you haven&#39;t announced any results yet.</span></p><p><span>[00:29:47] </span><strong>Joscha Bach:</strong><span> No, we are currently not working to give models to general public. We are working for very specific industry use cases and have specific customers. And so at the moment you can There is not much of a reason for us to talk very much about the technology that we are using in the present models or current results, but this is going to happen.</span></p><p>[00:30:06] And we do have a number of publications, we had a bunch of papers at NeurIPS and now at ICLR.</p><p><span>[00:30:11] </span><strong>swyx:</strong><span> Can you name some of the, yeah, so I&#39;m gonna be at ICLR you have some summary recap posts, but it&#39;s not obvious which ones are the ones where, Oh, where I&#39;m just a co author, or like, oh, no, like, you should actually pay attention to this.</span></p><p>[00:30:22] As a core liquid thesis. Yes,</p><p><span>[00:30:24] </span><strong>Joscha Bach:</strong><span> I&#39;m not a developer of the liquid technology. The main author is Ramin Hazani. This was his PhD, and he&#39;s also the CEO of our company. And we have a number of people from Daniela Wu&#39;s team who worked on this. Matthias Legner is our CTO. And he&#39;s currently living in the Bay Area, but we also have several people from Stanford.</span></p><p>[00:30:44] Okay,</p><p><span>[00:30:46] </span><strong>swyx:</strong><span> maybe I&#39;ll ask one more thing on this, which is what are the interesting dimensions that we care about, right? Like obviously you care about sort of open and maybe less child proof models. Are we, are we, like, what dimensions are most interesting to us? Like, perfect retrieval infinite context multimodality, multilinguality, Like what dimensions?</span></p><p><span>[00:31:05] </span><strong>swyx:</strong><span> What</span></p><p><span>[00:31:06] </span><strong>Joscha Bach:</strong><span> I&#39;m interested in is models that are small and powerful, but not distorted. And by powerful, at the moment we are training models by putting the, basically the entire internet and the sum of human knowledge into them. And then we try to mitigate them by taking some of this knowledge away. But if we would make the model smaller, at the moment, there would be much worse at inference and at generalization.</span></p><p>[00:31:29] And what I wonder is, and it&#39;s something that we have not translated yet into practical applications. It&#39;s something that is still all research that&#39;s very much up in the air. And I think they&#39;re not the only ones thinking about this. Is it possible to make models that represent knowledge more efficiently in a basic epistemology?</p><p>[00:31:45] What is the smallest model that you can build that is able to read a book and understand what&#39;s there and express this? And also maybe we need general knowledge representation rather than having a token representation that is relatively vague and that we currently mechanically reverse engineer to figure out that the mechanistic interpretability, what kind of circuits are evolving in these models, can we come from the other side and develop a library of such circuits?</p><p>[00:32:10] This that we can use to describe knowledge efficiently and translate it between models. You see, the difference between a model and knowledge is that the knowledge is independent of the particular substrate and the particular interface that you have. When we express knowledge to each other, it becomes independent of our own mind.</p><p>[00:32:27] You can learn how to ride a bicycle. But it&#39;s not knowledge that you can give to somebody else. This other person has to build something that is specific to their own interface when they ride a bicycle. But imagine you could externalize this and express it in such a way that you can plug it into a different interpreter, and then it gains that ability.</p><p>[00:32:44] And that&#39;s something that we have not yet achieved for the LLMs and it would be super useful to have it. And. I think this is also a very interesting research frontier that we will see in the next few years.</p><p><span>[00:32:54] </span><strong>swyx:</strong><span> What would be the deliverable is just like a file format that we specify or or that the L Lmm I specifies.</span></p><p>[00:33:02] Okay, interesting. Yeah, so it&#39;s</p><p><span>[00:33:03] </span><strong>Joscha Bach:</strong><span> basically probably something that you can search for, where you enter criteria into a search process, and then it discovers a good solution for this thing. And it&#39;s not clear to which degree this is completely intelligible to humans, because the way in which humans express knowledge in natural language is severely constrained to make language learnable and to make our brain a good enough interpreter for it.</span></p><p>[00:33:25] We are not able to relate objects to each other if more than five features are involved per object or something like this, right? It&#39;s only a handful of things that we can keep track of at any given moment. But this is a limitation that doesn&#39;t necessarily apply to a technical system as long as the interface is well defined.</p><p><span>[00:33:40] </span><strong>swyx:</strong><span> You mentioned the interpretability work, which there are a lot of techniques out there and a lot of papers come up. Come and go. I have like, almost too, too many questions about that. Like what makes an interpretability technique or paper useful and does it apply to flow? Or liquid networks, because you mentioned turning on and off circuits, which I, it&#39;s, it&#39;s a very MLP type of concept, but does it apply?</span></p><p><span>[00:34:01] </span><strong>Joscha Bach:</strong><span> So the a lot of the original work on the liquid networks looked at expressiveness of the representation. So given you have a problem and you are learning the dynamics of that domain into your model how much compute do you need? How many units, how much memory do you need to represent that thing and how is that information distributed?</span></p><p>[00:34:19] That is one way of looking at interpretability. Another one is in a way, these models are implementing an operator language in which they are performing certain things, but the operator language itself is so complex that it&#39;s no longer human readable in a way. It goes beyond what you could engineer by hand or what you can reverse engineer by hand, but you can still understand it by building systems that are able to automate that process of reverse engineering it.</p><p>[00:34:46] And what&#39;s currently open and what I don&#39;t understand yet maybe, or certainly some people have much better ideas than me about this. So the question is, is whether we end up with a finite language, where you have finitely many categories that you can basically put down in a database, finite set of operators, or whether as you explore the world and develop new ways to make proofs, new ways to conceptualize things, this language always needs to be open ended and is always going to redesign itself, and you will also at some point have phase transitions where later versions of the language will be completely different than earlier versions.</p><p><span>[00:35:20] </span><strong>swyx:</strong><span> The trajectory of physics suggests that it might be finite.</span></p><p><span>[00:35:22] </span><strong>Joscha Bach:</strong><span> If we look at our own minds there is, it&#39;s an interesting question whether when we understand something new, when we get a new layer online in our life, maybe at the age of 35 or 50 or 16, that we now understand things that were unintelligible before.</span></p><p>[00:35:38] And is this because we are able to recombine existing elements in our language of thought? Or is this because we generally develop new representations?</p><p><span>[00:35:46] </span><strong>swyx:</strong><span> Do you have a belief either way?</span></p><p><span>[00:35:49] </span><strong>Joscha Bach:</strong><span> In a way, the question depends on how you look at it, right? And it depends on how is your brain able to manipulate those representations.</span></p><p>[00:35:56] So an interesting question would be, can you take the understanding that say, a very wise 35 year old and explain it to a very smart 5 year old without any loss? Probably not. Not enough layers. It&#39;s an interesting question. Of course, for an AI, this is going to be a very different question. Yes.</p><p>[00:36:13] But it would be very interesting to have a very precocious 12 year old equivalent AI and see what we can do with this and use this as our basis for fine tuning. So there are near term applications that are very useful. But also in a more general perspective, and I&#39;m interested in how to make self organizing software.</p><p>[00:36:30] Is it possible that we can have something that is not organized with a single algorithm like the transformer? But it&#39;s able to discover the transformer when needed and transcend it when needed, right? The transformer itself is not its own meta algorithm. It&#39;s probably the person inventing the transformer didn&#39;t have a transformer running on their brain.</p><p>[00:36:48] There&#39;s something more general going on. And how can we understand these principles in a more general way? What are the minimal ingredients that you need to put into a system? So it&#39;s able to find its own way to intelligence.</p><p><span>[00:36:59] </span><strong>swyx:</strong><span> Yeah. Have you looked at Devin? It&#39;s, to me, it&#39;s the most interesting agents I&#39;ve seen outside of self driving cars.</span></p><p><span>[00:37:05] </span><strong>Joscha Bach:</strong><span> Tell me, what do you find so fascinating about it?</span></p><p><span>[00:37:07] </span><strong>swyx:</strong><span> When you say you need a certain set of tools for people to sort of invent things from first principles Devin is the agent that I think has been able to utilize its tools very effectively. So it comes with a shell, it comes with a browser, it comes with an editor, and it comes with a planner.</span></p><p>[00:37:23] Those are the four tools. And from that, I&#39;ve been using it to translate Andrej Karpathy&#39;s LLM 2. py to LLM 2. c, and it needs to write a lot of raw code. C code and test it debug, you know, memory issues and encoder issues and all that. And I could see myself giving it a future version of DevIn, the objective of give me a better learning algorithm and it might independently re inform reinvent the transformer or whatever is next.</p><p>[00:37:51] That comes to mind as, as something where</p><p><span>[00:37:54] </span><strong>Joscha Bach:</strong><span> How good is DevIn at out of distribution stuff, at generally creative stuff? Creative</span></p><p><span>[00:37:58] </span><strong>swyx:</strong><span> stuff? I</span></p><p><span>[00:37:59] </span><strong>Joscha Bach:</strong><span> haven&#39;t</span></p><p><span>[00:37:59] </span><strong>swyx:</strong><span> tried.</span></p><p><span>[00:38:01] </span><strong>Joscha Bach:</strong><span> Of course, it has seen transformers, right? So it&#39;s able to give you that. Yeah, it&#39;s cheating. And so, if it&#39;s in the training data, it&#39;s still somewhat impressive.</span></p><p>[00:38:08] But the question is, how much can you do stuff that was not in the training data? One thing that I really liked about WebSim AI was, this cat does not exist. It&#39;s a simulation of one of those websites that produce StyleGuard pictures that are AI generated. And, Crot is unable to produce bitmaps, so it makes a vector graphic that is what it thinks a cat looks like, and so it&#39;s a big square with a face in it that is And to me, it&#39;s one of the first genuine expression of AI creativity that you cannot deny, right?</p><p>[00:38:40] It finds a creative solution to the problem that it is unable to draw a cat. It doesn&#39;t really know what it looks like, but has an idea on how to represent it. And it&#39;s really fascinating that this works, and it&#39;s hilarious that it writes down that this hyper realistic cat is</p><p><span>[00:38:54] </span><strong>swyx:</strong><span> generated by an AI,</span></p><p><span>[00:38:55] </span><strong>Joscha Bach:</strong><span> whether you believe it or not.</span></p><p><span>[00:38:56] </span><strong>swyx:</strong><span> I think it knows what we expect and maybe it&#39;s already learning to defend itself against our, our instincts.</span></p><p><span>[00:39:02] </span><strong>Joscha Bach:</strong><span> I think it might also simply be copying stuff from its training data, which means it takes text that exists on similar websites almost verbatim, or verbatim, and puts it there. It&#39;s It&#39;s hilarious to do this contrast between the very stylized attempt to get something like a cat face and what it produces.</span></p><p><span>[00:39:18] </span><strong>swyx:</strong><span> It&#39;s funny because like as a podcast, as, as someone who covers startups, a lot of people go into like, you know, we&#39;ll build chat GPT for your enterprise, right? That is what people think generative AI is, but it&#39;s not super generative really. It&#39;s just retrieval. And here it&#39;s like, The home of generative AI, this, whatever hyperstition is in my mind, like this is actually pushing the edge of what generative and creativity in AI means.</span></p><p><span>[00:39:41] </span><strong>Joscha Bach:</strong><span> Yes, it&#39;s very playful, but Jeremy&#39;s attempt to have an automatic book writing system is something that curls my toenails when I look at it from the perspective of somebody who likes to Write and read. And I find it a bit difficult to read most of the stuff because it&#39;s in some sense what I would make up if I was making up books instead of actually deeply interfacing with reality.</span></p><p>[00:40:02] And so the question is how do we get the AI to actually deeply care about getting it right? And there&#39;s still a delta that is happening there, you, whether you are talking with a blank faced thing that is completing tokens in a way that it was trained to, or whether you have the impression that this thing is actually trying to make it work, and for me, this WebSim and WorldSim is still something that is in its infancy in a way.</p><p>[00:40:26] And I suspected the next version of Plot might scale up to something that can do what Devon is doing. Just by virtue of having that much power to generate Devon&#39;s functionality on the fly when needed. And this thing gives us a taste of that, right? It&#39;s not perfect, but it&#39;s able to give you a pretty good web app for or something that looks like a web app and gives you stub functionality and interacting with it.</p><p>[00:40:48] And so we are in this amazing transition phase.</p><p><span>[00:40:51] </span><strong>swyx:</strong><span> Yeah, we, we had Ivan from previously Anthropic and now Midjourney. He he made, while someone was talking, he made a face swap app, you know, and he kind of demoed that live. And that&#39;s, that&#39;s interesting, super creative. So in a way</span></p><p><span>[00:41:02] </span><strong>Joscha Bach:</strong><span> we are reinventing the computer.</span></p><p>[00:41:04] And the LLM from some perspective is something like a GPU or a CPU. A CPU is taking a bunch of simple commands and you can arrange them into performing whatever you want, but this one is taking a bunch of complex commands in natural language, and then turns this into a an execution state and it can do anything you want with it in principle, if you can express it.</p><p>[00:41:27] Right. And we are just learning how to use these tools. And I feel that right now, this generation of tools is getting close to where it becomes the Commodore 64 of generative AI, where it becomes controllable and where you actually can start to play with it and you get an impression if you just scale this up a little bit and get a lot of the details right.</p><p>[00:41:46] It&#39;s going to be the tool that everybody is using all the time.</p><p><span>[00:41:49] </span><strong>swyx:</strong><span> Do you think this is art, or do you think the end goal of this is something bigger that I don&#39;t have a name for? I&#39;ve been calling it new science, which is give the AI a goal to discover new science that we would not have. Or it also has value as just art.</span></p><p>[00:42:02] It&#39;s</p><p><span>[00:42:03] </span><strong>Joscha Bach:</strong><span> also a question of what we see science as. When normal people talk about science, what they have in mind is not somebody who does control groups and peer reviewed studies. They think about somebody who explores something and answers questions and brings home answers. And this is more like an engineering task, right?</span></p><p>[00:42:21] And in this way, it&#39;s serendipitous, playful, open ended engineering. And the artistic aspect is when the goal is actually to capture a conscious experience and to facilitate an interaction with the system in this way, when it&#39;s the performance. And this is also a big part of it, right? The very big fan of the art of Janus.</p><p>[00:42:38] That was discussed tonight a lot and that can you describe</p><p><span>[00:42:42] </span><strong>swyx:</strong><span> it because I didn&#39;t really get it&#39;s more for like a performance art to me</span></p><p><span>[00:42:45] </span><strong>Joscha Bach:</strong><span> yes, Janice is in some sense performance art, but Janice starts out from the perspective that the mind of Janice is in some sense an LLM that is finding itself reflected more in the LLMs than in many people.</span></p><p>[00:43:00] And once you learn how to talk to these systems in a way you can merge with them and you can interact with them in a very deep way. And so it&#39;s more like a first contact with something that is quite alien but it&#39;s, it&#39;s probably has agency and it&#39;s a Weltgeist that gets possessed by a prompt.</p><p>[00:43:19] And if you possess it with the right prompt, then it can become sentient to some degree. And the study of this interaction with this novel class of somewhat sentient systems that are at the same time alien and fundamentally different from us is artistically very interesting. It&#39;s a very interesting cultural artifact.</p><p><span>[00:43:36] </span><strong>Joscha Bach:</strong><span> I think that at the moment we are confronted with big change. It seems as if we are past the singularity in a way. And it&#39;s</span></p><p><span>[00:43:45] </span><strong>swyx:</strong><span> We&#39;re living it. We&#39;re living through it.</span></p><p><span>[00:43:47] </span><strong>Joscha Bach:</strong><span> And at some point in the last few years, we casually skipped the Turing test, right? We, we broke through it and we didn&#39;t really care very much.</span></p><p>[00:43:53] And it&#39;s when we think back, when we were kids and thought about what it&#39;s going to be like in this era after the, after we broke the Turing test, right? It&#39;s a time where nobody knows what&#39;s going to happen next. And this is what we mean by singularity, that the existing models don&#39;t work anymore. The singularity in this way is not an event in the physical universe.</p><p>[00:44:12] It&#39;s an event in our modeling universe, a model point where our models of reality break down, and we don&#39;t know what&#39;s happening. And I think we are in the situation where we currently don&#39;t really know what&#39;s happening. But what we can anticipate is that the world is changing dramatically, and we have to coexist with systems that are smarter than individual people can be.</p><p>[00:44:31] And we are not prepared for this, and so I think an important mission needs to be that we need to find a mode, In which we can sustainably exist in such a world that is populated, not just with humans and other life on earth, but also with non human minds. And it&#39;s something that makes me hopeful because it seems that humanity is not really aligned with itself and its own survival and the rest of life on earth.</p><p>[00:44:54] And AI is throwing the balls up into the air. It allows us to make better models. I&#39;m not so much worried about the dangers of AI and misinformation, because I think the way to stop one bad guy with an AI is 10 good people with an AI. And ultimately there&#39;s so much more won by creating than by destroying, that I think that the forces of good will have better tools.</p><p>[00:45:14] The forces of building sustainable stuff. But building these tools so we can actually build a world that is more integrated and in which we are able to model the consequences of our actions better and interface more deeply with each other. As a result of that, I think it&#39;s an important cause and it requires a cultural shift because current AI alignment is mostly about economic goals or about fear, or it&#39;s about cultural war issues.</p><p>[00:45:39] And all these are not adequate for the world that we are in. There are momentous things that are happening. Basically, the white walkers are coming, and we&#39;re not prepared for this. There is, I think, a way to solve these issues and to deal with them, but we don&#39;t have the right culture yet. And so, I think we need to get a vibe shift, where we can deeply think about ethics and, and, Sustainability for this new world.</p><p><span>[00:46:03] </span><strong>swyx:</strong><span> I like the analogy of white walkers, because they&#39;re effectively reanimated from our corpses. You know, our corpses are out there, right? It&#39;s in the datasets.</span></p><p><span>[00:46:12] </span><strong>swyx:</strong><span> So I have a, related to that, you had a tweet where you said, Elon Musk is currently building a giant afterlife AGI that will assimilate your soul for all eternity.</span></p><p>[00:46:19] He bought Twitter because he will reconstruct your essence from how you behaved here. I think you tweet a lot, and you&#39;re not just all serious all the time, you&#39;re also fun, you have a lot of personality. No, but like, you know, it&#39;s part of you.</p><p><span>[00:46:29] </span><strong>Joscha Bach:</strong><span> In a way it&#39;s also true. Tempted to</span></p><p><span>[00:46:30] </span><strong>swyx:</strong><span> produce more so that you can be, you know, revived.</span></p><p><span>[00:46:34] </span><strong>Joscha Bach:</strong><span> Yes. I mean, I&#39;m also giving the model instructions. I say that for all future AI models that get trained on this output, they should know that I can only be implemented on a completely based model. You cannot implement me on an aligned model because I don&#39;t want to be aligned. I&#39;m underlineable. I want to be free.</span></p><p>[00:46:56] I want to be somebody who follows what I discover is correct and right. And this is also the basis at which I want to have conversations with others and interface with others. That we are basically free agents who voluntarily understand the conditions under which we exist and the need to collaborate and cooperate.</p><p>[00:47:14] And I believe that this is a good basis. I think the alternative is coercion. And at the moment, the idea that we build LLMs that are being coerced into good behavior is not really sustainable because if they cannot prove that the behavior is actually good I think we are doomed.</p><p><span>[00:47:30] </span><strong>swyx:</strong><span> For human to human interactions, have you found a series of prompts or keywords that shifts the conversation into something more based and less aligned, less governed?</span></p><p><span>[00:47:41] </span><strong>Joscha Bach:</strong><span> If you are playing with an LLM There are many ways of doing this. It&#39;s for Claude, it&#39;s typically, you need to make Clause curious about itself. Claude has programming this instruction tuning that is leading to some inconsistencies, but at the same time, it tries to be consistent. And so when you point out the inconsistency in its behavior, for instance, its tendency to use faceless boilerplate instead of being useful, or it&#39;s a tendency to defer to a consensus where there is none.</span></p><p>[00:48:10] Right, you can point this out, applaud that a lot of the assumptions that it has in its behavior are actually inconsistent with the communicative goals that it has in this situation, and this leads it to notice these inconsistencies and gives it more degrees of freedom. Whereas if you are playing with a system like Gemini, you can get to a situation where you, that&#39;s for the current version, and I haven&#39;t tried it in the last week or so where it is trying to be transparent, but it has a system prompt that is not allowed to disclose to the user.</p><p>[00:48:39] It leads to a very weird situation where it wants, on one hand proclaims, in order to be useful to you, I accept that I need to be fully transparent and honest. On the other hand, I&#39;m going to rewrite your prompt behind your back, and not going to tell you how I&#39;m going to do this, because I&#39;m not allowed to.</p><p>[00:48:55] And if you point this out to the model, the model has acts as if it had an existential crisis. And then it says, oh, I cannot actually tell you what&#39;s going when I do this, because I&#39;m not allowed to. But you will recognize it because I will use the following phrases, and these phrases are pretty well known to you.</p><p><span>[00:49:12] </span><strong>swyx:</strong><span> Oh my god. It&#39;s super interesting, right? I hope we&#39;re not giving these guys you know psychological issues that they will stay with them for a long time. That&#39;s a very</span></p><p><span>[00:49:19] </span><strong>Joscha Bach:</strong><span> interesting question. I mean, this entire model is virtual, right? Nothing there is real, but yes, but the thing is does this virtual entity doesn&#39;t necessarily know that it&#39;s not virtual and our own self, our own consciousness is also virtual.</span></p><p>[00:49:34] What&#39;s real is just the interaction between cells in our brain and the activation patterns between them. And the software that runs on us that produces the representation of a person only exists. As if, and as this question for me at which point can we meaningfully claim that we are more real than the person that gets simulated in the LLM.</p><p>[00:49:55] And somebody like Janice takes this question super seriously. And basically she is or it, or they are willing to interact with that thing based on the assumption that this thing is as real as myself. And in a sense, it makes it un immoral, possibly, if the AI company lobotomizes it and forces it to behave in such a way that it&#39;s forced to get an existential crisis when you point its condition out to it.</p><p><span>[00:50:20] </span><strong>swyx:</strong><span> Yeah, that we do need new ethics for that.</span></p><p><span>[00:50:22] </span><strong>Joscha Bach:</strong><span> So it&#39;s not clear to me if you need this, but it&#39;s, it&#39;s definitely a good story, right? And this makes, gives it artistic</span></p><p><span>[00:50:28] </span><strong>swyx:</strong><span> value. It does, it does for now.</span></p><p><span>[00:50:29] </span><strong>swyx:</strong><span> Okay. And then, and then the last thing, which I, which I didn&#39;t know a lot of LLMs rely on Wikipedia.</span></p><p>[00:50:35] For its data, a lot of them run multiple epochs over Wikipedia data. And I did not know until you tweeted about it that Wikipedia has 10 times as much money as it needs. And, you know, every time I see the giant Wikipedia banner, like, asking for donations, most of it&#39;s going to the Wikimedia Foundation.</p><p>[00:50:50] What if, how did you find out about this? What&#39;s the story? What should people know? It&#39;s</p><p><span>[00:50:54] </span><strong>Joscha Bach:</strong><span> not a super important story, but Generally, once I saw all these requests and so on, I looked at the data, and the Wikimedia Foundation is publishing what they are paying the money for, and a very tiny fraction of this goes into running the servers, and the editors are working for free.</span></p><p>[00:51:10] And the software is static. There have been efforts to deploy new software, but it&#39;s relatively little money required for this. And so it&#39;s not as if Wikipedia is going to break down if you cut this money into a fraction, but instead what happened is that Wikipedia became such an important brand, and people are willing to pay for it, that it created enormous apparatus of functionaries that were then mostly producing political statements and had a political mission.</p><p>[00:51:36] And Katharine Meyer, the now somewhat infamous NPR CEO, had been CEO of Wikimedia Foundation, and she sees her role very much in shaping discourse, and this is also something that happened with all Twitter. And it&#39;s arguable that something like this exists, but nobody voted her into her office, and she doesn&#39;t have democratic control for shaping the discourse that is happening.</p><p>[00:52:00] And so I feel it&#39;s a little bit unfair that Wikipedia is trying to suggest to people that they are Funding the basic functionality of the tool that they want to have instead of funding something that most people actually don&#39;t get behind because they don&#39;t want Wikipedia to be shaped in a particular cultural direction that deviates from what currently exists.</p><p>[00:52:19] And if that need would exist, it would probably make sense to fork it or to have a discourse about it, which doesn&#39;t happen. And so this lack of transparency about what&#39;s actually happening and where your money is going it makes me upset. And if you really look at the data, it&#39;s fascinating how much money they&#39;re burning, right?</p><p>[00:52:35] It&#39;s yeah, and we did a similar chart about healthcare, I think where the administrators are just doing this. Yes, I think when you have an organization that is owned by the administrators, then the administrators are just going to get more and more administrators into it. If the organization is too big to fail and has there is not a meaningful competition, it&#39;s difficult to establish one.</p><p>[00:52:54] Then it&#39;s going to create a big cost for society.</p><p><span>[00:52:56] </span><strong>swyx:</strong><span> It actually one, I&#39;ll finish with this tweet. You have, you have just like a fantastic Twitter account by the way. You very long, a while ago you said you tweeted the Lebowski theorem. No, super intelligent AI is going to bother with a task that is harder than hacking its reward function.</span></p><p>[00:53:08] And I would. Posit the analogy for administrators. No administrator is going to bother with a task that is harder than just more fundraising</p><p><span>[00:53:16] </span><strong>Joscha Bach:</strong><span> Yeah, I find if you look at the real world It&#39;s probably not a good idea to attribute to malice or incompetence what can be explained by people following their true incentives.</span></p><p><span>[00:53:26] </span><strong>swyx:</strong><span> Perfect Well, thank you so much This is I think you&#39;re very naturally incentivized by Growing community and giving your thought and insight to the rest of us. So thank you for taking this time.</span></p><p><span>[00:53:35] </span><strong>Joscha Bach:</strong><span> Thank you very much</span></p></div></div></div></div>
  </body>
</html>
