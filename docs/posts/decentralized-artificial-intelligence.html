<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.chaos-engineering.dev/p/decentralized-artificial-intelligence">Original</a>
    <h1>Decentralized Artificial Intelligence</h1>
    
    <div id="readability-page-1" class="page"><div class=""><div><div dir="auto"><blockquote><p><em>Anyone who considers arithmetical methods of producing random digits is, of course, in a state of sin.</em></p><p><span>-</span><a href="https://dornsifecms.usc.edu/assets/sites/520/docs/VonNeumann-ams12p36-38.pdf" rel="">John Von Neumann</a></p></blockquote><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd96ebb0f-0199-4c76-9fa2-f880f0a06900_996x756.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd96ebb0f-0199-4c76-9fa2-f880f0a06900_996x756.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd96ebb0f-0199-4c76-9fa2-f880f0a06900_996x756.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd96ebb0f-0199-4c76-9fa2-f880f0a06900_996x756.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd96ebb0f-0199-4c76-9fa2-f880f0a06900_996x756.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd96ebb0f-0199-4c76-9fa2-f880f0a06900_996x756.png" width="574" height="435.68674698795184" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/d96ebb0f-0199-4c76-9fa2-f880f0a06900_996x756.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:756,&#34;width&#34;:996,&#34;resizeWidth&#34;:574,&#34;bytes&#34;:null,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:null,&#34;href&#34;:null,&#34;belowTheFold&#34;:false,&#34;topImage&#34;:true,&#34;internalRedirect&#34;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd96ebb0f-0199-4c76-9fa2-f880f0a06900_996x756.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd96ebb0f-0199-4c76-9fa2-f880f0a06900_996x756.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd96ebb0f-0199-4c76-9fa2-f880f0a06900_996x756.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd96ebb0f-0199-4c76-9fa2-f880f0a06900_996x756.png 1456w" sizes="100vw" fetchpriority="high"/></picture></div></a><figcaption>It’s more like this than you’d think.</figcaption></figure></div><p><span>A clever thing about generative models and ChatGPT is that they give you different results for the same prompt (or input). This is done, presumably, by setting the random seed to the computer’s current system clock time just before computing an </span><em>extraordinary</em><span> number of matrix multiplications (or some equivalent in a distributed sense when all of those parameters do not fit in the RAM of a single computer). </span></p><p>This trivial detail gives the illusion that ChatGPT is non-deterministic, but it’s not. </p><p><span>You can </span><a href="https://huggingface.co/docs/transformers/v4.28.1/en/main_classes/text_generation#transformers.GenerationMixin.sample.example" rel="">see this for yourself</a><span> in HuggingFace’s open source ChatGPT alternative: </span><a href="https://huggingface.co/chat/" rel="">HuggingChat</a><span>.</span></p><p>Large Language Models (LLMs)—just like all machine learning models—are an estimated static equation, which means that for a fixed input you will receive a fixed output. Generative models do some probability weighted random sampling to provide a little flair and the mirage of sentience.</p><p>But LLMs are nothing more than a bunch of numbers, multiplications, sums, and a splash of pseudo-random sampling.</p><p><span>OpenAI encountered </span><a href="https://apnews.com/article/chatgpt-ai-data-privacy-italy-66634e4d9ade3c0eb63edab62915066f" rel="">some </a><span>troubles recently, and they’ve done some incredible work to </span><a href="https://apnews.com/article/chatgpt-openai-data-privacy-italy-1e3f070ca86ec234cae4d08ac8443879" rel="">overcome them</a><span>.</span></p><p><span>But OpenAI, MetaAI, Google Research, DeepMind, or anyone else can’t solve the core problem, which is that true Artificial General Intelligence (AGI) needs </span><em>truly</em><span> Open AI; that is to say that no single entity or research lab should be trusted with the power of AGI.</span></p><p><span>After several months of reflection, I’ve come to only one conclusion: </span><em><strong>a cryptographically secure, decentralized ledger is the only solution to making AI safer.</strong></em></p><p><span>I’ve thought for quite some time that blockchain and crypto </span><em>the technologies</em><span>—not necessarily the digital currency—had incredible implications but I didn’t know what for…and it turns out the answer was hiding in the next hype cycle.</span></p><p>I am neither a crypto maximalist, nor even necessarily a crypto advocate. I am, however, a technologist who sees the value of the technology used by most crypto currencies. </p><p><em>As a brief aside, my biggest skepticism with cryptocurrencies is that a non-trivial share of their advocates seem to treat it as a long term store of value which creates an economic disincentive to transact, which then renders it a poor medium of exchange. Regardless, that’s how lots of people have treated Bitcoin, Ethereum, and other tokens.</em></p><p><span>So why do I believe “</span><em><strong>a cryptographically secure, decentralized ledger is the only solution” </strong></em><span>to truly Open AI?</span></p><p>Because it solves some core problems.</p><p><span>As I said, no single entity should be the sole owner of any true AGI. It creates far too much power in the hands of only well-capitalized institutions (i.e., those that can afford the compute necessary to train a </span><em>giganto</em><span> model).</span></p><p>There are other challenges outside of this, too. </p><p><span>The academic literature is ridden with examples of state of the art (SOTA) models that weren’t reproducible and while there’s an </span><a href="https://arxiv.org/pdf/2202.02326.pdf" rel="">ongoing effort to improve this</a><span> suffice it to say that a lot of models aren’t reproducible (maybe even most). </span></p><p>That’s bad science, but the incentives in academia are what they are.</p><p><span>ML industry practitioners have come quite a long way in model reproducibility (i.e., model version control) but in the early days many forgot about </span><em>data version control</em><span>. </span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e4f3dd8-3385-4351-9647-24091a235e8c_1532x1424.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e4f3dd8-3385-4351-9647-24091a235e8c_1532x1424.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e4f3dd8-3385-4351-9647-24091a235e8c_1532x1424.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e4f3dd8-3385-4351-9647-24091a235e8c_1532x1424.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e4f3dd8-3385-4351-9647-24091a235e8c_1532x1424.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e4f3dd8-3385-4351-9647-24091a235e8c_1532x1424.png" width="396" height="367.9862637362637" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/3e4f3dd8-3385-4351-9647-24091a235e8c_1532x1424.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:1353,&#34;width&#34;:1456,&#34;resizeWidth&#34;:396,&#34;bytes&#34;:278771,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e4f3dd8-3385-4351-9647-24091a235e8c_1532x1424.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e4f3dd8-3385-4351-9647-24091a235e8c_1532x1424.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e4f3dd8-3385-4351-9647-24091a235e8c_1532x1424.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3e4f3dd8-3385-4351-9647-24091a235e8c_1532x1424.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a><figcaption>Data is the foundation; software provides high quality data; and ML, hopefully, produces more data. Most importantly, great software begets more data.</figcaption></figure></div><p><span>Quite obviously, </span><em><strong>a model cannot be version controlled unless the data and the code that constructed both the model and the data are version controlled, too</strong></em><span>.</span></p><p><span>Thinking otherwise is dumb</span><em> </em><span>(</span><em>and, remember, that’s not you!</em><span>).</span></p><p>So in order to have reproducibility in general we need model and data reproducibility, and it turns out that a decentralized database that records every version posted to some chain is a very good candidate for that.</p><p><span>Most people don’t </span><em>really</em><span> care that you use their data for things so long as it (1) serves the right product experience and (2) isn’t malicious.</span></p><p>But some people care a lot! And some countries (e.g., Italy or European countries) care 100x more than that.</p><p><span>A benefit of cryptography and decentralization is that you can estimate “local” models without sending data and still contribute back the estimated gradient to the network. Additionally, you could encrypt the data as well to secure it. This is known as </span><a href="https://en.m.wikipedia.org/wiki/Federated_learning" rel="">Federated Learning</a><span> and is an active area of research. </span></p><p>That said, this approach isn’t actually what I think should exist, which are two separate ledgers: one for data and another for learning.</p><p><span>A frequent complaint that users of ChatGPT have is that the model was only trained on data up to September 2021, which means that the data and model are stale. Because it used large scale web data this makes a lot of sense as a practical limitation but for AGI to work, we need </span><em><span>streaming data </span><strong>and</strong><span> continuous learning</span></em><span>.</span></p><p><span>Both of these problems are non-trivial and require quite sophisticated large scale distributed computing and streaming data infrastructure...or they can be solved through decentralization and </span><em><strong>gradient</strong></em><span> mining.</span></p><p><span>I would like to underscore the “Large” in “Large Language Models”, they are very big and costly to run. Which is one of the main reasons why people or labs outside of the technology industry can’t really build these state of the art models</span></p><p><span>.</span></p><p><em><span>As a brief aside, academics, in their attempt to develop novel algorithms, most iterate on novel-ish architectures rather than try to update existing models, which is arguable a lot of wasted compute. </span><a href="https://arxiv.org/pdf/2106.09685.pdf" rel="">LoRA</a><span> is an an extraordinary example of the exact opposite of this.</span></em></p><p><span>Over the last decade, large scale machine learning models benefited greatly from using GPUs instead of CPUs because they are much more efficient at executing matrix multiplications (</span><a href="https://stackoverflow.com/questions/51344018/why-can-gpu-do-matrix-multiplication-faster-than-cpu" rel="">an embarrassingly parallelizable mathematical operation</a><span>).</span></p><p>They also turned out to be incredibly useful for Bitcoin mining. </p><p><span>Miners </span><em>could</em><span> decide to compute gradients (i.e., train a model) instead of transactions on the blockchain and, theoretically, this would be a straightforward migration.</span></p><p>Miners don’t mine for the sake of increasing our carbon emissions—they mine to make money. Therefore, there needs to be an economic incentive to make miners want to mine Gradients.</p><p>This could be a digital currency or whatever.</p><p><span>There also needs to be an incentive to contribute training data. People should be rewarded when they choose to contribute their data (</span><a href="https://www.deso.com/" rel="">DeSo is doing this</a><span>) and even more so for labeling their data.</span></p><p><span>Crypto currencies are often </span><a href="https://www.coinbase.com/learn/crypto-basics/what-is-a-fork#:~:text=their%20underlying%20code.-,A%20fork%20happens%20whenever%20a%20community%20makes%20a%20change%20to,off%20in%20a%20new%20direction." rel="">forked</a><span> and expanded upon for different goals. If we have a decentralized system where computed model weights are published to a decentralized ledger, then we can not only recover models at any point in time but we can also fork them and train them with different goals in mind (e.g., new architectures).</span></p><p><span>Beyond creating an extraordinary lineage of models, in an extreme case of models misbehaving (i.e., humanity’s doom</span></p><p><span>), we could find the point in time and the data that led to a chaotic AGI.</span></p><p>Who would benefit from a decentralized AGI? </p><p>First and foremost, uh, humanity. </p><p>Secondly, I think there would be a lot of implementation opportunities in embedding these new decentralized models, similar to how ChatGPT plugins are now all the rage. If you make the crypto analogy it was exchanges that were useful to users, so one might think an exchange for the usage of these models could ultimately be the answer. </p><p>As the world of technology evolves rapidly over the coming years, I actually think a marketplace for different types of AGI could be a thing. I know the obvious flaw here is “A true AGI would be able to have intelligence across a broad set of use cases” and while maybe that’s true in the future, it’s not true now and I imagine there will be lots of capturable value between now and when that future comes.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c93e648-e8c7-47b5-ba4c-deb58ee08ed4_988x1020.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c93e648-e8c7-47b5-ba4c-deb58ee08ed4_988x1020.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c93e648-e8c7-47b5-ba4c-deb58ee08ed4_988x1020.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c93e648-e8c7-47b5-ba4c-deb58ee08ed4_988x1020.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c93e648-e8c7-47b5-ba4c-deb58ee08ed4_988x1020.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c93e648-e8c7-47b5-ba4c-deb58ee08ed4_988x1020.png" width="338" height="348.94736842105266" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/2c93e648-e8c7-47b5-ba4c-deb58ee08ed4_988x1020.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:1020,&#34;width&#34;:988,&#34;resizeWidth&#34;:338,&#34;bytes&#34;:982972,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c93e648-e8c7-47b5-ba4c-deb58ee08ed4_988x1020.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c93e648-e8c7-47b5-ba4c-deb58ee08ed4_988x1020.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c93e648-e8c7-47b5-ba4c-deb58ee08ed4_988x1020.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c93e648-e8c7-47b5-ba4c-deb58ee08ed4_988x1020.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a><figcaption>For real though.</figcaption></figure></div><p><span>As mentioned throughout this article, a new approach needs to be taken to decentralize LLMs and AI more broadly so that we can attempt to control the inevitable “</span><a href="https://stackoverflow.com/questions/51344018/why-can-gpu-do-matrix-multiplication-faster-than-cpu" rel="">singularity</a><span>”. The approach I propose is analogous to </span><a href="https://bitcoin.org/bitcoin.pdf" rel="">Proof of Work</a><span> but instead of arbitrarily wasting compute, we can use the compute to estimate gradients.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1bff2b7c-34b4-4658-a6ab-1c72473dfbb9_1916x774.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1bff2b7c-34b4-4658-a6ab-1c72473dfbb9_1916x774.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1bff2b7c-34b4-4658-a6ab-1c72473dfbb9_1916x774.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1bff2b7c-34b4-4658-a6ab-1c72473dfbb9_1916x774.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1bff2b7c-34b4-4658-a6ab-1c72473dfbb9_1916x774.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1bff2b7c-34b4-4658-a6ab-1c72473dfbb9_1916x774.png" width="1456" height="588" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/1bff2b7c-34b4-4658-a6ab-1c72473dfbb9_1916x774.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:588,&#34;width&#34;:1456,&#34;resizeWidth&#34;:null,&#34;bytes&#34;:218474,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1bff2b7c-34b4-4658-a6ab-1c72473dfbb9_1916x774.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1bff2b7c-34b4-4658-a6ab-1c72473dfbb9_1916x774.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1bff2b7c-34b4-4658-a6ab-1c72473dfbb9_1916x774.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1bff2b7c-34b4-4658-a6ab-1c72473dfbb9_1916x774.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a><figcaption>A very crude depiction of Proof of Gradient.</figcaption></figure></div><p>I also mentioned that we would need two ledgers: (1) for the model weights and (2) another for the data used for training those weights. These could be treated in the same way as candidate transactions being added to the Blockchain where signatures are used to verify the chain of transactions.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c328bb6-b5f5-410b-9d62-f658af651954_1522x910.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c328bb6-b5f5-410b-9d62-f658af651954_1522x910.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c328bb6-b5f5-410b-9d62-f658af651954_1522x910.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c328bb6-b5f5-410b-9d62-f658af651954_1522x910.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c328bb6-b5f5-410b-9d62-f658af651954_1522x910.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c328bb6-b5f5-410b-9d62-f658af651954_1522x910.png" width="590" height="352.94642857142856" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/2c328bb6-b5f5-410b-9d62-f658af651954_1522x910.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:871,&#34;width&#34;:1456,&#34;resizeWidth&#34;:590,&#34;bytes&#34;:119950,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c328bb6-b5f5-410b-9d62-f658af651954_1522x910.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c328bb6-b5f5-410b-9d62-f658af651954_1522x910.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c328bb6-b5f5-410b-9d62-f658af651954_1522x910.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F2c328bb6-b5f5-410b-9d62-f658af651954_1522x910.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a><figcaption>In this case we would replace transactions with an incremental set of data or updated model weights.</figcaption></figure></div><p><span>All of this may sound a little ridiculous but it’s not. In fact, </span><a href="https://twitter.com/xanderatallah/status/1643356106670981122" rel="">the work has already begun</a><span> by the former CTO of </span><a href="https://opensea.io/" rel="">OpenSea</a><span>.</span></p><p>At the moment, many people (especially on Twitter) are pointing and laughing at crypto enthusiasts after the recent fall in cryptocurrency prices and that is a potential indicator that people have gone too far the other direction in their thinking about the space. </p><p>In general, it’s good to not jump on the bandwagon.</p><p>Happy mining!</p><p>-Francisco 🤠</p><p><span> wrote a banger on </span><a href="https://fintechbusinessweekly.substack.com/p/goldman-offloads-some-marcus-loans" rel="">Goldman&#39;s Offloading of GreenSky</a><span>.</span></p><p><span> wrote an excellent piece on </span><a href="https://substack.com/notes/post/p-118093154" rel="">Fed expectations this week</a><span>.</span></p><p><span>Alex Johnson at</span></p><p><span> as always shared some great thoughts on </span><a href="https://workweek.com/2023/04/15/right-to-win/?utm_source=Sailthru&amp;utm_medium=email&amp;utm_campaign=Fintech%20Takes%2004/14/23&amp;utm_term=Fintech%20Takes" rel="">Winning in Embedded Lending</a><span>.</span></p><p><span>Simon Taylor at </span></p><p><span> </span><a href="https://sytaylor.substack.com/p/fintech-food-do-we-need-narrower" rel="">wrote an excellent piece</a><span> about needing narrower banks and the latest Fintech drama.</span></p><p>Did you like this post? Do you have any feedback? Do you have some topics you’d like me to write about? Do you have any ideas how I could make this better? I’d love your feedback!</p><p><span>Feel free to respond to this email or reach out to me on </span><a href="https://twitter.com/franciscojarceo" rel="">Twitter</a><span>! 🤠</span></p></div></div></div></div>
  </body>
</html>
