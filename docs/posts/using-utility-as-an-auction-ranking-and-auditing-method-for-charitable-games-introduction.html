<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://techforgoodresearch.substack.com/p/using-utility-as-an-auction-ranking">Original</a>
    <h1>Using utility as an auction ranking and auditing method for charitable games: introduction</h1>
    
    <div id="readability-page-1" class="page"><div><div><div><div><article><div class=""><div><div dir="auto"><p><em><span>This is the first of a series of blog posts where I introduce the idea of “charitable games”. Charitable games are game theory based games in which one side offers resources while the other uses them. It’s intended to model scenarios in which NGOs, policy makers and alike need to make charitable decisions. In this series I hope to offer a formalization of this game and a real life application of it, partnering with </span><a href="https://www.womenwin.org/" rel="nofollow ugc noopener">WomenWin</a><span>.</span></em><span>In the context of non-profits we find ourselves in a peculiar modeling setting for traditional game theory scenarios. Instead of basing interactions on a monetary basis, I’m interested in maximizing welfare among beneficiaries.</span></p><p>Throughout this blog post, I’ll refer to large non-profits as “central agents” and smaller subsidiaries as “agents”. Smaller subsidiaries could mean people being directly benefited by the goods distributed by the central agent, sub-projects withing the central agent or local non-profits responsible for passing the goods further on to beneficiaries.</p><p>Resource allocation in this scenario might be challenging because agents are not necessarily motivated to act truthfully. A few different issues might arise:</p><p>a) even though all agents are possibly trying to effectively employ the best use of their resources to optimize for welfare, these efforts might not be aligned with the central agent’s goals;</p><p>b) agents might have access to private information about local demand that won’t be shared with the central agent and;</p><p>c) the agents are at least somewhat more motivated to help their own clients than those of other agents Lundy et al. [1].</p><p><span>The usual method for incentivizing truthful report of agents is to allocate resources via auction. The literature on mechanisms for utility maximization is recent, we have some work by Chakravarty and Kaplan [2] and Hartline and Roughgarden [3]. These approaches focus on minimizing payment in auction based games. However, I’m interested in developing a new subset of games which I’m calling </span><strong>charitable games</strong><span> where there’s no flow of goods nor any sort of monetary transaction from agents to central agents. This is because in the context of non-profits, agents commonly have no resources to participate in any sort of auction based scenario by bidding for goods.</span></p><p>Here I propose the use of a modified first-price sealed-bid multi-agent auction. The traditional FPSB multi-agent auction algorithm has each agent submitting a bid in secret without knowing the bids of the other agents. The resource is awarded to the highest bidder, and the price paid is the amount of the highest bid.</p><p>To address the financial inconsistencies in charitable game scenarios, the model (which will be further explained in the development blog post) aims to use the agents&#39; inputs to calculate their utility. This calculation is based on a function determined by a central agent and a reinforcement learning environment.</p><p>In a nutshell, this approach can be divided into two parts: Firstly, the central agent receives self-declared data from the agents. Using this data, the central agent can calculate the utility function that ranks the agents from those with the highest utility output to those representing the lowest utility values.</p><p>As for the second part of the model, it involves the act of simulating a credible environment in which the agents will be put into test. Each agent will have its own environment and will start off with their self-declared variables. These variables will change over time as the reinforcement learning algorithms aim to optimize for the utility function specified by the central agent. The result of running this scenario will offer us different values of the imputed variables and a new value for the output of the utility function.</p><p>Now the self-regulating function of an auction model&#39;s truthfulness comes into play. We compare both the variables provided by the agents and the final variables obtained from running the reinforcement learning scenarios. If the difference between these two sets of variables is very small, it means the agents were honest and competent—they accurately predicted the impact they would have in a given scenario. If the difference is large, it suggests the agents were either dishonest or failed to access how impactful they could be given a number of resources.</p><p>There are many ways to interpret the results given by this model. For example, one might be more interested in choosing among the agents that better assessed their impact rather than who had the highest utility function. I intend to expand on these considerations further in the development section.</p><p>The advantages of this model consists in running impossible scenarios. In the real world the resources allocated to charities is very limited and they constantly have to make difficult decisions in how to allocate these resources. It’s hardly ever possible to run experiments to figure out what’s the best way of distributing these resources because it’s so costly to do so. This approach has some advantages inherited from it’s highly analytical profile. The fact that the exact same environment will be used for all competing agents adds a degree of fairness to the process, allowing them to compete on an equal footing. It also makes it easy to test the same agents through many different kinds of scenarios. This model&#39;s purpose is to bridge the gap between policy makers or people allocating resources and their future impacts.</p><p><span>However, the disadvantages of this approach are manifold. No model is able to predict accurately diverse and complex human settings like the ones in which NGOs act. The data and models are incomplete, and the individuals often primarily responsible for building them have a very narrow perspective of the scenarios and realities they&#39;re modeling. Therefore, the aim of this work is not to serve as an oracle offering a clear vision of the future, but rather as another information source for those making extremely difficult decisions.</span></p></div></div></div></article></div></div></div></div></div>
  </body>
</html>
