<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://pub.sakana.ai/ctm/">Original</a>
    <h1>Continuous Thought Machines</h1>
    
    <div id="readability-page-1" class="page"><p id="no_javasript_warning">
    <h3>This page requires Javascript. Please enable it to view the website.</h3>
  </p><div id="dtbody">


<dt-byline></dt-byline>

<p>
<figcaption>
  tl;dr
</figcaption>
<figcaption>
  Neurons in brains use timing and synchronization in the way that they compute. This property seems essential for the flexibility and adaptability of biological intelligence. Modern AI systems discard this fundamental property in favor of efficiency and simplicity. We found a way of bridging the gap between the existing powerful implementations and scalability of modern AI, and the biological plausibility paradigm where <b>neuron timing matters</b>. The results have been surprising and encouraging.
<br/>
</figcaption>
</p>



<div id="maze-demo-container">
    <h2>Interactive demonstration</h2>
    <div>
        <div id="maze-demo">
            <!-- <div id="maze-load-overlay" class="maze-load-overlay loading-overlay-inactive">
                <div class="overlay-text">Click/Touch to load maze demo</div>
            </div> -->
            <p>Initializing...</p>
            
            <canvas id="mazeCanvas" width="39" height="39"></canvas>
            
            <div id="controls">
                
                <div>
                    <div>
                        <p>
                            <label for="validOnlyCheckbox">Valid Path Only</label>
                        </p>
                        <p>
                            <label for="autoSolveCheckbox">Auto-solve</label>
                        </p>
                    </div>
                    <div>
                        <p>
                            <label for="showPathCheckbox">Show Path</label>
                        </p>
                        <p>
                            <label for="showOverlayCheckbox">Show Attention Overlay</label>
                        </p>
                    </div>
                </div>
                <p><label for="fpsSlider">Animation FPS:</label>
                    
                    <span id="fpsValueDisplay">60</span>
                </p>
            </div> 
            <p>
                Click to move Start/ End (toggle with &#39;move&#39;)
            </p>
            </div> 
                 
            </div> 
        </div>
    
    



<h2>Introduction</h2>
<p>Neural networks (NNs) were originally inspired by biological brains, yet they remain significantly distinct from their biological counterparts. Brains demonstrate complex neural dynamics that evolve over time, but modern NNs intentionally abstract away such temporal dynamics in order to facilitate large-scale deep learning. For instance, the activation functions of standard NNs can be seen as an intentional abstraction of a neuron&#39;s firing rate, replacing the temporal dynamics of biological processes with a single, static value. Such simplifications, though enabling significant advancements in large-scale machine learning <dt-cite key="lecun2015deep,goodfellow2016deep,wei2022emergent"></dt-cite>, have resulted in a departure from the fundamental principles that govern biological neural computation.</p>
<p>Over hundreds of millions of years, evolution has endowed biological brains with rich neural dynamics, including spike-timing-dependent plasticity (STDP) <dt-cite key="caporale2008spike"></dt-cite> and neuronal oscillations. Emulating these mechanisms, particularly the temporal coding inherent in spike timing and synchrony, presents a significant challenge. Consequently, modern neural networks do not rely on temporal dynamics to perform compute, but rather prioritize simplicity and computational efficiency. This abstraction, while boosting performance on specific tasks, contributes to a recognized gap between the flexible, general nature of human cognition and current AI capabilities, suggesting fundamental components, potentially related to temporal processing, are missing from our current models <dt-cite key="lake2017building,marcus2018deep,chollet2019measure"></dt-cite>.</p>
<div>
  <h4>Why do this research?</h4>
  <p>Indeed, the notably high performance of modern AI across many fields suggests the emulation of neural dynamics is unwarranted. However, the gap between the highly flexible and general nature of human cognition and the current state of modern AI suggests missing components in our current models.</p>
</div>
<p>For these reasons, we argue that time should be a central component of artificial intelligence in order for it to eventually achieve levels of competency that rival or surpass human brains <dt-cite key="cariani2022time,maass2001relevance"></dt-cite>. Therefore, in this work, we address the strong limitation imposed by overlooking neural activity as a central aspect of intelligence. We introduce the <strong>Continuous Thought Machine (CTM)</strong>, a novel neural network architecture designed to explicitly incorporate neural timing as a foundational element. Our contributions are as follows:</p>
<ul>
<li>We introduce a <strong>decoupled internal dimension</strong>, a novel approach to modeling the temporal evolution of neural activity. We view this dimension as that over which thought can unfold in an artificial neural system, hence the choice of nomenclature.</li>
<li>We provide a mid-level abstraction for neurons, which we call <strong>neuron-level models</strong> (NLMs), where every neuron has its own internal weights that process a history of incoming signals (i.e., pre-activations) to activate (as opposed to a static ReLU, for example).</li>
<li>We use <strong>neural synchronization</strong> directly as the latent representation with which the CTM observes (e.g., through an attention query) and predicts (e.g., via a projection to logits). This biologically-inspired design choice puts forward neural activity as the crucial element for any manifestation of intelligence the CTM might demonstrate.</li>
</ul>
<h4>Reasoning models and recurrence</h4>
<p>The frontier of artificial intelligence faces a critical juncture: moving beyond simple input-output mappings towards genuine reasoning capabilities. While scaling existing models has yielded remarkable advancements, the associated computational cost and data demands are unsustainable and raise questions about the long-term viability of this approach. For sequential data, longstanding recurrent architectures <dt-cite key="hochreiter1997long,dey2017gate,medsker1999recurrent"></dt-cite> have largely been superseded by transformer-based approaches <dt-cite key="vaswani2017attention"></dt-cite>. Nevertheless, recurrence is re-emerging as a natural avenue for extending model complexity. Recurrence is promising because it enables iterative processing and the accumulation of information over time. Modern text generation models (sometimes referred to as &#39;reasoning models&#39;) use intermediate generations as a form of recurrence that enables additional compute during test-time. Recently, other works have demonstrated the benefits of the recurrent application of latent layers <dt-cite key="jaegle2021perceiver,geiping2025scaling,yang2023looped"></dt-cite>. While such methods bring us closer to the recurrent structure of biological brains, a fundamental gap nevertheless remains. <strong>We posit that recurrence, while essential, is merely one piece of the puzzle</strong>. The temporal dynamics unlocked by recurrence -- the precise timing and interplay of neural activity -- are equally crucial. The CTM differs from existing approaches in three ways: (1) the decoupled internal dimension enables sequential thought on any conceivable data modality; (2) private neuron-level models enables the consideration of precise neural timing; and (3) neural synchronization used directly as a representation for solving tasks.</p>
<hr/>
<h2>Method</h2>


<p>
<figcaption>
<b>Fig 1.</b> The Continuous Thought Machine: <span>a single step in its internal recurrent process.</span>
</figcaption>
<figcaption>
The CTM unfolds neural activity internally as it thinks about data. At each step (one of which demonstrated above) a truncated history of &#39;pre activations&#39; are collected and used for the <b>Neuron Level Models</b> (NLMs). The history of &#39;post activations&#39; produced by all NLMs over time are kept and used to compute neuron-to-neuron synchronization over time. This result is a <b>Synchronization Representation</b>: a new, parameter-efficient, and <i>evidently powerful</i> representation that the CTM uses to observe (via attention) and predict.
<br/>
</figcaption>
</p>
<p>The Continuous Thought Machine (CTM) is a neural network architecture that enables a novel approach to thinking about data. It departs from conventional feed-forward models by explicitly incorporating the concept of <strong>Neural Dynamics</strong> as the central component to its functionality. The video above gives a pictorial overview of the internal workings of the CTM. We give all technical details, including additional figures and verbose explanations in our <a href="https://arxiv.org/abs/2505.05522" target="_blank">Technical Report</a>. A <a href="https://github.com/SakanaAI/continuous-thought-machines" target="_blank">GitHub repository</a> is also available. We will provide links to relevant parts of the repository as we explain the model below.</p>
<div>
    <figure>
        <img src="https://pub.sakana.ai/ctm/assets/png/architecture.jpeg" alt="CTM architecture"/>
        <figcaption>
        <span><b>Fig 2.</b> CTM architecture</span>: The <span>1</span> synapse model (weights depicted as blue lines) models the cross-neuron interactions to produce pre-activations. For each neuron, a <span>2</span> history of pre-activations is kept, the most recent of which are used by the <span>3</span> neuron-level models (weights depicted as red lines) to produce <span>4</span> post-activations. A <span>5</span> history of post-activations is also kept and used to <span>6</span> compute a synchronization matrix. Neuron pairs are <span>7</span> selected from the synchronization matrix, yielding the <span>8</span> latent representations with which the CTM <span>9</span> produces outputs and modulates data through cross-attention. Modulated data (e.g., attention outputs) are <span>10</span> concatenated with post-activations for the next internal tick.
        </figcaption>
    </figure>
    <figure>
        <table>
            <thead>
                <tr>
                    <th scope="col">Variable</th>
                    <th scope="col">Description</th>
                </tr>
            </thead>
            <tbody>
                <tr>
                    <td>$\mathbf{z}^t$</td> 
                    <td>Post-activations at internal tick $t$, after neuron-level models have been used.</td> 
                </tr>
                <tr>
                    <td>$\theta_{\text{syn}}$</td>
                    <td>Recurrent (synapse) model weights; U-NET-like architecture that connects neurons at a given internal tick, $t$.</td>
                </tr>
                <tr>
                    <td>$\mathbf{a}^t$</td>
                    <td>Pre-activations at internal tick $t$.</td>
                </tr>
                <tr>
                    <td>$\mathbf{A}^t$</td>
                    <td>History of <i>most recent</i> pre-activations, designed as a FIFO list so that they are always length $M$; inputs to neuron-level models.</td>
                </tr>
                <tr>
                    <td>$\theta_{\text{d}}$</td>
                    <td>Weights of a <i>single neuron-level model</i>, $d$ of $D$; MLP architecture, unique weights per neuron.</td>
                </tr>
                <tr>
                    <td>$\mathbf{Z}^t$</td>
                    <td>History of <i>all</i> post-activations up to this internal tick, variable length; used as input for synchronization dot products.</td>
                </tr>
                <tr>
                    <td>$\mathbf{S}^t$</td>
                    <td>Synchronization matrix at internal tick $t$. In practice we use far fewer neurons than $D$ for separate $\mathbf{S}^t_{\text{out}}$ and $\mathbf{S}^t_{\text{action}}$ synchronization representations.</td>
                </tr>
                <tr>
                    <td>$\mathbf{W}_{\text{out}}$, $\mathbf{W}_{\text{in}}$</td>
                    <td>Linear weight matrices that project from $\mathbf{S}^t_{\text{out}}$ and $\mathbf{S}^t_{\text{action}}$ to attention queries and predictions, respectively.</td>
                </tr>
                <tr>
                    <td>$\mathbf{o}^t$</td> 
                    <td>Cross attention output.</td> 
                </tr>
                </tbody>
        </table>
    </figure>
</div>
<p><strong>The CTM consists of three main ideas</strong>:</p>
<ol>
<li>The use of <a href="#internal-ticks">internal recurrence</a>, enabling a dimension over which a concept analogous to <strong>thought</strong> can occur. The entire process visualised in the video above is a single tick; the <a href="#maze-demo">interactive maze demo</a> at the top of the page uses 75 ticks. This recurrence is completely decoupled from any data dimensions.</li>
<li><a href="#neuron-level-models">Neuron-level models</a>, that compute post-activations by applying private (i.e., on a per-neuron basis) MLP models to a <em>history of incoming pre-activations</em>.</li>
<li><a href="#synchronization-representation">Synchronization as a representation</a>, where the neural activity over time is tracked and used to compute how pairs of neurons synchronize with one another over time. This measure of synchronization is the representation with which the CTM takes action and makes predictions. Listing 3 in the <a href="https://arxiv.org/abs/2505.05522" target="_blank">Technical Report</a> shows the logic for this, and Appendix K details how we use a recursive computation for efficiency.</li>
</ol>
<div>
  <h4>But what about data?</h4>
  <div>
    <p>While data is undoubtedly crucial for any modeling, the CTM is designed around the idea of internal recurrence and synchronization, where the role of data is somewhat secondary to the internal process itself.</p>
    <p><a href="#from-data">Input data is attended to</a> and ingested at each internal tick based on the current sychronisation, and similarly for predictions.</p>
  </div>
</div>
<video src="assets/mp4/topvideo.mp4" type="video/mp4" autoplay="" muted="" playsinline="" loop=""></video>
<p>
<figcaption><b>Fig 3.</b> Neural Dynamics when thinking about ImageNet: <span>Each subplot is the activity of a single neuron over time. It is the synchronization between these that forms the representation used by the CTM.</span>
</figcaption>
</p>
<h3 id="internal-ticks">Internal ticks: the &#39;thought&#39; dimension</h3>
<p>We start by introducing the continuous internal dimension: <span><span><math><semantics><mrow><mi>t</mi><mo>∈</mo><mo>{</mo><mn>1</mn><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><mi>T</mi><mo>}</mo></mrow><annotation encoding="application/x-tex">t \in  \{ 1, \ldots ,T \}</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span>t</span><span>∈</span><span>{</span><span>1</span><span>,</span><span>…</span><span>,</span><span>T</span><span>}</span></span></span></span>. Unlike conventional sequential models -- such as RNNs or Transformers -- that process inputs step-by-step according to the sequence inherent in the data (e.g., words in a sentence or frames in a video), the CTM operates along a self-generated timeline of internal <strong>thought steps</strong>. This internal unfolding allows the model to iteratively build and refine its representations, even when processing static or non-sequential data such as images or mazes. To conform with existing nomenclature used in related works <dt-cite key="kirsch2021meta,pedersen2024structurally,kirsch2022introducing,schwarzschild2021can"></dt-cite>, we refer to these thought steps as &#39;internal ticks&#39; from here on.</p>
<div>
  <h4>A dimension over which thought can unfold.</h4>
  <p>The CTM&#39;s internal dimension is that over which the dynamics of neural activity can unfold. We believe that such dynamics are likely a cornerstone of intelligent thought.</p>
</div>
<h3 id="synapses">Recurrent weights: synapses</h3>
<p>A recurrent multi-layer perceptron (MLP structured in a U-NET fashion <dt-cite key="ronneberger2015u"></dt-cite>) acts as a synapse model for the CTM. At any internal tick <span><span><math><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span>t</span></span></span></span>, the synapse model produces what we consider <strong>pre-activations</strong>:</p>
<p><span><span><span><math><semantics><mrow><msup><mrow><mi mathvariant="bold">a</mi></mrow><mi>t</mi></msup><mo>=</mo><msub><mi>f</mi><mrow><msub><mi>θ</mi><mrow><mtext><mi mathvariant="normal">s</mi><mi mathvariant="normal">y</mi><mi mathvariant="normal">n</mi></mtext></mrow></msub></mrow></msub><mo>(</mo><mtext><mi mathvariant="normal">c</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">n</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">t</mi></mtext><mo>(</mo><msup><mrow><mi mathvariant="bold">z</mi></mrow><mi>t</mi></msup><mo separator="true">,</mo><msup><mrow><mi mathvariant="bold">o</mi></mrow><mi>t</mi></msup><mo>)</mo><mo>)</mo><mo>∈</mo><mtext> </mtext><msup><mrow><mi mathvariant="double-struck">R</mi></mrow><mi>D</mi></msup><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">\bold{a}^t = f_{\theta_{\text{syn}}}(\text{concat}(\bold{z}^t, \bold{o}^t)) \in~\mathbb{R}^D,
</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span><span><span>a</span></span><span><span><span><span>​</span></span><span><span>t</span></span></span><span><span><span>​</span></span>​</span></span></span><span>=</span><span><span>f</span><span><span><span><span>​</span></span><span><span><span><span>θ</span><span><span><span><span>​</span></span><span><span><span><span>s</span><span>y</span><span>n</span></span></span></span></span><span><span><span>​</span></span>​</span></span></span></span></span></span><span><span><span>​</span></span>​</span></span></span><span>(</span><span><span>c</span><span>o</span><span>n</span><span>c</span><span>a</span><span>t</span></span><span>(</span><span><span><span>z</span></span><span><span><span><span>​</span></span><span><span>t</span></span></span><span><span><span>​</span></span>​</span></span></span><span>,</span><span><span><span>o</span></span><span><span><span><span>​</span></span><span><span>t</span></span></span><span><span><span>​</span></span>​</span></span></span><span>)</span><span>)</span><span>∈</span><span> </span><span><span><span>R</span></span><span><span><span><span>​</span></span><span><span>D</span></span></span><span><span><span>​</span></span>​</span></span></span><span>,</span></span></span></span></span></p>
<p>where <span><span><math><semantics><mrow><msup><mrow><mi mathvariant="bold">o</mi></mrow><mi>t</mi></msup></mrow><annotation encoding="application/x-tex">\bold{o}^t</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span><span><span>o</span></span><span><span><span><span>​</span></span><span><span>t</span></span></span><span><span><span>​</span></span>​</span></span></span></span></span></span> is <a href="#from-data">from input data</a>. The <span><span><math><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span>M</span></span></span></span> <strong>most recent pre-activations</strong> are then collected into a pre-activation &#39;history&#39;:</p>
<p><span><span><span><math><semantics><mrow><msup><mrow><mi mathvariant="bold">A</mi></mrow><mi>t</mi></msup><mo>=</mo><mrow><mo fence="true">[</mo><mtable><mtr><mtd><mrow><msup><mrow><mi mathvariant="bold">a</mi></mrow><mrow><mi>t</mi><mo>−</mo><mi>M</mi><mo>+</mo><mn>1</mn></mrow></msup></mrow></mtd><mtd><mrow><msup><mrow><mi mathvariant="bold">a</mi></mrow><mrow><mi>t</mi><mo>−</mo><mi>M</mi><mo>+</mo><mn>2</mn></mrow></msup></mrow></mtd><mtd><mrow><mo>⋯</mo></mrow></mtd><mtd><mrow><msup><mrow><mi mathvariant="bold">a</mi></mrow><mi>t</mi></msup></mrow></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo>∈</mo><mtext> </mtext><msup><mrow><mi mathvariant="double-struck">R</mi></mrow><mrow><mi>D</mi><mo>×</mo><mi>M</mi></mrow></msup><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">\bold{A}^t = \begin{bmatrix}
\bold{a}^{t-M+1} &amp; \bold{a}^{t-M+2} &amp; \cdots &amp; \bold{a}^t
\end{bmatrix} \in~\mathbb{R}^{D \times M}.
</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span><span><span>A</span></span><span><span><span><span>​</span></span><span><span>t</span></span></span><span><span><span>​</span></span>​</span></span></span><span>=</span><span><span><span>[</span></span><span><span><span><span><span><span><span>​</span></span><span><span><span><span>a</span></span><span><span><span><span>​</span></span><span><span><span>t</span><span>−</span><span>M</span><span>+</span><span>1</span></span></span></span><span><span><span>​</span></span>​</span></span></span></span></span><span><span><span>​</span></span>​</span></span></span><span></span><span></span><span><span><span><span><span>​</span></span><span><span><span><span>a</span></span><span><span><span><span>​</span></span><span><span><span>t</span><span>−</span><span>M</span><span>+</span><span>2</span></span></span></span><span><span><span>​</span></span>​</span></span></span></span></span><span><span><span>​</span></span>​</span></span></span><span></span><span></span><span><span><span><span><span>​</span></span><span><span>⋯</span></span></span><span><span><span>​</span></span>​</span></span></span><span></span><span></span><span><span><span><span><span>​</span></span><span><span><span><span>a</span></span><span><span><span><span>​</span></span><span><span>t</span></span></span><span><span><span>​</span></span>​</span></span></span></span></span><span><span><span>​</span></span>​</span></span></span></span></span><span><span>]</span></span></span><span>∈</span><span> </span><span><span><span>R</span></span><span><span><span><span>​</span></span><span><span><span>D</span><span>×</span><span>M</span></span></span></span><span><span><span>​</span></span>​</span></span></span><span>.</span></span></span></span></span></p>
<h3 id="neuron-level-models">Neuron-level models</h3>
<p><span><span><math><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span>M</span></span></span></span> effectively defines the length of the <strong>history of pre-activations</strong> that each neuron level model works with. Each neuron, <span><span><math><semantics><mrow><mo>{</mo><mn>1</mn><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><mi>D</mi><mo>}</mo></mrow><annotation encoding="application/x-tex">\{1, \ldots, D\}</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span>{</span><span>1</span><span>,</span><span>…</span><span>,</span><span>D</span><span>}</span></span></span></span>, is then <strong>given its own privately parameterized MLP</strong> that produces what we consider <strong>post-activations</strong>:</p>
<p><span><span><span><math><semantics><mrow><msubsup><mrow><mi mathvariant="bold">z</mi></mrow><mi>d</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msubsup><mo>=</mo><msub><mi>g</mi><mrow><msub><mi>θ</mi><mi>d</mi></msub></mrow></msub><mo>(</mo><msubsup><mrow><mi mathvariant="bold">A</mi></mrow><mi>d</mi><mi>t</mi></msubsup><mo>)</mo><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">\bold{z}_d^{t+1} = g_{\theta_d}(\bold{A}_d^t),
</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span><span><span>z</span></span><span><span><span><span>​</span></span><span><span>d</span></span></span><span><span><span>​</span></span><span><span><span>t</span><span>+</span><span>1</span></span></span></span><span><span><span>​</span></span>​</span></span></span><span>=</span><span><span>g</span><span><span><span><span>​</span></span><span><span><span><span>θ</span><span><span><span><span>​</span></span><span><span>d</span></span></span><span><span><span>​</span></span>​</span></span></span></span></span></span><span><span><span>​</span></span>​</span></span></span><span>(</span><span><span><span>A</span></span><span><span><span><span>​</span></span><span><span>d</span></span></span><span><span><span>​</span></span><span><span>t</span></span></span><span><span><span>​</span></span>​</span></span></span><span>)</span><span>,</span></span></span></span></span></p>
<p>where <span><span><math><semantics><mrow><msub><mi>θ</mi><mi>d</mi></msub></mrow><annotation encoding="application/x-tex">\theta_d</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span><span>θ</span><span><span><span><span>​</span></span><span><span>d</span></span></span><span><span><span>​</span></span>​</span></span></span></span></span></span> are the unique parameters for neuron <span><span><math><semantics><mrow><mi>d</mi></mrow><annotation encoding="application/x-tex">d</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span>d</span></span></span></span>, and <span><span><math><semantics><mrow><msubsup><mrow><mi mathvariant="bold">z</mi></mrow><mi>d</mi><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msubsup></mrow><annotation encoding="application/x-tex">\bold{z}_d^{t+1}</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span><span><span>z</span></span><span><span><span><span>​</span></span><span><span>d</span></span></span><span><span><span>​</span></span><span><span><span>t</span><span>+</span><span>1</span></span></span></span><span><span><span>​</span></span>​</span></span></span></span></span></span> is a single unit in the vector that contains all <strong>post-activations</strong>. <span><span><math><semantics><mrow><msubsup><mrow><mi mathvariant="bold">A</mi></mrow><mi>d</mi><mi>t</mi></msubsup></mrow><annotation encoding="application/x-tex">\bold{A}_d^t</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span><span><span>A</span></span><span><span><span><span>​</span></span><span><span>d</span></span></span><span><span><span>​</span></span><span><span>t</span></span></span><span><span><span>​</span></span>​</span></span></span></span></span></span> is a <span><span><math><semantics><mrow><mi>M</mi></mrow><annotation encoding="application/x-tex">M</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span>M</span></span></span></span>-dimensional vector (time series). The full set of neuron post-activations are then concatenated with  <a href="#from-data">attention output</a> and fed recurrently into <span><span><math><semantics><mrow><msub><mi>f</mi><mrow><msub><mi>θ</mi><mrow><mtext><mi mathvariant="normal">s</mi><mi mathvariant="normal">y</mi><mi mathvariant="normal">n</mi></mtext></mrow></msub></mrow></msub></mrow><annotation encoding="application/x-tex">f_{\theta_{\text{syn}}}</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span><span>f</span><span><span><span><span>​</span></span><span><span><span><span>θ</span><span><span><span><span>​</span></span><span><span><span><span>s</span><span>y</span><span>n</span></span></span></span></span><span><span><span>​</span></span>​</span></span></span></span></span></span><span><span><span>​</span></span>​</span></span></span></span></span></span> to produce pre-activations for next step, <span><span><math><semantics><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">t+1</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span>t</span><span>+</span><span>1</span></span></span></span>, in the unfolding thought process.</p>
<h3 id="synchronization-representation">Synchronization as a representation: modulating data</h3>
<p>How should the CTM interact with the outside world? Specifically, how should the CTM consume inputs and produce outputs? We introduced a timing dimension over which something akin to thought can unfold. We also want the CTM&#39;s relationship with data (its interaction, so to speak) to depend not on a <em>snapshot</em> of the state of neurons (at some <span><span><math><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span>t</span></span></span></span>), but rather on the <strong>ongoing temporal dynamics of neuron activities</strong>. By way of solution, we turn again to natural brains for inspiration and find the concept of neural synchronization <dt-cite key="uhlhaas2009neural"></dt-cite> both fitting and powerful. For synchronization we start by collecting the post-activations into a post-activation &#39;history&#39;:</p>
<p><span><span><span><math><semantics><mrow><msup><mrow><mi mathvariant="bold">Z</mi></mrow><mi>t</mi></msup><mo>=</mo><mrow><mo fence="true">[</mo><mtable><mtr><mtd><mrow><msup><mrow><mi mathvariant="bold">z</mi></mrow><mrow><mn>1</mn></mrow></msup></mrow></mtd><mtd><mrow><msup><mrow><mi mathvariant="bold">z</mi></mrow><mrow><mn>2</mn></mrow></msup></mrow></mtd><mtd><mrow><mo>⋯</mo></mrow></mtd><mtd><mrow><msup><mrow><mi mathvariant="bold">z</mi></mrow><mi>t</mi></msup></mrow></mtd></mtr></mtable><mo fence="true">]</mo></mrow><mo>∈</mo><msup><mrow><mi mathvariant="double-struck">R</mi></mrow><mrow><mi>D</mi><mo>×</mo><mi>t</mi></mrow></msup><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">\bold{Z}^t = \begin{bmatrix}
\bold{z}^{1} &amp; \bold{z}^{2} &amp; \cdots &amp; \bold{z}^t
\end{bmatrix} \in \mathbb{R}^{D \times t}.
</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span><span><span>Z</span></span><span><span><span><span>​</span></span><span><span>t</span></span></span><span><span><span>​</span></span>​</span></span></span><span>=</span><span><span><span>[</span></span><span><span><span><span><span><span><span>​</span></span><span><span><span><span>z</span></span><span><span><span><span>​</span></span><span><span><span>1</span></span></span></span><span><span><span>​</span></span>​</span></span></span></span></span><span><span><span>​</span></span>​</span></span></span><span></span><span></span><span><span><span><span><span>​</span></span><span><span><span><span>z</span></span><span><span><span><span>​</span></span><span><span><span>2</span></span></span></span><span><span><span>​</span></span>​</span></span></span></span></span><span><span><span>​</span></span>​</span></span></span><span></span><span></span><span><span><span><span><span>​</span></span><span><span>⋯</span></span></span><span><span><span>​</span></span>​</span></span></span><span></span><span></span><span><span><span><span><span>​</span></span><span><span><span><span>z</span></span><span><span><span><span>​</span></span><span><span>t</span></span></span><span><span><span>​</span></span>​</span></span></span></span></span><span><span><span>​</span></span>​</span></span></span></span></span><span><span>]</span></span></span><span>∈</span><span><span><span>R</span></span><span><span><span><span>​</span></span><span><span><span>D</span><span>×</span><span>t</span></span></span></span><span><span><span>​</span></span>​</span></span></span><span>.</span></span></span></span></span></p>
<p>The length of <span><span><math><semantics><mrow><msup><mrow><mi mathvariant="bold">Z</mi></mrow><mi>t</mi></msup></mrow><annotation encoding="application/x-tex">\bold{Z}^t</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span><span><span>Z</span></span><span><span><span><span>​</span></span><span><span>t</span></span></span><span><span><span>​</span></span>​</span></span></span></span></span></span> is equal to the current internal tick, meaning that <strong>this dimension is not fixed</strong> and can be arbitrarily large. We define neural synchronization as the matrix yielded by the inner dot product between post-activation histories:</p>
<p><span><span><span><math><semantics><mrow><msup><mrow><mi mathvariant="bold">S</mi></mrow><mi>t</mi></msup><mo>=</mo><msup><mrow><mi mathvariant="bold">Z</mi></mrow><mi>t</mi></msup><mo>⋅</mo><mo>(</mo><msup><mrow><mi mathvariant="bold">Z</mi></mrow><mi>t</mi></msup><msup><mo>)</mo><mo>⊺</mo></msup><mo>∈</mo><mtext> </mtext><msup><mrow><mi mathvariant="double-struck">R</mi></mrow><mrow><mi>D</mi><mo>×</mo><mi>D</mi></mrow></msup><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">\bold{S}^t = \bold{Z}^t \cdot (\bold{Z}^t)^\intercal \in~\mathbb{R}^{D\times D}.
</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span><span><span>S</span></span><span><span><span><span>​</span></span><span><span>t</span></span></span><span><span><span>​</span></span>​</span></span></span><span>=</span><span><span><span>Z</span></span><span><span><span><span>​</span></span><span><span>t</span></span></span><span><span><span>​</span></span>​</span></span></span><span>⋅</span><span>(</span><span><span><span>Z</span></span><span><span><span><span>​</span></span><span><span>t</span></span></span><span><span><span>​</span></span>​</span></span></span><span><span>)</span><span><span><span><span>​</span></span><span><span>⊺</span></span></span><span><span><span>​</span></span>​</span></span></span><span>∈</span><span> </span><span><span><span>R</span></span><span><span><span><span>​</span></span><span><span><span>D</span><span>×</span><span>D</span></span></span></span><span><span><span>​</span></span>​</span></span></span><span>.</span></span></span></span></span></p>
<p>Since this matrix scales in <span><span><math><semantics><mrow><mi>O</mi><mo>(</mo><msup><mi>D</mi><mn>2</mn></msup><mo>)</mo></mrow><annotation encoding="application/x-tex">O(D^2)</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span>O</span><span>(</span><span><span>D</span><span><span><span><span>​</span></span><span><span>2</span></span></span><span><span><span>​</span></span>​</span></span></span><span>)</span></span></span></span> it makes practical sense to subsample <span><span><math><semantics><mrow><mo>(</mo><mi>i</mi><mo separator="true">,</mo><mi>j</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">(i,j)</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span>(</span><span>i</span><span>,</span><span>j</span><span>)</span></span></span></span> row-column pairs, which capture the synchronization between neurons <span><span><math><semantics><mrow><mi>i</mi></mrow><annotation encoding="application/x-tex">i</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span>i</span></span></span></span> and <span><span><math><semantics><mrow><mi>j</mi></mrow><annotation encoding="application/x-tex">j</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span>j</span></span></span></span>. To do so we randomly select <span><span><math><semantics><mrow><msub><mi>D</mi><mtext><mi mathvariant="normal">o</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">t</mi></mtext></msub></mrow><annotation encoding="application/x-tex">D_\text{out}</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span><span>D</span><span><span><span><span>​</span></span><span><span><span>o</span><span>u</span><span>t</span></span></span></span><span><span><span>​</span></span>​</span></span></span></span></span></span> and <span><span><math><semantics><mrow><msub><mi>D</mi><mtext><mi mathvariant="normal">a</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">n</mi></mtext></msub></mrow><annotation encoding="application/x-tex">D_\text{action}</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span><span>D</span><span><span><span><span>​</span></span><span><span><span>a</span><span>c</span><span>t</span><span>i</span><span>o</span><span>n</span></span></span></span><span><span><span>​</span></span>​</span></span></span></span></span></span> <span><span><math><semantics><mrow><mo>(</mo><mi>i</mi><mo separator="true">,</mo><mi>j</mi><mo>)</mo></mrow><annotation encoding="application/x-tex">(i,j)</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span>(</span><span>i</span><span>,</span><span>j</span><span>)</span></span></span></span> pairs from <span><span><math><semantics><mrow><mrow><mi mathvariant="bold">S</mi></mrow></mrow><annotation encoding="application/x-tex">\bold{S}</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span><span>S</span></span></span></span></span>, thus collecting two <strong>synchronization representations</strong>, <span><span><math><semantics><mrow><msubsup><mrow><mi mathvariant="bold">S</mi></mrow><mtext><mi mathvariant="normal">o</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">t</mi></mtext><mi>t</mi></msubsup><mo>∈</mo><mtext> </mtext><msup><mrow><mi mathvariant="double-struck">R</mi></mrow><mrow><msub><mi>D</mi><mtext><mi mathvariant="normal">o</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">t</mi></mtext></msub></mrow></msup></mrow><annotation encoding="application/x-tex">\bold{S}^t_\text{out} \in~\mathbb{R}^{D_\text{out}}</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span><span><span>S</span></span><span><span><span><span>​</span></span><span><span><span>o</span><span>u</span><span>t</span></span></span></span><span><span><span>​</span></span><span><span>t</span></span></span><span><span><span>​</span></span>​</span></span></span><span>∈</span><span> </span><span><span><span>R</span></span><span><span><span><span>​</span></span><span><span><span><span>D</span><span><span><span><span>​</span></span><span><span><span>o</span><span>u</span><span>t</span></span></span></span><span><span><span>​</span></span>​</span></span></span></span></span></span><span><span><span>​</span></span>​</span></span></span></span></span></span> and <span><span><math><semantics><mrow><msubsup><mrow><mi mathvariant="bold">S</mi></mrow><mtext><mi mathvariant="normal">a</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">n</mi></mtext><mi>t</mi></msubsup><mo>∈</mo><mtext> </mtext><msup><mrow><mi mathvariant="double-struck">R</mi></mrow><mrow><msub><mi>D</mi><mtext><mi mathvariant="normal">a</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">n</mi></mtext></msub></mrow></msup></mrow><annotation encoding="application/x-tex">\bold{S}^t_\text{action} \in~\mathbb{R}^{D_\text{action}}</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span><span><span>S</span></span><span><span><span><span>​</span></span><span><span><span>a</span><span>c</span><span>t</span><span>i</span><span>o</span><span>n</span></span></span></span><span><span><span>​</span></span><span><span>t</span></span></span><span><span><span>​</span></span>​</span></span></span><span>∈</span><span> </span><span><span><span>R</span></span><span><span><span><span>​</span></span><span><span><span><span>D</span><span><span><span><span>​</span></span><span><span><span>a</span><span>c</span><span>t</span><span>i</span><span>o</span><span>n</span></span></span></span><span><span><span>​</span></span>​</span></span></span></span></span></span><span><span><span>​</span></span>​</span></span></span></span></span></span>. <span><span><math><semantics><mrow><msubsup><mrow><mi mathvariant="bold">S</mi></mrow><mtext><mi mathvariant="normal">o</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">t</mi></mtext><mi>t</mi></msubsup></mrow><annotation encoding="application/x-tex">\bold{S}^t_\text{out}</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span><span><span>S</span></span><span><span><span><span>​</span></span><span><span><span>o</span><span>u</span><span>t</span></span></span></span><span><span><span>​</span></span><span><span>t</span></span></span><span><span><span>​</span></span>​</span></span></span></span></span></span> can then be projected to an output space as:</p>
<p><span><span><span><math><semantics><mrow><msup><mrow><mi mathvariant="bold">y</mi></mrow><mi>t</mi></msup><mo>=</mo><msub><mrow><mi mathvariant="bold">W</mi></mrow><mrow><mtext><mi mathvariant="normal">o</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">t</mi></mtext></mrow></msub><mo>⋅</mo><msubsup><mrow><mi mathvariant="bold">S</mi></mrow><mtext><mi mathvariant="normal">o</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">t</mi></mtext><mi>t</mi></msubsup><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">\bold{y}^t = \bold{W}_{\text{out}} \cdot \bold{S}^t_\text{out}.
</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span><span><span>y</span></span><span><span><span><span>​</span></span><span><span>t</span></span></span><span><span><span>​</span></span>​</span></span></span><span>=</span><span><span><span>W</span></span><span><span><span><span>​</span></span><span><span><span><span>o</span><span>u</span><span>t</span></span></span></span></span><span><span><span>​</span></span>​</span></span></span><span>⋅</span><span><span><span>S</span></span><span><span><span><span>​</span></span><span><span><span>o</span><span>u</span><span>t</span></span></span></span><span><span><span>​</span></span><span><span>t</span></span></span><span><span><span>​</span></span>​</span></span></span><span>.</span></span></span></span></span></p>

<div>
  <h4>Synchronization enables a very large representation.</h4>
  <p>
      As the model width, D, grows, the synchronization representation grows with
      \(\frac{D \times (D+1)}{2}\), offering opportunities for improved expressiveness without the need for more parameters in order to project a latent space to this size.
    </p>
</div>

<h4 id="from-data">Modulating input data</h4>
<p><span><span><math><semantics><mrow><msubsup><mrow><mi mathvariant="bold">S</mi></mrow><mtext><mi mathvariant="normal">a</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">n</mi></mtext><mi>t</mi></msubsup></mrow><annotation encoding="application/x-tex">\bold{S}^t_\text{action}</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span><span><span>S</span></span><span><span><span><span>​</span></span><span><span><span>a</span><span>c</span><span>t</span><span>i</span><span>o</span><span>n</span></span></span></span><span><span><span>​</span></span><span><span>t</span></span></span><span><span><span>​</span></span>​</span></span></span></span></span></span> can be used to take actions in the world (e.g., via attention as is in our setup):</p>
<p><span><span><span><math><semantics><mrow><msup><mrow><mi mathvariant="bold">q</mi></mrow><mi>t</mi></msup><mo>=</mo><msub><mrow><mi mathvariant="bold">W</mi></mrow><mrow><mtext><mi mathvariant="normal">i</mi><mi mathvariant="normal">n</mi></mtext></mrow></msub><mo>⋅</mo><msubsup><mrow><mi mathvariant="bold">S</mi></mrow><mtext><mi mathvariant="normal">a</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">n</mi></mtext><mi>t</mi></msubsup></mrow><annotation encoding="application/x-tex">\bold{q}^t = \bold{W}_{\text{in}} \cdot \bold{S}^t_\text{action}
</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span><span><span>q</span></span><span><span><span><span>​</span></span><span><span>t</span></span></span><span><span><span>​</span></span>​</span></span></span><span>=</span><span><span><span>W</span></span><span><span><span><span>​</span></span><span><span><span><span>i</span><span>n</span></span></span></span></span><span><span><span>​</span></span>​</span></span></span><span>⋅</span><span><span><span>S</span></span><span><span><span><span>​</span></span><span><span><span>a</span><span>c</span><span>t</span><span>i</span><span>o</span><span>n</span></span></span></span><span><span><span>​</span></span><span><span>t</span></span></span><span><span><span>​</span></span>​</span></span></span></span></span></span></span></p>
<p>where <span><span><math><semantics><mrow><msub><mrow><mi mathvariant="bold">W</mi></mrow><mrow><mtext><mi mathvariant="normal">o</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">t</mi></mtext></mrow></msub></mrow><annotation encoding="application/x-tex">\bold{W}_{\text{out}}</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span><span><span>W</span></span><span><span><span><span>​</span></span><span><span><span><span>o</span><span>u</span><span>t</span></span></span></span></span><span><span><span>​</span></span>​</span></span></span></span></span></span> and <span><span><math><semantics><mrow><msub><mrow><mi mathvariant="bold">W</mi></mrow><mrow><mtext><mi mathvariant="normal">i</mi><mi mathvariant="normal">n</mi></mtext></mrow></msub></mrow><annotation encoding="application/x-tex">\bold{W}_{\text{in}}</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span><span><span>W</span></span><span><span><span><span>​</span></span><span><span><span><span>i</span><span>n</span></span></span></span></span><span><span><span>​</span></span>​</span></span></span></span></span></span> are learned weight matrices that project synchronization into vectors for observation (e.g., attention queries, <span><span><math><semantics><mrow><msup><mrow><mi mathvariant="bold">q</mi></mrow><mi>t</mi></msup></mrow><annotation encoding="application/x-tex">\bold{q}^t</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span><span><span>q</span></span><span><span><span><span>​</span></span><span><span>t</span></span></span><span><span><span>​</span></span>​</span></span></span></span></span></span>) or outputs (e.g., logits, <span><span><math><semantics><mrow><msup><mrow><mi mathvariant="bold">y</mi></mrow><mi>t</mi></msup></mrow><annotation encoding="application/x-tex">\bold{y}^t</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span><span><span>y</span></span><span><span><span><span>​</span></span><span><span>t</span></span></span><span><span><span>​</span></span>​</span></span></span></span></span></span>). Even though there are <span><span><math><semantics><mrow><mo>(</mo><mi>D</mi><mo>×</mo><mo>(</mo><mi>D</mi><mo>+</mo><mn>1</mn><mo>)</mo><mo>)</mo><mi mathvariant="normal">/</mi><mn>2</mn></mrow><annotation encoding="application/x-tex">(D \times (D+1))/2</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span>(</span><span>D</span><span>×</span><span>(</span><span>D</span><span>+</span><span>1</span><span>)</span><span>)</span><span>/</span><span>2</span></span></span></span> unique pairings in <span><span><math><semantics><mrow><msup><mrow><mi mathvariant="bold">S</mi></mrow><mi>t</mi></msup></mrow><annotation encoding="application/x-tex">\bold{S}^t</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span><span><span>S</span></span><span><span><span><span>​</span></span><span><span>t</span></span></span><span><span><span>​</span></span>​</span></span></span></span></span></span>, <span><span><math><semantics><mrow><msub><mi>D</mi><mtext><mi mathvariant="normal">o</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">t</mi></mtext></msub></mrow><annotation encoding="application/x-tex">D_\text{out}</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span><span>D</span><span><span><span><span>​</span></span><span><span><span>o</span><span>u</span><span>t</span></span></span></span><span><span><span>​</span></span>​</span></span></span></span></span></span> and <span><span><math><semantics><mrow><msub><mi>D</mi><mtext><mi mathvariant="normal">a</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">n</mi></mtext></msub></mrow><annotation encoding="application/x-tex">D_\text{action}</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span><span>D</span><span><span><span><span>​</span></span><span><span><span>a</span><span>c</span><span>t</span><span>i</span><span>o</span><span>n</span></span></span></span><span><span><span>​</span></span>​</span></span></span></span></span></span> can be orders of magnitude smaller than this. That said, the full synchronization matrix is a large representation that has high future potential.</p>
<p>In most of our experiments we used standard cross attention <dt-cite key="vaswani2017attention"></dt-cite>:</p>
<p><span><span><span><math><semantics><mrow><msup><mrow><mi mathvariant="bold">o</mi></mrow><mi>t</mi></msup><mo>=</mo><mtext><mi mathvariant="normal">A</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">n</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">n</mi></mtext><mo>(</mo><mi>Q</mi><mo>=</mo><msup><mrow><mi mathvariant="bold">q</mi></mrow><mi>t</mi></msup><mo separator="true">,</mo><mi>K</mi><mi>V</mi><mo>=</mo><mtext><mi mathvariant="normal">F</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">e</mi><mi mathvariant="normal">E</mi><mi mathvariant="normal">x</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">c</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">r</mi></mtext><mo>(</mo><mtext><mi mathvariant="normal">d</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">a</mi></mtext><mo>)</mo><mo>)</mo></mrow><annotation encoding="application/x-tex">\bold{o}^t = \text{Attention}(Q=\bold{q}^t, KV=\text{FeatureExtractor}(\text{data}))
</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span><span><span>o</span></span><span><span><span><span>​</span></span><span><span>t</span></span></span><span><span><span>​</span></span>​</span></span></span><span>=</span><span><span>A</span><span>t</span><span>t</span><span>e</span><span>n</span><span>t</span><span>i</span><span>o</span><span>n</span></span><span>(</span><span>Q</span><span>=</span><span><span><span>q</span></span><span><span><span><span>​</span></span><span><span>t</span></span></span><span><span><span>​</span></span>​</span></span></span><span>,</span><span>K</span><span>V</span><span>=</span><span><span>F</span><span>e</span><span>a</span><span>t</span><span>u</span><span>r</span><span>e</span><span>E</span><span>x</span><span>t</span><span>r</span><span>a</span><span>c</span><span>t</span><span>o</span><span>r</span></span><span>(</span><span><span>d</span><span>a</span><span>t</span><span>a</span></span><span>)</span><span>)</span></span></span></span></span></p>
<p>where a &#39;FeatureExtractor&#39; model, e.g., a ResNet <dt-cite key="he2016deep"></dt-cite>, is first used to build useful local features for the keys and values. <span><span><math><semantics><mrow><msup><mrow><mi mathvariant="bold">o</mi></mrow><mrow><mi>t</mi></mrow></msup></mrow><annotation encoding="application/x-tex">\bold{o}^{t}</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span><span><span>o</span></span><span><span><span><span>​</span></span><span><span><span>t</span></span></span></span><span><span><span>​</span></span>​</span></span></span></span></span></span> is concatenated with <span><span><math><semantics><mrow><msup><mrow><mi mathvariant="bold">z</mi></mrow><mrow><mi>t</mi><mo>+</mo><mn>1</mn></mrow></msup></mrow><annotation encoding="application/x-tex">\bold{z}^{t+1}</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span><span><span>z</span></span><span><span><span><span>​</span></span><span><span><span>t</span><span>+</span><span>1</span></span></span></span><span><span><span>​</span></span>​</span></span></span></span></span></span> for the next cycle of recurrence.</p>
<h3 id="loss-function">Loss function: optimizing across internal ticks</h3>
<p>The CTM produces outputs at each internal tick, <span><span><math><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span>t</span></span></span></span>. A key question arises: how do we optimize the model across this internal temporal dimension?  Let <span><span><math><semantics><mrow><msup><mrow><mi mathvariant="bold">y</mi></mrow><mi>t</mi></msup><mo>∈</mo><msup><mrow><mi mathvariant="double-struck">R</mi></mrow><mrow><mi>C</mi></mrow></msup></mrow><annotation encoding="application/x-tex">\bold{y}^t \in \mathbb{R}^{C}</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span><span><span>y</span></span><span><span><span><span>​</span></span><span><span>t</span></span></span><span><span><span>​</span></span>​</span></span></span><span>∈</span><span><span><span>R</span></span><span><span><span><span>​</span></span><span><span><span>C</span></span></span></span><span><span><span>​</span></span>​</span></span></span></span></span></span> be the prediction vector (e.g., probabilities of classes) at internal tick <span><span><math><semantics><mrow><mi>t</mi></mrow><annotation encoding="application/x-tex">t</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span>t</span></span></span></span>, where <span><span><math><semantics><mrow><mi>C</mi></mrow><annotation encoding="application/x-tex">C</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span>C</span></span></span></span> is the number of classes.  Let <span><span><math><semantics><mrow><msub><mi>y</mi><mrow><mi>t</mi><mi>r</mi><mi>u</mi><mi>e</mi></mrow></msub></mrow><annotation encoding="application/x-tex">y_{true}</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span><span>y</span><span><span><span><span>​</span></span><span><span><span>t</span><span>r</span><span>u</span><span>e</span></span></span></span><span><span><span>​</span></span>​</span></span></span></span></span></span> be the ground truth target. We can compute a loss at each internal tick using a standard loss function, such as cross-entropy:</p>
<p><span><span><span><math><semantics><mrow><msup><mrow><mi mathvariant="script">L</mi></mrow><mi>t</mi></msup><mo>=</mo><mtext><mi mathvariant="normal">C</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">s</mi><mi mathvariant="normal">E</mi><mi mathvariant="normal">n</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">p</mi><mi mathvariant="normal">y</mi></mtext><mo>(</mo><msup><mrow><mi mathvariant="bold">y</mi></mrow><mi>t</mi></msup><mo separator="true">,</mo><msub><mi>y</mi><mrow><mi>t</mi><mi>r</mi><mi>u</mi><mi>e</mi></mrow></msub><mo>)</mo><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">    \mathcal{L}^t = \text{CrossEntropy}(\bold{y}^t, y_{true}),
</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span><span><span>L</span></span><span><span><span><span>​</span></span><span><span>t</span></span></span><span><span><span>​</span></span>​</span></span></span><span>=</span><span><span>C</span><span>r</span><span>o</span><span>s</span><span>s</span><span>E</span><span>n</span><span>t</span><span>r</span><span>o</span><span>p</span><span>y</span></span><span>(</span><span><span><span>y</span></span><span><span><span><span>​</span></span><span><span>t</span></span></span><span><span><span>​</span></span>​</span></span></span><span>,</span><span><span>y</span><span><span><span><span>​</span></span><span><span><span>t</span><span>r</span><span>u</span><span>e</span></span></span></span><span><span><span>​</span></span>​</span></span></span><span>)</span><span>,</span></span></span></span></span></p>
<p>and a corresponding certainty measure, <span><span><math><semantics><mrow><msup><mrow><mi mathvariant="script">C</mi></mrow><mi>t</mi></msup></mrow><annotation encoding="application/x-tex">\mathcal{C}^t</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span><span><span>C</span></span><span><span><span><span>​</span></span><span><span>t</span></span></span><span><span><span>​</span></span>​</span></span></span></span></span></span>. We compute certainty simply as 1 - normalised entropy. We compute <span><span><math><semantics><mrow><msup><mrow><mi mathvariant="script">L</mi></mrow><mi>t</mi></msup></mrow><annotation encoding="application/x-tex">\mathcal{L}^t</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span><span><span>L</span></span><span><span><span><span>​</span></span><span><span>t</span></span></span><span><span><span>​</span></span>​</span></span></span></span></span></span> and <span><span><math><semantics><mrow><msup><mrow><mi mathvariant="script">C</mi></mrow><mi>t</mi></msup></mrow><annotation encoding="application/x-tex">\mathcal{C}^t</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span><span><span>C</span></span><span><span><span><span>​</span></span><span><span>t</span></span></span><span><span><span>​</span></span>​</span></span></span></span></span></span> for all <span><span><math><semantics><mrow><mi>t</mi><mo>∈</mo><mo>{</mo><mn>1</mn><mo separator="true">,</mo><mo>…</mo><mo separator="true">,</mo><mi>T</mi><mo>}</mo></mrow><annotation encoding="application/x-tex">t \in \{1, \ldots, T\}</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span>t</span><span>∈</span><span>{</span><span>1</span><span>,</span><span>…</span><span>,</span><span>T</span><span>}</span></span></span></span>, yielding losses and certainties per internal tick, <span><span><math><semantics><mrow><mrow><mi mathvariant="script">L</mi></mrow><mo>∈</mo><msup><mrow><mi mathvariant="double-struck">R</mi></mrow><mrow><mi>T</mi></mrow></msup></mrow><annotation encoding="application/x-tex">\mathcal{L} \in \mathbb{R}^{T}</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span><span>L</span></span><span>∈</span><span><span><span>R</span></span><span><span><span><span>​</span></span><span><span><span>T</span></span></span></span><span><span><span>​</span></span>​</span></span></span></span></span></span> and <span><span><math><semantics><mrow><mrow><mi mathvariant="script">C</mi></mrow><mo>∈</mo><msup><mrow><mi mathvariant="double-struck">R</mi></mrow><mrow><mi>T</mi></mrow></msup></mrow><annotation encoding="application/x-tex">\mathcal{C} \in \mathbb{R}^{T}</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span><span>C</span></span><span>∈</span><span><span><span>R</span></span><span><span><span><span>​</span></span><span><span><span>T</span></span></span></span><span><span><span>​</span></span>​</span></span></span></span></span></span>.</p>
<p>A natural question arises: how should we reduce <span><span><math><semantics><mrow><mrow><mi mathvariant="script">L</mi></mrow></mrow><annotation encoding="application/x-tex">\mathcal{L}</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span><span>L</span></span></span></span></span> into a scalar loss for learning? Our loss function is designed to optimize CTM performance across the internal thought dimension. Instead of relying on a single step (e.g., the last step), which can incentivize the model to only output at that specific step, we dynamically aggregate information from two internal ticks: the point of minimum loss and the point of maximum certainty:</p>
<ul>
<li>the point of minimum loss: <span><span><math><semantics><mrow><msub><mi>t</mi><mn>1</mn></msub><mo>=</mo><mtext><mi mathvariant="normal">a</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">g</mi><mi mathvariant="normal">m</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">n</mi></mtext><mo>(</mo><mrow><mi mathvariant="script">L</mi></mrow><mo>)</mo></mrow><annotation encoding="application/x-tex">t_1=\text{argmin}(\mathcal{L})</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span><span>t</span><span><span><span><span>​</span></span><span><span>1</span></span></span><span><span><span>​</span></span>​</span></span></span><span>=</span><span><span>a</span><span>r</span><span>g</span><span>m</span><span>i</span><span>n</span></span><span>(</span><span><span>L</span></span><span>)</span></span></span></span>; and</li>
<li>the point of maximum certainty: <span><span><math><semantics><mrow><msub><mi>t</mi><mn>2</mn></msub><mo>=</mo><mtext><mi mathvariant="normal">a</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">g</mi><mi mathvariant="normal">m</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">x</mi></mtext><mo>(</mo><mrow><mrow><mi mathvariant="script">C</mi></mrow></mrow><mo>)</mo></mrow><annotation encoding="application/x-tex">t_2=\text{argmax}({\mathcal{C}})</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span><span>t</span><span><span><span><span>​</span></span><span><span>2</span></span></span><span><span><span>​</span></span>​</span></span></span><span>=</span><span><span>a</span><span>r</span><span>g</span><span>m</span><span>a</span><span>x</span></span><span>(</span><span><span><span>C</span></span></span><span>)</span></span></span></span>.</li>
</ul>
<p>This approach is advantageous because it means that the CTM can perform meaningful computations across multiple internal ticks, naturally facilitates a curriculum effect, and enables the CTM to tailor computation based on problem difficulty. The final loss is computed as:</p>
<p><span><span><span><math><semantics><mrow><mi>L</mi><mo>=</mo><mfrac><mrow><msup><mrow><mi mathvariant="script">L</mi></mrow><mrow><msub><mi>t</mi><mn>1</mn></msub></mrow></msup><mo>+</mo><msup><mrow><mi mathvariant="script">L</mi></mrow><mrow><msub><mi>t</mi><mn>2</mn></msub></mrow></msup></mrow><mrow><mn>2</mn></mrow></mfrac><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">    L = \frac{\mathcal{L}^{t_1} + \mathcal{L}^{t_2}}{2}.
</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span>L</span><span>=</span><span><span></span><span><span><span><span><span>​</span></span><span><span><span>2</span></span></span></span><span><span><span>​</span></span><span></span></span><span><span><span>​</span></span><span><span><span><span><span>L</span></span><span><span><span><span>​</span></span><span><span><span><span>t</span><span><span><span><span>​</span></span><span><span>1</span></span></span><span><span><span>​</span></span>​</span></span></span></span></span></span><span><span><span>​</span></span>​</span></span></span><span>+</span><span><span><span>L</span></span><span><span><span><span>​</span></span><span><span><span><span>t</span><span><span><span><span>​</span></span><span><span>2</span></span></span><span><span><span>​</span></span>​</span></span></span></span></span></span><span><span><span>​</span></span>​</span></span></span></span></span></span><span><span><span>​</span></span>​</span></span></span><span></span></span><span>.</span></span></span></span></span></p>
<div>
  <h4>More information in our Technical Report.</h4>
  <div>
    <p>Please take a look at our <a href="https://arxiv.org/abs/2505.05522" target="_blank">Technical Report</a> for more information.</p>
    <p>Specifically, it includes additional information on how we enable the CTM to learn short versus long time dependency.</p>
  </div>
</div>
<hr/>
<h2>Experiment: ImageNet</h2>
<div id="imagenet-experiment">
    <div> 
        <div id="imagenet-demos">
            <h3>Demonstrations</h3>
            
            
            <figcaption>
                <span><b>Fig 4.</b> Thinking about Images</span>: Top left is the average attention weighting (of the 16 heads shown) when the CTM observes the image on the right. Class predictions are shown on the bottom left and the certainty is shown on the bottom right (<span>green</span> denotes a correct prediction). The small images at the bottom are buttons to load other examples, showing a diversity of certainties and correctness.
            </figcaption>
        </div>
        <div>
            <h3>Results</h3>
            
            <div>
                <p>This is a subset of results from our ImageNet experiments (see the <a href="https://arxiv.org/abs/2505.05522" target="_blank">Technical Report</a> for more). Crucially, the CTM enables <b>Adaptive Compute</b> where the internal steps, (<i>how much thought the CTM is putting into the problem</i>) can be cut short. These figures show what can be expected in terms of accuracy when cutting thinking short. Only marginal gains are had past a certain point, but gains nonetheless.</p>
                <p> Fig 4. shows where the CTM looks as it reasons about the data. We show the <b>Attention Weights</b> for all 16 heads and demark where the model is looking for each (and on average at the top). The predictions are shown on the bottom left and certainty over time on the bottom right. Fig 6. shows a visualization of <b>Neural Activity</b> as the CTM thinks about a single image: note the multi-scale structure and how activity seems to &#39;flow&#39;.
            </p></div>
            
            <figcaption>
                <span><b>Fig 6.</b> Neural activity</span>: visualised in 2D using a <a href="https://umap-learn.readthedocs.io/en/latest/" target="_blank">UMAP</a> projection. Each neuron is shown as an individual dot, scaling in size with absolute magnitude, and color with value (<span>blue</span> for negative, <span>red</span> for positive). We show similar visualizations inside later demonstrations.
            </figcaption>
        </div>
        <div>
            <h3>Discussion</h3>
            <p>We never set out to train a model that achieved some remarkable new state-of-the-art performance on ImageNet. AI researchers already expect high performance on ImageNet after over a decade of research that uses it. Instead, we wanted to show just how different and interesting <b>the CTM&#39;s interaction with data</b> can be. The videos on the left/above demonstrate the thought process the CTM undertakes and the figures show its benefits.
            </p><p>Let&#39;s contextualize just what&#39;s going on here: the CTM is looking around these images, all the while building up its prediction, all by using the <b>synchronization of neural activity</b> directly as a representation. The <a href="#neural-dynamics">neural dynamics</a> we showed earlier are actually examples of dynamics from a CTM observing ImageNet! The paths output by the CTM in <a href="#maze-demo">the maze demo</a> are akin to the class predictions made here.
            </p><h4>The missing ingredient: TIME</h4>
            <p><b>Biological intelligence is still superior to AI in many cases</b> <dt-cite key="chollet2024arc,phan2025humanitysexamshort,lake2017building,ren2024brain"></dt-cite>. Biological brains solve tasks very differently to conventional neural networks, which might explain why this is the case. It might be that <a href="https://www.thetransmitter.org/neuroai/the-brain-holds-no-exclusive-rights-on-how-to-create-intelligence/" target="_blank">biological intelligence pays heed to time</a> in ways that modern AI simply does not. In this work, we aimed to develop a model that approaches problem-solving in a manner more aligned with biological brains, emphasizing the central role of the precise timing and interplay of neural dynamics. The interpretable and intuitive outcome we point at in the video demonstrations is very exciting as it suggests that the CTM is indeed leveraging time to its advantage, in order to reason about data.</p>
            <p>The details on model hyper-parameters can be found in the <a href="https://arxiv.org/abs/2505.05522" target="_blank">Technical Report</a>.</p>
        </div>
    </div> 
</div>

<h2>Experiment: Solving 2D Mazes - doing it the hard way</h2>
<div id="maze-experiment">
    <div> 
        <div>
            <h3>The why and the how</h3>
            <p>
            Solving mazes is a challenging task for machines <dt-cite key="zhang2025t,schwarzschild2021can,bansal2022end"></dt-cite>, where only the current <a href="https://openai.com/index/thinking-with-images/" target="_blank">bleeding edge models perform well</a> on fairly simple <a href="https://featurecrew.io/tests/maze" target="_blank">mazes</a>. Even so, existing methods either require careful design of the data/objective (e.g., outputs are images instead of a <i>solution</i>), or extensive tool use (e.g., LLMs that perform well at this), indicating that the underlying <b>intelligent reasoning</b> required to solve a maze, step-by-step, is not evidenced by these approaches.
            </p>
            <p>
            We trained n CTM on a new setup, requiring it to directly predict a path (truncated for simplicity) from start to finish in the form of steps: <b>L</b>eft, <b>R</b>ight, <b>U</b>p, <b>D</b>own, or <b>W</b>ait. A small version of the resultant model can be explored in the <a href="#maze-demo">interactive demo at the top of this page</a>. We show a demonstration of larger model here. Remarkably, the attention pattern is intuitive and follows the solution, all while using neural synchronization as a representation. It even generalizes beyond the truncated path! See the <a href="https://arxiv.org/abs/2505.05522" target="_blank">Technical Report</a>.
            </p>
            <h3>Demonstration</h3>
            
            <figcaption>
                <span><b>Fig 7.</b> Thinking about mazes</span>: each animation segment shows 75 internal ticks of the CTM when it is provided with the input maze. We show the route as it is constructed through the internal &#39;thought process&#39;, showing only the valid route (i.e., ignoring predictions through walls; see the associated toggle on the <a href="#maze-demo">demo</a>). 16 attention heads&#39; weights are shown at the bottom and the average is overlayed on the maze to show where the CTM is focusing. We &#39;teleport&#39; the CTM to its resultant predicted location until it lands on the target and then load a new maze.
            </figcaption>
        </div>
        <div>
            <h3 id="maze-results">Results</h3>
            
            <h3>Generalization</h3>
            <p>Each video below shows how well the CTM generalizes to bigger and more complex mazes, while retaining its reasoning prowess. To generate these we used a CTM trained to solve a path up to length 100 on 39 x 39 mazes, but the mazes shown here are of size 99 x 99 and the full paths are roughly 6x as long.</p>
            
        </div>
        <div>
            <h3>Discussion</h3>
            <p>Why run these experiments? We know that neural networks can be tailored to solve 2D mazes if we present the data in the &#34;right&#34; way. But, when presented in a fashion that requires a clear process through which the model must progress, existing methods fall short. Even current SoTA LLMs rely on tool use, which is impressive in its own right, but somewhat unsatisfying: an intelligent machine should be demonstrably intelligent, and humans don&#39;t require tools to solve these mazes. </p>
            <p>We set out to show that the CTM has the capacity to learn when complex reasoning is required, unlike the most comparable baseline methods. We also show how the CTM generalizes to larger and more complex mazes, indicating that its internal reasoning is not merely memorization, but rather a more natural and correct way to solve the underlying maze problem. Importantly, we made no specific structural changes to the model compared to the <a href="#imagenet-experiment">CTM we trained for ImageNet</a>; the only meaningful structural change was to output the solution as a 2D class space, applying cross entropy for each step.
            </p><h4>A World Model</h4>
            <p>We chose our setup carefully: (1) we used <b>no positional embedding</b> for attention; and (2) we required that the models predict the routes directly as a string of classes (e.g., go left, left, right, up, etc.). By forgoing positional embedding the CTM must build an <b>internal world model</b> in order to query the data and navigate the maze. The fact that it does so in such a convincing fashion is remarkable. </p>
            <h4>Where to go from here?</h4>
            <p>We have some strong evidence that the CTM is capable of solving challenging problems, and it does so in intuitive and interesting ways. The fact that it can solve mazes by building an internal world model &#34;on the fly&#34; without any positional embedding opens up avenues for future research. For instance, we would like to see how the CTM finds its way around more complex environments (e.g., games or videos) without any explicit positional encodings.</p>
        </div>
    </div> 
</div>
<h2>Experiment: Parity</h2>
<div id="parity-experiment">
    <div> 
        <div>
            <h3>Sequential data, non-sequentially</h3>
            <p>
            The parity of a binary sequence, given by the sign of the product of its elements, can reasonably be predicted by an RNN when the data is fed sequentially - the model need only maintain an internal state, flipping a &#39;switch&#39; whenever a negative number if encountered. When the entire sequence is provided at once, however, the task is significantly more challenging<dt-cite key="graves2016adaptive"></dt-cite>.
            </p>
            <p>
            We trained CTMs to solve a variant of this parity task: the model is input with a 64-length binary vector, and must predict the <i>cumulative</i> parity at each of the 64 positions.
            </p>
            <h3>Demonstration</h3>
            
            <figcaption>
                <span><b>Fig 9.</b> Determining the cumulative parity of a sequence</span>: shown are the movements of the attention weights from each of the 8 heads. Overlayed on the input sequences is the trajectory of the attention weight argmax. The larger sequences depict the models predictions and targets.
            </figcaption>
        </div>
        <div>
            <h3>Results</h3>
            
                <p>
                We compare the accuracy of CTMs trained with different numbers of internal ticks to parameter matched LSTMs. We found that CTMs with over 75 internal ticks could reliably solve this task, with some runs achieving 100% accuracy. The LSTMs, on the other hand, struggled to learn with over 10 internal ticks, suggesting that LSTMs are not well suited to unfolding an internal thought dimension.
                </p>
                <p>
                The left/above demonstration shows the solving process of the CTM: the movement of the attention weights, as well as their argmax overlayed on the inputs, the models predictions, the target and the neuron activations. Notice how the attention moves <b>backwards</b> through the data and determines the solution after observing the entire input. Some attention heads display interpretable behavior, such as the first attention head which attends to only negative parity positions (\(\blacksquare\)).
                </p>
            </div>
        <div>
   <h3>Learning sequential algorithms</h3>
            <p>We visualise the learned algorithms by plotting the accuracy (top) and attention weights (bottom) over the 75 internal ticks for each position in the 64-length sequence, at different points during training. One model (left) attends to the data in reverse order before predicting the cumulative parity at once; the other attends forward, predicting parity incrementally. Both achieve perfect accuracy.
            </p>
            <p>
            The ability of the CTM to search through the data in reverse order, suggests that the CTM is carrying out some form of planning, building up its understanding of the data before making a final decision -- the CTM is capable of forming and following a strategy.
            </p>
            <p>
                <figure>
                    <video src="assets/mp4/parity/run1.mp4" type="video/mp4" autoplay="" muted="" playsinline="" loop=""></video>
                    <figcaption>
                        <span><b>Fig 11a.</b> 75-Internal Tick CTM 1</span>: learns to attend to the data in reverse order, predicting the parity at the end of the reasoning process.
                    </figcaption>
                </figure>
                <figure>
                    <video src="assets/mp4/parity/run3.mp4" type="video/mp4" autoplay="" muted="" playsinline="" loop=""></video>
                        <figcaption>
                        <span><b>Fig 11b.</b> 75-Internal Tick CTM 2</span>: learns to attend from beginning to end, and with it, increasing its certainty in each prediction.
                    </figcaption>
                </figure>
            </p>
        </div>
    </div> 
</div>
<h2>Experiment: Q&amp;A MNIST</h2>
<div id="parity-experiment">
    <div> 
        <div>
            <h3>Memory via Synchronization</h3>
            <p>
            To assess the CTM’s ability to memorise and recall information, we design a Question and Answering (Q&amp;A) MNIST task. In this task, the model first observes a sequence of MNIST digits, followed by a series of interleaved index and operator embeddings that specify which digits should be recalled and which modular operation should be applied. Once all digits and index/operator embeddings have been presented, a zero-tensor flag signals the model to produce its final answer. An example is shown below.
            </p>
            <figure>
                <img src="https://pub.sakana.ai/ctm/assets/png/qamnist/qamnist_example.svg" alt="Accuracy during training"/>
                <figcaption>
                    <span><b>Fig 12.</b> Q&amp;A MNIST example</span>: a typical sequence observed by the model.
                </figcaption>
            </figure>
            <p>
            In our experiments, the memory length of the CTMs is such that the MNIST digits will always lie outside of the activation history window used by the neuron-level models. In this way, the CTM must organize its activations such that it can recall digits are later timesteps.
            </p>
            <h3>Demonstration</h3>
            
            <figcaption>
                <span><b>Fig 13.</b>Observing digits and answering questions</span>: the model is shown MNIST digits followed by operator and index embeddings which specifies the modular operation at the top. Shown also is the attention weights for the digits and the models predictions.
            </figcaption>
        </div>
        <div>
            <h3>Results</h3>
            <div>
                <figure>
                    <img src="https://pub.sakana.ai/ctm/assets/png/qamnist/accuracy_comparison.svg" alt="Accuracy during training"/>
                    <figcaption>
                        <span><b>Fig 14.</b> Accuracy during training</span>: for both CTMs and LSTMs trained with 1 internal tick per input and 10 internal ticks per input.
                    </figcaption>
                </figure>
                </div>
                <p>
                Our results show that, while the LSTM outperforms the CTM when only a single internal tick is used to process each input, the LSTM becomes more unstable when more internal ticks are used. The CTM, on the other hand, exhibits stronger performance with increasing internal ticks, achieving over 95% accuracy in the most challenging in-distribution task. 
                </p>
                <p>
                Furthermore, we highlight the ability of the CTM to recall digit values observed many timesteps in the past, arising purely from the organization and synchronization of neurons. This strong performance suggests that processing timing information through the synchronization of neuron activations may be a powerful mechanism for memorization and recall.
                </p>
            </div>
        <div>
            <h3>Generalization</h3>
            <p>
            We examine the generalization capabilities of the CTM by measuring the accuracy of the model when input with more digits or index-operator embeddings than observed during training, depicted below, with the training regime marked in red. We find that both the CTM and the LSTM baseline can generalize to an increased number of operations. Empirically, we find that this generalization arises from the model’s approach to solving the task: each time a new index embedding is presented, the model computes and stores the result of the specified operation, regardless of whether the answer flag has been given. This enables it to continue processing a stream of index and operator embeddings without needing to wait for a final signal.
            </p>
            
            <figcaption>
                <span><b>Fig 15.</b> Generalization:</span> accuracy of the CTM and LSTM for different numbers of input digits and operations. The red line indicates the training regime. For the CTM, performance scales with the number of internal ticks, while the converse is true for the LSTM.
            </figcaption>
        </div>
        </div>
    </div> 

<hr/>
<h2>Additional experiments</h2>
<h3>CTM versus humans</h3>
<p>In this section we test the CTM using CIFAR-10, comparing it to human performance, a feed-forward baseline, and an LSTM baseline. The purpose of this experiment was to contextualize the performance of the CTM alongside a standard feed-forward baseline, an LSTM baseline that also uses internal ticks for reasoning (potentially), and humans. We used a restricted backbone to highlight the differences between models (details in the <a href="https://arxiv.org/abs/2505.05522" target="_blank">Technical Report</a>).</p>
<p>We used two datasets of human labels for CIFAR-10; we call these CIFAR-10D <dt-cite key="ho2018cifar10"></dt-cite> owing to its calibration of difficulty levels, and CIFAR-10H <dt-cite key="peterson2019human"></dt-cite> originally used to quantify human uncertainty. CIFAR-10D can be found at <a href="https://sites.google.com/site/hophuoctien/projects/virec/cifar10-classification" target="_blank">here</a> and CIFAR-10H can be found <a href="https://github.com/jcpeterson/cifar-10h" target="_blank">here</a>.</p>

<p>For the human calibration we used the probabilities provided in CIFAR-10H, which were computed using guesses from multiple humans using the available human datasets. We computed calibration (Fig 16b.) as we did for ImageNet: we compute the predictive probability as the average probability for the chosen class over all internal ticks (for both CTM and LSTM). The CTM demonstrates the best calibration, even when compared to humans.</p>

<p>Fig 17. shows the neural activities for the CTM and the LSTM baseline. The CTM yields rich, diverse, and complex dynamics with multiple interesting features, including periodic behavior (there is <b>no periodic driving function</b>). The distinct difference between the CTM and LSTM neural activities is evidence that the two novel elements of the CTM (<a href="#neuron-level-models">neuron-level models</a> and <a href="#synchronization-representation">synchronization as a representation</a>) enable neural dynamics as a fundamental computational mechanic.</p>
<h3>CIFAR-100, ablation studies</h3>
<p>Fig 18. shows what happens when we vary the number of neurons (i.e., the model width) while keeping all else constant, including the training time. As with other models, a wider network could evidently benefit from a longer training time or different training hyper-parameters, hence the reduction in accuracy in Fig 18a. For Fig 18b. and Fig 18c. we set out to understand how unique the <a href="#neuron-level-models">Neuron-level models</a> tend to be, and that was related to the model width, as measured by the cosine similarity between the dynamics of different neurons. Fig 18b. shows that with a wider model (i.e., more neurons), we see more diversity instead of less. One might expect that with more neurons there is less &#39;space&#39; for diversity, but we observed the opposite.</p>

<p>Fig 19. shows the relationship between predictions and the number of internal ticks used by the CTM. We trained several CTMs (again keeping all other variables constant). In Fig 19b. we plot the distributions of the data over which steps the CTM is most certain (i.e., <span><span><math><semantics><mrow><msub><mi>t</mi><mn>2</mn></msub></mrow><annotation encoding="application/x-tex">t_2</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span><span>t</span><span><span><span><span>​</span></span><span><span>2</span></span></span><span><span><span>​</span></span>​</span></span></span></span></span></span> in <a href="#loss-function">the loss function</a>). What this shows is that the CTM uses a wide range of steps to become most certain about the data it observes. For each setup (25, 50 and 100 internal ticks), there are two concentrated areas in the distributions, indicating that the CTM is following separate internal processes depending on the data.</p>

<h3>Sorting real numbers</h3>
<p>For these experiments we trained a CTM to sort 30 real numbers from <span><span><math><semantics><mrow><mrow><mi mathvariant="script">N</mi></mrow><mo>(</mo><mn>0</mn><mo separator="true">,</mo><msub><mrow><mi>I</mi></mrow><mrow><mn>3</mn><mn>0</mn></mrow></msub><mo>)</mo></mrow><annotation encoding="application/x-tex">\mathcal{N}(0, {I}_{30})</annotation></semantics></math></span><span aria-hidden="true"><span></span><span></span><span><span><span>N</span></span><span>(</span><span>0</span><span>,</span><span><span><span>I</span></span><span><span><span><span>​</span></span><span><span><span>3</span><span>0</span></span></span></span><span><span><span>​</span></span>​</span></span></span><span>)</span></span></span></span>. The purpose of this experiment was twofold: (1) to understand if and when the CTM applies more or less compute in a controlled environment; and (2) see if we can train the CTM to output a sequence in sequential order using the <a href="https://pytorch.org/docs/stable/generated/torch.nn.CTCLoss.html">CTC loss</a>. This CTM could sort a length 30 list of real numbers approximately 80% of the time.</p>

<h3>Reinforcement Learning</h3>
<p>We have shown that the CTM can process non-sequential data via an continuous thought dimension. Here, we extend the CTM to tasks involving interation with an external environment, training CTMs with proximal policy optimization<dt-cite key="schulman2017proximal"></dt-cite> to solve a navigation task and partially observable variants of CartPole and Acrobot<dt-cite key="MinigridMiniworld23,towers2024gymnasium"></dt-cite>. In this setting, the CTM receives an observation, process it using a fixed number of internal thought steps, and outputs the next action. The history of activations is continuous across environment steps, such that activations from past environment steps can affect the present decision making process.</p>
<div>
  <figure>
    <video src="assets/mp4/rl/activations.mp4" type="video/mp4" autoplay="" muted="" playsinline="" loop=""></video>
    <figcaption>
    <span><b>Fig 21a.</b> CTM solving the MiniGrid Four Rooms task</span>: evidencing that the CTM can use a leverage a continuous history of activations to interact with the world.
    </figcaption>
  </figure>
  <figure>
    <img src="https://pub.sakana.ai/ctm/assets/png/rl/episode_lengths_avg.png" alt="CTM Training Curves of MiniGrid Four Rooms"/>
    <figcaption>
    <span><b>Fig 21b.</b>Training curves</span>: for this navigation task (episode length during training). Although the LSTM learns slightly faster, both solve the task and converge to the same average episode length.
    </figcaption>
  </figure>
</div>
<p>Although our results show that the CTM achieves a comparable performance to the LSTM baseline, the central goal of this section is provide evidence that the CTM can learn in a continuous environment.</p>
<hr/>
<h2>Conclusion</h2>
<p>The Continuous Thought Machine (CTM) represents a novel step towards bridging computational efficiency with biological plausibility in artificial intelligence. By moving beyond traditional pointwise activation functions to private neuron-level models, the CTM cultivates far richer neuron dynamics. Crucially, it leverages neural synchronization as a powerful and fundamentally new type of representation - distinct from the activation vectors prevalent since the early days of neural networks. This direct use of neuron dynamics as a first-class representational citizen allows the CTM to exhibit behaviors qualitatively different from contemporary models.</p>
<p>Our research demonstrates the tangible benefits of this approach. The CTM can dynamically build representations over time for tasks like image classification, form rich internal maps to attend to specific input data without positional embeddings, and naturally exhibit adaptive computation. Furthermore, it learns to synchronize neural dynamics to store and retrieve memories beyond its immediate activation history. This internal processing also lends itself to greater interpretability, as seen in its methodical solving of mazes and parity tasks.</p>
<p>Remarkably, the core CTM architecture remained largely consistent across a diverse range of challenging tasks, requiring only input/output module adjustments. This versatility and trainability were particularly evident in complex scenarios like maze navigation. The CTM succeeded with minimal tuning, where a traditional model like the LSTMs still struggled even after significant tuning efforts.</p>
<p>This work underscores a vital, yet often underexplored, synergy between neuroscience and machine learning. While modern AI is ostensibly brain-inspired, the two fields often operate in surprising isolation. The CTM serves as a testament to the power of drawing inspiration from biological principles. By starting with such inspiration and iteratively following the emergent, interesting behaviors, we developed a model with unexpected capabilities, such as its surprisingly strong calibration in classification tasks, a feature that was not explicitly designed for.</p>
<p>It is crucial to note that our approach advocates for borrowing concepts from biology rather than insisting on strict, literal plausibility; real neurons may not access their activation history as modeled in the CTM, yet emergent phenomena like traveling waves still manifest. This nuanced balance between practicality and biological inspiration opens a landscape of new research directions, which may hold the key to unlocking capabilities currently missing in AI, potentially leading to systems that exhibit more human-like intelligence and address its current limitations.</p>
<p>When we initially asked, &#34;why do this research?&#34;, we hoped the journey of the CTM would provide compelling answers. By embracing light biological inspiration and pursuing the novel behaviors observed, we have arrived at a model with emergent capabilities that exceeded our initial designs. We are committed to continuing this exploration, borrowing further concepts to discover what new and exciting behaviors will emerge, pushing the boundaries of what AI can achieve.</p>
</div></div>
  </body>
</html>
