<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://news.ycombinator.com/item?id=44490863">Original</a>
    <h1>Launch HN: Morph (YC S23) – Apply AI code edits at 4,500 tokens/sec</h1>
    
    <div id="readability-page-1" class="page"><div><td colspan="2"></td><td><div><p>Hey HN, I’m Tejas at Morph. We’ve built a blazing-fast model for applying AI-generated code edits directly into your files at 4,500+ tokens/sec. No more slow full-file rewrites or brittle search-and-replace hacks.</p><p>Here&#39;s a demo video: <a href="https://www.youtube.com/watch?v=LdT8epGHJPk" rel="nofollow">https://www.youtube.com/watch?v=LdT8epGHJPk</a>.</p><p>Why? AI spits out code that can’t reliably be inserted into existing code. Full file rewrites, brittle search-and-replace hacks are too slow, expensive, or error-prone.</p><p>Morph&#39;s approach:</p><p>- Your agent outputs edits “lazily”, referencing unmodified lines in the existing file (ex: // ...existing code...)</p><p>- Morph instantly applies these edits to a file using our Fast Apply model + speculative decoding against the original file, making AI patches fast, reliable, and production-ready.</p><p>This approach was pioneered by Cursor last year, but their models aren’t available as APIs—so we built Morph for developers everywhere (with a large free tier!)</p><p>Live demo (no signup): <a href="https://morphllm.com/dashboard">https://morphllm.com/dashboard</a> and docs: <a href="https://docs.morphllm.com/quickstart">https://docs.morphllm.com/quickstart</a></p><p>We have 2 Fast Apply models: morph-v3-fast - 4500+ tok/sec, and morph-v3-large - 2500+ tok/sec. These models power Fast Apply at create.xyz, databutton, continue.dev, and more!</p><p>We also provide retrieval models for embedding + reranking.
Next Up: Inline Edit Model (Cmd-K): Extremely fast inline edits - keep dev flow state; and Morph Tab API: Our Next Edit Prediction model guesses your next code edit + action with sub-500ms latency. It&#39;s currently in private beta, but you can request early access here: <a href="https://morphllm.com/tab">https://morphllm.com/tab</a></p><p>Hot takes:</p><p>1) Raw inference speed matters more than incremental accuracy gains for dev UX—agree or disagree?</p><p>2) Full-file rewrites by frontier models are legacy—Fast Apply edits win on speed, cost, reliability.</p><p>3) As benchmarks on narrow tasks saturate to 99%+, complexity is shifting from single frontier models to specialized inference-optimized models. As frontier models move upmarket, they&#39;ll leave simple tasks behind, and they&#39;ll be used to do tasks only frontier models can do</p><p>We’d love to hear your ideas and experiences with coding agents!</p></div></td></div></div>
  </body>
</html>
