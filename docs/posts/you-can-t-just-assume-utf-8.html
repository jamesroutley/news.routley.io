<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://csvbase.com/blog/9">Original</a>
    <h1>You can&#39;t just assume UTF-8</h1>
    
    <div id="readability-page-1" class="page"><div>
      <div>
        <p>Humans speak countless different languages.  Not only are these languages
incompatible, but runtime transpilation is a real pain.  Sadly, every
<a href="https://en.wikipedia.org/wiki/Esperanto">standardisation</a>
<a href="https://en.wikipedia.org/wiki/Lojban">initiative</a> has failed.</p>
<p>At least there is someone to blame for this state-of-affairs: God.  It was him,
after-all, who cursed humanity to speak different languages, in an <a href="https://www.kingjamesbibleonline.org/Genesis-11-7/">early
dispute over a controversial property
development</a>.</p>
<p>However, mankind can only blame itself for the fact that <em>computers</em> struggle
to talk to each other.</p>
<p>And one of the biggest problems is the most simple: computers do not agree on
how to write letters in binary.</p>
<h2>How to write letters in binary</h2>
<p>How are letters encoded into binary?</p>
<p>Let&#39;s take the character &#34;A&#34; for example.  It was assigned the number 65 in the
American Standard Code for Information Interchange, or
<a href="https://man7.org/linux/man-pages/man7/ascii.7.html">ASCII</a>.  This numbering
was <a href="https://codepoints.net/U+0041">grandfathered into</a> Unicode, except that
they the Unicode people write the number 65 in hexadecimal, as <code>U+0041</code>.  And
they call it a &#34;codepoint&#34;.</p>
<p>Easy enough - at least the number for &#34;A&#34; enjoys wide consensus.  But computers
can&#39;t just store decimal numbers, they can only store binary.</p>
<p>In the most popular character encoding, UTF-8, character number 65 (&#34;A&#34;) is
written:</p>
<p><code>01000001</code></p>
<p>Only the second and final bits are <code>1</code>, or &#34;on&#34;.  The second bit is worth 64
and the last bit is worth 1.  Those two sum up to 65.  Easy peasy.</p>
<p>Another popular encoding is UTF-16, mainly in the world of Windows, Java and
JavaScript.  65 is represented in UTF-16 this way:</p>
<p><code>01000001 00000000</code></p>
<p>That&#39;s much the same, except the UTF-16 uses (at least) two full bytes for each
character, but doesn&#39;t need any more bits to represent 65, so the second byte
is blank.</p>
<p>What about the other encodings?  Here are just a few of the other popular ones:</p>
<ul>
<li><a href="https://en.wikipedia.org/wiki/Windows-1252">Win-1252</a>, a non-Unicode
encoding, used where European languages are spoken</li>
<li><a href="https://en.wikipedia.org/wiki/KOI8-RU">KOI8</a> - non-Unicode, used where the
<a href="https://en.wikipedia.org/wiki/Cyrillic_script">Cyrillic alphabet</a> is</li>
<li><a href="https://en.wikipedia.org/wiki/GB_18030">GB18030</a> - is Unicode, but mainly used in mainland China</li>
<li><a href="https://en.wikipedia.org/wiki/Big5">Big5</a> - non-Unicode, widely used where
Traditional Chinese is</li>
<li><a href="https://en.wikipedia.org/wiki/Shift_JIS">Shift_JIS</a> - non-Unicode, used in Japan</li>
</ul>
<p>Well, all these other encodings also grandfathered in the ASCII letters, so
they all represent <code>A</code> as:</p>
<p><code>01000001</code></p>
<p>Just like UTF-8 does.</p>
<p>So happy days.  This is why the basic western alphabet usually works even when
the rest of the document is <a href="https://en.wikipedia.org/wiki/Mojibake">a garbled
mess</a>.  Many popular encodings - with
the notable exception of UTF-16 - follow ASCII at least for the Latin alphabet.</p>
<p>Well, so far, so good.  But now let&#39;s look at a trickier character.  The euro
sign, €.  It is numbered <a href="https://codepoints.net/U+20AC">8364</a> (<code>U+20AC</code>) by
the Unicode consortium.</p>
<p>In UTF-8, 8364 is represented by:</p>
<p><code>11100010 10000010 10101100</code></p>
<p>Notice that it takes three bytes in UTF-8.  UTF-8 is a &#34;variable-length&#34;
character encoding - the higher the Unicode number goes, the more bytes are
required.  (This is actually true for UTF-16 as well, but more rarely.)</p>
<p>In UTF-16 however, 8364 is encoded completely differently:</p>
<p><code>10101100 00100000</code></p>
<p>Win-1252, however, doesn&#39;t follow Unicode.  Instead, it numbers the euro sign
as 128.  Then it represents 128 this way:</p>
<p><code>10000000</code></p>
<p>So just the first bit is on, worth 128.</p>
<p>And this is where the trouble starts.  Once you leave the leafy suburbs of the
English alphabet, the representations quickly go to hell in an hand-basket.</p>
<p><code>€</code> is completely unrepresentable in KOI8.</p>
<p>In GB18030, € is encoded:</p>
<p><code>10100010 11100011</code></p>
<p>In Big5, € is:</p>
<p><code>10100011 11100001</code></p>
<p>In Shift JIS, it is:</p>
<p><code>10000000 00111111</code></p>
<p>All completely different and completely incompatible.  If you assume UTF-8 you
will get absolute nonsense.</p>
<h2>How to tell which encoding is being used?</h2>
<p>Some formats dictate the encoding, as JSON mandates UTF-8.  That certainly
keeps things simple - as soon as you know it&#39;s JSON, you know it must be UTF-8.</p>
<p>Other times, it&#39;s possible to transmit the encoding &#34;out-of-band&#34;.  HTTP allows
you to put the encoding in the <code>Content-Type</code> header:</p>
<div><pre><span></span><span>Content-type</span><span>:</span><span> </span><span>text</span><span>/</span><span>html</span><span>;</span><span> </span><span>charset</span><span>=</span><span>ISO-8859-1</span><span></span>
</pre></div>
<p>And some formats have an &#34;in-band&#34; way to signal the encoding.  For example,
some text files have the header:</p>
<div><pre><span></span><span># -*- encoding: utf-16be -*-</span><span></span>
</pre></div>
<p>Though that&#39;s a bit of a mind-bender because you need to be able to read the
file already in order to find that bit.</p>
<p>But what if there is no label?</p>
<p>And what if the label is wrong?  As I will come on to, this is not uncommon.</p>
<p>CSV files, in particular, have no way to signal, in-band, which encoding is
used.  You can&#39;t put a comment, because there is no space - and csv readers
will be unable to parse your csv in most cases.  And many popular tools that
work with CSV files (MS Excel) do not use UTF-8.</p>
<p>What then?</p>
<p>The answer is: statistics.</p>
<h2>Detecting the encoding with statistics</h2>
<p>There are two basic strategies which are used to detect the encoding of an
unlabelled text string.</p>
<ol>
<li>Byte-level</li>
<li>Character-level</li>
</ol>
<p>Most implementations use byte-level first, then character level next, if
necessary.</p>
<h3>Byte level heuristics</h3>
<p>The byte level is fairly straight forward.  You can just look at the bytes and
say whether they are plausible for a given character encoding.</p>
<p>For example, as I said above, UTF-16 (mostly) uses two bytes per character.
For Latin text (eg English) that tends to result in a lot of &#34;blank&#34; second
bytes.  Happily, many markup languages use a lot of Latin text (eg <code>&lt;</code>, <code>&gt;</code>,
<code>[</code>, <code>]</code> and so on), even if the document is not in a Latin script.  If your
test string contains lots and lots of blank second bytes - well, then it&#39;s
likely that it&#39;s UTF-16.</p>
<p>There are other giveaways.  Imagine you are a web-browser and a link has taken
the user to a file whose first two bytes are these:</p>
<p><code>00111100 00100001</code></p>
<p>If this were UTF-16, these two bytes would be ℼ, a symbol called <a href="https://codepoints.net/U+213C">&#34;double
struck small pi&#34;</a>, numbered in Unicode as 8508
(U+213C).  Is that a common first character in an HTML file?</p>
<p>Or, perhaps, is it more likely to be the two character sequence <code>&lt;!</code> encoded
with UTF-8?  Perhaps the following bytes are <code>doctype&gt;</code>, or the standard
boilerplate of any HTML document?  Just a hint!</p>
<p>Another giveaway are specific bytes.  UTF-16 frustratingly comes in two
versions, one where you write the bits in the normal way and one where you
write them all backwards.  In order for people to tell these two forms apart
the standard for UTF-16 includes a <a href="https://en.wikipedia.org/wiki/Byte_order_mark">&#34;byte order
mark&#34;</a> that you can put at the
front of a text stream to indicate which version you&#39;ve used.  This pair of
bytes doesn&#39;t occur very often in other encodings, and certainly not at the
start, so it&#39;s usually a good hint about what follows.</p>
<p>So bytes can get you pretty far.  If you can narrow it down unambiguously to
UTF-8 or UTF-16 at this point, your job is finished.</p>
<h3>Character level heuristics</h3>
<p>The tricky cases tend to be non-Unicode single byte encodings.  For example,
telling Win-1252 apart from KOI8, as both use the otherwise blank 1st bit of
ASCII to encode different things.</p>
<p>How do you tell these apart?  By frequency analysis.  You look at the letters
that would be present in the document, for example if it were KOI8 and ask &#34;is
this a typical distribution of letters for a Cyrillic document?&#34;.</p>
<p>Here is a basic algorithm:</p>
<ul>
<li>Exclude all encodings ruled out by prior byte-level heuristics</li>
<li>
For each remaining possible encoding <code>X</code><ul>
<li>Parse the input as though it were encoded with <code>X</code></li>
<li>Compare the frequencies of the characters in the string with those in a
known frequency table</li>
<li>Optionally, also compare the <em>pairs</em> of letters (eg <code>qu</code>) with a
known frequency table</li>
<li>If they are a good match, return <code>X</code></li>
</ul>
</li>
<li>Otherwise, fail</li>
</ul>
<p>Often you can also tell which language the document is in as well this way -
that&#39;s one way that web browsers know to pop up the &#34;do you want to translate
this page&#34; dialogue box.</p>
<h2>Does it really work?</h2>
<p>Heuristics tend to make people uneasy but the answer is: yes.  It works
surprisingly well.  It certainly works far better than simply assuming that the
text is UTF-8 - and ultimately that is the benchmark.</p>
<p>It probably should not be a surprise the statistics work well.  They often work
well on languages, from the <a href="https://paulgraham.com/better.html">first effective spam
filters</a> to, well, <a href="https://research.google.com/pubs/archive/35179.pdf">many
things</a>.</p>
<p>Heuristics are also important because people get the encoding wrong.</p>
<p>It would seem reasonable to assume that if you exporting a Excel sheet as a csv
file in the most recent release of MS Excel that you would get UTF-8.  Or maybe
UTF-16.  You would be wrong.  By default, in most configurations, Excel will
output your CSV encoded in Win-1252.</p>
<p>Win-1252 is a non-Unicode, single byte encoding.  It is an extension of ASCII
that rams enough characters for almost every European language into the unused
8th bit.  The typical Excel user has never heard of it, if they have heard of
character encoding at all.  <a href="https://www.kingjamesbibleonline.org/Ecclesiastes-1-18/">Ignorance is
bliss</a>.</p>
<h2>See also</h2>
<p>Probably the majority of encoding detection code runs off the principles
established by Netscape in the early 2000s.  The original authors&#39; paper
describing their approach <a href="https://www-archive.mozilla.org/projects/intl/universalcharsetdetection">is in Mozilla&#39;s
archive</a>.</p>
<p>There is a definite sense that auto-detecting text encoding is an instance of
<a href="https://en.wikipedia.org/wiki/Robustness_principle">Postel&#39;s Law</a>: &#34;be
conservative in what you do, be liberal in what you accept from others&#34;.
Postel&#39;s Law is something I always accepted as true but is now <a href="https://datatracker.ietf.org/doc/html/rfc9413">increasingly
controversial</a>.  Perhaps there
is a case to be made that csvbase&#39;s auto-detection should be a more explicit
user interface action than a pre-selected combo-box.  Answers on <a href="mailto:cal@calpaterson.com">a postcard,
to the usual address</a>.</p>

      </div>
    </div></div>
  </body>
</html>
