<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://news.ycombinator.com/item?id=39934480">Original</a>
    <h1>Ask HN: Most efficient way to fine-tune an LLM in 2024?</h1>
    
    <div id="readability-page-1" class="page"><div><div><p>In Apr 2024 what is the most efficient way to fine-tune an LLM?</p><p>In particular we are trying to understand performance vs. cost trade-offs. We don&#39;t have a budget to train from scratch.</p><p>We are working with a proprietary data set on the order of 100M tokens and are looking to fine-tune a general purpose language model and also create task-specific models based on the same corpus.</p><p>Any help would be appreciated!</p></div></div></div>
  </body>
</html>
