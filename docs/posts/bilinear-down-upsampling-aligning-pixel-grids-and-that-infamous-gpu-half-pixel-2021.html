<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://bartwronski.com/2021/02/15/bilinear-down-upsampling-pixel-grids-and-that-half-pixel-offset/">Original</a>
    <h1>Bilinear down/upsampling, aligning pixel grids, and that infamous GPU half pixel (2021)</h1>
    
    <div id="readability-page-1" class="page"><div>
						
<div><figure><a href="https://bartwronski.com/wp-content/uploads/2021/02/box_then_even_odd-6.gif"><img data-attachment-id="4201" data-permalink="https://bartwronski.com/box_then_even_odd-6/" data-orig-file="https://bartwronski.com/wp-content/uploads/2021/02/box_then_even_odd-6.gif" data-orig-size="576,576" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="box_then_even_odd-6" data-image-description="" data-image-caption="" data-medium-file="https://bartwronski.com/wp-content/uploads/2021/02/box_then_even_odd-6.gif?w=300" data-large-file="https://bartwronski.com/wp-content/uploads/2021/02/box_then_even_odd-6.gif?w=576" src="https://bartwronski.com/wp-content/uploads/2021/02/box_then_even_odd-6.gif?w=576" alt="" width="411" height="411" srcset="https://bartwronski.com/wp-content/uploads/2021/02/box_then_even_odd-6.gif?w=411 411w, https://bartwronski.com/wp-content/uploads/2021/02/box_then_even_odd-6.gif?w=150 150w, https://bartwronski.com/wp-content/uploads/2021/02/box_then_even_odd-6.gif?w=300 300w, https://bartwronski.com/wp-content/uploads/2021/02/box_then_even_odd-6.gif 576w" sizes="(max-width: 411px) 100vw, 411px"/></a><figcaption>See this ugly pixel shift when <strong>upsampling a downsampled image</strong>? My post describes where it can come from and how to avoid those! </figcaption></figure></div>



<p>Itâ€™s been more than two decades of me using bilinear texture filtering, a few months since <a href="https://bartwronski.com/2020/04/14/bilinear-texture-filtering-artifacts-alternatives-and-frequency-domain-analysis/">Iâ€™ve written about bilinear resampling</a>, but only two days since I discovered a bug of mine related to it. ğŸ˜… Similarly, just last week a colleague asked for a very fast implementation of bilinear on a CPU and it caused a series of questions â€œwhich kind of bilinear?â€.</p>



<p>So I figured itâ€™s an opportunity for another short blog post â€“ on bilinear filtering, but in context of down/upsampling. We will touch here on <strong>GPU half pixel offsets, aligning pixel grids, a bug / confusion in Tensorflow, deeper signal processing</strong> analysis of whatâ€™s going on during bilinear operations, and analysis of the magic of the<strong> famous â€œmagic kernelâ€</strong>.</p>



<p>I highly recommend <a href="https://bartwronski.com/2020/04/14/bilinear-texture-filtering-artifacts-alternatives-and-frequency-domain-analysis/">my previous post</a> as a primer on the topic, as Iâ€™ll use some of the tools and terminology from there, but itâ€™s not strictly required. Letâ€™s go!</p>



<p><strong>Edit:</strong> I wrote a <a href="https://bartwronski.com/2021/07/20/processing-aware-image-filtering-compensating-for-the-upsampling/">follow-up post to this one</a>, about designing downsampling filters to compensate for bilinear filtering.</p>



<h2>Bilinear confusion</h2>



<p>The term bilinear upsampling and downsampling is used a lot, but what does it mean?Â </p>



<p>One of the few ideas Iâ€™d like to convey in this post is that <strong>bilinear upsampling / downsampling doesnâ€™t have a single meaning or a consensus around this term use</strong>. Which is kind of surprising for a bread and butter type of image processing operation that is used all the time!</p>



<p>Itâ€™s also surprisingly hard to get it right even by image processing professionals, and a <a href="https://github.com/tensorflow/tensorflow/issues/6720">source of long standing bugs and confusion in top libraries</a> (and I know of some actual production bugs caused by this <strong>Tensorflow inconsistency</strong>)!</p>



<p><strong>Edit:</strong> thereâ€™s a blog post titled <em><a href="https://medium.com/hackernoon/how-tensorflows-tf-image-resize-stole-60-days-of-my-life-aba5eb093f35">â€œHow Tensorflowâ€™s tf.image.resize stole 60 days of my lifeâ€</a></em> and itâ€™s describing same issue. I know of some of my colleagues that spent months on fixing it in Tensorflow 2 â€“ imagine effort of fixing incorrect uses and â€œfixingâ€ already trained models that were trained around this bugâ€¦ </p>



<div><figure><img src="https://bartwronski.com/wp-content/uploads/2021/02/83be5-1gukweyudtylrxwkruo-3vq.png" alt="Image for post" width="358" height="158"/><figcaption>Image credit/source: <a href="https://medium.com/hackernoon/how-tensorflows-tf-image-resize-stole-60-days-of-my-life-aba5eb093f35">Oleksandr Savsunenko</a></figcaption></figure></div>



<p>Some parts of it like phase shifting are so tricky that a famous blog post of <strong>â€œmagic kernelâ€</strong> comes up every few years and again, experts re(read) it a few times to figure out whatâ€™s going on there, while the author simply <a href="http://www.johncostella.com/magic/">rediscovered the bilinear</a>! (<strong>Important note:</strong> I donâ€™t want to pick on the author, far from it, as he is a super smart and knowledgeable person, and willingness to share insights is always respect worthy. â€œMagic kernelâ€ is just an example of why itâ€™s so hard and confusing to talk about <strong>â€œbilinearâ€</strong>. I also respect how he amended and improved the post multiple times. But there is no â€œmagic kernelâ€.)</p>



<p>So letâ€™s have a look at whatâ€™s the problem. I will focus here exclusively on 2x up/downsampling and hope that some thought framework I propose and use here will be beneficial for you to also look at and analyze different (and non-integer factors).</p>



<p>Because of bilinear separability, I will again <strong>abuse the notation</strong> and call â€œbilinearâ€ a filter when applied to 1D signals and generally a lot of my analysis will be in 1D.</p>



<h2>Bilinear downsampling and upsampling</h2>



<p>What do we mean by <strong>bilinear upsampling</strong>?</p>



<p>Letâ€™s start with the most simple explanation, without the nitty gritty: it is creating a larger resolution image where every sample is created from bilinear filtering of a smaller resolution image.</p>



<p>For the bilinear downsampling, things get a bit muddy. It is using a bilinear filter to prevent signal aliasing when decimating the input image â€“ ugh, lots of technical terms. I will circle back to it, but first address the first common confusion.</p>



<h3>Is this box or bilinear downsampling? Two ways of addressing it</h3>



<p>When downsampling images by 2, we every often use terms box filter and bilinear filter interchangeably. And both can be correct. How so?</p>



<p>Letâ€™s have a look at the following diagram:Â </p>



<div><figure><a href="https://bartwronski.com/wp-content/uploads/2021/02/image.png"><img data-attachment-id="4166" data-permalink="https://bartwronski.com/image-43/" data-orig-file="https://bartwronski.com/wp-content/uploads/2021/02/image.png" data-orig-size="960,216" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://bartwronski.com/wp-content/uploads/2021/02/image.png?w=300" data-large-file="https://bartwronski.com/wp-content/uploads/2021/02/image.png?w=640" width="960" height="216" src="https://bartwronski.com/wp-content/uploads/2021/02/image.png?w=960" alt="" srcset="https://bartwronski.com/wp-content/uploads/2021/02/image.png 960w, https://bartwronski.com/wp-content/uploads/2021/02/image.png?w=150 150w, https://bartwronski.com/wp-content/uploads/2021/02/image.png?w=300 300w, https://bartwronski.com/wp-content/uploads/2021/02/image.png?w=768 768w" sizes="(max-width: 960px) 100vw, 960px"/></a><figcaption>(Bi)linear vs box downsampling give us the same effective weights. <strong>Black dots</strong> represent <strong>pixel centers</strong>, upper row is the target/low resolution texture, and the bottom row the source, higher resolution one. Blue lines represents discretized weights of the kernel. </figcaption></figure></div>



<p>We can see that a <strong>2 tap box filter is the same as a 2 tap bilinear filter</strong>. The reason for it is that in this case, both filters are centered between the pixels. After discretizing them (evaluating filter weights at sample points), there is no difference, as we no longer know what was the formula to generate them, and how the filter kernel looked outside of the evaluation points.</p>



<p>The most typical way of doing bilinear downsampling is the same as box downsampling. Using those two names for 2x downsampling interchangeably is both correct! (Side note: Things diverge when taking about more than 2x downsampling. This might be a good topic for another blog post.) For 1D signals it means averaging every two elements together, for 2D images averaging 4 elements to produce a single one.</p>



<p>You might have noticed something that I implicitly assumed there â€“ <strong>pixel centers there were shifted by half a pixel</strong>, and the edges/corners were aligned.</p>



<p>There is â€œanother wayâ€ of doing bilinear downsampling, like this:</p>



<div><figure><a href="https://bartwronski.com/wp-content/uploads/2021/02/image-1.png"><img data-attachment-id="4168" data-permalink="https://bartwronski.com/image-1-8/" data-orig-file="https://bartwronski.com/wp-content/uploads/2021/02/image-1.png" data-orig-size="517,219" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="image-1" data-image-description="" data-image-caption="" data-medium-file="https://bartwronski.com/wp-content/uploads/2021/02/image-1.png?w=300" data-large-file="https://bartwronski.com/wp-content/uploads/2021/02/image-1.png?w=517" src="https://bartwronski.com/wp-content/uploads/2021/02/image-1.png?w=517" alt="" width="403" height="170" srcset="https://bartwronski.com/wp-content/uploads/2021/02/image-1.png?w=401 401w, https://bartwronski.com/wp-content/uploads/2021/02/image-1.png?w=150 150w, https://bartwronski.com/wp-content/uploads/2021/02/image-1.png?w=300 300w, https://bartwronski.com/wp-content/uploads/2021/02/image-1.png 517w" sizes="(max-width: 403px) 100vw, 403px"/></a><figcaption>A second take on bilinear downsampling â€“ this time with pixel centers (black dots) aligned. Again the source image / signal is on the bottom, target signal on the top.</figcaption></figure></div>



<p>This one definitely and clearly is also a linear tent, and it doesnâ€™t shift pixel centers. The resulting filter weights of [0.25 0.5 0.25] are also called a [1 2 1] filter, or the simplest case of a <a href="http://www.cse.yorku.ca/~kosta/CompVis_Notes/binomial_filters.pdf.old">binomial filter</a>, a very reasonable approximation to a <a href="https://en.wikipedia.org/wiki/Gaussian_filter">Gaussian filter</a>. (To understand why, see what happens to the binomial distribution as the trial count goes to infinity!). Itâ€™s probably the filter I use the most in my work, but I digress. ğŸ™‚</p>



<p>Why this second method is not used that much? This is by design and a reason for half texel shifts in GPU coordinates / samplers, and you might have noticed the problem â€“ the last texel of high resolution array gets discarded. But letâ€™s not get ahead of ourselves, first we can have a look at the relationship with upsampling.</p>



<h3>Two ways of bilinear upsampling â€“ which one is â€œproperâ€?</h3>



<p>If you were to design a bilinear upsampling algorithm, there are a few ways to address it.</p>



<p>Let me start with a â€œnaiveâ€ one that can have problems. We can take every original pixel, and between them just place averages of the other ones.</p>



<div><figure><a href="https://bartwronski.com/wp-content/uploads/2021/02/image-2.png"><img data-attachment-id="4172" data-permalink="https://bartwronski.com/image-2-8/" data-orig-file="https://bartwronski.com/wp-content/uploads/2021/02/image-2.png" data-orig-size="513,213" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="image-2" data-image-description="" data-image-caption="" data-medium-file="https://bartwronski.com/wp-content/uploads/2021/02/image-2.png?w=300" data-large-file="https://bartwronski.com/wp-content/uploads/2021/02/image-2.png?w=513" loading="lazy" src="https://bartwronski.com/wp-content/uploads/2021/02/image-2.png?w=513" alt="" width="364" height="152" srcset="https://bartwronski.com/wp-content/uploads/2021/02/image-2.png?w=364 364w, https://bartwronski.com/wp-content/uploads/2021/02/image-2.png?w=150 150w, https://bartwronski.com/wp-content/uploads/2021/02/image-2.png?w=300 300w, https://bartwronski.com/wp-content/uploads/2021/02/image-2.png 513w" sizes="(max-width: 364px) 100vw, 364px"/></a><figcaption>Naive bilinear upsampling when pixel centers are aligned. Some pixels receive a copy of the source (green line), the other ones (alternating) a blend between two neighbors.</figcaption></figure></div>



<p>Is it bilinear / tent? Yes, itâ€™s a tent filter on zero-inserted image (more on it later). It has an unusual property; some pixels get blurred, some pixels stay â€œsharpâ€ (original copied).</p>



<p>But more importantly, if you do box/bilinear downsampling as described above, and then upsample an image, <strong>it will be shifted</strong>:</p>



<div><figure><a href="https://bartwronski.com/wp-content/uploads/2021/02/image-3.png"><img data-attachment-id="4174" data-permalink="https://bartwronski.com/image-3-7/" data-orig-file="https://bartwronski.com/wp-content/uploads/2021/02/image-3.png" data-orig-size="743,300" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="image-3" data-image-description="" data-image-caption="" data-medium-file="https://bartwronski.com/wp-content/uploads/2021/02/image-3.png?w=300" data-large-file="https://bartwronski.com/wp-content/uploads/2021/02/image-3.png?w=640" loading="lazy" src="https://bartwronski.com/wp-content/uploads/2021/02/image-3.png?w=743" alt="" width="510" height="206" srcset="https://bartwronski.com/wp-content/uploads/2021/02/image-3.png?w=510 510w, https://bartwronski.com/wp-content/uploads/2021/02/image-3.png?w=150 150w, https://bartwronski.com/wp-content/uploads/2021/02/image-3.png?w=300 300w, https://bartwronski.com/wp-content/uploads/2021/02/image-3.png 743w" sizes="(max-width: 510px) 100vw, 510px"/></a><figcaption>Using box downsampling, and then copy / interpolate upsampling shifts the image by half a pixel. This is a <strong>wrong way </strong>to do it! </figcaption></figure></div>



<p>Or rather â€“ it will not correct for the half pixel shift created by downsampling.</p>



<p>It will work however with downsampling using the second method. The second method interpolates every single output pixel; all are interpolated:</p>



<div><figure><a href="https://bartwronski.com/wp-content/uploads/2021/02/image-24.png"><img data-attachment-id="4242" data-permalink="https://bartwronski.com/image-24-4/" data-orig-file="https://bartwronski.com/wp-content/uploads/2021/02/image-24.png" data-orig-size="685,310" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="image-24" data-image-description="" data-image-caption="" data-medium-file="https://bartwronski.com/wp-content/uploads/2021/02/image-24.png?w=300" data-large-file="https://bartwronski.com/wp-content/uploads/2021/02/image-24.png?w=640" loading="lazy" src="https://bartwronski.com/wp-content/uploads/2021/02/image-24.png?w=685" alt="" width="494" height="223" srcset="https://bartwronski.com/wp-content/uploads/2021/02/image-24.png?w=494 494w, https://bartwronski.com/wp-content/uploads/2021/02/image-24.png?w=150 150w, https://bartwronski.com/wp-content/uploads/2021/02/image-24.png?w=300 300w, https://bartwronski.com/wp-content/uploads/2021/02/image-24.png 685w" sizes="(max-width: 494px) 100vw, 494px"/></a><figcaption>When done properly, bilinear down/upsample doesnâ€™t shift the image.</figcaption></figure></div>



<p>This another way of doing bilinear upsampling that might first feel initially <strong>unintuitive: every pixel is 0.75 of one pixel, and 0.25 of another one</strong>, alternating â€œto the leftâ€ and â€œto the rightâ€. This is exactly what a GPU does when you upsample a texture by 2x:</p>



<div><figure><a href="https://bartwronski.com/wp-content/uploads/2021/02/image-5.png"><img data-attachment-id="4177" data-permalink="https://bartwronski.com/image-5-6/" data-orig-file="https://bartwronski.com/wp-content/uploads/2021/02/image-5.png" data-orig-size="746,301" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="image-5" data-image-description="" data-image-caption="" data-medium-file="https://bartwronski.com/wp-content/uploads/2021/02/image-5.png?w=300" data-large-file="https://bartwronski.com/wp-content/uploads/2021/02/image-5.png?w=640" loading="lazy" src="https://bartwronski.com/wp-content/uploads/2021/02/image-5.png?w=746" alt="" width="520" height="210" srcset="https://bartwronski.com/wp-content/uploads/2021/02/image-5.png?w=520 520w, https://bartwronski.com/wp-content/uploads/2021/02/image-5.png?w=150 150w, https://bartwronski.com/wp-content/uploads/2021/02/image-5.png?w=300 300w, https://bartwronski.com/wp-content/uploads/2021/02/image-5.png 746w" sizes="(max-width: 520px) 100vw, 520px"/></a></figure></div>



<p>There are two simple explanations for those â€œalternatingâ€ weights. The first, easiest one is just looking at the â€œtentsâ€ in this scheme:</p>



<div><figure><a href="https://bartwronski.com/wp-content/uploads/2021/02/image-6.png"><img data-attachment-id="4180" data-permalink="https://bartwronski.com/image-6-5/" data-orig-file="https://bartwronski.com/wp-content/uploads/2021/02/image-6.png" data-orig-size="952,218" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="image-6" data-image-description="" data-image-caption="" data-medium-file="https://bartwronski.com/wp-content/uploads/2021/02/image-6.png?w=300" data-large-file="https://bartwronski.com/wp-content/uploads/2021/02/image-6.png?w=640" loading="lazy" width="952" height="218" src="https://bartwronski.com/wp-content/uploads/2021/02/image-6.png?w=952" alt="" srcset="https://bartwronski.com/wp-content/uploads/2021/02/image-6.png 952w, https://bartwronski.com/wp-content/uploads/2021/02/image-6.png?w=150 150w, https://bartwronski.com/wp-content/uploads/2021/02/image-6.png?w=300 300w, https://bartwronski.com/wp-content/uploads/2021/02/image-6.png?w=768 768w" sizes="(max-width: 952px) 100vw, 952px"/></a><figcaption>If we draw interpolation â€œtentsâ€, we can see that the lower resolution image samples are alternating on the either side of the high resolution sample.</figcaption></figure></div>



<p>Iâ€™ll have a look at the second interpretation of this filter â€“ <strong>itâ€™s [0.125 0.375 0.375 0.125]</strong> in disguise ğŸ•µï¸â€â™€ï¸, but first with this intro, I think itâ€™s time to make the main claim / statement: <strong>we need to be careful to use same reference coordinate frames when discussing images of different resolutions</strong>.</p>



<h2>Be careful about phase shifts</h2>



<p><strong>Your upsampling operations should be aware of what downsampling operations are and how they define the pixel grid offset, and the other way around!</strong></p>



<h3>Even / odd filters</h3>



<p>One important thing to internalize is that signal filters can have odd or even number of samples. If we have an even number of samples, such a filter doesnâ€™t have a â€œcenterâ€, so it has to shift the whole signal by a half pixel in either direction. By comparison, symmetric odd filters can shift specific frequencies, but donâ€™t shift the whole signal:</p>



<div><figure><a href="https://bartwronski.com/wp-content/uploads/2021/02/image-10.png"><img data-attachment-id="4191" data-permalink="https://bartwronski.com/image-10-4/" data-orig-file="https://bartwronski.com/wp-content/uploads/2021/02/image-10.png" data-orig-size="845,229" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="image-10" data-image-description="" data-image-caption="" data-medium-file="https://bartwronski.com/wp-content/uploads/2021/02/image-10.png?w=300" data-large-file="https://bartwronski.com/wp-content/uploads/2021/02/image-10.png?w=640" loading="lazy" src="https://bartwronski.com/wp-content/uploads/2021/02/image-10.png?w=845" alt="" width="452" height="122" srcset="https://bartwronski.com/wp-content/uploads/2021/02/image-10.png?w=452 452w, https://bartwronski.com/wp-content/uploads/2021/02/image-10.png?w=150 150w, https://bartwronski.com/wp-content/uploads/2021/02/image-10.png?w=300 300w, https://bartwronski.com/wp-content/uploads/2021/02/image-10.png?w=768 768w, https://bartwronski.com/wp-content/uploads/2021/02/image-10.png 845w" sizes="(max-width: 452px) 100vw, 452px"/></a><figcaption>Odd length filters can stay â€œcenteredâ€, while even length filters shift the signal/image by half a pixel.</figcaption></figure></div>



<p>If you know signal processing, those are the type I and II <a href="https://en.wikipedia.org/wiki/Linear_phase">linear phase filters</a>.</p>



<h3>Why shifts matter</h3>



<p>Hereâ€™s a visual demonstration of why it matters. A Kodak dataset image processed with different sequences, first starting with box downsampling:</p>



<div><figure><a href="https://bartwronski.com/wp-content/uploads/2021/02/box_then_even_odd-6.gif"><img data-attachment-id="4201" data-permalink="https://bartwronski.com/box_then_even_odd-6/" data-orig-file="https://bartwronski.com/wp-content/uploads/2021/02/box_then_even_odd-6.gif" data-orig-size="576,576" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="box_then_even_odd-6" data-image-description="" data-image-caption="" data-medium-file="https://bartwronski.com/wp-content/uploads/2021/02/box_then_even_odd-6.gif?w=300" data-large-file="https://bartwronski.com/wp-content/uploads/2021/02/box_then_even_odd-6.gif?w=576" loading="lazy" src="https://bartwronski.com/wp-content/uploads/2021/02/box_then_even_odd-6.gif?w=576" alt="" width="358" height="358" srcset="https://bartwronski.com/wp-content/uploads/2021/02/box_then_even_odd-6.gif?w=358 358w, https://bartwronski.com/wp-content/uploads/2021/02/box_then_even_odd-6.gif?w=150 150w, https://bartwronski.com/wp-content/uploads/2021/02/box_then_even_odd-6.gif?w=300 300w, https://bartwronski.com/wp-content/uploads/2021/02/box_then_even_odd-6.gif 576w" sizes="(max-width: 358px) 100vw, 358px"/></a><figcaption>Using box / tent even downsampling followed by either even, or odd upsampling.</figcaption></figure></div>



<p>And now with [1 2 1] tent odd downsampling: </p>



<div><figure><a href="https://bartwronski.com/wp-content/uploads/2021/02/box_then_even_odd-7.gif"><img data-attachment-id="4202" data-permalink="https://bartwronski.com/box_then_even_odd-7/" data-orig-file="https://bartwronski.com/wp-content/uploads/2021/02/box_then_even_odd-7.gif" data-orig-size="576,576" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="box_then_even_odd-7" data-image-description="" data-image-caption="" data-medium-file="https://bartwronski.com/wp-content/uploads/2021/02/box_then_even_odd-7.gif?w=300" data-large-file="https://bartwronski.com/wp-content/uploads/2021/02/box_then_even_odd-7.gif?w=576" loading="lazy" src="https://bartwronski.com/wp-content/uploads/2021/02/box_then_even_odd-7.gif?w=576" alt="" width="362" height="362" srcset="https://bartwronski.com/wp-content/uploads/2021/02/box_then_even_odd-7.gif?w=362 362w, https://bartwronski.com/wp-content/uploads/2021/02/box_then_even_odd-7.gif?w=150 150w, https://bartwronski.com/wp-content/uploads/2021/02/box_then_even_odd-7.gif?w=300 300w, https://bartwronski.com/wp-content/uploads/2021/02/box_then_even_odd-7.gif 576w" sizes="(max-width: 362px) 100vw, 362px"/></a><figcaption>Using tent odd downsampling followed by either even, or odd upsampling.</figcaption></figure></div>



<p>If there is a single lesson from my post, I would like it to be this one: Both â€œtakesâ€ on the bilinear up/downsampling above can be the valid and correct ones, you simply need to pick the proper one for your use-case and the convention used throughout your code/frameworks/libraries; <strong>always use a consistent coordinate convention for the downsampling and upsampling</strong>. When you see term â€œbilinearâ€, always double check what it means! Because of it, I actually like to reimplement those and be sure that Iâ€™m consistentâ€¦</p>



<p>That said, Iâ€™d argue that the <strong>â€œboxâ€ bilinear downsampling and the â€œalternating weightsâ€ are better for average use-case</strong>. The first reason might be somewhat subjective / minor (because bilinear down/upsampling is inherently low quality and I donâ€™t recommend using it when the quality matters more than simplicity / performance). If we visually inspect the upsampling operation, we can see more leftover aliasing (just look at the diagonal edges) in the odd/odd combo:</p>



<div><figure><a href="https://bartwronski.com/wp-content/uploads/2021/02/comp.gif"><img data-attachment-id="4204" data-permalink="https://bartwronski.com/comp/" data-orig-file="https://bartwronski.com/wp-content/uploads/2021/02/comp.gif" data-orig-size="576,576" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="comp" data-image-description="" data-image-caption="" data-medium-file="https://bartwronski.com/wp-content/uploads/2021/02/comp.gif?w=300" data-large-file="https://bartwronski.com/wp-content/uploads/2021/02/comp.gif?w=576" loading="lazy" src="https://bartwronski.com/wp-content/uploads/2021/02/comp.gif?w=576" alt="" width="391" height="391" srcset="https://bartwronski.com/wp-content/uploads/2021/02/comp.gif?w=391 391w, https://bartwronski.com/wp-content/uploads/2021/02/comp.gif?w=150 150w, https://bartwronski.com/wp-content/uploads/2021/02/comp.gif?w=300 300w, https://bartwronski.com/wp-content/uploads/2021/02/comp.gif 576w" sizes="(max-width: 391px) 100vw, 391px"/></a><figcaption>Two types of upsampling/downsampling can prevent image shifting, but produce differently looking and differently aliased images.</figcaption></figure></div>



<p>The second reason, IMO a more important one is how easily they align images. And this is why GPU sampling has this â€œinfamousâ€ half a pixel offset.</p>



<h2>That half pixel offset!</h2>



<p>Ok, so my favorite part starts â€“ half pixel offsets! Source of pain, frustration, misunderstanding, but also a super reasonable and robust way of representing texture and pixel coordinates. If you started graphics programming relatively recently (DX10+ era) or are not a graphics programmer â€“ this might be not a big deal for you. But basically, with older graphics APIs framebuffer coordinates didnâ€™t have a half texel offset, while the texture sampler expected it, so you had to add it manually. Sometimes people added it in the vertex shader, sometimes in the pixel shader, sometimes setting up uniforms on the CPUâ€¦ a complete mess; it was a source of endless bugs found almost every day, especially on video games shipping on multiple platforms / APIs!</p>



<h3>What do we mean by half pixel offset?</h3>



<p>If you have a 1D texture of size 4, what are your pixel/texel coordinates?</p>



<p>They can be [0, 1, 2, 3]. But GPUs use a convention of half pixel offsets, so they end up being [0.5, 1.5, 2.5, 3.5]. This translates to UVs, or â€œnormalizedâ€ coordinates [0.5/4, 1.5/4, 2.5/4, 3.5/4], which spans a range of [0.5/width, 1 â€“ 0.5/width].</p>



<p>This representation seems counterintuitive at first, but what it provides us is a guarantee and convention that the <strong>image corners </strong>are placed at<strong> [0 and 1] normalized</strong>, or [0, width] unnormalized.</p>



<p>This is really good for resampling images and operating on images with different resolutions.</p>



<p>Letâ€™s compare the two on the following diagrams:</p>



<div><figure><a href="https://bartwronski.com/wp-content/uploads/2021/02/image-7.png"><img data-attachment-id="4183" data-permalink="https://bartwronski.com/image-7-5/" data-orig-file="https://bartwronski.com/wp-content/uploads/2021/02/image-7.png" data-orig-size="838,303" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="image-7" data-image-description="" data-image-caption="" data-medium-file="https://bartwronski.com/wp-content/uploads/2021/02/image-7.png?w=300" data-large-file="https://bartwronski.com/wp-content/uploads/2021/02/image-7.png?w=640" loading="lazy" src="https://bartwronski.com/wp-content/uploads/2021/02/image-7.png?w=838" alt="" width="491" height="177" srcset="https://bartwronski.com/wp-content/uploads/2021/02/image-7.png?w=491 491w, https://bartwronski.com/wp-content/uploads/2021/02/image-7.png?w=150 150w, https://bartwronski.com/wp-content/uploads/2021/02/image-7.png?w=300 300w, https://bartwronski.com/wp-content/uploads/2021/02/image-7.png?w=768 768w, https://bartwronski.com/wp-content/uploads/2021/02/image-7.png 838w" sizes="(max-width: 491px) 100vw, 491px"/></a><figcaption>Half pixel offset convention aligns pixel grids perfectly, by aligning their corners/edges.</figcaption></figure></div>



<div><figure><a href="https://bartwronski.com/wp-content/uploads/2021/02/image-8.png"><img data-attachment-id="4185" data-permalink="https://bartwronski.com/image-8-5/" data-orig-file="https://bartwronski.com/wp-content/uploads/2021/02/image-8.png" data-orig-size="952,278" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="image-8" data-image-description="" data-image-caption="" data-medium-file="https://bartwronski.com/wp-content/uploads/2021/02/image-8.png?w=300" data-large-file="https://bartwronski.com/wp-content/uploads/2021/02/image-8.png?w=640" loading="lazy" src="https://bartwronski.com/wp-content/uploads/2021/02/image-8.png?w=952" alt="" width="472" height="137" srcset="https://bartwronski.com/wp-content/uploads/2021/02/image-8.png?w=469 469w, https://bartwronski.com/wp-content/uploads/2021/02/image-8.png?w=938 938w, https://bartwronski.com/wp-content/uploads/2021/02/image-8.png?w=150 150w, https://bartwronski.com/wp-content/uploads/2021/02/image-8.png?w=300 300w, https://bartwronski.com/wp-content/uploads/2021/02/image-8.png?w=768 768w" sizes="(max-width: 472px) 100vw, 472px"/></a><figcaption>No offset convention aligns the first pixel center perfectly â€“ and in the case of 2x scaling, also every other pixel. But images â€œoverlapâ€ outside of the 0,1 range and are not symmetric!</figcaption></figure></div>



<p>While the half a pixel align pixel corners, <strong>the other way of down/upsampling comes from aligning the first pixel centers in the image</strong>.</p>



<p>Now, letâ€™s have a look at how we compute the bilinear upsampling weights in the half a pixel shift convention:</p>



<div><figure><a href="https://bartwronski.com/wp-content/uploads/2021/02/image-9.png"><img data-attachment-id="4189" data-permalink="https://bartwronski.com/image-9-4/" data-orig-file="https://bartwronski.com/wp-content/uploads/2021/02/image-9.png" data-orig-size="526,374" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="image-9" data-image-description="" data-image-caption="" data-medium-file="https://bartwronski.com/wp-content/uploads/2021/02/image-9.png?w=300" data-large-file="https://bartwronski.com/wp-content/uploads/2021/02/image-9.png?w=526" loading="lazy" src="https://bartwronski.com/wp-content/uploads/2021/02/image-9.png?w=526" alt="" width="333" height="236" srcset="https://bartwronski.com/wp-content/uploads/2021/02/image-9.png?w=333 333w, https://bartwronski.com/wp-content/uploads/2021/02/image-9.png?w=150 150w, https://bartwronski.com/wp-content/uploads/2021/02/image-9.png?w=300 300w, https://bartwronski.com/wp-content/uploads/2021/02/image-9.png 526w" sizes="(max-width: 333px) 100vw, 333px"/></a></figure></div>



<p>This convention makes it amazingly simple and obvious where the weights come from â€“ and how simple the computation is once we align the grid corners. I personally use it as well even in APIs outside of GPU shader realm â€“ everything is easier. If adding and removing 0.5 adds performance cost, then can be removed at microoptimizations stage, but usually doesnâ€™t matter that much.</p>



<h3>Reasonable default?</h3>



<p><strong>Half a pixel offset for pixel centers used in GPU convention for both pixels and texels is a reasonable default for any image processing code dealing with images of different resolutions.</strong></p>



<p>This is expecially important when to dealing with textures of different resolutions and for example mip maps of non power of 2 textures. A texture with 9 texels instead of 4? No problem:</p>



<div><figure><a href="https://bartwronski.com/wp-content/uploads/2021/02/image-11.png"><img data-attachment-id="4206" data-permalink="https://bartwronski.com/image-11-4/" data-orig-file="https://bartwronski.com/wp-content/uploads/2021/02/image-11.png" data-orig-size="854,302" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="image-11" data-image-description="" data-image-caption="" data-medium-file="https://bartwronski.com/wp-content/uploads/2021/02/image-11.png?w=300" data-large-file="https://bartwronski.com/wp-content/uploads/2021/02/image-11.png?w=640" loading="lazy" src="https://bartwronski.com/wp-content/uploads/2021/02/image-11.png?w=854" alt="" width="437" height="154" srcset="https://bartwronski.com/wp-content/uploads/2021/02/image-11.png?w=435 435w, https://bartwronski.com/wp-content/uploads/2021/02/image-11.png?w=150 150w, https://bartwronski.com/wp-content/uploads/2021/02/image-11.png?w=300 300w, https://bartwronski.com/wp-content/uploads/2021/02/image-11.png?w=768 768w, https://bartwronski.com/wp-content/uploads/2021/02/image-11.png 854w" sizes="(max-width: 437px) 100vw, 437px"/></a><figcaption>A texture with 9 texels aligns easily and perfectly with a one with 4 texels. Very useful for graphics operations, where you want to abstract the texture resolutions away.</figcaption></figure></div>



<p>It makes sure that grids are aligned, and the up/downsampling operations â€œjust workâ€. To get box/bilinear downsampling, you can just take a single bilinear tap of the source texture, the same with the upsampling.</p>



<p>So trivial to use it that when you start graphics programming, you rarely think about it. Which is a double edge sword â€“ both great for an easy entry point for beginners, but also a source of confusion once you start getting deeper into it and analyzing whatâ€™s going on or do things like fractional or nearest neighbor downsampling (or e.g. create a non-interpolable depth map pyramidâ€¦).</p>



<p>Even if there were no other reasons, this is why Iâ€™d recommend treating phase shifting box downsample and the [0.25 0.75] / [0.75 0.25] upsamplers <strong>as your default when talking about bilinear</strong> as well.</p>



<p><strong>Bonus advantage</strong>: having texel coordinates shifted by 0.5 means that if you want to get an integer coordinate â€“ for example for texelFetch instruction â€“ you donâ€™t need to round. Floor / truncation (which in some settings can be a cheaper operation) gives you the closest pixel integer coordinate to index!</p>



<p><strong>Note:</strong> <a href="https://www.tensorflow.org/api_docs/python/tf/compat/v1/image/resize">Tensorflow got it wrong</a>. The â€œalign_cornersâ€ parameter alignsâ€¦ centers of the corner pixels??? This is a really bad and weird naming plus design choice, where upsampling a [0.0 1.0] by factor of 2 produces [0, 1/3, 2/3, 1], which is something completely unexpected and different from either of the conventions I described here.</p>



<h2>Signal processing â€“ bilinear upsampling</h2>



<p>I love writing about signal processing and analyzing signals also in the frequency domain, so let me explain here how you can model bilinear up/downsampling in the EE / signal processing framework.</p>



<p>Upsampling usually is represented as two operations: <strong>1. Zero insertion</strong> and <strong>2. Post filtering</strong>.</p>



<p>If you never heard of this way of looking at it (especially the zero insertion), itâ€™s most likely because in practice nobody in practice (at least in graphics or image processing) implements it like this, it would be super wasteful to do it in such a sequence. ğŸ™‚ </p>



<h3>Zero insertionÂ </h3>



<p>Zero insertion is an interesting, counter-intuitive operation. You insert zeros between each element (often multiplying the original ones by 2x to preserve the constant/average energy in the signal; or we can fold this multiplication in our filter later) and get 2x more samples, but they are not very â€œusefulâ€. You have an image consisting of mostly â€œholesâ€â€¦</p>



<div><figure><a href="https://bartwronski.com/wp-content/uploads/2021/02/image-12.png"><img data-attachment-id="4210" data-permalink="https://bartwronski.com/image-12-4/" data-orig-file="https://bartwronski.com/wp-content/uploads/2021/02/image-12.png" data-orig-size="468,468" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="image-12" data-image-description="" data-image-caption="" data-medium-file="https://bartwronski.com/wp-content/uploads/2021/02/image-12.png?w=300" data-large-file="https://bartwronski.com/wp-content/uploads/2021/02/image-12.png?w=468" loading="lazy" src="https://bartwronski.com/wp-content/uploads/2021/02/image-12.png?w=468" alt="" width="369" height="369" srcset="https://bartwronski.com/wp-content/uploads/2021/02/image-12.png?w=369 369w, https://bartwronski.com/wp-content/uploads/2021/02/image-12.png?w=150 150w, https://bartwronski.com/wp-content/uploads/2021/02/image-12.png?w=300 300w, https://bartwronski.com/wp-content/uploads/2021/02/image-12.png 468w" sizes="(max-width: 369px) 100vw, 369px"/></a><figcaption>In 2D zero insertion causes every 2Ã—2 quad contain one pixel and three zeros.</figcaption></figure></div>



<p>I think that looking at it in 1D might be more insightful:</p>



<div><figure><a href="https://bartwronski.com/wp-content/uploads/2021/02/image-25.png"><img data-attachment-id="4243" data-permalink="https://bartwronski.com/image-25-4/" data-orig-file="https://bartwronski.com/wp-content/uploads/2021/02/image-25.png" data-orig-size="380,373" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="image-25" data-image-description="" data-image-caption="" data-medium-file="https://bartwronski.com/wp-content/uploads/2021/02/image-25.png?w=300" data-large-file="https://bartwronski.com/wp-content/uploads/2021/02/image-25.png?w=380" loading="lazy" width="380" height="373" src="https://bartwronski.com/wp-content/uploads/2021/02/image-25.png?w=380" alt="" srcset="https://bartwronski.com/wp-content/uploads/2021/02/image-25.png 380w, https://bartwronski.com/wp-content/uploads/2021/02/image-25.png?w=150 150w, https://bartwronski.com/wp-content/uploads/2021/02/image-25.png?w=300 300w" sizes="(max-width: 380px) 100vw, 380px"/></a><figcaption>1D zero insertion â€“ notice high frequency oscillations.</figcaption></figure></div>



<p>From this plot, we can immediately see that with zero insertion, there are many high frequencies that were not there! All of those zeros create lots of high frequency coming from alternating and â€œoscillatingâ€ between the original signal, and zero. Filters that are â€œdilatedâ€ and have zeros in between coefficients (like a-trous / dilated convolution) are called <strong>comb filters</strong> â€“ because they resemble a comb teeth!</p>



<p>Letâ€™s look at it from the spectral analysis. Zero insertion duplicates the frequency spectrum:</p>



<div><figure><a href="https://bartwronski.com/wp-content/uploads/2021/02/image-15.png"><img data-attachment-id="4223" data-permalink="https://bartwronski.com/image-15-4/" data-orig-file="https://bartwronski.com/wp-content/uploads/2021/02/image-15.png" data-orig-size="372,373" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="image-15" data-image-description="" data-image-caption="" data-medium-file="https://bartwronski.com/wp-content/uploads/2021/02/image-15.png?w=300" data-large-file="https://bartwronski.com/wp-content/uploads/2021/02/image-15.png?w=372" loading="lazy" width="372" height="373" src="https://bartwronski.com/wp-content/uploads/2021/02/image-15.png?w=372" alt="" srcset="https://bartwronski.com/wp-content/uploads/2021/02/image-15.png 372w, https://bartwronski.com/wp-content/uploads/2021/02/image-15.png?w=150 150w, https://bartwronski.com/wp-content/uploads/2021/02/image-15.png?w=300 300w" sizes="(max-width: 372px) 100vw, 372px"/></a><figcaption>Upsampling by zero insertion duplicates the frequency spectrum.</figcaption></figure></div>



<p>Every frequency of the original signal is duplicated, but we know that there were no frequencies like this present in the smaller resolution image; it wasnâ€™t possible to represent anything above its Nyquist! To fix that, we need to filter them out after this operation with a low pass filter:</p>



<div><figure><a href="https://bartwronski.com/wp-content/uploads/2021/02/image-16.png"><img data-attachment-id="4225" data-permalink="https://bartwronski.com/image-16-4/" data-orig-file="https://bartwronski.com/wp-content/uploads/2021/02/image-16.png" data-orig-size="372,373" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="image-16" data-image-description="" data-image-caption="" data-medium-file="https://bartwronski.com/wp-content/uploads/2021/02/image-16.png?w=300" data-large-file="https://bartwronski.com/wp-content/uploads/2021/02/image-16.png?w=372" loading="lazy" src="https://bartwronski.com/wp-content/uploads/2021/02/image-16.png?w=372" alt="" width="339" height="340" srcset="https://bartwronski.com/wp-content/uploads/2021/02/image-16.png?w=339 339w, https://bartwronski.com/wp-content/uploads/2021/02/image-16.png?w=150 150w, https://bartwronski.com/wp-content/uploads/2021/02/image-16.png?w=300 300w, https://bartwronski.com/wp-content/uploads/2021/02/image-16.png 372w" sizes="(max-width: 339px) 100vw, 339px"/></a><figcaption>To get properly looking image, weâ€™d want to remove high frequencies from zero insertion by lowpass filtering.</figcaption></figure></div>



<p>I have shown some remainder frequency content on purpose, as itâ€™s generally hard to do â€œperfectâ€ lowpass filtering (and itâ€™s also questionable if weâ€™d want this â€“ ringing problems etc).</p>



<p>Here is how progressively filtered 1D signal looks like, notice high frequencies and â€œcombsâ€ disappearing:</p>



<div><figure><a href="https://bartwronski.com/wp-content/uploads/2021/02/zero_upsample_1d.gif"><img data-attachment-id="4245" data-permalink="https://bartwronski.com/zero_upsample_1d/" data-orig-file="https://bartwronski.com/wp-content/uploads/2021/02/zero_upsample_1d.gif" data-orig-size="288,288" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="zero_upsample_1d" data-image-description="" data-image-caption="" data-medium-file="https://bartwronski.com/wp-content/uploads/2021/02/zero_upsample_1d.gif?w=288" data-large-file="https://bartwronski.com/wp-content/uploads/2021/02/zero_upsample_1d.gif?w=288" loading="lazy" src="https://bartwronski.com/wp-content/uploads/2021/02/zero_upsample_1d.gif?w=288" alt="" width="334" height="334" srcset="https://bartwronski.com/wp-content/uploads/2021/02/zero_upsample_1d.gif 288w, https://bartwronski.com/wp-content/uploads/2021/02/zero_upsample_1d.gif?w=150 150w" sizes="(max-width: 334px) 100vw, 334px"/></a><figcaption>Notice how progressively more blurring causes upsampled signal lose the wrong high frequency comb teeth and it converges to 2x higher resolution original one!</figcaption></figure></div>



<p>Hereâ€™s an animation of blurring/filtering on the 2D image and how there it also causes this zero-inserted image to become more and more like just properly upsampled:</p>



<figure><a href="https://bartwronski.com/wp-content/uploads/2021/02/zero_upsample_blur-1.gif"><img data-attachment-id="4216" data-permalink="https://bartwronski.com/zero_upsample_blur-1/" data-orig-file="https://bartwronski.com/wp-content/uploads/2021/02/zero_upsample_blur-1.gif" data-orig-size="864,432" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="zero_upsample_blur-1" data-image-description="" data-image-caption="" data-medium-file="https://bartwronski.com/wp-content/uploads/2021/02/zero_upsample_blur-1.gif?w=300" data-large-file="https://bartwronski.com/wp-content/uploads/2021/02/zero_upsample_blur-1.gif?w=640" loading="lazy" width="864" height="432" src="https://bartwronski.com/wp-content/uploads/2021/02/zero_upsample_blur-1.gif?w=864" alt="" srcset="https://bartwronski.com/wp-content/uploads/2021/02/zero_upsample_blur-1.gif 864w, https://bartwronski.com/wp-content/uploads/2021/02/zero_upsample_blur-1.gif?w=150 150w, https://bartwronski.com/wp-content/uploads/2021/02/zero_upsample_blur-1.gif?w=300 300w, https://bartwronski.com/wp-content/uploads/2021/02/zero_upsample_blur-1.gif?w=768 768w" sizes="(max-width: 864px) 100vw, 864px"/></a><figcaption>Blurring zero inserted image converges to upsampled one!</figcaption></figure>



<p>Looks like image blending, but itâ€™s just blending filters â€“ imo itâ€™s pretty cool. ğŸ˜</p>



<h3>Nearest neighbor -&gt; box filter!</h3>



<p>Obviously, the choice of the blur (or technically â€“ lowpass) filter matters â€“ a lot. Some interesting connection: what if we convolve this zero-inserted signal with a <strong>symmetric [0.5, 0.5]</strong> (or 1,1 if we didnâ€™t multiply the signal by 2 when inserting zeros) filter?</p>



<div><figure><a href="https://bartwronski.com/wp-content/uploads/2021/02/zero_upsample_1d_nn.gif"><img data-attachment-id="4247" data-permalink="https://bartwronski.com/zero_upsample_1d_nn/" data-orig-file="https://bartwronski.com/wp-content/uploads/2021/02/zero_upsample_1d_nn.gif" data-orig-size="288,288" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="zero_upsample_1d_nn" data-image-description="" data-image-caption="" data-medium-file="https://bartwronski.com/wp-content/uploads/2021/02/zero_upsample_1d_nn.gif?w=288" data-large-file="https://bartwronski.com/wp-content/uploads/2021/02/zero_upsample_1d_nn.gif?w=288" loading="lazy" width="288" height="288" src="https://bartwronski.com/wp-content/uploads/2021/02/zero_upsample_1d_nn.gif?w=288" alt="" srcset="https://bartwronski.com/wp-content/uploads/2021/02/zero_upsample_1d_nn.gif 288w, https://bartwronski.com/wp-content/uploads/2021/02/zero_upsample_1d_nn.gif?w=150 150w" sizes="(max-width: 288px) 100vw, 288px"/></a></figure></div>



<div><figure><a href="https://bartwronski.com/wp-content/uploads/2021/02/zero_upsample_blur_nn.gif"><img data-attachment-id="4218" data-permalink="https://bartwronski.com/zero_upsample_blur_nn/" data-orig-file="https://bartwronski.com/wp-content/uploads/2021/02/zero_upsample_blur_nn.gif" data-orig-size="864,432" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="zero_upsample_blur_nn" data-image-description="" data-image-caption="" data-medium-file="https://bartwronski.com/wp-content/uploads/2021/02/zero_upsample_blur_nn.gif?w=300" data-large-file="https://bartwronski.com/wp-content/uploads/2021/02/zero_upsample_blur_nn.gif?w=640" loading="lazy" src="https://bartwronski.com/wp-content/uploads/2021/02/zero_upsample_blur_nn.gif?w=864" alt="" width="580" height="290" srcset="https://bartwronski.com/wp-content/uploads/2021/02/zero_upsample_blur_nn.gif?w=580 580w, https://bartwronski.com/wp-content/uploads/2021/02/zero_upsample_blur_nn.gif?w=150 150w, https://bartwronski.com/wp-content/uploads/2021/02/zero_upsample_blur_nn.gif?w=300 300w, https://bartwronski.com/wp-content/uploads/2021/02/zero_upsample_blur_nn.gif?w=768 768w, https://bartwronski.com/wp-content/uploads/2021/02/zero_upsample_blur_nn.gif 864w" sizes="(max-width: 580px) 100vw, 580px"/></a><figcaption>Convolving image with a [1, 1] filter is the same as nearest neighbor filter!</figcaption></figure></div>



<p>The interesting part here is that we kind of<strong> â€œreinventedâ€ the nearest neighbor filter</strong>! After a second of though, this should be intuitive; a sample that is zero gets contributions from the single non-zero neighbor, which is like a copy, while the sample that is non-zero is surrounded by two zeros, and they donâ€™t affect it.</p>



<p>We can see on the spectral / Fourier plot where the nearest neighbor hard edges and post-aliasing comes from (red part of the plot):</p>



<div><figure><a href="https://bartwronski.com/wp-content/uploads/2021/02/image-19.png"><img data-attachment-id="4230" data-permalink="https://bartwronski.com/image-19-4/" data-orig-file="https://bartwronski.com/wp-content/uploads/2021/02/image-19.png" data-orig-size="372,373" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="image-19" data-image-description="" data-image-caption="" data-medium-file="https://bartwronski.com/wp-content/uploads/2021/02/image-19.png?w=300" data-large-file="https://bartwronski.com/wp-content/uploads/2021/02/image-19.png?w=372" loading="lazy" width="372" height="373" src="https://bartwronski.com/wp-content/uploads/2021/02/image-19.png?w=372" alt="" srcset="https://bartwronski.com/wp-content/uploads/2021/02/image-19.png 372w, https://bartwronski.com/wp-content/uploads/2021/02/image-19.png?w=150 150w, https://bartwronski.com/wp-content/uploads/2021/02/image-19.png?w=300 300w" sizes="(max-width: 372px) 100vw, 372px"/></a></figure></div>



<p>The nearest neighbor upsampling is also shifting the signal (because it is even number of samples) and will work well to undo the box downsampling filter, which fits the common intuition of replicating samples being the â€œreverseâ€ of box filtering and causing no shift problem.</p>



<h3>Bilinear upsampling take one â€“ direct odd filter</h3>



<p>Letâ€™s have a look at how the strategy of â€œkeep one sample, interpolate betweenâ€ can be represented in this framework.</p>



<p>Itâ€™s equivalent to <strong>filtering our zero-upsampled image with a [0.25 0.5 0.25] filter.</strong></p>



<p>The problem is that in such setup, if we multiply the weights two (to keep average signal the same) and then by zeros (where the signal is zero), we get alternating [0.0 1.0 0.0] and [0.5 0.0 0.5] filters, with very different frequency response and variance reductionâ€¦Â Iâ€™ll reference you here again to my previous blog post on it, but basically you get <strong>alternating 1.0 and 0.5 of original signal variance</strong> (sum of effective weights squared).</p>



<h3>Bilinear upsampling take two â€“ two even filters</h3>



<p>The second approach of alternating weights of [0.25 0.75] can be seen as simply: nearest neighbor upsampling â€“ a filter of [0.5 0.5], and then [0.25 0.5 0.25] filtering!</p>



<p>This sequence of two convolutions gives us an effective kernel of <strong>[0.125 0.375 0.375 0.125]</strong> on the zero inserted image, so if we multiply it by 2 simply alternating [0.25 0.0 0.75 0.0] and [0.0 0.75 0.0 0.25]. <strong>Corners aligned bilinear upsampling (standard bilinear upsampling on the GPU) is exactly the same as the â€œmagic kernelâ€!</strong> ğŸ™‚Â This is also this second, more complicated explanation of bilinear 0.25 0.75 weights I promised.</p>



<p>Advantage of it is that with the effective weight of [0.25 0.75] and [0.75 0.25] (ignoring zeros) on alternating pixels, they have the same amount of filtering and <strong>variance reduction of 0.625</strong> â€“ very important!</p>



<p>This is how the combined frequency response compares to the previous one:Â </p>



<div><figure><a href="https://bartwronski.com/wp-content/uploads/2021/02/image-14.png"><img data-attachment-id="4222" data-permalink="https://bartwronski.com/image-14-4/" data-orig-file="https://bartwronski.com/wp-content/uploads/2021/02/image-14.png" data-orig-size="372,373" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="image-14" data-image-description="" data-image-caption="" data-medium-file="https://bartwronski.com/wp-content/uploads/2021/02/image-14.png?w=300" data-large-file="https://bartwronski.com/wp-content/uploads/2021/02/image-14.png?w=372" loading="lazy" src="https://bartwronski.com/wp-content/uploads/2021/02/image-14.png?w=372" alt="" width="393" height="394" srcset="https://bartwronski.com/wp-content/uploads/2021/02/image-14.png 372w, https://bartwronski.com/wp-content/uploads/2021/02/image-14.png?w=150 150w, https://bartwronski.com/wp-content/uploads/2021/02/image-14.png?w=300 300w" sizes="(max-width: 393px) 100vw, 393px"/></a><figcaption>Two ways of bilinear upsampling both leave aliasing (everything after the dashed line half Nyquist), as well as blur the signal (everything before it).</figcaption></figure></div>



<p>So as expected, more blurring, less aliasing, consistent behavior between pixels.</p>



<p>Neither is perfect, but the even one will generally cause you less â€œproblemsâ€.</p>



<h2>Signal processing â€“ bilinear downsampling</h2>



<p>By comparison, downsampling process should be a bit more familiar to readers who have done some computer graphics or image processing and know of aliasing in this context.</p>



<p>Downsampling consists of two steps in opposite order: <strong>1. Filtering the signal.</strong> <strong>2. Decimating the signal by discarding every other sample</strong>.</p>



<p>The ordering and step no 1 is important, as the second step, decimating is equivalent to (re)sampling. If we donâ€™t filter the signal spectrum above frequencies representible in the new resolution, we are going to end up with aliasing, folding back of frequencies above previous half Nyquist:</p>



<figure><a href="https://bartwronski.com/wp-content/uploads/2021/02/image-20.png"><img data-attachment-id="4232" data-permalink="https://bartwronski.com/image-20-4/" data-orig-file="https://bartwronski.com/wp-content/uploads/2021/02/image-20.png" data-orig-size="706,373" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="image-20" data-image-description="" data-image-caption="" data-medium-file="https://bartwronski.com/wp-content/uploads/2021/02/image-20.png?w=300" data-large-file="https://bartwronski.com/wp-content/uploads/2021/02/image-20.png?w=640" loading="lazy" width="706" height="373" src="https://bartwronski.com/wp-content/uploads/2021/02/image-20.png?w=706" alt="" srcset="https://bartwronski.com/wp-content/uploads/2021/02/image-20.png 706w, https://bartwronski.com/wp-content/uploads/2021/02/image-20.png?w=150 150w, https://bartwronski.com/wp-content/uploads/2021/02/image-20.png?w=300 300w" sizes="(max-width: 706px) 100vw, 706px"/></a><figcaption>When decimating, original signal frequencies will alias, appearing as wrong ones after decimation. To prevent aliasing, you generally want to prefilter the image with a strong antialiasing â€“ lowpass â€“ filter.</figcaption></figure>



<p>This is the aliasing the nearest-neighbor (no filtering) image downsampling causes:</p>



<div><figure><a href="https://bartwronski.com/wp-content/uploads/2021/02/image-21.png"><img data-attachment-id="4234" data-permalink="https://bartwronski.com/image-21-4/" data-orig-file="https://bartwronski.com/wp-content/uploads/2021/02/image-21.png" data-orig-size="380,373" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="image-21" data-image-description="" data-image-caption="" data-medium-file="https://bartwronski.com/wp-content/uploads/2021/02/image-21.png?w=300" data-large-file="https://bartwronski.com/wp-content/uploads/2021/02/image-21.png?w=380" loading="lazy" src="https://bartwronski.com/wp-content/uploads/2021/02/image-21.png?w=380" alt="" width="361" height="354" srcset="https://bartwronski.com/wp-content/uploads/2021/02/image-21.png?w=361 361w, https://bartwronski.com/wp-content/uploads/2021/02/image-21.png?w=150 150w, https://bartwronski.com/wp-content/uploads/2021/02/image-21.png?w=300 300w, https://bartwronski.com/wp-content/uploads/2021/02/image-21.png 380w" sizes="(max-width: 361px) 100vw, 361px"/></a><figcaption>Aliasing manifests as wrong frequencies; notice on the bottom plot how end of the spectrum looks like 2x smaller frequency than before decimation.</figcaption></figure></div>



<h3>Bilinear downsampling take one â€“ even bilinear filter</h3>



<p>First antialiasing filter weâ€™d want to analyze would be our old friend â€œlinear in box disguiseâ€, [0.5, 0.5] filter. It is definitely imperfect, and we can see <strong>both blurring, and some leftover aliasing</strong>:</p>



<div><figure><a href="https://bartwronski.com/wp-content/uploads/2021/02/image-23.png"><img data-attachment-id="4239" data-permalink="https://bartwronski.com/image-23-4/" data-orig-file="https://bartwronski.com/wp-content/uploads/2021/02/image-23.png" data-orig-size="372,373" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="image-23" data-image-description="" data-image-caption="" data-medium-file="https://bartwronski.com/wp-content/uploads/2021/02/image-23.png?w=300" data-large-file="https://bartwronski.com/wp-content/uploads/2021/02/image-23.png?w=372" loading="lazy" width="372" height="373" src="https://bartwronski.com/wp-content/uploads/2021/02/image-23.png?w=372" alt="" srcset="https://bartwronski.com/wp-content/uploads/2021/02/image-23.png 372w, https://bartwronski.com/wp-content/uploads/2021/02/image-23.png?w=150 150w, https://bartwronski.com/wp-content/uploads/2021/02/image-23.png?w=300 300w" sizes="(max-width: 372px) 100vw, 372px"/></a></figure></div>



<p>The Graphics community realized this a while ago â€“ when doing a series of downsamples for post-processing, <strong>for example bloom / glare</strong>; the default box/tent/bilinear filters are pretty bad in such case. Even small aliasing like this can be really bad when it gets â€œblownâ€ to the whole screen, and especially in motion. It was even a large chunk of Siggraph presentations, like <a href="http://www.iryoku.com/next-generation-post-processing-in-call-of-duty-advanced-warfare">this excellent one</a> from my friend Jorge Jimenez.</p>



<p>I also had a personal stab at addressing it early in my career, and even described the idea â€“ weird cross filter (because it was fast on the GPU) â€“ please donâ€™t do it, itâ€™s a bad idea and very <a href="https://bartwronski.com/2014/03/23/gdc-follow-up-screenspace-reflections-filtering-and-up-sampling/">outdated</a>! ğŸ™‚Â </p>



<h3>Bilinear downsampling take two â€“ odd bilinear filter</h3>



<p>By comparison the odd bilinear filter (that doesnâ€™t shift the phase) looks like a little different trade-off:</p>



<div><figure><a href="https://bartwronski.com/wp-content/uploads/2021/02/image-22.png"><img data-attachment-id="4237" data-permalink="https://bartwronski.com/image-22-4/" data-orig-file="https://bartwronski.com/wp-content/uploads/2021/02/image-22.png" data-orig-size="372,373" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="image-22" data-image-description="" data-image-caption="" data-medium-file="https://bartwronski.com/wp-content/uploads/2021/02/image-22.png?w=300" data-large-file="https://bartwronski.com/wp-content/uploads/2021/02/image-22.png?w=372" loading="lazy" width="372" height="373" src="https://bartwronski.com/wp-content/uploads/2021/02/image-22.png?w=372" alt="" srcset="https://bartwronski.com/wp-content/uploads/2021/02/image-22.png 372w, https://bartwronski.com/wp-content/uploads/2021/02/image-22.png?w=150 150w, https://bartwronski.com/wp-content/uploads/2021/02/image-22.png?w=300 300w" sizes="(max-width: 372px) 100vw, 372px"/></a></figure></div>







<p>To get better results -&gt; youâ€™ll need more samples, some of them with negative lobes. And you can design an even filter with more samples too, for example even Lanczos:</p>



<div><figure><a href="https://bartwronski.com/wp-content/uploads/2021/02/image-27.png"><img data-attachment-id="4251" data-permalink="https://bartwronski.com/image-27-4/" data-orig-file="https://bartwronski.com/wp-content/uploads/2021/02/image-27.png" data-orig-size="372,373" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="image-27" data-image-description="" data-image-caption="" data-medium-file="https://bartwronski.com/wp-content/uploads/2021/02/image-27.png?w=300" data-large-file="https://bartwronski.com/wp-content/uploads/2021/02/image-27.png?w=372" loading="lazy" src="https://bartwronski.com/wp-content/uploads/2021/02/image-27.png?w=372" alt="" width="339" height="340" srcset="https://bartwronski.com/wp-content/uploads/2021/02/image-27.png?w=339 339w, https://bartwronski.com/wp-content/uploads/2021/02/image-27.png?w=150 150w, https://bartwronski.com/wp-content/uploads/2021/02/image-27.png?w=300 300w, https://bartwronski.com/wp-content/uploads/2021/02/image-27.png 372w" sizes="(max-width: 339px) 100vw, 339px"/></a><figcaption>Itâ€™s possible to design better downsampling filters. This is just an example, as itâ€™s an art and craft of its own (on top of the hard science). ğŸ™‚</figcaption></figure></div>



<h2>Side note â€“ different trade-offs for up/downsampling?</h2>



<p>One interesting thing that has occurred to me on a few occasions is that the trade-offs for low pass filtering for upsampling and downsampling are different. If you use a â€œperfectâ€ upsampling lowpass filter, you will end up with nasty ringing.</p>



<p>This is typically not the case for downsampling. So you can opt for a sharper filter when downsampling, and a less sharp for upsampling, and this is what Photoshop suggests as well:</p>



<div><figure><a href="https://bartwronski.com/wp-content/uploads/2020/04/image-22.png"><img data-attachment-id="3806" data-permalink="https://bartwronski.com/image-22/" data-orig-file="https://bartwronski.com/wp-content/uploads/2020/04/image-22.png" data-orig-size="415,291" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="image-22" data-image-description="" data-image-caption="" data-medium-file="https://bartwronski.com/wp-content/uploads/2020/04/image-22.png?w=300" data-large-file="https://bartwronski.com/wp-content/uploads/2020/04/image-22.png?w=415" loading="lazy" src="https://bartwronski.com/wp-content/uploads/2020/04/image-22.png?w=415" alt="" width="382" height="268" srcset="https://bartwronski.com/wp-content/uploads/2020/04/image-22.png?w=382 382w, https://bartwronski.com/wp-content/uploads/2020/04/image-22.png?w=150 150w, https://bartwronski.com/wp-content/uploads/2020/04/image-22.png?w=300 300w, https://bartwronski.com/wp-content/uploads/2020/04/image-22.png 415w" sizes="(max-width: 382px) 100vw, 382px"/></a><figcaption>Photoshop also suggests smoother/more blurry upsampling filter, while a sharper (closer to â€œperfectâ€) lowpass filter, because ringing / halos tend to not be as much of a problem there as in the case of upsampling.</figcaption></figure></div>



<h2>Conclusions</h2>



<p>I hope that my blog post helped to clarify some common confusions coming from using the same, very broad terms to represent some different operations.</p>



<p>A few of main takeaways that Iâ€™d like to emphasize would be:</p>



<ol><li>There are <strong>a few ways of doing bilinear upsampling and downsampling</strong>. Make sure that whatever you use uses the same convention and <strong>doesnâ€™t shift your image</strong> after down/upsampling.</li><li>Half pixel center offset is a very convenient convention. It ensures that <strong>image borders and corners are aligned</strong>. It is default on the GPU and happens automatically. When working on the CPU/DSP, itâ€™s worth using the same convention.</li><li>Different ways of upsampling/downsampling have different frequency response, and different aliasing, sometimes varying on alternating pixels. If you care about it (and you should!), look more closely into which operation you choose and <strong>optimal performance/aliasing/smoothing tradeoffs</strong>.</li></ol>



<p>I wish more programmers were aware of those challenges and weâ€™d never again again hit bugs due to inconsistent coordinate and phase shifts between different operations or librariesâ€¦ I also with we could never see those â€œtriangularâ€ or jagged aliasing artifacts in images, but bilinear upsampling is so cheap and useful, that instead we should be just simply aware of potential problems and proactively address them.</p>



<p>To finish this section, I would again encourage you to read <a href="https://bartwronski.com/2020/04/14/bilinear-texture-filtering-artifacts-alternatives-and-frequency-domain-analysis/">my previous blog post </a>on some alternatives to bilinear sampling.</p>



<p>PS. What was my bug that I mentioned at beginning of the post? Oh, it was simple â€œoff by oneâ€ â€“ in numpy when convolving with np.signal.convolve1d and 2d I assumed wrong â€œdirectionâ€ of the convolution of even filters. Subtle bug, but it was shifting everything by one pixel after sequence of downsamples and upsamples. Oops. ğŸ˜…</p>
											</div></div>
  </body>
</html>
