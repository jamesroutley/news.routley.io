<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://web.archive.org/web/20121024051826/http://www.geocities.com/tablizer/top.htm">Original</a>
    <h1>Table Oriented Programming (2002)</h1>
    
    <div id="readability-page-1" class="page">

<center>


<hr/>

<img src="https://blog.rowan.earth/web/20121024051826im_/http://www.geocities.com/tablizer/tably.gif"/>
<SPAN face="arial">


A practical, intuitive, and consistent way to organize</SPAN>
<SPAN size="+1">

<hr/>

<SPAN color="#700030">
<h2> Summary of Primary Table-Oriented-Programming Concepts </h2>
</SPAN>

</SPAN></center><SPAN size="+1">

<ol>
<li> <b>Control Tables</b> - A way of organizing processing,
     decision, and attribute logic.
</li><li> <b>Table-Friendly Syntax</b> - Syntax and language constructs
     that make dealing with tables and T.O.P. easier and more
     natural. This includes overcoming the weaknesses of SQL.
</li><li> <b>Data Dictionaries</b> - Special Control Tables for
     storing processing, decision, and attribute logic for
     relational database fields and/or UI fields.
</li><li> <b>Fundamental and Consistent Collection Operations</b>
     - A base set of operations (interface)
     that all collections (tables, trees, stacks, lists, etc.)
     should have easy or built-in access to regardless of a
     collection&#39;s current size or complexity.
     (<SPAN color="red">Arrays are evil!</SPAN>
     Arrays are the Goto of the collections world.)
</li><li> <b>Code Management</b> - Relational tables are a potentially much
     more sophisticated tool for managing complex and multi-faceted
     collections of programming code than OO classes or files.
</li><li> <b>Database Engine Neutrality</b> - A T.O.P. system should be
     able to access a wide variety of database engines. There are
     some practical limitations to this, but the goal should be
     kept in mind.
</li><li>
    <b>Memory-Mapping Reduction</b> - The goal of reducing or
    eliminating the need to manually map and/or transfer memory variables
    to and from table fields and to and from the UI (screens).
    (This process should be invisible to the programmer regardless
    of the fact that internal implementation usually uses
    memory-based copies.)
</li><li> <b>File Directory Management</b> - 
    Hierarchies are too narrow in scope and too restrictive.
    It is time for multi-aspect thinking. One search key (the
    hierarchy) is not enough. (<a href="https://blog.rowan.earth/2022-worldbuilding-calendar/sets1.htm">Link</a>)
</li></ol>

<p><small>
Most of these concepts can be summed up nicely
</small>
</p>

<hr/>
<p>

Table-Oriented Programming (TOP for short) can be characterized
as a programming language and/or development method that makes
dealing with tables, lists, indexing, sorting, searching,
filtering, etc. a native and direct part of 
language design and complexity management.
This is a contrast to the clumsy collection API&#39;s and attribute
management techniques such as set/get
made popular by object oriented programming vendors.
Table-Oriented Programming can also be characterized by using tables to organize program logic, not just data. Such tables are called 
<a href="https://blog.rowan.earth/2022-worldbuilding-calendar/cntrl1.htm">Control Tables</a>.
They offer potential organization benefits over both raw
procedural programming and object oriented programming.
</p><p>
Most general-purpose languages use API-like constructs (function library calls) and SQL to deal with tables. We believe that this approach is too bulky, code intensive, and formal to be used often. Pushing into, Pulling out of, and converting data for API&#39;s and SQL is not very practical. (Some OOP languages do not call them API&#39;s but use something that is essentially the same.)
</p><p>
For example, most languages have special math-handling
syntax for dealing with mathematical equations. Example:
</p><pre>   a = (b * c) + e + f
</pre>
Now, if your only choice was to use API&#39;s, then you
would have to use syntax like:
<pre>   a = plus(plus(times(b,c),e),f)      // silly example
</pre>
Or, in OOP-ish syntax:
<pre>   a = ((b.times(c)).plus(e)).plus(f)   // sillier
</pre>
Or, as an OOP purist:
<pre>   a = ((b.math.times(c)).math.plus(e)).math.plus(f)   // silliest
</pre>

It would of course be silly to force math experts to use
such syntax; yet the <b>equivalent</b> is being done to database
and table developers.
This API-like approach is fine for occasional use, 
but if 70% of your
applications dealt with math, this would get a bit
cumbersome. We have  
<a href="https://blog.rowan.earth/2022-worldbuilding-calendar/funcs.htm">special constructs and syntax</a>
for math, <b>why not tables?</b> 
Most custom business applications use or need 
far more table handling than math. Perl is the king
of strings, Java is the king of networking, C is the
king of speed, we now need a king of tables. (SQL and
MS-Access fall short of the title).
<p>
The market focus on <a href="https://blog.rowan.earth/2022-worldbuilding-calendar/oopbad.htm">Object Oriented Programming</a> has left table-handling in the dust with regard to innovation.  Sorted tables and lists are actually very useful for dealing with complex data structures including 
<a href="https://blog.rowan.earth/2022-worldbuilding-calendar/trees.htm">trees</a>, 
stacks, queues, etc. Also, tables are not limited by the size of RAM, unlike traditional data structure algorithms. They provide built-in virtual memory. 
</p><p>
Most custom business applications are very table intensive. Accounting, inventory, reservation systems, order tracking, etc., are common examples. Also, file and directory lists, E-mail lists, sales prospects, and even lines and circles in a drawing program can be represented with tables. Yet, the languages usually used, such as C++ and Visual Basic, use nothing more than API&#39;s to work with tables. These languages 
encourage people to use in-memory constructs rather
than ordered tables. Sad.
</p><p>
<a name="sql"></a>
Although SQL is a high-level language that is quite powerful for certain types of operations, it is far from a general-purpose table processing language. Many programmers end up writing &#34;speggitti-SQL&#34; because the alternative is to use annoying API calls or convert to data cursors. SQL is also a poor match for interactive programs because it is more of a batch-processing and query processing language. 
</p><p>
SQL&#39;s set-oriented processing approach is often just not appropriate for many situations. SQL also has an annoying nest-happy LISP-like structure, which makes breaking down the logic into manageable chunks tough, especially for multi-joins. Using cursors can sometimes help, but they are far from standardized, given low vendor attention, and often not given &#34;native&#34; or direct access to the data engine.

</p><p>
SQL also cannot use functions and methods that are 
<u>in</u> the calling program; you have to use SQL&#39;s built-in or external functions. <u>SQL puts a wall between you, your code, and the data.</u> In addition, SQL does not support named fields sets, which will be described later.
(<a href="https://blog.rowan.earth/2022-worldbuilding-calendar/moretop.htm#sqlstuff">More on SQL and stored procedures.</a>)
</p><p>
TOP languages do exist in various levels or incarnations of
Table-orientedness. These include Xbase derivatives (dBASE, FoxPro, Clipper),
PAL (Paradox), Power-Builder, Perl (for certain list types), Progress,
Oracle&#39;s PL/SQL, and Clarion Developer.
(We will not necessarily vouch for the quality or design of
these languages, only say that they have a table-tilt to them.) 
These languages get little press compared to big OOP languages. Also, when upgrades are built for them, OOP features get most of the development resources, and their TOP features are treated as second priority by the vendors now. 
</p><p>
Why does OOP get 20 times more attention than TOP? We are not saying that TOP should be everything, but it does not deserve to be ignored. Being that tables are common and powerful, TOP does not deserve only 5% of the amount of attention that OOP gets. <u>We only ask for balance, not an overthrow.</u>
</p><hr/>
<h2> My Motivation </h2>

Why am I so heck-bent on promoting Table-Oriented-Programming?
Simply because I have found the table paradigm so very
useful for RAD (rapid development), software organization, and
flexibility.
Yet the IT market focused on technologies like <a href="https://blog.rowan.earth/2022-worldbuilding-calendar/oopbad.htm">
Object Oriented Programming</a> that made for better brochures
and airline magazine articles instead of real and practical
benefits. 
<p>
My exposure to TOP started back in the late 1980&#39;s when I
purchased a dBASE III book. I quickly fell in love with
dBASE and later its <a href="https://blog.rowan.earth/2022-worldbuilding-calendar/xbasefan.htm">XBase</a> derivatives.
(dBASE was not the first language I learned, nor was it
the first that I used in a commercial setting.)
It made working with relational tables such a snap that
I started to view ALL collections as XBase tables.
(Collections are any set of similar or closely related items.)
This even began including <a href="https://blog.rowan.earth/2022-worldbuilding-calendar/cntrl1.htm">program
logic</a>. (After all, OOP subclasses are simply a collection of
related classes.)
</p><p>
Other languages tended to use different
&#34;containers&#34; within the same language for collections.
Such containers include
arrays, vectors, dictionaries (associative arrays),
and API/object interfaces
to SQL database engines. The problem with these is that
they are very limited and very different from each
other. If the needs of a collection grew beyond the
bounds or features of one of these structures or significantly changed
in requirements, then switching to another
&#34;<a href="https://blog.rowan.earth/2022-worldbuilding-calendar/trees.htm#flatten">type</a>&#34;
of collection container or re-creating the needed
collection feature by hand was a pain in the [beep],
let alone darn illogical.
</p><p>
It seemed much more logical to me to have ONE
kind of interface into ANY collection and then
hook up an easy-to-use set of
<a href="https://blog.rowan.earth/2022-worldbuilding-calendar/collrght.htm">standard collection operations</a>
that would be available to ALL collections big and small.
(Not all engines will support all features, but the idea
is to switch engines to get needed features, and not your
existing API calls.)
Although it has some annoying limitations and language weaknesses,
XBase opened my eyes to table-oriented thinking.


</p><p>
OOP and other fads and trends prevented this powerful view
of collections from progressing any further, and even
reversed it to some extent. SQL as
an interface is fine for formal transactions, but is
too bulky and formal for many types of collection
manipulations. Thus, I am here trying to sell the dream and vision of
perhaps what should be called &#34;collection-oriented-programming.&#34;
I found it a more powerful metaphore than anything else
on the market, and I hope you will too.
</p></SPAN><hr/>
<a name="itop"></a>
<h2> Ideal Table Oriented Programming (ITOP) Features </h2>

We have looked at table-intensive processes and found a common set of features that would enhance TOP features of existing languages. We call these features &#34;Ideal Table Oriented Programming&#34; because not all are found in existing TOP languages. These features are to TOP what Inheritance, Polymorphism, and Encapsulation are to OOP. (In fact, ITOP 
<a href="https://blog.rowan.earth/2022-worldbuilding-calendar/buzzword.htm">shares many of these OOP aspects</a>.)
<center>
<a name="dd"></a>
<h3> Data Dictionaries </h3>
</center>

First, we will present an example data dictionary portion. Data dictionaries are an important concept to ITOP. We will refer to parts of it below to explain certain concepts. <p>


<table>
<caption>Data Dictionary Sample (simplified) </caption>
<tbody><tr>
  <th>Table- Spec.</th>
  <th>Field-Name</th>
  <th>Field-Title</th>
  <th>Pre-Func.</th>
  <th>Post-Func.</th>
  <th>Groups</th>
  <th>Sort-1</th>
  <th>Pick-Func.</th>
  <th>Total- able</th>
</tr>
<tr>
  <td>Customers</td>
  <td>CustName</td>
  <td>Customer Name</td>
  <td>{none}</td>
  <td>{none}</td>
  <td>R</td>
  <td>10</td>
  <td><nobr>custProfl()</nobr></td>
  <td>No</td>
</tr>
<tr>
  <td>Purchases</td>
  <td>PurchDate</td>
  <td>Purchase Date</td>
  <td>vdate1()</td>
  <td>dateFmt1(2)</td>
  <td>B,R</td>
  <td>20</td>
  <td>{none}</td>
  <td>No</td>
</tr>
<tr>
  <td>Trans</td>
  <td>Amt</td>
  <td>Purchase Amount</td>
  <td><nobr>preDollar()</nobr></td>
  <td><nobr>postDollar(</nobr> &#34;###,###.##&#34;)</td>
  <td>B,R</td>
  <td>30</td>
  <td>{none}</td>
  <td>Yes</td>  
</tr>

</tbody></table>
</p><p>
<u>Breif Table Legend:</u> 
</p><p>


Data dictionaries (DD&#39;s) are sort of a <b>table describing a table(s).</b> 
A DD differs from a common table structure list in that it may apply
to more than one table, and it can also assign functions or
behavior to handle common or related operations. DD&#39;s
are often described as only a documentation tool in some literature;
however, we are
extending or allowing them to also be used for the centralized
storage of field-related properties and/or operations actually used
in software.
</p><p>
Under ideal conditions, the DD provides enough information to generate input screens, multi-row grids, and reports without programming these from scratch. It keeps all logic related to a field or column in <b>one central place.</b> (Similar to the goal of an OOP class or subclass.)
It is much easier to find and change information in DD tables than hunting through
saparate modules or subclasses in program code.
DD&#39;s are not intended to replace all program code, just reduce
the need for it except down at the true customization level where it belongs.
</p><p>
See an 
<a href="https://blog.rowan.earth/2022-worldbuilding-calendar/ddsamp.htm">actual data dictionary</a>
for more examples and specifics.
Note that the linked examples don&#39;t need to contain programming
code and function calls to be effective. Putting programming
code in tables is simply one TOP technique among many,
but not a prerequisite.

</p><h3> The End of Linear Paradigms</h3>

Data dictionaries greatly reduce the need for bulky field
specifications often used in OOP:
<pre>   field1.property1 = x
   field1.property2 = x
   field1.property3 = x
   ...etc...
   field1.property29 = x
   field1.property30 = x
   field2.property1 = x
   field2.property2 = x
   ...etc...
   field49.property1 = x
   field49.property2 = x
   field49.property3 = x
   ...etc...
   field50.property30 = x
</pre>
I see these constructs all over VB and Java code. 
A construct like this is crying out for a tabled 
alternative when you have several dozen fields and
several properties/functions. If you have 4 tables with 20 fields each, and each field averages 15 used properties, then you would have to write about 1,200 lines of code. (4 x 20 x 15) However, this could be converted into a table that is about 80 by 20 in cell dimensions (we are assuming that there are a total of 20 properties and/or functions). The 2D nature of tables makes them much more compact and logical for representing similar information. (This applies to 
<a href="https://blog.rowan.earth/2022-worldbuilding-calendar/cntrl1.htm">control tables</a>
 as well as DD&#39;s.) Code that repeats similar, but slightly different constructs or assignments over and over again is sometimes called &#34;comb&#34; code, or &#34;E&#34; code because of it&#39;s repetitous appearance. (Stacked E&#39;s resemble a 
<a href="https://blog.rowan.earth/2022-worldbuilding-calendar/buzzword.htm#comb">comb</a>.)

<h3> Optional Data Dictionary </h3>

Although data dictionaries are very powerful, they should be optional. This is because DD&#39;s are a bit formal and take some effort to build, just like any good organizational paradigm. 
You should be able to generate a quick data table in a program without having to fill out a DD. Not all tables and lists require high levels of formality, especially if there are only a few fields. ITOP does not focus on just large or just small tables. Tables may be quick, ad-hoc array-like structures, billion-record IRS transactions, or something in-between. DD&#39;s should not be shoved down one&#39;s throat.
<h3> Detached Data Dictionary </h3>

In addition to being optional, DD&#39;s should not be built into the table file itself. This is where Microsoft Access goes wrong. DD&#39;s cannot be shared as easily if there must be a one-to-one relationship with each table. (One-to-one DD&#39;s can still be built if desired.) For example, sometimes the same or similar structures and operations are used with many different tables. 
<p>
Allowing all such tables to share one or few DD&#39;s makes maintanence much easier. Plus, tables from different systems can be accessed without having to convert to or from its native DD&#39;s. 
</p><p>
An ITOP application should make it easy to physically
separate the program code, data dictionary, and actual
tables if so desired. An option to jam them altogether
like MS-Access prefers should also be given.
</p><p>
In the DD example, the Table-Spec column allows asterisks to indicate that the Field-Name will be used to find the appropriate entry. For example, several tables may have a CustName field in them. Rather then creating an entry for each table, an asterisk is put in the TableSpec column to serve as a wild-card.

</p><h3> Extendable Data Dictionary </h3>

In addition to being optional, the DD should also be extendible if
needed by the application. ITOP should only expect that a certain minimum
set of fields be included. The developer should be able to add 
fields to the data dictionary as needed. 
<p>
For example, if a certain action happens when a field is double-clicked,
the data dictionary should be able to have a new column to enter the
snippet or function call for each field upon double-clicking. (This
example assumes that double-clicking is not already part of the minimum
standards.)

</p><h3> Pre and Post Validation Functions </h3>

The pre- and post-validation functions are a very powerful part of ITOP. They allow consistent processing of fields regardless of where they are entered or displayed. For example, the pre-validation function executes regardless of whether the data was entered in a form, a grid, or any other input approach (assuming a short-cut outside of ITOP is not used.)
<p>
The pre-validation function serves two purposes. First, it checks the data to see that it is correct, and second, formats the field data for storage. For instance, a date may be input as &#34;12/31/1998&#34;. The pre-validation function may change it to &#34;19981231&#34; before storing it in the actual table. If the user entered &#34;12/32/1998&#34;, then the function would return a value of &#39;false&#39; indicating an error. The function may resemble this psuedo code:
</p><pre>  Boolean Function Vdate1()  
    boolean status = true     // initialize
    yearpart = substr(curfld,7,4)
    monthpart = substr(curfld,1,2)
    daypart = substr(curlfd,4,2)
    if not between(monthpart,&#34;01&#34;,&#34;12&#34;) _
       or not between(daypart,&#34;01&#34;,&#34;31&#34;) then
      status = false
      curmsg = &#34;Bad month or day number&#34;
    else
      curout = convert2yyyymmdd(curfld)
    endif
    return(status)   // true if passed
  End Function
</pre>
Notes: Curfld, Curmsg, and Curout pre-assigned variables. Curfld is the current field as entered by the user. Curmsg is the error message given to the user if the validation fails (a default is assigned if not programmed), and Curout is the field re-formatted for storage. The ITOP system automatically prepares and uses these variables before and after the function is triggered by user or batch actions. Another such reserved variable may be the length of the native string. This variable assignment method is only one possible approach to pre-validation routines; depending on the programming language, it may be better to pass these as function parameters instead.
<p>
Post-validation routines re-format the input for display. There is no true/false return value since it was already checked during input. Therefore, the return value will be the reformatted field. For example, if the stored value is &#34;19981231&#34;, then the post-validation function can turn it into &#34;12/31/1998&#34;. In short, the post-validation function makes the output prettier or easier to read. The example above uses Datefmt1(2). This sample function returns the date with years shown as 2-digits. (The function may get the original value from a Curfld-like variable as shown in the pre-validation example.)
</p><p>
It may seem like a pain to write pre- and post-validation functions, but remember that the same functions can be used over and over again. The inputs and outputs to these functions are generic enough that generic functions can be written for common formats like dates, phone numbers, etc. Thus, you do not have to re-invent the wheel for similar field types. (Although the programmer is expected to build all the validation functions, a pre-built set could be included in the DD kit to save steps or serve as examples.)


</p><h3> Sort Orders </h3>


Data Dictionary Sort orders specify the order that fields appear on reports and screens. In our example the fields are given an order in the Sort-1 column.
The DD could also have a Sort-2 column, Sort-3 column, etc.


<hr/>
<h3> Standard Collection Operations </h3>

A good table-oriented system gives every collection (such as tables) a standard
set of operations that can be used on <b>all</b> tables. One is
not limited just to the operations that the programmer can see in advance
and explicitly builds in for a given collection. Building or adding
each of these operations in one at a time as the needs arise can be very
time-consuming.
<p>
These operations include
filtering, ordering, searching, auto caching and persistence, 
grouping and totaling, transferring, import and export, field/property 
selection, inserting, deleting, updating, and joining or relating.
<a href="https://blog.rowan.earth/2022-worldbuilding-calendar/collrght.htm">Click here for more details</a> 
on these fundamental operations.


<a name="ceiling"></a>
</p><h2> No Ceilings!</h2>

Many current approaches to collection processing have practical
ceilings that require arbitrary interface changes to move to
the next step.
When these ceilings are reached, the programmer is
forced to revamp the existing code to take advantage of
the next level of power. Such revamping is a waste of time
and resources. (<a href="https://blog.rowan.earth/2022-worldbuilding-calendar/meyer1.htm">Bertrand Meyer</a> calls
this the &#34;Continuity Problem&#34;, where a small change in the
requirements results in a large change in program code.)
<b>It would be like having to steer with your elbow if on
a bicycle, steer with your nose if in a car, and then
steer with your foot if in an 18-wheel rig.</b>
<p>
Fortunately, the
transportation industry pretty much standardized on 
steering by turning a wheel with one&#39;s hands regardless
of the vehicle size or task. (Well,
the bike uses a bar, but close enough.) The software
collections industry is not this wise yet. They still
want to <b>divide</b> collections into things like stacks,
queues, sets, dictionaries, trees, etc.; letting
short-lived operational needs drive the protocol chosen.
Collection needs change and grow over time repeatedly
in my experience. Thus, one should pick a flexible
collections protocol. Once a stack always a stack? Nooooo
waaaay. It may continue still acting
as a stack for some operations,
but often will need other views as well.
</p><p>
These ceilings are usually either complexity ceilings
or size ceilings (such as RAM). Let&#39;s look at a common Perl
approach and then some SQL problems that tend to be
ceiling bound.
</p><p>
Perlers often use lists of lists and/or pointers to lists
to store and process collections. Perl &#34;associative
arrays&#34; are basically a RAM table with 2 columns and
one index (to the &#34;key&#34; column).
If the requirements suddenly change, such as
the need for 3 columns, or 2 indexes with persistence, one then
has to completely <b>revamp</b> the way fields and/or indexing
is done. Perlers usually add a second level of complexity
in the form of a list of pointer or a list of lists.
In ITOP, or even XBase, these additions would be dirt simple.
There is nothing magic about the limit of 2 columns and
one index, so why does Perl and array-centric
thinking impose this <b>arbitrary limit</b>?

<small></small></p><blockquote><small>
Note that I have proposed using associative arrays elsewhere
quite a few times. This may seem like a contradiction. However,
those uses are generally an interface mechanism and not
data collection management.
</small></blockquote>

Although I find pointers to pointers 
nasty and error-prone to work with in almost any form, let
us just assume that this approach is fine in some cases.
However, if the complexity of the structure, the quantity
and variety of operations keeps growing, or the size of such
structures increase beyond a certain amount; then the
typical response is to use a more powerful relational
database add-in.
Aside from the fact that DB API&#39;s can be bureaucratic to work
with, one has to <b>convert</b> the native pointer structure and much
of its processing into something the DB API&#39;s can use.
<p>
Thus, there are roughly 3 different kinds of interfaces
one has to use as a collection graduates from simple to middle-level to
complex:
</p><ol>
<li> A regular or associative array.
</li><li> An array of arrays (or a list of pointers) if
     the structure grows beyond 2 columns or 1 index.
     (A &#34;doubling-up,&#34; if you will.)
</li><li> Relational API&#39;s when heavy persistence, concurrency,
     or size is needed.
</li></ol>
<p>
I see no reason why the same basic interface cannot be used
from baby collections to Oracle-size collections. Why
the industry tolerates this, I have no idea. Perhaps because
they have not seen collections done right.
</p><p>
Note that there may
be some minor setting differences as collections
scale. For example, transaction markers and concurrency
error handling may need to be specified for the
higher-end collections. However, these can be treated
as <b>additions</b> to the existing code, <b>not overhauls</b>.
</p><p>
Now let&#39;s look at traditional SQL operations. SQL is
usually fine for fairly simple processing stuff. However, as the
number of expressions, links (joins), and/or fields
increase; SQL can get nasty at times. Standard SQL lacks many
block-box (subroutines) and reference reduction (factoring)
techniques found in most programming
languages (and promoted as &#34;a good practice&#34;).
In standard SQL you usually cannot assign variables,
macros, subroutines, etc. to complex or repeating parts
in order to break the logic and sequence down into
<b>more manageable parts</b>. You simply end up with one big, messy
string with lots of parenthesis. Beyond a certain
complexity point one has to break the statement into
2 or more separate SQL statements.
</p><p>
Further, if set-oriented operations are no longer
sufficient to handle the complexity of the job,
the <b>entire</b> SQL statement has to be
<b>converted</b> into a cursor-oriented approach
that deals better with one record at a time. It is like
having to stop, backup for several miles, and then
start again on a different path.
(See <a href="https://blog.rowan.earth/2022-worldbuilding-calendar/sqlcrit.htm">SQL Criticism</a>.)
</p><p>
ITOP offers several techniques to avoid or reduce overhauls
from complexity and size changes. The primary technique
is the provision of a built-in set of standard, common,
rudimentary, yet powerful collection operations
(described above). Other techniques include
<a href="#sql_eval">internal-aware expression evaluation</a>
and the blurring of set-orientation versus cursor-orientation
in database commands. (Set-oriented operations have
some significant advantages in traditional client/server
setups, however, one should have a choice, especially
if the bandwidth between the client and the server is
sufficient.)

</p><p>
&#34;Complexity Scaling&#34; can also be horizontal as well
as vertical. For example, an API that is dedicated
to a stack collection can get cumbersome if the needs
grow outside of the traditional parameters of stacks.
I encounter the need to use and view stacks, trees,
queues, etc. in ways outside of these narrow collection
&#34;subtypes&#34; all the time. Requirements change and
your collections interface should be <b>ready</b> for such
<b>changes</b>.
</p>

<a name="convergence"></a>
<h2> Collection Convergence </h2>

There is a pattern to most of these (above) recommendations.

<p><img src="https://blog.rowan.earth/web/20121024051826im_/http://www.geocities.com/tablizer/converge.gif" alt="convergence diagram"/>
</p>

Right now many systems have roughly four different collections protocols or protocol types. 
Is there a reason for this? One may argue that different collections have different 
needs, and thus specialization is required. Although this is certainly true for the 
<b>implementation</b> much of the time, I find this generally not to be the case with the 
collection <b>protocols</b> themselves. The primary reason is that requirements change too often. 
A collection may start out as a tree or a stack, but <b>morphs</b> 
into a more general-looking collection as more requirements are needed. 
I have experienced this process on several occasions.
(See <a href="https://blog.rowan.earth/2022-worldbuilding-calendar/collrght.htm#taxonomy">The Collection Taxonomy Trap</a> 
for more about this, and
<a href="https://blog.rowan.earth/2022-worldbuilding-calendar/prpats.htm#dispatch">The Multi-Dispatch Pattern</a> 
for some source code management ideas.)
<p>
Besides morphability and scalability (described in previous
section), another benefit is <b>easier training</b>. 
Instead of learning four or more <b>different</b> collection 
management systems, one should only have to learn a single protocol. 
Fine adjustments and specialized extensions can then be added 
on as needed (such as a Pop(x) &#34;wrapper&#34; function for stack-like activity).
</p><p>
A third advantage is that the same collection system can be
used for all the different collection types and variations.
Rather than build a class/code
browser, an RDBMS browser, an array browser, etc.; vendors
can <b>focus</b> on building one grand collection system
and browser that does it all. It could even be modular such
that you can attach different text browsing engines that
highlight code keywords, etc. 
</p><p>
Even if you disagree with my specific protocol and/or syntax proposals, 
the idea of a consistent collection protocol should ring through 
as a very logical idea.

</p><blockquote><small>
 You may notice that my rejection of strong protocol taxonomies 
parallels my distaste for heavy use of sub-classing, also known as 
sub-typing and IS-A thinking. Software engineering has over-emphasized 
IS-A thinking. Perhaps in some niches it has an important place, but not 
for custom business applications.
</small></blockquote>

Â 
</div>
  </body>
</html>
