<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://swe-to-mle.pages.dev/posts/fooling-an-image-classifier/">Original</a>
    <h1>Fooling an Image Classifier</h1>
    
    <div id="readability-page-1" class="page"><div id="content"><p><em>In the dimly lit corridors of the ancient dungeon, where shadows dance and secrets lie in wait, an eerie silence is suddenly shattered by the faint creaking of wooden planks. Unbeknownst to the adventurers, a malevolent presence lurks among the mundane, adopting the guise of an innocuous chest or treasure trove. Beware the mimic, a shape-shifting aberration that hungers for the thrill of deception and the taste of unsuspecting intruders.</em></p>
<figure><a href="https://github.com/rguiscard/mimic.png" title="mimic" data-thumbnail="mimic.png" data-sub-html="&lt;h2&gt;Mimic awaiting its prey&lt;/h2&gt;&lt;p&gt;mimic&lt;/p&gt;">
        <img src="https://github.com/svg/loading.min.svg" data-src="mimic.png" data-srcset="mimic.png, mimic.png 1.5x, mimic.png 2x" data-sizes="auto" alt="mimic.png"/>
    </a><figcaption>Mimic awaiting its prey</figcaption>
    </figure>
<h2 id="the-quest">The Quest</h2>
<p>Crafting a <a href="https://en.wikipedia.org/wiki/Mimic_%28Dungeons_%26_Dragons%29" target="_blank" rel="noopener noreffer ">d&amp;d mimic</a>. Fool a CNN image classifier into thinking that a picture of a teapot is a chihuahua.</p>
<h2 id="image-classifier">Image Classifier</h2>
<p>Our target will be <a href="https://huggingface.co/microsoft/resnet-50" target="_blank" rel="noopener noreffer ">ResNet-50</a> pre-trained on <a href="https://huggingface.co/datasets/imagenet-1k" target="_blank" rel="noopener noreffer ">Imagenet-1k</a>.</p>
<p>Pull a pre-trained model from huggingface:</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>processor</span> <span>=</span> <span>AutoImageProcessor</span><span>.</span><span>from_pretrained</span><span>(</span><span>&#34;microsoft/resnet-50&#34;</span><span>)</span>
</span></span><span><span><span>model</span> <span>=</span> <span>ResNetForImageClassification</span><span>.</span><span>from_pretrained</span><span>(</span><span>&#34;microsoft/resnet-50&#34;</span><span>)</span>
</span></span></code></pre></div><p>For this post we’ll disable the normalization from the image processor because it makes things look wonky for humans</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>img_normalized</span> <span>=</span> <span>processor</span><span>(</span><span>image</span><span>,</span> <span>return_tensors</span><span>=</span><span>&#34;pt&#34;</span><span>)</span>
</span></span><span><span><span>img_not_normalized</span> <span>=</span> <span>processor</span><span>(</span><span>image</span><span>,</span> <span>return_tensors</span><span>=</span><span>&#34;pt&#34;</span><span>,</span> <span>do_normalize</span><span>=</span><span>False</span><span>)</span>
</span></span></code></pre></div><figure><a href="https://github.com/rguiscard/normalize.png" title="normalize" data-thumbnail="normalize.png" data-sub-html="&lt;h2&gt;Why we disable the normalization&lt;/h2&gt;&lt;p&gt;normalize&lt;/p&gt;">
        <img src="https://github.com/svg/loading.min.svg" data-src="normalize.png" data-srcset="normalize.png, normalize.png 1.5x, normalize.png 2x" data-sizes="auto" alt="normalize.png"/>
    </a><figcaption>Why we disable the normalization</figcaption>
    </figure>
<h2 id="modify-a-picture-by-hand">Modify a picture by hand</h2>
<p>Just to have a point of comparison let’s see what it would take before the teapot stop to be recognized by ResNet. By adding noise to the image, or by masking the side of the image.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>original_teapot</span> <span>=</span> <span>PIL</span><span>.</span><span>Image</span><span>.</span><span>open</span><span>(</span><span>&#34;teapot.jpg&#34;</span>
</span></span><span><span><span>teapot</span> <span>=</span> <span>processor</span><span>(</span><span>original_teapot</span><span>,</span> <span>return_tensors</span><span>=</span><span>&#34;pt&#34;</span><span>,</span> <span>do_normalize</span><span>=</span><span>do_normalize</span><span>)[</span><span>&#39;pixel_values&#39;</span><span>]</span>
</span></span><span><span><span>id</span><span>,</span> <span>_</span><span>,</span> <span>_</span><span>,</span> <span>_</span> <span>=</span> <span>classify</span><span>(</span><span>teapot</span><span>)</span>
</span></span><span><span>
</span></span><span><span><span># add random noise until it stops being a teapot</span>
</span></span><span><span><span>noisy_teapot</span> <span>=</span> <span>copy</span><span>.</span><span>deepcopy</span><span>(</span><span>teapot</span><span>)</span>
</span></span><span><span><span>while</span> <span>True</span><span>:</span>
</span></span><span><span>    <span>noise</span> <span>=</span> <span>torch</span><span>.</span><span>randn_like</span><span>(</span><span>teapot</span><span>)</span>
</span></span><span><span>    <span>noisy_teapot</span> <span>+=</span> <span>noise</span>
</span></span><span><span>    <span>noisy_teapot</span><span>.</span><span>clamp_</span><span>(</span><span>0</span><span>,</span> <span>1</span><span>)</span> <span># keep the image in the [0, 1] range</span>
</span></span><span><span>    <span>nid</span><span>,</span> <span>_</span><span>,</span> <span>_</span><span>,</span> <span>_</span> <span>=</span> <span>classify</span><span>(</span><span>noisy_teapot</span><span>)</span>
</span></span><span><span>    <span>if</span> <span>nid</span> <span>!=</span> <span>id</span><span>:</span> <span>break</span>
</span></span><span><span>
</span></span><span><span><span># mask sides of the picture until it stops being a teapot</span>
</span></span><span><span><span>masked_teapot</span> <span>=</span> <span>copy</span><span>.</span><span>deepcopy</span><span>(</span><span>teapot</span><span>)</span>
</span></span><span><span><span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>0</span><span>,</span> <span>224</span><span>,</span> <span>10</span><span>):</span>
</span></span><span><span>    <span>masked_teapot</span><span>[</span><span>0</span><span>,</span> <span>:,</span> <span>:,</span> <span>:</span><span>i</span><span>]</span> <span>=</span> <span>0</span> <span># mask a vertical strip on the left</span>
</span></span><span><span>    <span>masked_teapot</span><span>[</span><span>0</span><span>,</span> <span>:,</span> <span>:</span><span>i</span><span>,</span> <span>:]</span> <span>=</span> <span>0</span> <span># mask an horizontal strip on the top</span>
</span></span><span><span>    <span>nid</span><span>,</span> <span>_</span><span>,</span> <span>_</span><span>,</span> <span>_</span> <span>=</span> <span>classify</span><span>(</span><span>masked_teapot</span><span>)</span>
</span></span><span><span>    <span>if</span> <span>nid</span> <span>!=</span> <span>id</span><span>:</span> <span>break</span>
</span></span></code></pre></div><figure><a href="https://github.com/rguiscard/manual.png" title="manual" data-thumbnail="manual.png" data-sub-html="&lt;h2&gt;Manual noise/mask&lt;/h2&gt;&lt;p&gt;manual&lt;/p&gt;">
        <img src="https://github.com/svg/loading.min.svg" data-src="manual.png" data-srcset="manual.png, manual.png 1.5x, manual.png 2x" data-sizes="auto" alt="manual.png"/>
    </a><figcaption>Manual noise/mask</figcaption>
    </figure>
<h2 id="modify-using-gradient">Modify using gradient</h2>
<p>Let’s take advantage of the network to tell us how we could fool it.</p>
<p>Compute the gradient of the teapot with the desired label (e.g. “chihuahua”). And update the image with the generated gradient as noise, until it matches with the desired category.</p>
<p>To get the gradient I add a tensor of the same size as the trainingset filled with 0, and look at the gradient of this layer. By construction it will have the same gradient as the pixels in the image would.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>def</span> <span>morph</span><span>(</span><span>teapot</span><span>,</span> <span>target_idx</span><span>=</span><span>target_idx</span><span>):</span>
</span></span><span><span>  <span># some trick to get a gradient</span>
</span></span><span><span>  <span>gradient_noise</span> <span>=</span> <span>torch</span><span>.</span><span>zeros_like</span><span>(</span><span>teapot</span><span>,</span> <span>requires_grad</span><span>=</span><span>True</span><span>)</span>
</span></span><span><span>  <span>malicious_teapot</span> <span>=</span> <span>copy</span><span>.</span><span>deepcopy</span><span>(</span><span>teapot</span><span>)</span> <span>+</span> <span>gradient_noise</span>
</span></span><span><span>
</span></span><span><span>  <span>for</span> <span>epoch</span> <span>in</span> <span>tqdm</span><span>(</span><span>range</span><span>(</span><span>epochs</span><span>)):</span>
</span></span><span><span>    <span># forward pass</span>
</span></span><span><span>    <span>logits</span> <span>=</span> <span>model</span><span>(</span><span>malicious_teapot</span><span>)</span><span>.</span><span>logits</span>
</span></span><span><span>    <span>predicted_idx</span> <span>=</span> <span>logits</span><span>.</span><span>argmax</span><span>(</span><span>-</span><span>1</span><span>)</span><span>.</span><span>item</span><span>()</span>
</span></span><span><span>    <span># shortcircuit as soon as we match the target</span>
</span></span><span><span>    <span>if</span> <span>predicted_idx</span> <span>==</span> <span>target_idx</span><span>:</span>
</span></span><span><span>      <span>print</span><span>(</span><span>f</span><span>&#39;Predicted </span><span>{</span><span>model</span><span>.</span><span>config</span><span>.</span><span>id2label</span><span>[</span><span>predicted_idx</span><span>]</span><span>}</span><span> in </span><span>{</span><span>epoch</span><span>}</span><span> epochs&#39;</span><span>)</span>
</span></span><span><span>      <span>break</span>
</span></span><span><span>
</span></span><span><span>    <span>gradient_noise</span><span>.</span><span>grad</span> <span>=</span> <span>None</span>
</span></span><span><span>    <span>loss</span> <span>=</span> <span>F</span><span>.</span><span>cross_entropy</span><span>(</span><span>logits</span><span>,</span> <span>torch</span><span>.</span><span>tensor</span><span>([</span><span>target_idx</span><span>]))</span>
</span></span><span><span>    <span>loss</span><span>.</span><span>backward</span><span>()</span>
</span></span><span><span>    <span># update image with noise</span>
</span></span><span><span>    <span>new_noise</span> <span>=</span> <span>gradient_noise</span><span>.</span><span>grad</span> <span>*</span> <span>learning_rate</span>
</span></span><span><span>    <span>malicious_teapot</span> <span>-=</span> <span>new_noise</span>
</span></span><span><span>    <span># logging</span>
</span></span><span><span>    <span>if</span> <span>epoch</span> <span>%</span> <span>log_every</span> <span>==</span> <span>0</span><span>:</span>
</span></span><span><span>      <span>print</span><span>(</span><span>f</span><span>&#34;</span><span>{</span><span>epoch</span><span>:</span><span> 4</span><span>}</span><span> </span><span>{</span><span>loss</span><span>=}</span><span>&#34;</span><span>)</span>
</span></span><span><span>  <span>return</span> <span>malicious_teapot</span>
</span></span><span><span>
</span></span><span><span><span>malicious_teapot</span> <span>=</span> <span>morph</span><span>(</span><span>teapot</span><span>)</span>
</span></span></code></pre></div><figure><a href="https://github.com/rguiscard/malicious.png" title="malicious" data-thumbnail="malicious.png" data-sub-html="&lt;h2&gt;Malicious teapot&lt;/h2&gt;&lt;p&gt;malicious&lt;/p&gt;">
        <img src="https://github.com/svg/loading.min.svg" data-src="malicious.png" data-srcset="malicious.png, malicious.png 1.5x, malicious.png 2x" data-sizes="auto" alt="malicious.png"/>
    </a><figcaption>Malicious teapot</figcaption>
    </figure>
<p>Our magestic mimic:</p>
<figure><a href="https://github.com/rguiscard/malicious2.png" title="malicious2" data-thumbnail="malicious2.png" data-sub-html="&lt;h2&gt;Mimic teapot&lt;/h2&gt;&lt;p&gt;malicious2&lt;/p&gt;">
        <img src="https://github.com/svg/loading.min.svg" data-src="malicious2.png" data-srcset="malicious2.png, malicious2.png 1.5x, malicious2.png 2x" data-sizes="auto" alt="malicious2.png"/>
    </a><figcaption>Mimic teapot</figcaption>
    </figure>
<h2 id="dreaming-of-chihuahua">Dreaming of Chihuahua</h2>
<p>Now let’s crank it up to 11, how would the image change if we made the network overfit the picture on the chihuahua label.</p>
<figure><a href="https://github.com/rguiscard/dream.png" title="dream" data-thumbnail="dream.png" data-sub-html="&lt;h2&gt;Dreaming of Chihuahua&lt;/h2&gt;&lt;p&gt;dream&lt;/p&gt;">
        <img src="https://github.com/svg/loading.min.svg" data-src="dream.png" data-srcset="dream.png, dream.png 1.5x, dream.png 2x" data-sizes="auto" alt="dream.png"/>
    </a><figcaption>Dreaming of Chihuahua</figcaption>
    </figure>
<h2 id="the-code">The code</h2>
<p>You can get the code at <a href="https://github.com/peluche/mimic" target="_blank" rel="noopener noreffer ">https://github.com/peluche/mimic</a></p>


</div></div>
  </body>
</html>
