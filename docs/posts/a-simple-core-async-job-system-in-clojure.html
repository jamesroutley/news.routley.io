<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.janetacarr.com/creating-a-dead-simple-asynchronous-job-system-in-clojure/">Original</a>
    <h1>A simple core.async job system in Clojure</h1>
    
    <div id="readability-page-1" class="page"><div id="gh-main">
    <article>
        <header>
    <p><time datetime="2024-05-24">May 24, 2024</time>
    </p>

    

</header>

    <figure>
        <img srcset="/content/images/size/w300/2024/05/worker_system.png 300w,
                    /content/images/size/w720/2024/05/worker_system.png 720w,
                    /content/images/size/w960/2024/05/worker_system.png 960w,
                    /content/images/size/w1200/2024/05/worker_system.png 1200w,
                    /content/images/size/w2000/2024/05/worker_system.png 2000w" sizes="(max-width: 1200px) 100vw, 1200px" src="https://blog.janetacarr.com/content/images/size/w1200/2024/05/worker_system.png" alt="Dead simple core.async job system in Clojure"/>
    </figure>

<section>
    <p>In my off time (and my on time, for that matter) I&#39;ve been working on this quirky thing I&#39;ve called Scinamalink (sounds like &#39;skinamarink&#39;). Scinamalink lets customers send Magic login links to their users with a single REST API call. If you don&#39;t know what a magic login link is, it&#39;s basically a password reset email on steroids. Quite literally a link that just authenticates the user&#39;s session, skipping the usual password reset flow.  </p><p>My motivations for working on Scinamalink range from having something to show off my Clojure skills on Twitch, and to see if this is worthwhile for people since services like Auth0 and Clerk support magic login links. I&#39;m &#39;unbundling&#39; as the cool kids say. </p><p>An early problem I was concerned with was curtailing spam. I figure the best approach for this would be domain verification for the customer&#39;s domain. Makes sense. Time for an asynchronous job and some DNS queries. </p><h3 id="avoiding-a-rabbitmq-hole">Avoiding a RabbitMQ hole</h3><p>The first thing someone suggested was introducing some kind of message broker, like RabbitMQ, and going from there. I said <em>hell no</em>. I&#39;m trying to avoid complexity. Yet, I understand that building an async worker from scratch doesn&#39;t seem like the simplest approach. </p><p>My line of thinking is this: I think infrastructure is part of your Software Architecture. Every component in an architecture adds exponentially more complexity, whether it&#39;s a software component, or another process on the same network. By using something like RabbitMQ and writing the jobs for it, I&#39;m essentially adding two or three more components to the architecture: The RabbitMQ process, its deployment configuration, and the code to manage jobs from my main application server. </p><p>Such complexity may be worth it for some developers building a solution, but, as someone who wants to get to market faster, cutting the ops work looks like the better approach. The obvious trade-off being my single-process worker system may be less reliable than RabbitMQ. </p><h3 id="simple-yet-reliable-enough">Simple Yet Reliable Enough</h3><p>I have a single process with multiple threads, thanks to core.async. It&#39;s not lost on me that if the process fails, the jobs will be lost, so my approach to reliability starts at the data model and database. Let&#39;s take a look at the PostgreSQL data definition for a job: </p><pre><code>CREATE TYPE worker_job_state AS ENUM (&#39;created&#39;, &#39;starting&#39;, &#39;working&#39;, &#39;finished&#39;, &#39;crashed&#39;);

CREATE TABLE IF NOT EXISTS worker_jobs (
       id serial primary key,
       current_state worker_job_state not null default &#39;created&#39;,
       timeout timestamp default now() + interval &#39;24 hours&#39;,
       attempt_count integer not null default 0,
       priority integer not null default 1,
       context jsonb not null,
       created_at timestamp not null default now(),
       updated_at timestamp not null default now()
);</code></pre><p>I originally intended for timeouts and priorities to be a thing, but they&#39;re &#39;reserved for future use&#39; (waste of time). But, since each job could be different in implementation, it&#39;s necessary to store some of the context in a free-form JSON blob column. For example, when verifying domain ownership, it might be a good idea to store the customer and domain associated with the verification job. </p><p>However, we can see each job shares the same states describing the job&#39;s lifecycle: created, starting, working, finished, and crashed. I think each state is self-explanatory here, and these states imply each job function is a Finite-State-Machine (FSM).</p><h3 id="all-work-no-play">All work, no play</h3><p>So, I need to implement a Finite-State-Machine in Clojure. If you&#39;ve read any of my previous works, you know whats coming next: Functions returning functions. In short, we can implement a finite state machine by having a function represent each state. When a state needs to transition to another state, it returns that function, otherwise it returns itself. We can use the recurring lexical scope in a recursion to propel the state machine forward. It might be easier to start with the loop:</p><figure><pre><code>;; in scinamalink.core.worker namespace
(def buffer-limit (or (:job-buffer-limit env) 2048))
(defonce queue (a/chan (warning-dropping-buffer
                        buffer-limit
                        &#34;job queue full, job dropped&#34;)))

(defn worker
  &#34;Spins off a go-loop based worker and runs the job function
  pulled from channel `queue` in a core.async/thread. If that
  job returns a fn, puts it back on the `queue` for a worker
  to process. Otherwise, worker discards result and repeats.&#34;
  [queue]
  (a/go-loop [job (a/&lt;! queue)]
    (try
      (when-let [next-state (a/&lt;! (a/thread (job)))]
        (when (fn? next-state)
          (a/&gt;! queue next-state)))
      (catch Exception e
        (log/warn &#34;Possible job failure in worker: %s&#34; (.getMessage e))))
    (recur (a/&lt;! queue))))
</code></pre><figcaption><p><span>from core.workers namespace</span></p></figcaption></figure><p>This is a bit more complex than my past examples, but the same idea. We pull a job function off a core.async channel, <code>queue</code>, and execute it. The job function is executed in a core.async thread because jobs must perform blocking network operations. The result, the <code>next-state</code> function comes off the channel returned by thread. Instead of passing the <code>next-state</code> to the next recursive call, <code>next-state</code> returns back to the <code>queue</code>, provided it&#39;s a function, so it doesn&#39;t starve other job functions waiting in the <code>queue</code>. </p><p>Jobs-as-functions also makes for easy synchronous testing as I just wrote a regular (non-go) loop to test each job&#39;s FSM. Of course, the jobs themselves require a bit of forethought.</p><h3 id="they-took-our-jobs">They Took Our Jobs</h3><p>So what does a job function look like? They&#39;re pretty simple:</p><figure><pre><code>;; In scinamalink.jobs.domain-verification namespace
(defn finished
  [job]
  (try
    (swap! registry #(dissoc % (:id job)))
    (db-jobs/job-finished ds-opts (:id job))
    (log/debugf &#34;%s job %s finished&#34; (get-in job [:context :job-type]) (:id job))
    (catch Exception e
      (do (crashed job)
          (log/errorf &#34;Unexpected exception in domain verification finished function: %s&#34;
                      (.getMessage e))))))

(defn job-work
  [job]
  (try
    (let [{:keys [context]} job
          {:keys [customer-id domain-id]} context
          domain (db-domains/get-customer-domain-by-id ds-opts customer-id domain-id)
          {:keys [verification-code verified domain-name last-checked-at]} domain]
      (log/infof &#34;%s job %s checking domain %s&#34;
                 (get-in job [:context :job-type])
                 (:id job)
                 domain-name)
      (when-not domain
        (throw
         (ex-info (str &#34;Customer domain record missing for job &#34; (:id job)) context)))
      (if-not verified
        (do (db-domains/set-last-checked-at ds-opts customer-id domain-id (Instant/now))
            (if (= verification-code (dns/get-domain-text-record domain-name))
              (do (log/debugf &#34;setting domain to verified for job %s&#34; (:id job))
                  (db-domains/set-verified ds-opts customer-id domain-id true))
              (log/debugf &#34;no verification code found for job %s&#34; (:id job)))
            #(job-work job))
        #(finished job)))
    (catch Exception e
      (do (crashed job)
          (log/errorf &#34;error while completing job work: %s&#34; (.getMessage e))
          (db-jobs/job-failed ds-opts (:id job) (.getMessage e))))))

(defn do-job
  [job]
  (try
    (swap! registry #(assoc % (:id job) :working))
    (let [job (db-jobs/job-working ds-opts (:id job))]
      #(job-work job))
    (catch Exception e
      (do (crashed job)
          (log/errorf &#34;job failed: %s %s&#34; job (.getMessage e))
          (db-jobs/job-failed ds-opts (:id job) (.getMessage e))))))

(defn start-job
  [job]
  (try
    (swap! registry #(assoc % (:id job) :started))
    (let [job (db-jobs/job-started ds-opts (:id job))]
      (log/debugf &#34;Starting %s job %s&#34; (get-in job [:context :job-type]) (:id job))
      #(do-job job))
    (catch Exception e
      (do (crashed job)
          (log/errorf &#34;job failed in start-job function, job: %s message: %s&#34; job (.getMessage e))
          (db-jobs/job-failed ds-opts (:id job) (.getMessage e))))))

(defn -&gt;job
  [customer-id domain-id]
  (try
    (let [job-context {:job-type &#34;domain_verification&#34;
                       :customer-id customer-id
                       :domain-id domain-id}
          job (db-jobs/create-db-job ds-opts (db-jobs/next-week (Instant/now)) 0 1 job-context)]
      (log/info &#34;Domain verification job created&#34;)
      #(start-job job))
    (catch Exception e
      (log/warnf &#34;domain verification job failed: %s %s&#34; customer-id domain-id))))</code></pre><figcaption><p><span>from jobs.domain-verification namespace</span></p></figcaption></figure><p>The domain verification job gets created with <code>-&gt;job</code> which creates the job in the database and returns the first function to place on the queue with something like <code>(dispatch-work queue (-&gt;job customer-id domain-id))</code>. </p><p>Since the workers are so thin themselves, jobs are responsible for everything related to its function. Each state needs to clean up after itself if something goes wrong. They also update the database with its serialized context regardless of failure.</p><p>However, I&#39;m not bound by the rigidity of the job data model though. You&#39;ll notice that <code>job-work</code> does most of the work for this task, yet <code>do-job</code> sets the state to <code>:working</code> in the database. I did this because I didn&#39;t want to unnecessarily write the state <code>:working</code> to the database each time the job attempts to make the DNS query. The worker doesn&#39;t care as long as it gets a function. Although, when the process starts and loads the jobs from the database, it will start at <code>do-job</code> again.</p><h3 id="starting-restarting-and-unstarting-processes">Starting, Restarting, and Unstarting Processes</h3><p>At some point, jobs will need to be loaded from the database into the worker system whether it&#39;s from failures or restarts. This is a pretty simple process: Read from database, dispatch to the appropriate job constructor, and put the resulting jobs on the queue for the workers. </p><pre><code>(defmulti -&gt;job-fn
  &#34;Multimethod to dispatch on job creation function&#34;
  (fn [job]
    (let [{:keys [current-state context]} job]
      (vector (csk/-&gt;kebab-case-keyword (:job-type context))
              (keyword current-state)))))

;; Currently in core.worker, but should be in core.loader:
(defn- start-existing-helper!
  &#34;Recursively puts each `job` fn on the port `queue`,
  presumably to be processed by a worker (see above).&#34;
  [queue jobs]
  (let [job (first jobs)]
    (try
      (a/put! queue job (fn [all-good]
                          (if all-good
                            (start-existing-helper! queue (rest jobs))
                            (log/errorf &#34;didn&#39;t put job onto queue, exploding: %s&#34; job))))
      (catch Exception e
        (log/errorf &#34;didn&#39;t put job onto queue, exploding: %s&#34; job)))))

(defn start-existing-jobs!
  &#34;Starts existing jobs from the DB&#34;
  []
  (try
    (let [jobs (db-jobs/get-all-pending-jobs ds-opts buffer-limit)]
      (-&gt;&gt; jobs
           (mapv -&gt;job-fn)
           (start-existing-helper! queue)))
    (catch Exception e
      (log/errorf &#34;Unexpected error while starting existing jobs: %s&#34; (.getMessage e)))))</code></pre><p>In the actual job definition, we can extend <code>-&gt;job-fn</code> with a dispatch values that map to our database record&#39;s <code>context</code> column. </p><figure><pre><code>(defmethod worker/-&gt;job-fn [:domain-verification :created]
  [job]
  #(start-job job))

(defmethod worker/-&gt;job-fn [:domain-verification :starting]
  [job]
  #(do-job job))

(defmethod worker/-&gt;job-fn [:domain-verification :working]
  [job]
  #(job-work job))
</code></pre><figcaption><p><span>from jobs.domain-verification namespace</span></p></figcaption></figure><p>This <code>start-existing-jobs!</code> function gets called when the process starts, but we need a method to periodically load jobs while the process is running. Ideally, our job loader would be aware of each running job so that the same jobs aren&#39;t loaded over and over. </p><figure><pre><code>(defonce registry (atom {}))

;; 1hr = 3600000 ms
(defn loader
  &#34;Loads jobs from the Database into the job `w/queue`,
  skipping the currently running ones.&#34;
  [queue ms]
  (a/go-loop [to-chan (a/timeout ms)]
    (try
      (when-not (a/&lt;! to-chan)
        (a/&lt;!
         (a/thread
           (try
             (log/debugf &#34;Begin loading jobs from database&#34;)
             (log/debugf &#34;There are currently %s jobs in the registry&#34; (count (keys @registry)))
             (let [jobs (dbw/get-all-pending-jobs ds-opts w/buffer-limit)
                   running-jobs @registry
                   stored-jobs (-&gt;&gt; jobs
                                    (filterv #(not (contains? running-jobs (:id %))))
                                    (mapv w/-&gt;job-fn))]
               (doseq [job stored-jobs]
                 (w/dispatch-work queue job)))
             (catch Exception e
               (log/warn &#34;Loader exception while loading jobs from DB: %s&#34;
                         (.getMessage e)))))))
      (catch Exception e
        (log/warnf &#34;Possible job failure in worker: %s&#34; (.getMessage e))))
    (recur (a/timeout ms))))

(defn start-job-loaders!
  ([queue]
   (start-job-loaders! queue 1))
  ([queue n]
   (doseq [_ (range n)]
     (loader queue 600000))))</code></pre><figcaption><p><span>core.loader</span></p></figcaption></figure><p>Lucky for us, core.async violates the thread-local nature of Clojure Vars. Meaning, that I can have a Var pointing to an atom where information about all the running jobs is stored (Jobs take on responsibility of registering themselves). As we can see, a loader functions very similarly to a worker running the <code>start-existing-jobs!</code> functionality, filtering on what&#39;s in the <code>registry</code>  atom upon this iteration. After each iteration, the loaders will wait using a <code>core.async/timeout</code> for specified amount of time. </p><h3 id="big-picture">Big Picture</h3><p>Finally, the big picture of the sub-system emerges. </p><figure><img src="https://blog.janetacarr.com/content/images/2024/05/worker_system-1.png" alt="" loading="lazy" width="2000" height="1894" srcset="https://blog.janetacarr.com/content/images/size/w600/2024/05/worker_system-1.png 600w, https://blog.janetacarr.com/content/images/size/w1000/2024/05/worker_system-1.png 1000w, https://blog.janetacarr.com/content/images/size/w1600/2024/05/worker_system-1.png 1600w, https://blog.janetacarr.com/content/images/2024/05/worker_system-1.png 2000w" sizes="(min-width: 720px) 720px"/></figure><div><p><i><em> Follow me on the website formerly known as Twitter dot com and around the web </em></i><a href="https://x.com/janetacarr?ref=blog.janetacarr.com"><i><em>@janetacarr</em></i></a><i><em> , or not. ¯\_(ツ)_/¯</em></i></p></div>
</section>


    </article>
</div></div>
  </body>
</html>
