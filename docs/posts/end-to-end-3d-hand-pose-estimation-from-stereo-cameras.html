<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://arxiv.org/abs/2206.01384">Original</a>
    <h1>End-to-End 3D Hand Pose Estimation from Stereo Cameras</h1>
    
    <div id="readability-page-1" class="page"><div id="content-inner">
  <div id="abs">
    
    
    
      
    
  
    <p><a href="https://arxiv.org/pdf/2206.01384">Download PDF</a></p><blockquote>
      <span>Abstract:</span>  This work proposes an end-to-end approach to estimate full 3D hand pose from
stereo cameras. Most existing methods of estimating hand pose from stereo
cameras apply stereo matching to obtain depth map and use depth-based solution
to estimate hand pose. In contrast, we propose to bypass the stereo matching
and directly estimate the 3D hand pose from the stereo image pairs. The
proposed neural network architecture extends from any keypoint predictor to
estimate the sparse disparity of the hand joints. In order to effectively train
the model, we propose a large scale synthetic dataset that is composed of
stereo image pairs and ground truth 3D hand pose annotations. Experiments show
that the proposed approach outperforms the existing methods based on the stereo
depth.

    </blockquote>

    <!--CONTEXT-->
    
  </div>
</div><div>
      <h2>Submission history</h2><p> From: Jonathan Cefalu NÃ©e Rodriguez [<a href="https://arxiv.org/show-email/1ab9ef54/2206.01384">view email</a>]
      </p></div></div>
  </body>
</html>
