<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://anthonynsimon.com/blog/kubernetes-cluster-raspberry-pi/">Original</a>
    
    <div id="readability-page-1" class="page"><div><p><span>May 19, 2021</span> · <!-- -->16<!-- --> minute read</p></div><div><div><p>In this post I’ll be walking you step by step on how I built a bare-metal, 3-node Kubernetes cluster running on Raspberry Pis. I&#39;ll also share some tips and tricks I learned along the way, and towards the end I&#39;ll honor the classic &#34;I run my blog on Kubernetes&#34; meme by deploying a basic Ghost server.</p><p><a href="https://anthonynsimon.com/img/blog/kubernetes-cluster-raspberry-pi/cluster-overview.jpeg"><img src="https://anthonynsimon.com/img/blog/kubernetes-cluster-raspberry-pi/cluster-overview.jpeg" alt="Raspberry Pi Kubernetes Cluster" width="100%" height="auto" loading="lazy"/></a>
<em>The already assembled cluster.</em></p><p>While this is not meant to be a tutorial, feel free to use my article as reference if you’re building a cluster too. You can add more nodes if you&#39;d like. I chose three nodes simply because I’d run out of budget otherwise. After all, it&#39;s just my hobby project.</p><p>There&#39;s lots of guides on the internet on how to build similar clusters, with different parts and specs. It all comes down to your own preferences. For example, you can check out <a href="https://blog.alexellis.io/" rel="noopener">Alex Ellis&#39; Blog</a> for inspiration, he has lots of great material on the subject there.</p><h2><span id="hobbies-should-be-fun">Hobbies should be fun</span></h2><p>&#34;Why would you do this?&#34; - I’ve been meaning to build this cluster as a hobby project for some time now, for fun and learning. As a part-time solopreneur, I feel sometimes it’s too easy to get caught up in the mindset of only doing stuff that might lead to a clear payoff. It’s as if my brain has been wired to evaluate every action against some effort vs expected gain model.</p><p>When I started doing software development it was incredibly fun to just play around with new programming languages, building video games that never saw the light of the day, and generally just tinkering with stuff without any particular objective. It was fun, and I feel I learned a lot simply by building random projects with no concrete purpose other than out of curiosity.</p><p>That’s why, I wanted to re-incorporate some of that, essentially by doing “aimless exploration” of a topic that interests me, without a plan or concrete goal. I just want to see where it goes.</p><p>So without further ado, let’s get started with the article you’ve come to read.</p><h2><span id="the-showcase">The showcase</span></h2><p>This is the part which sounds like I&#39;m trying to convince you to build it too:</p><p><a href="https://anthonynsimon.com/img/blog/kubernetes-cluster-raspberry-pi/cluster-closeup.jpeg"><img src="https://anthonynsimon.com/img/blog/kubernetes-cluster-raspberry-pi/cluster-closeup.jpeg" alt="Cloudlet Case" width="100%" height="auto" loading="lazy"/></a>
<em>If you ask me, it’s very easy on the eyes. What do you think?</em></p><p><strong>It’s small, but mighty:</strong> 3x <a href="https://www.raspberrypi.org/products/raspberry-pi-4-model-b/" rel="noopener">Raspberry Pi 4B</a> (4 CPU, 8 GB RAM each), running Ubuntu Server 64-bit. That&#39;s 12 CPUs, 24 GB memory in total - plenty of room for running multiple projects.</p><p><strong>Energy, and cable efficient:</strong> All nodes are ARM64. I’m using <a href="https://en.wikipedia.org/wiki/Power_over_Ethernet" rel="noopener">Power-over-Ethernet (PoE)</a> to supply networking and energy over a single cable per cluster node.</p><p><strong>Simple:</strong> Uses <a href="https://k3s.io/" rel="noopener">K3s - a lightweight and ARM-optimized Kubernetes</a>. It was a breeze to install. I went from vanilla Ubuntu to <code>kubectl apply</code> in a couple of minutes.</p><p><strong>Self-contained:</strong> It’s portable and wirelessly connects to any network, so I can work on this cluster anywhere I go. The nodes live within their own private network. I simply plug one power cable, and the cluster is up and running.</p><h2><span id="how-much-does-the-raspberry-pi-cluster-cost">How much does the Raspberry Pi cluster cost</span></h2><p>For reference purposes, here&#39;s the list of parts needed, and approximate price. Admittedly, this is an expensive hobby. I&#39;m very lucky that my employer gives everyone a personal development budget, and they were happy to support this project.</p><p>The reference prices below do not include shipping/import tax costs, since that depends on where you&#39;re located.</p><div><table><thead><tr><th>Item</th><th>Unit price in USD</th></tr></thead><tbody><tr><td>3x Raspberry Pi 4B 8GB</td><td>$87.04</td></tr><tr><td>3x Mini PoE expansion board (fanless)</td><td>$23.10</td></tr><tr><td>3x SanDisk Micro SD card 32 GB</td><td>$10.87</td></tr><tr><td>5x 0.5m CAT6 Ethernet cables</td><td>$3.65</td></tr><tr><td>1x Cloudlet cluster case (incl. fans)</td><td>$75.21</td></tr><tr><td>1x TP-Link 5-Port Gigabit PoE Switch</td><td>$45.18</td></tr><tr><td>1x TP-Link Nano Router WLAN</td><td>$39.68</td></tr><tr><td>1x Micro SD card reader with USB-C connector</td><td>$15.87</td></tr><tr><td>1x Pack of cable straps</td><td>$9.15</td></tr><tr><td><strong>Total</strong></td><td><strong>$566.37</strong></td></tr></tbody></table></div><p>If you want to lower the cost, consider purchasing the 4 GB models, a more basic case, and don&#39;t go for a PoE capable network switch. Just don&#39;t forget to find an alternative way to power the Raspberry Pis if you opt for a non-PoE solution.</p><p>Next let&#39;s talk about networking. My cluster lives on its own private network, which brings a few advantages vs joining everything over my home WiFi.</p><h2><span id="network-topology">Network topology</span></h2><p>As cliché as it may sound, I do believe a picture is worth a thousand words. That&#39;s why I made the following diagram, illustrating the network topology for my cluster and home network:</p><p><a href="https://anthonynsimon.com/img/blog/kubernetes-cluster-raspberry-pi/cluster-network-topology.png"><img src="https://anthonynsimon.com/img/blog/kubernetes-cluster-raspberry-pi/cluster-network-topology.png" alt="Cluster network diagram" width="100%" height="auto" loading="lazy"/></a></p><p>Essentially, the nodes and the router talk to each other via the network switch on a wired connection, while the router serves as a gateway to the Internet via WiFi.</p><p>Having the cluster on a private network means that I have full control over the IP addresses of each node, even if I join different networks on the go. This makes the cluster portable, and easy to access without having to reconfigure routers, or my development environment.</p><p>Each node gets a static IP address assigned to them (instead of using the router&#39;s DHCP), which makes cluster node discovery much easier since each host is available at a predictable address. The router also serves as an Internet Gateway (connects the local network to the Internet).</p><p>Using a network switch with Power-over-Ethernet means I can just plug it to power, and the whole cluster is up and running. Each node gets networking and power from a single cable. Keeps things tidy, and simple.</p><h2><span id="assembling-the-raspberry-pis-cluster">Assembling the Raspberry Pi’s cluster</span></h2><p>To assemble the cluster, I started by preparing the cluster case and fans. Essentially it consisted of screwing the fans to the back of the case, and deciding which slots to use for each Raspberry Pi so that it could also fit the router and switch inside the box.</p><p><a href="https://anthonynsimon.com/img/blog/kubernetes-cluster-raspberry-pi/cluster-assembly-fans.jpeg"><img src="https://anthonynsimon.com/img/blog/kubernetes-cluster-raspberry-pi/cluster-assembly-fans.jpeg" alt="Assembling Raspberry Pi cluster" width="100%" height="auto" loading="lazy"/></a>
<em>You know you&#39;re in for a fun night when your desk looks like this.</em></p><p>I prepared each Raspberry Pi by attaching the PoE hat and the bundled heatsink to the board. I then inserted the micro SD card with the flashed OS image (more on that later).</p><p>Once ready, I simply attached each Raspberry Pi to the slot plate, which is what will hold them to the cluster case.</p><p><a href="https://anthonynsimon.com/img/blog/kubernetes-cluster-raspberry-pi/raspberry-pi-poe-hat.jpeg"><img src="https://anthonynsimon.com/img/blog/kubernetes-cluster-raspberry-pi/raspberry-pi-poe-hat.jpeg" alt="Raspberry Pi with PoE hat" width="100%" height="auto" loading="lazy"/></a>
<em>The Raspberry Pi 4 with the PoE hat already fitted in, and attached to the cluster slot plate.</em></p><p>I then plugged each Raspberry Pi to a fan (the fan is powered by the board&#39;s GPIO), and inserted them into the cluster case slot.</p><p><a href="https://anthonynsimon.com/img/blog/kubernetes-cluster-raspberry-pi/cluster-assembly-slots.jpeg"><img src="https://anthonynsimon.com/img/blog/kubernetes-cluster-raspberry-pi/cluster-assembly-slots.jpeg" alt="Attaching each Raspberry Pi to a cluster case slot" width="100%" height="auto" loading="lazy"/></a>
<em>The first of three Raspberry Pi and fan slots.</em></p><p>Once that was done, I connected each Raspberry Pi to the network switch via an Ethernet cable. Finally, I also connected the router to the switch, and give it power by using one of the USB-C ports on the Raspberry Pi. That means in one way or another, everything is powered by the switch.</p><p>Now all I have to do is to plug the switch to the power outlet, and done! The cluster is alive.</p><p><a href="https://anthonynsimon.com/img/blog/kubernetes-cluster-raspberry-pi/cluster-with-router-and-switch.jpeg"><img src="https://anthonynsimon.com/img/blog/kubernetes-cluster-raspberry-pi/cluster-with-router-and-switch.jpeg" alt="Cluster with router and PoE network switch" width="100%" height="auto" loading="lazy"/></a>
<em>I was too excited to turn the cluster on for the first time, so I made a mess with the cables.</em></p><h2><span id="flashing-the-os-image">Flashing the OS image</span></h2><p>Next up, I flash an OS image into each of the Micro SD cards. For this I use <a href="https://www.raspberrypi.org/software/operating-systems/" rel="noopener">Raspberry Pi Imager</a>. I also heard good things about <a href="https://www.balena.io/etcher/" rel="noopener">Etcher</a>, so feel free to try that one too.</p><p>I’m using Ubuntu Server 64-bit. Since each node has 8GB of memory available, I need a 64-bit OS to take advantage of all that space. I use Ubuntu since it’s well supported, and I’m quite familiar with it already. You can use the OS of your choice.</p><p><a href="https://anthonynsimon.com/img/blog/kubernetes-cluster-raspberry-pi/flashing-os.jpeg"><img src="https://anthonynsimon.com/img/blog/kubernetes-cluster-raspberry-pi/flashing-os.jpeg" alt="Raspberry Pi Imager to flash OS" width="100%" height="auto" loading="lazy"/></a>
<em>Using Raspberry Pi Imager to flash Ubuntu Server onto the microSD card.</em></p><p>There&#39;s a few things I want to pre-configure on each node once it boots. For that I used the <code>user-data</code> file, which follows the <a href="https://cloudinit.readthedocs.io/en/latest/" rel="noopener">cloud-init</a> spec. With this file, I can configure each node to:</p><ul><li>Enable SSH access.</li><li>Pre-authorize my SSH key.</li><li>Disable password access.</li><li>Setup a non-root user.</li><li>Define the hostname for each node.</li></ul><p>I want to set the hostname for each node so that I can easily identify it once it joins the network. It will come in handy later when the nodes need to talk to each other to form a cluster.</p><p>Here&#39;s what the <code>user-data</code> file looks like (notice there&#39;s a few variables that should be replaced):</p><div><pre><code><span># See cloud-init documentation for available options:</span><span>
</span><span></span><span># https://cloudinit.readthedocs.io/</span><span>
</span>
<span></span><span>ssh_pwauth</span><span>:</span><span> </span><span>false</span><span>
</span>
<span></span><span>groups</span><span>:</span><span>
</span><span>  </span><span>-</span><span> </span><span>ubuntu</span><span>:</span><span> </span><span>[</span><span>root</span><span>,</span><span> sys</span><span>]</span><span>
</span>
<span></span><span>users</span><span>:</span><span>
</span><span>  </span><span>-</span><span> default
</span><span>  </span><span>-</span><span> </span><span>name</span><span>:</span><span> junglet
</span><span>    </span><span>gecos</span><span>:</span><span> junglet
</span><span>    </span><span>sudo</span><span>:</span><span> ALL=(ALL) NOPASSWD</span><span>:</span><span>ALL
</span><span>    </span><span>groups</span><span>:</span><span> sudo
</span><span>    </span><span>ssh_import_id</span><span>:</span><span> None
</span><span>    </span><span>lock_passwd</span><span>:</span><span> </span><span>true</span><span>
</span><span>    </span><span>shell</span><span>:</span><span> /bin/bash
</span><span>    </span><span>ssh_authorized_keys</span><span>:</span><span>
</span><span>      </span><span>-</span><span> &lt;ssh</span><span>-</span><span>pub</span><span>-</span><span>key</span><span>&gt;</span><span>
</span>
<span></span><span>hostname</span><span>:</span><span> junglet</span><span>-</span><span>&lt;num</span><span>&gt;</span></code></pre></div><p>The name <code>junglet</code> is just the pet name I use for the cluster. Every node will have the hostname in the form: <code>junglet-&lt;node-number&gt;</code>. You&#39;re free to pick something else.</p><h2><span id="setting-up-the-router">Setting up the router</span></h2><p>Some of you might be wondering why I would need a router if I already have a switch to connect the nodes.</p><p>The router plays an important role: it assigns IP addresses to each device on the network (dynamically via DHCP, or manually using static IPs), and it also becomes the Internet gateway for the private network. Without it, the nodes wouldn’t be able to reach the Internet.</p><p>If you don&#39;t want to buy a router, you could <a href="https://www.raspberrypi.org/documentation/configuration/wireless/access-point-routed.md" rel="noopener">turn one of the Raspberry Pis into a router</a>, and use that as your Internet gateway. I didn&#39;t try it, so your best bet is to search for <a href="https://www.zahradnik.io/raspberry-pi-as-a-home-router" rel="noopener">guides on how to do that</a>. I&#39;ll focus on using a router here.</p><p>Within my private network, Internet connectivity comes by having the router, join my home network via WiFi, and use that as a default route. I could connect to the Internet via an Ethernet cable too, but I want the flexibility to have the cluster sitting next to me, in whichever room I might be in my home, and even take it with me on the go. So WiFi for Internet access it is.</p><p>With that said, let&#39;s configure the network on the router. First things first: I set a stronger password than <code>admin</code> on the router admin panel. While I don&#39;t expect anyone snooping around there, and I&#39;m not a security expert, I heard <a href="https://www.useapassphrase.com/" rel="noopener">passphrases</a> are generally a good idea.</p><p>I then set the network range that the router should use to allocate addresses. I picked <code>10.42.42.0/24</code>, which gives me 254 IPv4 addresses to work with (256 available addresses minus the broadcast address, and network address). I only have 3 nodes plus my dev laptop, so that&#39;s more than enough.</p><div><pre><code><span>[Dev laptop]                   Internet
</span>|                              ^
<!-- -->|                              |
<!-- -->|                              |
<!-- -->|                              |
<!-- -->+------&gt; [Home router] --------+
<!-- -->         192.0.0.0/24
<!-- -->              ^
<!-- -->              |
<!-- -->              |
<!-- -->              v
<!-- -->       [Cluster router]
<!-- -->        10.42.42.0/24
<!-- -->         ^     ^     ^
<!-- -->         |     |     |
<!-- -->         |     |     |
<!-- -->    +----+     |     +----+
<!-- -->    |          |          |
<!-- -->    |          |          |
<!-- -->    V          V          V
<!-- -->[Node 1]    [Node 2]   [Node 3]
</code></pre></div><p>I then reserve a static IP for each node, this makes the address for each node predictable, which makes SSH-ing to the nodes simpler. Reserving static IPs for each node means that they’ll always have the same IP address, even after restarts and as more devices join the network.</p><div><pre><code><span># &#34;junglet&#34; is just a pet hostname
</span>
<!-- -->junglet-1   10.42.42.100
<!-- -->junglet-2   10.42.42.101
<!-- -->junglet-3   10.42.42.102
</code></pre></div><p>Now that all nodes can talk to each other, and I can reach them at a predictable address, I just need to add a route for my private network to reach the Internet. That way it can perform OS updates, download Docker images, and whatnot.</p><p>To be able to reach the Internet from the cluster, I join the private network to my home network via WiFi. It comes down to using the admin interface of my router to connect to an external network, and using that as the default gateway for the cluster network.</p><p>Finally, let’s connect to each cluster node to ensure everything is working as expected. I added the following SSH config to my dev machine to make it easier to login to the nodes in the future:</p><div><pre><code><span># On my development laptop
</span># ~/.ssh/config
<!-- -->
<!-- -->Host junglet-1
<!-- -->  HostName 10.42.42.100
<!-- -->  User junglet
<!-- -->  IdentityFile ~/.ssh/junglet
<!-- -->
<!-- -->Host junglet-2
<!-- -->  HostName 10.42.42.101
<!-- -->  User junglet
<!-- -->  IdentityFile ~/.ssh/junglet
<!-- -->
<!-- -->Host junglet-3
<!-- -->  HostName 10.42.42.102
<!-- -->  User junglet
<!-- -->  IdentityFile ~/.ssh/junglet
</code></pre></div><p>I can now SSH into any of my Raspberry Pis using the following command:</p><div><pre><code><span>$ </span><span>ssh</span><span> junglet-</span><span>&lt;</span><span>node-number</span><span>&gt;</span><span>  </span><span># eg. junglet-1</span></code></pre></div><p>For example, I can check if junglet-1 can talk to junglet-2:</p><div><pre><code><span># Check if port 22 (SSH) is open on another cluster node</span><span>
</span><span>$ </span><span>nc</span><span> -zv </span><span>10.42</span><span>.42.101 </span><span>22</span><span>
</span>
<span>Connection to </span><span>10.42</span><span>.42.101 </span><span>22</span><span> port </span><span>[</span><span>tcp/ssh</span><span>]</span><span> succeeded</span><span>!</span></code></pre></div><p>Finally, we’re at the stage in which we can do anything we want with the nodes, they can talk to each other and to the internet too.</p><h2><span id="what-is-k3s-and-how-is-it-different-than-kubernetes">What is K3s and how is it different than Kubernetes</span></h2><p>While Kubernetes is not exactly simple to setup, I do find it simple to use once you’re familiar with it. That said, unless you’re using a managed offering it’s too easy to shoot yourself on the foot by misconfiguring the cluster, one of its dependencies, or worse mess up an upgrade.</p><p>Lucky for us, there’s K3s, a <a href="https://k3s.io/" rel="noopener">lightweight Kubernetes distribution</a>, optimized for ARM and packaged as a single 40MB binary. It also features a simplified install and update process, which is very welcome.</p><p>What’s really great about K3s is that <em>it is Kubernetes</em> - the real thing. I can reuse most of the tooling and knowledge that I’ve acquired over the years about running Kubernetes on AWS/GCP/DigitalOcean and Linode, but on my tiny Raspberry Pi cluster. Few &#34;cloud&#34; technologies really give you that kind of flexibility, and knowledge transfer.</p><p>Let’s set up K3s on each node. First, we need to do a couple of things:</p><ul><li>Update system packages.</li><li>Install docker.</li><li>Enable OS container features.</li><li>Reboot.</li></ul><p>Here&#39;s how I did that:</p><div><pre><code><span># Update packages</span><span>
</span><span>$ </span><span>sudo</span><span> </span><span>apt</span><span> upgrade -y
</span>
<span></span><span># Install docker</span><span>
</span><span>$ </span><span>sudo</span><span> </span><span>apt</span><span> </span><span>install</span><span> -y docker.io
</span>
<span></span><span># Check for OS container features enabled</span><span>
</span><span>$ </span><span>sudo</span><span> docker info
</span>
<span></span><span># You should see something like this</span><span>
</span><span></span><span>#</span><span>
</span><span></span><span># WARNING: No memory limit support</span><span>
</span><span></span><span># WARNING: No swap limit support</span><span>
</span><span></span><span># WARNING: No kernel memory limit support</span><span>
</span><span></span><span># WARNING: No kernel memory TCP limit support</span><span>
</span><span></span><span># WARNING: No oom kill disable support</span><span>
</span>
<span></span><span># Enable the required container features</span><span>
</span><span>$ </span><span>sudo</span><span> </span><span>sed</span><span> -i </span><span>\</span><span>
</span><span></span><span>&#39;$ s/$/ cgroup_enable=cpuset cgroup_enable=memory cgroup_memory=1 swapaccount=1/&#39;</span><span> </span><span>\</span><span>
</span>/boot/firmware/cmdline.txt
<!-- -->
<span></span><span># We need to reboot for the kernel flags to take effect.</span><span>
</span><span>$ </span><span>sudo</span><span> </span><span>reboot</span></code></pre></div><p>I enabled container features on the OS kernel, which we’ll be needing for Kubernetes. Updating this requires a system reboot, that&#39;s why the last command to restart the node is needed.</p><h2><span id="installing-k3s-on-the-raspberry-pi">Installing K3s on the Raspberry Pi</span></h2><p>I need to designate one or more of the cluster nodes as the &#34;server&#34;, a node which manages the cluster resources, while the other nodes behave as workers.</p><p>Luckily, K3s makes the whole setup a one-liner. I simply run the following command to setup the Kubernetes server node:</p><div><pre><code><span>$ </span><span>curl</span><span> -sfL https://get.k3s.io </span><span>|</span><span> </span><span>sh</span><span> -</span></code></pre></div><p>Once the server node is ready, I can grab the token so that the worker nodes can join the cluster securely:</p><div><pre><code><span># Copy the cluster token from the server node</span><span>
</span><span>$ </span><span>sudo</span><span> </span><span>cat</span><span> /var/lib/rancher/k3s/server/node-token</span></code></pre></div><p>Next, on each of the worker nodes I run the following command to setup K3s, and have them join the existing cluster (notice the two variables that should be replaced):</p><div><pre><code><span># Don&#39;t forget to replace $YOUR_SERVER_NODE_IP and $YOUR_CLUSTER_TOKEN</span><span>
</span><span>$ </span><span>curl</span><span> -sfL https://get.k3s.io </span><span>|</span><span> </span><span>K3S_URL</span><span>=</span><span>https://</span><span>$YOUR_SERVER_NODE_IP</span><span>:6443 </span><span>K3S_TOKEN</span><span>=</span><span>$YOUR_CLUSTER_TOKEN</span><span> </span><span>sh</span><span> -</span></code></pre></div><p>Let&#39;s check if I&#39;m able to talk to the cluster from any of the nodes:</p><div><pre><code><span># Within a cluster node</span><span>
</span>
<!-- -->$ kubectl get nodes
<!-- -->
<!-- -->NAME          STATUS   ROLES                  AGE   VERSION
<!-- -->junglet-1     Ready    control-plane,master   54s   v1.20
<span>junglet-2     Ready    </span><span>&lt;</span><span>none</span><span>&gt;</span><span>                 54s   v1.20
</span><span>junglet-3     Ready    </span><span>&lt;</span><span>none</span><span>&gt;</span><span>                 54s   v1.20</span></code></pre></div><p>Great, now we have a fully functioning kubernetes cluster, and I can talk to it via <code>kubectl</code> on one of the cluster nodes.</p><p>Right now I can SSH into one of the nodes and run <code>kubectl</code> commands to control the cluster. While that&#39;s perfectly fine, it would be better if I could manage the cluster from my development laptop. Let&#39;s set that up next.</p><h2><span id="accessing-k3s-from-my-dev-laptop">Accessing K3s from my dev laptop</span></h2><p>Let’s set up dev access on my laptop by adding the cluster credentials to my local <code>kubeconfig</code>. I already have <code>kubectl</code> installed on my laptop, but you can do so easily via brew on MacOS:</p><div><pre><code><span># Install Kubernetes tooling via brew</span><span>
</span><span>$ brew </span><span>install</span><span> kubernetes-cli
</span>
<span></span><span># Let&#39;s check it has been installed correctly</span><span>
</span>$ kubectl version
</code></pre></div><p>I then simply grab the <code>kubeconfig</code> file <a href="https://rancher.com/docs/k3s/latest/en/cluster-access/" rel="noopener">generated by K3s</a>. It&#39;s usually available at the path <code>/etc/rancher/k3s/k3s.yaml</code> on the server node:</p><div><pre><code><span>$ </span><span>cat</span><span> /etc/rancher/k3s/k3s.yaml</span></code></pre></div><p>In my case, I need to merge it with the one on my development laptop because I also manage other Kubernetes clusters, and I already configured access for them.</p><p>If this is your only cluster, you can simply replace the <code>~/.kube/config</code> file on your computer with the one generated by K3s.</p><h2><span id="first-deploy-kubernetes-dashboard">First deploy: Kubernetes dashboard</span></h2><p>Let&#39;s try out the cluster by <a href="https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/" rel="noopener">installing the Kubernetes admin dashboard</a>. You can follow the official instructions, but for illustration purposes I&#39;m including a basic install below:</p><div><pre><code><span># Create a namespace and and switch to it</span><span>
</span>$ kubectl create namespace kubernetes-dashboard
<!-- -->$ kubens kubernetes-dashboard
<!-- -->
<span></span><span># Deploy from the official source</span><span>
</span>$ kubectl apply -f https://raw.githubusercontent.com/kubernetes/dashboard/v2.2.0/aio/deploy/recommended.yaml
</code></pre></div><p>Now let&#39;s start a Kubernetes proxy to access the dashboards locally:</p><p>I&#39;m now able to access the dashboard at:</p><div><pre><code><span>http://localhost:8001/api/v1/namespaces/kubernetes-dashboard/services/https:kubernetes-dashboard:/proxy/#/overview?namespace=_all</span></code></pre></div><p><a href="https://anthonynsimon.com/img/blog/kubernetes-cluster-raspberry-pi/kubernetes-dashboard.png"><img src="https://anthonynsimon.com/img/blog/kubernetes-cluster-raspberry-pi/kubernetes-dashboard.png" alt="Kubernetes Dashboard" width="100%" height="auto" loading="lazy"/></a>
<em>Node stats on the Kubernetes dashboard.</em></p><p><strong>Important:</strong> Since the dashboard can control the cluster, you may need to <a href="https://github.com/kubernetes/dashboard/blob/master/docs/user/access-control/creating-sample-user.md" rel="noopener">create a Service Account</a> to obtain an access token and login to your dashboard. This seems like a good default, since we don&#39;t want anyone to be able to control the cluster just like that.</p><h2><span id="deploying-a-ghost-blog-on-kubernetes">Deploying a Ghost blog on Kubernetes</span></h2><p>Next, let&#39;s deploy a Ghost blog instance on the cluster. No Kubernetes article is complete without a reference to the &#34;Deployed my blog on Kubernetes&#34; meme:</p><p><a href="https://anthonynsimon.com/img/blog/kubernetes-cluster-raspberry-pi/blog-on-kubernetes-meme.png"><img src="https://anthonynsimon.com/img/blog/kubernetes-cluster-raspberry-pi/blog-on-kubernetes-meme.png" alt="Blog on Kubernetes meme" width="100%" height="auto" loading="lazy"/></a>
<em><a href="https://twitter.com/dexhorthy/status/856639005462417409" rel="noopener">Twitter source</a></em></p><p>Since this is for demonstration purposes, I&#39;m deploying a very basic example, <strong>without backups</strong> or persistent volumes. Deploy to production responsibly.</p><div><pre><code><span># Create namespace and switch to it</span><span>
</span>$ kubectl create ns my-blog
<!-- -->$ kubens my-blog
<!-- -->
<span></span><span># A basic deployment</span><span>
</span><span>$ </span><span>cat</span><span> </span><span>&lt;&lt;</span><span>EOF</span><span> </span><span>|</span><span> kubectl apply -f -</span><span>
</span><span>apiVersion: apps/v1
</span><span>kind: Deployment
</span><span>metadata:
</span><span>name: my-blog
</span><span>namespace: my-blog
</span><span>labels:
</span><span>app: my-blog
</span><span>spec:
</span><span>replicas: 1
</span><span>selector:
</span><span>matchLabels:
</span><span>  app: my-blog
</span><span>template:
</span><span>metadata:
</span><span>  labels:
</span><span>    app: my-blog
</span><span>spec:
</span><span>  containers:
</span><span>  - name: ghost
</span><span>    image: ghost:latest
</span><span>    ports:
</span><span>    - containerPort: 2368
</span><span>EOF
</span></code></pre></div><p>We can see the container is being created, and assigned to one of the cluster nodes:</p><div><pre><code><span>$ kubectl get pods
</span>
<!-- -->NAME                       READY   STATUS              RESTARTS   AGE
<span>my-blog-95D54d759c-B2pTt   </span><span>0</span><span>/1     ContainerCreating   </span><span>0</span><span>          3s
</span>
<!-- -->$ kubectl describe pod my-blog-95D54d759c-B2pTt
<!-- -->
<span></span><span>..</span><span>.
</span>Events:
<!-- -->Type    Reason     Age   From               Message
<!-- -->----    ------     ----  ----               -------
<!-- -->Normal  Scheduled  71s   default-scheduler  Successfully assigned my-blog/my-blog-95D54d759c-B2pTt to junglet-3
<span>Normal  Pulling    72s   kubelet            Pulling image </span><span>&#34;ghost:latest&#34;</span></code></pre></div><p>Great! Once the status switches to <code>Running</code>, let&#39;s use port-forwarding to access the blog:</p><div><pre><code><span>$ kubectl port-forward my-blog-95D54d759c-B2pTt </span><span>2368</span><span>:2368</span></code></pre></div><p>If you go to <code>localhost:2368/ghost</code>, you should be greeted by the Ghost admin welcome screen - ready for initial setup.</p><p><a href="https://anthonynsimon.com/img/blog/kubernetes-cluster-raspberry-pi/ghost-welcome-screen.png"><img src="https://anthonynsimon.com/img/blog/kubernetes-cluster-raspberry-pi/ghost-welcome-screen.png" alt="Ghost admin screen" width="100%" height="auto" loading="lazy"/></a></p><p>If you&#39;re planning on using this for your blog, you&#39;ll probably need to setup a <a href="https://kubernetes.io/docs/concepts/services-networking/service/" rel="noopener">Service</a> and <a href="https://kubernetes.io/docs/concepts/services-networking/ingress/" rel="noopener">Ingress</a> so that people can access the deployment from outside your network.</p><p>Don&#39;t forget to set up some form of backups or persistent volumes, since in my example it&#39;s just using ephemeral storage, and it will get wiped if the container restarts. There&#39;s numerous guides on <a href="https://rm3l.org/leveraging-kubernetes-cronjobs-for-automated-backups-of-a-headless-ghost-blog-to-aws-s3/" rel="noopener">how to backup to S3</a>, to a cluster volume, or equivalent. But that&#39;s outside of the scope of this post.</p><h2><span id="next-steps">Next steps</span></h2><p>The cluster is ready and we could do anything we want with it.</p><p>If you want to expose a cluster service over the Internet, you&#39;d need to get a static IP from your ISP, and set up port forwarding on the router. After all, this is a bare-metal cluster - we don&#39;t get those things for free. These steps would be the same whether you run Kubernetes or not.</p><p>There&#39;s alternative solutions like <a href="https://github.com/inlets/inlets" rel="noopener">inlets</a>, which enable you to expose private services to the Internet without going through the router / home IP.</p><p>Here&#39;s a few more ideas for what to play with next:</p><ul><li>Self-hosted CI/CD.</li><li>Functions-as-a-Service (eg. <a href="https://www.openfaas.com/" rel="noopener">OpenFaaS</a>).</li><li>Add network attached storage (we don&#39;t want to fry those Micro SD cards).</li><li>Experiment with container support on ARM platforms.</li><li>Use the cluster as a dev environment.</li></ul><h2><span id="bonus-using-nginx-instead-of-traefik-as-ingress">Bonus: Using NGINX instead of traefik as ingress</span></h2><p>K3s comes by default with <a href="https://traefik.io/" rel="noopener">traefik</a> as the ingress controller. I heard great things about it, but I prefer to use <a href="https://kubernetes.github.io/ingress-nginx/" rel="noopener">ingress-nginx</a>. This is simply because I&#39;m more familiar with it. You can choose pretty much any ingress controller you want for Kubernetes, so pick one according to your own preferences.</p><p>In my case, to use NGINX with K3s, all I had to do was to setup the server node with traefik disabled by using the following flags:</p><div><pre><code><span># Setup server node with flag to disable trafik, we&#39;ll install nginx afterwards.</span><span>
</span><span>$ </span><span>curl</span><span> -sfL https://get.k3s.io </span><span>|</span><span> </span><span>INSTALL_K3S_EXEC</span><span>=</span><span>&#34;server --no-deploy traefik&#34;</span><span> </span><span>sh</span></code></pre></div><p>I installed nginx-ingress using <a href="https://helm.sh/" rel="noopener">helm</a>, which came down to the following commands:</p><div><pre><code><span>$ kubectl create ns ingress-nginx
</span>$ kubens ingress-nginx
<!-- -->
<!-- -->$ helm repo add ingress-nginx https://kubernetes.github.io/ingress-nginx
<!-- -->$ helm repo update
<!-- -->$ helm install ingress-nginx ingress-nginx/ingress-nginx
</code></pre></div><p>There&#39;s many deployment options depending on your preferences. Just head over to the <a href="https://kubernetes.github.io/ingress-nginx/deploy/" rel="noopener">official documentation</a> and decide what works best for you.</p><p>Again, you don&#39;t need to do this, as it comes down to personal preference. It&#39;s just here for reference purposes if you&#39;re also interested in swapping the ingress controller.</p><h2><span id="bonus-building-crossplatform-docker-images">Bonus: Building cross-platform Docker images</span></h2><p>Since the nodes on this cluster are Raspberry Pi using ARM64 architecture, and most development machines are using AMD64 (x86_64), you might have some trouble building Docker images for your cluster.</p><p>You can always check the node architecture and allocatable resources via the following command:</p><p>If you&#39;re building ARM64 images on x86_64, lucky for us Docker supports <a href="https://docs.docker.com/desktop/multi-arch/" rel="noopener">building for multiple CPU architectures</a>. That means you can build and publish the same image for multiple target architectures.</p><p>Here&#39;s an example of how you can build a cross-platform Docker image:</p><div><pre><code><span>$ docker buildx build --platform linux/amd64,linux/arm64 </span><span>.</span></code></pre></div><p>Once you publish that image to your Docker registry, if you try to pull it on a cluster node, it will use the image for the target architecture. In the cluster&#39;s case that would be <code>linux/arm64</code>.</p><h2><span id="bonus-basic-nodepod-monitoring">Bonus: Basic node/pod monitoring</span></h2><p>You can install <a href="https://grafana.com/oss/grafana/" rel="noopener">Grafana</a> and <a href="https://prometheus.io/" rel="noopener">Prometheus</a> to monitor your cluster resources. But here&#39;s a quick tip if all you want is to look at the CPU/Memory utilization:</p><div><pre><code><span>$ kubectl </span><span>top</span><span> </span><span>&lt;</span><span>pods</span><span>|</span><span>nodes</span><span>&gt;</span><span>
</span>
<span>NAME          CPU</span><span>(</span><span>cores</span><span>)</span><span>    CPU%     MEMORY</span><span>(</span><span>bytes</span><span>)</span><span>   MEMORY%
</span><span>junglet-1     291m          </span><span>7</span><span>%       776Mi           </span><span>9</span><span>%
</span><span>junglet-2     177m          </span><span>4</span><span>%       420Mi           </span><span>5</span><span>%
</span><span>junglet-3     88m           </span><span>2</span><span>%       303Mi           </span><span>3</span><span>%</span></code></pre></div><p>While it&#39;s no time series or fancy chart, it does come handy when all you want is a simple way to check basic metrics. It leverages the built-in metrics server and API, so no need to install anything else.</p></div></div></div>
  </body>
</html>
