<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://martijnhols.nl/blog/how-much-traffic-can-a-pre-rendered-nextjs-site-handle">Original</a>
    <h1>How much traffic can a pre-rendered Next.js site handle?</h1>
    
    <div id="readability-page-1" class="page"><div><p>I&#39;ve often said things like &#34;<em>A pre-rendered site can easily serve hundreds of concurrent users</em>&#34;, because, well, I&#39;ve never seen one fail.</p>
<p>But how many can it <em>really</em> handle? Could my site actually handle a traffic surge from landing on something like the <span role="button" tabindex="0" aria-expanded="false">Hacker News frontpage</span>? How does it compare to server-side rendering? And is it actually worth jumping through hoops to avoid SSR?</p>
<p>I looked around for hard data on Next.js performance, but solid numbers were surprisingly hard to find. So, I ran some tests on my own site, and the results weren&#39;t what I expected. And in perfect timing, my article on <a href="https://martijnhols.nl/blog/everything-about-google-translate-crashing-react#not-just-react">Google Translate interfering with React</a> <a href="https://news.ycombinator.com/item?id=43023338">hit</a> the Hacker News frontpage the very next day.</p>
<p>Right after I discovered (spoiler alert) my site probably <em>couldn&#39;t</em> handle it.</p>
<h2 id="a-pre-rendered-site-on-a-vps">A pre-rendered site on a VPS</h2>
<p>The first thing I wanted to find out was whether my site could handle a surge in visitors from something like hitting the frontpage of Hacker News.</p>
<p>To test this, I wrote a basic <a href="https://k6.io/">k6</a> load testing script to measure the max requests per second my server could handle. The script was as simple as possible; it repeatedly requests a single page as many times as possible, while waiting for each request to complete. You can find the full test setup in the <a href="https://martijnhols.nl/blog/how-much-traffic-can-a-pre-rendered-nextjs-site-handle#addendum">addendum</a>.</p>
<figure><span aria-hidden="true">Picture: </span><p><img alt="Sign saying: Slow down - speed limit - 193 RPS" loading="lazy" width="200" height="292" decoding="async" data-nimg="1" srcset="/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fcover.57ced291.png&amp;w=256&amp;q=75 1x, /_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fcover.57ced291.png&amp;w=640&amp;q=75 2x" src="https://martijnhols.nl/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fcover.57ced291.png&amp;w=640&amp;q=75"/></p></figure>
<p>Running this script, a single Next.js instance serving my fully pre-rendered <a href="https://martijnhols.nl/">homepage</a> on an <span role="button" tabindex="0" aria-expanded="false">X4 BladeVPS</span> from <a href="https://www.transip.nl/">TransIP</a> could handle <strong>193 requests per second</strong>, with <b>only 63% of the requests responding within 500ms</b>.</p>
<p>One key thing to underline: <strong>each request in the test is just a single call to the pre-rendered Next.js page</strong>. No assets are requested. A real visitor would need <b>60+ additional requests</b>. That means as few as three simultaneous visitors could push the server dangerously close to its limit.</p>
<p>This was far lower than I expected.</p>
<h3 id="the-anatomy-of-a-visit">The anatomy of a visit</h3>
<p>To understand why this site needs 60+ requests, let&#39;s take a look at all of the requests that happen when someone visits <a href="https://martijnhols.nl/">my homepage</a>:</p>
<ol start="0">
<li>DNS lookup and SSL handshake.</li>
<li><b>Initial request</b> (1: 20.3 kB): The browser requests the HTML document.</li>
<li><b>CSS</b> (1: 1.6 kB): The browser parses the HTML and requests the essential
CSS file.</li>
</ol>
<p><strong>At this point the page is fully styled and visible, and users can interact with most elements, even before JavaScript loads.</strong> The main thing still missing are the:</p>
<ol start="3">
<li><b>Above-the-fold images</b> (5: 6.8 kB): The browser requests the images above
the fold.</li>
</ol>
<p>With typically only a few images above-the-fold, the total up to this point is usually between 50 kB and 100 kB. <strong>This is when the visitor starts seeing a complete page.</strong> As most interactive elements are implemented natively (with the platform), users can also already interact with the page (e.g. navigate around).</p>
<p>The rest of the requests are &#34;deferred&#34;; they&#39;re low priority and do not block rendering. This includes the majority of the requests:</p>
<ol start="4">
<li><b>Analytics</b> (1: 2.5 kB): The browser requests the Plausible script.</li>
<li><b>JavaScript</b> (13: 176.8 kB): The browser requests the JavaScript needed for
the main page.</li>
<li><b>Lazy-loaded images</b> (1: 22.8 kB): The browser requests lazy-loaded images
that are (partly) above the fold.</li>
<li><b>Placeholder data</b> (17: 11.9 kB): The browser requests placeholder data for
images under the fold.</li>
<li><b>Favicons</b> (2: 52.2 kB): The browser requests favicons of various sizes.</li>
<li><b>Preloaded resources</b> (22: 136.1 kB): The browser preloads resources for
potential navigation (to make them instant).</li>
</ol>
<p>The total ends up being <span role="button" tabindex="0" aria-expanded="false"><b>63 requests and 434.5 kB</b></span>.</p>
<p>This shows <strong>Next.js introduces a lot of extra requests and traffic</strong> compared to a more standard server-rendered site, or a non-Next.js static site. While this gives me, as a developer, <span role="button" tabindex="0" aria-expanded="false">full control over the user experience (UX)</span> and an excellent developer experience (DX), it also means the user and server have to handle a lot more traffic. Then again, I don&#39;t think &lt;500 kB is too much traffic for a modern website, especially since the page is already usable after the first 100 kB.</p>
<p><a href="https://react.dev/reference/rsc/server-components">React Server Components</a> (RSC) could improve this <b>slightly</b> by removing <span role="button" tabindex="0" aria-expanded="false">some of the client-side JavaScript</span>. Unfortunately the platform <a href="https://www.joshwcomeau.com/blog/how-i-built-my-blog-v2/#app-router-vs-pages-router-16">isn&#39;t very mature yet</a> and still has many issues. I&#39;m willing to deal with this for the sake of optimal performance, but the main blocker is still its <a href="https://www.joshwcomeau.com/react/css-in-rsc/#the-crux-of-the-problem-4">lack of CSS-in-JS support</a>. As soon as that&#39;s fixed (i.e. <a href="https://github.com/mui/pigment-css">PigmentCSS</a> is released), I&#39;ll be all over it.</p>
<h2 id="scaling-up">Scaling up</h2>
<p>After seeing the disappointing performance of my VPS, I tried scaling up my Docker container (<span aria-hidden="true">`</span><code translate="no">docker compose up -d --scale main=2 main</code><span aria-hidden="true">`</span>). Instead of a single container with one Node.js process handling all requests, I now had one process per CPU core (2 cores total).</p>
<figure><span aria-hidden="true">Picture: </span><p><img alt="CLI showing the scaling up of a Docker container, with two identical containers running afterwards" loading="lazy" width="1974" height="248" decoding="async" data-nimg="1" srcset="/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fdocker-scaling-up.c581b54f.png&amp;w=2048&amp;q=75 1x, /_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fdocker-scaling-up.c581b54f.png&amp;w=3840&amp;q=75 2x" src="https://martijnhols.nl/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fdocker-scaling-up.c581b54f.png&amp;w=3840&amp;q=75"/></p><figcaption><span aria-hidden="true">Caption: </span>Scaling up the container of the site<span aria-hidden="true"></span></figcaption></figure>
<div><p>Aside</p><div><p><span aria-hidden="true">&gt; <!-- -->Aside<!-- -->: </span></p><p>I use <a href="https://github.com/nginx-proxy/nginx-proxy">nginx-proxy</a> in front of my
Docker containers. It&#39;s awesome. It automatically <a href="https://github.com/nginx-proxy/nginx-proxy/tree/main/docs#upstream-server-http-load-balancing-support">load
balances</a>
if there are multiple containers listening to the same domain.</p></div></div>
<p>This barely helped. The VPS could now handle <b>275 requests per second</b> (<span>↑<!-- -->42.49<!-- -->%</span>), but still with <b>only 76% of requests responding within 500ms</b>. Still nowhere near enough to handle a full-blown &#34;<span role="button" tabindex="0" aria-expanded="false">hug of death</span>&#34;. And <strong>I really don&#39;t want my website to go down</strong>.</p>
<p>I also tested other files to get a sense for how the server would handle the additional 60+ requests. Here&#39;s what I found:</p>
<table><thead><tr><th>File</th><th>RPS</th><th>Bottleneck</th></tr></thead><tbody><tr><td>Homepage (20.3 kB)</td><td><span role="button" tabindex="0" aria-expanded="false">275 RPS</span></td><td>CPU</td></tr><tr><td>Blog article (13.9 kB)</td><td><span role="button" tabindex="0" aria-expanded="false">440 RPS</span></td><td>CPU</td></tr><tr><td>Large JS chunk (46.8 kB)</td><td><span role="button" tabindex="0" aria-expanded="false">203 RPS</span></td><td>CPU</td></tr><tr><td>Average JS chunk (6.1 kB)</td><td><span role="button" tabindex="0" aria-expanded="false">833 RPS</span></td><td>CPU</td></tr><tr><td>Small JS chunk (745 B)</td><td><span role="button" tabindex="0" aria-expanded="false">1,961 RPS</span></td><td>CPU</td></tr><tr><td>Image (17.7 kB)</td><td><span role="button" tabindex="0" aria-expanded="false">1,425 RPS</span></td><td>CPU</td></tr><tr><td>Statically generated RSS-feed (2.4 kB)</td><td><span role="button" tabindex="0" aria-expanded="false">849 RPS</span></td><td>CPU</td></tr></tbody></table>
<div><p>Aside</p><div><p><span aria-hidden="true">&gt; <!-- -->Aside<!-- -->: </span></p><p>One interesting thing to note; scaling only resulted in a<!-- --> <!-- -->
<span>↑<!-- -->42.49<!-- -->%</span> increase in RPS on the
homepage because<!-- --> <!-- -->
<b>Next.js already does basic multi-threading for GZIP compression</b>. This
means the original single container was already benefiting slightly from the
second CPU core even before scaling.</p></div></div>
<h3 id="a-surprise-traffic-spike">A surprise traffic spike</h3>
<p>In perfect timing, the day after I found out my server probably couldn&#39;t handle a big <em>hug of death</em>, my article <a href="https://martijnhols.nl/blog/everything-about-google-translate-crashing-react">Everything about Google Translate crashing React (and other web apps)</a> hit the Hacker News frontpage.</p>
<figure><span aria-hidden="true">Picture: </span><p><img alt="Screenshot of Hacker News showing the publication date &#34;2025-02-12T08:58:01&#34;" loading="lazy" width="1570" height="302" decoding="async" data-nimg="1" srcset="/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fhackernews-post-bumped.b004d7a3.png&amp;w=1920&amp;q=75 1x, /_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fhackernews-post-bumped.b004d7a3.png&amp;w=3840&amp;q=75 2x" src="https://martijnhols.nl/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fhackernews-post-bumped.b004d7a3.png&amp;w=3840&amp;q=75"/></p><figcaption><span aria-hidden="true">Caption: </span>The post showed it was an hour old on the 14th, while the actual publication date was two days prior.<span aria-hidden="true"></span></figcaption></figure>
<p>This came as a complete surprise, as <strong>I had last posted the article two days earlier</strong>. Turns out Hacker News can bump older posts straight to the frontpage for a second chance. I was thrilled my article (that I had spent a lot of time on) was getting attention, but it happening right after I realized my site might not be up to task was extra stressful.</p>
<p>Luckily, the traffic wasn&#39;t as intense as I had expected from the Hacker News frontpage, and my VPS held out. But it made me wonder, how bad can a hug of death get? That&#39;s something I&#39;ll dig into in a future article, along with more stats on my own experience.</p>
<h2 id="finding-a-replacement">Finding a replacement</h2>
<p>Frustrated with the performance of my VPS, I went looking for a better solution.</p>
<h3 id="cloudflare">Cloudflare</h3>
<p>The easy answer would be to put <a href="https://www.cloudflare.com/">Cloudflare</a> in front of my server and let it cache the hell out of the static content. I&#39;ve used this setup before; back when I ran <a href="https://wowanalyzer.com/">WoWAnalyzer</a>, a single server paired with Cloudflare effortlessly handled over 550,000 unique visitors in a month.</p>
<p>It&#39;s a nice proposition; <b>with Cloudflare, my server would only need to handle the initial request</b>, while Cloudflare takes care of the other 60. Since my VPS can already handle 200 visitors per second, that would mean problem solved.</p>
<p>But unfortunately, <b>Cloudflare isn&#39;t an option for me</b>. I care about (y)our privacy and I don&#39;t want Cloudflare sitting between my visitors and my site, logging every request and potentially tracking users across the web. Plus, in the current political climate, there are <a href="https://berthub.eu/articles/posts/you-can-no-longer-base-your-government-and-society-on-us-clouds/">other political concerns</a>.</p>
<p><strong>I want to stick exclusively to EU-based services</strong>.</p>
<h3 id="vercel">Vercel</h3>
<p>Another obvious option would be <a href="https://vercel.com/">Vercel</a> (or an EU equivalent). But honestly, that sounds like a nightmare to me. It&#39;s not cheap, the per-site pricing means I&#39;d either be locked in forever or have to tear things down when stopping a project, and it has unpredictable limits with extra costs on every single thing they could think of to charge extra for. This turns going viral from a technical challenge into worrying about what the total of the next bill is going to be. <strong>My current setup has a fixed cost, and I really like that.</strong></p>
<div><p>Aside</p><div><p><span aria-hidden="true">&gt; <!-- -->Aside<!-- -->: </span></p><p>I do pay for <a href="https://plausible.io/">Plausible</a>, which also has usage-based
pricing. But I don&#39;t mind paying for Plausible for three reasons: their
pricing steps are predictable and reasonable, they <a href="https://plausible.io/docs/subscription-plans#what-happens-if-i-go-over-my-monthly-page-views-limit">don&#39;t charge for
occasional traffic
spikes</a>,
and it&#39;s non-essential so I can drop them at any time. I <em>might</em> try
self-hosting in the future to save some money, but then again the last time I
did that with <span role="button" tabindex="0" aria-expanded="false">a similar analytics product</span>, I never got it to handle even a
fraction of the traffic that was thrown at it.</p></div></div>
<h3 id="home-server">Home server</h3>
<p>A home server would be the next best thing, but it isn&#39;t really an option for me. I don&#39;t have access to fiber to provide good response times, I don&#39;t want my IP to be public, my IP is dynamic, and my internet &amp; power aren&#39;t as reliable as I would want a server&#39;s to be. This <a href="https://www.contraption.co/a-mini-data-center/">may be a really good option for you</a> though, especially if <span role="button" tabindex="0" aria-expanded="false">data integrity</span> is not important and you&#39;re open to using Cloudflare.</p>
<h3 id="vps">VPS</h3>
<p>There is probably a better VPS for the same or less money, but I don&#39;t want to spend time researching providers, figuring out if they&#39;re operated from the EU, and then paying just to test their servers. Besides, it&#39;s unlikely a different VPS would make a huge difference.</p>
<h3 id="dedicated-server">Dedicated server</h3>
<!-- -->
<p><b>With those constraints, I reckon a dedicated server is going to be hard to beat.</b> I know it&#39;s kinda overkill for this site, but it&#39;s not the only thing I use my server for. I need a good home for my projects and I want the barrier for launching something new to be as low as possible. A server that I can freely mess around with would be ideal. It eliminates a barrier to my creativity.</p>
<p>Plus, it&#39;s a good skill to keep sharp.</p>
<h2 id="dedicated-server">Dedicated server</h2>
<p>For years, I rented a dedicated server from <a href="https://www.soyoustart.com/nl/"><b>So You Start</b></a>, a budget brand of OVH, to host <a href="https://wowanalyzer.com/">WoWAnalyzer</a>. That server (in combination with Cloudflare) effortlessly handled over 550,000 unique visitors in a single month, processing about 75 million requests without breaking a sweat. So, I figured I&#39;d give them another shot.</p>
<p>Their servers are very affordable. While they use older OVH hardware (2+ year old), their value is excellent. After a quick comparison, I went with the cheapest option; <span role="button" tabindex="0" aria-expanded="false"><b>36 euros per month</b></span> for a <a href="https://eco.ovhcloud.com/nl/soyoustart/sys-1/">6 core/12 thread Intel Xeon-E 2136</a> - only 8 euros more than the VPS used to be.</p>
<figure><span aria-hidden="true">Picture: </span><p><img alt="Overview of the specs of the dedicated server. It shows a SYS-1, with an Intel Xeon-E 2136 processor, 32GB DDR4 ECC 2666Mhz memory, 2x 512GB SSD NVMe Soft RAID storage and 500Mbit/s unmetered public bandwidth." loading="lazy" width="1748" height="852" decoding="async" data-nimg="1" srcset="/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fsys-dedicated-server.6624243e.png&amp;w=1920&amp;q=75 1x, /_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fsys-dedicated-server.6624243e.png&amp;w=3840&amp;q=75 2x" src="https://martijnhols.nl/_next/image?url=%2F_next%2Fstatic%2Fmedia%2Fsys-dedicated-server.6624243e.png&amp;w=3840&amp;q=75"/></p><figcaption><span aria-hidden="true">Caption: </span>Full specs of the dedicated server<span aria-hidden="true"></span></figcaption></figure>
<p><strong>This upgrade made a <em>huge</em> difference.</strong></p>
<p>Running 12 instances (one per thread), the server can handle 2,330 requests per second to the homepage (with 99% responding within 500ms).</p>
<p>I also ran another round of tests on some other files to see how they performed:</p>
<table><thead><tr><th>File</th><th>RPS</th><th>Difference</th><th>Bottleneck</th></tr></thead><tbody><tr><td>Homepage (20.3 kB)</td><td><span role="button" tabindex="0" aria-expanded="false">2,330 RPS</span></td><td><span>↑<!-- -->747.27<!-- -->%</span></td><td>CPU</td></tr><tr><td>Blog article (13.9 kB)</td><td><span role="button" tabindex="0" aria-expanded="false">3,950 RPS</span></td><td><span>↑<!-- -->797.73<!-- -->%</span></td><td>CPU</td></tr><tr><td>Large JS chunk (46.8 kB)</td><td><span role="button" tabindex="0" aria-expanded="false">1,249 RPS</span></td><td><span>↑<!-- -->515.27<!-- -->%</span></td><td>Network</td></tr><tr><td>Average JS chunk (6.1 kB)</td><td><span role="button" tabindex="0" aria-expanded="false">7,627 RPS</span></td><td><span>↑<!-- -->815.61<!-- -->%</span></td><td>CPU</td></tr><tr><td>Small JS chunk (730 B)</td><td><span role="button" tabindex="0" aria-expanded="false">16,175 RPS</span></td><td><span>↑<!-- -->724.83<!-- -->%</span></td><td>CPU</td></tr><tr><td>Image (17.7 kB)</td><td><span role="button" tabindex="0" aria-expanded="false">3,216 RPS</span></td><td><span>↑<!-- -->125.68<!-- -->%</span></td><td>Network</td></tr><tr><td>Statically generated RSS-feed (2.4 kB)</td><td><span role="button" tabindex="0" aria-expanded="false">9,395 RPS</span></td><td><span>↑<!-- -->1006.60<!-- -->%</span></td><td>CPU</td></tr></tbody></table>
<p>This time some files ran into network bottlenecks. This is because budget providers like So You Start usually come with lower bandwidth limits. In this case the max throughput of the server is 500 Mbps.</p>
<p><strong>This is probably more than enough to handle anything real users can throw at it.</strong></p>
<p>The average file size across all files is close to the size of the &#34;Average JS chunk&#34; (6.1 kB). Based on that, this server can support up to 7,600 requests per second. If we divide that by 60+ requests needed to load the homepage, we&#39;re looking at being able to handle a constant stream of over 125 visitors per second.</p>
<p>And blog posts tend to require fewer requests than the homepage (due to there being fewer images), meaning this setup can probably handle even more.</p>
<p>This is a setup I can rely on.</p>
<h2 id="ssr-performance">SSR performance</h2>
<p>Now that we have a solid baseline for static site performance, let&#39;s tackle the other big question: <em>how does server-side rendering (SSR) compare to pre-rendering?</em></p>
<p>A tricky part of benchmarking SSR is deciding <b>what to measure</b>. SSR pages often query databases (e.g. increment view count), call APIs (e.g. Algolia Search), or handling pagination. If we include that, the test would mostly reflect the overhead of that integration rather than SSR itself.</p>
<p>To give SSR the best possible shot, <strong>I&#39;ll focus purely on what happens when rendering a React page with some synchronous logic on the server</strong> - with no additional API or database interactions.</p>
<p>Each test case is a little different. The homepage simply renders the React component tree on the server. The blog article does a tiny bit of logic (calculating the related articles) before rendering. The RSS feed on the other hand, is dynamically generated using the <span aria-hidden="true">`</span><code translate="no">rss</code><span aria-hidden="true">`</span> library. Since SSR might affect each of these differently, I expect some variation in the results, making for an interesting comparison.</p>
<p>Without further ado, the results:</p>
<table><thead><tr><th>File</th><th>RPS</th><th>Difference</th><th>Bottleneck</th></tr></thead><tbody><tr><td>Homepage (20.3 kB)</td><td><span role="button" tabindex="0" aria-expanded="false">271 RPS</span></td><td><span>↓<!-- -->88.37<!-- -->%</span></td><td>CPU</td></tr><tr><td>Blog article (13.9 kB)</td><td><span role="button" tabindex="0" aria-expanded="false">884 RPS</span></td><td><span>↓<!-- -->77.62<!-- -->%</span></td><td>CPU</td></tr><tr><td>Statically generated RSS-feed (2.3 kB)</td><td><span role="button" tabindex="0" aria-expanded="false">4,521 RPS</span></td><td><span>↓<!-- -->51.88<!-- -->%</span></td><td>CPU</td></tr></tbody></table>
<p>I needed a few takes to process this one.</p>
<p>At first glance, <b>271 RPS on the homepage doesn&#39;t seem <em>that</em> bad</b>. Especially considering static assets (CSS, JS, images) are still static and their RPS will be largely unchanged.</p>
<p>But it&#39;s a different story when you consider that <strong>this is all a dedicated server, that is running nothing else, can handle</strong>. It maxes out at <b>almost 90% fewer requests per second</b> than static generation, and if that wasn&#39;t bad enough, only 74% of the requests to the homepage responded within 500ms (the median response time was 1.51 seconds, while 1 in 10 took over 3 seconds).</p>
<p><strong>SSR is very slow to boot.</strong></p>
<p>For good measure, I ran the same test on the VPS to see how it would hold up:</p>
<table><thead><tr><th>File</th><th>RPS</th><th><span role="button" tabindex="0" aria-expanded="false">Difference</span></th><th>Bottleneck</th></tr></thead><tbody><tr><td>Homepage (20.3 kB)</td><td><span role="button" tabindex="0" aria-expanded="false">34 RPS</span></td><td><span>↓<!-- -->87.64<!-- -->%</span></td><td>CPU</td></tr><tr><td>Blog article (13.9 kB)</td><td><span role="button" tabindex="0" aria-expanded="false">95 RPS</span></td><td><span>↓<!-- -->78.41<!-- -->%</span></td><td>CPU</td></tr><tr><td>Statically generated RSS-feed (2.3 kB)</td><td><span role="button" tabindex="0" aria-expanded="false">490 RPS</span></td><td><span>↓<!-- -->42.29<!-- -->%</span></td><td>CPU</td></tr></tbody></table>
<p>Oof.</p>
<p>The numbers make it clear; <strong>using SSR on a page that you&#39;re hoping to get a lot of visitors on is just asking for trouble.</strong></p>
<h2 id="final-thoughts">Final thoughts</h2>
<p>This whole journey started with a simple question: <em>can my site handle a big traffic surge?</em> I always assumed pre-rendering was enough for anything, but I&#39;m glad I put that assumption to the test. Turns out, my original VPS wasn&#39;t nearly as resilient as I thought. Just three visitors per second could have pushed it over its limits. That wasn&#39;t what I expected.</p>
<p>A dedicated server really is a massive upgrade over a VPS. And while it doesn’t have to cost much more, bandwidth limits can be a hidden bottleneck. No point spending extra on better CPU if your server&#39;s network can&#39;t keep up.</p>
<p>At this point, I think my setup can probably handle more than I&#39;ll ever really need.</p>
<p>However, if I&#39;m honest, that&#39;s still just speculation. I don&#39;t actually know for a fact how big a <em>hug of death</em> can get. But that&#39;s something for another time; I&#39;ll cover that, and stats of my own experience landing on the Hacker News frontpage, in a future article.</p>
<p>As for SSR, we now have hard numbers backing up the claim that pre-rendering scales far better.</p>
<p>I&#39;m still curious how much further the server can be pushed - without Next.js. In another upcoming article, I&#39;ll test whether replacing the Next.js server with Nginx and optimizing compression makes a big difference. This should show us whether the Next.js server is efficient in the first place.</p>
<p>Want to see those articles when they drop? Add my <a href="https://martijnhols.nl/rss.xml">RSS feed</a> to your reader or follow me on <a href="https://twitter.com/MartijnHols">Twitter</a>, <a href="https://bsky.app/profile/martijnhols.nl">BlueSky</a> or <span role="button" tabindex="0" aria-expanded="false"><a href="https://www.linkedin.com/in/martijnhols/">LinkedIn</a></span>.</p></div></div>
  </body>
</html>
