<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://ounapuu.ee/posts/2022/02/09/hn-stats-analytics/">Original</a>
    <h1>Surviving the front page of Hacker News on a 50 Mbps uplink</h1>
    
    <div id="readability-page-1" class="page"><div>
      
      <p>Around a month ago <a href="https://news.ycombinator.com/item?id=29871693">I shared my blog post</a>
on HackerNews. I guess I lucked out with the choice of the topic, because it
brought out a lot of enthusiasts who shared their own experiences with older
machinery that still works in 2022. I really appreciate the feedback and the
experiences shared!</p>
<p>Anyway, what is noteworthy in my opinion is that my blog runs off of a residential
connection that has an upload speed limit of 50 Mbps. Once I noticed the post
getting traction, I was worried for a moment. It’s not a rare sight to see a post
on the front page of HackerNews and see it being down due to all the attention
it got.</p>
<p>Somehow, my post managed to weather the storm. Here’s what happened.</p>
<h3 id="analyzing-the-logs">Analyzing the logs</h3>
<p>My page doesn’t have any sort of first-party or third-party analytics software
running. Tracking users across the web is a big no-go for me and I will live by
that, especially on my website. I do have <code>nginx</code> logs, though.</p>
<p>After a quick look around, I found <code>goaccess</code>, a tool that can parse <code>nginx</code>
logs and put together some basic statistics. I found it to be good enough for my
purposes. Here are some notable statistics.</p>
<p>To understand the HackerNews effect, note that the post was published on
2022-01-10 07:42. These logs also include requests towards services that I host
myself.</p>
<figure>
    <img src="https://ounapuu.ee/media/hn-stats-analytics/0-summary.png"/>
    
  </figure><p>


The summary of the week during which one of my posts got popular on HN, as
reported by <code>goaccess</code>, looks like this.</p>

  <figure>
    <img src="https://ounapuu.ee/media/hn-stats-analytics/1-unique-visitors.png"/>
    
  </figure>


<p>During quiet days, nginx logs around 50K requests a day. On 10th of January,
there was a 12x increase. The effect was also noticeable the next day, during
which I assume people caught up with their 100+ tabs that they usually have
open. This may also be down to the post being shared around as well.</p>

  <figure>
    <img src="https://ounapuu.ee/media/hn-stats-analytics/2-requested-files.png"/>
    
  </figure>


<p>Based on this statistic, it seems that the post got around 75K views, either by
real people, crawlers or preview generators.</p>

  <figure>
    <img src="https://ounapuu.ee/media/hn-stats-analytics/3-static-requests.png"/>
    
  </figure>


<p>When we look at the number of requests made towards specific assets, such as
the images in the post, we can see that real impressions are likely to be
around 55K. The first image has been downloaded more than the other two, likely
indicating that it was used as the preview image when the article was linked
on other sites.</p>
<p>This statistic also highlights a surprisingly large cost of web fonts.</p>

  <figure>
    <img src="https://ounapuu.ee/media/hn-stats-analytics/6-operating-systems.png"/>
    
  </figure>


<p>The OS results are likely to be biased, since my self-hosted services go through
the same reverse proxy. The “Unknown” section is likely related to crawlers and
other bots pinging my server.</p>

  <figure>
    <img src="https://ounapuu.ee/media/hn-stats-analytics/7-browsers.png"/>
    
  </figure>


<p>No surprise there: Chrome is the most popular browser used to reach my site.
Firefox makes up a good chunk of hits as well, but a lot of those are likely
requests made from my own machine.</p>

  <figure>
    <img src="https://ounapuu.ee/media/hn-stats-analytics/8-time-distribution.png"/>
    
  </figure>


<p>The time distribution of the requests is interesting. You can notice the background
noise associated with bots and crawlers that occurs during the night. My post
was posted in the morning in my local timezone (UTC +2), which was around the
time EU people wake up and get to work. The other spike around 14-15:00 can
likely be attributed to our friends over the Atlantic ocean.</p>
<p>16:00 in my local time is a bit special. A lot of things coincide with this time:</p>
<ul>
<li>the review embargo for the latest highly sought after CPU/GPU is over, followed
by a barrage of videos on this product in YouTube</li>
<li>the stock market opens and news start rolling in about some big moves</li>
<li>if Slack is having issues, then it’s around this time, because I can only
assume that people get to work and do a production release at the start of the
workday.</li>
</ul>

  <figure>
    <img src="https://ounapuu.ee/media/hn-stats-analytics/13-http-status-codes.png"/>
    
  </figure>


<p>To my surprise, my server survived this and there aren’t too many issues. The
400 and 500 errors are likely attributed to bots trying to exploit my server and
crawlers visiting links that are not valid any more.</p>

  <figure>
    <img src="https://ounapuu.ee/media/hn-stats-analytics/16-geolocation.png"/>
    
  </figure>


<p>There’s likely a bias here as well regarding Europe.</p>
<h3 id="how-i-built-the-blog">How I built the blog</h3>
<p>When I started writing blog posts regularly, I had some principles that I wanted
to stick to:</p>
<ul>
<li>the goal should be on the writing, not the part where I build the website itself</li>
<li>the site has to be static: build it once and deploy it, which should result in
fewer opportunities for attacks and reduced load on the CPU</li>
</ul>
<p>With this in mind, I decided to stick with <a href="https://gohugo.io/">Hugo</a>. Hugo is
just a single binary, has plenty of themes to pick from, and it seems like a
reasonable-enough choice for a site. It’s not the easiest to use as you’ll be
mainly operating in Markdown, and with the theme that I use, I have to
copy-paste a <code>&lt;figure&gt;</code> section, change the image name that it points to, and
make sure that I didn’t mess anything up. However, because this approach rules
out me getting hit by the hottest Wordpress plugin vulnerability of the week, I
think it’s a fair trade-off to make.</p>
<p>I picked <a href="https://github.com/panr/hugo-theme-hello-friend">this theme</a> by
<a href="https://twitter.com/panr">panr</a> and customized it so that it has a landing page
of sorts as well. I haven’t updated it yet and it has some flaws, but it gets
the job done, and that’s what matters to me the most.</p>
<p>Hosting media, such as images, seems like a no-brainer, just put them on the
page and be done with it. Pictures taken with an iPhone SE 2020 are quite big,
though (3-4 MB per image), which will result in the page loading very slowly.
To avoid images bloating the size of the page too much, I have set up a system
where I keep the original images in one folder, copy them to another one, run
<code>mogrify -resize 1024x768 -quality 85 *.jpg</code> to keep the images small, but still
detailed enough, and then deploy those converted images along with the rest of
the blog.</p>
<p>With converted images, a page with three images can fit in less than 1 MB of
transferred files without any issues. With original images, the same page would
require 10 MB of files to be transferred. The math is simple: with a limited
uplink, optimizing the images results in your server being able to serve 10x
more requests.</p>
<h3 id="residential-connections-and-dns">Residential connections and DNS</h3>
<p>If you’re like me, then you probably have a crappy router/modem box from your
local ISP, and a dynamic IP address that usually changes whenever you reboot
said box. This presents a challenge when you try to host anything from your
residential connection since the IP address could change at any time.</p>
<p>To resolve this, there are two options I’m aware of: dynamic DNS providers, or
setting up a script that talks to your DNS provider over a standard API.</p>
<p>I haven’t personally used any dynamic DNS providers, such as <a href="https://www.duckdns.org">DuckDNS</a>,
mainly because my domain registrar has a handy API that I can use to
automatically update my IP address with any time it changes. And yes, I did have
an issue with the script where I triggered a change every minute, resulting in
an angry e-mail being sent to me. Free tech tip: only propagate changes when the
IP address <em>actually</em> changes.</p>
<p>There’s one downside with this issue: you can set your domain TTL (time-to-live)
low, but no matter how low you set it, there will be a period of time after
an IP address change where some DNS servers will point to your old IP address.
This is an availability risk you have to consider when setting up a service on
a dynamic IP address.</p>
<h3 id="future-steps">Future steps</h3>
<p>At one point I took a look a the assets of the Hugo theme that I use and noticed
that it includes a dependency named <code>prism.js</code>, which might be a good thing to
include if you want to display code snippets with syntax highlighting. My issue
with it was that it was included on every page load and took up a significant
chunk of transferred data. I decided to remove it, and just like that, the page
loads even faster.</p>
<p>There’s still room for improvement. The page currently also includes some custom
fonts. If I decide that a built-in font is good enough, then there’s potential
for an additional 0.3 MB of savings.</p>
<p>The web is bloated enough already, but at least I can control what I send to the
client machines on my website.</p>
<h3 id="conclusion">Conclusion</h3>
<p>If you don’t want to go through all the hassle and just want a website up and
running, just get yourself a cheap virtual machine at a cloud provider, or use
something like Github Pages. Those solutions are less likely to hit limits with
bandwidth.</p>
<p>If you like tinkering and the decentralized, self-hosted web to exist
(<em>not Web 3.0!</em>), then feel free to use this post as inspiration for your very
own website. There’s a lot that you can do with limited resources, and it’s
fun to push the limit.</p>
<p>And as a quick tech tip: you can use <a href="https://web.archive.org/web/20220110074515/https://ounapuu.ee/posts/2022/01/09/why-i-went-back-to-using-a-thinkpad-from-2012/">The Wayback Machine</a>
as an insurance policy for your website. If you are concerned about it going
down, have them take a snapshot of it and link it somewhere in a comment.</p>

<p>Places where you can discuss this post:</p>
<ul>
<li><a href="https://news.ycombinator.com/item?id=30269421">Hacker News</a></li>
<li><a href="https://www.reddit.com/r/selfhosted/comments/so6vy5/selfhosting_on_a_limited_residential_connection/">/r/selfhosted</a></li>
<li><a href="https://forum.level1techs.com/t/hddhermans-blog/180788/5?u=hddherman">Level1Techs forum</a></li>
</ul>

    </div></div>
  </body>
</html>
