<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://engineering.fb.com/2025/10/06/developer-tools/openzl-open-source-format-aware-compression-framework/">Original</a>
    <h1>OpenZL: An open source format-aware compression framework</h1>
    
    <div id="readability-page-1" class="page"><div>

		<ul>
<li><a href="https://openzl.org/" target="_blank" rel="noopener">OpenZL</a> is a new open source data compression framework that offers lossless compression for structured data.</li>
<li><span>OpenZL is designed to offer the performance of a format-specific compressor with the easy maintenance of a single executable binary.</span></li>
<li>You can get started with OpenZL today by visiting our <a href="https://facebook.github.io/openzl/getting-started/quick-start/" target="_blank" rel="noopener"><span>Quick Start guide</span></a><span> and the</span> <a href="https://github.com/facebook/openzl" target="_blank" rel="noopener"><span>OpenZL GitHub repository.</span></a></li>
<li>Learn more about the <a href="https://arxiv.org/abs/2510.03203" target="_blank" rel="noopener">theory behind OpenZL in this whitepaper</a>.</li>
</ul>
<p><span>Today, we are excited to announce the public release of <a href="https://openzl.org/" target="_blank" rel="noopener">OpenZL</a>, a new data compression framework. OpenZL offers lossless compression for structured data, with performance comparable to specialized compressors. It accomplishes this by applying a configurable sequence of transforms to the input, revealing hidden order in the data, which can then be more easily compressed. Despite applying distinct transformation permutations for every file type, all OpenZL files can be decompressed using the same universal OpenZL decompressor.</span></p>
<h2><span>A Decade of Lessons</span></h2>
<p><span>When </span><a href="https://engineering.fb.com/2016/08/31/core-infra/smaller-and-faster-data-compression-with-zstandard/" target="_blank" rel="noopener"><span>Zstandard</span></a><span> was announced, it came with a simple pitch: It promised the same or better compression ratio of prior default but at the much increased speed required by datacenter workloads. By pairing strong entropy coding with a design that fully utilized modern CPU capabilities, Zstandard offered a substantial improvement that justified its presence in datacenters.</span></p>
<p><span>However, while it was improved over time, remaining within the Zstandard framework offers diminishing returns. So we started looking for the next great leap in data compression.</span></p>
<p><span>In this quest, one pattern kept repeating: Using generic methods on structured data leaves compression gains on the table. Data isn’t just byte soup. It can be columnar, encode enums, be restricted to specific ranges, or carry highly repetitive fields. More importantly, it has predictable shapes. A bespoke compressor that leans into that structure can beat general-purpose tools on both ratio and speed. But there’s a catch — every bespoke scheme means another compressor and decompressor to create, ship, audit, patch, and trust.</span></p>
<p><span>OpenZL is our answer to the tension between the performance of format-specific compressors and the maintenance simplicity of a single executable binary.</span></p>
<h2><span>Make the Structure Explicit</span></h2>
<p><span>General compressors rely on a one-size fits all processing strategy, or alternatively spend a lot of their cycles guessing which techniques to use. OpenZL saves those cycles by making the structure an explicit input parameter. Compression can then focus on a sequence of reversible steps that surface patterns before coding.</span></p>
<p><span>As a user, you provide OpenZL with the data shape (via a preset or a thin format description). Then the trainer, an offline optimization component, builds an effective compression config that can be re-employed for similar data. During encoding that config resolves into a concrete decode recipe that’s embedded into the frame. The universal decoder will directly execute that recipe, without any out-of-band information.</span></p>
<h2><span>An Example Compression Using OpenZL</span></h2>
<p><span>As an example, let’s compress </span><span>sao</span><span>, which is part of the </span><a href="https://sun.aei.polsl.pl/~sdeor/index.php?page=silesia" target="_blank" rel="noopener"><span>Silesia Compression Corpus</span></a><span>. This file follows a </span><a href="http://tdc-www.harvard.edu/software/catalogs/catalogsb.html" target="_blank" rel="noopener"><span>well-defined format</span></a><span> featuring an array of records, each one describing a star. Providing this information to OpenZL is enough to give it an edge over generic lossless compressors, which only see bytes.</span></p>
<p>Comparison on a M1 cpu, using clang-17</p>
<table>
<tbody>
<tr>
<td><span>Compressor</span></td>
<td><span>zstd -3</span></td>
<td><span>xz -9</span></td>
<td><span>OpenZL</span></td>
</tr>
<tr>
<td><span>Compressed Size</span></td>
<td><span>5,531,935 B​</span></td>
<td><span>4,414,351​ B</span></td>
<td><span>3,516,649​ B</span></td>
</tr>
<tr>
<td><span>Compression Ratio</span></td>
<td><span>x1.31</span></td>
<td><span>x1.64</span></td>
<td><span>x2.06</span></td>
</tr>
<tr>
<td><span>Compression Speed</span></td>
<td><span>220 MB/s</span></td>
<td><span>3.5 MB/s</span></td>
<td><span>340 MB/s</span></td>
</tr>
<tr>
<td><span>Decompression Speed</span></td>
<td><span>850 MB/s</span></td>
<td><span>45 MB/s</span></td>
<td><span>1200 MB/s</span></td>
</tr>
</tbody>
</table>

<p><span>Crucially, OpenZL produces a higher compression ratio </span><i><span>while preserving or even improving speed</span></i><span>, which is critical for data center processing pipelines.</span><span><br/>
</span></p>
<p><span>For illustration, this result is achieved using the following simple graph:</span><span><br/>
</span></p>
<p><img decoding="async" src="https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-graph-1.png" alt="" width="700" height="498" srcset="https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-graph-1.png 1999w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-graph-1.png?resize=916,651 916w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-graph-1.png?resize=768,546 768w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-graph-1.png?resize=1024,728 1024w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-graph-1.png?resize=1536,1092 1536w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-graph-1.png?resize=96,68 96w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-graph-1.png?resize=192,136 192w" sizes="(max-width: 992px) 100vw, 62vw"/></p>
<h3><i><span>A Brief Explanation</span></i></h3>
<p><span>So what is happening in this example?</span></p>
<p><span>We start by separating the header from the rest, a large table of structures. Then each field gets extracted into its own stream: the array of structures becomes a structure of arrays. After that point, we expect that each stream contains homogeneous data of the same type and semantic meaning. We can now focus on finding an optimal compression strategy for each one.</span></p>
<ul>
<li aria-level="1"><span>SRA0</span><span> is a position on the X axis. Due to the way the table is generated, the index is </span><i><span>mostly</span></i><span> sorted, inviting the use of </span><span>delta</span><span> to reduce the range of values represented. This mechanically makes the resulting stream easier to compress. </span></li>
<li aria-level="1"><span>SDEC0</span><span> is a position on the Y axis. It’s not as well sorted as the X axis, but we can at least exploit the fact that it’s bounded between a minimum and a maximum. This makes the higher bytes more predictable, which can be exploited for better compression with the </span><span>transpose</span><span> operation.</span></li>
<li aria-level="1"><span>The other fields (</span><span>IS</span><span>, </span><span>MAG</span><span>, </span><span>XRPM</span><span>, </span><span>XDPM</span><span>) share a common property: their cardinality is much lower than their quantities, and there is no relation between 2 consecutive values. This makes them a good target for </span><span>tokenize</span><span>, which will convert the stream into a dictionary and an index list.</span></li>
<li aria-level="1"><span>The resulting dictionaries and index lists are very different. They benefit from completely different compression strategies. So they are sent to dedicated processing graphs.</span></li>
</ul>
<p><span>The graph continues beyond these steps. But at some point, we can also stop making decisions. The main work is to group data into homogeneous streams. After that, one can count on </span><span>openzl</span><span> to take care of the rest. </span></p>
<p><span>To go even further, we would like to generate compression strategies that are specifically fine-tuned for each stream. This is where the </span><b>offline trainer stage</b><span> comes into play. </span></p>
<h2><span>Generate a Compressor Automatically</span></h2>
<p><span>It’s possible to take full control of the compression process, but it’s also not required. A faster strategy is to just describe your data and let the system learn a </span><b>compression config.</b></p>
<p><b>Describe the input: </b><span>With the </span><a href="https://facebook.github.io/openzl/api/c/graphs/sddl/" target="_blank" rel="noopener"><span>Simple Data Description Language (SDDL)</span></a><span>, you sketch how the bytes map to fields — rows, columns, enums, nested records. SDDL is for parsing only; it just tells OpenZL the shape of your data. Alternatively, you can write your own parser function directly using one of the supported languages, and register it with OpenZL to delegate the logic.</span></p>
<p><b>Learn the config: </b><span>Starting from a preset, a parser function or an SDDL description, the </span><b>trainer</b><span> runs a budgeted search over transform choices and parameters to produce a </span><b>Plan</b><span>. It can provide a full set of speed/ratio tradeoffs, or directly target the best configuration respecting some speed constraints. Internally it uses a cluster finder (to group fields that behave alike) and a graph explorer (to try candidate subgraphs and keep score).</span></p>
<p><b>Resolve at encode-time: </b><span>While compressing, the encoder turns the Plan into a concrete recipe — the </span><b>Resolved Graph</b><span>. If the Plan has control points, it picks the branch that fits the data and records that choice into the frame.</span></p>
<p><b>Decode without coordination: </b><span>Each frame chunk carries its own resolved graph. The single decoder checks it, enforces limits, and runs the steps in order. When a plan improves, you just roll out the new plan, no new decompressor needed. Old data keeps decoding; new data get improved gains. </span></p>
<p><i><span>In practice the loop is straightforward: describe (SDDL) → train (produce a plan) → compress (emit frames with resolved graphs) → decode anywhere with the same binary.</span></i></p>
<h2>Embracing Changes: Re-Training and In-Flight Control</h2>
<p><span>In the real world, data evolves constantly, in both structure and content. A compressor built for one version of a schema would have a short lifetime. </span></p>
<p><span>Thankfully, with the flexibility offered by compression plans, we can react swiftly to data changes. At Meta, this is the core mission of </span><b>Managed Compression</b><span>, originally created to automate dictionary compression with Zstandard, and presented in an earlier blog </span><a href="https://engineering.fb.com/2018/12/19/core-infra/zstandard/" target="_blank" rel="noopener"><span>on how we improved compression at with Zstandard</span></a><span>. </span></p>
<p><span>OpenZL offers a training process that updates compression plans to maintain or improve compression performance, based on provided data samples. Now the synergy with Managed Compression is apparent: Each registered use case is monitored, sampled, periodically re-trained, and receives new configs when they prove beneficial. The decompression side continues to decode both old and new data without any change.</span></p>
<p><b>Runtime Adaptation:</b><span> A compression config can include </span><b>control points</b><span> that read lightweight statistics at compression time (e.g., string repetition stats, run-length, histogram skew, delta variance) and choose the best branch of the Plan to go to next. Many technologies can be used, and textbook classifiers qualify. Control points handle bursts, outliers, and seasonal shifts without brute-force exploration: exploration is bounded, in order to maintain speed expectations. Taken branches are then recorded into the frame, and the decoder just executes the recorded path.</span></p>
<p><span>This gives the best of both worlds: dynamic behavior at compression time to handle variations and exceptions — without turning compression into an unbounded search problem — and with zero complexity added to the decoder.</span></p>
<h2><span>The Advantages of the Universal Decoder</span></h2>
<p><span>OpenZL is capable of compressing a vast array of data formats, and they can all be decompressed with a single decompressor binary. Even when the compression configuration changes, the decoder does not. This may sound like operational minutiae, but it’s critical to OpenZL’s deployment success.</span></p>
<ul>
<li aria-level="1"><b>One audited surface:</b><span> Security and correctness reviews focus on a single binary with consistent invariants, fuzzing, and hardening; there’s no myriad of per-format tools that can drift apart.</span></li>
<li aria-level="1"><b>Fleet-wide improvements: </b><span>A decoder update (security or performance — SIMD kernels, memory bounds, scheduling) benefits every compressed file, even those that predate the change.</span></li>
<li aria-level="1"><b>Operational clarity:</b><span> Same binary, same CLI, same metrics and dashboards across datasets; patching and rollout are uneventful by design.</span></li>
<li aria-level="1"><b>Continuous training: </b><span>With one decoder and many compression plans, we can keep improving while the system is live. Train a plan offline, try it on a small slice, then roll it out like any other config change. Backward compatibility is built-in — old frames still decode while new frames get better.</span></li>
</ul>
<p><span>In other words, it’s possible to afford domain-specific compression without fragmenting the ecosystem.</span></p>
<h2><span>Results With OpenZL</span></h2>
<p><span>When OpenZL is able to understand and parse the file format, it is able to offer large improvements in compression ratio, while still providing fast compression and decompression speed. However, this is no magic bullet. When OpenZL doesn’t understand the input file format, it simply falls back to </span><span>zstd</span><span>.</span></p>
<p><span>OpenZL, through its offline training capabilities, is also able to offer a wide range of configurations in the tradeoff space of compression ratio, compression speed, and decompression speed. Unlike traditional compressors, which offer configuration by setting a compression level, OpenZL offers configuration by serializing the compressor graph. This allows an immense amount of flexibility to select diverse tradeoffs.</span></p>
<p><span>These results are based on datasets we’ve <a href="https://arxiv.org/abs/2510.03203" target="_blank" rel="noopener">developed for our whitepaper</a>. The datasets were chosen because they are highly structured and in a format that OpenZL supports. Every figure below is produced with <a href="https://github.com/facebook/openzl/blob/dev/contrib/reproducibility/figures/script.sh" target="_blank" rel="noopener">scripts in the OpenZL repository</a> so they can be reproduced, and the input data and logs from our runs have been uploaded </span><a href="https://github.com/facebook/openzl/releases/tag/openzl-sample-artifacts" target="_blank" rel="noopener"><span>to GitHub</span></a><span>.</span></p>
<p><span>Note that data points connected by a line are pareto-optimal. All such points have the property that there is no point in the same dataset which beats them in both metrics.</span></p>
<figure id="attachment_23055" aria-describedby="caption-attachment-23055"><img decoding="async" src="https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-SAO-dataset-speeds-vs-ratio.png" alt="" width="700" height="334" srcset="https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-SAO-dataset-speeds-vs-ratio.png 1999w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-SAO-dataset-speeds-vs-ratio.png?resize=916,437 916w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-SAO-dataset-speeds-vs-ratio.png?resize=768,367 768w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-SAO-dataset-speeds-vs-ratio.png?resize=1024,489 1024w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-SAO-dataset-speeds-vs-ratio.png?resize=1536,733 1536w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-SAO-dataset-speeds-vs-ratio.png?resize=96,46 96w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-SAO-dataset-speeds-vs-ratio.png?resize=192,92 192w" sizes="(max-width: 992px) 100vw, 62vw"/><figcaption id="caption-attachment-23055"><strong>Figure 1 — SAO:</strong> These figures show compression speed and decompression speed vs. ratio for SAO comparing OpenZL with three general compression tools. As shown in the example, OpenZL destructures the star records into columns for each field, and then the trainer learns how to best compress each field to produce a set of OpenZL configurations offering a wide range of tradeoffs.</figcaption></figure>
<figure id="attachment_23056" aria-describedby="caption-attachment-23056"><img loading="lazy" decoding="async" src="https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-ERA5-dataset.png" alt="" width="700" height="324" srcset="https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-ERA5-dataset.png 1999w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-ERA5-dataset.png?resize=916,424 916w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-ERA5-dataset.png?resize=768,355 768w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-ERA5-dataset.png?resize=1024,474 1024w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-ERA5-dataset.png?resize=1536,711 1536w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-ERA5-dataset.png?resize=96,44 96w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-ERA5-dataset.png?resize=192,89 192w" sizes="auto, (max-width: 992px) 100vw, 62vw"/><figcaption id="caption-attachment-23056"><b>Figure 2 — Columnar numeric data: </b><span>These figures show compression speed and decompression speed vs. ratio for the ERA5 Flux dataset for OpenZL and three general compression tools. The data is presented to the compressor as a single array of 64-bit numeric data. For a given time budget, OpenZL achieves substantially higher compression ratios. Likewise, for a given compression ratio, OpenZL can complete the job with greater speed.</span></figcaption></figure>
<figure id="attachment_23057" aria-describedby="caption-attachment-23057"><img loading="lazy" decoding="async" src="https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-Binance-dataset.png" alt="" width="700" height="318" srcset="https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-Binance-dataset.png 1999w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-Binance-dataset.png?resize=916,417 916w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-Binance-dataset.png?resize=768,349 768w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-Binance-dataset.png?resize=1024,466 1024w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-Binance-dataset.png?resize=1536,698 1536w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-Binance-dataset.png?resize=96,44 96w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-Binance-dataset.png?resize=192,87 192w" sizes="auto, (max-width: 992px) 100vw, 62vw"/><figcaption id="caption-attachment-23057"><strong>Figure 3 — Parquet: </strong>These two figures show compression speed vs. ratio for the Binance and TLC Green Trip dataset for OpenZL and three general compression tools, presented as uncompressed Parquet files. OpenZL parses the Parquet format and learns the schema in order to tune compression to each file.</figcaption></figure>
<figure id="attachment_23058" aria-describedby="caption-attachment-23058"><img loading="lazy" decoding="async" src="https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-PPMF-unit-dataset.png" alt="" width="700" height="314" srcset="https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-PPMF-unit-dataset.png 1999w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-PPMF-unit-dataset.png?resize=916,411 916w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-PPMF-unit-dataset.png?resize=768,345 768w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-PPMF-unit-dataset.png?resize=1024,460 1024w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-PPMF-unit-dataset.png?resize=1536,690 1536w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-PPMF-unit-dataset.png?resize=96,43 96w, https://engineering.fb.com/wp-content/uploads/2025/10/Meta-OpenZL-PPMF-unit-dataset.png?resize=192,86 192w" sizes="auto, (max-width: 992px) 100vw, 62vw"/><figcaption id="caption-attachment-23058"><strong>Figure 4 — CSV: </strong>This figure shows the compression speed vs. ratio tradeoff for the PPMF Unit dataset for OpenZL and three general compression tools, presented as CSV files. OpenZL is able to offer excellent compression ratios, but the cost of parsing CSV caps the compression speed at about 64 MB/s. An improved parser will speed that up, however this strategy will likely never approach Zstd’s speeds of 1 GB/s. Nonetheless and not pictured here, OpenZL always has the option to fallback to the <span>zstd </span>codec, so its performance can be lower-bounded by <span>zstd</span>.</figcaption></figure>
<h3><em><span>When It’s Not Useful</span></em></h3>
<p><span>OpenZL relies on a description of some structure to leverage its set of transforms. When there is no structure, there is no advantage. This is typically the case in pure text documents, such as </span><span>enwik</span><span> or </span><span>dickens</span><span>. In these cases, OpenZL falls back to </span><span>zstd</span><span>, offering essentially the same level of performance.</span></p>
<h2><span>Getting Started With OpenZL</span></h2>
<p><span>OpenZL’s selection of codecs is well-suited to compressing vector, tabular, or tree-structured data, and can be expected to perform well with numeric, string, or binary data. Common examples include timeseries datasets, ML tensors, and database tables. Keep in mind that we are bound by the limits of information theory, so the input needs to have some order that can be uncovered. As time goes on, we plan to incorporate additional codecs, as described in the next section.</span></p>
<p><span>If your data fits one of the above categories, then give it a try! Visit the <a href="https://openzl.org/" target="_blank" rel="noopener">OpenZL site</a> and our </span><a href="https://facebook.github.io/openzl/getting-started/quick-start/" target="_blank" rel="noopener"><span>Quick Start guide</span></a><span> to get started.</span></p>
<p><span>If you want to dive into the code, check out the</span> <a href="https://github.com/facebook/openzl" target="_blank" rel="noopener"><span>GitHub repository</span></a><span> for source, documentation, and examples. We welcome contributions and feedback from the community!</span></p>
<h2><span>Where We’re Going</span></h2>
<p><span>OpenZL’s general direction is set: make it easier to expose structures, and exploit it with automated compression plans for evolving data.</span></p>
<p><b>Next up</b><span>: We’re extending the transform library for time-series and grid-shaped data, improving performance of codecs, and enabling the trainer to find better compression plans faster. We also are actively working to extend SDDL to describe nested data formats more flexibly. Finally, the automated compressor explorer is getting better at proposing safe, testable changes to a compression plan within a specified budget.</span></p>
<p><b>Where the community can help: </b><span>If you have a format or a dataset with obvious structure, try compressing it with an OpenZL prebuilt Plan. If it’s promising, try generating a new plan with the trainer or customizing it with our documentation to improve it. If it’s a format that the public might want, send it to us in a PR.</span></p>
<p><span>You can also contribute to the OpenZL core. If you have a knack for optimizing C/C++, help us speed up the engine or add transforms to cover new data formats. If your super power is reliability, the project would surely benefit from more validation rules and resource caps. And if you care about benchmarks, add your dataset to the harness so others can reproduce your results.</span></p>
<p><b>How to engage:</b><span> Open an issue on the GitHub issue board. If you have a use-case for which you would expect OpenZL to do better, provide a few small samples, so that we can analyze them together. You may also contribute to codec optimizations, and propose new graphs, parsers or control points. All these topics do not impact the universality of the decoder.</span></p>
<p><span>We believe OpenZL opens up a new universe of possibilities to the data compression field, and we’re excited to see what the open source community will do with it!</span></p>
<p><span>To learn more about Meta Open Source, visit our </span><a href="https://opensource.fb.com/" target="_blank" rel="noopener"><span>website</span></a><span>, subscribe to our </span><a href="https://www.youtube.com/channel/UCCQY962PmHabTjaHv2wJzfQ" target="_blank" rel="noopener"><span>YouTube channel</span></a><span>, or follow us on </span><a href="https://www.facebook.com/MetaOpenSource" target="_blank" rel="noopener"><span>Facebook</span></a><span>, </span><a href="https://www.threads.net/@metaopensource" target="_blank" rel="noopener"><span>Threads</span></a><span>, </span><a href="https://x.com/MetaOpenSource" target="_blank" rel="noopener"><span>X</span></a><span>, </span><a href="https://bsky.app/profile/metaopensource.bsky.social" target="_blank" rel="noopener"><span>Bluesky</span></a><span> and </span><a href="https://www.linkedin.com/showcase/meta-open-source?fbclid=IwZXh0bgNhZW0CMTEAAR2fEOJNb7zOi8rJeRvQry5sRxARpdL3OpS4sYLdC1_npkEy60gBS1ynXwQ_aem_mJUK6jEUApFTW75Emhtpqw" target="_blank" rel="noopener"><span>LinkedIn</span></a><span>.</span></p>

		
	</div></div>
  </body>
</html>
