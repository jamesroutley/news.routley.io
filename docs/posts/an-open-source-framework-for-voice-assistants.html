<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/pipecat-ai/pipecat">Original</a>
    <h1>Show HN: An open source framework for voice assistants</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto">
¬†<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/pipecat-ai/pipecat/blob/main/pipecat.png"><img alt="pipecat" width="300px" height="auto" src="https://github.com/pipecat-ai/pipecat/raw/main/pipecat.png"/></a>
</p></div>
<div dir="auto"><a id="user-content-pipecat" aria-label="Permalink: Pipecat" href="#pipecat"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><a href="https://pypi.org/project/pipecat-ai" rel="nofollow"><img src="https://camo.githubusercontent.com/e44c7b97b713ead1309d49f5930eaf97f7045880e0f508d21570d49f607485df/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f706970656361742d6169" alt="PyPI" data-canonical-src="https://img.shields.io/pypi/v/pipecat-ai"/></a> <a href="https://discord.gg/pipecat" rel="nofollow"><img src="https://camo.githubusercontent.com/884b6fbc9b12772324a7011eaee4cc25bc81d85225e7cf866f74b007051511e6/68747470733a2f2f696d672e736869656c64732e696f2f646973636f72642f31323339323834363737313635303536303231" alt="Discord" data-canonical-src="https://img.shields.io/discord/1239284677165056021"/></a></p>
<p dir="auto"><code>pipecat</code> is a framework for building voice (and multimodal) conversational agents. Things like personal coaches, meeting assistants, <a href="https://storytelling-chatbot.fly.dev/" rel="nofollow">story-telling toys for kids</a>, customer support bots, <a href="https://www.youtube.com/watch?v=lDevgsp9vn0" rel="nofollow">intake flows</a>, and snarky social companions.</p>
<p dir="auto">Take a look at some example apps:</p>
<p dir="auto">
    <a href="https://github.com/pipecat-ai/pipecat/tree/main/examples/simple-chatbot"><img src="https://github.com/pipecat-ai/pipecat/raw/main/examples/simple-chatbot/image.png" width="280"/></a>¬†
    <a href="https://github.com/pipecat-ai/pipecat/tree/main/examples/storytelling-chatbot"><img src="https://github.com/pipecat-ai/pipecat/raw/main/examples/storytelling-chatbot/image.png" width="280"/></a>
    </p>
<div dir="auto"><h2 tabindex="-1" dir="auto">Getting started with voice agents</h2><a id="user-content-getting-started-with-voice-agents" aria-label="Permalink: Getting started with voice agents" href="#getting-started-with-voice-agents"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">You can get started with Pipecat running on your local machine, then move your agent processes to the cloud when you‚Äôre ready. You can also add a üìû telephone number, üñºÔ∏è image output, üì∫ video input, use different LLMs, and more.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# install the module
pip install pipecat-ai

# set up an .env file with API keys
cp dot-env.template .env"><pre><span><span>#</span> install the module</span>
pip install pipecat-ai

<span><span>#</span> set up an .env file with API keys</span>
cp dot-env.template .env</pre></div>
<p dir="auto">By default, in order to minimize dependencies, only the basic framework functionality is available. Some third-party AI services require additional dependencies that you can install with:</p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install &#34;pipecat-ai[option,...]&#34;"><pre>pip install <span><span>&#34;</span>pipecat-ai[option,...]<span>&#34;</span></span></pre></div>
<p dir="auto">Your project may or may not need these, so they&#39;re made available as optional requirements. Here is a list:</p>
<ul dir="auto">
<li><strong>AI services</strong>: <code>anthropic</code>, <code>azure</code>, <code>fal</code>, <code>moondream</code>, <code>openai</code>, <code>playht</code>, <code>silero</code>, <code>whisper</code></li>
<li><strong>Transports</strong>: <code>local</code>, <code>websocket</code>, <code>daily</code></li>
</ul>
<div dir="auto"><h2 tabindex="-1" dir="auto">Code examples</h2><a id="user-content-code-examples" aria-label="Permalink: Code examples" href="#code-examples"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li><a href="https://github.com/pipecat-ai/pipecat/tree/main/examples/foundational">foundational</a> ‚Äî small snippets that build on each other, introducing one or two concepts at a time</li>
<li><a href="https://github.com/pipecat-ai/pipecat/tree/main/examples/">example apps</a> ‚Äî complete applications that you can use as starting points for development</li>
</ul>
<div dir="auto"><h2 tabindex="-1" dir="auto">A simple voice agent running locally</h2><a id="user-content-a-simple-voice-agent-running-locally" aria-label="Permalink: A simple voice agent running locally" href="#a-simple-voice-agent-running-locally"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Here is a very basic Pipecat bot that greets a user when they join a real-time session. We&#39;ll use <a href="https://daily.co" rel="nofollow">Daily</a> for real-time media transport, and <a href="https://elevenlabs.io/" rel="nofollow">ElevenLabs</a> for text-to-speech.</p>
<div dir="auto" data-snippet-clipboard-copy-content="#app.py

import asyncio
import aiohttp

from pipecat.frames.frames import EndFrame, TextFrame
from pipecat.pipeline.pipeline import Pipeline
from pipecat.pipeline.task import PipelineTask
from pipecat.pipeline.runner import PipelineRunner
from pipecat.services.elevenlabs import ElevenLabsTTSService
from pipecat.transports.services.daily import DailyParams, DailyTransport

async def main():
  async with aiohttp.ClientSession() as session:
    # Use Daily as a real-time media transport (WebRTC)
    transport = DailyTransport(
      room_url=...,
      token=...,
      &#34;Bot Name&#34;,
      DailyParams(audio_out_enabled=True))

    # Use Eleven Labs for Text-to-Speech
    tts = ElevenLabsTTSService(
      aiohttp_session=session,
      api_key=...,
      voice_id=...,
      )

    # Simple pipeline that will process text to speech and output the result
    pipeline = Pipeline([tts, transport.output()])

    # Create Pipecat processor that can run one or more pipelines tasks
    runner = PipelineRunner()

    # Assign the task callable to run the pipeline
    task = PipelineTask(pipeline)

    # Register an event handler to play audio when a
    # participant joins the transport WebRTC session
    @transport.event_handler(&#34;on_participant_joined&#34;)
    async def on_new_participant_joined(transport, participant):
      participant_name = participant[&#34;info&#34;][&#34;userName&#34;] or &#39;&#39;
      # Queue a TextFrame that will get spoken by the TTS service (Eleven Labs)
      await task.queue_frames([TextFrame(f&#34;Hello there, {participant_name}!&#34;), EndFrame()])

    # Run the pipeline task
    await runner.run(task)

if __name__ == &#34;__main__&#34;:
  asyncio.run(main())"><pre><span>#app.py</span>

<span>import</span> <span>asyncio</span>
<span>import</span> <span>aiohttp</span>

<span>from</span> <span>pipecat</span>.<span>frames</span>.<span>frames</span> <span>import</span> <span>EndFrame</span>, <span>TextFrame</span>
<span>from</span> <span>pipecat</span>.<span>pipeline</span>.<span>pipeline</span> <span>import</span> <span>Pipeline</span>
<span>from</span> <span>pipecat</span>.<span>pipeline</span>.<span>task</span> <span>import</span> <span>PipelineTask</span>
<span>from</span> <span>pipecat</span>.<span>pipeline</span>.<span>runner</span> <span>import</span> <span>PipelineRunner</span>
<span>from</span> <span>pipecat</span>.<span>services</span>.<span>elevenlabs</span> <span>import</span> <span>ElevenLabsTTSService</span>
<span>from</span> <span>pipecat</span>.<span>transports</span>.<span>services</span>.<span>daily</span> <span>import</span> <span>DailyParams</span>, <span>DailyTransport</span>

<span>async</span> <span>def</span> <span>main</span>():
  <span>async</span> <span>with</span> <span>aiohttp</span>.<span>ClientSession</span>() <span>as</span> <span>session</span>:
    <span># Use Daily as a real-time media transport (WebRTC)</span>
    <span>transport</span> <span>=</span> <span>DailyTransport</span>(
      <span>room_url</span><span>=</span>...,
      <span>token</span><span>=</span>...,
      <span>&#34;Bot Name&#34;</span>,
      <span>DailyParams</span>(<span>audio_out_enabled</span><span>=</span><span>True</span>))

    <span># Use Eleven Labs for Text-to-Speech</span>
    <span>tts</span> <span>=</span> <span>ElevenLabsTTSService</span>(
      <span>aiohttp_session</span><span>=</span><span>session</span>,
      <span>api_key</span><span>=</span>...,
      <span>voice_id</span><span>=</span>...,
      )

    <span># Simple pipeline that will process text to speech and output the result</span>
    <span>pipeline</span> <span>=</span> <span>Pipeline</span>([<span>tts</span>, <span>transport</span>.<span>output</span>()])

    <span># Create Pipecat processor that can run one or more pipelines tasks</span>
    <span>runner</span> <span>=</span> <span>PipelineRunner</span>()

    <span># Assign the task callable to run the pipeline</span>
    <span>task</span> <span>=</span> <span>PipelineTask</span>(<span>pipeline</span>)

    <span># Register an event handler to play audio when a</span>
    <span># participant joins the transport WebRTC session</span>
    <span>@<span>transport</span>.<span>event_handler</span>(<span>&#34;on_participant_joined&#34;</span>)</span>
    <span>async</span> <span>def</span> <span>on_new_participant_joined</span>(<span>transport</span>, <span>participant</span>):
      <span>participant_name</span> <span>=</span> <span>participant</span>[<span>&#34;info&#34;</span>][<span>&#34;userName&#34;</span>] <span>or</span> <span>&#39;&#39;</span>
      <span># Queue a TextFrame that will get spoken by the TTS service (Eleven Labs)</span>
      <span>await</span> <span>task</span>.<span>queue_frames</span>([<span>TextFrame</span>(<span>f&#34;Hello there, <span><span>{</span><span>participant_name</span><span>}</span></span>!&#34;</span>), <span>EndFrame</span>()])

    <span># Run the pipeline task</span>
    <span>await</span> <span>runner</span>.<span>run</span>(<span>task</span>)

<span>if</span> <span>__name__</span> <span>==</span> <span>&#34;__main__&#34;</span>:
  <span>asyncio</span>.<span>run</span>(<span>main</span>())</pre></div>
<p dir="auto">Run it with:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python app.py"><pre>python app.py</pre></div>
<p dir="auto">Daily provides a prebuilt WebRTC user interface. Whilst the app is running, you can visit at <code>https://&lt;yourdomain&gt;.daily.co/&lt;room_url&gt;</code> and listen to the bot say hello!</p>
<div dir="auto"><h2 tabindex="-1" dir="auto">WebRTC for production use</h2><a id="user-content-webrtc-for-production-use" aria-label="Permalink: WebRTC for production use" href="#webrtc-for-production-use"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">WebSockets are fine for server-to-server communication or for initial development. But for production use, you‚Äôll need client-server audio to use a protocol designed for real-time media transport. (For an explanation of the difference between WebSockets and WebRTC, see <a href="https://www.daily.co/blog/how-to-talk-to-an-llm-with-your-voice/#webrtc" rel="nofollow">this post.</a>)</p>
<p dir="auto">One way to get up and running quickly with WebRTC is to sign up for a Daily developer account. Daily gives you SDKs and global infrastructure for audio (and video) routing. Every account gets 10,000 audio/video/transcription minutes free each month.</p>
<p dir="auto">Sign up <a href="https://dashboard.daily.co/u/signup" rel="nofollow">here</a> and <a href="https://docs.daily.co/reference/rest-api/rooms" rel="nofollow">create a room</a> in the developer Dashboard.</p>
<div dir="auto"><h2 tabindex="-1" dir="auto">What is VAD?</h2><a id="user-content-what-is-vad" aria-label="Permalink: What is VAD?" href="#what-is-vad"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Voice Activity Detection ‚Äî very important for knowing when a user has finished speaking to your bot. If you are not using press-to-talk, and want Pipecat to detect when the user has finished talking, VAD is an essential component for a natural feeling conversation.</p>
<p dir="auto">Pipecast makes use of WebRTC VAD by default when using a WebRTC transport layer. Optionally, you can use Silero VAD for improved accuracy at the cost of higher CPU usage.</p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install pipecat-ai[silero]"><pre>pip install pipecat-ai[silero]</pre></div>
<p dir="auto">The first time your run your bot with Silero, startup may take a while whilst it downloads and caches the model in the background. You can check the progress of this in the console.</p>
<div dir="auto"><h2 tabindex="-1" dir="auto">Hacking on the framework itself</h2><a id="user-content-hacking-on-the-framework-itself" aria-label="Permalink: Hacking on the framework itself" href="#hacking-on-the-framework-itself"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><em>Note that you may need to set up a virtual environment before following the instructions below. For instance, you might need to run the following from the root of the repo:</em></p>
<div dir="auto" data-snippet-clipboard-copy-content="python3 -m venv venv
source venv/bin/activate"><pre>python3 -m venv venv
<span>source</span> venv/bin/activate</pre></div>
<p dir="auto">From the root of this repo, run the following:</p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install -r dev-requirements.txt -r {env}-requirements.txt
python -m build"><pre>pip install -r dev-requirements.txt -r {env}-requirements.txt
python -m build</pre></div>
<p dir="auto">This builds the package. To use the package locally (eg to run sample files), run</p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install --editable ."><pre>pip install --editable <span>.</span></pre></div>
<p dir="auto">If you want to use this package from another directory, you can run:</p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install path_to_this_repo"><pre>pip install path_to_this_repo</pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">Running tests</h3><a id="user-content-running-tests" aria-label="Permalink: Running tests" href="#running-tests"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">From the root directory, run:</p>
<div dir="auto" data-snippet-clipboard-copy-content="pytest --doctest-modules --ignore-glob=&#34;*to_be_updated*&#34; src tests"><pre>pytest --doctest-modules --ignore-glob=<span><span>&#34;</span>*to_be_updated*<span>&#34;</span></span> src tests</pre></div>
<div dir="auto"><h2 tabindex="-1" dir="auto">Setting up your editor</h2><a id="user-content-setting-up-your-editor" aria-label="Permalink: Setting up your editor" href="#setting-up-your-editor"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">This project uses strict <a href="https://peps.python.org/pep-0008/" rel="nofollow">PEP 8</a> formatting.</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">Emacs</h3><a id="user-content-emacs" aria-label="Permalink: Emacs" href="#emacs"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">You can use <a href="https://github.com/jwiegley/use-package">use-package</a> to install <a href="https://codeberg.org/ideasman42/emacs-py-autopep8" rel="nofollow">py-autopep8</a> package and configure <code>autopep8</code> arguments:</p>
<div dir="auto" data-snippet-clipboard-copy-content="(use-package py-autopep8
  :ensure t
  :defer t
  :hook ((python-mode . py-autopep8-mode))
  :config
  (setq py-autopep8-options &#39;(&#34;-a&#34; &#34;-a&#34;, &#34;--max-line-length=100&#34;)))"><pre>(<span>use-package</span> py-autopep8
  <span>:ensure</span> <span>t</span>
  <span>:defer</span> <span>t</span>
  <span>:hook</span> ((<span>python-mode</span> <span>.</span> py-autopep8-mode))
  <span>:config</span>
  (<span>setq</span> py-autopep8-options &#39;(<span><span>&#34;</span>-a<span>&#34;</span></span> <span><span>&#34;</span>-a<span>&#34;</span></span>, <span><span>&#34;</span>--max-line-length=100<span>&#34;</span></span>)))</pre></div>
<p dir="auto"><code>autopep8</code> was installed in the <code>venv</code> environment described before, so you should be able to use <a href="https://github.com/ryotaro612/pyvenv-auto">pyvenv-auto</a> to automatically load that environment inside Emacs.</p>
<div dir="auto" data-snippet-clipboard-copy-content="(use-package pyvenv-auto
  :ensure t
  :defer t
  :hook ((python-mode . pyvenv-auto-run)))
"><pre>(<span>use-package</span> pyvenv-auto
  <span>:ensure</span> <span>t</span>
  <span>:defer</span> <span>t</span>
  <span>:hook</span> ((<span>python-mode</span> <span>.</span> pyvenv-auto-run)))
</pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">Visual Studio Code</h3><a id="user-content-visual-studio-code" aria-label="Permalink: Visual Studio Code" href="#visual-studio-code"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Install the
<a href="https://marketplace.visualstudio.com/items?itemName=ms-python.autopep8" rel="nofollow">autopep8</a> extension. Then edit the user settings (<em>Ctrl-Shift-P</em> <code>Open User Settings (JSON)</code>) and set it as the default Python formatter, enable formatting on save and configure <code>autopep8</code> arguments:</p>
<div dir="auto" data-snippet-clipboard-copy-content="&#34;[python]&#34;: {
    &#34;editor.defaultFormatter&#34;: &#34;ms-python.autopep8&#34;,
    &#34;editor.formatOnSave&#34;: true
},
&#34;autopep8.args&#34;: [
    &#34;-a&#34;,
    &#34;-a&#34;,
    &#34;--max-line-length=100&#34;
],"><pre><span>&#34;[python]&#34;</span>: {
    <span>&#34;editor.defaultFormatter&#34;</span>: <span><span>&#34;</span>ms-python.autopep8<span>&#34;</span></span>,
    <span>&#34;editor.formatOnSave&#34;</span>: <span>true</span>
},
<span>&#34;autopep8.args&#34;</span>: [
    <span><span>&#34;</span>-a<span>&#34;</span></span>,
    <span><span>&#34;</span>-a<span>&#34;</span></span>,
    <span><span>&#34;</span>--max-line-length=100<span>&#34;</span></span>
],</pre></div>
<div dir="auto"><h2 tabindex="-1" dir="auto">Getting help</h2><a id="user-content-getting-help" aria-label="Permalink: Getting help" href="#getting-help"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">‚û°Ô∏è <a href="https://discord.gg/pipecat" rel="nofollow">Join our Discord</a></p>
<p dir="auto">‚û°Ô∏è <a href="https://x.com/pipecat_ai" rel="nofollow">Reach us on Twitter</a></p>
</article></div></div>
  </body>
</html>
