<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.blog/2020-05-20-three-bugs-in-the-go-mysql-driver/">Original</a>
    <h1>Three bugs in the Go MySQL driver (2020)</h1>
    
    <div id="readability-page-1" class="page"><div>
<div>
<div id="file-go-mysql-md">
<div id="file-go-mysql-md-readme">
<article itemprop="text">
<p dir="auto">Although GitHub.com is still a Rails monolith, over the past few years we’ve begun the process of extracting critical functionality from our main application, by rewriting some of the code in Go—mostly addressing the pieces that need to run faster and more reliably than what we can accomplish with Ruby. Last year, we deployed a new authorizations service in production, <code>authzd</code>, which powers the “fine-grained authorizations” feature that we announced in GitHub Satellite 2019.</p>
<p dir="auto">This has been a significant milestone and an interesting challenge, because <code>authzd</code> is our first Go service that reads from the production MySQL databases as part of a web request. In the past, we’ve deployed other Go services in our infrastructure that read and write to MySQL, but they’re either internal management services (such as our Search cluster manager, <code>manticore</code>), or async batch jobs (such as <code>gitbackups</code>, which takes care of scheduling Git repository backups). <code>authzd</code> is called several times during a normal request to our Rails monolith, meaning that its requirements for performance and reliability are much more stringent.</p>
<p dir="auto">Adding to this challenge, <code>authzd</code> is deployed to our Kubernetes clusters, where we’ve been experiencing issues with high latencies when opening new TCP connections, something that particularly affects the pooling of connections in the Go MySQL driver. One of the most dangerous lies that programmers tell themselves is that the network is reliable, because, well, most of the time the network <em>is</em> reliable. But when it gets slow or spotty, that’s when things start breaking, and we get to find out the underlying issues in the libraries we take for granted.</p>
<p dir="auto">Here’s what it took, from a MySQL point of view, to get <code>authzd</code> ready to serve all our production traffic while meeting our availability SLOs.</p>
<h2 dir="auto" dir="auto"><a id="user-content-the-crash" aria-hidden="true" href="#the-crash"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>The crash<a href="#" aria-label="&lt;a id=&#34;user-content-the-crash&#34; class=&#34;anchor&#34; aria-hidden=&#34;true&#34; href=&#34;#the-crash&#34;&gt;&lt;svg class=&#34;octicon octicon-link&#34; viewbox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path fill-rule=&#34;evenodd&#34; d=&#34;M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;The crash"></a></h2>
<p dir="auto">For a long time, <code>&#34;Invalid connection (unexpected EOF)&#34;</code> was the most elusive of all known Go MySQL bugs. It’s been over two years since <a href="https://github.com/go-sql-driver/mysql/issues/657" data-hovercard-type="issue" data-hovercard-url="/go-sql-driver/mysql/issues/657/hovercard">I initially diagnosed and reported the bug upstream</a>: we first came across this problem when deploying the initial versions of our repository backup orchestrator (<code>gitbackups</code>) to production.  At the time, there was no consensus on how to fix it on the MySQL driver, so we fixed <code>gitbackups</code> with a workaround in the application’s code. Last year, when doing our first <code>authzd</code> deploys to production, the issue was back in full effect: hundreds of <code>Invalid connection</code> errors per minute were dramatically increasing <code>authzd</code>‘s error response rate. This forced me to address the issue again, and I finally landed a fix upstream that solves the issue without having to change any application code. Let’s dive into the issue and its fix.</p>
<h3 dir="auto" dir="auto"><a id="user-content-fixing-the-issue" aria-hidden="true" href="#fixing-the-issue"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Fixing the issue<a href="#" aria-label="&lt;a id=&#34;user-content-fixing-the-issue&#34; class=&#34;anchor&#34; aria-hidden=&#34;true&#34; href=&#34;#fixing-the-issue&#34;&gt;&lt;svg class=&#34;octicon octicon-link&#34; viewbox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path fill-rule=&#34;evenodd&#34; d=&#34;M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Fixing the issue"></a></h3>
<p dir="auto">The job of a Go SQL driver is to provide a simple primitive to the <code>database/sql</code> package that comes in the Go standard library, a “SQL connection”. The connections that a driver provides are stateful, and cannot be used concurrently, because this is the default behavior for the connections of all major SQL servers (including MySQL and Postgres). This is where the <code>database/sql</code> package comes in: it manages the access and lifetime of these connections. The <code>DB</code> struct in the package, which is the entry point for all operations you can perform on a SQL database, is an abstraction over a connection pool, full of individual connections provided by the driver. Hence, calling methods like <code>(*DB).Query</code> or <code>(*DB).Exec</code> involves quite a bit of complex logic: polling the connection pool for a connection that is active but idle, or calling the underlying Driver to create a new connection if all the existing ones are busy, and then executing the command or query and returning the connection back to the pool, or discarding it if the pool is full.</p>
<p dir="auto">The “unexpected EOF” crash we experienced in both <code>gitbackups</code> and <code>authzd</code> always happens  when taking a connection out of the connection pool and trying to perform a query on it. The reason was obvious simply by reading the MySQL server logs. The server was closing connections that spent too long in Go’s <code>sql.(*DB)</code> pool because they reached their idle timeout. Keep in mind, we run our production MySQL clusters with a pretty aggressive idle timeout  (30s) to ensure we never have too many connections open at any given time. And yet, the fact that this invalid connection error was being reported to the app was puzzling (and a problem, because our service was continuously crashing).</p>
<p dir="auto">It’s common for TCP connections to be interrupted. The <code>database/sql</code> package is designed to handle an interruption in any of the hundreds of simultaneous connections that sit in a <code>(*DB)</code> pool at any time, and the specific driver implementation is supposed to help with this. A driver connection can become unhealthy for a multitude of reasons, whether it’s because it’s been closed, it received a bad packet, or any of the many things that can go wrong with a SQL connection. Whenever a driver detects that a connection has become unhealthy, it’s supposed to return <code>driver.ErrBadConn</code> on the next call to any of the methods in the connection.</p>
<p dir="auto"><code>ErrBadConn</code> is the magic word that signals the <code>database/sql</code> package that this stateful connection is no longer valid. If the connection was in the pool, it needs to be removed from the pool, or if the connection was just pulled from the pool to perform a query, it must be discarded and a new connection must be pulled from the pool (or created) so the query can be performed. With this logic in mind, it’s expected that calling <code>(*DB).Query</code> would never fail with an “invalid connection” error, because even if the library attempted to perform the query in an invalid connection, <code>driver.ErrBadConn</code> would be returned and cause the query to be retried in another connection, transparently, and without the user noticing.</p>
<p dir="auto">So, what’s going on in <code>authzd</code> to cause these “invalid connection” errors?</p>
<p dir="auto">There’s a nuanced mismatch between the TCP protocol and the MySQL wire protocol overlaid on top. A TCP connection is full-duplex, where data can be flowing in each direction independently of the other direction, while the overlaid MySQL protocol on top  becomes fully client-managed once it’s in its Command Phase. A MySQL server only sends a packet to a MySQL client in response to a packet from the client. This becomes an issue when the server closes an active connection in the Command Phase, because it reached its idle timeout, or because connections are actively being pruned by processes such as <code>pt-kill</code>. Let’s look at a network diagram:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/7f0fd5ef088b6b985e237e5ad51fe48407e5bca7f16f9237db2deaea2ad797eb/68747470733a2f2f692e696d6775722e636f6d2f743131434347642e706e67"><img decoding="async" src="https://camo.githubusercontent.com/7f0fd5ef088b6b985e237e5ad51fe48407e5bca7f16f9237db2deaea2ad797eb/68747470733a2f2f692e696d6775722e636f6d2f743131434347642e706e67" alt="" data-canonical-src="https://i.imgur.com/t11CCGd.png" loading="lazy"/></a></p>
<p dir="auto"><em>Figure 1: A network flow diagram representing the packets sent between the Go MySQL driver and the MySQL server.</em></p>
<p dir="auto">In this reproduction of the bug, we can see a standard TCP handshake, followed by a request and response pair at the MySQL level. We then sleep for several seconds. After a while without sending requests to the MySQL server, we reach the server-side timeout and the MySQL server performs an active <code>close</code> to our socket. When a TCP server closes a socket, the server’s kernel sends a <code>[FIN, ACK]</code> pair to the client, which means that the server is finished sending data. The client’s kernel acknowledges the <code>[FIN, ACK]</code> with an <code>[ACK]</code> but it doesn’t close its side of the connection—this is what we mean by TCP being full-duplex. The write side, client -&gt; server,  of the connection is independent, and must be explicitly closed by calling <code>close</code> in the client.</p>
<p dir="auto">In most network protocols on top of TCP, this isn’t an issue. The client is performing <code>read</code>s from the server, and as soon as it receives a <code>[SYN, ACK]</code>, the next read returns an <code>EOF</code> error, because the Kernel knows that the server won’t write more data to this connection. However, as discussed earlier, once a MySQL connection is in its Command Phase, the MySQL protocol is client-managed. The client only reads from the server <em>after</em> it sends a request, because the server only sends data in response to requests from the client.</p>
<p dir="auto">The previous network diagram clearly shows the practical effects of this. After the sleeping period, we send a request to the server and this <code>write</code> succeeds because our side of the connection is still open. The server consequently answers our request with a <code>[RST]</code> packet because <em>it’s</em> actually closed—we just don’t know about it yet. And then, when our client attempts to read the response from the MySQL server, it belatedly finds out that the connection is invalid as it receives an <code>EOF</code> error.</p>
<p dir="auto">This answers why our connection is crashing, but not why our application code is crashing with it. Our MySQL connection is no longer valid, and we found out about it (better late than never), so why doesn’t our MySQL driver return <code>driver.ErrBadConn</code> when this happens? And why doesn’t it allow <code>database/sql</code> to retry our query in a brand new connection? Sadly, because transparently retrying the query is not safe to do in the general case.</p>
<p dir="auto">The sequence of events depicted in the previous network diagram is very frequent. In our production MySQL clusters, it happens thousands of times per minute, particularly during off-peak hours when our service is mostly idle and the timeouts are reached. But that’s far from the only thing that could cause a connection to be closed.</p>
<p dir="auto">What would happen if we performed an <code>UPDATE</code> in a perfectly healthy connection, MySQL executed it, and then our network went down before it could reply to us? The Go MySQL driver would also receive an <code>EOF</code> after a valid write. But if it were to return <code>driver.ErrBadConn</code>, <code>database/sql</code> would run the <code>UPDATE</code> statement on a new connection. Disaster! Data corruption! And what a thoroughly annoying place to be in: we know that in the common case (when MySQL kills our connection), it’s safe to retry these queries. There was no error when writing the query to the network, but we know MySQL didn’t receive it — let alone executed it. But we must assume the worst, that the query <em>did</em> make it to the server. And hence, returning <code>driver.ErrBadConn</code> is not safe.</p>
<p dir="auto">So, how do we go about fixing this? The most obvious solution, and the one we applied on <code>gitbackups</code> back in the day, is calling <code>(*DB).SetConnMaxLifetime</code> on our client to set the max lifetime of MySQL connections to a value lower than our MySQL cluster’s idle timeout. This is far from ideal. For starters, <code>SetConnMaxLifetime</code> sets the <em>maximum duration</em> of any connection on the client, not its <em>maximum idle duration</em>. That means that <code>database/sql</code> will continuously kill connections when they’ve lived that long, even if the connections are being actively used and could not trigger the server’s idle timeout. The <code>database/sql</code> package does not provide a “maximum idle duration” API for databases, because not all SQL servers implement the concept of idle timeouts. Ah, the miseries of abstraction. In practice, this fix works OK except for the needless connection churn, and cases where the MySQL server is actively prunning connections, which this workaround cannot detect.</p>
<p dir="auto">Clearly, the optimal solution would be checking for a connection’s health once it’s pulled from the connection pool, and before we attempt to <code>write</code> any requests to it. This was unfortunately not possible until the introduction of <code><a href="https://golang.org/pkg/database/sql/driver/#SessionResetter" rel="nofollow">SessionResetter</a></code> in Go 1.10: before that interface was available, there was no way to know when a connection was being returned to the pool, which is why the bug stalled for almost 2 years until we could come up with an adequate fix.</p>
<p dir="auto">There are two ways to check the health of that connection: at the MySQL level, or at the TCP level. A MySQL health check involves sending a <code>PING</code> packet and waiting for its response. It’s always safe to return <code>driver.ErrBadConn</code> because the ping packet doesn’t perform write operations in MySQL (one would hope). However, there is the drawback of adding arbitrary latency to the first operation performed on a connection fresh off the pool. That’s a bit spooky, because connections are sent and returned to the pool often in a Go application. Consequently, we went with the cheaper and simpler fix which is to simply check whether the MySQL server has closed its side of the connection at the TCP level.</p>
<p dir="auto">Performing this check is very inexpensive, all we have to do is a non-blocking read on our connection before we attempt any writes. If the server has closed its side of the connection, we’ll get an <code>EOF</code> right away. If the connection is still open, the read also returns immediately but with an <code>EWOULDBLOCK</code> error, signaling that no data exists to be read (yet). Now, the good news is that all sockets in a Go program are already set to non-blocking mode. Don’t be fooled by the elegant abstraction of Goroutines. Under the hood, the user-land Go scheduler uses an async event loop to put Goroutines to sleep and wake them once they have data to read (how quaint). The bad news is that we don’t get to perform non-blocking reads by calling methods such as <code>net.Conn.Read</code>, because the scheduler will put us right to sleep (again, the elegant abstraction of Goroutines). The proper interface to perform this non-blocking read wasn’t introduced until Go 1.9: <code><a href="https://golang.org/pkg/net/#TCPConn.SyscallConn" rel="nofollow">(*TCPConn).SyscallConn</a></code> gives us access to the underlying file descriptor so we can use the <code>read</code> system call directly.</p>
<p dir="auto">Armed with this new API, <a href="https://github.com/go-sql-driver/mysql/pull/934" data-hovercard-type="pull_request" data-hovercard-url="/go-sql-driver/mysql/pull/934/hovercard">I was able to implement a connection health check that solved the “stale connections” issue</a> with less than five microseconds of overhead. A non-blocking read is very quick because, huh, that’s the point of non-blocking reads—they don’t block.</p>
<p dir="auto">After deploying the fix in production, all the “Invalid Connection” needles disappeared right away, resulting in our first “9” of availability for the service.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://i0.wp.com/user-images.githubusercontent.com/42793/57318792-6e3b6800-70fb-11e9-87f7-f9d69e8a3c7b.png?ssl=1"><img decoding="async" src="https://i0.wp.com/user-images.githubusercontent.com/42793/57318792-6e3b6800-70fb-11e9-87f7-f9d69e8a3c7b.png?ssl=1" alt="client needles for Authzd" loading="lazy" data-recalc-dims="1"/></a></p>
<p dir="auto"><em>Figure 2: Client-side needles and retries in <code>authzd</code> after a deploy</em></p>
<h3 dir="auto" dir="auto"><a id="user-content-production-tips" aria-hidden="true" href="#production-tips"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Production tips<a href="#" aria-label="&lt;a id=&#34;user-content-production-tips&#34; class=&#34;anchor&#34; aria-hidden=&#34;true&#34; href=&#34;#production-tips&#34;&gt;&lt;svg class=&#34;octicon octicon-link&#34; viewbox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path fill-rule=&#34;evenodd&#34; d=&#34;M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Production tips"></a></h3>
<ul dir="auto">
<li>
<p dir="auto">If your MySQL server uses idle timeouts, or is actively pruning connections, you don’t need to call <code>(*DB).SetConnMaxLifetime</code> in your production services. It’s no longer needed as the driver can now gracefully detect and retry stale connections. Setting a max lifetime for connections simply causes unnecessary churn by killing and re-opening healthy connections.</p>
</li>
<li>
<p dir="auto">A good pattern to manage high-throughput access to MySQL is configuring your <code>sql.(*DB)</code> pool (<code>(*DB).SetMaxIdleConns</code> and <code>(*DB).SetMaxOpenConns</code>) with values that support your peak-hour traffic for the service, and making sure that your MySQL server is actively pruning idle connections during off-hours. These pruned connections are detected by the MySQL driver and re-created when necessary.</p>
</li>
</ul>
<h2 dir="auto" dir="auto"><a id="user-content-the-timeout" aria-hidden="true" href="#the-timeout"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>The timeout<a href="#" aria-label="&lt;a id=&#34;user-content-the-timeout&#34; class=&#34;anchor&#34; aria-hidden=&#34;true&#34; href=&#34;#the-timeout&#34;&gt;&lt;svg class=&#34;octicon octicon-link&#34; viewbox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path fill-rule=&#34;evenodd&#34; d=&#34;M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;The timeout"></a></h2>
<p dir="auto">When we put a service like <code>authzd</code> as a dependency in the standard request path for our monolith, we’ve fundamentally added its response latency to the response latency of all the requests of our app, or for the requests that perform some kind of authorization—which is a lot of them. It’s crucial to ensure that <code>authzd</code> requests never take more time than what we’ve allotted for them, or they could very easily lead to a site-global performance degradation.</p>
<p dir="auto">From the Rails side, this means being very careful with how we perform RPC requests to the service and how we time them out. In the Go server side, it means one thing, <code>Context</code>. The <code>context</code> package was introduced to the standard library back in Go 1.7, although its API was already available for years as a separate library. Its premise is simple, pass a <code>context.Context</code> to every single function that is involved in the life-cycle of your service’s requests to make your service cancellation-aware. Each incoming HTTP request provides a <code>Context</code> object, which becomes canceled if the client disconnects early, and on top of it you can extend your <code>Context</code> with a deadline. This allows us to manage early request cancellation and request timeouts using a single API.</p>
<p dir="auto">The engineering team in charge of developing the new service did a stellar job of ensuring that all methods in <code>authzd</code> were passing around a <code>Context</code>, including the methods that perform queries to MySQL. Passing a <code>Context</code> to these methods is <em>fundamental</em> because they’re the most expensive part of our request life-cycle, and we need to ensure the <code>database/sql</code> query methods are receiving our request’s <code>Context</code> so they can cancel our MySQL queries early if they’re taking too long.</p>
<p dir="auto">In practice, however, it seemed like <code>authzd</code> wasn’t taking request cancellations or timeouts into account:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://i0.wp.com/user-images.githubusercontent.com/42793/56049594-261e6500-5d4a-11e9-9f26-92fe2734e240.png?ssl=1"><img decoding="async" src="https://i0.wp.com/user-images.githubusercontent.com/42793/56049594-261e6500-5d4a-11e9-9f26-92fe2734e240.png?ssl=1" alt="authzd-timeout" loading="lazy" data-recalc-dims="1"/></a></p>
<p dir="auto"><em>Figure 3: In-service response times for an <code>authzd</code> deployment. The resolver’s timeout was set to 1000ms—you can tell from the helpful red line I’ve drawn in the graph, but definitely not from the many random spikes that climb all the way to 5000ms.</em></p>
<p dir="auto">Just from looking at these metrics, it’s quite clear that even though we’re successfully propagating our request’s <code>Context</code> throughout our application’s code, there’s a point during the lifetime of some requests where cancellation is simply ignored. Finding this spot through code review can be rather laborious, even when we strongly suspect that the source of the timeouts must be the Go MySQL driver, since it’s the only part of our service that performs external requests. In this case, I captured a stack trace from a production host to find out where the code was blocking. It took several tries to capture a stack trace that seemed relevant, but once I had one that was blocking on a <code>QueryContext</code> call, the issue became immediately obvious:</p>
<pre><code>0  0x00000000007704cb in net.(*sysDialer).doDialTCP
    at /usr/local/go/src/net/tcpsock_posix.go:64
 1  0x000000000077041a in net.(*sysDialer).dialTCP
    at /usr/local/go/src/net/tcpsock_posix.go:61
 2  0x00000000007374de in net.(*sysDialer).dialSingle
    at /usr/local/go/src/net/dial.go:571
 3  0x0000000000736d03 in net.(*sysDialer).dialSerial
    at /usr/local/go/src/net/dial.go:539
 4  0x00000000007355ad in net.(*Dialer).DialContext
    at /usr/local/go/src/net/dial.go:417
 5  0x000000000073472c in net.(*Dialer).Dial
    at /usr/local/go/src/net/dial.go:340
 6  0x00000000008fe651 in github.com/github/authzd/vendor/github.com/go-sql-driver/mysql.MySQLDriver.Open
    at /home/vmg/src/gopath/src/github.com/github/authzd/vendor/github.com/go-sql-driver/mysql/driver.go:77
 7  0x000000000091f0ff in github.com/github/authzd/vendor/github.com/go-sql-driver/mysql.(*MySQLDriver).Open
    at &lt;autogenerated&gt;:1
 8  0x0000000000645c60 in database/sql.dsnConnector.Connect
    at /usr/local/go/src/database/sql/sql.go:636
 9  0x000000000065b10d in database/sql.(*dsnConnector).Connect
    at &lt;autogenerated&gt;:1
10  0x000000000064968f in database/sql.(*DB).conn
    at /usr/local/go/src/database/sql/sql.go:1176
11  0x000000000065313e in database/sql.(*Stmt).connStmt
    at /usr/local/go/src/database/sql/sql.go:2409
12  0x0000000000653a44 in database/sql.(*Stmt).QueryContext
    at /usr/local/go/src/database/sql/sql.go:2461
[...]
</code></pre>
<p dir="auto">The issue is that we’re not propagating our request’s <code>Context</code> as deeply as we initially thought. Although we’re passing the <code>Context</code> to <code>QueryContext</code> when performing SQL queries, and this context is being used to actually perform and timeout the SQL queries, there’s a corner case in the <code>database/sql/driver</code> API we’re missing. When we’re trying to perform a query but no connections are available in our connection pool, we need to create a new SQL connection by calling <code><a href="https://golang.org/src/database/sql/driver/driver.go?s=1594:2015#L45" rel="nofollow">driver.Driver.Open()</a></code>, but this interface method doesn’t take a <code>context.Context</code>!</p>
<p dir="auto">The previous stack trace clearly shows how in <code>(8)</code> we stop propagating our <code>Context</code> and simply call <code>(*MysqlDriver).Open()</code> with the DSN to our database. Opening a MySQL connection isn’t a cheap operation: it involves doing a TCP open, SSL negotiation (if we’re using SSL), performing the MySQL handshake and authentication, and setting any default connection options. In total, there are <em>at least</em> six network round trips which do not obey our request timeout, because they’re not <code>Context</code>-aware.</p>
<p dir="auto">What do we do about this? The first thing we tried is setting the <code>timeout</code> value on our connection’s DSN, which configures the TCP open timeout that <code>(*MySQLDriver).Open</code> uses. But this isn’t good enough, because TCP open is just the first step of initializing the connection. The remaining steps (MySQL handshake, etc) weren’t obeying any timeouts, so we still had requests going way past the global 1000ms timeout.</p>
<p dir="auto">The proper fix involved refactoring a large chunk of the Go MySQL driver. The underlying issue was introduced back in the Go 1.8 release, which implemented the <code>QueryContext</code> and <code>ExecContext</code> APIs. Although these APIs could be used to cancel SQL queries because they’re <code>Context</code> aware, the <code>driver.Open</code> method wasn’t updated to actually take a <code>context.Context</code> argument. This new interface was only added two patches later, in Go 1.10: a new <code><a href="https://golang.org/pkg/database/sql/driver/#Connector" rel="nofollow">Connector</a></code> interface was introduced, which had to be implemented <em>separately</em> from the driver itself. Hence, supporting both the old <code>driver.Driver</code> and <code>driver.Connector</code> interfaces required major changes in the structure of any SQL driver. Because of this complexity, and a lack of awareness that the old <code>Driver.Open</code> interface can easily lead to availability issues, the Go MySQL driver never got around to implementing the new interface.</p>
<p dir="auto">Fortunately, I had the time and patience to undertake that refactoring. After <a href="https://github.com/go-sql-driver/mysql/pull/941" data-hovercard-type="pull_request" data-hovercard-url="/go-sql-driver/mysql/pull/941/hovercard">shipping the resulting Go MySQL driver with the new Connector</a> interface in <code>authzd</code>, we could verify on stack traces that the context passed to <code>QueryContext</code> was being propagated when creating new MySQL connections:</p>
<pre><code>0  0x000000000076facb in net.(*sysDialer).doDialTCP
    at /usr/local/go/src/net/tcpsock_posix.go:64
 1  0x000000000076fa1a in net.(*sysDialer).dialTCP
    at /usr/local/go/src/net/tcpsock_posix.go:61
 2  0x0000000000736ade in net.(*sysDialer).dialSingle
    at /usr/local/go/src/net/dial.go:571
 3  0x0000000000736303 in net.(*sysDialer).dialSerial
    at /usr/local/go/src/net/dial.go:539
 4  0x0000000000734bad in net.(*Dialer).DialContext
    at /usr/local/go/src/net/dial.go:417
 5  0x00000000008fdf3e in github.com/github/authzd/vendor/github.com/go-sql-driver/mysql.(*connector).Connect
    at /home/vmg/src/gopath/src/github.com/github/authzd/vendor/github.com/go-sql-driver/mysql/connector.go:43
 6  0x00000000006491ef in database/sql.(*DB).conn
    at /usr/local/go/src/database/sql/sql.go:1176
 7  0x0000000000652c9e in database/sql.(*Stmt).connStmt
    at /usr/local/go/src/database/sql/sql.go:2409
 8  0x00000000006535a4 in database/sql.(*Stmt).QueryContext
    at /usr/local/go/src/database/sql/sql.go:2461
[...]
</code></pre>
<p dir="auto">Note how <code>(*DB).conn</code> now calls our driver’s <code>Connector</code> interface directly, passing the current <code>Context</code>. Likewise, it was very clear that the global request timeout was being obeyed for <em>all</em> requests:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://i0.wp.com/user-images.githubusercontent.com/42793/56049593-2585ce80-5d4a-11e9-9aa1-0245f616b58b.png?ssl=1"><img decoding="async" src="https://i0.wp.com/user-images.githubusercontent.com/42793/56049593-2585ce80-5d4a-11e9-9aa1-0245f616b58b.png?ssl=1" alt="authzd-good" loading="lazy" data-recalc-dims="1"/></a></p>
<p dir="auto"><em>Figure 4: Resolver response times with a timeout set at 90ms. You can tell that the <code>Context</code> is being respected because the 99th percentile looks more like a barcode than a graph</em></p>
<h3 dir="auto" dir="auto"><a id="user-content-production-tips-1" aria-hidden="true" href="#production-tips-1"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Production tips<a href="#" aria-label="&lt;a id=&#34;user-content-production-tips-1&#34; class=&#34;anchor&#34; aria-hidden=&#34;true&#34; href=&#34;#production-tips-1&#34;&gt;&lt;svg class=&#34;octicon octicon-link&#34; viewbox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path fill-rule=&#34;evenodd&#34; d=&#34;M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Production tips"></a></h3>
<ul dir="auto">
<li>
<p dir="auto">You don’t need to change your <code>sql.(*DB)</code> initialization to use the new <code>sql.OpenDB</code> API. Even when calling <code>sql.Open</code> in Go 1.10, the <code>database/sql</code> package detects the <code>Connector</code> interface and new connections are created with <code>Context</code> awareness.</p>
</li>
<li>
<p dir="auto">However, changing your application to use <code>sql.OpenDB</code> with a <code>mysql.NewConnector</code> has several benefits, most notably the fact that the connection options for your MySQL cluster can be configured out of a <code>mysql.Config</code> struct, without requiring to compose a DSN.</p>
</li>
<li>
<p dir="auto">Don’t set a <code>?timeout=</code> (or its <code>mysql.(Config).Timeout</code> equivalent) on your MySQL driver. Having a static value for a dial timeout is a bad idea, because it doesn’t take into account how much of your current request budget has been spent.</p>
</li>
<li>
<p dir="auto">Instead, make sure that every SQL operation in your app is using the <code>QueryContext</code> / <code>ExecContext</code> interfaces, so they can be canceled based on your current request’s <code>Context</code> regardless of whether the connection is failing to dial or the query is slow to execute.</p>
</li>
</ul>
<h2 dir="auto" dir="auto"><a id="user-content-the-race" aria-hidden="true" href="#the-race"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>The race<a href="#" aria-label="&lt;a id=&#34;user-content-the-race&#34; class=&#34;anchor&#34; aria-hidden=&#34;true&#34; href=&#34;#the-race&#34;&gt;&lt;svg class=&#34;octicon octicon-link&#34; viewbox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path fill-rule=&#34;evenodd&#34; d=&#34;M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;The race"></a></h2>
<p dir="auto">Last, here’s a very serious security issue caused from a data race, which is as devious as it is subtle. We’ve talked a lot about how <code>sql.(*DB)</code> is simply a wrapper around a pool of stateful connections, but there’s a detail we haven’t discussed. Performing a SQL query, either via <code>(*DB).Query</code> or <code>(*DB).QueryContext</code>, which is one of the most common operations you can do on a database, actually <em>steals</em> a connection from the pool.</p>
<p dir="auto">Unlike a simple call to <code>(*DB).Exec</code>, which has no actual data returned from the database, <code>(*DB).Query</code> may return one or more rows, and in order to read these rows from our app code, we must take control of the stateful connection where those rows will be written to by the server. That’s the purpose of the <code>sql.(*Rows)</code> struct, which is returned from each call to <code>Query</code> and <code>QueryContext</code>: it wraps a connection we’re borrowing from the pool so we can read the individual <code>Row</code>s from it. And this is why it’s critical to call <code>(*Rows).Close</code> once we’re done processing the results from our query, otherwise the stolen connection never returns to the connection pool.</p>
<p dir="auto">The flow of a normal SQL query with <code>databaseb/sql</code> has been identical since the very first stable release of Go. Something like:</p>
<div dir="auto">
<pre><span>rows</span>, <span>err</span> <span>:=</span> <span>db</span>.<span>Query</span>(<span>&#34;SELECT a, b FROM some_table&#34;</span>)
<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
    <span>return</span> <span>err</span>
}
<span>defer</span> <span>rows</span>.<span>Close</span>()

<span>for</span> <span>rows</span>.<span>Next</span>() {
    <span>var</span> <span>a</span>, <span>b</span> <span>string</span>
    <span>if</span> <span>err</span> <span>:=</span> <span>rows</span>.<span>Scan</span>(<span>&amp;</span><span>a</span>, <span>&amp;</span><span>b</span>); <span>err</span> <span>!=</span> <span>nil</span> {
        <span>return</span> <span>err</span>
    }
    <span>...</span>
}</pre>
</div>
<p dir="auto">That’s straightforward in practice: <code>(*DB).Query</code> returns a <code>sql.(*Rows)</code>, which is stealing a connection from the SQL pool—the connection on which we’ve performed the query. Subsequent calls to <code>(*Rows).Next</code> will read a result row from the connection, whose contents we can extract by calling <code>(*Rows).Scan</code>, until we finally call <code>(*Rows).Close</code> and then any further calls to <code>Next</code> will return <code>false</code> and any calls to <code>Scan</code> will return an error.</p>
<p dir="auto">Under the hood, the implementation involving the underlying driver is more complex: the driver returns <a href="https://golang.org/pkg/database/sql/driver/#Rows" rel="nofollow">its own Rows interface</a>, which is wrapped by <code>sql.(*Rows)</code>. However, as an optimization the driver’s <code>Rows</code> doesn’t have a <code>Scan</code> method, it has a <code>Next(dest []Value) error</code> iterator. The idea behind this iterator is that it returns <code>Value</code> objects for each column in the SQL query, so calling <code>sql.(*Rows).Next</code> simply calls <code>driver.Rows.Next</code> under the hood, keeping a pointer to the values returned by the driver. Then, when the user calls <code>sql.(*Rows).Scan</code>, the standard library converts the driver’s <code>Value</code> objects into the target types that the user passed as arguments to <code>Scan</code>. This means that the driver doesn’t need to perform argument conversion (the Go standard library takes care of it), and that the driver can return <em>borrowed memory</em> from its rows iterator instead of allocating new <code>Value</code>s, since the <code>Scan</code> method converts the memory anyway.</p>
<p dir="auto">As you may guess right away, the security issue we’re dealing with is caused by this <em>borrowed memory</em>. Returning temporary memory is actually an important optimization, which is explicitly encouraged in the driver contract, and works well in practice for MySQL because it lets us return pointers to the connection buffer where we’re reading results directly from MySQL. The row data for a SQL query as it comes off the wire can be passed directly to the <code>Scan</code> method, which will then parse its textual representation into the types (<code>int</code>, <code>bool</code>, <code>string</code>, etc) that the user is expecting. And this has always been safe to do, because we’re not overwriting our connection buffer until the user calls <code>sql.(*Rows).Next</code> again, so no data races are possible.</p>
<p dir="auto">…This was the case, at least, until the introduction of the <code>QueryContext</code> APIs in Go 1.8. With these new interfaces, it’s now possible to call <code>db.QueryContext</code> with a <code>Context</code> object that will interrupt a query early—we’ve discussed this at length in this post. But the fact that a query can be interrupted or timed out while we’re scanning its resulting rows opens up a serious security vulnerability. Any time a SQL query is interrupted while inside a <code>sql.(*Rows).Scan</code> call, the driver overwrites the underlying MySQL connection buffer, and <code>Scan</code> returns corrupted data.</p>
<p dir="auto">This may seem surprising, but it makes sense if we understand that canceling our <code>Context</code> means canceling the SQL query <em>in the client</em>, not in the MySQL server. The MySQL server continues serving the results of the query through our active MySQL connection, so if we want to be able to reuse the connection where a query has been canceled, we must first “drain” all the result packets that the server sent. To drain and discard all the remaining rows in the query, we need to read these packets into our connection buffer, and since query cancellation can happen at the same time as a <code>Scan</code> call, we overwrite the memory behind the <code>Value</code>s the user is scanning from. The result is, with an extremely high likelihood, corrupted data.</p>
<p dir="auto">This race is certainly spooky as described so far, but here’s the scariest thing of it all: in practice, you won’t be able to tell if the race is happening or has happened in your app. In the previous example of <code>rows.Scan</code> usage, despite the fact that we’re performing error checking, there is no reliable way to tell if our SQL query was canceled because our <code>Context</code> expired. If context cancellation has happened <em>inside</em> the <code>rows.Scan</code> call (for example, where it needs to happen for this data race to trigger), the row values are scanned, potentially with corrupted data, but no error is returned because <code>rows.Scan</code> only checks if the rows are closed once <em>when entering the function</em>. Hence, when the race triggers we’re getting back corrupted data without an error return. We won’t be able to tell that the query has been canceled until our <em>next</em> call to <code>rows.Scan</code>, but that call never happens because <code>rows.Next()</code> returns false, again without reporting an error.</p>
<p dir="auto">The only way to tell whether scanning the rows of our SQL query has finished cleanly or whether the query has been canceled early is checking the return value of <code>rows.Close</code>. And we’re not doing that because the rows are being closed in a <code>defer</code> statement. Oof. A <a href="https://github.com/search?p=2&amp;q=rows.Close%28%29&amp;type=Code">quick Code Search for <code>rows.Close()</code></a> on GitHub shows that pretty much <em>nobody</em> is explicitly checking the return value of <code>rows.Close()</code> in their Go code. This was actually safe to do before the <code>QueryContext</code> APIs were introduced, because <code>rows.Scan</code> would always catch any errors, but since Go 1.8, this isn’t  correct. Even after this data race is fixed in the Go MySQL driver, you won’t be able to tell whether you’ve scanned all the rows of your SQL query unless you check the return value of <code>rows.Close()</code>. So update your linters accordingly.</p>
<p dir="auto">I can think of several ways to fix this race. The most obvious is to always clone memory when returning from <code>driver.Rows.Next</code>, but this is also the slowest. The whole point of the driver contract is that the driver doesn’t allocate memory when calling <code>driver.Rows.Next</code>, because the memory allocation is delayed until the user calls <code>sql.(*Rows).Scan</code>. If we allocate in <code>Next</code>, we’re allocating <em>twice</em> for each row, which means that this bug fix would cause a significant performance regression. The Go MySQL maintainers were not OK with this, and I wasn’t either. Other similar approaches such as <a href="https://github.com/go-sql-driver/mysql/pull/904" data-hovercard-type="pull_request" data-hovercard-url="/go-sql-driver/mysql/pull/904/hovercard">truncating the underlying connection buffer when calling <code>sql.(*Rows).Close</code></a> were rejected for the same reason—they potentially allocate memory on each <code>Scan</code>. All these rejected fixes led to a stalemate between the maintainers which caused this critical bug to become stale for over six months. I personally find it terrifying that such a bug can go unfixed for so long, so I had to come up with a hot new take to fix the issue in our production hosts without causing a performance regression.</p>
<p dir="auto">The first thing I attempted was “draining” the MySQL connection without using the underlying connection buffer. If we don’t write to the connection buffer, then the data race won’t occur. This quickly became a nightmare of spaghetti code, because MySQL can send lots of packets which we must drain, and these packets all have different sizes, defined in their headers. Partially parsing these headers without a buffer was not pretty.</p>
<p dir="auto">After some more thought, I finally came up with a solution which was extremely simple and fast enough to be eventually merged upstream—double buffering. In ancient Computer Graphics stacks, one would write individual pixels directly on a frame buffer, and the monitor would simultaneously read the pixels at its given refresh rate. When the frame buffer was being written to while the screen was reading from it, a graphical glitch occurred—what we commonly call <em>flickering</em>. Flickering is fundamentally a data race which you can see with your own eyes, and you’ll agree that’s a pretty cool concept. The most straightforward way to fix flickering in computer graphics is to allocate <em>two</em> frame buffers: one buffer that the screen will be reading from (the front buffer), and another buffer that the graphics processor will be writing to (the back buffer). When the graphics processor is done rendering a frame, we atomically flip the back buffer with the front buffer, so the screen never reads a frame that’s currently being composed.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/7739309b96621b94a7df12b963bd4b927a6e2a45e63a03b7e791f6634959c0b1/68747470733a2f2f692e696d6775722e636f6d2f54744b76625a372e676966"><img decoding="async" src="https://camo.githubusercontent.com/7739309b96621b94a7df12b963bd4b927a6e2a45e63a03b7e791f6634959c0b1/68747470733a2f2f692e696d6775722e636f6d2f54744b76625a372e676966" alt="Nintendo 64 Double-Buffering" data-animated-image="" data-canonical-src="https://i.imgur.com/TtKvbZ7.gif" loading="lazy"/></a></p>
<p dir="auto"><em>Figure 5: Double buffering in the Nintendo 64 graphics stack. If this is good enough for Mario, it’s good enough for the MySQL driver</em></p>
<p dir="auto">This situation sounds a lot like what’s happening with the connection buffer on the MySQL driver, so why not fix it in the same way? In our case, when our <code>driver.Rows</code> struct is being closed because a query was canceled early, we <em>swap</em> our connection buffer with a background buffer, so that the user can still call <code>sql.Rows.Scan</code> on the front buffer while we’re draining the MySQL connection into the back buffer. The next time a SQL query is performed on the same connection, we’re going to continue reading into the background buffer, until the <code>Rows</code> are closed again and we flip the buffers to their original positions. This implementation is trivial, and although it allocates memory, it only does so <em>once</em> for the lifetime of a MySQL connection, so the allocation is easily amortized. We further optimized this corner case by delaying the allocation of the back buffer until the first time we need to drain data into it. In the common case where no queries are canceled early in a MySQL connection, no extra allocations are performed.</p>
<p dir="auto">After <a href="https://github.com/go-sql-driver/mysql/pull/945#issuecomment-479532346" data-hovercard-type="pull_request" data-hovercard-url="/go-sql-driver/mysql/pull/945/hovercard">carefully crafting some benchmarks</a> to ensure that the double buffering approach wasn’t causing performance regressions in any cases, I finally <a href="https://github.com/go-sql-driver/mysql/pull/943" data-hovercard-type="pull_request" data-hovercard-url="/go-sql-driver/mysql/pull/943/hovercard">landed the bug fix upstream</a>. Unfortunately, we have no way to check how often we’ve performed corrupted reads in the past because of this bug, but it’s probably been <em>quite a few</em> because, despite the subtlety in its origin, it’s surprisingly easy to trigger.</p>
<h3 dir="auto" dir="auto"><a id="user-content-production-tips-2" aria-hidden="true" href="#production-tips-2"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Production tips<a href="#" aria-label="&lt;a id=&#34;user-content-production-tips-2&#34; class=&#34;anchor&#34; aria-hidden=&#34;true&#34; href=&#34;#production-tips-2&#34;&gt;&lt;svg class=&#34;octicon octicon-link&#34; viewbox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path fill-rule=&#34;evenodd&#34; d=&#34;M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Production tips"></a></h3>
<ul dir="auto">
<li>
<p dir="auto">Always do an explicit check in for the error return in <code>(*Rows).Close</code>. It’s the only way to detect whether the SQL query has been interrupted during scanning. However, do not remove the <code>defer rows.Close()</code> call in your app, as it’s the only way the <code>Rows</code> get closed if a <code>panic</code> or early return happens during your scanning. Calling <code>(*Rows).Close</code> several times is always safe.</p>
</li>
<li>
<p dir="auto">Never use <code>(*Rows).Scan</code> with a <code>sql.RawBytes</code> target. Even though the Go MySQL driver is now much more resilient, accessing <code>RawBytes</code> can and will fail with other SQL drivers if your query is cancelled early. You will, most likely, read invalid data if that happens. The only difference between scanning into <code>[]byte</code> and <code>sql.RawBytes</code> is that the raw version won’t allocate extra memory. This tiny optimization isn’t worth the potential data race in a <code>Context</code>-aware application.</p>
</li>
</ul>
<h2 dir="auto" dir="auto"><a id="user-content-wrapping-up" aria-hidden="true" href="#wrapping-up"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Wrapping up<a href="#" aria-label="&lt;a id=&#34;user-content-wrapping-up&#34; class=&#34;anchor&#34; aria-hidden=&#34;true&#34; href=&#34;#wrapping-up&#34;&gt;&lt;svg class=&#34;octicon octicon-link&#34; viewbox=&#34;0 0 16 16&#34; version=&#34;1.1&#34; width=&#34;16&#34; height=&#34;16&#34; aria-hidden=&#34;true&#34;&gt;&lt;path fill-rule=&#34;evenodd&#34; d=&#34;M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z&#34;&gt;&lt;/path&gt;&lt;/svg&gt;&lt;/a&gt;Wrapping up"></a></h2>
<p dir="auto">Deploying code in a new programming language to production is always a challenge, particularly at the scale GitHub operates. The throughput and complexity of our MySQL usage patterns means we’ve spent many years tweaking our MySQL client for Ruby, and now we’re excited to do the same for the Go MySQL driver. The fixes we’ve upstreamed as part of our first Go deployment are now generally available as part of the <a href="https://github.com/go-sql-driver/mysql/releases/tag/v1.5.0">1.5.0 release</a> of the Go MySQL driver, and we will continue to contribute more fixes and functionality to the driver as we expand our production usage of Go.</p>
<p dir="auto">Thanks to the Go MySQL maintainers, <a href="https://github.com/methane">@methane</a> and <a href="https://github.com/julienschmidt">@julienschmidt</a>, for their help reviewing and landing these patches!</p>
</article></div>
</div>
</div></div></div>
  </body>
</html>
