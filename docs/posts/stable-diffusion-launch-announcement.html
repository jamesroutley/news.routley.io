<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://stability.ai/blog/stable-diffusion-announcement">Original</a>
    <h1>Stable Diffusion launch announcement</h1>
    
    <div id="readability-page-1" class="page"><div data-block-type="2" id="block-38add23192644959dd22"><div><p>Stability AI and our collaborators are proud to announce the first stage of release of Stable Diffusion to researchers via <a href="https://stability.ai/academia-access-form"><span>this form</span></a>, the model weights are hosted by our friends at Hugging Face once you get access. <a href="https://github.com/CompVis/stable-diffusion"><span>The code is available here</span></a> and the <a href="https://huggingface.co/CompVis/stable-diffusion">model card here</a>. We are working together towards a public release soon. </p><p>This has been led by Patrick Esser from <a href="https://runwayml.com/"><span>Runway</span></a> and Robin Rombach from the <a href="https://hci.iwr.uni-heidelberg.de/compvis"><span>CompVis</span></a> lab at Heidelberg University (now the <a href="https://ommer-lab.com"><span>Machine Vision &amp; Learning research group at LMU</span></a>), combined with support from communities at <a href="https://eleuther.ai"><span>Eleuther AI</span></a>, <a href="https://laion.ai/"><span>LAION</span></a> and our own generative AI team.</p><p>Stable Diffusion is a text-to-image model that will empower billions of people to create stunning art within seconds. It is a breakthrough in speed and quality meaning that it can run on consumer GPUs. You can see some of the amazing output that has been created by this model without pre or post-processing on this page.</p><p>The model itself builds upon the work of the team at CompVis and Runway in their widely used <a href="https://research.runwayml.com/high-resolution-image-synthesis-with-latent-diffusion-models"><span>latent diffusion model</span></a> combined with insights from the conditional diffusion models by our lead generative AI developer <a href="https://twitter.com/RiversHaveWings"><span>Katherine Crowson</span></a>, <a href="https://openai.com/dall-e-2/"><span>Dall-E 2</span></a> by <a href="https://openai.com"><span>Open AI</span></a>, <a href="https://imagen.research.google/"><span>Imagen</span></a> by <a href="https://research.google/teams/brain/"><span>Google Brain</span></a> and many others. We are delighted that AI media generation is a cooperative field and hope it can continue this way to bring the gift of creativity to all. </p>
</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1660143897519_3711"><div><p>The core dataset was trained on LAION-Aesthetics, a soon to be released subset of <a href="https://laion.ai/blog/laion-5b/"><span>LAION 5B</span></a>. LAION-Aesthetics was created with a new CLIP-based model that filtered LAION-5B based on how “beautiful” an image was, building on ratings from the alpha testers of stable diffusion. LAION-Aesthetics will be released with other subsets in the coming days on <a href="https://laion.ai"><span>https://laion.ai</span></a>.</p><p>Stable diffusion runs on under 10 GB of VRAM on consumer GPUs, generating images at 512x512 pixels in a few seconds. This will allow both researchers and soon the public to run this under a range of conditions, democratizing image generation. We look forward to the open ecosystem that will emerge around this and further models to truly explore the boundaries of latent space.</p><p>The model was trained on our 4,000 A100 Ezra-1 AI ultracluster over the last month as the first of a series of models exploring this and other approaches.</p><p>We have been testing the model at scale with over 10,000 beta testers that are creating 1.7 million images a day. </p>
</div></div><div data-block-type="2" id="block-yui_3_17_2_1_1660144070491_4802"><div><p>This output has given us numerous insights as we prepare for a public release soon. This will provide the template for the release of many open models we are currently training to unlock human potential. We will also be releasing open synthetic datasets based on this output for further research.</p><p>We aim to set new standards of collaboration and reproducibility for the models that we create and support and will share our learnings in the coming weeks. </p><p>We hope to progressively increase the number of collaborators for our benchmark models. If you would like to help, please join one of the communities we support and/or reach out to <a href="https://stability.ai/cdn-cgi/l/email-protection#cba2a5ada48bb8bfaaa9a7a2bfb2e5aaa2"><span><span data-cfemail="b2dbdcd4ddf2c1c6d3d0dbdedbc6cb9cd3db">[email protected]</span></span></a></p><p>Some comments by various folks:</p><p>“EleutherAI has spent the past two years advancing open source large-scale AI research. We are thrilled to be working with and supporting like-minded researchers to enable scientific access to these emerging technologies” - Stella Biderman, Lead Researcher at EleutherAI</p><p>&#34;With this project we continue to pursue our mission to make state of the art machine learning accessible for people from all over the world. 100% open. 100% free.&#34; - Christoph,  Organizational Lead &amp; researcher at LAION e.V.</p><p>“We are excited to see what will be built with the current models as well as to see what further works will be coming out of open, collaborative research efforts!” -</p><p>&#34;We&#39;re excited that state of the art text-to-image models are being built openly and we are happy to collaborate with CompVis and Stability.ai towards safely and ethically release the models to the public and help democratize ML capabilities with the whole community&#34; - Apolinário, ML Art Engineer, Hugging Face </p><p>“We are delighted to release the first in a series of benchmark open source Stable Diffusion models that will enable billions to be more creative, happy and communicative. This model builds on the work of many excellent researchers and we look forward to the positive effect of this and similar models on society and science in the coming years as they are used by billions worldwide”. - Emad, CEO, Stability AI</p><p>p.s. &#34;GPUs go brrr.&#34; - Robin</p>
</div></div></div>
  </body>
</html>
