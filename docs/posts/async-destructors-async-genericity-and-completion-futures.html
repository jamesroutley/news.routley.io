<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://sabrinajewson.org/blog/async-drop">Original</a>
    <h1>Async destructors, async genericity and completion futures</h1>
    
    <div id="readability-page-1" class="page"><div><p id="published"><time datetime="2022-03-24">2022-03-24</time></p><nav><ul><li><a href="#why-async-destructors">Why async destructors?</a></li><li><a href="#async-drop-after-future-cancellation">Async drop after future cancellation</a></li><li><a href="#hidden-awaits">Hidden awaits</a><ul><li><a href="#abort-now">“Abort now” designs</a></li><li><a href="#never-abort">“Never abort” designs</a></li><li><a href="#delayed-abort">“Delayed abort” designs</a></li></ul></li><li><a href="#async-drop-in-a-sync-function">Async drop in a sync function</a></li><li><a href="#panic-checks">Panic checks</a></li><li><a href="#unwinding-in-async">Unwinding in async</a></li><li><a href="#poll-drop-ready"><code>poll_drop_ready</code></a></li><li><a href="#function-implicit-bounds">Function implicit bounds</a></li><li><a href="#drop-supertrait">Drop supertrait</a></li><li><a href="#async-genericity">Async genericity</a></li><li><a href="#inspiration-from-const">Inspiration from <code>const</code></a></li><li><a href="#relaxed-drop-bounds">Relaxed drop bounds</a></li><li><a href="#synchronous-opt-out">Synchronous opt-out</a></li><li><a href="#async-traits-and-backwards-compatibility">Async traits and backwards compatibility</a></li><li><a href="#trait-impl-implicit-bounds">Trait impl implicit bounds</a></li><li><a href="#async-closures">Async closures</a></li><li><a href="#conclusion">Conclusion</a></li><li><a href="#completion-futures">Appendix A: Completion futures</a></li><li><a href="#weakly-async-functions">Appendix B: Weakly async functions</a></li><li><a href="#linear-types">Appendix C: Linear types</a></li><li><a href="#uncancellable-futures">Appendix D: Uncancellable futures</a></li></ul></nav><p>The main focus of this article will be on attempting to design a system to support asynchronous destructors in the Rust programming language, figuring the exact semantics of them and resolving any issues encountered along the way. By side effect, it also designs a language feature called “async genericity” which enables supporting blocking and asynchronous code with the same codebase, as well as designing a system for completion-guaranteed futures to be added to the language.</p><h2 id="why-async-destructors"><a href="#why-async-destructors"></a>Why async destructors?</h2><p>Async destructors, at a high level, would allow types to run code with <code>.await</code>s inside it when they are dropped. This enables cleanup code to actually perform I/O, giving much more freedom in the extent to which resources can be properly cleaned up. One notable use case for this is implementing the TLS protocol, in which:</p><blockquote><pre><code>Each party MUST send a &#34;close_notify&#34; alert before closing its write
side of the connection, unless it has already sent some error alert.
</code></pre></blockquote><p>(<a href="https://datatracker.ietf.org/doc/html/rfc8446#section-6.1">RFC 8446</a>). In order to make sure that this requirement is consistently fulfilled, TLS implementations should be able to send this alert when the <code>TlsStream</code> type is dropped - and if all I/O is done asynchronously, this requires asynchronous destructors.</p><p>Currently, this kind of cleanup is generally managed by methods like <a href="https://docs.rs/tokio/1/tokio/io/trait.AsyncWrite.html#tymethod.poll_shutdown"><code>poll_shutdown</code></a> and <a href="https://docs.rs/futures-io/0.3/futures_io/trait.AsyncWrite.html#tymethod.poll_close"><code>poll_close</code></a>: asynchronous functions that can optionally be called by the user if they want the type to be cleanly disposed of. However, this approach has several limitations:</p><ul><li>There is no way to statically guarantee that the method isn’t called twice, that’s up to the user.</li><li>There is no way to statically guarantee that the method is called at all - it can be very easy to forget.</li><li>Calling it at the lifecycle end of each value is cumbersome boilerplate, and would ideally not be necessary.</li><li>It only works on types that actually implement <code>AsyncWrite</code>. If your type is not actually a byte stream, too bad.</li></ul><p>Clearly we need a better solution than this. So let’s look at some practical examples to work out what features we’d need to improve the situation.</p><h2 id="async-drop-after-future-cancellation"><a href="#async-drop-after-future-cancellation"></a>Async drop after future cancellation</h2><p>Let’s start simple, with this trivial function:</p><pre><code><span>async <span><span><span>fn</span> </span><span>wait_then_drop_stream</span></span><span><span><span>(</span><span>_stream</span><span>:</span> TlsStream</span><span><span><span>)</span></span></span></span><span> </span><span><span><span>{</span>
	<span>time<span>::</span></span>sleep<span><span>(</span><span>Duration<span>::</span></span>from_secs<span><span>(</span><span>10</span></span><span><span>)</span></span></span><span><span>)</span></span>.await<span>;</span>
</span><span><span>}</span></span></span>
</span></code></pre><p>It’s an asynchronous function that takes ownership of a <code>TlsStream</code>, sleeps for 10 seconds, then implicitly drops it at the end. The most obvious characteristic we want of this function is that the TLS stream should perform graceful <code>close_notify</code> shutdown after the 10 seconds. However there’s also a slightly more subtle but equally important one: because in Rust every future is implicitly made cancellable at <code>.await</code> points, the same graceful shutdown should also happen if the future is cancelled. For example, suppose the function is used like this:</p><pre><code><span><span>let</span> handle <span>=</span> <span>task<span>::</span></span>spawn<span><span>(</span><span>wait_then_drop_stream</span><span><span>(</span>some_tls_stream</span><span><span>)</span></span></span><span><span>)</span></span><span>;</span>
<span>time<span>::</span></span>sleep<span><span>(</span><span>Duration<span>::</span></span>from_secs<span><span>(</span><span>5</span></span><span><span>)</span></span></span><span><span>)</span></span>.await<span>;</span>
handle.<span>cancel</span><span><span>(</span></span><span><span>)</span></span><span>;</span>
</span></code></pre><p>Just because we cancel the task overall doesn’t mean we suddenly want to sidestep the regular graceful shutdown and have the TLS stream finish in an unclean manner - in fact, we almost never want that. So somehow we need a way to register async operations to occur after a future is cancelled, in order to support running the graceful shutdown code in there. How do we do that?</p><p>As it turns out, with async destructors in the language that becomes quite easy: since future cancellation is signalled to the future is via calling its destructor, the future can simply itself have an async destructor and run the cleanup code in there. The precise semantics of this would work in a very similar way to how synchronous destruction works today: drop each of the local variables in reverse order (and this critically includes the <code>_stream</code> variable).</p><p>A second question we have to answer is what happens when async destruction <em>itself</em> is cancelled - for example, you might be in the middle of dropping a TLS stream, but at the same time your task suddenly gets aborted. To demonstrate this problem, take a look at this function:</p><pre><code><span>async <span><span><span>fn</span> </span><span>assign_stream</span></span><span><span><span>(</span><span>target</span><span>:</span> <span>&amp;</span><span>mut</span> TlsStream, <span>source</span><span>:</span> TlsStream</span><span><span><span>)</span></span></span></span><span> </span><span><span><span>{</span>
	<span>*</span>target <span>=</span> source<span>;</span> 	<span>println!</span><span><span>(</span></span><span><span><span>&#34;</span>1<span>&#34;</span></span></span><span><span>)</span></span><span>;</span>
	async <span><span>{</span> <span>println!</span><span><span>(</span></span><span><span><span>&#34;</span>2<span>&#34;</span></span></span><span><span>)</span></span> </span><span><span>}</span></span>.await<span>;</span>
	<span>println!</span><span><span>(</span></span><span><span><span>&#34;</span>3<span>&#34;</span></span></span><span><span>)</span></span><span>;</span>
	<span>yield_now</span><span><span>(</span></span><span><span>)</span></span>.await<span>;</span>
	<span>println!</span><span><span>(</span></span><span><span><span>&#34;</span>4<span>&#34;</span></span></span><span><span>)</span></span><span>;</span>
</span><span><span>}</span></span></span>
</span></code></pre><p>It assigns the <code>source</code> TLS stream to the <code>target</code> TLS stream (dropping the old <code>source</code> stream in the process), then prints out numbers 1 to 4. Under normal circumstances, this task would just run from top to bottom and always print out every number; but when cancellation gets involved, things become more complicated. If cancellation were to happen during the assignment of <code>source</code> to <code>target</code>, the language now has to decide what to do with the rest of the code - should it run it to the end? Should it immediately exit? Should it run only <em>some</em> of it?</p><p>There are three main categories of option worth talking about here: “abort now” designs, “never abort” designs and “delayed abort” designs. Each one has both advantages and drawbacks, which are explored in detail below.</p><h3 id="abort-now"><a href="#abort-now"></a>“Abort now” designs</h3><p>Under these designs, none of the four prints in the code above are guaranteed to run - if the assignment is aborted, it will exit the future as soon as possible while performing the minimum amount of cleanup (i.e. just running destructors and nothing else).</p><p>There are three variants of this design, differing slightly in when they require <code>.await</code> to be specified:</p><ol><li><p>Sometimes await: Under this design, <code>=</code> is kept to never require an <code>.await</code> and async function calls are kept to always require an <code>.await</code>. This mostly keeps things the same way as they are: no special new syntax is introduced, and no major breaking changes are made.</p><p>To get a feel for how this looks, here is a non-trivial “real world” async function implemented using it:</p><pre><code><span>async <span><span><span>fn</span> </span><span>handle_stream</span></span><span><span><span>(</span><span>mut</span> <span>stream</span><span>:</span> TlsStream</span><span><span><span>)</span></span></span></span><span> <span><span>-&gt;</span> <span>Result<span>&lt;</span><span>(</span><span>)</span><span>&gt;</span></span></span> </span><span><span><span>{</span>
	<span>loop</span> <span><span>{</span>
		<span>match</span> <span>read_message</span><span><span>(</span><span>&amp;</span><span>mut</span> stream</span><span><span>)</span></span>.await<span>?</span> <span><span>{</span>
			<span>Message<span>::</span></span>Redirect<span><span>(</span>address</span><span><span>)</span></span> <span>=&gt;</span> <span><span>{</span>
				stream <span>=</span> <span>connect</span><span><span>(</span>address</span><span><span>)</span></span>.await<span>?</span><span>;</span>
																<span>log<span>::</span></span>info<span>!</span><span><span>(</span><span><span>&#34;</span>Redirected<span>&#34;</span></span></span><span><span>)</span></span><span>;</span>
			</span><span><span>}</span></span>
			<span>Message<span>::</span></span>Exit <span>=&gt;</span> <span>break</span><span>,</span>
		</span><span><span>}</span></span>
	</span><span><span>}</span></span>
</span><span><span>}</span></span></span>
</span></code></pre><p>It does introduce a footgun as it will no longer be obvious at which points control flow can exit a function. It can also be considered inconsistent as some suspend points require an <code>.await</code> while others don’t, despite the fact that there is no meaningful semantic difference between the two kinds.</p></li><li><p>Never await: To resolve that inconsistency, this design removes <code>.await</code>s altogether, making all cancellation points completely invisible. Adapting our example from before, it would look like:</p><pre><code><span>async <span><span><span>fn</span> </span><span>handle_stream</span></span><span><span><span>(</span><span>mut</span> <span>stream</span><span>:</span> TlsStream</span><span><span><span>)</span></span></span></span><span> <span><span>-&gt;</span> <span>Result<span>&lt;</span><span>(</span><span>)</span><span>&gt;</span></span></span> </span><span><span><span>{</span>
	<span>loop</span> <span><span>{</span>
		<span>match</span> <span>read_message</span><span><span>(</span><span>&amp;</span><span>mut</span> stream</span><span><span>)</span></span><span>?</span> <span><span>{</span>
			<span>Message<span>::</span></span>Redirect<span><span>(</span>address</span><span><span>)</span></span> <span>=&gt;</span> <span><span>{</span>
				stream <span>=</span> <span>connect</span><span><span>(</span>address</span><span><span>)</span></span><span>?</span><span>;</span>
				<span>log<span>::</span></span>info<span>!</span><span><span>(</span><span><span>&#34;</span>Redirected<span>&#34;</span></span></span><span><span>)</span></span><span>;</span>
			</span><span><span>}</span></span>
			<span>Message<span>::</span></span>Exit <span>=&gt;</span> <span>break</span><span>,</span>
		</span><span><span>}</span></span>
	</span><span><span>}</span></span>
</span><span><span>}</span></span></span>
</span></code></pre><p>Aside from the technical issues of removing <code>.await</code> (is it done recursively? does it make implementing <code>Future</code> a breaking change? are async blocks made redundant? et cetera) and the backwards compatibility/churn issue, this has the same footgun issue as the previous option but turned up to the extreme - it would now be basically impossible to carefully manage where cancellations can occur and most users would end up having to treat cancellation more as a <code>pthread_kill</code> than a helpful control flow construct.</p></li><li><p>Always await: On the flip side, this design makes <code>.await</code>s mandatory everywhere. Assignments to a value with an asynchronous destructor must be done with a new <code>=.await</code> operator instead of plain <code>=</code>, and values cannot implicitly fall out of scope but must instead be explicitly <code>drop</code>ped by the user. Once again returning to the <code>handle_stream</code> example:</p><pre><code><span>async <span><span><span>fn</span> </span><span>handle_stream</span></span><span><span><span>(</span><span>mut</span> <span>stream</span><span>:</span> TlsStream</span><span><span><span>)</span></span></span></span><span> <span><span>-&gt;</span> <span>Result<span>&lt;</span><span>(</span><span>)</span><span>&gt;</span></span></span> </span><span><span><span>{</span>
	<span>loop</span> <span><span>{</span>
		<span>match</span> <span>read_message</span><span><span>(</span><span>&amp;</span><span>mut</span> stream</span><span><span>)</span></span>.await<span>?</span> <span><span>{</span>
			<span>Message<span>::</span></span>Redirect<span><span>(</span>address</span><span><span>)</span></span> <span>=&gt;</span> <span><span>{</span>
				stream <span>=</span>.await <span>connect</span><span><span>(</span>address</span><span><span>)</span></span>.await<span>?</span><span>;</span>
				<span>log<span>::</span></span>info<span>!</span><span><span>(</span><span><span>&#34;</span>Redirected<span>&#34;</span></span></span><span><span>)</span></span><span>;</span>
			</span><span><span>}</span></span>
			<span>Message<span>::</span></span>Exit <span>=&gt;</span> <span>break</span><span>,</span>
		</span><span><span>}</span></span>
	</span><span><span>}</span></span>
	<span>drop</span><span><span>(</span>stream</span><span><span>)</span></span>.await<span>;</span>
</span><span><span>}</span></span></span>
</span></code></pre><p>This is the only option of the three to definitively avoid the “implicit cancel” footgun, but it’s still not ideal as it ends up introducing new weird-looking syntax and makes writing async code pretty verbose.</p></li></ol><p>All three of these variants end up with pretty significant drawbacks - fundamentally, it’s pretty incompatible with the current async syntax and model. So if aborting is so tricky to support, what if we could sidestep the problem by avoiding it altogether?</p><h3 id="never-abort"><a href="#never-abort"></a>“Never abort” designs</h3><p>This design category eliminates implicit cancellation entirely from the language. Futures would, much like synchronous functions, run from linearly top to bottom without the possibility of caller-induced early exit (of course, panics can still cause early exit to happen). This means that all of <code>1</code>, <code>2</code>, <code>3</code> <em>and</em> <code>4</code> are guaranteed to be printed in the <code>assign_stream</code> function shown at the start of this section, since at no point is code execution ever allowed to stop. <a href="https://carllerche.netlify.app/2021/06/17/six-ways-to-make-async-rust-easier/">This approach has been proposed by Carl Lerche previously</a>, if you want to read more about it.</p><p>Much like the “abort now” category, it has three sub-designs, “always await”, “sometimes await” and “never await” depending on where <code>.await</code> is deemed to be necessary. Much of the same arguments listed up there apply, although there is no longer the issue of the footgun caused by potential cancellation points being implicit so it is mostly a question of weighing up consistency, breakage and new syntax.</p><p>This is another highly consistent approach, however it comes with the major downside of throwing away the very useful tool that is implicit cancellation contexts. While it is definitely possible for cancellation to be implemented as a library feature (see <a href="https://docs.rs/tokio-util/0.7/tokio_util/sync/struct.CancellationToken.html"><code>CancellationToken</code></a> and <a href="https://docs.rs/stop-token/0.7/stop_token/struct.StopToken.html"><code>StopToken</code></a>) and I want that to be an option for use cases that need it, most of the time having an implicit context is far more useful since it is less verbose and requires much less boilerplate to make use of. I would hate to see otherwise infallible functions become fallible, or an enormous migration effort to add cancellation token parameters to every function.</p><p>One argument Carl Lerche used to support his point was an example code snippet in which future cancellation combined with <code>select!</code> turned out to be a footgun. But as Yoshua Wuyts argued in <a href="https://blog.yoshuawuyts.com/futures-concurrency-3/">Futures Concurrency III</a>, the primary problem in code like that is the confusing semantics of <code>select!</code> and not the cancellation behaviour of futures. Ultimately, I do not believe cancellation to be problematic enough to warrant removing it from the language. Although this approach’s consistency and its parallel with blocking code is nice, cancellation is still useful and there are ways to combine it with async destructors that don’t introduce footguns.</p><p>Note that even with the other options, adding async destructors to the language would make it trivial to create a combinator that executes futures in a “no-cancellation” mode if such semantics are desired - see <a href="#uncancellable-futures">appendix D</a> for more.</p><h3 id="delayed-abort"><a href="#delayed-abort"></a>“Delayed abort” designs</h3><p>Unlike the previous two designs, these approaches try to fully embrace the syntactical difference between assigning and falling out of scope, which don’t require an <code>.await</code>, and calling an async function, which does. When the caller attempts to cancel the future during one of the former operations, the future will actually continue to run for a short while afterwards until it is able to reach one of the latter operations and properly exit.</p><p>This immediately solves the main set of problems that plagued the “abort now” designs without going to the extreme that never-abort did: there is no footgun as cancellation points are never implicitly introduced, no new syntax is added and no major breaking changes are made, and there is now a definite reason <em>why</em> <code>=</code> doesn’t need <code>.await</code> but calling functions does.</p><p>However, it is not perfect. It effectively introduces two different kinds of suspend point which behave pretty differently, an inconsistency not present with “abort now” and “never abort” designs. Additionally, it means that if you call a wrapper function around the <code>=</code> operator or call <code>drop</code> manually, it has subtly different semantics from using the built-in language behaviour since it changes what kind of suspend point it is. This is probably unexpected and unintuitive for most users.</p><p>There are three variations of this design, depending on when the code stops running:</p><ol><li>Abort before first await: Code will continue to run after cancellation of an operation like <code>=</code> until the next point at which <code>.await</code> occurs, at which point the outer future will promptly exit without even polling the inner future once. In the <code>assign_stream</code> example, that means that <code>1</code> is guaranteed to be printed, but everything after that isn’t.</li><li>Abort after first await: As with the previous one, but the future will be polled once (only to have its result discarded and the outer future to exit). In our example, that means <code>1</code> and <code>2</code> are guranteed to be printed, but not anything beyond that.</li><li>Abort at first suspend: The outer future will abort the first time a future which it <code>.await</code>s returns <code>Poll::Pending</code> when it is polled. In the example code, this will force all of <code>1</code>, <code>2</code> and <code>3</code> to be printed, but not <code>4</code> since <code><span><span>yield_now</span><span><span>(</span></span><span><span>)</span></span></span></code> causes a suspend point to occur. This is the most similar to how future cancellation works today, because cancellation cannot currently appear to happen without a suspend point (it still can’t with the above proposals, but it appears to because <code>async {}.await</code> potentially exits control flow). From the future’s perspective, this behaves is exactly as if the caller had just waited and then attempted cancellation later on.</li></ol><p>Although they might seem very similar, with the first two approaches an extremely subtle but very important paradigm shift is made: <code>.await</code> changes its meaning from being a “might suspend” operator to a “might halt” or “might abort” operator, since <code>async {}.await;</code> is now able to cause computation to suddenly stop. This is a small difference, but ends up very problematic as we now have to answer a whole host of new questions:</p><ul><li>If <code>.await</code> is just about cancellation, should we allow omitting it to call async functions while forbidding cancellation?</li><li>Should we allow calling <em>synchronous</em> functions with <code>.await</code> to introduce cancellation points around them?</li><li>Should we introduce plain <code>await;</code> statements to introduce those cancellation points, equivalent to <code>async {}.await;</code>?</li></ul><p>Phrased another way, we open ourselves up to this table existing whose empty boxes will come across as obvious holes:</p><table><thead><tr><th></th><th>Caller can’t cancel</th><th>Caller can cancel</th></tr></thead><tbody><tr><td><strong>Callee can’t cancel</strong></td><td><code>foo()</code></td><td>?</td></tr><tr><td><strong>Callee can cancel</strong></td><td>?</td><td><code>foo().await</code></td></tr></tbody></table><p>I don’t think that’s a situation we want to be in. The third approach avoids the whole situation altogether by tying abort opportunities to suspend points, removing the need for the second column in that table and thus closing those holes.</p><p>Additionally, the third variant is less of a breaking change because code that previously relied on the immediately-completing parts of an <code>async</code> operation not being able to abort won’t have to adjust their expectations. Technically it’s still non-breaking either way because no existing code uses asynchronous destructors, but it allows programmers to keep their mental model which is important too.</p><p>Because of all these reasons, I am in favour using a delayed abort design with abort-at-first-suspend: it would require little migration effort, avoids footguns and I don’t think is too surprising for users. The rest of this post will be written assuming that design is chosen.</p><h2 id="async-drop-in-a-sync-function"><a href="#async-drop-in-a-sync-function"></a>Async drop in a sync function</h2><p>Perhaps the hardest problem any async drop design has to face is what happens when a type with an async destructor gets dropped in a synchronous context. Consider this code:</p><pre><code><span><span><span><span>fn</span> </span><span>sync_drop_stream</span></span><span><span><span>(</span><span>_stream</span><span>:</span> TlsStream</span><span><span><span>)</span></span></span></span><span> </span><span><span><span>{</span></span><span><span>}</span></span></span>
</span></code></pre><p>The synchronous function declared takes a TLS stream as a parameter. It must do something with the stream it has been given since it has ownership and there’s no return value to pass it back to the caller, but it can’t use a regular asynchronous drop because it is a synchronous function. So what can it do? In <a href="https://without.boats/blog/poll-drop/#the-non-async-drop-problem">withoutboats’ post on this subject</a> they hypothesized two options:</p><blockquote><ol><li>Call it’s non-async destructor, like every other type.</li><li>Introduce some kind of executor to the runtime (probably just <code>block_on</code>) to call as part of the drop glue.</li></ol></blockquote><p>To me, both solutions seem pretty bad. Solution 2 is obviously unworkable for the reasons Boats’ outlined, but I believe solution 1 is far more of a footgun than it appears. Many many functions from the standard library become essentially off-limits, so not only do you not get their ergonomics in well-written code it would be very easy to create bug-ridden code too, simply by calling any function like <a href="https://doc.rust-lang.org/stable/std/option/enum.Option.html#method.insert"><code>Option::insert</code></a> on a TLS stream.</p><p>My alternative solution is to forbid that code from compiling entirely. For a type to be dropped in a synchronous context it must implement a certain trait, and this just wouldn’t be implemented for <code>TlsStream</code> and similar types. Therefore, barring using of an explicit <code>close_unclean</code> method on <code>TlsStream</code>, it becomes totally impossible to cause an unclean TLS close from anywhere, eliminating an entire category of bugs.</p><p>This approach is not without its difficulties - in fact, it has more of them than the others and lots of this article will be simply dedicated to figuring them out. But ultimately, I do believe it to a better solution for the sake of those stronger static guarantees.</p><h2 id="panic-checks"><a href="#panic-checks"></a>Panic checks</h2><p>I mentioned that this design would forbid at compile time async drop types being dropped in a synchronous context. So, seems easy right? Just detect when the compiler would run the destructor for each value and error out if it’s invalid.</p><pre><code><span><span><span><span>fn</span> </span><span>bad</span></span><span><span><span>(</span><span>stream</span><span>:</span> TlsStream</span><span><span><span>)</span></span></span></span><span> </span><span><span><span>{</span>
	<span>println!</span><span><span>(</span></span><span><span><span>&#34;</span><span>{:?}</span><span>&#34;</span></span></span><span><span>,</span> stream.<span>protocol_version</span><span><span>(</span></span><span><span>)</span></span><span>)</span></span><span>;</span>
	</span><span><span>}</span></span></span>
<span><span><span>fn</span> </span><span>good</span></span><span><span><span>(</span><span>stream</span><span>:</span> TlsStream</span><span><span><span>)</span></span></span></span><span> <span><span>-&gt;</span> TlsStream</span> </span><span><span><span>{</span>
	<span>println!</span><span><span>(</span></span><span><span><span>&#34;</span><span>{:?}</span><span>&#34;</span></span></span><span><span>,</span> stream.<span>protocol_version</span><span><span>(</span></span><span><span>)</span></span><span>)</span></span><span>;</span>
	stream
</span><span><span>}</span></span></span>
</span></code></pre><p>Except…it’s not so simple. Because at nearly every point in a program, it is possible for the thread to panic, and if that happens unwinding might start to occur and if <em>that</em> happens you need to drop all the local variables in scope but you can only do that if they have a synchronous destructor! So really the compiler ought to forbid <em>any</em> usage of values with an asynchronous destructor in a synchronous context since panics can always happen and mess things up.</p><pre><code><span><span><span><span>fn</span> </span><span>bad</span></span><span><span><span>(</span><span>stream</span><span>:</span> TlsStream</span><span><span><span>)</span></span></span></span><span> <span><span>-&gt;</span> TlsStream</span> </span><span><span><span>{</span> stream </span><span><span>}</span></span></span>
</span></code></pre><p>But that doesn’t work either. The usage of types with an asynchronous destructor in a synchronous context is absolutely necessary in many circumstances, for example <code>TlsStream::close_unclean</code> which takes <code>self</code> or <code>block_on</code> which takes a future. What the compiler actually needs to enforce is then slightly more relaxed: While a value that cannot be synchronously dropped is held in scope, no operations that might panic can occur. “Operations that might panic” here includes calling any function or triggering any operator overload. It only doesn’t include simple things like constructing a struct or tuple, accessing a type’s field (without overloaded <code>Deref</code>), matching, returning, or any other built-in and trivial operation.</p><pre><code><span><span><span><span>fn</span> </span><span>bad</span></span><span><span><span>(</span><span>stream</span><span>:</span> TlsStream</span><span><span><span>)</span></span></span></span><span> <span><span>-&gt;</span> TlsStream</span> </span><span><span><span>{</span>
	<span>println!</span><span><span>(</span></span><span><span><span>&#34;</span><span>{:?}</span><span>&#34;</span></span></span><span><span>,</span> stream.<span>protocol_version</span><span><span>(</span></span><span><span>)</span></span><span>)</span></span><span>;</span>
	stream
</span><span><span>}</span></span></span>
<span><span><span>fn</span> </span><span>good</span></span><span><span><span>(</span><span>stream</span><span>:</span> TlsStream</span><span><span><span>)</span></span></span></span><span> <span><span>-&gt;</span> TlsStream</span> </span><span><span><span>{</span> stream </span><span><span>}</span></span></span>
</span></code></pre><p>This rule is quite limited, but actually provides all the tools necessary for dealing with this situation. It is particularly effective when combined with <code>ManuallyDrop</code>: because <code>ManuallyDrop</code> skips running the destructor of a type, it is always able to be synchronously dropped even if the type inside isn’t. So as long as the first might-panic operation you do upon obtaining one of these values is calling <code>ManuallyDrop::new</code> on it, the compiler will allow you to do anything you like since the burden has effectively been shifted to <em>you</em> to drop the value if you want. What’s more, <code>ManuallyDrop::new</code> itself doesn’t have to be implemented with any compiler magic - since all it does is execute a struct expression and return it, it passes the panic check just fine.</p><h2 id="unwinding-in-async"><a href="#unwinding-in-async"></a>Unwinding in async</h2><p>Now that we’ve looked at what unwinding looks like in a synchronous context, let’s see what it looks like in an asynchronous one. It should be easier because this time we’re actually allowed to await on each value’s destruction.</p><pre><code><span>async <span><span><span>fn</span> </span><span>unwinds</span></span><span><span><span>(</span><span>_stream</span><span>:</span> TlsStream</span><span><span><span>)</span></span></span></span><span> </span><span><span><span>{</span>
	<span>panic!</span><span><span>(</span></span><span><span>)</span></span><span>;</span>
</span><span><span>}</span></span></span>
</span></code></pre><p>Sticking with the principle of forbidding ungraceful TLS stream shutdown entirely, it makes sense for the future to catch this panic and then asynchronously drop everything in scope like it usually would, before eventually propagating the panic to the caller.</p><p>For parity with synchronous code, while performing these asynchronous drops <a href="https://doc.rust-lang.org/stable/std/thread/fn.panicking.html"><code>std::thread::panicking</code></a> would return <code>true</code> and similarly panicking again would result in an abort. Actually storing the in-flight panic in the future is easy: simply store an optional pointer that is the <code><span><span>Box<span>&lt;</span>dyn Any <span>+</span> Send<span>&gt;</span></span></span></code> returned by <code>catch_unwind</code>, ready to be passed to <code>resume_unwind</code> later.</p><p>Unfortunately, those functions <a href="https://github.com/rust-lang/rfcs/issues/2810">aren’t available in <code>no_std</code> environments yet</a> so for now the compiler will probably have to use a workaround like aborting or leaking the values - or maybe implementing async destructors could be forbidden entirely on <code><span><span><span>#!</span><span>[</span><span>no_std</span><span>]</span></span></span></code>. If that issue is ever resolved it would be possible to improve the handling to something more useful.</p><p>There is one big issue with this approach however, and that is unwind safety. Unwind safety is the idea that panics in code can cause shared data structures to enter a logically invalid state, so whenever you are given the opportunity to observe the world after a panic it should be checked that you know that that might happen. This is regulated by two traits, <a href="https://doc.rust-lang.org/stable/std/panic/trait.UnwindSafe.html"><code>UnwindSafe</code></a> and <a href="https://doc.rust-lang.org/stable/std/panic/trait.RefUnwindSafe.html"><code>RefUnwindSafe</code></a>, which provide the necessary infrastructure to check all of this at compile time.</p><p>Implemented simply, this proposal would trivially break that concept:</p><pre><code><span><span><span>#</span><span>[</span><span>derive</span><span><span><span>(</span></span></span><span><span>Clone<span>,</span> Copy<span>,</span> PartialEq<span>,</span> Eq</span></span><span><span><span>)</span></span></span><span>]</span></span>
<span><span>enum</span> <span>State</span> <span><span>{</span> Valid<span>,</span> Invalid </span><span><span>}</span></span></span>

<span>let</span> state <span>=</span> <span>Cell<span>::</span></span>new<span><span>(</span><span>State<span>::</span></span>Valid</span><span><span>)</span></span><span>;</span>

<span>let</span> task <span>=</span> <span>pin!</span><span><span>(</span>async <span><span>{</span>
	<span>let</span> stream <span>=</span> some_tls_stream<span>;</span>
	state.<span>set</span><span><span>(</span><span>State<span>::</span></span>Invalid</span><span><span>)</span></span><span>;</span>
	<span>panic!</span><span><span>(</span></span><span><span>)</span></span><span>;</span>
	state.<span>set</span><span><span>(</span><span>State<span>::</span></span>Valid</span><span><span>)</span></span><span>;</span>
</span><span><span>}</span></span></span><span><span>)</span></span><span>;</span>
<span>let</span> <span>_</span> <span>=</span> task.<span>poll</span><span><span>(</span><span>&amp;</span><span>mut</span> cx</span><span><span>)</span></span><span>;</span>


<span>assert_eq!</span><span><span>(</span>state.<span>get</span><span><span>(</span></span><span><span>)</span></span><span>,</span> <span>State<span>::</span></span>Invalid</span><span><span>)</span></span><span>;</span>
</span></code></pre><p>So what do we do? Well, we have a few options:</p><ol><li>Require that all local variables in async contexts are <code>UnwindSafe</code>. This would prevent the above code from compiling because <code>&amp;Cell&lt;T&gt;</code> is <code>!UnwindSafe</code>.</li><li>Have compiler-generated <code>async {}</code> types only implement <code>Future</code> when <code>Self: UnwindSafe</code>. This is mostly the same as the first option, it just causes an error later in compilation.</li><li>Ignore unwind safety entirely - it’s already kind of useless because <code>std::thread::spawn</code> doesn’t require <code>F: UnwindSafe</code> and that can already be used to witness broken invariants. The system as a whole is definitely one of the more confusing and less understood parts of <code>std</code>, and it usually just amounts to slapping <code>AssertUnwindSafe</code> on everything until rustc is happy while not actually considering the implications.</li><li>Have async panics always cause synchronous drops of locals. This would force a sync drop option on types where it might not even make logical sense to have one, and async panic handling would permanently be done suboptimally.</li></ol><p>Personally, I’m quite in favour of option 3 - ignoring unwind safety entirely. I can’t think of a time where it has actually been useful for me or prevented a bug, but of course your mileage may vary (<a href="https://github.com/rust-lang/chalk/issues/260">I know <code>rust-analyzer</code> has been saved by unwind safety at least once</a>). I’m also open to option 1, although it could end up being quite a pain.</p><h2 id="poll-drop-ready"><a href="#poll-drop-ready"></a><code>poll_drop_ready</code></h2><p>In the now-closed <a href="https://github.com/rust-lang/rfcs/pull/2958">RFC 2958</a>, withoutboats proposed the following design for implementing asynchronous destructors:</p><pre><code><span><span><span>trait</span> <span>Drop</span> <span><span>{</span>
	<span><span><span>fn</span> </span><span>drop</span></span><span><span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span></span><span><span><span>)</span></span></span></span><span>;</span>

	<span><span><span>fn</span> </span><span>poll_drop_ready</span></span><span><span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span>, <span>cx</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Context<span>&lt;</span>&#39;<span>_</span><span>&gt;</span></span></span><span><span><span>)</span></span></span></span><span> <span><span>-&gt;</span> <span>Poll<span>&lt;</span><span>(</span><span>)</span><span>&gt;</span></span></span> </span><span><span><span>{</span>
		<span>Poll<span>::</span></span>Ready<span><span>(</span><span><span>(</span></span><span><span>)</span></span></span><span><span>)</span></span>
	</span><span><span>}</span></span></span>
</span><span><span>}</span></span></span>
</span></code></pre><p>Under this design, dropping a type would be a simple matter of forwarding to <code>poll_drop_ready</code> inside the future’s <code>poll</code> function until it returns <code><span><span>Poll<span>::</span></span>Ready<span><span>(</span><span><span>(</span></span><span><span>)</span></span></span><span><span>)</span></span></span></code> and execution can continue. Types would need to hold all state they need to use for destruction inside the type itself.</p><p>But this design comes with one <em>major</em> drawback that I haven’t seen mentioned so far: it breaks <code>Vec</code>’s three-pointer layout guarantee. The problem is that <code>Vec</code>, when destroyed, needs to drop each of its elements in order. So with an approach like <code>poll_drop_ready</code>, it would need to keep track of how many elements it has destroyed so far within the <code>Vec</code> itself, since it isn’t allowed to introduce any new external state during destruction. It can’t use any existing fields to do this - <code>ptr</code>, <code>len</code> and <code>capacity</code> are all necessary to keep around - therefore the only other option is adding a new field, but <a href="https://doc.rust-lang.org/stable/std/vec/struct.Vec.html#guarantees">Rust already guarantees</a> that <code>Vec</code> will never do that.</p><p>It’s not like there aren’t potential solutions to this, like hardcoding <code>Vec</code>’s async drop code into the language or only making it four <code>usize</code>s for async-drop types. But both of those are a hack, and to me appear to just be working around a more fundamental problem with the design.</p><p>So how do we avoid this? Well, we have to allow types to hold state - <em>new</em> state - in their asynchronous destructors. Such a design was <a href="https://without.boats/blog/poll-drop/#the-destructor-state-problem">rejected by withoutboats</a> for two reasons:</p><ol><li>The resulting future can be unexpectedly <code>!Send</code>.</li><li>It doesn’t play well with trait objects.</li></ol><p>I don’t believe the first problem to be particularly bad, as if a type’s asynchronous destructor ends up being <code>!Send</code> that simply forms part of the type’s public API, similarly to how the type itself being <code>Send</code> is. And in generic contexts, since <code>Send</code> implementations leak all over the place anyway the <code>Send</code>ness of destructors can too: it would be up to the user to provide a type with a <code>Send</code> destructor if they want the resulting future to be <code>Send</code>.</p><p>Trait objects definitely pose a larger challenge - since the new state is of variable size, it’s not possible to stack-allocate it anywhere like we usually would with non-type-erased types. But this isn’t a problem that needs to be immediately solved: it’s possible to just forbid <code>dyn</code> trait objects with asynchronous destructors for now, and potentially fill in this gap later. Since users can always create user-space workarounds for this feature, it’s not urgent to attempt to stabilize a solution immediately. Additionally because it’s a problem shared with all async traits, not just async destructors, if a general solution is found for those it would end up working for this too.</p><h2 id="function-implicit-bounds"><a href="#function-implicit-bounds"></a>Function implicit bounds</h2><p>Now we need to begin to consider how async drop works in generic code. In particular, when will a generic parameter enforce that a type does or does not support synchronous drop?</p><p>Within the current edition, it is essential that backward compatibility is maintained. Therefore, we can’t suddenly force <code>T: ?Drop</code> on any existing function or implementation, synchronous or asynchronous since they could very well be relying on synchronous drop support. If asynchronous drop is to be supported at all by an API, they must have to explicitly opt in to it (<a href="#relaxed-drop-bounds">more on this later</a>). All generic parameters and associated types without that opt-in would default to requiring a synchronous drop in every context.</p><p>To illustrate how this would work, here is an implementation of <code>FromIterator</code> for <code>Option</code> annotated with the implicit bounds:</p><pre><code><span><span><span>impl</span></span><span><span><span>&lt;</span>A, V<span>&gt;</span></span></span><span> <span>FromIterator<span>&lt;</span><span>Option<span>&lt;</span>A<span>&gt;</span></span><span>&gt;</span></span> <span>for</span></span><span> <span>Option</span><span><span>&lt;</span>V<span>&gt;</span></span>
</span><span><span>where</span>
			V<span>:</span> <span>FromIterator<span>&lt;</span>A<span>&gt;</span></span>,
</span><span><span><span>{</span>
	<span><span><span>fn</span> </span><span>from_iter</span></span><span><span>&lt;</span>I<span>&gt;</span></span><span><span><span>(</span><span>iter</span><span>:</span> I</span><span><span><span>)</span></span></span></span><span> <span><span>-&gt;</span> <span>Self</span>
	</span></span><span><span>where</span>
		I<span>:</span> <span>IntoIterator<span>&lt;</span>Item = <span>Option<span>&lt;</span>A<span>&gt;</span></span><span>&gt;</span></span>,
							</span><span><span><span>{</span>
		iter.<span>into_iter</span><span><span>(</span></span><span><span>)</span></span>.<span>scan</span><span><span>(</span><span><span>(</span></span><span><span>)</span></span><span>,</span> <span><span><span>|</span></span></span><span><span>_<span>,</span> <span>item</span><span>|</span></span> </span><span>item</span></span><span><span>)</span></span>.<span>collect</span><span><span>(</span></span><span><span>)</span></span>
	</span><span><span>}</span></span></span>
</span><span><span>}</span></span></span>
</span></code></pre><p>As a side note, I’m using <code>T: Drop</code> syntax to mean “supports synchronous drop”. Unfortunately, that is counterintuitively <em>not</em> what <code>T: Drop</code> currently means, nor does it mean “the type <a href="https://doc.rust-lang.org/stable/std/mem/fn.needs_drop.html"><code>needs_drop</code></a>”; instead, it is satisfied only if there a literal <code><span><span><span>impl</span> </span><span><span>Drop</span></span></span></code> block for the type, making the bound entirely useless in any actual code. But let’s ignore that and assume the more sensible meaning for now.</p><p>We get a lot more freedom when considering the next edition, and we can start relaxing the defaults of those bounds to something more commonly useful. As long as the standard library provides an adequate set of utilities for dealing with async drop types migrating should be painless.</p><p>Let’s look at a few simple examples to try and work out what these defaults should actually be.</p><pre><code><span><span><span><span>fn</span> </span><span>sync_drops_a_value</span></span><span><span>&lt;</span>T<span>&gt;</span></span><span><span><span>(</span><span>v</span><span>:</span> T</span><span><span><span>)</span></span></span></span><span> </span><span><span><span>{</span></span><span><span>}</span></span></span>
<span><span><span>fn</span> </span><span>sync_takes_a_ref</span></span><span><span>&lt;</span>T<span>&gt;</span></span><span><span><span>(</span><span>v</span><span>:</span> <span>&amp;</span>T</span><span><span><span>)</span></span></span></span><span> </span><span><span><span>{</span></span><span><span>}</span></span></span>
<span><span><span>fn</span> </span><span>sync_drops_a_clone</span></span><span><span>&lt;</span>T<span>:</span> Clone<span>&gt;</span></span><span><span><span>(</span><span>v</span><span>:</span> <span>&amp;</span>T</span><span><span><span>)</span></span></span></span><span> </span><span><span><span>{</span> v.<span>clone</span><span><span>(</span></span><span><span>)</span></span><span>;</span> </span><span><span>}</span></span></span>
async <span><span><span>fn</span> </span><span>async_drops_a_value</span></span><span><span>&lt;</span>T<span>&gt;</span></span><span><span><span>(</span><span>v</span><span>:</span> T</span><span><span><span>)</span></span></span></span><span> </span><span><span><span>{</span></span><span><span>}</span></span></span>
</span></code></pre><p><code>sync_drops_a_value</code> and <code>sync_drops_a_clone</code> should probably compile as-is and not work with async drop types. Similarly, <code>async_drops_a_value</code> should obviously work with async drop types, because of course async destructors would be supported in an asynchronous context. At first glance it looks like <code>sync_takes_a_ref</code> can follow suit - after all, it’s not trying to drop anything - but in practicality it can’t, because the compiler shouldn’t have to look into its function body to determine whether it actually does something like <code>sync_drops_a_clone</code> does or not. While that situation is unfortunate, it is not all bad because as it turns out the extra restriction does not matter in most cases, since users can often add an extra reference to the type to bridge the gap.</p><pre><code><span><span><span><span>fn</span> </span><span>takes_a_ref</span></span><span><span>&lt;</span>T <span>&gt;</span></span><span><span><span>(</span><span>val</span><span>:</span> <span>&amp;</span>T</span><span><span><span>)</span></span></span></span><span> </span><span><span><span>{</span>  </span><span><span>}</span></span></span>

<span>let</span> stream<span>:</span> TlsStream <span>=</span> <span>;</span>
<span>takes_a_ref</span><span><span>(</span><span>&amp;</span>stream</span><span><span>)</span></span><span>;</span> <span>takes_a_ref</span><span><span>(</span><span>&amp;</span><span>&amp;</span>stream</span><span><span>)</span></span><span>;</span> </span></code></pre><p>Normally, a double reference functions totally equivalently to a single one, so this shouldn’t be a too big problem. And as older APIs gradually migrate to new syntax it becomes less and less of one.</p><p>So past the next edition all synchronous functions would implicitly bound each generic parameter by <code>T: Drop</code> and all asynchronous functions would use the async equivalent. While this doesn’t cover the desired behaviour 100% of the time, it covers the majority of cases and that’s all that’s needed for a default - explicit bounds can be used whereever necessary.</p><p>Inherent functions follow much the same idea. Consider this example:</p><pre><code><span><span><span>struct</span> </span><span><span><span>Wrapper</span><span><span>&lt;</span>T<span>&gt;</span></span></span></span><span></span><span><span><span>(</span>T</span><span>)</span></span><span>;</span>

<span><span>impl</span></span><span><span><span>&lt;</span>T<span>&gt;</span></span></span><span> <span>Wrapper</span><span><span>&lt;</span>T<span>&gt;</span></span> </span><span><span><span>{</span>
	<span><span><span>fn</span> </span><span>some_sync_method</span></span><span><span><span>(</span><span>self</span></span><span><span><span>)</span></span></span></span><span> </span><span><span><span>{</span></span><span><span>}</span></span></span>
	<span><span><span>fn</span> </span><span>ref_method</span></span><span><span><span>(</span><span>&amp;</span><span>self</span></span><span><span><span>)</span></span></span></span><span> </span><span><span><span>{</span></span><span><span>}</span></span></span>
	async <span><span><span>fn</span> </span><span>some_async_method</span></span><span><span><span>(</span><span>self</span></span><span><span><span>)</span></span></span></span><span> </span><span><span><span>{</span></span><span><span>}</span></span></span>
</span><span><span>}</span></span></span>
</span></code></pre><p>With all the implicit bounds made explicit, it would look like this:</p><pre><code><span><span><span>struct</span> </span><span><span><span>Wrapper</span><span><span>&lt;</span>T<span>&gt;</span></span></span></span><span></span><span><span><span>(</span>T</span><span>)</span></span><span>;</span>

<span><span>impl</span></span><span><span><span>&lt;</span>T<span>&gt;</span></span></span><span> <span>Wrapper</span><span><span>&lt;</span>T<span>&gt;</span></span> </span><span><span><span>{</span>
	<span><span><span>fn</span> </span><span>some_sync_method</span></span><span><span><span>(</span><span>self</span></span><span><span><span>)</span></span></span></span><span> </span><span><span>where</span> T<span>:</span> Drop </span><span><span><span>{</span></span><span><span>}</span></span></span>
	<span><span><span>fn</span> </span><span>ref_method</span></span><span><span><span>(</span><span>&amp;</span><span>self</span></span><span><span><span>)</span></span></span></span><span> </span><span><span>where</span> T<span>:</span> Drop </span><span><span><span>{</span></span><span><span>}</span></span></span>
	async <span><span><span>fn</span> </span><span>some_async_method</span></span><span><span><span>(</span><span>self</span></span><span><span><span>)</span></span></span></span><span> </span><span><span>where</span> T<span>:</span> AsyncDrop </span><span><span><span>{</span></span><span><span>}</span></span></span>
</span><span><span>}</span></span></span>
</span></code></pre><p>There is one small addition though: because of the frequency of wanting to define several synchronous methods that don’t care about drop, one can specify relaxed bounds on the <code><span><span><span>impl</span></span></span></code> block itself and have it apply to every function inside of it. This would be useful for defining many of the <code>Option</code> methods:</p><pre><code><span><span><span>impl</span></span><span><span><span>&lt;</span>T<span>:</span> <span>?</span></span></span><span><span>Drop</span>&gt; <span>Option</span><span><span>&lt;</span>T<span>&gt;</span></span> </span><span><span><span>{</span>
	<span><span><span>pub</span> <span>fn</span> </span><span>is_some</span></span><span><span><span>(</span><span>&amp;</span><span>self</span></span><span><span><span>)</span></span></span></span><span> <span><span>-&gt;</span> <span>bool</span></span> </span><span><span><span>{</span>  </span><span><span>}</span></span></span>
	<span><span><span>pub</span> <span>fn</span> </span><span>is_none</span></span><span><span><span>(</span><span>&amp;</span><span>self</span></span><span><span><span>)</span></span></span></span><span> <span><span>-&gt;</span> <span>bool</span></span> </span><span><span><span>{</span>  </span><span><span>}</span></span></span>
	<span><span><span>pub</span> <span>fn</span> </span><span>as_ref</span></span><span><span><span>(</span><span>&amp;</span><span>self</span></span><span><span><span>)</span></span></span></span><span> <span><span>-&gt;</span> <span>Option<span>&lt;</span><span>&amp;</span>T<span>&gt;</span></span></span> </span><span><span><span>{</span>  </span><span><span>}</span></span></span>
	<span><span><span>pub</span> <span>fn</span> </span><span>as_mut</span></span><span><span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span></span><span><span><span>)</span></span></span></span><span> <span><span>-&gt;</span> <span>Option<span>&lt;</span><span>&amp;</span><span>mut</span> T<span>&gt;</span></span></span> </span><span><span><span>{</span>  </span><span><span>}</span></span></span>
	</span><span><span>}</span></span></span>
</span></code></pre><p>The choices of the exact syntax for this is discussed more later.</p><h2 id="drop-supertrait"><a href="#drop-supertrait"></a>Drop supertrait</h2><p>The following code compiles today:</p><pre><code><span><span><span>pub</span> <span>trait</span> <span>Foo</span> <span><span>{</span>
	<span><span><span>fn</span> </span><span>consumes_self</span></span><span><span><span>(</span><span>self</span></span><span><span><span>)</span></span></span></span><span> </span><span><span><span>{</span></span><span><span>}</span></span></span>
</span><span><span>}</span></span></span>
</span></code></pre><p>If any declared trait didn’t imply <code>Drop</code> as a supertrait, then we would have a breaking change as there would no longer be a guarantee that <code>self</code> can be dropped like that. Ultimately, I would like to follow in the path of <code>Sized</code> and have <code>Foo: Drop</code> <em>never</em> implied so that the above code would need an explicit <code><span><span>where</span> <span>Self</span><span>:</span> <span>Drop</span></span></code> bound, but until then that code must desugar like so:</p><pre><code><span><span><span>pub</span> <span>trait</span> <span>Foo</span>: Drop <span><span>{</span>
	<span><span><span>fn</span> </span><span>consumes_self</span></span><span><span><span>(</span><span>self</span></span><span><span><span>)</span></span></span></span><span> </span><span><span><span>{</span></span><span><span>}</span></span></span>
</span><span><span>}</span></span></span>
</span></code></pre><p>And everything can compile again.</p><p>It’s also possible that we could introduce some more complex rules about this in the current edition, like “the supertrait is only implied if there are any default methods”; but they would only help in a small number of cases and it would be easier to just convince users to use the next edition.</p><h2 id="async-genericity"><a href="#async-genericity"></a>Async genericity</h2><p>With the current suggestions taken alone, although async drop will be supported it would be rather inconvenient since almost no existing standard library APIs would support it. Just to show how difficult it would be to use, here are some functions that wouldn’t work with async drop types:</p><ul><li><code>Option::insert</code>, since it can drop the old value in the <code>Option</code>.</li><li>Many <code>HashMap</code> functions: <code>insert</code>, <code>entry</code>, etc since they call methods of user-supplied generics which can always panic.</li><li><code>Vec::push</code>, since it’s synchronous and can panic if the <code>Vec</code>’s length exceeds <code>isize::MAX</code>.</li><li><code>Box::new</code>, since it’s possible that allocation will be allowed to panic.</li></ul><p>One potential option is to introduce <code>_async</code> variants of each of these functions that are <code><span>async <span>fn</span></span></code>s. When dealing with async-drop types, you’d call <code><span>vec.<span>push_async</span><span><span>(</span>item</span><span><span>)</span></span>.await<span>;</span></span></code> instead of <code><span>vec.<span>push</span><span><span>(</span>item</span><span><span>)</span></span><span>;</span></span></code> and <code><span><span>Box</span><span><span>::</span></span>new_async<span><span>(</span>value</span><span><span>)</span></span>.await</span></code> instead of <code><span><span>Box</span><span><span>::</span></span>new<span><span>(</span>value</span><span><span>)</span></span></span></code>. However this would nearly double the API surface of the standard library and lead to a large amount of code duplication. This is obviously undesirable, so what can we do about it?</p><p>One potential path forward is a feature known as async overloading, <a href="https://blog.yoshuawuyts.com/async-overloading/">previously proposed by Yoshua Wuyts</a>. The idea is that synchronous functions can be overloaded by asynchronous ones, allowing <code>Vec::push_async</code> and <code>Vec::push</code> to effectively share the same namespace, and have the correct function be chosen based on context.</p><p>While this does solve the first problem of the doubled API surface quite neatly, it does not however solve the second problem of code duplication - one would still have to write two copies of nearly-identical code for an async and sync implementation of the same algorithm. And it comes with its own problems too, such as needing a good way to force one particular overload to be chosen of multiple possibilities.</p><p>My alternative idea is what I will refer to as async genericity. Unlike async overloading which has two separate functions with different bodies, under async genericity the async and sync equivalents of one function share a body that works for both. The compiler can then monomorphize this into two separate functions, just like it does for generic parameters. The correct version will be chosen at call site depending on the traits the given generic parameters implement. It is, to some extent, colourless async.</p><h2 id="inspiration-from-const"><a href="#inspiration-from-const"></a>Inspiration from <code>const</code></h2><p>I’d like to take inspiration from <a href="https://github.com/rust-lang/rust/issues/67792">the work on <code><span><span>const</span> <span>fn</span></span></code></a> which faces a similar problem to the one we’re facing now: how can one function be written that works for multiple modes (async/sync, const/non const)? A simple example of that is <code>drop</code>:</p><pre><code><span><span>const</span> <span><span><span>fn</span> </span><span>drop</span></span><span><span>&lt;</span>T<span>:</span> <span>~</span></span><span>const</span> <span>Drop</span><span>&gt;</span><span><span>(</span>_x<span>:</span> T</span><span><span>)</span></span> <span><span>{</span></span><span><span>}</span></span>
</span></code></pre><p>This function can be treated as “expanding” into two separate functions:</p><pre><code><span><span>const</span> <span><span><span>fn</span> </span><span>drop_const</span></span><span><span>&lt;</span>T<span>:</span> const Drop<span>&gt;</span></span><span><span><span>(</span><span>_x</span><span>:</span> T</span><span><span><span>)</span></span></span></span><span> </span><span><span><span>{</span></span><span><span>}</span></span></span>
<span><span><span>fn</span> </span><span>drop_non_const</span></span><span><span>&lt;</span>T<span>&gt;</span></span><span><span><span>(</span><span>_x</span><span>:</span> T</span><span><span><span>)</span></span></span></span><span> </span><span><span><span>{</span></span><span><span>}</span></span></span>
</span></code></pre><p>Where the correct one will be chosen at call site depending on whether <code>T</code> can be dropped in <code><span><span>const</span></span></code> contexts. <code><span><span>const</span> <span>Drop</span></span></code> is a compiler-generated <code>Drop</code> subtrait which has all the same methods as <code>Drop</code>, but converted to <code><span><span>const</span> <span>fn</span></span></code>s. This <code><span><span>const</span></span></code> modifier can actually be applied to any trait to automatically make it <code><span><span>const</span></span></code>: <code><span><span>const</span> <span>Iterator</span></span></code>, <code><span><span>const</span> Add</span></code> et cetera. You can read more about this in <a href="https://internals.rust-lang.org/t/pre-rfc-revamped-const-trait-impl-aka-rfc-2632/15192">its pre-RFC</a>, I won’t go into the details here.</p><p>I will use this as a starting point for the async generics design. It might look something like this:</p><pre><code><span><span>~</span>async <span><span><span>fn</span> </span><span>drop</span></span><span><span>&lt;</span>T<span>&gt;</span></span><span><span><span>(</span><span>_x</span><span>:</span> T</span><span><span><span>)</span></span></span></span><span> </span><span><span><span>{</span></span><span><span>}</span></span></span>
</span></code></pre><p>The <code>T: ~async Drop</code> bound is implied, like how <code>T: async Drop</code> would be implied in normal <code><span>async <span>fn</span></span></code>s. It “expands” to:</p><pre><code><span>async <span><span><span>fn</span> </span><span>drop_async</span></span><span><span>&lt;</span>T<span>&gt;</span></span><span><span><span>(</span><span>_x</span><span>:</span> T</span><span><span><span>)</span></span></span></span><span> </span><span><span><span>{</span></span><span><span>}</span></span></span>
<span><span><span>fn</span> </span><span>drop_sync</span></span><span><span>&lt;</span>T<span>&gt;</span></span><span><span><span>(</span><span>_x</span><span>:</span> T</span><span><span><span>)</span></span></span></span><span> </span><span><span><span>{</span></span><span><span>}</span></span></span>
</span></code></pre><p>In cases where there are multiple generic parameters, like for example:</p><pre><code><span><span>~</span>async <span><span><span>fn</span> </span><span>drop_pair</span></span><span><span>&lt;</span>A, B<span>&gt;</span></span><span><span><span>(</span><span>_</span>: A, <span>_</span>: B</span><span><span><span>)</span></span></span></span><span> </span><span><span><span>{</span></span><span><span>}</span></span></span>
</span></code></pre><p>The synchronous version is only possible when <em>all</em> parameters implement the synchronous version of the trait.</p><pre><code><span>async <span><span><span>fn</span> </span><span>drop_pair_async</span></span><span><span>&lt;</span>A, B<span>&gt;</span></span><span><span><span>(</span><span>_</span>: A, <span>_</span>: B</span><span><span><span>)</span></span></span></span><span> </span><span><span><span>{</span></span><span><span>}</span></span></span>

<span><span><span>fn</span> </span><span>drop_pair_sync</span></span><span><span>&lt;</span>A, B<span>&gt;</span></span><span><span><span>(</span><span>_</span>: A, <span>_</span>: B</span><span><span><span>)</span></span></span></span><span> </span><span><span><span>{</span></span><span><span>}</span></span></span>
</span></code></pre><p>If the function is being called where <code>A: Drop</code> but <code>B: async Drop</code>, the async version will be selected since <code>A: Drop</code> implies <code>A: async Drop</code> already.</p><p>If an <code>~async fn</code> is declared with <em>no</em> generic parameters that have an <code>~async</code> bound, then it’s actually totally equivalent to a synchronous function and should probably be warned against by rustc.</p><p>One important aspect to note is that <code><span>async</span></code> is somewhat the opposite of <code><span><span>const</span></span></code>. While a non-<code><span><span>const</span></span></code> function can always be substituted for a <code><span><span>const</span></span></code> one, the inverse is true of <code>async</code>: an <code><span>async</span></code> function can always be substituted for a sync one but not the other way around. This means that while <code><span><span>const</span> Trait</span></code> is a subtrait of <code>Trait</code> (fewer types implement it than just <code>Trait</code>), <code><span>async Trait</span></code> is a supertrait of <code>Trait</code> (more types implement it than just <code>Trait</code>). Or in other words, <code><span><span>const</span> Trait<span>:</span> Trait<span>:</span> async Trait</span></code>.</p><p>Another important impact of this system is that, unlike with <code>const</code>, upgrading an implementation from <code>async Trait</code> to <code>Trait</code> is a breaking change since the methods will now by default be synchronous instead of asynchronous, so you’ll get errors whereever you previously were using <code>.await</code>. Of course, the actual number of use cases is universally increased, not reduced (passing it to a function that accepts <code>async Trait</code> still works, and the methods will still require <code>.await</code> there) but direct callers will need to modify their code to have it build. However this should not be a large problem since it’s generally well known up front whether something will need async or not.</p><p>Another option would be to have <code>async Trait</code> and <code>Trait</code> be treated as two entirely separate traits, with no inherent connection between the two. This has the advantage of preventing mistakes like using <code>std::fs::File</code> in an asynchronous function at compile time (since <code>std::fs::File</code> would <em>not</em> implement <code>async Read</code>), but overall I do not think that to be worth it:</p><ol><li><p>Users can end up making the mistake anyway, just by calling a concrete blocking function like <code><span>.<span>metadata</span><span><span>(</span></span><span><span>)</span></span></span></code> on a <code>Path</code> or <code><span><span>std<span>::</span></span><span>thread<span>::</span></span>sleep</span></code>. It would only help prevent a small number of cases.</p></li><li><p>It is not always a mistake; sometimes it <em>is</em> useful to run blocking code in an asynchronous context, if for example one wants to mix asynchronous and blocking function calls on a blocking worker thread.</p></li><li><p>Sometimes whether an operation will <em>actually</em> block is only known dynamically, for example reading from a TCP stream - if it the stream is in <a href="https://doc.rust-lang.org/stable/std/net/struct.TcpStream.html#method.set_nonblocking">non-blocking mode</a> (which is explicitly a supported use case by the standard library) it should be fine to call it from <code>async</code> code.</p></li><li><p>By default types like <code><span><span>Vec<span>&lt;</span><span>u8</span><span>&gt;</span></span></span></code> (whose <code>Write</code> implementation is neither asynchronous nor blocking, and thus can be used in both contexts) would end up being exclusively synchronous. To support both, it would have to write out boilerplate code to implement both <code>async Trait</code> and <code>Trait</code> separately, or we’d have to introduce <em>another</em> new piece of syntax to share an implementation.</p><p>It gets worse when considering <code>Drop</code> - every non-generic type implementing that trait would have to migrate to this new syntax to even be usable at all in asynchronous contexts (or we could special-case <code>Drop</code> to have shared implementations, but I can’t think of a strong reason why <code>Drop</code> should be treated so differently from everything else).</p></li><li><p>Having the traits be separate rather increases the complexity of the system overall.</p></li></ol><h2 id="relaxed-drop-bounds"><a href="#relaxed-drop-bounds"></a>Relaxed drop bounds</h2><p>We introduced implicit default <code>Drop</code> bounds in a <a href="#function-implicit-bounds">previous section</a>; now that we have some actual syntax for async drop (<code>async Drop</code>) the question is how those bounds can be relaxed for functions that allow it.</p><p>I’d first like to introduce a new concept in this section: the <code>?Drop</code> bound. This bound can be considered the initial one before implicit bounds are added, and it imposes absolutely no requirements on to what extent the type supports being dropped. There would not be any situation in which this bound is necessary over <code>async Drop</code>, since the least “droppable” a type can be is <code>async Drop</code> - applying it only takes abilities away from the implementor while giving none to the caller. But it is still important to have because it avoids panic-check-passing synchronous functions that don’t care at all about <code>async</code> (<code>mem::replace</code>, <code>any::type_name</code>, <code>Option::map</code> etc) from having to write <code>async</code> in their signature to be general. It would feel rather strange for them to declare <code>&lt;T: async Drop&gt;</code> or something when they actually don’t drop the type asynchronously at all. It also enables future extensions into more kinds of drop which <a href="#linear-types">may be useful</a>.</p><p>All functions have a stronger default bound for generic parameters than <code>?Drop</code>, and that can be relaxed to <code>?Drop</code> in much the same way as the other implied bound in Rust, <code>Sized</code>: by adding <code>?Drop</code> as a trait bound in the parameter list or in the where clause. Like with <code>Sized</code> it only accepts the simple cases, so <code>?Drop</code> cannot be used as a supertrait (it is <a href="#drop-supertrait">the default anyway</a>) or as a bound on types other than a literal type parameter. There is a slight inconsistency here in that <code>?Drop</code> is used even when the implied bound isn’t actually <code>Drop</code>, because it could be in reality <code>async Drop</code>; so in a way it should really be <code>?async Drop</code> if the outer function is <code><span>async</span></code> and only <code>?Drop</code> if the outer function is sync. But since <code>?Drop</code> is shorter, more consistent and unambiguous anyway there’s no strong reason not to use it.</p><p>When relaxing bounds to something weaker than the default but stronger than <code>?Drop</code>, (particularly, setting them to <code>async Drop</code> in a synchronous function) the most obvious option is to support the trait name directly - use <code>T: async Drop</code> to support <code>T</code> not implementing any of the <code>Drop</code> subtraits (<code>Drop</code>, <code>const Drop</code>), but requiring it to implement <code>async Drop</code>. However this approach ends up being quite problematic because unlike <code>?Drop</code> whose unique syntax excuses it from only supporting a few special cases, <code>async Drop</code> is also a trait like any other and so must be supported in the general case like any other.</p><p>What this means is that having <code>T: async Drop</code> implicitly also relax a <code>Drop</code> bound breaks down in more complex cases (such as when it’s implied through a supertrait, or transitively via a bound in the <code>where</code> clause applied to another type) leading to inconsistent behaviour and confusing semantics.</p><p>Instead, Rust should take the consistent approach of <em>allowing</em> (but potentially warning against) bounds like <code>T: async Drop</code> on a synchronous function, but not giving them any effect unless they’re <em>also</em> paired with <code>?Drop</code>. Since <code>Drop</code> implies <code>async Drop</code>, adding <code>async Drop</code> in a synchronous function is a tautology and only by taking away the initial <code>Drop</code> bound does it have a meaning.</p><p>The only problem with this approach is its verbosity: <code>T: ?Drop + async Drop</code> is quite the mouthful to express one concept. It’s possible that Rust could introduce some syntax sugar to make it shorter, the only difficulty is what the actual syntax of that would be while remaining clear and unambiguous. I’m very much open to suggestions here.</p><h2 id="synchronous-opt-out"><a href="#synchronous-opt-out"></a>Synchronous opt-out</h2><p>While blindly turning every method in the trait <code>const</code> works most of the time for <code>const Trait</code>s, it doesn’t end up working so well for <code>async Trait</code>s. In particular, there are quite a few methods that would benefit from always being synchronous whether the outer trait is considered asynchronous or not, for example:</p><ul><li><code>Iterator::size_hint</code> and <code>ExactSizeIterator::len</code>: These methods should be O(1) and not perform I/O, so there’s no reason to have them be <code>async</code>.</li><li><code>Iterator::{step_by, chain, zip, map, filter, enumerate, ...}</code>: These functions just construct a type and return it, no asynchronity here.</li><li><code>Read::{by_ref, bytes, chain, take}</code>: More trivial functions that just construct a type.</li><li><code>BufRead::consume</code>: Any I/O done by the <code>BufRead</code> should occur in <code>fill_buf</code> and all <code>consume</code> should do is move around a couple numbers. Hence, it should be always synchronous.</li></ul><p>So evidently trait definitions need to be able to control what their <code>async</code> form would look like. Having any kind of default chosen by the Rust compiler would be a bad idea, because even without thinking about <code>async</code> code, just by writing a single trait you’d have already chosen and stabilized an <code>async</code> API. Plus, it’s not like many traits need to have async equivalents - it’s mostly just <code>Iterator</code>, I/O traits, functions and <code>Drop</code> that matter. Therefore I think it is best to have <code>async Trait</code> support be an opt-in by the trait declarer.</p><p>The syntax to declare one of these traits can be something along the lines of <code>trait ~async Foo</code>, <code>~async trait Foo</code>, or <code>async trait Foo</code> - I don’t have a strong preference and will use the first for now. In order to declare the methods of these traits as being conditionally async, the same <code>~async</code> syntax can actually be borrowed over from generic async functions - <code>Self</code> will just be treated as another generic parameter with an <code>~async Trait</code> bound. This produces a nice parallel between functions and traits, as demonstrated below:</p><pre><code><span><span>~</span>async <span><span><span>fn</span> </span><span>f</span></span><span><span>&lt;</span>T<span>:</span> <span>~</span></span>async Trait<span>&gt;</span><span><span>(</span></span><span><span>)</span></span> <span><span>{</span>  </span><span><span>}</span></span>

<span>trait</span> <span>~</span>async Trait <span><span>{</span> <span>~</span>async <span><span><span>fn</span> </span><span>f</span></span><span><span><span>(</span></span><span><span><span>)</span></span></span></span><span>;</span> </span><span><span>}</span></span>

async <span><span><span>fn</span> </span><span>f_async</span></span><span><span>&lt;</span>T<span>:</span> async Trait<span>&gt;</span></span><span><span><span>(</span></span><span><span><span>)</span></span></span></span><span> </span><span><span><span>{</span>  </span><span><span>}</span></span></span>
<span><span><span>fn</span> </span><span>f_sync</span></span><span><span>&lt;</span>T<span>:</span> Trait<span>&gt;</span></span><span><span><span>(</span></span><span><span><span>)</span></span></span></span><span> </span><span><span><span>{</span>  </span><span><span>}</span></span></span>

<span><span>trait</span> <span>async</span> Trait <span><span>{</span> async <span><span><span>fn</span> </span><span>f</span></span><span><span><span>(</span></span><span><span><span>)</span></span></span></span><span>;</span> </span><span><span>}</span></span></span>
<span><span>trait</span> <span>Trait</span> <span><span>{</span> <span><span><span>fn</span> </span><span>f</span></span><span><span><span>(</span></span><span><span><span>)</span></span></span></span><span>;</span> </span><span><span>}</span></span></span>
</span></code></pre><p>And since those functions are actually just regular <code>~async</code> functions, they also interact with generic parameters:</p><pre><code><span><span>trait</span> <span>~</span>async Trait <span><span>{</span>
	<span>~</span>async <span><span><span>fn</span> </span><span>f</span></span><span><span>&lt;</span>T<span>:</span> <span>~</span></span>async Read<span>&gt;</span><span><span>(</span>val<span>:</span> T</span><span><span>)</span></span><span>;</span>
</span><span><span>}</span></span>

<span><span>trait</span> <span>async</span> Trait <span><span>{</span>
	async <span><span><span>fn</span> </span><span>f_async</span></span><span><span>&lt;</span>T<span>:</span> async Read<span>&gt;</span></span><span><span><span>(</span><span>val</span><span>:</span> T</span><span><span><span>)</span></span></span></span><span>;</span>
</span><span><span>}</span></span></span>
<span><span>trait</span> <span>Trait</span> <span><span>{</span>
	async <span><span><span>fn</span> </span><span>f_async</span></span><span><span>&lt;</span>T<span>:</span> async Read<span>&gt;</span></span><span><span><span>(</span><span>val</span><span>:</span> T</span><span><span><span>)</span></span></span></span><span>;</span>
	<span><span><span>fn</span> </span><span>f_sync</span></span><span><span>&lt;</span>T<span>:</span> Read<span>&gt;</span></span><span><span><span>(</span><span>val</span><span>:</span> T</span><span><span><span>)</span></span></span></span><span>;</span>
</span><span><span>}</span></span></span>

<span><span>impl</span> </span><span>Trait <span>for</span></span><span> () </span><span><span><span>{</span>
	<span>~</span>async <span><span><span>fn</span> </span><span>f</span></span><span><span>&lt;</span>T<span>:</span> <span>~</span></span>async Read<span>&gt;</span><span><span>(</span>val<span>:</span> T</span><span><span>)</span></span> <span><span>{</span></span><span><span>}</span></span>
</span><span><span>}</span></span></span>
<span><span>impl</span> </span><span><span>async</span> <span>Trait</span> <span>for</span> <span>u32</span> </span><span><span><span>{</span>
	async <span><span><span>fn</span> </span><span>f</span></span><span><span>&lt;</span>T<span>:</span> async Read<span>&gt;</span></span><span><span><span>(</span><span>val</span><span>:</span> T</span><span><span><span>)</span></span></span></span><span> </span><span><span><span>{</span></span><span><span>}</span></span></span>
</span><span><span>}</span></span></span>
<span><span>impl</span></span><span><span><span>&lt;</span>T<span>:</span> <span>~</span></span></span><span><span>async</span> <span>Trait</span>&gt; ~<span>async</span> <span>Trait</span> <span>for</span> <span>&amp;</span><span>T</span> </span><span><span><span>{</span>
	<span>~</span>async <span><span><span>fn</span> </span><span>f</span></span><span><span>&lt;</span>T<span>:</span> <span>~</span></span>async Read<span>&gt;</span><span><span>(</span>val<span>:</span> T</span><span><span>)</span></span> <span><span>{</span></span><span><span>}</span></span>
</span><span><span>}</span></span></span>
</span></code></pre><p>Just like with regular <code>~async</code> functions, the synchronous version only exists when <em>all</em> generic parameters (here, both <code>T</code> and <code>Self</code>) implement the trait synchronously.</p><p>The last thing to note is that associated types in <code>~async Trait</code>s would have the implicit bound <code>~async Drop</code>: when the trait is an <code>async Trait</code> they’re allowed to be <code>async Drop</code> but when it’s a synchronous <code>Trait</code> they are required to be <code>Drop</code>. This should follow the rules that users will want most of the time.</p><p>To conclude, I’ll leave you with an annotated snippet of how the <code>Iterator</code> trait might look with added <code>async</code> support:</p><pre><code><span><span>pub</span> <span>trait</span> <span>~</span>async <span>Iterator</span> <span><span>{</span>
	<span>type</span> <span>Item</span><span>;</span>

	<span>~</span>async <span><span><span>fn</span> </span><span>next</span></span><span><span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span></span><span><span><span>)</span></span></span></span><span> <span><span>-&gt;</span> <span>Option<span>&lt;</span><span><span><span>Self</span><span>::</span></span></span>Item<span>&gt;</span></span></span></span><span>;</span>

	<span><span><span>fn</span> </span><span>size_hint</span></span><span><span><span>(</span><span>&amp;</span><span>self</span></span><span><span><span>)</span></span></span></span><span> <span><span>-&gt;</span> <span>(</span><span>usize</span>, <span>Option<span>&lt;</span><span>usize</span><span>&gt;</span></span><span>)</span></span> </span><span><span><span>{</span>
		<span><span>(</span><span>0</span><span>,</span> <span>None</span></span><span><span>)</span></span>
	</span><span><span>}</span></span></span>

	<span>~</span>async <span><span><span>fn</span> </span><span>fold</span></span><span><span>&lt;</span>B, F<span>&gt;</span></span><span><span><span>(</span><span>mut</span> <span>self</span>, <span>init</span><span>:</span> B, <span>f</span><span>:</span> F</span><span><span><span>)</span></span></span></span><span> <span><span>-&gt;</span> B
	</span></span><span><span>where</span>
		<span>Self</span><span>:</span> Sized,
				<span>Self</span><span>:</span> ~async Drop,
		F<span>:</span> ~async FnMut<span>(</span>B, <span><span><span>Self</span><span>::</span></span></span>Item<span>)</span> -&gt; B,
					</span><span><span><span>{</span>
		<span>let</span> <span>mut</span> accum <span>=</span> init<span>;</span>
						<span>while</span> <span>let</span> <span>Some</span><span><span>(</span>x</span><span><span>)</span></span> <span>=</span> <span>self</span>.<span>next</span><span><span>(</span></span><span><span>)</span></span>.await <span><span>{</span>
			accum <span>=</span> <span>f</span><span><span>(</span>accum<span>,</span> x</span><span><span>)</span></span>.await<span>;</span>
		</span><span><span>}</span></span>
		accum
	</span><span><span>}</span></span></span>

	<span><span><span>fn</span> </span><span>map</span></span><span><span>&lt;</span>B, F<span>&gt;</span></span><span><span><span>(</span><span>self</span>, <span>f</span><span>:</span> F</span><span><span><span>)</span></span></span></span><span> <span><span>-&gt;</span> <span>Map<span>&lt;</span><span>Self</span>, F<span>&gt;</span></span>
	</span></span><span><span>where</span>
		<span>Self</span><span>:</span> Sized,
														F<span>:</span> async FnMut<span>(</span><span><span><span>Self</span><span>::</span></span></span>Item<span>)</span> -&gt; B,
				F<span>:</span> ?Drop,
		B<span>:</span> ?Drop,
	</span><span><span><span>{</span>
		<span>Map<span>::</span></span>new<span><span>(</span><span>self</span><span>,</span> f</span><span><span>)</span></span>
	</span><span><span>}</span></span></span>

	</span><span><span>}</span></span>
</span></code></pre><p>Compared to the current design of adding a new <code>Stream</code>/<code>AsyncIterator</code> trait, this has the following advantages:</p><ul><li>We don’t have to decide between async vs sync callbacks for functions like <code>fold</code> (currently <a href="https://docs.rs/futures-util/0.3/futures_util/stream/trait.StreamExt.html#method.fold">futures-util</a> and <a href="https://docs.rs/tokio-stream/0.1/tokio_stream/trait.StreamExt.html#method.fold">tokio-stream</a> disagree about this).</li><li>We don’t have two separate functions <code>.map</code> and <code>.then</code> for sync and async respectively.</li><li><code>.map</code> with an async function can be called on a synchronous iterator, automatically turning it into an async one.</li><li>There’s no need for additional conversion functions like <code>.into_stream()</code> or <code>.into_async_iter()</code>.</li><li>Existing iterators like <code>slice::Iter</code> will automatically implement the new <code>async Iterator</code> trait.</li></ul><h2 id="async-traits-and-backwards-compatibility"><a href="#async-traits-and-backwards-compatibility"></a>Async traits and backwards compatibility</h2><p>If you look closely at my definition of <code>Iterator</code> above you’ll notice that it’s actually not backward compatible with the current definition of <code>Iterator</code>. The problem is that today, people can override functions like <code>fold</code> that are less powerful than the <code>~async</code> version. For example:</p><pre><code><span><span><span>impl</span> </span><span>Iterator <span>for</span></span><span> <span>Example</span> </span><span><span><span>{</span>
	<span>type</span> <span>Item</span> <span>=</span> <span><span>(</span></span><span><span>)</span></span><span>;</span>

	<span><span><span>fn</span> </span><span>next</span></span><span><span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span></span><span><span><span>)</span></span></span></span><span> <span><span>-&gt;</span> <span>Option<span>&lt;</span><span><span><span>Self</span><span>::</span></span></span>Item<span>&gt;</span></span></span> </span><span><span><span>{</span> <span>Some</span><span><span>(</span><span><span>(</span></span><span><span>)</span></span></span><span><span>)</span></span> </span><span><span>}</span></span></span>

	<span><span><span>fn</span> </span><span>fold</span></span><span><span>&lt;</span>B, F<span>&gt;</span></span><span><span><span>(</span><span>mut</span> <span>self</span>, <span>mut</span> <span>accum</span><span>:</span> B, <span>f</span><span>:</span> F</span><span><span><span>)</span></span></span></span><span> <span><span>-&gt;</span> B
	</span></span><span><span>where</span>
		F<span>:</span> FnMut<span>(</span>B, <span><span><span>Self</span><span>::</span></span></span>Item<span>)</span> -&gt; B,
	</span><span><span><span>{</span>
		<span>loop</span> <span><span>{</span> accum <span>=</span> <span>f</span><span><span>(</span>accum<span>,</span> <span><span>(</span></span><span><span>)</span></span></span><span><span>)</span></span> </span><span><span>}</span></span>
	</span><span><span>}</span></span></span>
</span><span><span>}</span></span></span>
</span></code></pre><p>Under my definition of <code>Iterator</code>, that code would instead need to be rewritten like this:</p><pre><code><span><span><span>impl</span> </span><span>Iterator <span>for</span></span><span> <span>Example</span> </span><span><span><span>{</span>
	<span>type</span> <span>Item</span> <span>=</span> <span><span>(</span></span><span><span>)</span></span><span>;</span>

	<span><span><span>fn</span> </span><span>next</span></span><span><span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span></span><span><span><span>)</span></span></span></span><span> <span><span>-&gt;</span> <span>Option<span>&lt;</span><span><span><span>Self</span><span>::</span></span></span>Item<span>&gt;</span></span></span> </span><span><span><span>{</span> <span>Some</span><span><span>(</span><span><span>(</span></span><span><span>)</span></span></span><span><span>)</span></span> </span><span><span>}</span></span></span>

	<span>~</span>async <span><span><span>fn</span> </span><span>fold</span></span><span><span>&lt;</span>B, F<span>&gt;</span></span><span><span><span>(</span><span>mut</span> <span>self</span>, <span>mut</span> <span>accum</span><span>:</span> B, <span>f</span><span>:</span> F</span><span><span><span>)</span></span></span></span><span> <span><span>-&gt;</span> B
	</span></span><span><span>where</span>
		F<span>:</span> ~async FnMut<span>(</span>B, <span><span><span>Self</span><span>::</span></span></span>Item<span>)</span> -&gt; B,
	</span><span><span><span>{</span>
		<span>loop</span> <span><span>{</span> accum <span>=</span> <span>f</span><span><span>(</span>accum<span>,</span> <span><span>(</span></span><span><span>)</span></span></span><span><span>)</span></span>.await </span><span><span>}</span></span>
	</span><span><span>}</span></span></span>
</span><span><span>}</span></span></span>
</span></code></pre><p>The iterator itself is still not async, but this change would additionally allow calling <code>fold</code> with an asynchronous callback even if the underlying iterator is still synchronous.</p><p>Unfortunately, we can’t just make the first version stop compiling due to Rust’s backward compatibility guarantees. And even an edition won’t be able to fix this, since the issue is greater than just a syntactical one.</p><p>I don’t think there is a reasonable way to somehow fix <code>fold</code> itself - its signature is effectively set in stone at this point. But we <em>can</em> add a <code><span><span>where</span> <span>Self</span><span>:</span> <span>Iterator<span>&lt;</span>Item = <span><span><span>Self</span><span>::</span></span></span>Item<span>&gt;</span></span></span></code> bound to it and then have the generic version be under a new name, <code>fold_async</code>. Since <code>fold_async</code> would be strictly more general than <code>fold</code>, the default implementation of <code>fold</code> can just forward to it. So the definition of <code>Iterator</code> would actually look more like this:</p><pre><code><span><span>pub</span> <span>trait</span> <span>~</span>async <span>Iterator</span> <span><span>{</span>
	<span>type</span> <span>Item</span><span>;</span>

	<span>~</span>async <span><span><span>fn</span> </span><span>next</span></span><span><span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span></span><span><span><span>)</span></span></span></span><span> <span><span>-&gt;</span> <span>Option<span>&lt;</span><span><span><span>Self</span><span>::</span></span></span>Item<span>&gt;</span></span></span></span><span>;</span>

	<span><span><span>fn</span> </span><span>fold</span></span><span><span>&lt;</span>B, F<span>&gt;</span></span><span><span><span>(</span><span>mut</span> <span>self</span>, <span>init</span><span>:</span> B, <span>f</span><span>:</span> F</span><span><span><span>)</span></span></span></span><span> <span><span>-&gt;</span> B
	</span></span><span><span>where</span>
		<span>Self</span><span>:</span> <span>Iterator<span>&lt;</span>Item = <span><span><span>Self</span><span>::</span></span></span>Item<span>&gt;</span></span> + Sized + Drop,
		F<span>:</span> FnMut<span>(</span>B, <span><span><span>Self</span><span>::</span></span></span>Item<span>)</span> -&gt; B,
	</span><span><span><span>{</span>
		<span>self</span>.<span>fold_async</span><span><span>(</span>init<span>,</span> f</span><span><span>)</span></span>
	</span><span><span>}</span></span></span>

	<span>~</span>async <span><span><span>fn</span> </span><span>fold_async</span></span><span><span>&lt;</span>B, F<span>&gt;</span></span><span><span><span>(</span><span>mut</span> <span>self</span>, <span>init</span><span>:</span> B, <span>f</span><span>:</span> F</span><span><span><span>)</span></span></span></span><span> <span><span>-&gt;</span> B
	</span></span><span><span>where</span>
		<span>Self</span><span>:</span> Sized + ~async Drop,
		F<span>:</span> ~async FnMut<span>(</span>B, <span><span><span>Self</span><span>::</span></span></span>Item<span>)</span> -&gt; B,
	</span><span><span><span>{</span>
		<span>let</span> <span>mut</span> accum <span>=</span> init<span>;</span>
		<span>while</span> <span>let</span> <span>Some</span><span><span>(</span>x</span><span><span>)</span></span> <span>=</span> <span>self</span>.<span>next</span><span><span>(</span></span><span><span>)</span></span>.await <span><span>{</span>
			accum <span>=</span> <span>f</span><span><span>(</span>accum<span>,</span> x</span><span><span>)</span></span>.await<span>;</span>
		</span><span><span>}</span></span>
		accum
	</span><span><span>}</span></span></span>

	</span><span><span>}</span></span>
</span></code></pre><p>Even though it looks very similar to not having async genericity at all, it is still better than without because:</p><ol><li>Overriding <code>fold_async</code> also effectively overrides <code>fold</code> - they’re able to share an implementation.</li><li>Async and sync iterators share definitions of <code>fold</code> and <code>fold_async</code>.</li></ol><p>This makes the feature still worth it in my opinion, even if we have to insert some hacks into <code>Iterator</code> to avoid breaking compatibility.</p><p>Unfortunately <code>fold</code> isn’t the only method that would need this treatment, potentially many others would too. By my count, this includes (in the standard library alone): <code>chain</code>, <code>zip</code>, <code>map</code>, <code>for_each</code>, <code>filter</code>, <code>filter_map</code>, <code>skip_while</code>, <code>take_while</code>, <code>map_while</code>, <code>scan</code>, <code>flat_map</code>, <code>flatten</code>, <code>inspect</code>, <code>collect</code>, <code>partition</code>, <code>try_fold</code>, <code>try_for_each</code>, <code>reduce</code>, <code>all</code>, <code>any</code>, <code>find</code>, <code>find_map</code>, <code>position</code>, <code>rposition</code>, <code>sum</code>, <code>product</code>, <code>cmp</code>, <code>partial_cmp</code>, <code>eq</code>, <code>ne</code>, <code>lt</code>, <code>le</code>, <code>gt</code>, <code>ge</code>, <code>DoubleEndedIterator::try_rfold</code>, <code>DoubleEndedIterator::rfold</code>, <code>DoubleEndedIterator::rfind</code> and <code>Read::chain</code>. If <code>async Clone</code> or <code>async Ord</code> become things, the list would grow longer.</p><p>It is a bit of a shame that functions like <code>map</code> and <code>Read::chain</code> have to have async versions though, since it’s not like anyone overrides <code>map</code> anyway. But because it’s <em>technically</em> possible, Rust has already promised not to break that code and so now can’t relax the signature of that function. Although who knows, maybe if we got a low % regression Crater run it would convince people that’s it’s acceptable breakage and the list could be shortened to the much more manageable <code>for_each</code>, <code>partition</code>, <code>try_fold</code>, <code>try_for_each</code>, <code>reduce</code>, <code>all</code>, <code>any</code>, <code>find</code>, <code>find_map</code>, <code>position</code>, <code>rposition</code>, <code>cmp</code>, <code>partial_cmp</code>, <code>eq</code>, <code>ne</code>, <code>lt</code>, <code>le</code>, <code>gt</code>, <code>ge</code>, <code>DoubleEndedIterator::try_rfold</code>, <code>DoubleEndedIterator::rfold</code> and <code>DoubleEndedIterator::rfind</code>. I would definitely rather do this, because frankly if you override <code>map</code> then you deserve what you get.</p><p>Out of the group, <code>collect</code>, <code>sum</code> and <code>product</code> are an especially interesting three because their <code>_async</code> versions (and their normal versions if we accept the technically breaking change) can’t use the standard <code>FromIterator</code>, <code>Product</code> and <code>Sum</code> traits since those traits are currently hardcoded to work for synchronous iterators only. So we would instead have to make new <code>*Async</code> versions of those traits with blanket implementations of the old versions:</p><pre><code><span><span>pub</span> <span>trait</span> <span>~</span>async <span>FromAsyncIterator<span>&lt;</span>A<span>&gt;</span></span><span>:</span> <span>Sized</span> <span><span>{</span>
    <span>~</span>async <span><span><span>fn</span> </span><span>from_async_iter</span></span><span><span>&lt;</span>T<span>:</span> <span>~</span></span>async <span>IntoIterator<span>&lt;</span>Item = A<span>&gt;</span></span><span>&gt;</span><span><span>(</span>iter<span>:</span> T</span><span><span>)</span></span> <span><span>-&gt;</span> <span>Self</span></span><span>;</span>
</span><span><span>}</span></span>
<span><span>impl</span></span><span><span><span>&lt;</span>T<span>:</span> <span>FromAsyncIterator<span>&lt;</span>A<span>&gt;</span></span>, A<span>&gt;</span></span></span><span> <span>FromIterator<span>&lt;</span>A<span>&gt;</span></span> <span>for</span></span><span> <span>T</span> </span><span><span><span>{</span>
	<span><span><span>fn</span> </span><span>from_iter</span></span><span><span>&lt;</span>T<span>:</span> <span>IntoIterator<span>&lt;</span>Item = A<span>&gt;</span></span><span>&gt;</span></span><span><span><span>(</span><span>iter</span><span>:</span> T</span><span><span><span>)</span></span></span></span><span> <span><span>-&gt;</span> <span>Self</span></span> </span><span><span><span>{</span>
		<span>Self</span><span><span>::</span></span>from_async_iter<span><span>(</span>iter</span><span><span>)</span></span>
	</span><span><span>}</span></span></span>
</span><span><span>}</span></span></span>
</span></code></pre><p>With similar code for both <code>Sum</code> and <code>Product</code>. Unlike <code>Iterator::fold</code>, since <code>from_iter</code>, <code>sum</code> and <code>product</code> aren’t default-implemented methods we can’t just add a new <code>from_async_iter</code> function to the <code>FromIterator</code> trait itself; an entirely new trait is needed.</p><h2 id="trait-impl-implicit-bounds"><a href="#trait-impl-implicit-bounds"></a>Trait impl implicit bounds</h2><p><a href="#function-implicit-bounds">Before</a>, I talked about how inside an inherent impl block, implicit <code>Drop</code> bounds to generics of the outer type would apply individually to each of the methods depending on its asynchronity, and the block itself would enforce no bounds on the type. Unfortunately, we don’t have that luxury when considering trait implementations: either the trait is implemented or it’s not and we can’t apply our own bounds to individual items.</p><p>However, we <em>do</em> know whether the trait overall should be considered asynchronous or not - whether it’s being implemented as <code>async Trait</code> or <code>Trait</code>. So we can just forward that property as the default kind of <code>Drop</code> bound, and it should be what users want most of the time. Of course, for the (hopefully) rare case that it’s <em>not</em> desired they can always override it. The most obvious time that crops up is when implementing a trait that isn’t an <code>async Trait</code> but still has async methods (i.e. an async trait with no synchronous equivalent) - then the drop bounds would end up overly restrictive:</p><pre><code><span><span><span>trait</span> <span>ExampleTrait</span> <span><span>{</span>
	async <span><span><span>fn</span> </span><span>foo</span></span><span><span>&lt;</span>V<span>&gt;</span></span><span><span><span>(</span><span>&amp;</span><span>self</span>, <span>value</span><span>:</span> V</span><span><span><span>)</span></span></span></span><span>;</span>
</span><span><span>}</span></span></span>

<span><span>struct</span> </span><span><span><span>Wrapper</span><span><span>&lt;</span>T<span>&gt;</span></span></span></span><span></span><span><span><span>(</span>T</span><span>)</span></span><span>;</span>

<span><span>impl</span></span><span><span><span>&lt;</span>T<span>&gt;</span></span></span><span> ExampleTrait <span>for</span></span><span> <span>Wrapper</span><span><span>&lt;</span>T<span>&gt;</span></span>
</span><span><span>where</span>
	</span><span><span><span>{</span>
	async <span><span><span>fn</span> </span><span>foo</span></span><span><span>&lt;</span>V<span>&gt;</span></span><span><span><span>(</span><span>&amp;</span><span>self</span>, <span>value</span><span>:</span> V</span><span><span><span>)</span></span></span></span><span>
	</span><span><span>where</span>
					</span><span><span><span>{</span>
		<span>todo!</span><span><span>(</span></span><span><span>)</span></span>
	</span><span><span>}</span></span></span>
</span><span><span>}</span></span></span>
</span></code></pre><p>But with any luck this kind of code won’t be too common, since users should ideally be writing most code as generic-over-async anyway.</p><p>An interesting side effect of the above rule is in code like below:</p><pre><code><span><span><span>struct</span> </span><span><span><span>Wrapper</span><span><span>&lt;</span>T<span>&gt;</span></span></span></span><span></span><span><span><span>(</span>T</span><span>)</span></span><span>;</span>

<span><span>impl</span></span><span><span><span>&lt;</span>T <span>&gt;</span></span></span><span> Drop <span>for</span></span><span> <span>Wrapper</span><span><span>&lt;</span>T<span>&gt;</span></span> </span><span><span><span>{</span>
	<span><span><span>fn</span> </span><span>drop</span></span><span><span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span></span><span><span><span>)</span></span></span></span><span> </span><span><span><span>{</span>
		<span>println!</span><span><span>(</span></span><span><span><span>&#34;</span>I am being dropped<span>&#34;</span></span></span><span><span>)</span></span><span>;</span>
	</span><span><span>}</span></span></span>
</span><span><span>}</span></span></span>
</span></code></pre><p>Although it is not obvious, this code wouldn’t compile because the <code>Drop</code> implementation of a type has more restrictive trait bounds than the type itself, and that isn’t allowed. But since it looks like this code should compile, I find it acceptable to introduce a special case and simply have the compiler forward that implicit <code>T: Drop</code> bound to the type itself, but only when a <code>Drop</code> implementation specifically is present.</p><p>Either way, that type does not work with <code>async Drop</code> types and the fix is like so:</p><pre><code><span><span><span>struct</span> </span><span><span><span>Wrapper</span><span><span>&lt;</span>T<span>&gt;</span></span></span></span><span></span><span><span><span>(</span>T</span><span>)</span></span><span>;</span>

<span><span>impl</span></span><span><span><span>&lt;</span>T<span>:</span> <span>?</span></span></span><span><span>Drop</span>&gt; <span>Drop</span> <span>for</span> <span>Wrapper</span><span><span>&lt;</span>T<span>&gt;</span></span> </span><span><span><span>{</span>
	<span><span><span>fn</span> </span><span>drop</span></span><span><span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span></span><span><span><span>)</span></span></span></span><span> </span><span><span><span>{</span>
		<span>println!</span><span><span>(</span></span><span><span><span>&#34;</span>I am being dropped<span>&#34;</span></span></span><span><span>)</span></span><span>;</span>
	</span><span><span>}</span></span></span>
</span><span><span>}</span></span></span>
</span></code></pre><h2 id="async-closures"><a href="#async-closures"></a>Async closures</h2><p>Supporting async genericity with closures (as required for functions like <code>Option::map</code> and <code>Iterator::fold</code>) requires <code>async {Fn, FnMut, FnOnce}</code> to exist as traits. It seems that this is a bit useless since we already have functions that return futures, but as it turns out there is an actual benefit to having separate <code>async</code> function traits, particularly when working with closures: it makes the lifetimes a lot easier to manage, since the returned futures will be able to borrow the closure and parameters - something impossible with the current design.</p><p>However in order for the <code>async Fn</code>-traits to be useful, they must be actually implemented by the relevant functions and closures. Currently, people support asynchronous callbacks by having closures that return futures (<code>|| async {}</code>) - and <code>async fn</code>s are desugared to functions of this form too. It wouldn’t be a good idea to attempt to change the behaviour of the former since that would need a hacky compiler special case for closures returning futures only, but thankfully we have reserved a bit of syntax that would be perfect for this use case: async closures (<code>async || {}</code>). If they were to evaluate to closure types implementing <code>async Fn</code> instead of <code>Fn</code>, they could be passed into async-generic functions like <code>Option::map</code> without a problem.</p><pre><code><span><span>let</span> output <span>=</span> some_option.<span>map</span><span><span>(</span>async <span>|</span>value<span>|</span> <span>process</span><span><span>(</span>value</span><span><span>)</span></span>.await</span><span><span>)</span></span>.await<span>;</span>

<span>let</span> output <span>=</span> some_option.<span>map</span><span><span>(</span><span><span><span>|</span></span></span><span><span><span>value</span><span>|</span></span> </span><span>async <span><span>{</span> <span>process</span><span><span>(</span>value</span><span><span>)</span></span>.await </span><span><span>}</span></span></span></span><span><span>)</span></span><span>;</span>
</span></code></pre><p>The less good side of this addition is with <code><span>async <span>fn</span></span></code>s: we would have to choose between keeping the current system of desugaring to a simple <code><span><span><span>-&gt;</span> impl Future</span></span></code> function, and implementing the <code>async Fn</code> traits. The former is backwards compatible and more transparent (since those functions can be replicated entirely in userspace), but the latter has better interopability with async generic functions. I am inclined to choose the latter design, but it’s an unfortunate decision to have to make.</p><p>Note that it wouldn’t be possible to implement <em>both</em> <code>async Fn</code> and <code>Fn</code>, because implementing <code>Fn</code> already implies implementing <code>async Fn</code> as an async function that never awaits; we would end up with conflicting implementations of <code>async Fn</code>, one that asynchronously evaluates to <code>T</code> and one that immediately evaluates to <code>impl Future&lt;Output = T&gt;</code>. To avoid that compile error we would have to choose one and discard the other.</p><h2 id="conclusion"><a href="#conclusion"></a>Conclusion</h2><p>In this post we sketched out a potential design for async drop, figuring out many details and intricacies along the way. The resulting proposal is unfortunately not a small one, however it does have much general usefulness outside of async destructors (<code>~async</code> in particular would be excellent to have for so much code) and lots of it is necessary if we are to minimize footguns.</p><p>As a summary of everything we’ve explored thus far:</p><ol><li>We figured out the desired edge case semantics of async drop during cancellation, panics and assignments, in synchronous functions and with generics.</li><li>We explored a system for async destructors based on destructor futures instead of <code>poll_drop_ready</code>.</li><li>We explored a mechanism for supporting code that is generic over whether it is <code>async</code> or not.</li><li>We hypothesized what is best to apply as the default generic drop bounds in functions, as well as how to relax and strengthen them if necessary.</li><li>We considered how async genericity would impact functions and closures.</li></ol><p>This post doesn’t attempt to provide a final design for async drop - there are still many open questions (e.g. <code>UnwindSafe</code>, <code>?Drop</code> syntax, <code><span><span><span>#!</span><span>[</span><span>no_std</span><span>]</span></span></span></code> support) and likely unknown unknowns. But it does attempt to properly explore one particular design to evaluate its complexity, feasability and usefulness. Out of all possible options, I think it to be quite a promising one and definitely possible to implement in some form.</p><p>Many thanks to Yoshua Wuyts for proofreading this for me!</p><h2 id="completion-futures"><a href="#completion-futures"></a>Appendix A: Completion futures</h2><p>Completion futures are a concept for a special type of future that is guaranteed at compile-time to not be prematurely dropped or leaked, in contrast to regular futures which can be stopped without warning at any time. It doesn’t sound like much, but completion futures are actually incredibly useful:</p><ul><li>They enable <code>spawn</code> and <code>spawn_blocking</code> functions that don’t restrict the future’s lifetime to <code>&#39;static</code>.</li><li>They enable creating zero-cost wrappers around completion-based APIs like <code>io_uring</code>, IOCP and libusb.</li><li>They enables better interopability with C++ futures, which have this guarantee by default.</li></ul><p>I have previously written <a href="https://github.com/SabrinaJewson/completion">a library for this</a> but it was very limited because it fundamentally needed to rely on <code>unsafe</code>, infecting just about every use of it with <code>unsafe</code> as well which was really not ideal. But it turns out that with an async destructor design like the one proposed by this post, it is much easier to support them in an even more powerful way and with minimal <code>unsafe</code>.</p><p>The solution is to add a single new trait to the core library:</p><pre><code><span><span>pub</span> <span>unsafe</span> auto <span><span>trait</span> <span>Leak</span> <span><span>{</span></span><span><span>}</span></span></span>
</span></code></pre><p>As an auto trait, it would be implemented for every single type other than a special <code>core::marker::PhantomNoLeak</code> marker and any type transitively containing that. What <code>Leak</code> represents is the ability to safely leak an instance of the type, via <a href="https://doc.rust-lang.org/stable/std/mem/fn.forget.html"><code>mem::forget</code></a>, reference cycles or anything similar. If a type opts out of implementing it, it is guaranteed that from creation, its <code>Drop</code> or <code>async Drop</code> implementation will be run if the type’s lifetime to end.</p><p>The standard library would have all the “leaky” APIs like <code>Arc</code>, <code>Rc</code>, <code>ManuallyDrop</code> and <code>MaybeUninit</code> require that <code>Leak</code> be implemented on the inner type, to avoid safe code being able to circumvent the restriction. Other than that, most other APIs would support both <code>Leak</code> and <code>!Leak</code> types, since they will run the destructor of inner values.</p><p>And this is all we need to support completion futures. An <code>io_uring</code> I/O operation future can be implemented by submitting the operation on creation and waiting for it to complete on drop, and the <code>!Leak</code> guarantee means that the <a href="https://github.com/spacejam/rio/issues/30">use-after-free issue</a> <code>io_uring</code> libraries currently have to work around is eliminated.</p><p>This is a very powerful feature, even more so than my old <code>unsafe</code>-based implementation. Because it guarantees not leaking from creation and not just from the first poll, scoped tasks don’t even need a special scope to be defined (à la <a href="https://docs.rs/crossbeam/0.8/crossbeam/fn.scope.html">Crossbeam</a>). Instead, an API like this just works:</p><pre><code><span><span>pub</span> async <span><span><span>fn</span> </span><span>spawn</span></span><span><span>&lt;</span><span>&#39;a</span>, R, F<span>&gt;</span></span><span><span><span>(</span><span>f</span><span>:</span> F</span><span><span><span>)</span></span></span></span><span> <span><span>-&gt;</span> <span>JoinHandle<span>&lt;</span><span>&#39;a</span>, R<span>&gt;</span></span>
</span></span><span><span>where</span>
	F<span>:</span> <span>Future<span>&lt;</span>Output = R<span>&gt;</span></span> + Send + <span>&#39;a</span>,
	R<span>:</span> Send,
</span><span><span><span>{</span>  </span><span><span>}</span></span></span>
</span></code></pre><p>It also has impacts on synchronous code, because <a href="https://doc.rust-lang.org/stable/std/thread/fn.spawn.html"><code>thread::spawn</code></a> gets to be extended in a similar way:</p><pre><code><span><span><span><span>pub</span> <span>fn</span> </span><span>spawn_scoped</span></span><span><span>&lt;</span><span>&#39;a</span>, R, F<span>&gt;</span></span><span><span><span>(</span><span>f</span><span>:</span> F</span><span><span><span>)</span></span></span></span><span> <span><span>-&gt;</span> <span>JoinHandle<span>&lt;</span><span>&#39;a</span>, R<span>&gt;</span></span>
</span></span><span><span>where</span>
	F<span>:</span> FnOnce<span>(</span><span>)</span> -&gt; R + Send + <span>&#39;a</span>,
	R<span>:</span> Send,
</span><span><span><span>{</span>  </span><span><span>}</span></span></span>
</span></code></pre><p>This would allow you to write code that borrows from the stack without problems:</p><pre><code><span><span>let</span> message <span>=</span> <span><span>&#34;</span>Hello World<span>&#34;</span></span>.<span>to_owned</span><span><span>(</span></span><span><span>)</span></span><span>;</span>

<span>let</span> thread_1 <span>=</span> <span>thread<span>::</span></span>spawn_scoped<span><span>(</span><span><span><span>|</span></span></span><span><span><span>|</span></span> </span><span><span>println!</span><span><span>(</span></span><span><span><span>&#34;</span><span>{message}</span><span>&#34;</span></span></span><span><span>)</span></span></span></span><span><span>)</span></span><span>;</span>
<span>let</span> thread_2 <span>=</span> <span>thread<span>::</span></span>spawn_scoped<span><span>(</span><span><span><span>|</span></span></span><span><span><span>|</span></span> </span><span><span>println!</span><span><span>(</span></span><span><span><span>&#34;</span><span>{message}</span><span>&#34;</span></span></span><span><span>)</span></span></span></span><span><span>)</span></span><span>;</span>
thread_1.<span>join</span><span><span>(</span></span><span><span>)</span></span>.<span>unwrap</span><span><span>(</span></span><span><span>)</span></span><span>;</span>
thread_2.<span>join</span><span><span>(</span></span><span><span>)</span></span>.<span>unwrap</span><span><span>(</span></span><span><span>)</span></span><span>;</span>

<span>let</span> task_1 <span>=</span> <span>task<span>::</span></span>spawn<span><span>(</span>async <span><span>{</span> <span>println!</span><span><span>(</span></span><span><span><span>&#34;</span><span>{message}</span><span>&#34;</span></span></span><span><span>)</span></span> </span><span><span>}</span></span></span><span><span>)</span></span>.await<span>;</span>
<span>let</span> task_2 <span>=</span> <span>task<span>::</span></span>spawn<span><span>(</span>async <span><span>{</span> <span>println!</span><span><span>(</span></span><span><span><span>&#34;</span><span>{message}</span><span>&#34;</span></span></span><span><span>)</span></span> </span><span><span>}</span></span></span><span><span>)</span></span>.await<span>;</span>
task_1.await.<span>unwrap</span><span><span>(</span></span><span><span>)</span></span><span>;</span>
task_2.await.<span>unwrap</span><span><span>(</span></span><span><span>)</span></span><span>;</span>
</span></code></pre><p>Neat, right?</p><p>As with many things it needs an edition boundary to implement fully: In the current edition, every generic parameter has to still imply <code>T: Leak</code> but in future editions that can be relaxed to <code>T: ?Leak</code>, allowing the small subset of APIs that <em>can</em> leak values (<code>Arc</code>, <code>Rc</code>, <code>mem::forget</code>, <code>ManuallyDrop</code>, etc) to declare so in their signature and the majority of APIs to have the less restrictive bound by default.</p><h2 id="weakly-async-functions"><a href="#weakly-async-functions"></a>Appendix B: Weakly async functions</h2><p>With the current design, there ends up being a large number of functions with the specific property that they need to be <code><span>async <span>fn</span></span></code>s if a type they deal with is <code>async Drop</code>, for the sole reason that they are able to panic while they have that type in scope. I listed a few at the start of the <a href="#async-genericity">async genericity</a> section, including <code>HashMap::{insert, entry}</code>, <code>Vec::push</code> and <code>Box::new</code>, but there’s one particularly relevant one here which is <code>task::spawn</code> (as seen in various runtimes: <a href="https://docs.rs/tokio/1/tokio/task/fn.spawn.html">tokio</a>, <a href="https://docs.rs/async-std/1/async_std/task/fn.spawn.html">async-std</a>, <a href="https://docs.rs/glommio/0.7/glommio/fn.spawn_local.html">glommio</a>, <a href="https://docs.rs/smol/1/smol/fn.spawn.html">smol</a>).</p><p>Across all those runtimes, <code>task::spawn</code> has the ability to panic before it spawns the future, which commonly can happen if the runtime is not running, but can also theoretically happen if allocation fails or there’s some other random system error. The problem is that just because of this one small edge case (and their presumed desire to support <code>async Drop</code> futures), <code>task::spawn</code> is forced to be a full <code>async fn</code> even though <em>in itself</em> it doesn’t do any <code>async</code> work.</p><p>This is especially bad for <code>task::spawn</code> as a function because it can easily trip up those who are migrating code. For example, while before this code would run the task in parallel with <code><span><span>other_work</span><span><span>(</span></span><span><span>)</span></span></span></code>:</p><pre><code><span><span>let</span> task <span>=</span> <span>task<span>::</span></span>spawn<span><span>(</span>some_future</span><span><span>)</span></span><span>;</span>
<span>other_work</span><span><span>(</span></span><span><span>)</span></span>.await<span>;</span>
task.await<span>;</span>
</span></code></pre><p>With the changes applied it would instead run <code><span><span>other_work</span><span><span>(</span></span><span><span>)</span></span></span></code> and wait for it to complete, and <em>then</em> spawn the task and not even wait for it to finish! (Unless of course dropping a task handle would be changed to implicitly join the task, which <em>may</em> be a better design overall - but the point still stands because it doesn’t run in parallel as people would expect.)</p><p>The fixed version would look like this:</p><pre><code><span><span>let</span> task <span>=</span> <span>task<span>::</span></span>spawn<span><span>(</span>some_future</span><span><span>)</span></span>.await<span>;</span>
<span>other_work</span><span><span>(</span></span><span><span>)</span></span>.await<span>;</span>
task.await<span>;</span>
</span></code></pre><p>But given that the old version doesn’t even fail to compile, it’s not an ideal situation to be in. Additionally, it does just look weird having a future that resolves to…another future.</p><p>My proposed solution to this problem is to add a new type of function to the language called “weakly async functions” which are in between asynchronous functions and synchronous functions. Let’s denote it here with <code>[async] fn</code>, but the syntax is obviously up for bikeshedding. The idea is this:</p><ul><li><code>[async] fn</code>s either complete synchronously or panic asynchronously.</li><li>Because they must complete synchronously, they cannot be cancelled and thus they don’t need to be <code>.await</code>ed - that can be made implicit.</li><li>Because they panic asynchronously, they bypass the panic check and are allowed to own types with asynchronous destructors across potential panic points (but are not allowed to drop them unless via a panic).</li><li>They are allowed to call regular <code>fn</code>s and other <code>[async] fn</code>s, but not <code>async fn</code>s.</li><li>They cannot be called from within synchronous functions.</li><li>They are not allowed to recurse, just like <code>async fn</code>s.</li><li>It is not a breaking change to convert from an <code>[async] fn</code> to a regular fn.</li></ul><p>This way, <code>task::spawn</code> (and a bunch of other functions like <code>Box::new</code>, <code>Box::pin</code>, <code>Vec::push</code>, <code>Result::unwrap</code> etc) would avoid requiring <code>.await</code>s when being called with <code>async Drop</code> types. This solves the above footgun while also contributing to the succintness of code. <code>task::spawn</code> would be defined something like this:</p><pre><code><span><span>pub</span> <span><span>[</span>async<span>]</span></span> <span><span><span>fn</span> </span><span>spawn</span></span><span><span>&lt;</span>O, F<span>&gt;</span></span><span><span><span>(</span></span><span><span><span>)</span></span></span></span><span> <span><span>-&gt;</span> <span>JoinHandle<span>&lt;</span>O<span>&gt;</span></span>
</span></span><span><span>where</span>
	F<span>:</span> <span>Future<span>&lt;</span>Output = O<span>&gt;</span></span> + Send + ?Drop + async Drop + <span>&#39;static</span>,
	O<span>:</span> Send,
</span></span></code></pre><p>And in asynchronous contexts would be callable with just <code>task::spawn(future)</code>, no await necessary.</p><p>When inside generic code, <code>[async]</code> would be treated as another state that <code>~async fn</code>s can be in, meaning there are actually three ways to those functions. There would additionally be <code>~[async] fn</code>s for functions that can be either <code>fn</code>s or <code>[async] fn</code>s, but not <code>async fn</code>s.</p><p>You’d also need a special kind of bound to represent “<code>Drop</code> when the function is synchronous and <code>async Drop</code> when the function is <code>async</code>, but also <code>async Drop</code> when the function is <code>[async]</code>, since this function does not drop a value of this type unless it panics”. For now I will use the incredibly verbose form <code>~[async] async Drop</code> to represent this, but if this feature is actually added a better and more bikeshedded syntax will probably have to be chosen.</p><p>This is the feature that allows us to define <code>Vec::push</code> generically:</p><pre><code><span><span><span>impl</span></span><span><span><span>&lt;</span>T<span>&gt;</span></span></span><span> <span>Vec</span><span><span>&lt;</span>T<span>&gt;</span></span> </span><span><span><span>{</span>
	<span>~</span><span><span>[</span>async<span>]</span></span> <span><span><span>fn</span> </span><span>push</span></span><span><span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span>, <span>item</span><span>:</span> T</span><span><span><span>)</span></span></span></span><span>
	</span><span><span>where</span>
		T<span>:</span> ?Drop + ~[async] async Drop,
	</span><span><span><span>{</span>
		
	</span><span><span>}</span></span></span>
</span><span><span>}</span></span></span>

<span><span>impl</span></span><span><span><span>&lt;</span>T<span>&gt;</span></span></span><span> <span>Vec</span><span><span>&lt;</span>T<span>&gt;</span></span> </span><span><span><span>{</span>
	<span><span><span>fn</span> </span><span>push_sync</span></span><span><span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span>, <span>item</span><span>:</span> T</span><span><span><span>)</span></span></span></span><span>
	</span><span><span>where</span>
		T<span>:</span> Drop,
	</span><span><span><span>{</span>
		
	</span><span><span>}</span></span></span>
	<span>~</span><span><span>[</span>async<span>]</span></span> <span><span><span>fn</span> </span><span>push_weak_async</span></span><span><span><span>(</span><span>&amp;</span><span>mut</span> <span>self</span>, <span>item</span><span>:</span> T</span><span><span><span>)</span></span></span></span><span>
	</span><span><span>where</span>
		T<span>:</span> ?Drop + async Drop,
	</span><span><span><span>{</span>
		
	</span><span><span>}</span></span></span>
</span><span><span>}</span></span></span>
</span></code></pre><p>Remember that this function can drop <code>item</code> and so can’t be fully synchronous, but also doesn’t drop <code>item</code> unless it’s panicking and so shouldn’t be made fully <code>async</code> either. As such it uses the in-between, supporting <code>async Drop</code> (and therefore also <code>[async] Drop</code>) when it is an <code>[async] fn</code> and <code>Drop</code> when it is a <code>fn</code>.</p><p>Unlike completion futures, I’m not so certain whether this is a good idea or not, or whether there aren’t any other simpler alternatives. But I do definitely think there is a problem here that does need to be addressed somehow, and to me this seems the best way to do it.</p><h2 id="linear-types"><a href="#linear-types"></a>Appendix C: Linear types</h2><p>I feel that I have to mention linear types at least once, given how much discourse there has been about them. A linear type is defined as “a type that must be used exactly once”. It turns out this definition is slightly vague, because it can refer to two things:</p><ol><li>Types which do not have any kind of <code>Drop</code> implementation and must be handled explicitly, but can be leaked with functions like <a href="https://doc.rust-lang.org/stable/std/mem/fn.forget.html"><code>mem::forget</code></a>.</li><li>Types which do have destructors and so can implicitly fall out of scope, but can’t be leaked with functions like <a href="https://doc.rust-lang.org/stable/std/mem/fn.forget.html"><code>mem::forget</code></a> (so they are guaranteed to be able to run code before falling out of scope).</li></ol><p>The former is a more common definition of linear types, and allows for types to force their users to be more explicit about what happens to them when they’re destroyed. I don’t have a proposal for this, but simply by coincidence the proposed <code>?Drop</code> bound feature does orient itself towards supporting linear types of this sort in future and although personally I do not think they will be worth adding, their viability has been increased as a side-effect.</p><p>The latter definition is what is implemented by the above <a href="#completion-futures">completion futures</a> proposal. In a way it’s not true linear types, but it’s the only one that gives the practical benefits of things like zero-cost <code>io_uring</code> and scoped tasks. It is also a lot less difficult to integrate into existing Rust code, which tends to rely quite heavily on destructors existing but not so much on values being safely leakable.</p><h2 id="uncancellable-futures"><a href="#uncancellable-futures"></a>Appendix D: Uncancellable futures</h2><p>I previously argued against <a href="https://carllerche.netlify.app/2021/06/17/six-ways-to-make-async-rust-easier/">Carl Lerche’s suggestion to make all async functions uncancellable</a> in favour of defining consistent semantics for <code>.await</code> rather than removing it. However, these kinds of functions not totally off the table; such a feature can still definitely exist, first of all as a userspace combinator:</p><pre><code><span><span>pub</span> async <span><span><span>fn</span> </span><span>must_complete</span></span><span><span>&lt;</span>F<span>:</span> Future<span>&gt;</span></span><span><span><span>(</span><span>fut</span><span>:</span> F</span><span><span><span>)</span></span></span></span><span> <span><span>-&gt;</span> <span><span><span>F</span><span>::</span></span></span>Output</span> </span><span><span><span>{</span>
	MustComplete<span><span>(</span>fut</span><span><span>)</span></span>.await
</span><span><span>}</span></span></span>

<span><span>#</span><span>[</span><span>pin_project</span><span><span><span>(</span></span></span><span><span>PinnedDrop</span></span><span><span><span>)</span></span></span><span>]</span></span>
<span><span>struct</span> </span><span><span><span>MustComplete</span><span><span>&lt;</span>F<span>:</span> Future<span>&gt;</span></span></span></span><span></span><span><span><span>(</span>#[pin] F</span><span>)</span></span><span>;</span>

<span><span>impl</span></span><span><span><span>&lt;</span>F<span>:</span> Future <span>+</span> <span>?</span></span></span><span><span>Drop</span> + <span>async</span> <span>Drop</span>&gt; <span>Future</span> <span>for</span> <span>MustComplete</span><span><span>&lt;</span>F<span>&gt;</span></span> </span><span><span><span>{</span>
	<span>type</span> <span>Output</span> <span>=</span> <span>F<span>::</span></span>Output<span>;</span>

	<span><span><span>fn</span> </span><span>poll</span></span><span><span><span>(</span><span>self</span>: <span>Pin<span>&lt;</span><span>&amp;</span><span>mut</span> <span>Self</span><span>&gt;</span></span>, <span>cx</span><span>:</span> <span>&amp;</span><span>mut</span> <span>task<span>::</span></span><span>Context<span>&lt;</span>&#39;<span>_</span><span>&gt;</span></span></span><span><span><span>)</span></span></span></span><span> <span><span>-&gt;</span> <span>Poll<span>&lt;</span><span><span><span>Self</span><span>::</span></span></span>Output<span>&gt;</span></span></span> </span><span><span><span>{</span>
		<span>self</span>.<span>project</span><span><span>(</span></span><span><span>)</span></span>.<span>0.</span><span>poll</span><span><span>(</span>cx</span><span><span>)</span></span>
	</span><span><span>}</span></span></span>
</span><span><span>}</span></span></span>

<span><span>#</span><span>[</span><span>pinned_drop</span><span>]</span></span>
<span><span>impl</span></span><span><span><span>&lt;</span>F<span>:</span> Future<span>&gt;</span></span></span><span> <span>async</span> <span>PinnedDrop</span> <span>for</span> <span>MustComplete</span><span><span>&lt;</span>F<span>&gt;</span></span> </span><span><span><span>{</span>
	async <span><span><span>fn</span> </span><span>drop</span></span><span><span><span>(</span><span>self</span>: <span>Pin<span>&lt;</span><span>&amp;</span><span>mut</span> <span>Self</span><span>&gt;</span></span></span><span><span><span>)</span></span></span></span><span> </span><span><span><span>{</span>
		<span>self</span>.<span>project</span><span><span>(</span></span><span><span>)</span></span>.<span>0.</span>await<span>;</span>
	</span><span><span>}</span></span></span>
</span><span><span>}</span></span></span>
</span></code></pre><p>Usable like so:</p><pre><code><span><span>must_complete</span><span><span>(</span>async <span><span>{</span>
	<span>some_very_important_work</span><span><span>(</span></span><span><span>)</span></span>.await<span>;</span>
	<span>that_must_not_be_interrupted</span><span><span>(</span></span><span><span>)</span></span>.await<span>;</span>
</span><span><span>}</span></span></span><span><span>)</span></span>
.await<span>;</span>
</span></code></pre><p>It could also exist as a language feature, which would additionally allow removing <code>.await</code> if that is desired. Either way, the effect is the same: this proposal easily enables writing futures that are guaranteed to not have cancellation points. Personally I do not think this use case is common enough to warrant a language feature, but it is still definitely worth considering.</p><p><a href="#">⮬ Back to top</a></p></div></div>
  </body>
</html>
