<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.businessinsider.com/andrew-ng-google-brain-big-tech-ai-risks-2023-10">Original</a>
    <h1>Google Brain cofounder says Big Tech lying about risks of AI</h1>
    
    <div id="readability-page-1" class="page"><div id="piano-inline-content-wrapper" data-piano-inline-content-wrapper=""> 
                    
                    
                    
                          
                          
                          <section data-offer-key="pre-churn-offer" data-component-type="inline-offer" data-place-after-element-selector=".post-content .content-lock-content &gt; p">
                            <article>
                              <img src="https://www.businessinsider.com/public/assets/subscription/marketing/banner-overlay/top-left.svg" alt=""/>
                              <img src="https://www.businessinsider.com/public/assets/subscription/marketing/banner-overlay/bottom-right.svg" alt=""/>
                          
                                        </article>
                          </section>
                    
                    <div data-component-type="content-lock" data-load-strategy="exclude">
                      <div>
                                  <ul><li>Big Tech is lying about some AI risks to shut down competition, a Google Brain cofounder has said.</li><li>Andrew Ng told The Australian Financial Review that tech leaders hoped to trigger strict regulation.</li><li>Some large tech companies didn&#39;t want to compete with open source, he added.</li></ul><div id="formContainer" data-component-type="inline-newsletter-module" data-event-label="insider_today" data-newsletter-id="1" data-list="Insider Today" data-acq-source="techinlinesignup">
                        
                        
                          <section>
                              
                        
                            <p><svg version="1.1" xmlns="http://www.w3.org/2000/svg" role="img" width="50" height="50" viewBox="0 0 50 50" style="enable-background:new 0 0 50 50;" xml:space="preserve">
                          <title>Loading</title>
                          <desc>Something is loading.</desc>
                          <path fill="#111" d="M43.935,25.145c0-10.318-8.364-18.683-18.683-18.683c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615c8.072,0,14.615,6.543,14.615,14.615H43.935z">
                            <animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animateTransform>
                          </path>
                        </svg></p>
                            
                        
                            
                        
                            <div>
                              <p>Thanks for signing up!</p>
                              
                              <p>
                              Access your favorite topics in a personalized feed while you&#39;re on the go.
                                    </p>
                            </div>
                        
                            
                            
                          </section>
                        
                            <div>
                                <p><img src="data:image/svg+xml,%3Csvg xmlns=&#39;http://www.w3.org/2000/svg&#39; viewBox=&#39;0 0 1 1&#39;%3E%3C/svg%3E" data-src="/public/assets/rebrand/newsletter-bull.png" alt="Bull" itemprop="contentUrl"/>
                              
                              
                              
                              </p>    </div>
                        
                          
                        </div><p>A leading AI expert and Google Brain cofounder said Big Tech companies were stoking fears about the technology&#39;s risks to shut down competition.</p><p>Google Brain was a deep-learning AI research team that merged with the DeepMind division earlier this year.</p><p><a target="_blank" href="https://www.businessinsider.com/ai-godfather-top-names-possibilities-dangers-openai-chatgpt-list-2023-8?r=US&amp;IR=T#british-american-computer-scientist-andrew-ng-founded-a-massive-deep-learning-project-called-google-brain-in-2011-9" data-analytics-product-module="body_link" rel="">Andrew Ng</a>, an adjunct professor at Stanford University who taught OpenAI CEO Sam Altman, told The Australian Financial Review that <a target="_blank" href="https://www.afr.com/technology/google-brain-founder-says-big-tech-is-lying-about-ai-human-extinction-danger-20231027-p5efnz" data-analytics-product-module="body_link" rel=" nofollow">the biggest tech companies </a>hoped to trigger strict regulation with the &#34;bad idea that AI could make us go extinct.&#34;</p><p>&#34;There are definitely large tech companies that would rather not have to try to compete with open source, so they&#39;re creating fear of AI leading to human extinction,&#34; he told the news outlet. &#34;It&#39;s been a weapon for lobbyists to argue for legislation that would be very damaging to the open-source community.&#34;</p><p>In May, <a target="_blank" href="https://www.businessinsider.com/ai-extinction-risk-openai-deepmind-anthropic-ceos-sam-altman-2023-5?r=US&amp;IR=T" data-analytics-product-module="body_link" rel="">AI experts and CEOs signed</a> a statement from the Center for AI Safety that compared the risks posed by AI with nuclear war and pandemics. OpenAI CEO <a target="_blank" rel="" href="https://www.businessinsider.com/sam-altman-chatgpt-openai-ceo-career-net-worth-ycombinator-prepper-2023-1" data-analytics-product-module="body_link"><u>Sam Altman</u></a>, DeepMind CEO Demis Hassabis, and Anthropic CEO Dario Amodei all put their names to the public statement.</p><p>Other AI heavyweights have issued several warnings about the <a target="_blank" href="https://www.businessinsider.com/elon-musk-ai-pause-openai-gpt4-powerful-development-2023-3?r=US&amp;IR=T" data-analytics-product-module="body_link" rel="">accelerated development of advanced</a> generative AI models, with many urging regulators to act quickly.</p><p>Governments around the world are <a target="_blank" href="https://www.businessinsider.com/ai-regulation-2023-us-eu-china-100-10?r=US&amp;IR=T" data-analytics-product-module="body_link" rel="">looking to regulate AI</a>, citing concerns over safety, potential job losses, and even the risk of human extinction. The European Union will likely be the first region to enforce oversight or <a target="_blank" rel="" href="https://www.businessinsider.com/us-copyright-office-new-rules-generative-ai-2023-8" data-analytics-product-module="body_link"><u>regulation</u></a> around generative AI.</p><p>Ng said the idea that AI could wipe out humanity could lead to policy proposals that require licensing of AI, which risked crushing innovation. Any necessary AI regulation should be created thoughtfully, he added. </p><p>Ng did not immediately respond to Insider&#39;s request for comment, made outside normal working hours.</p>
                      </div>
                    
                    </div>
                    
                    
                        </div></div>
  </body>
</html>
