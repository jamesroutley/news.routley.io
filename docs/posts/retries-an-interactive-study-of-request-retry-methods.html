<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://encore.dev/blog/retries">Original</a>
    <h1>Retries â€“ An interactive study of request retry methods</h1>
    
    <div id="readability-page-1" class="page"><div><div><div><p>Requests over the network can fail. This is something we cannot avoid, and to
write robust software we need to handle these failures or else they may be
presented to users as errors. One of the most common techniques for handling a
failed request is to retry it.</p><p>In this post we&#39;re going to visually explore different methods of retrying
requests, demonstrating why some common approaches are dangerous and ultimately
ending up at what the best practice is. At the end of this post you will have a
solid understanding of what makes safe retry behaviour, and a vivid
understanding of what doesn&#39;t.</p><p>We&#39;ll be focusing on when you have control over the behaviour of the client.
The advice in this post applies equally to when you&#39;re making requests to your
own backend services or third-party ones. We won&#39;t be covering any server-side
mitigations to the problems described in this post.</p><h2 id="setting-the-stage"><a href="#setting-the-stage">Setting the stage</a></h2><p>Let&#39;s introduce the elements involved in our visualisation. We have:</p><ul><li><span>Requests</span> can be thought of as HTTP requests. They can <span>succeed</span> or <span>fail</span>. <span>Failed</span> <span>requests</span> have spiked edges, <span>successful</span> <span>requests</span> stay smooth.</li><li><span>Load balancers</span> route <span>requests</span> from <span>clients</span> to <span>servers</span>.</li><li><span>Servers</span> accept and serve <span>requests</span>.</li><li><span>Clients</span> send <span>requests</span> to <span>servers</span> via a <span>load balancer</span>. After getting a response, they will <span>wait</span> an amount of time before sending another <span>request</span>.</li></ul><p>Here&#39;s how all of that that looks.</p><p>We have one <span>client</span> sending <span>requests</span> periodically to one <span>server</span>. You could imagine this is a <span>client</span> periodically checking the status of some background
job. The <span>request</span> goes through a <span>load balancer</span> that selects which <span>server</span> to send the <span>request</span>
to. <span>Requests</span> either <span>succeed</span> or <span>fail</span> which you can
see when they&#39;re making their return journey to the <span>client</span>. While the <span>client</span> is <span>waiting</span> to send its next <span>request</span>, it shows as a circular timer.</p><h4 id="adjust-animation-speed"><a href="#adjust-animation-speed"><strong>Adjust animation speed</strong></a></h4><p>If the animations are too fast or too slow for you, feel free to change them
now. This will affect all animations on this page.</p><h2 id="basic-retry-handling"><a href="#basic-retry-handling">Basic retry handling</a></h2><p>The simplest way to handle a <span>failure</span> is to do nothing.
In this visualisation the <span>server</span> is configured to <span>fail</span> 100% of the time, and each <span>client</span> will just <span>wait</span> to send
its next <span>request</span>.</p><p>Not all that exciting. <span>Requests</span> <span>fail</span> and the <span>client</span> just <span>waits</span> to send another. Let&#39;s do what people tend to do when
they check Sentry and notice that they&#39;re serving 503s due to a <span>failed</span> <span>request</span> to a third-party
service: retry 10 times in a tight loop.</p><p>You can see now that when a <span>request</span> <span>fails</span>, it is immediately retried. No <span>
waiting</span>. We&#39;ve configured a 100% failure rate to make the retries easier
to see, but if the failure rate was 5% then the odds of 2 requests failing
back to back is 1 in 400. 3 requests in a row is 1 in 8000. Retries allow you to
trade latency for reliability.</p><p>However, there&#39;s a subtle side-effect of behaving this way. Every time a <span>client</span> retries when it would have otherwise been <span>waiting</span>, an extra <span>request</span> is generated. This increases the overall load to our service.</p><p>Now we&#39;re going to add a few more <span>clients</span> and
introduce some buttons. The buttons control the <span>failure</span>
rate of our <span>servers</span>. For now, we&#39;re just going to
have 0% and 100%. When you&#39;re ready, switch from 0% to 100% and see what happens
to our <span>server</span>.</p><failure-rate-control target="control1" options="0 1"></failure-rate-control><p>If I&#39;m any good at tuning my simulations, you will quickly notice the <span>server</span> <em>explode</em>. Even after you set the <span>failure</span> rate back to 0% and the <span>server</span> has recovered, there&#39;s a chance it will keep
exploding.</p><p>What the explosion represents is a <span>server</span>
overloading and crashing. Then it restarts a few seconds later. This can happen
for all sorts of reasons in the real world, from the process running out of
memory to rare segfaults that only happen under stress. Typically <span>servers</span> will have <span>request</span>
queues that reject <span>requests</span> when the <span>server</span> has too much work to do, but to keep things simple
we&#39;re using overload to represent any potential failure mode.</p><p>Once the <span>server</span> has crashed once, the extra load
created by the retries can make it difficult to recover. When it comes back up,
it might get quickly overwhelmed and crash again. This problem gets worse as you
scale. Let&#39;s add in even more <span>clients</span> and a few more <span>servers</span> to handle the new load.</p><failure-rate-control target="control2" options="0 1"></failure-rate-control><p>What you&#39;re likely to see here is that the moment you switch from a 0% <span>failure</span> rate to 100%, traffic begins to ramp up as <span>clients</span> begin to retry. Eventually, one of the <span>servers</span> will crash. As soon as one <span>server</span> goes, the remaining two will be unable to handle
the new load.</p><p>You&#39;ll notice that setting the <span>failure</span> rate back to 0%
here will likely have no meaningful effect. You may eventually recover, but if
you&#39;re doing retries in a tight loop and you get into this overloaded state it
can be very hard to get back out. In practice, the quickest way to recover is to
add more <span>servers</span> to absorb the load. Once
stabilised, you can spin the extra <span>servers</span> back
down.</p><p>Give that a try in the next visualisation. It&#39;s tuned the same way as the
previous one, but this time there&#39;s an extra toggle that lets you control the
number of <span>servers</span>. Set the <span>failure</span> rate up to 100%, get into an overloaded state, then
set it back down to 0% and gradually add <span>servers</span>
until you&#39;re recovered. How many extra <span>servers</span> do
you need in order to stabilise?</p><failure-rate-control target="control2.1" options="0 1"></failure-rate-control><h2 id="retrying-with-a-delay"><a href="#retrying-with-a-delay">Retrying with a delay</a></h2><p>So retrying in a tight loop is problematic and we&#39;ve seen why. The next thing
people do is to add a delay between each retry. 10 retries with a <code>sleep(1000)</code>
between them. Let&#39;s see how that fares.</p><failure-rate-control target="control3" options="0 1"></failure-rate-control><p>You should notice the same pattern here as with no delay between retries. When
you set the <span>failure rate</span> to 100%, the <span>server</span> will crash shortly after. It may take a bit longer,
but it will happen. If the rate at which your <span>clients</span> retry is not longer than the rate at which they
normally send <span>requests</span>, you will see an increase in
overall load.</p><p>To demonstrate, let&#39;s try a <code>sleep(10000)</code> to wait 10 seconds after a <span>failed</span> <span>request</span>. This wait
is about twice as long as <span>clients</span> usually wait
before sending their next <span>request</span>.</p><failure-rate-control target="control4" options="0 1"></failure-rate-control><p>This &#34;works&#34; insofar as the <span>server</span> is unlikely to
get overloaded, and if it does it is able to recover with ease. But this will
lead to a bad user experience in practice. Users don&#39;t like waiting, and the
longer you sleep between retries, the more likely they are to refresh manually
or go and do something else. Both bad outcomes.</p><h2 id="so-whats-the-answer"><a href="#so-whats-the-answer">So what&#39;s the answer?</a></h2><p>We need a way of retrying that retries quickly in case the error is low
probability, thus protecting the user experience, but recognises when things are
really wrong and waits longer to prevent unrecoverable overload.</p><p>We need &#34;<strong>exponential backoff.</strong>&#34; There are lots of things you can configure
when calculating exponential backoff, but if you imagine we started off waiting
for 1 second and waited twice as long each retry, 10 retries would look like
this:</p><ul><li>1 second</li><li>2 seconds</li><li>4 seconds</li><li>8 seconds</li><li>16 seconds</li><li>32 seconds</li><li>1 minute and 4 seconds</li><li>2 minutes and 8 seconds</li><li>4 minutes and 16 seconds</li><li>8 minutes and 32 seconds</li></ul><p>This would be an enormous amount of time to wait, so in practice exponential
backoff is tuned to start lower than 1 second, and often has a lower multiplier.
Google&#39;s <a href="https://cloud.google.com/java/docs/reference/google-http-client/1.43.0/com.google.api.client.util.ExponentialBackOff" rel="nofollow" target="_blank">Java HTTP Client Library</a>, for example, starts at 0.5 seconds and
has a multiplier of 1.5. This yields the following retry intervals:</p><ul><li>0.5 seconds</li><li>0.75 seconds</li><li>1.125 seconds</li><li>1.687 seconds</li><li>2.53 seconds</li><li>3.795 seconds</li><li>5.692 seconds</li><li>8.538 seconds</li><li>12.807 seconds</li><li>19.210 seconds</li></ul><p>Enough mathematics, how does this look in practice? All of the following
examples use the Google HTTP library backoff defaults (0.5 second initial delay,
1.5 multiplier).</p><failure-rate-control target="control5" options="0 1"></failure-rate-control><p>As soon as you flip over to 100% <span>failure</span> rate you&#39;ll
notice the usual ramp up in <span>requests</span>, but as those <span>requests</span> are retried you will then notice that the
backoff kicks in and things calm down. The <span>server</span>
may crash but the <span>clients</span> give it space to recover.
When you flip back to 0% <span>failure</span> rate, the <span>server</span> is able to return to normal service quickly.</p><p>For fun, let&#39;s also see it in action at scale. I&#39;m going to give you some more <span>failure</span> rates to play with, too. Go wild.</p><failure-rate-control target="control6" options="0 0.2 0.4 0.6 0.8 1"></failure-rate-control><p>You may have struggled to get any of the <span>servers</span> to
crash in this example, even at a 100% <span>failure</span> rate.
This is exponential backoff at work, helping your <span>clients</span> recognise trouble and getting them to give your <span>servers</span> space to recover.</p><h2 id="jitter"><a href="#jitter">Jitter</a></h2><p>We&#39;ve seen the power of exponential backoff at work, but there&#39;s one last thing
we can do with our retries to make them truly best practice.</p><p>&#34;Jitter&#34; is the process of randomising how long we wait between retries to
within a specific range. To follow the Google HTTP client library example, they
add 50% jitter. So a retry interval can be between 50% lower and 50% higher than
the calculated figure. Here&#39;s how that affects our numbers from before:</p><ul><li>0.5 seconds, Â± 0.25 seconds</li><li>0.75 seconds, Â± 0.375 seconds</li><li>1.125 seconds, Â± 0.5625 seconds</li><li>1.687 seconds, Â± 0.8435 seconds</li><li>2.53 seconds, Â± 1.265 seconds</li><li>3.795 seconds, Â± 1.8975 seconds</li><li>5.692 seconds, Â± 2.846 seconds</li><li>8.538 seconds, Â± 4.269 seconds</li><li>12.807 seconds, Â± 6.4035 seconds</li><li>19.210 seconds, Â± 9.605 seconds</li></ul><p>This jitter helps prevent <span>clients</span> from synchronising
with each other and sending surges of <span>requests</span>.</p><h2 id="putting-this-in-to-code"><a href="#putting-this-in-to-code">Putting this in to code</a></h2><p>So you&#39;ve read this post and realised you&#39;re either not making use of retries,
or you&#39;re doing them dangerously. Here&#39;s some example Go code that implements
the retry strategy we&#39;ve built up to, exponential backoff with jitter, that you
can use in your own projects.</p><pre><div><p><code><span>package</span> main

<span>import</span> (
	<span>&#34;encoding/json&#34;</span>
	<span>&#34;fmt&#34;</span>
	<span>&#34;net/http&#34;</span>
	<span>&#34;time&#34;</span>

	<span>&#34;github.com/cenkalti/backoff/v4&#34;</span>
)

<span><span>func</span> <span>main</span><span>()</span></span> {
	bo := backoff.NewExponentialBackOff()
	bo.InitialInterval = <span>500</span> * time.Millisecond
	bo.Multiplier = <span>1.5</span>
	bo.RandomizationFactor = <span>0.5</span>

	err := backoff.Retry(<span><span>func</span><span>()</span></span> <span>error</span> {
		resp, err := http.Get(<span>&#34;https://jsonplaceholder.typicode.com/todos/1&#34;</span>)
		<span>if</span> err != <span>nil</span> {
			<span>return</span> err
		}
		<span>defer</span> resp.Body.Close()

		<span>var</span> result <span>map</span>[<span>string</span>]<span>interface</span>{}
		<span>if</span> err := json.NewDecoder(resp.Body).Decode(&amp;result); err != <span>nil</span> {
			<span>return</span> err
		}

		fmt.Printf(<span>&#34;%+v\n&#34;</span>, result)
		<span>return</span> <span>nil</span>
	}, bo)

	<span>if</span> err != <span>nil</span> {
		fmt.Println(<span>&#34;Request failed:&#34;</span>, err)
	}
}
</code></p></div></pre><h2 id="wrapping-up"><a href="#wrapping-up">Wrapping Up</a></h2><p>I hope that this post has helped visually cement how different retry behaviours
work in practice, and given you a good, intuitive understanding of the failure
modes. We can&#39;t always prevent failure, but we can set ourselves up to have the
best chance of recovering when it does happen.</p><p>To recap what we&#39;ve learned:</p><ul><li><strong>Retrying in a tight loop is dangerous.</strong> You risk getting into overload
situations that are difficult to recover from.</li><li><strong>Retrying with a delay</strong> helps a little bit but is still <strong>dangerous.</strong></li><li><strong>Exponential backoff</strong> is a much safer way of retrying, balancing user
experience with safety.</li><li><strong>Jitter</strong> adds an extra layer of protection, preventing clients from sending
synchronised surges of requests.</li></ul><p>If you have questions or feedback, please reach out on
<a href="https://encore.dev/slack">Slack</a>, via email at
<a href="https://healeycodes.com/cdn-cgi/l/email-protection#2b434e4747446b4e454844594e054f4e5d"><span data-cfemail="1b737e7777745b7e757874697e357f7e6d">[emailÂ protected]</span></a>, or
<a href="https://twitter.com/encoredotdev" rel="nofollow" target="_blank">@encoredotdev</a> on Twitter.</p><p><i><p>  Sam Rose has been programming professionally for over 10 years, with a focus
on the backend and SRE domains. He has worked at a wide range of companies, from
large ones like Google to smaller ones like Nebula.</p><p>  If you enjoyed this post, Sam has a collection of similarly visual and
interactive posts on his <a href="https://samwho.dev" rel="nofollow" target="_blank">personal site</a>. He has written
about <a href="https://samwho.dev/hashing" rel="nofollow" target="_blank">hashing</a>, <a href="https://samwho.dev/memory-allocation" rel="nofollow" target="_blank">memory
allocation</a>, and <a href="https://samwho.dev/load-balancing" rel="nofollow" target="_blank">load
balancing</a> so far, with more planned.</p><p>  To keep up to date with his work you can follow him on
<a href="https://twitter.com/samwhoo" rel="nofollow" target="_blank">Twitter</a>, and if you want to support what he does
he also has <a href="https://patreon.com/samwho" rel="nofollow" target="_blank">Patreon</a>.</p></i></p><h2 id="playground"><a href="#playground">Playground</a></h2><p>As a final treat, here&#39;s the visualisation with the debug UI exposed so that you
can tweak all of the parameters in whatever way you like. Enjoy ðŸ˜„</p></div></div></div></div>
  </body>
</html>
