<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://tutanota.com/blog/posts/eu-csam-scanning/">Original</a>
    <h1>Data shows that the EU&#39;s CSAM scanning will not have the intended effect</h1>
    
    <div id="readability-page-1" class="page"><p>In its draft law to combat child sexual abuse, the EU Commission describes one of the most sophisticated mass 
surveillance apparatuses ever deployed outside China: CSAM scanning on everybody&#39;s devices. 
As an email service we regularly receive monitoring orders from German authorities. We have analyzed this
data to find out whether monitoring orders are issued to prosecute child molesters.
</p><div><div><h2 id="csam-scanning">CSAM scanning</h2>
<p>The EU Commission&#39;s draft regulation on preventing and combating child abuse is a frontal attack on civil rights. And 
the EU Commission is pushing for this draft to become law with Trump-like exaggerations.</p>
<p>As citizens we can expect more from the EU Commission. The least we can ask for when the Commission wants to introduce 
surveillance mechanisms that will immensely weaken Europe’s cybersecurity would be honest communication.</p>
<p>No one denies that child sexual abuse is a big issue that needs to be addressed. But when proposing such drastic 
measures like CSAM scanning of every private chat message, the arguments must be sound. Otherwise, the EU Commission is not helping 
anyone – not the children, and not our free, democratic societies.</p>
<p>The EU Commission has managed to push three arguments into the public debate to swing the public opinion in favor
of scanning for CSA material on every device. But the arguments are blatantly wrong:</p>
<ol>
<li>One in Five: The EU Commission claims that One in Five children in the EU would be sexually abused.</li>
<li>AI-based surveillance would not harm our right to privacy, but save the children.</li>
<li>90 % of CSAM would be hosted on European servers</li>
</ol>
<p>The EU Commission uses the ‘One in Five’ claim to justify the proposed general mass surveillance of all European citizens.</p>
<p>Yes, child abuse is an immense problem. Every expert in the field of child protection will agree that politics need to do 
more to protect the most vulnerable in our society: children.</p>
<p>Nevertheless, the question of proportion must be looked at very closely when it comes to CSAM scanning on our personal devices: 
<strong>Is it okay that the EU introduces mass 
surveillance mechanisms for all EU citizens in an attempt to tackle child sexual abuse?</strong></p>
<p>To find an answer to this question, I would like to ask the EU Commission several questions:</p>
<h3 id="1-one-in-five">1. One in Five</h3>
<h4 id="where-does-the-number-one-in-five-come-from">Where does the number ‘One in Five’ come from?</h4>
<p>There is no statistic to be found that supports the ‘One in Five’ claim. This figure is prominently put on a website 
by the <a href="https://human-rights-channel.coe.int/stop-child-sexual-abuse-in-sport-en.html">Council of Europe</a>, 
but without giving any source.</p>
<p>According to the <a href="https://www.stop-child-abuse.net/child-abuse-in-europe/">World Health Organization (WHO)</a> 9.6% of children 
worldwide are sexually abused. Contrary to the EU figures, this data is based on a study, an analyses of community surveys.</p>
<p>Nevertheless, let’s ignore the European Commission’s exaggeration of affected children as the number published by the WHO is still 
very high and must be addressed. </p>
<p>The WHO number suggests that more than 6 million children in the EU suffer from sexual abuse.</p>
<p>Consequently, we can agree that the EU must do something to stop child sexual abuse. </p>
<h3 id="2-can-surveillance-help-tackle-child-abuse">2. Can surveillance help tackle child abuse?</h3>
<h4 id="where-does-the-abuse-take-place">Where does the abuse take place?</h4>
<p>Another question that is very important when introducing surveillance measures to tackle child sexual abuse is the 
one of effectiveness.</p>
<p><strong>If monitoring of our private communication (CSAM scanning) would help save millions of children in Europe from sexual abuse, many 
people would agree to the measure. But would that actually be the case?</strong></p>
<p>On the same website that the EU Commission claims that ‘1 in 5’ children are affected, they also say that <strong>“Between 70% 
and 85% of children know their abuser. The vast majority of children are victims of people they trust.”</strong></p>
<p>This begs the question: <strong>How, just how, is scanning for CSAM on every chat message going to help prevent child sexual 
abuse within the family, the sports club or the church?</strong></p>
<p>The EU Commission leaves this question unanswered.</p>
<h4 id="how-many-monitoring-orders-are-about-protecting-children">How many monitoring orders are about protecting children?</h4>
<p>To find out whether monitoring of private messages for CSA material may help tackle child sexual abuse, we must take a look at actual 
monitoring data that is already available.</p>
<p>As an email provider based in Germany we have such data. Our <a href="https://tutanota.com/blog/posts/transparency-report">transparency report</a> 
shows that we are regularly receiving valid telecommunications surveillance orders from German authorities to prosecute 
potential criminals. </p>
<p>One could think that Tutanota as a privacy-focused, end-to-end encrypted email service would be the go-to place for 
criminal offenders, for instance for sharing CSAM. In consequence, one would expect the number of court orders issued 
in regard to “child pornography” to be high.</p>
<p><strong>In 2021 we received ONE telecommunications surveillance order based on suspicion that the account was used in regard 
to “child pornography”.</strong></p>
<p>This is 1,3% of all orders that we received in 2021. More than two thirds of orders were issued in regard to “ransomware”; 
a few individual cases in regard to copyright infringement, preparation of serious crimes, blackmail and terror.</p>
<p>Numbers <a href="https://www.bundesjustizamt.de/DE/Themen/Buergerdienste/Justizstatistik/Telekommunikation/Telekommunikationsueberwachung_node.html">published</a> 
by the German Federal Office of Justice paint a similar picture: In Germany, more than 47.3 per cent of the measures 
for the surveillance of telecommunications according to § 100a StPO were ordered to find suspects of drug related offenses 
in 2019. <strong>Only 0.1 per cent of the orders - or 21(!) in total - where issued in relation to “child pornography”.</strong></p>
<p><img alt="Comparison of the percentage of wiretap orders for child pornography (CSAM) and drug offenses in Germany, 2009-2019." src="https://tutanota.com/blog/images/wiretap/wiretap-orders-germany.png"/></p><p>In 2019, there were 13.670 cases of child abuse according to the 
<a href="https://www.bmi.bund.de/SharedDocs/downloads/DE/publikationen/themen/sicherheit/pks-2019.pdf?__blob=publicationFile&amp;v=10">statistic of the German Federal Ministry of the Interior</a>
in Germany. </p>
<p><strong>If we take these numbers together, there were 13.670 children abused in Germany in 2019. In only 21 of these cases a 
telecommunications surveillance order was issued.</strong></p>
<p>It becomes obvious that the monitoring of telecommunications (which is already possible) does not play a significant 
role to track down perpetrators.</p>
<p><strong>The conclusion here is obvious: ‘More surveillance’ will not bring ‘more security’ to the children in Europe.</strong> </p>
<h3 id="3-europe---a-hub-for-csam">3. Europe - a hub for CSAM?</h3>
<p><strong>Similarly to the ‘One in Five’ claim, the EU Commission claims that 90% of child sexual abuse material is hosted on 
European servers. Again the EU Commission uses this claim to justify its planned CSAM scanning.</strong> </p>
<p>However, even experts in this field, the German eco Association that works together with the authorities to take down
CSAM (Child Sexual Abuse Material), <a href="https://www.heise.de/news/Meldestelle-zur-EU-Chatkontrolle-Freifahrtschein-fuer-staatliche-Ueberwachung-7091843.html">state</a> 
that “in their estimation, the numbers are a long way from the claimed 90 percent”.
Alexandra Koch-Skiba of the eco Association also 
<a href="https://www.spiegel.de/netzwelt/netzpolitik/eu-will-chats-im-kampf-gegen-kindesmissbrauch-durchleuchten-buergerrechtler-sind-alarmiert-a-3d2e4f66-4a2e-4171-a1ee-97f52ee6a889">says</a>: 
&#34;In our view, the draft has the potential to create a free pass for government surveillance. <strong>This is ineffective and illegal. 
Sustainable protection of children and young people would instead require more staff for investigations and comprehensive prosecution.</strong>&#34;</p>
<p>Even German law enforcement officials are 
<a href="https://www.spiegel.de/netzwelt/netzpolitik/eu-will-chats-im-kampf-gegen-kindesmissbrauch-durchleuchten-buergerrechtler-sind-alarmiert-a-3d2e4f66-4a2e-4171-a1ee-97f52ee6a889">criticizing</a> 
the EU plans behind closed doors. They argue that there would be other ways to track down more offenders. &#34;If it&#39;s just
about having more cases and catching more perpetrators, then you don&#39;t need such an encroachment on fundamental rights,&#34; 
says another longtime child abuse investigator.</p>
<h3 id="trump-like-argumentation">Trump-like argumentation</h3>
<p><strong>It is unbelievable that the EU Commission uses these exaggerations to swing the public opinion in favor of CSAM scanning. It 
looks like the argument ‘to protect the children’ is used to introduce Chinese-like surveillance mechanisms. Here in Europe.</strong></p>
<h4 id="but-europe-is-not-china">But Europe is not China.</h4>
</div></div></div>
  </body>
</html>
