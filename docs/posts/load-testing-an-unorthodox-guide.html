<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.marcobehler.com/guides/load-testing">Original</a>
    <h1>Load Testing: An Unorthodox Guide</h1>
    
    <div id="readability-page-1" class="page"><div>
<div>
<h3 id="_basic_load_testing_data">Basic Load Testing Data</h3>
<p>At a minimum, you should record the data in the following sections.</p>
<p>This doesn’t mean you immediately have to dive into complex tools, monitoring solutions and dashboards like <a href="https://docs.microsoft.com/en-us/azure/azure-monitor/app/app-insights-overview">Azure’s App Insights</a>, <a href="https://prometheus.io/">Prometheus</a> and <a href="https://www.elastic.co/kibana/">Kibana</a>.</p>
<p>Instead, you can start by writing a couple of lines of code that record e.g. your REST clients&#39; response times and convert those to a <a href="http://hdrhistogram.org/">HdrHistogram</a>. To see the corresponding code for all the graphs &amp; diagrams in this article, check out <a href="https://github.com/marcobehler/high-performance-java.git">PerformanceTest.java in my repo</a> and the <a href="https://github.com/jetty-project/jetty-perf">Jetty Perf Project</a>.</p>
<div>
<h4 id="_latencies">Latencies</h4>
<p>You’ll want <strong>your probe</strong> to record its request-response times for every test run and then figure out how the latencies changed across runs, once you start cranking up the load.</p>
<p>For that, it makes sense to not just record raw data (e.g. calling the <code><em>/tax_rate</em></code> endpoint of my REST application took [50ms, 51ms, 37ms, 49ms, …​, etc]), but to visualize those response rates in a <a href="http://hdrhistogram.org/">High Dynamic Range Histogram</a>.</p>
<p>Here’s a histogram that shows the probe’s latencies across multiple (in microseconds, divide by 1000 to get ms) load test runs, where loaders hammered the server from 1000 RPS → 50000 RPS.</p>
<p><img loading="lazy" src="https://www.marcobehler.com/images/guides/load_testing/latencies_histogram-506f3b50.png"/></p><p>The histogram, with just a single glance, will give you a quick idea of what your response time percentiles (90%, 99% etc..) look like and also how those response times change, with varying loads.</p>
</div>
<div>
<h4 id="_throughput">Throughput</h4>
<p>You’ll also want to have a general overview of the throughput of both, your loaders and your server and again, visualize the raw data in a line chart.</p>
<p>If you tell your loaders to send 4000 requests per second to the server, the throughput (i.e. sending those 4000 requests <em>every second</em> ) should, in fact, be 4000 requests per second, and not just 2314 requests. Which will result in a pretty constant line chart like seen below.</p>
<p><img loading="lazy" src="https://www.marcobehler.com/images/guides/load_testing/loader_throughput-071fee31.png"/></p><p>If that chart doesn’t look level, it means your loaders had issues generating that many requests and you must reduce the load and possibly spawn new ones.</p>
<p>Similarly, if your loaders are doing just fine, but your servers throughput chart looks like this:</p>
<p><img loading="lazy" src="https://www.marcobehler.com/images/guides/load_testing/server_throughput-d8b37752.png"/></p><p>You immediately know that your server has issues responding to that many requests, is definitely at its limit in one regard or another and you’ll need to cross-check with all the CPU/memory/application data below to find out what the culprit is.</p>
</div>
<div>
<h4 id="_http_status_codes">HTTP Status Codes</h4>
<p>This sounds so simple, but if forgotten leads to wrong conclusions. For every HTTP request that is sent during your load test, you should record its HTTP response status code. Was it all 200s? Good.</p>
<p>Were there bad requests (400s), because an API changed, or maybe even server errors (500s), because a pesky bug entered the backend? Then you’ll need to throw away your test results and re-run the test.</p>
<div>
<div>
<pre><code data-lang="text">[0]
252=200

[1]
248=200

[2]
250=200

[3]
251=200

[4]
250=200

[5]
250=200

...</code></pre>
</div>
</div>
<p>Above you’ll see a custom text format (taken from the <a href="https://github.com/jetty-project/jetty-perf">Jetty Perf Project</a>), that’ll quickly display all the status codes of all HTTP requests that were issued in a specific second of the test.</p>
<p>This is how you read those lines, e.g.</p>

<div>
<ul>
<li>
<p>[0]: The first second of the load test</p>
</li>
<li>
<p>252: Number of HTTP requests that were sent</p>
</li>
<li>
<p>200: Came back with Status Code 200</p>
</li>
</ul>
</div>
</div>
</div>
<div>
<h3 id="_os_metrics_big_picture">OS Metrics: Big Picture</h3>
<p>To find out if any of your participants (loaders, servers, probe) behaved or maybe were overloaded during your test run, you’ll need to record operating system metrics <em>for</em>.<em>every</em>.<em>single</em>.<em>participant</em> of the test.</p>
<div>
<h4 id="_cpu">CPU</h4>
<p>This will depend on your operating system, but if you are e.g. using Linux machines, you can gather data on your CPU in specific intervals with the <a href="https://linux.die.net/man/1/mpstat">mpstat</a> command (5s intervals in this case)</p>

<p>Assuming this command ran for 15 seconds (3 intervals a 5s) on a machine with 4 CPUs, you’d get output like this:</p>
<div>
<div>
<pre><code data-lang="console"><span>08:39:46     CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
08:39:46     all    9.15    0.00    7.31    0.01    0.00    1.22    0.00    0.00    0.00   82.31
08:39:46       0   12.64    0.00    8.95    0.00    0.00    0.99    0.00    0.00    0.00   77.42
08:39:46       1    5.25    0.00    3.87    0.00    0.00    5.99    0.00    0.00    0.00   84.90
08:39:46       2    7.70    0.00    6.70    0.00    0.00    0.00    0.00    0.00    0.00   85.60
08:39:46       3    7.77    0.00    6.68    0.00    0.00    0.09    0.00    0.00    0.00   85.46


08:39:56     CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
08:39:56     all    7.66    0.00    6.57    0.00    0.00    0.64    0.00    0.00    0.00   85.12
08:39:56       0   11.24    0.00    8.47    0.00    0.00    0.25    0.00    0.00    0.00   80.03
08:39:56       1    4.27    0.00    4.65    0.00    0.00    3.42    0.00    0.00    0.00   87.67
08:39:56       2    5.40    0.00    5.12    0.00    0.00    0.00    0.00    0.00    0.00   89.48
08:39:56       3    9.23    0.00    8.46    0.00    0.00    0.09    0.00    0.00    0.00   82.23


08:40:06     CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
08:40:06     all    7.51    0.00    6.12    0.00    0.00    0.71    0.01    0.00    0.00   85.65
08:40:06       0    8.90    0.00    6.32    0.00    0.00    0.27    0.09    0.00    0.00   84.43
08:40:06       1    7.60    0.00    5.65    0.00    0.00    3.00    0.00    0.00    0.00   83.75
08:40:06       2    5.60    0.00    5.60    0.00    0.00    0.00    0.00    0.00    0.00   88.80
08:40:06       3    9.26    0.00    7.95    0.00    0.00    0.09    0.00    0.00    0.00   82.71</span></code></pre>
</div>
</div>
<p>Every table above corresponds to a CPU load snapshot, either across <em>all</em> CPUs (averaged), or the individual CPUs (0,1,2,3 = 4 CPUs).</p>
<div>
<div>
<pre><code data-lang="console"><span>08:39:46     CPU    %usr   %nice    %sys %iowait    %irq   %soft  %steal  %guest  %gnice   %idle
08:39:46     all    9.15    0.00    7.31    0.01    0.00    1.22    0.00    0.00    0.00   82.31
08:39:46       0   12.64    0.00    8.95    0.00    0.00    0.99    0.00    0.00    0.00   77.42
08:39:46       1    5.25    0.00    3.87    0.00    0.00    5.99    0.00    0.00    0.00   84.90
08:39:46       2    7.70    0.00    6.70    0.00    0.00    0.00    0.00    0.00    0.00   85.60
08:39:46       3    7.77    0.00    6.68    0.00    0.00    0.09    0.00    0.00    0.00   85.46
</span></code></pre>
</div>
</div>
<p>For a quick &amp; dirty start you can simply take the inverse of the <code><em>%idle</em></code> column from the <code><em>all</em></code> line, to find out how busy your CPUs on average were during that snapshot (e.g. 100%-82.31% = 17,69%).</p>
<p>Though you naturally want to also have a look at individual CPU performance, especially for scenarios where only one of your CPUs was maxed out, while all others were idling.</p>
</div>
<div>
<h4 id="_network">Network</h4>
<p>Again, depending on your operating system you’ll want to gather snapshots of your network traffic with different commands. On Linux, you could be using the <a href="https://linux.die.net/man/1/sar">sar tool</a> for network snapshots every 5 seconds.</p>

<p>The output will be a file like this, where two tables correspond to one snapshot.</p>
<div>
<div>
<pre><code data-lang="console"><span>08:39:36        IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s   %ifutil
08:39:46           lo     12.30     12.30      1.62      1.62      0.00      0.00      0.00      0.00
08:39:46         ens5   5006.90   5094.00   1208.58    890.41      0.00      0.00      0.00      0.00

08:39:36        IFACE   rxerr/s   txerr/s    coll/s  rxdrop/s  txdrop/s  txcarr/s  rxfram/s  rxfifo/s  txfifo/s
08:39:46           lo      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00
08:39:46         ens5      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00

08:39:46        IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s   %ifutil
08:39:56           lo      3.70      3.70      0.49      0.49      0.00      0.00      0.00      0.00
08:39:56         ens5   5003.80   5114.30   1207.87    891.30      0.00      0.00      0.00      0.00

08:39:46        IFACE   rxerr/s   txerr/s    coll/s  rxdrop/s  txdrop/s  txcarr/s  rxfram/s  rxfifo/s  txfifo/s
08:39:56           lo      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00
08:39:56         ens5      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00

08:39:56        IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s   %ifutil
08:40:06           lo      4.00      4.00      0.51      0.51      0.00      0.00      0.00      0.00
08:40:06         ens5   4928.50   5019.20   1189.49    876.60      0.00      0.00      0.00      0.00

08:39:56        IFACE   rxerr/s   txerr/s    coll/s  rxdrop/s  txdrop/s  txcarr/s  rxfram/s  rxfifo/s  txfifo/s
08:40:06           lo      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00
08:40:06         ens5      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00      0.00</span></code></pre>
</div>
</div>
<p>Important are the columns <code><em>rxkB/s</em></code>, as well as <code><em>txkB/s</em></code>, which, if multiplied by 0.008, give you the megabits of data your network interfaces receives per second, as well as it sends out.</p>
<div>
<div>
<pre><code data-lang="console"><span>08:39:36        IFACE   rxpck/s   txpck/s    rxkB/s    txkB/s   rxcmp/s   txcmp/s  rxmcst/s   %ifutil
08:39:46           lo     12.30     12.30      1.62      1.62      0.00      0.00      0.00      0.00
08:39:46         ens5   5006.90   5094.00   1208.58    890.41      0.00      0.00      0.00      0.00</span></code></pre>
</div>
</div>
<p>Looking at the second snapshot above that would be</p>
<div>
<ul>
<li>
<p>1207.87 rxkB/s * 0,008 = 9.66 Megabit - quite a lot of room left, if you have a 100Mbit network interface.</p>
</li>
<li>
<p>891.30  txkB/s * 0.008 = 7.12 Megabit</p>
</li>
</ul>
</div>
<p>(Do note that networks adapters are usually duplex, hence if you have a 100MBit interface, you’re not only able to do just 50Mbit/50 Mbit.)</p>
</div>
<div>
<h4 id="_memory">Memory</h4>
<p>All the concepts mentioned above for CPU and network are also valid for memory. On Linux machines, you can capture memory snapshots every 5 seconds with the <a href="https://linux.die.net/man/1/free">free tool</a>.</p>

<p>You’ll receive output like this, again, each table corresponding to a specific snapshot.</p>
<div>
<div>
<pre><code data-lang="console"><span>              total        used        free      shared  buff/cache   available
Mem:           30Gi       504Mi        29Gi       0.0Ki       519Mi        30Gi
Swap:            0B          0B          0B

              total        used        free      shared  buff/cache   available
Mem:           30Gi       655Mi        29Gi       0.0Ki       519Mi        29Gi
Swap:            0B          0B          0B

              total        used        free      shared  buff/cache   available
Mem:           30Gi       661Mi        29Gi       0.0Ki       519Mi        29Gi
Swap:            0B          0B          0B
</span></code></pre>
</div>
</div>
<p>On a glance, you’ll see how much memory was <code><em>free</em></code>/<code><em>used</em></code>, from the total available amount.</p>
</div>
<div>
<h4 id="_io">I/O</h4>
<p>Will be added in the next revision of the guide.</p>
</div>
</div>
<div>
<h3 id="_application_metrics_detailed_picture">Application Metrics: Detailed Picture</h3>
<p>Apart from big picture data, you’ll also want to be able to have a closer look at what’s going on <em>inside</em> of your application. For that, you can collect the following data:</p>
<div>
<h4 id="_business_logic_execution_time">Business Logic Execution Time</h4>
<p>This depends a bit on the web server &amp; frameworks you are using, but essentially, you’d want to collect response times for requests <em>excluding</em> client latency and <em>excluding</em> parts of the system you cannot influence, e.g. your web server’s HTTP request handling.</p>
<p>In short: How much execution time does your business logic take? How long does your controller need to prepare a JSON response from an SQL query?</p>
<p>Again, you’ll want to visualize the data in a histogram, to get a quick understanding of request latencies and percentiles, across test runs.</p>
<p><img loading="lazy" src="https://www.marcobehler.com/images/guides/load_testing/execution_time-ddba322a.png"/>
</p></div>
<div>
<h4 id="_flame_graphs_cpumemory">Flame Graphs: CPU/Memory</h4>
<p>In simple terms, <a href="https://www.brendangregg.com/flamegraphs.html">Flame Graphs</a> allow you to visualize where your application, or rather its code paths, spends its CPU &amp; memory.</p>
<p>The example below is a Java CPU flame graph, though you can generate them for a variety of programming ecosystems and flame graphs not only show you your application’s code paths (green color), but also where CPU/memory is spent in terms of the JVM/C++ (yellow), operating system (red) and even the kernel (orange).</p>
<p><img loading="lazy" src="https://www.marcobehler.com/images/guides/load_testing/flamegraph-9e20f411.png"/></p>
</div>
<div>
<h4 id="_jhiccup_gc_collection_files_jvm_specific">JHiccup / GC Collection files (JVM specific)</h4>
<p>For garbage-collection platforms like the JVM, it also makes sense to record garbage collection logs and/or use an instrumentation tool like <a href="https://github.com/giltene/jHiccup">jHiccup</a>, which records JVM stalls.</p>
<p>Graphs/Examples will be added in the next revision of the guide.</p>
</div>
</div>
</div></div>
  </body>
</html>
