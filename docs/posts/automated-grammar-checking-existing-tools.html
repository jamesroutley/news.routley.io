<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="http://iafisher.com/blog/2024/06/grammar-checking-existing-tools">Original</a>
    <h1>Automated grammar checking: existing tools</h1>
    
    <div id="readability-page-1" class="page"><div class="page">
  
  

  <p><a href="https://iafisher.com/blog/2024/05/proposal-english-typechecker">My last post</a> proposed a command-line program to automatically check that a written text is grammatically correct – in software engineering terms, a &#34;type-checker&#34; for English prose. I further proposed that such a program should be <em>rule-based</em> rather than statistical.</p>
<p>Before embarking on writing such a program myself, I tried out the grammar checkers that already exist. These are my findings. The one-sentence summary is that I could not find an existing tool that meets my requirements. For the details, read on.</p>
<h2>Test sentences</h2>
<p>I used four ungrammatical sentences to test existing tools:</p>
<ol>
<li>One thing I am enthusiastic about tutoring.<ul>
<li>Missing &#39;is&#39; after &#39;about&#39;</li>
</ul>
</li>
<li>A one-on-one session is some of the best ways to help.<ul>
<li>&#39;some of&#39; should be &#39;one of&#39;</li>
</ul>
</li>
<li>Rust has excellent support for co-routines, which we are being actively developing.<ul>
<li>&#39;we are being&#39; should be &#39;we are&#39;</li>
</ul>
</li>
<li>We chose this particular algorithms since it is both work-conserving and has a special mechanism for low-latency wake-up of a domain when it receives an event.<ul>
<li>&#39;algorithms&#39; should be &#39;algorithm&#39;</li>
</ul>
</li>
</ol>
<p>I either made these typos myself, or spotted them in published text.</p>
<p>#1 is potentially tricky to catch because the substring on its own (&#34;I am enthusiastic about tutoring&#34;) is correct. #2 is an example of more complicated subject–object agreement. #3 and #4 are simpler mistakes (auxiliary verb agreement, &#39;this&#39; vs. &#39;these&#39;) but have some intervening words which could confuse simplistic checkers. #3 is more challenging to correct because the obvious substitution, &#39;developed&#39; for &#39;developing&#39;, is incompatible with the &#39;which&#39; at the beginning of the clause.</p>
<p>This is far from an exhaustive test. But I do think it is enough to get a rough impression of how good a grammar checker is.</p>
<h2>Existing tools</h2>
<p>I ran the test sentences through 8 grammar-checking tools.</p>
<p>Detection:</p>
<table>
<thead>
<tr>
<th>Tool</th>
<th>#1</th>
<th>#2</th>
<th>#3</th>
<th>#4</th>
</tr>
</thead>
<tbody>
<tr>
<td>Grammarly</td>
<td>yes</td>
<td>no</td>
<td>yes</td>
<td>yes</td>
</tr>
<tr>
<td>ProWritingAid</td>
<td>yes</td>
<td>no</td>
<td>no</td>
<td>no</td>
</tr>
<tr>
<td>Ginger</td>
<td>no</td>
<td>no</td>
<td>yes</td>
<td>yes</td>
</tr>
<tr>
<td>LanguageTool (online)</td>
<td>yes</td>
<td>yes</td>
<td>yes</td>
<td>yes</td>
</tr>
<tr>
<td>LanguageTool (open-source)</td>
<td>no</td>
<td>no</td>
<td>no</td>
<td>no</td>
</tr>
<tr>
<td>Google Docs</td>
<td>no</td>
<td>no</td>
<td>yes</td>
<td>yes</td>
</tr>
<tr>
<td>Microsoft Word</td>
<td>no</td>
<td>no</td>
<td>no</td>
<td>yes</td>
</tr>
<tr>
<td>Vale</td>
<td>no</td>
<td>no</td>
<td>no</td>
<td>no</td>
</tr>
</tbody>
</table>
<p>Correction (left blank if it did not detect the error in the first place):</p>
<table>
<thead>
<tr>
<th>Tool</th>
<th>#1</th>
<th>#2</th>
<th>#3</th>
<th>#4</th>
</tr>
</thead>
<tbody>
<tr>
<td>Grammarly</td>
<td>yes</td>
<td></td>
<td>yes</td>
<td>no</td>
</tr>
<tr>
<td>ProWritingAid</td>
<td>yes</td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Ginger</td>
<td></td>
<td></td>
<td>no</td>
<td>yes</td>
</tr>
<tr>
<td>LanguageTool (online)</td>
<td>yes</td>
<td>yes</td>
<td>yes</td>
<td>yes</td>
</tr>
<tr>
<td>LanguageTool (open-source)</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td>Google Docs</td>
<td></td>
<td></td>
<td>yes</td>
<td>yes</td>
</tr>
<tr>
<td>Microsoft Word</td>
<td></td>
<td></td>
<td></td>
<td>yes</td>
</tr>
<tr>
<td>Vale</td>
<td></td>
<td></td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p><a href="https://grammarly.com">Grammarly</a>,  <a href="https://prowritingaid.com/">ProWritingAid</a>, <a href="https://www.gingersoftware.com/proofreading">Ginger Proofreading</a> and the online version of <a href="https://languagetool.org/">LanguageTool</a> are all proprietary commercial services, so they wouldn&#39;t work for my purposes, but I included them in the comparison anyway. The subset of LanguageTool&#39;s engine that is available as free software is listed separately. It powers <a href="https://valentjn.github.io/ltex/index.html">ltex-ls</a> and <a href="https://caderek.github.io/gramma/">Gramma</a>. Google Docs and Microsoft Word have built-in grammar checkers. <a href="https://vale.sh/">Vale</a> is more of a style checker than a grammar checker, but it&#39;s the closest existing tool to what I envision.</p>
<p>I excluded a couple of JavaScript tools similar to Vale – <a href="https://github.com/textlint/textlint">TextLint</a>, <a href="https://github.com/GitbookIO/rousseau">rousseau</a>, <a href="https://github.com/btford/write-good">write-good</a> – which were either focused on style or used simplistic regular-expression matching that is inadequate for serious grammar-checking.</p>
<p>Grammarly and LanguageTool&#39;s online version did the best. Unfortunately, neither the open-source version of LanguageTool nor Vale caught any of the errors.</p>
<p>I was a little disappointed that Microsoft Word only caught one, as it is the &#34;only publicly well-documented commercial-grade grammar-based syntax checker&#34; (Dale &amp; Viethen 2021) – that is, the same approach that I am pursuing, based on a full parse of the text rather than pattern-matching against a list of known errors, which is what LanguageTool does (Naber 2003; Mozgovoy 2011).</p>
<h2>Academic research</h2>
<p>As my proposed design is a syntactic analyzer, I mainly read about computational grammars of natural languages, i.e. software that can parse sentences of natural language.</p>
<p>There have been several long-running <em>grammar engineering</em> projects that aim to create broad-coverage grammars of natural languages. One of the most complete is the <a href="https://github.com/delph-in/docs/wiki/ErgTop">English Resource Grammar</a> (ERG), which is based on the theoretical formalisms of Head-Driven Phrase Structure Grammar (HPSG) and Minimal Recursion Semantics. It includes a wealth of information about English in machine-readable form: 35,000 lexemes, 980 lexical types, 70 inflectional rules, and 200 syntactic rules (Flickinger 2010). It also has <a href="https://delph-in.github.io/delphin-viz/demo/#input=hello%20there!&amp;count=5&amp;grammar=erg2018-uw&amp;mrs=true">an online demo</a>. If you try it out, you&#39;ll quickly find that its analysis is at a level of detail that is probably unnecessary for the purpose of error detection. It is also – either by design or by accident – quite permissive: it produced a result for 3 of my 4 test sentences.</p>
<p>The Parallel Grammar Project (ParGram) is another grammar-engineering effort based on Lexical-Functional Grammar (LFG) rather than HPSG (Butt et al 2002).</p>
<p>On a different note, it would be helpful to have a large set of examples of ungrammatical sentences for testing and evaluation. The <a href="https://nyu-mll.github.io/CoLA/">Corpus of Linguistic Acceptability</a> (CoLA) is just such a collection, drawn from published linguistic papers. Many of the ungrammatical sentences are meant to illustrate or test a particular academic theory, though, so they are not very representative of mistakes that people make in real life.</p>
<h2>Summary</h2>
<p>There are many existing tools but none that meets my needs. The performance of some of the commercial products, Grammarly and LanguageTool&#39;s online version in particular, was impressive. The open-source tools did not come close.</p>
<p>The academic research into grammar engineering could be helpful. I don&#39;t think I could incorporate the ERG wholesale into my tool, but I might be able to extract and reuse some of the linguistic information inside of it.</p>
<p>I may yet be dissuaded, but for now I&#39;m carrying on with my original plan: to write my own, open-source, rule-based grammar-checking tool.</p>
<p>As before, if you read this post and you think I&#39;m wrong, please send me an email at <code>&lt;my first name&gt; @ &lt;this domain name&gt;</code>. I&#39;d be happy to hear about it.</p>
<h2>Acknowledgements</h2>
<p>Thank you to <a href="https://github.com/mischaikow">Chris Mischaikow</a> and a person who wished to remain anonymous for running my test sentences through Microsoft Word and <code>ltex-ls</code>, respectively.</p>
<h2>Bibliography</h2>
<ul>
<li>Butt et al 2002: &#34;The Parallel Grammar Project&#34; by Miriam Butt, Helge Dyvik, Tracy Holloway King, Hiroshi Masuichi, and Christian Rohrer, 2002. In <em>COLING-02: Grammar Engineering and Evaluation</em>. <a href="https://aclanthology.org/W02-1503/">https://aclanthology.org/W02-1503/</a></li>
<li>Dale &amp; Viethen 2021: &#34;The automated writing assistance landscape in 2021&#34; by Robert Dale and Jette Viethen, 2021. In <em>Natural Language Engineering</em> 27, pp. 511–518. <a href="https://doi.org/10.1017/S1351324921000164">https://doi.org/10.1017/S1351324921000164</a></li>
<li>Flickinger 2010: &#34;Accuracy vs. Robustness in Grammar Engineering&#34; by Dan Flickinger, 2010. In <em>Readings in Cognitive Science: Papers in Honor of Tom Wasow</em> edited by Emily M. Bender and Jennifer Arnold.</li>
<li>Mozgovoy 2011: &#34;Dependency-Based Rules for Grammar Checking with LanguageTool&#34; by Maxim Mozgovoy, 2011. In <em>Proceedings of the Federated Conference on Computer Science and Information Systems</em>, pp. 209–212. ISBN 978-83-60810-22-4. <a href="https://annals-csis.org/proceedings/2011/pliks/14.pdf">https://annals-csis.org/proceedings/2011/pliks/14.pdf</a></li>
<li>Naber 2003: &#34;A Rule-Based Style and Grammar Checker&#34; by Daniel Naber, 2003. Dissertation at Universität Bielefeld. <a href="https://www.danielnaber.de/languagetool/download/style_and_grammar_checker.pdf">https://www.danielnaber.de/languagetool/download/style_and_grammar_checker.pdf</a></li>
<li>Omelianchuk et al 2020: &#34;GECToR -- Grammatical Error Correction: Tag, Not Rewrite&#34; by Kostiantyn Omelianchuk, Vitaliy Atrasevych, Artem Chernodub, and Oleksandr Skurzhanskyi, 2020. <a href="https://arxiv.org/abs/2005.12592">https://arxiv.org/abs/2005.12592</a> ∎</li>
</ul>

  

  <hr/>
  <p><strong>Disclaimer:</strong> I occasionally make corrections and changes to posts after I publish them. You can view
    the full history of this post <a href="https://github.com/iafisher/blog/commits/master/2024-06-grammar-checking-existing-tools.md">on
    GitHub</a>.
  </p>
</div></div>
  </body>
</html>
