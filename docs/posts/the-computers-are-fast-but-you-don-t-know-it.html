<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="http://shvbsle.in/computers-are-fast-but-you-dont-know-it-p1/">Original</a>
    <h1>The computers are fast, but you don&#39;t know it</h1>
    
    <div id="readability-page-1" class="page"><div>
<div><p>Humans have a shit sense of measurement, especially for quantities that they can&#39;t biologically perceive. For example, you intuitively know how much more heavy a 10kg object is than a 1kg object.</p>
<p>For such quantities, your sense of measurement can improve if you have some way to translate them into signals that the brain is familiar with. 
For example, have you seen these videos?</p>
<ol>
<li><a href="https://www.youtube.com/watch?v=i93Z7zljQ7I">Universe Size Comparision 3D</a></li>
<li><a href="https://www.youtube.com/watch?v=qSOVBiEotaw">Measuring Jeff Bezos&#39; Wealth in Rice</a></li>
</ol>
<p>The second is my favorite. I eat one cup of rice every day. So I measure Jeff&#39;s wealth not just visually but also with my stomach.</p>
<p>Very recently, I did a few optimizations on a piece of code, which helped me intuitively understand how fast a computer can really go. Thought I&#39;d share [2].</p>
<h3 id="what-are-we-optimizing">What are we optimizing?</h3>
<p>The function looks something like this:</p>
<div><pre><span></span><span># note that this is a reduced form of the actual function</span>
<span>def</span> <span>aggregate</span><span>(</span><span>input_df</span><span>):</span>
    <span>weights</span> <span>=</span> <span>initialize_weights</span><span>(</span><span>len</span><span>(</span><span>input_df</span><span>))</span> 

    <span># input_df contains three columns timestamp, score &amp; id</span>
    <span>output_df</span> <span>=</span> <span>group_by_id</span><span>(</span><span>input_df</span><span>)</span> 

    <span># sorting happens within group</span>
    <span>output_df</span> <span>=</span> <span>sort_by_time</span><span>(</span><span>output_df</span><span>)</span> 
    <span>output_df</span> <span>=</span> <span>sort_by_score</span><span>(</span><span>output_df</span><span>,</span> <span>desc</span><span>=</span><span>True</span><span>)</span>

    <span># ranking happens within the group</span>
    <span>output_df</span> <span>=</span> <span>rank_within_id</span><span>(</span><span>output_df</span><span>)</span>

    <span># adds column `results`</span>
    <span>output_df</span> <span>=</span> <span>multiply_weights</span><span>(</span><span>output_df</span><span>,</span> <span>weights</span><span>)</span> 
    <span>results</span> <span>=</span> <span>results_sum_in_each_group</span><span>(</span><span>output_df</span><span>)</span>

    <span>return</span> <span>results</span> <span># is a list</span>
</pre></div>

<p>This is a score aggregation function that&#39;s used by one of our Machine Learning (ML) services. This function is crucial to getting the model to work. Note that the output of this function needs to be computed in less than 500ms for it to even make it to production. I was asked to optimize it.</p>
<p>Okay let&#39;s measure how this function performs for a 1000 calls (assume each input will have 10 items max)</p>
<p><img alt="Base" src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/shiv-1655399977.png"/></p>
<p>Took ~8 seconds to do 1000 calls. Not good at all :( Well, I wanted to try for 1 million calls but it just takes over 20 minutes to do so. Let&#39;s see how we can do better:</p>
<h3 id="optimization-1-writing-the-algorithm-without-pandas-trivial-algorithm-improvements">Optimization 1: Writing the algorithm without Pandas üêº + trivial algorithm improvements</h3>
<p>Python&#39;s &#34;Pandas&#34; library is great for playing around with the data but it&#39;s horrible for production. If you find yourself using it in a production system then it&#39;s time to grow up [1]. I replaced Pandas with simple python lists and implemented the algorithm manually to do the group-by and sort.</p>
<p>Also, the function for calculating weights was being re-initialized in every call, and all it did was initialize the same sequence of weights for some size of the array. This was a bonus and I pre-computed weights.</p>
<p>Here is how the function looked:</p>
<div><pre><span></span><span>WEIGHTS</span> <span>=</span> <span>initialize_weights</span><span>(</span><span>99999</span><span>)</span> 
<span>def</span> <span>aggregate_efficient</span><span>(</span><span>input_lists</span><span>):</span>
    <span>global</span> <span>WEIGHTS</span>

    <span># input_lists contain 2 lists</span>
    <span>output_lists</span> <span>=</span> <span>algorithm_wizardry</span><span>(</span><span>input_lists</span><span>)</span> 

    <span># add column `results`</span>
    <span>output_lists</span> <span>=</span> <span>multiply_weights</span><span>(</span><span>output_lists</span><span>,</span> <span>WEIGHTS</span><span>)</span> 
    <span>results</span> <span>=</span> <span>results_sum_in_each_group</span><span>(</span><span>output_lists</span><span>)</span>

    <span>return</span> <span>results</span> <span># is a list</span>

<span>aggregate_efficient</span><span>(</span><span>ip_list</span><span>)</span>
</pre></div>

<p>And this is how long it takes for 1 million calls:</p>
<p><img alt="Post optimization" src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/shiv-1655399920.png"/></p>
<p>So from 20 minutes, we have come down to 12 seconds! That&#39;s roughly a 9900% increase in speed.</p>
<p>This is enough for the function to go to production. But why stop here?</p>
<h3 id="optimization-2-cythonizing-our-functions">Optimization 2: Cythonizing our functions</h3>
<p>One of the simplest tricks to speed up a python function is to simply write it in Cython. Here is how to do it:</p>
<ol>
<li>Create your <code>.pyx</code> function</li>
</ol>
<p>The more <code>cdef</code> you can put here the better the optimization</p>
<div><pre><span></span><span>def</span> <span>aggregate_efficient_cyth</span><span>(</span><span>double</span><span>[:]</span> <span>score_array</span><span>,</span> 
                        <span>double</span><span>[:]</span> <span>time_array</span><span>,</span> 
                        <span>double</span><span>[:]</span> <span>weights</span><span>):</span> 

    <span>results</span> <span>=</span> <span>algorithm_wizardry</span><span>(</span><span>score_array</span><span>,</span> 
                                 <span>time_array</span><span>,</span> <span>weights</span><span>)</span>
    <span>return</span> <span>results</span>
</pre></div>

<ol start="2">
<li>Define your setup.py file</li>
</ol>
<p>We add some compiler flags to make it go fast. Some say -O3 flag is dangerous but that&#39;s how we roll</p>
<div><pre><span></span><span>from</span> <span>distutils.core</span> <span>import</span> <span>setup</span>
<span>from</span> <span>Cython.Build</span> <span>import</span> <span>cythonize</span>
<span>from</span> <span>distutils.extension</span> <span>import</span> <span>Extension</span>
<span>from</span> <span>Cython.Distutils</span> <span>import</span> <span>build_ext</span>


<span>ext_modules</span> <span>=</span> <span>[</span>
        <span>Extension</span><span>(</span><span>&#34;agg_cython&#34;</span><span>,</span>
            <span>[</span><span>&#34;agg_cython.pyx&#34;</span><span>],</span>
            <span>libraries</span><span>=</span><span>[</span><span>&#34;m&#34;</span><span>],</span>
            <span>extra_compile_args</span> <span>=</span> <span>[</span><span>&#34;-O3&#34;</span><span>,</span> <span>&#34;-ffast-math&#34;</span><span>,</span> <span>&#34;-march=native&#34;</span><span>,</span> <span>&#34;-fopenmp&#34;</span> <span>],</span>
            <span>extra_link_args</span><span>=</span><span>[</span><span>&#39;-fopenmp&#39;</span><span>],</span>
            <span>language</span><span>=</span><span>&#34;c++&#34;</span><span>)</span>
        <span>]</span>
<span>setup</span><span>(</span><span>name</span><span>=</span><span>&#34;agg_cyth_pure&#34;</span><span>,</span><span>cmdclass</span> <span>=</span> <span>{</span><span>&#39;build_ext&#39;</span><span>:</span> <span>build_ext</span><span>},</span> <span>ext_modules</span><span>=</span><span>ext_modules</span><span>,)</span>
</pre></div>

<p>And this is how it performs for 1 million calls:</p>
<p><img alt="Cython" src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/shiv-1655400765.png"/></p>
<p><code>~6.59</code> seconds i.e. ~82% increase in the speed. We managed to almost half the time of the previous optimization :) This is awesome!</p>
<p>We will not stop here. Let&#39;s go nuts</p>
<h3 id="optimization-3-writing-your-function-in-pure-c">Optimization 3: Writing your function in pure C++</h3>
<p>This is where the fun starts. This is one of the most important skills that I&#39;ve been able to add to my tech inventory (thanks <a href="https://ragv.in/">Rags</a> ), and if performance really matters to you then this will help you:</p>
<ol>
<li>Implement the function in pure C++</li>
</ol>
<div><pre><span></span><span>#include</span><span> </span><span>&#34;agg_cyth_fast.hpp&#34;</span><span></span>

<span>using</span><span> </span><span>namespace</span><span> </span><span>std</span><span>;</span><span></span>

<span>double</span><span> </span><span>agg_efficient</span><span>(</span><span>double</span><span> </span><span>score_array</span><span>[],</span><span> </span>
<span>                    </span><span>long</span><span> </span><span>time_array</span><span>[],</span><span></span>
<span>                    </span><span>double</span><span> </span><span>weight_lookup</span><span>[],</span><span></span>
<span>                    </span><span>int</span><span> </span><span>N</span><span>){</span><span></span>

<span>    </span><span>vector</span><span>&lt;</span><span>double</span><span>&gt;</span><span> </span><span>results</span><span> </span><span>=</span><span> </span><span>algorithm_wizardry</span><span>(</span><span>score_array</span><span>,</span><span></span>
<span>                                   </span><span>time_array</span><span>,</span><span> </span><span>weight_lookup</span><span>,</span><span> </span><span>N</span><span>);</span><span></span>
<span>    </span><span>return</span><span> </span><span>results</span><span>;</span><span></span>
<span>}</span><span></span>
</pre></div>

<ol start="2">
<li>Prepare your header file</li>
</ol>
<div><pre><span></span><span>#ifndef AGG_H</span>
<span>#define AGG_H</span>

<span>#include</span><span> </span><span>&lt;iostream&gt;</span><span></span>
<span>#include</span><span> </span><span>&lt;map&gt;</span><span></span>
<span>#include</span><span> </span><span>&lt;vector&gt;</span><span></span>
<span>#include</span><span> </span><span>&lt;algorithm&gt;</span><span></span>

<span>double</span><span> </span><span>agg_efficient</span><span>(</span><span>double</span><span>[],</span><span> </span><span>long</span><span>[],</span><span> </span><span>double</span><span>[],</span><span> </span><span>int</span><span>);</span><span></span>
<span>#endif</span>
</pre></div>

<ol start="3">
<li>Write a <code>.pyx</code> file to talk to C++</li>
</ol>
<div><pre><span></span><span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>from</span> <span>math</span> <span>import</span> <span>exp</span> 
<span>from</span> <span>libc.math</span> <span>cimport</span> <span>exp</span> <span>as</span> <span>c_exp</span>
<span>from</span> <span>cython.parallel</span> <span>import</span> <span>prange</span>
<span>cimport</span> <span>cython</span>


<span>cdef</span> <span>extern</span> <span>from</span> <span>&#34;agg_cyth_fast.hpp&#34;</span> <span>nogil</span><span>:</span>
    <span>double</span> <span>agg_efficient</span><span>(</span><span>double</span><span>[],</span> <span>long</span><span>[],</span> <span>double</span><span>[],</span> <span>int</span><span>)</span>

<span>def</span> <span>agg_efficient_fs</span><span>(</span><span>double</span><span>[:]</span> <span>score_array</span><span>,</span> 
                      <span>long</span><span>[:]</span> <span>time_array</span><span>,</span>  
                       <span>double</span><span>[:]</span> <span>weight_lookup</span><span>):</span>
    <span>cdef</span> <span>int</span> <span>N</span> <span>=</span> <span>len</span><span>(</span><span>starttime_array</span><span>)</span>
    <span>cdef</span> <span>double</span> <span>Y</span><span>;</span>
    <span>Y</span> <span>=</span> <span>agg_efficient</span><span>(</span><span>&amp;</span><span>score_array</span><span>[</span><span>0</span><span>],</span> 
                      <span>&amp;</span><span>time_array</span><span>[</span><span>0</span><span>],</span> 
                       <span>&amp;</span><span>weight_lookup</span><span>[</span><span>0</span><span>],</span> <span>N</span><span>);</span>
    <span>return</span> <span>Y</span>
</pre></div>

<p>Finally, we use a similar setup.py file as the previous optimization and build our function. This is effectively going to let us pass Python objects to a pure C++ function.</p>
<p>This is how it performs for 1 million calls:
<img alt="Pure CPP" src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/shiv-1655401551.png"/></p>
<p>It&#39;s crazy how fast pure C++ can be. We have reduced the time for the computation by ~119%! üéâ</p>
<p>We are not done yet. The .pyx file in this section has some code hidden but someone with a keen observation might have guessed the next optimization by looking at the imports.</p>
<h3 id="optimization-4-time-to-banish-the-global-interpreter-lock-gil">Optimization 4: Time to banish the Global Interpreter Lock (GIL)</h3>
<p>Python has this annoying thing called GIL, which won&#39;t let your multi-threaded python code run faster than a single-threaded one.</p>
<p>If you really want to bully your computer, why do it on a single core?</p>
<p>We now, use <a href="https://cython.readthedocs.io/en/latest/src/userguide/parallelism.html">prange</a> to simply parallelize our computations.</p>
<p>Simply add this to the <code>.pyx</code> file:</p>
<div><pre><span></span><span>@cython</span><span>.</span><span>boundscheck</span><span>(</span><span>False</span><span>)</span>
<span>@cython</span><span>.</span><span>wraparound</span><span>(</span><span>False</span><span>)</span>
<span>def</span> <span>agg_efficient_fs_batch</span><span>(</span><span>double</span><span>[:,:]</span> <span>score_array</span><span>,</span> 
                            <span>long</span><span>[:,:]</span> <span>time_array</span><span>,</span> 
                            <span>double</span><span>[:]</span> <span>weight_lookup</span><span>):</span>
    <span>cdef</span> <span>int</span> <span>M</span> <span>=</span> <span>len</span><span>(</span><span>score_array</span><span>)</span>
    <span>cdef</span> <span>double</span><span>[:]</span> <span>Y</span> <span>=</span> <span>np</span><span>.</span><span>zeros</span><span>(</span><span>M</span><span>)</span>
    <span>cdef</span> <span>int</span> <span>i</span><span>,</span> <span>N</span>
    <span>for</span> <span>i</span> <span>in</span> <span>prange</span><span>(</span><span>M</span><span>,</span> <span>nogil</span><span>=</span><span>True</span><span>):</span>
        <span>N</span> <span>=</span> <span>len</span><span>(</span><span>starttime_array</span><span>[</span><span>i</span><span>])</span>
        <span>Y</span><span>[</span><span>i</span><span>]</span> <span>=</span> <span>agg_efficient</span><span>(</span><span>&amp;</span><span>score_array</span><span>[</span><span>i</span><span>][</span><span>0</span><span>],</span> 
                             <span>&amp;</span><span>time_array</span><span>[</span><span>i</span><span>][</span><span>0</span><span>],</span> 
                             <span>&amp;</span><span>weight_lookup</span><span>[</span><span>0</span><span>],</span> <span>N</span><span>);</span>
    <span>return</span> <span>Y</span>
</pre></div>

<p>This is how much it takes the same 1 million calls in parallel on a 4 core machine:
<img alt="PrangeCyth" src="https://bear-images.sfo2.cdn.digitaloceanspaces.com/shiv-1655402561.png"/></p>
<p>That&#39;s an approximate ~237% increase in speed over the last optimization.</p>
<h3 id="to-summarize-for-1-million-calls">To Summarize, for 1 million calls:</h3>
<table>
<thead>
<tr>
<th>Optimization</th>
<th>Time Taken</th>
<th>Speedup Over Original</th>
</tr>
</thead>
<tbody>
<tr>
<td>None</td>
<td>1200s</td>
<td>-</td>
</tr>
<tr>
<td>Remove Pandas + Algo improvement</td>
<td>12s</td>
<td>~9900%</td>
</tr>
<tr>
<td>Cythonize Function</td>
<td>6.59s</td>
<td>~18109.4%</td>
</tr>
<tr>
<td>Pure C++ Implementation</td>
<td>3s</td>
<td>~33326.2%</td>
</tr>
<tr>
<td>Parallel C++ on 4 cores</td>
<td>890ms</td>
<td>~134731%</td>
</tr>
<tr>
<td>Parallel C++ on 32 cores</td>
<td>201ms</td>
<td>~596915%</td>
</tr>
</tbody>
</table>
<p>I guess this is how fast computers can be</p>
<p>Follow me on <a href="https://twitter.com/shvbsle">Twitter</a> if you want to bully your computer into going fast</p>
<p>Footnotes:</p>
<p>[1] Please don&#39;t get me wrong. Pandas is pretty fast for a typical dataset but it&#39;s not the processing that slows down pandas in my case. It&#39;s the creation of Pandas objects itself which can be slow. If your service needs to respond in less than 500ms, then you will feel the effect of each line of Pandas code.</p>
<p>[2] Wow, this hit the front page on Hackernews. Check out the <a href="https://news.ycombinator.com/item?id=31769294">discussion</a> for some further enlightenment</p>
</div>
</div></div>
  </body>
</html>
