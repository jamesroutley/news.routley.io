<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.undeadly.org/cgi?action=article;sid=20240418050520">Original</a>
    <h1>OpenBSD â€“ Coming soon to a -current system near you: parallel raw IP input</h1>
    
    <div id="readability-page-1" class="page"><div>
<p>Contributed by
<a href="http://bsdly.blogspot.com/">Peter N. M. Hansteen</a>
on <time datetime="2024-04-11T22:05:42Z">2024-04-11</time>
from the all the packets all at once dept.</p>
<p>The work to improve the capabilities of the network stack is about to take a noticeable step forward. In a message to <code>tech@</code> titled <a href="https://marc.info/?l=openbsd-tech&amp;m=171286702531925&amp;w=2">parallel raw IP input</a>, Alexander Bluhm (<code>bluhm@</code>) posted a patch that he describes as</p>
<blockquote><pre>List:       openbsd-tech
Subject:    parallel raw IP input
From:       Alexander Bluhm &lt;bluhm () openbsd ! org&gt;
Date:       2024-04-11 20:24:39

Hi,

As mvs@ mentioned, running raw IP in parallel is easier as it is
less complex than UDP.  Especially there is no socket splicing.

So I fixed one race in rip_input() and reused my shared net lock
ip_deliver() loop.
</pre></blockquote>

<blockquote><pre>The idea is that ip_deliver() may run with shared or exclusive net
lock.  The last parameter indicates the mode.  If is is running
with shared netlock and encounters a protocol that needs exclusive
lock, the packet is queued.

Before ip_ours() always queued the packet.  Now it tries to deliver
with shared net lock, and if that is not possible, it queues the
packet.

In case we have an IPv6 header chain that must switch from shared
to exclusive processing, the next protocol and mbuf offset are
stored in a mbuf tag.

The only drawback is that we have very limited test coverage for
raw IP.  The ip_deliver() shared locking change works also with
UDP, Hvroje has tested it in 2022.

ok?

bluhm
</pre></blockquote>
<p>Followed by the patch itself, which should apply to a then-recent -current checkout.</p>
<p>a little later, the patch was 
<a href="https://marc.info/?l=openbsd-cvs&amp;m=171312744110261&amp;w=2">committed</a>:</p>
<blockquote>
<pre>CVSROOT:	/cvs
Module name:	src
Changes by:	bluhm@cvs.openbsd.org	2024/04/14 14:46:27

Modified files:
	sys/net        : if_bridge.c 
	sys/netinet    : in_proto.c ip_input.c ip_var.h 
	sys/netinet6   : ip6_input.c 
	sys/sys        : mbuf.h protosw.h 

Log message:
Run raw IP input in parallel.

Running raw <abbr>IPv4</abbr> input with shared net lock in parallel is less
complex than <abbr>UDP</abbr>.  Especially there is no socket splicing.

New ip_deliver() may run with shared or exclusive net lock.  The
last parameter indicates the mode.  If is is running with shared
netlock and encounters a protocol that needs exclusive lock, the
packet is queued.  Old ip_ours() always queued the packet.  Now it
calls ip_deliver() with shared net lock, and if that cannot handle
the packet completely, the packet is queued and later processed
with exclusive net lock.

In case of an <abbr>IPv6</abbr> header chain, that switches from shared to
exclusive processing, the next protocol and mbuf offset are stored
in a mbuf tag.

OK mvs@
</pre>
</blockquote>
<p>
Via email, <code>bluhm@</code> added some further explanation:
</p><blockquote><pre>The commit from January is sending UDP in parallel.  Socket send,
when called from userland, uses shared net lock.  You need multiple
UDP sockets and threads writing to them to see an effect.

Now we are working on parallel input.  When traffic is directed to
different IP or ports, the network hardware can distribute flows
to different receive queues.  These queues are processed by one CPU
each.  Goal is to keep procssing parallel until data reaches userland.

IP input and forward runs parallel for a while.  Until last week
all protocol input was single threaded.  Now raw IP can run in
parallel.

Next step is UDP input in parallel.  It kind of works, but locking
in socket splicing is wrong.  In my experiments I see increase in
UDP througput of factor 4 to 7.  But the locking problems are quite
nasty.  I think we need more tests that agressively splice and
unsplice sockets.

Advantage of UDP over raw IP would be that testing is much easier.

Final protocol will be TCP, but that is hardest of all.  Single
stream TCP performance already got a performance boost by hardware
offloading.

hardware receive =&gt; IP input -&gt; protocol input =&gt; userland =&gt;
protocol output =&gt; IP output =&gt; hardware transmit

bluhm@ is working on -&gt; protocol input to make it parallel for more
protocols.  It is the final bottle neck.

mvs@ is looking at =&gt; to and from userland.  They behave differently
for UNIX domain, raw IP, UDP, and TCP, the latter is still single
threaded.
</pre></blockquote>
<p>
This all boils down to <em>faster packets</em>, due to the system&#39;s now ever more increasing ability to fully utilize multiple cores to process network traffic.
</p><p>
Testing is of course still appreciated, but this code is anyway destined to be in the next release.
</p></div></div>
  </body>
</html>
