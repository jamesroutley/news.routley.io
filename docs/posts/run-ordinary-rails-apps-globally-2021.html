<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://fly.io/blog/run-ordinary-rails-apps-globally/">Original</a>
    <h1>Run Ordinary Rails Apps Globally (2021)</h1>
    
    <div id="readability-page-1" class="page"><section> <img src="https://blog.plover.com/blog/2021-08-10/run-rails-globally.png" alt=""/> <p> We’re Fly.io. We take container images and run them on our hardware around the world. It’s pretty neat, and you <a href="https://fly.io/docs/speedrun/">should check it out</a>; with an already-working Docker container, you can be up and running on Fly.io in well under 10 minutes.</p><p>If you&#39;ve used your own Rails application from another continent, you may get the feeling that physics has beaten your performance tuning efforts. Page loads feel a bit sluggish, even with all the right database indexes and fancy CDN-backed assets.</p> <p><a href="https://fly.io/blog/last-mile-redis/">We&#39;ve said it before</a>: when it comes to responsiveness, sub-100ms times are the magic number; below 100ms, and things <em>feel</em> instantaneous.</p> <p>Now, simple regional asset caching — the CDN pitch — can bring apps closer to 100ms response times. But what if you could easily deploy your <em>application</em> globally? Not just images, but application logic. And what if you could do it without changes to your code?</p> <p>This type of global deployment sounds like a major infrastructure project — unrealistic to undertake in the short term, and long-term reserved for giant companies with serious technical faangs. It shouldn&#39;t be that way. All apps should run close to end users. And with the right plumbing, we can distribute and scale globally from day one.</p> <p>Fly.io has been doing a lot of cool stuff with <a href="https://fly.io/blog/building-a-distributed-turn-based-game-system-in-elixir/">Elixir and Phoenix</a>. Elixir, built on Erlang&#39;s distributed-by-design BEAM runtime, begs to be clustered and geographically distributed, and it really sings on Fly.io. But people do real work in Rails, too. That&#39;s why I wrote the <a href="https://github.com/superfly/fly-ruby">fly-ruby gem</a>. It&#39;s a tiny library that makes it trivial to deploy Rails apps on a global platform like Fly.io. No new framework or functional language learning required.</p> <p>This post is going to talk you through how <a href="https://github.com/superfly/fly-ruby">fly-ruby</a> works. Before we dig into the details of the gem itself, it&#39;s worth a minute to talk about how Fly.io works and what it means to optimize an application for it.</p> <h2 id="what-fly-io-does"><a href="#what-fly-io-does" aria-label="Anchor"></a>What Fly.io Does</h2><p>For our 100ms performance goal, Fly.io has two major features that Rails can take advantage of.</p> <p><strong>Region-local database replicas:</strong> <a href="https://fly.io/docs/getting-started/multi-region-databases/">Deploying a global Postgres cluster of read replicas on Fly.io</a> is easy. And read replicas are, by themselves, a good first step to improving Rails performance.</p> <p>Rails instances read from their corresponding regional replica, so your &#34;find local recipes&#34; app serves information about Pan-fried rice noodles in Hong Kong from a Postgres replica in Hong Kong, and Italian beef sandwiches from a replica in Chicago.</p> <p><strong>Replayable HTTP requests:</strong> Read replicas work great for <em>retrieving</em> data locally. But we sometimes need to write to the database, and replicas don&#39;t handle writes.</p> <p>Somewhere in the world (let&#39;s say Paris) we&#39;ll have a main Postgres — that means our write requests need to make their way to Paris, over Fly.io&#39;s private network.</p> <p>For example, an HTTP request may arrive in Hong Kong that needs to write to the main database in Paris. We can tell Fly.io&#39;s proxy - via the <code>Fly-Replay</code> response header - to <em>move the entire HTTP request to Paris&#39;s Rails instance</em>, and it will just work.</p> <h2 id="the-magical-fly-io-ruby-gem"><a href="#the-magical-fly-io-ruby-gem" aria-label="Anchor"></a>The magical Fly.io Ruby Gem</h2><p>So let&#39;s do some testing and figure out how to get below that 100ms threshold from Paris, Chicago, Sydney and Santiago, Chile.</p> <p>We&#39;ve tried most performance testing tools and our current favorite is <a href="https://k6.io">k6</a>, a modern, open source web performance testing tool. It&#39;s unique in its approach: you write tests in Javascript, interpreted and executed in a Go runtime. It has exquisite documentation - especially for those unfamiliar with web performance testing. Their hosted option supports distributed tests, but we can also <a href="https://github.com/jsierles/fly-k6">run tests from a global Fly.io app</a>!</p> <p>First, we should see how a vanilla, single-region deployment fares. We just need <a href="https://fly.io/docs/getting-started/multi-region-databases">a Postgres database</a> in Paris, and a Rails app deployed in the same region. It would be weird to write a whole article without mentioning food, so here&#39;s a little <a href="https://cookherenow.com">recipe search app</a> that&#39;s good for testing. For bonus points, it shows different recipes to people in different cities.</p> <p>Here&#39;s how it performs:</p> <div><pre><code>Single region deployment: Time to First Byte
cdg 72.7ms
ord 168.7ms
syd 286.2ms
scl 442.9ms
</code></pre></div><p>With the current, single region app config, every request is bounced to Paris. Great for people in Paris, not great for people in Santiago with a hankerin&#39; for Pastel de Choclo.</p> <p>If we deploy our app to more regions, we get a nasty surprise:</p> <div><pre><code>Multiregion deployment with single database: Time to First Byte
cdg 76ms
ord 258ms
syd 528.7ms
scl 1341ms
</code></pre></div><p>Performance got worse!? This isn&#39;t a very good sales pitch. There&#39;s a simple explanation, though, and we&#39;re halfway to faster Chilean recipe suggestions.</p> <p>The Rails instance in Sydney still needs to query the database — often multiple times — and <em>each</em> of those database queries bounces around the world to Paris (over an encrypted private network). Adding latency between the app server and database multiplies internet latency. One round trip from Sydney to Paris might take 400ms. Ten in a row feels like an hour.</p> <p>Now, here&#39;s the sales pitch. The <code>fly-ruby</code> gem will switch to regional replicas for database reads and <em>magically route write request to the primary database</em>.</p> <p>If we add the <code>fly-ruby</code> gem, set the PRIMARY_REGION environment variable, here&#39;s what happens:</p> <div><pre><code>Multiregion deployment with regional database replicas: Time to First Byte
cdg 75.1ms
ord 50.4ms
syd 45.8ms
scl 84.4ms
</code></pre></div><p>One tiny configuration change, 90% latency reduction, and our Rails app suddenly responds in sub-100ms. No architecture work required.</p> <h2 id="it-s-not-actually-magic"><a href="#it-s-not-actually-magic" aria-label="Anchor"></a>It&#39;s not actually magic</h2><p>This 300-line gem doesn&#39;t really do much. Postgres and the Fly.io global proxy <a href="https://fly.io/blog/globally-distributed-postgres/">do all the heavy lifting</a>. It&#39;s a set of Rack middleware that does the last little bit of work for you. And it&#39;s usable in any Rack-compatible application, for people who like their Ruby without restrictive rails.</p> <p>The magic here lives in the <code>Fly-Replay</code> header. I pass a <strong>state</strong><em>:</em> an arbitrary value written to the <code>Fly-Replay-Src</code> header, appended to the final replayed request to the primary application instance.</p> <p>This state assists the middleware in handling the replay under different conditions, as we&#39;ll see below.</p> <div><pre><code><span>def</span> <span>self</span><span>.</span><span>replay_in_primary_region!</span><span>(</span><span>state</span><span>:)</span>
  <span>res</span> <span>=</span> <span>Rack</span><span>::</span><span>Response</span><span>.</span><span>new</span><span>(</span>
    <span>&#34;&#34;</span><span>,</span>
    <span>409</span><span>,</span>
    <span>{</span><span>&#34;Fly-Replay&#34;</span> <span>=&gt;</span> <span>&#34;region=</span><span>#{</span><span>Fly</span><span>.</span><span>configuration</span><span>.</span><span>primary_region</span><span>}</span><span>;state=</span><span>#{</span><span>state</span><span>}</span><span>&#34;</span><span>}</span>
  <span>)</span>
  <span>res</span><span>.</span><span>finish</span>
<span>end</span>
</code></pre></div><p>I exploit the web perf rule of thumb that <strong>most requests are reads, and most reads use HTTP GET requests.</strong> I can safely reconnect Rails to the region-local database replica. The gem builds the replica URI using Fly.io&#39;s DNS service discovery and the <code>FLY_REGION</code> environment variable.</p> <div><pre><code><span>database_uri</span> <span>=</span> <span>URI</span><span>.</span><span>parse</span><span>(</span><span>ENV</span><span>[</span><span>&#39;DATABASE_URL&#39;</span><span>])</span>
<span>database_uri</span><span>.</span><span>host</span> <span>=</span> <span>&#34;</span><span>#{</span><span>ENV</span><span>[</span><span>&#39;FLY_REGION&#39;</span><span>]</span><span>}</span><span>.</span><span>#{</span><span>database_uri</span><span>.</span><span>hostname</span><span>}</span><span>&#34;</span>
<span>database_uri</span><span>.</span><span>port</span> <span>=</span> <span>5433</span>
<span>database_uri</span><span>.</span><span>to_s</span>
</code></pre></div><p>As a result, HTTP GET requests are passed directly down to the Rails application. And, in the normal case, they return after a speedy round trip to the database replica.</p> <p>But GET requests occasionally perform writes. It&#39;s dirty, but true.</p> <p>Fortunately, Postgres won&#39;t allow writes to a Postgres read replica. When a database write slips through, the Ruby Postgres library throws an exception. The gem inserts another middleware — at the <em>bottom</em> of the stack — to catch the<code>PG::ReadOnlySqlTransaction</code> exception. This halts the response and asks Fly.io to replay the original request in the primary region.</p> <div><pre><code><span>def</span> <span>call</span><span>(</span><span>env</span><span>)</span>
  <span>@app</span><span>.</span><span>call</span><span>(</span><span>env</span><span>)</span>
<span>rescue</span> <span>PG</span><span>::</span><span>ReadOnlySqlTransaction</span><span>,</span> <span>ActiveRecord</span><span>::</span><span>StatementInvalid</span> <span>=&gt;</span> <span>e</span>
  <span>if</span> <span>e</span><span>.</span><span>is_a?</span><span>(</span><span>PG</span><span>::</span><span>ReadOnlySqlTransaction</span><span>)</span> <span>||</span> <span>e</span><span>&amp;</span><span>.</span><span>cause</span><span>&amp;</span><span>.</span><span>is_a?</span><span>(</span><span>PG</span><span>::</span><span>ReadOnlySqlTransaction</span><span>)</span>
    <span>RegionalDatabase</span><span>.</span><span>replay_in_primary_region!</span><span>(</span><span>state: </span><span>&#34;captured_write&#34;</span><span>)</span>
  <span>else</span>
    <span>raise</span> <span>e</span>
  <span>end</span>
<span>end</span>
</code></pre></div><p>It could stop here. But there are a bunch of requests for which we don&#39;t have to do this dance. It&#39;s safe to assume that <strong>non-idempotent HTTP requests intend to write to the database.</strong> This includes, by default, POST, PUT, PATCH and DELETE requests.</p> <p>So, from high in the middleware stack, the gem halts and replay probably-write requests in the primary region, which prevents unnecessary application requests in the secondary region.</p> <p>One catch with this setup is: physics. Imagine we&#39;re handling a large replicated write — say, an HTTP POST of a large recipe entry in Santiago, Chile. Something that can happen is that a request to read that entry back from Santiago can race the replication of the write from Paris, and lose. You see this pattern, &#34;<em>create-and-redirect-to-show</em>&#34;, somewhat regularly in Rails apps, and if you break it, you can get a poor user experience.</p> <p>To prevent this, <strong>replayed requests set a configurable time threshold in a cookie</strong>. Requests arriving within the threshold sent by the browser will be sent to the primary region. This is a simple but valuable trade-off: a temporary performance penalty in exchange for consistency. Remember, we assume that most uses of the application won&#39;t write at all; the worst case isn&#39;t terrible, and the common case is very fast. It&#39;s usually the right trade.</p> <p>Curiously, this approach mirrors the Rails default implementation of <a href="https://edgeguides.rubyonrails.org/active_record_multiple_databases.html#activating-automatic-connection-switching">read/write splitting between primary and replica databases</a>.</p> <h2 id="i-rack"><a href="#i-rack" aria-label="Anchor"></a>I ❤️ Rack</h2><p>Apart from Fly.io&#39;s magic, the Rack standard made this gem a cinch to implement. Rack is one of the major successes of the Ruby and Rails development environment. It&#39;s underappreciated and deserves more appreciation, so here&#39;s some love.</p> <p>Most web apps share a lot of common behavior in marshaling, unmarshaling, validating, and routing requests. These are the basic features that a web framework provides, and why frameworks are so popular. It used to be difficult (and on some platforms it still is) to change those behaviors: you had to change your application, or, worse, the framework itself to accomplish it.</p> <p>Python&#39;s WSGI was probably the first standard aimed at solving this problem. Rack came shortly after, inspired by WSGI. Both provide a simple, elegant interface for inserting common behavior between web servers and applications. This also happens to be a great way to simplify framework-specific behavior.</p> <p>Try typing <code>rails middleware</code> in a Rails app production environment:</p> <div><pre><code><span>use</span> <span>ActionDispatch</span><span>::</span><span>HostAuthorization</span>
<span>use</span> <span>ActionDispatch</span><span>::</span><span>SSL</span>
<span>use</span> <span>Rack</span><span>::</span><span>Sendfile</span>
<span>use</span> <span>ActionDispatch</span><span>::</span><span>Static</span>
<span>use</span> <span>ActionDispatch</span><span>::</span><span>Executor</span>
<span>use</span> <span>ActiveSupport</span><span>::</span><span>Cache</span><span>::</span><span>Strategy</span><span>::</span><span>LocalCache</span><span>::</span><span>Middleware</span>
<span>use</span> <span>Rack</span><span>::</span><span>Runtime</span>
<span>use</span> <span>Rack</span><span>::</span><span>MethodOverride</span>
<span>use</span> <span>ActionDispatch</span><span>::</span><span>RequestId</span>
<span>use</span> <span>ActionDispatch</span><span>::</span><span>RemoteIp</span>
<span>use</span> <span>Rails</span><span>::</span><span>Rack</span><span>::</span><span>Logger</span>
<span>use</span> <span>ActionDispatch</span><span>::</span><span>ShowExceptions</span>
<span>use</span> <span>ActionDispatch</span><span>::</span><span>DebugExceptions</span>
<span>use</span> <span>ActionDispatch</span><span>::</span><span>ActionableExceptions</span>
<span>use</span> <span>ActionDispatch</span><span>::</span><span>Callbacks</span>
<span>use</span> <span>ActionDispatch</span><span>::</span><span>Cookies</span>
<span>use</span> <span>ActionDispatch</span><span>::</span><span>Session</span><span>::</span><span>CookieStore</span>
<span>use</span> <span>ActionDispatch</span><span>::</span><span>Flash</span>
<span>use</span> <span>ActionDispatch</span><span>::</span><span>ContentSecurityPolicy</span><span>::</span><span>Middleware</span>
<span>use</span> <span>ActionDispatch</span><span>::</span><span>PermissionsPolicy</span><span>::</span><span>Middleware</span>
<span>use</span> <span>Rack</span><span>::</span><span>Head</span>
<span>use</span> <span>Rack</span><span>::</span><span>ConditionalGet</span>
<span>use</span> <span>Rack</span><span>::</span><span>ETag</span>
<span>use</span> <span>Rack</span><span>::</span><span>TempfileReaper</span>
<span>run</span> <span>Cookherenow</span><span>::</span><span>Application</span><span>.</span><span>routes</span>
</code></pre></div><p>Exception handling, caching, session management, cookie encryption, static file delivery - all implemented as Rack middleware. Building apps this way provides a clear path for a request to reach an application, and more importantly, a standard way to <em>insert middlewares at a specific location.</em> The framework is now programmable.</p> <p>The <code>fly-ruby</code> gem implements two Rack &#34;middlewares&#34;. It&#39;s idiomatic, and easy to shoplift (from, say, <a href="https://github.com/getsentry/sentry-ruby">Sentry&#39;s exception handling library</a>).</p> <h2 id="what-about-background-jobs"><a href="#what-about-background-jobs" aria-label="Anchor"></a>What about background jobs?</h2><p>Background jobs are a core piece of infrastructure for most Rails apps. Naturally, they&#39;ll need to write to the database.Restricting worker processes to the primary region is the simplest way to handle such jobs in a multi-region scenario.</p> <p>But if we&#39;re using a database - like Postgres or Redis - to store the jobs, <em>queuing up the job itself will be slow</em> from secondary regions. If we enqueue lots of jobs in GET requests, this performance loss could offset our gains.</p> <p>Furthermore, some apps - like <a href="https://www.discourse.org">Discourse</a> - run smaller background jobs <a href="https://github.com/discourse/discourse/blob/main/lib/scheduler/defer.rb#L85">in the web process itself</a>. Both scenarios need to write the primary database without relying on HTTP trickery.</p> <p>For example, we might add code to <code>fly-ruby</code> like this.</p> <div><pre><code><span>Fly</span><span>.</span><span>on_primary</span> <span>do</span>
  <span>Recipes</span><span>.</span><span>transform</span>
<span>end</span>
</code></pre></div><p>The Rails support for read/write splits takes a similar path to <a href="https://edgeguides.rubyonrails.org/active_record_multiple_databases.html#using-manual-connection-switching">force a specific database connection</a>.</p> <h2 id="where-this-breaks-down"><a href="#where-this-breaks-down" aria-label="Anchor"></a>Where this breaks down</h2><p>Some complex Rails applications make this kind of setup difficult, like <a href="https://www.discourse.org">Discourse</a>.</p> <p><strong>Some apps write on every request</strong>. Think about things like lazy authentication session token refresh, or touching a user&#39;s <code>last_seen</code> attribute. These generate unexpected writes, and, worse, waste cycles on regional app servers.</p> <p>Moving work like this to a background job is a fine solution to this problem. It also happens to be a best practice for keeping applications performant and resilient. So if you can do this, you should.</p> <p>Background jobs in Rails apps without infrastructure support for jobs might seem like a pain. But it doesn&#39;t have to be. You could implement the <a href="https://github.com/rails/rails/blob/main/activejob/lib/active_job/queue_adapters/async_adapter.rb">ActiveJob in-memory queue</a> for jobs you would not mind losing on restart.</p> <p><strong>Complex interactions with other data stores may slow requests down.</strong> By default, Discourse backs statistics and logs into Redis, and reads and writes to it on every request. This can be tricky to deal with in a global deployment. Solutions like read/write splitting may be useful here, but they&#39;re not &#34;just install this gem&#34;-simple to implement.</p> <p><strong>Relying on catching read-only exceptions could lead to inconsistent data.</strong> For example, a visit counter being incremented in Redis <em>before the Postgres exception is raised</em> would be bumped twice: once in the secondary region request, and again in the replayed primary region request. Most apps aren&#39;t going to care about this, but you want to be aware of it.</p> <p><strong>Large multipart file uploads might be doubly slow</strong> if they&#39;re replayed <em>after</em> the browser upload completes.</p> <h2 id="what-s-next"><a href="#what-s-next" aria-label="Anchor"></a>What&#39;s next?</h2><p><a href="https://fly.io/blog/last-mile-redis/">Region-local Redis caches</a> would be dope. For Rails apps, this could mean that the common approach of fragments or Russian-doll caching could get a boost at the global level without much work.</p> <p>And more adapters! Adapters for <a href="https://github.com/superfly/fly-node">Nodejs/Express</a>, Phoenix, Django, and friends. They&#39;re totally doable and you should <a href="https://community.fly.io/">get in touch</a> if you like these kind of projects.</p>  </section></div>
  </body>
</html>
