<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://nand2mario.github.io/posts/2026/80386_multiplication_and_division/">Original</a>
    <h1>80386 Multiplication and Division</h1>
    
    <div id="readability-page-1" class="page"><div>
        <!-- <style>
  pre code { font-size: 0.85em; }
  code { font-size: 0.85em; }
</style> -->

<!-- # 80386 Multiplication and Division -->

<p>When Intel released the 80386 in October 1985, it marked a watershed moment for personal computing. The 386 was the first 32-bit x86 processor, increasing the register width from 16 to 32 bits and vastly expanding the address space compared to its predecessors. This wasn&#39;t just an incremental upgrade—it was the foundation that would carry the PC architecture for decades to come.</p>
<p>The timing was significant. By the mid-1980s, the IBM PC had established x86 as the dominant PC architecture, but the 16-bit 8086/286 processors were hitting their limits. Memory was constrained to 1MB (or 16MB with the 286&#39;s limited protected mode). Competing 32-bit architectures like the Motorola 68020 threatened Intel&#39;s dominance. The 386 was Intel&#39;s answer: full 32-bit computing with backward compatibility for the massive library of existing DOS software.</p>
<p>The 386 introduced important and long-lasting x86 features: a flat 4GB address space, virtual memory with paging, and a protected mode that actually worked. It would go on to run Windows 3.0, Windows 95, early Linux, and countless other operating systems that shaped modern computing.</p>
<h2 id="faster-arithmetic">Faster arithmetic</h2>
<p>In addition to its architectural advances, the 386 delivered a major jump in arithmetic performance. On the earlier 8086, multiplication and division were slow — 16-bit multiplication typically required 120–130 cycles, with division taking even longer at over 150 cycles. The 286 significantly improved on this by introducing faster microcode routines and modest hardware enhancements.</p>
<p>The 386 pushed performance further with dedicated hardware that processes multiplication and division at the rate of <strong>one bit per cycle</strong>, combined with a native 32-bit datapath width. The microcode still orchestrates the operation, but the heavy lifting happens in specialized datapath logic that advances every cycle.</p>
<p>Here are the actual cycle counts from the Intel 386 Programmer&#39;s Reference Manual:</p>
<table>
<thead>
<tr>
<th>Instruction</th>
<th>8-bit</th>
<th>16-bit</th>
<th>32-bit</th>
</tr>
</thead>
<tbody>
<tr>
<td>MUL</td>
<td>9-14</td>
<td>9-22</td>
<td>9-38</td>
</tr>
<tr>
<td>IMUL</td>
<td>9-14</td>
<td>9-22</td>
<td>9-38</td>
</tr>
<tr>
<td>DIV</td>
<td>14</td>
<td>22</td>
<td>38</td>
</tr>
<tr>
<td>IDIV</td>
<td>19</td>
<td>27</td>
<td>43</td>
</tr>
</tbody>
</table>
<p>The ranges for MUL/IMUL reflect an &#34;early-out&#34; optimization—the loop exits early when the remaining multiplier bits are all zeros (or all ones for signed). Division has no early-out, so cycle counts are fixed at roughly <code>width + overhead</code>.</p>
<p>To save silicon, the 386 reuses the main ALU for the per-iteration add/subtract work rather than having a separate multiplier unit. The microcode controls the iteration, while dedicated datapath logic handles the shifting and loop termination. Let&#39;s look at how these algorithms work.</p>
<h2 id="add-and-shift-multiplication">Add-and-shift multiplication</h2>
<p>The classic multiplication algorithm in processors is the Booth algorithm. However, the 80386 does not use that. Instead, an &#34;add-and-shift&#34; multiplication algorithm is used. This is similar to grade-school long multiplication. The difference is that instead of moving from lower digits to higher, we shift to the right. Here&#39;s the data layout:</p>
<p><img src="https://nand2mario.github.io/posts/2026/80386_multiplication_and_division/mul_layout.svg" alt="Multiplication data layout"/></p>
<p>Three key internal registers participate in multiplication: MULTMP, TMPB, and SIGMA. A notable challenge is that x86 instructions support 8-bit, 16-bit, and 32-bit operands. Consistent with the design philosophy of the 8086, the 386 achieves this flexibility by reusing the same registers and microcode routines for all operand sizes. In most cases, the identical hardware and microcode sequence accommodate different widths seamlessly. The diagram above shows how, for example, the result of multiplying two 16-bit numbers is arranged within a 32-bit product: it occupies the lower half of the SIGMA register and the upper half of TMPB.</p>
<p>Here is the multiplication algorithm in pseudocode:</p>
<pre><code>1: COUNTR = width-1
2: while (true):
3:   if (TMPB[0]) SIGMA &lt;= SIGMA + MULTMP
4:   {SIGMA, TMPB} &gt;&gt;= 1      // arithmetic shift for signed
5:   if (--COUNTR==0) break
6:   if (remaining TMPB bits are all 0 or all 1 for signed) break
7: {SIGMA, TMPB} &gt;&gt;= COUNTR   // compensate for early exit
8: correction for signed multiplication
</code></pre>
<p>Shifting to the right rather than the left simplifies the hardware circuits. Line 6 implements the important &#34;early-out&#34; optimization, which means the loop can terminate early if the remaining multiplier bits are all zeros—or all ones, in the case of signed multiplication. When this happens, line 7 adjusts for the early exit by shifting the accumulated result right by the number of remaining COUNTR bits.</p>
<p>Lines 1–7 fully describe unsigned multiplication. To extend this to signed multiplication, only a few tweaks are needed: use arithmetic (not logical) shifts on lines 4 and 7, and, as a final correction in line 8, subtract the multiplicand from the upper product register (SIGMA) if the multiplier was negative. For a deeper dive into the mathematics, see college-level computer organization resources such as <a href="https://web.ece.ucsb.edu/~parhami/pres_folder/f31-book-arith-pres-pt3.pdf">this one</a>.</p>
<p>The 80386 multiplication microcode closely mirrors the algorithm described above, and shows both the timing and the likely underlying hardware involved. The microcode routine shown here handles register-based multiplication—both unsigned and signed—and supports all three operand sizes: 8, 16, and 32 bits. Other forms, such as multiplying with a memory operand, are implemented similarly.</p>
<p>Before we examine the code, it’s helpful to quickly review the 80386’s microcode syntax and conventions. While the <a href="https://www.reenigne.org/blog/8086-microcode-disassembled/">8086 used 21-bit micro-operations</a>, the 80386 expanded these to 37 bits, adding fields to control more complex hardware functionality. Moves are written as <code>src-&gt;dest</code>, which simply means copying data from one register to another. The <code>alujmp</code> field directs either the ALU (using <code>src</code> and <code>alu_src</code> as inputs) or the microcode control flow, handling everything from arithmetic to jumps to indirect operations (<code>alu_src</code> as the jump target). Pay special attention to the <code>RPT</code> keyword found on the third line of the upcoming listing: this signals the microcode sequencer to repeatedly execute a micro-instruction, decrementing the COUNTR register each time, and continuing until COUNTR reaches zero, i.e. looping for COUNTR+1 iterations.</p>
<pre><code>; MUL/IMUL r
; src     dest    alu_src        alujmp  uop sub busop
DSTREG -&gt; MULTMP  BITS_V         LDCNTR          ; MULTMP=r (multiplicand), COUNTR=width-1
eAX_AL -&gt; TMPB    0              PASS2           ; TMPB=multiplier (AL/AX/EAX)
SIGMA             TMPB           IMUL3   RPT DLY ; hardware mult loop with early-out 
SIGMA                            PASS            ; pass through SIGMA
COUNTR -&gt; TMPD                                   ; save remaining COUNTR
RESULT -&gt; TMPC    TMPD           LDBSR8          ; load shift count: right shift, COUNTR
SIGMA  -&gt; TMPD    TMPC           SHIFT           ; shift {SIGMA,RESULT} to get low result
SIGMA  -&gt; eAX_AL  TMPD           MULFIX          ; write low result, set flags, signed mult correction
SIGMA             TMPD           SHIFT   RNI     ; shift {0,ProdU} to get high result
SIGMA  -&gt; eDX_AH                                 ; write high result
</code></pre>
<p>The <code>RESULT</code> register is used by both multiplication and division. For multiplication, it accumulates the lower half of the product as bits shift right out of TMPB during the loop. <code>MULFIX</code> is the correction for signed multiplication on pseudocode line 8.</p>
<h3 id="other-variants">Other variants</h3>
<p>The 386 introduced two new forms of IMUL beyond the original single-operand form:</p>
<ul>
<li><strong>Two-operand</strong>: <code>IMUL reg, r/m</code> - multiplies reg by r/m, stores in reg (single-width result)</li>
<li><strong>Three-operand</strong>: <code>IMUL reg, r/m, imm</code> - multiplies r/m by immediate, stores in reg (single-width result)</li>
</ul>
<p>These variants are interesting because they only produce a single-width result (discarding the upper half), making them faster for common cases where overflow isn&#39;t expected. The microcode for these uses a slightly different entry point that skips writing the upper result to EDX/DX/AH.</p>
<h2 id="division">Division</h2>
<p>80386 uses the standard <a href="https://en.wikipedia.org/wiki/Division_algorithm#Non-restoring_division">non-restoring division algorithm</a> for division. Here&#39;s the data layout:</p>
<p><img src="https://nand2mario.github.io/posts/2026/80386_multiplication_and_division/div_layout.svg" alt="Division data layout"/></p>
<p>The dividend is {SIGMA, DIVTMP} (max 64 bits), while the divisor is TMPB (max 32 bits). Each iteration shifts the dividend left by one bit and either adds or subtracts the divisor, building up the quotient in RESULT one bit at a time.</p>
<pre><code>1: do:                               // loop body is DIV7
2:     {SIGMA,DIVTMP} &lt;&lt;= 1;
3:     if (SIGMA &lt; 0) SIGMA += TMPB;
4:     else           SIGMA -= TMPB;
5:     RESULT = (RESULT &lt;&lt; 1) | (SIGMA &gt;= 0 ? 1 : 0)
6:     COUNTR--;
7: while (COUNTR &gt; 0)
8: if (SIGMA &lt; 0) SIGMA += TMPB;     // DIV5
</code></pre>
<p>Let&#39;s look at the division routine (<code>DIV r</code> at F6.6/F7.6) directly.</p>
<pre><code>; DIV r
eAX_AL -&gt; DIVTMP  BITS_V         LDCNTR          ; DIVTMP = lower half of dividend, COUNTR=width-1
eDX_AH                           PASS            ; SIGMA = upper half of dividend
DSTREG -&gt; TMPB                                   ; TMPB = divisor
SIGMA             TMPB            DIV7   RPT DLY ; Loop: dividend={SIGMA,DIVTMP}, divisor=TMPB
SIGMA             TMPB            DIV5           ; Final correction
SIGMA                            PASS            ; Preserve remainder through ALU
RESULT -&gt; eAX_AL                         RNI     ; accumulator = quotient 
SIGMA  -&gt; eDX_AH                                 ; upper-half reg = remainder
</code></pre>
<p>DIV7 and DIV5 are both single-cycle micro-operations. DIV7 implements the core of the division loop, corresponding to pseudocode lines 2–5 (excluding the COUNTR decrement). With each iteration, DIV7 updates SIGMA (the remainder) and RESULT (the quotient accumulator). The loop is controlled by the RPT instruction, which keeps the sequencer repeatedly executing DIV7 for COUNTR+1 iterations—there’s no early exit for division. After completing the main loop, DIV5 performs the final correction required by the non-restoring division algorithm (pseudocode line 8).</p>
<h3 id="signed-division-idiv">Signed division (IDIV)</h3>
<p>IDIV is more complex than DIV because it must handle signs. The approach is:</p>
<ol>
<li>Convert dividend and divisor to absolute values</li>
<li>Perform unsigned division</li>
<li>Adjust signs of quotient and remainder</li>
</ol>
<p>Here&#39;s the IDIV microcode:</p>
<pre><code>; IDIV r
-1                BITS_V         ADD             ; COUNTR=width-2
SIGMA  -&gt; COUNTR
eDX_AH                           PASS            ; SIGMA=upper dividend
eAX_AL -&gt; DIVTMP                                 ; DIVTMP=lower dividend
DSTREG -&gt; TMPB                                   ; TMPB=divisor
SIGMA             TMPB           PREDIV          ; |dividend|divisor|, save signs, first iteration
SIGMA             TMPB            DIV7   RPT DLY ; main division loop
SIGMA             TMPB            DIV5           ; non-restoring correction
SIGMA             TMPB           IDIV1           ; correct remainder sign
SIGMA                            PASS
SIGMA  -&gt; TMPB                                   ; save remainder
RESULT                           IDIV2           ; correct quotient sign -&gt; SIGMA
TMPB   -&gt; eDX_AH                         RNI     ; write remainder
SIGMA  -&gt; eAX_AL                                 ; write quotient
</code></pre>
<p>The key micro-ops are:</p>
<ul>
<li><strong>PREDIV</strong>: Computes absolute values of dividend and divisor, saves their signs in internal flip-flops, and performs the first division iteration</li>
<li><strong>IDIV1</strong>: Corrects the remainder&#39;s sign (remainder has same sign as dividend)</li>
<li><strong>IDIV2</strong>: Corrects the quotient&#39;s sign (negative if operand signs differ)</li>
</ul>
<p>This explains why IDIV takes 5 more cycles than DIV - the extra cycles handle sign computation and correction.</p>
<h2 id="additional-notes">Additional notes</h2>
<p>One of the biggest hurdles in deciphering CPUs is interpreting the role and meaning of each micro-operation and constant. Their interdependence often makes the process both challenging and fascinating. Consider BITS_V: at first glance, seeing it used in LDCNTR and loop logic, you might assume it simply represents the instruction’s bit width—such as 8, 16, or 32—meaning the RPT instruction would run for that number of COUNTR cycles. This approach seems to suffice for MUL and DIV. However, when applied to IDIV and AAM, the microcode repeatedly failed to function as expected. After many hours spent troubleshooting, I finally came across a clue in a seemingly unrelated part of the microcode:</p>
<pre><code>; PUSHAd
ESP               BITS_V         SUB         DLY      0    
SIGMA     INDSTK  -1             ADD             IN=+      
...
SIGMA  -&gt; eSP                                DLY           
</code></pre>
<p>This finally gave me the hint that BITS_V is <code>width-1</code> instead of <code>width</code>. Here PUSHA pushes 8 registers to the stack, so SP should be subtracted by <code>8*2=16</code> or <code>8*4=32</code> bytes. The existence of <code>SIGMA-1</code> (SIGMA, -1, ADD) after <code>SIGMA=ESP-BITS_V</code> (ESP, BITS_V, SUB) clearly indicates that BITS_V is one less than 16 or 32.</p>
<h2 id="comparison-with-modern-cpus">Comparison with modern CPUs</h2>
<p>The 386&#39;s iterative approach to multiplication and division was state-of-the-art for its time, but modern x86 processors have <a href="https://uops.info/">moved far beyond it</a>:</p>
<table>
<thead>
<tr>
<th>Era</th>
<th>Processor</th>
<th>32-bit MUL</th>
<th>32-bit DIV</th>
</tr>
</thead>
<tbody>
<tr>
<td>1985</td>
<td>80386</td>
<td>9-38 cycles</td>
<td>38 cycles</td>
</tr>
<tr>
<td>1993</td>
<td>Pentium</td>
<td>10 cycles</td>
<td>41 cycles</td>
</tr>
<tr>
<td>2000s</td>
<td>Core 2</td>
<td>3-4 cycles</td>
<td>17-41 cycles</td>
</tr>
<tr>
<td>2020s</td>
<td>Zen 3/Alder Lake</td>
<td>3-4 cycles</td>
<td>13-19 cycles</td>
</tr>
</tbody>
</table>
<p>Modern CPUs use dedicated multiplier arrays (often Booth-encoded Wallace trees) that can multiply 64-bit numbers in just a few cycles. Division remains slower because it&#39;s inherently sequential - each quotient bit depends on the previous remainder. However, modern CPUs use radix-4 or radix-16 division (computing 2-4 bits per cycle) and sophisticated prediction to speed things up.</p>
<p>The 386&#39;s &#34;one bit per cycle&#34; approach is elegant in its simplicity and its reuse of the main ALU. For an FPGA implementation, this microcode-driven design is actually quite practical - it minimizes hardware while still achieving reasonable performance.</p>
<p>Follows me on X (<a href="https://x.com/nand2mario">@nand2mario</a>) for updates, or use <a href="https://nand2mario.github.io/feed.xml">RSS</a>.</p>
<p>Credits: This analysis of the 80386 draws on the microcode disassembly and silicon reverse engineering work of <a href="https://www.reenigne.org/blog/">reenigne</a>, <a href="https://github.com/dbalsom">gloriouscow</a>, <a href="https://github.com/a-mcego">smartest blob</a>, and <a href="https://www.righto.com">Ken Shirriff</a>. For a detailed examination of the silicon itself, see Ken Shirriff’s <a href="https://www.righto.com/search/label/386">silicon reverse engineering series on the 80386</a>.</p>
    </div></div>
  </body>
</html>
