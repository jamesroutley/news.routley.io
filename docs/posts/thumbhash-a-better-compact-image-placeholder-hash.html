<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://evanw.github.io/thumbhash/">Original</a>
    <h1>ThumbHash: A better compact image placeholder hash</h1>
    
    <div id="readability-page-1" class="page">
  
  <p>
    A very compact representation of an image placeholder.
    Store it inline with your data and show it while the real image is loading for a smoother loading experience.
    It&#39;s similar to <a href="https://github.com/woltapp/blurhash">BlurHash</a> but with the following advantages:
  </p>
  <ul>
    <li>Encodes more detail in the same space</li>
    <li>Much faster to encode and decode</li>
    <li>Also encodes the aspect ratio</li>
    <li>Gives more accurate colors</li>
    <li>Supports images with alpha</li>
  </ul>
  <p>
    Despite doing all of these additional things, the code for ThumbHash is still similar in complexity to the code for
    BlurHash. One potential drawback compared to BlurHash is that the parameters of the algorithm are not configurable
    (everything is automatically configured).
  </p>
  <p>
    The code for this is available at
    <a href="https://github.com/evanw/thumbhash">https://github.com/evanw/thumbhash</a> and contains implementations for
    JavaScript, Rust, Swift, and Java. You can use <code>npm install thumbhash</code> to install the
    <a href="https://www.npmjs.com/package/thumbhash">JavaScript package</a> and <code>cargo add thumbhash</code> to
    install the <a href="https://crates.io/crates/thumbhash">Rust package</a>.
  </p>

  <h2 id="demo"><a href="#demo">#</a>Demo</h2>
  <table>
    <tbody><tr>
      <td>
        <img src="https://evanw.github.io/thumbhash/images/field.jpg" width="200" height="150"/>
      </td>
      <td>→</td>
      <td>
        </td>
      <td>→</td>
      <td>
        <img src="https://evanw.github.io/thumbhash/images/field-thumbhash.png" width="200" height="150"/>
      </td>
    </tr>
    <tr>
      <td>
         or drag/drop</td>
      <td colspan="3">
        ThumbHash generates an image</td>
      <td>
        Render the ThumbHash</td>
    </tr>
  </tbody></table>

  <h2 id="comparisons"><a href="#comparisons">#</a>Comparisons</h2>
  <p>
    The table below compares ThumbHash to several other similar approaches:
  </p>
  <ul>
    <li>
      <p>
        <b>ThumbHash:</b>
        ThumbHash encodes a higher-resolution luminance channel, a lower-resolution color channel, and an optional alpha
        channel. The format is described in detail in the <a href="#details">details section</a>. There are no
        parameters to configure.
      </p>
    </li>
    <li>
      <p>
        <b>BlurHash:</b>
        Uses <a href="https://github.com/woltapp/blurhash">BlurHash</a> with 3x3 components for square images, 4x3
        components for landscape images, and 3x4 components for portrait images. This is the configuration recommended
        in the documentation, and is roughly the same size as a ThumbHash encoded using base64.
      </p>
    </li>
    <li>
      <p>
        <b>Potato WebP:</b>
        This is an experiment of mine to see how Google&#39;s
        <a href="https://developers.google.com/speed/webp/docs/compression">WebP image format</a> does at this. The
        &#34;hash&#34; is just the contents of the &#34;VP8&#34; chunk in a minimal WebP file: 0% quality (i.e.
        <a href="https://knowyourmeme.com/memes/recorded-with-a-potato">potato quality</a>) and a size of 16x16, since
        WebP encodes everything in 16x16 blocks. The image is reconstructed by blurring a scaled-up copy of a minimal
        WebP file with the VP8 chunk reinserted.
      </p>
    </li>
  </ul>
  <p>
    In addition to these sample images, you can also drag and drop your own images to compare them here.
  </p>
  <table>
    <tbody><tr>
      <th>Original image</th>
      <th>ThumbHash</th>
      <th>BlurHash</th>
      <th>Potato WebP</th>
    </tr>
  </tbody></table>
  

  <h2 id="details"><a href="#details">#</a>Details</h2>
  <p>
    The image is approximated using the
    <a href="https://en.wikipedia.org/wiki/Discrete_cosine_transform">Discrete Cosine Transform</a>. Luminance is
    encoded using up to 7 terms in each dimension while chrominance (i.e. color) is encoded using 3 terms in each
    dimension. The optional alpha channel is encoded using 5 terms in each dimension if present. If alpha is present,
    luminance is only encoded using up to 5 terms in each dimension.
  </p>
  <p>
    Each channel of DCT coefficients comes in three parts: the DC term, the AC terms, and the scale. The DC term is the
    coefficient for the 0th order cosine and the AC terms are the coefficients of all other cosines (DC and AC are terms
    from signal processing). All values are quantized to only a few bits each. To maximize the useful numeric range, AC
    values are scaled up by the maximum magnitude and the scale is saved separately. In addition, ThumbHash omits the
    high-frequency half of the coefficients and only keep the low-frequency half. If you are familiar with JPEG&#39;s
    zig-zag coefficient order, this roughly corresponds to stopping halfway through that sequence. The rationale is that
    the low-frequency coefficients carry most of the information, and we also want a smooth image.
  </p>
  <p>
    Luminance and chrominance is represented in a simple color space that&#39;s easy to encode and decode. It uses the
    values L for luminance, P for yellow vs. blue, and Q for red vs. green (inspired by human eyesight). The
    advantage of LPQ over RGB is that variation in luminance is typically more important than variation in chrominance,
    so we can make better use of space by using more space for luminance and less space for chrominance. Note that the
    range of L is 0 to 1 but the range of P and Q is -1 to 1 because they each represent a subtraction.
  </p>
  <p>To convert from RGB to LPQ:</p>
  <pre>l = (r + g + b) / <span>3</span>;
p = (r + g) / <span>2</span> - b;
q = r - g;</pre>
  <p>And to convert from LPQ back to RGB:</p>
  <pre>b = l - <span>2</span> / <span>3</span> * p;
r = (<span>3</span> * l - b + q) / <span>2</span>;
g = r - q;</pre>
  <p>
    The file format is tightly packed and each number uses fewer than 8 bits.
    If the ThumbHash file format were to be represented as a C++ struct, it might look something like this:
  </p>
  <pre><span>struct</span> ThumbHash {
  
  <span>uint8_t</span> l_dc : <span>6</span>;
  <span>uint8_t</span> p_dc : <span>6</span>;
  <span>uint8_t</span> q_dc : <span>6</span>;
  <span>uint8_t</span> l_scale : <span>5</span>;
  <span>uint8_t</span> has_alpha : <span>1</span>;

  
  <span>uint8_t</span> l_count : <span>3</span>;
  <span>uint8_t</span> p_scale : <span>6</span>;
  <span>uint8_t</span> q_scale : <span>6</span>;
  <span>uint8_t</span> is_landscape : <span>1</span>;

  
  <span>#if</span> has_alpha
    
    <span>uint8_t</span> a_dc : <span>4</span>;
    <span>uint8_t</span> a_scale : <span>4</span>;
  <span>#endif</span>

  
  <span>uint8_t</span> l_ac[] : <span>4</span>;
  <span>uint8_t</span> p_ac[] : <span>4</span>;
  <span>uint8_t</span> q_ac[] : <span>4</span>;

  
  <span>#if</span> has_alpha
    <span>uint8_t</span> a_ac[] : <span>4</span>;
  <span>#endif</span>
};</pre>
  <p>
    The colon syntax after each field is the number of bits used by that field. The length of each AC array is the
    number of coefficients left after removing the 0th component (i.e. the DC component) and also removing the
    high-frequency half of the components. Representing that in C code might look something like this for a single
    channel, where <code>nx</code> and <code>ny</code> are the numbers of coefficients in each dimension:
  </p>
  <pre><span>for</span> (<span>int</span> y = <span>0</span>; y &lt; ny; y++)
  <span>for</span> (<span>int</span> x = <span>0</span>; x &lt; nx; x++)
    <span>if</span> ((x != <span>0</span> || y != <span>0</span>) &amp;&amp; (x * ny + y * nx &lt; nx * ny))
      readAC();</pre>
  <p>
    The number of luminance components is derived as follows:
  </p>
  <pre><span>if</span> (is_landscape) {
  lx = max(<span>3</span>, has_alpha ? <span>5</span> : <span>7</span>);
  ly = max(<span>3</span>, l_count);
} <span>else</span> {
  lx = max(<span>3</span>, l_count);
  ly = max(<span>3</span>, has_alpha ? <span>5</span> : <span>7</span>);
}</pre>
  <p>
    Using the <code>is_landscape</code> and <code>has_alpha</code> flags like this to make the number of coefficients in
    one dimension implicit is a way to save space. Since the number of components is automatically derived from the
    aspect ratio of the original image, you can also use this information to derive an approximation of the original
    aspect ratio.
  </p>
  <p>
    If you just want the average color of the image (e.g. in a situation where showing a placeholder image is
    impractical), you can get that by transforming the <code>l_dc</code>, <code>p_dc</code>, and <code>q_dc</code>
    values from LPQ to RGB. These values are conveniently at the front of the file for this purpose.
  </p>
  <p>
    Reference implementations for this algorithm can be found at
    <a href="https://github.com/evanw/thumbhash">https://github.com/evanw/thumbhash</a>.
  </p>

  

  



</div>
  </body>
</html>
