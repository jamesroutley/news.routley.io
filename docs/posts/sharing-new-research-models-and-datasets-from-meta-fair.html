<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://ai.meta.com/blog/meta-fair-research-new-releases/">Original</a>
    <h1>Sharing new research, models, and datasets from Meta FAIR</h1>
    
    <div id="readability-page-1" class="page"><div><p>For <a href="https://ai.meta.com/blog/fair-10-year-anniversary-open-science-meta/" target="_blank" data-lnfb-mode="ie"><u>more than a decade</u></a>, Meta’s Fundamental AI Research (FAIR) team has focused on advancing the state of the art in AI through open research. As innovation in the field continues to move at a rapid pace, we believe that collaboration with the global AI community is more important than ever. Maintaining an open science approach and sharing our work with the community help us stay true to our goal of building AI systems that work well for everyone and bring the world closer together.</p><p>Today, we’re excited to share some of the most recent FAIR research models with the global community. We’re publicly releasing six research artifacts that focus on themes at the core of our work: innovation, creativity, efficiency, and responsibility. These releases include image-to-text and text-to-music generation models, a multi-token prediction model, and a technique for detecting AI-generated speech. By publicly sharing our early research work, we hope to inspire iterations and ultimately help advance AI in a responsible way. We can’t wait to see what the community builds with these latest releases and continue the important conversations we’re having with the open source community.</p><br/></div></div>
  </body>
</html>
