<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://research.swtch.com/sparse">Original</a>
    <h1>Using uninitialized memory for fun and profit (2008)</h1>
    
    <div id="readability-page-1" class="page"><div>
      <div>
        
        
<p>
This is the story of a clever trick that&#39;s been around for
at least 35 years, in which array values can be left
uninitialized and then read during normal operations,
yet the code behaves correctly no matter what garbage
is sitting in the array.
Like the best programming tricks, this one is the right tool for the 
job in certain situations.
The sleaziness of uninitialized data
access is offset by performance improvements:
some important operations change from linear 
to constant time.
</p>

<p>
Alfred Aho, John Hopcroft, and Jeffrey Ullman&#39;s 1974 book 
<i>The Design and Analysis of Computer Algorithms</i>
hints at the trick in an exercise (Chapter 2, exercise 2.12):
</p>

<blockquote>
Develop a technique to initialize an entry of a matrix to zero
the first time it is accessed, thereby eliminating the <i>O</i>(||<i>V</i>||<sup>2</sup>) time
to initialize an adjacency matrix.
</blockquote>

<p>
Jon Bentley&#39;s 1986 book <a href="http://www.cs.bell-labs.com/cm/cs/pearls/"><i>Programming Pearls</i></a> expands
on the exercise (Column 1, exercise 8; <a href="http://www.cs.bell-labs.com/cm/cs/pearls/sec016.html">exercise 9</a> in the Second Edition):
</p>

<blockquote>
One problem with trading more space for less time is that 
initializing the space can itself take a great deal of time.
Show how to circumvent this problem by designing a technique
to initialize an entry of a vector to zero the first time it is
accessed.  Your scheme should use constant time for initialization
and each vector access; you may use extra space proportional
to the size of the vector.  Because this method reduces 
initialization time by using even more space, it should be
considered only when space is cheap, time is dear, and 
the vector is sparse.
</blockquote>

<p>
Aho, Hopcroft, and Ullman&#39;s exercise talks about a matrix and 
Bentley&#39;s exercise talks about a vector, but for now let&#39;s consider
just a simple set of integers.
</p>

<p>
One popular representation of a set of <i>n</i> integers ranging
from 0 to <i>m</i> is a bit vector, with 1 bits at the
positions corresponding to the integers in the set.
Adding a new integer to the set, removing an integer
from the set, and checking whether a particular integer
is in the set are all very fast constant-time operations
(just a few bit operations each).
Unfortunately, two important operations are slow:
iterating over all the elements in the set 
takes time <i>O</i>(<i>m</i>), as does clearing the set.
If the common case is that 
<i>m</i> is much larger than <i>n</i>
(that is, the set is only sparsely
populated) and iterating or clearing the set 
happens frequently, then it could be better to
use a representation that makes those operations
more efficient.  That&#39;s where the trick comes in.
</p>

<p>
Preston Briggs and Linda Torczon&#39;s 1993 paper,
“<a href="http://citeseer.ist.psu.edu/briggs93efficient.html"><b>An Efficient Representation for Sparse Sets</b></a>,”
describes the trick in detail.
Their solution represents the sparse set using an integer
array named <code>dense</code> and an integer <code>n</code>
that counts the number of elements in <code>dense</code>.
The <i>dense</i> array is simply a packed list of the elements in the
set, stored in order of insertion.
If the set contains the elements 5, 1, and 4, then <code>n = 3</code> and
<code>dense[0] = 5</code>, <code>dense[1] = 1</code>, <code>dense[2] = 4</code>:
</p>

<center>
<img src="http://research.swtch.com/sparse0.png"/>
</center>

<p>
Together <code>n</code> and <code>dense</code> are
enough information to reconstruct the set, but this representation
is not very fast.
To make it fast, Briggs and Torczon
add a second array named <code>sparse</code>
which maps integers to their indices in <code>dense</code>.
Continuing the example,
<code>sparse[5] = 0</code>, <code>sparse[1] = 1</code>, 
<code>sparse[4] = 2</code>.
Essentially, the set is a pair of arrays that point at
each other:
</p>

<center>
<img src="http://research.swtch.com/sparse0b.png"/>
</center>

<p>
Adding a member to the set requires updating both of these arrays:
</p>

<pre>add-member(i):
    dense[n] = i
    sparse[i] = n
    n++
</pre>

<p>
It&#39;s not as efficient as flipping a bit in a bit vector, but it&#39;s 
still very fast and constant time. 
</p>

<p>
To check whether <code>i</code> is in the set, you verify that
the two arrays point at each other for that element:
</p>

<pre>is-member(i):
    return sparse[i] &lt; n &amp;&amp; dense[sparse[i]] == i
</pre>

<p>
If <code>i</code> is not in the set, then <i>it doesn&#39;t matter what <code>sparse[i]</code> is set to</i>:
either <code>sparse[i]</code>
will be bigger than <code>n</code> or it will point at a value in 
<code>dense</code> that doesn&#39;t point back at it.
Either way, we&#39;re not fooled.  For example, suppose <code>sparse</code>
actually looks like:
</p>

<center>
<img src="http://research.swtch.com/sparse1.png"/>
</center>

<p>
<code>Is-member</code> knows to ignore
members of sparse that point past <code>n</code> or that
point at cells in <code>dense</code> that don&#39;t point back,
ignoring the grayed out entries:

</p><center>
<img src="http://research.swtch.com/sparse2.png"/>
</center>

<p>
Notice what just happened:
<code>sparse</code> can have <i>any arbitrary values</i> in
the positions for integers not in the set, 
those values actually get used during membership
tests, and yet the membership test behaves correctly!
(This would drive <a href="http://valgrind.org/">valgrind</a> nuts.)
</p>

<p>
Clearing the set can be done in constant time:
</p>
<pre>clear-set():
    n = 0
</pre>

<p>
Zeroing <code>n</code> effectively clears 
<code>dense</code> (the code only ever accesses
entries in dense with indices less than <code>n</code>), and
<code>sparse</code> can be uninitialized, so there&#39;s no 
need to clear out the old values.
</p>

<p>
This sparse set representation has one more trick up its sleeve:
the <code>dense</code> array allows an 
efficient implementation of set iteration.
</p>

<pre>iterate():
    for(i=0; i&lt;n; i++)
        yield dense[i]
</pre>

<p>
Let&#39;s compare the run times of a bit vector 
implementation against the sparse set:
</p>
<center>
<table>
<tbody><tr>
  <td><i>Operation</i>
  </td><td>
  </td><td><i>Bit Vector</i>
  </td><td>
  </td><td><i>Sparse set</i>
</td></tr>
<tr>
  <td>is-member
  </td><td>
  </td><td><i>O</i>(1)
  </td><td> 
  </td><td><i>O</i>(1)
</td></tr>
<tr>
  <td>add-member
  </td><td>
  </td><td><i>O</i>(1)
  </td><td>
  </td><td><i>O</i>(1)
</td></tr>
<tr>
  <td>clear-set
  </td><td></td><td><i>O</i>(<i>m</i>)
  </td><td></td><td><i>O</i>(1)
</td></tr>
<tr>
  <td>iterate
  </td><td></td><td><i>O</i>(<i>m</i>)
  </td><td></td><td><i>O</i>(<i>n</i>)
</td></tr>
</tbody></table>
</center>

<p>
The sparse set is as fast or faster than bit vectors for
every operation.  The only problem is the space cost:
two words replace each bit.
Still, there are times when the speed differences are enough
to balance the added memory cost.
Briggs and Torczon point out that liveness sets used 
during register allocation inside a compiler are usually
small and are cleared very frequently, making sparse sets the
representation of choice.
</p>

<p>
Another situation where sparse sets are the better choice
is work queue-based graph traversal algorithms.
Iteration over sparse sets visits elements
in the order they were inserted (above, 5, 1, 4),
so that new entries inserted during the iteration
will be visited later in the same iteration.
In contrast, iteration over bit vectors visits elements in
integer order (1, 4, 5), so that new elements inserted
during traversal might be missed, requiring repeated
iterations.
</p>

<p>
Returning to the original exercises, it is trivial to change
the set into a vector (or matrix) by making <code>dense</code>
an array of index-value pairs instead of just indices.
Alternately, one might add the value to the <code>sparse</code>
array or to a new array.
The relative space overhead isn&#39;t as bad if you would have been
storing values anyway.
</p>

<p>
Briggs and Torczon&#39;s paper implements additional set
operations and examines performance speedups from
using sparse sets inside a real compiler.
</p>








      </div>
    </div></div>
  </body>
</html>
