<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://videogigagan.github.io/">Original</a>
    <h1>VideoGigaGAN: Towards Detail-Rich Video Super-Resolution</h1>
    
    <div id="readability-page-1" class="page">


  <nav role="navigation" aria-label="main navigation">
    
    
  </nav>

<section>
  <div>
    <div>
      <div>
        <div>
          

          

          <p><span><sup>üê¢</sup>University of Maryland, College Park</span> ¬†¬†¬†¬†¬†¬†
            <span><sup><img src="https://videogigagan.github.io/assets/images/adobe.png" width="15"/></sup>Adobe Research</span>
          </p>

          
          



          
        </div>
      </div>
    </div>
  </div>
</section>


<!-- first row -->
<section id="8xresults">
  <div>
    <div>


    <p>
        <h2>8√ó Upsampling results (128√ó128‚Üí1024√ó1024)</h2>
    </p>    
    
  
       
    

      <center>
        <p>Our model is able to upsample a video up to 8√ó with rich details.</p>
      </center>
  </div>
</div></section>

<section id="abstract">
  <div>
    <div>
      <div>
        <h2>Abstract</h2>
        <p>Video super-resolution (VSR) approaches have shown impressive temporal consistency in upsampled videos. 
            However, these approaches tend to generate blurrier results than their image counterparts as they are limited in their generative capability.
            This raises a fundamental question: can we extend the success of a generative image upsampler to the VSR task while preserving the temporal consistency?
            We introduce VideoGigaGAN, a new generative VSR model that can produce videos with high-frequency details and temporal consistency.
            VideoGigaGAN builds upon a large-scale image upsampler -- GigaGAN. 
            Simply inflating GigaGAN to a video model by adding temporal modules produces severe temporal flickering.
            We identify several key issues and propose techniques that significantly improve the temporal consistency of upsampled videos.
            Our experiments show that, unlike previous VSR methods, VideoGigaGAN generates temporally consistent videos with more fine-grained appearance details.
            We validate the effectiveness of VideoGigaGAN by comparing it with state-of-the-art VSR models on public datasets and showcasing video results with 8√ó super-resolution.</p>
        <!-- <div class="column" style="display: flex; justify-content: center;">
          <div class="column has-text-justified" style="flex: 1;  max-width: 45%">
            <image src="assets/images/abstract.svg"/>
          </div>
          <div class="column has-text-justified" style="flex: 1; display: table;">
            <p style="display: table-cell; vertical-align: middle;">
              Our method only takes 15 minutes to optimize a representation from an in-the-wild video and can render novel views at 27 FPS.
              <br><br>
              On the NVIDIA Dataset, our method achieves a rendering quality comparable to state-of-the-art NeRF-based methods but is much faster to train and render. 
              <br><br>
              * The bubble size in the figure indicates the training time (GPU-hours). The training time does not include preprocessing time for all methods.
            </p>
          </div> -->
        </div>
      </div>
    </div>
  
</section>

<!-- Paper video. -->

  <div id="spotlight-video">
      <div>
          <div>
            <h2>
              <span>Overview: Why is it challenging?</span>
            </h2>
            
        </div>
      </div>
  </div>





<section id="method-overview">
  <div>
    <div>
      <div>
        <h2>Method Overview</h2>
        <div>
          <p><img src="https://videogigagan.github.io/assets/images/method_overview.svg"/></p></div>
      </div>
    </div>
  </div>
</section>


<section id="ablation">
    <div>
        <p>
            <h2>Ablation study</h2>
        </p>
        
        <center> 
          <p>
            Strong hallucination capability of image GigaGAN results in temporally flickering artifacts, 
            especially aliasing caused by the artifacted LR input.
          </p>
        </center>
        
        
        
        <!-- Slider for Data -->
        
        
        <p>Slide to switch between different examples</p> 

        <!-- Method Buttons -->
        
        
      <div>
        
        <p id="currentMethodDisplay2"> Image GigaGAN (base model) </p>
        <p> GT </p>
      </div>
        
        
       
        
    </div>
</section>

<section id="comparison">
    <div>
        <p>
            <h2>Comparison with previous methods</h2>
        </p>
        

        <center>
          <p>
            Compared to previous models, our models provides a detail-rich result with comparable temporal consistency.
          </p>
          </center><!-- Slider for Data -->
        
        
        
        <!-- <div class="columns is-centered has-text-centered">
          <p>Slide to switch between different examples</p>
        </div> -->

        

        

        

        <!-- Method Buttons -->
        
      
      

        

        
    </div>
</section>


<section id="4xresults">
    <div>
      <p>
        <h2>Results on generic videos (128√ó128‚Üí512√ó512)</h2>
      </p>
      
      
    
    <center>
      <p>
        Our model is able to handle generic videos of different categories.
      </p>
    </center>
</div></section>


<section id="BibTeX">
  <div>
    <h2>BibTeX</h2>
    <pre><code>@article{xu2024videogigagan,
      title={VideoGigaGAN: Towards Detail-rich Video Super-Resolution}, 
      author={Yiran Xu and Taesung Park and Richard Zhang and Yang Zhou and Eli Shechtman and Feng Liu and Jia-Bin Huang and Difan Liu},
      year={2024},
      eprint={2404.12388},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
  }</code></pre>
  </div>
</section>





  <!-- custom js file  -->
  <!-- <script defer src="./assets/js/fontawesome.all.min.js"></script> -->
  
  
  
  
  
  
  
  
  


</div>
  </body>
</html>
