<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/drti">Original</a>
    <h1>The Dynamic Runtime Inlining project</h1>
    
    <div id="readability-page-1" class="page"><article itemprop="text">
<p dir="auto">With this project it is possible to take the output from an
<a href="http://llvm.org/" rel="nofollow">LLVM</a> compiler such as
<a href="https://clang.llvm.org/" rel="nofollow">clang</a> and allow selected parts of the code
to recompile themselves at runtime. This can inline function calls
made via function pointers including virtual function dispatch and
across shared-object boundaries. In these cases the targets of the
calls are generally known only at runtime, hence the name &#34;Runtime
Inlining&#34;.</p>
<p dir="auto">This is different to LLVM&#39;s <a href="https://www.llvm.org/docs/LinkTimeOptimization.html" rel="nofollow">Link Time
Optimizations</a>
and can inline cases that LTO doesn&#39;t handle. It also <strong>doesn&#39;t</strong>
involve an LLVM bitcode <strong>interpreter</strong>; it runs native machine code
generated by Ahead of Time (AOT) compilation that can make calls to a
Just in Time (JIT) runtime compiler when needed.</p>
<p dir="auto">The basic concept is to get the normal compiler front end like clang
to emit its LLVM Intermediate Representation (IR) as a bitcode file,
then run a custom LLVM pass over this to inject DRTI code at the
appropriate places. The custom pass also embeds the original bitcode
as a binary string in the output so that the bitcode is available at
runtime for recompilation. The command-line tool llc compiles the
adapted bitcode into a native object file.</p>
<p dir="auto">Although the concept is fairly simple there were (and still are)
several challenges in its implementation. Currently the project is a
proof of concept, demonstrating that the idea can work, but not likely
to improve the speed of any real-world applications.</p>
<h2 dir="auto"><a id="user-content-supported-platforms" aria-hidden="true" href="#supported-platforms"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Supported Platforms</h2>
<p dir="auto">For now the code only works on Linux on the x86-64 architecture. It
requires a small patch to the LLVM sources which I&#39;ve tested with LLVM
version 12 and 13.</p>
<h2 dir="auto"><a id="user-content-building-the-code" aria-hidden="true" href="#building-the-code"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Building the code</h2>
<ol dir="auto">
<li>You&#39;ll need to download and unpack the LLVM sources (e.g. <a href="https://github.com/llvm/llvm-project/releases/download/llvmorg-12.0.1/llvm-project-12.0.1.src.tar.xz">llvm-project-12.0.1.src.tar.xz</a>)</li>
<li>Clone the drti git repository, e.g. git clone <a href="https://github.com/drti/drti.git">https://github.com/drti/drti.git</a></li>
<li>Apply the small LLVM source patch llvm-drti.patch from the drti root directory into the llvm subdirectory, e.g. cd llvm-project-12.0.1.src/llvm &amp;&amp; patch -p1 &lt;$HOME/drti/llvm-drti.patch</li>
<li>Configure, build and install LLVM and clang. Some suggested cmake options are -DLLVM_TARGETS_TO_BUILD=&#34;X86&#34; -DLLVM_ENABLE_PROJECTS=&#34;clang;compiler-rt&#34; -DCMAKE_INSTALL_PREFIX=$HOME/install/llvm-12</li>
</ol>
<p dir="auto">You can then cd to the drti root directory to build drti and run its
tests using make, providing the path to the root of your fresh LLVM
installation, e.g.</p>
<div dir="auto" data-snippet-clipboard-copy-content="make LLVM_EXE_ROOT_DIR=$HOME/install/llvm-12"><pre>make LLVM_EXE_ROOT_DIR=<span>$HOME</span>/install/llvm-12</pre></div>
<p dir="auto">Just to be clear, LLVM_EXE_ROOT_DIR should be set so that the Makefile
can run $(LLVM_EXE_ROOT_DIR)/bin/llvm-config.</p>
<p dir="auto">Please send <a href="mailto:62238636+drti@users.noreply.github.com">the
author</a> feedback if you
do try this out; I would be interested to hear if anyone else gets it
working.</p>
<h2 dir="auto"><a id="user-content-examples-and-tests" aria-hidden="true" href="#examples-and-tests"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Examples and tests</h2>
<p dir="auto">There are some tests in tests subdirectory which demonstrate function
pointer and virtual function inlining. The Makefiles contain the logic
for building the DRTI decoration pass, the runtime support functions
and for invoking the decoration pass on the test code. As noted in the
&#34;Implementation&#34; section, currently DRTI requires an explicit list of
candidate functions to decorate which is contained in
tests/drti_test_targets.txt</p>
<h2 dir="auto"><a id="user-content-implementation" aria-hidden="true" href="#implementation"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Implementation</h2>
<p dir="auto">This section details some of the complexities of making DRTI work,
including some remaining areas for further development.</p>
<h3 dir="auto"><a id="user-content-call-target-identification" aria-hidden="true" href="#call-target-identification"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Call-target identification</h3>
<p dir="auto">As mentioned in the introduction, DRTI has an ahead-of-time pass that
&#34;decorates&#34; functions in preparation for runtime inlining. However it
does <strong>not</strong> require that an entire program and all its libraries be
decorated. Decorated functions may call in to undecorated ones and
vice-versa.</p>
<p dir="auto">The problem, then, is for one decorated function to discover when the
target of a function call is another decorated function. Or to put it
another way, two decorated functions have to be able to recognise an
edge between them in the call graph, but only when it is a <strong>direct</strong>
edge with no intervening calls. The second condition is very
important, since a call chain from A* -&gt; B -&gt; C* (where only A* and C*
are decorated functions) must not result in mistakenly recompiling A
with a direct call to C.</p>
<p dir="auto">Unfortunately that means that a simple solution such as using
thread-specific storage (TSS) to retain a per-thread DRTI call stack
won&#39;t simply work, because only decorated functions would update the
state and intermediate non-decorated functions would be difficult to
detect.</p>
<p dir="auto">I thought about this problem for a while and have come up with what I
believe is a robust mechanism for communication between decorated
functions. This is only partly implemented at the moment, for reasons
explained in the following description.</p>
<p dir="auto">The first step is to find a register in which a decorated function can
pass a pointer to the latest node in the DRTI call tree.  Within the
Linux <a href="https://refspecs.linuxfoundation.org/elf/x86_64-abi-0.99.pdf" rel="nofollow">x86-64 Application Binary
Interface</a>
(ABI) r12 to r15 are suitable. The other registers are not suitable
since they might be used already in the function call or in the case
of r11 can be overwritten before arriving at the called function. I&#39;ve
chosen r14 to avoid unnecessary incompatibility with the <a href="https://clang.llvm.org/docs/AttributeReference.html#swift-context" rel="nofollow">swiftcall
convention</a>
after coming across <a href="https://reviews.llvm.org/D18092" rel="nofollow">D18092</a> and
<a href="https://reviews.llvm.org/D18108" rel="nofollow">D18108</a>. For this part using TSS
would also work, but the register mechanism is a bit simpler.</p>
<p dir="auto">The second and trickier part is to get a decorated function to
recognise when the r14 register is valid on entry, i.e. when the call
came directly from another decorated function. Perhaps surprisingly,
there is a way to do this by passing information via the return
address which is pushed onto the stack by the caller. The return
address normally points to the next instruction after a call, but if
we organise for the bytes preceding the return address to contain a
&#34;magic&#34; value instead of a call instruction, the callee can get the
return address from the stack and dereference it (minus an offset) to
check for the magic value. This assumes that the magic value could not
occur in a real call instruction, and also that the return address is
not too close to the start of a page boundary, since the preceding
page isn&#39;t guaranteed to be readable and we don&#39;t want to SEGV in any
circumstances. If there are any other runtime instrumentation systems
using the same trick it would also require that they choose a distinct
magic value, of course.</p>
<p dir="auto">This actually leaves one gap in the detection mechanism since a &#34;tail&#34;
call to a decorated function via a jump does not push a return
address; it leaves its own caller&#39;s return address on top of the
stack. So in the call chain A* -&gt; B -&gt; C* where B -&gt; C* is a jump
rather than a call, C* would mistakenly conclude that it had been
called directly by A*. There is a way out of this problem though,
since B is required to preserve the callee-saved r14 register. This
means that C* can safely read the call tree information provided by A*
and examine the final call&#39;s target address to determine whether the
call would have gone directly to C* or not. This is made more
complicated by the presence of the procedure linkage table (PLT) and
virtual function call &#34;thunks&#34; but I believe it is doable.</p>
<p dir="auto">In the existing proof-of-concept the tail-call detection is not yet
implemented but there is a test case in the code that demonstrates the
problem. The magic value is also stored slightly further away from the
return address than described above. This last issue can be fixed by
making each decorated call go via a small trampoline function that
overwrites the return address and then jumps to the original call
target (of course, this will upset the CPU&#39;s return address stack a
little, see <a href="https://blog.stuffedcow.net/2018/04/ras-microbenchmarks/" rel="nofollow">Microbenchmarking Return Address Branch
Prediction</a>
for a nice discussion of this). The manipulated return address can
then point to an instruction that jumps back to the code after the
original call site can can be immediately preceded by the magic
value. This avoids any risk of mistaking a normal call for a decorated
one.</p>
<p dir="auto">Protection against unreadable preceding pages is already implemented,
by forcing the return addresses to be highly aligned. This means the
return is either to the zeroth byte of a page or sufficiently far into
the page that the magic value is guaranteed to be readable.</p>
<h3 dir="auto"><a id="user-content-deciding-what-calls-to-inline" aria-hidden="true" href="#deciding-what-calls-to-inline"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Deciding what calls to inline</h3>
<p dir="auto">Currently the developer must provide an explicit list of functions to
be decorated by the DRTI pass. This is done via an environment
variable and/or a text file. All chains of three decorated functions
will be recompiled (once only) the first time the chain is discovered
at runtime.</p>
<p dir="auto">In theory the explicit list is not necessary but doing without would
require significantly more work to reduce the overheads of the
injected code and to implement runtime heuristics to decide when to
recompile. There is some background on efficient implementation
techniques in the paper <a href="https://dl.acm.org/doi/pdf/10.1145/2500828.2500829" rel="nofollow">Deriving Code Coverage Information from
Profiling Data Recorded for a Trace-based Just-in-time
Compiler</a> by
Christian Häubl, Christian Wimmer and Hanspeter Mössenböck.</p>
<h3 dir="auto"><a id="user-content-call-re-targeting" aria-hidden="true" href="#call-re-targeting"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Call re-targeting</h3>
<p dir="auto">DRTI does not have an implementation of &#34;on stack replacement&#34;. This
means that the only way that inlining can actually happen is where
there is a chain of at least three decorated calls. The first call has
to be decorated so that it can be retargeted to a recompiled version
of its target function, and that target function must make a call to
another decorated function that can be inlined during recompilation.</p>
<p dir="auto">For example in a chain of decorated calls A* -&gt; B* -&gt; C*, the
intermediate function B could be recompiled with C inlined, resulting
in B+. Then, assuming the original B* ever returns, A* could call B+
instead of B* the next time it needs. This works because the decorated
code in A* includes support for this &#34;retargeting&#34;.</p>
<p dir="auto">This can probably be improved using something like the <a href="http://llvm.org/docs/StackMaps.html" rel="nofollow">stack
maps</a> that were developed for the
WebKit JavaScript runtime compiler. As I understand it WebKit has
since moved away from using LLVM but the stack map code could still be
useful for DRTI.</p>
<h3 dir="auto"><a id="user-content-de-optimization" aria-hidden="true" href="#de-optimization"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>De-optimization</h3>
<p dir="auto">Currently the recompiled code does not perform any profiling and so
can&#39;t detect the need for &#34;de-optimization&#34;. This means that the first
call target encountered will be the one hard-coded into the recompiled
version, and any other call targets will go via a slower path without
any inlining.</p>
<h3 dir="auto"><a id="user-content-symbol-resolution" aria-hidden="true" href="#symbol-resolution"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Symbol resolution</h3>
<p dir="auto">Ahead of time compilation depends on a linker to handle external
symbols. At runtime it&#39;s a bit trickier and in some cases the symbolic
information simply won&#39;t be available, for example a stripped program
and/or symbols with &#34;hidden&#34; visibility. For this reason the DRTI
decoration pass not only saves the original bitcode in the output
module but also an array with the address of every global that the
original bitcode requires. During runtime recompilation it can use
this array to resolve symbols as needed.</p>
<h3 dir="auto"><a id="user-content-static-data" aria-hidden="true" href="#static-data"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Static data</h3>
<p dir="auto">When recompiling a module at runtime, DRTI takes care to ensure that
it does not end up with an extra copy of any static data defined in a
module. For example a C++ function with a static variable such as the
test function below results in two global variables as shown in the
following LLVM assembly code.</p>
<div dir="auto" data-snippet-clipboard-copy-content="const void* test_target2()
{
    static unsigned&amp; counter = drti_test::new_counter(&#34;test_target2&#34;);
    ++counter;
    return drti_test::instruction_pointer();
}"><pre><span>const</span> <span>void</span>* <span>test_target2</span>()
{
    <span>static</span> <span>unsigned</span>&amp; counter = <span>drti_test::new_counter</span>(<span><span>&#34;</span>test_target2<span>&#34;</span></span>);
    ++counter;
    <span>return</span> <span>drti_test::instruction_pointer</span>();
}</pre></div>
<div dir="auto" data-snippet-clipboard-copy-content="@_ZZ12test_target2vE7counter = internal unnamed_addr global i32* null, align 8, !dbg !0
@_ZGVZ12test_target2vE7counter = internal global i64 0, align 8"><pre><span>@_ZZ12test_target2vE7counter = internal unnamed_addr</span> <span>global</span> <span>i32</span><span>*</span><span> null</span><span>,</span><span> align </span><span>8</span><span>,</span><span> !dbg !</span><span>0</span>
<span>@_ZGVZ12test_target2vE7counter = internal</span> <span>global</span> <span>i64 </span><span>0</span><span>,</span><span> align </span><span>8</span></pre></div>
<p dir="auto">These names demangle to the following, by the way:</p>
<div dir="auto" data-snippet-clipboard-copy-content="@test_target2()::counter = internal unnamed_addr global i32* null, align 8, !dbg !0
@guard variable for test_target2()::counter = internal global i64 0, align 8"><pre><span>@test_target2()::counter = internal unnamed_addr</span> <span>global</span> <span>i32</span><span>*</span><span> null</span><span>,</span><span> align </span><span>8</span><span>,</span><span> !dbg !</span><span>0</span>
<span>@guard variable for test_target2()::counter = internal</span> <span>global</span> <span>i64 </span><span>0</span><span>,</span><span> align </span><span>8</span></pre></div>
<p dir="auto">When recompiling this module DRTI converts these variables from
&#34;internal&#34; linkage to &#34;external&#34; and resolves them against the global
variables array, as mentioned above in the section on &#34;Symbol
resolution&#34;. This ensures that there is still only one copy of the
static data in the program, and therefore prevents the initialisation
function being called again the first time the recompiled version of
the function runs. One further optimization that is not implemented,
but could be in theory, is to elide the initalisation code entirely
from the recompiled version of the function.</p>
<h3 dir="auto"><a id="user-content-virtual-function-calls" aria-hidden="true" href="#virtual-function-calls"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Virtual function calls</h3>
<p dir="auto">Virtual functions calls are more difficult to inline than normal
function pointer calls, since overridden functions require an implicit
type conversion and, in some cases, a pointer adjustment on the
implicit &#34;this&#34; argument. To see the issue, consider the following classes:</p>
<div dir="auto" data-snippet-clipboard-copy-content="struct Base { virtual void foo() = 0; };
struct Derived : Base { void foo() override; };
void bar(Base* b)
{
    b-&gt;foo();
}"><pre><span>struct</span> <span>Base</span> { <span>virtual</span> <span>void</span> <span>foo</span>() = 0; };
<span>struct</span> <span>Derived</span> : Base { <span>void</span> <span>foo</span>() <span>override</span>; };
<span>void</span> <span>bar</span>(Base* b)
{
    b-&gt;<span>foo</span>();
}</pre></div>
<p dir="auto">The call to b-&gt;foo() looks like this in LLVM bitcode, where it&#39;s
important to note that it is calling a function of type
void(%struct.Base*):</p>
<div dir="auto" data-snippet-clipboard-copy-content="  %vtable = load void (%struct.Base*)**, void (%struct.Base*)*** %0, align 8, !tbaa !1600
  %1 = load void (%struct.Base*)*, void (%struct.Base*)** %vtable, align 8
  tail call void %1(%struct.Base* %b)
                    ^^^^^^^^^^^^^"><pre><span>  %vtable = load void (%struct.Base</span><span>*</span><span>)</span><span>**,</span><span> void (%struct.Base</span><span>*</span><span>)</span><span>***</span> <span>%0</span><span>,</span><span> align </span><span>8</span><span>,</span><span> !tbaa !</span><span>1600</span>
<span>  %</span><span>1</span><span> = load void (%struct.Base</span><span>*</span><span>)</span><span>*,</span><span> void (%struct.Base</span><span>*</span><span>)</span><span>**</span><span> %vtable</span><span>,</span><span> align </span><span>8</span>
<span>  tail </span><span>call</span><span> void %</span><span>1</span><span>(%struct.Base</span><span>*</span><span> %b)</span>
<span>                    ^^^^^^^^^^^^^</span></pre></div>
<p dir="auto">However the implementation function expects a Derived* as shown here:</p>
<div dir="auto" data-snippet-clipboard-copy-content="define void @_ZN7Derived3fooEv(%struct.Derived* nocapture %this)
                               ^^^^^^^^^^^^^^^^"><pre><span>define void @_ZN7Derived3fooEv(%struct.Derived</span><span>*</span><span> nocapture %this)</span>
<span>                               ^^^^^^^^^^^^^^^^</span></pre></div>
<p dir="auto">This is inevitable since a member function within the class Derived
must have a &#34;this&#34; pointer of the correct type. So when at runtime
DRTI attempts to recompile the function bar() with a direct call to
Derived::foo there is an argument type mismatch. There isn&#39;t enough
information in the LLVM bitcode to deduce that a type conversion is
valid, and neither is there information about whether a &#34;this&#34; pointer
fixup is required, which can arise due to multiple inheritance.</p>
<p dir="auto">In principle the necessary information could either be provided
automatically by the C++ front-end, or derived from inspection of the
instructions within any virtual call thunk. As an aside, this kind of
instruction inspection is probably necessary to detect tail-calls and
procedure-linkage table calls as well. In any case, neither of these
automatic mechanisms is implemented in the proof of concept and the
developer has to provide pointer conversion function(s) explicitly
using a DRTI macro called DRTI_CONVERTIBLE, for example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="DRTI_CONVERTIBLE(Base*, Derived*);"><pre><span>DRTI_CONVERTIBLE</span>(Base*, Derived*);</pre></div>
<p dir="auto">This results in a conversion function that DRTI will attempt to find
if needed during runtime compilation:</p>
<div dir="auto" data-snippet-clipboard-copy-content="__attribute__((used, always_inline))
static inline Derived* __drti_converter(Base* value, Derived*)
{
    return static_cast&lt;Derived*&gt;(value);
};"><pre><span>__attribute__</span>((used, always_inline))
static inline Derived* __drti_converter(Base* value, Derived*)
{
    <span>return</span> <span>static_cast</span>&lt;Derived*&gt;(value);
};</pre></div>
<p dir="auto">As mentioned this is just a workaround; in a more fully developed
solution there would be automatic support for virtual function call
type conversion and this pointer fixups.</p>
<h2 dir="auto"><a id="user-content-the-llvm-source-code-patch" aria-hidden="true" href="#the-llvm-source-code-patch"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>The LLVM source code patch</h2>
<p dir="auto">DRTI needs to manipulate LLVM machine instructions to enable the
passing of call tree information between functions. Although LLVM
provides various mechanisms for external code to add custom passes
over the machine-independent Intermediate Representation (IR) I
couldn&#39;t find anything equivalent for the target-specific &#34;machine&#34;
passes. In general for code to have access to the MachineFunction and
MachineInstr objects it has to be built in to the LLVM target from
within the LLVM source tree. There is some support for replacing the
register allocator via the RegisterRegAlloc class as described in
<a href="https://www.llvm.org/docs/WritingAnLLVMPass.html" rel="nofollow">WritingAnLLVMPass</a>
but DRTI isn&#39;t a register allocator.</p>
<p dir="auto">For this reason, the llvm-drti.patch file in the drti root directory
contains minor changes to TargetPassConfig.h and .cpp to support
custom machine passes in third-party code such as DRTI.</p>
<h2 dir="auto"><a id="user-content-conclusions" aria-hidden="true" href="#conclusions"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Conclusions</h2>
<p dir="auto">DRTI demonstrates runtime re-compilation of the output from LLVM-based
ahead-of-time compilers. By doing this it can inline function calls
whose targets are not known until runtime. This is something that JIT
compilers do as a matter of course but which, in general,
ahead-of-time compilers cannot. It is currently a proof of concept.</p>
<p dir="auto">Please contact the author via <a href="mailto:62238636+drti@users.noreply.github.com">62238636+drti@users.noreply.github.com</a>
with any comments or questions.</p>
</article></div>
  </body>
</html>
