<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.codingconfessions.com/p/are-function-calls-still-slow-in-python">Original</a>
    <h1>Recent Performance Improvements in Function Calls in CPython</h1>
    
    <div id="readability-page-1" class="page"><div><div dir="auto"><p><span>I came across this </span><a href="https://x.com/pmukherjee02/status/1816242069087596811" rel="">viral post</a><span> on X/Twitter where Pritam found that his Leetcode solution was slower when he was using Python’s </span><code>min</code><span> built-in function and the performance improved when he implemented </span><code>min</code><span> inline in his Python code. </span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81915a52-173f-441e-b896-d332fe6ce787_594x440.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81915a52-173f-441e-b896-d332fe6ce787_594x440.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81915a52-173f-441e-b896-d332fe6ce787_594x440.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81915a52-173f-441e-b896-d332fe6ce787_594x440.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81915a52-173f-441e-b896-d332fe6ce787_594x440.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81915a52-173f-441e-b896-d332fe6ce787_594x440.png" width="594" height="440" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/81915a52-173f-441e-b896-d332fe6ce787_594x440.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:440,&#34;width&#34;:594,&#34;resizeWidth&#34;:null,&#34;bytes&#34;:131726,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:false,&#34;topImage&#34;:true,&#34;internalRedirect&#34;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81915a52-173f-441e-b896-d332fe6ce787_594x440.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81915a52-173f-441e-b896-d332fe6ce787_594x440.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81915a52-173f-441e-b896-d332fe6ce787_594x440.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F81915a52-173f-441e-b896-d332fe6ce787_594x440.png 1456w" sizes="100vw" fetchpriority="high"/></picture></div></a></figure></div><p>It’s true that function calls can be costly, they are known to be even more costly in interpreted languages such as Python. And the usual recommendation has been to inline your functions if they are part of the bottleneck.</p><p>The OP in this screenshot was using Python 2 which is an ancient history at this point of time. But Python 3 has been through multiple releases in the last decade and the last few releases have been very focused on improving the performance of the language. So is it still true that function calls are expensive in Python?</p><p>I was curious so I created 3 microbenchmarks to measure three things:</p><ul><li><p>What is the impact of calling a built-in in a loop</p></li><li><p>What is the impact of calling a Python function in a loop</p></li><li><p>And what is the impact of inlining that function in the loop</p></li></ul><p>Unsurprisingly, the results show that the performance of CPython has improved significantly in all the three areas with the recent releases. </p><p>In this post I am going to discuss the specific improvements introduced in CPython which help improve the performance of the interpreter. I am going to explain why things were slow previously and how the new change helps with that. Let’s dive in.</p><p>We will go over the three benchmarks one by one. For each benchmark we will look at the code, see the performance numbers across CPython releases and then discuss the specific optimization introduced in CPython which have led to the improvement across the releases.</p><p>Let’s start with the first benchmark where we are doing some simple computation inside a loop, such as computing a min from a list. The code is shown below. It uses a while loop instead of a more Pythonic for loop because the original code in the Twitter post was using a while loop and I wanted to stick to that.</p><pre><code>def benchmark1(heights):
    a = 1
    b = len(heights) - 1
    min_height = heights[0]
    while a &lt; b:
        if heights[a] &lt; min_height:
            min_height = heights[a]
        a += 1

    return min_height
</code></pre><p>Following are the performance numbers for this benchmark for last few CPython versions:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0cb6dca-5d9b-43ed-a8f6-b436b9785b2f_485x192.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0cb6dca-5d9b-43ed-a8f6-b436b9785b2f_485x192.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0cb6dca-5d9b-43ed-a8f6-b436b9785b2f_485x192.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0cb6dca-5d9b-43ed-a8f6-b436b9785b2f_485x192.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0cb6dca-5d9b-43ed-a8f6-b436b9785b2f_485x192.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0cb6dca-5d9b-43ed-a8f6-b436b9785b2f_485x192.png" width="485" height="192" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/f0cb6dca-5d9b-43ed-a8f6-b436b9785b2f_485x192.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:192,&#34;width&#34;:485,&#34;resizeWidth&#34;:null,&#34;bytes&#34;:16604,&#34;alt&#34;:&#34;The timings for computing min of a list of values in a loop without invoking any function calls&#34;,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null}" alt="The timings for computing min of a list of values in a loop without invoking any function calls" title="The timings for computing min of a list of values in a loop without invoking any function calls" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0cb6dca-5d9b-43ed-a8f6-b436b9785b2f_485x192.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0cb6dca-5d9b-43ed-a8f6-b436b9785b2f_485x192.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0cb6dca-5d9b-43ed-a8f6-b436b9785b2f_485x192.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff0cb6dca-5d9b-43ed-a8f6-b436b9785b2f_485x192.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a><figcaption>The timings for computing min of a list of values in a loop without invoking any function calls</figcaption></figure></div><p>This benchmark is simply measuring the overhead of simple computation such as comparing two integers inside a loop. As we can see the interpreter has gotten significantly better at doing this with the recent releases. Now let’s discuss what internal optimizations are responsible for this.</p><p>One of the simple optimizations introduced in CPython was that of super instructions. These are special bytecode instructions that are generated by fusing together two consecutive instructions of specific types which tend to occur in pairs in programs. Let’s understand how it works in the context of this specific benchmark.</p><p><span>The image below shows the bytecode for the loop body of this benchmark for Python 3.14.0a0 (left) and Python 3.10 (right). In the loop the interpreter needs to repeatedly load the </span><code>heights[a]</code><span> and </span><code>min_height</code><span> values onto the stack before it can compare them. For loading these values onto the stack the interpreter executes the </span><code>LOAD_FAST</code><span> instruction.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ed0e078-0e16-497c-ac91-339ebc81de39_1347x703.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ed0e078-0e16-497c-ac91-339ebc81de39_1347x703.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ed0e078-0e16-497c-ac91-339ebc81de39_1347x703.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ed0e078-0e16-497c-ac91-339ebc81de39_1347x703.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ed0e078-0e16-497c-ac91-339ebc81de39_1347x703.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_2400,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ed0e078-0e16-497c-ac91-339ebc81de39_1347x703.png" width="1200" height="626.2806236080178" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/4ed0e078-0e16-497c-ac91-339ebc81de39_1347x703.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:false,&#34;imageSize&#34;:&#34;large&#34;,&#34;height&#34;:703,&#34;width&#34;:1347,&#34;resizeWidth&#34;:1200,&#34;bytes&#34;:null,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:null,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ed0e078-0e16-497c-ac91-339ebc81de39_1347x703.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ed0e078-0e16-497c-ac91-339ebc81de39_1347x703.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ed0e078-0e16-497c-ac91-339ebc81de39_1347x703.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F4ed0e078-0e16-497c-ac91-339ebc81de39_1347x703.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a></figure></div><p><span>We can see a clear difference between the bytecode for the two Python versions. The 3.10 version contains two consecutive </span><code>LOAD_FAST</code><span> instructions, while the 3.14 version contains a single </span><code>LOAD_FAST_LOAD_FAST</code><span> instruction. </span></p><p>This is an example of a super instruction. It is generated by the compiler during an optimization pass after it generates the initial bytecode for the program. The following figure shows the code for this optimization in CPython, it was introduced during the 3.13 release.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50e7475a-338f-4024-8448-7f66930b9149_1076x538.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50e7475a-338f-4024-8448-7f66930b9149_1076x538.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50e7475a-338f-4024-8448-7f66930b9149_1076x538.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50e7475a-338f-4024-8448-7f66930b9149_1076x538.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50e7475a-338f-4024-8448-7f66930b9149_1076x538.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50e7475a-338f-4024-8448-7f66930b9149_1076x538.png" width="728" height="364" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/50e7475a-338f-4024-8448-7f66930b9149_1076x538.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:false,&#34;imageSize&#34;:&#34;normal&#34;,&#34;height&#34;:538,&#34;width&#34;:1076,&#34;resizeWidth&#34;:728,&#34;bytes&#34;:null,&#34;alt&#34;:&#34;The implementation of the superinstruction optimization inside the CPython compiler. File: flowgraph.c&#34;,&#34;title&#34;:null,&#34;type&#34;:null,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null}" alt="The implementation of the superinstruction optimization inside the CPython compiler. File: flowgraph.c" title="The implementation of the superinstruction optimization inside the CPython compiler. File: flowgraph.c" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50e7475a-338f-4024-8448-7f66930b9149_1076x538.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50e7475a-338f-4024-8448-7f66930b9149_1076x538.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50e7475a-338f-4024-8448-7f66930b9149_1076x538.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F50e7475a-338f-4024-8448-7f66930b9149_1076x538.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a><figcaption>The implementation of the superinstruction optimization inside the CPython compiler. File: flowgraph.c</figcaption></figure></div><p>The main benefit of this optimization is that it reduces the amount of work done by the interpreter. Interpreting every instruction requires fetching the next opcode, decoding it, and then jumping to the code where the implementation of that bytecode is present. This is a small amount of overhead but inside a hot loop everything magnifies.</p><p>Additionally, this also helps the CPU execute the interpreter loop efficiently. Having fewer bytecode instructions in the interpreter means fewer jumps for the CPU as well. Having fewer jumps in a tight loop results in improved instruction cache locality, and better usage of the branch predictor because the freed up branch table entries could be used for other branches. </p><p><span>Moreover, the implementation of the </span><code>LOAD_FAST_LOAD_FAST</code><span> instruction in the interpreter provides the CPU with an opportunity to increase its instruction throughput. Modern CPUs can process multiple instructions in parallel, a capability known as instruction-level parallelism, provided there are enough independent instructions available. In the case of </span><code>LOAD_FAST_LOAD_FAST</code><span>, its implementation contains several instructions that are independent of each other, allowing them to be executed concurrently.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d76065-d018-4351-9311-22a48ca2ab08_1140x440.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d76065-d018-4351-9311-22a48ca2ab08_1140x440.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d76065-d018-4351-9311-22a48ca2ab08_1140x440.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d76065-d018-4351-9311-22a48ca2ab08_1140x440.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d76065-d018-4351-9311-22a48ca2ab08_1140x440.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_2400,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d76065-d018-4351-9311-22a48ca2ab08_1140x440.png" width="1200" height="463.1578947368421" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/52d76065-d018-4351-9311-22a48ca2ab08_1140x440.png&#34;,&#34;srcNoWatermark&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/8e703af9-aeb3-49a5-9955-e84b834bead4_1140x440.png&#34;,&#34;fullscreen&#34;:false,&#34;imageSize&#34;:&#34;large&#34;,&#34;height&#34;:440,&#34;width&#34;:1140,&#34;resizeWidth&#34;:1200,&#34;bytes&#34;:91416,&#34;alt&#34;:&#34;The implementation of the LOAD_FAST_LOAD_FAST instruction in the CPython bytecode interpreter. The simultaneous loading of two values onto the stack provides the CPU to perform those instructions in parallel due to instruction level parallelism&#34;,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null}" alt="The implementation of the LOAD_FAST_LOAD_FAST instruction in the CPython bytecode interpreter. The simultaneous loading of two values onto the stack provides the CPU to perform those instructions in parallel due to instruction level parallelism" title="The implementation of the LOAD_FAST_LOAD_FAST instruction in the CPython bytecode interpreter. The simultaneous loading of two values onto the stack provides the CPU to perform those instructions in parallel due to instruction level parallelism" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d76065-d018-4351-9311-22a48ca2ab08_1140x440.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d76065-d018-4351-9311-22a48ca2ab08_1140x440.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d76065-d018-4351-9311-22a48ca2ab08_1140x440.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F52d76065-d018-4351-9311-22a48ca2ab08_1140x440.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a><figcaption>The implementation of the LOAD_FAST_LOAD_FAST instruction in the CPython bytecode interpreter. The simultaneous loading of two values onto the stack provides the CPU to perform those instructions in parallel due to instruction level parallelism</figcaption></figure></div><p><span>The 2nd optimization which is massively helping the performance for this benchmark is </span><a href="https://peps.python.org/pep-0659/" rel="">instruction specialization</a><span> introduced in CPython 3.12 release. </span></p><p><span>If you look at the bytecode from the previous section again, you should notice that the interpreter needs to repeatedly execute the </span><code>COMPARE_OP</code><span> and </span><code>BINARY_OP</code><span> for doing comparison and increment operations inside the loop. </span></p><p><span>These instructions are relatively expensive to execute because they involve dynamic dispatch. I’ve discussed what exactly goes on behind the scenes here in my article “</span><a href="https://blog.codingconfessions.com/p/cpython-dynamic-dispatch-internals" rel="">How Many Lines of C it Takes to Execute a + b in Python?</a><span>“. But let me give the summary. </span></p><p><span>When the interpreter needs to handle instructions such as </span><code>BINARY_OP</code><span> or </span><code>COMPARE_OP</code><span>, it receives the operands on the stack. The interpreter is unaware of the concrete types of these operand objects, whether they are ints, strings, floats or something else, and as a result it does not know how to handle this specific operation for the operands at hand. The interpreter figures out how to handle the operation by doing a function pointer lookup inside the operand objects. But it involves a massive amount of pointer chasing.</span></p><ul><li><p>The interpreter first needs to dereference the operand object</p></li><li><p>Next, it needs to dereference the pointer to the PyTypeObject field (ob_type) which contains the function pointer tables</p></li><li><p>Then the interpreter needs to dereference the function pointer table and lookup the function pointer</p></li><li><p>Finally, it needs to dereference the function pointer itself to call the function.</p></li></ul><p>The following figure illustrates this pointer chasing.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff77293c6-c6ac-4b12-b5d6-247d114f846d_1556x764.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff77293c6-c6ac-4b12-b5d6-247d114f846d_1556x764.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff77293c6-c6ac-4b12-b5d6-247d114f846d_1556x764.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff77293c6-c6ac-4b12-b5d6-247d114f846d_1556x764.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff77293c6-c6ac-4b12-b5d6-247d114f846d_1556x764.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_2400,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff77293c6-c6ac-4b12-b5d6-247d114f846d_1556x764.png" width="1200" height="589.2857142857143" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/f77293c6-c6ac-4b12-b5d6-247d114f846d_1556x764.png&#34;,&#34;srcNoWatermark&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/528d2397-6915-48e6-845e-7ab1e306cca3_1556x764.png&#34;,&#34;fullscreen&#34;:false,&#34;imageSize&#34;:&#34;large&#34;,&#34;height&#34;:715,&#34;width&#34;:1456,&#34;resizeWidth&#34;:1200,&#34;bytes&#34;:149619,&#34;alt&#34;:&#34;The amount of indirection involved when the bytecode interpreter needs to handle a binary op or a comparison op&#34;,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null}" alt="The amount of indirection involved when the bytecode interpreter needs to handle a binary op or a comparison op" title="The amount of indirection involved when the bytecode interpreter needs to handle a binary op or a comparison op" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff77293c6-c6ac-4b12-b5d6-247d114f846d_1556x764.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff77293c6-c6ac-4b12-b5d6-247d114f846d_1556x764.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff77293c6-c6ac-4b12-b5d6-247d114f846d_1556x764.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff77293c6-c6ac-4b12-b5d6-247d114f846d_1556x764.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a><figcaption>The amount of indirection involved when the bytecode interpreter needs to handle a binary op or a comparison op</figcaption></figure></div><p>This level of indirection is bad at the CPU level because all of these pointer dereferences are dependent memory loads. It means that the CPU needs to wait for the first load to finish before it can proceed with the next. It reduces the instruction throughput, and if any of those loads have a cache miss, it can cause a long stall of hundreds of cycles until the data arrives from the main memory.</p><p><span>But thanks to instruction specialization, the slow </span><code>BINARY_OP</code><span> and </span><code>COMPARE_OP</code><span> instructions are converted to specialized instructions such as </span><code>BINARY_ADD_INT</code><span> where the add operation is done directly in the interpreter without doing any pointer lookups. </span></p><p><span>This is a slight variation of the previous benchmark. Here instead of doing the min computation ourselves, we are calling the built-in </span><code>min</code><span> function. The code for this benchmark is below:</span></p><pre><code>def benchmark2(heights):
    a = 1
    b = len(heights) - 1
    min_height = heights[0]
    while a &lt; b:
        min_height = min(heights[a], min_height)
        a += 1

    return min_height
</code></pre><p>This benchmark is measuring the overhead involved in calling a built-in function. The following table shows the improvement in CPython’s performance for this across releases.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fddcffe67-219d-4ef4-8e44-a3efae3dbdc5_581x189.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fddcffe67-219d-4ef4-8e44-a3efae3dbdc5_581x189.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fddcffe67-219d-4ef4-8e44-a3efae3dbdc5_581x189.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fddcffe67-219d-4ef4-8e44-a3efae3dbdc5_581x189.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fddcffe67-219d-4ef4-8e44-a3efae3dbdc5_581x189.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fddcffe67-219d-4ef4-8e44-a3efae3dbdc5_581x189.png" width="581" height="189" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/ddcffe67-219d-4ef4-8e44-a3efae3dbdc5_581x189.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:189,&#34;width&#34;:581,&#34;resizeWidth&#34;:null,&#34;bytes&#34;:17839,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fddcffe67-219d-4ef4-8e44-a3efae3dbdc5_581x189.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fddcffe67-219d-4ef4-8e44-a3efae3dbdc5_581x189.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fddcffe67-219d-4ef4-8e44-a3efae3dbdc5_581x189.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fddcffe67-219d-4ef4-8e44-a3efae3dbdc5_581x189.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a></figure></div><p>There have been two changes which can be attributed to the improvement of this version from 17.33 seconds in Python 3.10 to 6.7 seconds in Python 3.14.0a0. Let’s discuss those.</p><p>Let’s take a look at the bytecode for the code of this benchmark.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc3033048-9738-4242-9072-a55e02d1225a_953x540.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc3033048-9738-4242-9072-a55e02d1225a_953x540.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc3033048-9738-4242-9072-a55e02d1225a_953x540.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc3033048-9738-4242-9072-a55e02d1225a_953x540.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc3033048-9738-4242-9072-a55e02d1225a_953x540.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc3033048-9738-4242-9072-a55e02d1225a_953x540.png" width="953" height="540" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/c3033048-9738-4242-9072-a55e02d1225a_953x540.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:540,&#34;width&#34;:953,&#34;resizeWidth&#34;:null,&#34;bytes&#34;:94620,&#34;alt&#34;:&#34;Bytecode for the version2 of the benchmark for CPython 3.14.0a0&#34;,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null}" alt="Bytecode for the version2 of the benchmark for CPython 3.14.0a0" title="Bytecode for the version2 of the benchmark for CPython 3.14.0a0" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc3033048-9738-4242-9072-a55e02d1225a_953x540.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc3033048-9738-4242-9072-a55e02d1225a_953x540.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc3033048-9738-4242-9072-a55e02d1225a_953x540.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc3033048-9738-4242-9072-a55e02d1225a_953x540.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a><figcaption>Bytecode for the version2 of the benchmark for CPython 3.14.0a0</figcaption></figure></div><p><span>When executing this, the interpreter needs to load the </span><code>min()</code><span> built-in function onto the stack. For doing that it executes the </span><code>LOAD_GLOBAL</code><span> instruction.</span></p><p><span>The </span><code>LOAD_GLOBAL</code><span> instruction needs to lookup the named global object in two dictionaries. The first dictionary contains all the globals in the current scope, and the second contains all the builtins.</span></p><p><span>Dictionary lookups are fast but they are not free. Again, thanks to instruction specialization the interpreter optimizes this into a specialized instruction: </span><code>LOAD_GLOBAL_BUILTIN</code><span>.</span></p><p>The specialized instruction caches the index of the object in the builtins dictionary. It avoids the entire dictionary lookup process and simply returns the object at the cached index value. The following figure shows how the interpreter implements this instruction.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F28c22888-7d4d-42b1-b405-2036a4e876c2_1588x373.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F28c22888-7d4d-42b1-b405-2036a4e876c2_1588x373.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F28c22888-7d4d-42b1-b405-2036a4e876c2_1588x373.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F28c22888-7d4d-42b1-b405-2036a4e876c2_1588x373.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F28c22888-7d4d-42b1-b405-2036a4e876c2_1588x373.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_2400,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F28c22888-7d4d-42b1-b405-2036a4e876c2_1588x373.png" width="1200" height="281.86813186813185" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/28c22888-7d4d-42b1-b405-2036a4e876c2_1588x373.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:false,&#34;imageSize&#34;:&#34;large&#34;,&#34;height&#34;:342,&#34;width&#34;:1456,&#34;resizeWidth&#34;:1200,&#34;bytes&#34;:91702,&#34;alt&#34;:&#34;The implementation of the LOAD_GLOBAL_BUILTIN instruction in the CPython bytecode interpreter&#34;,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null}" alt="The implementation of the LOAD_GLOBAL_BUILTIN instruction in the CPython bytecode interpreter" title="The implementation of the LOAD_GLOBAL_BUILTIN instruction in the CPython bytecode interpreter" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F28c22888-7d4d-42b1-b405-2036a4e876c2_1588x373.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F28c22888-7d4d-42b1-b405-2036a4e876c2_1588x373.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F28c22888-7d4d-42b1-b405-2036a4e876c2_1588x373.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F28c22888-7d4d-42b1-b405-2036a4e876c2_1588x373.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a><figcaption>The implementation of the LOAD_GLOBAL_BUILTIN instruction in the CPython bytecode interpreter</figcaption></figure></div><p><span>But the specialization of </span><code>LOAD_GLOBAL</code><span> into </span><code>LOAD_GLOBAL_BUILTIN</code><span> is not the main contributor to the impressive improvement of this benchmark. The real reason is a specific optimization applied to the </span><code>min</code><span> and </span><code>max</code><span> builtins. </span></p><p><span>There are two calling conventions inside the interpreter for calling functions, one is the old convention called </span><code>tp_call</code><span> and the other is </span><code>vectorcall</code><span>. </span></p><p><span>When using </span><code>tp_call</code><span>, intermediate tuples and dictionaries are created for passing the function arguments and there might be overhead of other intermediate objects as well (more details described in the </span><a href="https://peps.python.org/pep-0590/" rel="">PEP 0590</a><span>). In the </span><code>vectorcall</code><span> convention, the arguments are passed as part of a vector which eliminates a lot of the intermediate object creation.</span></p><p><span>Before the CPython 3.13 release, the </span><code>min</code><span> and </span><code>max</code><span> builtins were being called using the </span><code>tp_call</code><span> convention. This meant that calling these inside a hot loop would allocate and deallocate a ton of intermediate objects. By switching to the </span><code>vectorcall</code><span> convention the performance of these builtins has been reported to improve by upto 200%, and even in this benchmark it shows an improvement of more than 150%.</span></p><p><span>You can read the PR of this change </span><a href="https://github.com/python/cpython/issues/90350" rel="">here</a><span> for more context.</span></p><p>Finally, let’s discuss what changes are behind the performance improvements of the 3rd benchmark which implements min as a Python function and calls it from inside the loop. The code is shown below.</p><pre><code>def pymin(a, b):
    if a &lt;= b:
        return a
    return b
	

def benchmark3(heights):
    a = 1
    b = len(heights) - 1
    min_height = heights[0]
    while a &lt; b:
        min_height = pymin(heights[a], min_height)
        a += 1

    return min_height
</code></pre><p>The following table shows the performance of different CPython releases for this benchmark:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcbbadcb0-368e-405b-a862-2e5221b87c3c_577x188.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcbbadcb0-368e-405b-a862-2e5221b87c3c_577x188.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcbbadcb0-368e-405b-a862-2e5221b87c3c_577x188.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcbbadcb0-368e-405b-a862-2e5221b87c3c_577x188.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcbbadcb0-368e-405b-a862-2e5221b87c3c_577x188.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcbbadcb0-368e-405b-a862-2e5221b87c3c_577x188.png" width="577" height="188" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/cbbadcb0-368e-405b-a862-2e5221b87c3c_577x188.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:188,&#34;width&#34;:577,&#34;resizeWidth&#34;:null,&#34;bytes&#34;:18356,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcbbadcb0-368e-405b-a862-2e5221b87c3c_577x188.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcbbadcb0-368e-405b-a862-2e5221b87c3c_577x188.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcbbadcb0-368e-405b-a862-2e5221b87c3c_577x188.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fcbbadcb0-368e-405b-a862-2e5221b87c3c_577x188.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a></figure></div><p>As per the numbers in the table for this benchmark version, the performance improved significantly from 3.10 to 3.12 and then marginally for 3.14.0a0. </p><p>This benchmark is essentially measuring the overhead involved in executing a python to python function call (because both the caller and callee are implemented in Python).</p><p>Until Python 3.11 the way Python to Python function calls were handled in the interpreter was convoluted and expensive, it involved the interpreter invoking itself recursively for handling each such function call. This recursion got inlined in CPython 3.11 release, leading to significant performance improvements. Let’s understand it in detail.</p><p><span>The interpreter starts the execution of a Python program from the program’s main function. This is done by first setting up the stackframe for the main function and then invoking the interpreter. The entry point of the interpreter is the function </span><code>_PyEval_EvalFrameDefault</code><span> defined in </span><a href="https://github.com/python/cpython/blob/3.13/Python/ceval.c#L676" rel="">ceval.c</a><span>. </span></p><blockquote><p><em><strong>What is a stackframe?</strong><span> Execution of every function in your code requires a corresponding stackframe. The stackframe contains the locals and globals of that function, the compiled bytecode, instruction pointer etc which help the interpreter execute the code. For more details you can watch the recording of my talk on </span><a href="https://blog.codingconfessions.com/p/recording-of-live-session-on-cpython" rel="">CPython Virtual Machine Internals</a><span> which covers how the virtual machine is implemented in CPython.</span></em></p></blockquote><p><span>The </span><code>_PyEval_EvalFrameDefault</code><span> function contains a giant switch case for handling all the bytecode instructions supported by the interpreter. The function iterates through the instructions of the given function and executes the corresponding switch case.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feaacabce-9244-44ed-930c-b09b2e48323c_1212x724.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feaacabce-9244-44ed-930c-b09b2e48323c_1212x724.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feaacabce-9244-44ed-930c-b09b2e48323c_1212x724.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feaacabce-9244-44ed-930c-b09b2e48323c_1212x724.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feaacabce-9244-44ed-930c-b09b2e48323c_1212x724.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feaacabce-9244-44ed-930c-b09b2e48323c_1212x724.png" width="1212" height="724" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/eaacabce-9244-44ed-930c-b09b2e48323c_1212x724.png&#34;,&#34;srcNoWatermark&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/fa76651b-3730-4a24-acf6-0d80804859f8_1212x724.png&#34;,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:724,&#34;width&#34;:1212,&#34;resizeWidth&#34;:null,&#34;bytes&#34;:null,&#34;alt&#34;:&#34;An example of the bytecode evaluation loop of a toy VM implemented in Python. The interpreter loops through each bytecode instruction and based on the opcode handles it. The CPython VM is implemented in C, this is just to give an idea.&#34;,&#34;title&#34;:null,&#34;type&#34;:null,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null}" alt="An example of the bytecode evaluation loop of a toy VM implemented in Python. The interpreter loops through each bytecode instruction and based on the opcode handles it. The CPython VM is implemented in C, this is just to give an idea." title="An example of the bytecode evaluation loop of a toy VM implemented in Python. The interpreter loops through each bytecode instruction and based on the opcode handles it. The CPython VM is implemented in C, this is just to give an idea." srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feaacabce-9244-44ed-930c-b09b2e48323c_1212x724.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feaacabce-9244-44ed-930c-b09b2e48323c_1212x724.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feaacabce-9244-44ed-930c-b09b2e48323c_1212x724.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Feaacabce-9244-44ed-930c-b09b2e48323c_1212x724.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a><figcaption>An example of the bytecode evaluation loop of a toy VM implemented in Python. The interpreter loops through each bytecode instruction and based on the opcode handles it. The CPython VM is implemented in C, this is just to give an idea.</figcaption></figure></div><p><span>When you call another function in your Python code, it results in the </span><code>CALL</code><span> bytecode instruction being generated. When the interpreter encounters a </span><code>CALL</code><span> instruction, things get interesting. </span></p><p><span>In CPython 3.10 and earlier, the </span><code>CALL</code><span> instruction used to create a new interpreter stackframe for the function being called and then it used to recursively reenter the interpreter by calling its entry point </span><code>_PyEval_EvalFrameDefault</code><span>.</span></p><p>This was bad for performance from many angles at the hardware level. The recursive call into the interpreter required saving the registers for the current function, and pushing a new C stackframe. It would lead to increased memory usage because each recursive interpreter call would allocate its own local variables on the stack, and other heap allocations. Apart from that it would also lead to poor instruction cache locality due to the constant jumps in and out of the bytecode evaluation loop.</p><p><span>In the 3.11 release this was fixed by eliminating the recursive call to the interpreter. Now the </span><code>CALL</code><span> instruction simply creates the stackframe for the called function, after that it immediately starts evaluating the new function’s bytecode without ever leaving the loop. </span></p><blockquote><h6><em>Note: Your code may be calling a function which is implemented in C, or it could be calling a function written in Python. The above discussion is about a Python function call. In the case of a C function call the interpreter never needed to do all the gymnastics discussed above.</em></h6></blockquote><p><span>You can read the discussion behind this change in the </span><a href="https://bugs.python.org/issue45256" rel="">CPython bug tracker</a><span>.</span></p><p><span>While most of the improvement seen in the performance of this benchmark is due to the inlining described above, there is another minor improvement related to function call execution in the interpreter. It is the specialization of the </span><code>CALL</code><span> instruction.</span></p><p><span>The </span><code>CALL</code><span> instruction is a generic instruction for executing all kinds of callables. When handling it, the interpreter needs to check the type of the callable, such as whether it is a class method, instance method, a function or something else, and based on that it needs to invoke the callable in the right manner. </span></p><p>The specialization of this instruction saves all of this extra work for the interpreter and inside a tight loop it might help improve the performance.</p><p>In this article, we’ve dug into the nitty-gritty of Python performance, specifically looking at the cost of function calls, built-in calls and inlining code in a hot loop. We saw how recent tweaks in CPython have made things faster. Our benchmarks showed some solid performance boosts from Python 3.10 to Python 3.14.0a0. Here’s a quick rundown of what’s behind those gains:</p><ul><li><p><strong>Super Instructions</strong><span>: By merging back-to-back bytecode instructions into single “super” instructions like </span><code>LOAD_FAST_LOAD_FAST</code><span>, CPython cuts down on the overhead of running individual bytecode instructions. This boost helps both the interpreter and the CPU run more efficiently.</span></p></li><li><p><strong>Bytecode Instruction Specialization</strong><span>: New specialized bytecode instructions (like </span><code>BINARY_ADD_INT</code><span>) remove the need for slow, dynamic dispatch, speeding up everyday operations.</span></p></li><li><p><strong>Optimization of Builtins</strong><span>: Switching from the older </span><code>tp_call</code><span> method to the faster </span><code>vectorcall</code><span> has given a big performance push to the </span><code>min</code><span> and </span><code>max</code><span> builtins.</span></p></li><li><p><strong>Inlining Python-to-Python Function Calls</strong><span>: By getting rid of the old way of handling Python-to-Python function calls (which involved cumbersome recursive interpreter calls), newer versions like CPython 3.11 make these function calls faster and smoother.</span></p></li></ul><p><span>Overall, these changes show Python’s ongoing effort to get faster and more efficient. But before taking any of the findings from these articles and applying to your code, remember to first profile and measure to find the slowest paths (</span><a href="https://en.wikipedia.org/wiki/Amdahl%27s_law" rel="">Amdahl&#39;s law</a><span>).</span></p><ul><li><p><a href="https://bugs.python.org/issue45256" rel="">Inlining the handling of Python-to-Python function calls in the interpreter</a></p></li><li><p><a href="https://github.com/python/cpython/issues/90350" rel="">Optimization of min and max in CPython</a></p></li><li><p><a href="http://PEP 659 – Specializing Adaptive Interpreter" rel="">PEP 659 – Specializing Adaptive Interpreter</a></p></li><li><p><a href="https://blog.codingconfessions.com/p/recording-of-live-session-on-cpython" rel="">CPython Virtual Machine Internals</a></p></li><li><p><a href="https://blog.codingconfessions.com/p/cpython-dynamic-dispatch-internals" rel="">Dynamic dispatch internals of CPython</a></p></li></ul><p>If you find my work interesting and valuable, you can support me by opting for a paid subscription (it’s $6 monthly/$60 annual). As a bonus you get access to monthly live sessions, and all the past recordings. </p><p><span>Many people report failed payments, or don’t want a recurring subscription. For that I also have a </span><a href="https://buymeacoffee.com/codeconfessions" rel="">buymeacoffee page</a><span>. Where you can buy me coffees or become a member. I will upgrade you to a paid subscription for the equivalent duration here.</span></p><p data-attrs="{&#34;url&#34;:&#34;https://buymeacoffee.com/codeconfessions&#34;,&#34;text&#34;:&#34;Buy me a coffee&#34;,&#34;action&#34;:null,&#34;class&#34;:&#34;button-wrapper&#34;}" data-component-name="ButtonCreateButton"><a href="https://buymeacoffee.com/codeconfessions" rel=""><span>Buy me a coffee</span></a></p><p>I also have a GitHub Sponsor page. You will get a sponsorship badge, and also a complementary paid subscription here.</p><p data-attrs="{&#34;url&#34;:&#34;https://github.com/sponsors/abhinav-upadhyay&#34;,&#34;text&#34;:&#34;Sponsor me on GitHub&#34;,&#34;action&#34;:null,&#34;class&#34;:&#34;button-wrapper&#34;}" data-component-name="ButtonCreateButton"><a href="https://github.com/sponsors/abhinav-upadhyay" rel=""><span>Sponsor me on GitHub</span></a></p><p data-attrs="{&#34;url&#34;:&#34;https://blog.codingconfessions.com/p/are-function-calls-still-slow-in-python?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&#34;,&#34;text&#34;:&#34;Share&#34;,&#34;action&#34;:null,&#34;class&#34;:null}" data-component-name="ButtonCreateButton"><a href="https://blog.codingconfessions.com/p/are-function-calls-still-slow-in-python?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p></div></div></div>
  </body>
</html>
