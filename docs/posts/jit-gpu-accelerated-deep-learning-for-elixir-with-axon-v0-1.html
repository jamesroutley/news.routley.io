<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://seanmoriarity.com/2022/06/16/jit-gpu-accelerated-deep-learning-for-elixir-with-axon-v0-1/">Original</a>
    <h1>JIT/GPU accelerated deep learning for Elixir with Axon v0.1</h1>
    
    <div id="readability-page-1" class="page"><div>
		
<p>I am excited to announce the official v0.1.0 release ofÂ <a href="https://github.com/elixir-nx/axon">Axon</a>Â andÂ <a href="https://github.com/elixir-nx/axon_onnx">AxonOnnx</a>. A lot has changed (and improved) since the initialÂ <a href="https://seanmoriarity.com/2021/04/08/axon-deep-learning-in-elixir/">public announcement of Axon</a>. In this post I will explore Axon and its internals, and give reasoning for some of the design decisions made along the way.</p>



<p>You can view the official documentation here:</p>



<ul><li><a href="https://hexdocs.pm/axon/Axon.html">Axon</a></li><li><a href="https://hexdocs.pm/axon_onnx/AxonOnnx.html">AxonOnnx</a></li></ul>



<h2>What is Axon?</h2>



<p>At a high-level, Axon is a library for creating and training neural networks. Axon is implemented in pure Elixir and relies onÂ <a href="https://github.com/elixir-nx/nx">Nx</a>Â to compile Neural Networks to the CPU/GPU just-in-time. It consists of a few components which are loosely tied together:</p>



<h3>Functional API</h3>



<p>The functional API are â€œlow-levelâ€ implementations of common neural network operations. Itâ€™s similar toÂ <code>torch.functional</code>Â orÂ <code>tf.nn</code>Â in the Python ecosystem. The functional API offers no conveniencesâ€”just implementations. These implementations are all written inÂ <code>defn</code>, so they can be JIT compiled, or composed with Nx transformations likeÂ <code>grad</code>Â in otherÂ <code>defn</code>Â functions.</p>



<p>The Functional API consists of:</p>



<ul><li><a href="https://hexdocs.pm/axon/Axon.Activations.html">Axon.Activations</a></li><li><a href="https://hexdocs.pm/axon/Axon.Initializers.html">Axon.Initializers</a></li><li><a href="https://hexdocs.pm/axon/Axon.Layers.html">Axon.Layers</a></li><li><a href="https://hexdocs.pm/axon/Axon.Losses.html">Axon.Losses</a></li><li><a href="https://hexdocs.pm/axon/Axon.Metrics.html">Axon.Metrics</a></li><li><a href="https://hexdocs.pm/axon/Axon.Recurrent.html">Axon.Recurrent</a></li></ul>



<h3>Model Creation API</h3>



<p>The model creation API is a high-level API for creating and executing neural networks. The API will be covered in-depth in this post, so Iâ€™ll omit the details here.</p>



<h3>Optimization API</h3>



<p>The optimization API is built to mirror the beautifulÂ <a href="https://github.com/deepmind/optax">Optax</a>Â library. Optax is literally my favorite library thatâ€™s not written in Elixir. The idea is to implement optimizers using composable higher-order functions. I highly recommend checking out theÂ <a href="https://hexdocs.pm/axon/Axon.Updates.html">Axon.Updates</a>Â documentation as well as the Optax library.</p>



<h3>Loop API</h3>



<p>The Loop API is an API for writing loops (like training and evaluation loops) in a functional style. Elixir is a functional language, which means we cannot take advantage of mutable state in the same way you would be able to in Python frameworks. To get around this,Â <code>Axon.Loop</code>Â constructs loops as reducers over data with some state. The API itself is inspired by theÂ <a href="https://pytorch.org/ignite/index.html">PyTorch Ignite</a>Â library.</p>



<p>The Loop API is still a work-in-progress, so you should expect significant improvements in subsequent Axon releases.</p>



<h2>What really is a Neural Network?</h2>



<p>There are really two interpretations of this question Iâ€™d like to explore:</p>



<ol><li>What is a neural networkÂ <em>mathematically</em>?</li><li>What is a neural network in the eyes of Axon?</li></ol>



<p>Mathematically a neural network is just a composition of linear and non-linear transformations with some learnable parameters. In Nx, you can implement a neural network relatively easily withÂ <code>defn</code>:</p>


<div><pre title="">defn feed_forward_network(x, w1, b1, w2, b2, w3, b3) do
  x
  |&gt; Nx.dot(w1)
  |&gt; Nx.add(b1)
  |&gt; Nx.sigmoid()
  |&gt; Nx.dot(w2)
  |&gt; Nx.add(b2)
  |&gt; Nx.sigmoid()
  |&gt; Nx.dot(w3)
  |&gt; Nx.add(b3)
  |&gt; Nx.sigmoid()
end
</pre></div>


<p>Thereâ€™s really nothing more to it! Of course, implementing neural networks in Nx now introduces a lot of painful boilerplate. The goal of Axon is to abstract away the boilerplate, and make creating and training neural networks a breeze in Elixir.</p>



<p>So what is a neural network in the eyes of Axon? Axon sees a neural network as an Elixir struct:</p>


<div><pre title="">  defstruct [
    :id,
    :name,
    :output_shape,
    :parent,
    :parameters,
    :args,
    :op,
    :policy,
    :hooks,
    :opts,
    :op_name
  ]
</pre></div>


<p>Of particular importance in this struct are:Â <code>parent</code>,Â <code>parameters</code>, andÂ <code>op</code>.Â <code>parent</code>Â is a list of parent networks which are also Axon structs. Itâ€™s a recursive data structure which represents a computation graph with some additional metadata relevant to specific neural network tasks.Â <code>parameters</code>Â represent a list of trainable parameters attached to this layer. Theyâ€™re automatically initialized when the model is initialized, and will be part of the training process within Axonâ€™s internal APIs.Â <code>op</code>Â is a function thatâ€™s applied onÂ <code>parent</code>Â andÂ <code>parameters</code>. In laymenâ€™s terms, Axon views a neural network as just a function of other â€œneural networksâ€ (Axon structs) and trainable parameters. In fact, you can â€œwrapâ€ any function you want into a neural network withÂ <code>Axon.layer</code>:</p>



<pre>defn dense(input, weight, bias, _opts \\ []) do
  input
  |&gt; Nx.dot(weight)
  |&gt; Nx.add(bias)
end

input = Axon.input({nil, 32}, &#34;features&#34;)
weight = Axon.param({32, 64}, &#34;weight&#34;)
bias = Axon.param({64}, &#34;bias&#34;)

Axon.layer(&amp;dense/4, [input, weight, bias])</pre>



<p>Notice I only had to define anÂ <code>input</code>Â layer and two trainable parameters using Axonâ€™s built-in function. UsingÂ <code>Axon.layer</code>Â should feel a lot like using Elixirâ€™sÂ <code>apply</code>Â â€” youâ€™re just applying a function to some specialized inputs. All but a few of Axonâ€™s built-in layers are implemented in essentially this same manner:</p>



<ol><li>Define an implementation function inÂ <a href="https://github.com/elixir-nx/axon/blob/main/lib/axon/layers.ex">Axon.Layers</a></li><li>Wrap the implementation in a layer with a public interface inÂ <a href="https://github.com/elixir-nx/axon/blob/main/lib/axon.ex">Axon</a></li></ol>



<h2>Itâ€™s just a Graph</h2>



<p>The â€œmagicâ€ of Axon is its compiler, which knows how to convert Axon structs into meaningful initialization and prediction functions. Model execution comes in the form of two functions:Â <code>Axon.init/3</code>Â andÂ <code>Axon.predict/4</code>.Â <code>Axon.init/3</code>Â returns a modelâ€™s initial parameters:</p>



<pre>model = Axon.input({nil, 32}) |&gt; Axon.dense(64)

model_state = Axon.init(model)</pre>



<p>For prediction, you need both a model and a compatible model state:</p>



<pre>model = Axon.input({nil, 32}) |&gt; Axon.dense(64)

model_state = Axon.init(model)
input = Nx.random_uniform({1, 32})

Axon.predict(model, model_state, input)</pre>



<p>BothÂ <code>Axon.init/3</code>Â andÂ <code>Axon.predict/4</code>Â take additional compilation options; however, itâ€™s recommended you use global configuration rather than compilation options. For example, rather than:</p>



<pre>Axon.predict(model, model_state, input, compiler: EXLA)</pre>



<p>You should use:</p>



<pre>EXLA.set_as_nx_default([:tpu, :cuda, :rocm, :host])

Axon.predict(model, model_state, input)</pre>



<p><code>Axon.init/3</code>Â also optionally accepts initial parameters to initialize portions of a model from an initial state (e.g. if trying to fine-tune a model). This is whereÂ <code>Axon.namespace/2</code>Â comes in handy. You can â€œtagâ€ a part of a model as belonging to a particular namespace, and initialize without needing to know anything about the underlying architecture:</p>



<pre>{bert, bert_params} = get_bert_model()
bert = bert |&gt; Axon.namespace(&#34;bert&#34;)

model = bert |&gt; Axon.dense(1)

model_state = Axon.init(model, %{&#34;bert&#34; =&gt; bert_params})</pre>



<p><code>Axon.namespace/2</code>Â is one of the few layers with special meaning in Axon. Thereâ€™s alsoÂ <code>Axon.input/2</code>,Â <code>Axon.constant/3</code>, andÂ <code>Axon.container/3</code>. Input layers are symbolic representations of model inputs. Each input is associated with a unique name used to reference it when passing names to a model. For example, if you have multiple inputs, you can give them semantic meanings:</p>



<pre>text_features = Axon.input({nil, 32}, &#34;text_features&#34;)
cat_features = Axon.input({nil, 32}, &#34;cat_features&#34;)</pre>



<p>With named inputs, you donâ€™t have to worry about passing things out of order, since youâ€™ll always reference an input by itâ€™s name:</p>



<pre>model = Axon.add(text_features, cat_features)

Axon.predict(model, model_state, %{&#34;text_features&#34; =&gt; text_inp, &#34;cat_features&#34; =&gt; cat_inp})</pre>



<p><code>Axon.constant/3</code>Â allows you to introduce constant-values into the graph. Be warned that introducing large constants will have negative impacts on the performance of the model.</p>



<p><code>Axon.container/3</code>Â can accept any validÂ <a href="https://hexdocs.pm/nx/Nx.Container.html">Nx container</a>. This is particularly useful for giving semantic meaning to outputs:</p>



<pre>model = Axon.container(%{
  last_hidden_state: last_hidden_state,
  pooler_output: pooler_output
})</pre>



<p><strong>Every other Axon built-in layer is treated in the same way as custom layers by the compiler.</strong>Â This means that (besides for the few â€œspecial layersâ€) thereâ€™s no difference between what you can do with a custom layer and what you can do with a built-in layer. Theyâ€™re both handledÂ <a href="https://github.com/elixir-nx/axon/blob/a859be766e52d89e1140060d1e52e79667bd6fa1/lib/axon/compiler.ex#L369">by the same clause in the Axon compiler</a>.</p>



<p>In the Axon interpretation of a neural network, everyÂ <em>execution</em>Â of a graph is seen as aÂ <strong>specialized compilation of the graph</strong>. In other words, initialization and prediction are just two types of compilation. Thereâ€™s nothing stopping you from implementing your own specialized compilation of an Axon graph in the same way. For example, an older version of Axon implemented a macroÂ <code>Axon.penalty</code>Â which compiled a graph into a regularization function. Axon also implements theÂ <code>Inspect</code>Â protocolâ€”which itself can be seen as a symbolic compilation of the graph.</p>



<h2>Maybe you donâ€™t like my APIâ€¦</h2>



<p>The Axon interpretation of a â€œmodelâ€ is intentionally as flexible as possible. All you need to do is build a data structure. This means that if youâ€™re not satisfied with Axonâ€™s model creation API, you can create your own! As long as you finish with an Axon struct, your model will work with the rest of Axonâ€™s components. The Axon struct is really the unifying data structure for every component of the Axon library. I would love to see some cool Neural Network DSLs pop-up which build off of the lower-level components Axon defines.</p>



<h2>Converting to Other Formats</h2>



<p>Another benefit of the Axon data structure is portability. If you can traverse the Axon graph, you can lower or compile it into a meaningful function or representation, such as ONNX. This is exactly the functionality AxonOnnx providesâ€”you can take a pre-trained model from popular frameworks like PyTorch and TensorFlow, convert them to ONNX, and then import them into Elixir withÂ <code>AxonOnnx.import</code>. For example, you can take any of the ONNX supported models inÂ <a href="https://huggingface.co/docs/transformers/serialization">HuggingFace Transformers</a>Â and import them in Axon with ease!</p>



<p>Just export the model you want:</p>


<div><pre title="">$ python -m transformers.onnx --model=bert-base-cased models/

</pre></div>


<p>And load it with AxonOnnx:</p>



<pre>{bert, bert_params} = AxonOnnx.import(&#34;path/to/bert.onnx&#34;)</pre>



<p>The ability to import and use external models is an absoluteÂ <em>must</em>Â for any Neural network library (especially given the pace of progress in deep learning). AxonOnnx enables Elixir programmers to utilize pre-trained models from the Python ecosystem without needing to implement or train them from scratch.</p>



<p>This also means you can integrate some pretty cool pre-trained models with established projects like Phoenix and LiveView. For example <a href="https://github.com/thehaigo/live_onnx">live_onnx</a>, implements a sample ML application using AxonOnnx and LiveView.</p>



<p>You should note that we are still actively working to enable support for all of ONNXâ€™s operations. If you have a model youâ€™d like to see supported, please feel free to open an issue or a PR ğŸ™‚</p>



<h2>Future Work</h2>



<p>If you look at theÂ <a href="https://github.com/elixir-nx/axon/issues">issues tracker</a>Â youâ€™ll notice thereâ€™s still much work to be done; however, the core components of Axon are at a stable point. This means you can use Axon with a reasonable expectation of stability. Moving forward, you can expect the following from Axon:</p>



<ul><li>First-class transformer model support</li><li>More integration withÂ <a href="https://livebook.dev/">Livebook</a></li><li>Mixed precision training</li><li>Multi-device training</li></ul>



<p>Additionally, Iâ€™d like to build out a large collection of Axon examples. If you are looking for a place to get started in the Nx ecosystem, please feel free to open a pull request which demonstrates Axon applied to a unique problem set. If youâ€™re looking for inspiration, check outÂ <a href="https://keras.io/examples/">Keras Examples</a>.</p>



<h2>Acknowledgements</h2>



<p>I am very grateful toÂ <a href="https://dockyard.com/">DockYard</a>Â and their support of the Elixir Machine Learning Ecosystem from the beginning. Additionally, Axon would not be where it is today without the hard work of all of the Nx contributors and the individuals Erlang Ecosystem Foundation ML WG. The Elixir community is nothing short of amazing, and I hope Axon can play a small part in seeing the community grow.</p>



<h2><a href="https://gist.github.com/josevalim/8c1fcee737f28ca188ebfb020540536c#functional-api"></a></h2>
	</div></div>
  </body>
</html>
