<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/tyiannak/pyAudioAnalysis">Original</a>
    <h1>A library for audio feature extraction, regression, classification, segmentation</h1>
    
    <div id="readability-page-1" class="page"><div data-target="readme-toc.content">
          <article itemprop="text">
<p dir="auto"><em>This is general info. Click <a href="https://github.com/tyiannak/pyAudioAnalysis/wiki">here</a> for the complete wiki and <a href="https://hackernoon.com/audio-handling-basics-how-to-process-audio-files-using-python-cli-jo283u3y" rel="nofollow">here</a> for a more generic intro to audio data handling</em></p>
<h2 dir="auto"><a id="user-content-news" aria-hidden="true" href="#news"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>News</h2>
<ul dir="auto">
<li>[2021-08-30] New article: <a href="https://www.mdpi.com/2076-3417/11/17/7962" rel="nofollow">Deep Multimodal Emotion Recognition on Human Speech: A Review</a></li>
<li>[2021-08-06] <a href="https://github.com/tyiannak/deep_audio_features">deep-audio-features</a> deep audio classification and feature extraction using CNNs and Pytorch</li>
<li>[2020-09-12] <a href="https://medium.com/behavioral-signals-ai/intro-to-audio-analysis-recognizing-sounds-using-machine-learning-20fd646a0ec5" rel="nofollow">&#34;Intro to audio analysis&#34;</a>: intro to  audio feature extraction, classification and segmentation</li>
<li>Check out <a href="https://github.com/tyiannak/paura">paura</a> a Python script for realtime recording and analysis of audio data</li>
</ul>
<h2 dir="auto"><a id="user-content-general" aria-hidden="true" href="#general"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>General</h2>
<p dir="auto">pyAudioAnalysis is a Python library covering a wide range of audio analysis tasks. Through pyAudioAnalysis you can:</p>
<ul dir="auto">
<li>Extract audio <em>features</em> and representations (e.g. mfccs, spectrogram, chromagram)</li>
<li><em>Train</em>, parameter tune and <em>evaluate</em> classifiers of audio segments</li>
<li><em>Classify</em> unknown sounds</li>
<li><em>Detect</em> audio events and exclude silence periods from long recordings</li>
<li>Perform <em>supervised segmentation</em> (joint segmentation - classification)</li>
<li>Perform <em>unsupervised segmentation</em> (e.g. speaker diarization) and extract audio <em>thumbnails</em></li>
<li>Train and use <em>audio regression</em> models (example application: emotion recognition)</li>
<li>Apply dimensionality reduction to <em>visualize</em> audio data and content similarities</li>
</ul>
<h2 dir="auto"><a id="user-content-installation" aria-hidden="true" href="#installation"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Installation</h2>
<ul dir="auto">
<li>Clone the source of this library: <code>git clone https://github.com/tyiannak/pyAudioAnalysis.git</code></li>
<li>Install dependencies: <code>pip install -r ./requirements.txt </code></li>
<li>Install using pip: <code>pip install -e .</code></li>
</ul>
<h2 dir="auto"><a id="user-content-an-audio-classification-example" aria-hidden="true" href="#an-audio-classification-example"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>An audio classification example</h2>
<blockquote>
<p dir="auto">More examples and detailed tutorials can be found <a href="https://github.com/tyiannak/pyAudioAnalysis/wiki">at the wiki</a></p>
</blockquote>
<p dir="auto">pyAudioAnalysis provides easy-to-call wrappers to execute audio analysis tasks. Eg, this code first trains an audio segment classifier, given a set of WAV files stored in folders (each folder representing a different class) and then the trained classifier is used to classify an unknown audio WAV file</p>
<div data-snippet-clipboard-copy-content="from pyAudioAnalysis import audioTrainTest as aT
aT.extract_features_and_train([&#34;classifierData/music&#34;,&#34;classifierData/speech&#34;], 1.0, 1.0, aT.shortTermWindow, aT.shortTermStep, &#34;svm&#34;, &#34;svmSMtemp&#34;, False)
aT.file_classification(&#34;data/doremi.wav&#34;, &#34;svmSMtemp&#34;,&#34;svm&#34;)
"><pre><span>from</span> <span>pyAudioAnalysis</span> <span>import</span> <span>audioTrainTest</span> <span>as</span> <span>aT</span>
<span>aT</span>.<span>extract_features_and_train</span>([<span>&#34;classifierData/music&#34;</span>,<span>&#34;classifierData/speech&#34;</span>], <span>1.0</span>, <span>1.0</span>, <span>aT</span>.<span>shortTermWindow</span>, <span>aT</span>.<span>shortTermStep</span>, <span>&#34;svm&#34;</span>, <span>&#34;svmSMtemp&#34;</span>, <span>False</span>)
<span>aT</span>.<span>file_classification</span>(<span>&#34;data/doremi.wav&#34;</span>, <span>&#34;svmSMtemp&#34;</span>,<span>&#34;svm&#34;</span>)</pre></div>
<blockquote>
<p dir="auto">Result:
(0.0, array([ 0.90156761,  0.09843239]), [&#39;music&#39;, &#39;speech&#39;])</p>
</blockquote>
<p dir="auto">In addition, command-line support is provided for all functionalities. E.g. the following command extracts the spectrogram of an audio signal stored in a WAV file: <code>python audioAnalysis.py fileSpectrogram -i data/doremi.wav</code></p>
<h2 dir="auto"><a id="user-content-further-reading" aria-hidden="true" href="#further-reading"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Further reading</h2>
<p dir="auto">Apart from this README file, to bettern understand how to use this library one should read the following:</p>
<ul dir="auto">
<li><a href="https://hackernoon.com/audio-handling-basics-how-to-process-audio-files-using-python-cli-jo283u3y" rel="nofollow">Audio Handling Basics: Process Audio Files In Command-Line or Python</a>, if you want to learn how to handle audio files from command line, and some basic programming on audio signal processing. Start with that if you don&#39;t know anything about audio.</li>
<li><a href="https://hackernoon.com/intro-to-audio-analysis-recognizing-sounds-using-machine-learning-qy2r3ufl" rel="nofollow">Intro to Audio Analysis: Recognizing Sounds Using Machine Learning</a> This goes a bit deeper than the previous article, by providing a complete intro to theory and practice of audio feature extraction, classification and segmentation (includes many Python examples).</li>
<li><a href="https://github.com/tyiannak/pyAudioAnalysis/wiki">The library&#39;s wiki</a></li>
<li><a href="https://hackernoon.com/how-to-use-machine-learning-to-color-your-lighting-based-on-music-mood-bi163u8l" rel="nofollow">How to Use Machine Learning to Color Your Lighting Based on Music Mood</a>. An interesting use-case of using this lib to train a real-time music mood estimator.</li>
<li>A more general and theoretic description of the adopted methods (along with several experiments on particular use-cases) is presented <a href="http://journals.plos.org/plosone/article?id=10.1371/journal.pone.0144610" rel="nofollow">in this publication</a>. <em>Please use the following citation when citing pyAudioAnalysis in your research work</em>:</li>
</ul>
<div data-snippet-clipboard-copy-content="@article{giannakopoulos2015pyaudioanalysis,
  title={pyAudioAnalysis: An Open-Source Python Library for Audio Signal Analysis},
  author={Giannakopoulos, Theodoros},
  journal={PloS one},
  volume={10},
  number={12},
  year={2015},
  publisher={Public Library of Science}
}
"><pre>@<span>article</span>{<span>giannakopoulos2015pyaudioanalysis</span>,
  <span>title</span><span>=</span>{<span>pyAudioAnalysis</span>: <span>An</span> <span>Open</span><span>-</span><span>Source</span> <span>Python</span> <span>Library</span> <span>for</span> <span>Audio</span> <span>Signal</span> <span>Analysis</span>},
  <span>author</span><span>=</span>{<span>Giannakopoulos</span>, <span>Theodoros</span>},
  <span>journal</span><span>=</span>{<span>PloS</span> <span>one</span>},
  <span>volume</span><span>=</span>{<span>10</span>},
  <span>number</span><span>=</span>{<span>12</span>},
  <span>year</span><span>=</span>{<span>2015</span>},
  <span>publisher</span><span>=</span>{<span>Public</span> <span>Library</span> <span>of</span> <span>Science</span>}
}</pre></div>
<p dir="auto">For Matlab-related audio analysis material check  <a href="http://www.amazon.com/Introduction-Audio-Analysis-MATLAB%C2%AE-Approach/dp/0080993885" rel="nofollow">this book</a>.</p>
<h2 dir="auto"><a id="user-content-author" aria-hidden="true" href="#author"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Author</h2>
<p><a target="_blank" rel="noopener noreferrer" href="https://camo.githubusercontent.com/ac1cb9403373db1139cdca7246645856a5e5b02b54c7c1c8f81e73c258192934/68747470733a2f2f747969616e6e616b2e6769746875622e696f2f66696c65732f332e4a5047"><img src="https://camo.githubusercontent.com/ac1cb9403373db1139cdca7246645856a5e5b02b54c7c1c8f81e73c258192934/68747470733a2f2f747969616e6e616b2e6769746875622e696f2f66696c65732f332e4a5047" height="100" data-canonical-src="https://tyiannak.github.io/files/3.JPG"/></a></p>
<p dir="auto"><a href="https://tyiannak.github.io" rel="nofollow">Theodoros Giannakopoulos</a>,
Principal Researcher of Multimodal Machine Learning at the <a href="https://labs-repos.iit.demokritos.gr/MagCIL/index.html" rel="nofollow">Multimedia Analysis Group of the Computational Intelligence Lab (MagCIL)</a> of the Institute of Informatics and Telecommunications, of the National Center for Scientific Research &#34;Demokritos&#34;</p>
</article>
        </div></div>
  </body>
</html>
