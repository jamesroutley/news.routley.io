<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://aras-p.info/blog/2025/02/09/Surface-Stable-Fractal-Dither-on-Playdate/">Original</a>
    <h1>Surface-Stable Fractal Dither on Playdate</h1>
    
    <div id="readability-page-1" class="page"><div>
    <div>
      <div>

<article>
  <header>
    
    
  </header>
  <section>
    <p>Rune Skovbo Johansen has a really sweet <a href="https://github.com/runevision/Dither3D"><strong>Surface-Stable Fractal Dithering</strong></a>
technique, where the dither dots ‚Äústick‚Äù to 3D surfaces, yet the dot density adapts to the view distance and zoom
level.</p>
<p>Some people have asked whether this would be a good technique for <a href="https://play.date/">Playdate</a>, given that the screen
is one-bit color. And so I had to try it out! Here‚Äôs a video: <br/>


    
    </p><p>
      <iframe allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen" loading="eager" referrerpolicy="strict-origin-when-cross-origin" src="https://www.youtube.com/embed/zhkAIKEHeV0?autoplay=0&amp;controls=1&amp;end=0&amp;loop=0&amp;mute=0&amp;start=0" title="YouTube video"></iframe>
    </p>

<p>And here‚Äôs the code: <a href="https://github.com/aras-p/playdate-dither3d"><strong>github.com/aras-p/playdate-dither3d</strong></a>.</p>
<p>This is a long-arse post, so here‚Äôs the sections:
</p><nav id="TableOfContents">
  <ul>
    <li><a href="#is-it-practical">Is it practical?</a></li>
    <li><a href="#surface-stable-fractal-dithering">Surface-Stable Fractal Dithering</a></li>
    <li><a href="#perspective-correct-texturing">Perspective correct texturing</a></li>
    <li><a href="#displaying-brightness-on-a-playdate">Displaying brightness on a Playdate</a></li>
    <li><a href="#porting-surface-stable-fractal-noise-to-playdate">‚ÄúPorting‚Äù Surface-Stable Fractal Noise to Playdate</a></li>
    <li><a href="#optimizing-fractal-dithering">Optimizing Fractal Dithering</a></li>
    <li><a href="#scanline-rasterizers">Scanline Rasterizers</a></li>
    <li><a href="#comparing-scanline-rasterizers-to-actual-gpu">Comparing Scanline Rasterizers to actual GPU</a></li>
    <li><a href="#back-to-scanline-rasterizer">Back to scanline rasterizer</a></li>
    <li><a href="#thats-it-for-now">That‚Äôs it for now!</a></li>
  </ul>
</nav>
<h3 id="is-it-practical">Is it practical?</h3>
<p>My impression: <strong>not really practical</strong>.</p>
<p>Playdate hardware is like a PC from 1995 - no GPU at all, one fairly simple CPU
core. As such, it can do fairly simple 3D rendering (well, you need to write the whole rasterizer on the CPU),
but can barely do more than a handful of math operations per rasterized pixel. Rasterizing with screen-space fixed
Bayer or Blue Noise dither patterns is the way to go due to their simplicity.</p>
<p>You can <em>barely</em> do textured triangles, whereas cost of Fractal Dithering is, with some simplifications, at
least twice that (you still need to interpolate the texture coordinates, do some additional math on them, do a
3D texture lookup, and additional math on that).</p>
<blockquote>
<p>But, while doing this, I‚Äôve learned a thing or two about software rasterizers. Of course, everyone else has learned that
in 1997, but I‚Äôve <em>never</em> written a perspective-correct textured triangle rasterizer‚Ä¶ As
the old saying goes, ‚Äúthe best time to write a triangle rasterizer was thirty years ago. The second best time is today.‚Äù
So what follows is various notes I have made during the process.</p>
</blockquote>
<h3 id="surface-stable-fractal-dithering">Surface-Stable Fractal Dithering</h3>
<p>Rune has a really great <a href="https://www.youtube.com/watch?v=HPqGaIMVuLs">video explaining the technique</a>, and an extended
<a href="https://www.youtube.com/watch?v=EzjWBmhO_1E">feature demo video</a>, plus all the source in the
<a href="https://github.com/runevision/Dither3D">github repository</a>, with most of the shader logic being in
<a href="https://github.com/runevision/Dither3D/blob/main/Assets/Dither3D/Dither3DInclude.cginc">Dither3DInclude.cginc</a>
HLSL shader file.</p>
<p>Here‚Äôs an outline of the steps. We have some scene where the input for dithering is ‚Äúbrightness‚Äù: </p>
<p>And the Surface-Stable Fractal Dithering (with a 4x4 dither pattern) turns it into this: </p>
<p>Now, the dots above are still nicely anti-aliased; whereas Playdate is strictly 1-bit screen. Giving it only
two colors, and making them similar to how the device screen looks like, the result would be like this (note that
resolution here is 2x larger than Playdate, i.e. 800x480): </p>
<p>In addition to brightness, the dithering process needs geometry texture coordinates (‚ÄúUVs‚Äù) as well. The dithering
pattern ‚Äústicks‚Äù to the surfaces by placing them in UV space. </p>
<p>It also needs the derivatives of UVs in screen space, to know ‚Äúhow fast‚Äù they change across the screen projection. That
will be used to make sure the dither pattern is roughly constant size on screen. On the GPU, the derivatives
fall out naturally out of 2x2 pixel execution pattern, and in HLSL are provided by <code>ddx</code> and <code>ddy</code> built-in functions.
Here they are, visualized as <code>abs(ddx(uv))*100</code> and <code>abs(ddy(uv))*100</code> respectively: </p>
<p>Now, given these four derivative values, the technique uses singular value decomposition to find the minimum and
maximum rate of change (these might not be aligned to screen axes). The maximum and minimum frequencies (scaled up 30x)
look like:</p>
<p>The minimum frequency, together with user/material-specified dot spacing factor, gets turned into base
dither dot spacing value:</p>
<p>Then it is further adjusted by input brightness (if ‚Äúsize variability‚Äù material parameter is zero), so that
the actual dots stay roughly the same size, but in darker areas their spacing spreads further out.</p>
<p>This spacing is then used to calculate two factors used to sample a 3D lookup texture: 1) by which power
of two to adjust the mesh UVs so that the dither dots pattern is placed onto surface properly, and 2) which
actual dither pattern ‚Äúslice‚Äù to use, so that the pattern more or less seamlessly blends between powers-of-two
levels.</p>
<p>The mesh UVs, adjusted for 3D texture sampling, look like this, as well as indication which Z slice of the texture to use:</p>
<p>Result of sampling the 3D lookup texture (that was prepared ahead of time) is:</p>
<p>The 3D texture itself for the 4x4 dither pattern (64x64x16, with 3D texture slices side by side) looks like this:</p>
<p><em>We‚Äôre almost there!</em> Next up, the algorithm calculates contrast factor, which is based on material settings,
dot spacing, and the ratio of minimum and maximum UV rate of change. From that, the base brightness value
that the contrast is scaled around is calculated (normally it would be 0.5, but where the pattern would be very blurry
that would look bad, so there it is scaled away). And finally, the threshold value to compare the radial gradient from
3D texture is calculated based on input brightness. The contrast, base value and threshold respectively look like:</p>
<p>And finally we get our result:</p>
<p>So all of that was‚Ä¶ <em>&lt;takes a quick look&gt;</em> something like one 3D texture sample, 4 divisions, 2 raises to a
power, 3 square roots, 3 exp2s, 1 log2, and several dozen regular multiplies or additions for every pixel.
Provided you have UVs and their derivatives already, that is.</p>
<p>That should, like, <em>totally fly</em> on a Playdate, right? ü•π</p>
<p>Anyway, let‚Äôs do this! But first‚Ä¶</p>
<h3 id="perspective-correct-texturing">Perspective correct texturing</h3>
<p>Triangles have texture coordinates defined at their vertices, and while rasterizing the triangle, you interpolate
the texture coordinates, and at each pixel, read the texture value corresponding to the interpolated coordinate.
Here‚Äôs a simple checkerboard texture using interpolated UVs (ignore the noisy dithering; it is unrelated): </p>
<p>However, if we look at the same mesh at an angle, it looks really weird:</p>
<p>That is because under perspective projection, you need to use
<a href="https://en.wikipedia.org/wiki/Texture_mapping#Perspective_correctness">perspective correct texture mapping</a>,
and not just simply interpolate UVs in screen space. With perspective correction things look good, however that
means now we have to do a division per-pixel. And, divisions are slow. Anyway, this is the least of our problems
(for now‚Ä¶).</p>
<h3 id="displaying-brightness-on-a-playdate">Displaying brightness on a Playdate</h3>
<p>Playdate <a href="https://help.play.date/hardware/the-specs/">hardware</a> has 1-bit ‚Äúmemory LCD‚Äù display: each pixel
can only be ‚Äúon‚Äù or ‚Äúoff‚Äù. So typically to display ‚Äúbrightness‚Äù, some sort of dithering is used. The example
simple 3D rasterizer included in the <a href="https://play.date/dev/">Playdate SDK</a> (‚Äúmini3d‚Äù) contains code
that rasterizes triangles using different patterns based on brightness: </p>
<p>Another common approach is to use a <a href="https://momentsingraphics.de/BlueNoise.html">blue noise texture</a>
for thresholding the brightness. I‚Äôve used that approach in ‚Äú<a href="https://aras-p.info/blog/2024/05/20/Crank-the-World-Playdate-demo/">Everybody Wants to Crank the World</a>‚Äù
Playdate demo as well.</p>
<p>So the question now is, could Surface-Stable Fractal Noise be another approach to display ‚Äúbrightness‚Äù on a 1-bit
Playdate screen?</p>
<h3 id="porting-surface-stable-fractal-noise-to-playdate">‚ÄúPorting‚Äù Surface-Stable Fractal Noise to Playdate</h3>
<p>I had a triangle rasterizer based on Fabian Giesen‚Äôs
‚Äú<a href="https://gist.github.com/rygorous/9b793cd21d876da928bf4c7f3e625908">Simple watertight triangle rasterizer</a>‚Äù
working on a Playdate. This is a half-space / barycentric rasterizer, which is a good fit for hardware
or modern CPUs with SIMD instruction sets. It <em>might</em> be a bad fit for Playdate CPU, but for now we‚Äôre not very
concerned with that. The code is nice and small; further recommended reading from Fabian are
‚Äú<a href="https://fgiesen.wordpress.com/2013/02/06/the-barycentric-conspirac/">The barycentric conspiracy</a>‚Äù,
‚Äú<a href="https://fgiesen.wordpress.com/2013/02/08/triangle-rasterization-in-practice/">Triangle rasterization in practice</a>‚Äù,
‚Äú<a href="https://fgiesen.wordpress.com/2013/02/10/optimizing-the-basic-rasterizer/">Optimizing the basic rasterizer</a>‚Äù
blog posts, as well as ‚Äú<a href="https://www.pouet.net/topic.php?which=8760&amp;page=1#c408170">Fast software rasteriser in JavaScript?</a>‚Äù
discussion on pou√´t.</p>
<p>Initial port of Rune‚Äôs <a href="https://github.com/runevision/Dither3D/blob/main/Assets/Dither3D/Dither3DInclude.cginc">dithering shader code</a> on a Playdate looked like this:</p>
<p>Welp, this does not look correct <em>at all</em>. Time to debug where exactly it goes wrong!</p>
<blockquote>
<p>For development convenience, I have the whole ‚Äú<a href="https://github.com/aras-p/playdate-dither3d">playdate application</a>‚Äù
setup as both a Playdate build target, and an application that can build for PC.
There‚Äôs a super tiny ‚Äúplatform abstraction‚Äù that provides pointer to ‚Äúscreen‚Äù, as well as input
controls handling, and on a Playdate that goes directly into the SDK, whereas on a PC that is all handled
through <a href="https://github.com/floooh/sokol">Sokol</a>. Is nice!</p>
</blockquote>
<p>For the ‚ÄúPC‚Äù build target, in addition to the regular 1-bit ‚Äúscreen‚Äù buffer, I also have a full-color
‚ÄúRGBA per pixel‚Äù debug overlay buffer. That way I can have the correct shader with some debug visualizations
running in Unity, and my own ‚Äúshader port‚Äù running in a software rasterizer, side by side, with
a full color debug overlay. Check it out ‚Äì left side my code (displaying obviously incorrect result),
right side Unity: </p>
<p>The mesh UVs are correct and interpolated correctly (multiplied by 5 to see their interpolation better): </p>
<p>Derivatives in my code, turns out, were not entirely wrong, but not correct either: </p>
<p>At that point my rasterizer was doing 1 pixel at a time, so in order to calculate the derivatives
I tried to calculate them with some math, and got the math wrong, obviosly. With the full
proper calculation, they were correct:</p>
<p>Turns out I also had the 3D texture Z layers order wrong, and with that fixed, everything else
was correct too. Dither UVs, 3D texture radial pattern, render result, render result with 2 colors
only, and finally render result with non-constant input lighting: </p>
<p>So, yay! It works!</p>
<p>It runs at‚Ä¶ <em>830 milliseconds</em> per frame though (1.2FPS). üêå</p>
<h3 id="optimizing-fractal-dithering">Optimizing Fractal Dithering</h3>
<p>Trivially move some math from per-pixel to be done once per triangle: <em>604ms</em>.</p>
<p>Replace division and <code>exp2f</code> call by directly working on floating point bits. If we are in ‚Äúregular floats‚Äù
range (no NaNs/infinities/denormals), <code>x / exp2f((float)i)</code> can be replaced by something like:</p>
<pre><code>// equivalent to `x / exp2f((float)i)`, provided we are not in
// infinities / subnormals territory.
static inline float adjust_float_exp(float x, int i)
{
    union {
        float f;
        uint32_t u;
    } fu;
    fu.f = x;
    fu.u -= (uint32_t)i &lt;&lt; 23;
    return fu.f;
}
</code></pre>
<p>In the dither shader, this was used to transform mesh UVs to the fractal pattern UVs. That gets us down to
<em>316ms</em>, yay! (by the way, such an optimization for today‚Äôs GPUs is barely ‚Äì if at all ‚Äì worth doing)</p>
<p>Likewise, in the 3D texture fractal level and fraction calculation that uses <code>log2f</code> and a <code>floorf</code>
can also be replaced with direct float bit manipulation:</p>
<pre><code>//float spacingLog = log2f(spacing);
//const float patternScaleLevel = floorf(spacingLog); // Fractal level.
//const int patternScaleLevel_i = (int)patternScaleLevel;
//float f = spacingLog - patternScaleLevel; // Fractional part.
//
// instead of above, work on float bits directly:
union {
    float f;
    uint32_t u;
} fu;
fu.f = spacing;
// patternScaleLevel is just float exponent:
const int patternScaleLevel_i = (int)((fu.u &gt;&gt; 23) &amp; 0xFF) - 127;
// fractional part is:
// - take the mantissa bits of spacing,
// - set exponent to 127, i.e. range [0,1)
// - use that as a float and subtract 1.0
fu.u = (fu.u &amp; 0x7FFFFF) | 0x3F800000;
float f = fu.f - 1.0f;
</code></pre>
<p><em>And now we are at 245ms.</em></p>
<p>And now, switch the rasterizer to operate in 2x2 pixel blocks (hey, just like a GPU does!). This <em>does</em>
make the code much longer (<a href="https://github.com/aras-p/playdate-dither3d/commit/82b157d58e4">commit</a>),
but things like derivatives come ‚Äúfor free‚Äù, plus it allows doing a bunch
of calculations (all the dither dot spacing, 3D texture level etc.) once per 2x2 pixel block. <em>149ms.</em></p>
<p><a href="https://github.com/aras-p/playdate-dither3d/commit/48ce2c9a875">Some</a>
<a href="https://github.com/aras-p/playdate-dither3d/commit/6a090aee21c">more</a> simple math operation moves
and we‚Äôre at <em>123ms</em>.</p>
<p>At this point I was out of easy ideas, so I decided that running ‚Äúfull‚Äù effect on a Playdate
is not going to work, so <strong>it is time to simplify / approximate it</strong>.</p>
<p>The effect spends quite some effort in determining nice ‚Äúcontrast‚Äù value, but it comes with a cost:
doing singular value decomposition on the four derivatives, a division, and a bunch of other maths.
Let‚Äôs remove all that, and instead determine dither pattern spacing by a simple average of <code>dU/dX</code>,
<code>dV/dX</code>, <code>dU/dY</code>, <code>dV/dU</code>. Then there‚Äôs no longer additional contrast tweak based on ‚Äúblurriness‚Äù
(ratio of min/max UV change). However, it runs at <em>107ms</em> now, but looks different: </p>
<p>The 3D lookup texture for dithering, at 64x64x16 resolution, is 64 kilobytes in size. The CPU
cache is only 8KB, and the memory bandwidth is not great. Maybe we could reduce the texture horizontal
resolution (to 32x32x16), for a 16KB texture, and it would not reduce quality all that much? Looks
a bit different, but hey, <em>83ms</em> now:</p>
<p>Instead of doing perspective correct UV interpolation for every pixel, do it for every
2nd pixel only, i.e. for the first column of each 2x2 pixel block. For the other column,
do regular interpolation between this and next block‚Äôs UV values
(<a href="https://github.com/aras-p/playdate-dither3d/commit/69334c13eba">commit</a>). <em>75ms</em>:</p>
<p>Simplify the final math that does sampled 3D texture result comparison, now it is just a simple
‚Äúcompare value with threshold‚Äù. <em>65ms</em>:</p>
<p>At this point I was out of easy ideas how to speed it up further (harder ideas: do perspective correct
interpolation at even lower frequency). However, anecdotally, the whole current approach
of using halfspace/barycentric rasterizer is probably not a good fit for the Playdate CPU (it does
not have SIMD instructions that would be useful for this task, afterall). So maybe I should
try out the classic ‚Äúscanline‚Äù rasterizer approach?</p>
<h3 id="scanline-rasterizers">Scanline Rasterizers</h3>
<p>The <a href="https://play.date/dev/">Playdate SDK</a> sample code (‚Äúmini3d‚Äù) contains a simple scanline triangle rasterizer,
however it can only cover whole triangle in a screen-space aligned pattern, and has no support for
texture coordinates or any other sort of interpolation. However, people have taken that and expanded
on it, e.g. there‚Äôs <a href="https://github.com/nstbayless/mini3d-plus">Mini3D+</a> that adds near plane clipping,
texturing, alpha-testing, fog, etc. Nice!</p>
<p>So let‚Äôs try it out. Here‚Äôs the same scene, with just a pure black/white checkerboard pattern based on mesh
UVs. My existing halfspace/barycentric rasterizer, and the one from Mini3D+ respectively:
<a href="https://aras-p.info/blog/2025/02/09/Surface-Stable-Fractal-Dither-on-Playdate/07-pd-halfspace-checker.png"><img src="https://aras-p.info/blog/2025/02/09/Surface-Stable-Fractal-Dither-on-Playdate/07-pd-halfspace-checker.png" title="" alt="" width="360px"/></a>
<a href="https://aras-p.info/blog/2025/02/09/Surface-Stable-Fractal-Dither-on-Playdate/07-pd-scanline-checker.png"><img src="https://aras-p.info/blog/2025/02/09/Surface-Stable-Fractal-Dither-on-Playdate/07-pd-scanline-checker.png" title="" alt="" width="360px"/></a></p>
<p>Immediate notes:</p>
<ul>
<li>Yes the scanline rasterizer (for UV based checkerboard at least) is faster using the scanline approach
(54ms halfspace, 33ms scanline),</li>
<li>However the scanline one has more ‚Äúartifacts‚Äù: stray black pixels near edge of plane/cube, and in general
things are shifted by a pixel here and there for some reason. At this point I do not know which one
is ‚Äúmore correct‚Äù however, but the difference was bothering me :)</li>
<li>The checkerboard lines are ‚Äúmore wiggly‚Äù in the scanline one, most visible on the ‚Äúfloor‚Äù object.</li>
</ul>
<p>I tried to ‚Äúport‚Äù the dithering effect to this rasterizer, but got lost in trying to calculate the correct
UV derivatives (horizontal ones are easy, vertical ones are harder). And the subtle rendering differences
were bothering me, so I decided to <em>actually</em> read up about scanline rasterizers. The seminal series
on them are from 1995/1996, by Chris Hecker for Game Developer Magazine. Hecker has the archive
and the code drop at his website: <a href="https://chrishecker.com/Miscellaneous_Technical_Articles">Perspective Texture Mapping</a>.</p>
<p>So! Taking the initial (fully floating point) rasterizer from Hecker‚Äôs code, the UV based checkerboard
renders like this: </p>
<p>This one runs slower than Mini3D+ one (42ms), but does not have stray ‚Äúblack pixels‚Äù artifacts around some
mesh edges, and the lines on the floor are no longer wiggly. However, it is <em>slightly different</em> compared
to the halfspace one! Why? This has nothing to do with task at hand, but the fact was bothering me, so‚Ä¶</p>
<h3 id="comparing-scanline-rasterizers-to-actual-gpu">Comparing Scanline Rasterizers to actual GPU</h3>
<p>Again using my ‚Äúcolored debug overlay on PC build‚Äù feature, I made a synthetic ‚Äútest scene‚Äù with various cases
of UV mapped geometry, with cases like:</p>
<ul>
<li>Checkerboard should map exactly 1:1 to pixels, at regular orientation, and geometry being rotated
by exactly 90 degrees,</li>
<li>The same, but geometry coordinates being shifted by less than half a pixel; the result should look the same.</li>
<li>Some geometry that should be exactly one pixel away from screen edge,</li>
<li>Some geometry where each checkerboard square should map to 1.5 (will have aliasing patterns) or 2 (should be exact)
screen pixels.</li>
<li>Several cases of perspective projection,</li>
<li>Several cases of geometry being clipped by screen edges.</li>
</ul>
<p>Here‚Äôs how it is rendered by the halfspace/barycentric rasterizer:</p>
<p>And then I made a simple Unity shader &amp; C# script that renders exactly the same setup, using actual GPU. Here it is (pasted
into the same window frame as the test app):</p>
<p>Not exactly the same, but <em>really close</em>, I‚Äôll claim this is acceptable (FWIW, GPUs use 8 bits subtexel precision,
whereas my code uses 4 bits).</p>
<p>The rasterizer from Mini3D+ however looks much more different: 1) some cases do not map checkerboard to pixels 1:1,
2) the artifacts between some faces is where the rasterizer is not ‚Äúwatertight‚Äù and neighboring faces both
write to the same pixels, 3) some cases where geometry should be exactly one pixel away from screen edge are actually not. </p>
<p>Hecker‚Äôs ‚Äúfully floating point‚Äù rasterizer looks better, but still a lot more different from what the GPU does.</p>
<p>The fixed point, sub-dividing affine span rasterizer from Hecker‚Äôs code (i.e. the last iteration before the assembly-optimized
one) looks like this however. It fixes some artifacts from the previous one, but still covers slightly different pixels
compared to the GPU, and introduces UV wrapping artifacts at right sides of some planes. </p>
<p>My understanding of the difference is that <em>maybe Hecker‚Äôs rasterizer follows pre-Direct3D 10 coordinate conventions</em>,
i.e. where pixel integer coordinates are placed directly on pixel centers. From part 3 of the article series, there‚Äôs
this bit:</p>
<blockquote>
<p>I chose the corresponding screen coordinates for the destination. I wanted the destination pixel centers to map
exactly to the source pixel centers.</p>
</blockquote>
<p>And when talking about how one would map a texture directly to screen at 1:1 ratio, he talks about adding -0.5 offset
to the coordinates. This sounds very much like what people back in Direct3D 8/9 times had to always keep in mind,
or try to <a href="https://aras-p.info/blog/2016/04/08/solving-dx9-half-pixel-offset/">solve that automatically in all their shaders</a>.</p>
<p>While this coordinate system intuitively makes sense (pixel centers are at integer coordinates, yay!),
eventually everyone realized it causes more problems down the line. The official
<a href="https://microsoft.github.io/DirectX-Specs/d3d/archive/D3D11_3_FunctionalSpec.htm#3.3.1%20Pixel%20Coordinate%20System">DirectX Specs website</a> minces no words:</p>
<blockquote>
<p>D3D9 and prior had a terrible Pixel Coordinate System where the origin was the center of the top left pixel on the RenderTarget</p>
</blockquote>
<p>Armed with that guess, I <a href="https://github.com/aras-p/playdate-dither3d/commit/b691214bbd70">changed</a>
the Hecker‚Äôs rasterizer code to shift positions by half a pixel, and remove the complexicated <code>dUdXModifier</code> dance
it was doing. And it became <em>way</em> closer to what the GPU is doing:</p>
<p>The fixed point, subdividing affine Hecker‚Äôs rasterizer with the above fix was <em>more correct</em> than
the one from Mini3D+, and running a <em>tiny bit</em> faster by now. So I left only that code, and proceeded with it.</p>
<h3 id="back-to-scanline-rasterizer">Back to scanline rasterizer</h3>
<p>Initial ‚Äúport‚Äù of the Fractal Dithering to the scanline rasterizer was at <em>102ms</em>, i.e. slower than
halfspace one (63ms). But, I was calculating the UV derivatives for every pixel. Derivatives along
X axis are cheap (just difference to next pixel, which the inner scanline loop already does),
but the vertical ones I was doing in a ‚Äúslow but correct‚Äù way.</p>
<p>The derivatives change fairly slowly across the triangle surface however, so what if I calculate
<code>dU/dY</code> and <code>dV/dY</code> only at the scanline endpoints, and just interpolate it across? This gets us
down to <em>71ms</em>.</p>
<p>But hey! <em>Maybe I do not need the per-pixel UV derivatives at all?</em> The whole reason for derivatives
is to calculate the dither pattern spacing. But, at least in my scenes, the spacing varies <em>very slowly</em>
(if at all) across the triangle surface. Recall the previous visualization:</p>
<p>I can just calculate the derivatives at triangle vertices, do all the dither spacing
calculations there, and interpolate spacing value across the triangle. <em>56ms</em>!</p>
<p>Then, do the 3D lookup math directly from fixed point UVs that are interpolated
by the rasterizer. The previous ‚Äúreplace division by exp2‚Äù trick by working on floating
point bits is even simpler in fixed point: just shift by the provided integer
amount, and take the fractional bits as needed. <em>50ms</em> </p>
<p>And the final optimization step I did so far has nothing to do with dithering step itself:
the higher level code was transforming all mesh triangles, calculating their normals for lighting,
then sorting them by distance, and finally rasterizing them back-to-front. Here the triangles
that are back-facing, outside of the screen, or zero-area are culled. I moved the triangle culling
to happen before sorting (there‚Äôs no point in sorting invisible triangles anyway), and now
the scanline dither effect runs at <em>45ms</em> (halfspace one at <em>60ms</em>).</p>
<h3 id="thats-it-for-now">That‚Äôs it for now!</h3>
<p>So, this scene runs at 45ms (20-22FPS) on the Playdate device right now, which is much better
than the initial 830ms (1.2FPS). Can it be made yet faster? Most likely.</p>
<p>Does it make it a practical effect on the Playdate? Dunno, it is quite heavy and at this low
resolution, does not look very good (it does not help that some approximations/simplifications
I did actually increase dither pattern aliasing).</p>
<p>But hey, this was fun! I learned a thing or three. And if you want either a scanline or
a halfspace rasterizer for Playdate that very closely matches what actual GPU would do
(i.e. it is a more correct rasterizer than mini3d from Playdate SDK or Mini3D+), you can find
them at <a href="https://github.com/aras-p/playdate-dither3d">github.com/aras-p/playdate-dither3d</a></p>

  </section>
  
</article>

    </div>
    
    </div>
  </div></div>
  </body>
</html>
