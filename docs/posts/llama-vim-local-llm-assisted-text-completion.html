<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/ggml-org/llama.vim">Original</a>
    <h1>Llama.vim â€“ Local LLM-assisted text completion</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto">Local LLM-assisted text completion.</p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/1991296/380711734-a950e38c-3b3f-4c46-94fe-0d6e0f790fc6.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc3MDcxNjMsIm5iZiI6MTczNzcwNjg2MywicGF0aCI6Ii8xOTkxMjk2LzM4MDcxMTczNC1hOTUwZTM4Yy0zYjNmLTRjNDYtOTRmZS0wZDZlMGY3OTBmYzYucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MDEyNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTAxMjRUMDgyMTAzWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NTIyMjIwYTcxN2ZkOGMxNTA2YWUzOGU4ODYwYTIzNmNkNzlhMDQ2OWRhYjAyYjdmYWI3MGIwOTFiODZlNmU0YyZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.fFLp6pzc9Fs3foGY_C8BukvkQQZcfYbgC2EalRfKwH4"><img width="485" alt="image" src="https://private-user-images.githubusercontent.com/1991296/380711734-a950e38c-3b3f-4c46-94fe-0d6e0f790fc6.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc3MDcxNjMsIm5iZiI6MTczNzcwNjg2MywicGF0aCI6Ii8xOTkxMjk2LzM4MDcxMTczNC1hOTUwZTM4Yy0zYjNmLTRjNDYtOTRmZS0wZDZlMGY3OTBmYzYucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MDEyNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTAxMjRUMDgyMTAzWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9NTIyMjIwYTcxN2ZkOGMxNTA2YWUzOGU4ODYwYTIzNmNkNzlhMDQ2OWRhYjAyYjdmYWI3MGIwOTFiODZlNmU0YyZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.fFLp6pzc9Fs3foGY_C8BukvkQQZcfYbgC2EalRfKwH4"/></a>
<hr/>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/1991296/381658578-206c8399-ff73-495d-ba67-65725138c021.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc3MDcxNjMsIm5iZiI6MTczNzcwNjg2MywicGF0aCI6Ii8xOTkxMjk2LzM4MTY1ODU3OC0yMDZjODM5OS1mZjczLTQ5NWQtYmE2Ny02NTcyNTEzOGMwMjEuZ2lmP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MDEyNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTAxMjRUMDgyMTAzWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9YzlhMWFjMGYwOTExMDc2NjhmMDRmY2I4YTlkOTQ5YzBmMGVkYzA3N2UyZDVjMjRiNzM4ODE2MThhYTIwMTEyZSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.sRPRNAOY8JHFcNqX3AxRpEMjzrLJuIGxHCJf0_5VwpU"><img src="https://private-user-images.githubusercontent.com/1991296/381658578-206c8399-ff73-495d-ba67-65725138c021.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc3MDcxNjMsIm5iZiI6MTczNzcwNjg2MywicGF0aCI6Ii8xOTkxMjk2LzM4MTY1ODU3OC0yMDZjODM5OS1mZjczLTQ5NWQtYmE2Ny02NTcyNTEzOGMwMjEuZ2lmP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MDEyNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTAxMjRUMDgyMTAzWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9YzlhMWFjMGYwOTExMDc2NjhmMDRmY2I4YTlkOTQ5YzBmMGVkYzA3N2UyZDVjMjRiNzM4ODE2MThhYTIwMTEyZSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.sRPRNAOY8JHFcNqX3AxRpEMjzrLJuIGxHCJf0_5VwpU" alt="llama vim-swift" data-animated-image=""/></a></p>

<ul dir="auto">
<li>Auto-suggest on cursor movement in <code>Insert</code> mode</li>
<li>Toggle the suggestion manually by pressing <code>Ctrl+F</code></li>
<li>Accept a suggestion with <code>Tab</code></li>
<li>Accept the first line of a suggestion with <code>Shift+Tab</code></li>
<li>Control max text generation time</li>
<li>Configure scope of context around the cursor</li>
<li>Ring context with chunks from open and edited files and yanked text</li>
<li><a href="https://github.com/ggerganov/llama.cpp/pull/9787" data-hovercard-type="pull_request" data-hovercard-url="/ggerganov/llama.cpp/pull/9787/hovercard">Supports very large contexts even on low-end hardware via smart context reuse</a></li>
<li>Display performance stats</li>
</ul>



<div dir="auto" data-snippet-clipboard-copy-content="Plug &#39;ggml-org/llama.vim&#39;"><pre>Plug <span><span>&#39;</span>ggml-org/llama.vim<span>&#39;</span></span></pre></div>

<div dir="auto" data-snippet-clipboard-copy-content="cd ~/.vim/bundle
git clone https://github.com/ggml-org/llama.vim"><pre><span>cd</span> <span>~</span>/.vim/bundle
git clone https://github.com/ggml-org/llama.vim</pre></div>
<p dir="auto">Then add <code>Plugin &#39;llama.vim&#39;</code> to your <em>.vimrc</em> in the <code>vundle#begin()</code> section.</p>

<p dir="auto">The plugin requires a <a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a> server instance to be running at <a href="https://github.com/ggml-org/llama.vim/blob/7d3359077adbad4c05872653973c3ceb09f18ad9/autoload/llama.vim#L34-L36"><code>g:llama_config.endpoint</code></a></p>



<p dir="auto">Either build from source or use the latest binaries: <a href="https://github.com/ggerganov/llama.cpp/releases">https://github.com/ggerganov/llama.cpp/releases</a></p>

<p dir="auto">Here are recommended settings, depending on the amount of VRAM that you have:</p>
<ul dir="auto">
<li>
<p dir="auto">More than 16GB VRAM:</p>
<div dir="auto" data-snippet-clipboard-copy-content="llama-server \
    -hf ggml-org/Qwen2.5-Coder-7B-Q8_0-GGUF \
    --port 8012 -ngl 99 -fa -ub 1024 -b 1024 -dt 0.1 \
    --ctx-size 0 --cache-reuse 256"><pre>llama-server \
    -hf ggml-org/Qwen2.5-Coder-7B-Q8_0-GGUF \
    --port 8012 -ngl 99 -fa -ub 1024 -b 1024 -dt 0.1 \
    --ctx-size 0 --cache-reuse 256</pre></div>
</li>
<li>
<p dir="auto">Less than 16GB VRAM:</p>
<div dir="auto" data-snippet-clipboard-copy-content="llama-server \
    -hf ggml-org/Qwen2.5-Coder-3B-Q8_0-GGUF \
    --port 8012 -ngl 99 -fa -ub 1024 -b 1024 -dt 0.1 \
    --ctx-size 0 --cache-reuse 256"><pre>llama-server \
    -hf ggml-org/Qwen2.5-Coder-3B-Q8_0-GGUF \
    --port 8012 -ngl 99 -fa -ub 1024 -b 1024 -dt 0.1 \
    --ctx-size 0 --cache-reuse 256</pre></div>
</li>
<li>
<p dir="auto">Less than 8GB VRAM:</p>
<div dir="auto" data-snippet-clipboard-copy-content="llama-server \
    -hf ggml-org/Qwen2.5-Coder-1.5B-Q8_0-GGUF \
    --port 8012 -ngl 99 -fa -ub 1024 -b 1024 -dt 0.1 \
    --ctx-size 0 --cache-reuse 256"><pre>llama-server \
    -hf ggml-org/Qwen2.5-Coder-1.5B-Q8_0-GGUF \
    --port 8012 -ngl 99 -fa -ub 1024 -b 1024 -dt 0.1 \
    --ctx-size 0 --cache-reuse 256</pre></div>
</li>
</ul>
<p dir="auto">Use <code>:help llama</code> for more details.</p>

<p dir="auto">The plugin requires FIM-compatible models: <a href="https://huggingface.co/collections/ggml-org/llamavim-6720fece33898ac10544ecf9" rel="nofollow">HF collection</a></p>

<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/1991296/376671627-8f5748b3-183a-4b7f-90e1-9148f0a58883.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc3MDcxNjMsIm5iZiI6MTczNzcwNjg2MywicGF0aCI6Ii8xOTkxMjk2LzM3NjY3MTYyNy04ZjU3NDhiMy0xODNhLTRiN2YtOTBlMS05MTQ4ZjBhNTg4ODMucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MDEyNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTAxMjRUMDgyMTAzWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MmI1OTcxMjI4MDE1ZWZlMGYzZjMyMGNmMjk1OWYwYzBmOGFhM2VhMjhiYzYyOWM4Y2YzOTkyMWRhM2ViMDAzNSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.yprk1JFXn9BEigC3ytR8tDMpxpLcXSZbW_UzbXqus-E"><img width="1758" alt="image" src="https://private-user-images.githubusercontent.com/1991296/376671627-8f5748b3-183a-4b7f-90e1-9148f0a58883.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc3MDcxNjMsIm5iZiI6MTczNzcwNjg2MywicGF0aCI6Ii8xOTkxMjk2LzM3NjY3MTYyNy04ZjU3NDhiMy0xODNhLTRiN2YtOTBlMS05MTQ4ZjBhNTg4ODMucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MDEyNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTAxMjRUMDgyMTAzWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MmI1OTcxMjI4MDE1ZWZlMGYzZjMyMGNmMjk1OWYwYzBmOGFhM2VhMjhiYzYyOWM4Y2YzOTkyMWRhM2ViMDAzNSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.yprk1JFXn9BEigC3ytR8tDMpxpLcXSZbW_UzbXqus-E"/></a>
<div dir="auto"><h3 tabindex="-1" dir="auto">Using <code>llama.vim</code> on M1 Pro (2021) with <code>Qwen2.5-Coder 1.5B Q8_0</code>:</h3><a id="user-content-using-llamavim-on-m1-pro-2021-with-qwen25-coder-15b-q8_0" aria-label="Permalink: Using llama.vim on M1 Pro (2021) with Qwen2.5-Coder 1.5B Q8_0:" href="#using-llamavim-on-m1-pro-2021-with-qwen25-coder-15b-q8_0"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/1991296/378362882-0ccb93c6-c5c5-4376-a5a3-cc99fafc5eef.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc3MDcxNjMsIm5iZiI6MTczNzcwNjg2MywicGF0aCI6Ii8xOTkxMjk2LzM3ODM2Mjg4Mi0wY2NiOTNjNi1jNWM1LTQzNzYtYTVhMy1jYzk5ZmFmYzVlZWYucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MDEyNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTAxMjRUMDgyMTAzWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MzM5MWU3NzVlYTQ5MDU5Mjg5MDBlMDcxNGI2YWQ4YmM0NTIxMmZkMDdiYzBiN2VhZGM4MWEwY2RiMDRiNmE5NiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.WWLi-q3CmCBsX6r-pDfet0ExjVql9H-DrLe8BgwnA30"><img width="1512" alt="image" src="https://private-user-images.githubusercontent.com/1991296/378362882-0ccb93c6-c5c5-4376-a5a3-cc99fafc5eef.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc3MDcxNjMsIm5iZiI6MTczNzcwNjg2MywicGF0aCI6Ii8xOTkxMjk2LzM3ODM2Mjg4Mi0wY2NiOTNjNi1jNWM1LTQzNzYtYTVhMy1jYzk5ZmFmYzVlZWYucG5nP1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MDEyNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTAxMjRUMDgyMTAzWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9MzM5MWU3NzVlYTQ5MDU5Mjg5MDBlMDcxNGI2YWQ4YmM0NTIxMmZkMDdiYzBiN2VhZGM4MWEwY2RiMDRiNmE5NiZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.WWLi-q3CmCBsX6r-pDfet0ExjVql9H-DrLe8BgwnA30"/></a>
<p dir="auto">The orange text is the generated suggestion. The green text contains performance stats for the FIM request: the currently used context is <code>15186</code> tokens and the maximum is <code>32768</code>. There are <code>30</code> chunks in the ring buffer with extra context (out of <code>64</code>). So far, <code>1</code> chunk has been evicted in the current session and there are <code>0</code> chunks in queue. The newly computed prompt tokens for this request were <code>260</code> and the generated tokens were <code>25</code>. It took <code>1245 ms</code> to generate this suggestion after entering the letter <code>c</code> on the current line.</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">Using <code>llama.vim</code> on M2 Ultra with <code>Qwen2.5-Coder 7B Q8_0</code>:</h3><a id="user-content-using-llamavim-on-m2-ultra-with-qwen25-coder-7b-q8_0" aria-label="Permalink: Using llama.vim on M2 Ultra with Qwen2.5-Coder 7B Q8_0:" href="#using-llamavim-on-m2-ultra-with-qwen25-coder-7b-q8_0"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<details open="">
  <summary>
    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true">
    <path d="M16 3.75v8.5a.75.75 0 0 1-1.136.643L11 10.575v.675A1.75 1.75 0 0 1 9.25 13h-7.5A1.75 1.75 0 0 1 0 11.25v-6.5C0 3.784.784 3 1.75 3h7.5c.966 0 1.75.784 1.75 1.75v.675l3.864-2.318A.75.75 0 0 1 16 3.75Zm-6.5 1a.25.25 0 0 0-.25-.25h-7.5a.25.25 0 0 0-.25.25v6.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-6.5ZM11 8.825l3.5 2.1v-5.85l-3.5 2.1Z"></path>
</svg>
    <span aria-label="Video description llama.vim-0-lq.mp4">llama.vim-0-lq.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/1991296/378408916-1f1eb408-8ac2-4bd2-b2cf-6ab7d6816754.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc3MDcxNjMsIm5iZiI6MTczNzcwNjg2MywicGF0aCI6Ii8xOTkxMjk2LzM3ODQwODkxNi0xZjFlYjQwOC04YWMyLTRiZDItYjJjZi02YWI3ZDY4MTY3NTQubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MDEyNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTAxMjRUMDgyMTAzWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ZGVmM2Q5MzQ3YjY1OGJhNTE0MzZiM2ZlYjMyMzZkNzU2OWI2OTJiMjhiM2UzMTJkOTdiOGYyZmNjOWFjZGMyOSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.eOyXkrdmA5a4yAGID370AOOiF1LobfQFHzIiRA9tJfQ" data-canonical-src="https://private-user-images.githubusercontent.com/1991296/378408916-1f1eb408-8ac2-4bd2-b2cf-6ab7d6816754.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzc3MDcxNjMsIm5iZiI6MTczNzcwNjg2MywicGF0aCI6Ii8xOTkxMjk2LzM3ODQwODkxNi0xZjFlYjQwOC04YWMyLTRiZDItYjJjZi02YWI3ZDY4MTY3NTQubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI1MDEyNCUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNTAxMjRUMDgyMTAzWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9ZGVmM2Q5MzQ3YjY1OGJhNTE0MzZiM2ZlYjMyMzZkNzU2OWI2OTJiMjhiM2UzMTJkOTdiOGYyZmNjOWFjZGMyOSZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.eOyXkrdmA5a4yAGID370AOOiF1LobfQFHzIiRA9tJfQ" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto">Demonstrates that the global context is accumulated and maintained across different files and showcases the overall latency when working in a large codebase.</p>

<p dir="auto">The plugin aims to be very simple and lightweight and at the same time to provide high-quality and performant local FIM completions, even on consumer-grade hardware. Read more on how this is achieved in the following links:</p>
<ul dir="auto">
<li>Initial implementation and techincal description: <a data-error-text="Failed to load title" data-id="2572915687" data-permission-text="Title is private" data-url="https://github.com/ggerganov/llama.cpp/issues/9787" data-hovercard-type="pull_request" data-hovercard-url="/ggerganov/llama.cpp/pull/9787/hovercard" href="https://github.com/ggerganov/llama.cpp/pull/9787">ggerganov/llama.cpp#9787</a></li>
<li>Classic Vim support: <a data-error-text="Failed to load title" data-id="2604384087" data-permission-text="Title is private" data-url="https://github.com/ggerganov/llama.cpp/issues/9995" data-hovercard-type="pull_request" data-hovercard-url="/ggerganov/llama.cpp/pull/9995/hovercard" href="https://github.com/ggerganov/llama.cpp/pull/9995">ggerganov/llama.cpp#9995</a></li>
</ul>

<ul dir="auto">
<li>VS Code: <a href="https://github.com/ggml-org/llama.vscode">https://github.com/ggml-org/llama.vscode</a></li>
</ul>
</article></div></div>
  </body>
</html>
