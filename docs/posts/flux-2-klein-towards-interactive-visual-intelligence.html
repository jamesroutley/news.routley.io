<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://bfl.ai/blog/flux2-klein-towards-interactive-visual-intelligence">Original</a>
    <h1>FLUX.2 [Klein]: Towards Interactive Visual Intelligence</h1>
    
    <div id="readability-page-1" class="page"><div><h2><strong>FLUX.2 [klein]: Towards Interactive Visual Intelligence</strong></h2><p>Today, we release the FLUX.2 [klein] model family, our fastest image models to date. FLUX.2 [klein] unifies generation and editing in a single compact architecture, delivering state-of-the-art quality with end-to-end inference as low as under a second. Built for applications that require real-time image generation without sacrificing quality, and runs on consumer hardware with as little as 13GB VRAM.</p><p><a target="_blank" rel="noindex nofollow" href="https://bfl.ai/models/flux-2-klein#try-demo"><strong><span>Try it now for free here</span></strong></a></p><p><img alt="" draggable="false" loading="lazy" width="1280" height="720" decoding="async" data-nimg="1" srcset="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F2gpum2i6%2Fproduction%2F2bd2ec8704480a772cf35f1017ffb8488aab630c-1280x720.gif&amp;w=1920&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F2gpum2i6%2Fproduction%2F2bd2ec8704480a772cf35f1017ffb8488aab630c-1280x720.gif&amp;w=3840&amp;q=75 2x" src="https://liquidbrain.net/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F2gpum2i6%2Fproduction%2F2bd2ec8704480a772cf35f1017ffb8488aab630c-1280x720.gif&amp;w=3840&amp;q=75"/></p><p><em>Demo showing editing with FLUX.2 [klein]</em></p><h3><strong>Why go [klein]?</strong></h3><p>Visual Intelligence is entering a new era. As AI agents become more capable, they need visual generation that can keep up; models that respond in real-time, iterate quickly, and run efficiently on accessible hardware.</p><p>The <em>klein</em> name comes from the German word for &#34;small&#34;, reflecting both the compact model size and the minimal latency. But FLUX.2 [klein] is anything but limited. These models deliver exceptional performance in text-to-image generation, image editing and multi-reference generation, typically reserved for much larger models.</p><h3><strong>What&#39;s New</strong></h3><ul><li><span>Sub-second inference. Generate or edit images in under 0.5s on modern hardware.</span></li><li><span>Photorealistic outputs and high diversity, especially in the base variants.</span></li><li><span>Unified generation and editing. Text-to-image, image editing, and multi-reference support in a single model while delivering frontier performance.</span></li><li><span>Runs on consumer GPUs. The 4B model fits in ~13GB VRAM (RTX 3090/4070 and above).</span></li><li><span>Developer-friendly &amp; Accessible: Apache 2.0 on 4B models, open weights for 9B models. Full open weights for customization and fine-tuning.</span></li><li><span>API and open weights. Production-ready API or run locally with full weights.</span></li></ul><p><em>Note: The “FLUX [dev] Non-Commercial License” has been renamed to “FLUX Non-Commercial License” and will apply to the 9B Klein models. No material changes have been made to the license.</em></p><p><img alt="" draggable="false" loading="lazy" width="2127" height="1400" decoding="async" data-nimg="1" srcset="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F2gpum2i6%2Fproduction%2F41055678178f6fe75ca618b854b195e48dfc55ed-2127x1400.jpg&amp;w=3840&amp;q=75 1x" src="https://liquidbrain.net/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F2gpum2i6%2Fproduction%2F41055678178f6fe75ca618b854b195e48dfc55ed-2127x1400.jpg&amp;w=3840&amp;q=75"/></p><p><em>Text to Image collage using FLUX.2 [klein]</em></p><h3><strong>The FLUX.2 [klein] Model Family</strong></h3><h4><strong>FLUX.2 [klein] 9B</strong></h4><p>Our flagship small model. Defines the Pareto frontier for quality vs. latency across text-to-image, single-reference editing, and multi-reference generation. Matches or exceeds models 5x its size - in under half a second. Built on a 9B flow model with 8B Qwen3 text embedder, step-distilled to 4 inference steps.</p><p>Combine multiple input images, blend concepts, and iterate on complex compositions - all at sub-second speed with frontier-level quality. No model this fast has ever done this well.</p><p><strong>License</strong>: FLUX NCL</p><p><img alt="" draggable="false" loading="lazy" width="4544" height="2805" decoding="async" data-nimg="1" srcset="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F2gpum2i6%2Fproduction%2F86adb8bf9ea077f3aebe392af1077f0337ed9c48-4544x2805.jpg&amp;w=3840&amp;q=75 1x" src="https://liquidbrain.net/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F2gpum2i6%2Fproduction%2F86adb8bf9ea077f3aebe392af1077f0337ed9c48-4544x2805.jpg&amp;w=3840&amp;q=75"/></p><p><em>Imagine editing collage using FLUX.2 [klein]</em></p><h4><strong></strong></h4><p>Fully open under Apache 2.0. Our most accessible model, it runs on consumer GPUs like the RTX 3090/4070. Compact but capable: supports T2I, I2I, and multi-reference at quality that punches above its size. Built for local development and edge deployment.</p><p><strong>License</strong>: Apache 2.0<br/></p><h4><strong>FLUX.2 [klein] Base 9B / 4B:</strong></h4><p>The full-capacity foundation models. Undistilled, preserving complete training signal for maximum flexibility. Ideal for fine-tuning, LoRA training, research, and custom pipelines where control matters more than speed. Higher output diversity than the distilled models.</p><p><strong>License</strong>: 4B Base under Apache 2.0, 9B Base under FLUX NCL</p><p><img alt="" draggable="false" loading="lazy" width="2127" height="1400" decoding="async" data-nimg="1" srcset="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F2gpum2i6%2Fproduction%2F900de0722995119df9f27d799bdfed194d2112ac-2127x1400.jpg&amp;w=3840&amp;q=75 1x" src="https://liquidbrain.net/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F2gpum2i6%2Fproduction%2F900de0722995119df9f27d799bdfed194d2112ac-2127x1400.jpg&amp;w=3840&amp;q=75"/></p><p><em>Output Diversity using FLUX.2 [klein]<br/></em></p><h4><strong>Quantized versions</strong></h4><p>We are also releasing FP8 and NVFP4 versions of all [klein] variants, developed in collaboration with NVIDIA for optimized inference on RTX GPUs. Same capabilities, smaller footprint - compatible with even more hardware.</p><ul><li><span><strong>FP8:</strong> Up to 1.6x faster, up to 40% less VRAM</span></li><li><span><strong>NVFP4:</strong> Up to 2.7x faster, up to 55% less VRAM</span></li></ul><p><em>Benchmarks on RTX 5080/5090, T2I at 1024×1024<br/></em>Same licenses apply: Apache 2.0 for 4B variants, FLUX NCL for 9B.</p><h4><strong></strong></h4><p><img alt="" draggable="false" loading="lazy" width="3548" height="1173" decoding="async" data-nimg="1" srcset="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F2gpum2i6%2Fproduction%2F8ece18115cc75a4d34c42eda81a68bbd78048666-3548x1173.jpg&amp;w=3840&amp;q=75 1x" src="https://liquidbrain.net/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F2gpum2i6%2Fproduction%2F8ece18115cc75a4d34c42eda81a68bbd78048666-3548x1173.jpg&amp;w=3840&amp;q=75"/></p><p><img alt="" draggable="false" loading="lazy" width="3541" height="1173" decoding="async" data-nimg="1" srcset="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F2gpum2i6%2Fproduction%2Fc29dea8ec862d79ecdc82e8013f37ee22a148cb8-3541x1173.jpg&amp;w=3840&amp;q=75 1x" src="https://liquidbrain.net/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2F2gpum2i6%2Fproduction%2Fc29dea8ec862d79ecdc82e8013f37ee22a148cb8-3541x1173.jpg&amp;w=3840&amp;q=75"/></p><p><strong><em>FLUX.2 [klein] Elo vs Latency (top) and VRAM (bottom) across Text-to-Image, Image-to-Image Single Reference, and Multi-Reference tasks.</em></strong> <em>FLUX.2 [klein] matches or exceeds Qwen&#39;s quality at a fraction of the latency and VRAM, and outperforms Z-Image while supporting both text-to-image generation and (multi-reference) image editing in a unified model. The base variants trade some speed for full customizability and fine-tuning, making them better suited for research and adaptation to specific use cases. Speed is measured on a GB200 in bf16.</em></p><h3><strong>Into the New</strong></h3><p>FLUX.2 [klein] is more than a faster model. It&#39;s a step toward our vision of interactive visual intelligence. We believe the future belongs to creators and developers with AI that can see, create, and iterate in real-time. Systems that enable new categories of applications: real-time design tools, agentic visual reasoning, interactive content creation.</p><h3><strong>Resources</strong></h3><p><strong>Try it</strong></p><ul><li><span><a target="_blank" rel="noindex nofollow" href="https://bfl.ai/models/flux-2-klein#try-demo">Demo</a></span></li><li><span><a target="_blank" rel="noindex nofollow" href="https://bfl.ai/play">Playground</a></span></li><li><span><a target="_blank" rel="noindex nofollow" href="https://huggingface.co/spaces/black-forest-labs/FLUX.2-klein-9B">HF Space for [klein] 9B</a>, <a target="_blank" rel="noindex nofollow" href="https://huggingface.co/spaces/black-forest-labs/FLUX.2-klein-4B">HF Space for [klein] 4B</a></span></li></ul><p><strong>Build with it</strong></p><ul><li><span><a target="_blank" rel="noindex nofollow" href="https://docs.bfl.ai/flux_2/flux2_overview#flux-2-%5Bklein%5D-models">Documentation</a></span></li><li><span><a target="_blank" rel="noindex nofollow" href="https://github.com/black-forest-labs/flux2">GitHub</a></span></li><li><span><a target="_blank" rel="noindex nofollow" href="https://huggingface.co/collections/black-forest-labs/flux2">Model Weights</a></span></li></ul><p><strong>Learn more</strong></p><ul><li><span><a target="_blank" rel="noindex nofollow" href="https://bfl.ai/models/flux-2-klein">https://bfl.ai/models/flux-2-klein</a></span></li></ul></div></div>
  </body>
</html>
