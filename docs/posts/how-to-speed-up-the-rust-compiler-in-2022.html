<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://nnethercote.github.io/2022/02/25/how-to-speed-up-the-rust-compiler-in-2022.html">Original</a>
    <h1>How to speed up the Rust compiler in 2022</h1>
    
    <div id="readability-page-1" class="page"><div aria-label="Content">
      <div>
        <article itemscope="" itemtype="http://schema.org/BlogPosting">

  

  <div itemprop="articleBody">
    <p>Between 2016 and 2020 I wrote a series of blog posts called <a href="https://blog.mozilla.org/nnethercote/2020/09/08/how-to-speed-up-the-rust-compiler-one-last-time/">“How to speed up
the Rust
compiler”</a>.
These were mostly about my work on the Rust compiler, plus some updates on the
progress on the Rust compiler’s speed in general.</p>

<p>I am now back on the Rust bandwagon as a member of Futurewei’s Rust team, and
it’s time to start up the blog series again.</p>

<h2 id="successes">Successes</h2>

<p>In the past few months I have landed some PRs that improved things.</p>

<p><a href="https://github.com/rust-lang/rust/pull/90746">#90746</a>: This PR changed a hot
but non-critical <code>assert!</code> to a <code>debug_assert!</code>, meaning it isn’t run in
release builds, for wins of up to 5% on two benchmarks.</p>

<p><a href="https://github.com/rust-lang/rust/pull/91246">#91246</a>: <code>Layout::array</code> is a
function, involved with vector growth, that is instantiated frequently. This PR
made it more concise, reducing the amount of generated LLVM IR, and reducing
compile times by up to 4% on a few benchmarks, with sub-1% improvements on lots
of benchmarks, though the results were a bit noisy.</p>

<p><a href="https://github.com/rust-lang/rust/pull/91844/">#91844</a>: This PR eliminated the
<code>ObligationCauseData</code> structure, reducing allocation rates, for some sub-1%
wins in lots of benchmarks.</p>

<p><a href="https://github.com/rust-lang/hashbrown/pull/305">hashbrown #305</a>: rustc uses
hash tables heavily, and I discovered that approximately one third of all
non-modifying hash table lookups are on an empty table! <code>hashbrown</code> would
nonetheless hash the inputs and perform a normal lookup in the case. This PR
changed it to fail immediately if the table is empty, for one win of 11% and
lots in the 1-4% range. This change was later merged into rustc as part of the
<code>hashbrown</code> update in
<a href="https://github.com/rust-lang/rust/pull/92998">#92998</a>.</p>

<p><a href="https://github.com/rust-lang/rust/pull/91948">#91948</a>: This PR, co-authored
with <a href="https://github.com/camelid">camelid</a>, avoided lots of allocations in
rustdoc caused by symbol-to-string conversions, for good wins across all
rustdoc benchmarks of up to 5%.</p>

<p><a href="https://github.com/rust-lang/rust/pull/92604">#92604</a>: This PR optimized
LEB128 reading during metadata encoding (yet
<a href="https://github.com/rust-lang/rust/pull/69050">again</a>) for wins of up to 3%
across many benchmarks.</p>

<p><a href="https://github.com/rust-lang/rust/pull/93066">#93066</a>: The <code>Decoder</code> trait
used for metadata decoding was fallible, using <code>Result</code> throughout. But
decoding failures should only happen if something highly unexpected happens
(e.g. metadata is corrupted) and on failure the calling code would just abort.
This PR changed <code>Decoder</code> to be infallible throughout—panicking immediately
instead of panicking slightly later—thus avoiding lots of pointless <code>Result</code>
propagation, for wins across many benchmarks of up to 2%.</p>

<p><a href="https://github.com/rust-lang/rust/pull/93148">#93148</a>: rustc uses
<a href="https://en.wikipedia.org/wiki/String_interning">interning</a> pervasively, for
strings and many other internal types. Interned types are guaranteed unique and
can be compared and hashed cheaply (by considering just the pointer, rather
than the contents), but some of the interned types weren’t taking advantage of
that. This large PR overhauled the types used for interning so they were more
consistent, for wins across many benchmarks of up to 4%.</p>

<h2 id="failures">Failures</h2>

<p>But not everything I tried worked.</p>

<ul>
  <li>I tried to speed up lexing for the <a href="https://github.com/rust-lang/rustc-perf/blob/master/collector/benchmarks/externs/src/lib.rs"><code>externs</code> stress
test</a>
by changing the handling of the first char in new tokens, but it didn’t help.</li>
  <li>I tried shrinking various arena-allocated types, such as <code>Ty</code> and
<code>Predicate</code>, but it didn’t help enough to be worth the effort.</li>
  <li>I drafted a dead store elimination optimization pass for MIR, inspired by the
presence of obviously redundant code relating to drop flags. It worked, but
the measurable performance benefits were negligible, and not worth the extra
code.</li>
  <li>I tried various ways to improve the representation of vectors use with
<code>ast::PathSeg</code> and <code>AttrVec</code>, without success.</li>
  <li>I tried to <a href="https://github.com/rust-lang/rust/pull/72013">further</a> optimize
code relating to vector growth to minimize LLVM IR generation, but
<a href="https://github.com/rust-lang/rust/pull/91848">failed</a> to do it in a way that
didn’t reduce the speed of the compiled code.</li>
  <li>I tried changing the minimum capacity of non-empty Hash tables from 3 to 7.
This gave some small (1-2%) performance wins, but increased peak memory usage
by more (5-10%) and so wasn’t worth it.</li>
  <li>I tried <a href="https://nnethercote.github.io/2021/12/08/a-brutally-effective-hash-function-in-rust.html">numerous
things</a>
to improve the <code>FxHasher</code> algorithm used by rustc’s hash tables, without
success.</li>
  <li>I tried increasing the buffer size used by <code>StableHasher</code>, which is used
with incremental compilation, but caused a slight performance regression.</li>
  <li>I tried some tweaks with interning: pre-interning some common interned
values, caching some recently interned values, and avoiding a double lookup
when interning symbols. None of them helped.</li>
  <li>I tried speeding up <code>find_library_crate</code> and failed, though some 
clean-ups I did along the way <a href="https://github.com/rust-lang/rust/pull/93608">were
merged</a>.</li>
  <li>I tried tweaking how <code>TypeFoldable</code>/<code>TypeFolder</code>/<code>TypeVisitor</code> work, without
success, though it did lead to some <a href="https://github.com/rust-lang/rust/pull/93758">better
documentation</a>.</li>
  <li>I tried a bunch of things to get jemalloc to provide accurate actual sizes of
allocated blocks, without success. (The design of various Rust and jemalloc
API boundaries made this task more difficult than I would have liked.) I also
experimented with jemalloc’s “sized deallocation” feature, which several
people assured me would be a win, but it slowed things down. The way jemalloc
is hooked into rustc is quite messy and at least I was able to <a href="https://github.com/rust-lang/rust/pull/92222">clarify it a
little</a>.</li>
</ul>

<p>You can see that I had more failures than successes. Finding performance wins
is a lot harder than it used to be. Much of the low-hanging fruit has been
plucked, and my success rate is down. Running the usual profilers on the <a href="https://github.com/rust-lang/rustc-perf/tree/master/collector/benchmarks">usual
benchmarks</a>
(and only measuring the final crate of each benchmark, not the whole
compilation graph) is less effective than before.</p>

<p>So what now?</p>

<h2 id="next-steps">Next steps</h2>

<p>Fortunately, there is a path forward. <a href="https://github.com/lqd/">lqd</a> recently
started working full-time on compiler performance, and he did a <a href="https://github.com/lqd/rustc-benchmarking-data">large data
gathering exercise</a>, running a
variety of profilers across almost 800 of the most popular crates on
<a href="https://crates.io/">crates.io</a>. This included both intra-crate and
cross-project measurements. The results give us insight into compiler
performance across a much larger range of real-world code than the benchmark
suite, which has 46 benchmarks, only half of which are derived from real-world
crates.</p>

<p>I have written <a href="https://hackmd.io/mxdn4U58Su-UQXwzOHpHag?view">an analysis</a> of
the gathered data, pulling out interesting findings. Things like:</p>
<ul>
  <li>Some parts of the compiler are hot for some crates, but these don’t show up
in the existing benchmarks. Macro parsing is the most extreme example, and
looks likely to be quite optimizable.</li>
  <li>Certain crates are both widely used and slow to compile, such as
<code>syn</code>/<code>quote</code>/<code>proc-macro2</code>. Can they be improved?</li>
  <li>Even trivial build scripts seem surprisingly slow to compile. Why is that?</li>
  <li>Our benchmark suite has versions of numerous popular crates that are 3 or 4
years old. We should update them, and possibly add/remove some.</li>
  <li>Cargo’s scheduling may have room for improvement.</li>
</ul>

<p>This analysis has informed a
<a href="https://hackmd.io/YJQSj_nLSZWl2sbI84R1qA?view">roadmap</a> for compiler
performance work in 2022. I finished the draft analysis and roadmap documents
just yesterday, but they are already bearing fruit…</p>

<p><a href="https://github.com/rust-lang/rust/pull/93984/">#93984</a>: This PR introduced an
optimized representation for large bitsets, which greatly reduces the peak
memory requirements for a few crates (by up to 60%!), and also avoids a lot of
memory copying, for speed wins of up to 14%. Pleasingly, this fixed the 
<a href="https://github.com/rust-lang/rust/issues/54208">final outstanding performance
regression</a> from the
introduction of the “new” borrow checker back in 2018!</p>

<p><a href="https://github.com/rust-lang/rust/pull/94316">#94316</a>: This PR optimized the
processing of string literals containing escapes, for up to 7% wins on a few
popular crates.</p>

<p>I am hopeful that this new roadmap will lead to more sizeable improvements like
these.</p>

<h2 id="general-progress">General progress</h2>

<p>From the period <a href="https://perf.rust-lang.org/compare.html?start=2021-11-11&amp;end=2022-02-25&amp;stat=wall-time">2021-11-11 to
2022-02-25</a>
there were 303 improvements to the results of the rustc benchmark suite, many
of which were over 10%, and only 21 regressions, as the following screenshot
summarizes.</p>

<p><img src="https://nnethercote.github.io/images/2022/02/25/rustc-perf-wall-time-2021-11-11-to-2022-02-25.png" alt="rustc-perf wall-time 2021-11-11 to 2022-02-25"/></p>

<p>For rustc developers there was the additional nice result that rustc bootstrap
times dropped by 10%.</p>

<p>This is a healthy result for this 3.5 month period. It is due to the efforts of
many people, and continues the long trend of performance improvements.</p>

  </div>
</article>

      </div>
    </div></div>
  </body>
</html>
