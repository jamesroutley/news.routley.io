<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/antirez/flux2.c">Original</a>
    <h1>Flux 2 Klein pure C inference</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto">This program generates images from text prompts (and optionally from other images) using the FLUX.2-klein-4B model from Black Forest Labs. It can be used as a library as well, and is implemented entirely in C, with zero external dependencies beyond the C standard library. MPS and BLAS acceleration are optional but recommended.</p>
<div dir="auto"><h2 tabindex="-1" dir="auto">An experiment in AI code generation and open source software</h2><a id="user-content-an-experiment-in-ai-code-generation-and-open-source-software" aria-label="Permalink: An experiment in AI code generation and open source software" href="#an-experiment-in-ai-code-generation-and-open-source-software"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">I (the human here, Salvatore) wanted to test code generation with a more ambitious task, over the weekend. This is the result. It is my first open source project where I wrote zero lines of code. I believe that inference systems not using the Python stack (which I do not appreciate) are a way to free open models usage and make AI more accessible. There is already a project <a href="https://github.com/leejet/stable-diffusion.cpp">doing the inference of diffusion models in C / C++</a> that supports multiple models, and is based on GGML. I wanted to see if, with the assistance of modern AI, I could reproduce this work in a more concise way, from scratch, in a weekend. Looks like it is possible.</p>
<p dir="auto">This code base was written with Claude Code, using the Claude Max plan, the small one of ~80 euros per month. I almost reached the limits but this plan was definitely sufficient for such a large task, which was surprising. In order to simplify the usage of this software, no quantization is used, nor do you need to convert the model. It runs directly with the safetensors model as input, using floats.</p>
<p dir="auto">Even if the code was generated using AI, my help in steering towards the right design, implementation choices, and correctness has been vital during the development. I learned quite a few things about working with non trivial projects and AI.</p>

<div dir="auto" data-snippet-clipboard-copy-content="# Build (choose your backend)
make mps       # Apple Silicon (fastest)
# or: make blas    # Intel Mac / Linux with OpenBLAS
# or: make generic # Pure C, no dependencies

# Download the model (~16GB)
pip install huggingface_hub
python download_model.py

# Generate an image
./flux -d flux-klein-model -p &#34;A woman wearing sunglasses&#34; -o output.png"><pre><span><span>#</span> Build (choose your backend)</span>
make mps       <span><span>#</span> Apple Silicon (fastest)</span>
<span><span>#</span> or: make blas    # Intel Mac / Linux with OpenBLAS</span>
<span><span>#</span> or: make generic # Pure C, no dependencies</span>

<span><span>#</span> Download the model (~16GB)</span>
pip install huggingface_hub
python download_model.py

<span><span>#</span> Generate an image</span>
./flux -d flux-klein-model -p <span><span>&#34;</span>A woman wearing sunglasses<span>&#34;</span></span> -o output.png</pre></div>
<p dir="auto">That&#39;s it. No Python runtime, no PyTorch, no CUDA toolkit required at inference time.</p>

<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/antirez/flux2.c/blob/main/images/woman_with_sunglasses.png"><img src="https://github.com/antirez/flux2.c/raw/main/images/woman_with_sunglasses.png" alt="Woman with sunglasses"/></a></p>
<p dir="auto"><em>Generated with: <code>./flux -d flux-klein-model -p &#34;A picture of a woman in 1960 America. Sunglasses. ASA 400 film. Black and White.&#34; -W 250 -H 250 -o /tmp/woman.png</code>, and later processed with image to image generation via <code>./flux -d flux-klein-model -i /tmp/woman.png -o /tmp/woman2.png -p &#34;oil painting of woman with sunglasses&#34; -v -H 256 -W 256</code></em></p>

<ul dir="auto">
<li><strong>Zero dependencies</strong>: Pure C implementation, works standalone. BLAS optional for ~30x speedup (Apple Accelerate on macOS, OpenBLAS on Linux)</li>
<li><strong>Metal GPU acceleration</strong>: Automatic on Apple Silicon Macs</li>
<li><strong>Text-to-image</strong>: Generate images from text prompts</li>
<li><strong>Image-to-image</strong>: Transform existing images guided by prompts</li>
<li><strong>Integrated text encoder</strong>: Qwen3-4B encoder built-in, no external embedding computation needed</li>
<li><strong>Memory efficient</strong>: Automatic encoder release after encoding (~8GB freed)</li>
<li><strong>Low memory mode</strong>: <code>--mmap</code> flag enables on-demand weight loading, reducing peak memory from ~16GB to ~4-5GB for 16GB RAM systems</li>
</ul>


<div dir="auto" data-snippet-clipboard-copy-content="./flux -d flux-klein-model -p &#34;A fluffy orange cat sitting on a windowsill&#34; -o cat.png"><pre>./flux -d flux-klein-model -p <span><span>&#34;</span>A fluffy orange cat sitting on a windowsill<span>&#34;</span></span> -o cat.png</pre></div>

<p dir="auto">Transform an existing image based on a prompt:</p>
<div dir="auto" data-snippet-clipboard-copy-content="./flux -d flux-klein-model -p &#34;oil painting style&#34; -i photo.png -o painting.png -t 0.7"><pre>./flux -d flux-klein-model -p <span><span>&#34;</span>oil painting style<span>&#34;</span></span> -i photo.png -o painting.png -t 0.7</pre></div>
<p dir="auto">The <code>-t</code> (strength) parameter controls how much the image changes:</p>
<ul dir="auto">
<li><code>0.0</code> = no change (output equals input)</li>
<li><code>1.0</code> = full generation (input only provides composition hint)</li>
<li><code>0.7</code> = good balance for style transfer</li>
</ul>

<p dir="auto"><strong>Required:</strong></p>
<div data-snippet-clipboard-copy-content="-d, --dir PATH        Path to model directory
-p, --prompt TEXT     Text prompt for generation
-o, --output PATH     Output image path (.png or .ppm)"><pre><code>-d, --dir PATH        Path to model directory
-p, --prompt TEXT     Text prompt for generation
-o, --output PATH     Output image path (.png or .ppm)
</code></pre></div>
<p dir="auto"><strong>Generation options:</strong></p>
<div data-snippet-clipboard-copy-content="-W, --width N         Output width in pixels (default: 256)
-H, --height N        Output height in pixels (default: 256)
-s, --steps N         Sampling steps (default: 4)
-S, --seed N          Random seed for reproducibility"><pre><code>-W, --width N         Output width in pixels (default: 256)
-H, --height N        Output height in pixels (default: 256)
-s, --steps N         Sampling steps (default: 4)
-S, --seed N          Random seed for reproducibility
</code></pre></div>
<p dir="auto"><strong>Image-to-image options:</strong></p>
<div data-snippet-clipboard-copy-content="-i, --input PATH      Input image for img2img
-t, --strength N      How much to change the image, 0.0-1.0 (default: 0.75)"><pre><code>-i, --input PATH      Input image for img2img
-t, --strength N      How much to change the image, 0.0-1.0 (default: 0.75)
</code></pre></div>
<p dir="auto"><strong>Output options:</strong></p>
<div data-snippet-clipboard-copy-content="-q, --quiet           Silent mode, no output
-v, --verbose         Show detailed config and timing info"><pre><code>-q, --quiet           Silent mode, no output
-v, --verbose         Show detailed config and timing info
</code></pre></div>
<p dir="auto"><strong>Other options:</strong></p>
<div data-snippet-clipboard-copy-content="-m, --mmap            Low memory mode (load weights on-demand, slower)
-e, --embeddings PATH Load pre-computed text embeddings (advanced)
-h, --help            Show help"><pre><code>-m, --mmap            Low memory mode (load weights on-demand, slower)
-e, --embeddings PATH Load pre-computed text embeddings (advanced)
-h, --help            Show help
</code></pre></div>

<p dir="auto">The seed is always printed to stderr, even when random:</p>
<div data-snippet-clipboard-copy-content="$ ./flux -d flux-klein-model -p &#34;a landscape&#34; -o out.png
Seed: 1705612345
out.png"><pre><code>$ ./flux -d flux-klein-model -p &#34;a landscape&#34; -o out.png
Seed: 1705612345
out.png
</code></pre></div>
<p dir="auto">To reproduce the same image, use the printed seed:</p>
<div data-snippet-clipboard-copy-content="$ ./flux -d flux-klein-model -p &#34;a landscape&#34; -o out.png -S 1705612345"><pre><code>$ ./flux -d flux-klein-model -p &#34;a landscape&#34; -o out.png -S 1705612345
</code></pre></div>

<p dir="auto">Choose a backend when building:</p>
<div dir="auto" data-snippet-clipboard-copy-content="make            # Show available backends
make generic    # Pure C, no dependencies (slow)
make blas       # BLAS acceleration (~30x faster)
make mps        # Apple Silicon Metal GPU (fastest, macOS only)"><pre>make            <span><span>#</span> Show available backends</span>
make generic    <span><span>#</span> Pure C, no dependencies (slow)</span>
make blas       <span><span>#</span> BLAS acceleration (~30x faster)</span>
make mps        <span><span>#</span> Apple Silicon Metal GPU (fastest, macOS only)</span></pre></div>
<p dir="auto"><strong>Recommended:</strong></p>
<ul dir="auto">
<li>macOS Apple Silicon: <code>make mps</code></li>
<li>macOS Intel: <code>make blas</code></li>
<li>Linux with OpenBLAS: <code>make blas</code></li>
<li>Linux without OpenBLAS: <code>make generic</code></li>
</ul>
<p dir="auto">For <code>make blas</code> on Linux, install OpenBLAS first:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Ubuntu/Debian
sudo apt install libopenblas-dev

# Fedora
sudo dnf install openblas-devel"><pre><span><span>#</span> Ubuntu/Debian</span>
sudo apt install libopenblas-dev

<span><span>#</span> Fedora</span>
sudo dnf install openblas-devel</pre></div>
<p dir="auto">Other targets:</p>
<div dir="auto" data-snippet-clipboard-copy-content="make clean      # Clean build artifacts
make info       # Show available backends for this platform
make test       # Run reference image test"><pre>make clean      <span><span>#</span> Clean build artifacts</span>
make info       <span><span>#</span> Show available backends for this platform</span>
make <span>test</span>       <span><span>#</span> Run reference image test</span></pre></div>

<p dir="auto">The model weights are downloaded from HuggingFace:</p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install huggingface_hub
python download_model.py"><pre>pip install huggingface_hub
python download_model.py</pre></div>
<p dir="auto">This downloads approximately 16GB to <code>./flux-klein-model</code>:</p>
<ul dir="auto">
<li>VAE (~300MB)</li>
<li>Transformer (~4GB)</li>
<li>Qwen3-4B Text Encoder (~8GB)</li>
<li>Tokenizer</li>
</ul>


<p dir="auto"><strong>FLUX.2-klein-4B</strong> is a rectified flow transformer optimized for fast inference:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Component</th>
<th>Architecture</th>
</tr>
</thead>
<tbody>
<tr>
<td>Transformer</td>
<td>5 double blocks + 20 single blocks, 3072 hidden dim, 24 attention heads</td>
</tr>
<tr>
<td>VAE</td>
<td>AutoencoderKL, 128 latent channels, 8x spatial compression</td>
</tr>
<tr>
<td>Text Encoder</td>
<td>Qwen3-4B, 36 layers, 2560 hidden dim</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><strong>Inference steps</strong>: This is a distilled model that produces good results with exactly 4 sampling steps.</p>

<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Phase</th>
<th>Memory</th>
</tr>
</thead>
<tbody>
<tr>
<td>Text encoding</td>
<td>~8GB (encoder weights)</td>
</tr>
<tr>
<td>Diffusion</td>
<td>~8GB (transformer ~4GB + VAE ~300MB + activations)</td>
</tr>
<tr>
<td>Peak</td>
<td>~16GB (if encoder not released)</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">The text encoder is automatically released after encoding, reducing peak memory during diffusion. If you generate multiple images with different prompts, the encoder reloads automatically.</p>

<p dir="auto">For systems with limited RAM (16GB or less), the <code>--mmap</code> flag enables memory-mapped weight loading:</p>
<div dir="auto" data-snippet-clipboard-copy-content="./flux -d flux-klein-model -p &#34;A cat&#34; -o cat.png --mmap"><pre>./flux -d flux-klein-model -p <span><span>&#34;</span>A cat<span>&#34;</span></span> -o cat.png --mmap</pre></div>
<p dir="auto"><strong>How it works:</strong> Instead of loading all model weights into RAM upfront, <code>--mmap</code> keeps the safetensors files memory-mapped and loads weights on-demand:</p>
<ul dir="auto">
<li><strong>Text encoder (Qwen3):</strong> Each of the 36 transformer layers (~400MB each) is loaded, processed, and immediately freed. Only ~2GB stays resident instead of ~8GB.</li>
<li><strong>Denoising transformer:</strong> Each of the 5 double-blocks (~300MB) and 20 single-blocks (~150MB) is loaded on-demand and freed after use. Only ~200MB of shared weights stays resident instead of ~4GB.</li>
</ul>
<p dir="auto">This reduces peak memory from ~16GB to ~4-5GB, making inference possible on systems with only 16GB of RAM (tested on Linux).</p>
<p dir="auto"><strong>Backend compatibility:</strong></p>
<ul dir="auto">
<li><code>make generic</code> - Works</li>
<li><code>make blas</code> - Works</li>
<li><code>make mps</code> - Works, but less beneficial since MPS already uses bf16 weights on GPU (no expansion to float32), so memory pressure is lower</li>
</ul>
<p dir="auto"><strong>Trade-off:</strong> Inference is slower with <code>--mmap</code> due to repeated disk I/O and weight conversion. Use it only when you don&#39;t have enough RAM for normal operation.</p>

<p dir="auto">Benchmarks on <strong>Apple M3 Max</strong> (128GB RAM), generating a 4-step image.</p>
<p dir="auto"><strong>Important:</strong> Previous benchmarks in this README were misleading - they compared C timings (which included model loading) against PyTorch timings (which excluded loading and used warmup runs). The table below shows fair &#34;cold start&#34; benchmarks where all implementations include model loading time and no warmup:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Size</th>
<th>C (MPS)</th>
<th>C (BLAS)</th>
<th>PyTorch (MPS)</th>
</tr>
</thead>
<tbody>
<tr>
<td>256x256</td>
<td>22s</td>
<td>24s</td>
<td>11s</td>
</tr>
<tr>
<td>512x512</td>
<td>30s</td>
<td>44s</td>
<td>13s</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><strong>Notes:</strong></p>
<ul dir="auto">
<li>All times measured with <code>time</code> command (wall clock), including model loading, no warmup.</li>
<li>The C implementation uses float32 throughout, while PyTorch uses bfloat16 with highly optimized MPS kernels.</li>
<li>PyTorch benefits from keeping activations on GPU between operations; the C implementation currently transfers data between CPU and GPU for each operation.</li>
<li>The <code>make generic</code> backend (pure C, no BLAS) is approximately 30x slower than BLAS and not included in benchmarks.</li>
</ul>

<p dir="auto"><strong>Maximum resolution</strong>: 1024x1024 pixels. Higher resolutions require prohibitive memory for the attention mechanisms.</p>
<p dir="auto"><strong>Minimum resolution</strong>: 64x64 pixels.</p>
<p dir="auto">Dimensions should be multiples of 16 (the VAE downsampling factor).</p>

<p dir="auto">The library can be integrated into your own C/C++ projects. Link against <code>libflux.a</code> and include <code>flux.h</code>.</p>

<p dir="auto">Here&#39;s a complete program that generates an image from a text prompt:</p>
<div dir="auto" data-snippet-clipboard-copy-content="#include &#34;flux.h&#34;
#include &lt;stdio.h&gt;

int main(void) {
    /* Load the model. This loads VAE, transformer, and text encoder. */
    flux_ctx *ctx = flux_load_dir(&#34;flux-klein-model&#34;);
    if (!ctx) {
        fprintf(stderr, &#34;Failed to load model: %s\n&#34;, flux_get_error());
        return 1;
    }

    /* Configure generation parameters. Start with defaults and customize. */
    flux_params params = FLUX_PARAMS_DEFAULT;
    params.width = 512;
    params.height = 512;
    params.seed = 42;  /* Use -1 for random seed */

    /* Generate the image. This handles text encoding, diffusion, and VAE decode. */
    flux_image *img = flux_generate(ctx, &#34;A fluffy orange cat in a sunbeam&#34;, &amp;params);
    if (!img) {
        fprintf(stderr, &#34;Generation failed: %s\n&#34;, flux_get_error());
        flux_free(ctx);
        return 1;
    }

    /* Save to file. Format is determined by extension (.png or .ppm). */
    flux_image_save(img, &#34;cat.png&#34;);
    printf(&#34;Saved cat.png (%dx%d)\n&#34;, img-&gt;width, img-&gt;height);

    /* Clean up */
    flux_image_free(img);
    flux_free(ctx);
    return 0;
}"><pre><span>#include</span> <span>&#34;flux.h&#34;</span>
<span>#include</span> <span>&lt;stdio.h&gt;</span>

<span>int</span> <span>main</span>(<span>void</span>) {
    <span>/* Load the model. This loads VAE, transformer, and text encoder. */</span>
    <span>flux_ctx</span> <span>*</span><span>ctx</span> <span>=</span> <span>flux_load_dir</span>(<span>&#34;flux-klein-model&#34;</span>);
    <span>if</span> (!<span>ctx</span>) {
        <span>fprintf</span>(<span>stderr</span>, <span>&#34;Failed to load model: %s\n&#34;</span>, <span>flux_get_error</span>());
        <span>return</span> <span>1</span>;
    }

    <span>/* Configure generation parameters. Start with defaults and customize. */</span>
    <span>flux_params</span> <span>params</span> <span>=</span> <span>FLUX_PARAMS_DEFAULT</span>;
    <span>params</span>.<span>width</span> <span>=</span> <span>512</span>;
    <span>params</span>.<span>height</span> <span>=</span> <span>512</span>;
    <span>params</span>.<span>seed</span> <span>=</span> <span>42</span>;  <span>/* Use -1 for random seed */</span>

    <span>/* Generate the image. This handles text encoding, diffusion, and VAE decode. */</span>
    <span>flux_image</span> <span>*</span><span>img</span> <span>=</span> <span>flux_generate</span>(<span>ctx</span>, <span>&#34;A fluffy orange cat in a sunbeam&#34;</span>, <span>&amp;</span><span>params</span>);
    <span>if</span> (!<span>img</span>) {
        <span>fprintf</span>(<span>stderr</span>, <span>&#34;Generation failed: %s\n&#34;</span>, <span>flux_get_error</span>());
        <span>flux_free</span>(<span>ctx</span>);
        <span>return</span> <span>1</span>;
    }

    <span>/* Save to file. Format is determined by extension (.png or .ppm). */</span>
    <span>flux_image_save</span>(<span>img</span>, <span>&#34;cat.png&#34;</span>);
    <span>printf</span>(<span>&#34;Saved cat.png (%dx%d)\n&#34;</span>, <span>img</span><span>-&gt;</span><span>width</span>, <span>img</span><span>-&gt;</span><span>height</span>);

    <span>/* Clean up */</span>
    <span>flux_image_free</span>(<span>img</span>);
    <span>flux_free</span>(<span>ctx</span>);
    <span>return</span> <span>0</span>;
}</pre></div>
<p dir="auto">Compile with:</p>
<div dir="auto" data-snippet-clipboard-copy-content="gcc -o myapp myapp.c -L. -lflux -lm -framework Accelerate  # macOS
gcc -o myapp myapp.c -L. -lflux -lm -lopenblas              # Linux"><pre>gcc -o myapp myapp.c -L. -lflux -lm -framework Accelerate  <span><span>#</span> macOS</span>
gcc -o myapp myapp.c -L. -lflux -lm -lopenblas              <span><span>#</span> Linux</span></pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">Image-to-Image Transformation</h3><a id="user-content-image-to-image-transformation" aria-label="Permalink: Image-to-Image Transformation" href="#image-to-image-transformation"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Transform an existing image guided by a text prompt. The <code>strength</code> parameter controls how much the image changes:</p>
<div dir="auto" data-snippet-clipboard-copy-content="#include &#34;flux.h&#34;
#include &lt;stdio.h&gt;

int main(void) {
    flux_ctx *ctx = flux_load_dir(&#34;flux-klein-model&#34;);
    if (!ctx) return 1;

    /* Load the input image */
    flux_image *photo = flux_image_load(&#34;photo.png&#34;);
    if (!photo) {
        fprintf(stderr, &#34;Failed to load image\n&#34;);
        flux_free(ctx);
        return 1;
    }

    /* Set up parameters. Output size defaults to input size. */
    flux_params params = FLUX_PARAMS_DEFAULT;
    params.strength = 0.7;  /* 0.0 = no change, 1.0 = full regeneration */
    params.seed = 123;

    /* Transform the image */
    flux_image *painting = flux_img2img(ctx, &#34;oil painting, impressionist style&#34;,
                                         photo, &amp;params);
    flux_image_free(photo);  /* Done with input */

    if (!painting) {
        fprintf(stderr, &#34;Transformation failed: %s\n&#34;, flux_get_error());
        flux_free(ctx);
        return 1;
    }

    flux_image_save(painting, &#34;painting.png&#34;);
    printf(&#34;Saved painting.png\n&#34;);

    flux_image_free(painting);
    flux_free(ctx);
    return 0;
}"><pre><span>#include</span> <span>&#34;flux.h&#34;</span>
<span>#include</span> <span>&lt;stdio.h&gt;</span>

<span>int</span> <span>main</span>(<span>void</span>) {
    <span>flux_ctx</span> <span>*</span><span>ctx</span> <span>=</span> <span>flux_load_dir</span>(<span>&#34;flux-klein-model&#34;</span>);
    <span>if</span> (!<span>ctx</span>) <span>return</span> <span>1</span>;

    <span>/* Load the input image */</span>
    <span>flux_image</span> <span>*</span><span>photo</span> <span>=</span> <span>flux_image_load</span>(<span>&#34;photo.png&#34;</span>);
    <span>if</span> (!<span>photo</span>) {
        <span>fprintf</span>(<span>stderr</span>, <span>&#34;Failed to load image\n&#34;</span>);
        <span>flux_free</span>(<span>ctx</span>);
        <span>return</span> <span>1</span>;
    }

    <span>/* Set up parameters. Output size defaults to input size. */</span>
    <span>flux_params</span> <span>params</span> <span>=</span> <span>FLUX_PARAMS_DEFAULT</span>;
    <span>params</span>.<span>strength</span> <span>=</span> <span>0.7</span>;  <span>/* 0.0 = no change, 1.0 = full regeneration */</span>
    <span>params</span>.<span>seed</span> <span>=</span> <span>123</span>;

    <span>/* Transform the image */</span>
    <span>flux_image</span> <span>*</span><span>painting</span> <span>=</span> <span>flux_img2img</span>(<span>ctx</span>, <span>&#34;oil painting, impressionist style&#34;</span>,
                                         <span>photo</span>, <span>&amp;</span><span>params</span>);
    <span>flux_image_free</span>(<span>photo</span>);  <span>/* Done with input */</span>

    <span>if</span> (!<span>painting</span>) {
        <span>fprintf</span>(<span>stderr</span>, <span>&#34;Transformation failed: %s\n&#34;</span>, <span>flux_get_error</span>());
        <span>flux_free</span>(<span>ctx</span>);
        <span>return</span> <span>1</span>;
    }

    <span>flux_image_save</span>(<span>painting</span>, <span>&#34;painting.png&#34;</span>);
    <span>printf</span>(<span>&#34;Saved painting.png\n&#34;</span>);

    <span>flux_image_free</span>(<span>painting</span>);
    <span>flux_free</span>(<span>ctx</span>);
    <span>return</span> <span>0</span>;
}</pre></div>
<p dir="auto"><strong>Strength values:</strong></p>
<ul dir="auto">
<li><code>0.3</code> - Subtle style transfer, preserves most details</li>
<li><code>0.5</code> - Moderate transformation</li>
<li><code>0.7</code> - Strong transformation, good for style transfer</li>
<li><code>0.9</code> - Almost complete regeneration, keeps only composition</li>
</ul>
<div dir="auto"><h3 tabindex="-1" dir="auto">Generating Multiple Images</h3><a id="user-content-generating-multiple-images" aria-label="Permalink: Generating Multiple Images" href="#generating-multiple-images"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">When generating multiple images with different seeds but the same prompt, you can avoid reloading the text encoder:</p>
<div dir="auto" data-snippet-clipboard-copy-content="flux_ctx *ctx = flux_load_dir(&#34;flux-klein-model&#34;);
flux_params params = FLUX_PARAMS_DEFAULT;
params.width = 256;
params.height = 256;

/* Generate 5 variations with different seeds */
for (int i = 0; i &lt; 5; i++) {
    flux_set_seed(1000 + i);

    flux_image *img = flux_generate(ctx, &#34;A mountain landscape at sunset&#34;, &amp;params);

    char filename[64];
    snprintf(filename, sizeof(filename), &#34;landscape_%d.png&#34;, i);
    flux_image_save(img, filename);
    flux_image_free(img);
}

flux_free(ctx);"><pre><span>flux_ctx</span> <span>*</span><span>ctx</span> <span>=</span> <span>flux_load_dir</span>(<span>&#34;flux-klein-model&#34;</span>);
<span>flux_params</span> <span>params</span> <span>=</span> <span>FLUX_PARAMS_DEFAULT</span>;
<span>params</span>.<span>width</span> <span>=</span> <span>256</span>;
<span>params</span>.<span>height</span> <span>=</span> <span>256</span>;

<span>/* Generate 5 variations with different seeds */</span>
<span>for</span> (<span>int</span> <span>i</span> <span>=</span> <span>0</span>; <span>i</span> <span>&lt;</span> <span>5</span>; <span>i</span><span>++</span>) {
    <span>flux_set_seed</span>(<span>1000</span> <span>+</span> <span>i</span>);

    <span>flux_image</span> <span>*</span><span>img</span> <span>=</span> <span>flux_generate</span>(<span>ctx</span>, <span>&#34;A mountain landscape at sunset&#34;</span>, <span>&amp;</span><span>params</span>);

    <span>char</span> <span>filename</span>[<span>64</span>];
    <span>snprintf</span>(<span>filename</span>, <span>sizeof</span>(<span>filename</span>), <span>&#34;landscape_%d.png&#34;</span>, <span>i</span>);
    <span>flux_image_save</span>(<span>img</span>, <span>filename</span>);
    <span>flux_image_free</span>(<span>img</span>);
}

<span>flux_free</span>(<span>ctx</span>);</pre></div>
<p dir="auto">Note: The text encoder (~8GB) is automatically released after the first generation to save memory. It reloads automatically if you use a different prompt.</p>

<p dir="auto">All functions that can fail return NULL on error. Use <code>flux_get_error()</code> to get a description:</p>
<div dir="auto" data-snippet-clipboard-copy-content="flux_ctx *ctx = flux_load_dir(&#34;nonexistent-model&#34;);
if (!ctx) {
    fprintf(stderr, &#34;Error: %s\n&#34;, flux_get_error());
    /* Prints something like: &#34;Failed to load VAE - cannot generate images&#34; */
    return 1;
}"><pre><span>flux_ctx</span> <span>*</span><span>ctx</span> <span>=</span> <span>flux_load_dir</span>(<span>&#34;nonexistent-model&#34;</span>);
<span>if</span> (!<span>ctx</span>) {
    <span>fprintf</span>(<span>stderr</span>, <span>&#34;Error: %s\n&#34;</span>, <span>flux_get_error</span>());
    <span>/* Prints something like: &#34;Failed to load VAE - cannot generate images&#34; */</span>
    <span>return</span> <span>1</span>;
}</pre></div>

<p dir="auto"><strong>Core functions:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="flux_ctx *flux_load_dir(const char *model_dir);   /* Load model, returns NULL on error */
void flux_free(flux_ctx *ctx);                     /* Free all resources */

flux_image *flux_generate(flux_ctx *ctx, const char *prompt, const flux_params *params);
flux_image *flux_img2img(flux_ctx *ctx, const char *prompt, const flux_image *input,
                          const flux_params *params);"><pre><span>flux_ctx</span> <span>*</span><span>flux_load_dir</span>(<span>const</span> <span>char</span> <span>*</span><span>model_dir</span>);   <span>/* Load model, returns NULL on error */</span>
<span>void</span> <span>flux_free</span>(<span>flux_ctx</span> <span>*</span><span>ctx</span>);                     <span>/* Free all resources */</span>

<span>flux_image</span> <span>*</span><span>flux_generate</span>(<span>flux_ctx</span> <span>*</span><span>ctx</span>, <span>const</span> <span>char</span> <span>*</span><span>prompt</span>, <span>const</span> <span>flux_params</span> <span>*</span><span>params</span>);
<span>flux_image</span> <span>*</span><span>flux_img2img</span>(<span>flux_ctx</span> <span>*</span><span>ctx</span>, <span>const</span> <span>char</span> <span>*</span><span>prompt</span>, <span>const</span> <span>flux_image</span> <span>*</span><span>input</span>,
                          <span>const</span> <span>flux_params</span> <span>*</span><span>params</span>);</pre></div>
<p dir="auto"><strong>Image handling:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="flux_image *flux_image_load(const char *path);     /* Load PNG or PPM */
int flux_image_save(const flux_image *img, const char *path);  /* 0=success, -1=error */
flux_image *flux_image_resize(const flux_image *img, int new_w, int new_h);
void flux_image_free(flux_image *img);"><pre><span>flux_image</span> <span>*</span><span>flux_image_load</span>(<span>const</span> <span>char</span> <span>*</span><span>path</span>);     <span>/* Load PNG or PPM */</span>
<span>int</span> <span>flux_image_save</span>(<span>const</span> <span>flux_image</span> <span>*</span><span>img</span>, <span>const</span> <span>char</span> <span>*</span><span>path</span>);  <span>/* 0=success, -1=error */</span>
<span>flux_image</span> <span>*</span><span>flux_image_resize</span>(<span>const</span> <span>flux_image</span> <span>*</span><span>img</span>, <span>int</span> <span>new_w</span>, <span>int</span> <span>new_h</span>);
<span>void</span> <span>flux_image_free</span>(<span>flux_image</span> <span>*</span><span>img</span>);</pre></div>
<p dir="auto"><strong>Utilities:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="void flux_set_seed(int64_t seed);                  /* Set RNG seed for reproducibility */
const char *flux_get_error(void);                  /* Get last error message */
void flux_release_text_encoder(flux_ctx *ctx);     /* Manually free ~8GB (optional) */"><pre><span>void</span> <span>flux_set_seed</span>(<span>int64_t</span> <span>seed</span>);                  <span>/* Set RNG seed for reproducibility */</span>
<span>const</span> <span>char</span> <span>*</span><span>flux_get_error</span>(<span>void</span>);                  <span>/* Get last error message */</span>
<span>void</span> <span>flux_release_text_encoder</span>(<span>flux_ctx</span> <span>*</span><span>ctx</span>);     <span>/* Manually free ~8GB (optional) */</span></pre></div>

<div dir="auto" data-snippet-clipboard-copy-content="typedef struct {
    int width;              /* Output width in pixels (default: 256) */
    int height;             /* Output height in pixels (default: 256) */
    int num_steps;          /* Denoising steps, use 4 for klein (default: 4) */
    float guidance_scale;   /* CFG scale, use 1.0 for klein (default: 1.0) */
    int64_t seed;           /* Random seed, -1 for random (default: -1) */
    float strength;         /* img2img only: 0.0-1.0 (default: 0.75) */
} flux_params;

/* Initialize with sensible defaults */
#define FLUX_PARAMS_DEFAULT { 256, 256, 4, 1.0f, -1, 0.75f }"><pre><span>typedef</span> <span>struct</span> {
    <span>int</span> <span>width</span>;              <span>/* Output width in pixels (default: 256) */</span>
    <span>int</span> <span>height</span>;             <span>/* Output height in pixels (default: 256) */</span>
    <span>int</span> <span>num_steps</span>;          <span>/* Denoising steps, use 4 for klein (default: 4) */</span>
    <span>float</span> <span>guidance_scale</span>;   <span>/* CFG scale, use 1.0 for klein (default: 1.0) */</span>
    <span>int64_t</span> <span>seed</span>;           <span>/* Random seed, -1 for random (default: -1) */</span>
    <span>float</span> <span>strength</span>;         <span>/* img2img only: 0.0-1.0 (default: 0.75) */</span>
} <span>flux_params</span>;

<span>/* Initialize with sensible defaults */</span>
<span>#define</span> <span>FLUX_PARAMS_DEFAULT</span> { 256, 256, 4, 1.0f, -1, 0.75f }</pre></div>

<p dir="auto">MIT</p>
</article></div></div>
  </body>
</html>
