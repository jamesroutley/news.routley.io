<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://research.google/blog/deep-researcher-with-test-time-diffusion/">Original</a>
    <h1>Deep researcher with test-time diffusion</h1>
    
    <div id="readability-page-1" class="page"><div data-gt-publish-date="20250919">
                    
                    
    


<section>
    <div>
        
  <div data-gt-id="rich_text" data-gt-component-name="">
    




    <p data-block-key="ocegg">The recent advances in large language models (LLMs) have fueled the emergence of <a href="https://openai.com/index/introducing-deep-research/" target="_blank" rel="noopener noreferrer">deep research</a> (DR) agents. These agents demonstrate remarkable capabilities, including the generation of <a href="https://arxiv.org/abs/2409.04109" target="_blank" rel="noopener noreferrer">novel ideas</a>, efficient <a href="https://arxiv.org/abs/2503.09516" target="_blank" rel="noopener noreferrer">information retrieval</a>, experimental execution, and the subsequent drafting of comprehensive <a href="https://arxiv.org/pdf/2408.06941" target="_blank" rel="noopener noreferrer">reports</a> and <a href="https://arxiv.org/abs/2504.08066" target="_blank" rel="noopener noreferrer">academic papers</a>.</p><p data-block-key="acuge">Currently, most <a href="https://github.com/assafelovic/gpt-researcher" target="_blank" rel="noopener noreferrer">public DR agents</a> use a variety of clever techniques to improve their results, like <a href="https://research.google/blog/language-models-perform-reasoning-via-chain-of-thought/">performing reasoning via chain-of-thought</a> or <a href="https://openreview.net/forum?id=H4S4ETc8c9" target="_blank" rel="noopener noreferrer">generating multiple answers</a> and selecting the best one. While they&#39;ve made impressive progress, they often bolt different tools together without considering the iterative nature of human research. They&#39;re missing the key process (i.e., planning, drafting, researching, and iterating based on feedback) on which people rely when writing a paper about a complex topic. A key part of that revision process is to do more research to <a href="https://www.emerald.com/jd/article-abstract/69/2/243/198951/Patterns-of-graduate-students-information-seeking?redirectedFrom=fulltext" target="_blank" rel="noopener noreferrer">find missing information or strengthen your arguments</a>. This human pattern is surprisingly similar to the mechanism of <a href="https://proceedings.mlr.press/v202/zhang23as/zhang23as.pdf" target="_blank" rel="noopener noreferrer"><i>retrieval</i></a>-augmented diffusion models that start with a “noisy” or messy output and gradually refine it into a high-quality result. What if an AI agent&#39;s rough draft is the noisy version, and a search tool acts as the denoising step that cleans it up with new facts?</p><p data-block-key="5njoq">Today we introduce <a href="https://arxiv.org/abs/2507.16075" target="_blank" rel="noopener noreferrer">Test-Time Diffusion Deep Researcher</a> (TTD-DR), a DR agent that imitates the way humans do research. To our knowledge, TTD-DR is the first research agent that models research report writing as a diffusion process, where a messy first draft is gradually polished into a high-quality final version. We introduce two new algorithms that work together to enable TTD-DR. First, component-wise optimization via <a href="https://arxiv.org/abs/2501.09891" target="_blank" rel="noopener noreferrer">self-evolution</a> enhances the quality of each step in the research workflow. Then, report-level refinement via <a href="https://arxiv.org/abs/2302.02285" target="_blank" rel="noopener noreferrer">denoising with retrieval</a> applies newly retrieved information to revise and improve the report draft. We demonstrate that TTD-DR achieves state-of-the-art results on long-form report writing and multi-hop reasoning tasks.</p>
</div>

    </div>
</section>

                    
                    
    


<section>
    <div>
        
  <div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h2>Test-Time Diffusion Deep Researcher</h2>
            
        
        
    </p>



    <p data-block-key="ocegg">TTD-DR is designed to take a user query as input and then create a preliminary draft that serves as an evolving foundation to guide the research plan. This evolving draft is iteratively refined using a denoising with retrieval process (report-level refinement) that takes the information it finds and uses it to improve the draft at each step. This happens in a continuous loop that improves the report with each cycle. To top it all off, a self-evolution algorithm constantly enhances the entire process, from the initial plan to the final report. This powerful combination of refinement and self-improvement leads to a more coherent report writing process.</p>
</div>

    </div>
</section>

                    
                    
    


<section>
    
</section>

                    
                    
    


<section>
    <div>
        
  <div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h3>Backbone DR design</h3>
            
        
        
    </p>



    <p data-block-key="ocegg">The backbone DR design consists of three stages that we outline below.</p><ol><li data-block-key="40uvv"><b>Research plan generation:</b> Produces a structured research plan upon receiving a user query. This plan outlines a list of key areas needed for the final report, serving as an initial guideline for the subsequent information-gathering process.</li><li data-block-key="9c90d"><b>Iterative search:</b> Contains two sub-agents: Search Question Generation (stage 2a in the figure below) formulates a search query based on the research plan, the user query, and the context from previous search iterations (i.e., past questions and answers). Answer Searching (stage 2b) searches the available sources to find relevant documents and returns a summarized answer, similar to <a href="https://en.wikipedia.org/wiki/Retrieval-augmented_generation" target="_blank" rel="noopener noreferrer">retrieval-augmented generation</a> (RAG) systems.</li><li data-block-key="dambo"><b>Final report generation:</b> Produces a comprehensive and coherent final report by combining all the structured information gathered, that is, the plan and the series of question-answer pairs.</li></ol>
</div>

    </div>
</section>

                    
                    
    


<section>
    
</section>

                    
                    
    


<section>
    <div>
        
  <div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h3>Component-wise self-evolution</h3>
            
        
        
    </p>



    <p data-block-key="ocegg">We leverage a self-evolutionary algorithm to enhance the performance of each stage&#39;s agents in order to <i>find</i> and <i>preserve</i> the high quality context.</p><ul><li data-block-key="e6eh6"><b>Initial states:</b> The leftmost blocks in the diagram below represent multiple diverse answer variants based on the output of previous stages, which are used to explore a larger search space. This ideally leads to discovery of more valuable information.</li><li data-block-key="c8sei"><b>Environmental feedback:</b> Each answer variant is assessed by an LLM-as-a-judge, utilizing auto-raters for metrics, such as helpfulness and comprehensiveness. These raters not only provide fitness scores but also generate textual feedback that help improve the answer.</li><li data-block-key="9d9u5"><b>Revision:</b> With the scores and feedback from the previous step, each variant undergoes a revision step to adapt toward better fitness scores. The environmental feedback and revision steps repeat until reaching some maximum number of iterations or until the agent determines no more revisions are needed.</li><li data-block-key="fh789"><b>Cross-over:</b> Finally, multiple revised variants are merged into a single, high-quality output. This merging process consolidates the best information from all evolutionary paths, producing superior context for the main report generation process.</li></ul>
</div>

    </div>
</section>

                    
                    
    


<section>
    
</section>

                    
                    
    


<section>
    <div>
        
  <div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h3>Report-level denoising with retrieval</h3>
            
        
        
    </p>



    <p data-block-key="ocegg">Since a preliminary noisy draft is useless for complex topics without real research, TTD-DR uses a search tool that denoises and evolves the draft.</p><p data-block-key="2cj8q">Specifically, we feed the current draft report into the Search Generation stage (Stage 2a) of the backbone DR workflow to inform the generation of the next search query. After obtaining a synthesized answer in the Answer Searching stage (Stage 2b), the new information is used to revise the report draft, either by adding new details or by verifying existing information. This process of feeding the denoised report back to generate the next search query is repeated. The draft is progressively denoised until the search process concludes, at which point a final agent writes the final report based on all historical search answers and revisions (Stage 3).</p>
</div>

    </div>
</section>

                    
                    
    


<section>
    <div>
        
  <div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h2>Results</h2>
            
        
        
    </p>



    <p data-block-key="ocegg">We evaluate TTD-DR&#39;s performance using benchmark datasets that focus on two broad tasks: 1) Complex queries that require research agents to produce a long-form comprehensive report (<a href="https://github.com/Su-Sea/ydc-deep-research-evals" target="_blank" rel="noopener noreferrer">DeepConsult</a>) and, 2) multi-hop queries that require extensive search and reasoning to answer (<a href="https://scale.com/leaderboard/humanitys_last_exam" target="_blank" rel="noopener noreferrer">Humanity&#39;s Last Exam</a> [HLE] and <a href="https://huggingface.co/datasets/gaia-benchmark/GAIA" target="_blank" rel="noopener noreferrer">GAIA</a>). We sub-sample 200 queries from HLE that need more search and reasoning (HLE-Search). Both categories fit into our objective of building a general-purpose, real-world research companion. We compare our DR systems with <a href="https://openai.com/index/introducing-deep-research/" target="_blank" rel="noopener noreferrer">OpenAI Deep Research</a>.</p><p data-block-key="b0lhd">TTD-DR consistently achieves better results across all benchmarks. Notably, when compared to OpenAI DR, TTD-DR achieves 74.5% win rate for the <i>long-form</i> research report generation tasks. Additionally, it outperforms OpenAI DR by 7.7% and 1.7% on the two extensive research datasets with <i>short-form</i> ground-truth answers.</p>
</div>

    </div>
</section>

                    
                    
    


<section>
    
</section>

                    
                    
    


<section>
    <div>
        
  <div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h3>Ablation study</h3>
            
        
        
    </p>



    <p data-block-key="ocegg">For the ablation study, we incrementally add the three methods in the section above. Our DR agents use <a href="https://arxiv.org/abs/2507.06261" target="_blank" rel="noopener noreferrer">Gemini-2.5-pro</a> as the base model. All other baseline agents use their default LLMs. The charts below show the ablation study for our DR agents. The backbone DR agent underperforms OpenAI DR. With the addition of the proposed self-evolution algorithm, we observe that for DeepConsult, our system outperforms OpenAI Deep Research with 59.8% win rates. The Correctness scores on HLE-Search and GAIA datasets also show an improvement of 4.4% and 1.2%. Finally, incorporating diffusion with retrieval leads to substantial gains across all benchmarks.</p>
</div>

    </div>
</section>

                    
                    
    


<section>
    
</section>

                    
                    
    


<section>
    <div>
        
  <p data-block-key="ocegg">The <a href="https://en.wikipedia.org/wiki/Pareto_front" target="_blank" rel="noopener noreferrer">Pareto-frontier diagram</a> below further shows the test-time scaling efficiency of TTD-DR compared with other DR agents. We found that TTD-DR is more efficient than OpenAI DR, as with the same latency, it achieves the better quality per win-rate. See the <a href="https://arxiv.org/abs/2507.16075" target="_blank" rel="noopener noreferrer">paper</a> for more details.</p>

    </div>
</section>

                    
                    
    


<section>
    
</section>

                    
                    
    


<section>
    <div>
        
  <div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h2>Conclusion</h2>
            
        
        
    </p>



    <p data-block-key="ocegg">The Deep Researcher with Test-Time Diffusion (TTD-DR) is a new framework inspired by the iterative way humans do research. This agent addresses the limitations of existing DR agents by conceptualizing report generation as a diffusion process. The TTD-DR framework significantly outperforms existing DR agents across various benchmarks requiring intensive search and multi-hop reasoning. It demonstrates state-of-the-art performance in generating comprehensive long-form research reports and identifying concise answers for multi-hop search and reasoning tasks. We believe the reason it works so well is its &#34;draft-first&#34; design, which keeps the whole research process focused and coherent, preventing important information from getting lost along the way.</p>
</div>

    </div>
</section>

                    
                    
    


<section>
    <div>
        
  <div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h2>Availability on Google Cloud Platform</h2>
            
        
        
    </p>



    <p data-block-key="ocegg">A product version of this work is available on <a href="https://cloud.google.com/agentspace/docs/research-assistant" target="_blank" rel="noopener noreferrer">Google Agentspace</a>, implemented with Google Cloud <a href="https://cloud.google.com/vertex-ai/generative-ai/docs/agent-development-kit/quickstart" target="_blank" rel="noopener noreferrer">Agent Development Kit</a>.</p>
</div>

    </div>
</section>

                    
                    
    


<section>
    <div>
        
  <div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h2>Acknowledgements</h2>
            
        
        
    </p>



    <p data-block-key="ocegg"><i>This research was conducted by Rujun Han, Yanfei Chen, Guan Sun, Lesly Miculicich, Zoey CuiZhu, Yuanjun (Sophia) Bi, Weiming Wen, Hui Wan, Chunfeng Wen, Solène Maître, George Lee, Vishy Tirumalashetty, Xiaowei Li, Emily Xue, Zizhao Zhang, Salem Haykal, Burak Gokturk, Tomas Pfister, and Chen-Yu Lee.</i></p>
</div>

    </div>
</section>

                    
                </div></div>
  </body>
</html>
