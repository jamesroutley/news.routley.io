<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/nichtdax/awesome-totally-open-chatgpt">Original</a>
    <h1>Awesome-totally-open-ChatGPT: A list of open alternatives to ChatGPT</h1>
    
    <div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text">
<p dir="auto">ChatGPT is GPT-3.5 with RLHF (Reinforcement Learning with Human Feedback) for chat system.</p>
<p dir="auto">By alternative, I mean projects feature different language model for chat system.
Projects are <strong>not</strong> counted if they are:</p>
<ul dir="auto">
<li>alternative frontend projects because they just call the API from OpenAI.</li>
<li>alternative transformer decoder models to GPT 3.5 either because the training data of them are (mostly) not for chat system.</li>
</ul>
<p dir="auto">Tags:</p>
<ul dir="auto">
<li>B: bare (no data, no model&#39;s weight, no chat system)</li>
<li>M: mildly bare (yes data, yes model&#39;s weight, bare chat via API)</li>
<li>F: full (yes data, yes model&#39;s weight, fancy chat system including TUI and GUI)</li>
<li>C: complicated (semi open source, not really open souce, based on closed model, ...)</li>
</ul>

<p dir="auto">Append the new project at the end of file</p>
<div dir="auto" data-snippet-clipboard-copy-content="## [{owner}/{project-name}]{https://github.com/link/to/project}

Lorem ipsum dolor sit amet.

Tags: B"><pre><span><span>##</span><span> </span>[{owner}/{project-name}]{https://github.com/link/to/project}</span>

Lorem ipsum dolor sit amet.

Tags: B</pre></div>

<h2 tabindex="-1" dir="auto"><a id="user-content-lucidrainspalm-rlhf-pytorch" aria-hidden="true" href="#lucidrainspalm-rlhf-pytorch"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a><a href="https://github.com/lucidrains/PaLM-rlhf-pytorch">lucidrains/PaLM-rlhf-pytorch</a></h2>
<p dir="auto">Implementation of RLHF (Reinforcement Learning with Human Feedback) on top of the PaLM architecture. Basically ChatGPT but with PaLM</p>
<p dir="auto">Tags: B</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-togethercomputeropenchatkit" aria-hidden="true" href="#togethercomputeropenchatkit"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a><a href="https://github.com/togethercomputer/OpenChatKit">togethercomputer/OpenChatKit</a></h2>
<p dir="auto">OpenChatKit provides a powerful, open-source base to create both specialized and general purpose chatbots for various applications.</p>
<p dir="auto">Related links:</p>
<ul dir="auto">
<li><a href="https://huggingface.co/spaces/togethercomputer/OpenChatKit" rel="nofollow">spaces/togethercomputer/OpenChatKit</a></li>
</ul>
<p dir="auto">Tags: F</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-oobaboogatext-generation-webui" aria-hidden="true" href="#oobaboogatext-generation-webui"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a><a href="https://github.com/oobabooga/text-generation-webui">oobabooga/text-generation-webui</a></h2>
<p dir="auto">A gradio web UI for running Large Language Models like GPT-J 6B, OPT, GALACTICA, LLaMA, and Pygmalion.</p>
<p dir="auto">Tags: F</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-koboldaikoboldai-client" aria-hidden="true" href="#koboldaikoboldai-client"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a><a href="https://github.com/KoboldAI/KoboldAI-Client">KoboldAI/KoboldAI-Client</a></h2>
<p dir="auto">This is a browser-based front-end for AI-assisted writing with multiple local &amp; remote AI models. It offers the standard array of tools, including Memory, Authorâ€™s Note, World Info, Save &amp; Load, adjustable AI settings, formatting options, and the ability to import existing AI Dungeon adventures. You can also turn on Adventure mode and play the game like AI Dungeon Unleashed.</p>
<p dir="auto">Tags: F</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-laion-aiopen-assistant" aria-hidden="true" href="#laion-aiopen-assistant"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a><a href="https://github.com/LAION-AI/Open-Assistant">LAION-AI/Open-Assistant</a></h2>
<p dir="auto">OpenAssistant is a chat-based assistant that understands tasks, can interact with third-party systems, and retrieve information dynamically to do so.</p>
<p dir="auto">Related links:</p>
<ul dir="auto">
<li><a href="https://huggingface.co/OpenAssistant" rel="nofollow">huggingface.co/OpenAssistant</a></li>
<li><a href="https://www.reddit.com/r/OpenAssistant/" rel="nofollow">r/OpenAssistant/</a></li>
</ul>
<p dir="auto">Tags: F</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-tatsu-labstanford_alpaca" aria-hidden="true" href="#tatsu-labstanford_alpaca"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a><a href="https://github.com/tatsu-lab/stanford_alpaca">tatsu-lab/stanford_alpaca</a></h2>
<p dir="auto">This is the repo for the Stanford Alpaca project, which aims to build and share an instruction-following LLaMA model. Related links:</p>
<ul dir="auto">
<li><a href="https://github.com/pointnetwork/point-alpaca">pointnetwork/point-alpaca</a></li>
<li><a href="https://github.com/tloen/alpaca-lora">tloen/alpaca-lora</a></li>
<li><a href="https://www.reddit.com/r/LocalLLaMA/comments/11o6o3f/how_to_install_llama_8bit_and_4bit/" rel="nofollow">r/LocalLLaMA How to install LLaMA: 8-bit and 4-bit</a></li>
<li><a href="https://github.com/antimatter15/alpaca.cpp">antimatter15/alpaca.cpp</a></li>
<li><a href="https://github.com/ggerganov/llama.cpp">ggerganov/llama.cpp</a></li>
</ul>
<p dir="auto">See these Reddit comments first <a href="https://www.reddit.com/r/MachineLearning/comments/11uk8ti/comment/jcpd3yu/?utm_source=share&amp;utm_medium=web2x&amp;context=3" rel="nofollow">#1</a></p>
<p dir="auto">Tags: C</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-blinkdlchatrwkv" aria-hidden="true" href="#blinkdlchatrwkv"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a><a href="https://github.com/BlinkDL/ChatRWKV">BlinkDL/ChatRWKV</a></h2>
<p dir="auto">ChatRWKV is like ChatGPT but powered by RWKV (100% RNN) language model, and open source.</p>
<p dir="auto">Tags: F</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-thudmchatglm-6b" aria-hidden="true" href="#thudmchatglm-6b"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a><a href="https://github.com/THUDM/ChatGLM-6B">THUDM/ChatGLM-6B</a></h2>
<p dir="auto">ChatGLM-6B is an open bilingual language model based on General Language Model (GLM) framework, with 6.2 billion parameters. With the quantization technique, users can deploy locally on consumer-grade graphics cards (only 6GB of GPU memory is required at the INT4 quantization level).</p>
<p dir="auto">Related links:</p>
<ul dir="auto">
<li>Alternative Web UI: <a href="https://github.com/Akegarasu/ChatGLM-webui">Akegarasu/ChatGLM-webui</a></li>
<li>Slim version (remove 20K image tokens to reduce memory usage): <a href="https://huggingface.co/silver/chatglm-6b-slim" rel="nofollow">silver/chatglm-6b-slim</a></li>
<li>Fintune ChatGLM-6b using low-rank adaptation (LoRA): <a href="https://github.com/lich99/ChatGLM-finetune-LoRA">lich99/ChatGLM-finetune-LoRA</a></li>
<li>Deploying ChatGLM on Modelz: <a href="https://github.com/tensorchord/modelz-ChatGLM">tensorchord/modelz-ChatGLM</a></li>
<li>Docker image with built-on playground UI and streaming API compatible with OpenAI, using <a href="https://github.com/hyperonym/basaran">Basaran</a>: <a href="https://hub.docker.com/r/peakji92/chatglm/tags" rel="nofollow">peakji92/chatglm:6b</a></li>
</ul>
<p dir="auto">Tags: F</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-bigscience-workshopxmtf" aria-hidden="true" href="#bigscience-workshopxmtf"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a><a href="https://github.com/bigscience-workshop/xmtf">bigscience-workshop/xmtf</a></h2>
<p dir="auto">This repository provides an overview of all components used for the creation of BLOOMZ &amp; mT0 and xP3 introduced in the paper <a href="https://arxiv.org/abs/2211.01786" rel="nofollow">Crosslingual Generalization through Multitask Finetuning</a>.</p>
<p dir="auto">Related links:</p>
<ul dir="auto">
<li><a href="https://huggingface.co/bigscience/bloomz" rel="nofollow">bigscience/bloomz</a></li>
<li><a href="https://huggingface.co/bigscience/mt0-base" rel="nofollow">bigscience/mt0-base</a></li>
</ul>
<p dir="auto">Tags: M</p>
</article>
          </div></div>
  </body>
</html>
