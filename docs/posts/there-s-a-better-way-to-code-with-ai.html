<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://nmn.gl/blog/ai-amnesia">Original</a>
    <h1>There’s a Better Way to Code with AI</h1>
    
    <div id="readability-page-1" class="page"><div itemprop="articleBody">
    
    
      <p>Every developer I know has the same frustrating ritual. Open Claude Code or Cursor and ask it to do a task. The AI gives you generic code, sometimes useful (but usually not). You correct it. It apologizes. You explain again, with additional context.</p>

<p>Rinse, repeat, until you want to throw your laptop out the window.</p>

<p><a href="https://x.com/zeeg/status/1935402230062190672">David Cramer from Sentry</a> recently shared his AI workflow where he maintains manual rules files to give LLMs context. Solid approach, but it feels like too much copy-pasting. It’s 2025, and machines can do a better job of remembering things.</p>

<p>It’s funny how we’ve built the most powerful reasoning systems in human history, then lobotomized them by making them forget everything after each conversation. My question: is there a better way?</p>

<!--more-->

<h2 id="the-story">The Story</h2>

<p>Until recently, my daily routine looked like this:</p>

<ol>
  <li>Open Claude Code/Cursor</li>
  <li>Explain the task</li>
  <li>It gives a wrong result on the first try</li>
  <li>Retry, this time with more context</li>
  <li>It gives a wrong result on the second try</li>
  <li>Spend 30 minutes fixing it</li>
  <li>Close the conversation in frustration</li>
  <li>Repeat the next day</li>
</ol>

<p>I was essentially training the same AI from scratch every single day. <em>The definition of insanity, right?</em></p>

<p>That’s when it hit me: The AI isn’t the problem. The conversation model is.</p>

<h2 id="building-a-second-brain">Building a Second Brain</h2>

<p>I started thinking about how human teams actually work. Senior developers don’t explain the entire codebase to new hires every morning. They build institutional knowledge. <strong>They have coding standards, architectural decisions, and learned preferences that persist.</strong></p>

<p>So I built Giga — an AI memory system that learns from your conversations and builds a persistent knowledge base. <strong>Not another rules file you maintain manually, but a system that watches how you code, what you prefer, and what decisions you make.</strong></p>

<p>I made a “reflect” command which allows the AI to look back on it’s own conversation to identify patterns. While dogfooding it, I noticed something magical happening. Giga confidently identifies actual patterns, saves them as “neurons” in the second brain, and allows me to evoke them when I need them.</p>

<p>My AI is finally able to remember my preferences, and it uses them to make better decisions.</p>

<h2 id="how-to-fix-your-ai-workflow">How to Fix Your AI Workflow</h2>

<p>If you’re tired of the hamster wheel, here’s what actually works:</p>

<ul>
  <li>Question the reset. Why are you starting fresh every time? Your conversation history is data. Your corrections are training examples. Your preferences are valuable.</li>
  <li>Build incremental context. Instead of massive context dumps, add one new piece of information per conversation. Let the AI learn gradually, like a human would.</li>
  <li>Think in systems, not conversations. Individual AI chats are tactics. Building persistent AI knowledge is strategy.</li>
</ul>

<h2 id="the-path-forward">The Path Forward</h2>

<p>The future isn’t necessarily more powerful models. It’s AI that remembers, learns, and gets better over time — like a real team member.</p>

<p>We’re at an inflection point. We can keep playing the role of human context providers, or we can build systems that actually learn and improve.</p>

<p>I’m betting on the latter.</p>

<p>The question isn’t whether AI will get smarter. It’s whether we’ll get smarter about using it.</p>

<p><em>Building Giga taught me that the best way forward with code generation AI isn’t about better models — it’s about better context and memory. Giga is in private beta and only available for select teams, but if you’re interested in seeing how persistent AI knowledge works in practice, <a href="mailto:hello@gigamind.dev">shoot me an email</a> and I’d love to show you a demo.</em></p>

    
    
    

    
    
  </div></div>
  </body>
</html>
