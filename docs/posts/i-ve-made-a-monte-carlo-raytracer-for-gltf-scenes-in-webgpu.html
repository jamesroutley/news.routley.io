<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/lisyarus/webgpu-raytracer">Original</a>
    <h1>Show HN: I&#39;ve made a Monte-Carlo raytracer for glTF scenes in WebGPU</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/lisyarus/webgpu-raytracer/blob/trunk/screenshots/combined.png"><img src="https://github.com/lisyarus/webgpu-raytracer/raw/trunk/screenshots/combined.png" alt=""/></a></p>
<p dir="auto"><em>See more screenshots in the <a href="https://github.com/lisyarus/webgpu-raytracer/blob/trunk/screenshots">screenshots</a> directory.</em></p>

<p dir="auto">This is a GPU &#34;software&#34; raytracer (i.e. using manual ray-scene intersections and not RTX) written using the WebGPU API. It expects a single glTF scene as input. It supports flat-colored and textured materials with albedo, normal, and material maps. It doesn&#39;t support refraction (yet).</p>
<p dir="auto">There are a bunch of test scenes in the <a href="https://github.com/lisyarus/webgpu-raytracer/blob/trunk/test_scenes">test_scenes</a> directory.</p>
<p dir="auto">It uses wgpu-native WebGPU implementation, and SDL2 to create a window to render to.</p>

<p dir="auto">To run the program, first build it (see instructions below), then run it with a single glTF scene in the command arguments. For example, if you&#39;ve built the project in a <code>build</code> directory inside the project root, then you can run <code>./webgpu-raytracer ../test_scenes/bunny/bunny_100k.gltf</code>.</p>
<p dir="auto">An optional second command-line parameter defines the background of the scene. It can either be an RGB comma-separated triple like <code>1,0.5,0.25</code>, or path to an HDRI environment map. The <a href="https://github.com/lisyarus/webgpu-raytracer/blob/trunk/env_maps">env_maps</a> directory contains some sample enrivonment maps.</p>
<p dir="auto">By default, a simple preview of the scene is rendered. Press <code>[SPACE]</code> to activate raytracing.</p>
<p dir="auto">Here are all the controls:</p>
<ul dir="auto">
<li>Mouse (while pressing left mouse button): rotate the camera</li>
<li><code>[Q][E]</code>: roll the camera</li>
<li><code>[W][A][S][D]</code>: move the camera</li>
<li><code>[LSHIFT][LCTRL]</code>: speed up / slow down camera controls</li>
<li><code>[SPACE]</code>: activate raytracing</li>
</ul>
<p dir="auto">If the camera changes in raytracing mode, the raytracing result is discarded and the preview mode is activated again (i.e. there&#39;s no temporal reprojection in this case).</p>

<ul dir="auto">
<li>The raytracer uses standard Monte-Carlo integration with multiple importance sampling, see <a href="https://github.com/lisyarus/webgpu-raytracer/blob/trunk/shaders/raytrace_monte_carlo.wgsl">the corresponding shader</a>.</li>
<li>Fast ray-scene intersections are done using a BVH built with a simple surface-area heuristic at program start (see <a href="https://jacco.ompf2.com/2022/04/13/how-to-build-a-bvh-part-1-basics/" rel="nofollow">Jacco Bikker&#39;s amazing article series</a> about this).</li>
<li>Raytracing uses multiple importance sampling (MIS) between several direction sampling strategies: cosine-weighted (good for diffuse materials), direct light sampling (good for rough materials), VNDF sampling (good for smooth materials), and transmission sampling (good for transparent materials). See also <a href="https://lisyarus.github.io/blog/posts/multiple-importance-sampling.html" rel="nofollow">my article</a> explaining how MIS works.</li>
<li>The material used is the standard glTF Cook-Torrance GGX with a thin-walled transmission as described by <a href="https://github.com/KhronosGroup/glTF/blob/main/extensions/2.0/Khronos/KHR_materials_transmission/README.md">KHR_materials_transmission</a>.</li>
<li><a href="https://gpuopen.com/download/publications/Bounded_VNDF_Sampling_for_Smith-GGX_Reflections.pdf" rel="nofollow">VNDF</a> normals distribution is used to improve convergence.</li>
<li>Refractive materials are not supported. I tried to incorporate refractions into VNDF sampling but never managed to figure it out; this work resides in a separate <a href="https://github.com/lisyarus/webgpu-raytracer/tree/vndf-refraction-wip"><code>vndf-refraction-wip</code></a> branch.</li>
<li>NB: the <code>use camera.wgsl;</code> construct in the shaders is not standard WGSL, - instead, a rudimentary <a href="https://github.com/lisyarus/webgpu-raytracer/blob/trunk/source/shader_registry.cpp">shader importing mechanism</a> is implemented in this project.</li>
</ul>

<p dir="auto">With no promises of implementing any of this, in no particular order:</p>
<ul dir="auto">
<li>✅ Support environment maps &amp; a fixed-color environment</li>
<li>✅ Sample emissive triangles in proportion to area &amp; intensity (probably using <a href="https://en.wikipedia.org/wiki/Alias_method" rel="nofollow">Vose alias method</a>)</li>
<li>✅ Support albedo, material &amp; normal maps</li>
<li>Sample environment map pixels in proportion to intensity (using the same alias method)</li>
<li>Implement refraction + VNDF</li>
<li>Incorporate <a href="https://github.com/jbikker/tinybvh">tinybvh</a> and test different BVH variants for performance</li>
<li>Implement wavefront path-tracing</li>
<li>Support GLB input scenes</li>
</ul>

<p dir="auto">To build this project, you need</p>
<ul dir="auto">
<li><a href="https://cmake.org" rel="nofollow">CMake</a></li>
<li><a href="https://www.libsdl.org/" rel="nofollow">SDL2</a> (you can probably install it via your system&#39;s package manager)</li>
<li><a href="https://github.com/gfx-rs/wgpu-native">wgpu-native</a></li>
</ul>
<p dir="auto">To install wgpu-native, download <a href="https://github.com/gfx-rs/wgpu-native/releases">some release archive</a> for your platform, and unpack it somewhere. This project was built with the <a href="https://github.com/gfx-rs/wgpu-native/releases/tag/v0.19.4.1">v0.19.4.1</a> release, and might not work with older versions.</p>
<p dir="auto">Don&#39;t forget to check out submodules:</p>
<ul dir="auto">
<li><a href="https://github.com/g-truc/glm">glm</a> for vector &amp; matrix maths</li>
<li><a href="https://github.com/Tencent/rapidjson">rapidjson</a> for parsing glTF scenes</li>
<li><a href="https://github.com/nothings/stb">stb</a> for loading images</li>
</ul>
<p dir="auto">You can do this at clone time, using <code>git clone &lt;repo-url&gt; --recurse-submodules</code>. Add <code>--shallow-submodules</code> to prevent loading the whole commit history of those submodules. Otherwise, you can checkout submodules at any time after cloning the repo with <code>git submodule update --init --recursive</code>.</p>
<p dir="auto">Then, follow the usual steps for building something with CMake:</p>
<ul dir="auto">
<li>Create a build directory</li>
<li>In the build directory, run <code>cmake &lt;path-to-webgpu-demo-source&gt; -DWGPU_NATIVE_ROOT=&lt;path-to-unpacked-wgpu-native&gt;</code></li>
<li>Build the project: <code>cmake --build .</code></li>
</ul>

<p dir="auto">The <a href="https://github.com/lisyarus/webgpu-raytracer/blob/trunk/include/webgpu-demo/sdl_wgpu.h"><code>include/webgpu-demo/sdl2_wgpu.h</code></a> and <a href="https://github.com/lisyarus/webgpu-raytracer/blob/trunk/source/sdl_wgpu.c"><code>source/sdl2_wgpu.c</code></a> files implement a function <code>WGPUSurface SDL_WGPU_CreateSurface(WGPUInstance, SDL_Window *)</code> which creates a WebGPU surface from an SDL2 window, and should work on Linux (X11 and Wayland), Windows and MacOS. It is mostly based on <a href="https://github.com/eliemichel/glfw3webgpu/blob/main/glfw3webgpu.c">glfw3webgpu</a>.</p>
<p dir="auto">These files are almost standalone, and can be copied directly into your project, if you want to use WebGPU with SDL2. Note that the <code>sdl2_wgpu.c</code> file needs to be compiled as Objective-C for MacOS (add <code>-x objective-c</code> to compile flags for this file), and the <code>QuartzCore</code> framework needs to be linked with your application (add <code>-framework QuartzCore</code> to your linker flags).</p>

<p dir="auto">The <a href="https://github.com/lisyarus/webgpu-demo/blob/main/cmake/Findwgpu-native.cmake"><code>cmake/Findwgpu-native.cmake</code></a> find script is also useful on its own, and can be used in other CMake-based projects. Simply add its location to <code>CMAKE_MODULE_PATH</code>, and call <code>find_package(wgpu-native)</code>. It creates a <code>wgpu-native</code> imported library that can be simply linked to your executable via <code>target_link_libraries</code> (it sets up include directories automatically).</p>
</article></div></div>
  </body>
</html>
