<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/MiniMax-AI/MiniMax-M1">Original</a>
    <h1>MiniMax-M1 open-weight, large-scale hybrid-attention reasoning model</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto">
  <themed-picture data-catalyst-inline="true"><picture>
    <source srcset="/MiniMax-AI/MiniMax-M1/raw/main/figures/MiniMaxLogo-Dark.png" media="(prefers-color-scheme: dark)"/>
      <img src="https://github.com/MiniMax-AI/MiniMax-M1/raw/main/figures/MiniMaxLogo-Light.png" width="60%" alt="MiniMax"/>
    
  </picture></themed-picture>
</div>
<hr/>
<p><a href="https://www.minimax.io" rel="nofollow">
    <img alt="Homepage" src="https://camo.githubusercontent.com/3faa1e14d767d4a75cf9ed5610309fbb6fe899cec1f03f659f57e5961de37e9b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5f486f6d65706167652d4d696e694d61782d4646343034303f7374796c653d666c61742d737175617265266c6162656c436f6c6f723d324333453530266c6f676f3d646174613a696d6167652f7376672b786d6c3b6261736536342c50484e325a79423462577875637a30696148523063446f764c336433647935334d793576636d63764d6a41774d43397a646d6369494868746247357a4f6e68736157357250534a6f644852774f693876643364334c6e637a4c6d39795a7938784f546b354c336873615735724969423261575633516d393450534977494441674e446b774c6a4532494451784d533433496a34385a47566d637a3438633352356247552b4c6d4e736379307865325a706247773649325a6d5a6a74395043397a64486c735a5434384c32526c5a6e4d2b50484268644767675932786863334d39496d4e73637930784969426b50534a4e4d6a4d7a4c6a51314c4451774c6a6778595445334c6a55314c4445334c6a55314c4441734d5377774c544d314c6a45734d46597a4d7a45754e545a684e4441754f4449734e4441754f4449734d4377774c4445744f4445754e6a4d734d4659784e4456684d5463754e5455734d5463754e5455734d4377784c4441744d7a55754d446b734d4859334f5334774e6d45304d4334344d6977304d4334344d6977774c4441734d5330344d5334324d797777566a45354e5334304d6d45784d5334324d7977784d5334324d7977774c4441734d5377794d7934794e697777646a49344c6a5932595445334c6a55314c4445334c6a55314c4441734d4377774c444d314c6a45734d4659784e4456424e4441754f4449734e4441754f4449734d4377774c4445734d5451774c4445304e56597a4d7a45754e545a684d5463754e5455734d5463754e5455734d4377774c4441734d7a55754d537777566a49784e793431614442574e4441754f4446684e4441754f4445734e4441754f4445734d4377784c4445734f4445754e6a49734d4659794f4445754e545a684d5445754e6a4d734d5445754e6a4d734d4377784c4445744d6a4d754d6a59734d4670744d6a45314c6a6b734e6a4d754e4545304d4334344e6977304d4334344e6977774c4441734d4377304d4467754e544d734d545131566a4d774d4334344e5745784e7934314e5377784e7934314e5377774c4441734d53307a4e5334774f537777646930794e6a42684e4441754f4449734e4441754f4449734d4377774c4441744f4445754e6a4d734d46597a4e7a41754f446c684d5463754e5455734d5463754e5455734d4377774c4445744d7a55754d537777566a4d7a4d4745784d5334324d7977784d5334324d7977774c4445734d4330794d7934794e697777646a51774c6a6732595451774c6a67784c4451774c6a67784c4441734d4377774c4467784c6a59794c4442574e4441754f4446684d5463754e5455734d5463754e5455734d4377774c4445734d7a55754d537777646a49324d4745304d4334344d6977304d4334344d6977774c4441734d4377344d5334324d797777566a45304e5745784e7934314e5377784e7934314e5377774c4445734d53777a4e5334784c4442574d6a67784c6a5532595445784c6a597a4c4445784c6a597a4c4441734d4377774c44497a4c6a49324c4442574d545131515451774c6a67314c4451774c6a67314c4441734d4377774c4451304f53347a4e5377784d4451754d6a46614969382b5043397a646d632b266c6f676f57696474683d3230" data-canonical-src="https://img.shields.io/badge/_Homepage-MiniMax-FF4040?style=flat-square&amp;labelColor=2C3E50&amp;logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB2aWV3Qm94PSIwIDAgNDkwLjE2IDQxMS43Ij48ZGVmcz48c3R5bGU+LmNscy0xe2ZpbGw6I2ZmZjt9PC9zdHlsZT48L2RlZnM+PHBhdGggY2xhc3M9ImNscy0xIiBkPSJNMjMzLjQ1LDQwLjgxYTE3LjU1LDE3LjU1LDAsMSwwLTM1LjEsMFYzMzEuNTZhNDAuODIsNDAuODIsMCwwLDEtODEuNjMsMFYxNDVhMTcuNTUsMTcuNTUsMCwxLDAtMzUuMDksMHY3OS4wNmE0MC44Miw0MC44MiwwLDAsMS04MS42MywwVjE5NS40MmExMS42MywxMS42MywwLDAsMSwyMy4yNiwwdjI4LjY2YTE3LjU1LDE3LjU1LDAsMCwwLDM1LjEsMFYxNDVBNDAuODIsNDAuODIsMCwwLDEsMTQwLDE0NVYzMzEuNTZhMTcuNTUsMTcuNTUsMCwwLDAsMzUuMSwwVjIxNy41aDBWNDAuODFhNDAuODEsNDAuODEsMCwxLDEsODEuNjIsMFYyODEuNTZhMTEuNjMsMTEuNjMsMCwxLDEtMjMuMjYsMFptMjE1LjksNjMuNEE0MC44Niw0MC44NiwwLDAsMCw0MDguNTMsMTQ1VjMwMC44NWExNy41NSwxNy41NSwwLDAsMS0zNS4wOSwwdi0yNjBhNDAuODIsNDAuODIsMCwwLDAtODEuNjMsMFYzNzAuODlhMTcuNTUsMTcuNTUsMCwwLDEtMzUuMSwwVjMzMGExMS42MywxMS42MywwLDEsMC0yMy4yNiwwdjQwLjg2YTQwLjgxLDQwLjgxLDAsMCwwLDgxLjYyLDBWNDAuODFhMTcuNTUsMTcuNTUsMCwwLDEsMzUuMSwwdjI2MGE0MC44Miw0MC44MiwwLDAsMCw4MS42MywwVjE0NWExNy41NSwxNy41NSwwLDEsMSwzNS4xLDBWMjgxLjU2YTExLjYzLDExLjYzLDAsMCwwLDIzLjI2LDBWMTQ1QTQwLjg1LDQwLjg1LDAsMCwwLDQ0OS4zNSwxMDQuMjFaIi8+PC9zdmc+&amp;logoWidth=20"/>
  </a>
  <a href="https://arxiv.org/abs/2506.13585" rel="nofollow">
    <img alt="Paper" src="https://camo.githubusercontent.com/2604333fbd9843f0be50433505993398230120aca88af3c4dc94e4e8e3034c43/68747470733a2f2f696d672e736869656c64732e696f2f62616467652ff09f93965f50617065722d4d696e694d61782d2d4d312d4646343034303f7374796c653d666c61742d737175617265266c6162656c436f6c6f723d324333453530" data-canonical-src="https://img.shields.io/badge/📖_Paper-MiniMax--M1-FF4040?style=flat-square&amp;labelColor=2C3E50"/>
  </a>
  <a href="https://chat.minimax.io/" rel="nofollow">
    <img alt="Chat" src="https://camo.githubusercontent.com/cf1a97c2a522fe9d780765d5cc263bf289cde77cb8a51435a994aaf202e3e89f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5f4d696e694d61785f436861742d4646343034303f7374796c653d666c61742d737175617265266c6162656c436f6c6f723d324333453530266c6f676f3d646174613a696d6167652f7376672b786d6c3b6261736536342c50484e325a79423462577875637a30696148523063446f764c336433647935334d793576636d63764d6a41774d43397a646d6369494868746247357a4f6e68736157357250534a6f644852774f693876643364334c6e637a4c6d39795a7938784f546b354c336873615735724969423261575633516d393450534977494441674e446b774c6a4532494451784d533433496a34385a47566d637a3438633352356247552b4c6d4e736379307865325a706247773649325a6d5a6a74395043397a64486c735a5434384c32526c5a6e4d2b50484268644767675932786863334d39496d4e73637930784969426b50534a4e4d6a4d7a4c6a51314c4451774c6a6778595445334c6a55314c4445334c6a55314c4441734d5377774c544d314c6a45734d46597a4d7a45754e545a684e4441754f4449734e4441754f4449734d4377774c4445744f4445754e6a4d734d4659784e4456684d5463754e5455734d5463754e5455734d4377784c4441744d7a55754d446b734d4859334f5334774e6d45304d4334344d6977304d4334344d6977774c4441734d5330344d5334324d797777566a45354e5334304d6d45784d5334324d7977784d5334324d7977774c4441734d5377794d7934794e697777646a49344c6a5932595445334c6a55314c4445334c6a55314c4441734d4377774c444d314c6a45734d4659784e4456424e4441754f4449734e4441754f4449734d4377774c4445734d5451774c4445304e56597a4d7a45754e545a684d5463754e5455734d5463754e5455734d4377774c4441734d7a55754d537777566a49784e793431614442574e4441754f4446684e4441754f4445734e4441754f4445734d4377784c4445734f4445754e6a49734d4659794f4445754e545a684d5445754e6a4d734d5445754e6a4d734d4377784c4445744d6a4d754d6a59734d4670744d6a45314c6a6b734e6a4d754e4545304d4334344e6977304d4334344e6977774c4441734d4377304d4467754e544d734d545131566a4d774d4334344e5745784e7934314e5377784e7934314e5377774c4441734d53307a4e5334774f537777646930794e6a42684e4441754f4449734e4441754f4449734d4377774c4441744f4445754e6a4d734d46597a4e7a41754f446c684d5463754e5455734d5463754e5455734d4377774c4445744d7a55754d537777566a4d7a4d4745784d5334324d7977784d5334324d7977774c4445734d4330794d7934794e697777646a51774c6a6732595451774c6a67784c4451774c6a67784c4441734d4377774c4467784c6a59794c4442574e4441754f4446684d5463754e5455734d5463754e5455734d4377774c4445734d7a55754d537777646a49324d4745304d4334344d6977304d4334344d6977774c4441734d4377344d5334324d797777566a45304e5745784e7934314e5377784e7934314e5377774c4445734d53777a4e5334784c4442574d6a67784c6a5532595445784c6a597a4c4445784c6a597a4c4441734d4377774c44497a4c6a49324c4442574d545131515451774c6a67314c4451774c6a67314c4441734d4377774c4451304f53347a4e5377784d4451754d6a46614969382b5043397a646d632b266c6f676f57696474683d3230" data-canonical-src="https://img.shields.io/badge/_MiniMax_Chat-FF4040?style=flat-square&amp;labelColor=2C3E50&amp;logo=data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHhtbG5zOnhsaW5rPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5L3hsaW5rIiB2aWV3Qm94PSIwIDAgNDkwLjE2IDQxMS43Ij48ZGVmcz48c3R5bGU+LmNscy0xe2ZpbGw6I2ZmZjt9PC9zdHlsZT48L2RlZnM+PHBhdGggY2xhc3M9ImNscy0xIiBkPSJNMjMzLjQ1LDQwLjgxYTE3LjU1LDE3LjU1LDAsMSwwLTM1LjEsMFYzMzEuNTZhNDAuODIsNDAuODIsMCwwLDEtODEuNjMsMFYxNDVhMTcuNTUsMTcuNTUsMCwxLDAtMzUuMDksMHY3OS4wNmE0MC44Miw0MC44MiwwLDAsMS04MS42MywwVjE5NS40MmExMS42MywxMS42MywwLDAsMSwyMy4yNiwwdjI4LjY2YTE3LjU1LDE3LjU1LDAsMCwwLDM1LjEsMFYxNDVBNDAuODIsNDAuODIsMCwwLDEsMTQwLDE0NVYzMzEuNTZhMTcuNTUsMTcuNTUsMCwwLDAsMzUuMSwwVjIxNy41aDBWNDAuODFhNDAuODEsNDAuODEsMCwxLDEsODEuNjIsMFYyODEuNTZhMTEuNjMsMTEuNjMsMCwxLDEtMjMuMjYsMFptMjE1LjksNjMuNEE0MC44Niw0MC44NiwwLDAsMCw0MDguNTMsMTQ1VjMwMC44NWExNy41NSwxNy41NSwwLDAsMS0zNS4wOSwwdi0yNjBhNDAuODIsNDAuODIsMCwwLDAtODEuNjMsMFYzNzAuODlhMTcuNTUsMTcuNTUsMCwwLDEtMzUuMSwwVjMzMGExMS42MywxMS42MywwLDEsMC0yMy4yNiwwdjQwLjg2YTQwLjgxLDQwLjgxLDAsMCwwLDgxLjYyLDBWNDAuODFhMTcuNTUsMTcuNTUsMCwwLDEsMzUuMSwwdjI2MGE0MC44Miw0MC44MiwwLDAsMCw4MS42MywwVjE0NWExNy41NSwxNy41NSwwLDEsMSwzNS4xLDBWMjgxLjU2YTExLjYzLDExLjYzLDAsMCwwLDIzLjI2LDBWMTQ1QTQwLjg1LDQwLjg1LDAsMCwwLDQ0OS4zNSwxMDQuMjFaIi8+PC9zdmc+&amp;logoWidth=20"/>
  </a>
  <a href="https://www.minimax.io/platform" rel="nofollow">
    <img alt="API" src="https://camo.githubusercontent.com/033a96d7a4beb7f7872861878556c078064d874835da92f5d2ff5a0fe037c960/68747470733a2f2f696d672e736869656c64732e696f2f62616467652fe29aa15f4150492d506c6174666f726d2d4646343034303f7374796c653d666c61742d737175617265266c6162656c436f6c6f723d324333453530" data-canonical-src="https://img.shields.io/badge/⚡_API-Platform-FF4040?style=flat-square&amp;labelColor=2C3E50"/>
  </a>
  <a href="https://github.com/MiniMax-AI/MiniMax-MCP">
    <img alt="MCP" src="https://camo.githubusercontent.com/a1dd6a9aad054731a18f4af8cc4f477aa43f9cf83920e1676324b97204238b5e/68747470733a2f2f696d672e736869656c64732e696f2f62616467652ff09f9a805f4d43502d4d696e694d61785f4d43502d4646343034303f7374796c653d666c61742d737175617265266c6162656c436f6c6f723d324333453530" data-canonical-src="https://img.shields.io/badge/🚀_MCP-MiniMax_MCP-FF4040?style=flat-square&amp;labelColor=2C3E50"/>
  </a>
</p>
<p><a href="https://huggingface.co/MiniMaxAI" rel="nofollow">
    <img alt="Hugging Face" src="https://camo.githubusercontent.com/94aa40386a1540394a4a71cdd73d62c70d4639e122e71df56f06b8a404754daa/68747470733a2f2f696d672e736869656c64732e696f2f62616467652ff09fa4975f48756767696e675f466163652d4d696e694d61782d4646343034303f7374796c653d666c61742d737175617265266c6162656c436f6c6f723d324333453530" data-canonical-src="https://img.shields.io/badge/🤗_Hugging_Face-MiniMax-FF4040?style=flat-square&amp;labelColor=2C3E50"/>
  </a>
  <a href="https://github.com/MiniMax-AI/MiniMax-M1">
    <img alt="GitHub" src="https://camo.githubusercontent.com/f8147f98bcc14eb4bdbeba8461a7af5189604ad0ac027765507eaef31fb3456c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652ff09f90995f4769744875622d4d696e694d61782d4646343034303f7374796c653d666c61742d737175617265266c6162656c436f6c6f723d324333453530" data-canonical-src="https://img.shields.io/badge/🐙_GitHub-MiniMax-FF4040?style=flat-square&amp;labelColor=2C3E50"/>
  </a>
  <a href="https://www.modelscope.cn/organization/MiniMax" rel="nofollow">
    <img alt="ModelScope" src="https://camo.githubusercontent.com/0715f6acf7fc905d6a032c08bd8f41b03f492fda6b3f70bf565e853643052b05/68747470733a2f2f696d672e736869656c64732e696f2f62616467652ff09fa496efb88f5f4d6f64656c53636f70652d4d696e694d61782d4646343034303f7374796c653d666c61742d737175617265266c6162656c436f6c6f723d324333453530" data-canonical-src="https://img.shields.io/badge/🤖️_ModelScope-MiniMax-FF4040?style=flat-square&amp;labelColor=2C3E50"/>
  </a>
  <a href="https://github.com/MiniMax-AI/MiniMax-M1/blob/main/LICENSE">
    <img alt="License" src="https://camo.githubusercontent.com/938892ddd7b2f59b079c0be16d5b388f03a3ff8868dbcf480033d0ae3690964f/68747470733a2f2f696d672e736869656c64732e696f2f62616467652fe29a96efb88f5f4c6963656e73652d4170616368655f322e302d4646343034303f7374796c653d666c61742d737175617265266c6162656c436f6c6f723d324333453530" data-canonical-src="https://img.shields.io/badge/⚖️_License-Apache_2.0-FF4040?style=flat-square&amp;labelColor=2C3E50"/>
  </a>
  <a href="https://github.com/MiniMax-AI/MiniMax-01/blob/main/figures/wechat-qrcode.jpeg">
    <img alt="WeChat" src="https://camo.githubusercontent.com/e2a1862bfaa62514518f7eba6c5ad931f8b898d3ebf9867f69f29a83c0d4131d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652ff09f92ac5f5765436861742d4d696e694d61782d4646343034303f7374796c653d666c61742d737175617265266c6162656c436f6c6f723d324333453530" data-canonical-src="https://img.shields.io/badge/💬_WeChat-MiniMax-FF4040?style=flat-square&amp;labelColor=2C3E50"/>
  </a>
</p>


<p dir="auto">We introduce MiniMax-M1, the world&#39;s first open-weight, large-scale hybrid-attention reasoning model.
MiniMax-M1 is powered by a hybrid Mixture-of-Experts (MoE) architecture combined with a lightning
attention mechanism. The model is developed based on our previous <a href="https://huggingface.co/MiniMaxAI/MiniMax-Text-01" rel="nofollow">MiniMax-Text-01 model</a>,
which contains a total of 456 billion parameters with 45.9 billion parameters activated
per token. Consistent with MiniMax-Text-01, the M1 model natively supports a context length of 1
million tokens, 8x the context size of DeepSeek R1. Furthermore, the lightning attention mechanism
in MiniMax-M1 enables efficient scaling of test-time compute – For example, compared to DeepSeek
R1, M1 consumes 25% of the FLOPs at a generation length of 100K tokens. These properties make M1
particularly suitable for complex tasks that require processing long inputs and thinking extensively.
MiniMax-M1 is trained using large-scale reinforcement learning (RL) on diverse problems ranging from
traditional mathematical reasoning to sandbox-based, real-world software engineering environments.
We develop an efficient RL scaling framework for M1 highlighting two perspectives: (1) We propose
CISPO, a novel algorithm that clips importance sampling weights instead of token updates, which
outperforms other competitive RL variants; (2) Our hybrid-attention design naturally enhances the
efficiency of RL, where we address unique challenges when scaling RL with the hybrid architecture. We
train two versions of MiniMax-M1 models with <a href="https://huggingface.co/MiniMaxAI/MiniMax-M1-40k" rel="nofollow">40K</a> and
<a href="https://huggingface.co/MiniMaxAI/MiniMax-M1-80k" rel="nofollow">80K</a> thinking budgets respectively. Experiments
on standard benchmarks show that our models outperform other strong open-weight models such as
the original DeepSeek-R1 and Qwen3-235B, particularly on complex software engineering, tool using,
and long context tasks. With efficient scaling of test-time compute, MiniMax-M1 serves as a strong
foundation for next-generation language model agents to reason and tackle real-world challenges.</p>
<p dir="auto">
  <a target="_blank" rel="noopener noreferrer" href="https://github.com/MiniMax-AI/MiniMax-M1/blob/main/figures/TextBench.png"><img width="100%" src="https://github.com/MiniMax-AI/MiniMax-M1/raw/main/figures/TextBench.png"/></a>
  </p>

<p dir="auto"><strong>Performance of MiniMax-M1 on core benchmarks.</strong></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th><strong>Category</strong></th>
<th><strong>Task</strong></th>
<th><strong>MiniMax-M1-80K</strong></th>
<th><strong>MiniMax-M1-40K</strong></th>
<th><strong>Qwen3-235B-A22B</strong></th>
<th><strong>DeepSeek-R1-0528</strong></th>
<th><strong>DeepSeek-R1</strong></th>
<th><strong>Seed-Thinking-v1.5</strong></th>
<th><strong>Claude 4 Opus</strong></th>
<th><strong>Gemini 2.5 Pro (06-05)</strong></th>
<th><strong>OpenAI-o3</strong></th>
</tr>
</thead>
<tbody>
<tr>
<td></td>
<td><em>Extended Thinking</em></td>
<td><em>80K</em></td>
<td><em>40K</em></td>
<td><em>32k</em></td>
<td><em>64k</em></td>
<td><em>32k</em></td>
<td><em>32k</em></td>
<td><em>64k</em></td>
<td><em>64k</em></td>
<td><em>100k</em></td>
</tr>
<tr>
<td><em><strong>Mathematics</strong></em></td>
<td>AIME 2024</td>
<td>86.0</td>
<td>83.3</td>
<td>85.7</td>
<td>91.4</td>
<td>79.8</td>
<td>86.7</td>
<td>76.0</td>
<td>92.0</td>
<td>91.6</td>
</tr>
<tr>
<td></td>
<td>AIME 2025</td>
<td>76.9</td>
<td>74.6</td>
<td>81.5</td>
<td>87.5</td>
<td>70.0</td>
<td>74.0</td>
<td>75.5</td>
<td>88.0</td>
<td>88.9</td>
</tr>
<tr>
<td></td>
<td>MATH-500</td>
<td>96.8</td>
<td>96.0</td>
<td>96.2</td>
<td>98.0</td>
<td>97.3</td>
<td>96.7</td>
<td>98.2</td>
<td>98.8</td>
<td>98.1</td>
</tr>
<tr>
<td><em><strong>General Coding</strong></em></td>
<td>LiveCodeBench <em>(24/8~25/5)</em></td>
<td>65.0</td>
<td>62.3</td>
<td>65.9</td>
<td>73.1</td>
<td>55.9</td>
<td>67.5</td>
<td>56.6</td>
<td>77.1</td>
<td>75.8</td>
</tr>
<tr>
<td></td>
<td>FullStackBench</td>
<td>68.3</td>
<td>67.6</td>
<td>62.9</td>
<td>69.4</td>
<td>70.1</td>
<td>69.9</td>
<td>70.3</td>
<td>--</td>
<td>69.3</td>
</tr>
<tr>
<td><em><strong>Reasoning &amp; Knowledge</strong></em></td>
<td>GPQA Diamond</td>
<td>70.0</td>
<td>69.2</td>
<td>71.1</td>
<td>81.0</td>
<td>71.5</td>
<td>77.3</td>
<td>79.6</td>
<td>86.4</td>
<td>83.3</td>
</tr>
<tr>
<td></td>
<td>HLE <em>(no tools)</em></td>
<td>8.4*</td>
<td>7.2*</td>
<td>7.6*</td>
<td>17.7*</td>
<td>8.6*</td>
<td>8.2</td>
<td>10.7</td>
<td>21.6</td>
<td>20.3</td>
</tr>
<tr>
<td></td>
<td>ZebraLogic</td>
<td>86.8</td>
<td>80.1</td>
<td>80.3</td>
<td>95.1</td>
<td>78.7</td>
<td>84.4</td>
<td>95.1</td>
<td>91.6</td>
<td>95.8</td>
</tr>
<tr>
<td></td>
<td>MMLU-Pro</td>
<td>81.1</td>
<td>80.6</td>
<td>83.0</td>
<td>85.0</td>
<td>84.0</td>
<td>87.0</td>
<td>85.0</td>
<td>86.0</td>
<td>85.0</td>
</tr>
<tr>
<td><em><strong>Software Engineering</strong></em></td>
<td>SWE-bench Verified</td>
<td>56.0</td>
<td>55.6</td>
<td>34.4</td>
<td>57.6</td>
<td>49.2</td>
<td>47.0</td>
<td>72.5</td>
<td>67.2</td>
<td>69.1</td>
</tr>
<tr>
<td><em><strong>Long Context</strong></em></td>
<td>OpenAI-MRCR <em>(128k)</em></td>
<td>73.4</td>
<td>76.1</td>
<td>27.7</td>
<td>51.5</td>
<td>35.8</td>
<td>54.3</td>
<td>48.9</td>
<td>76.8</td>
<td>56.5</td>
</tr>
<tr>
<td></td>
<td>OpenAI-MRCR <em>(1M)</em></td>
<td>56.2</td>
<td>58.6</td>
<td>--</td>
<td>--</td>
<td>--</td>
<td>--</td>
<td>--</td>
<td>58.8</td>
<td>--</td>
</tr>
<tr>
<td></td>
<td>LongBench-v2</td>
<td>61.5</td>
<td>61.0</td>
<td>50.1</td>
<td>52.1</td>
<td>58.3</td>
<td>52.5</td>
<td>55.6</td>
<td>65.0</td>
<td>58.8</td>
</tr>
<tr>
<td><em><strong>Agentic Tool Use</strong></em></td>
<td>TAU-bench <em>(airline)</em></td>
<td>62.0</td>
<td>60.0</td>
<td>34.7</td>
<td>53.5</td>
<td>--</td>
<td>44.0</td>
<td>59.6</td>
<td>50.0</td>
<td>52.0</td>
</tr>
<tr>
<td></td>
<td>TAU-bench <em>(retail)</em></td>
<td>63.5</td>
<td>67.8</td>
<td>58.6</td>
<td>63.9</td>
<td>--</td>
<td>55.7</td>
<td>81.4</td>
<td>67.0</td>
<td>73.9</td>
</tr>
<tr>
<td><em><strong>Factuality</strong></em></td>
<td>SimpleQA</td>
<td>18.5</td>
<td>17.9</td>
<td>11.0</td>
<td>27.8</td>
<td>30.1</td>
<td>12.9</td>
<td>--</td>
<td>54.0</td>
<td>49.4</td>
</tr>
<tr>
<td><em><strong>General Assistant</strong></em></td>
<td>MultiChallenge</td>
<td>44.7</td>
<td>44.7</td>
<td>40.0</td>
<td>45.0</td>
<td>40.7</td>
<td>43.0</td>
<td>45.8</td>
<td>51.8</td>
<td>56.5</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">* conducted on the text-only HLE subset.</p>
<p dir="auto">Our models are evaluated with <code>temperature=1.0</code>, <code>top_p=0.95</code>.</p>

<p dir="auto">We report results derived from the Agentless scaffold. Departing from the original pipeline, our methodology employs a two-stage localization process (without any embedding-based retrieval mechanisms): initial coarse-grained file localization followed by fine-grained localization to specific files and code elements. The values for our models are calculated on the subset of n=486 verified tasks which work on our infrastructure. The excluded 14 test cases that were incompatible with our internal infrastructure are:
<code>&#34;astropy__astropy-7606&#34;</code>,
<code>&#34;astropy__astropy-8707&#34;</code>,
<code>&#34;astropy__astropy-8872&#34;</code>,
<code>&#34;django__django-10097&#34;</code>,
<code>&#34;matplotlib__matplotlib-20488&#34;</code>,
<code>&#34;psf__requests-2317&#34;</code>,
<code>&#34;psf__requests-2931&#34;</code>,
<code>&#34;psf__requests-5414&#34;</code>,
<code>&#34;pylint-dev__pylint-6528&#34;</code>,
<code>&#34;pylint-dev__pylint-7277&#34;</code>,
<code>&#34;sphinx-doc__sphinx-10435&#34;</code>,
<code>&#34;sphinx-doc__sphinx-7985&#34;</code>,
<code>&#34;sphinx-doc__sphinx-8269&#34;</code>,
<code>&#34;sphinx-doc__sphinx-8475&#34;</code></p>

<p dir="auto">We evaluate TAU-Bench with GPT-4.1 as user model and without any custom tools. The maximum number of interaction steps is 40.
Our general system prompt is:</p>
<div data-snippet-clipboard-copy-content="- In each round, you need to carefully examine the tools provided to you to determine if any can be used.
- You must adhere to all of the policies. Pay attention to the details in the terms. Solutions for most situations can be found within these policies."><pre><code>- In each round, you need to carefully examine the tools provided to you to determine if any can be used.
- You must adhere to all of the policies. Pay attention to the details in the terms. Solutions for most situations can be found within these policies.
</code></pre></div>

<p dir="auto">Download the model from HuggingFace repository:</p>
<ul dir="auto">
<li><a href="https://huggingface.co/MiniMaxAI/MiniMax-M1-40k" rel="nofollow">MiniMax-M1-40k</a></li>
<li><a href="https://huggingface.co/MiniMaxAI/MiniMax-M1-80k" rel="nofollow">MiniMax-M1-80k</a></li>
</ul>
<p dir="auto">For production deployment, we recommend using <a href="https://docs.vllm.ai/en/latest/" rel="nofollow">vLLM</a> to serve MiniMax-M1. vLLM provides excellent performance for serving large language models with the following features:</p>
<ul dir="auto">
<li>🔥 Outstanding service throughout performance</li>
<li>⚡ Efficient and intelligent memory management</li>
<li>📦 Powerful batch request processing capability</li>
<li>⚙️ Deeply optimized underlying performance</li>
</ul>
<p dir="auto">For detailed vLLM deployment instructions, please refer to our <a href="https://github.com/MiniMax-AI/MiniMax-M1/blob/main/docs/vllm_deployment_guide.md">vLLM Deployment Guide</a>.
Alternatively, you can also deploy using Transformers directly. For detailed Transformers deployment instructions, you can see our <a href="https://github.com/MiniMax-AI/MiniMax-M1/blob/main/docs/transformers_deployment_guide.md">MiniMax-M1 Transformers Deployment Guide</a>.</p>

<p dir="auto">The MiniMax-M1 model supports function calling capabilities, enabling the model to identify when external functions need to be called and output function call parameters in a structured format. <a href="https://github.com/MiniMax-AI/MiniMax-M1/blob/main/docs/function_call_guide.md">MiniMax-M1 Function Call Guide</a> provides detailed instructions on how to use the function calling feature of MiniMax-M1.</p>

<p dir="auto">For general use and evaluation, we provide a <a href="https://chat.minimax.io/" rel="nofollow">Chatbot</a> with online search capabilities and the <a href="https://www.minimax.io/platform/" rel="nofollow">online API</a> for developers. For general use and evaluation, we provide the <a href="https://github.com/MiniMax-AI/MiniMax-MCP">MiniMax MCP Server</a> with video generation, image generation, speech synthesis, and voice cloning for developers.</p>

<p dir="auto">Contact us at <a href="mailto:model@minimax.io">model@minimax.io</a>.</p>
</article></div></div>
  </body>
</html>
