<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://mensfeld.pl/2022/11/ruby-concurrency-is-hard-how-i-became-a-ruby-on-rails-contributor/">Original</a>
    <h1>Ruby concurrency is hard: how I became a Ruby on Rails contributor</h1>
    
    <div id="readability-page-1" class="page"><div>
			
				
	  <div id="toc_container"><p>Table of Contents</p><ul><li><a href="#ephemeral-bug-from-a-test-suite"><span>1</span> Ephemeral bug from a test-suite</a></li><li><a href="#process-shutdown-coordination"><span>2</span> Process shutdown coordination</a></li><li><a href="#pinpointing-the-issue"><span>3</span> Pinpointing the issue</a></li><li><a href="#reproduction"><span>4</span> Reproduction</a></li><li><a href="#fixing-the-issue"><span>5</span> Fixing the issue</a></li><li><a href="#fixing-the-world"><span>6</span> Fixing the world</a><ul><li><a href="#rails-activesupport-and-actionview"><span>6.1</span> Rails (ActiveSupport and ActionView)</a></li><li><a href="#i18n"><span>6.2</span> i18n</a></li><li><a href="#dry-schema"><span>6.3</span> dry-schema</a></li><li><a href="#rom-factory"><span>6.4</span> rom-factory</a></li><li><a href="#other-repositories"><span>6.5</span> Other repositories</a></li></ul></li><li><a href="#summary"><span>7</span> Summary</a></li><li><a href="#afterwords"><span>8</span> Afterwords</a></li></ul></div>

<p>For the past several weeks, I&#39;ve been trying to fix a cranky spec in <a href="https://github.com/karafka/karafka/" title="Karafka">Karafka</a> integrations suite, which in the end, lead me to become a Ruby on Rails micro-contributor and submitting similar fix to several other high-popularity projects from the Ruby ecosystem. Here&#39;s my story of trying to make sense of my specs and Ruby concurrency.</p>
<h3><span id="ephemeral-bug-from-a-test-suite">Ephemeral bug from a test-suite</span></h3>
<p>Karafka is a Ruby and Rails multi-threaded efficient Kafka processing framework. To provide reliable OSS that is multi-threaded, I had to have the option to run my test suite concurrently to simulate how Karafka operates. Since it was a specific use case, I created my micro-framework.</p>
<p>Long story short: It runs end-to-end integration specs by running them in separate Ruby processes. Each starts Karafka, runs all the code in various configurations, connects to Kafka, checks assertions, and at the end, shuts down.</p>
<p><img decoding="async" src="https://mensfeld.pl/wp-content/uploads/2022/11/specsrunner.png" alt=""/></p>
<p>Such an approach allowed me to ensure that the process&#39;s whole lifecycle and its components work as expected. Specs are started with supervision, so in case of any hang, it will be killed after 5 minutes.</p>
<p>Karafka itself also has an internal shutdown supervisor. In case of a user shutdown request, if the shutdown takes longer than the defined expected time, Karafka will stop despite having things running. And this is what was happening with this single spec:</p>
<pre><code>E, [2022-11-19T16:47:49.602718 #14843] ERROR -- : Forceful Karafka server stop
F, [2022-11-19T16:47:49.602825 #14843] FATAL -- : #&lt;Karafka::Core::Monitoring::Event:0x0000562932d752b0 @id=&#34;error.occurred&#34;, @payload={:caller=&gt;Karafka::Server, :error=&gt;#&lt;Karafka::Errors::ForcefulShutdownError: Karafka::Errors::ForcefulShutdownError&gt;, :type=&gt;&#34;app.stopping.error&#34;}&gt;</code></pre>
<p><a href="https://github.com/karafka/karafka/actions/runs/3504293603/jobs/5869892047#step:8:195" title="This damn spec">This damn spec</a> did not want to stop!</p>
<p>Many things are working under the hood:</p>
<ul>
<li>workers that process jobs that could hang and force the process to wait</li>
<li>jobs queue that is also connected to the polling thread (to poll more data when no work is to be done)</li>
<li>listeners that poll data from Kafka that could hang</li>
<li>consumer groups with several threads polling Kafka data that might get stuck because of some underlying error</li>
<li>Other bugs in the coordination of work and states.</li>
</ul>
<p>One thing that certainly worked was the process supervision that would forcefully kill it after 30 seconds.</p>
<h3><span id="process-shutdown-coordination">Process shutdown coordination</span></h3>
<p>The graceful shutdown of such a process takes work. When you have many connections to Kafka, upon a poorly organized shutdown, you may trigger several rebalances that may cause short-lived topics assignments causing nothing except friction and potentially blocking the whole process.</p>
<p>To mitigate this, Karafka shuts down actively and gracefully. That is, until the absolute end, it claims the ownership of given topics and partitions, actively waiting for all the current work to be finished. This looks more or less like so:</p>
<p><img decoding="async" loading="lazy" width="611" height="541" src="https://mensfeld.pl/wp-content/uploads/2022/11/karafka-shutdown.png" alt="" srcset="https://mensfeld.pl/wp-content/uploads/2022/11/karafka-shutdown.png 611w, https://mensfeld.pl/wp-content/uploads/2022/11/karafka-shutdown-300x266.png 300w" sizes="(max-width: 611px) 100vw, 611px"/></p>
<p><strong>Note</strong>: Consumer groups internally in Karafka are a bit different than Kafka consumer groups. Here we focus on internal Karafka concepts.</p>
<h3><span id="pinpointing-the-issue">Pinpointing the issue</span></h3>
<p>After several failed attempts and fixing other bugs, I added a lot of extra instrumentation to check what Karafka hangs on. It was hanging because there were hanging listener threads!</p>
<p>As stated above, to close Karafka gracefully, all work from the jobs queue needs to be finished, and listeners that poll data from Kafka need to be able to exit the polling loops. It&#39;s all coordinated using a job queue. The job queue we&#39;re using is pretty complex with some blocking capabilities, and you can read about it <a href="https://mensfeld.pl/2022/01/reduce-your-method-calls-by-99-9-by-replacing-threadpass-with-queuepop/" title="here">here</a>, but the interesting part of the code can be reduced to this:</p>
<pre><code>@semaphores = Concurrent::Map.new { |h, k| h[k] = Queue.new }</code></pre>
<p>Those queues are used as semaphores in the polling loops until all the current work is done. Since each <code>Queue</code> is assigned to a different subscription group within its thread and hidden behind a concurrent map, there should be no problem. Right?</p>
<p><img decoding="async" loading="lazy" src="https://mensfeld.pl/wp-content/uploads/2022/11/meme.jpg" alt="" width="500" height="500" srcset="https://mensfeld.pl/wp-content/uploads/2022/11/meme.jpg 500w, https://mensfeld.pl/wp-content/uploads/2022/11/meme-300x300.jpg 300w, https://mensfeld.pl/wp-content/uploads/2022/11/meme-150x150.jpg 150w" sizes="(max-width: 500px) 100vw, 500px"/></p>
<h3><span id="reproduction">Reproduction</span></h3>
<p>Once I had my crazy suspicion, I decided to reduce it down to a proof of concept:</p>
<pre><code>require &#39;concurrent-ruby&#39;

100.times do
  ids = Set.new
  semaphores = Concurrent::Hash.new { |h, k| h[k] = Queue.new }

  100.times.map do
    Thread.new do
      ids &lt;&lt; semaphores[&#39;test&#39;].object_id
    end
  end.each(&amp;:join)

  raise &#34;I expected 1 semaphore but got #{ids.size}&#34; if ids.size != 1
end</code></pre>
<p>once executed, boom:</p>
<pre><code>poc.rb:13:in `&lt;main&gt;&#39;: I expected 1 semaphore but got 2 (RuntimeError)</code></pre>
<p>There is more than one semaphore for one listener! This caused Karafka to wait until forced to stop because the worker thread would use a different semaphore than the listener thread.</p>
<p>But how is that even possible?</p>
<p>Well, <code>Concurrent::Hash</code> and <code>Concurrent::Map</code> initialization is indeed thread-safe but not precisely as you would expect them to be. The docs state that:</p>
<blockquote>
<p>This version locks against the object itself for every method call, ensuring only one thread can be reading or writing at a time. This includes iteration methods like #each, which takes the lock repeatedly when reading an item.</p>
</blockquote>
<p>&#34;only one thread can be reading or writing at a time&#34;. However, we are doing both at different times. Our code:</p>
<pre><code>semaphores = Concurrent::Hash.new { |h, k| h[k] = Queue.new }</code></pre>
<p>is actually equivalent to:</p>
<pre><code>semaphores = Concurrent::Hash.new do |h, k|
  queue = Queue.new
  h[k] = queue
end</code></pre>
<p>and the block content is <strong>not</strong> locked fully. One threads queue can overwrite the other if the Ruby scheduler stops the execution in the middle. Here&#39;s the flow of things happening in the form of a diagram:</p>
<p><img decoding="async" loading="lazy" src="https://mensfeld.pl/wp-content/uploads/2022/11/dangling2.png" alt="" width="441" height="601"/></p>
<p>Once in a while listener would receive a dangling queue object, effectively blocking the polling process.</p>
<p><img decoding="async" loading="lazy" src="https://mensfeld.pl/wp-content/uploads/2022/11/where.jpeg" alt="" width="500" height="282" srcset="https://mensfeld.pl/wp-content/uploads/2022/11/where.jpeg 884w, https://mensfeld.pl/wp-content/uploads/2022/11/where-300x170.jpeg 300w, https://mensfeld.pl/wp-content/uploads/2022/11/where-768x434.jpeg 768w, https://mensfeld.pl/wp-content/uploads/2022/11/where-766x433.jpeg 766w" sizes="(max-width: 500px) 100vw, 500px"/></p>
<h3><span id="fixing-the-issue">Fixing the issue</span></h3>
<p>This can be fixed either by replacing the <code>Concurrent::Hash</code> with <code>Concurrent::Map</code> and using the <code>#compute_if_absent</code> method or by introducing a lock inside of the <code>Concurrent::Hash</code> initialization block:</p>
<pre><code>Concurrent::Map.new do |k, v|
  k.compute_if_absent(v) { [] }
end

mutex = Mutex.new

Concurrent::Hash.new do |k, v|
  mutex.synchronize do
    break k[v] if k.key?(v)
    k[v] = []
  end
end</code></pre>
<p>Okay, but what does Ruby on Rails and other projects do with all of this?</p>
<h3><span id="fixing-the-world">Fixing the world</span></h3>
<p>I figured out that if I made this mistake, maybe others did. I decided to check my local gems to find occurrences quickly. Inside my local gem cache, I executed the following code:</p>
<pre><code>fgrep -R &#39;Concurrent::Hash.new {&#39; ./
fgrep -R &#39;Concurrent::Hash.new do&#39; ./
fgrep -R &#39;Concurrent::Map.new {&#39; ./
fgrep -R &#39;Concurrent::Map.new do&#39; ./</code></pre>
<p>and validated that I&#39;m not an isolated case. I wasn&#39;t alone!</p>
<p>Then using <a href="https://sourcegraph.com/search" title="Sourcegraph">Sourcegraph</a> I pinpointed a few projects that had the potential for fixes:</p>
<ul>
<li>rails (activesupport and actionview)</li>
<li>i18n</li>
<li>dry-schema</li>
<li>finite_machine</li>
<li>graphql-ruby</li>
<li>rom-factory</li>
<li>apache  whimsy</li>
<li>krane</li>
<li>puppet</li>
</ul>

<p>I am not a domain expert in any of those, and understanding the severity of each was beyond my time constraints, but I decided to give it a shot.</p>
<h4><span id="rails-activesupport-and-actionview">Rails (ActiveSupport and ActionView)</span></h4>
<p>Within Rails, this &#34;pattern&#34; was used twice: in ActiveSupport and ActionView.</p>
<p>In ActionView, it was used within a cache:</p>
<pre><code>PREFIXED_PARTIAL_NAMES = Concurrent::Map.new do |h, k|
  h[k] = Concurrent::Map.new
end</code></pre>
<p>and assuming that the cached result is stateless (same result each time for the same key), the issue could only cause an extra computation upon first parallel requests to this cache.</p>
<p>In the case of ActiveSupport, none of the concurrency code was needed, so I just replaced it with a simple <code>Hash</code>.</p>
<p>Both, luckily, were not that severe, though worth fixing nonetheless.</p>
<p>PR: <a href="https://github.com/rails/rails/pull/46536">https://github.com/rails/rails/pull/46536</a></p>
<p>Both were merged, and this is how I became a Ruby on Rails contributor :)</p>
<h4><span id="i18n">i18n</span></h4>
<p>This case was slightly more interesting because the concurrent cache stores all translations. In theory, this could cause similar leakage as in Karafka, effectively losing a language by loading it to a different <code>Concurrent::Hash</code>:</p>
<pre><code>100.times.map do
  Thread.new do
    I18n.backend.store_translations(rand.to_s, :foo =&gt; { :bar =&gt; &#39;bar&#39;, :baz =&gt; &#39;baz&#39; })
  end
end.each(&amp;:join)

I18n.available_locales.count #=&gt; 1</code></pre>
<p>This could lead to hard-to-debug problems. Once in a while, your system could raise something like this:</p>
<pre><code>:en is not a valid locale (I18n::InvalidLocale)</code></pre>
<p>without an apparent reason, and this problem would go away after a restart.</p>
<p>PR: <a href="https://github.com/ruby-i18n/i18n/pull/644">https://github.com/ruby-i18n/i18n/pull/644</a></p>
<h4><span id="dry-schema">dry-schema</span></h4>
<p>Another cache case where the risk would revolve around double-computing.</p>
<p>PR: <a href="https://github.com/dry-rb/dry-schema/pull/440">https://github.com/dry-rb/dry-schema/pull/440</a></p>
<h4><span id="rom-factory">rom-factory</span></h4>
<p>This one is interesting! Let&#39;s reduce the code to a smaller POC first and see what will happen under heavy threading:</p>
<pre><code>require &#39;singleton&#39;
require &#39;concurrent-ruby&#39;

class Sequences
  include Singleton

  attr_reader :registry

  def initialize
    reset
  end

  def next(key)
    registry[key] += 1
  end

  def reset
    @registry = Concurrent::Map.new { |h, k| h[k] = 0 }
    self
  end
end

seq = Sequences.instance

loop do
  100.times.map do
    Thread.new { seq.next(&#39;boom&#39;) }
  end.each(&amp;:join)

  size = seq.registry[&#39;boom&#39;]

  raise &#34;Wanted 100 but got #{size}&#34; unless size == 100

  seq.reset
end</code></pre>
<pre><code>poc.rb:37:in `block in &lt;main&gt;&#39;: Wanted 100 but got 1 (RuntimeError)</code></pre>
<p>The counter value gets biased. What is even more interesting is that making the map safe won&#39;t be enough:</p>
<pre><code>@registry = Concurrent::Map.new { |h, k| h.compute_if_absent(k) { 0 } }</code></pre>
<pre><code>poc.rb:36:in `block in &lt;main&gt;&#39;: Wanted 100 but got 55 (RuntimeError)</code></pre>
<p>there is one more &#34;unsafe&#34; method:</p>
<pre><code>def next(key)
  registry[key] += 1
end</code></pre>
<p>this operation also is not atomic, thus needs to be wrapped with a mutex:</p>
<pre><code>def initialize
  @mutex = Mutex.new
  reset
end

def next(key)
  @mutex.synchronize do
    registry[key] += 1
  end
end</code></pre>
<p>Only then is this code safe to be used.</p>
<p><a href="https://github.com/rom-rb/rom-factory/pull/80">https://github.com/rom-rb/rom-factory/pull/80</a></p>
<h4><span id="other-repositories">Other repositories</span></h4>
<ul>
<li>finite-machine: <a href="https://github.com/piotrmurach/finite_machine/pull/77">https://github.com/piotrmurach/finite_machine/pull/77</a></li>
<li>graphql-Ruby: <a href="https://github.com/rmosolgo/graphql-ruby/pull/4251">https://github.com/rmosolgo/graphql-ruby/pull/4251</a></li>
<li>Apache Whimsy: <a href="https://github.com/apache/whimsy/pull/169">https://github.com/apache/whimsy/pull/169</a></li>
<li>Puppet: <a href="https://github.com/puppetlabs/puppet/pull/8951">https://github.com/puppetlabs/puppet/pull/8951</a></li>
<li>Shopify Krane: <a href="https://github.com/Shopify/krane/pull/911">https://github.com/Shopify/krane/pull/911</a></li>
<li>Issue reported in the concurrent-ruby repo: <a href="https://github.com/ruby-concurrency/concurrent-ruby/issues/970">https://github.com/ruby-concurrency/concurrent-ruby/issues/970</a></li>
</ul>
<h3><span id="summary">Summary</span></h3>
<p>In my opinion, there are a few outcomes of this story:</p>
<ul>
<li>Karafka has a solid test-suite!</li>
<li>If you are doing concurrency-related work, you better test it in a multi-threaded environment and test it well.</li>
<li>Concurrency is hard to many of us (maybe that&#39;s because we are special ;) ).</li>
<li>RTFM and read it well :)</li>
<li>Do not be afraid to help others by submitting pull requests!</li>
</ul>
<p>
On the other hand, looking at the frequency of this issue, it may be worth opening a discussion about changing this behavior and making the initialization fully locked.
</p>
<h3><span id="afterwords">Afterwords</span></h3>
<p><code>Concurrent::Hash</code> under cRuby is just a <code>Hash</code>. You can check it out <a href="https://github.com/ruby-concurrency/concurrent-ruby/blob/master/lib/concurrent-ruby/concurrent/hash.rb#L21" title="here">here</a>.</p>
<hr/>
<p>Cover photo by <a href="https://www.flickr.com/photos/kulor/3860722889/"> James Broad</a> on <a href="https://creativecommons.org/licenses/by-nc-sa/2.0/" title="Attribution-NonCommercial-ShareAlike 2.0 Generic (CC BY-NC-SA 2.0)">Attribution-NonCommercial-ShareAlike 2.0 Generic (CC BY-NC-SA 2.0)</a>. Image has been cropped.</p>

				
			</div></div>
  </body>
</html>
