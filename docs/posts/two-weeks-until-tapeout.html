<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://essenceia.github.io/projects/two_weeks_until_tapeout/">Original</a>
    <h1>Two Weeks Until Tapeout</h1>
    
    <div id="readability-page-1" class="page"><div><div><h2>Living under rocks<span><a href="#living-under-rocks" aria-label="Anchor">#</a></span></h2><p>As anyone that hasn’t been living under a rock might have heard, AI accelerators are the coolest kids in town these days. And although I have never been part of the “in” crowd, this time at least, I get the appeal.</p><p>So when the opportunity arose to join an experimental shuttle using global foundries 180nm for FREE I jumped onto the opportunity and designed my own JTAG!</p><p>…</p><p>I’m sorry? Is this not what you were expecting?</p><p>Frankly, I would love to tell you a great story about how I went into this wanting to design a free and open source silicon proven AI accelerator that the community could freely extend and re-use in their own projects. But in truth this project started out first as me wanting to design some far less sexy, in-silicon debug infrastructure and only later came to include the systolic matrix matrix multiplication accelerator … to serve as the design under test.</p><p>No wonder I was never one of the cool kids.</p><p>Also, I’m designing everything from scratch and have only two weeks left, welcome to the crunch.</p><figure><img src="https://hannahilea.com/projects/two_weeks_until_tapeout/feature_layout.png" alt="chip render"/><figcaption>GDS rendering of this project using the GF180 PDK</figcaption></figure><p><span><span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentcolor" d="M506.3 417 293 53c-16.33-28-57.54-28-73.98.0l-213.2 364C-10.59 444.9 9.849 480 42.74 480h426.6c32.76.0 53.26-35 36.96-63zM232 168c0-13.25 10.75-24 24-24s24 10.8 24 24v128c0 13.25-10.75 24-23.1 24S232 309.3 232 296V168zm24 248c-17.36.0-31.44-14.08-31.44-31.44s14.07-31.44 31.44-31.44 31.44 14.08 31.44 31.44C287.4 401.9 273.4 416 256 416z"></path></svg>
</span></span><span>If you are looking for a more formal overview of this ASIC, you can find the datasheet <a href="https://github.com/Essenceia/Systolic_MAC_with_DFT/blob/main/docs/info.md" target="_blank">here</a></span></p><h3>Experimental shuttle<span><a href="#experimental-shuttle" aria-label="Anchor">#</a></span></h3><p>Once again this tapeout was done as part of a Tiny Tapeout shuttle, but this time, it went out as not part of a public but an experimental shuttle.</p><p><span><span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentcolor" d="M47.6 300.4 228.3 469.1c7.5 7 17.4 10.9 27.7 10.9s20.2-3.9 27.7-10.9L464.4 300.4c30.4-28.3 47.6-68 47.6-109.5v-5.8c0-69.9-50.5-129.5-119.4-141C347 36.5 300.6 51.4 268 84L256 96 244 84c-32.6-32.6-79-47.5-124.6-39.9C50.5 55.6.0 115.2.0 185.1v5.8c0 41.5 17.2 81.2 47.6 109.5z"></path></svg>
</span></span><span>You can learn more about the awesome Tiny Tapeout shuttle programs at the official website: <a href="https://tinytapeout.com/" target="_blank">https://tinytapeout.com</a></span></p><p>These experimental shuttles are used as testing grounds for new nodes and flows in order to iron out issues before they are opened to the public.</p><p>Participation in these experimental shuttles is commonly reserved to contributors having previously submitted to Tiny Tapeout.</p><p>This limitation was set in place in order to help select for veteran designers as these experimental tapeout typically have less stable tooling and the final chip doesn’t feature the same level of inter design isolation as in a public tapeout.</p><p>Contributions to these shuttles are done with the understanding that the resulting chip might not be functional for some reason outside of the designers control.</p><p>Given these limitations, the Tiny Tapeout program is generously making submissions to these shuttles free of charge.</p><p>In practice, this makes area effectively free, explaining the higher occurrence of absolutely massive designs being submitted.</p><figure><img src="https://hannahilea.com/projects/two_weeks_until_tapeout/tt_gf02.png" alt="chip render"/><figcaption>Full GDS render of the GF 0.2 Tiny Tapeout chip, with a lot of large multi-tile designs.</figcaption></figure><p>If the final chip is deemed sufficiently functional, the resulting ASICs along with the dev board will be available for purchase at the <a href="https://store.tinytapeout.com/" target="_blank">Tiny Tapeout store</a>.</p><p>Given you need to have taped out a chip with Tiny Tapeout before to be eligible, I became eligible 14 days before the experimental shuttle submission deadline.</p><h2>Combo<span><a href="#combo" aria-label="Anchor">#</a></span></h2><p>Before we start, let us acknowledge what I am attempting to do, alone.</p><p>Now that safety precautions are out of the way:</p><p>Welcome to a tale of two designs.</p><p>The first, is the systolic array, typically found at the heart of any AI inference accelerator, its function is to perform matrix-matrix multiplications.</p><p>The other is our silicon debug infrastructure, namely the all ubiquitous JTAG TAP component. Its goal is to provide something to latch onto when my ASIC comes back as an expensive brick and I am frantically trying to figure out where I fucked up. Given I wish to trust it not to be broken, having something that is proven early is very important since my masterplan is to slap it on all my future tapeouts.</p><h2>Project Roadmap<span><a href="#project-roadmap" aria-label="Anchor">#</a></span></h2><p>Alright, I have to admit something: <del>I embellished reality in order to make myself look good</del> I lied. Although initially I had 2 weeks to do this tapeout,
because I spent the first 4 days reeling from the after effects of my previous tapeout (aka: sleeping, going outside and talking to another human being) and “deciding on a technical direction” which is corporate speech for describing a mixture between “procrastinating” and “figuring out what I could build without sacrificing too much of my remaining sanity”, I now had 10 days left. You’re welcome.</p><p>Given my self-imposed dire straits of a timeline, if I wanted to have any hope whatsoever of meeting the tapeout deadline I needed a battle plan: here is the roadmap.</p><div><pre>---
config:
  logLevel: &#39;debug&#39;
  theme: &#39;default&#39;
  gitGraph:
    showBranches: true
    mainBranchName: &#39;architecture&#39;
    mainBranchOrder: 6
---
      gitGraph TB:
        commit id: &#34;idea &#34;
        commit id: &#34;figured it out &#34;
        branch design order: 4
        checkout design
        commit id: &#39;basic RTL &#39;
        branch simulation  order: 5
        checkout simulation 
        commit id: &#39;this RTL is broken &#39;
        checkout design 
        commit id: &#39;starts to work &#39;
        branch implementation  order: 3
        checkout implementation
        commit id: &#39;RIP timing &#39;
        commit id: &#39;RIP area &#39;
        checkout design
        commit id: &#39;looking good &#39;
        branch emulation  order: 2
        checkout emulation
        commit id: &#39;bitstream acquired &#39;
        branch firmware
        commit id: &#39;firmware bringup &#39;
        checkout emulation
        merge firmware
        checkout design
        merge emulation
        merge simulation
        checkout implementation
        merge design
        commit id: &#39;tapeout! &#39;
</pre></div><ul><li>architecture: what I need to build and how components would interface with one another.</li><li>design: where most of the RTL design takes place.</li><li>simulation: I write tests for simulating and validating that my design is behaving correctly and without any identifiable bugs. I used the classic Cocotb wrapper around iverilog for this.</li><li>FPGA emulation: when the design has mostly taken shape is when emulation takes place. This is the step where I port the design to an FPGA.</li><li>firmware: Alongside the emulation I bring up the firmware to interface with my design. This allows me to validate there are no issues when interfacing between the MCU and the ASIC.</li><li>implementation: this is when the ASIC flow is run and is the longest running task. It starts being run when the RTL design starts becoming functional to identify and fix timing and area utilization issues. And once all the verification is finished, it is run one final time to generate the final ASIC GDSII (manufacturing files).</li></ul><p>The most astute readers might have noticed that this grand strategy is pretty much the same roadmap I always use.</p><blockquote><p>If it aint broken dont fix it.
~ a wise man</p></blockquote><h3>Flow saves the day<span><a href="#flow-saves-the-day" aria-label="Anchor">#</a></span></h3><p>So, why am I doing this to myself? Well, self delusion is a powerful force, and it was telling me this timeline would be possible if I leveraged my previous experience with the Tiny Tapeout/Librelane/OpenROAD flows, my existing personal linting/simulation/fpga/firmware flows, my existing code bases, and my own <del>ingrained knowledge of the dark arts</del> experience.</p><p>But, let us not delude ourselves, the saving grace of this terrible idea was really just how great the Tiny Tapeout/Librelane/OpenROAD ASIC flow is.</p><p><a href="https://openroad.readthedocs.io/en/latest/" target="_blank">The OpenROAD project</a> was conceived with a no-human-in-the-loop (NHIL) target, and the goal of enabling 24-hour-or-less design turnaround times.</p><p><a href="https://librelane.readthedocs.io/en/latest/" target="_blank">Librelane</a>, the master coordinator of the flow itself, brings together
OpenROAD, Yoysy, ABC, Magic, and many more amazing open source tools, building on top of this philosophy.
Creating a process that takes you from your verilog and a few configurations all the way to the tapeout ready artifacts, in an extremely streamlined and fast fashion, requiring minimal human intervention.</p><p>Tiny Tapeout then completes the loop, running your testbenches on top of the entire implementation, and then allowing you to automatically upload your GDSII for integration into the shuttle chip.</p><p>This deeply resonates with my personal beliefs that faster iteration times are central to higher quality and more efficient design :</p><blockquote><p>Since I believe a low iteration time is paramount to project velocity and getting big things done, I also want to automatize all of the Vivado flow from taking the rtl to the SVF generation.</p></blockquote><p>Thus, not only was I building on top of a legacy of efficient design flows, but I had previously <del>spent</del> invested a lot of time streamlining my tasks, especially repetitive ones.</p><p>A classic example would be my FPGA build flow used for emulation. It only requires a single command to create the Vivado project, read all the rtl and constraint files, synthesize, optionally add an ILA core and connect any wires marked for debug to it, implement, and then flash the bitstream :</p><p>Essentially, the bottleneck to making this design, from scratch in 10 days, wasn’t going to be the tools, but the squishy human between the chair and the keyboard.</p><figure><img src="https://hannahilea.com/projects/two_weeks_until_tapeout/homo_electronicus.jpg" alt="me only my couch"/><figcaption><strong>homo electro-engineerus</strong> observed in its natural habitat in a pre-tapeout hibernation period known as a ‘crunch’. During this period, the specimen will seldom move from its cave, surviving exclusively on a diet of ‘coffee’ and ‘HEB smoked ham’.</figcaption></figure><h2>Design<span><a href="#design" aria-label="Anchor">#</a></span></h2><p>Without further ado, let’s talk design !</p><h2>Systolic Array Design<span><a href="#systolic-array-design" aria-label="Anchor">#</a></span></h2><p>The goal of this systolic array is to perform a 2×2 matrix-matrix multiply on 8-bit integer numbers.</p><p>Without going too much into detail on why systolic arrays are the recurring stars at the heart of modern AI inference accelerators,
their main strength is achieving a high ratio of compute to everything else. And since memory operations are the most
expensive family of operations by far, a hh ratio of compute to memory operations.</p><p>Data is recirculated directly within the array and reused across multiple consecutive operations rather than
being repeatedly fetched/written from/to memory. This matters because memory accesses are expensive.
SRAM accesses cost time and significant power, while DRAM accesses cost eternities of time and egregious amounts of power.
Compute operations, even 64 bit floating point multiplications, are by comparison, cheap.</p><p>Thus, the larger the systolic array, the deeper the chain of compute, the better this compute to memory ratio becomes.</p><h4>Energy ratio<span><a href="#energy-ratio" aria-label="Anchor">#</a></span></h4><p><span></span><span>The following sub-section is me geeking out on power consumption numbers.
If you don’t have a deeply engrained passion for discussing pJ (pico Joules) you can safely skip it, I won’t judge you.</span></p><p>As an illustrative example of this evolution of compute ratios, let us compare the power cost of 64 bit floating point multiply-add (MAC) operations in a hypothetical systolic array designed on a 45nm node running at 0.9V.</p><p>Compared with the energy expenditure needed to access this data using 256 bit wide reads to the 16nm DRAM. DRAM access costs will include the 10mm of wire, interface and access costs.</p><p>In this example, we will very generously assume the weights are stored in place and do not need to be updated, so will assume only the input data matrix needs to be read from DRAM.</p><table><thead><tr><th>Operation</th><th>45 nm</th></tr></thead><tbody><tr><td>16-bit integer multiply</td><td>2 pJ</td></tr><tr><td>64-bit floating-point multiply-add</td><td>50 pJ</td></tr><tr><td>64-bit access to 8-Kbyte SRAM</td><td>14 pJ</td></tr><tr><td>256-bit access to 1-Mbyte SRAM</td><td>566 pJ</td></tr><tr><td>256-bit 10 mm wire</td><td>310 pJ</td></tr><tr><td>256-bit DRAM interface</td><td>5,120 pJ</td></tr><tr><td>256-bit DRAM access</td><td>2,048 pJ</td></tr></tbody></table><p>source: <a href="https://chipgen.stanford.edu/people/alum/pdf/1309_KrishnaMalladi_EnergyProportionalMem.pdf" target="_blank">ENERGY PROPORTIONAL MEMORY SYSTEMS</a></p><p>Even though I purposefully chose 64 bit floats, the most energy intensive arithmetic operation,
we still required a 64x64 systolic array before the cost of compute started exceeding the cost of the initial DRAM value reads.</p><p>aka: For those not living in 2026, we have uncovered a new clue to the mystery of where all the low-power DRAM chips have suddenly vanished to!</p><h4>Scaling<span><a href="#scaling" aria-label="Anchor">#</a></span></h4><p>Another great feature of systolic arrays is how regular they are and how well their design scales. So, although today I am designing a small 2x2 array, without much re-work this can be scaled up to a larger 256x256 array.</p><p>Some of you might be wondering: if area is free and systolic arrays scale so well, why am I limiting myself to only making a 2x2 array ?</p><p>Well, because I am a good neighbor and any additional tile of area I use is potentially depriving someone else from having the area available to submit their project.</p><p>Since the initial motivation for this project was to design some proven in silicon debug infrastructure, a 2x2 array is sufficient for my needs.</p><h3>Constraints<span><a href="#constraints" aria-label="Anchor">#</a></span></h3><p>Since this ASIC is once again taping out as part of a Tiny Tapeout shuttle, it has to grapple with the similar limitations as my <a href="https://essenceia.github.io/projects/blake2s_hashing_accelerator_a_solo_tapeout_journey/#io-bottleneck" target="_blank">previous hashing accelerator</a>, namely: the eternal I/O bandwidth limitation!</p><figure><img src="https://hannahilea.com/projects/two_weeks_until_tapeout/chip.svg" alt="chip schematic"/><figcaption>Tiny Tapeout chip (I recommend switching the page to light mode for better readability of the pin names)</figcaption></figure><p>This limitations comes in two flavors:</p><ol><li>Pin count: eight input pins, eight output pins, and eight configurable I/O pins, limiting my parallel buses in and out of the accelerator.</li><li>Maximum operating frequency: unlike with the well-trodden path that was the public Skywater 130nm shuttle tapeout, for this experimental shuttle the maximum switching frequency of these pins hasn’t been characterized yet. And since I haven’t yet figured out how to do this characterization using a simulator myself, I’ve hand-wavingly assumed that both the input and output directions have a sustainable switching frequency of 50 MHz, and have sized the path timings around that assumption.</li></ol><p>Additionally, I once again have the constraint of not having any SRAM. Though unlike with the Skywater 130 tapeout, the GlobalFoundries 180nm PDK does include a proven SRAM macro!</p><p>Hooray! Human progress is unstoppable !</p><p>This time, the limitation was actually imposed by the experimental nature of this shuttle.</p><p>Firstly, the flow didn’t initially support these macros out of the box. More specifically in the way they were laid out, which led to a slew of DRC failures that needed to be fixed.</p><p>Secondly, this experimental shuttle didn’t provide individual project power gating. As such, integrating this SRAM macro was commonly deemed not the best idea, and the community collectively agreed to wait for a future shuttle, which would include per-project macro power gating, before including it.</p><h3>Design Details<span><a href="#design-details" aria-label="Anchor">#</a></span></h3><p>This system is broken into two parts :</p><ul><li>the compute units</li><li>the main array controller</li></ul><h3>Compute units<span><a href="#compute-units" aria-label="Anchor">#</a></span></h3><p>Since this is a 2×2 systolic array, there are four compute units. Each unit takes in an 8 bit signed integer and performs a multiply, addition, and a clamping operation, producing 8 bit signed integers.</p><figure><img src="https://hannahilea.com/projects/two_weeks_until_tapeout/compute_unit.svg" alt="shematic"/><figcaption>Compute unit critical path.</figcaption></figure><h4>Multiplication<span><a href="#multiplication" aria-label="Anchor">#</a></span></h4><p>The multiply is done using a custom (from scratch) implementation of a Booth Radix-4 multiplier with Wallace trees.</p><p>This multiplier architecture strikes a good balance between area, power and performance, and can be regarded as the multiplier equivalent of what “Rental White™&#34;[1] is to interior design.</p><p>Meaning it is a solid, well rounded from a PPA’s perspective, multiplier option, that without being anything novel or groundbreaking, is probably good enough for your use case (and given my +2ns of worst negative slack, and comfortable area occupancy, it was plenty good enough for mine).</p><p>Another advantage of booth radix-4 is that, since we are performing a signed multiplication, we can optimize out a level in the Wallace tree we are using for the partial product additions given we only have 4 partial products, unlike the 5 needed for unsigned operations.</p><p><span></span><span><p>The original article plan included an in-depth explanation of the booth radix-4 multiplication implementation and optimization, resulting in a very interesting but also very dry multi-page explanation covered with boolean algebra. Resulting in its canning.</p><p>If you are looking for a good explanation of this multiplier and its optimization see chapter 11 of ‘CMOS VLSI Design: A Circuits and Systems Perspective’.</p><p><a href="https://pages.hmc.edu/harris/cmosvlsi/4e/index.html" target="_blank">Link to David Money Harris (co-author) blog.</a></p></span></p><h4>Clamping<span><a href="#clamping" aria-label="Anchor">#</a></span></h4><p>The clamping operation occurs after both the multiply and addition operations. At which point the data is now 17 bit wide, and since we want to prevent our data size from exploding, the clamping operation is needed to clamp the outgoing data back down to eight bits.</p><p>$$
clamp_{i8}(x) = \begin{cases}
\phantom{-}127,\,\text{if}\,x &gt; 127, \\
\phantom{-12}x,\,\text{if}\,x \in [-128,127], \\
-128,\,\text{if}\,x &lt; -128
\end{cases}
$$</p><h4>In place weight storage<span><a href="#in-place-weight-storage" aria-label="Anchor">#</a></span></h4><p>Given that the weights have high temporal and spatial locality, meaning the same set of weights can be reused over multiple unique input data matrices, in order to save on bandwidth, the choice was made to store an 8 bit weight in place inside of each unit.</p><p>A separate control sequence allows the user to load a new set of weights inside each of the units.
The weight packet is sent over four consecutive cycles using the same input interface as the data matrix.</p><h3>Array controller<span><a href="#array-controller" aria-label="Anchor">#</a></span></h3><p>Given the way in which the matrix matrix multiplication is performed using a systolic array, the input data matrix needs to be shaped and fed to the array in a staggered manner.</p><p>Understandably readers might not instinctively get what I mean by “the data needs to be shaped”.</p><p>In order to help better illustrate this point, I would like to bring your attention to a great animation to show how data flows through the array.</p><p>An added bonus is that this animation is also of a 2×2 systolic array, such that it shares the same data with the same arrival constraints as my accelerator.</p><figure><img src="https://hannahilea.com/projects/two_weeks_until_tapeout/systolic_array.gif" alt=""/><figcaption>Credit : Pan, William. (2025). Systolic Array Simulator. GitHub Repository.<a href="https://github.com/wp4032/william-pan.com" target="_blank">https://github.com/wp4032/william-pan.com</a></figcaption></figure><p><span><span><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 512 512"><path fill="currentcolor" d="M256 0C114.6.0.0 114.6.0 256s114.6 256 256 256 256-114.6 256-256S397.4.0 256 0zm0 128c17.67.0 32 14.33 32 32 0 17.67-14.33 32-32 32s-32-14.3-32-32 14.3-32 32-32zm40 256h-80c-13.2.0-24-10.7-24-24s10.75-24 24-24h16v-64h-8c-13.25.0-24-10.75-24-24s10.8-24 24-24h32c13.25.0 24 10.75 24 24v88h16c13.25.0 24 10.75 24 24s-10.7 24-24 24z"></path></svg>
</span></span><span><p>This animation is not a carbon copy of my accelerator. Rather, readers should use this animation as a tool to better understand how data flows in a
systolic array and how it results in the computation of a matrix-matrix multiplication. For the sake of completeness, I would like to point out the major differences with my implementation:</p><ul><li>this animation uses floating-point numbers, I am using 8-bit integers</li><li>there is no clamping step</li><li>the timings are not entirely identical. In my accelerator, many more operations occur on the same cycle. Granted, this was probably done in an effort to help make the animation more legible.</li></ul></span></p><p>In addition to helping shape the input data to the systolic array, this controller also helps coordinate data transfers around my I/O limitations.</p><p>Given the parallel data bus allows only 8 bits of input data to arrive per cycle, it is used to control the input buffers in order to accumulate enough data to create the next wave.</p><p>Similarly on the output side, when the accelerator produces two 8-bit results per cycle, the controller stores the results in an output buffer in order to only stream out 8 bits per cycle.</p><figure><img src="https://hannahilea.com/projects/two_weeks_until_tapeout/array_controller.svg" alt="shematic"/><figcaption>Array Controller interfacing with both the input and output data buffers.</figcaption></figure><h3>Validation<span><a href="#validation" aria-label="Anchor">#</a></span></h3><p>Validation was an extremely important step for this systolic array, particularly for validating my custom implementation of the Booth Radix-4 multiplication.</p><p>Once again, I used Cocotb as the abstracting layer allowing me to interface with multiple different simulators. Namely, icarus verilog for my standard verification and CVC for the post implementation timing annotated netlist.</p><p>Given the nature of the problem, I made extensive use of randomization in order to get better testing coverage and attempt to hit corner cases that would not have been revealed using a directed approach. This randomization randomized both the values of the inputs weight and data, and also the timings with which this incoming data was fed over the parallel bus to the accelerator.</p><h3>Firmware<span><a href="#firmware" aria-label="Anchor">#</a></span></h3><p>The firmware used to interface with this accelerator was designed to run on the RP2040 Raspberry Pi silicon and used the PIO hardware block to drive the parallel port.</p><p>I followed a similar approach as with my hashing accelerator, co-designing with the PIO imposed limitation when designing the parallel bus protocol.</p><p>Although this was designed for an RP2040, I later learned that the Tiny Tapeout boards would be evolving to a new version of the chip. These new PCBs would use a different pinout layout for communicating with the ASIC chips.</p><p>Although this will necessitate to re-adapt parts of the firmware for the new dev boards, this shouldn’t cause any major incompatibilities.</p><h2>JTAG TAP Design<span><a href="#jtag-tap-design" aria-label="Anchor">#</a></span></h2><p>The second major component of this design and admittedly the actual principle piece of this ASIC is the JTAG TAP.</p><p>As stated earlier when my ASIC comes back as a glorified paperweight I will suddenly have a strong and immediate need for some
kind of hardware block providing some in-silicon observability.</p><p>This is absolutely crucial, as it isn’t a question of if but when one of my ASIC will have hardware issues.</p><p>As such, this TAP is actually a part of my larger efforts to help produce a set of DFT (Design for Test) proven IPs/tools that I can integrate into all of my future ASICs. As such, I have quite an incentive to have these designs proven early.</p><p>JTAG was chosen as it is a very common debug protocol. Not only is it well-defined but has good off-the-shelf support, both on the hardware (debug probes) and software side.</p><h3>JTAG Implementation<span><a href="#jtag-implementation" aria-label="Anchor">#</a></span></h3><p>In addition to implementing all of the basic JTAG features in order to be compliant with the protocol, I additionally added custom instructions, extending it to fit my personal requirements.</p><p>Required instructions :</p><ul><li><code>EXTEST</code>, opcode <code>0x0</code>, boundary scan operation</li><li><code>IDCODE</code>, opcode <code>0x1</code>, read JTAG tap identifiers, which allows the hardware to advertise itself on the JTAG scan chain</li><li><code>SAMPLE_PRELOAD</code>, opcode <code>0x2</code>, boundary scan operation</li><li><code>BYPASS</code>, opcode <code>0x7</code>, set the TAP in bypass mode</li></ul><p>Custom instructions :</p><ul><li><code>USER_REG</code>, opcode <code>0x3</code>, custom instruction used to probe the internal registers</li></ul><p>The systolic array is quite a deep structure in the sense that the data is directly reused as it is recirculated within the
array.</p><p>As such, it is very easy to lose track of what the internal state is, having only the input and output observable to the user.
Although this might stay manageable with a 2 x 2 array.
As the structure grows larger, this will start to become more and more of an issue.</p><p>In order to help address this future pain point, I added the custom <code>USER_REG</code> JTAG
instruction to read the current state of a target compute units internal registers.</p><p><a href="https://github.com/Essenceia/Systolic_MAC_with_DFT/tree/main?tab=readme-ov-file#user_reg" target="_blank">Link to the datasheet of the <code>USER_REG</code> instruction.</a></p><h3>Design<span><a href="#design-1" aria-label="Anchor">#</a></span></h3><p>The JTAG TAP design itself is quite straightforward as JTAG was conceived as a hardware first protocol, and this shows
in its implementation. The design clearly flows from the JTAG specification to the RTL (unlike you BLAKE2 I am looking at you!).
As such I do not think it is worthwhile to discuss it in detail.</p><p>What makes this design more interesting is how the JTAG and the systolic array live in two different clock domains. Making this accelerator have not one but two separate clock trees.</p><p>On the altar of this noble cause, I sacrificed one of my precious data input pins to serve as the JTAG clock input (TCK).</p><figure><img src="https://hannahilea.com/projects/two_weeks_until_tapeout/array_clk.webp" alt=""/><figcaption>Clock tree of clk, the clock from the systolic array.</figcaption></figure></div></div></div>
  </body>
</html>
