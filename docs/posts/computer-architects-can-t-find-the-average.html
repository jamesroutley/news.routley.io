<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://dgsq.net/2025-04-27-averages/">Original</a>
    <h1>Computer Architects Can&#39;t Find the Average</h1>
    
    <div id="readability-page-1" class="page"><div>
        <p>Computer architects can’t agree on a way to find the average.</p>

<p>For years, academic practitioners in this field have been arguing about the appropriate way to summarize the average performance of their designs.<sup id="fnref:arguments" role="doc-noteref"><a href="#fn:arguments" rel="footnote">1</a></sup> That is: given \(n\) workloads, if system \(A\) outperforms system \(B\) by \(S_1, S_2, \ldots, S_n\) on each, how much faster should you say system \(A\) is, on average? I think this argument is kind of pointless through.</p>

<p>For the most part, people tend to use the arithmetic mean \(\left(\frac{1}{n} \sum_{i=1}^n S_i\right)\) or the geometric mean \(\left(\sqrt[n]{\prod_{i=1}^n S_i}\right)\). Henessey and Patterson’s famous <em>Computer Architecture: A Quantitative Approach</em> advocates for the latter:</p>
<blockquote>
  <p>Using the geometric mean ensures two important properties:</p>
  <ol>
    <li>The geometric mean of the ratios is the same as the ratio of the geometric means.</li>
    <li>The ratio of the geometric means is equal to the geometric mean of the performance ratios, which implies that the choice of the reference computer is irrelevant.</li>
  </ol>

  <p>Therefore the motivations to use the geometric mean are substantial, especially when we use performance ratios to make comparisons.</p>
</blockquote>

<p>Other people disagree with H&amp;P’s reasoning, but I think it’s just about as good as it gets.</p>



<p>Recently (well, over a year ago now), a <a href="https://ieeexplore.ieee.org/document/10419888">paper</a> appeared in <em>IEEE Computer Architecture Letters</em> with the title <em>R.I.P. Geomean Speedup Use Equal-Work (Or Equal-Time) Harmonic Mean Speedup Instead</em>. Its author, Eeckhout, argues that geomean is bad, and people should instead be using what he calls the <em>Equal-Work Harmonic Speedup</em> or the <em>Equal-Time Harmonic Speedup</em>. Eeckhout also presented this work at <a href="https://hpca-conf.org/2025/main-program/">HPCA 2025</a> as a part of the <em>Best of Computer Architecture Letters</em> session.</p>

<p>The main thing that Eeckhout seems to dislike about the geometric mean is that it “lacks physical meaning.” He claims that using one of his alternatives is better because they have physical meaning. One of the alternatives that he proposes is the <em>Equal-Time Harmonic Speedup</em> (\(ETS\)), which is just the harmonic mean of the speedups observed on each workload.</p><p>

\[ETS = \frac{n}{\sum_{i=1}^n \frac{1}{S_i}}\]

</p><p>Why use the Harmonic Mean instead of the Geometric Mean? Well, if every workload takes the same amount of time to run on the baseline system, the ETS is equal to the total speedup observed when running each of those workloads sequentially.<sup id="fnref:ets" role="doc-noteref"><a href="#fn:ets" rel="footnote">2</a></sup> Eeckhout says that this physical meaning provides us with a compelling reason to use something like this over the geometric mean.</p>

<p><strong>But this physical meaning doesn’t matter!</strong> When I report a score for SPEC, I don’t <em>really</em> care about how long it takes to run every single workload in that benchmark in a sequential fashion! It’s not like I expect to run a suduko solver (<code>exchange2</code>), then immediately compile <code>gcc</code>, and then perform video compression (<code>x264</code>). I mean, I might run all of these at some point, but certainly not for the exact same amount of time.<sup id="fnref:aside1" role="doc-noteref"><a href="#fn:aside1" rel="footnote">3</a></sup> Although the harmonic mean has a clear physical meaning, it’s not one that really matters for many benchmark suites.</p>

<p>Admittedly, I don’t <em>really</em> care about the geometric mean of these workloads either. I agree with Eeckhout when he says the geomean doesn’t have a clear physical meaning. But it comes down to a choice between an average that doesn’t have a clear physical meaning and one whose physical meaning isn’t relevant in most situations.</p>



<p>Unless you actually know the precise mix of workloads being run in a real system, any number you report is going to fail to accurately predict the effect of your design on that system. Benchmarks like SPEC are useful insofar as they show general performance patterns, but no matter how you cut it, a single number is always going to fail to provide a perfect comparison between machines when using a general-purpose benchmark suite.</p>

<p>If you do know the particular applications that you care about, and you know their relative importance, then by all means, take their weighted average and you’ll be set.</p>

<p>Otherwise, I suggest just using the geomean. It’s easy to compare, and everyone else is familiar with it. Use another mean at your own risk: they’ll all just be wrong in different ways.</p>



<p>I really don’t know. Seems like this argument should be over by now.</p>

<p>One of my former mentors once told me that he never looks at an academic paper’s evaluation section. If the idea presented in the rest of the paper sounds reasonable, maybe he’ll try to apply its innovations to the production design. If the idea sounds rediculous, or addresses a problem he’s already solved in another way, then it’s of no use, regardless of much speedup the authors might claim.<sup id="fnref:eval" role="doc-noteref"><a href="#fn:eval" rel="footnote">4</a></sup></p>

<p>There are other problems that contribute to the industry perspective of academic evaluations. But I share this anecdote just to say: academic computer architects should spend more time coming up with new, inherently interesting ideas, and less time talking about which method of averaging is the least meaningless.</p>




      </div></div>
  </body>
</html>
