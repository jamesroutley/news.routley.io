<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://ianservin.com/2026/01/13/project-skywatch-aka-wescam-at-home/">Original</a>
    <h1>Project SkyWatch (a.k.a. Wescam at Home)</h1>
    
    <div id="readability-page-1" class="page"><div>
<p>Professional aviation surveillance relies on a specific piece of hardware: the EO/IR (Electro-Optical/Infra-Red) gimbal. These are the gyro-stabilized turrets you see on the nose of police helicopters or military drones, capable of keeping a rock-solid lock on a target regardless of how the aircraft maneuvers.</p>



<figure><p>
<iframe title="L3Harris | WESCAM MX™-15 Best of" width="500" height="281" src="https://www.youtube.com/embed/MOUuxITR4eA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
</p></figure>



<p>I wanted to replicate this capability to help track aircraft from the ground—building a tool that allows a consumer camera to lock onto and follow a target with similar stability, but without the defense-contractor budget.</p>



<h4><strong>The Hardware Constraint</strong></h4>



<p>The core of this build is a generic PTZ (Pan-Tilt-Zoom) camera, the kind typically used for streaming church services or campus lectures.</p>



<figure><a href="https://amzn.to/3Nkw0QM"><img decoding="async" width="1024" height="565" src="https://ianservin.com/wp-content/uploads/2026/01/SCR-20260112-tbas-2-1024x565.png" alt="An Amazon product page for the AVKANS AI Auto Tracking NDI 6 Camera, priced at $389.00.

The main image features a sleek, matte black PTZ (Pan-Tilt-Zoom) camera with a prominent &#34;NDI HX3&#34; logo on the side arm. Beside the camera is a small black metal mounting bracket. To the left, a vertical gallery shows several thumbnail images and videos of the product in use.

The product title highlights key features: 20X Live Streaming, HDMI SDI USB3.0 connectivity, and compatibility with NDI HX2 &amp; NDI HX3. It is marketed for church worship, events, and social media livestreaming. A blue notification bar at the top indicates the item was &#34;Last purchased Aug 2, 2024.&#34; The right sidebar shows &#34;Prime Two-Day&#34; shipping, &#34;In Stock&#34; status, and &#34;Add to Cart&#34; / &#34;Buy Now&#34; buttons." srcset="https://ianservin.com/wp-content/uploads/2026/01/SCR-20260112-tbas-2-1024x565.png 1024w, https://ianservin.com/wp-content/uploads/2026/01/SCR-20260112-tbas-2-300x166.png 300w, https://ianservin.com/wp-content/uploads/2026/01/SCR-20260112-tbas-2-768x424.png 768w, https://ianservin.com/wp-content/uploads/2026/01/SCR-20260112-tbas-2-1536x848.png 1536w, https://ianservin.com/wp-content/uploads/2026/01/SCR-20260112-tbas-2-2048x1130.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px"/></a><figcaption><em>The camera in question: an AVKANS LV20N, a knockoff of a 20x zoom PTZOptics unit</em></figcaption></figure>



<p>While cost-effective, these cameras present a major engineering challenge for tracking any object, let alone aircraft. Their motors are designed for slow, dampened pans across a stage, not for tracking a jet moving at 300 knots. The mechanical and electronics latency is significant; if you simply tell the camera to “follow that plane,” by the time the motors react, the target has often moved out of the frame.</p>



<figure><video height="1080" width="1920" controls="" loop="" muted="" src="https://ianservin.com/wp-content/uploads/2026/01/20260106_-_B777_-_CA03126_-_tracking-short.mp4"></video></figure>



<p>To make this hardware viable, the heavy lifting has to move from mechanics to mathematics.</p>



<h4><strong>The Software Stack</strong></h4>



<p>I built a custom control loop to bridge the gap between the camera’s sluggish motors and the dynamic speed of the targets. The stack fuses three main concepts to help the system maintain a visual lock:</p>



<p><strong>Visual Processing (OpenCV &amp; CSRT)</strong></p>



<p><strong>Prediction (Kalman Filter)</strong></p>



<ul>
<li><strong>Smoothing:</strong> It filters out sensor noise and jitter from the tracker.</li>



<li><strong>Prediction:</strong> Crucially, it predicts where the aircraft <em>will be</em> roughly 200ms in the future (accounting for system latency).</li>



<li><strong>Feed-Forward Control:</strong> Instead of just reacting to the error (Feedback), the system feeds the predicted velocity directly to the motors (Feed-Forward). This allows the camera to “lead” the target, eliminating the drag/lag typical of reactive PID loops.</li>
</ul>



<p><strong>Control (PID + Feed-Forward Loop)</strong></p>



<figure><p>
<iframe loading="lazy" title="What Is PID Control? | Understanding PID Control, Part 1" width="500" height="281" src="https://www.youtube.com/embed/wkfEZmsQqiA?list=PLn8PRpmsu08pQBgjxYFXSsODEF3Jqmm-y" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
</p></figure>



<ul>
<li><strong>Proportional:</strong> Corrects the immediate position error.</li>



<li><strong>Integral:</strong> Corrects steady-state error (e.g., wind resistance or motor deadbands).</li>



<li><strong>Derivative:</strong> Dampens the movement to prevent overshoot.</li>



<li><strong>Dynamic Speed Limiting:</strong> I also implemented a dynamic velocity clamp that scales the motor aggressivity based on the distance to the target. This allows for high-speed slew when acquireing a target, but precision micro-stepping when the target is centered.</li>
</ul>



<h4><strong>The “Virtual” Gimbal</strong></h4>



<p>Even with a tuned PID loop, the plastic gears in a consumer PTZ camera have physical limitations. There is always some mechanical play that results in jitter at high zoom levels and the onboard control electronics (including their dampening/smoothing algorithms) introduce latency that prevent perfect mechanical stabilization.</p>



<p>To solve this, I implemented a digital stabilization layer—essentially a “virtual gimbal.” The software crops into the sensor slightly and shifts the image frame-by-frame to counteract the imperfect mechanical stabilization. The result is an incredibly stable image that mimics the expensive mechanical stabilization of professional EO/IR turrets.</p>



<figure><video height="1080" width="1920" controls="" loop="" muted="" src="https://ianservin.com/wp-content/uploads/2026/01/20260102-N62TV-short.mp4"></video><figcaption><em>Demonstration: tracking a media helicopter, toggling on digital stabilization shortly after acquiring a lock.</em></figcaption></figure>



<h4><strong>Data Fusion</strong></h4>



<p>An optical lock is useful, but context is better. Since the system knows the camera’s precise azimuth and elevation, I can correlate the visual data with live ADS-B telemetry. When tracking a target, the system queries local ADS-B traffic to find an aircraft at those specific coordinates. This data comes from a local ADS-B receiver with a script monitoring tar1090.</p>



<h4><strong>Why Build This?</strong></h4>



<p>This project is an experiment in <em>sousveillance</em>—monitoring the monitors. It involves taking the technologies used for ISR (Intelligence, Surveillance, and Reconnaissance) and adapting them for civilian use. By understanding how these tracking systems work, we gain a better understanding of the airspace above us and the tools often used to watch it.</p>



<p>This project is available on <a href="https://github.com/airplaneian/skywatch_ptz_control">Github</a> under an MIT license.</p>
</div></div>
  </body>
</html>
