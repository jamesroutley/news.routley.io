<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://cceckman.com/writing/pass-correct-code/">Original</a>
    <h1>Tests should pass any correct program</h1>
    
    <div id="readability-page-1" class="page"><div>
<p>Let’s talk about software tests.</p>
<p>A test is a program that
takes in some <em>other</em> program, and returns a pass/fail response:
<code>my_test(program) -&gt; boolean</code>.<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p>
<p>A test is supposed to check some (not all) correctness properties of the program.
But it’s easy to write a test that checks <em>the wrong thing</em>,
and fails programs that are correct.</p>
<p>This leads to a comment <a href="https://github.com/fastly/Viceroy/pull/450" rel="external" target="_blank">I often make</a> during code review:</p>
<blockquote>
<p>A test should pass on any correct program.</p>
</blockquote>
<h2 id="the-spectrum-of-software-correctness">The spectrum of software correctness</h2>
<p>Writing good tests requires careful thought, and not a little effort.</p>
<p>At the one end of the spectrum are tests that apply over all inputs.
You might write and check <a href="https://softwarefoundations.cis.upenn.edu/" rel="external" target="_blank">a proof</a>,
or use a <a href="https://practicalalloy.github.io/" rel="external" target="_blank">model checker</a>.
These require careful formalizations – even restructuring of the software –
to make sure the property you’re trying to test <a href="https://en.wikipedia.org/wiki/Rice%27s_theorem" rel="external" target="_blank">is actually decidaable</a>.</p>
<p>Alternatively, you can test empirically, and run the program on a subset of possible inputs.
<a href="https://hypothesis.readthedocs.io/en/latest/" rel="external" target="_blank">Property testing</a> and <a href="https://lcamtuf.coredump.cx/afl/" rel="external" target="_blank">fuzz testing</a>
can explore the input space to find interesting inputs.
Most commonly (in my experience), you write directed tests, where the particular input is embedded in the test.<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup></p>
<h2 id="dont-look-under-the-hood">Don’t look under the hood</h2>
<p>The easiest test to write requires very little thought: a <a href="https://testing.googleblog.com/2015/01/testing-on-toilet-change-detector-tests.html" rel="external" target="_blank">change-detector test</a>,
which precisely mirrors the code under test.<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>
More broadly, it’s easy to write tests depend on details of the code under test
<strong>that are not relevant for correctness</strong>.</p>
<p>Consider this (Pythonic) pseudocode example:</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>def</span> <span>add_from_fetched_arguments</span><span>(</span><span>fetch_a</span><span>:</span> <span>Callable</span><span>[[],</span> <span>int</span><span>],</span> <span>fetch_b</span><span>:</span> <span>Callable</span><span>[[],</span> <span>int</span><span>])</span> <span>-&gt;</span> <span>int</span><span>:</span>
</span></span><span><span>    <span>a</span> <span>=</span> <span>fetch_a</span><span>()</span>
</span></span><span><span>    <span>b</span> <span>=</span> <span>fetch_b</span><span>()</span>
</span></span><span><span>    <span>return</span> <span>a</span> <span>+</span> <span>b</span>
</span></span></code></pre></div><p>The program name gives its expectation: it adds whatever it fetched from the arguments.</p>
<p>You might be tempted to write a test that:</p>
<ol>
<li>Asserts that A is called (and provides value 3)</li>
<li>Asserts that B is called (and provides value 4)</li>
<li>Asserts that the result is 7</li>
</ol>
<p>But which of these properties is relevant for correctness?
If <code>fetch_a</code> and <code>fetch_b</code> have no side effects or ordering constraints, then only property (3) actually matters!</p>
<p>You might say: “If you test on just inputs 3 and 4, then <code>return 7</code> passes the tests, but is not correct!”
That’s true – and if that’s a problem, then you should consider
writing multiple test cases so the trivial result doesn’t hold, or upgrading to a property-based test.<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup></p>
<h2 id="asymmetry-in-testing">Asymmetry in testing</h2>
<p>Directed tests, property-based tests, and fuzzers are all forms of testing, not proof. As Dijkstra said,</p>
<!-- citation: http://homepages.cs.ncl.ac.uk/brian.randell/NATO/nato1969.PDF -->
<blockquote>
<p>Testing shows the presence, not the absence of bugs.</p>
</blockquote>
<p>More generally, a test can prove <em>in</em>correctness, but not <em>correctness</em>.</p>
<p>If we know a test won’t prove correctness, we should be broad in what we consider correct;
tend towards false positives, not false negatives.
A test will only ever validate a narrow set of properties – keep those properties to the bare minimum.</p>
<h2 id="practical-advice">Practical advice</h2>
<p>Use test-driven development: write the tests, then write the implementation.
Write the test based on what <em>must</em> happen for success, not what <em>could</em> happen.</p>
<p><a href="https://testing.googleblog.com/2024/02/increase-test-fidelity-by-avoiding-mocks.html" rel="external" target="_blank">Use fakes instead of mocks.</a>
<a href="https://testing.googleblog.com/2013/03/testing-on-toilet-testing-state-vs.html" rel="external" target="_blank">Test outcomes / state, not interactions.</a></p>
<p>And let me know if you have thoughts on this!</p>




</div></div>
  </body>
</html>
