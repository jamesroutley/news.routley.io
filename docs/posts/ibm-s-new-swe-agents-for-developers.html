<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://research.ibm.com/blog/ibm-swe-agents">Original</a>
    <h1>IBM&#39;s new SWE agents for developers</h1>
    
    <div id="readability-page-1" class="page"><div><p>For most software developers, every day starts with where the last one left off. Trawling through the backlog of issues on GitHub you didn’t deal with the day before, you&#39;re triaging which ones you can fix quickly, which will take more time, and which ones you really don’t know what to do with yet. You might have 30 issues in your backlog and know you only have time to tackle 10. It can feel like a Sisyphean task and it’s easy to get burned out if not managed properly.</p><p>But what if there were tools that could make finding bugs, suggesting fixes, and testing those ideas as easy as submitting an issue on GitHub?</p><p>At TechXchange today, IBM showed off a new set of AI agents designed specifically to make the lives of developers easier. The goal is that these agents will help cut down the amount of time that developers have to spend hunting for answers to bugs in their backlogs, freeing up more time to work on new projects. These are the first software engineering (SWE) agents of their kind powered by open LLMs that can autonomously resolve GitHub issues efficiently.</p><div><figure><div><p><span><img alt="ibm-swe-agent-flow.png" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill"/></span></p></div><p><figcaption>IBM SWE-Agent 1.0 system architecture. Given a GitHub issue, the Agent first ”localizes” to where the bugs are and then edits those lines of code to resolve them.</figcaption></p></figure></div><p>Localization is the first big task tackled with an agent. If you can’t find where a bug is in your code, you can’t fix it. Localization is the task of finding the files and lines of code in an organization’s codebase that are causing a given error.</p><p>When an error is spotted by a quality assurance (QA) engineer, they’ll file a bug report, which would go into the developer’s backlog and add to the pile of bugs to sift through. Finding the offending line — and ensuring altering it won’t affect anything else in the codebase — is a time-consuming process.</p><p>But with the SWE localization agent, a developer could open a bug report they’ve received on GitHub, tag it with “ibm-swe-agent-1.0” and the agent will quickly work in the background to find the troublesome code. Once it’s found the location, it’ll suggest a fix that the developer could implement to resolve the issue. That developer could then review the proposed fix and decide if it’s the best way to solve the problem, potentially even using other agents to figure it out.</p><div><figure><div><div></div></div><p><figcaption>The IBM SWE Agent in action</figcaption></p></figure></div><p>The localization tool is just one of a few new AI agents IBM Research has developed that aim to take a chunk out of the workload developers have on their plate. There’s also one for editing lines of code based on developer requests, which relies on <a href="https://www.ibm.com/granite">IBM&#39;s Granite LLM</a> on watsonx, <a href="https://ibm.github.io/prompt-declaration-language/">via PDL</a>. Another agent can be used for developing and executing tests to ensure that code will run as intended. In each case, they can be invoked right where developers would want them to be, such as in GitHub.</p><p>On average, the SWE agents can localize and fix problems within five minutes, and in testing, they have managed a 24% success rate on the <a href="https://www.swebench.com/">SWE-bench tests</a>. These measure how efficiently AI agents can solve real-world problems found on GitHub. That score places the IBM SWE agent high up the SWE-bench leaderboard, well above many other agents relying on massive frontier models, like GPT-4o and Claude 3. </p><div><figure><div><p><span><img alt="SWE-Bench.jpg" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill"/></span></p></div><p><figcaption>These results compare IBM’s SWE-Agent 1.0 (dark blue, right) with only open-source LLMs being at par with some of the top performers.</figcaption></p></figure></div><div><figure><div><p><span><img alt="localization-rectified.jpg" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill"/></span></p></div><p><figcaption>Localization results above show that their agent with open-source LLMs are almost tied in performance with an agent with frontier LLMs.</figcaption></p></figure></div><p>In each case, these agents observe, think, and act. They differ from singular LLMs or foundation models, as they can call upon different models and stores of information to answer questions in ways that are most efficient. And they can plan out the steps required to carry out that task — something an LLM cannot do on its own. An agent can do complex, complete tasks without additional input from a user.</p><p>It made sense for IBM to build agentic tools like these, argues Ruchir Puri, chief scientist at IBM Research, not just for its own developers, but for all the enterprise developers IBM strives to assist. There are other competitive SWE agent tools looking to aid developers at work, but they primarily are relying on massive, proprietary frontier models that cost a great deal at inference time. “Our goal was to build IBM SWE-Agent for enterprises who want a cost efficient SWE agent to run wherever their code resides — even behind your firewall — while still being performant,” Puri said.</p></div></div>
  </body>
</html>
