<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://artificialanalysis.ai">Original</a>
    <h1>Benchmarks and comparison of LLM AI models and API hosting providers</h1>
    
    <div id="readability-page-1" class="page"><div><div><p>Analysis of AI models and hosting providers - choose the best model and provider for your use case</p><h2>Highlights</h2></div></div><div><div><div><p>Model Quality</p><div><div><p>Quality Index; Higher is better</p></div></div></div><div><p>Speed</p><div><div><p>Throughput in Tokens per Second; Higher is better</p></div></div></div><div><p>Price</p><div><div><p>USD per 1M Tokens; Lower is better</p></div></div></div></div><div><div><p><h2>Models comparison highlights</h2></p></div><div><div><div><h2>Quality vs. Throughput, Price</h2></div><div><div><div><div><p>Quality: General reasoning index, Throughput: Tokens per Second, Price: USD per 1M Tokens</p><div><div><div><svg></svg><svg></svg><p><span>Size represents <!-- -->Price (USD per M Tokens)</span></p></div></div></div></div></div></div><div><div><div><p><span>There is a trade-off between model quality and throughput, with higher quality models typically having lower throughput.</span></p></div><p><span><span>Quality:</span> Index based on several quality benchmarks</span></p><p><span><span>Throughput:</span> Tokens per second received while the model is generating tokens (ie. after first chunk has been received from the API)</span></p><p><span><span>Price:</span> Price per token, represented as USD per million Tokens. Price is a blend of Input &amp; Output token prices (3:1 ratio)</span></p><p><span><span>Average across hosts:</span> Average measurement across all hosts which support the model.</span></p> </div></div></div></div></div><div><div><div><h2>Quality comparison by ability</h2></div><div><div><div><div><p>Varied metrics by ability categorization; Higher is better</p><div><div><p><span>General Ability (Chatbot Arena)</span></p></div><div><p><span>Reasoning &amp; Knowledge (MMLU)</span></p></div><div><p><span>Reasoning &amp; Knowledge (MT Bench)</span></p></div></div></div></div></div><div><div><div><p><span>OpenAI&#39;s GPT-4 is the clear quality leader across quality metrics. However, models including Gemini Pro and Mixtral 8x7B have reached GPT-3.5 performance in some measures.</span></p></div><p><span><span>Total Response Time:</span> Time to receive a 100 token response. Estimated based on Latency (time to receive first chunk) and Throughput (tokens per second)</span></p><p><span><span>Average across hosts:</span> Average measurement across all hosts which support the model.</span></p> </div></div></div></div></div></div><div><div><p><h2>Host comparison highlights</h2></p></div><p>Reference model used for comparison: Llama 2 70b</p><div><div><div><div><div><div><p>Quality: General reasoning index, Throughput: Tokens per Second, Price: USD per 1M Tokens; Reference model: Llama 2 70b</p></div></div></div><div><div><div><p><span>Smaller, emerging hosts are offering high throughput and at competitive prices.</span></p></div><p><span><span>Price:</span> Price per token, represented as USD per million Tokens. Price is a blend of Input &amp; Output token prices (3:1 ratio)</span></p><p><span><span>Throughput:</span> Tokens per second received while the model is generating tokens (ie. after first chunk has been received from the API)</span></p> </div></div></div></div></div><div><div><div><h2>Pricing: Input and Output prices</h2></div><div><div><div><div><p>Price: USD per 1M Tokens; Lower is better; Reference model: Llama 2 70b</p></div></div></div><div><div><div><p><span>Hosts typically charge different prices for input and output tokens. The ratio of input / output token price for a certain use-case may significantly impact overall costs.</span></p></div><p><span><span>Input price:</span> Price per token included in the request/message sent to the API, represented as USD per million Tokens.</span></p><p><span><span>Output price:</span> Price per token generated by the model (received from the API), represented as USD per million Tokens.</span></p> </div></div></div></div></div></div><div><p>See more information on any of our supported models</p></div></div></div>
  </body>
</html>
