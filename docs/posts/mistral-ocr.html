<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://mistral.ai/fr/news/mistral-ocr">Original</a>
    <h1>Mistral OCR</h1>
    
    <div id="readability-page-1" class="page"><div><p dir="ltr">Throughout history, advancements in information abstraction and retrieval have driven human progress. From hieroglyphs to papyri, the printing press to digitization, each leap has made human knowledge more accessible and actionable, fueling further innovation. </p>
<p dir="ltr">Today, we’re at the precipice of the next big leap—to unlock the collective intelligence of all digitized information. Approximately <a href="https://resources.data.gov/glossary/unstructured-data/">90%</a> of the world’s organizational data is stored as documents, and to harness this potential, we are introducing <a href="https://docs.mistral.ai/capabilities/document/">Mistral OCR</a>. </p>
<p dir="ltr">As a result, Mistral OCR is an ideal model to use in combination with a RAG system taking multimodal documents (such as slides or complex PDFs) as input.</p>
<p dir="ltr">We have made Mistral OCR as the default model for document understanding across millions of users on Le Chat, and are releasing the API <em>mistral-ocr-latest</em> at 1000 pages / $ (and approximately double the pages per dollar with batch inference). The API is available today on our developer suite <a href="http://console.mistral.ai">la Plateforme</a>, and coming soon to our cloud and inference partners, as well as on-premises.</p>
<h2 dir="ltr">Highlights</h2>
<ol>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">State of the art understanding of complex documents</p>
</li>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Natively multilingual and multimodal</p>
</li>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Top-tier benchmarks</p>
</li>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Fastest in its category</p>
</li>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Doc-as-prompt, structured output</p>
</li>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Selectively available to self-host for organizations dealing with highly sensitive or classified information</p>
</li>
</ol>
<p dir="ltr">Let’s dive into each. </p>
<h3 dir="ltr">State of the art understanding of complex documents</h3>
<p dir="ltr">Mistral OCR excels in understanding complex document elements, including interleaved imagery, mathematical expressions, tables, and advanced layouts such as LaTeX formatting. The model enables deeper understanding of rich documents such as scientific papers with charts, graphs, equations and figures. </p>
<p dir="ltr">Below is an example of the model extracting text as well as imagery from a given PDF into a markdown file. You can access the notebook <a href="https://colab.research.google.com/drive/11NdqWVwC_TtJyKT6cmuap4l9SryAeeVt?usp=sharing" target="_blank" rel="noopener">here</a>. </p>
<p dir="ltr"><iframe title="YouTube video player" src="https://www.youtube.com/embed/6lRBm0KnzBI?si=qLSblC2rsBdxg4qu" width="560" height="315" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen="allowfullscreen"></iframe></p>
<p dir="ltr">Below we have side-by-side comparisons of PDFs and their respective OCR&#39;s outputs. Hover the slider  to switch between input and output. </p>





<h3 dir="ltr">Top-tier benchmarks</h3>
<p dir="ltr">Mistral OCR has consistently outperformed other leading OCR models in rigorous benchmark tests. Its superior accuracy across multiple aspects of document analysis is illustrated below. We extract embedded images from documents along with text. The other LLMs compared below, do not have that capability. For a fair comparison, we evaluate them on our internal “text-only” test-set containing various publication papers, and PDFs from the web; below:</p>
<div dir="ltr">
<table><colgroup> <col width="178"/> <col width="105"/> <col width="108"/> <col width="106"/> <col width="103"/> <col width="101"/> </colgroup>
<thead>
<tr>
<th>Model</th>
<th>Overall</th>
<th>Math</th>
<th>Multilingual</th>
<th>Scanned</th>
<th>Tables</th>
</tr>
</thead>
<tbody>
<tr>
<td>Google Document AI</td>
<td>83.42</td>
<td>80.29</td>
<td>86.42</td>
<td>92.77</td>
<td>78.16</td>
</tr>
<tr>
<td>Azure OCR</td>
<td>89.52</td>
<td>85.72</td>
<td>87.52</td>
<td>94.65</td>
<td>89.52</td>
</tr>
<tr>
<td>Gemini-1.5-Flash-002</td>
<td>90.23</td>
<td>89.11</td>
<td>86.76</td>
<td>94.87</td>
<td>90.48</td>
</tr>
<tr>
<td>Gemini-1.5-Pro-002</td>
<td>89.92</td>
<td>88.48</td>
<td>86.33</td>
<td>96.15</td>
<td>89.71</td>
</tr>
<tr>
<td>Gemini-2.0-Flash-001</td>
<td>88.69</td>
<td>84.18</td>
<td>85.80</td>
<td>95.11</td>
<td>91.46</td>
</tr>
<tr>
<td>GPT-4o-2024-11-20</td>
<td>89.77</td>
<td>87.55</td>
<td>86.00</td>
<td>94.58</td>
<td>91.70</td>
</tr>
<tr>
<td>Mistral OCR 2503</td>
<td>94.89</td>
<td>94.29</td>
<td>89.55</td>
<td>98.96</td>
<td>96.12</td>
</tr>
</tbody>
</table>
</div>
<h3 dir="ltr">Natively multilingual</h3>
<p dir="ltr">Since Mistral’s founding, we have aspired to serve the world with our models, and consequently strived for multilingual capabilities across our offerings. Mistral OCR takes this to a new level, being able to parse, understand, and transcribe thousands of scripts, fonts, and languages across all continents. This versatility is crucial for both global organizations that handle documents from diverse linguistic backgrounds, as well as hyperlocal businesses serving niche markets.</p>
<div dir="ltr">
<table><colgroup> <col width="236"/> <col width="203"/> </colgroup>
<thead>
<tr>
<th>Model</th>
<th>Fuzzy Match in Generation</th>
</tr>
</thead>
<tbody>
<tr>
<td>Google-Document-AI</td>
<td>95.88</td>
</tr>
<tr>
<td>Gemini-2.0-Flash-001</td>
<td>96.53</td>
</tr>
<tr>
<td>Azure OCR</td>
<td>97.31</td>
</tr>
<tr>
<td>Mistral OCR</td>
<td>99.02</td>
</tr>
</tbody>
</table>
</div>

<p dir="ltr">Benchmarks by language:</p>
<div dir="ltr">
<table><colgroup> <col width="133"/> <col width="123"/> <col width="126"/> <col width="170"/> </colgroup>
<thead>
<tr>
<th>Language</th>
<th>Azure OCR</th>
<th>Google Doc AI</th>
<th>Mistral OCR</th>
</tr>
</thead>
<tbody>
<tr>
<td>ru</td>
<td>97.35</td>
<td>95.56</td>
<td>99.09</td>
</tr>
<tr>
<td>fr</td>
<td>97.50</td>
<td>96.36</td>
<td>99.20</td>
</tr>
<tr>
<td>hi</td>
<td>96.45</td>
<td>95.65</td>
<td>97.55</td>
</tr>
<tr>
<td>zh</td>
<td>91.40</td>
<td>90.89</td>
<td>97.11</td>
</tr>
<tr>
<td>pt</td>
<td>97.96</td>
<td>96.24</td>
<td>99.42</td>
</tr>
<tr>
<td>de</td>
<td>98.39</td>
<td>97.09</td>
<td>99.51</td>
</tr>
<tr>
<td>es</td>
<td>98.54</td>
<td>97.52</td>
<td>99.54</td>
</tr>
<tr>
<td>tr</td>
<td>95.91</td>
<td>93.85</td>
<td>97.00</td>
</tr>
<tr>
<td>uk</td>
<td>97.81</td>
<td>96.24</td>
<td>99.29</td>
</tr>
<tr>
<td>it</td>
<td>98.31</td>
<td>97.69</td>
<td>99.42</td>
</tr>
<tr>
<td>ro</td>
<td>96.45</td>
<td>95.14</td>
<td>98.79</td>
</tr>
</tbody>
</table>
</div>

<h2 dir="ltr">Fastest in its category</h2>
<p dir="ltr">Being lighter weight than most models in the category, Mistral OCR performs significantly faster than its peers, processing up to 2000 pages per minute on a single node. The ability to rapidly process documents ensures continuous learning and improvement even for high-throughput environments.</p>
<h3 dir="ltr">Doc-as-prompt, structured output</h3>
<p dir="ltr">Mistral OCR also introduces the use of documents as prompts, enabling more powerful and precise instructions. This capability allows users to extract specific information from documents and format it in structured outputs, such as JSON. Users can chain extracted outputs into downstream function calls and build agents.</p>
<h3 dir="ltr">Available to self-host on a selective basis</h3>
<p dir="ltr">For organizations with stringent data privacy requirements, Mistral OCR offers a self-hosting option. This ensures that sensitive or classified information remains secure within your own infrastructure, providing compliance with regulatory and security standards. If you would like to explore self-deployment with us, please <a href="https://mistral.ai/contact">let us know</a>.</p>
<h2 dir="ltr">Use cases</h2>
<p dir="ltr">We are empowering our beta customers to elevate their organizational knowledge by transforming their extensive document repositories into actions and solutions. Some of the key use cases where our technology is making a significant impact include:</p>
<p dir="ltr"><strong>Digitizing scientific research</strong>: Leading research institutions have been experimenting with Mistral OCR to convert scientific papers and journals into AI-ready formats, making them accessible to downstream intelligence engines. This has facilitated measurably faster collaboration and accelerated scientific workflows.</p>
<p dir="ltr"><strong>Preserving historical and cultural heritage</strong>: Organizations and nonprofits that are custodians of heritage have been using Mistral OCR to digitize historical documents and artifacts, ensuring their preservation and making them accessible to a broader audience.</p>
<p dir="ltr"><strong>Streamlining customer service</strong>: Customer service departments are exploring Mistral OCR to transform documentation and manuals into indexed knowledge, reducing response times and improving customer satisfaction.</p>
<p dir="ltr"><strong>Making literature across design, education, legal, etc. AI ready</strong>: Mistral OCR has also been helping companies convert technical literature, engineering drawings, lecture notes, presentations, regulatory filings and much more into indexed, answer-ready formats, unlocking intelligence and productivity across millions of documents.</p>
<h2 dir="ltr">Experience it today</h2>
<p dir="ltr">Mistral OCR capabilities are free to try on <a href="http://chat.mistral.ai">le Chat</a>. To try the API, head over to <a href="http://console.mistral.ai">la Plateforme</a>. We’d love to get your feedback; expect the model to continue to get even better in the weeks to come. As part of our strategic engagement programs, we will also offer on-premises deployment on a <a href="https://mistral.ai/contact">selective basis</a>.</p></div></div>
  </body>
</html>
