<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.fractalkitty.com/math-storytelling-day-2025/">Original</a>
    <h1>Math Storytelling Day 2025</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">


<p dir="auto">We introduce SimpleFold, the first flow-matching based protein folding model that solely uses general purpose transformer layers. SimpleFold does not rely on expensive modules like triangle attention or pair representation biases, and is trained via a generative flow-matching objective. We scale SimpleFold to 3B parameters and train it on more than 8.6M distilled protein structures together with experimental PDB data. To the best of our knowledge, SimpleFold is the largest scale folding model ever developed. On standard folding benchmarks, SimpleFold-3B model achieves competitive performance compared to state-of-the-art baselines. Due to its generative training objective, SimpleFold also demonstrates strong performance in ensemble prediction. SimpleFold challenges the reliance on complex domain-specific architectures designs in folding, highlighting an alternative yet important avenue of progress in protein structure prediction.</p>


<p dir="auto">To install <code>simplefold</code> package from github repository, run</p>
<div data-snippet-clipboard-copy-content="git clone https://github.com/apple/ml-simplefold.git
cd ml-simplefold
conda create -n simplefold python=3.10
python -m pip install -U pip build; pip install -e ."><pre><code>git clone https://github.com/apple/ml-simplefold.git
cd ml-simplefold
conda create -n simplefold python=3.10
python -m pip install -U pip build; pip install -e .
</code></pre></div>
<p dir="auto">If you want to use MLX backend on Apple silicon:</p>
<div data-snippet-clipboard-copy-content="pip install mlx==0.28.0
pip install git+https://github.com/facebookresearch/esm.git"><pre><code>pip install mlx==0.28.0
pip install git+https://github.com/facebookresearch/esm.git
</code></pre></div>

<p dir="auto">We provide a jupyter notebook <a href="https://www.fractalkitty.com/apple/ml-simplefold/blob/main/sample.ipynb"><code>sample.ipynb</code></a> to predict protein structures from example protein sequences.</p>

<p dir="auto">Once you have <code>simplefold</code> package installed, you can predict the protein structure from target fasta file(s) via the following command line. We provide support for both <a href="https://pytorch.org/" rel="nofollow">PyTorch</a> and <a href="https://mlx-framework.org/" rel="nofollow">MLX</a> (recommended for Apple hardware) backends in inference.</p>
<div data-snippet-clipboard-copy-content="simplefold \
    --simplefold_model simplefold_100M \  # specify folding model in simplefold_100M/360M/700M/1.1B/1.6B/3B
    --num_steps 500 --tau 0.01 \        # specify inference setting
    --nsample_per_protein 1 \           # number of generated conformers per target
    --plddt \                           # output pLDDT
    --fasta_path [FASTA_PATH] \         # path to the target fasta directory or file
    --output_dir [OUTPUT_DIR] \         # path to the output directory
    --backend [mlx, torch]              # choose from MLX and PyTorch for inference backend "><pre><code>simplefold \
    --simplefold_model simplefold_100M \  # specify folding model in simplefold_100M/360M/700M/1.1B/1.6B/3B
    --num_steps 500 --tau 0.01 \        # specify inference setting
    --nsample_per_protein 1 \           # number of generated conformers per target
    --plddt \                           # output pLDDT
    --fasta_path [FASTA_PATH] \         # path to the target fasta directory or file
    --output_dir [OUTPUT_DIR] \         # path to the output directory
    --backend [mlx, torch]              # choose from MLX and PyTorch for inference backend 
</code></pre></div>

<p dir="auto">We provide predicted structures from SimpleFold of different model sizes:</p>
<div data-snippet-clipboard-copy-content="https://ml-site.cdn-apple.com/models/simplefold/cameo22_predictions.zip # predicted structures of CAMEO22
https://ml-site.cdn-apple.com/models/simplefold/casp14_predictions.zip  # predicted structures of CASP14
https://ml-site.cdn-apple.com/models/simplefold/apo_predictions.zip     # predicted structures of Apo
https://ml-site.cdn-apple.com/models/simplefold/codnas_predictions.zip  # predicted structures of Fold-switch (CoDNaS)"><pre><code>https://ml-site.cdn-apple.com/models/simplefold/cameo22_predictions.zip # predicted structures of CAMEO22
https://ml-site.cdn-apple.com/models/simplefold/casp14_predictions.zip  # predicted structures of CASP14
https://ml-site.cdn-apple.com/models/simplefold/apo_predictions.zip     # predicted structures of Apo
https://ml-site.cdn-apple.com/models/simplefold/codnas_predictions.zip  # predicted structures of Fold-switch (CoDNaS)
</code></pre></div>
<p dir="auto">We use the docker image of <a href="https://git.scicore.unibas.ch/schwede/openstructure/" rel="nofollow">openstructure</a> 2.9.1 to evaluate generated structures for folding tasks (i.e., CASP14/CAMEO22). Once having the docker image enabled, you can run evaluation via:</p>
<div data-snippet-clipboard-copy-content="python src/simplefold/evaluation/analyze_folding.py \
    --data_dir [PATH_TO_TARGET_MMCIF] \
    --sample_dir [PATH_TO_PREDICTED_MMCIF] \
    --out_dir [PATH_TO_OUTPUT] \
    --max-workers [NUMBER_OF_WORKERS]"><pre><code>python src/simplefold/evaluation/analyze_folding.py \
    --data_dir [PATH_TO_TARGET_MMCIF] \
    --sample_dir [PATH_TO_PREDICTED_MMCIF] \
    --out_dir [PATH_TO_OUTPUT] \
    --max-workers [NUMBER_OF_WORKERS]
</code></pre></div>
<p dir="auto">To evaluate results of two-state prediction (i.e., Apo/CoDNaS), one need to compile the <a href="https://zhanggroup.org/TM-score/TMscore.cpp" rel="nofollow">TMsore</a> and then run evaluation via:</p>
<div data-snippet-clipboard-copy-content="python src/simplefold/evaluation/analyze_two_state.py \ 
    --data_dir [PATH_TO_TARGET_DATA_DIRECTORY] \
    --sample_dir [PATH_TO_PREDICTED_PDB] \
    --tm_bin [PATH_TO_TMscore_BINARY] \
    --task apo \ # choose from apo and codnas
    --nsample 5"><pre><code>python src/simplefold/evaluation/analyze_two_state.py \ 
    --data_dir [PATH_TO_TARGET_DATA_DIRECTORY] \
    --sample_dir [PATH_TO_PREDICTED_PDB] \
    --tm_bin [PATH_TO_TMscore_BINARY] \
    --task apo \ # choose from apo and codnas
    --nsample 5
</code></pre></div>

<p dir="auto">You can also train or tune SimpleFold on your end. Instructions below include details for SimpleFold training.</p>


<p dir="auto">SimpleFold is trained on joint datasets including experimental structures from <a href="https://www.rcsb.org/" rel="nofollow">PDB</a>, as well as distilled predictions from <a href="https://alphafold.ebi.ac.uk/download#swissprot-section" rel="nofollow">AFDB SwissProt</a> and <a href="https://afesm.foldseek.com/" rel="nofollow">AFESM</a>. Target lists of filtered SwissProt and AFESM targets thta are used in our training can be found:</p>
<div data-snippet-clipboard-copy-content="https://ml-site.cdn-apple.com/models/simplefold/swissprot_list.csv # list of filted SwissProt (~270K targets)
https://ml-site.cdn-apple.com/models/simplefold/afesm_list.csv # list of filted AFESM targets (~1.9M targets)
https://ml-site.cdn-apple.com/models/simplefold/afesme_dict.json # list of filted extended AFESM (AFESM-E) (~8.6M targets)"><pre><code>https://ml-site.cdn-apple.com/models/simplefold/swissprot_list.csv # list of filted SwissProt (~270K targets)
https://ml-site.cdn-apple.com/models/simplefold/afesm_list.csv # list of filted AFESM targets (~1.9M targets)
https://ml-site.cdn-apple.com/models/simplefold/afesme_dict.json # list of filted extended AFESM (AFESM-E) (~8.6M targets)
</code></pre></div>
<p dir="auto">In <code>afesme_dict.json</code>, the data is stored in the following structure:</p>
<div data-snippet-clipboard-copy-content="{
    cluster 1 ID: {&#34;members&#34;: [protein 1 ID, protein 2 ID, ...]},
    cluster 2 ID: {&#34;members&#34;: [protein 1 ID, protein 2 ID, ...]},
    ...
}"><pre><code>{
    cluster 1 ID: {&#34;members&#34;: [protein 1 ID, protein 2 ID, ...]},
    cluster 2 ID: {&#34;members&#34;: [protein 1 ID, protein 2 ID, ...]},
    ...
}
</code></pre></div>
<p dir="auto">Of course, one can use own customized datasets to train or tune SimpleFold models. Instructions below list how to process the dataset for SimpleFold training.</p>

<p dir="auto">To process downloaded mmcif files, you need <a href="https://redis.io/docs/latest/operate/oss_and_stack/install/archive/install-redis/" rel="nofollow">Redis</a> installed and launch the Redis server:</p>
<div data-snippet-clipboard-copy-content="wget https://boltz1.s3.us-east-2.amazonaws.com/ccd.rdb
redis-server --dbfilename ccd.rdb --port 7777"><pre><code>wget https://boltz1.s3.us-east-2.amazonaws.com/ccd.rdb
redis-server --dbfilename ccd.rdb --port 7777
</code></pre></div>
<p dir="auto">You can then process mmcif files to input format for SimpleFold:</p>
<div data-snippet-clipboard-copy-content="python src/simplefold/process_mmcif.py \
    --data_dir [MMCIF_DIR]   # directory of mmcif files
    --out_dir [OUTPUT_DIR]   # directory of processed targets
    --use-assembly"><pre><code>python src/simplefold/process_mmcif.py \
    --data_dir [MMCIF_DIR]   # directory of mmcif files
    --out_dir [OUTPUT_DIR]   # directory of processed targets
    --use-assembly
</code></pre></div>

<p dir="auto">The configuration of model is based on <a href="https://hydra.cc/docs/intro/" rel="nofollow"><code>Hydra</code></a>. An example training configuration can be found in <code>configs/experiment/train</code>. To change dataset and model settings, one can refer to config files in <code>configs/data</code> and <code>configs/model</code>. To initiate SimpleFold training:</p>
<div data-snippet-clipboard-copy-content="python train experiment=train"><pre><code>python train experiment=train
</code></pre></div>
<p dir="auto">To train SimpleFold with FSDP strategy:</p>
<div data-snippet-clipboard-copy-content="python train_fsdp.py experiment=train_fsdp"><pre><code>python train_fsdp.py experiment=train_fsdp
</code></pre></div>

<p dir="auto">If you found this code useful, please cite the following paper:</p>
<div data-snippet-clipboard-copy-content="@article{simplefold,
  title={SimpleFold: Folding Proteins is Simpler than You Think},
  author={Wang, Yuyang and Lu, Jiarui and Jaitly, Navdeep and Susskind, Josh and Bautista, Miguel Angel},
  journal={arXiv preprint arXiv:2509.18480},
  year={2025}
}"><pre><code>@article{simplefold,
  title={SimpleFold: Folding Proteins is Simpler than You Think},
  author={Wang, Yuyang and Lu, Jiarui and Jaitly, Navdeep and Susskind, Josh and Bautista, Miguel Angel},
  journal={arXiv preprint arXiv:2509.18480},
  year={2025}
}
</code></pre></div>

<p dir="auto">Our codebase is built using multiple opensource contributions, please see <a href="https://www.fractalkitty.com/apple/ml-simplefold/blob/main/ACKNOWLEDGEMENTS">ACKNOWLEDGEMENTS</a> for more details.</p>

<p dir="auto">Please check out the repository <a href="https://www.fractalkitty.com/apple/ml-simplefold/blob/main/LICENSE">LICENSE</a> before using the provided code and
<a href="https://www.fractalkitty.com/apple/ml-simplefold/blob/main/LICENSE_MODEL">LICENSE_MODEL</a> for the released models.</p>
</article></div></div>
  </body>
</html>
