<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/cofob/autogenlib">Original</a>
    <h1>Python lib generates its code on-the-fly based on usage</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<blockquote>
<p dir="auto">The only library you&#39;ll need ever.</p>
<p dir="auto">Import wisdom, export code.</p>
</blockquote>
<p dir="auto">AutoGenLib is a Python library that automatically generates code on-the-fly using OpenAI&#39;s API. When you try to import a module or function that doesn&#39;t exist, AutoGenLib creates it for you based on a high-level description of what you need.</p>

<ul dir="auto">
<li><strong>Dynamic Code Generation</strong>: Import modules and functions that don&#39;t exist yet</li>
<li><strong>Context-Aware</strong>: New functions are generated with knowledge of existing code</li>
<li><strong>Progressive Enhancement</strong>: Add new functionality to existing modules seamlessly</li>
<li><strong>No Default Caching</strong>: Each import generates fresh code for more varied and creative results</li>
<li><strong>Full Codebase Context</strong>: LLM can see all previously generated modules for better consistency</li>
<li><strong>Caller Code Analysis</strong>: The LLM analyzes the actual code that&#39;s importing the module to better understand the context and requirements</li>
<li><strong>Automatic Exception Handling</strong>: All exceptions are sent to LLM to provide clear explanation and fixes for errors.</li>
</ul>


<p dir="auto">Or install from source:</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/cofob/autogenlib.git
cd autogenlib
pip install -e ."><pre>git clone https://github.com/cofob/autogenlib.git
<span>cd</span> autogenlib
pip install -e <span>.</span></pre></div>

<ul dir="auto">
<li>Python 3.12+</li>
<li>OpenAI API key</li>
</ul>

<p dir="auto">Set OpenAI API key in <code>OPENAI_API_KEY</code> env variable.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Import a function that doesn&#39;t exist yet - it will be automatically generated
from autogenlib.tokens import generate_token

# Use the generated function
token = generate_token(length=32)
print(token)"><pre><span># Import a function that doesn&#39;t exist yet - it will be automatically generated</span>
<span>from</span> <span>autogenlib</span>.<span>tokens</span> <span>import</span> <span>generate_token</span>

<span># Use the generated function</span>
<span>token</span> <span>=</span> <span>generate_token</span>(<span>length</span><span>=</span><span>32</span>)
<span>print</span>(<span>token</span>)</pre></div>

<ol dir="auto">
<li>You initialize AutoGenLib with a description of what you need</li>
<li>When you import a module or function under the <code>autogenlib</code> namespace, the library:
<ul dir="auto">
<li>Checks if the module/function already exists</li>
<li>If not, it analyzes the code that&#39;s performing the import to understand the context</li>
<li>It sends a request to OpenAI&#39;s API with your description and the context</li>
<li>The API generates the appropriate code</li>
<li>The code is validated and executed</li>
<li>The requested module/function becomes available for use</li>
</ul>
</li>
</ol>

<div dir="auto"><h3 tabindex="-1" dir="auto">Generate a TOTP Generator</h3><a id="user-content-generate-a-totp-generator" aria-label="Permalink: Generate a TOTP Generator" href="#generate-a-totp-generator"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto" data-snippet-clipboard-copy-content="from autogenlib.totp import totp_generator

print(totp_generator(&#34;SECRETKEY123&#34;))"><pre><span>from</span> <span>autogenlib</span>.<span>totp</span> <span>import</span> <span>totp_generator</span>

<span>print</span>(<span>totp_generator</span>(<span>&#34;SECRETKEY123&#34;</span>))</pre></div>
<p dir="auto">Add a Verification Function Later</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Later in your application, you need verification:
from autogenlib.totp import verify_totp
result = verify_totp(&#34;SECRETKEY123&#34;, &#34;123456&#34;)
print(f&#34;Verification result: {result}&#34;)"><pre><span># Later in your application, you need verification:</span>
<span>from</span> <span>autogenlib</span>.<span>totp</span> <span>import</span> <span>verify_totp</span>
<span>result</span> <span>=</span> <span>verify_totp</span>(<span>&#34;SECRETKEY123&#34;</span>, <span>&#34;123456&#34;</span>)
<span>print</span>(<span>f&#34;Verification result: <span><span>{</span><span>result</span><span>}</span></span>&#34;</span>)</pre></div>

<div dir="auto" data-snippet-clipboard-copy-content="# Import a function - AutoGenLib will see how your data is structured
from autogenlib.processor import get_highest_score

# Define your data structure
data = [{&#34;user&#34;: &#34;Alice&#34;, &#34;score&#34;: 95}, {&#34;user&#34;: &#34;Bob&#34;, &#34;score&#34;: 82}]

# The function will work with your data structure without you having to specify details
print(get_highest_score(data))  # Will correctly extract the highest score"><pre><span># Import a function - AutoGenLib will see how your data is structured</span>
<span>from</span> <span>autogenlib</span>.<span>processor</span> <span>import</span> <span>get_highest_score</span>

<span># Define your data structure</span>
<span>data</span> <span>=</span> [{<span>&#34;user&#34;</span>: <span>&#34;Alice&#34;</span>, <span>&#34;score&#34;</span>: <span>95</span>}, {<span>&#34;user&#34;</span>: <span>&#34;Bob&#34;</span>, <span>&#34;score&#34;</span>: <span>82</span>}]

<span># The function will work with your data structure without you having to specify details</span>
<span>print</span>(<span>get_highest_score</span>(<span>data</span>))  <span># Will correctly extract the highest score</span></pre></div>

<div dir="auto" data-snippet-clipboard-copy-content="# You can use init function to additionally hint the purpose of your library
from autogenlib import init
init(&#34;Cryptographic utility library&#34;)

# Generate encryption module
from autogenlib.encryption import encrypt_text, decrypt_text
encrypted = encrypt_text(&#34;Secret message&#34;, &#34;password123&#34;)
decrypted = decrypt_text(encrypted, &#34;password123&#34;)
print(decrypted)

# Generate hashing module
from autogenlib.hashing import hash_password, verify_password
hashed = hash_password(&#34;my_secure_password&#34;)
is_valid = verify_password(&#34;my_secure_password&#34;, hashed)
print(f&#34;Password valid: {is_valid}&#34;)"><pre><span># You can use init function to additionally hint the purpose of your library</span>
<span>from</span> <span>autogenlib</span> <span>import</span> <span>init</span>
<span>init</span>(<span>&#34;Cryptographic utility library&#34;</span>)

<span># Generate encryption module</span>
<span>from</span> <span>autogenlib</span>.<span>encryption</span> <span>import</span> <span>encrypt_text</span>, <span>decrypt_text</span>
<span>encrypted</span> <span>=</span> <span>encrypt_text</span>(<span>&#34;Secret message&#34;</span>, <span>&#34;password123&#34;</span>)
<span>decrypted</span> <span>=</span> <span>decrypt_text</span>(<span>encrypted</span>, <span>&#34;password123&#34;</span>)
<span>print</span>(<span>decrypted</span>)

<span># Generate hashing module</span>
<span>from</span> <span>autogenlib</span>.<span>hashing</span> <span>import</span> <span>hash_password</span>, <span>verify_password</span>
<span>hashed</span> <span>=</span> <span>hash_password</span>(<span>&#34;my_secure_password&#34;</span>)
<span>is_valid</span> <span>=</span> <span>verify_password</span>(<span>&#34;my_secure_password&#34;</span>, <span>hashed</span>)
<span>print</span>(<span>f&#34;Password valid: <span><span>{</span><span>is_valid</span><span>}</span></span>&#34;</span>)</pre></div>

<div dir="auto"><h3 tabindex="-1" dir="auto">Setting the OpenAI API Key</h3><a id="user-content-setting-the-openai-api-key" aria-label="Permalink: Setting the OpenAI API Key" href="#setting-the-openai-api-key"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Set your OpenAI API key as an environment variable:</p>
<div dir="auto" data-snippet-clipboard-copy-content="export OPENAI_API_KEY=&#34;your-api-key-here&#34;
# Optional
export OPENAI_API_BASE_URL=&#34;https://openrouter.ai/api/v1&#34;  # Use OpenRouter API
export OPENAI_MODEL=&#34;openai/gpt-4.1&#34;"><pre><span>export</span> OPENAI_API_KEY=<span><span>&#34;</span>your-api-key-here<span>&#34;</span></span>
<span><span>#</span> Optional</span>
<span>export</span> OPENAI_API_BASE_URL=<span><span>&#34;</span>https://openrouter.ai/api/v1<span>&#34;</span></span>  <span><span>#</span> Use OpenRouter API</span>
<span>export</span> OPENAI_MODEL=<span><span>&#34;</span>openai/gpt-4.1<span>&#34;</span></span></pre></div>
<p dir="auto">Or in your Python code (not recommended for production):</p>
<div dir="auto" data-snippet-clipboard-copy-content="import os
os.environ[&#34;OPENAI_API_KEY&#34;] = &#34;your-api-key-here&#34;"><pre><span>import</span> <span>os</span>
<span>os</span>.<span>environ</span>[<span>&#34;OPENAI_API_KEY&#34;</span>] <span>=</span> <span>&#34;your-api-key-here&#34;</span></pre></div>

<p dir="auto">By default, AutoGenLib does not cache generated code. This means:</p>
<ul dir="auto">
<li>Each time you import a module, the LLM generates fresh code</li>
<li>You get more varied and often funnier results due to LLM hallucinations</li>
<li>The same import might produce different implementations across runs</li>
</ul>
<p dir="auto">If you want to enable caching (for consistency or to reduce API calls):</p>
<div dir="auto" data-snippet-clipboard-copy-content="from autogenlib import init
init(&#34;Library for data processing&#34;, enable_caching=True)"><pre><span>from</span> <span>autogenlib</span> <span>import</span> <span>init</span>
<span>init</span>(<span>&#34;Library for data processing&#34;</span>, <span>enable_caching</span><span>=</span><span>True</span>)</pre></div>
<p dir="auto">Or toggle caching at runtime:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from autogenlib import init, set_caching
init(&#34;Library for data processing&#34;)

# Later in your code:
set_caching(True)  # Enable caching
set_caching(False)  # Disable caching"><pre><span>from</span> <span>autogenlib</span> <span>import</span> <span>init</span>, <span>set_caching</span>
<span>init</span>(<span>&#34;Library for data processing&#34;</span>)

<span># Later in your code:</span>
<span>set_caching</span>(<span>True</span>)  <span># Enable caching</span>
<span>set_caching</span>(<span>False</span>)  <span># Disable caching</span></pre></div>
<p dir="auto">When caching is enabled, generated code is stored in <code>~/.autogenlib_cache</code>.</p>

<ul dir="auto">
<li>Requires internet connection to generate new code</li>
<li>Depends on OpenAI API availability</li>
<li>Generated code quality depends on the clarity of your description</li>
<li>Not suitable for production-critical code without review</li>
</ul>

<div dir="auto"><h3 tabindex="-1" dir="auto">Inspecting Generated Code</h3><a id="user-content-inspecting-generated-code" aria-label="Permalink: Inspecting Generated Code" href="#inspecting-generated-code"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">You can inspect the code that was generated for a module:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from autogenlib.totp import totp_generator
import inspect
print(inspect.getsource(totp_generator))"><pre><span>from</span> <span>autogenlib</span>.<span>totp</span> <span>import</span> <span>totp_generator</span>
<span>import</span> <span>inspect</span>
<span>print</span>(<span>inspect</span>.<span>getsource</span>(<span>totp_generator</span>))</pre></div>
<div dir="auto"><h2 tabindex="-1" dir="auto">How AutoGenLib Uses the OpenAI API</h2><a id="user-content-how-autogenlib-uses-the-openai-api" aria-label="Permalink: How AutoGenLib Uses the OpenAI API" href="#how-autogenlib-uses-the-openai-api"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">AutoGenLib creates prompts for the OpenAI API that include:</p>
<ol dir="auto">
<li>The description you provided</li>
<li>Any existing code in the module being enhanced</li>
<li>The full context of all previously generated modules</li>
<li>The code that&#39;s importing the module/function (new feature!)</li>
<li>The specific function or feature needed</li>
</ol>
<p dir="auto">This comprehensive context helps the LLM generate code that&#39;s consistent with your existing codebase and fits perfectly with how you intend to use it.</p>

<p dir="auto">Contributions are not welcome! This is just a fun PoC project.</p>

<p dir="auto">MIT License</p>
<hr/>
<p dir="auto"><em>Note: This library is meant for prototyping and experimentation. Always review automatically generated code before using it in production environments.</em></p>
<p dir="auto"><em>Note: Of course 100% of the code of this library was generated via LLM</em></p>
</article></div></div>
  </body>
</html>
