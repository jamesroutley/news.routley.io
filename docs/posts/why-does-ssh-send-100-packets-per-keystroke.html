<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://eieio.games/blog/ssh-sends-100-packets-per-keystroke">Original</a>
    <h1>Why does SSH send 100 packets per keystroke?</h1>
    
    <div id="readability-page-1" class="page"><article>
<p>Here are a few lines of summarized <code>tcpdump</code> output for an ssh session where I send a single keystroke:</p>
<pre><code><span>$ ./first_lines_of_pcap.sh single-key.pcap
</span><span>  <span>1</span>   <span>0</span>.000s  CLIENT-<span>&gt;</span>SERVER   <span>36</span> bytes
</span><span>  <span>2</span>   <span>0</span>.007s  SERVER-<span>&gt;</span>CLIENT  <span>564</span> bytes
</span><span>  <span>3</span>   <span>0</span>.015s  CLIENT-<span>&gt;</span>SERVER    <span>0</span> bytes
</span><span>  <span>4</span>   <span>0</span>.015s  CLIENT-<span>&gt;</span>SERVER   <span>36</span> bytes
</span><span>  <span>5</span>   <span>0</span>.015s  SERVER-<span>&gt;</span>CLIENT   <span>36</span> bytes
</span><span>  <span>6</span>   <span>0</span>.026s  CLIENT-<span>&gt;</span>SERVER    <span>0</span> bytes
</span><span>  <span>7</span>   <span>0</span>.036s  CLIENT-<span>&gt;</span>SERVER   <span>36</span> bytes
</span><span>  <span>8</span>   <span>0</span>.036s  SERVER-<span>&gt;</span>CLIENT   <span>36</span> bytes
</span><span>  <span>9</span>   <span>0</span>.046s  CLIENT-<span>&gt;</span>SERVER    <span>0</span> bytes
</span><span> <span>10</span>   <span>0</span>.059s  CLIENT-<span>&gt;</span>SERVER   <span>36</span> bytes
</span></code></pre>
<p>I said a “few” because there are a <em>lot</em> of these lines.</p>
<pre><code><span>$ ./summarize_pcap.sh single-key.pcap
</span><span>Total packets: <span>270</span>
</span><span>
</span><span>  <span>36</span>-byte msgs:   <span>179</span> packets <span>(</span> <span>66.3</span>%<span>)</span>   <span>6444</span> bytes
</span><span>  Other data:       <span>1</span> packet  <span>(</span>  <span>0.4</span>%<span>)</span>    <span>564</span> bytes
</span><span>  TCP ACKs:        <span>90</span> packets <span>(</span> <span>33.3</span>%<span>)</span>
</span><span>
</span><span>  Data sent:      <span>6444</span> bytes <span>in</span> <span>36</span>-byte messages,  <span>564</span> bytes <span>in</span> other data
</span><span>  Ratio:          <span>11</span>.4x <span>more</span> data <span>in</span> <span>36</span>-byte messages than other data
</span><span>
</span><span>  Data packet rate: ~90 packets/second <span>(</span>avg <span>11.1</span> ms between data packets<span>)</span>
</span></code></pre>
<p>That is a lot of packets for one keypress. What’s going on here? Why do I care?</p>
<details><summary><svg xmlns="http://www.w3.org/2000/svg" width="20px" height="20px" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M1 12s4-8 11-8 11 8 11 8-4 8-11 8-11-8-11-8z"></path><circle cx="12" cy="12" r="3"></circle></svg> <!-- -->here&#39;s those scripts if you&#39;re curious</summary><pre><code><span>
</span><span>tshark <span>-r</span> <span>&#34;<span>$1</span>&#34;</span> <span>\</span>
</span><span>  <span>-T</span> fields <span>-e</span> frame.number <span>-e</span> frame.time_relative <span>-e</span> ip.src <span>-e</span> ip.dst <span>-e</span> tcp.len <span>|</span> <span>\</span>
</span><span>  <span>awk</span> <span>&#39;NR&lt;=10 {dir = ($3 ~ /71\.190/ ? &#34;CLIENT-&gt;SERVER&#34; : &#34;SERVER-&gt;CLIENT&#34;);
</span></span><span><span>       printf &#34;%3d  %6.3fs  %-4s  %3s bytes\n&#34;, $1, $2, dir, $5}&#39;</span>
</span></code></pre><pre><code><span>
</span><span>tshark <span>-r</span> <span>&#34;<span>$1</span>&#34;</span> <span>-Y</span> <span>&#34;frame.time_relative &lt;= 2.0&#34;</span> <span>-T</span> fields <span>-e</span> frame.time_relative <span>-e</span> tcp.len <span>|</span> <span>awk</span> <span>&#39;
</span></span><span><span>  {
</span></span><span><span>      count++
</span></span><span><span>      payload = $2
</span></span><span><span>
</span></span><span><span>      if (payload == 0) {
</span></span><span><span>          acks++
</span></span><span><span>      } else if (payload == 36) {
</span></span><span><span>          mystery++
</span></span><span><span>          if (NR &gt; 1 &amp;&amp; prev_data_time &gt; 0) {
</span></span><span><span>              delta = $1 - prev_data_time
</span></span><span><span>              sum_data_deltas += delta
</span></span><span><span>              data_intervals++
</span></span><span><span>          }
</span></span><span><span>          prev_data_time = $1
</span></span><span><span>      } else {
</span></span><span><span>          game_data++
</span></span><span><span>          game_bytes = payload
</span></span><span><span>          if (NR &gt; 1 &amp;&amp; prev_data_time &gt; 0) {
</span></span><span><span>              delta = $1 - prev_data_time
</span></span><span><span>              sum_data_deltas += delta
</span></span><span><span>              data_intervals++
</span></span><span><span>          }
</span></span><span><span>          prev_data_time = $1
</span></span><span><span>      }
</span></span><span><span>  }
</span></span><span><span>  END {
</span></span><span><span>      print &#34;Total packets:&#34;, count
</span></span><span><span>      print &#34;&#34;
</span></span><span><span>      printf &#34;  36-byte msgs:   %3d packets (%5.1f%%)  %5d bytes\n&#34;, mystery, 100*mystery/count, mystery*36
</span></span><span><span>      printf &#34;  Other data:     %3d packet  (%5.1f%%)  %5d bytes\n&#34;, game_data, 100*game_data/count, game_bytes
</span></span><span><span>      printf &#34;  TCP ACKs:       %3d packets (%5.1f%%)\n&#34;, acks, 100*acks/count
</span></span><span><span>      print &#34;&#34;
</span></span><span><span>      printf &#34;  Data sent:      %d bytes in 36-byte messages,  %d bytes in other data\n&#34;, mystery*36, game_bytes
</span></span><span><span>      printf &#34;  Ratio:          %.1fx more data in 36-byte messages than other data\n&#34;, (mystery*36)/game_bytes
</span></span><span><span>      print &#34;&#34;
</span></span><span><span>      avg_ms = (sum_data_deltas / data_intervals) * 1000
</span></span><span><span>      printf &#34;  Data packet rate: ~%d packets/second (avg %.1f ms between data packets)\n&#34;, int(1000/avg_ms + 0.5), avg_ms
</span></span><span><span>  }&#39;</span>
</span></code></pre></details>
<!-- -->
<h2 id="toc:discovery">Discovery</h2>
<p>I am working on a high-performance game that runs over ssh. The TUI for the game is created in <a href="https://github.com/charmbracelet/bubbletea">bubbletea</a> <a>1</a> and sent over ssh via <a href="https://github.com/charmbracelet/wish">wish</a>.</p>
<div data-is-footnote="true"><div><div><div><p><span>1</span></p><p>I have also forked bubbletea to make it faster. Stay tuned!</p></div></div></div></div>
<p>The game is played in an 80x60 window that I update 10 times a second. I’m targeting at least 2,000 concurrent players, which means updating ~100 million cells a second. I care about performance.</p>
<p>So I have a script that connects a few hundred bots over ssh and has them make a move a second. Then I use go’s <a href="https://pkg.go.dev/net/http/pprof">outstanding profiling tools</a> to look at what’s going on.</p>
<p>Yesterday I inadvertently broke my test harness. Instead of regularly sending game data, my server sent the bots a single message that said “your screen is too small.” This cut my game’s CPU and bandwidth usage in half.</p>
<p>At first I was disappointed. I (briefly) thought I had a free massive speedup on my hands, but it was actually a testing error.</p>
<p>But wait.</p>
<p><em>If I wasn’t sending game data back to my bots, why did CPU usage drop by 50% instead of 100%?</em></p>
<h2 id="toc:investigation">Investigation</h2>
<p>As part of debugging the test harness issue, I used <code>tcpdump</code> to log game traffic with and without the breaking change. Something like:</p>
<pre><code><span>
</span><span><span>timeout</span> 30s tcpdump <span>-i</span> eth0 <span>&#39;port 22&#39;</span> <span>-w</span> with-breaking-change.pcap
</span><span>
</span><span><span>timeout</span> 30s tcpdump <span>-i</span> eth0 <span>&#39;port 22&#39;</span> <span>-w</span> without-breaking-change.pcap
</span></code></pre>
<p>Our breaking change stopped us from rendering our game over ssh. So <code>with-breaking-change.pcap</code> contains packets that represent the <em>overhead</em> of each connection without actually rendering the game.</p>
<p>I was debugging this with Claude Code, so I asked it to summarize what it saw in the pcap.</p>
<pre><code><span>Wanna take a look yourself? I put with-breaking-change.pcap in this directory
</span><span>
</span><span>--
</span><span>
</span><span>Wow! Here&#39;s what I found:
</span><span>
</span><span>Packet Size Distribution (413,703 total packets):
</span><span>274,907 packets (66%): Exactly 36 bytes
</span><span>138,778 packets (34%): 0 bytes (TCP ACKs)
</span><span>18 packets (&lt;0.1%): 72 bytes
</span></code></pre>
<p>Further analysis on a smaller pcap pointed to these mysterious packets arriving ~20ms apart.</p>
<p>This was baffling to me (and to Claude Code). We kicked around several ideas like:</p>
<ul>
<li>SSH flow control messages</li>
<li>PTY size polling or other status checks</li>
<li>Some quirk of bubbletea or wish</li>
</ul>
<p>One thing stood out - these exchanges were initiated by my <em>ssh client</em> (stock ssh installed on MacOS) - not by my server.</p>
<p>On a hunch, I took a <code>tcpdump</code> of a regular ssh session.</p>
<pre><code><span>
</span><span><span>sudo</span> tcpdump <span>-ien0</span> <span>&#39;port 22&#39;</span>
</span><span>
</span><span>
</span><span><span>ssh</span> <span>$some_vm_of_mine</span>
</span></code></pre>
<p>I waited for the initial connection chatter to die down, sent one keystroke to my remote vm, and looked at the <code>tcpdump</code> output.</p>
<p>I saw the exact same pattern! What in the world?</p>
<h2 id="toc:root-cause">Root cause</h2>
<p>Once I realized that this was a property of stock ssh and not my game, debugging got a lot easier.</p>
<p>Running <code>ssh -vvv</code> gave me a pretty good sense of what was going on:</p>
<pre><code><span>debug3: obfuscate_keystroke_timing: starting: interval ~20ms
</span><span>debug3: obfuscate_keystroke_timing: stopping: chaff time expired (49 chaff packets sent) 
</span><span>debug3: obfuscate_keystroke_timing: starting: interval ~20ms
</span><span>debug3: obfuscate_keystroke_timing: stopping: chaff time expired (101 chaff packets sent)
</span></code></pre>
<p>That <code>20ms</code> is a smoking gun - it lines up perfectly with the mysterious pattern we saw earlier! And the rest of the message is pretty helpful too - we sent 49 “chaff” packets for the first keystroke and 101 “chaff” for around the second one.</p>
<p>In 2023, ssh added <a href="https://undeadly.org/cgi?action=article;sid=20230829051257">keystroke timing obfuscation</a>. The idea is that the speed at which you type different letters betrays some information about which letters you’re typing. So ssh sends lots of “chaff” packets along with your keystrokes to make it hard for an attacker to determine when you’re actually entering keys.</p>
<p>That makes a lot of sense for regular ssh sessions, where privacy is critical. But it’s a lot of overhead for an open-to-the-whole-internet game where <em>latency</em> is critical.</p>

<p>Keystroke obfuscation can be disabled client-side. After reverting my original breaking change, I tried updating my test harness to pass <code>ObscureKeystrokeTiming=no</code> when starting up ssh sessions.</p>
<p>This worked great. CPU usage dropped dramatically and bots still received valid data.</p>
<p>But this is hardly a solution in the real world. I want <code>ssh mygame</code> to Just Work without asking users to pass options that they might not understand.</p>
<p>Claude Code originally didn’t have much faith that we could disable this functionality server-side.</p>
<div><p><img alt="Screenshot of a claude code transcript. Full text:
User
Is there any way to disable responding to the chaff server-side?

Assistant
Probably not. Here&#39;s why:

The chaff packets are legitimate SSH protocol messages (likely SSH_MSG_CHANNEL_WINDOW_ADJUST). The server must respond to maintain the SSH connection according to the protocol spec - if it ignored them, the connection would stall or break.
" loading="lazy" width="1678" height="602" decoding="async" data-nimg="1" src="https://eieio.games/images/ssh-sends-100-packets-per-keystroke/probably-not.webp"/></p><p>generated with simon willison&#39;s excellent claude-code-transcripts tool</p></div>
<p>Fortunately, the <a href="https://undeadly.org/cgi?action=article&amp;sid=20230829051257">description</a> I found of SSH keystroke obfuscation made it easy to look up the relevant code in go’s ssh library (which I was transitively depending on).</p>
<pre><code><span>Log message:
</span><span>Introduce a transport-level ping facility
</span><span>
</span><span>This adds a pair of SSH transport protocol messages SSH2_MSG_PING/PONG
</span><span>to implement a ping capability. These messages use numbers in the &#34;local
</span><span>extensions&#34; number space and are advertised using a &#34;<a href="https://eieio.games/cdn-cgi/l/email-protection" data-cfemail="2e5e4740496e415e4b405d5d46004d4143">[email protected]</a>&#34;
</span><span>ext-info message with a string version number of &#34;0&#34;.
</span></code></pre>
<p>The “chaff” messages that ssh uses to obscure keystrokes are SSH2_MSG_PING messages. And they’re sent to servers that advertise the availability of the <code><a href="https://eieio.games/cdn-cgi/l/email-protection" data-cfemail="b0c0d9ded7f0dfc0d5dec3c3d89ed3dfdd">[email protected]</a></code> extension. What if we just…don’t advertise <code><a href="https://eieio.games/cdn-cgi/l/email-protection" data-cfemail="bcccd5d2dbfcd3ccd9d2cfcfd492dfd3d1">[email protected]</a></code>?</p>
<p>I searched <a href="https://cs.opensource.google/go/x/crypto/+/master:ssh/">go’s ssh library</a> for <code><a href="https://eieio.games/cdn-cgi/l/email-protection" data-cfemail="beced7d0d9fed1cedbd0cdcdd690ddd1d3">[email protected]</a></code> and found <a href="https://cs.opensource.google/go/x/crypto/+/833695f0a57b3037385dc9c0073bc88773cae6f3">the commit where support was added</a>. The commit was tiny and seemed <em>very</em> easy to revert.</p>
<p>I cloned the go crypto repo and told Claude to revert this change and update our dependencies to use our clone (<a href="https://go.dev/ref/mod#go-mod-file-replace">go’s replace directive</a> makes forking a library very easy).</p>
<p>Then I re-ran my test harness. The results were…very good:</p>
<pre><code><span>Total CPU  29.90%          -&gt; 11.64%
</span><span>Syscalls   3.10s           -&gt; 0.66s
</span><span>Crypto     1.6s            -&gt; 0.11s
</span><span>Bandwidth  ~6.5 Mbit/sec   -&gt; ~3 Mbit/sec
</span></code></pre>
<p>Claude was also pretty pumped:</p>
<div><p><img alt="Chat message from claude code. Full text:
HOLY COW! Look at that CPU usage:

Duration: 30.15s, Total samples = 3.51s (11.64%)
" loading="lazy" width="1658" height="290" decoding="async" data-nimg="1" src="https://eieio.games/images/ssh-sends-100-packets-per-keystroke/claude-pumped.webp"/></p><p>yes it&#39;s 1:30 am what of it</p></div>
<p>Obviously forking go’s crypto library is a little scary, and I’m gonna have to do some thinking about how to maintain my little patch in a safe way.</p>
<p>But this is a <em>huge</em> improvement. I’ve spent much of the last week squeezing out small single-digit performance wins. A &gt;50% drop was unimaginable to me.</p>
<h2 id="toc:debugging-with-llms-was-fun">Debugging with LLMs was fun</h2>
<p>I’ve been thinking about <a href="https://eieio.games/blog/will-ai-pet-my-dog-for-me/">whether LLMs remove parts of the problem-solving process that I enjoy</a>. But I’ve gotta say, debugging this problem using Claude Code was super fun.</p>
<p>I am familiar enough with <code>tcpdump</code>, <code>tshark</code>, and friends to know what they can do. But I don’t use them regularly enough to be fast with them. Being able to tell an agent “here’s a weird pcap - tell me what’s going on” was really lovely. And by watching commands as the agent ran them I was able to keep my mental model of the problem up to date.</p>
<p>There were still edge cases. At some point in my confusion I switched to ChatGPT  and it <em>very</em> confidently told me that my tcpdump output was normal ssh behavior:</p>
<div><p><img alt="ChatGPT message. Full text:
Yeah, that trace looks wild at first glance, but it’s mostly “normal” SSH/TCP behavior plus the fact that SSH is optimized for latency, not packet efficiency.

Let me unpack what you’re seeing and why it’s chewing CPU.

1. What those tcpdump lines actually are

From your snippet:
" loading="lazy" width="1350" height="464" decoding="async" data-nimg="1" src="https://eieio.games/images/ssh-sends-100-packets-per-keystroke/chatgpt-confident.webp"/></p><p>do all chatgpt messages have this tone and formatting now?</p></div>
<p>And then doubled down when I pushed back:</p>
<div><p><img alt="ChatGPT message. Full text:
Thought for 42s

Gotcha, that context helps a lot.

Short version:
What you’re seeing is almost certainly a ton of tiny writes being turned into a ton of tiny SSH records, not some special “per-keypress flow-control storm” in SSH itself.
" loading="lazy" width="1350" height="350" decoding="async" data-nimg="1" src="https://eieio.games/images/ssh-sends-100-packets-per-keystroke/chatgpt-confident2.webp"/></p><p>no!!!</p></div>
<p>Similarly, I had to push Claude Code to consider forking go’s ssh library. And I had to make the original leap of “wait…if our test harness was broken, why was usage not 0%?”</p>
<p>When you say “LLMs did not fully solve this problem” some people tend to respond with “you’re holding it wrong!”</p>
<p>I think they’re sometimes right! Interacting with LLMs is a new skill, and it feels pretty weird if you’re used to writing software like it’s 2020. A more talented user of LLMs may have trivially solved this problem.</p>
<p>But the best way to develop a skill is by practicing it. And for me, that means figuring out how to transfer my problem-solving intuitions to the tools that I’m using.</p>
<p>Besides. Being in the loop is fun. How else would I write this post?</p></article></div>
  </body>
</html>
