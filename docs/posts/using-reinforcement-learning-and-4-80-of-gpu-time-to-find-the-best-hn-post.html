<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://openpipe.ai/blog/hacker-news-rlhf-part-1">Original</a>
    <h1>Using reinforcement learning and $4.80 of GPU time to find the best HN post</h1>
    
    <div id="readability-page-1" class="page"><p data-framer-name="Title" data-framer-component-type="RichTextContainer"><h2 data-styles-preset="xlGGgKzvk">Using Reinforcement Learning and $4.80 of GPU Time to Find the Best HN Post Ever (RLHF Part 1)</h2></p><div data-framer-name="Content" data-framer-component-type="RichTextContainer"><p><em>Background: I‚Äôm Kyle, the founder of OpenPipe. OpenPipe is a managed fine-tuning service that makes it easy to build your own LLMs that achieve very high accuracy on a specific task. In this post we‚Äôll go under the covers and explain RLHF, which is one of the techniques we use to accomplish this.</em></p><p>What do the following Hacker News stories have in common?</p><p>None reached the front page; in fact none of them even got any upvotes! But <strong>they were all identified by a fine-tuned model as being likely to do well on HN</strong>. And subjectively (as someone who spends far more time on HN than I should) I actually agree with the model on this one; those all look like stories that deserved more attention than they got.</p><p>In this post we‚Äôll discuss how to build a <!--$--><a href="https://huggingface.co/docs/trl/main/en/reward_trainer" rel="noopener">reward model</a><!--/$--> that can predict the upvote count that a specific HN story will get. And in follow-up posts in this series, we‚Äôll use that reward model along with reinforcement learning to create a model that can write high-value HN stories!</p><h3>RL and RLHF: A 2-Minute Intro</h3><p><!--$--><a href="https://huggingface.co/tasks/reinforcement-learning" rel="noopener">Reinforcement learning</a><!--/$--> (RL) is a set of ML techniques that improves a model&#39;s performance by letting it take actions in an environment, and then get rewarded or penalized for those actions. Based on the rewards or penalties, the model‚Äôs behavior is updated over time to (hopefully) do more of the actions that are rewarded, and avoid those that are penalized.</p><p>Reinforcement learning from human feedback (RLHF) was developed by OpenAI and first described <!--$--><a href="https://openai.com/index/learning-from-human-preferences/" rel="noopener">here</a><!--/$--> as a way of adapting RL techniques to LLMs specifically. The first key step is to develop a <!--$--><a href="https://huggingface.co/docs/trl/main/en/reward_trainer" rel="noopener">reward model</a><!--/$-->, which is a model that takes an input and output from an LLM, and tries to predict how ‚Äúgood‚Äù the output is. The ‚Äúhuman feedback‚Äù part of RLHF refers to using humans to rate or compare outputs, and using that human preference data to train reward models. However, there are often other signals you can use to determine an output‚Äôs quality and train your model, as we‚Äôll see.</p><p>Once you have a reward model, the second step is to use it to improve the performance of your generation model, by training your model to create outputs that have a higher reward on average. There are lots of techniques possible here depending on your domain and the tools you have available‚Äîwe‚Äôll cover these in the next post!</p><h3>Whence Data?</h3><p>To train a good reward model, the most critical input is <strong>high-quality feedback data</strong>. This can take many forms. At OpenPipe we have some customers building ‚Äúco-pilot‚Äù or autocomplete flows, where the model suggests an action that the user can accept or reject. In this case, tracking whether an output was accepted or rejected is a great signal. For certain applications like chatbots or recommendation systems, you can proactively offer the user several potential outputs to choose from, and use which option they preferred as your feedback signal.</p><p>In our case we‚Äôll go with a readily available dataset: HN stories along with their upvote counts. Upvote counts are a great reward signal; while they‚Äôre somewhat noisy, upvote count is usually correlated with post quality. For convenience in this project, I‚Äôve scraped every HN post and comment ever (all 41 million of them!) and uploaded the full set <!--$--><a href="https://huggingface.co/datasets/OpenPipe/hacker-news" rel="noopener">here</a><!--/$-->. Using <!--$--><a href="https://pola.rs/" rel="noopener">Polars</a><!--/$-->, let‚Äôs take a quick look at how many posts and comments we have(1):</p><p><img alt="" data-framer-asset="data:framer/asset-reference,0cjXCFjnUcqeVy47SLH96YNpvdw.png" data-framer-height="622" data-framer-width="1206" height="311" src="https://framerusercontent.com/images/0cjXCFjnUcqeVy47SLH96YNpvdw.png" srcset="https://framerusercontent.com/images/0cjXCFjnUcqeVy47SLH96YNpvdw.png?scale-down-to=512 512w,https://framerusercontent.com/images/0cjXCFjnUcqeVy47SLH96YNpvdw.png?scale-down-to=1024 1024w,https://framerusercontent.com/images/0cjXCFjnUcqeVy47SLH96YNpvdw.png 1206w" width="603" data-framer-original-sizes="" sizes="(min-width: 1200px) 100vw, (max-width: 1199px) 100vw"/></p><h3>Defining the Task</h3><p>Ok, we have 5 million stories, that‚Äôs plenty to train a model! But we also have a problem. Our dataset has the story title, URL, date and submitter, but for most of the stories it doesn‚Äôt have the content, because it‚Äôs just an off-platform link. This might cause trouble for our reward model; a story‚Äôs content is often very important to whether users choose to upvote it or not. Without that information the reward model might not be able to make a good prediction!</p><p>One option would be to scrape the URLs for those 5 million posts (and hope they still exist). But to simplify, instead I‚Äôll just limit to stories that have only text bodies, instead of links. That leaves us with ~150K stories to deal with.</p><p><img alt="" data-framer-asset="data:framer/asset-reference,G6Zgc0MOhvkT5p4kCFfiuzrbZ2g.png" data-framer-height="573" data-framer-width="1754" height="286" src="https://framerusercontent.com/images/G6Zgc0MOhvkT5p4kCFfiuzrbZ2g.png" srcset="https://framerusercontent.com/images/G6Zgc0MOhvkT5p4kCFfiuzrbZ2g.png?scale-down-to=512 512w,https://framerusercontent.com/images/G6Zgc0MOhvkT5p4kCFfiuzrbZ2g.png?scale-down-to=1024 1024w,https://framerusercontent.com/images/G6Zgc0MOhvkT5p4kCFfiuzrbZ2g.png 1754w" width="877" data-framer-original-sizes="" sizes="(min-width: 1200px) 100vw, (max-width: 1199px) 100vw"/></p><p>Nice, that should be manageable! Let‚Äôs take a look at how those are distributed chronologically:</p><p><img alt="" data-framer-asset="data:framer/asset-reference,FbKFUkZPfeL9a1UuvFvZkhdaBs.png" data-framer-height="1470" data-framer-width="2970" height="735" src="https://framerusercontent.com/images/FbKFUkZPfeL9a1UuvFvZkhdaBs.png" srcset="https://framerusercontent.com/images/FbKFUkZPfeL9a1UuvFvZkhdaBs.png?scale-down-to=512 512w,https://framerusercontent.com/images/FbKFUkZPfeL9a1UuvFvZkhdaBs.png?scale-down-to=1024 1024w,https://framerusercontent.com/images/FbKFUkZPfeL9a1UuvFvZkhdaBs.png?scale-down-to=2048 2048w,https://framerusercontent.com/images/FbKFUkZPfeL9a1UuvFvZkhdaBs.png 2970w" width="1485" data-framer-original-sizes="" sizes="(min-width: 1200px) 100vw, (max-width: 1199px) 100vw"/></p><p><strong>Woah</strong>, the graph looks remarkably flat‚Ä¶ as long as you focus on the 2008-2015 period, or 2016-2024 period. But in 2015 there is a stark discontinuity, where the number of stories (with text) shoots up by &gt;10x, and the average score drops by 5x! Is this some kind of <!--$--><a href="https://en.wikipedia.org/wiki/Eternal_September" rel="noopener">eternal September</a><!--/$-->?</p><p>To avoid potential data drift issues from that discontinuity, we‚Äôll limit our dataset to the post-2016 stories. That way the model we create will be more attuned to what makes an HN story good or bad <em>today</em>, which will be helpful for future posts in the series.</p><p>Next, let‚Äôs quickly plot the distribution of story scores. For the rest of this exercise we‚Äôll actually use the <strong>natural log of post score</strong> as the number we‚Äôre tracking, instead of the raw score itself. This smooths out the distribution a bit, which will hopefully make life easier for our model. Effectively, this transformation means that its task will be to predict the ‚Äúorder of magnitude‚Äù of a score rather than the score directly. This intuitively maps more closely to what we want, which is a prediction of the ‚Äúorder of magnitude‚Äù of a post‚Äôs score. A model that can tell us whether a story should get popular at all is more tractable than one that tries to guess whether it will get 120 vs 200 upvotes (a harder task).</p><p><img alt="" data-framer-asset="data:framer/asset-reference,wgwpMwqZBHayeABYiwohFXlJA.png" data-framer-height="569" data-framer-width="1769" height="284" src="https://framerusercontent.com/images/wgwpMwqZBHayeABYiwohFXlJA.png" srcset="https://framerusercontent.com/images/wgwpMwqZBHayeABYiwohFXlJA.png?scale-down-to=512 512w,https://framerusercontent.com/images/wgwpMwqZBHayeABYiwohFXlJA.png?scale-down-to=1024 1024w,https://framerusercontent.com/images/wgwpMwqZBHayeABYiwohFXlJA.png 1769w" width="884" data-framer-original-sizes="" sizes="(min-width: 1200px) 100vw, (max-width: 1199px) 100vw"/></p><h3>Training the Model</h3><p>Actually training the model is easy and fun! You can find the full code I used <!--$--><a href="https://github.com/OpenPipe/best-hn/blob/main/stories_train_model_v3.py" rel="noopener">here</a><!--/$-->. A few things to call out:</p><ul><li data-preset-tag="p"><p>Since this isn‚Äôt a generative task (we‚Äôre just trying to predict a single score, not a string of text) our model architecture options are wide open! We could use classic encoder models like <!--$--><a href="https://arxiv.org/abs/1907.11692" rel="noopener">RoBERTa</a><!--/$--> or <!--$--><a href="https://arxiv.org/abs/2111.09543" rel="noopener">DeBERTaV3</a><!--/$-->, which are often used for this kind of problem. <strong>However</strong>, in practice I‚Äôve found that modern LLMs that do well on generative tasks are also extremely strong on this kind of predictive task, so I‚Äôve used <!--$--><a href="https://huggingface.co/meta-llama/Llama-3.1-8B" rel="noopener">Llama 3.1 8B</a><!--/$--> here(2).</p></li><li data-preset-tag="p"><p>It‚Äôs super important that your training inputs includes all the information your model will need to make predictions. In this case, I included the post title, author, date, and content. All of those factors could be relevant to the chance a story gets voted up.</p></li><li data-preset-tag="p"><p>I used the <!--$--><a href="https://github.com/linkedin/Liger-Kernel" rel="noopener">Liger Kernel</a><!--/$--> optimizations for both training and later inference. This sped up training time by ~30% and cut RAM usage significantly while maintaining model quality.</p></li></ul><p>Training on 114K stories for one epoch on an H100 on <!--$--><a href="https://www.runpod.io/" rel="noopener">Runpod</a><!--/$--> took about 1.5 hours and cost $4.05. That‚Äôs not much time for a model that (hopefully) understands all of HN!</p><p>We can also follow along the performance on our validation set as training happens:</p><p><img alt="" data-framer-asset="data:framer/asset-reference,pUUrTFODxi4Q2PACKEb2QTMGd4I.png" data-framer-height="842" data-framer-width="1398" height="421" src="https://framerusercontent.com/images/pUUrTFODxi4Q2PACKEb2QTMGd4I.png" srcset="https://framerusercontent.com/images/pUUrTFODxi4Q2PACKEb2QTMGd4I.png?scale-down-to=512 512w,https://framerusercontent.com/images/pUUrTFODxi4Q2PACKEb2QTMGd4I.png?scale-down-to=1024 1024w,https://framerusercontent.com/images/pUUrTFODxi4Q2PACKEb2QTMGd4I.png 1398w" width="699" data-framer-original-sizes="" sizes="(min-width: 1200px) 100vw, (max-width: 1199px) 100vw"/></p><p>The model finishes with a root mean-square error (RMSE) of 1.11. Remember, we‚Äôre asking the model to predict log(score). To translate that back to its accuracy on the real score we reverse the log: <em>e</em>^1.11 ~= 3. This means that <em>on average</em>, our model‚Äôs predicted score is off by a factor of <strong>3</strong>. Is that still good enough to be useful? We&#39;ll see!</p><h3>Running Inference</h3><p>Let‚Äôs see what our model thinks of all the HN stories! I used <!--$--><a href="https://github.com/OpenPipe/best-hn/blob/main/inference.py" rel="noopener">this code</a><!--/$--> to run our model against the entire corpus of HN stories. I found that using the <!--$--><a href="https://huggingface.co/docs/transformers/en/index" rel="noopener">Transformers</a><!--/$--> library, along with the Liger Kernels we used for training gave adequate performance without resorting to an inference-focused library like <!--$--><a href="https://github.com/sgl-project/sglang" rel="noopener">sglang</a><!--/$-->. I again ran this on an H100 on RunPod, and it only took 15 minutes to process all 140K stories in the corpus.</p><p>Ok, let‚Äôs limit to our test set and see how well our model does at predicting scores! Here‚Äôs a heatmap comparing the model‚Äôs predicted log(Score) on the Y-axis to the real log(Score) on the X-axis:</p><p><img alt="" data-framer-asset="data:framer/asset-reference,pNpLANmHNfqWhOQC5OtE1BCVc4.png" data-framer-height="1170" data-framer-width="1750" height="585" src="https://framerusercontent.com/images/pNpLANmHNfqWhOQC5OtE1BCVc4.png" srcset="https://framerusercontent.com/images/pNpLANmHNfqWhOQC5OtE1BCVc4.png?scale-down-to=512 512w,https://framerusercontent.com/images/pNpLANmHNfqWhOQC5OtE1BCVc4.png?scale-down-to=1024 1024w,https://framerusercontent.com/images/pNpLANmHNfqWhOQC5OtE1BCVc4.png 1750w" width="875" data-framer-original-sizes="" sizes="(min-width: 1200px) 100vw, (max-width: 1199px) 100vw"/></p><p>Interesting! The correlation is actually not bad (0.53), but our model is very consistently over-estimating the score at the low end, and underestimating it at the high end. This is surprising; some variation on any given data point is expected, but such a consistent mis-estimation trend isn‚Äôt what we‚Äôd expect.</p><p>What causes this? I don‚Äôt know for sure, but I suspect this is an artifact of the <strong>randomness in getting to the HN front page</strong>. You can think of a post‚Äôs predicted score as</p><p><code>predicted_score = (probability_of_hitting_front_page * final_score_if_it_hits_front_page)</code></p><p>Even if the model gets <em>extremely good</em> at predicting <code>final_score_if_it_hits_front_page</code>, there‚Äôs still the inherent randomness of <code>probability_of_hitting_front_page</code> that is fundamentally unpredictable. As a result, the model learns to ‚Äúhedge its bets‚Äù by predicting a score somewhere between 0 and the ‚Äútrue‚Äù predicted score if this story were to hit the front page.</p><p>So, <strong>how good are the stories it picks</strong>? Let‚Äôs take a look!</p><h3>Let‚Äôs see the stories!</h3><p>How well does the model do on identifying great HN stories? Here are the top 10 stories it predicts as most successful, with both the predicted and actual score(3).</p><p><img alt="" data-framer-asset="data:framer/asset-reference,fsY5awADsmvk74RkQJiPtZXtRrM.png" data-framer-height="964" data-framer-width="1736" height="482" src="https://framerusercontent.com/images/fsY5awADsmvk74RkQJiPtZXtRrM.png" srcset="https://framerusercontent.com/images/fsY5awADsmvk74RkQJiPtZXtRrM.png?scale-down-to=512 512w,https://framerusercontent.com/images/fsY5awADsmvk74RkQJiPtZXtRrM.png?scale-down-to=1024 1024w,https://framerusercontent.com/images/fsY5awADsmvk74RkQJiPtZXtRrM.png 1736w" width="868" data-framer-original-sizes="" sizes="(min-width: 1200px) 100vw, (max-width: 1199px) 100vw"/></p><p>Ok, those seem‚Ä¶ interesting. It seems like the model has correctly identified that service complaints (8/10) and people talking about indie apps making money (2/10) very reliably make it to the front page, which all 10 apparently did!</p><p>We can also look at the top stories that the model believes should be successful, but actually fell through the cracks. Here are the top-predicted-score stories with a real score of 1 (zero upvotes):</p><p><img alt="" data-framer-asset="data:framer/asset-reference,ZkpuvOPGIH6TT7Nua9dFWQXCg.png" data-framer-height="962" data-framer-width="1760" height="481" src="https://framerusercontent.com/images/ZkpuvOPGIH6TT7Nua9dFWQXCg.png" srcset="https://framerusercontent.com/images/ZkpuvOPGIH6TT7Nua9dFWQXCg.png?scale-down-to=512 512w,https://framerusercontent.com/images/ZkpuvOPGIH6TT7Nua9dFWQXCg.png?scale-down-to=1024 1024w,https://framerusercontent.com/images/ZkpuvOPGIH6TT7Nua9dFWQXCg.png 1760w" width="880" data-framer-original-sizes="" sizes="(min-width: 1200px) 100vw, (max-width: 1199px) 100vw"/></p><p>There are some nice gems on this list! Still a lot of complaints (4/10) but some more interesting content as well. There are some good diamonds in the rough there that probably should have sparked more discussion like <!--$--><a href="https://news.ycombinator.com/item?id=33413945" rel="noopener">dealing with Machiavellian co-founders</a><!--/$-->, <!--$--><a href="https://news.ycombinator.com/item?id=28747573" rel="noopener">pushing through burn-out</a><!--/$-->, and <!--$--><a href="https://news.ycombinator.com/item?id=25162971" rel="noopener">recording a signal from a single electron</a><!--/$-->.</p><h2>Part 2: Writing a Great HN Post</h2><p>Our reward model helps us define what a good HN post looks like. Is there anything else we can do with it? <strong>Yes</strong>! A fundamental property of machine learning is that if something can be measured, it can be optimized! So now that we can <strong>measure</strong> post quality, can we actually <strong>improve</strong> it? RLHF gives us a powerful set of techniques to do so, which we‚Äôll cover in the next post in the series. üôÇ</p><p>And as a final plug: if you have an AI-powered app deployed in production and a possible source of feedback, please <strong>contact me</strong> at <!--$--><a href="mailto:kyle@openpipe.ai" rel="noopener">kyle@openpipe.ai</a><!--/$-->. We are working closely with a number of design partners on improving our RLHF stack and would love to help you get better quality on your tasks!</p><p><strong>Footnotes</strong></p><ol><li data-preset-tag="p"><p>This query took 17 seconds to load the dataset into RAM and then aggregating by type was almost instant. It is absolutely incredible to me that I can load <em>every HN post and comment ever</em> into RAM in a few seconds on my (admittedly beefy) dev laptop, and analyze them at will. What an age of abundance!</p></li><li data-preset-tag="p"><p>We actually do <em>slightly</em> modify the architecture of the model to make it work more naturally as a reward model. Instead of the model‚Äôs final layer having a separate output for every possible token, we just have a single output that we train to predict the reward signal.</p></li><li data-preset-tag="p"><p>Since 80% of our stories were in the training set we have to worry about memorization here. Maybe the model is just <em>remembering</em> that these specific stories got a high score? After looking at the data a bit more closely though I don‚Äôt think that‚Äôs the case. only 7/10 of these stories were in the training set, less than the 80% proportion that were in the training set overall. So the model doesn‚Äôt seem to have the bias towards high-scoring stories in the training set you‚Äôd expect if it were just memorizing the distribution.</p></li></ol></div></div>
  </body>
</html>
