<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/georgia-tech-db/eva">Original</a>
    <h1>Show HN: EVA ‚Äì AI-Relational Database System</h1>
    
    <div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><p><a href="https://evadb.readthedocs.io/" rel="nofollow">
    <img src="https://raw.githubusercontent.com/georgia-tech-db/eva/master/docs/images/eva/eva-banner.png" alt="EVA" width="1000px"/>
  </a>
</p>

<p><a href="https://colab.research.google.com/github/georgia-tech-db/eva/blob/master/tutorials/03-emotion-analysis.ipynb" rel="nofollow">
            <img src="https://camo.githubusercontent.com/84f0493939e0c4de4e6dbe113251b4bfb5353e57134ffd9fcab6b8714514d4d1/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open EVA on Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg"/>
        </a>
        <a href="https://join.slack.com/t/eva-db/shared_invite/zt-1i10zyddy-PlJ4iawLdurDv~aIAq90Dg" rel="nofollow">
            <img alt="Slack" src="https://camo.githubusercontent.com/31d14662e57618e354174f5f9f18b087d7e6a28776ade48ba657246d8278a3fb/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f736c61636b2d6576612d6666363962342e7376673f6c6f676f3d736c61636b" data-canonical-src="https://img.shields.io/badge/slack-eva-ff69b4.svg?logo=slack"/>
        </a>          
        <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/6235b057733887b2636f1b0efb027d8a354382319fb463229733c8bc19e4273f/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f65766164622e737667"><img alt="PyPI" src="https://camo.githubusercontent.com/6235b057733887b2636f1b0efb027d8a354382319fb463229733c8bc19e4273f/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f65766164622e737667" data-canonical-src="https://img.shields.io/pypi/v/evadb.svg"/></a>
        <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/91a06dcb1fd47a3945fa2aca0db7be76ca77c19e4e1f674a7e9ecf581ca0546c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d417061636865253230322d627269676874677265656e2e7376673f6c6f676f3d617061636865"><img alt="License" src="https://camo.githubusercontent.com/91a06dcb1fd47a3945fa2aca0db7be76ca77c19e4e1f674a7e9ecf581ca0546c/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f6c6963656e73652d417061636865253230322d627269676874677265656e2e7376673f6c6f676f3d617061636865" data-canonical-src="https://img.shields.io/badge/license-Apache%202-brightgreen.svg?logo=apache"/></a>
        <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/d4fb159e53a3ae2030c7820654e6362ffcb3836dc1de0674d8e11747ab4caced/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f507974686f6e2d2d76657273696f6e732d332e372532307c253230332e382532307c253230332e392532307c253230332e31302d627269676874677265656e"><img alt="Python Versions" src="https://camo.githubusercontent.com/d4fb159e53a3ae2030c7820654e6362ffcb3836dc1de0674d8e11747ab4caced/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f507974686f6e2d2d76657273696f6e732d332e372532307c253230332e382532307c253230332e392532307c253230332e31302d627269676874677265656e" data-canonical-src="https://img.shields.io/badge/Python--versions-3.7%20|%203.8%20|%203.9%20|%203.10-brightgreen"/></a>
        <a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/af6cea08b407c86933c82bb360636c17ceb32f3b0cdb8f8669996f983588fbbc/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f67656f726769612d746563682d64622f6576612f62616467652e7376673f6272616e63683d6d6173746572"><img alt="Coverage Status" src="https://camo.githubusercontent.com/af6cea08b407c86933c82bb360636c17ceb32f3b0cdb8f8669996f983588fbbc/68747470733a2f2f636f766572616c6c732e696f2f7265706f732f6769746875622f67656f726769612d746563682d64622f6576612f62616467652e7376673f6272616e63683d6d6173746572" data-canonical-src="https://coveralls.io/repos/github/georgia-tech-db/eva/badge.svg?branch=master"/></a>            
</p>
<h3 tabindex="-1" dir="auto"><a id="user-content-eva-is-a-database-system-for-building-simpler-and-faster-ai-powered-applications" aria-label="Heading link" href="#eva-is-a-database-system-for-building-simpler-and-faster-ai-powered-applications"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a><b>EVA is a database system for building simpler and faster AI-powered applications.</b></h3> 
<p dir="auto">EVA is designed for supporting database applications that operate on both structured (tables, feature vectors) and unstructured data (videos, podcasts, PDFs, etc.) using deep learning models. It accelerates AI pipelines by 10-100x using a collection of optimizations inspired by time-tested relational database systems, including function caching, sampling, and cost-based predicate reordering. EVA supports an AI-oriented SQL-like query language tailored for analyzing unstructured data. It comes with a wide range of models for analyzing unstructured data, including models for image classification, object detection, OCR, text sentiment classification, face detection, etc. It is fully implemented in Python and licensed under the Apache license.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-quick-links" aria-label="Heading link" href="#quick-links"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Quick Links</h2>
<ul dir="auto">
<li><a href="#features">Features</a></li>
<li><a href="#quick-start">Quick Start</a></li>
<li><a href="#documentation">Documentation</a></li>
<li><a href="#demo">Demo</a></li>
<li><a href="#illustrative-applications">Illustrative Applications</a></li>
<li><a href="#community-and-support">Community and Support</a></li>
<li><a href="#contributing">Contributing</a></li>
<li><a href="#license">License</a></li>
</ul>
<h2 tabindex="-1" dir="auto"><a id="user-content-features" aria-label="Heading link" href="#features"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Features</h2>
<ul dir="auto">
<li><g-emoji alias="crystal_ball" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f52e.png">üîÆ</g-emoji> Build simpler AI-powered applications using short SQL-like queries</li>
<li><g-emoji alias="zap" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/26a1.png">‚ö°Ô∏è</g-emoji> 10-100x faster AI pipelines using AI-centric query optimization</li>
<li><g-emoji alias="moneybag" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4b0.png">üí∞</g-emoji> Save money spent on GPU-driven inference</li>
<li><g-emoji alias="rocket" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f680.png">üöÄ</g-emoji> First-class support for your custom deep learning models through user-defined functions</li>
<li><g-emoji alias="package" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4e6.png">üì¶</g-emoji> Built-in caching to eliminate redundant model invocations across queries</li>
<li><g-emoji alias="keyboard" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/2328.png">‚å®Ô∏è</g-emoji> First-class support for PyTorch and HuggingFace models</li>
<li><g-emoji alias="snake" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f40d.png">üêç</g-emoji> Installable via pip and fully implemented in Python</li>
</ul>
<h2 tabindex="-1" dir="auto"><a id="user-content-demo" aria-label="Heading link" href="#demo"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Demo</h2>
<p dir="auto">Here are some illustrative EVA-backed applications (all of them are Jupyter notebooks that can be opened in Google Colab):</p>
<ul dir="auto">
<li><g-emoji alias="crystal_ball" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f52e.png">üîÆ</g-emoji> <a href="https://evadb.readthedocs.io/en/stable/source/tutorials/03-emotion-analysis.html" rel="nofollow">Examining the emotion palette of actors in a movie</a></li>
<li><g-emoji alias="crystal_ball" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f52e.png">üîÆ</g-emoji> <a href="https://evadb.readthedocs.io/en/stable/source/tutorials/02-object-detection.html" rel="nofollow">Analysing traffic flow at an intersection </a></li>
<li><g-emoji alias="crystal_ball" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f52e.png">üîÆ</g-emoji> <a href="https://evadb.readthedocs.io/en/stable/source/tutorials/01-mnist.html" rel="nofollow">Classifying images based on their content</a></li>
<li><g-emoji alias="crystal_ball" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f52e.png">üîÆ</g-emoji> <a href="https://github.com/georgia-tech-db/license-plate-recognition">Recognizing license plates </a></li>
<li><g-emoji alias="crystal_ball" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f52e.png">üîÆ</g-emoji> <a href="https://github.com/georgia-tech-db/toxicity-classification">Analysing toxicity of social media memes </a></li>
</ul>
<h2 tabindex="-1" dir="auto"><a id="user-content-documentation" aria-label="Heading link" href="#documentation"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Documentation</h2>
<ul dir="auto">
<li><a href="https://evadb.readthedocs.io/" rel="nofollow">Detailed Documentation</a>
<ul dir="auto">
<li>If you are wondering why you might need an AI-relational database system, start with the page on <a href="https://evadb.readthedocs.io/en/stable/source/overview/video.html#" rel="nofollow">Video Database Systems</a>.</li>
<li>The <a href="https://evadb.readthedocs.io/en/stable/source/overview/installation.html" rel="nofollow">Getting Started</a> page shows how you can use EVA for different AI pipelines, and how you can easily extend EVA by defining an user-defined function that wraps around your custom deep learning model.</li>
<li>The <a href="https://evadb.readthedocs.io/en/stable/source/tutorials/index.html" rel="nofollow">User Guides</a> section contains Jupyter Notebooks that demonstrate how to use various features of EVA. Each notebook includes a link to Google Colab to run the code.</li>
</ul>
</li>
<li><a href="https://github.com/georgia-tech-db/eva/blob/master/tutorials/03-emotion-analysis.ipynb">Tutorials</a></li>
<li><a href="https://join.slack.com/t/eva-db/shared_invite/zt-1i10zyddy-PlJ4iawLdurDv~aIAq90Dg" rel="nofollow">Join Slack</a></li>
<li><a href="https://github.com/georgia-tech-db/eva/blob/master/tutorials/03-emotion-analysis.ipynb">Demo</a></li>
</ul>
<h2 tabindex="-1" dir="auto"><a id="user-content-quick-start" aria-label="Heading link" href="#quick-start"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Quick Start</h2>
<ul dir="auto">
<li>Install EVA using the pip package manager. EVA supports Python versions &gt;= 3.7.</li>
</ul>

<ul dir="auto">
<li>To launch and connect to an EVA server in a Jupyter notebook, check out this <a href="https://github.com/georgia-tech-db/eva/blob/master/tutorials/03-emotion-analysis.ipynb">illustrative emotion analysis notebook</a>:</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="cursor = connect_to_server()"><pre>cursor = <span>connect_to_server</span>()</pre></div>
<ul dir="auto">
<li>Load a video onto the EVA server (we use <a href="https://github.com/georgia-tech-db/eva/blob/master/data/ua_detrac/ua_detrac.mp4">ua_detrac.mp4</a> for illustration):</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="LOAD VIDEO &#34;data/ua_detrac/ua_detrac.mp4&#34; INTO TrafficVideo;"><pre>LOAD VIDEO <span><span>&#34;</span>data/ua_detrac/ua_detrac.mp4<span>&#34;</span></span> INTO TrafficVideo;</pre></div>
<ul dir="auto">
<li>That&#39;s it! You can now run queries over the loaded video:</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="SELECT id, data FROM TrafficVideo WHERE id &lt; 5;"><pre><span>SELECT</span> id, data <span>FROM</span> TrafficVideo <span>WHERE</span> id <span>&lt;</span> <span>5</span>;</pre></div>
<ul dir="auto">
<li>Search for frames in the video that contain a car</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="SELECT id, data FROM TrafficVideo WHERE [&#39;car&#39;] &lt;@ YoloV5(data).labels;"><pre><span>SELECT</span> id, data <span>FROM</span> TrafficVideo <span>WHERE</span> [<span><span>&#39;</span>car<span>&#39;</span></span>] <span>&lt;</span>@ YoloV5(data).labels;</pre></div>
<table>
<thead>
<tr>
<th>Source Video</th>
<th>Query Result</th>
</tr>
</thead>
<tbody>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/georgia-tech-db/eva/releases/download/v0.1.0/traffic-input.webp"><img alt="Source Video" src="https://github.com/georgia-tech-db/eva/releases/download/v0.1.0/traffic-input.webp" width="300"/></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/georgia-tech-db/eva/releases/download/v0.1.0/traffic-output.webp"><img alt="Query Result" src="https://github.com/georgia-tech-db/eva/releases/download/v0.1.0/traffic-output.webp" width="300"/></a></td>
</tr>
</tbody>
</table>
<ul dir="auto">
<li>Search for frames in the video that contain a pedestrian and a car</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="SELECT id, data FROM TrafficVideo WHERE [&#39;pedestrian&#39;, &#39;car&#39;] &lt;@ YoloV5(data).labels;"><pre><span>SELECT</span> id, data <span>FROM</span> TrafficVideo <span>WHERE</span> [<span><span>&#39;</span>pedestrian<span>&#39;</span></span>, <span><span>&#39;</span>car<span>&#39;</span></span>] <span>&lt;</span>@ YoloV5(data).labels;</pre></div>
<ul dir="auto">
<li>Search for frames with more than three cars</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="SELECT id, data FROM TrafficVideo WHERE ArrayCount(YoloV5(data).labels, &#39;car&#39;) &gt; 3;"><pre><span>SELECT</span> id, data <span>FROM</span> TrafficVideo <span>WHERE</span> ArrayCount(YoloV5(data).labels, <span><span>&#39;</span>car<span>&#39;</span></span>) <span>&gt;</span> <span>3</span>;</pre></div>
<ul dir="auto">
<li><strong>Use your custom deep learning model in queries</strong> with a user-defined function (UDF):</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="CREATE UDF IF NOT EXISTS MyUDF
INPUT  (frame NDARRAY UINT8(3, ANYDIM, ANYDIM))
OUTPUT (labels NDARRAY STR(ANYDIM), bboxes NDARRAY FLOAT32(ANYDIM, 4),
        scores NDARRAY FLOAT32(ANYDIM))
TYPE  Classification
IMPL  &#39;eva/udfs/fastrcnn_object_detector.py&#39;;"><pre>CREATE UDF IF NOT EXISTS MyUDF
INPUT  (frame NDARRAY UINT8(<span>3</span>, ANYDIM, ANYDIM))
OUTPUT (labels NDARRAY STR(ANYDIM), bboxes NDARRAY FLOAT32(ANYDIM, <span>4</span>),
        scores NDARRAY FLOAT32(ANYDIM))
TYPE  Classification
IMPL  <span><span>&#39;</span>eva/udfs/fastrcnn_object_detector.py<span>&#39;</span></span>;</pre></div>
<ul dir="auto">
<li><strong>Compose multiple models in a single query</strong> to set up useful AI pipelines.</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="   -- Analyse emotions of faces in a video
   SELECT id, bbox, EmotionDetector(Crop(data, bbox)) 
   FROM MovieVideo JOIN LATERAL UNNEST(FaceDetector(data)) AS Face(bbox, conf)  
   WHERE id &lt; 15;"><pre>   <span><span>--</span> Analyse emotions of faces in a video</span>
   <span>SELECT</span> id, bbox, EmotionDetector(Crop(data, bbox)) 
   <span>FROM</span> MovieVideo <span>JOIN</span> LATERAL UNNEST(FaceDetector(data)) <span>AS</span> Face(bbox, conf)  
   <span>WHERE</span> id <span>&lt;</span> <span>15</span>;</pre></div>
<ul dir="auto">
<li>
<p dir="auto"><strong>EVA runs queries faster using its AI-centric query optimizer</strong>. Two key optimizations are:</p>
<p dir="auto"><g-emoji alias="floppy_disk" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f4be.png">üíæ</g-emoji> <strong>Caching</strong>: EVA automatically caches and reuses previous query results (especially model inference results), eliminating redundant computation and reducing query processing time.</p>
<p dir="auto"><g-emoji alias="dart" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f3af.png">üéØ</g-emoji> <strong>Predicate Reordering</strong>: EVA optimizes the order in which the query predicates are evaluated (e.g., runs the faster, more selective model first), leading to faster queries and lower inference costs.</p>
</li>
</ul>
<p dir="auto">Consider these two exploratory queries on a dataset of <g-emoji alias="dog2" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f415.png">üêï</g-emoji> images:
<a target="_blank" rel="noopener noreferrer" href="https://github.com/georgia-tech-db/eva/blob/master/data/assets/eva_performance_comparison.png?raw=true"><img width="40%" src="https://github.com/georgia-tech-db/eva/raw/master/data/assets/eva_performance_comparison.png?raw=true"/></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="  -- Query 1: Find all images of black-colored dogs
  SELECT id, bbox FROM dogs 
  JOIN LATERAL UNNEST(YoloV5(data)) AS Obj(label, bbox, score) 
  WHERE Obj.label = &#39;dog&#39; 
    AND Color(Crop(data, bbox)) = &#39;black&#39;; 

  -- Query 2: Find all Great Danes that are black-colored
  SELECT id, bbox FROM dogs 
  JOIN LATERAL UNNEST(YoloV5(data)) AS Obj(label, bbox, score) 
  WHERE Obj.label = &#39;dog&#39; 
    AND DogBreedClassifier(Crop(data, bbox)) = &#39;great dane&#39; 
    AND Color(Crop(data, bbox)) = &#39;black&#39;;"><pre>  <span><span>--</span> Query 1: Find all images of black-colored dogs</span>
  <span>SELECT</span> id, bbox <span>FROM</span> dogs 
  <span>JOIN</span> LATERAL UNNEST(YoloV5(data)) <span>AS</span> Obj(label, bbox, score) 
  <span>WHERE</span> <span>Obj</span>.<span>label</span> <span>=</span> <span><span>&#39;</span>dog<span>&#39;</span></span> 
    <span>AND</span> Color(Crop(data, bbox)) <span>=</span> <span><span>&#39;</span>black<span>&#39;</span></span>; 

  <span><span>--</span> Query 2: Find all Great Danes that are black-colored</span>
  <span>SELECT</span> id, bbox <span>FROM</span> dogs 
  <span>JOIN</span> LATERAL UNNEST(YoloV5(data)) <span>AS</span> Obj(label, bbox, score) 
  <span>WHERE</span> <span>Obj</span>.<span>label</span> <span>=</span> <span><span>&#39;</span>dog<span>&#39;</span></span> 
    <span>AND</span> DogBreedClassifier(Crop(data, bbox)) <span>=</span> <span><span>&#39;</span>great dane<span>&#39;</span></span> 
    <span>AND</span> Color(Crop(data, bbox)) <span>=</span> <span><span>&#39;</span>black<span>&#39;</span></span>;</pre></div>
<p dir="auto">By reusing the results of the first query and reordering the predicates based on the available cached inference results, EVA runs the second query <strong>10x faster</strong>!</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-illustrative-applications" aria-label="Heading link" href="#illustrative-applications"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Illustrative Applications</h2>
<h3 tabindex="-1" dir="auto"><a id="user-content--traffic-analysis-object-detection-model" aria-label="Heading link" href="#-traffic-analysis-object-detection-model"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a><g-emoji alias="crystal_ball" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f52e.png">üîÆ</g-emoji> <a href="https://evadb.readthedocs.io/en/stable/source/tutorials/02-object-detection.html" rel="nofollow">Traffic Analysis</a> (Object Detection Model)</h3>
<table>
<thead>
<tr>
<th>Source Video</th>
<th>Query Result</th>
</tr>
</thead>
<tbody>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/georgia-tech-db/eva/releases/download/v0.1.0/traffic-input.webp"><img alt="Source Video" src="https://github.com/georgia-tech-db/eva/releases/download/v0.1.0/traffic-input.webp" width="300"/></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/georgia-tech-db/eva/releases/download/v0.1.0/traffic-output.webp"><img alt="Query Result" src="https://github.com/georgia-tech-db/eva/releases/download/v0.1.0/traffic-output.webp" width="300"/></a></td>
</tr>
</tbody>
</table>
<h3 tabindex="-1" dir="auto"><a id="user-content--mnist-digit-recognition-image-classification-model" aria-label="Heading link" href="#-mnist-digit-recognition-image-classification-model"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a><g-emoji alias="crystal_ball" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f52e.png">üîÆ</g-emoji> <a href="https://evadb.readthedocs.io/en/stable/source/tutorials/01-mnist.html" rel="nofollow">MNIST Digit Recognition</a> (Image Classification Model)</h3>
<table>
<thead>
<tr>
<th>Source Video</th>
<th>Query Result</th>
</tr>
</thead>
<tbody>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/georgia-tech-db/eva/releases/download/v0.1.0/mnist-input.webp"><img alt="Source Video" src="https://github.com/georgia-tech-db/eva/releases/download/v0.1.0/mnist-input.webp" width="150"/></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/georgia-tech-db/eva/releases/download/v0.1.0/mnist-output.webp"><img alt="Query Result" src="https://github.com/georgia-tech-db/eva/releases/download/v0.1.0/mnist-output.webp" width="150"/></a></td>
</tr>
</tbody>
</table>
<h3 tabindex="-1" dir="auto"><a id="user-content--movie-emotion-analysis-face-detection--emotion-classfication-models" aria-label="Heading link" href="#-movie-emotion-analysis-face-detection--emotion-classfication-models"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a><g-emoji alias="crystal_ball" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f52e.png">üîÆ</g-emoji> <a href="https://evadb.readthedocs.io/en/stable/source/tutorials/03-emotion-analysis.html" rel="nofollow">Movie Emotion Analysis</a> (Face Detection + Emotion Classfication Models)</h3>
<table>
<thead>
<tr>
<th>Source Video</th>
<th>Query Result</th>
</tr>
</thead>
<tbody>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/georgia-tech-db/eva/releases/download/v0.1.0/gangubai-input.webp"><img alt="Source Video" src="https://github.com/georgia-tech-db/eva/releases/download/v0.1.0/gangubai-input.webp" width="400"/></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/georgia-tech-db/eva/releases/download/v0.1.0/gangubai-output.webp"><img alt="Query Result" src="https://github.com/georgia-tech-db/eva/releases/download/v0.1.0/gangubai-output.webp" width="400"/></a></td>
</tr>
</tbody>
</table>
<h3 tabindex="-1" dir="auto"><a id="user-content--license-plate-recognition-plate-detection--ocr-extraction-models" aria-label="Heading link" href="#-license-plate-recognition-plate-detection--ocr-extraction-models"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a><g-emoji alias="crystal_ball" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f52e.png">üîÆ</g-emoji> <a href="https://github.com/georgia-tech-db/eva-application-template">License Plate Recognition</a> (Plate Detection + OCR Extraction Models)</h3>
<table>
<thead>
<tr>
<th>Query Result</th>
</tr>
</thead>
<tbody>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/georgia-tech-db/license-plate-recognition/blob/main/README_files/README_12_3.png"><img alt="Query Result" src="https://github.com/georgia-tech-db/license-plate-recognition/raw/main/README_files/README_12_3.png" width="300"/></a></td>
</tr>
</tbody>
</table>
<h3 tabindex="-1" dir="auto"><a id="user-content--meme-toxicity-classification-ocr-extraction--toxicity-classification-models" aria-label="Heading link" href="#-meme-toxicity-classification-ocr-extraction--toxicity-classification-models"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a><g-emoji alias="crystal_ball" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f52e.png">üîÆ</g-emoji> <a href="https://github.com/georgia-tech-db/toxicity-classification">Meme Toxicity Classification</a> (OCR Extraction + Toxicity Classification Models)</h3>
<table>
<thead>
<tr>
<th>Query Result</th>
</tr>
</thead>
<tbody>
<tr>
<td><a target="_blank" rel="noopener noreferrer nofollow" href="https://raw.githubusercontent.com/georgia-tech-db/toxicity-classification/main/README_files/README_16_2.png"><img alt="Query Result" src="https://raw.githubusercontent.com/georgia-tech-db/toxicity-classification/main/README_files/README_16_2.png" width="200"/></a></td>
</tr>
</tbody>
</table>
<h2 tabindex="-1" dir="auto"><a id="user-content-community-and-support" aria-label="Heading link" href="#community-and-support"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Community and Support</h2>
<p dir="auto"><g-emoji alias="wave" fallback-src="https://github.githubassets.com/images/icons/emoji/unicode/1f44b.png">üëã</g-emoji> If you have general questions about EVA, want to say hello or just follow along, we&#39;d like to invite you to join our <a href="https://join.slack.com/t/eva-db/shared_invite/zt-1i10zyddy-PlJ4iawLdurDv~aIAq90Dg" rel="nofollow">Slack Community</a>.</p>
<a href="https://join.slack.com/t/eva-db/shared_invite/zt-1i10zyddy-PlJ4iawLdurDv~aIAq90Dg" rel="nofollow">              
    <img src="https://raw.githubusercontent.com/georgia-tech-db/eva/master/docs/images/eva/eva-slack.png" alt="EVA Slack Channel" width="500"/>
</a>
<p dir="auto">If you run into any problems or issues, please create a Github issue and we&#39;ll try our best to help.</p>
<p dir="auto">Don&#39;t see a feature in the list? Search our issue tracker if someone has already requested it and add a comment to it explaining your use-case, or open a new issue if not. We prioritize our roadmap based on user feedback, so we&#39;d love to hear from you.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-contributing" aria-label="Heading link" href="#contributing"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Contributing</h2>
<p dir="auto"><a href="https://pypi.org/project/evadb" rel="nofollow"><img src="https://camo.githubusercontent.com/6235b057733887b2636f1b0efb027d8a354382319fb463229733c8bc19e4273f/68747470733a2f2f696d672e736869656c64732e696f2f707970692f762f65766164622e737667" alt="PyPI Version" data-canonical-src="https://img.shields.io/pypi/v/evadb.svg"/></a>
<a href="https://circleci.com/gh/georgia-tech-db/eva" rel="nofollow"><img src="https://camo.githubusercontent.com/b3d8e3dd6bdebd8b5e397338435af85f28fed09a4191fb1fdbbd00ca5ccc463d/68747470733a2f2f636972636c6563692e636f6d2f67682f67656f726769612d746563682d64622f6576612e7376673f7374796c653d737667" alt="CI Status" data-canonical-src="https://circleci.com/gh/georgia-tech-db/eva.svg?style=svg"/></a>
<a href="https://evadb.readthedocs.io/en/stable/index.html" rel="nofollow"><img src="https://camo.githubusercontent.com/41956a71a3eb1087fec3bcd0b915dc2992ae1f00a9605461767cc674611e6245/68747470733a2f2f72656164746865646f63732e6f72672f70726f6a656374732f65766164622f62616467652f3f76657273696f6e3d737461626c65" alt="Documentation Status" data-canonical-src="https://readthedocs.org/projects/evadb/badge/?version=stable"/></a></p>
<p dir="auto">EVA is the beneficiary of many <a href="https://github.com/georgia-tech-db/eva/graphs/contributors">contributors</a>. All kinds of contributions to EVA are appreciated. To file a bug or to request a feature, please use <a href="https://github.com/georgia-tech-db/eva/issues">GitHub issues</a>. <a href="https://github.com/georgia-tech-db/eva/pulls">Pull requests</a> are welcome.</p>
<p dir="auto">For more information, see our
<a href="https://evadb.readthedocs.io/en/stable/source/contribute/index.html" rel="nofollow">contribution guide</a>.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-license" aria-label="Heading link" href="#license"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>License</h2>
<p dir="auto">Copyright (c) 2018-present <a href="http://db.cc.gatech.edu/" rel="nofollow">Georgia Tech Database Group</a>.
Licensed under <a href="https://github.com/georgia-tech-db/eva/blob/master/LICENSE">Apache License</a>.</p>
</article>
          </div></div>
  </body>
</html>
