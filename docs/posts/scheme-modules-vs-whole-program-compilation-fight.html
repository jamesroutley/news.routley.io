<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="http://wingolog.org/archives/2024/01/05/scheme-modules-vs-whole-program-compilation-fight">Original</a>
    <h1>Scheme modules vs. whole-program compilation: fight</h1>
    
    <div id="readability-page-1" class="page"><div><p>In a recent dispatch, I explained <a href="https://wingolog.org/archives/2023/11/16/a-whiff-of-whiffle">the whole-program compilation
strategy used in Whiffle and
Hoot</a>.
Today’s note explores what a correct solution might look like.</p><h3>being explicit</h3><p>Consider a module that exports an increment-this-integer procedure.
We’ll use syntax from the <a href="https://standards.scheme.org/corrected-r6rs/r6rs-Z-H-10.html#node_chap_7">R6RS
standard</a>:</p><pre>(library (inc)
  (export inc)
  (import (rnrs))
  (define (inc n) (+ n 1)))
</pre><p>If we then have a program:</p><pre>(import (rnrs) (inc))
(inc 42)
</pre><p>Then the meaning of this program is clear: it reduces to <tt>(+ 42 1)</tt>,
then to 43.  Fine enough.  But how do we get there?  How does the
compiler compose the program with the modules that it uses
(transitively), to produce a single output?</p><p>In
<a href="https://wingolog.org/archives/2023/11/13/i-accidentally-a-scheme">Whiffle</a>
(and <a href="https://gitlab.com/spritely/guile-hoot">Hoot</a>), the answer is,
sloppily.  There is a <a href="https://github.com/wingo/whiffle/blob/main/runtime/prelude.scm">standard
prelude</a>
that initially has a number of bindings from the host compiler,
<a href="https://gnu.org/s/guile/">Guile</a>.  One of these is <tt>+</tt>, exposed under
the name <tt>%+</tt>, where the <tt>%</tt> in this case is just a warning to the reader that this is a weird
primitive binding.  Using this primitive, the prelude defines a
wrapper:</p><pre>...
(define (+ x y) (%+ x y))
...
</pre><p>At compilation-time, Guile’s compiler recognizes <tt>%+</tt> as special, and
therefore compiles the body of <tt>+</tt> as consisting of a primitive call
(<i>primcall</i>), in this case to the addition primitive.  The Whiffle (and Hoot, and
native Guile) back-ends then avoid referencing an imported binding when
compiling <tt>%+</tt>, and instead produce backend-specific code: <tt>%+</tt>
disappears.  Most uses of the <tt>+</tt> wrapper get inlined so <tt>%+</tt> ends up
generating code all over the program.</p><p>The prelude is lexically splatted into the compilation unit via a
pre-expansion phase, so you end up with something like:</p><pre>(let () ; establish lexical binding contour
  ...
  (define (+ x y) (%+ x y))
  ...
  (let () ; new nested contour
    (define (inc n) (+ n 1))
    (inc 42)))
</pre><p>This program will probably optimize (via partial evaluation) to just
<tt>43</tt>.  (What about <tt>let</tt> and <tt>define</tt>?  Well.  Perhaps we’ll get to
that.)</p><p>But, again here I have taken a short-cut, which is about modules.  Hoot
and Whiffle don’t really do modules, yet anyway.  I keep telling
Spritely colleagues that it’s complicated, and rightfully they keep
asking why, so this article gets into it.</p><h3>is it really a big <tt>letrec</tt>?</h3><p>Firstly you have to ask, what is the compilation unit anyway?  I mean,
given a set of modules <i>A</i>, <i>B</i>, <i>C</i> and so on, you could choose to
compile them separately, relying on the dynamic linker to compose them
at run-time, or all together, letting the compiler gnaw on them all at
once.  Or, just <i>A</i> and <i>B</i>, and so on.  One good-enough answer to this
problem is
<a href="https://www.andykeep.com/pubs/scheme-10.pdf"><tt>library-group</tt></a> form,
which explicitly defines a set of topologically-sorted modules that
should be compiled together.  In our case, to treat the <tt>(inc)</tt> module
together with our example program as one compilation unit, we would
have:</p><pre>(library-group
  ;; start with sequence of libraries
  ;; to include in compilation unit...
  (library (inc) ...)

  ;; then the tail is the program that
  ;; might use the libraries
  (import (rnrs) (inc))
  (inc 42))
</pre><p>In this example, the <tt>(rnrs)</tt> base library is not part of the
compilation unit.  Presumably it will be linked in, either as a build
step or dynamically at run-time.  For Hoot we would want the whole
prelude to be included, because we don’t want any run-time dependencies.
Anyway hopefully this would expand out to something like the set of
nested <tt>define</tt> forms inside nested <tt>let</tt> lexical contours.</p><p>And that was my instinct: somehow we are going to smash all these
modules together into a big nested <tt>letrec</tt>, and the compiler will go to
town.  And this would work, for a “normal” programming language.</p><p>But with Scheme, there is a problem: macros.  Scheme is a “programmable
programming language” that allows users to extend its syntax as well as
its semantics.  R6RS defines a procedural syntax transformer (“macro”)
facility, in which the user can define functions that run on code at
compile-time (specifically, during syntax expansion).  Scheme macros
manage to compose lexical scope from the macro definition with the scope
at the macro instantiation site, by annotating these expressions with
source location and scope information, and making syntax transformers
mostly preserve those annotations.</p><p>“Macros are great!”, you say: well yes, of course.  But they are a
problem too.  Consider this incomplete library:</p><pre>(library (ctinc)
  (import (rnrs) (inc))
  (export ctinc)
  (define-syntax ctinc
    (lambda (stx)
      ...)) // ***
</pre><p>The idea is to define a version of <tt>inc</tt>, but at compile-time: a <tt>(ctinc 42)</tt> form should expand directly to <tt>43</tt>, not a call to <tt>inc</tt> (or even
<tt>+</tt>, or <tt>%+</tt>).  We define syntax transformers with <tt>define-syntax</tt>
instead of <tt>define</tt>.  The right-hand-side of the definition (<tt>(lambda (stx) ...)</tt>) should be a procedure of one argument, which returns one
value: so far so good.  Or is it?  How do we actually evaluate what
<tt>(lambda (stx) ...)</tt> means?  What should we fill in for <tt>...</tt>?  When
evaluating the transformer value, what definitions are in scope?  What
does <tt>lambda</tt> even mean in this context?</p><p>Well... here we butt up against the phasing wars of the mid-2000s.  R6RS
defines a <a href="https://standards.scheme.org/corrected-r6rs/r6rs-Z-H-10.html#node_sec_7.2">whole system to explicitly declare what bindings are
available
when</a>,
then carves out a huge exception to allow for so-called <a href="https://cs.indiana.edu/~dyb/pubs/implicit-phasing.pdf">implicit
phasing</a>, in
which the compiler figures it out on its own.  In this example we
imported <tt>(rnrs)</tt> for the default phase, and this is the module that
defines <tt>lambda</tt> (and indeed <tt>define</tt> and <tt>define-syntax</tt>).  The
standard defines that <tt>(rnrs)</tt> makes its bindings available both at
run-time and expansion-time (compilation-time), so <tt>lambda</tt> means what
we expect that it does.  Whew!  Let’s just assume implicit phasing,
going forward.</p><p>The operand to the syntax transformer is a <i>syntax object</i>: an
expression annotated with source and scope information.  To pick it
apart, R6RS defines a pattern-matching helper, <tt>syntax-case</tt>.  In our
case <tt>ctinc</tt> is unary, so we can begin to flesh out the syntax
transformer:</p><pre>(library (ctinc)
  (import (rnrs) (inc))
  (export ctinc)
  (define-syntax ctinc
    (lambda (stx)
      (syntax-case stx ()
        ((ctinc n)
         (inc n)))))) // ***
</pre><p>But here there’s a detail, which is that when <tt>syntax-case</tt> destructures
<i>stx</i> to its parts, those parts themselves are syntax objects which
carry the scope and source location annotations.  To strip those
annotations, we call the <tt>syntax-&gt;datum</tt> procedure, exported by
<tt>(rnrs)</tt>.</p><pre>(library (ctinc)
  (import (rnrs) (inc))
  (export ctinc)
  (define-syntax ctinc
    (lambda (stx)
      (syntax-case stx ()
        ((ctinc n)
         (inc (syntax-&gt;datum #&#39;n)))))))
</pre><p>And with this, voilà our program:</p><pre>(library-group
  (library (inc) ...)
  (library (ctinc) ...)
  (import (rnrs) (ctinc))
  (ctinc 42))
</pre><p>This program should pre-expand to something like:</p><pre>(let ()
  (define (inc n) (+ n 1))
  (let ()
    (define-syntax ctinc
      (lambda (stx)
        (syntax-case stx ()
          ((ctinc n)
           (inc (syntax-&gt;datum #&#39;n))))))
    (ctinc 42)))
</pre><p>And then expansion should transform <tt>(ctinc 42)</tt> to 43.  However, our
naïve pre-expansion is not good enough for this to be possible.  If you
ran this in Guile you would get an error:</p><pre>Syntax error:
unknown file:8:12: reference to identifier outside its scope in form inc
</pre><p>Which is to say, <tt>inc</tt> is not available as a value within the definition
of <tt>ctinc</tt>.  <tt>ctinc</tt> could residualize an expression that <i>refers</i> to
<tt>inc</tt>, but it can’t use it to produce the output.</p><h3>modules are not expressible with local lexical binding</h3><p>This brings us to the heart of the issue: with procedural macros,
modules impose a phasing discipline on the expansion process.
Definitions from any given module must be available both at expand-time
and at run-time.  In our example, <tt>ctinc</tt> needs <tt>inc</tt> at expand-time,
which is an early part of the compiler that is unrelated to any later
partial evaluation by the optimizer.  We can’t make <tt>inc</tt> available at
expand-time just using <tt>let</tt> / <tt>letrec</tt> bindings.</p><p>This is an annoying result!  What do other languages do?  Well, mostly
they aren’t programmable, in the sense that they don’t have macros.
There are some ways to get programmability using e.g. <tt>eval</tt> in
JavaScript, but these systems are not very amenable to “offline”
analysis of the kind needed by an ahead-of-time compiler.</p><p>For those declarative languages with macros, Scheme included, I
understand the state of the art is to expand module-by-module and then
stitch together the results of expansion later, using a kind of
link-time optimization.  You visit a module’s definitions twice: once to
evaluate them while expanding, resulting in live definitions that can be
used by further syntax expanders, and once to residualize an abstract
syntax tree, which will eventually be spliced into the compilation unit.</p><p>Note that in general the expansion-time and the residual definitions
don’t need to be the same, and indeed during cross-compilation they are
often different.  If you are compiling with Guile as host and Hoot as
target, you might implement <tt>cons</tt> one way in Guile and another way in
Hoot, choosing between them with <tt>cond-expand</tt>.</p><h3>lexical scope regained?</h3><p>What is to be done?  Glad you asked, Vladimir.  But, I don’t really
know.  The compiler wants a big blob of <tt>letrec</tt>, but the expander wants
a pearl-string of modules.  Perhaps we try to satisfy them both?  The
<tt>library-group</tt> paper suggests that modules should be expanded one by
one, then stitched into a <tt>letrec</tt> by AST transformations.  It’s not
that lexical scope is incompatible with modules and whole-program
compilation; the problems arise when you add in macros.  So by expanding
first, in units of modules, we reduce high-level Scheme to a lower-level
language without syntax transformers, but still on the level of
<tt>letrec</tt>.</p><p>I was unreasonably pleased by the effectiveness of the “just splat in a
prelude” approach, and I will miss it.  I even pled for a kind of
stop-gap fat-fingered solution to sloppily parse module forms and keep
on splatting things together, but colleagues helpfully talked me away
from the edge.  So good-bye, sloppy: I repent my ways and will make
amends, with 40 hail-maries and an alpha renaming thrice daily and more
often if in moral distress.  Further bulletins as events warrant.  Until
then, happy scheming!</p></div></div>
  </body>
</html>
