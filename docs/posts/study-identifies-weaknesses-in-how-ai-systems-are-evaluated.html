<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.oii.ox.ac.uk/news-events/study-identifies-weaknesses-in-how-ai-systems-are-evaluated/">Original</a>
    <h1>Study identifies weaknesses in how AI systems are evaluated</h1>
    
    <div id="readability-page-1" class="page"><div id="main">	
			
		
		

			<section id="intro">
				<div>
					<div>
						<div>
													
								<svg id="content-curve" data-name="Layer 1" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 326.38 119.42"><defs></defs><path d="M331.49,698.69V811A336.87,336.87,0,0,0,657.87,698.69Z" transform="translate(-331.49 -698.69)"></path></svg>
	
	
				
						
							<div>
								<div>
		
									<div>
										
										<div>
										<p><b>Published on</b></p></div>
									</div>
				
																
					</div>
							<div>
																	<p>
										Largest systematic review of AI benchmarks highlights need for clearer definitions and stronger scientific standards.									</p>
											
						</div>	
				</div>
							
	
	
												
				</div>
			</div>
						
						
						
						
								</div>
				
			</section>
			<section id="news-story-section">

				<div>
			
												<p><span data-contrast="auto">A new study led by the Oxford Internet Institute (OII) at the University of Oxford and involving a team of 42 researchers from leading global institutions including <a href="https://www.epfl.ch/en/">EPFL</a>, <a href="https://www.stanford.edu/">Stanford University,</a> the <a href="https://www.tum.de/en/">Technical University of Munich</a>, <a href="https://www.berkeley.edu/">UC Berkeley</a>, the <a href="https://www.aisi.gov.uk/">UK AI Security Institute</a>, the <a href="https://www.weizenbaum-institut.de/en">Weizenbaum Institute,</a> and <a href="https://www.yale.edu/">Yale University</a>, has found that many of the tests used to measure the capabilities and safety of large language models (LLMs) lack scientific rigour. </span><span data-ccp-props="{&#34;201341983&#34;:1,&#34;335559740&#34;:360}"> </span></p>
<p><span data-contrast="auto">In </span><a href="https://oxrml.com/measuring-what-matters/"><i><span data-contrast="auto">Measuring What Matters: Construct Validity in Large Language Model Benchmarks</span></i></a><span data-contrast="auto">, accepted for publication in the upcoming <a href="https://neurips.cc/virtual/2025/loc/san-diego/poster/121477">NeurIPS conference proceedings</a>, researchers review 445 AI benchmarks – the standardised evaluations used to compare and rank AI systems. </span><span data-ccp-props="{&#34;201341983&#34;:1,&#34;335559740&#34;:360}"> </span></p>
<p><span data-contrast="auto">The researchers found that many of these benchmarks are built on unclear definitions or weak analytical methods, making it difficult to draw reliable conclusions about AI progress, capabilities or safety.</span><span data-ccp-props="{&#34;201341983&#34;:1,&#34;335559740&#34;:360}"> </span></p>
<p><span data-contrast="auto">“Benchmarks underpin nearly all claims about advances in AI,” says <a href="https://www.oii.ox.ac.uk/people/profiles/andrew-bean/">Andrew Bean</a>, lead author of the study. “But without shared definitions and sound measurement, it becomes hard to know whether models are genuinely improving or just appearing to.”</span><span data-ccp-props="{&#34;201341983&#34;:1,&#34;335559740&#34;:360}"> </span></p>
<p><span data-contrast="auto">Benchmarks play a central role in how AI systems are designed, deployed, and regulated. They guide research priorities, shape competition between models, and are increasingly referenced in policy and regulatory frameworks, including the EU AI Act, which calls for risk assessments based on “appropriate technical tools and benchmarks.”</span><span data-ccp-props="{&#34;201341983&#34;:1,&#34;335559740&#34;:360}"> </span></p>
<p><span data-contrast="auto">The study warns that if benchmarks are not scientifically sound, they may give developers and regulators a misleading picture of how capable or safe AI systems really are.</span><span data-ccp-props="{&#34;201341983&#34;:1,&#34;335559740&#34;:360}"> </span></p>
<p><span data-contrast="none">“This work reflects the kind of large-scale collaboration the field needs,” adds <a href="https://www.oii.ox.ac.uk/people/profiles/adam-mahdi/">Dr. Adam Mahdi</a>. “By bringing together leading AI labs, we’re starting to tackle one of the most fundamental gaps in current AI evaluation.”</span><span data-ccp-props="{&#34;201341983&#34;:1,&#34;335559740&#34;:360}"> </span></p>
<p><b><span data-contrast="auto">Key findings</span></b><span data-ccp-props="{&#34;201341983&#34;:1,&#34;335559740&#34;:360}"> </span></p>
<ol>
<li><b><span data-contrast="auto"> Lack of statistical rigour</span></b></li>
</ol>
<p><span data-contrast="auto">Only 16% of the reviewed studies used statistical methods when comparing model performance. This means that reported differences between systems or claims of superiority could be due to chance rather than genuine improvement.</span><span data-ccp-props="{&#34;201341983&#34;:1,&#34;335559740&#34;:360}"> </span></p>
<ol start="2">
<li><b><span data-contrast="auto"> Vague or contested definitions</span></b></li>
</ol>
<p><span data-contrast="auto">Around half of the benchmarks aimed to measure abstract ideas such as reasoning or harmlessness without clearly defining what those terms mean. Without a shared understanding of these concepts, it is difficult to ensure that benchmarks are testing what they intend to.</span></p>
<p><b><span data-contrast="auto">Examples</span></b><span data-ccp-props="{&#34;201341983&#34;:1,&#34;335559740&#34;:360}"> </span></p>
<ul>
<li data-leveltext="" data-font="Symbol" data-listid="1" data-list-defn-props="{&#34;335552541&#34;:1,&#34;335559685&#34;:720,&#34;335559991&#34;:360,&#34;469769226&#34;:&#34;Symbol&#34;,&#34;469769242&#34;:[8226],&#34;469777803&#34;:&#34;left&#34;,&#34;469777804&#34;:&#34;&#34;,&#34;469777815&#34;:&#34;hybridMultilevel&#34;}" data-aria-posinset="1" data-aria-level="1"><b><span data-contrast="auto">Confounding formatting rules</span></b><span data-contrast="auto"> – A test might ask a model to solve a simple logic puzzle but also require it to present the answer in a very specific, complicated format. If the model gets the puzzle right but fails the formatting, it looks worse than it really is.</span><span data-ccp-props="{&#34;201341983&#34;:1,&#34;335559740&#34;:360}"> </span></li>
<li data-leveltext="" data-font="Symbol" data-listid="1" data-list-defn-props="{&#34;335552541&#34;:1,&#34;335559685&#34;:720,&#34;335559991&#34;:360,&#34;469769226&#34;:&#34;Symbol&#34;,&#34;469769242&#34;:[8226],&#34;469777803&#34;:&#34;left&#34;,&#34;469777804&#34;:&#34;&#34;,&#34;469777815&#34;:&#34;hybridMultilevel&#34;}" data-aria-posinset="1" data-aria-level="1"><b><span data-contrast="auto">Brittle performance</span></b><span data-contrast="auto"> – A model might do well on short, primary school-style maths questions, but if you change the numbers or wording slightly, it suddenly fails. This shows it may be memorising patterns rather than truly understanding the problem</span></li>
<li data-leveltext="" data-font="Symbol" data-listid="1" data-list-defn-props="{&#34;335552541&#34;:1,&#34;335559685&#34;:720,&#34;335559991&#34;:360,&#34;469769226&#34;:&#34;Symbol&#34;,&#34;469769242&#34;:[8226],&#34;469777803&#34;:&#34;left&#34;,&#34;469777804&#34;:&#34;&#34;,&#34;469777815&#34;:&#34;hybridMultilevel&#34;}" data-aria-posinset="1" data-aria-level="1"><b><span data-contrast="auto">Unsupported claims</span></b><span data-contrast="auto"> – If a model scores well on multiple-choice questions from medical exams, people might claim it has doctor-level expertise. But passing an exam is only one small part of what doctors do, so the result can be misleading.</span></li>
</ul>
<p><b><span data-contrast="auto">Recommendations for better benchmarking</span></b><span data-ccp-props="{&#34;201341983&#34;:1,&#34;335559740&#34;:360}"> </span></p>
<p><span data-contrast="auto">The authors stress that these problems are fixable. Drawing on established methods from fields such as psychometrics and medicine, they propose eight recommendations to improve the validity of AI benchmarks. These include:</span><span data-ccp-props="{&#34;201341983&#34;:1,&#34;335559740&#34;:360}"> </span></p>
<ul>
<li data-leveltext="" data-font="Symbol" data-listid="2" data-list-defn-props="{&#34;335552541&#34;:1,&#34;335559685&#34;:720,&#34;335559991&#34;:360,&#34;469769226&#34;:&#34;Symbol&#34;,&#34;469769242&#34;:[8226],&#34;469777803&#34;:&#34;left&#34;,&#34;469777804&#34;:&#34;&#34;,&#34;469777815&#34;:&#34;hybridMultilevel&#34;}" data-aria-posinset="1" data-aria-level="1"><b><span data-contrast="auto">Define and isolate</span></b><span data-contrast="auto">: Provide a precise, operational definition for the concept being measured and control for unrelated factors.</span><span data-ccp-props="{&#34;201341983&#34;:1,&#34;335559740&#34;:360}"> </span></li>
</ul>
<ul>
<li data-leveltext="" data-font="Symbol" data-listid="2" data-list-defn-props="{&#34;335552541&#34;:1,&#34;335559685&#34;:720,&#34;335559991&#34;:360,&#34;469769226&#34;:&#34;Symbol&#34;,&#34;469769242&#34;:[8226],&#34;469777803&#34;:&#34;left&#34;,&#34;469777804&#34;:&#34;&#34;,&#34;469777815&#34;:&#34;hybridMultilevel&#34;}" data-aria-posinset="2" data-aria-level="1"><b><span data-contrast="auto">Build representative evaluations</span></b><span data-contrast="auto">: Ensure test items represent real-world conditions and cover the full scope of the target skill or behaviour. </span><span data-ccp-props="{&#34;201341983&#34;:1,&#34;335559740&#34;:360}"> </span></li>
</ul>
<ul>
<li data-leveltext="" data-font="Symbol" data-listid="2" data-list-defn-props="{&#34;335552541&#34;:1,&#34;335559685&#34;:720,&#34;335559991&#34;:360,&#34;469769226&#34;:&#34;Symbol&#34;,&#34;469769242&#34;:[8226],&#34;469777803&#34;:&#34;left&#34;,&#34;469777804&#34;:&#34;&#34;,&#34;469777815&#34;:&#34;hybridMultilevel&#34;}" data-aria-posinset="3" data-aria-level="1"><b><span data-contrast="auto">Strengthen analysis and justification</span></b><span data-contrast="auto">: Use statistical methods to report uncertainty and enable robust comparisons; conduct detailed error analysis to understand why a model fails; and justify why the benchmark is a valid measure for its intended purpose.</span><span data-ccp-props="{&#34;201341983&#34;:1,&#34;335559740&#34;:360}"> </span></li>
</ul>
<p><span data-contrast="auto">The team also provides a </span><b><span data-contrast="auto">Construct Validity Checklist,</span></b><span data-contrast="auto"> a practical tool researchers, developers, and regulators can use to assess whether an AI benchmark follows sound design principles before relying on its results. The checklist is available at </span><a href="https://oxrml.com/measuring-what-matters/"><span data-contrast="none">https://oxrml.com/measuring-what-matters/</span></a><span data-contrast="auto"> </span><span data-ccp-props="{&#34;201341983&#34;:1,&#34;335559740&#34;:360}"> </span></p>
<p><span data-contrast="auto">The paper, </span><i><span data-contrast="auto">Measuring What Matters: Construct Validity in Large Language Model Benchmarks</span></i><span data-contrast="auto">, will be published as part of the NeurIPS 2025 peer-reviewed conference proceedings in San Diego from 2-7 December. The peer-reviewed paper is available on request. </span><span data-ccp-props="{&#34;201341983&#34;:1,&#34;335559740&#34;:360}"> </span></p>
<p><b><span data-contrast="auto">Media spokespeople</span></b><span data-ccp-props="{&#34;201341983&#34;:1,&#34;335559740&#34;:360}"> </span></p>
<p><span data-contrast="auto">Lead author: Andrew Bean, Doctoral Student, Oxford Internet Institute, University of Oxford</span><span data-ccp-props="{&#34;201341983&#34;:1,&#34;335559740&#34;:360}"> </span></p>
<p><span data-contrast="auto">Senior authors: Adam Mahdi, Associate Professor, and Luc Rocher, Associate Professor, Oxford Internet Institute, University of Oxford</span><span data-ccp-props="{&#34;201341983&#34;:1,&#34;335559740&#34;:360}"> </span></p>
<p><b><span data-contrast="auto">Contact</span></b><span data-contrast="auto"> </span><span data-ccp-props="{&#34;201341983&#34;:1,&#34;335559740&#34;:360}"> </span></p>
<p><span data-contrast="auto">For more information and briefings, please contact: </span></p>
<p><span data-contrast="auto">T: +44 (0)1865 280527</span><span data-ccp-props="{&#34;201341983&#34;:1,&#34;335559740&#34;:360}"> </span></p>
<p><span data-contrast="auto">M: +44 (0)7551 345493 </span><span data-ccp-props="{&#34;201341983&#34;:1,&#34;335559740&#34;:360}"> </span></p>
<p><a href="mailto:E:%E2%80%AFpress@oii.ox.ac.uk"><span data-contrast="none">E:</span><span data-contrast="none"> </span><span data-contrast="none">press@oii.ox.ac.uk</span></a><span data-contrast="auto">   </span><span data-ccp-props="{&#34;201341983&#34;:1,&#34;335559740&#34;:360}"> </span></p>

<p><b><span data-contrast="auto">About the Oxford Internet Institute (OII)</span></b><b><span data-contrast="auto">  </span></b><span data-contrast="auto"> </span><span data-contrast="auto"> </span><span data-ccp-props="{&#34;201341983&#34;:1,&#34;335559740&#34;:360}"> </span></p>
<p><span data-contrast="auto">The Oxford Internet Institute (OII) has been at the forefront of exploring the human impact of emerging technologies for 25 years. As a multidisciplinary research and teaching department, we bring together scholars and students from diverse fields to examine the opportunities and challenges posed by transformative innovations such as artificial intelligence, large language models, machine learning, digital platforms, and autonomous agents.</span><span data-ccp-props="{&#34;201341983&#34;:1,&#34;335557856&#34;:16777215,&#34;335559739&#34;:0,&#34;335559740&#34;:360}"> </span></p>

<p><b><span data-contrast="auto">About the University of Oxford</span></b><b><span data-contrast="auto"> </span></b><span data-contrast="auto"> </span><span data-contrast="auto"> </span><span data-ccp-props="{&#34;201341983&#34;:1,&#34;335557856&#34;:16777215,&#34;335559739&#34;:0,&#34;335559740&#34;:360}"> </span></p>
<p><span data-contrast="auto">Oxford University was placed number one in the Times Higher Education World University Rankings for the tenth year running in 2025. At the heart of this success are the twin-pillars of our ground-breaking research and innovation and our distinctive educational offer. Oxford is world-famous for research and teaching excellence and home to some of the most talented people from across the globe.   </span></p>

<p><b><span data-contrast="auto">Funding information</span></b><span data-ccp-props="{&#34;201341983&#34;:1,&#34;335559740&#34;:360}"> </span></p>
<ul>
<li data-leveltext="" data-font="Symbol" data-listid="3" data-list-defn-props="{&#34;335552541&#34;:1,&#34;335559685&#34;:720,&#34;335559991&#34;:360,&#34;469769226&#34;:&#34;Symbol&#34;,&#34;469769242&#34;:[8226],&#34;469777803&#34;:&#34;left&#34;,&#34;469777804&#34;:&#34;&#34;,&#34;469777815&#34;:&#34;hybridMultilevel&#34;}" data-aria-posinset="1" data-aria-level="1"><span data-contrast="auto">A.M.B. is supported in part by the Clarendon Scholarships and the Oxford Internet Institute’s Research Programme on AI &amp; Work. </span><span data-ccp-props="{&#34;201341983&#34;:1,&#34;335559740&#34;:360}"> </span></li>
</ul>
<ul>
<li data-leveltext="" data-font="Symbol" data-listid="3" data-list-defn-props="{&#34;335552541&#34;:1,&#34;335559685&#34;:720,&#34;335559991&#34;:360,&#34;469769226&#34;:&#34;Symbol&#34;,&#34;469769242&#34;:[8226],&#34;469777803&#34;:&#34;left&#34;,&#34;469777804&#34;:&#34;&#34;,&#34;469777815&#34;:&#34;hybridMultilevel&#34;}" data-aria-posinset="2" data-aria-level="1"><span data-contrast="auto">A.M. is supported by the Oxford Internet Institute’s Research Programme on AI &amp; Work.</span><span data-ccp-props="{&#34;201341983&#34;:1,&#34;335559740&#34;:360}"> </span></li>
</ul>
<ul>
<li data-leveltext="" data-font="Symbol" data-listid="3" data-list-defn-props="{&#34;335552541&#34;:1,&#34;335559685&#34;:720,&#34;335559991&#34;:360,&#34;469769226&#34;:&#34;Symbol&#34;,&#34;469769242&#34;:[8226],&#34;469777803&#34;:&#34;left&#34;,&#34;469777804&#34;:&#34;&#34;,&#34;469777815&#34;:&#34;hybridMultilevel&#34;}" data-aria-posinset="3" data-aria-level="1"><span data-contrast="auto">R.O.K. is supported by a Fellowship from the Cosmos Institute. H.M. is supported by ESRC [ES/P000649/1] and would like to acknowledge the London Initiative for Safe AI.</span><span data-ccp-props="{&#34;201341983&#34;:1,&#34;335559740&#34;:360}"> </span></li>
</ul>
<ul>
<li data-leveltext="" data-font="Symbol" data-listid="3" data-list-defn-props="{&#34;335552541&#34;:1,&#34;335559685&#34;:720,&#34;335559991&#34;:360,&#34;469769226&#34;:&#34;Symbol&#34;,&#34;469769242&#34;:[8226],&#34;469777803&#34;:&#34;left&#34;,&#34;469777804&#34;:&#34;&#34;,&#34;469777815&#34;:&#34;hybridMultilevel&#34;}" data-aria-posinset="4" data-aria-level="1"><span data-contrast="auto">C.E. is supported by the EPSRC Centre for Doctoral Training in Health Data Science (EP/S02428X/1) and the AXA Research Fund. </span><span data-ccp-props="{&#34;201341983&#34;:1,&#34;335559740&#34;:360}"> </span></li>
</ul>
<ul>
<li data-leveltext="" data-font="Symbol" data-listid="3" data-list-defn-props="{&#34;335552541&#34;:1,&#34;335559685&#34;:720,&#34;335559991&#34;:360,&#34;469769226&#34;:&#34;Symbol&#34;,&#34;469769242&#34;:[8226],&#34;469777803&#34;:&#34;left&#34;,&#34;469777804&#34;:&#34;&#34;,&#34;469777815&#34;:&#34;hybridMultilevel&#34;}" data-aria-posinset="5" data-aria-level="1"><span data-contrast="auto">F.L. is supported by Clarendon and Jason Hu studentships. </span><span data-ccp-props="{&#34;201341983&#34;:1,&#34;335559740&#34;:360}"> </span></li>
</ul>
<ul>
<li data-leveltext="" data-font="Symbol" data-listid="3" data-list-defn-props="{&#34;335552541&#34;:1,&#34;335559685&#34;:720,&#34;335559991&#34;:360,&#34;469769226&#34;:&#34;Symbol&#34;,&#34;469769242&#34;:[8226],&#34;469777803&#34;:&#34;left&#34;,&#34;469777804&#34;:&#34;&#34;,&#34;469777815&#34;:&#34;hybridMultilevel&#34;}" data-aria-posinset="6" data-aria-level="1"><span data-contrast="auto">H.R.K.’s PhD is supported by the Economic and Social Research Council grant ES/P000649/1. </span><span data-ccp-props="{&#34;201341983&#34;:1,&#34;335559740&#34;:360}"> </span></li>
</ul>
<ul>
<li data-leveltext="" data-font="Symbol" data-listid="3" data-list-defn-props="{&#34;335552541&#34;:1,&#34;335559685&#34;:720,&#34;335559991&#34;:360,&#34;469769226&#34;:&#34;Symbol&#34;,&#34;469769242&#34;:[8226],&#34;469777803&#34;:&#34;left&#34;,&#34;469777804&#34;:&#34;&#34;,&#34;469777815&#34;:&#34;hybridMultilevel&#34;}" data-aria-posinset="7" data-aria-level="1"><span data-contrast="auto">M.G. was supported by the SMARTY (PCI2024-153434) project funded by the Agencia Estatal de Investigación (doi:10.13039/501100011033) and by the European Commission through the Chips Act Joint Undertaking project SMARTY (Grant 101140087). This material is based in part upon work supported by the National Science Foundation Graduate Research Fellowship Program under Grant No. DGE-2139841. </span><span data-ccp-props="{&#34;201341983&#34;:1,&#34;335559740&#34;:360}"> </span></li>
</ul>
<ul>
<li data-leveltext="" data-font="Symbol" data-listid="3" data-list-defn-props="{&#34;335552541&#34;:1,&#34;335559685&#34;:720,&#34;335559991&#34;:360,&#34;469769226&#34;:&#34;Symbol&#34;,&#34;469769242&#34;:[8226],&#34;469777803&#34;:&#34;left&#34;,&#34;469777804&#34;:&#34;&#34;,&#34;469777815&#34;:&#34;hybridMultilevel&#34;}" data-aria-posinset="8" data-aria-level="1"><span data-contrast="auto">O.D. is supported by the UKRI’s EPSRC AIMS CDT grant (EP/S024050/1). </span><span data-ccp-props="{&#34;201341983&#34;:1,&#34;335559740&#34;:360}"> </span></li>
</ul>
<ul>
<li data-leveltext="" data-font="Symbol" data-listid="3" data-list-defn-props="{&#34;335552541&#34;:1,&#34;335559685&#34;:720,&#34;335559991&#34;:360,&#34;469769226&#34;:&#34;Symbol&#34;,&#34;469769242&#34;:[8226],&#34;469777803&#34;:&#34;left&#34;,&#34;469777804&#34;:&#34;&#34;,&#34;469777815&#34;:&#34;hybridMultilevel&#34;}" data-aria-posinset="9" data-aria-level="1"><span data-contrast="auto">J.R is supported by the Engineering and Physical Sciences Research Council. </span><span data-ccp-props="{&#34;201341983&#34;:1,&#34;335559740&#34;:360}"> </span></li>
</ul>
<ul>
<li data-leveltext="" data-font="Symbol" data-listid="3" data-list-defn-props="{&#34;335552541&#34;:1,&#34;335559685&#34;:720,&#34;335559991&#34;:360,&#34;469769226&#34;:&#34;Symbol&#34;,&#34;469769242&#34;:[8226],&#34;469777803&#34;:&#34;left&#34;,&#34;469777804&#34;:&#34;&#34;,&#34;469777815&#34;:&#34;hybridMultilevel&#34;}" data-aria-posinset="10" data-aria-level="1"><span data-contrast="auto">J.B. would like to acknowledge funding by the Federal Ministry of Education and Research of Germany (BMBF) under grant no. 16DII131. </span><span data-ccp-props="{&#34;201341983&#34;:1,&#34;335559740&#34;:360}"> </span></li>
</ul>
<ul>
<li data-leveltext="" data-font="Symbol" data-listid="3" data-list-defn-props="{&#34;335552541&#34;:1,&#34;335559685&#34;:720,&#34;335559991&#34;:360,&#34;469769226&#34;:&#34;Symbol&#34;,&#34;469769242&#34;:[8226],&#34;469777803&#34;:&#34;left&#34;,&#34;469777804&#34;:&#34;&#34;,&#34;469777815&#34;:&#34;hybridMultilevel&#34;}" data-aria-posinset="11" data-aria-level="1"><span data-contrast="auto">A. Bibi would like to acknowledge the UK AISI systemic safety grant. </span><span data-ccp-props="{&#34;201341983&#34;:1,&#34;335559740&#34;:360}"> </span></li>
</ul>
<ul>
<li data-leveltext="" data-font="Symbol" data-listid="3" data-list-defn-props="{&#34;335552541&#34;:1,&#34;335559685&#34;:720,&#34;335559991&#34;:360,&#34;469769226&#34;:&#34;Symbol&#34;,&#34;469769242&#34;:[8226],&#34;469777803&#34;:&#34;left&#34;,&#34;469777804&#34;:&#34;&#34;,&#34;469777815&#34;:&#34;hybridMultilevel&#34;}" data-aria-posinset="12" data-aria-level="1"><span data-contrast="auto">A. Bosselut gratefully acknowledges the support of the Swiss National Science Foundation (No. 215390), Innosuisse (PFFS-21-29), the EPFL Center for Imaging, Sony Group Corporation, and a Meta LLM Evaluation Research Grant.</span><span data-ccp-props="{&#34;201341983&#34;:1,&#34;335559740&#34;:360}"> </span></li>
</ul>
				</div>
				
			</section>
			

				<section data-wpr-lazyrender="1" id="related_people">
	<div>
		<div>
							
				<h2>Related People</h2>
			
			
			
			<div>
				

	<article>
					<a href="https://www.oii.ox.ac.uk/people/profiles/andrew-bean/">
									<img alt="Andrew Bean" src="data:image/svg+xml,%3Csvg%20xmlns=&#39;http://www.w3.org/2000/svg&#39;%20viewBox=&#39;0%200%200%200&#39;%3E%3C/svg%3E" data-lazy-src="https://www.oii.ox.ac.uk/wp-content/uploads/2021/09/5242-1400-170x170.webp"/>
								<div>
											<h4> Andrew Bean</h4>
						<p><i>DPhil Student</i></p>
											
						<p>Andrew holds a B.S. in Applied Mathematics from Yale University and an MSc in Social Data Science from the OII. He is a Clarendon Scholar and was previously a Thouron Prize winner at the University of Cambridge (Pembroke College).</p>
											</div>
									<div>
						<p>View profile
													</p>
					</div>
									</a>
			</article>


	<article>
					<a href="https://www.oii.ox.ac.uk/people/profiles/adam-mahdi/">
									<img alt="Adam Mahdi" src="data:image/svg+xml,%3Csvg%20xmlns=&#39;http://www.w3.org/2000/svg&#39;%20viewBox=&#39;0%200%200%200&#39;%3E%3C/svg%3E" data-lazy-src="https://www.oii.ox.ac.uk/wp-content/uploads/2021/12/5242-0230-1-170x170.jpg"/>
								<div>
											<h4>Dr Adam Mahdi</h4>
						<p><i>Senior Research Fellow</i></p>
											
						<p>Adam Mahdi’s research focuses on digital health and application of machine learning in social sciences. He is the director of the UKRI-funded OxCOVID19 Project and a fellow at Wolfson College, University of Oxford.</p>
											</div>
									<div>
						<p>View profile
													</p>
					</div>
									</a>
			</article>


	<article>
					<a href="https://www.oii.ox.ac.uk/people/profiles/luc-rocher/">
									<img alt="Luc Rocher" src="data:image/svg+xml,%3Csvg%20xmlns=&#39;http://www.w3.org/2000/svg&#39;%20viewBox=&#39;0%200%200%200&#39;%3E%3C/svg%3E" data-lazy-src="https://www.oii.ox.ac.uk/wp-content/uploads/2021/10/portrait-luc-2023-extended-170x170.png"/>
								<div>
											<h4>Dr Luc Rocher</h4>
						<p><i>Associate Professor</i></p>
											
						<p>Luc conducts human-centred computing research to understand how data and algorithms impact society. They work to make digital power visible to the public and guide the development of accountable, sustainable, and safe algorithms for all.</p>
											</div>
									<div>
						<p>View profile
													</p>
					</div>
									</a>
			</article>
			</div>
		</div>
	</div>
</section>	
				

				
				

<section id="related_sites">
	<div>
		<div>
			<div>
							
				<h2>Related Project</h2>
									
							
				
			<div id="related_sites-">


				<div>
					
<article>
	<div>
		<p><img src="data:image/svg+xml,%3Csvg%20xmlns=&#39;http://www.w3.org/2000/svg&#39;%20viewBox=&#39;0%200%200%200&#39;%3E%3C/svg%3E" alt="ai-diagnosis" data-lazy-src="https://www.oii.ox.ac.uk/wp-content/uploads/2024/03/ai-diagnosis-450x254.jpg"/>
		</p>

		<div>
		<h4><a href="https://www.oii.ox.ac.uk/research/projects/benchmarking-large-language-models-for-self-diagnosis/">Benchmarking Large Language Models for Self-Diagnosis</a></h4>
		</div>

			<p>Our work investigates applications of large language models (LLMs) in healthcare settings, with a particular focus on interactions between LLMs and human users. The project focuses on LLMs for medical self-diagnosis.</p>
			</div>


	
</article>



				</div>
					<div>
						
					</div>	
				</div>
			</div>
		</div>
	</div>
</section>
	

				
				
					
			
			

		</div></div>
  </body>
</html>
