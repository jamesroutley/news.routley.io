<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://llmspy.org/docs/v3">Original</a>
    <h1>OSS ChatGPT WebUI ‚Äì 530 Models, MCP, Tools, Gemini RAG, Image/Audio Gen</h1>
    
    <div id="readability-page-1" class="page"><p>Major release focused on extensibility, expanded provider support, and enhanced user experience.</p><div>
<div><table><thead><tr><th>Feature</th><th>Description</th></tr></thead><tbody><tr><td><strong>530+ Models</strong></td><td>Access over 530 models from 24 providers via <a href="https://models.dev" rel="noreferrer noopener" target="_blank">models.dev</a> integration</td></tr><tr><td><strong>Model Selector</strong></td><td>Redesigned full-featured dialog with search, filtering, sorting, and favorites</td></tr><tr><td><strong>Extensions</strong></td><td>Add features, providers, and customize the UI with a flexible plugin architecture</td></tr><tr><td><strong>Gemini RAG</strong></td><td>Manage Gemini File Search Stores and manage document uploads for RAG workflows</td></tr><tr><td><strong>Tool Support</strong></td><td>First-class Python function calling for LLM interactions with your local environment</td></tr><tr><td><strong>MCP Support</strong></td><td>Connect to Model Context Protocol servers for extended tool capabilities</td></tr><tr><td><strong>Computer Use</strong></td><td>Desktop automation - control mouse, keyboard, and take screenshots like a human</td></tr><tr><td><strong>KaTeX Math Typesetting</strong></td><td>Support for beautiful rendering of LaTeX math expressions</td></tr><tr><td><strong>Calculator UI</strong></td><td>Beautiful UX Friendly UI to evaluate python math expressions</td></tr><tr><td><strong>Run Code UI</strong></td><td>Execute Python, JS, TypeScript and C# code scripts in a CodeMirror editor</td></tr><tr><td><strong>Image Generation</strong></td><td>Built-in support for Google, OpenAI, OpenRouter, Chutes, and Nvidia</td></tr><tr><td><strong>Audio Generation</strong></td><td>TTS support for Gemini 2.5 Flash/Pro Preview models</td></tr><tr><td><strong>Media Gallery</strong></td><td>Beautiful UI to browse generated images and audio generations</td></tr><tr><td><strong>SQLite Storage</strong></td><td>Migrated IndexedDB to server SQLite for robust persistence and concurrent usage</td></tr><tr><td><strong>Asset Caching</strong></td><td>Persistent image/file file caching with metadata</td></tr><tr><td><strong>Gemini RAG Extension</strong></td><td>Manage Gemini File Search Stores for RAG workflows with document uploads and sync</td></tr></tbody></table></div>
<hr/>
<h2 id="table-of-contents"><a data-card="" href="#table-of-contents">Table of Contents</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h2>
<ul>
<li><a href="#new-model-selector-ui">New Model Selector UI</a></li>
<li><a href="#rewritten-for-extensibility">Rewritten for Extensibility</a></li>
<li><a href="#extensions-system">Extensions System</a></li>
<li><a href="#gemini-rag-extension">Gemini RAG Extension</a></li>
<li><a href="#tool-support">Tool Support</a></li>
<li><a href="#mcp-support">MCP Support</a></li>
<li><a href="#core-tools">Core Tools</a></li>
<li><a href="#computer-use">Computer Use</a></li>
<li><a href="#calculator-ui">Calculator UI</a></li>
<li><a href="#run-code-ui">Run Code UI</a></li>
<li><a href="#katex-math-typesetting">KaTeX Math Typesetting</a></li>
<li><a href="#image-generation-support">Image Generation Support</a></li>
<li><a href="#audio-generation-support">Audio Generation Support</a></li>
<li><a href="#media-gallery">Media Gallery</a></li>
<li><a href="#system-prompts-library">System Prompts Library</a></li>
<li><a href="#server-sqlite-and-cached-file-storage-persistence">Server-Side SQLite Storage</a></li>
<li><a href="#image-cache--optimization">Image Cache &amp; Optimization</a></li>
<li><a href="#cli---more-powerful-than-ever">CLI - More Powerful Than Ever</a></li>
<li><a href="#upgrade-instructions">Upgrade Instructions</a></li>
</ul>
<hr/>

<p>Get instant access to 530+ models from 24 providers with extensibility at its core:</p>

<h3 id="upgrade"><a data-card="" href="#upgrade">Upgrade</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>

<p>See <a href="https://llmspy.org/docs/getting-started/installation">Install Docs</a> for running from Docker or source.</p>
<hr/>

<p>A major change to significantly increase the available models is the switch to utilizing the same <a href="https://models.dev" rel="noreferrer noopener" target="_blank">models.dev</a> open provider and model catalogue as used and maintained by <a href="https://opencode.ai" rel="noreferrer noopener" target="_blank">OpenCode</a>.</p>
<p><strong>llms.json</strong> provider configuration is now a <strong>superset</strong> of <a href="https://models.dev/api.json" rel="noreferrer noopener" target="_blank">models.dev/api.json</a> where its definitions are merged, allowing you to enable providers using just <code>&#34;enabled&#34;: true</code> to inherit the configuration from <strong>models.dev</strong></p>
<h3 id="-expanded-provider-support"><a data-card="" href="#-expanded-provider-support">üåê Expanded Provider Support</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p>The switch to <a href="https://models.dev" rel="noreferrer noopener" target="_blank">models.dev</a> greatly expands the model selection to over <strong>530 models</strong> from <strong>24 different providers</strong>, including new support for:</p>
<div><table><thead><tr><th>Provider</th><th>Models</th><th>Provider</th><th>Models</th></tr></thead><tbody><tr><td>Alibaba</td><td>39</td><td>Hugging Face</td><td>14</td></tr><tr><td>Chutes</td><td>56</td><td>Zai Coding Plan</td><td>6</td></tr><tr><td>DeepSeek</td><td>2</td><td>MiniMax</td><td>1</td></tr><tr><td>Fireworks AI</td><td>12</td><td>Moonshot AI</td><td>5</td></tr><tr><td>GitHub Copilot</td><td>27</td><td>Nvidia</td><td>24</td></tr><tr><td>GitHub Models</td><td>55</td><td>Zai</td><td>6</td></tr><tr><td>Cerebras</td><td>3</td><td></td><td></td></tr><tr><td>LMStudio</td><td>local</td><td>Ollama</td><td>local</td></tr></tbody></table></div>
<p>Non OpenAI Compatible LLM and Image generation providers are maintained in the <a href="https://github.com/ServiceStack/llms/tree/main/llms/extensions/providers" rel="noreferrer noopener" target="_blank">providers</a> extension, registered using the <code>ctx.add_provider()</code> API. There are several different provider implementations to take advantage of features available in each provider, such as <strong>Interleaved Thinking</strong> support in Anthropic&#39;s Messages API which enables all Claude and MiniMax models to reason between tool calls for improved agentic performance.</p>

<h3 id="-automatic-provider-updates"><a data-card="" href="#-automatic-provider-updates">üîÑ Automatic Provider Updates</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p>This actively maintained list of available providers and models are automatically updated into your <code>providers.json</code> daily that can also be manually updated with:</p>
<figure dir="ltr" tabindex="-1"><div role="region" tabindex="0"><pre><code><span><span>llms</span><span> --update-providers</span></span></code></pre></div></figure>
<p>As an optimization only the providers that are referenced in your <code>llms.json</code> are saved. Any additional providers you want to use that are not included in models.dev can be added to your <code>~/.llms/providers-extra.json</code>, which get merged into your <code>providers.json</code> on every update.</p>
<p>This keeps your local configuration file lightweight by only including the providers that are available for use.</p>
<h3 id="configuration-examples"><a data-card="" href="#configuration-examples">Configuration Examples</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p>Enable providers by ID ‚Äî all configuration is automatically inherited:</p>
<figure dir="ltr" tabindex="-1"><div role="region" tabindex="0"><pre><code><span><span>{</span></span>
<span><span>  &#34;openai&#34;</span><span>: { </span><span>&#34;enabled&#34;</span><span>: </span><span>true</span><span> },</span></span>
<span><span>  &#34;xai&#34;</span><span>: { </span><span>&#34;enabled&#34;</span><span>: </span><span>true</span><span> }</span></span>
<span><span>}</span></span></code></pre></div></figure>
<p>See <a href="https://llmspy.org/docs/configuration">Configuration</a> docs for more info.</p>
<h3 id="new-model-selector-ui"><a data-card="" href="#new-model-selector-ui">New Model Selector UI</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p>With over 530 models from 24 providers now available, discovering and selecting the right model required a complete overhaul.
The Model Selector has been completely redesigned as a full-featured dialog offering:</p>
<ul>
<li><strong>üîç Smart Search &amp; Discovery</strong> - Instantly search across model names, IDs, and providers</li>
<li><strong>üéØ Advanced Filtering</strong> - Filter by name, providers &amp; input and output modalities</li>
<li><strong>üìä Flexible Sorting</strong> - Sort by Knowledge Cutoff, Release Date, Last Updated &amp; Context</li>
<li><strong>‚≠ê Favorites System</strong> - Star model card to add/remove to favorites quick list</li>
<li><strong>üíé Rich Model Cards</strong> - In depth model overview at a glance</li>
</ul>
<p>Where providers can be quickly enabled or disabled to customize which models are available:</p>
<p><a href="https://llmspy.org/docs/features/model-selector"><img src="https://llmspy.org/img/model-selector-providers.webp"/></a></p><p>See <a href="https://llmspy.org/docs/features/model-selector">Model Selector</a> docs for more info.</p>
<hr/>

<p>llms.py has been rewritten from the ground-up with extensibility a <strong>core concept</strong> where all <a href="https://llmspy.org/docs/extensions/built-in">major UI and Server features</a> now layer on their encapsulated functionality by using the public Client &amp; Server Extensibility APIs.</p>
<p>Extensions are just folders that can add both Server and UI features using the public client and server extensibility APIs. <a href="https://llmspy.org/docs/extensions/built-in">Built-in features</a> are just extensions in the repo&#39;s <a href="https://github.com/ServiceStack/llms/tree/main/llms/extensions" rel="noreferrer noopener" target="_blank">llms/extensions</a> folder which <a href="https://llmspy.org/docs/extensions/built-in#disable-extensions">can be disabled</a> or overridden by adding them to your local <code>~/.llms/extensions</code> folder. Too minimize bloat, only features that are generally useful and don&#39;t require additional dependencies are included as built-in extensions.</p>
<p>llms includes support for installing and uninstalling extensions from any GitHub repository. For better discoverability, non built-in extensions are maintained in the <a href="https://github.com/orgs/llmspy/repositories" rel="noreferrer noopener" target="_blank">github.com/llmspy</a> organization repositories which anyone else is welcome to contribute their repos to for increased discoverability.</p>
<p>UI components are now registered and referenced as Global Vue components, which can be easily replaced by registering Vue components with the same name as done in the <a href="https://github.com/llmspy/xmas/blob/main/ui/index.mjs" rel="noreferrer noopener" target="_blank">xmas</a> extension demo.</p>
<p>This approach allows <a href="https://github.com/ServiceStack/llms/blob/main/llms/main.py" rel="noreferrer noopener" target="_blank">main.py</a> to retain a <strong>lean functional core in a single file</strong> whilst still being fully extensible and lays the foundation for <strong>rapid development of new features</strong> - both from the core team and external 3rd party extensions - enabling the community to extend llms.py in new unanticipated ways.</p>
<p>For deployments requiring minimal footprint, the <a href="https://llmspy.org/docs/deployment/custom-build">Custom Build</a> docs shows how to create a tailored distribution with only the specific extensions you need - perfect for CLI-only or lightweight API server deployments.</p>

<p>To keep the core lightweight while enabling limitless enhancements, we&#39;ve implemented a flexible <strong>Extensions system</strong> inspired by ComfyUI Custom Nodes. This allows adding new features, pages and toolbar icons, register new provider implementations, extend, replace, and customize the UI with your own custom features, just by adding new extension folders.</p>
<h3 id="managing-extensions"><a data-card="" href="#managing-extensions">Managing Extensions</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p><strong>List available extensions:</strong></p>
<figure dir="ltr" tabindex="-1"><div role="region" tabindex="0"><pre><code><span><span>llms</span><span> --add</span></span></code></pre></div></figure>
<p>Output:</p>
<figure dir="ltr" tabindex="-1"><div role="region" tabindex="0"><pre><code><span><span>Available extensions:</span></span>
<span><span>  fast_mcp     Add MCP Support using FastMCP</span></span>
<span><span>  gemini       Google Gemini RAG file search with document management, auto-upload &amp; sync</span></span>
<span><span>  xmas         Example of utilizing the Extensions APIs to give llms.py some Christmas spirit</span></span>
<span><span>  duckduckgo   Add web search tool capabilities using Duck Duck Go</span></span>
<span><span></span></span>
<span><span>Usage:</span></span>
<span><span>  llms --add &lt;extension&gt;</span></span>
<span><span>  llms --add &lt;github-user&gt;/&lt;repo&gt;</span></span></code></pre></div></figure>
<p><strong>Install an extension:</strong></p>
<figure dir="ltr" tabindex="-1"><div role="region" tabindex="0"><pre><code><span><span>llms</span><span> --add</span><span> fast_mcp</span></span></code></pre></div></figure>
<p><strong>Install a 3rd-party extension:</strong></p>
<figure dir="ltr" tabindex="-1"><div role="region" tabindex="0"><pre><code><span><span>llms</span><span> --add</span><span> my_user/my_extension</span></span></code></pre></div></figure>
<div><div><div><p>INFO</p><p>Clones the GitHub repo into <code>~/.llms/extensions/my_extension</code> and installs any <code>requirements.txt</code> dependencies.</p></div></div></div>
<p><strong>List installed extensions:</strong></p>
<figure dir="ltr" tabindex="-1"><div role="region" tabindex="0"><pre><code><span><span>llms</span><span> --remove</span></span></code></pre></div></figure>
<p><strong>Remove an extension:</strong></p>
<figure dir="ltr" tabindex="-1"><div role="region" tabindex="0"><pre><code><span><span>llms</span><span> --remove</span><span> fast_mcp</span></span></code></pre></div></figure>
<h3 id="manual-installation"><a data-card="" href="#manual-installation">Manual Installation</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p>Extensions can be installed from GitHub or by creating a local folder:</p>
<ul>
<li><strong>Local</strong>: Simply create a folder in <code>~/.llms/extensions/my_extension</code></li>
<li><strong>GitHub</strong>: Clone extensions into <code>~/.llms/extensions</code>, e.g:</li>
</ul>
<figure dir="ltr" tabindex="-1"><div role="region" tabindex="0"><pre><code><span><span>git clone https://github.com/user/repo ~/.llms/extensions/my_extension</span></span></code></pre></div></figure>
<p>See <a href="https://llmspy.org/docs/extensions">Extensions</a> docs for more details.</p>
<h3 id="how-it-works-server"><a data-card="" href="#how-it-works-server">How it Works (Server)</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p>Extensions are Python modules that plug into the server lifecycle using special hooks defined in their <code>__init__.py</code>:</p>
<div><table><thead><tr><th>Hook</th><th>Purpose</th></tr></thead><tbody><tr><td><code>__parser__(parser)</code></td><td>Add custom CLI arguments</td></tr><tr><td><code>__install__(ctx)</code></td><td>Enhance the server instance (routes, providers, filters, etc.)</td></tr><tr><td><code>__load__(ctx)</code></td><td>Load data or perform <strong>async</strong> tasks before server starts</td></tr><tr><td><code>__run__(ctx)</code></td><td>Execute custom logic when running in CLI mode</td></tr></tbody></table></div>
<p>The <code>ctx</code> parameter provides access to the <code>ExtensionContext</code>.</p>
<p>See <a href="https://llmspy.org/docs/extensions/server">Server Extensions</a> docs for more details.</p>
<h3 id="how-it-works-ui"><a data-card="" href="#how-it-works-ui">How it Works (UI)</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p>Extensions can also include frontend components:</p>
<ol>
<li><strong>Placement</strong>: Add a <code>ui</code> folder within your extension directory</li>
<li><strong>Access</strong>: Files in this folder are automatically served at <code>/ext/&lt;extension_name&gt;/*</code></li>
<li><strong>Integration</strong>: Create a <code>ui/index.mjs</code> file. This is the entry point and must export an <code>install</code> function:</li>
</ol>
<figure dir="ltr" tabindex="-1"><div role="region" tabindex="0"><pre><code><span><span>const</span><span> MyComponent</span><span> =</span><span> {</span></span>
<span><span>    template: </span><span>`...`</span></span>
<span><span>}</span></span>
<span></span>
<span><span>// ui/index.mjs</span></span>
<span><span>export</span><span> default</span><span> {</span></span>
<span><span>    install</span><span>(</span><span>ctx</span><span>) {</span></span>
<span><span>        // Register or replace components, add routes, etc.</span></span>
<span><span>        ctx.</span><span>components</span><span>({ MyComponent })</span></span>
<span><span>    }</span></span>
<span><span>}</span></span></code></pre></div></figure>
<p>See <a href="https://llmspy.org/docs/extensions/ui">UI Extensions</a> docs for more details.</p>
<h3 id="example-xmas-extension"><a data-card="" href="#example-xmas-extension">Example: xmas extension</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p>The <a href="https://github.com/llmspy/xmas" rel="noreferrer noopener" target="_blank">xmas</a> extension demonstrates these capabilities where it utilizes the Extensions APIs to give llms.py a splash of Christmas spirit. It uses <code>__install__</code> to register an API endpoint and a UI extension for its UI features.</p>
<h3 id="replacing-core-components"><a data-card="" href="#replacing-core-components">Replacing Core Components</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p>All UI features of xmas is implemented in its <a href="https://github.com/llmspy/xmas/blob/main/ui/index.mjs" rel="noreferrer noopener" target="_blank">ui/index.mjs</a>
which overrides default <code>Brand</code> and <code>Welcome</code> components by registering components with the same name, e.g:</p>
<figure dir="ltr" tabindex="-1"><div role="region" tabindex="0"><pre><code><span><span>const</span><span> Brand</span><span> =</span><span> {</span></span>
<span><span>    template: </span><span>`</span></span>
<span><span>    &lt;div class=&#34;flex-shrink-0 p-2 border-b border-gray-200 dark:border-gray-700&#34;&gt;</span></span>
<span><span>        &lt;button type=&#34;button&#34; @click=&#34;$router.push(&#39;/&#39;)&#34; class=&#34;...&#34;&gt;</span></span>
<span><span>            üéÑ {{ $state.title }} üéÑ</span></span>
<span><span>        &lt;/button&gt;</span></span>
<span><span>    &lt;/div&gt;</span></span>
<span><span>    `</span><span>,</span></span>
<span><span>}</span></span>
<span><span>const</span><span> Welcome</span><span> =</span><span> {</span></span>
<span><span>    template: </span><span>`&lt;!-- Custom Welcome Screen --&gt;`</span><span>,</span></span>
<span><span>    setup</span><span>() { </span><span>/* ... */</span><span> }</span></span>
<span><span>}</span></span>
<span></span>
<span><span>export</span><span> default</span><span> {</span></span>
<span><span>    install</span><span>(</span><span>ctx</span><span>) {</span></span>
<span><span>        ctx.</span><span>components</span><span>({</span></span>
<span><span>            // Replaces built-in UI Components</span></span>
<span><span>            Brand,</span></span>
<span><span>            Welcome,</span></span>
<span><span>            // Registers other custom components used in this UI Extension</span></span>
<span><span>            XmasPage,</span></span>
<span><span>            XmasTopPanel,</span></span>
<span><span>        })</span></span>
<span><span>    }</span></span>
<span><span>}</span></span></code></pre></div></figure>
<p>To change both the home page and brand on the top-left to give every page title a festive touch:</p>
<p>It also demonstrates adding a new icon on the left sidebar to open its custom Xmas page component and a top-panel component to display its &#34;Ask Santa&#34; portal:</p>

<p>The Xmas page calls a custom API endpoint registered in its <code>__install__</code> hook to return a custom festive greeting, whilst the top-panel modifies chat requests while its Top Panel is open to add a Santa system prompt which is enough to implement its &#34;Ask Santa&#34; feature.</p>
<p>Smart generation models like Nano Banana&#39;s <strong>gemini-2.5-flash-image</strong> perform exceptionally well here as they&#39;re able to answer your kids questions with rich, detailed responses and image outputs.</p>
<hr/>

<p>The <a href="https://github.com/llmspy/gemini" rel="noreferrer noopener" target="_blank">gemini</a> extension provides a complete solution for managing Google Gemini&#39;s <a href="https://ai.google.dev/api/file-search" rel="noreferrer noopener" target="_blank">File Search Stores</a>, enabling <strong>RAG (Retrieval Augmented Generation)</strong> workflows with automatic document uploads, category organization, and bidirectional sync between your local database and Gemini&#39;s cloud storage.</p>
<p>Build up your own knowledge base in File Stores, optionally organized into categories, that you can query to ground your AI chats with your own data - whether that&#39;s searching across a single document, a category of related documents, or your entire filestore.</p>
<h3 id="install-1"><a data-card="" href="#install-1">Install</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p>Install the <strong>gemini</strong> extension via the CLI:</p>
<figure dir="ltr" tabindex="-1"><div role="region" tabindex="0"><pre><code><span><span>llms</span><span> --add</span><span> gemini</span></span></code></pre></div></figure>
<p>After which you&#39;ll be able to click the <strong>Gemini Icon</strong> to open the Gemini extension page from the sidebar to manage your filestores.</p>
<h3 id="key-features"><a data-card="" href="#key-features">Key Features</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<ul>
<li><strong>Filestore Management</strong>: Create and manage isolated stores of documents for different projects or knowledge bases</li>
<li><strong>Drag &amp; Drop Uploads</strong>: Easily upload documents (PDF, Text, Markdown, etc.) by dragging them into the UI</li>
<li><strong>Smart Categorization</strong>: Organize documents into categories (folders) for granular retrieval</li>
<li><strong>Contextual RAG Chat</strong>:<!-- -->
<ul>
<li><strong>Ask Filestore</strong>: Chat with the entire knowledge base of a filestore</li>
<li><strong>Ask Category</strong>: Focus your chat on a specific category within a filestore</li>
<li><strong>Ask Document</strong>: Chat with a single specific document</li>
</ul>
</li>
<li><strong>Bi-Directional Sync</strong>: Reconcile your local database with the remote Gemini File API</li>
</ul>
<h3 id="uploading-documents"><a data-card="" href="#uploading-documents">Uploading Documents</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p>Documents can be uploaded by dragging and dropping files onto the upload zone or clicking to open the file picker. You can organize uploads into category folders by typing a category name before uploading.</p>
<p>Uploads are processed asynchronously by a <strong>Background Worker</strong> utilizing a <strong>DB Queue</strong>, so you can continue working while documents are indexed. The worker automatically starts when new documents are uploaded and efficiently handles batch processing without blocking the UI.</p>
<h3 id="rag-chat-in-action"><a data-card="" href="#rag-chat-in-action">RAG Chat in Action</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p>Once documents are uploaded, you can start contextual RAG chat sessions with your data. Each session is pre-configured with a Gemini Model and the <code>file_search</code> tool to query your selected filestore, category, or document - as shown in the <strong>meta example</strong> below querying this very <strong>v3</strong> document for its best features:</p>
<p>The grounded sources used to answer your query are displayed at the bottom of each chat response, allowing you to verify and explore the source documents.</p>
<p>See the <a href="https://llmspy.org/docs/extensions/gemini">Gemini Extension</a> docs for complete usage instructions.</p>
<hr/>

<p>This release also includes <strong>first-class support for Python function calling (Tools)</strong>, allowing LLMs to interact with your local environment and custom functionality.</p>
<p>Tools can be defined using standard Python functions where its tool definition can be implicitly defined from its function&#39;s signature, type hints, and docstrings:</p>
<figure dir="ltr" tabindex="-1"><div role="region" tabindex="0"><pre><code><span><span>def</span><span> get_current_time</span><span>(tz_name: Optional[</span><span>str</span><span>] </span><span>=</span><span> None</span><span>) -&gt; </span><span>str</span><span>:</span></span>
<span><span>    &#34;&#34;&#34;</span></span>
<span><span>    Get current time in ISO-8601 format.</span></span>
<span></span>
<span><span>    Args:</span></span>
<span><span>        tz_name: Optional timezone name (e.g. &#39;America/New_York&#39;). Defaults to UTC.</span></span>
<span><span>    &#34;&#34;&#34;</span></span>
<span><span>    if</span><span> tz_name:</span></span>
<span><span>        try</span><span>:</span></span>
<span><span>            tz </span><span>=</span><span> ZoneInfo(tz_name)</span></span>
<span><span>        except</span><span> Exception</span><span>:</span></span>
<span><span>            return</span><span> f</span><span>&#34;Error: Invalid timezone &#39;</span><span>{</span><span>tz_name</span><span>}</span><span>&#39;&#34;</span></span>
<span><span>    else</span><span>:</span></span>
<span><span>        tz </span><span>=</span><span> timezone.utc</span></span>
<span></span>
<span><span>    return</span><span> datetime.now(tz).isoformat()</span></span></code></pre></div></figure>
<h3 id="register-tools-for-function-calling"><a data-card="" href="#register-tools-for-function-calling">Register tools for function calling</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<h4 id="implicit-tool-definition"><a data-card="" href="#implicit-tool-definition">Implicit Tool Definition</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h4>
<p>Tools can be registered within an extension&#39;s <code>install</code> hook using <code>ctx.register_tool</code>:</p>
<figure dir="ltr" tabindex="-1"><div role="region" tabindex="0"><pre><code><span><span>def</span><span> install</span><span>(ctx):</span></span>
<span><span>    # Automatic definition from function signature</span></span>
<span><span>    ctx.register_tool(get_current_time)</span></span></code></pre></div></figure>
<p>If no group is specified, tools are registered under the default <code>custom</code> group, alternatively you can group them under your preferred name:</p>
<figure dir="ltr" tabindex="-1"><div role="region" tabindex="0"><pre><code><span><span>ctx.register_tool(get_current_time, </span><span>group</span><span>=</span><span>&#34;my_tools&#34;</span><span>)</span></span></code></pre></div></figure>
<h4 id="explicit-tool-definition"><a data-card="" href="#explicit-tool-definition">Explicit Tool Definition</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h4>
<p>When more fine-grain configuration is needed you can use an explicit tool definition, e.g:</p>
<figure dir="ltr" tabindex="-1"><div role="region" tabindex="0"><pre><code><span><span>ctx.register_tool(</span></span>
<span><span>    get_current_time,</span></span>
<span><span>    {</span></span>
<span><span>        &#34;type&#34;</span><span>: </span><span>&#34;function&#34;</span><span>,</span></span>
<span><span>        &#34;function&#34;</span><span>: {</span></span>
<span><span>            &#34;name&#34;</span><span>: </span><span>&#34;get_current_time&#34;</span><span>,</span></span>
<span><span>            &#34;description&#34;</span><span>: </span><span>&#34;Get current time in ISO-8601 format.&#34;</span><span>,</span></span>
<span><span>            &#34;parameters&#34;</span><span>: {</span></span>
<span><span>                &#34;type&#34;</span><span>: </span><span>&#34;object&#34;</span><span>,</span></span>
<span><span>                &#34;properties&#34;</span><span>: {</span></span>
<span><span>                    &#34;tz_name&#34;</span><span>: {</span></span>
<span><span>                        &#34;type&#34;</span><span>: </span><span>&#34;string&#34;</span><span>,</span></span>
<span><span>                        &#34;description&#34;</span><span>: </span><span>&#34;timezone name (e.g. &#39;America/New_York&#39;)&#34;</span><span>,</span></span>
<span><span>                        &#34;default&#34;</span><span>: </span><span>&#34;UTC&#34;</span></span>
<span><span>                    }</span></span>
<span><span>                },</span></span>
<span><span>                &#34;required&#34;</span><span>: []</span></span>
<span><span>            }</span></span>
<span><span>        }</span></span>
<span><span>    })</span></span></code></pre></div></figure>
<h3 id="ui-management"><a data-card="" href="#ui-management">UI Management</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<ul>
<li><strong>One-Click Enable/Disable</strong>: Use the Tool Selector in the top-right to control which tools to use per request</li>
<li><strong>Granular Control</strong>: Select &#34;All&#34;, &#34;None&#34;, or specific tools for each chat session</li>
</ul>
<p><strong>Dedicated Tools Page</strong>: View all registered tools and their definitions at <code>/tools</code> or via the sidebar</p>
<hr/>

<p>The <a href="https://github.com/llmspy/fast_mcp" rel="noreferrer noopener" target="_blank">fast_mcp</a> extension brings <strong>Model Context Protocol (MCP)</strong> support to llms.py, allowing you to extend LLM capabilities with a wide range of external tools and services using the <a href="https://gofastmcp.com" rel="noreferrer noopener" target="_blank">FastMCP Python Framework</a>.</p>
<h3 id="install-2"><a data-card="" href="#install-2">Install</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<figure dir="ltr" tabindex="-1"><div role="region" tabindex="0"><pre><code><span><span>llms</span><span> --add</span><span> fast_mcp</span></span></code></pre></div></figure>
<h3 id="key-features-1"><a data-card="" href="#key-features-1">Key Features</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<ul>
<li><strong>Standardized Tool Access</strong>: Connect to any MCP-compliant server (Node.js, Python, etc.) seamlessly</li>
<li><strong>Dynamic Discovery</strong>: Automatically discovers and registers all tools exposed by configured servers</li>
<li><strong>Parallel Discovery</strong>: All configured MCP servers are discovered concurrently for fast startup times</li>
<li><strong>UI Management</strong>: Add, edit, and manage MCP servers directly from the Tools page</li>
</ul>

<h3 id="configuration"><a data-card="" href="#configuration">Configuration</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p>MCP servers are configured via a <code>mcp.json</code> file. By default, Anthropic&#39;s <a href="https://github.com/modelcontextprotocol/servers/tree/main/src/git" rel="noreferrer noopener" target="_blank">Git MCP Server</a> is pre-configured:</p>
<figure dir="ltr" tabindex="-1"><div role="region" tabindex="0"><pre><code><span><span>{</span></span>
<span><span>  &#34;mcpServers&#34;</span><span>: {</span></span>
<span><span>    &#34;git&#34;</span><span>: {</span></span>
<span><span>      &#34;command&#34;</span><span>: </span><span>&#34;uvx&#34;</span><span>,</span></span>
<span><span>      &#34;args&#34;</span><span>: [</span><span>&#34;mcp-server-git&#34;</span><span>, </span><span>&#34;--repository&#34;</span><span>, </span><span>&#34;$PWD&#34;</span><span>]</span></span>
<span><span>    },</span></span>
<span><span>    &#34;gemini-gen&#34;</span><span>: {</span></span>
<span><span>      &#34;description&#34;</span><span>: </span><span>&#34;Gemini Image and Audio TTS generation&#34;</span><span>,</span></span>
<span><span>      &#34;command&#34;</span><span>: </span><span>&#34;uvx&#34;</span><span>,</span></span>
<span><span>      &#34;args&#34;</span><span>: [</span><span>&#34;gemini-gen-mcp&#34;</span><span>],</span></span>
<span><span>      &#34;env&#34;</span><span>: {</span></span>
<span><span>        &#34;GEMINI_API_KEY&#34;</span><span>: </span><span>&#34;$GEMINI_API_KEY&#34;</span></span>
<span><span>      }</span></span>
<span><span>    }    </span></span>
<span><span>  }</span></span>
<span><span>}</span></span></code></pre></div></figure>
<h3 id="managing-servers"><a data-card="" href="#managing-servers">Managing Servers</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p>Add, edit, or remove MCP servers directly from the UI:</p>

<h3 id="executing-tools"><a data-card="" href="#executing-tools">Executing Tools</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p>MCP tools can be executed directly from the Tools page or invoked by LLMs during chat sessions:</p>

<h3 id="html-results"><a data-card="" href="#html-results">HTML Results</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p>Tool outputs containing HTML content are rendered within a sandboxed iframe, letting you interact with rich content and even play games:</p>
<p>See the <a href="https://llmspy.org/docs/mcp/fast_mcp">MCP Support</a> docs for complete configuration and usage details.</p>
<h3 id="omarchy-mcp"><a data-card="" href="#omarchy-mcp">Omarchy MCP</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p>For <a href="https://omarchy.org" rel="noreferrer noopener" target="_blank">Omarchy</a> users, the <a href="https://llmspy.org/docs/mcp/omarchy_mcp">Omarchy MCP</a> enables AI assistants to manage themes - including listing, switching, previewing, installing, and removing themes from your Omarchy desktop environment.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/eV17C0cJz00" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen=""></iframe>

<p>The built-in <a href="https://github.com/ServiceStack/llms/blob/main/llms/extensions/core_tools/__init__.py" rel="noreferrer noopener" target="_blank">core_tools</a> extension provides essential functionality for LLMs to interact with their environment, perform calculations, and manage persistent data.</p>
<h3 id="memory-tools"><a data-card="" href="#memory-tools">Memory Tools</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p>Functions for persistent key-value storage.</p>
<ul>
<li><code>memory_read</code> - Read a value from persistent memory.</li>
<li><code>memory_write</code> - Write a value to persistent memory.</li>
</ul>
<h3 id="file-system-tools"><a data-card="" href="#file-system-tools">File System Tools</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p>All file system operations are restricted to the current working directory for safety.</p>
<ul>
<li><code>read_file</code> - Read a text file from disk.</li>
<li><code>write_file</code> - Write text to a file (overwrites existing content).</li>
<li><code>list_directory</code> - List directory contents including file names, sizes, and modification times.</li>
<li><code>glob_paths</code> - Find files and directories matching a glob pattern.</li>
</ul>
<h3 id="utilities"><a data-card="" href="#utilities">Utilities</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<ul>
<li><code>get_current_time</code> - Get the current time in ISO-8601 format.</li>
</ul>
<h3 id="math--logic"><a data-card="" href="#math--logic">Math &amp; Logic</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<ul>
<li><code>calc</code> - Evaluate a mathematical expression. Supports arithmetic, comparison, boolean operators, and common math functions.</li>
</ul>
<h3 id="code-execution-tools"><a data-card="" href="#code-execution-tools">Code Execution Tools</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p>LLMS includes a suite of tools for executing code in various languages within a sandboxed environment. These tools are designed to allow the agent to run scripts, perform calculations, and verify logic safely.</p>
<h4 id="supported-languages"><a data-card="" href="#supported-languages">Supported Languages</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h4>
<ul>
<li><code>run_python(code)</code> - Executes Python code.</li>
<li><code>run_javascript(code)</code> - Executes JavaScript code (uses <code>bun</code> or <code>node</code>).</li>
</ul>

<ul>
<li><code>run_typescript(code)</code> - Executes TypeScript code (uses <code>bun</code> or <code>node</code>).</li>
<li><code>run_csharp(code)</code> - Executes C# code (uses <code>dotnet run</code> with .NET 10+ single-file support).</li>
</ul>


<p>The built-in <a href="https://github.com/ServiceStack/llms/tree/main/llms/extensions/computer" rel="noreferrer noopener" target="_blank">computer_use</a> extension transforms AI agents into autonomous computer operators. Based on <a href="https://github.com/anthropics/anthropic-quickstarts/tree/main/computer-use-demo" rel="noreferrer noopener" target="_blank">Anthropic&#39;s computer use tools</a>, it enables agents to see your screen, control the mouse and keyboard, execute shell commands, and edit files - just like a human sitting at the computer.</p>
<p>This unlocks powerful capabilities that traditional API-based tools cannot achieve:</p>
<ul>
<li><strong>Visual Verification</strong>: Confirm that code actually renders correctly in a browser</li>
<li><strong>Desktop Automation</strong>: Control any GUI application - web browsers, IDEs, terminals</li>
<li><strong>End-to-End Workflows</strong>: Chain together multiple applications in a single task</li>
<li><strong>Legacy Applications</strong>: Automate software that lacks APIs</li>
</ul>
<p>For example, an agent can write a web application, open a browser, and capture a screenshot to prove it works:</p>
<p>See the <a href="https://llmspy.org/docs/extensions/computer_use">Computer Use</a> docs for complete usage details.</p>

<p>As some core tools are particularly useful on their own, dedicated UIs has been added for the <code>calc</code> tool with support for evaluating mathematical python expressions, including arithmetic, comparison, boolean operators, <code>math.*</code> functions &amp; constants and python list comprehensions</p>
<ul>
<li><strong>üñ•Ô∏è UX Friendly Interface</strong> - Clean, modern, responsive UI with dark mode support</li>
<li><strong>üíæ Persistent History</strong> - Calculations automatically saved to localStorage and preserved between sessions</li>
<li><strong>‚ö° 1-Click Interaction</strong> - Click history items to instantly load expressions and copy to clipboard</li>
<li><strong>‚å®Ô∏è Keyboard-Free Access</strong> - Complete UI buttons for numbers, operators, constants, and math functions</li>
<li><strong>üêç Python Math Support</strong> - Full access to Python&#39;s math library including trig, stats, and more</li>
<li><strong>üõ°Ô∏è Safe Evaluation</strong> - AST-based evaluator prevents arbitrary code execution for secure calculations</li>
</ul>

<p>Whilst the <code>run_python</code> tools provides a scratch pad for running stand-alone Python, JavaScript, TypeScript, and C# code in a sandbox.</p>
<p>The UI uses <strong>CodeMirror</strong> as the code editor, providing a better user experience with syntax highlighting, code completion, and other IDE-like features for writing code.</p>


<p>The UI uses <strong>CodeMirror</strong> as the code editor, providing a better user experience with syntax highlighting, code completion, and other IDE-like features for writing code.</p>
<div><div><div><p>INFO</p><p>As both dedicated UIs run the tools directly, they don&#39;t use AI or consume any tokens</p></div></div></div>
<p>See the <a href="https://llmspy.org/docs/features/run-code-ui">Run Code UI</a> docs for more details.</p>
<hr/>

<p>The <a href="https://github.com/ServiceStack/llms/tree/main/llms/extensions/katex" rel="noreferrer noopener" target="_blank">katex</a> extension enables beautiful rendering of LaTeX math expressions in AI responses using <a href="https://katex.org/" rel="noreferrer noopener" target="_blank">KaTeX</a>. It integrates automatically with the markdown parser to render math equations in both inline and block formats.</p>
<h3 id="features"><a data-card="" href="#features">Features</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<ul>
<li><strong>Fast Rendering</strong>: Uses KaTeX for high-performance rendering of math expressions.</li>
<li><strong>Inline Math</strong>: Renders math within text using <code>$</code> or <code>$$</code> delimiters.</li>
<li><strong>Block Math</strong>: Renders complex equations in their own block using <code>$</code> or <code>$$</code> delimiters across multiple lines.</li>
<li><strong>Auto-Integration</strong>: Automatically extends the <code>marked</code> parser used in the application.</li>
</ul>

<hr/>

<p>Unlike text generation, there&#39;s no standard API for image generation across providers - each requires its own custom implementation. Despite the additional effort required, there&#39;s now seamless image generation support through both the UI and CLI with built-in integrations for:</p>
<div><table><thead><tr><th>Provider</th><th>Status</th></tr></thead><tbody><tr><td>Google</td><td>‚úÖ Supported</td></tr><tr><td>OpenAI</td><td>‚úÖ Supported</td></tr><tr><td>OpenRouter</td><td>‚úÖ Supported</td></tr><tr><td>Chutes</td><td>‚úÖ Supported</td></tr><tr><td>Z.ai</td><td>‚úÖ Supported</td></tr><tr><td>Nvidia</td><td>‚úÖ Supported</td></tr></tbody></table></div>
<p>To begin select an image generation model from the Model Selector that supports image generation:</p>
<p>When an image generation model is selected, the chat prompt will the option to specify which aspect ratio to use for the generated images:</p>
<h3 id="command-line-usage"><a data-card="" href="#command-line-usage">Command-Line Usage</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p>Generate images using the <code>--out image</code> modifier:</p>
<figure dir="ltr" tabindex="-1"><div role="region" tabindex="0"><pre><code><span><span>llms</span><span> --out</span><span> image</span><span> &#34;cat in a hat&#34;</span></span></code></pre></div></figure>
<p>Which uses the <code>out:image</code> chat template in <code>llms.json</code> for its image generation request. Before returning, any assets are saved to cache and their local path and HTTP URL returned, e.g:</p>
<p><strong>Output:</strong></p>
<figure dir="ltr" tabindex="-1"><div role="region" tabindex="0"><pre><code><span><span>Here is a cat in a hat for you! </span></span>
<span><span></span></span>
<span><span>Saved files:</span></span>
<span><span>/home/mythz/.llms/cache/c9/c9b2fd2a1d95708251...5d3f467a.png</span></span>
<span><span>http://localhost:8000/~cache/c9/c9b2fd2a1d95708251...5d3f467a.png</span></span></code></pre></div></figure>
<h3 id="specify-a-model"><a data-card="" href="#specify-a-model">Specify a Model</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p>Use any model that supports image generation by specifying its <strong>ID</strong> or <strong>name</strong>:</p>
<figure dir="ltr" tabindex="-1"><div role="region" tabindex="0"><pre><code><span><span>llms</span><span> -m</span><span> &#34;gemini-2.5-flash-image&#34;</span><span> --out</span><span> image</span><span> &#34;cat in a hat&#34;</span></span>
<span><span>llms</span><span> -m</span><span> &#34;Gemini 2.5 Flash Image&#34;</span><span> --out</span><span> image</span><span> &#34;cat in a hat&#34;</span></span></code></pre></div></figure>
<div><div><div><p>INFO</p><p>üìÅ All generated images are saved to <code>~/.llms/cache</code> using their SHA-256 hash as the filename.</p></div></div></div>

<p>Audio generation is an emerging capability with limited provider support where Text-to-Speech generation through both the UI and CLI, currently only supports Google&#39;s latest TTS models:</p>
<div><table><thead><tr><th>Model</th><th>Description</th></tr></thead><tbody><tr><td><strong>Gemini 2.5 Flash Preview TTS</strong></td><td>Fast, lightweight TTS</td></tr><tr><td><strong>Gemini 2.5 Pro Preview TTS</strong></td><td>High-quality TTS</td></tr></tbody></table></div>
<p>Typically you&#39;d select the audio generation model from the Model Selector to find models that supports audio generation:</p>
<p>But despite models.dev listing them as capable of audio generation, only Gemini&#39;s TTS models are currently supported for audio generation through Gemini&#39;s API as Alibaba doesn&#39;t yet support the <strong>audio</strong> modality.</p>
<h3 id="ui--command-line-usage"><a data-card="" href="#ui--command-line-usage">UI &amp; Command-Line Usage</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p>Available in both the UI and on the command-line using <code>--out audio</code>:</p>
<figure dir="ltr" tabindex="-1"><div role="region" tabindex="0"><pre><code><span><span>llms</span><span> --out</span><span> audio</span><span> &#34;Merry Christmas&#34;</span></span>
<span><span>llms</span><span> -m</span><span> gemini-2.5-pro-preview-tts</span><span> --out</span><span> audio</span><span> &#34;Merry Christmas&#34;</span></span></code></pre></div></figure>
<h3 id="output"><a data-card="" href="#output">Output</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p>Audio files are saved locally and accessible via HTTP URL:</p>
<figure dir="ltr" tabindex="-1"><div role="region" tabindex="0"><pre><code><span><span>Saved files:</span></span>
<span><span>/Users/llmspy/.llms/cache/c2/c27b5fd43ebbdbca...acf118.wav</span></span>
<span><span>http://localhost:8000/~cache/c2/c27b5fd43ebbdbca...acf118.wav</span></span></code></pre></div></figure>
<h3 id="playback"><a data-card="" href="#playback">Playback</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p><strong>From the command line:</strong></p>
<figure dir="ltr" tabindex="-1"><div role="region" tabindex="0"><pre><code><span><span>play</span><span> /Users/llmspy/.llms/cache/c2/c27b5fd43ebbdbca...acf118.wav</span></span></code></pre></div></figure>
<p><strong>From the browser:</strong>
Run server with <code>llms --serve 8000</code> to play URL in your browser.</p>

<p>The <a href="https://github.com/ServiceStack/llms/tree/main/llms/extensions/gallery" rel="noreferrer noopener" target="_blank">gallery</a> extension intercepts all generated image, audio &amp; file assets and uploaded files in <code>~/.llms/cache</code> file storage whose metadata is maintained in a SQLite database at <code>~/.llms/user/default/gallery/gallery.sqlite</code></p>
<p>Dedicated UIs are available for quickly browsing and navigating or generated images / audio files including a lightbox previewer for full-size viewing:</p>
<h4 id="portrait-images"><a data-card="" href="#portrait-images">Portrait Images</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h4>
<h4 id="square-images"><a data-card="" href="#square-images">Square Images</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h4>
<h4 id="landscape-images"><a data-card="" href="#landscape-images">Landscape Images</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h4>
<h4 id="audio-generations"><a data-card="" href="#audio-generations">Audio Generations</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h4>
<hr/>

<p>System prompts support was refactored into a replaceable <a href="https://github.com/ServiceStack/llms/tree/main/llms/extensions/system_prompts" rel="noreferrer noopener" target="_blank">system_prompts</a> extension which configures AI requests with a library of <strong>over 200+</strong> awesome curated system prompts that can be selected from the UI.</p>
<h3 id="custom-system-prompts"><a data-card="" href="#custom-system-prompts">Custom System Prompts</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p>You can maintain your own library of system prompts for all anonymous users at:
<code>~/.llms/user/default/system-prompts.json</code></p>
<p>Or for signed in users at:
<code>~/.llms/user/&lt;github-user&gt;/system-prompts.json</code></p>
<p>With the JSON file simply containing an array of names and their system prompts, e.g:</p>
<figure dir="ltr" tabindex="-1"><div role="region" tabindex="0"><pre><code><span><span>[</span></span>
<span><span>    {</span></span>
<span><span>        &#34;name&#34;</span><span>: </span><span>&#34;Helpful Assistant&#34;</span><span>,</span></span>
<span><span>        &#34;prompt&#34;</span><span>: </span><span>&#34;You are a helpful assistant.&#34;</span></span>
<span><span>    }</span></span>
<span><span>]</span></span></code></pre></div></figure>
<p>Browse the complete collection of available system prompts below:</p>

<hr/>

<p>Another major change is the migration from client-side IndexedDB storage to a robust server-side SQLite databases. This architectural shift ensures better data consistency, improved performance that enables parallel executions and multi-device access to your chat history.</p>
<p>To keep the database efficient and portable, binary assets (images, audio, etc.) are not stored directly in the SQLite database, Instead all generated assets are stored in the local file system cache at <code>~/.llms/cache</code> and only <strong>relative URLs</strong> referencing these assets are stored in the database.</p>
<h4 id="concurrency-model"><a data-card="" href="#concurrency-model">Concurrency Model</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h4>
<p>To ensure data integrity and high performance without complex locking mechanisms, the system utilizes a <strong>single background thread</strong> to  write operations to the database. This design improves concurrency handling and eliminates database locking issues during high-load scenarios.</p>
<h4 id="multi-tenancy--security"><a data-card="" href="#multi-tenancy--security">Multi-Tenancy &amp; Security</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h4>
<p>When authentication is enabled, data isolation is automatically enforced. All core tables, including <code>threads</code> and <code>requests</code>, are scoped to the authenticated user, ensuring that users can only access their own data.</p>

<p>A new caching system has been implemented for generated assets and uploaded images and files that&#39;s now persisted in <code>~/.llms/cache</code>, preserving them across messages and sessions.</p>
<ul>
<li><strong>Efficient Storage</strong>: Only cache references are stored with chat messages</li>
<li><strong>Persistent Access</strong>: Images remain accessible in previews and downloads after page reloads</li>
<li><strong>Automatic Management</strong>: System handles file storage and serving transparently</li>
</ul>
<p>Now that all persistence is server-side, to transfer or backup your configurations, extensions and Chat History you need only copy your <code>~/.llms</code> folder.</p>
<hr/>

<p>All server extension features including tools, custom providers, database persistence, and image/audio generation are fully accessible via the command line, making llms.py a powerful terminal-based AI assistant.</p>
<h3 id="core-cli-usage"><a data-card="" href="#core-cli-usage">Core CLI Usage</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<figure dir="ltr" tabindex="-1"><div role="region" tabindex="0"><pre><code><span><span># One-shot query</span></span>
<span><span>llms</span><span> &#34;What is the capital of France?&#34;</span></span>
<span></span>
<span><span># Specify model by ID or name</span></span>
<span><span>llms</span><span> -m</span><span> claude-opus-45</span><span> &#34;Explain quantum computing&#34;</span></span>
<span><span>llms</span><span> -m</span><span> &#34;Claude Opus 4.5&#34;</span><span> &#34;Write a Python function&#34;</span></span></code></pre></div></figure>
<h3 id="tools--function-calling"><a data-card="" href="#tools--function-calling">Tools &amp; Function Calling</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p>All registered tools are automatically available in CLI mode. Enable specific tools with the <code>--tools</code> flag:</p>
<figure dir="ltr" tabindex="-1"><div role="region" tabindex="0"><pre><code><span><span># Use all available tools by default (`--tools all`)</span></span>
<span><span>llms</span><span> &#34;Read the file data.txt and calculate the sum&#34;</span></span>
<span></span>
<span><span># Use specific tools</span></span>
<span><span>llms</span><span> --tools</span><span> calc,get_current_time</span><span> &#34;What time is it in Tokyo and what&#39;s 15% of 230?&#34;</span></span>
<span></span>
<span><span># Don&#39;t use any tools</span></span>
<span><span>llms</span><span> --tools</span><span> none</span><span> &#34;Tell me a joke&#34;</span></span></code></pre></div></figure>
<h3 id="extensions-management"><a data-card="" href="#extensions-management">Extensions Management</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<figure dir="ltr" tabindex="-1"><div role="region" tabindex="0"><pre><code><span><span># List available extensions from github.com/llmspy</span></span>
<span><span>llms</span><span> --add</span></span>
<span></span>
<span><span># Install an extension</span></span>
<span><span>llms</span><span> --add</span><span> fast_mcp</span></span>
<span></span>
<span><span># Install a 3rd-party extension from GitHub</span></span>
<span><span>llms</span><span> --add</span><span> github-user/repo-name</span></span>
<span></span>
<span><span># List installed extensions</span></span>
<span><span>llms</span><span> --remove</span></span>
<span></span>
<span><span># Uninstall an extension</span></span>
<span><span>llms</span><span> --remove</span><span> fast_mcp</span></span></code></pre></div></figure>
<h3 id="provider-management"><a data-card="" href="#provider-management">Provider Management</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<figure dir="ltr" tabindex="-1"><div role="region" tabindex="0"><pre><code><span><span># List all enabled providers and models</span></span>
<span><span>llms</span><span> ls</span></span>
<span></span>
<span><span># List available models from a specific provider</span></span>
<span><span>llms</span><span> ls</span><span> google</span></span>
<span></span>
<span><span># Enable a provider</span></span>
<span><span>llms</span><span> --enable</span><span> google</span></span>
<span></span>
<span><span># Disable a provider</span></span>
<span><span>llms</span><span> --disable</span><span> google</span></span>
<span></span>
<span><span># Update provider definitions from models.dev (automatically updated daily)</span></span>
<span><span>llms</span><span> --update-providers</span></span></code></pre></div></figure>
<h3 id="image-analysis-audio-transcribing--documents-processing"><a data-card="" href="#image-analysis-audio-transcribing--documents-processing">Image Analysis, Audio Transcribing &amp; Documents Processing</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<figure dir="ltr" tabindex="-1"><div role="region" tabindex="0"><pre><code><span><span># Image Analysis</span></span>
<span><span>llms</span><span> --image</span><span> https://example.com/chart.jpg</span><span> &#34;Analyze this chart&#34;</span></span>
<span></span>
<span><span># Audio Processing</span></span>
<span><span>llms</span><span> -m</span><span> gpt-4o-audio-preview</span><span> --audio</span><span> interview.mp3</span><span> &#34;Transcribe this interview&#34;</span></span>
<span></span>
<span><span># Document Processing</span></span>
<span><span>llms</span><span> -m</span><span> gpt-5</span><span> --file</span><span> report.pdf</span><span> &#34;Extract action items&#34;</span></span></code></pre></div></figure>
<h3 id="media-generation"><a data-card="" href="#media-generation">Media Generation</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p>Generate images and audio directly from the command line:</p>
<figure dir="ltr" tabindex="-1"><div role="region" tabindex="0"><pre><code><span><span># Generate images</span></span>
<span><span>llms</span><span> --out</span><span> image</span><span> &#34;A serene mountain landscape at sunset&#34;</span></span>
<span><span>llms</span><span> -m</span><span> &#34;gemini-2.5-flash-image&#34;</span><span> --out</span><span> image</span><span> &#34;Logo for a tech startup&#34;</span></span>
<span></span>
<span><span># Generate audio</span></span>
<span><span>llms</span><span> --out</span><span> audio</span><span> &#34;Welcome to our podcast&#34;</span></span>
<span><span>llms</span><span> -m</span><span> gemini-2.5-pro-preview-tts</span><span> --out</span><span> audio</span><span> &#34;Hello world&#34;</span></span></code></pre></div></figure>
<p>All generated media is automatically saved to <code>~/.llms/cache</code> with metadata persisted in SQLite.</p>
<h3 id="database-persistence"><a data-card="" href="#database-persistence">Database Persistence</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p>All CLI interactions are automatically persisted to <code>~/.llms/user/app/app.sqlite</code>, including:</p>
<ul>
<li>Chat threads and messages</li>
<li>Tool calls and results</li>
<li>Generated assets and file references</li>
<li>User preferences and settings</li>
</ul>
<p>Ensuring your conversation history is preserved and accessible from both CLI and Web UI.</p>
<h3 id="server-mode"><a data-card="" href="#server-mode">Server Mode</a><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" aria-hidden="true"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></h3>
<p>Launch the web UI while keeping full CLI access:</p>
<figure dir="ltr" tabindex="-1"><div role="region" tabindex="0"><pre><code><span><span># Start UI and Chat Completion API on port 8000</span></span>
<span><span>llms</span><span> --serve</span><span> 8000</span></span></code></pre></div></figure>
<p>See <a href="https://llmspy.org/docs/features/cli">CLI Docs</a> for more details.</p>
<hr/>

<figure dir="ltr" tabindex="-1"><div role="region" tabindex="0"><pre><code><span><span># Update llms to v3</span></span>
<span><span>pip</span><span> install</span><span> llms-py</span><span> --upgrade</span></span>
<span></span>
<span><span># Start the server</span></span>
<span><span>llms</span><span> --serve</span><span> 8000</span></span></code></pre></div></figure>
<p><strong>Happy holidays from llms.py!</strong> üéÑ</p>
<hr/>

<p>With llms .py rebuilt from the ground up as an extensible platform, we hope to foster a thriving community extension ecosystem where developers can share innovative solutions and extend llms.py in ways we haven&#39;t yet imagined.</p>
<p>As llms .py is still in active development, we welcome <a href="https://github.com/ServiceStack/llms/discussions" rel="noreferrer noopener" target="_blank">your feedback</a> on any features that would better support 3rd party extensions and help cultivate this growing community.</p>
<hr/></div></div>
  </body>
</html>
