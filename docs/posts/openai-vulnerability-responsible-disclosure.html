<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://requilence.any.org/open-ai-vulnerability-responsible-disclosure">Original</a>
    <h1>OpenAI – vulnerability responsible disclosure</h1>
    
    <div id="readability-page-1" class="page"><div id="blocks"><div><div id="6876dabd877a9114f9593f0e"><div><div><div><p>On </p><markupbold>29 May 2025</markupbold><p> I privately reported a vulnerability to the OpenAI disclosure mailbox using an encrypted email. The flaw allows peeking at chat responses intended for other users. This content may contain personal data, confidential business plans, or proprietary code. OpenAI acknowledged receipt with an automated reply, but I haven&#39;t received a human follow-up (as of the 16th of July), and the issue remains unpatched.</p></div></div></div></div><div id="6876f720877a9114f9593fb5"><div><div><p>The leaked responses show clear signs of being real conversations: they start with contextually appropriate replies, sometimes reference the original user question, appear in various languages, and maintain coherent conversational flow.</p></div></div></div><div id="6876f73c877a9114f9593fbf"><div><div><p>Most convincingly, one response contained accurate financial analysis of an obscure company with a non-Latin name in a small country. When I tested my own ChatGPT requesting the same report without web tools, it said: &#34;Unfortunately, I don&#39;t have specific financial statements for [company name] in my training data, and since you&#39;ve asked not to use web search, I can&#39;t pull them live.&#34; This proves the original response came from a real user session with web search enabled, not hallucination.</p></div></div></div><div id="6876dcaf877a9114f9593f35"><div><div><p>I chose to report this vulnerability via official disclosure email rather than through the <a href="https://bugcrowd.com/engagements/openai" target="_blank">bug bounty platform</a> because of concerning terms in their disclosure agreement. When you submit through their portal, you&#39;re required to agree not to share any information about the issue you found - essentially a blanket non-disclosure that prevents researchers from discussing their findings publicly, even after remediation. </p></div></div></div><div id="6876e23d877a9114f9593f66"><div><div><p>This approach seems misaligned with the broader security community&#39;s values and contrasts sharply with companies like Google, who encourage responsible disclosure and allow researchers to publish details after fixes are deployed. Transparency in security research benefits everyone by advancing collective knowledge and holding companies accountable for timely fixes.</p></div></div></div><div id="6876dabd877a9114f9593f10"><div><div><p>I have followed the industry‑standard 45‑day disclosure window (<a href="https://certcc.github.io/certcc_disclosure_policy/" target="_blank">CERT/CC, ISO/IEC 29147</a>) as a good-faith effort to respond to my report. Because the vulnerability still exists and because users are unknowingly at risk, I am issuing this limited, non‑technical disclosure:</p></div></div></div><div id="6876dabd877a9114f9593f11"><div><div><p><markupbold>No exploit code, proof‑of‑concept, or reproduction steps are included here.</markupbold></p></div></div></div><div id="6876dabd877a9114f9593f12"><div><div><p><markupbold>Only the fact and severity of the flaw are being disclosed.</markupbold></p></div></div></div><div id="6876dabd877a9114f9593f14"><div><div><div><markupbold>Best-in-class models ≠ mature security. </markupbold><p>Market leaders may have &#34;AI‑driven&#34; security pipelines, yet real people still need to triage, reproduce, and remediate bugs. Even well‑funded teams can leave critical tickets untouched.</p></div></div></div></div><div id="6876dabd877a9114f9593f15"><div><div><div><markupbold>Cloud LLMs amplify privacy stakes.</markupbold><p> Large language models ingest and generate fragments of our digital lives. A single misconfiguration can leak thousands of sensitive conversations in seconds. Treating privacy as an afterthought is untenable when the blast radius is this large.</p></div></div></div></div><div id="6876dabd877a9114f9593f16"><div><div><div><markupbold>Transparency builds trust.</markupbold><p> Vendors that close the loop with researchers, publish post‑mortems, and ship fixes quickly keep users safer and strengthen their platforms.</p></div></div></div></div><div id="6876dabd877a9114f9593f18"><div><div><div><markupbold>Avoid sharing sensitive content</markupbold><p> with OpenAI models until an official fix or advisory is released.</p></div></div></div></div><div id="6876dabd877a9114f9593f19"><div><div><div><markupbold>Use data‑segmentation features</markupbold><p> (if available) and scrub prompts of personal identifiers.</p></div></div></div></div><div id="6876dabd877a9114f9593f1a"><div><div><div><markupbold>Monitor OpenAI security page</markupbold><p> for updates or mitigation guidance.</p></div></div></div></div><div id="6876dabd877a9114f9593f1c"><div><div><p>Staff the security inbox with humans empowered to respond within 3–5 business days.</p></div></div></div><div id="6876dabd877a9114f9593f1d"><div><div><p>Publish a clear vulnerability response policy with service‑level objectives (SLOs).</p></div></div></div><div id="6876dabd877a9114f9593f1e"><div><div><p>Conduct periodic third‑party penetration tests that cover model‑to‑model isolation and data governance controls.</p></div></div></div><div id="6876dabd877a9114f9593f1f"><div><div><p>Reward, not ignore, good‑faith researchers. Bug bounty goodwill is perishable.</p></div></div></div><div id="6876dfab877a9114f9593f58"><div><div><p>Do not restrict researchers from disclosing issues via the bug bounty portal policies.</p></div></div></div><div id="6876dabd877a9114f9593f21"><div><div><p>I remain ready to collaborate with the OpenAI security team and will gladly test any candidate patch. Users deserve guarantees that their private conversations stay private. Until then, caution is advised.</p></div></div></div><div id="6876dabd877a9114f9593f22"><div><div><p><markupitalic>— A concerned security researcher</markupitalic></p></div></div></div><div id="6876e7d3877a9114f9593f7f"><div><div><div><p><img src="https://anytype-static.fra1.cdn.digitaloceanspaces.com/emojies/2709.png"/></p></div><div><markupitalic>github/proton/gmail/X/whatever: requilence</markupitalic><markupbold>:</markupbold> <markupcode>1234 5678 9ABC DEF0 1234 5678 9ABC DEF0 1234 5678</markupcode> </div></div></div></div></div></div></div>
  </body>
</html>
