<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://bhmt.dev/blog/sonic_pi/">Original</a>
    <h1>Sonic Pi: Ruby as a Composition Tool</h1>
    
    <div id="readability-page-1" class="page"><div>
      <p>Like the blip of an intro on the front page says, my degree was originally in music. My running joke as a web dev is that neither has meaningfully required me to count past 32. And while my main concentration was vocals, I&#39;ve since realized I should probably <em>stop</em> strictly calling this a nontechnical field, because my actual major was recording — even if I <em>did</em> primarily branch out into this for the sake of tracking my own material.</p>
<p>That last part fell off for a <em>few</em> reasons. First of all, I pretty quickly fell into tech work just by happenstance, and it happened to take. I also didn&#39;t have the space or resources or skillset to realistically amass a <em>lot</em> of different instruments. (Or other audio equipment.) I did pick up bass competently enough after a peer-pressure-induced lark, which happened to stick after picking up Scott Pilgrim (that was a joke... <a href="https://www.youtube.com/watch?v=RtDhGuEGgyc">it was FLCL</a>), and I picked up piano in the course of my major enough to passably self-accompany, but six-string guitars elude me about as much as consistently organizing with a group of other people who play things.</p>
<p>But I also mostly learned to <em>track</em> live instruments, and the small, disorganized experiments I took at electronic music never stuck. Something about a whole other set of overwhelm around picking synths up as <em>instruments,</em> I guess, even if I&#39;m pretty familiar with audio workstations conceptually. But more recently, after a series of constraints that put all the instruments I <em>do</em> have into storage, I&#39;ve taken a dive back into what was <em>also</em> one of my first attempts to learn how to code: <a href="https://sonic-pi.org">Sonic Pi</a>. Ironically enough, as I&#39;ve started making better sense of the language that underpins it, I&#39;ve also started feeling some of my prior knowledge around audio engineering click in new and different ways.</p>
<p>Sonic Pi, created by Sam Aaron, is a <em>very</em> different beast from most audio applications: it&#39;s a software synth controlled entirely through code. It comes with its own control language (a <em>domain-specific language</em>, or DSL) that extends Ruby to map various music and audio concepts onto it. So for instance, you&#39;ll find note names as symbols, like <code>:c4</code>, corresponding to their equivalent MIDI codes. You&#39;ll find <code>chord</code> and <code>scale</code> constructors that take notes and chord/scale structures as arguments, such as <code>chord(:d3, :maj7)</code>. There&#39;s a <code>play</code> that&#39;s used in conjunction with Ruby&#39;s native <code>sleep</code> (sort of... more on that in a second), and a <code>play_pattern_timed</code> that abridges this for you by taking a list of notes and a time interval. (Quarter/half/etc notes are just plain numbers here, and hopefully don&#39;t require more explanation.)</p>
<p>The goal of this project was to track one demo. Compose one instrumental backing, purely by writing code, without the use of anything this this tool didn&#39;t come with out of the box. Because I could <em>use</em> MIDI, or external samples, but then I&#39;m back to rabbit-holing about other audio tools.</p>
<p>I did accomplish this, but it&#39;s a little long for this piece, so for now let&#39;s do something simpler. (And a little less depressing. Besides, my mic was missing for a while during that same storage shuffle, so I never got around to tracking vocals for that anyway.)</p>
<p>If you install the app itself, you can follow along by copy-pasting the code below. (Note that for length I won&#39;t be repeating everything, so at points that I mention I&#39;m reusing sections, or for persistent values like bpm or synth settings, just scroll up.) <em>Also</em> out of the box, you get a detailed set of documentation for the language as well as a series of tutorials.</p>
<pre><code>


use_bpm <span>70</span>
  use_synth <span>:pulse</span> 

play <span>:c2</span>
sleep <span>0.25</span>
play <span>:d2</span>
sleep <span>0.25</span>
play <span>:e2</span>
sleep <span>0.25</span>
play <span>:g2</span>
sleep <span>0.25</span>




play_pattern_timed [ <span>:c3</span>, <span>:d3</span>, <span>:e3</span>, <span>:g3</span> ], <span>0.25</span>
</code></pre>
<p>Of course, I can also just demonstrate the audio itself:</p>
<p>(Note: Some examples below won&#39;t be full blocks of code, or just don&#39;t demonstrate audible changes, so I won&#39;t be doing this for <em>all</em> of them.)</p>
<p>Since this is built on top of plain Ruby, we can abridge this, and make it more flexible so we&#39;re not repeating a lot of code.</p>
<p>We&#39;ll define the whole sequence here:</p>
<pre><code>
<span>def</span> <span>arpeggiate</span> <span>do</span> root, is_minor = <span>false</span>
  
  
  
  <span>4</span>.times <span>do</span>
    
    
    third = <span>4</span>
    third -= <span>1</span> <span>if</span> is_minor
    
    
    

    sequence = [ <span>0</span>, <span>2</span>, third, <span>7</span> ].map { |<span>note</span>| root + note }
    
    play_pattern_timed sequence, <span>0.25</span>

    
    root += <span>12</span>
  <span>end</span>

  
  
  <span>4</span>.times <span>do</span>
    third = <span>8</span>
    third += <span>1</span> <span>if</span> is_minor
    
    sequence = [ <span>0</span>, <span>5</span>, third, <span>10</span> ].map { |<span>note</span>| root - note }

    play_pattern_timed sequence, <span>0.25</span>

    root -= <span>12</span>
  <span>end</span>
<span>end</span>

</code></pre>
<p>And we can then can run through this same pattern several times, at different starting points:</p>
<pre><code>in_thread <span>do</span>
  
  
  
  
  
  use_synth <span>:pulse</span>
  use_synth_defaults <span>amp:</span> <span>0.1</span>

  <span>2</span>.times <span>do</span>
    
    
    
    
    arpeggiate(<span>:c3</span>)
    arpeggiate(<span>:a2</span>, <span>:min</span>)
  <span>end</span>

  arpeggiate(<span>:f2</span>)
  arpeggiate(<span>:g2</span>)
  arpeggiate(<span>:ab2</span>)
  arpeggiate(<span>:bb2</span>)
<span>end</span> 
</code></pre>
<p>You might be wondering about that <code>in_thread do</code> block.</p>
<p>Sonic Pi also uses loops to run code in parallel. So by wrapping the above in one, we can run two separate &#34;instruments&#34; in parallel.</p>
<p>We could <em>also</em>, say...</p>
<pre><code>
in_thread <span>do</span>
  
<span>end</span>

in_thread <span>do</span>
  use_synth <span>:saw</span>
  use_synth_defaults <span>amp:</span> <span>0.2</span>

  melody = [
    <span>:c5</span>, <span>:b4</span>, <span>:d5</span>,
    <span>:c5</span>,
    <span>:c5</span>, <span>:b4</span>, <span>:d5</span>,
    <span>:d5</span>, <span>:e5</span>, <span>:c5</span>,
    <span>:a4</span>, <span>:g4</span>, <span>:a4</span>,
    <span>:b4</span>, <span>:c5</span>, <span>:d5</span>, <span>:g5</span>,
    <span>:f5</span>, <span>:eb5</span>, <span>:d5</span>, <span>:c5</span>,
    <span>:g5</span>, <span>:f5</span>, <span>:eb5</span>, <span>:d5</span>,
  ]
  
  
  
  
  rhythm_a = [ <span>4</span>, <span>2</span>, <span>2</span> ]

  
  
  
  
  
  
  rhythm = [
    rhythm_a,
    <span>8</span>,
    rhythm_a,
    [<span>0.5</span>] * <span>2</span>, <span>7</span>,
    rhythm_a,
    <span>3</span>, <span>1</span>, [<span>2</span>] * <span>2</span>,
    [ <span>1</span>, [<span>0.5</span>] * <span>2</span>, <span>6</span> ] * <span>2</span>
  ].flatten
  
  
  
  play_pattern_timed melody, rhythm
in_thread <span>do</span>
</code></pre>
<p>We could layer these in a couple of different ways to get a &#34;choir&#34; here. You can manually specify chords to play, but you might not have <em>every part</em> of one in a single section, or might want them spread out in specific ways. In that case, you could construct layered notes manually using <code>ring</code> and then just pass them into one list:</p>
<pre><code>choir = [
  ring(<span>:c5</span>, <span>:e5</span>), ring(<span>:c5</span>, <span>:e5</span>), ring(<span>:d5</span>, <span>:f5</span>)
  ring(<span>:c5</span>, <span>:e5</span>)
  
]












</code></pre>
<p>But real choirs don&#39;t all sing in singular rhythmic patterns, and this doesn&#39;t need to either. We can also nest threads, to share parts across different voices.</p>
<pre><code>  
  
  
  
  with_fx <span>:reverb</span>, <span>mix:</span> <span>0.2</span> <span>do</span>
    
    
</code></pre>
<pre><code>in_thread <span>do</span>
  use_synth <span>:saw</span>
  
  
  

  rhythm_a = [ <span>2</span>, <span>1</span>, <span>1</span> ]

  
  
  
  
  
  
  
  

    
    in_thread <span>do</span>
      use_synth_defaults <span>amp:</span> <span>0.25</span>
        
      melody = [
        <span>:c5</span>, <span>:b4</span>, <span>:d5</span>,
        <span>:c5</span>, 
      ]

      
      
      
      rhythm = [
        rhythm_a, 
      ].flatten
        
    <span>end</span>

    
    in_thread <span>do</span>
      use_synth_defaults <span>amp:</span> <span>0.2</span>

      
      
      
      melody = [
        <span>:c5</span>, <span>:b4</span>, <span>:d5</span>,
        <span>:c5</span>, 
      ]
        
      
      
      
      
      
      
      

      
      
      
      
      rhythm = [
        rhythm_a 
      ].flatten
    <span>end</span>
  <span>end</span>
<span>end</span>

</code></pre>
<p>We <em>could</em> give them different voicings with distinct rhythmic patterns. But the source piece (the Prelude, from Final Fantasy) has numerous arrangements that don&#39;t always add that much complexity to its layers, so we don&#39;t have to do that <em>here</em>.</p>
<p>So let&#39;s go back to the rings. Since <code>play_pattern_timed</code> adds a <code>sustain</code> value, we <em>could</em> set that manually. It would look like:</p>
<pre><code>

use_synth_defaults <span>release:</span> <span>0.2</span>, <span>amp:</span> <span>0.2</span>




play_pattern_timed [ring(<span>:c5</span>, <span>:e5</span>)], <span>4</span>, <span>sustain:</span> <span>3.8</span>
play_pattern_timed [ring(<span>:b4</span>, <span>:d5</span>)], <span>2</span>, <span>sustain:</span> <span>1.8</span>
play_pattern_timed [ring(<span>:d5</span>, <span>:f5</span>)], <span>2</span>, <span>sustain:</span> <span>1.8</span>
play_pattern_timed [ring(<span>:c5</span>, <span>:e5</span>)], <span>8</span>, <span>sustain:</span> <span>7.8</span>










</code></pre>
<p>But that&#39;s kind of verbose, and manually handling the offsetting is kind of a pain in the ass, and we can define a function for this.</p>
<p>Before I get to that, though, let me explain some of these parameters above a little more. This is called an <em>envelope</em> — specifically an ADSR (Attack, Decay, Sustain, Release) envelope — and it refers to how the volume levels of a sound are shaped. The Sonic Pi docs have more detail on this, but to give you a simplified explanation of each:</p>
<p><em>Attack</em> is the initial &#34;strike&#34; of a sound, and represents the time that it takes to reach its initial peak, coming from 0. Quick examples would be like the pluck of a guitar string, or the hammer of a piano. Slower ones would be the press of an accordion, or a bowed string that&#39;s slowly increasing in volume.</p>
<p><em>Decay</em> is the time the sound takes to leave that peak. Think when you&#39;re holding down a piano key or a guitar string <em>after</em> it&#39;s first hit. The note is continuing, but it still has a slow fade to it. The sound won&#39;t just continue indefinitely, even if you&#39;re still <em>holding</em> the key that made it ring out.</p>
<p><em>Sustain</em> is the time a sound is held at a stable level, <em>without</em> the fadeout that makes a decay. Examples of sustain include a string being bowed at a consistent volume, or vocals that are being held.</p>
<p><em>Release</em> is the time between letting go of the sound and it actually going silent. A piano key that you hit <em>without</em> holding it will still ring out for a brief moment. A vocalist may still let out a short exhale after letting go of a note. And so on.</p>
<p>Not every sound has every one of these. Synths, for instance, are generated tones that don&#39;t necessarily have any initial build or lingering trail to them. Other, more natural instruments will have these things (or not) in different proportions depending on how you play them. Here, we&#39;re simulating a choir section, but the goal isn&#39;t really to make it lifelike, so the only real aim is to make sure it&#39;s holding for the correct time and has a <em>little</em> bit of separation between chords.</p>
<p>All of that being said, back to the function at hand. We can take the notes that make each chord and define shorthand for them, because</p>
<pre><code><span>def</span> <span>choral_rings</span> notes, sus
  offset = sus &lt; <span>1</span> ? <span>0.1</span> : <span>0.2</span>
  
  
  
  play ring(*notes), <span>sustain:</span> sus - offset, <span>release:</span> offset
  sleep sus
<span>end</span>
</code></pre>
<p>Going further, we can make all of this loop indefinitely, like an <em>actual</em> video game, with <code>live_loop</code>.</p>
<p>Sonic Pi is largely built for live performance — the code inside a <code>live_loop</code> will run until you tell the program to stop. You can alter the contents as it&#39;s playing, and by rerunning the start command, the loop will update the on the next run.</p>
<p>To do this, you&#39;d replace the outer <code>in_thread</code> loops with <code>live_loop :some_unique_name</code>. This gets a little more complex when we&#39;re talking about effects chains — they&#39;re recreated each time the loop runs, so it&#39;s cheaper on resources to run the effects outside the <code>live_loop</code> block, especially as you stack them. But we&#39;re not here to get deep into audio or software engineering right now. We&#39;re here to make blips blip.</p>
<!-- (TORYAH!) -->
<pre><code>live_loop <span>:harp</span> <span>do</span>
  
<span>end</span>

live_loop <span>:choir</span> <span>do</span>
  

  
  
  
  
<span>end</span>
</code></pre>
<p>Ultimately, the whole thing looks like this:</p>
<pre><code>
use_bpm <span>75</span>

<span>def</span> <span>arpeggiate</span> note, is_minor = <span>false</span>
  
  
  
  
  ascending_three = is_minor ? note + <span>3</span> : note + <span>4</span>
  
  ascending = [note, note + <span>2</span>, ascending_three, note + <span>7</span>]
  ascending_arp = [
    *ascending,
    *ascending.map { |<span>note</span>| note + <span>12</span> },
    *ascending.map { |<span>note</span>| note + <span>24</span> },
    *ascending.map { |<span>note</span>| note + <span>36</span> }
  ]
  
  top = note + <span>48</span>
  descending_three = is_minor ? top - <span>9</span> : top - <span>8</span>
  
  descending = [top, top - <span>5</span>, descending_three, top - <span>10</span>]
  
  descending_arp = [
    *descending,
    *descending.map { |<span>note</span>| note - <span>12</span> },
    *descending.map { |<span>note</span>| note - <span>24</span> },
    *descending.map { |<span>note</span>| note - <span>36</span> }
  ]
  
  
  
  
  
  
  
  [*ascending_arp, *descending_arp]

  
  
<span>end</span>

arp_c = arpeggiate <span>:c3</span>
arp_a = arpeggiate <span>:a2</span>, <span>true</span>
arp_f = arpeggiate <span>:f2</span>
arp_g = arpeggiate <span>:g2</span>
arp_ab = arpeggiate <span>:ab2</span>
arp_bb = arpeggiate <span>:bb2</span>

live_loop <span>:harp</span> <span>do</span>
  use_synth <span>:square</span> 
  use_synth_defaults <span>amp:</span> <span>0.15</span>
  
  <span>2</span>.times <span>do</span>
    play_pattern_timed (arp_c), <span>0.25</span>
    play_pattern_timed (arp_a), <span>0.25</span>
  <span>end</span>
  play_pattern_timed (arp_f), <span>0.25</span>
  play_pattern_timed (arp_g), <span>0.25</span>
  play_pattern_timed (arp_ab), <span>0.25</span>
  play_pattern_timed (arp_bb), <span>0.25</span>
<span>end</span>

<span>def</span> <span>choral_rings</span> notes, sus
  offset = sus &lt; <span>1</span> ? <span>0.1</span> : <span>0.2</span>
  
  play ring(*notes), <span>sustain:</span> sus - offset, <span>release:</span> offset
  sleep sus
<span>end</span>

live_loop <span>:choir</span> <span>do</span>
  use_synth <span>:saw</span>
  use_synth_defaults <span>amp:</span> <span>0.35</span>
  
  sleep <span>64</span>
  
  with_fx <span>:reverb</span>, <span>mix:</span> <span>0.75</span> <span>do</span>
    choral_rings [<span>:c5</span>, <span>:e5</span>], <span>4</span>
    choral_rings [<span>:b4</span>, <span>:d5</span>], <span>2</span>
    choral_rings [<span>:d5</span>, <span>:f5</span>], <span>2</span>
    choral_rings [<span>:c5</span>, <span>:e5</span>], <span>8</span>
    
    choral_rings [<span>:c5</span>, <span>:e5</span>], <span>4</span>
    choral_rings [<span>:b4</span>, <span>:d5</span>], <span>2</span>
    choral_rings [<span>:d5</span>, <span>:f5</span>], <span>2</span>
    choral_rings [<span>:d5</span>, <span>:f5</span>], <span>0.5</span>
    choral_rings [<span>:e5</span>, <span>:g5</span>], <span>0.5</span>
    choral_rings [<span>:c5</span>, <span>:e5</span>], <span>7</span>
    
    choral_rings [<span>:a4</span>, <span>:c5</span>], <span>4</span>
    choral_rings [<span>:g4</span>, <span>:b4</span>], <span>2</span>
    choral_rings [<span>:a4</span>, <span>:c5</span>], <span>2</span>
    choral_rings [<span>:b4</span>, <span>:d5</span>], <span>3</span>
    choral_rings [<span>:c5</span>, <span>:e5</span>], <span>1</span>
    choral_rings [<span>:d5</span>, <span>:f5</span>], <span>2</span>
    choral_rings [<span>:b4</span>, <span>:g5</span>], <span>2</span>
    
    choral_rings [<span>:d5</span>, <span>:f5</span>], <span>1</span>
    choral_rings [<span>:c5</span>, <span>:eb5</span>], <span>0.5</span>
    choral_rings [<span>:bb4</span>, <span>:d5</span>], <span>0.5</span>
    choral_rings [<span>:ab4</span>, <span>:c5</span>], <span>6</span>
    
    choral_rings [<span>:eb5</span>, <span>:g5</span>], <span>1</span>
    choral_rings [<span>:d5</span>, <span>:f5</span>], <span>0.5</span>
    choral_rings [<span>:c5</span>, <span>:eb5</span>], <span>0.5</span>
    choral_rings [<span>:bb4</span>, <span>:d5</span>], <span>6</span>
  <span>end</span>
<span>end</span>

</code></pre>
<p>And sounds like this.</p>
<p>As much as tech work is usually discussed in terms of computer <em>science</em> (and as much as I&#39;ve had ex bosses neg me for my major in college), programming is also art. And it&#39;s not even just art when you&#39;re using it to purposely do something creative — such as generating audio like this, or something more visual like designing layouts using CSS. What&#39;s understated is that writing code is a creative act, much like writing anything else. See, you&#39;re not <em>just</em> talking to a machine in the most optimized fashion possible. You&#39;re <em>also</em> talking to other people. And even talking to yourself. (You&#39;re <em>not</em> crazy though — you&#39;re just a little unwell.) Code is ultimately text, and organized text at that. Ultimately, it&#39;s <em>read</em> and not just written — so writing <em>good</em> code is about writing code that can be understood at a glance, whether that&#39;s to other people, or to you in six months.</p>
<p>But once in a while though, the art of it really <em>is</em> the point in itself.</p>

    </div></div>
  </body>
</html>
