<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://baecher.dev/stdout/incremental-backups-of-gmail-takeouts/">Original</a>
    <h1>Incremental Backups of Gmail Takeouts</h1>
    
    <div id="readability-page-1" class="page">
    <p><a href="https://baecher.dev/">Home</a></p>

    

    <p>
      December 2025
    </p>

    <p>
      In an earlier writeup I discussed <a href="https://baecher.dev/stdout/reproducible-git-bundles/">how to create reproducible bundles</a> of git repositories such that a file-based backup strategy can operate incrementally.
      My next target in this vein is Gmail Takeout: your Google account can be locked for arbitrary reasons, legitimate or otherwise, so it&#39;s imperative to have a regular backup of your mail.
      Google&#39;s <a href="https://takeout.google.com">Takeout</a> service is a straightforward way to achieve this.
      In my case I have about 20 years of mail history in the account, going back all the way to the invite-only beta.
      Surprisingly that amounts to 5.7GiB <em>only</em>, with attachments being the driving factor, of course, all delivered in a single text-based <a href="https://en.wikipedia.org/wiki/Mbox"><kbd>mbox</kbd></a> file.
    </p>

    <p>
      This is completely fine for a one-time snapshot, but if you want to back this file up regularly with something like <a href="https://restic.net/">restic</a>, then you will quickly end up in a world of pain: since new mails are not even appended to the end of the file, each cycle of takeout-then-backup essentially produces a new giant file.
      It would be nice if incremental backups only added the delta of mails that are actually new since the last backup.
    </p>

    <p>
      I considered (and actually implemented) multiple different solutions to this problem.
      In one approach, I parsed the entire file and stripped out the attachments in order to store them as separate files, only leaving a link in the corresponding mail.
      This works reasonably well because the attachments account for the overwhelming majority of data.
      However, I was not particularly happy with this solution because parsing the file correctly is not trivial and resulted in a lot of complex code.
      The mail format is very forgiving so you end up with many special cases around peculiar behavior of mail clients.
      To give you an idea, consider that there is no length encoding; it&#39;s all multipart boundaries, and they can be nested, too.
      Actual attachment data also comes in a variety of different encodings, even file-name encoding is done in several micro formats.
      In the end I got the correct number of mails with my parser compared to the Gmail interface (accounting for threaded view), but the complexity of that code felt wrong.
    </p>

    <p>
      What I eventually settled on instead is a simple chunking heuristic based on the <kbd>From ...</kbd> line in front of every mail.
      The catch is that this line can also appear in the body of a mail.
      This results in slight oversplitting: every mail boundary is also a chunk boundary, but not every chunk boundary is a mail boundary.
      In other words, one mail may be partitioned into multiple chunks.
      Each chunk is then saved as a file, content addressed by its MD5 sum.
      Content addressing makes the approach resistant against mail reordering in the <kbd>mbox</kbd> file.
      We could have used the Gmail mail id for this purpose, but the uniform distribution of the content hash enables easy creation of well-distributed subdirectories such that no single directory contains too many files.
      To ensure recovery of the original <kbd>mbox</kbd> file we finally record the sequence of chunks as encountered.
      With this we satisfy the requirement that new mails only add new chunks plus a new sequence of chunks, the latter being fairly negligible in size.
    </p>

    <p>
      With my low-traffic Gmail account, I end up with about 99.8K chunks ≈ mails from 50.6K threads.
      This is tolerable enough for me, but I can see bigger accounts having 10× or 100× mails, at which point the number of chunks may become a concern from a file-system perspective.
      One mitigation would be reducing the chunking frequency by introducing arbitrary additional conditions, e.g., only split when <kbd>hash(&#39;From&#39; line)</kbd> is even.
    </p>

    <p>
      You can find the <a href="https://github.com/pb-/gmail-mbox-codec/">app implementation</a> on Github.
    </p>

    <hr/>

    <p>
      <a href="#top">Return to top</a>
    </p>
  

</div>
  </body>
</html>
