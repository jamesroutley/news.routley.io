<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://stefan-marr.de/2022/11/how-effective-are-classic-lookup-optimizations-for-rails-apps/">Original</a>
    <h1>How effective are classic lookup optimizations for Rails apps?</h1>
    
    <div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p><a href="https://stefan-marr.de/2020/12/shape-of-large-source-code-ruby/">We know</a>
that Ruby and especially Rails applications can be very dynamic and pretty large.
Though, many of the optimizations interpreters and even just-in-time compilers
use <a href="https://stefan-marr.de/2020/08/optimizing-the-unoptimizable-using-old-ideas/">have been invented in the 1980s and 1990s</a> before Ruby and Rails even existed.
So, I was wondering: do these optimizations still have a chance of coping
with the millions of lines of Ruby code that
large Rails apps from <a href="https://shopify.engineering/yjit-just-in-time-compiler-cruby">Shopify</a>, <a href="https://stripe.com/blog/sorbet-stripes-type-checker-for-ruby">Stripe</a>, or <a href="https://gitlab.com/gitlab-org/gitlab/-/issues/365293">GitLab</a> have?</p>

<p>As part of her research, <a href="#paper">Sophie wrote a paper</a> investigating the behavior
of method call sites in detail.
She looked at how well optimizations such as lookup caches,
target duplicate elimination, and splitting apply to modern Ruby code.
I’ll use the work here as a foundation and zoom in on the Rails apps we looked at.
For all details including the measurement methodology,
I’ll defer to <a href="https://stefan-marr.de/downloads/dls22-kaleba-et-al-analyzing-the-run-time-call-site-behavior-of-ruby-applications.pdf">sec. 3 of the paper</a>.
It also discusses how Sophie instrumented <a href="https://github.com/oracle/TruffleRuby">TruffleRuby</a>
and how the data was processed.</p>

<h2 id="blograils-erubirails-the-liquid-benchmarks">BlogRails, ERubiRails, the Liquid Benchmarks</h2>

<p>The benchmarks I am going to be focusing on are called BlogRails,
ERubiRails, LiquidCartRender, and LiquidRenderBibs.
<a href="https://github.com/Shopify/yjit-bench/tree/main/benchmarks/railsbench">BlogRails</a>,
usually referred to as <em>railsbench</em>,
is a small Ruby on Rails application, simulating a basic blog,
as created by Rails’ scaffold generator.
The benchmark accesses existing blog posts and creates new ones.
The <a href="https://github.com/Shopify/yjit-bench/tree/main/benchmarks/erubi_rails">ERubiRails</a> is a similarly small Rails app
and renders <a href="https://github.com/ruby/erb">an ERB template</a> from the Discourse project.</p>

<p>I also included two <a href="https://shopify.github.io/liquid/">Liquid</a> template language benchmarks here out of curiosity.
LiquidCartRender uses Liquid to render an HTML page
for a shopping cart. LiquidRenderBibs renders an HTML page with a list
of papers that have a variety of different data bits to be shown (specifically this one <a href="https://stefan-marr.de/papers">here</a>).</p>





<table>
  <thead>
    <tr>
      <th> </th>
      <th> </th>
      <th> </th>
      <th> </th>
      <th> </th>
      <th> </th>
      <th>Poly. and</th>
      <th>Used</th>
      <th>Poly. and</th>
    </tr>
    <tr>
      <th> </th>
      <th> </th>
      <th>Statement</th>
      <th> </th>
      <th>Function</th>
      <th>Calls</th>
      <th>Megamorphic</th>
      <th>Call</th>
      <th>Megamorphic</th>
    </tr>
    <tr>
      <th>Benchmark</th>
      <th>Statements</th>
      <th>Coverage</th>
      <th>Functions</th>
      <th>Coverage</th>
      <th>(in 1000)</th>
      <th>Calls</th>
      <th>Sites</th>
      <th>Call Sites</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>BlogRails</td>
      <td>118,717</td>
      <td>48%</td>
      <td>37,595</td>
      <td>38%</td>
      <td>13,863</td>
      <td>7.4%</td>
      <td>52,361</td>
      <td>2.3%</td>
    </tr>
    <tr>
      <td>ERubiRails</td>
      <td>117,922</td>
      <td>45%</td>
      <td>37,328</td>
      <td>35%</td>
      <td>12,309</td>
      <td>5.4%</td>
      <td>47,794</td>
      <td>2.3%</td>
    </tr>
    <tr>
      <td>LiquidCartRender</td>
      <td>23,562</td>
      <td>39%</td>
      <td>6,269</td>
      <td>30%</td>
      <td>236</td>
      <td>5.5%</td>
      <td>3,581</td>
      <td>2.4%</td>
    </tr>
    <tr>
      <td>LiquidRenderBibs</td>
      <td>23,277</td>
      <td>39%</td>
      <td>6,185</td>
      <td>29%</td>
      <td>385</td>
      <td>23.4%</td>
      <td>3,466</td>
      <td>2.8%</td>
    </tr>
  </tbody>
</table>

<p>As the table above shows, the Rails benchmarks have about 120,000 Ruby statements each,
of which 45-48% are executed.
Of the circa 37,500 functions, about 35-38% are executed.
In total, the BlogRails benchmark makes about 13,863,000 function calls.
7.4% of these calls are polymorphic or megamorphic.</p>

<p>In Ruby, a call site is considered to be <em>monomorphic</em>, if there is a single
receiver class seen during execution, which also means there’s usually a
single method that is being called.
When there is more than one different receiver type,
we call the call site <em>polymorphic</em>.
Once there were more than a certain number of receiver types,
a call site is <em>megamorphic</em>. In TruffleRuby, this happens when
more than 8 different receiver types were used at the call site.
Though, this is a bit of a simplification, and we’ll get into more details in the <a href="#polymorphism">next section</a>.</p>

<p>Until then we can observer that ERubiRails seems a bit less polymorphic.
Only 5.4% of its calls are polymorphic or megamorphic.</p>

<p>The Liquid benchmarks are much smaller, with only about 23,500 statements
in about 6,200 functions.
The number of calls being between 236,000 and 385,000 is also significantly smaller.
Surprisingly, about 23% of all calls in the LiquidRenderBibs benchmark are polymorphic.
While I haven’t looked into it in more detail, I would assume that this
might be an artifact of the template having to handle a large number of differences in the input data.</p>

<p>Compared to other languages, these numbers do not feel too different.
For instance, the <a href="https://dl.acm.org/doi/10.1145/2048066.2048118">Dacapo Con Scala</a>
project found somewhat similar numbers for Java and Scala.
In the Scala benchmarks they looked at, 89.7% of all calls were monomorphic.
The Java benchmarks had about 91.5% of all calls being monomorphic.</p>

<p>This means what we see for Rails is roughly in line with what one would expect.
This is good news, because it means that the classic optimizations are likely going to work as expected.</p>

<p>But before getting too enthusiastic, let’s dig a little deeper to see whether that is indeed the case.</p>

<h2 id="polymorphism">Receiver versus Target Polymorphism</h2>

<p>Let’s take a very simple, Rails-like example as a starting point.
The following code shows the <code>ApplicationController</code> defining
the <code>status</code> method, which simply returns an HTTP status code.</p>

<p>We also define an <code>ArticlesController</code> as subclass of <code>ApplicationController</code>.
The <code>ArticlesController</code> implements the <code>index</code> method, which for brevity is kept empty.</p>

<figure><pre><code data-lang="ruby"><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
</pre></td><td><pre><span>class</span> <span>ApplicationController</span>
  <span>def</span> <span>status</span>
    <span>200</span>
  <span>end</span>
<span>end</span>

<span>class</span> <span>ArticlesController</span> <span>&lt;</span> <span>ApplicationController</span>
  <span>def</span> <span>index</span>
  <span>end</span>
<span>end</span>

<span>controllers</span> <span>=</span> <span>[</span>
  <span>ArticlesController</span><span>.</span><span>new</span><span>,</span>
  <span>ApplicationController</span><span>.</span><span>new</span>
<span>]</span>
<span>controllers</span><span>.</span><span>select</span> <span>{</span> <span>|</span><span>c</span><span>|</span> <span>c</span><span>.</span><span>status</span> <span>==</span> <span>200</span> <span>}</span>
</pre></td></tr></tbody></table></code></pre></figure>

<p>At the end of the example on line 16, we have an array with both controllers,
and select the ones with the status code being 200.
The call to the <code>status</code> method is <em>receiver-polymorphic</em>.
This means the call site sees multiple different receiver types,
in our case the two controllers.
Though, at the same time, the call site is <em>target-monomorphic</em>.
This means, there’s only a single method that is activated.</p>

<p>TruffleRuby optimizes this case by using two
<a href="https://bibliography.selflanguage.org/_static/pics.pdf">polymorphic inline caches</a> or more accurately <a href="https://stefan-marr.de/papers/pldi-marr-et-al-zero-overhead-metaprogramming/#x1-130003.1">dispatch chains</a>,
one after another, as depicted in <a href="#fig1">fig. 1</a>.</p>

<figure id="fig1">
<img src="https://stefan-marr.de/assets/2022/call-behavior/invoke-dispatch-chain.svg"/>
<figcaption>Fig. 1. Optimizing Method Dispatch</figcaption>
</figure>

<p>By using two dispatch chains, a language implementation can often turn
a receiver-polymorphic call site into a target-monomorphic one.
The first dispatch chain acts as classic lookup cache.
It takes the receiver type<sup>1</sup>
<span><sup>1</sup> Since TruffleRuby uses object shapes to optimize objects, they would be used as a proxy for the receiver type.</span>
and caches the method as the result of a lookup.
The second cache deduplicates the target methods and in the case of TruffleRuby,
it caches Truffle’s <em>call nodes</em>, which implement the method activation,
but also optimizations such as <a href="#method-splitting">splitting</a>.</p>

<p>Based on our data, eliminating duplicate targets is also an effective optimization for Rails:</p>


<table>
<tbody><tr>
<th></th>
<th colspan="2">Number of Calls</th>
<th colspan="2">After Eliminating Duplicate Targets</th>
</tr>
<tr>
<th>Benchmark</th>
<th>Polymorphic</th>
<th>Megamorphic</th>
<th>Polymorphic</th>
<th>Megamorphic</th>
</tr>
<tr>
<td>BlogRails</td>
<td>956,515</td>
<td>63,319</td>
<td>-48.8%</td>
<td>-99.1%</td>
</tr>
<tr>
<td>ERubiRails</td>
<td>626,535</td>
<td>40,699</td>
<td>-37.4%</td>
<td>-98.6%</td>
</tr>
<tr>
<td>LiquidCartRender</td>
<td>12,598</td>
<td>280</td>
<td>-73.3%</td>
<td>-100.0%</td>
</tr>
<tr>
<td>LiquidRenderBibs</td>
<td>89,866</td>
<td>280</td>
<td>-73.7%</td>
<td>-100.0%</td>
</tr>
</tbody></table>

<p>The table above gives the absolute number of calls these benchmarks do.
As we can see in column two and three there are relatively few
megamorphic calls to begin with.
In TruffleRuby, a call site is megamorphic when there are more than
8 different receivers or target methods.
Megamorphic calls can be a performance issue, especially when
class hierarchies are deep and method lookup is costly,
because for such megamorphic calls, we cannot cache the lookup results.</p>

<p>The good news is that eliminating of duplicate targets is highly effective
in avoiding megamorphic calls. As we can see in column five,
most calls stop being megamorphic.
However, the optimization is much less effective in avoiding polymorphic calls,
reducing their number by only 37.4-48.8%. This means, that about 50-60% of
calls are still polymorphic.</p>

<p>For a basic interpreter, this isn’t too bad, because we still avoid the
overhead of a lookup. However, for TruffleRuby with its just-in-time compilation,
this situation is not ideal, because method inlining, i.e., replacing a call
by taking the method body and integrating it into the caller during compilation,
is limited.</p>

<p>On the positive side, our Liquid render benchmarks benefit nicely here.
While I haven’t looked in detail, the number of megamorphic calls being the same
suggests that these calls are made in the initial setup and eliminating duplicate
targets prevents them from being megamorphic.</p>

<h2 id="method-splitting">Method Splitting</h2>

<p>TruffleRuby uses an optimization that is not as common in just-in-time compiling
systems: method splitting.
Most just-in-time compilers rely solely on inlining to enable classic compiler
optimizations and get efficient native code.
Though, since TruffleRuby builds on the Truffle framework with its
<a href="https://stefan-marr.de/papers/oopsla-marr-ducasse-meta-tracing-vs-partial-evaluation/#x1-70002.1">metacompilation</a> approach,
it tries harder to optimize even before the just-in-time compilation kicks in.</p>

<p>Truffle’s method splitting copies a method in a state that is <em>uninitialized</em>.
For us most importantly this means, it copies the method without the lookup cache entries
as illustrated in <a href="#fig2">fig. 2</a>.
The split method, i.e. the copy, is then associated with a single call site.
The idea is that this copy <em>specializes</em> itself in the context of this single
caller, which hopefully means method calls are more likely to be monomorphic.</p>

<figure id="fig2">
<img src="https://stefan-marr.de/assets/2022/call-behavior/method-splitting.svg"/>
<figcaption>Fig. 2. Method Splitting copies a method for use at a specific call site.
The copy is <em>uninitialized</em>, which means the dispatch chains do not contain any
entries yet.</figcaption>
</figure>

<p>So, is splitting succeeding at <em>monomorphizing</em> call sites?
Let’s look at the data. Note, we already eliminated duplicate targets.
Thus, the numbers are a little smaller here.</p>


<table>
<tbody><tr>
<th></th>
<th colspan="2">Number of Calls (w/o duplicate targets)</th>
<th colspan="2">After Splitting</th>
</tr>
<tr>
<th>Benchmark</th>
<th>Polymorphic</th>
<th>Megamorphic</th>
<th>Polymorphic</th>
<th>Megamorphic</th>
</tr>
<tr>
<td>BlogRails</td>
<td>490,072</td>
<td>557</td>
<td>-100%</td>
<td>-100%</td>
</tr>
<tr>
<td>ERubiRails</td>
<td>391,997</td>
<td>553</td>
<td>-100%</td>
<td>-100%</td>
</tr>
<tr>
<td>LiquidCartRender</td>
<td>2,000</td>
<td>0</td>
<td>-100%</td>
<td>n/a</td>
</tr>
<tr>
<td>LiquidRenderBibs</td>
<td>23,633</td>
<td>0</td>
<td>-100%</td>
<td>n/a</td>
</tr>
</tbody></table>

<p>Indeed, splitting is highly effective in turning polymorphic and megamorphic
calls into monomorphic calls, which allows the just-in-time compiler to
aggressively inline and optimize the Ruby code.</p>

<h2 id="overall-monomorphization">Overall Monomorphization</h2>

<p>As we have seen in the last table, the polymorphic and megamorphic calls were
all monomorphized.
Though, let’s take a slightly different look at the data.
Instead of looking at the run-time calls, let’s look at how many targets there are at a call site.</p>


<table>
<tbody><tr>
<th></th>
<th colspan="3">Maximum Number of Targets</th>
</tr>
<tr>
<th></th>
<th>before</th>
<th>target duplicates</th>
<th>after</th>
</tr>
<tr>
<th>Benchmark</th>
<th>optimizations</th>
<th>eliminated</th>
<th>splitting</th>
</tr>
<tr>
<td>BlogRails</td>
<td>206</td>
<td>24</td>
<td>2</td>
</tr>
<tr>
<td>ERubiRails</td>
<td>206</td>
<td>24</td>
<td>2</td>
</tr>
<tr>
<td>LiquidCartRender</td>
<td>20</td>
<td>5</td>
<td>1</td>
</tr>
<tr>
<td>LiquidRenderBibs</td>
<td>20</td>
<td>7</td>
<td>1</td>
</tr>
</tbody></table>

<p>From this table we can see that the Rails benchmarks have at least one call site
with 206 different receiver types.
After eliminate duplicate target
methods, we see at most 24 different targets.
Adding splitting to the system reduces it further to at most 2 entries.
As we saw from the number of run-time calls, these optimizations in combination
are indeed highly effective for Rails applications.</p>

<p>From this brief look, we can conclude that despite these optimizations having been invented some 30-40 years ago,
they are still highly effective even for today’s dynamic Ruby on Rails systems.</p>

<h2 id="who-you-gonna-call-analyzing-the-run-time-call-site-behavior-of-ruby-applications">Who You Gonna Call: Analyzing the Run-time Call-Site Behavior of Ruby Applications</h2>


<p>In our paper, we go into many more details.
We also look at how blocks behave
(spoiler: they turn out to be slightly more polymorphic than methods).
We investigate how lookup caches evolve over time
and find patterns that may help us to improve performance further in the
future.
We also noticed that TruffleRuby’s splitting is a little too enthusiastic.
For instance, blocks/Procs were always split, <a href="https://github.com/oracle/truffleruby/commit/02c9988791fd6c1a385d4e3865e5abb5fa7ffa12">which has been fixed already</a>.
There is more work to be done to see whether splitting can further be reduced
to avoid redundant work at run time.
Though, that’s for another day.</p>

<p>Meanwhile, please give the paper a read,
attend our <a href="https://2022.splashcon.org/details/dls-2022-papers/2/Who-You-Gonna-Call-Analyzing-the-Run-time-Call-Site-Behavior-of-Ruby-Applications">presentation at DLS</a>, and find us with questions, comments,
and suggestions on Twitter <a href="https://twitter.com/sophiekaleba">@SophieKaleba</a> and <a href="https://twitter.com/smarr">@smarr</a>.</p>

<p><strong>Abstract</strong></p>

<blockquote>
  <p>Applications written in dynamic languages are becoming larger and larger and companies increasingly use multi-million line codebases in production. At the same time, dynamic languages rely heavily on dynamic optimizations, particularly those that reduce the overhead of method calls.</p>

<p>In this work, we study the call-site behavior of Ruby benchmarks that are being used to guide the development of upcoming Ruby implementations such as TruffleRuby and YJIT. We study the interaction of call-site lookup caches, method splitting, and elimination of duplicate call-targets.</p>

<p>We find that these optimizations are indeed highly effective on both smaller and large benchmarks, methods and closures alike, and help to open up opportunities for further optimizations such as inlining. However, we show that TruffleRuby’s splitting may be applied too aggressively on already-monomorphic call-sites, coming at a run-time cost. We also find three distinct patterns in the evolution of call-site behavior over time, which may help to guide novel optimizations. We believe that our results may support language implementers in optimizing runtime systems for large codebases built in dynamic languages.</p>

</blockquote>

<ul>
  <li>Who You Gonna Call: Analyzing the Run-time Call-Site Behavior of Ruby Applications</li>

    <li>
      Paper:
        <a href="https://stefan-marr.de/downloads/dls22-kaleba-et-al-analyzing-the-run-time-call-site-behavior-of-ruby-applications.pdf">
          PDF</a>
    </li>

    <li>
        DOI: <a href="https://doi.org/10.1145/3563834.3567538">10.1145/3563834.3567538</a>
    </li>

    


    <li>
      BibTex:
      <span tabindex="0"><span>bibtex</span>
      <pre>@inproceedings{Kaleba:2022:CallSites,
  abstract = {Applications written in dynamic languages are becoming larger and larger and companies increasingly use multi-million line codebases in production. At the same time, dynamic languages rely heavily on dynamic optimizations, particularly those that reduce the overhead of method calls.
  
  In this work, we study the call-site behavior of Ruby benchmarks that are being used to guide the development of upcoming Ruby implementations such as TruffleRuby and YJIT. We study the interaction of call-site lookup caches, method splitting, and elimination of duplicate call-targets.
  
  We find that these optimizations are indeed highly effective on both smaller and large benchmarks, methods and closures alike, and help to open up opportunities for further optimizations such as inlining. However, we show that TruffleRuby&#39;s splitting may be applied too aggressively on already-monomorphic call-sites, coming at a run-time cost. We also find three distinct patterns in the evolution of call-site behavior over time, which may help to guide novel optimizations. We believe that our results may support language implementers in optimizing runtime systems for large codebases built in dynamic languages.},
  acceptancerate = {0.4},
  author = {Kaleba, Sophie and Larose, Octave and Jones, Richard and Marr, Stefan},
  booktitle = {Proceedings of the 18th Symposium on Dynamic Languages},
  day = {7},
  doi = {10.1145/3563834.3567538},
  keywords = {Analysis CallSite DynamicLanguages Inlining LookupCache MeMyPublication Splitting myown},
  location = {Auckland, New Zealand},
  month = dec,
  note = {(acceptance rate 40%)},
  pages = {14},
  pdf = {https://stefan-marr.de/downloads/dls22-kaleba-et-al-analyzing-the-run-time-call-site-behavior-of-ruby-applications.pdf},
  publisher = {ACM},
  series = {DLS&#39;22},
  title = {Who You Gonna Call: Analyzing the Run-time Call-Site Behavior of Ruby Applications},
  year = {2022},
  month_numeric = {12}
}
</pre>
      </span>
    </li>
</ul>

<h3 id="acknowledgments">Acknowledgments</h3>

<p>Thanks to Sophie, Octave, and Chris Seaton for suggestions and corrections on this blog post.</p>


</div></div>
  </body>
</html>
