<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.google/technology/developers/gemma-open-models/">Original</a>
    <h1>Gemma: New Open Models</h1>
    
    <div id="readability-page-1" class="page"><article ng-init="drawerToggle = {&#39;open&#39;: true}">

    
    


<section data-analytics-module="{
  &#34;module_name&#34;: &#34;Article Hero&#34;,
  &#34;section_header&#34;: &#34;Gemma: Introducing new state\u002Dof\u002Dthe\u002Dart open models&#34;
}">
  
</section>


    

    
      

<div data-analytics-module="{
    &#34;module_name&#34;: &#34;Hero Menu&#34;,
    &#34;section_header&#34;: &#34;Gemma: Introducing new state\u002Dof\u002Dthe\u002Dart open models&#34;
  }">
  <div>
    <div>
      
      
        <p>
          Gemma is built for responsible AI development from the same research and technology used to create Gemini models.
        </p>
      
    </div>
  </div>
  <div>
    <div>
      
        
  
    
  

  
    <div>
      
  

<div>
  <p>Tris Warkentin</p>
  
    <p>
      Director, Google DeepMind
    </p>
  
  
</div>

    </div>
  


      
    </div>
    
      
    
    
  </div>
</div>

    

    
      







<div>
  <div>
    <figure>
      <div>
  <p><img srcset="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemma-header.width-600.format-webp.webp 600w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemma-header.width-1200.format-webp.webp 1200w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemma-header.width-1600.format-webp.webp 1600w" sizes="(max-width: 599px) 100vw, (max-width: 1023px) 600px, 1024px" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/gemma-header.width-1200.format-webp.webp" fetchpriority="high" alt="The word “Gemma” and a spark icon with blueprint styling appears in a blue gradient against a black background."/>
  </p>
</div>

      
    </figure>
  </div>
</div>


    

    
    <section>
      <div>
        
          
          
          <div data-reading-time="true" data-component="uni-drop-cap|uni-tombstone">

            
              


<google-read-aloud-player data-analytics-module="{
        &#34;event&#34;: &#34;module_impression&#34;,
        &#34;module_name&#34;: &#34;ai_audio&#34;,
        &#34;section_header&#34;: &#34;Gemma: Introducing new state\u002Dof\u002Dthe\u002Dart open models&#34;
    }" data-date-modified="2024-02-21T13:47:02.283485+00:00" data-progress-bar-style="half-wave" data-api-key="AIzaSyBLT6VkYe-x7sWLZI2Ep26-fNkBKgND-Ac" data-article-style="style9" data-tracking-ids="G-HGNBTNCHCQ,G-6NKTLKV14N" data-voice-list="en.ioh-pngnat:Cyan,en.usb-pngnat:Lime" data-layout-style="style1" data-highlight-mode="word-over-paragraph" data-highlight-text-color="#000000" data-highlight-word-background="#8AB4F8" data-highlight-paragraph-background="#D2E3FC" data-background="linear-gradient(180deg, #F1F3F4 0%, #F8F9FA 100%)" data-foreground-color="#202124" data-font="600 16px Google Sans, sans-serif" data-box-shadow="0px 1px 3px 1px rgba(60, 64, 67, 0.15)">
</google-read-aloud-player>




            

            
            
<!--article text-->

  
    <div data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Gemma: Introducing new state\u002Dof\u002Dthe\u002Dart open models&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><p data-block-key="c7knx">At Google, we believe in <a href="https://ai.google/" rt-link-type="external">making AI helpful for everyone</a>. We have a long history of contributing innovations to the open community, such as with <a href="https://blog.research.google/2017/08/transformer-novel-neural-network.html" rt-link-type="external">Transformers</a>, <a href="https://www.tensorflow.org/" rt-link-type="external">TensorFlow</a>, <a href="https://blog.research.google/2018/11/open-sourcing-bert-state-of-art-pre.html" rt-link-type="external">BERT</a>, <a href="https://blog.research.google/2020/02/exploring-transfer-learning-with-t5.html" rt-link-type="external">T5</a>, <a href="https://github.com/google/jax" rt-link-type="external">JAX</a>, <a href="https://deepmind.google/discover/blog/alphafold-a-solution-to-a-50-year-old-grand-challenge-in-biology/" rt-link-type="external">AlphaFold</a>, and <a href="https://deepmind.google/discover/blog/competitive-programming-with-alphacode/" rt-link-type="external">AlphaCode</a>. Today, we’re excited to introduce a new generation of open models from Google to assist developers and researchers in building AI responsibly.</p><h2 data-block-key="cpl7a">Gemma open models</h2><p data-block-key="48b6k"><a href="https://ai.google.dev/gemma/?utm_source=keyword&amp;utm_medium=referral&amp;utm_campaign=gemma_cta&amp;utm_content=" rt-link-type="external">Gemma</a> is a family of lightweight, state-of-the-art <a href="https://opensource.googleblog.com/2024/02/building-open-models-responsibly-gemini-era.html" rt-link-type="external">open models</a> built from the same research and technology used to create the <a href="https://deepmind.google/technologies/gemini/#introduction" rt-link-type="external">Gemini</a> models. Developed by Google DeepMind and other teams across Google, Gemma is inspired by Gemini, and the name reflects the Latin <i>gemma</i>, meaning “precious stone.” Accompanying our model weights, we’re also releasing tools to support developer innovation, foster collaboration, and guide responsible use of Gemma models.</p><p data-block-key="ebmmu">Gemma is available worldwide, starting today. Here are the key details to know:</p><ul><li data-block-key="d3250">We’re releasing model weights in two sizes: <a href="https://www.kaggle.com/models/google/gemma" rt-link-type="external">Gemma 2B and Gemma 7B</a>. Each size is released with pre-trained and instruction-tuned variants.</li><li data-block-key="93fl7">A new <a href="https://ai.google.dev/responsible?utm_source=agd&amp;utm_medium=referral&amp;utm_campaign=explore-responsible&amp;utm_content" rt-link-type="external">Responsible Generative AI Toolkit</a> provides guidance and essential tools for creating safer AI applications with Gemma.</li><li data-block-key="fj09f">We’re providing toolchains for inference and supervised fine-tuning (SFT) across all major frameworks: JAX, PyTorch, and TensorFlow through native <a href="https://github.com/keras-team/keras" rt-link-type="external">Keras 3.0</a>.</li><li data-block-key="7ed0k">Ready-to-use <a href="http://ai.google.dev/gemma/docs/get_started" rt-link-type="external">Colab</a> and <a href="https://www.kaggle.com/models/google/gemma/code" rt-link-type="external">Kaggle notebooks</a>, alongside integration with popular tools such as <a href="http://huggingface.co/google" rt-link-type="external">Hugging Face</a>, <a href="https://github.com/google/maxtext" rt-link-type="external">MaxText</a>, <a href="https://github.com/NVIDIA/GenerativeAIExamples/tree/main/models/Gemma" rt-link-type="external">NVIDIA NeMo</a> and <a href="https://github.com/NVIDIA/TensorRT-LLM" rt-link-type="external">TensorRT-LLM</a>, make it easy to get started with Gemma.</li><li data-block-key="ei3as"><a href="https://www.kaggle.com/models/google/gemma" rt-link-type="external">Pre-trained and instruction-tuned Gemma models</a> can run on your laptop, workstation, or Google Cloud with easy deployment on <a href="https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/335" rt-link-type="external">Vertex AI</a> and <a href="https://cloud.google.com/kubernetes-engine/docs/integrations/ai-infra" rt-link-type="external">Google Kubernetes Engine</a> (GKE).</li><li data-block-key="3pmgh">Optimization across multiple AI hardware platforms ensures industry-leading performance, including <a href="https://cloud.google.com/nvidia" rt-link-type="external">NVIDIA GPUs</a> and <a href="https://cloud.google.com/tpu" rt-link-type="external">Google Cloud TPUs</a>.</li><li data-block-key="9up68"><a href="https://www.kaggle.com/models/google/gemma/license/consent" rt-link-type="external">Terms of use</a> permit responsible commercial usage and distribution for all organizations, regardless of size.</li></ul><h2 data-block-key="8rpl2">State-of-the-art performance at size</h2><p data-block-key="5d12o">Gemma models share technical and infrastructure components with <a href="https://deepmind.google/technologies/gemini/#introduction" rt-link-type="external">Gemini</a>, our largest and most capable AI model widely available today. This enables Gemma 2B and 7B to achieve best-in-class performance for their sizes compared to other open models. And Gemma models are capable of running directly on a developer laptop or desktop computer. Notably, Gemma surpasses significantly larger models on key benchmarks while adhering to our rigorous standards for safe and responsible outputs. See the <a href="https://goo.gle/GemmaReport" rt-link-type="external">technical report</a> for details on performance, dataset composition, and modeling methodologies.</p></div>
      </div>
    </div>
  

  
    







  
      <div data-analytics-module="{
          &#34;module_name&#34;: &#34;Inline Images&#34;,
          &#34;section_header&#34;: &#34;Gemma: Introducing new state\u002Dof\u002Dthe\u002Dart open models&#34;
        }">
  

  <p><img alt="A chart showing Gemma performance on common benchmarks, compared to Llama-2 7B and 13B" src=" https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Benchmark_chart_Updates_19.02_1.width-100.format-webp.webp " loading="lazy" data-loading="{
                &#34;mobile&#34;: &#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Benchmark_chart_Updates_19.02_1.width-500.format-webp.webp&#34;,
                &#34;desktop&#34;: &#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Benchmark_chart_Updates_19.02_1.width-1000.format-webp.webp&#34;
              }"/>
        
      
    
    </p>
    
  
    </div>
  



  

  
    <div data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Gemma: Introducing new state\u002Dof\u002Dthe\u002Dart open models&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><h2 data-block-key="c7knx">Responsible by design</h2><p data-block-key="4lgk">Gemma is designed with our <a href="https://ai.google.dev/responsible?utm_source=agd&amp;utm_medium=referral&amp;utm_campaign=explore-responsible&amp;utm_content" rt-link-type="external">AI Principles</a> at the forefront. As part of making Gemma pre-trained models safe and reliable, we used automated techniques to filter out certain personal information and other sensitive data from training sets. Additionally, we used extensive fine-tuning and reinforcement learning from human feedback (RLHF) to align our instruction-tuned models with responsible behaviors. To understand and reduce the risk profile for Gemma models, we conducted robust evaluations including manual red-teaming, automated adversarial testing, and assessments of model capabilities for dangerous activities. These evaluations are outlined in our <a href="https://www.kaggle.com/models/google/gemma" rt-link-type="external">Model Card</a>.<a href="#footnote-1" id="footnote-source-1" data-ga4-analytics-superscript-click="" data-target="inline text"><sup>1</sup></a></p><p data-block-key="b9d8h">We’re also releasing a new <a href="https://ai.google.dev/responsible?utm_source=agd&amp;utm_medium=referral&amp;utm_campaign=explore-responsible&amp;utm_content" rt-link-type="external">Responsible Generative AI Toolkit</a> together with Gemma to help developers and researchers prioritize building safe and responsible AI applications. The toolkit includes:</p><ul><li data-block-key="cv45q"><b>Safety classification:</b> We provide a <a href="https://codelabs.developers.google.com/codelabs/responsible-ai/agile-classifiers" rt-link-type="external">novel methodology</a> for building robust safety classifiers with minimal examples.</li><li data-block-key="3n2vq"><b>Debugging:</b> A model <a href="https://codelabs.developers.google.com/codelabs/responsible-ai/lit-gemma" rt-link-type="external">debugging tool</a> helps you investigate Gemma&#39;s behavior and address potential issues.</li><li data-block-key="9t500"><b>Guidance:</b> You can access best practices for model builders based on Google’s experience in developing and deploying large language models.</li></ul><h2 data-block-key="2rvc1">Optimized across frameworks, tools and hardware</h2><p data-block-key="20an5">You can fine-tune Gemma models on your own data to adapt to specific application needs, such as summarization or retrieval-augmented generation (RAG). Gemma supports a wide variety of tools and systems:</p><ul><li data-block-key="f5o6v"><b>Multi-framework tools:</b> Bring your favorite framework, with reference implementations for inference and fine-tuning across multi-framework Keras 3.0, native PyTorch, JAX, and Hugging Face Transformers.</li><li data-block-key="fi8n8"><b>Cross-device compatibility:</b> Gemma models run across popular device types, including laptop, desktop, IoT, mobile and cloud, enabling broadly accessible AI capabilities.</li><li data-block-key="1c9nk"><b>Cutting-edge hardware platforms:</b> We’ve <a href="https://blogs.nvidia.com/blog/google-gemma-llm-rtx-ai-pc" rt-link-type="external">partnered with NVIDIA to optimize Gemma for NVIDIA GPUs</a>, from data center to the cloud to local RTX AI PCs, ensuring industry-leading performance and integration with cutting-edge technology.</li><li data-block-key="e0epi"><b>Optimized for Google Cloud:</b> Vertex AI provides a broad MLOps toolset with a range of tuning options and one-click deployment using built-in inference optimizations. Advanced customization is available with fully-managed Vertex AI tools or with self-managed GKE, including deployment to cost-efficient infrastructure across GPU, TPU, and CPU from either platform.</li></ul><h2 data-block-key="etm40">Free credits for research and development</h2><p data-block-key="6f9uo">Gemma is built for the open community of developers and researchers powering AI innovation. You can start working with Gemma today using free access in Kaggle, a free tier for Colab notebooks, and $300 in credits for first-time Google Cloud users. Researchers can also apply for <a href="https://docs.google.com/forms/d/e/1FAIpQLSe0grG6mRFW6dNF3Rb1h_YvKqUp2GaXiglZBgA2Os5iTLWlcg/viewform" rt-link-type="external">Google Cloud credits</a> of up to $500,000 to accelerate their projects.</p><h2 data-block-key="c1db6">Getting started</h2><p data-block-key="8k2d8">You can explore more about Gemma and access quickstart guides on <a href="http://ai.google.dev/gemma" rt-link-type="external">ai.google.dev/gemma</a>.</p><p data-block-key="aj6c">As we continue to expand the Gemma model family, we look forward to introducing new variants for diverse applications. Stay tuned for events and opportunities in the coming weeks to connect, learn and build with Gemma.</p><p data-block-key="76mu1">We’re excited to see what you create!</p></div>
      </div>
    </div>
  


            
            

            
              




            
          </div>
        
      </div>
    </section>
  </article></div>
  </body>
</html>
