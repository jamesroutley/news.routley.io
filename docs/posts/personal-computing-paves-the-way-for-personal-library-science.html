<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.bramadams.dev/issue-55/">Original</a>
    <h1>Personal computing paves the way for personal library science</h1>
    
    <div id="readability-page-1" class="page"><div>
      <div>
        <p><a href="https://www.bramadams.dev/issue-54/">&lt; Previous Issue</a></p><p>Dear Reader,</p><p>Sometimes, a moment happens not instantaneously, but over many seasons. Looked back on with the blessing of hindsight, there exists a discrete before and after the moment, but for those who lived it, the moment may have had a very long &#34;during&#34; period. Those who live in the &#34;during&#34; find themselves impatient, looking to be on the other side of the event, anxiously waiting for &#34;now&#34; to be &#34;history&#34;. They want to live to see the thing complete. They want it to be done.</p><p>For when &#34;now&#34; becomes history, there is a sense of peace of mind, a complete loop, a chord that resolves into something.</p><blockquote>
<p>History cannot be told while it is happening, therefore, not only because the people involved are too busy or too confused to puzzle it out, but because what is happening can’t be made sense of until its implications have been resolved.</p>
</blockquote>
<p><em>-- Everything Is Obvious: *Once You Know the Answer</em></p><figure><img src="https://www.bramadams.dev/content/images/2024/04/Camille-Corot-Muse.jpeg" alt="" loading="lazy" width="900" height="1200" srcset="https://www.bramadams.dev/content/images/size/w600/2024/04/Camille-Corot-Muse.jpeg 600w, https://www.bramadams.dev/content/images/2024/04/Camille-Corot-Muse.jpeg 900w" sizes="(min-width: 720px) 720px"/></figure><p>The curse of those who live and breathe is the task of trying to make sense of what will be – while it is – before it was.</p><h3 id="the-during">The &#34;During&#34;</h3><p>In <a href="https://www.bramadams.dev/issue-54/">issue #54</a>, I wrote about a moment that is very much in its &#34;during&#34; phase, the formalization of <strong>Personal Library Science</strong>. I can not know how the story of Personal Library Science will be told by those who have the convenience of history to aid them. I can only discuss the landscape as I see it, the work completed by those who came <em>before me</em>, and the work being done now <em>by me</em>.  </p><blockquote>Someday, libraries will be fully mechanized. Then, without leaving one’s office, it will be possible to pick up the phone, dial in a code, and have the actual paper one is looking for almost instantly at hand. Something of the sort has got to happen, or our libraries will become buried in the mass of books and articles now being printed, and searching in the old way will become hopeless.</blockquote><p><em>-- Pieces of the Action (1970)</em></p><p>The &#34;during&#34; is hard work, and very lonely work. There are no promises of success, and indeed, the path is one where you can&#39;t see more than three feet ahead of you and you exist on the cliff&#39;s edge of extinction by any silly mishap. The work  of &#34;during&#34; is exhausting, and it constantly holds you taut and alert, afraid of the shadows that lurk beyond the campfire&#39;s edge.</p><figure><img src="https://www.bramadams.dev/content/images/2024/04/Horace-Vernet-Cliff-of-Fecamp.jpeg" alt="" loading="lazy" width="1200" height="818" srcset="https://www.bramadams.dev/content/images/size/w600/2024/04/Horace-Vernet-Cliff-of-Fecamp.jpeg 600w, https://www.bramadams.dev/content/images/size/w1000/2024/04/Horace-Vernet-Cliff-of-Fecamp.jpeg 1000w, https://www.bramadams.dev/content/images/2024/04/Horace-Vernet-Cliff-of-Fecamp.jpeg 1200w" sizes="(min-width: 720px) 720px"/></figure><p>Fortunately, the work of the edge isn&#39;t without some form of solace. The work becomes manageable, perhaps even virtuous, if we allow ourselves to commiserate with those who struggled and strived in the past to make their dreams a reality. To understand their history is to write our story.</p><p>In this issue, we&#39;ll discuss a topic that is firmly in our past. This history is not only a guide for Personal Library Science, but a key player in it&#39;s very fiber of being. We will be talking about the <strong>Personal</strong> in the <em>portmanteau</em> that is <strong><em>Personal</em></strong> Library Science, which comes from <strong><em>Personal</em></strong> Computing.</p><h3 id="personal-computing">Personal Computing</h3><figure><iframe width="200" height="150" src="https://www.youtube.com/embed/0KDdU0DCbJA?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="" title="1995 Flashback: First-time PC user can’t work computer"></iframe></figure><p>In 1975, the Altair 8800 was released. Widely considered <a href="https://nerdfighteria.info/v/M5BZou6C01w/?ref=bramadams.dev">the first personal computer</a>, the critical advancement of computing was driven by affordability and programmability. Easier, more natural programming languages like BASIC and lower costs for hardware components made computers not massive time sharing leviathans owned only by defense departments for missile ballistic calculations and academia interested in pushing engineering and acquiring grants, but machines people could bring into their own homes.</p><figure><img src="https://www.bramadams.dev/content/images/2024/04/Library-Science-Issue-54.jpg" alt="" loading="lazy" width="477" height="417"/></figure><p>The computer was no longer just a tool for <em>major</em> cost intensive purposes, but <em>minor</em> individualized purposes. Personal computing made computing became less about humanity, and more about humans.</p><blockquote>
<p>As the 1990s opened, the workstation technology of the previous decade was beginning to look distinctly threatened by newer, low-cost and high-performance personal computers based on the Intel 386 chip and its descendants. <mark>For the first time, individual hackers could afford to have home machines comparable in power and storage capacity to the minicomputers of ten years earlier</mark>—Unix engines capable of supporting a full development environment and talking to the Internet.</p>
</blockquote>
<p><em>-- The Cathedral &amp; the Bazaar: Musings on Linux and Open Source by an Accidental Revolutionary</em></p><p>Scientists paved the way for engineers, engineers paved the way for hackers, hackers paved the way for hobbyists, hobbyists paved the way for everyone else. Today we live in a world where every person&#39;s phone is slightly different than their neighbors, and this is a good thing.</p><p><strong>Idiosyncratic technology creates a natural world. </strong>Solve the problems that need solving, then get out the way.</p><blockquote>
<p><mark>Companies establish their DNA very early on. It can make them tremendously successful, but it can also make it hard for them to escape when what served them well in the early days doesn&#39;t serve them so well any more.</mark> I remember being an intern at IBM Research in Yorktown Heights around 1982, seeing the culture still dominated by batch processing. Even when they were doing timesharing, they talked in terms of virtual card readers and virtual card punches. Everything was still 80-column records. With DEC, it was the timesharing mentality that they never escaped. And I suppose with Microsoft it&#39;s an open question whether they&#39;ll be able to move beyond the desktop-PC mentality.</p>
</blockquote>
<p><em>author&#39;s note -- ironically this was posted a few weeks before the writing of this issue: <a href="https://www.wheresyoured.at/the-men-who-killed-google/?ref=bramadams.dev">The man Who Killed Google Search</a></em></p>
<p><em>-- Coders at Work: Reflections on the Craft of Programming (2008)</em></p><p>What does the legacy and lessons of the rise of Personal Computing at the end of the 20th century teach us about the possible path of Personal Library Science?</p><h3 id="companionship">Companionship</h3><figure><iframe width="200" height="113" src="https://www.youtube.com/embed/TqsuhWNesso?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="" title="GPT-3: Your New Lifelong Companion"></iframe></figure><p>In 2020, I made the claim that the advantage of GPT models was not its ability to <em>scale</em>, but its ability to solve <em>local</em> problems. This claim began to come true years later with the release of the GPT Store (<a href="https://www.bramadams.dev/issue-42/"><em>discussed in issue #42</em></a>). Suddenly, individual people – not at the organization level – found themselves being able to create their own solutions to their unique, idiosyncratic problems.</p><blockquote>Idiosyncratic technology creates a natural world.</blockquote><p>By writing detailed instruction sets and using tactics like <a href="https://www.elastic.co/what-is/semantic-search?ref=bramadams.dev">semantic search</a> and <a href="https://docs.haystack.deepset.ai/docs/function-calling?ref=bramadams.dev#:~:text=Function%20calling%20is%20a%20powerful,with%20external%20APIs%20and%20services.">function calling</a>, LLMs <strong>leverage</strong> the effort of the individual into emergent and complex processes. </p><p>This <strong>leverage</strong> is the same leverage that made personal computing so ubiquitous, so quickly. The leverage created a new asset class, data. It gave us (you and me) superpowers of communication, and those of us who could communicate with the programs themselves (programmers) found themselves solving problems that gave them access to near limitless wealth.</p><blockquote>It’s cheaper to reuse existing software components than to write code from scratch, which also makes it possible for entrepreneurs to start software companies with fewer up-front costs. The entire software industry owes its financial success to leveraging this arbitrage.</blockquote><p><em>-- Working in Public: The Making and Maintenance of Open Source Software</em></p><h3 id="personal-library-science-is-leverage-for-ones-library">Personal Library Science Is Leverage For One&#39;s Library</h3><p>Personal Library Science is the <strong>leverage of LLM technology, applied to a personal library.</strong> </p><p>A <em>personal</em> <em>library</em> differs from a <em>impersonal</em> <em>library</em> in the fact that a personal library is an <strong>interpretation</strong> of a source material. These interpretations include: photographs from different photographers at the same event, or favorite scenes from a movie, or favorite passages from books, parts of songs that bring you to tears, etc. Importantly, these interpretations create unique sets that go on to create unique problems which require unique, idiosyncratic solutions. Sound familiar?</p><blockquote>While a painting or a prose description can never be other than a narrowly selective interpretation, a photograph can be treated as a narrowly selective transparency. But despite the presumption of veracity that gives all photographs authority, interest, seductiveness, the work that photographers do is no generic exception to the usually shady commerce between art and truth. Even when photographers are most concerned with mirroring reality, they are still haunted by tacit imperatives of taste and conscience. The immensely gifted members of the Farm Security Administration photographic project of the late 1930s (among them Walker Evans, Dorothea Lange, Ben Shahn, Russell Lee) would take dozens of frontal pictures of one of their sharecropper subjects until satisfied that they had gotten just the right look on film—the precise expression on the subject’s face that supported their own notions about poverty, light, dignity, texture, exploitation, and geometry. In deciding how a picture should look, in preferring one exposure to another, photographers are always imposing standards on their subjects. Although there is a sense in which the camera does indeed capture reality, not just interpret it, photographs are as much an interpretation of the world as paintings and drawings are. Those occasions when the taking of photographs is relatively undiscriminating, promiscuous, or self-effacing do not lessen the didacticism of the whole enterprise. This very passivity—and ubiquity—of the photographic record is photography’s “message,” its aggression.</blockquote><p><em>-- On Photography</em></p><figure><img src="https://www.bramadams.dev/content/images/2024/04/Poor-Jo-by-Earl-of-Carlisle.jpeg" alt="" loading="lazy" width="848" height="1200" srcset="https://www.bramadams.dev/content/images/size/w600/2024/04/Poor-Jo-by-Earl-of-Carlisle.jpeg 600w, https://www.bramadams.dev/content/images/2024/04/Poor-Jo-by-Earl-of-Carlisle.jpeg 848w" sizes="(min-width: 720px) 720px"/></figure><p>In <a href="https://www.bramadams.dev/issue-54/">issue #54</a>, I wrote: </p><blockquote>...personal library science is focused on <strong>your relationship with your information</strong>. How do we <strong>store</strong> information so that it useful at a later date? How do we <strong>transform</strong> our information into new valuable assets in different creative domains? How do we do all of this while being flexible enough for the idiosyncrasies, proclivities, likes and dislikes of <strong>eight billion distinct individuals</strong>? How do we <strong>chronicle</strong> the information diet of a single person as they learn new things, interact with the world at different phases in their life? How do we make sure we can <strong>pass down</strong> our best knowledge to generations below?</blockquote><p>Many of these questions were asked and solved by the existence of personal computing. The existence of software has had a foundational impact on the types of solutions we can create to solve these large, incalculable problems. By solving them over and over in slightly different ways that make sense to an individual the problem eventually dissolves. </p><p>In fact, I&#39;d argue that the history of personal computing teaches us that <strong><em>all top down solutions are less complete – and therefore less useful – than bottom up emergent solutions</em></strong>.</p><p>The issue is that we are now deluged with data, our interpreter antenna is going haywire trying to calculate, to store, to relate, to understand. LLMs have changed the math entirely in this endeavor, particularly thanks to the ability to store, reference, and <strong>transform data that <em>we</em> find to be important, not data that <em>others tell us </em>is important</strong>. </p><p><strong>Solutions such as </strong><a href="https://github.com/bramses/commonplace-bot?ref=bramadams.dev"><strong>Commonplace Bot</strong></a><strong> and </strong><a href="https://github.com/bramses/quoordinates?ref=bramadams.dev"><strong>Quoordinates</strong></a><strong> are proof points of the value of our personal libraries.</strong></p><p>This insight is critical to our work, and the frameworks and technological gains provided by personal computing and LLMs make our task of hoping to one day understand ourselves, to use our personal libraries to secure our intellectual legacies and create our art, a bit more manageable.</p><h3 id="up-next">Up Next</h3><p>Next week, we will dive into the history of the commonplace book. The commonplace book is the foundation for the <em>commonbase</em> (commonplace + database) and is an integral ingredient of Personal Library Science.</p><h3 id="teaser">Teaser</h3><p><em>...Humanity often comes up with certain great ideas concurrently including calculus, natural selection, the use of language, etc. This concurrent creation is known as adjacent possible, and is driven by the available technology and discourse of an era.  The invention of the commonplace book is no different and has lived many different lives as: the zibaldone, the miscellany, the zettelkasten, the...</em></p><figure><img src="https://www.bramadams.dev/content/images/2024/04/July-31-Screen-Shot-from-History-of-Information.png" alt="" loading="lazy" width="618" height="386" srcset="https://www.bramadams.dev/content/images/size/w600/2024/04/July-31-Screen-Shot-from-History-of-Information.png 600w, https://www.bramadams.dev/content/images/2024/04/July-31-Screen-Shot-from-History-of-Information.png 618w"/></figure><h2 id="ye-olde-newsstandweekly-updates">Ye Olde Newsstand - Weekly Updates</h2><figure><a href="https://www.bramadams.dev/week-of-april-26-2024/"><div><p>Week of April 26, 2024</p><p>ft. Chris. P Bacon</p><p><img src="https://www.bramadams.dev/content/images/size/w256h256/2023/01/leda-2.jpeg" alt=""/><span>Bram Adams</span></p></div><p><img src="https://www.bramadams.dev/content/images/2024/04/Ethiopian-Head-Hellenistic.jpeg" alt=""/></p></a><figcaption><p dir="ltr"><span>Canvas Apps, speedboat accidents, the First Hokage was just a dude</span></p></figcaption></figure><p>Thanks for reading, and see you next Sunday!</p><p><em>ars longa, vita brevis,</em></p><p>Bram</p>
      </div>
    </div></div>
  </body>
</html>
