<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.google/technology/developers/gemini-3-pro-vision/">Original</a>
    <h1>Gemini 3 Pro: the frontier of vision AI</h1>
    
    <div id="readability-page-1" class="page"><article>

    
    


<section>
  <div>
    
      <div>
        







<div data-component="uni-breadcrumb">
  
  <nav aria-label="Breadcrumb">
    <span>Breadcrumb</span>
    <ol data-analytics-module="{
      &#34;module_name&#34;: &#34;breadcrumbs&#34;,
      &#34;section_header&#34;: &#34;Gemini 3 Pro: the frontier of vision AI&#34;
    }">
    
      <li>
      
        <a href="https://blog.google/" title="The Keyword" aria-label="The Keyword" data-ga4-analytics-landing-lead="{
  &#34;event&#34;: &#34;landing_page_lead&#34;,
  &#34;link_text&#34;: &#34;The Keyword&#34;
}">
          <svg role="presentation" aria-hidden="true">
  <use xmlns:xlink="http://www.w3.org/1999/xlink" href="/static/blogv2/images/icons.svg?version=pr20251203-1737#uni-icon-homepage"></use>
</svg>

        </a>
      
      </li>
    
      <li>
      
      <svg role="presentation" aria-hidden="true">
  <use xmlns:xlink="http://www.w3.org/1999/xlink" href="/static/blogv2/images/icons.svg?version=pr20251203-1737#uni-icon-chevron-right"></use>
</svg>

        
          <a href="https://blog.google/technology/" data-ga4-analytics-landing-lead="{
  &#34;event&#34;: &#34;landing_page_lead&#34;,
  &#34;link_text&#34;: &#34;Technology&#34;
}">
              Technology
          </a>
        
      
      </li>
    
      <li>
      
      <svg role="presentation" aria-hidden="true">
  <use xmlns:xlink="http://www.w3.org/1999/xlink" href="/static/blogv2/images/icons.svg?version=pr20251203-1737#uni-icon-chevron-right"></use>
</svg>

        
          <a href="https://blog.google/technology/developers/" data-ga4-analytics-landing-lead="{
  &#34;event&#34;: &#34;landing_page_lead&#34;,
  &#34;link_text&#34;: &#34;Developers&#34;
}">
              Developers
          </a>
        
      
      </li>
    
    
    
    </ol>
  </nav>
  
  </div>


      </div>
    
    
  </div>
</section>


    

    
      








<div data-analytics-module="{
    &#34;module_name&#34;: &#34;Hero Menu&#34;,
    &#34;section_header&#34;: &#34;Gemini 3 Pro: the frontier of vision AI&#34;
  }">
  
  <div>
    <div>
      <div>
        <div>
          
            <p>Dec 05, 2025</p>
          
          
            <p><span aria-hidden="true">·</span></p><uni-reading-time></uni-reading-time>
          
        </div>
        




      </div>
      
        <p>
          Gemini 3 Pro delivers state-of-the-art performance across document, spatial, screen and video understanding.
        </p>
      
    </div>
  </div>
  
  <div>
    <div>
      
        


  
  
    
  


      

      
      
    </div>
    
      
        


<div data-component="uni-ai-generated-summary" data-analytics-module="{
    &#34;event&#34;: &#34;module_impression&#34;,
    &#34;module_name&#34;: &#34;ai_summary&#34;,
    &#34;section_header&#34;: &#34;CTA&#34;
  }">
  <div data-component="uni-ai-summary-btn">
    <div>
      
        <div data-summary-id="ai_summary_1">
          <h2>General summary</h2>
          <p>Gemini 3 Pro is Google&#39;s most capable multimodal model that delivers state-of-the-art performance across document, spatial, screen and video understanding. You can use it for complex visual reasoning, document processing, and understanding spatial relationships. Check out the developer documentation or play with the model in Google AI Studio to get started.</p>
          
          <p><small>
            Summaries were generated by Google AI. Generative AI is experimental.
          </small>
        </p></div>
      

      

      </div>
  </div>
</div>

      
    
    
  </div>
</div>

    

    
      










<div>
  <div>
    <figure>
      <div>
        <p><img alt="Image with black background and Gemini 3 Pro logo" data-component="uni-progressive-image" fetchpriority="high" height="150px" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/GeminiAFVAI_Wagtial_RD1-V01.width-200.format-webp.webp" width="360px" data-sizes="(max-width: 1023px) 100vw,(min-width: 1024px and max-width: 1259) 80vw, 1046px" data-srcset="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/GeminiAFVAI_Wagtial_RD1-V01.width-800.format-webp.webp 800w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/GeminiAFVAI_Wagtial_RD1-V01.width-1200.format-webp.webp 1200w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/GeminiAFVAI_Wagtial_RD1-V01.width-1600.format-webp.webp 1600w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/GeminiAFVAI_Wagtial_RD1-V01.width-2200.format-webp.webp 2200w"/>
        </p>
      </div>
      
    </figure>
  </div>
</div>






    

    
    <section>
      <div>
        
          
          
          <div data-reading-time="true" data-component="uni-article-body">

            
  
    



















<div data-component="uni-audio-player-tts" uni-l10n="{
       &#34;stop&#34;: &#34;Click to stop audio&#34;,
       &#34;play&#34;: &#34;Click to play audio&#34;,
       &#34;progress&#34;: &#34;Current audio progress minutes with seconds: [[progress]]&#34;,
       &#34;duration&#34;: &#34;Duration of the audio minutes with seconds: [[duration]]&#34;,
       &#34;settings&#34;: &#34;Click for settings&#34;,
       &#34;timeText&#34;: &#34;[[duration]] minutes&#34;
     }" data-analytics-module="{
      &#34;module_name&#34;: &#34;Audio TTS&#34;,
      &#34;section_header&#34;: &#34;Gemini 3 Pro: the frontier of vision AI&#34;
     }" data-tts-audios="[
      
        {&#34;voice_name&#34;: &#34;Umbriel&#34;,
        &#34;voice_source&#34;: &#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/media/tts_audio_82841_umbriel_2025_12_05_20_01_10.wav&#34;,
        &#34;mimetype&#34;: &#34;audio/x-wav&#34;},
      
        {&#34;voice_name&#34;: &#34;Gacrux&#34;,
        &#34;voice_source&#34;: &#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/media/tts_audio_82841_gacrux_2025_12_05_20_01_18.wav&#34;,
        &#34;mimetype&#34;: &#34;audio/x-wav&#34;}
      ]">
  <p><audio title="Gemini 3 Pro: the frontier of vision AI">
      <source src="self.ttsaudio_set.first.tts_audio.url" type="self.ttsaudio_set.first.tts_audio.file.file.mime_type"/>
      <p>Your browser does not support the audio element.</p>
  </audio></p><div aria-label="">
    <div>
      <div>
        <p><span>
          Listen to article
          <span tabindex="0" role="tooltip" aria-label="This content is generated by Google AI. Generative AI is experimental">
            <p>This content is generated by Google AI. Generative AI is experimental</p>
            <svg>
  <use xmlns:xlink="http://www.w3.org/1999/xlink" href="/static/blogv2/images/icons.svg?version=pr20251203-1737#ttf-info"></use>
</svg>

          </span>
        </span></p><p>[[duration]] minutes</p>
      </div>
      <div>
        <div>
          
          </div>
        <div>
          
          
          
        </div>
      </div>
    </div>
  </div>
</div>

  





            
            
<!--article text-->

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Gemini 3 Pro: the frontier of vision AI&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><p data-block-key="xsagr">Gemini 3 Pro represents a generational leap from simple recognition to true visual and spatial reasoning. It is our most capable multimodal model ever, delivering state-of-the-art performance across document, spatial, screen and video understanding.</p><p data-block-key="b88m8">This model sets new highs on vision benchmarks such as MMMU Pro and Video MMMU for complex visual reasoning, as well as use-case-specific benchmarks across document, spatial, screen and long video understanding.</p></div>
      </div>
    </div>
  

  
    














<uni-image-full-width alignment="full" alt-text="Vision AI benchmarks table" external-image="" or-mp4-video-title="" or-mp4-video-url="" section-header="Gemini 3 Pro: the frontier of vision AI" external-link="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini3Pro-AFVAI_Benchmark_RD5_V02.original.png" custom-class="image-full-width--constrained-width uni-component-spacing">
  
  
    <p><img alt="Vision AI benchmarks table" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini3Pro-AFVAI_Benchmark_RD5_V0.width-100.format-webp_wwXZ4Yy.webp" loading="lazy" data-loading="{
            &#34;mobile&#34;: &#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini3Pro-AFVAI_Benchmark_RD5_V0.width-500.format-webp_25Rvx2V.webp&#34;,
            &#34;desktop&#34;: &#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini3Pro-AFVAI_Benchmark_RD5_V.width-1000.format-webp_BRpOn6h.webp&#34;
          }"/>
    </p>
  
</uni-image-full-width>


  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Gemini 3 Pro: the frontier of vision AI&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><h2 data-block-key="xsagr">1. Document understanding</h2><p data-block-key="bkmek">Real-world documents are messy, unstructured, and difficult to parse — often filled with interleaved images, illegible handwritten text, nested tables, complex mathematical notation and non-linear layouts. Gemini 3 Pro represents a major leap forward in this domain, excelling across the entire document processing pipeline — from highly accurate Optical Character Recognition (OCR) to complex visual reasoning.</p><h3 data-block-key="dh4go">Intelligent perception</h3><p data-block-key="1b3jd">To truly understand a document, a model must accurately detect and recognize text, tables, math formulas, figures and charts regardless of noise or format.</p><p data-block-key="28nt3">A fundamental capability is &#34;derendering&#34; — the ability to reverse-engineer a visual document back into structured code (HTML, LaTeX, Markdown) that would recreate it. As illustrated below, Gemini 3 demonstrates accurate perception across diverse modalities including converting an 18th-century merchant log into a complex table, or transforming a raw image with mathematical annotation into precise LaTeX code.</p></div>
      </div>
    </div>
  

  
    

















<uni-image-carousel section-header="Gemini 3 Pro: the frontier of vision AI" images="[
    
      {
        
          
          
          &#34;src&#34;: [&#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini3Pro-AFVAI_DU1_RD1-V01.max-1600x1600.format-webp.webp&#34;,&#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini3Pro-AFVAI_DU1_RD1-V01.max-2161x2161.format-webp.webp&#34;],
        
        &#34;alt&#34;: &#34;Input image of an old merchants handbook ledger along with an output image that clearly reconstructed transcription&#34;,
        &#34;isVideo&#34;: false,
        &#34;videoTitle&#34;: &#34;&#34;
      },
    
      {
        
          
          
          &#34;src&#34;: [&#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini3Pro-AFVAI_DU2_RD1-V01.max-1600x1600.format-webp.webp&#34;,&#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini3Pro-AFVAI_DU2_RD1-V01.max-2161x2161.format-webp.webp&#34;],
        
        &#34;alt&#34;: &#34;Input image of a scan of an equation alongside an output of the model solving the equation&#34;,
        &#34;isVideo&#34;: false,
        &#34;videoTitle&#34;: &#34;&#34;
      },
    
      {
        
          
          
          &#34;src&#34;: [&#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini3Pro-AFVAI_DU3_RD1-V01.max-1600x1600.format-webp.webp&#34;,&#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini3Pro-AFVAI_DU3_RD1-V01.max-2161x2161.format-webp.webp&#34;],
        
        &#34;alt&#34;: &#34;Image showing input of a scanned diagram into a an interactive chart&#34;,
        &#34;isVideo&#34;: false,
        &#34;videoTitle&#34;: &#34;&#34;
      }
    
  ]">
  
    
      <div slot="caption-slot-0">
        <p data-block-key="emnqt">Example 1: Handwritten Complex Table from 18th century Albany Merchant’s Handbook</p>
      </div>
    
  
    
      <div slot="caption-slot-1">
        <p data-block-key="ngppg">Example 2: Reconstructing equations from an image</p>
      </div>
    
  
    
      <div slot="caption-slot-2">
        <p data-block-key="ngppg">Example 3: Reconstructing Florence Nightingale&#39;s original Polar Area Diagram into an interactive chart (with a toggle!)</p>
      </div>
    
  
</uni-image-carousel>

  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Gemini 3 Pro: the frontier of vision AI&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><h3 data-block-key="xsagr">Sophisticated reasoning</h3><p data-block-key="6cne6">Users can rely on Gemini 3 to perform complex, multi-step reasoning across tables and charts — even in long reports. In fact, the model notably outperforms the human baseline on the CharXiv Reasoning benchmark (80.5%).</p><p data-block-key="e51o0">To illustrate this, imagine a user analyzing the 62-page U.S. Census Bureau &#34;<a href="https://www.census.gov/content/dam/Census/library/publications/2023/demo/p60-279.pdf">Income in the United States: 2022</a>&#34; report with the following prompt: “Compare the 2021–2022 percent change in the Gini index for &#34;Money Income&#34; versus &#34;Post-Tax Income&#34;, and what caused the divergence in the post-tax measure, and in terms of &#34;Money Income&#34;, does it show the lowest quintile&#39;s share rising or falling?”</p><p data-block-key="4586l">Swipe through the images below to see the model&#39;s step-by-step reasoning.</p></div>
      </div>
    </div>
  

  
    

















<uni-image-carousel section-header="Gemini 3 Pro: the frontier of vision AI" images="[
    
      {
        
          
          
          &#34;src&#34;: [&#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini3Pro-AFVAI_SR1_RD3-V01.max-1600x1600.format-webp.webp&#34;,&#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini3Pro-AFVAI_SR1_RD3-V01.max-2161x2161.format-webp.webp&#34;],
        
        &#34;alt&#34;: &#34;Pdf image highlighting the numbers \u002D1.2 and 3.2&#34;,
        &#34;isVideo&#34;: false,
        &#34;videoTitle&#34;: &#34;&#34;
      },
    
      {
        
          
          
          &#34;src&#34;: [&#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini3Pro-AFVAI_SR2_RD4-V01.max-1600x1600.format-webp.webp&#34;,&#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini3Pro-AFVAI_SR2_RD4-V01.max-2166x2166.format-webp.webp&#34;],
        
        &#34;alt&#34;: &#34;Pdf image highlighting the ARPA policies lapsing in 2021 and the stimulus payments ending&#34;,
        &#34;isVideo&#34;: false,
        &#34;videoTitle&#34;: &#34;&#34;
      },
    
      {
        
          
          
          &#34;src&#34;: [&#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini3Pro-AFVAI_SR3_RD2-V01.max-1600x1600.format-webp.webp&#34;,&#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini3Pro-AFVAI_SR3_RD2-V01.max-2161x2161.format-webp.webp&#34;],
        
        &#34;alt&#34;: &#34;Pdf highlighting the numbers 2.9 and 3.0 for 2021 and 2022 respectively&#34;,
        &#34;isVideo&#34;: false,
        &#34;videoTitle&#34;: &#34;&#34;
      },
    
      {
        
          
          
          &#34;src&#34;: [&#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini3Pro-AFVAI_SR4_RD2-V01.max-1600x1600.format-webp.webp&#34;,&#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini3Pro-AFVAI_SR4_RD2-V01.max-2161x2161.format-webp.webp&#34;],
        
        &#34;alt&#34;: &#34;Final model response text&#34;,
        &#34;isVideo&#34;: false,
        &#34;videoTitle&#34;: &#34;&#34;
      }
    
  ]">
  
    
      <div slot="caption-slot-0">
        <p data-block-key="692km">Visual Extraction: To answer the Gini Index Comparison question, Gemini located and cross-referenced this info in Figure 3 about “Money Income decreased by 1.2 percent” and in Table B-3 about “Post-Tax Income increased by 3.2 percent”</p>
      </div>
    
  
    
      <div slot="caption-slot-1">
        <p data-block-key="97gzw">Causal Logic: Crucially, Gemini 3 does not stop at the numbers; it correlates this gap with the text’s policy analysis, correctly identifying Lapse of ARPA Policies and the end of Stimulus Payments are the main causes.</p>
      </div>
    
  
    
      <div slot="caption-slot-2">
        <p data-block-key="97gzw">Numerical Comparison: To compare the lowest quantile’s share rising or falling, Gemini3 looked at table A-3, and compared the number of 2.9 and 3.0, and concluded that “the share of aggregate household income held by the lowest quintile was rising.”</p>
      </div>
    
  
    
      <div slot="caption-slot-3">
        <p data-block-key="97gzw">Final Model Answer</p>
      </div>
    
  
</uni-image-carousel>

  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Gemini 3 Pro: the frontier of vision AI&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><h2 data-block-key="xsagr">2. Spatial understanding</h2><p data-block-key="1qcle">Gemini 3 Pro is our strongest spatial understanding model so far. Combined with its strong reasoning, this enables the model to make sense of the physical world.</p><ul><li data-block-key="f05rj"><b>Pointing capability:</b> Gemini 3 has the ability to point at specific locations in images by outputting pixel-precise coordinates. Sequences of 2D points can be strung together to perform complex tasks, such as estimating human poses or reflecting trajectories over time.</li><li data-block-key="9gqvq"><b>Open vocabulary references:</b> Gemini 3 identifies objects and their intent using an open vocabulary. The most direct application is robotics: the user can ask a robot to generate spatially grounded plans like, “Given this messy table, come up with a plan on how to sort the trash.” This also extends to AR/XR devices, where the user can request an AI assistant to “Point to the screw according to the user manual.”</li></ul></div>
      </div>
    </div>
  

  
    

















<uni-image-carousel section-header="Gemini 3 Pro: the frontier of vision AI" images="[
    
      {
        
          
          
          &#34;src&#34;: [&#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini3Pro-AFVAI_SU1_RD2-V01.max-1052x1052.format-webp.webp&#34;,&#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini3Pro-AFVAI_SU1_RD2-V01.max-1052x1505.format-webp.webp&#34;],
        
        &#34;alt&#34;: &#34;Image showing a cluttered box, a bottle, a screwdriver, a pouch and a measuring tape on a table. A line connects a clear path between the measuring tape and the box created by Gemini 3 Pro&#34;,
        &#34;isVideo&#34;: false,
        &#34;videoTitle&#34;: &#34;&#34;
      },
    
      {
        
          
          
          &#34;src&#34;: [&#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini3Pro-AFVAI_SU2_RD2-V01.max-1086x1086.format-webp.webp&#34;,&#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini3Pro-AFVAI_SU2_RD2-V01.max-1086x1505.format-webp.webp&#34;],
        
        &#34;alt&#34;: &#34;A picture of a cluttered kitchen counter with open cabinets. Three lines show the trajectory between the mug, the glass and the bowl and specific spots in the cabinet where they should go, created by Gemini 3 Pro&#34;,
        &#34;isVideo&#34;: false,
        &#34;videoTitle&#34;: &#34;&#34;
      },
    
      {
        
          
          
          &#34;src&#34;: [&#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini3Pro-AFVAI_SU3_RD2-V01.max-1505x1505.format-webp.webp&#34;,&#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini3Pro-AFVAI_SU3_RD2-V01.max-1505x1505.format-webp.webp&#34;],
        
        &#34;alt&#34;: &#34;Picture of a circuit board with each distinct item labeled by Gemini 3 Pro&#34;,
        &#34;isVideo&#34;: false,
        &#34;videoTitle&#34;: &#34;&#34;
      }
    
  ]">
  
    
  
    
  
    
  
</uni-image-carousel>

  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Gemini 3 Pro: the frontier of vision AI&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><h2 data-block-key="xsagr">3. Screen understanding</h2><p data-block-key="4p5p9">Gemini 3.0 Pro’s spatial understanding really shines through its screen understanding of desktop and mobile OS screens. This reliability helps make computer use agents robust enough to automate repetitive tasks. UI understanding capabilities can also enable tasks like QA testing, user onboarding and UX analytics. The following computer use demo shows the model perceiving and clicking with high precision.</p></div>
      </div>
    </div>
  

  
    
  
    




  <uni-youtube-player-article index="10" thumbnail-alt="Video of the model interacting with an excel sheet, precisely clicking, using the cursor and typing." subtitle="Task: Summarize the total revenue for each promotion type in a new sheet (Sheet2) with the promotion names as the column headers using the Pivot Table feature." video-id="McUaA_C9Etw" video-type="video">
  </uni-youtube-player-article>











  


  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Gemini 3 Pro: the frontier of vision AI&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><h2 data-block-key="xsagr">4. Video understanding</h2><p data-block-key="9h86s">Gemini 3 Pro takes a massive leap forward in how AI understands video, the most complex data format we interact with. It is dense, dynamic, multimodal and rich with context.</p><ol><li data-block-key="aehdr"><b>High frame rate understanding:</b> We have optimized the model to be much stronger at understanding fast-paced actions when sampling at &gt;1 frames-per-second. Gemini 3 Pro can capture rapid details — vital for tasks like analyzing golf swing mechanics.</li></ol></div>
      </div>
    </div>
  

  
    














<uni-image-full-width alignment="full" alt-text="Video showing four people pickleball on the left with the model prompt and output on the right" external-image="" or-mp4-video-title="Video understanding pickleball" or-mp4-video-url="https://storage.googleapis.com/gweb-uniblog-publish-prod/original_videos/High_FPS__Visual_Understanding_RD4-V01.mp4" section-header="Gemini 3 Pro: the frontier of vision AI" custom-class="image-full-width--constrained-width uni-component-spacing">
  
    <div slot="caption-slot">
      <p data-block-key="s3g1z">By processing video at 10 FPS—10x the default speed—Gemini 3 Pro catches every swing and shift in weight, unlocking deep insights into player mechanics.</p>
    </div>
  
  
</uni-image-full-width>


  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Gemini 3 Pro: the frontier of vision AI&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><p data-block-key="xsagr"><b>2. Video reasoning with “thinking” mode:</b> We upgraded &#34;thinking&#34; mode to go beyond object recognition toward true video reasoning. The model can now better trace complex cause-and-effect relationships over time. Instead of just identifying <i>what</i> is happening, it understands <i>why</i> it is happening.</p><p data-block-key="e1c1n"><b>3. Turning long videos into action:</b> Gemini 3 Pro bridges the gap between video and code. It can extract knowledge from long-form content and immediately translate it into functioning apps or structured code.</p></div>
      </div>
    </div>
  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Gemini 3 Pro: the frontier of vision AI&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><h2 data-block-key="xsagr">5. Real-world applications</h2><p data-block-key="aqpn">Here are a few ways we think various fields will benefit from Gemini 3’s capabilities.</p><h3 data-block-key="fb7rp">Education</h3><p data-block-key="7aijr">Gemini 3.0 Pro’s enhanced vision capabilities drive significant gains in the education field, particularly for diagram-heavy questions central to math and science. It successfully tackles the full spectrum of multimodal reasoning problems found from middle school through post-secondary curriculums. This includes visual reasoning puzzles (like <a href="https://matharena.ai/?comp=overall--visual_mathematics">Math Kangaroo</a>) and complex chemistry and physics diagrams.</p><p data-block-key="cl9j">Gemini 3’s visual intelligence also powers the generative capabilities of <a href="https://blog.google/technology/ai/nano-banana-pro/">Nano Banana Pro</a>. By combining advanced reasoning with precise generation, the model, for example, can help users identify exactly where they went wrong in a homework problem.</p></div>
      </div>
    </div>
  

  
    














<uni-image-full-width alignment="full" alt-text="Image showing input of a handwritten equation on the left and the model&#39;s correction annotated on top of the handwritten equation" external-image="" or-mp4-video-title="" or-mp4-video-url="" section-header="Gemini 3 Pro: the frontier of vision AI" external-link="https://storage.googleapis.com/gweb-uniblog-publish-prod/documents/Gemini3Pro-AFVAI_NB_RD1-V01.png" custom-class="image-full-width--constrained-width uni-component-spacing">
  
    <div slot="caption-slot">
      <p data-block-key="s3g1z">Prompt: “Here is a photo of my homework attempt. Please check my steps and tell me where I went wrong. Instead of explaining in text, show me visually on my image.” (Note: Student work is shown in blue; model corrections are shown in red). [<a href="https://aistudio.google.com/app/prompts?state=%7B%22ids%22:%5B%2211Grik6b3t2VkSxKPLLxOOmnXWbnnAm3x%22%5D,%22action%22:%22open%22,%22userId%22:%22116272852503442258852%22,%22resourceKeys%22:%7B%7D%7D&amp;usp=sharing,%20https://drive.google.com/file/d/1Ge2wuz_QrMVAcghl_gdOeMP533Z27X5Z/view?usp=sharing">See prompt in Google AI Studio</a>]</p>
    </div>
  
  
    <p><img alt="Image showing input of a handwritten equation on the left and the model&#39;s correction annotated on top of the handwritten equation" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini3Pro-AFVAI_NB_RD1-V01.width-100.format-webp.webp" loading="lazy" data-loading="{
            &#34;mobile&#34;: &#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini3Pro-AFVAI_NB_RD1-V01.width-500.format-webp.webp&#34;,
            &#34;desktop&#34;: &#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini3Pro-AFVAI_NB_RD1-V01.width-1000.format-webp.webp&#34;
          }"/>
    </p>
  
</uni-image-full-width>


  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Gemini 3 Pro: the frontier of vision AI&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><h3 data-block-key="xsagr">Medical and biomedical imaging</h3><p data-block-key="2sjeg">Gemini 3 Pro


<a data-ga4-analytics-superscript-click="" data-target="inline text" href="#footnote-1" id="footnote-source-1" aria-label="Jump to link reference 1">
  <sup>1</sup>
</a>
 stands as our most capable general model for medical and biomedical imagery understanding, achieving state-of-the-art performance across major public benchmarks in MedXpertQA-MM (a difficult expert-level medical reasoning exam), VQA-RAD (radiology imagery Q&amp;A) and MicroVQA (multimodal reasoning benchmarks for microscopy based biological research).</p></div>
      </div>
    </div>
  

  
    














<uni-image-full-width alignment="full" alt-text="Image showing a stained kidney cortex image on the left and the model prompt and response on the right" external-image="" or-mp4-video-title="" or-mp4-video-url="" section-header="Gemini 3 Pro: the frontier of vision AI" external-link="https://storage.googleapis.com/gweb-uniblog-publish-prod/documents/Gemini3Pro-AFVAI_Medical2_RD1-V01.png" custom-class="image-full-width--constrained-width uni-component-spacing">
  
    <div slot="caption-slot">
      <p data-block-key="nw6mp">Input image from <a href="https://huggingface.co/datasets/jmhb/microvqa">MicroVQA</a> - a benchmark for microscopy-based biological research</p>
    </div>
  
  
    <p><img alt="Image showing a stained kidney cortex image on the left and the model prompt and response on the right" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini3Pro-AFVAI_Medical2_RD1-V01.width-100.format-webp.webp" loading="lazy" data-loading="{
            &#34;mobile&#34;: &#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini3Pro-AFVAI_Medical2_RD1-V01.width-500.format-webp.webp&#34;,
            &#34;desktop&#34;: &#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/Gemini3Pro-AFVAI_Medical2_RD1-V0.width-1000.format-webp.webp&#34;
          }"/>
    </p>
  
</uni-image-full-width>


  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Gemini 3 Pro: the frontier of vision AI&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><h3 data-block-key="80m2f">Law and finance</h3><p data-block-key="5oumv">Gemini 3 Pro’s enhanced document understanding helps professionals in finance and law tackle highly complex workflows. Finance platforms can seamlessly analyze dense reports filled with charts and tables, while legal platforms benefit from the model&#39;s sophisticated document reasoning.</p></div>
      </div>
    </div>
  

  
    




<uni-pull-quote content-style="block" quote="“We’re impressed by Gemini 3&#39;s improvements in advanced legal reasoning, especially its ability to understand and edit contracts with complex redlines. This has been particularly valuable for our in-house customers due to the high volume and variability of the legal contracts they handle.”" section-header="Gemini 3 Pro: the frontier of vision AI" author-name="Harvey.ai">
</uni-pull-quote>


  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Gemini 3 Pro: the frontier of vision AI&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><h2 data-block-key="80m2f">6. Media resolution control</h2><p data-block-key="9kjcp">Gemini 3 Pro improves the way it processes visual inputs by preserving the native aspect ratio of images. This drives significant quality improvements across the board.</p><ul><li data-block-key="6vo46"><b>High resolution:</b> Maximizes fidelity for tasks requiring fine detail, such as dense OCR or complex document understanding.</li><li data-block-key="14obh"><b>Low resolution:</b> Optimizes for cost and latency on simpler tasks, such as general scene recognition or long-context tasks.</li></ul><p data-block-key="5knu2">For specific recommendations, refer to our <a href="https://ai.google.dev/gemini-api/docs/gemini-3?thinking=high">Gemini 3.0 Documentation Guide</a>.</p><h2 data-block-key="515ei">Build with Gemini 3 Pro</h2><p data-block-key="76n2">We are excited to see what you build with these new capabilities. To get started, check out our <a href="https://ai.google.dev/gemini-api/docs/gemini-3?thinking=high">developer documentation</a> or play with the model in <a href="https://aistudio.google.com/prompts/new_chat?model=gemini-3-pro-preview&amp;e=0">Google AI Studio</a> today.</p></div>
      </div>
    </div>
  


            
            

            
              


<div data-analytics-module="{
    &#34;module_name&#34;: &#34;Article Tags&#34;,
    &#34;section_header&#34;: &#34;Gemini 3 Pro: the frontier of vision AI&#34;
  }">
  <p><span>POSTED IN:</span>
  </p>
  <nav>
    <ul>
    
      <li>
        
        
        


  <a href=" https://blog.google/technology/developers/ " data-ga4-analytics-landing-lead="{
  &#34;event&#34;: &#34;landing_page_lead&#34;,
  &#34;link_text&#34;: &#34;Developers&#34;
}">


Developers


  </a>


      </li>
    

    
      <li>
        
        
        


  <a href=" https://blog.google/technology/ai/ " data-ga4-analytics-landing-lead="{
  &#34;event&#34;: &#34;landing_page_lead&#34;,
  &#34;link_text&#34;: &#34;Developers&#34;
}">


AI


  </a>


      </li>
    
      <li>
        
        
        


  <a href=" https://blog.google/products/gemini/ " data-ga4-analytics-landing-lead="{
  &#34;event&#34;: &#34;landing_page_lead&#34;,
  &#34;link_text&#34;: &#34;Developers&#34;
}">


Gemini Models


  </a>


      </li>
    
    </ul>
  </nav>
</div>

            
          </div>
        
      </div>
    </section>
  </article></div>
  </body>
</html>
