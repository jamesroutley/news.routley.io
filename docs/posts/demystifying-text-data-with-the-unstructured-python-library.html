<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://saeedesmaili.com/demystifying-text-data-with-the-unstructured-python-library/">Original</a>
    <h1>Demystifying Text Data with the Unstructured Python Library</h1>
    
    <div id="readability-page-1" class="page"><div><article itemscope="" itemtype="http://schema.org/Article"><header><small>2023-07-05<!-- --> • 6 min read</small></header><section itemprop="articleBody"><p>In the world of data, textual data stands out as being particularly complex. It doesn’t fall into neat rows and columns like numerical data does. As a side project, I’m in the process of developing my own personal AI assistant. The objective is to use the data within my notes and documents to answer my questions. The important benefit is all data processing will occure locally on my computer, ensuring that no documents are uploaded to the cloud, and my documents will remain private.</p>
<p>To handle such unstructured data, I’ve found the <a href="https://unstructured-io.github.io/unstructured/index.html" target="_blank" rel="nofollow noopener noreferrer"><code>unstructured</code></a> Python library to be extremely useful. It’s a flexible tool that works with various document formats, including Markdown, , XML, and HTML documents.</p>
<h2>Starting with <code>unstructured</code></h2>
<p>You can easily install the library by:</p>

<h2>Loading and partitioning a document</h2>
<p>The first thing you’ll want to do with your document is split it up into smaller parts or sections. This process, called partitioning, makes it easier to categorize and extract text.</p>
<p>Here’s how you do it:</p>
<div data-language="python"><pre><code><span>from</span> unstructured<span>.</span>partition<span>.</span>auto <span>import</span> partition

elements <span>=</span> partition<span>(</span>filename<span>=</span><span>&#34;example-docs/note.md&#34;</span><span>)</span></code></pre></div>
<p>example-docs/note.md:</p>
<div data-language="text"><pre><code>## My test title

And here is a sample text.</code></pre></div>
<p>When we partition a document, the output is a list of document <code>Element</code> objects. These element objects represent different components of the source document. The <code>unstructured</code> library supports various element types including <code>Title</code>, <code>NarrativeText</code>, and <code>ListItem</code>. To access the element type you can use the <code>category</code> method:</p>
<div data-language="python"><pre><code><span>for</span> element <span>in</span> elements<span>:</span>
    <span>print</span><span>(</span><span><span>f&#34;</span><span><span>{</span>element<span>.</span>category<span>}</span></span><span>:&#34;</span></span><span>)</span>
    <span>print</span><span>(</span>element<span>)</span>
    <span>print</span><span>(</span><span>&#34;\n&#34;</span><span>)</span></code></pre></div>
<p>Output:</p>
<div data-language="text"><pre><code>Title
My test title


NarrativeText
And here is a sample text.</code></pre></div>
<p>The list of document elements can be converted to a list of dictionaries using the <code>convert_to_dict</code> function:</p>
<div data-language="python"><pre><code><span>from</span> unstructured<span>.</span>staging<span>.</span>base <span>import</span> convert_to_dict

dict_data <span>=</span> convert_to_dict<span>(</span>elements<span>)</span></code></pre></div>
<p>Output:</p>
<div data-language="text"><pre><code>[{&#39;type&#39;: &#39;Title&#39;,
  &#39;coordinates&#39;: None,
  &#39;coordinate_system&#39;: None,
  &#39;layout_width&#39;: None,
  &#39;layout_height&#39;: None,
  &#39;element_id&#39;: &#39;a3114599252de55bea36c288aa9aa199&#39;,
  &#39;metadata&#39;: {&#39;filename&#39;: &#39;sample-doc.md&#39;,
   &#39;filetype&#39;: &#39;text/markdown&#39;,
   &#39;page_number&#39;: 1},
  &#39;text&#39;: &#39;My test title&#39;},
 {&#39;type&#39;: &#39;NarrativeText&#39;,
  &#39;coordinates&#39;: None,
  &#39;coordinate_system&#39;: None,
  &#39;layout_width&#39;: None,
  &#39;layout_height&#39;: None,
  &#39;element_id&#39;: &#39;6e78562ede477550604528df644630e8&#39;,
  &#39;metadata&#39;: {&#39;filename&#39;: &#39;sample-doc.md&#39;,
   &#39;filetype&#39;: &#39;text/markdown&#39;,
   &#39;page_number&#39;: 1},
  &#39;text&#39;: &#39;And here is a sample text.&#39;}]</code></pre></div>
<p>But since I want to store the chunks of texts in a database and do some exploratory analysis with the data, I used <code>convert_to_dataframe</code> function to convert the text elements into pandas dataframe:</p>
<div data-language="python"><pre><code><span>from</span> unstructured<span>.</span>staging<span>.</span>base <span>import</span> convert_to_dataframe

df <span>=</span> convert_to_dataframe<span>(</span>elements<span>)</span></code></pre></div>
<p><span>
      <a href="https://saeedesmaili.com/static/288f80e1f01dfe387bb66bb4f2414d0c/1d7f7/unstructured-dataframe.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="unstructured to pandas dataframe" title="unstructured to pandas dataframe" src="https://saeedesmaili.com/static/288f80e1f01dfe387bb66bb4f2414d0c/f058b/unstructured-dataframe.png" srcset="/static/288f80e1f01dfe387bb66bb4f2414d0c/c26ae/unstructured-dataframe.png 158w,
/static/288f80e1f01dfe387bb66bb4f2414d0c/6bdcf/unstructured-dataframe.png 315w,
/static/288f80e1f01dfe387bb66bb4f2414d0c/f058b/unstructured-dataframe.png 630w,
/static/288f80e1f01dfe387bb66bb4f2414d0c/40601/unstructured-dataframe.png 945w,
/static/288f80e1f01dfe387bb66bb4f2414d0c/78612/unstructured-dataframe.png 1260w,
/static/288f80e1f01dfe387bb66bb4f2414d0c/1d7f7/unstructured-dataframe.png 2038w" sizes="(max-width: 630px) 100vw, 630px" loading="lazy"/>
  </a>
    </span></p>
<h2>Gettng the metadata</h2>
<p>One neat feature of the <code>unstructured</code> library is how it keeps track of various metadata about the elements it extracts from documents. For example, you might want to know which elements come from which page number. You can extract the metadata for a given document element like so:</p>
<div data-language="python"><pre><code>doc_metadata <span>=</span> elements<span>[</span><span>0</span><span>]</span><span>.</span>metadata<span>.</span>to_dict<span>(</span><span>)</span>
<span>print</span><span>(</span>doc_metadata<span>)</span></code></pre></div>
<p>Output:</p>
<div data-language="text"><pre><code>{&#39;filename&#39;: &#39;note.md&#39;, &#39;filetype&#39;: &#39;text/markdown&#39;, &#39;page_number&#39;: 1}</code></pre></div>
<p>All document types return the following metadata fields when the information is available from the source file: <code>filename</code>, <code>file_directory</code>, <code>date</code>, <code>filetype</code>, and<code>page_number</code>.</p>
<h2>Preparing for Transformers</h2>
<p>When you’re ready to feed your text into a transformer model for further processing, you can use the <code>stage_for_transformers</code> function. This function prepares your text elements by splitting them into chunks that fit into the model’s attention window.</p>
<p>In the following example, I’m using a library called <code>SentenceTransformers</code> (I’ve written more about using this library in <a href="https://saeedesmaili.com/how-to-use-sentencetransformers-to-generate-text-embeddings-locally/" target="_blank" rel="nofollow noopener noreferrer">my previous blog post</a>):</p>
<div data-language="python"><pre><code><span>from</span> sentence_transformers <span>import</span> SentenceTransformer
<span>from</span> unstructured<span>.</span>staging<span>.</span>huggingface <span>import</span> stage_for_transformers

model <span>=</span> SentenceTransformer<span>(</span><span>&#34;all-MiniLM-L6-v2&#34;</span><span>)</span>
chunked_elements <span>=</span> stage_for_transformers<span>(</span>elements<span>,</span> model<span>.</span>tokenizer<span>)</span></code></pre></div>
<p>And now I can load all the notes in a specific directory, so I can convert them to embedding vectors later:</p>
<div data-language="python"><pre><code>all_elements <span>=</span> <span>[</span><span>]</span>
root_dir <span>=</span> <span>&#39;/corpus&#39;</span>

<span>for</span> directory<span>,</span> subdirectories<span>,</span> files <span>in</span> os<span>.</span>walk<span>(</span>root_dir<span>)</span><span>:</span>
    <span>for</span> <span>file</span> <span>in</span> files<span>:</span>
        full_path <span>=</span> os<span>.</span>path<span>.</span>join<span>(</span>directory<span>,</span> <span>file</span><span>)</span>
        all_elements <span>+=</span> partition<span>(</span>filename<span>=</span>full_path<span>)</span></code></pre></div>
<h2>Limitations of <code>unstructured</code></h2>
<p>This library has some issues and limitations as well.</p>
<ul>
<li>When loading and parsing <code>docx</code> files, it can’t properly recognize bullet points as <code>ListItem</code> and most of the times labels them as <code>NarrativeText</code> or <code>Title</code>. This makes the <code>Title</code> recognition unreliable as well, since when you look into the output, you can’t tell for sure if each <code>Title</code> is actually a title or a list item labeled incorrectly as a <code>Title</code>. (<a href="https://github.com/Unstructured-IO/unstructured/issues/768" target="_blank" rel="nofollow noopener noreferrer">issue on github</a>)</li>
<li>When working with large documents, there isn’t any way to know what are the parents of each paragraph or title. This could be a very useful feature to have, specially when feeding back the data to an LLM. (<a href="https://github.com/Unstructured-IO/unstructured/issues/889" target="_blank" rel="nofollow noopener noreferrer">issue on github</a>)</li>
</ul>
<h2>Alternatives</h2>
<p>After playing with <code>unstructured</code> I tried to see if there are better alternatives for reading documents with python. Although I will need to load documents with various formats, I narrowed down my search to first find alternatives for reading <code>docx</code> files first (as this it the format you get when downloading a large folder of documents from Google Drive). Here are what I found:</p>
<h3><code>python-docx</code></h3>
<ul>
<li>It seems powerful, but it’s complicated to work with.</li>
<li>I tried loading and parsing a few <code>docx</code> files. The biggest issue I experienced was with loading any text that includes hyperlinks. For some unknown reason, the texts of hyperlinks are returned empty in the final output. This makes it unusable for my purpose, since the link texts provide valuable information in the text.</li>
<li>Pro: It is able to provide the heading level info for titles (as <code>Heading 1</code>, <code>Heading 2</code>, etc).</li>
</ul>
<h3><code>docx2txt</code></h3>
<ul>
<li>It uses <code>python-docx</code> under the hood.</li>
<li>Only returns a giant full text string of the loaded document. This would require me to split my documents to meaningful chunks, which is not a trivial task to do.</li>
<li>Pro: It doesn’t have any problems with hyperlinks and the output text is readable and useful.</li>
<li>Pro: It is also very easy to use.</li>
</ul>
<h3><code>simplify_docx</code></h3>
<ul>
<li>It works on top of <code>python-docx</code>.</li>
<li>This library basically converts the complicated output of <code>python-docx</code> to a more easy to use json output.</li>
<li>It also have the same issue with hyperlinks and returns empty texts when there is a link in the paragraph.</li>
</ul>
<p>So I will continue using <code>unstructured</code> for now. It’s worth mentioning that, yes, this could be accomplished more easily using <a href="https://python.langchain.com/docs/get_started/introduction.html" target="_blank" rel="nofollow noopener noreferrer">LangChain</a> or other similar tools. However, part of my motivation in building this personal AI assistant is the learning journey. By using <code>unstructured</code> to load documents and other similar tools for embeddings and so on, I’m gaining a deeper understanding of the underlying processes, rather than using a one-stop-shop solution like <code>LangChain</code>.</p>
<p>I’ll be sharing more about the progress I’m making in building this personal AI assistant in future posts, so stay tuned.</p></section><hr/></article></div></div>
  </body>
</html>
