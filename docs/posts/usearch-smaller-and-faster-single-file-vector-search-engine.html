<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://unum-cloud.github.io/usearch/">Original</a>
    <h1>USearch: Smaller and faster single-file vector search engine</h1>
    
    <div id="readability-page-1" class="page"><article role="main">
          <section id="overview">


<h3>
Smaller &amp; Faster Single-File</h3>
<span><br/></span>
<p>
<a href="https://discord.gg/A6wxt6dS9j"><img height="25" src="https://github.com/unum-cloud/.github/raw/main/assets/discord.svg" alt="Discord"/></a>
   
<a href="https://www.linkedin.com/company/unum-cloud/"><img height="25" src="https://github.com/unum-cloud/.github/raw/main/assets/linkedin.svg" alt="LinkedIn"/></a>
   
<a href="https://twitter.com/unum_cloud"><img height="25" src="https://github.com/unum-cloud/.github/raw/main/assets/twitter.svg" alt="Twitter"/></a>
   
<a href="https://unum.cloud/post"><img height="25" src="https://github.com/unum-cloud/.github/raw/main/assets/blog.svg" alt="Blog"/></a>
   
<a href="https://github.com/unum-cloud/usearch"><img height="25" src="https://github.com/unum-cloud/.github/raw/main/assets/github.svg" alt="GitHub"/></a>
</p><p>
Euclidean • Angular • Jaccard • Hamming • Haversine • User-Defined Metrics
</p><hr/>
<ul>
<li><p>✅ Benchmark-topping performance.</p></li>
<li><p>✅ Simple and extensible <a href="https://github.com/unum-cloud/usearch/blob/main/include/usearch/index.hpp">single C++11 header</a> implementation.</p></li>
<li><p>✅ SIMD-optimized and <a href="#user-defined-functions">user-defined metrics</a> with JIT-compilation.</p></li>
<li><p>✅ Variable dimensionality vectors for unique applications, including search over compressed data.</p></li>
<li><p>✅ Bitwise Tanimoto and Sorensen coefficients for <a href="#usearch--rdkit--molecular-search">Genomics and Chemistry applications</a>.</p></li>
<li><p>✅ Hardware-agmostic <code><span>f16</span></code> &amp; <code><span>f8</span></code> - <a href="#memory-efficiency-downcasting-and-quantization">half-precision &amp; quarter-precision support</a>.</p></li>
<li><p>✅ <a href="#disk-based-indexes">View large indexes from disk</a> without loading into RAM.</p></li>
<li><p>✅ Space-efficient point-clouds with <code><span>uint40_t</span></code>, accommodating 4B+ size.</p></li>
<li><p>✅ Compatible with OpenMP and custom “executors”, for fine-grained control over CPU utilization.</p></li>
<li><p>✅ Supports multiple vectors per label.</p></li>
<li><p>✅ On-the-fly deletions.</p></li>
<li><p>✅ <a href="#usearch--ai--multi-modal-semantic-search">Semantic Search</a> and <a href="#joins">Joins</a>.</p></li>
</ul>
<section id="comparison-with-faiss">
<h2>Comparison with FAISS<a href="#comparison-with-faiss" title="Permalink to this heading">#</a></h2>
<p>FAISS is a widely recognized standard for high-performance vector search engines.
USearch and FAISS both employ the same HNSW algorithm, but they differ significantly in their design principles.
USearch is compact and broadly compatible without sacrificing performance, with a primary focus on user-defined metrics and fewer dependencies.</p>
<div>
<table>
<thead>
<tr><th></th>
<th><p>FAISS</p></th>
<th><p>USearch</p></th>
</tr>
</thead>
<tbody>
<tr><td><p>Implementation</p></td>
<td><p>84 K <a href="https://en.wikipedia.org/wiki/Source_lines_of_code">SLOC</a> in <code><span>faiss/</span></code></p></td>
<td><p>3 K <a href="https://en.wikipedia.org/wiki/Source_lines_of_code">SLOC</a> in <code><span>usearch/</span></code></p></td>
</tr>
<tr><td><p>Supported metrics</p></td>
<td><p>9 fixed metrics</p></td>
<td><p>Any User-Defined metrics</p></td>
</tr>
<tr><td><p>Supported ID types</p></td>
<td><p><code><span>uint32_t</span></code>, <code><span>uint64_t</span></code></p></td>
<td><p><code><span>uint32_t</span></code>, <code><span>uint40_t</span></code>, <code><span>uint64_t</span></code></p></td>
</tr>
<tr><td><p>Dependencies</p></td>
<td><p>BLAS, OpenMP</p></td>
<td><p>None</p></td>
</tr>
<tr><td><p>Bindings</p></td>
<td><p>SWIG</p></td>
<td><p>Native</p></td>
</tr>
<tr><td><p>Acceleration</p></td>
<td><p>Learned Quantization</p></td>
<td><p>Downcasting</p></td>
</tr>
</tbody>
</table>
</div>
<p>Base functionality is identical to FAISS, and the interface must be familiar if you have ever investigated Approximate Nearest Neigbors search:</p>
<div><div><pre><span></span>$ pip install usearch numpy

import numpy as np
from usearch.index import Index

index = Index(
    ndim=3, # Define the number of dimensions in input vectors
    metric=&#39;cos&#39;, # Choose &#39;l2sq&#39;, &#39;haversine&#39; or other metric, default = &#39;ip&#39;
    dtype=&#39;f32&#39;, # Quantize to &#39;f16&#39; or &#39;f8&#39; if needed, default = &#39;f32&#39;
    connectivity=16, # Optional: How frequent should the connections in the graph be
    expansion_add=128, # Optional: Control the recall of indexing
    expansion_search=64, # Optional: Control the quality of search
)

vector = np.array([0.2, 0.6, 0.4])
index.add(42, vector)
matches, distances, count = index.search(vector, 10)

assert len(index) == 1
assert count == 1
assert matches[0] == 42
assert distances[0] &lt;= 0.001
assert np.allclose(index[42], vector)
</pre></div>
</div>
</section>
<section id="user-defined-functions">
<h2>User-Defined Functions<a href="#user-defined-functions" title="Permalink to this heading">#</a></h2>
<p>While most vector search packages concentrate on just a couple of metrics - “Inner Product distance” and “Euclidean distance,” USearch extends this list to include any user-defined metrics.
This flexibility allows you to customize your search for a myriad of applications, from computing geo-spatial coordinates with the rare <a href="https://ashvardanian.com/posts/abusing-vector-search#geo-spatial-indexing">Haversine</a> distance to creating custom metrics for composite embeddings from multiple AI models.</p>
<a href="https://github.com/unum-cloud/usearch/blob/main/assets/usearch-approaches-white.png?raw=true"><img alt="USearch: Vector Search Approaches" src="https://github.com/unum-cloud/usearch/blob/main/assets/usearch-approaches-white.png?raw=true"/></a>
<p>Unlike older approaches indexing high-dimensional spaces, like KD-Trees and Locality Sensitive Hashing, HNSW doesn’t require vectors to be identical in length.
They only have to be comparable.
So you can apply it in <a href="https://ashvardanian.com/posts/abusing-vector-search">obscure</a> applications, like searching for similar sets or fuzzy text matching, using <a href="https://twitter.com/LukeGessler/status/1679211291292889100?s=20">GZip</a> as a distance function.</p>
<blockquote>
</blockquote>
</section>
<section id="memory-efficiency-downcasting-and-quantization">
<h2>Memory Efficiency, Downcasting, and Quantization<a href="#memory-efficiency-downcasting-and-quantization" title="Permalink to this heading">#</a></h2>
<p>Training a quantization model and dimension-reduction is a common approach to accelerate vector search.
Those, however, are only sometimes reliable, can significantly affect the statistical properties of your data, and require regular adjustments if your distribution shifts.</p>
<a href="https://github.com/unum-cloud/usearch/blob/main/assets/usearch-neighbor-types.png?raw=true"><img alt="USearch uint40_t support" src="https://github.com/unum-cloud/usearch/blob/main/assets/usearch-neighbor-types.png?raw=true"/></a>
<p>Instead, we have focused on high-precision arithmetic over low-precision downcasted vectors.
The same index, and <code><span>add</span></code> and <code><span>search</span></code> operations will automatically down-cast or up-cast between <code><span>f32_t</span></code>, <code><span>f16_t</span></code>, <code><span>f64_t</span></code>, and <code><span>f8_t</span></code> representations, even if the hardware doesn’t natively support it.
Continuing the topic of memory-efficiency, we provide a <code><span>uint40_t</span></code> to allow collection with over 4B+ vectors without allocating 8 bytes for every neighbor reference in the proximity graph.</p>
<div>
<table>
<thead>
<tr><th></th>
<th><p>FAISS, <code><span>f32</span></code></p></th>
<th><p>USearch, <code><span>f32</span></code></p></th>
<th><p>USearch, <code><span>f16</span></code></p></th>
<th><p>USearch, <code><span>f8</span></code></p></th>
</tr>
</thead>
<tbody>
<tr><td><p>Batch Insert</p></td>
<td><p>16 K/s</p></td>
<td><p>73 K/s</p></td>
<td><p>100 K/s</p></td>
<td><p>104 K/s <strong>+550%</strong></p></td>
</tr>
<tr><td><p>Batch Search</p></td>
<td><p>82 K/s</p></td>
<td><p>103 K/s</p></td>
<td><p>113 K/s</p></td>
<td><p>134 K/s <strong>+63%</strong></p></td>
</tr>
<tr><td><p>Bulk Insert</p></td>
<td><p>76 K/s</p></td>
<td><p>105 K/s</p></td>
<td><p>115 K/s</p></td>
<td><p>202 K/s <strong>+165%</strong></p></td>
</tr>
<tr><td><p>Bulk Search</p></td>
<td><p>118 K/s</p></td>
<td><p>174 K/s</p></td>
<td><p>173 K/s</p></td>
<td><p>304 K/s <strong>+157%</strong></p></td>
</tr>
<tr><td><p>Recall @ 10</p></td>
<td><p>99%</p></td>
<td><p>99.2%</p></td>
<td><p>99.1%</p></td>
<td><p>99.2%</p></td>
</tr>
</tbody>
</table>
</div>
<blockquote>
<p>Dataset: 1M vectors sample of the Deep1B dataset.
Hardware: <code><span>c7g.metal</span></code> AWS instance with 64 cores and DDR5 memory.
HNSW was configured with identical hyper-parameters:
connectivity <code><span>M=16</span></code>,
expansion @ construction <code><span>efConstruction=128</span></code>,
and expansion @ search <code><span>ef=64</span></code>.
Batch size is 256.
Both libraries were compiled for the target architecture.
Jump to the <a href="https://github.com/unum-cloud/usearch/blob/main/docs/benchmarks.md">Performance Tuning</a> section to read about the effects of those hyper-parameters.</p></blockquote>
</section>
<section id="disk-based-indexes">
<h2>Disk-based Indexes<a href="#disk-based-indexes" title="Permalink to this heading">#</a></h2>
<p>With USearch, you can serve indexes from external memory, enabling you to optimize your server choices for indexing speed and serving costs.
This can result in <strong>20x costs reduction</strong> on AWS and other public clouds.</p>
<div><div><pre><span></span><span>index</span><span>.</span><span>save</span><span>(</span><span>&#34;index.usearch&#34;</span><span>)</span>

<span>loaded_copy</span> <span>=</span> <span>index</span><span>.</span><span>load</span><span>(</span><span>&#34;index.usearch&#34;</span><span>)</span>
<span>view</span> <span>=</span> <span>Index</span><span>.</span><span>restore</span><span>(</span><span>&#34;index.usearch&#34;</span><span>,</span> <span>view</span><span>=</span><span>True</span><span>)</span>

<span>other_view</span> <span>=</span> <span>Index</span><span>(</span><span>ndim</span><span>=...</span><span>,</span> <span>metric</span><span>=</span><span>CompiledMetric</span><span>(</span><span>...</span><span>))</span>
<span>other_view</span><span>.</span><span>view</span><span>(</span><span>&#34;index.usearch&#34;</span><span>)</span>
</pre></div>
</div>
</section>
<section id="id2">
<h2>Joins<a href="#id2" title="Permalink to this heading">#</a></h2>
<p>One of the big questions these days is how will AI change the world of databases and data-management?
Most databases are still struggling to implement high-quality fuzzy search, and the only kind of joins they know are deterministic.
A <code><span>join</span></code> is different from searching for every entry, as it requires a one-to-one mapping, banning collisions among separate search results.</p>
<div>
<table>
<thead>
<tr><th><p>Exact Search</p></th>
<th><p>Fuzzy Search</p></th>
<th><p>Semantic Search ?</p></th>
</tr>
</thead>
<tbody>
<tr><td><p>Exact Join</p></td>
<td><p>Fuzzy Join ?</p></td>
<td><p>Semantic Join ??</p></td>
</tr>
</tbody>
</table>
</div>
<p>Using USearch one can implement sub-quadratic complexity approximate, fuzzy, and semantic joins.
This can come handy in any fuzzy-matching tasks, common to Database Management Software.</p>
<div><div><pre><span></span><span>men</span> <span>=</span> <span>Index</span><span>(</span><span>...</span><span>)</span>
<span>women</span> <span>=</span> <span>Index</span><span>(</span><span>...</span><span>)</span>
<span>pairs</span><span>:</span> <span>dict</span> <span>=</span> <span>men</span><span>.</span><span>join</span><span>(</span><span>women</span><span>,</span> <span>max_proposals</span><span>=</span><span>0</span><span>,</span> <span>exact</span><span>=</span><span>False</span><span>)</span>
</pre></div>
</div>
<blockquote>
</blockquote>
</section>
<section id="functionality">
<h2>Functionality<a href="#functionality" title="Permalink to this heading">#</a></h2>
<p>By now, core functionality is supported across all bindings.
Broader functionality is ported per request.</p>
<div>
<table>
<thead>
<tr><th></th>
<th><p>C++</p></th>
<th><p>Python</p></th>
<th><p>Java</p></th>
<th><p>JavaScript</p></th>
<th><p>Rust</p></th>
<th><p>GoLang</p></th>
<th><p>Swift</p></th>
</tr>
</thead>
<tbody>
<tr><td><p>add/search/remove</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
</tr>
<tr><td><p>save/load/view</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
</tr>
<tr><td><p>join</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
</tr>
<tr><td><p>user-defiend metrics</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
</tr>
<tr><td><p>variable-length vectors</p></td>
<td><p>✅</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
</tr>
<tr><td><p>4B+ capacities</p></td>
<td><p>✅</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
<td><p>❌</p></td>
</tr>
</tbody>
</table>
</div>
</section>
<section id="application-examples">
<h2>Application Examples<a href="#application-examples" title="Permalink to this heading">#</a></h2>
<section id="usearch-ai-multi-modal-semantic-search">
<h3>USearch + AI = Multi-Modal Semantic Search<a href="#usearch-ai-multi-modal-semantic-search" title="Permalink to this heading">#</a></h3>
<p>AI has a growing number of applications, but one of the coolest classic ideas is to use it for Semantic Search.
One can take an encoder model, like the multi-modal UForm, and a web-programming framework, like UCall, and build a text-to-image search platform in just 20 lines of Python.</p>
<div><div><pre><span></span><span>import</span> <span>ucall</span>
<span>import</span> <span>uform</span>
<span>import</span> <span>usearch</span>

<span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>import</span> <span>PIL</span> <span>as</span> <span>pil</span>

<span>server</span> <span>=</span> <span>ucall</span><span>.</span><span>Server</span><span>()</span>
<span>model</span> <span>=</span> <span>uform</span><span>.</span><span>get_model</span><span>(</span><span>&#39;unum-cloud/uform-vl-multilingual&#39;</span><span>)</span>
<span>index</span> <span>=</span> <span>usearch</span><span>.</span><span>index</span><span>.</span><span>Index</span><span>(</span><span>ndim</span><span>=</span><span>256</span><span>)</span>

<span>@server</span>
<span>def</span> <span>add</span><span>(</span><span>label</span><span>:</span> <span>int</span><span>,</span> <span>photo</span><span>:</span> <span>pil</span><span>.</span><span>Image</span><span>.</span><span>Image</span><span>):</span>
    <span>image</span> <span>=</span> <span>model</span><span>.</span><span>preprocess_image</span><span>(</span><span>photo</span><span>)</span>
    <span>vector</span> <span>=</span> <span>model</span><span>.</span><span>encode_image</span><span>(</span><span>image</span><span>)</span><span>.</span><span>detach</span><span>()</span><span>.</span><span>numpy</span><span>()</span>
    <span>index</span><span>.</span><span>add</span><span>(</span><span>label</span><span>,</span> <span>vector</span><span>.</span><span>flatten</span><span>(),</span> <span>copy</span><span>=</span><span>True</span><span>)</span>

<span>@server</span>
<span>def</span> <span>search</span><span>(</span><span>query</span><span>:</span> <span>str</span><span>)</span> <span>-&gt;</span> <span>np</span><span>.</span><span>ndarray</span><span>:</span>
    <span>tokens</span> <span>=</span> <span>model</span><span>.</span><span>preprocess_text</span><span>(</span><span>query</span><span>)</span>
    <span>vector</span> <span>=</span> <span>model</span><span>.</span><span>encode_text</span><span>(</span><span>tokens</span><span>)</span><span>.</span><span>detach</span><span>()</span><span>.</span><span>numpy</span><span>()</span>
    <span>matches</span> <span>=</span> <span>index</span><span>.</span><span>search</span><span>(</span><span>vector</span><span>.</span><span>flatten</span><span>(),</span> <span>3</span><span>)</span>
    <span>return</span> <span>matches</span><span>.</span><span>labels</span>

<span>server</span><span>.</span><span>run</span><span>()</span>
</pre></div>
</div>
<p>We have pre-processed some commonly used datasets, cleaning the images, producing the vectors, and pre-building the index.</p>

</section>
<section id="usearch-rdkit-molecular-search">
<h3>USearch + RDKit = Molecular Search<a href="#usearch-rdkit-molecular-search" title="Permalink to this heading">#</a></h3>
<p>Comparing molecule graphs and searching for similar structures is expensive and slow.
It can be seen as a special case of the NP-Complete Subgraph Isomorphism problem.
Luckily, domain-specific approximate methods exists.
The one commonly used in Chemistry, is to generate structures from <a href="https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system">SMILES</a>, and later hash them into binary fingerprints.
The later are searchable with bitwise similarity metrics, like the Tanimoto coefficient.
Below is na example using the RDKit package.</p>
<div><div><pre><span></span><span>from</span> <span>usearch.index</span> <span>import</span> <span>Index</span><span>,</span> <span>MetricKind</span>
<span>from</span> <span>rdkit</span> <span>import</span> <span>Chem</span>
<span>from</span> <span>rdkit.Chem</span> <span>import</span> <span>AllChem</span>

<span>import</span> <span>numpy</span> <span>as</span> <span>np</span>

<span>molecules</span> <span>=</span> <span>[</span><span>Chem</span><span>.</span><span>MolFromSmiles</span><span>(</span><span>&#39;CCOC&#39;</span><span>),</span> <span>Chem</span><span>.</span><span>MolFromSmiles</span><span>(</span><span>&#39;CCO&#39;</span><span>)]</span>
<span>encoder</span> <span>=</span> <span>AllChem</span><span>.</span><span>GetRDKitFPGenerator</span><span>()</span>

<span>fingerprints</span> <span>=</span> <span>np</span><span>.</span><span>vstack</span><span>([</span><span>encoder</span><span>.</span><span>GetFingerprint</span><span>(</span><span>x</span><span>)</span> <span>for</span> <span>x</span> <span>in</span> <span>molecules</span><span>])</span>
<span>fingerprints</span> <span>=</span> <span>np</span><span>.</span><span>packbits</span><span>(</span><span>fingerprints</span><span>,</span> <span>axis</span><span>=</span><span>1</span><span>)</span>

<span>index</span> <span>=</span> <span>Index</span><span>(</span><span>ndim</span><span>=</span><span>2048</span><span>,</span> <span>metric</span><span>=</span><span>MetricKind</span><span>.</span><span>Tanimoto</span><span>)</span>
<span>labels</span> <span>=</span> <span>np</span><span>.</span><span>arange</span><span>(</span><span>len</span><span>(</span><span>molecules</span><span>))</span>

<span>index</span><span>.</span><span>add</span><span>(</span><span>labels</span><span>,</span> <span>fingerprints</span><span>)</span>
<span>matches</span> <span>=</span> <span>index</span><span>.</span><span>search</span><span>(</span><span>fingerprints</span><span>,</span> <span>10</span><span>)</span>
</pre></div>
</div>
</section>
</section>
<section id="todo">
<h2>TODO<a href="#todo" title="Permalink to this heading">#</a></h2>
<ul>
<li><p>JavaScript: Allow calling from “worker threads”.</p></li>
<li><p>Rust: Allow passing a custom thread ID.</p></li>
<li><p>C# .NET bindings.</p></li>
</ul>
</section>
<section id="integrations">
<h2>Integrations<a href="#integrations" title="Permalink to this heading">#</a></h2>
<ul>
<li><p>[x] GPT-Cache.</p></li>
<li><p>[ ] LangChain.</p></li>
<li><p>[ ] Microsoft Semantic Kernel.</p></li>
<li><p>[ ] PyTorch.</p></li>
</ul>
</section>
<section id="citations">
<h2>Citations<a href="#citations" title="Permalink to this heading">#</a></h2>
<div><div><pre><span></span>@software{Vardanian_USearch_2022,
doi = {10.5281/zenodo.7949416},
author = {Vardanian, Ash},
title = {{USearch by Unum Cloud}},
url = {https://github.com/unum-cloud/usearch},
version = {0.13.0},
year = {2022}
month = jun,
}
</pre></div>
</div>



</section>
</section>

        </article></div>
  </body>
</html>
