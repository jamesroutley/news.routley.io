<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://newpipe.net/">Original</a>
    <h1>NewPipe – Lightweight YouTube experience for Android</h1>
    
    <div id="readability-page-1" class="page"><div id="content"><p><em>Born of ancient magic, the Chromatic Chameleon prowls the shadows with scales that pulse and shimmer in a dance of arcane radiance. Its form, a living canvas, shifts through the hues of twilight, an elusive guardian draped in spectral energies. Only those with keen senses may glimpse the majestic, ever-changing creature lurking in the mystic realms.</em></p>
<figure><a href="https://swe-to-mle.pages.dev/posts/neural-style-transfer/chameleon.png" title="chameleon" data-thumbnail="chameleon.png" data-sub-html="&lt;h2&gt;Chromatic Chameleon&lt;/h2&gt;&lt;p&gt;chameleon&lt;/p&gt;">
        <img src="https://swe-to-mle.pages.dev/svg/loading.min.svg" data-src="chameleon.png" data-srcset="chameleon.png, chameleon.png 1.5x, chameleon.png 2x" data-sizes="auto" alt="chameleon.png"/>
    </a><figcaption>Chromatic Chameleon</figcaption>
    </figure>
<h2 id="the-quest">The Quest</h2>
<p>Repurpose an image classifier to do style transfer from a donor style image to a receiver content image.</p>
<h2 id="neural-style-transfer">Neural Style Transfer</h2>
<p>At a conceptual level, we want to feed the content and style images to the network and snapshot activations values of the inner layers of the image classifier. Merge them. And recreate an image through gradient descent to contain aspects of both at the same time.</p>
<h3 id="hook-into-the-image-classifier">Hook into the image classifier</h3>
<p>First we need to hook into the classifier to get access to the activation values of the network</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>def</span> <span>hook</span><span>(</span><span>layer</span><span>,</span> <span>k</span><span>,</span> <span>mem</span><span>=</span><span>None</span><span>):</span>
</span></span><span><span>    <span>if</span> <span>mem</span> <span>is</span> <span>None</span><span>:</span> <span>mem</span> <span>=</span> <span>{}</span>
</span></span><span><span>    <span>def</span> <span>f</span><span>(</span><span>module</span><span>,</span> <span>input</span><span>,</span> <span>output</span><span>):</span>
</span></span><span><span>        <span>mem</span><span>[</span><span>k</span><span>]</span> <span>=</span> <span>output</span>
</span></span><span><span>    <span>layer</span><span>.</span><span>register_forward_hook</span><span>(</span><span>f</span><span>)</span>
</span></span><span><span>    <span>return</span> <span>mem</span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>hooked</span><span>(</span><span>model</span><span>):</span>
</span></span><span><span>    <span>m</span> <span>=</span> <span>copy</span><span>.</span><span>deepcopy</span><span>(</span><span>model</span><span>)</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>
</span></span><span><span>    <span>mem</span> <span>=</span> <span>{}</span>
</span></span><span><span>    <span>for</span> <span>layer</span> <span>in</span> <span>range</span><span>(</span><span>37</span><span>):</span>
</span></span><span><span>        <span>mem</span> <span>=</span> <span>hook</span><span>(</span><span>m</span><span>.</span><span>features</span><span>[</span><span>layer</span><span>],</span> <span>layer</span><span>,</span> <span>mem</span><span>=</span><span>mem</span><span>)</span>
</span></span><span><span>    <span>return</span> <span>mem</span><span>,</span> <span>m</span>
</span></span></code></pre></div><h3 id="extract-the-content-image-compression">Extract the content: Image Compression</h3>
<p>The first step is to extract the features that are relevent to the content image. This could also be reframed as a compression problem. Can we take the activation values from an inner layer of the network and use them to reconstruct the original image.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>def</span> <span>apply_content</span><span>(</span><span>start</span><span>,</span> <span>content</span><span>,</span> <span>layer</span><span>=</span><span>content_layer</span><span>,</span> <span>epochs</span><span>=</span><span>10</span><span>,</span> <span>m</span><span>=</span><span>vgg_hooked</span><span>,</span> <span>mem</span><span>=</span><span>vgg_mem</span><span>):</span>
</span></span><span><span>    <span>activations</span> <span>=</span> <span>save_activations</span><span>(</span><span>content</span><span>)</span>
</span></span><span><span>    <span># move to device</span>
</span></span><span><span>    <span>start</span> <span>=</span> <span>copy</span><span>.</span><span>deepcopy</span><span>(</span><span>start</span><span>.</span><span>detach</span><span>())</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span><span>.</span><span>requires_grad_</span><span>()</span>
</span></span><span><span>    <span>target</span> <span>=</span> <span>activations</span><span>[</span><span>layer</span><span>]</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>
</span></span><span><span>    <span>m</span> <span>=</span> <span>m</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>
</span></span><span><span>    <span>m</span><span>.</span><span>eval</span><span>()</span>
</span></span><span><span>    <span># optimizer</span>
</span></span><span><span>    <span>optimizer</span> <span>=</span> <span>torch</span><span>.</span><span>optim</span><span>.</span><span>LBFGS</span><span>([</span><span>start</span><span>])</span>
</span></span><span><span>    <span>for</span> <span>epoch</span> <span>in</span> <span>tqdm</span><span>(</span><span>range</span><span>(</span><span>epochs</span><span>)):</span>
</span></span><span><span>        <span>def</span> <span>closure</span><span>():</span>
</span></span><span><span>            <span>m</span><span>(</span><span>start</span><span>)</span>
</span></span><span><span>            <span>predicted</span> <span>=</span> <span>mem</span><span>[</span><span>layer</span><span>]</span>
</span></span><span><span>            <span>loss</span> <span>=</span> <span>F</span><span>.</span><span>mse_loss</span><span>(</span><span>predicted</span><span>,</span> <span>target</span><span>)</span>
</span></span><span><span>            <span>optimizer</span><span>.</span><span>zero_grad</span><span>()</span>
</span></span><span><span>            <span>loss</span><span>.</span><span>backward</span><span>()</span>
</span></span><span><span>            <span>return</span> <span>loss</span>
</span></span><span><span>    
</span></span><span><span>        <span>optimizer</span><span>.</span><span>step</span><span>(</span><span>closure</span><span>)</span>
</span></span><span><span>        <span>start</span><span>.</span><span>data</span> <span>=</span> <span>torch</span><span>.</span><span>clip</span><span>(</span><span>start</span><span>,</span> <span>0.0</span><span>,</span> <span>1.0</span><span>)</span><span>.</span><span>data</span>
</span></span><span><span>    <span>return</span> <span>start</span>
</span></span></code></pre></div><figure><a href="https://swe-to-mle.pages.dev/posts/neural-style-transfer/image-compression.png" title="image-compression" data-thumbnail="image-compression.png" data-sub-html="&lt;h2&gt;Image compression using a CNN&lt;/h2&gt;&lt;p&gt;image-compression&lt;/p&gt;">
        <img src="https://swe-to-mle.pages.dev/svg/loading.min.svg" data-src="image-compression.png" data-srcset="image-compression.png, image-compression.png 1.5x, image-compression.png 2x" data-sizes="auto" alt="image-compression.png"/>
    </a><figcaption>Image compression using a CNN</figcaption>
    </figure>
<p>The earlier layers are fairly big and it’s easy to reconstruct a good version of the original image, but later ones are much smaller and a lot of the details are lost. “Creating progressively noisier and noisier images.</p>
<h3 id="extract-the-style-gram-matrix">Extract the style: Gram matrix</h3>
<p>For the style we do not want to recreate the original image. We only care about its essence. We care about how features relate to each other. And for that we compute the <code>Gram matrix</code> (aka. covariance, aka. correlation) between the channels at a given layer.</p>
<p>The idea is to capture the relation between features of a painting. For example the yellow stars and moon are correlated with convex radiant shapes, while the blue are swirly spirals, and the vegetation is weavy.</p>
<figure><a href="https://swe-to-mle.pages.dev/posts/neural-style-transfer/starry-night.png" title="starry-night" data-thumbnail="starry-night.png" data-sub-html="&lt;h2&gt;The Starry Night&lt;/h2&gt;&lt;p&gt;starry-night&lt;/p&gt;">
        <img src="https://swe-to-mle.pages.dev/svg/loading.min.svg" data-src="starry-night.png" data-srcset="starry-night.png, starry-night.png 1.5x, starry-night.png 2x" data-sizes="auto" alt="starry-night.png"/>
    </a><figcaption>The Starry Night</figcaption>
    </figure>
<p>The similarity between two channels is computed by taking their dot product. We can do it for all pairs by doing a matrix multiplication <code>Channels @ Channels.T</code>.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>def</span> <span>gram</span><span>(</span><span>layer</span><span>):</span>
</span></span><span><span>  <span>n_channel</span> <span>=</span> <span>layer</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>]</span>
</span></span><span><span>  <span>layer</span> <span>=</span> <span>layer</span><span>.</span><span>view</span><span>(</span><span>n_channel</span><span>,</span> <span>-</span><span>1</span><span>)</span>
</span></span><span><span>  <span>layer</span> <span>=</span> <span>layer</span> <span>/</span> <span>(</span><span>layer</span><span>.</span><span>norm</span><span>(</span><span>dim</span><span>=</span><span>1</span><span>,</span> <span>keepdim</span><span>=</span><span>True</span><span>)</span> <span>+</span> <span>1e-8</span><span>)</span> <span># normalize to 1 and avoid division by 0</span>
</span></span><span><span>  <span>res</span> <span>=</span> <span>layer</span> <span>@</span> <span>layer</span><span>.</span><span>T</span>
</span></span><span><span>  <span>return</span> <span>res</span>
</span></span></code></pre></div><p>We then chose a combination of layers to extract the style from (e.g. <code>style_layers = [1, 6, 11, 20, 29]</code>). Keeping in mind that very firsts layers have color information, early layers basic shapes, and more and more composit patterns.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>def</span> <span>apply_style</span><span>(</span><span>start</span><span>,</span> <span>style</span><span>,</span> <span>layers</span><span>=</span><span>style_layers</span><span>,</span> <span>epochs</span><span>=</span><span>10</span><span>,</span> <span>m</span><span>=</span><span>vgg_hooked</span><span>,</span> <span>mem</span><span>=</span><span>vgg_mem</span><span>):</span>
</span></span><span><span>    <span>activations</span> <span>=</span> <span>save_activations</span><span>(</span><span>style</span><span>)</span>
</span></span><span><span>    <span># move to device</span>
</span></span><span><span>    <span>start</span> <span>=</span> <span>copy</span><span>.</span><span>deepcopy</span><span>(</span><span>start</span><span>.</span><span>detach</span><span>())</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span><span>.</span><span>requires_grad_</span><span>()</span>
</span></span><span><span>    <span>targets</span> <span>=</span> <span>[</span><span>gram</span><span>(</span><span>activations</span><span>[</span><span>layer</span><span>])</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span> <span>for</span> <span>layer</span> <span>in</span> <span>layers</span><span>]</span>
</span></span><span><span>    <span>m</span> <span>=</span> <span>m</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>
</span></span><span><span>    <span>m</span><span>.</span><span>eval</span><span>()</span>
</span></span><span><span>    <span># optimizer</span>
</span></span><span><span>    <span>optimizer</span> <span>=</span> <span>torch</span><span>.</span><span>optim</span><span>.</span><span>LBFGS</span><span>([</span><span>start</span><span>])</span>
</span></span><span><span>    <span>for</span> <span>epoch</span> <span>in</span> <span>tqdm</span><span>(</span><span>range</span><span>(</span><span>epochs</span><span>)):</span>
</span></span><span><span>        <span>def</span> <span>closure</span><span>():</span>
</span></span><span><span>            <span>m</span><span>(</span><span>start</span><span>)</span>
</span></span><span><span>            <span>predictions</span> <span>=</span> <span>[</span><span>gram</span><span>(</span><span>mem</span><span>[</span><span>layer</span><span>])</span> <span>for</span> <span>layer</span> <span>in</span> <span>layers</span><span>]</span>
</span></span><span><span>            <span>losses</span> <span>=</span> <span>[</span><span>F</span><span>.</span><span>mse_loss</span><span>(</span><span>predicted</span><span>,</span> <span>target</span><span>)</span> <span>for</span> <span>predicted</span><span>,</span> <span>target</span> <span>in</span> <span>zip</span><span>(</span><span>predictions</span><span>,</span> <span>targets</span><span>)]</span>
</span></span><span><span>            <span>loss</span> <span>=</span> <span>torch</span><span>.</span><span>stack</span><span>(</span><span>losses</span><span>)</span><span>.</span><span>sum</span><span>()</span>
</span></span><span><span>            <span>optimizer</span><span>.</span><span>zero_grad</span><span>()</span>
</span></span><span><span>            <span>loss</span><span>.</span><span>backward</span><span>()</span>
</span></span><span><span>            <span>return</span> <span>loss</span>
</span></span><span><span>
</span></span><span><span>        <span>optimizer</span><span>.</span><span>step</span><span>(</span><span>closure</span><span>)</span>
</span></span><span><span>        <span>start</span><span>.</span><span>data</span> <span>=</span> <span>torch</span><span>.</span><span>clip</span><span>(</span><span>start</span><span>,</span> <span>0.0</span><span>,</span> <span>1.0</span><span>)</span><span>.</span><span>data</span>
</span></span><span><span>    <span>return</span> <span>start</span>
</span></span></code></pre></div><p>Let’s have a look at some style extractions from Van Gogh’s Stary Night painting applied to a dog picture.</p>
<figure><a href="https://swe-to-mle.pages.dev/posts/neural-style-transfer/style-extraction.png" title="style-extraction" data-thumbnail="style-extraction.png" data-sub-html="&lt;h2&gt;Style extraction from starry night to a dog&lt;/h2&gt;&lt;p&gt;style-extraction&lt;/p&gt;">
        <img src="https://swe-to-mle.pages.dev/svg/loading.min.svg" data-src="style-extraction.png" data-srcset="style-extraction.png, style-extraction.png 1.5x, style-extraction.png 2x" data-sizes="auto" alt="style-extraction.png"/>
    </a><figcaption>Style extraction from starry night to a dog</figcaption>
    </figure>
<h3 id="putting-it-together">Putting it together</h3>
<p>Now we can mix both the re-construction of the content, and the essence of the style together. Also known as neural style transfer.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>style_layers</span> <span>=</span> <span>[</span><span>1</span><span>,</span> <span>6</span><span>,</span> <span>11</span><span>,</span> <span>20</span><span>,</span> <span>29</span><span>]</span>
</span></span><span><span><span>content_layer</span> <span>=</span> <span>28</span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>style_transfer</span><span>(</span><span>start</span><span>,</span> <span>content</span><span>,</span> <span>style</span><span>,</span> <span>scaler</span><span>=</span><span>1.</span><span>,</span> <span>content_layer</span><span>=</span><span>content_layer</span><span>,</span> <span>style_layers</span><span>=</span><span>style_layers</span><span>,</span> <span>epochs</span><span>=</span><span>10</span><span>,</span> <span>m</span><span>=</span><span>vgg_hooked</span><span>,</span> <span>mem</span><span>=</span><span>vgg_mem</span><span>):</span>
</span></span><span><span>    <span>content_activations</span> <span>=</span> <span>save_activations</span><span>(</span><span>content</span><span>)</span>
</span></span><span><span>    <span>style_activations</span> <span>=</span> <span>save_activations</span><span>(</span><span>style</span><span>)</span>
</span></span><span><span>    <span># move to device</span>
</span></span><span><span>    <span>start</span> <span>=</span> <span>copy</span><span>.</span><span>deepcopy</span><span>(</span><span>start</span><span>.</span><span>detach</span><span>())</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span><span>.</span><span>requires_grad_</span><span>()</span>
</span></span><span><span>    <span>content_target</span> <span>=</span> <span>content_activations</span><span>[</span><span>content_layer</span><span>]</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>
</span></span><span><span>    <span>style_targets</span> <span>=</span> <span>[</span><span>gram</span><span>(</span><span>style_activations</span><span>[</span><span>layer</span><span>])</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span> <span>for</span> <span>layer</span> <span>in</span> <span>style_layers</span><span>]</span>
</span></span><span><span>    <span>m</span> <span>=</span> <span>m</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>
</span></span><span><span>    <span>m</span><span>.</span><span>eval</span><span>()</span>
</span></span><span><span>    <span># optimizer</span>
</span></span><span><span>    <span>optimizer</span> <span>=</span> <span>torch</span><span>.</span><span>optim</span><span>.</span><span>LBFGS</span><span>([</span><span>start</span><span>])</span>
</span></span><span><span>    <span>for</span> <span>epoch</span> <span>in</span> <span>tqdm</span><span>(</span><span>range</span><span>(</span><span>epochs</span><span>)):</span>
</span></span><span><span>        <span>def</span> <span>closure</span><span>():</span>
</span></span><span><span>            <span>m</span><span>(</span><span>start</span><span>)</span>
</span></span><span><span>            <span># content loss</span>
</span></span><span><span>            <span>content_predicted</span> <span>=</span> <span>mem</span><span>[</span><span>content_layer</span><span>]</span>
</span></span><span><span>            <span>content_loss</span> <span>=</span> <span>F</span><span>.</span><span>mse_loss</span><span>(</span><span>content_predicted</span><span>,</span> <span>content_target</span><span>)</span>
</span></span><span><span>            <span># style loss</span>
</span></span><span><span>            <span>style_predictions</span> <span>=</span> <span>[</span><span>gram</span><span>(</span><span>mem</span><span>[</span><span>layer</span><span>])</span> <span>for</span> <span>layer</span> <span>in</span> <span>style_layers</span><span>]</span>
</span></span><span><span>            <span>style_losses</span> <span>=</span> <span>[</span><span>F</span><span>.</span><span>mse_loss</span><span>(</span><span>predicted</span><span>,</span> <span>target</span><span>)</span> <span>for</span> <span>predicted</span><span>,</span> <span>target</span> <span>in</span> <span>zip</span><span>(</span><span>style_predictions</span><span>,</span> <span>style_targets</span><span>)]</span>
</span></span><span><span>            <span>style_loss</span> <span>=</span> <span>torch</span><span>.</span><span>stack</span><span>(</span><span>style_losses</span><span>)</span><span>.</span><span>sum</span><span>()</span>
</span></span><span><span>            <span># merge losses</span>
</span></span><span><span>            <span>loss</span> <span>=</span> <span>content_loss</span> <span>+</span> <span>scaler</span> <span>*</span> <span>style_loss</span>
</span></span><span><span>            <span>optimizer</span><span>.</span><span>zero_grad</span><span>()</span>
</span></span><span><span>            <span>loss</span><span>.</span><span>backward</span><span>()</span>
</span></span><span><span>            <span>return</span> <span>loss</span>
</span></span><span><span>
</span></span><span><span>        <span>optimizer</span><span>.</span><span>step</span><span>(</span><span>closure</span><span>)</span>
</span></span><span><span>        <span>start</span><span>.</span><span>data</span> <span>=</span> <span>torch</span><span>.</span><span>clip</span><span>(</span><span>start</span><span>,</span> <span>0.0</span><span>,</span> <span>1.0</span><span>)</span><span>.</span><span>data</span>
</span></span><span><span>    <span>return</span> <span>start</span>
</span></span></code></pre></div><figure><a href="https://swe-to-mle.pages.dev/posts/neural-style-transfer/starry-dog.png" title="starry-dog" data-thumbnail="starry-dog.png" data-sub-html="&lt;h2&gt;Starry Night meets Dog&lt;/h2&gt;&lt;p&gt;starry-dog&lt;/p&gt;">
        <img src="https://swe-to-mle.pages.dev/svg/loading.min.svg" data-src="starry-dog.png" data-srcset="starry-dog.png, starry-dog.png 1.5x, starry-dog.png 2x" data-sizes="auto" alt="starry-dog.png"/>
    </a><figcaption>Starry Night meets Dog</figcaption>
    </figure>
<figure><a href="https://swe-to-mle.pages.dev/posts/neural-style-transfer/cubist-dog.png" title="cubist-dog" data-thumbnail="cubist-dog.png" data-sub-html="&lt;h2&gt;Cubism meets Dog&lt;/h2&gt;&lt;p&gt;cubist-dog&lt;/p&gt;">
        <img src="https://swe-to-mle.pages.dev/svg/loading.min.svg" data-src="cubist-dog.png" data-srcset="cubist-dog.png, cubist-dog.png 1.5x, cubist-dog.png 2x" data-sizes="auto" alt="cubist-dog.png"/>
    </a><figcaption>Cubism meets Dog</figcaption>
    </figure>
<p>Good artists borrow, great artists steal, Neural networks compute Gram matrix.</p>
<h2 id="the-code">The code</h2>
<p>You can get the code at <a href="https://github.com/peluche/neural-style-transfer" target="_blank" rel="noopener noreffer ">https://github.com/peluche/neural-style-transfer</a></p>
</div></div>
  </body>
</html>
