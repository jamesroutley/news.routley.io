<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.nature.com/articles/s41562-022-01516-2">Original</a>
    <h1>Evidence of a predictive coding hierarchy in the human brain listening to speech</h1>
    
    <div id="readability-page-1" class="page"><div>
                <section data-title="Main"><div id="Sec1-section"><h2 id="Sec1">Main</h2><div id="Sec1-content"><p>In less than three years, deep learning has made considerable progress in text generation, translation and completion<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Vaswani, A. et al. Attention is all you need. In Advances in Neural Information Processing Systems, Vol. 30 (Curran Associates, 2017)." href="#ref-CR1" id="ref-link-section-d44958756e432">1</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Radford, A. et al. Language models are unsupervised multitask Learners (2019)." href="#ref-CR2" id="ref-link-section-d44958756e432_1">2</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Brown, T. B. et al. Language models are few-shot learners. In Advances in Neural Information Processing Systems, Vol. 33, 1877-1901 (Curran Associates, 2020)." href="#ref-CR3" id="ref-link-section-d44958756e432_2">3</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Fan, A., Lewis, M. and Dauphin, Y. Hierarchical Neural Story Generation. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 889–898 (Association for Computational Linguistics, 2018)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR4" id="ref-link-section-d44958756e435">4</a></sup> thanks to algorithms trained with a simple objective: predicting words from their nearby context. Remarkably, the activations of these models have been shown to linearly map onto human brain responses to speech and text<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Jain, S. and Huth, A. G. Incorporating context into language encoding models for fMRI. In Proc. 32nd Conference on Neural Information Processing Systems (NeurIPS 2018), Vol. 31, (Curran Associates, 2018)." href="#ref-CR5" id="ref-link-section-d44958756e439">5</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Toneva, M. &amp; Wehbe, L. Interpreting and improving natural-language processing (in machines) with natural language-processing (in the brain). In Advances in Neural Information Processing Systems, Vol. 32 (Curran Associates, 2019)." href="#ref-CR6" id="ref-link-section-d44958756e439_1">6</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Caucheteux, C. &amp; King, J.-R. Brains and algorithms partially converge in natural language processing. Commun Biol. 5, 134 (2022)." href="#ref-CR7" id="ref-link-section-d44958756e439_2">7</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Schrimpf, M. et al. The neural architecture of language: Integrative modeling converges on predictive processing. Proceedings of the National Academy of Sciences, Vol. 118, e2105646118 (Proceedings of the National Academy of Sciences, 2020)." href="#ref-CR8" id="ref-link-section-d44958756e439_3">8</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Toneva, M., Mitchell, T. M. &amp; Wehbe, L. Combining computational controls with natural text reveals new aspects of meaning composition. Nat. Comput. Sci. 2, 745–757 (2022)." href="#ref-CR9" id="ref-link-section-d44958756e439_4">9</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Reddy, A. J. &amp; Wehbe, L. Syntactic representations in the human brain: beyond effort-based metrics. Preprint at bioRxiv 
                https://doi.org/10.1101/2020.06.16.155499
                
               (2021)." href="#ref-CR10" id="ref-link-section-d44958756e439_5">10</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Goldstein, A. et al. Shared computational principles for language processing in humans and deep language models. Nat Neurosci. 25, 369–380 (2022)." href="#ref-CR11" id="ref-link-section-d44958756e439_6">11</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Millet, J., et al. Toward a realistic model of speech processing in the brain with self-supervised learning. In Advances in Neural Information Processing Systems (NeurIPS, 2022)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR12" id="ref-link-section-d44958756e442">12</a></sup>. Additionally, this mapping primarily depends on the algorithms’ ability to predict future words<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Caucheteux, C. &amp; King, J.-R. Brains and algorithms partially converge in natural language processing. Commun Biol. 5, 134 (2022)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR7" id="ref-link-section-d44958756e446">7</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Schrimpf, M. et al. The neural architecture of language: Integrative modeling converges on predictive processing. Proceedings of the National Academy of Sciences, Vol. 118, e2105646118 (Proceedings of the National Academy of Sciences, 2020)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR8" id="ref-link-section-d44958756e449">8</a></sup>, hence suggesting that this objective suffices to make them converge to brain-like computations.</p><p>Yet, a gap persists between humans and these algorithms: in spite of considerable training data, current language models are challenged by long story generation, summarization and coherent dialogue and information retrieval<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Holtzman, A., Buys, J., Maxwell Forbes, L. D. &amp; Choi, Y. The curious case of neural text degeneration. In International Conference on Learning Representations (2020)." href="#ref-CR13" id="ref-link-section-d44958756e456">13</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Wiseman, S., Shieber, S. M. &amp; Rush, A. M. Challenges in data-to-document generation. In Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing, 2253–2263. (Association for Computational Linguistics, 2017)." href="#ref-CR14" id="ref-link-section-d44958756e456_1">14</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Thakur, N., Reimers, N., Rücklé, A., Srivastava, A. &amp; Gurevych, I. BEIR: a heterogenous benchmark for zero-shot evaluation of information retrieval models. In Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2) (2021)." href="#ref-CR15" id="ref-link-section-d44958756e456_2">15</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Raffel, C. et al. Exploring the limits of transfer learning with a unified text-to-text transformer. J. Mach. Learn. Res. 21, 140 (2020)." href="#ref-CR16" id="ref-link-section-d44958756e456_3">16</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Krishna, K., Roy, A. &amp; Iyyer, M. Hurdles to progress in long-form question answering. In Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 4940–4957 (Association for Computational Linguistics, 2021)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR17" id="ref-link-section-d44958756e459">17</a></sup>; they fail to capture several syntactic constructs and semantics properties<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Lakretz, Y. et al. The emergence of number and syntax units in LSTM language models. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Volume 1 (Long and Short Papers), 11–20 (Association for Computational Linguistics, 2019)." href="#ref-CR18" id="ref-link-section-d44958756e463">18</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Arehalli, S. and Linzen, T. Neural language models capture some, but not all, agreement attraction effects. Preprint at PsyArXiv 
                https://doi.org/10.31234/osf.io/97qcg
                
               (2020)." href="#ref-CR19" id="ref-link-section-d44958756e463_1">19</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Lakretz, Y. et al. Can RNNs learn recursive nested subject-verb agreements? Preprint at arXiv 
                https://doi.org/10.48550/arXiv.2101.02258
                
               (2021)." href="#ref-CR20" id="ref-link-section-d44958756e463_2">20</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Baroni, M. Linguistic generalization and compositionality in modern artificial neural networks. Philos. Trans. R. Soc. Lond. B Biol. Sci. 375, 20190307 (2020)." href="#ref-CR21" id="ref-link-section-d44958756e463_3">21</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 22" title="Lake, B. M. &amp; Murphy, G. L. Word meaning in minds and machines. Psychol. Rev. Advance online publication 
                https://doi.org/10.1037/rev0000297
                
               (2021)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR22" id="ref-link-section-d44958756e466">22</a></sup> and their linguistic understanding is superficial<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Arehalli, S. and Linzen, T. Neural language models capture some, but not all, agreement attraction effects. Preprint at PsyArXiv 
                https://doi.org/10.31234/osf.io/97qcg
                
               (2020)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR19" id="ref-link-section-d44958756e470">19</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Baroni, M. Linguistic generalization and compositionality in modern artificial neural networks. Philos. Trans. R. Soc. Lond. B Biol. Sci. 375, 20190307 (2020)." href="#ref-CR21" id="ref-link-section-d44958756e473">21</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Lake, B. M. &amp; Murphy, G. L. Word meaning in minds and machines. Psychol. Rev. Advance online publication 
                https://doi.org/10.1037/rev0000297
                
               (2021)." href="#ref-CR22" id="ref-link-section-d44958756e473_1">22</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Marcus, G. Gpt-2 and the nature of intelligence. The Gradient 
                https://thegradient.pub/gpt2-and-the-nature-of-intelligence/
                
               (2020)." href="#ref-CR23" id="ref-link-section-d44958756e473_2">23</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Warstadt, A. and Bowman, S. R. What artificial neural networks can tell us about human language acquisition. Preprint at arXiv 
                https://doi.org/10.48550/arXiv.2208.07998
                
               (2022)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR24" id="ref-link-section-d44958756e476">24</a></sup>. For instance, they tend to incorrectly assign the verb to the subject in nested phrases like ‘the keys that the man holds ARE here’<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Lakretz, Y. et al. Can RNNs learn recursive nested subject-verb agreements? Preprint at arXiv 
                https://doi.org/10.48550/arXiv.2101.02258
                
               (2021)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR20" id="ref-link-section-d44958756e480">20</a></sup>. Similarly, when text generation is optimized on next-word prediction only, deep language models generate bland, incoherent sequences or get stuck in repetitive loops<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Holtzman, A., Buys, J., Maxwell Forbes, L. D. &amp; Choi, Y. The curious case of neural text degeneration. In International Conference on Learning Representations (2020)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR13" id="ref-link-section-d44958756e484">13</a></sup>.</p><p>Predictive coding theory<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Rumelhart, D. E. &amp; McClelland, J. L. An interactive activation model of context effects in letter perception: Part 2. The contextual enhancement effect and some tests and extensions of the model. Psychol. Rev. 89, 60–94 (1982)." href="#ref-CR25" id="ref-link-section-d44958756e491">25</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Rao, R. P. &amp; Ballard, D. H. Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. Nat. Neurosci. 2, 79–87 (1999)." href="#ref-CR26" id="ref-link-section-d44958756e491_1">26</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 27" title="Friston, K. &amp; Kiebel, S. Predictive coding under the free-energy principle. Philos. Trans. R. Soc. Lond. B Biol. Sci. 364, 1211–1221 (2009)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR27" id="ref-link-section-d44958756e494">27</a></sup> offers a potential explanation to these shortcomings; while deep language models are mostly tuned to predict the very next word, this framework suggests that the human brain makes predictions over multiple timescales and levels of representations across the cortical hierarchy<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 28" title="Wacongne, C. et al. Evidence for a hierarchy of predictions and prediction errors in human cortex. Proc. Natl Acad. Sci. USA 108, 20754–20759 (2011)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR28" id="ref-link-section-d44958756e498">28</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 29" title="Garrido, M. I., Kilner, J. M., Stephan, K. E. &amp; Friston, K. J. The mismatch negativity: a review of underlying mechanisms. Clin. Neurophysiol. 120, 453–463 (2009)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR29" id="ref-link-section-d44958756e501">29</a></sup> (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig1">1a</a>).</p><p>Previous work already evidenced speech predictions in the brain by correlating word or phonetic surprisal, that is, the extent to which a word or phone is expected, with functional magnetic resonance imaging (fMRI)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Willems, R. M., Frank, S. L., Nijhof, A. D., Hagoort, P. &amp; van den Bosch, A. Prediction during natural language comprehension. Cereb. Cortex 26, 2506–2516 (2016)." href="#ref-CR30" id="ref-link-section-d44958756e511">30</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Lopopolo, A., Frank, S. L., van den Bosch, A. &amp; Willems, R. M. Using stochastic language models (SLM) to map lexical, syntactic, and phonological information processing in the brain. PLoS ONE 12, e0177794 (2017)." href="#ref-CR31" id="ref-link-section-d44958756e511_1">31</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Okada, K., Matchin, W. &amp; Hickok, G. Neural evidence for predictive coding in auditory cortex during speech production. Psychon. Bull. Rev. 25, 423–430 (2018)." href="#ref-CR32" id="ref-link-section-d44958756e511_2">32</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 33" title="Shain, C., Blank, I. A., van Schijndel, M., Schuler, W. &amp; Fedorenko, E. fMRI reveals language-specific predictive coding during naturalistic sentence comprehension.Neuropsychologia 138, 107307 (2020)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR33" id="ref-link-section-d44958756e514">33</a></sup>, electroencephalography<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Heilbron, M., Armeni, K., Schoffelen, J.-M., Hagoort, P. &amp; de Lange, F. P. A hierarchy of linguistic predictions during natural language comprehension. Proc. Natl. Acad. Sci. USA 119, e2201968119 (2022)." href="#ref-CR34" id="ref-link-section-d44958756e518">34</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Heilbron, M., Ehinger, B., Hagoort, P. &amp; de Lange, F. P. Tracking naturalistic linguistic predictions with deep neural language models. In Conference on Cognitive Computational Neuroscience (2019)." href="#ref-CR35" id="ref-link-section-d44958756e518_1">35</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 36" title="Donhauser, P. W. &amp; Baillet, S. Two distinct neural timescales for predictive speech processing. Neuron 105, 385–393 (2020)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR36" id="ref-link-section-d44958756e521">36</a></sup>, magnetoencephalography<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 37" title="Mousavi, Z., Kiani, M. M. and Aghajan, H. Brain signatures of surprise in EEG and MEG data. Preprint at bioRxiv 
                https://doi.org/10.1101/2020.01.06.895664
                
               (2020)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR37" id="ref-link-section-d44958756e525">37</a></sup> and electrocorticography<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Goldstein, A. et al. Shared computational principles for language processing in humans and deep language models. Nat Neurosci. 25, 369–380 (2022)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR11" id="ref-link-section-d44958756e529">11</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 38" title="Forseth, K. J., Hickok, G., Rollo, P. S. &amp; Tandon, N. Language prediction mechanisms in human auditory cortex. Nat. Commun. 11, 5240 (2020)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR38" id="ref-link-section-d44958756e532">38</a></sup>. However, such surprisal estimates derive from models trained to predict the very next word or phoneme and reduce down their output to a single number, that is, the probability of the next token. Consequently, the nature of the predicted representations and their temporal scope are largely unknown.</p><p>In this study, we address these issues by analysing the brain signals of 304 individuals listening to short stories while their brain activity is recorded with fMRI<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 39" title="Nastase, S. A. et al. Narratives: fMRI data for evaluating models of naturalistic language comprehension. Sci. Data 8, 250 (2021)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR39" id="ref-link-section-d44958756e540">39</a></sup>. After confirming that deep language algorithms linearly map onto brain activity<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Toneva, M. &amp; Wehbe, L. Interpreting and improving natural-language processing (in machines) with natural language-processing (in the brain). In Advances in Neural Information Processing Systems, Vol. 32 (Curran Associates, 2019)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR6" id="ref-link-section-d44958756e544">6</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Schrimpf, M. et al. The neural architecture of language: Integrative modeling converges on predictive processing. Proceedings of the National Academy of Sciences, Vol. 118, e2105646118 (Proceedings of the National Academy of Sciences, 2020)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR8" id="ref-link-section-d44958756e547">8</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 40" title="Caucheteux, C., Gramfort, A. &amp; King, J.-R. Disentangling syntax and semantics in the brain with deep networks. In Proceedings of the 38th International Conference on Machine Learning, 1336-1348 (PMLR, 2021)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR40" id="ref-link-section-d44958756e550">40</a></sup>, we show that enhancing these models with long-range and multi-level predictions improves such brain mapping. Critically, and in line with predictive coding theory, our results reveal a hierarchical organization of language predictions in the cortex, in which the highest areas predict the most distant and highest-level representations.</p><div data-test="figure" data-container-section="figure" id="figure-1" data-title="Experimental approach."><figure><figcaption><b id="Fig1" data-test="figure-caption-text">Fig. 1: Experimental approach.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s41562-022-01516-2/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41562-022-01516-2/MediaObjects/41562_2022_1516_Fig1_HTML.png?as=webp"/><img aria-describedby="Fig1" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41562-022-01516-2/MediaObjects/41562_2022_1516_Fig1_HTML.png" alt="figure 1" loading="lazy" width="685" height="220"/></picture></a></div><p><b>a</b>, Deep language algorithms are typically trained to predict words from their close contexts. Unlike these algorithms, the brain makes, according to predictive coding theory, (1) long-range and (2) hierarchical predictions. <b>b</b>, To test this hypothesis, we first extracted the fMRI signals of 304 individuals each listening to ≈26 min of short stories (<i>Y</i>) as well as the activations of a deep language algorithm (<i>X</i>) input with the same stories. We then quantified the similarity between <i>X</i> and <i>Y</i> with a ‘brain score’: a Pearson correlation <span>\({{{\mathcal{R}}}}\)</span> after an optimal linear projection <i>W</i> (<a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Sec10">Methods</a>). <b>c</b>, To test whether adding representations of future words (or predicted words; Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41562-022-01516-2#MOESM1">4)</a> improves this correlation, we concatenated (<span>⊕</span>) the network’s activations (<i>X</i>, depicted here as a black rectangle) to the activations of a ‘forecast window’ (<span>\(\tilde{X}\)</span>, depicted here as a coloured rectangle). We used PCA to reduce the dimensionality of the forecast window down to the dimensionality of <i>X</i>. Finally, <span>\({{{\mathcal{F}}}}\)</span> quantifies the gain of brain score obtained by enhancing the activations of the language algorithm to this forecast window. We repeated this analysis with variably distant windows (<i>d</i>, <a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Sec10">Methods</a>). <b>d</b>, Top, a flat forecast score across distances indicates that forecast representations do not make the algorithm more similar to the brain. Bottom, by contrast, a forecast score peaking at <i>d</i> &gt; 1 would indicate that the model lacks brain-like forecast. The peak of <span>\({{{{\mathcal{F}}}}}^{d}\)</span> indicates how far off in the future the algorithm would need to forecast representations to be most similar to the brain.</p></div></figure></div></div></div></section><section data-title="Results"><div id="Sec2-section"><h2 id="Sec2">Results</h2><div id="Sec2-content"><h3 id="Sec3">Deep language models map onto brain activity</h3><p>First, we quantified the similarity between deep language models and the brain, when these two systems are inputted with the same stories. For this, we used the Narratives dataset<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 39" title="Nastase, S. A. et al. Narratives: fMRI data for evaluating models of naturalistic language comprehension. Sci. Data 8, 250 (2021)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR39" id="ref-link-section-d44958756e729">39</a></sup> and analysed the fMRI of 304 individuals listening to short stories (27 stories ranging from 7 to 56 min; 4.6 h of unique stimulus in total, 26 min on average per participant, from 7 to 99 min). We then fitted, for each voxel and each individual independently, a linear ridge regression to predict the fMRI signals from the activations of several deep language models. Finally, we computed the corresponding ‘brain scores’ using held-out data, that is, the voxel-wise correlation between the fMRI signals and the predictions of the ridge regression input with the activations of a given language model (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig1">1b</a>). For clarity, we first focused on the activations of the eighth layer of Generative Pre-trained Transformer 2 (GPT-2), a 12-layer causal deep neural network provided by HuggingFace<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Radford, A. et al. Language models are unsupervised multitask Learners (2019)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR2" id="ref-link-section-d44958756e736">2</a></sup> because it best predicts brain activity<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Caucheteux, C. &amp; King, J.-R. Brains and algorithms partially converge in natural language processing. Commun Biol. 5, 134 (2022)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR7" id="ref-link-section-d44958756e740">7</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Schrimpf, M. et al. The neural architecture of language: Integrative modeling converges on predictive processing. Proceedings of the National Academy of Sciences, Vol. 118, e2105646118 (Proceedings of the National Academy of Sciences, 2020)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR8" id="ref-link-section-d44958756e743">8</a></sup>.</p><p>In line with previous studies<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Jain, S. and Huth, A. G. Incorporating context into language encoding models for fMRI. In Proc. 32nd Conference on Neural Information Processing Systems (NeurIPS 2018), Vol. 31, (Curran Associates, 2018)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR5" id="ref-link-section-d44958756e750">5</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Caucheteux, C. &amp; King, J.-R. Brains and algorithms partially converge in natural language processing. Commun Biol. 5, 134 (2022)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR7" id="ref-link-section-d44958756e753">7</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 40" title="Caucheteux, C., Gramfort, A. &amp; King, J.-R. Disentangling syntax and semantics in the brain with deep networks. In Proceedings of the 38th International Conference on Machine Learning, 1336-1348 (PMLR, 2021)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR40" id="ref-link-section-d44958756e756">40</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 41" title="Wehbe, L., Vaswani, A., Knight, K. &amp; Mitchell, T. Aligning context-based statistical models of language with brain activity during reading. In Proc. 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP), 233–243 (Association for Computational Linguistics, 2014)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR41" id="ref-link-section-d44958756e759">41</a></sup>, the activations of GPT-2 accurately map onto a distributed and bilateral set of brain areas. Brain scores peaked in the auditory cortex and in the anterior temporal and superior temporal areas (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig2">2a</a>, Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41562-022-01516-2#MOESM1">1</a>, Supplementary Note <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41562-022-01516-2#MOESM1">1</a> and Supplementary Tables <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41562-022-01516-2#MOESM1">1–3</a>). The effect sizes of these brain scores are in line with previous work<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Caucheteux, C. &amp; King, J.-R. Brains and algorithms partially converge in natural language processing. Commun Biol. 5, 134 (2022)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR7" id="ref-link-section-d44958756e776">7</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 42" title="Huth, A. G., de Heer, W. A., Griffiths, T. L., Theunissen, F. E. &amp; Gallant, J. L. Natural speech reveals the semantic maps that tile human cerebral cortex. Nature 532, 453–458 (2016)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR42" id="ref-link-section-d44958756e779">42</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 43" title="Toneva, M., Mitchell, T. M. &amp; Wehbe, L. The meaning that emerges from combining words is robustly localizable in space but not in time. Preprint at bioRxiv 
                https://doi.org/10.1101/2020.09.28.316935
                
               (2020)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR43" id="ref-link-section-d44958756e782">43</a></sup>: for instance, the highest brain scores (<i>R</i> = 0.23 in the superior temporal sulcus (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig2">2a</a>)) represent 60% of the maximum explainable signal, as assessed with a noise ceiling analysis (<a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Sec10">Methods</a>). Supplementary Note <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41562-022-01516-2#MOESM1">2</a> and Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41562-022-01516-2#MOESM1">2</a> show that, on average, similar brain scores are achieved with other state-of-the-art language models and Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41562-022-01516-2#MOESM1">3</a> shows that auditory regions can be further improved with lower-level speech representations. As expected, the brain score of word rate (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41562-022-01516-2#MOESM1">3)</a>, noise ceiling (<a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Sec10">Methods</a>) and GPT-2 (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig2">2a</a>) all peak in the language network<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 44" title="Fedorenko, E. et al. Neural correlate of the construction of sentence meaning. Proc. Natl. Acad. Sci. USA 113, E6256–E6262 (2016)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR44" id="ref-link-section-d44958756e814">44</a></sup>. Overall, these results confirm that deep language models linearly map onto brain responses to spoken stories.</p><div data-test="figure" data-container-section="figure" id="figure-2" data-title="Isolating language predictions and their temporal scope in the human brain."><figure><figcaption><b id="Fig2" data-test="figure-caption-text">Fig. 2: Isolating language predictions and their temporal scope in the human brain.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s41562-022-01516-2/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41562-022-01516-2/MediaObjects/41562_2022_1516_Fig2_HTML.png?as=webp"/><img aria-describedby="Fig2" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41562-022-01516-2/MediaObjects/41562_2022_1516_Fig2_HTML.png" alt="figure 2" loading="lazy" width="685" height="375"/></picture></a></div><p><b>a</b>, The ‘brain score’ (<span>\({{{\mathcal{R}}}}\)</span>; Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig1">1b</a> and <a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Sec10">Methods</a>), obtained with GPT-2, for each individual and each voxel, here averaged across individuals (<i>n</i> = 304). Only the voxels with significant brain scores are colour-coded. <b>b</b>, Average (across voxels) brain scores obtained with GPT-2 with (grey) or without (blue) forecast representations. The average brain score peaks at <i>d</i><sup>*</sup> = 8 (grey star). <b>c</b>, For each voxel, the average (across individuals) ‘forecast score’ <span>\({{{{\mathcal{F}}}}}^{d}\)</span>, that is<i>,</i> the gain in brain score when concatenating the activations of GPT-2 with a forecast window <span>\({\tilde{X}}^{(8)}\)</span> is shown. Only the voxels with significant forecast scores are colour-coded. <b>d</b>, Average (across voxels) forecast scores for different distance <i>d</i>. <b>e</b>, Distance that maximizes <span>\({{{{\mathcal{F}}}}}^{d}\)</span>, computed for each individual and each voxel and denoted <i>d</i><sup>*</sup>. This ‘forecast distance’ reveals the regions associated with short- and long-range forecasts. Regions in red and blue are associated with long-range and short-range forecasts, respectively. We only display the voxels with a significant average peak (<span>\({{{{\mathcal{F}}}}}^{{d}^{* }}-{{{{\mathcal{F}}}}}^{0},{d}^{* }=\,8\)</span>; <a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Sec10">Methods</a>). <b>f</b>, Forecast score within two regions of interest. For each region, we report the average forecast scores of individuals with a representative peak (individuals whose peak belongs to the 45–55 percentiles of all peaks, <i>n</i> = 30 individuals). <b>g</b>, Forecast distance of seven regions of interest, computed for each voxel of each individual and then averaged within the selected brain regions. For all panels, we report the average effect across individuals (<i>n</i> = 304), with the 95% CIs across individuals (<b>b</b>,<b>d</b>,<b>f</b>). <i>P</i> values were assessed with a two-sided Wilcoxon signed-rank test across individuals. In <b>a</b>,<b>c</b>,<b>e</b>, <i>P</i> values were corrected for multiple comparisons across voxels using the FDR and brain maps are thresholded at <i>P</i> &lt; 0.01. The boxplot in <b>g</b> summarizes the distribution of the effect obtained on ten distinct and random subdivisions of the dataset.</p></div></figure></div><h3 id="Sec4">Isolating long-range predictions in the brain</h3><p>Next, we tested whether enhancing the activations of language models with long-range predictions leads to higher brain scores (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig1">1c,d</a>). Specifically, for each word, we concatenated (1) the model activations of the present word (denoted <i>X</i>) and (2) a ‘forecast window’ (denoted <span>\({\tilde{X}}^{(d)}\)</span>), consisting of the embeddings of future words and parameterized by a temporal distance <i>d</i> and width of <i>w</i> = 7 words (see Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41562-022-01516-2#MOESM1">4</a> for the growing window analysis). While the width is the number of concatenated words, <i>d</i> corresponds to the distance between the current word and the last word of the window. For instance, <span>\({\tilde{X}}^{(10)}\)</span> is the concatenation of words at distances 4, 5 and up to 10 from the current word, and <span>\({\tilde{X}}^{(8)}\)</span> is the concatenation of words at distances 2, 3 and up to 8 from the current word. For each distance <i>d</i>, we computed the ‘forecast score’ (denoted <span>\({{{{\mathcal{F}}}}}^{d}\)</span>) by comparing the brain scores obtained with and without the forecast representations (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig2">2b</a>).</p><p>Our results show that <span>\({{{\mathcal{F}}}}\)</span> is maximal for a distance of <i>d</i> = 8 words and peaks in the areas typically associated with language processing (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig2">2b–d</a>). For comparison, there are 2.54 words per second on average in the stimuli. Thus, 8 words correspond to 3.15 s of audio (the time of two successive fMRI scans). These forecast scores are bilaterally distributed in the brain, except for the inferior-frontal and supramarginal gyri (<i>P</i> &lt; 0.001 in the pars opercularis and supramarginal, using a two-sided pairwise Wilcoxon rank-sum test between the left and right hemispheres, after correcting for multiple comparisons (<a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Sec10">Methods</a>)).</p><p>Supplementary analyses confirm that (1) each future word from word zero to ten significantly contributes to the forecast effect, (2) forecast representations are best captured with a window size of around 8 words, (3) random forecast representations do not improve brain scores and (4) using the words generated by GPT-2 instead of the true future words achieves lower but similar results (Supplementary Notes <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41562-022-01516-2#MOESM1">3</a>–<a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41562-022-01516-2#MOESM1">5</a> and Supplementary Figs. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41562-022-01516-2#MOESM1">4–</a><a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41562-022-01516-2#MOESM1">6)</a>.</p><p>Together, these results reveal long-range forecast representations in the brain representing a 23% (±9% across individuals) improvement in brain scores (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig2">2a,b</a>).</p><h3 id="Sec5">The time range of predictions varies along the brain hierarchy</h3><p>Both anatomical and functional studies have shown that the cortex is organized as a hierarchy<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 28" title="Wacongne, C. et al. Evidence for a hierarchy of predictions and prediction errors in human cortex. Proc. Natl Acad. Sci. USA 108, 20754–20759 (2011)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR28" id="ref-link-section-d44958756e1402">28</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 45" title="Felleman, D. J. &amp; Van Essen, D. C. Distributed hierarchical processing in the primate cerebral cortex. Cereb. Cortex 1, 1–47 (1991)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR45" id="ref-link-section-d44958756e1405">45</a></sup>: for example, low-level acoustics, phonemes and semantics are primarily encoded in Heschl’s gyrus, the superior temporal gyrus and the associative cortices of the frontal, temporal and parietal lobes, respectively<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 42" title="Huth, A. G., de Heer, W. A., Griffiths, T. L., Theunissen, F. E. &amp; Gallant, J. L. Natural speech reveals the semantic maps that tile human cerebral cortex. Nature 532, 453–458 (2016)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR42" id="ref-link-section-d44958756e1409">42</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Lerner, Y., Honey, C. J., Silbert, L. J. &amp; Hasson, U. Topographic mapping of a hierarchy of temporal receptive windows using a narrated story. J. Neurosci. 31, 2906–2915 (2011)." href="#ref-CR46" id="ref-link-section-d44958756e1412">46</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Kell, A. J. E., Yamins, D. L. K., Shook, E. N., Norman-Haignere, S. V. &amp; McDermott, J. H. A task-optimized neural network replicates human auditory behavior, predicts brain responses, and reveals a cortical processing hierarchy. Neuron 98, 630–644 (2018)." href="#ref-CR47" id="ref-link-section-d44958756e1412_1">47</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Mesgarani, N., Cheung, C., Johnson, K. &amp; Chang, E. F. Phonetic feature encoding in human superior temporal gyrus. Science 343, 1006–1010 (2014)." href="#ref-CR48" id="ref-link-section-d44958756e1412_2">48</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 49" title="Hickok, G. &amp; Poeppel, D. The cortical organization of speech processing. Nat. Rev. Neurosci. 8, 393–402 (2007)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR49" id="ref-link-section-d44958756e1415">49</a></sup>.</p><p>Do the different levels of this cortical hierarchy predict the same time window? To address this issue, we estimated the peak of the forecast score of each voxel and denoted <i>d</i><sup>*</sup> the corresponding distance. The results show that the prefrontal area forecast, on average, is further off in the future than temporal areas (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig2">2e</a>). For instance, <i>d</i><sup>*</sup> in the inferior temporal gyrus (IFG) is higher than in the anterior superior temporal sulcus (aSTS) (Δ<i>d</i><sup>*</sup> = 0.9 ± 0.2, <i>P</i> &lt; 0.001; Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig2">2f,g</a>).</p><p>The variation of optimal forecast distance along the temporo-parietal-frontal axis is largely symmetric across the two hemispheres (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41562-022-01516-2#MOESM1">1)</a>.</p><h3 id="Sec6">Predictions are increasingly contextual along the hierarchy</h3><p>What is the nature of these predictive representations? To address this issue, we assessed whether the forecast score relates to (1) low or high as well as (2) syntactic or semantic representations. To this aim, we computed the forecast scores as in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig1">1c</a> but varied the layer used from GPT-2. Then, we identified <i>k</i><sup>*</sup> for each voxel, that is, the depth that maximizes the forecast scores (<a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Sec10">Methods</a>). We considered that the deep layers of language algorithms encode higher-level and more contextualized representations than their first layers<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 50" title="Jawahar, G., Sagot, B. &amp; Seddah, D. What Does BERT learn about the structure of language? In Proc. 57th Annual Meeting of the Association for Computational Linguistics, 3651–3657 (Association for Computational Linguistics, 2019)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR50" id="ref-link-section-d44958756e1468">50</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 51" title="Manning, C. D., Clark, K., Hewitt, J., Khandelwal, U. &amp; Levy, O. Emergent linguistic structure in artificial neural networks trained by self-supervision. Proc. Natl. Acad. Sci. USA 117, 30046–30054 (2020)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR51" id="ref-link-section-d44958756e1471">51</a></sup>.</p><p>Our results showed that the optimal forecast depth varies along the expected cortical hierarchy (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig3">3a</a>). Specifically, associative cortices are best modelled with deeper forecasts (<i>k</i><sup>*</sup> &gt; 6) than low-level language areas (for example, <i>k</i><sup>*</sup> &lt; 6 in Heschl’s gyri/sulci, aSTS; Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig3">3a,b</a>). The difference between regions, while small on average, was highly significant across individuals (for example, between the angular and Heschl’s gyri: Δ<i>k</i><sup>*</sup> = 2.5 ± 0.3, <i>P</i> &lt; 0.001) and observed in both the left and right hemispheres (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig3">3b</a>).</p><div data-test="figure" data-container-section="figure" id="figure-3" data-title="Organization of hierarchical predictions in the brain."><figure><figcaption><b id="Fig3" data-test="figure-caption-text">Fig. 3: Organization of hierarchical predictions in the brain.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s41562-022-01516-2/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41562-022-01516-2/MediaObjects/41562_2022_1516_Fig3_HTML.png?as=webp"/><img aria-describedby="Fig3" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41562-022-01516-2/MediaObjects/41562_2022_1516_Fig3_HTML.png" alt="figure 3" loading="lazy" width="685" height="385"/></picture></a></div><p><b>a</b>, Depth of the representation that maximizes the forecast score in the brain, denoted <i>k</i><sup>*</sup>. Forecast scores were computed for each depth, individual and voxel, at a fixed distance of <i>d</i><sup>*</sup> = 8 and averaged across individuals. We computed the optimal depth for each individual and voxel and plotted the average forecast depth across individuals. Dark regions are best accounted for by deep forecasts, while light regions are best accounted for by shallow forecasts. Only significant voxels are colour-coded as in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig2">2c</a>). <b>b</b>, Same as <b>a</b> but with <i>k</i><sup>*</sup> averaged across the voxels of nine regions of interest, in the left (circle) and right (triangle) hemispheres. Scores were averaged across individuals (<i>n</i> = 304) and the boxplot summarizes the distribution of the effect obtained on ten distinct and random subdivisions of the dataset. Pairwise significance between regions was assessed using a two-sided Wilcoxon rank-sum test on the left hemisphere’s scores (the grey bars indicate <i>P</i> &lt; 0.001).</p></div></figure></div><p>Together, these results suggest that the long-range predictions of frontoparietal cortices are more contextualized and of higher level than the short-term predictions of low-level brain regions.</p><h3 id="Sec7">Syntactic and semantic predictions show different time ranges</h3><p>To factorize forecast representations into syntactic and semantic components, we applied a method introduced in Caucheteux et al.<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 40" title="Caucheteux, C., Gramfort, A. &amp; King, J.-R. Disentangling syntax and semantics in the brain with deep networks. In Proceedings of the 38th International Conference on Machine Learning, 1336-1348 (PMLR, 2021)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR40" id="ref-link-section-d44958756e1565">40</a></sup> and proceeded as follows: for each word and its preceding context, we generated ten possible futures, which matches the syntax of the true future words. We chose <i>k</i> = 10 possible futures following<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 40" title="Caucheteux, C., Gramfort, A. &amp; King, J.-R. Disentangling syntax and semantics in the brain with deep networks. In Proceedings of the 38th International Conference on Machine Learning, 1336-1348 (PMLR, 2021)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR40" id="ref-link-section-d44958756e1572">40</a></sup>. For each of these possible futures, we extracted the corresponding GPT-2 activations and averaged them across the ten possible futures (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig4">4a</a> and <a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Sec10">Methods</a>). This method allowed us to decompose the activations of a given language model <i>X</i> into syntactic (the average vector, denoted <i>X</i><sub>syn</sub>) and semantic components (the residuals, <i>X</i><sub>sem</sub> = <i>X</i> − <i>X</i><sub>syn</sub>) (<a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Sec10">Methods</a>). Once the syntactic and semantic forecast windows were built, we computed the corresponding forecast scores (<a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Sec10">Methods</a>).</p><div data-test="figure" data-container-section="figure" id="figure-4" data-title="Factorizing syntactic and semantic predictions in the brain."><figure><figcaption><b id="Fig4" data-test="figure-caption-text">Fig. 4: Factorizing syntactic and semantic predictions in the brain.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s41562-022-01516-2/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41562-022-01516-2/MediaObjects/41562_2022_1516_Fig4_HTML.png?as=webp"/><img aria-describedby="Fig4" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41562-022-01516-2/MediaObjects/41562_2022_1516_Fig4_HTML.png" alt="figure 4" loading="lazy" width="685" height="401"/></picture></a></div><p><b>a</b>, Method to extract syntactic and semantic forecast representations, adapted from Caucheteux et al.<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 40" title="Caucheteux, C., Gramfort, A. &amp; King, J.-R. Disentangling syntax and semantics in the brain with deep networks. In Proceedings of the 38th International Conference on Machine Learning, 1336-1348 (PMLR, 2021)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR40" id="ref-link-section-d44958756e1622">40</a></sup>. For each word and its context (for example, ‘Great, your <i>paper</i> ... ’, we generated ten possible futures with the same syntax as the original sentence (part of speech and dependency tree) but randomly sampled semantics (for example, ‘... remains so true’, ‘... appears so small’). Then, we extracted the corresponding GPT-2 activations (layer eight). Finally, we averaged the activations across the ten futures. This method allowed us to extract the syntactic component common to the ten futures, denoted <i>X</i><sub>syn</sub>. The semantic component was defined as the residuals of syntax in the full activations; <i>X</i><sub>sem</sub> = <i>X</i> − <i>X</i><sub>syn</sub>. We built the syntactic and semantic forecast windows by concatenating the syntactic and semantic components of seven consecutive future words, respectively (<a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Sec10">Methods</a>). <b>b</b>, Syntactic (blue) and semantic (red) forecast scores, on average across all voxels, as in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig2">2c</a>. Scores were averaged across individuals; the shaded regions indicate the 95% CIs across individuals (<i>n</i> = 304). The average peaks across individuals are indicated with a star. <b>c</b>, Semantic forecast scores for each voxel, averaged across individuals and at <i>d</i><sup>*</sup> = 8, the distance that maximizes the semantic forecast scores in <b>b</b>. Only significant voxels are displayed as in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig2">2c</a>. <b>d</b>, Same as <b>c</b> for syntactic forecast scores and <i>d</i><sup>*</sup> = 5.</p></div></figure></div><p>The results show that semantic forecasts are long range (<i>d</i><sup>*</sup> = 8) and involve a distributed network peaking in the frontal and parietal lobes. By contrast, syntactic forecasts (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig4">4b</a>) are relatively short range (<i>d</i><sup>*</sup> = 5) and localized in the superior temporal and left frontal areas (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig4">4c,d</a>). Note that the syntactic model without a forecast window (which has a lower dimensionality) performs better than the syntactic model with a distant forecast window. Such diminished scores can occur when there is no added information in the extra dimension of the regression because of the infamous curse of dimensionality<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 52" title="Bellman, R. Dynamic programming. Science 153, 34–37 (1966)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR52" id="ref-link-section-d44958756e1708">52</a></sup>. This suggests that a long-range syntactic forecast is not detectable in the present dataset.</p><p>Overall, these results reveal multiple levels of predictions in the brain in which the superior temporal cortex predominantly predicts short-term, shallow and syntactic representations whereas the inferior-frontal and parietal areas predominantly predict long-term, contextual, high-level and semantic representations.</p><h3 id="Sec8">Adapting GPT-2 into a predictive coding architecture</h3><p>These results show that concatenating present and future word representations of GPT-2 leads to a better modelling of brain activity, especially in frontoparietal areas (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig2">2)</a>. Does fine-tuning GPT-2 to predict longer-range, more contextual and higher-level representations improve brain mapping in such regions? To answer this question, we fine-tuned GPT-2 on Wikipedia, not only using language modelling (that is, predicting the next word), but also a high-level and long-range objective (that is, predicting high-level representations of far-off words). Specifically, the high-level objective is to predict layer 8 of the pretrained GPT-2 model, of word t + 8 (<a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Sec10">Methods</a>). The results show that GPT-2 fine-tuned with high-level and long-range modelling best accounts for frontoparietal responses (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig5">5</a>, &gt;2% gain in the IFG and angular/supramarginal gyri on average, all <i>P</i> &lt; 0.001). On the other hand, auditory areas and lower-level brain regions do not significantly benefit from such a high-level objective (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig5">5</a> and Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41562-022-01516-2#MOESM1">7)</a>. These results further strengthen the role of frontoparietal areas in predicting long-range, contextual and high-level representations of language.</p><div data-test="figure" data-container-section="figure" id="figure-5" data-title="Gain in brain score when fine-tuning GPT-2 with a mixture of language modelling and high-level prediction."><figure><figcaption><b id="Fig5" data-test="figure-caption-text">Fig. 5: Gain in brain score when fine-tuning GPT-2 with a mixture of language modelling and high-level prediction.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s41562-022-01516-2/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41562-022-01516-2/MediaObjects/41562_2022_1516_Fig5_HTML.png?as=webp"/><img aria-describedby="Fig5" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41562-022-01516-2/MediaObjects/41562_2022_1516_Fig5_HTML.png" alt="figure 5" loading="lazy" width="685" height="334"/></picture></a></div><p><b>a</b>, Gain in brain scores between GPT-2 fine-tuned with language modelling plus high-level prediction (for <i>α</i><sub>high level</sub> = 0.5) and GPT-2 fine-tuned with language modelling alone. Only the voxels with a significant gain are displayed (<i>P</i> &lt; 0.05 with a two-sided Wilcoxon rank-sum test after FDR correction for multiple comparisons). <b>b</b>, Brain score gain as a function of the high-level weight <i>α</i> in the loss (equation (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Equ8">8</a>)), from full language modelling (left, <i>α</i> = 0) to full high-level prediction (right, <i>α</i> = 1). Gains were averaged across voxels within six regions of interests (see <a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Sec10">Methods</a> for the parcellation and Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41562-022-01516-2#MOESM1">7</a> for the other regions in the brain). Scores were averaged across individuals and we display the 95% CIs across individuals (<i>n</i> = 304).</p></div></figure></div></div></div></section><section data-title="Discussion"><div id="Sec9-section"><h2 id="Sec9">Discussion</h2><div id="Sec9-content"><p>In the present study, we put specific hypotheses of predictive coding theory to the test<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Rumelhart, D. E. &amp; McClelland, J. L. An interactive activation model of context effects in letter perception: Part 2. The contextual enhancement effect and some tests and extensions of the model. Psychol. Rev. 89, 60–94 (1982)." href="#ref-CR25" id="ref-link-section-d44958756e1805">25</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Rao, R. P. &amp; Ballard, D. H. Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. Nat. Neurosci. 2, 79–87 (1999)." href="#ref-CR26" id="ref-link-section-d44958756e1805_1">26</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 27" title="Friston, K. &amp; Kiebel, S. Predictive coding under the free-energy principle. Philos. Trans. R. Soc. Lond. B Biol. Sci. 364, 1211–1221 (2009)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR27" id="ref-link-section-d44958756e1808">27</a></sup>. While deep language algorithms are typically trained to make nearby and word-level predictions<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Vaswani, A. et al. Attention is all you need. In Advances in Neural Information Processing Systems, Vol. 30 (Curran Associates, 2017)." href="#ref-CR1" id="ref-link-section-d44958756e1812">1</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Radford, A. et al. Language models are unsupervised multitask Learners (2019)." href="#ref-CR2" id="ref-link-section-d44958756e1812_1">2</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Brown, T. B. et al. Language models are few-shot learners. In Advances in Neural Information Processing Systems, Vol. 33, 1877-1901 (Curran Associates, 2020)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR3" id="ref-link-section-d44958756e1815">3</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Devlin, J., Chang, M.-W., Lee, K. &amp; Toutanova, K. BERT: pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 1, 4171–4186, (Association for Computational Linguistics, 2019)." href="#ref-CR53" id="ref-link-section-d44958756e1818">53</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Liu, Y. et al. RoBERTa: a robustly optimized BERT pretraining approach. Preprint at arXiv 
                https://doi.org/10.48550/arXiv.1907.11692
                
               (2019)." href="#ref-CR54" id="ref-link-section-d44958756e1818_1">54</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 55" title="Clark, K., Luong, M.-T. &amp; Le, Q. V. &amp; Manning, C. D. ELECTRA: pre-training text encoders as discriminators rather than generators. Preprint at arXiv 
                https://doi.org/10.48550/arXiv.2003.10555
                
               (2020)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR55" id="ref-link-section-d44958756e1821">55</a></sup>, we assessed whether cortical hierarchy predicts multiple levels of representations, spanning multiple timescales. With this aim in mind, we compared activations of the brain to those of state-of-the-art deep language models<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Jain, S. and Huth, A. G. Incorporating context into language encoding models for fMRI. In Proc. 32nd Conference on Neural Information Processing Systems (NeurIPS 2018), Vol. 31, (Curran Associates, 2018)." href="#ref-CR5" id="ref-link-section-d44958756e1825">5</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Toneva, M. &amp; Wehbe, L. Interpreting and improving natural-language processing (in machines) with natural language-processing (in the brain). In Advances in Neural Information Processing Systems, Vol. 32 (Curran Associates, 2019)." href="#ref-CR6" id="ref-link-section-d44958756e1825_1">6</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Caucheteux, C. &amp; King, J.-R. Brains and algorithms partially converge in natural language processing. Commun Biol. 5, 134 (2022)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR7" id="ref-link-section-d44958756e1828">7</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 42" title="Huth, A. G., de Heer, W. A., Griffiths, T. L., Theunissen, F. E. &amp; Gallant, J. L. Natural speech reveals the semantic maps that tile human cerebral cortex. Nature 532, 453–458 (2016)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR42" id="ref-link-section-d44958756e1831">42</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 56" title="Caucheteux, C., Gramfort, A. &amp; King, J.-R. Deep language algorithms predict semantic comprehension from brain activity. Sci Rep. 12, 16327 (2022)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR56" id="ref-link-section-d44958756e1834">56</a></sup>. We successfully validated our hypothesis on a cohort of 304 participants listening to spoken narratives<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 39" title="Nastase, S. A. et al. Narratives: fMRI data for evaluating models of naturalistic language comprehension. Sci. Data 8, 250 (2021)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR39" id="ref-link-section-d44958756e1838">39</a></sup>. Brain activity is best explained by the activations of deep language algorithms enhanced with long-range and high-level predictions. Our study provides three additional contributions.</p><p>First, the lateral, dorsolateral and inferior-frontal cortices and the supramarginal gyrus exhibited the longest forecast distances. Interestingly, these cortical regions were repeatedly linked to high-level semantics, long-term planning, attentional control, abstract thinking and other high-level executive functions<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 57" title="Gilbert, S. J. &amp; Burgess, P. W. Executive function. Curr. Biol. 18, R110–R114 (2008)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR57" id="ref-link-section-d44958756e1845">57</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 58" title="Shallice, T. &amp; Burgess, P. Deficits in strategy application following frontal lobe damage in man. Brain 114, 727–741 (1991)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR58" id="ref-link-section-d44958756e1848">58</a></sup>. This result echoes with previous studies showing that the integration constant of the frontoparietal cortices is larger than those of sensory and temporal areas<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 46" title="Lerner, Y., Honey, C. J., Silbert, L. J. &amp; Hasson, U. Topographic mapping of a hierarchy of temporal receptive windows using a narrated story. J. Neurosci. 31, 2906–2915 (2011)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR46" id="ref-link-section-d44958756e1852">46</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Wang, L. et al. Dynamic predictive coding across the left fronto-temporal language hierarchy: evidence from MEG, EEG and fMRI. Preprint at bioRxiv 
                https://doi.org/10.1101/2021.02.17.431452
                
               (2021)." href="#ref-CR59" id="ref-link-section-d44958756e1855">59</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Lee, C. S., Aly, M. &amp; Baldassano, C. Anticipation of temporally structured events in the brain. eLife 10, e64972 (2021)." href="#ref-CR60" id="ref-link-section-d44958756e1855_1">60</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 61" title="Caucheteux, C., Gramfort, A. and King, J.-R. Model-based analysis of brain activity reveals the hierarchy of language in 305 subjects. In Proc. EMNLP 2021, Conference on Empirical Methods in Natural Language Processing 3635–3644 (Association for Computational Linguistics, 2021)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR61" id="ref-link-section-d44958756e1858">61</a></sup>. Specifically, our findings suggest that these regions, located at the top of the language hierarchy, are not limited to passively integrating past stimuli but actively anticipate future language representations.</p><p>Second, we showed that the depth of predictive representations varies along a similar anatomical organization: low-level predictions best model the superior temporal sulcus and gyrus, while high-level predictions best model the middle temporal, parietal and frontal areas. This finding extends previous studies investigating the multiplicity of predictions underlying complex sound or speech processing<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 28" title="Wacongne, C. et al. Evidence for a hierarchy of predictions and prediction errors in human cortex. Proc. Natl Acad. Sci. USA 108, 20754–20759 (2011)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR28" id="ref-link-section-d44958756e1865">28</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 34" title="Heilbron, M., Armeni, K., Schoffelen, J.-M., Hagoort, P. &amp; de Lange, F. P. A hierarchy of linguistic predictions during natural language comprehension. Proc. Natl. Acad. Sci. USA 119, e2201968119 (2022)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR34" id="ref-link-section-d44958756e1868">34</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 36" title="Donhauser, P. W. &amp; Baillet, S. Two distinct neural timescales for predictive speech processing. Neuron 105, 385–393 (2020)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR36" id="ref-link-section-d44958756e1871">36</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 62" title="Vidal, Y., Brusini, P., Bonfieni, M., Mehler, J. &amp; Bekinschtein, T. A. Neural signal to violations of abstract rules using speech-like stimuli. eNeuro 6, ENEURO.0128-19.2019 (2019)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR62" id="ref-link-section-d44958756e1874">62</a></sup>. While previous studies focused on correlating brain activity with a subset of hand-crafted and unidimensional prediction errors (for example, word or phoneme surprisal), the present analyses explored and decomposed high-dimensional predictions. More generally, our results support the idea that, unlike current language algorithms, the brain is not limited to predict word-level representations but rather predicts multiple levels of representations.</p><p>Finally, we decomposed these neural activations into syntactic and semantic representations and showed that semantic features, as opposed to syntactic ones, drive long-range forecasts. This finding strengthens the idea that while syntax may be explicitly represented in neural activity<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 40" title="Caucheteux, C., Gramfort, A. &amp; King, J.-R. Disentangling syntax and semantics in the brain with deep networks. In Proceedings of the 38th International Conference on Machine Learning, 1336-1348 (PMLR, 2021)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR40" id="ref-link-section-d44958756e1881">40</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 63" title="Nelson, M. J. et al. Neurophysiological dynamics of phrase-structure building during sentence processing. Proc. Natl Acad. Sci. USA 114, E3669–E3678 (2017)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR63" id="ref-link-section-d44958756e1884">63</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 64" title="Ding, N., Melloni, L., Zhang, H., Tian, X. &amp; Poeppel, D. Cortical tracking of hierarchical linguistic structures in connected speech. Nat. Neurosci. 19, 158–164 (2016)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR64" id="ref-link-section-d44958756e1887">64</a></sup>, predicting high-level semantics may be at the core of long-form language processing<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 65" title="Jackendoff, R. &amp; Jackendoff, R. S. Foundations of Language: Brain, Meaning, Grammar, Evolution (Oxford Univ. Press, 2002)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR65" id="ref-link-section-d44958756e1891">65</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 66" title="Shain, C. et al. ‘Constituent length’ effects in fMRI do not provide evidence for abstract syntactic processing. Preprint at bioRxiv 
                https://doi.org/10.1101/2021.11.12.467812
                
               (2021)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR66" id="ref-link-section-d44958756e1894">66</a></sup>.</p><p>Together, these results support predictive coding theories, whereby the brain continually predicts sensory inputs, compares these predictions to the truth and updates its internal model accordingly<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Rumelhart, D. E. &amp; McClelland, J. L. An interactive activation model of context effects in letter perception: Part 2. The contextual enhancement effect and some tests and extensions of the model. Psychol. Rev. 89, 60–94 (1982)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR25" id="ref-link-section-d44958756e1902">25</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 26" title="Rao, R. P. &amp; Ballard, D. H. Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. Nat. Neurosci. 2, 79–87 (1999)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR26" id="ref-link-section-d44958756e1905">26</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 67" title="McClelland, J. L. &amp; Rumelhart, D. E. An interactive activation model of context effects in letter perception: I. An account of basic findings. Psychol. Rev. 88, 375–407 (1981)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR67" id="ref-link-section-d44958756e1908">67</a></sup>. Our study further clarifies this general framework. Not only does the brain predict sensory inputs but each region of the cortical hierarchy is organized to predict different temporal scopes and different levels of representations (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig1">1a</a>). However, the link between hierarchical constructs in syntax and functional hierarchy in the cortex and in the model is a major question to explore<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 40" title="Caucheteux, C., Gramfort, A. &amp; King, J.-R. Disentangling syntax and semantics in the brain with deep networks. In Proceedings of the 38th International Conference on Machine Learning, 1336-1348 (PMLR, 2021)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR40" id="ref-link-section-d44958756e1915">40</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 51" title="Manning, C. D., Clark, K., Hewitt, J., Khandelwal, U. &amp; Levy, O. Emergent linguistic structure in artificial neural networks trained by self-supervision. Proc. Natl. Acad. Sci. USA 117, 30046–30054 (2020)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR51" id="ref-link-section-d44958756e1918">51</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 68" title="Hale, J. T. et al. Neurocomputational models of language processing. Ann. Rev. Linguist. 8, 427–446 (2022)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR68" id="ref-link-section-d44958756e1921">68</a></sup>.</p><p>This computational organization is at odds with current language algorithms, which are mostly trained to make adjacent and word-level predictions (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig1">1a</a>). Some studies investigated alternative learning rules<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Fan, A., Lewis, M. and Dauphin, Y. Hierarchical Neural Story Generation. In Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), 889–898 (Association for Computational Linguistics, 2018)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR4" id="ref-link-section-d44958756e1931">4</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 53" title="Devlin, J., Chang, M.-W., Lee, K. &amp; Toutanova, K. BERT: pre-training of deep bidirectional transformers for language understanding. In Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, 1, 4171–4186, (Association for Computational Linguistics, 2019)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR53" id="ref-link-section-d44958756e1934">53</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 55" title="Clark, K., Luong, M.-T. &amp; Le, Q. V. &amp; Manning, C. D. ELECTRA: pre-training text encoders as discriminators rather than generators. Preprint at arXiv 
                https://doi.org/10.48550/arXiv.2003.10555
                
               (2020)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR55" id="ref-link-section-d44958756e1937">55</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Jernite, Y., Bowman, S. R. &amp; Sontag, D. Discourse-based objectives for fast unsupervised sentence representation learning. Preprint at arXiv 
                https://doi.org/10.48550/arXiv.1705.00557
                
               (2017)." href="#ref-CR69" id="ref-link-section-d44958756e1940">69</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Lewis, M. et al. BART: denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. In Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics, 7871–7880 (Association for Computational Linguistics, 2020)." href="#ref-CR70" id="ref-link-section-d44958756e1940_1">70</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Yang, Z. et al. XLNet: generalized autoregressive pretraining for language understanding. In Advances in Neural Information Processing Systems, 32 (Curran Associates, 2019)." href="#ref-CR71" id="ref-link-section-d44958756e1940_2">71</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 72" title="Joshi, M. et al. SpanBERT: Improving Pre-training by Representing and Predicting Spans. In Transactions of the Association for Computational Linguistics 8, 64–77 (2020)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR72" id="ref-link-section-d44958756e1943">72</a></sup> but they did not combine both long-range and high-level predictions. We speculate that the brain architecture evidenced in this study presents at least one major benefit over its current deep learning counterparts. While future observations rapidly become indeterminate in their original format, their latent representations may remain predictable over long periods. This issue is already pervasive in speech- and image-based algorithms and has been partially bypassed with losses based on pretrained embedding<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 73" title="Szegedy, C. et al. Going deeper with convolutions. In Proc. 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR), 1–9 (IEEE, 2015)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR73" id="ref-link-section-d44958756e1947">73</a></sup>, contrastive learning and, more generally, joint embedding architectures<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Chen, T., Kornblith, S., Norouzi, M. &amp; Hinton, G. A simple framework for contrastive learning of visual representations. In Proceedings of the 37th International Conference on Machine Learning, 149 (2020)." href="#ref-CR74" id="ref-link-section-d44958756e1951">74</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="He, K., Fan, H., Wu, Y., Xie, S. and Girshick, R. Momentum contrast for unsupervised visual representation learning. Preprint at arXiv 
                https://doi.org/10.48550/arXiv.1911.05722
                
               (2020)." href="#ref-CR75" id="ref-link-section-d44958756e1951_1">75</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="El-Nouby, A. et al. XCiT: cross-covariance image transformers. In Advances in Neural Information Processing Systems, 34, 20014–20027 (Curran Associates, 2021)." href="#ref-CR76" id="ref-link-section-d44958756e1951_2">76</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 77" title="Bardes, A., Ponce, J. &amp; LeCun, Y. VICReg: variance-invariance-covariance regularization for self-supervised learning. In International Conference on Learning Representations (2022)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR77" id="ref-link-section-d44958756e1954">77</a></sup>. In this study, we highlight that this issue also prevails in language models, where word sequences, but arguably not their meaning, rapidly become unpredictable. Our results suggests that predicting multiple levels of representations over multiple temporal scopes may be critical to address the indeterminate nature of such distant observations and adjust their relative confidence accordingly<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 78" title="Kepecs, A., Uchida, N., Zariwala, H. A. &amp; Mainen, Z. F. Neural correlates, computation and behavioural impact of decision confidence. Nature 455, 227–231 (2008)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR78" id="ref-link-section-d44958756e1958">78</a></sup>.</p><p>Three main elements mitigate these conclusions. First, unlike temporally resolved techniques<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Caucheteux, C. &amp; King, J.-R. Brains and algorithms partially converge in natural language processing. Commun Biol. 5, 134 (2022)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR7" id="ref-link-section-d44958756e1965">7</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Goldstein, A. et al. Shared computational principles for language processing in humans and deep language models. Nat Neurosci. 25, 369–380 (2022)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR11" id="ref-link-section-d44958756e1968">11</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 36" title="Donhauser, P. W. &amp; Baillet, S. Two distinct neural timescales for predictive speech processing. Neuron 105, 385–393 (2020)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR36" id="ref-link-section-d44958756e1971">36</a></sup>, the temporal resolution of fMRI is around 1.5 s and can thus hardly be used to investigate sublexical predictions. Second, the precise representations and predictions computed in each region of the cortical hierarchy are to be characterized. This will probably require new probing techniques because the interpretation of neural representations is a major challenge to both artificial intelligence and neuroscience. Finally, the predictive coding architecture presently tested is rudimentary. A systematic generalization, scaling and evaluation of this approach on natural language processing benchmarks is necessary to demonstrate the effective utility of making models more similar to the brain.</p><p>Beyond clarifying the brain and computational bases of language, our study thus calls for systematically training algorithms to predict multiple timescales and levels of representations.</p></div></div></section><section data-title="Methods"><div id="Sec10-section"><h2 id="Sec10">Methods</h2><div id="Sec10-content"><h3 id="Sec11">Notations</h3><p>We denote:</p><ul>
                <li>
                  <p><i>w</i> as a sequence of <i>M</i> words (that is, several short stories);</p>
                </li>
                <li>
                  <p><i>X</i> as the activations of a deep language model input with <i>w</i>, of size <i>M</i> × <i>U</i>, with <i>U</i> as the dimensionality of the embeddings (for a layer of GPT-2, <i>U</i> = 768). Except if stated otherwise, we used the activations extracted from the eighth layer of a 12-layer GPT-2 model. We explicitly denote <i>X</i><sub><i>k</i></sub> as the activations extracted from layer <i>k</i> when using another layer;</p>
                </li>
                <li>
                  <p><i>Y</i> as the fMRI recordings elicited by <i>w</i>, of size <i>T</i> × <i>V</i>, with <i>T</i> as the number of fMRI time samples and <i>V</i> as the number of voxels;</p>
                </li>
                <li>
                  <p><span>\({{{\mathcal{R}}}}(X)\)</span> as the brain score of <i>X</i>;</p>
                </li>
                <li>
                  <p><span>\({\widetilde{X}}^{(d)}\)</span> as the forecast window containing information up to <i>d</i> words in the future. Briefly, the forecast window is the concatenation of the deep net activations of seven successive words, the last word being at a distance <i>d</i> from the current word;</p>
                </li>
                <li>
                  <p><span>\({{{{\mathcal{F}}}}}^{(d)}(X)\)</span> as the forecast score at distance <i>d</i>, that is, the gain in brain score when concatenating the forecast window <span>\({\tilde{X}}^{(d)}\)</span> to the network’s activations; <span>\({{{{\mathcal{F}}}}}^{(d)}(X)={{{\mathcal{R}}}}(X\oplus {\tilde{X}}^{(d)})-{{{\mathcal{R}}}}(X)\)</span>;</p>
                </li>
                <li>
                  <p><i>d</i><sup>*</sup> as the distance maximizing the forecast score; <span>\({d}^{* }={{{{\rm{argmax}}}}}_{d\in [-10,\ldots,30]}\,{{{{\mathcal{F}}}}}^{(d)}(X)\)</span>;</p>
                </li>
                <li>
                  <p><i>k</i><sup>*</sup> as the network’s depth maximizing the forecast score at a fixed distance <i>d</i> = 8; <span>\({k}^{* }={{{{\rm{argmax}}}}}_{k\in [0,\ldots ,12]}\,{{{{\mathcal{F}}}}}^{(8)}({X}_{k})\)</span>, with <i>X</i><sub><i>k</i></sub> as the activations extracted from the <i>k</i><sup>th</sup> layer of GPT-2. We used <i>d</i> = 8 because it was the distance with the best forecast score on average across individuals and voxels.</p>
                </li>
              </ul><h3 id="Sec12">fMRI dataset</h3><p>We used the brain recordings (denoted <i>Y</i>) of the Narratives dataset<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 39" title="Nastase, S. A. et al. Narratives: fMRI data for evaluating models of naturalistic language comprehension. Sci. Data 8, 250 (2021)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR39" id="ref-link-section-d44958756e2670">39</a></sup>, a publicly available dataset containing the fMRI recordings of 345 individuals listening to 27 spoken stories in English, from 7 to 56 min (4.6 h of unique stimulus in total). We use the preprocessed fMRI signals from the original dataset, without spatial smoothing (referred to as ‘afni-nosmooth’ in the repository) and sampled with TR = 1.5 s. The preprocessing steps were performed using fMRIPrep<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 79" title="Esteban, O. et al. fMRIPrep: a robust preprocessing pipeline for functional MRI. Nat. Methods 16, 111–116 (2019)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR79" id="ref-link-section-d44958756e2674">79</a></sup>; no temporal filtering was applied. The resulting preprocessing led to the analysis of cortical voxels projected onto the surface and morphed onto an ‘fsaverage’ template brain; hereafter, they are referred to as voxels for simplicity. As suggested in the original paper, some individual–story pairs were excluded because of noise, resulting in 304 individuals and 622 individual–story pairs and 4 h of unique audio material in total.</p><h3 id="Sec13">Activations of deep language models</h3><p>We compared the fMRI recordings with the activations of several pretrained deep language model inputs with the same sentences presented to the individuals. For clarity, we primarily focused on GPT-2, a high-performing causal language model trained to predict words given their previous context. GPT-2 consists of 12 Transformer modules<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Vaswani, A. et al. Attention is all you need. In Advances in Neural Information Processing Systems, Vol. 30 (Curran Associates, 2017)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR1" id="ref-link-section-d44958756e2686">1</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Radford, A. et al. Language models are unsupervised multitask Learners (2019)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR2" id="ref-link-section-d44958756e2689">2</a></sup>, each of them referred to as ‘layer’, stacked onto one non-contextual word embedding layer. We used the pretrained models from Huggingface<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 80" title="Wolf, T. et al. Transformers: State-of-the-art natural language processing. In Proc. 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, 38–45 (Association for Computational Linguistics, 2020)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR80" id="ref-link-section-d44958756e2693">80</a></sup> (1.5 billion parameters trained on 8 million Web pages).</p><p>In practice, to extract the activations <i>X</i> elicited by a sequence of <i>M</i> words <i>w</i> from the <i>k</i><sup>th</sup> layer of the network, we (1) formatted the textual transcript of the sequence <i>w</i> (replacing special punctuation marks such as ‘-’ and duplicated marks ‘?.’ by dots), (2) tokenized the text using the Huggingface tokenizer, (3) inputted the network with the tokens and (4) extracted the corresponding activations from layer <i>k</i>. This resulted in a vector of size <i>M</i> × <i>U</i>, with <i>M</i> the number of words and <i>U</i> the number of units per layer (that is, <i>U</i> = 768). Given the constrained context size of the network, each word was successively inputted to the network with at most 1,024 previous tokens. For instance, while the third word’s vector was computed by inputting the network with (<i>w</i><sub>1</sub>, <i>w</i><sub>2</sub>, <i>w</i><sub>3</sub>), the last word’s vector <i>w</i><sub><i>M</i></sub> was computed by inputting the network with (<i>w</i><sub><i>M</i>−1,024</sub>,…,<i>w</i><sub><i>M</i></sub>). The alignment between the audio recordings of the stories and their textual transcripts was provided in the original Narratives database<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 39" title="Nastase, S. A. et al. Narratives: fMRI data for evaluating models of naturalistic language comprehension. Sci. Data 8, 250 (2021)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR39" id="ref-link-section-d44958756e2768">39</a></sup>.</p><h3 id="Sec14">Brain scores</h3><p>Following previous works<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Caucheteux, C. &amp; King, J.-R. Brains and algorithms partially converge in natural language processing. Commun Biol. 5, 134 (2022)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR7" id="ref-link-section-d44958756e2780">7</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 42" title="Huth, A. G., de Heer, W. A., Griffiths, T. L., Theunissen, F. E. &amp; Gallant, J. L. Natural speech reveals the semantic maps that tile human cerebral cortex. Nature 532, 453–458 (2016)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR42" id="ref-link-section-d44958756e2783">42</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 56" title="Caucheteux, C., Gramfort, A. &amp; King, J.-R. Deep language algorithms predict semantic comprehension from brain activity. Sci Rep. 12, 16327 (2022)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR56" id="ref-link-section-d44958756e2786">56</a></sup>, we evaluated, for each individual <i>s</i> and voxel <i>v</i>, the mapping between (1) the fMRI activations <i>Y</i><sup>(<i>s</i>,<i>v</i>)</sup> in response to the audio stories and (2) the activations <i>X</i> of the deep network input with the textual transcripts of the same stories. To this end, we fitted a linear ridge regression <i>W</i> on a training set to predict the fMRI scans given the network’s activations. Then, we evaluated this mapping by computing the Pearson correlation between predicted and actual fMRI scans on a held-out set:</p><div id="Equ1"><p><span>$${{{{\mathcal{R}}}}}^{(s,v)}:X\mapsto {{{\rm{corr}}}}\left(W\cdot X,{Y}^{(s,v)}\right)$$</span></p><p>
                    (1)
                </p></div><p>with <i>W</i> as the fitted linear projection, corr as Pearson’s correlation, <i>X</i> as the activations of GPT-2 and <i>Y</i><sup>(<i>s</i>,<i>v</i>)</sup> as the fMRI scans of one individual <i>s</i> at one voxel <i>v</i>, both elicited by the same held-out stories.</p><p>In practice and following Huth et al.<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 42" title="Huth, A. G., de Heer, W. A., Griffiths, T. L., Theunissen, F. E. &amp; Gallant, J. L. Natural speech reveals the semantic maps that tile human cerebral cortex. Nature 532, 453–458 (2016)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR42" id="ref-link-section-d44958756e2940">42</a></sup>, we modelled the slow bold response thanks to a finite impulse response (FIR) model with six delays (from 0 to 9 s, TR = 1.5 s). Still following Huth et al.<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 42" title="Huth, A. G., de Heer, W. A., Griffiths, T. L., Theunissen, F. E. &amp; Gallant, J. L. Natural speech reveals the semantic maps that tile human cerebral cortex. Nature 532, 453–458 (2016)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR42" id="ref-link-section-d44958756e2944">42</a></sup>, we summed the model activations of the words presented within the same TR to match the sampling frequency of the fMRI and language models (Supplementary Figs. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41562-022-01516-2#MOESM1">8</a> and <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41562-022-01516-2#MOESM1">9)</a>. Then, we estimated the linear mapping <i>W</i> with an <i>ℓ</i><sub>2</sub>-penalized linear regression after standardizing the data and reducing their dimensionality (for computational reasons). We implemented scikit-learn<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 81" title="Pedregosa, F. et al. Scikit-learn: machine learning in Python. J. Mach. Learn. Res. 12, 2825–2830 (2011)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR81" id="ref-link-section-d44958756e2962">81</a></sup> and used a pipeline with the following steps: (1) standardization of the features (set to 0 mean with an s.d. of 1 using a StandardScaler), (2) principal component analysis (PCA) with 20 components and (3) <i>ℓ</i><sub>2</sub>-penalized linear regression (RidgeCV in scikit-learn). In Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41562-022-01516-2#MOESM1">3c</a>, we replicated the main analyses without PCA (the brain scores and forecast effect were slightly underestimated by the PCA). The regularization hyperparameter of the RidgeCV was selected with a nested leave-one-out cross-validation among ten possible values log-spaced between 10<sup>−1</sup> and 10<sup>8</sup> for each voxel and each training fold.</p><p>The outer cross-validation scheme, which allows for an independent performance evaluation, uses five folds obtained by splitting the fMRI time series into five contiguous chunks. The Pearson correlations averaged across the five test folds is called ‘brain score’ and denoted as <span>\({{{{\mathcal{R}}}}}^{(s,v)}(X)\)</span>. It measures the mapping between the activation space <i>X</i> and the brain of one individual <i>s</i> at one voxel <i>v</i> in response to the same language stimulus.</p><p>In Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig2">2a,b</a>, brain scores were computed for each (individual, voxel) pair. We then averaged brain scores across individuals (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig2">2a</a>) and/or voxels (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig2">2b</a>) depending on the analysis. For simplicity, we denote <span>\({{{\mathcal{R}}}}(X)\)</span> as the brain scores averaged across individuals and/or voxels.</p><h3 id="Sec15">Forecast windows</h3><p>We tested whether adding forecast representations would improve our ability to predict brain activity. To this aim, we did not modify the deep network itself but added forecast representations to the encoding model’s input, that is, the forecast window. The forecast window at distance <i>d</i>, denoted by <span>\({\widetilde{X}}^{(d)}\)</span>, is the concatenation of the network’s activations of seven successive words, the last one being at a distance <i>d</i> from the current word. Precisely, the forecast window of a word <i>w</i><sub><i>n</i></sub> at a distance <i>d</i> is the concatenation of the network’s activations elicited by words <i>w</i><sub><i>n</i> + <i>d</i>−6</sub>, …, <i>w</i><sub><i>n</i> + <i>d</i></sub>. Thus,</p><div id="Equ2"><p><span>$${\widetilde{X}}^{(d)}={({X}_{{w}_{n+d-7}}\oplus \cdots \oplus {X}_{{w}_{n+d}})}_{n\in [1,\ldots ,M]}$$</span></p><p>
                    (2)
                </p></div><p>with <span>⊕</span> as the concatenation operator and <i>M</i> as the number of words in the transcript <i>w</i> (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41562-022-01516-2#MOESM1">9</a>). Note that <i>d</i> can be negative: in that case, the forecast window only contains past information. Except if stated otherwise, the forecast window was built out of the activations <i>X</i> extracted from the eighth layer of GPT-2. In Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig3">3</a>, the forecast window was built out of the activations <i>X</i><sub><i>k</i></sub> extracted from different layers <i>k</i> of GPT-2. We denoted <span>\({\widetilde{X}}_{k}^{(d)}\)</span> as the corresponding forecast windows. In Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig4">4</a>, the forecast windows were built out of the syntactic (<i>X</i><sub>syn</sub>) and semantic (<i>X</i><sub>sem</sub>) activations of GPT-2.</p><h3 id="Sec16">Forecast scores</h3><p>For each distance <i>d</i>, individual <i>s</i> and voxel <i>v</i>, we computed the ‘forecast score’ <span>\({{{{\mathcal{F}}}}}^{(d,s,v)}\)</span>, which is the gain in brain score when concatenating the forecast windows to the present GPT-2 activations. Thus,</p><div id="Equ3"><p><span>$${{{{\mathcal{F}}}}}^{(d,s,v)}:X\mapsto {{{{\mathcal{R}}}}}^{(s,v)}(X\oplus {\widetilde{X}}^{(d)})-{{{\mathcal{R}}}}(X)$$</span></p><p>
                    (3)
                </p></div><p>To match the dimensionality of <i>X</i> and <span>\(\tilde{X}\)</span>, the PCA used to compute the mapping was trained on <i>X</i> and <span>\(\tilde{X}\)</span> separately before concatenating the two features, that is, <span>\({{{\mathcal{F}}}}(X)={{{\mathcal{R}}}}({{{\rm{PCA}}}}(X)+{{{\rm{PCA}}}}(\tilde{X}))-{{{\mathcal{R}}}}({{{\rm{PCA}}}}(X))\)</span>.</p><h3 id="Sec17">Forecast distance</h3><p>To test whether the forecast scope varied along the cortical hierarchy, we estimated the distance maximizing the forecast score. Precisely, the optimal ‘forecast distance’ <i>d</i><sup>*</sup> for each individual <i>s</i> and voxel <i>v</i> was defined as:</p><div id="Equ4"><p><span>$${d}_{(s,v)}^{* }={{{{\rm{argmax}}}}}_{d\in [-10,\ldots ,30]}{{{{\mathcal{F}}}}}^{(d,s,v)}(X)$$</span></p><p>
                    (4)
                </p></div><p>with <i>X</i> as the activations of the language model and <span>\({{{{\mathcal{F}}}}}^{(d,s,v)}\)</span> as the forecast score at distance <i>d</i> for individual <i>s</i> and voxel <i>v</i> (equation (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Equ3">3</a>)). The forecast distances <i>d</i><sup>*</sup> were then averaged across individuals and/or voxels depending on the analyses.</p><p>The present analysis is only relevant for the brain regions for which forecast scores are not flat. Indeed, computing the distance maximizing a flat curve would be misleading. Thus, in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig2">2e</a>, we computed the difference <span>\({{{{\mathcal{F}}}}}^{8}-{{{{\mathcal{F}}}}}^{0}\)</span> for each individual and voxel, assessed the significance with a Wilcoxon rank-sum test across individuals and ignored the voxels with a non-significant difference (<i>P</i> &gt; 0.01).</p><h3 id="Sec18">Forecast’s depth</h3><p>To test whether the depth of the forecast varied along the cortical hierarchy, we computed the forecast score for different depths of representation. We replaced <i>X</i> by the activations <i>X</i><sub><i>k</i></sub> extracted from layer <i>k</i> of GPT-2 (<i>k</i> <span>∈</span> [0, …, 12]) in equations (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Equ3">3</a>) and (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Equ2">4</a>). Then, we computed the depth maximizing the forecast score, called ‘forecast depth’, and given by:</p><div id="Equ5"><p><span>$${k}_{(d,s,v)}^{* }={{{{\rm{argmax}}}}}_{k\in [0,\ldots ,12]}{{{{\mathcal{F}}}}}^{(d,s,v)}({X}_{k})$$</span></p><p>
                    (5)
                </p></div><p>with <span>\({{{{\mathcal{F}}}}}^{(d,s,v)}({X}_{k})={{{{\mathcal{R}}}}}^{(s,v)}({X}_{k}\oplus {\widetilde{{X}_{k}}}^{(d)})-{{{\mathcal{R}}}}({X}_{k})\)</span> (equation (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Equ3">3</a>)). For simplicity, we studied the depth focusing on the fixed distance <i>d</i> = 8 (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig3">3c,d</a>), which maximizes the forecast score in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig2">2</a>.</p><h3 id="Sec19">Decomposing model activations into syntactic and semantic components</h3><p>To extract the syntactic and semantic components of <i>X</i>, a vector of activations in response to a story <i>w</i>, we applied a method introduced in Caucheteux et al.<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 40" title="Caucheteux, C., Gramfort, A. &amp; King, J.-R. Disentangling syntax and semantics in the brain with deep networks. In Proceedings of the 38th International Conference on Machine Learning, 1336-1348 (PMLR, 2021)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR40" id="ref-link-section-d44958756e4520">40</a></sup> (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig4">4a</a>). For each word, (1) we generated <i>n</i> = 10 futures of the same syntax as the true future (that is, same part of speech and dependency tags as the true future) but randomly sampled semantics, (2) we computed the activations for each of the 10 possible futures and (3) we averaged the activations across the 10 futures. We used the same hyperparameter <i>n</i> = 10 as in the original paper. The method actually converges from n = 7 (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41562-022-01516-2#MOESM1">8</a> in the paper). This method allows to extract the average vector <i>X</i><sub>syn</sub>, which contains syntactic information but is deprived of semantic information. The semantic activations <i>X</i><sub>sem</sub> = <i>X</i> − <i>X</i><sub>syn</sub> are the residuals of syntax in the full activations <i>X</i>. In the original paper (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig3">3</a>), the authors checked with probing analyses that the syntactic embeddings encoded relevant syntactic information (part of speech and depth of the syntactic tree) and no longer encoded semantic information (word frequency, word embedding, semantic category).</p><h3 id="Sec20">Syntactic and semantic forecast windows</h3><p>To investigate syntactic and semantic forecasts in the brain, we built forecast windows out of the syntactic and semantic activations of GPT-2, respectively. To this aim, we first built the forecast windows out of GPT-2 activations <span>\({\widetilde{X}}^{(d)}\)</span>. Then, we extracted the syntactic <span>\({\widetilde{X}}_{{{{\rm{syn}}}}}^{(d)}\)</span> and semantic <span>\({\widetilde{X}}_{{{{\rm{sem}}}}}^{(d)}\)</span> components of the concatenated activations, as introduced in Caucheteux et al.<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 40" title="Caucheteux, C., Gramfort, A. &amp; King, J.-R. Disentangling syntax and semantics in the brain with deep networks. In Proceedings of the 38th International Conference on Machine Learning, 1336-1348 (PMLR, 2021)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR40" id="ref-link-section-d44958756e4717">40</a></sup>. Finally, the syntactic forecast score is the increase in brain score when concatenating the syntactic window:</p><div id="Equ6"><p><span>$${{{{\mathcal{F}}}}}_{{{{\rm{syn}}}}}^{(d)}={{{\mathcal{R}}}}(X\oplus {\widetilde{X}}_{{{{\rm{syn}}}}}^{(d)})-{{{\mathcal{R}}}}(X)$$</span></p><p>
                    (6)
                </p></div><p>Similarly, the semantic forecast score is given by:</p><div id="Equ7"><p><span>$${{{{\mathcal{F}}}}}_{{{{\rm{sem}}}}}^{(d)}={{{\mathcal{R}}}}(X\oplus {\widetilde{X}}_{{{{\rm{sem}}}}}^{(d)})-{{{\mathcal{R}}}}(X)$$</span></p><p>
                    (7)
                </p></div><h3 id="Sec21">Brain parcellation</h3><p>We systematically implemented whole-brain analyses and computed scores for each voxel in the brain. Yet, for simplicity, we report the scores averaged across selected regions of interest in Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig2">2f,g</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig3">3c</a>. To this aim, we used a subdivision of the Destrieux atlas<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 82" title="Destrieux, C., Fischl, B., Dale, A. &amp; Halgren, E. Automatic parcellation of human cortical gyri and sulci using standard anatomical nomenclature. Neuroimage 53, 1–15 (2010)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR82" id="ref-link-section-d44958756e4984">82</a></sup>. Regions with more than 500 vertices were split into smaller parts. This resulted in 142 regions per hemisphere, each containing fewer than 500 vertices.</p><div><div><div data-component-scroll-wrapper=""><table><thead><tr><th colspan="2"><p>This results in 142 regions per hemisphere, each containing fewer than 500 vertices</p></th></tr></thead><tbody><tr><td><p>STG / STS</p></td><td><p>Superior temporal gyrus / sulcus</p></td></tr><tr><td><p>aSTS</p></td><td><p>Anterior STS</p></td></tr><tr><td><p>mSTS</p></td><td><p>Mid STS</p></td></tr><tr><td><p>pSTS</p></td><td><p>Posterior STS</p></td></tr><tr><td><p>Angular / Supramar</p></td><td><p>Angular / Supramarginal inferior parietal gyrus</p></td></tr><tr><td><p>IFG / IFS</p></td><td><p>Inferior frontal gyrus / sulcus</p></td></tr><tr><td><p>Tri / Op</p></td><td><p>Pars triangularis / opercularis (IFG)</p></td></tr><tr><td><p>Heschl G / Heschl S</p></td><td><p>Heschl gyrus / sulcus</p></td></tr></tbody></table></div></div></div><h3 id="Sec22">Statistical significance</h3><p>We systematically implemented single-individual and whole-brain analyses: all metrics (brain score, forecast score, forecast distance and depth) were computed for each individual–voxel pair. We report the metrics averaged across individuals and/or voxels depending on the analysis. Statistics were computed across individuals using a two-sided Wilcoxon rank-sum test from Scipy<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 83" title="Virtanen, P. et al. SciPy 1.0: fundamental algorithms for scientific computing in Python. Nat. Methods 17, 261–272 (2020)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR83" id="ref-link-section-d44958756e5124">83</a></sup> assessing whether the metric (or the difference between two metrics) was significantly different from zero and then corrected for multiple comparisons using the false discovery rate (FDR). We report an effect as significant if <i>P</i> &lt; 0.01. The shaded regions in Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig2">2</a>, <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig4">4</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig5">5</a> correspond to the 95% confidence intervals (CIs) across individuals (<i>n</i> = 304). The boxplots in Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig2">2</a>–<a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig5">5</a> summarize the distribution of the effect obtained on 10 distinct and random subdivisions of the dataset.</p><h3 id="Sec23">Noise ceiling</h3><p>The fMRI recordings are inherently noisy. To assess the amount of explainable signal, we used a ‘noise ceiling’ analysis, that is, we predicted the brain responses <i>Y</i><sup>(<i>s</i>)</sup> of each individual <i>s</i> given the responses of the other individuals to the same story <span>\(\overline{Y}\)</span>. We proceeded similarly as the brain score computation and applied the same setting as equation (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Equ1">1</a>) but used the average brain signals of other individuals’ brains <span>\({\overline{Y}}^{(s)}=\frac{1}{| {{{\mathcal{S}}}}| }{\sum }_{{s}^{{\prime} }\ne s}{Y}^{({s}^{{\prime} })}\)</span> (of size <i>T</i> × <i>V</i>) instead of the network’s activations <i>X</i>. Precisely:</p><ul>
                <li>
                  <p>For the brain score computation, <i>Y</i><sup>(<i>s</i>)</sup> represents the fMRI recordings of individual <i>s</i>, corresponding to all the stories individual <i>s</i> listened to while being scanned. <i>X</i> consists of the contextual embeddings of the corresponding words, summed within each TR and transformed with FIR. Thus,</p><div id="Equa"><p><span>$${R}_{{{{\rm{brain}}\ {\rm{score}}}}}(s)={{{\rm{corr}}}}[{W}^{(s)}\cdot X,{Y}^{(s)}]$$</span></p></div><p>with <i>X</i> as the GPT-2 embeddings, temporally aligned with <i>Y</i> using FIR.</p>
                </li>
                <li>
                  <p>For the noise ceiling computation, <i>Y</i><sup>(<i>s</i>)</sup> is the same as for the brain score computation. <i>X</i> consists of the average fMRI recordings of the other individuals who listened to the same stories as individual <i>s</i>. <i>X</i> and <i>Y</i> have the same dimensionality and the bold delay is assumed to be comparable across individuals, so we did not apply a FIR to X. Thus,</p><div id="Equb"><p><span>$${R}_{{{{\rm{noise}}\ {\rm{ceiling}}}}}(s)={{{\rm{corr}}}}[{W}^{(s)}\cdot {\overline{Y}}^{(s)},{Y}^{(s)}]$$</span></p></div><p>with <i>Y</i><sup>(<i>s</i>)</sup> as the average fMRI of the other individuals who listened to the same story as individual <i>s</i>.</p>
                </li>
              </ul><p>For both the brain score and noise ceiling computation, we fitted a ridge regression <i>W</i><sup>(<i>s</i>)</sup> for each individual <i>s</i>, predicting <i>Y</i><sup>(<i>s</i>)</sup> given <i>X</i>, using the same fivefold cross-validation setting. We evaluated the prediction successively on the five test folds using Pearson correlation and averaged the correlation scores across folds. This resulted in one brain score and one noise ceiling estimate per individual (and voxel). Results averaged across individuals are displayed in Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41562-022-01516-2#MOESM1">10</a>. This score is one possible upper bound for the best brain score that can be obtained given the level of noise in the dataset.</p><h3 id="Sec24">Fine-tuning GPT-2 with a long-range and high-level objective</h3><p>Does fine-tuning GPT-2 to predict long-term, high-level and more contextualized representations increase its similarity with the brain?</p><p>To test this question, we fine-tuned GPT-2 using a mixture of language modelling loss and high-level and long-term loss. We then evaluated brain scores and test whether the high-level objective would lead to significantly higher brain scores than the language modelling objective.</p><h4 id="Sec25">Architecture and losses</h4><p>We fine-tuned the pretrained GPT-2 model provided by Huggingface with a mixture of language modelling and high-level forecast. The mixture loss was parameterized by a hyperparameter <i>α</i> <span>∈</span> [0,1]. The total loss minimized is given by:</p><div id="Equ8"><p><span>$${{{\mathcal{L}}}}={\alpha }^{{\prime} }{{{{\mathcal{L}}}}}_{\mathrm{high-level}}+(1-{\alpha }^{{\prime} }){{{{\mathcal{L}}}}}_{\mathrm{language}\ {\mathrm{modelling}}}$$</span></p><p>
                    (8)
                </p></div><p>with the constraint that <span>\({\alpha }^{{\prime} }{{{{\mathcal{L}}}}}_{\mathrm{high-level}}=\alpha (1-{\alpha }^{{\prime} }){{{{\mathcal{L}}}}}_{\mathrm{language}\ {\mathrm{modelling}}}\)</span>. Doing so, setting <i>α</i> to 0.5 means that each term of the loss contributes to 50% of the total loss. The language modelling objective predicts the next word and it is given by:</p><div id="Equc"><p><span>$${{{{\mathcal{L}}}}}_{\mathrm{language}\ {\mathrm{modelling}}}={{{\rm{CE}}}}\left[{h}_{\mathrm{language}\ {\mathrm{modelling}}}\circ f({x}_{t}),{x}_{t+1}\right]$$</span></p></div><p>with:</p><ul>
                  <li>
                    <p>CE as the cross-entropy loss;</p>
                  </li>
                  <li>
                    <p><i>f</i> as the learned fine-tuned model. <i>f</i> is initialized with the weights of pretrained GPT-2. Thus, <i>f</i> is a 12-layers Transformer network stacked onto a word embedding, each layer having a dimensionality of 768;</p>
                  </li>
                  <li>
                    <p><span>\(h_{{\rm{language}}\,{\rm{modelling}}}\)</span> as the language modelling linear head on top of the last layer of <i>f</i>, from 768 to <i>n</i><sub>vocab</sub>, which predicts the next word;</p>
                  </li>
                  <li>
                    <p><i>x</i><sub><i>t</i></sub> as the input tokens;</p>
                  </li>
                  <li>
                    <p><i>x</i><sub><i>t</i> + 1</sub> as the input tokens shifted from one time step (the succeeding words).</p>
                  </li>
                </ul><p>The high-level objective predicts layer <i>k</i> of word at distance <i>d</i> from the current word and it is given by:</p><div id="Equd"><p><span>$${{{{\mathcal{L}}}}}_{\mathrm{high-level}}^{k,d}={{{\rm{CPC}}}}[{h}_{\mathrm{high-level}}\circ f({x}_{t}),{N}^{k}({x}_{t+d})]$$</span></p></div><p>where:</p><ul>
                  <li>
                    <p><i>N</i><sup><i>k</i></sup> is a separate and fixed network. Here, we use the pretrained version of GPT-2 provided by Huggingface, taken at layer <i>k</i>. Its weights are fixed: they do not vary with training.</p>
                  </li>
                  <li>
                    <p><span>\(h_{{\rm{high}}\hbox{-}{\rm{level}}}\)</span> is a linear head on top of the last layer of <i>f</i>, from 768 to 768, which predicts the activations of the <i>k</i><sup>th</sup> layer of the fixed network <i>N</i><sup><i>k</i></sup>, corresponding to the word at distance <i>d</i> from the current word.</p>
                  </li>
                  <li>
                    <p><i>x</i> represents the inputs, <i>x</i><sub><i>t</i></sub> marks the current words and <i>x</i><sub><i>t</i> + <i>d</i></sub> marks the words at distance <i>d</i> from the current word.</p>
                  </li>
                  <li>
                    <p>CPC is the contrastive predicting coding loss<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 84" title="Hénaff, O. J. et al. Data-efficient image recognition with contrastive predictive coding. In Proceedings of the 37th International Conference on Machine Learning, 4182–4192 (PMLR, 2020)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR84" id="ref-link-section-d44958756e6385">84</a></sup>.</p><div id="Eque"><p><span>$${{{\rm{CPC}}}}=-{{{\rm{log}}}}\frac{{{{\rm{Exp}}}}\left[S\left({y}_{{{{\rm{predicted}}}}},{y}_{{{{\rm{true}}}},{{{\rm{positive}}}}}\right)/\tau \right]}{{\sum }_{\mathrm{negative}}{{{\rm{Exp}}}}\left[S\left({y}_{{{{\rm{predicted}}}}},{y}_{{{{\rm{true}}}},{{{\rm{negative}}}}}\right)/\tau \right]}$$</span></p></div><p>with <i>S</i> as a similarity metric, <i>y</i><sub>true,negative</sub> as a set of negative samples and <i>y</i><sub>true,positive</sub> as a set of positive samples.</p>
                  </li>
                </ul><p>In practice, we chose to predict the hidden states at layer <i>k</i> = 8 of the future word at distance <i>d</i> = 8. We chose layer <i>k</i> = 8 and <i>d</i> = 8 because it led to the best results (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig2">2d</a>). To compute the CPC loss, we took <i>τ</i> = 0.1 and used the cosine similarity as similarity metric <i>S</i>. We used 2,000 negatives randomly sampled from a negative queue (of size 2,500). The negative queue was updated at each batch by adding the hidden states to the non-target words from the current batch. Such hidden states were extracted from the pretrained network at layer <i>k</i> (<i>N</i><sup><i>k</i></sup>). For the high-level and language modelling losses to have a fixed contribution <i>α</i> and 1 − <i>α</i> over training, we updated the parameter <span>\({\alpha }^{{\prime} }\)</span> in equation (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Equ8">8</a>) every 100 gradient steps.</p><h4 id="Sec26">Dataset and training</h4><p>We fine-tuned GPT-2 on the already preprocessed English Wikipedia dataset (<a href="https://huggingface.co/datasets/wikipedia">https://huggingface.co/datasets/wikipedia</a>) consisting of 6M documents (30 GB) on 2 graphics processing units. We used the ‘Trainer’ implementation from Huggingface with the default training arguments (Adam optimizer, learning rate = 0.00005; see <a href="https://huggingface.co/docs/transformers/main_classes/trainer">https://huggingface.co/docs/transformers/main_classes/trainer</a> for the other default parameters). Because of memory constraints, we restricted the context size of GPT-2 to 256 tokens and used a batch size of 4 per device (thus, 2 × 4 × 256 = 1,024 tokens per batch and gradient updates). For stability, we fine-tune the top tier layers of the network (from layer 8 to layer 12), while the bottom layers were kept frozen. Fine-tuning the whole network with language modelling led to a significant drop in brain scores (with fixed training parameters). Losses were monitored on a separate evaluation set of 1,000 Wikipedia documents.</p><h4 id="Sec27">Evaluation</h4><p>We fine-tuned seven GPT-2 models with different high-level weight <i>α</i>, from a loss being full language modelling (<i>α</i> = 0), half language modelling and high-level (<i>α</i> = 0.5) to full high-level (<i>α</i> = 1). During the training, we saved ≈15 model checkpoints (regularly log-spaced between 0 and 10<sup>6</sup> gradient updates). For each model and step, we computed the brain scores of its concatenated layers [0,4,8,12] on the same Narratives dataset<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 39" title="Nastase, S. A. et al. Narratives: fMRI data for evaluating models of naturalistic language comprehension. Sci. Data 8, 250 (2021)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR39" id="ref-link-section-d44958756e6685">39</a></sup>. We chose to span all layers from 0 to 12 because representations could ‘move’ across layers during the fine-tuning, which could bias the results. We then averaged the brain scores across steps and assessed the gain of one network over another. In Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41562-022-01516-2#Fig5">5</a>, we report the gain averaged across individuals when adding increasingly more high-level prediction in the loss.</p><h3 id="Sec28">Reporting summary</h3><p>Further information on research design is available in the <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41562-022-01516-2#MOESM2">Nature Portfolio Reporting Summary</a> linked to this article.</p></div></div></section>
                </div><div>
            <section data-title="Data availability"><div id="data-availability-section"><h2 id="data-availability">Data availability</h2><div id="data-availability-content">
            
            <p>The Narratives dataset<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 39" title="Nastase, S. A. et al. Narratives: fMRI data for evaluating models of naturalistic language comprehension. Sci. Data 8, 250 (2021)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR39" id="ref-link-section-d44958756e6771">39</a></sup> is publicly available on OpenNeuro <a href="https://openneuro.org/datasets/ds002345/versions/1.1.4">https://openneuro.org/datasets/ds002345/versions/1.1.4</a>.</p>
          </div></div></section><section data-title="Code availability"><div id="code-availability-section"><h2 id="code-availability">Code availability</h2><div id="code-availability-content">
            
            <p>All analyses were performed using Python and scikit-learn<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 81" title="Pedregosa, F. et al. Scikit-learn: machine learning in Python. J. Mach. Learn. Res. 12, 2825–2830 (2011)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR81" id="ref-link-section-d44958756e6790">81</a></sup>. The fMRI data were analysed with nilearn (<a href="https://nilearn.github.io/stable/index.html">https://nilearn.github.io/stable/index.html</a>), mne-python<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Gramfort, A. et al. MEG and EEG data analysis with MNE-Python. Front. Neurosci. 7, 267 (2013)." href="#ref-CR85" id="ref-link-section-d44958756e6801">85</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Dai, Z. et al. Transformer-XL: attentive language models beyond a fixed-length context. In Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics, 2978–2988 (Association for Computational Linguistics, 2019)." href="#ref-CR86" id="ref-link-section-d44958756e6801_1">86</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Nunez-Elizalde, A. O., Huth, A. G. &amp; Gallant, J. L. Voxelwise encoding models with non-spherical multivariate normal priors. Neuroimage 197, 482–492 (2019)." href="#ref-CR87" id="ref-link-section-d44958756e6801_2">87</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 88" title="Dupré la Tour, T., Eickenberg, M., Nunez-Elizalde, A. O. &amp; Gallant, J. Feature-space selection with banded ridge regression. Neuroimage 264, 119728 (2022)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR88" id="ref-link-section-d44958756e6804">88</a></sup> and freesurfer (<a href="https://surfer.nmr.mgh.harvard.edu/">https://surfer.nmr.mgh.harvard.edu/</a>). Deep language models were analysed using the transformers library<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 80" title="Wolf, T. et al. Transformers: State-of-the-art natural language processing. In Proc. 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations, 38–45 (Association for Computational Linguistics, 2020)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR80" id="ref-link-section-d44958756e6815">80</a></sup>. Statistical significance was assessed using Scipy<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 83" title="Virtanen, P. et al. SciPy 1.0: fundamental algorithms for scientific computing in Python. Nat. Methods 17, 261–272 (2020)." href="https://www.nature.com/articles/s41562-022-01516-2#ref-CR83" id="ref-link-section-d44958756e6820">83</a></sup>.</p>
          </div></div></section><div id="MagazineFulltextArticleBodySuffix"><section aria-labelledby="Bib1" data-title="References"><div id="Bib1-section"><h2 id="Bib1">References</h2><div id="Bib1-content"><div data-container-section="references"><ol data-track-component="outbound reference"><li data-counter="1."><p id="ref-CR1">Vaswani, A. et al. Attention is all you need. In <i>Advances in Neural Information Processing Systems</i>, Vol. 30 (Curran Associates, 2017).</p></li><li data-counter="2."><p id="ref-CR2">Radford, A. et al. Language models are unsupervised multitask Learners (2019).</p></li><li data-counter="3."><p id="ref-CR3">Brown, T. B. et al. Language models are few-shot learners. In <i>Advances in Neural Information Processing Systems</i>, Vol. 33, 1877-1901 (Curran Associates, 2020).</p></li><li data-counter="4."><p id="ref-CR4">Fan, A., Lewis, M. and Dauphin, Y. Hierarchical Neural Story Generation. In <i>Proceedings of the 56th Annual Meeting of the Association for Computational Linguistics</i> (Volume 1: Long Papers), 889–898 (Association for Computational Linguistics, 2018).</p></li><li data-counter="5."><p id="ref-CR5">Jain, S. and Huth, A. G. Incorporating context into language encoding models for fMRI. In <i>Proc. 32nd Conference on Neural Information Processing Systems (NeurIPS 2018),</i> Vol. 31, (Curran Associates, 2018).</p></li><li data-counter="6."><p id="ref-CR6">Toneva, M. &amp; Wehbe, L. Interpreting and improving natural-language processing (in machines) with natural language-processing (in the brain). In <i>Advances in Neural Information Processing Systems</i>, Vol. 32 (Curran Associates, 2019).</p></li><li data-counter="7."><p id="ref-CR7">Caucheteux, C. &amp; King, J.-R. Brains and algorithms partially converge in natural language processing. <i>Commun Biol</i>. <b>5</b>, 134 (2022).</p></li><li data-counter="8."><p id="ref-CR8">Schrimpf, M. et al. The neural architecture of language: Integrative modeling converges on predictive processing. <i>Proceedings of the National Academy of Sciences,</i> Vol. 118, e2105646118 (Proceedings of the National Academy of Sciences, 2020).</p></li><li data-counter="9."><p id="ref-CR9">Toneva, M., Mitchell, T. M. &amp; Wehbe, L. Combining computational controls with natural text reveals new aspects of meaning composition. <i>Nat. Comput. Sci.</i> <b>2</b>, 745–757 (2022).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s43588-022-00354-6" data-track-action="article reference" href="https://doi.org/10.1038%2Fs43588-022-00354-6" aria-label="Article reference 9" data-doi="10.1038/s43588-022-00354-6">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=36777107" aria-label="PubMed reference 9">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC9912822" aria-label="PubMed Central reference 9">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 9" href="http://scholar.google.com/scholar_lookup?&amp;title=Combining%20computational%20controls%20with%20natural%20text%20reveals%20new%20aspects%20of%20meaning%20composition&amp;journal=Nat.%20Comput.%20Sci.&amp;doi=10.1038%2Fs43588-022-00354-6&amp;volume=2&amp;pages=745-757&amp;publication_year=2022&amp;author=Toneva%2CM&amp;author=Mitchell%2CTM&amp;author=Wehbe%2CL">
                    Google Scholar</a> 
                </p></li><li data-counter="10."><p id="ref-CR10">Reddy, A. J. &amp; Wehbe, L. Syntactic representations in the human brain: beyond effort-based metrics. Preprint at <i>bioRxiv</i> <a href="https://doi.org/10.1101/2020.06.16.155499">https://doi.org/10.1101/2020.06.16.155499</a> (2021).</p></li><li data-counter="11."><p id="ref-CR11">Goldstein, A. et al. Shared computational principles for language processing in humans and deep language models. <i>Nat Neurosci.</i> <b>25</b>, 369–380 (2022).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41593-022-01026-4" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41593-022-01026-4" aria-label="Article reference 11" data-doi="10.1038/s41593-022-01026-4">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB38XmsFajt7s%3D" aria-label="CAS reference 11">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=35260860" aria-label="PubMed reference 11">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC8904253" aria-label="PubMed Central reference 11">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 11" href="http://scholar.google.com/scholar_lookup?&amp;title=Shared%20computational%20principles%20for%20language%20processing%20in%20humans%20and%20deep%20language%20models&amp;journal=Nat%20Neurosci.&amp;doi=10.1038%2Fs41593-022-01026-4&amp;volume=25&amp;pages=369-380&amp;publication_year=2022&amp;author=Goldstein%2CA">
                    Google Scholar</a> 
                </p></li><li data-counter="12."><p id="ref-CR12">Millet, J., et al. Toward a realistic model of speech processing in the brain with self-supervised learning. In <i>Advances in Neural Information Processing Systems</i> (NeurIPS, 2022).</p></li><li data-counter="13."><p id="ref-CR13">Holtzman, A., Buys, J., Maxwell Forbes, L. D. &amp; Choi, Y. The curious case of neural text degeneration. In <i>International Conference on Learning Representations</i> (2020).</p></li><li data-counter="14."><p id="ref-CR14">Wiseman, S., Shieber, S. M. &amp; Rush, A. M. Challenges in data-to-document generation. In <i>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</i>, 2253–2263. (Association for Computational Linguistics, 2017).</p></li><li data-counter="15."><p id="ref-CR15">Thakur, N., Reimers, N., Rücklé, A., Srivastava, A. &amp; Gurevych, I. BEIR: a heterogenous benchmark for zero-shot evaluation of information retrieval models. In <i>Thirty-fifth Conference on Neural Information Processing Systems Datasets and Benchmarks Track (Round 2)</i> (2021).</p></li><li data-counter="16."><p id="ref-CR16">Raffel, C. et al. Exploring the limits of transfer learning with a unified text-to-text transformer. <i>J. Mach. Learn. Res.</i> <b>21</b>, 140 (2020).</p><p><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 16" href="http://scholar.google.com/scholar_lookup?&amp;title=Exploring%20the%20limits%20of%20transfer%20learning%20with%20a%20unified%20text-to-text%20transformer&amp;journal=J.%20Mach.%20Learn.%20Res.&amp;volume=21&amp;publication_year=2020&amp;author=Raffel%2CC">
                    Google Scholar</a> 
                </p></li><li data-counter="17."><p id="ref-CR17">Krishna, K., Roy, A. &amp; Iyyer, M. Hurdles to progress in long-form question answering. In <i>Proceedings of the 2021 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</i>, 4940–4957 (Association for Computational Linguistics, 2021).</p></li><li data-counter="18."><p id="ref-CR18">Lakretz, Y. et al. The emergence of number and syntax units in LSTM language models. In <i>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</i>, Volume 1 (Long and Short Papers), 11–20 (Association for Computational Linguistics, 2019).</p></li><li data-counter="19."><p id="ref-CR19">Arehalli, S. and Linzen, T. Neural language models capture some, but not all, agreement attraction effects. Preprint at <i>PsyArXiv</i> <a href="https://doi.org/10.31234/osf.io/97qcg">https://doi.org/10.31234/osf.io/97qcg</a> (2020).</p></li><li data-counter="20."><p id="ref-CR20">Lakretz, Y. et al. Can RNNs learn recursive nested subject-verb agreements? Preprint at <i>arXiv</i> <a href="https://doi.org/10.48550/arXiv.2101.02258">https://doi.org/10.48550/arXiv.2101.02258</a> (2021).</p></li><li data-counter="21."><p id="ref-CR21">Baroni, M. Linguistic generalization and compositionality in modern artificial neural networks. <i>Philos. Trans. R. Soc. Lond. B Biol. Sci.</i> <b>375</b>, 20190307 (2020).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1098/rstb.2019.0307" data-track-action="article reference" href="https://doi.org/10.1098%2Frstb.2019.0307" aria-label="Article reference 21" data-doi="10.1098/rstb.2019.0307">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31840578" aria-label="PubMed reference 21">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 21" href="http://scholar.google.com/scholar_lookup?&amp;title=Linguistic%20generalization%20and%20compositionality%20in%20modern%20artificial%20neural%20networks&amp;journal=Philos.%20Trans.%20R.%20Soc.%20Lond.%20B%20Biol.%20Sci.&amp;doi=10.1098%2Frstb.2019.0307&amp;volume=375&amp;publication_year=2020&amp;author=Baroni%2CM">
                    Google Scholar</a> 
                </p></li><li data-counter="22."><p id="ref-CR22">Lake, B. M. &amp; Murphy, G. L. Word meaning in minds and machines. <i>Psychol. Rev</i>. Advance online publication <a href="https://doi.org/10.1037/rev0000297">https://doi.org/10.1037/rev0000297</a> (2021).</p></li><li data-counter="23."><p id="ref-CR23">Marcus, G. Gpt-2 and the nature of intelligence. <i>The Gradient</i> <a href="https://thegradient.pub/gpt2-and-the-nature-of-intelligence/">https://thegradient.pub/gpt2-and-the-nature-of-intelligence/</a> (2020).</p></li><li data-counter="24."><p id="ref-CR24">Warstadt, A. and Bowman, S. R. What artificial neural networks can tell us about human language acquisition. Preprint at <i>arXiv</i> <a href="https://doi.org/10.48550/arXiv.2208.07998">https://doi.org/10.48550/arXiv.2208.07998</a> (2022).</p></li><li data-counter="25."><p id="ref-CR25">Rumelhart, D. E. &amp; McClelland, J. L. An interactive activation model of context effects in letter perception: Part 2. The contextual enhancement effect and some tests and extensions of the model. <i>Psychol. Rev.</i> <b>89</b>, 60–94 (1982).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1037/0033-295X.89.1.60" data-track-action="article reference" href="https://doi.org/10.1037%2F0033-295X.89.1.60" aria-label="Article reference 25" data-doi="10.1037/0033-295X.89.1.60">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DyaL387islyhtA%3D%3D" aria-label="CAS reference 25">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=7058229" aria-label="PubMed reference 25">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 25" href="http://scholar.google.com/scholar_lookup?&amp;title=An%20interactive%20activation%20model%20of%20context%20effects%20in%20letter%20perception%3A%20Part%202.%20The%20contextual%20enhancement%20effect%20and%20some%20tests%20and%20extensions%20of%20the%20model&amp;journal=Psychol.%20Rev.&amp;doi=10.1037%2F0033-295X.89.1.60&amp;volume=89&amp;pages=60-94&amp;publication_year=1982&amp;author=Rumelhart%2CDE&amp;author=McClelland%2CJL">
                    Google Scholar</a> 
                </p></li><li data-counter="26."><p id="ref-CR26">Rao, R. P. &amp; Ballard, D. H. Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. <i>Nat. Neurosci.</i> <b>2</b>, 79–87 (1999).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/4580" data-track-action="article reference" href="https://doi.org/10.1038%2F4580" aria-label="Article reference 26" data-doi="10.1038/4580">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DyaK1MXhsl2ns7k%3D" aria-label="CAS reference 26">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=10195184" aria-label="PubMed reference 26">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 26" href="http://scholar.google.com/scholar_lookup?&amp;title=Predictive%20coding%20in%20the%20visual%20cortex%3A%20a%20functional%20interpretation%20of%20some%20extra-classical%20receptive-field%20effects&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2F4580&amp;volume=2&amp;pages=79-87&amp;publication_year=1999&amp;author=Rao%2CRP&amp;author=Ballard%2CDH">
                    Google Scholar</a> 
                </p></li><li data-counter="27."><p id="ref-CR27">Friston, K. &amp; Kiebel, S. Predictive coding under the free-energy principle. <i>Philos. Trans. R. Soc. Lond. B Biol. Sci.</i> <b>364</b>, 1211–1221 (2009).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1098/rstb.2008.0300" data-track-action="article reference" href="https://doi.org/10.1098%2Frstb.2008.0300" aria-label="Article reference 27" data-doi="10.1098/rstb.2008.0300">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=19528002" aria-label="PubMed reference 27">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2666703" aria-label="PubMed Central reference 27">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 27" href="http://scholar.google.com/scholar_lookup?&amp;title=Predictive%20coding%20under%20the%20free-energy%20principle&amp;journal=Philos.%20Trans.%20R.%20Soc.%20Lond.%20B%20Biol.%20Sci.&amp;doi=10.1098%2Frstb.2008.0300&amp;volume=364&amp;pages=1211-1221&amp;publication_year=2009&amp;author=Friston%2CK&amp;author=Kiebel%2CS">
                    Google Scholar</a> 
                </p></li><li data-counter="28."><p id="ref-CR28">Wacongne, C. et al. Evidence for a hierarchy of predictions and prediction errors in human cortex. <i>Proc. Natl Acad. Sci. USA</i> <b>108</b>, 20754–20759 (2011).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1073/pnas.1117807108" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.1117807108" aria-label="Article reference 28" data-doi="10.1073/pnas.1117807108">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC38Xkt1OjsA%3D%3D" aria-label="CAS reference 28">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=22147913" aria-label="PubMed reference 28">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3251061" aria-label="PubMed Central reference 28">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 28" href="http://scholar.google.com/scholar_lookup?&amp;title=Evidence%20for%20a%20hierarchy%20of%20predictions%20and%20prediction%20errors%20in%20human%20cortex&amp;journal=Proc.%20Natl%20Acad.%20Sci.%20USA&amp;doi=10.1073%2Fpnas.1117807108&amp;volume=108&amp;pages=20754-20759&amp;publication_year=2011&amp;author=Wacongne%2CC">
                    Google Scholar</a> 
                </p></li><li data-counter="29."><p id="ref-CR29">Garrido, M. I., Kilner, J. M., Stephan, K. E. &amp; Friston, K. J. The mismatch negativity: a review of underlying mechanisms. <i>Clin. Neurophysiol.</i> <b>120</b>, 453–463 (2009).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.clinph.2008.11.029" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.clinph.2008.11.029" aria-label="Article reference 29" data-doi="10.1016/j.clinph.2008.11.029">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=19181570" aria-label="PubMed reference 29">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2671031" aria-label="PubMed Central reference 29">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 29" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20mismatch%20negativity%3A%20a%20review%20of%20underlying%20mechanisms&amp;journal=Clin.%20Neurophysiol.&amp;doi=10.1016%2Fj.clinph.2008.11.029&amp;volume=120&amp;pages=453-463&amp;publication_year=2009&amp;author=Garrido%2CMI&amp;author=Kilner%2CJM&amp;author=Stephan%2CKE&amp;author=Friston%2CKJ">
                    Google Scholar</a> 
                </p></li><li data-counter="30."><p id="ref-CR30">Willems, R. M., Frank, S. L., Nijhof, A. D., Hagoort, P. &amp; van den Bosch, A. Prediction during natural language comprehension. <i>Cereb. Cortex</i> <b>26</b>, 2506–2516 (2016).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1093/cercor/bhv075" data-track-action="article reference" href="https://doi.org/10.1093%2Fcercor%2Fbhv075" aria-label="Article reference 30" data-doi="10.1093/cercor/bhv075">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=25903464" aria-label="PubMed reference 30">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 30" href="http://scholar.google.com/scholar_lookup?&amp;title=Prediction%20during%20natural%20language%20comprehension&amp;journal=Cereb.%20Cortex&amp;doi=10.1093%2Fcercor%2Fbhv075&amp;volume=26&amp;pages=2506-2516&amp;publication_year=2016&amp;author=Willems%2CRM&amp;author=Frank%2CSL&amp;author=Nijhof%2CAD&amp;author=Hagoort%2CP&amp;author=van%20den%20Bosch%2CA">
                    Google Scholar</a> 
                </p></li><li data-counter="31."><p id="ref-CR31">Lopopolo, A., Frank, S. L., van den Bosch, A. &amp; Willems, R. M. Using stochastic language models (SLM) to map lexical, syntactic, and phonological information processing in the brain. <i>PLoS ONE</i> <b>12</b>, e0177794 (2017).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1371/journal.pone.0177794" data-track-action="article reference" href="https://doi.org/10.1371%2Fjournal.pone.0177794" aria-label="Article reference 31" data-doi="10.1371/journal.pone.0177794">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28542396" aria-label="PubMed reference 31">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5436813" aria-label="PubMed Central reference 31">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 31" href="http://scholar.google.com/scholar_lookup?&amp;title=Using%20stochastic%20language%20models%20%28SLM%29%20to%20map%20lexical%2C%20syntactic%2C%20and%20phonological%20information%20processing%20in%20the%20brain&amp;journal=PLoS%20ONE&amp;doi=10.1371%2Fjournal.pone.0177794&amp;volume=12&amp;publication_year=2017&amp;author=Lopopolo%2CA&amp;author=Frank%2CSL&amp;author=van%20den%20Bosch%2CA&amp;author=Willems%2CRM">
                    Google Scholar</a> 
                </p></li><li data-counter="32."><p id="ref-CR32">Okada, K., Matchin, W. &amp; Hickok, G. Neural evidence for predictive coding in auditory cortex during speech production. <i>Psychon. Bull. Rev.</i> <b>25</b>, 423–430 (2018).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.3758/s13423-017-1284-x" data-track-action="article reference" href="https://doi.org/10.3758%2Fs13423-017-1284-x" aria-label="Article reference 32" data-doi="10.3758/s13423-017-1284-x">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28397076" aria-label="PubMed reference 32">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 32" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20evidence%20for%20predictive%20coding%20in%20auditory%20cortex%20during%20speech%20production&amp;journal=Psychon.%20Bull.%20Rev.&amp;doi=10.3758%2Fs13423-017-1284-x&amp;volume=25&amp;pages=423-430&amp;publication_year=2018&amp;author=Okada%2CK&amp;author=Matchin%2CW&amp;author=Hickok%2CG">
                    Google Scholar</a> 
                </p></li><li data-counter="33."><p id="ref-CR33">Shain, C., Blank, I. A., van Schijndel, M., Schuler, W. &amp; Fedorenko, E. fMRI reveals language-specific predictive coding during naturalistic sentence comprehension.<i>Neuropsychologia</i> <b>138</b>, 107307 (2020).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuropsychologia.2019.107307" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuropsychologia.2019.107307" aria-label="Article reference 33" data-doi="10.1016/j.neuropsychologia.2019.107307">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31874149" aria-label="PubMed reference 33">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 33" href="http://scholar.google.com/scholar_lookup?&amp;title=fMRI%20reveals%20language-specific%20predictive%20coding%20during%20naturalistic%20sentence%20comprehension.&amp;journal=Neuropsychologia&amp;doi=10.1016%2Fj.neuropsychologia.2019.107307&amp;volume=138&amp;publication_year=2020&amp;author=Shain%2CC&amp;author=Blank%2CIA&amp;author=van%20Schijndel%2CM&amp;author=Schuler%2CW&amp;author=Fedorenko%2CE">
                    Google Scholar</a> 
                </p></li><li data-counter="34."><p id="ref-CR34">Heilbron, M., Armeni, K., Schoffelen, J.-M., Hagoort, P. &amp; de Lange, F. P. A hierarchy of linguistic predictions during natural language comprehension. <i>Proc. Natl. Acad. Sci. USA</i> <b>119</b>, e2201968119 (2022).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1073/pnas.2201968119" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.2201968119" aria-label="Article reference 34" data-doi="10.1073/pnas.2201968119">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB38Xit1antLrI" aria-label="CAS reference 34">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=35921434" aria-label="PubMed reference 34">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC9371745" aria-label="PubMed Central reference 34">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 34" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20hierarchy%20of%20linguistic%20predictions%20during%20natural%20language%20comprehension&amp;journal=Proc.%20Natl.%20Acad.%20Sci.%20USA&amp;doi=10.1073%2Fpnas.2201968119&amp;volume=119&amp;publication_year=2022&amp;author=Heilbron%2CM&amp;author=Armeni%2CK&amp;author=Schoffelen%2CJ-M&amp;author=Hagoort%2CP&amp;author=de%20Lange%2CFP">
                    Google Scholar</a> 
                </p></li><li data-counter="35."><p id="ref-CR35">Heilbron, M., Ehinger, B., Hagoort, P. &amp; de Lange, F. P. Tracking naturalistic linguistic predictions with deep neural language models. In <i>Conference on Cognitive Computational Neuroscience</i> (2019).</p></li><li data-counter="36."><p id="ref-CR36">Donhauser, P. W. &amp; Baillet, S. Two distinct neural timescales for predictive speech processing. <i>Neuron</i> <b>105</b>, 385–393 (2020).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2019.10.019" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2019.10.019" aria-label="Article reference 36" data-doi="10.1016/j.neuron.2019.10.019">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 36" href="http://scholar.google.com/scholar_lookup?&amp;title=Two%20distinct%20neural%20timescales%20for%20predictive%20speech%20processing&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2019.10.019&amp;volume=105&amp;publication_year=2020&amp;author=Donhauser%2CPW&amp;author=Baillet%2CS">
                    Google Scholar</a> 
                </p></li><li data-counter="37."><p id="ref-CR37">Mousavi, Z., Kiani, M. M. and Aghajan, H. Brain signatures of surprise in EEG and MEG data. Preprint at <i>bioRxiv</i> <a href="https://doi.org/10.1101/2020.01.06.895664">https://doi.org/10.1101/2020.01.06.895664</a> (2020).</p></li><li data-counter="38."><p id="ref-CR38">Forseth, K. J., Hickok, G., Rollo, P. S. &amp; Tandon, N. Language prediction mechanisms in human auditory cortex. <i>Nat. Commun.</i> <b>11</b>, 5240 (2020).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41467-020-19010-6" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41467-020-19010-6" aria-label="Article reference 38" data-doi="10.1038/s41467-020-19010-6">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3cXitFCks7fJ" aria-label="CAS reference 38">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=33067457" aria-label="PubMed reference 38">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7567874" aria-label="PubMed Central reference 38">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 38" href="http://scholar.google.com/scholar_lookup?&amp;title=Language%20prediction%20mechanisms%20in%20human%20auditory%20cortex&amp;journal=Nat.%20Commun.&amp;doi=10.1038%2Fs41467-020-19010-6&amp;volume=11&amp;publication_year=2020&amp;author=Forseth%2CKJ&amp;author=Hickok%2CG&amp;author=Rollo%2CPS&amp;author=Tandon%2CN">
                    Google Scholar</a> 
                </p></li><li data-counter="39."><p id="ref-CR39">Nastase, S. A. et al. Narratives: fMRI data for evaluating models of naturalistic language comprehension. <i>Sci. Data</i> <b>8</b>, 250 (2021).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41597-021-01033-3" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41597-021-01033-3" aria-label="Article reference 39" data-doi="10.1038/s41597-021-01033-3">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=34584100" aria-label="PubMed reference 39">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC8479122" aria-label="PubMed Central reference 39">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 39" href="http://scholar.google.com/scholar_lookup?&amp;title=Narratives%3A%20fMRI%20data%20for%20evaluating%20models%20of%20naturalistic%20language%20comprehension&amp;journal=Sci.%20Data&amp;doi=10.1038%2Fs41597-021-01033-3&amp;volume=8&amp;publication_year=2021&amp;author=Nastase%2CSA">
                    Google Scholar</a> 
                </p></li><li data-counter="40."><p id="ref-CR40">Caucheteux, C., Gramfort, A. &amp; King, J.-R. Disentangling syntax and semantics in the brain with deep networks. In <i>Proceedings of the 38th International Conference on Machine Learning,</i> 1336-1348 (PMLR, 2021).</p></li><li data-counter="41."><p id="ref-CR41">Wehbe, L., Vaswani, A., Knight, K. &amp; Mitchell, T. Aligning context-based statistical models of language with brain activity during reading. In <i>Proc. 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP)</i>, 233–243 (Association for Computational Linguistics, 2014).</p></li><li data-counter="42."><p id="ref-CR42">Huth, A. G., de Heer, W. A., Griffiths, T. L., Theunissen, F. E. &amp; Gallant, J. L. Natural speech reveals the semantic maps that tile human cerebral cortex. <i>Nature</i> <b>532</b>, 453–458 (2016).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nature17637" data-track-action="article reference" href="https://doi.org/10.1038%2Fnature17637" aria-label="Article reference 42" data-doi="10.1038/nature17637">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=27121839" aria-label="PubMed reference 42">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4852309" aria-label="PubMed Central reference 42">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 42" href="http://scholar.google.com/scholar_lookup?&amp;title=Natural%20speech%20reveals%20the%20semantic%20maps%20that%20tile%20human%20cerebral%20cortex&amp;journal=Nature&amp;doi=10.1038%2Fnature17637&amp;volume=532&amp;pages=453-458&amp;publication_year=2016&amp;author=Huth%2CAG&amp;author=de%20Heer%2CWA&amp;author=Griffiths%2CTL&amp;author=Theunissen%2CFE&amp;author=Gallant%2CJL">
                    Google Scholar</a> 
                </p></li><li data-counter="43."><p id="ref-CR43">Toneva, M., Mitchell, T. M. &amp; Wehbe, L. The meaning that emerges from combining words is robustly localizable in space but not in time. Preprint at <i>bioRxiv</i> <a href="https://doi.org/10.1101/2020.09.28.316935">https://doi.org/10.1101/2020.09.28.316935</a> (2020).</p></li><li data-counter="44."><p id="ref-CR44">Fedorenko, E. et al. Neural correlate of the construction of sentence meaning. <i>Proc. Natl. Acad. Sci. USA</i> <b>113</b>, E6256–E6262 (2016).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1073/pnas.1612132113" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.1612132113" aria-label="Article reference 44" data-doi="10.1073/pnas.1612132113">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC28XhsFKjsLzM" aria-label="CAS reference 44">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=27671642" aria-label="PubMed reference 44">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5068329" aria-label="PubMed Central reference 44">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 44" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20correlate%20of%20the%20construction%20of%20sentence%20meaning&amp;journal=Proc.%20Natl.%20Acad.%20Sci.%20USA&amp;doi=10.1073%2Fpnas.1612132113&amp;volume=113&amp;pages=E6256-E6262&amp;publication_year=2016&amp;author=Fedorenko%2CE">
                    Google Scholar</a> 
                </p></li><li data-counter="45."><p id="ref-CR45">Felleman, D. J. &amp; Van Essen, D. C. Distributed hierarchical processing in the primate cerebral cortex. <i>Cereb. Cortex</i> <b>1</b>, 1–47 (1991).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1093/cercor/1.1.1" data-track-action="article reference" href="https://doi.org/10.1093%2Fcercor%2F1.1.1" aria-label="Article reference 45" data-doi="10.1093/cercor/1.1.1">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DyaK38zltlGmsg%3D%3D" aria-label="CAS reference 45">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=1822724" aria-label="PubMed reference 45">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 45" href="http://scholar.google.com/scholar_lookup?&amp;title=Distributed%20hierarchical%20processing%20in%20the%20primate%20cerebral%20cortex&amp;journal=Cereb.%20Cortex&amp;doi=10.1093%2Fcercor%2F1.1.1&amp;volume=1&amp;pages=1-47&amp;publication_year=1991&amp;author=Felleman%2CDJ&amp;author=Van%20Essen%2CDC">
                    Google Scholar</a> 
                </p></li><li data-counter="46."><p id="ref-CR46">Lerner, Y., Honey, C. J., Silbert, L. J. &amp; Hasson, U. Topographic mapping of a hierarchy of temporal receptive windows using a narrated story. <i>J. Neurosci.</i> <b>31</b>, 2906–2915 (2011).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.3684-10.2011" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.3684-10.2011" aria-label="Article reference 46" data-doi="10.1523/JNEUROSCI.3684-10.2011">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC3MXislGitrs%3D" aria-label="CAS reference 46">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=21414912" aria-label="PubMed reference 46">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3089381" aria-label="PubMed Central reference 46">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 46" href="http://scholar.google.com/scholar_lookup?&amp;title=Topographic%20mapping%20of%20a%20hierarchy%20of%20temporal%20receptive%20windows%20using%20a%20narrated%20story&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.3684-10.2011&amp;volume=31&amp;pages=2906-2915&amp;publication_year=2011&amp;author=Lerner%2CY&amp;author=Honey%2CCJ&amp;author=Silbert%2CLJ&amp;author=Hasson%2CU">
                    Google Scholar</a> 
                </p></li><li data-counter="47."><p id="ref-CR47">Kell, A. J. E., Yamins, D. L. K., Shook, E. N., Norman-Haignere, S. V. &amp; McDermott, J. H. A task-optimized neural network replicates human auditory behavior, predicts brain responses, and reveals a cortical processing hierarchy. <i>Neuron</i> <b>98</b>, 630–644 (2018).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2018.03.044" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2018.03.044" aria-label="Article reference 47" data-doi="10.1016/j.neuron.2018.03.044">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 47" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20task-optimized%20neural%20network%20replicates%20human%20auditory%20behavior%2C%20predicts%20brain%20responses%2C%20and%20reveals%20a%20cortical%20processing%20hierarchy&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2018.03.044&amp;volume=98&amp;publication_year=2018&amp;author=Kell%2CAJE&amp;author=Yamins%2CDLK&amp;author=Shook%2CEN&amp;author=Norman-Haignere%2CSV&amp;author=McDermott%2CJH">
                    Google Scholar</a> 
                </p></li><li data-counter="48."><p id="ref-CR48">Mesgarani, N., Cheung, C., Johnson, K. &amp; Chang, E. F. Phonetic feature encoding in human superior temporal gyrus. <i>Science</i> <b>343</b>, 1006–1010 (2014).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1126/science.1245994" data-track-action="article reference" href="https://doi.org/10.1126%2Fscience.1245994" aria-label="Article reference 48" data-doi="10.1126/science.1245994">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC2cXjt1ymtrg%3D" aria-label="CAS reference 48">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=24482117" aria-label="PubMed reference 48">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4350233" aria-label="PubMed Central reference 48">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 48" href="http://scholar.google.com/scholar_lookup?&amp;title=Phonetic%20feature%20encoding%20in%20human%20superior%20temporal%20gyrus&amp;journal=Science&amp;doi=10.1126%2Fscience.1245994&amp;volume=343&amp;pages=1006-1010&amp;publication_year=2014&amp;author=Mesgarani%2CN&amp;author=Cheung%2CC&amp;author=Johnson%2CK&amp;author=Chang%2CEF">
                    Google Scholar</a> 
                </p></li><li data-counter="49."><p id="ref-CR49">Hickok, G. &amp; Poeppel, D. The cortical organization of speech processing. <i>Nat. Rev. Neurosci.</i> <b>8</b>, 393–402 (2007).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nrn2113" data-track-action="article reference" href="https://doi.org/10.1038%2Fnrn2113" aria-label="Article reference 49" data-doi="10.1038/nrn2113">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BD2sXksFSis7w%3D" aria-label="CAS reference 49">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=17431404" aria-label="PubMed reference 49">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 49" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20cortical%20organization%20of%20speech%20processing&amp;journal=Nat.%20Rev.%20Neurosci.&amp;doi=10.1038%2Fnrn2113&amp;volume=8&amp;pages=393-402&amp;publication_year=2007&amp;author=Hickok%2CG&amp;author=Poeppel%2CD">
                    Google Scholar</a> 
                </p></li><li data-counter="50."><p id="ref-CR50">Jawahar, G., Sagot, B. &amp; Seddah, D. What Does BERT learn about the structure of language? In <i>Proc. 57th Annual Meeting of the Association for Computational Linguistics</i>, 3651–3657 (Association for Computational Linguistics, 2019).</p></li><li data-counter="51."><p id="ref-CR51">Manning, C. D., Clark, K., Hewitt, J., Khandelwal, U. &amp; Levy, O. Emergent linguistic structure in artificial neural networks trained by self-supervision. <i>Proc. Natl. Acad. Sci. USA</i> <b>117</b>, 30046–30054 (2020).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1073/pnas.1907367117" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.1907367117" aria-label="Article reference 51" data-doi="10.1073/pnas.1907367117">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3cXisVKnsLbI" aria-label="CAS reference 51">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32493748" aria-label="PubMed reference 51">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7720155" aria-label="PubMed Central reference 51">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 51" href="http://scholar.google.com/scholar_lookup?&amp;title=Emergent%20linguistic%20structure%20in%20artificial%20neural%20networks%20trained%20by%20self-supervision&amp;journal=Proc.%20Natl.%20Acad.%20Sci.%20USA&amp;doi=10.1073%2Fpnas.1907367117&amp;volume=117&amp;pages=30046-30054&amp;publication_year=2020&amp;author=Manning%2CCD&amp;author=Clark%2CK&amp;author=Hewitt%2CJ&amp;author=Khandelwal%2CU&amp;author=Levy%2CO">
                    Google Scholar</a> 
                </p></li><li data-counter="52."><p id="ref-CR52">Bellman, R. Dynamic programming. <i>Science</i> <b>153</b>, 34–37 (1966).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1126/science.153.3731.34" data-track-action="article reference" href="https://doi.org/10.1126%2Fscience.153.3731.34" aria-label="Article reference 52" data-doi="10.1126/science.153.3731.34">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:STN:280:DC%2BC3czpslaisA%3D%3D" aria-label="CAS reference 52">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=17730601" aria-label="PubMed reference 52">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 52" href="http://scholar.google.com/scholar_lookup?&amp;title=Dynamic%20programming&amp;journal=Science&amp;doi=10.1126%2Fscience.153.3731.34&amp;volume=153&amp;pages=34-37&amp;publication_year=1966&amp;author=Bellman%2CR">
                    Google Scholar</a> 
                </p></li><li data-counter="53."><p id="ref-CR53">Devlin, J., Chang, M.-W., Lee, K. &amp; Toutanova, K. BERT: pre-training of deep bidirectional transformers for language understanding. In <i>Proceedings of the 2019 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies</i>, <b>1,</b> 4171–4186, (Association for Computational Linguistics, 2019).</p></li><li data-counter="54."><p id="ref-CR54">Liu, Y. et al. RoBERTa: a robustly optimized BERT pretraining approach. Preprint at <i>arXiv</i> <a href="https://doi.org/10.48550/arXiv.1907.11692">https://doi.org/10.48550/arXiv.1907.11692</a> (2019).</p></li><li data-counter="55."><p id="ref-CR55">Clark, K., Luong, M.-T. &amp; Le, Q. V. &amp; Manning, C. D. ELECTRA: pre-training text encoders as discriminators rather than generators. Preprint at <i>arXiv</i> <a href="https://doi.org/10.48550/arXiv.2003.10555">https://doi.org/10.48550/arXiv.2003.10555</a> (2020).</p></li><li data-counter="56."><p id="ref-CR56">Caucheteux, C., Gramfort, A. &amp; King, J.-R. Deep language algorithms predict semantic comprehension from brain activity. <i>Sci Rep.</i> <b>12</b>, 16327 (2022).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41598-022-20460-9" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41598-022-20460-9" aria-label="Article reference 56" data-doi="10.1038/s41598-022-20460-9">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB38XisFOht73P" aria-label="CAS reference 56">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=36175483" aria-label="PubMed reference 56">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC9522791" aria-label="PubMed Central reference 56">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 56" href="http://scholar.google.com/scholar_lookup?&amp;title=Deep%20language%20algorithms%20predict%20semantic%20comprehension%20from%20brain%20activity&amp;journal=Sci%20Rep.&amp;doi=10.1038%2Fs41598-022-20460-9&amp;volume=12&amp;publication_year=2022&amp;author=Caucheteux%2CC&amp;author=Gramfort%2CA&amp;author=King%2CJ-R">
                    Google Scholar</a> 
                </p></li><li data-counter="57."><p id="ref-CR57">Gilbert, S. J. &amp; Burgess, P. W. Executive function. <i>Curr. Biol.</i> <b>18</b>, R110–R114 (2008).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.cub.2007.12.014" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.cub.2007.12.014" aria-label="Article reference 57" data-doi="10.1016/j.cub.2007.12.014">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BD1cXhvVWit7w%3D" aria-label="CAS reference 57">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=18269902" aria-label="PubMed reference 57">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 57" href="http://scholar.google.com/scholar_lookup?&amp;title=Executive%20function&amp;journal=Curr.%20Biol.&amp;doi=10.1016%2Fj.cub.2007.12.014&amp;volume=18&amp;pages=R110-R114&amp;publication_year=2008&amp;author=Gilbert%2CSJ&amp;author=Burgess%2CPW">
                    Google Scholar</a> 
                </p></li><li data-counter="58."><p id="ref-CR58">Shallice, T. &amp; Burgess, P. Deficits in strategy application following frontal lobe damage in man. <i>Brain</i> <b>114</b>, 727–741 (1991).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1093/brain/114.2.727" data-track-action="article reference" href="https://doi.org/10.1093%2Fbrain%2F114.2.727" aria-label="Article reference 58" data-doi="10.1093/brain/114.2.727">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=2043945" aria-label="PubMed reference 58">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 58" href="http://scholar.google.com/scholar_lookup?&amp;title=Deficits%20in%20strategy%20application%20following%20frontal%20lobe%20damage%20in%20man&amp;journal=Brain&amp;doi=10.1093%2Fbrain%2F114.2.727&amp;volume=114&amp;pages=727-741&amp;publication_year=1991&amp;author=Shallice%2CT&amp;author=Burgess%2CP">
                    Google Scholar</a> 
                </p></li><li data-counter="59."><p id="ref-CR59">Wang, L. et al. Dynamic predictive coding across the left fronto-temporal language hierarchy: evidence from MEG, EEG and fMRI. Preprint at <i>bioRxiv</i> <a href="https://doi.org/10.1101/2021.02.17.431452">https://doi.org/10.1101/2021.02.17.431452</a> (2021).</p></li><li data-counter="60."><p id="ref-CR60">Lee, C. S., Aly, M. &amp; Baldassano, C. Anticipation of temporally structured events in the brain. <i>eLife</i> <b>10</b>, e64972 (2021).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.7554/eLife.64972" data-track-action="article reference" href="https://doi.org/10.7554%2FeLife.64972" aria-label="Article reference 60" data-doi="10.7554/eLife.64972">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3MXitlOgs7bP" aria-label="CAS reference 60">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=33884953" aria-label="PubMed reference 60">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC8169103" aria-label="PubMed Central reference 60">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 60" href="http://scholar.google.com/scholar_lookup?&amp;title=Anticipation%20of%20temporally%20structured%20events%20in%20the%20brain&amp;journal=eLife&amp;doi=10.7554%2FeLife.64972&amp;volume=10&amp;publication_year=2021&amp;author=Lee%2CCS&amp;author=Aly%2CM&amp;author=Baldassano%2CC">
                    Google Scholar</a> 
                </p></li><li data-counter="61."><p id="ref-CR61">Caucheteux, C., Gramfort, A. and King, J.-R. Model-based analysis of brain activity reveals the hierarchy of language in 305 subjects. In <i>Proc.</i> <i>EMNLP 2021, Conference on Empirical Methods in Natural Language Processing</i> 3635–3644 (Association for Computational Linguistics, 2021).</p></li><li data-counter="62."><p id="ref-CR62">Vidal, Y., Brusini, P., Bonfieni, M., Mehler, J. &amp; Bekinschtein, T. A. Neural signal to violations of abstract rules using speech-like stimuli. <i>eNeuro</i> <b>6</b>, ENEURO.0128-19.2019 (2019).</p></li><li data-counter="63."><p id="ref-CR63">Nelson, M. J. et al. Neurophysiological dynamics of phrase-structure building during sentence processing. <i>Proc. Natl Acad. Sci. USA</i> <b>114</b>, E3669–E3678 (2017).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1073/pnas.1701590114" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.1701590114" aria-label="Article reference 63" data-doi="10.1073/pnas.1701590114">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC2sXmtFGgu7Y%3D" aria-label="CAS reference 63">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28416691" aria-label="PubMed reference 63">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5422821" aria-label="PubMed Central reference 63">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 63" href="http://scholar.google.com/scholar_lookup?&amp;title=Neurophysiological%20dynamics%20of%20phrase-structure%20building%20during%20sentence%20processing&amp;journal=Proc.%20Natl%20Acad.%20Sci.%20USA&amp;doi=10.1073%2Fpnas.1701590114&amp;volume=114&amp;pages=E3669-E3678&amp;publication_year=2017&amp;author=Nelson%2CMJ">
                    Google Scholar</a> 
                </p></li><li data-counter="64."><p id="ref-CR64">Ding, N., Melloni, L., Zhang, H., Tian, X. &amp; Poeppel, D. Cortical tracking of hierarchical linguistic structures in connected speech. <i>Nat. Neurosci.</i> <b>19</b>, 158–164 (2016).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nn.4186" data-track-action="article reference" href="https://doi.org/10.1038%2Fnn.4186" aria-label="Article reference 64" data-doi="10.1038/nn.4186">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC2MXhvFOmtb3M" aria-label="CAS reference 64">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=26642090" aria-label="PubMed reference 64">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 64" href="http://scholar.google.com/scholar_lookup?&amp;title=Cortical%20tracking%20of%20hierarchical%20linguistic%20structures%20in%20connected%20speech&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fnn.4186&amp;volume=19&amp;pages=158-164&amp;publication_year=2016&amp;author=Ding%2CN&amp;author=Melloni%2CL&amp;author=Zhang%2CH&amp;author=Tian%2CX&amp;author=Poeppel%2CD">
                    Google Scholar</a> 
                </p></li><li data-counter="65."><p id="ref-CR65">Jackendoff, R. &amp; Jackendoff, R. S. <i>Foundations of Language: Brain, Meaning, Grammar, Evolution</i> (Oxford Univ. Press, 2002).</p></li><li data-counter="66."><p id="ref-CR66">Shain, C. et al. ‘Constituent length’ effects in fMRI do not provide evidence for abstract syntactic processing. Preprint at <i>bioRxiv</i> <a href="https://doi.org/10.1101/2021.11.12.467812">https://doi.org/10.1101/2021.11.12.467812</a> (2021).</p></li><li data-counter="67."><p id="ref-CR67">McClelland, J. L. &amp; Rumelhart, D. E. An interactive activation model of context effects in letter perception: I. An account of basic findings. <i>Psychol. Rev.</i> <b>88</b>, 375–407 (1981).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1037/0033-295X.88.5.375" data-track-action="article reference" href="https://doi.org/10.1037%2F0033-295X.88.5.375" aria-label="Article reference 67" data-doi="10.1037/0033-295X.88.5.375">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 67" href="http://scholar.google.com/scholar_lookup?&amp;title=An%20interactive%20activation%20model%20of%20context%20effects%20in%20letter%20perception%3A%20I.%20An%20account%20of%20basic%20findings&amp;journal=Psychol.%20Rev.&amp;doi=10.1037%2F0033-295X.88.5.375&amp;volume=88&amp;pages=375-407&amp;publication_year=1981&amp;author=McClelland%2CJL&amp;author=Rumelhart%2CDE">
                    Google Scholar</a> 
                </p></li><li data-counter="68."><p id="ref-CR68">Hale, J. T. et al. Neurocomputational models of language processing. <i>Ann. Rev. Linguist.</i> <b>8</b>, 427–446 (2022).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1146/annurev-linguistics-051421-020803" data-track-action="article reference" href="https://doi.org/10.1146%2Fannurev-linguistics-051421-020803" aria-label="Article reference 68" data-doi="10.1146/annurev-linguistics-051421-020803">Article</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 68" href="http://scholar.google.com/scholar_lookup?&amp;title=Neurocomputational%20models%20of%20language%20processing&amp;journal=Ann.%20Rev.%20Linguist.&amp;doi=10.1146%2Fannurev-linguistics-051421-020803&amp;volume=8&amp;pages=427-446&amp;publication_year=2022&amp;author=Hale%2CJT">
                    Google Scholar</a> 
                </p></li><li data-counter="69."><p id="ref-CR69">Jernite, Y., Bowman, S. R. &amp; Sontag, D. Discourse-based objectives for fast unsupervised sentence representation learning. Preprint at <i>arXiv</i> <a href="https://doi.org/10.48550/arXiv.1705.00557">https://doi.org/10.48550/arXiv.1705.00557</a> (2017).</p></li><li data-counter="70."><p id="ref-CR70">Lewis, M. et al. BART: denoising sequence-to-sequence pre-training for natural language generation, translation, and comprehension. In <i>Proceedings of the 58th Annual Meeting of the Association for Computational Linguistics,</i> 7871–7880 (Association for Computational Linguistics, 2020).</p></li><li data-counter="71."><p id="ref-CR71">Yang, Z. et al. XLNet: generalized autoregressive pretraining for language understanding. In <i>Advances in Neural Information Processing Systems,</i> 32 (Curran Associates, 2019).</p></li><li data-counter="72."><p id="ref-CR72">Joshi, M. et al. SpanBERT: Improving Pre-training by Representing and Predicting Spans. <i>In</i> <i>Transactions of the Association for Computational Linguistics</i> <b>8</b>, 64–77 (2020).</p><p><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 72" href="http://scholar.google.com/scholar_lookup?&amp;title=SpanBERT%3A%20Improving%20Pre-training%20by%20Representing%20and%20Predicting%20Spans&amp;journal=In&amp;volume=8&amp;pages=64-77&amp;publication_year=2020&amp;author=Joshi%2CM">
                    Google Scholar</a> 
                </p></li><li data-counter="73."><p id="ref-CR73">Szegedy, C. et al. Going deeper with convolutions. In <i>Proc. 2015 IEEE Conference on Computer Vision and Pattern Recognition (CVPR)</i>, 1–9 (IEEE, 2015).</p></li><li data-counter="74."><p id="ref-CR74">Chen, T., Kornblith, S., Norouzi, M. &amp; Hinton, G. A simple framework for contrastive learning of visual representations. In <i>Proceedings of the 37th International Conference on Machine Learning,</i> 149 (2020).</p></li><li data-counter="75."><p id="ref-CR75">He, K., Fan, H., Wu, Y., Xie, S. and Girshick, R. Momentum contrast for unsupervised visual representation learning. Preprint at <i>arXiv</i> <a href="https://doi.org/10.48550/arXiv.1911.05722">https://doi.org/10.48550/arXiv.1911.05722</a> (2020).</p></li><li data-counter="76."><p id="ref-CR76">El-Nouby, A. et al. XCiT: cross-covariance image transformers. In A<i>dvances in Neural Information Processing Systems,</i> <b>34</b>, 20014–20027 (Curran Associates, 2021)<i>.</i></p></li><li data-counter="77."><p id="ref-CR77">Bardes, A., Ponce, J. &amp; LeCun, Y. VICReg: variance-invariance-covariance regularization for self-supervised learning. In <i>International Conference on Learning Representations</i> (2022).</p></li><li data-counter="78."><p id="ref-CR78">Kepecs, A., Uchida, N., Zariwala, H. A. &amp; Mainen, Z. F. Neural correlates, computation and behavioural impact of decision confidence. <i>Nature</i> <b>455</b>, 227–231 (2008).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/nature07200" data-track-action="article reference" href="https://doi.org/10.1038%2Fnature07200" aria-label="Article reference 78" data-doi="10.1038/nature07200">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BD1cXhtV2qtLnO" aria-label="CAS reference 78">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=18690210" aria-label="PubMed reference 78">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 78" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20correlates%2C%20computation%20and%20behavioural%20impact%20of%20decision%20confidence&amp;journal=Nature&amp;doi=10.1038%2Fnature07200&amp;volume=455&amp;pages=227-231&amp;publication_year=2008&amp;author=Kepecs%2CA&amp;author=Uchida%2CN&amp;author=Zariwala%2CHA&amp;author=Mainen%2CZF">
                    Google Scholar</a> 
                </p></li><li data-counter="79."><p id="ref-CR79">Esteban, O. et al. fMRIPrep: a robust preprocessing pipeline for functional MRI. <i>Nat. Methods</i> <b>16</b>, 111–116 (2019).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41592-018-0235-4" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41592-018-0235-4" aria-label="Article reference 79" data-doi="10.1038/s41592-018-0235-4">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BC1cXisVyhurnN" aria-label="CAS reference 79">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30532080" aria-label="PubMed reference 79">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 79" href="http://scholar.google.com/scholar_lookup?&amp;title=fMRIPrep%3A%20a%20robust%20preprocessing%20pipeline%20for%20functional%20MRI&amp;journal=Nat.%20Methods&amp;doi=10.1038%2Fs41592-018-0235-4&amp;volume=16&amp;pages=111-116&amp;publication_year=2019&amp;author=Esteban%2CO">
                    Google Scholar</a> 
                </p></li><li data-counter="80."><p id="ref-CR80">Wolf, T. et al. Transformers: State-of-the-art natural language processing. In <i>Proc. 2020 Conference on Empirical Methods in Natural Language Processing: System Demonstrations</i>, 38–45 (Association for Computational Linguistics, 2020).</p></li><li data-counter="81."><p id="ref-CR81">Pedregosa, F. et al. Scikit-learn: machine learning in Python. <i>J. Mach. Learn. Res.</i> <b>12</b>, 2825–2830 (2011).</p><p><a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 81" href="http://scholar.google.com/scholar_lookup?&amp;title=Scikit-learn%3A%20machine%20learning%20in%20Python&amp;journal=J.%20Mach.%20Learn.%20Res.&amp;volume=12&amp;pages=2825-2830&amp;publication_year=2011&amp;author=Pedregosa%2CF">
                    Google Scholar</a> 
                </p></li><li data-counter="82."><p id="ref-CR82">Destrieux, C., Fischl, B., Dale, A. &amp; Halgren, E. Automatic parcellation of human cortical gyri and sulci using standard anatomical nomenclature. <i>Neuroimage</i> <b>53</b>, 1–15 (2010).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2010.06.010" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2010.06.010" aria-label="Article reference 82" data-doi="10.1016/j.neuroimage.2010.06.010">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=20547229" aria-label="PubMed reference 82">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 82" href="http://scholar.google.com/scholar_lookup?&amp;title=Automatic%20parcellation%20of%20human%20cortical%20gyri%20and%20sulci%20using%20standard%20anatomical%20nomenclature&amp;journal=Neuroimage&amp;doi=10.1016%2Fj.neuroimage.2010.06.010&amp;volume=53&amp;pages=1-15&amp;publication_year=2010&amp;author=Destrieux%2CC&amp;author=Fischl%2CB&amp;author=Dale%2CA&amp;author=Halgren%2CE">
                    Google Scholar</a> 
                </p></li><li data-counter="83."><p id="ref-CR83">Virtanen, P. et al. SciPy 1.0: fundamental algorithms for scientific computing in Python. <i>Nat. Methods</i> <b>17</b>, 261–272 (2020).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1038/s41592-019-0686-2" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41592-019-0686-2" aria-label="Article reference 83" data-doi="10.1038/s41592-019-0686-2">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3cXislCjuro%3D" aria-label="CAS reference 83">CAS</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32015543" aria-label="PubMed reference 83">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7056644" aria-label="PubMed Central reference 83">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 83" href="http://scholar.google.com/scholar_lookup?&amp;title=SciPy%201.0%3A%20fundamental%20algorithms%20for%20scientific%20computing%20in%20Python&amp;journal=Nat.%20Methods&amp;doi=10.1038%2Fs41592-019-0686-2&amp;volume=17&amp;pages=261-272&amp;publication_year=2020&amp;author=Virtanen%2CP">
                    Google Scholar</a> 
                </p></li><li data-counter="84."><p id="ref-CR84">Hénaff, O. J. et al. Data-efficient image recognition with contrastive predictive coding. In <i>Proceedings of the 37th International Conference on Machine Learning</i>, 4182–4192 (PMLR, 2020).</p></li><li data-counter="85."><p id="ref-CR85">Gramfort, A. et al. MEG and EEG data analysis with MNE-Python. <i>Front. Neurosci.</i> <b>7</b>, 267 (2013).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.3389/fnins.2013.00267" data-track-action="article reference" href="https://doi.org/10.3389%2Ffnins.2013.00267" aria-label="Article reference 85" data-doi="10.3389/fnins.2013.00267">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=24431986" aria-label="PubMed reference 85">PubMed</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC3872725" aria-label="PubMed Central reference 85">PubMed Central</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 85" href="http://scholar.google.com/scholar_lookup?&amp;title=MEG%20and%20EEG%20data%20analysis%20with%20MNE-Python&amp;journal=Front.%20Neurosci.&amp;doi=10.3389%2Ffnins.2013.00267&amp;volume=7&amp;publication_year=2013&amp;author=Gramfort%2CA">
                    Google Scholar</a> 
                </p></li><li data-counter="86."><p id="ref-CR86">Dai, Z. et al. Transformer-XL: attentive language models beyond a fixed-length context. In <i>Proceedings of the 57th Annual Meeting of the Association for Computational Linguistics</i>, 2978–2988 (Association for Computational Linguistics, 2019).</p></li><li data-counter="87."><p id="ref-CR87">Nunez-Elizalde, A. O., Huth, A. G. &amp; Gallant, J. L. Voxelwise encoding models with non-spherical multivariate normal priors. <i>Neuroimage</i> <b>197</b>, 482–492 (2019).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2019.04.012" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2019.04.012" aria-label="Article reference 87" data-doi="10.1016/j.neuroimage.2019.04.012">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31075394" aria-label="PubMed reference 87">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 87" href="http://scholar.google.com/scholar_lookup?&amp;title=Voxelwise%20encoding%20models%20with%20non-spherical%20multivariate%20normal%20priors&amp;journal=Neuroimage&amp;doi=10.1016%2Fj.neuroimage.2019.04.012&amp;volume=197&amp;pages=482-492&amp;publication_year=2019&amp;author=Nunez-Elizalde%2CAO&amp;author=Huth%2CAG&amp;author=Gallant%2CJL">
                    Google Scholar</a> 
                </p></li><li data-counter="88."><p id="ref-CR88">Dupré la Tour, T., Eickenberg, M., Nunez-Elizalde, A. O. &amp; Gallant, J. Feature-space selection with banded ridge regression. <i>Neuroimage</i> <b>264</b>, 119728 (2022).</p><p><a data-track="click" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2022.119728" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2022.119728" aria-label="Article reference 88" data-doi="10.1016/j.neuroimage.2022.119728">Article</a> 
    <a data-track="click" rel="nofollow noopener" data-track-label="link" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=36334814" aria-label="PubMed reference 88">PubMed</a> 
    <a data-track="click" data-track-action="google scholar reference" data-track-label="link" rel="nofollow noopener" aria-label="Google Scholar reference 88" href="http://scholar.google.com/scholar_lookup?&amp;title=Feature-space%20selection%20with%20banded%20ridge%20regression&amp;journal=Neuroimage&amp;doi=10.1016%2Fj.neuroimage.2022.119728&amp;volume=264&amp;publication_year=2022&amp;author=Dupr%C3%A9%20la%20Tour%2CT&amp;author=Eickenberg%2CM&amp;author=Nunez-Elizalde%2CAO&amp;author=Gallant%2CJ">
                    Google Scholar</a> 
                </p></li></ol><p><a data-track="click" data-track-action="download citation references" data-track-label="link" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/s41562-022-01516-2?format=refman&amp;flavour=references">Download references<svg width="16" height="16" focusable="false" role="img" aria-hidden="true"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p></div></div></div></section></div><section data-title="Acknowledgements"><div id="Ack1-section"><h2 id="Ack1">Acknowledgements</h2><p>This project was funded, in part, by the Bettencourt-Schueller Foundation, the Philippe Foundation and FrontCog grant no. ANR-17-EURE-0017 to J.R.K. for his work at Université Paris Sciences et Lettres. The funders had no role in study design, data collection and analysis, decision to publish or preparation of the manuscript.</p></div></section><section aria-labelledby="author-information" data-title="Author information"><div id="author-information-section"><h2 id="author-information">Author information</h2><div id="author-information-content"><h3 id="affiliations">Authors and Affiliations</h3><ol><li id="Aff1"><p>Meta AI, Paris, France</p><p>Charlotte Caucheteux, Alexandre Gramfort &amp; Jean-Rémi King</p></li><li id="Aff2"><p>Université Paris-Saclay, Inria, Commissariat à l’Énergie Atomique et aux Énergies Alternatives, Paris, France</p><p>Charlotte Caucheteux &amp; Alexandre Gramfort</p></li><li id="Aff3"><p>Laboratoire des systèmes perceptifs, Département d’études cognitives, École normale supérieure, PSL University, CNRS, Paris, France</p><p>Jean-Rémi King</p></li></ol><h3 id="contributions">Contributions</h3><p>C.C., A.G. and J.-R.K. jointly designed the analysis, interpreted the results and wrote the paper. C.C. performed the analyses and experiments.</p><h3 id="corresponding-author">Corresponding authors</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" href="mailto:ccaucheteux@meta.com">Charlotte Caucheteux</a> or <a id="corresp-c2" href="mailto:jeanremi@meta.com">Jean-Rémi King</a>.</p></div></div></section><section data-title="Ethics declarations"><div id="ethics-section"><h2 id="ethics">Ethics declarations</h2><div id="ethics-content">
            
              <h3 id="FPar2">Competing interests</h3>
              <p>The authors declare no competing interests.</p>
            
          </div></div></section><section data-title="Peer review"><div id="peer-review-section"><h2 id="peer-review">Peer review</h2><div id="peer-review-content">
            
            
              <h3 id="FPar1">Peer review information</h3>
              <p><i>Nature Human Behaviour</i> thanks Samuel Nastase and the other, anonymous, reviewer(s) for their contribution to the peer review of this work.</p>
            
          </div></div></section><section data-title="Additional information"><div id="additional-information-section"><h2 id="additional-information">Additional information</h2><p><b>Publisher’s note</b> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></div></section><section data-title="Supplementary information"><div id="Sec29-section"><h2 id="Sec29">Supplementary information</h2></div></section><section data-title="Rights and permissions"><div id="rightslink-section"><h2 id="rightslink">Rights and permissions</h2><div id="rightslink-content">
              <p><b>Open Access</b>  This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons license, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons license, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons license and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this license, visit <a href="http://creativecommons.org/licenses/by/4.0/" rel="license">http://creativecommons.org/licenses/by/4.0/</a>.</p>
            <p><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Evidence%20of%20a%20predictive%20coding%20hierarchy%20in%20the%20human%20brain%20listening%20to%20speech&amp;author=Charlotte%20Caucheteux%20et%20al&amp;contentID=10.1038%2Fs41562-022-01516-2&amp;copyright=The%20Author%28s%29&amp;publication=2397-3374&amp;publicationDate=2023-03-02&amp;publisherName=SpringerNature&amp;orderBeanReset=true&amp;oa=CC%20BY">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info" data-title="About this article"><div id="article-info-section"><h2 id="article-info">About this article</h2><div id="article-info-content"><div><p><a data-crossmark="10.1038/s41562-022-01516-2" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1038/s41562-022-01516-2" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img width="57" height="81" alt="Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>"/></a></p><div><h3 id="citeas">Cite this article</h3><p>Caucheteux, C., Gramfort, A. &amp; King, JR. Evidence of a predictive coding hierarchy in the human brain listening to speech.
                    <i>Nat Hum Behav</i>  (2023). https://doi.org/10.1038/s41562-022-01516-2</p><p><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" data-track-external="" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/s41562-022-01516-2?format=refman&amp;flavour=citation">Download citation<svg width="16" height="16" focusable="false" role="img" aria-hidden="true"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#global-icon-download"></use></svg></a></p><ul data-test="publication-history"><li><p>Received<span>: </span><span><time datetime="2022-03-31">31 March 2022</time></span></p></li><li><p>Accepted<span>: </span><span><time datetime="2022-12-15">15 December 2022</time></span></p></li><li><p>Published<span>: </span><span><time datetime="2023-03-02">02 March 2023</time></span></p></li><li><p><abbr title="Digital Object Identifier">DOI</abbr><span>: </span><span>https://doi.org/10.1038/s41562-022-01516-2</span></p></li></ul></div></div></div></div></section>
            </div></div>
  </body>
</html>
