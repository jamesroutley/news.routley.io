<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/Om-Alve/smolGPT">Original</a>
    <h1>A minimal PyTorch implementation for training your own small LLM from scratch</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto">A minimal PyTorch implementation for training your own small LLM from scratch. Designed for educational purposes and simplicity, featuring efficient training, flash attention, and modern sampling techniques.</p>

<ul dir="auto">
<li><strong>Minimal Codebase</strong>: Pure PyTorch implementation with no abstraction overhead</li>
<li><strong>Modern Architecture</strong>: GPT model with:
<ul dir="auto">
<li>Flash Attention (when available)</li>
<li>RMSNorm and SwiGLU</li>
<li>Efficient top-k/p/min-p sampling</li>
</ul>
</li>
<li><strong>Training Features</strong>:
<ul dir="auto">
<li>Mixed precision (bfloat16/float16)</li>
<li>Gradient accumulation</li>
<li>Learning rate decay with warmup</li>
<li>Weight decay &amp; gradient clipping</li>
</ul>
</li>
<li><strong>Dataset Support</strong>: Built-in TinyStories dataset processing</li>
<li><strong>Custom Tokenizer</strong>: SentencePiece tokenizer training integration</li>
</ul>

<div dir="auto" data-snippet-clipboard-copy-content="pip install torch sentencepiece tqdm requests numpy"><pre>pip install torch sentencepiece tqdm requests numpy</pre></div>
<p dir="auto"><strong>Requirements</strong>:</p>
<ul dir="auto">
<li>Python 3.8+</li>
<li>PyTorch 2.0+ with CUDA</li>
<li>Modern GPU (recommended)</li>
</ul>

<div dir="auto"><h3 tabindex="-1" dir="auto">Option 1: Full Training Cycle</h3><a id="user-content-option-1-full-training-cycle" aria-label="Permalink: Option 1: Full Training Cycle" href="#option-1-full-training-cycle"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ol dir="auto">
<li><strong>Prepare Dataset</strong></li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="python preprocess.py prepare-dataset --vocab-size 4096"><pre>python preprocess.py prepare-dataset --vocab-size 4096</pre></div>
<ol start="2" dir="auto">
<li><strong>Start Training</strong></li>
</ol>

<ol start="3" dir="auto">
<li><strong>Generate Text</strong></li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="python sample.py \
    --prompt &#34;Once upon a time&#34; \
    --num_samples 3 \
    --temperature 0.7 \
    --max_new_tokens 500"><pre>python sample.py \
    --prompt <span><span>&#34;</span>Once upon a time<span>&#34;</span></span> \
    --num_samples 3 \
    --temperature 0.7 \
    --max_new_tokens 500</pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">Option 2: Use Pre-trained Model</h3><a id="user-content-option-2-use-pre-trained-model" aria-label="Permalink: Option 2: Use Pre-trained Model" href="#option-2-use-pre-trained-model"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ol dir="auto">
<li><strong>Download Assets</strong></li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="# Download tokenizer
wget https://huggingface.co/OmAlve/TinyStories-SmolGPT/resolve/main/tok4096.model -P data/

# Download pre-trained checkpoint
wget https://huggingface.co/OmAlve/TinyStories-SmolGPT/resolve/main/ckpt-v1.pt -P out/"><pre><span><span>#</span> Download tokenizer</span>
wget https://huggingface.co/OmAlve/TinyStories-SmolGPT/resolve/main/tok4096.model -P data/

<span><span>#</span> Download pre-trained checkpoint</span>
wget https://huggingface.co/OmAlve/TinyStories-SmolGPT/resolve/main/ckpt-v1.pt -P out/</pre></div>
<ol start="2" dir="auto">
<li><strong>Run Inference</strong></li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="python sample.py \
    --prompt &#34;Once upon a time&#34; \
    --tokenizer_path data/tok4096.model \
    --ckpt_dir out/ \
    --num_samples 3 \
    --max_new_tokens 200 \
    --temperature 0.7"><pre>python sample.py \
    --prompt <span><span>&#34;</span>Once upon a time<span>&#34;</span></span> \
    --tokenizer_path data/tok4096.model \
    --ckpt_dir out/ \
    --num_samples 3 \
    --max_new_tokens 200 \
    --temperature 0.7</pre></div>
<div dir="auto"><h2 tabindex="-1" dir="auto">Pre-trained Model Details üîç</h2><a id="user-content-pre-trained-model-details-" aria-label="Permalink: Pre-trained Model Details üîç" href="#pre-trained-model-details-"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">The provided checkpoint was trained on the TinyStories dataset.</p>
<p dir="auto">Architecture:</p>
<ul dir="auto">
<li>4096-token vocabulary</li>
<li>8 heads</li>
<li>8-layer transformer</li>
<li>512 embedding dimension</li>
<li>Trained on <code>~4 Billion Tokens</code> for around <code>18.5</code> hours</li>
</ul>
<p dir="auto">Validation Loss - <code>1.0491</code></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Om-Alve/smolGPT/blob/main/assets/loss.png"><img src="https://github.com/Om-Alve/smolGPT/raw/main/assets/loss.png" alt="Loss Curve"/></a></p>


<div data-snippet-clipboard-copy-content="Prompt: One day, Lily met a unicorn

Output:
One day, Lily met a unicorn in the park. The unicorn had shiny fur and a pretty dress. Lily asked the unicorn, &#34;Where did you come from?&#34;
The unicorn replied, &#34;I came from the forest and wanted to meet you, Lily. I am here to make sure you are safe.&#34;
Lily and the unicorn played together and had lots of fun. But then, the unicorn started to act funny. Lily didn&#39;t know what was happening. Suddenly, the unicorn turned into a little girl and said, &#34;I was under a spell, and your kindness broke it. Thank you for breaking it.&#34;
Lily was surprised and happy. She gave the unicorn a big hug and they played together all day. From that day on, the unicorn would always come to play with Lily - her new friend."><pre lang="text"><code>Prompt: One day, Lily met a unicorn

Output:
One day, Lily met a unicorn in the park. The unicorn had shiny fur and a pretty dress. Lily asked the unicorn, &#34;Where did you come from?&#34;
The unicorn replied, &#34;I came from the forest and wanted to meet you, Lily. I am here to make sure you are safe.&#34;
Lily and the unicorn played together and had lots of fun. But then, the unicorn started to act funny. Lily didn&#39;t know what was happening. Suddenly, the unicorn turned into a little girl and said, &#34;I was under a spell, and your kindness broke it. Thank you for breaking it.&#34;
Lily was surprised and happy. She gave the unicorn a big hug and they played together all day. From that day on, the unicorn would always come to play with Lily - her new friend.
</code></pre></div>
<div data-snippet-clipboard-copy-content="Prompt: The dragon flew over the mountains

Output:
The dragon flew over the mountains, over the rivers and over the rivers. He was very brave and strong.
One day, the dragon saw something very strange. It was a big, shiny rock. He wanted to know what it was, so he flew down and touched it with his nose. Suddenly, the rock began to move!
The dragon was so surprised! He had never seen anything like it before. He looked around and saw that it was a little mouse! The mouse was very scared and started to run away.
The dragon was very sad. He wanted to help the mouse, so he decided to try and make friends. He flew around and around until he found the mouse. He said hello to the mouse and asked if he wanted to be friends.
The mouse was so happy! He said yes, and they played together all day long. From then on, the dragon and the mouse were the best of friends. They had lots of fun together and the dragon was never lonely again."><pre><code>Prompt: The dragon flew over the mountains

Output:
The dragon flew over the mountains, over the rivers and over the rivers. He was very brave and strong.
One day, the dragon saw something very strange. It was a big, shiny rock. He wanted to know what it was, so he flew down and touched it with his nose. Suddenly, the rock began to move!
The dragon was so surprised! He had never seen anything like it before. He looked around and saw that it was a little mouse! The mouse was very scared and started to run away.
The dragon was very sad. He wanted to help the mouse, so he decided to try and make friends. He flew around and around until he found the mouse. He said hello to the mouse and asked if he wanted to be friends.
The mouse was so happy! He said yes, and they played together all day long. From then on, the dragon and the mouse were the best of friends. They had lots of fun together and the dragon was never lonely again.
</code></pre></div>

<p dir="auto">Key parameters (modify in <code>config.py</code>):</p>
<p dir="auto"><strong>Model Architecture</strong>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="GPTConfig(
    block_size=512,    # Context length
    n_layer=8,         # Number of transformer layers
    n_head=8,          # Number of attention heads
    n_embed=512,       # Embedding dimension
    dropout=0.2,       # Dropout rate
    bias=False         # Use bias in layers
)"><pre><span>GPTConfig</span>(
    <span>block_size</span><span>=</span><span>512</span>,    <span># Context length</span>
    <span>n_layer</span><span>=</span><span>8</span>,         <span># Number of transformer layers</span>
    <span>n_head</span><span>=</span><span>8</span>,          <span># Number of attention heads</span>
    <span>n_embed</span><span>=</span><span>512</span>,       <span># Embedding dimension</span>
    <span>dropout</span><span>=</span><span>0.2</span>,       <span># Dropout rate</span>
    <span>bias</span><span>=</span><span>False</span>         <span># Use bias in layers</span>
)</pre></div>
<p dir="auto"><strong>Training</strong>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="TrainingConfig(
    batch_size=64,
    max_iters=30000,
    learning_rate=6e-4,
    weight_decay=0.1,
    grad_clip=1.0,
    warmup_iters=1000
)"><pre><span>TrainingConfig</span>(
    <span>batch_size</span><span>=</span><span>64</span>,
    <span>max_iters</span><span>=</span><span>30000</span>,
    <span>learning_rate</span><span>=</span><span>6e-4</span>,
    <span>weight_decay</span><span>=</span><span>0.1</span>,
    <span>grad_clip</span><span>=</span><span>1.0</span>,
    <span>warmup_iters</span><span>=</span><span>1000</span>
)</pre></div>

<div data-snippet-clipboard-copy-content="om-alve-smolgpt/
‚îú‚îÄ‚îÄ config.py       - Model &amp; training configuration
‚îú‚îÄ‚îÄ dataset.py      - Data loading &amp; preprocessing
‚îú‚îÄ‚îÄ model.py        - GPT model implementation
‚îú‚îÄ‚îÄ preprocess.py   - Dataset preparation scripts
‚îú‚îÄ‚îÄ sample.py       - Text generation script
‚îú‚îÄ‚îÄ tokenizer.py    - Tokenizer wrapper
‚îî‚îÄ‚îÄ train.py        - Main training loop"><pre><code>om-alve-smolgpt/
‚îú‚îÄ‚îÄ config.py       - Model &amp; training configuration
‚îú‚îÄ‚îÄ dataset.py      - Data loading &amp; preprocessing
‚îú‚îÄ‚îÄ model.py        - GPT model implementation
‚îú‚îÄ‚îÄ preprocess.py   - Dataset preparation scripts
‚îú‚îÄ‚îÄ sample.py       - Text generation script
‚îú‚îÄ‚îÄ tokenizer.py    - Tokenizer wrapper
‚îî‚îÄ‚îÄ train.py        - Main training loop
</code></pre></div>

<p dir="auto">Contributions welcome! Please open an issue or PR for:</p>
<ul dir="auto">
<li>Bug fixes</li>
<li>Performance improvements</li>
<li>New features</li>
</ul>
<hr/>
<p dir="auto"><strong>Note</strong>: This implementation is inspired by modern LLM training practices and adapted for educational purposes. For production use, consider scaling up model size and dataset.</p>
</article></div></div>
  </body>
</html>
