<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.dbrgn.ch/2023/1/14/threema/">Original</a>
    <h1>Some thoughts on the ETH&#39;s Threema analysis</h1>
    
    <div id="readability-page-1" class="page"><div id="wrapper">
        
        

        

        <section id="content">

    

        

    <div>
        <p><em>Let&#39;s start with a disclaimer: I work at Threema. I&#39;m a software engineer
there, working on various systems. I&#39;m not a founder or part of the management,
but joined the company a few years ago. In this blog, I&#39;m only speaking for
myself, not for my employer. I&#39;m obviously not impartial, but this blog post
contains purely my own views, it was not commissioned, written or altered by
my employer.</em></p>
<h2>Contents</h2>
<ul>
<li><a href="#intro">Intro</a></li>
<li><a href="#history">Where&#39;s Threema Coming From?</a></li>
<li><a href="#choices">Protocol Choices</a></li>
<li><a href="#expectations">Expectations Towards Messengers</a></li>
<li><a href="#findings">The Findings</a>: <a href="#attack1">Attack 1</a>, <a href="#attack2">Attack 2</a>,
  <a href="#attack3">Attack 3</a>, <a href="#attack4">Attack 4</a>, <a href="#attack5">Attack 5</a>, <a href="#attack6">Attack
  6</a>, <a href="#attack7">Attack 7</a></li>
<li><a href="#outro">Outro</a></li>
</ul>
<h2><a name="intro"></a>Intro</h2>
<p>On Tuesday, <a href="https://breakingthe3ma.app/files/Threema-PST22.pdf">a new thesis paper by a master student at ETH
Zürich</a> was published. It
contains an analysis of various protocols used by Threema, resulting in 7
attacks (6 of them new). The official statement by Threema <a href="https://threema.ch/en/blog/posts/news-alleged-weaknesses-statement">can be found
here</a>.</p>
<p>In the last few days, there have been quite some heated discussions and
strongly worded comments on the internet (from both sides), with wordings like
&#34;Threema was broken&#34;, &#34;riddled with vulnerabilities&#34;, &#34;deadly flaws&#34; vs
&#34;analysis of outdated protocol&#34; or &#34;hopelessly oversold findings&#34;. I don&#39;t want
to write about that, but would instead welcome a more technical discussion.</p>
<p>The goal is to give context to some design decisions that might seem a bit odd
nowadays, and to take a look at the preconditions and impact of the findings.
The blogpost has gotten a bit long, I apologize for that.</p>
<h2><a name="history"></a>Where&#39;s Threema Coming From?</h2>
<p>The first version of Threema was written by Manuel in 2012, in a time where
WhatsApp (not yet owned by Facebook) would blast your messages through the
internet café without any encryption whatsoever. By opening Wireshark in
Starbucks, you could read all conversations that people around you were having.</p>
<p>In the instant messaging world, especially on mobile, there were barely any
secure options. WhatsApp (released in 2009) was quickly becoming widely used.
People were still using Windows Live Messenger and chatted over Facebook
(without TLS). Some nerds used XMPP with OTR (I was one of them, running my own
ejabberd instance for a few years), but in practice you would either not verify
the sessions at all – because it&#39;s a hassle – or the sessions would regularly
break (especially across different clients). Sending files had a success rate
of maybe 20%.</p>
<p>Peter Sunde (of Pirate Bay fame) announced
<a href="http://web.archive.org/web/20131122032027/https://heml.is/">Hemlis</a> the
following year in 2013, an E2EE messenger that collected 150k USD in a
crowdfunding, but was discontinued before it was out of beta. The Swiss company
Qnective published
<a href="https://web.archive.org/web/20131127130741/https://www.myenigma.com/">myENIGMA</a>
in 2013 as well, but it failed to gain traction. And then there was
<a href="http://web.archive.org/web/20131126030123/https://www.whispersystems.org/">TextSecure</a>,
made by Twitter, which – at that time – was a replacement for your SMS app and
which would opportunistically encrypt SMS messages towards recipients that also
had TextSecure installed. Open Whisper Systems was founded in 2013, and until
2014 TextSecure had no support for group chats. (Today, the codebases of
TextSecure and RedPhone have evolved into Signal.) This all happened <em>after</em> the
first version of Threema was released.</p>
<p>In summary: Secure messaging wasn&#39;t pervasive at all, and the existing options
were either overly technical, had a bad user experience or never made it out of
beta. That&#39;s why Manuel wrote the first version of Threema for himself and his
friends, and released it for iOS in December 2012.</p>
<p>Besides having end-to-end encryption of all messages, you could also scan the
public key of another contact in form of a QR code, and this would <a href="https://threema.ch/en/faq/levels_expl">mark the
contact as verified in the UI</a>. It was
implemented in a way that non-technical people could understand and use. As far
as I know, Threema was the first messenger to offer a simple way of
authenticating contacts in a mobile messenger with a single scan, and remained
the only one for several years. Other messengers sometimes provided end-to-end
encryption, but often without authentication, opening up the possibility of
MITM attacks. (Signal has introduced the marking of conversations as verified
<a href="https://signal.org/blog/verified-safety-number-updates/">in 2017</a>.)</p>
<h2><a name="choices"></a>Protocol Choices</h2>
<p>On the protocol side: In 2012, TLS was in a bit of a bad state. Mobile
operating systems commonly offered no modern ciphersuites at all and were
sometimes plagued with bad random number generators. (For example: Android
4.0.4 didn&#39;t even support TLS 1.1 yet.)</p>
<p>Of course, for asynchronous E2EE messaging, TLS isn&#39;t really an option anyways.
OTR was around at that time, but it required both parties to be online at the
same time in order to establish a session. This means that you cannot send a
message to a recipient before that person has accepted the conversation
request. The Signal protocol didn&#39;t exist yet and the Axolotl Ratchet by Trevor
Perrin and Moxie Marlinspike was only developed the following year in 2013 (and
published in 2014).</p>
<p>With these options, the protocol choices by Threema at launch were:</p>
<ul>
<li>A client-server protocol modelled after <a href="https://curvecp.org/">CurveCP</a>,
  which is a protocol developed by Daniel &#34;djb&#34; Bernstein and announced at the
  CCC congress in 2010. (This protocol is also vulnerable to the ephemeral key
  compromise weakness described by the authors of the ETH thesis.)</li>
<li>An end-to-end encryption protocol based on the NaCl library (with NaCl also
  developed and published by Bernstein). Threema E2E messages use a classical
  binary type-value format and random padding to prevent the server from
  guessing the message contents based on the length of the encrypted message.
  Contacts use a long-lived public/private keypair, just like PGP.</li>
<li>HTTPS for the contact discovery API.</li>
</ul>
<p>Besides simplicity of implementation (which generally is an important aspect in
secure software), the choice of NaCl long-lived keys also enabled that
out-of-band key verification feature mentioned above. Identities are
irrevocably tied to a public key, meaning that once you&#39;ve verified and stored
an identity, you can be sure that messages from that identity are encrypted by
the corresponding private key. In contrast to protocols where each device has
its own device keys, and where users get used to regular &#34;the key of your
conversation partner has changed&#34; warnings, this means that once you&#39;ve fetched
the public key of a user, the directory server isn&#39;t able to replace that
public key with a different one. For the case where an identity is compromised,
there is a key revocation feature built-in.</p>
<p>I&#39;d argue that – given the historical context and the &#34;don&#39;t roll your own
crypto&#34; approach – these choices were sensible and appropriate. Both the
client-server protocol and the end-to-end encryption format use concepts and
libraries from Daniel Bernstein, who is quite the authority in cryptography. I
especially find the following quote from the paper a bit displaced:</p>
<blockquote>
<p>To their credit, Threema’s developers did (largely) avoid “rolling their own
crypto” but this advice should be extended to “don’t roll your own
cryptographic protocol”. <strong>Of course this advice is only useful if good
alternatives are available. In the particular case of the C2S protocol,
Threema could have adopted the Noise IK protocol or just used TLS.</strong></p>
</blockquote>
<p>I&#39;ve discussed TLS (and its state on mobile platforms) above. And the Noise
Protocol Framework (which incidentally is also inspired by NaCl and CurveCP)
simply didn&#39;t exist yet (AFAIK it was first published in 2013). Basing a
protocol on CurveCP is precisely trying to avoid inventing cryptographic
protocols from scratch. (It&#39;s unfortunate that both CurveCP and our protocol
contained a flaw, and that we didn&#39;t notice this before.)</p>
<h2><a name="expectations"></a>Expectations Towards Messengers</h2>
<p>Nowadays, the world looks a bit different, especially with regards to the
expectations towards a messenger. Two of the &#34;recurring themes&#34; are perfect
forward secrecy and post-compromise security. There are various efforts
underway to improve our protocols in this regard. One of them was the
introduction of perfect forward secrecy – with the marketing name &#34;Ibex&#34; – as
an additional layer, so that it can be rolled out in an interoperable way.</p>
<p>The development of Ibex began more than a year ago in cooperation with a
cryptographer, and was <em>not</em> in reaction to the ETH research group (something
that was claimed in interviews, even though the researchers knew from the
meeting with Threema that we were already working on PFS for a while). We
chose to develop our own protocol due to compatibilty reasons: Using a
different, incompatible protocol would mean splitting the entire userbase, and
becoming incompatible with existing apps, third party clients and server-side
integrations. The decision to cooperate with an external cryptographer during
the design phase was precisely to minimize the risks of &#34;rolling your own
cryptographic protocol&#34;.</p>
<p>There were also a lot of other changes over the years to improve privacy and
security properties of our protocols and systems. Often, design choices that may
seem odd at first glance, are guided by external constraints. For example, early
versions of iOS did not allow waking up an application in response to a push
notification. This means that if you&#39;d get an end-to-end encrypted message, the
app would not know who it&#39;s from, and could not display any name on the lock
screen. Without UX features like that, the user experience is not good, clearly
worse than when using a messenger that does not value privacy. As a workaround,
the first version of Threema had the concept of the &#34;public nickname&#34;, chosen
by the user (optional and explicitly indicated to be public), which is included
in the non-E2EE header of every message. Nowadays, iOS has the concept of
notification extensions, which can decrypt incoming messages, so the public
nickname became unnecessary metadata. In 2021 (after we dropped support for iOS
versions that didn&#39;t yet support notification extensions) we implemented
support for processing E2EE metadata (including the nickname). Additionally, we
started encrypting the push payload between the chat server and Apple&#39;s APNs
server. We also used this occasion for more modern algorithmic design choices
like BLAKE2b as KDF and Protobuf as serialization format. (We&#39;ve started using
BLAKE2b for a while now for newer protocols, to achieve better key separation
and to avoid payload confusion issues).</p>
<p>In summary, expectations towards mobile messengers are changing and
requirements are increasing. Not just on the cryptographic side. A mobile
messenger, which was essentially a glorified SMS app in the past, must now be
able to send files, view and edit videos and photos, offer end-to-end encrypted
1:1 and group calls, offer multi-device capabilities and ease of use from the
desktop, and much more, all while remaining secure and shipping regular updates
and features.</p>
<p>We are certainly aware of these expectations and are constantly trying to
review and improve our code and protocols. In some cases, we seem to do well
(we have passed multiple external audits of our apps successfully without any
major issues so far), and in other cases, we did not and should have been more
proactive (e.g. trying to apply formal verification methods to the protocols).
I reject the implication from the thesis though that Threema was only reactive,
and at the same time acknowledge that we must (and will) improve certain
processes. Some changes are already in progress, and more are to come.</p>
<h2><a name="findings"></a>The Findings</h2>
<p>Now on to the main findings! One thing that bugged me about the <a href="https://breakingthe3ma.app/">marketing
website</a> of the research team was the fact, that
it summarized the broad idea and the worst-case impact for each attack
scenario, but mostly did not mention the requirements, assumptions and
prerequisites. A user that isn&#39;t technical enough to read and understand the
paper, but reads through the website, must assume that it is highly unsafe to
keep using Threema. In the worst case, they&#39;ll go back to use something like
WhatsApp or Telegram (since &#34;messengers are all unsafe, so it doesn&#39;t matter
which one to pick&#34;).</p>
<p>So let&#39;s look at the attacks, the impact and the requirements for each of them
at the time of initial disclosure. (Note: I&#39;m not trying to imply that these
findings aren&#39;t valid, or that they aren&#39;t important, I only want to show what
they mean in practice.)</p>

<h3>⚔️ <a name="attack1"></a>Attack 1: C2S Ephemeral Key Compromise</h3>
<p><strong>What was required to pull off the attack?</strong></p>
<ol>
<li>
<p>A value that is used in the client-server-handshake (an ephemeral key) must
   be extracted from the mobile app. For this, an attacker must have access to
   the value in the app&#39;s memory, something that requires breaking Android&#39;s
   core security concepts, for example by infecting the user&#39;s device with
   targeted malware that breaks app isolation and gives full access to the
   memory. Additionally, even with full memory access it is non-trivial to
   actually identify the bytes belonging to that ephemeral key.</p>
</li>
<li>
<p>A network connection handshake between the client and the server must be
   recorded for the user that is being attacked. For this, the attacker needs
   access to the network of the user, of the server, or anywhere in between.</p>
</li>
<li>
<p>To avoid detection, the user&#39;s app must not be connected when the attacker
   connects to the server. If the user&#39;s app is connected at the same time
   (something that usually happens at least whenever a new message arrives due
   to push notifications), they will get a warning that another device with the
   same identity has connected to the server. While this warning trigger system
   wasn&#39;t always perfect in practice (due to a lot of false positives from
   users that didn&#39;t uninstall Threema when migrating to a new phone), there is
   always the risk of detection.</p>
</li>
</ol>
<p><strong>What could be gained by pulling off this attack?</strong></p>
<ul>
<li>An attacker can read some message metadata (e.g. the Threema ID of the
  sender, the Threema ID of the recipient or the timestamp of the message) of
  the otherwise encrypted messages, but not the E2EE message contents.</li>
<li>Based on this information, an attacker can delete messages from the server&#39;s
  message queue by acknowledging the receipt towards the server. When the real
  user reconnects, they will not get that message anymore. However, without
  knowing the content of the messages, it&#39;s hard to decide which messages to
  drop and which messages to keep, in order to make a semantic difference in
  the conversation, without risking being discovered.</li>
</ul>
<p><strong>How was this fixed?</strong></p>
<ul>
<li>The vouch box in the C2S handshake protocol was adjusted, in order to avoid
  this vulnerability.</li>
<li>When using PFS (&#34;Ibex&#34;) in a 1:1 chat, reordered and missing messages are
  detected and the user is warned.</li>
</ul>
<p><strong>Other notes</strong></p>
<ul>
<li>If an attacker manages to access the memory of arbitrary apps on a
  smartphone, then that entire phone (and connected accounts) must be
  considered completely compromised, and losing an ephemeral handshake key is
  probably the least of your worries.</li>
</ul>

<h3>⚔️ <a name="attack2"></a>Attack 2: Vouch Box Forgery</h3>
<p><strong>What was required to pull off the attack?</strong></p>
<ol>
<li>
<p>Have access to approximately 8100 CPU cores for 24 hours. Run a program to
   compute a certain value X.</p>
</li>
<li>
<p>Convince a user to use the server&#39;s public key like a contact public key.
   There are two variants suggested in the paper:</p>
<ul>
<li>
<p>a) Request a Threema Gateway ID with a certain public key that is
   equivalent to the server&#39;s public key and pay for that ID (64 CHF). Or...</p>
</li>
<li>
<p>b) Get read and write access to an Android data backup of the target user.
   Use a vulnerability in the open source Zip4j Java library (used by the
   Threema app) to modify the encrypted backup (without knowing the contents)
   in a way that manages to precisely overwrite their own public key inside
   the backup file with the server&#39;s public key. (<small>Details: Know where
   in the encrypted and compressed contact list backup inside the ZIP file
   his public key is stored. It could be anywhere in a range of typically
   several thousand bytes; the adversary needs to guess blindly, must hit the
   exact byte offset and typically only gets one chance. Overwrite the
   location thus found/guessed, XORing in the difference between their own
   (compressed) public key and the server’s public key (as ZIP encryption
   uses AES-CTR). The fact that the backup data is compressed further
   complicates the exploit to the point where the adversary would essentially
   need to know the entire exact backup contents in advance.</small>)</p>
</li>
</ul>
</li>
<li>
<p>Now the user must restore this manipulated backup on their device.</p>
</li>
<li>
<p>After this has happened, convince the target user to send the exact value X
   (which could look like this: <code>u9j6ߓ&#39;jjखԻ^߃1כW:-́;ܡRA</code>) to the Gateway ID from
   2a or to the ID behind the public key from 2b. Once the user has sent this
   text (only that precise text, no additional text) to the attacker, there is a
   1-in-254 chance that the attack has succeeded. For a successful attack, the
   text needs to be sent to the attacker by the user approximately 200 times on
   average.</p>
</li>
</ol>
<p><strong>What could be gained by pulling off this attack?</strong></p>
<p>The same as for attack 1:</p>
<ul>
<li>An attacker can read some message metadata (e.g. the Threema ID of the
  sender, the Threema ID of the recipient or the timestamp of the message) of
  the otherwise encrypted messages, but not the E2EE message contents.</li>
<li>Based on this information, an attacker can delete messages from the server&#39;s
  message queue by acknowledging the receipt towards the server. When the real
  user reconnects, they will not get that message anymore. However, without
  knowing the content of the messages, it&#39;s hard to decide which messages to
  drop and which messages to keep, in order to make a semantic difference in
  the conversation, without risking being discovered.</li>
</ul>
<p><strong>How was this fixed?</strong></p>
<ul>
<li>Threema Gateway does not allow creating accounts with certain affected public
  keys anymore. The account created by the researchers was suspended. We
  checked for other Gateway IDs with such a key, but found none.</li>
<li>The vouch box in the C2S handshake protocol was adjusted, in order to avoid
  this vulnerability.</li>
<li>When using PFS (&#34;Ibex&#34;) in a 1:1 chat, reordered and missing messages are
  detected and the user is warned.</li>
</ul>
<p><strong>Other notes</strong></p>
<p>The marketing website of the research team describes this attack as follows:</p>
<blockquote>
<p>This attack means that, under some circumstances, a user might compromise his
or her own account by simply sending a message to another user. </p>
</blockquote>
<p>I&#39;m leaving it up to the reader to decide wether this is a fair summary of the
attack.</p>

<h3>⚔️ <a name="attack3"></a>Attack 3: Message Reordering and Deletion</h3>
<p><strong>What was required to pull off the attack?</strong></p>
<ol>
<li>The attacker needs full access to Threema&#39;s chat server</li>
<li>When deleting messages: The sender of a message must not pay attention to the
   delivery receipts. (The sender can see if some messages aren&#39;t delivered,
   because the delivery receipt isn&#39;t being received for this message. It&#39;s
   suspicious if the message before and after are marked as delivered, but the
   one in between still seems undelivered.)</li>
</ol>
<p><strong>What could be gained by pulling off this attack?</strong></p>
<p>Very similar to attacks 1 and 2:</p>
<ul>
<li>An attacker can read some message metadata (e.g. the Threema ID of the
  sender, the Threema ID of the recipient or the timestamp of the message) of
  the otherwise encrypted messages, but not the E2EE message contents.</li>
<li>Based on this information, an attacker can delete or reorder messages.
  However, without knowing the content of the messages, if an attacker would
  like to change semantics of a conversation, it would be guesswork which
  messages to reorder, and how to reorder them.</li>
</ul>
<p><strong>How was this fixed?</strong></p>
<ul>
<li>When using PFS (&#34;Ibex&#34;) in a 1:1 chat, reordered and missing messages are
  detected and the user is warned.</li>
</ul>
<!--

**Other notes**

The described attack only focusses on the protocol level. However, if ensuring
unmodified message ordering is a desired property of a messaging system, then
the actual display of the messages in the application is relevant. It doesn't
matter whether an inconsistency is due to the protocol messages being received
in a certain order, or a bug in the application. For example, even with PFS
built-in, Signal has and has had multiple bugs that result in reordered
messages in the application (Desktop:
[1](https://github.com/signalapp/Signal-Desktop/issues/5475),
[2](https://github.com/signalapp/Signal-Desktop/issues/2714),
[3](https://github.com/signalapp/Signal-Desktop/issues/2424), Android:
[4](https://github.com/signalapp/Signal-Android/issues/9580),
[5](https://github.com/signalapp/Signal-Android/issues/9978), iOS:
[6](https://github.com/signalapp/Signal-iOS/issues/3511),
[7](https://github.com/signalapp/Signal-iOS/issues/5241)).

Message ordering in asynchronous messaging systems is hard. To quote a Signal
developer from one of the issue threads linked above:

> This isn't an easily-solvable problem given that Signal does client-side
> fanout for group message sends. That means if I'm sending a message to a
> group with 20 people in it, I send that message 20 times. This is because the
> service doesn't know who is in the group -- a purposeful and important
> property.
>
> If multiple people are sending messages at the same time in a larger group,
> that means recipients could receive messages in different orders depending on
> how each sender fanned-out the messages. We're thinking about how this could
> be improved, but it's a hard problem.

-->


<h3>⚔️ <a name="attack4"></a>Attack 4: Message Replay and Reflection</h3>
<p><strong>What was required to pull off the attack?</strong></p>
<ol>
<li>The attacker needs full access to Threema&#39;s chat server over a longer time
   period</li>
<li>The attacker must store messages sent to a certain user</li>
<li>The attacked user must use the Android version of the app</li>
<li>The attacker must know when a user restores a backup</li>
</ol>
<p><strong>What could be gained by pulling off this attack?</strong></p>
<ul>
<li>When a user reinstalls the app and restores a backup on Android, or when the
  user switches the device (something that probably happens every few years for
  typical users), then the attacker could re-send old messages (from before the
  app was (re)installed) to that user. To the recipient, these messages could
  look like they were sent only recently.</li>
</ul>
<p><strong>How was this fixed?</strong></p>
<ul>
<li>We&#39;re adding the <code>createdAt</code> timestamp of a message to the encrypted metadata
  part of the message, so that the user is warned if the non-encrypted
  timestamp deviates significantly from the encrypted timestamp. (Note that it
  is deliberate that the server can overwrite the message timestamps, since
  this can be used to fix client-generated timestamps for users that have set
  their phones to the wrong timezone and thus appear to be sending messages
  from the future).</li>
<li>When using PFS (&#34;Ibex&#34;) in a 1:1 chat, replayed messages are detected and the
  user is warned.</li>
</ul>

<h3>⚔️ <a name="attack5"></a>(Attack 5: Kompromat)</h3>
<p><em>(This attack was already discovered by another researcher in 2021 and patched
on all platforms soon after. While the ETH researchers have strictly speaking
not uncovered this issue – in contrast to some statements in the paper and
website – I&#39;m including it here for completeness.).</em></p>
<p><strong>What was required to pull off the attack?</strong></p>
<ol>
<li>The attacked user A must use an app version older than December 2021 (as this
   attack was already discovered by another researcher in 2021 and patched on
   all platforms)</li>
<li>The attacker needs full access to Threema&#39;s directory server</li>
<li>When the attacked user A authenticates against the directory server, it must
   receive a modified authentication challenge where an ephemeral public key is
   replaced with the long-term public key of another Threema user B.</li>
</ol>
<p><strong>What could be gained by pulling off this attack?</strong></p>
<ul>
<li>With every modified authentication challenge sent by the attacked user A, one
  message will be encrypted by user A so that it can be sent to A or B and it
  appears to be encrypted and signed by the other party.</li>
</ul>
<p><strong>How was this fixed?</strong></p>
<ul>
<li>The immediate vulnerability was fixed in the apps by ensuring that the
  authentication challenge sent by the server does not start with a prefix that
  could also be the start of a valid end-to-end message</li>
<li>To also tackle the root cause of this issue (payload confusion due to missing
  key separation), the directory server authentication was updated to a new
  format that is not vulnerable to payload confusion</li>
</ul>

<h3>⚔️ <a name="attack6"></a>Attack 6: Cloning via Threema ID Export</h3>
<p><strong>What was required to pull off the attack?</strong></p>
<ol>
<li>Full access to an unlocked phone running the Threema app</li>
<li>The Threema app may not be protected with access protection like a passphrase
   or biometric lock (or the user must be compelled to provide this information)</li>
<li>A backup must be exported without the user noticing</li>
<li>Once the account has been restored on a different device by the attacker,
   the user and the attacker may not connect to the server at the same time,
   otherwise a server warning will be generated on the user&#39;s device, stating
   &#34;another connection for the same identity has been established.&#34;</li>
</ol>
<p><strong>What could be gained by pulling off this attack?</strong></p>
<ul>
<li>Full (but not undetectable) account compromise</li>
<li>If this happens, the user must revoke their identity and generate a new one</li>
</ul>
<p><strong>How was this fixed?</strong></p>
<ul>
<li>The &#34;rogue device warning&#34; detection mechanism was updated, so that a user
  will be warned if an attacker connects to the server with the same identity,
  even if the user was not connected at that time. (This feature is already
  implemented, but is being phased-in incrementally on the server side, to
  ensure that there aren&#39;t unwanted false positive warning messages shown to
  the user.)</li>
<li>We&#39;re thinking about additional/enforced access protection when exporting a
  backup, even if the user hasn&#39;t set up access protection for the app.</li>
</ul>
<p><strong>Other notes</strong></p>
<p>The paper notes:</p>
<blockquote>
<p>This is in contrast to Threema, where a Threema ID export is undetectable on
the victim device after it happened and, due to the lack of forward secrecy
and post-compromise security, irreversibly forfeits all security.</p>
</blockquote>
<p>While it is correct that the <em>creation</em> of a backup is not detectable by the
user, its <em>usage</em> had a high chance to be detectable because the server
generates warnings on a device if another device repeatedly connects with the
same ID. (With the updated rogue device warning mechanism, it should not be
possible anymore to connect to the server without triggering a warning on the
attacked user&#39;s device, even if that device is offline.)</p>

<h3>⚔️ <a name="attack7"></a>Attack 7: Compression Side-Channel</h3>
<p><strong>What was required to pull off the attack?</strong></p>
<ol>
<li>User must have enabled Threema Safe</li>
<li>User must have the attacker as a contact in the app, or they must not have
   enabled the &#34;block unknown&#34; privacy setting</li>
<li>Have a way to measure the size of a user&#39;s uploaded Threema Safe backup.
   This can be done with one of two methods:<ul>
<li>a) Have access to the Threema Safe server where backups are stored.
   Additionally, have a way to identify (on the Threema Safe backup server)
   which backup belongs to the user. By design, it is not possible to
   determine who a backup belongs to by looking at the encrypted backup file.
   One option would be knowing the IP address of the uploader, and being able
   to log/correlate the IP address of the backup upload. In today&#39;s mobile
   networks, the wide use of CGNAT – where hundreds or thousands of devices
   share the same public IP – may make this harder.</li>
<li>b) Have access to the target device&#39;s network, or to the unlocked
   physical device. Record the network traffic between the device and
   Threema&#39;s backup server.</li>
</ul>
</li>
<li>Have a way to restart the user&#39;s app tens of thousands of times. In the
   paper, they required a median of 19.4k backup attempts, and a mean of 23.4k
   attempts. The way this was done by the researcher is by using Android
   debugging tools to stop and restart the Threema app in an automated way.
   This requires both physical access to the unlocked phone over a long period
   (between a few hours to multiple days) and enabling developer mode on said
   Android device.</li>
<li>After every restart, the attacker must send a message to the attacked user,
   in order to change the nickname in the user&#39;s address book.</li>
</ol>
<p><strong>What could be gained by pulling off this attack?</strong></p>
<ul>
<li>Full (but not undetectable) account compromise</li>
<li>If this happens, the user must revoke their identity and generate a new one</li>
<li>In the experiment described in the paper, once <em>all</em> requirements above were
  fulfilled, they had a success rate of roughly 47%</li>
</ul>
<p><strong>How was this fixed?</strong></p>
<ul>
<li>Compression for Safe backups was disabled</li>
</ul>

<h2><a name="outro"></a>Outro</h2>
<p>The findings were disclosed to Threema on 2022-10-03 and acknowledged on the
same day. The first server-side mitigations were deployed the same day. The
first batch of client-side mitigations was released on 2022-10-27, more
mitigations in the apps were published on 2022-11-29. Further mitigations and
protocol improvements are being worked on. Development of Ibex (our protocol
for PFS on the end-to-end layer) already began over a year ago and was
initially released to both platforms in December. An independent formal
security analysis is already on the way.</p>
<p>I hope that researchers will keep poking at our open source apps and our
protocols, in order to make them better and more secure. We welcome coordinated
disclosure and also run a bug bounty program with bounties up to 10&#39;000 CHF.</p>
<p>We will keep improving our apps, adding new features in a way that&#39;s as
privacy-preserving as possible, and we will keep auditing and improving both
our protocols and implementations.</p>
<p>Happy 2023!</p>
    </div>

        





        </section>
    </div></div>
  </body>
</html>
