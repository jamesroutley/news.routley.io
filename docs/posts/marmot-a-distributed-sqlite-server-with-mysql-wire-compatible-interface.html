<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/maxpert/marmot">Original</a>
    <h1>Marmot – A distributed SQLite server with MySQL wire compatible interface</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto"><a href="https://goreportcard.com/report/github.com/maxpert/marmot" rel="nofollow"><img src="https://camo.githubusercontent.com/a9cf99f212f56b414c865728a2659a62b2129d1edcf479e5a53d1366dc2def36/68747470733a2f2f676f7265706f7274636172642e636f6d2f62616467652f6769746875622e636f6d2f6d6178706572742f6d61726d6f74" alt="Go Report Card" data-canonical-src="https://goreportcard.com/badge/github.com/maxpert/marmot"/></a>
<a href="https://discord.gg/AWUwY66XsE" rel="nofollow"><img src="https://camo.githubusercontent.com/dfd80a5843107ada4de21a02a89c0bb029f240e404f38ee2b101e784685e0e8e/68747470733a2f2f62616467656e2e6e65742f62616467652f69636f6e2f646973636f72643f69636f6e3d646973636f7264266c6162656c3d4d61726d6f74" alt="Discord" data-canonical-src="https://badgen.net/badge/icon/discord?icon=discord&amp;label=Marmot"/></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/7d665d92a54ac639b00283b01653885ccfb206dab2d80fd32a1674608b7a6c03/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6d6178706572742f6d61726d6f74"><img src="https://camo.githubusercontent.com/7d665d92a54ac639b00283b01653885ccfb206dab2d80fd32a1674608b7a6c03/68747470733a2f2f696d672e736869656c64732e696f2f6769746875622f6c6963656e73652f6d6178706572742f6d61726d6f74" alt="GitHub" data-canonical-src="https://img.shields.io/github/license/maxpert/marmot"/></a></p>

<p dir="auto">Marmot v2 is a leaderless, distributed SQLite replication system built on a gossip-based protocol with distributed transactions and eventual consistency.</p>
<p dir="auto"><strong>Key Features:</strong></p>
<ul dir="auto">
<li><strong>Leaderless Architecture</strong>: No single point of failure - any node can accept writes</li>
<li><strong>MySQL Protocol Compatible</strong>: Connect with any MySQL client (DBeaver, MySQL Workbench, mysql CLI)</li>
<li><strong>WordPress Compatible</strong>: Full MySQL function support for running distributed WordPress</li>
<li><strong>Distributed Transactions</strong>: Percolator-style write intents with conflict detection</li>
<li><strong>Multi-Database Support</strong>: Create and manage multiple databases per cluster</li>
<li><strong>DDL Replication</strong>: Distributed schema changes with automatic idempotency and cluster-wide locking</li>
<li><strong>Production-Ready SQL Parser</strong>: Powered by rqlite/sql AST parser for MySQL→SQLite transpilation</li>
<li><strong>CDC-Based Replication</strong>: Row-level change data capture for consistent replication</li>
</ul>

<div dir="auto"><h3 tabindex="-1" dir="auto">The Problem with Traditional Replication</h3><a id="user-content-the-problem-with-traditional-replication" aria-label="Permalink: The Problem with Traditional Replication" href="#the-problem-with-traditional-replication"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">MySQL active-active requires careful setup of replication, conflict avoidance, and monitoring. Failover needs manual intervention. Split-brain scenarios demand operational expertise. This complexity doesn&#39;t scale to edge deployments.</p>

<ul dir="auto">
<li><strong>Zero operational overhead</strong>: Automatic recovery from split-brain via eventual consistency + anti-entropy</li>
<li><strong>No leader election</strong>: Any node accepts writes, no failover coordination needed</li>
<li><strong>Direct SQLite access</strong>: Clients can read the local SQLite file directly for maximum performance</li>
<li><strong>Tunable consistency</strong>: Choose ONE/QUORUM/ALL per your latency vs durability needs</li>
</ul>

<ul dir="auto">
<li>Ecosystem compatibility - existing drivers, ORMs, GUI tools work out-of-box</li>
<li>Battle-tested wire protocol implementations</li>
<li>Run real applications like WordPress without modification</li>
</ul>

<p dir="auto">Marmot excels at <strong>read-heavy edge scenarios</strong>:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Use Case</th>
<th>How Marmot Helps</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Distributed WordPress</strong></td>
<td>Multi-region WordPress with replicated database</td>
</tr>
<tr>
<td><strong>Lambda/Edge sidecars</strong></td>
<td>Lightweight regional SQLite replicas, local reads</td>
</tr>
<tr>
<td><strong>Edge vector databases</strong></td>
<td>Distributed embeddings with local query</td>
</tr>
<tr>
<td><strong>Regional config servers</strong></td>
<td>Fast local config reads, replicated writes</td>
</tr>
<tr>
<td><strong>Product catalogs</strong></td>
<td>Geo-distributed catalog data, eventual sync</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<div dir="auto"><h3 tabindex="-1" dir="auto">When to Consider Alternatives</h3><a id="user-content-when-to-consider-alternatives" aria-label="Permalink: When to Consider Alternatives" href="#when-to-consider-alternatives"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li><strong>Strong serializability required</strong> → CockroachDB, Spanner</li>
<li><strong>Single-region high-throughput</strong> → PostgreSQL, MySQL directly</li>
<li><strong>Large datasets (&gt;100GB)</strong> → Sharded solutions</li>
</ul>

<div dir="auto" data-snippet-clipboard-copy-content="# Start a single-node cluster
./marmot-v2

# Connect with MySQL client
mysql -h localhost -P 3306 -u root

# Or use DBeaver, MySQL Workbench, etc."><pre><span><span>#</span> Start a single-node cluster</span>
./marmot-v2

<span><span>#</span> Connect with MySQL client</span>
mysql -h localhost -P 3306 -u root

<span><span>#</span> Or use DBeaver, MySQL Workbench, etc.</span></pre></div>

<div dir="auto" data-snippet-clipboard-copy-content="# Test DDL and DML replication across a 2-node cluster
./scripts/test-ddl-replication.sh

# This script will:
# 1. Start a 2-node cluster
# 2. Create a table on node 1 and verify it replicates to node 2
# 3. Insert data on node 1 and verify it replicates to node 2
# 4. Update data on node 2 and verify it replicates to node 1
# 5. Delete data on node 1 and verify it replicates to node 2

# Manual cluster testing
./examples/start-seed.sh              # Start seed node (port 8081, mysql 3307)
./examples/join-cluster.sh 2 localhost:8081  # Join node 2 (port 8082, mysql 3308)
./examples/join-cluster.sh 3 localhost:8081  # Join node 3 (port 8083, mysql 3309)

# Connect to any node and run queries
mysql --protocol=TCP -h localhost -P 3307 -u root
mysql --protocol=TCP -h localhost -P 3308 -u root

# Cleanup
pkill -f marmot-v2"><pre><span><span>#</span> Test DDL and DML replication across a 2-node cluster</span>
./scripts/test-ddl-replication.sh

<span><span>#</span> This script will:</span>
<span><span>#</span> 1. Start a 2-node cluster</span>
<span><span>#</span> 2. Create a table on node 1 and verify it replicates to node 2</span>
<span><span>#</span> 3. Insert data on node 1 and verify it replicates to node 2</span>
<span><span>#</span> 4. Update data on node 2 and verify it replicates to node 1</span>
<span><span>#</span> 5. Delete data on node 1 and verify it replicates to node 2</span>

<span><span>#</span> Manual cluster testing</span>
./examples/start-seed.sh              <span><span>#</span> Start seed node (port 8081, mysql 3307)</span>
./examples/join-cluster.sh 2 localhost:8081  <span><span>#</span> Join node 2 (port 8082, mysql 3308)</span>
./examples/join-cluster.sh 3 localhost:8081  <span><span>#</span> Join node 3 (port 8083, mysql 3309)</span>

<span><span>#</span> Connect to any node and run queries</span>
mysql --protocol=TCP -h localhost -P 3307 -u root
mysql --protocol=TCP -h localhost -P 3308 -u root

<span><span>#</span> Cleanup</span>
pkill -f marmot-v2</pre></div>

<p dir="auto">Marmot can run <strong>distributed WordPress</strong> with full database replication across nodes. Each WordPress instance connects to its local Marmot node, and all database changes replicate automatically.</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">MySQL Compatibility for WordPress</h3><a id="user-content-mysql-compatibility-for-wordpress" aria-label="Permalink: MySQL Compatibility for WordPress" href="#mysql-compatibility-for-wordpress"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Marmot implements MySQL functions required by WordPress:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Category</th>
<th>Functions</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Date/Time</strong></td>
<td>NOW, CURDATE, DATE_FORMAT, UNIX_TIMESTAMP, DATEDIFF, YEAR, MONTH, DAY, etc.</td>
</tr>
<tr>
<td><strong>String</strong></td>
<td>CONCAT_WS, SUBSTRING_INDEX, FIND_IN_SET, LPAD, RPAD, etc.</td>
</tr>
<tr>
<td><strong>Math/Hash</strong></td>
<td>RAND, MD5, SHA1, SHA2, POW, etc.</td>
</tr>
<tr>
<td><strong>DML</strong></td>
<td>ON DUPLICATE KEY UPDATE (transformed to SQLite ON CONFLICT)</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<div dir="auto"><h3 tabindex="-1" dir="auto">Quick Start: 3-Node WordPress Cluster</h3><a id="user-content-quick-start-3-node-wordpress-cluster" aria-label="Permalink: Quick Start: 3-Node WordPress Cluster" href="#quick-start-3-node-wordpress-cluster"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto" data-snippet-clipboard-copy-content="cd examples/wordpress-cluster
./run.sh up"><pre><span>cd</span> examples/wordpress-cluster
./run.sh up</pre></div>
<p dir="auto">This starts:</p>
<ul dir="auto">
<li><strong>3 Marmot nodes</strong> with QUORUM write consistency</li>
<li><strong>3 WordPress instances</strong> each connected to its local Marmot node</li>
</ul>
<div data-snippet-clipboard-copy-content="┌─────────────┐  ┌─────────────┐  ┌─────────────┐
│ WordPress-1 │  │ WordPress-2 │  │ WordPress-3 │
│ :9101       │  │ :9102       │  │ :9103       │
└──────┬──────┘  └──────┬──────┘  └──────┬──────┘
       ▼                ▼                ▼
┌─────────────┐  ┌─────────────┐  ┌─────────────┐
│  Marmot-1   │◄─┤  Marmot-2   │◄─┤  Marmot-3   │
│ MySQL: 9191 │  │ MySQL: 9192 │  │ MySQL: 9193 │
└─────────────┘  └─────────────┘  └─────────────┘
       └──────────────┴──────────────┘
              QUORUM Replication"><pre><code>┌─────────────┐  ┌─────────────┐  ┌─────────────┐
│ WordPress-1 │  │ WordPress-2 │  │ WordPress-3 │
│ :9101       │  │ :9102       │  │ :9103       │
└──────┬──────┘  └──────┬──────┘  └──────┬──────┘
       ▼                ▼                ▼
┌─────────────┐  ┌─────────────┐  ┌─────────────┐
│  Marmot-1   │◄─┤  Marmot-2   │◄─┤  Marmot-3   │
│ MySQL: 9191 │  │ MySQL: 9192 │  │ MySQL: 9193 │
└─────────────┘  └─────────────┘  └─────────────┘
       └──────────────┴──────────────┘
              QUORUM Replication
</code></pre></div>
<p dir="auto"><strong>Test it:</strong></p>
<ol dir="auto">
<li>Open <a href="http://localhost:9101" rel="nofollow">http://localhost:9101</a> - complete WordPress installation</li>
<li>Open <a href="http://localhost:9102" rel="nofollow">http://localhost:9102</a> or <a href="http://localhost:9103" rel="nofollow">http://localhost:9103</a></li>
<li>See your content replicated across all nodes!</li>
</ol>
<p dir="auto"><strong>Commands:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="./run.sh status   # Check cluster health
./run.sh logs-m   # Marmot logs only
./run.sh logs-wp  # WordPress logs only
./run.sh down     # Stop cluster"><pre>./run.sh status   <span><span>#</span> Check cluster health</span>
./run.sh logs-m   <span><span>#</span> Marmot logs only</span>
./run.sh logs-wp  <span><span>#</span> WordPress logs only</span>
./run.sh down     <span><span>#</span> Stop cluster</span></pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">Production Considerations for WordPress</h3><a id="user-content-production-considerations-for-wordpress" aria-label="Permalink: Production Considerations for WordPress" href="#production-considerations-for-wordpress"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li><strong>Media uploads</strong>: Use S3/NFS for shared media storage (files not replicated by Marmot)</li>
<li><strong>Sessions</strong>: Use Redis or database sessions for sticky-session-free load balancing</li>
<li><strong>Caching</strong>: Each node can use local object cache (Redis/Memcached per region)</li>
</ul>

<p dir="auto">Marmot v2 uses a fundamentally different architecture from other SQLite replication solutions:</p>
<p dir="auto"><strong>vs. rqlite/dqlite/LiteFS:</strong></p>
<ul dir="auto">
<li>❌ They require a primary node for all writes</li>
<li>✅ Marmot allows writes on <strong>any node</strong></li>
<li>❌ They use leader election (Raft)</li>
<li>✅ Marmot uses <strong>gossip protocol</strong> (no leader)</li>
<li>❌ They require proxy layer or page-level interception</li>
<li>✅ Marmot uses <strong>MySQL protocol</strong> for direct database access</li>
</ul>
<p dir="auto"><strong>How It Works:</strong></p>
<ol dir="auto">
<li><strong>Write Coordination</strong>: 2PC (Two-Phase Commit) with configurable consistency (ONE, QUORUM, ALL)</li>
<li><strong>Conflict Resolution</strong>: Last-Write-Wins (LWW) with HLC timestamps</li>
<li><strong>Cluster Membership</strong>: SWIM-style gossip with failure detection</li>
<li><strong>Data Replication</strong>: Full database replication - all nodes receive all data</li>
<li><strong>DDL Replication</strong>: Cluster-wide schema changes with automatic idempotency</li>
</ol>
<div dir="auto"><h2 tabindex="-1" dir="auto">Comparison with Alternatives</h2><a id="user-content-comparison-with-alternatives" aria-label="Permalink: Comparison with Alternatives" href="#comparison-with-alternatives"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Aspect</th>
<th>Marmot</th>
<th>MySQL Active-Active</th>
<th>rqlite/dqlite</th>
<th>TiDB</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Leader</strong></td>
<td>None</td>
<td>None (but complex)</td>
<td>Yes (Raft)</td>
<td>Yes (Raft)</td>
</tr>
<tr>
<td><strong>Failover</strong></td>
<td>Automatic</td>
<td>Manual intervention</td>
<td>Automatic</td>
<td>Automatic</td>
</tr>
<tr>
<td><strong>Split-brain recovery</strong></td>
<td>Automatic (anti-entropy)</td>
<td>Manual</td>
<td>N/A (leader-based)</td>
<td>N/A</td>
</tr>
<tr>
<td><strong>Consistency</strong></td>
<td>Tunable (ONE/QUORUM/ALL)</td>
<td>Serializable</td>
<td>Strong</td>
<td>Strong</td>
</tr>
<tr>
<td><strong>Direct file read</strong></td>
<td>✅ SQLite file</td>
<td>❌</td>
<td>❌</td>
<td>❌</td>
</tr>
<tr>
<td><strong>JS-safe AUTO_INCREMENT</strong></td>
<td>✅ Compact mode (53-bit)</td>
<td>N/A</td>
<td>N/A</td>
<td>❌ 64-bit breaks JS</td>
</tr>
<tr>
<td><strong>Edge-friendly</strong></td>
<td>✅ Lightweight</td>
<td>❌ Heavy</td>
<td><g-emoji alias="warning">⚠️</g-emoji> Moderate</td>
<td>❌ Heavy</td>
</tr>
<tr>
<td><strong>Operational complexity</strong></td>
<td>Low</td>
<td>High</td>
<td>Low</td>
<td>High</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>

<p dir="auto">Marmot v2 supports <strong>distributed DDL (Data Definition Language) replication</strong> without requiring master election:</p>

<ol dir="auto">
<li>
<p dir="auto"><strong>Cluster-Wide Locking</strong>: Each DDL operation acquires a distributed lock per database (default: 30-second lease)</p>
<ul dir="auto">
<li>Prevents concurrent schema changes on the same database</li>
<li>Locks automatically expire if a node crashes</li>
<li>Different databases can have concurrent DDL operations</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Automatic Idempotency</strong>: DDL statements are automatically rewritten for safe replay</p>
<div dir="auto" data-snippet-clipboard-copy-content="CREATE TABLE users (id INT)
→ CREATE TABLE IF NOT EXISTS users (id INT)

DROP TABLE users
→ DROP TABLE IF EXISTS users"><pre><span>CREATE</span> <span>TABLE</span> <span>users</span> (id <span>INT</span>)
→ CREATE TABLE IF NOT EXISTS users (id <span>INT</span>)

<span>DROP</span> <span>TABLE</span> users
→ <span>DROP</span> <span>TABLE</span> <span>IF</span> EXISTS users</pre></div>
</li>
<li>
<p dir="auto"><strong>Schema Version Tracking</strong>: Each database maintains a schema version counter</p>
<ul dir="auto">
<li>Incremented on every DDL operation</li>
<li>Exchanged via gossip protocol for drift detection</li>
<li>Used by delta sync to validate transaction applicability</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Quorum-Based Replication</strong>: DDL replicates like DML through the same 2PC mechanism</p>
<ul dir="auto">
<li>No special master node needed</li>
<li>Works with existing consistency levels (QUORUM, ALL, etc.)</li>
</ul>
</li>
</ol>

<div dir="auto" data-snippet-clipboard-copy-content="[ddl]
# DDL lock lease duration (seconds)
lock_lease_seconds = 30

# Automatically rewrite DDL for idempotency
enable_idempotent = true"><pre>[<span>ddl</span>]
<span><span>#</span> DDL lock lease duration (seconds)</span>
<span>lock_lease_seconds</span> = <span>30</span>

<span><span>#</span> Automatically rewrite DDL for idempotency</span>
<span>enable_idempotent</span> = <span>true</span></pre></div>

<ul dir="auto">
<li>✅ <strong>Do</strong>: Execute DDL from a single connection/node at a time</li>
<li>✅ <strong>Do</strong>: Use qualified table names (<code>mydb.users</code> instead of <code>users</code>)</li>
<li><g-emoji alias="warning">⚠️</g-emoji> <strong>Caution</strong>: ALTER TABLE is less idempotent - avoid replaying failed ALTER operations</li>
<li>❌ <strong>Don&#39;t</strong>: Run concurrent DDL on the same database from multiple nodes</li>
</ul>

<p dir="auto">Marmot v2 uses <strong>Change Data Capture (CDC)</strong> for replication instead of SQL statement replay:</p>

<ol dir="auto">
<li><strong>Row-Level Capture</strong>: Instead of replicating SQL statements, Marmot captures the actual row data changes (INSERT/UPDATE/DELETE)</li>
<li><strong>Binary Data Format</strong>: Row data is serialized as CDC messages with column values, ensuring consistent replication regardless of SQL dialect</li>
<li><strong>Deterministic Application</strong>: Row data is applied directly to the target database, avoiding parsing ambiguities</li>
</ol>

<ul dir="auto">
<li><strong>Consistency</strong>: Same row data applied everywhere, no SQL parsing differences</li>
<li><strong>Performance</strong>: Binary format is more efficient than SQL text</li>
<li><strong>Reliability</strong>: No issues with SQL syntax variations between MySQL and SQLite</li>
</ul>

<p dir="auto">For UPDATE and DELETE operations, Marmot automatically extracts row keys:</p>
<ul dir="auto">
<li>Uses PRIMARY KEY columns when available</li>
<li>Falls back to ROWID for tables without explicit primary key</li>
<li>Handles composite primary keys correctly</li>
</ul>

<p dir="auto">Marmot can publish CDC events to external messaging systems, enabling real-time data pipelines, analytics, and event-driven architectures. Events follow the <strong><a href="https://debezium.io/" rel="nofollow">Debezium</a> specification</strong> for maximum compatibility with existing CDC tooling.</p>

<ul dir="auto">
<li><strong>Debezium-Compatible Format</strong>: Events conform to the <a href="https://debezium.io/documentation/reference/stable/connectors/postgresql.html#postgresql-events" rel="nofollow">Debezium event structure</a>, compatible with Kafka Connect, Flink, Spark, and other CDC consumers</li>
<li><strong>Multi-Sink Support</strong>: Publish to multiple destinations simultaneously (Kafka, NATS)</li>
<li><strong>Glob-Based Filtering</strong>: Filter which tables and databases to publish</li>
<li><strong>Automatic Retry</strong>: Exponential backoff with configurable limits</li>
<li><strong>Persistent Cursors</strong>: Survives restarts without losing position</li>
</ul>

<div dir="auto" data-snippet-clipboard-copy-content="[publisher]
enabled = true

[[publisher.sinks]]
name = &#34;kafka-main&#34;
type = &#34;kafka&#34;                    # &#34;kafka&#34; or &#34;nats&#34;
format = &#34;debezium&#34;               # Debezium-compatible JSON format
brokers = [&#34;localhost:9092&#34;]      # Kafka broker addresses
topic_prefix = &#34;marmot.cdc&#34;       # Topics: {prefix}.{database}.{table}
filter_tables = [&#34;*&#34;]             # Glob patterns (e.g., &#34;users&#34;, &#34;order_*&#34;)
filter_databases = [&#34;*&#34;]          # Glob patterns (e.g., &#34;prod_*&#34;)
batch_size = 100                  # Events per poll cycle
poll_interval_ms = 10             # Polling interval

# NATS sink example
[[publisher.sinks]]
name = &#34;nats-events&#34;
type = &#34;nats&#34;
format = &#34;debezium&#34;
nats_url = &#34;nats://localhost:4222&#34;
topic_prefix = &#34;marmot.cdc&#34;
filter_tables = [&#34;*&#34;]
filter_databases = [&#34;*&#34;]"><pre>[<span>publisher</span>]
<span>enabled</span> = <span>true</span>

[[<span>publisher</span>.<span>sinks</span>]]
<span>name</span> = <span><span>&#34;</span>kafka-main<span>&#34;</span></span>
<span>type</span> = <span><span>&#34;</span>kafka<span>&#34;</span></span>                    <span><span>#</span> &#34;kafka&#34; or &#34;nats&#34;</span>
<span>format</span> = <span><span>&#34;</span>debezium<span>&#34;</span></span>               <span><span>#</span> Debezium-compatible JSON format</span>
<span>brokers</span> = [<span><span>&#34;</span>localhost:9092<span>&#34;</span></span>]      <span><span>#</span> Kafka broker addresses</span>
<span>topic_prefix</span> = <span><span>&#34;</span>marmot.cdc<span>&#34;</span></span>       <span><span>#</span> Topics: {prefix}.{database}.{table}</span>
<span>filter_tables</span> = [<span><span>&#34;</span>*<span>&#34;</span></span>]             <span><span>#</span> Glob patterns (e.g., &#34;users&#34;, &#34;order_*&#34;)</span>
<span>filter_databases</span> = [<span><span>&#34;</span>*<span>&#34;</span></span>]          <span><span>#</span> Glob patterns (e.g., &#34;prod_*&#34;)</span>
<span>batch_size</span> = <span>100</span>                  <span><span>#</span> Events per poll cycle</span>
<span>poll_interval_ms</span> = <span>10</span>             <span><span>#</span> Polling interval</span>

<span><span>#</span> NATS sink example</span>
[[<span>publisher</span>.<span>sinks</span>]]
<span>name</span> = <span><span>&#34;</span>nats-events<span>&#34;</span></span>
<span>type</span> = <span><span>&#34;</span>nats<span>&#34;</span></span>
<span>format</span> = <span><span>&#34;</span>debezium<span>&#34;</span></span>
<span>nats_url</span> = <span><span>&#34;</span>nats://localhost:4222<span>&#34;</span></span>
<span>topic_prefix</span> = <span><span>&#34;</span>marmot.cdc<span>&#34;</span></span>
<span>filter_tables</span> = [<span><span>&#34;</span>*<span>&#34;</span></span>]
<span>filter_databases</span> = [<span><span>&#34;</span>*<span>&#34;</span></span>]</pre></div>

<p dir="auto">Events follow the <a href="https://debezium.io/documentation/reference/stable/connectors/postgresql.html#postgresql-change-events-value" rel="nofollow">Debezium envelope structure</a>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
  &#34;schema&#34;: { ... },
  &#34;payload&#34;: {
    &#34;before&#34;: null,
    &#34;after&#34;: {&#34;id&#34;: 1, &#34;name&#34;: &#34;alice&#34;, &#34;email&#34;: &#34;alice@example.com&#34;},
    &#34;source&#34;: {
      &#34;version&#34;: &#34;2.0.0&#34;,
      &#34;connector&#34;: &#34;marmot&#34;,
      &#34;name&#34;: &#34;marmot&#34;,
      &#34;ts_ms&#34;: 1702500000000,
      &#34;db&#34;: &#34;myapp&#34;,
      &#34;table&#34;: &#34;users&#34;
    },
    &#34;op&#34;: &#34;c&#34;,
    &#34;ts_ms&#34;: 1702500000000
  }
}"><pre>{
  <span>&#34;schema&#34;</span>: { <span>... </span>},
  <span>&#34;payload&#34;</span>: {
    <span>&#34;before&#34;</span>: <span>null</span>,
    <span>&#34;after&#34;</span>: {<span>&#34;id&#34;</span>: <span>1</span>, <span>&#34;name&#34;</span>: <span><span>&#34;</span>alice<span>&#34;</span></span>, <span>&#34;email&#34;</span>: <span><span>&#34;</span>alice@example.com<span>&#34;</span></span>},
    <span>&#34;source&#34;</span>: {
      <span>&#34;version&#34;</span>: <span><span>&#34;</span>2.0.0<span>&#34;</span></span>,
      <span>&#34;connector&#34;</span>: <span><span>&#34;</span>marmot<span>&#34;</span></span>,
      <span>&#34;name&#34;</span>: <span><span>&#34;</span>marmot<span>&#34;</span></span>,
      <span>&#34;ts_ms&#34;</span>: <span>1702500000000</span>,
      <span>&#34;db&#34;</span>: <span><span>&#34;</span>myapp<span>&#34;</span></span>,
      <span>&#34;table&#34;</span>: <span><span>&#34;</span>users<span>&#34;</span></span>
    },
    <span>&#34;op&#34;</span>: <span><span>&#34;</span>c<span>&#34;</span></span>,
    <span>&#34;ts_ms&#34;</span>: <span>1702500000000</span>
  }
}</pre></div>
<p dir="auto"><strong>Operation Types</strong> (per <a href="https://debezium.io/documentation/reference/stable/connectors/postgresql.html#postgresql-create-events" rel="nofollow">Debezium spec</a>):</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Operation</th>
<th><code>op</code></th>
<th><code>before</code></th>
<th><code>after</code></th>
</tr>
</thead>
<tbody>
<tr>
<td>INSERT</td>
<td><code>c</code> (create)</td>
<td><code>null</code></td>
<td>row data</td>
</tr>
<tr>
<td>UPDATE</td>
<td><code>u</code> (update)</td>
<td>old row</td>
<td>new row</td>
</tr>
<tr>
<td>DELETE</td>
<td><code>d</code> (delete)</td>
<td>old row</td>
<td><code>null</code></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>

<p dir="auto">Topics follow the pattern: <code>{topic_prefix}.{database}.{table}</code></p>
<p dir="auto">Examples:</p>
<ul dir="auto">
<li><code>marmot.cdc.myapp.users</code></li>
<li><code>marmot.cdc.myapp.orders</code></li>
<li><code>marmot.cdc.analytics.events</code></li>
</ul>

<ul dir="auto">
<li><strong>Real-Time Analytics</strong>: Stream changes to data warehouses (Snowflake, BigQuery, ClickHouse)</li>
<li><strong>Event-Driven Microservices</strong>: Trigger actions on data changes</li>
<li><strong>Cache Invalidation</strong>: Keep caches in sync with database changes</li>
<li><strong>Audit Logging</strong>: Capture all changes for compliance</li>
<li><strong>Search Indexing</strong>: Keep Elasticsearch/Algolia in sync</li>
</ul>
<p dir="auto">For more details, see the <a href="https://maxpert.github.io/marmot/integrations" rel="nofollow">Integrations documentation</a>.</p>


<p dir="auto">Deploy Marmot as a lightweight regional replica alongside Lambda functions:</p>
<ul dir="auto">
<li>Local SQLite reads (sub-ms latency)</li>
<li>Writes replicate to cluster</li>
<li>No cold-start database connections</li>
</ul>
<div dir="auto"><h3 tabindex="-1" dir="auto">Read-Only Regional Replicas</h3><a id="user-content-read-only-regional-replicas" aria-label="Permalink: Read-Only Regional Replicas" href="#read-only-regional-replicas"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Scale reads globally with replica mode:</p>
<div dir="auto" data-snippet-clipboard-copy-content="[replica]
enabled = true
master_address = &#34;central-cluster:8080&#34;
reconnect_interval_seconds = 5"><pre>[<span>replica</span>]
<span>enabled</span> = <span>true</span>
<span>master_address</span> = <span><span>&#34;</span>central-cluster:8080<span>&#34;</span></span>
<span>reconnect_interval_seconds</span> = <span>5</span></pre></div>
<ul dir="auto">
<li>Follows master via streaming replication</li>
<li>Zero cluster participation overhead</li>
<li>Auto-reconnect on network issues</li>
</ul>
<div dir="auto"><h3 tabindex="-1" dir="auto">Hybrid: Edge Reads, Central Writes</h3><a id="user-content-hybrid-edge-reads-central-writes" aria-label="Permalink: Hybrid: Edge Reads, Central Writes" href="#hybrid-edge-reads-central-writes"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>Deploy full cluster in central region</li>
<li>Deploy read replicas at edge locations</li>
<li>Application routes writes to central, reads to local replica</li>
</ul>
<div dir="auto"><h2 tabindex="-1" dir="auto">SQL Statement Compatibility</h2><a id="user-content-sql-statement-compatibility" aria-label="Permalink: SQL Statement Compatibility" href="#sql-statement-compatibility"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Marmot supports a wide range of MySQL/SQLite statements through its MySQL protocol server. The following table shows compatibility for different statement types:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Statement Type</th>
<th>Support</th>
<th>Replication</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>DML - Data Manipulation</strong></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>INSERT</code> / <code>REPLACE</code></td>
<td>✅ Full</td>
<td>✅ Yes</td>
<td>Includes qualified table names (db.table)</td>
</tr>
<tr>
<td><code>UPDATE</code></td>
<td>✅ Full</td>
<td>✅ Yes</td>
<td>Includes qualified table names</td>
</tr>
<tr>
<td><code>DELETE</code></td>
<td>✅ Full</td>
<td>✅ Yes</td>
<td>Includes qualified table names</td>
</tr>
<tr>
<td><code>SELECT</code></td>
<td>✅ Full</td>
<td>N/A</td>
<td>Read operations</td>
</tr>
<tr>
<td><code>LOAD DATA</code></td>
<td>✅ Full</td>
<td>✅ Yes</td>
<td>Bulk data loading</td>
</tr>
<tr>
<td><strong>DDL - Data Definition</strong></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>CREATE TABLE</code></td>
<td>✅ Full</td>
<td>✅ Yes</td>
<td>Replicated with cluster-wide locking</td>
</tr>
<tr>
<td><code>ALTER TABLE</code></td>
<td>✅ Full</td>
<td>✅ Yes</td>
<td>Replicated with cluster-wide locking</td>
</tr>
<tr>
<td><code>DROP TABLE</code></td>
<td>✅ Full</td>
<td>✅ Yes</td>
<td>Replicated with cluster-wide locking</td>
</tr>
<tr>
<td><code>TRUNCATE TABLE</code></td>
<td>✅ Full</td>
<td>✅ Yes</td>
<td></td>
</tr>
<tr>
<td><code>RENAME TABLE</code></td>
<td>✅ Full</td>
<td>✅ Yes</td>
<td>Replicated with cluster-wide locking</td>
</tr>
<tr>
<td><code>CREATE/DROP INDEX</code></td>
<td>✅ Full</td>
<td>✅ Yes</td>
<td>Replicated with cluster-wide locking</td>
</tr>
<tr>
<td><code>CREATE/DROP VIEW</code></td>
<td>✅ Full</td>
<td>✅ Yes</td>
<td>Replicated with cluster-wide locking</td>
</tr>
<tr>
<td><code>CREATE/DROP TRIGGER</code></td>
<td>✅ Full</td>
<td>✅ Yes</td>
<td>Replicated with cluster-wide locking</td>
</tr>
<tr>
<td><strong>Database Management</strong></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>CREATE DATABASE</code></td>
<td>✅ Full</td>
<td>✅ Yes</td>
<td>Replicated with cluster-wide locking</td>
</tr>
<tr>
<td><code>DROP DATABASE</code></td>
<td>✅ Full</td>
<td>✅ Yes</td>
<td>Replicated with cluster-wide locking</td>
</tr>
<tr>
<td><code>ALTER DATABASE</code></td>
<td>✅ Full</td>
<td>✅ Yes</td>
<td>Replicated with cluster-wide locking</td>
</tr>
<tr>
<td><code>SHOW DATABASES</code></td>
<td>✅ Full</td>
<td>N/A</td>
<td>Metadata query</td>
</tr>
<tr>
<td><code>SHOW TABLES</code></td>
<td>✅ Full</td>
<td>N/A</td>
<td>Metadata query</td>
</tr>
<tr>
<td><code>USE database</code></td>
<td>✅ Full</td>
<td>N/A</td>
<td>Session state</td>
</tr>
<tr>
<td><strong>Transaction Control</strong></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>BEGIN</code> / <code>START TRANSACTION</code></td>
<td>✅ Full</td>
<td>N/A</td>
<td>Transaction boundary</td>
</tr>
<tr>
<td><code>COMMIT</code></td>
<td>✅ Full</td>
<td>✅ Yes</td>
<td>Commits distributed transaction</td>
</tr>
<tr>
<td><code>ROLLBACK</code></td>
<td>✅ Full</td>
<td>✅ Yes</td>
<td>Aborts distributed transaction</td>
</tr>
<tr>
<td><code>SAVEPOINT</code></td>
<td>✅ Full</td>
<td>✅ Yes</td>
<td>Nested transaction support</td>
</tr>
<tr>
<td><strong>Locking</strong></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>LOCK TABLES</code></td>
<td>✅ Parsed</td>
<td>❌ No</td>
<td>Requires distributed locking coordination</td>
</tr>
<tr>
<td><code>UNLOCK TABLES</code></td>
<td>✅ Parsed</td>
<td>❌ No</td>
<td>Requires distributed locking coordination</td>
</tr>
<tr>
<td><strong>Session Configuration</strong></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>SET</code> statements</td>
<td>✅ Parsed</td>
<td>❌ No</td>
<td>Session-local, not replicated</td>
</tr>
<tr>
<td><strong>XA Transactions</strong></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>XA START/END/PREPARE</code></td>
<td>✅ Parsed</td>
<td>❌ No</td>
<td>Marmot uses its own 2PC protocol</td>
</tr>
<tr>
<td><code>XA COMMIT/ROLLBACK</code></td>
<td>✅ Parsed</td>
<td>❌ No</td>
<td>Not compatible with Marmot&#39;s model</td>
</tr>
<tr>
<td><strong>DCL - Data Control</strong></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>GRANT</code> / <code>REVOKE</code></td>
<td>✅ Parsed</td>
<td>❌ No</td>
<td>User management not replicated</td>
</tr>
<tr>
<td><code>CREATE/DROP USER</code></td>
<td>✅ Parsed</td>
<td>❌ No</td>
<td>User management not replicated</td>
</tr>
<tr>
<td><code>ALTER USER</code></td>
<td>✅ Parsed</td>
<td>❌ No</td>
<td>User management not replicated</td>
</tr>
<tr>
<td><strong>Administrative</strong></td>
<td></td>
<td></td>
<td></td>
</tr>
<tr>
<td><code>OPTIMIZE TABLE</code></td>
<td>✅ Parsed</td>
<td>❌ No</td>
<td>Node-local administrative command</td>
</tr>
<tr>
<td><code>REPAIR TABLE</code></td>
<td>✅ Parsed</td>
<td>❌ No</td>
<td>Node-local administrative command</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>

<ul dir="auto">
<li>✅ <strong>Full</strong>: Fully supported and working</li>
<li>✅ <strong>Parsed</strong>: Statement is parsed and recognized</li>
<li><g-emoji alias="warning">⚠️</g-emoji> <strong>Limited</strong>: Works but has limitations in distributed context</li>
<li>❌ <strong>No</strong>: Not supported or not replicated</li>
<li><strong>N/A</strong>: Not applicable (read-only or session-local)</li>
</ul>

<ol dir="auto">
<li>
<p dir="auto"><strong>Schema Changes (DDL)</strong>: DDL statements are fully replicated with cluster-wide locking and automatic idempotency. See the DDL Replication section for details.</p>
</li>
<li>
<p dir="auto"><strong>XA Transactions</strong>: Marmot has its own distributed transaction protocol based on 2PC. MySQL XA transactions are not compatible with Marmot&#39;s replication model.</p>
</li>
<li>
<p dir="auto"><strong>User Management (DCL)</strong>: User and privilege management statements are local to each node. For production deployments, consider handling authentication at the application or proxy level.</p>
</li>
<li>
<p dir="auto"><strong>Table Locking</strong>: <code>LOCK TABLES</code> statements are recognized but not enforced across the cluster. Use application-level coordination for distributed locking needs.</p>
</li>
<li>
<p dir="auto"><strong>Qualified Names</strong>: Marmot fully supports qualified table names (e.g., <code>db.table</code>) in DML and DDL operations.</p>
</li>
</ol>
<div dir="auto"><h2 tabindex="-1" dir="auto">MySQL Protocol &amp; Metadata Queries</h2><a id="user-content-mysql-protocol--metadata-queries" aria-label="Permalink: MySQL Protocol &amp; Metadata Queries" href="#mysql-protocol--metadata-queries"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Marmot includes a MySQL-compatible protocol server, allowing you to connect using any MySQL client (DBeaver, MySQL Workbench, mysql CLI, etc.). The server supports:</p>

<p dir="auto">Marmot provides full support for MySQL metadata queries, enabling GUI tools like DBeaver to browse databases, tables, and columns:</p>
<ul dir="auto">
<li><strong>SHOW Commands</strong>: <code>SHOW DATABASES</code>, <code>SHOW TABLES</code>, <code>SHOW COLUMNS FROM table</code>, <code>SHOW CREATE TABLE</code>, <code>SHOW INDEXES</code></li>
<li><strong>INFORMATION_SCHEMA</strong>: Queries against <code>INFORMATION_SCHEMA.TABLES</code>, <code>INFORMATION_SCHEMA.COLUMNS</code>, <code>INFORMATION_SCHEMA.SCHEMATA</code>, and <code>INFORMATION_SCHEMA.STATISTICS</code></li>
<li><strong>Type Conversion</strong>: Automatic SQLite-to-MySQL type mapping for compatibility</li>
</ul>
<p dir="auto">These metadata queries are powered by the <strong>rqlite/sql AST parser</strong>, providing production-grade MySQL query compatibility.</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">Connecting with MySQL Clients</h3><a id="user-content-connecting-with-mysql-clients" aria-label="Permalink: Connecting with MySQL Clients" href="#connecting-with-mysql-clients"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto" data-snippet-clipboard-copy-content="# Using mysql CLI
mysql -h localhost -P 3306 -u root

# Connection string for applications
mysql://root@localhost:3306/marmot"><pre><span><span>#</span> Using mysql CLI</span>
mysql -h localhost -P 3306 -u root

<span><span>#</span> Connection string for applications</span>
mysql://root@localhost:3306/marmot</pre></div>

<p dir="auto">Marmot handles various failure and recovery scenarios automatically:</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">Network Partition (Split-Brain)</h3><a id="user-content-network-partition-split-brain" aria-label="Permalink: Network Partition (Split-Brain)" href="#network-partition-split-brain"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Scenario</th>
<th>Behavior</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Minority partition</strong></td>
<td>Writes <strong>fail</strong> - cannot achieve quorum</td>
</tr>
<tr>
<td><strong>Majority partition</strong></td>
<td>Writes <strong>succeed</strong> - quorum achieved</td>
</tr>
<tr>
<td><strong>Partition heals</strong></td>
<td>Delta sync + LWW merges divergent data</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><strong>How it works:</strong></p>
<ol dir="auto">
<li>During partition, only the majority side can commit writes (quorum enforcement)</li>
<li>When partition heals, nodes exchange transaction logs via <code>StreamChanges</code> RPC</li>
<li>Conflicts resolved using Last-Writer-Wins (LWW) with HLC timestamps</li>
<li>Higher node ID breaks ties for simultaneous writes</li>
</ol>

<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Scenario</th>
<th>Recovery Method</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Brief outage</strong></td>
<td>Delta sync - replay missed transactions</td>
</tr>
<tr>
<td><strong>Extended outage</strong></td>
<td>Snapshot transfer + delta sync</td>
</tr>
<tr>
<td><strong>New node joining</strong></td>
<td>Full snapshot from existing node</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><strong>Anti-Entropy Background Process:</strong></p>
<p dir="auto">Marmot v2 includes an automatic anti-entropy system that continuously monitors and repairs replication lag across the cluster:</p>
<ol dir="auto">
<li><strong>Lag Detection</strong>: Every 60 seconds (configurable), each node queries peers for their replication state</li>
<li><strong>Smart Recovery Decision</strong>:
<ul dir="auto">
<li><strong>Delta Sync</strong> if lag &lt; 10,000 transactions AND &lt; 1 hour: Streams missed transactions incrementally</li>
<li><strong>Snapshot Transfer</strong> if lag exceeds thresholds: Full database file transfer for efficiency</li>
</ul>
</li>
<li><strong>Gap Detection</strong>: Detects when transaction logs have been GC&#39;d and automatically falls back to snapshot</li>
<li><strong>Multi-Database Support</strong>: Tracks and syncs each database independently</li>
<li><strong>GC Coordination</strong>: Garbage collection respects peer replication state - logs aren&#39;t deleted until all peers have applied them</li>
</ol>
<p dir="auto"><strong>Delta Sync Process:</strong></p>
<ol dir="auto">
<li>Lagging node queries <code>last_applied_txn_id</code> for each peer/database</li>
<li>Requests transactions since that ID via <code>StreamChanges</code> RPC</li>
<li><strong>Gap Detection</strong>: Checks if first received txn_id has a large gap from requested ID
<ul dir="auto">
<li>If gap &gt; delta_sync_threshold_txns, indicates missing (GC&#39;d) transactions</li>
<li>Automatically falls back to snapshot transfer to prevent data loss</li>
</ul>
</li>
<li>Applies changes using LWW conflict resolution</li>
<li>Updates replication state tracking (per-database)</li>
<li>Progress logged every 100 transactions</li>
</ol>
<p dir="auto"><strong>GC Coordination with Anti-Entropy:</strong></p>
<ul dir="auto">
<li>Transaction logs are retained with a two-tier policy:
<ul dir="auto">
<li><strong>Min retention</strong> (2 hours): Must be &gt;= delta sync threshold, respects peer lag</li>
<li><strong>Max retention</strong> (24 hours): Force delete after this time to prevent unbounded growth</li>
</ul>
</li>
<li>Config validation enforces: <code>gc_min &gt;= delta_threshold</code> and <code>gc_max &gt;= 2x delta_threshold</code></li>
<li>Each database tracks replication progress per peer</li>
<li>GC queries minimum applied txn_id across all peers before cleanup</li>
<li><strong>Gap detection</strong> prevents data loss if GC runs while nodes are offline</li>
</ul>

<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Write Consistency</th>
<th>Behavior</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>ONE</code></td>
<td>Returns after 1 node ACK (fast, less durable)</td>
</tr>
<tr>
<td><code>QUORUM</code></td>
<td>Returns after majority ACK (default, balanced)</td>
</tr>
<tr>
<td><code>ALL</code></td>
<td>Returns after all nodes ACK (slow, most durable)</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><strong>Conflict Resolution:</strong></p>
<ul dir="auto">
<li>All conflicts resolved via LWW using HLC timestamps</li>
<li>No data loss - later write always wins deterministically</li>
<li>Tie-breaker: higher node ID wins for equal timestamps</li>
</ul>

<ul dir="auto">
<li><strong>Selective Table Watching</strong>: All tables in a database are replicated. Selective table replication is not supported.</li>
<li><strong>WAL Mode Required</strong>: SQLite must use WAL mode for reliable multi-process changes.</li>
<li><strong>Eventually Consistent</strong>: Rows may sync out of order. <code>SERIALIZABLE</code> transaction assumptions may not hold across nodes.</li>
<li><strong>Concurrent DDL</strong>: Avoid running concurrent DDL operations on the same database from multiple nodes (protected by cluster-wide lock with 30s lease).</li>
</ul>
<div dir="auto"><h2 tabindex="-1" dir="auto">Auto-Increment &amp; ID Generation</h2><a id="user-content-auto-increment--id-generation" aria-label="Permalink: Auto-Increment &amp; ID Generation" href="#auto-increment--id-generation"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">The Problem with Distributed IDs</h3><a id="user-content-the-problem-with-distributed-ids" aria-label="Permalink: The Problem with Distributed IDs" href="#the-problem-with-distributed-ids"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Distributed databases need globally unique IDs, but traditional solutions cause problems:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Solution</th>
<th>Issue</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>UUID</strong></td>
<td>128-bit, poor index performance, not sortable</td>
</tr>
<tr>
<td><strong>Snowflake/HLC 64-bit</strong></td>
<td>Exceeds JavaScript&#39;s <code>Number.MAX_SAFE_INTEGER</code> (2^53-1)</td>
</tr>
<tr>
<td><strong>TiDB AUTO_INCREMENT</strong></td>
<td>Returns 64-bit IDs that <strong>break JavaScript clients</strong> silently</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><strong>The JavaScript Problem:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="// 64-bit ID from TiDB or other distributed DBs
const id = 7318624812345678901;
console.log(id);  // 7318624812345679000 - WRONG! Precision lost!

// JSON parsing also breaks
JSON.parse(&#39;{&#34;id&#34;: 7318624812345678901}&#39;);  // {id: 7318624812345679000}"><pre><span>// 64-bit ID from TiDB or other distributed DBs</span>
<span>const</span> <span>id</span> <span>=</span> <span>7318624812345678901</span><span>;</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>id</span><span>)</span><span>;</span>  <span>// 7318624812345679000 - WRONG! Precision lost!</span>

<span>// JSON parsing also breaks</span>
<span>JSON</span><span>.</span><span>parse</span><span>(</span><span>&#39;{&#34;id&#34;: 7318624812345678901}&#39;</span><span>)</span><span>;</span>  <span>// {id: 7318624812345679000}</span></pre></div>
<p dir="auto">TiDB&#39;s answer? &#34;Use strings.&#34; But that breaks ORMs, existing application code, and type safety.</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">Marmot&#39;s Solution: Compact ID Mode</h3><a id="user-content-marmots-solution-compact-id-mode" aria-label="Permalink: Marmot&#39;s Solution: Compact ID Mode" href="#marmots-solution-compact-id-mode"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Marmot offers <strong>two ID generation modes</strong> to solve this:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Mode</th>
<th>Bits</th>
<th>Range</th>
<th>Use Case</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>extended</code></td>
<td>64-bit</td>
<td>Full HLC timestamp</td>
<td>New systems, non-JS clients</td>
</tr>
<tr>
<td><code>compact</code></td>
<td>53-bit</td>
<td>JS-safe integers</td>
<td><strong>Legacy systems, JavaScript, REST APIs</strong></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<div dir="auto" data-snippet-clipboard-copy-content="[mysql]
auto_id_mode = &#34;compact&#34;  # Safe for JavaScript (default)
# auto_id_mode = &#34;extended&#34;  # Full 64-bit for new systems"><pre>[<span>mysql</span>]
<span>auto_id_mode</span> = <span><span>&#34;</span>compact<span>&#34;</span></span>  <span><span>#</span> Safe for JavaScript (default)</span>
<span><span>#</span> auto_id_mode = &#34;extended&#34;  # Full 64-bit for new systems</span></pre></div>
<p dir="auto"><strong>Compact Mode Guarantees:</strong></p>
<ul dir="auto">
<li>IDs stay under <code>Number.MAX_SAFE_INTEGER</code> (9,007,199,254,740,991)</li>
<li>Still globally unique across all nodes</li>
<li>Still monotonically increasing (per node)</li>
<li>No silent precision loss in JSON/JavaScript</li>
<li>Works with existing ORMs expecting integer IDs</li>
</ul>
<p dir="auto"><strong>With Marmot compact mode:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="const id = 4503599627370496;
console.log(id);  // 4503599627370496 - Correct!
JSON.parse(&#39;{&#34;id&#34;: 4503599627370496}&#39;);  // {id: 4503599627370496} - Correct!"><pre><span>const</span> <span>id</span> <span>=</span> <span>4503599627370496</span><span>;</span>
<span>console</span><span>.</span><span>log</span><span>(</span><span>id</span><span>)</span><span>;</span>  <span>// 4503599627370496 - Correct!</span>
<span>JSON</span><span>.</span><span>parse</span><span>(</span><span>&#39;{&#34;id&#34;: 4503599627370496}&#39;</span><span>)</span><span>;</span>  <span>// {id: 4503599627370496} - Correct!</span></pre></div>

<blockquote>
<p dir="auto"><strong>Note:</strong> Marmot automatically converts <code>INT AUTO_INCREMENT</code> to <code>BIGINT</code> to support distributed ID generation.</p>
</blockquote>
<ol dir="auto">
<li>
<p dir="auto"><strong>DDL Transformation</strong>: When you create a table with <code>AUTO_INCREMENT</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="CREATE TABLE users (id INT AUTO_INCREMENT PRIMARY KEY, name VARCHAR(100))
-- Becomes internally:
CREATE TABLE users (id BIGINT PRIMARY KEY, name TEXT)"><pre><span>CREATE</span> <span>TABLE</span> <span>users</span> (id <span>INT</span> AUTO_INCREMENT <span>PRIMARY KEY</span>, name <span>VARCHAR</span>(<span>100</span>))
<span><span>--</span> Becomes internally:</span>
<span>CREATE</span> <span>TABLE</span> <span>users</span> (id <span>BIGINT</span> <span>PRIMARY KEY</span>, name <span>TEXT</span>)</pre></div>
</li>
<li>
<p dir="auto"><strong>DML ID Injection</strong>: When inserting with <code>0</code> or <code>NULL</code> for an auto-increment column:</p>
<div dir="auto" data-snippet-clipboard-copy-content="INSERT INTO users (id, name) VALUES (0, &#39;alice&#39;)
-- Becomes internally (compact mode):
INSERT INTO users (id, name) VALUES (4503599627370496, &#39;alice&#39;)"><pre><span>INSERT INTO</span> users (id, name) <span>VALUES</span> (<span>0</span>, <span><span>&#39;</span>alice<span>&#39;</span></span>)
<span><span>--</span> Becomes internally (compact mode):</span>
<span>INSERT INTO</span> users (id, name) <span>VALUES</span> (<span>4503599627370496</span>, <span><span>&#39;</span>alice<span>&#39;</span></span>)</pre></div>
</li>
<li>
<p dir="auto"><strong>Explicit IDs Preserved</strong>: If you provide an explicit non-zero ID, it is used as-is.</p>
</li>
</ol>
<p dir="auto"><strong>Schema-Based Detection:</strong></p>
<p dir="auto">Marmot automatically detects auto-increment columns by querying SQLite schema directly:</p>
<ul dir="auto">
<li>Single-column <code>INTEGER PRIMARY KEY</code> (SQLite rowid alias)</li>
<li>Single-column <code>BIGINT PRIMARY KEY</code> (Marmot&#39;s transformed columns)</li>
</ul>
<p dir="auto">No registration required - columns are detected from schema at runtime, works across restarts, and works with existing databases.</p>

<p dir="auto">Marmot v2 uses a TOML configuration file (default: <code>config.toml</code>). All settings have sensible defaults.</p>

<div dir="auto" data-snippet-clipboard-copy-content="node_id = 0  # 0 = auto-generate
data_dir = &#34;./marmot-data&#34;"><pre><span>node_id</span> = <span>0</span>  <span><span>#</span> 0 = auto-generate</span>
<span>data_dir</span> = <span><span>&#34;</span>./marmot-data<span>&#34;</span></span></pre></div>

<div dir="auto" data-snippet-clipboard-copy-content="[transaction]
heartbeat_timeout_seconds = 10  # Transaction timeout without heartbeat
conflict_window_seconds = 10    # Conflict resolution window
lock_wait_timeout_seconds = 50  # Lock wait timeout (MySQL: innodb_lock_wait_timeout)"><pre>[<span>transaction</span>]
<span>heartbeat_timeout_seconds</span> = <span>10</span>  <span><span>#</span> Transaction timeout without heartbeat</span>
<span>conflict_window_seconds</span> = <span>10</span>    <span><span>#</span> Conflict resolution window</span>
<span>lock_wait_timeout_seconds</span> = <span>50</span>  <span><span>#</span> Lock wait timeout (MySQL: innodb_lock_wait_timeout)</span></pre></div>
<p dir="auto"><strong>Note</strong>: Transaction log garbage collection is managed by the replication configuration to coordinate with anti-entropy. See <code>replication.gc_min_retention_hours</code> and <code>replication.gc_max_retention_hours</code>.</p>

<div dir="auto" data-snippet-clipboard-copy-content="[connection_pool]
pool_size = 4              # Number of SQLite connections
max_idle_time_seconds = 10 # Max idle time before closing
max_lifetime_seconds = 300 # Max connection lifetime (0 = unlimited)"><pre>[<span>connection_pool</span>]
<span>pool_size</span> = <span>4</span>              <span><span>#</span> Number of SQLite connections</span>
<span>max_idle_time_seconds</span> = <span>10</span> <span><span>#</span> Max idle time before closing</span>
<span>max_lifetime_seconds</span> = <span>300</span> <span><span>#</span> Max connection lifetime (0 = unlimited)</span></pre></div>

<div dir="auto" data-snippet-clipboard-copy-content="[grpc_client]
keepalive_time_seconds = 10    # Keepalive ping interval
keepalive_timeout_seconds = 3  # Keepalive ping timeout
max_retries = 3                # Max retry attempts
retry_backoff_ms = 100         # Retry backoff duration"><pre>[<span>grpc_client</span>]
<span>keepalive_time_seconds</span> = <span>10</span>    <span><span>#</span> Keepalive ping interval</span>
<span>keepalive_timeout_seconds</span> = <span>3</span>  <span><span>#</span> Keepalive ping timeout</span>
<span>max_retries</span> = <span>3</span>                <span><span>#</span> Max retry attempts</span>
<span>retry_backoff_ms</span> = <span>100</span>         <span><span>#</span> Retry backoff duration</span></pre></div>

<div dir="auto" data-snippet-clipboard-copy-content="[coordinator]
prepare_timeout_ms = 2000 # Prepare phase timeout
commit_timeout_ms = 2000  # Commit phase timeout
abort_timeout_ms = 2000   # Abort phase timeout"><pre>[<span>coordinator</span>]
<span>prepare_timeout_ms</span> = <span>2000</span> <span><span>#</span> Prepare phase timeout</span>
<span>commit_timeout_ms</span> = <span>2000</span>  <span><span>#</span> Commit phase timeout</span>
<span>abort_timeout_ms</span> = <span>2000</span>   <span><span>#</span> Abort phase timeout</span></pre></div>

<div dir="auto" data-snippet-clipboard-copy-content="[cluster]
grpc_bind_address = &#34;0.0.0.0&#34;
grpc_port = 8080
seed_nodes = []                # List of seed node addresses
cluster_secret = &#34;&#34;            # PSK for cluster authentication (see Security section)
gossip_interval_ms = 1000      # Gossip interval
gossip_fanout = 3              # Number of peers to gossip to
suspect_timeout_ms = 5000      # Suspect timeout
dead_timeout_ms = 10000        # Dead timeout"><pre>[<span>cluster</span>]
<span>grpc_bind_address</span> = <span><span>&#34;</span>0.0.0.0<span>&#34;</span></span>
<span>grpc_port</span> = <span>8080</span>
<span>seed_nodes</span> = []                <span><span>#</span> List of seed node addresses</span>
<span>cluster_secret</span> = <span><span>&#34;</span><span>&#34;</span></span>            <span><span>#</span> PSK for cluster authentication (see Security section)</span>
<span>gossip_interval_ms</span> = <span>1000</span>      <span><span>#</span> Gossip interval</span>
<span>gossip_fanout</span> = <span>3</span>              <span><span>#</span> Number of peers to gossip to</span>
<span>suspect_timeout_ms</span> = <span>5000</span>      <span><span>#</span> Suspect timeout</span>
<span>dead_timeout_ms</span> = <span>10000</span>        <span><span>#</span> Dead timeout</span></pre></div>

<p dir="auto">Marmot supports Pre-Shared Key (PSK) authentication for cluster communication. <strong>This is strongly recommended for production deployments.</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="[cluster]
# All nodes in the cluster must use the same secret
cluster_secret = &#34;your-secret-key-here&#34;"><pre>[<span>cluster</span>]
<span><span>#</span> All nodes in the cluster must use the same secret</span>
<span>cluster_secret</span> = <span><span>&#34;</span>your-secret-key-here<span>&#34;</span></span></pre></div>
<p dir="auto"><strong>Environment Variable (Recommended):</strong></p>
<p dir="auto">For production, use the environment variable to avoid storing secrets in config files:</p>
<div dir="auto" data-snippet-clipboard-copy-content="export MARMOT_CLUSTER_SECRET=&#34;your-secret-key-here&#34;
./marmot"><pre><span>export</span> MARMOT_CLUSTER_SECRET=<span><span>&#34;</span>your-secret-key-here<span>&#34;</span></span>
./marmot</pre></div>
<p dir="auto">The environment variable takes precedence over the config file.</p>
<p dir="auto"><strong>Generating a Secret:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Generate a secure random secret
openssl rand -base64 32"><pre><span><span>#</span> Generate a secure random secret</span>
openssl rand -base64 32</pre></div>
<p dir="auto"><strong>Behavior:</strong></p>
<ul dir="auto">
<li>If <code>cluster_secret</code> is empty and <code>MARMOT_CLUSTER_SECRET</code> is not set, authentication is disabled</li>
<li>A warning is logged at startup when authentication is disabled</li>
<li>All gRPC endpoints (gossip, replication, snapshots) are protected when authentication is enabled</li>
<li>Nodes with mismatched secrets will fail to communicate (connection rejected with &#34;invalid cluster secret&#34;)</li>
</ul>
<div dir="auto"><h3 tabindex="-1" dir="auto">Cluster Membership Management</h3><a id="user-content-cluster-membership-management" aria-label="Permalink: Cluster Membership Management" href="#cluster-membership-management"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Marmot provides admin HTTP endpoints for managing cluster membership (requires <code>cluster_secret</code> to be configured):</p>
<p dir="auto"><strong>Node Lifecycle:</strong></p>
<ul dir="auto">
<li>New/restarted nodes <strong>auto-join</strong> via gossip - no manual intervention needed</li>
<li>Nodes marked REMOVED via admin API <strong>cannot auto-rejoin</strong> - must be explicitly allowed</li>
<li>This prevents decommissioned nodes from accidentally rejoining the cluster</li>
</ul>
<div dir="auto" data-snippet-clipboard-copy-content="# View cluster members and quorum info
curl -H &#34;X-Marmot-Secret: your-secret&#34; http://localhost:8080/admin/cluster/members

# Remove a node from the cluster (excludes from quorum, blocks auto-rejoin)
curl -X POST -H &#34;X-Marmot-Secret: your-secret&#34; http://localhost:8080/admin/cluster/remove/2

# Allow a removed node to rejoin (node must then restart to join)
curl -X POST -H &#34;X-Marmot-Secret: your-secret&#34; http://localhost:8080/admin/cluster/allow/2"><pre><span><span>#</span> View cluster members and quorum info</span>
curl -H <span><span>&#34;</span>X-Marmot-Secret: your-secret<span>&#34;</span></span> http://localhost:8080/admin/cluster/members

<span><span>#</span> Remove a node from the cluster (excludes from quorum, blocks auto-rejoin)</span>
curl -X POST -H <span><span>&#34;</span>X-Marmot-Secret: your-secret<span>&#34;</span></span> http://localhost:8080/admin/cluster/remove/2

<span><span>#</span> Allow a removed node to rejoin (node must then restart to join)</span>
curl -X POST -H <span><span>&#34;</span>X-Marmot-Secret: your-secret<span>&#34;</span></span> http://localhost:8080/admin/cluster/allow/2</pre></div>
<p dir="auto">See the <a href="https://maxpert.github.io/marmot/operations" rel="nofollow">Operations documentation</a> for detailed usage and examples.</p>

<p dir="auto">For read-only replicas that follow a master node without participating in the cluster:</p>
<div dir="auto" data-snippet-clipboard-copy-content="[replica]
enabled = true                       # Enable read-only replica mode
master_address = &#34;master:8080&#34;       # Master node gRPC address
reconnect_interval_seconds = 5       # Reconnect delay on disconnect"><pre>[<span>replica</span>]
<span>enabled</span> = <span>true</span>                       <span><span>#</span> Enable read-only replica mode</span>
<span>master_address</span> = <span><span>&#34;</span>master:8080<span>&#34;</span></span>       <span><span>#</span> Master node gRPC address</span>
<span>reconnect_interval_seconds</span> = <span>5</span>       <span><span>#</span> Reconnect delay on disconnect</span></pre></div>
<p dir="auto"><strong>Note:</strong> Replica mode is mutually exclusive with cluster mode. A replica receives all data via streaming replication but cannot accept writes.</p>

<div dir="auto" data-snippet-clipboard-copy-content="[replication]
default_write_consistency = &#34;QUORUM&#34;      # Write consistency level: ONE, QUORUM, ALL
default_read_consistency = &#34;LOCAL_ONE&#34;    # Read consistency level
write_timeout_ms = 5000                   # Write operation timeout
read_timeout_ms = 2000                    # Read operation timeout

# Anti-Entropy: Background healing for eventual consistency
# - Detects and repairs divergence between replicas
# - Uses delta sync for small lags, snapshot for large lags
# - Includes gap detection to prevent incomplete data after GC
enable_anti_entropy = true                 # Enable automatic catch-up for lagging nodes
anti_entropy_interval_seconds = 60         # How often to check for lag (default: 60s)
delta_sync_threshold_transactions = 10000  # Delta sync if lag &lt; 10K txns
delta_sync_threshold_seconds = 3600        # Snapshot if lag &gt; 1 hour

# Garbage Collection: Reclaim disk space by deleting old transaction records
# - gc_min must be &gt;= delta_sync_threshold (validated at startup)
# - gc_max should be &gt;= 2x delta_sync_threshold (recommended)
# - Set gc_max = 0 for unlimited retention
gc_min_retention_hours = 2   # Keep at least 2 hours (&gt;= 1 hour delta threshold)
gc_max_retention_hours = 24  # Force delete after 24 hours"><pre>[<span>replication</span>]
<span>default_write_consistency</span> = <span><span>&#34;</span>QUORUM<span>&#34;</span></span>      <span><span>#</span> Write consistency level: ONE, QUORUM, ALL</span>
<span>default_read_consistency</span> = <span><span>&#34;</span>LOCAL_ONE<span>&#34;</span></span>    <span><span>#</span> Read consistency level</span>
<span>write_timeout_ms</span> = <span>5000</span>                   <span><span>#</span> Write operation timeout</span>
<span>read_timeout_ms</span> = <span>2000</span>                    <span><span>#</span> Read operation timeout</span>

<span><span>#</span> Anti-Entropy: Background healing for eventual consistency</span>
<span><span>#</span> - Detects and repairs divergence between replicas</span>
<span><span>#</span> - Uses delta sync for small lags, snapshot for large lags</span>
<span><span>#</span> - Includes gap detection to prevent incomplete data after GC</span>
<span>enable_anti_entropy</span> = <span>true</span>                 <span><span>#</span> Enable automatic catch-up for lagging nodes</span>
<span>anti_entropy_interval_seconds</span> = <span>60</span>         <span><span>#</span> How often to check for lag (default: 60s)</span>
<span>delta_sync_threshold_transactions</span> = <span>10000</span>  <span><span>#</span> Delta sync if lag &lt; 10K txns</span>
<span>delta_sync_threshold_seconds</span> = <span>3600</span>        <span><span>#</span> Snapshot if lag &gt; 1 hour</span>

<span><span>#</span> Garbage Collection: Reclaim disk space by deleting old transaction records</span>
<span><span>#</span> - gc_min must be &gt;= delta_sync_threshold (validated at startup)</span>
<span><span>#</span> - gc_max should be &gt;= 2x delta_sync_threshold (recommended)</span>
<span><span>#</span> - Set gc_max = 0 for unlimited retention</span>
<span>gc_min_retention_hours</span> = <span>2</span>   <span><span>#</span> Keep at least 2 hours (&gt;= 1 hour delta threshold)</span>
<span>gc_max_retention_hours</span> = <span>24</span>  <span><span>#</span> Force delete after 24 hours</span></pre></div>
<p dir="auto"><strong>Anti-Entropy Tuning:</strong></p>
<ul dir="auto">
<li><strong>Small clusters (2-3 nodes)</strong>: Use default settings (60s interval)</li>
<li><strong>Large clusters (5+ nodes)</strong>: Consider increasing interval to 120-180s to reduce network overhead</li>
<li><strong>High write throughput</strong>: Increase <code>delta_sync_threshold_transactions</code> to 50000+</li>
<li><strong>Long-running clusters</strong>: Keep <code>gc_max_retention_hours</code> at 24+ to handle extended outages</li>
</ul>
<p dir="auto"><strong>GC Configuration Rules (Validated at Startup):</strong></p>
<ul dir="auto">
<li><code>gc_min_retention_hours</code> must be &gt;= <code>delta_sync_threshold_seconds</code> (in hours)</li>
<li><code>gc_max_retention_hours</code> should be &gt;= 2x <code>delta_sync_threshold_seconds</code></li>
<li>Violating these rules will cause startup failure with helpful error messages</li>
</ul>

<div dir="auto" data-snippet-clipboard-copy-content="[query_pipeline]
transpiler_cache_size = 10000  # LRU cache for MySQL→SQLite transpilation
validator_pool_size = 8        # SQLite connection pool for validation"><pre>[<span>query_pipeline</span>]
<span>transpiler_cache_size</span> = <span>10000</span>  <span><span>#</span> LRU cache for MySQL→SQLite transpilation</span>
<span>validator_pool_size</span> = <span>8</span>        <span><span>#</span> SQLite connection pool for validation</span></pre></div>

<div dir="auto" data-snippet-clipboard-copy-content="[mysql]
enabled = true
bind_address = &#34;0.0.0.0&#34;
port = 3306
max_connections = 1000
unix_socket = &#34;&#34;              # Unix socket path (empty = disabled)
unix_socket_perm = 0660       # Socket file permissions
auto_id_mode = &#34;compact&#34;      # &#34;compact&#34; (53-bit, JS-safe) or &#34;extended&#34; (64-bit)"><pre>[<span>mysql</span>]
<span>enabled</span> = <span>true</span>
<span>bind_address</span> = <span><span>&#34;</span>0.0.0.0<span>&#34;</span></span>
<span>port</span> = <span>3306</span>
<span>max_connections</span> = <span>1000</span>
<span>unix_socket</span> = <span><span>&#34;</span><span>&#34;</span></span>              <span><span>#</span> Unix socket path (empty = disabled)</span>
<span>unix_socket_perm</span> = <span>0</span><span>660       </span><span><span>#</span> Socket file permissions</span>
<span>auto_id_mode</span> = <span><span>&#34;</span>compact<span>&#34;</span></span>      <span><span>#</span> &#34;compact&#34; (53-bit, JS-safe) or &#34;extended&#34; (64-bit)</span></pre></div>
<p dir="auto"><strong>Unix Socket Connection</strong> (lower latency than TCP):</p>
<div dir="auto" data-snippet-clipboard-copy-content="mysql --socket=/tmp/marmot/mysql.sock -u root"><pre>mysql --socket=/tmp/marmot/mysql.sock -u root</pre></div>

<div dir="auto" data-snippet-clipboard-copy-content="[publisher]
enabled = false  # Enable CDC publishing to external systems

[[publisher.sinks]]
name = &#34;kafka-main&#34;              # Unique sink name
type = &#34;kafka&#34;                   # &#34;kafka&#34; or &#34;nats&#34;
format = &#34;debezium&#34;              # Debezium-compatible JSON (only option)
brokers = [&#34;localhost:9092&#34;]     # Kafka broker addresses
topic_prefix = &#34;marmot.cdc&#34;      # Topic pattern: {prefix}.{db}.{table}
filter_tables = [&#34;*&#34;]            # Glob patterns for table filtering
filter_databases = [&#34;*&#34;]         # Glob patterns for database filtering
batch_size = 100                 # Events to read per poll cycle
poll_interval_ms = 10            # Polling interval (default: 10ms)
retry_initial_ms = 100           # Initial retry delay on failure
retry_max_ms = 30000             # Max retry delay (30 seconds)
retry_multiplier = 2.0           # Exponential backoff multiplier"><pre>[<span>publisher</span>]
<span>enabled</span> = <span>false</span>  <span><span>#</span> Enable CDC publishing to external systems</span>

[[<span>publisher</span>.<span>sinks</span>]]
<span>name</span> = <span><span>&#34;</span>kafka-main<span>&#34;</span></span>              <span><span>#</span> Unique sink name</span>
<span>type</span> = <span><span>&#34;</span>kafka<span>&#34;</span></span>                   <span><span>#</span> &#34;kafka&#34; or &#34;nats&#34;</span>
<span>format</span> = <span><span>&#34;</span>debezium<span>&#34;</span></span>              <span><span>#</span> Debezium-compatible JSON (only option)</span>
<span>brokers</span> = [<span><span>&#34;</span>localhost:9092<span>&#34;</span></span>]     <span><span>#</span> Kafka broker addresses</span>
<span>topic_prefix</span> = <span><span>&#34;</span>marmot.cdc<span>&#34;</span></span>      <span><span>#</span> Topic pattern: {prefix}.{db}.{table}</span>
<span>filter_tables</span> = [<span><span>&#34;</span>*<span>&#34;</span></span>]            <span><span>#</span> Glob patterns for table filtering</span>
<span>filter_databases</span> = [<span><span>&#34;</span>*<span>&#34;</span></span>]         <span><span>#</span> Glob patterns for database filtering</span>
<span>batch_size</span> = <span>100</span>                 <span><span>#</span> Events to read per poll cycle</span>
<span>poll_interval_ms</span> = <span>10</span>            <span><span>#</span> Polling interval (default: 10ms)</span>
<span>retry_initial_ms</span> = <span>100</span>           <span><span>#</span> Initial retry delay on failure</span>
<span>retry_max_ms</span> = <span>30000</span>             <span><span>#</span> Max retry delay (30 seconds)</span>
<span>retry_multiplier</span> = <span>2.0</span>           <span><span>#</span> Exponential backoff multiplier</span></pre></div>
<p dir="auto">See the <a href="https://maxpert.github.io/marmot/integrations" rel="nofollow">Integrations documentation</a> for details on event format, Kafka/NATS configuration, and use cases.</p>

<div dir="auto" data-snippet-clipboard-copy-content="[logging]
verbose = false          # Enable verbose logging
format = &#34;console&#34;       # Log format: console or json"><pre>[<span>logging</span>]
<span>verbose</span> = <span>false</span>          <span><span>#</span> Enable verbose logging</span>
<span>format</span> = <span><span>&#34;</span>console<span>&#34;</span></span>       <span><span>#</span> Log format: console or json</span></pre></div>

<div dir="auto" data-snippet-clipboard-copy-content="[prometheus]
enabled = true  # Metrics served on gRPC port at /metrics endpoint"><pre>[<span>prometheus</span>]
<span>enabled</span> = <span>true</span>  <span><span>#</span> Metrics served on gRPC port at /metrics endpoint</span></pre></div>
<p dir="auto"><strong>Accessing Metrics:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="# Metrics are multiplexed with gRPC on the same port
curl http://localhost:8080/metrics

# Prometheus scrape config
scrape_configs:
  - job_name: &#39;marmot&#39;
    static_configs:
      - targets: [&#39;node1:8080&#39;, &#39;node2:8080&#39;, &#39;node3:8080&#39;]"><pre><span><span>#</span> Metrics are multiplexed with gRPC on the same port</span>
curl http://localhost:8080/metrics

<span><span>#</span> Prometheus scrape config</span>
scrape_configs:
  - job_name: <span><span>&#39;</span>marmot<span>&#39;</span></span>
    static_configs:
      - targets: [<span><span>&#39;</span>node1:8080<span>&#39;</span></span>, <span><span>&#39;</span>node2:8080<span>&#39;</span></span>, <span><span>&#39;</span>node3:8080<span>&#39;</span></span>]</pre></div>
<p dir="auto">See <code>config.toml</code> for complete configuration reference with detailed comments.</p>

<p dir="auto">Performance benchmarks on a local development machine (Apple M-series, 3-node cluster, single machine):</p>

<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Parameter</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>Nodes</td>
<td>3 (ports 3307, 3308, 3309)</td>
</tr>
<tr>
<td>Threads</td>
<td>16</td>
</tr>
<tr>
<td>Batch Size</td>
<td>10 ops/transaction</td>
</tr>
<tr>
<td>Consistency</td>
<td>QUORUM</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>

<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Metric</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>Throughput</td>
<td><strong>4,175 ops/sec</strong></td>
</tr>
<tr>
<td>TX Throughput</td>
<td><strong>417 tx/sec</strong></td>
</tr>
<tr>
<td>Records Loaded</td>
<td>200,000</td>
</tr>
<tr>
<td>Errors</td>
<td>0</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>

<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Metric</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>Throughput</td>
<td><strong>3,370 ops/sec</strong></td>
</tr>
<tr>
<td>TX Throughput</td>
<td><strong>337 tx/sec</strong></td>
</tr>
<tr>
<td>Duration</td>
<td>120 seconds</td>
</tr>
<tr>
<td>Total Operations</td>
<td>404,930</td>
</tr>
<tr>
<td>Errors</td>
<td>0</td>
</tr>
<tr>
<td>Retries</td>
<td>37 (0.09%)</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><strong>Operation Distribution:</strong></p>
<ul dir="auto">
<li>READ: 20%</li>
<li>UPDATE: 30%</li>
<li>INSERT: 35%</li>
<li>DELETE: 5%</li>
<li>UPSERT: 10%</li>
</ul>

<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Percentile</th>
<th>Latency</th>
</tr>
</thead>
<tbody>
<tr>
<td>P50</td>
<td>4.3ms</td>
</tr>
<tr>
<td>P90</td>
<td>14.0ms</td>
</tr>
<tr>
<td>P95</td>
<td>36.8ms</td>
</tr>
<tr>
<td>P99</td>
<td>85.1ms</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>

<p dir="auto">All 3 nodes maintained identical row counts (346,684 rows) throughout the test, confirming consistent replication.</p>
<blockquote>
<p dir="auto"><strong>Note</strong>: These benchmarks are from a local development machine with all nodes on the same host. Production deployments across multiple machines will have different characteristics based on network latency. Expect P99 latencies of 50-200ms for cross-region QUORUM writes.</p>
</blockquote>
<div dir="auto"><h2 tabindex="-1" dir="auto">Backup &amp; Disaster Recovery</h2><a id="user-content-backup--disaster-recovery" aria-label="Permalink: Backup &amp; Disaster Recovery" href="#backup--disaster-recovery"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">Option 1: Litestream (Recommended)</h3><a id="user-content-option-1-litestream-recommended" aria-label="Permalink: Option 1: Litestream (Recommended)" href="#option-1-litestream-recommended"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Marmot&#39;s SQLite files are standard WAL-mode databases, compatible with <a href="https://litestream.io/" rel="nofollow">Litestream</a>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="litestream replicate /path/to/marmot-data/*.db s3://bucket/backup"><pre>litestream replicate /path/to/marmot-data/<span>*</span>.db s3://bucket/backup</pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">Option 2: CDC to External Storage</h3><a id="user-content-option-2-cdc-to-external-storage" aria-label="Permalink: Option 2: CDC to External Storage" href="#option-2-cdc-to-external-storage"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Enable CDC publisher to stream changes to Kafka/NATS, then archive to your preferred storage.</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">Option 3: Filesystem Snapshots</h3><a id="user-content-option-3-filesystem-snapshots" aria-label="Permalink: Option 3: Filesystem Snapshots" href="#option-3-filesystem-snapshots"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Since Marmot uses SQLite with WAL mode, you can safely snapshot the data directory during operation.</p>

<p dir="auto"><a href="https://starchart.cc/maxpert/marmot" rel="nofollow"><img src="https://camo.githubusercontent.com/ee99a4dc41e48fb1f38d51af628abb0ae1fd696beb5ccd37d3dfa28e7377565f/68747470733a2f2f7374617263686172742e63632f6d6178706572742f6d61726d6f742e7376673f76617269616e743d6164617074697665" alt="Stargazers over time" data-canonical-src="https://starchart.cc/maxpert/marmot.svg?variant=adaptive"/></a></p>

<ul dir="auto">
<li>For FAQs visit <a href="https://maxpert.github.io/marmot/intro#faq" rel="nofollow">this page</a></li>
<li>For community visit our <a href="https://discord.gg/AWUwY66XsE" rel="nofollow">discord</a> or discussions on GitHub</li>
</ul>
</article></div></div>
  </body>
</html>
