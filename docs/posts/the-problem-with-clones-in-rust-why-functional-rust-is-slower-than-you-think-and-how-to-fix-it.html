<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://hamy.xyz/blog/2026-02_the-problem-with-clones-in-rust">Original</a>
    <h1>The Problem with Clones in Rust - Why Functional Rust is Slower Than You Think (And How to Fix It)</h1>
    
    <div id="readability-page-1" class="page"><p>DISCLOSURE: If you buy through affiliate links, I may earn a small commission. <a href="https://hamy.xyz/blog/disclosures">(disclosures)</a></p><div><p>I&#39;ve been exploring <a href="https://hamy.xyz/blog/2026-01_high-level-rust">High Level Rust</a> as a way to get 80% of Rust&#39;s benefits with 20% of the pain. The core idea: use immutable data with functional pipelines and generous cloning to avoid borrow checker and lifetime complexity.</p>
<p>There&#39;s just one problem. Clones in Rust are expensive - far more expensive than in most mainstream languages. If you&#39;re not careful, your &#34;high-level&#34; Rust can actually run <em>slower</em> than garbage-collected languages like C#, TypeScript, or Python.</p>
<p>In this post I want to dig into why Rust clones are expensive, how they compare to other languages, and how to fix it so you can write functional Rust without tanking your performance.</p>
<iframe width="560" height="315" src="https://www.youtube.com/embed/5SntrSo8VMw?si=2YJcMt3GpSX5UNiy" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>
<h2 id="why-rust-clones-are-different">Why Rust Clones Are Different</h2>
<p>In most languages, &#34;copying&#34; an object is cheap because you&#39;re copying references, not data.</p>
<pre><code>// C#
var p1 = new Person(&#34;alice&#34;, tags);
var p2 = p1 with { Name = &#34;bob&#34; };
// p2.Tags points to same memory as p1.Tags
// Only &#34;bob&#34; string is newly allocated
</code></pre>
<p>C#, TypeScript, and Python all do shallow copies by default - when you clone a record, you copy pointers to the existing data rather than duplicating it. The garbage collector handles cleanup later.</p>
<p>F# goes further with its default collections (<code>list</code>, <code>Map</code>, <code>Set</code>) which use structural sharing - when you &#34;modify&#34; an immutable collection, you create a new version that reuses most of the old structure. Only the changed nodes are new; everything else points to the same memory as before. This is similar to what the <code>imbl</code> crate does in Rust.</p>
<p>Rust does deep copies of structs by default. When you call <code>.clone()</code> on a struct with Strings and Vecs, you&#39;re allocating new heap buffers and copying all the data:</p>
<pre><code>struct Person { id: i64, name: String, email: String }

let p1 = Person { id: 1, name: &#34;alice&#34;.into(), email: &#34;a@b.com&#34;.into() };
let p2 = p1.clone();
// id: bitwise copy (8 bytes on stack, essentially free)
// name: allocates new heap buffer, copies &#34;alice&#34;
// email: allocates new heap buffer, copies &#34;a@b.com&#34;
</code></pre>
<p>This is more technically correct - you get true independence between copies with no shared state. But it&#39;s also much slower.</p>
<h2 id="how-much-slower">How Much Slower?</h2>
<p><img src="https://cdn.hamy.xyz/labs/posts/2026/2026-02_the-problem-rust-clones/2026-02_problem-rust-clone_shallow-vs-deep.png" alt="Rust Deep Copies"/></p>
<p>Here&#39;s an approximate performance comparison for a typical immutable update (a struct with ~5 fields, 2 strings):</p>
<table>
<thead>
<tr>
<th>Language</th>
<th>What Happens</th>
<th>Est. Time</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>C# record struct</strong></td>
<td>Stack memcpy, refs copied</td>
<td>~15-30ns</td>
</tr>
<tr>
<td><strong>Rust (Arc fields)</strong></td>
<td>Refcount bump</td>
<td>~20-40ns</td>
</tr>
<tr>
<td><strong>F#</strong></td>
<td>New heap object, refs copied</td>
<td>~25-50ns</td>
</tr>
<tr>
<td><strong>TypeScript</strong></td>
<td>O(n) property copy, refs copied</td>
<td>~50-100ns</td>
</tr>
<tr>
<td><strong>Python</strong></td>
<td>New dict/object, refs copied</td>
<td>~100-200ns</td>
</tr>
<tr>
<td><strong>Rust (owned Strings)</strong></td>
<td>Deep clone all fields</td>
<td>~100-500ns</td>
</tr>
</tbody>
</table>
<p>Naive Rust clones are <strong>3-5x slower</strong> than the equivalent operation in garbage-collected languages.</p>
<p><img src="https://cdn.hamy.xyz/labs/posts/2026/2026-02_the-problem-rust-clones/2026-02_problem-rust-clones_cost-by-language.png" alt="Rust vs GC languages for clone costs"/></p>
<p>The relative cost per immutable update shakes out to:</p>
<table>
<thead>
<tr>
<th>Language</th>
<th>Relative Cost</th>
</tr>
</thead>
<tbody>
<tr>
<td>C# record struct</td>
<td>1x (baseline)</td>
</tr>
<tr>
<td>Rust (Arc fields)</td>
<td>~1x</td>
</tr>
<tr>
<td>F#</td>
<td>~1.2x</td>
</tr>
<tr>
<td>TypeScript</td>
<td>~1.5x</td>
</tr>
<tr>
<td>Python</td>
<td>~2-3x</td>
</tr>
<tr>
<td><strong>Rust (owned Strings)</strong></td>
<td><strong>~3-5x</strong></td>
</tr>
</tbody>
</table>
<p>If you&#39;re doing functional transforms in a hot path - mapping over collections, building up state immutably, chaining operations - those 3-5x multipliers add up fast. You can easily end up with Rust code that&#39;s slower than Python for certain workloads.</p>
<h2 id="why-gc-languages-win-at-cloning">Why GC Languages &#34;Win&#34; at Cloning</h2>
<p>Garbage-collected languages get cheap copies by default because:</p>
<ol>
<li><strong>Strings are immutable references</strong> under the hood</li>
<li>They just <strong>copy pointers</strong> for unchanged fields</li>
<li>The <strong>GC handles cleanup</strong> later</li>
</ol>
<p>This is the tradeoff Rust makes for deterministic memory management. You pay the allocation / deallocation costs upfront instead of amortizing it through garbage collection. For mutation-heavy code, this is a win. For clone-heavy functional code, it&#39;s a tax.</p>
<h2 id="how-to-fix-slow-clones">How to Fix Slow Clones</h2>
<p>There are two approaches:</p>
<h3 id="option-1-don-t-clone-use-mutations">Option 1: Don&#39;t Clone (Use Mutations)</h3>
<p>The idiomatic Rust approach is to leverage the ownership system for safe mutations. This is what Rust was designed for - fast, safe mutations without garbage collection overhead.</p>
<p>If you have a hot path, reach for mutations. It&#39;s faster and more idiomatic.</p>
<h3 id="option-2-make-clones-cheap">Option 2: Make Clones Cheap</h3>
<p>If you want functional pipelines with generous cloning (like I do with <a href="https://hamy.xyz/blog/2026-01_high-level-rust">High Level Rust</a>), you need to make your clones cheap. The way to do this is to make your Rust structs behave like GC language structs internally:</p>
<table>
<thead>
<tr>
<th>Instead of</th>
<th>Use</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>String</code></td>
<td><code>Arc&lt;str&gt;</code></td>
</tr>
<tr>
<td><code>Vec&lt;T&gt;</code></td>
<td><code>Arc&lt;[T]&gt;</code> or <code>imbl::Vector&lt;T&gt;</code></td>
</tr>
<tr>
<td>Nested struct</td>
<td><code>Arc&lt;ChildStruct&gt;</code></td>
</tr>
</tbody>
</table>
<p>With Arc fields, clone becomes a refcount bump instead of a deep copy. Here&#39;s the difference in practice (<a href="https://github.com/SIRHAMY/light-clone/blob/main/BENCHMARKS.md">benchmarks</a>):</p>
<table>
<thead>
<tr>
<th>Scenario</th>
<th>Standard Clone</th>
<th>Arc/Immutable</th>
<th>Speedup</th>
</tr>
</thead>
<tbody>
<tr>
<td>10KB string</td>
<td>83ns</td>
<td>11ns</td>
<td><strong>7.5x</strong></td>
</tr>
<tr>
<td>10K element vector</td>
<td>622ns</td>
<td>41ns</td>
<td><strong>15x</strong></td>
</tr>
<tr>
<td>10K element hashmap</td>
<td>2,200ns</td>
<td>15ns</td>
<td><strong>147x</strong></td>
</tr>
<tr>
<td>Nested struct (50 levels)</td>
<td>1,900ns</td>
<td>15ns</td>
<td><strong>127x</strong></td>
</tr>
</tbody>
</table>
<p>Your clones become as cheap as C# or F#.</p>
<pre><code>#[derive(Clone)]
struct Person {
    id: i64,                    // Copy - no allocation
    name: Arc&lt;str&gt;,             // Clone = refcount bump
    email: Arc&lt;str&gt;,            // Clone = refcount bump
    address: Arc&lt;Address&gt;,      // Clone = refcount bump
    tags: imbl::Vector&lt;Arc&lt;str&gt;&gt;, // Clone = pointer copy (structural sharing)
}
</code></pre>
<h3 id="helpful-crates">Helpful Crates</h3>
<table>
<thead>
<tr>
<th>Crate</th>
<th>What it does</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>imbl</code></td>
<td>Persistent collections (Vector, HashMap) with structural sharing - O(1) clones</td>
</tr>
<tr>
<td><code>arcstr</code></td>
<td>Ergonomic <code>Arc&lt;str&gt;</code> with literal support</td>
</tr>
<tr>
<td><code>smol_str</code></td>
<td>Small string optimization + Arc for larger</td>
</tr>
<tr>
<td><code>bytes</code></td>
<td><code>Bytes</code> type, essentially <code>Arc&lt;[u8]&gt;</code> with slicing</td>
</tr>
<tr>
<td><code>triomphe</code></td>
<td>Faster Arc (no weak ref support)</td>
</tr>
</tbody>
</table>
<p>For collections, <code>imbl</code> is particularly useful. You trade slightly slower mutations for dramatically faster clones:</p>
<table>
<thead>
<tr>
<th>Operation</th>
<th><code>Vec</code></th>
<th><code>imbl::Vector</code></th>
</tr>
</thead>
<tbody>
<tr>
<td>Clone entire collection</td>
<td>O(n) ~5-10μs</td>
<td><strong>O(1) ~10-20ns</strong></td>
</tr>
<tr>
<td>Random access</td>
<td>O(1) ~5ns</td>
<td>O(log n) ~30-80ns</td>
</tr>
<tr>
<td>Push/Append</td>
<td>O(1) ~10-30ns</td>
<td>O(log n) ~50-150ns</td>
</tr>
</tbody>
</table>
<p>If you&#39;re cloning more than ~50-100 times per mutation, immutable collections win on total time.</p>
<h2 id="the-gotcha-cheap-and-expensive-clones-look-the-same">The Gotcha: Cheap and Expensive Clones Look the Same</h2>
<p>The problem with the cloning approach is that expensive clones and cheap clones look identical in Rust:</p>
<pre><code>expensive_struct.clone()  // Deep copy, ~500ns
cheap_struct.clone()      // Refcount bump, ~30ns
</code></pre>
<p>There&#39;s no type-level distinction. You can accidentally introduce an expensive clone and tank your performance without any compiler warning.</p>
<p>I&#39;m working on <a href="https://github.com/SIRHAMY/light-clone">LightClone</a> to help with this - a trait that enforces cheap clones at compile time by ensuring all underlying data types are pre-determined to be cheap - <code>Arc</code>-wrapped, <code>Copy</code>, or known persistent data structures. It&#39;s early, but the goal is to make the type system catch expensive clones so you can avoid unexpected perf hits.</p>
<pre><code>// This won&#39;t compile - String is expensive to clone
#[derive(LightClone)]
struct Person {
    id: i64,
    name: String,  // ERROR: String doesn&#39;t implement LightClone
}

// This compiles - Arc&lt;str&gt; is cheap to clone
#[derive(LightClone)]
struct Person {
    id: i64,
    name: Arc&lt;str&gt;,  // OK: Arc&lt;str&gt; implements LightClone
}
</code></pre>
<p><em>There are also some <a href="https://smallcultfollowing.com/babysteps/blog/2025/11/10/just-call-clone/">alias proposals</a> in the Rust community to address this at the language level but they haven&#39;t moved much so unclear how soon they&#39;ll land.</em></p>
<h2 id="does-this-actually-matter-for-web-apis">Does This Actually Matter for Web APIs?</h2>
<p>For typical web API backends: <strong>probably not much</strong>.</p>
<table>
<thead>
<tr>
<th>Operation</th>
<th>Typical Time</th>
</tr>
</thead>
<tbody>
<tr>
<td>Database query</td>
<td>1-50ms</td>
</tr>
<tr>
<td>External API call</td>
<td>10-200ms</td>
</tr>
<tr>
<td>JSON serialization</td>
<td>10-100μs</td>
</tr>
<tr>
<td>Business logic (CPU)</td>
<td>50-500μs</td>
</tr>
<tr>
<td>Clone overhead</td>
<td>0.1-10μs</td>
</tr>
</tbody>
</table>
<p>Clone performance is noise compared to I/O latency. If 90% of your request time is waiting on the database, optimizing clone performance gets you... not much.</p>
<p>Where clone performance matters:</p>
<ul>
<li>Batch data processing</li>
<li>Tight loops over large collections</li>
<li>Game engines, real-time systems</li>
<li>Anywhere you&#39;re CPU-bound</li>
</ul>
<p>But for many of those you&#39;ll just reach for mutations anyway. So for general high level apps - reach for high level Rust, use LightClone to enforce cheap clones, and enjoy the devx improvements.</p>
<h2 id="next">Next</h2>
<p>Rust&#39;s clone behavior is one of the hidden costs of using it as a high-level language. Unlike GC languages where cloning is cheap by default, Rust requires you to think about memory and opt into cheap clones by using Arc and immutable collections.</p>
<p>The good news is once you know the pattern, it&#39;s not hard to apply. Use <code>Arc&lt;str&gt;</code> instead of <code>String</code>, <code>imbl::Vector</code> instead of <code>Vec</code>, wrap nested structs in <code>Arc</code>. Your clones become GC-language cheap while keeping Rust&#39;s other benefits.</p>
<p>If you&#39;re interested in this approach, check out <a href="https://github.com/SIRHAMY/light-clone">LightClone</a> - I&#39;m building it to make the type system enforce cheap clones so you don&#39;t accidentally tank your performance. Star it on GitHub if you want to support it and continue to see it develop.</p>
<p>If you liked this post you might also like:</p>
<ul>
<li><a href="https://hamy.xyz/blog/2026-01_high-level-rust">High-Level Rust: Getting 80% of the Benefits with 20% of the Pain</a></li>
<li><a href="https://hamy.xyz/blog/2026-01_missing-programming-language">The Missing Programming Language - Why There&#39;s No S-Tier Language (Yet)</a></li>
<li><a href="https://hamy.xyz/blog/2025-11_why-im-moving-blog-fsharp-to-csharp">Why I&#39;m Moving my Blog from F# to C#</a></li>
</ul>
</div></div>
  </body>
</html>
