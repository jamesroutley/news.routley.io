<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://chapel-lang.org/blog/posts/announcing-chapel-1.32/">Original</a>
    <h1>Announcing Chapel 1.32</h1>
    
    <div id="readability-page-1" class="page"><div>
    
    
    

    

    <p>The Chapel developer community is excited to announce the release of
Chapel version 1.32!  To obtain a copy, please refer to the
<a href="https://chapel-lang.org/download.html">Downloading Chapel</a> page on
the Chapel website.</p>
<h3 id="highlights-of-chapel-132">Highlights of Chapel 1.32</h3>
<h4 id="chapel-20-release-candidate">Chapel 2.0 Release Candidate</h4>
<p>The main highlight of Chapel 1.32 is that it is a release candidate
for our forthcoming Chapel 2.0 release!  If you’re not familiar with
the concept of Chapel 2.0, it is intended to be a release that
declares a core subset of the language and library features as
‘stable’.  These features are ones that we intend to support in
their current form going forward, such that code relying on them
will not break across releases.  Meanwhile, other features will be
considered ‘unstable’, implying that they are ones where we are
still learning from user experiences and refining interfaces before
considering them to be stabilized.  Unstable features may continue
evolving after the 2.0 release, either by improving them until they
too are stable, or replacing them with other, more stable features.</p>
<p>Chapel 1.32 being a 2.0 release candidate means that this is a key
time for Chapel users to give us feedback about aspects of our
design that they would like to see change prior to the 2.0 release.
Users may also want to compile their programs with the
<code>--warn-unstable</code> flag in order to identify any unstable features
that they are currently relying upon.  Reliance on such features
could motivate you to advocate for stabilizing those features sooner,
or you could simply view it as an opportunity to be aware that those
features may continue to evolve over time.  We are generally
interested in hearing about which unstable features user code is
currently relying upon, to help with our own prioritization efforts.</p>
<p>Users with feedback about 2.0 readiness or the stability of current
features are encouraged to share it with us on <a href="https://chapel.discourse.group/c/users/">Chapel’s Discourse
user forum</a> or as a <a href="https://github.com/chapel-lang/chapel/issues">GitHub
issue</a>.</p>
<p>As part of the team’s push to make this a worthy Chapel 2.0 release
candidate, Chapel 1.32 contains a large number of improvements to
the language, compiler, and libraries.  Some of these changes
include:</p>
<ul>
<li>
<p>new warnings to encourage a programming style in which generic
types are more clearly visible in a program’s source code</p>
</li>
<li>
<p>a change in the default intent for arrays and record receivers
(i.e., <code>this</code>) to <code>const</code> for greater uniformity with other types</p>
</li>
<li>
<p>revised definitions of the compiler’s interpretation of <code>const</code>
intents and default return/yield intents</p>
</li>
<li>
<p>significant improvements to ranges, domains, and distributions,
including converting distribution types to records, obviating the
need for the <code>dmap</code> type</p>
</li>
<li>
<p>major improvements to the <code>IO</code>, <code>Math</code>, <code>BigInteger</code>, and <code>Time</code>
modules, including a new IO serialization framework for specifying
how to read and write types to files orthogonally from the file’s
format (see <a href="#io-serialization-framework">below</a> for more detail)</p>
</li>
</ul>
<p>For more information about these changes, and many others not
summarized here, refer to the
<a href="https://github.com/chapel-lang/chapel/blob/release/1.32/CHANGES.md">CHANGES.md</a>
file, <a href="https://chapel-lang.org/docs/1.32/">documentation</a> for Chapel
1.32, or forthcoming <a href="https://chapel-lang.org/releaseNotes.html">release note
slides</a>.</p>
<h4 id="gpu-improvements">GPU Improvements</h4>
<p>Version 1.32 includes significant improvements to Chapel’s support
for vendor-neutral GPU programming, both in terms of performance and
capabilities.</p>
<p>Key performance improvements include:</p>
<ul>
<li>
<p>compiler optimizations to reduce the number of pointer
dereferences when accessing arrays within GPU kernels</p>
</li>
<li>
<p>switching the default memory allocation scheme for arrays to
‘array_on_device’ mode, in which an array’s data is stored
directly on the GPU rather than in managed memory</p>
</li>
<li>
<p>a reduction in overheads when invoking math routines within GPU
kernels by eliminating unnecessary boilerplate wrapper code</p>
</li>
<li>
<p>using per-task GPU streams, which can enable
communication-computation overlap to improve performance</p>
</li>
</ul>
<p>The non-trivial impact of these optimizations can be seen in the
following graphs, which show the improvements that have occurred in
a Chapel port of the SHOC Sort benchmark on both NVIDIA and AMD
GPUs.  Note that the second graph includes data transfer times while
the first does not.</p>
<figure><img src="https://chapel-lang.org/blog/posts/announcing-chapel-1.32/SHOC-sort-combined.png"/>
</figure>

<p>Chapel’s support for AMD effectively reaches feature parity with
NVIDIA in this release, largely due to the addition of a number of
math routines that had not been supported for AMD in
Chapel 1.31.  In addition, the Chapel compiler’s <code>--savec</code> flag
can now be used to inspect the assembly code generated when
targeting AMD GPUs.</p>
<p>Meanwhile, when targeting NVIDIA GPUs, Chapel 1.32 adds support for
generating multi-architecture binaries by setting <code>CHPL_GPU_ARCH</code> to
a comma-separated list of target architectures.</p>
<p>See the latest <a href="https://chapel-lang.org/docs/1.32/technotes/gpu.html">GPU
Programming</a>
technical note for additional details about these changes and
Chapel’s overall support for GPUs in 1.32.</p>
<h4 id="support-for-co-locales">Support for Co-Locales</h4>
<p>Since its inception, Chapel has preferred to represent each compute
node as a single top-level locale, using multitasking to implement
any intra-node parallelism.  This approach has been beneficial in
many problem domains where running a process per core could result
in larger memory requirements or poor surface-to-volume effects due
to the amount of <span>
<label for="SPMD definition">SPMD</label>

<span>
<span>[note:</span>
SPMD = Single Program, Multiple Data, a static and coarse-grained
style of parallelism in which multiple copies of the same program
are executed, e.g. one per processor core 
<span>]</span>
</span>
</span>

parallelism.</p>
<p>However, as modern compute nodes have begun to support multiple <span>
<label for="NIC definition">NICs,</label>

<span>
<span>[note:</span>
NICs = Network Interface
Chips, which permit processes to communicate with remote nodes 
<span>]</span>
</span>
</span>
 this traditional approach has faced challenges.
Specifically, it is unduly complicated to have a single locale (UNIX
process) leverage multiple NICs effectively; yet using just one NIC
leaves potential performance benefits on the floor by not exercising
the network to its full capacity.</p>
<p>To address this, Chapel 1.32 introduces user-facing support for
<em>co-locales</em>, in which multiple locales can be mapped to a single
compute node.  Using co-locales can lead to performance improvements
by making better use of the network and/or reducing the number of
memory references that cross between sockets.  For example, the
following charts show improvements to a pair of benchmarks when run
using two locales per node on a dual-NIC HPE Cray EX system using
Slingshot 11:</p>
<figure><img src="https://chapel-lang.org/blog/posts/announcing-chapel-1.32/co-locales-perf.png"/>
</figure>

<p>Current support is limited to running a locale per socket on a given
compute node, and is also limited to certain platforms and
configurations:</p>
<ul>
<li>
<p>HPE Cray EX platforms with Slingshot 11 when using <code>CHPL_COMM=ofi</code></p>
</li>
<li>
<p>InfiniBand-based systems when using <code>CHPL_COMM=gasnet</code> with
<code>CHPL_COMM_SUBSTRATE=ibv</code></p>
</li>
<li>
<p>Configurations using <code>CHPL_LAUNCHER=slurm-srun</code> or <code>pbs-gasnetrun_ibv</code></p>
</li>
</ul>
<p>To opt-in to using co-locales, specify the number of locales for your
Chapel program using a product of nodes and locales per node.  For
example, the following invocation:</p>
<div><pre tabindex="0"><code data-lang="bash"><span><span>$ ./myChapelProgram -nl 8x2
</span></span></code></pre></div><p>says to run the Chapel program on 8 nodes with 2 locales per node,
for a total of 16 locales.</p>
<p>For more information on using co-locales with Chapel, please refer
to <a href="https://chapel-lang.org/docs/1.32/usingchapel/multilocale.html#co-locales">the online
documentation</a>.</p>
<h4 id="io-serialization-framework">IO Serialization Framework</h4>
<p>The IO serialization framework <a href="https://chapel-lang.org/blog/posts/announcing-chapel-1.31/#prototypical-support-for-io-serializers">that was prototyped in Chapel
1.31</a>
is now used by default for calls like <code>writeln()</code> and <code>read()</code>, and
it is also available for use with types written by end-users.</p>
<p>As an illustration, consider the following example that prints an
array in a couple of different formats:</p>
<div data-code-type="main" data-code-section="only"><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="Chapel"><span><span><span>use</span><span> </span><span>IO</span><span>,</span><span> </span><span>JSON</span><span>;</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>var</span><span> </span><span>A</span><span> </span><span>=</span><span> </span><span>[</span><span>1</span><span>,</span><span> </span><span>2</span><span>,</span><span> </span><span>3</span><span>,</span><span> </span><span>4</span><span>];</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>writeln</span><span>(</span><span>A</span><span>);</span><span>             </span><span>// prints &#39;1 2 3 4&#39;  
</span></span></span><span><span><span></span><span>
</span></span></span><span><span><span></span><span>var</span><span> </span><span>jsonWriter</span><span> </span><span>=</span><span> </span><span>stdout</span><span>.</span><span>withSerializer</span><span>(</span><span>jsonSerializer</span><span>);</span><span>  
</span></span></span><span><span><span></span><span>jsonWriter</span><span>.</span><span>writeln</span><span>(</span><span>A</span><span>);</span><span>  </span><span>// prints &#39;[1, 2, 3, 4]&#39;  
</span></span></span></code></pre></td></tr></tbody></table>
</div>
</div>
<p>Line 5
 uses a normal
<code>writeln()</code> to print the array of integers to the standard console
output (<code>stdout</code>) using Chapel’s traditional format—one element
at a time, separated by spaces.  Then, in line 7, we create a
variant of <code>stdout</code> that uses the <a href="https://chapel-lang.org/docs/1.32/modules/standard/JSON.html">JSON
serializer</a>
for all <code>write()</code>s called on it.  The result is that when we write
the array to this output stream in line 8, it is printed using
standard JSON formatting.  Other current serializers support
<a href="https://chapel-lang.org/docs/1.32/modules/standard/IO.html#IO.binarySerializer">binary</a>,
<a href="https://chapel-lang.org/docs/1.32/modules/packages/YAML.html">YAML</a>,
and <a href="https://chapel-lang.org/docs/1.32/modules/packages/ChplFormat.html">Chapel
syntax</a>
as alternate formats.</p>
<p>The new serialization framework also includes deserializers, which
support reading values back in from the given format.  And most
importantly, users can now define their own methods specifying how
their types should be written or read.  This can be done in a
format-neutral manner for simplicity, or in a way that’s sensitive
to the output format when needed.  For more information on defining
these methods, please refer to <a href="https://chapel-lang.org/docs/1.32/modules/standard/ChapelIO.html#the-serialize-and-deserialize-methods">their online
documentation</a>.</p>
<h4 id="improved-arm64-support">Improved ARM64 Support</h4>
<p>Thanks to our colleagues on the
<a href="https://www.sandia.gov/qthreads/">Qthreads</a> team at Sandia National
Laboratories, support for ARM64 chips is significantly improved in
Chapel 1.32.  Specifically, this release bundles version 1.19 of
Qthreads, in which task creation and switching have been
re-implemented using assembly code for ARM64 chips.  This can
dramatically reduce multitasking overheads when using Chapel’s
preferred <code>CHPL_TASKS=qthreads</code> mode.</p>
<p>As a simple illustration, the following table shows the impact of
this fast task switching on a 16-node run of
<a href="https://github.com/jdevinney/bale">Bale</a> Index Gather using various
implementation strategies:</p>
<table>
<thead>
<tr>
<th>Approach</th>
<th>w/out fast tasks</th>
<th>with fast tasks</th>
<th>improvement</th>
</tr>
</thead>
<tbody>
<tr>
<td>ordered</td>
<td>70.7 MB/s/node</td>
<td>84.7 MB/s/node</td>
<td>1.20x</td>
</tr>
<tr>
<td>ordered, oversubscribed</td>
<td>86.3 MB/s/node</td>
<td>140.4 MB/s/node</td>
<td>1.63x</td>
</tr>
<tr>
<td>unordered</td>
<td>147.5 MB/s/node</td>
<td>152.3 MB/s/node</td>
<td>1.03x</td>
</tr>
<tr>
<td>aggregated</td>
<td>1352.0 MB/s/node</td>
<td>1448.5 MB/s/node</td>
<td>1.07x</td>
</tr>
</tbody>
</table>
<p>In addition, Qthreads 1.19 also improved portability for ARM64-based
platforms.  This enables the use of <code>CHPL_TASKS=qthreads</code> on a wider
variety of systems, such as M1/M2 Macs, where it is now the default.</p>
<h4 id="and-much-more">And much more…</h4>
<p>Beyond the highlights mentioned here, Chapel 1.32 contains numerous
other improvements to Chapel’s features and interfaces, such as:</p>
<ul>
<li>
<p>initial support for array allocations that will throw if the
system is out of memory</p>
</li>
<li>
<p>a more robust set of types and routines for dealing with C pointer
types, particularly with respect to <code>const</code>-ness</p>
</li>
<li>
<p>initial support for interface declarations, to opt-in to special
methods like the serialization methods mentioned above</p>
</li>
<li>
<p>features for power users to better understand the vectorization
and transformation of their Chapel programs</p>
</li>
<li>
<p>support for selecting between processor types on chips with
heterogeneous processing units</p>
</li>
</ul>
<p>For a more complete list of changes in Chapel 1.32, please refer
to its
<a href="https://github.com/chapel-lang/chapel/blob/release/1.32/CHANGES.md">CHANGES.md</a>
file.</p>
<h3 id="for-more-information">For More Information</h3>
<p>For questions about any of the changes in this release, please reach
out to the developer community on <a href="https://chapel.discourse.group/">Discourse</a>.</p>
<p>As always, we’re interested in feedback on how we can help make the
Chapel language, libraries, implementation, and tools more useful to
you in your work.</p>
<p>And always, thanks to <a href="https://github.com/chapel-lang/chapel/blob/release/1.32/CONTRIBUTORS.md">everyone who
contributed</a>
to the Chapel 1.32 release!</p>

</div></div>
  </body>
</html>
