<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.toast.cafe/posix2024-xcu">Original</a>
    <h1>What&#39;s New in POSIX 2024</h1>
    
    <div id="readability-page-1" class="page"><div>
    <article>
        <h2 id="toc">Table of Contents</h2>
<ul id="toc-list">
<li>
<a href="#highlights" rel="nofollow">Highlights</a><ul>
<li>
<a href="#handling-of-filenames-in-shell" rel="nofollow">Handling of Filenames in Shell</a></li>
<li>
<a href="#modern-c" rel="nofollow">Modern C</a></li>
<li>
<a href="#limits--cooperation" rel="nofollow">Limits &amp; Cooperation</a></li>
<li>
<a href="#makefiles" rel="nofollow">Makefiles</a></li>
<li>
<a href="#logging" rel="nofollow">Logging</a></li>
<li>
<a href="#internationalization" rel="nofollow">Internationalization</a></li>
<li>
<a href="#minor-changes" rel="nofollow">Minor Changes</a></li>
</ul>
</li>
<li>
<a href="#changes-index" rel="nofollow">Changes Index</a></li>
</ul>
<p>In the 1950s, computers did not really interoperate. ARPANET has not yet happened (that would become a thing in the 60s), and every operating system was typically tied to the hardware that was meant to run on. Most communication actually happened over telephone, and no company was more present in that space than the Bell System. Unfortunately, the way they were so present was through exclusive supply contracts (with its subsidiary Western Electric) and a vast array of patents that it would refuse to license to competitors. So they got an antitrust suit aimed at them, which after seven years of litigation culminated in the 1956 consent decree. The Bell System was broken up, obliged to license all of its patents royalty-free, and barred from entering any industry other than telecommunications. So they made Unix.</p>
<p>Unix was unique, because the focus was on the software (since Bell couldn’t compete in this space anyway, as per the above). An evolution of Multics, it was developed on a PDP-7 (by cross-compiling). They then ported a compiler-compiler to it, leading to the development of B. Once their internal needs outgrew the PDP-7, it got ported to the PDP-11, and gained full typesetting capabilities. Gaining some traction internally, when Bell acquired other PDP-11s, instead of running DEC’s own OS for the machine, they simply ran Unix on it. This has led to the rewrite of the OS in C, a higher level (comparatively, of course) language, which enabled the porting of it to other machines (like the Interdata 7/32 and 8/32). Interest grew, and Bell (not being allowed to turn Unix into a product) simply shipped it at manufacturing cost for the media. Notably, ARPANET used it (see: RFC 681).</p>
<p>In the early 1980s, Unix had become a univeral operating system, used on virtually every serious machine. Then, AT&amp;T got hit by an antitrust suit again. The exact details matter less, but freed it from the old restriction. System V immediately turned into a product, almost killing it. That very year, the GNU project was created, and the BSD project was started in Berkeley. Having grown accustomed to interoperability (since up until that point, there was only really one serious Unix), several standardization attempts were created. The System V Interface Definition was the AT&amp;T one, Europe created the X/Open consortium of Single UNIX Specification fame, and the IEEE put out POSIX. These latter two would eventually merge and become equivalent, developed by the Austin Group, defining the only interface said to be universally interoperable on the OS level that we have to this day.</p>
<p>As of the previous release of POSIX, the Austin Group gained more control over the specification, having it be more working group oriented, and they got to work making the POSIX specification more modern. POSIX 2024 is the first release that bears the fruits of this labor, and as such, the changes made to it are particularly interesting, as they will define the direction of the specification going forwards. This is what this article is about!</p>
<p>Well, mostly. POSIX is composed of a couple of sections. Notably XBD (Base Definitions, which talk about things like what a file is, how regular expressions work, etc), XSH (System Interfaces, the C API that defines POSIX’s internals), and XCU (which defines the shell command language, and the standard utilities available for the system). There’s also XRAT, which explains the rationale of the authors, but it’s less relevant for our purposes today. XBD and XRAT are both interesting as context for XSH and XCU, but those are the real meat of the specification. This article will focus on the XCU section, in particular the utilities part of that section. If you’re more interested in the XSH section, there’s an excellent summary page by <a href="https://sortix.org/" rel="nofollow">sortix’s</a> Jonas Termansen that you can read <a href="https://sortix.org/blog/posix-2024/" rel="nofollow">here</a>.</p>
<h2 id="highlights">Highlights <a href="#highlights" rel="nofollow">#</a></h2>
<h3 id="handling-of-filenames-in-shell">Handling of Filenames in Shell <a href="#handling-of-filenames-in-shell" rel="nofollow">#</a></h3>
<p>One of the most common errors in shell scripts when working with files tends to be the presumption that the newline character (<code>\n</code>) will not be present in the filename. Consider, for example, wanting to do some processing of files in a directory, processing the most recently modified ones first, with some custom break condition. The most common (naive) way of implementing this looks like this<sup id="fnref:1"><a href="#fn:1" rel="nofollow">1</a></sup>:</p>
<pre><code><span><span>1</span><span>ls -t <span>|</span> <span>while</span> <span>read</span> -r f<span>;</span> <span>do</span>
</span></span><span><span>2</span><span>	<span># if my condition; then break; fi</span>
</span></span><span><span>3</span><span>	<span># do something with $f</span>
</span></span><span><span>4</span><span><span>done</span>
</span></span></code></pre><p>After all, <code>read(1p)</code> reads logical lines from stdin into a variable, and <code>ls(1p)</code> outputs one entry per line. The problem is that pathnames<sup id="fnref:2"><a href="#fn:2" rel="nofollow">2</a></sup> (as per section <code>3.254</code> of POSIX 2024) are just strings (meaning they can contain any bytes except the NUL character), meaning it’s incorrect to even treat it as a character string, let alone something you can put in a newline-separated form. As such, the correct solution, historically, has been to loop over the files in some other way (such as wildcards, which aren’t subject to expansion, or using <code>find(1p)</code>), then sort them, then run on the sorted datatype. This question is probably one of the most talked about in shell. POSIX 2024 addresses this issue in two ways.</p>
<h4 id="the-null-option">The Null Option <a href="#the-null-option" rel="nofollow">#</a></h4>
<p><code>find(1p)</code> now supports the <code>-print0</code> primary, which makes <code>find</code> use the NUL character as a separator. To go along with it, <code>xargs(1p)</code> now supports the <code>-0</code> argument, which reads arguments expecting them to be separated with NUL characters. Finally, for (most) other usecases, <code>read(1p)</code> now supports the <code>-d</code> (delimiter) argument, where <code>-d &#39;&#39;</code> means the NUL character is the delimiter. This is a non-ideal resolution though. Previous POSIX releases have considered <code>-print0</code> before, but never ended up adopting it because using a null terminator meant that any utility that would need to process that output would need to have a new option to parse that type of output.</p>
<p>More precisely, this approach does not resolve our original problem. <code>xargs(1p)</code> can’t sort, and therefore we still have to handle that logic separately, unless <code>sort(1p)</code> also grows this support, even after <code>read(1p)</code>. This problem continues with every other type of use-case. Importantly, it breaks the interoperability that POSIX was made to uphold.</p>
<p>Thankfully, there is the second way that they’re fixing this issue.</p>
<h4 id="the-nuclear-option">The Nuclear Option <a href="#the-nuclear-option" rel="nofollow">#</a></h4>
<p>We’ve established that, yes, pathnames can include newlines. We have not established <em>why</em> they can do that. After some deliberation, the Austin Group could not find a single use-case for newlines in pathnames besides breaking naive scripts. Wouldn’t it be nice if the naive scripts were just correct now? Ok, that might be a bit much all at once. We’re heading there though!
A bunch of C functions<sup id="fnref:3"><a href="#fn:3" rel="nofollow">3</a></sup> are now encouraged to report <code>EILSEQ</code> if the last component of a pathname to a file they are to create contains a newline (put differently, they’re to error out instead of creating a filename that contains a newline).</p>
<p>As for the utilities, the following utilities are now either encouraged to error out if they are to create a filename that contains a newline, and/or encouraged to error out if they are about to print a pathname that contains a newline in a context where newlines may be used as a separator: <code>admin(1p)</code>, <code>ar(1p)</code>, <code>awk(1p)</code>, <code>basename(1p)</code>, <code>cd(1p)</code>, <code>cksum(1p)</code>, <code>cmp(1p)</code>, <code>command(1p)</code>, <code>compress(1p)</code>, <code>cp(1p)</code>, <code>csplit(1p)</code>, <code>ctags(1p)</code>, <code>cxref(1p)</code>, <code>dd(1p)</code>, <code>df(1p)</code>, <code>diff(1p)</code>, <code>dirname(1p)</code>, <code>du(1p)</code>, <code>ed(1p)</code>, <code>ex(1p)</code>, <code>file(1p)</code>, <code>find(1p)</code>, <code>fuser(1p)</code>, <code>get(1p)</code>, <code>grep(1p)</code>, <code>hash(1p)</code>, <code>head(1p)</code>, <code>ipcs(1p)</code>, <code>link(1p)</code>, <code>ln(1p)</code>, <code>localedef(1p)</code>, <code>ls(1p)</code>, <code>m4(1p)</code>, <code>mailx(1p)</code>, <code>make(1p)</code>, <code>man(1p)</code>, <code>mkdir(1p)</code>, <code>mkfifo(1p)</code>, <code>mv(1p)</code>,<code>nm(1p)</code>, <code>patch(1p)</code>, <code>pax(1p)</code>, <code>prs(1p)</code>, <code>pws(1p)</code>, <code>rm(1p)</code>, <code>rmdel(1p)</code>, <code>sact(1p)</code>, <code>sccs(1p)</code>, <code>sh(1p)</code>, <code>sort(1p)</code>, <code>split(1p)</code>, <code>tee(1p)</code>, <code>touch(1p)</code>, <code>type(1p)</code>, <code>uncompress(1p)</code>, <code>unget(1p)</code>, <code>uniq(1p)</code>,<code>uucp(1p)</code>, <code>uudecode(1p)</code>, <code>val(1p)</code>, <code>vi(1p)</code>, <code>wc(1p)</code>, <code>what(1p)</code>, <code>yacc(1p)</code>, and <code>zcat(1p)</code>.</p>
<p>Furthermore, <code>sh(1p)</code> talks about future direction, which may require the above to be treated as errors, and <code>pr(1p)</code> has a new section talking about “problematic pathnames” (since, for its use-case, tabs and vertical tabs are also problem-causing).</p>
<p>This is a much better solution, even in its current form. Unless your threat model includes attackers targeting you in particular (which, for example, immediately excludes all “home use” scripts), you can reasonably expect people to be discouraged from creating newline-containing characters, where before it might have been perceived as a “clever hack”. You can’t rely on your system enforcing those files not exist, but this is a major step in that direction.</p>
<h4 id="tldr">TL;DR <a href="#tldr" rel="nofollow">#</a></h4>
<p>While code like <code>ls -t | while read -r f</code> isn’t strictly correct yet, it’s likely to become strictly correct eventually. It’s also much more reasonable to opt into this early, unless you’re writing software with security requirements, are deleting files based on inputs, or similar.</p>
<h3 id="modern-c">Modern C <a href="#modern-c" rel="nofollow">#</a></h3>
<p>C has come a pretty long way in the last half-century, but for most intents and purposes, we haven’t been able to really benefit from it. Did you know that since <code>c11</code> we actually have built-in unicode support via <code>&lt;uchar.h&gt;</code> (ISO/IEC TR 19769:2004)? Most modern programs can’t actually utilize this, because they target <code>c89</code> (often incorrectly called “ANSI C”) or (if you’re lucky) <code>c99</code>. Why does this happen?</p>
<p>Well, when you’re building a new C program, you must decide what version of C to target. Target something too new, and no one will be able to build it. An example of this is <a href="https://github.com/aristocratos/btop" rel="nofollow">btop++</a>, which targetted some newer C++ features (notably <code>&lt;ranges&gt;</code>) that at the time of its publishing LLVM simply did not support: <code>libc++</code> simply didn’t have them yet (at least not in a stable format available on most distributions), and you couldn’t use gcc’s <code>libstdc++</code> because its <code>&lt;ranges&gt;</code> implementation depended on concepts (which LLVM also did not have yet).</p>
<p>As such, what you do, is you look at the platforms you want your program to run on, and try to figure out what the least common denominator would be. It just so happens that for the longest time, that denominator would be <code>c89</code>. For a little while now, it’s been <code>c99</code>. As for why that is, POSIX is a large part. You see, up until POSIX 2024, POSIX required that the <code>c89</code> compiler be present on the system. If you have <code>c89</code> you’re compliant, and if you do not, you are not. Most operating systems try to be POSIX compliant, and so it becomes a typical expectation (so you don’t have to worry about not having C at all, something other languages do have to worry about). This broad presumption of availability also pushes the embedded developers to provide something along those lines as well (setting the expectation of expectations), so most microcontrollers will have a <code>c89</code> (or again, recently, <code>c99</code>) toolchain available for them.</p>
<p>In short, application authors will tend not to target something until it’s fairly common, unless there’s a disproportionate advantage for their specific use-case (such as with <code>c99</code> over <code>c89</code>). What’s fairly common is strongly influenced by what is pseudo-guaranteed by the only portable standard we have.</p>
<p>Anyway, POSIX 2024 now requires <code>c17</code>, and does not require <code>c89</code>. Furthermore, the rationale mentions that future editions will not require <code>c17</code>, but will simply require whatever C specification version is the most modern and already implemented by major toolchains. So going forward, it’ll be much easier to justify using actually modern C for your new projects, and we can expect more and more embedded tools to provide modern C versions (something we’re already seeing, especially on microcontrollers that are based on ARM or RISC-V).</p>
<h3 id="limits--cooperation">Limits &amp; Cooperation <a href="#limits--cooperation" rel="nofollow">#</a></h3>
<p>Operating systems impose limits (often arbitrary) on what runs inside of them, and your applications (and scripts, and interactive usage) may also want to impose some limits and cooperation on what you run. As such, it’s important that you be able to interact with these limits. This is what the <code>nice(1p)</code>, <code>renice(1p)</code>, and <code>ulimit(1p)</code> utilities are meant to do.</p>
<p>Unfortunately, <code>renice(1p)</code> only worked in absolutes, and <code>ulimit(1p)</code> only let you set a maximum write size for files (and didn’t differentiate between hard and soft limits), and was only available as part of the XSI extension.</p>
<p>With POSIX 2024, <code>ulimit(1p)</code> now supports reporting hard and soft limits and defines how those are used and interact. Additionally, the core image size, data segment size, open file descriptor amount, stack size, cpu time<sup id="fnref:4"><a href="#fn:4" rel="nofollow">4</a></sup>, and address space limits now exist. This means that you can now (or rather, in the near future) reasonably rely on those existing and actually make use of them in portable scripts. <code>renice(1p)</code> is also updated to support the <code>-n</code> option (just like <code>nice(1p)</code>) to change the niceness value relatively.</p>
<p>Finally, we get a new utility: <code>timeout(1p)</code>. A lot of tools over the years have added options to handle their own timeouts (<code>curl(1)</code> in particular comes to mind, having several different types of timeouts for various use-cases), but with <code>timeout(1p)</code> you don’t need those (except for the added flexibility) anymore. It even handles child processes (in several implementation defined ways) and (importantly) lets you customize the signal and send a secondary <code>SIGKILL</code> after a secondary timeout.</p>
<h3 id="makefiles">Makefiles <a href="#makefiles" rel="nofollow">#</a></h3>
<p><code>make(1p)</code> remains the default build system to this day. Or at least sort of. Most people tend to write large scripts that wrap around make for various reasons, but in the end they will tend to produce a <code>Makefile</code> (though ninja has been gaining a lot of traction). Let’s take a look at a typical example to explain what the improvements are.</p>
<p>Our use-case is simple: we have a bunch of <code>.c</code> files in <code>./</code>. We want to compile and link them together. We also have a dependency (let’s say it’s libcurl) that requires some additional <code>CFLAGS</code> and <code>LDFLAGS</code>, which we query using <code>pkg-config</code> (well, I’m going to use <code>pkgconf</code>, it’s compatible). Importantly, we’re lazy in that we don’t want to specify every <code>.c</code> file in the directory in our Makefile. We also want to be able to clean our <code>.o</code> files without resorting to something like <code>git clean -fx</code> (that might clean some temporary artifacts that we do want to keep). With GNU Make, that might look something like so:</p>
<pre><code><span><span> 1</span><span><span>SRC</span> <span>:=</span> <span>$(</span>wildcard *.c<span>)</span>
</span></span><span><span> 2</span><span><span>OBJ</span> <span>:=</span> <span>$(</span>SRC:.c<span>=</span>.o<span>)</span>
</span></span><span><span> 3</span><span>
</span></span><span><span> 4</span><span><span>CC</span> <span>?=</span> cc
</span></span><span><span> 5</span><span>
</span></span><span><span> 6</span><span><span>CFLAGS</span>  <span>?=</span> -Os -pipe
</span></span><span><span> 7</span><span><span>LDFLAGS</span> <span>?=</span> -Wl,-O2
</span></span><span><span> 8</span><span><span>LIBS</span>    <span>?=</span>
</span></span><span><span> 9</span><span>
</span></span><span><span>10</span><span><span>PKGCONF</span> <span>?=</span> pkgconf
</span></span><span><span>11</span><span>
</span></span><span><span>12</span><span><span>CURLC</span> <span>!=</span> <span>$(</span>PKGCONF<span>)</span> --cflags libcurl
</span></span><span><span>13</span><span><span>CURLL</span> <span>!=</span> <span>$(</span>PKGCONF<span>)</span> --libs   libcurl
</span></span><span><span>14</span><span>
</span></span><span><span>15</span><span><span>CFLAGS</span>  <span>:=</span> <span>$(</span>CFLAGS<span>)</span>  <span>$(</span>CURLC<span>)</span>
</span></span><span><span>16</span><span><span>LDFLAGS</span> <span>:=</span> <span>$(</span>LDFLAGS<span>)</span> <span>$(</span>CURLL<span>)</span>
</span></span><span><span>17</span><span>
</span></span><span><span>18</span><span><span>myprog</span><span>:</span> <span>$(</span><span>OBJ</span><span>)</span>
</span></span><span><span>19</span><span>	<span>$(</span>CC<span>)</span> -o <span>$@</span> <span>$(</span>LDFLAGS<span>)</span> <span>$(</span>LIBS<span>)</span> $^
</span></span><span><span>20</span><span>
</span></span><span><span>21</span><span><span>.PHONY</span><span>:</span> <span>clean</span>
</span></span><span><span>22</span><span><span>clean</span><span>:</span>
</span></span><span><span>23</span><span>	rm -f <span>$(</span>OBJ<span>)</span> myprog
</span></span></code></pre><p>This will not work on anything but GNU Make. MacOS make<sup id="fnref:5"><a href="#fn:5" rel="nofollow">5</a></sup> won’t be happy with the <code>!=</code> used for <code>CURLC</code>, while bsdmake and bmake won’t be happy with <code>$^</code>. POSIX make would be unhappy with the <code>:=</code>, <code>wildcard</code> and <code>.PHONY</code>. Similarly, if we targetted <code>bmake</code> initially, the result would not properly run on <code>gmake</code>, and so on. The various implementations are mutually incompatible in diverging ways, since the POSIX implementation lacked critical features required for writing such small (and the vast majority of Makefiles <em>should</em> be this small) Makefiles.</p>
<p>While there’s still no good solution for the <code>$(wildcard *.c)</code> portion of this<sup id="fnref:6"><a href="#fn:6" rel="nofollow">6</a></sup>, the following, annotated with comments for changes, should now work in strict POSIX compatibility<sup id="fnref:7"><a href="#fn:7" rel="nofollow">7</a></sup>:</p>
<pre><code><span><span> 1</span><span><span># .POSIX: is meant to make the Make implementation behave as though
</span></span></span><span><span> 2</span><span><span># it is standard POSIX-make, since there may be conflicts
</span></span></span><span><span> 3</span><span><span></span><span>.POSIX</span><span>:</span>
</span></span><span><span> 4</span><span><span># we use ::= here, since POSIX does not define :=.
</span></span></span><span><span> 5</span><span><span># we also strictly enumerate the sources
</span></span></span><span><span> 6</span><span><span></span><span>SRC </span><span>::</span>= <span>one</span>.<span>c</span> <span>two</span>.<span>c</span>
</span></span><span><span> 7</span><span><span>OBJ </span><span>::</span>= <span>$(</span><span>SRC</span>:.<span>c</span>=.<span>o</span><span>)</span>
</span></span><span><span> 8</span><span>
</span></span><span><span> 9</span><span><span>CC</span> <span>?=</span> cc
</span></span><span><span>10</span><span>
</span></span><span><span>11</span><span><span>CFLAGS</span>  <span>?=</span> -Os -pipe
</span></span><span><span>12</span><span><span>LDFLAGS</span> <span>?=</span> -Wl,-O2
</span></span><span><span>13</span><span><span>LIBS</span>    <span>?=</span>
</span></span><span><span>14</span><span>
</span></span><span><span>15</span><span><span>PKGCONF</span> <span>?=</span> pkgconf
</span></span><span><span>16</span><span>
</span></span><span><span>17</span><span><span>CURLC</span> <span>!=</span> <span>$(</span>PKGCONF<span>)</span> --cflags libcurl
</span></span><span><span>18</span><span><span>CURLL</span> <span>!=</span> <span>$(</span>PKGCONF<span>)</span> --libs   libcurl
</span></span><span><span>19</span><span>
</span></span><span><span>20</span><span><span># ditto re: ::=
</span></span></span><span><span>21</span><span><span></span><span>CFLAGS  </span><span>::</span>= <span>$(</span><span>CFLAGS</span><span>)</span>  <span>$(</span><span>CURLC</span><span>)</span>
</span></span><span><span>22</span><span><span>LDFLAGS </span><span>::</span>= <span>$(</span><span>LDFLAGS</span><span>)</span> <span>$(</span><span>CURLL</span><span>)</span>
</span></span><span><span>23</span><span>
</span></span><span><span>24</span><span><span>myprog</span><span>:</span> <span>$(</span><span>OBJ</span><span>)</span>
</span></span><span><span>25</span><span>	<span>$(</span>CC<span>)</span> -o <span>$@</span> <span>$(</span>LDFLAGS<span>)</span> <span>$(</span>LIBS<span>)</span> $^
</span></span><span><span>26</span><span>
</span></span><span><span>27</span><span><span>.PHONY</span><span>:</span> <span>clean</span>
</span></span><span><span>28</span><span><span>clean</span><span>:</span>
</span></span><span><span>29</span><span>	rm -f <span>$(</span>OBJ<span>)</span> myprog
</span></span></code></pre><p>That’s very few changes! Importantly, <code>gmake</code> can already handle this, meaning that by targeting this feature set you are strictly improving compatibility.</p>
<p>To be very specific, POSIX 2024 added support for the <code>$^</code> and <code>$+</code> internal macros, <code>::=</code>, <code>:::=</code>, <code>!=</code>, <code>?=</code>, and <code>+=</code> macro assignment forms, silent includes via <code>-include</code>, <code>.NOTPARALLEL</code>, <code>.PHONY</code>, and <code>.WAIT</code> special targets (of which I did not cover the parallelism ones, as those will typically be mostly useful to meta build systems), and other less important changes that will be listed out in full below.</p>
<h3 id="logging">Logging <a href="#logging" rel="nofollow">#</a></h3>
<p>Our computers have more and more cores. In early 2017 (when the previous version of the standard was being finalized), most consumer grade hardware still maxed out at 4 cores (likely with SMT). This was also the segment of the market most likely to have background batch processing done in shell (as more enterprise-grade uses tend to write in a programming language that can integrate with their numerous external APIs). As such, while background processes were certainly common, it wasn’t as much of a common expectation that one might be doing some major processing (e.g. video re-encoding) in the background while performing other tasks. Of course, right after that point, in March 2017, the first generation of AMD Ryzen CPUs dropped on the scene and put processors with as many as 16 threads into the hands of consumers at more than reasonable prices. Today, in 2024, it’s difficult to buy a new workstation cpu with fewer than 12 threads, making the abovementioned scenarios all the more common.</p>
<p>The original specification of <code>logger(1p)</code> was written with a fairly uncommon, albeit necessary, use-case in mind. Today, such use-cases are much more common, and could be even more common if logging was easier to do correctly<sup id="fnref:8"><a href="#fn:8" rel="nofollow">8</a></sup>. This original specification basically said that <code>logger(1p)</code> takes arguments like echo, but instead of outputting the text into stdout, it does so into syslog. It also means that logging the output of commands is unduly complicated.</p>
<p>In POSIX 2024, <code>logger(1p)</code> becomes a more fully-qualified command, with arguments and stdin interpretation. Notably, if there are no non-option arguments, <code>logger(1p)</code> will read the contents to log from stdin. It is also possible to ask the contents of a specific file to be logged using <code>-f</code>. Additionally, the syslog priority can be specified with <code>-p</code>, the <code>pid</code> of the logger process on each message using <code>-i</code>, and a syslog tag string using <code>-t</code>. Of additional importance, every non-empty line in the input or file shall be logged as a separate message, which means that the <code>-i</code> argument can be used to perform bulk logging where you can differentiate between failed runs.</p>
<h3 id="internationalization">Internationalization <a href="#internationalization" rel="nofollow">#</a></h3>
<p>Different people speak different languages, and it’s important to be able to translate your program for those. While you’re writing a C program or something along those lines, you can always reach for a library that you link into (such as GNU intl). While you’re writing a shell script, however, your options tend to be far more limited, since you can’t distribute it alongside the script very easily. Wouldn’t it be helpful if the standard everyone follows to various degrees actually settled on whatever interface was the most used in practice? Anyway, POSIX 2024 has adopted the <code>gettext</code> suite ala GNU, both as a system interface (<code>gettext(3p)</code> and co) and in the CLI (<code>gettext(1p)</code>, <code>ngettext(1p)</code>, <code>xgettext(1p)</code>, <code>msgmft(1p)</code>).</p>
<p>Since the target audience for this article is primarily shell people and advanced end-users, I’ll quickly go over the utilization in a shell context. <em>If you’re already familiar with the basics of GNU’s implementation, you can skip the rest of this section!</em> Translations are organized by message IDs (<code>msgid</code>) which can then be turned into arbitrary message strings (<code>msgstr</code>). These are encoded in a Portable Object file (<code>.po</code>), which you compile into a Machine Object file (<code>.mo</code>) using <code>msgfmt(1p)</code>. You then place them on your system in such a way that the <code>gettext(1p)</code> utilities will be able to find them, and the typical <code>LANG</code>/<code>LANGUAGE</code>/<code>LC_ALL</code>/<code>LC_MESSAGES</code> mechanism will get you the correct translations.</p>
<p>For the purposes of this minimal example, we’re going to write a very small program that talks about pets. The program will either print <code>you like cats</code>, <code>you like dogs</code>, or <code>you have %d pets</code> (where the <code>%d</code> will be used for <code>printf</code> output). We’ll also demonstrate how special-case plural forms work. We’ll be making a French and an English translation, and everything will be done relative to a directory of your choosing, that I will refer to as <code>$PWD</code> or <code>.</code> interchangeably. We’ll start by writing our two annotated <code>.po</code> files.</p>
<pre><code># ./en/pets.po : the filename and location is arbitrary
# empty messageid and str signals the header
# different languages deal with plural forms differently
# English only has a special case for &#34;one&#34;
# the `plural=` section is a C-like conditional expression
msgid &#34;&#34;
msgstr &#34;&#34;
&#34;Content-Type: text/plain; charset=utf-8\n&#34;
&#34;Plural-Forms: nplurals=2; plural=n != 1;\n&#34;
&#34;Language: en\n&#34;

# the IDs here are identical the messages
# since English is the source language for us
msgid &#34;you like cats&#34;
msgstr &#34;you like cats&#34;

msgid &#34;you like dogs&#34;
msgstr &#34;you like dogs&#34;

# note that if a translation isn&#39;t found
# the msgid is used as is
msgid &#34;you have a pet&#34;
msgid_plural &#34;you have %d pets&#34;
msgstr[0] &#34;you have a pet&#34;
msgstr[1] &#34;you have %d pets&#34;
</code></pre>
<pre><code># ./fr/pets.po
# we&#39;ll have a special case for 0 (aucun) and 1 (un)
# then the rest will be general case plural
msgid &#34;&#34;
msgstr &#34;&#34;
&#34;Content-Type: text/plain; charset=utf-8\n&#34;
&#34;Plural-Forms: nplurals=3; plural=(n==0)?0: (n==1)?1: 2\n&#34;

msgid &#34;you like cats&#34;
msgstr &#34;vous aimez les chats&#34;

msgid &#34;you like dogs&#34;
msgstr &#34;vous aimez les chiens&#34;

# I translated &#34;pet&#34; as &#34;little companion&#34;
# as there&#39;s no satisfactory direct translation
msgid &#34;you have a pet&#34;
msgid_plural &#34;you have %d pets&#34;
msgstr[0] &#34;vous n&#39;avez pas de petits compagnons&#34;
msgstr[1] &#34;vous avez un petit compagnon&#34;
msgstr[2] &#34;vous avez %d petits compagnons&#34;
</code></pre>
<p>These files aren’t usable as-is. We need to compile them into <code>.mo</code> files. We’ll start by compiling them in the same directory: <code>msgfmt en/pets.po -o en/pets.mo; msgfmt fr/pets.po -o fr/pets.mo</code>. We now need to place them in a location that <code>gettext(1p)</code> and co. will be able to find it in. For those specific commands there are numerous special cases, and we’ll take advantage of those via <code>TEXTDOMAINDIR</code>. Under <code>$TEXTDOMAINDIR</code>, the system will try to look for your <code>$LC_MESSAGES</code> locale followed by <code>LC_MESSAGES</code>, then your textdomain. For convenience, we’ll make some symlinks: <code>ln -s . en/LC_MESSAGES; ln -s . fr/LC_MESSAGES</code>. We can now demonstrate the messages manually!</p>
<pre><code><span><span> 1</span><span><span>export</span> <span>TEXTDOMAINDIR</span><span>=</span><span>$PWD</span>
</span></span><span><span> 2</span><span>
</span></span><span><span> 3</span><span><span># the system will access $TEXTDOMAINDIR/${locales…}/$TEXTDOMAIN.mo</span>
</span></span><span><span> 4</span><span><span># you can avoid setting $TEXTDOMAIN if you specify it on the CLI</span>
</span></span><span><span> 5</span><span><span>export</span> <span>TEXTDOMAIN</span><span>=</span>pets
</span></span><span><span> 6</span><span>
</span></span><span><span> 7</span><span><span># we can now translate simple messages!</span>
</span></span><span><span> 8</span><span><span>LC_MESSAGES</span><span>=</span>fr gettext -s <span>&#39;you like cats&#39;</span>
</span></span><span><span> 9</span><span><span># =&gt; &#34;vous aimez les chats&#34;</span>
</span></span><span><span>10</span><span><span>LC_MESSAGES</span><span>=</span>en gettext -s <span>&#39;you like dogs&#39;</span>
</span></span><span><span>11</span><span><span># =&gt; &#34;you like dogs&#34;</span>
</span></span><span><span>12</span><span><span># if you try to access a translation that doesn&#39;t exist,</span>
</span></span><span><span>13</span><span><span># it will simply print the ID, thus why it needs to be representative</span>
</span></span><span><span>14</span><span><span>LC_MESSAGES</span><span>=</span>it gettext -s <span>&#39;you like cats&#39;</span>
</span></span><span><span>15</span><span><span># =&gt; &#34;you like cats&#34;</span>
</span></span><span><span>16</span><span>
</span></span><span><span>17</span><span><span># for plural forms, you use ngettext(1p)</span>
</span></span><span><span>18</span><span><span># because we probably also want to show the real number,</span>
</span></span><span><span>19</span><span><span># ngettext can output printf-compatible format strings</span>
</span></span><span><span>20</span><span><span># so we&#39;ll write a wrapper</span>
</span></span><span><span>21</span><span><span># $1: locale; $2: msgid; $3: msgid_plural; $4: quantity</span>
</span></span><span><span>22</span><span>plural<span>()</span> <span>{</span>
</span></span><span><span>23</span><span>	<span>printf</span> <span>&#34;</span><span>$(</span><span>LC_MESSAGES</span><span>=</span><span>&#34;</span><span>$1</span><span>&#34;</span> ngettext <span>&#34;</span><span>$2</span><span>&#34;</span> <span>&#34;</span><span>$3</span><span>&#34;</span> <span>&#34;</span><span>$4</span><span>&#34;</span><span>)</span><span>\n&#34;</span> <span>&#34;</span><span>$4</span><span>&#34;</span>
</span></span><span><span>24</span><span><span>}</span>
</span></span><span><span>25</span><span><span># we can now demonstrate how the translation system adapts to plurals</span>
</span></span><span><span>26</span><span><span>for</span> i in <span>$(</span>seq <span>0</span> 2<span>)</span><span>;</span> <span>do</span>
</span></span><span><span>27</span><span>	plural en <span>&#39;you have a pet&#39;</span> <span>&#39;you have %d pets&#39;</span> <span>$i</span>
</span></span><span><span>28</span><span><span>done</span>
</span></span><span><span>29</span><span><span># =&gt; you have 0 pets</span>
</span></span><span><span>30</span><span><span># =&gt; you have a pet</span>
</span></span><span><span>31</span><span><span># =&gt; you have 2 pets</span>
</span></span><span><span>32</span><span>
</span></span><span><span>33</span><span><span># in French, we had a special case for 0, let&#39;s see it in action:</span>
</span></span><span><span>34</span><span><span>for</span> i in <span>$(</span>seq <span>0</span> 2<span>)</span><span>;</span> <span>do</span>
</span></span><span><span>35</span><span>	plural fr <span>&#39;you have a pet&#39;</span> <span>&#39;you have %d pets&#39;</span> <span>$i</span>
</span></span><span><span>36</span><span><span>done</span>
</span></span><span><span>37</span><span><span># =&gt; vous n&#39;avez pas de petits compagnons</span>
</span></span><span><span>38</span><span><span># =&gt; vous avez un petit compagnon</span>
</span></span><span><span>39</span><span><span># =&gt; vous avez 2 petits compagnons</span>
</span></span><span><span>40</span><span>
</span></span><span><span>41</span><span><span># if you try to access a translation that doesn&#39;t exist,</span>
</span></span><span><span>42</span><span><span># the system will follow typical English rules, as above:</span>
</span></span><span><span>43</span><span><span>for</span> i in <span>$(</span>seq <span>0</span> 2<span>)</span><span>;</span> <span>do</span>
</span></span><span><span>44</span><span>	plural it <span>&#39;you have a pet&#39;</span> <span>&#39;you have %d pets&#39;</span> <span>$i</span>
</span></span><span><span>45</span><span><span>done</span>
</span></span><span><span>46</span><span><span># you have 0 pets</span>
</span></span><span><span>47</span><span><span># you have a pet</span>
</span></span><span><span>48</span><span><span># you have 2 pets</span>
</span></span></code></pre><p>In short, you can now rely on GNU-style <code>gettext</code> and <code>ngettext</code> utilities to be present, and write your script with the presumption that they are there. If the translation files are not installed, the message ID will be used (intelligently, in the case of plural forms), so you don’t need to worry about the possibility of them not being installed.</p>
<h3 id="minor-changes">Minor Changes <a href="#minor-changes" rel="nofollow">#</a></h3>
<p>These are changes that are relatively minor, but I still think deserve a spotlight.</p>
<ul>
<li><code>readlink(1p)</code> and <code>realpath(1p)</code> are now part of the standard, meaning you can reliably find where a symlink points to.</li>
<li><code>rm(1p)</code> takes a <code>-d</code> argument to remove empty directories too, enabling <code>rm -d *</code> and similar use-cases. You also get <code>-v</code>.</li>
<li><code>printf(1p)</code> now supports numbered conversion specs. For example, <code>printf &#39;%2$s%1$s&#39; a b</code> will print out <code>ba</code>.</li>
<li><code>sed(1p)</code> got several interesting upgrades, though for me the highlights are being able to use EREs like in <code>grep(1p)</code> using <code>-E</code>, as well as the <code>i</code> flag on the <code>s</code> command.</li>
<li><code>test(1p)</code> now has <code>-ef</code>, <code>-nt</code>, <code>-ot</code>. String comparisons (<code>&gt;</code> and <code>&lt;</code>) are now affected by collation.</li>
<li>There is a new category of utility, notably intrinsic utilities. These are like a special built-in that can be overridden by a user function, or as a regular built-in that cannot be substituted on the PATH nor need to be possible to exec (except for kill). It’s an important change, but it’s not very relevant for anyone that’s not writing a shell interpreter.</li>
</ul>
<h2 id="changes-index">Changes Index <a href="#changes-index" rel="nofollow">#</a></h2>
<p>If you’re here early, hi! I’ve been working on this piece (I have a good chunk of an MB in plaintext notes) since the middle of the summer. Instead of letting it continue to drag on, I decided to radically reduce the scope just to the highlights, and only the XCU Utilities section. Thanks to sortix (linked above), I feel like I can stick with that latter, but I still plan to actually write out the full changes index here, as well as go over any of the Shell Command Language changes. It’s just going to take a long time still, since I’m not interested in simply dumping out the change notifications, but rather explain every change being made (albeit not as completely as I do in the highlights section). I will update this page in-place and post a second announcement when this section is complete. Don’t expect it any time soon though (probably not until early 2025).</p>



        

        
    </article>
</div></div>
  </body>
</html>
