<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.binwang.me/2023-12-14-ZFS-Profiling-on-Arch-Linux.html">Original</a>
    <h1>ZFS Profiling on Arch Linux</h1>
    
    <div id="readability-page-1" class="page"><div id="article_content">
<article id="post">
  <header>
    
    
      <p>Posted on 14 Dec 2023, tagged <code>ZFS</code><code>Linux</code><code>Profiling</code><code>dkms</code><code>kernel</code></p>
    
  </header>

  <p>I bought a new video game recently but found <code>z_rd_int</code> processes took almost all the CPU time when I was playing it. That doesn’t make much sense to me since I install games on a non compressed ZFS dataset. Even though I don’t have a powerful CPU, I don’t expect ZFS to use all of them and only reads about 60-70MiB/s from each of the NVME SSDs. To double check, I used <code>iostat -x 1</code> to confirm the iowait is very low. So disk IO is not the bottleneck.</p>

<p>Without finding any root cause from Internet, I decide to do some profiling by myself. From OpenZFS’ Github issues, people are using <a href="https://perf.wiki.kernel.org/index.php/Main_Page">perf</a> to do profiling. It is trivial enough to do it from a glance. But let <code>perf</code> showing debug symbols for ZFS spent me a lot of time. So in this article, I will document the steps to enable debug symbols for ZFS and hopefully it can help more people that facing difficulties to do it. After that, I will continue with how do I find the root cause and the solution. If you’ve seen my previous blog <a href="https://www.binwang.me/2023-09-30-A-Boring-JVM-Memory-Profiling-Story.html">A Boring JVM Memory Profiling Story</a>, this is an even more boring profiling story. But the tool set is important. Use them efficiently and hopefully all the profiling stories become boring.</p>

<h2 id="1-enable-debug-info-for-zfs">1. Enable Debug Info for ZFS</h2>

<p>On Arch Linux, if you run <code>perf top</code>, you can see kernel has debug symbols attached like this:</p>

<div><div><pre><code>2.95%  [kernel]                                        [k] entry_SYSCALL_64
</code></pre></div></div>

<p>But for some other processes like zfs ones, it only has an address like this:</p>

<div><div><pre><code>2.65%  [zfs]                                           [k] 0x00000000002990cf
</code></pre></div></div>

<p>This is because perf cannot find debug info for zfs module. Let’s enable it now.</p>

<h3 id="11-use-dkms-package">1.1 Use DKMS Package</h3>

<p>First we need to use <a href="https://wiki.archlinux.org/title/Dynamic_Kernel_Module_Support">DKMS</a> package instead a pre compiled one so that we can control the compiling behaviour when build the zfs kernel module. In Arch Linux, the package name is <code>zfs-dkms</code> either in AUR or <a href="https://github.com/archzfs/archzfs">archzfs</a> repo. Be aware packages are different from those different repos even they have the same name. Personally I like archzfs repo more since it’s more well maintained and has better dependency management.</p>

<h3 id="12-enable-debuginfo-flags">1.2 Enable debuginfo Flags</h3>

<h4 id="tldr">TL;DR:</h4>

<p>Add these three lines to <code>/etc/sysconfig/zfs</code>, (re)install the zfs dkms package and reboot.</p>

<div><div><pre><code><span>ZFS_DKMS_ENABLE_DEBUG</span><span>=</span>y
<span>ZFS_DKMS_ENABLE_DEBUGINFO</span><span>=</span>y
<span>ZFS_DKMS_DISABLE_STRIP</span><span>=</span>y
</code></pre></div></div>

<p>Decompress the installed ko file.</p>

<div><div><pre><code><span>sudo </span>unzstd /lib/modules/&lt;your kernel version&gt;/updates/dkms/zfs.ko.zst
</code></pre></div></div>

<p>Now you should be able to see zfs symbols in <code>perf top</code>.</p>

<p>Remember to cleanup the files after profiling.</p>

<p>If you care about the reason behind these changes, continue reading. Otherwise you can skip the remaining of this section.</p>

<h4 id="what-is-etcsysconfigzfs">What is <code>/etc/sysconfig/zfs</code>?</h4>

<p>The package <code>zfs-dkms</code> only installs the code that will be compiled by dkms to <code>/usr/src/zfs-&lt;zfs-version&gt;</code>. (I learned this by reading <code>PKGBUILD</code> of the aur package). Then when <code>dkms</code> commands are run, <code>dkms</code> copies the files to <code>/var/lib/dkms/zfs/&lt;zfs-version&gt;/build</code> to build it and then install the built ko files to <code>/lib/modules/&lt;your kernel version&gt;/updates/dkms</code>. So in order to build zfs module with debug symbols, we need to let dkms uses correct compile flags.</p>

<p>Under <code>/usr/src/zfs-&lt;zfs-version&gt;</code>, there is <code>dkms.conf</code> that tells DKMS how to use the source code to build and install modules. We can find some key information there:</p>

<div><div><pre><code><span>PRE_BUILD</span><span>=</span><span>&#34;configure
  --prefix=/usr
  --with-config=kernel
  --with-linux=</span><span>\$</span><span>(
    if [ -e &#34;</span><span>\$</span><span>{</span>kernel_source_dir/%build/source<span>}</span><span>&#34; ]
    then
      echo &#34;</span><span>\$</span><span>{</span>kernel_source_dir/%build/source<span>}</span><span>&#34;
    else
      echo &#34;</span><span>\$</span><span>{</span>kernel_source_dir<span>}</span><span>&#34;
    fi
  )
  --with-linux-obj=&#34;</span><span>\$</span><span>{</span>kernel_source_dir<span>}</span><span>&#34;
  </span><span>\$</span><span>(
    [[ -n </span><span>\&#34;\$</span><span>{ICP_ROOT}</span><span>\&#34;</span><span> ]] &amp;&amp; </span><span>\\</span><span>
    {
      echo --with-qat=</span><span>\&#34;\$</span><span>{ICP_ROOT}</span><span>\&#34;</span><span>
    }
  )
  </span><span>\$</span><span>(
    [[ -r </span><span>\$</span><span>{PACKAGE_CONFIG} ]] </span><span>\\</span><span>
    &amp;&amp; source </span><span>\$</span><span>{PACKAGE_CONFIG} </span><span>\\</span><span>
    &amp;&amp; shopt -q -s extglob </span><span>\\</span><span>
    &amp;&amp; </span><span>\\</span><span>
    {
      if [[ </span><span>\$</span><span>{ZFS_DKMS_ENABLE_DEBUG,,} == @(y|yes) ]]
      then
        echo --enable-debug
      fi
      if [[ </span><span>\$</span><span>{ZFS_DKMS_ENABLE_DEBUGINFO,,} == @(y|yes) ]]
      then
        echo --enable-debuginfo
      fi
    }
  )
&#34;</span>
</code></pre></div></div>

<p>There is <code>--enable-debug</code> and <code>--enable-debuginfo</code>. Run <code>./configure --help</code> shows the meaning of these two flags:</p>

<div><div><pre><code>  --enable-debug          Enable compiler and code assertions [default=no]
  --enable-debuginfo      Force generation of debuginfo [default=no]
</code></pre></div></div>

<p>So if those two flags are enabled, the zfs module should be built with debug info. The code above checks <code>ZFS_DKMS_ENABLE_DEBUG</code> and <code>ZFS_DKMS_ENABLE_DEBUGINFO</code> in file <code>${PACKAGE_CONFIG}</code>. If they are <code>y</code> or <code>yes</code>, the corresponding flags are enabled. At the beginning of <code>dkms.conf</code> we can find <code>PACKAGE_CONFIG</code> is defined as <code>/etc/sysconfig/zfs</code>.</p>

<p>However, only defining <code>ZFS_DKMS_ENABLE_DEBUG</code> and <code>ZFS_DKMS_ENABLE_DEBUGINFO</code> is not enough. I learnt it the hard way. Checking <code>dkms.conf</code> more closely, we can see these code below:</p>

<div><div><pre><code>STRIP[0]<span>=</span><span>&#34;</span><span>\$</span><span>(
  [[ -r </span><span>\$</span><span>{PACKAGE_CONFIG} ]] </span><span>\\</span><span>
  &amp;&amp; source </span><span>\$</span><span>{PACKAGE_CONFIG} </span><span>\\</span><span>
  &amp;&amp; shopt -q -s extglob </span><span>\\</span><span>
  &amp;&amp; [[ </span><span>\$</span><span>{ZFS_DKMS_DISABLE_STRIP,,} == @(y|yes) ]] </span><span>\\</span><span>
  &amp;&amp; echo -n no
)&#34;</span>
</code></pre></div></div>

<p><code>man dkms</code> shows the meaning of <code>STRIP</code>:</p>

<div><div><pre><code>STRIP[#]=
       By default strip is considered to be &#34;yes&#34;. If set to  &#34;no&#34;,  DKMS  will
       not  run strip -g against your built module to remove debug symbols from
       it.  STRIP[0] is used as the default for any unset entries in the  STRIP
       array.
</code></pre></div></div>

<p>If <code>STRIP</code> is not set to <code>no</code>, <code>dkms</code> will stripe the debug info! So we also need to set <code>ZFS_DKMS_DISABLE_STRIP</code> in <code>/etc/sysconfig/zfs</code> to <code>y</code> or <code>yes</code> so that <code>STRIP[0]</code> will be <code>no</code>.</p>

<h4 id="why-unzstd">Why unzstd?</h4>

<p>In my system, the dkms modules are compressed with zstd when installing. But it seems <code>perf</code> is not able to read the compressed module file in order to find the debug symbols, so we need to uncompress it at the same location.</p>

<h2 id="2-profiling-zfs">2. Profiling ZFS</h2>

<p><code>perf top</code> can show the CPU usage for each function in real time. But in order to analysis it better, we can record it with <code>perf record -g -p &lt;pid&gt;</code>. It should generate <code>perf.data</code> file in the current directory. Press <code>Ctrl + C</code> to stop the recording and flush the file.</p>

<p>Then use <code>sudo perf report</code> to show the report of the recording. Mine is like this (press <code>+</code> to extend a row of interest in <code>perf report</code>):</p>

<div><div><pre><code>Samples: 277K of event &#39;cycles:P&#39;, Event count (approx.): 244633155596
Children      Self  Command   Shared Object     Symbol
+   96.59%     0.01%  z_rd_int  [zfs]             [k] zio_do_crypt_uio
+   96.58%     0.00%  z_rd_int  [zfs]             [k] crypto_decrypt
+   96.57%     0.01%  z_rd_int  [zfs]             [k] aes_decrypt_atomic
+   75.53%     8.17%  z_rd_int  [zfs]             [k] aes_encrypt_block
+   49.76%     0.00%  z_rd_int  [zfs]             [k] crypto_update_uio
+   49.76%     0.00%  z_rd_int  [zfs]             [k] aes_decrypt_contiguous_blocks
+   49.76%     4.52%  z_rd_int  [zfs]             [k] ccm_mode_decrypt_contiguous_blocks
+   46.42%     2.08%  z_rd_int  [zfs]             [k] ccm_decrypt_final
+   42.15%     6.94%  z_rd_int  [zfs]             [k] aes_aesni_encrypt
-   24.72%    24.36%  z_rd_int  [zfs]             [k] kfpu_end
     24.36% ret_from_fork_asm
        ret_from_fork
        kthread
        0xffffffffc02b15eb
        zio_execute
        zio_done
        zio_pop_transforms
        zio_decrypt
        spa_do_crypt_abd
        zio_do_crypt_data
        zio_do_crypt_uio
        crypto_decrypt
      + aes_decrypt_atomic
-   21.20%    20.96%  z_rd_int  [zfs]             [k] kfpu_begin
     20.96% ret_from_fork_asm
        ret_from_fork
        kthread
        0xffffffffc02b15eb
        zio_execute
        zio_done
        zio_pop_transforms
        zio_decrypt
        spa_do_crypt_abd
        zio_do_crypt_data
        zio_do_crypt_uio
        crypto_decrypt
      + aes_decrypt_atomic
+   14.42%    14.21%  z_rd_int  [zfs]             [k] aes_encrypt_intel
+    7.36%     7.14%  z_rd_int  [zfs]             [k] aes_xor_block
+    6.31%     6.16%  z_rd_int  [zfs]             [k] aes_copy_block
+    1.27%     0.03%  z_rd_int  [zfs]             [k] arc_read_done
+    1.17%     0.02%  z_rd_int  [zfs]             [k] zio_vdev_io_done
+    1.14%     0.00%  z_rd_int  [zfs]             [k] abd_iterate_func
</code></pre></div></div>

<h2 id="3-find-root-cause">3. Find Root Cause</h2>

<p>From the profiling report, we can easily see that the CPU is mostly used on decrypting the content on ZFS. That makes some sense because decryption do need CPU power. But there is no reason it uses so much CPU at that throughput. In fact found some performance issues related encryption and did something to rule out some causes:</p>

<ol>
  <li>I made sure the AES hardware acceleration is enabled for my CPU by checking <code>lscpu | grep aes</code>.</li>
  <li>My system can decrypt and encrypt at a much higher speed (2000+ MB/s) by running <code>cryptsetup benchmark</code>.</li>
</ol>

<p>That’s why I need the profiling to confirm where the bottleneck comes from.</p>

<p>Even though the code path is related to decryption, the hotspot is at <code>kfpu_begin</code> and <code>kfpu_end</code>. I read the code and have totally no idea what they are doing. I asked ChatGPT and it explains to me that it’s saving and restoring FPU state. I don’t know if its answer is correct or not, but that at least gave me some direction to search issues. At last I found this Github issue <a href="https://github.com/openzfs/zfs/pull/9749">ICP: Improve AES-GCM performance</a>. It says exactly that there is performance issue with saving FPU state when doing encryption. And the PR improves it for AES-GCM algorithm. It states AES-CCM can benifit from similar fix but the performance improvement will not be as great. So in the discussion of the PR, they decide to change the default encryption algorithm to AES-GCM instead of AES-CCM.</p>

<p>I <a href="https://www.binwang.me/2020-01-28-Migrate-Arch-Linux-to-Zfs.html">started use zfs</a> before this PR. So I checked the encryption algorithm on my system by <code>zfs get all &lt;dataset&gt; | grep encryption</code>. And it is indeed using AES-CCM. In order to confirm it is causing performance issue, I did some benchmark on AES-CCM, AES-GCM and not encrypted datasets.</p>

<p>First, created the datasets:</p>

<div><div><pre><code><span>sudo </span>zfs create <span>-o</span> <span>encryption</span><span>=</span>aes-256-ccm <span>-o</span> <span>compression</span><span>=</span>off <span>-o</span> <span>atime</span><span>=</span>off zroot/root/ccm-test
<span>sudo </span>zfs create <span>-o</span> <span>encryption</span><span>=</span>aes-256-gcm <span>-o</span> <span>compression</span><span>=</span>off <span>-o</span> <span>atime</span><span>=</span>off zroot/root/gcm-test
<span>sudo </span>zfs create <span>-o</span> <span>encryption</span><span>=</span>off <span>-o</span> <span>compression</span><span>=</span>off <span>-o</span> <span>atime</span><span>=</span>off zroot/local_steam_unencrypt
</code></pre></div></div>

<p>Then I write a script to benchmark it:</p>

<div><div><pre><code><span>#!/bin/bash</span>

<span>set</span> <span>-e</span>

<span>function </span>print_cputime<span>()</span> <span>{</span>
	<span>pname</span><span>=</span><span>$1</span>
	<span>for </span>pid <span>in</span> <span>`</span>pgrep <span>$pname</span><span>`</span> <span>;</span> <span>do
		</span>ps <span>-p</span> <span>$pid</span> <span>-o</span> cputime,etime
	<span>done</span>
<span>}</span>


<span>function </span>benchmark <span>{</span>
	<span>test_name</span><span>=</span><span>$1</span>
	<span>test_file</span><span>=</span><span>$2</span>

	<span>file_size</span><span>=</span><span>&#34;20480&#34;</span>

	<span>echo</span> <span>&#34;### Start benchmark </span><span>$test_name</span><span>&#34;</span>

	<span>echo</span> <span>&#34;### Print z_wr_iss cpu time before the write test&#34;</span>
	print_cputime z_wr_iss
	<span>echo</span> <span>&#34;### Start write test&#34;</span>
	<span>time dd </span><span>if</span><span>=</span>/dev/random <span>of</span><span>=</span><span>$test_file</span> <span>bs</span><span>=</span>1M <span>count</span><span>=</span><span>$file_size</span> <span>oflag</span><span>=</span>direct
	<span>echo</span> <span>&#34;### Pring z_wr_iss cpu time afte the write test&#34;</span>
	print_cputime z_wr_iss

	<span>echo</span> <span>&#34;### Print z_rd_int cpu time before the read test&#34;</span>
	print_cputime z_rd_int
	<span>echo</span> <span>&#34;### Start read test&#34;</span>
	<span>time dd </span><span>if</span><span>=</span><span>$test_file</span> <span>of</span><span>=</span>/dev/null <span>bs</span><span>=</span>1M <span>count</span><span>=</span><span>$file_size</span>
	<span>echo</span> <span>&#34;### Print z_rd_int cpu time before the read test&#34;</span>
	print_cputime z_rd_int
<span>}</span>

benchmark ccm-test /ccm-test/test-file
benchmark gcm-test /gcm-test/test-file
benchmark non-encrypt-test /data/local_steam/test-file
</code></pre></div></div>

<p>My ZFS cache is set to 8GB. So I write and read files with 20GB. It uses dd to write and read a file. Before the read and write, it uses <code>ps -o cputime,etime</code> to print out CPU time and wall time used by each related ZFS processes.</p>

<p>Running this script creates lots of output. The full output can be found in the appendix at the end. Here are the key lines:</p>

<div><div><pre><code>### Start benchmark ccm-test
// ... output omitted ...
21474836480 bytes (21 GB, 20 GiB) copied, 107.307 s, 200 MB/s
// ... output omitted ...
### Start benchmark gcm-test
// ... output omitted ...
21474836480 bytes (21 GB, 20 GiB) copied, 13.7417 s, 1.6 GB/s
// ... output omitted ...
### Start benchmark non-encrypt-test
// ... output omitted ...
21474836480 bytes (21 GB, 20 GiB) copied, 9.03496 s, 2.4 GB/s
// ... output omitted ...
</code></pre></div></div>

<p>During the test, AES-CCM makes <code>z_rd_int</code> takes all CPU time as observed before. For AES-GCM, it’s much better, <code>z_rd_int</code> takes less than 50% and for non encrypted it’s less than 20%. The testing output prints the CPU time and wall time for each of the <code>z_rd_int</code> processes before and after the test. So you can count the percentage.</p>

<p>From the test result, we can see AES-CCM indeed affect read performance a lot. It’s even slower than writes. We can confirm this is the root cause for our problem.</p>

<h2 id="4-solution-and-workaround">4. Solution and Workaround</h2>

<p>The solution is obvious: just change the encryption from AES-CCM to AES-GCM. But it cannot be done without migrating the dataset to another place and then move it back. It takes time. At the mean time, I moved my Steam library to a non encrypted dataset since I have enough disk space to do the migration. It doesn’t have sensitive information. Yes it exposes the machine to <a href="https://en.wikipedia.org/wiki/Evil_maid_attack">evil maid attack</a>, but my setup on the machine doesn’t prevent it anyway. See my previous blog <a href="https://www.binwang.me/2021-09-19-Personal-ZFS-Offsite-Online-Backup-Solution.html">Personal ZFS Offsite Backup Solution</a> for more information on putting a machine into a not trusted environment.</p>

<p>I’ll do the migration from AES-CCM to AES-GCM in the future and report back how it works. Stay tuned!</p>

<h2 id="5-appendix">5. Appendix</h2>

<p>Here is the full output from the benchmark script:</p>

<div><div><pre><code>### Start benchmark ccm-test
### Print z_wr_iss cpu time before the write test
    TIME     ELAPSED
00:47:56  3-03:39:21
    TIME     ELAPSED
00:22:34  3-03:39:21
    TIME     ELAPSED
00:47:54  3-03:39:21
    TIME     ELAPSED
00:47:55  3-03:39:21
    TIME     ELAPSED
00:00:01  3-03:39:17
    TIME     ELAPSED
00:00:00  3-03:39:17
    TIME     ELAPSED
00:04:50    15:30:06
    TIME     ELAPSED
00:04:49    15:29:57
    TIME     ELAPSED
00:04:51    15:29:56
    TIME     ELAPSED
00:04:51    15:29:18
    TIME     ELAPSED
00:00:00    10:07:30
    TIME     ELAPSED
00:00:00       55:49
### Start write test
20480+0 records in
20480+0 records out
21474836480 bytes (21 GB, 20 GiB) copied, 91.4066 s, 235 MB/s

real	1m31.414s
user	0m0.059s
sys	0m53.252s
### Pring z_wr_iss cpu time afte the write test
    TIME     ELAPSED
00:49:23  3-03:40:53
    TIME     ELAPSED
00:22:34  3-03:40:53
    TIME     ELAPSED
00:49:21  3-03:40:53
    TIME     ELAPSED
00:49:22  3-03:40:53
    TIME     ELAPSED
00:00:01  3-03:40:49
    TIME     ELAPSED
00:00:00  3-03:40:49
    TIME     ELAPSED
00:04:50    15:31:38
    TIME     ELAPSED
00:04:50    15:31:28
    TIME     ELAPSED
00:04:51    15:31:28
    TIME     ELAPSED
00:04:51    15:30:50
    TIME     ELAPSED
00:00:00    10:09:01
    TIME     ELAPSED
00:00:00       57:21
### Print z_rd_int cpu time before the read test
    TIME     ELAPSED
00:24:46  3-03:40:53
    TIME     ELAPSED
00:00:02  3-03:40:49
    TIME     ELAPSED
00:01:50       06:47
    TIME     ELAPSED
00:01:49       06:47
### Start read test
20480+0 records in
20480+0 records out
21474836480 bytes (21 GB, 20 GiB) copied, 107.307 s, 200 MB/s

real	1m47.372s
user	0m0.060s
sys	0m8.091s
### Print z_rd_int cpu time after the read test
    TIME     ELAPSED
00:26:24  3-03:42:41
    TIME     ELAPSED
00:00:02  3-03:42:37
    TIME     ELAPSED
00:03:28       08:34
    TIME     ELAPSED
00:03:27       08:34
### Start benchmark gcm-test
### Print z_wr_iss cpu time before the write test
    TIME     ELAPSED
00:49:35  3-03:42:41
    TIME     ELAPSED
00:22:34  3-03:42:41
    TIME     ELAPSED
00:49:33  3-03:42:41
    TIME     ELAPSED
00:49:33  3-03:42:41
    TIME     ELAPSED
00:00:01  3-03:42:37
    TIME     ELAPSED
00:00:00  3-03:42:37
    TIME     ELAPSED
00:04:50    15:33:26
    TIME     ELAPSED
00:04:50    15:33:16
    TIME     ELAPSED
00:04:51    15:33:16
    TIME     ELAPSED
00:04:51    15:32:38
    TIME     ELAPSED
00:00:00    10:10:49
    TIME     ELAPSED
00:00:00       59:08
### Start write test
20480+0 records in
20480+0 records out
21474836480 bytes (21 GB, 20 GiB) copied, 56.9529 s, 377 MB/s

real	0m56.960s
user	0m0.045s
sys	0m53.566s
### Pring z_wr_iss cpu time afte the write test
    TIME     ELAPSED
00:49:42  3-03:43:38
    TIME     ELAPSED
00:22:35  3-03:43:38
    TIME     ELAPSED
00:49:39  3-03:43:38
    TIME     ELAPSED
00:49:39  3-03:43:38
    TIME     ELAPSED
00:00:01  3-03:43:34
    TIME     ELAPSED
00:00:00  3-03:43:34
    TIME     ELAPSED
00:04:51    15:34:23
    TIME     ELAPSED
00:04:50    15:34:14
    TIME     ELAPSED
00:04:52    15:34:13
    TIME     ELAPSED
00:04:52    15:33:35
    TIME     ELAPSED
00:00:00    10:11:46
    TIME     ELAPSED
00:00:00    01:00:06
### Print z_rd_int cpu time before the read test
    TIME     ELAPSED
00:26:24  3-03:43:38
    TIME     ELAPSED
00:00:02  3-03:43:34
    TIME     ELAPSED
00:00:00       00:05
    TIME     ELAPSED
00:00:00       00:05
### Start read test
20480+0 records in
20480+0 records out
21474836480 bytes (21 GB, 20 GiB) copied, 13.7417 s, 1.6 GB/s

real	0m13.743s
user	0m0.071s
sys	0m11.215s
### Print z_rd_int cpu time after the read test
    TIME     ELAPSED
00:26:31  3-03:43:52
    TIME     ELAPSED
00:00:02  3-03:43:48
    TIME     ELAPSED
00:00:07       00:19
    TIME     ELAPSED
00:00:07       00:19
### Start benchmark non-encrypt-test
### Print z_wr_iss cpu time before the write test
    TIME     ELAPSED
00:49:42  3-03:43:52
    TIME     ELAPSED
00:22:35  3-03:43:52
    TIME     ELAPSED
00:49:40  3-03:43:52
    TIME     ELAPSED
00:49:39  3-03:43:52
    TIME     ELAPSED
00:00:01  3-03:43:48
    TIME     ELAPSED
00:00:00  3-03:43:48
    TIME     ELAPSED
00:04:51    15:34:37
    TIME     ELAPSED
00:04:50    15:34:28
    TIME     ELAPSED
00:04:52    15:34:28
    TIME     ELAPSED
00:04:52    15:33:49
    TIME     ELAPSED
00:00:00    10:12:01
    TIME     ELAPSED
00:00:00    01:00:20
### Start write test
20480+0 records in
20480+0 records out
21474836480 bytes (21 GB, 20 GiB) copied, 56.0508 s, 383 MB/s

real	0m56.052s
user	0m0.042s
sys	0m53.060s
### Pring z_wr_iss cpu time afte the write test
    TIME     ELAPSED
00:49:46  3-03:44:49
    TIME     ELAPSED
00:22:35  3-03:44:49
    TIME     ELAPSED
00:49:44  3-03:44:49
    TIME     ELAPSED
00:49:43  3-03:44:49
    TIME     ELAPSED
00:00:01  3-03:44:44
    TIME     ELAPSED
00:00:00  3-03:44:44
    TIME     ELAPSED
00:04:51    15:35:33
    TIME     ELAPSED
00:04:50    15:35:24
    TIME     ELAPSED
00:04:52    15:35:24
    TIME     ELAPSED
00:04:52    15:34:46
    TIME     ELAPSED
00:00:00    10:12:57
    TIME     ELAPSED
00:00:00    01:01:16
### Print z_rd_int cpu time before the read test
    TIME     ELAPSED
00:26:31  3-03:44:49
    TIME     ELAPSED
00:00:02  3-03:44:45
    TIME     ELAPSED
00:00:07       01:16
    TIME     ELAPSED
00:00:07       01:16
### Start read test
20480+0 records in
20480+0 records out
21474836480 bytes (21 GB, 20 GiB) copied, 9.03496 s, 2.4 GB/s

real	0m9.036s
user	0m0.032s
sys	0m8.207s
### Print z_rd_int cpu time after the read test
    TIME     ELAPSED
00:26:33  3-03:44:58
    TIME     ELAPSED
00:00:02  3-03:44:54
    TIME     ELAPSED
00:00:09       01:25
    TIME     ELAPSED
00:00:09       01:25
</code></pre></div></div>

</article>







<!-- MathJax -->




</div></div>
  </body>
</html>
