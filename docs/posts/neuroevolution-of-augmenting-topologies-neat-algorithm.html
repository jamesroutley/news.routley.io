<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://en.wikipedia.org/wiki/Neuroevolution_of_augmenting_topologies">Original</a>
    <h1>Neuroevolution of augmenting topologies (NEAT algorithm)</h1>
    
    <div id="readability-page-1" class="page"><div>
							

						<p>From Wikipedia, the free encyclopedia</p>
					</div><div id="mw-content-text"><div lang="en" dir="ltr">
<p><b>NeuroEvolution of Augmenting Topologies</b> (<b>NEAT</b>) is a <a href="https://en.wikipedia.org/wiki/Genetic_algorithm" title="Genetic algorithm">genetic algorithm</a> (GA) for the generation of evolving <a href="https://en.wikipedia.org/wiki/Artificial_neural_network" title="Artificial neural network">artificial neural networks</a> (a <a href="https://en.wikipedia.org/wiki/Neuroevolution" title="Neuroevolution">neuroevolution</a> technique) developed by <a href="https://en.wikipedia.org/wiki/Kenneth_Stanley" title="Kenneth Stanley">Kenneth Stanley</a> and <a href="https://en.wikipedia.org/wiki/Risto_Miikkulainen" title="Risto Miikkulainen">Risto Miikkulainen</a> in 2002 while at <a href="https://en.wikipedia.org/wiki/The_University_of_Texas_at_Austin" title="The University of Texas at Austin">The University of Texas at Austin</a>. It alters both the weighting parameters and structures of networks, attempting to find a balance between the fitness of evolved solutions and their diversity. It is based on applying three key techniques: tracking genes with history markers to allow crossover among topologies, applying speciation (the evolution of species) to preserve innovations, and developing topologies incrementally from simple initial structures (&#34;complexifying&#34;).
</p>
<meta property="mw:PageProp/toc"/>

<p>On simple control tasks, the NEAT algorithm often arrives at effective networks more quickly than other contemporary neuro-evolutionary techniques and <a href="https://en.wikipedia.org/wiki/Reinforcement_learning" title="Reinforcement learning">reinforcement learning</a> methods, as of 2006.<sup id="cite_ref-stanley2002_1-0"><a href="#cite_note-stanley2002-1"><span>[</span>1<span>]</span></a></sup><sup id="cite_ref-taylor2006_2-0"><a href="#cite_note-taylor2006-2"><span>[</span>2<span>]</span></a></sup>
</p>

<p>Traditionally, a neural network topology is chosen by a human experimenter, and effective connection weight values are learned through a training procedure. This yields a situation whereby a trial and error process may be necessary in order to determine an appropriate topology. NEAT is an example of a topology and weight evolving artificial neural network (TWEANN) which attempts to simultaneously learn weight values and an appropriate topology for a neural network.
</p><p>In order to encode the network into a phenotype for the GA, NEAT uses a direct encoding scheme which means every connection and neuron is explicitly represented. This is in contrast to indirect encoding schemes which define rules that allow the network to be constructed without explicitly representing every connection and neuron, allowing for more compact representation.
</p><p>The NEAT approach begins with a <a href="https://en.wikipedia.org/wiki/Perceptron" title="Perceptron">perceptron</a>-like feed-forward network of only input neurons and output neurons. As evolution progresses through discrete steps, the complexity of the network&#39;s topology may grow, either by inserting a new neuron into a connection path, or by creating a new connection between (formerly unconnected) neurons.
</p>
<div><h3 id="Competing_conventions">Competing conventions</h3><p><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Neuroevolution_of_augmenting_topologies&amp;action=edit&amp;section=3" title="Edit section: Competing conventions"><span>edit</span></a><span>]</span></span></p></div>
<p>The competing conventions problem arises when there is more than one way of representing information in a phenotype. For example, if a genome contains neurons <i>A</i>, <i>B</i> and <i>C</i> and is represented by [A B C], if this genome is crossed with an identical genome (in terms of functionality) but ordered [C B A] crossover will yield children that are missing information ([A B A] or [C B C]), in fact 1/3 of the information has been lost in this example. NEAT solves this problem by tracking the history of genes by the use of a global innovation number which increases as new genes are added. When adding a new gene the global innovation number is incremented and assigned to that gene. Thus the higher the number the more recently the gene was added. For a particular generation if an identical mutation occurs in more than one genome they are both given the same number, beyond that however the mutation number will remain unchanged indefinitely.
</p><p>These innovation numbers allow NEAT to match up genes which can be crossed with each other.<sup id="cite_ref-stanley2002_1-1"><a href="#cite_note-stanley2002-1"><span>[</span>1<span>]</span></a></sup>
</p>

<p>The original implementation by Ken Stanley is published under the <a href="https://en.wikipedia.org/wiki/GNU_General_Public_License" title="GNU General Public License">GPL</a>. It integrates with <a href="https://en.wikipedia.org/wiki/GNU_Guile" title="GNU Guile">Guile</a>, a GNU <a href="https://en.wikipedia.org/wiki/Scheme_(programming_language)" title="Scheme (programming language)">scheme</a> interpreter. This implementation of NEAT is considered the conventional basic starting point for implementations of the NEAT algorithm.
</p>


<p>In 2003, Stanley devised an extension to NEAT that allows evolution to occur in real time rather than through the iteration of generations as used by most genetic algorithms. The basic idea is to put the population under constant evaluation with a &#34;lifetime&#34; timer on each individual in the population. When a network&#39;s timer expires, its current fitness measure is examined to see whether it falls near the bottom of the population, and if so, it is discarded and replaced by a new network bred from two high-fitness parents. A timer is set for the new network and it is placed in the population to participate in the ongoing evaluations.
</p><p>The first application of rtNEAT is a video game called Neuro-Evolving Robotic Operatives, or NERO. In the first phase of the game, individual players deploy robots in a &#39;sandbox&#39; and train them to some desired tactical doctrine. Once a collection of robots has been trained, a second phase of play allows players to pit their robots in a battle against robots trained by some other player, to see how well their training regimens prepared their robots for battle.
</p>

<p>An extension of Ken Stanley&#39;s NEAT, developed by Colin Green, adds periodic pruning of the network topologies of candidate solutions during the evolution process. This addition addressed concern that unbounded automated growth would generate unnecessary structure.
</p>


<p><a href="https://en.wikipedia.org/wiki/HyperNEAT" title="HyperNEAT">HyperNEAT</a> is specialized to evolve large scale structures. It was originally based on the <a href="https://en.wikipedia.org/wiki/CPPN" title="CPPN">CPPN</a> theory and is an active field of research.
</p>

<p>Content-Generating NEAT (cgNEAT) evolves custom video game content based on user preferences. The first video game to implement cgNEAT is <a href="https://en.wikipedia.org/wiki/Galactic_Arms_Race" title="Galactic Arms Race">Galactic Arms Race</a>, a space-shooter game in which unique particle system weapons are evolved based on player usage statistics.<sup id="cite_ref-hastings2009_3-0"><a href="#cite_note-hastings2009-3"><span>[</span>3<span>]</span></a></sup> Each particle system weapon in the game is controlled by an evolved <a href="https://en.wikipedia.org/wiki/CPPN" title="CPPN">CPPN</a>, similarly to the evolution technique in the <a href="https://en.wikipedia.org/wiki/NEAT_Particles" title="NEAT Particles">NEAT Particles</a> interactive art program.
</p>

<p>odNEAT is an online and decentralized version of NEAT designed for multi-robot systems.<sup id="cite_ref-4"><a href="#cite_note-4"><span>[</span>4<span>]</span></a></sup>  odNEAT is executed onboard robots themselves during task execution to continuously optimize the parameters and the topology of the artificial neural network-based controllers. In this way, robots executing odNEAT have the potential to adapt to changing conditions and learn new behaviors as they carry out their tasks. The online evolutionary process is implemented according to a physically distributed island model. Each robot optimizes an internal population of candidate solutions (intra-island variation), and two or more robots exchange candidate solutions when they meet (inter-island migration). In this way, each robot is potentially self-sufficient and the evolutionary process capitalizes on the exchange of controllers between multiple robots for faster synthesis of effective controllers.
</p>

<ul><li><a href="https://en.wikipedia.org/wiki/Evolutionary_acquisition_of_neural_topologies" title="Evolutionary acquisition of neural topologies">Evolutionary acquisition of neural topologies</a></li></ul>

<div>
<div><ol>
<li id="cite_note-stanley2002-1"><span>^ <a href="#cite_ref-stanley2002_1-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-stanley2002_1-1"><sup><i><b>b</b></i></sup></a></span> <span>Kenneth O. Stanley and Risto Miikkulainen (2002). &#34;Evolving Neural Networks Through Augmenting Topologies&#34;. Evolutionary Computation 10 (2): 99-127</span>
</li>
<li id="cite_note-taylor2006-2"><span><b><a href="#cite_ref-taylor2006_2-0">^</a></b></span> <span>Matthew E. Taylor, Shimon Whiteson, and Peter Stone (2006). &#34;Comparing Evolutionary and Temporal Difference Methods in a Reinforcement Learning Domain&#34;. GECCO 2006: Proceedings of the Genetic and Evolutionary Computation Conference.</span>
</li>
<li id="cite_note-hastings2009-3"><span><b><a href="#cite_ref-hastings2009_3-0">^</a></b></span> <span>Erin J. Hastings, Ratan K. Guha, and Kenneth O. Stanley (2009). &#34;Automatic Content Generation in the Galactic Arms Race Video Game &#34;. IEEE Transactions on Computational Intelligence and AI in Games, volume 4, number 1, pages 245-263, New York: IEEE Press, 2009.</span>
</li>
<li id="cite_note-4"><span><b><a href="#cite_ref-4">^</a></b></span> <span><cite id="CITEREFSilvaUrbanoCorreiaChristensen2015">Silva, Fernando; Urbano, Paulo; Correia, Luís; Christensen, Anders Lyhne (2015-09-15). &#34;odNEAT: An Algorithm for Decentralised Online Evolution of Robotic Controllers&#34;. <i>Evolutionary Computation</i>. <b>23</b> (3): 421–449. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1162%2Fevco_a_00141">10.1162/evco_a_00141</a>. <a href="https://en.wikipedia.org/wiki/Hdl_(identifier)" title="Hdl (identifier)">hdl</a>:<span title="Freely accessible"><a rel="nofollow" href="https://hdl.handle.net/10071%2F10504">10071/10504</a></span>. <a href="https://en.wikipedia.org/wiki/PMID_(identifier)" title="PMID (identifier)">PMID</a> <a rel="nofollow" href="https://pubmed.ncbi.nlm.nih.gov/25478664">25478664</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" title="S2CID (identifier)">S2CID</a> <a rel="nofollow" href="https://api.semanticscholar.org/CorpusID:20815070">20815070</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Evolutionary+Computation&amp;rft.atitle=odNEAT%3A+An+Algorithm+for+Decentralised+Online+Evolution+of+Robotic+Controllers&amp;rft.volume=23&amp;rft.issue=3&amp;rft.pages=421-449&amp;rft.date=2015-09-15&amp;rft_id=info%3Ahdl%2F10071%2F10504&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A20815070%23id-name%3DS2CID&amp;rft_id=info%3Apmid%2F25478664&amp;rft_id=info%3Adoi%2F10.1162%2Fevco_a_00141&amp;rft.aulast=Silva&amp;rft.aufirst=Fernando&amp;rft.au=Urbano%2C+Paulo&amp;rft.au=Correia%2C+Lu%C3%ADs&amp;rft.au=Christensen%2C+Anders+Lyhne&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3ANeuroevolution+of+augmenting+topologies"></span></span>
</li>
</ol></div></div>



<ul><li>Stanley&#39;s <a rel="nofollow" href="http://nn.cs.utexas.edu/soft-view.php?SoftID=4">original</a>, <a rel="nofollow" href="https://github.com/matheust3/mtNEAT">mtNEAT</a> and <a rel="nofollow" href="http://www.cs.utexas.edu/users/nn/keyword?rtneat">rtNEAT</a> for <a href="https://en.wikipedia.org/wiki/C%2B%2B" title="C++">C++</a></li>
<li><a rel="nofollow" href="https://cs.gmu.edu/~eclab/projects/ecj/">ECJ</a>, <a rel="nofollow" href="http://nn.cs.utexas.edu/soft-view.php?SoftID=5">JNEAT</a>, <a rel="nofollow" href="http://neat4j.sourceforge.net/">NEAT 4J</a>, <a rel="nofollow" href="http://anji.sourceforge.net/">ANJI</a> for <a href="https://en.wikipedia.org/wiki/Java_(programming_language)" title="Java (programming language)">Java</a></li>
<li><a rel="nofollow" href="https://sharpneat.sourceforge.io/">SharpNEAT</a> for <a href="https://en.wikipedia.org/wiki/C_Sharp_(programming_language)" title="C Sharp (programming language)">C#</a></li>
<li><a rel="nofollow" href="http://multineat.com/features.html">MultiNEAT</a> (<a rel="nofollow" href="https://web.archive.org/web/20210515000059/http://multineat.com/features.html">MultiNEAT</a> at the <a href="https://en.wikipedia.org/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a> (archived 2021-05-15)) and <a rel="nofollow" href="https://github.com/matheust3/mtNEAT">mtNEAT</a> for <a href="https://en.wikipedia.org/wiki/C%2B%2B" title="C++">C++</a> and <a href="https://en.wikipedia.org/wiki/Python_(programming_language)" title="Python (programming language)">Python</a></li>
<li><a rel="nofollow" href="https://github.com/CodeReclaimers/neat-python">neat-python</a> for <a href="https://en.wikipedia.org/wiki/Python_(programming_language)" title="Python (programming language)">Python</a></li>
<li><a rel="nofollow" href="https://neuralfit.net/">NeuralFit</a> (not an exact implementation) and <a rel="nofollow" href="https://pypi.python.org/pypi/neat-python/">neat-python</a> for <a href="https://en.wikipedia.org/wiki/Python_(programming_language)" title="Python (programming language)">Python</a></li>
<li><a href="https://en.wikipedia.org/wiki/Encog" title="Encog">Encog</a> for <a href="https://en.wikipedia.org/wiki/Java_(programming_language)" title="Java (programming language)">Java</a> and <a href="https://en.wikipedia.org/wiki/C_Sharp_(programming_language)" title="C Sharp (programming language)">C#</a></li>
<li><a rel="nofollow" href="https://github.com/noio/peas">peas</a> for <a href="https://en.wikipedia.org/wiki/Python_(programming_language)" title="Python (programming language)">Python</a></li>
<li><a rel="nofollow" href="http://rubyneat.com">RubyNEAT</a> for <a href="https://en.wikipedia.org/wiki/Ruby_(programming_language)" title="Ruby (programming language)">Ruby</a></li>
<li><a rel="nofollow" href="https://github.com/OptimusLime/neatjs">neatjs</a> for <a href="https://en.wikipedia.org/wiki/Javascript_(programming_language)" title="Javascript (programming language)">Javascript</a></li>
<li><a rel="nofollow" href="https://github.com/wagenaartje/neataptic">Neataptic</a> for <a href="https://en.wikipedia.org/wiki/Javascript_(programming_language)" title="Javascript (programming language)">Javascript</a> (not an exact implementation)</li>
<li><a rel="nofollow" href="https://gitlab.com/onnoowl/Neat-Ex">Neat-Ex</a> for <a href="https://en.wikipedia.org/wiki/Elixir_(programming_language)" title="Elixir (programming language)">Elixir</a></li>
<li><a rel="nofollow" href="https://github.com/BiagioFesta/EvolutionNet">EvolutionNet</a> for <a href="https://en.wikipedia.org/wiki/C%2B%2B" title="C++">C++</a></li>
<li><a rel="nofollow" href="https://github.com/yaricom/goNEAT">goNEAT</a> for <a href="https://en.wikipedia.org/wiki/Go_(programming_language)" title="Go (programming language)">Go (programming language)</a></li></ul>

<ul><li><a rel="nofollow" href="http://www.cs.ucf.edu/~kstanley/neat.html">NEAT Homepage</a> (<a rel="nofollow" href="https://web.archive.org/web/20231205130538/http://www.cs.ucf.edu/~kstanley/neat.html">NEAT Homepage</a> at the <a href="https://en.wikipedia.org/wiki/Wayback_Machine" title="Wayback Machine">Wayback Machine</a> (archived 2023-12-05))</li>
<li><a rel="nofollow" href="http://eplex.cs.ucf.edu">&#34;Evolutionary Complexity Research Group at UCF&#34;</a> - Ken Stanley&#39;s current research group</li>
<li><a rel="nofollow" href="http://nerogame.org/">NERO: Neuro-Evolving Robotic Operatives</a> - an example application of rtNEAT</li>
<li><a rel="nofollow" href="https://dl.acm.org/doi/10.1145/1810136.1810137">GAR: Galactic Arms Race</a> - an example application of cgNEAT</li>
<li><a rel="nofollow" href="http://picbreeder.org/">&#34;PicBreeder.org&#34;</a> - Online, collaborative art generated by CPPNs evolved with NEAT.</li>
<li><a rel="nofollow" href="http://EndlessForms.com/">&#34;EndlessForms.com&#34;</a> - A 3D version of Picbreeder, where you interactively evolve 3D objects that are encoded with CPPNs and evolved with NEAT.</li>
<li><a rel="nofollow" href="http://beacon-center.org/blog/2012/08/13/evolution-101-neuroevolution/">BEACON Blog: What is neuroevolution?</a></li>
<li><a rel="nofollow" href="https://www.youtube.com/watch?v=qv6UVOQ0F44">MarI/O - Machine Learning for Video Games</a>, a <a href="https://en.wikipedia.org/wiki/YouTube" title="YouTube">YouTube</a> video demonstrating an implementation of NEAT learning to play <i><a href="https://en.wikipedia.org/wiki/Super_Mario_World" title="Super Mario World">Super Mario World</a></i></li>
<li><a rel="nofollow" href="http://gekkoquant.com/2016/03/13/evolving-neural-networks-through-augmenting-topologies-part-1-of-4/">&#34;GekkoQuant.com&#34;</a> - A visual tutorial series on NEAT, including solving the classic pole balancing problem using NEAT in R</li>
<li><a rel="nofollow" href="https://www.engadget.com/2015/06/17/super-mario-world-self-learning-ai/">&#34;Artificial intelligence learns Mario level in just 34 attempts</a> NEAT explained via MarI/O program</li></ul>
<!-- 
NewPP limit report
Parsed by mw‐api‐ext.eqiad.main‐56b95b6779‐7knpb
Cached time: 20241204141100
Cache expiry: 2592000
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.215 seconds
Real time usage: 0.294 seconds
Preprocessor visited node count: 694/1000000
Post‐expand include size: 22265/2097152 bytes
Template argument size: 714/2097152 bytes
Highest expansion depth: 8/100
Expensive parser function count: 2/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 23745/5000000 bytes
Lua time usage: 0.127/10.000 seconds
Lua memory usage: 4839332/52428800 bytes
Number of Wikibase entities loaded: 0/400
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  261.373      1 -total
 41.22%  107.730      8 Template:Cite_journal
 35.43%   92.606      1 Template:Short_description
 34.62%   90.486      1 Template:Reflist
 16.42%   42.927      2 Template:Pagetype
 13.14%   34.353      3 Template:Main_other
 11.34%   29.629      1 Template:SDcat
  7.79%   20.361      1 Template:Main
  4.17%   10.897      2 Template:Webarchive
  3.23%    8.454      1 Template:Refbegin
-->

<!-- Saved in parser cache with key enwiki:pcache:344922:|#|:idhash:canonical and timestamp 20241204141100 and revision id 1261143590. Rendering was triggered because: api-parse
 -->
</div><!--esi <esi:include src="/esitest-fa8a495983347898/content" /> -->
</div></div>
  </body>
</html>
