<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://lspace.swyx.io/p/agi-hard">Original</a>
    <h1>What Is AGI-Hard</h1>
    
    <div id="readability-page-1" class="page"><div><div><article><div class=""><div><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F12287bf7-b92d-449a-8f07-34893610d83f_756x567.jpeg" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F12287bf7-b92d-449a-8f07-34893610d83f_756x567.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F12287bf7-b92d-449a-8f07-34893610d83f_756x567.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F12287bf7-b92d-449a-8f07-34893610d83f_756x567.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F12287bf7-b92d-449a-8f07-34893610d83f_756x567.jpeg 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F12287bf7-b92d-449a-8f07-34893610d83f_756x567.jpeg" width="727" height="545.25" data-attrs="{&#34;src&#34;:&#34;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/12287bf7-b92d-449a-8f07-34893610d83f_756x567.jpeg&#34;,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:567,&#34;width&#34;:756,&#34;resizeWidth&#34;:727,&#34;bytes&#34;:96958,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/jpeg&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:false,&#34;internalRedirect&#34;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F12287bf7-b92d-449a-8f07-34893610d83f_756x567.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F12287bf7-b92d-449a-8f07-34893610d83f_756x567.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F12287bf7-b92d-449a-8f07-34893610d83f_756x567.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F12287bf7-b92d-449a-8f07-34893610d83f_756x567.jpeg 1456w" sizes="100vw"/></picture></div></a><figcaption>After every new AI breakthrough</figcaption></figure></div><p><span>The late Larry Tesler is </span><a href="https://www.thinkautomation.com/bots-and-ai/teslers-theorem-and-the-problem-of-defining-ai/" rel="">often quoted</a><span> as saying that</span></p><blockquote><p> “Artificial intelligence is whatever hasn’t been done yet.”</p></blockquote><p><span>There’s a very real problem in writing about AI, in that it actually does not have a precise, commonly accepted definition. The scope of AI is essentially unbounded, going from “</span><strong><a href="https://twitter.com/ken_wheeler/status/1574207221470302208" rel="">A</a></strong><a href="https://twitter.com/ken_wheeler/status/1574207221470302208" rel=""> lot of </a><strong><a href="https://twitter.com/ken_wheeler/status/1574207221470302208" rel="">I</a></strong><a href="https://twitter.com/ken_wheeler/status/1574207221470302208" rel="">fs</a><span>” to transcription to translation to computer vision to prediction, to the currently hyped generative use cases, to fictional sentient beings both </span><a href="https://en.wikipedia.org/wiki/Her_(film)" rel="">digital</a><span> and </span><a href="https://en.wikipedia.org/wiki/Ex_Machina_(film)" rel="">physical</a><span>. </span></p><p><span>This makes serious debate about productizing AI difficult, because when you can just handwave at anything and say “with enough data this will get solved”</span><a id="footnote-anchor-1-78814824" href="https://lspace.swyx.io/p/agi-hard#footnote-1-78814824" rel="">1</a><span>, </span><strong>it is hard to distinguish talking head/futurist/alarmist bullshit from the dreams of serious builders who are making unimaginable, but real, advances</strong><span>. </span></p><p><a href="https://en.wikipedia.org/wiki/Brandolini%27s_law" rel="">Brandolini’s law</a><span> guarantees that there will be more of the former than the latter, yet this problem of distinguishing the “adjacent possible” from the “outright science fiction” is the most immediate need of investors and founders.</span></p><p><span>This was my inherent discomfort with rejecting/considering out of hand </span><a href="https://twitter.com/swyx/status/1574109181015199744?s=20&amp;t=OfhXztT2io4dNnvoIdplXQ" rel="">the responses to my AI Red Wedding piece</a><span>, because I would be forced to articulate the reasons why I think </span><a href="https://twitter.com/floydophone/status/1574113923082731521?s=20&amp;t=OfhXztT2io4dNnvoIdplXQ" rel="">paralegal</a><span> work is more vulnerable than</span><a href="https://twitter.com/sadsadpanini/status/1574363416982159360?s=20&amp;t=OfhXztT2io4dNnvoIdplXQ" rel=""> infographics</a><span>, or </span><a href="https://twitter.com/swyx/status/1574229654902382592?s=20&amp;t=OfhXztT2io4dNnvoIdplXQ" rel="">why programmers have less to worry from Codex than transcribers have to worry about Whisper</a><a id="footnote-anchor-2-78814824" href="https://lspace.swyx.io/p/agi-hard#footnote-2-78814824" rel="">2</a><span>. Elon is </span><a href="https://futurism.com/the-byte/tesla-summon-prediction" rel="">repeatedly wrong</a><span> about full self driving, and now Emad is saying visual presentations like Powerpoint will be “</span><a href="https://docs.google.com/document/d/15yWcJ-EUM0f1nfxg4EK5Ef-ayN-F_nq7GV85PFwEU-g/edit?usp=sharing" rel="">solved in the next couple of years</a><span>”. </span></p><p><strong>What are the driving factors behind the “AI vulnerability factor” of each industry?</strong><span> If we were forced to choose, is it more profitable/possible to </span><a href="https://lspace.swyx.io/p/eigenquestions-for-the-ai-red-wedding#%C2%A7moravecs-paradox-and-superhuman-ai-capabilities" rel="">replace the low skilled or augment the high skilled</a><span>?</span></p><p><span>I think this is the sort of debate that makes good podcast fodder but ultimately the sheer diversity of human industry means that it is very hard to do top down analysis. Who would have guessed that the first casualty of Stable Diffusion would </span><em><strong>not</strong></em><span> be Stock Photography companies, who are </span><a href="https://interestingengineering.com/innovation/shutterstock-collaborates-with-openai-to-start-selling-ai-generated-art" rel="">simply building it into their offerings</a><span>, and instead </span><a href="https://twitter.com/levelsio/status/1584946335782174720" rel="">the 3D virtual staging industry</a><span>? Even for those with existing “AI enabled” solutions, the future is here but not evenly distributed, as </span><a href="https://twitter.com/catherinesjkim/status/1574172810296979458?s=20&amp;t=OfhXztT2io4dNnvoIdplXQ" rel="">this reply about Brex/Ramp demonstrates</a><span>.</span></p><p><span>The solution to stopping the debate comes (</span><em>here is the most 2022 sentence I have ever typed</em><span>) in </span><a href="https://twitter.com/tszzl/status/1575173284441731072?s=20&amp;t=OfhXztT2io4dNnvoIdplXQ" rel="">an exchange</a><span> between roon and Grimes (yes, Elon’s partner Grimes) on self driving:</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fee3dc3c0-4206-4a80-9a1d-207e3467933d_1220x1628.png" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fee3dc3c0-4206-4a80-9a1d-207e3467933d_1220x1628.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fee3dc3c0-4206-4a80-9a1d-207e3467933d_1220x1628.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fee3dc3c0-4206-4a80-9a1d-207e3467933d_1220x1628.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fee3dc3c0-4206-4a80-9a1d-207e3467933d_1220x1628.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fee3dc3c0-4206-4a80-9a1d-207e3467933d_1220x1628.png" width="1220" height="1628" data-attrs="{&#34;src&#34;:&#34;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/ee3dc3c0-4206-4a80-9a1d-207e3467933d_1220x1628.png&#34;,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:1628,&#34;width&#34;:1220,&#34;resizeWidth&#34;:null,&#34;bytes&#34;:410369,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;internalRedirect&#34;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fee3dc3c0-4206-4a80-9a1d-207e3467933d_1220x1628.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fee3dc3c0-4206-4a80-9a1d-207e3467933d_1220x1628.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fee3dc3c0-4206-4a80-9a1d-207e3467933d_1220x1628.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fee3dc3c0-4206-4a80-9a1d-207e3467933d_1220x1628.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a></figure></div><p><span>Grimes makes a classic tech product error in casually waving away a problem with “just”, and roon calls her out on it by pointing out that “</span><a href="https://twitter.com/tszzl/status/1575173284441731072?s=20&amp;t=OfhXztT2io4dNnvoIdplXQ" rel="">perfect visual reasoning is AGI hard</a><span>”.</span></p><p><span>This is a useful “stop sequence” for AI handwaving. Software engineers and computer scientists already have a tool for understanding the limits of infinite spaces - </span><a href="https://en.wikipedia.org/wiki/P_versus_NP_problem" rel="">the P vs NP problem</a><span> - as well as an accepted wisdom that there is a known area of algorithm research that is too unrealistic to be productive, because working on it would be functionally equivalent to proving P = NP.</span></p><p>I’ll spare you further layman elaboration that you can Google, but the implications of declaring a problem space “NP-hard” (there is also “NP-complete”, which has a distinct definition, but we will ignore) is something we can use in productized AI conversations:</p><ul><li><p><strong>Finality</strong><span>: “You can stop here” is very useful for endlessly expansive debates</span></p></li><li><p><strong>Equivalence</strong><span>: “If this is true, then X will also be true, do I believe that?” is very useful for thinking through predictions</span></p></li></ul><p>Similarly, as far as we know, we don’t have AGI yet, and so the class of problems that are “AGI hard” should be assumed impossible/not worth working on without also having a plan for solving AGI. </p><p><strong>In other words, you cannot “just” assume that there will be a solution to AGI-hard problems</strong><span>. All conversations about products requiring AGI-hard solutions are effectively science fiction until we actually have AGI (which we truly don’t know if will arrive in </span><a href="https://news.ycombinator.com/item?id=32525721" rel="">10</a><span> years, or 100, or 1000, or never).</span></p><p><span>When I asked friends a good yardstick for “AGI-hard” would be, the universal first response was some form of “</span><a href="https://iep.utm.edu/theomind/" rel="">Theory of Mind</a><span>”. A simpler version of this might be called </span><strong>empathy</strong><span>, or being able to form a thesis about you, gauge your interests and capabilities, and act accordingly.</span></p><p>This is either a level of difficulty beyond a classic Turing test, or perhaps the ultimate essence of one, since empathy is at the heart of humanity.</p><p><span>I felt this when trying out </span><strong>Quazel</strong><span>, which is a language training app combining OpenAI Whisper + GPT3 recently </span><a href="https://news.ycombinator.com/item?id=32993130" rel="">launched on Hacker News</a><span>. </span></p><div><figure><a target="_blank" href="https://twitter.com/swyx/status/1574753964154814464/photo/2" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Faa077b9b-a37f-4a74-90e4-5807e8332841_2468x1472.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Faa077b9b-a37f-4a74-90e4-5807e8332841_2468x1472.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Faa077b9b-a37f-4a74-90e4-5807e8332841_2468x1472.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Faa077b9b-a37f-4a74-90e4-5807e8332841_2468x1472.jpeg 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Faa077b9b-a37f-4a74-90e4-5807e8332841_2468x1472.jpeg" width="1456" height="868" data-attrs="{&#34;src&#34;:&#34;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/aa077b9b-a37f-4a74-90e4-5807e8332841_2468x1472.jpeg&#34;,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:868,&#34;width&#34;:1456,&#34;resizeWidth&#34;:null,&#34;bytes&#34;:null,&#34;alt&#34;:&#34;Image&#34;,&#34;title&#34;:null,&#34;type&#34;:null,&#34;href&#34;:&#34;https://twitter.com/swyx/status/1574753964154814464/photo/2&#34;,&#34;belowTheFold&#34;:true,&#34;internalRedirect&#34;:null}" alt="Image" title="Image" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Faa077b9b-a37f-4a74-90e4-5807e8332841_2468x1472.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Faa077b9b-a37f-4a74-90e4-5807e8332841_2468x1472.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Faa077b9b-a37f-4a74-90e4-5807e8332841_2468x1472.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Faa077b9b-a37f-4a74-90e4-5807e8332841_2468x1472.jpeg 1456w" sizes="100vw" loading="lazy"/></picture></div></a></figure></div><p>Translated:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fdedb8c0d-2025-43d9-ad1c-f302fab4daca_976x834.jpeg" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fdedb8c0d-2025-43d9-ad1c-f302fab4daca_976x834.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fdedb8c0d-2025-43d9-ad1c-f302fab4daca_976x834.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fdedb8c0d-2025-43d9-ad1c-f302fab4daca_976x834.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fdedb8c0d-2025-43d9-ad1c-f302fab4daca_976x834.jpeg 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fdedb8c0d-2025-43d9-ad1c-f302fab4daca_976x834.jpeg" width="976" height="834" data-attrs="{&#34;src&#34;:&#34;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/dedb8c0d-2025-43d9-ad1c-f302fab4daca_976x834.jpeg&#34;,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:834,&#34;width&#34;:976,&#34;resizeWidth&#34;:null,&#34;bytes&#34;:null,&#34;alt&#34;:&#34;Image&#34;,&#34;title&#34;:null,&#34;type&#34;:null,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;internalRedirect&#34;:null}" alt="Image" title="Image" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fdedb8c0d-2025-43d9-ad1c-f302fab4daca_976x834.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fdedb8c0d-2025-43d9-ad1c-f302fab4daca_976x834.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fdedb8c0d-2025-43d9-ad1c-f302fab4daca_976x834.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fdedb8c0d-2025-43d9-ad1c-f302fab4daca_976x834.jpeg 1456w" sizes="100vw" loading="lazy"/></picture></div></a></figure></div><p><span>Impressive (if </span><a href="https://news.ycombinator.com/item?id=32995240" rel="">not actually colloquial</a><span>), but my Chinese is rusty and halting, and a reasonable Chinese tutor would have immediately detected this and lowered their own communication level to put me at ease. Instead, Quazel barrelled on, in an admittedly impressive conversational style, understandable but enough that it might be intimidating.</span></p><p><span>This intimidation factor is key. </span><strong>The goal for AI applications is not “replicate humans as closely as possible”.</strong><span> We don’t really care about that, and in fact, </span><strong>we </strong><em><strong>want</strong></em><strong> AI to be superhuman as long as it is aligned</strong><span>. But we care that it fills the job to be done, which in this case was “help me learn Chinese”. The chatty second question here might spur me to improve my Chinese, but it might cause someone else to hide in their shell. It would take </span><strong>empathy</strong><span> for an AI language tutor to determine what kind of learner I am, and adjust accordingly. We can all probably tell that GPT-3 does not have this capability, and, if theory-of-mind is AGI-hard, then we should also conclude that a </span><strong>level-adjusting AI language tutor product</strong><span> is not viable to work on (a shame, given this also means </span><a href="https://en.wikipedia.org/wiki/Bloom%27s_2_sigma_problem" rel="">Bloom’s 2 sigma problem</a><span> is AGI-hard).</span></p><p><span>We could approximate empathy; just in October 2022 alone we’ve seen papers on </span><a href="https://arxiv.org/abs/2210.08863" rel="">Single-Life Reinforcement Learning</a><span> and </span><a href="https://arxiv.org/abs/2210.14215" rel="">In-context Reinforcement Learning</a><span>, and CarperAI launched </span><a href="https://github.com/CarperAI/trlx" rel="">trlX</a><span>, a way to fine-tune language models with Reinforcement Learning via Human Feedback. We could also lower the promises of our products - dull scissors aren’t perfect scissors but still better than no scissors. But the AGI-hard barrier is a clear line in the sand.</span></p><p><span>The illusion or belief that our counterpart exists and understands us is also important to us - this is why </span><strong>AI therapists</strong><span> might help some folks, but an AI therapist capable of performing at or above human ability would also be AGI-hard.</span></p><p><span>F. Scott Fitzgerald is often </span><a href="https://fs.blog/dani-shapiro-still-writing/" rel="">quoted</a><span>: &#34;</span><em>The test of a first-rate intelligence is the ability to hold two opposing ideas in mind at the same time and still retain the ability to function.</em><span>&#34; </span></p><p>This is too high a bar; many humans easily fail this test.</p><p><span>But yet we instinctively know that </span><a href="https://knowyourmeme.com/memes/the-ability-to-speak-does-not-make-you-intelligent" rel="">the ability to speak does not make you intelligent</a><span>, and the ability for generative AI to create beautiful images </span><a href="https://twitter.com/fabianstelzer/status/1561019187451011074" rel="">like this</a><span> does not make it an artist that can </span><a href="https://www.reddit.com/r/StableDiffusion/comments/xg39ac/we_live_in_a_society/" rel="">create this</a><span>:</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe27b4d3-51a3-493d-97ae-5f5ef14204cc_640x891.png" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe27b4d3-51a3-493d-97ae-5f5ef14204cc_640x891.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe27b4d3-51a3-493d-97ae-5f5ef14204cc_640x891.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe27b4d3-51a3-493d-97ae-5f5ef14204cc_640x891.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe27b4d3-51a3-493d-97ae-5f5ef14204cc_640x891.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe27b4d3-51a3-493d-97ae-5f5ef14204cc_640x891.png" width="640" height="891" data-attrs="{&#34;src&#34;:&#34;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/fe27b4d3-51a3-493d-97ae-5f5ef14204cc_640x891.png&#34;,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:891,&#34;width&#34;:640,&#34;resizeWidth&#34;:null,&#34;bytes&#34;:null,&#34;alt&#34;:&#34;Post image&#34;,&#34;title&#34;:null,&#34;type&#34;:null,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;internalRedirect&#34;:null}" alt="Post image" title="Post image" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe27b4d3-51a3-493d-97ae-5f5ef14204cc_640x891.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe27b4d3-51a3-493d-97ae-5f5ef14204cc_640x891.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe27b4d3-51a3-493d-97ae-5f5ef14204cc_640x891.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Ffe27b4d3-51a3-493d-97ae-5f5ef14204cc_640x891.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a></figure></div><p><span>Visually interesting, </span><strong>but with a message</strong><span>. The AIs of today would perhaps describe this as “crowd of people looking at 2 paintings of buxom women AI art being auctioned by a robot, while a human artist girl struggles to sell a human painting for $1, watercolor”</span><a id="footnote-anchor-3-78814824" href="https://lspace.swyx.io/p/agi-hard#footnote-3-78814824" rel="">3</a><span>. A human who took one look and then closed their eyes could describe the </span><em>meaning</em><span> of the art, and be more precise, than </span><em>what</em><span> specifically is in it.</span></p><p><span>The joy and problem with latent space being infinitely larger than our real world is it is constrained by nasty inconveniences like physics and economics. A baby is born with a great deal of genetically imprinted transfer learning; time flows in one direction, sound (usually) does not have color, </span><a href="https://www.reddit.com/r/todayilearned/comments/4i6dve/til_that_children_born_blind_still_smile_meaning/" rel="">smiles = happiness</a><span>. A little bit of time in our world and they would learn that the vast majority of humans have two hands, yet our </span><a href="https://lspace.swyx.io/p/multiverse-not-metaverse" rel="">AI art portals</a><span> happily transport us to worlds where those limits don’t apply.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fdac737ed-1645-461f-9506-85995e6f3873_1155x628.jpeg" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fdac737ed-1645-461f-9506-85995e6f3873_1155x628.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fdac737ed-1645-461f-9506-85995e6f3873_1155x628.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fdac737ed-1645-461f-9506-85995e6f3873_1155x628.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fdac737ed-1645-461f-9506-85995e6f3873_1155x628.jpeg 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fdac737ed-1645-461f-9506-85995e6f3873_1155x628.jpeg" width="1155" height="628" data-attrs="{&#34;src&#34;:&#34;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/dac737ed-1645-461f-9506-85995e6f3873_1155x628.jpeg&#34;,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:628,&#34;width&#34;:1155,&#34;resizeWidth&#34;:null,&#34;bytes&#34;:null,&#34;alt&#34;:&#34;Non-edited results from DALL-E 2 and Stable Diffusion (1.4) at the end of August 2022, both showing issues with limbs. Prompt is &#39;A woman embracing a man&#39;&#34;,&#34;title&#34;:null,&#34;type&#34;:null,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;internalRedirect&#34;:null}" alt="Non-edited results from DALL-E 2 and Stable Diffusion (1.4) at the end of August 2022, both showing issues with limbs. Prompt is &#39;A woman embracing a man&#39;" title="Non-edited results from DALL-E 2 and Stable Diffusion (1.4) at the end of August 2022, both showing issues with limbs. Prompt is &#39;A woman embracing a man&#39;" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fdac737ed-1645-461f-9506-85995e6f3873_1155x628.jpeg 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fdac737ed-1645-461f-9506-85995e6f3873_1155x628.jpeg 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fdac737ed-1645-461f-9506-85995e6f3873_1155x628.jpeg 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2Fdac737ed-1645-461f-9506-85995e6f3873_1155x628.jpeg 1456w" sizes="100vw" loading="lazy"/></picture></div></a></figure></div><p><span>The simple answer “get a physics engine and some human models and generate a few billion more training samples for embeddings” will probably fix this eventually, but that is a hotfix over an endless whackamole of complexity arising from the fact that AI learns from data about the world, yet does not actually live in the world it models (Yann LeCun actually calls these </span><a href="https://twitter.com/ylecun/status/1537893350295998465" rel="">world models</a><span> and notes we are </span><a href="https://twitter.com/ylecun/status/1472589622500864003" rel="">far from able</a><span> to do this). “The map is not the territory”, and we’ve only got very good map makers and navigators with AI. </span></p><p>Humanity is Robin Williams, and AI is Matt Damon. The map is not the territory.</p><div id="youtube2-oRG2jlQWCsY" data-attrs="{&#34;videoId&#34;:&#34;oRG2jlQWCsY&#34;,&#34;startTime&#34;:null,&#34;endTime&#34;:null}"><p><iframe src="https://www.youtube-nocookie.com/embed/oRG2jlQWCsY?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0" frameborder="0" loading="lazy" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true" width="728" height="409"></iframe></p></div><p><span>The map will only equal the territory when we can fully simulate our world for AI to train in, which means the AGI-hardness problem is also a proxy for </span><a href="https://en.wikipedia.org/wiki/Simulation_hypothesis" rel="">the simulation hypothesis</a><span>. If we can solve simulation, we’ll solve AGI-hard physical modeling problems, but it is less evident that AGI-hard problems are also simulation-hard. </span></p><blockquote><p><em><span>As you may have experienced with </span><a href="https://hypebeast.com/2022/10/joe-rogan-steve-jobs-play-ht-podcast-ai-ai-powered-podcast" rel="">the Joe Rogan-Steve Jobs AI podcast</a><span>, simulation-hard problems are likely also </span><a href="https://en.wikipedia.org/wiki/Mind_uploading" rel="">uploading</a><span>-hard and </span><a href="https://replika.com/" rel="">replica</a><span>-hard.</span></em></p></blockquote><p>The physical intuition problem translates at the limit to conceptual intuition. GPT3 can understand some analogies and to think step by step, but we can’t trust it to reliably infer concepts because it doesn’t have any real understanding of logic. Ironic, given machines are built atop logic gates. So:</p><ul><li><p><strong>Math: </strong><span>Can AI invent calculus from first principles?</span></p></li><li><p><strong>Physics</strong><span>: Can AI do Einsteinian thought experiments and derive relativity?</span></p></li><li><p><strong>Finance</strong><span>: Can AI look at option payoffs and know to borrow from the </span><a href="https://en.wikipedia.org/wiki/Heat_equation" rel="">heat equation</a><span> to create </span><a href="https://en.wikipedia.org/wiki/Black%E2%80%93Scholes_model" rel="">Black-Scholes</a><span>?</span></p></li><li><p><strong>Music</strong><span>: Can AI have taste? Set trends? Make </span><a href="https://mixtape.swyx.io/episodes/music-friday-remixes-interpolations-and-the-nostalgia-loop-charlie-harding" rel="">remixes and interpolations</a><span>? How many </span><a href="https://en.wikipedia.org/wiki/Infinite_monkey_theorem" rel="">infinite monkeys</a><span> does it take an AI to come up with “</span><a href="https://www.youtube.com/watch?v=XPBwXKgDTdE&amp;lc=Ugzu6PyVjzrEtxFhRl14AaABAg" rel="">you made a rebel of a careless man’s careful daughter</a><span>”, and how many more to understand how special that line is?</span></p></li><li><p><strong>Programming</strong><span>: Can AI create AI? Quine LLMs?</span></p></li></ul><p>These physical and conceptual intuition-type problems are likely to be AGI-hard.</p><p><span>But we’ve derived some useful equivalencies at least: </span><em>AGI-hard = Simulation-hard = Uploading-hard = Replica-hard.</em></p><p>Perhaps AGI-hard is too hard - it’s tiring and depressing (or perhaps reassuring? depending on your view) to keep coming up with ways computers will never be good enough.</p><p>But it’s also useful to keep with you a list of “things AI is totally capable of, but just can’t do yet”, just so you can test when you’re dealing with an AI. Using AI (the Adjacent Impossible) to combat AI, if you will.</p><p><strong>This is a moving target</strong><span>; the original CAPTCHA was originally a perfectly good Turing test, but had to be </span><a href="https://developers.google.com/search/blog/2018/10/introducing-recaptcha-v3-new-way-to" rel="">retired</a><span> when </span><a href="https://www.perimeterx.com/resources/blog/2020/captchas-hard-for-humans-easy-for-bots/" rel="">AI solved it better than humans</a><span>. Not perfect; but useful.</span></p><p><span>My favorite recent example is detecting deepfakes by asking the caller to </span><a href="https://news.ycombinator.com/item?id=32384653" rel="">turn sideways</a><span>:</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6fe63bb0-0f19-42da-8101-372d1d892e82_2514x1678.png" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6fe63bb0-0f19-42da-8101-372d1d892e82_2514x1678.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6fe63bb0-0f19-42da-8101-372d1d892e82_2514x1678.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6fe63bb0-0f19-42da-8101-372d1d892e82_2514x1678.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6fe63bb0-0f19-42da-8101-372d1d892e82_2514x1678.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6fe63bb0-0f19-42da-8101-372d1d892e82_2514x1678.png" width="1456" height="972" data-attrs="{&#34;src&#34;:&#34;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/6fe63bb0-0f19-42da-8101-372d1d892e82_2514x1678.png&#34;,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:972,&#34;width&#34;:1456,&#34;resizeWidth&#34;:null,&#34;bytes&#34;:3043598,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;internalRedirect&#34;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6fe63bb0-0f19-42da-8101-372d1d892e82_2514x1678.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6fe63bb0-0f19-42da-8101-372d1d892e82_2514x1678.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6fe63bb0-0f19-42da-8101-372d1d892e82_2514x1678.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F6fe63bb0-0f19-42da-8101-372d1d892e82_2514x1678.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a></figure></div><p>Of course, this is just a question of lack of data, but it is pretty obvious that we don’t have anywhere the same level of data of face profiles at different angles compared to point-blank face photos. </p><p>In particular, NeRFs are making it much easier to create and navigate virtual space:</p><p><span>Someday, though, that trick will fall to the ever-progressing AI. Then you have </span><a href="https://news.ycombinator.com/item?id=32387915" rel="">other options</a><span>:</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9c8e0a44-47fa-450e-9135-b22081aef2f8_1756x790.png" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9c8e0a44-47fa-450e-9135-b22081aef2f8_1756x790.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9c8e0a44-47fa-450e-9135-b22081aef2f8_1756x790.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9c8e0a44-47fa-450e-9135-b22081aef2f8_1756x790.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9c8e0a44-47fa-450e-9135-b22081aef2f8_1756x790.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9c8e0a44-47fa-450e-9135-b22081aef2f8_1756x790.png" width="1456" height="655" data-attrs="{&#34;src&#34;:&#34;https://bucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com/public/images/9c8e0a44-47fa-450e-9135-b22081aef2f8_1756x790.png&#34;,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:655,&#34;width&#34;:1456,&#34;resizeWidth&#34;:null,&#34;bytes&#34;:210703,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;internalRedirect&#34;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9c8e0a44-47fa-450e-9135-b22081aef2f8_1756x790.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9c8e0a44-47fa-450e-9135-b22081aef2f8_1756x790.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9c8e0a44-47fa-450e-9135-b22081aef2f8_1756x790.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fbucketeer-e05bbc84-baa3-437e-9518-adb32be77984.s3.amazonaws.com%2Fpublic%2Fimages%2F9c8e0a44-47fa-450e-9135-b22081aef2f8_1756x790.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a></figure></div><ul><li><p>Lex Fridman asks a question of Andrej Karpathy, and he reframes the question before answering. “I wonder if a language model can do that”</p><div id="youtube2-_W1JBAfV4Io" data-attrs="{&#34;videoId&#34;:&#34;_W1JBAfV4Io&#34;,&#34;startTime&#34;:null,&#34;endTime&#34;:null}"><p><iframe src="https://www.youtube-nocookie.com/embed/_W1JBAfV4Io?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0" frameborder="0" loading="lazy" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true" width="728" height="409"></iframe></p></div></li><li><p><span>Melanie Mitchell of the Santa Fe Institute has also published a paper on </span><a href="https://arxiv.org/pdf/2104.12871.pdf" rel="">Why AI is Harder than We Think</a><span>, covering 4 fallacies:</span></p><ul><li><p>Fallacy 1: Narrow intelligence is on a continuum with general intelligence</p></li><li><p>Fallacy 2: Easy things are easy and hard things are hard</p></li><li><p>Fallacy 3: The lure of wishful mnemonics</p></li><li><p>Fallacy 4: Intelligence is all in the brain</p></li></ul></li><li><p>Interview here</p><div id="youtube2-A8m1Oqz2HKc" data-attrs="{&#34;videoId&#34;:&#34;A8m1Oqz2HKc&#34;,&#34;startTime&#34;:null,&#34;endTime&#34;:null}"><p><iframe src="https://www.youtube-nocookie.com/embed/A8m1Oqz2HKc?rel=0&amp;autoplay=0&amp;showinfo=0&amp;enablejsapi=0" frameborder="0" loading="lazy" gesture="media" allow="autoplay; fullscreen" allowautoplay="true" allowfullscreen="true" width="728" height="409"></iframe></p></div></li></ul><p>If you enjoyed this post, I’d appreciate a reshare on your hellsite of choice :)</p></div></div></div></article></div></div></div>
  </body>
</html>
