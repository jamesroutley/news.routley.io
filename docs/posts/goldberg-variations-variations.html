<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://reubenson.com/recurse/week-4/">Original</a>
    <h1>Goldberg Variations Variations</h1>
    
    <div id="readability-page-1" class="page"><div>
      
<h3>Week 4 at Recurse Center</h3>
<p>After seeing my friend Asha Tamirisa give a talk on building a <a href="https://thekitchen.org/on-view/counter-archiving-the-avant-garde/">counter-archive of The Kitchen</a> at <a href="https://pioneerworks.org/programs/software-for-artists-day-8">Software for Artists Day</a> last week, I&#39;ve been thinking more about the overlap between archives and ML training sets, how each deals with concerns of how information perpetuates biases, and produces contestable views of history and reality. Complex socio-economic and political realities are embedded in the objective artifacts that may be included or excluded in both archives and training sets.</p>
<p>The emergence of certain canonical training sets, like <a href="https://www.kaggle.com/datasets/wcukierski/enron-email-dataset">this archive of half a million emails within Enron</a> obtained by the federal government during its investigation, says something too about how ML is a powerful tool for distilling and operationalizing archives. To turn archives of the near or distant past into substrates that can be mined for the purposes of future prediction or content generation.</p>
<p>In the information age, big tech often finds a business model in leveraging capital to extract value from assets already in circulation in the wider economy (e.g.ride-sharing or behavioral surplus), and this continues to be the pattern in how today&#39;s LLMs feed on the previously inert archives of the past.</p>
<blockquote>
<p>I listened to the music. It was hideous. I have never heard anything like it. It was distorted, diabolical, without sense or meaning, except, perhaps, an alien, disconcerting meaning that should never have been there. I could believe only with the greatest effort that it had once been a Bach Fugue, part of a most orderly and respected work.</p>
<p>(Excerpt from Philip K. Dick&#39;s <em>The Preserving Machine</em>, thanks <a href="https://laurelschwulst.com/">Laurel</a>!)</p>
</blockquote>
<p>This last week, I&#39;ve been buiding a neural net model trained on MIDI transcriptions of Bach to produce Bach-like music, though not very well at the time of this writing. Around this time last year, I was digging up old MIDI websites from the 1990s, of which I can imagine only a fraction are still online. There are some sizeable training sets available for purposes like this, but I&#39;ve been returning to my old bookmarks instead, and so far have been relying on MIDI transcriptions shared on <a href="http://www.jsbach.net">Dave&#39;s J.S. Bach Page</a> (first launched in 1996, and last updated in 2010). While revisiting this beautiful website, I came across a figure named John Sankey, known then as the <a href="https://johnsankey.ca/harpsichord.html"><em>Harpsichordist to the Internet</em></a>. I was also surprised to see brief mention in his writings on his personal experience in having his <a href="https://johnsankey.ca/bach.html">MIDI files stolen and commercialized</a>, before the longer arc of music piracy during the MP3 age and the rise of Spotify. I&#39;d largely thought of this early period of music file-sharing on the web as a more wholesome era, but it&#39;s helpful to remember that the incentives have been such that much smaller actors than the tech behemoths of today have long taken advantage of opportunities to build products around freely available information on the web.</p>
<p>With all this in mind, and with my remaining two weeks at Recurse, I&#39;d like to spend a little more time exploring the question of how ML may work towards or alongside archives, rather than ingest them entirely, tracing the faultlines between the archive and the training set.</p>
<!-- 

been thinking more about how the problematics of archives (tk) bleeds over into the questions of perpetuated biases within training sets for ML systems

- Are ML systems just archives at scale?
- So much effort is leveraged into producing a corpus of training data, but has often been built out of what's simply available (enron emails?)
- Big tech has always been prone to leveraging capital in order to extract capital from assets already in circulation in the wider economy (the ride-sharing model, the labor behind maintaining Wikipedia)
- A smaller example of the above is found in Sankey, who I discovered while exploring the early music web. How, even then, smaller actors than the tech behemoths today sought out arbitrage opportunities to build products around freely available information
- In the remaining two weeks at Recurse, I'd like to spend a little more time exploring the question of how machine learning may work alongside the project of archive-building, of what divergences may exist between the archive and the training corpus. -->
    </div></div>
  </body>
</html>
