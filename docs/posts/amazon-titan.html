<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://aws.amazon.com/bedrock/titan/">Original</a>
    <h1>Amazon Titan</h1>
    
    <div id="readability-page-1" class="page"><div id="aws-page-content" data-page-alert-target="true"> 
   <main id="aws-page-content-main" role="main" tabindex="-1"> 
     
     
    <div> 
     <div> 
      <div> 
       <h2 id="Overview"> Overview</h2> 
       <p><span>Amazon Bedrock is a new service that makes FMs available from leading AI startups and Amazon via an API. Bedrock is the easiest way for customers to build and scale generative AI-based applications using FMs, democratizing access for all builders. Bedrock offers the ability to access a range of powerful FMs for text and images—including Amazon Titan FMs— through a scalable, reliable, and secure AWS managed service. Amazon Titan FMs are pretrained on large datasets, making them powerful, general-purpose models. Use them as is or privately to customize them with your own data for a particular task without annotating large volumes of data.</span><br/> </p> 
      </div> 
     </div> 
    </div> 
    <div> 
     <div> 
      <div> 
       <h2 id="Benefits"> Benefits</h2> 
       <div> 
        <div> 
         <h3 id="Automate_natural_language_tasks_such_as_summarization_and_text_generation"> Automate natural language tasks such as summarization and text generation</h3> 
         <p>Titan Text is a generative large language model (LLM) for tasks such as summarization, text generation (for example, creating a blog post), classification, open-ended Q&amp;A, and information extraction.<br/> </p> 
        </div> 
        <div> 
         <h3 id="Enhance_search_accuracy_and_improve_personalized_recommendations"> Enhance search accuracy and improve personalized recommendations</h3> 
         <p>Titan Embeddings is an LLM that translates text inputs (words, phrases or possibly large units of text) into numerical representations (known as embeddings) that contain the semantic meaning of the text. While this LLM doesn’t generate text, it is useful for applications like personalization and search because, by comparing embeddings, the model can produce more relevant and contextual responses than word matching.<br/> </p> 
        </div> 
        <div> 
         <h3 id="Support_responsible_use_of_AI_by_reducing_inappropriate_or_harmful_content"> Support responsible use of AI by reducing inappropriate or harmful content</h3> 
         <p>Titan FMs are built to detect and remove harmful content in the data, reject inappropriate content in the user input, and filter model outputs that contain inappropriate content (such as hate speech, profanity, and violence).<br/> </p> 
        </div> 
       </div> 
      </div> 
     </div> 
    </div> 
     
     
    <div data-da-type="so" data-da-so-type="viewport" data-da-so-language="en" data-da-so-category="monitoring" data-da-so-name="tile2-mobile" data-da-so-version="benefits" data-da-so-url="/products/databases"> 
     <div> 
      <div> 
       <h2 id="Built_on_top_of_over_20_years_of_ML_experience"> Built on top of over 20 years of ML experience</h2> 
       <p>AI and ML have been a focus for Amazon for over 20 years, and many of the capabilities customers use with Amazon are driven by ML. We have thousands of engineers at Amazon committed to ML, and it’s a big part of our heritage, current ethos, and future. Amazon Titan models are built by leveraging Amazon’s decades of experience to make ML accessible to anyone who wants to use it.</p> 
      </div> 
     </div> 
    </div> 
    <div> 
     <div> 
      <div> 
       <h2 id="Customer_success"> Customer success</h2> 
       <div> 
        <div> 
         <figure> 
          <p><img src="https://d1.awsstatic.com/pdp-customer-logos/Coda-logo-23.9221da8b8b923e048ac0de89f32f73e56a3bdded.png" alt="Coda" title="Coda"/> 
          </p> 
         </figure> 
        </div> 
        <div> 
         <div> 
          <div> 
           <blockquote>
             “As longtime happy AWS customers, we’re excited about how Amazon Bedrock can bring quality, scalability, and performance to Coda AI. We also appreciate that we can use Amazon Titan models through a simple API without provisioning or managing infrastructure. Since all our data is already on AWS, we are able to quickly incorporate generative AI using Bedrock, with all the security and privacy we need to protect our data built in. With over tens of thousands of teams running on Coda, including large teams like Uber, the New York Times, and Square, reliability and scalability are really important.” 
           </blockquote> 
           <p><b>Shishir Mehrotra, Co-Founder &amp; CEO - Coda</b><br/> </p> 
          </div> 
         </div> 
        </div> 
       </div> 
      </div> 
     </div> 
    </div> 
     
     
   </main> 
  </div></div>
  </body>
</html>
