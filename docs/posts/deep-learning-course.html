<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://fleuret.org/dlc/">Original</a>
    <h1>Deep Learning Course</h1>
    
    <div id="readability-page-1" class="page">

<!-- ************************************************************ -->
<!-- ************************************************************ -->
<!-- ************************************************************ -->



<p>You can find here <a href="#lectures">slides, recordings</a>,
and a <a href="#vm">virtual machine</a>
for <a href="https://fleuret.org/francois/">François
Fleuret</a>&#39;s deep-learning
courses <a href="https://wwwi.unige.ch/cursus/programme-des-cours/web/teachings/details/2020-14X050">14x050</a>
of the <a href="https://www.unige.ch">University of Geneva,</a>
<!-- and <a href="https://edu.epfl.ch/coursebook/en/deep-learning-EE-559">EE-559</a> -->
<!-- of the <a href="https://www.epfl.ch/index.en.html">École -->
<!-- Polytechnique Fédérale de Lausanne,</a> -->
Switzerland.</p>

<p>This course is a thorough introduction to deep-learning, with
examples in the <a href="https://pytorch.org">PyTorch</a>
framework:</p>

<ul>
<li>machine learning objectives and main challenges,</li>
<li>tensor operations,</li>
<li>automatic differentiation, gradient descent,</li>
<li>deep-learning specific techniques,</li>
<li>generative, recurrent, attention models.</li>
</ul>

<p>You can check the <a href="#information">pre-requisites.</a></p>

<!-- ********************************************************************** -->

<p>This course was developped initialy at
the <a href="https://www.idiap.ch">Idiap Research Institute</a>
in 2018, and taught as EE-559
at <a href="https://www.epfl.ch/index.en.html">École
Polytechnique Fédérale de Lausanne</a> until 2022. The notes for
the handouts were added with the help
of <a href="https://www.idiap.ch/~ocanevet/">Olivier
Canévet.</a></p>

<p>Thanks to Adam Paszke, Jean-Baptiste Cordonnier, Alexandre
Nanchen, Xavier Glorot, Andreas Steiner, Matus Telgarsky,
Diederik Kingma, Nikolaos Pappas, Soumith Chintala, and Shaojie
Bai for their answers or comments.</p>

<!-- ************************************************************ -->
<!-- ************************************************************ -->
<!-- ************************************************************ -->

<p>In addition to the materials available here, I also wrote and
distribute <a href="https://fleuret.org/francois/lbdl.html">&#34;The Little Book of Deep Learning&#34;,</a> a
phone-formatted short introduction to deep learning for readers with a
STEM background.</p>



<p>The slide pdfs are the ones I use for the lectures. They are in
landscape format with overlays to facilitate the presentation. The
handout pdfs are compiled without these fancy effects in portrait
orientation, with additional notes. The screencasts are available both
as in-browser streaming or downloadable mp4 files.</p>

<p>You can get archives with all the pdf files
(1097 slides):</p>

<ul>
<li><a href="https://fleuret.org/dlc/materials/dlc-handout-all.zip">dlc-handout-all.zip</a> (101.6Mb)</li>
<li><a href="https://fleuret.org/dlc/materials/dlc-slides-all.zip">dlc-slides-all.zip</a> (101.6Mb)</li>
</ul>

<p>and subtitles for the screencasts generated automaticallly
with <a href="https://github.com/openai/whisper">OpenAI&#39;s
Whisper</a>:</p>
<ul>
<li> <a href="https://fleuret.org/dlc/materials/dlc-video-subtitles.zip">dlc-video-subtitles.zip</a>
(502.1Kb)</li>
</ul>

<p>or the individual lectures:</p>

<ul>
  <li><a id="lecture-1"></a>1. Introduction. (90 slides, 1h57min videos)
  <img src="https://fleuret.org/dlc/pics/thumb-1.png" alt="Icon made from one of the slides"/>
    <table>
    <tbody><tr>
      <td>1.1.</td><td>From neural networks to deep learning. (18 slides, 26min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-1-1-from-anns-to-deep-learning.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-1-1-from-anns-to-deep-learning.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-1-1-from-anns-to-deep-learning.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-1-1-from-anns-to-deep-learning.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>1.2.</td><td>Current applications and success. (25 slides, 29min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-1-2-current-success.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-1-2-current-success.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-1-2-current-success.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-1-2-current-success.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>1.3.</td><td>What is really happening? (10 slides, 11min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-1-3-what-is-happening.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-1-3-what-is-happening.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-1-3-what-is-happening.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-1-3-what-is-happening.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>1.4.</td><td>Tensor basics and linear regression. (13 slides, 21min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-1-4-tensors-and-linear-regression.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-1-4-tensors-and-linear-regression.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-1-4-tensors-and-linear-regression.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-1-4-tensors-and-linear-regression.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>1.5.</td><td>High dimension tensors. (20 slides, 25min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-1-5-high-dimension-tensors.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-1-5-high-dimension-tensors.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-1-5-high-dimension-tensors.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-1-5-high-dimension-tensors.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>1.6.</td><td>Tensor internals. (4 slides, 6min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-1-6-tensor-internals.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-1-6-tensor-internals.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-1-6-tensor-internals.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-1-6-tensor-internals.mp4">mp4</a>).</td>
    </tr>
    </tbody></table>
  </li>

  <li><a id="lecture-2"></a>2. Machine learning fundamentals. (72 slides, 1h44min videos)
  <img src="https://fleuret.org/dlc/pics/thumb-2.png" alt="Icon made from one of the slides"/>
    <table>
    <tbody><tr>
      <td>2.1.</td><td>Loss and risk. (12 slides, 20min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-2-1-loss-and-risk.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-2-1-loss-and-risk.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-2-1-loss-and-risk.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-2-1-loss-and-risk.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>2.2.</td><td>Over and under fitting. (25 slides, 36min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-2-2-overfitting.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-2-2-overfitting.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-2-2-overfitting.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-2-2-overfitting.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>2.3.</td><td>Bias-variance dilemma. (10 slides, 18min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-2-3-bias-variance-dilemma.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-2-3-bias-variance-dilemma.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-2-3-bias-variance-dilemma.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-2-3-bias-variance-dilemma.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>2.4.</td><td>Proper evaluation protocols. (6 slides, 11min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-2-4-evaluation-protocols.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-2-4-evaluation-protocols.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-2-4-evaluation-protocols.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-2-4-evaluation-protocols.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>2.5.</td><td>Basic clusterings and embeddings. (19 slides, 19min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-2-5-basic-embeddings.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-2-5-basic-embeddings.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-2-5-basic-embeddings.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-2-5-basic-embeddings.mp4">mp4</a>).</td>
    </tr>
    </tbody></table>
  </li>

  <li><a id="lecture-3"></a>3. Multi-layer perceptron and back-propagation. (68 slides, 1h54min videos)
  <img src="https://fleuret.org/dlc/pics/thumb-3.png" alt="Icon made from one of the slides"/>
    <table>
    <tbody><tr>
      <td>3.1.</td><td>The perceptron. (16 slides, 28min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-3-1-perceptron.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-3-1-perceptron.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-3-1-perceptron.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-3-1-perceptron.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>3.2.</td><td>Probabilistic view of a linear classifier. (8 slides, 14min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-3-2-LDA.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-3-2-LDA.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-3-2-LDA.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-3-2-LDA.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>3.3.</td><td>Linear separability and feature design. (10 slides, 17min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-3-3-features.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-3-3-features.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-3-3-features.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-3-3-features.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>3.4.</td><td>Multi-Layer Perceptrons. (10 slides, 11min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-3-4-MLP.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-3-4-MLP.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-3-4-MLP.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-3-4-MLP.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>3.5.</td><td>Gradient descent. (13 slides, 24min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-3-5-gradient-descent.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-3-5-gradient-descent.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-3-5-gradient-descent.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-3-5-gradient-descent.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>3.6.</td><td>Back-propagation. (11 slides, 20min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-3-6-backprop.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-3-6-backprop.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-3-6-backprop.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-3-6-backprop.mp4">mp4</a>).</td>
    </tr>
    </tbody></table>
  </li>

  <li><a id="lecture-4"></a>4. Graphs of operators, autograd, and convolutional layers. (86 slides, 1h36min videos)
  <img src="https://fleuret.org/dlc/pics/thumb-4.png" alt="Icon made from one of the slides"/>
    <table>
    <tbody><tr>
      <td>4.1.</td><td>DAG networks. (11 slides, 21min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-4-1-DAG-networks.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-4-1-DAG-networks.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-4-1-DAG-networks.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-4-1-DAG-networks.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>4.2.</td><td>Autograd. (20 slides, 22min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-4-2-autograd.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-4-2-autograd.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-4-2-autograd.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-4-2-autograd.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>4.3.</td><td>PyTorch modules and batch processing. (15 slides, 15min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-4-3-modules-and-batch-processing.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-4-3-modules-and-batch-processing.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-4-3-modules-and-batch-processing.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-4-3-modules-and-batch-processing.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>4.4.</td><td>Convolutions. (23 slides, 23min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-4-4-convolutions.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-4-4-convolutions.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-4-4-convolutions.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-4-4-convolutions.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>4.5.</td><td>Pooling. (7 slides, 5min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-4-5-pooling.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-4-5-pooling.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-4-5-pooling.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-4-5-pooling.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>4.6.</td><td>Writing a PyTorch module. (10 slides, 10min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-4-6-writing-a-module.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-4-6-writing-a-module.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-4-6-writing-a-module.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-4-6-writing-a-module.mp4">mp4</a>).</td>
    </tr>
    </tbody></table>
  </li>

  <li><a id="lecture-5"></a>5. Initialization and optimization. (81 slides, 1h42min videos)
  <img src="https://fleuret.org/dlc/pics/thumb-5.png" alt="Icon made from one of the slides"/>
    <table>
    <tbody><tr>
      <td>5.1.</td><td>Cross-entropy loss. (9 slides, 17min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-5-1-cross-entropy-loss.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-5-1-cross-entropy-loss.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-5-1-cross-entropy-loss.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-5-1-cross-entropy-loss.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>5.2.</td><td>Stochastic gradient descent. (17 slides, 26min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-5-2-SGD.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-5-2-SGD.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-5-2-SGD.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-5-2-SGD.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>5.3.</td><td>PyTorch optimizers. (8 slides, 6min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-5-3-optim.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-5-3-optim.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-5-3-optim.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-5-3-optim.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>5.4.</td><td>L<sub><small>2</small></sub> and L<sub><small>1</small></sub> penalties. (11 slides, 13min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-5-4-l2-l1-penalties.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-5-4-l2-l1-penalties.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-5-4-l2-l1-penalties.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-5-4-l2-l1-penalties.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>5.5.</td><td>Parameter initialization. (20 slides, 19min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-5-5-initialization.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-5-5-initialization.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-5-5-initialization.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-5-5-initialization.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>5.6.</td><td>Architecture choice and training protocol. (9 slides, 13min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-5-6-architecture-and-training.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-5-6-architecture-and-training.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-5-6-architecture-and-training.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-5-6-architecture-and-training.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>5.7.</td><td>Writing an autograd function. (7 slides, 8min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-5-7-writing-an-autograd-function.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-5-7-writing-an-autograd-function.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-5-7-writing-an-autograd-function.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-5-7-writing-an-autograd-function.mp4">mp4</a>).</td>
    </tr>
    </tbody></table>
  </li>

  <li><a id="lecture-6"></a>6. Going deeper. (86 slides, 1h39min videos)
  <img src="https://fleuret.org/dlc/pics/thumb-6.png" alt="Icon made from one of the slides"/>
    <table>
    <tbody><tr>
      <td>6.1.</td><td>Benefits of depth. (12 slides, 24min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-6-1-benefits-of-depth.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-6-1-benefits-of-depth.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-6-1-benefits-of-depth.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-6-1-benefits-of-depth.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>6.2.</td><td>Rectifiers. (7 slides, 4min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-6-2-rectifiers.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-6-2-rectifiers.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-6-2-rectifiers.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-6-2-rectifiers.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>6.3.</td><td>Dropout. (11 slides, 13min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-6-3-dropout.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-6-3-dropout.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-6-3-dropout.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-6-3-dropout.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>6.4.</td><td>Batch normalization. (16 slides, 19min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-6-4-batch-normalization.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-6-4-batch-normalization.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-6-4-batch-normalization.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-6-4-batch-normalization.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>6.5.</td><td>Residual networks. (21 slides, 22min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-6-5-residual-networks.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-6-5-residual-networks.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-6-5-residual-networks.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-6-5-residual-networks.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>6.6.</td><td>Using GPUs. (19 slides, 18min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-6-6-using-GPUs.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-6-6-using-GPUs.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-6-6-using-GPUs.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-6-6-using-GPUs.mp4">mp4</a>).</td>
    </tr>
    </tbody></table>
  </li>

  <li><a id="lecture-7"></a>7. Autoencoders. (93 slides, 1h22min videos)
  <img src="https://fleuret.org/dlc/pics/thumb-7.png" alt="Icon made from one of the slides"/>
    
  </li>

  <li><a id="lecture-8"></a>8. Computer vision. (88 slides, 1h49min videos)
  <img src="https://fleuret.org/dlc/pics/thumb-8.png" alt="Icon made from one of the slides"/>
    <table>
    <tbody><tr>
      <td>8.1.</td><td>Computer vision tasks. (14 slides, 20min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-8-1-CV-tasks.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-8-1-CV-tasks.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-8-1-CV-tasks.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-8-1-CV-tasks.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>8.2.</td><td>Networks for image classification. (36 slides, 44min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-8-2-image-classification.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-8-2-image-classification.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-8-2-image-classification.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-8-2-image-classification.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>8.3.</td><td>Networks for object detection. (15 slides, 21min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-8-3-object-detection.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-8-3-object-detection.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-8-3-object-detection.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-8-3-object-detection.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>8.4.</td><td>Networks for semantic segmentation. (10 slides, 11min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-8-4-segmentation.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-8-4-segmentation.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-8-4-segmentation.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-8-4-segmentation.mp4">mp4</a>).</td>
    </tr>
    <tr>
      <td>8.5.</td><td>DataLoader and neuro-surgery. (13 slides, 13min video)</td>
    </tr>
    <tr>
      <td></td>
      <td><a href="https://fleuret.org/dlc/materials/dlc-handout-8-5-dataloader-and-surgery.pdf">handout</a>
      (<a href="https://fleuret.org/dlc/materials/dlc-slides-8-5-dataloader-and-surgery.pdf">slides</a>),
      <a href="https://fleuret.org/dlc/streaming/dlc-video-8-5-dataloader-and-surgery.mp4">stream</a>
      (<a href="https://fleuret.org/dlc/videos/dlc-video-8-5-dataloader-and-surgery.mp4">mp4</a>).</td>
    </tr>
    </tbody></table>
  </li>

  <li><a id="lecture-9"></a>9. Under the hood. (92 slides, 1h22min videos)
  <img src="https://fleuret.org/dlc/pics/thumb-9.png" alt="Icon made from one of the slides"/>
    
  </li>

  <li><a id="lecture-10"></a>10. Autoregression and Normalizing Flows. (84 slides, 1h27min videos)
  <img src="https://fleuret.org/dlc/pics/thumb-10.png" alt="Icon made from one of the slides"/>
    
  </li>

  <li><a id="lecture-11"></a>11. Generative Adversarial Networks. (91 slides, 1h22min videos)
  <img src="https://fleuret.org/dlc/pics/thumb-11.png" alt="Icon made from one of the slides"/>
    
  </li>

  <li><a id="lecture-12"></a>12. Recurrent models and NLP. (73 slides, 1h18min videos)
  <img src="https://fleuret.org/dlc/pics/thumb-12.png" alt="Icon made from one of the slides"/>
    
  </li>

  <li><a id="lecture-13"></a>13. Attention models. (the screencasts are not up-to-date, check the slides! – 93 slides, 1h25min videos)
  <img src="https://fleuret.org/dlc/pics/thumb-13.png" alt="Icon made from one of the slides"/>
    
  </li>


</ul>



<ul>
<li><a href="https://fleuret.org/dlc/materials/dlc-practical-1.pdf">Practical 1</a></li>
<!-- <li><a href="materials/dlc-practical-1.pdf">Practical 1</a> (<a href="src/dlc_practical_1_solution.py">solution</a>)</li> -->
<li><a href="https://fleuret.org/dlc/materials/dlc-practical-2.pdf">Practical 2</a></li>
<!-- <li><a href="materials/dlc-practical-2.pdf">Practical 2</a> (<a href="src/dlc_practical_2_solution.py">solution</a>)</li> -->
<li><a href="https://fleuret.org/dlc/materials/dlc-practical-3.pdf">Practical 3</a></li>
<!-- <li><a href="materials/dlc-practical-3.pdf">Practical 3</a> (<a href="src/dlc_practical_3_solution.py">solution</a>)</li> -->
<li><a href="https://fleuret.org/dlc/materials/dlc-practical-4.pdf">Practical 4</a></li>
<!-- <li><a href="materials/dlc-practical-4.pdf">Practical 4</a> (<a href="src/dlc_practical_4_solution.py">solution</a>)</li> -->
<li><a href="https://fleuret.org/dlc/materials/dlc-practical-5.pdf">Practical 5</a></li>
<!-- <li><a href="materials/dlc-practical-5.pdf">Practical 5</a> (<a href="src/dlc_practical_5_solution.py">solution</a>)</li> -->
<li><a href="https://fleuret.org/dlc/materials/dlc-practical-6.pdf">Practical 6</a></li>
<!-- <li><a href="materials/dlc-practical-6.pdf">Practical 6</a> (<a href="src/dlc_practical_6_solution.py">solution</a>)</li> -->
</ul>

<!-- ************************************************************ -->
<!-- ************************************************************ -->
<!-- ************************************************************ -->



<h2>Pre-requisites</h2>

<ul>
<li>Linear algebra (vectors, matrices, Euclidean spaces),</li>
<li>differential calculus (Jacobian, Hessian, chain rule),</li>
<li>Python programming,</li>
<li>basics in probabilities and statistics (discrete and continuous
distributions, law of large numbers, conditional probabilities,
Bayes, PCA),</li>
<li>basics in optimization (notion of minima, gradient descent),</li>
<li>basics in algorithmic (computational costs),</li>
<li>basics in signal processing (Fourier transform, wavelets).</li>
</ul>

<h2>Documentation</h2>

<p>You may have to look at the Python, Jupyter notebook, and PyTorch
documentations at</p>

<ul>
<li><a href="https://docs.python.org/">https://docs.python.org/</a></li>
<li><a href="https://jupyter.org/">https://jupyter.org/</a></li>
<li><a href="https://pytorch.org/docs/">https://pytorch.org/docs/</a></li>
</ul>

<!-- ************************************************************ -->

<h2><a id="prologue"></a>Practical session prologue</h2>

<p>Helper Python prologue for the practical
sessions: <a href="https://fleuret.org/dlc/src/dlc_practical_prologue.py">dlc_practical_prologue.py</a></p>

<h3>Argument parsing</h3>

<p>This prologue parses command-line arguments as follows</p>

<pre>usage: dummy.py [-h] [--full] [--tiny] [--seed SEED]
[--cifar] [--data_dir DATA_DIR]

DLC prologue file for practical sessions.

optional arguments:
-h, --help           show this help message and exit
--full               Use the full set, can take ages (default
False)
--tiny               Use a very small set for quick checks
(default False)
--seed SEED          Random seed (default 0, &lt; 0 is no seeding)
--cifar              Use the CIFAR data-set and not MNIST
(default False)
--data_dir DATA_DIR  Where are the PyTorch data located (default
$PYTORCH_DATA_DIR or &#39;./data&#39;)
</pre>

<h3>Loading data</h3>

<p>The prologue provides the function</p>

<pre>load_data(cifar = None, one_hot_labels = False, normalize = False, flatten = True)
</pre>

<p>which downloads the data when required, reshapes the images to 1d
vectors if <span>flatten</span>
is <span>True</span>, and narrows to a small subset of
samples if <span>--full</span> is not selected.</p>

<p>It returns a tuple of four tensors: <span>train_data</span>,
<span>train_target</span>, <span>test_data</span>, and <span>test_target</span>.</p>

<p>If <span>cifar</span> is <span>True</span>, the data-base used is CIFAR10, if it
is <span>False</span>, MNIST is used, if it is None, the argument
<span>--cifar</span> is taken into account.</p>

<p>If <span>one_hot_labels</span> is <span>True</span>, the targets are converted to 2d
<span>torch.Tensor</span> with as many columns as there are classes, and
-1 everywhere except the coefficients [n, y_n], equal to 1.</p>

<p>If <span>normalize</span> is <span>True</span>, the data tensors are normalized
according to the mean and variance of the training one.</p>

<p>If <span>flatten</span> is <span>True</span>, the data tensors are flattened
into 2d tensors of dimension N × D, discarding the image structure
of the samples. Otherwise they are 4d tensors of dimension N × C
× H × W.</p>

<h3>Minimal example</h3>

<pre>import dlc_practical_prologue as prologue

train_input, train_target, test_input, test_target = prologue.load_data()

print(&#39;train_input&#39;, train_input.size(), &#39;train_target&#39;, train_target.size())
print(&#39;test_input&#39;, test_input.size(), &#39;test_target&#39;, test_target.size())
</pre>

<p>prints</p>

<pre>* Using MNIST
** Reduce the data-set (use --full for the full thing)
** Use 1000 train and 1000 test samples
train_input torch.Size([1000, 784]) train_target torch.Size([1000])
test_input torch.Size([1000, 784]) test_target torch.Size([1000])
</pre>

<!-- ************************************************************ -->
<!-- ************************************************************ -->
<!-- ************************************************************ -->



<p>A Virtual Machine (VM) is a software that simulates a complete
computer. The one we provide here includes a Linux operating
system and all the tools needed to use PyTorch from a web
browser
(<i>e.g.</i> <a href="https://www.mozilla.org/en-US/firefox/new/">Mozilla
Firefox</a> or <a href="https://www.google.com/chrome/">Google
Chrome</a>).</p>

<h3>Installation</h3>

<ol>
<li>Download and install <a href="https://www.virtualbox.org/wiki/Downloads">Oracle&#39;s VirtualBox,</a></li>
<li>download the <a href="https://fleuret.org/dlc/files/dlc-vm.ova">virtual machine OVA package</a> (1.68Gb), and</li>
<li>open the latter in VirtualBox with <span>File → Import Appliance</span>.</li>
</ol>

<p>You should now see an entry in the list of VMs. The first time
it starts, it provides a menu to choose the keyboard layout you
want to use (you can force the configuration later by running
the command <span>sudo set-kbd</span>).</p>

<p><b>If the VM does not start and VirtualBox complains that the
VT-x is not enabled, you have to activate the virtualization
capabilities of your CPU in the BIOS of your computer.</b></p>

<h3><a id="using-the-vm"></a>Using the VM</h3>

<p>The VM automatically starts
a <a href="https://jupyter.org/">JupyterLab</a> on port 8888 and
exports that port to the host. This means that you can access this
JupyterLab with a web browser on the machine running VirtualBox at
<a href="http://localhost:8888/">http://localhost:8888/</a>
and use Python notebooks, view files, start terminals, and edit source
files. Typing <span>!bye</span> in a notebook
or <span>bye</span> in a terminal will shutdown the
VM.</p>

<p>You can run a terminal and a text editor from inside the Jupyter
notebook for exercises that require more than the notebook
itself. Source files can be executed by running in a terminal the
Python command with the source file name as argument. Both can be done
from the main Jupyter window with:</p>

<ul>
<li><span>New → Text File</span> to create
the source code, or selecting the file and
clicking <span>Edit</span> to edit an existing
one.</li>
<li><span>New → Terminal</span> to start a
shell from which you can run Python.</li>
</ul>

<!-- <p><b>Files saved in the VM are erased when the VM is -->
<!-- re-installed, which happens for each session on the EPFL -->
<!-- machines. So you should download files you want to keep from -->
<!-- the Jupyter notebook to your account and re-upload them later -->
<!-- when you need them.</b></p> -->

<p>This VM also exports an ssh port to the port 2022 on the host,
which allows to log in with standard ssh clients on Linux and
OSX, and with applications such
as <a href="https://www.putty.org/">PuTTY</a> on Windows. The
default login is <span>&#39;dave&#39;</span> and
password <span>&#39;dummy&#39;</span>, same password
for the root account.</p>

<h3>Remarks</h3>

<p>Note that performance for computation will be very poor compared to
<a href="https://pytorch.org/get-started/locally/">installing
PyTorch</a> natively on your machine. In particular, the VM does
not take advantage of a GPU if you have one.</p>

<p><b>Finally, please also note that this VM is configured in a
convenient but highly non-secured manner, with easy to guess
passwords, including for the root, and network-accessible
non-protected Jupyter notebooks.</b></p>

<p>This VM is built on
a <a href="https://www.linuxfoundation.org/">Linux</a> <a href="https://www.debian.org/">Debian,</a>
with <a href="https://conda.io/miniconda.html">miniconda,</a>
<a href="https://pytorch.org/">PyTorch,</a> <a href="http://yann.lecun.com/exdb/mnist/">MNIST,</a>
<a href="https://www.cs.toronto.edu/~kriz/cifar.html">CIFAR10,</a> and many Python utility packages installed.</p>

<!-- ************************************************************ -->
<!-- ************************************************************ -->
<!-- ************************************************************ -->



<p>My own materials on this page are licensed under the
<a href="https://fleuret.org/dlc/by-nc-sa-4.0.txt">Creative Commons BY-NC-SA 4.0
International License.</a></p>

<p>More simply: I am okay with this material being used for
regular academic teaching, but definitely not for a book /
youtube loaded with ads / whatever monetization model I am not
aware of.</p>

<!-- ********************************************************************** -->



<!-- ********************************************************************** -->




</div>
  </body>
</html>
