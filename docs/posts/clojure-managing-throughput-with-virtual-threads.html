<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://andersmurphy.com/2024/05/06/clojure-managing-throughput-with-virtual-threads.html">Original</a>
    <h1>Clojure: Managing throughput with virtual threads</h1>
    
    <div id="readability-page-1" class="page"><article><hgroup><p><time datetime="2024-05-06T00:00:00+00:00">06 May 2024</time></p></hgroup><hr/><p>Before the introduction of Java 21 virtual threads we were heavy users of <a href="https://github.com/clj-commons/claypoole">claypoole</a> a fantastic library for simple but effective parallelism using thread pools. However, things get complicated with virtual threads, they shouldn&#39;t be pooled, as they aren&#39;t a scarce resource. So how do we limit throughput when we have &#34;unlimited&#34; threads? In this post we will look at using java <code>Semaphore</code> class to implement basic token bucket rate limiting to control throughput.</p><p>One of the other key insights I&#39;ve drawn from claypoole is that unordered parallelism helps minimising latency, as it allows you to process results as soon as they became available. So we&#39;ll also explore unordered parallelism with virtual threads.</p><p>To get an virtual thread <code>executor</code> we can call:</p><pre><code><span>(</span>defonce <strong>executor</strong> <span>(</span>Executors/newVirtualThreadPerTaskExecutor<span>))</span>
</code></pre><p>We can combine this with an <code>ExecutorCompletionService</code> to get tasks as they complete rather than the order they are submitted in:</p><pre><code><span>(</span>def <strong>cs</strong> <span>(</span>ExecutorCompletionService/new executor<span>))</span>
</code></pre><p>We can submit tasks to the <code>CompletionService</code> with <code>.submit</code>:</p><pre><code><span>(</span>run! <span>(</span>fn [x] <span>(</span>ExecutorCompletionService/.submit
                  cs #<span>(</span>inc x<span>)))</span>
    [1 2 3 4 5]<span>)</span>
</code></pre><p>We are using Clojure 1.12.0-alpha10 methods as values syntax e.g: <code>ExecutorCompletionService/.submit</code>. This means we don&#39;t have to mannualy type hint to avoid reflection.</p><p>To take completed tasks from the service we use <code>.take</code>:</p><pre><code><span>(</span>-&gt;&gt; <span>(</span>repeatedly #<span>(</span>deref <span>(</span>ExecutorCompletionService/.take cs<span>)))</span>
    <span>(</span>take 5<span>))</span>
</code></pre><p>It&#39;s important to note that <code>.take</code> is blocking so if we <code>take</code> more tasks than there are from the completion service this code will block indefinitely (or until more tasks are submitted to the service). Because of this our implementation of <code>upmap</code> will consume eagerly (i.e it requires all of it&#39;s inputs before it will execute) as we need to know the total number of items that we will want to take <code>(count coll)</code>.</p><p>We can combine all of this to write our own implementation of <code>upmap</code> (unordered pmap):</p><pre><code><span>(</span>defn <strong>upmap</strong>
  <span>(</span>[f coll]
   <span>(</span>let [cs <span>(</span>ExecutorCompletionService/new executor<span>)</span>]
     <span>(</span>run! <span>(</span>fn [x] <span>(</span>ExecutorCompletionService/.submit
                     cs #<span>(</span>f x<span>)))</span> coll<span>)</span>
     <span>(</span>-&gt;&gt; <span>(</span>repeatedly #<span>(</span>deref <span>(</span>ExecutorCompletionService/.take cs<span>)))</span>
       <span>(</span>take <span>(</span>count coll<span>))))))</span>
</code></pre><p><code>upmap</code> takes completed tasks lazily, which lets us process them as they are completed rather than waiting for all tasks to complete:</p><pre><code><span>(</span>upmap inc [1 2 3 4 5 6]<span>)</span><span>
=&gt;</span>

<span>(</span>2 3 4 5 6 7<span>)</span>
</code></pre><p>Now lets look at implementing rate limiting. There&#39;s no point spinning up a bunch of virtual threads to make requests against a third party API only to have some fail due to exceeding the third party API&#39;s rate limit.</p><p>We can use semaphores for this. Semaphores are similar to pools, but instead of pooling a scarce resource like threads, semaphores instead pool permits:</p><pre><code><span>(</span>defonce <strong>sem</strong>
  <span>(</span>Semaphore/new 2 true<span>))</span>
</code></pre><p>We set fairness to <code>true</code> to prevent starvation. From the docs:</p><blockquote><p> The constructor for this class optionally accepts a fairness parameter... When fairness is set true, the semaphore guarantees that threads invoking any of the acquire methods are selected to obtain permits in the order in which their invocation of those methods was processed (first-in-first-out; FIFO). </p></blockquote><p>Worth keeping in mind this will have a throughput cost, so might not always be the right choice:</p><blockquote><p> Generally, semaphores used to control resource access should be initialized as fair, to ensure that no thread is starved out from accessing a resource. When using semaphores for other kinds of synchronization control, the throughput advantages of non-fair ordering often outweigh fairness considerations. </p></blockquote><p>We can combine Semaphores with virtual threads to implement token bucket rate limiting (X req/s with burst of X). This is trivial with virtual threads as we can spin up a new virtual thread (with <code>Thread/startVirtualThread</code>) to return the permit to the semaphore pool after the allotted time. In our case we have two permits and we want a rate limit of 2 req/s so we sleep for 1000ms before returning a permit:</p><pre><code><span>(</span>defn <strong>rate-limited-sem-release</strong> [sem]
  <span>;; block until available
</span>  <span>(</span>Semaphore/.acquire sem<span>)</span>
  <span>;; Create another virtual thread that will release this semaphore
</span>  <span>;; to refill the bucked when the time is up.
</span>  <span>(</span>Thread/startVirtualThread
    #<span>(</span>do <span>(</span>Thread/sleep 1000<span>)</span> <span>;; wait 1 second
</span>         <span>(</span>Semaphore/.release sem<span>))))</span>
</code></pre><p>Something to keep in mind is the accuracy of <code>Thread/sleep</code>. From the java language specification:</p><blockquote><p> Thread.sleep causes the currently executing thread to sleep (temporarily cease execution) for the specified duration, subject to the precision and accuracy of system timers and schedulers. The thread does not lose ownership of any monitors, and resumption of execution will depend on scheduling and the availability of processors on which to execute the thread. </p></blockquote><p>But for our use case this is accurate enough. In my testing it&#39;s only been off by a few milliseconds.</p><p>Combining this all together we get:</p><pre><code><span>(</span>defn <strong>upmap</strong>
  <span>(</span>[f coll]
   <span>(</span>upmap nil f coll<span>))</span>
  <span>(</span>[sem f coll]
   <span>(</span>let [cs <span>(</span>ExecutorCompletionService/new executor<span>)</span>]
     <span>(</span>run!
       <span>(</span>fn [x]
         <span>(</span>when sem <span>(</span>rate-limited-sem-release sem<span>))</span>
         <span>(</span>ExecutorCompletionService/.submit cs <span>(</span>fn [] <span>(</span>f x<span>))))</span> coll<span>)</span>
     <span>(</span>-&gt;&gt; <span>(</span>repeatedly #<span>(</span>deref <span>(</span>ExecutorCompletionService/.take cs<span>)))</span>
       <span>(</span>take <span>(</span>count coll<span>))))))</span>
</code></pre><p>Let&#39;s see if it works:</p><pre><code><span>(</span>time
  <span>(</span>-&gt;&gt; <span>(</span>upmap sem inc [1 2 3 4 5 6 8 9 10]<span>)</span>
    <span>(</span>run! prn<span>)))</span>
    <span>
=&gt;</span>
3
4
5
10
11
7
6
9
&#34;Elapsed time: 4019.565335 msecs&#34;

nil
</code></pre><p>The execution time is correct (greater than 4000msec). However, we are getting all the results in one go. This is happening because the semaphore is blocking the <code>run!</code> function and the way the code is currently written we can&#39;t start taking from the <code>CompletionService</code> until all the tasks have been submitted.</p><p>We can get around this by throwing more virtual threads at the problem. We use <code>Thread/startVirtualThread</code> to execute the <code>run!</code> function in another thread, so even if it blocks we can still start taking completed tasks:</p><pre><code><span>(</span>defn <strong>upmap</strong>
  <span>(</span>[f coll]
   <span>(</span>upmap nil f coll<span>))</span>
  <span>(</span>[sem f coll]
   <span>(</span>let [cs <span>(</span>ExecutorCompletionService/new executor<span>)</span>]
<ins>+    <span>(</span>Thread/startVirtualThread</ins>
       #<span>(</span>run!
          <span>(</span>fn [x]
            <span>(</span>when sem <span>(</span>rate-limited-sem-release sem<span>))</span>
            <span>(</span>ExecutorCompletionService/.submit cs <span>(</span>fn [] <span>(</span>f x<span>))))</span> coll<span>))</span>
     <span>(</span>-&gt;&gt; <span>(</span>repeatedly #<span>(</span>deref <span>(</span>ExecutorCompletionService/.take cs<span>)))</span>
       <span>(</span>take <span>(</span>count coll<span>))))))</span>
</code></pre><p>Let&#39;s see if <code>upmap</code> now behaves as we expect:</p><pre><code><span>(</span>time
  <span>(</span>-&gt;&gt; <span>(</span>upmap sem inc [1 2 3 4 5 6 8 9 10]<span>)</span>
    <span>(</span>run! prn<span>)))</span>
    <span>
=&gt;</span>
3
4
<span>...</span>
5
10
<span>...</span>
11
7
<span>...</span>
6
9
&#34;Elapsed time: 4019.565335 msecs&#34;

nil
</code></pre><p>Excellent we now get the results as they complete, whilst still respecting the rate limit. </p><p>All of this with zero dependencies. The power that Clojure&#39;s tight integration with the Java is really amazing.</p><p>The full example <a href="https://github.com/andersmurphy/clj-cookbook/tree/master/virtual-threads/managing-throughput">project can be found here</a>.</p><p><strong>Further reading:</strong></p><ul><li><a href="https://inside.java/2024/02/04/sip094/" title="">Managing Throughput with Virtual Threads - Sip of Java</a></li><li><a href="https://ericnormand.me/guide/clojure-virtual-threads">Virtual Threads in Clojure</a></li><li><a href="https://clojure.org/news/2024/04/28/clojure-1-12-alpha10#method_values">Clojure Method Values</a></li><li><a href="https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/concurrent/ExecutorCompletionService.html">ExecutorCompletionService</a></li><li><a href="https://docs.oracle.com/en/java/javase/21/docs/api/java.base/java/util/concurrent/Semaphore.html">Semaphore</a></li></ul><p><strong>Discussion:</strong></p><p><a href="https://news.ycombinator.com/item?id=40275997">Hacker News</a></p></article></div>
  </body>
</html>
