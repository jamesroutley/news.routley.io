<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://devblogs.microsoft.com/oldnewthing/20190830-00/?p=102823">Original</a>
    <h1>The sad history of Unicode printf-style format specifiers in Visual C&#43;&#43; (2019)</h1>
    
    <div id="readability-page-1" class="page"><div id="featured">

	<div>
                         <p>
            August 30th, 2019</p><!-- .entry-meta -->
        
<p>Windows adopted Unicode before most other operating systems.<sup>[citation needed]</sup> As a result, Windows’s solutions to many problems differ from solutions adopted by those who waited for the dust to settle.¹ The most notable example of this is that Windows used UCS-2 as the Unicode encoding. This was the encoding recommended by the Unicode Consortium because Unicode 1.0 supported only 65536 characters.² The Unicode Consortium changed their minds five years later, but by then it was far too late for Windows, which had already shipped Win32s, Windows NT 3.1, Windows NT 3.5, Windows NT 3.51, and Windows 95, all of which used UCS-2.³</p>
<p>But today we’re going to talk about <code>printf</code>-style format strings.</p>
<p>Windows adopted Unicode before the C language did. This meant that Windows had to invent Unicode support in the C runtime. The result was functions like <code>wcscmp</code>, <code>wcschr</code>, and <code>wprintf</code>. As for <code>printf</code>-style format strings, here’s what we ended up with:</p>
<ul>
<li>The <code>%s</code> format specifier represents a string in the same width as the format string.</li>
<li>The <code>%S</code> format specifier represents a string in the opposite width as the format string.</li>
<li>The <code>%hs</code> format specifier represents a narrow string regardless of the width of the format string.</li>
<li>The <code>%ws</code> and <code>%ls</code> format specifiers represent a wide string regardless of the width of the format string.</li>
</ul>
<p>The idea behind this pattern was so that you could write code like this:</p>
<pre>TCHAR buffer[256];
GetSomeString(buffer, 256);
_tprintf(TEXT(&#34;The string is %s.\n&#34;), buffer);
</pre>
<p>If the code is compiled as ANSI, the result is</p>
<pre>char buffer[256];
GetSomeStringA(buffer, 256);
printf(&#34;The string is %s.\n&#34;, buffer);
</pre>
<p>And if the code is compiled as Unicode, the result is⁴</p>
<pre>wchar_t buffer[256];
GetSomeStringW(buffer, 256);
wprintf(L&#34;The string is %s.\n&#34;, buffer);
</pre>
<p>By following the convention that <code>%s</code> takes a string in the same width as the format string itself, this code runs properly when compiled either as ANSI or as Unicode. It also makes converting existing ANSI code to Unicode much simpler, since you can keep using <code>%s</code>, and it will morph to do what you need.</p>
<p>When Unicode support formally arrived in C99, the C standard committee chose a different model for <code>printf</code> format strings.</p>
<ul>
<li>The <code>%s</code> and <code>%hs</code> format specifiers represent an narrow string.</li>
<li>The <code>%ls</code> format specifier represents a wide string.</li>
</ul>
<p>This created a problem. There were six years and untold billions of lines of code in the Windows ecosystem that used the old model. What should the Visual C and C++ compiler do?</p>
<p>They chose to stick with the existing nonstandard model, so as not to break every Windows program on the planet.</p>
<p>If you want your code to work both on runtimes that use the Windows classic <code>printf</code> rules as well as those that use C standard <code>printf</code> rules, you can limit yourself to <code>%hs</code> for narrow strings and <code>%ls</code> for wide strings, and you’ll get consistent results regardless of whether the format string was passed to <code>sprintf</code> or <code>wsprintf</code>.</p>
<pre>#ifdef UNICODE
#define TSTRINGWIDTH TEXT(&#34;l&#34;)
#else
#define TSTRINGWIDTH TEXT(&#34;h&#34;)
#endif

TCHAR buffer[256];
GetSomeString(buffer, 256);
_tprintf(TEXT(&#34;The string is %&#34;) TSTRINGWIDTH TEXT(&#34;s\n&#34;), buffer);

char buffer[256];
GetSomeStringA(buffer, 256);
printf(&#34;The string is %hs\n&#34;, buffer);

wchar_t buffer[256];
GetSomeStringW(buffer, 256);
wprintf(&#34;The string is %ls\n&#34;, buffer);
</pre>
<p>Encoding the <code>TSTRINGWIDTH</code> separately lets you do things like</p>
<pre>_tprintf(TEXT(&#34;The string is %10&#34;) TSTRINGWIDTH TEXT(&#34;s\n&#34;), buffer);
</pre>
<p>Since people like tables, here’s a table.</p>
<table>
<tbody>
<tr>
<th colspan="2">Format</th>
<th>Windows classic</th>
<th>C standard</th>
<td> </td>
</tr>
<tr>
<td><code>%s</code></td>
<td><code>printf</code></td>
<td><code>char*</code></td>
<td><code>char*</code></td>
<td>⇐</td>
</tr>
<tr>
<td><code>%s</code></td>
<td><code>wprintf</code></td>
<td><code>wchar_t*</code></td>
<td><code>char*</code></td>
</tr>
<tr>
<td><code>%S</code></td>
<td><code>printf</code></td>
<td><code>wchar_t*</code></td>
<td>N/A</td>
</tr>
<tr>
<td><code>%S</code></td>
<td><code>wprintf</code></td>
<td><code>char*</code></td>
<td>N/A</td>
</tr>
<tr>
<td><code>%hs</code></td>
<td><code>printf</code></td>
<td><code>char*</code></td>
<td><code>char*</code></td>
<td>⇐</td>
</tr>
<tr>
<td><code>%hs</code></td>
<td><code>wprintf</code></td>
<td><code>char*</code></td>
<td><code>char*</code></td>
<td>⇐</td>
</tr>
<tr>
<td><code>%ls</code></td>
<td><code>printf</code></td>
<td><code>wchar_t*</code></td>
<td><code>wchar_t*</code></td>
<td>⇐</td>
</tr>
<tr>
<td><code>%ls</code></td>
<td><code>wprintf</code></td>
<td><code>wchar_t*</code></td>
<td><code>wchar_t*</code></td>
<td>⇐</td>
</tr>
<tr>
<td><code>%ws</code></td>
<td><code>printf</code></td>
<td><code>wchar_t*</code></td>
<td>N/A</td>
</tr>
<tr>
<td><code>%ws</code></td>
<td><code>wprintf</code></td>
<td><code>wchar_t*</code></td>
<td>N/A</td>
</tr>
</tbody>
</table>
<p>I highlighted the rows where the C standard agrees with the Windows classic format.⁵ If you want your code to work the same under either format convention, you should stick to those rows.</p>
<p>¹ You’d think that adopting Unicode early would give Windows the first-mover advantage, but at least with respect to Unicode, it ended up being a first-mover disadvantage, because everybody else could sit back and wait for better solutions to emerge (such as UTF-8) before beginning their Unicode adoption efforts.</p>
<p>² I guess they thought that 65536 characters <a href="https://groups.google.com/forum/#!msg/alt.folklore.computers/mpjS-h4jpD8/9DW_VQVLzpkJ"> should be enough for anyone</a>.</p>
<p>³ This was later upgraded to UTF-16. Fortunately, UTF-16 is backward compatible with UCS-2 for the code points that are representable in both.</p>
<p>⁴ Technically, the Unicode version was</p>
<pre><span>unsigned short</span> buffer[256];
GetSomeStringW(buffer, 256);
wprintf(L&#34;The string is %s.\n&#34;, buffer);
</pre>
<p>because there was not yet a <code>wchar_t</code> as an independent type. Prior to the introduction of <code>wchar_t</code> to the standard, the <code>wchar_t</code> type was just a synonym for <code>unsigned short</code>. The changing fate of the <code>wchar_t</code> type <a href="https://devblogs.microsoft.com/oldnewthing/20161201-00/?p=94836"> has its own story</a>.</p>
<p>⁵ The Windows classic format came first, so the question is whether the C standard chose to align with the Windows classic format, rather than vice versa.</p>

        

		
        
	</div><!-- .entry-content -->

</div></div>
  </body>
</html>
