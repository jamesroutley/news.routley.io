<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/jamii/hytradboi-jam-2022">Original</a>
    <h1>Goal: Pass all 4259065 tests in sqllogictest in 1 week</h1>
    
    <div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><p dir="auto">Goal: Pass all 4259065 tests in <a href="https://www.sqlite.org/sqllogictest/doc/trunk/about.wiki" rel="nofollow">sqllogictest</a>. From scratch. No dependencies. No surrender.</p>
<h2 dir="auto"><a id="user-content-day-1" aria-hidden="true" href="#day-1"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Day 1</h2>
<p dir="auto">I wrote the test harness in advance, so my starting point on Monday morning was 4.2 million test failures.</p>
<div data-snippet-clipboard-copy-content="&gt; zig build test_slt -Drelease-safe=true -- $(rg --files deps/slt)
HashMap(
    error.Unimplemented =&gt; 4259065,
)
passes =&gt; 0"><pre><code>&gt; zig build test_slt -Drelease-safe=true -- $(rg --files deps/slt)
HashMap(
    error.Unimplemented =&gt; 4259065,
)
passes =&gt; 0
</code></pre></div>
<p dir="auto">Serious databases write their own parsers, but serious databases aren&#39;t finished in a week. We&#39;re going to need a shortcut. Let&#39;s grab this <a href="https://github.com/JakeWheat/sql-overview/blob/master/sql-2016-foundation-grammar.txt">bnf</a> extracted from the SQL 2016 spec.</p>
<p dir="auto">Only 9139 lines long.</p>
<p dir="auto">Also impossible to parse, because they don&#39;t escape tokens. Sometimes a <code>[</code> is just a <code>[</code>, but sometimes it opens an optional group.</p>
<div data-snippet-clipboard-copy-content="&lt;left bracket&gt; ::=
  [

&lt;less than operator&gt; ::=
  &lt;

&lt;identifier body&gt; ::=
  &lt;identifier start&gt; [ &lt;identifier part&gt;... ]"><pre><code>&lt;left bracket&gt; ::=
  [

&lt;less than operator&gt; ::=
  &lt;

&lt;identifier body&gt; ::=
  &lt;identifier start&gt; [ &lt;identifier part&gt;... ]
</code></pre></div>
<p dir="auto">Also check this out:</p>
<div data-snippet-clipboard-copy-content="&lt;national character large object type&gt; ::=
    NATIONAL CHARACTER LARGE OBJECT [ &lt;left paren&gt; &lt;character large object length&gt; &lt;right
    paren&gt; ]
  | NCHAR LARGE OBJECT [ &lt;left paren&gt; &lt;character large object length&gt; &lt;right paren&gt; ]
  | NCLOB [ &lt;left paren&gt; &lt;character large object length&gt; &lt;right paren&gt; ]"><pre><code>&lt;national character large object type&gt; ::=
    NATIONAL CHARACTER LARGE OBJECT [ &lt;left paren&gt; &lt;character large object length&gt; &lt;right
    paren&gt; ]
  | NCHAR LARGE OBJECT [ &lt;left paren&gt; &lt;character large object length&gt; &lt;right paren&gt; ]
  | NCLOB [ &lt;left paren&gt; &lt;character large object length&gt; &lt;right paren&gt; ]
</code></pre></div>
<p dir="auto">Yeah, they line-wrapped to 90 columns in the middle of <code>&lt;right paren&gt;</code>, so I have to strip excess whitespace from names after parsing them.</p>
<p dir="auto">So parsing the bnf is kind of a mess, but I only have to parse this one bnf and not bnfs in general so I just <a href="https://github.com/jamii/hytradboi-jam-2022/blob/2ce6ca692af647d32f830be7b9939bd1057fe18a/lib/sql/BnfParser.zig#L179-L219">mashed in a bunch of special cases</a>.</p>
<p dir="auto">I don&#39;t really have a way of looking at the result yet, but I at least <a href="https://github.com/jamii/hytradboi-jam-2022/blob/2ce6ca692af647d32f830be7b9939bd1057fe18a/lib/sql/BnfParser.zig#L134-L141">have the right number of definitions</a>.</p>
<p dir="auto">So now I just have to use the bnf to parse sql. I don&#39;t really know how to do that because I always just hand-write recursive descent parsers whenever I need to parse something.</p>
<p dir="auto">The sql grammar is <a href="https://en.wikipedia.org/wiki/Left_recursion#Removing_left_recursion" rel="nofollow">left-recursive</a> so I can&#39;t just go top-down or it will potentially loop forever. But there is a neat trick that I heard when working with <a href="https://xtdb.com/" rel="nofollow">xtdb</a> earlier this year. It&#39;s tricky to explain, but the intuition is similar to how <a href="https://en.wikipedia.org/wiki/Iterative_deepening_depth-first_search" rel="nofollow">iterative depth-first search</a> avoids getting stuck in infinitely deep search trees.</p>
<p dir="auto">So whenever we hit a rule that might be left-recursive, we make an entry in the cache that says &#34;parse failed&#34;. That forces it to explore other branches. If it manages to find some base case, we put that in the cache and try again to see if we can parse a bigger chunk of the input. If we ever get a result that is not better than the result already in the cache then there isn&#39;t any point exploring deeper trees.</p>
<p dir="auto"><a href="https://github.com/jamii/hytradboi-jam-2022/blob/2ce6ca692af647d32f830be7b9939bd1057fe18a/lib/sql/Parser.zig#L156-L182">Here&#39;s the core of that loop</a>. It took a while to debug the logic, but I think it makes sense now that I&#39;ve worked through it.</p>
<p dir="auto">It took a lot more debugging to start successfully parsing actual sql:</p>
<ul dir="auto">
<li>My bnf parser had the wrong binding power for <code>|</code>. I had to turn it into a slightly <a href="https://matklad.github.io/2020/04/13/simple-but-powerful-pratt-parsing.html" rel="nofollow">Pratt</a> parser to fix it.</li>
<li>The bnf from the spec doesn&#39;t describe actual sql that well (eg <code>select 1;</code> is invalid in the spec despite being accepted by every database since forever). So I&#39;ve had to start tweaking the bnf to get the sqlite tests to parse.</li>
</ul>
<p dir="auto">Here&#39;s where the scoreboard stands at the end of the day.</p>
<div data-snippet-clipboard-copy-content="&gt; time zig build test_slt -Drelease-safe=true -- $(rg --files deps/slt)
HashMap(
    error.Unimplemented =&gt; 172471,
    error.ParseError =&gt; 4086594,
)
passes =&gt; 0
________________________________________________________
Executed in   94.84 secs    fish           external
   usr time   94.33 secs    2.63 millis   94.33 secs
   sys time    0.53 secs    0.00 millis    0.53 secs"><pre><code>&gt; time zig build test_slt -Drelease-safe=true -- $(rg --files deps/slt)
HashMap(
    error.Unimplemented =&gt; 172471,
    error.ParseError =&gt; 4086594,
)
passes =&gt; 0
________________________________________________________
Executed in   94.84 secs    fish           external
   usr time   94.33 secs    2.63 millis   94.33 secs
   sys time    0.53 secs    0.00 millis    0.53 secs
</code></pre></div>
<p dir="auto">Tomorrow I&#39;ll start working through those parse failures. Probably I&#39;ll need to build a little gui debugger to help, because trying to read through printlns of all the productions of that massive grammar is not time efficient.</p>
<h2 dir="auto"><a id="user-content-day-2" aria-hidden="true" href="#day-2"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Day 2</h2>
<p dir="auto">I realized that I unthinkingly made the parser greedy. It will backtrack within an <code>either</code>, but if the first branch succeeds it will never go back to explore the second branch. That means when it hits something like <code>avg(c)</code> it parses the <code>avg</code> as an identifier and then can&#39;t backtrack to try to parse it as a function call later.</p>
<p dir="auto">SQL can be parsed with this minimal backtracking (that&#39;s how the materialize parser works) but the bnf grammar is not designed with this in mind and it would be way too much work to edit it by hand.</p>
<p dir="auto">I read a bunch about table driven parsers for arbitrary context-free grammars (because who knows what class of grammar this bnf is). Eventually I decided it would be safer to just add backtracking to the parser I already have, since that&#39;s a method I already understand.</p>
<p dir="auto">I flailed for a long while trying to figure out how to combine this with the memoized loop used for handling left-recursive definitions. Eventually I came up with what I think is a workable design, where the memoized value is stored on the parse stack and the loop works by adding backtrack points whenever the a recursive definition completes succesfully.</p>
<p dir="auto">I started on the implementation but at this point I&#39;m just staring at the screen and not making forward progress, so I&#39;m going to stop early and get some rest.</p>
<p dir="auto">My original plan looked like this:</p>
<ul dir="auto">
<li>sql parser (3 days)</li>
<li>name resolution (1 day)</li>
<li>type inference and lowering (1 day)</li>
<li>optimization and execution (1 day)</li>
<li>grind out the long tail of bugs (1 day)</li>
</ul>
<p dir="auto">I estimated 3 days to get the sql parser working because I&#39;ve been to sql-land before and I know what horrors lurk there, but I&#39;m a little worried now that it will take even longer.</p>
<h2 dir="auto"><a id="user-content-day-3" aria-hidden="true" href="#day-3"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Day 3</h2>
<p dir="auto">Yesterday I was trying to be all fancy make the backtracking actually backtrack (which is much harder when you don&#39;t have generators or lazy lists built into the language). Today I decided to just get on with it and generate every subparse. I got this working really quickly.</p>
<p dir="auto">Unfortunately, I then discovered that the bnf from the spec is wildly ambiguous. Check out the <a href="https://gist.github.com/jamii/2a497a867a5612adaac5536f290ac29c">7 different parses</a> for <code>select 1;</code>.</p>
<p dir="auto">I ran the thing against the whole test suite just to see how badly I&#39;m doing:</p>
<div data-snippet-clipboard-copy-content="HashMap(
    error.NoParse =&gt; 3971842,
    error.Unimplemented =&gt; 275660,
    error.AmbiguousParse =&gt; 11563,
)
passes =&gt; 0
________________________________________________________
Executed in   31.88 mins    fish           external
   usr time   31.77 mins    0.00 micros   31.77 mins
   sys time    0.10 mins  734.00 micros    0.10 mins"><pre><code>HashMap(
    error.NoParse =&gt; 3971842,
    error.Unimplemented =&gt; 275660,
    error.AmbiguousParse =&gt; 11563,
)
passes =&gt; 0
________________________________________________________
Executed in   31.88 mins    fish           external
   usr time   31.77 mins    0.00 micros   31.77 mins
   sys time    0.10 mins  734.00 micros    0.10 mins
</code></pre></div>
<p dir="auto">It&#39;s really slow because every complex query produces a bazillion parse trees. And it&#39;s still not parsing most of the tests correctly.</p>
<p dir="auto">Plus, even if I get this whole thing working, I have to then turn those awful parse trees into something sane.</p>
<p dir="auto">So... this is not going to work.</p>
<p dir="auto">I didn&#39;t want to roll my own parser because we did that at materialize and while it worked out fine, it&#39;s more than 10kloc of rust. If I was just directly transcribing it I would have to type at 5 characters per second for 24 straight hours. I looked around at some other databases and even the ones that use parser generators are huge:</p>
<div data-snippet-clipboard-copy-content="&gt; scc cockroachdb-parser/pkg/sql/scanner/ cockroachdb-parser/pkg/sql/parser/
-------------------------------------------------------------------------------
Language                 Files     Lines   Blanks  Comments     Code Complexity
-------------------------------------------------------------------------------
Go                           6      2305      202       356     1747        403
AWK                          4       243       27        73      143          0
Bazel                        2       183       11         9      163          0
Shell                        2        49       13         8       28          1
Happy                        1     14658      843         0    13815          0
Markdown                     1       284       65         0      219          0
gitignore                    1         8        1         2        5          0
-------------------------------------------------------------------------------
Total                       17     17730     1162       448    16120        404
-------------------------------------------------------------------------------
Estimated Cost to Develop (organic) $500,413
Estimated Schedule Effort (organic) 10.572043 months
Estimated People Required (organic) 4.205190
-------------------------------------------------------------------------------
Processed 506614 bytes, 0.507 megabytes (SI)
-------------------------------------------------------------------------------"><pre><code>&gt; scc cockroachdb-parser/pkg/sql/scanner/ cockroachdb-parser/pkg/sql/parser/
-------------------------------------------------------------------------------
Language                 Files     Lines   Blanks  Comments     Code Complexity
-------------------------------------------------------------------------------
Go                           6      2305      202       356     1747        403
AWK                          4       243       27        73      143          0
Bazel                        2       183       11         9      163          0
Shell                        2        49       13         8       28          1
Happy                        1     14658      843         0    13815          0
Markdown                     1       284       65         0      219          0
gitignore                    1         8        1         2        5          0
-------------------------------------------------------------------------------
Total                       17     17730     1162       448    16120        404
-------------------------------------------------------------------------------
Estimated Cost to Develop (organic) $500,413
Estimated Schedule Effort (organic) 10.572043 months
Estimated People Required (organic) 4.205190
-------------------------------------------------------------------------------
Processed 506614 bytes, 0.507 megabytes (SI)
-------------------------------------------------------------------------------
</code></pre></div>
<p dir="auto">Except sqlite, which has a tiny little grammar definition.</p>
<div data-snippet-clipboard-copy-content="&gt; scc sqlite/src/parse.y sqlite/tool/lemon.c sqlite/tool/lempar.c
-------------------------------------------------------------------------------
Language                 Files     Lines   Blanks  Comments     Code Complexity
-------------------------------------------------------------------------------
C                            2      6961      356      1195     5410        916
Happy                        1      1928      179         0     1749          0
-------------------------------------------------------------------------------
Total                        3      8889      535      1195     7159        916
-------------------------------------------------------------------------------
Estimated Cost to Develop (organic) $213,397
Estimated Schedule Effort (organic) 7.647269 months
Estimated People Required (organic) 2.479133
-------------------------------------------------------------------------------
Processed 285597 bytes, 0.286 megabytes (SI)
-------------------------------------------------------------------------------"><pre><code>&gt; scc sqlite/src/parse.y sqlite/tool/lemon.c sqlite/tool/lempar.c
-------------------------------------------------------------------------------
Language                 Files     Lines   Blanks  Comments     Code Complexity
-------------------------------------------------------------------------------
C                            2      6961      356      1195     5410        916
Happy                        1      1928      179         0     1749          0
-------------------------------------------------------------------------------
Total                        3      8889      535      1195     7159        916
-------------------------------------------------------------------------------
Estimated Cost to Develop (organic) $213,397
Estimated Schedule Effort (organic) 7.647269 months
Estimated People Required (organic) 2.479133
-------------------------------------------------------------------------------
Processed 285597 bytes, 0.286 megabytes (SI)
-------------------------------------------------------------------------------
</code></pre></div>
<p dir="auto">I only have to parse sqlite grammar, and even then probably only a fraction of it. So it looks like writing a parser generator might be plausible and by now it&#39;s really my only option if I want to get any tests passing at all.</p>
<p dir="auto">So here&#39;s my <a href="https://github.com/jamii/hytradboi-jam-2022/blob/29a6225c957a326adde81f02be3c47633f1ea84b/lib/sql/grammar.txt">grammar</a> so far. It&#39;s parsed by <a href="https://github.com/jamii/hytradboi-jam-2022/blob/29a6225c957a326adde81f02be3c47633f1ea84b/lib/sql/GrammarParser.zig">GrammarParser</a>. In theory I could do this at comptime, but until we get a <a href="https://github.com/ziglang/zig/issues/1291" data-hovercard-type="issue" data-hovercard-url="/ziglang/zig/issues/1291/hovercard">comptime allocator</a> that&#39;s going to be a yak shave and I am way too many yak shaves deep already. So I laboriously but reliably write out all the rules into <a href="https://github.com/jamii/hytradboi-jam-2022/blob/29a6225c957a326adde81f02be3c47633f1ea84b/lib/sql/grammar.zig">grammar.zig</a>.</p>
<p dir="auto">The <a href="https://github.com/jamii/hytradboi-jam-2022/blob/29a6225c957a326adde81f02be3c47633f1ea84b/lib/sql/Tokenizer.zig">Tokenizer</a> is written by hand and seems to be basically done - it runs without complaint on the entire test set. I might discover bugs there later, of course.</p>
<p dir="auto">The <a href="https://github.com/jamii/hytradboi-jam-2022/blob/29a6225c957a326adde81f02be3c47633f1ea84b/lib/sql/Parser.zig">Parser</a> is fun. There is a single parse function, but because it reads the rules from grammar.zig at compile time it gets specialized for each parse rule. Basically I got the same result as hand-generating the parser code, without having to splices a bunch of strings together. After the jam maybe I&#39;ll have some yak shave time to cut out grammar.zig entirely and do all the grammar stuff at comptime, and then it&#39;ll be a pretty sweet system.</p>
<p dir="auto">The best part about this is that I get really nice parse trees by generating rich types from the input grammar. <a href="https://github.com/jamii/hytradboi-jam-2022/blob/29a6225c957a326adde81f02be3c47633f1ea84b/lib/sql/grammar.zig#L442-L460">Eg</a>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="pub const anon_18 = ?distinct_or_all;
pub const anon_19 = ?from;
pub const anon_20 = ?where;
pub const anon_21 = ?group_by;
pub const anon_22 = ?having;
pub const anon_23 = ?window;
pub const anon_24 = ?order_by;
pub const anon_25 = ?limit;
pub const select = struct {
    distinct_or_all: *anon_18,
    result_columns: *result_columns,
    from: *anon_19,
    where: *anon_20,
    group_by: *anon_21,
    having: *anon_22,
    window: *anon_23,
    order_by: *anon_24,
    limit: *anon_25,
};"><pre><span>pub</span> <span>const</span> <span>anon_18</span> <span>=</span> <span>?</span><span>distinct_or_all</span>;
<span>pub</span> <span>const</span> <span>anon_19</span> <span>=</span> <span>?</span><span>from</span>;
<span>pub</span> <span>const</span> <span>anon_20</span> <span>=</span> <span>?</span><span>where</span>;
<span>pub</span> <span>const</span> <span>anon_21</span> <span>=</span> <span>?</span><span>group_by</span>;
<span>pub</span> <span>const</span> <span>anon_22</span> <span>=</span> <span>?</span><span>having</span>;
<span>pub</span> <span>const</span> <span>anon_23</span> <span>=</span> <span>?</span><span>window</span>;
<span>pub</span> <span>const</span> <span>anon_24</span> <span>=</span> <span>?</span><span>order_by</span>;
<span>pub</span> <span>const</span> <span>anon_25</span> <span>=</span> <span>?</span><span>limit</span>;
<span>pub</span> <span>const</span> <span>select</span> <span>=</span> <span>struct</span> {
    <span>distinct_or_all</span>: <span>*</span><span>anon_18</span>,
    <span>result_columns</span>: <span>*</span><span>result_columns</span>,
    <span>from</span>: <span>*</span><span>anon_19</span>,
    <span>where</span>: <span>*</span><span>anon_20</span>,
    <span>group_by</span>: <span>*</span><span>anon_21</span>,
    <span>having</span>: <span>*</span><span>anon_22</span>,
    <span>window</span>: <span>*</span><span>anon_23</span>,
    <span>order_by</span>: <span>*</span><span>anon_24</span>,
    <span>limit</span>: <span>*</span><span>anon_25</span>,
};</pre></div>
<p dir="auto">I still can&#39;t parse many of the tests because I haven&#39;t implemented expressions, operator precedence etc. So I&#39;m still stuck in parsing land. But I can see the light at the end of the tunnel now.</p>
<p dir="auto">And at least it&#39;s fast:</p>
<div data-snippet-clipboard-copy-content="&gt; time zig build test_slt -Drelease-safe=true -- $(rg --files deps/slt)
HashMap(
    error.ParseError =&gt; 4257825,
    error.Unimplemented =&gt; 1240,
)
passes =&gt; 0
________________________________________________________
Executed in   11.85 secs    fish           external
   usr time   11.49 secs    0.44 millis   11.49 secs
   sys time    0.39 secs    1.79 millis    0.39 secs"><pre><code>&gt; time zig build test_slt -Drelease-safe=true -- $(rg --files deps/slt)
HashMap(
    error.ParseError =&gt; 4257825,
    error.Unimplemented =&gt; 1240,
)
passes =&gt; 0
________________________________________________________
Executed in   11.85 secs    fish           external
   usr time   11.49 secs    0.44 millis   11.49 secs
   sys time    0.39 secs    1.79 millis    0.39 secs
</code></pre></div>
<p dir="auto">I&#39;m going to spend tomorrow fleshing out as much of the parsing as possible and then switch to trying to analyze and execute some of the simpler tests.</p>
<h2 dir="auto"><a id="user-content-day-4" aria-hidden="true" href="#day-4"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Day 4</h2>
<p dir="auto">I lost a lot of time in the morning to segfaults in the zig compiler. I eventually worked around it by moving more stuff from comptime to codegen.</p>
<p dir="auto">I fleshed out the parser and grammar a bunch more. I added memoization again to handle left recursion, as well as a ton of debugging output.</p>
<p dir="auto">I was making pretty good progress through parsing more and more queries when something I added caused some queries to loop seemingly forever in the parser. I&#39;ve been bangind my head against this for hours and getting nowhere.</p>
<p dir="auto">I suspect something in the interaction between memoization and the stack of expr_* types that handle precedence in the grammar. Maybe I&#39;ll figure it out tomorrow.</p>
<p dir="auto">It&#39;s not looking good for passing any tests at all, let alone all of them. The light at the end of the tunnel was a train.</p>
<hr/>
<p dir="auto">I figured it out at home.</p>
<p dir="auto">I was barking up totally the wrong tree. The <code>expr</code> grammar is actually not left-recursive after the changes I made, which means the memo is not being applied. But the memo was covering up the fact that I wrote the grammar in a silly way that required exponential time to parse with memoization.</p>
<p dir="auto">Which means I actually don&#39;t need memoization (which I spent most of today working on) at all for my grammar.</p>
<p dir="auto">This whole left-recursive memoization thing has been a total dead end. I should have stuck with techniques I&#39;m familiar with from the start. This is not the time to be trying experimental new things.</p>
<p dir="auto">The silver lining is this:</p>
<div data-snippet-clipboard-copy-content="HashMap(
    error.ParseError =&gt; 3725149,
    error.Unimplemented =&gt; 533916,
)
passes =&gt; 0
________________________________________________________
Executed in   50.07 secs    fish           external
   usr time   49.83 secs    1.75 millis   49.82 secs
   sys time    0.23 secs    1.90 millis    0.23 secs"><pre><code>HashMap(
    error.ParseError =&gt; 3725149,
    error.Unimplemented =&gt; 533916,
)
passes =&gt; 0
________________________________________________________
Executed in   50.07 secs    fish           external
   usr time   49.83 secs    1.75 millis   49.82 secs
   sys time    0.23 secs    1.90 millis    0.23 secs
</code></pre></div>
<p dir="auto">That&#39;s about 12.5% of the tests parsing!</p>

<p dir="auto">I made some changes to the parser generator, added a whole bunch of debugging tools to the parser itself and then sat down and cranked on the grammar till I can parse 100% of the tests. I&#39;m finally out of the damn tunnel.</p>
<p dir="auto">Then I sketched out a framework for planning and evaluation and filled out just enough to handle scalar-only queries.</p>
<div data-snippet-clipboard-copy-content="HashMap(
    error.NoPlan =&gt; 4066003,
)
skips =&gt; 3869887
passes =&gt; 193062
________________________________________________________
Executed in  121.77 secs    fish           external
   usr time  120.77 secs    0.02 millis  120.77 secs
   sys time    0.96 secs    1.01 millis    0.96 secs"><pre><code>HashMap(
    error.NoPlan =&gt; 4066003,
)
skips =&gt; 3869887
passes =&gt; 193062
________________________________________________________
Executed in  121.77 secs    fish           external
   usr time  120.77 secs    0.02 millis  120.77 secs
   sys time    0.96 secs    1.01 millis    0.96 secs
</code></pre></div>
<p dir="auto">4.5% of tests are passing!</p>
<p dir="auto">This is how I expected the week to go. Not death by bnf.</p>
<p dir="auto">The odds of hitting 100% now are very low - there is a long tail of weird behavior that I expected to have much more time to implement. But I think in the next two days I might be able to get to something respectable.</p>

<p dir="auto">Full steam ahead:</p>
<div data-snippet-clipboard-copy-content="total =&gt; 5939714
HashMap(
    error.TypeError =&gt; 198542,
    error.NoPlan =&gt; 2345772,
    error.StatementShouldError =&gt; 2,
    error.ParseError =&gt; 2,
    error.TestExpectedEqual =&gt; 9379,
    error.BadColumn =&gt; 42749,
)
skips =&gt; 127880
passes =&gt; 3215388 (= 54.13%)

________________________________________________________
Executed in  581.30 secs    fish           external
   usr time  258.12 secs  660.00 micros  258.12 secs
   sys time  342.46 secs  324.00 micros  342.46 secs"><pre><code>total =&gt; 5939714
HashMap(
    error.TypeError =&gt; 198542,
    error.NoPlan =&gt; 2345772,
    error.StatementShouldError =&gt; 2,
    error.ParseError =&gt; 2,
    error.TestExpectedEqual =&gt; 9379,
    error.BadColumn =&gt; 42749,
)
skips =&gt; 127880
passes =&gt; 3215388 (= 54.13%)

________________________________________________________
Executed in  581.30 secs    fish           external
   usr time  258.12 secs  660.00 micros  258.12 secs
   sys time  342.46 secs  324.00 micros  342.46 secs
</code></pre></div>
<p dir="auto">What are we looking at here?</p>
<p dir="auto"><strong>total =&gt; 5939714</strong>. Some tests are marked with tags like <code>onlyif sqlite</code> or <code>skipif sqlite</code>. Before I was only looking at tests with no tags (ie generic sql), but today I found out that tags are often used to split out setup code like:</p>
<div data-snippet-clipboard-copy-content="onlyif oracle
statement ok
CREATE TABLE foo(...funky oracle workaround...)

skipif oracle
statement ok
CREATE TABLE foo(...regular sql...)"><pre><code>onlyif oracle
statement ok
CREATE TABLE foo(...funky oracle workaround...)

skipif oracle
statement ok
CREATE TABLE foo(...regular sql...)
</code></pre></div>
<p dir="auto">I was skipping both, which left me with no table. So now I&#39;m doing any statements tagged with <code>skipif</code>, which leaves me with a lot more tests to pass.</p>
<p dir="auto"><strong>passes =&gt; 3215388 (= 54.13%)</strong>. That&#39;s a lot of progress.</p>
<p dir="auto"><strong>skips =&gt; 127880</strong>. Most of the slt files start with some statements to set up some data, followed by a bunch of data. If I know that I screwed up one of those statements, I still try to execute the queries but I assign any errors to the <code>skip</code> category so I&#39;m not debugging the wrong sql.</p>
<p dir="auto"><strong>error.NoPlan =&gt; 2345772</strong>. Things that my planner does not support yet.</p>
<p dir="auto"><strong>error.TypeError =&gt; 198542</strong>. Sqlite has some hilarious implicit type casts. I didn&#39;t implement these, so sometimes my queries fail when sqlite tries to eg add a boolean to a string. Some of these might also be from the planner miscounting columns though.</p>
<div data-snippet-clipboard-copy-content="sqlite&gt; select TRUE + &#34;foo&#34;;
1"><pre><code>sqlite&gt; select TRUE + &#34;foo&#34;;
1
</code></pre></div>
<p dir="auto"><strong>error.BadColumn =&gt; 42749</strong>. Sometimes I generate plans that refer to non-existent columns. I catch these during eval so that the bounds check doesn&#39;t kill my test run.</p>
<p dir="auto"><strong>error.TestExpectedEqual =&gt; 9379</strong>. I produced the wrong output for the test. Surprisingly few of these.</p>
<p dir="auto"><strong>error.ParseError =&gt; 2</strong>. I added a bunch of new tests, so I had to expand the grammar some more. I didn&#39;t catch everything.</p>
<p dir="auto"><strong>error.StatementShouldError =&gt; 2</strong>. Some statement was supposed to abort with an error but it didn&#39;t. This will probably screw up other tests in the same file.</p>
<hr/>
<p dir="auto">The major changes I made today were supporting most statements, almost all scalar expressions, SELECT/FROM/WHERE and some forms of non-correlated subqueries.</p>
<p dir="auto">I also added memory (via std.heap.GeneralPurposeAllocator) and cpu limits (via counting backwards branches) to evaluation, to prevent the odd bad plan from trashing my test run.</p>
<p dir="auto">With one day left to go I have to be strategic about what I support next. A few days ago I dumped a list of grammar rules by how many test cases they occur in. The list is probably a bit out of date with the new added tests, but hopefully directionally correct.</p>
<p dir="auto">The big ones I&#39;m missing are:</p>
<ul dir="auto">
<li>ORDER BY = 804266</li>
<li>JOIN = 143153</li>
<li>GROUP = 108561</li>
<li>subquery = 97229</li>
<li>function call = 57144</li>
<li>VIEW = 57144 (this is probably responsible for most of the skips though)</li>
<li>UNION/INTERSECT/EXCEPT = 20440</li>
<li>DELETE = 19877 (again, probably responsble for a lot of skips and/or wrong results)</li>
<li>CASE = 16811</li>
<li>HAVING = 13375</li>
</ul>
<p dir="auto">So tomorrow I&#39;ll probably just try and crank through features in that order and see where I end up.</p>
<h2 dir="auto"><a id="user-content-day-7" aria-hidden="true" href="#day-7"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Day 7</h2>
<p dir="auto">I completely rewrote the way name resolution works to handle the addition of all the weird edge cases in select_body. I can now handle stuff like <code>select a, count(a+1) as count, a+2 as c from foo where c &gt; 0 order by b, count</code>. (Think about what order those scalar expressions have to get executed in). I&#39;ll go into depth about that in the final writeup.</p>
<p dir="auto">Then I just cranked. I added way more detail to the error reports so I could priority sort missing features and then I typed a lot of code.</p>
<div data-snippet-clipboard-copy-content="&gt; git diff 3b25276a871f752a700e7a4942d51fd50ce63f5 --stat                                                nix-shell
 README.md             |    7 +
 lib/sql.zig           |   22 +-
 lib/sql/Evaluator.zig |  286 +++++++++++++++++++---
 lib/sql/Planner.zig   | 1097 ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++----------------
 lib/sql/grammar.txt   |    2 +-
 lib/sql/grammar.zig   |   21 +-
 test/slt.zig          |    9 +-
 7 files changed, 1188 insertions(+), 256 deletions(-)"><pre><code>&gt; git diff 3b25276a871f752a700e7a4942d51fd50ce63f5 --stat                                                nix-shell
 README.md             |    7 +
 lib/sql.zig           |   22 +-
 lib/sql/Evaluator.zig |  286 +++++++++++++++++++---
 lib/sql/Planner.zig   | 1097 ++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++++----------------
 lib/sql/grammar.txt   |    2 +-
 lib/sql/grammar.zig   |   21 +-
 test/slt.zig          |    9 +-
 7 files changed, 1188 insertions(+), 256 deletions(-)
</code></pre></div>
<p dir="auto">Funnily enough, it looks like I&#39;ve been averaging about 1000 lines per day:</p>
<div data-snippet-clipboard-copy-content="&gt; scc ./lib                                                                                              nix-shell
-------------------------------------------------------------------------------
Language                 Files     Lines   Blanks  Comments     Code Complexity
-------------------------------------------------------------------------------
Zig                          8      6476      185       106     6185        708
Plain Text                   3       390       17         0      373          0
-------------------------------------------------------------------------------
Total                       11      6866      202       106     6558        708
-------------------------------------------------------------------------------
Estimated Cost to Develop (organic) $194,627
Estimated Schedule Effort (organic) 7.384347 months
Estimated People Required (organic) 2.341581
-------------------------------------------------------------------------------
Processed 268876 bytes, 0.269 megabytes (SI)
-------------------------------------------------------------------------------"><pre><code>&gt; scc ./lib                                                                                              nix-shell
-------------------------------------------------------------------------------
Language                 Files     Lines   Blanks  Comments     Code Complexity
-------------------------------------------------------------------------------
Zig                          8      6476      185       106     6185        708
Plain Text                   3       390       17         0      373          0
-------------------------------------------------------------------------------
Total                       11      6866      202       106     6558        708
-------------------------------------------------------------------------------
Estimated Cost to Develop (organic) $194,627
Estimated Schedule Effort (organic) 7.384347 months
Estimated People Required (organic) 2.341581
-------------------------------------------------------------------------------
Processed 268876 bytes, 0.269 megabytes (SI)
-------------------------------------------------------------------------------
</code></pre></div>
<p dir="auto">I implemented ORDER BY, GROUP BY (without grouped columns), functions, aggregates, CASE, CAST, correlated IN, INNER/CROSS JOIN and various edge cases in sqlite&#39;s implicit coercions and comparisons.</p>
<p dir="auto">I got pretty damn close.</p>
<div data-snippet-clipboard-copy-content="&gt; zig build generate_grammar &amp;&amp; time zig build test_slt -Drelease-safe=true -- $(rg --files deps/slt | sort -h)
...
total =&gt; 5939714
HashMap(
    error.NoPlanOther =&gt; 133170,
    error.TestExpectedEqual =&gt; 16820,
    error.NoPlanExprAtom =&gt; 2848,
    error.OutOfJuice =&gt; 2162,
    error.WrongNumberOfColumnsReturned =&gt; 1681,
    error.NoPlanCompound =&gt; 1000,
    error.NoPlanConstraint =&gt; 550,
    error.NoPlanLeft =&gt; 191,
    error.BadEvalAggregate =&gt; 59,
    error.NoPlanStatement =&gt; 32,
    error.ParseError =&gt; 2,
    error.StatementShouldError =&gt; 2,
)
skips =&gt; 123015
passes =&gt; 5658182 (= 95.26%)

________________________________________________________
Executed in   18.64 mins    fish           external
   usr time  462.87 secs    0.00 micros  462.87 secs
   sys time  658.11 secs  891.00 micros  658.11 secs"><pre><code>&gt; zig build generate_grammar &amp;&amp; time zig build test_slt -Drelease-safe=true -- $(rg --files deps/slt | sort -h)
...
total =&gt; 5939714
HashMap(
    error.NoPlanOther =&gt; 133170,
    error.TestExpectedEqual =&gt; 16820,
    error.NoPlanExprAtom =&gt; 2848,
    error.OutOfJuice =&gt; 2162,
    error.WrongNumberOfColumnsReturned =&gt; 1681,
    error.NoPlanCompound =&gt; 1000,
    error.NoPlanConstraint =&gt; 550,
    error.NoPlanLeft =&gt; 191,
    error.BadEvalAggregate =&gt; 59,
    error.NoPlanStatement =&gt; 32,
    error.ParseError =&gt; 2,
    error.StatementShouldError =&gt; 2,
)
skips =&gt; 123015
passes =&gt; 5658182 (= 95.26%)

________________________________________________________
Executed in   18.64 mins    fish           external
   usr time  462.87 secs    0.00 micros  462.87 secs
   sys time  658.11 secs  891.00 micros  658.11 secs
</code></pre></div>
<p dir="auto">Man, if I hadn&#39;t spent more than half the week in that parsing rabbit hole I really think I might have made it to 100%. But this&#39;ll do.</p>
</article>
          </div></div>
  </body>
</html>
