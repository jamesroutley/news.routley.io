<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://topicpartition.io/blog/postgres-pubsub-queue-benchmarks">Original</a>
    <h1>Kafka is Fast ‚Äì I&#39;ll use Postgres</h1>
    
    <div id="readability-page-1" class="page"><article>
<p>I feel like the tech world lives in two camps.</p>
<ol>
<li>One camp chases buzzwords.</li>
</ol>
<p>This camp tends to adopt whatever‚Äôs popular without thinking hard about whether it‚Äôs appropriate. They tend to fall for all the purported benefits the sales pitch gives them - real-time, infinitely scale, cutting-edge, cloud-native, serverless, zero-trust, AI-powered, etc.</p>
<p>You see this everywhere in the Kafka world: Streaming Lakehouse‚Ñ¢Ô∏è, Kappa‚Ñ¢Ô∏è Architecture, Streaming AI Agents<sup><a href="#user-content-fn-1" id="user-content-fnref-1" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup>.</p>
<p>This phenomenon is sometimes known as <em>resume-driven design</em>. Modern practices actively encourage this. Consultants push ‚Äúinnovative architectures‚Äù stuffed with vendor tech via ‚Äúinsight‚Äù reports<sup><a href="#user-content-fn-5" id="user-content-fnref-5" data-footnote-ref="" aria-describedby="footnote-label">2</a></sup>. System design interviews expect you to design Google-scale architectures that are inevitably at a scale 100x higher than the company you‚Äôre interviewing for would ever need. Career progression rewards you for replatforming to the Hot New Stack‚Ñ¢Ô∏è, not for being resourceful.</p>
<ol start="2">
<li>The other camp chases common sense</li>
</ol>
<p>This camp is far more pragmatic. They strip away unnecessary complexity and steer clear of overengineered solutions. They reason from first principles before making technology choices. They resist marketing hype and approach vendor claims with healthy skepticism.</p>
<p>Historically, it has felt like Camp 1 definitively held the upper hand in sheer numbers and noise. Today, it feels like the pendulum may be beginning to swing back, at least a tiny bit. Two recent trends are on the side of Camp 2:</p>
<p>Trend 1 - the ‚Äú<a href="https://topicpartition.io/Small-Data" data-slug="Small-Data">Small Data</a>‚Äù movement. People are realizing two things - their data isn‚Äôt that big and their computers are becoming big too. You can rent a <a href="https://instances.vantage.sh/aws/ec2/x1e.xlarge">128-core, 4 TB of RAM instance<svg aria-hidden="true" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> from AWS. AMD just released 192-core CPUs this summer. That ought to be enough for anybody.<sup><a href="#user-content-fn-4" id="user-content-fnref-4" data-footnote-ref="" aria-describedby="footnote-label">3</a></sup></p>
<p>Trend 2 - the Postgres Renaissance. The space is seeing incredible growth and investment<sup><a href="#user-content-fn-3" id="user-content-fnref-3" data-footnote-ref="" aria-describedby="footnote-label">4</a></sup>. In the last 2 years, the phrase <a href="https://github.com/Olshansk/postgres_for_everything">‚ÄúJust Use Postgres (for everything)‚Äù<svg aria-hidden="true" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> has gained a ton of popularity. The basic premise is that you shouldn‚Äôt complicate things with new tech when you don‚Äôt need to, and that Postgres alone solves most problems pretty well. Postgres competes with purpose-built solutions like:</p>
<ul>
<li>Elasticsearch (functionality supported by Postgres‚Äô <code>tsvector</code>/<code>tsquery</code>)</li>
<li>MongoDB (<code>jsonb</code>)</li>
<li>Redis (<code>CREATE UNLOGGED TABLE</code>)</li>
<li>AI Vector Databases (<code>pgvector</code>, <code>pgai</code>)</li>
<li>Snowflake (<code>pg_mooncake</code>, <code>pg_duckdb</code>)</li>
</ul>
<p>and‚Ä¶ Kafka (this blog).</p>
<p>The claim isn‚Äôt that Postgres is functionally equivalent to any of these specialized systems. The claim is that it handles 80%+ of their use cases with 20% of the development effort. (Pareto Principle)</p>
<p>When you combine the two trends, the appeal becomes obvious. Postgres is a battle-tested, well-known system that is simple, scalable and reliable. Pair it with today‚Äôs powerful hardware and you quickly begin to realize that, more often than not, you do not need the state-of-the-art highly optimized and complex distributed system in order to handle your organization‚Äôs scale.</p>
<p><a href="https://bento.me/stanislavkozlovski">Despite being somebody who is biased towards Kafka<svg aria-hidden="true" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, I tend to agree. Kafka is similar to Postgres in that it‚Äôs stable, mature, battle-tested and boasts a strong community. It also scales a lot further. Despite that, I don‚Äôt think it‚Äôs the right choice for a lot of cases. Very often I see it get adopted where <a href="https://www.reddit.com/r/apachekafka/comments/1o7gbyg/controlling_llm_outputs_with_kafka_schema/">it doesn‚Äôt make sense<svg aria-hidden="true" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>.</p>
<p><strong>A 500 KB/s workload should not use Kafka.</strong> There is a scalability cargo cult in tech that always wants to choose ‚Äúthe best possible‚Äù tech for a problem - but this misses the forest for the trees. The ‚Äúbest possible‚Äù solution frequently isn‚Äôt a technical question - it‚Äôs a practical one. Adriano makes an airtight case for why you should opt for <strong>simple tech</strong> in his <a href="https://adriano.fyi/posts/2023-09-24-choose-postgres-queue-technology">PG as Queue blog<svg aria-hidden="true" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> (2023) that originally inspired me to write this.</p>
<p>Enough background. In this article, we will do three simple things:</p>
<ol>
<li>Benchmark how far Postgres can scale for pub/sub messaging - <a href="#pg-as-a-pubsub"># PG as a Pub/Sub</a></li>
<li>Benchmark how far Postgres can scale for queueing - <a href="#pg-as-a-queue"># PG as a Queue</a></li>
<li>Concisely touch upon when Postgres can be a fit for these use cases - <a href="#should-you-use-postgres"># Should You Use Postgres?</a></li>
</ol>
<p>I am not aiming for an exhaustive in-depth evaluation. Benchmarks are messy af. Rather, my goal is to publish some reasonable data points which can start a discussion.</p>
<p><em>(while this article is for Postgres, feel free to replace it with your database of choice)</em></p>
<hr/>

<p>If you‚Äôd like to skip straight to the results, here they are:</p>
<details>
  <summary>üî• The Benchmark Results</summary>
<h3 id="pub-sub-results">Pub-Sub Results<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#pub-sub-results"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>

































<div><table><thead><tr><th>Setup</th><th>‚úçÔ∏è <strong>Write</strong></th><th>üìñ <strong>Read</strong></th><th>üî≠ <strong>e2e Latency<sup><a href="#user-content-fn-9" id="user-content-fnref-9" data-footnote-ref="" aria-describedby="footnote-label">5</a></sup> (p99)</strong></th><th>Notes</th></tr></thead><tbody><tr><td><strong>1√ó c7i.xlarge</strong></td><td><strong>4.8 MiB/s</strong></td><td><strong>24.6 MiB/s</strong> (5x fanout)</td><td><strong>60 ms</strong></td><td>~60 % CPU; 4 partitions</td></tr><tr><td><strong>3√ó c7i.xlarge (replicated)</strong></td><td><strong>4.9 MiB/s</strong></td><td><strong>24.5 MiB/s</strong> (5x fanout)</td><td><strong>186 ms</strong></td><td>~65 % CPU; cross-AZ RF‚âà2.5; 4 partitions</td></tr><tr><td><strong>1√ó c7i.24xlarge</strong></td><td><strong>238 MiB/s</strong></td><td><strong>1.16 GiB/s</strong> (5x fanout)</td><td><strong>853 ms</strong></td><td>~10 % CPU (idle); 30 partitions</td></tr></tbody></table></div>
<h3 id="queue-results">Queue Results<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#queue-results"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>





























<div><table><thead><tr><th>Setup</th><th>üì¨ <strong>Throughput (read + write)</strong></th><th>üî≠ <strong>e2e Latency<sup><a href="#user-content-fn-9" id="user-content-fnref-9-2" data-footnote-ref="" aria-describedby="footnote-label">5</a></sup> (p99)</strong></th><th>Notes</th></tr></thead><tbody><tr><td><strong>1√ó c7i.xlarge</strong></td><td><strong>2.81 MiB/s</strong></td><td><strong>17.7 ms</strong></td><td>~60 % CPU; read-client bottleneck</td></tr><tr><td><strong>3√ó c7i.xlarge (replicated)</strong></td><td><strong>2.34 MiB/s</strong></td><td><strong>920 ms ‚ö†Ô∏è<sup><a href="#user-content-fn-19" id="user-content-fnref-19" data-footnote-ref="" aria-describedby="footnote-label">6</a></sup></strong></td><td>replication lag inflated E2E latency</td></tr><tr><td><strong>1√ó c7i.24xlarge</strong></td><td><strong>19.7 MiB/s</strong></td><td><strong>930 ms ‚ö†Ô∏è<sup><a href="#user-content-fn-19" id="user-content-fnref-19-2" data-footnote-ref="" aria-describedby="footnote-label">6</a></sup></strong></td><td>~50 % CPU; single-table bottleneck</td></tr></tbody></table></div>
<p>Make sure to at least read the last section of the article where we philosophize - <a href="#should-you-use-postgres"># Should You Use Postgres?</a></p>
</details>
<hr/>

<p>There are dozens of blogs out there using Postgres as a <u>queue</u>, but interestingly enough I haven‚Äôt seen one use it as a pub-sub messaging system.</p>
<p>A quick distinction between the two because I often see them get confused:</p>
<ol>
<li>
<p><strong>Queues</strong> are meant for point-to-point communication. They‚Äôre widely used for asynchronous background jobs: worker apps (clients) process a task in the queue like sending an e-mail or pushing a notification. The event is consumed once and it‚Äôs done with. A message is immediately deleted (popped) off the queue once it‚Äôs consumed. Queues do not have strict ordering guarantees<sup><a href="#user-content-fn-6" id="user-content-fnref-6" data-footnote-ref="" aria-describedby="footnote-label">7</a></sup>.</p>
</li>
<li>
<p><strong>Pub-sub</strong> messaging differs from the queue in that it is meant for one-to-many communication. This inherently means there is a large read fanout - more than one reader client is interested in any given message. Good pub-sub systems decouple readers from writers by storing data on disks. This allows them to not impose a max queue depth limit - something in-memory queues need to do in order to prevent them from going OOM.</p>
<p>There is also a general expectation that there is strict order - events should be read in the same order that they arrived in the system.</p>
</li>
</ol>
<p>Postgres‚Äô main competitor here is Kafka, which is the standard in pub-sub today. Various (mostly-proprietary) alternatives exist.<sup><a href="#user-content-fn-13" id="user-content-fnref-13" data-footnote-ref="" aria-describedby="footnote-label">8</a></sup></p>
<p>Kafka uses the Log data structure to hold messages. You‚Äôll see my benchmark basically reconstructs a log from Postgres primitives.</p>
<p>Postgres doesn‚Äôt seem to have any popular libraries for pub-sub<sup><a href="#user-content-fn-27" id="user-content-fnref-27" data-footnote-ref="" aria-describedby="footnote-label">9</a></sup> use cases, so I had to write my own. The Kafka-inspired workflow I opted for is this:</p>
<ol>
<li>Writers produce batches of messages per statement<sup><a href="#user-content-fn-20" id="user-content-fnref-20" data-footnote-ref="" aria-describedby="footnote-label">10</a></sup> (<code>INSERT INTO</code>). Each transaction carries one batch insert and targets a single <code>topicpartition</code> table<sup><a href="#user-content-fn-14" id="user-content-fnref-14" data-footnote-ref="" aria-describedby="footnote-label">11</a></sup></li>
<li>Each writer is sticky to one table, but in aggregate they produce to multiple tables.</li>
<li>Each message has a unique monotonically-increasing offset number. A specific row in a special <code>log_counter</code> table denotes the latest offset for a given <code>topicpartition</code> table.</li>
<li>Write transactions atomically update both the <code>topicpartition</code> data and the <code>log_counter</code> row. This ensures consistent offset tracking across concurrent writers.</li>
<li>Readers poll for new messages. They consume the <code>topicpartition</code> table(s) sequentially, starting from the lowest offset and progressively reading up.</li>
<li>Readers are split into consumer groups. Each group performs separate, independent reads and makes progress on the <code>topicpartition</code> tables.</li>
<li>Each group contains 1 reader per <code>topicpartition</code> table.</li>
<li>Readers store their progress in a <code>consumer_offsets</code> table, with a row for each <code>topicpartition,group</code> pair.</li>
<li>Each reader updates the latest processed offset (claiming the records), selects the records and processes them inside a single transaction.</li>
</ol>
<p>This ensures Kafka-like semantics - gapless, monotonically-increasing offsets and at-least-once/at-most-once processing. This test in particular uses at-least-once semantics, but neither choice should impact the benchmark results.</p>
<h2 id="pub-sub-setup">Pub-Sub Setup<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#pub-sub-setup"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<h4 id="table">Table<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#table"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h4>
<figure data-rehype-pretty-code-figure=""><pre tabindex="0" data-language="sql" data-theme="github-light github-dark"><code data-language="sql" data-theme="github-light github-dark"><span data-line=""><span>CREATE</span><span> TABLE</span><span> log_counter</span><span> (</span></span>
<span data-line=""><span>  id           </span><span>INT</span><span> PRIMARY KEY</span><span>, </span><span>-- topicpartition table name id</span></span>
<span data-line=""><span>  next_offset  </span><span>BIGINT</span><span> NOT NULL</span><span>  -- next offset to assign</span></span>
<span data-line=""><span>);</span></span>
<span data-line=""> </span>
<span data-line=""><span>for</span><span> i </span><span>in</span><span> NUM_PARTITIONS:</span></span>
<span data-line=""><span>  CREATE</span><span> TABLE</span><span> topicpartition</span><span>%d (</span></span>
<span data-line=""><span>    id          </span><span>BIGSERIAL</span><span> PRIMARY KEY</span><span>,</span></span>
<span data-line=""><span>    -- strictly increasing offset (indexed by UNIQUE)</span></span>
<span data-line=""><span>    c_offset    </span><span>BIGINT</span><span> UNIQUE</span><span> NOT NULL</span><span>,</span></span>
<span data-line=""><span>    payload     </span><span>BYTEA</span><span> NOT NULL</span><span>,</span></span>
<span data-line=""><span>    created_at  </span><span>TIMESTAMPTZ</span><span> NOT NULL</span><span> DEFAULT</span><span> now</span><span>()</span></span>
<span data-line=""><span>  );</span></span>
<span data-line=""><span>  INSERT INTO</span><span> log_counter(id, next_offset) </span><span>VALUES</span><span> (%d, </span><span>1</span><span>);</span></span>
<span data-line=""> </span>
<span data-line=""><span>CREATE</span><span> TABLE</span><span> consumer_offsets</span><span> (</span></span>
<span data-line=""><span>  group_id     </span><span>TEXT</span><span> NOT NULL</span><span>,     </span><span>-- consumer group identifier</span></span>
<span data-line=""><span>  -- topic-partition id (matches log_counter.id / topicpartitionN)</span></span>
<span data-line=""><span>  topic_id     </span><span>INT</span><span>  NOT NULL</span><span>,</span></span>
<span data-line=""><span>  -- next offset the consumer group should claim</span></span>
<span data-line=""><span>  next_offset  </span><span>BIGINT</span><span> NOT NULL</span><span> DEFAULT</span><span> 1</span><span>,</span></span>
<span data-line=""><span>  PRIMARY KEY</span><span> (group_id, topic_id)</span></span>
<span data-line=""><span>);</span></span></code></pre></figure>
<h4 id="writes">Writes<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#writes"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h4>
<p>The benchmark runs <code>N</code> writer goroutines. These represent writer clients.
Each one loops and atomically inserts <code>$BATCH_SIZE</code> records while updating the latest offset:</p>
<figure data-rehype-pretty-code-figure=""><pre tabindex="0" data-language="sql" data-theme="github-light github-dark"><code data-language="sql" data-theme="github-light github-dark"><span data-line=""><span>WITH</span><span> reserve </span><span>AS</span><span> (</span></span>
<span data-line=""><span>  UPDATE</span><span> log_counter</span></span>
<span data-line=""><span>  SET</span><span> next_offset </span><span>=</span><span> next_offset </span><span>+</span><span> $</span><span>1</span></span>
<span data-line=""><span>  WHERE</span><span> id </span><span>=</span><span> $</span><span>3</span><span>::</span><span>int</span></span>
<span data-line=""><span>  RETURNING (next_offset </span><span>-</span><span> $</span><span>1</span><span>) </span><span>AS</span><span> first_off</span></span>
<span data-line=""><span>)</span></span>
<span data-line=""> </span>
<span data-line=""><span>INSERT INTO</span><span> topicpartition%d(c_offset, payload)</span></span>
<span data-line=""><span>SELECT</span><span> r</span><span>.</span><span>first_off</span><span> +</span><span> p</span><span>.</span><span>ord</span><span> -</span><span> 1</span><span>, </span><span>p</span><span>.</span><span>payload</span></span>
<span data-line=""><span>FROM</span><span> reserve r,</span></span>
<span data-line=""><span>     unnest($</span><span>2</span><span>::</span><span>bytea</span><span>[]) </span><span>WITH</span><span> ORDINALITY </span><span>AS</span><span> p(payload, ord);</span></span></code></pre></figure>
<h4 id="reads">Reads<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#reads"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h4>
<p>The benchmark also runs <code>N</code> reader goroutines. Each reader is assigned a particular consumer group and partition. The group as a whole reads all partitions while each reader in the group reads only one partition at a time.</p>
<p>The reader loops, opens a transaction, optimistically claims <code>$BATCH_SIZE</code> records (by advancing the offset mark beyond them), selects them and processes the records.
If successful, it commits the transaction and through that advances the offset for the group.</p>
<p>It is a pull-based read (just like Kafka), rather than push-based. If the reader has no records to poll, it sleeps for a bit.</p>
<p>First it opens a transaction:</p>
<figure data-rehype-pretty-code-figure=""><pre tabindex="0" data-language="sql" data-theme="github-light github-dark"><code data-language="sql" data-theme="github-light github-dark"><span data-line=""><span>BEGIN</span><span> TRANSACTION</span></span></code></pre></figure>
<p>Then it claims the offsets:</p>
<figure data-rehype-pretty-code-figure=""><pre tabindex="0" data-language="sql" data-theme="github-light github-dark"><code data-language="sql" data-theme="github-light github-dark"><span data-line=""><span>WITH</span><span> counter_tip </span><span>AS</span><span> (</span></span>
<span data-line=""><span>  SELECT</span><span> (next_offset </span><span>-</span><span> 1</span><span>) </span><span>AS</span><span> highest_committed_offset</span></span>
<span data-line=""><span>  FROM</span><span> log_counter</span></span>
<span data-line=""><span>  WHERE</span><span> id </span><span>=</span><span> $</span><span>3</span><span>::</span><span>int</span><span> -- partition id</span></span>
<span data-line=""><span>),</span></span>
<span data-line=""> </span>
<span data-line=""><span>-- select &amp; lock the particular group&lt;-&gt;topic_partition&lt;-&gt;offset pair</span></span>
<span data-line=""><span>to_claim </span><span>AS</span><span> (</span></span>
<span data-line=""><span>  SELECT</span></span>
<span data-line=""><span>    c</span><span>.</span><span>group_id</span><span>,</span></span>
<span data-line=""><span>    c</span><span>.</span><span>next_offset</span><span> AS</span><span> n0, </span><span>-- old start offset pointer before update</span></span>
<span data-line=""><span>    -- takes the min of the batch size</span></span>
<span data-line=""><span>    -- or the current offset delta w.r.t the tip of the log</span></span>
<span data-line=""><span>    LEAST</span><span>(</span></span>
<span data-line=""><span>      $</span><span>2</span><span>::</span><span>bigint</span><span>, </span><span>-- BATCH_SIZE</span></span>
<span data-line=""><span>      GREATEST</span><span>(</span><span>0</span><span>,</span></span>
<span data-line=""><span>        (</span><span>SELECT</span><span> highest_committed_offset </span><span>FROM</span><span> counter_tip) </span><span>-</span><span> c</span><span>.</span><span>next_offset</span><span> +</span><span> 1</span><span>)</span></span>
<span data-line=""><span>    ) </span><span>AS</span><span> delta</span></span>
<span data-line=""><span>  FROM</span><span> consumer_offsets c</span></span>
<span data-line=""><span>  WHERE</span><span> c</span><span>.</span><span>group_id</span><span> =</span><span> $</span><span>1</span><span>::</span><span>text</span><span> AND</span><span> c</span><span>.</span><span>topic_id</span><span> =</span><span> $</span><span>3</span><span>::</span><span>int</span></span>
<span data-line=""><span>  FOR</span><span> UPDATE</span></span>
<span data-line=""><span>),</span></span>
<span data-line=""> </span>
<span data-line=""><span>-- atomically select + update the offset</span></span>
<span data-line=""><span>upd </span><span>AS</span><span> (</span></span>
<span data-line=""><span>  UPDATE</span><span> consumer_offsets c</span></span>
<span data-line=""><span>  SET</span><span> next_offset </span><span>=</span><span> c</span><span>.</span><span>next_offset</span><span> +</span><span> t</span><span>.</span><span>delta</span></span>
<span data-line=""><span>  FROM</span><span> to_claim t</span></span>
<span data-line=""><span>  WHERE</span><span> c</span><span>.</span><span>group_id</span><span> =</span><span> t</span><span>.</span><span>group_id</span><span> AND</span><span> c</span><span>.</span><span>topic_id</span><span> =</span><span> $</span><span>3</span><span>::</span><span>int</span></span>
<span data-line=""><span>  RETURNING</span></span>
<span data-line=""><span>    t</span><span>.</span><span>n0</span><span> AS</span><span> claimed_start_offset, </span><span>-- start = the old next_offset</span></span>
<span data-line=""><span>    (</span><span>c</span><span>.</span><span>next_offset</span><span> -</span><span> 1</span><span>) </span><span>AS</span><span> claimed_end_offset </span><span>-- end   = new pointer - 1</span></span>
<span data-line=""><span>)</span></span>
<span data-line=""> </span>
<span data-line=""><span>SELECT</span><span> claimed_start_offset, claimed_end_offset</span></span>
<span data-line=""><span>FROM</span><span> upd;</span></span></code></pre></figure>
<p>Followed by selecting the claimed records:</p>
<figure data-rehype-pretty-code-figure=""><pre tabindex="0" data-language="sql" data-theme="github-light github-dark"><code data-language="sql" data-theme="github-light github-dark"><span data-line=""><span>SELECT</span><span> c_offset, payload, created_at</span></span>
<span data-line=""><span>  FROM</span><span> topicpartition%d</span></span>
<span data-line=""><span>  WHERE</span><span> c_offset </span><span>BETWEEN</span><span> $</span><span>1</span><span> AND</span><span> $</span><span>2</span></span>
<span data-line=""><span>  ORDER BY</span><span> c_offset</span></span></code></pre></figure>
<p>Finally, the data gets processed by the business logic (no-op in our benchmark) and the transaction is closed:</p>
<figure data-rehype-pretty-code-figure=""><pre tabindex="0" data-language="sql" data-theme="github-light github-dark"><code data-language="sql" data-theme="github-light github-dark"><span data-line=""><span>COMMIT</span><span>;</span></span></code></pre></figure>
<p>If you‚Äôre wondering <em>‚Äúwhy no <code>NOTIFY/LISTEN</code>?‚Äù</em> - my understanding of that feature is that it‚Äôs an optimization and cannot be fully relied upon, so polling is required either way<sup><a href="#user-content-fn-21" id="user-content-fnref-21" data-footnote-ref="" aria-describedby="footnote-label">12</a></sup>. Given that, I just copied Kafka‚Äôs relatively simple design.</p>
<h2 id="pub-sub-results-1">Pub-Sub Results<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#pub-sub-results-1"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>The full code and detailed results are all published on GitHub at <a href="https://github.com/stanislavkozlovski/pg-queue-pubsub-benchmark">stanislavkozlovski/pg-queue-pubsub-benchmark<svg aria-hidden="true" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>.
I ran three setups - a single-node 4 vCPU, a 3-node replicated 4 vCPU and a single-node 96 vCPU setup. Here are the summarized results for each:</p>
<h3 id="4-vcpu-single-node">4 vCPU Single Node<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#4-vcpu-single-node"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p><small><em>The results are the average of three 2-minute tests.</em></small>
<small><em><a href="https://github.com/stanislavkozlovski/pg-queue-pubsub-benchmark/blob/e6ccbd9a3dd7eb64e6498fcccc251095584ea0cc/results/pubsub/4vcpu/single_node/4vcpu.md">[full results link]<svg aria-hidden="true" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></em></small></p>
<p><strong>Setup:</strong></p>
<ul>
<li><a href="https://instances.vantage.sh/aws/ec2/c7i.xlarge">c7i.xlarge<svg aria-hidden="true" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> Postgres server /w 25GB gp3 9000 IOPS EBS volume</li>
<li>mostly default Postgres settings (synchronous commit, fsync);
<ul>
<li><code>autovacuum_analyze_scale_factor = 0.05</code> set on the partition tables too (unclear if it has an effect)</li>
</ul>
</li>
<li>each row‚Äôs payload is 1 KiB (1024 bytes)</li>
<li>4 topicpartition tables</li>
<li>10 writers (2 writers per partition on average)</li>
<li>5x read fanout via 5 consumer groups</li>
<li>20 reader clients total (4 readers per group)</li>
<li>write batch size: 100 records</li>
<li>read batch size: 200 records</li>
</ul>
<p><strong>Results:</strong></p>
<ul>
<li>
<p>write message rate: <strong>5036 msg/s</strong></p>
</li>
<li>
<p>write throughput: <strong>4.8 MiB/s</strong></p>
</li>
<li>
<p>write latency: 38.7ms p99 / 6.2ms p95</p>
</li>
<li>
<p>read message rate: <strong>25,183 msg/s</strong></p>
</li>
<li>
<p>read message throughput: <strong>24.6 MiB/s</strong></p>
</li>
<li>
<p>read latency: 27.3ms p99 (varied 8.9ms-47ms b/w runs); 4.67ms p95</p>
</li>
<li>
<p>end-to-end latency<sup><a href="#user-content-fn-9" id="user-content-fnref-9-3" data-footnote-ref="" aria-describedby="footnote-label">5</a></sup>: <strong>60ms p99</strong> / 10.6ms p95</p>
</li>
<li>
<p>server kept at ~60% CPU;</p>
</li>
<li>
<p>disk was at ~1200 writes/s with iostat claiming 46 MiB/s</p>
</li>
</ul>
<p>These are pretty good results. It‚Äôs funny to think that the majority of people run a complex distributed system like Kafka for similar workloads<sup><a href="#user-content-fn-24" id="user-content-fnref-24" data-footnote-ref="" aria-describedby="footnote-label">13</a></sup>.</p>
<h3 id="4-vcpu-tri-node">4 vCPU Tri-Node<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#4-vcpu-tri-node"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>Now, a replicated setup to more accurately mimic the durability and availability guarantees of Kafka.</p>
<p><small><em>The average of two 5-minute tests.</em></small>
<small><em><a href="https://github.com/stanislavkozlovski/pg-queue-pubsub-benchmark/blob/8164907ba0f1afa6bfec3b402950217f31952d2a/results/pubsub/4vcpu/three_node/4vcpu_replicated.md">[full results link]<svg aria-hidden="true" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></em></small></p>
<p><strong>Setup:</strong></p>
<ul>
<li>3x <a href="https://instances.vantage.sh/aws/ec2/c7i.xlarge">c7i.xlarge<svg aria-hidden="true" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> Postgres servers /w 25GB gp3 9000 IOPS EBS volume
<ul>
<li>each on a separate AZ (us-east-1a, us-east-1b, us-east-1c)</li>
<li>one <code>sync</code> replica and one <code>potential</code><sup><a href="#user-content-fn-22" id="user-content-fnref-22" data-footnote-ref="" aria-describedby="footnote-label">14</a></sup> replica</li>
</ul>
</li>
<li>a few custom Postgres settings like <code>wal_compression</code>, <code>max_worker_processes</code>, <code>max_parallel_workers</code>, <code>max_parallel_workers_per_gather</code> and of course - <code>hot_standby</code>
<ul>
<li><code>autovacuum_analyze_scale_factor = 0.05</code> set on the partition tables too (unclear if it has an effect)</li>
</ul>
</li>
<li>each row‚Äôs payload is 1 KiB (1024 bytes)</li>
<li>4 topicpartition tables</li>
<li>10 writers (2 writers per partition on average)</li>
<li>5x read fanout via 5 consumer groups</li>
<li>readers only access the primary DB<sup><a href="#user-content-fn-25" id="user-content-fnref-25" data-footnote-ref="" aria-describedby="footnote-label">15</a></sup>; readers are in the same AZ as the primary;</li>
<li>20 reader clients total (4 readers per group)</li>
<li>write batch size: 100 records</li>
<li>read batch size: 200 records</li>
</ul>
<p><strong>Results:</strong></p>
<ul>
<li>
<p>write message rate: <strong>5015 msg/s</strong></p>
</li>
<li>
<p>write throughput: <strong>4.9 MiB/s</strong></p>
</li>
<li>
<p>write latency: 153.45ms p99 / 6.8ms p95</p>
</li>
<li>
<p>read message rate: <strong>25,073 msg/s</strong></p>
</li>
<li>
<p>read message throughput: <strong>24.5 MiB/s</strong></p>
</li>
<li>
<p>read latency: 57ms p99; 4.91ms p95</p>
</li>
<li>
<p>end-to-end latency<sup><a href="#user-content-fn-9" id="user-content-fnref-9-4" data-footnote-ref="" aria-describedby="footnote-label">5</a></sup>: <strong>186ms p99</strong> / 12ms p95</p>
</li>
<li>
<p>server kept at ~65% CPU;</p>
</li>
<li>
<p>disk was at ~1200 writes/s with iostat claiming 46 MiB/s</p>
</li>
</ul>
<p>Now these are astonishing results! Throughput was not impacted at all. Latency increased but not extremely. Our p99 e2e latency 3x‚Äôd (60ms vs 185ms), but the p95 barely moved from 10.6ms to 12ms.</p>
<p>This shows that a simple 3-node Postgres cluster can pretty easily sustain what is a very common Kafka workload - 5 MB/s ingest and 25 MB/s egress. Not only that, but for a cheap cost too. Just $11,514 per year.<sup><a href="#user-content-fn-26" id="user-content-fnref-26" data-footnote-ref="" aria-describedby="footnote-label">16</a></sup></p>
<p>Typically, you‚Äôd expect Postgres to run more expensive than Kafka at a certain scale, simply because it wasn‚Äôt designed to be efficient for this use case.
Not here though. Running Kafka yourself would cost the same. Running the same workload through a Kafka vendor will cost you at least $50,000 a year. ü§Ø</p>
<p>By the way, in Kafka it‚Äôs customary to apply client-side compression on your data. If we assume your messages were 5 KB in size and your clients applied a pretty regular compression ratio of 4x<sup><a href="#user-content-fn-28" id="user-content-fnref-28" data-footnote-ref="" aria-describedby="footnote-label">17</a></sup> - Postgres is actually handling 20 MB/s ingress and 100 MB/s egress.</p>
<h3 id="96-vcpu-single-node">96 vCPU Single Node<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#96-vcpu-single-node"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>Ok, let‚Äôs see how far Postgres will go.</p>
<p><small><em>The results are the average of three 2-minute tests.</em></small>
<small><em><a href="https://github.com/stanislavkozlovski/pg-queue-pubsub-benchmark/blob/8164907ba0f1afa6bfec3b402950217f31952d2a/results/pubsub/96vcpu/single_node/96vcpu.md">[full results link]<svg aria-hidden="true" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></em></small></p>
<p><strong>Setup:</strong></p>
<ul>
<li><a href="https://instances.vantage.sh/aws/ec2/c7i.24xlarge">c7i.24xlarge<svg aria-hidden="true" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> (96 vCPU, 192 GiB RAM) Postgres server instance /w 250GB io2 12,000 IOPS EBS volume</li>
<li>modified Postgres settings (<code>huge_pages</code> on, other settings scaled to match the machine);
<ul>
<li>still kept fsync &amp; synchronous_commit on for durability.</li>
<li><code>autovacuum_analyze_scale_factor = 0.05</code> set on the partition tables too (unclear if it has an effect)</li>
</ul>
</li>
<li>each row‚Äôs payload is 1 KiB (1024 bytes)</li>
<li>30 topicpartition tables</li>
<li>100 writers (~3.33 writers per partition on average)</li>
<li>5x read fanout via 5 consumer groups</li>
<li>150 reader clients total (5 readers per group)</li>
<li>write batch size: 200 records</li>
<li>read batch size: 200 records</li>
</ul>
<p><strong>Results:</strong></p>
<ul>
<li>
<p>write message rate: <strong>243,000 msg/s</strong></p>
</li>
<li>
<p>write throughput: <strong>238 MiB/s</strong></p>
</li>
<li>
<p>write latency: 138ms p99 / 47ms p95</p>
</li>
<li>
<p>read message rate: <strong>1,200,000 msg/s</strong></p>
</li>
<li>
<p>read message throughput: <strong>1.16 GiB/s</strong></p>
</li>
<li>
<p>read latency: 24.6ms p99</p>
</li>
<li>
<p>end-to-end latency<sup><a href="#user-content-fn-9" id="user-content-fnref-9-5" data-footnote-ref="" aria-describedby="footnote-label">5</a></sup>: <strong>853ms p99</strong> / 242ms p95 / 23.4ms p50</p>
</li>
<li>
<p>server kept at <strong>~10%</strong> CPU (basically idle);</p>
</li>
<li>
<p>bottleneck: The bottleneck was the write rate per partition. It seems like the test wasn‚Äôt able to write at a higher rate than 8 MiB/s (8k msg/s) per table with this design. I didn‚Äôt push further, but I do wonder now as I write this - how far would writes have scaled?</p>
<ul>
<li>Reads were trivial to scale. Adding more consumer groups was trivial - I tried with 10x fanout and still ran at low CPU. I didn‚Äôt include it because I didn‚Äôt feel the need to push to an unrealistic read-fanout extreme.</li>
</ul>
</li>
</ul>
<p>240 MiB/s ingress and 1.16 GiB/s egress are pretty good! The 96 vCPU machine was overkill for this test - it could have done a lot more, or we could have simply opted for a smaller machine. For what it‚Äôs worth, I do think it‚Äôs worth it to deploy a separate Kafka cluster at this scale. Kafka can save you a lot of money here because it can be more efficient in how it handles cross-zone network traffic with features like <a href="https://blog.2minutestreaming.com/p/diskless-kafka-topics-kip-1150">Diskless Kafka<svg aria-hidden="true" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>.</p>
<h3 id="pub-sub-test-summary">Pub-Sub Test Summary<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#pub-sub-test-summary"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p><small><em>The summarized table with the three test results can be found here <span>‚Üí</span> üëâ <a href="https://github.com/stanislavkozlovski/pg-queue-pubsub-benchmark/tree/main/results#pubsub-results">stanislavkozlovski/pg-queue-pubsub-benchmark<svg aria-hidden="true" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></em></small></p>
<p>These tests seem to show that Postgres is pretty competitive with Kafka at low scale.</p>
<p>You may have noticed none of these tests were particularly long-running. From my understanding, the value in longer-running tests is to test table vacuuming in Postgres, as that can have negative performance effects. In the pub-sub section, vacuuming doesn‚Äôt apply because the tables are append-only. My other reasoning for running shorter tests was to keep costs in check and not spend too much time<sup><a href="#user-content-fn-10" id="user-content-fnref-10" data-footnote-ref="" aria-describedby="footnote-label">18</a></sup>.</p>
<p>In any case, no benchmark is perfect. My goal wasn‚Äôt to indisputably prove <code>$MY_CLAIM</code>. Rather, I want to start a discussion by showing that what‚Äôs possible is likely larger than what most people assume. I certainly didn‚Äôt assume I‚Äôd get such good numbers, especially with the pub-sub part.</p>
<hr/>

<p>In Postgres, a queue can be implemented with <code>SELECT FOR UPDATE SKIP LOCKED</code>. This command selects an unlocked row and locks it. It also skips reading already-locked rows. That‚Äôs how mutual exclusion is achieved - a worker can‚Äôt get other workers‚Äô jobs.</p>
<p>Postgres has a very popular <a href="https://github.com/pgmq/pgmq">pgmq<svg aria-hidden="true" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> library that offers a slick queue API. To keep it simple and understand the end-to-end flow better, I decided to write my own queue. The basic version of it is very easy. My workflow is:</p>
<ol>
<li>add job (<code>INSERT</code>)</li>
<li>lock row &amp; take job (<code>SELECT FOR UPDATE SKIP LOCKED</code>)</li>
<li>process job (<code>{your business logic}</code>)</li>
<li>mark job as ‚Äúdone‚Äù (<code>UPDATE</code> a field or <code>DELETE &amp; INSERT</code> the row into a separate table)</li>
</ol>
<p>Postgres competes with RabbitMQ, AWS SQS, NATS, Redis<sup><a href="#user-content-fn-7" id="user-content-fnref-7" data-footnote-ref="" aria-describedby="footnote-label">19</a></sup> and to an extent Kafka<sup><a href="#user-content-fn-8" id="user-content-fnref-8" data-footnote-ref="" aria-describedby="footnote-label">20</a></sup> here.</p>
<h2 id="queue-setup">Queue Setup<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#queue-setup"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<h4 id="table-1">Table<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#table-1"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h4>
<p>We use a simple <code>queue</code> table. When an element is processed off the queue, it‚Äôs moved into the archive table.</p>
<figure data-rehype-pretty-code-figure=""><pre tabindex="0" data-language="sql" data-theme="github-light github-dark"><code data-language="sql" data-theme="github-light github-dark"><span data-line=""><span>CREATE</span><span> TABLE</span><span> queue</span><span> (</span></span>
<span data-line=""><span>  id </span><span>BIGSERIAL</span><span> PRIMARY KEY</span><span>,</span></span>
<span data-line=""><span>  payload </span><span>BYTEA</span><span> NOT NULL</span><span>,</span></span>
<span data-line=""><span>	created_at </span><span>TIMESTAMP</span><span> NOT NULL</span><span> DEFAULT</span><span> NOW</span><span>()</span></span>
<span data-line=""><span>)</span></span>
<span data-line=""> </span>
<span data-line=""><span>CREATE</span><span> TABLE</span><span> queue_archive</span><span> (</span></span>
<span data-line=""><span>  id </span><span>BIGINT</span><span>,</span></span>
<span data-line=""><span>  payload </span><span>BYTEA</span><span> NOT NULL</span><span>,</span></span>
<span data-line=""><span>  created_at </span><span>TIMESTAMP</span><span> NOT NULL</span><span>, </span><span>-- ts the event was originally created at</span></span>
<span data-line=""><span>  processed_at </span><span>TIMESTAMP</span><span> NOT NULL</span><span> DEFAULT</span><span> NOW</span><span>() </span><span>-- ts the event was processed at</span></span>
<span data-line=""><span>)</span></span></code></pre></figure>
<h4 id="writes-1">Writes<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#writes-1"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h4>
<p>We again run <code>N</code> writer client goroutines.
Each one simply loops and sequentially inserts a single random item into the table:</p>
<figure data-rehype-pretty-code-figure=""><pre tabindex="0" data-language="sql" data-theme="github-light github-dark"><code data-language="sql" data-theme="github-light github-dark"><span data-line=""><span>INSERT INTO</span><span> queue</span><span> (payload) </span><span>VALUES</span><span> ($</span><span>1</span><span>)</span></span></code></pre></figure>
<p>It only inserts one message per statement, which is pretty inefficient at scale.</p>
<h4 id="reads-1">Reads<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#reads-1"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h4>
<p>We again run <code>M</code> reader client goroutines. Each reader loops and processes one message.
The processing is done inside a database transaction.</p>
<figure data-rehype-pretty-code-figure=""><pre tabindex="0" data-language="sql" data-theme="github-light github-dark"><code data-language="sql" data-theme="github-light github-dark"><span data-line=""><span>BEGIN</span><span>;</span></span>
<span data-line=""> </span>
<span data-line=""><span>SELECT</span><span> id, payload, created_at</span></span>
<span data-line=""><span>  FROM</span><span> queue</span></span>
<span data-line=""><span>  ORDER BY</span><span> id</span></span>
<span data-line=""><span>  FOR</span><span> UPDATE</span><span> SKIP</span><span> LOCKED</span></span>
<span data-line=""><span>  LIMIT</span><span> 1</span><span>;</span></span>
<span data-line=""> </span>
<span data-line=""><span>-- Your business code &#34;processes&#34; the message. In the benchmark, it&#39;s a no-op.</span></span>
<span data-line=""> </span>
<span data-line=""><span>DELETE</span><span> FROM</span><span> queue</span><span> WHERE</span><span> id </span><span>=</span><span> $</span><span>1</span><span>;</span></span>
<span data-line=""> </span>
<span data-line=""><span>INSERT INTO</span><span> queue_archive (id, payload, created_at, processed_at)</span></span>
<span data-line=""><span>  VALUES</span><span> ($</span><span>1</span><span>,$</span><span>2</span><span>,$</span><span>3</span><span>,</span><span>NOW</span><span>());</span></span>
<span data-line=""> </span>
<span data-line=""><span>COMMIT</span><span>;</span></span></code></pre></figure>
<p>Each reader again only works with one message at a time per transaction.</p>
<h2 id="queue-results-1">Queue Results<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#queue-results-1"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>I again ran the same three setups - a single-node 4 vCPU, a 3-node replicated 4 vCPU and a single-node 96 vCPU setup. Here are the summarized results for each:</p>
<h3 id="4-vcpu-single-node-1">4 vCPU Single Node<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#4-vcpu-single-node-1"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p><small><em>The results are the average of two 15-minute tests. I also ran three 2-minute tests. They all performed similarly.</em></small>
<small><em><a href="https://github.com/stanislavkozlovski/pg-queue-pubsub-benchmark/blob/e6ccbd9a3dd7eb64e6498fcccc251095584ea0cc/results/queue/4vcpu/single_node/4vcpu.md">[full results link]<svg aria-hidden="true" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></em></small></p>
<p><strong>Setup:</strong></p>
<ul>
<li><a href="https://instances.vantage.sh/aws/ec2/c7i.xlarge">c7i.xlarge<svg aria-hidden="true" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> Postgres server /w 25GB gp3 9000 IOPS EBS volume</li>
<li>all default Postgres settings<sup><a href="#user-content-fn-16" id="user-content-fnref-16" data-footnote-ref="" aria-describedby="footnote-label">21</a></sup></li>
<li>each row‚Äôs payload is 1 KiB (1024 bytes)</li>
<li>10 writer clients, 15 reader clients</li>
</ul>
<p><strong>Results:</strong></p>
<ul>
<li>message rate: <strong>2885 msg/s</strong></li>
<li>throughput: <strong>2.81 MiB/s</strong></li>
<li>write latency: 2.46ms p99</li>
<li>read latency: 4.2ms p99</li>
<li>end-to-end latency<sup><a href="#user-content-fn-9" id="user-content-fnref-9-6" data-footnote-ref="" aria-describedby="footnote-label">5</a></sup>: 17.72ms p99</li>
<li>server kept at ~60% CPU;</li>
</ul>
<p>What I found Postgres wasn‚Äôt good at was handling client count. The bottleneck in this setup was the read clients. Each client could not read more than ~192 messages a second because of its median read latency and sequential read nature.</p>
<p>Increasing client count boosted throughput but violated my ~60% CPU target. Trying to run 50 write and 50 read clients got to 4000 msg/s without increasing the queue depth but pegged the server‚Äôs CPU to 100%. I wanted to keep the benchmarks realistic for what you may run in production, rather than maxing out what a machine can do. This would be easily alleviated with a connection pooler (standard across all prod PG deployments) or a larger machine.</p>
<p>Another thing worth mentioning is that the workload could sustain a lot more writes than reads. If I didn‚Äôt throttle the benchmark, it would write at 12,000 msg/s and read at 2,800 msg/s. In the spirit of simplicity, I didn‚Äôt debug further and instead throttled my writes to see at what point I could get a stable 1:1 workload.</p>
<h3 id="4-vcpu-tri-node-1">4 vCPU Tri-Node<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#4-vcpu-tri-node-1"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p><small><em>A single 10-minute test.</em></small>
<small><em><a href="https://github.com/stanislavkozlovski/pg-queue-pubsub-benchmark/blob/e6ccbd9a3dd7eb64e6498fcccc251095584ea0cc/results/queue/4vcpu/three_node/4vcpu_replicated.md">[full results link]<svg aria-hidden="true" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></em></small></p>
<p><strong>Setup:</strong></p>
<ul>
<li>3x <a href="https://instances.vantage.sh/aws/ec2/c7i.xlarge">c7i.xlarge<svg aria-hidden="true" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> Postgres servers /w 25GB gp3 9000 IOPS EBS volume
<ul>
<li>each on a separate AZ (us-east-1a, us-east-1b, us-east-1c)</li>
<li>one <code>sync</code> replica and one <code>potential</code><sup><a href="#user-content-fn-22" id="user-content-fnref-22-2" data-footnote-ref="" aria-describedby="footnote-label">14</a></sup> replica</li>
</ul>
</li>
<li>a few custom Postgres settings like <code>wal_compression</code>, <code>max_worker_processes</code>, <code>max_parallel_workers</code>, <code>max_parallel_workers_per_gather</code> and of course - <code>hot_standby</code></li>
<li>each row‚Äôs payload is 1 KiB (1024 bytes)</li>
<li>10 writer clients, 15 reader clients</li>
<li>readers only access the primary DB<sup><a href="#user-content-fn-25" id="user-content-fnref-25-2" data-footnote-ref="" aria-describedby="footnote-label">15</a></sup>; readers are in the same AZ as the primary;</li>
</ul>
<p><strong>Results:</strong></p>
<ul>
<li>message rate: <strong>2397 msg/s</strong></li>
<li>throughput: <strong>2.34 MiB/s</strong></li>
<li>write latency: 3.3ms p99</li>
<li>read latency: 7.6ms p99</li>
<li>end-to-end latency<sup><a href="#user-content-fn-9" id="user-content-fnref-9-7" data-footnote-ref="" aria-describedby="footnote-label">5</a></sup>: 920ms p99 ‚ö†Ô∏è<sup><a href="#user-content-fn-19" id="user-content-fnref-19-3" data-footnote-ref="" aria-describedby="footnote-label">6</a></sup>; 536ms p95; 7ms p50</li>
<li>server kept at ~60% CPU;</li>
</ul>
<p>As expected, throughput and latency were impacted somewhat. But not that much. It‚Äôs still over 2000 messages a second, which is pretty good for an HA queue!</p>
<h3 id="96-vcpu-single-node-1">96 vCPU Single Node<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#96-vcpu-single-node-1"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p><small><em>The average of three 2-minute tests.</em></small>
<small><em><a href="https://github.com/stanislavkozlovski/pg-queue-pubsub-benchmark/blob/e6ccbd9a3dd7eb64e6498fcccc251095584ea0cc/results/queue/96vcpu/single_node/96vcpu.md">[full results link]<svg aria-hidden="true" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></em></small></p>
<p><strong>Setup:</strong></p>
<ul>
<li><a href="https://instances.vantage.sh/aws/ec2/c7i.24xlarge">c7i.24xlarge<svg aria-hidden="true" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> Postgres server instance /w 250GB io2 12,000 IOPS EBS volume</li>
<li>modified Postgres settings (<code>huge_pages</code> on, other settings scaled to match the machine);
<ul>
<li>still kept fsync &amp; synchronous_commit on for durability.</li>
</ul>
</li>
<li>each row‚Äôs payload is 1 KiB (1024 bytes)</li>
<li>100 writer clients, 200 reader clients</li>
</ul>
<p><strong>Results:</strong></p>
<ul>
<li>message rate: <strong>20,144 msg/s</strong></li>
<li>throughput: <strong>19.67 MiB/s</strong></li>
<li>write latency: 9.42ms p99</li>
<li>read latency: 22.6ms p99</li>
<li>end-to-end latency: 930ms p99 ‚ö†Ô∏è<sup><a href="#user-content-fn-19" id="user-content-fnref-19-4" data-footnote-ref="" aria-describedby="footnote-label">6</a></sup>; 709ms p95; 12.6ms p50</li>
<li>server at 40-60% CPU;</li>
</ul>
<p>This run wasn‚Äôt that impressive. There is some bottleneck in the single-table queue approach at this scale which I didn‚Äôt bother figuring out. I figured that it wasn‚Äôt important to reach absurd numbers on a single table, since all realistic scenarios would have multiple queues and never reach 20,000 msg/s on a single one. The 96 vCPU instance would likely scale far further were we to run a few separate queue tables in parallel.</p>
<h3 id="queue-test-summary">Queue Test Summary<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#queue-test-summary"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p><small><em>The summarized table with the three test results can be found here <span>‚Üí</span> üëâ <a href="https://github.com/stanislavkozlovski/pg-queue-pubsub-benchmark/tree/main/results#queue-results">stanislavkozlovski/pg-queue-pubsub-benchmark<svg aria-hidden="true" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></em></small></p>
<p>Even a modest Postgres node can durably push thousands of queue ops/sec, which already covers the scale 99% of companies ever hit with a single queue.
As I said earlier, the last 2 years have seen the Just Use Postgres slogan become mainstream. The <code>pgmq</code> <a href="https://github.com/pgmq/pgmq">library<svg aria-hidden="true" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>‚Äôs star history captures this trend perfectly:
<img src="https://topicpartition.io/blog/images/pgmq_star_history.png" alt="pgmq"/></p>
<hr/>

<p>Most of the time - <strong>yes</strong>. You should always default to Postgres until the constraints prove you wrong.</p>
<p>Kafka is obviously better optimized for pub-sub workloads. Queue systems are obviously better optimized for queue workloads. The point is that <strong>picking a technology based on technical optimization alone is a flawed approach</strong>. To throw an analogy:</p>
<blockquote>
<p>a Formula One car is optimized to drive faster, but I still use a sedan to go to work. I am way more comfortable driving my sedan than an F1 car.</p>
<p><small><em>(seriously, see <a href="https://www.youtube.com/watch?v=nsup4xKpb20">the steering wheel<svg aria-hidden="true" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> on these things)</em></small></p>
</blockquote>
<p>The Postgres sedan comes with many quality-of-life comforts that the F1 Kafka does not:</p>
<ul>
<li>ability to debug messages with regular SQL</li>
<li>ability to delete, re-order or edit messages in place</li>
<li>ability to join pub-sub data with regular tables</li>
<li>ability to trivially read specific data via rich SQL queries (<code>ID=54</code>, <code>name=&#34;John&#34;</code>, <code>cost&gt;1000</code>)</li>
</ul>
<p>Giving up these comforts is a justified sacrifice for your F1 car to go at 378 kmh (235 mph), but masochistic if you plan on driving at 25kmh (15 mph).</p>
<p>Donald Knuth warned us in 1974 - <strong>premature optimization</strong> is the root of all evil. Deploying Kafka at small scale is premature optimization.
The point of this article is to show you that this ‚Äúsmall scale‚Äù number has grown further than what people remember it to be - it can comfortably mean many megabytes per second.</p>
<p>We are in a Postgres Renaissance for a reason: Postgres is <strong>frequently</strong> good enough. Modern NVMEs and cheap RAM allow it to scale absurdly high.</p>
<p>What‚Äôs the alternative?</p>
<h2 id="custom-solutions-for-everything">Custom Solutions for Everything?<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#custom-solutions-for-everything"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>Naive engineers tend to adopt a specialized technology at the slightest hint of a need:</p>
<ul>
<li><em>Need a cache?</em> Redis, of course!</li>
<li><em>Search?</em> Let‚Äôs deploy Elasticsearch!</li>
<li><em>Offline data analysis?</em> BigQuery or Snowflake - that‚Äôs what our data analysts used at their last job.</li>
<li><em>No schemas?</em> We need a NoSQL database like MongoDB.</li>
<li><em>Have to crunch some numbers on S3?</em> Let‚Äôs use Spark!</li>
</ul>
<p>A good engineer thinks through the bigger picture.</p>
<ul>
<li><em>Does this new technology move the needle?</em></li>
<li><em>Is shaving a few milliseconds off our query worth the extra organizational complexity introduced with the change?</em></li>
<li><em>Will our users notice?</em></li>
</ul>
<p>At small scale, these systems hurt you more than they benefit you. Distributed systems - both in terms of node count and system cardinality - should be respected, feared, avoided and employed only as a weapon of last resort against particularly gnarly problems. Everything with a distributed system becomes more challenging and time-consuming.</p>
<p>The problem is <strong>the organizational overhead</strong>. The organizational overhead of adopting a new system, learning its nuances, configs, establishing monitoring, establishing processes around deployments and upgrades, attaining operational expertise on how to manage it, creating runbooks, testing it, debugging it, adopting its clients and API, using its UI, keeping up with its ecosystem, etc.</p>
<p>All of these are real organizational costs that can take months to get right, even if the system in question isn‚Äôt difficult (a lot are). Managed SaaS offerings trade off some of the organizational overhead for greater financial costs - but they still don‚Äôt remove it all. And until you reach the scale where the technology is necessary, you pay these extra <em>{financial, organizational}</em> costs for zero significant gain.</p>
<p>If the same can be done with tech for which you‚Äôve already paid the organizational costs for (e.g Postgres), adopting something else prematurely is most definitely an anti-pattern. You don‚Äôt need web-scale technologies when you don‚Äôt have web-scale problems.</p>
<h2 id="mvi-a-better-alternative">MVI (a better alternative)<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#mvi-a-better-alternative"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>What I think is a better approach is to search for the <strong>minimum viable infrastructure</strong> (MVI): build the smallest amount of system while still providing value.</p>
<ol>
<li>choose <strong>good-enough</strong> technology your org is already <strong>familiar</strong> with
<ul>
<li><em>good-enough</em> == meets your users‚Äô needs without being too slow/expensive/insecure</li>
<li><em>familiar</em> == your org has prior experience, has runbooks/ops setups, monitoring, UI, etc</li>
</ul>
</li>
<li>solve a real problem with it</li>
<li>use the minimum set of features
<ul>
<li>the fewer features you use, the more flexibility you have to move off the infra in question in the future (e.g if locked in with a vendor)</li>
</ul>
</li>
</ol>
<p>Bonus points if that technology:</p>
<ul>
<li>is widely adopted so finding good engineers for it is trivial (Postgres - check)</li>
<li>has a strong and growing network effect (Postgres - check)</li>
</ul>
<p>The MVI approach reduces the surface area of your infra. The fewer moving parts you have, the fewer failure modes you worry about and the less glue code you have to maintain.</p>
<p>Unfortunately, it‚Äôs human nature to go against this. Just like startups suffer due to <a href="https://en.wikipedia.org/wiki/Minimum_viable_product">MVP<svg aria-hidden="true" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> bloat <em>(one more feature!)</em>, infra teams suffer due to MVI bloat <em>(one more system!)</em></p>
<h2 id="why-are-we-like-this">Why are we like this?<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#why-are-we-like-this"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>I won‚Äôt pretend to be able to map out the exact path-dependent outcome, but my guess is this:</p>
<ol start="0">
<li>the zero interest rate era gave us abundant speculative money that was invested in any company that could grow fast</li>
<li>a lot of viral internet companies were growing at speeds that led old infra to become obsolete fast</li>
<li>this prompted the next wave of ZIRP investment - specialized data infrastructure companies (in a gold rush, sell shovels!); some of these data infra startups spun off directly from the high-growth companies themselves</li>
<li>each well-funded data infra vendor is financially motivated to evangelize their product and have you adopt it even when you don‚Äôt need to (<a href="https://topicpartition.io/blog/everyone-is-talking-their-book" data-slug="blog/everyone-is-talking-their-book">Everyone is Talking Their Book</a>). They had deep pockets for marketing and used them.</li>
<li>innovative infrastructure software got engineered. It was exciting - so engineers got <a href="https://xkcd.com/356/">nerd-sniped<svg aria-hidden="true" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> into it</li>
<li>a <a href="https://www.youtube.com/watch?v=b2F-DItXtZs">web-scale<svg aria-hidden="true" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> craze/cargo cult developed, where everybody believed they need to be able to scale from zero to millions of RPS because they may go viral any day.</li>
<li>a trend developed to copy whatever solutions the most successful, largest digital-native companies were using (Amazon, Google, Uber, etc.)</li>
<li>the trend became a self-perpetuating prophecy: these technologies became a sought-after skill on resumes
<ul>
<li>system design interview questions were adapted to test for knowledge of these systems</li>
<li>within an organization, engineers (knowingly or not) pushed for projects that are exciting and helped build their resumes;</li>
</ul>
</li>
</ol>
<p>This trend continues to grow while there is no strong competing force that is sufficiently motivated to push the opposite view. Even engineers inside a company, who ought to be motivated to keep things simple, have strong incentives to pursue extra complexity. It benefits their career by giving them a project to use as ammo for their next promotion and improves their resume (cool tech/story on there) for their next job-hop. Plus it‚Äôs simply more fun.</p>
<p>This is why I think we, as an industry, don‚Äôt always use the simplest solution available.</p>
<p>In most cases, Postgres is that simplest solution that is available.</p>
<h2 id="but-it-wont-scale">But It Won‚Äôt Scale!<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#but-it-wont-scale"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h2>
<p>I want to wrap this article up, but one rebuttal I can‚Äôt miss addressing is the ‚Äúit won‚Äôt scale argument‚Äù.</p>
<p>The argument goes something like this: ‚Äúin today‚Äôs age we can go viral at a moment‚Äôs notice; these viral moments are very valuable for our business so we need to aggressively design in a way that keeps our app stable under traffic spikes‚Äù</p>
<p>I have three arguments against this:</p>
<h3 id="1-postgres-scales">1. Postgres Scales<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#1-postgres-scales"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>As of 2025, OpenAI <a href="https://news.ycombinator.com/item?id=44074702">still uses<svg aria-hidden="true" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> an unsharded Postgres architecture with only one primary instance for writes<sup><a href="#user-content-fn-17" id="user-content-fnref-17" data-footnote-ref="" aria-describedby="footnote-label">22</a></sup>. OpenAI is <em><strong>the</strong></em> poster-child of rapid viral growth. They hold the record for <a href="https://www.researchgate.net/figure/Time-to-reach-100-million-users-for-different-technologies-in-months-after-initial_fig1_372212988">the fastest startup to reach 100 million users<svg aria-hidden="true" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>.</p>
<p><a href="https://bohanzhang.me/">Bohan Zhang<svg aria-hidden="true" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>, a member of OpenAI‚Äôs infrastructure team and co-founder of <a href="https://ottertune.com/">OtterTune<svg aria-hidden="true" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> (a Postgres tuning service), can be quoted as saying<sup><a href="#user-content-fn-29" id="user-content-fnref-29" data-footnote-ref="" aria-describedby="footnote-label">23</a></sup>:</p>
<blockquote>
<p><em>‚ÄúAt OpenAI, we utilize an unsharded architecture with one writer and multiple readers, demonstrating that PostgreSQL can scale gracefully under massive read loads.‚Äù</em></p>
<p><em>‚ÄúThe main message of my talk was that if you are not too write heavy, you can scale Postgres to a very high read throughput with read replicas using only a single master! That is exactly the message that needs to be spelled out as that covers <strong>the vast majority</strong> of apps.‚Äù</em></p>
<p><em>‚ÄúPostgres is probably the default choice for developers right now. You can use Postgres for a very long time. If you are building a startup with read-heavy workloads, just start with Postgres. If you hit a scalability issue, increase the instance size. You can scale it to a very large scale. If in the future the database becomes a bottleneck, congratulations. You have built a successful startup. It‚Äôs a good problem to have.‚Äù</em></p>
<p>(slightly edited for clarity and grammar)</p>
</blockquote>
<p>Despite their rapid growth to a user base of more than 800 million, OpenAI has still NOT opted for a web-scale distributed database. If they haven‚Äôt‚Ä¶ why does your unproven project need to?</p>
<h3 id="2-you-have-more-time-to-scale-than-you-think">2. You Have More Time To Scale Than You Think<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#2-you-have-more-time-to-scale-than-you-think"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>Let‚Äôs say it‚Äôs a good principle to design/test for ~10x your scale. Here are the years of <em>consistent</em> growth rate it takes to get to 10x your current scale:</p>





































<div><table><thead><tr><th>annual growth</th><th>years to hit 10√ó scale</th></tr></thead><tbody><tr><td>10 %</td><td>24.16 y</td></tr><tr><td>25 %</td><td>10.32 y</td></tr><tr><td>50 %</td><td>5.68 y</td></tr><tr><td>75 %</td><td>4.11 y</td></tr><tr><td>100 %</td><td>3.32 y</td></tr><tr><td>150 %</td><td>2.51 y</td></tr><tr><td>200 %</td><td>2.10 y</td></tr></tbody></table></div>
<p>It goes to show that even at extreme growth levels, you still have years to migrate between solutions.
The majority of developers, though, work at companies in the 0-50% growth rate. They are more likely to have moved on to another job by the time the solution needs to change (if ever).</p>
<h3 id="3-its-overdesign">3. It‚Äôs Overdesign<a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#3-its-overdesign"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<p>In an ideal world, you <em>would</em> build for scale and any other future problem you may hit in 10 years.</p>
<p>In the real world, you have finite bandwidth, so you have to build for the most immediate, highest ROI problem.</p>
<p><a href="https://lobste.rs/s/wshruu/small_data#c_kjygo0">Commenter snej on lobste.rs<svg aria-hidden="true" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> captured it well:</p>
<blockquote>
<p>Planning your infrastructure around being able to handle that is sort of like buying a huge Marshall stack as your first guitar amp because your garage band might get invited to open for Coldplay.</p>
</blockquote>

<p>Just use Postgres until it breaks.</p>
<hr/>
<h3 id="disclaimers"><em>Disclaimers</em><a role="anchor" aria-hidden="true" tabindex="-1" data-no-popover="true" href="#disclaimers"><svg width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M10 13a5 5 0 0 0 7.54.54l3-3a5 5 0 0 0-7.07-7.07l-1.72 1.71"></path><path d="M14 11a5 5 0 0 0-7.54-.54l-3 3a5 5 0 0 0 7.07 7.07l1.71-1.71"></path></svg></a></h3>
<ul>
<li>
<p><em>Title inspiration comes from a great recent piece - <a href="https://dizzy.zone/2025/09/24/Redis-is-fast-Ill-cache-in-Postgres/">‚ÄúRedis is fast - I‚Äôll cache in Postgres‚Äù<svg aria-hidden="true" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a></em></p>
</li>
<li>
<p><em>I‚Äôm a complete Postgres noob. You may see a lot of dumb mistakes here. Feel free to call me out on them - I‚Äôm happy to learn. I used AI to help a lot with some of the PG tools to use. This both shows how inexperienced I am in the context and how easy it is to start. I am generally skeptical of AI‚Äôs promise (in the short-term), but there‚Äôs no denying it has made a large dent in democratizing niche/low-level knowledge.</em></p>
</li>
</ul>
<p>If you‚Äôd like to reach out to me, you can find me on <a href="https://www.linkedin.com/in/stanislavkozlovski/">LinkedIn<svg aria-hidden="true" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a> or <a href="https://x.com/BdKozlovski">X (Twitter)<svg aria-hidden="true" style="max-width:0.8em;max-height:0.8em;" viewBox="0 0 512 512"><path d="M320 0H288V64h32 82.7L201.4 265.4 178.7 288 224 333.3l22.6-22.6L448 109.3V192v32h64V192 32 0H480 320zM32 32H0V64 480v32H32 456h32V480 352 320H424v32 96H64V96h96 32V32H160 32z"></path></svg></a>.</p>
</article></div>
  </body>
</html>
