<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://sirupsen.com/napkin/problem-10-mysql-transactions-per-second">Original</a>
    <h1>MySQL transactions per second vs. fsyncs per second (2020)</h1>
    
    <div id="readability-page-1" class="page"><article><p><time datetime="2020-07-17">Jul 2020</time></p><p><strong>Just wondering how many transactions or writes per second MySQL can handle?</strong> While it depends on many factors, fundamentally, about as many transactions as MySQL can commit to disk per second. A modern disk can do <a href="https://github.com/sirupsen/napkin-math#numbers">~1000 fsyncs per second</a>, but MySQL will group multiple writes with each fsync. An okay rule-of-thumb would be 5000-15,000 writes per second, depending on things like writes per transaction, number of indexes, hardware, size of writes, etc. Read the article to understand this in more depth!</p><nav><ol><li><a href="https://sirupsen.com/napkin/problem-10-mysql-transactions-per-second#problem-10-is-mysqls-maximum-transactions-per-second-equivalent-to-fsyncs-per-second">Problem 10: Is MySQL’s maximum transactions per second equivalent to fsyncs per second?</a></li><li><a href="https://sirupsen.com/napkin/problem-10-mysql-transactions-per-second#problem-9-inverted-index">Problem 9: Inverted Index</a></li></ol></nav><p>Napkin friends, from near and far, it’s time for another napkin problem!</p>
<p>Since the beginning of this newsletter I’ve posed problems for you to try to
answer. Then in the next month’s edition, you hear my answer. Talking with a few
of you, it seems many of you read these as posts regardless of their
problem-answer format.</p>
<p>That’s why I’ve decided to experiment with a simpler format: posts where I both
present a problem and solution in one go. This one will be long, since it’ll
include an answer to last month’s.</p>
<p>Hope you enjoy this format! As always, you are encouraged to reach out with
feedback.</p>
<h2 id="problem-10-is-mysqls-maximum-transactions-per-second-equivalent-to-fsyncs-per-second">Problem 10: Is MySQL’s maximum transactions per second equivalent to fsyncs per second?<svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="currentColor" viewBox="0 0 24 24"><path d="M9.199 13.599a5.99 5.99 0 0 0 3.949 2.345 5.987 5.987 0 0 0 5.105-1.702l2.995-2.994a5.992 5.992 0 0 0 1.695-4.285 5.976 5.976 0 0 0-1.831-4.211 5.99 5.99 0 0 0-6.431-1.242 6.003 6.003 0 0 0-1.905 1.24l-1.731 1.721a.999.999 0 1 0 1.41 1.418l1.709-1.699a3.985 3.985 0 0 1 2.761-1.123 3.975 3.975 0 0 1 2.799 1.122 3.997 3.997 0 0 1 .111 5.644l-3.005 3.006a3.982 3.982 0 0 1-3.395 1.126 3.987 3.987 0 0 1-2.632-1.563A1 1 0 0 0 9.201 13.6zm5.602-3.198a5.99 5.99 0 0 0-3.949-2.345 5.987 5.987 0 0 0-5.105 1.702l-2.995 2.994a5.992 5.992 0 0 0-1.695 4.285 5.976 5.976 0 0 0 1.831 4.211 5.99 5.99 0 0 0 6.431 1.242 6.003 6.003 0 0 0 1.905-1.24l1.723-1.723a.999.999 0 1 0-1.414-1.414L9.836 19.81a3.985 3.985 0 0 1-2.761 1.123 3.975 3.975 0 0 1-2.799-1.122 3.997 3.997 0 0 1-.111-5.644l3.005-3.006a3.982 3.982 0 0 1 3.395-1.126 3.987 3.987 0 0 1 2.632 1.563 1 1 0 0 0 1.602-1.198z"></path></svg></h2>
<p>How many transactions (‘writes’) per second is MySQL capable of?</p>
<p>A naive model of how a write (a SQL insert/update/delete) to an ACID-compliant
database like MySQL works might be the following (this applies equally to
Postgres, or any other relational/ACID-compliant databases, but we’ll
proceed to work with MySQL as it’s the one I know best):</p>
<ol>
<li>Client sends query to MySQL over an existing connection: <code>INSERT INTO products (name, price) VALUES (&#39;Sneaker&#39;, 100)</code></li>
<li>MySQL inserts the new record to the write-ahead-log (WAL) and calls
<code>fsync(2)</code> to tell the operating system to tell the filesystem to tell the
disk to make <em>sure</em> that this data is <em>for sure</em>, pinky-swear committed to
the disk. This step, being the most complex, is depicted below.</li>
<li>MySQL inserts the record into an in-memory page in the backing storage engine
(InnoDB) so the record will be visible to subsequent queries. Why commit to
the storage engine <em>and</em> the WAL? The storage engine is optimized for serving
query results the data, and the WAL for writing it in a safe manner — we
can’t serve a <code>SELECT</code> efficiently from the WAL!</li>
<li>MySQL returns <code>OK</code> to the client.</li>
<li>MySQL eventually calls <code>fsync(2)</code> to ensure InnoDB commits the page to disk.</li>
</ol>
<figure><img alt="Napkin_10" fetchpriority="high" width="1759" height="1198" decoding="async" data-nimg="1" sizes="(min-width: 36rem) 36rem 100vw" srcset="/_next/image?url=%2Fimages%2F87759326-21adeb00-c7dc-11ea-89c7-559ca11530e8.png&amp;w=640&amp;q=75 640w, /_next/image?url=%2Fimages%2F87759326-21adeb00-c7dc-11ea-89c7-559ca11530e8.png&amp;w=750&amp;q=75 750w, /_next/image?url=%2Fimages%2F87759326-21adeb00-c7dc-11ea-89c7-559ca11530e8.png&amp;w=828&amp;q=75 828w, /_next/image?url=%2Fimages%2F87759326-21adeb00-c7dc-11ea-89c7-559ca11530e8.png&amp;w=1080&amp;q=75 1080w, /_next/image?url=%2Fimages%2F87759326-21adeb00-c7dc-11ea-89c7-559ca11530e8.png&amp;w=1200&amp;q=75 1200w, /_next/image?url=%2Fimages%2F87759326-21adeb00-c7dc-11ea-89c7-559ca11530e8.png&amp;w=1920&amp;q=75 1920w, /_next/image?url=%2Fimages%2F87759326-21adeb00-c7dc-11ea-89c7-559ca11530e8.png&amp;w=2048&amp;q=75 2048w, /_next/image?url=%2Fimages%2F87759326-21adeb00-c7dc-11ea-89c7-559ca11530e8.png&amp;w=3840&amp;q=75 3840w" src="https://sirupsen.com/_next/image?url=%2Fimages%2F87759326-21adeb00-c7dc-11ea-89c7-559ca11530e8.png&amp;w=3840&amp;q=75"/></figure>
<p>In the event of power-loss at any of these points, the behaviour can be defined
without nasty surprises, upholding our dear ACID-compliance.</p>
<p>Splendid! Now that we’ve constructed a naive model of how a relational database
might handle writes safely, we can consider the latency of inserting a new
record into the database. When we consult <a href="https://github.com/sirupsen/napkin-math">the reference napkin numbers</a>, we
see that the <code>fsync(2)</code> in step (2) is by <em>far</em> the slowest operation in the
blocking chain at 1 ms.</p>
<p>For example, the network handling at step (1) takes roughly ~10 μs (TCP Echo
Server is what we can classify as ‘the TCP overhead’). The <code>write(2)</code> itself
prior to the <code>fsync(2)</code> is also negligible at ~10 μs, since this system call
essentially just writes to an in-memory buffer (the ‘page cache’) in the kernel.
This doesn’t guarantee the actual bits are committed on disk, which means an
unexpected loss of power would erase the data, dropping our ACID-compliance on
the floor. Calling <code>fsync(2)</code> guarantees us the bits are persisted on the disk,
which will survive an unexpected system shutdown.  Downside is that it’s 100x
slower.</p>
<p>With that, we should be able to form a simple hypothesis on the maximum
throughput of MySQL:</p>
<blockquote>
<p>The maximum theoretical throughput of MySQL is equivalent to the maximum
number of <code>fsync(2)</code> per second.</p>
</blockquote>
<p>We know that <code>fsync(2)</code> takes 1 ms from earlier, which means we would naively
expect that MySQL would be able to perform in the neighbourhood of: <code>1s / 1ms/fsync = 1000 fsyncs/s = 1000 transactions/s</code> .</p>
<p>Excellent. We followed the first three of the napkin math steps: (1) Model the
system, (2) Identify the relevant latencies, (3) Do the napkin math, (4) Verify
the napkin calculations against reality.</p>
<p>On to (4: Verifying)! We’ll write a simple benchmark in Rust that writes to
MySQL with 16 threads, doing 1,000 insertions each:</p>
<pre><code><span>for</span> i <span>in</span> <span>0</span><span>..</span><span>16</span> <span>{</span>
    handles<span>.</span><span>push</span><span>(</span><span>thread<span>::</span></span><span>spawn</span><span>(</span><span>{</span>
        <span>let</span> pool <span>=</span> pool<span>.</span><span>clone</span><span>(</span><span>)</span><span>;</span>
        <span>move</span> <span><span>|</span><span>|</span></span> <span>{</span>
            <span>let</span> <span>mut</span> conn <span>=</span> pool<span>.</span><span>get_conn</span><span>(</span><span>)</span><span>.</span><span>unwrap</span><span>(</span><span>)</span><span>;</span>
            
            
            <span>for</span> _ <span>in</span> <span>0</span><span>..</span><span>1000</span> <span>{</span>
                conn<span>.</span><span>exec_drop</span><span>(</span>
                    <span>r&#34;INSERT INTO products (shop_id, title) VALUES (:shop_id, :title)&#34;</span><span>,</span>
                    <span>params!</span> <span>{</span> <span>&#34;shop_id&#34;</span> <span>=&gt;</span> <span>123</span><span>,</span> <span>&#34;title&#34;</span> <span>=&gt;</span> <span>&#34;aerodynamic chair&#34;</span> <span>}</span><span>,</span>
                <span>)</span>
                <span>.</span><span>unwrap</span><span>(</span><span>)</span><span>;</span>
            <span>}</span>
        <span>}</span>
    <span>}</span><span>)</span><span>)</span><span>;</span>

    <span>for</span> handle <span>in</span> handles <span>{</span>
      handle<span>.</span><span>join</span><span>(</span><span>)</span><span>.</span><span>unwrap</span><span>(</span><span>)</span><span>;</span>
    <span>}</span>
    
<span>}</span>
</code></pre>
<p>This takes ~3 seconds to perform 16,000 insertions, or ~5,300 insertions per
second. This is <strong>5x</strong> more than the 1,000 <code>fsync</code> per second our napkin math
told us would be the theoretical maximum transactional throughput!</p>
<p>Typically with napkin math we aim for being within an order of magnitude, which
we are. But, when I do napkin math it usually establishes a lower-bound for the
system, i.e. from first-principles, how fast <em>could</em> this system perform in
ideal circumstances?</p>
<p>Rarely is the system 5x faster than napkin math. When we identify a
significant-ish gap between the real-life performance and the expected
performance, I call it the “first-principle gap.” This is where curiosity sets
in. It typically means there’s (1) an opportunity to improve the system, or (2)
a flaw in our model of the system. In this case, only (2) makes sense, because
the system is faster than we predicted.</p>
<p>What’s wrong with our model of how the system works? Why aren’t fsyncs per
second equal to transactions per second?</p>
<p>First I examined the benchmark… is something wrong? Nope <code>SELECT COUNT(*) FROM products</code> says 16,000. Is the MySQL I’m using configured to not <code>fsync</code> on every
write? Nope, it’s at the <a href="https://dev.mysql.com/doc/refman/5.7/en/innodb-parameters.html#sysvar_innodb_flush_log_at_trx_commit">safe default</a>.</p>
<p>Then I sat down and thought about it. Perhaps MySQL is <em>not</em> doing an <code>fsync</code>
for every <em>single</em> write? If it’s processing 5,300 insertions per second,
perhaps it’s batching multiple writes together as part of writing to the WAL,
step (2) above? Since each transaction is so short, MySQL would benefit from
waiting a few microseconds to see if other transactions want to ride along
before calling the expensive <code>fsync(2)</code>.</p>
<p>We can test this hypothesis by writing a simple <code>bpftrace</code> script to observe the
number of <code>fsync(1)</code> for the ~16,000 insertions:</p>
<pre><code>tracepoint<span>:</span>syscalls<span>:</span>sys_enter_fsync<span>,</span>tracepoint<span>:</span>syscalls<span>:</span>sys_enter_fdatasync
<span>/</span>comm <span>==</span> <span>&#34;mysqld&#34;</span><span>/</span>
<span>{</span>
        <span>@fsyncs</span> <span>=</span> <span>count</span><span>(</span><span>)</span><span>;</span>
<span>}</span>
</code></pre>
<p>Running this during the ~3 seconds it takes to insert the 16,000 records we get
~8,000 <code>fsync</code> calls:</p>
<pre><code>$ <span>sudo</span> bpftrace fsync_count.d
Attaching <span>2</span> probes<span>..</span>.
^C

@fsyncs: <span>8037</span>
</code></pre>
<p>This is a peculiar number. If MySQL was batching fsyncs, we’d expect something
far lower. This number means that we’re on average doing ~2,500 <code>fsync</code> per
second, at a latency of ~0.4ms. This is twice as fast as the <code>fsync</code> latency we
expect, the 1ms mentioned earlier. For sanity, I ran the script to benchmark
<code>fsync</code> outside MySQL again, no, <a href="https://github.com/sirupsen/napkin-math/blob/fe780331c6f0c6f225a70c8a37c21e0740f7c73c/src/main.rs#L491">still 1ms</a>. <a href="https://gist.github.com/sirupsen/9fd5fe9466e82df073ed8a13ed1f661f#file-napkin-bash">Looked at the
distribution</a>, and it was consistently ~1ms.</p>
<p>So there’s two things we can draw from this: (1) We’re able to <code>fsync</code> more than
twice as fast as we expect, (2) Our hypothesis was correct that MySQL is more
clever than doing one <code>fsync</code> per transaction, however, since <code>fsync</code> also was
faster than expected, this didn’t explain everything.</p>
<p>If you remember from above, while committing the transaction could theoretically
be a single <code>fsync</code>, other features of MySQL might also call <code>fsync</code>. Perhaps
they’re adding noise?</p>
<p>We need to group <code>fsync</code> by file descriptor to get a better idea of how MySQL
uses <code>fsync</code>. However, the raw file descriptor number doesn’t tell us much. We
can use <code>readlink</code> and the <code>proc</code> file-system to obtain the file name the file
descriptor points to. Let’s write a <a href="https://github.com/iovisor/bpftrace"><code>bpftrace</code> script</a> to see what’s being
<code>fsync</code>‘ed:</p>
<pre><code>tracepoint<span>:</span>syscalls<span>:</span>sys_enter_fsync<span>,</span>tracepoint<span>:</span>syscalls<span>:</span>sys_enter_fdatasync
<span>/</span>comm <span>==</span> <span>str</span><span>(</span><span>$</span><span>1</span><span>)</span><span>/</span>
<span>{</span>
  <span>@fsyncs</span><span>[</span>args<span>-</span><span>&gt;</span>fd<span>]</span> <span>=</span> <span>count</span><span>(</span><span>)</span><span>;</span>
  <span>if</span> <span>(</span><span>@fd_to_filename</span><span>[</span>args<span>-</span><span>&gt;</span>fd<span>]</span><span>)</span> <span>{</span>
  <span>}</span> <span>else</span> <span>{</span>
    <span>@fd_to_filename</span><span>[</span>args<span>-</span><span>&gt;</span>fd<span>]</span> <span>=</span> <span>1</span><span>;</span>
    <span>system</span><span>(</span><span>&#34;echo -n &#39;fd %d -&gt; &#39; &amp;1&gt;&amp;2 | readlink /proc/%d/fd/%d&#34;</span><span>,</span>
           args<span>-</span><span>&gt;</span>fd<span>,</span> pid<span>,</span> args<span>-</span><span>&gt;</span>fd<span>)</span><span>;</span>
  <span>}</span>
<span>}</span>

END <span>{</span>
  <span>clear</span><span>(</span><span>@fd_to_filename</span><span>)</span><span>;</span>
<span>}</span>
</code></pre>
<p>Running this while inserting the 16,000 transactions into MySQL gives us:</p>
<pre><code>personal@napkin:~$ <span>sudo</span> bpftrace --unsafe fsync_count_by_fd.d mysqld
Attaching <span>5</span> probes<span>..</span>.
fd <span>5</span> -<span>&gt;</span> /var/lib/mysql/ib_logfile0 
fd <span>9</span> -<span>&gt;</span> /var/lib/mysql/ibdata1 
fd <span>11</span> -<span>&gt;</span> /var/lib/mysql/
fd <span>13</span> -<span>&gt;</span> /var/lib/mysql/undo_001 
fd <span>15</span> -<span>&gt;</span> /var/lib/mysql/undo_002 
fd <span>27</span> -<span>&gt;</span> /var/lib/mysql/mysql.ibd 
fd <span>34</span> -<span>&gt;</span> /var/lib/mysql/napkin/products.ibd 
fd <span>99</span> -<span>&gt;</span> /var/lib/mysql/binlog.000019 
^C

@fsyncs<span>[</span><span>9</span><span>]</span>: <span>2</span>
@fsyncs<span>[</span><span>12</span><span>]</span>: <span>2</span>
@fsyncs<span>[</span><span>27</span><span>]</span>: <span>12</span>
@fsyncs<span>[</span><span>34</span><span>]</span>: <span>47</span>
@fsyncs<span>[</span><span>13</span><span>]</span>: <span>86</span>
@fsyncs<span>[</span><span>15</span><span>]</span>: <span>93</span>
@fsyncs<span>[</span><span>11</span><span>]</span>: <span>103</span>
@fsyncs<span>[</span><span>99</span><span>]</span>: <span>2962</span>
@fsyncs<span>[</span><span>5</span><span>]</span>: <span>4887</span>
</code></pre>
<p>What we can observe here is that the majority of the writes are to the “redo
log”, what we call the “write-ahead-log” (WAL). There’s a few <code>fsync</code> calls to
commit the InnoDB table-space, not nearly as often, as we can always recover
this from the WAL in case we crash between them. Reads work just fine prior to
the <code>fsync</code>, as the queries can simply be served out of memory from InnoDB.</p>
<p>The only surprising thing here is the substantial volume of writes to the
binlog, which we haven’t mentioned before. You can think of the binlog as the
“replication stream.” It’s a stream of events such as <code>row a changed from x to y</code>, <code>row b was deleted</code>, and <code>table u added column c</code>. The primary replica
streams this to the read-replicas, which use it to update their own data.</p>
<p>When you think about it, the <code>binlog</code> and the WAL need to be kept exactly in
sync. We can’t have something committed on the primary replica, but not
committed to the replicas. If they’re not in sync, this could cause loss of data
due to drift in the read-replicas. The primary could commit a change to the WAL,
lose power, recover, and never write it to the binlog.</p>
<p>Since <code>fsync(1)</code> can only sync a single file-descriptor at a time, how can you
possibly ensure that the <code>binlog</code> and the WAL contain the transaction?</p>
<p>One solution would be to merge the <code>binlog</code> and the <code>WAL</code> into one log. I’m not
entirely sure why that’s not the case, but likely the reasons are historic. If
you know, let me know!</p>
<p>The solution employed by MySQL is to use a 2-factor commit. This requires three
<code>fsync</code>s to commit the transaction. <a href="https://www.burnison.ca/notes/fun-mysql-fact-of-the-day-everything-is-two-phase">This</a> and <a href="https://kristiannielsen.livejournal.com/12254.html">this reference</a> explain
this process in more detail. Because the WAL is touched twice as part of the
2-factor commit, it explains why we see roughly ~2x the number of <code>fsync</code> to
that over the bin-log from the bpftrace output above. The process of grouping
multiple transactions into one 2-factor commit in MySQL is called ‘group commit.’</p>
<p>What we can gather from these numbers is that it seems the ~16,000 transactions
were, thanks to group commit, reduced into ~2885 commits, or ~5.5 transactions
per commit on average.</p>
<p>But there’s still one other thing remaining… why was the average latency per
<code>fsync</code> twice as fast as in our benchmark? Once again, we write a simple
<code>bpftrace</code> script:</p>
<pre><code>tracepoint:syscalls:sys_enter_fsync,tracepoint:syscalls:sys_enter_fdatasync
/comm == &#34;mysqld&#34;/
{
        @start[tid] = nsecs;
}

tracepoint:syscalls:sys_exit_fsync,tracepoint:syscalls:sys_exit_fdatasync
/comm == &#34;mysqld&#34;/
{
        @bytes = lhist((nsecs - @start[tid]) / 1000, 0, 1500, 100);
        delete(@start[tid]);
}
</code></pre>
<p>Which throws us this histogram, confirming that we’re seeing some <em>very</em> fast
<code>fsync</code>s:</p>
<pre><code><span><span><span>personal@napkin</span><span>:</span><span>~</span></span><span>$</span> <span><span>sudo</span> bpftrace fsync_latency.d</span></span>
<span>Attaching 4 probes...
^C

@bytes:
[0, 100)             439 |@@@@@@@@@@@@@@@                                     |
[100, 200)             8 |                                                    |
[200, 300)             2 |                                                    |
[300, 400)           242 |@@@@@@@@                                            |
[400, 500)          1495 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@|
[500, 600)           768 |@@@@@@@@@@@@@@@@@@@@@@@@@@                          |
[600, 700)           376 |@@@@@@@@@@@@@                                       |
[700, 800)           375 |@@@@@@@@@@@@@                                       |
[800, 900)           379 |@@@@@@@@@@@@@                                       |
[900, 1000)          322 |@@@@@@@@@@@                                         |
[1000, 1100)         256 |@@@@@@@@                                            |
[1100, 1200)         406 |@@@@@@@@@@@@@@                                      |
[1200, 1300)         690 |@@@@@@@@@@@@@@@@@@@@@@@@                            |
[1300, 1400)         803 |@@@@@@@@@@@@@@@@@@@@@@@@@@@                         |
[1400, 1500)         582 |@@@@@@@@@@@@@@@@@@@@                                |
[1500, ...)         1402 |@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@    |
</span></code></pre>
<p>To understand exactly what’s going on here, we’d have to dig into the
file-system we’re using. This is going to be out of scope (otherwise I’m never
going to be sending anything out). But, to not leave you completely hanging,
presumably, <code>ext4</code> is using techniques similar to MySQL’s group commit to batch
writes together in the journal (equivalent to the write-ahead-log of MySQL). In
ext4’s vocabulary, this seems to be called <a href="https://www.kernel.org/doc/Documentation/filesystems/ext4.txt"><code>max_batch_time</code></a>, but the
documentation on this is scanty at best. The disk could also be doing this in
addition/instead of the file-system. If you know more about this, please
enlighten me!</p>
<p>The bottom-line is that <code>fsync</code> can perform faster during real-life workloads than the
1 ms I obtain on this machine from repeatedly writing and <code>fsync</code>ing a file. Most
likely from the ext4 equivalent of group commit, which we won’t see on a
benchmark that never does multiple <code>fsync</code>s in parallel.</p>
<p>This brings us back around to explaining the discrepancy between real-life and
the napkin-math of MySQL’s theoretical, maximum throughput. We are able to
achieve an at least 5x increase in throughput from raw <code>fsync</code> calls due to:</p>
<ol>
<li>MySQL merging multiple transactions into fewer <code>fsync</code>s through ‘group commits.’</li>
<li>The file-system and/or disk merging multiple <code>fsync</code>s performed in parallel
through its own ‘group commits’, yielding faster performance.</li>
</ol>
<p>In essence, the same technique of batching is used at every layer to improve
performance.</p>
<p>While we didn’t manage to explain <em>everything</em> that’s going on here, I certainly
learned a lot from this investigation. It’d be interesting light of this to play
with changing the <a href="https://mariadb.com/kb/en/group-commit-for-the-binary-log/#changing-group-commit-frequency">group commit settings</a> to optimize MySQL for throughput over
latency. This could also be tuned at the file-system level.</p>
<h2 id="problem-9-inverted-index">Problem 9: Inverted Index<svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="currentColor" viewBox="0 0 24 24"><path d="M9.199 13.599a5.99 5.99 0 0 0 3.949 2.345 5.987 5.987 0 0 0 5.105-1.702l2.995-2.994a5.992 5.992 0 0 0 1.695-4.285 5.976 5.976 0 0 0-1.831-4.211 5.99 5.99 0 0 0-6.431-1.242 6.003 6.003 0 0 0-1.905 1.24l-1.731 1.721a.999.999 0 1 0 1.41 1.418l1.709-1.699a3.985 3.985 0 0 1 2.761-1.123 3.975 3.975 0 0 1 2.799 1.122 3.997 3.997 0 0 1 .111 5.644l-3.005 3.006a3.982 3.982 0 0 1-3.395 1.126 3.987 3.987 0 0 1-2.632-1.563A1 1 0 0 0 9.201 13.6zm5.602-3.198a5.99 5.99 0 0 0-3.949-2.345 5.987 5.987 0 0 0-5.105 1.702l-2.995 2.994a5.992 5.992 0 0 0-1.695 4.285 5.976 5.976 0 0 0 1.831 4.211 5.99 5.99 0 0 0 6.431 1.242 6.003 6.003 0 0 0 1.905-1.24l1.723-1.723a.999.999 0 1 0-1.414-1.414L9.836 19.81a3.985 3.985 0 0 1-2.761 1.123 3.975 3.975 0 0 1-2.799-1.122 3.997 3.997 0 0 1-.111-5.644l3.005-3.006a3.982 3.982 0 0 1 3.395-1.126 3.987 3.987 0 0 1 2.632 1.563 1 1 0 0 0 1.602-1.198z"></path></svg></h2>
<p><a href="https://sirupsen.com/napkin/problem-9/">Last month, we looked at the inverted
index.</a> This data-structure is what’s
behind full-text search, and the way the documents are packed works well for set
intersections.</p>
<figure><img alt="" loading="lazy" width="1007" height="648" decoding="async" data-nimg="1" sizes="(min-width: 36rem) 36rem 100vw" srcset="/_next/image?url=%2Fimages%2F66641ef5-efe4-440a-a616-0d30310e7540.png&amp;w=640&amp;q=75 640w, /_next/image?url=%2Fimages%2F66641ef5-efe4-440a-a616-0d30310e7540.png&amp;w=750&amp;q=75 750w, /_next/image?url=%2Fimages%2F66641ef5-efe4-440a-a616-0d30310e7540.png&amp;w=828&amp;q=75 828w, /_next/image?url=%2Fimages%2F66641ef5-efe4-440a-a616-0d30310e7540.png&amp;w=1080&amp;q=75 1080w, /_next/image?url=%2Fimages%2F66641ef5-efe4-440a-a616-0d30310e7540.png&amp;w=1200&amp;q=75 1200w, /_next/image?url=%2Fimages%2F66641ef5-efe4-440a-a616-0d30310e7540.png&amp;w=1920&amp;q=75 1920w, /_next/image?url=%2Fimages%2F66641ef5-efe4-440a-a616-0d30310e7540.png&amp;w=2048&amp;q=75 2048w, /_next/image?url=%2Fimages%2F66641ef5-efe4-440a-a616-0d30310e7540.png&amp;w=3840&amp;q=75 3840w" src="https://sirupsen.com/_next/image?url=%2Fimages%2F66641ef5-efe4-440a-a616-0d30310e7540.png&amp;w=3840&amp;q=75"/></figure>
<p><strong>(A) How long do you estimate it’d take to get the ids for <code>title AND see</code> with 2
million ids for title, and 1 million for see?</strong></p>
<p>Let’s assume that each document id is stored as a 64-bit integer. Then we’re
dealing with <code>1 * 10^6 * 64bit = 8 Mb</code> and <code>2 * 10^6 * 64 bit = 16 Mb</code>. If we
use an exceptionally simple set intersection algorithm of essentially two nested
for-loops, we need to scan ~<code>24Mb</code> of sequential memory. According to the
<a href="https://github.com/sirupsen/napkin-math">reference</a>, we can do this in <code>1Mb/100us * 24Mb = 2.4ms</code>.</p>
<p>Strangely, the Lucene <a href="https://home.apache.org/~mikemccand/lucenebench/AndHighHigh.html">nightly benchmarks</a> are performing these queries at
roughly 22 QPS, or <code>1000ms/22 = 45ms</code> per query. That’s substantially worse than
our prediction. I was ready to explain why Lucene might be <em>faster</em> (e.g. by
compressing postings to less than 64-bit), but not why it might be 20x slower!
We’ve got ourselves another first-principle gap.</p>
<p>Some slowness can be due to reading from disk, but since the access pattern is
sequential, it <a href="https://github.com/sirupsen/napkin-math">should only be 2-3x slower</a>. The hardware could be different
than the reference, but hardly anything that’d explain 20x. Sending the data to
the client might incur a large penalty, but again, 20x seems enormous. This type
of gap points towards missing something fundamental (as we saw with MySQL).
Unfortunately, this month I didn’t have time to dig much deeper than this, as I
prioritized the MySQL post.</p>
<p><strong>(B) What about title OR see?</strong></p>
<p>In this case we’d have to scan roughly as much memory, but handle more documents
and potentially transfer more back to the client. We’d expect to roughly be in
the same ballpark for performance ~<code>2.4ms</code>.</p>
<p>Lucene in this case is doing <a href="https://home.apache.org/~mikemccand/lucenebench/OrHighHigh.html">roughly half the throughput</a>, which aligns with
our relative expectations. But again, in absolute terms, Lucene’s handling these
queries in ~100ms, which is much, much higher than we expect.</p>
<p><strong>(C) How do the Lucene nightly benchmarks compare for (A) and (B)? This file
shows some of the actual terms used. If they don’t line up, how might you
explain the discrepency?</strong></p>
<p>Answered inline with (A) and (B).</p>
<p><strong>(D) Let’s imagine that we want title AND see and order the results by the last
modification date of each document. How long would you expect that to take?</strong></p>
<p>If the postings are not stored in that order, we’d naively expect in the worst
case we’d need to sort roughly ~24Mb of memory, <a href="https://github.com/sirupsen/napkin-math#numbers">at
5ms/Mb</a>. This would land us in the
<code>5mb/mb * 24mb ~= 120ms</code> query time ballpark.</p>
<p>In reality, this seems like an unintentional trick question. If ordered by last
modification date, they’d already be sorted in roughly that order, since new
documents are inserted to the end of the list. Which means they’re already
stored in <em>roughly</em> the right order, meaning our sort has to move far less bits
around. Even if that wasn’t the case, we could store sorted list for just this
column, which e.g. Lucene allows with doc values.</p><div><p>Subscribe through email,</p><!-- --> <p><a href="https://sirupsen.com/atom.xml">RSS</a></p><!-- --><p>or</p><!-- --> <p><a href="https://twitter.com/Sirupsen" title="Twitter" target="_blank" rel="noopener noreferrer">Twitter</a></p><!-- --><p>to new articles!</p><p> <!-- -->3,637<!-- --> <!-- -->subscribers</p></div><p><i>You might also like...</i></p><ul><li><a href="https://sirupsen.com/napkin/problem-14-using-checksums-to-verify">Using checksums to verify syncing 100M database records</a></li><li><a href="https://sirupsen.com/shitlists">Shitlist Driven Development</a></li><li><a href="https://sirupsen.com/napkin/neural-net">Neural Network From Scratch</a></li><li><a href="https://sirupsen.com/napkin/problem-9">Inverted Index Performance and Merkle Tree Syncronization</a></li><li><a href="https://sirupsen.com/napkin/problem-15">Increase HTTP Performance by Fitting In the Initial TCP Slow Start Window</a></li></ul></article></div>
  </body>
</html>
