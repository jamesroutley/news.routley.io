<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://leancrew.com/all-this/2024/11/square-roots-and-maxima/">Original</a>
    <h1>Square roots and maxima</h1>
    
    <div id="readability-page-1" class="page"><div id="container">
       <!-- header -->
      
      <div id="content">
        <p>
          <span></span>
          <a href="https://leancrew.com/all-this/2024/11/the-tetrahedral-days-of-christmas/">Previous post</a>        </p>
        
        <p>November 29, 2024 at  7:11 PM by Dr. Drang</p>
        <p>A few days ago, I saw this short YouTube video from Grant Sanderson at <a href="https://www.youtube.com/@3blue1brown">3Blue1Brown</a>:</p>

<iframe height="520" src="https://www.youtube.com/embed/Pny70rNPJLk" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe>

<p>The gist of the video is that if you have three independent random variables, <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>X</mi> <mn>1</mn></msub></math>, <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>X</mi> <mn>2</mn></msub></math>, and <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msub><mi>X</mi> <mn>3</mn></msub></math>, that are all uniformly distributed between 0 and 1, then</p>

<p><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><mi mathvariant="normal">P</mi><mo stretchy="false">[</mo><mi>max</mi><mo stretchy="false">(</mo><msub><mi>X</mi> <mn>1</mn></msub><mo>,</mo><msub><mi>X</mi> <mn>2</mn></msub><mo stretchy="false">)</mo><mo>≤</mo><mi>x</mi><mo stretchy="false">]</mo><mo>=</mo><mi mathvariant="normal">P</mi><mo stretchy="false">[</mo><msqrt><mrow><msub><mi>X</mi> <mn>3</mn></msub></mrow></msqrt><mo>≤</mo><mi>x</mi><mo stretchy="false">]</mo><mo>=</mo><msup><mi>x</mi> <mn>2</mn></msup></math></p><p>where <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi mathvariant="normal">P</mi><mo stretchy="false">[</mo><mo>⋅</mo><mo stretchy="false">]</mo></math> represents the probability of the thing in the brackets.</p>

<p>I should mention here that I’m not using the same notation as Grant. The textbook used in the class where I learned this sort of stuff was Ang and Tang’s <a href="https://catalog.loc.gov/vwebv/holdingsInfo?searchId=11641&amp;recCount=25&amp;recPointer=1&amp;bibId=4579293"><em>Probability Concepts in Engineering Planning and Design</em></a>. They used capital letters for random variables and lowercase letters for particular values. It’s a nice convention that makes it easy to distinguish the random from the nonrandom. I’ve stuck with it for 45 years and don’t intend to change.</p>

<p>The probability <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>P</mi><mo stretchy="false">[</mo><mi>X</mi><mo>≤</mo><mi>x</mi><mo stretchy="false">]</mo></math> is a function of <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>x</mi></math> and is known as the <em>cumulative distribution function</em><sup id="fnref:bell"><a href="#fn:bell" rel="footnote">1</a></sup> (CDF) of <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>X</mi></math>. Therefore, the probabilities given above are the CDFs of the functions <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>max</mi><mo stretchy="false">(</mo><msub><mi>X</mi> <mn>1</mn></msub><mo>,</mo><msub><mi>X</mi> <mn>2</mn></msub><mo stretchy="false">)</mo></math> and <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><msqrt><mrow><msub><mi>X</mi> <mn>3</mn></msub></mrow></msqrt></math>.</p>

<p>Grant does his usual excellent job of explaining why these two functions have the same CDF, but if you have any doubts, it’s fairly easy to check his work numerically. This is one of the great advantages of having so much computing power at our disposal.</p>

<p>We’ll generate three sets of <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>n</mi></math> random numbers from the uniform distribution, apply the <code>max</code> and <code>sqrt</code> functions to them, and sort the results in ascending order. Then we can estimate the probabilities by dividing the rank of each value—that is, its position in the sorted list—by <math xmlns="http://www.w3.org/1998/Math/MathML" display="inline"><mi>n</mi></math>.</p>

<p>Let’s look at an example of how this works. We’ll generate 20 random numbers from a uniform distribution between 0 and 1, take their square roots, and sort them. Here are the sorted values, their ranks, and the ranks divided by 20.</p>

<table>
<thead>
<tr>
  <th>Value</th>
  <th>Rank</th>
  <th>Rank/20</th>
</tr>
</thead>
<tbody>
<tr>
  <td>0.15153773</td>
  <td>1</td>
  <td>0.05</td>
</tr>
<tr>
  <td>0.31017013</td>
  <td>2</td>
  <td>0.10</td>
</tr>
<tr>
  <td>0.32107819</td>
  <td>3</td>
  <td>0.15</td>
</tr>
<tr>
  <td>0.36746846</td>
  <td>4</td>
  <td>0.20</td>
</tr>
<tr>
  <td>0.47920455</td>
  <td>5</td>
  <td>0.25</td>
</tr>
<tr>
  <td>0.51328779</td>
  <td>6</td>
  <td>0.30</td>
</tr>
<tr>
  <td>0.55133211</td>
  <td>7</td>
  <td>0.35</td>
</tr>
<tr>
  <td>0.65800726</td>
  <td>8</td>
  <td>0.40</td>
</tr>
<tr>
  <td>0.72510687</td>
  <td>9</td>
  <td>0.45</td>
</tr>
<tr>
  <td>0.76085816</td>
  <td>10</td>
  <td>0.50</td>
</tr>
<tr>
  <td>0.80286435</td>
  <td>11</td>
  <td>0.55</td>
</tr>
<tr>
  <td>0.81393308</td>
  <td>12</td>
  <td>0.60</td>
</tr>
<tr>
  <td>0.82690246</td>
  <td>13</td>
  <td>0.65</td>
</tr>
<tr>
  <td>0.90907066</td>
  <td>14</td>
  <td>0.70</td>
</tr>
<tr>
  <td>0.91344562</td>
  <td>15</td>
  <td>0.75</td>
</tr>
<tr>
  <td>0.91666637</td>
  <td>16</td>
  <td>0.80</td>
</tr>
<tr>
  <td>0.91701938</td>
  <td>17</td>
  <td>0.85</td>
</tr>
<tr>
  <td>0.94649904</td>
  <td>18</td>
  <td>0.90</td>
</tr>
<tr>
  <td>0.94874985</td>
  <td>19</td>
  <td>0.95</td>
</tr>
<tr>
  <td>0.99254165</td>
  <td>20</td>
  <td>1.00</td>
</tr>
</tbody>
</table>

<p>Plotting these points, we get</p>

<p><img width="100%" src="https://leancrew.com/all-this/images2024/20241129-CDF%20points%20for%20square%20root.png" alt="CDF points for square root" title="CDF points for square root"/></p>

<p>where I’ve added extra points at (0, 0) and (1, 1) to remind us that those are the limits; no value can be less than or equal to 0 and all values must be less than or equal to 1.</p>

<p>To complete the plot, there should be a horizontal line from each point to the next <em>x</em> value, where the function should then jump up to the next point.</p>

<p><img width="100%" src="https://leancrew.com/all-this/images2024/20241129-CDF%20points%20with%20lines%20for%20square%20root.png" alt="CDF points with lines for square root" title="CDF points with lines for square root"/></p>

<p>Why? Because, for example, 40% (8 of 20) of the sample values are less than or equal to <em>any</em> value from 0.65800726 (inclusive) and 0.72510687 (exclusive). Similarly for all the other in-between portions of the graph.</p>

<p>Since there’s a step at each <em>x</em> value, we don’t need to show the points, just the lines. Here’s a plot of both the <code>max</code> and <code>sqrt</code> sample CDFs for 20 samples, along with the analytical solution given by Grant:</p>

<p><img width="100%" src="https://leancrew.com/all-this/images2024/20241129-CDF%20comparison%20with%2020%20samples.png" alt="CDF comparison with 20 samples" title="CDF comparison with 20 samples"/></p>

<p>The sample CDFs look reasonably close to the analytical one. Let’s bump up the number of samples to 100 and see what we get:</p>

<p><img width="100%" src="https://leancrew.com/all-this/images2024/20241129-CDF%20comparison%20with%20100%20samples.png" alt="CDF comparison with 100 samples" title="CDF comparison with 100 samples"/></p>

<p>Closer to the analytical result, as expected. Just to be ridiculous, we’ll do it again with 10,000 samples:</p>

<p><img width="100%" src="https://leancrew.com/all-this/images2024/20241129-CDF%20comparison%20with%2010000%20samples.png" alt="CDF comparison with 10000 samples" title="CDF comparison with 10000 samples"/></p>

<p>With this many samples, you can’t even see the steps, but it’s clear that both of the sample CDFs are converging to the analytical one.</p>

<p>If you have some background in statistics, you might be expecting me to run the <a href="https://online.stat.psu.edu/stat415/book/export/html/838">Kolmogorov-Smirnov test</a> to check the goodness of fit between the sample and the analytical CDFs. But I think what we’ve done is a sufficient check on Grant’s work (as if that were needed). You can go ahead with the K-S test on your own.</p>

<p>Although running a numerical check was nice, my main purpose in making these graphs was to see how to use the <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.step.html"><code>step</code> method</a> in Matplotlib. It’s a  plotting routine made especially for this type of graph. While you can use the usual <a href="https://matplotlib.org/stable/api/_as_gen/matplotlib.pyplot.plot.html"><code>plot</code></a> for a stepwise function, you’d have to first construct arrays with two values for every step. The advantage in using <code>step</code> is that it takes care of all that bookkeeping. The arrays you pass to it need only one value for each step; it takes care of plotting the second value automatically.</p>

<p>Here’s the code that produces the graph for 20 samples:</p>

<pre><code>python:
 1:  #!/usr/bin/env python3
 2:  
 3:  import numpy as np
 4:  import matplotlib.pyplot as plt
 5:  
 6:  # CDF by analysis
 7:  x = np.linspace(0, 1, 101)
 8:  cdfAnalysis = x**2
 9:  
10:  # Sample CDFs using random numbers
11:  rng = np.random.default_rng(seed=1732895964)
12:  n = 20
13:  heights = np.linspace(0, n, n+1)/n
14:  heights = np.concatenate((heights, np.ones(1)))
15:  
16:  # Max of two uniform variates
17:  X1 = rng.uniform(0, 1, n)
18:  X2 = rng.uniform(0, 1, n)
19:  Xmax = np.sort(np.maximum(X1, X2))
20:  Xmax = np.concatenate((np.zeros(1), Xmax, np.ones(1)))
21:  
22:  # Sqrt of uniform variate
23:  X3 = rng.uniform(0, 1, n)
24:  Xsqrt = np.sort(np.sqrt(X3))
25:  Xsqrt = np.concatenate((np.zeros(1), Xsqrt, np.ones(1)))
26:  
27:  # Create the plot with a given size in inches
28:  fig, ax = plt.subplots(figsize=(6, 4), layout=&#39;tight&#39;)
29:  
30:  # Add plots
31:  ax.step(Xmax, heights, where=&#39;post&#39;, color=&#39;#7570b3&#39;, lw=2, label=&#39;Max&#39;)
32:  ax.step(Xsqrt, heights, where=&#39;post&#39;, color=&#39;#e7298a&#39;, lw=2, label=&#39;Sqrt&#39;)
33:  ax.plot(x, cdfAnalysis, &#39;--&#39;, color=&#39;black&#39;, lw=1, label=&#39;Analysis&#39;)
34:  
35:  # Title and axis labels
36:  plt.title(f&#39;CDFs (n = {n:,d})&#39;)
37:  plt.xlabel(&#39;x&#39;)
38:  plt.ylabel(&#39;Probability&#39;)
39:  
40:  # Make the border and tick marks 0.5 points wide
41:  [ i.set_linewidth(0.5) for i in ax.spines.values() ]
42:  ax.tick_params(which=&#39;both&#39;, width=.5)
43:  
44:  # Add the legend
45:  ax.legend(loc=(.1, .6))
46:  
47:  # Save as PDF
48:  plt.savefig(f&#39;20241129-CDF comparison with {n} samples.png&#39;, format=&#39;png&#39;, dpi=200)
</code></pre>

<p>The values used to plot the analytical results are given in Lines 7–8. I like NumPy’s <code>linspace</code> function because it works by default the way I think: you give it the start and end values and the number of values to generate and off it goes. No worries about whether the end value is included or not. It is.</p>

<p>The next section, Lines 11–14, sets up the random number generator and the step heights for both the <code>max</code> and <code>sqrt</code> samples. You can specify the <a href="https://en.wikipedia.org/wiki/Random_seed">seed value</a> for NumPy’s random number generator, which is helpful when you’re editing and debugging code and want to get the same set of values every time you run the script. The seed I used was the time I started writing this code in <a href="https://en.wikipedia.org/wiki/Unix_time">epoch seconds</a>. I got it from the command line using</p>

<pre><code>date +&#39;%s&#39;
</code></pre>

<p>Another advantage of setting the seed is that anyone else who runs the code will get the same plot I got.</p>

<p>Although this code is for 20 samples, Line 12 can be edited to handle any number of samples.</p>

<p>The <a href="https://numpy.org/doc/stable/reference/generated/numpy.concatenate.html"><code>concatenate</code> function</a> in Line 14 adds an extra 1 to the end of the <code>heights</code> variable. I discussed the reason for doing that earlier in the post. It’s of some small value with just 20 samples but not very useful when we get up to 10,000.</p>

<p>Lines 17–20 generate the <em>x</em> values for the <code>max</code> samples. They generate two sets of random numbers that are uniformly distributed between 0 and 1, get the maximum of each pair, and sort them in ascending order. The <code>concatenate</code> function was then used to add a 0 at the front of the <code>Xmax</code> array and a 1 at the end.</p>

<p>Lines 23–25 generate the <em>x</em> values for the <code>sqrt</code> samples. The process is similar to the <code>max</code> samples but we need to generate only one set of random numbers.</p>

<p>From this point on, it’s all plotting. The key feature is the use of <code>step</code> in Lines 31 and 32. The <em>x</em> values (either <code>Xmax</code> or <code>Xsqrt</code>) and <code>heights</code> are passed to <code>step</code>, and it handles all the plotting. An interesting parameter is <code>where</code>, which can be assigned either <code>pre</code> (the default) or <code>post</code>. The <code>where</code> parameter dictates whether the horizontal parts of the graph are plotted before or after each given point. Because of the way I set up the various arrays, <code>post</code> was the correct choice.</p>

<p>I got the color values in Lines 31 and 32 from the <a href="https://colorbrewer2.org/#type=sequential&amp;scheme=BuGn&amp;n=3">ColorBrewer site</a>. They’re meant to be easy to distinguish for both colorblind and non-colorblind viewers. I suspect there’s a way to specify the ColorBrewer colors in Matplotlib automatically, but I haven’t looked into it.</p>

<p>The only other interesting part of the code is that Lines 36 and 48 change the title and filename according to the number of samples specified on Line 12.</p>

<p>As I said, it’s nice to have computers around to check on your analysis. Numerical integration and differentiation, Monte Carlo simulation, and graphing results are all things that can get you results quickly if you teach yourself how to use the software that’s available. These are certainly not proofs, and there’s always the danger of setting up your computer solution incorrectly—it’s easy to follow the same wrong path numerically that you followed analytically. But when done with care, these checks can give you confidence that you may not have with an analytical solution by itself.</p>


        <p>
          <span></span>
          <a href="https://leancrew.com/all-this/2024/11/the-tetrahedral-days-of-christmas/">Previous post</a>        </p>

      </div> <!-- content -->
      
       <!-- sidebar -->
       
       <!-- footer -->
    </div></div>
  </body>
</html>
