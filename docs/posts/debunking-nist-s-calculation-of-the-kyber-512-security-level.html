<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.cr.yp.to/20231003-countcorrectly.html">Original</a>
    <h1>Debunking NIST&#39;s calculation of the Kyber-512 security level</h1>
    
    <div id="readability-page-1" class="page">

<hr/>
<div>
<p>Older (Access-J): <a href="https://accelerated-computing.com/blog/notes-on-neural-networks-01-basic-concepts/20230609-turboboost.html" accesskey="j"><b>2023.06.09: Turbo Boost:</b></a> <span>How to perpetuate security problems. #overclocking #performancehype #power #timing #hertzbleed #riskmanagement #environment</span></p>
<details><summary>Table of contents (Access-I for index page)</summary>
<table>
<tbody><tr><td><b>2023.10.03: The inability to count correctly:</b> Debunking NIST&#39;s calculation of the Kyber-512 security level. #nist #addition #multiplication #ntru #kyber #fiasco</td></tr>
<tr><td><a href="https://accelerated-computing.com/blog/notes-on-neural-networks-01-basic-concepts/20230609-turboboost.html"><b>2023.06.09: Turbo Boost:</b></a> <span>How to perpetuate security problems. #overclocking #performancehype #power #timing #hertzbleed #riskmanagement #environment</span></td></tr>
<tr><td><a href="https://accelerated-computing.com/blog/notes-on-neural-networks-01-basic-concepts/20220805-nsa.html"><b>2022.08.05: NSA, NIST, and post-quantum cryptography:</b></a> <span>Announcing my second lawsuit against the U.S. government. #nsa #nist #des #dsa #dualec #sigintenablingproject #nistpqc #foia</span></td></tr>
<tr><td><a href="https://accelerated-computing.com/blog/notes-on-neural-networks-01-basic-concepts/20220129-plagiarism.html"><b>2022.01.29: Plagiarism as a patent amplifier:</b></a> <span>Understanding the delayed rollout of post-quantum cryptography. #pqcrypto #patents #ntru #lpr #ding #peikert #newhope</span></td></tr>
<tr><td><a href="https://accelerated-computing.com/blog/notes-on-neural-networks-01-basic-concepts/20201206-msword.html"><b>2020.12.06: Optimizing for the wrong metric, part 1: Microsoft Word:</b></a> <span>Review of &#34;An Efficiency Comparison of Document Preparation Systems Used in Academic Research and Development&#34; by Knauff and Nejasmic. #latex #word #efficiency #metrics</span></td></tr>
<tr><td><a href="https://accelerated-computing.com/blog/notes-on-neural-networks-01-basic-concepts/20191024-eddsa.html"><b>2019.10.24: Why EdDSA held up better than ECDSA against Minerva:</b></a> <span>Cryptosystem designers successfully predicting, and protecting against, implementation failures. #ecdsa #eddsa #hnp #lwe #bleichenbacher #bkw</span></td></tr>
<tr><td><a href="https://accelerated-computing.com/blog/notes-on-neural-networks-01-basic-concepts/20190430-vectorize.html"><b>2019.04.30: An introduction to vectorization:</b></a> <span>Understanding one of the most important changes in the high-speed-software ecosystem. #vectorization #sse #avx #avx512 #antivectors</span></td></tr>
<tr><td><a href="https://accelerated-computing.com/blog/notes-on-neural-networks-01-basic-concepts/20171105-infineon.html"><b>2017.11.05: Reconstructing ROCA:</b></a> <span>A case study of how quickly an attack can be developed from a limited disclosure. #infineon #roca #rsa</span></td></tr>
<tr><td><a href="https://accelerated-computing.com/blog/notes-on-neural-networks-01-basic-concepts/20171017-collisions.html"><b>2017.10.17: Quantum algorithms to find collisions:</b></a> <span>Analysis of several algorithms for the collision problem, and for the related multi-target preimage problem. #collision #preimage #pqcrypto</span></td></tr>
<tr><td><a href="https://accelerated-computing.com/blog/notes-on-neural-networks-01-basic-concepts/20170723-random.html"><b>2017.07.23: Fast-key-erasure random-number generators:</b></a> <span>An effort to clean up several messes simultaneously. #rng #forwardsecrecy #urandom #cascade #hmac #rekeying #proofs</span></td></tr>
<tr><td><a href="https://accelerated-computing.com/blog/notes-on-neural-networks-01-basic-concepts/20170719-pqbench.html"><b>2017.07.19: Benchmarking post-quantum cryptography:</b></a> <span>News regarding the SUPERCOP benchmarking system, and more recommendations to NIST. #benchmarking #supercop #nist #pqcrypto</span></td></tr>
<tr><td><a href="https://accelerated-computing.com/blog/notes-on-neural-networks-01-basic-concepts/20161030-pqnist.html"><b>2016.10.30: Some challenges in post-quantum standardization:</b></a> <span>My comments to NIST on the first draft of their call for submissions. #standardization #nist #pqcrypto</span></td></tr>
<tr><td><a href="https://accelerated-computing.com/blog/notes-on-neural-networks-01-basic-concepts/20160607-dueprocess.html"><b>2016.06.07: The death of due process:</b></a> <span>A few notes on technology-fueled normalization of lynch mobs targeting both the accuser and the accused. #ethics #crime #punishment</span></td></tr>
<tr><td><a href="https://accelerated-computing.com/blog/notes-on-neural-networks-01-basic-concepts/20160516-quantum.html"><b>2016.05.16: Security fraud in Europe&#39;s &#34;Quantum Manifesto&#34;:</b></a> <span>How quantum cryptographers are stealing a quarter of a billion Euros from the European Commission. #qkd #quantumcrypto #quantummanifesto</span></td></tr>
<tr><td><a href="https://accelerated-computing.com/blog/notes-on-neural-networks-01-basic-concepts/20160315-jefferson.html"><b>2016.03.15: Thomas Jefferson and Apple versus the FBI:</b></a> <span>Can the government censor how-to books? What if some of the readers are criminals? What if the books can be understood by a computer? An introduction to freedom of speech for software publishers. #censorship #firstamendment #instructions #software #encryption</span></td></tr>
<tr><td><a href="https://accelerated-computing.com/blog/notes-on-neural-networks-01-basic-concepts/20151120-batchattacks.html"><b>2015.11.20: Break a dozen secret keys, get a million more for free:</b></a> <span>Batch attacks are often much more cost-effective than single-target attacks. #batching #economics #keysizes #aes #ecc #rsa #dh #logjam</span></td></tr>
<tr><td><a href="https://accelerated-computing.com/blog/notes-on-neural-networks-01-basic-concepts/20150314-optimizing.html"><b>2015.03.14: The death of optimizing compilers:</b></a> <span>Abstract of my tutorial at ETAPS 2015. #etaps #compilers #cpuevolution #hotspots #optimization #domainspecific #returnofthejedi</span></td></tr>
<tr><td><a href="https://accelerated-computing.com/blog/notes-on-neural-networks-01-basic-concepts/20150218-printing.html"><b>2015.02.18: Follow-You Printing:</b></a> <span>How Equitrac&#39;s marketing department misrepresents and interferes with your work. #equitrac #followyouprinting #dilbert #officespaceprinter</span></td></tr>
<tr><td><a href="https://accelerated-computing.com/blog/notes-on-neural-networks-01-basic-concepts/20140602-saber.html"><b>2014.06.02: The Saber cluster:</b></a> <span>How we built a cluster capable of computing 3000000000000000000000 multiplications per year for just 50000 EUR. #nvidia #linux #howto</span></td></tr>
<tr><td><a href="https://accelerated-computing.com/blog/notes-on-neural-networks-01-basic-concepts/20140517-insns.html"><b>2014.05.17: Some small suggestions for the Intel instruction set:</b></a> <span>Low-cost changes to CPU architecture would make cryptography much safer and much faster. #constanttimecommitment #vmul53 #vcarry #pipelinedocumentation</span></td></tr>
<tr><td><a href="https://accelerated-computing.com/blog/notes-on-neural-networks-01-basic-concepts/20140411-nist.html"><b>2014.04.11: NIST&#39;s cryptographic standardization process:</b></a> <span>The first step towards improvement is to admit previous failures. #standardization #nist #des #dsa #dualec #nsa</span></td></tr>
<tr><td><a href="https://accelerated-computing.com/blog/notes-on-neural-networks-01-basic-concepts/20140323-ecdsa.html"><b>2014.03.23: How to design an elliptic-curve signature system:</b></a> <span>There are many choices of elliptic-curve signature systems. The standard choice, ECDSA, is reasonable if you don&#39;t care about simplicity, speed, and security. #signatures #ecc #elgamal #schnorr #ecdsa #eddsa #ed25519</span></td></tr>
<tr><td><a href="https://accelerated-computing.com/blog/notes-on-neural-networks-01-basic-concepts/20140213-ideal.html"><b>2014.02.13: A subfield-logarithm attack against ideal lattices:</b></a> <span>Computational algebraic number theory tackles lattice-based cryptography.</span></td></tr>
<tr><td><a href="https://accelerated-computing.com/blog/notes-on-neural-networks-01-basic-concepts/20140205-entropy.html"><b>2014.02.05: Entropy Attacks!</b></a> <span>The conventional wisdom says that hash outputs can&#39;t be controlled; the conventional wisdom is simply wrong.</span></td></tr>
</tbody></table></details></div><hr/>
<h2>2023.10.03: The inability to count correctly: <span>Debunking NIST&#39;s calculation of the Kyber-512 security level. #nist #addition #multiplication #ntru #kyber #fiasco</span></h2>
<p><img src="https://accelerated-computing.com/blog/notes-on-neural-networks-01-basic-concepts/20231003/longevity.png"/></p>
<p>[Sidney Harris cartoon used with permission.
Copyright holder: <a href="http://sciencecartoonsplus.com/">ScienceCartoonsPlus.com</a>.]</p>
<p>Quick, what&#39;s 2<sup>40</sup> plus 2<sup>40</sup>?
It&#39;s 2<sup>80</sup>, right?</p>
<p>No, obviously not.
40 plus 40 is 80,
and
2<sup>40</sup> <em>times</em> 2<sup>40</sup> is 2<sup>80</sup>,
but
2<sup>40</sup> <em>plus</em> 2<sup>40</sup> is only 2<sup>41</sup>.</p>
<p><strong>Take a deep breath and relax.</strong>
When cryptographers
are analyzing the security of
cryptographic systems,
<em>of course</em>
they don&#39;t make stupid mistakes such as
multiplying numbers that should have been added.</p>
<p>If such an error somehow managed to appear,
<em>of course</em> it would immediately be caught
by the robust procedures that cryptographers follow
to thoroughly review security analyses.</p>
<p>Furthermore,
in the context of standardization processes
such as the NIST Post-Quantum Cryptography Standardization Project (NISTPQC),
<em>of course</em> the review procedures are even more stringent.</p>
<p>The only way
for the security claims for modern cryptographic standards
to turn out to fail
would be because of some unpredictable new discovery
revolutionizing the field.</p>
<p><strong>Oops, wait, maybe not.</strong>
In 2022,
NIST announced plans to standardize
a particular cryptosystem, Kyber-512.
As justification, NIST issued claims
regarding the security level of Kyber-512.
In 2023,
NIST issued a draft standard for Kyber-512.</p>
<p>NIST&#39;s underlying calculation of the security level
was a severe and indefensible miscalculation.
NIST&#39;s primary error is exposed in this blog post,
and boils down to nonsensically <em>multiplying</em> two costs that should have been <em>added</em>.</p>
<p>How did such a serious error
slip past NIST&#39;s review process?
Do we dismiss this as an isolated incident?
Or do we conclude that something is fundamentally broken
in the procedures that NIST is following?</p>
<p><strong>Discovering the secret workings of NISTPQC.</strong> 
I filed a FOIA request
<a href="https://blog.cr.yp.to/20220805-nsa.html">&#34;NSA, NIST, and post-quantum cryptography&#34;</a>
in March 2022.
NIST stonewalled, in violation of the law.
Civil-rights firm
<a href="https://loevy.com">Loevy &amp; Loevy</a>
filed a lawsuit on my behalf.</p>
<p>That lawsuit has been gradually
<a href="https://nist.pqcrypto.org/foia/index.html">revealing</a>
secret NIST documents,
shedding some light on what was actually going on behind the scenes,
including much heavier NSA involvement than indicated by NIST&#39;s public narrative.
Compare, for example, the following documents:</p>
<ul>
<li>
<p>A <a href="https://web.archive.org/web/20230910091944/https://csrc.nist.gov/CSRC/media/Events/ISPAB-MARCH-2014-MEETING/documents/a_quantum_world_v1_ispab_march_2014.pdf">public 2014 document</a>
says that its author is
&#34;Post Quantum Cryptography Team, National Institute of Standards and Technology
(NIST), pqc@nist.gov&#34;.</p>
</li>
<li>
<p>A <a href="https://nist.pqcrypto.org/foia/index.html#20230815/Re_%20pqc%20mailing list(1)-3.pdf">secret 2016 document</a>
listed the actual pqc@nist.gov team members,
with more NSA people
(Nick Gajcowski; David Hubbard; Daniel Kirkwood; Brad Lackey; Laurie Law; John McVey;
Mark Motley; Scott Simon; Jerry Solinas; David Tuller)
than NIST people.
(Another Department of Defense representative on the list
was Jacob Farinholt, Naval Surface Warfare Center, US Navy.
I&#39;m not sure about Evan Bullock.)</p>
</li>
<li>
<p>Another <a href="https://nist.pqcrypto.org/foia/index.html#20230619/Re_%20Your%20visit%20to%20NIST%20.pdf">secret 2016 document</a>
shows that NSA&#39;s Scott Simon was scheduled to visit NIST on 12 January 2016.</p>
</li>
<li>
<p>Another <a href="https://nist.pqcrypto.org/foia/index.html#20230508/RE_%20Outline%20for%20PQC%20announcement.pdf">secret 2016 document</a>
shows that NIST&#39;s &#34;next meeting with the NSA PQC folks&#34; was scheduled for 26 January 2016.</p>
</li>
<li>
<p>Another <a href="https://nist.pqcrypto.org/foia/index.html#20230508/pqc%20stuff.pdf">secret 2016 document</a>
shows that Michael Groves from NSA&#39;s UK partner
was scheduled to visit NIST on 2 February 2016.</p>
</li>
<li>
<p>Another <a href="https://nist.pqcrypto.org/foia/index.html#20230915/Foreign%20Trip%20Report-09232016dm-ykl.doc">secret 2016 document</a>
lists Colin Whorlow from NSA&#39;s UK partner
as someone that NIST visited in 2016,
in particular discussing
&#34;confidence and developments for each of the primary PQC families&#34;.</p>
</li>
<li>
<p>A <a href="https://web.archive.org/web/20230316130702/https://csrc.nist.gov/CSRC/media/Presentations/pqc-update-round-2-and-beyond/images-media/pqcrypto-sept2020-moody.pdf">public 2020 document</a>
says &#34;Engagement with community and stakeholders.
This includes feedback we received from many, including the NSA.
We keep everyone out of our internal standardization meetings and the decision process.
The feedback received (from the NSA) did not change any of our decisions ...
NIST encouraged the NSA to provide comments publicly.
NIST alone makes the PQC standardization decisions, based on publicly available information, and stands by those decisions&#34;.</p>
</li>
</ul>
<p>I filed a new FOIA request in January 2023,
after NIST issued its claims regarding the security level of Kyber-512.
NIST again stonewalled.
Loevy &amp; Loevy has now filed a new lawsuit regarding that FOIA request.</p>
<p>Public material regarding Kyber-512 already shows
how NIST multiplied costs that should have been added,
how NIST sabotaged public review of this calculation,
and how important this calculation was for NIST&#39;s narrative of Kyber outperforming NTRU,
filling a critical gap left by other steps
that NIST took to promote the same narrative.
This blog post goes carefully through the details.</p>
<p><strong>Alice and Bob paint a fence.</strong>
At this point you might be thinking
something like this:
&#34;Sorry, no, it&#39;s not plausible
that anyone could have mixed up
a formula saying 2<sup>x</sup>+2<sup>y</sup> with a formula saying 2<sup>x+y</sup>,
whatever the motivations might have been.&#34;</p>
<p>As a starting point for understanding what happened,
think about schoolchildren in math class facing a word problem:</p>
<blockquote>
<p>There is a fence to paint.
Alice would take 120 minutes to paint the fence.
Bob would take 240 minutes to paint the fence.
How long would it take Alice and Bob
to paint the fence together?</p>
</blockquote>
<p>The approved answer in school
says that Alice paints 1/120 of the fence per minute,
and Bob paints 1/240 of the fence per minute,
so together they paint 1/120 + 1/240 = 1/80 of the fence per minute,
so it takes them 80 minutes to paint the fence.</p>
<p>The real answer could be more complicated
because of second-order effects.
Probably Alice and Bob working together
are getting less tired
than Alice or Bob working alone for longer would have.
In the opposite direction,
maybe there&#39;s a slowdown because Alice and Bob
enjoy each other&#39;s company
and pause for a coffee.</p>
<p>Schoolchildren often give answers such as
240 − 120 = 120,
or 120 + 240 = 360,
or (120 + 240)/2 = 180.
These children are just manipulating numbers,
not thinking through what the numbers <em>mean</em>.</p>
<p><strong>Two disciplines for catching errors.</strong>
In later years of education,
physics classes
teach students a type-checking discipline
of tracking <em>units</em> with each number.</p>
<p>Here are examples of calculations following this discipline:</p>
<ul>
<li>
<p>Dividing &#34;1 fence&#34; by &#34;120 min&#34;
  gives &#34;0.00833 fence/min&#34;.</p>
</li>
<li>
<p>Adding &#34;0.00833 fence/min&#34;
  to &#34;0.00417 fence/min&#34;
  gives &#34;0.01250 fence/min&#34;.</p>
</li>
<li>
<p>Taking the reciprocal gives &#34;80.0 min/fence&#34;.</p>
</li>
</ul>
<p>The same discipline wouldn&#39;t let you add,
for example, &#34;1 fence&#34; to &#34;120 min&#34;:
the units don&#39;t match.</p>
<p>This discipline avoids many basic errors.
On the other hand,
it still allows, e.g., the mistake of adding
&#34;120 min&#34; to &#34;240 min&#34; to obtain &#34;360 min&#34;.</p>
<p>What catches this mistake
is a discipline stronger than tracking units:
namely, tracking <em>semantics</em>.</p>
<p>The numbers have meanings.
They&#39;re quantitative features of real objects.
For example,
80 minutes
is the total time for Alice and Bob
to paint the fence
when Alice is painting part of the fence
and Bob is painting part of the fence.
That&#39;s what
the question asked us to calculate.</p>
<p>A different question would be
the total time for Alice to paint the fence
and then for Bob to repaint the same fence.
This would be 120 minutes plus 240 minutes.</p>
<p>Yet another question would be
the total time
for Alice to paint the fence,
and then for Bob to wait for the coat
of paint to dry,
and then for Bob to apply a second coat.
Answering this would require more information,
namely the waiting time.</p>
<p>All of these questions make sense.
They pass type-checking.
But their semantics are different.</p>
<p><strong>Alice and Bob tally the costs of an attack.</strong>
Alice and Bob have finished painting
and are now discussing the merits
of different encryption systems.</p>
<p><img src="https://accelerated-computing.com/blog/notes-on-neural-networks-01-basic-concepts/20231003/alice-bob.png"/>
They&#39;d like to make sure that
breaking whichever system they pick
is <em>at least</em> as hard as searching for an AES-128 key.
They&#39;ve agreed that searching for an AES-128 key
is slightly above 2<sup>140</sup> bit operations.</p>
<p>Alice and Bob are broadcasting their discussion
for anyone who&#39;s interested.
Let&#39;s listen to what they&#39;re saying:</p>
<ul>
<li>
<p>Alice:
&#34;Hmmm,
there are a bunch of sources saying
that the XYZZY attack algorithm uses 2<sup>80</sup> iterations
to break this particular cryptosystem.
It&#39;s worrisome that this number is so low.
What else do we know
about the cost of the attack?&#34;</p>
</li>
<li>
<p>Bob:
&#34;I found a source saying
that there are actually extra factors
in the iteration count,
and estimating that
the XYZZY attack uses 2<sup>95</sup> iterations.&#34;</p>
</li>
<li>
<p>Alice:
&#34;Here&#39;s another source
looking at the details
of the computations inside each iteration,
and estimating that those computations
cost 2<sup>25</sup> bit operations.&#34;</p>
</li>
<li>
<p>Bob:
&#34;There&#39;s also a gigantic array being accessed.
Here&#39;s a source
estimating that the memory access
inside each iteration
is as expensive as 2<sup>35</sup> bit operations.&#34;</p>
</li>
<li>
<p>Alice:
&#34;Okay, let&#39;s review.
The best estimate available
for the total cost of each iteration in the XYZZY attack
is around 2<sup>35</sup> bit operations.
A tiny part of that is
2<sup>25</sup> bit operations for computation.
The main cost is the equivalent of
2<sup>35</sup> bit operations for the memory access.&#34;</p>
</li>
<li>
<p>Bob:
&#34;Agreed.
Multiplying
2<sup>95</sup> iterations
by
2<sup>35</sup> bit operations per iteration
gives us a total of 2<sup>130</sup> bit operations.
Doesn&#39;t meet the security target.&#34;</p>
</li>
<li>
<p>Alice:
&#34;Right,
that&#39;s a thousand times easier than AES-128 key search.
Let&#39;s move on to the next cryptosystem.&#34;</p>
</li>
</ul>
<p><strong>How to botch the tally of costs.</strong>
Imagine a government agency
that has also
been looking at this particular cryptosystem,
but with one critical difference:
the agency is desperate to say
that this cryptosystem is okay.</p>
<p>How does the agency deal with the XYZZY attack?</p>
<p>One answer is to aim
for a lower security goal,
hyping the cost of carrying out 2<sup>130</sup> bit operations.
For comparison,
Bitcoin mining
did only about 2<sup>111</sup> bit operations in 2022.
(&#34;Only&#34;!)</p>
<p>But let&#39;s assume that
the agency has promised the world
that it will reach <em>at least</em>
the AES-128 security level.</p>
<p>What does the agency do?</p>
<p>Here&#39;s an idea.
For the costs per iteration,
<strong>instead of <em>adding</em> 2<sup>25</sup> for computation to 2<sup>35</sup> for memory access,
how about <em>multiplying</em> 2<sup>25</sup> for computation by 2<sup>35</sup> for memory access?</strong></p>
<p>The product is 2<sup>60</sup>.
Multiplying this by 2<sup>95</sup> iterations
gives 2<sup>155</sup>, solidly above 2<sup>143</sup>.
Problem solved!</p>
<p><strong>How discipline catches the error.</strong>
Alice and Bob are correctly tracking
the semantics of each number.
The agency isn&#39;t.</p>
<p>The total attack cost is the number of iterations
times the cost per iteration.
Each iteration incurs</p>
<ul>
<li>
<p>cost for computation, estimated as 2<sup>25</sup> bit operations, and</p>
</li>
<li>
<p>cost for memory access, estimated to be as expensive as 2<sup>35</sup> bit operations.</p>
</li>
</ul>
<p>The agency&#39;s multiplication of these two costs
makes no sense,
and produces a claimed per-iteration cost that&#39;s millions of times larger
than the properly estimated per-iteration cost.</p>
<p>This multiplication is so glaringly wrong
that it doesn&#39;t even pass
physics-style type-checking.
Specifically,
multiplying
&#34;2<sup>25</sup> bitops/iter&#34;
by
&#34;2<sup>35</sup> bitops/iter&#34;
doesn&#39;t give
&#34;2<sup>60</sup> bitops/iter&#34;.
It gives
&#34;2<sup>60</sup> bitops<sup>2</sup>/iter<sup>2</sup>&#34;.
Multiplying further by &#34;2<sup>95</sup> iter&#34;
doesn&#39;t give
&#34;2<sup>155</sup> bitops&#34;;
it gives
&#34;2<sup>155</sup> bitops<sup>2</sup>/iter&#34;.</p>
<p><strong>Agency desperation strikes back.</strong>
How can the agency
phrase this nonsensical calculation of a severely inflated security estimate
in a way that will pass superficial review?</p>
<p>The goal here is for the 155 to sound
as if it&#39;s simply putting together
numbers from existing sources.
For example:</p>
<ul>
<li>
<p><SPAN color="red">Here&#39;s a source estimating
  an iteration count of 2<sup>95</sup>.</SPAN></p>
</li>
<li>
<p><SPAN color="red">Here&#39;s a source estimating
  2<sup>25</sup> bit operations per iteration.</SPAN></p>
</li>
<li>
<p><SPAN color="red">Here&#39;s a source estimating
  that accounting for memory
  multiplies costs by 2<sup>35</sup>.</SPAN></p>
</li>
<li>
<p><SPAN color="red">95 plus 25 plus 35 is 155,
  solidly above 143.</SPAN></p>
</li>
</ul>
<p>The deception here is in the third step,
the step that leaps from
cost 2<sup>25</sup> per iteration
to cost 2<sup>60</sup> per iteration.</p>
<p>How many readers are going to check
the third source
and see that it was actually estimating
cost 2<sup>35</sup> per iteration?</p>
<p><strong>Streamlining the marketing.</strong>
The wrong calculation sounds even simpler
if there&#39;s a previous source
that has already put the 2<sup>95</sup>
and the 2<sup>25</sup> together:</p>
<ul>
<li>
<p><SPAN color="red">Here&#39;s a source estimating
  2<sup>120</sup> bit operations.</SPAN></p>
</li>
<li>
<p><SPAN color="red">Here&#39;s a source estimating
  that accounting for memory
  multiplies costs by 2<sup>35</sup>.</SPAN></p>
</li>
<li>
<p><SPAN color="red">120 plus 35 is 155,
  solidly above 143.</SPAN></p>
</li>
</ul>
<p>At this point the agency
has completely suppressed
any mention of iterations,
despite the central role of iterations
in the attack and in any competent analysis of the attack.</p>
<p>How many readers are going
to check <em>both</em> sources,
see that
the second source
estimates cost 2<sup>35</sup> per iteration,
and see that
the iteration count in the first source
is far below 2<sup>120</sup>?</p>
<p><strong>Kyber&#39;s limited selection of security levels.</strong>
You might be thinking something like this:
&#34;Okay, sure, I see how it would be possible for a desperate agency
to replace cost addition with a nonsensical multiplication,
replacing 2<sup>130</sup> with a fake 2<sup>155</sup>,
while at the same time making this hard for people to see.
But <strong>why would anyone have wanted to play this risky game?</strong>
If Kyber-512 was around 2<sup>130</sup>,
and the target was a little above 2<sup>140</sup>,
why didn&#39;t they just bump up the parameters to 10% higher security,
something like Kyber-576?&#34;</p>
<p>This is an obvious question given that
RSA and ECC and (to take some post-quantum examples) McEliece and NTRU
naturally support whatever size you want.</p>
<p>A long, long time ago,
I wrote
<a href="https://cr.yp.to/nistp224.html">fast software</a>
for the NSA/NIST P-224 elliptic curve,
and then found a
<a href="https://cr.yp.to/talks.html#2001.10.29">better curve</a>
at that security level,
namely
y<sup>2</sup> = x<sup>3</sup> + 7530x<sup>2</sup> + x mod 2<sup>226</sup>−5.
But then I decided that bumping the size up
to <a href="https://lib25519.cr.yp.to">2<sup>255</sup>−19</a>
would be much more comfortable, so I did.</p>
<p>Kyber is different.
You <em>can&#39;t</em> just bump up Kyber&#39;s parameters to 10% higher security:</p>
<ul>
<li>
<p>Kyber-576 doesn&#39;t exist.
  If you want something stronger than Kyber-512
  then you have to increase the &#34;dimension&#34; by 50%,
  jumping all the way up to Kyber-768.</p>
</li>
<li>
<p>If you want something stronger than Kyber-768
  then you have to jump all the way up to Kyber-1024.</p>
</li>
<li>
<p>If you want something stronger than Kyber-1024
  then, sorry, tough luck.</p>
</li>
</ul>
<p>One of the &#34;unique advantages of Kyber&#34;
specifically advertised in the
<a href="https://web.archive.org/web/20230310174959/https://pq-crystals.org/kyber/data/kyber-specification-round3-20210804.pdf#subsection.6.1">official Kyber documentation</a>
is that implementing a &#34;dimension-256 NTT&#34;
handles &#34;<em>all parameter sets</em>&#34; for Kyber
(emphasis in original).
This &#34;NTT&#34; isn&#39;t something optional for Kyber implementors;
it&#39;s baked into the structure of Kyber&#39;s public keys and ciphertexts.
Using dimensions that aren&#39;t multiples of 256
would require changing the core Kyber design.</p>
<p>The same Kyber &#34;advantage&#34; also means that going beyond 1024
would lead to performance issues and,
more importantly,
security issues surrounding occasional
&#34;decryption failures&#34; forced by the prime baked into the NTT.
Avoiding this would again
require changing the core Kyber design.</p>
<p>For comparison,
NTRU options targeting higher security levels—including
simple proofs that there are no decryption failures—are readily available.
For example, one of the
<a href="https://ntruprime.cr.yp.to">NTRU Prime</a>
options is <code>sntrup1277</code>.</p>
<p>But let&#39;s assume that NIST doesn&#39;t care about Kyber&#39;s limitations at the high end.
Let&#39;s instead focus on the low end,
specifically on applications that
have limited sizes for public keys and/or ciphertexts
and thus can&#39;t use the highest available security levels.</p>
<p>An application limited to 1KB
can&#39;t use Kyber-768 (1184-byte public keys, 1088-byte ciphertexts).
The highest-security Kyber option for that application
is Kyber-512 (800-byte keys, 768-byte ciphertexts).</p>
<p>The same application obtains
higher security with NTRU,
according to a security-estimation mechanism called &#34;Core-SVP&#34;.
For example, the application can use </p>
<ul>
<li>
<p><code>sntrup653</code> (994-byte keys, 897-byte ciphertexts),
  where the Core-SVP security estimate is 2<sup>129</sup>,
  or</p>
</li>
<li>
<p>NTRU-677 (<code>ntruhps2048677</code>, 931-byte keys, 931-byte ciphertexts),
  where Core-SVP is 2<sup>145</sup>,</p>
</li>
</ul>
<p>while the current version of Kyber-512,
starting with the round-3 version from 2020,
has Core-SVP just 2<sup>118</sup>.</p>
<p>Is this &#34;Core-SVP&#34; something I made up to make Kyber look bad?
Absolutely not:</p>
<ul>
<li>
<p>Core-SVP is the security-estimation mechanism
that was <em>chosen by the Kyber team</em>
to estimate security levels
in its round-1 and round-2 submissions.
The mechanism was introduced by Kyber&#39;s predecessor, NewHope.</p>
</li>
<li>
<p>In 2020,
after I expressed
<a href="https://groups.google.com/a/list.nist.gov/g/pqc-forum/c/o2roJXAlsUk/m/iyvpfk0hAQAJ">skepticism</a>
about whether Core-SVP
&#34;gets the right ordering of security levels&#34;,
NIST
<a href="https://groups.google.com/a/list.nist.gov/g/pqc-forum/c/o2roJXAlsUk/m/69c5Ph9vCAAJ">stated</a> that
&#34;we feel that the CoreSVP metric does
indicate which lattice schemes are being more and less
aggressive in setting their parameters&#34;.
NIST&#39;s official
<a href="https://web.archive.org/web/20230903180546/https://nvlpubs.nist.gov/nistpubs/ir/2020/NIST.IR.8309.pdf">round-2 report</a>
in 2020
used Core-SVP for comparisons.</p>
</li>
<li>
<p>The original definition of Core-SVP assigns
2<sup>112</sup> to the round-3 version of Kyber-512.
Round-3 Kyber
<a href="https://groups.google.com/a/list.nist.gov/g/pqc-forum/c/NSe0wAzKJtA/m/dLP05gv7BgAJ">switched</a>
to a new definition of Core-SVP
that increases Kyber&#39;s Core-SVP
(without changing anything for NTRU).</p>
</li>
</ul>
<p>This blog post has bigger fish to fry,
so let&#39;s blindly accept Kyber&#39;s
claim that the new definition is better,
meaning that Kyber-512 has Core-SVP 2<sup>118</sup>.
That&#39;s still clearly worse than the
2<sup>129</sup> for <code>sntrup653</code> and the 2<sup>145</sup> for NTRU-677.</p>
<p>It&#39;s not that Kyber&#39;s competitors
<em>always</em> beat Kyber in size-security tradeoffs.
For example,
if an application instead has a limit of 1184 bytes,
then it can use Kyber-768, which has Core-SVP 2<sup>181</sup>,
while <code>ntruhps</code> needs 1230 bytes to reach Core-SVP 2<sup>179</sup>.</p>
<p>But Kyber&#39;s competitors
<em>often</em> beat Kyber in size-security tradeoffs.
Throwing away Kyber-512,
leaving just Kyber-768 and Kyber-1024,
means that Kyber has nothing as small as the 931 bytes for NTRU-677.</p>
<p><img src="https://accelerated-computing.com/blog/notes-on-neural-networks-01-basic-concepts/20231003/latticerisks-sizegraph.png"/>
The normal way for scientists to present quantitative tradeoffs is with scatterplots,
such as Figure 3.5 in my 2019 paper
<a href="https://cr.yp.to/papers.html#paretoviz">&#34;Visualizing size-security tradeoffs for lattice-based encryption&#34;</a>.
The particular scatterplot shown here is
Figure 7.3 in the 2021 paper
<a href="https://ntruprime.cr.yp.to/warnings.html">&#34;Risks of lattice KEMs&#34;</a>
from the NTRU Prime Risk-Management Team.
The vertical axis is the Core-SVP security estimate,
and the horizontal axis is ciphertext bytes.</p>
<p>The scatterplot shows that
Kyber has a higher Core-SVP than NTRU
for applications with a size limit of,
e.g., 768 bytes or 1088 bytes.
But NTRU has a higher Core-SVP than Kyber
for applications with a size limit of,
e.g., 700 bytes or 1024 bytes or 2048 bytes.
Kyber has nothing as small as the 699-byte option for NTRU.
Kyber also has nothing as strong as the 1842-byte option for NTRU.
NTRU is also trivially capable of adding further options
between and beyond what&#39;s shown in the graph,
whereas for Kyber this is more problematic.</p>
<p><strong>Official evaluation criteria for the competition.</strong>
NIST had issued an
<a href="https://web.archive.org/web/20220119113311/https://csrc.nist.gov/CSRC/media/Projects/Post-Quantum-Cryptography/documents/call-for-proposals-final-dec-2016.pdf">official call</a>
for post-quantum proposals in 2016.
One of the evaluation criteria in the call was as follows:</p>
<blockquote>
<p>Assuming good overall security and performance, schemes with greater
flexibility will meet the needs of more users than less flexible schemes,
and therefore, are preferable.</p>
</blockquote>
<p>One of the official examples given for &#34;flexibility&#34;
was that it is
“straightforward to customize the scheme&#39;s parameters to meet a
range of security targets and performance goals&#34;.</p>
<p>The call proposed five broad security &#34;categories&#34;,
and said that submitters could specify even more than
five parameter sets to demonstrate flexibility:</p>
<blockquote>
<p>Submitters may also provide more than one parameter set in the same
category, in order to demonstrate how parameters can be tuned to offer
better performance or higher security margins.</p>
</blockquote>
<p>In 2020,
NIST eliminated NewHope.
One of the reasons stated
in the aforementioned
<a href="https://web.archive.org/web/20230903180546/https://nvlpubs.nist.gov/nistpubs/ir/2020/NIST.IR.8309.pdf">round-2 report</a>
was that
&#34;KYBER naturally supports a category 3 security strength parameter set,
whereas NewHope does not&#34;.
NewHope offered only NewHope-512 and NewHope-1024.</p>
<p>Imagine Kyber similarly offering only Kyber-768 and Kyber-1024,
acknowledging that Kyber-512 doesn&#39;t meet the minimum security level specified by NIST.
It&#39;s then very easy to see how limited Kyber&#39;s flexibility is
compared to NTRU&#39;s broader, denser spectrum of security levels.
How, then, would NIST argue that Kyber is the best option?</p>
<p>One answer is that the evaluation criteria say more flexibility is preferable
only assuming &#34;good overall security and performance&#34;.
But how would NIST argue that NTRU doesn&#39;t have &#34;good overall security and performance&#34;?</p>
<p>Regarding the security of Kyber and NTRU,
NIST&#39;s official 2022
<a href="https://web.archive.org/web/20230824124130/https://nvlpubs.nist.gov/nistpubs/ir/2022/NIST.IR.8413-upd1.pdf">selection report</a>
says that NIST is
&#34;confident in the security that each provides&#34;.
The report describes MLWE, the problem inside Kyber,
as &#34;marginally more convincing&#34; than the problem inside NTRU.
There&#39;s much more that could and should have been said about
the security comparison between Kyber and NTRU:</p>
<ul>
<li>
<p>Kyber&#39;s use of modules,
  despite being portrayed as purely having a (marginal) security benefit,
  also introduces
  <a href="https://groups.google.com/a/list.nist.gov/g/pqc-forum/c/BfnzYM8emOw/m/WHHQzM78AQAJ">extra subfields</a>
  into the cryptosystem structure,
  creating security risks
  analogous to the risks of taking extra subfields in pre-quantum DH.
  Fewer extra subfields appear in NTRU (depending on parameters) than in Kyber.
  NTRU Prime completely avoids extra subfields.</p>
</li>
<li>
<p>Kyber&#39;s QROM IND-CCA2 proof assuming MLWE hardness is much looser
  than NTRU&#39;s QROM IND-CCA2 proof assuming hardness of the problem inside NTRU.
  In other words,
  even under the assumption that MLWE is as strong as the problem inside NTRU,
  Kyber could be much weaker than NTRU.</p>
</li>
<li>
<p>NIST could have told people to use NTRU
  shortly after its deadline for NISTPQC input in 2021.
  Instead it delayed for three quarters of a year to carry out patent negotiations,
  and ended up telling people
  to wait for its Kyber patent license to activate in 2024,
  <strong>giving away three years of user data to attackers</strong>.
  Picking Kyber was doing obvious damage to security
  given the patent situation.</p>
</li>
</ul>
<p>The situation isn&#39;t that NTRU avoids <em>every</em> security risk of Kyber.
A <a href="https://ntruprime.cr.yp.to/warnings.html">careful comparison</a>
finds mathematical security risks in both directions.
Maybe there&#39;s a way to argue that the mathematical security risks for NTRU
should be given higher weight than the mathematical security risks for Kyber.
But the immediate choice that NIST was facing in 2021 between NTRU and Kyber,
assuming that the attackers currently recording user data
will have quantum computers in the future, was between</p>
<ul>
<li>
<p>the security risks of NTRU and</p>
</li>
<li>
<p>the guaranteed security failure of not yet deploying anything.</p>
</li>
</ul>
<p>The call for submissions said
&#34;NIST believes it is critical that this process leads to cryptographic
standards that can be freely implemented in security technologies and products&#34;.
Nothing else in the call was labeled as &#34;critical&#34;.
How could NIST ignore the damage that it was doing in not going ahead with NTRU?
NIST knew it didn&#39;t have a patent license signed for Kyber yet,
let alone an <em>activated</em> patent license.</p>
<p>Anyway,
let&#39;s get back to the question of how NIST might be able to argue
that NTRU doesn&#39;t have &#34;good overall security and performance&#34;.
A report saying that NIST is
&#34;confident in the security that each provides&#34;
is obviously not claiming that NTRU doesn&#39;t have &#34;good overall security&#34;.
What about performance?</p>
<p>The same selection report admits that
&#34;the overall performance of any of these KEMs
would be acceptable for general-use applications&#34;.
If the objective is to use performance differences as a deciding factor
between two acceptable options,
let&#39;s see how Kyber would stack up without Kyber-512:
<img src="https://accelerated-computing.com/blog/notes-on-neural-networks-01-basic-concepts/20231003/latticerisks-sizegraph-no512.png"/></p>
<ul>
<li>
<p>Kyber-768 and Kyber-1024 provide size-security tradeoffs that NTRU doesn&#39;t match.</p>
</li>
<li>
<p>NTRU-677 and NTRU-1229
  provide size-security tradeoffs that Kyber doesn&#39;t match.
  Even more options are already implemented for NTRU Prime.</p>
</li>
<li>
<p>The smallest options are from NTRU, not Kyber.</p>
</li>
<li>
<p>The highest-security options are from NTRU, not Kyber.</p>
</li>
</ul>
<p>This is a solid case for eliminating Kyber in favor of NTRU,
given NIST&#39;s declaration that there can be only one.</p>
<p>(If NIST thought that performance differences at this scale matter,
and if the best performance comes from Kyber at some security levels
and NTRU at other security levels,
then why wasn&#39;t NIST allowing both?
Answer:
The movie says there can be only one!
STOP ASKING QUESTIONS!)</p>
<p><strong>Tilting the competition, part 1: ignoring NTRU&#39;s extra flexibility.</strong>
Keeping Kyber-512 changes the competition.
Having three options, Kyber-512 and Kyber-768 and Kyber-1024,
looks a lot better than having just two.</p>
<p>There are four NTRU circles in the first scatterplot above,
namely NTRU-509 and NTRU-677 and NTRU-821 and NTRU-1229.
But NTRU-821 isn&#39;t a winner,
and earlier in NISTPQC there wasn&#39;t an NTRU-1229.</p>
<p>Wait a minute.
The NTRU literature has always made clear that NTRU supports many more options.
For example,
here&#39;s a scatterplot
from John Schanck&#39;s 2018 paper
<a href="https://eprint.iacr.org/2018/1174">&#34;A comparison of NTRU variants&#34;</a>.
<img src="https://accelerated-computing.com/blog/notes-on-neural-networks-01-basic-concepts/20231003/schanck-ntru.png"/>
There are a huge number of dots;
each dot is showing another NTRU option.</p>
<p>One of the bizarre twists in NISTPQC
was the following <a href="https://groups.google.com/a/list.nist.gov/g/pqc-forum/c/LPuZKGNyQJ0/m/ZUoZZss5AwAJ">announcement</a>
from NIST in 2020:
&#34;NIST believes that too many parameter sets make
evaluation and analysis more difficult.&#34;
I asked
<a href="https://groups.google.com/a/list.nist.gov/g/pqc-forum/c/LPuZKGNyQJ0/m/XchLDA3HAwAJ">various questions</a>
about this, starting as follows:</p>
<blockquote>
<p>How many is &#34;too many&#34;? How did flexibility, which was portrayed as
purely positive in the call for proposals, turn into a bad thing for
NIST? The call for proposals explicitly allowed multiple parameter sets
<em>per category</em>, never suggesting that this would be penalized!</p>
<p>NIST&#39;s latest report complains about NewHope&#39;s lack of flexibility to
use dimensions strictly between 512 and 1024. If a submission team is
thinking &#34;Aha, Kyber similarly suffers from its lack of flexibility to
target security levels strictly between maybe-2<sup>128</sup> and maybe-2<sup>192</sup>, and
we can clearly show this to NIST by selecting parameter sets at several
intermediate security levels&#34;, then isn&#39;t this something NIST should be
interested in, rather than discouraging by making submitters worry that
this is &#34;too many parameter sets&#34;?</p>
</blockquote>
<p>NIST never replied.</p>
<p>Think about what this is like for
submitters trying to figure out what to do:</p>
<ul>
<li>
<p>The official evaluation criteria say flexibility is good.</p>
</li>
<li>
<p>A high-profile submission has just been eliminated,
  in part for having only two parameter sets.</p>
</li>
<li>
<p>So, okay, implement more parameter sets
  to demonstrate flexibility.</p>
</li>
<li>
<p>But, yikes, NIST is suddenly going out of its way
  to criticize &#34;too many&#34; parameter sets.
  They won&#39;t say what &#34;too many&#34; means
  and where this criticism came from.</p>
</li>
</ul>
<p>NTRU Prime
moved up to selecting six <code>sntrup</code> parameter sets
(plus six <code>ntrulpr</code> parameter sets, which, compared to <code>sntrup</code>,
have larger ciphertexts but smaller public keys),
enough that the flexibility advantage over Kyber should have been impossible to ignore.
NIST ignored it.</p>
<p><strong>Tilting the competition, part 2: exaggerating and hyping key-generation costs.</strong>
For Intel&#39;s recent Golden Cove microarchitecture
(the &#34;performance&#34; cores in Alder Lake CPUs),
<a href="https://bench.cr.yp.to"><code>https://bench.cr.yp.to</code></a>
reports that</p>
<ul>
<li>
<p>Kyber-512 takes 25829 cycles for encapsulation
  and 20847 cycles for decapsulation,
  while</p>
</li>
<li>
<p>NTRU-509 takes just 15759 cycles for encapsulation
  and 25134 cycles for decapsulation.</p>
</li>
</ul>
<p>The total cycle count for handling a ciphertext,
the total of encapsulation and decapsulation,
is 13% smaller for NTRU-509 than for Kyber-512.</p>
<p>NTRU-509 also beats Kyber-512 in ciphertext size.
NTRU-509 is the leftmost dot in the first scatterplot above,
meaning smallest ciphertexts.</p>
<p>On the other hand,
NTRU-509 takes 112866 cycles for key generation
while Kyber-512 takes only 17777 cycles.
The total of key generation plus encapsulation plus decapsulation
is more than twice as large for NTRU-509 as for Kyber-512.</p>
<p>When some factors favor one option and some factors favor another option,
someone objectively searching for the best option
will think about what weight to put on each factor.
Here are three reasons that a careful performance analysis
will put very low weight on Kyber&#39;s key-generation speedup:</p>
<ul>
<li>
<p>There&#39;s overwhelming evidence that these cycle counts
  are far less important than byte counts.
  A useful rule of thumb is that sending or receiving a byte
  has similar cost to 1000 cycles;
  see Section 6.6 of the aforementioned paper
  <a href="https://ntruprime.cr.yp.to/warnings.html">&#34;Risks of lattice KEMs&#34;</a>.
  Sending a key, receiving a key, sending a ciphertext, and receiving a ciphertext
  involves thousands of bytes, similar cost to millions of cycles.</p>
</li>
<li>
<p>All of these KEMs are designed to allow a key to be reused for many ciphertexts.
  If an application actually cares about the cost of key generation
  then this reuse is an obvious step to take.
  NIST&#39;s
  <a href="https://web.archive.org/web/20220119113311/https://csrc.nist.gov/CSRC/media/Projects/Post-Quantum-Cryptography/documents/call-for-proposals-final-dec-2016.pdf">official evaluation criteria</a>
  already acknowledged the possibility
  that &#34;applications can cache public keys,
  or otherwise avoid transmitting them frequently&#34;.
  Many applications are naturally reusing keys in any case.</p>
</li>
<li>
<p>Even in the extreme case of an application that structurally has to use
  a new key for each ciphertext,
  there&#39;s a trick due to Montgomery that makes NTRU key generation much faster.
  Billy Bob Brumley, Ming-Shing Chen, Nicola Tuveri, and I
  have a paper
  <a href="https://cr.yp.to/papers.html#opensslntru">&#34;OpenSSLNTRU: Faster post-quantum TLS key exchange&#34;</a>
  at USENIX Security 2022
  giving a web-browsing demo on top of TLS 1.3 using <code>sntrup761</code>
  with Montgomery&#39;s trick for key generation.
  We already had the paper and code online in 2021,
  before NIST&#39;s deadline for input regarding NISTPQC decisions.</p>
</li>
</ul>
<p>In other words:
If an average key is used for just 100 ciphertexts
then Kyber-512 saving 95089 Golden Cove cycles in key generation is</p>
<ul>
<li>
<p>of similar importance to changing ciphertext size by <em>a fraction of a byte</em>;</p>
</li>
<li>
<p>6x less important
  than NTRU-509 saving 5783 cycles per ciphertext;
  and</p>
</li>
<li>
<p>not what will happen in applications trying to optimize key-generation time,
  since in NTRU&#39;s case those applications will use Montgomery&#39;s trick.</p>
</li>
</ul>
<p>With this in mind,
let&#39;s look at the &#34;Kyber vs NTRU vs Saber&#34; slide
from NIST&#39;s March 2022 talk
<a href="https://web.archive.org/web/20220811213554/https://csrc.nist.gov/csrc/media/Presentations/2022/the-beginning-of-the-end-the-first-nist-pqc-standa/images-media/pkc2022-march2022-moody.pdf">&#34;The beginning of the end: the first NIST PQC standards&#34;</a>.</p>
<p><img src="https://accelerated-computing.com/blog/notes-on-neural-networks-01-basic-concepts/20231003/how-to-lie-with-graphs.png"/>
The eye is immediately drawn to the larger red bars on the right.
NTRU appears in two of the groups of bars,
in both cases with clearly larger bars,
meaning worse performance.</p>
<p>The main message NIST is communicating here is that
NTRU costs strikingly more than Kyber and Saber.
Only a small part of the audience
will go to the effort of checking the numbers
and seeing how NIST manipulated
the choices in its presentation to favor Kyber over NTRU:</p>
<ul>
<li>
<p>The graph gives 100% weight to key generation,
  utterly failing to account for key reuse.</p>
</li>
<li>
<p>The graph also
  utterly fails to account for Montgomery&#39;s trick.</p>
</li>
<li>
<p>The graph does include some recognition of communication costs,
  but even here NIST couldn&#39;t resist tweaking the numbers:
  &#34;1000*(PK+CT)&#34; counts Alice&#39;s cost while omitting Bob&#39;s cost.</p>
</li>
</ul>
<p>Regarding the last point:
1000 is just a rule of thumb.
NIST could have posted a rationale for a proposal to use 500
and asked for public comments.
But it didn&#39;t.</p>
<p>NIST&#39;s
<a href="https://nist.pqcrypto.org/foia/index.html#20230105/KSN%20Document.docx">secret October 2021 Kyber-SABER-NTRU comparison</a>
claimed, without citation, that I had said 1000*(PK+CT) was reasonable.
Compare this to what I had
<a href="https://groups.google.com/a/list.nist.gov/g/pqc-forum/c/VK9dROwgY0Y/m/PIXc9wTtCAAJ">actually written</a>
in 2019
about the costs of sending and receiving a ciphertext,
after various NTRU Prime documents had given examples backing up the first sentence:</p>
<blockquote>
<p>Typically sending or receiving a byte costs at least three orders of
magnitude more than a clock cycle. Taking bytes+cycles/1000 for
sntrup4591761 gives 1047+45 = 1092 for the sender, 1047+94 = 1141 for
the receiver, which is better than 1248 no matter how few cycles you
use.</p>
</blockquote>
<p>The numbers here account for Alice sending a 1047-byte <code>sntrup4591761</code> ciphertext
and Bob receiving a 1047-byte ciphertext,
on top of about 45000 Haswell cycles for Alice&#39;s enc
and about 94000 cycles for Bob&#39;s dec
(which was later sped up a lot,
but this barely matters next to the ciphertext sizes).
See also the more detailed NTRU examples in Section 6.6 of <a href="https://ntruprime.cr.yp.to/warnings.html">&#34;Risks of lattice KEMs&#34;</a>,
filed before NIST&#39;s deadline for input at the end of October 2021.</p>
<p>NIST&#39;s secret comparison continued by saying &#34;David suggests 2000?&#34;,
apparently referring to a
<a href="https://nist.pqcrypto.org/foia/index.html#20221213/PQC%20KEM%20Benchmarks%2020200407.pdf">secret performance comparison in 2020</a>
where NIST used &#34;bandwidth cost of 2000 cycles/byte&#34;.
Evidently NIST was considering multiple options for this number.
Maybe more FOIA results
will shed more light on how exactly NIST ended up with a NIST-fabricated option
that—<em>quelle surprise!</em>—is better for Kyber.</p>
<p>As for key reuse,
NIST might try to defend itself by saying, look, there&#39;s
a separate PK+CT bandwidth graph on the left,
which for these KEMs is visually close to a 2000*CT+enc+dec graph.
However:</p>
<ul>
<li>
<p>NIST chose to deemphasize the bandwidth graph by using thinner red bars for it.</p>
<p>The graph isn&#39;t invisible,
so together the two graphs don&#39;t give exactly 100% weight to key-generation time.
But a key used for 100 ciphertexts
incurs 1 keygen, 100 enc, and 100 dec,
meaning only 1% weight for key-generation time,
which is <em>very</em> far from the weight
conveyed by NIST&#39;s slide.</p>
</li>
<li>
<p>NIST chose to use smaller (and non-log)
  vertical scales for the bandwidth graph.
  This further deemphasizes that graph <em>and</em>
  makes it hard for the audience to notice
    the size advantage of
    NTRU-509 (699-byte keys and 699-byte ciphertexts)
    over Kyber-512 (800-byte keys and 768-byte ciphertexts).</p>
<p>NTRU-509&#39;s savings of 170 bytes in key+ciphertext size
compared to Kyber-512
is comparable to saving 340000 cycles in total for Alice and Bob.
This easily outweighs the cost of NTRU-509 key generation,
even in the extreme case of one ciphertext per key,
even <em>without</em> Montgomery&#39;s trick,
even if one rewinds a decade from Alder Lake to Haswell.</p>
<p>In short, NTRU-509&#39;s size advantage
is more important than Kyber-512&#39;s keygen-time advantage.
But NIST chose to give more vertical space to Kyber&#39;s keygen-time advantage
than to NTRU-509&#39;s size advantage.</p>
</li>
<li>
<p>NIST applied a <a href="https://cr.yp.to/papers.html#categories">discretization attack</a>
  to both graphs
  to conceal the security advantages of the larger NTRU options.</p>
<p>If NIST had provided an honest size-vs.-Core-SVP scatterplot,
then readers would have seen
that NTRU-677 has much higher Core-SVP than Kyber-512
and much better size than Kyber-768.
NIST would never have been able to get away with its
<a href="https://web.archive.org/web/20230824124130/https://nvlpubs.nist.gov/nistpubs/ir/2022/NIST.IR.8413-upd1.pdf">claim</a>
that NTRU has &#34;somewhat larger public keys and ciphertexts&#34; than Kyber:
a scatterplot immediately shows that,
no, this depends on the target security level,
with NTRU smaller at some security levels
and Kyber smaller at others.</p>
<p>Instead NIST started with the options in Core-SVP order
and then <em>grouped the options according to &#34;category&#34;</em>.
Because of this grouping,
the options <em>look like</em> they have some arbitrary order within each &#34;category&#34;.
People looking at the graph
have no idea that NTRU&#39;s placement farther to the right in each &#34;category&#34;
reflects NTRU&#39;s higher security levels.
A different choice of &#34;category&#34; cutoffs
would have reversed the visual comparison.</p>
</li>
</ul>
<p>As for the failure to account for Montgomery&#39;s trick,
NIST might try to defend itself
by saying that the OpenSSLNTRU software focused on NTRU Prime,
so NIST&#39;s only choice was to presume that there&#39;s no speedup for NTRU beyond NTRU Prime.
In fact, the OpenSSLNTRU paper had already explained why there will be about a 2x speedup.</p>
<p><strong>Tilting the competition, part 3: concealing the fact that NTRU offers the highest security levels.</strong>
The official call for submissions in 2016
recommended focusing on &#34;categories 1, 2 and/or 3&#34;.
See below for a full quote.</p>
<p>The call also recommended that submitters
&#34;specify some other level of security that demonstrates the ability of
their cryptosystem to scale up beyond category 3&#34;.
NTRU (and NTRU Prime) did this,
specifying parameters across a wide range of security levels.
See, e.g., the 2018 scatterplot shown above.</p>
<p>In the aforementioned
<a href="https://web.archive.org/web/20230903180546/https://nvlpubs.nist.gov/nistpubs/ir/2020/NIST.IR.8309.pdf">round-2 report</a>
from 2020, NIST suddenly</p>
<ul>
<li>
<p>said that it
  &#34;strongly encourages the
  submitters to provide at least one parameter set that meets category 5&#34;,</p>
</li>
<li>
<p>complained that
  &#34;the NTRU submission lacks a category 5 parameter set proposal&#34;
  when the costs of memory are ignored,
  and</p>
</li>
<li>
<p>complained that NTRU Prime provided
  &#34;a narrower range of CoreSVP
  values than other lattice submissions targeting security strengths 1, 3, and 5&#34;.</p>
</li>
</ul>
<p>This wasn&#39;t following the official evaluation criteria.
NIST was retroactively changing &#34;recommend&#34; to &#34;strongly encourage&#34;,
was retroactively changing &#34;beyond category 3&#34; to &#34;category 5&#34;,
and was ignoring all of the existing documentation of NTRU&#39;s flexibility.</p>
<p>Submissions that provided &#34;category 4&#34;,
or provided higher security within &#34;category 3&#34;,
were fully meeting the recommendation in the official evaluation criteria:</p>
<blockquote>
<p>Submitters may also provide more than one parameter set in the same
category, in order to demonstrate how parameters can be tuned to offer better
performance or higher security margins.</p>
<p>NIST recommends that submitters primarily focus on parameters meeting the
requirements for categories 1, 2 and/or 3, since these are likely to provide sufficient
security for the foreseeable future. To hedge against future breakthroughs in cryptanalysis
or computing technology, NIST also recommends that submitters provide at least one
parameter set that provides a substantially higher level of security, above category 3.
Submitters can try to meet the requirements of categories 4 or 5, or they can specify some
other level of security that demonstrates the ability of their cryptosystem to scale up
beyond category 3.</p>
</blockquote>
<p>But, in 2020,
NIST wasn&#39;t even trying to follow the official evaluation criteria.
It was inventing new evaluation criteria, with no warning,
and retroactively applying
those criteria to criticize the NTRU and NTRU Prime submissions.</p>
<p>Unsurprisingly,
those submissions responded with software for higher security levels:</p>
<ul>
<li>
<p>NTRU responded with reference implementations of NTRU-1229 and NTRU-HRSS-1373.
  The NTRU team didn&#39;t provide optimized implementations
  (maybe it ran out of time, which is NIST&#39;s fault
  for not having asked for category 5
  in the official call four years earlier),
  but it reported that NTRU-1229 has Core-SVP 2<sup>301</sup>
  and that NTRU-HRSS-1373 has Core-SVP 2<sup>310</sup>.
  Both of these are solidly above Kyber-1024&#39;s 2<sup>254</sup>.</p>
</li>
<li>
<p>NTRU Prime responded with reference and optimized implementations of various options,
  such as <code>sntrup1277</code> and <code>ntrulpr1277</code>,
  which have Core-SVP 2<sup>270</sup> and 2<sup>271</sup> respectively,
  again above anything Kyber offers.
  (There&#39;s a code generator automatically
  producing all of the official NTRU Prime implementations;
  the generator is
  easily extensible to cover further parameter sets.)</p>
</li>
</ul>
<p>After insisting on higher security levels
(and adopting Core-SVP)
in its 2020 round-2 report,
NIST praised NTRU
for responding with higher security levels
(as measured by Core-SVP)
than Kyber, right?</p>
<p>Of course not.
NIST concealed the fact
that NTRU was offering higher security levels than Kyber:</p>
<ul>
<li>
<p>NIST&#39;s big graph
  doesn&#39;t show any NTRU options in the top &#34;category&#34;.
  (The cover story writes itself:
  The NTRU submission didn&#39;t provide optimized software for the new options!
  Reporting reference speeds would have been unfair!
  NIST is just trying to protect readers from being misled!)</p>
</li>
<li>
<p>For readers who go to the effort of looking at the small graph,
  the discretization attack
  makes NTRU&#39;s higher security levels
  look just like Kyber&#39;s lower security levels.</p>
</li>
</ul>
<p>Readers looking at NIST&#39;s graphs are left with the impression
that NTRU is <em>less</em> flexible than Kyber
and, in particular,
has <em>more</em> trouble reaching high security levels.
This is exactly the opposite of the facts.</p>
<p><strong>Tilting the competition, part 4: throwing away the highest-performance option.</strong>
NTRU-1229 and NTRU-HRSS-1373 aren&#39;t the only options
that NIST excluded from its big graph.
Let&#39;s again look at the low end,
the top-performance end,
where NIST chose to exclude NTRU-509.</p>
<p>Optimized NTRU-509 software was already available.
If NIST had included NTRU-509 in the big graph
then that graph would have shown NTRU-509 as the best performer,
better than Kyber-512.</p>
<p>Accounting for key reuse
would have further favored NTRU-509.
Accounting for Montgomery&#39;s trick
would have further favored NTRU-509.
Upgrading from Haswell
would have further favored NTRU-509.
Counting 1000 cycles per byte for Alice <em>and</em> for Bob
would have further favored NTRU-509.</p>
<p>But NIST simply removed NTRU-509 from the big graph,
making NTRU look strictly worse than Kyber in that graph.</p>
<p>NIST went even further in its subsequent report
selecting Kyber for standardization:
<a href="https://web.archive.org/web/20230824124130/https://nvlpubs.nist.gov/nistpubs/ir/2022/NIST.IR.8413-upd1.pdf">the report</a>
didn&#39;t show NTRU-509 in any of the figures or tables.
The report&#39;s descriptions of Kyber&#39;s performance
were visibly more positive
than its descriptions of NTRU&#39;s performance,
as illustrated by
NIST&#39;s claim that NTRU has &#34;somewhat larger public keys and ciphertexts&#34; than Kyber.</p>
<p>How does NIST stop people from quickly spotting the errors in
this &#34;somewhat larger public keys and ciphertexts&#34; claim?</p>
<p>A discretization attack
easily hides the fact that NTRU has smaller sizes than Kyber at intermediate security levels,
but it doesn&#39;t hide NTRU-509 being smaller than Kyber-512.
NIST&#39;s narrative also relied on kicking out NTRU-509.</p>
<p>How can NIST justify throwing NTRU-509 away?</p>
<p>The only possible answer
is claiming that NTRU-509 doesn&#39;t reach the minimum allowed NISTPQC security level,
the security level of AES-128.
But, at the same time, NIST is including Kyber-512,
so NIST is claiming that Kyber-512
<em>does</em> reach the security level of AES-128.</p>
<p>NTRU-509 has Core-SVP 2<sup>106</sup>, just
6 bits below Kyber-512&#39;s original Core-SVP (2<sup>112</sup>)
or
12 bits below Kyber-512&#39;s revised Core-SVP (2<sup>118</sup>).
Evidently NIST is claiming that AES-128 is inside this narrow margin:
in other words, that
NTRU-509 has <em>slightly</em> lower security than AES-128
while Kyber-512 has <em>slightly</em> higher security than AES-128.</p>
<p><img src="https://accelerated-computing.com/blog/notes-on-neural-networks-01-basic-concepts/20231003/shattering.png"/>
Let&#39;s take a moment to admire how spectacularly fragile this is:</p>
<ul>
<li>
<p>If some effect slightly increases lattice security levels
  compared to what NIST is claiming,
  then NTRU-509 is back in the game,
  outperforming all of the Kyber options.</p>
</li>
<li>
<p>If some effect slightly reduces lattice security levels
  compared to what NIST is claiming,
  then Kyber-512 is gone,
  and NTRU-677 outperforms all of the Kyber options.</p>
</li>
<li>
<p><em>If</em> security levels are measured in a way that
<em>just</em> manages to have Kyber-512 retained while NTRU-509 isn&#39;t retained,
then NTRU&#39;s superior flexibility still provides the highest security level
and wins at various intermediate levels,
but Kyber wins at other intermediate levels
and provides the highest performance level,
so putting enough weight on the highest performance level favors Kyber.</p>
</li>
</ul>
<p>See how important it is
for Kyber-512 to reach the AES-128 security level?
Without that, Kyber is in big trouble:
NTRU provides the highest level of security
<em>and</em> the highest level of performance
<em>and</em> the best flexibility.</p>
<p><strong>The chaos beyond Core-SVP.</strong>
How is Kyber-512 supposed to reach the AES-128 security level
if AES-128 needs more than 2<sup>140</sup> bit operations to break
while the Core-SVP security estimate for Kyber-512 is only 2<sup>118</sup>?</p>
<p>This question was briefly addressed in the
<a href="https://web.archive.org/web/20230323095809/https://pq-crystals.org/kyber/data/kyber-specification.pdf">round-1 Kyber submission</a>
in 2017.
That submission said that the 2017 version of Kyber-512 had Core-SVP 2<sup>112</sup>,
falling short of the target by 30 bits,
but gave a five-line list of reasons that &#34;it seems clear&#34;
that Kyber-512 has at least 30 bits more security than Core-SVP indicates.</p>
<p>The
<a href="https://web.archive.org/web/20230919163511/https://pq-crystals.org/kyber/data/kyber-specification-round2.pdf">round-2 Kyber submission</a>
in 2019
made the same claim regarding the 2019 version of Kyber-512.
In 2020,
I <a href="https://groups.google.com/a/list.nist.gov/g/pqc-forum/c/o2roJXAlsUk/m/EHW9h87kAAAJ">disproved</a>
the stated rationale.
To summarize:</p>
<ul>
<li>
<p>Kyber&#39;s argument that it was gaining security from
  &#34;the additional rounding noise (the LWR problem, see [13, 8]), i.e. the
  deterministic, uniformly distributed noise introduced in ciphertexts via [rounding]&#34; was simply wrong.
  Attackers could freely target Kyber&#39;s keys, and the keys didn&#39;t have any rounding.</p>
</li>
<li>
<p>Kyber&#39;s argument that it was gaining security from the
  &#34;additional cost of sieving with asymptotically subexponential complexity&#34;
  was <a href="https://groups.google.com/a/list.nist.gov/g/pqc-forum/c/o2roJXAlsUk/m/5ORleAt4AQAJ">unfounded and probably wrong</a>:
  as far as I could tell (and as far as we know today),
  the actual asymptotics are subexponentially <em>faster</em> than Core-SVP,
  not subexponentially slower.
  It was still plausible that the costs for specific sizes such as Kyber-512
  were higher than Core-SVP,
  but this required an analysis that Kyber hadn&#39;t carried out.</p>
</li>
<li>
<p>Kyber&#39;s arguments that it was gaining security from
  &#34;the (polynomial) number of calls to the SVP oracle that are
  required to solve the MLWE problem&#34;
  and &#34;the gate count required for one &#39;operation&#39; &#34;
  were plausible, but didn&#39;t seem to be enough to rescue Kyber-512 without further help.</p>
</li>
<li>
<p>Kyber&#39;s argument that it was gaining security from
  &#34;the cost of access into exponentially large memory&#34;
  was plausible as a matter of real-world attack costs.
  NTRU Prime had already proposed a particular way to quantify this cost.</p>
<p>However,
the
<a href="https://web.archive.org/web/20220119113311/https://csrc.nist.gov/CSRC/media/Projects/Post-Quantum-Cryptography/documents/call-for-proposals-final-dec-2016.pdf">official call for submissions</a>
had asked for a security level of at least 2<sup>143</sup> &#34;classical gates&#34;
without regard to memory-access costs.
So this argument was useless for rescuing Kyber-512:
it wasn&#39;t what the official evaluation criteria were asking for.</p>
</li>
</ul>
<p>To try to rescue Kyber-512,
the
<a href="https://web.archive.org/web/20230310174959/https://pq-crystals.org/kyber/data/kyber-specification-round3-20210804.pdf">round-3 Kyber submission</a></p>
<ul>
<li>
<p>changed Kyber-512 and (as noted above) redefined Core-SVP
  to obtain Core-SVP 2<sup>118</sup> rather than 2<sup>112</sup>;</p>
</li>
<li>
<p>took (without credit) my <a href="https://groups.google.com/a/list.nist.gov/g/pqc-forum/c/o2roJXAlsUk/m/5ORleAt4AQAJ">preliminary analysis</a>
  of the gaps between Core-SVP and reality;</p>
</li>
<li>
<p>added further numerical estimates regarding the gaps
  and the &#34;known unknowns&#34;;</p>
</li>
<li>
<p>concluded that this preliminary analysis
  gave a <strong>32-bit range of security estimates</strong>,
  specifically 151 bits plus or minus 16 &#34;in either direction&#34;;
  and</p>
</li>
<li>
<p>claimed that dropping to 135 wouldn&#39;t be &#34;catastrophic,
  in particular given the massive memory requirements
  that are ignored in the gate-count metric&#34;.</p>
</li>
</ul>
<p>The memory argument again wasn&#39;t relevant,
given the official evaluation criteria asking for 2<sup>143</sup> &#34;classical gates&#34;.
Kyber-512 wasn&#39;t claiming to require 2<sup>143</sup> &#34;classical gates&#34; to break;
it was claiming some undetermined number between 2<sup>135</sup> and 2<sup>167</sup>.</p>
<p>Various papers then appeared
claiming to cut further bits out of lattice security in various ways,
such as a <a href="https://eprint.iacr.org/2022/239">2022 paper</a>
reporting an order-of-magnitude speedup
from tweaking the &#34;BKZ&#34; layer inside attacks.
Many of the papers made the analyses of lattice security
even more complicated and even less stable than before.
For example, for one line of &#34;dual attacks&#34;:</p>
<ul>
<li>
<p>there&#39;s an Asiacrypt paper and a paper from Israel&#39;s Matzov organization
  with complicated analyses claiming to reduce Kyber-512&#39;s 151 to 137;</p>
</li>
<li>
<p>but then there&#39;s a Crypto paper
  <a href="https://eprint.iacr.org/2023/302">&#34;Does the dual-sieve attack on learning with errors even work?&#34;</a>
  giving the impression that, no, this whole line of attacks fails;</p>
</li>
<li>
<p>but then the actual contents of the Crypto paper
  are merely saying that there&#39;s a &#34;presumably significant&#34; change in the improvements without <em>quantifying</em> the change;</p>
</li>
<li>
<p>but then there&#39;s a new paper
  <a href="https://eprint.iacr.org/2023/1238">&#34;A remark on the independence heuristic in the dual attack&#34;</a>
  that sounds like it&#39;s helping quantify the change;</p>
</li>
<li>
<p>but that paper still doesn&#39;t get all the way to
  claiming any particular attack cost for Kyber-512;</p>
</li>
<li>
<p>but then there&#39;s another new paper
  <a href="https://eprint.iacr.org/2023/1460">&#34;Rigorous foundations for dual attacks in coding theory&#34;</a>
  that, for a dual attack against an analogous low-rate decoding problem,
  says that a &#34;slight modification of this algorithm&#34;
  avoids the issue raised in the Crypto paper;</p>
</li>
<li>
<p>but that paper doesn&#39;t analyze what the idea means for lattices;</p>
</li>
<li>
<p>but then there&#39;s another new paper
  <a href="https://eprint.iacr.org/2023/1508">&#34;Provable dual attacks on learning with errors&#34;</a>
  that says it proves the correctness of a simplified dual attack for lattices;</p>
</li>
<li>
<p>but that paper also doesn&#39;t quantify consequences for Kyber-512.</p>
</li>
</ul>
<p>And this is just one small piece of a giant unholy mess
that some cryptographers say we should trust.</p>
<p>How, back in 2022, did NIST end up concluding that Kyber-512 is as hard to break as AES-128?
Time to look at some quotes.
I&#39;ll go through the quotes in two parts:
first, looking at what NIST said its notion of hardness was;
second, going line by line through what NIST said about Kyber-512&#39;s security level.</p>
<p><strong>NIST rescuing Kyber-512, part 1: manipulating the qualification criteria.</strong>
In the call for submissions,
it was crystal clear that cryptosystems had to be at least as hard to break as AES-128
in <em>every</em> &#34;potentially relevant&#34; cost metric:</p>
<blockquote>
<p>Each category will be defined by a comparatively easy-to-analyze reference primitive,
whose security will serve as a floor for a wide variety of metrics that NIST deems
potentially relevant to practical security. ...</p>
<p>In order for a
cryptosystem to satisfy one of the above security requirements, any attack must require
computational resources comparable to or greater than the stated threshold, with respect
to <em>all</em> metrics that NIST deems to be potentially relevant to practical security.</p>
</blockquote>
<p>(Emphasis in original.)</p>
<p>The call commented on the &#34;classical gates&#34; to break AES-128 etc.
Obviously &#34;classical gates&#34; were a &#34;potentially relevant&#34; cost metric.</p>
<p>What exactly is this metric?
The literature defines many different gate sets.
NIST dodged years of requests to define exactly which gates
it was including as &#34;classical gates&#34;.
NIST&#39;s 2022
<a href="https://web.archive.org/web/20230824124130/https://nvlpubs.nist.gov/nistpubs/ir/2022/NIST.IR.8413-upd1.pdf">selection report</a>
finally pinned down one part of this,
allowing &#34;each one-bit memory read or write&#34; as a cost-1 gate.</p>
<p>Here&#39;s an illustration of how important definitions of cost metrics are:</p>
<ul>
<li>
<p>Kyber&#39;s security analysis relies on
  an <a href="https://eprint.iacr.org/2019/1161">Asiacrypt 2020 paper</a>
  for counting the number of &#34;gates&#34; inside the most important attack step
  inside &#34;primal&#34; attacks.</p>
</li>
<li>
<p>Tung Chou and I have a new paper
  <a href="https://cat.cr.yp.to/papers.html">&#34;CryptAttackTester: formalizing attack analyses&#34;</a>
  including an appendix that, for Kyber-512,
  <strong>cuts almost 10 bits out of the &#34;gate&#34; count</strong>
  for the &#34;primary optimisation target&#34; in the Asiacrypt 2020 paper,
  exploiting the fact that the Asiacrypt 2020 paper counts a memory-access &#34;gate&#34; as cost 1.
  (The Asiacrypt 2020 paper also relies on this; it&#39;s not a typo in that paper.)</p>
</li>
<li>
<p>The same appendix also disproves the claim
  that an &#34;optimal&#34; AES-128 key search requires 2<sup>143</sup> &#34;gates&#34;,
  but the reduction in AES-128 &#34;gate&#34; counts
  isn&#39;t as large as the reduction in Kyber-512 &#34;gate&#34; counts.</p>
</li>
</ul>
<p>Keep this in mind if you hear people claiming that the costs of lattice attacks have been thoroughly analyzed.</p>
<p>Anyway,
being able to access arbitrarily large amounts of memory for cost 1 isn&#39;t realistic:
the actual costs of data communication grow with distance.
But NIST said in 2020
that anyone proposing a replacement metric
<a href="https://groups.google.com/a/list.nist.gov/g/pqc-forum/c/o2roJXAlsUk/m/9oeKbY5MAQAJ">&#34;must at minimum convince NIST that the metric meets the following criteria&#34;</a>,
which &#34;seems to us like a fairly tall order&#34;:</p>
<ul>
<li>
<p>&#34;The value of the proposed metric can be accurately measured (or at least lower
  bounded) for all known attacks (accurately mere means at least as accurately as for
  gate count.)&#34;</p>
</li>
<li>
<p>&#34;We can be reasonably confident that all known attacks have been
  optimized with respect to the proposed metric. (at least as confident
  as we currently are for gate count.)&#34;</p>
</li>
<li>
<p>&#34;The proposed metric will more accurately reflect the real-world
  feasibility of implementing attacks with future technology than gate
  count -- in particular, in cases where gate count underestimates the
  real-world difficulty of an attack relative to the attacks on AES or
  SHA3 that define the security strength categories.&#34;</p>
</li>
<li>
<p>&#34;The proposed metric will not replace these underestimates with overestimates.&#34;</p>
</li>
</ul>
<p>There have been no announcements on the NISTPQC mailing list
of anyone claiming to have met these minimum criteria,
never mind the question of whether such a claim could survive public scrutiny.</p>
<p>Recall that
NIST excluded NTRU-509
from the figures and tables in its selection report,
the report announcing the selection of Kyber over NTRU.
If you look for the report&#39;s explanation of <em>why</em> NIST excluded NTRU-509,
you&#39;ll find the following quote:</p>
<blockquote>
<p>The submission specification uses both local and non-local cost models for determining
the security category of their parameter sets. For a more direct comparison with the other
KEM finalists, the assignment of security categories according to the non-local cost model
is appropriate. This is what NIST used for NTRU in the figures and tables in this report.</p>
</blockquote>
<p>The underlying definition of &#34;local&#34; accounts for long-distance communication costs,
whereas &#34;non-local&#34; allows accessing arbitrarily large amounts of memory for free.</p>
<p>Everything I&#39;ve been describing from NIST above, and more,
sounds consistent with the official call for submissions asking for
2<sup>143</sup> &#34;classical gates&#34;,
<strong>not counting the costs of memory access</strong>:</p>
<ul>
<li>
<p>To try to avoid overestimating security levels,
  NIST was insisting on counting <em>just</em> bit operations for computation,
  ignoring the costs of communication.</p>
</li>
<li>
<p>In response to the round-1 NTRU Prime submission,
  which provided a
  <a href="https://ntruprime.cr.yp.to/nist/ntruprime-20171130.pdf#subsection.6.7">detailed rationale</a>
  for including the costs of memory access,
  NIST complained in its
  <a href="https://web.archive.org/web/20230920201351/https://nvlpubs.nist.gov/nistpubs/ir/2019/NIST.IR.8240.pdf">round-1 report</a>
  that the submission
  &#34;uses a cost model for lattice attacks
  with higher complexity than many of the other lattice-based candidates&#34;.
  (NTRU Prime started reporting Core-SVP in round 2.)</p>
</li>
<li>
<p>In its <a href="https://web.archive.org/web/20230903180546/https://nvlpubs.nist.gov/nistpubs/ir/2020/NIST.IR.8309.pdf">round-2 report</a>,
  as noted above,
  NIST complained that
  &#34;the NTRU submission lacks a category 5 parameter set proposal&#34;
  <em>when memory-access costs are ignored</em>.</p>
</li>
<li>
<p>In its
  <a href="https://web.archive.org/web/20230824124130/https://nvlpubs.nist.gov/nistpubs/ir/2022/NIST.IR.8413-upd1.pdf">selection report</a>,
  NIST kicked out NTRU-509
  because NTRU-509&#39;s &#34;category 1&#34; claim
  relied on a &#34;local cost model&#34;, i.e., accounting for memory-access costs;
  see above for the full quote.</p>
</li>
</ul>
<p>With this in mind,
consider the fact that NIST was including Kyber-512 in its figures and tables in the same report.
This must mean that NIST was claiming
that breaking Kyber-512 takes at least 2<sup>143</sup> bit operations,
<em>without accounting for memory-access costs</em>, right?</p>
<p>Nope. NIST doesn&#39;t ask Kyber
to meet the same criteria as other submissions.</p>
<p>In <a href="https://groups.google.com/a/list.nist.gov/g/pqc-forum/c/4MBurXr58Rs/m/-1Ja0ZYyAQAJ">November 2022</a>,
NIST announced a list of parameter sets that it was &#34;planning&#34; to standardize,
including Kyber-512.
NIST&#39;s announcement
avoided claiming that Kyber requires as many &#34;classical gates&#34; to break as AES-128.
The announcement
specifically acknowledged the possibility of Kyber being &#34;a few bits&#34; below
(while omitting the possibility of Kyber being many more bits below):</p>
<blockquote>
<p>It is clear that in the gate-count metric it is a very close call and
that in this metric the pre-quantum security of Kyber-512 may be a few
bits below the one of AES-128.</p>
</blockquote>
<p>Instead the announcement relied on accounting for &#34;realistic memory access costs&#34;
to claim that Kyber-512 qualified for &#34;category 1&#34;:</p>
<blockquote>
<p>... the best known attacks against Kyber-512 require huge amounts
of memory and the real attack cost will need to take the cost of
(access to) memory into account.  This cost is not easy to calculate,
as it depends on the memory access patterns  of the lattice algorithms
used for cryptanalysis, as well as the physical properties of the
memory hardware.  Nonetheless, barring major improvements in
cryptanalysis, it seems unlikely that the cost of memory access will
ever become small enough to cause Kyber-512 to fall below category 1
security, in realistic models of security that take these costs into
account.  We acknowledge there can be different views on our current
view to include Kyber-512.</p>
<p>As a point of clarification: in this email, we refer to parameter sets
based on the claimed security strength category where those parameter
sets are most recently specified, irrespective of whether those
parameter sets actually meet their claimed security level. That said,
our current assessment is that, <strong>when realistic memory access costs of
known attacks are taken into account, all the parameter sets we plan
to standardize do, in fact, meet their claimed security strength
categories</strong>.</p>
</blockquote>
<p>(Emphasis added.)</p>
<p><img src="https://accelerated-computing.com/blog/notes-on-neural-networks-01-basic-concepts/20231003/inconsistency.png"/>
So NIST used a &#34;non-local&#34; free-memory metric to kick out NTRU-509,
but used a memory-access-is-expensive metric
to claim that Kyber-512 qualifies for &#34;category 1&#34;.
Can anyone tell me how these two things make sense together?</p>
<p>(As a side note,
NIST subsequently
<a href="https://groups.google.com/a/list.nist.gov/g/pqc-forum/c/4MBurXr58Rs/m/VcKp223-DQAJ">stated</a>
that its 2022 selection report was merely reflecting
&#34;the submitters&#39; <u>claimed</u> security categories&#34;
and that the report was making no
&#34;assertions about whether or not the parameter sets
actually provided the claimed level of security&#34;.
How does NIST reconcile this with the report kicking out NTRU-509 while keeping Kyber-512?
Both of those submissions
were claiming to achieve &#34;category 1&#34; given memory-access costs.)</p>
<p>For anyone who cares about reviewability of security analyses,
NIST&#39;s sudden switch to accounting for Kyber&#39;s memory-access costs
should be setting off alarm bells.</p>
<p>None of the official Kyber security analyses
had tried to quantify the effects of memory on security levels.
The Kyber documentation had merely pointed at memory as supposedly saving the day
in case there weren&#39;t enough &#34;gates&#34;.</p>
<p>In the absence of an analysis,
how exactly was NIST concluding that memory-access costs
were enough to close the gap?</p>
<p><strong>NIST rescuing Kyber-512, part 2: NIST&#39;s botched security analysis.</strong>
In early December 2022,
I asked how NIST was arriving at its conclusion that Kyber-512
was as hard to break as AES-128.</p>
<p>NIST followed up with an
<a href="https://groups.google.com/a/list.nist.gov/g/pqc-forum/c/4MBurXr58Rs/m/xHojUDCaBAAJ">explanation</a>
on 7 December 2022.
I&#39;ll refer to this explanation as
&#34;NIST&#39;s botched security analysis of Kyber-512&#34;;
for brevity, &#34;<strong>NISTBS</strong>&#34;.</p>
<p>One of the complications in NISTBS is
that it considers a large space of scenarios, with analysis steps mixed
into comments on the likelihood of each scenario.
Even worse,
NISTBS doesn&#39;t give any confirming end-to-end examples
of the tallies obtained in each particular scenario.
So a security reviewer has to trace carefully
through each step of NISTBS.</p>
<p>Here&#39;s one example of a scenario
from within the space that NISTBS specifies.
I&#39;ll call this &#34;scenario X&#34; for future reference.
Scenario X makes the following three assumptions:</p>
<ul>
<li>
<p>Assume accuracy of 2<sup>137</sup> from the most recent attack paper taken
  into account (Matzov) regarding the number of &#34;gates&#34;. (This is a
  number specifically mentioned in NISTBS as a starting point; see below.
  NISTBS also considers the more complicated possibility of this estimate
  being invalid.)</p>
</li>
<li>
<p>Assume this isn&#39;t affected by the &#34;known unknowns&#34;. (This is a
  possibility specifically mentioned in NISTBS; see below. NISTBS
  also considers the more complicated possibility of the security level
  being affected by the &#34;known unknowns&#34;.)</p>
</li>
<li>
<p>Assume accuracy of the RAM-cost model in the NTRU Prime
  documentation. (This is one of two sources that NISTBS
  repeatedly points to and calculates numbers on the basis of. NISTBS also
  considers other possibilities for the RAM cost.)</p>
</li>
</ul>
<p>Obviously the quantitative conclusions of NISTBS vary depending on the exact
assumptions. Considering scenario X is simpler than considering
the full space of scenarios. I&#39;ll use scenario X as an example below.</p>
<p>Without further ado, here&#39;s every line of NISTBS,
NIST&#39;s botched security analysis of Kyber-512.</p>
<blockquote>
<p><SPAN color="#663319">
We can elaborate a little bit further on our reasoning leading to our
current assessment that Kyber512 likely meets NIST category I (similar
considerations apply to the other parameter sets we plan to
standardize for lattice-based schemes.)
</SPAN></p>
</blockquote>
<p>This is a preliminary statement regarding the importance of the
calculations at hand. See below for the calculations.</p>
<blockquote>
<p><SPAN color="#663319">
That said, beyond this message, we don’t think further elaboration of
our current position will be helpful. While we did consult among
ourselves and with the Kyber team,
</SPAN></p>
</blockquote>
<p>I filed a formal complaint in December 2022 regarding NIST&#39;s lack of
transparency for its investigation of Kyber-512&#39;s security level. As
noted above, I filed a new FOIA request in January 2023.</p>
<blockquote>
<p><SPAN color="#663319">
it’s basically just our considered
opinion based on the same publicly available information everyone else
has access to.
</SPAN></p>
</blockquote>
<p>This is not true. NISTBS starts from, e.g., the Matzov paper&#39;s
2<sup>137</sup> estimate for &#34;gates&#34;, but then goes beyond this in quantifying the
impact of memory costs, something the Matzov paper definitely did not
do. What we&#39;ll see later is how NISTBS botches its own calculations
<em>starting from</em> the Matzov number.</p>
<blockquote>
<p><SPAN color="#663319">
The point of this thread is to seek a broader range of
perspectives on whether our current plan to standardize Kyber512 is a
good one, and a long back and forth between us and a single researcher
does not serve that purpose.
</SPAN></p>
</blockquote>
<p>Public review of NIST&#39;s security evaluations requires transparency and
clarity regarding those evaluations. It is not appropriate for NIST to
be asking for a range of perspectives while concealing information. An
open and transparent process would involve less &#34;back and forth&#34; than
the process that NIST chose.</p>
<blockquote>
<p><SPAN color="#663319">
Here&#39;s how we see the situation:
In April this year, “Report on the Security of LWE” was published by
MATZOV (<a href="https://zenodo.org/record/6412487#.Y4-V53bMKUk">https://zenodo.org/record/6412487#.Y4-V53bMKUk</a>), describing an
attack, assessed in the RAM model to bring some parameter sets,
including Kyber512, slightly below their claimed security strength
categories.
</SPAN></p>
</blockquote>
<p>This is the most recent attack paper mentioned in NISTBS. That&#39;s
why my definition of scenario X says &#34;the most recent attack paper
taken into account (Matzov)&#34;.</p>
<p>It&#39;s surprising that NISTBS doesn&#39;t mention any of the newer
attack papers. NIST had hypothesized that there are no &#34;major improvements in
cryptanalysis&#34; (see full quote above), but this doesn&#39;t justify ignoring
the improvements that have already been published!</p>
<p>Anyway, given that NISTBS is calculating security levels starting from
the Matzov paper, let&#39;s look carefully at those calculations.</p>
<p>&#34;Assessed in the RAM model&#34; appears to be referring to the Matzov
paper counting the number of &#34;gates&#34;. As a side note, &#34;the&#34; RAM model is
ambiguous; the literature defines many different RAM models, and many
different sets of &#34;gates&#34;, as noted above.</p>
<blockquote>
<p><SPAN color="#663319">
In particular, the report estimates the cost of attacking Kyber512
using a classical lattice attack to be 2<sup>137</sup> bit operations, which is
less than the approximately 2<sup>143</sup> bit operations required to
classically attack AES-128.
</SPAN></p>
</blockquote>
<p>NISTBS takes this 137 as the foundation of various calculations below.</p>
<p>This doesn&#39;t mean NISTBS is saying Kyber-512 is broken in 2<sup>137</sup> &#34;gates&#34;.
NISTBS is saying that Matzov estimated 137, and then NISTBS is calculating
various consequences of the 137. If the 137 is inaccurate then the
details of the NISTBS calculations (see below) go up or down accordingly.</p>
<p>For purposes of putting together the sources available, the simplest
case to consider is that 2<sup>137</sup> accurately counts the number of &#34;gates&#34;.
Scenario X explicitly assumes this.</p>
<blockquote>
<p><SPAN color="#663319">
However, like previous lattice attacks, the MATZOV attack is based on
sieving techniques, which require a large amount of (apparently
unstructured) access to a very large memory.
</SPAN></p>
</blockquote>
<p>In announcing its plans to standardize Kyber-512, NIST had said that
&#34;the best known attacks against Kyber-512 require huge amounts of
memory&#34;; here NISTBS is reiterating this.</p>
<blockquote>
<p><SPAN color="#663319">
The RAM model ignores the cost of this memory access,
</SPAN></p>
</blockquote>
<p>Indeed, the &#34;gate&#34; counts in question ignore the cost of memory access.</p>
<blockquote>
<p><SPAN color="#663319">
and while the science of comparing the cost of memory access to other
costs involved in a large cryptanalytic attack is not as mature as we
would like, it seems overwhelmingly likely that, in any realistic
accounting of memory access costs, these will significantly exceed the
costs that are assessed by the RAM model for lattice sieving. 
</SPAN></p>
</blockquote>
<p>Here are three obvious examples of quantitative questions raised by this
part of NISTBS. Quantification is essential for cryptographic security
review.</p>
<p>First, what exactly does &#34;significantly&#34; mean in this context?</p>
<p>Second, how does NISTBS reach its &#34;overwhelmingly likely ... significantly
exceed&#34; conclusion?</p>
<p>Third, how does NISTBS get from &#34;significantly exceed&#34; to its conclusion
that having Kyber-512 fall short of AES-128 is &#34;unlikely&#34;? (Assuming no
&#34;major improvements in cryptanalysis&#34;.)</p>
<p>NISTBS does eventually get to some quantified calculations; see below.</p>
<blockquote>
<p><SPAN color="#663319">
The largest practical implementation of sieving techniques we know of,
described in detail in “Advanced Lattice Sieving on GPUs, with Tensor
Cores” by Ducas, Stevens, and van Woerden
(https://eprint.iacr.org/2021/141), was forced by memory access
limitations, to adopt settings for bucket size, that would be
suboptimal according to the RAM model.
</SPAN></p>
</blockquote>
<p>Something else unclear from this part of NISTBS is whether &#34;bucket size
... suboptimal&#34; is supposed to imply NIST&#39;s &#34;significantly&#34; claim
regarding &#34;costs&#34;, and, from there, NIST&#39;s claim that it&#39;s &#34;unlikely&#34;
for Kyber-512 to be easier to break than AES-128.</p>
<blockquote>
<p><SPAN color="#663319">
It should be noted that, increasing the scale of the instances being
attacked to near cryptographic scale would probably require extensive
hardware optimization, e.g. by using special purpose ASICs, and these
techniques, being generally acknowledged to be less effective against
memory-intensive tasks, would likely make memory access even more of a
bottleneck.
</SPAN></p>
</blockquote>
<p>Qualitatively, this is a reasonable summary of what the literature on
point is saying. However, at this point the reader still doesn&#39;t know
how NISTBS gets from this to the claim that Kyber-512 is &#34;unlikely&#34; to
be below the AES-128 security level.</p>
<blockquote>
<p><SPAN color="#663319">
Additionally,
</SPAN></p>
</blockquote>
<p>This is where NISTBS transitions into quantification.</p>
<blockquote>
<p><SPAN color="#663319">
While the Kyber, Dilithium, and Falcon teams did not give a
quantitative assessment of the practical cost of memory access during
sieving against cryptographic parameters, assessments by the NTRU and
NTRUprime teams gave estimates that would suggest the cost of sieving
against category 1 parameters, in models that account for the cost of
memory access, is something like 20 to 40 bits of security more than
would be suggested by the RAM model.
</SPAN></p>
</blockquote>
<p>Finally some numbers to work with! See below for how NISTBS uses these
numbers.</p>
<p>As a side note, NIST seems to have very low confidence in the numbers
it&#39;s citing, saying not just &#34;estimates&#34; but also &#34;suggest&#34; and
&#34;something like&#34;. But the question I want to focus on here is <em>not</em> how
confident NIST is in the sources that it cites. The question is simply
what security level NISTBS is calculating for Kyber-512 <em>starting from</em>
the sources it cites.</p>
<p>Scenario X explicitly assumes accuracy of one of the two sources that
NISTBS cites, specifically NTRU Prime. In context, this choice of source
is favorable to Kyber:
NISTBS points to NTRU Prime as giving Kyber a
40-bit bonus, and points to NTRU as giving Kyber only a 20-bit bonus.</p>
<blockquote>
<p><SPAN color="#663319">
(For NTRU’s estimates see section 6.3 of the round 3 specification
document available at <a href="https://ntru.org/index.shtml">https://ntru.org/index.shtml</a> . For NTRUprime’s
estimates see section 6.11 of
<a href="https://ntruprime.cr.yp.to/nist/ntruprime-20201007.pdf">https://ntruprime.cr.yp.to/nist/ntruprime-20201007.pdf</a> .
</SPAN></p>
</blockquote>
<p>Scenario X specifically assumes &#34;accuracy of the RAM-cost model in
the NTRU Prime documentation&#34;, one of the two sources that NISTBS relies
upon for its quantification. See below for the numbers that NISTBS
obtains from this source.</p>
<blockquote>
<p><SPAN color="#663319">
The Kyber spec (available at
<a href="https://pq-crystals.org/kyber/data/kyber-specification-round3-20210804.pdf">https://pq-crystals.org/kyber/data/kyber-specification-round3-20210804.pdf</a>)
discusses, but does not quantify, memory access costs in section 5.3 (Q6))
</SPAN></p>
</blockquote>
<p>Indeed, what&#39;s cited here doesn&#39;t quantify this. So let&#39;s keep going
with the numbers that NISTBS obtains from other sources.</p>
<blockquote>
<p><SPAN color="#663319">
Taking Matzov&#39;s estimates of the attack cost to be accurate,
</SPAN></p>
</blockquote>
<p>This is exactly what scenario X is assuming. Of course, NISTBS also
considers other possibilities, but, as an illustrative example, let&#39;s
follow through what NISTBS obtains from this assumption.</p>
<blockquote>
<p><SPAN color="#663319">
only 6 bits of security from memory access costs are required for
Kyber512 to meet category 1,
</SPAN></p>
</blockquote>
<p>Indeed, 137 is &#34;only&#34; 6 bits short of the 143 goal. NIST wants to find 6
bits of security that it can credit to Kyber-512, plus so much security
margin that it can claim not to be worried about the &#34;known unknowns&#34;
etc. The point of NISTBS is to argue that the costs of memory do the job.</p>
<blockquote>
<p><SPAN color="#663319">
so in this case Kyber512 would meet category 1 even if the NTRU and
NTRUprime submission significantly overestimate the cost of memory
access in lattice sieving algorithms.
</SPAN></p>
</blockquote>
<p>Here NIST is finding more than its desired 6 bits of security, by
giving Kyber the aforementioned &#34;20 to 40 bits&#34; coming from &#34;assessments
by the NTRU and NTRUprime teams&#34; of the extra costs coming from memory
access.</p>
<p>For example, if NTRU says 20 and if this is accurate, then NISTBS is
calculating a security level of 137+20 = 157, safely above 143. (Again,
this is explicitly assuming accuracy of the 137 in the first place.)</p>
<p>As another example, if NTRU Prime says 40 and if this is accurate, then
NISTBS is calculating a security level of 137+40 = 177, even farther
above 143. (Once again assuming accuracy of the 137.)</p>
<p>See how simple this calculation is? NISTBS points to its sources as
saying that there are actually &#34;20 to 40 bits of security more than
would be suggested by the RAM model&#34; (in NIST&#39;s words). So NISTBS adds
20 or 40 to Matzov&#39;s 137, giving 157 or 177.</p>
<p>NIST says that even if those sources have &#34;significantly&#34; overestimated
the memory-access cost then Kyber-512 is still okay. To figure out what
NIST means by &#34;significant&#34; here, simply work backwards from NIST&#39;s
desired conclusion: if &#34;20 bits&#34; is overestimated by as many as 14 bits,
then that still leaves 20−14 bits, covering the desired 6 bits. Anyway,
Scenario X simply assumes accuracy of the NTRU Prime RAM-cost model.</p>
<blockquote>
<p><SPAN color="#663319">
Further, since about 5 of the 14 claimed bits of security by Matzov
involved speedups to local computations in AllPairSearch (as described
by section 6 of the MATZOV paper), it is likely that Kyber512 would
not be brought below category 1  by the MATZOV attack, as long as
state of the art lattice cryptanalyses prior to the MATZOV paper were
bottlenecked by memory at all.
</SPAN></p>
</blockquote>
<p>It&#39;s of course correct that if there&#39;s a bottleneck then speeding up
computations outside the bottleneck has little impact. See below for how
NIST seems to be using this to claim <em>even more</em> security.</p>
<blockquote>
<p><SPAN color="#663319">
However, we acknowledge there is some additional uncertainty in the
exact complexity of the MATZOV attack (and all other sieving-based
lattice attacks) due to the known-unknowns Dan alludes to (described
with quantitative estimates in section 5.3 of the Kyber spec.)
</SPAN></p>
</blockquote>
<p>Three reasons that it might be possible to beat Matzov&#39;s 2<sup>137</sup> &#34;gates&#34;
are (1) inaccuracies in Matzov&#39;s analysis (of course, these could also
point the other way), (2) missing optimizations covered by the &#34;known
unknowns&#34;, and (3) missing optimizations beyond the &#34;known unknowns&#34;.</p>
<p>Here NIST is pointing to #2. As a side note, it&#39;s disturbing to not see
NIST accounting for #1 and #3. NIST explicitly assumed that there are no
&#34;major&#34; improvements in cryptanalysis; but some of its scenarios have
Kyber with very few bits of security margin, and closing those wouldn&#39;t
require &#34;major&#34; improvements.</p>
<p>Scenario X skips this complication: it explicitly assumes that the 137
is accurate, and that there are no improvements from the &#34;known
unknowns&#34;.</p>
<blockquote>
<p><SPAN color="#663319">
Nonetheless, even taking the most paranoid values for these
known-unknowns (16 bits of security loss),
</SPAN></p>
</blockquote>
<p>This is what the Kyber documentation says is the worst case, yes.</p>
<blockquote>
<p><SPAN color="#663319">
the cost of memory access and/or algorithmically making memory access
local, would still need to be less than what both the NTRU and
NTRUPrime submissions assume.
</SPAN></p>
</blockquote>
<p>I found this puzzling when I first saw it: if we take 137, and then
subtract a hypothesized 16, then we need to find 22 bits, which is
less than the 40 that NISTBS mentioned but <em>not</em> less than the 20. What&#39;s
going on?</p>
<p>The best explanation I could come up with is that NIST thinks the 16
overlap the 5 bits that NISTBS mentioned above from Matzov, so NIST is
actually taking 137−16+5, meaning that NIST has to find only 17 bits,
and then the 20 that NISTBS attributes to NTRU is enough (at least if we
disregard the uncertainties conveyed by &#34;estimate&#34; and &#34;suggest&#34; and
&#34;something like&#34;).</p>
<p>Again, Scenario X simply assumes that the 137 is accurate, with no
speedups from the &#34;known unknowns&#34;, so this complication doesn&#39;t arise
for that scenario.</p>
<blockquote>
<p><SPAN color="#663319">
The low end estimate of approximately 20 bits (from the NTRU
submission) is based on a conjecture by Ducas that a fully local
implementation of the BGJ1 sieving algorithm is possible.
</SPAN></p>
</blockquote>
<p>Here NIST is pointing to a reason to ask whether the NTRU model is too
low. Scenario X explicitly takes the NTRU Prime model, which doesn&#39;t
trigger this particular issue.</p>
<blockquote>
<p><SPAN color="#663319">
So, in the case that all known-unknowns take on the most paranoid
values, this would either require a sieving algorithm with local
memory access that is much better than any such published algorithm,
and in fact better than any that has been conjectured (at least as far
as we are aware),
</SPAN></p>
</blockquote>
<p>This is summarizing the NISTBS calculations from the perspective of what
algorithmic improvements would be required to break NIST&#39;s conclusions.
This isn&#39;t relevant to scenario X.</p>
<blockquote>
<p><SPAN color="#663319">
or it would require the approximately 40 bits of additional security
quoted as the &#34;real cost of memory access&#34; by the NTRUprime submission
to be a massive overestimate.
</SPAN></p>
</blockquote>
<p>This is summarizing the NISTBS calculations from the perspective of what
modeling errors would be required to break NIST&#39;s conclusions.</p>
<p>It&#39;s concerning to observe deviations between what NISTBS attributes to
its source here and what the source actually says. For example, the
source says that it&#39;s <em>estimating</em> the cost of memory access, whereas
NIST incorrectly makes it sound as if the source is mislabeling an
estimate as a fact. Furthermore, contrary to what NISTBS&#39;s &#34;quoted as&#34;
claim leads readers to believe, the &#34;40 bits&#34; that NISTBS claims as
memory overhead is <em>not</em> a quote from what the source says on this
topic.</p>
<p>Presumably NIST obtained 40 in the following easy way: look at the
security-level table on page 103 of the source; observe that pre-quantum
sieving for <code>sntrup653</code> at the top is listed as 169 and 129 for &#34;real&#34;
and &#34;free&#34; respectively; subtract the 129 from the 169.</p>
<blockquote>
<p><SPAN color="#663319">
In any event, a lot of things would have to go wrong simultaneously to
push the real-world classical cost of known attacks against Kyber512
below category 1, which is why we don&#39;t think it&#39;s terribly likely.
</SPAN></p>
</blockquote>
<p>This is going beyond the per-scenario calculations into an overall
probability conclusion.</p>
<blockquote>
<p><SPAN color="#663319">
As a final note, known quantum speedups for lattice sieving are much
less effective than Grover’s algorithm for brute force key search, so
in the likely scenario where the limiting attack on AES128 is Grover’s
algorithm, this would further increase the security margin of Kyber512
over AES128 in practice.
</SPAN></p>
</blockquote>
<p>This is yet another complication, and one with several unquantified
steps. It&#39;s also blatantly inconsistent with earlier comments from NIST on
the impact of Grover&#39;s algorithm.</p>
<p>For example, in email dated 11 Sep 2017 13:48:59 +0000 to
pqc-forum@nist.gov (before the list moved to Google), NIST wrote that
&#34;even if we assume the sort of quantum technology often suggested to be
possible in 15 years (e.g. ~1GW power requirement and a few hours to
factor a 2048 bit number), current technology can still do brute force
search cheaper than Grover’s algorithm&#34;. Where are the numbers backing
up NIST&#39;s new claim that Grover&#39;s algorithm is &#34;likely&#34; the top threat?</p>
<p>Surely NIST agrees that pre-quantum metrics are at least &#34;potentially&#34;
relevant to the practical security of Kyber-512. Consequently, under the
official evaluation criteria, NIST can&#39;t use post-quantum metrics as a
way to rescue Kyber-512 if Kyber-512 is easier to break than AES-128 in
the pre-quantum metrics.</p>
<p>I&#39;ll focus below on how NISTBS botched its calculation of the
pre-quantum Kyber-512 security level.</p>
<p><strong>What the underlying numbers actually mean.</strong>
Core-SVP is a rough estimate for the number of iterations
in a particular type of lattice attack.
Each iteration involves large-scale memory access and computation.</p>
<p>Let&#39;s look at how the latest versions
of the documentation for two submissions, NTRU Prime and Kyber,
convert their estimates for the number of iterations
into larger security-level estimates.
(Note that both of the documents in question are from 2020,
so the numbers don&#39;t include subsequent attack improvements.)</p>
<p>NTRU Prime focuses on the cost of memory access.
In particular,
for the important task of sorting N small items,
a two-dimensional circuit of area essentially N needs time essentially N<sup>1/2</sup>,
whereas a circuit of the same area running for the same time
can carry out essentially N<sup>3/2</sup> bit operations.</p>
<p>To put these two types of costs on the same scale,
the NTRU Prime documentation estimates
&#34;the cost of each access to a bit within N bits of memory
as the cost of N<sup>0.5</sup>/2<sup>5</sup> bit operations&#34;,
and explains how the 2<sup>5</sup> comes from analyzing energy numbers reported by Intel.</p>
<p>As a concrete example:</p>
<ul>
<li>
<p>The NTRU Prime documentation reports Core-SVP 2<sup>129</sup> for <code>sntrup653</code>,
  meaning a rough estimate of 2<sup>129</sup> iterations.</p>
</li>
<li>
<p>The documentation also reports a rough estimate
  that memory accesses cost, in total,
  the equivalent of 2<sup>169</sup> bit operations for <code>sntrup653</code>.
  This comes from combining
  the N<sup>0.5</sup>/2<sup>5</sup> formula with estimates for N, for the number of iterations,
  and for the number of bits accessed inside each iteration.</p>
</li>
</ul>
<p>For comparison,
recall that Kyber-512 says Core-SVP 2<sup>118</sup>.
A rough estimate for the cost of memory accesses in this Kyber-512 attack
is the equivalent of 2<sup>154</sup> bit operations.</p>
<p>This might sound similar to the Kyber documentation
estimating 2<sup>151</sup> bit operations (&#34;gates&#34;).
But the 2<sup>151</sup> estimate in the Kyber documentation
isn&#39;t an estimate of the bit-operation equivalent of memory access.
It&#39;s ignoring memory access.
It&#39;s instead considering the number of bit operations
used inside the attack&#39;s computations,
and estimating that this number is somewhere between 2<sup>135</sup> and 2<sup>167</sup>,
given the &#34;known unknowns&#34;.</p>
<p><strong>Agency desperation, revisited.</strong>
With the meaning of the numbers in mind,
let&#39;s briefly summarize how NISTBS tries to use computations <em>and</em> memory
to push up the claimed security level of Kyber-512:</p>
<ul>
<li><SPAN color="red">
  Start with 118 bits of security for Core-SVP.
  </SPAN></li>
</ul>
<p>Indeed, Core-SVP estimates 2<sup>118</sup> iterations,
  at least with the round-3 Kyber redefinition of Core-SVP.</p>
<ul>
<li><SPAN color="red">
  Add 33 bits of security, giving Kyber-512&#39;s claimed 151 bits of security,
  to account for the bit operations used in computations.
  </SPAN></li>
</ul>
<p>Yes, the Kyber-512 documentation has a preliminary estimate of 2<sup>151</sup> bit operations.</p>
<ul>
<li><SPAN color="red">
  Oh, oops, Kyber says this could be 16 bits too high,
  and Matzov says it reached 137,
  and maybe these could be combined,
  and there are other attack papers too?
  That&#39;s okay: memory will come to the rescue!
  </SPAN></li>
</ul>
<p>Will it? Quantification needed.</p>
<ul>
<li><SPAN color="red">
  Add &#34;40 bits of additional security&#34; (NIST&#39;s words)
  supposedly estimated by NTRU Prime,
  turning Matzov&#39;s 137 bits of security into 177 bits of security.
  </SPAN></li>
</ul>
<p>This is where NISTBS goes horribly wrong.</p>
<p>The calculation here doesn&#39;t even pass basic type-checking.
Yes, there&#39;s a 2<sup>40</sup> in NTRU Prime for <code>sntrup653</code>,
but that&#39;s 2<sup>40</sup> bitops/iter.
Multiplying this by Matzov&#39;s bitops,
and portraying the result as bitops,
is nonsense from NIST.</p>
<p>Whatever the cost is for computation per iteration,
you have to <em>add</em> that to the cost for memory access per iteration.
<em>Multiplying</em> is wrong.</p>
<p>In the typical case of both numbers being considerably above 1,
multiplying the numbers—which is exactly what NISTBS is doing when it says
&#34;40 bits of security more than would be suggested by the RAM model&#34;
and &#34;40 bits of additional security&#34;—gives
an embarrassing, indefensible overestimate of attack costs.</p>
<p>To finish this NISTBS recap, let&#39;s briefly summarize
the happy conclusions that NISTBS draws:</p>
<ul>
<li>
<p><SPAN color="red">
  Look at how much security margin we have here!
  The critical point is that, starting from 137,
  &#34;only 6 bits of security from memory access costs are required for
  Kyber512 to meet category 1&#34; (NIST&#39;s words).
  So we don&#39;t have to worry about a few bits here and there,
  such as the possibility of 137 being too high.
  </SPAN></p>
</li>
<li>
<p><SPAN color="red">
  We can even get away with replacing 40 bits of NTRU Prime
  with an attacker-optimistic 20 bits of security from NTRU,
  since that gives 157 bits of security.
  Still way above 143!
  Surely we aren&#39;t going to lose <em>all</em> 16 bits from the &#34;known unknowns&#34;.
  </SPAN></p>
</li>
<li>
<p><SPAN color="red">
  To summarize,
  &#34;a lot of things would have to go wrong simultaneously to
  push the real-world classical cost of known attacks against Kyber512
  below category 1, which is why we don&#39;t think it&#39;s terribly likely&#34;
  (NIST&#39;s words).
  </SPAN></p>
</li>
</ul>
<p>Yeah, sounds great,
except that it&#39;s all based on a botched calculation.</p>
<p><strong>How easy it is to catch the error.</strong>
This blog post is aimed at people who want to understand
the whole picture of what&#39;s going on here.
But imagine that you&#39;re looking at NISTBS without knowing any of this.
How quickly can you see that NISTBS is wrong?</p>
<p>I think the fastest answer is the following simple sanity check.
If</p>
<ul>
<li>
<p>Kyber estimates that the computations in breaking Kyber-512
cost between 2<sup>135</sup> and 2<sup>167</sup> bit operations,
and</p>
</li>
<li>
<p>NTRU Prime estimates that the memory accesses in breaking <code>sntrup653</code>
(which seems harder to break than Kyber-512)
cost the equivalent of 2<sup>169</sup> bit operations,
and</p>
</li>
<li>
<p>attacks then improve by a factor 2<sup>14</sup>,</p>
</li>
</ul>
<p>how can NIST end up estimating that breaking Kyber-512 costs 2<sup>177</sup> bit operations?</p>
<p>This doesn&#39;t tell you <em>where</em> NIST went wrong,
but there&#39;s a more basic trick that works for that.
See where NISTBS is claiming
that the NTRU Prime documentation
estimates &#34;40 bits of security more than would be suggested by the RAM model&#34;
(NIST&#39;s words),
<em>without giving a full quote from the NTRU Prime documentation</em>?</p>
<p>I&#39;m one of the NTRU Prime submitters.
I already knew that this NISTBS claim was false:
it&#39;s misattributing NIST&#39;s wishful thinking to the NTRU Prime documentation.
But say you&#39;re reading this claim <em>without</em> knowing in advance that it&#39;s false.
How do you figure out that it&#39;s false?</p>
<p>Here&#39;s a hard answer and an easy answer:</p>
<ul>
<li>
<p>Hard answer:
Follow NISTBS&#39;s pointer
to Section 6.11 of the documentation.
That section starts on page 68, ends on page 70,
doesn&#39;t say &#34;40&#34;, and doesn&#39;t say &#34;the RAM model&#34;.
You can read through all the formulas and comments,
try to match it up to the NISTBS claim,
and see that nothing matches.</p>
</li>
<li>
<p>Easy answer:
As soon as you observe that this citation is hard to check,
simply <em>ask for clarification</em> regarding what exactly the citation is referring to.
Honest authors will be happy to clarify.</p>
</li>
</ul>
<p>As a followup,
let&#39;s imagine that
NIST responds by saying
&#34;We calculated the 40 by subtracting 129 from 169 on the top row of Table 2&#34;.
NIST is then implicitly claiming that the 129 is an example of
calculating security in &#34;the RAM model&#34;.
How do you figure out that this implicit claim is false?</p>
<p>This followup similarly has a hard answer and an easy answer:</p>
<ul>
<li>
<p>Hard answer:
Read through enough material about what NIST calls &#34;the RAM model&#34;
to see that this doesn&#39;t match the definition of the 129 in the source document.</p>
</li>
<li>
<p>Easy answer:
Simply <em>ask for clarification</em> of what exactly the rest of the citation,
the part attributing something about &#34;the RAM model&#34; to the NTRU Prime documentation,
is referring to.
Honest authors will again be happy to clarify.</p>
</li>
</ul>
<p>Asking questions
is the normal scientific process
for rapidly reaching clarity—and rapidly fixing errors.
For the particular error at hand,
it takes very few rounds to pinpoint the discrepancy:
the 2<sup>129</sup> in the source document for <code>sntrup653</code> is Core-SVP,
<em>not</em> a gate count in what NIST calls &#34;the RAM model&#34;.</p>
<p>Of course,
this clarification process doesn&#39;t work when an agency
decides to dodge clarification questions,
for example because it doesn&#39;t <em>want</em> errors to be fixed.</p>
<p><strong>The research that would be needed for a correct calculation.</strong>
To fix NIST&#39;s calculation,
one needs to carefully distinguish two different effects:</p>
<ul>
<li>
<p>Kyber-512&#39;s preliminary estimate of security being 33 bits above Core-SVP
  (151 vs. 118)
  comes partially
  from estimating the number of
  bit operations inside the computations in an iteration inside a &#34;primal&#34; attack;
  see the <a href="https://eprint.iacr.org/2019/1161">Asiacrypt 2020 paper</a> mentioned above.
  The cost for computation per iteration
  has to be <em>added</em> to the cost for memory access per iteration.
  <em>Multiplying</em> these costs, as NIST did,
  is exactly the central mistake highlighted in this blog post.</p>
</li>
<li>
<p>On the other hand,
  the estimate comes partially from saying
  that there&#39;s an outer loop
  increasing the number of iterations compared to Core-SVP.
  Multiplying the new iteration count
  by the cost of memory access per iteration
  makes perfect sense.</p>
</li>
</ul>
<p>Quantifying these effects
requires tracing carefully through
hundreds of pages of papers on state-of-the-art lattice attacks
(not just rewriting the Asiacrypt 2020 paper)
to see what would happen if costs of memory access were included.</p>
<p>What makes this <em>really</em> tough is that
a change of cost metric also forces
reoptimization of the entire stack of attack subroutines,
along with all applicable parameters.</p>
<p>Consider, as one of many examples,
the choice between low-memory &#34;enumeration&#34;
and high-memory &#34;sieving&#34; as a subroutine inside BKZ.
The Kyber documentation uses cost metrics that ignore the cost of memory access
to conclude that enumeration is less efficient than sieving.
If NIST is suddenly saying that memory access makes sieving slower
than obviously there&#39;s a gap in the Kyber analysis.
Where&#39;s the recalculation that accounts for the cost of memory access,
and for the large
<a href="https://eprint.iacr.org/2020/707">recent</a>
<a href="https://eprint.iacr.org/2020/1260">improvements</a>
in enumeration?</p>
<p>Shortly after Matzov&#39;s attack appeared in April 2022,
I had sent a message to the NISTPQC mailing list
<a href="https://groups.google.com/a/list.nist.gov/g/pqc-forum/c/Fm4cDfsx65s/m/0dBVXOcSCAAJ">summarizing</a>
the complicated analysis that needed to be done.
I took, as an example, a less Kyber-favorable scenario
in which the &#34;known unknowns&#34; reduce 137 to 121,
and I said that simply multiplying the bit-operation count by 2<sup>40</sup> would be wrong:</p>
<blockquote>
<p>Does accounting for real RAM costs close the gap between 2<sup>121.5</sup> and
2<sup>143</sup>? One might think that, sure, this is covered by the 2<sup>40</sup> mentioned
above: Kyber-512 previously had security 2<sup>40</sup>*2<sup>135.5</sup> = 2<sup>175.5</sup>, so a
32.5-bit security margin, and the new paper is reducing this to an
18.5-bit security margin: i.e., the new paper is merely cutting out 40%
of the Kyber security margin, rather than breaking Kyber outright.</p>
<p>But let&#39;s look more closely at the numbers. As a preliminary point,
round-3 Kyber-512 is starting from Core-SVP just 2<sup>112</sup> and
revised-Core-SVP just 2<sup>118</sup>, with exponent 87% and 91% of 129
respectively, so the obvious estimate is about 2<sup>36</sup> instead of 2<sup>40</sup>.</p>
<p>Furthermore, this 2<sup>36</sup> is accounting for the energy cost of accesses to
a giant RAM array, while it&#39;s clear that many of the bits of security
beyond Core-SVP claimed in the round-3 Kyber security analysis are
coming from accounting for the cost of local bit operations. These
effects don&#39;t multiply; they add!</p>
<p>Internally, Core-SVP is starting from estimates of the number of
&#34;operations&#34; inside sieving. It makes sense to say that the attacker
needs to pay for the large-scale memory access inside each &#34;operation&#34;.
It also makes sense to say that the attacker needs to pay for all the
bit operations inside each &#34;operation&#34;. But the local bit operations are
an asymptotically irrelevant extra cost on top of the memory access, and
the best bet is that they don&#39;t make much difference for Kyber-512. The
real cost of this type of algorithm is, at a large scale, driven
primarily by data motion, not by local computation. ...</p>
<p>So I don&#39;t see how current knowledge can justify suggesting that the
costs of RAM rescue Kyber-512 from the new attack. It seems entirely
possible that the real costs of this Kyber-512 attack are considerably
below the costs of a brute-force AES-128 attack. Deciding this one way
or the other will require much more serious analysis of attack costs.</p>
</blockquote>
<p>An agency desperate to rescue Kyber-512
will take note of the first part of what I had written:
great, memory-access costs bump Kyber&#39;s security level up by 40 bits,
giving us a healthy security margin!</p>
<p>The agency won&#39;t listen to the subsequent part saying that,
no, this calculation is garbage.</p>
<p>The agency won&#39;t even listen to the preliminary adjustment of 40 to 36:
we have a healthy security margin, why worry about a few bits here and there?</p>
<p>Meanwhile,
if there&#39;s something that sounds like a few bits <em>favoring</em> Kyber-512,
then the desperate agency happily takes note of that,
as the following example illustrates.</p>
<p>The fact that the cost of memory access in each iteration
adds to the cost of computation in each iteration,
rather than multiplying,
has a silver lining for defenders:
in the common situation of memory access being dominant,
improvements in the cost of computation per iteration
make little difference in total cost.
I mentioned this in my April 2022 message regarding the Matzov paper:</p>
<blockquote>
<p>The new paper seems to have some local speedups to the sieving inner
loop, which similarly should be presumed to make little difference next
to the memory-access bottleneck, but my understanding is that this is
under half of the bits of security loss that the paper is reporting.</p>
</blockquote>
<p>Now look at this from the perspective of the desperate agency.
Aha, some bits of the Matzov speedup
are computation speedups that won&#39;t matter next to memory access!
As long as we&#39;re willing to switch to counting memory access,
this effect downgrades the Matzov speedup,
which sounds good for Kyber-512!</p>
<p>Sure enough,
NISTBS says that
&#34;about 5 of the 14 claimed bits of security by Matzov
involved speedups to local computations&#34;,
and portrays this as a &#34;further&#34; reason for confidence in Kyber-512,
beyond the &#34;40 bits of additional security&#34; supposedly produced by memory access.</p>
<p>This is double-counting the silver lining.
Multiplying the 2<sup>40</sup> cost of memory access per iteration
by Matzov&#39;s 2<sup>137</sup> bit operations
is already assuming (implicitly and incorrectly)
that every bit operation has its own iteration,
giving 2<sup>137</sup> iterations.
This leaves no room for multiplying by a &#34;further&#34; 2<sup>5</sup>.
The estimated 2<sup>5</sup> is actually on a completely different axis:
it&#39;s an estimate for the Matzov-vs.-previous speedup ratio in one metric
divided by the Matzov-vs.-previous speedup ratio in another metric.</p>
<p><strong>NIST rescuing Kyber-512, part 3: dodging clarification requests.</strong>
When NISTBS appeared in December 2022,
I looked through and saw
that NISTBS was multiplying, rather than adding,
the cost of memory access per iteration
and the cost of computation per iteration,
despite my having already pointed out in April 2022 that this was wrong.</p>
<p>But, hmmm, NIST didn&#39;t write NISTBS in a verification-friendly way.
In particular, as noted above,
NIST didn&#39;t include any examples of confirming tallies.</p>
<p>It seemed perfectly clear
that NIST was adding &#34;40 bits of additional security&#34;
to 137 in scenario X.
But NIST didn&#39;t bother saying, yes,
the security level is 177 in that scenario.
NIST also didn&#39;t make clear where exactly it was getting the 40 from.</p>
<p>When I find mistakes in security analyses,
the authors usually say
&#34;Thanks for catching the mistake!&#34;—<a href="https://groups.google.com/a/list.nist.gov/g/pqc-forum/c/rJYnyTEi92E/m/l5xBpeTpBQAJ">except</a>
<a href="https://groups.google.com/a/list.nist.gov/g/pqc-forum/c/_kBMTq3RM28/m/afIJBlpoBAAJ">in</a>
<a href="https://groups.google.com/a/list.nist.gov/g/pqc-forum/c/8_uKOBN4Srw/m/KoAbiE4TDAAJ">lattice</a>-<a href="https://groups.google.com/a/list.nist.gov/g/pqc-forum/c/Yx0wZuZP6ag/m/Q_H9lf_zCAAJ">based</a>
<a href="https://groups.google.com/a/list.nist.gov/g/pqc-forum/c/SxH_NkLOv9Q/m/iCT1Y2VaAwAJ">cryptography</a>,
where the authors usually claim that they meant something different from what they had written.
This continual evasion is a serious disincentive to security review.
If there was <em>any</em> way that I could have misunderstood what NISTBS was saying,
then I wanted to know that at the outset,
before doing the work of writing up an explanation of the error.</p>
<p>So I posted a
<a href="https://groups.google.com/a/list.nist.gov/g/pqc-forum/c/4MBurXr58Rs/m/KeqHDr2lBAAJ">short clarification question</a>.
Specifically,
I spelled out scenario X
and asked whether, in that scenario, I was
&#34;correctly gathering that you&#39;re calculating the Kyber-512
security level as 2<sup>177</sup> (i.e., 34 bits of security margin compared to
2<sup>143</sup> for AES-128), where this 177 comes from the above 137 plus 40,
where 40 comes from 169 minus 129 on page 103 of the NTRU Prime
documentation, specifically &#39;real&#39; minus &#39;free&#39; for pre-quantum sieving
for sntrup653&#34;.</p>
<p>I was expecting a prompt answer saying &#34;Yes, for that specific scenario we&#39;re calculating 177 bits of security,
and we&#39;re getting the 40 from the 169 and 129 that you mentioned.&#34;</p>
<p>What actually happened is that NIST didn&#39;t reply.</p>
<p>Seriously?
<strong>NIST picks a risky, bleeding-edge cryptosystem to standardize for users worldwide,
and then doesn&#39;t even bother answering clarification questions
about what NIST claims the security level is?</strong></p>
<p>I mentioned above
that I filed a formal complaint
regarding the lack of transparency.
Here&#39;s what the complaint said:</p>
<blockquote>
<p>NIST has publicly claimed that Kyber-512 is as difficult to break as
AES-128 (see, e.g., page 8 and Figure 1 of NISTIR 8413 claiming that
Kyber-512 is &#34;category 1&#34;), at least by known attacks. As you know, this
is the minimum security level allowed by the official evaluation
criteria for the NIST Post-Quantum Cryptography Standardization Project.</p>
<p>However, NIST has concealed many details of the investigation that led
to this claim. NIST admits that &#34;we did consult among ourselves and with
the Kyber team&#34;; NIST still has not published those communications.</p>
<p>I have been trying to review the details of NIST&#39;s work on this topic.
NIST&#39;s lack of transparency makes this review process unnecessarily
difficult.</p>
<p>Some information was released by Dr. Moody and Dr. Perlner in response
to my requests, but this information is (1) incomplete and (2) unclear.
My email dated 8 Dec 2022 03:10:06 +0100 consisted of an &#34;am I correctly
gathering&#34; clarification question that could have been immediately
answered with a simple &#34;Yes, that&#39;s correct&#34; if my understanding of
NIST&#39;s calculations was correct; but there was no reply, so presumably
NIST actually meant something else. Surely the communications that NIST
is concealing shed light on how NIST actually reached the above claim.</p>
<p>I am writing to file a formal complaint regarding NIST&#39;s failure to
promptly and publicly disclose full details of its investigation of the
security of Kyber-512. This investigation should have been carried out
transparently from the outset, allowing prompt correction of any errors
that NIST failed to detect. The fact that NIST was still concealing the
details in July 2022 prevented the public from seeing how NIST arrived
at NISTIR 8413&#39;s claims on the topic. The fact that NIST is continuing
to conceal the details today seems inexplicable except as part of NIST
trying to limit public review of NIST&#39;s security evaluations.</p>
<p>Please acknowledge receipt of this message, and please publish full
details of NIST&#39;s investigation of the security of Kyber-512.</p>
</blockquote>
<p>I escalated the complaint to NIST&#39;s Matthew Scholl on 20 January 2023.
Scholl didn&#39;t reply.
The public still hasn&#39;t seen the details of
NIST&#39;s consultations &#34;among ourselves and with the Kyber team&#34;
regarding Kyber-512.</p>
<p>Maybe Scholl was sending internal email:
&#34;Why is djb asking about this?
Did we screw something up again?&#34;
Maybe NIST looked again at my April 2022 message,
realized how badly it had botched its Kyber-512 security analysis,
and then decided that it could get away with being obstructionist
rather than admitting the error.</p>
<p>Or maybe NIST,
still struggling to catch up on post-quantum cryptography,
simply hasn&#39;t had time to figure out the meaning of the numbers
that it&#39;s multiplying to obtain its claims regarding Kyber-512.
But this doesn&#39;t explain what happened next,
namely NIST spending more time dodging clarification questions
than it would have spent simply answering the questions.</p>
<p>The same day that I escalated
my non-transparency complaint to Scholl,
I publicly noted NIST&#39;s non-responsiveness,
and
<a href="https://groups.google.com/a/list.nist.gov/g/pqc-forum/c/4MBurXr58Rs/m/EQXN_5z-AQAJ">asked</a>
if anyone saw another way to interpret NIST&#39;s calculations:</p>
<blockquote>
<p>In the absence of such clarity, reviewers have to worry that putting
NIST&#39;s stated components together in what <em>seems</em> to be the obvious way,
and then doing the work to disprove what NIST <em>appears</em> to be claiming
about the security margin, will lead to a response claiming that, no,
NIST meant something else. It&#39;s natural to ask for clarification.</p>
<p>... I&#39;ve again gone through NIST&#39;s 7 December email, and again concluded
that for this scenario NIST is claiming 34 bits in the way spelled out
below. Is there any way I could be missing something here? Does anyone
see another way to interpret NIST&#39;s calculations?</p>
</blockquote>
<p>NIST
<a href="https://groups.google.com/a/list.nist.gov/g/pqc-forum/c/4MBurXr58Rs/m/VcKp223-DQAJ">dodged</a>,
replying that NIST&#39;s email &#34;speaks for itself&#34;.</p>
<p>Well, yes, I think NISTBS speaks for itself, and is very clearly adding
the &#34;40 bits of additional security&#34; to the 137 postulated in scenario X,
obtaining 177 in that scenario,
i.e., 34 bits more than NIST&#39;s 143 target.
I was simply asking for NIST to confirm that, yes,
in that scenario you take the 137 from Matzov,
and add the &#34;40 bits of additional security&#34;,
giving 177 bits of security.</p>
<p>NIST also tried to shift attention to the question of
&#34;whether or not our current plan to standardize Kyber512 is a good one&#34;,
while downplaying the question of whether NIST had correctly calculated
the Kyber-512 security level:</p>
<blockquote>
<p>While
reviewers are free, as a fun exercise, to attempt to &#34;disprove what NIST
<em>appears</em> to be claiming about the security margin,&#34; the results of this
exercise would not be particularly useful to the standardization process.</p>
</blockquote>
<p>Seriously?
NIST</p>
<ul>
<li>
<p>kicks out NTRU-509 as supposedly being easier to break than AES-128,</p>
</li>
<li>
<p>keeps Kyber-512 as supposedly being as hard to break as AES-128,</p>
</li>
<li>
<p>repeatedly, inside its rationale for selecting Kyber, points to Kyber-512&#39;s efficiency,</p>
</li>
<li>
<p>says it&#39;s planning to standardize Kyber-512 as supposedly being as hard to break as AES-128,
  and then</p>
</li>
<li>
<p>claims that disproving NIST&#39;s Kyber-512 security-level calculation wouldn&#39;t be useful input?</p>
</li>
</ul>
<p>I
<a href="https://groups.google.com/a/list.nist.gov/g/pqc-forum/c/4MBurXr58Rs/m/0mzp87QiCgAJ">replied</a>,
starting with again asking for clarification:</p>
<blockquote>
<p>I <em>think</em> I understand what NIST is claiming in that message regarding
the quantitative Kyber security level.</p>
<p>I <em>think</em> that my clarification question (focusing on one example, much
shorter than NIST&#39;s message) is identifying the obvious interpretation.</p>
<p>But then why hasn&#39;t NIST simply said &#34;Yes, that&#39;s correct&#34; in response?</p>
<p>If the interpretation I&#39;ve identified differs from what NIST meant, can
NIST please simply say what the difference is, so that security
reviewers don&#39;t have to spend time on the quantitative security claims
that NIST currently <em>seems</em> to be making?</p>
</blockquote>
<p>I also commented on the notion that this wouldn&#39;t be useful input:</p>
<blockquote>
<p>If Kyber-512 doesn&#39;t meet the minimum security level allowed by the
official call for submissions to the NIST Post-Quantum Cryptography
Standardization Project then Kyber-512 should not be standardized.</p>
<p>NIST&#39;s evaluation of the Kyber-512 security level---after various attack
advances newer than the latest version of the Kyber submission---depends
explicitly on NIST&#39;s calculations of the impact of memory costs.</p>
<p>With all due respect, is it so hard to imagine that NIST has botched
those calculations? If NIST is so sure that it got the whole sequence of
calculations right, why is it so resistant to clarification questions
that will help reviewers check and confirm that NIST got this right? If
NIST <em>isn&#39;t</em> sure, doesn&#39;t that make public review even more important?</p>
<p>In any case, there&#39;s a strong public interest in having NIST&#39;s security
evaluations clearly and promptly explained, to maximize the chance of
having errors corrected before bad decisions are set into stone.</p>
</blockquote>
<p>NIST
<a href="https://groups.google.com/a/list.nist.gov/g/pqc-forum/c/4MBurXr58Rs/m/FaoVfGA6CgAJ">dodged again</a>:</p>
<blockquote>
<p>It would be helpful to redirect discussion to</p>
<p>1)      The question of whether Kyber512 is as hard to break as AES128, (which is a
scientific question that cannot be settled by NIST pronouncements)</p>
<p>2)      The related question of whether Kyber512 should be standardized, (which is a
question where NIST will ultimately need to make a definitive decision, but thus far
we have only signaled we are leaning towards yes.)</p>
<p>With this in mind, I would like to note that the technical point on which Dan has
asked for clarification is effectively &#34;how much additional security does Kyber512
get on account of memory access costs, according to the NTRUprime submission&#39;s
memory cost model?&#34; Surely Dan, being on the NTRUPrime team, is in a better position
to answer this question than us.</p>
</blockquote>
<p>Seriously?
NIST</p>
<ul>
<li>
<p>takes NTRU Prime&#39;s smallest bitops/iter number,</p>
</li>
<li>
<p>slightly screws up by failing to downscale that number from <code>sntrup653</code> to Kyber-512,</p>
</li>
<li>
<p>massively screws up by multiplying that number by Matzov&#39;s 2<sup>137</sup> bitops,</p>
</li>
<li>
<p>claims on this basis that
  &#34;a lot of things would have to go wrong simultaneously to
  push the real-world classical cost of known attacks against Kyber512 below category 1&#34;,
  and then</p>
</li>
<li>
<p>says that any questions should be addressed to the NTRU Prime team?</p>
</li>
</ul>
<p>Even if NIST <em>didn&#39;t</em> understand by this point that it had screwed up,
it certainly knew that</p>
<ul>
<li>
<p>NISTBS was stating conclusions about the Kyber-512 security level relative to AES-128,
  and</p>
</li>
<li>
<p>those conclusions were not in the source documents that NISTBS was citing.</p>
</li>
</ul>
<p>Those conclusions were the result of <em>calculations announced by NIST</em>.
It&#39;s completely inappropriate
for NIST to be trying to deflect clarification questions about those calculations.</p>
<p><a href="https://blog.cr.yp.to/20220129-plagiarism.html">Chris Peikert</a>
had entered the discussion in the meantime
to issue blanket denials that NIST was claiming any particular number of bits of security.
Of course, Peikert didn&#39;t propose an alternative interpretation
of NIST&#39;s words &#34;40 bits of additional security&#34;.</p>
<p>I posted a
<a href="https://groups.google.com/a/list.nist.gov/g/pqc-forum/c/4MBurXr58Rs/m/bpbdpmtICgAJ">line-by-line dissection</a>
of NISTBS,
very similar to the line-by-line dissection shown above,
and asked if anyone could see any alternative interpretation:</p>
<blockquote>
<p>If anyone sees any way that I could be misunderstanding the details of
NIST&#39;s posting, please pinpoint which step is at issue and what the
alternative interpretation of NIST&#39;s calculation is supposed to be.</p>
</blockquote>
<p>There was no reply.</p>
<p>Perhaps NIST will now claim that,
when it wrote &#34;40 bits of additional security&#34;,
it actually meant something different from, um, 40 bits of additional security.
But then why didn&#39;t NIST promptly answer my first question
by saying that, no, they didn&#39;t mean 40 bits of additional security,
and here&#39;s what they did mean?</p>
<p>I went far beyond the call of duty
in informing NIST of my understanding of NISTBS,
asking for confirmation,
and giving them ample time to reply.
By dodging, NIST successfully delayed having NISTBS publicly debunked.</p>
<p>At some point one has to draw a line and say that this has gone too far.
NIST&#39;s miscalculation of Kyber-512&#39;s security level
is still sitting there misinforming people,
and it has to be corrected.</p>
<p><strong>NIST rescuing Kyber-512, part 4: standards making unreviewable security claims.</strong>
In August 2023,
NIST released a
<a href="https://web.archive.org/web/20230827094905/https://nvlpubs.nist.gov/nistpubs/FIPS/NIST.FIPS.203.ipd.pdf">draft</a>
of its Kyber standard (&#34;ML-KEM&#34;),
in particular saying
&#34;it is claimed that the computational resources needed to break ML-KEM
are greater than or equal to the computational resources needed to break the block cipher ...
ML-KEM-512 is claimed to be in security category 1, ML-KEM-768 is claimed to be in security category 3, and ML-KEM-1024 is claimed to be in security category 5&#34;.</p>
<p>Impressive use of the passive voice.
Is <em>NIST</em> claiming these categories?
Are the <em>designers</em> claiming these categories?
Is someone else claiming these categories?</p>
<p>Citation needed.
Or, really, <em>responsibility</em> needed.</p>
<p>Appendix A of the draft
again says that these &#34;categories&#34; are defined as
matching or surpassing AES-128, AES-192, and AES-256 respectively
in every &#34;potentially relevant&#34; cost metric:</p>
<blockquote>
<p>Each category is defined by a comparatively easy-to-analyze reference primitive, whose security
will serve as a floor for a wide variety of metrics that NIST deems potentially relevant to practical
security. ...</p>
<p>In order for a cryptosystem to satisfy one
of the above security requirements, any attack must require computational resources comparable
to or greater than the stated threshold, with respect to all metrics that NIST deems to be potentially
relevant to practical security.</p>
</blockquote>
<p>The latest Kyber documentation says that
the Kyber-512 attack cost could be as low as 2<sup>135</sup> &#34;classical gates&#34;.
That&#39;s below NIST&#39;s estimate of 2<sup>143</sup> &#34;classical gates&#34; for AES-128,
never mind subsequent attack developments.
Where exactly is the justification for claiming that Kyber-512 reaches the AES-128 floor
in all potentially relevant metrics?</p>
<p>Is NIST now officially declaring that &#34;classical gates&#34; aren&#39;t &#34;potentially relevant to practical security&#34;?</p>
<p>If so,
how does NIST reconcile this with NIST&#39;s 2022 selection report,
which used gate counts (&#34;the non-local cost model&#34;)
as an excuse to kick out the most efficient lattice KEM that NIST was considering,
namely NTRU-509?</p>
<p>What exactly <em>are</em> the metrics that NIST is now using
for the claim that Kyber-512 is as hard to break as AES-128?
When and where were the definitions of those metrics published?
(NISTBS doesn&#39;t even pass basic type-checking,
let alone refer to a clearly defined metric.)</p>
<p>Where&#39;s the analysis of Kyber-512&#39;s security level in NIST&#39;s metrics?</p>
<p>For comparison,
where&#39;s the analysis of the AES-128 security level in NIST&#39;s metrics?</p>
<p>The Kyber documentation concentrates on Kyber-512 for its concrete cost analysis,
but the subexponential &#34;dimensions for free&#34; speedup (and subsequent improvements)
should do more damage to security at larger sizes.
Where are the analyses of the Kyber-768, AES-192, Kyber-1024, and AES-256 security levels in NIST&#39;s metrics?</p>
<p>NIST&#39;s call for submissions said the following:</p>
<blockquote>
<p>All submitters are advised to
be somewhat conservative in assigning parameters to a given category, but submitters of
algorithms where the complexity of the best known attack has recently decreased
significantly, or is otherwise poorly understood, should be especially conservative.</p>
</blockquote>
<p>How exactly is this being handled for the latest &#34;category&#34; claims?
Are the claims accounting for
the 32-bit range of &#34;known unknowns&#34; in the latest Kyber documentation?
A wider range given the &#34;unknowns&#34; appearing in newer papers?
An even wider range to protect against the likelihood of further attack speedups?</p>
<p>Readers understand the word &#34;claim&#34;
to be asserting that something is true,
not to be merely saying &#34;we don&#39;t think it&#39;s terribly likely that this is false&#34;.
Why does this draft standard
conceal NIST&#39;s assessment of the probability of failure?</p>
<p>The official NISTPQC call for submissions said
<a href="https://web.archive.org/web/20220119113311/https://csrc.nist.gov/CSRC/media/Projects/Post-Quantum-Cryptography/documents/call-for-proposals-final-dec-2016.pdf">&#34;NIST will perform a thorough analysis of the submitted algorithms in a manner that is open and transparent to the public&#34;</a>.
Scholl said
<a href="https://web.archive.org/web/20211115191840/https://www.nist.gov/blogs/taking-measure/post-quantum-encryption-qa-nists-matt-scholl">&#34;We operate transparently. We&#39;ve shown all our work&#34;</a>.
But the reality is that
security reviewers aren&#39;t even being given a clear statement of <em>what</em> exactly is being claimed about Kyber&#39;s security,
let alone what the justification for that claim is supposed to be.</p>
<p><strong>Next steps.</strong>
Given how unstable and poorly understood the lattice attack surface is,
standardizing Kyber-512 (or NTRU-509) would be reckless.</p>
<p>The poor understanding is a sign of danger.
Contrary to NISTBS,
it&#39;s entirely possible that Kyber-512 is substantially easier to break than AES-128
with attacks that have already been published,
even considering the costs of memory access.
The opposite is also possible.
Figuring out the actual status of this bleeding-edge proposal would be a tough research project.</p>
<p>The instability is another sign of danger.
How are we supposed to manage the risks of better attacks wiping out many more bits of security?</p>
<p>(&#34;Bad news: It&#39;s broken. Good news: Comparing it to AES-128 has become much easier.&#34;)</p>
<p>AES-128 isn&#39;t some stratospheric security level.
For example,
<a href="https://blog.cr.yp.to/20151120-batchattacks.html">multi-target attacks</a>
against AES-128
take only 2<sup>88</sup> computations to break one of a trillion keys.
That amount of computation is already feasible for large-scale attackers today.
Even if you think this is too expensive to worry about,
what happens if a cryptosystem actually loses 10 or 20 or 30 bits compared to that?</p>
<p>A paper at ACM CCS 2021
claimed to be able to show that one-out-of-many-ciphertext attacks against Kyber
are as hard as single-ciphertext attacks.
But I have a paper
<a href="https://cr.yp.to/papers.html#lprrr">&#34;Multi-ciphertext security degradation for lattices&#34;</a>
that</p>
<ul>
<li>
<p>points out an apparently unfixable flaw in the proof and</p>
</li>
<li>
<p>shows that,
  according to the heuristics used in Kyber&#39;s security analysis,
  particular multi-ciphertext attacks are asymptotically more efficient
  than the standard single-ciphertext attacks.</p>
</li>
</ul>
<p>The main theorem of my paper isn&#39;t easy but now has a proof
fully verified by <a href="https://www.cl.cam.ac.uk/~jrh13/hol-light/">HOL Light</a>.
&#34;Asymptotically&#34; refers to what happens when sizes grow to infinity;
more research is required to quantify
the impact of these multi-ciphertext attacks—and whatever improved attacks people
find—upon Kyber&#39;s limited range of sizes.
This is just one of many unexplored parts of the attack surface.</p>
<p>Some attack avenues have clear quantitative limits:
for example, 2<sup>40</sup>-target attacks can&#39;t eliminate more than 40 bits of security.
Replacing Kyber-512 with Kyber-1024 clearly reduces risks
(which is not to say that it eliminates <em>all</em> risks:
look at what happened to SIKE).
There are many previous examples in cryptography
of attacks that would have been stopped
if cryptographic parameters had been chosen just twice as large
as what people had thought was necessary.</p>
<p>Standardizing Kyber-512 means that Kyber-512 will be deployed
in many applications that would easily have been able to afford Kyber-1024 or NTRU-1229
or something even larger.
This is true even if the standard has Kyber-1024 (or Kyber-768)
as an option, even <em>the recommended option</em>.
It&#39;s
<a href="https://cr.yp.to/papers.html#competitions">easier</a>
for a manager to take the fastest option
than to investigate whether the fastest option is actually needed.
Why exactly <em>won&#39;t</em> a manager take the fastest option
if NIST has declared it to be a standard option?</p>
<p>Security is supposed to be job #1.
So I recommend eliminating Kyber-512.
I also recommend that NIST be honest with the public about what happened here:</p>
<ul>
<li>
<p>Honest NIST: &#34;We were desperate to establish that Kyber-512 is as hard to break as AES-128,
  given the costs of memory access, assuming no attack improvements.
  This desperation led us to botch our security-level calculations. Sorry.&#34;</p>
</li>
<li>
<p>Public: &#34;So you&#39;re withdrawing the claim that Kyber-512 qualifies for category 1?&#34;</p>
</li>
<li>
<p>Honest NIST: &#34;Correct. We are not making a claim either way.
  Settling this requires future research.
  Given the uncertainties regarding the performance of current attacks
  and the risks of better attacks,
  we are no longer planning to standardize Kyber-512.
  Our apologies to anyone who already invested effort in Kyber-512.&#34;</p>
</li>
<li>
<p>Public: &#34;But, wait, doesn&#39;t removing Kyber-512
  make NTRU the clear winner in flexibility and performance?&#34;</p>
</li>
<li>
<p>Honest NIST: &#34;Yes.
  We were desperate to create the opposite perception.
  That&#39;s why we were desperate to keep Kyber-512.
  That&#39;s also why we were manipulating our selection and presentation of data in other ways,
  for example by kicking out NTRU-509 on the basis of gate counts
  while keeping Kyber-512 on the basis of memory-access costs.
  Sorry.&#34;</p>
</li>
<li>
<p>Public: &#34;Partway through the competition,
  you suddenly started criticizing submissions that weren&#39;t providing category 5.
  NTRU responded with parameters having much higher Core-SVP than Kyber-1024.
  Does Kyber-1024 meet category 5?&#34;</p>
</li>
<li>
<p>Honest NIST: &#34;Figuring that out would be another tough research project.
  The latest versions of Kyber-512, Kyber-768, and Kyber-1024
  report Core-SVP 2<sup>118</sup>, 2<sup>183</sup>, and 2<sup>256</sup>,
  so we extrapolated from saying that Kyber-512 is in category 1
  to saying that Kyber-768 is in category 3 and that Kyber-1024 is in category 5.
  We never looked at the details.
  Sorry.&#34;</p>
</li>
<li>
<p>Public: &#34;Doesn&#39;t your official report say that you&#39;re confident in the security of NTRU?
  Doesn&#39;t this mean that NTRU actually scores better than Kyber on all three evaluation factors?&#34;</p>
</li>
<li>
<p>Honest NIST: &#34;Yes.
  The only decisive factor listed in our selection report was that
  Kyber was &#39;near the top (if not the top) in most benchmarks&#39;.
  Without Kyber-512, Kyber can&#39;t compete with NTRU in performance.
  Sorry.&#34;</p>
</li>
<li>
<p>Public: &#34;Why were you so desperate to take Kyber over NTRU in the first place?&#34;</p>
</li>
<li>
<p>Honest NIST: &#34;Here are the full records that we were keeping secret,
  and in particular they answer that question.
  These records also show why we weren&#39;t meeting our commitment to operate transparently,
  and why we repeatedly lied about this.&#34;</p>
</li>
<li>
<p>Public: &#34;You exposed three years of user data to attackers
  by telling people to use Kyber starting when your patent license activates in 2024,
  rather than telling people to use NTRU starting in 2021!&#34;</p>
</li>
<li>
<p>Honest NIST: &#34;Sorry. What&#39;s done is done.
  We&#39;re locked into standardizing Kyber at this point,
  and deviating from this would produce even more slowdowns.
  We&#39;ll standardize Kyber-768 as category 2 and Kyber-1024 as category 4.&#34;</p>
</li>
</ul>
<p>After everything that has happened,
I&#39;m skeptical that we&#39;re going to suddenly see Honest NIST,
but hope springs eternal.</p>
<p>[2023.10.04 edit: &#34;NIST-509&#34; -&gt; &#34;NTRU-509&#34;.]</p><hr/><SPAN size="1"><b>Version:</b>
This is version 2023.10.04 of the 20231003-countcorrectly.html web page.
</SPAN>

</div>
  </body>
</html>
