<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/divyaprakash0426/autoshorts">Original</a>
    <h1>Show HN: AutoShorts ‚Äì Local, GPU-accelerated AI video pipeline for creators</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<blockquote>
<p dir="auto">Automatically generate viral-ready vertical short clips from long-form gameplay footage using AI-powered scene analysis, GPU-accelerated rendering, and optional AI voiceovers.</p>
</blockquote>
<p dir="auto">AutoShorts analyzes your gameplay videos to identify the most engaging moments‚Äîaction sequences, funny fails, or highlight achievements‚Äîthen automatically crops, renders, and adds subtitles or AI voiceovers to create ready-to-upload short-form content.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/b5ee2140b8002196a21d37a714a79eb491f005f5c2026df62aeb675021374255/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d332e31302d626c7565"><img src="https://camo.githubusercontent.com/b5ee2140b8002196a21d37a714a79eb491f005f5c2026df62aeb675021374255/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d332e31302d626c7565" alt="Python" data-canonical-src="https://img.shields.io/badge/python-3.10-blue"/></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/dc8c3e49ff4d8b14d8de3ef63d632f0bf74edb3304d2d6b17a6ccea77e9b1128/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5079546f7263682d2532334545344332432e7376673f7374796c653d666c6174266c6f676f3d5079546f726368266c6f676f436f6c6f723d7768697465"><img src="https://camo.githubusercontent.com/dc8c3e49ff4d8b14d8de3ef63d632f0bf74edb3304d2d6b17a6ccea77e9b1128/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f5079546f7263682d2532334545344332432e7376673f7374796c653d666c6174266c6f676f3d5079546f726368266c6f676f436f6c6f723d7768697465" alt="PyTorch" data-canonical-src="https://img.shields.io/badge/PyTorch-%23EE4C2C.svg?style=flat&amp;logo=PyTorch&amp;logoColor=white"/></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/785edadaa028a6fbef9a79536387abbef923c96c492935302762c832e2e6bc85/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f435544412d31322e782d677265656e"><img src="https://camo.githubusercontent.com/785edadaa028a6fbef9a79536387abbef923c96c492935302762c832e2e6bc85/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f435544412d31322e782d677265656e" alt="CUDA" data-canonical-src="https://img.shields.io/badge/CUDA-12.x-green"/></a>
<a target="_blank" rel="noopener noreferrer nofollow" href="https://camo.githubusercontent.com/a59ca146c6e132f75197fb2a5ed3de506e7bbcc8f9bdd3ccac14beba343105d3/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f636b65722d2532333064623765642e7376673f7374796c653d666c6174266c6f676f3d646f636b6572266c6f676f436f6c6f723d7768697465"><img src="https://camo.githubusercontent.com/a59ca146c6e132f75197fb2a5ed3de506e7bbcc8f9bdd3ccac14beba343105d3/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f636b65722d2532333064623765642e7376673f7374796c653d666c6174266c6f676f3d646f636b6572266c6f676f436f6c6f723d7768697465" alt="Docker" data-canonical-src="https://img.shields.io/badge/docker-%230db7ed.svg?style=flat&amp;logo=docker&amp;logoColor=white"/></a>
<a href="https://github.com/divyaprakash0426/autoshorts/blob/main/LICENSE"><img src="https://camo.githubusercontent.com/fdf2982b9f5d7489dcf44570e714e3a15fce6253e0cc6b5aa61a075aac2ff71b/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4d49542d79656c6c6f772e737667" alt="License: MIT" data-canonical-src="https://img.shields.io/badge/License-MIT-yellow.svg"/></a></p>
<hr/>

<p dir="auto">Here are some shorts automatically generated from gameplay footage:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Sample 1</th>
<th>Sample 2</th>
<th>Sample 3</th>
<th>Sample 4</th>
</tr>
</thead>
<tbody>
<tr>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/divyaprakash0426/autoshorts/blob/main/generated/showcase/indianajones_pt1_scene-0.gif"><img src="https://github.com/divyaprakash0426/autoshorts/raw/main/generated/showcase/indianajones_pt1_scene-0.gif" alt="Sample 1" data-animated-image=""/></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/divyaprakash0426/autoshorts/blob/main/generated/showcase/indianajones_pt1_scene-1.gif"><img src="https://github.com/divyaprakash0426/autoshorts/raw/main/generated/showcase/indianajones_pt1_scene-1.gif" alt="Sample 2" data-animated-image=""/></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/divyaprakash0426/autoshorts/blob/main/generated/showcase/indianajones_pt1_scene-2.gif"><img src="https://github.com/divyaprakash0426/autoshorts/raw/main/generated/showcase/indianajones_pt1_scene-2.gif" alt="Sample 3" data-animated-image=""/></a></td>
<td><a target="_blank" rel="noopener noreferrer" href="https://github.com/divyaprakash0426/autoshorts/blob/main/generated/showcase/indianajones_pt1_scene-3.gif"><img src="https://github.com/divyaprakash0426/autoshorts/raw/main/generated/showcase/indianajones_pt1_scene-3.gif" alt="Sample 4" data-animated-image=""/></a></td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<hr/>

<div dir="auto"><h3 tabindex="-1" dir="auto">üéØ AI-Powered Scene Analysis</h3><a id="user-content--ai-powered-scene-analysis" aria-label="Permalink: üéØ AI-Powered Scene Analysis" href="#-ai-powered-scene-analysis"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li><strong>Multi-Provider Support</strong>: Choose between <strong>OpenAI</strong> (GPT-5-mini, GPT-4o) or <strong>Google Gemini</strong> for scene analysis</li>
<li><strong>Semantic Analysis Modes</strong>:
<ul dir="auto">
<li><code>action</code> ‚Äî Focus on intense combat/action moments</li>
<li><code>funny</code> ‚Äî Detect fail compilations and humorous moments</li>
<li><code>highlight</code> ‚Äî Find memorable achievements and clutch plays</li>
<li><code>mixed</code> ‚Äî Auto-detect the best category for each clip (recommended)</li>
</ul>
</li>
</ul>
<div dir="auto"><h3 tabindex="-1" dir="auto">üéôÔ∏è Subtitle Generation</h3><a id="user-content-Ô∏è-subtitle-generation" aria-label="Permalink: üéôÔ∏è Subtitle Generation" href="#Ô∏è-subtitle-generation"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li><strong>Speech Mode</strong>: Uses OpenAI Whisper to transcribe voice/commentary</li>
<li><strong>AI Captions Mode</strong>: AI-generated contextual captions for gameplay without voice</li>
<li><strong>Caption Styles</strong>: <code>gaming</code>, <code>dramatic</code>, <code>funny</code>, <code>minimal</code>, or <code>auto</code></li>
<li><strong>PyCaps Integration</strong>: Multiple visual templates including <code>hype</code>, <code>retro-gaming</code>, <code>neo-minimal</code></li>
<li><strong>AI Enhancement</strong>: Semantic tagging and emoji suggestions (e.g., &#34;HEADSHOT! üíÄüî•&#34;)</li>
</ul>
<div dir="auto"><h3 tabindex="-1" dir="auto">üîä AI Voiceover (ChatterBox TTS)</h3><a id="user-content--ai-voiceover-chatterbox-tts" aria-label="Permalink: üîä AI Voiceover (ChatterBox TTS)" href="#-ai-voiceover-chatterbox-tts"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li><strong>Local TTS Generation</strong>: No cloud API needed for voice synthesis</li>
<li><strong>Emotion Control</strong>: Adjustable emotion/exaggeration levels for English</li>
<li><strong>Multilingual Support</strong>: 20+ languages including Japanese, Korean, Chinese, Spanish, French, and more</li>
<li><strong>Voice Cloning</strong>: Optional reference audio for custom voice styles</li>
<li><strong>Smart Mixing</strong>: Automatic ducking of game audio when voiceover plays</li>
</ul>
<div dir="auto"><h3 tabindex="-1" dir="auto">‚ö° GPU-Accelerated Pipeline</h3><a id="user-content--gpu-accelerated-pipeline" aria-label="Permalink: ‚ö° GPU-Accelerated Pipeline" href="#-gpu-accelerated-pipeline"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li><strong>Scene Detection</strong>: Custom implementation using <code>decord</code> + PyTorch on GPU</li>
<li><strong>Audio Analysis</strong>: <code>torchaudio</code> on GPU for fast RMS and spectral flux calculation</li>
<li><strong>Video Analysis</strong>: GPU streaming via <code>decord</code> for stable motion estimation</li>
<li><strong>Image Processing</strong>: <code>cupy</code> (CUDA-accelerated NumPy) for blur and transforms</li>
<li><strong>Rendering</strong>: PyTorch + <strong>NVENC</strong> hardware encoder for ultra-fast rendering</li>
</ul>
<div dir="auto"><h3 tabindex="-1" dir="auto">üìê Smart Video Processing</h3><a id="user-content--smart-video-processing" aria-label="Permalink: üìê Smart Video Processing" href="#-smart-video-processing"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>Scenes ranked by combined action score (audio 0.6 + video 0.4 weights)</li>
<li>Configurable aspect ratio (default 9:16 for TikTok/Shorts/Reels)</li>
<li>Smart cropping with optional blurred background for non-vertical footage</li>
<li>Retry logic during rendering to avoid spurious failures</li>
</ul>
<div dir="auto"><h3 tabindex="-1" dir="auto">üõ°Ô∏è Robust Fallback System</h3><a id="user-content-Ô∏è-robust-fallback-system" aria-label="Permalink: üõ°Ô∏è Robust Fallback System" href="#Ô∏è-robust-fallback-system"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">AutoShorts is designed to work even when optimal components fail:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Component</th>
<th>Primary</th>
<th>Fallback</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Video Encoding</strong></td>
<td>NVENC (GPU)</td>
<td>libx264 (CPU)</td>
</tr>
<tr>
<td><strong>Subtitle Rendering</strong></td>
<td>PyCaps (styled)</td>
<td>FFmpeg burn-in (basic)</td>
</tr>
<tr>
<td><strong>AI Analysis</strong></td>
<td>OpenAI/Gemini API</td>
<td>Heuristic scoring (local)</td>
</tr>
<tr>
<td><strong>TTS Device</strong></td>
<td>CUDA (GPU)</td>
<td>CPU inference</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<hr/>


<ul dir="auto">
<li><strong>NVIDIA GPU</strong> with CUDA support (RTX series recommended for NVENC + TTS)</li>
<li><strong>NVIDIA Drivers</strong> compatible with CUDA 12.x</li>
</ul>

<ul dir="auto">
<li>Python 3.10</li>
<li>FFmpeg 4.4.2 (for Decord compatibility)</li>
<li>CUDA Toolkit with <code>nvcc</code> (for building Decord from source)</li>
<li>System libraries: <code>libgl1</code>, <code>libglib2.0-0</code></li>
</ul>
<hr/>

<div dir="auto"><h3 tabindex="-1" dir="auto">Option 1: Makefile Installation (Recommended)</h3><a id="user-content-option-1-makefile-installation-recommended" aria-label="Permalink: Option 1: Makefile Installation (Recommended)" href="#option-1-makefile-installation-recommended"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">The Makefile handles everything automatically‚Äîenvironment creation, dependency installation, and building Decord with CUDA support.</p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/divyaprakash0426/autoshorts.git
cd autoshorts

# Run the installer (uses conda/micromamba automatically)
make install

# Activate the environment
overlay use .venv/bin/activate.nu    # For Nushell
# OR
source .venv/bin/activate            # For Bash/Zsh"><pre>git clone https://github.com/divyaprakash0426/autoshorts.git
<span>cd</span> autoshorts

<span><span>#</span> Run the installer (uses conda/micromamba automatically)</span>
make install

<span><span>#</span> Activate the environment</span>
overlay use .venv/bin/activate.nu    <span><span>#</span> For Nushell</span>
<span><span>#</span> OR</span>
<span>source</span> .venv/bin/activate            <span><span>#</span> For Bash/Zsh</span></pre></div>
<p dir="auto">The Makefile will:</p>
<ol dir="auto">
<li>Download micromamba if conda/mamba is not found</li>
<li>Create a Python 3.10 environment with FFmpeg 4.4.2</li>
<li>Install NV Codec Headers for NVENC support</li>
<li>Build Decord from source with CUDA enabled</li>
<li>Install all pip requirements</li>
</ol>
<div dir="auto"><h3 tabindex="-1" dir="auto">Option 2: Docker (GPU Required)</h3><a id="user-content-option-2-docker-gpu-required" aria-label="Permalink: Option 2: Docker (GPU Required)" href="#option-2-docker-gpu-required"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><strong>Prerequisite</strong>: <a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/install-guide.html" rel="nofollow">NVIDIA Container Toolkit</a> must be installed.</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Build the image
docker build -t autoshorts .

# Run with GPU access
docker run --rm \
    --gpus all \
    -v $(pwd)/gameplay:/app/gameplay \
    -v $(pwd)/generated:/app/generated \
    --env-file .env \
    autoshorts"><pre><span><span>#</span> Build the image</span>
docker build -t autoshorts <span>.</span>

<span><span>#</span> Run with GPU access</span>
docker run --rm \
    --gpus all \
    -v <span><span>$(</span>pwd<span>)</span></span>/gameplay:/app/gameplay \
    -v <span><span>$(</span>pwd<span>)</span></span>/generated:/app/generated \
    --env-file .env \
    autoshorts</pre></div>
<blockquote>
<p dir="auto"><strong>Note</strong>: The <code>--gpus all</code> flag is essential for NVENC and CUDA acceleration.</p>
</blockquote>
<hr/>

<p dir="auto">Copy <code>.env.example</code> to <code>.env</code> and configure:</p>

<div dir="auto"><h3 tabindex="-1" dir="auto">Key Configuration Options</h3><a id="user-content-key-configuration-options" aria-label="Permalink: Key Configuration Options" href="#key-configuration-options"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Category</th>
<th>Variable</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>AI Provider</strong></td>
<td><code>AI_PROVIDER</code></td>
<td><code>openai</code>, <code>gemini</code>, or <code>local</code></td>
</tr>
<tr>
<td></td>
<td><code>AI_ANALYSIS_ENABLED</code></td>
<td>Enable/disable AI scene analysis</td>
</tr>
<tr>
<td></td>
<td><code>OPENAI_MODEL</code></td>
<td>Model for analysis (e.g., <code>gpt-5-mini</code>)</td>
</tr>
<tr>
<td></td>
<td><code>AI_SCORE_WEIGHT</code></td>
<td>How much to weight AI vs heuristic (0.0-1.0)</td>
</tr>
<tr>
<td><strong>Semantic Analysis</strong></td>
<td><code>SEMANTIC_GOAL</code></td>
<td><code>action</code>, <code>funny</code>, <code>highlight</code>, or <code>mixed</code></td>
</tr>
<tr>
<td></td>
<td><code>CANDIDATE_CLIP_COUNT</code></td>
<td>Number of clips to analyze</td>
</tr>
<tr>
<td><strong>Subtitles</strong></td>
<td><code>ENABLE_SUBTITLES</code></td>
<td>Enable subtitle generation</td>
</tr>
<tr>
<td></td>
<td><code>SUBTITLE_MODE</code></td>
<td><code>speech</code> (Whisper), <code>ai_captions</code>, or <code>none</code></td>
</tr>
<tr>
<td></td>
<td><code>CAPTION_STYLE</code></td>
<td><code>gaming</code>, <code>dramatic</code>, <code>funny</code>, <code>minimal</code>, <code>auto</code></td>
</tr>
<tr>
<td></td>
<td><code>PYCAPS_TEMPLATE</code></td>
<td>Visual template for captions</td>
</tr>
<tr>
<td><strong>TTS Voiceover</strong></td>
<td><code>ENABLE_TTS</code></td>
<td>Enable ChatterBox voiceover</td>
</tr>
<tr>
<td></td>
<td><code>TTS_LANGUAGE</code></td>
<td>Language code (e.g., <code>en</code>, <code>ja</code>, <code>es</code>)</td>
</tr>
<tr>
<td></td>
<td><code>TTS_EMOTION_LEVEL</code></td>
<td>Emotion intensity or <code>auto</code></td>
</tr>
<tr>
<td><strong>Video Output</strong></td>
<td><code>TARGET_RATIO_W/H</code></td>
<td>Aspect ratio (default 9:16)</td>
</tr>
<tr>
<td></td>
<td><code>SCENE_LIMIT</code></td>
<td>Max clips per source video</td>
</tr>
<tr>
<td></td>
<td><code>MIN/MAX_SHORT_LENGTH</code></td>
<td>Clip duration bounds (seconds)</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">See <code>.env.example</code> for the complete list with detailed descriptions.</p>
<hr/>

<ol dir="auto">
<li>
<p dir="auto"><strong>Place source videos</strong> in the <code>gameplay/</code> directory</p>
</li>
<li>
<p dir="auto"><strong>Run the script</strong>:</p>

</li>
<li>
<p dir="auto"><strong>Generated clips</strong> are saved to <code>generated/</code></p>
</li>
</ol>

<div data-snippet-clipboard-copy-content="generated/
‚îú‚îÄ‚îÄ video_name scene-0.mp4          # Rendered short clip
‚îú‚îÄ‚îÄ video_name scene-0_sub.json     # Subtitle data
‚îú‚îÄ‚îÄ video_name scene-0.ffmpeg.log   # Render log
‚îú‚îÄ‚îÄ video_name scene-1.mp4
‚îî‚îÄ‚îÄ ..."><pre><code>generated/
‚îú‚îÄ‚îÄ video_name scene-0.mp4          # Rendered short clip
‚îú‚îÄ‚îÄ video_name scene-0_sub.json     # Subtitle data
‚îú‚îÄ‚îÄ video_name scene-0.ffmpeg.log   # Render log
‚îú‚îÄ‚îÄ video_name scene-1.mp4
‚îî‚îÄ‚îÄ ...
</code></pre></div>
<hr/>


<div dir="auto" data-snippet-clipboard-copy-content="pip install ruff
ruff check ."><pre>pip install ruff
ruff check <span>.</span></pre></div>


<blockquote>
<p dir="auto">Tests mock GPU availability and can run in standard CI environments.</p>
</blockquote>

<p dir="auto">For faster iteration during development, you can skip expensive steps using these environment variables in your <code>.env</code>:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Variable</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>DEBUG_SKIP_ANALYSIS=1</code></td>
<td>Skip AI scene analysis (uses cached/heuristic scores)</td>
</tr>
<tr>
<td><code>DEBUG_SKIP_RENDER=1</code></td>
<td>Skip video rendering (useful for testing analysis only)</td>
</tr>
<tr>
<td><code>DEBUG_RENDERED_CLIPS=&#34;path1:category,path2&#34;</code></td>
<td>Test with specific pre-rendered clips</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">Example workflow for testing subtitles only:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# In .env
DEBUG_SKIP_ANALYSIS=1
DEBUG_SKIP_RENDER=1
DEBUG_RENDERED_CLIPS=&#34;generated/test_clip.mp4:action&#34;"><pre><span><span>#</span> In .env</span>
DEBUG_SKIP_ANALYSIS=1
DEBUG_SKIP_RENDER=1
DEBUG_RENDERED_CLIPS=<span><span>&#34;</span>generated/test_clip.mp4:action<span>&#34;</span></span></pre></div>
<hr/>

<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Issue</th>
<th>Solution</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>&#34;CUDA not available&#34;</strong></td>
<td>Ensure <code>--gpus all</code> (Docker) or CUDA toolkit is installed</td>
</tr>
<tr>
<td><strong>NVENC Error</strong></td>
<td>Falls back to <code>libx264</code> automatically; check GPU driver</td>
</tr>
<tr>
<td><strong>PyCaps fails</strong></td>
<td>Falls back to FFmpeg burn-in subtitles automatically</td>
</tr>
<tr>
<td><strong>Decord EOF hang</strong></td>
<td>Increase <code>DECORD_EOF_RETRY_MAX</code> or set <code>DECORD_SKIP_TAIL_FRAMES=300</code></td>
</tr>
<tr>
<td><strong>API rate limits</strong></td>
<td>Switch to <code>gpt-5-mini</code> (10M free tokens/day) or use <code>local</code> provider</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<hr/>

<p dir="auto">This project builds upon the excellent work of:</p>
<ul dir="auto">
<li><strong><a href="https://github.com/artryazanov/shorts-maker-gpu">artryazanov/shorts-maker-gpu</a></strong> ‚Äî Heuristics-based shorts maker</li>
<li><strong><a href="https://github.com/Binary-Bytes/Auto-YouTube-Shorts-Maker">Binary-Bytes/Auto-YouTube-Shorts-Maker</a></strong> ‚Äî Original concept and inspiration</li>
</ul>
<hr/>

<p dir="auto">This project is licensed under the <a href="https://github.com/divyaprakash0426/autoshorts/blob/main/LICENSE">MIT License</a>.</p>
<p dir="auto"><a href="https://www.buymeacoffee.com/divyaprakash0426" rel="nofollow"><img src="https://camo.githubusercontent.com/9f44ce2dc3b3eecdd02598900866ffc518801df1932849703dae1e5ce5031070/68747470733a2f2f7777772e6275796d6561636f666665652e636f6d2f6173736574732f696d672f637573746f6d5f696d616765732f6f72616e67655f696d672e706e67" alt="&#34;Buy Me A Coffee&#34;" data-canonical-src="https://www.buymeacoffee.com/assets/img/custom_images/orange_img.png"/></a></p>
</article></div></div>
  </body>
</html>
