<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.runpulse.com/blog/putting-andrew-ngs-ocr-models-to-the-test">Original</a>
    <h1>Putting Andrew Ng&#39;s OCR models to the test</h1>
    
    <div id="readability-page-1" class="page"><div><main><section><div><div><div><div><a href="#"></a><div id="w-node-_3a102f57-930f-0fd9-eead-5ac90c36e33c-cd40214d"><div><div><div><p>February 27, 2025</p><p>•</p><p>3 min read</p></div></div></div><p><img src="https://cdn.prod.website-files.com/6707c5683ddae1a50202bac6/67c11080ceef71342e14181e_V2.png" loading="lazy" alt="Putting Andrew Ng’s OCR Models to The Test" sizes="(max-width: 479px) 100vw, (max-width: 767px) 94vw, (max-width: 991px) 90vw, 59vw" srcset="https://cdn.prod.website-files.com/6707c5683ddae1a50202bac6/67c11080ceef71342e14181e_V2-p-500.png 500w, https://cdn.prod.website-files.com/6707c5683ddae1a50202bac6/67c11080ceef71342e14181e_V2-p-800.png 800w, https://cdn.prod.website-files.com/6707c5683ddae1a50202bac6/67c11080ceef71342e14181e_V2-p-1080.png 1080w, https://cdn.prod.website-files.com/6707c5683ddae1a50202bac6/67c11080ceef71342e14181e_V2-p-1600.png 1600w, https://cdn.prod.website-files.com/6707c5683ddae1a50202bac6/67c11080ceef71342e14181e_V2-p-2000.png 2000w, https://cdn.prod.website-files.com/6707c5683ddae1a50202bac6/67c11080ceef71342e14181e_V2-p-2600.png 2600w, https://cdn.prod.website-files.com/6707c5683ddae1a50202bac6/67c11080ceef71342e14181e_V2-p-3200.png 3200w, https://cdn.prod.website-files.com/6707c5683ddae1a50202bac6/67c11080ceef71342e14181e_V2.png 3952w"/></p><div><p>Today, Andrew Ng, one of the legends of the AI world, released a new document extraction service that went viral on X (<a href="https://x.com/AndrewYNg/status/1895183929977843970">link here</a>). At Pulse, we put the models to the test with complex financial statements and nested tables – the results were underwhelming to say the least, and suffer from many of the same issues we see when simply dumping documents into GPT or Claude.</p><p>Our engineering team, along with many X users, discovered alarming issues when testing complex financial statements:</p><ul role="list"><li><strong>Over 50% hallucinated values</strong> in complex financial tables</li><li><strong>Missing negative signs</strong> and currency markers</li><li><strong>Completely fabricated numbers</strong> in several instances</li><li><strong>30+ second processing times</strong> per document</li></ul><figure><p><img src="https://cdn.prod.website-files.com/6707c5683ddae1a50202bac6/67c11c3472901190a48f37d5_AD_4nXcsVArniAceFxxvlvsJRYfXlF-sti0gFtkstbghLibkKay2C_d7rWZPgPuinvJLmc-BVZSo0radqJl7dyqoLgqZhUEXyxqJ6FYjiPZBOtTp2kl6nqNKI7SeFbTzPXnuxthSMEyOIQ.png" loading="lazy" alt=""/></p><figcaption>Ground Truth</figcaption></figure><figure><p><img src="https://cdn.prod.website-files.com/6707c5683ddae1a50202bac6/67c11c3d37e1c950cd8f0895_AD_4nXe0Vg_zeFFraWhcd4tqvE2pyTB4kf9VZ2JZD5rbvvi8_vxbHeKlVx9HwTn2aMlW6FoVbZ4pbAy-DvVd6IR306J8qVTOeWm_TAbEi6raUwqbTRcV7zDAls9p0Epe1hPB6JNt6R7djQ.png" loading="lazy" alt=""/></p><figcaption>Andrew Ng OCR Output</figcaption></figure><figure><p><img src="https://cdn.prod.website-files.com/6707c5683ddae1a50202bac6/67c11c4e79e1aebc34ccec4d_AD_4nXcBer3Y3DbitGWJxlT4LM9XpZ2ZQ2AIpKsN62AhFejibMjVqZJ1AbKsWxYRfZ3SCW937eeU4zB76JYcFLZhb9FWgd43lrprfsOfCG8ilv-gBD-47gTWsMLBPrWML4SWqcHibneVLw.png" loading="lazy" alt=""/></p><figcaption>Pulse Output</figcaption></figure><p>When financial decisions worth millions depend on accurate extraction, these errors aren&#39;t just inconvenient – they&#39;re potentially catastrophic.</p><p>Let’s run through some quick math: in a typical enterprise scenario with 1,000 pages containing 200 elements per page (usually repeated over tens of thousands of documents), even 99% accuracy still means 2,000 incorrect entries. That&#39;s 2,000 potential failure points that can completely compromise a data pipeline. Our customers have consistently told us they need over 99.9% accuracy for mission-critical operations. With probabilistic LLM models, each extraction introduces a new chance for error, and these probabilities compound across thousands of documents, making the failure rate unacceptably high for real-world applications where precision is non-negotiable.</p><p>As we&#39;ve detailed in our <a href="https://www.runpulse.com/blog/why-llms-suck-at-ocr">previous viral blog post</a>, using LLMs alone for document extraction creates fundamental problems. Their nondeterministic nature means you&#39;ll get different results on each run. Their low spatial awareness makes them unsuitable for complex layouts in PDFs and slides. And their processing speed presents serious bottlenecks for large-scale document processing.</p><p>At Pulse, we&#39;ve taken a different approach that delivers:</p><ul role="list"><li><strong>Accurate extraction</strong> with probability of errors slowly approaching 0</li><li><strong>Complete table, chart and graph data</strong> preservation</li><li><strong>Low-latency processing time</strong> per document</li></ul><p><a href="https://www.runpulse.com/blog/pulse-approach-to-document-intelligence">Our solution</a> combines proprietary table transformer models built from the ground up with traditional computer vision algorithms. We use LLMs only for specific, controlled tasks where they excel – not as the entire extraction pipeline. </p><p>If your organization processes financial, legal, or healthcare documents at scale and needs complete reliability (or really any industry where accuracy is non-negotiable), we&#39;d love to show you how Pulse can transform your workflow.</p><p>Book a demo <a href="https://www.runpulse.com/demo">here</a> to see the difference for yourself.</p></div></div></div></div></div></div></section></main></div></div>
  </body>
</html>
