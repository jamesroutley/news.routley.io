<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://r0bk.github.io/killedbyllm/">Original</a>
    <h1>Killed by LLM</h1>
    
    <div id="readability-page-1" class="page"><div><header><p>A memorial to the benchmarks that defined—and were defeated by—AI progress</p></header><div><div><div><svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="11" cy="11" r="8"></circle><path d="m21 21-4.3-4.3"></path></svg></div></div></div><div><div><div data-year="2024"><div><h2>2024</h2></div><div><div><div><div><div><h3>ARC-AGI<span>(<!-- -->2019<!-- --> - <!-- -->2024<!-- -->)</span></h3><p><span>Reasoning</span></p></div><div><p><span>Killed by</span></p><p><span>Saturation</span></p><a href="https://arxiv.org/abs/1911.01547" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></div></div><p>Killed 1 month ago, Abstract reasoning challenge consisting of visual pattern completion tasks. Each task presents a sequence of abstract visual patterns and requires selecting the correct completion. Created by François Chollet as part of a broader investigation into measuring intelligence. It was 5 years and 1 months old.</p><div><div><p><span>Defeated by:</span></p><!-- --><p>O3</p></div><div><div><p>Original Score</p><p>Human Baseline: ~80%</p></div><div><p>Final Score</p><p><span>O3: 87.5%</span></p></div></div></div></div></div><div><div><div><div><h3>MATH<span>(<!-- -->2021<!-- --> - <!-- -->2024<!-- -->)</span></h3><p><span>Mathematics</span></p></div><div><p><span>Killed by</span></p><p><span>Saturation</span></p><a href="https://arxiv.org/abs/2103.03874" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></div></div><p>Killed 4 months ago, A dataset of 12K challenging competition mathematics problems from AMC, AIME, and other math competitions. Problems range from pre-algebra to olympiad-level and require complex multi-step reasoning. Each problem has a detailed solution that tests mathematical reasoning capabilities. It was 3 years and 6 months old.</p><div><div><p><span>Defeated by:</span></p><!-- --><p>O1</p></div><div><div><p>Original Score</p><p>Average CS PhD: ~40%</p></div><div><p>Final Score</p><p><span>O1: 94.8%</span></p></div></div></div></div></div><div><div><div><div><h3>BIG-Bench-Hard<span>(<!-- -->2022<!-- --> - <!-- -->2024<!-- -->)</span></h3><p><span>Multi-task</span></p></div><div><p><span>Killed by</span></p><p><span>Saturation</span></p><a href="https://arxiv.org/abs/2210.09261" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></div></div><p>Killed 7 months ago, A curated suite of 23 challenging tasks from BIG-Bench where language models initially performed below average human level. Selected to measure progress on particularly difficult capabilities. It was 1 year and 8 months old.</p><div><div><p><span>Defeated by:</span></p><!-- --><p>Sonnet 3.5</p></div><div><div><p>Original Score</p><p>Average Human: 67.7%</p></div><div><p>Final Score</p><div><p><span>Sonnet 3.5: 93.1%</span></p><a href="https://assets.anthropic.com/m/1cd9d098ac3e6467/original/Claude-3-Model-Card-October-Addendum.pdf" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></div></div></div></div></div></div><div><div><div><div><h3>HumanEval<span>(<!-- -->2021<!-- --> - <!-- -->2024<!-- -->)</span></h3><p><span>Coding</span></p></div><div><p><span>Killed by</span></p><p><span>Saturation</span></p><a href="https://arxiv.org/abs/2107.03374" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></div></div><p>Killed 8 months ago, A collection of 164 Python programming problems designed to test language models&#39; coding abilities. Each problem includes a function signature, docstring, and unit tests. Models must generate complete, correct function implementations that pass all test cases. It was 2 years and 10 months old.</p><div><div><p><span>Defeated by:</span></p><!-- --><p>GPT-4o</p></div><div><div><p>Original Score</p><p>Unspecified</p></div><div><p>Final Score</p><div><p><span>GPT-4o: 90.2%</span></p><a href="https://openai.com/index/hello-gpt-4o/" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></div></div></div></div></div></div><div><div><div><div><h3>IFEval<span>(<!-- -->2023<!-- --> - <!-- -->2024<!-- -->)</span></h3><p><span>Instruction Following</span></p></div><div><p><span>Killed by</span></p><p><span>Saturation</span></p><a href="https://arxiv.org/abs/2311.07911" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></div></div><p>Killed 10 months ago, A comprehensive evaluation suite testing instruction following capabilities across coding, math, roleplay, and other tasks. Measures ability to handle complex multi-step instructions and constraints. It was 4 months old.</p><div><div><p><span>Defeated by:</span></p><!-- --><p>LLama 3.3 70B</p></div><div><div><p>Original Score</p><p>Unspecified</p></div><div><p>Final Score</p><div><p><span>LLama 3.3 70B: 92.1%</span></p><a href="https://github.com/meta-llama/llama-models/blob/main/models/llama3_2/MODEL_CARD_VISION.md" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></div></div></div></div></div></div></div></div></div><div><div data-year="2023"><div><h2>2023</h2></div><div><div><div><div><div><h3>GSM8K<span>(<!-- -->2021<!-- --> - <!-- -->2023<!-- -->)</span></h3><p><span>Mathematics</span></p></div><div><p><span>Killed by</span></p><div><p><span>Saturation</span></p><div><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"></circle><path d="M12 16v-4"></path><path d="M12 8h.01"></path></svg><p>GSM8K is often considered contaminated because of its inclusion in several instruction following datasets</p></div></div><a href="https://arxiv.org/abs/2110.14168" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></div></div><p>Killed 1 year ago, A collection of 8.5K grade school math word problems requiring step-by-step solutions. Problems test both numerical computation and natural language understanding through multi-step mathematical reasoning. It was 2 years and 1 months old.</p><div><div><p><span>Defeated by:</span></p><!-- --><p>GPT-4</p></div><div><div><p>Original Score</p><p>Unspecified</p></div><div><p>Final Score</p><div><p><span>GPT-4: 92.0%</span></p><a href="https://cdn.openai.com/papers/gpt-4.pdf" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></div></div></div></div></div></div><div><div><div><div><h3>Turing Test<span>(<!-- -->1950<!-- --> - <!-- -->2023<!-- -->)</span></h3><p><span>Conversation</span></p></div><div><p><span>Killed by</span></p><div><p><span>Saturation</span></p><div><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"></circle><path d="M12 16v-4"></path><path d="M12 8h.01"></path></svg><p>While the Turing Test remains philosophically significant, modern LLMs can consistently pass it, making it no longer effective at measuring the frontier of AI capabilities.</p></div></div><a href="https://courses.cs.umbc.edu/471/papers/turing.pdf" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></div></div><p>Killed 1 year ago, The original AI benchmark proposed by Alan Turing in 1950. In this &#39;imitation game&#39;, a computer must convince human judges it is human through natural conversation. The test sparked decades of debate about machine intelligence and consciousness. It was 73 years and 5 months old.</p><div><div><p><span>Defeated by:</span></p><!-- --><p>GPT-4</p></div><div><div><p>Original Score</p><p>Interrogator &gt;50%</p></div><div><p>Final Score</p><div><p><span>Interrogator 46%</span></p><a href="https://arxiv.org/pdf/2405.08007" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></div></div></div></div></div></div><div><div><div><div><h3>ARC (AI2)<span>(<!-- -->2018<!-- --> - <!-- -->2023<!-- -->)</span></h3><p><span>Reasoning</span></p></div><div><p><span>Killed by</span></p><p><span>Saturation</span></p><a href="https://arxiv.org/abs/1803.05457" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></div></div><p>Killed 1 year ago, AI2 Reasoning Challenge (ARC) - A collection of grade-school level multiple-choice reasoning tasks testing logical deduction, spatial reasoning, and temporal reasoning. Each task requires applying abstract reasoning skills to solve multi-step problems. It was 5 years old.</p><div><div><p><span>Defeated by:</span></p><!-- --><p>GPT-4</p></div><div><div><p>Original Score</p><p>Unspecifed</p></div><div><p>Final Score</p><div><p><span>GPT-4: 96.3%</span></p><a href="https://cdn.openai.com/papers/gpt-4.pdf" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></div></div></div></div></div></div><div><div><div><div><h3>HellaSwag<span>(<!-- -->2019<!-- --> - <!-- -->2023<!-- -->)</span></h3><p><span>Common Sense</span></p></div><div><p><span>Killed by</span></p><p><span>Saturation</span></p><a href="https://arxiv.org/abs/1905.07830" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></div></div><p>Killed 1 year ago, A challenging dataset of multiple-choice questions about everyday scenarios. Uses adversarial filtering to test models&#39; ability to understand and reason about real-world situations and their likely outcomes. It was 3 years and 10 months old.</p><div><div><p><span>Defeated by:</span></p><!-- --><p>GPT-4</p></div><div><div><p>Original Score</p><p>Human: 95.6%</p></div><div><p>Final Score</p><div><p><span>GPT-4: 95.3%</span></p><a href="https://cdn.openai.com/papers/gpt-4.pdf" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></div></div></div></div></div></div><div><div><div><div><h3>MMLU<span>(<!-- -->2020<!-- --> - <!-- -->2023<!-- -->)</span></h3><p><span>Knowledge</span></p></div><div><p><span>Killed by</span></p><p><span>Saturation</span></p><a href="https://arxiv.org/abs/2009.03300" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></div></div><p>Killed 1 year ago, A comprehensive benchmark covering 57 subjects including mathematics, history, law, computer science, and more. Questions are drawn from real-world sources like professional exams to test both breadth and depth of knowledge across diverse academic domains. It was 2 years and 6 months old.</p><div><div><p><span>Defeated by:</span></p><!-- --><p>GPT-4</p></div><div><div><p>Original Score</p><p>95th pct Human: 87.0%</p></div><div><p>Final Score</p><div><p><span>GPT-4: 87.3%</span></p><a href="https://cdn.openai.com/papers/gpt-4.pdf" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></div></div></div></div></div></div><div><div><div><div><h3>WinoGrande<span>(<!-- -->2019<!-- --> - <!-- -->2023<!-- -->)</span></h3><p><span>Common Sense</span></p></div><div><p><span>Killed by</span></p><p><span>Saturation</span></p><a href="https://arxiv.org/abs/1907.10641" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></div></div><p>Killed 1 year ago, An enhanced version of WSC with 44K problems testing common-sense reasoning through pronoun resolution. Uses adversarial filtering to ensure problems require real-world understanding. It was 3 years and 8 months old.</p><div><div><p><span>Defeated by:</span></p><!-- --><p>GPT-4</p></div><div><div><p>Original Score</p><p>Human: 94%</p></div><div><p>Final Score</p><div><p><span>GPT-4: 87.5%</span></p><a href="https://cdn.openai.com/papers/gpt-4.pdf" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></div></div></div></div></div></div></div></div></div><div><div data-year="2022"><div><h2>2022</h2></div><div><div><div><div><div><h3>BIG-Bench<span>(<!-- -->2021<!-- --> - <!-- -->2022<!-- -->)</span></h3><p><span>Multi-task</span></p></div><div><p><span>Killed by</span></p><div><p><span>Saturation</span></p><div><svg xmlns="http://www.w3.org/2000/svg" width="12" height="12" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="10"></circle><path d="M12 16v-4"></path><path d="M12 8h.01"></path></svg><p>BIG-Bench further faces contamination challenges as: (a) Its canary string has been reproduced by many major models (b) Its contamination has been highlighted in many papers i.e. GPT-4 technical report</p></div></div><a href="https://arxiv.org/abs/2206.04615" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></div></div><p>Killed 2 years ago, A collaborative collection of 204 tasks spanning linguistics, childhood development, math, common-sense reasoning, biology, physics, social bias, and software development. Tests diverse capabilities of language models. It was 10 months old.</p><div><div><p><span>Defeated by:</span></p><!-- --><p>Palm 540B</p></div><div><div><p>Original Score</p><p>Human: 49.8%</p></div><div><p>Final Score</p><div><p><span>Palm 540B: 61.4%</span></p><a href="https://arxiv.org/pdf/2204.02311" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="10" height="10" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></div></div></div></div></div></div></div></div></div><div><div data-year="2019"><div><h2>2019</h2></div><div><div><div><div><div><h3>SuperGLUE<span>(<!-- -->2019<!-- --> - <!-- -->2019<!-- -->)</span></h3><p><span>Language</span></p></div><div><p><span>Killed by</span></p><p><span>Saturation</span></p><a href="https://arxiv.org/abs/1905.00537" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></div></div><p>Killed 5 years ago, A collection of more challenging language understanding tasks including word sense disambiguation, causal reasoning, and reading comprehension. Designed as a more difficult successor to GLUE. It was 5 months old.</p><div><div><p><span>Defeated by:</span></p><!-- --><p>T5</p></div><div><div><p>Original Score</p><p>Human: 89.8%</p></div><div><p>Final Score</p><p><span>T5: 89.3%</span></p></div></div></div></div></div><div><div><div><div><h3>WSC<span>(<!-- -->2012<!-- --> - <!-- -->2019<!-- -->)</span></h3><p><span>Common Sense</span></p></div><div><p><span>Killed by</span></p><p><span>Saturation</span></p><a href="https://cdn.aaai.org/ocs/4492/4492-21843-1-PB.pdf" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></div></div><p>Killed 5 years ago, A collection of carefully crafted sentence pairs with ambiguous pronoun references that resolve differently based on small changes. Designed to test genuine language understanding over statistical patterns. It was 7 years and 3 months old.</p><div><div><p><span>Defeated by:</span></p><!-- --><p>ROBERTA (w SFT)</p></div><div><div><p>Original Score</p><p>Human: 96.5%</p></div><div><p>Final Score</p><p><span>ROBERTA (w SFT): 90.1%</span></p></div></div></div></div></div><div><div><div><div><h3>GLUE<span>(<!-- -->2018<!-- --> - <!-- -->2019<!-- -->)</span></h3><p><span>Language</span></p></div><div><p><span>Killed by</span></p><p><span>Saturation</span></p><a href="https://arxiv.org/abs/1804.07461" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></div></div><p>Killed 5 years ago, A collection of nine tasks for evaluating natural language understanding, including single-sentence tasks, similarity and paraphrase tasks, and inference tasks. The primary NLU benchmark before SuperGLUE. It was 1 year and 1 months old.</p><div><div><p><span>Defeated by:</span></p><!-- --><p>XLNet</p></div><div><div><p>Original Score</p><p>Human: 87.1%</p></div><div><p>Final Score</p><p><span>XLNet: 88.4%</span></p></div></div></div></div></div><div><div><div><div><h3>TriviaQA<span>(<!-- -->2017<!-- --> - <!-- -->2019<!-- -->)</span></h3><p><span>Knowledge</span></p></div><div><p><span>Killed by</span></p><p><span>Saturation</span></p><a href="https://arxiv.org/abs/1705.03551" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></div></div><p>Killed 5 years ago, A large-scale dataset of 650K question-answer-evidence triples authored by trivia enthusiasts. Requires cross-sentence reasoning and synthesis of information from multiple sources. It was 2 years and 1 months old.</p><div><div><p><span>Defeated by:</span></p><!-- --><p>SpanBERT</p></div><div><div><p>Original Score</p><p>Human: 79.7%</p></div><div><p>Final Score</p><p><span>SpanBERT: 83.6%</span></p></div></div></div></div></div><div><div><div><div><h3>SQuAD v2.0<span>(<!-- -->2018<!-- --> - <!-- -->2019<!-- -->)</span></h3><p><span>Language</span></p></div><div><p><span>Killed by</span></p><p><span>Saturation</span></p><a href="https://arxiv.org/abs/1806.03822" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></div></div><p>Killed 5 years ago, An extension of SQuAD that adds unanswerable questions. Models must both answer questions when possible and determine when no answer is supported by the passage. It was 11 months old.</p><div><div><p><span>Defeated by:</span></p><!-- --><p>BERT</p></div><div><div><p>Original Score</p><p>Human: 89.5%</p></div><div><p>Final Score</p><p><span>BERT: 89.5%</span></p></div></div></div></div></div><div><div><div><div><h3>SQuAD<span>(<!-- -->2016<!-- --> - <!-- -->2019<!-- -->)</span></h3><p><span>Language</span></p></div><div><p><span>Killed by</span></p><p><span>Saturation</span></p><a href="https://arxiv.org/abs/1606.05250" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></div></div><p>Killed 5 years ago, A reading comprehension dataset of 100,000+ questions posed by crowdworkers on Wikipedia articles. Answers must be text segments from the corresponding reading passage. It was 2 years and 10 months old.</p><div><div><p><span>Defeated by:</span></p><!-- --><p>BERT</p></div><div><div><p>Original Score</p><p>Human: 91.2%</p></div><div><p>Final Score</p><p><span>BERT: 93.2%</span></p></div></div></div></div></div></div></div></div><div><div data-year="2018"><div><h2>2018</h2></div><div><div><div><div><div><h3>SWAG<span>(<!-- -->2018<!-- --> - <!-- -->2018<!-- -->)</span></h3><p><span>Common Sense</span></p></div><div><p><span>Killed by</span></p><p><span>Saturation</span></p><a href="https://arxiv.org/abs/1808.05326" target="_blank" rel="noopener noreferrer"><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></div></div><p>Killed 6 years ago, A dataset of 113K multiple choice questions about grounded situations. Given a partial description of a situation, models must predict what happens next from 4 choices using common sense reasoning. It was 5 months old.</p><div><div><p><span>Defeated by:</span></p><!-- --><p>BERT</p></div><div><div><p>Original Score</p><p>Human: 88%</p></div><div><p>Final Score</p><p><span>BERT: 86%</span></p></div></div></div></div></div></div></div></div></div><div><div><h2>Inspiration</h2><p>This website is meant to be a bit of fun, and to help us take a look back and remember the massive amount of progress that has been made — much of which I didn&#39;t believe I&#39;d see within my lifetime.</p><p>It has also been heavily inspired by Cody Ogden&#39;s<!-- --> <a href="https://killedbygoogle.com" target="_blank" rel="noopener noreferrer">Killed by Google</a></p></div><div><h2>Understanding &#34;Saturation&#34;</h2><p>For KilledByLLM <i>&#34;Saturation&#34;</i> means a benchmark can no longer measure the frontier. While these benchmarks are still increadibly useful, valuable tools — they are no longer able to meaningfully contribute to the question of <i>&#34;Can AI do X?&#34;</i></p></div><div><h2>Data Collection Challenges</h2><div><p>This project represents a best-effort attempt to document benchmarks-of-note that have been envloped by LLMs. Proper attribution, timing and scores have been difficult to determine definitively, hence there may be some errors.</p><div><p><span>To illustrate this, let&#39;s examine &#34;Qwen-2.5-72B-instruct&#34; on MATH:</span></p><ul><li><span></span><span>From Qwen&#39;s technical report - 83.1</span></li><li><span></span><span>From Stanford&#39;s HELM - 79.0</span></li><li><span></span><span>From Huggingface&#39;s Open LLM Leaderboard - 38.7</span></li></ul><p>These scores significantly deviatiate from eachother!</p><p>Hence we take scores in the following approach:</p><p>Please raise an issue or PR if you identify any discrepancies!</p><ol><li><p>From the author&#39;s paper/ technical report/ model card</p></li><li><p>From succeeding benckmark papers <span>e.g. SQuAD 2.0 discusses SQuAD 1.1 performance</span></p></li><li><p>From third party sources <span>e.g. Stanford&#39;s HELM</span></p></li></ol></div></div><p>Found an error or have additional data? <!-- --> <a href="https://github.com/R0bk/killedbyllm" target="_blank" rel="noopener noreferrer"><span>Contribute on GitHub</span><svg xmlns="http://www.w3.org/2000/svg" width="14" height="14" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M15 3h6v6"></path><path d="M10 14 21 3"></path><path d="M18 13v6a2 2 0 0 1-2 2H5a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h6"></path></svg></a></p></div></div></div><p>P.S. The em dashes on this page were lovingly handwritten by humans.</p></div>
  </body>
</html>
