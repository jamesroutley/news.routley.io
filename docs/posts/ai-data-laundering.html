<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://waxy.org/2022/09/ai-data-laundering-how-academic-and-nonprofit-researchers-shield-tech-companies-from-accountability/">Original</a>
    <h1>AI Data Laundering</h1>
    
    <div id="readability-page-1" class="page"><article id="post-44966">

<div>
<p>Yesterday, Meta’s AI Research Team announced <a href="https://makeavideo.studio/">Make-A-Video</a>, a “state-of-the-art AI system that generates videos from text.”</p>
<figure><div>
<blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">We’re pleased to introduce Make-A-Video, our latest in <a href="https://twitter.com/hashtag/GenerativeAI?src=hash&amp;ref_src=twsrc%5Etfw">#GenerativeAI</a> research! With just a few words, this state-of-the-art AI system generates high-quality videos from text prompts.</p>— Meta AI (@MetaAI) <a href="https://twitter.com/MetaAI/status/1575495462894723072?ref_src=twsrc%5Etfw">September 29, 2022</a></blockquote>
</div></figure>
<p>Like he did for <a href="https://waxy.org/2022/08/exploring-12-million-of-the-images-used-to-train-stable-diffusions-image-generator/">the Stable Diffusion data</a>, Simon Willison created a <a href="https://simonwillison.net/2022/Sep/29/webvid/">Datasette browser</a> to explore WebVid-10M, one of the two datasets used to train the video generation model, and quickly learned that <strong>all 10.7 million video clips</strong> were scraped from Shutterstock, watermarks and all.</p>
<p>In addition to the Shutterstock clips, Meta also used 10 million video clips from <a href="https://github.com/microsoft/XPretrain/tree/main/hd-vila-100m">this 100M video dataset</a> from Microsoft Research Asia. It’s not mentioned on their GitHub, but if you dig into <a href="https://openaccess.thecvf.com/content/CVPR2022/supplemental/Xue_Advancing_High-Resolution_Video-Language_CVPR_2022_supplemental.pdf">the paper</a>, you learn that every clip came from over 3 million YouTube videos.</p>
<p>So, in addition to a massive chunk of Shutterstock’s video collection, Meta is also using millions of YouTube videos collected by Microsoft to make its text-to-video AI.</p>
<h2>Non-Commercial Use</h2>
<p>The academic researchers who compiled the Shutterstock dataset acknowledged the copyright implications in <a href="https://www.arxiv-vanity.com/papers/2104.00650/">their paper</a>, writing, “The use of data collected for this study is authorised via the Intellectual Property Office’s Exceptions to Copyright for Non-Commercial Research and Private Study.”</p>
<p>But then Meta is using those academic non-commercial datasets to train a model, presumably for future commercial use in their products. Weird, right?</p>
<p>Not really. It’s become standard practice for technology companies working with AI to commercially use datasets and models collected and trained by non-commercial research entities like universities or non-profits. </p>
<p>In some cases, they’re directly funding that research.</p>
<p>For example, many people believe that Stability AI created the popular text-to-image AI generator Stable Diffusion, but they funded its development by the <a href="https://ommer-lab.com/">Machine Vision &amp; Learning research group</a> at the Ludwig Maximilian University of Munich. In their repo for the project, the LMU researchers thank Stability AI for the “generous compute donation” that made it possible. </p>
<p>The massive image-text caption datasets used to train Stable Diffusion, Google’s Imagen, and the text-to-image component of Make-A-Video weren’t made by Stability AI either. They all came from <a href="https://laion.ai/">LAION</a>, a small nonprofit organization registered in Germany. Stability AI directly funds LAION’s compute resources, as well.</p>
<h2>Shifting Accountability</h2>
<p>Why does this matter? Outsourcing the heavy lifting of data collection and model training to non-commercial entities allows corporations to avoid accountability and potential legal liability.</p>
<p>It’s currently unclear if training deep learning models on copyrighted material is a form of infringement, but it’s a harder case to make if the data was collected and trained in a non-commercial setting. One of the four factors of the “fair use” exception in U.S. copyright law is the purpose or character of the use. In their <a href="https://www.copyright.gov/fair-use/">Fair Use Index</a>, the U.S. Copyright Office writes:</p>
<blockquote><p>“Courts look at how the party claiming fair use is using the copyrighted work, and are more likely to find that nonprofit educational and noncommercial uses are fair.”</p></blockquote>
<p>A federal court could find that the data collection and model training was infringing copyright, but because it was conducted by a university and a nonprofit, falls under fair use.</p>
<p>Meanwhile, a company like Stability AI would be free to commercialize that research in their own <a href="https://beta.dreamstudio.ai/">DreamStudio</a> product, or however else they choose, taking credit for its success to raise a <a href="https://twitter.com/kenrickcai/status/1567568427933650944">rumored $100M funding round</a> at a valuation upwards of $1 billion, while shifting any questions around privacy or copyright onto the academic/nonprofit entities they funded.</p>
<figure><div>
<blockquote data-width="550" data-dnt="true"><p lang="en" dir="ltr">Not sure if I mentione but stable diffusion is a model created and released by CompVis at University of Heidelberg.</p>— Emad (@EMostaque) <a href="https://twitter.com/EMostaque/status/1559671897834520582?ref_src=twsrc%5Etfw">August 16, 2022</a></blockquote>
</div></figure>
<p>This academic-to-commercial pipeline abstracts away ownership of data models from their practical applications, a kind of <a href="https://www.ai-lsc.ch/artificial-intelligence/data-laundering">data laundering</a> where vast amounts of information are ingested, manipulated, and frequently relicensed under an open-source license for commercial use.</p>
<h2>Unforeseen Consequences</h2>
<p>Years ago, like many people, I used to upload my photos to Flickr with a Creative Commons license that required attribution and allowed non-commercial use. Yahoo released a database of 100 million of those Creative Commons-licensed images for academic research, to help the burgeoning field of AI. Researchers at the University of Washington took 3.5 million of the Flickr photos with faces in them, over 670,000 people (including me), and released the <a href="https://exposing.ai/megaface/">MegaFace dataset</a>, part of a research competition sponsored by Google and Intel.</p>
<p>I was happy to let people remix and reuse my photos for non-commercial use with attribution, but that’s not how they were used. Instead, academic researchers took the work of millions of people, stripped it of attribution against its license terms, and redistributed it to thousands of groups, including corporations, military agencies, and law enforcement.</p>
<p>In their analysis for <a href="https://exposing.ai/">Exposing.ai</a>, Adam Harvey and Jules LaPlace summarized <a href="https://exposing.ai/megaface/">the impact of the project</a>:</p>
<blockquote><p>[The] MegaFace face recognition dataset exploited the good intentions of Flickr users and the Creative Commons license system to advance facial recognition technologies around the world by companies including Alibaba, Amazon, Google, CyberLink, IntelliVision, N-TechLab (FindFace.pro), Mitsubishi, Orion Star Technology, Philips, Samsung1, SenseTime, Sogou, Tencent, and Vision Semantics to name only a few. According to the press release from the University of Washington, “more than 300 research groups [were] working with MegaFace” as of 2016, including multiple law enforcement agencies.</p></blockquote>
<p>That dataset was used to build the facial recognition AI models that now power surveillance tech companies like <a href="https://www.nytimes.com/2020/01/18/technology/clearview-privacy-facial-recognition.html">Clearview AI</a>, in use by law enforcement agencies around the world, as well as <a href="https://www.businessinsider.com/clearview-ai-facial-recognition-us-army-cid-criminal-command-tech-2021-8">the U.S. Army</a>. The Chinese government has used it to train their surveillance systems. As the New York Times <a href="https://www.nytimes.com/2021/01/31/technology/facial-recognition-photo-tool.html">reported last year</a>:</p>
<blockquote><p>MegaFace has been downloaded more than 6,000 times by companies and government agencies around the world, according to a New York Times public records request. They included the U.S. defense contractor Northrop Grumman; In-Q-Tel, the investment arm of the Central Intelligence Agency; ByteDance, the parent company of the Chinese social media app TikTok; and the Chinese surveillance company Megvii.</p></blockquote>
<p>The University of Washington eventually <a href="http://megaface.cs.washington.edu/">decommissioned</a> the dataset and no longer distributes it. I don’t think any of those researchers, or even the people at Yahoo who decided to release the photos in the first place, ever foresaw how it would later be used. </p>
<figure><img width="1024" height="452" src="https://waxy.org/wp-content/uploads/2022/09/image-6-1024x452.png" alt="" srcset="https://waxy.org/wp-content/uploads/2022/09/image-6-1024x452.png 1024w, https://waxy.org/wp-content/uploads/2022/09/image-6-300x132.png 300w, https://waxy.org/wp-content/uploads/2022/09/image-6-768x339.png 768w, https://waxy.org/wp-content/uploads/2022/09/image-6-1536x678.png 1536w, https://waxy.org/wp-content/uploads/2022/09/image-6-800x353.png 800w, https://waxy.org/wp-content/uploads/2022/09/image-6.png 1920w" sizes="(max-width: 1024px) 100vw, 1024px"/><figcaption>408 of about 4,753,520 face images from the MegaFace face recognition training and benchmarking dataset. Visualization by <a href="https://exposing.ai/megaface/">Adam Harvey of Exposing.ai.</a></figcaption></figure>
<p>They were motivated to push AI forward and didn’t consider the possible repercussions. They could have made inclusion into the dataset opt-in, but they didn’t, probably because it would’ve been complicated and the data wouldn’t have been nearly as useful. They could have enforced the license and restricted commercial use of the dataset, but they didn’t, probably because it would have been a lot of work and probably because it would have <a href="https://www.wired.com/story/top-ai-researchers-financial-backing-big-tech/">impacted their funding</a>.</p>
<p>Asking for permission slows technological progress, but it’s hard to take back something you’ve unconditionally released into the world.</p>
<hr/>
<p>As I <a href="https://waxy.org/2022/08/opening-the-pandoras-box-of-ai-art/">wrote about last month</a>, I’m incredibly excited about these new AI art systems. The rate of progress is staggering, with three stunning announcements yesterday alone: aside from Meta’s Make-A-Video, there was also <a href="https://dreamfusion3d.github.io/">DreamFusion</a> for text-to-3D synthesis and <a href="https://phenaki.video/">Phenaki</a>, another text-to-video model capable of making long videos with prompts that change over time.</p>
<p>But I grapple with <a href="https://waxy.org/2022/08/opening-the-pandoras-box-of-ai-art/">the ethics</a> of how they were made and the lack of consent, attribution, or even an opt-out for their training data. Some are <a href="https://www.inputmag.com/culture/mat-dryhurst-holly-herndon-artists-ai-spawning-source-dall-e-midjourney">working on this</a>, but I’m skeptical: once a model is trained on something, it’s nearly impossible for it to forget. (At least <a href="https://github.com/tamlhp/awesome-machine-unlearning">for now</a>.)</p>
<p>Like with the artists, photographers, and other creators found in the <a href="https://waxy.org/2022/08/exploring-12-million-of-the-images-used-to-train-stable-diffusions-image-generator/">2.3 billion images</a> that trained Stable Diffusion, I can’t help but wonder how the creators of those 3 million YouTube videos feel about Meta using their work to train their new model.</p>
</div>
</article></div>
  </body>
</html>
