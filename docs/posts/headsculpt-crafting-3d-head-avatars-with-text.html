<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://brandonhan.uk/HeadSculpt/">Original</a>
    <h1>HeadSculpt: Crafting 3D Head Avatars with Text</h1>
    
    <div id="readability-page-1" class="page">


<section>
  <div>
    <div>
      <div>
        <div>
          
          

          
          <div>
            <p>
            <span><sup>1</sup>University of Surrey <sup>2</sup>The University of Hong Kong <sup>3</sup>
Imperial College London</span>
            </p><p>
            <span><sup>4</sup>iFlyTek-Surrey Joint Research Centre on AI <sup>5</sup>
Surrey Institute for People-Centred AI</span>
          </p></div>

          <!-- <div class="is-size-4 publication-authors">
            <span class="author-block">
              Anonymous Author(s)
            </span>
          </div> -->

          <!-- <div class="is-size-5 publication-authors">
            NeurIPS 2023 Submission
          </div> -->

          
        </div>
      </div>
    </div>
  </div>
</section>



<section>
  <div>
    <!-- Abstract. -->
    <div>
      <div>
        <h2>Abstract</h2>
        <p>
            Recently, text-guided 3D generative methods have made remarkable advancements in producing high-quality textures and geometry, capitalizing on the proliferation of large vision-language and image diffusion models. However, existing methods still struggle to create high-fidelity 3D head avatars in two aspects: (1) They rely mostly on a pre-trained text-to-image diffusion model whilst missing the necessary 3D awareness and head priors. This makes them prone to inconsistency and geometric distortions in the generated avatars. (2) They fall short in fine-grained editing. This is primarily due to the inherited limitations from the pre-trained 2D image diffusion models, which become more pronounced when it comes to 3D head avatars. In this work, we address these challenges by introducing a versatile coarse-to-fine pipeline dubbed HeadSculpt for crafting (i.e., generating and editing) 3D head avatars from textual prompts. Specifically, we first equip the diffusion model with 3D awareness by leveraging landmark-based control and a learned textual embedding representing the back view appearance of heads, enabling 3D-consistent head avatar generations. We further propose a novel identity-aware editing score distillation strategy to optimize a textured mesh with a high-resolution differentiable rendering technique. This enables identity preservation while following the editing instruction. We showcase HeadSculpt&#39;s superior fidelity and editing capabilities through comprehensive experiments and comparisons with existing methods.
          </p>
      </div>
    </div>
    <!--/ Abstract. -->

    <hr/>

    <div>
      <div>
        <h2>3D Head Avatar Generation</h2>
        <p>
            HeadSculpt can create an assortment of head avatars, including humans (both celebrities and ordinary individuals) as well as
            non-human characters like superheroes, comic/game characters, paintings, and more.
          </p>
        
      </div>
    </div>

    <hr/>

    <div>
      <div>
        <h2>3D Head Avatar Editing</h2>
        <p>
            In addition to head avatar creations, our method enables fine-grained editing, including local changes, shape/texture modifications, and style transfers.
          </p>

        

        

        

        

        
      </div>
    </div>

    <hr/>

    <div>
      <div>
        <h2>Method</h2>
        <p>
             We craft high-resolution 3D head avatars in a coarse-to-fine manner. <b>(a)</b> We optimize neural field representations for the coarse model. <b>(b)</b> We refine or edit the model using the extracted 3D mesh and apply identity-aware editing score distillation if editing is the target. <b>(c)</b> The core of our pipeline is the prior-driven score distillation, which incorporates landmark control, enhanced view-dependent prompts, and an InstructPix2Pix branch.
          </p>
        <p><img src="https://brandonhan.uk/HeadSculpt/static/img/pipeline.png"/>
      </p></div>
    </div>

    </div>
</section>





<section id="BibTeX">
  <div>
    <h2>BibTeX</h2>
    <pre><code>
      @article{han2023headsculpt,
        title={HeadSculpt: Crafting 3D Head Avatars with Text},
        author={Xiao Han and Yukang Cao and Kai Han and Xiatian Zhu and Jiankang Deng and Yi-Zhe Song and Tao Xiang and Kwan-Yee K. Wong},
        journal={arXiv preprint arXiv:2306.03038},
        year={2023}
      }
    </code></pre>
  </div>
</section>





</div>
  </body>
</html>
