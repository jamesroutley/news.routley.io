<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/gregpr07/browser-use">Original</a>
    <h1>Show HN: I wrote an open-source browser alternative for Computer Use for any LLM</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto">Let LLMs interact with websites through a simple interface.</p>

<div dir="auto" data-snippet-clipboard-copy-content="from src import Agent
from langchain_openai import ChatOpenAI

agent = Agent(
    task=&#39;Go to hackernews on show hn and give me top 10 post titels, their points and hours. Calculate for each the ratio of points per hour.&#39;,
    llm=ChatOpenAI(model=&#39;gpt-4o&#39;),
)

await agent.run()"><pre><span>from</span> <span>src</span> <span>import</span> <span>Agent</span>
<span>from</span> <span>langchain_openai</span> <span>import</span> <span>ChatOpenAI</span>

<span>agent</span> <span>=</span> <span>Agent</span>(
    <span>task</span><span>=</span><span>&#39;Go to hackernews on show hn and give me top 10 post titels, their points and hours. Calculate for each the ratio of points per hour.&#39;</span>,
    <span>llm</span><span>=</span><span>ChatOpenAI</span>(<span>model</span><span>=</span><span>&#39;gpt-4o&#39;</span>),
)

<span>await</span> <span>agent</span>.<span>run</span>()</pre></div>

<div dir="auto">
    <p><a href="https://www.loom.com/share/63612b5994164cb1bb36938d62fe9983" rel="nofollow">
      <img src="https://camo.githubusercontent.com/218a2fa2cc8d4e8780b7e24e8eb691144f6a3eea6d1f2c01eb8b83717efccb6b/68747470733a2f2f63646e2e6c6f6f6d2e636f6d2f73657373696f6e732f7468756d626e61696c732f36333631326235393934313634636231626233363933386436326665393938332d313166343761393439303631333536382d66756c6c2d706c61792e676966" data-animated-image="" data-canonical-src="https://cdn.loom.com/sessions/thumbnails/63612b5994164cb1bb36938d62fe9983-11f47a9490613568-full-play.gif"/>
    </a></p><p dir="auto"><i>Prompt: Go to hackernews on show hn and give me top 10 post titels, their points and hours. Calculate for each the ratio of points per hour. (1x speed) </i></p>
</div>
<div dir="auto">
    <p><a href="https://www.loom.com/share/2af938b9f8024647950a9e18b3946054" rel="nofollow">
      <img src="https://camo.githubusercontent.com/6fc61338132a01db3b8ad6e85bc6783a749dfa124ba2f4d0e55905761f94a5da/68747470733a2f2f63646e2e6c6f6f6d2e636f6d2f73657373696f6e732f7468756d626e61696c732f32616639333862396638303234363437393530613965313862333934363035342d623939633733336366363730653536382d66756c6c2d706c61792e676966" data-animated-image="" data-canonical-src="https://cdn.loom.com/sessions/thumbnails/2af938b9f8024647950a9e18b3946054-b99c733cf670e568-full-play.gif"/>
    </a></p><p dir="auto"><i>Prompt: Search the top 3 AI companies 2024 and find what out what concrete hardware each is using for their model. (1x speed)</i></p>
</div>
<div dir="auto">
    <div dir="auto">
        <p><a target="_blank" rel="noopener noreferrer" href="https://github.com/gregpr07/browser-use/blob/main/static/kayak.gif"><img src="https://github.com/gregpr07/browser-use/raw/main/static/kayak.gif" alt="Kayak flight search demo" data-animated-image=""/></a></p><p dir="auto"><i>Prompt: Go to kayak.com and find a one-way flight from ZÃ¼rich to San Francisco on 12 January 2025. (2.5x speed)</i></p>
    </div>
    <div dir="auto">
        <p><a target="_blank" rel="noopener noreferrer" href="https://github.com/gregpr07/browser-use/blob/main/static/photos.gif"><img src="https://github.com/gregpr07/browser-use/raw/main/static/photos.gif" alt="Photos search demo" data-animated-image=""/></a></p><p dir="auto"><i>Prompt: Opening new tabs and searching for images for these people: Albert Einstein, Oprah Winfrey, Steve Jobs. (2.5x speed)</i></p>
    </div>
</div>


<ol dir="auto">
<li>Create a virtual environment and install dependencies:</li>
</ol>
<div dir="auto" data-snippet-clipboard-copy-content="# I recommend using uv
pip install -r requirements.txt"><pre><span><span>#</span> I recommend using uv</span>
pip install -r requirements.txt</pre></div>
<ol start="2" dir="auto">
<li>Add your API keys to the <code>.env</code> file:</li>
</ol>

<p dir="auto">You can use any LLM model supported by LangChain by adding the appropriate environment variables. See <a href="https://python.langchain.com/docs/integrations/chat/" rel="nofollow">langchain models</a> for available options.</p>

<ul dir="auto">
<li>Universal LLM Support - Works with any Language Model</li>
<li>Interactive Element Detection - Automatically finds interactive elements</li>
<li>Multi-Tab Management - Seamless handling of browser tabs</li>
<li>XPath Extraction for scraping functions - No more manual DevTools inspection</li>
<li>Vision Model Support - Process visual page information</li>
<li>Customizable Actions - Add your own browser interactions (e.g. add data to database which the LLM can use)</li>
<li>Handles dynamic content - dont worry about cookies or changing content</li>
<li>Chain-of-thought prompting with memory - Solve long-term tasks</li>
<li>Self-correcting - If the LLM makes a mistake, the agent will self-correct its actions</li>
</ul>


<p dir="auto">You can persist the browser across multiple agents and chain them together.</p>
<div dir="auto" data-snippet-clipboard-copy-content="from langchain_anthropic import ChatAnthropic
from src import Agent, Controller

# Persist browser state across agents
controller = Controller()

# Initialize browser agent
agent1 = Agent(
	task=&#39;Open 5 VCs websites in the New York area.&#39;,
	llm=ChatAnthropic(model_name=&#39;claude-3-sonnet&#39;, timeout=25, stop=None, temperature=0.3),
	controller=controller,
)
agent2 = Agent(
	task=&#39;Give me the names of the founders of the companies in all tabs.&#39;,
	llm=ChatAnthropic(model_name=&#39;claude-3-sonnet&#39;, timeout=25, stop=None, temperature=0.3),
	controller=controller,
)

await agent1.run()
founders, history = await agent2.run()

print(founders)"><pre><span>from</span> <span>langchain_anthropic</span> <span>import</span> <span>ChatAnthropic</span>
<span>from</span> <span>src</span> <span>import</span> <span>Agent</span>, <span>Controller</span>

<span># Persist browser state across agents</span>
<span>controller</span> <span>=</span> <span>Controller</span>()

<span># Initialize browser agent</span>
<span>agent1</span> <span>=</span> <span>Agent</span>(
	<span>task</span><span>=</span><span>&#39;Open 5 VCs websites in the New York area.&#39;</span>,
	<span>llm</span><span>=</span><span>ChatAnthropic</span>(<span>model_name</span><span>=</span><span>&#39;claude-3-sonnet&#39;</span>, <span>timeout</span><span>=</span><span>25</span>, <span>stop</span><span>=</span><span>None</span>, <span>temperature</span><span>=</span><span>0.3</span>),
	<span>controller</span><span>=</span><span>controller</span>,
)
<span>agent2</span> <span>=</span> <span>Agent</span>(
	<span>task</span><span>=</span><span>&#39;Give me the names of the founders of the companies in all tabs.&#39;</span>,
	<span>llm</span><span>=</span><span>ChatAnthropic</span>(<span>model_name</span><span>=</span><span>&#39;claude-3-sonnet&#39;</span>, <span>timeout</span><span>=</span><span>25</span>, <span>stop</span><span>=</span><span>None</span>, <span>temperature</span><span>=</span><span>0.3</span>),
	<span>controller</span><span>=</span><span>controller</span>,
)

<span>await</span> <span>agent1</span>.<span>run</span>()
<span>founders</span>, <span>history</span> <span>=</span> <span>await</span> <span>agent2</span>.<span>run</span>()

<span>print</span>(<span>founders</span>)</pre></div>
<p dir="auto">You can use the <code>history</code> to run the agents again deterministically.</p>

<p dir="auto">Run examples directly from the command line:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python examples/try.py &#34;Your query here&#34; --provider [openai|anthropic]"><pre>python examples/try.py <span><span>&#34;</span>Your query here<span>&#34;</span></span> --provider [openai<span>|</span>anthropic]</pre></div>

<p dir="auto">You need to add <code>ANTHROPIC_API_KEY</code> to your environment variables. Example usage:</p>
<div dir="auto" data-snippet-clipboard-copy-content="
python examples/try.py &#34;Search the top 3 AI companies 2024 and find out in 3 new tabs what hardware each is using for their models&#34; --provider anthropic"><pre>python examples/try.py <span><span>&#34;</span>Search the top 3 AI companies 2024 and find out in 3 new tabs what hardware each is using for their models<span>&#34;</span></span> --provider anthropic</pre></div>

<p dir="auto">You need to add <code>OPENAI_API_KEY</code> to your environment variables. Example usage:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python examples/try.py &#34;Go to hackernews on show hn and give me top 10 post titels, their points and hours. Calculate for each the ratio of points per hour. &#34; --provider anthropic"><pre>python examples/try.py <span><span>&#34;</span>Go to hackernews on show hn and give me top 10 post titels, their points and hours. Calculate for each the ratio of points per hour. <span>&#34;</span></span> --provider anthropic</pre></div>

<p dir="auto">All LangChain chat models are supported. Tested with:</p>
<ul dir="auto">
<li>GPT-4o</li>
<li>GPT-4o Mini</li>
<li>Claude 3.5 Sonnet</li>
<li>LLama 3.1 405B</li>
</ul>

<ul dir="auto">
<li>When extracting page content, the message length increases and the LLM gets slower.</li>
<li>Currently one agent costs about 0.01$</li>
<li>Sometimes it tries to repeat the same task over and over again.</li>
<li>Some elements might not be extracted which you want to interact with.</li>
<li>What should we focus on the most?
<ul dir="auto">
<li>Robustness</li>
<li>Speed</li>
<li>Cost reduction</li>
</ul>
</li>
</ul>

<ul>
<li> Save agent actions and execute them deterministically</li>
<li> Pydantic forced output</li>
<li> Third party SERP API for faster Google Search results</li>
<li> Multi-step action execution to increase speed</li>
<li> Test on mind2web dataset</li>
<li> Add more browser actions</li>
</ul>

<p dir="auto">Contributions are welcome! Feel free to open issues for bugs or feature requests.</p>
<hr/>
<div dir="auto">
  <p><b>Star â­ this repo if you find it useful!</b></p></div>
</article></div></div>
  </body>
</html>
