<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://jakearchibald.com/2024/video-with-transparency/">Original</a>
    <h1>Video with Alpha Transparency on the Web</h1>
    
    <div id="readability-page-1" class="page"><div><p>I&#39;ve been helping some teams at Shopify improve page load performance, and the issue of &#39;videos with an alpha channel&#39; kept coming up, where videos of UI mocks needed to be composited on top of inconsistent backgrounds, such as larger CSS backgrounds.</p>
<p>Often a good solution here is to create the animation using web technologies, but sometimes video is a better solution for consistent frame rates, and allows for effects like motion blur which don&#39;t currently exist on the web.</p>


<figure>
<stacked-alpha-video>
  <video autoplay="" crossorigin="" muted="" playsinline="" loop="">
    <source src="/c/split-av1-86bc6e48.mp4" type="video/mp4; codecs=av01.0.08M.08.0.110.01.01.01.1"/>
    <source src="/c/split-hevc-9103f51b.mp4" type="video/mp4; codecs=hvc1.1.6.H120.b0"/>
  </video>
</stacked-alpha-video>
<figcaption>A Shopify UI video with transparency (click to pause)</figcaption>
</figure>



<p>I didn&#39;t know much about it, so I dug in to try and find the most robust and efficient way to do it. I thought it was going to be a nice little I-can-do-this-while-jetlagged hackday project, but it&#39;s way more complicated than I thought. It turns out, the &#39;native&#39; ways of doing it are inefficient and buggy. If you handle the transparency yourself, you avoid these bugs, and serve a file that&#39;s half the size, or less.</p>
<p>If you just want the solution, <a href="https://www.npmjs.com/package/stacked-alpha-video">here&#39;s <code>&lt;stacked-alpha-video&gt;</code></a>, an NPM package to handle the playback of these videos.</p>
<p>Otherwise, here&#39;s what I discovered, and the many bugs I filed along the way.</p>
<h2 id="native-support-for-transparency-in-web-compatible-video-formats"><a href="#native-support-for-transparency-in-web-compatible-video-formats">Native support for transparency in web-compatible video formats</a></h2>
<p>Web-friendly video formats have supported transparency for 15 years. So by now it&#39;d be well-supported and easy to use, right? Right?</p>
<p>Right?</p>
<h3 id="avif-aint-it"><a href="#avif-aint-it">AVIF ain&#39;t it</a></h3>
<p>AV1 is a great video format in terms of the compression ratio, and the encoder is great for a variety of content. However, surprisingly, it doesn&#39;t support transparency.</p>
<p>AVIF is an image format built from AV1. AVIF <em>does</em> support transparency. Also, &#39;animated AVIF&#39; is a thing. It&#39;s stored as two AV1 streams, where the additional stream is a luma-only (black &amp; white) video representing the alpha channel.</p>
<p>Taking the example at the top of this post, I can get the size down to 504 kB with acceptable loss.</p>
<p>Here&#39;s a demo, butâ€¦ don&#39;t get your hopes up:</p>






<p>Given that <a href="https://caniuse.com/avif">AVIF is well supported</a>, it sounds like the ideal solution. Butâ€¦</p>
<h4 id="it-doesnt-work-in-safari"><a href="#it-doesnt-work-in-safari">It doesn&#39;t work in Safari</a></h4>
<p>Although Safari supports AVIF, and supports transparency in AVIF, it doesn&#39;t correctly support transparency in an animated AVIF. It looks a real mess, and its horrendously slow.</p>
<p><a href="https://bugs.webkit.org/show_bug.cgi?id=275906">Bug report</a>.</p>
<h4 id="the-performance-is-prohibitively-bad"><a href="#the-performance-is-prohibitively-bad">The performance is prohibitively bad</a></h4>
<p>Chrome and Firefox render the AVIF correctly, but it struggles to hit 60fps even on an ultra high-end laptop. On Android, it struggles to hit even a few frames per second.</p>
<ul>
<li><a href="https://issues.chromium.org/issues/349566435">Chrome bug report</a>.</li>
<li><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1909646">Firefox bug report</a>.</li>
</ul>
<h4 id="streaming-is-poor"><a href="#streaming-is-poor">Streaming is poor</a></h4>
<p>When playing content back via <code>&lt;video&gt;</code>, browsers will delay starting playback until it thinks enough is buffered for uninterrupted playback. However, because this is <code>&lt;img&gt;</code> rather than <code>&lt;video&gt;</code>, Chrome will just display frames as soon as it has the data, making playback really choppy on slower connections.</p>
<p>This is really becauseâ€¦</p>
<h4 id="animated-image-formats-are-a-hack"><a href="#animated-image-formats-are-a-hack">Animated image formats are a hack</a></h4>
<p>Im my opinion, animated AVIF doesn&#39;t make sense in a world where AV1 video exists. Even if all the above bugs were fixed, you&#39;d still be unable to:</p>
<ul>
<li>Show browser video playback controls.</li>
<li>Programmatically pause/resume playback, e.g. for accessibility reasons.</li>
<li>Fallback to an alternative video format via <code>&lt;source&gt;</code>.</li>
<li>Include audio.</li>
</ul>
<p>There are benefits to being able to include animated content in an <code>&lt;img&gt;</code>, especially in contexts like forums that support <code>&lt;img&gt;</code> but not <code>&lt;video&gt;</code>. The good news is, Safari solved this back in 2018:</p>
<div><pre><code><span><span><span>&lt;</span>img</span> <span>src</span><span><span>=</span><span>&#34;</span>whatever.mp4<span>&#34;</span></span> <span>alt</span><span><span>=</span><span>&#34;</span>â€¦<span>&#34;</span></span> <span>/&gt;</span></span></code></pre></div><p>The above just works in Safari. You can even use videos as image content in CSS. The bad news is, <a href="https://issues.chromium.org/issues/41359195">Chrome isn&#39;t interested in supporting this</a>. Booooooooo.</p>
<h4 id="encoding-animated-avif"><a href="#encoding-animated-avif">Encoding animated AVIF</a></h4>
<p>For completeness: here&#39;s how to create an animated AVIF using <a href="https://ffmpeg.org/">ffmpeg</a>:</p>
<div><pre><code><span>INPUT</span><span>=</span><span>&#34;in.mov&#34;</span> <span>OUTPUT</span><span>=</span><span>&#34;out.avif&#34;</span> <span>CRF</span><span>=</span><span>45</span> <span>CRFA</span><span>=</span><span>60</span> <span>CPU</span><span>=</span><span>3</span> <span>bash</span> <span>-c</span> <span>&#39;ffmpeg -y -i &#34;$INPUT&#34; -color_range tv -pix_fmt:0 yuv420p -pix_fmt:1 gray8 -filter_complex &#34;[0:v]format=pix_fmts=yuva444p[main]; [main]split[main][alpha]; [alpha]alphaextract[alpha]&#34; -map &#34;[main]:v&#34; -map &#34;[alpha]:v&#34; -an -c:v libaom-av1 -cpu-used &#34;$CPU&#34; -crf &#34;$CRF&#34; -crf:1 &#34;$CRFA&#34; -pass 1 -f null /dev/null &amp;&amp; ffmpeg -y -i &#34;$INPUT&#34; -color_range tv -pix_fmt:0 yuv420p -pix_fmt:1 gray8 -filter_complex &#34;[0:v]format=pix_fmts=yuva444p[main]; [main]split[main][alpha]; [alpha]alphaextract[alpha]&#34; -map &#34;[main]:v&#34; -map &#34;[alpha]:v&#34; -an -c:v libaom-av1 -cpu-used &#34;$CPU&#34; -crf &#34;$CRF&#34; -crf:1 &#34;$CRFA&#34; -pass 2 &#34;$OUTPUT&#34;&#39;</span></code></pre></div><ul>
<li><code>CRF</code> (0-63): Lower values are higher quality, larger filesize.</li>
<li><code>CRFA</code> (0-63): Like <code>CRF</code>, but for the alpha channel.</li>
<li><code>CPU</code> (0-8): Weirdly, <em>lower</em> values use more CPU, which improves quality, but encodes much slower. I wouldn&#39;t go lower than 3.</li>
</ul>
<h3 id="vp9--hevc-somewhat-works"><a href="#vp9--hevc-somewhat-works">VP9 + HEVC somewhat works</a></h3>
<p>This solution isn&#39;t ideal, and definitely isn&#39;t the most efficient, but it&#39;s the best we&#39;ve got when it comes to native support, meaning it works without JavaScript:</p>
<figure>
<video controls="" autoplay="" crossorigin="" muted="" playsinline="" loop="">
  <source type="video/quicktime; codecs=hvc1.1.6.H120.b0" src="/c/hevc-00087707.mov"/>
  <source type="video/webm; codecs=vp09.00.41.08" src="/c/vp9-b9979ea8.webm"/>
</video>
<figcaption>A reasonable solution that doesn&#39;t need JavaScript</figcaption>
</figure>

<p>This is 1.1 MB in Chrome &amp; Firefox via the VP9 codec, and 3.4 MB in Safari via the HEVC codec. The VP9 is double the size of the AVIF, which shows the generational gap between the codecs.</p>
<div><pre><code><span><span><span>&lt;</span>video</span> <span>playsinline</span> <span>muted</span> <span>autoplay</span> <span>loop</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>source</span> <span>type</span><span><span>=</span><span>&#34;</span>video/quicktime; codecs=hvc1.1.6.H120.b0<span>&#34;</span></span> <span>src</span><span><span>=</span><span>&#34;</span>video.mov<span>&#34;</span></span> <span>/&gt;</span></span>
  <span><span><span>&lt;</span>source</span> <span>type</span><span><span>=</span><span>&#34;</span>video/webm; codecs=vp09.00.41.08<span>&#34;</span></span> <span>src</span><span><span>=</span><span>&#34;</span>video.webm<span>&#34;</span></span> <span>/&gt;</span></span>
<span><span><span>&lt;/</span>video</span><span>&gt;</span></span></code></pre></div><p>The HEVC must appear first. Safari supports VP9, but it doesn&#39;t support VP9 with transparency (<a href="https://bugs.webkit.org/show_bug.cgi?id=275908">bug report</a>), so we need to &#39;encourage&#39; Safari to pick the HEVC file over the VP9.</p>
<p>I&#39;m a little worried that a non-Apple device will try to play the HEVC file, but not support transparency (after all, it&#39;s an <a href="https://developer.apple.com/av-foundation/HEVC-Video-with-Alpha-Interoperability-Profile.pdf">Apple extension to the format (pdf)</a>), resulting in broken output. However, I haven&#39;t seen this happen yet.</p>
<p>Also, there are a couple of bugs to be aware of:</p>
<ul>
<li><a href="https://issues.chromium.org/issues/349610465">Chrome Android gets the alpha channel wrong</a>. Depending on how much transparency you use, it might not matter too much. This has been fixed in Canary, but at time of writing, it hasn&#39;t reached stable.</li>
<li><a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1905878">Playback often stalls on Firefox for Android</a>.</li>
</ul>
<h4 id="encoding-vp9"><a href="#encoding-vp9">Encoding VP9</a></h4>
<p>With <a href="https://ffmpeg.org/">ffmpeg</a>:</p>
<div><pre><code><span>INPUT</span><span>=</span><span>&#34;in.mov&#34;</span> <span>OUTPUT</span><span>=</span><span>&#34;out.webm&#34;</span> <span>CRF</span><span>=</span><span>45</span> <span>EFFORT</span><span>=</span><span>&#34;good&#34;</span> <span>bash</span> <span>-c</span> <span>&#39;ffmpeg -y -i &#34;$INPUT&#34; -pix_fmt yuva420p -an -c:v libvpx-vp9 -crf &#34;$CRF&#34; -b:v 0 -deadline &#34;$EFFORT&#34; -threads 4 -lag-in-frames 25 -row-mt 1 -pass 1 -f null /dev/null &amp;&amp; ffmpeg -y -i &#34;$INPUT&#34; -pix_fmt yuva420p -an -c:v libvpx-vp9 -crf &#34;$CRF&#34; -b:v 0 -deadline &#34;$EFFORT&#34; -threads 4 -lag-in-frames 25 -row-mt 1 -pass 2 &#34;$OUTPUT&#34;&#39;</span></code></pre></div><ul>
<li><code>CRF</code> (0-63): Lower values are higher quality, larger filesize.</li>
<li><code>EFFORT</code> (<code>best</code> or <code>good</code>): <code>good</code> is faster, but slightly lower quality.</li>
</ul>
<h4 id="encoding-hevc"><a href="#encoding-hevc">Encoding HEVC</a></h4>
<p>This is the format you need for Apple devices, so it might not surprise you to hear that you can only encode it on MacOS.</p>
<p>In addition, you really need to fork out Â£50 or whatever for <a href="https://www.apple.com/uk/final-cut-pro/compressor/">Apple&#39;s Compressor</a>.</p>
<p>But even then, the results aren&#39;t great. I don&#39;t think Apple&#39;s Compressor is designed with this kind of content in mind, so you usually end up with a much larger file size than the equivalent VP9.</p>
<p><a href="https://youtu.be/Js4fNuOh1Ac">Here&#39;s a quick video guide to using the Compressor app to encode video with an alpha channel</a>.</p>
<p>If, after forking out Â£Â£Â£ for an Apple device, you really really really don&#39;t want to spend Â£50 on Compressor, you can encode a kinda shitty version using <a href="https://ffmpeg.org/">ffmpeg</a>. Note: this only works on MacOS, as it calls out to the built-in codec.</p>
<div><pre><code>ffmpeg <span>-i</span> in.mov <span>-c:v</span> hevc_videotoolbox <span>-require_sw</span> <span>1</span> <span>-alpha_quality</span> <span>0.1</span> <span>-tag:v</span> hvc1 <span>-q:v</span> <span>35</span> <span>-vf</span> <span>&#34;premultiply=inplace=1&#34;</span> out.mov</code></pre></div><ul>
<li><code>-q:v</code> (0-100): Quality, where 100 is the highest quality with largest file size.</li>
<li><code>-alpha_quality</code> (0-1): Separate control of the alpha channel quality.</li>
</ul>
<p>The reason this method is worse is because, for whatever reason, it uses the BGRA pixel format. This means the red, green, and blue channels are stored separately. This isn&#39;t very efficient. Video formats tend to use YUV, where brightness (Y) is stored separate to colour (UV). Human eyes are more sensitive to brightness than colour, so this separation means more bits can be spent on the brightness data vs the colour. I&#39;ve <a href="https://trac.ffmpeg.org/ticket/11068">filed a bug to see if this can be fixed</a>. In the meantime, this method will yield around double the file size compared the already-not-great Compressor result.</p>
<p>There&#39;s <a href="https://bitbucket.org/multicoreware/x265_git/issues/577/support-for-alpha-transparency-per-apple">a feature request for the open source &amp; cross-platform x265 codec to support transparency</a>, but it doesn&#39;t seem to be going anywhere.</p>
<h2 id="doing-it-manually"><a href="#doing-it-manually">Doing it manually</a></h2>
<p>AV1 is the most efficient codec we have in browsers, but it doesn&#39;t support transparency. When it&#39;s in an AVIF container, it does, but the performance is prohibitively bad.</p>
<p>So, I thought, what if I split the video in two, making it double height, where the top half is the video without the alpha channel, and the bottom half is the alpha channel represented as brightness?</p>
<figure>
  <video controls="" autoplay="" crossorigin="" muted="" playsinline="" loop="">
    <source src="/c/split-av1-86bc6e48.mp4" type="video/mp4; codecs=av01.0.08M.08.0.110.01.01.01.1"/>
    <source src="/c/split-hevc-9103f51b.mp4" type="video/mp4; codecs=hvc1.1.6.H120.b0"/>
  </video>
<figcaption>Top half: colour data. Bottom half: alpha data.</figcaption>
</figure>

<p>Then, a WebGL fragment shader can be used to efficiently apply the bottom half as a mask to the top half:</p>
<div><pre><code>
<span>uniform</span> <span>sampler2D</span> u_frame<span>;</span>


<span>varying</span> <span>vec2</span> v_texCoord<span>;</span>

<span>void</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
  
  <span>vec2</span> colorCoord <span>=</span> <span>vec2</span><span>(</span>v_texCoord<span>.</span>x<span>,</span> v_texCoord<span>.</span>y <span>*</span> <span>0.5</span><span>)</span><span>;</span>
  
  <span>vec2</span> alphaCoord <span>=</span> <span>vec2</span><span>(</span>v_texCoord<span>.</span>x<span>,</span> <span>0.5</span> <span>+</span> v_texCoord<span>.</span>y <span>*</span> <span>0.5</span><span>)</span><span>;</span>

  
  <span>vec4</span> color <span>=</span> <span>texture2D</span><span>(</span>u_frame<span>,</span> colorCoord<span>)</span><span>;</span>
  <span>float</span> alpha <span>=</span> <span>texture2D</span><span>(</span>u_frame<span>,</span> alphaCoord<span>)</span><span>.</span>r<span>;</span>

  
  gl_FragColor <span>=</span> <span>vec4</span><span>(</span>color<span>.</span>rgb<span>,</span> alpha<span>)</span><span>;</span>
<span>}</span></code></pre></div><p>And here it is:</p>
<figure>
<stacked-alpha-video>
  <video autoplay="" crossorigin="" muted="" playsinline="" loop="">
    <source src="/c/split-av1-86bc6e48.mp4" type="video/mp4; codecs=av01.0.08M.08.0.110.01.01.01.1"/>
    <source src="/c/split-hevc-9103f51b.mp4" type="video/mp4; codecs=hvc1.1.6.H120.b0"/>
  </video>
</stacked-alpha-video>
<figcaption>A Shopify UI video with transparency (click to pause)</figcaption>
</figure>



<p>For Chrome, Firefox, and Safari on a iPhone 15 Pro or M3 MacBook Pro, this is 460 kB. A huge reduction compared to 1.1 or 3.4 MB for the native version.</p>
<p>Other Apple devices don&#39;t support AV1, so they need an HEVC version at 1.14 MB, which isn&#39;t as good, but still a lot smaller than the 3.4 MB version they&#39;d get for the native version.</p>
<p>The 460 kB AV1 version is even significantly smaller than the 504 kB AVIF. I&#39;m not really sure why. With the AVIF, I encoded with the exact same settings - I even encoded the alpha data lower quality in the AVIF, so in theory it should be at an advantage. I guess the AVIF has overhead by being two separate video streams, whereas the stacked version is one video.</p>
<h3 id="wrapping-it-up-in-a-web-component"><a href="#wrapping-it-up-in-a-web-component">Wrapping it up in a web component</a></h3>
<p>I&#39;ve <a href="https://www.npmjs.com/package/stacked-alpha-video">published a little web component to handle the rendering</a>:</p>
<div><pre><code><span><span><span>&lt;</span>stacked-alpha-video</span><span>&gt;</span></span>
  <span><span><span>&lt;</span>video</span> <span>autoplay</span> <span>crossorigin</span> <span>muted</span> <span>playsinline</span> <span>loop</span><span>&gt;</span></span>
    <span><span><span>&lt;</span>source</span>
      <span>src</span><span><span>=</span><span>&#34;</span>av1.mp4<span>&#34;</span></span>
      <span>type</span><span><span>=</span><span>&#34;</span>video/mp4; codecs=av01.0.08M.08.0.110.01.01.01.1<span>&#34;</span></span>
    <span>/&gt;</span></span>
    <span><span><span>&lt;</span>source</span> <span>src</span><span><span>=</span><span>&#34;</span>hevc.mp4<span>&#34;</span></span> <span>type</span><span><span>=</span><span>&#34;</span>video/mp4; codecs=hvc1.1.6.H120.b0<span>&#34;</span></span> <span>/&gt;</span></span>
  <span><span><span>&lt;/</span>video</span><span>&gt;</span></span>
<span><span><span>&lt;/</span>stacked-alpha-video</span><span>&gt;</span></span></code></pre></div><p>You control playback via the <code>&lt;video&gt;</code>, so you&#39;re in full control over how the video is fetched, and it can also start fetching before JS loads. The web component just handles the rendering.</p>
<p><a href="https://offthemainthread.tech/episode/are-web-components-worth-it/">I&#39;m far from a web component absolutist</a>, but it seemed like the perfect choice here to make the component useable across frameworks, or without a framework.</p>
<p><a href="https://www.npmjs.com/package/stacked-alpha-video">It&#39;s available on NPM</a>, but <a href="https://github.com/jakearchibald/stacked-alpha-video?tab=readme-ov-file#dont-want-to-use-a-web-component">I also export the internals</a>, so you can access the WebGL bits without going via the web component.</p>
<p>The one thing I think it&#39;s missing is being able to use the native <code>&lt;video&gt;</code> controls, so I <a href="https://github.com/whatwg/html/issues/10507">filed an issue for that too</a>.</p>
<h3 id="encoding-the-video"><a href="#encoding-the-video">Encoding the video</a></h3>
<p>Again, ffmpeg is the tool for the job. Here&#39;s the filter:</p>
<div><pre><code><span>-filter_complex</span> <span>&#34;[0:v]format=pix_fmts=yuva444p[main]; [main]split[main][alpha]; [alpha]alphaextract[alpha]; [main][alpha]vstack&#34;</span></code></pre></div><p>Breaking it up step by step:</p>
<ol>
<li><code>[0:v]format=pix_fmts=yuva444p[main]</code> convert to a predictable format.</li>
<li><code>[main]split[main][alpha]</code> fork the output.</li>
<li><code>[alpha]alphaextract[alpha]</code> with the &#39;alpha&#39; fork, pull the alpha data out to luma data, creating a black &amp; white view of the transparency.</li>
<li><code>[main][alpha]vstack</code> stack the &#39;main&#39; and &#39;alpha&#39; forks on top of each other.</li>
</ol>
<h4 id="encoding-av1"><a href="#encoding-av1">Encoding AV1</a></h4>
<p>This is the ideal format:</p>
<div><pre><code><span>INPUT</span><span>=</span><span>&#34;in.mov&#34;</span> <span>OUTPUT</span><span>=</span><span>&#34;av1.mp4&#34;</span> <span>CRF</span><span>=</span><span>45</span> <span>CPU</span><span>=</span><span>3</span> <span>bash</span> <span>-c</span> <span>&#39;ffmpeg -y -i &#34;$INPUT&#34; -filter_complex &#34;[0:v]format=pix_fmts=yuva444p[main]; [main]split[main][alpha]; [alpha]alphaextract[alpha]; [main][alpha]vstack&#34; -pix_fmt yuv420p -an -c:v libaom-av1 -cpu-used &#34;$CPU&#34; -crf &#34;$CRF&#34; -pass 1 -f null /dev/null &amp;&amp; ffmpeg -y -i &#34;$INPUT&#34; -filter_complex &#34;[0:v]format=pix_fmts=yuva444p[main]; [main]split[main][alpha]; [alpha]alphaextract[alpha]; [main][alpha]vstack&#34; -pix_fmt yuv420p -an -c:v libaom-av1 -cpu-used &#34;$CPU&#34; -crf &#34;$CRF&#34; -pass 2 -movflags +faststart &#34;$OUTPUT&#34;&#39;</span></code></pre></div><ul>
<li><code>CRF</code> (0-63): Lower values are higher quality, larger filesize.</li>
<li><code>CPU</code> (0-8): Weirdly, <em>lower</em> values use more CPU, which improves quality, but encodes much slower. I wouldn&#39;t go lower than 3.</li>
</ul>
<h4 id="encoding-hevc-1"><a href="#encoding-hevc-1">Encoding HEVC</a></h4>
<p>Safari on Apple devices will use the AV1 if they have a hardware decoder (iPhone 15 Pro, M3 MacBook Pro), otherwise they need an HEVC alternative. But, since we don&#39;t need native transparency support, we can use the open source &amp; cross-platform x265 codec:</p>
<div><pre><code><span>INPUT</span><span>=</span><span>&#34;in.mov&#34;</span> <span>OUTPUT</span><span>=</span><span>&#34;hevc.mp4&#34;</span> <span>CRF</span><span>=</span><span>30</span> <span>PRESET</span><span>=</span><span>&#34;veryslow&#34;</span> <span>bash</span> <span>-c</span> <span>&#39;ffmpeg -y -i &#34;$INPUT&#34; -filter_complex &#34;[0:v]format=pix_fmts=yuva444p[main]; [main]split[main][alpha]; [alpha]alphaextract[alpha]; [main][alpha]vstack&#34; -pix_fmt yuv420p -an -c:v libx265 -preset &#34;$PRESET&#34; -crf &#34;$CRF&#34; -tag:v hvc1 -movflags +faststart &#34;$OUTPUT&#34;&#39;</span></code></pre></div><ul>
<li><code>CRF</code> (0-63): Lower values are higher quality, larger filesize.</li>
<li><code>PRESET</code> (<code>medium</code>, <code>slow</code>, <code>slower</code>, <code>veryslow</code>): The slower you go, the better the output.</li>
</ul>
<p>I find I have to go with a much lower CRF than with the AV1.</p>
<h2 id="aside-limited-range"><a href="#aside-limited-range">Aside: limited range</a></h2>
<p>The ffmpeg examples I&#39;ve given here result in the videos being encoded in &#39;limited range&#39;. This uses 16-235 rather than the full 8bit 0-255. This &#39;feature&#39; exists due to old CRT TVs which would suffer from signal overshooting. Unfortunately, it still hangs around as a kind of default, even to the degree where <a href="https://issues.chromium.org/issues/354454801">Chrome has bugs when handling the full range</a>.</p>
<p>8bit is pretty minimal when it comes to gradients, so this ~15% reduction can result in banding. If this is a problem, you can try encoding to one of the 10bit pixel formats by swapping out <code>format=pix_fmts=yuva444p</code> for <code>format=pix_fmts=yuva444p10le</code>, and changing the <code>pix_fmt</code> to <code>yuv444p10le</code>. I&#39;ll leave that for you to figure out ðŸ˜€</p>
</div></div>
  </body>
</html>
