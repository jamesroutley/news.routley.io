<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://news.ycombinator.com/item?id=31883373">Original</a>
    <h1>Ask HN: GPT-3 reveals my full name â€“ can I do anything?</h1>
    
    <div id="readability-page-1" class="page"><div>Alternatively: What&#39;s the current status of Personally Identifying Information and language models?<p>I try to hide my real name whenever possible, out of an abundance of caution. You can still find it if you search carefully, but in today&#39;s hostile internet I see this kind of soft pseudonymity as my digital personal space, and expect to have it respected.</p><p>When playing around in GPT-3 I tried making sentences with my username. Imagine my surprise when I see it spitting out my (globally unique, unusual) full name!</p><p>Looking around, I found a paper that says language models spitting out personal information is a problem[1], a Google blog post that says there&#39;s not much that can be done[2], and an article that says OpenAI might automatically replace phone numbers in the future but other types of PII are harder to remove[3]. But nothing on what is <i>actually</i> being done.</p><p>If I had found my personal information on Google search results, or Facebook, I could ask the information to be removed, but GPT-3 seems to have no such support. Are we supposed to accept that large language models may reveal private information, with no recourse?</p><p>I don&#39;t care much about my <i>name</i> being public, but I don&#39;t know what else it might have memorized (political affiliations? Sexual preferences? Posts from 13-year old me?). In the age of GDPR this feels like an enormous regression in privacy.</p><p>EDIT: a small thank you for everybody commenting so far for not directly linking to specific results or actually writing my name, however easy it might be.</p><p>If my request for pseudonymity sounds strange given my lax infosec:</p><p>- I&#39;m more worried about the consequences of language models in general than my own case, and</p><p>- people have done a lot more for a lot less name information[4].</p><p>[1]: <a href="https://arxiv.org/abs/2012.07805" rel="nofollow">https://arxiv.org/abs/2012.07805</a></p><p>[2]: <a href="https://ai.googleblog.com/2020/12/privacy-considerations-in-large.html" rel="nofollow">https://ai.googleblog.com/2020/12/privacy-considerations-in-...</a></p><p>[3]: <a href="https://www.theregister.com/2021/03/18/openai_gpt3_data/" rel="nofollow">https://www.theregister.com/2021/03/18/openai_gpt3_data/</a></p><p>[4]: <a href="https://en.wikipedia.org/wiki/Slate_Star_Codex#New_York_Times_controversy" rel="nofollow">https://en.wikipedia.org/wiki/Slate_Star_Codex#New_York_Time...</a></p></div></div>
  </body>
</html>
