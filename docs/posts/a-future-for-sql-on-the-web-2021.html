<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://jlongster.com/future-sql-web">Original</a>
    <h1>A future for SQL on the web (2021)</h1>
    
    <div id="readability-page-1" class="page">


<p>I discovered something absurd recently and I’m very excited to tell you about it.</p>
<p>The end result is <a href="https://github.com/jlongster/absurd-sql">absurd-sql</a>, and it’s a persistent backend for SQLite on the web. That means it doesn’t have to load the whole db into memory, and writes persist. In this post I will explain the absurdities of the web’s storage APIs (mainly IndexedDB), show how SQLite provides a 10x perf improvement, explain all the cool tricks that make it work, and explain the locking/transactional semantics that make it robust.</p>
<center>
—
</center>
<p>If you are writing a web app today, you’ll probably choose <a href="https://developer.mozilla.org/en-US/docs/Web/API/IndexedDB_API">IndexedDB</a> to store data. It’s the only option for something database-like that works across all browsers.</p>
<p>As you attempt to build a local app, you will quickly find that it’s a poor database to build an entire app around. Sure, it might be fine for small bits of functionality. But if we really want webapps to be impressive (I do), we need a more powerful way to work with data.</p>
<p>IndexedDB is slow. What’s even worse, in my testing Chrome, which is by the far the major browser, has the slowest implementation. Simple operations against the database take ~10ms (and I’m being charitable!), while it’s common for me to be profiling SQLite at ~.01ms. This makes a massive difference for what kinds of apps you can write against it.</p>
<p>You’re on your own if you want to query data in IndexedDB. The only function it provides is <a href="https://developer.mozilla.org/en-US/docs/Web/API/IDBObjectStore/count"><code>count</code></a>, and the rest of the <a href="https://developer.mozilla.org/en-US/docs/Web/API/IDBObjectStore">APIs</a> just return a range of items. You’ll have to construct your own query functionality by wiring up indexes and structuring your data in specific ways.</p>
<p>Heck, you can’t even add a new “object store”, which is sort of like a table, at any point in time. You can only do it when <em>opening the database</em>, and doing so forces all other tabs to kill their database connection!</p>
<p>Maybe IDB was supposed to be low-level and you’re supposed to reach for a library to help provide better support for these features. Every library I looked at was messy and made performance even worse (one of the most popular “fast” ones I looked at took ~45ms to just get one item!?).</p>
<p>I say abstract away the whole thing. I have something for you that you should reach for next time instead of all those other libraries. And it’s going to <em>massively</em> improve your life as a developer.</p>
<h2 id="introducing-absurd-sql">Introducing absurd-sql</h2>
<p>SQL is a great way to build apps. <em>Especially</em> small local web apps. Key/value stores may have their place in large distributed systems, but <em>wow</em> wouldn’t it be great if we could use <a href="https://www.sqlite.org/index.html">SQLite</a> on the web?</p>
<div>
<svg height="300px" width="300px" fill="#6D28D9" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" x="0px" y="0px" viewBox="0 0 90 90" enable-background="new 0 0 90 90" xml:space="preserve">
<path d="M48.958,11.021l9.077,19.246l20.712,3.139c5.688,0.861,6.032,3.424,1.969,7.574L66.029,55.969l3.36,20.438  c1.099,6.678-0.901,8.287-5.489,5.766L45.119,71.877L26.337,82.182c-4.589,2.523-6.589,0.918-5.489-5.764l3.359-20.438L9.521,40.99  c-4.063-4.146-3.72-6.709,1.968-7.572l20.713-3.141l9.078-19.271C43.952,5.344,46.682,6.188,48.958,11.021z"></path>
</svg><p>
I’m excited to announce <a href="https://github.com/jlongster/absurd-sql">absurd-sql</a> which makes this possible. absurd-sql is a filesystem backend for <a href="https://github.com/sql-js/sql.js/">sql.js</a> that <strong>allows SQLite to read/write from IndexedDB in small blocks, just like it would a disk</strong>. I ported my app to use and you can try it <a href="https://app.actualbudget.com/?wtf_source=absurd-post">here</a>. </p><svg height="300px" width="300px" fill="#6D28D9" xmlns="http://www.w3.org/2000/svg" xmlns:xlink="http://www.w3.org/1999/xlink" version="1.1" x="0px" y="0px" viewBox="0 0 90 90" enable-background="new 0 0 90 90" xml:space="preserve"><path d="M48.958,11.021l9.077,19.246l20.712,3.139c5.688,0.861,6.032,3.424,1.969,7.574L66.029,55.969l3.36,20.438  c1.099,6.678-0.901,8.287-5.489,5.766L45.119,71.877L26.337,82.182c-4.589,2.523-6.589,0.918-5.489-5.764l3.359-20.438L9.521,40.99  c-4.063-4.146-3.72-6.709,1.968-7.572l20.713-3.141l9.078-19.271C43.952,5.344,46.682,6.188,48.958,11.021z"></path></svg>
</div>
<p>This whole situation, and how well this project ended up working out, really is absurd. Why? In all browsers except Chrome, <em>IndexedDB is implemented using SQLite</em>. Anyway…</p>
<p>A huge thanks to phiresky writing the article <a href="https://phiresky.github.io/blog/2021/hosting-sqlite-databases-on-github-pages/">Hosting SQLite databases on Github Pages</a> which inspired me to do this. It’s a very clever technique and it gave me the idea to research this.</p>
<p>sql.js is already a great project for using SQLite on the web. It compiles SQLite to WebAssembly, and lets you read databases and run queries. The major problem is that <strong>you can’t persist any writes</strong>. It loads the entire db into memory, and only changes the in-memory data. Once you refresh the page, all your changes are lost.</p>
<p>While in-memory databases have their uses, it kneecaps SQLite into something far less useful. To build any kind of app with it, we need the ability to write and persist.</p>
<p><strong>absurd-sql solves this</strong>, and it works by intercepting read/write requests from SQLite and fetching and persisting them into IndexedDB (or any other persistent backend). I wrote a whole filesystem layer that is aware of how SQLite reads and writes blocks, and it efficiently performs the operations correctly.</p>
<p>What this means is <strong>it never loads the database into memory</strong> because it only loads whatever SQLite asks for, and <strong>writes always persist</strong>.</p>
<p>We use sql.js because it already has a large community and is by far the most common way to use SQL on the web. Now, all you have to do is install absurd-sql and add some lines of code to hook it up. It looks like this:</p>

<details>
<summary>A few notes: this currently requires <a href="https://github.com/jlongster/sql.js">my fork</a> of sql.js but hopefully these changes will be merged in…</summary> This API is likely to change. The reason for <code>register_for_idb</code> is because Emscripten doesn’t properly hook up the file locking API, so we need to manually forward SQLite’s lock requests. Lastly, this code must run in a web worker. The APIs we need are only available there, but that’s fine because you shouldn’t be blocking the main thread.
</details>
<p>Use <code>db</code> like you would normally, except now it efficiently reads and persists writes to IndexedDB! See the <a href="https://github.com/jlongster/absurd-sql">README</a> for more information, and look at the <a href="https://sql.js.org/">sql.js docs</a> for the database API. You can also use this <a href="https://github.com/jlongster/absurd-example-project">example project</a> to get started quickly.</p>

<p>We’re bringing <a href="https://www.w3.org/TR/webdatabase/">WebSQL</a> back, baby!</p>
<p>While I wouldn’t recommend this for production quite yet, <strong>I ported my app <a href="https://app.actualbudget.com/?wtf_source=absurd-post">Actual</a></strong> to use it and it works! Click “try demo” to see it in action, and look at your IndexedDB storage.</p>
<h2 id="more-than-just-another-database">More than just another database</h2>
<p>I talk a lot about IndexedDB in this post because it’s the only persistent storage that works across all browsers today. The problem is it couples two needs into one: databases and persistent storage.</p>
<p>What happens when you’ve built your entire app around IndexedDB, and then a <a href="https://web.dev/storage-foundation/">brand new super fast storage layer</a> comes to the web? You’ve locked yourself in.</p>
<p>Using sql.js + absurd-sql, we’ve abstracted away the storage layer. I’ll talk about how much faster absurd-sql is than IndexedDB below, but don’t be fooled: we are still <em>far</em> away from native performance. We are about 50-100x slower than native SQLite because we have no way to make faster writes. (but don’t let that scare you; it’s still fast enough for many use cases and SQLite’s caching helps a ton)</p>
<p>IndexedDB is just one backend for absurd-sql. I’ve already experimented with <a href="https://gist.github.com/jlongster/ec00ddbb47b4b29897ab5939b8e32fbe">a webkitFileSystem backend</a>, but I haven’t been able to match IDB’s performance yet. I must be missing how to do bulk reads and writes, because it’s terribly slow.</p>
<p>There is a new proposal called <a href="https://web.dev/storage-foundation/">Storage Foundation API</a> which is built exactly for this use case. I’m talking with the authors and I will experiment with a backend using that. (It’s missing some critical things like locking, but hopefully solvable)</p>
<p>There is potential for another 1 or 2 orders of magnitude increase in performance in the future. When that happens, all you’ll have to do is switch a couple lines of code!</p>
<h3 id="a-note-about-indexeddb-durability">A note about IndexedDB durability</h3>
<p>Let’s hope a new storage API comes along because it’s worth mentioning that it’s not guaranteed that your IndexedDB data will live forever. Supposedly browsers <em>may</em> delete your IndexedDB database under certain conditions.</p>
<p>While this very rarely happens (I haven’t seen it yet), the fact that it’s possible puts a major downer on using it for persistent storage. For now, you can use it for anything that is also backed up in the cloud — but I wouldn’t use it for something that only lives locally and it meant to last for the rest of your life. Hopefully we’ll get a better storage API for that.</p>
<p>Ok — off to the fun stuff!</p>
<h2 id="tradeoffs-what-tradeoffs">Tradeoffs? What tradeoffs?</h2>
<p>SQLite, even though it’s implemented on top of IndexedDB, easily beats out IndexedDB in every single performance metric. The absurdity!</p>
<p>I wrote a bechmarking app to test many different scenarios: <a href="https://priceless-keller-d097e5.netlify.app">https://priceless-keller-d097e5.netlify.app</a>. It runs a couple different queries, and lets you configure SQLite in various ways, and also lets you run them against a raw IndexedDB implementation.</p>
<p>All data is in <a href="https://docs.google.com/spreadsheets/d/1Cpb9r3cZlbZgp1RoSTmh22wOPCRMqINzMUelUTIDo8Y/edit?usp=sharing">this spreadsheet</a>, and the benchmark code is <a href="https://github.com/jlongster/absurd-sql/tree/master/src/examples/bench">here</a>.</p>
<h3 id="reads">Reads</h3>
<p>These are the results of a query like <code>SELECT SUM(*) FROM kv</code> which forces the db to read all items (2015 macbook pro). For IndexedDB, it <a href="https://github.com/jlongster/absurd-sql/blob/master/src/examples/bench/queries-raw-idb.js#L46">was implemented</a> by opening a cursor and summing each item.</p>
<p><img src="https://jlongster.com/perf-sum-chrome.png"/></p>
<details>
<summary>Expand to see Firefox’s data, which looks similar but their IDB is twice as fast (look at the Y axis). For the same of simplicity, I’ll focus on Chrome.</summary> <img src="https://jlongster.com/perf-sum-firefox.png"/>
</details>
<h3 id="writes">Writes</h3>
<p>Here is the results of doing a bunch of inserts like <code>INSERT INTO kv (key, value) VALUES (&#34;large-uuid-string-0001&#34;, 53234.22)</code>, and using a bulk <code>put</code> (we only wait for transaction success) with the same data with IndexedDB:</p>
<p><img src="https://jlongster.com/perf-writes-chrome.png"/></p>
<p>I realize that writes are difficult to measure; I tried to do a fair comparison. I am doing a bulk insert in IndexedDB, and should be as fast as it can be. I’m also not doing anything tricky like making SQLite not wait for the disk to be flushed or something like that. They both use the exact same flow.</p>
<details>
<summary>Again, expand to see Firefox’s data, which is over twice as fast</summary> <img src="https://jlongster.com/perf-writes-firefox.png"/>
</details>
<p>My original target was 1,000,000 items, and absurd-sql handles that just fine. It’s a little slow, writing takes 4-6s and reading takes 2-3 seconds. But I wasn’t even patient enough to wait for IndexedDB to finish. It eventually did, but writes was the order of 2 or 3 minutes and reads was somewhere in the 1 minute range I think.</p>
<p>IndexedDB seems get worse the more items you throw at it; it’s not exactly linear, and there’s a point where it’s just not feasible to use anymore.</p>
<h3 id="whats-the-catch">What’s the catch?</h3>
<p>Surely there’s a catch somewhere. Where are we paying the cost of those wins?</p>
<p>There is <em>one</em> downside: you need to download a 1MB WebAssembly file (actually I forgot about gzipping! it’s only 409KB after that). But <em>that’s it</em>. That’s the only catch. Everything else is an upside, and with WASM streaming compilation, the cost of parsing/compiling is relatively low. For real apps it’s a no-brainer, especially since it’s so cacheable (it never changes).</p>
<p>Not only do you get fantastic performance, you also get <em>all the features</em> of a great database:</p>
<ul>
<li>Transactions! (that don’t suck and try to auto-commit)</li>
<li>A whole query system!</li>
<li>Views!</li>
<li>Common Table Expressions!</li>
<li>Triggers!</li>
<li>Full-text search!</li>
<li>Caching (more major speedups)!</li>
<li>So much more!</li>
</ul>
<p><a href="https://vigilant-visvesvaraya-4f8ee5.netlify.app/">Here’s a demo of full text search</a>. Click “load data” to load some data in, and then start typing in the input. If you refresh the page the data will still be there.</p>
<h2 id="no-really-how-is-this-possible">No really — how is this possible?</h2>
<p>Whenever something looks too good to be true, I like to sit back and make sure I’m not missing something. Is there some catch I’m missing?</p>
<p>How can we beat IndexedDB so easily anyway? If this works, why don’t we do the same thing with native SQLite and chop up a SQLite db into SQLite?</p>
<p>The reason it works is because IndexedDB is <em>so slow</em>. The simple act of batching read/writes provides such drastic performance benefits, that no amount of CPU processing is going to close the gap. Because that’s the thing — we <em>are</em> doing a lot more CPU work! Shouldn’t that count for something negative?</p>
<p>No — because we save <em>so much time</em> avoiding IndexedDB reads/writes that the CPU hit is negligable. You don’t even see unless you look real close. Gaining that time gives us a lot of time to do everything SQLite does, and <em>still</em> be 5x (or much more) faster.</p>
<p>I’m really hoping for a better storage API like <a href="https://web.dev/storage-foundation/">this one</a>. Let’s hope it happens.</p>
<h2 id="not-fast-enough-caching-to-the-rescue">Not fast enough? Caching to the rescue!</h2>
<p>As I mentioned earlier in the post, while these results are extremely promising, a look at native SQLite performance is sobering. It’s an order of magnitude or 2 faster.</p>
<p>If you are doing a lot of reads, the current performance is not sufficient to support a real-world app. But there’s a very easy fix for it: use SQLite caching!</p>
<p>SQLite automatically uses a 2MB page cache, so you might not even notice any perf problems. It will cache the results of any read requests, and evict it whenever a write happens. For the usual use case of an app where there are many reads and sometimes writes, this works very well.</p>
<p>If you are working with larger data, you can try to bump the page cache up. Even something like 10MB would be fine. We’re basically lazily loading a lot of the db into memory, but we let SQLite manage it so it knows when to evict.</p>
<p>Increasing the page size is another way to reduce reads, which I explain below.</p>
<h3 id="page-sizes">Page sizes</h3>
<p>If you loaded data in the demo, open your developer tools and look at your IndexedDB data (in Chrome, it’s under the “Application” tab). You’ll see something like this:</p>
<p><img src="https://jlongster.com/idb-data.png"/></p>
<p>Note how it stores data in blocks of 4096 bytes, which is the default page size of SQLite. The smaller page size, the more reads it has to do, and originally I thought this would be way too small to work. However, with the below optimizations it works fine!</p>
<p>However, you are free to bump up the page size. It must be a power two, so you can try 8192. Doing this cuts reads in half, and will increase performance. It’s not magical though; larger block sizes means it might read or wrote a lot of data that it doesn’t need. Profile and see what works for you. <strong>All of the perf benchmarks use a page size of 4096</strong>, meaning it uses a less performant config to try to be fair. It can run even faster though!</p>
<p>How do you change page size? Just use SQLite:</p>

<p>You must <code>VACUUM</code> for it to take effect; SQLite must restructure the whole db to change the page size. If you do this, we automatically change how we store data:</p>
<p><img src="https://jlongster.com/idb-data2.png"/></p>
<p>Note how it’s blocks of 8192 now. We read the required page size directly from the bytes of the file and respect it.</p>
<p>In my app Actual (<a href="https://app.actualbudget.com/?wtf_source=absurd-post">try the demo</a>), it uses a 4096 block size. Eventually I’ll make it larger, but the same file is shared across platforms and I don’t want to effect mobile/desktop.</p>
<h2 id="how-it-works">How it works</h2>
<p>There are several tricks required to get this level of performance. Because IndexedDB is so slow, if we don’t do things right we could actually be much slower than a raw IndexedDB because we’re recreating transactions or something like that.</p>
<p>The goal is to do whatever you would expect would happen: if SQLite it making a bunch of sequential reads, it should open a cursor and iterate through the data. It should not open a new transaction for every read. This is difficult to do because we only have a single <code>read</code> function that takes an offset and length. However, with some tricks we’re able to make it work.</p>
<p>Another goal is to <strong>maintain as little state as possible</strong>. We shouldn’t be tracking lock state, our own change counter, or page size. We read directly from the SQLite file when needed, and leverage IndexedDB’s transaction semantics for locking. The only state we store is the size of the file, and that’s fine. This makes it far more reliable.</p>
<h3 id="the-big-problem-sync-apis">The big problem: sync APIs</h3>
<p>The biggest problem is when sqlite does a read or write, the API is totally synchronous because it’s based on the C API. Accessing IndexedDB is always async, so how do we get around that?</p>
<p>We spawn a worker process and give it a <code>SharedArrayBuffer</code> and then use the <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Atomics"><code>Atomics</code></a> API to communicate via the buffer. For example, our backend writes a read request into the shared buffer, and the worker reads it, performs the read async, and then writes the result back.</p>
<p>I wrote a small <a href="https://github.com/jlongster/absurd-sql/blob/master/src/indexeddb/shared-channel.js">channel abstraction</a> to send different types of data across a SharedArrayBuffer.</p>
<p>The real magic is the <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/Atomics/wait"><code>Atomics.wait</code></a> API. It’s a beautiful thing. When you call it, it completely blocks JS until the condition is met. You use it to wait on some data in the <code>SharedArrayBuffer</code>, and this is what enables us to turn the async read/write into a sync one. The backend calls it to wait on the result from the worker and blocks until it’s done.</p>
<p>Another option would be to use <a href="https://emscripten.org/docs/porting/asyncify.html">Asyncify</a>, an Emscripten technique for turning sync C calls into async ones. However, there’s no way I’m going to touch that. It works by transforming the entire code to unwind/rewind stacks, causing a massive perf hit and bloating the binary size. It’s just too invasive and would force SQLite to have an async API.</p>
<p><code>Atomics.wait</code> unlocks some key performance improvements anyway. It’s good.</p>
<h3 id="long-lived-indexeddb-transactions">Long-lived IndexedDB transactions</h3>
<p>IndexedDB has an awful behavior where it auto-commits transactions once the event loop is done processing. This makes it impossible to use a transaction over time, and requires you to create a new one if you are doing many reads over time. Creating a transaction is <em>super</em> slow and this is a massive perf hit.</p>
<p>However, <code>Atomics.wait</code> is so great. We <em>also</em> use it in the worker to block the process which keeps transactions alive. We open a transaction, and then block the whole thread so the system can’t take it away from me. I love it!</p>
<p>That means while processing requests from SQLite, we can reuse a transaction for all of them. If 1000 reads come through, we will use the same <code>readonly</code> transaction for all of them, which is a massive speedup.</p>
<details>
<summary>This glossing over details; we only keep the transaction open for the scope of a lock…</summary> SQLite always locks files when reading and writing, and we open a single transaction for the scope of the lock
</details>
<h3 id="iterating-with-cursors">Iterating with cursors</h3>
<p>It’s faster to iterate over data with <a href="https://developer.mozilla.org/en-US/docs/Web/API/IDBObjectStore/openCursor">cursors</a>. We only get separate <code>read</code> requests though; how can we use cursors?</p>
<p>Because we keep a single transaction open for reads over time, we can detect when sequential reads are happening and open a cursor. There’s a lot of interesting tradeoffs here because opening a cursor is actually super slow in some browsers, but iterating is a lot faster than many <code>get</code> requests. This backend will intelligently detect when several sequential reads happen and automatically switch to using a cursor.</p>
<p>Interestingly, in Firefox (and I think Safari) using a cursor is a <em>massive</em> speedup. In Chrome it’s only slightly faster.</p>
<h3 id="file-locking-and-transactional-semantics">File locking and transactional semantics</h3>
<p>This one is for the database nerds. This is probably the most important thing to get right because if not your database will get corrupted. Performance doesn’t matter with a corrupted database.</p>
<p>How do we make sure we’re always applying writes correctly? Unsurprisingly, it’s complicated! But I believe the algorihm implemented is robust.</p>
<h4 id="atomic-commits">Atomic commits</h4>
<p>The first thing to understand is the assumptions that SQLite makes. We need to meet these assumptions 100% or otherwise risk database corruption.</p>
<p><a href="https://www.sqlite.org/atomiccommit.html">Atomic Commit In SQLite</a> is a great description of how writes work. I also studied the source code a lot to understand any other requirements. It comes down to this:</p>
<ul>
<li>SQLite uses a journal and makes writes twice, first in the journal and then to the normal file.</li>
<li>You can’t avoid something like a power outage which shuts down your computer in the middle of flushing out writes. Because SQLite makes writes twice, if this happens it always has at least one file in tact. If the db file is partially written, it has a “hot journal” and just re-applies the journal. If the journal is partially written, that’s no big deal and it just ignores it. That allows an atomic commit (all or nothing).</li>
<li>It all rides on <code>fsync</code> working properly. After it calls <code>fsync</code>, it assumes that all writes have successfully made it to disk. If this is not true, it’s possible for <em>both</em> files to be partially written.</li>
</ul>
<p>The first requirement we must meet is to provide an <code>fsync</code> method that flushes out writes atomically.</p>
<p>Here’s the thing: if we’re using IndexedDB, we don’t have to worry about any of this. IDB already provides transactional sematics; if we open a transaction and do a bunch of writes, they either all succeed or not. That takes the weight off of us and we can rely on that.</p>
<p>We don’t really even need a journal file. We could tell SQLite to avoid using one with <code>journal_mode=OFF</code>, however it still needs to journal for rolling back transactions (<code>ROLLBACK</code>). So you should use <code>journal_mode=MEMORY</code> which keeps the journal in memory — that’s much faster than writing it to disk.</p>
<p>There’s also <a href="https://sqlite.org/wal.html">write-ahead logging</a>, or “WAL mode”. This can be more efficient if working with a real disk. However, to achieve its performance it requires things like shared memory using <code>mmap</code> and things like that. I don’t think we can reliably map those semantics onto IndexedDB, and I don’t even see the point. WAL potentially <em>adds</em> more overhead if we’re just writing them all to IDB anyway. The structure of the writes isn’t as important to us.</p>
<h4 id="file-locking">File locking</h4>
<p>SQLite uses <a href="https://www.sqlite.org/lockingv3.html">advisory locks</a> to coordinate between db connections. How locks are used is described in detail on <a href="https://www.sqlite.org/atomiccommit.html">Atomic Commit In SQLite</a>.</p>
<p>It’s super important that we get this write. We need to lock our data in the same way the SQLite expect, otherwise connections could write over each other. Even though we depend on IndexedDB transactions, that doesn’t mean they are ordered correctly.</p>
<p>We can leverage transactions, however. We just need to do some extra work. IndexedDB <code>readonly</code> transactions can run in parallel, while <code>readwrite</code> transactions with only run one at a time. We can use this to implement locking — once a <code>readwrite</code> transaction is running, the file is effectively locked.</p>
<p><a href="https://github.com/jlongster/absurd-sql/blob/master/src/indexeddb/worker.js#L423">Here’s our method</a> that implements locking, and the comment above it is helpful.</p>
<p>When a <code>SHARED</code> lock is requested, we open a readonly transaction. It’s fine if many <code>SHARED</code> locks exist at once, and that works with parallel <code>readonly</code> transactions. However when a write lock is requested, we open a <code>readwrite</code> transaction. Once that transaction is running, we know we control the database because of IDB semantics.</p>
<p>The only problem is that another thread might have written data down between the time that we requested a <code>readwrite</code> lock and got it. <a href="https://github.com/sqlite/sqlite/blob/master/src/pager.c#L93-L96">SQLite already gives us this information</a>! Once we’ve grabbed a readwrite transaction, we can read some bytes from the file which represent SQLite’s “change counter”. If that counter is the same as what we had when we requested a write, it’s safe to write!</p>
<p>(If you’re familiar with how SQLite upgrades/downgrades locks, we implement the same flow and you can view the source for upgrading <a href="https://github.com/jlongster/absurd-sql/blob/master/src/indexeddb/worker.js#L95">here</a>)</p>
<p>SQLite locks a file for writing whenever a transaction starts, like <code>BEGIN TRANSACTION</code>, and then unlocks it when the transaction ends. In a way we’re mapping SQLite transactions onto IndexedDB <code>readwrite</code> transactions, but I wouldn’t think of it that way because we don’t translate <code>ROLLBACK</code> to <code>abort()</code> in IndexedDB. We’re leveraging IDB transactions to ensure safe atomic writes, and we write down whatever SQLite tells us to.</p>
<p>This is only possible because we have long-lived IDB transactions, since we can open a <code>readwrite</code> transaction once and make sure we have it over the course of the write lock. If we had to reopen it, it would destroy our ability to safely write to the db and it would get easily corrupted.</p>

<p>While most browsers support <code>SharedArrayBuffer</code>, Safari has not enabled it yet. I’m not too worried about it because it will in the future, however we need to provide some kind of support for it today.</p>
<p>absurd-sql provides a <a href="https://github.com/jlongster/absurd-sql/blob/master/src/indexeddb/file-ops-fallback.js">fallback mode</a> if <code>SharedArrayBuffer</code> is not available. The way it works is it reads all the data in at the beginning so reads happen sync.</p>
<p>Writes are more difficult: it assumes that writes are always successful, but actually queues them up to run in the background. We implement the same transactional semantics as before (only write when it’s safe), but they happen in the background.</p>
<p>The major problem with this is when a write is <em>not</em> successful, the whole database is stale. We can never write to the file again. We could potentially restart the db and read the entire file again but that feels to complicated.</p>
<p>The end result is that if you have two tabs open in Safari, only one of them can actually perform writes. If both of them try to, one of them is going to detect that something has changed from underneath it and never write to to the db. It will continue to work in memory, but when you refresh changes will be lost. The app should notify the user when this happens so they don’t lose data.</p>
<h2 id="come-help">Come help!</h2>
<p>I would love your help in testing this and improving it! Come over to <a href="https://github.com/jlongster/absurd-sql">the repo</a>, and I hope you have fun SQLing.</p>
<p>- James</p>




</div>
  </body>
</html>
