<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://lite.berkeley-humanoid.org/">Original</a>
    <h1>Berkeley Humanoid Lite â€“ Open-source robot</h1>
    
    <div id="readability-page-1" class="page"><div>
    
    
    

    <iframe src="https://www.youtube.com/embed/dIdJGkMDFl4?si=SRD7HhQQbhM3JCRA" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen="" autoplay=""></iframe>

    <h2>Abstract</h2>
    <div>
      <p>
        Despite significant interest and advancements in humanoid robotics, most existing commercially available hardware remains high-cost, closed-source, and non-transparent within the robotics community. This lack of accessibility and customization hinders the growth of the field and the broader development of humanoid technologies. To address these challenges and promote democratization in humanoid robotics, we demonstrate <b>Berkeley Humanoid Lite</b>, an open-source humanoid robot designed to be accessible, customizable, and beneficial for the entire community. 
      </p>
      <p>
        The core of this design is a modular 3D-printed gearbox for the actuators and robot body. All components can be sourced from widely available e-commerce platforms and fabricated using standard desktop 3D printers, keeping the total hardware cost under $5,000 (based on U.S. market prices). The design emphasizes modularity and ease of fabrication. To address the inherent limitations of 3D-printed gearboxes, such as reduced strength and durability compared to metal alternatives, we adopted a cycloidal gear design, which provides an optimal form factor in this context. Extensive testing was conducted on the 3D-printed actuators to validate their durability and alleviate concerns about the reliability of plastic components. To demonstrate the capabilities of Berkeley Humanoid Lite, we conducted a series of experiments, including the development of a locomotion controller using reinforcement learning. These experiments successfully showcased zero-shot policy transfer from simulation to hardware, highlighting the platform&#39;s suitability for research validation.
      </p>
      <p>
        By making the hardware design, embedded code, and training and deployment frameworks fully open-source and globally accessible, we aim for Berkeley Humanoid Lite to serve as a pivotal step toward democratizing the development of humanoid robotics.
      </p>

      <p><img src="https://lite.berkeley-humanoid.org/static/berkeley-humaonid-lite-cover.png" alt="Berkeley Humanoid Lite"/>
    </p></div>
  
    <h2>Demonstrations</h2>
    <div>
      <div>
        <video autoplay="" muted="" loop="" playsinline="" src="./static/experiments/bhl-playing-with-rubik-cube.mp4" poster="./static/loading.gif"></video>
        <p>Playing with a Rubik&#39;s Cube</p>
      </div>
      <div>
        <video autoplay="" muted="" loop="" playsinline="" src="./static/experiments/bhl-writing-its-name.mp4" poster="./static/loading.gif"></video>
        <p>Writing its name with a marker</p>
      </div>
    </div>
    <div>
      
      <div>
        <video autoplay="" muted="" loop="" playsinline="" src="./static/experiments/bhl-biped-locomotion.mp4" poster="./static/loading.gif"></video>
        <p>Locomotion in bipedal configuration</p>
      </div>
    </div>

    <h2>Comparision</h2>
    <p>
        To be able to benchmark against other robots and illustrate our focus on accessibility and customizability while maintaining sufficient performance, we introduce a quantitative metric that captures cost-effectiveness. Specifically, we define the performance factor as the average peak torque of all actuated DoFs, normalized by the robot&#39;s size:
      </p>
      <p>
        \begin{equation}
        \hat{p} = \frac{1}{N h mg} \sum_{i=1}^N |\tau_i^{\max}|.
        \end{equation}
      </p>
      <p>
        $N$ denotes the number of actuated DoFs, $h$ and $mg$ represent the height and weight of the robot, and $|\tau_i^{\max}|$ represents the maximum torque of the i-th joint motor. The performance factor per dollar is then defined as the performance factor divided by the cost or selling price of the robot:
      </p>
      <p>
        \begin{equation}
        \varphi = \frac{\hat{p}}{\text{cost}}.
        \end{equation}
      </p>
      <p>
        As shown in the figure below, our platform achieves high performance factor with a cost lower than <b>$5000</b>.
      </p>
      <p><img src="https://lite.berkeley-humanoid.org/static/comparision.png" alt="Comparison of performance factors across different platforms"/></p>
    
    <h2>BibTeX</h2>
    <pre>      <code>@inproceedings{chi2025demonstrating,
  title={Demonstrating Berkeley Humanoid Lite: An Open-source, Accessible, and Customizable 3D-printed Humanoid Robot},
  author={Yufeng Chi and Qiayuan Liao and Junfeng Long and Xiaoyu Huang and Sophia Shao and Borivoje Nikolic and Zhongyu Li and Koushil Sreenath},
  year={2025},
  eprint={},
  archivePrefix={arXiv},
  primaryClass={cs.RO},
  url={},
}</code>
    </pre>
    
    <h2>Community</h2>
    <div>
      <div>
        <h3>Discord Community</h3>
        <p>Scan QR code to join our Discord server:</p>
        <p><img src="https://lite.berkeley-humanoid.org/static/discord-invite.png" alt="Discord QR Code"/>
      </p></div>
      <div>
        <h3>WeChat Group</h3>
        <p>Scan QR code to join our WeChat group:</p>
        <p><img src="https://lite.berkeley-humanoid.org/static/wechat-invite.jpg" alt="WeChat QR Code"/>
      </p></div>
    </div>

    <h2>Acknowledgements</h2>
    <div>
      <p>
        We would like to thank Lydia Liu, Widyadewi Soedarmadji, and Daniel Wong for the early-stage project explorations. We would also like to thank Alex Hao and Ted Zhang for providing help on supporting the experiments. We are grateful to Chengyi Lux Zhang for the generous assistance. Finally, we appreciate the helpful discussions from all members of Hybrid Robotics Group and SLICE lab.
      </p>
      <p>
        This work is supported in part by NSF 2303735 for POSE, in part by NSF 2238346 for CAREER, in part by the Robotics and AI Institute. K. Sreenath has financial interest in the Robotics and AI Institute. He and the company may benefit from the commercialization of the results of this research.
      </p>
    </div>
  </div></div>
  </body>
</html>
