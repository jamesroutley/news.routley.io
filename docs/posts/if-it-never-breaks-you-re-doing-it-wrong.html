<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://ntietz.com/blog/if-it-never-breaks-youre-doing-it-wrong/?utm_source=atom&amp;utm_medium=feed">Original</a>
    <h1>If it never breaks, you&#39;re doing it wrong</h1>
    
    <div id="readability-page-1" class="page"><div><p>When the power goes out, most people are understanding.
Yet the most <em>livid</em> I&#39;ve seen people is when web apps or computers they use have a bug or go down.
But most of the time, it&#39;s a really bad sign if this <em>never</em> happens.</p>
<p>I was talking to my dad about this recently.
For most of his career, he was a corporate accountant for a public utility company.
Our professional interests overlap in risk, systems, internal controls, and business processes.
These all play into software engineering, but risk in particular is why we <em>should</em> expect our computer systems to fail us.</p>

<p>As a motivating example, let&#39;s talk about the power company.
When&#39;s the last time you had a power outage?
If you&#39;re in the US, it&#39;s probably not that long ago.
My family had our last outage for about an hour last year, and my parents had their power go out for half a day a few weeks ago.</p>
<p>Both of these outages were from things that were preventable.</p>
<p>My family&#39;s power outage was because a tree came down on an above ground power line.
This could have been prevented by burying the cables.
This would take quite a bit of digging, and it&#39;s common in a lot of new developments, but where we are everything is above ground for legacy reasons.
Or maybe we could have removed more of the trees around the power lines!
But that&#39;s probably not a great idea, because trees are important for a lot of reasons, including preventing erosion and mitigating floods.</p>
<p>My parents&#39; power outage was from an animal climbing into some equipment (this makes me very sad, poor thing).
This could have been prevented by protecting and sealing the equipment.
Perhaps there was protection and it was broken, and an inspection could have found it.
Or perhaps the equipment needed other forms of protection and sealing.</p>
<p>There are <em>also</em> power failures for reasons that are a failure to recognize and acknowledge risk, or a change to the risk levels.
In particular, I think about the failures of Texas&#39;s power grid recently.
These failures involved an overloading of the grid in a way that was predicted, and resulted in catastrophic failures.
The risk that this would happen changed as our climate has changed, and utilities infrastructure is difficult to quickly update to reflect this change in reality.</p>
<p>The thing is, all of these interventions are known.
We can do all of these things, and they&#39;re discussed.
Each of them comes with a <em>cost</em>.
There are two aspects of this cost: there are the literal dollars we pay to make these interventions, and there is the opportunity cost of what we <em>don&#39;t</em> do instead.
In a world of limited resources, we must consider both.</p>
<p>When you&#39;re deciding which changes to make, you have to weigh the cost of interventions against the cost of doing nothing.
Your cost of not doing anything is roughly the probability of an event happening times the expected cost of such an event.
You can calculate that, and you should!
Whereas your cost of doing an intervention is the cost of the intervention plus any lost gains from the things you opt not to do instead (this can be lost revenue or it can be from <em>other</em> failures you get from doing this intervention over other ones).</p>

<p>This all comes back to software.
Let&#39;s look at an example, using fake numbers for ease of calculation.</p>
<p>Let&#39;s say you have a web app that powers an online store.
People spend $1 in your shop each minute, and you know you have a bug that gives you a 10% chance of going down for an hour once a month.
Should you fix it?</p>
<p>We want to say yes by default, because geez, one hour of downtime a month is a lot!
But this is a decision we can put numbers behind.
Off the bat, we want to say that the cost of an outage would be <code>0.1 * 60 * 1</code>, or $6 a month.
If your software developers cost you $3/hour, and can fix this in 10 hours, then you&#39;d expect to make a profit on fixing this in five months.</p>
<p>But this also ignores some real-world aspects of the issue:
How will downtime or uptime affect your reputation, and will people still be willing to buy from you?
If you&#39;re down, do you lose the money or do people return later and spend it (are you an essential purchase)?
Are purchases uniformly distributed across time as we used here for simplicity, or are there peak times when you lose <em>more</em> from being down?
Is your probability of going down uniform or is it correlated to traffic levels (and thus probably to revenue lost)?</p>
<p>Quantifying the loss from going down is <em>hard</em>, but it&#39;s doable.
You have to make your assumptions clear and well known.</p>

<p>The other lens to look at this through is what you give up to ensure no downtime.
Downtime is expensive, and so is increasing amounts of uptime.</p>
<p>Going from 9% to 99% uptime is pretty cheap.
Going from 99% to 99.9% uptime gets a little trickier.
And going from 99.9% uptime to 99.99% uptime is very expensive.
Pushing further than that gets prohibitively expensive, not least because you will be seeking to be more reliable than the very components you depend on!
That shift to be more reliable than the components you use means a significant shift in thinking and how you design things, and it comes with a cost.</p>
<p>When you work to increase uptime, it&#39;s at the expense of something else.
Maybe you have to cut a hot new feature out of the roadmap in order to get a little more stability.
There goes a big contract from a customer that wanted that feature.
Or maybe you have to reduce your time spent on resolving tech debt.
There goes your dev velocity, right out the window.</p>
<p>This can even be a perverse loop.
Pushing toward more stability can increase complexity in your system while robbing you of the time to resolve tech debt, and both complexity and tech debt increase the rate of bugs in your system.
And this leads to more instability and more downtime!</p>
<p>There are some team configurations and companies who can setup engineering systems in a way where they&#39;re able to really push uptime to incredible levels.
What the major cloud providers and CDNs do is <em>incredible</em>.
On the other hand, small teams have some inherent limits to what they&#39;re able to achieve here.
With a handful of engineers you&#39;re not going to be able to setup the in-house data centers and power supplies that are necessary to even have a possibility of pushing past a certain point of uptime.
Each team has a limit to what they can do, and it gets exceedingly expensive the closer you push to that limit.</p>

<p>An interesting question is why people get upset when software fails, especially when we&#39;re not similarly upset by other failures.
I&#39;m not entirely sure, since I&#39;m generally understanding when systems fail (this has always been my nature, but it&#39;s been refined through my job and experience).
But I have a few hypotheses.</p>
<ul>
<li>It&#39;s hard to be patient when you have money on the line.
If you have money on the line from a failure (commission for people selling the software, revenue for people using it in their business, etc.) then this is going to viscerally <em>hurt</em>, and it takes deliberate effort to see past that pain.</li>
<li>We don&#39;t see the fallible parts of software.
We see power lines every day, and we can directly understand the failures: a tree fell on a line, it&#39;s out, makes sense.
But with software, we mostly see a thin veneer over the top of the system, and none of its inner workings.
This makes it a lot harder to understand why it might fail without being a trained professional.</li>
<li>Each failure seems unique.
When the power goes out, we experience it the same way each time, so we get used to it.
But when a piece of software fails, it may fail in different ways each time, and we don&#39;t have a general &#34;all software fails at once&#34; moment but rather many individual softwares failing independently.
This makes us never really get used to running into these issues, and they&#39;re a surprise each time.</li>
<li>We know who to be mad at.
When the power goes out, we don&#39;t really know who we can be upset at.
We shouldn&#39;t be upset at the line workers, because they&#39;re not deciding what to maintain; who, then?
Whereas with software, we know who to be mad at: the software engineers of course!
(Let&#39;s just ignore the fact that software engineers are not often making the <em>business decision</em> of what to focus development efforts on.)</li>
<li>We don&#39;t actually get more mad, I just see it more because I&#39;m in software.
This one is interesting: we might not actually be more mad when power goes out, I might just be more aware of it.
I&#39;m not sure how to check this, but I&#39;d be curious to hear from people in other fields about when things fail and how understanding folks are.</li>
</ul>
<p>I&#39;m sure there are more reasons!
At any rate, it&#39;s a tricky problem.
We can start to shift it by talking openly about the risk we take and the costs involved.
Trade-offs are so fundamental to the engineering process.</p>
<hr/>
<p>Thank you to <a href="https://erikarow.land/">Erika Rowland</a> for reviewing a draft of this post and providing very helpful feedback!</p>
<hr/>



</div><p>
    If this post was enjoyable or useful for you, <strong>please share it!</strong>
    If you have comments, questions, or feedback, you can email <a href="mailto:me@ntietz.com">my personal email</a>.
    To get new posts and support my work, subscribe to the <a href="https://ntietz.com/newsletter/">newsletter</a>. There is also an <a href="https://ntietz.com/atom.xml">RSS feed</a>.
  </p></div>
  </body>
</html>
