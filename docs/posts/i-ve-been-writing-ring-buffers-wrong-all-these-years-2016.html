<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.snellman.net/blog/archive/2016-12-13-ring-buffers/">Original</a>
    <h1>I&#39;ve been writing ring buffers wrong all these years (2016)</h1>
    
    <div id="readability-page-1" class="page"><div><div>
<p>
So there I was, implementing a one element ring buffer. Which,
I&#39;m sure you&#39;ll agree, is a perfectly reasonable data structure.

</p><p>
It was just surprisingly annoying to write, due to reasons we&#39;ll
get to in a bit. After giving it a bit of thought, I realized I&#39;d always
been writing ring buffers &#34;wrong&#34;, and there was a better way.

<read-more></read-more>


</p><h3>Array + two indices</h3>

<p>
There are two common ways of implementing a queue with a ring buffer.

</p><p> One is to use an array as the backing storage plus two indices
to the array; read and write. To shift a
value from the head of the queue, index into the array by the read
index, and then increment the read index. To push a value to the back,
index into the array by the write index, store the value in that
offset, and then increment the write index.

</p><p> Both indices will always be in the range 0..(capacity - 1). This
is done by masking the value after an index gets incremented.

</p><p>
That implementation looks basically like:

</p><pre>uint32 read;
uint32 write;
mask(val)  { return val &amp; (array.capacity - 1); }
inc(index) { return mask(index + 1); }
push(val)  { assert(!full()); array[write] = val; write = inc(write); }
shift()    { assert(!empty()); ret = array[read]; read = inc(read); return ret; }
empty()    { return read == write; }
full()     { return inc(write) == read; }
size()     { return mask(write - read); }
</pre>

<p>
The downside of this representation is that you always waste one element
in the array. If the array is 4 elements, the queue can hold at most 3. Why?
Well, an empty buffer will have a read pointer that&#39;s equal
to the write pointer; a buffer with capacity N and size N would also
have have a read pointer equal to the write pointer. Like this:

</p><p>
<img src="https://debamitro.github.io/blog/stc/images/rb-normal.png"/>

</p><p>
The 0 and 4 element cases are indistinguishable, so we need to prevent one
from ever happening.  Since empty queues are kind of necessary, it follows
that the latter case needs to go. The queue has to be defined
as full when one element in the array is still unused. And that&#39;s the
way I&#39;ve always done it.

</p><p>
Losing one element isn&#39;t a huge deal when the ring buffer has thousands
of elements. But when the array is supposed to have just one element...
That&#39;s 100% overhead, 0% payload!

</p><h3>Array + index + length </h3>

<p>
The alternative is to use one index field and one length field. Shifting
an element indexes to the array by the read index, increments the read
index, and then decrements the length. Pushing an element writes to
the slot that &#34;length&#34; elements after the read index, and then
increments the length. That looks something like this:

</p><pre>uint32 read;
uint32 length;
mask(val)  { return val &amp; (array.capacity - 1); }
inc(index) { return mask(index + 1); }
push(val)  { assert(!full()); array[mask(read + length++)] = val; }
shift()    { assert(!empty()); --length; ret = array[read]; read = inc(read); return ret; }
empty()    { return length == 0; }
full()     { return length == array.capacity; }
size()     { return length; }
</pre>

<p>
This uses the full capacity of the array, with the code not getting much more
complex.

</p><p>
But at least I&#39;ve never liked this representation. The most common use
for ring buffers is for it to be the intermediary between a concurrent
reader and writer (be it two threads, to processes sharing memory, or
a software process communicating with hardware). And for that, the
index + size representation is kind of miserable. Both the reader and
the writer will be writing to the length field, which is bad for
caching. The read index and the length will also need to always be
read and updated atomically, which would be awkward.

</p><p>
(Obviously my one element ring buffer wasn&#39;t going to be used in a
concurrent setting. But it&#39;s a matter of principle.)

</p><h3>Array + two unmasked indices</h3>

<p> So is there an option that gets the benefits of both
representations, without introducing a third state variable?
(Whether it&#39;s two indices + a size, or two indices + some kind
of a full vs. empty flag). Turns out there is, and it&#39;s really
simple. It uses two indices, but with one tweak compared to the
first solution: don&#39;t squash the indices into the correct
range when they are incremented, but only when they are used to index into
the array. Instead you let them grow unbounded, and eventually
wrap around to zero once the unsigned integer overflows. So:

</p><p>
<img src="https://debamitro.github.io/blog/stc/images/rb-nowrap.png"/>

</p><p>
This reclaims the wasted slot.
The code modifying the indices also becomes simpler, since the
clumsy ordering of increments vs. array accesses was only needed for
maintaining the invariant that the index is always in range.

</p><pre>uint32 read;
uint32 write;
mask(val)  { return val &amp; (array.capacity - 1); }
push(val)  { assert(!full()); array[mask(write++)] = val; }
shift()    { assert(!empty()); return array[mask(read++)]; }
</pre>

<p>
Checking the status of the ring also gets simpler:

</p><pre>empty()    { return read == write; }
full()     { return size() == array.capacity }
size()     { return write - read; }
</pre>

<p>
This all works, assuming the following restrictions:

</p><ul>
<li> The implementation language supports wraparound on unsigned
  integer overflow.
  If it doesn&#39;t, this approach doesn&#39;t really buy anything. (What will
  happen in these languages is that the indices get promoted to bignums
  which will be bad, or they get promoted to doubles which will be worse.
  So you&#39;ll need to manually restrict their range anyway).
</li><li> The capacity must always be a power of two. (<b>Edit</b>: This
  limitation does not come just from the definition of <code>mask</code>
  using a bitwise <code>and</code>.
  It applies even if mask were defined using modular arithmetic or a
  conditional. It&#39;s required for the code to be correct on unsigned
  integer overflow.)
</li><li> The maximum capacity can only be half the range of the index
  data types. (So 2^31-1 when using 32 bit unsigned integers).
  In a way that could be interpreted as stealing the top bit of the
  index to function as a flag. But the case against flags isn&#39;t so much
  the extra memory as having to maintain the extra state.
</li></ul>

<p>
All of those seem like non-issues. What kind of a monster would make
a non-power of two ring anyway?

</p><p> This is of course not a new invention. The earliest instance I
could find with a bit of searching was from 2004, with Andrew Morton
<a href="http://lkml.iu.edu/hypermail/linux/kernel/0409.1/2709.html">mentioning
in it a code review</a> so casually that it seems to have been a
well established trick. But the vast majority of implementations
I looked at do not do this.

</p><p>
So here&#39;s the question: Why do people use the version that&#39;s inferior
and more complicated? I&#39;ve must have written a dozen ring buffers over
the years, and before being forced to really think about it, I&#39;d always
just used the first definition. I can understand why a textbook wouldn&#39;t
take advantage of unsigned integer wraparound. But it seems like it
should be exactly the kind of cleverness that hackers would relish
using and passing on.

</p><ul>
<li>Could it just be tradition? It seems likely that
this is the kind of thing one learns by osmosis, and then never
revisits. But even so, you&#39;d expect the &#34;good&#34;
implementations to push out the &#34;bad&#34; ones at some
point, which doesn&#39;t seem to be happening in this case.
</li><li>Is it resistance to having code actually take advantage of integer
overflow, rather than it be a sign of a bug?
</li><li>Are non-power of two capacities for ring buffers actually
common?
</li></ul>

<p>
Join me next week for the exciting sequel to this post, &#34;I&#39;ve
been tying my shoelaces wrong all these years&#34;.

</p></div></div></div>
  </body>
</html>
