<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.google/technology/google-deepmind/gemini-computer-use-model/">Original</a>
    <h1>Gemini 2.5 Computer Use model</h1>
    
    <div id="readability-page-1" class="page"><article>

    
    


<section>
  
</section>


    

    
      








<div data-analytics-module="{
    &#34;module_name&#34;: &#34;Hero Menu&#34;,
    &#34;section_header&#34;: &#34;Introducing the Gemini 2.5 Computer Use model&#34;
  }">
  
  <div>
    <div>
      
      
        <p>
          Available in preview via the API, our Computer Use model is a specialized model built on Gemini 2.5 Pro’s capabilities to power agents that can interact with user interfaces.
        </p>
      
    </div>
  </div>
  
  <div>
    
    
      
        


<div data-component="uni-ai-generated-summary" data-analytics-module="{
    &#34;event&#34;: &#34;module_impression&#34;,
    &#34;module_name&#34;: &#34;ai_summary&#34;,
    &#34;section_header&#34;: &#34;CTA&#34;
  }">
  <div data-component="uni-ai-summary-btn">
    <div>
      
        <div data-summary-id="ai_summary_1">
          <h2>General summary</h2>
          <p>Google is releasing the Gemini 2.5 Computer Use model via the Gemini API, enabling developers to build agents that can interact with user interfaces. This model outperforms others in web and mobile control benchmarks with lower latency. You can access it now on Google AI Studio and Vertex AI to start building and share feedback in the Developer Forum.</p>
          
          <p><small>
            Summaries were generated by Google AI. Generative AI is experimental.
          </small>
        </p></div>
      

      

      </div>
  </div>
</div>

      
    
    
  </div>
</div>

    

    
      










<div>
  <div>
    <figure>
      <div>
        <p><img alt="Gemini Computer Use" data-component="uni-progressive-image" fetchpriority="high" height="150px" src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/CTU_2096x1182_RD6-V01.width-200.format-webp.webp" width="360px" data-sizes="(max-width: 1023px) 100vw,(min-width: 1024px and max-width: 1259) 80vw, 1046px" data-srcset="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/CTU_2096x1182_RD6-V01.width-800.format-webp.webp 800w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/CTU_2096x1182_RD6-V01.width-1200.format-webp.webp 1200w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/CTU_2096x1182_RD6-V01.width-1600.format-webp.webp 1600w, https://storage.googleapis.com/gweb-uniblog-publish-prod/images/CTU_2096x1182_RD6-V01.width-2200.format-webp.webp 2200w"/>
        </p>
      </div>
      
    </figure>
  </div>
</div>






    

    
    <section>
      <div>
        
          
          
          <div data-reading-time="true" data-component="uni-article-body">

            
              





<uni-article-speakable page-title="Introducing the Gemini 2.5 Computer Use model" listen-to-article="Listen to article" data-date-modified="2025-10-07T20:39:24.825126+00:00" data-tracking-ids="G-HGNBTNCHCQ,G-6NKTLKV14N" data-voice-list="en.ioh-pngnat:Cyan,en.usb-pngnat:Lime" data-script-src="https://www.gstatic.com/readaloud/player/web/api/js/api.js" data-highlight-mode="word-over-paragraph"></uni-article-speakable>

            

            
            
<!--article text-->

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Introducing the Gemini 2.5 Computer Use model&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><p data-block-key="pa3tk">Earlier this year, we <a href="https://www.youtube.com/live/o8NiE3XMPrM?si=9uCZ5JXT0xtGyr1H&amp;t=874">mentioned</a> that we&#39;re bringing computer use capabilities to developers via the Gemini API. Today, we are releasing the <a href="http://ai.google.dev/gemini-api/docs/computer-use">Gemini 2.5 Computer Use model</a>, our new specialized model built on Gemini 2.5 Pro’s visual understanding and reasoning capabilities that powers agents capable of interacting with user interfaces (UIs). It outperforms leading alternatives on multiple web and mobile control benchmarks, all with lower latency. Developers can access these capabilities via the Gemini API in <a href="http://ai.google.dev/gemini-api/docs/computer-use">Google AI Studio</a> and <a href="https://cloud.google.com/vertex-ai/generative-ai/docs/computer-use">Vertex AI</a>.</p><p data-block-key="b74v6">While AI models can interface with software through structured APIs, many digital tasks still require direct interaction with graphical user interfaces, for example, filling and submitting forms. To complete these tasks, agents must navigate web pages and applications just as humans do: by clicking, typing and scrolling. The ability to natively fill out forms, manipulate interactive elements like dropdowns and filters, and operate behind logins is a crucial next step in building powerful, general-purpose agents.</p><h2 data-block-key="2t6df">How it works</h2><p data-block-key="7bmpr">The model’s core capabilities are exposed through the new `computer_use` tool in the Gemini API and should be operated within a loop. Inputs to the tool are the user request, screenshot of the environment, and a history of recent actions. The input can also specify whether to exclude functions from the <a href="http://ai.google.dev/gemini-api/docs/computer-use#supported-actions">full list of supported UI actions</a> or specify additional custom functions to include.</p></div>
      </div>
    </div>
  

  
    














<uni-image-full-width alignment="full" alt-text="Diagram of AI agent loop: Initial task leads to a screenshot/context, which is sent to the Model, which returns a response to the computer environment to execute an action." external-image="" or-mp4-video-title="" or-mp4-video-url="" section-header="Introducing the Gemini 2.5 Computer Use model" custom-class="image-full-width--constrained-width uni-component-spacing">
  
    <div slot="caption-slot">
      <p data-block-key="9i6az">Gemini 2.5 Computer Use Model flow</p>
    </div>
  
  
    <p><img alt="Diagram of AI agent loop: Initial task leads to a screenshot/context, which is sent to the Model, which returns a response to the computer environment to execute an action." src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/CTU-Diagram-RD4-V01.width-100.format-webp.webp" loading="lazy" data-loading="{
            &#34;mobile&#34;: &#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/CTU-Diagram-RD4-V01.width-500.format-webp.webp&#34;,
            &#34;desktop&#34;: &#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/CTU-Diagram-RD4-V01.width-1000.format-webp.webp&#34;
          }"/>
    </p>
  
</uni-image-full-width>


  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Introducing the Gemini 2.5 Computer Use model&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><p data-block-key="pa3tk">The model then analyzes these inputs and generates a response, typically a function call representing one of the UI actions such as clicking or typing. This response may also contain a request for an end user confirmation, which is required for certain actions such as making a purchase. The client-side code then executes the received action.</p><p data-block-key="b440f">After the action is executed, a new screenshot of the GUI and the current URL are sent back to the Computer Use model as a function response restarting the loop. This iterative process continues until the task is complete, an error occurs or the interaction is terminated by a safety response or user decision.</p><p data-block-key="36n25">The Gemini 2.5 Computer Use model is primarily optimized for web browsers, but also demonstrates strong promise for mobile UI control tasks. It is not yet optimized for desktop OS-level control.</p><p data-block-key="79qun">Check out a few demos below to see the model in action (shown here at 3X speed).</p></div>
      </div>
    </div>
  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Introducing the Gemini 2.5 Computer Use model&#34;
         }">
      <div data-component="uni-article-paragraph">
        <p data-block-key="nly14"><b>Prompt:</b> “From <a href="https://tinyurl.com/pet-care-signup">https://tinyurl.com/pet-care-signup</a>, get all details for any pet with a California residency and add them as a guest in my spa CRM at <a href="https://pet-luxe-spa.web.app/">https://pet-luxe-spa.web.app/</a>. Then, set up a follow up visit appointment with the specialist Anima Lavar for October 10th anytime after 8am. The reason for the visit is the same as their requested treatment.”</p>
      </div>
    </div>
  

  
    
  
    




  <uni-youtube-player-article index="5" thumbnail-alt="Gemini Computer Use demo at a pet spa" video-id="_lu-FcPUIfM" video-type="video">
  </uni-youtube-player-article>











  


  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Introducing the Gemini 2.5 Computer Use model&#34;
         }">
      <div data-component="uni-article-paragraph">
        <p data-block-key="nly14"><b>Prompt: “</b>My art club brainstormed tasks ahead of our fair. The board is chaotic and I need your help organizing the tasks into some categories I created. Go to <a href="http://sticky-note-jam.web.app">sticky-note-jam.web.app</a> and ensure notes are clearly in the right sections. Drag them there if not.”</p>
      </div>
    </div>
  

  
    
  
    




  <uni-youtube-player-article index="7" thumbnail-alt="Demo of computer use model using sticky notes" video-id="slOLc1nkKY0" video-type="video">
  </uni-youtube-player-article>











  


  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Introducing the Gemini 2.5 Computer Use model&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><h2 data-block-key="pa3tk">How it performs</h2><p data-block-key="ac68d">The Gemini 2.5 Computer Use model demonstrates strong performance on multiple web and mobile control benchmarks. The table below includes results from self-reported numbers, evaluations run by Browserbase and evaluations we ran ourselves. Evaluation details are available in the <a href="https://storage.googleapis.com/deepmind-media/gemini/computer_use_eval_additional_info.pdf">Gemini 2.5 Computer Use evaluation info</a> and in <a href="https://www.browserbase.com/blog/evaluating-browser-agents">Browserbase’s blog post</a>. Unless otherwise indicated, scores shown are for computer use tools exposed via API.</p></div>
      </div>
    </div>
  

  
    














<uni-image-full-width alignment="full" alt-text="Benchmark performance table: Gemini 2.5 Computer Use leads in Online-Mind2Web, WebVoyager, and AndroidWorld benchmarks." external-image="" or-mp4-video-title="" or-mp4-video-url="" section-header="Introducing the Gemini 2.5 Computer Use model" custom-class="image-full-width--constrained-width uni-component-spacing">
  
    <div slot="caption-slot">
      <p data-block-key="9i6az">Gemini 2.5 Computer Use outperforms leading alternatives on multiple benchmarks</p>
    </div>
  
  
    <p><img alt="Benchmark performance table: Gemini 2.5 Computer Use leads in Online-Mind2Web, WebVoyager, and AndroidWorld benchmarks." src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/CTU-Benchmark_Chart-RD5_V01.width-100.format-webp.webp" loading="lazy" data-loading="{
            &#34;mobile&#34;: &#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/CTU-Benchmark_Chart-RD5_V01.width-500.format-webp.webp&#34;,
            &#34;desktop&#34;: &#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/CTU-Benchmark_Chart-RD5_V01.width-1000.format-webp.webp&#34;
          }"/>
    </p>
  
</uni-image-full-width>


  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Introducing the Gemini 2.5 Computer Use model&#34;
         }">
      <div data-component="uni-article-paragraph">
        <p data-block-key="pa3tk">The model offers leading quality for browser control at the lowest latency, as measured by performance on the Browserbase harness for Online-Mind2Web.</p>
      </div>
    </div>
  

  
    














<uni-image-full-width alignment="full" alt-text="Latency vs. Quality scatterplot: Gemini 2.5 Computer Use is lowest in latency and highest in accuracy (70%+ accuracy, ∼225 sec latency)." external-image="" or-mp4-video-title="" or-mp4-video-url="" section-header="Introducing the Gemini 2.5 Computer Use model" custom-class="image-full-width--constrained-width uni-component-spacing">
  
    <div slot="caption-slot">
      <p data-block-key="9i6az">Gemini 2.5 Computer Use delivers high accuracy while maintaining low latency</p>
    </div>
  
  
    <p><img alt="Latency vs. Quality scatterplot: Gemini 2.5 Computer Use is lowest in latency and highest in accuracy (70%+ accuracy, ∼225 sec latency)." src="https://storage.googleapis.com/gweb-uniblog-publish-prod/images/CTU-Scatterplot-RD7.width-100.format-webp.webp" loading="lazy" data-loading="{
            &#34;mobile&#34;: &#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/CTU-Scatterplot-RD7.width-500.format-webp.webp&#34;,
            &#34;desktop&#34;: &#34;https://storage.googleapis.com/gweb-uniblog-publish-prod/images/CTU-Scatterplot-RD7.width-1000.format-webp.webp&#34;
          }"/>
    </p>
  
</uni-image-full-width>


  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Introducing the Gemini 2.5 Computer Use model&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><h2 data-block-key="vcpc9">How we approached safety</h2><p data-block-key="26l5s">We believe that the only way to build agents that will benefit everyone is to be responsible from the start. AI agents that control computers introduce unique risks, including intentional misuse by users, unexpected model behavior, and prompt injections and scams in the web environment. Thus, it is critical to implement safety guardrails with care.</p><p data-block-key="ab068">We have trained safety features directly into the model to address these three key risks (described in the <a href="https://storage.googleapis.com/deepmind-media/Model-Cards/Gemini-2-5-Computer-Use-Model-Card.pdf">Gemini 2.5 Computer Use System Card</a>).</p><p data-block-key="7liej">Further, we also provide developers with safety controls, which empower developers to prevent the model from auto-completing potentially high-risk or harmful actions. Examples of these actions include harming a system&#39;s integrity, compromising security, bypassing CAPTCHAs, or controlling medical devices. The controls:</p><ul><li data-block-key="3f5gh"><b>Per-step safety service:</b> An out-of-model, inference-time safety service that assesses each action the model proposes before it’s executed.</li><li data-block-key="cu905"><b>System instructions:</b> Developers can further specify that the agent either refuses or asks for user confirmation before it takes specific kinds of high-stakes actions. (Example in <a href="https://googledevai.devsite.corp.google.com/gemini-api/docs/computer-use#supported-actions">documentation</a>).</li></ul><p data-block-key="65eg3">Additional recommendations for developers on safety measures and best practices can be found in our <a href="https://googledevai.devsite.corp.google.com/gemini-api/docs/computer-use#safety-best-practices">documentation</a>. While these safeguards are designed to reduce risk, we urge all developers to thoroughly test their systems before launch.</p></div>
      </div>
    </div>
  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Introducing the Gemini 2.5 Computer Use model&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><h2 data-block-key="pa3tk">How early testers have used it</h2><p data-block-key="cnndn">Google teams have already deployed the model to production for use cases including UI testing, which can make software development signficantly faster. Versions of this model have also been powering <a href="https://deepmind.google/models/project-mariner/">Project Mariner</a>, the <a href="https://firebase.blog/posts/2025/04/app-testing-agent/">Firebase Testing Agent</a>, and some agentic capabilities in <a href="https://blog.google/products/search/ai-mode-agentic-personalized/">AI Mode in Search</a>.</p><p data-block-key="9h8sv">Users from our early access program have also been testing the model to power personal assistants, workflow automation, and UI testing, and have seen strong results. In their own words:</p></div>
      </div>
    </div>
  

  
    




<uni-pull-quote content-style="block" quote="“A lot of our workflows require interacting with interfaces meant for humans where speed is especially important. Gemini 2.5 Computer Use is far ahead of the competition, often being 50% faster and better than the next best solutions we’ve considered.” - Poke.com, a proactive AI assistant in iMessage, WhatsApp and SMS with multiple third-party and agentic workflows." section-header="Introducing the Gemini 2.5 Computer Use model">
</uni-pull-quote>


  

  
    




<uni-pull-quote content-style="block" quote="“Our agents run fully autonomously, performing work where small mistakes in collecting and parsing data are unacceptable. Gemini 2.5 Computer Use outperformed other models at reliably parsing context in complex cases, increasing performance by up to 18% on our hardest evals.”  — Autotab, a drop-in AI agent." section-header="Introducing the Gemini 2.5 Computer Use model">
</uni-pull-quote>


  

  
    




<uni-pull-quote content-style="block" quote="“When conventional scripts encounter failures, the model assesses the current screen state and autonomously ascertains the required actions to complete the workflow. This implementation now successfully rehabilitates over 60% of executions (which used to take multiple days to fix).” — Google’s payments platform team, which implemented the Computer Use model as a contingency mechanism to address fragile end-to-end UI tests that contributed to 25% of all test failures." section-header="Introducing the Gemini 2.5 Computer Use model">
</uni-pull-quote>


  

  
    <div role="presentation" data-analytics-module="{
           &#34;module_name&#34;: &#34;Paragraph&#34;,
           &#34;section_header&#34;: &#34;Introducing the Gemini 2.5 Computer Use model&#34;
         }">
      <div data-component="uni-article-paragraph">
        <div><h2 data-block-key="22clf">How to get started</h2><p data-block-key="envv8">Starting today, the model is available in public preview, accessible via the Gemini API on Google AI Studio and Vertex AI.</p><ul><li data-block-key="b1ua4"><b>Try it now:</b> In a demo environment hosted by <a href="http://gemini.browserbase.com/">Browserbase</a>.</li><li data-block-key="fdtcr"><b>Start building</b>: Dive into our <a href="https://github.com/google/computer-use-preview">reference</a> and <a href="http://ai.google.dev/gemini-api/docs/computer-use">documentation</a> (see <a href="https://cloud.google.com/vertex-ai/generative-ai/docs/computer-use">Vertex AI docs for enterprise use</a>) to learn how to build your own agent loop locally with Playwright or in a cloud VM with Browserbase.</li><li data-block-key="ds8mg"><b>Join the community:</b> We’re excited to see what you build. Share feedback and help guide our roadmap in our <a href="https://discuss.ai.google.dev/c/gemini-api/4">Developer Forum</a>.</li></ul></div>
      </div>
    </div>
  


            
            

            
              




            
          </div>
        
      </div>
    </section>
  </article></div>
  </body>
</html>
