<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.nature.com/articles/s41586-023-06004-9">Original</a>
    <h1>Deepmind Alphadev: Faster sorting algorithms discovered using deep RL</h1>
    
    <div id="readability-page-1" class="page"><div>
                <section data-title="Main"><div id="Sec1-section"><h2 id="Sec1">Main</h2><div id="Sec1-content"><p>Human intuition and know-how have been crucial in improving algorithms. However, many algorithms have reached a stage whereby human experts have not been able to optimize them further, leading to an ever-growing computational bottleneck. The work in classical program synthesis literature, spanning many decades, aims to generate correct programs and/or optimize programs using proxies for latency. These include enumerative search techniques<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Bansal, S. &amp; Aiken, A. Automatic generation of peephole superoptimizers. ACM SIGARCH Comput. Arch. News 34, 394–403 (2006)." href="#ref-CR4" id="ref-link-section-d81547407e677">4</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Alur, R. et al. Syntax-Guided Synthesis (IEEE, 2013)." href="#ref-CR5" id="ref-link-section-d81547407e677_1">5</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Phothilimthana, P. M. et al. Scaling up superoptimization. In Proc. Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems 297–310 (ACM, 2016)." href="#ref-CR6" id="ref-link-section-d81547407e677_2">6</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Barthe, G. et al. From relational verification to SIMD loop synthesis. In Proc. of the 18th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming 123–134 (ACM, 2013)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR7" id="ref-link-section-d81547407e680">7</a></sup> and stochastic search<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Alur, R. et al. Syntax-Guided Synthesis (IEEE, 2013)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR5" id="ref-link-section-d81547407e684">5</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Phothilimthana, P. M. et al. Scaling up superoptimization. In Proc. Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems 297–310 (ACM, 2016)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR6" id="ref-link-section-d81547407e687">6</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Schkufza, E., Sharma, R. &amp; Aiken, A. Stochastic superoptimization. ACM SIGPLAN Notices 48, 305–315 (2013)." href="#ref-CR8" id="ref-link-section-d81547407e690">8</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Bunel, R. et al. Learning to superoptimize programs. In Proc. International Conference on Learning Representations (ICLR, 2016)." href="#ref-CR9" id="ref-link-section-d81547407e690_1">9</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="Phothilimthana, P. M. et al. Chlorophyll: synthesis-aided compiler for low-power spatial architectures. ACM SIGPLAN Notices 49, 396–407 (2014)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR10" id="ref-link-section-d81547407e693">10</a></sup> as well as the more recent trend of using deep learning in program synthesis for generating correct programs<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Vinyals, O. et al. Grammar as a foreign language. Adv. Neural Inform. Proc. Syst. 28, 2773–2781 (2015)." href="#ref-CR11" id="ref-link-section-d81547407e697">11</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Chen, X., Liu, C. &amp; Song, D. Towards synthesizing complex programs from input-output examples. In Proc. International Conference on Learning Representations (ICLR, 2018)." href="#ref-CR12" id="ref-link-section-d81547407e697_1">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Devlin, J. et al. Robustfill: neural program learning under noisy i/o. In Proc. International Conference on Machine Learning 990–998 (PMLR, 2017)." href="#ref-CR13" id="ref-link-section-d81547407e697_2">13</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Li, Y. et al. Competition-level code generation with AlphaCode. Science 378, 1092–1097 (2022)." href="#ref-CR14" id="ref-link-section-d81547407e697_3">14</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Pearce, H. et al. Can codex and other large language models help us fix security bugs? Preprint at 
                  https://arxiv.org/abs/2112.02125
                  
                 (2021)." href="#ref-CR15" id="ref-link-section-d81547407e697_4">15</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Chen, M. et al. Evaluating large language models trained on code. Preprint at 
                  https://arxiv.org/abs/2107.03374
                  
                 (2021)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR16" id="ref-link-section-d81547407e700">16</a></sup>. Using deep reinforcement learning (DRL), we can take this a step further by generating correct and performant algorithms by optimizing for actual measured latency at the CPU instruction level, by more efficiently searching and considering the space of correct and fast programs compared to previous work.</p><p>One of the fundamental questions in computer science is how to sort a sequence<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Bingmann, T., Marianczuk, J. &amp; Sanders, P. Engineering faster sorters for small sets of items. Software: Pract. Exper. 51, 965–1004 (2021)." href="#ref-CR17" id="ref-link-section-d81547407e707">17</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Levcopoulos, C. &amp; Petersson, O. Splitsort: an adaptive sorting algorithm. Inform. Proc. Lett. 39, 205–211 (1991)." href="#ref-CR18" id="ref-link-section-d81547407e707_1">18</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Helman, D. R., Bader, D. A. &amp; JáJá, J. A randomized parallel sorting algorithm with an experimental study. J. Parallel Distrib. Comput. 52, 1–23 (1998)." href="#ref-CR19" id="ref-link-section-d81547407e707_2">19</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Goodrich, M. T. Randomized shellsort: a simple oblivious sorting algorithm. In Proc. of the Twenty-First Annual ACM-SIAM Symposium on Discrete Algorithms 1262–1277 (ACM, 2010)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR20" id="ref-link-section-d81547407e710">20</a></sup>. This is taught in elementary computer science classes around the world<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="Mehlhorn, K., Sanders, P. &amp; Sanders, P. Algorithms and Data Structures: The Basic Toolbox Vol. 55. (Springer, 2008)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR21" id="ref-link-section-d81547407e714">21</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 22" title="Knebl, H. Algorithms and Data Structures (Springer, 2020)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR22" id="ref-link-section-d81547407e717">22</a></sup> and is used ubiquitously by a vast range of applications<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Karatzoglou, A., Baltrunas, L. &amp; Shi, Y. Learning to rank for recommender systems. In Proc. of the 7th ACM Conference on Recommender Systems 493–494 (ACM, 2013)." href="#ref-CR23" id="ref-link-section-d81547407e721">23</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Yang, J. Y., Zhang, B. &amp; Mao, Y. Study on Information Retrieval Sorting Algorithm in Network-BasedManufacturing Environment. In Applied Mechanics and Materials Vol. 484, 183–186 (Trans Tech Publishing, 2014)." href="#ref-CR24" id="ref-link-section-d81547407e721_1">24</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Krallmann, J., Schwiegelshohn, U. &amp; Yahyapour, R. On the design and evaluation of job schedulingalgorithms. In Workshop on Job Scheduling Strategies for Parallel Processing 17–42 (Springer, 1999)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR25" id="ref-link-section-d81547407e724">25</a></sup>. Decades of computer science research have focused on discovering and optimizing sorting algorithms<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="White, S. K., Martinez, T. &amp; Rudolph, G. Generating a novel sort algorithm using Reinforcement Programming. In Proc. IEEE Congress on Evolutionary Computation 1–8 (IEEE, 2010)." href="#ref-CR26" id="ref-link-section-d81547407e728">26</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Srivastava, S., Gulwani, S. &amp; Foster, J. S. From program verification to program synthesis. In Proc. of the 37th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages 313–326 (ACM, 2010)." href="#ref-CR27" id="ref-link-section-d81547407e728_1">27</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 28" title="Ansel, J. et al. Petabricks: a language and compiler for algorithmic choice. ACM Sigplan Notices 44, 38–49 (2009)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR28" id="ref-link-section-d81547407e731">28</a></sup>. A key component of practical solutions is a small sort over a short sequence of elements; this algorithm is called repeatedly when sorting large arrays that use divide-and-conquer approaches<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 29" title="Smith, D. R. The design of divide and conquer algorithms. Sci. Comput. Program. 5, 37–58 (1985)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR29" id="ref-link-section-d81547407e735">29</a></sup>. In this work, we focus on two types of small sort algorithm: (1) the fixed sort and (2) the variable sort. Fixed sort algorithms sort sequences of a fixed length (for example, sort 3 can only sort sequences of length 3), whereas variable sort algorithms can sort a sequence of varying size (for example, variable sort 5 can sort sequences ranging from one to five elements).</p><p>We formulate the problem of discovering new, efficient sorting algorithms as a single-player game that we refer to as AssemblyGame. In this game, the player selects a series of low-level CPU instructions, which we refer to as assembly instructions<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 30" title="Irvine, K. R. et al. Assembly Language for Intel-Based Computers (Prentice Hall, 2003)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR30" id="ref-link-section-d81547407e742">30</a></sup>, to combine to yield a new and efficient sorting algorithm. This is challenging as the player needs to consider the combinatorial space of assembly instructions to yield an algorithm that is both provably correct and fast. The hardness of the AssemblyGame arises not only from the size of the search space, which is similar to extremely challenging games such as chess (10<sup>120</sup> games)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 31" title="Shannon, C. E. XXII. Programming a computer for playing chess. London, Edinb. Dublin Philos. Mag. J. Sci. 41.314, 256–275 (1950)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR31" id="ref-link-section-d81547407e748">31</a></sup> and Go (10<sup>700</sup> games)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 32" title="Silver, D. et al. Mastering the game of Go with deep neural networks and tree search. Nature 529, 484–489 (2016)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR32" id="ref-link-section-d81547407e754">32</a></sup>, but also from the nature of the reward function. A single incorrect instruction in the AssemblyGame can potentially invalidate the entire algorithm, making exploration in this space of games incredibly challenging.</p><p>To play the game, we introduce AlphaDev, a learning agent that is trained to search for correct and efficient algorithms. This agent is comprised of two core components, namely (1) a learning algorithm and (2) a representation function. The AlphaDev learning algorithm can incorporate both DRL as well as stochastic search optimization algorithms to play AssemblyGame. The primary learning algorithm in AlphaDev is an extension of AlphaZero<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 33" title="Silver, D. et al. A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play. Science 362, 1140–1144 (2018)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR33" id="ref-link-section-d81547407e761">33</a></sup>, a well-known DRL algorithm, in which a neural network is trained to guide a search to solve AssemblyGame. The representation function is interchangeable and captures the underlying structure of assembly programs. The primary AlphaDev representation is based on Transformers<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 34" title="Vaswani, A. et al. Attention is all you need. Adv. Neural Inform. Proc. Syst. 30, 5999–6009 (2017)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR34" id="ref-link-section-d81547407e765">34</a></sup>.</p><p>Using AlphaDev, we have discovered fixed and variable sort algorithms from scratch that are both new and more efficient than the state-of-the-art human benchmarks. The fixed sort solutions for sort 3, sort 4 and sort 5 discovered by AlphaDev have been integrated into the standard sort function in the LLVM standard C++ library<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Gelmi, M. Introduce branchless sorting functions for sort3, sort4 and sort5. LLVM.org 
                  https://reviews.llvm.org/D118029
                  
                 (2022)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR3" id="ref-link-section-d81547407e773">3</a></sup>. This library is used by several million users including universities and numerous international companies<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 35" title="LLVM. LLVM users 
                  https://llvm.org/Users.html
                  
                 (LLVM, 2022)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR35" id="ref-link-section-d81547407e777">35</a></sup>. In addition, we analyse the new algorithm discoveries, compare AlphaDev to stochastic search optimization approaches and apply AlphaDev to further domains to showcase the generality of the approach.</p></div></div></section><section data-title="Representing algorithms as low-level CPU instructions"><div id="Sec2-section"><h2 id="Sec2">Representing algorithms as low-level CPU instructions</h2><div id="Sec2-content"><p>When compiling algorithms to machine code from a high level language such as C++ (for example, the sorting function in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Fig1">1a</a>), the algorithm is first compiled into assembly (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Fig1">1b</a>). The assembler then converts the assembly program into executable machine code. In this work, we optimize algorithms at the assembly level<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 30" title="Irvine, K. R. et al. Assembly Language for Intel-Based Computers (Prentice Hall, 2003)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR30" id="ref-link-section-d81547407e795">30</a></sup>. In a typical assembly program, the values are copied from memory into registers, manipulated between registers and then written back to memory. The set of assembly instructions supported depends on the processor architecture. For the purposes of this work, we focus on a subset of assembly instructions supported by the x86 processor architecture using the AT&amp;T syntax<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 36" title="Bartlett, J. Learn to Program with Assembly 271–273 (Apress, 2021)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR36" id="ref-link-section-d81547407e799">36</a></sup>. Each instruction is of the format Opcode<span>⟨</span>Operand<sub>A</sub>, Operand<sub>B</sub><span>⟩</span>. An example instruction is mov<a,b>, which is defined as move a value from source (A) to destination (B). Further instruction definitions such as compare (cmp<a,b>), conditional move (cmovX<a,b>) and jump (jX<a>) can be found in Extended Data Table </a></a,b></a,b></a,b><a data-track="click" data-track-label="link" data-track-action="table anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Tab3">1</a>. In the example in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Fig1">1b</a>, %eax, %ecx, %edx, %edi correspond to four different register locations and (%rsi), 4(%rsi) correspond to two different memory locations. The symbol $2 is a placeholder for a constant value, which corresponds to the length of the vector in this example. We use the terms assembly program and assembly algorithm interchangeably in this work. This is because AlphaDev builds an assembly program from scratch, from an initially unordered set of instructions, each time it plays AssemblyGame, defining a new and efficient algorithm.</p><div data-test="figure" data-container-section="figure" id="figure-1" data-title="The relationship between C++ and assembly programs."><figure><figcaption><b id="Fig1" data-test="figure-caption-text">Fig. 1: The relationship between C++ and assembly programs.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s41586-023-06004-9/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41586-023-06004-9/MediaObjects/41586_2023_6004_Fig1_HTML.png?as=webp"/><img aria-describedby="Fig1" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41586-023-06004-9/MediaObjects/41586_2023_6004_Fig1_HTML.png" alt="figure 1" loading="lazy" width="685" height="255"/></picture></a></div><p><b>a</b>, A C++ implementation of a variable sort 2 function that sorts any input sequence of up to two elements. <b>b</b>, The C++ implementation in <b>a</b> is compiled to this equivalent low-level assembly representation.</p></div></figure></div></div></div></section><section data-title="DRL for discovering faster algorithms"><div id="Sec3-section"><h2 id="Sec3">DRL for discovering faster algorithms</h2><div id="Sec3-content"><p>In this section, we formulate optimizing algorithms at the CPU instruction level as a reinforcement learning (RL) problem<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 37" title="Sutton, R. S. &amp; Barto, A. G. Reinforcement Learning: An Introduction 2nd edn (MIT Press, 2018)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR37" id="ref-link-section-d81547407e850">37</a></sup>, in which the environment is modelled as a single-player game that we refer to as AssemblyGame. Each state in this game is defined as a vector <b>S</b><sub><b>t</b></sub> = <span>⟨</span><b>P</b><sub><b>t</b></sub>, <b>Z</b><sub><b>t</b></sub><span>⟩</span> where <b>P</b><sub><b>t</b></sub> is a representation of the algorithm generated thus far in the game and <b>Z</b><sub><b>t</b></sub> represents the state of memory and registers after executing the current algorithm on a set of predefined inputs. As seen in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Fig2">2a</a>, at timestep <i>t</i>, the player receives the current state <b>S</b><sub><b>t</b></sub> and executes an action <b>a</b><sub><b>t</b></sub>. This involves appending a legal assembly instruction (for example, mov&lt;A,B&gt;) to the current algorithm generated thus far. A reward <i>r</i><sub><b>t</b></sub>is received that comprises both a measure of algorithm correctness and latency. Algorithm correctness (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Fig2">2b</a>) involves inputting a set of <i>N</i> test sequences into the current algorithm <b>P</b><sub><b>t</b></sub> to generate <i>N</i> outputs. These outputs are then compared to the expected outputs and a correctness reward <i>r</i><sub><b>t</b></sub> is computed. Latency rewards can be generated by either (1) penalizing the agent for increasing the length of the algorithm (when length and latency are highly correlated) that we refer to as the algorithm length reward, or (2) measuring the actual latency of the algorithm. The game is executed for a limited number of steps, after which the game is terminated. Winning the game corresponds to generating a correct, low-latency algorithm using assembly instructions. Losing the game corresponds to generating an incorrect algorithm or a correct but inefficient algorithm.</p><div data-test="figure" data-container-section="figure" id="figure-2" data-title="The AssemblyGame and algorithm correctness computation."><figure><figcaption><b id="Fig2" data-test="figure-caption-text">Fig. 2: The AssemblyGame and algorithm correctness computation.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s41586-023-06004-9/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41586-023-06004-9/MediaObjects/41586_2023_6004_Fig2_HTML.png?as=webp"/><img aria-describedby="Fig2" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41586-023-06004-9/MediaObjects/41586_2023_6004_Fig2_HTML.png" alt="figure 2" loading="lazy" width="685" height="281"/></picture></a></div><p><b>a</b>, The AssemblyGame is played by AlphaDev, which receives as input the current assembly algorithm generated thus far <b>S</b><sub><b>t</b></sub> and plays the game by selecting an action to execute. In this example, the action is a mov&lt;Register<sub>0</sub>,Memory<sub>1</sub>&gt; assembly instruction, which is appended to the current algorithm. The agent receives a reward that is a function of the algorithm’s correctness, discussed in <b>b</b>, as well as the algorithm’s latency. The game is won by the player discovering a low latency, correct algorithm. <b>b</b>, The program correctness and latency computations are used to compute the reward <i>r</i><sub>t</sub>. In this example, test sequences are input to the algorithm; for example, in the case of sorting three elements, test inputs comprise all sequences of unsorted elements of length 3. For each sequence, the algorithm output is compared to the expected output (in the case of sorting, the expected output is the sorted elements). In this example, the output <span>\({\bf{D}}{\boldsymbol{{\prime} }}\)</span> does not match the expected output <span>\({\bf{B}}{\boldsymbol{{\prime} }}\)</span> and the algorithm is therefore incorrect.</p></div></figure></div><p>We refer to the agent that plays this single-player game as AlphaDev. The agent’s primary learning algorithm is an extension of the AlphaZero agent<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 32" title="Silver, D. et al. Mastering the game of Go with deep neural networks and tree search. Nature 529, 484–489 (2016)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR32" id="ref-link-section-d81547407e1026">32</a></sup> and guides a Monte Carlo tree search (MCTS) planning procedure using a deep neural network<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 33" title="Silver, D. et al. A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play. Science 362, 1140–1144 (2018)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR33" id="ref-link-section-d81547407e1030">33</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 38" title="Schrittwieser, J. et al. Mastering atari, go, chess and shogi by planning with a learned model. Nature 588, 604–609 (2020)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR38" id="ref-link-section-d81547407e1033">38</a></sup>. The input to the neural network is the state <b>S</b><sub><b>t</b></sub> and the output is a policy and value prediction. The policy prediction is a distribution over actions and the value function is a prediction of the cumulative returns <i>R</i> that the agent should expect to receive from the current state <b>S</b><sub><b>t</b></sub>. During a game, the agent receives as input the current state <b>S</b><sub><b>t</b></sub>. The agent then executes an MCTS procedure and uses this to select the next action to take. The generated games are then used to update the network’s parameters, enabling the agent to learn.</p><p>It is critical that AlphaDev has a representation<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 39" title="Maillard, O.-A., Ryabko, D. &amp; Munos, R. Selecting the state-representation in reinforcement learning. Adv. Neural Inform. Proc. Syst. 24, 2627–2635 (2011)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR39" id="ref-link-section-d81547407e1062">39</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 40" title="Qian, R. et al. Spatiotemporal contrastive video representation learning. In Proc. IEEE/CVF Conference on Computer Vision and Pattern Recognition 6964–6974 (IEEE, 2021)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR40" id="ref-link-section-d81547407e1065">40</a></sup> capable of representing complex algorithmic structures to efficiently explore the space of instructions. To achieve this, we introduce the AlphaDev representation network (Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Fig5">1a</a>). This network comprises two components, namely (1) a transformer encoder network that provides the agent with a representation of the algorithm structure, and (2) the CPU state encoder network that helps the agent predict how the algorithm affects the dynamics of memory and registers. The CPU state encoder network comprises a multilayer perceptron that receives as input the state of each register and memory location for a given set of inputs. These networks each output embeddings that are combined to yield the AlphaDev state representation.</p><h3 id="Sec4">Transformer encoder</h3><p>Transformers are natural text encoders and have had much success with language models recently<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Li, Y. et al. Competition-level code generation with AlphaCode. Science 378, 1092–1097 (2022)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR14" id="ref-link-section-d81547407e1079">14</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 34" title="Vaswani, A. et al. Attention is all you need. Adv. Neural Inform. Proc. Syst. 30, 5999–6009 (2017)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR34" id="ref-link-section-d81547407e1082">34</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 41" title="Brown, T. et al. Language models are few-shot learners. Adv. Neural Inform. Proc. Syst. 33, 1877–1901 (2020)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR41" id="ref-link-section-d81547407e1085">41</a></sup>. As such, this motivated us to adapt the standard transformer to model assembly instructions. We developed and incorporated a transformer encoder, our adaptation of the MultiQuery transformer encoder<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 42" title="Shazeer, N. Fast transformer decoding: one write-head is all you need. Preprint at 
                  https://arxiv.org/abs/1911.02150
                  
                 (2019)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR42" id="ref-link-section-d81547407e1089">42</a></sup>, into the AlphaDev representation network to represent the assembly instructions. Each assembly instruction’s Opcode and corresponding Operands are converted to one-hot encodings and concatenated to form the raw input sequence. This is fed through a multilayer transformer encoder, which maps it to corresponding embedding vectors (see Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Fig5">1b</a> for an illustration).</p><h3 id="Sec5">Latency value functions</h3><p>Latency is an important reward signal that is used to guide the agent in discovering performant algorithms. To better estimate latency, we implemented a dual value function setup, whereby AlphaDev has two value function heads: one predicting algorithm correctness and the second predicting algorithm latency. The latency head is used to directly predict the latency of a given program by using the program’s actual computed latency as a Monte Carlo target for AlphaDev during training. This dual-head approach achieved substantially better results than the vanilla, single head value function setup when optimizing for real latency.</p></div></div></section><section data-title="Results"><div id="Sec6-section"><h2 id="Sec6">Results</h2><div id="Sec6-content"><h3 id="Sec7">Discovering faster sort algorithms</h3><p>We trained the AlphaDev agent from scratch to generate a range of fixed sort and variable sort algorithms that are both correct and achieve lower latency than the state-of-the-art human benchmarks.</p><h3 id="Sec8">Fixed sorting algorithms</h3><p>We considered three fundamental algorithms: sort 3, sort 4 and sort 5. The state-of-the-art human benchmarks for these algorithms are sorting networks<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 43" title="Bundala, D. &amp; Závodny, J. Optimal sorting networks. In Proc. International Conference on Language and Automata Theory and Applications 236–247 (Springer, 2014)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR43" id="ref-link-section-d81547407e1126">43</a></sup> as they generate efficient, conditional branchless assembly code. This means that all instructions are executed sequentially and there is no branching involved. Improving on these algorithms is challenging as they are already highly optimized. As seen in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Tab1">1a</a>, AlphaDev is able to find algorithms with fewer instructions than the human benchmarks for sort 3 and sort 5 and matches the state-of-the-art performance on sort 4. These shorter algorithms do indeed lead to lower latency as the algorithm length and latency are correlated for the conditional branchless case; see Appendix B in <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41586-023-06004-9#MOESM1">Supplementary Information</a> for more details. We also explored scaling to slightly larger sorts using a variant of AlphaDev. We managed to save three instructions on sort 6, two instructions on sort 7 and one instruction on sort 8, which provides a promising basis for future work. See Appendix C in <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41586-023-06004-9#MOESM1">Supplementary Information</a> for an overview of the approach.</p><div data-test="inline-table" data-container-section="table" id="table-1"><figure><figcaption><b id="Tab1" data-test="table-caption">Table 1 AlphaDev performance when optimizing for algorithm length and latency</b></figcaption></figure></div><h3 id="Sec9">Variable sorting algorithms</h3><p>We considered three variable sorting algorithms: VarSort3, VarSort4 and VarSort5. The human benchmark in each case is defined as an algorithm that, for a given input length, calls the corresponding sorting network. In this case, branching is required, which greatly increases the complexity of the problem as the agent needs to (1) determine how many subalgorithms it needs to construct and (2) build the body of the main algorithm in parallel. The agent may also need to call subalgorithms from other subalgorithms. In this case, optimizing for length leads to significantly shorter algorithms compared to the human benchmarks as seen in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Tab1">1a</a>. However, owing to the complexities introduced by branching, latency and length are not always correlated; see <a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Sec42">Supplementary Information</a> for more details. As such, we implemented a procedure that measures the actual latency of the programs by taking the fifth percentile of latency measurements across 100 different machines, with computed confidence intervals<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 44" title="Hahn, G. J. &amp; Meeker, W. Q. Statistical Intervals: A Guide for Practitioners Vol. 92 (John Wiley &amp; Sons, 2011)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR44" id="ref-link-section-d81547407e1489">44</a></sup>, and optimize this metric. See <a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Sec18">Methods</a> for the full benchmarking setup. When optimizing for latency, the agent improves significantly on the human benchmarks in each case as seen in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Tab1">1b</a>.</p><h3 id="Sec10">New algorithm discoveries</h3><p>The solutions discovered by AlphaDev include new and exciting algorithmic discoveries that lead to more efficient performance. In the fixed sort setting, we found that AlphaDev discovered two interesting sequences of instructions that, when applied to a sorting network algorithm, reduce the algorithm by one assembly instruction each time. We refer to each sequence of instructions as (1) the AlphaDev swap move and (2) the AlphaDev copy move respectively.</p><h3 id="Sec11">AlphaDev swap move</h3><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Fig3">3a</a> presents an optimal sorting network for three elements (see <a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Sec18">Methods</a> for an overview of sorting networks). We will explain how AlphaDev has improved the circled network segment. There are many variants of this structure that are found in sorting networks of various sizes, and the same argument applies in each case. The circled part of the network (last two comparators) can be seen as a sequence of instructions that takes an input sequence <span>⟨</span>A, B, C<span>⟩</span> and transforms each input as shown in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Tab2">2a</a> (left). However, a comparator on wires B and C precedes this operator and therefore input sequences where B ≤ C are guaranteed. This means that it is enough to compute min(A, B) as the first output instead of min(A, B, C) as shown in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Tab2">2a</a> (right). The pseudocode difference between Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Fig3">3b,c</a> demonstrates how the AlphaDev swap move saves one instruction each time it is applied.</p><div data-test="figure" data-container-section="figure" id="figure-3" data-title="Sorting networks and algorithmic improvements discovered by AlphaDev."><figure><figcaption><b id="Fig3" data-test="figure-caption-text">Fig. 3: Sorting networks and algorithmic improvements discovered by AlphaDev.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s41586-023-06004-9/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41586-023-06004-9/MediaObjects/41586_2023_6004_Fig3_HTML.png?as=webp"/><img aria-describedby="Fig3" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41586-023-06004-9/MediaObjects/41586_2023_6004_Fig3_HTML.png" alt="figure 3" loading="lazy" width="685" height="572"/></picture></a></div><p><b>a</b>, An optimal classic sorting network for three inputs. The circled comparators have been improved by AlphaDev. See the AlphaDev swap move for more details. <b>b</b>,<b>c</b>, The assembly pseudocode before applying the AlphaDev swap move (<b>b</b>) and after applying the AlphaDev swap move (<b>c</b>), resulting in the removal of a single instruction. <b>d</b>, An optimal classic sorting network comparator configuration that has been improved by AlphaDev. See the AlphaDev copy move for more details. <b>e</b>,<b>f</b>, The assembly pseudocode before applying the AlphaDev copy move (<b>e</b>) and after applying the AlphaDev copy move (<b>f</b>), resulting in the removal of a single instruction.</p></div></figure></div><div data-test="inline-table" data-container-section="table" id="table-2"><figure><figcaption><b id="Tab2" data-test="table-caption">Table 2 Analysis of the AlphaDev swap and copy moves</b></figcaption></figure></div><h3 id="Sec12">AlphaDev copy move</h3><p>Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Fig3">3d</a> presents a sorting network configuration, consisting of three comparators, that is applied across four wires. This configuration is found in a sort 8 sorting network and corresponds to an operator taking four inputs <span>⟨</span>A, B, C, D<span>⟩</span> and transforming them into four outputs as seen in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Tab2">2b</a> (on the left). One can show that as part of sort 8, the input that flows into the operator satisfies the following inequality: <span>\({\rm{D}}\ge \min ({\rm{A}},{\rm{C}})\)</span>. This means that the operator can be improved by applying the AlphaDev copy move that is defined in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Tab2">2b</a> (on the right), resulting in one instruction less than the original operator. The code difference between the original operator and the code after applying the AlphaDev copy move is visualized in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Fig3">3e,f</a>, respectively.</p><h3 id="Sec13">New variable sort algorithms</h3><p>The VarSort4 algorithm discovered by AlphaDev is particularly interesting. The flow diagram for the human benchmark algorithm and AlphaDev can be seen in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Fig4">4a,b</a>, respectively. The human benchmark algorithm determines the length of the input vector, and then calls the corresponding sorting network to sort the elements. The AlphaDev solution has a completely different approach as seen in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Fig4">4b</a>. If the length of the input vector is strictly greater than 2, then sort 3 is immediately called, resulting in the first three elements being sorted. If the vector is greater than three elements, then a simplified sort 4 algorithm is called that sorts the remaining unsorted elements in the input vector. It is this simplified part of the routine that yields significant gains in terms of algorithmic length and latency.</p><div data-test="figure" data-container-section="figure" id="figure-4" data-title="Fundamentally different algorithms discovered by AlphaDev."><figure><figcaption><b id="Fig4" data-test="figure-caption-text">Fig. 4: Fundamentally different algorithms discovered by AlphaDev.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s41586-023-06004-9/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41586-023-06004-9/MediaObjects/41586_2023_6004_Fig4_HTML.png?as=webp"/><img aria-describedby="Fig4" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41586-023-06004-9/MediaObjects/41586_2023_6004_Fig4_HTML.png" alt="figure 4" loading="lazy" width="685" height="293"/></picture></a></div><p><b>a</b>, A flow diagram of the variable sort 4 (VarSort4) human benchmark algorithm. In this algorithm, a sequence of unsorted numbers are input into the algorithm. If the sequence length is four, three or two numbers, then the corresponding sort 4, sort 3 or sort 2 sorting network is called that sorts the resulting sequence. The result is then returned and output by the function. <b>b</b>, The VarSort4 algorithm discovered by AlphaDev. This algorithm also receives sequences of length four, three or two numbers as input. In this case, if the length is two, then it calls the sort 2 sorting network and returns. If the length is three then it calls sort 3 to sort the first three numbers and returns. If, however, the length is greater than three, then it calls sort 3, followed by a simplified sort 4 routine that sorts the remaining unsorted number. It is this part of the routine that results in significant latency savings.</p></div></figure></div><h3 id="Sec14">Stochastic search optimization approaches</h3><p>It is important to understand the advantages and limitations of RL compared to other approaches for program optimization. As such, we implemented a state-of-the-art stochastic superoptimization approach<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Schkufza, E., Sharma, R. &amp; Aiken, A. Stochastic superoptimization. ACM SIGPLAN Notices 48, 305–315 (2013)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR8" id="ref-link-section-d81547407e1917">8</a></sup>, adapted it to the sort setting and used it as the learning algorithm in AlphaDev. We refer to this variant as AlphaDev-S (see <a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Sec18">Methods</a> for more details). We run this algorithm with at least the same amount of resources and wall-clock time as AlphaDev. AlphaDev-S requires a prohibitive amount of time to optimize directly for latency as latency needs to be computed after every mutation. As such, AlphaDev-S optimizes for a latency proxy, namely algorithm length and, then, at the end of training, we search through all correct programs generated by AlphaDev-S and benchmark each one to find the lowest latency solution. In general, we find that AlphaDev consistently outperforms AlphaDev-S when learning from scratch without previous knowledge. In addition, as the size of the program increases, AlphaDev explores orders of magnitude fewer programs (12 million programs in the worst case) compared to AlphaDev-S (31 trillion programs in the worst case). This may be because AlphaDev is able to better explore the space of algorithms compared to the breadth-first stochastic search procedure that gets stuck more easily into local optima; see <a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Sec18">Methods</a> for an overview of this exploration hypothesis. In addition, AlphaDev never evaluates latency during search as it uses the latency value function predictions and, because of this, only needs to compute actual measured latency on less than 0.002% of generated programs. When incorporating previous knowledge into AlphaDev-S, such as warm starting the learning algorithm with a near-optimal solution, AlphaDev-S is more computationally efficient for sort 3, sort 4 and sort 5 (branchless assembly algorithms) and also generates competitive low-latency algorithms to that of AlphaDev in each case. However, for algorithms that require branching (if–else statements), in which algorithm length and latency are not well correlated, AlphaDev discovers lower latency solutions than AlphaDev-S, even when warm starting this algorithm with a near-optimal solution. See <a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Sec18">Methods</a> for an in-depth analysis of these algorithms.</p><h3 id="Sec15">Generalization to additional domains</h3><p>To test the generality of AlphaDev, we train the agent on a set of additional domains. These include a protocol buffer deserialization subroutine called VarInt, presented below, and a competitive coding problem (see Appendix D in <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41586-023-06004-9#MOESM1">Supplementary Information</a> for more details). The competitive coding domain latency performance is reported in Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Tab1">1b</a>.</p><p>Protocol Buffer is Google’s open-source data format used to serialize structured data<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 45" title="Google. Protocol buffers, version 0.2.5; 
                  https://developers.google.com/protocol-buffers
                  
                 (2022)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR45" id="ref-link-section-d81547407e1947">45</a></sup>. This format is commonly used in cases in which performance or network load is of primary concern. The VarInt algorithm<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 46" title="Google. VarInt protocol buffer serialization and deserialization, version 0.2.5; 
                  https://developers.google.com/protocol-buffers/docs/encoding
                  
                 (2022)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR46" id="ref-link-section-d81547407e1951">46</a></sup> is a key component in both the serialization and deserialization processes. We trained the AlphaDev agent as in variable sort to optimize the VarInt deserialization function with respect to correctness and measured latency. For correctness, we reward the agent for correctly deserializing each input. We use a set of 80 inputs and corresponding outputs that cover common protobuf use cases. AlphaDev learns an optimized VarInt deserialization function and manages to significantly outperform the human benchmark for single valued inputs. Our agent discovers a branchless solution that is both shorter (Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Tab1">1a</a>) and roughly three times faster than the human benchmark (Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Tab1">1b</a>). In doing so, the agent also discovered a new VarInt assignment move in which AlphaDev learns to combine two operations into a single instruction leading to latency savings. See Appendix D.1 in <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41586-023-06004-9#MOESM1">Supplementary Information</a> for a full overview of this move. This is a strong indication that AlphaDev is capable of generalizing to optimize non-trivial, real-world algorithms.</p><h3 id="Sec16">Libc++ sort patch</h3><p>The sort 3, sort 4 and sort 5 algorithms in the LLVM libc++ standard sorting library are called many times by larger sorting algorithms and are therefore fundamental components of the library. We reverse engineered the low-level assembly sorting algorithms discovered by AlphaDev for sort 3, sort 4 and sort 5 to C++ and discovered that our sort implementations led to improvements of up to 70% for sequences of a length of five and roughly 1.7% for sequences exceeding 250,000 elements. These improvements are for the uint32, uint64 and float data types for ARMv8, Intel Skylake and AMD Zen 2 CPU architectures; see Appendix E in <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41586-023-06004-9#MOESM1">Supplementary Information</a> for the full performance tables. The performance improvements are due to both the branchless conditional assembly generated by AlphaDev as well as the new AlphaDev swap move. For sort 5, we used a 43 length algorithm discovered by AlphaDev, as it led to a more efficient C++ implementation. These algorithms were sent for review and have officially been included in the libc++ standard sorting library<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Gelmi, M. Introduce branchless sorting functions for sort3, sort4 and sort5. LLVM.org 
                  https://reviews.llvm.org/D118029
                  
                 (2022)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR3" id="ref-link-section-d81547407e1975">3</a></sup>. It is the first change to these sub-routines in over a decade. This is also the first time that any component in this sort library has been replaced by an algorithm that has been automatically discovered using reinforcement learning. We estimate that these routines are being called trillions of times every day<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Amazon. Amazon S3—two trillion objects, 1.1 million requests/second. AWS 
                  https://aws.amazon.com/blogs/aws/amazon-s3-two-trillion-objects-11-million-requests-second/
                  
                 (2013)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR1" id="ref-link-section-d81547407e1979">1</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 35" title="LLVM. LLVM users 
                  https://llvm.org/Users.html
                  
                 (LLVM, 2022)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR35" id="ref-link-section-d81547407e1982">35</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 47" title="Protvin, R. &amp; Levenberg, J. Why Google stores billions of lines of code in a single repository. Commun. ACM 59, 78–87 (2016)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR47" id="ref-link-section-d81547407e1985">47</a></sup>.</p></div></div></section><section data-title="Discussion"><div id="Sec17-section"><h2 id="Sec17">Discussion</h2><div id="Sec17-content"><p>AlphaDev discovers new, state-of-the-art sorting algorithms from scratch that have been incorporated into the LLVM C++ library, used by millions of developers and applications around the world<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Karatzoglou, A., Baltrunas, L. &amp; Shi, Y. Learning to rank for recommender systems. In Proc. of the 7th ACM Conference on Recommender Systems 493–494 (ACM, 2013)." href="#ref-CR23" id="ref-link-section-d81547407e1998">23</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Yang, J. Y., Zhang, B. &amp; Mao, Y. Study on Information Retrieval Sorting Algorithm in Network-BasedManufacturing Environment. In Applied Mechanics and Materials Vol. 484, 183–186 (Trans Tech Publishing, 2014)." href="#ref-CR24" id="ref-link-section-d81547407e1998_1">24</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Krallmann, J., Schwiegelshohn, U. &amp; Yahyapour, R. On the design and evaluation of job schedulingalgorithms. In Workshop on Job Scheduling Strategies for Parallel Processing 17–42 (Springer, 1999)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR25" id="ref-link-section-d81547407e2001">25</a></sup>. Both AlphaDev and stochastic search are powerful algorithms. An interesting direction for future research is to investigate combining these algorithms together to realize the complementary advantages of both approaches.</p><p>It is important to note that AlphaDev can, in theory, generalize to functions that do not require exhaustive verification of test cases. For example, hashing functions<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 48" title="Berman, I. et al. Multi-collision resistant hash functions and their applications. In Proc. Annual International Conference on the Theory and Applications of Cryptographic Techniques 133–161 (Springer, 2018)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR48" id="ref-link-section-d81547407e2008">48</a></sup> as well as cryptographic hashing functions<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 49" title="Damgård, I. B. Collision free hash functions and public key signature schemes. In Workshop on the Theory and Application of of Cryptographic Techniques 203–216 (Springer, 1987)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR49" id="ref-link-section-d81547407e2012">49</a></sup> define function correctness by the number of hashing collisions. Therefore, in this case, AlphaDev can optimize for minimizing collisions as well as latency. AlphaDev can also, in theory, optimize complicated logic components within the body of large, impressive functions. We hope that AlphaDev can provide interesting insights and inspire new approaches in both the artificial intelligence and program synthesis communities.</p></div></div></section><section data-title="Methods"><div id="Sec18-section"><h2 id="Sec18">Methods</h2><div id="Sec18-content"><h3 id="Sec19">Background</h3><h4 id="Sec20">AlphaZero</h4><p>AlphaZero<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 33" title="Silver, D. et al. A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play. Science 362, 1140–1144 (2018)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR33" id="ref-link-section-d81547407e2033">33</a></sup> is an RL algorithm that leverages MCTS as a policy improvement operator. It consists of (1) a representation network <i>f</i><sup>rep</sup> that outputs a latent representation <b>h</b><sub><i>t</i></sub> of the state <b>S</b><sub><i>t</i></sub>; and (2) a prediction network <i>f</i><sup>pred</sup> that predicts the expected return (the value) <span>\({\hat{v}}_{t}\)</span> and a policy (that is, distribution over the action space) <span>\({\hat{\pi }}_{t}\)</span> from a given latent state. The algorithm uses the true dynamics and reward when planning. MuZero<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 38" title="Schrittwieser, J. et al. Mastering atari, go, chess and shogi by planning with a learned model. Nature 588, 604–609 (2020)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR38" id="ref-link-section-d81547407e2136">38</a></sup> is a model-based variant of AlphaZero that has the same representation and prediction networks, but also learns a model of the dynamics and predicts rewards, which it uses for planning. Specifically, it learns a dynamics network <i>f</i><sup>dyn</sup> that predicts the next latent state <span>\({{\bf{\text{h}}}}_{t}^{k+1}\)</span> and reward <span>\({\hat{r}}_{t}^{k+1}\)</span> resulting from a transition. Note that the subscript <i>t</i> denotes timesteps in the real environment and the superscript <i>k</i> represents timesteps in the model.</p><div id="Equ1"><p><span>$${{\bf{\text{h}}}}_{t}={f}^{rep}({{\bf{\text{S}}}}_{t})$$</span></p><p>
                    (1)
                </p></div><div id="Equ2"><p><span>$${{\bf{\text{h}}}}_{t}^{k+1},\,{\hat{r}}_{t}^{k+1}={f}^{dyn}({{\bf{\text{h}}}}_{t}^{k},{{\bf{\text{a}}}}_{t}^{k})$$</span></p><p>
                    (2)
                </p></div><div id="Equ3"><p><span>$${\hat{v}}_{t},\,{\hat{\pi }}_{t}={f}^{pred}({{\bf{\text{h}}}}_{t})$$</span></p><p>
                    (3)
                </p></div><p>On reaching a new state, AlphaZero proceeds by first encoding the state into a latent representation with the representation network. Then, the true dynamics or dynamics network (for MuZero) as well as the prediction network <i>f</i><sup>pred</sup>(<b>h</b><sub><i>t</i></sub>) are used to simulate several trajectories that fill out a search tree, by sampling state transitions. At each node, the actions are selected using an optimistic strategy called the predictor upper confidence tree bound<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 32" title="Silver, D. et al. Mastering the game of Go with deep neural networks and tree search. Nature 529, 484–489 (2016)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR32" id="ref-link-section-d81547407e2590">32</a></sup>, meant to balance exploration (trying new actions) and exploitation (progressing further down the subtree of the current estimate of the best action). This strategy starts out by following the predicted policy <span>\({\hat{\pi }}_{t}\)</span> closely, and gradually shifts towards maximizing the predicted value function. Ultimately, an action is recommended by sampling from the root node with probability proportional to its visit count during MCTS. The predicted policy is then trained to match the visit counts of the MCTS policy in an attempt to distil the search procedure into a policy such that subsequent iterations of MCTS will disregard nodes that are not promising.</p><h4 id="Sec21">Sorting networks</h4><p>Sorting networks are very efficient as their structures can be parallelized on modern CPU architectures. They therefore tend to achieve faster runtime performance, especially on small sorts, compared to popular and efficient base case algorithms such as insertion sort<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Bingmann, T., Marianczuk, J. &amp; Sanders, P. Engineering faster sorters for small sets of items. Software: Pract. Exper. 51, 965–1004 (2021)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR17" id="ref-link-section-d81547407e2641">17</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 43" title="Bundala, D. &amp; Závodny, J. Optimal sorting networks. In Proc. International Conference on Language and Automata Theory and Applications 236–247 (Springer, 2014)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR43" id="ref-link-section-d81547407e2644">43</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 50" title="Hwang, M. Sort, Bitset (GitHub, 2021)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR50" id="ref-link-section-d81547407e2647">50</a></sup>. A sorting network<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 43" title="Bundala, D. &amp; Závodny, J. Optimal sorting networks. In Proc. International Conference on Language and Automata Theory and Applications 236–247 (Springer, 2014)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR43" id="ref-link-section-d81547407e2651">43</a></sup> consists of two types of item called comparators (vertical lines) and wires (horizontal lines) (Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Fig6">2a</a>). Each wire carries a value from left to right. When two wires intersect at a comparator, the values on the two wires are compared. If the value of the bottom wire is smaller than the value of the top wire, then the values are swapped between wires as seen in Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Fig6">2b</a>. A programmatic implementation of a sorting network consists of executing these swaps on particular pairs of elements from the input sequence in a particular order.</p><h3 id="Sec22">Action pruning rules</h3><p>We pruned the action space by removing some program invariances (for example, the order of register allocation) and illegal instructions (for example, comparing two memory locations). This helps reducing the size of the action space and increases convergence rate. For our experiments, we used the following rules:</p><ol>
                  <li>
                    <span>(1)</span>
                    
                      <p>Memory locations are always read in incremental order.</p>
                    
                  </li>
                  <li>
                    <span>(2)</span>
                    
                      <p>Registers are allocated in incremental order.</p>
                    
                  </li>
                  <li>
                    <span>(3)</span>
                    
                      <p>We cannot compare or conditionally move to a memory location (illegal).</p>
                    
                  </li>
                  <li>
                    <span>(4)</span>
                    
                      <p>We can read and write to each memory location only once.</p>
                    
                  </li>
                  <li>
                    <span>(5)</span>
                    
                      <p>We cannot use non-initialized registers (illegal).</p>
                    
                  </li>
                  <li>
                    <span>(6)</span>
                    
                      <p>Do not perform consecutive compare instructions.</p>
                    
                  </li>
                </ol><h4 id="Sec23">Training regime</h4><p>We train AlphaDev on a Tensor Processing Unit (TPU) v.3, with a total batch size of 1,024 per TPU core. We use up to 16 TPU cores and train for 1 million iterations. On the actor side, the games are played on standalone TPU v.4, and we use up to 512 actors. In practice, across all tasks, training takes, in the worst case, 2 days to converge.</p><h4 id="Sec24">AlphaDev-S</h4><p>It is important to understand the advantages and limitations of RL compared to other possible approaches for program optimization. As such, we implemented a state-of-the-art stochastic superoptimization approach<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Schkufza, E., Sharma, R. &amp; Aiken, A. Stochastic superoptimization. ACM SIGPLAN Notices 48, 305–315 (2013)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR8" id="ref-link-section-d81547407e2754">8</a></sup> and incorporated it into AlphaDev as the learning algorithm to optimize sorting functions. We refer to this adapted version as AlphaDev-S. Our re-implementation has been specifically optimized for the sorting domain. This includes implementing the algorithm to run with our assembly environment, defining a correctness and performance loss function specific to sorting and running extensive hyperparameter sweeps to identify the best variant. The cost function used for AlphaDev-S is <i>c</i> = correctness + <i>α</i> × performance where correctness corresponds to computing the number of incorrect input sequence elements that are still unsorted, performance corresponds to the algorithm length reward and <i>α</i> is a weight trading off the two cost functions. We are unable to optimize directly for latency as this slows down the learning algorithm considerably making learning infeasible. It should be noted that this function has been adapted to support the same set of assembly instructions used by AlphaDev as well as prune the same set of incorrect or illegal actions. It also uses the same program correctness computation module (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Fig2">2b</a>) to compute the correctness term.</p><p>AlphaDev-S is then executed by first proposing a transformation to the program stored in the buffer (which may be empty or initialized with an already sorted program). The correctness and performance terms are then computed using the program correctness module and algorithm length, respectively. If the cost is lower than the current best cost, the new program is accepted with high probability, otherwise it is rejected. We will now discuss the correctness cost function and transform weights in more detail.</p><h4 id="Sec25">Correctness cost</h4><p>For the correctness cost function, we implemented three types of cost function. The first one is defined as the percentage of incorrectly placed items: <span>\(\frac{P-P{C}_{t}}{P}\)</span> where <i>P</i> is the total number of items to place and PC<sub><i>t</i></sub> is number of correctly placed items at timestep <i>t</i>. The second variant is the square root of this equation. The final cost function takes the square root of the difference <span>\(\sqrt{-{PC}_{t}}\)</span> and this is what yielded the best performance.</p><h4 id="Sec26">Program transformations</h4><p>We enabled several program transformations such as adding an instruction to increase the size of the program (Add Transform), swapping two instructions (Swap Transform), randomly changing an Opcode for an instruction (Opcode Transform), randomly sampling an Operand for a chosen instruction (Operand Transform) and randomly sample an Opcode and its corresponding Operands (Instruction Transform). It is possible to influence the sampling of these transforms to encourage some to be sampled more or less frequently. We optimized the weights for sampling transforms by running an extensive hyperparameter sweep.</p><h3 id="Sec27">Investigative studies for AlphaDev variants</h3><p>We now present a set of investigative studies that help to better understand the advantages and limitations of the DRL and the stochastic search learning algorithms used in AlphaDev. We compare AlphaDev to AlphaDev-S. We implemented two variants of AlphaDev-S: (1) Cold Start (AlphaDev-S-CS) and (2) Warm Start (AlphaDev-S-WS). AlphaDev-S-CS uses no previous information and has to generate a program from an empty program buffer. AlphaDev-S-WS’s buffer is warm started with a correct sorting program (for example, optimal sorting network assembly program) and it edits the program to optimize it further. We compared the variants with AlphaDev in both the individual and variable sort algorithm setups.</p><p>Because AlphaDev always learns from scratch with no previous knowledge, the direct comparison would be to the cold start stochastic search version: AlphaDev-S-CS. However, as initial near-optimal programs may sometimes be available, we also compare AlphaDev to the warm start stochastic search version: AlphaDev-S-WS.</p><p>It should be noted that the stochastic search variants are unable to optimize directly for latency, as this would make learning infeasible because of computational efficiency. As such, our AlphaDev-S variants optimize for algorithm length. Then, at the end of training, we iterate through the set of generated programs for AlphaDev-S across varying lengths and identify the program with the lowest latency.</p><p>In each case, the stochastic search algorithms (AlphaDev-S) are run using at least the same computational resources and wall-clock time to that of AlphaDev.</p><h4 id="Sec28">Fixed sort</h4><p>We first examine the performance of the various approaches for the fixed sort algorithms. In this case, all algorithmic variants optimize for algorithm length as algorithm length and latency are highly correlated in the conditional branchless setting (see <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41586-023-06004-9#MOESM1">Supplementary Information</a> for more details).</p><p>In the cold start setting, AlphaDev-S-CS is unable to find the optimal programs in each case as seen in Extended Data Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Tab4">2a</a>. In addition, AlphaDev-S-CS explores orders of magnitude more programs than AlphaDev as shown in Extended Data Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Tab4">2b</a>. In the warm start setting, AlphaDev-S is warm started with a near-optimal sorted program, and is able to match the performance of AlphaDev in each case as shown in Extended Data Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Tab4">2a</a>. It is more computationally efficient than AlphaDev as shown in Extended Data Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Tab4">2c</a> but explores orders of magnitude more programs for sort 3 and sort 5 as shown in Extended Data Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Tab4">2b</a>. It can be argued that AlphaDev-S-WS has a substantial advantage in this scenario as it is provided with an initial near-optimal program. We will show in the <a data-track="click" data-track-label="link" data-track-action="section anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Sec31">Variable sort</a> section that when the algorithms become more complicated and branching is introduced, warm starting the learning algorithm with a near-optimal program is not enough and can cause it to get stuck in suboptimal solutions.</p><h4 id="Sec29">Brute-force approach</h4><p>We also used a brute-force approach to prove that no program shorter than 17 instructions exists for sort 3. We had to enumerate roughly 10<sup>32</sup> programs and, even with pruning heuristics, it took more than 3 days to prove this hypothesis. For sort 4 and above this approach is infeasible.</p><h4 id="Sec30">Latency benchmarking suite</h4><p>The length of a program is only a proxy for the performance of an algorithm. As we introduce branching structures, the length and latency of a program are not well correlated. Therefore, we run the programs on actual machines and measure their latency. Microbenchmarking is very challenging given the numerous noise sources that could affect the measurements. This is especially true when running on shared machines where there could be interference from other processes. Our approach is to have a separate benchmarking service, replicated on separated machines, so that we can quickly perform many measurements in a controlled environment under different conditions. The system works as follows:</p><ol>
                    <li>
                      <span>(1)</span>
                      
                        <p>The RL agent processes 1,000 measurements across the machines using the replicated service.</p>
                      
                    </li>
                    <li>
                      <span>(2)</span>
                      
                        <p>For each measurement, the service runs the given sorting algorithm over 10,000 random inputs (for example, for sort 3 this would be 3 × 10,000 = 30,000 random integers).</p>
                      
                    </li>
                    <li>
                      <span>(3)</span>
                      
                        <p>We measure the time taken using a CPU performance counter (CPU_CLK_UNHALTED.CORE).</p>
                      
                    </li>
                  </ol><p>We then take the fifth percentile as our final measurement, because we assume that most noise sources are one-sided (for example, cache misses, pre-emptions and so on). During training we process the measurements across ten machines for computational efficiency. After training, we benchmark AlphaDev’s solution against the baseline solutions, and process the measurements across 100 machines for more accuracy and noise reduction. For each benchmark, we compute confidence intervals using the distribution-free two-sided confidence interval for a quantile tabular method<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 44" title="Hahn, G. J. &amp; Meeker, W. Q. Statistical Intervals: A Guide for Practitioners Vol. 92 (John Wiley &amp; Sons, 2011)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR44" id="ref-link-section-d81547407e2987">44</a></sup>.</p><h4 id="Sec31">Variable sort</h4><p>When optimizing directly for latency, AlphaDev outperforms AlphaDev-S-WS on VarSort3, VarSort4 and VarSort5 as seen in Extended Data Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Tab5">3a</a>. AlphaDev-S-CS fails to find a solution in each case. In the cases of VarSort4 and VarSort5, program length and latency are not correlated (see <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41586-023-06004-9#MOESM1">Supplementary Information</a> for more details). This indicates that when program length cannot be used as a proxy for performance, AlphaDev is able to find lower latency solutions compared to AlphaDev-S. This is even in the case where the stochastic search is warm started with a near-optimal program. In addition, AlphaDev converges to the optimal solution after exploring a maximum of 12M programs as seen in Extended Data Table <a data-track="click" data-track-label="link" data-track-action="table anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Tab5">3b</a>. This is orders of magnitude lower than that of AlphaDev-S-CS and AlphaDev-S-WS, respectively (31 trillion programs in the worst case).</p><h3 id="Sec32">Exploration hypothesis</h3><p>We proposed that AlphaDev-S struggles to discover programs when learning from scratch and gets stuck in local optima when warm started because of its limited exploration capabilities as a result of the stochastic search procedure. Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Fig7">3</a> shows two-dimensional <i>t</i>-stochastic neighbour embedding (<i>t</i>-SNE) projections<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 51" title="Van der Maaten, L. &amp; Hinton, G. Visualizing data using t-SNE. J. Mach. Learn. Res. 9.11, 2579–2605 (2008)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR51" id="ref-link-section-d81547407e3026">51</a></sup> of AlphaDev and AlphaDev-S’s assembly algorithms discovered during their respective training procedures for VarSort5. The features used in the projection include correctness, latency, algorithm length and a histogram count of the instructions used per algorithm. Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Fig7">3a</a> indicates the regions in algorithm space explored by AlphaDev, AlphaDev-S-CS and AlphaDev-S-WS, respectively, whereas Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Fig7">3b</a> superimposes algorithm correctness onto each point in the <i>t</i>-SNE projection in which the colour indicates the correctness of each discovered algorithm, ranging from incorrect algorithms (purple) to correct algorithms (yellow). The AlphaDev-S variants both cover a densely packed circular region around their initial seed, which highlights the breadth-first nature of their stochastic search procedure. This illustrates that AlphaDev-S-CS fails to navigate through the space of incorrect algorithms in a reasonable amount of time and discover correct algorithms when learning from scratch. A similar argument applies to AlphaDev-S-WS whereby, when optimizing from an already correct but suboptimal expert demonstration, the algorithm is biased towards exploring its vicinity and struggles to escape this local maxima. By contrast, AlphaDev has more diverse algorithm space coverage, as the long-term value function is a guiding signal for discovering new and interesting parts of algorithm space. As seen in Extended Data Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s41586-023-06004-9#Fig7">3b</a>, it is capable of escaping the space of incorrect algorithms to discover a new space of correct algorithms, highlighting the exploration advantages afforded by AlphaDev.</p><h3 id="Sec33">Related work</h3><h4 id="Sec34">Assembly optimization</h4><p>There are numerous approaches to optimizing assembly programs, which we have classified into three groups: enumerative search, stochastic search and symbolic search<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Alur, R. et al. Syntax-Guided Synthesis (IEEE, 2013)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR5" id="ref-link-section-d81547407e3056">5</a></sup>.</p><p>First, enumerative search techniques include brute-force program enumeration<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Bansal, S. &amp; Aiken, A. Automatic generation of peephole superoptimizers. ACM SIGARCH Comput. Arch. News 34, 394–403 (2006)." href="#ref-CR4" id="ref-link-section-d81547407e3063">4</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Alur, R. et al. Syntax-Guided Synthesis (IEEE, 2013)." href="#ref-CR5" id="ref-link-section-d81547407e3063_1">5</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Phothilimthana, P. M. et al. Scaling up superoptimization. In Proc. Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems 297–310 (ACM, 2016)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR6" id="ref-link-section-d81547407e3066">6</a></sup> as well as implicit enumeration using symbolic theorem proving<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 52" title="Gulwani, S. et al. Synthesis of loop-free programs. ACM SIGPLAN Notices 46.6, 62–73 (2011)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR52" id="ref-link-section-d81547407e3070">52</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 53" title="Sasnauskas, R. et al. Souper: a synthesizing superoptimizer. Preprint at 
                  https://arxiv.org/abs/1711.04422
                  
                 (2017)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR53" id="ref-link-section-d81547407e3073">53</a></sup>. These approaches search through the space of programs to find a solution based on a predefined set of programs, heuristic and/or cost function. These approaches struggle to span large regions of program space, especially as the size and complexity of the program increases.</p><p>Second, stochastic search techniques circumvent comprehensive enumeration by relying on sampling mechanisms such as Markov chain Monte Carlo sampling<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Alur, R. et al. Syntax-Guided Synthesis (IEEE, 2013)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR5" id="ref-link-section-d81547407e3080">5</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Phothilimthana, P. M. et al. Scaling up superoptimization. In Proc. Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems 297–310 (ACM, 2016)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR6" id="ref-link-section-d81547407e3083">6</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Schkufza, E., Sharma, R. &amp; Aiken, A. Stochastic superoptimization. ACM SIGPLAN Notices 48, 305–315 (2013)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR8" id="ref-link-section-d81547407e3086">8</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Bunel, R. et al. Learning to superoptimize programs. In Proc. International Conference on Learning Representations (ICLR, 2016)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR9" id="ref-link-section-d81547407e3089">9</a></sup>. Rajeev Alur et al.<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Alur, R. et al. Syntax-Guided Synthesis (IEEE, 2013)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR5" id="ref-link-section-d81547407e3093">5</a></sup> define a correctness specification, provided by a logical formula that uses symbols from a background theory. The goal is to then find an implementation expression such that logical formula defining the specification is valid. The idea is to iteratively add test cases and then search and expand the program to solve the given test cases. They optimize for correctness on problems from the book Hacker’s delight<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 54" title="Warren, H. S. Hacker’s Delight (Pearson Education, 2013)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR54" id="ref-link-section-d81547407e3097">54</a></sup>. Phitchaya Mangpo Phothilimthana et al.<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Phothilimthana, P. M. et al. Scaling up superoptimization. In Proc. Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems 297–310 (ACM, 2016)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR6" id="ref-link-section-d81547407e3101">6</a></sup> introduce the LENS algorithm that is based on running enumerative, stochastic and symbolic search in parallel, while relying on handcrafted pruning rules. This setup is capable of optimizing up to 21 instructions, and cannot optimize for latency nor support branching. Another algorithm<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Schkufza, E., Sharma, R. &amp; Aiken, A. Stochastic superoptimization. ACM SIGPLAN Notices 48, 305–315 (2013)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR8" id="ref-link-section-d81547407e3105">8</a></sup> is based on Markov chain Monte Carlo rejection sampling and applies transformations to programs in assembly using a loss function that is a function of correctness and performance. Many of these approaches are prone to getting stuck in local minima and may also struggle as the size and/or complexity of the program increases. In addition, incorporating actual, measured latency into these approaches are either infeasible or prohibitively expensive.</p><p>Third, symbolic search approaches can also be implemented to optimize assembly programs. These include SAT solvers<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 55" title="Hamadi, Y., Jabbour, S. &amp; Sais, L. ManySAT: a parallel SAT solver. J. Satisfiability, Boolean Model. Comput. 6, 245–262 (2010)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR55" id="ref-link-section-d81547407e3112">55</a></sup>, SMT solvers<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Alur, R. et al. Syntax-Guided Synthesis (IEEE, 2013)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR5" id="ref-link-section-d81547407e3116">5</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Phothilimthana, P. M. et al. Scaling up superoptimization. In Proc. Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems 297–310 (ACM, 2016)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR6" id="ref-link-section-d81547407e3119">6</a></sup> and Mixed Integer Programs (MIPs)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 56" title="Wolsey, L. A. Mixed integer programming. In Wiley Encyclopedia of Computer Science and Engineering 1–10 (Wiley, 2007)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR56" id="ref-link-section-d81547407e3123">56</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 57" title="Nair, V. et al. Solving mixed integer programs using neural networks. Preprint at 
                  https://arxiv.org/abs/2012.13349
                  
                 (2020)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR57" id="ref-link-section-d81547407e3126">57</a></sup>. However, these approaches suffer from scaling issues. For example, classical solvers require a problem to be translated into a certain canonical form. It usually requires an expert in the said solvers and a substantial amount of time to find an efficient formulation. In addition, for any new modification of the problem, this has to be repeated. Classical solvers are also hard to parallelize and thus, it is challenging to leverage more hardware to speed up the solving process. Another symbolic search algorithm is Cholorphyll<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="Phothilimthana, P. M. et al. Chlorophyll: synthesis-aided compiler for low-power spatial architectures. ACM SIGPLAN Notices 49, 396–407 (2014)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR10" id="ref-link-section-d81547407e3130">10</a></sup> that implements a multi-phase approach. It first requires as input a source program with partition annotations that specify where code and data reside. Then, a layout synthesizer maps program fragments onto physical cores to minimize computational costs. The code is then separated into per-core program fragments and the program fragments are compiled into machine code. At this point, a superoptimizer optimizes each of these fragments.</p><h4 id="Sec35">SIMD optimization</h4><p>Various approaches<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Inoue, H. et al. AA-sort: a new parallel sorting algorithm for multi-core SIMD processors. In Proc. International Conference on Parallel Architecture and Compilation Techniques (PACT 2007) 189–198 (IEEE, 2007)." href="#ref-CR58" id="ref-link-section-d81547407e3142">58</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Yin, Z. et al. Efficient parallel sort on avx-512-based multi-core and many-core architectures. In Proc. IEEE 21st International Conference on High Performance Computing and Communications 168–176 (IEEE, 2019)." href="#ref-CR59" id="ref-link-section-d81547407e3142_1">59</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 60" title="Blacher, M. et al. Vectorized and performance-portable Quicksort. Preprint at 
                  https://arxiv.org/abs/2205.05982
                  
                 (2022)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR60" id="ref-link-section-d81547407e3145">60</a></sup> have also been applied to sorting functions that run in the single instruction, multiple data (SIMD)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 61" title="Wikipedia. Single instruction, multiple data 
                  https://en.m.wikipedia.org/wiki/SIMD
                  
                 (2022)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR61" id="ref-link-section-d81547407e3149">61</a></sup> setup. This setup is capable of parallelizing instruction execution, but is not supported at present in popular libraries such as LLVM’s libc++ std::sort library. One example is that from Gilles Barthe et al.<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Barthe, G. et al. From relational verification to SIMD loop synthesis. In Proc. of the 18th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming 123–134 (ACM, 2013)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR7" id="ref-link-section-d81547407e3153">7</a></sup> that proposes a methodology for optimizing programs by automatically vectorizing loops with SIMD instructions. They do this by introducing a framework for verifying the correctness of transformations to a program and performing a search-based procedure using the said transformation. Their framework can discover SIMD looping structures of up to nine instructions in 0.12 s, which corresponds to a minimum 2× speed-up.</p><h4 id="Sec36">RL approaches for program synthesis</h4><p>There are also several studies using RL for program optimization. Kevin Ellis et al.<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 62" title="Ellis, K. et al. Write, execute, assess: program synthesis with a REPL. Adv. Neural Inform. Proc. Syst.32, 9137–9146 (2019)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR62" id="ref-link-section-d81547407e3165">62</a></sup> learn a policy and value function to write and evaluate code, as well as performing a Monte Carlo-style search strategy during inference. This work requires a pretraining step and aims to generate correct programs that satisfy a predefined specification. The approach is successfully applied to computer-aided design and string editing programs. SuperSonic<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 63" title="Wang, H. et al. Automating reinforcement learning architecture design for code optimization. In Proc. 31st ACM SIGPLAN International Conference on Compiler Construction 129–143 (ACM, 2022)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR63" id="ref-link-section-d81547407e3169">63</a></sup> uses an RL meta-optimizer to select between different RL architectures, using a Multi-Armed Bandit policy search to find a state representation, reward function and RL algorithm that is optimal for the current task. This requires keeping track of many RL algorithms and architectures, which are used as part of the state space. By contrast, our approach only focuses on training a single RL architecture, taking advantage of MCTS search and powerful state representations. Shypula et al.<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 64" title="Shypula, A. G. et al. Learning to superoptimize real-world programs. Preprint at 
                  https://arxiv.org/abs/2109.13498
                  
                 (2022)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR64" id="ref-link-section-d81547407e3173">64</a></sup> create a supervised assembly dataset and use it to train a Transformer model for mapping unoptimized to optimized code, followed by an RL stage for improving the solution quality. Our method does not require a supervised dataset or two separate training and finetuning stages, and optimizes everything end-to-end using RL and search instead. Chen et al.<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 65" title="Chen, X., Liu, C. &amp; Song, D. Execution-guided neural program synthesis. In Proc. International Conference on Learning Representations (ICLR, 2018)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR65" id="ref-link-section-d81547407e3177">65</a></sup> define their own domain specific language and perform input–output program synthesis that better uses the intermediate program representation to guide the synthesis routine. They show that this can be incorporated with RL, using the setup of Rudy Bunel et al.<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 66" title="Bunel, R. et al. Leveraging grammar and reinforcement learning for neural program synthesis. In Proc. International Conference on Learning Representations (ICLR, 2018)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR66" id="ref-link-section-d81547407e3181">66</a></sup> and improve the correctness of generated functions. They do not, however, optimize for program length or latency.</p><h4 id="Sec37">Input–output examples for program synthesis</h4><p>A large body of work addresses the problem of learning programs from input–output pairs. One type of approach learns a neural network for matching inputs to outputs directly<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Vinyals, O. et al. Grammar as a foreign language. Adv. Neural Inform. Proc. Syst. 28, 2773–2781 (2015)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR11" id="ref-link-section-d81547407e3193">11</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Devlin, J. et al. Robustfill: neural program learning under noisy i/o. In Proc. International Conference on Machine Learning 990–998 (PMLR, 2017)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR13" id="ref-link-section-d81547407e3196">13</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 67" title="Aharoni, R. &amp; Goldberg, Y. Towards string-to-tree neural machine translation. In Proc. 55th Annual Meeting of the Association for Computational Linguistics132–140 (ACL, 2017)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR67" id="ref-link-section-d81547407e3199">67</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 68" title="Dong, L. &amp; Lapata, M. Language to logical form with neural attention. In Proc. 54th Annual Meeting of the Association for Computational Linguistics 33–43 (ACL, 2016)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR68" id="ref-link-section-d81547407e3202">68</a></sup>. This approach is difficult to integrate into existing libraries and can struggle to generalize to previously unseen inputs, although there has been some encouraging recent progress using graph representations<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 69" title="Ibarz, B. et al. A generalist neural algorithmic learner. In Proc. Learning on Graphs Conference Vol. 198, 2:1–2:23 (PMLR, 2022)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR69" id="ref-link-section-d81547407e3206">69</a></sup>. Another type of approach is to perform a search in program space, guided by a learned model<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Chen, X., Liu, C. &amp; Song, D. Towards synthesizing complex programs from input-output examples. In Proc. International Conference on Learning Representations (ICLR, 2018)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR12" id="ref-link-section-d81547407e3210">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Chen, X., Song, D. &amp; Tian, Y. Latent execution for neural program synthesis beyond domain-specific languages. Adv. Neural Inform. Proc. Syst. 34, 22196–22208 (2021)." href="#ref-CR70" id="ref-link-section-d81547407e3213">70</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Parisotto, E. et al. Neuro-symbolic program synthesis. Preprint at 
                  https://arxiv.org/abs/1611.01855
                  
                 (2016)." href="#ref-CR71" id="ref-link-section-d81547407e3213_1">71</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 72" title="Ellis, K., Solar-Lezama, A. &amp; Tenenbaum, J. Sampling for Bayesian program learning. Adv. Neural Inform. Proc. Syst. 29, 1297–1305 (2016)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR72" id="ref-link-section-d81547407e3216">72</a></sup>. For instance, Chen et al.<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 70" title="Chen, X., Song, D. &amp; Tian, Y. Latent execution for neural program synthesis beyond domain-specific languages. Adv. Neural Inform. Proc. Syst. 34, 22196–22208 (2021)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR70" id="ref-link-section-d81547407e3220">70</a></sup> use a model that predicts the next program token on the basis of a partial program and the input–output pairs. This bears some similarities to how search is guided in our approach: the learned policy prior in AlphaZero is a model for predicting the next token, learned on the basis of a combination of a partial program and that program’s effects on the inputs. However, we are interested in finding correct and efficient programs, which we achieve by further learning a value function for approximating the expected latency of partial programs, and using AlphaZero to incorporate this value function into the search process.</p><h4 id="Sec38">Deep learning for code generation</h4><p>There are also several deep learning approaches that use large languages models to generate code. These approaches vary in their uses from transpilation, code refactoring and explaining code<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Pearce, H. et al. Can codex and other large language models help us fix security bugs? Preprint at 
                  https://arxiv.org/abs/2112.02125
                  
                 (2021)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR15" id="ref-link-section-d81547407e3233">15</a></sup> to generating human-level competitive code using a natural language description<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Li, Y. et al. Competition-level code generation with AlphaCode. Science 378, 1092–1097 (2022)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR14" id="ref-link-section-d81547407e3237">14</a></sup>. That particular work aims to generate correct code, but does not focus on generating low-latency solutions.</p><h4 id="Sec39">Sort-based program optimization</h4><p>There are several program synthesis studies that have tackled sorting algorithms. For example, White et al.<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 26" title="White, S. K., Martinez, T. &amp; Rudolph, G. Generating a novel sort algorithm using Reinforcement Programming. In Proc. IEEE Congress on Evolutionary Computation 1–8 (IEEE, 2010)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR26" id="ref-link-section-d81547407e3249">26</a></sup> use RL for learning sorting functions. Their work uses several heuristics and a domain specific language to yield a sorting algorithm called reinforcement programming sort. Srivastava et al.<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 27" title="Srivastava, S., Gulwani, S. &amp; Foster, J. S. From program verification to program synthesis. In Proc. of the 37th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages 313–326 (ACM, 2010)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR27" id="ref-link-section-d81547407e3253">27</a></sup> encodes the program synthesis as a verification problem. Specifically, they represent a synthesis task as a tuple consisting of the functional expression, the domains and guards appearing in the synthesized program and the resource constraints. The idea is that, given a prespecified resource constraint, their synthesizer produces a program that meets the predefined specification to ensure correctness. They apply this to discover merge sort and quick sort. Jason Ansel et al.<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 28" title="Ansel, J. et al. Petabricks: a language and compiler for algorithmic choice. ACM Sigplan Notices 44, 38–49 (2009)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR28" id="ref-link-section-d81547407e3257">28</a></sup> takes as input predefined algorithms (for example, insertion sort, merge sort and quick sort) and then determines when to select these algorithms for execution using its autotuner function. It does so by defining a language that contains rules and transforms that dictate how the algorithms are selected and where they are executed.</p></div></div></section>
                </div><div>
            <section data-title="Data availability"><div id="data-availability-section"><h2 id="data-availability">Data availability</h2><p>The data used to train the system were generated synthetically according to the procedures explained in the paper. The algorithms discovered by AlphaDev for the copy and swap operators are presented in the main paper. We have also released the discovered AlphaDev assembly implementations for sort 3–8 as well as VarSort3, 4 and 5 on Github at <a href="https://github.com/deepmind/alphadev">https://github.com/deepmind/alphadev</a>. We have included exhaustive tests to ensure that each implementation is correct. In addition, Appendix G in <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41586-023-06004-9#MOESM1">Supplementary Information</a> contains a list of additional, correct sorting algorithms discovered by AlphaDev for sort 3, sort 4 and sort 5. The performance of the sort 3, sort 4 and sort 5 algorithms on the official LLVM benchmarking suite for three different CPU architectures as well as floats, int32 and int64 data types is detailed in Appendix E in the <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41586-023-06004-9#MOESM1">Supplementary Information</a>. In addition, the AlphaDev sort 3, sort 4 and sort 5 implementations can be found in the LLVM libc++ standard sorting library<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Gelmi, M. Introduce branchless sorting functions for sort3, sort4 and sort5. LLVM.org 
                  https://reviews.llvm.org/D118029
                  
                 (2022)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR3" id="ref-link-section-d81547407e3375">3</a></sup>.</p></div></section><section data-title="Code availability"><div id="code-availability-section"><h2 id="code-availability">Code availability</h2><p>We have also released pseudocode at <a href="https://github.com/deepmind/alphadev">https://github.com/deepmind/alphadev</a> that includes the environment, the full actor and training loops as well as the core MCTS algorithm. In addition, we include our actual JAX implementation of our policy, value and representation networks that enable the architectures to be reproduced. Finally, we have a config file containing the hyperparameter definitions to be used with the agent.</p></div></section><div id="MagazineFulltextArticleBodySuffix"><section aria-labelledby="Bib1" data-title="References"><div id="Bib1-section"><h2 id="Bib1">References</h2><div id="Bib1-content"><div data-container-section="references"><ol data-track-component="outbound reference"><li data-counter="1."><p id="ref-CR1">Amazon. Amazon S3—two trillion objects, 1.1 million requests/second. <i>AWS</i> <a href="https://aws.amazon.com/blogs/aws/amazon-s3-two-trillion-objects-11-million-requests-second/">https://aws.amazon.com/blogs/aws/amazon-s3-two-trillion-objects-11-million-requests-second/</a> (2013).</p></li><li data-counter="2."><p id="ref-CR2">Cormen, T. H. et al. <i>Introduction to Algorithms</i> (MIT Press, 2022).</p></li><li data-counter="3."><p id="ref-CR3">Gelmi, M. Introduce branchless sorting functions for sort3, sort4 and sort5. <i>LLVM.org</i> <a href="https://reviews.llvm.org/D118029">https://reviews.llvm.org/D118029</a> (2022).</p></li><li data-counter="4."><p id="ref-CR4">Bansal, S. &amp; Aiken, A. Automatic generation of peephole superoptimizers. <i>ACM SIGARCH Comput. Arch. News</i> <b>34</b>, 394–403 (2006).</p></li><li data-counter="5."><p id="ref-CR5">Alur, R. et al. <i>Syntax-Guided Synthesis</i> (IEEE, 2013).</p></li><li data-counter="6."><p id="ref-CR6">Phothilimthana, P. M. et al. Scaling up superoptimization. In <i>Proc. Twenty-First International Conference on Architectural Support for Programming Languages and Operating Systems</i> 297–310 (ACM, 2016).</p></li><li data-counter="7."><p id="ref-CR7">Barthe, G. et al. From relational verification to SIMD loop synthesis. In <i>Proc. of the 18th ACM SIGPLAN Symposium on Principles and Practice of Parallel Programming</i> 123–134 (ACM, 2013).</p></li><li data-counter="8."><p id="ref-CR8">Schkufza, E., Sharma, R. &amp; Aiken, A. Stochastic superoptimization. <i>ACM SIGPLAN Notices</i> <b>48</b>, 305–315 (2013).</p></li><li data-counter="9."><p id="ref-CR9">Bunel, R. et al. Learning to superoptimize programs. In <i>Proc. International Conference on Learning Representations</i> (ICLR, 2016).</p></li><li data-counter="10."><p id="ref-CR10">Phothilimthana, P. M. et al. Chlorophyll: synthesis-aided compiler for low-power spatial architectures. <i>ACM SIGPLAN Notices</i> <b>49</b>, 396–407 (2014).</p></li><li data-counter="11."><p id="ref-CR11">Vinyals, O. et al. Grammar as a foreign language. <i>Adv. Neural Inform. Proc. Syst.</i> <b>28</b>, 2773–2781 (2015).</p></li><li data-counter="12."><p id="ref-CR12">Chen, X., Liu, C. &amp; Song, D. Towards synthesizing complex programs from input-output examples. In <i>Proc. International Conference on Learning Representations</i> (ICLR, 2018).</p></li><li data-counter="13."><p id="ref-CR13">Devlin, J. et al. Robustfill: neural program learning under noisy i/o. In <i>Proc. International Conference on Machine Learning</i> 990–998 (PMLR, 2017).</p></li><li data-counter="14."><p id="ref-CR14">Li, Y. et al. Competition-level code generation with AlphaCode. <i>Science</i> <b>378</b>, 1092–1097 (2022).</p></li><li data-counter="15."><p id="ref-CR15">Pearce, H. et al. Can codex and other large language models help us fix security bugs? Preprint at <a href="https://arxiv.org/abs/2112.02125">https://arxiv.org/abs/2112.02125</a> (2021).</p></li><li data-counter="16."><p id="ref-CR16">Chen, M. et al. Evaluating large language models trained on code. Preprint at <a href="https://arxiv.org/abs/2107.03374">https://arxiv.org/abs/2107.03374</a> (2021).</p></li><li data-counter="17."><p id="ref-CR17">Bingmann, T., Marianczuk, J. &amp; Sanders, P. Engineering faster sorters for small sets of items. <i>Software: Pract. Exper.</i> <b>51</b>, 965–1004 (2021).</p></li><li data-counter="18."><p id="ref-CR18">Levcopoulos, C. &amp; Petersson, O. Splitsort: an adaptive sorting algorithm. <i>Inform. Proc. Lett.</i> <b>39</b>, 205–211 (1991).</p></li><li data-counter="19."><p id="ref-CR19">Helman, D. R., Bader, D. A. &amp; JáJá, J. A randomized parallel sorting algorithm with an experimental study. <i>J. Parallel Distrib. Comput.</i> <b>52</b>, 1–23 (1998).</p></li><li data-counter="20."><p id="ref-CR20">Goodrich, M. T. Randomized shellsort: a simple oblivious sorting algorithm. In <i>Proc. of the Twenty-First Annual ACM-SIAM Symposium on Discrete Algorithms</i> 1262–1277 (ACM, 2010).</p></li><li data-counter="21."><p id="ref-CR21">Mehlhorn, K., Sanders, P. &amp; Sanders, P. <i>Algorithms and Data Structures: The Basic Toolbox</i> Vol. 55. (Springer, 2008).</p></li><li data-counter="22."><p id="ref-CR22">Knebl, H. <i>Algorithms and Data Structures</i> (Springer, 2020).</p></li><li data-counter="23."><p id="ref-CR23">Karatzoglou, A., Baltrunas, L. &amp; Shi, Y. Learning to rank for recommender systems. In <i>Proc. of the 7th ACM Conference on Recommender Systems</i> 493–494 (ACM, 2013).</p></li><li data-counter="24."><p id="ref-CR24">Yang, J. Y., Zhang, B. &amp; Mao, Y. Study on Information Retrieval Sorting Algorithm in Network-BasedManufacturing Environment. In <i>Applied Mechanics and Materials</i> Vol. 484, 183–186 (Trans Tech Publishing, 2014).</p></li><li data-counter="25."><p id="ref-CR25">Krallmann, J., Schwiegelshohn, U. &amp; Yahyapour, R. On the design and evaluation of job schedulingalgorithms. In <i>Workshop on Job Scheduling Strategies for Parallel Processing</i> 17–42 (Springer, 1999).</p></li><li data-counter="26."><p id="ref-CR26">White, S. K., Martinez, T. &amp; Rudolph, G. Generating a novel sort algorithm using Reinforcement Programming. In <i>Proc. IEEE Congress on Evolutionary Computation</i> 1–8 (IEEE, 2010).</p></li><li data-counter="27."><p id="ref-CR27">Srivastava, S., Gulwani, S. &amp; Foster, J. S. From program verification to program synthesis. In <i>Proc. of the 37th Annual ACM SIGPLAN-SIGACT Symposium on Principles of Programming Languages</i> 313–326 (ACM, 2010).</p></li><li data-counter="28."><p id="ref-CR28">Ansel, J. et al. Petabricks: a language and compiler for algorithmic choice. <i>ACM Sigplan Notices</i> <b>44</b>, 38–49 (2009).</p></li><li data-counter="29."><p id="ref-CR29">Smith, D. R. The design of divide and conquer algorithms. <i>Sci. Comput. Program.</i> <b>5</b>, 37–58 (1985).</p></li><li data-counter="30."><p id="ref-CR30">Irvine, K. R. et al. <i>Assembly Language for Intel-Based Computers</i> (Prentice Hall, 2003).</p></li><li data-counter="31."><p id="ref-CR31">Shannon, C. E. XXII. Programming a computer for playing chess. <i>London, Edinb. Dublin Philos. Mag. J. Sci.</i> <b>41.314</b>, 256–275 (1950).</p></li><li data-counter="32."><p id="ref-CR32">Silver, D. et al. Mastering the game of Go with deep neural networks and tree search. <i>Nature</i> <b>529</b>, 484–489 (2016).</p></li><li data-counter="33."><p id="ref-CR33">Silver, D. et al. A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play. <i>Science</i> <b>362</b>, 1140–1144 (2018).</p></li><li data-counter="34."><p id="ref-CR34">Vaswani, A. et al. Attention is all you need. <i>Adv. Neural Inform. Proc. Syst.</i> <b>30</b>, 5999–6009 (2017).</p></li><li data-counter="35."><p id="ref-CR35">LLVM. LLVM users <a href="https://llvm.org/Users.html">https://llvm.org/Users.html</a> (LLVM, 2022).</p></li><li data-counter="36."><p id="ref-CR36">Bartlett, J. <i>Learn to Program with Assembly</i> 271–273 (Apress, 2021).</p></li><li data-counter="37."><p id="ref-CR37">Sutton, R. S. &amp; Barto, A. G. <i>Reinforcement Learning: An Introduction</i> 2nd edn (MIT Press, 2018).</p></li><li data-counter="38."><p id="ref-CR38">Schrittwieser, J. et al. Mastering atari, go, chess and shogi by planning with a learned model. <i>Nature</i> <b>588</b>, 604–609 (2020).</p></li><li data-counter="39."><p id="ref-CR39">Maillard, O.-A., Ryabko, D. &amp; Munos, R. Selecting the state-representation in reinforcement learning. <i>Adv. Neural Inform. Proc. Syst.</i> <b>24</b>, 2627–2635 (2011).</p></li><li data-counter="40."><p id="ref-CR40">Qian, R. et al. Spatiotemporal contrastive video representation learning. In <i>Proc. IEEE/CVF Conference on Computer Vision and Pattern Recognition</i> 6964–6974 (IEEE, 2021).</p></li><li data-counter="41."><p id="ref-CR41">Brown, T. et al. Language models are few-shot learners. <i>Adv. Neural Inform. Proc. Syst.</i> <b>33</b>, 1877–1901 (2020).</p></li><li data-counter="42."><p id="ref-CR42">Shazeer, N. Fast transformer decoding: one write-head is all you need. Preprint at <a href="https://arxiv.org/abs/1911.02150">https://arxiv.org/abs/1911.02150</a> (2019).</p></li><li data-counter="43."><p id="ref-CR43">Bundala, D. &amp; Závodny, J. Optimal sorting networks. In <i>Proc. International Conference on Language and Automata Theory and Applications</i> 236–247 (Springer, 2014).</p></li><li data-counter="44."><p id="ref-CR44">Hahn, G. J. &amp; Meeker, W. Q. <i>Statistical Intervals: A Guide for Practitioners</i> Vol. 92 (John Wiley &amp; Sons, 2011).</p></li><li data-counter="45."><p id="ref-CR45">Google. Protocol buffers, version 0.2.5; <a href="https://developers.google.com/protocol-buffers">https://developers.google.com/protocol-buffers</a> (2022).</p></li><li data-counter="46."><p id="ref-CR46">Google. VarInt protocol buffer serialization and deserialization, version 0.2.5; <a href="https://developers.google.com/protocol-buffers/docs/encoding">https://developers.google.com/protocol-buffers/docs/encoding</a> (2022).</p></li><li data-counter="47."><p id="ref-CR47">Protvin, R. &amp; Levenberg, J. Why Google stores billions of lines of code in a single repository. <i>Commun. ACM</i> <b>59</b>, 78–87 (2016).</p></li><li data-counter="48."><p id="ref-CR48">Berman, I. et al. Multi-collision resistant hash functions and their applications. In <i>Proc. Annual International Conference on the Theory and Applications of Cryptographic Techniques</i> 133–161 (Springer, 2018).</p></li><li data-counter="49."><p id="ref-CR49">Damgård, I. B. Collision free hash functions and public key signature schemes. In <i>Workshop on the Theory and Application of of Cryptographic Techniques</i> 203–216 (Springer, 1987).</p></li><li data-counter="50."><p id="ref-CR50">Hwang, M. Sort, Bitset (GitHub, 2021).</p></li><li data-counter="51."><p id="ref-CR51">Van der Maaten, L. &amp; Hinton, G. Visualizing data using t-SNE. <i>J. Mach. Learn. Res.</i> <b>9.11</b>, 2579–2605 (2008).</p></li><li data-counter="52."><p id="ref-CR52">Gulwani, S. et al. Synthesis of loop-free programs. <i>ACM SIGPLAN Notices</i> <b>46.6</b>, 62–73 (2011).</p></li><li data-counter="53."><p id="ref-CR53">Sasnauskas, R. et al. Souper: a synthesizing superoptimizer. Preprint at <a href="https://arxiv.org/abs/1711.04422">https://arxiv.org/abs/1711.04422</a> (2017).</p></li><li data-counter="54."><p id="ref-CR54">Warren, H. S. <i>Hacker’s Delight</i> (Pearson Education, 2013).</p></li><li data-counter="55."><p id="ref-CR55">Hamadi, Y., Jabbour, S. &amp; Sais, L. ManySAT: a parallel SAT solver. <i>J. Satisfiability, Boolean Model. Comput.</i> <b>6</b>, 245–262 (2010).</p></li><li data-counter="56."><p id="ref-CR56">Wolsey, L. A. Mixed integer programming. In <i>Wiley Encyclopedia of Computer Science and Engineering</i> 1–10 (Wiley, 2007).</p></li><li data-counter="57."><p id="ref-CR57">Nair, V. et al. Solving mixed integer programs using neural networks. Preprint at <a href="https://arxiv.org/abs/2012.13349">https://arxiv.org/abs/2012.13349</a> (2020).</p></li><li data-counter="58."><p id="ref-CR58">Inoue, H. et al. AA-sort: a new parallel sorting algorithm for multi-core SIMD processors. In <i>Proc. International Conference on Parallel Architecture and Compilation Techniques (PACT 2007)</i> 189–198 (IEEE, 2007).</p></li><li data-counter="59."><p id="ref-CR59">Yin, Z. et al. Efficient parallel sort on avx-512-based multi-core and many-core architectures. In <i>Proc. IEEE 21st International Conference on High Performance Computing and Communications</i> 168–176 (IEEE, 2019).</p></li><li data-counter="60."><p id="ref-CR60">Blacher, M. et al. Vectorized and performance-portable Quicksort. Preprint at <a href="https://arxiv.org/abs/2205.05982">https://arxiv.org/abs/2205.05982</a> (2022).</p></li><li data-counter="61."><p id="ref-CR61">Wikipedia. Single instruction, multiple data <a href="https://en.m.wikipedia.org/wiki/SIMD">https://en.m.wikipedia.org/wiki/SIMD</a> (2022).</p></li><li data-counter="62."><p id="ref-CR62">Ellis, K. et al. Write, execute, assess: program synthesis with a REPL. <i>Adv. Neural Inform. Proc. Syst.</i><b>32</b>, 9137–9146 (2019).</p></li><li data-counter="63."><p id="ref-CR63">Wang, H. et al. Automating reinforcement learning architecture design for code optimization. In <i>Proc. 31st ACM SIGPLAN International Conference on Compiler Construction</i> 129–143 (ACM, 2022).</p></li><li data-counter="64."><p id="ref-CR64">Shypula, A. G. et al. Learning to superoptimize real-world programs. Preprint at <a href="https://arxiv.org/abs/2109.13498">https://arxiv.org/abs/2109.13498</a> (2022).</p></li><li data-counter="65."><p id="ref-CR65">Chen, X., Liu, C. &amp; Song, D. Execution-guided neural program synthesis. In <i>Proc. International Conference on Learning Representations</i> (ICLR, 2018).</p></li><li data-counter="66."><p id="ref-CR66">Bunel, R. et al. Leveraging grammar and reinforcement learning for neural program synthesis. In <i>Proc. International Conference on Learning Representations</i> (ICLR, 2018).</p></li><li data-counter="67."><p id="ref-CR67">Aharoni, R. &amp; Goldberg, Y. Towards string-to-tree neural machine translation. In <i>Proc. 55th Annual Meeting of the Association for Computational Linguistics</i>132–140 (ACL, 2017).</p></li><li data-counter="68."><p id="ref-CR68">Dong, L. &amp; Lapata, M. Language to logical form with neural attention. In <i>Proc. 54th Annual Meeting of the Association for Computational Linguistics</i> 33–43 (ACL, 2016).</p></li><li data-counter="69."><p id="ref-CR69">Ibarz, B. et al. A generalist neural algorithmic learner. In <i>Proc. Learning on Graphs Conference</i> Vol. 198, 2:1–2:23 (PMLR, 2022).</p></li><li data-counter="70."><p id="ref-CR70">Chen, X., Song, D. &amp; Tian, Y. Latent execution for neural program synthesis beyond domain-specific languages. <i>Adv. Neural Inform. Proc. Syst.</i> <b>34</b>, 22196–22208 (2021).</p></li><li data-counter="71."><p id="ref-CR71">Parisotto, E. et al. Neuro-symbolic program synthesis. Preprint at <a href="https://arxiv.org/abs/1611.01855">https://arxiv.org/abs/1611.01855</a> (2016).</p></li><li data-counter="72."><p id="ref-CR72">Ellis, K., Solar-Lezama, A. &amp; Tenenbaum, J. Sampling for Bayesian program learning. <i>Adv. Neural Inform. Proc. Syst.</i> <b>29</b>, 1297–1305 (2016).</p></li></ol><p><a data-track="click" data-track-action="download citation references" data-track-label="link" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/s41586-023-06004-9?format=refman&amp;flavour=references">Download references<svg width="16" height="16" focusable="false" role="img" aria-hidden="true"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-download"></use></svg></a></p></div></div></div></section></div><section data-title="Acknowledgements"><div id="Ack1-section"><h2 id="Ack1">Acknowledgements</h2><p>We thank P. Kurylowicz, N. Anderson and Z. Ahmed for assistance coordinating the research; L. Dionne and N. Klauser for patiently reviewing our LLVM code; and N. Vaish, D. Gove, D. Kutenin and A. Fawzi for their helpful advice during the course of the project. We also thank our colleagues at DeepMind for their encouragement and support.</p></div></section><section aria-labelledby="author-information" data-title="Author information"><div id="author-information-section"><h2 id="author-information">Author information</h2><div id="author-information-content"><p><span id="author-notes">Author notes</span></p><ol><li id="na1"><p>These authors contributed equally: Daniel J. Mankowitz, Andrea Michi, Anton Zhernov, Marco Gelmi, Marco Selvi, Cosmin Paduraru, Edouard Leurent</p></li></ol><h3 id="affiliations">Authors and Affiliations</h3><ol><li id="Aff1"><p>Deepmind, London, UK</p><p>Daniel J. Mankowitz, Andrea Michi, Anton Zhernov, Marco Gelmi, Marco Selvi, Cosmin Paduraru, Edouard Leurent, Shariq Iqbal, Jean-Baptiste Lespiau, Alex Ahern, Thomas Köppe, Kevin Millikin, Stephen Gaffney, Sophie Elster, Jackson Broshear, Chris Gamble, Kieran Milan, Robert Tung, Taylan Cemgil, Mohammadamin Barekatain, Yujia Li, Amol Mandhane, Thomas Hubert, Julian Schrittwieser, Demis Hassabis, Pushmeet Kohli, Martin Riedmiller, Oriol Vinyals &amp; David Silver</p></li><li id="Aff2"><p>Google, Mountain View, CA, USA</p><p>Minjae Hwang</p></li></ol><h3 id="contributions">Contributions</h3><p>D.J.M., A.Michi and A.Z. conceived the idea and lead the research. A.Michi, D.J.M., A.Z., M.G., M.S., C.P., E.L., S.I. and A.Mandhane developed the neural network architecture and training. J.-B.L., C.P., M.G., D.J.M. and E.L. developed the baseline. M.G., A.Z., D.J.M., M.H., A.A., T.K. and K.Millikin analysed the generated algorithms and helped with the sort patch. D.J.M., A.Michi, A.Z., S.G., S.E., J.B., R.T., C.G. and K.Milan, managed the research. A.Michi, M.G. and M.S. led the technical platform. A.Mandhane, T.H., Y.L., J.S., T.C., M.B., P.K., M.R., D.S., O.V. and D.H. contributed technical advice and ideas. D.J.M. and A.Z. conceived the project. D.J.M., C.P., E.L., A.Michi, M.G., A.Z., P.K. and M.S. wrote the paper.</p><h3 id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" href="mailto:dmankowitz@deepmind.com">Daniel J. Mankowitz</a>.</p></div></div></section><section data-title="Ethics declarations"><div id="ethics-section"><h2 id="ethics">Ethics declarations</h2><div id="ethics-content">
              
                <h3 id="FPar2">Competing interests</h3>
                <p>D.J.M., A.Michi, A.Z., M.G., M.S., C.P., E.L., S.I., A.Mandhane, P.K., M.R., D.S. and O.V. are planning to file a patent application relating to subject matter contained in this paper in the name of DeepMind Technologies Limited. The remaining authors declare no competing interests.</p>
              
            </div></div></section><section data-title="Peer review"><div id="peer-review-section"><h2 id="peer-review">Peer review</h2><div id="peer-review-content">
              
              
                <h3 id="FPar1">Peer review information</h3>
                <p><i>Nature</i> thanks Zheng Wang and the other, anonymous, reviewer(s) for their contribution to the peer review of this work.</p>
              
            </div></div></section><section data-title="Additional information"><div id="additional-information-section"><h2 id="additional-information">Additional information</h2><p><b>Publisher’s note</b> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></div></section><section data-title="Extended data figures and tables"><div id="Sec41-section"><h2 id="Sec41">Extended data figures and tables</h2><div id="Sec41-content"><div data-test="supplementary-info"><div data-test="supp-item" id="Fig5"><h3><a data-track="click" data-track-action="view supplementary info" data-track-label="link" data-test="supp-info-link" href="https://www.nature.com/articles/s41586-023-06004-9/figures/5" data-supp-info-image="//media.springernature.com/lw685/springer-static/esm/art%3A10.1038%2Fs41586-023-06004-9/MediaObjects/41586_2023_6004_Fig5_ESM.jpg">Extended Data Fig. 1 The AlphaDev representation network architecture.</a></h3><p><b>(a)</b> The AlphaDev representation network comprises a Transformer Encoder network that receives as input the assembly algorithm generated thus far. It also contains a CPU State Encoder network that receives as input the current state of memory and registers. The exact architecture and hyperparameters can be found in the <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s41586-023-06004-9#MOESM1">Supplementary Information</a>, Appendix A. <b>(b)</b> Before inputting instructions into the Transformer Encoder network, each program instruction’s opcode and operands are converted to one-hot encodings and concatenated. The resulting encoding is then fed into the Transformer Encoder network.</p></div><div data-test="supp-item" id="Fig6"><h3><a data-track="click" data-track-action="view supplementary info" data-track-label="link" data-test="supp-info-link" href="https://www.nature.com/articles/s41586-023-06004-9/figures/6" data-supp-info-image="//media.springernature.com/lw685/springer-static/esm/art%3A10.1038%2Fs41586-023-06004-9/MediaObjects/41586_2023_6004_Fig6_ESM.jpg">Extended Data Fig. 2 An example sorting network<sup></sup></a><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 43" title="Bundala, D. &amp; Závodny, J. Optimal sorting networks. In Proc. International Conference on Language and Automata Theory and Applications 236–247 (Springer, 2014)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR43" id="ref-link-section-d81547407e3457">43</a>.</h3><p><b>(a)</b> The horizontal lines are called wires and the vertical lines are called comparators. <b>(b)</b> An initially unsorted sequence of values are input into the sorting network on the left hand side. At various stages two wires encounter a comparator. If the value at the top of the comparator is smaller than the value at the bottom of the comparator, the numbers switch wires. An optimal sorting network places comparators in specific positions so as to sort any sequence of unsorted values using the minimum number of comparators.</p></div><div data-test="supp-item" id="Fig7"><h3><a data-track="click" data-track-action="view supplementary info" data-track-label="link" data-test="supp-info-link" href="https://www.nature.com/articles/s41586-023-06004-9/figures/7" data-supp-info-image="//media.springernature.com/lw685/springer-static/esm/art%3A10.1038%2Fs41586-023-06004-9/MediaObjects/41586_2023_6004_Fig7_ESM.jpg">Extended Data Fig. 3 Hypothesis for improved exploration using AlphaDev.</a></h3><p><b>(a)</b> A 2D t-SNE<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 51" title="Van der Maaten, L. &amp; Hinton, G. Visualizing data using t-SNE. J. Mach. Learn. Res. 9.11, 2579–2605 (2008)." href="https://www.nature.com/articles/s41586-023-06004-9#ref-CR51" id="ref-link-section-d81547407e3495">51</a></sup> projection indicating the regions explored by AlphaDev (blue) compared to AlphaDev-S. <b>(b)</b> The same 2D t-SNE projection as in (a) with algorithm correctness superimposed onto each point from incorrect programs (purple) to correct programs (yellow). As seen in the figure, AlphaDev-S struggles to move out of local optima whereas AlphaDev is able to explore from the space of incorrect programs to the space of correct programs.</p></div><div data-test="supp-item"><div data-test="inline-table" data-container-section="table" id="table-3"><figure><figcaption><b id="Tab3" data-test="table-caption">Extended Data Table 1 Additional Assembly instructions</b></figcaption></figure></div></div><div data-test="supp-item"><div data-test="inline-table" data-container-section="table" id="table-4"><figure><figcaption><b id="Tab4" data-test="table-caption">Extended Data Table 2 Comparison of AlphaDev and AlphaDev-S for fixed sort</b></figcaption></figure></div></div><div data-test="supp-item"><div data-test="inline-table" data-container-section="table" id="table-5"><figure><figcaption><b id="Tab5" data-test="table-caption">Extended Data Table 3 Comparison of AlphaDev and AlphaDev-S on variable sort</b></figcaption></figure></div></div></div></div></div></section><section data-title="Supplementary information"><div id="Sec42-section"><h2 id="Sec42">Supplementary information</h2></div></section><section data-title="Rights and permissions"><div id="rightslink-section"><h2 id="rightslink">Rights and permissions</h2><div id="rightslink-content">
                <p><b>Open Access</b>  This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <a href="http://creativecommons.org/licenses/by/4.0/" rel="license">http://creativecommons.org/licenses/by/4.0/</a>.</p>
              <p><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Faster%20sorting%20algorithms%20discovered%20using%20deep%20reinforcement%20learning&amp;author=Daniel%20J.%20Mankowitz%20et%20al&amp;contentID=10.1038%2Fs41586-023-06004-9&amp;copyright=The%20Author%28s%29&amp;publication=0028-0836&amp;publicationDate=2023-06-07&amp;publisherName=SpringerNature&amp;orderBeanReset=true&amp;oa=CC%20BY">Reprints and Permissions</a></p></div></div></section><section aria-labelledby="article-info" data-title="About this article"><div id="article-info-section"><h2 id="article-info">About this article</h2><div id="article-info-content"><div><p><a data-crossmark="10.1038/s41586-023-06004-9" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1038/s41586-023-06004-9" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img width="57" height="81" alt="Check for updates. Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>"/></a></p><div><h3 id="citeas">Cite this article</h3><p>Mankowitz, D.J., Michi, A., Zhernov, A. <i>et al.</i> Faster sorting algorithms discovered using deep reinforcement learning.
                    <i>Nature</i> <b>618</b>, 257–263 (2023). https://doi.org/10.1038/s41586-023-06004-9</p><p><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" data-track-external="" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/s41586-023-06004-9?format=refman&amp;flavour=citation">Download citation<svg width="16" height="16" focusable="false" role="img" aria-hidden="true"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-download"></use></svg></a></p><ul data-test="publication-history"><li><p>Received<span>: </span><span><time datetime="2022-07-25">25 July 2022</time></span></p></li><li><p>Accepted<span>: </span><span><time datetime="2023-03-23">23 March 2023</time></span></p></li><li><p>Published<span>: </span><span><time datetime="2023-06-07">07 June 2023</time></span></p></li><li><p>Issue Date<span>: </span><span><time datetime="2023-06-08">08 June 2023</time></span></p></li><li><p><abbr title="Digital Object Identifier">DOI</abbr><span>: </span><span>https://doi.org/10.1038/s41586-023-06004-9</span></p></li></ul></div></div></div></div></section>
            </div></div>
  </body>
</html>
