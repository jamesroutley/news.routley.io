<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://rwmj.wordpress.com/2023/02/14/frame-pointers-vs-dwarf-my-verdict/">Original</a>
    <h1>Frame pointers vs. DWARF – my verdict</h1>
    
    <div id="readability-page-1" class="page"><div>
		
<p>A couple of weeks ago I wrote a blog posting here about Fedora having frame pointers (<a href="https://lwn.net/Articles/919940/">LWN backgrounder</a>, <a href="https://news.ycombinator.com/item?id=34632677">HN thread</a>).  <a href="https://rwmj.wordpress.com/2023/02/06/frame-pointers-an-important-update/">I made some mistakes in that blog posting and retracted it</a>, but I wasn’t wrong about the conclusions, just wrong about how I reached them.  Frame pointers are much better than DWARF.  DWARF unwinding might have some theoretical advantages but it’s worse in every practical respect.</p>



<p>In particular:</p>



<ol>
<li>Frame pointers give you much faster profiling with much less overhead.  This practically means you can do continuous performance collection and analysis which would be impossible with DWARF.</li>



<li>DWARF unwinding has foot-guns which make it easy to screw up and collect insufficient data for analysis.  You cannot know in advance how much data to collect.  The defaults are much too small, and even increasing the collection size to unreasonably large sizes isn’t enough.</li>



<li>The overhead of collecting DWARF callgraph data adversely affects what you’re trying to analyze.</li>



<li>Frame pointers have some corner cases which they don’t handle well (certain leaf and most inlined functions aren’t collected), but these don’t matter a great deal in reality.</li>



<li>DWARF unwinding can show inlined functions as if they are separate stack frames.  (Opinions differ as to whether or not this is an advantage.)</li>
</ol>



<p>Below I’ll try to demonstrate some of the issues, but first a little bit of background is necessary about how all this works.</p>



<p>When you run <code>perf record -a</code> on a workload, the kernel fires a timer interrupt on every CPU 100s or 1000s of times a second.  Each interrupt must collect a stack trace for that CPU at that moment which is then sent up to the userspace perf process that writes it to a <code>perf.data</code> file in the current directory.  Obviously collecting this stack trace and writing it to the file must be done as quickly as possible with the least overhead.</p>



<p>Also the stack trace may start inside the kernel and go all the way out to userspace (unless the CPU was running userspace code at the moment it was interrupted in which case it just collects userspace).  That involves unwinding the two different stacks.</p>



<p>For the kernel stack, the <a href="https://www.kernel.org/doc/html/latest/x86/orc-unwinder.html">kernel has its own unwinding information called ORC</a>.  For the userspace stack you choose (with the <code>perf --call-graph</code> option) whether to use frame pointers or DWARF.  For frame pointers the kernel is able to immediately walk up the userspace stack all the way to the top (assuming everything was compiled with frame pointers, but that is now true for Fedora 38).  For DWARF however the format is complicated and the kernel cannot unwind it immediately.  Instead the kernel just collects the user stack.  But collecting the whole stack would consume far too much storage, so by default it only collects the first 8K.  Many userspace stacks will be larger than this, in which case the data collection will simply be incomplete – it will never be possible to recover the full stack trace.  You can adjust the size of stack collected, but that massively bloats the <code>perf.data</code> file as we’ll see below.</p>



<p>To demonstrate what I mean, I collected a set of traces using fio and nbdkit on Fedora 38, using both frame pointers and DWARF.  The command is:</p>



<pre><code>sudo perf record -a -g [--call-graph=...] -- nbdkit -U - null 1G --run &#39;export uri; fio nbd.fio&#39;</code></pre>



<p>with the <a href="https://github.com/axboe/fio/blob/b65023f3c8849e122b2a223838ae9fdaed994e84/examples/nbd.fio#L1">nbd.fio file from fio’s examples</a>.</p>



<p>I used no <code>--call-graph</code> option for collecting frame pointers (as it is the default), and <code>--call-graph=dwarf,{4096,8192,16384,32768}</code> to collect the DWARF examples with 4 different stack sizes.</p>



<p>I converted the resulting data into <a href="https://www.brendangregg.com/flamegraphs.html">flame graphs using Brendan Gregg’s tools</a>.</p>



<p>Everything was run on my idle <a href="https://rwmj.wordpress.com/2019/09/04/amd-ryzen-9-3900x-nice/">12 core / 24 thread AMD development machine</a>.</p>



<figure><table><tbody><tr><td>Type</td><td>Size of perf.data</td><td>Lost chunks</td><td>Flame graph</td></tr><tr><td>Frame pointers</td><td>934 MB</td><td>0</td><td><a href="http://oirase.annexia.org/rwmj.wp.com/2023-fp/fio-fp.svg">Link</a></td></tr><tr><td>DWARF (4K)</td><td>10,104 MB</td><td>425</td><td><a href="http://oirase.annexia.org/rwmj.wp.com/2023-fp/fio-dwarf-4k.svg">Link</a></td></tr><tr><td>DWARF (8K)</td><td>18,733 MB</td><td>1,643</td><td><a href="http://oirase.annexia.org/rwmj.wp.com/2023-fp/fio-dwarf-8k.svg">Link</a></td></tr><tr><td>DWARF (16K)</td><td>35,149 MB</td><td>5,333</td><td><a href="http://oirase.annexia.org/rwmj.wp.com/2023-fp/fio-dwarf-16k.svg">Link</a></td></tr><tr><td>DWARF (32K)</td><td>57,590 MB</td><td>545,024</td><td><a href="http://oirase.annexia.org/rwmj.wp.com/2023-fp/fio-dwarf-32k.svg">Link</a></td></tr></tbody></table></figure>



<p>The first most obvious thing is that even with the smallest stack data collection, DWARF’s perf.data is over 10 times larger, and it balloons even larger once you start to collect more reasonable stack sizes.  For a single minute of data collection, collecting 10s of gigabytes of data is not very practical even on high end machines, and continuous performance analysis would be impossible at these data rates.</p>



<p>Related to this, the overhead of perf increases.  It is ~ 0.1% for frame pointers.  For DWARF the overhead goes: 0.8% (4K), 1.5% (8K), 2.8% (16K), 2.7% (32K).  But this disguises the true overhead because it doesn’t count the cost of writing to disk.  Unfortunately on this machine I have full disk encryption enabled (which does add a lot to the overhead of writing nearly 60 GB of perf data), but you can see the overhead of all that encryption separate from perf in the flame graph.  The total overhead of perf + writing + encryption is about 20%.</p>



<figure><img data-attachment-id="8202" data-permalink="https://rwmj.wordpress.com/2023/02/14/frame-pointers-vs-dwarf-my-verdict/perf-overhead/" data-orig-file="https://rwmj.files.wordpress.com/2023/02/perf-overhead.png" data-orig-size="640,311" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="perf-overhead" data-image-description="" data-image-caption="" data-medium-file="https://rwmj.files.wordpress.com/2023/02/perf-overhead.png?w=450" data-large-file="https://rwmj.files.wordpress.com/2023/02/perf-overhead.png?w=500" src="https://rwmj.files.wordpress.com/2023/02/perf-overhead.png?w=640" alt="" srcset="https://rwmj.files.wordpress.com/2023/02/perf-overhead.png 640w, https://rwmj.files.wordpress.com/2023/02/perf-overhead.png?w=150 150w, https://rwmj.files.wordpress.com/2023/02/perf-overhead.png?w=450 450w" sizes="(max-width: 640px) 100vw, 640px"/></figure>



<div><div>
<p>This may also be the reason for seeing so many “lost chunks” even on this very fast machine.  All of the DWARF tests even at the smallest size printed:</p>



<pre><code>Check IO/CPU overload!</code></pre>
</div></div>



<p>But is the DWARF data accurate? Clearly not.  This is to be expected, collecting a partial user stack is not going to be enough to reconstruct a stack trace, but remember that even with 4K of stack, the perf.data is already &gt; 10 times larger than for frame pointers.  Zooming in to the nbdkit process only and comparing the flamegraphs shows significant amounts of incomplete stack traces, even when collecting 32K of stack.</p>



<p>On the left, nbdkit with frame pointers (correct).  On the right, nbdkit with DWARF and 32K collection size.  Notice on the right the large number of unattached frames.  nbdkit <code>main()</code> does not directly call Unix domain socket send and receive functions!</p>



<figure><p><img id="8204" src="https://rwmj.files.wordpress.com/2023/02/framepointer-nbdkit.png" alt="" width="640" height="328"/><img id="8205" src="https://rwmj.files.wordpress.com/2023/02/dwarf-32k-nbdkit.png" alt="" width="640" height="336"/></p></figure>



<p>If 8K (the default) is insufficient, and even 32K is not enough, how large do we need to make the DWARF stack collection?  I couldn’t find out because I don’t have enough space for the expected 120 GB <code>perf.data</code> file at the next size up.</p>



<p>Let’s have a look at one thing which DWARF can do — show inlined and leaf functions.  The stack trace for these is more accurate as you can see below.  (To reproduce, zoom in on the <code>nbd_poll</code> function).  On the left, frame pointers.  On the right DWARF with 32K stacks, showing the extra <code>enter_*</code> frames which are inlined.</p>



<figure><img data-attachment-id="8210" data-permalink="https://rwmj.wordpress.com/2023/02/14/frame-pointers-vs-dwarf-my-verdict/nbdpoll-both/" data-orig-file="https://rwmj.files.wordpress.com/2023/02/nbdpoll-both.png" data-orig-size="388,186" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="nbdpoll-both" data-image-description="" data-image-caption="" data-medium-file="https://rwmj.files.wordpress.com/2023/02/nbdpoll-both.png?w=388" data-large-file="https://rwmj.files.wordpress.com/2023/02/nbdpoll-both.png?w=388" src="https://rwmj.files.wordpress.com/2023/02/nbdpoll-both.png?w=388" alt="" srcset="https://rwmj.files.wordpress.com/2023/02/nbdpoll-both.png 388w, https://rwmj.files.wordpress.com/2023/02/nbdpoll-both.png?w=150 150w" sizes="(max-width: 388px) 100vw, 388px"/></figure>



<p>My final summary here is that for most purposes you would be better off using frame pointers, and it’s a good thing that Fedora 38 now compiles everything with frame pointers.  It should result in easier performance analysis, and even makes continuous performance analysis more plausible.</p>
	</div></div>
  </body>
</html>
