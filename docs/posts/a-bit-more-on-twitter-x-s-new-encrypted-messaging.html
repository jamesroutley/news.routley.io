<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.cryptographyengineering.com/2025/06/09/a-bit-more-on-twitter-xs-new-encrypted-messaging/">Original</a>
    <h1>A bit more on Twitter/X&#39;s new encrypted messaging</h1>
    
    <div id="readability-page-1" class="page"><article id="post-8540">
	
	<div>
		
<p>Matthew Garrett has a <a href="https://mjg59.dreamwidth.org/71646.html">nice post</a> about Twitter (uh, X)’s new end-to-end encryption messaging protocol, which is now called XChat. The TL;DR of Matthew’s post is that from a cryptographic perspective, XChat isn’t great. The details are all contained within Matthew’s post, but here’s a quick TL;DR:</p>



<ul>
<li><strong>There’s no forward secrecy.</strong> Unlike Signal protocol, which uses a <a href="https://signal.org/docs/specifications/doubleratchet/">double-ratchet</a> to continuously update the user’s secret keys, the XChat cryptography just encrypts each message under a recipient’s long-term public key. The actual encryption mechanism is based on an encryption scheme from <a href="https://doc.libsodium.org/">libsodium</a>.</li>



<li><strong>User private keys are stored at X. </strong>XChat stores user <em>private key</em>s at its own servers. To obtain your private keys, you first log into X’s key-storage system using a password such as PIN. This is needed to support stateless clients like web browsers, and in fairness it’s not dissimilar to what Meta has done with its encryption for <a href="https://about.fb.com/news/2023/12/default-end-to-end-encryption-on-messenger/">Facebook Messenger and Instagram</a>. Of course, those services use Hardware Security Modules (HSMs), and critically, <span>X does not appear to.</span></li>



<li><strong>X’s key storage is based on “Juicebox.” </strong>To implement their secret-storage system, XChat uses a protocol called <a href="https://juicebox.xyz/">Juicebox</a>. Juicebox “shards” your key material across three servers, so that in principle the loss or compromise of one server won’t hurt you. </li>
</ul>



<p>Matthew’s post correctly identifies that the major vulnerability in X’s system is this key storage approach. If decryption keys live in three servers that are all under X’s control, then <span>X can probably obtain anyone’s key and decrypt their messages.</span><em> </em>X could do this for their own internal purposes: for example because their famously chill owner got angry at some user. Or they could do it because a warrant or subpoena compels them to. If we judge XChat as an end-to-end encryption scheme, this seems like a pretty game-over type of vulnerability.</p>



<p>So in a sense, everything comes down to the security of Juicebox <span>and the specific deployment choices that X made.</span> Since Matthew wrote his post, I’ve learned a bit more about both of these things. In this post I’d like to go on a slightly deeper dive into the Juicebox portion of X’s system. This will hopefully shed some light on what X is up to, and why you shouldn’t use XChat.</p>



<h3>What’s Juicebox even for?</h3>



<p>Many end-to-end encryption (E2E) apps have run into a specific problem: these systems require users to store their own secret keys. Unfortunately, users are just plain bad at this. </p>



<p>Sometimes we forget keys because we lose our devices. Often we have more than one device, which means our keys end up in the wrong place. A much worse situation occurs when apps want to work in ordinary web browsers: this means that secret keys have to be airlifted into that context as well. </p>



<p>The obvious remedy for this problem is just to store secret keys with the service provider itself. This is convenient, but completely misses the <em>whole point of end-to-end encryption</em>, which is that service providers should not have access to your secrets! Storing decryption keys — in an accessible form — on the provider’s servers is absolutely a no-go.</p>



<p>One way out of this conundrum is for the user to <span>encrypt</span> their secret key, then upload the encrypted value to the service provider. In theory, they can download their secret keys anytime they want and they should know that their secrets are safe. But of course there’s a problem: <em>what secret key are you going to use to encrypt your secret key!?</em> Answering this question quickly leads you into an infinite pile of turtles.</p>


<div>
<figure><a href="https://blog.cryptographyengineering.com/wp-content/uploads/2025/06/image.png"><img data-attachment-id="8555" data-permalink="https://blog.cryptographyengineering.com/2025/06/09/a-bit-more-on-twitter-xs-new-encrypted-messaging/image-81/" data-orig-file="https://blog.cryptographyengineering.com/wp-content/uploads/2025/06/image.png" data-orig-size="1224,1226" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://blog.cryptographyengineering.com/wp-content/uploads/2025/06/image.png?w=300" data-large-file="https://blog.cryptographyengineering.com/wp-content/uploads/2025/06/image.png?w=700" width="1022" height="1023" src="https://blog.cryptographyengineering.com/wp-content/uploads/2025/06/image.png?w=1022" alt=""/></a></figure></div>


<p>Rather than descend into paradox, systems like Juicebox, Signal SVR, and <a href="https://blog.cryptographyengineering.com/2016/08/13/is-apples-cloud-key-vault-crypto/">iCloud Key Vault</a> offer an alternative. Their observation is that while <em>cryptographic keys are hard to hang on to</em>, users generally <span>do</span> remember simple passwords like PINs, particularly if they’re asked to re-enter them periodically. <em>What if we use the user’s PIN/password to encrypt the stronger cryptographic key that we upload to the server?</em></p>



<p>While this is better than nothing, it isn’t good. Most human-selected passwords and PINs make for terrible cryptographic keys. In particular, short PINs (like the 6-digit decimal pins many people use for their phone passcode) are vulnerable to efficient brute-force guessing attacks. A six-digit PIN provides at most 2<sup>20</sup> security, which is what cryptographers call “a pretty small number.” Even if you use a “hard” key derivation function like <a href="https://en.wikipedia.org/wiki/Scrypt">scrypt</a> or <a href="https://en.wikipedia.org/wiki/Argon2">Argon2</a> with insane difficulty settings, you’re still probably still going to lose your data.</p>



<p>Fortunately there is another way.</p>



<p>For many years, cryptographers have considered the problem of turning “weak secrets” into strong ones. The problem is sometimes known as <em><a href="https://www.usenix.org/system/files/conference/usenixsecurity17/sec17-lai.pdf">password</a> <a href="https://dl.acm.org/doi/10.1145/3372297.3417266">hardening</a></em>, and doing it well usually requires additional components. First, you need to have some strong cryptographic secret that can be “mixed” into the user’s password to make a produce a truly strong encryption key. Second, you need some mechanism to <em>limit</em> the number of guessing attempts that the user makes, so an attacker can’t simply run an online attack to work through the PIN-space. <span>This cannot be enforced using cryptography alone</span>: you must add a server (or servers) to enforce these checks. Critically, the  server will place limits on how many <em>incorrect passwords</em> the user can enter: <em>e.g., </em>after ten incorrect attempts, the user’s account gets locked or erased.</p>



<p>In one sense, we’re right back where we started: someone needs to operate a a server. If that server is under the control of the service provider, then they can disable the guessing limits and/or extract the server’s secret key material, at which point you’re back to square one. </p>



<p>Many services have engineered some reasonable solutions to this problem, however. They boil down to the following alternatives, which can be implemented separately or together:</p>



<ol>
<li>The server can be implemented inside of a specialized Hardware Security Module, which is set up so that the provider cannot reprogram it or access its key material (at least, after it’s been configured.) This approach was pioneered by Apple, and is now in use by <a href="https://blog.cryptographyengineering.com/2016/08/13/is-apples-cloud-key-vault-crypto/">iCloud Key Vault</a>, <a href="https://blog.cryptographyengineering.com/2020/07/10/a-few-thoughts-about-signals-secure-value-recovery/">Signal SVR</a>, <a href="https://engineering.fb.com/2021/09/10/security/whatsapp-e2ee-backups/">WhatsApp</a> and <a href="https://about.fb.com/news/2023/12/default-end-to-end-encryption-on-messenger/">Facebook Messenger</a>.</li>



<li>Alternatively, the server can be “split up” into multiple pieces that are each run by different parties. The idea here is that the user must contact <em>T</em> out of <em>N</em> different servers in order to obtain the correct key (a common example is 2-of-3.) As long as an attacker cannot compromise <em>T</em> different servers, the combined system will still be able to enforce the guessing limits and prevent attackers from getting the key. Naturally this idea fundamentally depends on the assumption that the servers are not run by the same party!</li>
</ol>



<p>And at last, we come to Juicebox.</p>



<p>Juicebox is an software-based distributed key hardening service that can be implemented across multiple servers. Users can “enroll” their account into the system, at which point the Juicebox servers will convert their PIN/password into a strong cryptographic key (by mixing it with a secret stored on the Juicebox servers.) Later on, they can contact the Juicebox servers and — assuming they enter the right password, and don’t try too many incorrect guesses — they can obtain that same cryptographic key from the system. Users can specify the number of servers (<em>N</em>) and the threshold (<em>T</em>), and the goal is that the system can survive the loss (or unavailability) of N-T servers, and it should retain its security even if an attacker compromises <em>A&lt;T</em> of them. Most critically, Juicebox enforces limits: if too many incorrect passwords are entered, Juicebox will lock or destroy the user’s account.</p>



<p>In principle, Juicebox servers (called “<em>realms</em>” in the project’s lingo) can be either “software based” or they can be deployed inside of HSMs. <span>However, to the best of my knowledge the HSM capability is not fully supported</span>, and has not been used in deployments (at X or anywhere else.) This means the security of XChat’s version of Juicebox probably comes down to a question of who runs the servers.</p>



<h3>So who runs X’s Juicebox servers, and do they use HSMs?</h3>



<p>To the best of my knowledge, all of the XChat servers are run in software by Twitter/X itself. If this turns out to be incorrect, I will be thrilled to update this post. But so far I’ve seen nothing to indicate that they’re run by different parties, or that this system is in any way hardened against legal requests.</p>



<p>To put this more explicitly, without any protections like the verifiable use of HSMs and/or distributing Juicebox servers across mutually-distrustful operators, having three servers does relatively little to protect users’ secrets against the service operator. And even if X is secretly implementing these protections, implementing them in secret is <span>stupid.</span> As a wise man once said:</p>


<div>
<figure><a href="https://blog.cryptographyengineering.com/wp-content/uploads/2025/06/image-3.png"><img data-attachment-id="8577" data-permalink="https://blog.cryptographyengineering.com/2025/06/09/a-bit-more-on-twitter-xs-new-encrypted-messaging/image-84/" data-orig-file="https://blog.cryptographyengineering.com/wp-content/uploads/2025/06/image-3.png" data-orig-size="720,405" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://blog.cryptographyengineering.com/wp-content/uploads/2025/06/image-3.png?w=300" data-large-file="https://blog.cryptographyengineering.com/wp-content/uploads/2025/06/image-3.png?w=700" width="720" height="405" src="https://blog.cryptographyengineering.com/wp-content/uploads/2025/06/image-3.png?w=720" alt=""/></a></figure></div>


<p>Verifying that the XChat Juicebox servers are software-only is more complicated. Digging around in the Juicebox Github, you’ll find a software-only as well as an HSM-specific implementation of their “realms.” Specifically, there is an <a href="https://github.com/juicebox-systems/juicebox-hsm-realm">entire repository</a> dedicated to supporting Juicebox on <a href="https://www.entrust.com/products/hsm/nshield-solo">Entrust nShield Solo XC HSMs</a> (see here for <a href="https://juicebox.xyz/blog/running-a-hsm-realm">instructions</a>) although this same code can also be deployed outside of HSMs. There is even a cool “<a href="https://github.com/juicebox-systems/ceremony">ceremony</a>” document that a group of administrators can perform to certify that they set the HSM up correctly, and that they destroyed all of the cards that could allow it to be re-programmed! </p>





<p>However, after speaking to Juicebox’s protocol designer <a href="https://github.com/imperiopolis">Nora Trapp</a>, I’m doubtful that any of this is in use at X. Nora told me that the Juicebox project shut down over a year ago and the engineers moved on, and what code there is now open source and not actively maintained (this matches with project commits I can see.) Nora also looked at XChat’s Juicebox deployment and sent me the following commentary:</p>



<blockquote>
<p>From what I’ve seen, there are four realms currently in use by Twitter: <code><a href="http://realm-a.x.com" target="_blank" rel="noreferrer noopener">realm-a.x.com</a></code>, <code><a href="http://realm-b.x.com" target="_blank" rel="noreferrer noopener">realm-b.x.com</a></code>, <code><a href="http://realm-east1.x.com" target="_blank" rel="noreferrer noopener">realm-east1.x.com</a></code>, and <code><a href="http://realm-west1.x.com" target="_blank" rel="noreferrer noopener">realm-west1.x.com</a></code>.</p>



<ul>
<li><code>realm-a</code> and <code>realm-b</code> are definitely software realms. They don’t use Noise (only true of software realms) and rely solely on TLS. In contrast, HSM-backed realms use Noise within TLS, with TLS terminated at the LB and Noise inside the HSM.</li>



<li><code>realm-east1</code> and <code>realm-west1</code> appear to run code from <a href="https://github.com/juicebox-systems/juicebox-hsm-realm" target="_blank" rel="noreferrer noopener">juicebox-hsm-realm</a>. For example, hitting <code><a href="https://realm-east1.x.com/livez" target="_blank" rel="noreferrer noopener">https://realm-east1.x.com/livez</a></code> shows they’re likely using the repo unmodified from <code>main</code>. However, this doesn’t mean they’re HSM-backed. The repo includes a “software HSM” for testing, which is insecure and doesn’t provide actual HSM properties.</li>
</ul>



<p>Timing analysis (e.g. via the convenient <code>x-exec-time</code> response header X left in place) suggests these are indeed using the software HSM. Real HSMs are typically significantly slower. And even if by some chance they’re running real HSMs, no ceremony has been published, so there’s no reason to trust they’re secure or that the key material isn’t exfiltrated.</p>
</blockquote>



<p>Nora also <a href="https://juicebox.xyz/blog/dont-put-all-your-juice-in-one-box">wrote a post very recently warning deployers to stop placing all servers under the control of a single service provider</a>, which seems very applicable to what Twitter/X is doing.</p>



<p>Obviously this doesn’t prove that X isn’t using HSMs. Though, obviously, there’s no reason that you should hope something is secure when the deployer is going out of their way not to tell you it is. When it comes to XChat, my advice is that you should assume this deployment is (1) entirely in software, and (2) all Juicebox “realms” are run by the same organization. This means you should assume that <em>your decryption keys could be recovered by X’s server administrators</em> with at most a little fuss, unless you use a very strong password.</p>



<h3>That’s bad, but let’s talk more about the Juicebox protocol anyway!</h3>



<p>If all you came for was a bit of discussion about the security posture of XChat, then <a href="https://mjg59.dreamwidth.org/71646.html">Matthew’s post</a> and the additional notes above are all you need. Unless and until X proves that they’re using HSMs (and have destroyed all programming cards) you should just assume that their Juicebox instantiation is based on software realms under X’s control, and that means it is likely vulnerable to brute-force password-guessing attacks.</p>



<p>The rest of this post is going to look past X. </p>



<p>Let’s assume that a deployer has configured Juicebox intelligently: meaning that some/all realms will be deployed inside of HSMs, and/or realms are spread across multiple organizational trust boundaries — such that no single organization can easily demand recovery of anyone’s password. The question we want to ask now is: what guarantees does Juicebox provide in this setting, and how does the protocol work?</p>



<p><strong>Threshold OPRFs. </strong>The core cryptographic primitive <a href="https://juicebox.xyz/assets/whitepapers/juiceboxprotocol_revision7_20230807.pdf">inside of Juicebox</a> is called a <em>threshold oblivious pseudorandom function</em>, or t-OPRF. I’ve written about OPRFs before, specifically <a href="https://blog.cryptographyengineering.com/2018/10/19/lets-talk-about-pake/">in the context of Password-Authenticated Key Agreement</a> (PAKE schemes.) Nonetheless, I think it’s helpful to start from the top.</p>



<p>Let’s leave aside the “oblivious” part for a minute. <a href="https://blog.cryptographyengineering.com/2023/05/08/prfs-prps-and-other-fantastic-things/">PRFs are functions</a> that take in a key <em>K</em> and a string <em>P</em> (for example, a password), and output a string of bits. We might write as: </p>



<p><em>O</em> = PRF(<em>K, P</em>)</p>



<p>Provided that an attacker does not know the key, the resulting string <em>O</em> should <span>look</span> random, meaning that the output of a PRF makes for excellent cryptographic keys. In many practical implementations, PRFs are realized using functions like <a href="https://en.wikipedia.org/wiki/HMAC">HMAC</a> or <a href="https://en.wikipedia.org/wiki/CBC-MAC">CBC-MAC</a>; however, there are many different ways to build them.</p>



<p>An <span>oblivious</span> PRF (OPRF) is a two-party cryptographic protocol that helps a client and server jointly compute the output of a PRF. It works like this:</p>



<ol>
<li>Imagine a server has the cryptographic key <em>K.</em></li>



<li>The client has their string <em>P</em> (such as a password.)</li>



<li>At the end of a successful protocol run, the <span>client</span> should obtain <em>O</em> = PRF(<em>K, P</em>). The server gets no output at all.</li>



<li>Critically: <span>neither party should learn the other party’s input</span>, and the server <span>should not learn the client’s result</span>, either.</li>
</ol>



<p>With this tool in hand, it’s easy to build a very simple password-hardening protocol. Simply configure the server with a key <em>K </em>(preferably a different key for every user account), and then have the client run the OPRF protocol with the server to obtain <em>O</em> = PRF(<em>K, P</em>). The resulting value <em>O</em> will make for an excellent encryption key, which the client can use to encrypt any secret values it wants. The best part of this arrangement is that the OPRF protocol ensures that the server never learns the user’s password <em>P</em>, so no information leaks even if the server is fully malicious!</p>



<p>This basic design has some limitations, of course. It does not allow the server to <span>limit</span> the number password guesses, nor does it allow us to spread the process over many different servers.</p>



<p>Addressing the first problem is easy. When the client first registers their account with the server, they can run the OPRF protocol to obtain <em>O</em> = PRF(<em>K, P</em>). Next, they compute some “authenticator tag” <em>T </em>that’s derived in some way from the secret <em>O</em>. They can then store that tag <em>T</em> on the server. When a user returns to log back into the system, the client and server can run the OPRF protocol, and then conduct some process to verify that the <em>O</em> received by the client is consistent with the tag <em>T</em> stored at the server. (<span>The exact process for doing this is important, and I’ll discuss it further below.)</span> If this is <em>unsuccessful</em>, then the server can increment a counter to indicate an incorrect password guess on that user’s account. If the protocol completes successfully, then the server should reset that counter back to zero.<sup>1</sup></p>



<p>Critically, when the counter reaches some maximum (usually ten incorrect attempts), the server must lock the user’s account — or much better, delete the account-specific key <em>K</em>. This is what prevents attackers from systematically guessing their way through every possible PIN.</p>



<p>Splitting up the PRF into multiple servers is only slightly more complicated. The basic idea relies on the fact that the <a href="https://datatracker.ietf.org/doc/rfc9497/">specific OPRF used by Juicebox</a> is based on elliptic curves, and this makes it very amenable to threshold implementations. I’m going to put the details into a <a href="https://blog.cryptographyengineering.com/some-quick-notes-on-t-oprfs/">separate page right here </a>since it’s a little boring. But you should just take away that (1) the service operator can split up the key <em>K</em> across multiple servers, and (2) a client can talk to any <em>T</em> of them and eventually obtain PRF(K, P). </p>



<h3><strong>How does the client prove it got the right key</strong>, and what attacks are there?</h3>



<p>You’ll notice that these “incorrect attempt” counters are a big part of the protection inside of a system like Juicebox. As long as an attacker can only make, say, a maximum of ten incorrect guessing attempts, then even a relatively weak password like 234984 is probably not too bad. If an attacker can make <em>many possible</em> guesses, then the whole system is fairly weak.</p>



<p>Note that in most of these attacks we are going to make the very strong assumption that <span>the server operator is the attacker</span><em> </em>and that they’ve deployed Juicebox in such a way that they can’t just read the secrets out of their own instance (e.g., in this hypothetical scenario, they have deployed Juicebox using HSMs or distributed trust.) Since the whole point of end-to-end encryption is that users’ secret keys should not be known to a server operator, this isn’t too strong of an assumption. Moreover, we’ve recently <a href="https://blog.cryptographyengineering.com/2025/02/12/u-k-asks-to-backdoor-icloud-backup-encryption/">seen governments make secret requests to companies like Apple</a> to force them to bypass their end-to-end encrypted services. This means that both hacking and legal compulsion are real concerns. </p>



<p>Within this setting there exist a handful of attacks that could come up in a system like Juicebox. Some are easier than others to prevent:</p>



<ol>
<li>An attacker could try to enter a few password guesses, then wait for the real user to log in. As long as the real user enters the correct password, the attempt counter on the server(s) will drop back to zero. This attack could allow you to make up to, say, nine invalid guesses for each genuine user login.<sup>2</sup> </li>



<li>If the servers don’t coordinate with each other, a smart attacker could try to guess passwords against different subsets of the Juicebox servers: for example if 2-of-10 servers are needed to recover the key, then an attacker actually could actually obtain many more than ten guesses. This is because the attacker could make at least ten attempts with each <em>subset</em> comprising two servers, before all the necessary servers locked them out. Juicebox’s <a href="https://github.com/juicebox-systems/juicebox-hsm-realm?tab=readme-ov-file">HSM implementation</a> actually goes to some lengths to prevent this (as <a href="https://github.com/signalapp/SecureValueRecovery2">SVR</a> did before them) by having servers share the current password counter values with each other using a <a href="https://en.wikipedia.org/wiki/Consensus_(computer_science)">consensus protocol</a>.</li>
</ol>



<p>Another possibility is that a malicious (software) server operator could try to attack the protocol directly. Just for fun, I thought it might be interesting to conclude with one <em>possible</em> attack I noticed while perusing the protocol description. I’m almost certain this won’t work in practice — and the Juicebox developers agree, but I thought it was a fun illustration of the <em>types</em> of vulnerabilities that show up in these systems.</p>



<p>Recall then whenever a Juicebox client successfully completes the protocol with a set of <em>T</em> servers, it must somehow convince those servers that it obtained the right key. This is necessary because a correct password entry should <span>reset</span> those servers’ attempt counters back to zero, whereas an <em>incorrect</em> guess will increase the attempt counter. (Without a mechanism to reset the counter, the counter will keep rising until the user’s account gets permanently locked.)</p>



<p><a href="https://juicebox.xyz/assets/whitepapers/juiceboxprotocol_revision7_20230807.pdf">The client deals with this</a> by first computing a value called the unlockKey from the t-OPRF output, and then calculating a set of “tags” called the unlockKeyTags, one for each server (realm) in the system:</p>


<div>
<figure><a href="https://blog.cryptographyengineering.com/wp-content/uploads/2025/06/image-5.png"><img data-attachment-id="8612" data-permalink="https://blog.cryptographyengineering.com/2025/06/09/a-bit-more-on-twitter-xs-new-encrypted-messaging/image-86/" data-orig-file="https://blog.cryptographyengineering.com/wp-content/uploads/2025/06/image-5.png" data-orig-size="1518,1332" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://blog.cryptographyengineering.com/wp-content/uploads/2025/06/image-5.png?w=300" data-large-file="https://blog.cryptographyengineering.com/wp-content/uploads/2025/06/image-5.png?w=700" loading="lazy" width="1024" height="898" src="https://blog.cryptographyengineering.com/wp-content/uploads/2025/06/image-5.png?w=1024" alt=""/></a></figure></div>


<p>The calculation of each unlockKeyTags[i] value is customized to include the “realm ID” of the server, which means that the tag for server <em>i</em> is specific only to that server. It cannot be extracted from a malicious server <em>i </em>and replayed against server <em>j</em>, which would be very bad. The client then sends each value unlockKeyTags[i] to the appropriate server. The servers can verify the received tag against a copy they stored during the account registration process. If it matches, they reset their counter back to zero as follows:</p>


<div>
<figure><a href="https://blog.cryptographyengineering.com/wp-content/uploads/2025/06/image-6.png"><img data-attachment-id="8614" data-permalink="https://blog.cryptographyengineering.com/2025/06/09/a-bit-more-on-twitter-xs-new-encrypted-messaging/image-87/" data-orig-file="https://blog.cryptographyengineering.com/wp-content/uploads/2025/06/image-6.png" data-orig-size="1246,408" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="image" data-image-description="" data-image-caption="" data-medium-file="https://blog.cryptographyengineering.com/wp-content/uploads/2025/06/image-6.png?w=300" data-large-file="https://blog.cryptographyengineering.com/wp-content/uploads/2025/06/image-6.png?w=700" loading="lazy" width="1024" height="335" src="https://blog.cryptographyengineering.com/wp-content/uploads/2025/06/image-6.png?w=1024" alt=""/></a></figure></div>


<p>However, the only thing that differentiates these tags from one another is the notion that realm IDs for different servers will always be different. What if this assumption isn’t correct?</p>



<p>The attack I’m concerned about is pretty bizarre, but it looks like this. Imagine a user has previously registered its key into several real HSM-based servers. Now someone hacks into the service provider. This hacker “tricks” clients into sending subsequent login requests to a <span>new set of malicious servers</span> that the attacker spins up using software (i.e., no HSM protections.)</p>



<p>Ordinarily this attack wouldn’t be a disaster, since the OPRF should prevent those new servers from learning the user’s password inputs. But let’s imagine that the hacker sets the “realm ID” of these new servers to be identical to the realm ID of the real (HSM) servers. In this case, the value of unlockKeyTag[i] sent to the malicious servers will be <em>identical</em> to the value that would have been stored within the HSM-based servers. Once the attacker learns this value, they can make an unlimited number of guesses against the HSM server with the same realm ID: this is because the stolen unlockKeyTags[i] value will reset the HSM server’s counter. </p>



<p>I ran this past Nora and she pointed out a number of practical issues that will probably make this sort of attack much less likely to work, but it’s still fun to find this sort of thing. More importantly, I think it shows how delicate distributed protocols like this can be, and how sometimes one’s assumptions may not always be valid. </p>



<p><em>Post image: Noah Berger/AP Photo</em></p>



<p><em>Notes:</em></p>



<ol>
<li>Obviously this can be dangerous. An attacker who just wants to deny service to the user can enter deliberately-incorrect guesses until the user’s account becomes permanently locked. To prevent this, most services require that you log In using a traditional password first, then you can access the password strengthening server second. Some systems also add time delays, to ensure that an attacker cannot quickly exhaust the counter.</li>



<li>The “try N attempts and then let the client log in normally” attack was outlined to me by Ian Miers.</li>
</ol>
	</div><!-- .entry-content -->

			<!-- .entry-footer -->
	</article></div>
  </body>
</html>
