<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.jeffgeerling.com/blog/2026/ai-is-destroying-open-source/">Original</a>
    <h1>AI is destroying Open Source, and it&#39;s not even good yet</h1>
    
    <div id="readability-page-1" class="page"><section><p>Over the weekend Ars Technica <a href="https://arstechnica.com/ai/2026/02/after-a-routine-code-rejection-an-ai-agent-published-a-hit-piece-on-someone-by-name/">retracted an article</a> because the AI a writer used <a href="https://bsky.app/profile/benjedwards.com/post/3mewgow6ch22p">hallucinated quotes</a> from an open source library maintainer.</p><p>The irony here is the maintainer in question, Scott Shambaugh, was <a href="https://theshamblog.com/an-ai-agent-published-a-hit-piece-on-me/">harassed by someone&#39;s AI agent</a> over not merging it&#39;s AI slop code.</p><p>It&#39;s likely the bot was running through someone&#39;s local &#39;agentic AI&#39; instance (likely using OpenClaw). The guy who built OpenClaw was just hired by OpenAI to &#34;work on bringing agents to everyone.&#34; You&#39;ll have to forgive me if I&#39;m not enthusastic about that.</p><h2 id="video">Video</h2><p>This blog post is a lightly-edited transcript of the video I published to YouTube today. Scroll past the video embed if you&#39;re like me, and you&#39;d rather read the text :)</p><div><p><iframe src="https://www.youtube.com/embed/bZJ7A1QoUEI" frameborder="0" allowfullscreen=""></iframe></p></div><h2 id="impacts-on-open-source">Impacts on Open Source</h2><p>Last month, even before OpenClaw&#39;s release, curl maintainer Daniel Stenberg <a href="https://daniel.haxx.se/blog/2026/01/26/the-end-of-the-curl-bug-bounty/">dropped bug bounties</a> because AI slop resulted in actual <em>useful</em> vulnerability reports going from 15% of all submissions down to 5%.</p><p>And that&#39;s not the worst of it—the authors of these bug reports seem to have a more entitled attitude:</p><blockquote><p>These &#34;helpers&#34; try too hard to twist whatever they find into something horribly bad and a critical vulnerability, but they rarely actively contribute to actually improve curl. They can go to extreme efforts to argue and insist on their specific current finding, but not to write a fix or work with the team on improving curl long-term etc. I don&#39;t think we need more of that.</p></blockquote><p>These agentic AI users don&#39;t care about curl. They don&#39;t care about Daniel or other open source maintainers. They just want to grab quick cash bounties using their private AI army.</p><p>I manage <a href="https://github.com/geerlingguy">over 300 open source projects</a>, and while many are more niche than curl or matplotlib, I&#39;ve seen my own increase in AI slop PRs.</p><p>It&#39;s gotten <em>so</em> bad, GitHub added a feature to <a href="https://github.blog/changelog/2026-02-13-new-repository-settings-for-configuring-pull-request-access/">disable Pull Requests entirely</a>. Pull Requests are the fundamental thing that made GitHub popular. And now we&#39;ll see that feature closed off in more and more repos.</p><p>AI slop generation is getting easier, but it&#39;s not getting smarter. From what I&#39;ve seen, models have <a href="https://er.educause.edu/articles/2025/9/an-ai-plateau">hit a plateau</a> where code generation is <em>pretty good</em><sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>...</p><p>But it&#39;s not improving like it did the past few years. The problem is the humans who <em>review</em> the code—who are responsible for the useful software that keeps our systems going—don&#39;t have infinite resources (unlike AI companies).</p><p>Some people suggest AI could take over code review too, but that&#39;s not the answer.</p><p>If you&#39;re running a personal weather dashboard or building a toy server for your Homelab, fine. But I wouldn&#39;t run my production apps—that actually make money or could cause harm if they break—on unreviewed AI code.</p><p>If this was a problem already, OpenClaw&#39;s release, and this hiring by OpenAI to democratize agentic AI further, will only make it worse. Right now the AI craze feels the same as the <a href="https://uk.finance.yahoo.com/news/what-happened-to-nfts-094039263.html">crypto and NFT boom</a>, with the same signs of insane behavior and reckless optimism.</p><p>The difference is there&#39;s more useful purposes for LLMs and machine learning, so scammers can point to those uses as they bring down everything good in the name of their AI god.</p><p>Since my video <a href="https://www.youtube.com/watch?v=9rbz0akyLyQ">The RAM Shortage Comes for Us All</a> in December, we have <em>hard drives</em> as the next looming AI-related shortage, as <a href="https://www.tomshardware.com/pc-components/hdds/western-digital-is-already-sold-out-of-hard-drives-for-all-of-2026-chief-says-some-long-term-agreements-for-2027-and-2028-already-in-place">Western Digital just announced</a> they&#39;re already sold through their inventory for 2026.</p><p>Some believe the AI bubble isn&#39;t a bubble, but those people are misguided, just like the AI that hallucinated the quotes in that Ars Technica article.</p><p>And they say <a href="https://www.bogleheads.org/forum/viewtopic.php?t=375826">&#34;this time it&#39;s different&#34;</a>, but it&#39;s not. The same signs are there from other crashes. The big question I have is, how many other things will AI companies destroy before they have to pay their dues.</p></section></div>
  </body>
</html>
