<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.bradfieldcs.com/you-are-not-google-84912cf44afb?gi=3239087b9b49">Original</a>
    <h1>You Are Not Google (2017)</h1>
    
    <div id="readability-page-1" class="page"><section><div><div><p id="49c9">Software engineers go crazy for the most ridiculous things. We like to think that we‚Äôre hyper-rational, but when we have to choose a technology, we end up in a kind of frenzy ‚Äî bouncing from one person‚Äôs Hacker News comment to another‚Äôs blog post until, in a stupor, we float helplessly toward the brightest light and lay prone in front of it, oblivious to what we were looking for in the first place.</p><p id="0c52">This is not how rational people make decisions, but it <em>is</em> how software engineers decide to use MapReduce.</p><p id="4d64">As Joe Hellerstein sideranted to <a href="https://archive.org/details/ucberkeley_webcast_NSKvCVFmk2E" rel="noopener ugc nofollow" target="_blank">his undergrad databases class</a> (54 min in):</p><blockquote><p id="badf">The thing is there‚Äôs like 5 companies in the world that run jobs that big. For everybody else‚Ä¶ you‚Äôre doing all this I/O for fault tolerance that you didn‚Äôt really need. People got kinda Google mania in the 2000s: ‚Äúwe‚Äôll do everything the way Google does because we also run the world‚Äôs largest internet data service‚Äù [tilts head sideways and waits for laughter]</p></blockquote><figure><div role="button" tabindex="0"><p><img alt="" src="https://miro.medium.com/max/1400/1*9ngayPVvoHBf5Le7Uqw1dA.jpeg" width="700" height="415" role="presentation"/></p></div><figcaption>How many stories are your data center buildings? Google chose to stop at 4, for this one in Mayes County, Oklahoma.</figcaption></figure><p id="7373">Having more fault tolerance than you need might sound fine, but consider the cost: not only would you be doing much more I/O, you might be switching from a mature system‚Äîwith stuff like transactions, indexes, and query optimizers‚Äîto something relatively threadbare. What a <a href="https://homes.cs.washington.edu/~billhowe/mapreduce_a_major_step_backwards.html" rel="noopener ugc nofollow" target="_blank">major step backwards</a>. How many Hadoop users make these tradeoffs consciously? How many of those users make these tradeoffs wisely?</p><p id="f7a6">MapReduce/Hadoop is a soft target at this point because even the cargo culters have realized that the planes ain‚Äôt en route. But the same observation can be made more broadly: if you‚Äôre using a technology that originated at a large company, but your use case is very different, it‚Äôs unlikely that you arrived there deliberately; no, it‚Äôs more likely you got there through a ritualistic belief that imitating the giants would bring the same riches.</p><figure><p><img alt="" src="https://miro.medium.com/max/982/1*eOGYrIsn8jRwY9Q6IMjLBQ.jpeg" width="491" height="373" role="presentation"/></p></figure><p id="0dd2">Ok, so yes: this is another ‚Äúdon‚Äôt cargo cult‚Äù article. But wait! I have a helpful checklist for you, one you can use to make better decisions.</p><h2 id="b256">Cool Tech? UNPHAT.</h2><p id="22b2">Next time you find yourself Googling some cool new technology to (re)build your architecture around, I urge you to stop and follow <strong>UNPHAT</strong> instead:</p><ol><li id="4d1b">Don‚Äôt even start considering solutions until you <strong>Understand</strong> the problem. Your goal should be to ‚Äúsolve‚Äù the problem mostly within the <em>problem</em> domain, not the solution domain.</li><li id="6612"><strong>eNumerate </strong>multiple candidate solutions. Don‚Äôt just start prodding at your favorite!</li><li id="8e4f">Consider a candidate solution, then<strong> </strong>read the<strong> Paper</strong> if there is one.</li><li id="2df9">Determine the<strong> Historical context</strong> in which the candidate solution was designed or developed.</li><li id="8f7d">Weigh <strong>Advantages</strong> against disadvantages. <em>Determine what was de-prioritized</em> to achieve what <em>was </em>prioritized.</li><li id="843d"><strong>Think!</strong> Soberly and humbly ponder how well this solution fits your problem. <em>What fact would need to be different for you to change your mind? </em>For instance, how much smaller would the data need to be before you‚Äôd elect <em>not</em> to use Hadoop?</li></ol><h2 id="d47c">You Are Also Not Amazon</h2><p id="999b">It‚Äôs pretty straightforward to apply UNPHAT. Consider my recent conversation with a company that briefly considered using Cassandra for a read-heavy workflow over data that was loaded in nightly:</p><p id="90ae">Having read the Dynamo paper, and knowing Cassandra to be a close derivative, I understood that these distributed databases prioritize <em>write availability</em> (Amazon wanted the ‚Äúadd to cart‚Äù action to never fail). I also appreciated that they did this by compromising consistency, as well as basically every feature present in a traditional RDBMS. But the company I was speaking with <em>did not </em>need to prioritize write availability since the access pattern called for one big write per day. ü§î</p><figure><p><img alt="" src="https://miro.medium.com/max/1200/1*2c9zLYMMHf0SMJRCs2rtUg.jpeg" width="600" height="400" role="presentation"/></p><figcaption>Amazon sells a lot of stuff. If ‚Äúadd to cart‚Äù occasionally failed, they would lose a lot of money. Is your use case the same?</figcaption></figure><p id="b4eb">This company considered Cassandra because the PostgreSQL query in question was taking minutes, which they figured was a hardware limitation. After a few questions, we determined that the table was around 50 million rows and 80 bytes wide, so would take around 5 seconds to to be read in its entirety off SSD, if a full FileScan were needed. That‚Äôs slow, but it‚Äôs 2 orders of magnitudes faster than the actual query. ü§î</p><p id="53cf">At this point, I really wanted to ask more questions (understand the problem!) and had started weighing up about 5 strategies for when the problem grew (enumerate multiple candidate solutions!), but it was already pretty clear that Cassandra would have been the wrong solution entirely. All they needed was some patient tuning, perhaps re-modeling some of the data, <em>maybe</em> (but probably not) another technology choice‚Ä¶ but certainly not the high-write availability key value store that Amazon created for its shopping cart!</p><h2 id="d580">Furthermore, You Are Not LinkedIn</h2><p id="a931">I was surprised to discover that one student‚Äôs company had chosen to architect their system around Kafka. This was surprising because, as far as I could tell, their business processed just a few dozen very high value transactions per day‚Äîperhaps a few hundred on a good day. <em>At this throughput, the primary datastore could be a human writing into a physical book.</em></p><p id="2da8">In comparison, Kafka was designed to handle the throughput of all the analytics events at LinkedIn: a monumental number. Even a couple of years ago, this amounted to <a href="https://engineering.linkedin.com/kafka/running-kafka-scale" rel="noopener ugc nofollow" target="_blank">around 1 trillion events per day, with peaks of over 10 million messages per second</a>. I understand that Kafka is still useful for lower throughput workloads, but 10 orders of magnitude lower?</p><figure><p><img alt="" src="https://miro.medium.com/max/1024/1*58fByP3ysdAKFlbH_KAWRQ.jpeg" width="512" height="320" role="presentation"/></p><figcaption>The sun, while massive, is only 6 orders of magnitude larger than earth.</figcaption></figure><p id="3874">Perhaps the engineers really <em>did</em> make an informed decision based on their expected needs and a good understanding of the rationale of Kafka. But my guess is that they fed off the community‚Äôs (generally justifiable) enthusiasm around Kafka and put little thought into whether it was the right fit for the job. I mean‚Ä¶ 10 orders of magnitude!</p><h2 id="4387">You Are Not Amazon, Again</h2><p id="86c5">More popular than Amazon‚Äôs distributed datastore is the architectural pattern they credit with enabling them to scale: service-oriented architecture. As Werner Vogels pointed out in <a href="https://queue.acm.org/detail.cfm?id=1142065" rel="noopener ugc nofollow" target="_blank">this 2006 interview by Jim Gray</a>, Amazon realized in 2001 that they were struggling to scale their front end, and that a service-oriented architecture ended up helping. This sentiment reverberated from one engineer to another, until startups with just a few engineers and barely any users started splintering their brochureware app into nanoservices.</p><p id="2e37">But by the time Amazon decided to move to SOA, <a href="http://media.corporate-ir.net/media_files/irol/97/97664/reports/2001annualreport.pdf" rel="noopener ugc nofollow" target="_blank">they had around 7,800 employees and did over $3 billion in sales</a>.</p><figure><div role="button" tabindex="0"><p><img alt="" src="https://miro.medium.com/max/1400/1*Y0LRyBrgv4U7NAgy3fLhlA.jpeg" width="700" height="349" role="presentation"/></p></div><figcaption>The Bill Graham Auditorium in San Francisco has capacity for 7,000 people. Amazon had around 7,800 employees when it moved to SOA.</figcaption></figure><p id="6cd7">That‚Äôs not to say you should hold off on SOA until you reach the 7,800 employee mark‚Ä¶ just, <em>think</em> <em>for yourself</em>. Is it the best solution to your problem? What is your problem exactly, and what are other ways you could solve it?</p><p id="46e6">If you tell me that your 50-person engineering organization would grind to a halt without SOA, I‚Äôm going to wonder why so many larger companies do just fine with a large but well-organized single application.</p><h2 id="f46e">Even Google Is Not Google</h2><p id="718d">Use of large scale dataflow engines like Hadoop and Spark can be particularly funny: very often a traditional DBMS is better suited to the workload, and sometimes the volume of data is so small that it could even fit <em>in memory. </em>Did you know you can buy a terabyte of RAM for around $10,000? Even if you had a billion users, this would give you 1kB <em>of RAM</em> per user to work with.</p><p id="759e">Perhaps this isn‚Äôt enough for your workload, and you will need to read and write back to disk. But do you need to read and write back to literally thousands of disks? How much data do you have exactly? GFS and MapReduce were created to deal with the problem of computing over <em>the entire web</em>, such as‚Ä¶ rebuilding a search index over <em>the entire web</em>.</p><figure><p><img alt="" src="https://miro.medium.com/max/1340/1*IIXjS60xq8fQOT_7IsbrQA.jpeg" width="670" height="365" role="presentation"/></p><figcaption>Hard drives prices are now much lower than they were in 2003, the year the GFS paper was published.</figcaption></figure><p id="d448">Perhaps you have read the GFS and MapReduce papers and appreciate that part of the problem for Google wasn‚Äôt capacity but throughput: they distributed storage because it was taking too long to stream bytes off disk. But what‚Äôs the throughput of the devices you‚Äôll be using in 2017? Considering that you won‚Äôt need nearly as many of them as Google did, can you just buy better ones? What would it cost you to use SSDs?</p><p id="c157">Maybe you expect to scale. But have you done the math? Are you likely to accumulate data faster than the rate at which SSD prices will go down? How much would your business need to grow before all your data would no longer fit on one machine? As of 2016, Stack Exchange served 200 million requests per day, <a href="https://nickcraver.com/blog/2016/02/17/stack-overflow-the-architecture-2016-edition/" rel="noopener ugc nofollow" target="_blank">backed by just four SQL servers</a>: a primary for Stack Overflow, a primary for everything else, and two replicas.</p><p id="ca91">Again, you may go through a process like UNPHAT and still decide to use Hadoop or Spark. The decision may even be the right one. What‚Äôs important is that you <em>actually use the right tool for the job</em>. Google knows this well: once they decided that MapReduce wasn‚Äôt the right tool for building the index, they stopped using it.</p><h2 id="1a8c">First, Understand the Problem</h2><p id="78a3">My message isn‚Äôt new, but maybe it‚Äôs the version that speaks to you, or maybe UNPHAT is memorable enough for you to apply it. If not, you might try Rich Hickey‚Äôs talk <a href="https://www.youtube.com/watch?v=f84n5oFoZBc" rel="noopener ugc nofollow" target="_blank">Hammock Driven Development</a>, or the Polya book <a href="https://www.amazon.com/How-Solve-Mathematical-Princeton-Science/dp/069111966X" rel="noopener ugc nofollow" target="_blank"><em>How to Solve It</em></a>, or Hamming‚Äôs course <a href="https://www.youtube.com/playlist?list=PL2FF649D0C4407B30" rel="noopener ugc nofollow" target="_blank"><em>The Art of Doing Science and Engineering</em></a>. What we‚Äôre all imploring you to do is to <strong>think</strong>! And to actually understand the problem you are trying to solve. In Polya‚Äôs galvanic words:</p><blockquote><p id="0a27">It is foolish to answer a question that you do not understand. It is sad to work for an end that you do not desire.</p></blockquote></div></div></section></div>
  </body>
</html>
