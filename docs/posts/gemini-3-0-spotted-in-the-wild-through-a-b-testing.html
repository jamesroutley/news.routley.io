<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://ricklamers.io/posts/gemini-3-spotted-in-the-wild/">Original</a>
    <h1>Gemini 3.0 spotted in the wild through A/B testing</h1>
    
    <div id="readability-page-1" class="page"><div><p>So I kept reading rumors that Gemini 3.0 is accessible through Google AI Studio through A/B testing and the SVGs folks were posting (of Xbox controllers in particular) made me think that they might be right.</p><p>Gemini 3.0 is one of the most anticipated releases in AI at the moment because of the expected advances in coding performance.</p><p>Evaluating models is a difficult task, but surprisingly the SVG generation task seems to be a very efficient proxy for gauging model quality as <a href="https://simonwillison.net/tags/pelican-riding-a-bicycle/">@simonw</a> has shown us using his “pelican riding a bicycle” test.</p><p>Lo and behold, after trying a couple of times I got the A/B screen and got an SVG image of an Xbox 360 controller that looked VERY impressive compared to the rest of the frontier.</p><p><img alt="Gemini 3.0 Xbox controller output" loading="lazy" src="https://ricklamers.io/gemini-3-xbox-controller.png"/></p><p>The exact prompt I used:</p><pre tabindex="0"><code>Create an SVG image of an Xbox 360 controller. Output it in a Markdown multi-line code block.
Like this:
```svg
...
```
</code></pre><p>For what it’s worth the model ID for “Gemini 3.0” was <code>ecpt50a2y6mpgkcn</code> which doesn’t really help understand which version of the model it is. Perhaps since I user selected Gemini 2.5 Pro it is actually Gemini 3.0 Pro that it is pitted against, as comparing Gemini 3.0 Flash to Gemini 2.5 Pro in an A/B test makes less sense to me. Also, it had about 24s higher TTFT and output length was about 40% longer (this includes reasoning tokens AFAICT), but that doesn’t say much other than it’s likely not a “GPT-5 Pro” type answer that uses significant test time compute.</p><h2 id="appendix">Appendix</h2><p>“Gemini 3.0” A/B result versus the Gemini 2.5 Pro model:</p><p><img alt="Gemini 3.0 vs Gemini 2.5 Pro comparison" loading="lazy" src="https://ricklamers.io/gemini-3-vs-2-5-comparison.png"/></p></div></div>
  </body>
</html>
