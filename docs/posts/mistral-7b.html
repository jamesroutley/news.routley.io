<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://arxiv.org/abs/2310.06825">Original</a>
    <h1>Mistral 7B</h1>
    
    <div id="readability-page-1" class="page"><div id="content-inner">
  <div id="abs">
    
    
    <div><p><span>Authors:</span><a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Jiang,+A+Q">Albert Q. Jiang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sablayrolles,+A">Alexandre Sablayrolles</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mensch,+A">Arthur Mensch</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bamford,+C">Chris Bamford</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chaplot,+D+S">Devendra Singh Chaplot</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=de+las+Casas,+D">Diego de las Casas</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Bressand,+F">Florian Bressand</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lengyel,+G">Gianna Lengyel</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lample,+G">Guillaume Lample</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Saulnier,+L">Lucile Saulnier</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lavaud,+L+R">Lélio Renard Lavaud</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lachaux,+M">Marie-Anne Lachaux</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Stock,+P">Pierre Stock</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Scao,+T+L">Teven Le Scao</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lavril,+T">Thibaut Lavril</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wang,+T">Thomas Wang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lacroix,+T">Timothée Lacroix</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Sayed,+W+E">William El Sayed</a></p></div>            
    <p><a href="https://arxiv.org/pdf/2310.06825.pdf">Download PDF</a></p><blockquote>
            <span>Abstract:</span>We introduce Mistral 7B v0.1, a 7-billion-parameter language model engineered for superior performance and efficiency. Mistral 7B outperforms Llama 2 13B across all evaluated benchmarks, and Llama 1 34B in reasoning, mathematics, and code generation. Our model leverages grouped-query attention (GQA) for faster inference, coupled with sliding window attention (SWA) to effectively handle sequences of arbitrary length with a reduced inference cost. We also provide a model fine-tuned to follow instructions, Mistral 7B -- Instruct, that surpasses the Llama 2 13B -- Chat model both on human and automated benchmarks. Our models are released under the Apache 2.0 license.
    </blockquote>

    <!--CONTEXT-->
    
  </div>
</div><div>
      <h2>Submission history</h2><p> From: Devendra Singh Chaplot [<a href="https://arxiv.org/show-email/1509be8a/2310.06825">view email</a>]      </p></div></div>
  </body>
</html>
