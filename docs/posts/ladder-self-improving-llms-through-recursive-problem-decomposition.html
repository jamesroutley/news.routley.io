<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://arxiv.org/abs/2503.00735">Original</a>
    <h1>Ladder: Self-Improving LLMs Through Recursive Problem Decomposition</h1>
    
    <div id="readability-page-1" class="page"><div id="content-inner">
  <div id="abs">
    
    
                
    <p><a href="https://arxiv.org/pdf/2503.00735">View PDF</a>
    <a href="https://arxiv.org/html/2503.00735v3">HTML (experimental)</a></p><blockquote>
            <span>Abstract:</span>We introduce LADDER (Learning through Autonomous Difficulty-Driven Example Recursion), a framework which enables Large Language Models to autonomously improve their problem-solving capabilities through self-guided learning by recursively generating and solving progressively simpler variants of complex problems. Unlike prior approaches that require curated datasets or human feedback, LADDER leverages a model&#39;s own capabilities to generate easier question variants. We demonstrate LADDER&#39;s effectiveness in the subject of mathematical integration, improving Llama 3.2 3B&#39;s accuracy from 1% to 82% on undergraduate-level problems and enabling Qwen2.5 7B Deepseek-R1 Distilled to achieve 73% on the MIT Integration Bee qualifying examination. We also introduce TTRL (Test-Time Reinforcement Learning), where we perform reinforcement learning on variants of test problems at inference time. TTRL enables Qwen2.5 7B Deepseek-R1 Distilled to achieve a state-of-the-art score of 90% on the MIT Integration Bee qualifying examination, surpassing OpenAI o1&#39;s performance. These results show how self-directed strategic learning can achieve significant capability improvements without relying on architectural scaling or human supervision.
    </blockquote>

    <!--CONTEXT-->
    
  </div>
</div><div>
      <h2>Submission history</h2><p> From: Akira Yoshiyama [<a href="https://arxiv.org/show-email/52684320/2503.00735" rel="nofollow">view email</a>]      </p></div></div>
  </body>
</html>
