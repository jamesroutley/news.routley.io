<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/sueszli/autograd.c">Original</a>
    <h1>Show HN: Autograd.c – A tiny ML framework built from scratch</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div data-snippet-clipboard-copy-content="$ toilet -f mono9 -w 100 &#34;autograd.c&#34; 

                    ▄                                    █               
     ▄▄▄   ▄   ▄  ▄▄█▄▄   ▄▄▄    ▄▄▄▄   ▄ ▄▄   ▄▄▄    ▄▄▄█          ▄▄▄  
    ▀   █  █   █    █    █▀ ▀█  █▀ ▀█   █▀  ▀ ▀   █  █▀ ▀█         █▀  ▀ 
    ▄▀▀▀█  █   █    █    █   █  █   █   █     ▄▀▀▀█  █   █         █     
    ▀▄▄▀█  ▀▄▄▀█    ▀▄▄  ▀█▄█▀  ▀█▄▀█   █     ▀▄▄▀█  ▀█▄██    █    ▀█▄▄▀ 
                                 ▄  █                                    
                                  ▀▀                                     

$ cat docs/about.md | fold -w 75

	a minimal reverse mode autograd engine in c with reference counted tensors,
	arena allocated function nodes, explicit dependency counting, centralized 
	gradient accumulation, scalar loss backpropagation and a small set of core 
	tensor ops implemented with tightly coupled forward and backward code.

$ make download

    data/cifar-10-binary  40%[====&gt;         ]  33.10M  2.55MB/s    eta 47s    

$ make run-release

    loaded data
    train samples: 50000
    test samples: 10000
    created model
    starting training

	avg loss: 2.2632, avg acc: 20.48%
    evaluating: 100%|█████████████████████████████████████| 79/79 [0.7it/s]
    test acc: 23.56%

	┌─────────────────── loss (epoch  2/15) ───────────────────┐
	│                              •                           │ 2.3112 (max)
	│                                                          │
	│                            ••                            │
	│            •          •                  •               │
	│•                               •                         │
	│    ••••          • •            •                        │
	│          ••   • •       •                       •        │
	│ ••     •     •                                           │
	│         •           •     •       •   •     •            │
	│   •                                 •        •           │
	│             •  •  •  • • •       •            •   • •    │
	│                               •    •       •             │
	│                                      • •       •     •   ┤––– 2.2941
	│                                           •              │
	│                                         •        • •     │ 2.2899 (min)
	└──────────────────────────────────────────────────────────┘
	96%|██████████████████████████████████████████████▊   | 750/782 [1.5it/s]"><pre><code>$ toilet -f mono9 -w 100 &#34;autograd.c&#34; 

                    ▄                                    █               
     ▄▄▄   ▄   ▄  ▄▄█▄▄   ▄▄▄    ▄▄▄▄   ▄ ▄▄   ▄▄▄    ▄▄▄█          ▄▄▄  
    ▀   █  █   █    █    █▀ ▀█  █▀ ▀█   █▀  ▀ ▀   █  █▀ ▀█         █▀  ▀ 
    ▄▀▀▀█  █   █    █    █   █  █   █   █     ▄▀▀▀█  █   █         █     
    ▀▄▄▀█  ▀▄▄▀█    ▀▄▄  ▀█▄█▀  ▀█▄▀█   █     ▀▄▄▀█  ▀█▄██    █    ▀█▄▄▀ 
                                 ▄  █                                    
                                  ▀▀                                     

$ cat docs/about.md | fold -w 75

	a minimal reverse mode autograd engine in c with reference counted tensors,
	arena allocated function nodes, explicit dependency counting, centralized 
	gradient accumulation, scalar loss backpropagation and a small set of core 
	tensor ops implemented with tightly coupled forward and backward code.

$ make download

    data/cifar-10-binary  40%[====&gt;         ]  33.10M  2.55MB/s    eta 47s    

$ make run-release

    loaded data
    train samples: 50000
    test samples: 10000
    created model
    starting training

	avg loss: 2.2632, avg acc: 20.48%
    evaluating: 100%|█████████████████████████████████████| 79/79 [0.7it/s]
    test acc: 23.56%

	┌─────────────────── loss (epoch  2/15) ───────────────────┐
	│                              •                           │ 2.3112 (max)
	│                                                          │
	│                            ••                            │
	│            •          •                  •               │
	│•                               •                         │
	│    ••••          • •            •                        │
	│          ••   • •       •                       •        │
	│ ••     •     •                                           │
	│         •           •     •       •   •     •            │
	│   •                                 •        •           │
	│             •  •  •  • • •       •            •   • •    │
	│                               •    •       •             │
	│                                      • •       •     •   ┤––– 2.2941
	│                                           •              │
	│                                         •        • •     │ 2.2899 (min)
	└──────────────────────────────────────────────────────────┘
	96%|██████████████████████████████████████████████▊   | 750/782 [1.5it/s]
</code></pre></div>
</article></div></div>
  </body>
</html>
