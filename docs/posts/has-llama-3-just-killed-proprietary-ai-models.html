<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.kadoa.com/blog/llama3-killed-proprietary-models">Original</a>
    <h1>Has Llama-3 just killed proprietary AI models?</h1>
    
    <div id="readability-page-1" class="page"><div><p>Meta released Llama-3 only three days  ago, and it already feels like the inflection point when open source models finally closed the gap with proprietary models.
The benchmarks show that Llama-3 70B matches GPT-4 and Claude Opus in most tasks, and the even more powerful Llama-3 400B+ model is still training.</p>
<h3>Meta vs OpenAI</h3>
<p>Meta can likely outspend OpenAI on compute and talent:</p>
<ul>
<li>OpenAI makes an estimated revenue of $2B and is likely unprofitable. Meta generated a revenue of $134B and profits of $39B in 2023.</li>
<li>Meta&#39;s compute resources likely outrank OpenAI by now.</li>
<li>Open source likely attracts better talent and researchers.</li>
</ul>
<p>One possible outcome could be the acquisition of OpenAI by Microsoft to catch up with Meta.
Google is also making moves into the open model space and has similar capabilities to Meta. It will be interesting to see where they fit in.
. I&#39;m definitely</p>
<h3>The Winners: Developers and AI Product Startups</h3>
<p>I recently wrote about the <a href="https://www.kadoa.com/blog/why-building-an-ai-startup-feels-amazing">excitement of building an AI startup</a> right now,
as your product automatically improves with each major model advancement.
With the release of Llama-3, the opportunities for developers are even greater:</p>
<ul>
<li>No more vendor lock-in.</li>
<li>Instead of just wrapping proprietary API endpoints, developers can now integrate AI deeply into their products in a very cost-effective and performant way. There are already over 800 <a href="https://huggingface.co/models?sort=modified&amp;search=llama3">llama-3 models variations on Hugging Face</a>, and it looks like everyone will be able to fine-tune for their us-cases, languages, or industry.</li>
<li>Faster, cheaper hardware: Groq can now generate 800 llama-3 tokens per second at a small fraction of the GPT costs. Near-instant LLM responses at low prices are on the horizon.</li>
</ul>
<p>Open source multimodal models for vision and video still have to catch up, but I expect this to happen very soon.</p>
<p>But who knows, maybe GPT-5 will surprise us all and surpass our imaginations of what transformer models can do.</p>
<p>These are definitely super exciting times to build in the AI space!</p></div></div>
  </body>
</html>
