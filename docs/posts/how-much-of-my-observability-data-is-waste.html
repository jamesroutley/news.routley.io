<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://usetero.com/blog/the-question-your-observability-vendor-wont-answer">Original</a>
    <h1>How much of my observability data is waste?</h1>
    
    <div id="readability-page-1" class="page"><article>
<p>This year marks a decade for me in observability.</p>
<p>I left my engineering job in 2016 to start Timber.io, a hosted logging platform, because I thought logs could be simple and great. Timber became Vector. Vector got mass adoption. It got acquired, and I stayed for three years.</p>
<p>And somewhere along the way, the optimism curdled.</p>
<p>I&#39;m not a cynical person. I believed observability could make engineers&#39; lives better. But after a decade, after hundreds of conversations with teams bleeding money across every major vendor, after hearing firsthand how their vendors strong-armed them instead of helping; I&#39;ve seen enough. The whole industry has lost the plot.</p>
<h2>Does any of this sound familiar?</h2>
<p>You run observability at your company. But really, you&#39;re the cost police. You wake up to a log line in a hot path, a metric tag that exploded cardinality. You chase down the engineer. They didn&#39;t do anything wrong, they&#39;re just disconnected from what any of this costs. The renewal is always in the back of your mind because mismanaging it reflects poorly on you. Sometimes you catch these mistakes. Sometimes you don&#39;t. When you don&#39;t, you crawl to your rep asking for forgiveness. Maybe they help the first time, even the second. By the fourth or fifth, they stop. &#34;It&#39;s your data.&#34; But even with the mistakes, if you&#39;re diligent, checking dashboards, staying on top of things, you manage to stay under your commit and avoid an early renewal. But the renewal still gives you a black eye: 40% higher than last year. Your budget didn&#39;t grow that much. So you consider switching vendors, but asking your engineers to frantically migrate dashboards, alerts, and change workflows is a distraction that also reflects poorly on you. You&#39;re in a lose-lose situation. So you go back to your vendor and ask them to help. You championed them internally; brought them six, seven figure business. Surely they&#39;d return the favor. A slightly bigger discount, help you cut costs by showing you what data is safe to drop. But they don&#39;t budge. They could help; they don&#39;t.</p>
<p>Case Taintor, Director of Engineering at Klarna, <a href="https://www.linkedin.com/posts/case-taintor-251b294_we-drop-suppliers-who-lack-an-interest-in-activity-7067495746320687104-Msgl">put it all too well</a>:</p>
<blockquote>
<p>The most frustrating part of watching your money burn is knowing your supplier could help if they only cared about your long term success.</p>
</blockquote>
<p>So why has this gone on for over a decade? Something is <em>deeply</em> wrong if after ten years these same problems not only exist, but have gotten worse.</p>
<p>But what&#39;s wrong, exactly? Should your vendor help you? It <em>is</em> your data. They didn&#39;t create it. You sent it to them under their pricing model. For years I accepted that framing too. Maybe this is just how it works.</p>
<p>Then I bumped into a question that changed my thinking.</p>
<h2>How much of my observability data is waste?</h2>
<p>You&#39;ve asked it. Your vendor has asked it. You know the answer isn&#39;t zero. But what is it? 10%? 20%? 40%? At what point does &#34;that&#39;s just how it works&#34; stop being an acceptable answer?</p>
<p>You see, anyone who&#39;s been in this space knows that cost is far and away the biggest problem. You can take all of the other problems, bundle them together, multiply them by 100, and they still would not surpass cost. It shows up everywhere. All of the &#34;innovation&#34; in observability can be traced back to cost in some way. Pipelines? Cost. Fancy new storages? Cost. OpenTelemetry? Yes, cost.</p>
<p>So in that context, this seems like a pretty important question. Maybe the most important question in observability. Which means it must be unanswerable, right? Because if someone could answer it and let you keep paying for garbage anyway, that would be unconscionable.</p>
<p>Put it to the test. Ask your vendor what percentage of your data is waste. They&#39;ll play ignorant. &#34;It&#39;s your data.&#34; They don&#39;t understand it well enough to tell you what&#39;s worth keeping. But they understand it well enough to sell you an AI SRE that can &#34;root cause in minutes.&#34;</p>
<p>It&#39;s this willful ignorance that gets me. Everyone knows what&#39;s right but plays the quarterly earnings game instead. Except it&#39;s not a game for the people on the other side. I got a front row seat with Vector users. Vector wasn&#39;t deployed for fun; it was often deployed in crisis, usually around renewal time when the cost of this game came due. I watched people lose their jobs for &#34;mismanaging&#34; the observability budget. I saw the stress on their faces, the lost sleep.</p>
<p>So when I first bumped into this question while helping a Vector user, and wanted to answer it but couldn&#39;t, that&#39;s when my optimism curdled.</p>
<h2>So I answered it</h2>
<p>After I left Vector, the question stayed with me. I took a year off, but Vector users still found me with questions. One in particular jumped out because it was impossible not to: emails, LinkedIn messages, people in my network pinging me on their behalf. I wasn&#39;t annoyed. I knew exactly what was going on. So I agreed to help. Except this time, no roadmaps, no one telling me what to do. In exchange, they&#39;d give me access to their data so I could try to answer the question, which I suspected was their actual problem anyway.</p>
<p>So I signed all the docs, got access to their Vector environment, and took a look at their Vector config. It was the mother of all configs (sorry guys, no offense). Dozens of components connected into a complex DAG. Every cost reduction trick in the book: sampling, aggregating, storage tiering, archiving, and a massive list of regexes to match and drop waste. But I wasn&#39;t appalled, I respected it. They weren&#39;t being careless, they were doing everything they possibly could.</p>
<p>One trick in particular intrigued me: the regex list. It was the bottleneck, but it was also something else: an expression of understanding. Every pattern represented an engineer who understood their service well enough to say &#34;this is waste.&#34; My first instinct was to optimize it. I stumbled on <a href="https://github.com/intel/hyperscan">Hyperscan</a>. Turns out you can compile tens of thousands of patterns and still match at line rate. That flipped my thinking: what if I took this to the extreme and automated that understanding to produce thousands of patterns?</p>
<p>So I built a system to do exactly that. It compressed billions of logs into thousands of semantic events, each one evaluated with the context it needed: the service, the failure scenarios, the patterns, how it all fits together. (The deep details are outside the scope of this post, but if you&#39;re curious, <a href="https://docs.usetero.com/data-quality/overview">here&#39;s how it works today.</a>)</p>
<p>I ran it against the first service: ~40% waste. Another: ~60%. Another: ~30%. On average, ~40% waste.</p>
<p>I knew the number wasn&#39;t zero, but I wasn&#39;t expecting 40%. So I pressure tested it. Went through hundreds of lines manually. Checked it against their existing patterns. It checked out. With that confidence, I brought it to them.</p>
<p>They laughed. &#34;We can&#39;t just drop half of our logs.&#34; Fair. But that&#39;s not what I was asking. I showed them: this wasn&#39;t anything new. It was the same analysis they were already doing, just at scale, more complete, more accurate. Most of their hand-written patterns were already represented in my set, often simpler and faster. They could tweak the analysis, roll it out slowly, push it to teams to take action in their own code.</p>
<p>And that&#39;s what happened. The knowledge stopped the bleeding. Over time, services cleaned up their logging. Pipelines got simpler. Bills went down. Not because anyone dropped data recklessly, but because they finally knew what was worth keeping.</p>
<h2>Why observability feels broken</h2>
<p>The answer to this question isn&#39;t just a number. It&#39;s the answer to why observability feels broken despite it being more expensive than ever. Think about it.</p>
<p>On the surface: you&#39;re paying twice what you should. Cut the waste, cut the bill. Simple.</p>
<p>Go deeper: the cost policing, the weekly dashboard checks, the monthly exercises, the begging your rep for forgiveness when someone&#39;s log blows up the bill, the pipelines. All of that exists because you&#39;re managing garbage. Half the complexity you&#39;ve built is dedicated to noise.</p>
<p>Go deeper still: your engineers complain that observability doesn&#39;t help them debug faster despite costing millions. Of course it doesn&#39;t. They&#39;re drowning in noise and calling it data. The alerts fire on garbage. The dashboards are cluttered with garbage. The AI can&#39;t find the signal because there&#39;s too much garbage in the way.</p>
<p>And underneath all of it: this number shouldn&#39;t exist if your vendor was aligned with you.</p>
<p>Take a look around the market. <a href="https://blog.pragmaticengineer.com/datadog-65m-year-customer-mystery/">$65M bills</a>. <a href="https://newsletter.pragmaticengineer.com/p/the-pulse-148">$170M bills</a>. <a href="https://hex.tech/careers/infra-engineer-observability-whisperer/">Entire roles for cost control</a>. &#34;Observe without limits.&#34; &#34;Stop sampling.&#34; &#34;More data, more insight.&#34; Dozens of products. It&#39;s all backwards. The goal isn&#39;t more data, more products, or more complexity.</p>
<blockquote>
<p><strong>The goal is understanding with less.</strong></p>
</blockquote>
<p>And how do you prove understanding? The question. Either you understand the data well enough to answer it or you don&#39;t.</p>
<p>There&#39;s a future where you&#39;re not the cost cop. Where observability just works. Where your vendor&#39;s success depends on yours.</p>
<p>That&#39;s the future we&#39;re building at Tero.</p>
<p><a href="https://usetero.com/book-a-demo">Get your number.</a></p></article></div>
  </body>
</html>
