<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://leftoverlocals.com/">Original</a>
    <h1>LeftoverLocals: A vulnerability that allows data recovery from GPU memory</h1>
    
    <div id="readability-page-1" class="page"><div id="main"><p><img src="https://leftoverlocals.com/leftoverlocals.png" alt="LeftoverLocals"/></p><h2 id="updates">Updates</h2><ul><li>2024-01-16: Initial release</li></ul><h2 id="description">Description</h2><p>Trail of Bits is disclosing LeftoverLocals: a vulnerability that allows data recovery from GPU memory created by another process on Apple, Qualcomm, and AMD GPUs. LeftoverLocals impacts the security posture of GPU applications, with particular significance to LLMs and ML models that run on impacted GPUs. By recovering local memory – an optimized GPU memory region – we built a PoC where an attacker can listen into another user’s interactive LLM session (e.g., llama.cpp) across process or container boundaries.</p><p><img src="https://leftoverlocals.com/images/attacker_listening.gif" alt="Attacker Listening"/></p><p><img src="https://leftoverlocals.com/images/writer_process.gif" alt="Writer Process"/></p><h2 id="demo">Demo</h2><p><iframe src="https://www.youtube.com/embed/g2A7GvbnItg" allowfullscreen="" title="YouTube Video"></iframe></p><h2 id="report">Report</h2><p>See the full report at our blog <a href="https://blog.trailofbits.com/2024/01/16/leftoverlocals-listening-to-llm-responses-through-leaked-gpu-local-memory/">here</a>.</p></div></div>
  </body>
</html>
