<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.vice.com/en/article/dy7axa/how-i-broke-into-a-bank-account-with-an-ai-generated-voice">Original</a>
    <h1>I Broke into a Bank Account with an AI-Generated Voice</h1>
    
    <div id="readability-page-1" class="page"><div data-component="BodyComponentRenderer"><div><div><p><a href="https://www.vice.com/en/topic/cyber"><img src="https://video-images.vice.com/topics/57a205628cb727dec795a6b1/callout_logo/1614199980283-screen-shot-2021-02-24-at-34918-pm.png?resize=240:*" alt="Screen Shot 2021-02-24 at 3"/></a></p><p>Hacking. Disinformation. Surveillance. CYBER is Motherboard&#39;s podcast and reporting on the dark underbelly of the internet.</p></div><p><span data-component="TextBlock"><p>The bank thought it was talking to me; the AI-generated voice certainly sounded the same.</p></span><span data-component="TextBlock"><p>On Wednesday, I phoned my bank’s automated service line. To start, the bank asked me to say in my own words why I was calling. Rather than speak out loud, I clicked a file on my nearby laptop to play a sound clip: “check my balance,” my voice said. But this wasn&#39;t actually my voice. It was a synthetic clone I had made using readily available artificial intelligence technology.</p></span></p></div><p><span data-component="TextBlock"><p>“Okay,” the bank replied. It then asked me to enter or say my date of birth as the first piece of authentication. After typing that in, the bank said “please say, ‘my voice is my password.’” </p></span><span data-component="TextBlock"><p>Again, I played a sound file from my computer. “My voice is my password,” the voice said. The bank&#39;s security system spent a few seconds authenticating the voice. </p></span><span data-component="TextBlock"><p>“Thank you,” the bank said. I was in.</p></span><span data-component="TextBlock"><p>I couldn’t believe it—it had worked. I had used an AI-powered replica of a voice to break into a bank account. After that, I had access to the account information, including balances and a list of recent transactions and transfers.</p></span><span data-component="TextBlock"><p>Banks across the U.S. and Europe use this sort of voice verification to let customers log into their account over the phone. Some banks tout voice identification as equivalent to a fingerprint, a secure and convenient way for users to interact with their bank. But this experiment shatters the idea that voice-based biometric security provides foolproof protection in a world where anyone can now generate synthetic voices for cheap or sometimes at no cost. I used a free voice creation service from ElevenLabs, a powerful AI-voice company that has already been used to <a href="https://www.vice.com/en/article/93axnd/voice-actors-doxed-with-ai-voices-on-twitter">dox and harass specific people</a>. </p></span><span data-component="TextBlock"><p>Now, that abuse can extend to fraud and hacking. Some experts I spoke to after doing this experiment are now calling for banks to ditch voice authentication altogether, although real-world abuse at this time could be rare.</p></span></p><div><p><span data-component="TextBlock"><p>Rachel Tobac, CEO of social engineering focused firm SocialProof Security, told Motherboard “I recommend all organizations leveraging voice ‘authentication’ switch to a secure method of identity verification, like multi-factor authentication, ASAP.” This sort of voice replication can be “completed without ever needing to interact with the person in real life.” </p></span><span data-component="TextBlock"><p>Online trolls have already used ElevenLabs to make replica voices of people without their consent, using clips of the peoples’ voices online. Potentially anyone with even a few minutes of their voice publicly available—YouTubers, social media influencers, politicians, journalists—could be susceptible to this sort of voice cloning.</p></span></p><p><span data-component="TextBlock"><p>I performed the test on an account with Lloyds Bank in the UK. On its website, Lloyds Bank says its <a href="https://www.lloydsbank.com/contact-us/voice-id.html" target="_blank">“Voice ID”</a> program is safe. “Your voice is like your fingerprint and unique to you,” the site reads. “Voice ID analyses over 100 different characteristics of your voice which like your fingerprint, are unique to you. Such as, how you use your mouth and vocal chords, your accent and how fast you talk. It even recognises you if you have a cold or a sore throat,” it adds.</p></span><span data-component="TextBlock"><p>Plenty of banks in the U.S. offer similar voice verification services. TD Bank has one called <a href="https://tdbank.intelliresponse.com/index.jsp?requestType=NormalRequest&amp;question=What+is+TD+VoicePrint+and+how+do+I+enroll" target="_blank">“VoicePrint,”</a> and says on its website “Your voiceprint, like your fingerprint, is unique to you—no one else has a voice just like you.” Chase has <a href="https://www.chase.com/personal/voice-biometrics" target="_blank">“Voice ID”</a> which, like Lloyds Bank, also claims a customer’s voiceprint “is created from more than 100 different physical and behavioral characteristics.” Wells Fargo’s <a href="https://www.wellsfargo.com/help/security-and-fraud/voice-verification-faqs/" target="_blank">“Voice Verification,”</a> meanwhile, “effectively protects your identity,” according to the bank’s website.</p></span></p></div><div><p><span data-component="TextBlock"><p>Although I only conducted the test on Lloyds Bank, given the similar nature and functioning of these other systems, they may be at risk to AI-powered voices too. Many banks allow users to do a host of banking features over the phone, such as checking transaction history, account balances, and in some cases transferring funds. </p></span></p><div data-component="RelatedArticleBlock"><div><div><a href="https://payments.posthaven.com/en/article/93axnd/voice-actors-doxed-with-ai-voices-on-twitter" tabindex="-1"><div><div><picture><source media="(min-width: 1000px)" srcset="data://image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAJCAMAAAAM9FwAAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAyNpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuNi1jMTQwIDc5LjE2MDQ1MSwgMjAxNy8wNS8wNi0wMTowODoyMSAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvIiB4bWxuczp4bXBNTT0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wL21tLyIgeG1sbnM6c3RSZWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9zVHlwZS9SZXNvdXJjZVJlZiMiIHhtcDpDcmVhdG9yVG9vbD0iQWRvYmUgUGhvdG9zaG9wIENDIChNYWNpbnRvc2gpIiB4bXBNTTpJbnN0YW5jZUlEPSJ4bXAuaWlkOjQ2QjUwODI3MUI1NTExRTk5RjE3QTJDRDlCQzU1MDg0IiB4bXBNTTpEb2N1bWVudElEPSJ4bXAuZGlkOjQ2QjUwODI4MUI1NTExRTk5RjE3QTJDRDlCQzU1MDg0Ij4gPHhtcE1NOkRlcml2ZWRGcm9tIHN0UmVmOmluc3RhbmNlSUQ9InhtcC5paWQ6NDZCNTA4MjUxQjU1MTFFOTlGMTdBMkNEOUJDNTUwODQiIHN0UmVmOmRvY3VtZW50SUQ9InhtcC5kaWQ6NDZCNTA4MjYxQjU1MTFFOTlGMTdBMkNEOUJDNTUwODQiLz4gPC9yZGY6RGVzY3JpcHRpb24+IDwvcmRmOlJERj4gPC94OnhtcG1ldGE+IDw/eHBhY2tldCBlbmQ9InIiPz5A+02rAAAABlBMVEX///8AAABVwtN+AAAAAXRSTlMAQObYZgAAAA5JREFUeNpiYBikACDAAACZAAGHvThgAAAAAElFTkSuQmCC"/><source media="(min-width: 700px)" srcset="data://image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAJCAMAAAAM9FwAAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAyNpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuNi1jMTQwIDc5LjE2MDQ1MSwgMjAxNy8wNS8wNi0wMTowODoyMSAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvIiB4bWxuczp4bXBNTT0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wL21tLyIgeG1sbnM6c3RSZWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9zVHlwZS9SZXNvdXJjZVJlZiMiIHhtcDpDcmVhdG9yVG9vbD0iQWRvYmUgUGhvdG9zaG9wIENDIChNYWNpbnRvc2gpIiB4bXBNTTpJbnN0YW5jZUlEPSJ4bXAuaWlkOjQ2QjUwODI3MUI1NTExRTk5RjE3QTJDRDlCQzU1MDg0IiB4bXBNTTpEb2N1bWVudElEPSJ4bXAuZGlkOjQ2QjUwODI4MUI1NTExRTk5RjE3QTJDRDlCQzU1MDg0Ij4gPHhtcE1NOkRlcml2ZWRGcm9tIHN0UmVmOmluc3RhbmNlSUQ9InhtcC5paWQ6NDZCNTA4MjUxQjU1MTFFOTlGMTdBMkNEOUJDNTUwODQiIHN0UmVmOmRvY3VtZW50SUQ9InhtcC5kaWQ6NDZCNTA4MjYxQjU1MTFFOTlGMTdBMkNEOUJDNTUwODQiLz4gPC9yZGY6RGVzY3JpcHRpb24+IDwvcmRmOlJERj4gPC94OnhtcG1ldGE+IDw/eHBhY2tldCBlbmQ9InIiPz5A+02rAAAABlBMVEX///8AAABVwtN+AAAAAXRSTlMAQObYZgAAAA5JREFUeNpiYBikACDAAACZAAGHvThgAAAAAElFTkSuQmCC"/><source media="(min-width: 0px)" srcset="data://image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABAAAAAJCAMAAAAM9FwAAAAAGXRFWHRTb2Z0d2FyZQBBZG9iZSBJbWFnZVJlYWR5ccllPAAAAyNpVFh0WE1MOmNvbS5hZG9iZS54bXAAAAAAADw/eHBhY2tldCBiZWdpbj0i77u/IiBpZD0iVzVNME1wQ2VoaUh6cmVTek5UY3prYzlkIj8+IDx4OnhtcG1ldGEgeG1sbnM6eD0iYWRvYmU6bnM6bWV0YS8iIHg6eG1wdGs9IkFkb2JlIFhNUCBDb3JlIDUuNi1jMTQwIDc5LjE2MDQ1MSwgMjAxNy8wNS8wNi0wMTowODoyMSAgICAgICAgIj4gPHJkZjpSREYgeG1sbnM6cmRmPSJodHRwOi8vd3d3LnczLm9yZy8xOTk5LzAyLzIyLXJkZi1zeW50YXgtbnMjIj4gPHJkZjpEZXNjcmlwdGlvbiByZGY6YWJvdXQ9IiIgeG1sbnM6eG1wPSJodHRwOi8vbnMuYWRvYmUuY29tL3hhcC8xLjAvIiB4bWxuczp4bXBNTT0iaHR0cDovL25zLmFkb2JlLmNvbS94YXAvMS4wL21tLyIgeG1sbnM6c3RSZWY9Imh0dHA6Ly9ucy5hZG9iZS5jb20veGFwLzEuMC9zVHlwZS9SZXNvdXJjZVJlZiMiIHhtcDpDcmVhdG9yVG9vbD0iQWRvYmUgUGhvdG9zaG9wIENDIChNYWNpbnRvc2gpIiB4bXBNTTpJbnN0YW5jZUlEPSJ4bXAuaWlkOjQ2QjUwODI3MUI1NTExRTk5RjE3QTJDRDlCQzU1MDg0IiB4bXBNTTpEb2N1bWVudElEPSJ4bXAuZGlkOjQ2QjUwODI4MUI1NTExRTk5RjE3QTJDRDlCQzU1MDg0Ij4gPHhtcE1NOkRlcml2ZWRGcm9tIHN0UmVmOmluc3RhbmNlSUQ9InhtcC5paWQ6NDZCNTA4MjUxQjU1MTFFOTlGMTdBMkNEOUJDNTUwODQiIHN0UmVmOmRvY3VtZW50SUQ9InhtcC5kaWQ6NDZCNTA4MjYxQjU1MTFFOTlGMTdBMkNEOUJDNTUwODQiLz4gPC9yZGY6RGVzY3JpcHRpb24+IDwvcmRmOlJERj4gPC94OnhtcG1ldGE+IDw/eHBhY2tldCBlbmQ9InIiPz5A+02rAAAABlBMVEX///8AAABVwtN+AAAAAXRSTlMAQObYZgAAAA5JREFUeNpiYBikACDAAACZAAGHvThgAAAAAElFTkSuQmCC"/><img alt="" decoding="async" loading="eager"/></picture></div></div></a></div></div></div><p><span data-component="TextBlock"><p>For this particular attack, a fraudster would also need the target’s date of birth. But thanks to a plethora of data breaches, brokers, or people sharing personal details online, a date of birth is often readily available.</p></span><span data-component="TextBlock"><p>A Lloyds Bank spokesperson said in a statement that “Voice ID is an optional security measure, however we are confident that it provides higher levels of security than traditional knowledge-based authentication methods, and that our layered approach to security and fraud prevention continues to provide the right level of protection for customers&#39; accounts, while still making them easy to access when needed.”</p></span><span data-component="TextBlock"><p>Lloyds Bank said it is aware of the threat of synthetic voices and deploying countermeasures, but has not seen a case where such a voice has been used to commit fraud against its customers. Synthetic voices are not as attractive to fraudsters as other much more common methods, and voice ID has led to a significant dip in fraud with phone banking, Lloyds Bank said.</p></span><span data-component="TextBlock"><p>Given how rare synthetic voice fraud is at the moment, consumers are likely better placed using it if it means protecting them from other sorts of fraud, such as phishing. That calculus might change if the consumer is a public figure, with lots of high-quality audio of their voice readily available on the internet.</p></span></p></div><div><p><span data-component="TextBlock"><p>TD Bank, Chase, and Wells Fargo did not respond to a request for comment on whether they are aware of AI-powered voices being used to target customer accounts, and what mitigations, if any, they are taking to stop the threat. In September, lawyers <a href="https://news.bloomberglaw.com/privacy-and-data-security/capital-one-faces-lawsuit-over-use-of-biometric-voice-prints" target="_blank">sued a group of U.S. financial institutions</a> because biometric voice prints used to identify callers violate the California Invasion of Privacy Act.</p></span></p><blockquote data-component="QuoteBlock"><p><em><strong>Do you know anything else about bank voice ID, or how AI voices are being abused? We&#39;d love to hear from you. Using a non-work phone or computer, you can contact Joseph Cox securely on Signal on +44 20 8133 5190, Wickr on josephcox, or email joseph.cox@vice.com.</strong></em></p></blockquote><p><span data-component="TextBlock"><p>Over the last few weeks I have tested a few AI-voice generation services. Most of them had problems or limitations with recreating my British accent, which would be necessary to access the Lloyds Bank account. Eventually I used ElevenLabs, which handled the accent well. </p></span><span data-component="TextBlock"><p>To create the voice, I recorded about five minutes of speech and uploaded it to ElevenLabs (for the audio clips, I read sections of Europe’s data protection law). A short while later, the synthetic voice was ready to use, with it saying whatever text was entered into ElevenLabs’ site.</p></span></p></div><div><div data-component="ImageBlock"><div><div><picture><source media="(min-width: 1000px)" srcset="https://video-images.vice.com/_uncategorized/1677172720630-11labs.jpeg?resize=20:*"/><source media="(min-width: 700px)" srcset="https://video-images.vice.com/_uncategorized/1677172720630-11labs.jpeg?resize=20:*"/><source media="(min-width: 0px)" srcset="https://video-images.vice.com/_uncategorized/1677172720630-11labs.jpeg?resize=20:*"/><img alt="elevenlabs.jpg" decoding="async" loading="eager"/></picture></div></div><p>A screenshot of ElevenLabs&#39; interface. Image: Motherboard.</p></div></div><p><span data-component="TextBlock"><p>The experiment of entering the bank account failed multiple times, with Lloyd Bank’s system saying it could not authenticate the voice. After making some tweaks on ElevenLabs, such as having it read a longer body of text to make cadences sound more natural, the generated audio successfully bypassed the bank’s security.</p></span><span data-component="TextBlock"><p>On its website ElevenLabs says its use cases include providing voices for newsletters, books, and videos. But with minimal guardrails in place at launch, people quickly abused ElevenLabs’ technology. Members of 4chan used the service to generate replicas of specific voice actors, and then had them <a href="https://www.vice.com/en/article/93axnd/voice-actors-doxed-with-ai-voices-on-twitter">read out the actors’ home addresses in posts on Twitter</a>. Before that, 4chan also used ElevenLabs to make synthetic versions of celebrities spout racist and transphobic things, such as <a href="https://www.vice.com/en/article/dy7mww/ai-voice-firm-4chan-celebrity-voices-emma-watson-joe-rogan-elevenlabs">a fake Emma Watson reading Mein Kampf</a>. After those celebrity clips, ElevenLabs tweeted to ask what safeguards it should put in place, such as asking for full ID identification of users or requiring payment information. Motherboard, however, was able to generate the voice without providing ID or any payment information, potentially because the account was made before ElevenLabs introduced new security measures. The cost of creating the bank security bypassing voice was free.</p></span><span data-component="TextBlock"><p>ElevenLabs did not respond to multiple requests for comment. In <a href="https://www.vice.com/en/article/93axnd/voice-actors-doxed-with-ai-voices-on-twitter">a previous statement</a>, Mati Staniszewski, an ex-Palantir deployment strategist and now co-founder of ElevenLabs, said “Our new safeguards are already rapidly reducing instances of misuse and we&#39;re grateful to our user community for continuing to flag any examples where extra action needs to be taken and we will support authorities in identifying those users if the law was broken.”</p></span><span data-component="TextBlock"><p><em><strong>Subscribe to our cybersecurity podcast, <a href="https://itunes.apple.com/gb/podcast/cyber/id1441708044?mt=2" target="_blank">CYBER</a>. Subscribe to <a href="https://www.twitch.tv/motherboardtv" target="_blank">our new Twitch channel</a>.</strong></em></p></span></p></div><div><div><div><p><h3>ORIGINAL REPORTING ON EVERYTHING THAT MATTERS IN YOUR INBOX.</h3></p><p>By signing up, you agree to the<!-- --> <a href="https://vice-web-statics-cdn.vice.com/privacy-policy/en_us/page/terms-of-use.html">Terms of Use</a> <!-- -->and<!-- --> <a href="https://vice-web-statics-cdn.vice.com/privacy-policy/en_us/page/privacy-policy.html">Privacy Policy</a> <!-- -->&amp; to receive electronic communications from Vice Media Group, which may include marketing promotions, advertisements and sponsored content.</p></div></div></div></div>
  </body>
</html>
