<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://16bpp.net/blog/post/noexcept-can-sometimes-help-or-hurt-performance/">Original</a>
    <h1>C&#43;&#43;&#39;s `noexcept` can sometimes help or hurt performance</h1>
    
    <div id="readability-page-1" class="page"><div><p>Over the course of working on <a href="https://github.com/define-private-public/PSRayTracing/">PSRayTracing</a> (PSRT), I&#39;ve been trying to find all sorts of tricks and techniques to squeeze out more performance from this C++ project. Most of it tends to be alternative algorithms, code rewriting, and adjusting data structures. I thought sprinkling the <a href="https://en.cppreference.com/w/cpp/language/final"><code>final</code> keyword</a> like an all purpose seasoning around every class was &#34;free performance gain&#34;. <a href="https://16bpp.net/blog/post/the-performance-impact-of-cpp-final-keyword/">But... that didn&#39;t really turn out to be the case</a>.</p>

<p>Back in the early days of this project (2020-2021), I recall hearing about the <a href="https://en.cppreference.com/w/cpp/language/noexcept_spec"><code>noexcept</code> keyword</a> for the first time. I was reading through Scott Meyer&#39;s works and picked up a copy of &#34;Effective Modern C++&#34; and watched a few CppCon talks about exceptions. I don&#39;t remember too much, but what I clearly recall:</p>

<ol>
	<li>Exceptions are slow, don&#39;t use them</li>
	<li><code>noexcept</code> will make your code faster</li>
</ol>

<p>I re-picked up a copy of the aforementioned book whilst writing this. &#34;Item 14: Declare functions <code>noexcept</code> if they won&#39;t emit exceptions&#34; is the section that advocates for this keyword. Due to copyright, I cannot post any of the text here. Throughout the section the word &#34;optimization&#34; is used. But, it neglects any benchmark.</p>

<p>For those of you unfamiliar with <code>noexcept</code>, here is the nutshell explanation: you can use it to mark if a function <span>will not throw an exception</span>. This is useful for documentation and defining APIs. Personally, I really like that the keyword exists.</p>

<p>Similar to what I did for the <code>final</code> keyword, I created a <code>NOEXCEPT</code> macro that could be used to toggle on/off the use of <code>noexcept</code> at CMake configuration time. This way I could see by how much the keyword could improve throughput by.</p>

<p>When I did the initial A/B testing, <a href="https://github.com/define-private-public/PSRayTracing/blob/124ac4eacea0734857d4e329a49c54fc30a003c3/README.rst#marking-functions-as-noexcept">I don&#39;t recall seeing that much of a speedup</a>. The rendering code (which is what is measured) had zero exceptions from the start. PSRT does have a few, but they are all exclusively used in setup; not during any performance critical sections. I still left it in (and turned on) because it didn&#39;t seem to hurt anything and potentially help.</p>

<p>Back in April 2024 when I published that <a href="https://16bpp.net/blog/post/the-performance-impact-of-cpp-final-keyword/">one article about my findings of <code>final</code>&#39;s performance impact,</a> I submitted it to <a href="https://cppcast.com/">CppCast</a> via email. Timur Doumler (one of the co-hosts) asked me if I had any performance benchmarks about the use of <code>noexcept</code>. I did not.</p>

<p>But since the time I first added in <code>NOEXCEPT</code>, I had created automated testing tools (which also tracks the performance) and an analysis suite to view the data. I decided to re-run all of the same tests (including more), but this time to truly see if <code>noexcept</code> actually does have some impact on performance.</p>

<p>The short answer is: <strong>yes, but also no; it&#39;s complicated and silly</strong>.</p>

<p><img alt="Render of sphere with surface normal" src="https://storage.googleapis.com/sixteenbpp/blog/images/noexcept-can-sometimes-help-or-hurt-performance/normal_sphere.png"/></p>



<h5>Prior Art</h5>

<p>In his email, Mr. Doumler told me that no one else in the C++ community had yet to publish any benchmarks about the keyword; to see if it actually did help performance.</p>

<p>At first, I wasn&#39;t able to find any. But eventually I did stumble across <a href="https://stackoverflow.com/questions/16104057/does-noexcept-improve-performance/65346695#65346695">a 2021 answer to a 2013 stack overflow question</a>. <code>vector::emplace_back()</code> was found to be about 25-30% faster if <code>noexcept</code> was being used. Fairly significant! But this lacks telling us what CPU, OS, and Compiler were used.</p>

<p>In the 11th hour of writing this, <a href="https://www.youtube.com/watch?v=dVRLp-Rwg0k">I found a lighting talk from C++ on Sea 2019</a>. Niels Dekker (while working on <a href="https://itk.org/">ITK</a>) did his own version of the <code>NOEXCEPT</code> macro along <a href="https://github.com/N-Dekker/noexcept_benchmark">with benchmarks</a>. He is reporting some performance improvements, but his talk also said there are places where <code>noexcept</code> was negative. One other finding is that it was compiler dependent.</p>

<p>And, that&#39;s about it. From cursory Googling there is a lot of discussion but not many numbers from an actual benchmark. If any readers happen to have one on hand, please message me so I can update this section.</p>



<h3>How Does noexcept Make Programs Faster?</h3>

<p>This is something I had some trouble trying to figure out (<a href="https://www.reddit.com/r/cpp_questions/comments/p7dlgb/after_10_years_i_am_still_not_sure_about_the/">and I don&#39;t seem to be the only one</a>). An obvious answer could be &#34;<em>because it prevents you from <a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2019/p1886r0.html">using exceptions that slow down your code</a>.</em>&#34; But this isn&#39;t satisfactory.</p>

<p>Among performance minded folks, there is a lot of hate for exceptions. GCC has a compiler flag <code>-fno-exceptions</code> to forcibly turn off the feature. Some folks are trying to remedy the situation by providing alternatives. Boost itself has two: <a href="https://www.boost.org/doc/libs/1_85_0/libs/outcome/doc/html/index.html">Outcome</a> and <a href="https://boostorg.github.io/leaf/">LEAF</a>. Right now LEAF seems to be <a href="https://github.com/boostorg/leaf/blob/e5cf085aee39c1a415121f0e064c0afaa46c0c6f/benchmark/benchmark.md">winning in terms of speed</a>.</p>

<p><a href="https://visualstudiomagazine.com/Articles/2016/10/01/noexcept.aspx?admgarea=ALM">Kate Gregory wrote an article entitled &#34;Make Your Code Faster with noexcept&#34; (2016)</a> that provides more insight. Quote:</p>

<blockquote>
<p><em>First, the compiler doesn&#39;t have to do a certain amount of setup -- essentially the infrastructure that enables stack unwinding, and teardown on the way into and out of your function -- if no exceptions will be propagating up from it. ...</em></p>

<p><em>Second, the Standard Library is noexcept-aware and uses it to decide between copies, which are generally slow, and moves, which can be orders of magnitude faster, when doing common operations like making a vector bigger.</em></p>
</blockquote>

<p>While this provides how <code>noexcept</code> can help performance, it neglects to provide something important: a benchmark.</p>

<hr/>


<h3>Why &#34;Don&#39;t Use noexcept&#34;?</h3>

<p>I didn&#39;t understand this either. I couldn&#39;t find many (simple) resources advocating for this camp. I found a paper (from 2011) entitled &#34;<a href="https://www.open-std.org/jtc1/sc22/wg21/docs/papers/2011/n3248.pdf"><code>noexcept</code> Prevents Library Validation</a>&#34;. I&#39;m not sure how relevant it is 13+ years later. Else, Mr. Doumler sent me a good case via email:</p>

<blockquote>
<p><em>Meanwhile, sprinkling <code>noexcept</code> everywhere causes lots of other problems, for example if you want to use things like a throwing assert for testing your code that just doesn&#39;t work.</em></p>
</blockquote>

<p>Assertions are great for development and debugging; everyone loves them. They are absolutely vital to building any major C/C++ project. This is something I do not want taken away.</p>

<p>Personally, I like the <code>noexcept</code> keyword. It&#39;s very useful for documentation and telling others how to use code. We&#39;ve all been burned by an unexpected exception at some point. It&#39;s nice to have in the language in my opinion for this reason.</p>



<h3>How This Test Works</h3>

<p>It&#39;s the exact same as the last time for what I did with <code>final</code>. But for those of you who aren&#39;t familiar, let me explain:</p>

<ol>
	<li>It&#39;s a simple A/B test of the <code>noexcept</code> keyword being turned on and off with the same codebase</li>
	<li>The test is an implementation of Peter Shirley&#39;s <a href="https://raytracing.github.io/">Ray Tracing in One Weekend book series</a></li>
	<li>It&#39;s fully CPU bound and vanilla-as-possible-modern-standard-C++</li>
	<li>All scenes from the book are rendered 50 times <strong>without</strong> <code>noexcept</code> turned on
	<ul>
		<li>Each test case has slightly different parameters (e.g. image size, number of cores, random seed, etc.)</li>
		<li>One pass can take about 10-20 hours.</li>
		<li><strong>Only the time spent rendering is measured</strong> (using nanoseconds)</li>
	</ul>
	</li>
	<li>Once again, we repeat the above, but <strong>with</strong> <code>noexcept</code> turned on</li>
	<li>The off vs. on time difference is calculated as a percentage
	<ul>
		<li>E.g. <code>off=100 ms</code> and <code>on=90 ms</code>. Speedup is 10 ms, so we say that&#39;s an +11% performance boost</li>
	</ul>
	</li>
	<li>All of the above is repeated for a matrix of different chips (AMD, Intel, Apple), different operating systems (Linux, Mac, Windows) and different compilers (GCC, clang, MSVC). This time I tested 10 different configurations</li>
</ol>

<p>All of the code was built using CMake and compiled with Release mode on, which should give the most performant runtimes (.e.g GCC/clang use <code>-O3</code> and MSVC has its equivalent).</p>

<p>One important thing I do need to state about this test:</p>

<p>Unfortunately, 100% of all images rendered did not come out the same. The overwhelming super majority did; and when they were different it&#39;s negligible. When I first worked on this project <a href="https://old.reddit.com/r/cpp/comments/7i21sn/til_uniform_int_distribution_is_not_portable/">I didn&#39;t know <code>std::uniform_int_distribution</code> doesn&#39;t actually produce the same results on different compilers</a>. (A major issue IMO because that means the standard isn&#39;t really portable). A few scenes (such as Book 2&#39;s final scene) use an RNG to place objects and generate some noise textures. For example, GCC &amp; MSVC (regardless of CPU/OS) seem to produce the exact same scene and same pixels. But clang has a few objects in different positions and some noise is different. Surprisingly, it is mostly intact compared to the other two. I find this astonishing. But I don&#39;t think the difference is that much to require a redo of the experiment. You can see the comparisons in <a href="https://storage.googleapis.com/sixteenbpp/blog/images/noexcept-can-sometimes-help-or-hurt-performance/book_2_final_scene_renders.zip">this hefty .zip file</a>.</p>

<p>This discrepancy shouldn&#39;t matter that much for two reasons:</p>

<ol>
	<li>The differences are not too significant (see the .zip linked above if you&#39;re skeptical)</li>
	<li>The comparison is <code>&lt;CHIP&gt; + &lt;OS&gt; + &lt;COMPILER&gt; with &lt;FEATURE&gt; off</code> vs. <code>&lt;CHIP&gt; + &lt;OS&gt; + &lt;COMPILER&gt; with &lt;FEATURE&gt; on</code></li>
</ol>

<p>With this said, at the end I do some fun number crunching in a Jupyter notebook and show you some colourful tables &amp; charts alongside analysis.</p>

<p>Please keep in mind that this is a fairly specific benchmark. The (initial) goal of PSRT was to render pretty CGI pictures really fast (without breaking the original books&#39; architecture). It works in a mostly recursive manner. Different applications such as financial analysis, protein folding simulations, or training AIs could have different results.</p>

<p>If you&#39;re wondering how I can turn off and on the use of <code>noexcept</code>, it works by (ab)using preprocessor macros:</p>


<p>And thus we powder it all around the code like so:</p>


<p>Once again, this is something <strong>I would never <u>EVER</u> do in production code</strong>; and you shouldn&#39;t either.</p>

<p>Also, I am (now) aware there is <code>noexcept(true)</code> and <code>noexcept(false)</code> that I could have done instead. I didn&#39;t know about it at the time and did this ugly C macro. Please forgive me merciless internet commentators.</p>

<p>Almost every function in this project has been marked with this macro. There are a few... exceptions... but these are in the setup or teardown sections of the program. None are in any of the rendering code (which is what is measured). This should allow us to see if marking functions as <code>noexcept</code> help performance or not.</p>

<p>PSRayTracing is not a &#34;real world&#34; application. Primarily serving as an amateur academic project, it does try to be modeled based on real world experiences. Personally, I do believe that commercial products like Unreal Engine or <a href="https://renderman.pixar.com/">Pixar&#39;s RenderMan</a> can serve as better benchmarking tools in general. But I have no idea about their ability to A/B test the C++ language, algorithms, data structures, etc. This is something PSRT has been set up to do.</p>



<h3>Results From The Suite</h3>

<p>Running the entire test suite an exhausting 22 times, it took cumulatively an absolutely melting 370 hours ðŸ« ðŸ« </p>

<p>One thing I need to note is the AMD+Windows runs are &#34;artificial&#34; in a sense. When I did the initial analysis I noticed some of the variance in the data was higher than desired. So I ran the suite a second time (once for GCC and MSVC), but for each test case I took the fastest runtime between both attempts. This way AMD+Windows could be given the best chance possible.</p>

<p>So, does <code>noexcept</code> help performance?Â  Here&#39;s the grand summary:</p>



<p><img alt="Overall Performance of noexcept" src="https://storage.googleapis.com/sixteenbpp/blog/images/noexcept-can-sometimes-help-or-hurt-performance/overall_performance.png"/></p>



<p>We can see here that in some configurations, <code>noexcept</code> gave a half to full percent performance increase; which I think unfortunately could be declared fuzz. In the situations where there was a drop, it&#39;s around -2% on average. <code>noexcept</code> isn&#39;t really doing that much; it&#39;s even acutely harmful for performance. Bar charting that data:</p>



<p><img alt="Overall Performance of noexcept Barchart" src="https://storage.googleapis.com/sixteenbpp/blog/images/noexcept-can-sometimes-help-or-hurt-performance/overall_performance_barchart.png"/></p>



<p>I do need to remind: this is not supposed to be a Monday Night Compiler Smackdown cage match, but once again there are interesting things to observe:</p>

<ul>
	<li>Like last time, the Apple Silicon trounces everything else, and by a significant amount</li>
	<li>clang (on Linux) is considerably slower than GCC</li>
	<li>If you were to overlay the AMD bars on top of the Intel ones, it almost looks the same</li>
	<li>Your OS (the runtime environment) can have a significant impact on throughput. GCC is doing way better on Linux than Windows.</li>
</ul>

<p>Summaries are okay, but they don&#39;t tell the whole picture. Next, let&#39;s see how many of the test cases had a performance increase. While a 1% speedup could not seem like much, for some applications that does equal a lot in cost savings.</p>



<p><img alt="Percent of Test Cases Faster" src="https://storage.googleapis.com/sixteenbpp/blog/images/noexcept-can-sometimes-help-or-hurt-performance/percent_of_test_cases_faster.png"/></p>



<p>What about the inverse? Here are the percentages of tests having a slowdown with <code>noexcept</code>:</p>



<p><img alt="Percent of Test Cases Slower" src="https://storage.googleapis.com/sixteenbpp/blog/images/noexcept-can-sometimes-help-or-hurt-performance/percent_of_test_cases_slower.png"/></p>



<p>I don&#39;t think there&#39;s too much we can glean from these tables other than the runtime delta typically stays within the (very) low single percents. Looking at it per scene tells a different story:</p>



<p><img alt="Average Delta Percent If noexcept Used" src="https://storage.googleapis.com/sixteenbpp/blog/images/noexcept-can-sometimes-help-or-hurt-performance/mean_delta_percent_if_noexcept_used.png"/></p>



<p>When we look at the average &#34;percentage performance delta per scene&#34;, we can clearly see there are some scenes that benefit quite well from <code>noexcept</code>, others are getting hit quite hard. It&#39;s also interesting to note how many scenes are barely helped or hurt. Means are good, but seeing the median gives a more fair look at the results. When that is done with the above data, <code>noexcept</code> looks to be less impactful:</p>



<p><img alt="Median Delta Percent If noexcept Used" src="https://storage.googleapis.com/sixteenbpp/blog/images/noexcept-can-sometimes-help-or-hurt-performance/median_delta_percent_if_noexcept_used.png"/></p>



<p>If you want to look at the variance, <a href="https://storage.googleapis.com/sixteenbpp/blog/images/noexcept-can-sometimes-help-or-hurt-performance/variance_delta_percent_if_noexcept_used.png">I have the table right here</a>. I don&#39;t think it&#39;s as interesting as the above two (though you can have it anyways).</p>

<p>So overall, it mostly looks like <code>noexcept</code> is either providing a very marginal performance increase or decrease. <strong>Personally, I think it is fair to consider the measured performance increase/hit from <code>noexcept</code> to be fuzz</strong>; that means it kind of does nothing at all to help runtime speed.</p>

<p>There are some interesting &#34;islands&#34; to take a look at from the above chart.</p>



<h3>The AMD+Ubuntu+GCC configuration</h3>

<p>We actually see a very significant and consistent performance boost of 6-8% with <code>noexcept</code> turned on! But this is only for the scenes from book 1. When I first saw this I was wondering what could have caused it, and eventually I realized it was related to the architecture of the scene geometry from the first book.</p>

<p>All scene data is stored inside of a <code>std::vector</code> called <a href="https://github.com/define-private-public/PSRayTracing/blob/acb04979c49ea8adef8c4afc349a96015834835e/render_library/Objects/HittableList.hpp"><code>HittableList</code></a>. For these scenes, when the ray tracer is traversing through the scene geometry it&#39;s doing a sequential search; this was done for simplicity. Any practical graphics engine (realtime or not) will use a tree like structure instead for the scene information.</p>

<p>Starting in book 2 the second task is to use a <a href="https://en.wikipedia.org/wiki/Bounding_volume_hierarchy">BVH</a> to store the scene. This provides a massive algorithmic boost to the performance. All subsequent scenes in this book use a BVH instead of a list of objects. This is why we don&#39;t see that same speedup in Book 2 (and in fact, a minor performance hit).</p>

<p>From up above, if you remember one of the arguments for &#34;<code>noexcept</code> is faster&#34; is the standard library is aware and can use (faster) memory move operations instead of (slower) copy operations. This is most likely the cause of the performance increase. But the BVH node is not part of <code>std::</code>, and doesn&#39;t have move constructors implemented. Therefore when using it <code>noexcept</code> does nearly nothing.</p>

<p>What is more fascinating is that the boost was <strong>only</strong> seen on AMD+Ubuntu+GCC configuration. Swap out any one of those variables (CPU, OS, or compiler) and no significant gain (in fact a tiny loss) was observed.</p>



<h4>Digging A Little Bit Deeper</h4>

<p>So... There&#39;s actually two BVH tree implementations in PSRT. One of them is the original from book 2. The other one is something I cooked up called <a href="https://github.com/define-private-public/PSRayTracing/blob/acb04979c49ea8adef8c4afc349a96015834835e/render_library/Objects/BVHNode_MorePerformant.cpp"><code>BVHNode_MorePerformant</code></a>. It&#39;s 100% API compatible with the standard <code>BVHNode</code>. <a href="https://github.com/define-private-public/PSRayTracing/blob/acb04979c49ea8adef8c4afc349a96015834835e/README.rst#bvh-tree-as-a-list">But under the hood it works a little differently</a>. The quick gist of it: instead of using a tree of pointers to store and traverse, the data is stored in a <code>std::vector</code> in a particular order. The traversal is still done in a tree-like manner, but because of the memory layout of what needs to be checked it can be more efficient. Years ago when I first wrote and tested this class I did see a small speedup in lookups.</p>

<p>It might be good to measure replacing <code>HittableList</code> in book 1 (on AMD+Ubuntu+GCC) with both BVH implementations and see the results:</p>



<p><img alt="Book1 BVH vs. HittableList Overall" src="https://storage.googleapis.com/sixteenbpp/blog/images/noexcept-can-sometimes-help-or-hurt-performance/book1_amd_gcc_linux_overall_performance.png"/></p>



<p><img alt="Book1 BVH vs. HittableList Overall Barchart" src="https://storage.googleapis.com/sixteenbpp/blog/images/noexcept-can-sometimes-help-or-hurt-performance/book1_amd_gcc_linux_overall_performance_barchart.png"/></p>



<p><img alt="Book1 BVH vs. HittableList Average Delta Percent" src="https://storage.googleapis.com/sixteenbpp/blog/images/noexcept-can-sometimes-help-or-hurt-performance/book1_amd_gcc_linux_mean_delta_percent_if_noexcept_used.png"/></p>



<p><img alt="Book1 BVH vs. HittableList Median Delta Percent" src="https://storage.googleapis.com/sixteenbpp/blog/images/noexcept-can-sometimes-help-or-hurt-performance/book1_amd_gcc_linux_median_delta_percent_if_noexcept_used.png"/></p>

<p>(Variance table <a href="https://storage.googleapis.com/sixteenbpp/blog/images/noexcept-can-sometimes-help-or-hurt-performance/book1_amd_gcc_linux_variance_delta_percent_if_noexcept_used.png">available here</a> if you&#39;re interested (it&#39;s boring)).</p>

<p>Using <code>std::vector</code> with a dash of <code>noexcept</code> in your code will make that container faster. But we have to remember it&#39;s algorithmically inefficient compared to a BVH. And slapping <code>noexcept</code> on top of that (the BVH) can actually be harmful!!. And much to my dismay, my <code>BVHNode_MorePerformant</code> was beaten by the book&#39;s default implementation ðŸ˜­</p>

<p>Shortly below there is a secondary benchmark that has a &#34;reduced&#34; version of <code>HittableList</code> across the configurations. But I would like to address a few other points of interest.</p>



<h3>Intel+Windows+MSVC</h3>

<p>Looking at the mean/median tables from <a href="https://storage.googleapis.com/sixteenbpp/blog/images/noexcept-can-sometimes-help-or-hurt-performance/median_delta_percent_if_noexcept_used.png">further above</a>, the Intel+Windows+MSVC run seems to get a little bit of a hit overall when using <code>noexcept</code>. The <code>book2::perlin_sphere::</code> series of tests steer towards a negative impact. And there are two scenes that have a whopping -10% performance hit with the keyword enabled!!</p>



<p><img alt="Perlin Sphere with Trilinear Noise Interpolation" src="https://storage.googleapis.com/sixteenbpp/blog/images/noexcept-can-sometimes-help-or-hurt-performance/trilinear_noise_interpolation.png"/></p>



<p>I am wholly confused as to why this is happening. As you can see, they are pretty simple scenes. Looking at the two cases with the larger performance hit, they are using <a href="https://en.wikipedia.org/wiki/Trilinear_interpolation">trilinear interpolation</a> (<a href="https://en.wikipedia.org/wiki/Hermite_interpolation">hermetic</a> and non-hermetic). The code <a href="https://github.com/define-private-public/PSRayTracing/blob/acb04979c49ea8adef8c4afc349a96015834835e/render_library/PerlinReal.cpp#L68">is right here</a>. There are some 3-dimensional loops inside of the interpolation over some <code>std::array</code> objects. This is <em>maybe</em> the source of the slowdown (with <code>noexcept</code> on) but I do not want to speculate too much. It&#39;s a very minor subset of the test suite..</p>

<p>If you look at the source code, those three dimensional loops can be manually unrolled, which <em>could</em> (and I stress &#34;<em>could</em>&#34;) lead to a performance boost. Sometimes the compiler is smart enough to unroll loops for us in the generated assembly. I didn&#39;t want to do it at the time since I thought it was going to make the code overly complex and a maintenance nightmare. This is something to take a look at later.</p>



<h3>Looking (a little) More At std::vector</h3>

<p>I think it is fair to conclude using <code>std::vector</code>, with <code>noexcept</code> does lead to a performance increase (compared to without the keyword). <strong>But this is only happening on one configuration.</strong></p>

<p>I thought it would be best to write up <a href="https://github.com/define-private-public/PSRayTracing/blob/ab524a577ccbe3e4a2884a6f958f1b9a10af3ae5/experiments/noexcept_keyword/noexcept_vector_search_test.cpp">a small testing program</a> (that operates just like <code>HittableList</code>). It does the following:</p>

<ol>
	<li>Generate a list of random numbers</li>
	<li>Generate a number to search for (could be out of range)</li>
	<li>Try to find that number in the list
	<ul>
		<li>With this part we turn on/off <code>noexcept</code></li>
	</ul>
	</li>
</ol>


<p>The program (of course) was compiled with <code>-O3 </code>and was supplied the same arguments across each configuration. It&#39;s run like this and here is the output:</p>

<pre>ben@computer:folder$ ./list_test_clang_17 1337 9999999 10000
Checking 9999999 elements, 10000 times...
  plain average time: 2976 us
  `noexcept` average time: 2806 us

  plain median time: 2982 us
  `noexcept` median time: 2837 us</pre>



<p>After testing on each configuration these were the grand results:</p>

<p><img alt="std::vector noexcept Search Test Results Table" src="https://storage.googleapis.com/sixteenbpp/blog/images/noexcept-can-sometimes-help-or-hurt-performance/vector_search_test_results_table.png"/></p>



<p>This is a very limited test. We can see there is a fairly consistent speedup for all x86 cases (and a very nice one for AMD+Windows). Apple Silicon has nothing and is likely fuzz.</p>

<p>The people who like <code>noexcept</code> might find this validating, but it&#39;s at odds with the tables from measuring PSRT: <strong>The speedups here aren&#39;t being matched with all the results from book 1</strong>, which uses the same &#34;sequential search in <code>std::vector</code>&#34; technique.</p>

<p>Look at <a href="https://storage.googleapis.com/sixteenbpp/blog/images/noexcept-can-sometimes-help-or-hurt-performance/median_delta_percent_if_noexcept_used.png">the median chart from above</a>. The only reliable speedup came from AMD+Linux+GCC, of around +7%. All other configurations were flat or possibly fuzz. In this mini test AMD+Linux+GCC meters 12% and many other configurations have a significant positive impact from <code>noexcept</code>.</p>

<p><strong>In a more complex program the speedup wasn&#39;t reproducible</strong>.</p>

<p>From the last article, a commenter on HackerNews mentioned how they didn&#39;t like PSRT as a benchmark because it was too large. They preferred tests of small components. This is absolutely ludicrous since as software developers we&#39;re not writing small programs. We are building complex systems that interact, move memory around, switch contexts, invalidate cache, wait on resources, etc.</p>

<p>Just because a speedup is seen for a single component doesn&#39;t mean it will show up later when programs become large and have a lot of moving parts.</p>

<p>Hopefully I&#39;ve illustrated this point.</p>



<h5>Looking At The Assembly</h5>

<p>C++ isn&#39;t what&#39;s running on the CPU, it&#39;s the generated assembly code. Usually to prove that something is faster, I&#39;ve seen other articles post the generated assembly code, saying &#34;<em>It&#39;s optimized!!&#34;</em> I saw this for <code>final</code>, but what is <code>noexcept</code> doing?</p>

<p>Using the above testing program, let&#39;s see what the difference is in the generated x86 assembly (from GCC 13 with <code>-O3</code>):</p>


<p>These two look... <a href="https://i.redd.it/6lwrp2xhplg41.jpg">oddly the same</a>. I&#39;m only spotting one difference, this line where the arguments are swapped in order:</p>

<pre>&lt;   cmp DWORD PTR [rdx+rax*4], esi

---

&gt;   cmp esi, DWORD PTR [rdx+rax*4]</pre>



<p>I&#39;m not well versed in assembly, but what I can tell <a href="https://www.felixcloutier.com/x86/cmp">from documentation</a>, it doesn&#39;t seem like the order of arguments from the <code>cmp</code> instruction instruction matter. <strong>If they do, someone please tell me so I can correct this information</strong>. I&#39;d be VERY surprised if this swapped order is what caused the speedup in the limited benchmark above. Anyone who understands assembly much better than I, please provide insight. I would be grateful.</p>

<p>Assembly inspection usually can give insights, but it&#39;s no excuse for not measuring your code.</p>

<p>Wrapping up this detour into <code>std::vector</code>, other STL containers <strong><em><span>might</span></em></strong> have a performance increase, but we do not know for certain. Thus far only measurements from <code>std::vector</code> have been taken. I have no idea if something like <a href="https://en.cppreference.com/w/cpp/container/unordered_map"><code>std::unordered_map</code></a> is impacted by <code>noexcept</code>. There are many other popular alternative container implementations (e.g. <a href="https://www.boost.org/doc/libs/1_85_0/doc/html/container.html">Boost</a>, <a href="https://abseil.io/docs/cpp/guides/container">Abseil</a>, <a href="https://github.com/facebook/folly/tree/main/folly/container">Folly</a>, <a href="https://doc.qt.io/qt-6/containers.html">Qt&#39;s</a>). Do these get helped, hurt, or placebo&#39;d by <code>noexcept</code>? <strong>We don&#39;t know</strong>.</p>

<p>And keep in mind, in the context of PSRT, we only saw a consistent speedup on one specific configuration (out of ten); some even saw a minute drop. The CPU, OS, and compiler play a role.</p>

<hr/>


<p>I really question whether <code>noexcept</code> helps performance. Just like with <code>final</code>, it doesn&#39;t seem to be doing much. Some cases it helps, other cases it hurts. We did find one solid case for Book 1 with AMD+Linux+GCC; but that&#39;s it.</p>

<p>And after seeing that overall hit/gain can be from -3% to +1%, I&#39;ve actually become skeptical and <a href="https://github.com/define-private-public/PSRayTracing/commit/acb04979c49ea8adef8c4afc349a96015834835e">decided to turn it off</a>. I still like the keyword as a documentation tool and hint to other programmers. But for performance, it mostly looks to be a sugar pill.</p>

<p>My most important advice is the same as last time: <strong>don&#39;t trust anything until you&#39;ve measured it.</strong></p>

<hr/>


<h6>Last Notes</h6>

<p>I really didn&#39;t think I was going to be running such a similar test again and so quickly. This has inspired me to take a look at a few other performance claims I&#39;ve heard but yet to have seen numbers posted for.</p>

<p>As for the benchmark itself, I would have loved to throw in some Android and iOS runs as well, but I do not have the bandwidth for that, or infrastructure to make it possible unless I were to quit my day job. We don&#39;t have too much high performance computing on mobile and ARM chips yet, but I can see it being something in the future. This is one of the deficiencies of this test. I&#39;d really like to throw Windows+clang into the mix too, but right now there isn&#39;t a turnkey solution like how <a href="https://github.com/skeeto/w64devkit">w64devkit</a> provides GCC for Windows. Embedded and other &#34;exotic&#34; chips/runtimes have been given any love either. Maybe even playing with an IBM z16 might be fun ðŸ˜ƒ</p>

<p>PSRT doesn&#39;t also have a good way to &#34;score&#34; how intense a scene is. E.g. number of objects, what kinds, how complex, what materials, textures, lighting, etc. All that can be done right now is &#34;feature on vs. feature off&#34;.Â  I&#39;d also want to expand this to other applications out side of computer graphics too.</p>

<p>If you want to follow what goes on with PSRayTracing, check out the <a href="https://github.com/define-private-public/PSRayTracing">GitHub page</a> and subscribe to the releases. But do note the active development is done over <a href="https://gitlab.com/define-private-public/PSRayTracing">on GitLab</a>.Â  You can find all of my measurements and analysis tools <a href="https://github.com/define-private-public/PSRayTracing/tree/ab524a577ccbe3e4a2884a6f958f1b9a10af3ae5/experiments/noexcept_keyword">in this section of the repo</a>.</p>

<p>Till next time~</p></div></div>
  </body>
</html>
