<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://tmikov.blogspot.com/2023/09/how-to-speed-up-micro-benchmark-300x.html">Original</a>
    <h1>Static Hermes: Compile JavaScript to speed it up 300x (in microbenchmarks)</h1>
    
    <div id="readability-page-1" class="page"><div>
<p>This is the first of a series of light blog posts about Static Hermes,
covering topics that I find interesting or amusing. It is not intended to be
a systematic introduction to Static Hermes design.Consider it more like a backstage
pass to the quirks, features, and “aha!” moments that make Static Hermes unique.</p>
<p>If you’re not familiar with Static Hermes, it’s an evolving project we’re working
on to explore the confluence of static typing and JavaScript. It is work in progress,
but we’re excited about the possibilities it opens up for performance improvements
and more.</p>
<p>For more background:</p>
<ul>
<li><a href="https://twitter.com/tmikov/status/1700353858763911570?s=20">Tweet with the slide deck of the Static Hermes announcement</a></li>
<li><a href="https://twitter.com/tmikov/status/1181618035355865089?s=20">Previous talk about Hermes</a></li>
</ul>
<p>Contents:</p>
<ul>
<li><a href="#meet-interp-dispatchjs">Meet interp-dispatch.js</a></li>
<li><a href="#lets-run-it">Let’s Run It!</a></li>
<li><a href="#static-hermes-with-untyped-code">Static Hermes with Untyped Code</a></li>
<li><a href="#helping-the-compiler">Helping the Compiler</a></li>
<li><a href="#other-ways-to-help-the-compiler">Other Ways to Help the Compiler</a></li>
<li><a href="#some-observations">Some Observations</a></li>
<li><a href="#revisiting-the-original-untyped-code">Revisiting The Original Untyped Code</a></li>
<li><a href="#conclusion">Conclusion</a></li>
</ul>
<h2 id="meet-interp-dispatch.js">Meet interp-dispatch.js</h2>
<p><code>interp-dispatch.js</code> is a Hermes micro-benchmark written to evaluate the interpreter
dispatch overhead and to catch regressions in it. When we say <em>dispatch overhead</em>,
we mean the extra work the interpreter needs to do <em>in addition to</em> executing the
actual instructions. Specifically, switching to the instruction implementation based
on the instruction opcode. So, this test deliberately uses cheap instructions, but
lots of them.</p>
<p>Of course, to some degree it also evaluates the performance of the implementations of
the instructions themselves, since it is impossible to separate the dispatch overhead
from instruction execution.</p>
<p>It is an fun benchmark because its minimalistic and loop-heavy design makes it
highly sensitive to minor changes, offering insights into the impact of such
changes on running time.</p>
<p><code>interp-dispatch.js</code> does not claim to have a higher meaning than that, to represent
useful classes of calculations, etc. You can make up your own mind about it.</p>
<p>Without further ado, this is it:</p>
<pre><code><span>function</span> <span>bench</span> <span>(</span>lc<span>,</span> fc<span>)</span> <span>{</span>
    <span>var</span> n<span>,</span> fact<span>;</span>
    <span>var</span> res <span>=</span> <span>0</span><span>;</span>
    <span>while</span> <span>(</span><span>--</span>lc <span>&gt;=</span> <span>0</span><span>)</span> <span>{</span>
        n <span>=</span> fc<span>;</span>
        fact <span>=</span> n<span>;</span>
        <span>while</span> <span>(</span><span>--</span>n <span>&gt;</span> <span>1</span><span>)</span>
            fact <span>*=</span> n<span>;</span>
        res <span>+=</span> fact<span>;</span>
    <span>}</span>
    <span>return</span> res<span>;</span>
<span>}</span>

<span>let</span> t1 <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span><span>;</span>
<span>var</span> res <span>=</span> <span>bench</span><span>(</span><span>4e6</span><span>,</span> <span>100</span><span>)</span><span>;</span>
<span>print</span><span>(</span>Date<span>.</span><span>now</span><span>(</span><span>)</span> <span>-</span> t1<span>,</span> <span>&#34;ms,&#34;</span><span>,</span> res<span>)</span><span>;</span>
</code></pre>
<p>It calculates the same factorial in a loop a specified number of times and adds the results.</p>
<p>Let’s look at the compiled bytecode:</p>
<pre><code>Function&lt;bench&gt;(3 params, 10 registers, 0 symbols):
    LoadParam         r5, 2
    LoadConstZero     r4
    LoadConstUInt8    r3, 1
    LoadParam         r0, 1
    Dec               r2, r0
    LoadConstZero     r1
    LoadConstZero     r0
    JNotGreaterEqual  L1, r2, r0
L4:
    Dec               r8, r5
    Mov               r7, r5
    Mov               r6, r7
    JNotGreater       L2, r8, r3
L3:
    Mul               r7, r7, r8
    Dec               r8, r8
    Mov               r6, r7
    JGreater          L3, r8, r3
L2:
    Add               r1, r1, r6
    Dec               r2, r2
    Mov               r0, r1
    JGreaterEqual     L4, r2, r4
L1:
    Ret               r0
</code></pre>
<p>It is pretty tight. The inner loop is the instructions from <code>L3:</code> to <code>JGreater</code>. Not bad,
though we can eliminate the extra <code>Mov</code>, shrinking the loop from four to three instructions.</p>
<p>The outer loop is from <code>L4:</code> to <code>JGreaterEqual</code>.</p>
<h2 id="lets-run-it">Let’s Run It!</h2>
<p>Running it with the Hermes interpreter, we get the following:</p>
<pre><code>$ hermes-rel -w bench.js
2086 ms, 3.7330486176528693e+164
</code></pre>
<p>2086 ms, that is a very respectable result for an interpreter. This isn’t too surprising,
given the considerable effort put into optimizing the Hermes interpreter, with plans for
even more significant improvements.</p>
<p>Now, let’s examine the impact of native compilation:</p>
<pre><code>$ shermes-rel -w bench.js -o bench

$ ./bench
2388 ms 3.7330486176528693e+164
</code></pre>
<p>Well, that’s a bit underwhelming. 2388 ms - a bit slower than the
interpreter. How is that possible?</p>
<p>The answer lies in the nature of untyped code. Intuitively, Static Hermes can’t do
much for completely untyped code. It has to assume that <code>lc</code> and <code>fc</code> can be any
type, including string or <code>BigInt</code>. Let’s dig a little deeper.</p>
<h2 id="static-hermes-with-untyped-code">Static Hermes with Untyped Code</h2>
<p>First, let’s check out the assembly code generated by Static Hermes:</p>
<pre><code>$ shermes-rel -S bench.js 
$ cat bench.s
</code></pre>
<p>Remember the inner JS loop?</p>
<pre><code>    <span>while</span> <span>(</span><span>--</span>n <span>&gt;</span> <span>1</span><span>)</span>
        fact <span>*=</span> n<span>;</span>
</code></pre>
<p>This is it compiled to armv8 assembly:</p>
<pre><code>LBB2_4:
        mov     x0, x19
        mov     x1, x23
        mov     x2, x25
        bl      __sh_ljs_mul_rjs
        str     x0, [sp, #72]
        mov     x0, x19
        mov     x1, x25
        bl      __sh_ljs_dec_rjs
        ldr     x8, [sp, #72]
        str     x0, [sp, #80]
        str     x8, [sp, #64]
        add     x2, sp, #8
        mov     x0, x19
        mov     x1, x25
        bl      __sh_ljs_greater_rjs
        tbnz    w0, #0, LBB2_4
</code></pre>
<p>You can clearly see why it’s not fast: multiplication, decrement, and comparison are all
function calls. This confirms our intuition.</p>
<p>To dig deeper, let’s see what Static Hermes thinks the types are, using the <code>--dump-lra</code> option:</p>
<pre><code>shermes -dump-lra bench.js
</code></pre>
<p>Here’s the relevant part of the inner loop’s internal representation:</p>
<pre><code>%BB4:
  $loc5 = BinaryMultiplyInst (:number|bigint) $loc5, $loc6
  $loc6 = UnaryDecInst (:number|bigint) $loc6
  $loc4 = MovInst (:number|bigint) $loc5
  $loc5 = CmpBrGreaterThanInst $loc6, $np0, %BB4, %BB3
</code></pre>
<p>The types following each instruction show that Static Hermes infers <code>n</code> and <code>fact</code>
to be either number or bigint. This is  neat, but unfortunately still requires a
function call for each operation.</p>
<p>But how does it know that they can be only <code>number</code> or <code>bigint</code>? What if the inputs were
strings or <code>undefined</code> or even something crazy like regular expressions? Let’s look at
the beginning of the function:</p>
<pre><code>function bench(lc: any, fc: any): string|number
frame = []
%BB0:
  ...
  $loc3      = LoadParamInst (:any) %fc: any
  $loc0      = LoadParamInst (:any) %lc: any
  $loc2      = UnaryDecInst (:number|bigint) $loc0
</code></pre>
<p>It is loading <code>fc</code> into <code>$loc3</code> and <code>lc</code> into <code>$loc0</code>. At this point we can see Static
Hermes still thinks that they can be anything, <code>any</code>. But then it decrements <code>$loc0</code>,
and we can see that the result if <code>UnaryDecInst</code> changes to <code>number|bigint</code>. Static Hermes
knows that the result of the JavaScript <code>--</code> operator is always <code>number</code> or <code>bigint</code>,
regardless of its inputs and can take advantage of that.</p>
<p>In other words, Static Hermes uses the rules of JavaScript to reason about and infer
the possible types of every value. This is very powerful, but unfortunately it is not
always enough to generate efficient code. Often, we need to pin down a specific type,
not just that it is one of several possible.</p>
<p>So, with this understanding, could a minimal change to the code make it faster?</p>
<h2 id="helping-the-compiler">Helping the Compiler</h2>
<p>Static Hermes infers types based on JavaScript language rules. For example, it knows
that the result of the <code>--</code> operator is always <code>number|bigint</code>. Can we help it narrow
down the type even further?</p>
<p>Absolutely. In JavaScript, the unary <code>+</code> operator is designed to always return a number.
So, when we write:</p>
<pre><code>    x <span>=</span> <span>+</span>x<span>;</span>
</code></pre>
<p>Both we and the compiler can be confident that <code>x</code> is now a number.</p>
<p>The most crucial variable in this benchmark is <code>fc</code>, which controls the inner loop.
Let’s apply this optimization technique to it:</p>
<pre><code><span>function</span> <span>bench</span> <span>(</span>lc<span>,</span> fc<span>)</span> <span>{</span>
    fc <span>=</span> <span>+</span>fc<span>;</span>
    <span>var</span> n<span>,</span> fact<span>;</span>
    <span>var</span> res <span>=</span> <span>0</span><span>;</span>
    
<span>}</span>
</code></pre>
<p>Now, let’s run it through Static Hermes again:</p>
<pre><code>$ shermes-rel -w bench.js -o bench

$ ./bench
278 ms 3.7330486176528693e+164
</code></pre>
<p>Impressive! The execution time is down to 278 ms, making it 7.5 times faster than the
interpreter and 8.6 times faster than our previous run—all from a single-line change.</p>
<p>To confirm out understanding, let’s check the IR again:</p>
<pre><code>shermes -dump-lra bench.js

...
...
%BB4:
  $np8       = BinaryMultiplyInst (:number) $np8, $np7
  $np7       = UnaryDecInst (:number) $np7
  $np6       = MovInst (:number) $np8
  $loc1      = CmpBrGreaterThanInst $np7, $np4, %BB4, %BB3
</code></pre>
<p>As expected, all operations are now strictly of type <code>number</code>. The assembly reflects
this optimization:</p>
<pre><code>LBB2_4:
	fmul	d0, d0, d1
	fadd	d1, d1, d12
	fcmp	d1, d10
	b.gt	LBB2_4
</code></pre>
<p>It’s a tight loop, devoid of function calls, just as we’d hoped.</p>
<h2 id="other-ways-to-help-the-compiler">Other Ways to Help the Compiler</h2>
<p>While wrapping up this post, I began pondering other ways to assist the compiler that
are worth mentioning.</p>
<p>An observant reader might wonder: if we’re only calling bench with numbers, why doesn’t
Static Hermes recognize <code>lc</code> and <code>fc</code> as such? The reason is that <code>bench()</code> is a global
function. It is assigned to a global variable, or more accurately to a property of the
global object <code>globalThis.bench</code>. Static Hermes can’t make assumptions about how it might
be called from elsewhere in the code.</p>
<p>In reality, most code resides in modules, be it CommonJS or ESM. While we won’t get into
the whole module system here, we can simulate this behavior by enclosing our code in a
self-invoking function. This allows Static Hermes to make more precise inferences about
function call sites.</p>
<pre><code><span>(</span><span>function</span> <span>module</span><span>(</span>exports<span>)</span> <span>{</span>

<span>function</span> <span>bench</span> <span>(</span>lc<span>,</span> fc<span>)</span> <span>{</span>
    <span>var</span> n<span>,</span> fact<span>;</span>
    <span>var</span> res <span>=</span> <span>0</span><span>;</span>
    <span>while</span> <span>(</span><span>--</span>lc <span>&gt;=</span> <span>0</span><span>)</span> <span>{</span>
        n <span>=</span> fc<span>;</span>
        fact <span>=</span> n<span>;</span>
        <span>while</span> <span>(</span><span>--</span>n <span>&gt;</span> <span>1</span><span>)</span>
            fact <span>*=</span> n<span>;</span>
        res <span>+=</span> fact<span>;</span>
    <span>}</span>
    <span>return</span> res<span>;</span>
<span>}</span>

<span>let</span> t1 <span>=</span> Date<span>.</span><span>now</span><span>(</span><span>)</span><span>;</span>
<span>var</span> res <span>=</span> <span>bench</span><span>(</span><span>4e6</span><span>,</span> <span>100</span><span>)</span><span>;</span>
<span>print</span><span>(</span>Date<span>.</span><span>now</span><span>(</span><span>)</span> <span>-</span> t1<span>,</span> <span>&#34;ms&#34;</span><span>,</span> res<span>)</span><span>;</span>

<span>}</span><span>)</span><span>(</span><span>{</span><span>}</span><span>)</span><span>;</span>
</code></pre>
<p>Let’s run it:</p>
<pre><code>$ shermes-rel -w bench-mod.js -o bench-mod

$ ./bench-mod
6 ms 3.7330486176528693e+164
</code></pre>
<p>Wait, what? A jaw-dropping 6 ms! That’s 348 times faster than the interpreter and 46 times
faster than our earlier optimization. What led to this dramatic improvement?</p>
<p>It turns out that Static Hermes is now able to inline <code>bench()</code> directly into the main
function, replacing the parameters with their actual values. Not only does it know their
types, it knows their values!</p>
<p>For clarity, I’ve trimmed down the code to focus on the compiler’s output:</p>
<pre><code><span>(</span><span>function</span> <span>module</span><span>(</span>exports<span>)</span> <span>{</span>
<span>function</span> <span>bench</span> <span>(</span>lc<span>,</span> fc<span>)</span> <span>{</span>
  
<span>}</span>
<span>return</span> <span>bench</span><span>(</span><span>4e6</span><span>,</span> <span>100</span><span>)</span><span>;</span>
<span>}</span><span>)</span><span>(</span><span>{</span><span>}</span><span>)</span><span>;</span>
</code></pre>
<p>Here is the generated IR:</p>
<pre><code>function module(exports: any): number [allCallsitesKnownInStrictMode]
frame = []
%BB0:
  $np5       = HBCLoadConstInst (:number) 0: number
  $np2       = HBCLoadConstInst (:number) 1: number
  $np6       = HBCLoadConstInst (:number) 3999999: number
  $np1       = HBCLoadConstInst (:number) 0: number
%BB1:
  $np8       = HBCLoadConstInst (:number) 99: number
  $np7       = HBCLoadConstInst (:number) 100: number
%BB4:
  $np0       = BinaryMultiplyInst (:number) $np7, $np8
  $np8       = UnaryDecInst (:number) $np8
  $np7       = MovInst (:number) $np0
  $loc0      = CmpBrGreaterThanInst $np8, $np2, %BB4, %BB3
%BB3:
  $np0       = BinaryAddInst (:number) $np1, $np0
  $np6       = UnaryDecInst (:number) $np6
  $np1       = MovInst (:number) $np0
  $np6       = MovInst (:number) $np6
  $loc0      = CmpBrGreaterThanOrEqualInst $np6, $np5, %BB1, %BB2
%BB2:
  $loc0      = ReturnInst $np0
function_end
</code></pre>
<p>As you can see, the parameters are now constants. The assembly code is even more
remarkable:</p>
<pre><code>LBB2_1:
	fmov	d1, x9
	fadd	d0, d0, d1
	fadd	d0, d0, d1
	fadd	d0, d0, d1
	fadd	d0, d0, d1
	subs	w8, w8, #4
	b.ne	LBB2_1
</code></pre>
<p>The compiler (LLVM) has determined that the inner loop is a constant and has
pre-calculated its value <code>x9</code>. The outer loop has been <em>unrolled</em> four times
(its body has been copied four times, to decrease the number of iterations).</p>
<p>This is a fascinating result, demonstrating a series of compiler optimizations compounding
each other to produce something unexpected and incredibly fast.</p>
<h2 id="some-observations">Some Observations</h2>
<p>A discerning reader might observe that the original code isn’t exactly a model of efficiency —
it calculates the same factorial 4 million times. Why? Because it’s a micro-benchmark designed
to evaluate interpreter dispatch overhead, not to be a paragon of smart coding. The value of
the factorial is irrelevant here.</p>
<p>One could rewrite the code to calculate the factorial just once and then multiply it by 4
million. However, this would defeat the purpose of the benchmark:</p>
<pre><code><span>function</span> <span>bench</span> <span>(</span>lc<span>,</span> fc<span>)</span> <span>{</span>
    fact <span>=</span> fc<span>;</span>
    <span>while</span> <span>(</span><span>--</span>fc <span>&gt;</span> <span>1</span><span>)</span>
        fact <span>*=</span> fc<span>;</span>
    <span>return</span> fact <span>*</span> lc<span>;</span>
<span>}</span>
</code></pre>
<p>Could a compiler theoretically optimize this for us? Sure, but compiler optimizations
involve trade-offs and are often designed with a specific set of use-cases in mind.
In our case, we’re focused on React Native performance, and an optimization like this
wouldn’t be particularly beneficial.</p>
<p>Similarly, LLVM could technically optimize away the entire outer loop in the previous
section, since the result of bench() is a compile-time constant when the parameters
are constants. However, such an optimization isn’t generally useful, especially not in
the context we care about.</p>
<h2 id="revisiting-the-original-untyped-code">Revisiting The Original Untyped Code</h2>
<p>Let’s circle back to the original, unmodified code. We already know that in the inner
loop — the most computationally intensive part of the function — the variables could
only be of type <code>number</code> or <code>bigint</code>. So, could we compile two separate versions of the
loop and dynamically switch between them based on the variable type?</p>
<p>Technically, yes. However, applying this approach more broadly presents challenges.
Imagine a loop with multiple variables, each having different potential types. This
scenario could lead to a combinatorial explosion of type combinations, necessitating a
separate compiled version for each. Even if we were to emit just two versions for most
scenarios, that would still double the size of the output code.</p>
<p>For those interested in this approach, <a href="http://www-sop.inria.fr/members/Manuel.Serrano/publi/serrano-dls18.pdf">Manuel Serrano’s HopC compiler</a> employs a similar
strategy. It generates two versions of every function: one optimized based on heuristics
for the most likely type combinations, and a generic “fallback” version for all other types.</p>
<p>This is an avenue we might explore down the line. However, it’s worth noting that its
utility may be somewhat limited in our specific use-case. This approach mainly benefits
basic types like <code>number</code> and <code>bigint</code>, but doesn’t offer much for more complex types such as
objects.</p>
<h2 id="what-about-type-annotations">What About Type Annotations?</h2>
<p>You might be asking, “Given that Static Hermes is designed to leverage type annotations, why didn’t we use them in this benchmark?” Good question. We chose not to use them for a couple of reasons. First, skipping annotations allowed us to explore the type inference capabilities of this nascent compiler technology. Second, in this particular benchmark, type annotations wouldn’t make a difference. Why? Because we employed other techniques—like the unary <code>+</code> operator—that conveyed the same type information to the compiler. This approach gives us insight into what Static Hermes can deduce and optimize without explicit annotations.</p>
<h2 id="conclusion">Conclusion</h2>
<p>So there you have it. We kicked the tires on Static Hermes a bit, played around with a
micro-benchmark, and even managed to soup it up — way up. Turns out, understanding a little bit
about how Static Hermes (or any compiler, really) thinks can go a long way in making your code
faster. But it’s not like you need to pull out all the stops for every piece of code you write.</p>
<p>If you’re into this stuff,  keep an eye out for more posts like this; we’re just scratching
the surface.</p>
</div></div>
  </body>
</html>
