<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://ziglang.org/devlog/2025/#2025-07-23">Original</a>
    <h1>New Aarch64 Back End</h1>
    
    <div id="readability-page-1" class="page"><p>This page contains a curated list of recent changes to main branch Zig.</p><p>
      This page contains entries for the year <span>2025</span>. Other years are available in
      <a href="https://ziglang.org/devlog/">the Devlog archive page</a>.
    </p><div>
      <div id="2025-07-23">
        <p><span>July 23, 2025</span></p>
        <p>Author: Andrew Kelley &amp; Jacob Young</p><p>Jacob <a href="https://github.com/ziglang/zig/pull/24536" target="_blank">upstreamed his new backend yesterday</a>.</p><pre><code>    275 src/codegen/aarch64/Mir.zig
    138 src/codegen/aarch64/abi.zig
  11799 src/codegen/aarch64/encoding.zig
  10981 src/codegen/aarch64/Select.zig
    905 src/codegen/aarch64/Disassemble.zig
   1653 src/codegen/aarch64/Assemble.zig
    194 src/codegen/aarch64.zig
  25945 total
</code></pre><p>Itâ€™s passing 1547/1960 (79%) of the behavior tests compared to the LLVM backend.</p><p>Although it will grow in size as it approaches completion, it is considerably less logic than the x86 backend:</p><pre><code>     608 src/arch/x86_64/abi.zig
     904 src/arch/x86_64/bits.zig
  194471 src/arch/x86_64/CodeGen.zig
     507 src/arch/x86_64/Disassembler.zig
     980 src/arch/x86_64/Emit.zig
    2790 src/arch/x86_64/encoder.zig
    1072 src/arch/x86_64/Encoding.zig
    2700 src/arch/x86_64/encodings.zon
     689 src/arch/x86_64/Lower.zig
    2152 src/arch/x86_64/Mir.zig
  206873 total
</code></pre><p>In terms of binary size, it adds about 330KB (2%) to the compiler executable.</p><p>Jacob made some pretty neat architectural decisions with this one. For instance, it uses the actual machine code instruction encoding for the compilerâ€™s internal MIR structure. This means that instruction encoding is done on the N codegen threads instead of the 1 linker thread.</p><p>All of the previous backends used a shared two-pass liveness analysis. This new backend has its own similar bespoke two-pass liveness analysis, except that the second pass also happens to generate all of the Mir in reverse at the same time! Besides cutting down on the number of passes that need to iterate over each function, making this backend speedier than other backends at generating code, this will allow backend-specific instruction lowerings that match multiple Air instructions to affect liveness and cause earlier instructions to become unused and end up not producing any code. This means that none of the incredibly complex deferred value tracking from the x86_64 backend is needed, allowing the tracking state machine to be vastly simplified.</p><p>Itâ€™s not quite an apples-to-apples comparison due to missing features, but so far it is significantly faster than the x86 backend:</p><pre><code>Benchmark 1 (117 runs): zig build-exe hello.zig -fno-llvm -OReleaseSmall -target x86_64-linux
  measurement          mean Â± Ïƒ            min â€¦ max           outliers         delta
  wall_time          42.7ms Â± 5.03ms    34.2ms â€¦ 54.1ms          0 ( 0%)        0%
  peak_rss            110MB Â±  580KB     109MB â€¦  111MB          0 ( 0%)        0%
  cpu_cycles          115M  Â± 2.50M      110M  â€¦  122M           0 ( 0%)        0%
  instructions        167M  Â± 11.4K      167M  â€¦  167M           0 ( 0%)        0%
  cache_references   7.64M  Â± 80.4K     7.45M  â€¦ 7.86M           0 ( 0%)        0%
  cache_misses       1.18M  Â± 37.9K     1.10M  â€¦ 1.29M           1 ( 1%)        0%
  branch_misses       885K  Â± 11.2K      859K  â€¦  911K           0 ( 0%)        0%
Benchmark 2 (156 runs): zig build-exe hello.zig -fno-llvm -OReleaseSmall -target aarch64-linux
  measurement          mean Â± Ïƒ            min â€¦ max           outliers         delta
  wall_time          32.1ms Â± 4.22ms    23.7ms â€¦ 44.2ms          0 ( 0%)        âš¡- 24.8% Â±  2.6%
  peak_rss            103MB Â±  663KB     101MB â€¦  105MB          7 ( 4%)        âš¡-  6.5% Â±  0.1%
  cpu_cycles         40.8M  Â± 1.17M     37.8M  â€¦ 43.5M           0 ( 0%)        âš¡- 64.6% Â±  0.4%
  instructions       50.9M  Â± 9.49K     50.9M  â€¦ 50.9M           0 ( 0%)        âš¡- 69.5% Â±  0.0%
  cache_references   2.58M  Â± 52.4K     2.49M  â€¦ 2.85M           1 ( 1%)        âš¡- 66.2% Â±  0.2%
  cache_misses        454K  Â± 22.9K      413K  â€¦  512K           0 ( 0%)        âš¡- 61.6% Â±  0.6%
  branch_misses       274K  Â± 3.13K      268K  â€¦  283K           1 ( 1%)        âš¡- 69.0% Â±  0.2%
</code></pre><p>As for machine code quality, itâ€™s too early to make reasonable comparisons, but suffice to say itâ€™s looking quite promising! Weâ€™ll make another devlog entry when itâ€™s capable of compiling more complex projects.</p>
      </div>
    
      <div id="2025-06-30">
        <p><span>June 30, 2025</span></p>
        <p>Author: Loris Cro</p><p>We scheduled a new Zig SHOWTIME episode for July 2nd to talk with Andrew about the Zig roadmap for 2026.</p><p>For more information check out <a href="https://zig.show/episodes/41/" target="_blank">https://zig.show/episodes/41/</a></p>
      </div>
    
      <div id="2025-06-14">
        <p><span>June 14, 2025</span></p>
        <p>Author: Matthew Lugg</p><p>Less than a week ago, we finally turned on the x86_64 backend by default for Debug builds on Linux and macOS. Today, weâ€™ve got a big performance improvement to it: weâ€™ve parallelized the compiler pipeline even more!</p><p>These benefits do not affect the LLVM backend, because it uses a lot more shared state; in fact, it is still limited to one thread, where every other backend was able to use two threads even before this change. But for the self-hosted backends, machine code generation is essentially an isolated task, so we can run it in parallel with everything else, and even run multiple code generation jobs in parallel with one another. The generated machine code then all gets glued together on the linker thread at the end. This means we end up with one thread performing semantic analysis, arbitrarily many threads performing code generation, and one thread performing linking. Parallelizing this phase is particularly beneficial because instruction selection for x86_64 is incredibly complex due to the architectureâ€™s huge variety of extensions and instructions.</p><p>This worked culminated in a <a href="https://github.com/ziglang/zig/pull/24124" target="_blank">pull request</a>, created by myself and Jacob, which was merged a couple of days ago. It was a fair amount of work, because a lot of internal details of the compiler pipeline needed reworking to completely isolate machine code generation from the linker. But it was all worth it in the end for the performance gains! Using the self-hosted x86_64 backend, we saw anywhere from 5% through to 50% improvements in wall-clock time for compiling Zig projects. For example, Andrew reports being able to build the Zig compiler itself (excluding linking LLVM, which would add a couple of seconds to the time) in 10 seconds or less:</p><pre><code>Benchmark 1 (32 runs): [... long command to build compiler with old compiler ...]
  measurement          mean Â± Ïƒ            min â€¦ max           outliers         delta
  wall_time          13.8s  Â± 71.4ms     13.7s â€¦ 13.8s           0 ( 0%)        0%
  peak_rss           1.08GB Â± 18.3MB    1.06GB â€¦ 1.10GB          0 ( 0%)        0%
  cpu_cycles          109G  Â± 71.2M      109G  â€¦  109G           0 ( 0%)        0%
  instructions        240G  Â± 48.3M      240G  â€¦  240G           0 ( 0%)        0%
  cache_references   6.42G  Â± 7.31M     6.41G  â€¦ 6.42G           0 ( 0%)        0%
  cache_misses        450M  Â± 1.02M      449G  â€¦  451G           0 ( 0%)        0%
  branch_misses       422M  Â±  783K      421M  â€¦  423M           0 ( 0%)        0%
Benchmark 2 (34 runs): [... long command to build compiler with new compiler ...]
  measurement          mean Â± Ïƒ            min â€¦ max           outliers         delta
  wall_time         10.00s  Â± 32.2ms     9.96s â€¦ 10.0s           0 ( 0%)        âš¡- 27.4% Â±  0.9%
  peak_rss           1.35GB Â± 18.6MB    1.34GB â€¦ 1.37GB          0 ( 0%)        ğŸ’©+ 25.7% Â±  3.9%
  cpu_cycles         95.1G  Â±  371M     94.8G  â€¦ 95.5G           0 ( 0%)        âš¡- 12.8% Â±  0.6%
  instructions        191G  Â± 7.30M      191G  â€¦  191G           0 ( 0%)        âš¡- 20.6% Â±  0.0%
  cache_references   5.93G  Â± 33.3M     5.90G  â€¦ 5.97G           0 ( 0%)        âš¡-  7.5% Â±  0.9%
  cache_misses        417M  Â± 4.55M      412M  â€¦  421M           0 ( 0%)        âš¡-  7.2% Â±  1.7%
  branch_misses       391M  Â±  549K      391M  â€¦  392M           0 ( 0%)        âš¡-  7.3% Â±  0.4%
</code></pre><p>As another data point, I measure a 30% improvement in the time taken to build a simple â€œHello Worldâ€:</p><pre><code>Benchmark 1 (15 runs): /home/mlugg/zig/old-master/build/stage3/bin/zig build-exe hello.zig
  measurement          mean Â± Ïƒ            min â€¦ max           outliers         delta
  wall_time           355ms Â± 4.04ms     349ms â€¦  361ms          0 ( 0%)        0%
  peak_rss            138MB Â±  359KB     138MB â€¦  139MB          0 ( 0%)        0%
  cpu_cycles         1.61G  Â± 16.4M     1.59G  â€¦ 1.65G           0 ( 0%)        0%
  instructions       3.20G  Â± 57.8K     3.20G  â€¦ 3.20G           0 ( 0%)        0%
  cache_references    113M  Â±  450K      112M  â€¦  113M           0 ( 0%)        0%
  cache_misses       10.5M  Â±  122K     10.4M  â€¦ 10.8M           0 ( 0%)        0%
  branch_misses      9.73M  Â± 39.2K     9.67M  â€¦ 9.79M           0 ( 0%)        0%
Benchmark 2 (21 runs): /home/mlugg/zig/master/build/stage3/bin/zig build-exe hello.zig
  measurement          mean Â± Ïƒ            min â€¦ max           outliers         delta
  wall_time           244ms Â± 4.35ms     236ms â€¦  257ms          1 ( 5%)        âš¡- 31.5% Â±  0.8%
  peak_rss            148MB Â±  909KB     146MB â€¦  149MB          2 (10%)        ğŸ’©+  7.3% Â±  0.4%
  cpu_cycles         1.47G  Â± 12.5M     1.45G  â€¦ 1.49G           0 ( 0%)        âš¡-  8.7% Â±  0.6%
  instructions       2.50G  Â±  169K     2.50G  â€¦ 2.50G           1 ( 5%)        âš¡- 22.1% Â±  0.0%
  cache_references    106M  Â±  855K      105M  â€¦  108M           1 ( 5%)        âš¡-  5.6% Â±  0.4%
  cache_misses       9.67M  Â±  145K     9.35M  â€¦ 10.0M           2 (10%)        âš¡-  8.3% Â±  0.9%
  branch_misses      9.23M  Â± 78.5K     9.09M  â€¦ 9.39M           0 ( 0%)        âš¡-  5.1% Â±  0.5%
</code></pre><p>By the way, Iâ€™m a real sucker for some good <code>std.Progress</code> output, so I canâ€™t help but mention how much I enjoy just <em>watching</em> the compiler now, and seeing all the work that itâ€™s doing:</p>
<p>Even with these numbers, weâ€™re still far from done in the area of compiler performance. Future improvements to our self-hosted linkers, as well as in the code which emits a function into the final binary, could help to speed up linking, which is now sometimes the bottleneck of compilation speed (you can actually see this bottleneck in the asciinema above). We also want to <a href="https://github.com/ziglang/zig/issues/24144" target="_blank">improve the quality of the machine code we emit</a>, which not only makes Debug binaries perform better, but (perhaps counterintutively) should further speed up linking. Other performance work on our radar includes decreasing the amount of work the compiler does at the very end of compilation (its â€œflushâ€ phase) to eliminate another big chunk of overhead, and (in the more distant future) parallelizing semantic analysis.</p><p>Perhaps most significantly of all, incremental compilation â€“ which has been a long-term investment of the Zig project for many years â€“ is getting pretty close to being turned on by default in some cases, which will allow small changes to <a href="https://www.youtube.com/clip/Ugkxjn7L0hEfN1XLfH1soaUdCksG3FvJkXIS" target="_blank">rebuild in milliseconds</a>. By the way, remember that you can try out incremental compilation and start reaping its benefits <em>right now</em>, as long as youâ€™re okay with possible compiler bugs! Check out <a href="https://github.com/ziglang/zig/issues/21165" target="_blank">the tracking issue</a> if you want to learn more about that.</p><p>Thatâ€™s enough rambling â€“ I hope yâ€™all are as excited about these improvements as we are. Zigâ€™s compilation speed is the best itâ€™s ever been, and hopefully the worst itâ€™ll ever be again ;)</p>
      </div>
    
      <div id="2025-06-08">
        <p><span>June 08, 2025</span></p>
        <p>Author: Andrew Kelley</p><p>Now, when you target x86_64, by default, Zig will use its own x86 backend rather than using LLVM to lower a bitcode file to an object file.</p><p>The default is not changed on Windows yet, because more COFF linker work needs to be done first.</p><p>The x86 backend is now passing 1987 behavior tests, versus 1980 passed by the LLVM backend. In reality there are 2084 behavior tests, but the extra ones there are generally redundant with LLVMâ€™s own test suite for its own x86 backend, so we only run those when testing with self-hosted x86. Anyway, my point is that Zigâ€™s x86 backend is now <em>more robust</em> than its LLVM backend in terms of implementing the Zig language.</p><p>Why compete with LLVM on code generation? There are <a href="https://ziggit.dev/t/can-someone-explain-why-zig-is-moving-away-from-llvm-but-in-simple-way/1226/6?u=andrewrk" target="_blank">a handful of reasons</a>, but mainly, because we can dramatically outperform LLVM at compilation speed.</p><pre><code>Benchmark 1 (6 runs): zig build-exe hello.zig -fllvm
  measurement          mean Â± Ïƒ            min â€¦ max           outliers         delta
  wall_time           918ms Â± 32.8ms     892ms â€¦  984ms          0 ( 0%)        0%
  peak_rss            214MB Â±  629KB     213MB â€¦  215MB          0 ( 0%)        0%
  cpu_cycles         4.53G  Â± 12.7M     4.52G  â€¦ 4.55G           0 ( 0%)        0%
  instructions       8.50G  Â± 3.27M     8.50G  â€¦ 8.51G           0 ( 0%)        0%
  cache_references    356M  Â± 1.52M      355M  â€¦  359M           0 ( 0%)        0%
  cache_misses       75.6M  Â±  290K     75.3M  â€¦ 76.1M           0 ( 0%)        0%
  branch_misses      42.5M  Â± 49.2K     42.4M  â€¦ 42.5M           0 ( 0%)        0%
Benchmark 2 (19 runs): zig build-exe hello.zig
  measurement          mean Â± Ïƒ            min â€¦ max           outliers         delta
  wall_time           275ms Â± 4.94ms     268ms â€¦  283ms          0 ( 0%)        âš¡- 70.1% Â±  1.7%
  peak_rss            137MB Â±  677KB     135MB â€¦  138MB          0 ( 0%)        âš¡- 36.2% Â±  0.3%
  cpu_cycles         1.57G  Â± 9.60M     1.56G  â€¦ 1.59G           0 ( 0%)        âš¡- 65.2% Â±  0.2%
  instructions       3.21G  Â±  126K     3.21G  â€¦ 3.21G           1 ( 5%)        âš¡- 62.2% Â±  0.0%
  cache_references    112M  Â±  758K      110M  â€¦  113M           0 ( 0%)        âš¡- 68.7% Â±  0.3%
  cache_misses       10.5M  Â±  102K     10.4M  â€¦ 10.8M           1 ( 5%)        âš¡- 86.1% Â±  0.2%
  branch_misses      9.22M  Â± 52.0K     9.14M  â€¦ 9.31M           0 ( 0%)        âš¡- 78.3% Â±  0.1%
</code></pre><p>For a larger project like the Zig compiler itself, it takes the time down from 75 seconds to 20 seconds.</p><p>Weâ€™re <em>only just getting started</em>. Weâ€™ve already started work <a href="https://asciinema.org/a/722533" target="_blank">fully parallelizing code generation</a>. Weâ€™re also just a few linker enhancements and bug fixes away from making incremental compilation stable and robust in combination with this backend. There is still low hanging fruit for improving the generated x86 code quality. And weâ€™re looking at aarch64 next - work that is expected to be accelerated thanks to our new Legalize pass.</p><p>The CI has finished building the respective commit, so you can try this out yourself by fetching the latest master branch build from <a href="https://ziglang.org/download/">the download page</a>.</p><p>Finally, hereâ€™s a gentle reminder that Zig Software Foundation is a 501(c)(3) non-profit that funds its development with donations from generous people like you. If you like what weâ€™re doing, please <a href="https://ziglang.org/zsf/">help keep us financially sustainable</a>!</p>
      </div>
    
      <div id="2025-06-06">
        <p><span>June 06, 2025</span></p>
        <p>Author: Loris Cro</p><p>Iâ€™ve released a few days ago a new video on YouTube where I show how to get started with the Zig build system for those who have not grokked it yet.</p><p>In the video I show how to create a package that exposes a Zig module and then how to import that module in another Zig project. After June I will add more videos to the series in order to cover more of the build system.</p><p>Hereâ€™s the video: <a href="https://youtu.be/jy7w_7JZYyw" target="_blank">https://youtu.be/jy7w_7JZYyw</a></p>
      </div>
    
      <div id="2025-05-20">
        <p><span>May 20, 2025</span></p>
        <p>Author: Alex RÃ¸nne Petersen</p><p>Pull requests <a href="https://github.com/ziglang/zig/pull/23835" target="_blank">#23835</a> and <a href="https://github.com/ziglang/zig/pull/23913" target="_blank">#23913</a> have now been merged. This means that, using <code>zig cc</code> or <code>zig build</code>, you can now build binaries targeting FreeBSD 14.0.0+ and NetBSD 10.1+ from any machine, just as youâ€™ve been able to for Linux, macOS, and Windows for a long time now.</p><p>This builds on the <a href="https://github.com/ziglang/libc-abi-tools" target="_blank">strategy</a> we were already using for glibc and will soon be using for other targets as well. For any given FreeBSD/NetBSD release, we build libc and related libraries for every supported target, and then extract public symbol information from the resulting ELF files. We then combine all that information into a very compact <code>abilists</code> file that gets shipped with Zig. Finally, when the user asks to link libc while cross-compiling, we load the <code>abilists</code> file and build a stub library for each constituent libc library (<code>libc.so</code>, <code>libm.so</code>, etc), making sure that it accurately reflects the symbols provided by libc for the target architecture and OS version, and has the expected <a href="https://en.wikipedia.org/wiki/Soname" target="_blank">soname</a>. This is all quite similar to how the <a href="https://llvm.org/docs/CommandGuide/llvm-ifs.html" target="_blank">llvm-ifs tool</a> works.</p><p>We currently import <a href="https://en.wikipedia.org/wiki/Crt0" target="_blank">crt0</a> code from the latest known FreeBSD/NetBSD release and manually apply any patches needed to make it work with any OS version that we support cross-compilation to. This is necessary because the OS sometimes changes the crt0 ABI. Weâ€™d like to eventually <a href="https://github.com/ziglang/zig/issues/23875" target="_blank">reimplement the crt0 code in Zig</a>.</p><p>We also ship FreeBSD/NetBSD system and libc headers with the Zig compiler. Unlike the stub libraries we produce, however, we always import headers from the latest version of the OS. This is because it would be far too space-inefficient to ship separate headers for every OS version, and we realistically donâ€™t have the time to audit the headers on every import and add appropriate version guards to all new declarations. The good news, though, is that we do accept patches to add version guards when necessary; weâ€™ve already had many contributions of this sort in our imported glibc headers.</p><p>Please take this for a spin and report any bugs you find!</p><p>We would like to also add support for <a href="https://github.com/ziglang/zig/issues/2878" target="_blank">OpenBSD libc</a> and <a href="https://github.com/ziglang/zig/issues/23880" target="_blank">Dragonfly BSD libc</a>, but because these BSDs cannot be conveniently cross-compiled from Linux, we need motivated users of them to chip in. Besides those, we are also looking into <a href="https://github.com/ziglang/zig/issues/23879" target="_blank">SerenityOS</a>, <a href="https://github.com/ziglang/zig/issues/23906" target="_blank">Android</a>, and <a href="https://github.com/ziglang/zig/issues/23877" target="_blank">Fuchsia</a> libc support.</p>
      </div>
    
      <div id="2025-04-09">
        <p><span>April 09, 2025</span></p>
        <p>Author: Loris Cro</p><p>The official Zig website now builds using standalone Zine. A lot of code got rewritten so if you see regressions on the website, please open an issue. Regressions only please, thanks!</p><p>Normally a Zine update would not be worthy of a devlog entry, but the recent update to it was pretty big as Zine went from being a funky Zig build script to a standalone executable. If you were interested in Zine before but never got the time to try it out, this milestone is a great moment to <a href="https://zine-ssg.io" target="_blank">give it a shot</a>. Run <code>zine init</code> to get a sample website that also implements a devlog for you out of the box.</p><p>P.S. Iâ€™ve also added dates to each entry on the page, people were asking for this for a while :^)</p>
      </div>
    
      <div id="2025-03-03">
        <p><span>March 03, 2025</span></p>
        <p>The 0.14.0 release is coming shortly. We didnâ€™t get the release notes done yet, and Iâ€™m calling it a day.</p><p>Tomorrow morning Iâ€™ll make the tag, kick off the CI, and then work to finish the release notes while it builds.</p><p>I know there were a lot of things that sadly didnâ€™t make the cut. Letâ€™s try to get them into 0.14.1 or 0.15.0. Meanwhile, there are a ton of major and minor enhancements that have already landed, and will debut tomorrow.</p>
      </div>
    
      <div id="2025-02-24">
        <p><span>February 24, 2025</span></p>
        <p>Author: David Rubin</p><p>Lately, Iâ€™ve been extensively working with C interop, and one thing thatâ€™s been sorely missing is clear error messages from UBSan. When compiling C with <code>zig cc</code>, Zig provides better defaults, including implicitly enabling <code>-fsanitize=undefined</code>. This has been great for catching subtle bugs and makes working with C more bearable. However, due to the lack of a UBSan runtime, all undefined behavior was previously caught with a <code>trap</code> instruction.</p><p>For example, consider this example C program:</p><pre><code><span>#include</span> <span>&lt;stdio.h&gt;</span>

<span>int</span> <span>foo</span>(<span>int</span> <span>x</span>, <span>int</span> <span>y</span>) {
    <span>return</span> <span>x</span> <span>+</span> <span>y</span><span>;</span>
}

<span>int</span> <span>main</span>() {
    <span>int</span> <span>result</span> <span>=</span> <span>foo</span>(<span>0x7fffffff</span>, <span>0x7fffffff</span>)<span>;</span>
    <span>printf</span>(<span>&#34;%d\n&#34;</span>, <span>result</span>)<span>;</span>
}
</code></pre>
<p>Running this with <code>zig cc</code> used to result in an unhelpful error:</p><pre><code>$ zig run test.c -lc
fish: Job 1, &#39;zig run empty.c -lc&#39; terminated by signal SIGILL (Illegal instruction)
</code></pre><p>Not exactly informative! To understand what went wrong, youâ€™d have to run the executable in a debugger. Even then, tracking down the root cause could be daunting. Many newcomers ran into this <code>Illegal instruction</code> error without realizing that UBSan was enabled by default, leading to confusion. This issue was common enough to warrant a dedicated <a href="https://github.com/ziglang/zig/wiki/zig-cc-compatibility-with-clang#ubsan-and-sigill-illegal-instruction" target="_blank">Wiki page</a>.</p><p>With the new <a href="https://github.com/ziglang/zig/pull/22488" target="_blank">UBSan runtime merged</a>, the experience has completely changed. Now instead of an obscure <code>SIGILL</code>, you get a much more helpful error message:</p><pre><code>$ zig run test.c -lc
thread 208135 panic: signed integer overflow: 2147483647 + 2147483647 cannot be represented in type &#39;int&#39;
/home/david/Code/zig/build/test.c:4:14: 0x1013e41 in foo (test.c)
    return x + y;
             ^
/home/david/Code/zig/build/test.c:8:18: 0x1013e63 in main (test.c)
    int result = foo(0x7fffffff, 0x7fffffff);
                 ^
../sysdeps/nptl/libc_start_call_main.h:58:16: 0x7fca4c42e1c9 in __libc_start_call_main (../sysdeps/x86/libc-start.c)
../csu/libc-start.c:360:3: 0x7fca4c42e28a in __libc_start_main_impl (../sysdeps/x86/libc-start.c)
???:?:?: 0x1013de4 in ??? (???)
???:?:?: 0x0 in ??? (???)
fish: Job 1, &#39;zig run test.c -lc&#39; terminated by signal SIGABRT (Abort)
</code></pre><p>Now, not only do we see <em>what</em> went wrong (signed integer overflow), but we also see <em>where</em> it happened â€“ two critical pieces of information that were previously missing.</p><h2>Remaining Limitations</h2><p>While the new runtime vastly improves debugging, there are still two features that LLVMâ€™s UBSan runtime provides which ours doesnâ€™t support yet:</p><ol><li>In C++, UBSan can detect when an objectâ€™s vptr indicates the wrong dynamic type or when its lifetime hasnâ€™t started. Supporting this would require replicating the Itanium C++ ABI, which isnâ€™t worth the extreme complexity.</li><li>Currently, the runtime doesnâ€™t show the exact locations of attributes like <code>assume_aligned</code> and <code>__nonnull</code>. This should be relatively straightforward to add, and contributions are welcome!</li></ol><p>If youâ€™ve ever been frustrated by cryptic <code>SIGILL</code> errors while trying out Zig, this update should make debugging undefined behavior a lot easier!</p>
      </div>
    
      <div id="2025-02-07">
        <p><span>February 07, 2025</span></p>
        <p>Author: Andrew Kelley</p><p>Alright, I know Iâ€™m supposed to be focused on issue triage and merging PRs for the upcoming release this month, but in my defense, I do some of my best work while procrastinating.</p><p>Jokes aside, this week we had CI failures due to Zigâ€™s debug allocator creating too many memory mappings. This was interfering with Jacobâ€™s work on the x86 backend, so I spent the time to <a href="https://github.com/ziglang/zig/pull/20511#issuecomment-2638356298" target="_blank">rework the debug allocator</a>.</p><p>Since this was a chance to eliminate the dependency on a compile-time known page size, I based my work on contributor archbirdplusâ€™s patch to add runtime-known page size support to the Zig standard library. With this change landed, it means Zig finally works on Asahi Linux. My fault for originally making page size compile-time known. Sorry about that!</p><p>Along with detecting page size at runtime, the new implementation no longer memsets each page to 0xaa bytes then back to 0x00 bytes, no longer searches when freeing, and no longer depends on a treap data structure. Instead, the allocation metadata is stored inline, on the page, using a pre-cached lookup table that is computed at compile-time:</p><pre><code>
<span>fn</span> <span>calculateSlotCount</span><span>(</span><span>size_class_index</span><span>:</span> <span>usize</span><span>)</span> <span>SlotIndex</span> <span>{</span>
    <span>const</span> <span>size_class</span> <span>=</span> <span>@as</span><span>(</span><span>usize</span><span>,</span> <span>1</span><span>)</span> <span>&lt;&lt;</span> <span>@as</span><span>(</span><span>Log2USize</span><span>,</span> <span>@intCast</span><span>(</span><span>size_class_index</span><span>)</span><span>)</span><span>;</span>
    <span>var</span> <span>lower</span><span>:</span> <span>usize</span> <span>=</span> <span>1</span> <span>&lt;&lt;</span> <span>minimum_slots_per_bucket_log2</span><span>;</span>
    <span>var</span> <span>upper</span><span>:</span> <span>usize</span> <span>=</span> <span>(</span><span>page_size</span> <span>-</span> <span>bucketSize</span><span>(</span><span>lower</span><span>)</span><span>)</span> <span>/</span> <span>size_class</span><span>;</span>
    <span>while</span> <span>(</span><span>upper</span> <span>&gt;</span> <span>lower</span><span>)</span> <span>{</span>
        <span>const</span> <span>proposed</span><span>:</span> <span>usize</span> <span>=</span> <span>lower</span> <span>+</span> <span>(</span><span>upper</span> <span>-</span> <span>lower</span><span>)</span> <span>/</span> <span>2</span><span>;</span>
        <span>if</span> <span>(</span><span>proposed</span> <span>==</span> <span>lower</span><span>)</span> <span>return</span> <span>lower</span><span>;</span>
        <span>const</span> <span>slots_end</span> <span>=</span> <span>proposed</span> <span>*</span> <span>size_class</span><span>;</span>
        <span>const</span> <span>header_begin</span> <span>=</span> <span>mem</span><span>.</span><span>alignForward</span><span>(</span><span>usize</span><span>,</span> <span>slots_end</span><span>,</span> <span>@alignOf</span><span>(</span><span>BucketHeader</span><span>)</span><span>)</span><span>;</span>
        <span>const</span> <span>end</span> <span>=</span> <span>header_begin</span> <span>+</span> <span>bucketSize</span><span>(</span><span>proposed</span><span>)</span><span>;</span>
        <span>if</span> <span>(</span><span>end</span> <span>&gt;</span> <span>page_size</span><span>)</span> <span>{</span>
            <span>upper</span> <span>=</span> <span>proposed</span> <span>-</span> <span>1</span><span>;</span>
        <span>}</span> <span>else</span> <span>{</span>
            <span>lower</span> <span>=</span> <span>proposed</span><span>;</span>
        <span>}</span>
    <span>}</span>
    <span>const</span> <span>slots_end</span> <span>=</span> <span>lower</span> <span>*</span> <span>size_class</span><span>;</span>
    <span>const</span> <span>header_begin</span> <span>=</span> <span>mem</span><span>.</span><span>alignForward</span><span>(</span><span>usize</span><span>,</span> <span>slots_end</span><span>,</span> <span>@alignOf</span><span>(</span><span>BucketHeader</span><span>)</span><span>)</span><span>;</span>
    <span>const</span> <span>end</span> <span>=</span> <span>header_begin</span> <span>+</span> <span>bucketSize</span><span>(</span><span>lower</span><span>)</span><span>;</span>
    <span>assert</span><span>(</span><span>end</span> <span>&lt;=</span> <span>page_size</span><span>)</span><span>;</span>
    <span>return</span> <span>lower</span><span>;</span>
<span>}</span>
</code></pre>
<p>Itâ€™s pretty nice because you can tweak some global constants and then get optimal slot sizes. That assert at the end means if the constraints could not be satisfied you get a compile error. Meanwhile in C land, equivalent code has to resort to handcrafted lookup tables. Just look at the top of malloc.c from musl:</p><pre><code><span>const</span> <span>uint16_t</span> <span>size_classes</span>[] <span>=</span> {
	<span>1</span>, <span>2</span>, <span>3</span>, <span>4</span>, <span>5</span>, <span>6</span>, <span>7</span>, <span>8</span>,
	<span>9</span>, <span>10</span>, <span>12</span>, <span>15</span>,
	<span>18</span>, <span>20</span>, <span>25</span>, <span>31</span>,
	<span>36</span>, <span>42</span>, <span>50</span>, <span>63</span>,
	<span>72</span>, <span>84</span>, <span>102</span>, <span>127</span>,
	<span>146</span>, <span>170</span>, <span>204</span>, <span>255</span>,
	<span>292</span>, <span>340</span>, <span>409</span>, <span>511</span>,
	<span>584</span>, <span>682</span>, <span>818</span>, <span>1023</span>,
	<span>1169</span>, <span>1364</span>, <span>1637</span>, <span>2047</span>,
	<span>2340</span>, <span>2730</span>, <span>3276</span>, <span>4095</span>,
	<span>4680</span>, <span>5460</span>, <span>6552</span>, <span>8191</span>,
}<span>;</span>
</code></pre>
<p>Not nearly as nice to experiment with different size classes. The waterâ€™s warm, Rich, come on in! ğŸ˜›</p><p>Anyway, as a result of reworking this allocator, not only does it work with runtime-known page size, and avoid creating too many memory mappings, it also performs significantly better than before. The motivating test case for these changes was this degenerate ast-check task, with a debug compiler:</p><pre><code>Benchmark 1 (3 runs): master/bin/zig ast-check ../lib/compiler_rt/udivmodti4_test.zig
  measurement          mean Â± Ïƒ            min â€¦ max           outliers         delta
  wall_time          22.8s  Â±  184ms    22.6s  â€¦ 22.9s           0 ( 0%)        0%
  peak_rss           58.6MB Â± 77.5KB    58.5MB â€¦ 58.6MB          0 ( 0%)        0%
  cpu_cycles         38.1G  Â± 84.7M     38.0G  â€¦ 38.2G           0 ( 0%)        0%
  instructions       27.7G  Â± 16.6K     27.7G  â€¦ 27.7G           0 ( 0%)        0%
  cache_references   1.08G  Â± 4.40M     1.07G  â€¦ 1.08G           0 ( 0%)        0%
  cache_misses       7.54M  Â± 1.39M     6.51M  â€¦ 9.12M           0 ( 0%)        0%
  branch_misses       165M  Â±  454K      165M  â€¦  166M           0 ( 0%)        0%
Benchmark 2 (3 runs): branch/bin/zig ast-check ../lib/compiler_rt/udivmodti4_test.zig
  measurement          mean Â± Ïƒ            min â€¦ max           outliers         delta
  wall_time          20.5s  Â± 95.8ms    20.4s  â€¦ 20.6s           0 ( 0%)        âš¡- 10.1% Â±  1.5%
  peak_rss           54.9MB Â±  303KB    54.6MB â€¦ 55.1MB          0 ( 0%)        âš¡-  6.2% Â±  0.9%
  cpu_cycles         34.8G  Â± 85.2M     34.7G  â€¦ 34.9G           0 ( 0%)        âš¡-  8.6% Â±  0.5%
  instructions       25.2G  Â± 2.21M     25.2G  â€¦ 25.2G           0 ( 0%)        âš¡-  8.8% Â±  0.0%
  cache_references   1.02G  Â±  195M      902M  â€¦ 1.24G           0 ( 0%)          -  5.8% Â± 29.0%
  cache_misses       4.57M  Â±  934K     3.93M  â€¦ 5.64M           0 ( 0%)        âš¡- 39.4% Â± 35.6%
  branch_misses       142M  Â±  183K      142M  â€¦  142M           0 ( 0%)        âš¡- 14.1% Â±  0.5%
</code></pre><p>I didnâ€™t stop there, however. Even though I had release tasks to get back to, this left me <em>itching</em> to make a fast allocator - one that was designed for multi-threaded applications built in ReleaseFast mode.</p><p>Itâ€™s a tricky problem. A fast allocator needs to avoid contention by storing thread-local state, however, it does not directly learn when a thread exits, so one thread must periodically attempt to reclaim another threadâ€™s resources. There is also the producer-consumer pattern - one thread only allocates while one thread only frees. A naive implementation would never reclaim this memory.</p><p>Inspiration struck, and <a href="https://github.com/ziglang/zig/blob/42dbd35d3e16247ee68d7e3ace0da3778a1f5d37/lib/std/heap/SmpAllocator.zig" target="_blank">200 lines of code later</a> I had a working implementationâ€¦ after Jacob helped me find a couple logic bugs.</p><p>I created <a href="https://github.com/andrewrk/CarmensPlayground" target="_blank">Where in the World Did Carmenâ€™s Memory Go?</a> and used it to test a couple specific usage patterns. Idea here is to over time collect a robust test suite, do fuzzing, benchmarking, etc., to make it easier to try out new Allocator ideas in Zig.</p><p>After getting good scores on those contrived tests, I turned to the real world use cases of the Zig compiler itself. Since it can be built with and without libc, itâ€™s a great way to test the performance delta between the two.</p><p>Hereâ€™s that same degenerate case above, but with a release build of the compiler - glibc zig vs no libc zig:</p><pre><code>Benchmark 1 (32 runs): glibc/bin/zig ast-check ../lib/compiler_rt/udivmodti4_test.zig
  measurement          mean Â± Ïƒ            min â€¦ max           outliers         delta
  wall_time           156ms Â± 6.58ms     151ms â€¦  173ms          4 (13%)        0%
  peak_rss           45.0MB Â± 20.9KB    45.0MB â€¦ 45.1MB          1 ( 3%)        0%
  cpu_cycles          766M  Â± 10.2M      754M  â€¦  796M           0 ( 0%)        0%
  instructions       3.19G  Â± 12.7      3.19G  â€¦ 3.19G           0 ( 0%)        0%
  cache_references   4.12M  Â±  498K     3.88M  â€¦ 6.13M           3 ( 9%)        0%
  cache_misses        128K  Â± 2.42K      125K  â€¦  134K           0 ( 0%)        0%
  branch_misses      1.14M  Â±  215K      925K  â€¦ 1.43M           0 ( 0%)        0%
Benchmark 2 (34 runs): SmpAllocator/bin/zig ast-check ../lib/compiler_rt/udivmodti4_test.zig
  measurement          mean Â± Ïƒ            min â€¦ max           outliers         delta
  wall_time           149ms Â± 1.87ms     146ms â€¦  156ms          1 ( 3%)        âš¡-  4.9% Â±  1.5%
  peak_rss           39.6MB Â±  141KB    38.8MB â€¦ 39.6MB          2 ( 6%)        âš¡- 12.1% Â±  0.1%
  cpu_cycles          750M  Â± 3.77M      744M  â€¦  756M           0 ( 0%)        âš¡-  2.1% Â±  0.5%
  instructions       3.05G  Â± 11.5      3.05G  â€¦ 3.05G           0 ( 0%)        âš¡-  4.5% Â±  0.0%
  cache_references   2.94M  Â± 99.2K     2.88M  â€¦ 3.36M           4 (12%)        âš¡- 28.7% Â±  4.2%
  cache_misses       48.2K  Â± 1.07K     45.6K  â€¦ 52.1K           2 ( 6%)        âš¡- 62.4% Â±  0.7%
  branch_misses       890K  Â± 28.8K      862K  â€¦ 1.02M           2 ( 6%)        âš¡- 21.8% Â±  6.5%
</code></pre><p>Outperforming glibc!</p><p>And finally hereâ€™s the entire compiler building itself:</p><pre><code>Benchmark 1 (3 runs): glibc/bin/zig build -Dno-lib -p trash
  measurement          mean Â± Ïƒ            min â€¦ max           outliers         delta
  wall_time          12.2s  Â± 99.4ms    12.1s  â€¦ 12.3s           0 ( 0%)        0%
  peak_rss            975MB Â± 21.7MB     951MB â€¦  993MB          0 ( 0%)        0%
  cpu_cycles         88.7G  Â± 68.3M     88.7G  â€¦ 88.8G           0 ( 0%)        0%
  instructions        188G  Â± 1.40M      188G  â€¦  188G           0 ( 0%)        0%
  cache_references   5.88G  Â± 33.2M     5.84G  â€¦ 5.90G           0 ( 0%)        0%
  cache_misses        383M  Â± 2.26M      381M  â€¦  385M           0 ( 0%)        0%
  branch_misses       368M  Â± 1.77M      366M  â€¦  369M           0 ( 0%)        0%
Benchmark 2 (3 runs): SmpAllocator/fast/bin/zig build -Dno-lib -p trash
  measurement          mean Â± Ïƒ            min â€¦ max           outliers         delta
  wall_time          12.2s  Â± 49.0ms    12.2s  â€¦ 12.3s           0 ( 0%)          +  0.0% Â±  1.5%
  peak_rss            953MB Â± 3.47MB     950MB â€¦  957MB          0 ( 0%)          -  2.2% Â±  3.6%
  cpu_cycles         88.4G  Â±  165M     88.2G  â€¦ 88.6G           0 ( 0%)          -  0.4% Â±  0.3%
  instructions        181G  Â± 6.31M      181G  â€¦  181G           0 ( 0%)        âš¡-  3.9% Â±  0.0%
  cache_references   5.48G  Â± 17.5M     5.46G  â€¦ 5.50G           0 ( 0%)        âš¡-  6.9% Â±  1.0%
  cache_misses        386M  Â± 1.85M      384M  â€¦  388M           0 ( 0%)          +  0.6% Â±  1.2%
  branch_misses       377M  Â±  899K      377M  â€¦  378M           0 ( 0%)        ğŸ’©+  2.6% Â±  0.9%
</code></pre><p>I feel that this is a key moment in the Zig projectâ€™s trajectory. <a href="https://github.com/ziglang/zig/pull/22808" target="_blank">This last piece of the puzzle</a> marks the point at which the language and standard library has become <em>strictly better</em> to use than C and libc.</p><p>While other languages build on top of libc, Zig instead has conquered it!</p>
      </div>
    
      <div id="2025-01-24">
        <p><span>January 24, 2025</span></p>
        <p>Author: Alex RÃ¸nne Petersen</p><p>One of the major things <a href="https://github.com/jacobly0" target="_blank">Jacob</a> has been working on is good debugging support for Zig. This includes an <a href="https://github.com/jacobly0/llvm-project/tree/lldb-zig" target="_blank">LLDB fork</a> with enhancements for the Zig language, and is primarily intended for use with Zigâ€™s self-hosted backends. With the self-hosted x86_64 backend becoming much more usable in the upcoming 0.14.0 release, I decided to type up a <a href="https://github.com/ziglang/zig/wiki/LLDB-for-Zig" target="_blank">wiki page</a> with instructions for building and using the fork.</p><p>If youâ€™re already trying out Zigâ€™s self-hosted backend in your workflow, please take the LLDB fork for a spin and see how it works for you.</p>
      </div>
    </div></div>
  </body>
</html>
