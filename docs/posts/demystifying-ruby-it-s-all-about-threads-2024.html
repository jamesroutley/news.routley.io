<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.papey.fr/post/07-demystifying-ruby-01/">Original</a>
    <h1>Demystifying Ruby: It&#39;s all about threads (2024)</h1>
    
    <div id="readability-page-1" class="page"><div role="main">
  <div>
    <div>
      <article role="main">
        <p><a href="https://www.ruby-lang.org">Ruby</a> is a dynamic, <strong>interpreted</strong>, open-source programming language known for its simplicity, productivity, and its ‚Äúhuman-readable‚Äù syntax. Ruby is often used in web development, particularly with the <a href="https://rubyonrails.org/">Ruby on Rails</a> framework. It supports object-oriented, functional, and imperative programming paradigms.</p>
<p>The most known and used Ruby Virtual Machine is the <strong>M</strong>atz <strong>R</strong>uby <strong>I</strong>nterpreter (aka CRuby), developed by <a href="https://en.wikipedia.org/wiki/Yukihiro_Matsumoto">Yukihiro Matsumoto</a> (aka Matz), the creator of Ruby. All other Ruby implementation such as <a href="https://www.jruby.org/">JRuby</a>, <a href="https://github.com/oracle/truffleruby">TruffleRuby</a> and so on are out of the scope of this blog post.</p>
<p>The <strong>MRI</strong> implements the <strong>G</strong>lobal <strong>I</strong>nterpreter <strong>L</strong>ock, a mechanism to ensure that one and only one thread runs at the same time effectively limiting <strong>true parallelism</strong>. Reading between the lines, one can understand that Ruby <strong>is multi-threaded</strong>, but with a <strong>parallelism limit of 1</strong> (or maybe more üëÄ).</p>
<p>Many popular Gems such as <a href="https://github.com/puma/puma">Puma</a>, <a href="https://github.com/sidekiq/sidekiq">Sidekiq</a>, <a href="https://github.com/rails/rails">Rails</a>, <a href="https://github.com/getsentry/sentry-ruby">Sentry</a> are multi-threaded</p>
<h2 id="process--ractor--threads--and-fibers-">Process üíé, Ractor ü¶ñ, Threads üßµ and Fibers üåΩ</h2>
<p>Here‚Äôs an overview of all the intricated layers in Ruby that deal with concurrency and parallelism (<a href="https://go.dev/blog/waza-talk">and yes they are not the same thing</a>). Let‚Äôs explore each of them in depth.</p>
<p><a href="https://mermaid.live/edit#pako:eNp90T1rwzAQBuC_Ii6LA_bQuos1FGKblkKH0GbUIkunWlS2jD5oQsh_r5q4JKE0mg7pfY5DtwdhJQKFD8ennmxaNpJ0VhmDtbMCvSfZmjtuDBrthyWDJSmKR1KnwBsXwbo_76cO9THWpNimd8glyRo7iugcjiEnHQoePRKrSOiRPL-8nmVzlG2ST7pDdwnPIR92BsmKKG0MXahK5T44-4l0UZblXBdfWoaePkzbS1PPputumPLaNLOpVPW_ub827e9st8zdtIUcBnQD1zJtYf_TgUH6kwEZ0FRKVDyawICNhxTlMdj33SiABhcxhzhJHrDVPO1vOF0evgGmupYU"><img src="https://mermaid.ink/img/pako:eNp90T1rwzAQBuC_Ii6LA_bQuos1FGKblkKH0GbUIkunWlS2jD5oQsh_r5q4JKE0mg7pfY5DtwdhJQKFD8ennmxaNpJ0VhmDtbMCvSfZmjtuDBrthyWDJSmKR1KnwBsXwbo_76cO9THWpNimd8glyRo7iugcjiEnHQoePRKrSOiRPL-8nmVzlG2ST7pDdwnPIR92BsmKKG0MXahK5T44-4l0UZblXBdfWoaePkzbS1PPputumPLaNLOpVPW_ub827e9st8zdtIUcBnQD1zJtYf_TgUH6kwEZ0FRKVDyawICNhxTlMdj33SiABhcxhzhJHrDVPO1vOF0evgGmupYU?type=png" alt=""/></a></p>
<p><a href="https://youtu.be/GJfsbhJY8gk">You‚Äôre inside a simulation of a simulation‚Ä¶inside another giant simulation! <em>laughs harder</em></a></p>
<p>By default, all this nested structure exist in the most simple Ruby program you can think of.</p>
<p>I need you to trust me, so here is a proof :</p>
<div><pre tabindex="0"><code data-lang="ruby"><span><span><span>#!/usr/bin/env ruby</span>
</span></span><span><span>
</span></span><span><span><span># Print the current Process ID</span>
</span></span><span><span><span>puts</span> <span>&#34;Current Process ID: </span><span>#{</span><span>Process</span><span>.</span><span>pid</span><span>}</span><span>&#34;</span>
</span></span><span><span>
</span></span><span><span><span># Ractor</span>
</span></span><span><span><span>puts</span> <span>&#34;Current Ractor: </span><span>#{</span><span>Ractor</span><span>.</span><span>current</span><span>}</span><span>&#34;</span>
</span></span><span><span>
</span></span><span><span><span># Print the current Thread</span>
</span></span><span><span><span>puts</span> <span>&#34;Current Thread: </span><span>#{</span><span>Thread</span><span>.</span><span>current</span><span>}</span><span>&#34;</span>
</span></span><span><span>
</span></span><span><span><span># Print the current Fiber</span>
</span></span><span><span><span>puts</span> <span>&#34;Current Fiber: </span><span>#{</span><span>Fiber</span><span>.</span><span>current</span><span>}</span><span>&#34;</span>
</span></span></code></pre></div><pre tabindex="0"><code>Current Process ID: 6608
Current Ractor: #&lt;Ractor:#1 running&gt;
Current Thread: #&lt;Thread:0x00000001010db270 run&gt;
Current Fiber: #&lt;Fiber:0x00000001012f3ee0 (resumed)&gt;
</code></pre><p>Every piece of Ruby code runs in a Fiber, that runs in a Thread, that runs in a Ractor, that runs in a Process</p>
<h3 id="process-">Process üíé</h3>
<p>This one is probably the easier to understand. Your computer is running many processes in parallel for example : your window manager and the web browser you are using right now are two processes that runs in parallel.</p>
<p>So to run Ruby processes in parallel, you can just open two terminal windows and run one program in each and voil√† (or you can also run <code>fork</code> in your program).</p>
<p>In this case, scheduling is orchestrated by the Operating System, memory is isolated between process A and process B (like, you don‚Äôt want Word to have access to your browser memory ?)</p>
<p>If you want to pass data from process A to process B, you need interprocessus communication mechanisms such as pipes, queues, sockets, signals or more trivial stuff like a shared file where one read and the other write (beware of race-condition then!)</p>
<h3 id="ractor-">Ractor ü¶ñ</h3>
<p>Ractors are a new, experimental feature designed to achieve parallel execution within a Ruby program. Managed by the VM (and not the Operating System), Ractors use native threads under the hood to run in paralllel. Each Ractor behaves like an independent virtual machine (VM) inside the same Ruby process, with its own isolated memory. ‚ÄúRactor‚Äù stands for ‚ÄúRuby Actors,‚Äù and, as in the Actor model, Ractors communicate by passing messages to exchange data without the need for shared memory, avoiding the <code>Mutex</code> approach. Each Ractor has its own GIL, allowing them to run independently without interference from other Ractors.</p>
<p>In summary, Ractors offer a model for true parallelism where memory isolation prevents race conditions, and message-passing provides a structured and safe way for Ractors to interact, enabling efficient parallel execution in Ruby.</p>
<p>Lets try it !<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup></p>
<div><pre tabindex="0"><code data-lang="ruby"><span><span><span>require</span> <span>&#39;time&#39;</span>
</span></span><span><span>
</span></span><span><span><span># `sleep` used here is not really CPU bound but it‚Äôs used to simplify the example</span>
</span></span><span><span><span>def</span> <span>cpu_bound_task</span><span>()</span>
</span></span><span><span>  <span>sleep</span><span>(</span><span>2</span><span>)</span>
</span></span><span><span><span>end</span>
</span></span><span><span>
</span></span><span><span><span># Divide a large range into smaller chunks</span>
</span></span><span><span><span>ranges</span> <span>=</span> <span>[</span>
</span></span><span><span>  <span>(</span><span>1</span><span>..</span><span>25_000</span><span>),</span>
</span></span><span><span>  <span>(</span><span>25_001</span><span>..</span><span>50_000</span><span>),</span>
</span></span><span><span>  <span>(</span><span>50_001</span><span>..</span><span>75_000</span><span>),</span>
</span></span><span><span>  <span>(</span><span>75_001</span><span>..</span><span>100_000</span><span>)</span>
</span></span><span><span><span>]</span>
</span></span><span><span>
</span></span><span><span><span># Start timing</span>
</span></span><span><span><span>start_time</span> <span>=</span> <span>Time</span><span>.</span><span>now</span>
</span></span><span><span>
</span></span><span><span><span># Create Ractors to calculate the sum in parallel with delays</span>
</span></span><span><span><span>ractors</span> <span>=</span> <span>ranges</span><span>.</span><span>map</span> <span>do</span> <span>|</span><span>range</span><span>|</span>
</span></span><span><span>  <span>Ractor</span><span>.</span><span>new</span><span>(</span><span>range</span><span>)</span> <span>do</span> <span>|</span><span>r</span><span>|</span>
</span></span><span><span>    <span>cpu_bound_task</span><span>()</span>
</span></span><span><span>    <span>r</span><span>.</span><span>sum</span>
</span></span><span><span>  <span>end</span>
</span></span><span><span><span>end</span>
</span></span><span><span>
</span></span><span><span><span># Collect results from all Ractors</span>
</span></span><span><span><span>sum</span> <span>=</span> <span>ractors</span><span>.</span><span>sum</span><span>(</span><span>&amp;</span><span>:take</span><span>)</span>
</span></span><span><span>
</span></span><span><span><span># End timing</span>
</span></span><span><span><span>end_time</span> <span>=</span> <span>Time</span><span>.</span><span>now</span>
</span></span><span><span>
</span></span><span><span><span># Calculate and display total execution time</span>
</span></span><span><span><span>execution_time</span> <span>=</span> <span>end_time</span> <span>-</span> <span>start_time</span>
</span></span><span><span><span>puts</span> <span>&#34;Total sum: </span><span>#{</span><span>sum</span><span>}</span><span>&#34;</span>
</span></span><span><span><span>puts</span> <span>&#34;Parallel Execution time: </span><span>#{</span><span>execution_time</span><span>}</span><span> seconds&#34;</span>
</span></span><span><span>
</span></span><span><span><span># Start timing</span>
</span></span><span><span><span>start_time</span> <span>=</span> <span>Time</span><span>.</span><span>now</span>
</span></span><span><span>
</span></span><span><span><span>sum</span> <span>=</span> <span>ranges</span><span>.</span><span>sum</span> <span>do</span> <span>|</span><span>range</span><span>|</span>
</span></span><span><span>  <span>cpu_bound_task</span><span>()</span>
</span></span><span><span>  <span>range</span><span>.</span><span>sum</span>
</span></span><span><span><span>end</span>
</span></span><span><span>
</span></span><span><span><span># End timing</span>
</span></span><span><span><span>end_time</span> <span>=</span> <span>Time</span><span>.</span><span>now</span>
</span></span><span><span>
</span></span><span><span><span># Calculate and display total execution time</span>
</span></span><span><span><span>execution_time</span> <span>=</span> <span>end_time</span> <span>-</span> <span>start_time</span>
</span></span><span><span>
</span></span><span><span><span>puts</span> <span>&#34;Total sum: </span><span>#{</span><span>sum</span><span>}</span><span>&#34;</span>
</span></span><span><span><span>puts</span> <span>&#34;Sequential Execution time: </span><span>#{</span><span>execution_time</span><span>}</span><span> seconds&#34;</span>
</span></span></code></pre></div><pre tabindex="0"><code>warning: Ractor is experimental, and the behavior may change in future versions of Ruby! Also there are many implementation issues.
Total sum: 5000050000
Parallel Execution time: 2.005622 seconds
Total sum: 5000050000
Sequential Execution time: 8.016461 seconds
</code></pre><p><strong>And here is the proof that Ractors run in parallel.</strong></p>
<p>As I said earlier they are fairly experimental and not used in many Gems nor code you might see.</p>
<p><strong>The are really here to distribute intensive CPU bound tasks to all you CPU cores.</strong></p>
<h3 id="thread-">Thread üßµ</h3>
<p>The key difference between OS threads and Ruby threads lies in how they handle concurrency and resource management. OS threads are managed by the operating system, allowing them to run in parallel across multiple CPU cores, making them more resource-intensive but enabling true parallelism. In contrast, Ruby threads‚Äîespecially in MRI Ruby‚Äîare managed by the interpreter and restricted by the <strong>G</strong>lobal <strong>I</strong>nterpreter <strong>L</strong>ock (<strong>GIL</strong>), meaning only one thread can execute Ruby code at a time, limiting them to concurrency without true parallelism. This makes Ruby threads lightweight (also known as ‚ÄúGreen Threads‚Äù) but unable to fully utilize multicore systems (as opposed to Ractor that allow multiple ‚ÄúRuby VM‚Äù to run in the same process).</p>
<p>Let‚Äôs take a look at this code snippet that uses threads :</p>
<div><pre tabindex="0"><code data-lang="ruby"><span><span><span>require</span> <span>&#39;time&#39;</span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>slow</span><span>(</span><span>name</span><span>,</span> <span>duration</span><span>)</span>
</span></span><span><span>  <span>puts</span> <span>&#34;</span><span>#{</span><span>name</span><span>}</span><span> start - </span><span>#{</span><span>Time</span><span>.</span><span>now</span><span>.</span><span>strftime</span><span>(</span><span>&#39;%H:%M:%S&#39;</span><span>)</span><span>}</span><span>&#34;</span>
</span></span><span><span>  <span>sleep</span><span>(</span><span>duration</span><span>)</span>
</span></span><span><span>  <span>puts</span> <span>&#34;</span><span>#{</span><span>name</span><span>}</span><span> end - </span><span>#{</span><span>Time</span><span>.</span><span>now</span><span>.</span><span>strftime</span><span>(</span><span>&#39;%H:%M:%S&#39;</span><span>)</span><span>}</span><span>&#34;</span>
</span></span><span><span><span>end</span>
</span></span><span><span>
</span></span><span><span><span>puts</span> <span>&#39;no threads&#39;</span>
</span></span><span><span><span>start_time</span> <span>=</span> <span>Time</span><span>.</span><span>now</span>
</span></span><span><span><span>slow</span><span>(</span><span>&#39;1&#39;</span><span>,</span> <span>3</span><span>)</span> 
</span></span><span><span><span>slow</span><span>(</span><span>&#39;2&#39;</span><span>,</span> <span>3</span><span>)</span> 
</span></span><span><span><span>puts</span> <span>&#34;total : </span><span>#{</span><span>Time</span><span>.</span><span>now</span> <span>-</span> <span>start_time</span><span>}</span><span>s</span><span>\n\n</span><span>&#34;</span>
</span></span><span><span>
</span></span><span><span><span>puts</span> <span>&#39;threads&#39;</span>
</span></span><span><span><span>start_time</span> <span>=</span> <span>Time</span><span>.</span><span>now</span>
</span></span><span><span><span>thread1</span> <span>=</span> <span>Thread</span><span>.</span><span>new</span> <span>{</span> <span>slow</span><span>(</span><span>&#39;1&#39;</span><span>,</span> <span>3</span><span>)</span> <span>}</span>
</span></span><span><span><span>thread2</span> <span>=</span> <span>Thread</span><span>.</span><span>new</span> <span>{</span> <span>slow</span><span>(</span><span>&#39;2&#39;</span><span>,</span> <span>3</span><span>)</span> <span>}</span>
</span></span><span><span><span>thread1</span><span>.</span><span>join</span>
</span></span><span><span><span>thread2</span><span>.</span><span>join</span>
</span></span><span><span><span>puts</span> <span>&#34;total : </span><span>#{</span><span>Time</span><span>.</span><span>now</span> <span>-</span> <span>start_time</span><span>}</span><span>s</span><span>\n\n</span><span>&#34;</span>
</span></span></code></pre></div><pre tabindex="0"><code>no threads
1 start - 08:23:20
1 end - 08:23:23
2 start - 08:23:23
2 end - 08:23:26
total : 6.006063s

threads
1 start - 08:23:26
2 start - 08:23:26
1 end - 08:23:29
2 end - 08:23:29
total : 3.006418s
</code></pre><p>The Ruby interpreter controls when threads are switched, typically after a set number of instructions or when a thread performs a blocking operation like file I/O or network access. This allows Ruby to be effective for I/O-bound tasks, even though CPU-bound tasks remain limited by the <strong>GIL</strong>.</p>
<p>There is some shenanigans available for you to use, like the <code>priority</code> attribute instruct the interpreter that you want it to favor the run of a thread with a higher priority, without any guarantee the the Ruby VM will honor it. If you want to go more brutal <code>Thread.pass</code> is available. As a rule of thumb, it‚Äôs considered a bad idea to play with those low level instructions in your code.</p>
<p>But why the need for the <strong>GIL</strong> in the first place ? Because the internal structures of the <strong>MRI</strong> are not thread safe! It‚Äôs very specific to the <strong>MRI</strong> other Ruby implementations like <strong>JRuby</strong> don‚Äôt have those limitations.</p>
<p>Finally, do not forget that threads <strong>share memory</strong>, so this open the door to race conditions. Here is an overcomplicated example for you to understand this. It relies on the fact that class level variables shares the same memory space. Using class variables for something else than a constant is considered a bad practice.</p>
<div><pre tabindex="0"><code data-lang="ruby"><span><span><span># frozen_string_literal: true</span>
</span></span><span><span>
</span></span><span><span><span>class</span> <span>Counter</span>
</span></span><span><span>  <span># Shared class variable</span>
</span></span><span><span>  <span>@@count</span> <span>=</span> <span>0</span>
</span></span><span><span>
</span></span><span><span>  <span>def</span> <span>self</span><span>.</span><span>increment</span>
</span></span><span><span>    <span>1000</span><span>.</span><span>times</span> <span>do</span>
</span></span><span><span>      <span>current_value</span> <span>=</span> <span>@@count</span>
</span></span><span><span>      <span>sleep</span><span>(</span><span>0</span><span>.</span><span>0001</span><span>)</span>  <span># Small delay to allow context switches</span>
</span></span><span><span>      <span>@@count</span> <span>=</span> <span>current_value</span> <span>+</span> <span>1</span>  <span># Increment the count</span>
</span></span><span><span>    <span>end</span>
</span></span><span><span>  <span>end</span>
</span></span><span><span>
</span></span><span><span>  <span>def</span> <span>self</span><span>.</span><span>count</span>
</span></span><span><span>    <span>@@count</span>
</span></span><span><span>  <span>end</span>
</span></span><span><span><span>end</span>
</span></span><span><span>
</span></span><span><span><span># Create an array to hold the threads</span>
</span></span><span><span><span>threads</span> <span>=</span> <span>[]</span>
</span></span><span><span>
</span></span><span><span><span># Create 10 threads that all increment the @@count variable</span>
</span></span><span><span><span>10</span><span>.</span><span>times</span> <span>do</span>
</span></span><span><span>  <span>threads</span> <span>&lt;&lt;</span> <span>Thread</span><span>.</span><span>new</span> <span>do</span>
</span></span><span><span>    <span>Counter</span><span>.</span><span>increment</span>
</span></span><span><span>  <span>end</span>
</span></span><span><span><span>end</span>
</span></span><span><span>
</span></span><span><span><span># Wait for all threads to finish</span>
</span></span><span><span><span>threads</span><span>.</span><span>each</span><span>(</span><span>&amp;</span><span>:join</span><span>)</span>
</span></span><span><span>
</span></span><span><span><span># Display the final value of @@count</span>
</span></span><span><span><span>puts</span> <span>&#34;Final count: </span><span>#{</span><span>Counter</span><span>.</span><span>count</span><span>}</span><span>&#34;</span>
</span></span><span><span>
</span></span><span><span><span># Check if the final count matches the expected value</span>
</span></span><span><span><span>if</span> <span>Counter</span><span>.</span><span>count</span> <span>==</span> <span>10_000</span>
</span></span><span><span>  <span>puts</span> <span>&#34;Final count is correct: </span><span>#{</span><span>Counter</span><span>.</span><span>count</span><span>}</span><span>&#34;</span>
</span></span><span><span><span>else</span>
</span></span><span><span>  <span>puts</span> <span>&#34;Race condition detected: expected 10000, got </span><span>#{</span><span>Counter</span><span>.</span><span>count</span><span>}</span><span>&#34;</span>
</span></span><span><span><span>end</span>
</span></span></code></pre></div><pre tabindex="0"><code>Final count: 1000
Race condition detected: expected 10000, got 1000
</code></pre><p>The sleep here force a context switch to another thread as it‚Äôs an I/O operation. This results in the <code>@@count</code> value being reset to previous value when the context changes back from thread to thread.</p>
<p>In your day to day code, you should not use thread, but it‚Äôs good to know that they exists under the hood in most of the Gems we use daily!</p>
<h3 id="fiber-">Fiber üåΩ</h3>
<p>Here we go for the final nested level ! Fiber is a very lightweight cooperative concurrency mechanism. Unlike threads, fibers are not preemptively scheduled; instead, they explicitly pass control back and forth. <a href="http://Fiber.new"><code>Fiber.new</code></a> take the block you will execute in you fiber. From there, you can use <code>Fiber.yield</code> and <code>Fiber.resume</code> to control the back and forth between the fibers. As we saw earlier, Fibers run inside the same Ruby thread (so they share the same memory space). As every other concept highlighted in this blog post, you should consider <code>Fiber</code> as a very low level interface and I would avoid building a lot of code based on them. The only valid use case for me is <code>Generator</code>. With <code>Fiber</code> s it‚Äôs relatively easy to create a lazy generator as in the code below.</p>
<div><pre tabindex="0"><code data-lang="ruby"><span><span><span>def</span> <span>fibernnacci</span>
</span></span><span><span>  <span>Fiber</span><span>.</span><span>new</span> <span>do</span>
</span></span><span><span>    <span>a</span><span>,</span> <span>b</span> <span>=</span> <span>0</span><span>,</span> <span>1</span>
</span></span><span><span>    <span>loop</span> <span>do</span>
</span></span><span><span>      <span>Fiber</span><span>.</span><span>yield</span> <span>a</span>
</span></span><span><span>      <span>a</span><span>,</span> <span>b</span> <span>=</span> <span>b</span><span>,</span> <span>a</span> <span>+</span> <span>b</span>
</span></span><span><span>    <span>end</span>
</span></span><span><span>  <span>end</span>
</span></span><span><span><span>end</span>
</span></span><span><span>
</span></span><span><span><span>fib</span> <span>=</span> <span>fibernnacci</span>
</span></span><span><span><span>5</span><span>.</span><span>times</span> <span>do</span>
</span></span><span><span>  <span>puts</span> <span>Time</span><span>.</span><span>now</span><span>.</span><span>to_s</span>
</span></span><span><span>  <span>puts</span> <span>fib</span><span>.</span><span>resume</span>
</span></span><span><span><span>end</span> 
</span></span></code></pre></div><pre tabindex="0"><code>2024-10-19 15:58:54 +0200
0
2024-10-19 15:58:54 +0200
1
2024-10-19 15:58:54 +0200
1
2024-10-19 15:58:54 +0200
2
2024-10-19 15:58:54 +0200
3
</code></pre><p>As you can see in this output, code lazy generates values only when they need to be consumed. This allows for interesting patterns and properties you might need in your toolbelt.</p>
<p>Once again, as it‚Äôs low level API, using Fibers in your code is probably not the best idea. The most known Gem that heavily use Fibers is the <a href="https://github.com/socketry/async">Async</a> Gem (used by <a href="https://github.com/socketry/falcon">Falcon</a>).</p>
<h2 id="wrap-up">Wrap Up</h2>
<p>Ruby provides several concurrency models, each with unique characteristics suited for different tasks.</p>
<ul>
<li><strong>Processes</strong> offer full memory isolation and can run in parallel across CPU cores, making them great for tasks that need complete separation but are resource-heavy.</li>
<li><strong>Ractors</strong>, introduced in Ruby 3, also provide parallelism with memory isolation, but within the same process, allowing for safer parallel execution by passing messages between ractors.</li>
<li><strong>Threads</strong> are lighter than processes, sharing memory within the same process, and can run concurrently, but they require careful synchronization to avoid race conditions.</li>
<li><strong>Fibers</strong> are the lightest concurrency mechanism, offering cooperative multitasking by manually yielding control. They share the same memory and are most useful for building generators or coroutines, rather than parallel execution.</li>
</ul>
<p>With that knowledge, you now have arguments to enter the never-ending <a href="https://github.com/puma/puma">Puma</a> (threads-first approach) vs. <a href="https://rubygems.org/gems/unicorn/versions/5.1.0?locale=fr">Unicorn</a> (process-first approach) debate. Just remember, discussing this topic is like trying to explain the difference between Vi and Emacs! It‚Äôs an exercise left to the reader to find out which one is the winner!<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup></p>



        
          
        

        

        
      </article>

      
        
      


      

    </div>
  </div>
</div></div>
  </body>
</html>
