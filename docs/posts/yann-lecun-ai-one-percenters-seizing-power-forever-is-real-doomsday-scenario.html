<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.businessinsider.com/sam-altman-and-demis-hassabis-just-want-to-control-ai-2023-10">Original</a>
    <h1>Yann LeCun: AI one-percenters seizing power forever is real doomsday scenario</h1>
    
    <div id="readability-page-1" class="page"><div>
                      <section data-track-content="" data-post-type="post">
                        <div id="piano-inline-content-wrapper" data-piano-inline-content-wrapper=""> 
                    
                    
                    
                          
                          
                          <section data-offer-key="pre-churn-offer" data-component-type="inline-offer" data-place-after-element-selector=".post-content .content-lock-content &gt; p">
                            <article>
                              <img src="https://www.businessinsider.com/public/assets/subscription/marketing/banner-overlay/top-left.svg" alt=""/>
                              <img src="https://www.businessinsider.com/public/assets/subscription/marketing/banner-overlay/bottom-right.svg" alt=""/>
                          
                                        </article>
                          </section>
                    
                    <div data-component-type="content-lock" data-load-strategy="exclude">
                      <div>
                                  <ul><li>An AI godfather has had it with the doomsdayers.</li><li>Meta&#39;s Yann LeCun thinks tech bosses&#39; bleak comments on  AI risks could do more harm than good.</li><li>The naysaying is actually about keeping control of AI in the hands of a few, he said.</li></ul><div id="formContainer" data-component-type="inline-newsletter-module" data-event-label="insider_today" data-newsletter-id="1" data-list="Insider Today" data-acq-source="techinlinesignup">
                        
                        
                          <section>
                              
                        
                            <p><svg version="1.1" xmlns="http://www.w3.org/2000/svg" role="img" width="50" height="50" viewBox="0 0 50 50" style="enable-background:new 0 0 50 50;" xml:space="preserve">
                          <title>Loading</title>
                          <desc>Something is loading.</desc>
                          <path fill="#111" d="M43.935,25.145c0-10.318-8.364-18.683-18.683-18.683c-10.318,0-18.683,8.365-18.683,18.683h4.068c0-8.071,6.543-14.615,14.615-14.615c8.072,0,14.615,6.543,14.615,14.615H43.935z">
                            <animateTransform attributeType="xml" attributeName="transform" type="rotate" from="0 25 25" to="360 25 25" dur="0.6s" repeatCount="indefinite"></animateTransform>
                          </path>
                        </svg></p>
                            
                        
                            
                        
                            <div>
                              <p>Thanks for signing up!</p>
                              
                              <p>
                              Access your favorite topics in a personalized feed while you&#39;re on the go.
                                    </p>
                            </div>
                        
                            
                            
                          </section>
                        
                            <div>
                                <p><img src="data:image/svg+xml,%3Csvg xmlns=&#39;http://www.w3.org/2000/svg&#39; viewBox=&#39;0 0 1 1&#39;%3E%3C/svg%3E" data-src="/public/assets/rebrand/newsletter-bull.png" alt="Bull" itemprop="contentUrl"/>
                              
                              
                              
                              </p>    </div>
                        
                          
                        </div><p><a target="_blank" href="https://www.businessinsider.com/yann-lecun-artificial-intelligence-generative-ai-threaten-humanity-existential-risk-2023-6" data-analytics-product-module="body_link" rel=""><u>AI godfather Yann LeCun</u></a> wants us to forget some of the more far-fetched <a target="_blank" href="https://www.businessinsider.com/billionaire-bunker-openai-sam-altman-joked-ai-apocalypse-2023-10" data-analytics-product-module="body_link" rel=""><u>doomsday scenarios.</u></a></p><p>He sees a different, real threat on the horizon: the rise of power hungry one-percenters who rob everyone else of AI&#39;s riches.</p><p>Over the weekend, Meta&#39;s chief AI scientist accused some of the most prominent founders in AI of <a target="_blank" href="https://x.com/ylecun/status/1718670073391378694?s=20" data-analytics-product-module="body_link" rel=" nofollow"><u>&#34;fear-mongering&#34; and &#34;massive corporate lobbying&#34;</u></a> to serve their own interests.</p><p>He named <a target="_blank" href="https://www.businessinsider.com/sam-altman-chatgpt-openai-ceo-career-net-worth-ycombinator-prepper-2023-1" data-analytics-product-module="body_link" rel=""><u>OpenAI&#39;s Sam Altman</u></a>, Google DeepMind&#39;s Demis Hassabis, and Anthropic&#39;s Dario Amodei in a lengthy weekend post on X.</p><p><span>&#34;Altman, Hassabis, and Amodei are the ones doing massive corporate lobbying at the moment,&#34; LeCun wrote, referring to these founders&#39; role in shaping regulatory conversations about AI safety. &#34;They are the ones who are attempting to perform a regulatory capture of the AI industry.&#34;</span></p><p><span>He added that if these efforts succeed, the outcome would be a &#34;catastrophe&#34; because &#34;a small number of companies will control AI.&#34; </span></p><p><span>That&#39;s significant since, as almost everyone who matters in tech agrees, AI </span><a target="_blank" href="https://www.businessinsider.com/bill-gates-chatgpt-ai-artificial-intelligenct-as-important-pc-internet-2023-2" data-analytics-product-module="body_link" rel=""><span>is the biggest development in technology</span></a><span> since the microchip or the internet.</span></p><p>LeCun&#39;s comments came in response to <a target="_blank" href="https://x.com/tegmark/status/1718663322738868595?s=20" data-analytics-product-module="body_link" rel=" nofollow"><u>a post on X from physicist Max Tegmark</u></a>, who suggested that LeCun wasn&#39;t taking the AI doomsday arguments seriously enough. </p><p>&#34;Thanks to<a target="_blank" href="https://twitter.com/RishiSunak" data-analytics-product-module="body_link" rel=" nofollow"><u> @RishiSunak</u></a> &amp;<a target="_blank" href="https://twitter.com/vonderleyen" data-analytics-product-module="body_link" rel=" nofollow"><u> @vonderleyen</u></a> for realizing that AI xrisk arguments from Turing, Hinton, Bengio, Russell, Altman, Hassabis &amp; Amodei can&#39;t be refuted with snark and corporate lobbying alone,&#34; Tegmark wrote, referring to the UK&#39;s upcoming global AI safety summit.</p><div id="1698669306740" data-styles="default-width" data-embed-type="custom" data-script="https://platform.twitter.com/widgets.js" data-type="embed"><blockquote><p lang="en" dir="ltr">Yann, I&#39;d love to hear you make arguments rather than acronyms. Thanks to <a href="https://twitter.com/RishiSunak?ref_src=twsrc%5Etfw" data-analytics-product-module="body_link" rel=" nofollow">@RishiSunak</a> &amp; <a href="https://twitter.com/vonderleyen?ref_src=twsrc%5Etfw" data-analytics-product-module="body_link" rel=" nofollow">@vonderleyen</a> for realizing that AI xrisk arguments from Turing, Hinton, Bengio, Russell, Altman, Hassabis &amp; Amodei can&#39;t be refuted with snark and corporate lobbying alone. <a href="https://t.co/Zv1rvOA3Zz" data-analytics-product-module="body_link" rel=" nofollow">https://t.co/Zv1rvOA3Zz</a></p>— Max Tegmark (@tegmark) <a href="https://twitter.com/tegmark/status/1718663322738868595?ref_src=twsrc%5Etfw" rel=" nofollow">October 29, 2023</a></blockquote>   
                        </div><h2><strong>LeCun says founder fretting is just lobbying</strong></h2><p>Since the <a target="_blank" href="https://www.businessinsider.com/everything-you-need-to-know-about-chat-gpt-2023-1" data-analytics-product-module="body_link" rel=""><u>launch of ChatGPT</u></a>, AI&#39;s power players have become major public figures.</p><p>But, LeCun said, founders such as Altman and Hassabis have spent a lot of time drumming up fear about the very technology they&#39;re selling. </p><p>In March, more than 1,000 tech leaders, including Elon Musk, Altman, Hassabis, and Amodei, <a target="_blank" href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/" data-analytics-product-module="body_link" rel=" nofollow"><u>signed a letter calling for a minimum six-month pause on AI development</u></a>. </p><p>The letter cited &#34;profound risks to society and humanity&#34; posed by hypothetical AI systems. Tegmark, one of the letter&#39;s signatories, has <a target="_blank" href="https://www.youtube.com/watch?v=VcVfceTsD0A" data-analytics-product-module="body_link" rel=" nofollow"><u>described AI development as &#34;a suicide race.&#34;</u></a></p><p>LeCun and others say these kinds of headline-grabbing warnings are just about cementing power and skating over the real, imminent risks of AI.</p><p>Those risks include worker exploitation and data theft that generates profit for &#34;a handful of entities,&#34; according to the Distributed AI Research Institute (DAIR).</p><p>The focus on hypothetical dangers also divert attention away from the boring-but-important question of how AI development actually takes shape.</p><p>LeCun has described how people are <a target="_blank" href="https://x.com/ylecun/status/1642524629137760259?s=20" data-analytics-product-module="body_link" rel=" nofollow"><u>&#34;hyperventilating about AI risk&#34;</u></a> because they have fallen for what he describes as the myth of the &#34;hard take-off.&#34; This is the idea that &#34;the minute you turn on a super-intelligent system, humanity is doomed.&#34;</p><p>But imminent doom is unlikely, he argues, because every new technology in fact goes through a very ordered development process before wider release.</p><div id="1698669306740" data-styles="default-width" data-embed-type="custom" data-script="https://platform.twitter.com/widgets.js" data-type="embed"><blockquote><p lang="en" dir="ltr">Every new technology is developed and deployed the same way: </p>— Yann LeCun (@ylecun) <a href="https://twitter.com/ylecun/status/1642523756332568577?ref_src=twsrc%5Etfw" rel=" nofollow">April 2, 2023</a></blockquote> </div><p>So the area to focus on, is in fact, <em>how</em> AI is developed right now. And for LeCun, the real danger is that the development of AI is locked into private, for-profit entities who never release their findings, while <a target="_blank" href="https://www.businessinsider.com/andrew-ng-google-brain-big-tech-ai-risks-2023-10" data-analytics-product-module="body_link" rel="">AI&#39;s open-source community</a> gets obliterated. </p><p>His consequent worry is that regulators let it happen because they&#39;re distracted by killer robot arguments.</p><p>Leaders like LeCun have championed open-source developers as their work on tools that rival, say, OpenAI&#39;s ChatpGPT,  brings a new level of transparency to AI development. </p><p>LeCun&#39;s employer, Meta, <a target="_blank" href="https://www.businessinsider.com/meta-llama2-open-source-mark-zuckerberg-balls-replit-amjad-masad-2023-10" data-analytics-product-module="body_link" rel="">made its own large language model</a> that competes with GPT, LLaMa 2, (somewhat) open source. The idea is that the broader tech community can look under the hood of the model. No other big tech company has done a similar open-source release, though OpenAI is <a target="_blank" href="https://www.businessinsider.com/openai-chatgpt-release-open-source-ai-model-2023-5" data-analytics-product-module="body_link" rel="">rumored to be thinking about it</a>.</p><p>For LeCun, keeping AI development closed is a real reason for alarm.</p><p>&#34;<span>The alternative, which will </span><em><span>inevitably</span></em><span> happen if open source AI is regulated out of existence, is that a small number of companies from the West Coast of the US and China will control AI platform and hence control people&#39;s entire digital diet,&#34; he wrote. </span></p><p><span>&#34;What does that mean for democracy? What does that mean for cultural diversity?&#34;</span></p>
                      </div>
                    
                    </div>
                    
                    
                        </div>
                    
                        
                        
                        
                        <div data-only-on="mobile" data-component-type="notification-prompt">
                          <div>
                            <div>
                                <p><img src="data:image/svg+xml,%3Csvg xmlns=&#39;http://www.w3.org/2000/svg&#39; viewBox=&#39;0 0 1 1&#39;%3E%3C/svg%3E" data-src="/public/assets/shared/light-switch.png" alt="A picture of a switch and lightbulb" itemprop="contentUrl"/>
                              
                              
                              
                              </p>    </div>
                            <div>
                              <p>
                                Sign up for notifications from Insider! Stay up to date with what you want to know.
                              </p>
                              <p>Subscribe to push notifications</p>
                            </div>
                          </div>
                        </div>    
                        </section>
                    </div></div>
  </body>
</html>
