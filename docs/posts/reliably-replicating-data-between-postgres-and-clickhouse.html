<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://benjaminwootton.com/insights/clickhouse-peerdb-cdc/">Original</a>
    <h1>Reliably replicating data between Postgres and ClickHouse</h1>
    
    <div id="readability-page-1" class="page"><div> <p>In this series of articles we are going to demonstrate how to reliably replicate data from PostgreSQL to ClickHouse.</p><p>In <a href="https://benjaminwootton.com/insights/clickhouse-peerdb-cdc/">part one</a>, we will use <a href="https://www.peerdb.io/">PeerDB open source</a> to achieve this using an open source and self managed stack.  In <a href="https://benjaminwootton.com/insights/clickhouse-peerdb-clickpipes-postgrescdc/">part two</a>, we will look at how we can use <a href="https://clickhouse.com/clickpipes">ClickPipes</a>, the data integration component of <a href="https://clickhouse.com">ClickHouse Cloud</a> to achieve the same result with a fully managed solution.  In <a href="https://benjaminwootton.com/insights/clickhouse-peerdb-demo/">part three</a> we include a video walkthrough of both tools for those who prefer a visual demo.</p><h2 id="why-postgresql-and-clickhouse">Why PostgreSQL and ClickHouse?</h2><p>ClickHouse is becoming the default analytical database of choice for Postgres users.  This is because both databases share a common open source heritage whilst excelling at different workloads - Postgres for transactional workloads (OLTP) and ClickHouse for analytics (OLAP).</p><p>The first use case we come across is a traditional requirement for data warehousing, where businesses want to extract and centralise application data into an OLAP warehouse for analytics, dashboards or reporting.  PostgreSQL is already extremely popular as a transactional database, and with the growth of ClickHouse as a real time data warehouse, this combination of databases is naturally growing in adoption.</p><p>The second more interesting use cases arises when businesses choose to run both PostgreSQL and ClickHouse to support the same application.  Often, these teams start with PostgreSQL behind their application, but over time, the analytical components of their application begin to slow down or put too much strain on the system, negatively affecting the user experience. To resolve this, they add a separate database tailored for large-scale analytics and increasingly reach for ClickHouse.</p><h2 id="data-replication">Data Replication</h2><p>Once the databases are selected, the next challenge is ensuring reliable, ongoing data replication from PostgreSQL to ClickHouse. While it’s possible to handle this at the application layer by writing data directly into ClickHouse, replicating data at the database level tends to be simpler and more reliable.</p><p>Several tools can facilitate this process, such as <a href="https://debezium.io/">Debezium</a>, <a href="https://airbyte.io/">AirByte</a>, and <a href="https://fivetran.com/">Fivetran</a>.  However, it’s worth considering a more recent alternative <a href="https://www.peerdb.io/">PeerDB</a> , for several reasons.</p><p>First, unlike many ETL tools that aim to support a wide variety of database connectors, PeerDB focuses exclusively on PostgreSQL as a data source.  This specialisation has allowed the team to create one of the <a href="https://docs.peerdb.io/why-peerdb">fastest and most scalable CDC solutions for PostgreSQL</a>, with support for advanced features like complex data types and partitioned tables.</p><p>Second, in July 2024, <a href="https://clickhouse.com/blog/clickhouse-acquires-peerdb-to-boost-real-time-analytics-with-postgres-cdc-integration">ClickHouse acquired PeerDB</a>. Since then, the integration between the two platforms has deepened, including the <a href="https://clickhouse.com/blog/postgres-cdc-connector-clickpipes-private-preview">private preview of PeerDB integrated into ClickHouse Cloud</a>.  This strategic alignment makes PeerDB the natural choice when working with PostgreSQL and ClickHouse.</p><h2 id="self-managed-vs-fully-managed">Self Managed vs Fully Managed</h2><p>This leaves us with two options for using PeerDB at the time of writing.</p><p>The first is to use the <a href="https://www.peerdb.io/">PeerDB open source distribution</a> and run it in a self hosted configuration on your own server.   This can be used to send data from any Postgres database (including open source or AWS RDS) to either open source ClickHouse and ClickHouse Cloud.</p><p>The second option is to use a fully managed version of PeerDB which <a href="https://benjaminwootton.com/insights/clickhouse-clickpipes-postgrescdc/">is integrated and embedded into ClickHouse Cloud</a>.  In this instance, the solution is branded as PostgreSQL CDC for ClickPipes, though PeerDB is used behind the scenes.</p><p>Though Open Source PeerDB isn’t too tricky to setup and operate, having this critical process deployed and reliably ran for you as a managed service is one less thing to worry about.  We would therefore recommend that ClickHouse Cloud users make use of the managed route, discussed in <a href="https://benjaminwootton.com/insights/clickhouse-clickpipes-postgrescdc">part two</a>.</p><h2 id="core-concepts">Core Concepts</h2><p>PeerDB is responsible for taking data from a PostgreSQL source database and reliably copying it into a target data warehouse, in our case ClickHouse.  These sources and targets are referred to as “peers” within PeerDB.</p><p>After defining your source and target peers, you will then define “mirrors” which represent your replication processes.  For each mirror, you will define which tables you want to replicate and the frequency of the replication.  It may be the case, for instance, that some tables need to be fresher than others within ClickHouse so different mirrors can be configured in different ways depending on your requirements.</p><p>When integrating PostgreSQL and ClickHouse, there will typically be an initial load or snapshot process to replicate all of your historical data.  When doing this, you may need to configure options such as the batch size and the number of parallel processes to run for the snapshot.  This may need to be set with care if you are loading a lot of data from a live production system.</p><p>After the initial load, PeerDB will then begin replicating all of the inserts, updates and deletes that occur again your chosen tables in PostgreSQL, and apply them to the ClickHouse target tables continuously and in near real-time to keep the tables in line.</p><p>As well as simply replicaitng the tables, we also have the option of applying <a href="https://blog.peerdb.io/row-level-transformations-in-postgres-cdc-using-lua">data transformations </a> as data moves through PeerDB.  Carrying out these transformations within PeerDB rather can be more efficient whilst supporting use cases such as removing sensitive data or unnesting JSON during the replication process.</p><h3 id="cdc-vs-sql-integration">CDC vs SQL Integration</h3><p>There are two primary options for extracting data from your source PostgreSQL database which are referred to as CDC and Query Replication.</p><p>CDC (Change Data Capture) is a low level solution whereby PeerDB will source data by listening to a log of low level change events emitted from PostgreSQL.</p><p>The Query Replication route extracts data from the PostgreSQL source by periodically issuing a SQL query.  This route allows you to do things like applying where clauses onto the query and carry out joins across multiple source tables.  This route may also be necessary if your source table does not have a primary key.</p><p>The Query Replication route is much more flexible, but there are a few downsides.  Firstly, it will need to run as a periodic batch, whereas the CDC mechanism is streaming based and can be run at lower latency.  In addition, the Query Replication route would also add more load onto the source database than the CDC approach.   With a fast analytical database like ClickHouse and the option of applying transformations within PeerDB, <strong>the go-to should be to stick to CDC to emit “low level” events, and do any transformation work within PeerDB or within ClickHouse away from your transactional application database</strong>.</p><h2 id="walkthrough">Walkthrough</h2><p>We will now walk through the process of setting up and configuring PeerDB for the first time in order to illustrate the process.  We will assume that you have access to a running PostgreSQL and ClickHouse database as a prerequisite.  You will also need Docker installed on your system.</p><h3 id="deploying-peerdb">Deploying PeerDB</h3><p>You can download run PeerDB by cloning <a href="https://github.com/PeerDB-io/peerdb">this repo</a> and running the run-peerdb.sh script contained within:</p><pre tabindex="0" data-language="plaintext"><code><span><span>git clone --recursive https://github.com/PeerDB-io/peerdb.git</span></span>
<span><span>cd peerdb</span></span>
<span><span>./run-peerdb.sh</span></span>
<span><span></span></span></code></pre><p>PeerDB is deployed as a set of Docker containers which are orchestrated with a Docker compose file contained in the repo above.  After a few minutes, you should see a number of Docker containers running on your system:</p><pre tabindex="0" data-language="plaintext"><code><span><span>CONTAINER ID   IMAGE                                                   COMMAND                  CREATED             STATUS                    PORTS                                                                                         NAMES</span></span>
<span><span>0ae1675e1119   ghcr.io/peerdb-io/peerdb-ui:stable-v0.22.3              &#34;/app/entrypoint.sh …&#34;   About an hour ago   Up 47 minutes             0.0.0.0:3000-&gt;3000/tcp, :::3000-&gt;3000/tcp                                                     peerdb-ui</span></span>
<span><span>49a546b7bf33   ghcr.io/peerdb-io/flow-snapshot-worker:stable-v0.22.3   &#34;./peer-flow snapsho…&#34;   About an hour ago   Up 47 minutes                                                                                                           flow-snapshot-worker</span></span>
<span><span>1c4ecc241450   ghcr.io/peerdb-io/flow-worker:stable-v0.22.3            &#34;./peer-flow worker&#34;     About an hour ago   Up 47 minutes                                                                                                           flow-worker</span></span>
<span><span>c8e5423090ab   ghcr.io/peerdb-io/flow-api:stable-v0.22.3               &#34;./peer-flow api --p…&#34;   About an hour ago   Up 47 minutes             0.0.0.0:8112-8113-&gt;8112-8113/tcp, :::8112-8113-&gt;8112-8113/tcp                                 flow_api</span></span>
<span><span>74d3b70f0251   temporalio/admin-tools:1.25.2-tctl-1.18.1-cli-1.1.1     &#34;/etc/temporal/entry…&#34;   About an hour ago   Up 47 minutes (healthy)                                                                                                 temporal-admin-tools</span></span>
<span><span>b8f81dac7f8c   temporalio/ui:2.34.0                                    &#34;./start-ui-server.sh&#34;   About an hour ago   Up 47 minutes             0.0.0.0:8085-&gt;8080/tcp, [::]:8085-&gt;8080/tcp                                                   temporal-ui</span></span>
<span><span>03f04411a5c8   temporalio/auto-setup:1.26                              &#34;/etc/temporal/entry…&#34;   About an hour ago   Up 47 minutes             6933-6935/tcp, 6939/tcp, 7234-7235/tcp, 7239/tcp, 0.0.0.0:7233-&gt;7233/tcp, :::7233-&gt;7233/tcp   temporal</span></span>
<span><span>5fc3eb9f377b   ghcr.io/peerdb-io/peerdb-server:stable-v0.22.3          &#34;./peerdb-server&#34;        About an hour ago   Up 47 minutes             0.0.0.0:9900-&gt;9900/tcp, :::9900-&gt;9900/tcp                                                     peerdb-server</span></span>
<span><span>380d591d9e30   postgres:17-alpine                                      &#34;docker-entrypoint.s…&#34;   About an hour ago   Up 47 minutes (healthy)   0.0.0.0:9901-&gt;5432/tcp, [::]:9901-&gt;5432/tcp                                                   catalog</span></span>
<span><span>d7957db52ee6   minio/minio:RELEASE.2024-11-07T00-52-20Z                &#34;/bin/sh -c &#39; export…&#34;   About an hour ago   Up 47 minutes             0.0.0.0:9001-&gt;9000/tcp, [::]:9001-&gt;9000/tcp, 0.0.0.0:9002-&gt;36987/tcp, [::]:9002-&gt;36987/tcp    peerdb-quickstart-minio-1</span></span>
<span><span></span></span></code></pre><p>At this stage, PeerDB is ready to be configured and used, but first, we will need some test data to work with!</p><h3 id="creating-test-data-in-postgresql">Creating Test Data In PostgreSQL</h3><p>We will begin by creating a table in our PostgreSQL database.  Our test data will bet a set of ecommerce orders including amounts, order status and delivery information:</p><pre tabindex="0" data-language="plaintext"><code><span><span>CREATE TABLE orders (</span></span>
<span><span>    order_id SERIAL PRIMARY KEY,</span></span>
<span><span>    customer_id INT NOT NULL,</span></span>
<span><span>    order_date TIMESTAMP DEFAULT CURRENT_TIMESTAMP,</span></span>
<span><span>    status VARCHAR(50) DEFAULT &#39;Pending&#39;,</span></span>
<span><span>    total_amount NUMERIC(10, 2) NOT NULL,</span></span>
<span><span>    shipping_address TEXT NOT NULL,</span></span>
<span><span>    payment_method VARCHAR(50) NOT NULL,</span></span>
<span><span>    shipping_date TIMESTAMP,</span></span>
<span><span>    delivery_date TIMESTAMP,</span></span>
<span><span>    created_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP,</span></span>
<span><span>    updated_at TIMESTAMP DEFAULT CURRENT_TIMESTAMP</span></span>
<span><span>);</span></span>
<span><span></span></span></code></pre><h3 id="generating-test-data">Generating Test Data</h3><p>We will then generate some random synthetic data in the source table:</p><pre tabindex="0" data-language="plaintext"><code><span><span>INSERT INTO orders (customer_id, order_date, status, total_amount, shipping_address, payment_method, shipping_date, delivery_date)</span></span>
<span><span>SELECT </span></span>
<span><span>    (RANDOM() * 1000)::INT + 1 AS customer_id,</span></span>
<span><span>    NOW() - INTERVAL &#39;1 day&#39; * (RANDOM() * 365) AS order_date,</span></span>
<span><span>    CASE WHEN RANDOM() &lt; 0.2 THEN &#39;Shipped&#39; WHEN RANDOM() &lt; 0.6 THEN &#39;Completed&#39; ELSE &#39;Pending&#39; END AS status,</span></span>
<span><span>    ROUND((RANDOM() * 1000)::numeric, 2) AS total_amount,</span></span>
<span><span>    &#39;123 Example St, City, Country&#39; AS shipping_address,</span></span>
<span><span>    CASE WHEN RANDOM() &lt; 0.5 THEN &#39;Credit Card&#39; ELSE &#39;PayPal&#39; END AS payment_method,</span></span>
<span><span>    NOW() - INTERVAL &#39;1 day&#39; * (RANDOM() * 30) AS shipping_date,</span></span>
<span><span>    NOW() - INTERVAL &#39;1 day&#39; * (RANDOM() * 60) AS delivery_date</span></span>
<span><span>FROM generate_series(1, 1000000);</span></span>
<span><span></span></span></code></pre><p>We have generated a million rows representing our eCommerce orders, but the same technique can scale to greater volumes for your benchmarkings.</p><h3 id="configuring-peerdb">Configuring PeerDB</h3><p>PeerDB can be configured in one of two ways.  Firstly, there is a web based UI which can be used to configure your peers and mirrors then monitor the ongoing state of your replication.  This UI runs on port 3000 by default:</p><picture> <source srcset="/_astro/peerdbgui.TCx8Db5u_1AY0si.webp" type="image/webp"/> <img src="https://benjaminwootton.com/_astro/peerdbgui.TCx8Db5u_Z2eBUo9.png" alt="" width="2942" height="1681" loading="lazy" decoding="async"/> </picture><p>Alternatively, it is possible to connect to PeerDB and configure it via a SQL interface.  This allows you to script your setup in plain SQL which can be source controlled and tested more effectively rather than needing to click around in a UI.</p><p>In the example below, we create two peers, then a mirror which replicates the “orders” table in PostgreSQL to the “orders” table in ClickHouse.</p><pre tabindex="0" data-language="plaintext"><code><span><span>-- Create the source Peer</span></span>
<span><span>CREATE PEER postgres_peer FROM POSTGRES WITH( host = &#39;YOUR_POSTGRES_HOST&#39;, port = &#39;YOUR_POSTGRES_PORT&#39;, user = &#39;postgres&#39;, password = &#39;postgres&#39;, database = &#39;postgres&#39; );</span></span>
<span><span></span></span>
<span><span>-- Create the destination Peer over the native SSL port/TLS</span></span>
<span><span>CREATE PEER clickhouse_peer FROM CLICKHOUSE WITH( host = &#39;YOUR_CLICKHOUSE_HOST&#39;, port = &#39;9440&#39;, user = &#39;default&#39;, password = &#39;YOUR_CLICKHOUSE_PASSWORD&#39;, database = &#39;default&#39; );</span></span>
<span><span></span></span>
<span><span>-- Create the mirror</span></span>
<span><span>CREATE MIRROR cdc_mirror FROM postgres_peer TO clickhouse_peer WITH TABLE MAPPING (public.orders:orders) WITH(do_initial_copy = true);</span></span>
<span><span></span></span></code></pre><p>Our preference tends to be a scriptable solution like this so we would tend towards SQL, but the end result is similar either way.</p><h3 id="initial-replication">Initial Replication</h3><p>In less than 20 seconds (surprisingly little time for a million rows), the initial snapshot process will complete.  The table will be created in ClickHouse and the data should be replicated into it with the schema matching the PostgreSQL schema.</p><p>Audit columns for the sync time, the deleted flag and the peerdb version are added automatically by PeerDB:</p><pre tabindex="0" data-language="plaintext"><code><span><span>SELECT</span></span>
<span><span>    order_id,</span></span>
<span><span>    customer_id,</span></span>
<span><span>    order_date,</span></span>
<span><span>    _peerdb_synced_at,</span></span>
<span><span>    _peerdb_is_deleted</span></span>
<span><span>FROM orders</span></span>
<span><span>LIMIT 5</span></span>
<span><span></span></span>
<span><span>Query id: 70e1364e-66b5-431c-bbbe-e592c4b00556</span></span>
<span><span></span></span>
<span><span>   ┌─order_id─┬─customer_id─┬─────────────────order_date─┬─────────────_peerdb_synced_at─┬─_peerdb_is_deleted─┐</span></span>
<span><span>1. │        1 │         881 │ 2024-03-29 05:17:31.091477 │ 2025-01-24 13:50:44.250000000 │                  0 │</span></span>
<span><span>2. │        2 │         874 │ 2024-07-29 14:22:16.122020 │ 2025-01-24 13:50:44.250000000 │                  0 │</span></span>
<span><span>3. │        3 │         541 │ 2024-12-31 06:14:07.539825 │ 2025-01-24 13:50:44.250000000 │                  0 │</span></span>
<span><span>4. │        4 │         455 │ 2024-12-08 12:56:08.528432 │ 2025-01-24 13:50:44.250000000 │                  0 │</span></span>
<span><span>5. │        5 │          12 │ 2024-06-06 10:38:42.814761 │ 2025-01-24 13:50:44.250000000 │                  0 │</span></span>
<span><span>   └──────────┴─────────────┴────────────────────────────┴───────────────────────────────┴────────────────────┘</span></span>
<span><span></span></span>
<span><span>5 rows in set. Elapsed: 0.003 sec. Processed 8.19 thousand rows, 196.62 KB (2.63 million rows/s., 63.13 MB/s.)</span></span>
<span><span>Peak memory usage: 5.12 MiB.</span></span>
<span><span></span></span></code></pre><p>When new data is inserted into the PostgreSQL table, new rows should be propagated into ClickHouse.  To demonstrate, we can create another 5000 rows in PostgreSQL:</p><pre tabindex="0" data-language="plaintext"><code><span><span>INSERT INTO orders (customer_id, order_date, status, total_amount, shipping_address, payment_method, shipping_date, delivery_date)</span></span>
<span><span>SELECT </span></span>
<span><span>    (RANDOM() * 1000)::INT + 1 AS customer_id,</span></span>
<span><span>    NOW() - INTERVAL &#39;1 day&#39; * (RANDOM() * 365) AS order_date,</span></span>
<span><span>    CASE WHEN RANDOM() &lt; 0.2 THEN &#39;Shipped&#39; WHEN RANDOM() &lt; 0.6 THEN &#39;Completed&#39; ELSE &#39;Pending&#39; END AS status,</span></span>
<span><span>    ROUND((RANDOM() * 1000)::numeric, 2) AS total_amount,</span></span>
<span><span>    &#39;123 Example St, City, Country&#39; AS shipping_address,</span></span>
<span><span>    CASE WHEN RANDOM() &lt; 0.5 THEN &#39;Credit Card&#39; ELSE &#39;PayPal&#39; END AS payment_method,</span></span>
<span><span>    NOW() - INTERVAL &#39;1 day&#39; * (RANDOM() * 30) AS shipping_date,</span></span>
<span><span>    NOW() - INTERVAL &#39;1 day&#39; * (RANDOM() * 60) AS delivery_date</span></span>
<span><span>FROM generate_series(1, 5000);</span></span>
<span><span></span></span></code></pre><p>Within seconds, the same batch of rows should be replicated into ClickHouse.</p><p>At this point, it may be worth running a few aggregation queries (sums, averages) to build confidence that the replication is running as expected.</p><h3 id="update-and-delete-semantics">Update and Delete Semantics</h3><p>By default, PeerDB will create a ReplacingMergeTree table in ClickHouse to hold the incoming data.  This means that when a row is replicated into ClickHouse, any row with the same primary key will be replaced on the next merge.  This gives you the effect of the data being “updated” as it is updated in PeerDB.</p><p>To illustrate this, let’s update a row in PostgreSQL:</p><pre tabindex="0" data-language="plaintext"><code><span><span>update orders set status = &#39;Cancelled&#39; where order_id = 3;</span></span>
<span><span></span></span></code></pre><p>After a few seconds, the ClickHouse table will contain both rows:</p><pre tabindex="0" data-language="plaintext"><code><span><span>SELECT</span></span>
<span><span>    order_id,</span></span>
<span><span>    status</span></span>
<span><span>FROM orders</span></span>
<span><span>WHERE order_id = 3</span></span>
<span><span></span></span>
<span><span>Query id: 9a77bf2e-31fb-4cf5-a6cb-13968cb333af</span></span>
<span><span></span></span>
<span><span>   ┌─order_id─┬─status────┐</span></span>
<span><span>1. │        3 │ Cancelled │</span></span>
<span><span>   └──────────┴───────────┘</span></span>
<span><span>   ┌─order_id─┬─status────┐</span></span>
<span><span>2. │        3 │ Completed │</span></span>
<span><span>   └──────────┴───────────┘</span></span>
<span><span></span></span>
<span><span>2 rows in set. Elapsed: 0.006 sec. Processed 8.19 thousand rows, 171.83 KB (1.39 million rows/s., 29.17 MB/s.)</span></span>
<span><span>Peak memory usage: 2.07 MiB.</span></span>
<span><span></span></span></code></pre><p>When we query with final to illustrate how the data will look post merge, we can see that we only have one row with the row effectively being updated:</p><pre tabindex="0" data-language="plaintext"><code><span><span>SELECT</span></span>
<span><span>    order_id,</span></span>
<span><span>    status</span></span>
<span><span>FROM orders</span></span>
<span><span>FINAL</span></span>
<span><span>WHERE order_id = 3</span></span>
<span><span></span></span>
<span><span>Query id: 2594761c-73a7-4981-9661-48a7ad5df14a</span></span>
<span><span></span></span>
<span><span>   ┌─order_id─┬─status────┐</span></span>
<span><span>1. │        3 │ Cancelled │</span></span>
<span><span>   └──────────┴───────────┘</span></span>
<span><span></span></span>
<span><span>1 row in set. Elapsed: 0.006 sec. Processed 16.39 thousand rows, 343.69 KB (2.82 million rows/s., 59.08 MB/s.)</span></span>
<span><span>Peak memory usage: 6.42 MiB.</span></span>
<span><span></span></span></code></pre><p>If you do need different behaviour, you can choose to switch to a standard MergeTree to retain the history at the point where you create your PeerDB mirror.  As always with ClickHouse, you need to be aware of the semantics associated with the table engine you choose.</p><p>Deletes in PostgreSQL are sent into the target with a peerdb_is_deleted column set to 1, representing a logical delete.  You would therefore need to handle the fact that the record is only logically deleted either in your downstream ClickHouse views, reports or applications.</p><p>For example, a PostgreSQL delete:</p><pre tabindex="0" data-language="plaintext"><code><span><span>delete from orders where order_id = 3;</span></span>
<span><span></span></span></code></pre><p>Is eventually integrated with _peerdb_is_deleted = 1.</p><pre tabindex="0" data-language="plaintext"><code><span><span>SELECT</span></span>
<span><span>    order_id,</span></span>
<span><span>    status,</span></span>
<span><span>    _peerdb_is_deleted</span></span>
<span><span>FROM orders</span></span>
<span><span>FINAL</span></span>
<span><span>WHERE order_id = 3</span></span>
<span><span></span></span>
<span><span>Query id: 90da35af-1f6f-470c-b932-1455aba26655</span></span>
<span><span></span></span>
<span><span>   ┌─order_id─┬─status─┬─_peerdb_is_deleted─┐</span></span>
<span><span>1. │        3 │        │                  1 │</span></span>
<span><span>   └──────────┴────────┴────────────────────┘</span></span>
<span><span></span></span>
<span><span>1 row in set. Elapsed: 0.006 sec. Processed 16.39 thousand rows, 343.74 KB (2.89 million rows/s., 60.66 MB/s.)</span></span>
<span><span>Peak memory usage: 8.18 MiB.</span></span>
<span><span></span></span></code></pre><p>Again, materialised views and different table engines can be used to coerce the data to appear how you need it within ClickHouse.</p><h3 id="schema-evolution">Schema Evolution</h3><p>If you add a column onto your source table, this is automatically reflected in ClickHouse at the point that the next record is integrated.</p><p>In the example below, we have added a new column premium_customer into PostgreSQL:</p><pre tabindex="0" data-language="plaintext"><code><span><span>alter table orders add premium_customer boolean;</span></span>
<span><span></span></span></code></pre><p>The column is then reflected in PostgreSQL when the next record is replicated with a default value specified:</p><pre tabindex="0" data-language="plaintext"><code><span><span>SELECT premium_customer</span></span>
<span><span>FROM orders</span></span>
<span><span>LIMIT 5</span></span>
<span><span></span></span>
<span><span>Query id: 62a26e8d-8892-4abb-bfc6-889212d89197</span></span>
<span><span></span></span>
<span><span>   ┌─premium_customer─┐</span></span>
<span><span>1. │ false            │</span></span>
<span><span>2. │ false            │</span></span>
<span><span>3. │ false            │</span></span>
<span><span>4. │ false            │</span></span>
<span><span>5. │ false            │</span></span>
<span><span>   └──────────────────┘</span></span>
<span><span></span></span>
<span><span>5 rows in set. Elapsed: 0.003 sec. Processed 8.19 thousand rows, 40.96 KB (3.24 million rows/s., 16.18 MB/s.)</span></span>
<span><span>Peak memory usage: 1.04 MiB.</span></span>
<span><span></span></span></code></pre><p>Dropping a column in your source table does not remove it from ClickHouse, but should set the values to NULL in the target table.</p><p>Please note that even though the new column is integrated, ClickHouse schema evolution is <a href="https://docs.peerdb.io/features/schema-changes">not explicitly documented as being supported</a> so tread carefully when updating your source tables!</p><h2 id="gotchas-when-running-an-open-source-stack">Gotchas When Running An Open Source Stack</h2><p>There are a few gotchas when runnning the open source stack which slowed us down with getting started.</p><p>The first is related to the MiniIO Configuration.  PeerDB takes data from PostgreSQL and puts it in a staging area before it is loaded into ClickHouse.  By default this staging area is hosted in a <a href="https://min.io/">MinIO</a> container which runs inside of the PeerDB Docker compose stack.  As ClickHouse will be running outside of Docker, it needs a hostname which resolves to the MiniIO container.</p><p>Within your docker-compose.yml file, you will need to change this line:</p><pre tabindex="0" data-language="plaintext"><code><span><span>PEERDB_CLICKHOUSE_AWS_CREDENTIALS_AWS_ENDPOINT_URL_S3: http://host.docker.internal:9001</span></span>
<span><span></span></span></code></pre><p>To a real and accessible IP address where MinIO is running:</p><pre tabindex="0" data-language="plaintext"><code><span><span>PEERDB_CLICKHOUSE_AWS_CREDENTIALS_AWS_ENDPOINT_URL_S3: http://172.31.26.57:9001</span></span>
<span><span></span></span></code></pre><p>If running on AWS, you may also need to open a security group port.</p><p>Secondly, we experienced a number of issues relating to Docker Snap on Ubuntu.  This included containers in Docker compose not being able to connect to each other, and not being able to write to our external EBS volume.  Ensure that you have setup Docker following the instructions on their website for an easier time with PeerDB open source.</p><p>Aside from these gotchas, the Open Source PeerDB version was relatively easy to deploy and run and we found a single instance to be scalable to millions of rows with low latency.</p><h2 id="conclusion">Conclusion</h2><p>PostgreSQL and ClickHouse are highly complementary technologies for transactional and analytical workloads.</p><p>Though there are various options for ETL and CDC between these two databases, PeerDB is now the natural choice considering it’s performance and their recent acquisition by ClickHouse Inc.</p><p>In this article we have introduced core concepts and demonstrated how PeerDB can be deployed as part of an open source and self managed stack.</p><p>In the <a href="https://benjaminwootton.com/insights/clickhouse-peerdb-clickpipes-postgrescdc/">next article</a> we describe how the same can be achieved with a fully managed cloud hosted solution.</p> </div></div>
  </body>
</html>
