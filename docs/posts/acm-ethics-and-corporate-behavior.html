<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://cacm.acm.org/magazines/2022/3/258894-acm-ethics-and-corporate-behavior/fulltext">Original</a>
    <h1>ACM, Ethics, and Corporate Behavior</h1>
    
    <div id="readability-page-1" class="page"><div id="container">
<div id="layout">

<section>



<hr/>
<div id="articleFullText">



<div id="asset-42319">
<figure>
<img alt="CACM Senior Editor Moshe Y. Vardi" src="https://cacm.acm.org/system/assets/0004/2319/021622_Moshe-Vardi.large.jpg?1645021829&amp;1645021828" title="CACM Senior Editor Moshe Y. Vardi"/>
</figure>
</div>


<p>Everyone in computing is promoting ethics these days. The Vatican has issued the <em>Rome Call for AI Ethics</em>, which has been endorsed by many organizations, including tech companies. Facebook (now Meta) has donated millions of U.S. dollars to establish a new Institute for Ethics in Artificial Intelligence at the Technical University of Munich, since &#34;ensuring the responsible and thoughtful use of AI is foundational to everything we do.&#34;<sup><a href="#FNA">a</a></sup> Google announced it &#34;is committed to making progress in the responsible development of AI.&#34;<sup><a href="#FNB">b</a></sup> And last, but not least, ACM now requires nominators and endorsers of ACM award candidates attest that &#34;To the best of my knowledge, the candidate … has not committed any action that violates the ACM Code of Ethics and ACM&#39;s Core Values.&#34;</p>
<p>But AI technology is the fundamental technology that underlies <em>&#34;Surveillance Capitalism,&#34;</em> defined as an economic system centered on the commodification of personal data with the core purpose of profit-making. Under the mantra of &#34;Information wants to be free,&#34; several tech companies have turned themselves into advertising companies. They have also perfected the technology of micro-targeted advertising, which matches ads with individual preferences. In Silicon Valley lingo, this business model is described as, &#34;If you&#39;re not paying for it, you&#39;re the product.&#34; Shoshana Zuboff argued<sup><a href="#FNC">c</a></sup> eloquently about the societal risk posed by surveillance capitalism. &#34;We can have democracy,&#34; she wrote, &#34;or we can have a surveillance society, but we cannot have both.&#34; Internet companies have mastered the art of harvesting the grains of information we share with them, using them to construct heaps of information about us. And just as the grains of information are turned into a heap of information about us, the grains of influence that Internet companies give us result in a heap of influence we are not aware of, as we learned from the Cambridge Analytica scandal. All of this is enabled by machine learning that maps user profiles to advertisements. AI is also used to moderate content for social-media users with a primary goal of maximizing user engagement, and, as a consequence, advertising revenues. </p>
<p>Surveillance capitalism is perfectly legal, and enormously profitable, but it is unethical, many people believe,<sup><a href="#FND">d</a></sup> including me. After all, the ACM Code of Professional Ethics<sup><a href="#FNE">e</a></sup> starts with &#34;Computing professionals&#39; actions change the world. To act responsibly, they should reflect upon the wider impacts of their work, consistently supporting the public good.&#34; It would be extremely difficult to argue that surveillance capitalism supports the public good.</p>
<p>The tension between an unethical business model and a façade of ethical behavior creates unsustainable tension inside some of these companies. In December 2020, Timnit Gebru, a computer scientist who works on algorithmic bias, was the center of a public controversy stemming from her abrupt and contentious departure from Google as technical co-lead of the Ethical Artificial Intelligence Team, after higher management requested she withdraw an as-yet-unpublished paper, which detailed multiple risks and biases of large language models, or remove the names of all Google co-authors. This management request was described by many Googlers as &#34;an unprecedented research censorship.&#34;<sup><a href="#FNF">f</a></sup> In the aftermath of Gebru&#39;s dismissal, Google fired Margaret Mitchell, another top researcher on its AI ethics team. In response to these firings, the ACM Conference for Fairness, Accountability, and Transparency (FAccT) decided to suspend its sponsorship relationship with Google, stating briefly that &#34;having Google as a sponsor for the 2021 conference would not be in the best interests of the community.&#34;</p>
<p>The biggest problem that computing faces today is not that AI technology is unethical—though machine bias is a serious issue—but that AI technology is used by large and powerful corporations to support a business model that is, arguably, unethical. Yet, with the exception of FAccT, I have seen practically no serious discussion in the ACM community of its relationship with surveillance-capitalism corporations. For example, the ACM Turing Award, ACM&#39;s highest award, is now accompanied by a prize of US$1 million, supported by Google.</p>
<p>Furthermore, the issue is not just ACM&#39;s relationship with tech companies. We must also consider how we view officers and technical leaders in these companies. Seriously holding members of our community accountable for the decisions of the institutions they lead raises important questions. How do we apply the standard of &#34;have not committed any action that violates the ACM Code of Ethics and ACM&#39;s Core Values&#34; to such people? It is time for us to have difficult and nuanced conversations on responsible computing, ethics, corporate behavior, and professional responsibility.</p>

<p><a href="#PageTop">Back to Top</a></p>

<div id="article-authorinfo"><h3>Author</h3>
<p><strong>Moshe Y. Vardi</strong> (<a href="mailto:vardi@cs.rice.edu">vardi@cs.rice.edu</a>) is University Professor and the Karen Ostrum George Distinguished Service Professor in Computational Engineering at Rice University, Houston, TX, USA. He is the former Editor-in-Chief of <em>Communications.</em></p>
</div>

<p><a href="#PageTop">Back to Top</a></p>



<div id="article-permission">
<hr/><p>Copyright held by author.</p>
</div>

<p>The Digital Library is published by the Association for Computing Machinery. Copyright © 2022 ACM, Inc.</p>


<hr/>

<p>
No entries found
</p>

</div>

<a href="https://cacm.acm.org/magazines/2022/3/258894-acm-ethics-and-corporate-behavior/%20"></a>
</section>

</div>
</div></div>
  </body>
</html>
