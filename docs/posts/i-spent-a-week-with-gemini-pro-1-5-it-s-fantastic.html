<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://every.to/chain-of-thought/i-spent-a-week-with-gemini-pro-1-5-it-s-fantastic">Original</a>
    <h1>I Spent a Week with Gemini Pro 1.5–It&#39;s Fantastic</h1>
    
    <div id="readability-page-1" class="page"><div>
    <div>
    <h4>Sponsored By: Destiny</h4>
    <div>
<h5><p>﻿<span contenteditable="false"><a href="https://destiny.xyz/every" target="_blank" data-advertisement-id="596"><img src="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/advertisements/596/optimized_Every%20.png"/></a></span>﻿</p></h5>
<h5>Own game-changing companies</h5>
<p>Venture capital investing has long been limited to a select few—until now. </p>
<p>With the <a href="https://destiny.xyz/every" rel="noopener noreferrer" target="_blank" data-advertisement-id="596">Destiny Tech100 (DXYZ)</a> , you&#39;ll be able to invest in top private companies like OpenAI and SpaceX from the convenience of your brokerage account. </p>
<p><a href="https://destiny.xyz/every" rel="noopener noreferrer" target="_blank" data-advertisement-id="596"><strong><u>Claim your free share</u></strong></a> before it lists on the NYSE. Sponsored by Destiny.</p>



</div>
    
</div>
<p>I got access to Gemini Pro 1.5 this week, a new private beta LLM from Google that is significantly better than previous models the company has released. (This is not the same as the publicly available version of Gemini that made headlines for <a href="https://www.theverge.com/2024/2/21/24079371/google-ai-gemini-generative-inaccurate-historical" rel="noopener noreferrer" target="_blank">refusing to create pictures of white people</a>. That will be forgotten in a week; this will be relevant for months and years to come.)</p><p>Gemini 1.5 Pro read an entire novel and told me in detail about a scene hidden in the middle of it. It read a whole codebase and suggested a place to insert a new feature—with sample code. It even read through all of my highlights on reading app Readwise and selected one for an essay I’m writing.</p><p>Somehow, Google figured out how to build an AI model that can comfortably accept up to <em>1 million tokens</em> with each prompt. For context, you could fit all of Eliezer Yudkowsky’s 1,967-page opus <em>Harry Potter and the Methods of Rationality </em>into <em>every message</em> you send to Gemini. (Why would you want to do this, you ask? For science, of course.)</p><p>Gemini Pro 1.5 is a serious achievement for two reasons: </p><p>1) <strong>Gemini Pro 1.5’s context window is far bigger than the next closest models. </strong>While Gemini Pro 1.5 is comfortably consuming entire works of rationalist doomer fanfiction, GPT-4 Turbo can only accept 128,000 tokens. This is about enough to accept Peter Singer’s comparatively slim 354-page volume <em>Animal Liberation, </em>one of the founding texts of the effective altruism movement.  </p><p>Last week GPT-4’s context window seemed big; this week—after using Gemini Pro 1.5—it seems like an amount that would curl Derek Zoolander’s hair:</p><p><a href="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/2987/optimized_SKrl7Ap8_CshyMPZzU6g5BYJQiO4qovUOxHxtEwsnMKgt3hyE62jLlphOGOnymq3IWijCRw52Qa2CHLCV0P2ayN_vW0Ty3vKQCvEHUJjyMTwFDwOlRTmvu3vzELxeBX3KmMyk0rEGD3-OJbprsbWClo.jpeg?link=true" target="_blank"><img src="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/2987/optimized_SKrl7Ap8_CshyMPZzU6g5BYJQiO4qovUOxHxtEwsnMKgt3hyE62jLlphOGOnymq3IWijCRw52Qa2CHLCV0P2ayN_vW0Ty3vKQCvEHUJjyMTwFDwOlRTmvu3vzELxeBX3KmMyk0rEGD3-OJbprsbWClo.jpeg"/></a></p><p>﻿2) <strong>Gemini Pro 1.5 can use the whole context window. </strong>In my testing, Gemini Pro 1.5 handled huge prompts wonderfully. It’s a big leap forward from current models, whose performance degrades significantly as prompts get bigger. Even though their context windows are smaller, they don’t perform well as prompts approach their size limits. They tend to forget what you said at the beginning of the prompt or miss key information located in the middle. This doesn’t happen with Gemini.</p><p>These context window improvements are so important because they make the model smarter and easier to work with out of the box. It might be possible to get the same performance from GPT-4, but you’d have to write a lot of extra code in order to do so. I’ll explain why in a moment, but for now you should know: Gemini means you don’t need any of that infrastructure. It just works.</p><p>Let’s walk through an example, and then talk about the new use cases that Gemini Pro 1.5 enables. </p><div>
    
    <div>
<p>VC investing has traditionally been reserved to a privileged few. But now <a href="https://destiny.xyz/every" rel="noopener noreferrer" target="_blank" data-advertisement-id="596">Destiny Tech100 (DXYZ)</a> is changing that. You can own a piece of groundbreaking private companies such as OpenAI and SpaceX, all from the convenience of your brokerage account. Claim your free share before it hits the NYSE. Sponsored by Destiny.</p>



</div>
    
</div>
<h2>Why size matters (when it comes to a context window)</h2><p>I’ve been reading Chaim Potok’s 1967 novel, <em>The Chosen. </em>It features a classic enemies-to-lovers storyline about two Brooklyn Jews who find friendship and personal growth in the midst of a horrible softball accident. (As a Jew, let me say that yes, “horrible softball accident” is the most Jewish inciting incident in a book since Moses parted the Red Sea.)  </p><p>In the book, Reuven Malter and his Orthodox yeshiva softball team are playing against a Hasidic team led by Danny Saunders, the son of the rebbe. In a pivotal early scene, Danny is at bat and full of rage. He hits a line drive toward Reuven, who catches the ball with his face. It smashes his glasses, spraying shards of glass into his eye and nearly blinding him. Despite his injury, Reuven catches the ball. The first thing his teammates care about is not his eye or the traumatic head injury he just suffered—it’s that he made the catch.</p><p>If you’re a writer like me and you’re typing an anecdote like the one I just wrote, you might want to put into your article the quote from one of Reuven’s teammates right after he caught the ball to make it come alive.</p><p>If you go to ChatGPT for help, it’s not going to do a good job initially: </p><p><a href="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/2987/optimized_5m9XaeCjJatECMsZPWfHiETRxcnEuqNzAsS-7tLNXfldqs5t4B5cFb69KayzRsHqDp7ILGdT7_Bm4e2r47Rk2l157vTp-upj0hxz4Uv25qGIRbQW5CJgaxsqIqNcITFUT4IcVxRaY8UF8yAK2Yz7nUg.png?link=true" target="_blank"><img src="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/2987/optimized_5m9XaeCjJatECMsZPWfHiETRxcnEuqNzAsS-7tLNXfldqs5t4B5cFb69KayzRsHqDp7ILGdT7_Bm4e2r47Rk2l157vTp-upj0hxz4Uv25qGIRbQW5CJgaxsqIqNcITFUT4IcVxRaY8UF8yAK2Yz7nUg.png"/></a></p><p>This is wrong. Because, as I said, Sydney Goldberg did not care about Reuven’s injury—he cared about the game! But all is not lost. If you give ChatGPT a plain text version of <em>The Chosen</em> and ask the same question, it’ll return a great answer:</p><p><a href="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/2987/optimized_RzVSwQXYEzkc1-jRgMbJI0w_MORMnpOxiUxuFsor9W8aQc89Kg2rNQwUbISr2tZYhoMoY3ytH3PzyChjzWCAeosSW-gSs3-cQ7eWVmKGoOVJWBYajK2sq_pSAY7-VWKT5nEYvCc7AhirdVZo8tkDOV4.png?link=true" target="_blank"><img src="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/2987/optimized_RzVSwQXYEzkc1-jRgMbJI0w_MORMnpOxiUxuFsor9W8aQc89Kg2rNQwUbISr2tZYhoMoY3ytH3PzyChjzWCAeosSW-gSs3-cQ7eWVmKGoOVJWBYajK2sq_pSAY7-VWKT5nEYvCc7AhirdVZo8tkDOV4.png"/></a></p><p>This is correct! (It also confirms for us that Sydney Goldberg has his priorities straight.) So what happened?</p><p>ChatGPT behaved as if I’d given it an open-book test. We can improve ChatGPT’s responses by, when asking it a question, giving it a little notecard with some extra information that it might use to answer it. </p><p>In this case we gave it an entire book to read through. But you’ll notice a problem: The entire book can’t fit into ChatGPT’s context window. So how does it work?</p><p>In order to answer my question, there’s a lot of code in ChatGPT that performs <strong>retrieval</strong>: It divides <em>The Chosen</em> up into small chunks through which it searches to find ones that seem relevant to the query. The retrieval code passes the original question, “What’s the first thing that Sydney Goldberg says to Reuven after he gets hit in the eye by the baseball?” <em>and</em> the most relevant sections of text it can find in the book to GPT-4, which produces an answer. (For a more detailed explanation, <a href="https://every.to/chain-of-thought/how-to-build-a-chatbot-with-gpt-3?sid=35036" rel="noopener noreferrer" target="_blank">read this piece</a>.)</p><p>Again, we have to pass GPT-4 <em>chunks</em> of text—not the whole book—because GPT-4 can only fit so much text into its context window. If you’re paying attention, you’ll see the problem: Because the context window is so small, the performance of our model for answering certain kinds of queries is bottle-necked by how good we are at searching for relevant pieces of information to give to the model. (I wrote about this phenomenon about a year ago <a href="https://every.to/chain-of-thought/gpt-4-is-a-reasoning-engine" rel="noopener noreferrer" target="_blank">in this piece</a>.)</p><p>If our search functionality doesn’t turn up relevant text chunks, well, GPT-4’s answer won’t be good. It doesn’t matter how smart GPT-4 is—it’s only as good as the chunks we turn up.</p><p>Let’s say we’re picking up <em>The Chosen</em> after a few weeks. We’ve read the first two sections, and before we begin the third we want to get a summary of what’s already happened in the book. We upload it to ChatGPT and ask it to summarize:</p><p><a href="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/2987/optimized_aiJO3PEKKuKHmxH_2-kkiz_dU--g3ziZiYLtVKnEdo0_DEW-cSQpAGanVh6zXG3hKbG9p-h0DTj7WPxBFw0xmg95Db1R0NbQcSjCJWES8ZLacB7zzJfcwK0uqP7Swn69urVtlj2Bv5mIaywHiRq1e58.png?link=true" target="_blank"><img src="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/2987/optimized_aiJO3PEKKuKHmxH_2-kkiz_dU--g3ziZiYLtVKnEdo0_DEW-cSQpAGanVh6zXG3hKbG9p-h0DTj7WPxBFw0xmg95Db1R0NbQcSjCJWES8ZLacB7zzJfcwK0uqP7Swn69urVtlj2Bv5mIaywHiRq1e58.png"/></a></p><p>ChatGPT gives us a vague answer that’s correct, but it’s not very detailed because it can’t fit enough of the book into its context window to output a great one. </p><p>Let’s see what happens when we don’t have to divide the book up into chunks.  Instead, we use Gemini, which can read through the entire book at once:</p><p><a href="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/2987/optimized_5ndXV70ZOkhbkKS_SwjPvGjuGthtO8PtByUrwwegnG6mowFMMaL7gPszZywK2evsc0dbcDcT3SGzDlRfHsC-KSJg0CgNDjMXuSZSfD-gYkcH17guW3WCsCw5VxDhbumEuRjgpgUwDiBPs1dhP5W_v2s.png?link=true" target="_blank"><img src="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/2987/optimized_5ndXV70ZOkhbkKS_SwjPvGjuGthtO8PtByUrwwegnG6mowFMMaL7gPszZywK2evsc0dbcDcT3SGzDlRfHsC-KSJg0CgNDjMXuSZSfD-gYkcH17guW3WCsCw5VxDhbumEuRjgpgUwDiBPs1dhP5W_v2s.png"/></a></p><p>You’ll notice that Gemini’s answer is significantly more detailed and provides key plot points from the book that ChatGPT can’t give. (Technically, we could probably get a similar summary out of GPT-4 if we devised a clever system for chunking and summarizing it, but it would take a lot of work, and Gemini makes that work unnecessary.)</p><p>Gemini’s use cases aren’t limited to reading novels of self-discovery through softball accidents. There are hundreds of others that it unlocks that were previously difficult to do with ChatGPT, or with a custom solution. </p><p>For example, at Every, we’re incubating a software product that can help <a href="https://twitter.com/danshipper/status/1735398395752198442" rel="noopener noreferrer" target="_blank">you organize your files with AI</a>. I wrote the original code for the file organizer, and our lead engineer, Avishek, wrote a GPT-4 integration. He wanted to know where to hook the GPT-4 integration into the existing codebase. So we uploaded it to Gemini and asked:</p><p><a href="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/2987/optimized_XR6ONC4CxNAXqwkjLonwUfQ6JM7Z5TfgaxIuxg9Vty2U9lTW3In_mYypbLbW4j6Uz_hROYJMCKvw6Dn_VYEmycnQzI0WknHp98cC1qaWJVd8mFamw8F0GRbSEPCwjeemoc-9J_qEdvD69bKpV60A-0A.png?link=true" target="_blank"><img src="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/2987/optimized_XR6ONC4CxNAXqwkjLonwUfQ6JM7Z5TfgaxIuxg9Vty2U9lTW3In_mYypbLbW4j6Uz_hROYJMCKvw6Dn_VYEmycnQzI0WknHp98cC1qaWJVd8mFamw8F0GRbSEPCwjeemoc-9J_qEdvD69bKpV60A-0A.png"/></a></p><p>It found the right place in the code and wrote the code Avishek needed in order to complete the integration. This is something just short of magic, dramatically accelerating developer productivity, especially on larger projects.</p><p>It doesn’t stop there, either. I’ve been writing for a long time about how transformer models might become <a href="https://every.to/chain-of-thought/gpt-4-a-copilot-for-the-mind?sid=35073" rel="noopener noreferrer" target="_blank">copilots for the mind</a>—and <a href="https://every.to/chain-of-thought/the-end-of-organizing?sid=35074" rel="noopener noreferrer" target="_blank">end our need to organize our notes</a> forever. Gemini Pro 1.5 is a step in that direction. For example, recently I was writing a piece about an effect I’ve noticed that I’m calling “I can do it myself” syndrome, where people tend to not use ChatGPT and similar tools because they feel like they can get the same task done more quickly, at better quality, if they do it themselves. It’s like inexperienced managers who micromanage their reports to the point of doing most of the work themselves, guaranteeing it’s done the way they want it to, but sacrificing a lot of leverage in the process. </p><p>I wanted an anecdote to open the essay with, so I asked Gemini to find one in my reading highlights. It came up with something perfect:﻿</p><p><a href="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/2987/optimized_2guBdWnLlBm7smAIdqUFYI_wGMqFBIq_Qpg04ujMgd7kl0P12I1pybXHe80ayLjaeG-2MF7AdGx74i0EcRGOqEG9tTioDP_J5BvF9QdTn-4aUG-gdIygvJQoYRZaOSfK8PCRbXlN04r8C320o3eO4vk.png?link=true" target="_blank"><img src="https://d24ovhgu8s7341.cloudfront.net/uploads/editor/posts/2987/optimized_2guBdWnLlBm7smAIdqUFYI_wGMqFBIq_Qpg04ujMgd7kl0P12I1pybXHe80ayLjaeG-2MF7AdGx74i0EcRGOqEG9tTioDP_J5BvF9QdTn-4aUG-gdIygvJQoYRZaOSfK8PCRbXlN04r8C320o3eO4vk.png"/></a></p><p>I could not have found a better anecdote, and it’s not a generic one—it’s from my own reading history and taste. </p><p><strong><em>Except, </em></strong>I later learned that<strong> </strong>the anecdote is made up. The general thrust of the idea is true—Luce did run both the editorial and business sides of Time—so it is pointing me in the right direction. But after I reviewed my Readwise highlights I couldn&#39;t find the exact quote Gemini came up with. (I only figured this out after Gwen and other savvy Hacker News commenters pointed it out in a previous version of this article.)</p><p>So, Gemini is not perfect. You do need to check its work. But if you&#39;re careful it&#39;s a powerful tool.</p><p>Again, all of this comes back to the context window. This kind of performance is only possible because with Gemini we don’t need to search for or sort relevant pieces of information before we hand it to the model. We just feed it everything we have and let the model do the rest.</p><p>It’s much easier to work with large context windows, and they can deliver far more consistent and powerful results without extra retrieval code. The question is: What’s next?</p><h2>The future of large context models</h2><p>About a year ago <a href="https://every.to/chain-of-thought/gpt-4-is-a-reasoning-engine?sid=35075" rel="noopener noreferrer" target="_blank">I wrote</a>:</p><p>“People have been saying that data is the new oil for a long time. But I do think, in this case, if you’ve spent a lot of time collecting and curating your own personal set of notes, articles, books, and highlights it’ll be the equivalent of having a topped-off oil drum in your bedroom during an OPEC crisis.”</p><p>Gemini is the perfect example of why this is true. With its large context window, all of the personal data you’ve been collecting is at the tip of your fingers ready to be deployed at the right place and the right time, in whatever task you need it for. The more personal data you have—even if it’s disorganized—the better. </p><p>There are a few important caveats to note, though:</p><p>First, this is a private beta that I can use for free. These models often perform differently (read: worse) when they are released publicly, and we don’t know how Gemini will perform when it’s tasked with operating at Google scale. There’s also no telling how much pumping 1 million tokens is going to cost into Gemini when it’s live. Over time the cost of using it will likely significantly decrease, but it will take a while.</p><p>Second, Gemini is pretty slow. Many requests took a minute or more to return, so it’s not a drop-in replacement for every LLM use case. It’s for the heavy lifting that you can’t get done with ChatGPT, which you probably don’t need to do on a regular basis. I would expect speed to increase significantly over time as well, but it’s still not there yet. </p><p>OpenAI has some catching up to do, and I’ll be watching to see how they respond. But the other players on my mind—companies like Langchain, LlamaIndex (where I’m an investor), Pinecone, and Weaviate—are to some degree betting on <em>retrieval</em> being an important component of LLM usage. They either provide the library that does the chunking and searching for information to pass to the LLM, or the datastore that keeps the information searchable and safe. As I mentioned earlier, retrieval is less relevant when you have a large context window, because you can input  all of your information into each request.</p><p>You might think those companies are in trouble. Gemini’s huge context window <em>does</em> make some of what they’re building less important for basic queries. But I think retrieval will still be important long-term. </p><p>If there’s one thing we know about humanity, it’s that our ambition scales with the tools we have available to satisfy it. If 1 million token context models become the norm, we’ll learn to fill them. Every chat prompt will include all of our emails, and all of our journal entries, and maybe a book or two for good measure. Retrieval will still be used to figure out which 1 million tokens are the most relevant, rather than what it’s used for now: to find which 1,000 tokens are the most relevant.</p><p>It’s an exciting time. Expect more experiments from me in the weeks to come!</p><hr/><p><strong><em>Dan Shipper</em></strong><em> is the co-founder and CEO of Every, where he writes the </em><a href="https://every.to/chain-of-thought" rel="noopener noreferrer" target="_blank"><em>Chain of Thought</em></a><em> column and hosts the podcast </em><a href="https://open.spotify.com/show/5qX1nRTaFsfWdmdj5JWO1G" rel="noopener noreferrer" target="_blank">How Do You Use ChatGPT?</a><em> You can follow him on X at </em><a href="https://twitter.com/danshipper" rel="noopener noreferrer" target="_blank"><em>@danshipper</em></a><em> and on </em><a href="https://www.linkedin.com/in/danshipper/" rel="noopener noreferrer" target="_blank"><em>LinkedIn</em></a><em>, and Every on X at </em><a href="https://twitter.com/every" rel="noopener noreferrer" target="_blank"><em>@every</em></a><em> and on </em><a href="https://www.linkedin.com/company/everyinc/" rel="noopener noreferrer" target="_blank"><em>LinkedIn</em></a><em>.</em></p><hr/><p><strong>Correction: </strong>An earlier version of this article did not note that the Henry Luce quote was hallucinated. It has been updated with that information.</p>
  </div></div>
  </body>
</html>
