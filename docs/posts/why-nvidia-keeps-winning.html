<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.chinatalk.media/p/why-nvidia-keeps-winning-the-rise">Original</a>
    <h1>Why Nvidia Keeps Winning</h1>
    
    <div id="readability-page-1" class="page"><div><div dir="auto"><p><a href="https://www.fabricatedknowledge.com/about" rel="">Doug O’Laughlin</a><span> is the author of </span><a href="https://www.fabricatedknowledge.com/" rel="">Fabricated Knowledge</a><span> and has been writing about the interaction between semiconductors and the AI revolution for years. In this interview, we focus on Nvidia — how it rose to prominence, its importance to the large language model revolution, and the corporate and policy implications of its trillion-dollar valuation. Do note we recorded this episode before the latest reporting around </span><a href="https://www.bloomberg.com/news/articles/2023-06-28/us-plans-new-ai-computer-chip-export-controls-aimed-at-nvidia" rel="">possible enhanced chip controls</a><span> and </span><a href="https://interconnected.blog/us-vs-china-a-cloud-proxy-war/?utm_content=buffer5b3c5&amp;utm_medium=social&amp;utm_source=twitter.com&amp;utm_campaign=buffer" rel="">cloud compute</a><span> restrictions. </span></p><p>In the conversation below, we cover:</p><ul><li><p>Nvidia’s origin in the graphics card industry, and CEO Jensen Huang’s creation of a GPU ecosystem, which set up Nvidia to become a dominant player;</p></li><li><p>How the rise of transformer models in AI benefited from Nvidia’s compute and software ecosystem, allowing for larger, more scalable models;</p></li><li><p>The absence (for now) of foreign and domestic competitors for Nvidia, especially in China;</p></li><li><p>What US export controls on Chinese hardware mean for US-China AI competition; and</p></li><li><p>The limits and opportunities that accompany China’s potential access to foreign cloud services. </p></li></ul><p><strong>Jordan Schneider:</strong><span> Let’s start with </span><a href="https://en.wikipedia.org/wiki/Jensen_Huang" rel="">Jensen Huang</a><span>, who was born in Taiwan, moved to the US in 1967 at the age of four, and later decides he wants to do computer graphics. Take us from there. Doug, what are the deep origins of Nvidia?</span></p><p><strong>Doug O’Laughlin:</strong><span> Nvidia was truly a fly-by-night thing. They knew they wanted to do graphics cards. There were a few other competitors. The company’s first name had its origin in “NV” or “next version,” the name they gave to all their files. At some point, they had to incorporate and said, “We’re going to do ‘Nvidia’ for the Latin word for ‘envy.’” </span></p><p><strong>They were always just focused on the next chips.</strong><span> The first chip they made is </span><a href="https://en.wikipedia.org/wiki/NV1" rel="">NV1</a><span> in 1995. That chip was just a low-level card for the graphics market. This was when the industry was starting to add graphical user interfaces to computers. They partnered with what is now </span><a href="https://en.wikipedia.org/wiki/STMicroelectronics" rel="">STMicroelectronics</a><span> to launch their first chip. It was okay. Then they launched their second chip, which was a little better. They skirted bankruptcy. </span></p><p><span>At this point, they’re duking it out with </span><a href="https://en.wikipedia.org/wiki/Silicon_Graphics" rel="">Silicon Graphics</a><span>, </span><a href="https://en.wikipedia.org/wiki/3dfx_Interactive" rel="">3dfx Interactive</a><span>, and </span><a href="https://en.wikipedia.org/wiki/S3_Graphics" rel="">S3 Graphics</a><span>. There are a lot of other companies, but they don’t matter because Nvidia and </span><a href="https://en.wikipedia.org/wiki/ATI_Technologies" rel="">ATI Technologies</a><span> — which later is acquired by </span><a href="https://en.wikipedia.org/wiki/AMD" rel="">AMD</a><span> — are the only two companies that make it through this intense period. There were tons of graphics cards, and Nvidia was the winner of them all.</span></p><p><strong>Around the period of 2000 to 2002, Nvidia becomes the stalwart.</strong><span> It has an amazing series of products and takes a lot of share, usually at the high end of the market. </span></p><p>That is the story of the beginning of Nvidia. It went from a tiny, fledgling, fab-less chip company to making new products and eventually winning its place market share. They became dominant and have held that position in gaming ever since.</p><p><strong>Jordan Schneider:</strong><span> Nvidia is the king of computer gaming. But that wasn’t enough for the company’s leadership, it seems. How did they take the firm to the next level?</span></p><p><strong>Doug O’Laughlin:</strong><span> Jensen has always been very vocal about accelerated compute. There’s an important shift here. I want to explain the difference between </span><a href="https://en.wikipedia.org/wiki/Parallel_computing" rel="">parallel computing</a><span> and the rest of computing. </span><a href="https://en.wikipedia.org/wiki/X86" rel="">X86</a><span> is one of the </span><a href="https://en.wikipedia.org/wiki/Central_processing_unit" rel="">CPUs</a><span> that you’re familiar with. It fetches instructions, does a job, and puts it back. They do that very quickly. GPUs, however, are specifically meant for rendering every single pixel on your screen. Each pixel, color, and location is a parallel problem. </span></p><p><span>Let’s take 1080p. There are thousands of pixels, and each pixel needs to know how to move and how to change. You can’t just do this with the CPU because it would try to calculate each individual pixel. You need a machine that is extremely wide and parallel so that it can do all these little computations at the same time. That’s how you get a </span><a href="https://en.wikipedia.org/wiki/Graphical_user_interface" rel="">graphic user interface</a><span>. </span></p><p>Those three pixels, shaders, or calculating triangles are best done by matrix multiplication, which is important for AI. The type of calculation that GPUs were meant for — the graphics processing for the highly parallel calculation of all the pixels — ends up being almost a perfect use case for the primary, heaviest part of AI computing.</p><p><strong>Jordan Schneider:</strong><span> Is it just happenstance that the GPUs that render </span><a href="https://www.youtube.com/watch?v=yR3Ftt07mDQ" rel="">Tribes II</a><span> are the same ones the deep learning revolution requires? Or is something more fundamental going on?</span></p><p><strong>Doug O’Laughlin:</strong><span> I would say it’s a mix of both. The type of processor ends up being well-suited for gaming. This market has a need that Nvidia can fulfill in the near term, and it can make money the entire way. But Jensen definitely, clearly had his eye on the ball. </span></p><p><strong>He was talking in the 2010s about accelerated computing — about how all the workloads of the world needed to be sped up. Every year he would talk about it.</strong><span> Everyone was like, “Oh, that’s pretty cool.” But every year we would never really see it happen. But Jensen, the entire time, was giving away the ecosystem.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbe679b7-39fd-46a7-8da4-fdd87cf954d6_640x427.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbe679b7-39fd-46a7-8da4-fdd87cf954d6_640x427.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbe679b7-39fd-46a7-8da4-fdd87cf954d6_640x427.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbe679b7-39fd-46a7-8da4-fdd87cf954d6_640x427.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbe679b7-39fd-46a7-8da4-fdd87cf954d6_640x427.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbe679b7-39fd-46a7-8da4-fdd87cf954d6_640x427.png" width="640" height="427" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/fbe679b7-39fd-46a7-8da4-fdd87cf954d6_640x427.png&#34;,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:427,&#34;width&#34;:640,&#34;resizeWidth&#34;:null,&#34;bytes&#34;:null,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:null,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbe679b7-39fd-46a7-8da4-fdd87cf954d6_640x427.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbe679b7-39fd-46a7-8da4-fdd87cf954d6_640x427.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbe679b7-39fd-46a7-8da4-fdd87cf954d6_640x427.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffbe679b7-39fd-46a7-8da4-fdd87cf954d6_640x427.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a><figcaption>Jensen Huang</figcaption></figure></div><p>Remember, code is not used to running on a graphics card. It has to be split into small pieces and then fed into the machine parallel.</p><p><span>There’s something called </span><a href="https://en.wikipedia.org/wiki/CUDA" rel="">CUDA</a><span>, which is software that makes code more parallel so you can put it into the GPU.</span></p><p>He started giving it away for free as much as he could to all the researchers by maybe as early as 2010. He would just give away GPUs and CUDA and make sure all the researchers were working and using GPUs. That way, they would only know how to do their problems on GPUs while optimizing their physics libraries on GPUs. </p><p><strong>Jensen had his eye on the ball and knew he was creating an ecosystem and making his product the one to use</strong><span>. He gives it away for free so everyone knows how to use it. Then everyone uses it in their workflows and optimizes around it.</span></p><p>He does this for about a decade. Jensen the whole time looks at these problems and knows these super-massive multiplication problems are the future of big data. </p><p>I don’t think that would have been a spicy opinion in the 2010s — that matrix multiplication would be used for very large data sets and hard, complicated problems; that’s not a big leap. But pursuing that path, seeing that vision, and creating the ecosystem around it — giving away a lot of it for free — is how Jensen locked in that ecosystem ten years ago.</p><p><strong>Jordan Schneider:</strong><span> How does the revolution in </span><a href="https://en.wikipedia.org/wiki/Transformer_(machine_learning_model)" rel="">transformers</a><span> connect to the compute and software ecosystem Nvidia built?</span></p><p><strong>Doug O’Laughlin:</strong><span> Transformers are a specific type of AI model. Each transformer takes a lot of data — say, a phrase or sentence used by a large language model — and puts all the information each word has into a transformer cell.</span></p><p><span>Transformers don’t perform as well as neural networks do at a small size. (</span><a href="https://en.wikipedia.org/wiki/Recurrent_neural_network" rel="">Recurrent neural networks</a><span> and </span><a href="https://en.wikipedia.org/wiki/Convolutional_neural_network" rel="">convolutional neural networks</a><span> are two examples, and there are other types of </span><a href="https://en.wikipedia.org/wiki/Artificial_neural_network" rel="">neural networks</a><span>.) </span></p><p>These transformers are the tiny, single blocks of compute that make these models possible. Training and teaching the transformer cell is a guess-and-check process. The computer guesses the outcome, and you check against the actuals. Then it just does this over and over again until it has guessed and checked everything it could within a data set. By doing this, we learn all the relationships. </p><p><span>Now we could take these relationships, and whenever you feed us new information, we can use what we’ve learned from all the information that’s been fed to us and give you a result. That’s the transformer</span><a href="https://en.wikipedia.org/wiki/Large_language_model" rel=""> LLM</a><span> breakdown. It’s guessing and checking, and lots and lots of compute.</span></p><p><strong>Jordan Schneider:</strong><span> Nvidia has two lines of revenue: gaming and data centers. How has the past quarter answered some questions about Nvidia’s long-term importance?</span></p><p><strong>Doug O’Laughlin</strong><span>: </span><a href="https://www.chinatalk.media/p/gpt-4-ai-unleashed" rel="">ChatGPT</a><span> has become a viral and meaningful product. It has millions of users, though its market penetration is still a small percentage of the total. </span></p><p><span>This AI thing has been happening for a while now. GPT-3 was good. And as you know, if you use the 3.5, it’s a very good model. But we finally hit the tipping point of it becoming a true consumer product. Once people started to consume it, they started to realize its potential. </span><strong>To be clear, it’s still very immature. But one of the things that’s important about this whole story is that we have a roadmap for AI to get better, which is rare.</strong></p><p>Transformer models improve as they get larger. Researchers have been making them larger, and they’ve been improving. We’re now at the point where we need new GPUs so we can make larger models that we know are going to be better. That’s how we’re going to improve.</p><p><span>The biggest problem — the big-ticket item — for anyone to enter the game is having a lot of GPUs. For example, there’s a private, VC-backed company called </span><a href="https://en.wikipedia.org/wiki/Anthropic" rel="">Anthropic</a><span>, and they just raised billions of dollars. They’re going to spend billions of dollars on GPUs.</span></p><p>Let’s compare AI workloads to traditional workloads. A traditional workload, like hosting a website, requires loading the website, then the website pings a web server, and then the web server tells you all the responses. These are really easy problems in terms of compute.</p><p><span>But if you look at AI, it’s totally different. Let’s say you ask AI a question. It runs your thirty-word sentence into its model. Its model has billions of parameters showing the relationships between all these words. </span><strong>Each time you run a ChatGPT query, it costs cents. That doesn’t sound like a lot, but in terms of compute, Googling doesn’t round to a cent</strong><span>. The big difference is that AI is way more compute-intensive. Not only is it compute-intensive, but we know it gets better with even more computing.</span></p><p><strong>Jordan Schneider:</strong><span> Who else needs the type of compute Nvidia is selling?</span></p><p><strong>Doug O’Laughlin:</strong><span> The big ones are Microsoft and </span><a href="https://www.chinatalk.media/p/openai-how-did-they-do-it-lessons" rel="">OpenAI</a><span>. There are also a lot of enterprises starting to put real dollars behind this. Salesforce says it will</span><a href="https://techcrunch.com/2023/06/12/salesforce-launches-ai-cloud-to-bring-models-to-the-enterprise/" rel=""> add AI</a><span> to all our workloads. </span><a href="https://en.wikipedia.org/wiki/ServiceNow" rel="">ServiceNow</a><span> is </span><a href="https://news.crunchbase.com/ai-robotics/servicenow-artificial-intelligence-enterprise-startups-investment/" rel="">investing in AI</a><span> as well. Enterprises are starting to meaningfully move forward.</span></p><p><span>Bloomberg made </span><a href="https://hub.jhu.edu/2023/05/31/ai-chatbot-speaks-finance/" rel="">BloombergGPT</a><span>, which is trained on financial data. It’s much smaller than OpenAI’s ChatGPT, but it’s better at finance because of that specialization. Everyone wants to bring their own data sets and make their own models built on their proprietary data set, which they believe will outperform publicly available competitors.</span></p><p>Nvidia even sells a managed service to train customer models. Meta is a good example. Right now most of the core investing is coming from big companies at the top trying to create solutions that can be scaled and sold to other companies and individuals. No one knows where the limits of improvement end. </p><p><strong>Right now OpenAI is clearly in the lead. But it’s so dynamic that their lead is not guaranteed. So everyone has to invest in it</strong><span>.</span></p><p><span>Sam Altman said something insane. To make OpenAI viable, they need at least </span><a href="https://www.theinformation.com/articles/openais-losses-doubled-to-540-million-as-it-developed-chatgpt" rel="">$100 billion</a><span>. That’s crazy, right? But we know that the models get better if we make them bigger. So the only way we can make them bigger is if we buy a lot more GPUs.</span></p><p><strong>Jordan Schneider:</strong><span> Nvidia can charge enormous margins because they’re largely the only game in town. But there are lots of others who have tried to design their own chips. Why are these options not as good as Nvidia’s?</span></p><p><strong>Doug O’Laughlin:</strong><span> There really is only one real competitor, and that’s Google. I just wrote a </span><a href="https://www.fabricatedknowledge.com/p/the-coming-wave-of-ai-and-how-nvidia" rel="">piece about this</a><span>. I talk about the three-headed hydra of Nvidia’s competition. </span></p><p><span>The order from smallest to largest is software, hardware, and networking. Software is really important. </span><a href="https://en.wikipedia.org/wiki/Cerebras" rel="">Cerebras</a><span> is a hardware competitor.</span></p><p>When these AI accelerator companies started to make hardware, one of the problems every single one of these companies ran into was that they didn’t have the software to support the problem. They had to build it. They had to build a software stack out of the box every single time if they wanted to do a new problem.</p><p>In that view, AI was going to be relatively fixed. People would know what the right answer would be. But the world was so dynamic. Things changed. GPUs are better than CPUs. They are flexible enough to be used for any matrix multiplication problem. A lot of companies made the bet on convolutional neural networks. But then the transformer model came and completely blew them away.</p><p>Networking is another level. These models are becoming so large — you go and buy a $40,000 GPU, but it’s still not going to be enough to train your model. It’ll take years or months to train a model across tens of thousands of GPUs. </p><p><strong><span>One issue is the </span><a href="https://link.springer.com/chapter/10.1007/978-3-319-29746-0_1" rel="">interconnect problem</a><span>. It’s not just how good the software and hardware are — it’s how good the hardware works together in a </span><a href="https://canvas.vt.edu/courses/58198/files/4550808/download?verifier=Qo0nVyKoWYU9tpyvNo3FFYtSn5eJxxLjCWbVJYdL&amp;wrap=1" rel="">big system</a><span>.</span></strong></p><p>The analogy I use is that the pizza is too big to bake in any single oven. For one cohesive model — or pizza — to be finished, you have to cut each pizza into these tiny little slices and each oven is meant to cook just that slice. Then you put them all together into this giant cohesive model.</p><p><span>There is an advantage there called </span><a href="https://en.wikipedia.org/wiki/NVLink" rel="">NVLink</a><span>, and there’s a lot of software optimization to scale up these models so they are larger than just a single GPU. Nvidia has done a really good job at that. The AI hardware companies haven’t offered a good solution.</span></p><p>Google has been at the forefront of AI research for a long time. They have a lot of the things Nvidia has, but they are custom, in-house, and proprietary. They don’t sell it as a solution. </p><p><a href="https://en.wikipedia.org/wiki/Tensor_Processing_Unit" rel="">TPUs</a><span> are their hardware, and </span><a href="https://developers.googleblog.com/2017/03/xla-tensorflow-compiled.html" rel="">XLA</a><span> is their software. They have their own </span><a href="https://cloud.google.com/network-connectivity/docs/interconnect/how-to/cci/oci/connectivity-overview" rel="">OCI networking product</a><span> with the models on top of it.</span></p><p><strong>Google right now is probably the closest real competitor that has a complete vertical full stack. </strong><span>Nvidia doesn’t have a full vertical stack because they’re not customer-facing and they don’t make the models. They make some open-source models. They improve the entire ecosystem. But they’re essentially AI as a service, and they’re trying to sell it to people who are making the models.</span></p><p><strong>Google is trying to own the entire stack — consumer to model to hardware to networking — and sell it. So far, Google has truly the most competitive, differentiated offering relative to Nvidia. But no one else has made the solutions that Nvidia does.</strong></p><p>There’s a big difference between making a theoretical chip that can solve a model and then you have to troubleshoot it — versus Nvidia, where you could buy 10,000 GPUs and it will work out of the box. That’s a big difference.</p><p>Productization — Nvidia has done a really good job at making a product to sell to customers — that’s their big differentiator. The three-headed hydra of Nvidia is hard to compete with.</p><p>We saw the AI hardware companies: they tried to make better hardware, but they couldn’t beat them. They tied them on hardware, but they couldn’t beat them on the software. We’re not even talking about the network fee.</p><p>This is the hard problem. </p><p><strong>You have to compete with them on three different fronts, and most companies are lucky to be able to compete with them on one</strong><span>.</span></p><p><strong>Jordan Schneider:</strong><span> In October 2022, the US Department of Commerce enacted </span><a href="https://www.chinatalk.media/p/new-chip-export-controls-explained" rel="">export controls</a><span> designed to stop PRC-based data centers from acquiring the kind of full-stack compute Nvidia provides. What are the implications of there being no Chinese firms that can compete with foreign compute offerings?</span></p><p><strong>Doug O’Laughlin:</strong><span> Maybe the only company I’ve heard of is </span><a href="https://en.wikipedia.org/wiki/Biren_Technology" rel="">Biren</a><span>, the GPU company. But that product is super behind. </span></p><p><span>One of the benefits is that the US seems to be ahead in the innovation game. Also, China has a GPT </span><a href="https://www.chinatalk.media/p/chinas-censors-are-afraid-of-what" rel="">censorship problem</a><span>.</span></p><p><strong>On top of that, they can’t really design the chips. </strong><span>Some aspects of </span><a href="https://en.wikipedia.org/wiki/Electronic_design_automation" rel="">EDA </a><span>have been turned off for them. And we limited the networking aspect of it. Nvidia can sell chips to China, and they do. They probably sell millions and billions of dollars worth of </span><a href="https://www.reuters.com/technology/nvidia-tweaks-flagship-h100-chip-export-china-h800-2023-03-21/" rel="">H800</a><span> — essentially a limited version of the H100 with a much worse net worth. The specs are kind of similar. It’s probably like a slower bin or something like that.</span></p><p><span>The Bureau of Industry and Security was thoughtful and said the US can give them as much hardware or as many chips as they want — but </span><strong>China can’t scale up to make these ginormous models if they don’t have the networking</strong><span>. That’s how the United States has hampered and cut off the ability of China to be even in the race. </span></p><p>I’m sure there are domestic companies that are trying to get around this problem because the chips are the same. I’m sure there’s some way to improve the networking and be able to scale it out in an even bigger, better way. It&#39;s just not going to be what is available off the chip today.</p><p><strong>It’s hard for me to imagine China competing on these large language models because they have their hands tied behind their backs. They can’t scale up to this huge amount. </strong><span>Maybe they could scale up with even more H800s, but it would cost some ridiculous number that is truly mind-boggling. That’s just in the race to buy Nvidia GPUs.</span></p><p><strong>Jordan Schneider:</strong><span> Chinese firms, however, are not restricted in accessing cloud services overseas. Nothing is stopping a Chinese company from buying top-of-the-line Nvidia compute from AWS. Does that alter the dynamic?</span></p><p><strong>Doug O’Laughlin:</strong><span> For these companies, it matters quite a bit. It’s kind of relegated China to being a consumer, a purchaser. They can only buy the IP, but they can never own it.</span></p><p><strong>Jordan Schneider:</strong><span> So Chinese firms can’t compete on hardware, but they could train their models on cloud services and then compete with Western firms? They might spend pennies on compute hoping to get dollars of revenue back.</span></p><p><strong>Doug O’Laughlin:</strong><span> Maybe hopefully they can spend pennies to get dollars. But realistically, if I had to guess, they’re going to be spending pennies to make $0.50. It’s going to come in at a lot lower margins than it used to. That’s a big deal.</span></p><p>But if China and the US are in an ideological trade war, why bother at all? It seems that we’re closer to that, so why bother. We have cut off the future of humanity.</p><p><strong>Jordan Schneider:</strong><span> This undermines Jensen’s claim that if we don’t let Chinese firms buy semiconductors, we’re going to fall behind. Chinese firms might still access compute, but instead of housing it in </span><a href="https://www.datacenterdynamics.com/en/news/chinas-netease-breaks-ground-on-data-center-in-guizhou-province/" rel="">Guizhou</a><span>, they’re just getting it from server farms in Seattle or Singapore.</span></p><p>Is the US comfortable with Chinese firms having relatively unfettered access to these hardware stacks, but just outside of the territory of the PRC?</p><p><strong>Doug O’Laughlin:</strong><span> The important part of this whole thing is latency. They can use ChatGPT, but the raw latency is going to be a lot slower than in the United States. We get to use it at a speed of about sixty milliseconds per response. For them, it might be one to two seconds. Some consumers will be able to eat that.</span></p><p><strong>Jordan Schneider:</strong><span> Hopefully AWS knows what’s going on in their servers enough to stop a </span><a href="https://mitchellaerospacepower.org/wp-content/uploads/2022/11/MI_Forum_47-Chinese-Airfields-Final.pdf" rel="">Chinese drone swarm</a><span> from invading Taiwan while relying on cloud compute in Singapore.</span></p><p><strong>Doug O’Laughlin:</strong><span> I would think they’re aware enough. But on top of that, the closer compute cluster is going to win because one’s going to be faster than the other. If you have to lease it, it’s a physical problem. If they’re renting AI models in Virginia or North Carolina, wherever the giant server farm is, that’s going to be a 600-millisecond latency versus running it locally in Taiwan. The faster one will win.</span></p><p><strong>Jordan Schneider:</strong><span> The dream is to have advanced computing directly on your PC or iPhone rather than having to access it via the cloud. Is this sort of thing a threat to Nvidia’s future?</span></p><p><strong>Doug O’Laughlin:</strong><span> The most ideal future would be for everyone to have a personal ChatGPT. It’s generalizable. That’s one of the big benefits of it. It’d be on your phone or your computer. But so far it just doesn’t seem as if that’s going to be the case.</span></p><p>There will be lower-quality imprints being done on stuff like that, where it’s dumber. You have facial recognition, for example, on your phone. That is an inference problem solved on your phone without the cloud. But the high-end, cutting-edge models are done with ginormous data sets. It’s going to take a decade or two of improvements to get to ChatGPT-4 on your phone. It’ll take about a decade to host a model of that size on your phone.</p><p><strong>Jordan Schneider:</strong><span> The CHIPS Act is about to invest tens of billions of dollars to bring fabrication to the US and help kickstart the next generation of hardware companies. What lessons should policymakers take from Nvidia?</span></p><p><strong>Doug O’Laughlin:</strong><span> This is a hard question because Nvidia’s history is somewhat due to being in the right place at the right time and creating a GPU.</span></p><p><span>Nvidia’s story reminds me of Netflix co-founder </span><a href="https://en.wikipedia.org/wiki/Reed_Hastings" rel="">Reed Hastings</a><span>. He said Netflix would ship DVDs but would also one day stream content on the Internet. That kind of long-term bet is what Jensen did long ago. It’s hard for me to imagine another company making that kind of a long-term, societally changing bet.</span></p><p>Nvidia for its entire life has been duking it out in the graphics and GPU market. The competition that happened in the US was probably good for Nvidia to improve its product and create a roadmap.</p><p>But the hard problem is that Nvidia was always a fabless company, so they got to ride on the coattails of TSMC. They were able to be so innovative on the back of TSMC by creating this open boundary for everyone. That’s the biggest lesson for policymakers.</p><p>Creating that platform at the bottom of the compute level and then enabling other companies to build on top of that is important. That’s what we’re trying to solve with this CHIPS Act.</p><p><strong>The CHIPS Act is helping. But is it enough? We’re going to see.</strong></p><p><span>There are </span><a href="https://www.networkworld.com/article/3697858/intel-looking-likely-to-manufacture-nvidia-chips.html" rel="">headlines</a><span> right now, with some talking about how Nvidia is considering </span><a href="https://en.wikipedia.org/wiki/Tape-out" rel="">taping out</a><span> at 18A for Intel, which would be a huge win for the West.</span></p><p>These GPUs are the most strategic thing policymakers could want out of compute, and they can be fabbed in the United States using Intel’s process. That would be a huge win, it’s something that people who are close to this space are all watching and waiting for. Intel’s 18A process is an important inflection node for Intel as well. </p><p><strong>The takeaway is that Nvidia was enabled by a foundry that could do everything they wanted so Nvidia could focus on the market, innovation, and design while TSMC took care of the rest. </strong><span>Having that public asset is important. </span></p><p><strong>Doug O’Laughlin:</strong><span> Jensen is one of the </span><a href="https://www.visualcapitalist.com/who-are-the-longest-serving-active-ceos-in-the-sp-500/" rel="">longest-serving public CEOs</a><span>. He founded the company in 1993. What’s amazing is that after twenty years sometimes people miss the boat and they get less good. You cannot say that about Jensen. He has definitely been on the ball the entire time. He’s been talking about accelerated compute for a decade. He’s been talking about all these societal changes.</span></p><p>Look, it’s happening. He’s been right the entire time. We should have listened. He’s been right about a long-term vision. Being able to see five to ten years in the future is rare. Jensen did it. He was always steering to this long-term target on the horizon.</p><p><strong>Jordan Schneider:</strong><span> We talked on </span><a href="https://www.chinatalk.media/p/semis-101-with-asianometry-and-fabricated" rel="">another podcast</a><span> about </span><a href="https://en.wikipedia.org/wiki/James_Gleick" rel="">James Gleick</a><span>. There should be a James Gleick chapter on Nvidia when he hopefully writes his AI book. How absurd and beautiful is it that a company built to allow teenagers to play video games and render </span><a href="https://en.wikipedia.org/wiki/Wolfenstein" rel="">Wolfenstein</a><span> ends up being the thing that ushers in an entire </span><a href="https://podcasts.apple.com/us/podcast/jeff-ding-on-us-vs-china-ai-and-lessons-from-past/id1289062927?i=1000612569365" rel="">industrial revolution</a><span>? There’s something wonderful and human about how our just wanting to play more realistic games has ended up turning into this incredible thing that’s going to change the lives of not just gamers, but everyone.</span></p><p><strong>Doug O’Laughlin:</strong><span> There’s something beautiful about play. We’re social animals.</span></p><p><span>I’m re-reading Gleick’s </span><em><a href="https://www.amazon.com/Information-History-Theory-Flood/dp/1400096235" rel="">The Information</a></em><span> because it’s very applicable. AI is a lot like an information compiler.</span></p><p><span>Jensen in one of his keynotes talks about how you can take any amount of data where there’s a relationship and put it into another form of data — text to video, video to text, text to DNA. We could ask ChatGPT right now to go write a </span><a href="https://chickenonaraft.com/" rel="">ship song</a><span> for ChinaTalk and transcode it into </span><a href="https://medium.com/@91mattmoore/chatgpt-for-bioinformatics-404c6d0817a1" rel="">DNA sequences</a><span>. We can do that.</span></p><p>We’re a little hot right now. Things are a little peaky, a little bubbly. People are freaking out a little bit. But the societal changes that come with this are going to be a big deal.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a109382-705a-4729-94cb-87e8b31f0f8f_1024x1024.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a109382-705a-4729-94cb-87e8b31f0f8f_1024x1024.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a109382-705a-4729-94cb-87e8b31f0f8f_1024x1024.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a109382-705a-4729-94cb-87e8b31f0f8f_1024x1024.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a109382-705a-4729-94cb-87e8b31f0f8f_1024x1024.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a109382-705a-4729-94cb-87e8b31f0f8f_1024x1024.png" width="410" height="410" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/3a109382-705a-4729-94cb-87e8b31f0f8f_1024x1024.png&#34;,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:1024,&#34;width&#34;:1024,&#34;resizeWidth&#34;:410,&#34;bytes&#34;:null,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:null,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null}" alt="" srcset="https://substackcdn.com/image/fetch/w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a109382-705a-4729-94cb-87e8b31f0f8f_1024x1024.png 424w, https://substackcdn.com/image/fetch/w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a109382-705a-4729-94cb-87e8b31f0f8f_1024x1024.png 848w, https://substackcdn.com/image/fetch/w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a109382-705a-4729-94cb-87e8b31f0f8f_1024x1024.png 1272w, https://substackcdn.com/image/fetch/w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3a109382-705a-4729-94cb-87e8b31f0f8f_1024x1024.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a><figcaption></figcaption></figure></div></div></div></div>
  </body>
</html>
