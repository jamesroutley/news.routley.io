<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://ashwanirathee.com/blog/2025/sort2/">Original</a>
    <h1>Sorting algorithms with CUDA</h1>
    
    <div id="readability-page-1" class="page"><article> <div id="markdown-content"> <p>Building on my previous post on sorting algorithms, I implemented the same algorithms using CUDA to explore performance improvements through parallel computing. The goal is to see how we can leverage the power of parallel computing to speed up our sorting algorithms. I went for a NVIDIA recruiting event some days ago, that was a great event and it motivated me to try to rewrite the sorting algorithms using CUDA.</p> <p>I’ll take merge sort as our test algorithm because it nicely divides the problem into smaller subproblems with two equal halves, which is a good fit for parallel computing.</p> <h2 id="basic-recursive-top-down-merge-sort">Basic Recursive Top Down Merge Sort</h2> <p>Below is the basic top down merge sort logic, where I recursively divide the array into two halves until I reach the base case of a single element, and then merge the sorted halves back together.</p> <p>To merge two sorted arrays, we compare their starting elements, pick the smaller one for the output array, and move the pointers forward.</p> <div><div><pre><code><span>MERGE_SORT</span><span>(</span><span>arr</span><span>,</span> <span>left</span><span>,</span> <span>right</span><span>)</span>
    <span>IF</span> <span>left</span> <span>&lt;</span> <span>right</span> <span>THEN</span>
        <span>mid</span> <span>←</span> <span>left</span> <span>+</span> <span>(</span><span>right</span> <span>-</span> <span>left</span><span>)</span> <span>/</span> <span>2</span>

        <span>// Recursively sort first half</span>
        <span>MERGE_SORT</span><span>(</span><span>arr</span><span>,</span> <span>left</span><span>,</span> <span>mid</span><span>)</span>

        <span>// Recursively sort second half</span>
        <span>MERGE_SORT</span><span>(</span><span>arr</span><span>,</span> <span>mid</span> <span>+</span> <span>1</span><span>,</span> <span>right</span><span>)</span>

        <span>// Merge the sorted halves</span>
        <span>MERGE</span><span>(</span><span>arr</span><span>,</span> <span>left</span><span>,</span> <span>mid</span><span>,</span> <span>right</span><span>)</span>
    <span>ENDIF</span>
<span>END</span> <span>MERGE_SORT</span>
</code></pre></div></div> <p>Now let’s look at the CPU implementation which is linked below:</p> <p><a href="https://gist.github.com/ashwanirathee/b2bd7b9ad81179b48863c4074ff0258a#file-merge_sort-cpp" rel="external nofollow noopener" target="_blank">Code: Basic Recursive Merge Sort on CPU</a></p> <h5 id="notes">Notes:</h5> <ul> <li>Function Signatures: <ul> <li> <code>void merge(uint8_t* arr, uint8_t* temp, long long left, long long mid, long long right)</code>: <ul> <li> <code>uint8_t</code> instead of <code>int</code> for the array elements is done to keep values small(0-255)</li> <li> <code>long long</code> for the indices allows for very large arrays(10^18)</li> <li> <code>uint8_t* temp</code> acts as scratch space for merge operation and give performance improvements</li> </ul> </li> <li> <code>void mergeSort(uint8_t* arr, uint8_t* temp, long long left, long long right)</code> follows pseudo code which divides the array into two halves and calls itself on those two halves. When it reaches the base case of a single element, it calls the merge function to merge the two halves back together.</li> </ul> </li> <li>GPU vs CPU sorting: <ul> <li>Arrays are generated with passed arguments with specific seed(i.e. 1)</li> <li>All implementations do nearly the same amount of work</li> <li>Merge sort result needs to be called back to the original array from GPU to CPU which is an overhead and compared with sorted array using <code>std::sort</code> from CPU</li> <li>A better comparison could be sorting random arrays on the GPU itself and comparing the results</li> <li>How we do sorting and where we do sorting matters a lot depending on the larger context of the use</li> </ul> </li> <li> <code>Wall Clock time</code> to run the whole program is used for the plots and not just the time taken to sort the array</li> <li> <code>Correctness checking</code> is done by sorting the original array by using the <code>std::sort</code> and compare the results</li> <li>Time Complexity with Average Case: O(n log n)</li> <li>Space Complexity: O(n)</li> </ul> <h4 id="basic-recursive-top-down-merge-sort-in-cuda">Basic Recursive Top Down Merge Sort in CUDA</h4> <p>Now, let’s see how we can implement this in CUDA. It follows the same pattern as the CPU implementation. It’s my first naive implementation on CUDA. The kernel is launched for each merge operation and recursion is done on CPU.</p> <p><a href="https://gist.github.com/ashwanirathee/b2bd7b9ad81179b48863c4074ff0258a#file-merge_sort-cu" rel="external nofollow noopener" target="_blank">Code: Basic Recursive Merge Sort with CUDA</a></p> <h5 id="notes-1">Notes:</h5> <ul> <li> <code>#include &lt;cuda_runtime.h&gt;</code> provides access to the CUDA Runtime API and functions like <code>cudaMalloc()</code>, <code>cudaMemcpy()</code>, <code>cudaFree()</code>, <code>kernel&lt;&lt;&lt;numBlocks, threadsPerBlock&gt;&gt;&gt;(args)</code>, <code>cudaGetErrorString()</code>, <code>cudaGetLastError()</code> </li> <li> <code>__global__ void mergeSort(uint8_t* arr, uint8_t* temp, long long left, long long right)</code> is the kernel function which is launched for each merge operation which for now does exactly the same thing as the CPU implementation</li> <li>Within <code>void mergeSort(....)</code> <ul> <li> <code>merge&lt;&lt;&lt;1, 1&gt;&gt;&gt;(...)</code> launches the kernel for each merge operation but right now just launches a single thread to do entire merge which is not efficient. <code>&lt;&lt;&lt;1,1&gt;&gt;&gt;</code> specifies the number of thread blocks and num of threads per thread block. <code>&lt;&lt;&lt;numBlocks, blockSize&gt;&gt;&gt;</code> is the syntax for launching a kernel in CUDA. Number of threads you have in total is <code>numBlocks * blockSize</code> and they can be arranged in 1D, 2D, or 3D grid.</li> <li> <code>cudaDeviceSynchronize()</code> makes it wait for this merge to complete before moving onto next stage to avoid correctness issues.</li> <li> <code>cudaMalloc(....)</code> is used to allocate memory on GPU. <code>cudaMemcpy(..., cudaMemcpyHostToDevice)</code> and <code>cudaMemcpy(...., cudaMemcpyDeviceToHost)</code> can be used to copy data between CPU and GPU.</li> <li> <code>cudaFree(cu_arr)</code> is used to free the memory on GPU.</li> </ul> </li> </ul> <h4 id="comparision-between-cpu-and-gpu-implementation-of-basic-recursive-merge-sort">Comparision between CPU and GPU implementation of basic recursive merge sort</h4> <p>This implementation is not very efficient as you can see in Figure 1, the kernel is launched for each merge operation and recursion is done on CPU. CUDA does not handle recursion efficiently, so we need to flatten the recursion into a loop.</p> <div> <div> <figure> <picture> <source srcset="/assets/img/merge_sort_comparison-480.webp 480w,/assets/img/merge_sort_comparison-800.webp 800w,/assets/img/merge_sort_comparison-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="https://jamiepalatnik.com/assets/img/merge_sort_comparison.png" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $(&#39;.responsive-img-srcset&#39;).remove();"/> </picture> </figure> </div> </div> <p>Big questions I had:</p> <ul> <li>Why does CUDA doesn’t handle recursion well? <ul> <li>Our merge function is launched as a single thread on the GPU and the recursion is done on the CPU. Deep recursion is problematic as it can lead to stack overflow given the small size of threads on the GPU. There is a non trivial kernel launch overhead for each merge operation. Recursion doesn’t allow for a lot of parallelism. Syncronization is also a problem.</li> </ul> </li> <li>How can we make things better? <ul> <li>Rewrite the recursion into an iterative loop and do bottom up merge sort.</li> </ul> </li> </ul> <p>Unlike CPU implementations, where recursion is commonly used, CUDA requires an iterative approach with careful memory management and thread synchronization to achieve optimal performance as shown in implementations below.</p> <h2 id="bottom-up-iterative-merge-sort">Bottom Up Iterative Merge Sort</h2> <p>Since CUDA does not efficiently handle recursion due to stack limitations, we implement an iterative approach for merge sort instead. Core of the iterative approach is to merge the array in a bottom up manner. We start by merging the smallest subarrays of size 1, then merge the subarrays of size 2, then 4, 8, 16, and so on.</p> <div><div><pre><code><span>MERGE_SORT</span><span>(</span><span>arr</span><span>,</span> <span>temp</span><span>,</span> <span>start</span><span>,</span> <span>end</span><span>)</span>
    <span>FOR</span> <span>sub_size</span> <span>←</span> <span>1</span> <span>TO</span> <span>end</span> <span>STEP</span> <span>2</span> <span>×</span> <span>sub_size</span> <span>DO</span>
        <span>FOR</span> <span>left</span> <span>←</span> <span>0</span> <span>TO</span> <span>end</span> <span>STEP</span> <span>2</span> <span>×</span> <span>sub_size</span> <span>DO</span>
            <span>mid</span> <span>←</span> <span>MIN</span><span>(</span><span>left</span> <span>+</span> <span>sub_size</span> <span>-</span> <span>1</span><span>,</span> <span>end</span><span>)</span>
            <span>right</span> <span>←</span> <span>MIN</span><span>(</span><span>left</span> <span>+</span> <span>2</span> <span>×</span> <span>sub_size</span> <span>-</span> <span>1</span><span>,</span> <span>end</span><span>)</span>

            <span>MERGE</span><span>(</span><span>arr</span><span>,</span> <span>temp</span><span>,</span> <span>left</span><span>,</span> <span>mid</span><span>,</span> <span>right</span><span>)</span>
        <span>ENDFOR</span>
    <span>ENDFOR</span>
<span>END</span> <span>MERGE_SORT</span>
</code></pre></div></div> <p>Now let’s look at the CPU implementation which is linked below:</p> <p><a href="https://gist.github.com/ashwanirathee/b2bd7b9ad81179b48863c4074ff0258a#file-iterative_merge_sort-cpp" rel="external nofollow noopener" target="_blank">Code: Iterative Merge Sort on CPU</a></p> <h5 id="notes-2">Notes:</h5> <div><div><pre><code><span>void</span> <span>mergeSort</span><span>(</span><span>uint8_t</span><span>*</span> <span>arr</span><span>,</span> <span>uint8_t</span><span>*</span> <span>temp</span><span>,</span> <span>long</span> <span>long</span> <span>n</span><span>)</span> <span>{</span>
    <span>long</span> <span>long</span> <span>left</span><span>,</span> <span>mid</span><span>,</span> <span>right</span><span>,</span> <span>size</span><span>;</span>
    <span>for</span> <span>(</span><span>size</span> <span>=</span> <span>1</span><span>;</span> <span>size</span> <span>&lt;</span> <span>n</span><span>;</span> <span>size</span> <span>*=</span> <span>2</span><span>)</span> <span>{</span>
        <span>for</span> <span>(</span><span>left</span> <span>=</span> <span>0</span><span>;</span> <span>left</span> <span>&lt;</span> <span>n</span> <span>-</span> <span>size</span><span>;</span> <span>left</span> <span>+=</span> <span>2</span> <span>*</span> <span>size</span><span>)</span> <span>{</span>
            <span>mid</span> <span>=</span> <span>left</span> <span>+</span> <span>size</span> <span>-</span> <span>1</span><span>;</span>
            <span>right</span> <span>=</span> <span>std</span><span>::</span><span>min</span><span>(</span><span>left</span> <span>+</span> <span>2</span> <span>*</span> <span>size</span> <span>-</span> <span>1</span><span>,</span> <span>n</span> <span>-</span> <span>1</span><span>);</span>
            <span>mergeKernel</span><span>(</span><span>arr</span><span>,</span> <span>temp</span><span>,</span> <span>left</span><span>,</span> <span>mid</span><span>,</span> <span>right</span><span>);</span>
        <span>}</span>
    <span>}</span>
<span>}</span>
</code></pre></div></div> <p>We have flattened the recursion into a loop:</p> <ul> <li> <code>Top for loop</code> increases the size from <code>1 to n</code> in <code>powers of 2</code> so we have sizes <code>1,2,4,8</code>. One might worry that what about arrays that don’t nicely fit as powers of 2, it was worry for me too and it’s handled nicely by <code>clamping the right index to the end of the array</code>.</li> <li> <code>Inner for loop</code> goes over the array in steps of 2*size and merges the subarrays of size <code>size</code> starting from <code>left</code> to <code>right</code> and <code>mid</code> is the middle of the subarray. Notice <code>right = std::min(left + 2 * size - 1, n - 1);</code> which clamps the right index to the end of the array.</li> <li> <code>mergeKernel</code> is the same as <code>merge</code> function in the recursive approach but now it’s called in a loop.</li> </ul> <h4 id="bottom-up-iterative-merge-sort-in-cuda">Bottom Up Iterative Merge Sort in CUDA</h4> <p>Major takeaway for me personally come from this implementation. In the above implementation there are two loops, so my thought was to do second loop in parallel on GPU which mainly does the merge operations in parallel for the entire array.</p> <div><div><pre><code><span>void</span> <span>mergeSort</span><span>(</span><span>uint8_t</span><span>*</span> <span>arr</span><span>,</span> <span>uint8_t</span><span>*</span> <span>temp</span><span>,</span> <span>long</span> <span>long</span> <span>n</span><span>)</span> <span>{</span>
    <span>bool</span> <span>flipflop</span> <span>=</span> <span>true</span><span>;</span>
    <span>long</span> <span>long</span> <span>numThreads</span><span>,</span> <span>gridSize</span><span>;</span>
    <span>long</span> <span>long</span> <span>size</span><span>;</span> <span>// size means the merge arrays sizes</span>
    <span>for</span> <span>(</span><span>size</span> <span>=</span> <span>1</span><span>;</span> <span>size</span> <span>&lt;</span> <span>n</span><span>;</span> <span>size</span> <span>*=</span> <span>2</span><span>)</span> <span>{</span>
        <span>numThreads</span> <span>=</span> <span>max</span><span>(</span><span>n</span> <span>/</span> <span>(</span><span>2</span> <span>*</span> <span>size</span><span>),</span> <span>(</span><span>long</span> <span>long</span><span>)</span><span>1</span><span>);</span>
        <span>gridSize</span> <span>=</span> <span>(</span><span>numThreads</span> <span>+</span> <span>THREADS_PER_BLOCK</span> <span>-</span> <span>1</span><span>)</span> <span>/</span> <span>THREADS_PER_BLOCK</span><span>;</span>
        <span>mergeKernel</span><span>&lt;&lt;&lt;</span><span>gridSize</span><span>,</span> <span>THREADS_PER_BLOCK</span><span>&gt;&gt;&gt;</span><span>(</span><span>flipflop</span> <span>?</span> <span>arr</span> <span>:</span> <span>temp</span><span>,</span> <span>flipflop</span> <span>?</span> <span>temp</span> <span>:</span> <span>arr</span><span>,</span> <span>size</span><span>,</span> <span>n</span><span>);</span>
        <span>CUDA_CHECK</span><span>(</span><span>cudaGetLastError</span><span>());</span>
        <span>CUDA_CHECK</span><span>(</span><span>cudaDeviceSynchronize</span><span>());</span>
        <span>flipflop</span> <span>=</span> <span>!</span><span>flipflop</span><span>;</span>
    <span>}</span>

    <span>if</span> <span>(</span><span>!</span><span>flipflop</span><span>)</span> <span>CUDA_CHECK</span><span>(</span><span>cudaMemcpy</span><span>(</span><span>arr</span><span>,</span> <span>temp</span><span>,</span> <span>n</span> <span>*</span> <span>sizeof</span><span>(</span><span>uint8_t</span><span>),</span> <span>cudaMemcpyDeviceToDevice</span><span>));</span>
<span>}</span>
</code></pre></div></div> <h4 id="notes-3">Notes:</h4> <ul> <li> <code>flipflop</code> is used to keep track of which array is the final sorted array and which is the scratch space.</li> <li> <code>numThreads</code> is the number of threads we need to launch for the merge operation. <code>gridSize</code> is the number of blocks we need to launch.</li> <li>After size of the merge arrays is calculated: <ul> <li>Given the size of the merge arrays, merge happens on two subarrays of size <code>size</code>. Hence I need to launch <code>n / (2 * size)</code> threads(that 1 helps in case where size becomes bigger n/2).</li> <li> <code>gridSize</code> is calculated by dividing the number of threads by <code>THREADS_PER_BLOCK</code> and rounding up. Grid size is the number of blocks we need to launch.</li> <li>In mergeKernel we specify gridSize and THREADS_PER_BLOCK to launch the kernel. <code>mergeKernel&lt;&lt;&lt;gridSize, THREADS_PER_BLOCK&gt;&gt;&gt;(flipflop ? arr : temp, flipflop ? temp : arr, size, n);</code> notice the ternary operator to switch between the arrays where arr and temp serve as <code>ping-pong buffers</code> where based on state of flipflop we read from one and write to another.</li> <li> <code>CUDA_CHECK(cudaGetLastError());</code> and <code>CUDA_CHECK(cudaDeviceSynchronize());</code> are used to check for errors and to make sure the kernel has finished executing before moving on to the next stage.</li> </ul> </li> <li> <code>if (!flipflop) CUDA_CHECK(cudaMemcpy(arr, temp, n * sizeof(uint8_t), cudaMemcpyDeviceToDevice));</code> is used to copy the final sorted array back to the original array if the final sorted array is in the temp array.</li> </ul> <p>Now let’s look at the mergeKernel which is shown:</p> <div><div><pre><code><span>__global__</span> <span>void</span> <span>mergeKernel</span><span>(</span><span>uint8_t</span><span>*</span> <span>arr</span><span>,</span> <span>uint8_t</span><span>*</span> <span>temp</span><span>,</span> <span>long</span> <span>long</span> <span>curr_size</span><span>,</span> <span>long</span> <span>long</span> <span>n</span><span>)</span> <span>{</span>
    <span>long</span> <span>long</span> <span>index</span> <span>=</span> <span>blockIdx</span><span>.</span><span>x</span> <span>*</span> <span>blockDim</span><span>.</span><span>x</span> <span>+</span> <span>threadIdx</span><span>.</span><span>x</span><span>;</span>
    <span>long</span> <span>long</span> <span>left</span> <span>=</span> <span>2</span> <span>*</span> <span>curr_size</span> <span>*</span> <span>index</span><span>;</span>
    <span>if</span> <span>(</span><span>left</span> <span>&gt;=</span> <span>n</span><span>)</span> <span>return</span><span>;</span> 

    <span>long</span> <span>long</span> <span>mid</span> <span>=</span> <span>min</span><span>(</span><span>left</span> <span>+</span> <span>curr_size</span> <span>-</span> <span>1</span><span>,</span> <span>n</span> <span>-</span> <span>1</span><span>);</span>
    <span>long</span> <span>long</span> <span>right</span> <span>=</span> <span>min</span><span>(</span><span>left</span> <span>+</span> <span>2</span> <span>*</span> <span>curr_size</span> <span>-</span> <span>1</span><span>,</span> <span>n</span> <span>-</span> <span>1</span><span>);</span>

    <span>long</span> <span>long</span> <span>i</span> <span>=</span> <span>left</span><span>,</span> <span>j</span> <span>=</span> <span>mid</span> <span>+</span> <span>1</span><span>,</span> <span>k</span> <span>=</span> <span>left</span><span>;</span>

    <span>///.... below is the good old merge logic</span>
<span>}</span>
</code></pre></div></div> <h4 id="notes-4">Notes:</h4> <ul> <li>It took me a ton of time to understand the indexing and how to launch the kernel for the merge operation properly. I launch 1d grids and 1d blocks. <code>blockIdx.x</code> gives the block index which could be 1,2,3,4,… and then <code>blockDim.x</code> specifies the number of threads in a block. <code>blockIdx.x * blockDim.x</code> after we add it <code>threadIdx.x</code>(0 to THREADS_PER_BLOCK-1) gives the index of the thread globally where each index is unique.</li> <li>Now we are able to uniquely identify our thread globally, we want to give it a <code>unique subproblem</code> depending on this <code>index</code>. We now shift our focus on calculating the <code>left</code>, <code>mid</code>, and <code>right</code> indices for the subarray we want to merge. We have a array of size n, each thread is supposed to deal with subproblems of size <code>2 * curr_size</code> starting from <code>left</code> to <code>right</code>.</li> <li> <code>Most Important question</code>: how many indexes I have? index= <code>blockIdx.x * blockDim.x + threadIdx.x</code> and if the blockIdx.x is 0 and threadIdx.x is 0, we have minimum index as 0. We know max blockIdx.x is gridSize-1. So the maximum index is <code>(gridSize-1) * blockDim.x + blockDim.x - 1</code> creating <code>gridSize * blockDim.x -1</code> as max. If we replace gridSize with <code>numThreads + THREADS_PER_BLOCK -1 / THREADS_PER_BLOCK</code> and blockDim.x with <code>THREADS_PER_BLOCK</code>, we get <code>numThreads + THREADS_PER_BLOCK - 2</code>. So the maximum index is approximately <code>n / 2 × curr_size​</code> to cater to our subproblems with some extra threads.</li> <li>Given we have indexes from 0 to <code>n/2 * curr_size</code>, we can calculate the <code>left index</code> as <code>2 * curr_size * index</code> which roughly covers all of the array. If we have <code>left &gt;= n</code> we return as we have covered the whole array. There was an interesting edge case where this left was previously an <code>int</code> leading to overflow and I had to change it to <code>long long</code>, I found that error with <code>compute-sanitizer</code> and using debug symbols by using <code>-g -G</code> while compiling with nvcc.</li> <li>After we find <code>left</code>, <code>mid</code>, <code>right</code>, it’s the same old merge logic.</li> <li>I tried with different values of <code>THREADS_PER_BLOCK</code> but results were almost the same.</li> </ul> <h3 id="results">Results</h3> <p>We defined the task of generating the random arrays on CPU, doing sorting on CPU/GPU and then comparing with the standard sorting method <code>std::sort</code> on CPU.</p> <ul> <li>Bottom-up iterative merge sort in CUDA significantly improves efficiency by parallelizing merge operations</li> <li>It’s not unexpected to see that <code>CPU approaches</code> do better for smaller arrays for the overall wall clock times of the program.</li> <li> <code>thrust::sort</code> comes out to be better than my implementations for larger arrays where <code>GPU iterative method</code> is <code>reasonably competitive</code> while recursive approach is way behind.</li> <li> <code>CPU</code> approaches i.e. recursive and iterative are very competitive with <code>std::sort</code> </li> <li>10^7 is the tipping point where the GPU sort with <code>thrust::sort</code> beats the standard sorting on CPU and my implementation <code>GPU iterative</code> comes very close too.</li> <li>The overhead for sending the data to the GPU and bringing back data from GPU is likely the cause for the time difference between CPU and GPU approaches for size 10^1 to 10^4.</li> </ul> <div> <div> <figure> <picture> <source srcset="/assets/img/merge_sort_comparison_iterative-480.webp 480w,/assets/img/merge_sort_comparison_iterative-800.webp 800w,/assets/img/merge_sort_comparison_iterative-1400.webp 1400w," type="image/webp" sizes="95vw"/> <img src="https://jamiepalatnik.com/assets/img/merge_sort_comparison_iterative.png" width="100%" height="auto" loading="eager" onerror="this.onerror=null; $(&#39;.responsive-img-srcset&#39;).remove();"/> </picture> </figure> </div> </div> <h3 id="conclusion-and-future-work">Conclusion and Future Work</h3> <p>I learned a lot about merge sort which had elluded me for a very long time. This simple algorithm also gave a very nice opportunity to learn the basics of CUDA with medium difficulty. There are several things that I could have done better and I would like to explore in the future:</p> <ul> <li>Define the tasks better or more tasks where goals could be: <ul> <li>Things need to start from CPU and endup on the GPU only for further computation or vice versa</li> <li>Things need to start and end on the individual devices only.</li> <li>Things need to start on GPU and go to CPU for further computation.</li> </ul> </li> <li>Attempt implementing <code>Parallel Merge Sort</code> as suggested by <code>Prof Rezaul</code> at <code>SBU</code> in references [1]</li> <li>Compare way bigger arrays going from <code>10^7 to 10^18</code> and <code>stress testing</code> how much sorting we can do on either of the devices.</li> <li>Optimize further for performance on GPU by using <code>shared memory</code>, using <code>thrust:sort</code> at <code>specific level</code> in combination with my implementation like we do long multiplication in the karatsuba algorithm for size of n &lt; 20 as I was taught in <code>CSE 201</code> by <code>Prof Sesh</code>.</li> <li>Utilize the threads in CPU implementations to see if that can be useful for improving performance.</li> <li>Compare the effects of using different sizes of <code>THREAD_PER_BLOCK</code> and maybe rather than each thread solving 1 subproblems, <code>each threads solve more than 1 subproblems</code> given we are waiting till all threads finish.</li> </ul> <h3 id="references">References:</h3> <ul> <li><a href="https://www3.cs.stonybrook.edu/~rezaul/Spring-2019/CSE613/CSE613-lecture-7.pdf" rel="external nofollow noopener" target="_blank">Prof Rezaul&#39;s Notes on Parallel Algorithms</a></li> <li><a href="https://www.geeksforgeeks.org/merge-sort/" rel="external nofollow noopener" target="_blank">GeeksForGeeks: MergeSort</a></li> <li><a href="https://developer.nvidia.com/blog/even-easier-introduction-cuda/%0A" rel="external nofollow noopener" target="_blank">NVIDIA&#39;s Introduction to CUDA by Mark Harris</a></li> <li><a href="https://www.youtube.com/watch?v=_XOZ2IiP2nw" rel="external nofollow noopener" target="_blank">MergeSort Explanation on Youtube</a></li> </ul> </div> </article></div>
  </body>
</html>
