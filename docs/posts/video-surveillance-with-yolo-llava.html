<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/PsyChip/machina">Original</a>
    <h1>Video Surveillance with YOLO&#43;llava</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto">CCTV viewer with realtime object tagger [WIP]</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/PsyChip/machina/blob/main/demo.png"><img src="https://github.com/PsyChip/machina/raw/main/demo.png" alt="partial screenshot"/></a></p>

<ul dir="auto">
<li><a href="https://llava-vl.github.io" rel="nofollow">LLAVA</a></li>
<li><a href="https://github.com/ultralytics/ultralytics">YOLO 11</a></li>
<li><a href="https://opencv.org" rel="nofollow">OpenCV</a></li>
</ul>

<p dir="auto">Simply it connects to a high-resolution RTSP stream in a separate thread,
queues the frames into memory as it is and resamples it for processing.</p>
<p dir="auto">YOLO takes this frame, application gives a specific id based on it&#39;s coordinates,
size and timestamp then tries to match the same object on every iteration.</p>
<p dir="auto">Another thread runs in background, iterates that object array continuously and
makes LLM requests to Ollama server for object tagging</p>

<p dir="auto">It calculates the center of every detection box, pinpoint on screen and gives 16px
tolerance on all directions. Script tries to find closest object as fallback and
creates a new object in memory in last resort.
You can observe persistent objects in <code>/elements</code> folder</p>

<p dir="auto">Every input frame resampled to 640x480 for processing, got avg 20ms interference time
with yolo 11 small model (yolo11s.pt) on Geforce GTX 1060 which is almost 7 years old
graphics card. Other models available in &#34;models&#34; directory</p>
<p dir="auto">Stream delays by 1-2 seconds on every 10~ minutes due to network conditions, script also
have a frame skip mechanism on 3 seconds of detection idle.</p>

<ul dir="auto">
<li>Clone the repository</li>
<li>Install <a href="https://ollama.com/" rel="nofollow">ollama</a> server</li>
<li>Pull the LLAVA model by running <code>ollama run llava</code></li>
<li>Open <code>app.py</code> and set your rtmp stream address at line 18</li>
<li>Install the dependencies by running <code>pip install -r requirements.txt</code></li>
<li>Run the script <code>py app.py</code></li>
</ul>

<ul dir="auto">
<li>S : snapshot, actual image from input stream</li>
<li>R : start/stop recording. it records what you see.</li>
<li>Q : quit app</li>
</ul>

<p dir="auto">This is a living project, trying to create a <em>complete</em> headless security system by
taking advantage of modern vision, object detection models on my spare time.</p>
<p dir="auto">Feel free to contribute with code, ideas or even maybe a little bit donation
via ko-fi or bitcoin</p>
<p dir="auto">-<a href="https://ko-fi.com/psychip" rel="nofollow">https://ko-fi.com/psychip</a>
-BTC: bc1qlq067vldngs37l5a4yjc4wvhyt89wv3u68dsuv</p>
<p dir="auto">Created by PsyChip</p>
<ul dir="auto">
<li><a href="mailto:root@psychip.net">root@psychip.net</a></li>
</ul>
<p dir="auto">.eof</p>
</article></div></div>
  </body>
</html>
