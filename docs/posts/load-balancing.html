<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://samwho.dev/load-balancing/">Original</a>
    <h1>Load Balancing</h1>
    
    <div id="readability-page-1" class="page"><div>
        

<p>Past a certain point, web applications outgrow a single server deployment.
Companies either want to increase their availability, scalability, or both! To
do this, they deploy their application across multiple servers with a load
balancer in front to distribute incoming requests. Big companies may need
thousands of servers running their web application to handle the load.</p>
<p>In this post we&#39;re going to focus on the ways that a single load balancer might
distribute HTTP requests to a set of servers. We&#39;ll start from the bottom and
work our way up to modern load balancing algorithms.</p>
<h2 id="visualising-the-problem"><a href="#visualising-the-problem">›</a>
Visualising the problem</h2>
<p>Let&#39;s start at the beginning: a single <span>load
balancer</span> sending <span>requests</span> to a single <span>server</span>. <span>Requests</span> are being
sent at a rate of 1 request per second (RPS), and each <span>request</span> reduces in size as the <span>server</span> processes it.</p>

<p>For a lot of websites, this setup works just fine. Modern <span>servers</span> are powerful and can handle a lot of <span>requests</span>. But what happens when they can&#39;t keep up?</p>

<p>Here we see that a rate of 3 RPS causes some <span>requests</span> to get <span>dropped</span>. If
a <span>request</span> arrives at the <span>server</span> while another <span>request</span>
is being processed, the <span>server</span> will <span>drop</span> it.  This will result in an error being shown to the
user and is something we want to avoid. We can add another <span>server</span> to our <span>load
balancer</span> to fix this.</p>

<p>No more <span>dropped</span> <span>requests</span>! The way our <span>load
balancer</span> is behaving here, sending a request to each <span>server</span> in turn, is called &#34;round robin&#34; load balancing.
It&#39;s one of the simplest forms of load balancing, and works well when your <span>servers</span> are all equally powerful and your <span>requests</span> are all equally expensive.</p>

<h2 id="when-round-robin-doesn-t-cut-it"><a href="#when-round-robin-doesn-t-cut-it">›</a>
When round robin doesn&#39;t cut it</h2>
<p>In the real world, it&#39;s rare for <span>servers</span> to be
equally powerful and <span>requests</span> to be equally
expensive. Even if you use the exact same <span>server</span>
hardware, performance may differ. Applications may have to service many
different types of <span>requests</span>, and these will likely
have different performance characteristics.</p>
<p>Let&#39;s see what happens when we vary <span>request</span> cost.
In the following simulation, <span>requests</span> aren&#39;t
equally expensive. You&#39;ll be able to see this by some <span>requests</span> taking longer to shrink than others.</p>

<p>While most <span>requests</span> get served successfully, we do
<span>drop</span> some. One of the ways we can mitigate this is
to have a &#34;request queue.&#34;</p>

<p>Request queues help us deal with uncertainty, but it&#39;s a trade-off. We will
<span>drop</span> fewer <span>requests</span>,
but at the cost of some <span>requests</span> having a higher
latency. If you watch the above simulation long enough, you might notice the
<span>requests</span> subtly changing colour. The longer they go
without being served, the more their colour will change. You&#39;ll also notice that
thanks to the <span>request</span> cost variance, <span>servers</span> start to exhibit an imbalance. Queues will get
backed up on <span>servers</span> that get unlucky and have to
serve multiple expensive <span>requests</span> in a row. If
a queue is full, we will <span>drop</span> the <span>request</span>.</p>
<p>Everything said above applies equally to <span>servers</span>
that vary in power. In the next simulation we also vary the power of each
<span>server</span>, which is represented visually with a darker
shade of grey.</p>

<p>The <span>servers</span> are given a random power value, but odds
are some are less powerful than others and quickly start to <span>drop</span> <span>requests</span>. At the same
time, the more powerful <span>servers</span> sit idle most of the
time. This scenario shows the key weakness of round robin: variance.</p>
<p>Despite its flaws, however, round robin is still the default HTTP load balancing
method for <a href="https://nginx.org/en/docs/http/load_balancing.html">nginx</a>.</p>
<h2 id="improving-on-round-robin"><a href="#improving-on-round-robin">›</a>
Improving on round robin</h2>
<p>It&#39;s possible to tweak round robin to perform better with variance. There&#39;s an
algorithm called called &#34;weighted round robin&#34; which involves getting humans
to tag each <span>server</span> with a weight that dictates how
many <span>requests</span> to send to it.</p>
<p>In this simulation, we use each <span>server&#39;s</span> known power
value as its weight, and we give more powerful <span>servers</span> more <span>requests</span> as we
loop through them.</p>

<p>While this handles the variance of <span>server</span> power
better than vanilla round robin, we still have <span>request</span> variance to contend with. In practice, getting
humans to set the weight by hand falls apart quickly. Boiling <span>server</span> performance down to a single number is hard, and
would require careful load testing with real workloads. This is rarely done, so
another variant of weighted round robin calculates weights dynamically by using
a proxy metric: latency.</p>
<p>It stands to reason that if one <span>server</span> serves
<span>requests</span> 3 times faster than another <span>server</span>, it&#39;s probably 3 times faster and should receive
3 times more <span>requests</span> than the other <span>server</span>.</p>

<p>I&#39;ve added text to each <span>server</span> this time that shows
the average latency of the last 3 <span>requests</span> served.
We then decide whether to send 1, 2, or 3 <span>requests</span>
to each <span>server</span> based on the relative differences in
the latencies. The result is very similar to the initial weighted round robin
simulation, but there&#39;s no need to specify the weight of each <span>server</span> up front. This algorithm will also be able to adapt
to changes in <span>server</span> performance over time. This is
called &#34;dynamic weighted round robin.&#34;</p>
<p>Let&#39;s see how it handles a complex situation, with high variance in both <span>server</span> power and <span>request</span>
cost. The following simulation uses randomised values, so feel free to refresh
the page a few times to see it adapt to new variants.</p>

<h2 id="moving-away-from-round-robin"><a href="#moving-away-from-round-robin">›</a>
Moving away from round robin</h2>
<p>Dynamic weighted round robin seems to account well for variance in both <span>server</span> power and <span>request
</span> cost. But what if I told you we could do even better, and with a simpler
algorithm?</p>

<p>This is called &#34;least connections&#34; load balancing.</p>
<p>Because the <span>load balancer</span> sits between the
<span>server</span> and the user, it can accurately keep track
of how many outstanding <span>requests</span> each <span>server</span> has. Then when a new <span>
request</span> comes in and it&#39;s time to determine where to send it, it knows
which <span>servers</span> have the least work to do and
prioritises those.</p>
<p>This algorithm performs extremely well regardless how much variance exists.
It cuts through uncertainty by maintaining an accurate understanding of what
each <span>server</span> is doing. It also has the benefit of
being very simple to implement. For these reasons, you will find this algorithm
as the default HTTP load balancing method for AWS&#39;s load balancers. It&#39;s also
an option in nginx, and well worth experimenting with if you&#39;ve never changed
the default.</p>
<p>Let&#39;s see this in action in a similarly complex simulation, the same parameters
we gave the dynamic weighted round robin algorithm above. Again, these
parameters are randomised within given ranges, so refresh the page to see new
variants.</p>

<p>While this algorithm is a great balance between simplicity and performance, it&#39;s
not immune to <span>dropping</span> <span>requests</span>. However, what you&#39;ll notice is that the only
time this algorithm <span>drops</span> <span>requests</span> is when there is literally no more queue space
available. It will make sure all available resources are in use, and that makes
it a great default choice for most workloads.</p>
<h2 id="optimizing-for-latency"><a href="#optimizing-for-latency">›</a>
Optimizing for latency</h2>
<p>Up until now I&#39;ve been avoiding a crucial part of the discussion: what we&#39;re
optimising for. Implicitly, I&#39;ve been considering <span>dropped</span> <span>requests</span> to be
really bad and seeking to avoid them. This is a nice goal, but it&#39;s not the
metric we most want to optimise for in an HTTP <span>load
balancer</span>.</p>
<p>What we&#39;re often more concerned about is latency. This is measured in
milliseconds from the moment a <span>request</span> is created
to the moment it has been served. When we&#39;re discussing latency in this context,
it is common to talk about different &#34;percentiles.&#34; For example, the 50th
percentile (also called the &#34;median&#34;) is defined as the millisecond value for
which 50% of requests are below, and 50% are above.</p>
<p>I ran 3 simulations with identical parameters for 60 seconds and took a variety
of measurements every second. Each simulation varied only by the load balancing
algorithm used. Let&#39;s compare the medians for each of the 3 simulations:</p>

<p>You might not have expected it, but round robin has the best median latency. If
we weren&#39;t looking at any other data points, we&#39;d miss the full story.  Let&#39;s
take a look at the 95th and 99th percentiles.</p>

<p>Note: there&#39;s no colour difference between the different percentiles for each
load balancing algorithm. Higher percentiles will always be higher on the graph.</p>
<p>We see that round robin doesn&#39;t perform well in the higher percentiles.  How can
it be that round robin has a great median, but bad 95th and 99th percentiles?</p>
<p>In round robin, the state of each <span>server</span> isn&#39;t
considered, so you&#39;ll get quite a lot of <span>requests</span>
going to <span>servers</span> that are idle. This is how we get
the low 50th percentile. On the flip side, we&#39;ll also happily send <span>requests</span> to <span>servers</span> that are
overloaded, hence the bad 95th and 99th percentiles.</p>
<p>We can take a look at the full data in histogram form:</p>

<p>I chose the parameters for these simulations to avoid <span>dropping</span> any <span>requests</span>. This
guarantees we compare the same number of data points for all 3 algorithms.
Let&#39;s run the simulations again but with an increased RPS value, designed to
push all of the algorithms past what they can handle.  The following is a graph
of cumulative <span>requests</span> <span>dropped</span> over time.</p>

<p>Least connections handles overload much better, but the cost of doing that is
slightly higher 95th and 99th percentile latencies. Depending on your use-case,
this might be a worthwhile trade-off.</p>
<h2 id="one-last-algorithm"><a href="#one-last-algorithm">›</a>
One last algorithm</h2>
<p>If we <em>really</em> want to optimise for latency, we need an algorithm that takes
latency into account. Wouldn&#39;t it be great if we could combine the dynamic
weighted round robin algorithm with the least connections algorithm? The latency
of weighted round robin and the resilience of least connections.</p>
<p>Turns out we&#39;re not the first people to have this thought. Below is a simulation
using an algorithm called &#34;peak exponentially weighted moving average&#34; (or
PEWMA). It&#39;s a long and complex name but hang in there, I&#39;ll break down how it
works in a moment.</p>

<p>I&#39;ve set specific parameters for this simulation that are guaranteed to exhibit
an expected behaviour. If you watch closely, you&#39;ll notice that the algorithm
just stops sending <span>requests</span> to the leftmost <span>server</span> after a while. It does this because it figures out
that all of the other <span>servers</span> are faster, and
there&#39;s no need to send <span>requests</span> to the slowest
one. That will just result in <span>requests</span> with a
higher latency.</p>
<p>So how does it do this? It combines techniques from dynamic weighted round robin
with techniques from least connections, and sprinkles a little bit of its own
magic on top.</p>
<p>For each <span>server</span>, the algorithm keeps track of the
latency from the last N <span>requests</span>. Instead of using
this to calculate an average, it sums the values but with an exponentially
decreasing scale factor. This results in a value where the older a latency is,
the less it contributes to the sum. Recent <span>requests</span>
influence the calculation more than old ones.</p>
<p>That value is then taken and multiplied by the number of open connections to the
<span>server</span> and the result is the value we use to choose
which <span>server</span> to send the next <span>request</span> to. Lower is better.</p>
<p>So how does it compare? First let&#39;s take a look at the 50th, 95th, and 99th
percentiles when compared against the least connections data from earlier.</p>

<p>We see a marked improvement across the board! It&#39;s far more pronounced at the
higher percentiles, but consistently present for the median as well. Here we
can see the same data in histogram form.</p>

<p>How about <span>dropped</span> <span>requests</span>?</p>

<p>It starts out performing better, but over time performs worse than least
connections. This makes sense. PEWMA is opportunistic in that it tries to get
the best latency, and this means it may sometimes leave a <span>
server</span> less than fully loaded.</p>
<p>I want to add here that PEWMA has a lot of parameters that can be tweaked. The
implementation I wrote for this post uses a configuration that seemed to work
well for the situations I tested it in, but further tweaking could get you
better results vs least connections. This is one of the downsides of PEWMA vs
least connections: extra complexity.</p>
<h2 id="conclusion"><a href="#conclusion">›</a>
Conclusion</h2>
<p>I spent a long time on this post. It was difficult to balance realism against
ease of understanding, but I feel good about where I landed. I&#39;m hopeful that
being able to see how these complex systems behave in practice, in ideal and
less-than-ideal scenarios, helps you grow an intuitive understanding of when
they would best apply to your workloads.</p>
<p><strong>Obligatory disclaimer</strong>: You must always benchmark your own workloads over
taking advice from the Internet as gospel. My simulations here ignore some real
life constraints (server slow start, network latency), and are set up to display
specific properties of each algorithm. They aren&#39;t realistic benchmarks to be
taken at face value.</p>
<p>To round this out, I leave you with a version of the simulation that lets you
tweak most of the parameters in real time. Have fun!</p>
<h2 id="playground"><a href="#playground">›</a>
Playground</h2>


    </div></div>
  </body>
</html>
