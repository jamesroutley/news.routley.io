<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://montyanderson.net/writing/embeddings">Original</a>
    <h1>Embeddings, vectors, and arithmetic</h1>
    
    <div id="readability-page-1" class="page"><div><article>
    <p><a href="https://montyanderson.net/">montyanderson.net <i></i></a></p>
    
    <h2>December 2023</h2>

    <p>
        An embedding is the representation of a piece of text like a word, sentence, or paragraph. Traditionally this value is in the form of a mathematical vector - a point in space. You can think of it as analogous to coordinates on a map that just happens to have many, many dimensions.
    </p>

    <p>
        Once you have generated these embeddings, you can do all sorts of computationally cheap operations you could do on any set of vectors. Lilian Weng&#39;s project shows you a ranking of the closest emojis to your search query in meaning-space.
    </p>

    <blockquote>
        <video width="100%" autoplay="" loop="" muted="" playsinline="">
            <source src="/assets/embeddings-emoji-search.mp4" type="video/mp4"/>
            Your browser does not support the video tag.
        </video>

        <p>Lilian Weng&#39;s <a href="https://www.emojisearch.app/">Emoji Search <i></i></a></p>
    </blockquote>

    <p>
        In this example, the vector representation of every emoji has been computed in advance against OpenAI&#39;s Ada model. When you execute a search, only your new query is translated into an embedding. The results are simply the closest few emoji vectors, calculated using the euclidean distance or cosine similarity. The semantic nature of the ranking is a byproduct of the AI model&#39;s intuitive association between these related concepts.
    </p>

    <p>
        Intrigued by this, myself and Barney Hill have started to explore the idea of using arithmetic on language vectors. What does semantic addition look like? We weren&#39;t sure, so we built a simple app that lets you add two emojis and see the closest known emoji to that result.
    </p>

    <blockquote>
        <video width="100%" autoplay="" loop="" muted="" playsinline="">
            <source src="/assets/embeddings-emoji-add.mp4" type="video/mp4"/>
            Your browser does not support the video tag.
        </video>

        <p>UK + Burger = America.</p>
    </blockquote>

    <p>
        It worked mostly, remarkably well - although the model reflects many stereotypes and flaws present in the training data. At Prodia, we&#39;ve started to investigate building safety systems by checking if the input prompts are within a distance threshold of known adult or illegal concepts.
        The CompVis group have created a widely-used safety filter does something <a href="https://huggingface.co/CompVis/stable-diffusion-safety-checker">similar <i></i></a>, after first processing an image via OpenAI&#39;s Clip model.
    </p>

    <p>
        It is not hard to imagine a radically different, fuzzier future now that machines can reason about meaning deep within text. Who needs files and organisation when semantic search is deeply and widely integrated? Embeddings can be representations of many more things than text, like audio or video. Multi-modal search across many media types may not be far away.
    </p>

    <p>
        <i>To be continued.</i>
    </p>
</article> 
    </div></div>
  </body>
</html>
