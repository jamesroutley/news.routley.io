<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.thenewatlantis.com/publications/tech-strikes-back">Original</a>
    <h1>&#34;Accelerationism&#34; is an overdue corrective to years of gloom</h1>
    
    <div id="readability-page-1" class="page"><div>
          
          
<p>A new tech ideology is ascendant online. “Introducing effective accelerationism,” the pseudonymous user Beff Jezos tweeted, rather grandly, in May 2022. “E/acc” — pronounced <em>ee-ac</em><em>k</em> — “is a direct product [of the] tech Twitter schizosphere,” he wrote. “We hope you join us in this new endeavour.”</p>



<p>The reaction from Jezos’s peers was a mix of positive, critical, and perplexed. “What the f*** is e/acc,” <a href="https://twitter.com/pee_zombie/status/1556767844322492416">posted</a> multiple users. “Accelerationism is unfortunately now just a buzzword,” <a href="https://twitter.com/SamoBurja/status/1620166798057545728">sighed</a> political scientist Samo Burja, referring to a related concept <a href="https://web.archive.org/web/20180113012817/https:/jacobitemag.com/2017/05/25/a-quick-and-dirty-introduction-to-accelerationism/">popularized</a> around 2017. “I guess unavoidable for Twitter subcultures?” “These [people] are absolutely bonkers,” <a href="https://twitter.com/timnitGebru/status/1624548093701287937">grumbled Timnit Gebru</a>, an artificial intelligence researcher and activist who frequently criticizes the tech industry. “Their fanaticism + god complex is exhausting.”</p>



<p>Despite the criticism, e/acc persists, and is growing, in the tech hive mind. E/acc’s founders believe that the tech world has become captive to a monoculture. If it becomes paralyzed by a fear of the future, it will never produce meaningful benefits. Instead, e/acc encourages more ideas, more growth, more competition, more action. “Whether you’re building a family, a startup, a spaceship, a robot, or better energy policy, <em>just build</em>,” <a href="https://www.effectiveacceleration.org/posts/4LtypqdAmQ3AgKtJD/what-the-f-is-e-acc">writes</a> one anonymous poster. “Do something hard. Do it for everyone who comes next. That’s it. Existence will take care of the rest.”</p>



<p>Jezos <a href="https://www.youtube.com/watch?v=wbfviqlGy2U">admits</a> that his initial announcement was a bit of a “shitpost.” And e/acc’s perceived lack of clarity — what, exactly, are they advocating for? — makes it tempting to dismiss it. Nevertheless, it has since caught the attention of a growing number of tech figures: venture capitalist Marc Andreessen, Y Combinator president Garry Tan, Notion co-founder Chris Prucha, Intercom co-founder Ciaran Lee, and science investor and former U.S. state official Jim O’Neill, some of whom add “e/acc” to their online display names and bios as a sign of solidarity.</p>



<figure><img decoding="async" width="1280" height="783" src="https://www.thenewatlantis.com/wp-content/uploads/2024/01/Asparouhova-1-1280x783.jpg" alt="" srcset="https://www.thenewatlantis.com/wp-content/uploads/2024/01/Asparouhova-1-1280x783.jpg 1280w, https://www.thenewatlantis.com/wp-content/uploads/2024/01/Asparouhova-1-1920x1174.jpg 1920w, https://www.thenewatlantis.com/wp-content/uploads/2024/01/Asparouhova-1-640x391.jpg 640w, https://www.thenewatlantis.com/wp-content/uploads/2024/01/Asparouhova-1-1536x939.jpg 1536w, https://www.thenewatlantis.com/wp-content/uploads/2024/01/Asparouhova-1.jpg 2048w" sizes="(max-width: 1280px) 100vw, 1280px"/><figcaption>Beff Jezos, in a photo published to his Twitter feed under his real name, Guillaume Verdon, the day after it was revealed by <em>Forbes</em>.</figcaption></figure>



<p>If e/acc isn’t entirely sure yet what it is for, it does know what it’s against. One of its chief adversaries is AI safety, a field concerned with the risks of developing AI too quickly. Another, closely related, adversary is effective altruism, a utilitarian movement that aims to “do the most good” in the world. Even e/acc’s name is a jab against EA. Whereas AI safetyists follow the precautionary principle in their thinking about AI — emphasizing risk avoidance over action — effective accelerationists preach blazing forward into the unknown, arguing that we will only learn by doing.</p>



<p>But these debates don’t explain why e/acc became suddenly popular among a wider set of technologists, many of whom aren’t involved with artificial intelligence. E/acc’s significance lies in its counterbalancing force not just to AI safety, but to widespread public concerns about the risks posed by the tech industry at large. Effective accelerationists worry that these concerns have become so entrenched that they threaten to extinguish the light of tech itself.</p>


<div><div>
  
	<h5>
		AI’s Moment of Self-Doubt	</h5>
</div></div>


<p>In March 2023, the Future of Life Institute published an <a href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/">open letter</a> calling for artificial intelligence labs, such as OpenAI and Google AI, to immediately pause the development of technology more powerful than GPT-4 for at least six months. “If such a pause cannot be enacted quickly,” the letter stated, “governments should step in and institute a moratorium.” The letter also called for new systems of auditing, certification, monitoring, and regulation as AI develops.</p>



<p>The letter was initially signed by over a thousand people, many of whom were not just concerned citizens but AI technologists themselves, including Yoshua Bengio, a pioneer of artificial intelligence research; Elon Musk, one of OpenAI’s original co-founders (though he has not been involved since 2018); and Emad Mostaque, founder of Stability AI. Another statement, warning of the “risk of extinction from AI,” was published by the Center for AI Safety in May. It was signed by AI leaders at OpenAI, Anthropic, and DeepMind, as well as senior executives from Google and Microsoft.</p>



<p>Artificial intelligence is a rare domain where technologists themselves are being proactively cautious about their own power before any demonstrable harm has been done. The moral panic now comes from within — a stark deviation from how technological revolutions historically influence society, as scholar Carlota Perez documents in her seminal 2002 book <em>Technological Revolutions and Financial Capital</em>.</p>



<p>Perez looked at major technological innovations in the industrial age — including steam and railway, steel and electricity, oil and automobiles, and digital communication — and noticed that they follow a pattern. There is the initial “big bang” event that signifies a major technical breakthrough, which goes largely unnoticed at the time. Technologists, however, recognize its potential and build upon this breakthrough for decades, until it attracts wider adoption and interest. Financial capital then takes over from technologists to continue driving its development, which creates a speculative public frenzy, a financial bubble, and collapse, followed by a period of reflection and reconciliation as the technology is finally stabilized and absorbed into our social norms.</p>



<p>While Perez suggests that this cycle occurs roughly every fifty years, if we squint a bit, we can see it play out with several more-recent technological breakthroughs, such as cloud computing and smartphones — which together drove the Web 2.0 startup boom — and cryptocurrency. In each case, technologists are generally advocates, not detractors, of the opportunities they see before the rest of the world catches on.</p>



<p>Even when financial capital is not so involved, technologists have historically been fiercely protective of their right to build and distribute their work. Open-source programmers in the late 1990s and early 2000s were adamant that we should not restrict how their free and public code could be used, nor hold programmers liable for users’ decisions. Cryptographic code was once considered a form of munitions in the United States, subject to tightly controlled export laws; it was technologists who advocated for the right to share this code across national borders. When it comes to artificial intelligence, on the other hand, some technologists are skipping ahead to reflecting on its harms before the impact is clear.</p>



<p>It’s not that tech has never had a community concerned about the risks and ethics of artificial intelligence; they just weren’t the ones driving its development. AI safety has been a cottage research field for decades, championed by rationalists — an Internet community that prioritizes logical thought and eliminating cognitive bias — and effective altruists. The Machine Intelligence Research Institute, co-founded by AI researcher Eliezer Yudkowsky, began focusing on these risks in 2005. Overcoming Bias, a blog started by Yudkowsky and economist Robin Hanson the following year, was the predecessor to the forum LessWrong, which became a watering hole for people concerned about AI’s impact on society.</p>



<p>Such efforts were widely recognized and even supported by those in tech, but seemingly more from a place of symbolic goodwill — the way a prominent financier might support the arts — than serious engagement. AI safety research, and its underlying rationalist community, was a comforting reminder to wealthy entrepreneurs that tech was not just a shallow way to make money through startups, but a thoughtful, intellectual place with its own philosophical culture.</p>



<p>Since late 2022, however, when the explosive success of OpenAI’s ChatGPT made the potential of artificial intelligence suddenly visible to the public, what was once a niche subculture became an unlikely public face of the controversy over AI development. Parties previously unaffiliated with the AI safetyists suddenly became their bedfellows, such as Tristan Harris, a former Google employee and self-described “tech ethicist” who had made a name for himself by raising concerns about the harms of social media. These cautionary positions have now spread to a wider set of startup founders and engineers.</p>


<div><div>
  
	<h5>
		‘We Want the Apocalyptoids to Lose’	</h5>
</div></div>


<p>Why are so many technologists suddenly circumspect about AI development?</p>



<p>For OpenAI and other large corporate labs, this position may be partly strategic: <a href="https://www.theverge.com/2023/5/19/23728174/ai-regulation-senate-hearings-regulatory-capture-laws">some onlookers</a> grumble that these labs are working to achieve regulatory capture, courting favor with government. If nothing else, their leaders have likely learned from the wave of backlash against social media executives that it’s better to preemptively establish relationships with policymakers than to be brash. Sam Altman, the CEO of OpenAI, <a href="https://techpolicy.press/transcript-senate-judiciary-subcommittee-hearing-on-oversight-of-ai/">testified</a> before the Senate last spring that “we want to work with the government to prevent [problems] from happening.”</p>



<p>Among a wider set of technologists, the appeal of AI safety might reflect a cognitive tendency to overly formalize social problems. AI’s risks are especially frightening for those who find comfort in predicting human behavior with math rather than lived experience. Calculating these risks and designing theoretical governance structures to avoid them is itself a form of nerd sniping, visible in other places among the likes of rationalists and crypto-governance enthusiasts.</p>



<p>Or, perhaps, wanting to be regulated is a subconscious way for tech to reassure itself about its central importance in the world, which distracts from an otherwise uneasy lull in the industry. AI is the crown jewel of the tech industry at a time when the golden age of software startups has passed. Venture capital funding crashed from its frothy peak in 2022, marking a new and grueling era for startup founders. AI is a critical morale boost to rally tech’s spirits; being important enough to warrant regulatory action means its relevance won’t fade anytime soon.</p>



<p>Regardless of motivations, it’s this anomalous behavior of tech leaders to worry about their own work that effective accelerationists are reacting to. They find it strange and disheartening to see their fellow technologists so timid and docile in the face of a major new development.</p>



<p>Instead, e/accs exhort their peers to pluck up and find the courage to embrace unfamiliar territory — a stance that is often interpreted by others as reckless. Grimes, the futuristic-chic musician who also traverses tech circles, cautioned e/acc’s founders to be more thoughtful about how they express themselves. “You are freaking people out,” she <a href="https://diyhpl.us/wiki/transcripts/2023-03-12-twitter-eacc-grimes/">stated</a> in a Twitter Space discussion last March. “[It’s] causing people to panic at non-profits and agitate for government regulation…. I think that’s the kind of thing you need to be careful about and mindful of. Powerful people are watching this.”</p>



<p>While effective accelerationists can be juvenile, letting their love of memes overshadow their substance, its founders, in their serious moments, don’t advocate for willful ignorance of risks. Both Beff Jezos and Bayeslord, another pseudonymous founder, have repeatedly stated that they support efforts to align AI with human welfare — they just don’t want fear to be the primary guide of technological innovation.<em> </em>“From now on I don’t want to see a single tweet about how e/acc doesn’t want people to work on alignment,” Bayeslord <a href="https://twitter.com/bayeslord/status/1633929450231599104">declared</a>. “On the contrary, we think reliability engineering is valuable work. However, we also want the apocalyptoids and the power hungry to lose.”</p>



<p>Effective accelerationists don’t want us all to stop caring. Just the opposite: they wish that everyone cared more. They don’t want to be known for bleating platitudes about “a better future,” then airily waving away the details. Rather, their moral vision is one where more people — including and especially those who consider themselves hands-off today — actively engage with emerging technology and identify concrete plans for its development and stewardship, rather than reflexively backing away from what they don’t understand. Discussing the risks <em>and</em> opportunities in front of us intelligently, e/accs believe, is a sign of a flourishing civil society.</p>



<p>E/acc’s nemesis is not the political left, with its proclivity toward regulation. One <a href="https://twitter.com/mister_shroom/status/1689813354745942016">Twitter poll</a> asking effective accelerationists how they self-identified politically — an informal poll, but perhaps a meaningful one, given how close-knit and online the movement is so far — was split roughly evenly between left and right. “The previous culture war was between left and right,” Jezos <a href="https://twitter.com/BasedBeffJezos/status/1682307495195447296">says</a>. Now “acceleration is the only option, degrowth is death.”</p>



<p>Rather than use well-trod political labels, e/acc wants to be the alternative to what they call <em>decels</em>, for “decelerationists”: proponents of a passive, overly cautious approach to the future. Back when “disruption” was a buzzword, tech was united against this timid mindset, which it saw as the default outsider position, of those trapped in their miserable 9-to-5 cubicle jobs who could only think in terms of red tape and bureaucracy. As effective accelerationists see it, in recent years the decel attitude has crept into tech itself, and nowhere more clearly than in debates about artificial intelligence.</p>


<div><div>
  
	<h5>
		‘The Future Will Be Better’	</h5>
</div></div>


<p>If decels had a face in tech, it would be Big Tech employees, the defanged, corporatized version of the hackers and outcasts who once inspired the tech industry, now imprisoned on motivational posters aimed at self-loathing managers. This, perhaps, is something that e/accs and some tech critics can agree upon: Settling for a middling Big Tech job — chasing lavish promotions instead of making history — represents a failure to realize the promises of tech and what it sought to accomplish, which those on the frontier now want to recapture.</p>



<p>It was the tech backlash of the 2010s that tore a hole through tech’s image as it previously saw itself: a burgeoning industry composed of startups and their financiers, whose members would grind away writing code on their MacBooks and attending Y Combinator’s demo days, whose hardest decision every year was whether to go to Burning Man. Though a founder’s life was filled with highs and lows, the cycle of tech seemed stable and predictable. Most importantly, tech was beloved by the outside world, who gleefully consumed stories of young founders and their mythical overnight successes.</p>



<p>What went wrong? While tech believed it was changing the world for the better, PayPal co-founder and venture capitalist Peter Thiel warned in his 2014 book <em>Zero to One</em> that this era was marked by “indefinite optimism.” In contrast to the definite optimist, who not only articulates a vision for the future but “plans and works to make it better,” the indefinite optimist believes “the future will be better, but he doesn’t know how exactly…. He expects to profit from the future but sees no reason to design it concretely.”</p>



<p>Published at the height of tech’s infatuation with startup disruption, Thiel’s comments proved to be several steps ahead of the rest of the tech industry. While Thiel generally approved of startups as a vehicle for definite optimists to realize their goals, he criticized the incrementalist attitude that he saw creeping into Silicon Valley. Founders from this era busily copied the methodology from Eric Ries’s 2011 book <em>The</em> <em>Lean Startup</em> that emphasized iterating upon customer feedback to find the right fit between product and market. They adopted Y Combinator’s “Make something people want” motto as canon, and pitched their companies to investors within the familiar framework of “I’m building X for Y”: “eBay for space” (Airbnb), “Uber for trucking” (Convoy) and so on. Thiel was skeptical of this trend. He challenged founders to build solutions based on what they <em>wanted</em> to happen, rather than hamfistedly plastering a layer of software onto every problem in sight.</p>



<p>Silicon Valley’s indefinite optimism was equally foreshadowed by Marc Andreessen’s 2011 article “<a href="https://a16z.com/why-software-is-eating-the-world/">Why Software Is Eating the World</a>.” While the phrase is remembered as a prediction of how founders from this era would become enormously wealthy, it also captures how their success was due to riding the wave of digitization, rather than leading with definite optimism. Tech’s love of digital disruption became a running joke: whether health care, local business, or agriculture, it seemed every outmoded industry could be magically transformed by the pixie dust of software. The subsequent graveyard of startups from this period reveals a lack of understanding by founders of how these industries actually worked, and of the complex social and political forces that shape them.</p>



<p>Beyond startups, tech’s sunny naïveté extended to its relationship to society, creating resentment. There was the story of Patrick McConlogue, a software programmer living in New York, who attracted ire in 2013 when he published a Medium post explaining that he had offered Leo, a homeless man, a choice between either $100 in cash or three JavaScript books and a laptop, as well as an hour of McConlogue’s time every day to teach him how to code. Leo chose the latter, and McConlogue kept his promise and taught him how to code. They even built a ridesharing app together. But two years later, Leo was still homeless, overwhelmed by the attention he’d received, and no longer coding. Though McConlogue’s attempts were earnest, he had applied a one-size-fits-all solution and hoped for the best. When he did not succeed, there was no backup plan.</p>



<p>It was tech’s indefinite optimism that prevented it from heeding the signs of discontent swirling about, clinging to the industry like San Francisco’s fog. There were the rising rents; the commuter protests; the murmurs about how tech’s biggest accomplishments were creating a crisis of attention, loneliness, and political strife — all easily dismissed by tech workers, whose experience had taught them that even against long odds they could only ever win, until they hit a snag in the fall of 2016.</p>



<p>The outcome of the U.S. presidential election not only shocked legislators, who set about searching for answers from tech companies they believed were partly to blame for Donald Trump’s victory; it also marked the turnover of the Obama administration, which had enthusiastically supported tech’s optimism. The world had called tech’s bluff, and it turned out that behind the cheerful promises of a better future there was no real vision that would assuage the betrayal that many felt.</p>





<p>Those in tech burrowed underground to lick their wounds. As the smoke cleared, they began having private conversations with trusted peers and friends. They struggled to reconcile the sudden surge of anger from outsiders with their own internal sense of self. Over the next few years, tech experienced a profound loss of identity, followed by a search for meaning.</p>



<p>Founders and engineers are not typically known for their innate interest in “non-technical” topics like philosophy and history, but they turned now to these pursuits to make sense of their predicament. Snapchat founder and CEO Evan Spiegel, who had previously made headlines for a series of boorish emails he had sent as an undergraduate to his Stanford fraternity brothers, now stood in front of the French-American Foundation in 2017 and spoke about Alexis de Tocqueville, who, as Spiegel put it, believed that “the newspaper was one of the most important tools for helping democracy overcome individualism.”</p>



<p>Ultimately, everyone in tech was trying to answer the same question, posed for millennia by those unlucky souls who find themselves suddenly in exile: How, now, shall we live? If the brash, unchecked ambition that had defined tech for decades was no longer something to be proud of, how should technologists find meaning in their work today?</p>



<p>The varying answers to this question scattered tech workers into different factions. Many were alarmed and remorseful about the harm they had caused — to America’s social fabric, teenage mental health, and the future of the country. They now faced difficult questions from friends and family about the transgressions of their employers, and resolved to shepherd what they saw as a more responsible approach to technology, examining the effects of misinformation, algorithmic bias, and lack of content moderation. Tristan Harris, the ex-Google tech ethicist, became a vocal advocate for addressing the negative effects of social media, featuring prominently in the 2020 Netflix documentary <em>The Social Dilemma</em>.</p>



<p>Others blamed the American managerial class, whose appendages were tangled in a secular monoculture that had lost its moral and spiritual purpose. They found solace in the philosophical writings of Nick Land and a pseudonymous blogger named Mencius Moldbug, who expounded upon the idea that progressive liberal democracy is becoming an all-powerful bureaucratic oligarchy, the solution to which is a return to monarchy and traditional values. This was the beginning of the neoreactionary movement, which grew into the New Right today, and whose members, and associated figures in tech like Peter Thiel, backed anti-establishment candidates like J. D. Vance and Blake Masters in the 2022 elections.</p>



<p>Still others felt that the problem was that America no longer valued technological progress and innovation. They read economist Tyler Cowen’s 2011 book <em>The Great Stagnation</em>, which warned that the American economy had begun to plateau. In 2019, Cowen and Stripe co-founder Patrick Collison published an <em>Atlantic</em> article titled “<a href="https://www.theatlantic.com/science/archive/2019/07/we-need-new-science-progress/594946/">We Need a New Science of Progress</a>,” by which they meant a study of “the combination of economic, technological, scientific, cultural, and organizational advancement that has transformed our lives and raised standards of living over the past couple of centuries.” Their efforts fostered a movement, sometimes called “progress studies” or just “progress,” as well as its cousin movement “abundance,” whose proponents focus on removing institutional roadblocks to innovation — particularly through an economic and policy lens — such as the development of clean energy, building more housing and public works, and funding scientific research.</p>



<p>Others saw poor governance of San Francisco — which had attracted media attention for its crime, dirtiness, and political infighting — as a sign of how tech had underutilized its influence, falling out of step with its environment. The San Francisco School Board and district attorney elections became hotly contested battles as tech workers organized to support candidates who aligned with their values. Garry Tan, the Y Combinator president who grew up in a working-class Bay Area immigrant family, devoted himself to improving San Francisco’s living conditions, organizing recall campaigns, and supporting the launch of GrowSF, a political action committee founded by tech workers that focuses on reducing homelessness and improving public safety and services.</p>



<p>While each of these tribes has a different underlying philosophy and agenda, they are united by an embrace of definite, rather than indefinite, approaches. Instead of the incrementalist, “software eating the world” approach to disruption, these tech tribes are now focused on bringing about tangible, meaningful change. They also tend to have greater humility toward what they realize they don’t know. They are more likely to consult and build relationships with subject matter experts, policymakers, and researchers to inform their understanding of industries beyond their own. They are no longer afraid to get their hands dirty learning about climate science or housing materials, or approaching politicians, in order to achieve their goals.</p>



<p>For example, in tech’s indefinite era, Google’s parent company Alphabet launched Sidewalk Labs as an “urban innovation” company, which touted a project in Toronto featuring buzzy smart-city technology including sensors and touchscreens to help residents visualize energy usage and traffic patterns. The project never materialized. In today’s definite era, wealthy tech patrons want to back San Francisco’s GrowSF, which prioritizes “outcomes over ideologies” and whose plans for the city read more like a sensible agenda than a sci-fi novel: build homeless shelters, construct subway tunnels and bike lanes, and elect politicians who can get it all done.</p>



<p>Another example of the shift — or the need for it — can be seen in the work of Jennifer Pahlka. Serving as U.S. Deputy Chief Technology Officer in the Obama administration, founder of Code for America, and creator of the United States Digital Service, Pahlka was one of the most visible faces of tech’s relationship to government in the 2010s. Code for America connects software engineers and designers with city governments to build web applications; the United States Digital Service is a government tech unit that consults federal agencies on how to improve their digital services, founded partly as a response to the disastrous technical rollout of Healthcare.gov in 2013.</p>



<p>But digital tech alone was never a solution. In her 2023 book, <em>Recoding America: Why Government Is Failing in the Digital Age and How We Can Do Better</em>, Pahlka argues that people in government chronically undervalue the challenge of implementation of new digital projects, simply outsourcing them to software contractors and expecting that they mindlessly follow orders, rather than take part in the design process itself. “Although government must adapt to an increasingly digital world,” Pahlka writes, “the heart of the adaptation isn’t mobile apps, cloud computing, or even artificial intelligence.” Instead, “we have to examine and challenge the underlying structures, assumptions, and values that drive the larger system of government in which the bureaucracy of implementation operates.”</p>



<p>There was a time when indefinite optimists believed in “disruption” and “move fast and break things.” Now definite optimists believe in “progress” and “acceleration.” In the abstract, the two sets of concepts seem indistinguishable from one another. The difference is in strategy and tactics, and it is a more grounded focus on building for the future that effective accelerationists preach.</p>


<div><div>
  	<div>
	  <p><a href="https://www.thenewatlantis.com/issues/no-75-winter-2024" target="_blank" rel="noopener"><img decoding="async" loading="lazy" src="https://www.thenewatlantis.com/wp-content/uploads/2024/02/TNA75-logo-landscape.jpg" alt="" width="234" height="180" srcset="https://www.thenewatlantis.com/wp-content/uploads/2024/02/TNA75-logo-landscape.jpg 800w, https://www.thenewatlantis.com/wp-content/uploads/2024/02/TNA75-logo-landscape-640x493.jpg 640w" sizes="(max-width: 234px) 100vw, 234px"/></a></p>
<p> Keep reading our <strong>Winter 2024</strong> issue</p>
	</div>
	</div></div>





<div><div>
  
	<h5>
		‘Let’s Make an Ideology Where the Builders Are Heroes’	</h5>
</div></div>


<p>Definite optimists strive for concrete goals, but e/acc is not, at least in its current form, a prescriptive movement with an agenda. Instead, e/acc is best understood as a cultural mirror, or what Jezos <a href="https://www.youtube.com/watch?v=wbfviqlGy2U">calls</a> a “meta philosophy.” It reflects a shift in sentiment across many subcultures of builders, all of whom think tech has more to offer the world than overfunded software startups filled with free snacks and ping pong tables.</p>



<p>Jezos himself was, he says, a theoretical physicist with a graduate degree who joined a Big Tech company to work on machine learning. After three years, he quit, disgusted with the lifestyle. “So much of what is broken with big tech is because it selects for pure status-seekers rather than builders,” he <a href="https://twitter.com/BasedBeff/status/1539031985368322050">tweeted</a>. Jezos sold his car, moved back in with his parents to save money, and eventually took out a personal loan to start a company, buying $100,000 worth of GPUs and building an army of workstations in his home.</p>



<p>It was while Jezos was working in Big Tech that he created a pseudonymous Twitter account and found others to talk to. In the early days of the Covid pandemic, confined to their homes, he and a handful of other accounts began having late-night discussions on Twitter Spaces — a voice-only conversation app — about where the world was going. Like Jezos, many of them also worked in Big Tech and were frustrated by the milquetoast ambitions of their organizations. And like Jezos, they tweeted as a way to vent, while using pseudonyms to avoid repercussions at work. (Against his will, Jezos’s real identity was revealed by <em>Forbes</em> in December.) E/acc emerged from these conversations as a philosophy for “builders to express how they feel about their role in society and what they’re contributing to civilization, and how they can feel happy with their day-to-day lives,” Jezos <a href="https://www.youtube.com/watch?v=wbfviqlGy2U">explained</a> in an interview on the Moment of Zen podcast. It was an antidote to the shame and embarrassment that lingered from the tech backlash, a way to take back the spirit of tech.</p>



<p>“E/acc was cooked up when some Big Tech engineers were very talented but crushed by top-down bureaucracy,” Beff <a href="https://diyhpl.us/wiki/transcripts/2023-03-03-twitter-bayeslord-pmarca/">reminisced</a> on a Twitter Space last March. On a subsequent Space, he <a href="https://diyhpl.us/wiki/transcripts/2023-03-12-twitter-eacc-grimes/">added</a>: “There’s a pervasive mind virus in a lot of Big Tech organizations that causes a lot of engineers working on powerful tech to have self-hatred. It’s not healthy at all…. They kind of get depressed because the whole system tells them that they are bad…. I was thinking, let’s make an ideology where the engineers and builders are heroes.”</p>



<p>E/acc is a litmus test for whether someone is a corporate “wagie,” mindlessly collecting paychecks at a Big Tech company or overfunded startup, or whether the person believes that tech, at its best, is not merely another industry like finance or fashion but a safe haven for people from all backgrounds to build the future they envision, free from cynical naysayers.</p>



<p>Having descended down the other side of the backlash, tech is now preoccupied with solving problems in the physical world with a more sophisticated toolkit than before. There is an influx of founders starting “deep tech” companies, which tackle complex technical and scientific challenges in areas such as nuclear energy, aerospace, and biotech — all unthinkable in the previous era, when the mention of anything non-software sent investors running in the other direction. What’s more, the new founders now come from a different talent pool, bringing deep expertise from “hard” scientific and engineering backgrounds.</p>



<p>And this activity isn’t just restricted to startups anymore, either. Tech now understands the role that policy can play in helping — or hindering — them to build faster, across an array of issues. The Institute for Progress, a tech-minded D.C. policy think tank, is partnering with the National Science Foundation to design and test new ways to fund research and innovation. Founders working in and around artificial intelligence travel to D.C. to meet with policymakers, from Amjad Masad seeking to demonstrate “<a href="https://twitter.com/amasad/status/1671545371619885063">the positive and pragmatic side of AI</a>” through his software-creation platform Replit, to Clem Delangue advocating for “<a href="https://twitter.com/ClementDelangue/status/1699764609933078937">transparency, openness, and distribution of value and power</a>” with AI developer-tool company Hugging Face.</p>



<p>We are also seeing tech’s ethos attract like-minded people from other sectors, even if they don’t have backgrounds in startups. Ezra Klein of the <em>New York Times</em> and Derek Thompson of the <em>Atlantic</em> are two of the most prominent voices advocating for “abundance.” Dartmouth economics professor Heidi Williams leads the Institute for Progress’s science policy efforts. Frontier, a $1 billion initiative started by Stripe to kickstart the carbon removal market, relies upon a panel of advisors and technical reviewers from industry, research, and academia.</p>



<p>The newest generation of technologists knows they won’t derive long-term satisfaction from building a trivial product feature and selling it to a Big Tech company for a few hundred million dollars. They want to rekindle the torch of tech from before the glut and frivolity of the startup frenzy, the part that’s still acceptable to memorialize in Hollywood biopics about Nikola Tesla and Alan Turing. And they realize now that accomplishing this will require them to expand their own skills and knowledge, instead of believing that software alone will save (or eat) the world.</p>



<p>Not all of their efforts are associated with effective accelerationism itself, but they grew from the same psychological place that drove Beff Jezos and his peers to ruminate about the purpose of tech during the pandemic. There is a groundswell of excitement in tech, still rising, that feels like a palate cleanser to the doom and gloom of the post-backlash era. E/acc may not offer the roadmap that definite optimists need, but it signals a shift in tech culture that is long overdue.</p>
                  </div></div>
  </body>
</html>
