<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://aiola.com/blog/introducing-whisper-medusa/">Original</a>
    <h1>AiOla open-sources ultra-fast ‘multi-head’ speech recognition model</h1>
    
    <div id="readability-page-1" class="page"><div id="blog-display">
    
    <div>
        <div>
                        <div>
                <picture decoding="async">
<source type="image/webp" data-lazy-srcset="https://aiola.com/wp-content/uploads/2024/08/aiOla-Releases-Breakthrough-AI-Model1.jpg.webp 1110w, https://aiola.com/wp-content/uploads/2024/08/aiOla-Releases-Breakthrough-AI-Model1-300x169.jpg.webp 300w, https://aiola.com/wp-content/uploads/2024/08/aiOla-Releases-Breakthrough-AI-Model1-1024x578.jpg.webp 1024w, https://aiola.com/wp-content/uploads/2024/08/aiOla-Releases-Breakthrough-AI-Model1-768x434.jpg.webp 768w" srcset="data:image/svg+xml,%3Csvg%20xmlns=&#39;http://www.w3.org/2000/svg&#39;%20viewBox=&#39;0%200%201110%20627&#39;%3E%3C/svg%3E" data-lazy-sizes="(max-width: 1110px) 100vw, 1110px"/>
<img width="1110" height="627" src="data:image/svg+xml,%3Csvg%20xmlns=&#39;http://www.w3.org/2000/svg&#39;%20viewBox=&#39;0%200%201110%20627&#39;%3E%3C/svg%3E" alt="aiOla drops ultra-fast ‘multi-head’ speech recognition model, beats OpenAI Whisper" decoding="async" data-lazy-srcset="https://aiola.com/wp-content/uploads/2024/08/aiOla-Releases-Breakthrough-AI-Model1.jpg 1110w, https://aiola.com/wp-content/uploads/2024/08/aiOla-Releases-Breakthrough-AI-Model1-300x169.jpg 300w, https://aiola.com/wp-content/uploads/2024/08/aiOla-Releases-Breakthrough-AI-Model1-1024x578.jpg 1024w, https://aiola.com/wp-content/uploads/2024/08/aiOla-Releases-Breakthrough-AI-Model1-768x434.jpg 768w" data-lazy-sizes="(max-width: 1110px) 100vw, 1110px" data-lazy-src="https://aiola.com/wp-content/uploads/2024/08/aiOla-Releases-Breakthrough-AI-Model1.jpg"/>
</picture>
            </div>
            
            
            <div>
                <p><span>The best kind of artificial intelligence (AI) tools are those that are </span><i><span>accessible and accurate for all</span></i><span>. At aiOla, we’ve been hard at work to create the best available </span><a href="https://aiola.com/glossary/automatic-speech-recognition/" data-wpel-link="internal"><span>automatic speech recognition model</span></a><span>, and now, we’re excited to announce that we’ve released our open-source AI model, Whisper-Medusa. </span></p>
<p><span>Whisper-Medusa outperforms </span><a href="https://aiola.com/aiola-vs-openai-whisper/" data-wpel-link="internal"><span>OpenAI’s Whisper</span></a><span> by operating 50% faster with no loss in performance. Adding speed while maintaining high levels of accuracy was made possible by the way our model can predict tokens. A </span><a href="https://www.miquido.com/ai-glossary/ai-token/#:~:text=In%20the%20field%20of%20AI,words%2C%20characters%2C%20or%20phrases." data-wpel-link="external" target="_blank" rel="external noopener noreferrer"><span>token</span></a><span> is a unit of data that an algorithm processes. OpenAI’s Whisper model predicts one token at a time, whereas aiOla’s Whisper-Medusa predicts ten at a time, thereby expediting speech prediction speed by 50% and generation runtime, especially for long-form audios. aiOla currently offers Whisper-Medusa as a 10-head model, with future plans to release a 20-head version with equivalent accuracy.</span></p>
<p><span>Given this feat, Whisper-Medusa’s model’s weights and code are available on <a href="https://github.com/aiola-lab/whisper-medusa" target="_blank" rel="noopener external noreferrer" data-wpel-link="external">Hugging Face and GitHub</a>. “Creating Whisper-Medusa was not an easy task, but its significance to the community is profound,” says Gill Hetz, VP of Research at aiOla.</span></p>
<p><span>Based on  a </span><a href="https://paperswithcode.com/method/multi-head-attention" target="_blank" rel="noopener external noreferrer" data-wpel-link="external"><span>multi-head attention architecture</span></a><span> (hence the name), Whisper-Medusa is trained using weak supervision. In this process, the main components of OpenAI’s Whisper are initially frozen. At the same time, additional parameters are being trained. This training process involves using Whisper to transcribe audio datasets and employing these transcriptions as labels to train Medusa’s additional token prediction modules.</span></p>
<p><iframe title="We&#39;ve just released an open-source AI model, that makes OpenAI&#39;s Whisper over 50% faster!" width="500" height="281" src="https://www.youtube.com/embed/StF998wIYs0?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" referrerpolicy="strict-origin-when-cross-origin" allowfullscreen=""></iframe></p>
<h2><span>The Business Advantage</span></h2>
<p><span>While we’ve covered the technical specifications, let’s consider why this is such big news for all businesses looking to accomplish more with the use of speech technology.  aiOla’s AI technology empowers frontline workers to fulfill critical operations with accuracy, speed, and insights. No matter what industry you work in, aiOla’s back-end system, called aiOla Jargonic, can automatically transform your paper-based and manual processes into digital workflows. It’s as easy as uploading a photo or file of your existing processes. Without disruptions or any adjustments, aiOla will <a href="https://aiola.com/blog/workflow-automation/" data-wpel-link="internal">digitize the workflow</a>. </span></p>
<p><span>aiOla’s system is able to understand your business-specific jargon in real-time, with no prior re-training or coding necessary. Additionally, Whisper-Medusa is improving performance and reducing latency (delays). Since a bulk of language that is used in businesses to complete processes is nuanced and specific vocabulary, it requires a bespoke technology to comprehend. aiOla delivers a tailored solution for every business, in any industry. </span></p>
<p><span>Frontline workers get to leverage aiOla’s intuitive app, aiOla Interactive, to complete processes by voice or touch. With speech-enabled process completion, aiOla opens the door to something you’d otherwise miss out on as workers complete their tasks– captured, valuable data and insights. aiOla takes unstructured speech data and converts it into usable information so that your business can act proactively and make informed decisions to optimize efficiency, cut costs, and improve resource allocation, for example. </span></p>
<p><span>Not only does aiOla understand business-specific jargon, but it can also comprehend over 100 languages in any accent and in any acoustic environment. This opens the door for use cases across every industry, including: aviation, <a href="https://aiola.com/industry/food-manufacturing/" data-wpel-link="internal">food manufacturing</a>, <a href="https://aiola.com/industry/logistics-warehousing/" data-wpel-link="internal">logistics and warehousing</a>, healthcare, </span><a href="https://aiola.com/industry-overview/" data-wpel-link="internal"><span>and more. </span></a></p>
<h2><span>A Giant Leap Forward </span></h2>
<p><span>With aiOla’s Whisper-Medusa businesses can take advantage of a speech recognition model that is faster at understanding language with 95%+ accuracy.</span></p>
<p><span>With both speed and accuracy at your fingertips, aiOla empowers frontline workers to accomplish more, in less time, with zero interruption to existing processes.</span><a href="https://github.com/aiola-lab/whisper-medusa" target="_blank" rel="noopener external noreferrer" data-wpel-link="external"><span>Navigate here</span></a><span> to find the open-source files. </span></p>
            </div>
        </div>
        <div>

            
            

            <div>
                <div>
                    <picture decoding="async">
<source type="image/webp" data-lazy-srcset="https://aiola.com/wp-content/uploads/2023/06/layer-24.png.webp" srcset="data:image/svg+xml,%3Csvg%20xmlns=&#39;http://www.w3.org/2000/svg&#39;%20viewBox=&#39;0%200%20197%20232&#39;%3E%3C/svg%3E"/>
<img width="197" height="232" src="data:image/svg+xml,%3Csvg%20xmlns=&#39;http://www.w3.org/2000/svg&#39;%20viewBox=&#39;0%200%20197%20232&#39;%3E%3C/svg%3E" alt="Jolene Amit" decoding="async" data-lazy-src="https://aiola.com/wp-content/uploads/2023/06/layer-24.png"/>
</picture>
                </div>
                <div>
                    <p>Author</p>
                    <p>Jolene Amit</p>
                    <p>Jolene Amit is an experienced tech marketing professional spanning over 16 years and is currently the CMO @aiOla.</p>
                </div>
                <p><img width="55" height="55" src="data:image/svg+xml,%3Csvg%20xmlns=&#39;http://www.w3.org/2000/svg&#39;%20viewBox=&#39;0%200%2055%2055&#39;%3E%3C/svg%3E" alt="Pen" decoding="async" data-lazy-src="https://aiola.com/wp-content/uploads/2023/06/521663-1.png"/></p>
            </div>
            

        </div>
    </div>

</div></div>
  </body>
</html>
