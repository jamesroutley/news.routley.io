<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://minimaxir.com/2022/09/stable-diffusion-ugly-sonic/">Original</a>
    <h1>I Resurrected “Ugly Sonic” with Stable Diffusion Textual Inversion</h1>
    
    <div id="readability-page-1" class="page"><div><p>So there’s a new popular AI image generation tool named <a href="https://github.com/CompVis/stable-diffusion" target="_blank" rel="noopener">Stable Diffusion</a>. But first, let’s discuss why you really clicked on the link to this article: <a href="https://knowyourmeme.com/memes/ugly-sonic" target="_blank" rel="noopener">Ugly Sonic</a>.</p><figure id="figure-hes-sonic-but-ugly-via-paramount-pictures"><div><p><img alt="He&#39;s Sonic, but Ugly. via Paramount Pictures" srcset="/2022/09/stable-diffusion-ugly-sonic/ugly_sonic_hu89d926edd03c5878f62fcf553068403b_720336_deb8b72e8833663e7c3d0579cc2dcfc7.png 400w,
/2022/09/stable-diffusion-ugly-sonic/ugly_sonic_hu89d926edd03c5878f62fcf553068403b_720336_e969418e91092f9eee702de55086dda2.png 760w,
/2022/09/stable-diffusion-ugly-sonic/ugly_sonic_hu89d926edd03c5878f62fcf553068403b_720336_1200x1200_fit_gaussian_3.png 1200w" src="https://minimaxir.com/2022/09/stable-diffusion-ugly-sonic/ugly_sonic_hu89d926edd03c5878f62fcf553068403b_720336_deb8b72e8833663e7c3d0579cc2dcfc7.png" width="760" height="760" loading="lazy" data-zoomable=""/></p></div><figcaption>He’s Sonic, but Ugly. via Paramount Pictures</figcaption></figure><p>A short background: <a href="https://www.sonicthehedgehog.com" target="_blank" rel="noopener">Sonic the Hedgehog</a> is one of the most iconic video game characters of all time.</p><figure id="figure-key-art-of-modern-sonic-from-super-smash-brothers-ultimate-via-nintendohttpswwwsmashbroscomen_usfighter38html"><div><p><img alt="Key art of &#34;Modern&#34; Sonic from Super Smash Brothers Ultimate. [via Nintendo](https://www.smashbros.com/en_US/fighter/38.html)" srcset="/2022/09/stable-diffusion-ugly-sonic/Sonic_-_Super_Smash_Bros._Ultimate%20copy_hue5431530e04e38f7c819acceb01cdf11_418029_fe2a6308dd27b602e60dbf24a2843f15.png 400w,
/2022/09/stable-diffusion-ugly-sonic/Sonic_-_Super_Smash_Bros._Ultimate%20copy_hue5431530e04e38f7c819acceb01cdf11_418029_e8f8ebc8b1932110ee9956b22dd9a472.png 760w,
/2022/09/stable-diffusion-ugly-sonic/Sonic_-_Super_Smash_Bros._Ultimate%20copy_hue5431530e04e38f7c819acceb01cdf11_418029_1200x1200_fit_gaussian_3.png 1200w" src="https://minimaxir.com/2022/09/stable-diffusion-ugly-sonic/Sonic_-_Super_Smash_Bros._Ultimate%20copy_hue5431530e04e38f7c819acceb01cdf11_418029_fe2a6308dd27b602e60dbf24a2843f15.png" width="600" height="743" loading="lazy" data-zoomable=""/></p></div><figcaption>Key art of “Modern” Sonic from Super Smash Brothers Ultimate. <a href="https://www.smashbros.com/en_US/fighter/38.html" target="_blank" rel="noopener">via Nintendo</a></figcaption></figure><p>The initial movie trailer released in 2019 for the Sonic the Hedgehog movie included a peculiar <em>general-audience-friendly</em> design for Sonic.</p><p><iframe src="https://www.youtube.com/embed/4mW9FE5ILJs" allowfullscreen="" title="YouTube Video"></iframe></p><p>This was a more humanoid Sonic, with small eyes, blue furry arms, and <em>human teeth</em>. After backlash, Sonic was redesign to be closer to his modern game incarnation:</p><figure id="figure-comparison-between-the-two-designs-via-newsweekhttpswwwnewsweekcomsonic-hedgehog-redesign-movie-conspiracy-old-vs-new-comparison-1471620"><div><p><img alt="Comparison between the two designs. [via Newsweek](https://www.newsweek.com/sonic-hedgehog-redesign-movie-conspiracy-old-vs-new-comparison-1471620)" srcset="/2022/09/stable-diffusion-ugly-sonic/new-vs-old-sonic-hedgehog_hu07a07131e2baa41544ae7decb667647b_24100_5ed841305a07a70ce55d8d8f52df08cc.webp 400w,
/2022/09/stable-diffusion-ugly-sonic/new-vs-old-sonic-hedgehog_hu07a07131e2baa41544ae7decb667647b_24100_92656c8de3d3f9054795dd076b8a80e4.webp 760w,
/2022/09/stable-diffusion-ugly-sonic/new-vs-old-sonic-hedgehog_hu07a07131e2baa41544ae7decb667647b_24100_1200x1200_fit_q75_h2_gaussian_2.webp 1200w" src="https://minimaxir.com/2022/09/stable-diffusion-ugly-sonic/new-vs-old-sonic-hedgehog_hu07a07131e2baa41544ae7decb667647b_24100_5ed841305a07a70ce55d8d8f52df08cc.webp" width="760" height="427" loading="lazy" data-zoomable=""/></p></div><figcaption>Comparison between the two designs. <a href="https://www.newsweek.com/sonic-hedgehog-redesign-movie-conspiracy-old-vs-new-comparison-1471620" target="_blank" rel="noopener">via Newsweek</a></figcaption></figure><p>The movie itself turned out to be the best video-game movie ever, which sounds <a href="https://tvtropes.org/pmwiki/pmwiki.php/Main/DamnedByFaintPraise" target="_blank" rel="noopener">damning by faint praise</a> but it was an accurate assessment. Years later, a gag in the straight-to-Disney+ movie <a href="https://www.imdb.com/title/tt3513500/" target="_blank" rel="noopener">Chip N’ Dale: Rescue Rangers</a> reintroduced this design as a gag, officially called Ugly Sonic.</p><p><iframe src="https://www.youtube.com/embed/uZzl3Y1HDAQ" allowfullscreen="" title="YouTube Video"></iframe></p><p>So why not see if AI can resurrect this Ugly Sonic? (that’s a rhetorical question, please don’t answer it)</p><p>I decided to use Ugly Sonic to test Stable Diffusion for three reasons: one, because he’s a computer-generated character so it seems thematically appropriate; two, because there aren’t many images of him in the training dataset so generated output should be truly unique; and three, because if Paramount wants to send me a cease and desist for besmirching the the Ugly Sonic brand, that would be objectively hilarious.</p><h2 id="stable-diffusion-is-a-crazy-gadget">Stable Diffusion is a Crazy Gadget</h2><div><p>All images generated by Stable Diffusion v1.4 in this post are generated with a classifier guidance of 7.5 with 50 denoising steps. Images are cherrypicked from 16 total generations from the prompt, as occasionally the prompt is misinterpreted by Stable Diffusion, or the generations aren’t funny enough. Additionally, the NSFW filter was disabled during generation due to frequent false positives: none of the images used in this post are NSFW, although some may argue that Ugly Sonic himself is NSFL.</p></div><p>I’ve always had difficulty generating a normal Sonic the Hedgehog image with AI image generation. <a href="https://openai.com/dall-e-2/" target="_blank" rel="noopener">DALL-E 2</a>, for example, just flat-out can’t do it.</p><figure id="figure-a-portrait-of-sonic-the-hedgehog-via-dall-e-2"><div><p><img alt="`a portrait of Sonic the Hedgehog`, via DALL-E 2" srcset="/2022/09/stable-diffusion-ugly-sonic/a071601b4209bcd2_hu33b829fd75505c91bcbc60b925fae7fc_1073451_0c59908b823f98d321421112470c21e1.png 400w,
/2022/09/stable-diffusion-ugly-sonic/a071601b4209bcd2_hu33b829fd75505c91bcbc60b925fae7fc_1073451_ab8b7be4b1cf5244bf036c37ab19ac63.png 760w,
/2022/09/stable-diffusion-ugly-sonic/a071601b4209bcd2_hu33b829fd75505c91bcbc60b925fae7fc_1073451_1200x1200_fit_gaussian_3.png 1200w" src="https://minimaxir.com/2022/09/stable-diffusion-ugly-sonic/a071601b4209bcd2_hu33b829fd75505c91bcbc60b925fae7fc_1073451_0c59908b823f98d321421112470c21e1.png" width="760" height="760" loading="lazy" data-zoomable=""/></p></div><figcaption><code>a portrait of Sonic the Hedgehog</code>, via DALL-E 2</figcaption></figure><p>Stable Diffusion does a tad better, capturing Sonic with a variety of styles and eras.</p><figure id="figure-a-portrait-of-sonic-the-hedgehog-via-stable-diffusion"><div><p><img alt="`a portrait of Sonic the Hedgehog`, via Stable Diffusion" srcset="/2022/09/stable-diffusion-ugly-sonic/d3bc427a63dad734_hud2e13215184b505334e5b0683eb02a49_923356_15dd9863f9a18fe1b9e23ed43f8c3b73.png 400w,
/2022/09/stable-diffusion-ugly-sonic/d3bc427a63dad734_hud2e13215184b505334e5b0683eb02a49_923356_6c9c314bdca65304410a0bcb875d3069.png 760w,
/2022/09/stable-diffusion-ugly-sonic/d3bc427a63dad734_hud2e13215184b505334e5b0683eb02a49_923356_1200x1200_fit_gaussian_3.png 1200w" src="https://minimaxir.com/2022/09/stable-diffusion-ugly-sonic/d3bc427a63dad734_hud2e13215184b505334e5b0683eb02a49_923356_15dd9863f9a18fe1b9e23ed43f8c3b73.png" width="760" height="760" loading="lazy" data-zoomable=""/></p></div><figcaption><code>a portrait of Sonic the Hedgehog</code>, via Stable Diffusion</figcaption></figure><p>Indeed, there are <a href="https://haveibeentrained.com/?search_text=sonic%20the%20hedgehog" target="_blank" rel="noopener">many images of Sonic</a> in the training dataset, however the generated images do not verbatim reproduce or otherwise plagiarize results from the training set above (I checked each one).</p><p>By now, you probably already know that Stable Diffusion takes in text and generates an image from random latent noise. The text encoding is done through a large pretrained CLIP model. However, a new technique called <a href="https://textual-inversion.github.io" target="_blank" rel="noopener">textual inversion</a> can reverse engineer the 768D “encoding” of a concept with the CLIP encoding space given a few example images and without modifying the underlying image generation model, which can then be used with the model to generate more specific images.</p><figure id="figure-demo-of-textual-inversion-via-the-official-project-repohttpstextual-inversiongithubio"><div><p><img alt="Demo of textual inversion, via [the official project repo](https://textual-inversion.github.io)" srcset="/2022/09/stable-diffusion-ugly-sonic/teaser_huc481276552365ce4ad34e266c5e05428_168778_25b13e1d93f671b01b88fd150b73f074.jpg 400w,
/2022/09/stable-diffusion-ugly-sonic/teaser_huc481276552365ce4ad34e266c5e05428_168778_bb795c8c7af0f31fdb90237d4d1d3a02.jpg 760w,
/2022/09/stable-diffusion-ugly-sonic/teaser_huc481276552365ce4ad34e266c5e05428_168778_1200x1200_fit_q75_gaussian.jpg 1200w" src="https://minimaxir.com/2022/09/stable-diffusion-ugly-sonic/teaser_huc481276552365ce4ad34e266c5e05428_168778_25b13e1d93f671b01b88fd150b73f074.jpg" width="760" height="358" loading="lazy" data-zoomable=""/></p></div><figcaption>Demo of textual inversion, via <a href="https://textual-inversion.github.io" target="_blank" rel="noopener">the official project repo</a></figcaption></figure><p>Soon after, Hugging Face <a href="https://twitter.com/psuraj28/status/1567212122970685442" target="_blank" rel="noopener">released a Colab Notebook</a> that makes training the model to obtain the concept straightforward. From that, I trained an <a href="https://huggingface.co/sd-concepts-library/ugly-sonic" target="_blank" rel="noopener">Ugly Sonic object concept</a> on 5 image crops from the movie trailer, with 6,000 steps and 1 gradient accumulation step (on a T4 GPU, this took about 1.5 hours and cost about $0.21 on a GCP Spot instance). I then <a href="https://colab.research.google.com/drive/1-Go3l9HpSIkjvDfR0gm8kWLPRnsaUIYd?usp=sharing" target="_blank" rel="noopener">customized the inference Colab notebook</a> to more easily generate images from a new textual inversion.</p><p>The Ugly Sonic object concept, once loaded into the text encoder, can be invoked by including <code>&lt;ugly-sonic&gt;</code> in the prompt where you’d normally include an object. Let’s test it out with a simple <a href="https://minimaxir.com/2021/08/vqgan-clip/" target="_blank" rel="noopener">VQGAN + CLIP-esque</a> prompt such as <code>a beautiful portrait of &lt;ugly-sonic&gt; by Leonardo Da Vinci</code> which should have a more expected output:</p><figure id="figure-a-beautiful-portrait-of--by-leonardo-da-vinci-via-stable-diffusion"><div><p><img alt="`a beautiful portrait of  by Leonardo Da Vinci`, via Stable Diffusion" srcset="/2022/09/stable-diffusion-ugly-sonic/8ed7ee0d3e25a187_hu6cf38f6b2853fde87c418a49bda66382_1087050_a84773be898d7f181b3df052c3501ef1.png 400w,
/2022/09/stable-diffusion-ugly-sonic/8ed7ee0d3e25a187_hu6cf38f6b2853fde87c418a49bda66382_1087050_b1b07dea9a284d7d06a23801ac21ab48.png 760w,
/2022/09/stable-diffusion-ugly-sonic/8ed7ee0d3e25a187_hu6cf38f6b2853fde87c418a49bda66382_1087050_1200x1200_fit_gaussian_3.png 1200w" src="https://minimaxir.com/2022/09/stable-diffusion-ugly-sonic/8ed7ee0d3e25a187_hu6cf38f6b2853fde87c418a49bda66382_1087050_a84773be898d7f181b3df052c3501ef1.png" width="760" height="760" loading="lazy" data-zoomable=""/></p></div><figcaption><code>a beautiful portrait of &lt;ugly-sonic&gt; by Leonardo Da Vinci</code>, via Stable Diffusion</figcaption></figure><p>😵‍💫</p><p>Apparently the textual inversion tokens can have an unexpectedly strong effect on the resulting output. Fortunately, there’s a Stable Diffusion prompt hacking trick I <a href="https://www.reddit.com/r/StableDiffusion/comments/xd1ze4/increases_attention_to_enclosed_words_decreases/" target="_blank" rel="noopener">saw on Reddit</a>: wrapping terms you want to emphasize with <code>()</code> increases their “weight” in the generation, while <code>[]</code> decreases the weight. Modifying the prompt to also include deemphasis on Ugly Sonic and emphasis on the medium of <code>painting, oil on canvas</code> gives better results.</p><figure id="figure-a-beautiful-portrait-of--by-leonardo-da-vinci-painting-oil-on-canvas-via-stable-diffusion"><div><p><img alt="`a beautiful portrait of [[[]]] by Leonardo Da Vinci, (((painting, oil on canvas)))`, via Stable Diffusion" srcset="/2022/09/stable-diffusion-ugly-sonic/e04ddaa8da5edbf5_hu2eed26573be14b9ceb8c55e11db4f88e_1127984_65d6a9fbeeeecaaf6892f20003363d41.png 400w,
/2022/09/stable-diffusion-ugly-sonic/e04ddaa8da5edbf5_hu2eed26573be14b9ceb8c55e11db4f88e_1127984_5284d44088c05e208d8404fdb155bfff.png 760w,
/2022/09/stable-diffusion-ugly-sonic/e04ddaa8da5edbf5_hu2eed26573be14b9ceb8c55e11db4f88e_1127984_1200x1200_fit_gaussian_3.png 1200w" src="https://minimaxir.com/2022/09/stable-diffusion-ugly-sonic/e04ddaa8da5edbf5_hu2eed26573be14b9ceb8c55e11db4f88e_1127984_65d6a9fbeeeecaaf6892f20003363d41.png" width="760" height="760" loading="lazy" data-zoomable=""/></p></div><figcaption><code>a beautiful portrait of [[[&lt;ugly-sonic&gt;]]] by Leonardo Da Vinci, (((painting, oil on canvas)))</code>, via Stable Diffusion</figcaption></figure><p>Close enough!</p><p>There is a lot of trial and error, but fortunately Stable Diffusion generation is fast enough and cheap enough that you can brute force it. And this is just the beginning.</p><h2 id="mad-latent-space">Mad Latent Space</h2><p>Now that we have a working Ugly Sonic inversion, let’s get dangerous. The standard modifiers added to AI-generate image prompts work here to increase realism.</p><figure id="figure-hyperrealistic--unreal-engine-4k-via-stable-diffusion"><div><p><img alt="`hyperrealistic , unreal engine, 4k`, via Stable Diffusion" srcset="/2022/09/stable-diffusion-ugly-sonic/eae2c80e866d45b5_hu3abe668baa93671f4539db66d41884dc_955192_d5190b36259f044995a6235c528b1758.png 400w,
/2022/09/stable-diffusion-ugly-sonic/eae2c80e866d45b5_hu3abe668baa93671f4539db66d41884dc_955192_6ccd32b5fac149fd74308489a8c6d990.png 760w,
/2022/09/stable-diffusion-ugly-sonic/eae2c80e866d45b5_hu3abe668baa93671f4539db66d41884dc_955192_1200x1200_fit_gaussian_3.png 1200w" src="https://minimaxir.com/2022/09/stable-diffusion-ugly-sonic/eae2c80e866d45b5_hu3abe668baa93671f4539db66d41884dc_955192_d5190b36259f044995a6235c528b1758.png" width="760" height="760" loading="lazy" data-zoomable=""/></p></div><figcaption><code>hyperrealistic &lt;ugly-sonic&gt;, unreal engine, 4k</code>, via Stable Diffusion</figcaption></figure><p>Ugly Sonic is better rendered here than in the movie trailer.</p><p>It’s noticeable here, but in some cases the generated figure is closer to Modern Sonic than Ugly Sonic. It’s possible the trained concept and the encoded <code>Sonic the Hedgehog</code> text are similarly embedded in the latent space. Hence we need to curate the generated images so we try not to include the <em>boring</em> Modern Sonic that no one likes.</p><p>Ugly Sonic must be hungry, let’s get him his favorite food: a chili dog.</p><figure id="figure--sitting-and-eating-a-chili-dog-stock-photo-via-stable-diffusion"><div><p><img alt="` sitting and eating a ((chili dog)), stock photo`, via Stable Diffusion" srcset="/2022/09/stable-diffusion-ugly-sonic/d8bc24adb9f679fe_hue067378eb998cd15d1a0cb43ae3caecb_967979_4f3154b5a89dd6a901cf80638457f686.png 400w,
/2022/09/stable-diffusion-ugly-sonic/d8bc24adb9f679fe_hue067378eb998cd15d1a0cb43ae3caecb_967979_45c6a677e7e909672c789b2fa3b21e33.png 760w,
/2022/09/stable-diffusion-ugly-sonic/d8bc24adb9f679fe_hue067378eb998cd15d1a0cb43ae3caecb_967979_1200x1200_fit_gaussian_3.png 1200w" src="https://minimaxir.com/2022/09/stable-diffusion-ugly-sonic/d8bc24adb9f679fe_hue067378eb998cd15d1a0cb43ae3caecb_967979_4f3154b5a89dd6a901cf80638457f686.png" width="760" height="760" loading="lazy" data-zoomable=""/></p></div><figcaption><code>&lt;ugly-sonic&gt; sitting and eating a ((chili dog)), stock photo</code>, via Stable Diffusion</figcaption></figure><p>Now that he’s had lunch, Ugly Sonic can now spend time with the former president of the United States, Barack Obama!</p><figure id="figure-hyperrealistic--shakes-hands-with-barack-obama-via-stable-diffusion"><div><p><img alt="`hyperrealistic  shakes hands with Barack Obama`, via Stable Diffusion" srcset="/2022/09/stable-diffusion-ugly-sonic/59aec00fb3f1e797_hu731981668ce30b6bfb54d1bdec7a1085_1030833_10874042e4d573db4fa293498e3c0def.png 400w,
/2022/09/stable-diffusion-ugly-sonic/59aec00fb3f1e797_hu731981668ce30b6bfb54d1bdec7a1085_1030833_9223036be2ac3ed20199513c1d27cda0.png 760w,
/2022/09/stable-diffusion-ugly-sonic/59aec00fb3f1e797_hu731981668ce30b6bfb54d1bdec7a1085_1030833_1200x1200_fit_gaussian_3.png 1200w" src="https://minimaxir.com/2022/09/stable-diffusion-ugly-sonic/59aec00fb3f1e797_hu731981668ce30b6bfb54d1bdec7a1085_1030833_10874042e4d573db4fa293498e3c0def.png" width="760" height="760" loading="lazy" data-zoomable=""/></p></div><figcaption><code>hyperrealistic &lt;ugly-sonic&gt; shakes hands with Barack Obama</code>, via Stable Diffusion</figcaption></figure><p>Let’s go full circle and put Ugly Sonic back into a video game!</p><figure id="figure--as-a-character-in-a-genesis-video-game-16-bit-pixel-art-via-stable-diffusion"><div><p><img alt="`[[[[]]]] as a character in a ((Genesis)) video game, ((((16-bit pixel art))))`, via Stable Diffusion" srcset="/2022/09/stable-diffusion-ugly-sonic/d2dbb4ada2fc87cc_hueee669375451135ce1e05b1e1f6e22e9_1075915_83f60089357fdc40f12ae7eed1c72f34.png 400w,
/2022/09/stable-diffusion-ugly-sonic/d2dbb4ada2fc87cc_hueee669375451135ce1e05b1e1f6e22e9_1075915_d3665a534808419acba5396c7c538ed1.png 760w,
/2022/09/stable-diffusion-ugly-sonic/d2dbb4ada2fc87cc_hueee669375451135ce1e05b1e1f6e22e9_1075915_1200x1200_fit_gaussian_3.png 1200w" src="https://minimaxir.com/2022/09/stable-diffusion-ugly-sonic/d2dbb4ada2fc87cc_hueee669375451135ce1e05b1e1f6e22e9_1075915_83f60089357fdc40f12ae7eed1c72f34.png" width="760" height="760" loading="lazy" data-zoomable=""/></p></div><figcaption><code>[[[[&lt;ugly-sonic&gt;]]]] as a character in a ((Genesis)) video game, ((((16-bit pixel art))))</code>, via Stable Diffusion</figcaption></figure><p>It’s indeed possible to use more than one textual inversion at a time in a prompt, and the <a href="https://huggingface.co/sd-concepts-library" target="_blank" rel="noopener">Concepts gallery</a> is a good repository of trained concepts. What about giving Ugly Sonic a psychedelic aspect by combining a <a href="https://huggingface.co/sd-concepts-library/liquid-light" target="_blank" rel="noopener">liquid light style concept</a> and a <a href="https://huggingface.co/sd-concepts-library/nebula" target="_blank" rel="noopener">nebula style concept</a>?</p><figure id="figure-a-hyperrealistic-portrait-of--in-the-style-of--and-the-style-of--trending-on-artstation-via-stable-diffusion"><div><p><img alt="`a ((((hyperrealistic portrait)))) of [] in the style of  and the style of , trending on artstation`, via Stable Diffusion" srcset="/2022/09/stable-diffusion-ugly-sonic/d8bf6343c03dde31_hubd35abc600b88a9640c493ba1f715fb0_1151591_15cdde0aa0240304481ce877732478b1.png 400w,
/2022/09/stable-diffusion-ugly-sonic/d8bf6343c03dde31_hubd35abc600b88a9640c493ba1f715fb0_1151591_2ae3a6d5f6971bf5d4098914e3021377.png 760w,
/2022/09/stable-diffusion-ugly-sonic/d8bf6343c03dde31_hubd35abc600b88a9640c493ba1f715fb0_1151591_1200x1200_fit_gaussian_3.png 1200w" src="https://minimaxir.com/2022/09/stable-diffusion-ugly-sonic/d8bf6343c03dde31_hubd35abc600b88a9640c493ba1f715fb0_1151591_15cdde0aa0240304481ce877732478b1.png" width="760" height="760" loading="lazy" data-zoomable=""/></p></div><figcaption><code>a ((((hyperrealistic portrait)))) of [&lt;ugly-sonic&gt;] in the style of &lt;lls&gt; and the style of &lt;nebula&gt;, trending on artstation</code>, via Stable Diffusion</figcaption></figure><p>Lastly, Stable Diffusion experts on <a href="https://www.reddit.com/r/StableDiffusion/" target="_blank" rel="noopener">/r/StableDiffusion</a> have gotten prompt engineering down to a science, with massive prompts even longer than the ones above. Let’s just YOLO Ugly Sonic into one.</p><figure id="figure--dynamic-comic-hero-pose-detailed-city-at-night-background-aesthetic-captivating-concept-art-anime-hyper-detailed-and-intricate-realistic-shaded-fine-detail-realistic-proportions-symmetrical-sharp-focus-8k-resolution-with-lineart-flat-ink-trending-on-pixiv-fanbox-via-stable-diffusion-prompt-adapted-from-herehttpswwwredditcomrstablediffusioncommentsxemaq3making_someone_dreams_comes_true_but_in_waifu"><div><p><img alt="` dynamic comic hero pose, detailed city at night background, aesthetic, captivating, (((concept art, anime, hyper-detailed and intricate, realistic shaded, fine detail, realistic proportions, symmetrical, sharp focus, 8K resolution, with lineart flat ink, trending on pixiv fanbox)))`, via Stable Diffusion. Prompt adapted [from here](https://www.reddit.com/r/StableDiffusion/comments/xemaq3/making_someone_dreams_comes_true_but_in_waifu/)." srcset="/2022/09/stable-diffusion-ugly-sonic/7762adbe6895884c_hu765bfde0c05ace0b134a4c39cdd5510f_1121042_8dcbbacb3ad520cb50908c8d5655ba50.png 400w,
/2022/09/stable-diffusion-ugly-sonic/7762adbe6895884c_hu765bfde0c05ace0b134a4c39cdd5510f_1121042_c7d7d18103a655093783784cd0e73b94.png 760w,
/2022/09/stable-diffusion-ugly-sonic/7762adbe6895884c_hu765bfde0c05ace0b134a4c39cdd5510f_1121042_1200x1200_fit_gaussian_3.png 1200w" src="https://minimaxir.com/2022/09/stable-diffusion-ugly-sonic/7762adbe6895884c_hu765bfde0c05ace0b134a4c39cdd5510f_1121042_8dcbbacb3ad520cb50908c8d5655ba50.png" width="760" height="760" loading="lazy" data-zoomable=""/></p></div><figcaption><code>&lt;ugly-sonic&gt; dynamic comic hero pose, detailed city at night background, aesthetic, captivating, (((concept art, anime, hyper-detailed and intricate, realistic shaded, fine detail, realistic proportions, symmetrical, sharp focus, 8K resolution, with lineart flat ink, trending on pixiv fanbox)))</code>, via Stable Diffusion. Prompt adapted <a href="https://www.reddit.com/r/StableDiffusion/comments/xemaq3/making_someone_dreams_comes_true_but_in_waifu/" target="_blank" rel="noopener">from here</a>.</figcaption></figure><p>The funny thing about textual inversion is that each of these concepts are only 4KB on disk. Although a given textual inversion concept may not work with future versions of Stable Diffusions or other diffusion models using the CLIP encoder, it’s a good demo of how well trained concepts can be used to get more specific outputs, even if the concept isn’t in the original dataset the model was trained upon.</p><p>Again, you can use the <a href="https://huggingface.co/sd-concepts-library/ugly-sonic" target="_blank" rel="noopener">Ugly Sonic concept</a> yourself with a <a href="https://colab.research.google.com/drive/1-Go3l9HpSIkjvDfR0gm8kWLPRnsaUIYd?usp=sharing" target="_blank" rel="noopener">textual inversion inference notebook</a> or <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui" target="_blank" rel="noopener">another Stable Diffusion user interface</a> that supports textual inversion to generate your own Ugly Sonics with Stable Diffusion!</p><p>There were a few AI-generated images of Ugly Sonic with his human teeth, but I opted not to include them because I have <em>standards</em>, believe it or not.</p><hr/><p><em>Disclosure: I am neither an artist nor an expert in art theory. All my comments on what are “good” AI art generations are my own (likely bad) opinions.</em></p><p><em>Also, I am not a furry. Even though my name is Max Woolf.</em></p><div><p>If you liked this post, I have set up a <strong><a href="https://www.patreon.com/minimaxir" target="_blank" rel="noopener">Patreon</a></strong> to fund my machine learning/deep learning/software/hardware needs for my future crazy yet cool projects, and any monetary contributions to the Patreon are appreciated and will be put to good creative use.</p></div></div></div>
  </body>
</html>
