<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://news.ucsc.edu/2024/06/matmul-free-llm.html">Original</a>
    <h1>Researchers run high-performing LLM on the energy needed to power a lightbulb</h1>
    
    <div id="readability-page-1" class="page"><div id="sprflt">

          <div id="main" role="main">
            
            <p>By eliminating the most computationally expensive element of a large language model, engineers drastically improve energy efficiency while maintaining performance
</p><div><figure><img alt="A rendering of a lightbulb seen through a grid diagram of a neural network" src="https://news.ucsc.edu/2024/06/images/illo_450.jpg"/><figcaption>UC Santa Cruz researchers found that they could power a billion-parameter-scale language model on just 13 watts, about equal to the energy of powering a lightbulb. Illustration by Molly Fine.</figcaption></figure><div><p>Large language models such as ChaptGPT have proven to be able to produce remarkably intelligent results, but the energy and monetary costs associated with running these massive algorithms is sky high. It costs $700,000 per day in energy costs to run ChatGPT 3.5, according to recent estimates, and leaves behind a massive carbon footprint in the process.</p></div></div>
            
          </div>
          
          

        </div></div>
  </body>
</html>
