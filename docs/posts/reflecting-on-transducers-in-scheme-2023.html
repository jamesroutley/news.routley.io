<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.thatgeoguy.ca/blog/2023/01/04/reflections-on-transducers/">Original</a>
    <h1>Reflecting on transducers in Scheme (2023)</h1>
    
    <div id="readability-page-1" class="page"><div>
            

<p>On <em>2023-01-04</em> by <em>ThatGeoGuy</em></p>

<p>So over the holidays I have had something of a little bug in my brain:
<a href="https://www.youtube.com/watch?v=6mTbuzafcII">transducers</a>. It started when I was thinking of working on
an unrelated side-project, but I more or less got frustrated and asked myself <em>“why doesn’t Scheme
have a library that is as good as Rust’s <code>Iterator</code> trait?”</em> I am a strong proponent of Rust both at
work and outside of work; however, I don’t always want to use Rust. Sometimes I’m scripting
something fairly quick-and-dirty, but largely I’m part of the Lisp Cult<sup id="fnref:cult" role="doc-noteref"><a href="#fn:cult" rel="footnote">1</a></sup> and I have fun
writing Scheme. This isn’t about picking languages or favourites, it’s about <strong>finding out why</strong>, in
the case of my question above.</p>

<p>Needless to say, this eventually led me to writing my own egg (module) for transducers in Scheme. If
all has gone well, it should already be available to download and install by running:</p>

<div><div><pre><code>chicken-install <span>-s</span> transducers
</code></pre></div></div>

<p>I only note this because I think this blog post will serve as a good companion piece of
documentation for the egg. I think the rationale is especially worth digging into, because this
isn’t new ground and through the process of writing this egg I really felt like I was reinventing
the wheel.</p>

<p>Likewise: before we start, I should note here that I’m going to mostly talk about CHICKEN Scheme
here since that’s the Scheme I’m most familiar with. I do think that almost everything I write here
is pretty applicable to R5RS / R7RS-small Scheme; however, if your specific Scheme system has some
(non-standard) way of handling anything I talk about here please do forgive me — I am very
likely not aware of it. I’ll also be talking heavily about concepts such as <code>fold</code>, <code>map</code>, etc. If
you don’t know what those are and haven’t done any kind of functional programming before you may
want to skip this post. I’d be happy to write a tutorial if needed, but I’ll avoid doing that here
for brevity.</p>



<p>Okay, so back to the bug in my brain: why transducers? Well, this journey for me actually started
with me thinking about <a href="https://doc.rust-lang.org/stable/std/iter/trait.Iterator.html">Rust’s <code>Iterator</code>
trait</a>. This trait is excellent and is
probably one of the traits I use the most when programming at work. Regardless of the type that I
start with, <code>Iterator</code> allows me to write code using the same set of meta-functions (<code>map</code>,
<code>filter</code>, etc.) without having to write each implementation individually for each data structure.
Just by providing a <code>next</code> implementation, I get access to all of the goodies provided by the
<code>Iterator</code> trait for <del>free</del> relatively cheap.</p>

<p>But Scheme doesn’t really have anything like this! Rust can manage the above because traits are a
construct that happens at the type level. They’re a way of being able to abstract types in a
polymorphic way. You can write a <code>map</code> such that it works for all <code>T</code> that are <code>Iterator</code> —
the equivalent in Scheme isn’t really possible. Scheme is a dynamic language, so this kind of
polymorphism isn’t gonna fly.</p>

<p>The idea of “iterate over an entire collection” is a pretty common one in programming. For the sake
of brevity, I’m not going to justify why I think this is important. But let’s look at a couple
examples of where Scheme fails because it doesn’t have some generic way to operate over different
collections.</p>

<h2 id="a-list-of-schemes-failures-to-abstract">A <code>list?</code> of Scheme’s failures to abstract</h2>

<h3 id="there-is-a--map---fold---etc-for-every-data-structure-except-when-there-isnt">There is a <code>-map</code> / <code>-fold</code> / <code>-etc</code> for every data structure, except when there isn’t</h3>

<p>The most recent SRFI (Scheme Request for Implementation)<sup id="fnref:srfi" role="doc-noteref"><a href="#fn:srfi" rel="footnote">2</a></sup> for working with Scheme vectors is
<a href="https://srfi.schemers.org/srfi-133/srfi-133.html">SRFI-133 - Vector Library (R7RS Compatible)</a>.
This library standardizes some of the API for working with vectors. Operations such as folding,
unfolding, copying, etc. are all made available by importing <code>srfi-133</code>.</p>

<p>Except for one - <code>vector-filter</code>. Unlike in other languages, vectors in Scheme are dynamically
allocated but fixed in size. This means that you can’t just <code>push</code> or <code>push_back</code> on a Scheme vector
like you can in e.g. Rust or C++. Because of this, SRFI 133 does not provide a procedure to filter
elements, because the final result of such a procedure could have an unknown size, and any
<code>vector-filter</code> would need to know how many elements to allocate in the vector before it ran.</p>

<p>This is very very very annoying. It’s not that amortized O(1) pushing is hard to implement, but
Scheme as a language tries as hard as it can to remain small. As a result, this kind of stuff is
left to the last developer in the chain to work around. Now every time you want to do something like
the following Rust code:</p>

<div><div><pre><code><span>fn</span> <span>filter_odd_values</span><span>(</span><span>v</span><span>:</span> <span>Vec</span><span>&lt;</span><span>u8</span><span>&gt;</span><span>)</span> <span>-&gt;</span> <span>Vec</span><span>&lt;</span><span>u8</span><span>&gt;</span> <span>{</span>
    <span>v</span><span>.into_iter</span><span>()</span>
     <span>.filter</span><span>(|</span><span>t</span><span>|</span> <span>t</span> <span>%</span> <span>2</span> <span>!=</span> <span>0</span><span>)</span>
     <span>.collect</span><span>()</span>
<span>}</span>
</code></pre></div></div>

<p>You have to make the following choice:</p>

<ol>
  <li>Implement and carefully manage an implementation of <code>vector-filter</code>, as well as add tests,
documentation, etc.</li>
  <li>Convert to another data type first, run that data type’s filter (e.g. the list version of
<code>filter</code> in SRFI-1), and then convert back to a vector.</li>
  <li>Something else???</li>
</ol>

<p>These kinds of operations (map, filter, etc.) are not universal across all Scheme types, usually
because there’s a missing piece (cannot do amortized O(1) push to vector, has hidden internal state,
etc). Every new collection has to define these operations every time a new type is added. This is a
lot of work for very little gain!</p>

<p>Now let’s actually talk a little more in-depth about that second point, which is another failure of
Scheme…</p>

<h3 id="using-lists-as-intermediates">Using lists as intermediates</h3>

<p>I’m going to quote here from the <a href="https://google.github.io/styleguide/lispguide.xml?showone=Do_not_abuse_lists#Do_not_abuse_lists">Google LISP
guidelines</a>:</p>

<blockquote>
  <p>You must select proper data representation. You must not abuse the LIST data structure.</p>

  <p>Even though back in 1958, LISP was short for “LISt Processing”, its successor Common Lisp has been
a modern programming language with modern data structures since the 1980s. You must use the proper
data structures in your programs.</p>

  <p>You must not abuse the builtin (single-linked) LIST data structure where it is not appropriate,
even though Common Lisp makes it especially easy to use it.</p>

  <p>You must only use lists when their performance characteristics is appropriate for the algorithm at
hand: sequential iteration over the entire contents of the list.</p>
</blockquote>

<p>Just because Scheme (and Lisps) are primarily based around lists does not mean that we should still
be abusing the list data structure so. Let me clarify the actual point I am making here: <em>I think
library authors aren’t coordinating and as a result downstream users are forced to abuse the list
data structure even when they don’t want to.</em></p>

<p>I am explicitly <strong>NOT</strong> saying that people writing Scheme today aren’t using appropriate data
structures. There is certainly some of that happening in undergraduate classes somewhere, but that
is irrelevant to my point. Instead, I want to point out how almost every SRFI or Scheme-specific
module (such as CHICKEN eggs) provides the following two procedures:</p>

<div><div><pre><code><span>(</span><span>type-&gt;list</span> <span>t</span><span>)</span>

<span>(</span><span>list-&gt;type</span> <span>lst</span><span>)</span>
</code></pre></div></div>

<p>And yet, despite everything you almost never see <code>type-&gt;vector</code>, <code>type-&gt;u8vector</code>, <code>type-1-&gt;type-2</code>,
etc. There are some rare exceptions to this (e.g. SRFI 158), but often even those exceptions are
providing <code>type-&gt;vector</code> by first doing:</p>

<div><div><pre><code><span>(</span><span>define</span> <span>(</span><span>type-&gt;vector</span> <span>t</span><span>)</span>
  <span>(</span><span>list-&gt;vector</span>
    <span>(</span><span>type-&gt;list</span> <span>t</span><span>)))</span>
</code></pre></div></div>

<p>This… is exhausting. No matter what you do in Scheme you just can’t get away from this. We have a
fragmented language, and that is very much by design. The fact that there are multiple
implementations of the R5RS/R6RS/R7RS standards that can all be considered “Scheme” is not a
problem. The problem is that when we build libraries to extend the core language we do so poorly and
incentivize users to go through lists as an intermediate as much as possible.</p>

<p>To emphasize I want to point out what Rust does because the standard library and traits are cohesive
in a way that Scheme isn’t. Look at the following snippet:</p>

<div><div><pre><code><span>let</span> <span>new_collection</span> <span>=</span> <span>values</span>
    <span>.into_iterator</span><span>()</span>
    <span>.map</span><span>(</span><span>/* ... */</span><span>)</span>
    <span>.enumerate</span><span>()</span>
    <span>.filter</span><span>(</span><span>/* ... */</span><span>)</span>
    <span>.collect</span><span>();</span>
</code></pre></div></div>

<p>This snippet of code shows so much about language design and the amount of thought that went into
developer ergonomics just to map, enumerate, and filter over a collection of items. You don’t even
know what <code>values</code> is, but it doesn’t matter! You don’t know what <code>new_collection</code> is, but it
doesn’t matter! That code will still work as long as the type of <code>values</code> implements <code>IntoIterator</code>
and the type of <code>new_collection</code> implements <code>FromIterator</code>.</p>

<h3 id="fold-ordering-is-a-f-k-xing-nightmare">Fold ordering is a <code>(f k x)</code>ing nightmare</h3>

<p>Let’s talk one more time about <code>fold</code>, <code>vector-fold</code>, et al. These functions provide a “folding”
given some function <code>f</code>, a sentinel value <code>k</code>, and a collection <code>xs</code>. Usually the signature is:</p>



<p>But what about that function <code>f</code>? What is its signature?</p>



<p>Okay, that can sometimes look a lot like <code>cons</code>, which takes in a value (<code>x</code>) and a sentinel (<code>k</code>)
and does something with it. You can then write:</p>

<div><div><pre><code><span>(</span><span>fold</span> <span>cons</span> <span>&#39;</span><span>()</span> <span>(</span><span>list</span> <span>1</span> <span>2</span> <span>3</span><span>))</span>
<span>; =&gt; (3 2 1)</span>
</code></pre></div></div>

<p>which will reverse a list. Okay, great! Let’s do the same thing for a vector of <code>xs</code> and reverse it
into a list:</p>

<div><div><pre><code><span>(</span><span>import</span> <span>srfi-133</span><span>)</span>

<span>(</span><span>vector-fold</span> <span>cons</span> <span>&#39;</span><span>()</span> <span>(</span><span>vector</span> <span>1</span> <span>2</span> <span>3</span><span>))</span>
<span>;=&gt; (((() . 1) . 2) . 3)</span>
</code></pre></div></div>

<p>What the hell? Why isn’t that the same? Aren’t these supposed to be abstractions over folding? Well,
it’s because <code>fold</code> in SRFI-1 takes in an <code>f</code> with the ordering <code>(f x k)</code> and <code>vector-fold</code> in
SRFI-133 takes in an <code>f</code> with the ordering <code>(f k x)</code>. SRFI-113 provides <code>set-fold</code> that takes in the
ordering <code>(f x k)</code> whereas SRFI-158 provides <code>generator-fold</code> that takes in the ordering <code>(f x k)</code>
whereas SRFI-160 provides <code>u8vector-fold</code> that takes in the ordering <code>(f k x)</code>… I could keep
going.</p>

<p>This is the dumbest inconsistency in the language and we’re all losing brain cells thinking about
it. Universally I think <code>cons</code>-like ordering is the wrong ordering, but here’s the thing: I wouldn’t
even care as long as we picked one and were consistent with it.</p>

<p>My point in all of this is to show that as it stands there’s a lot of complexity and a lot of
annoyances in trying to use the right data structure(s) in Scheme. Even if we dodge the whole
<code>type-&gt;list</code> and <code>list-&gt;type</code> anti-pattern, we still have to be vigilant about fold ordering, which
procedures are available (filter may not be!) and this all takes patience, time, experience, and for
a whole lot of nothing.</p>

<h3 id="one-last-point">One last point…</h3>

<p>One last point I want to make is that often times libraries often come with a collection of their
own map / fold / filter etc. procedures, but it is never really clear what the performance of these
is. I mean, one can generally think of map as being O(n), but you can’t be sure that the person who
implemented the standard was careful and wrote the best map possible.</p>

<p>A lot of SRFI’s provide a reference implementation that can work on just about any Scheme, but will
aim to be portable before it aims to be fast or efficient. I think among the complaints I could have
this is actually not a big deal. Benchmark and then make it faster based on what you measure, etc.
But the key here is that we probably should be in a position where folding / mapping / filtering are
optimized already, and we shouldn’t be suspecting those are our bottleneck. I think generally this
can be assumed true because most SRFIs are pretty high quality, but everytime I switch between data
structures I now have to ask myself:</p>

<ul>
  <li>What should I expect for performance here?</li>
  <li>What should I expect in terms of documentation?</li>
  <li>What should I expect in terms of convention?</li>
  <li>What should I expect in terms of …?</li>
</ul>

<p>I fully admit that you can’t abstract across different types without having to ask this in some
form. This is a lot to deal with when programming though. I don’t ask these kinds of questions in
Rust or C++ — <code>Iterator::map</code> and <code>std::transmute</code> operate the same as long as the type
implements the correct trait / interfaces (e.g. <code>std::begin</code> and <code>std::end</code>). Incrementing a pointer
or calling an expensive <code>Iterator::next</code> are possible, but it’s a lot easier to know where to look
if you find iteration to be slow!</p>

<p>While I love what one can do with Scheme, I hate that this is the mind-space I have to put myself in
every time I open my editor. We absolutely should strive for better, can do better, and we deserve
better.</p>

<h2 id="why-not-use">Why not use…?</h2>

<p>So I started seeking out if there was something in Scheme that allowed me to solve this problem.
There were a lot of different ways to crack it, but I want to focus on two specifically that ended
up being the closest to something that actually begins to touch on the issues I outlined.</p>

<h3 id="why-not-use-srfi-158-generators-and-accumulators">Why not use SRFI-158 (Generators and Accumulators)?</h3>

<p>SRFI-158 is the latest attempt by the SRFI committee<sup id="fnref:committee" role="doc-noteref"><a href="#fn:committee" rel="footnote">3</a></sup> to abstract over things that
“generate” and “accumulate” values. Let’s consider an example: a list can generate values by popping
off the head of the list (<code>car</code>), and the rest of the values are held in the <code>cdr</code>. Lists can also
be accumulated by <code>cons</code>ing the different parts together. You often have to reverse a list after
<code>cons</code>ing all the parts, but you can do that as a finalization step.</p>

<p>Generators and Accumulators abstract over the generation of values and the accumulation of values.
This can be done for just about any type, because generators are just regular thunks, that is,
functions that take in zero arguments. I suggest <a href="https://srfi.schemers.org/srfi-158/srfi-158.html">reading the
SRFI</a>, it is very instructive and the document explains
its expected use-case very well. It expounds on the previous SRFI-121, which only outlined
generators, but there’s notes about that too.</p>

<p>My main problem with generators and accumulators is that they basically replace all our existing
data types with a new type (generators) that can then be mapped / filtered over in a unified way.
After one is done with <code>gmap</code> / <code>gfilter</code> / etc. they can then convert this generator back into some
kind of type using an accumulator or one of the built in <code>generator-&gt;type</code> procedures. This solves a
problem of abstraction by routing around it. Rather than worry about what operations are defined on
a type, we instead just create a type that has all operations work on it.</p>

<p>This kind of approach is a good first abstraction, but fails because it is generally impossible to
make this fast. It also doesn’t solve the fact that we have <code>type-&gt;list</code> and <code>list-&gt;type</code>
proliferation. If anything, it makes it worse because most libraries are not generator-aware, and
writing generators correctly can be tricky. That’s not to say writing any code cannot be tricky, but
the obvious ways to write a generator are often using <code>make-coroutine-generator</code> which uses
<code>call/cc</code><sup id="fnref:call-cc" role="doc-noteref"><a href="#fn:call-cc" rel="footnote">4</a></sup> and as a result is pretty slow on most Schemes.</p>

<h3 id="why-not-use-srfi-171-transducers">Why not use SRFI-171 (Transducers)?</h3>

<p>Aha, so we finally get to transducers! Well, I think if you’re familiar with Clojure’s transducers,
you’re already seeing where I was heading with this. But if SRFI-171 exists and works on CHICKEN
Scheme, then why did I go ahead and make my own library? Why am I rambling about this here?</p>

<p>Well, I had some problems with SRFI-171. Mostly, I was unhappy with the interface and the sparsity
of the API. It provides some basic transduction operations like <code>list-transduce</code>,
<code>vector-transduce</code>, etc. as well as a bunch of different transducers (map / filter / etc). However,
it is missing some key components:</p>

<ul>
  <li>It cannot collect vectors, and in particular it does not provide any reducer / collection
procedure to do so.</li>
  <li>It fails to correctly parameterize what makes <code>list-transduce</code> different from e.g.
<code>vector-transduce</code>. I will get into this a bit more later.</li>
  <li>It provides transducers that definitely incentivize users to do the wrong thing with their
programs. In particular it provides <code>tdelete-neighbor-duplicates</code> and <code>tdelete-duplicates</code>. This
is very much in the realm of my opinions but if you want to delete duplicates what you want is a
“set” data structure of some kind. SRFI-113 provides a data structure in that vein (based on
SRFI-69 hash-tables) but one could very well imagine a bunch of different set-like data structures
that one might use depending on the context of the problem.<sup id="fnref:delete-duplicates" role="doc-noteref"><a href="#fn:delete-duplicates" rel="footnote">5</a></sup></li>
  <li>Documentation is sorely lacking. I actually read the SRFI documents <em>and</em> the mailing lists and I
still came away thinking “<em>this is it?</em>”. I think this can be fixed, and this comment definitely
deserves a blog post on its own but SRFI documents are not sufficient enough on their own to
constitute good documentation for a library / API.<sup id="fnref:my-sins" role="doc-noteref"><a href="#fn:my-sins" rel="footnote">6</a></sup></li>
</ul>

<p>SRFI-171 was actually not what I wanted to even use at first either, but I slowly realized that
transducers were the only form that would tick all of the boxes for me. I tested it for performance
and well… It remains faster than SRFI-158. There’s at least one benchmark example <a href="https://srfi-email.schemers.org/srfi-171/msg/13991062/">on the mailing
list</a> where SRFI-158 is slower. I’ve seen this
across a lot of examples in my own testing, so I’m not convinced it’s a fluke. In fact, I actually
think I know <em>why</em> SRFI-171 is faster, but let’s table that for now.</p>

<p>Needless to say, I felt that there was something lacking in SRFI-171 and that I could do better.
Unfortunately the things I wanted to change weren’t really possible to retro-actively adapt into
SRFI-171. Unlike a normal library, the whole point of SRFIs is that once they’re finalized, that
SRFI is locked in stone. You can’t just add or remove or deprecate functions. You can change the
default implementation if there’s a bug or add a post-finalization note about how the
implementation should behave if there’s ambiguity, but you can’t just start picking and ripping at
an SRFI. This kind of attitude towards software / APIs is anathemic to change. This can be seen as
good or bad, but I think this kind of ideology is mostly dead outside of Scheme (and maybe parts of
C++). I want to clarify that I don’t disparage the SRFI team, I think there’s a lot in the community
who want to standardize across Scheme implementations, but this is not how any other language works
with their libraries in the year 2023.</p>



<p>Okay, okay, let’s shift the tone a bit. I have been complaining a lot about Scheme and our libraries
(with love), but let’s finally talk about what <a href="https://www.youtube.com/watch?v=6mTbuzafcII">transducers</a>
actually are. Transducers were an “invention” of Rich Hickey, the creator of Clojure. I put
“invention” in quotes here because I think that a lot of the groundwork and ideas somewhat predate
Rich Hickey in the literature that he references in the original video I linked. But for the sake of
making this easier to refer to, we’ll say “invented.”</p>

<p>Anyways, the main trick with transducers is that we can treat almost any map / filter / etc.
operation as a left-fold over some data structure. That data structure must be some kind of “totally
ordered multi-set,”<sup id="fnref:series" role="doc-noteref"><a href="#fn:series" rel="footnote">7</a></sup> that is:</p>

<ul>
  <li>It must have some total ordering (i.e. we can get the items in it out in some order)
    <ul>
      <li>We don’t actually need that ordering to be anything specific, it just needs to exist.</li>
      <li>Lists have an ordering if you start from the head and move to the tail</li>
      <li>There doesn’t just have to be one ordering, vectors can be ordered forward and in reverse for
example.</li>
    </ul>
  </li>
  <li>It must contain elements (items) that we can sequentially operate (fold) over.</li>
</ul>

<p>Anyways, given some “multi-set” whose items “can be ordered” we can basically replace any map /
filter / etc. with an equivalent fold operation. For example one could take the <code>fold</code> from SRFI-1
and implement map:</p>

<div><div><pre><code><span>;; Assume some mapping function `f`</span>

<span>(</span><span>fold</span> <span>cons</span>
      <span>&#39;</span><span>()</span>
      <span>(</span><span>fold</span> <span>(</span><span>lambda</span> <span>(</span><span>x</span> <span>k</span><span>)</span> <span>(</span><span>cons</span> <span>(</span><span>f</span> <span>x</span><span>)</span> <span>k</span><span>))</span>
            <span>&#39;</span><span>()</span>
            <span>(</span><span>list</span> <span>1</span> <span>2</span> <span>3</span> <span>4</span> <span>5</span><span>))</span>
</code></pre></div></div>

<p>I added in the reverse above as another fold as well. Anyways, the key is that “map” really only
depends on the reducing function (in the above example, <code>cons</code>) to be implemented. So the difference
between e.g. SRFI-1 <code>map</code> and SRFI-133 <code>vector-map</code> is really just parameterizing on how we “reduce”
across the fold. If it’s <code>cons</code>, then we get SRFI-1 <code>map</code>. If it’s something more complicated (like
creating a vector and pushing items into it), then we could get a <code>vector-map</code> instead.</p>

<p>So the first trick to transducers is that every “transducer” function (map / filter / etc.) is
parameterized based on the “reducer.” The video goes into good detail about this, but basically we
change <code>map</code> from something that looks like fold into:</p>

<div><div><pre><code><span>(</span><span>define</span> <span>(</span><span>map</span> <span>f</span><span>)</span>
  <span>(</span><span>lambda</span> <span>(</span><span>reducer</span><span>)</span>
    <span>(</span><span>case-lambda</span>
      <span>(()</span> <span>(</span><span>reducer</span><span>))</span>
      <span>((</span><span>result</span><span>)</span> <span>(</span><span>reducer</span> <span>result</span><span>))</span>
      <span>((</span><span>result</span> <span>item</span><span>)</span>
       <span>(</span><span>reducer</span> <span>result</span> <span>(</span><span>f</span> <span>item</span><span>))))))</span>
</code></pre></div></div>

<p>Notice the ordering of our reducer is different than <code>cons</code> ordering, but we’ll ignore that for
now. The second trick can also be seen in the above snippet as well: by using <code>case-lambda</code> we can
have a few different forms for our transducer. If I were to give names to them I’d call them:</p>

<ul>
  <li><strong>No arguments</strong> (<code>sentinel</code>): The sentinel value to use. As we can see here it depends on the
reducer to decide what that default value is.</li>
  <li><strong>One argument</strong> (<code>finalize / collect</code>): This is what to do once we have our final “almost reduced” value.
In the case of the example I gave earlier this was just returning the list, but one could imagine
reversing the list, shrinking a vector, etc. You can see <code>map</code> depends on the reducer here too.</li>
  <li><strong>Two arguments</strong> (<code>reduce-step</code>): This is what we typically think of when thinking of the reduce
function. In the original example I gave for mapping-as-a-fold this was <code>(lambda (x k) (cons (f x)
k))</code>.</li>
</ul>

<p>Okay, so that’s about the two tricks that one needs to know about transducers in order to understand
how to use them in Clojure. Mostly, you can take any “collection” in Clojure and you can then use
the following form:</p>

<div><div><pre><code><span>(</span><span>transduce</span><span> </span><span>(</span><span>comp</span><span>
             </span><span>(</span><span>filter</span><span> </span><span>odd?</span><span>)</span><span>
             </span><span>(</span><span>map</span><span> </span><span>(</span><span>lambda</span><span> </span><span>(</span><span>x</span><span>)</span><span> </span><span>(</span><span>*</span><span> </span><span>3</span><span> </span><span>x</span><span>))))</span><span>
           </span><span>+</span><span>
           </span><span>(</span><span>range</span><span> </span><span>5</span><span>))</span><span>
</span></code></pre></div></div>

<p>or, you can provide a sentinel value (e.g. <code>100</code>) directly:</p>

<div><div><pre><code><span>(</span><span>transduce</span><span> </span><span>(</span><span>comp</span><span>
             </span><span>(</span><span>filter</span><span> </span><span>odd?</span><span>)</span><span>
             </span><span>(</span><span>map</span><span> </span><span>(</span><span>lambda</span><span> </span><span>(</span><span>x</span><span>)</span><span> </span><span>(</span><span>*</span><span> </span><span>3</span><span> </span><span>x</span><span>))))</span><span>
           </span><span>+</span><span>
           </span><span>100</span><span>
           </span><span>(</span><span>range</span><span> </span><span>5</span><span>))</span><span>
</span></code></pre></div></div>

<p>Okay, cool. This does seem to solve what I want in Scheme, at least in principle. Let’s tick off
some boxes:</p>

<ul>
  <li>All transducers are independent of the input collection / type</li>
  <li>We don’t use lists as intermediates, in fact we can ignore lists entirely and use whatever
data structures make the most sense.</li>
  <li>[?] Fold ordering is consistent. It is in Clojure, but mostly because when we define transducers
or collectors our <code>reduce-step</code> must always be in the same order. In the <code>map</code> definition I gave
above it is always <code>(result item)</code> not <code>(item result)</code> like it is with <code>cons</code>. This could go
either way but transducers only work if that is uniform!</li>
  <li>Performance is linked to the type we’re iterating over, but map and filter aren’t getting
faster or slower as a result of that. We avoid inefficiency in intermediate types / copies though,
and we don’t have to invent new <code>type-1-&gt;type-2</code> methods everywhere as we go.</li>
</ul>



<p>So transducers are really the solution I’ve been looking for. SRFI-171 suggests they are fast, and
Clojure shows that they have most if not all of the properties I’m looking for. But SRFI-171 is
limited and doesn’t provide everything I’m looking for. Additionally, Clojure seems to be able to do
some magic. For example, why can I do the following in Clojure:</p>

<div><div><pre><code><span>(</span><span>transduce</span><span> </span><span>(</span><span>map</span><span> </span><span>add1</span><span>)</span><span> </span><span>+</span><span> </span><span>&lt;list-or-vector-or-hashmap-or...&gt;</span><span>)</span><span>
</span></code></pre></div></div>

<p>but in Scheme I seem to have to do:</p>

<div><div><pre><code><span>(</span><span>list-transduce</span> <span>(</span><span>map</span> <span>add1</span><span>)</span> <span>+</span> <span>&lt;list&gt;</span><span>)</span>
</code></pre></div></div>

<p>or</p>

<div><div><pre><code><span>(</span><span>vector-transduce</span> <span>(</span><span>map</span> <span>add1</span><span>)</span> <span>+</span> <span>&lt;vector&gt;</span><span>)</span>
</code></pre></div></div>

<p>???</p>

<p>It certainly seems like Clojure is doing some magic underneath the hood, but what is it?</p>

<h2 id="polymorphism-and-monomorphization">Polymorphism and monomorphization</h2>

<p>Well, in short, Clojure can provide a form of parametric polymorphism via <a href="https://clojure.org/reference/protocols">Clojure
Protocols</a>. This allows them to dispatch the <code>transduce</code> call
according to what type the argument in the last place of the call-site is. So if you passed a list,
you get effectively <code>list-transduce</code>, and if you pass a hashmap, you’d get <code>hashmap-transduce</code>.</p>

<p>This works well enough in Clojure because protocols leverage the JVM; specifically, they basically
map 1:1 with a Java Interface on the backend. But Scheme isn’t on the JVM (at least, not all
Schemes), and implementing some kind of dynamic-dispatch is going to introduce some overhead. Some
Scheme systems have object systems like <a href="https://wiki.call-cc.org/eggref/5/coops">COOPS</a> or
<a href="https://www.gnu.org/software/guile/manual/html_node/GOOPS.html">GOOPS</a>, but this is:</p>

<ol>
  <li>A lot of code to depend on</li>
  <li>Not going to be generally portable</li>
</ol>

<p>Portability wasn’t really my concern here. After all, I’m really only concerned with CHICKEN Scheme.
If I wanted to use Guile, I’d use it, but it is not the Scheme I reach for usually. Nevertheless, I
don’t want to dive into something so CHICKEN-specific here. The point I really want to make is one
that’s not too dissimilar to what Rich Hickey made about how map / filter et al. are just
parameterizations of a left-fold: Clojure’s polymorphic dispatch is just an assumed parameterization
of the <code>transduce</code> form.</p>

<p>I wrote some of these thoughts <a href="https://coales.co/@thatgeoguy/109593495240951129">on Mastodon</a> but to
summarize here: I think the main difference here is that Scheme is aggressively monomorphic by
default. As a dynamic language that doesn’t have a single implementation or host platform /
environment, it is always going to be. So we have to think about <code>transduce</code> not as it is in
Clojure, but as it should be if we parameterized the assumed traversal of the data structure.
Thinking this way gets us a new kind of transduce:</p>

<div><div><pre><code><span>(</span><span>transduce</span> <span>folder</span>     <span>; A procedure that knows how to fold across a data structure</span>
           <span>transducer</span> <span>; The xforms / transducers used in clojure</span>
           <span>collector</span>  <span>; The reducer that &#34;collects&#34; the final result</span>
           <span>sentinel</span>   <span>; A sentinel value (optional) to seed the collector</span>
           <span>data</span><span>)</span>      <span>; The data to fold over</span>
</code></pre></div></div>

<p>This gives us a <code>transduce</code> that shows us a pipeline of different pieces we can put together:</p>

<ul>
  <li><strong>folder</strong>: Think of this as the routine that can pick apart our data</li>
  <li><strong>transducer</strong>: These are the operations that happen on our data as it passes through the
pipeline.</li>
  <li><strong>collector</strong>: This is the structure in which we want to collect our output.</li>
</ul>

<p>Folder, transducer, and collector all happen in that order, so I have placed the fold operation as
the first argument. In my egg, one can then do:</p>

<div><div><pre><code><span>(</span><span>transduce</span> <span>list-fold</span>
           <span>(</span><span>compose</span>
             <span>(</span><span>filter</span> <span>odd?</span><span>)</span>
             <span>(</span><span>map</span> <span>add1</span><span>))</span>
           <span>+</span>
           <span>100</span>
           <span>(</span><span>list</span> <span>1</span> <span>2</span> <span>3</span> <span>4</span> <span>5</span> <span>6</span> <span>7</span> <span>8</span> <span>9</span><span>))</span>
</code></pre></div></div>

<p>What does this do under the hood? Well, here’s the code:</p>

<div><div><pre><code><span>(</span><span>define</span> <span>transduce</span>
  <span>(</span><span>case-lambda</span>
    <span>((</span><span>folder</span> <span>xform</span> <span>collector</span> <span>iterable</span><span>)</span>
     <span>(</span><span>transduce</span> <span>folder</span> <span>xform</span> <span>collector</span> <span>(</span><span>collector</span><span>)</span> <span>iterable</span><span>))</span>
    <span>((</span><span>folder</span> <span>xform</span> <span>collector</span> <span>sentinel</span> <span>iterable</span><span>)</span>
     <span>(</span><span>let*</span> <span>((</span><span>xf</span> <span>(</span><span>xform</span> <span>collector</span><span>))</span>
            <span>(</span><span>result</span> <span>(</span><span>folder</span> <span>xf</span> <span>sentinel</span> <span>iterable</span><span>)))</span>
       <span>(</span><span>xf</span> <span>result</span><span>)))))</span>
</code></pre></div></div>

<p>The important bit is in that second <code>case-lambda</code> arm. We leverage the folder to be specific to the
iterable (list, vector, set, mapping, etc.). This maintains the monomorphic dispatch that Scheme
requires, without losing generality. We don’t have to proliferate multiple <code>transduce</code> procedures
that then need to be tested / documented / remembered. Instead, we just need a special fold for each
type.</p>

<div><div><pre><code><span>(</span><span>define</span> <span>(</span><span>list-fold</span> <span>f</span> <span>sentinel</span> <span>xs</span><span>)</span>
  <span>(</span><span>if</span> <span>(</span><span>null?</span> <span>xs</span><span>)</span>
    <span>sentinel</span>
    <span>(</span><span>let</span> <span>((</span><span>x</span> <span>(</span><span>f</span> <span>sentinel</span> <span>(</span><span>car</span> <span>xs</span><span>))))</span>
      <span>(</span><span>if</span> <span>(</span><span>reduced?</span> <span>x</span><span>)</span>
        <span>(</span><span>unwrap</span> <span>x</span><span>)</span>
        <span>(</span><span>list-fold</span> <span>f</span> <span>x</span> <span>(</span><span>cdr</span> <span>xs</span><span>))))))</span>
</code></pre></div></div>

<p>In particular, this fold is a bit different than what is usually written. The trick here is that we
have one more branch operation for checking if a value is <code>reduced?</code> or not. Some algorithms quit
early without traversing a whole list. For example, if we wanted to <code>find</code> the first odd number in a
list we wouldn’t want to have to traverse the rest of the list after we find it. Likely, you’ve been
trained to use <code>call/cc</code> for this kind of early exit, but transducers don’t need it. If any
transducer (or collector) returns <code>(make-reduced x)</code> early, then the transduction will end at that
item.</p>

<p>By branching on <code>reduced?</code> in the above <code>list-fold</code>, we’re able to quit-early in a generic and
call/cc-free way. No continuations means that our code is very easy to convert into
continuation-passing-style (CPS) in a very straightforward-to-optimize way. In practice, there isn’t
really any material performance hit for doing this. It is required to make our <code>transduce</code> behave
correctly, so we need new “fold” operations for every type in order to use transduction over that
type. This admittedly isn’t <em>ideal</em>, but I’ve reduced the problem space from “reinvent every map /
filter / fold / any / every / chain / flatten / zip” operation to “reinvent fold to allow early
termination.”</p>

<p>In truth, that’s not the whole story because <code>flatten</code> / <code>chain</code> / <code>interleave</code> / <code>zip</code> operations
are type specific as well. However, these can be managed mostly through macros (which are publicly
exported and documented with clear examples). I would like to come up with a better solution here,
but I’m not sure that I will anytime soon. I’ve spent enough time faffing about on it already so I
think I’ll take a break and accept what I have.</p>

<h2 id="on-naming">On Naming</h2>

<p>I’m admittedly taking a deviation in normal Scheme naming in some places. More importantly though,
I’ve chosen to not provide map / filter / etc. under prefixed names. I strongly believe we need to
move out of the era of pretending that lists are the default for these. Transducers should be the
default, and we should just train people to use them.</p>

<p>Are they confusing? Certainly at first they are very confusing. If you’ve made it this far into the
post though I’m certain you (the reader) are not that far from understanding it
completely.<sup id="fnref:on-confusion" role="doc-noteref"><a href="#fn:on-confusion" rel="footnote">8</a></sup></p>

<h2 id="performance">Performance</h2>

<p>Performance is great. I’m going to mostly avoid benchmarks and let you do your own, because there’s
no way I’ll be able to fairly represent whatever you’re trying to do. But just for fun run this:</p>

<div><div><pre><code>$ cat transducer-bench.scm
(import transducers)

(time
  (transduce
    fixnum-range-fold
    (compose
      (filter odd?)
      (map (lambda (x) (* 3 x))))
    +
    (iota 100000000)))
</code></pre></div></div>

<p>Note that <code>iota</code> above is not from SRFI-1. On my machine I get the following output:</p>

<div><div><pre><code>$ csc -O3 -static transducer-bench.scm
$ time ./transducer-bench
3.518s CPU time, 0.001s GC time (major), 1/108400 GCs (major/minor), maximum live heap: 877.83 KiB

real	0m3.540s
user	0m3.535s
sys	0m0.004s
</code></pre></div></div>

<p>That’s 3.540s to filter, multiply, and sum <code>100_000_000</code> numbers. That’s pretty good! Admittedly
this isn’t representative of a real workflow in any way, but the generator equivalent is much
slower:</p>

<div><div><pre><code>$ cat gen-bench.scm
(import srfi-158)

(time
  (generator-fold
    +
    0
    (gmap (lambda (x) (* 3 x))
          (gfilter odd?
                   (make-iota-generator 100000000)))))
$ csc -O3 -static gen-bench.scm
$ time ./gen-bench
9.666s CPU time, 0.001s GC time (major), 100000002/81404 mutations (total/tracked), 5/256433 GCs (major/minor), maximum live heap: 368.68 KiB

real	0m9.674s
user	0m9.607s
sys	0m0.064s
</code></pre></div></div>

<h3 id="why-are-transducers-faster-than-generators">Why are transducers faster than generators?</h3>

<p>I mentioned earlier that I think I know the reason transducers are faster than generators (generally
speaking). In the definition of <code>transduce</code>:</p>

<div><div><pre><code><span>(</span><span>define</span> <span>transduce</span>
  <span>(</span><span>case-lambda</span>
    <span>((</span><span>folder</span> <span>xform</span> <span>collector</span> <span>iterable</span><span>)</span>
     <span>(</span><span>transduce</span> <span>folder</span> <span>xform</span> <span>collector</span> <span>(</span><span>collector</span><span>)</span> <span>iterable</span><span>))</span>
    <span>((</span><span>folder</span> <span>xform</span> <span>collector</span> <span>sentinel</span> <span>iterable</span><span>)</span>
     <span>(</span><span>let*</span> <span>((</span><span>xf</span> <span>(</span><span>xform</span> <span>collector</span><span>))</span>
            <span>(</span><span>result</span> <span>(</span><span>folder</span> <span>xf</span> <span>sentinel</span> <span>iterable</span><span>)))</span>
       <span>(</span><span>xf</span> <span>result</span><span>)))))</span>
</code></pre></div></div>

<p>We generate the procedure <code>xf</code> by calling <code>(xform collector)</code>. The final function that we call on
every item is the composition and execution of all the <code>xform</code>s over the <code>collector</code>. By the time we
start to fold over some data type by calling the <code>folder</code> our function <code>xf</code> is:</p>

<ol>
  <li>Already finally defined - it can thus be compiled and inlined pretty aggressively</li>
  <li>Local - we don’t have to call multiple functions to do all our mapping / filtering / etc.
Generators like <code>gmap</code> have to loop internally and manage internal state, which means that
they’re calling other generators, which might be calling other generators, and so on. Transducers
loop over data locally and call one function (which can be cached / inlined) that does
everything across the whole algorithm. Transducers’ speed is defined by the complexity of the
process, not by the number of intermediate layers taken to express that process.</li>
</ol>

<p>Now I might be wrong on one or both of those points (after all, I did not inspect the compiled
output to really confirm this), but my intuition is telling me I can’t be that far off. Overall, I’m
not sure that a well-written transducer is ever going to be slower than an equivalent generator.
Many in the Scheme community won’t care about performance as much as I do here, so it may be
immaterial. ¯\_(ツ)_/¯</p>

<h2 id="other-goodies">Other Goodies</h2>

<h3 id="amortized-o1-collection-of-any-vector-type">Amortized O(1) collection of any vector type</h3>

<p>Let’s say that the entire Scheme community looks at this project and thinks: yeah no thanks. If
you’re going to dismiss what is done here PLEASE PLEASE PLEASE just see
<a href="https://gitlab.com/ThatGeoGuy/chicken-transducers/-/blob/main/src/transducers.vectors.scm#L98"><code>src/transducers.vectors.scm</code></a>
and how I add vector collection. With this library you can do:</p>

<div><div><pre><code><span>(</span><span>import</span> <span>transducers</span><span>)</span>

<span>(</span><span>transduce</span> <span>range-fold</span>
           <span>(</span><span>compose</span>
             <span>(</span><span>filter</span> <span>odd?</span><span>)</span>
             <span>(</span><span>map</span> <span>add1</span><span>))</span>
           <span>(</span><span>collect-u8vector</span><span>)</span>
           <span>(</span><span>iota</span> <span>100</span><span>))</span>
</code></pre></div></div>

<p>The magic here is <code>(collect-u8vector #!optional (size-hint 0))</code>, which will push all results to a
vector in amortized O(1) time, using a strategy reminiscent to what Rust’s <code>Vec</code> and C++’s
<code>std::vector</code> do. This operation (or at least one like it, named differently) is available for all:</p>

<ul>
  <li>Scheme vectors (aka <code>vector</code>)</li>
  <li>SRFI-4 &amp; SRFI-160 vectors (including <code>c64</code> and <code>c128</code> vectors)</li>
</ul>

<p>There is no intermediate list built, there is no conversion from another data structure. When the
vector being collected runs out of size and needs to be extended, it uses 2× the capacity (so
exponential growth) and will copy over the data using what effectively amounts to a memcpy. It is
<em>fast</em>.</p>

<p>If nothing else these very same procedures work with SRFI-171 Transducers as well. I have released
the egg under the MIT license so copy and paste them into your code if you must, but can we please
incorporate this more wholly into the Scheme ecosystem?</p>

<p>Lastly - this can be optimized even further if one decides to add a size-hint to the collector:</p>

<div><div><pre><code><span>(</span><span>import</span> <span>transducers</span><span>)</span>

<span>(</span><span>transduce</span> <span>range-fold</span>
           <span>(</span><span>compose</span>
             <span>(</span><span>filter</span> <span>odd?</span><span>)</span>
             <span>(</span><span>map</span> <span>add1</span><span>))</span>
           <span>(</span><span>collect-u8vector</span> <span>100</span><span>)</span>
           <span>(</span><span>iota</span> <span>100</span><span>))</span>
</code></pre></div></div>

<p>While the size may not be precise (filter could allow through 100% of the data or 0% of the data),
the size-hint can help you reduce the amount of re-allocation you’re doing if you think you have an
idea of the size of the final collection. Also notice that <code>iota</code> is from the <code>transducers</code> library.
It’s a custom range structure that should be faster to use with transducers than constructing a full
list with SRFI-1’s <code>iota</code> procedure.</p>

<h3 id="reader-fold-works-with-generators-today"><code>reader-fold</code> works with generators today</h3>

<p>I probably won’t use SRFI-158 (generators and accumulators) ever again but you might already have
incorporated them into some of your code. The <code>reader-fold</code> procedure works with generators as they
are today, as well as procedures like <code>read</code> / <code>read-char</code> / <code>read-byte</code> / etc.</p>

<p>Transducers are general enough that they can support generators without having to do anything
special:</p>

<div><div><pre><code><span>(</span><span>import</span> <span>transducers</span> <span>srfi-158</span><span>)</span>

<span>(</span><span>transduce</span> <span>reader-fold</span>
           <span>values</span>
           <span>collect-list</span>
           <span>(</span><span>make-iota-generator</span> <span>10</span><span>))</span>
</code></pre></div></div>

<p>So if you have a generator today I suspect that switching will be easy.</p>

<h2 id="some-open-problems-with-the-transducers-egg">Some open problems with the <code>transducers</code> egg</h2>

<p><code>transducers</code> isn’t really perfect — far from it. There are still a lot of things that I’m not
sure about. A short list of my gripes and open questions with the code I’ve written so far:</p>

<ol>
  <li>Is passing the <code>folder</code> procedure into <code>transduce</code> ergonomic or should I be making
<code>list-transduce</code> / <code>vector-transduce</code> / <code>reader-transduce</code> and such like SRFI-171 does? I like
how explicit the current form is so I am likely to leave it, but I’m open to hearing if the
Scheme community has strong dissent here.</li>
  <li>I currently have not made this an R7RS module. Do folks outside of the CHICKEN community want me
to make this more general? Some shims would be needed (mostly for the check-errors egg), but I
think it could be done. I’ve avoided it for the most part because CHICKEN’s module system has
been enough for me, but if there’s interest I can look into it.</li>
  <li>Macros for different <code>flatten</code> / <code>chain</code> / <code>interleave</code> / <code>zip</code> transducers. What to do with
these? Is the macro-based approach the most extensible for outside types? I feel like while the
macros I’ve written aren’t too hard to come to terms with it can be a bit dizzying to get started
with someone else’s macros vs. just implementing the procedure yourself.</li>
  <li>Strings. One thing missing from all of this is the fact that I haven’t provided <code>string-fold</code> /
<code>collect-string</code> variants in the same way that I did for vectors. This is mostly because strings
suck, and I’m not sure how to best dance on the UTF-8 / non-UTF-8 minefield that CHICKEN has
going on. If one wants to the <code>reader-fold</code> operations can be used with the corresponding
<code>read-char</code> and <code>with-input-from-string</code> procedures to get string support for transducers, but
that seems like it’s likely to encourage bad performance. Hopefully there’s a version of CHICKEN
someday where I can just ship UTF-8 string support only. <a href="https://wiki.call-cc.org/unicode-transition#how-to-handle-invalid-utf-8-sequences">That’s a possibility,
maybe?</a></li>
</ol>



<p>Before I’m done, I do want to clear some air on my thoughts on the SRFI and standardization efforts
within the Scheme community. First and foremost, I want to be clear that I do not disparage those
who work on SRFIs nor do I think the work they are doing is useless or otherwise harmful to Scheme
as a community. I believe some of my post will come off as rather critical of the SRFI process,
which I think is appropriate (in measures, at least).</p>

<p>I am not going to name or point to any particular member of the SRFI process, nor am I going to try
and blame them all for my criticisms here. I think of a lot of this as evolutionary, not
revolutionary. But to get to the point, my feedback for the SRFI process:</p>

<ul>
  <li>There is too much wasted focus on <code>-map</code> / <code>-filter</code> / etc. procedures as part of each SRFI
process. This is especially true when discussing data structure SRFIs. It’s a waste of time -
transducers have all but won (in my mind at least, and in the mind of the Clojure community). I
think given the level of abstraction allowed by transducers, some version of them (similar to my
egg or otherwise) should probably be the base standard to which we hold our collections.</li>
  <li>As a corollary to the above point, there are things transducers <strong>should not</strong> do. I didn’t really
go into it because it’s a bit of a distraction from the article I was writing, but e.g. procedures
like <code>set-union</code>, <code>sort!</code>, etc. are prime examples. For these kinds of algorithms, we should
absolutely spend more time fleshing out SRFIs to figure out how to make those work across
different Scheme implementations in an ergonomic way. But there’s a big difference between
operating on the whole collection vs. type-specific functionality.</li>
  <li>More thought and leadership needs to be put in to direct the “standard library” of R7RS-large (or
R8RS-large or whatever) to be more interoperable and compatible across the board. Rust is a good
example here — while the language is young the core team goes to brutal extents to make sure
that traits and features integrate well together. It’s a lot of work (and I realize I’m trying to
both beg and choose here) but the current state of affairs isn’t enough in my opinion. This isn’t
even some argument or doom-saying about commercial use of Scheme either, because regular users
have to put up with inconsistencies like <code>(f x k)</code> vs <code>(f k x)</code> ordering all the dang time! I know
we’re all hacking for fun and education and to scratch our own itches but we really ought to get
the core bits right.</li>
</ul>

<p>Does this mean we need a regular Scheme conference where we can all get together and help guide
this? Are we not inter-mingling ideas across different Schemes and Lisps and languages and programs
enough? I won’t prescribe an answer but I can for sure say that I have hope that the SRFI process
can adapt.</p>

<p>Overall I don’t even think most of the SRFIs are useless or anything; heck, I use a few of them in
some capacity as dependencies of <code>transducers</code>. I don’t even think things like <code>vector-copy!</code> or
<code>reverse!</code> need to be in Scheme proper but ultimately we should make sure that we’re not directing
users to interfaces like <code>vector-map</code> or <code>vector-append</code> when in practice the code that folks want
to write is a transducer.<sup id="fnref:the-code-users-want-to-write" role="doc-noteref"><a href="#fn:the-code-users-want-to-write" rel="footnote">9</a></sup></p>



<p>In short: use transducers, whether it be the egg I just published or SRFI-171 or something you’ve
built yourself. They’re performant, they’re composable, and they’re a hell of a lot easier to test.
They stop us all from having to reinvent the wheel that is mapping / folding / filtering every time
a new data type comes along. You and your code and your users will thank you.</p>

<p>I set out this blog post trying to understand <strong>why</strong> Scheme didn’t have anything as powerful or
flexible as Rust’s <code>Iterator</code> trait. I don’t know if my transducers egg is as powerful or flexible,
but it certainly is a step towards it. Scheme is a great language regardless of the critcisms or
holes I’ve poked about different features of the language and community here, and it’s helped me
conceptualize a lot of important ideas that I’ve taken with me to other languages. My hope is that
by introducing a different kind of transducer into Scheme I’ll be helping someone else skip past a
lot of the churn that comes with learning and working with Scheme.</p>

<p>To end this, I want to provide a few helpful URLs:</p>

<ul>
  <li><strong>Repository</strong> (MIT licensed): <a href="https://gitlab.com/ThatGeoGuy/chicken-transducers">https://gitlab.com/ThatGeoGuy/chicken-transducers</a></li>
  <li><strong>Documentation</strong>: <a href="https://wiki.call-cc.org/eggref/5/transducers">https://wiki.call-cc.org/eggref/5/transducers</a></li>
  <li><strong>CHICKEN bug tracker</strong>: <a href="https://bugs.call-cc.org">https://bugs.call-cc.org</a></li>
</ul>

<p>I highly suggest giving those a read over and of course feel free to leave feedback (either on the
repo or the CHICKEN bug tracker) if you find anything good worth discussing. You can also find me in
<code>#chicken</code> or <code>#scheme</code> on LiberaChat.</p>

<hr/>



        </div></div>
  </body>
</html>
