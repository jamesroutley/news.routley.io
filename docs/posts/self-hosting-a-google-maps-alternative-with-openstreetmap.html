<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://wcedmisten.fyi/post/self-hosting-osm/">Original</a>
    <h1>Self Hosting a Google Maps Alternative with OpenStreetMap</h1>
    
    <div id="readability-page-1" class="page"><div><div><div><div><p><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M3.5 0a.5.5 0 0 1 .5.5V1h8V.5a.5.5 0 0 1 1 0V1h1a2 2 0 0 1 2 2v11a2 2 0 0 1-2 2H2a2 2 0 0 1-2-2V5h16V4H0V3a2 2 0 0 1 2-2h1V.5a.5.5 0 0 1 .5-.5z"></path></svg> <!-- -->November 20, 2022<!-- --></p><p><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 16 16" height="1em" width="1em" xmlns="http://www.w3.org/2000/svg"><path d="M16 8A8 8 0 1 1 0 8a8 8 0 0 1 16 0zM8 3.5a.5.5 0 0 0-1 0V9a.5.5 0 0 0 .252.434l3.5 2a.5.5 0 0 0 .496-.868L8 8.71V3.5z"></path></svg> <!-- -->9 min read<!-- --></p></div></div><h2 id="why-thats-weird">Why? That&#39;s weird</h2>
<!-- --><p>No, it&#39;s not! Google Maps is probably the most amazing service we get for free<!-- --><sup><a href="#user-content-fn-google-footnote" id="user-content-fnref-google-footnote" data-footnote-ref="true" aria-describedby="footnote-label">1</a></sup>
It&#39;s something I use almost every day and is incredibly useful for getting around.<!-- --></p>
<!-- --><p>But what if I didn&#39;t need Google at all?</p>
<!-- --><p>OpenStreetMap provides crowdsourced mapping
data available for free to the world. But this isn&#39;t to say I can just use OSM.
The organization does provide the data, but its usage policy encourages users
to not rely on their servers for personal use,
and instead take responsibility for hosting themselves.
And based on this project, I can see why. The hardware requirements are not for
the faint of heart.</p>
<!-- --><h2 id="hardware">Hardware</h2>
<!-- --><p>I had access to a gaming PC that was mostly unused.
These days my girlfriend and I prefer to play couch
co-op games on the Switch, rather than on PCs in separate rooms.
So I thought I&#39;d make use of this fairly beefy desktop and turn it
into a self-hosted map server.</p>
<!-- --><p>This particular desktop<!-- --><sup><a href="#user-content-fn-desktop" id="user-content-fnref-desktop" data-footnote-ref="true" aria-describedby="footnote-label">2</a></sup> has:<!-- --></p>
<!-- --><ul>
<!-- --><li>Intel i7 gen 10700kf CPU</li>
<!-- --><li>32 GB of RAM</li>
<!-- --><li>1TB NVMe SSD</li>
<!-- --><li>GTX 2070 GPU</li>
<!-- --><li>750 Watt PSU</li>
<!-- --></ul>
<!-- --><p>It cost $1,270 when I bought it (open box) from Microcenter
about two years ago.</p>
<!-- --><p>To meet the demanding requirements<!-- --><sup><a href="#user-content-fn-osm-requirements" id="user-content-fnref-osm-requirements" data-footnote-ref="true" aria-describedby="footnote-label">3</a></sup>
for running a map server for the entire planet,
I also bought 128 GB of RAM to replace the 32 GB it came with.
This brought the total hardware cost to $1,670.<!-- --></p>
<!-- --><p>This is quite a large price for self-hosting, but it should
be noted that the requirements are roughly proportional to the
geographic boundaries of the data. If you wanted to self-host
a map service for a smaller region (a European country or a few
US states), this could be accomplished with a much more modest
computer.</p>
<!-- --><p>In the end, I compromised and lowered my expectations
to only hosting the map data for North America.</p>
<!-- --><h2 id="requirements">Requirements</h2>
<!-- --><p>What does it take to match Google Maps? In my mind, there are 3 main
requirements:</p>
<!-- --><ul>
<!-- --><li>A &#34;slippy map&#34; which can be dragged and zoomed interactively</li>
<!-- --><li>A way to route from place to place</li>
<!-- --><li>A way to search for locations</li>
<!-- --></ul>
<!-- --><p>These can be solved with 3-ish services:</p>
<!-- --><ul>
<!-- --><li>a tile server<!-- --><sup><a href="#user-content-fn-tile" id="user-content-fnref-tile" data-footnote-ref="true" aria-describedby="footnote-label">4</a></sup> (technically this involves multiple services)<!-- --></li>
<!-- --><li>valhalla<!-- --><sup><a href="#user-content-fn-valhalla" id="user-content-fnref-valhalla" data-footnote-ref="true" aria-describedby="footnote-label">5</a></sup>, a routing service<!-- --></li>
<!-- --><li>nominatim<!-- --><sup><a href="#user-content-fn-nominatim" id="user-content-fnref-nominatim" data-footnote-ref="true" aria-describedby="footnote-label">6</a></sup>, a geocoding service<!-- --></li>
<!-- --></ul>
<!-- --><h2 id="implementation">Implementation</h2>
<!-- --><p>To accomplish this, I set up a github repo to group together
these core services and run them using docker-compose.</p>
<!-- --><p>This repo can be found
<!-- --><a href="https://github.com/wcedmisten/docker-openstreetmap-stack">here</a>.<!-- --></p>
<!-- --><p>It was surprisingly easy to piece together these dockerized
services in a single docker-compose.</p>
<!-- --><p>The READMEs for these services suggest creating a separate
docker volume before starting the containers.
This is useful because the import can take a very long time
(multiple days for the whole planet).</p>
<!-- --><p>I initially tried to import the entire planet.osm.pbf file,
which is currently 66 GB. However, the import kept crashing, so I
limited the scope of my project to only use data in North America.
If I need to travel abroad anytime soon I&#39;ll just have to use Google Maps.</p>
<!-- --><p>The North America extract is only 12GB in its compressed protobuf format,
so I was able to run all 3 services on this data.</p>
<!-- --><p>Remarkably, the services extract this data into a much more verbose
(but more read efficient) format.</p>
<!-- --><p>To see how much final disk space was being used, I ran:</p>
<!-- --><pre><code>docker system <!-- --><span>df</span> -v
<!-- --></code></pre>
<!-- --><p>From the output, it was clear why I couldn&#39;t import the entire planet.</p>
<!-- --><pre><code>VOLUME NAME      LINKS     SIZE
nominatim-<!-- --><span>data</span>   <!-- --><span>1</span>         <!-- --><span>291.</span>9GB
osm-<!-- --><span>data</span>         <!-- --><span>2</span>         <!-- --><span>337.</span>8GB
osm-tiles        <!-- --><span>1</span>         <!-- --><span>203.</span>3MB
valhalla-<!-- --><span>data</span>    <!-- --><span>2</span>         <!-- --><span>37.</span>6GB
<!-- --></code></pre>
<!-- --><p>Even on this smaller extract, these services already use a large portion
of my 1TB SSD (667 GB total). Assuming the usage scales proportionally,
I would need around 3.7TB of storage for the entire planet. Not to mention
the RAM requirements also scaling.</p>
<!-- --><h2 id="webapp">Webapp</h2>
<!-- --><p>I also made some modifications to the Valhalla webapp<!-- --><sup><a href="#user-content-fn-valhalla-app" id="user-content-fnref-valhalla-app" data-footnote-ref="true" aria-describedby="footnote-label">7</a></sup> to
improve the mobile layout with a more responsive UI. These changes
got upstreamed into the main repo! Open source is amazing.<!-- --></p>
<!-- --><p>I also changed the backend services being used, to avoid
putting demand on the official OSM servers
and instead, make the requests to my own hosted instances.</p>
<!-- --><p>This demo can be found here: <!-- --><a href="https://map-demo.wcedmisten.dev">https://map-demo.wcedmisten.dev</a></p>
<!-- --><h3 id="demo-screenshots">Demo Screenshots</h3>
<!-- --><p>Routing:</p>
<!-- --><p><img src="https://wcedmisten.fyi/self-hosting-osm/routing-screenshot.png" alt="Routing from Charlottesville to Seattle"/></p>
<!-- --><p>Isochrones:</p>
<!-- --><p><img src="https://wcedmisten.fyi/self-hosting-osm/isochrone.png" alt="Pedestrian isochrone in Charlottesville"/></p>
<!-- --><h2 id="configuring-the-server">Configuring the server</h2>
<!-- --><p>To actually serve traffic outside my local network,
I had to set up some additional configurations.</p>
<!-- --><h3 id="enabling-ddns">Enabling DDNS</h3>
<!-- --><p>Because I don&#39;t have a static IP address through my
Internet Service Provider,
I needed to use a Dynamic Domain Name Service client, which
updates my DNS records to point at the current IP address of my router.
Since it&#39;s not static, my ISP occasionally will reset the IP
address allocated to me.
I used <!-- --><code>ddclient</code>. This provides less reliability than a static IP,
but it&#39;s good enough just for my hobbyist development server.<!-- --></p>
<!-- --><h3 id="nginx">Nginx</h3>
<!-- --><p>To serve traffic at different subdomains like <!-- --><code>maps.wcedmisten.dev</code>,
I set up Nginx to send traffic to each subdomain
to the correct port as configured in <!-- --><code>docker-compose.yml</code>.
I also used the <!-- --><code>certbot</code> command
to automatically generate a certificate from LetsEncrypt for
each subdomain and update the Nginx config. This part was also
pretty seamless.<!-- --></p>
<!-- --><p>This part of <!-- --><code>/etc/nginx/sites-available/default</code>
looked like this before running
<!-- --><code>certbot</code>, which added a bunch of additional config to handle
https.<!-- --></p>
<!-- --><pre><code>server {
    server_name maps.wcedmisten.dev<!-- -->
    location / {
        proxy_set_header Host $host<!-- -->
        proxy_pass http://127.0.0.1:8080<!-- -->
        proxy_redirect off<!-- -->
    }
}

server {
    server_name valhalla.wcedmisten.dev<!-- -->
    location / {
        proxy_set_header Host $host<!-- -->
        proxy_pass http://127.0.0.1:8002<!-- -->
        proxy_redirect off<!-- -->
    }
}
<!-- --></code></pre>
<!-- --><h3 id="port-forwarding">Port forwarding</h3>
<!-- --><p>Finally, to get external traffic from the internet connected to my computer
(and specifically to Nginx), I had to set up port-forwarding on my router.
The Netgear admin interface shows each device connected to the network,
so this was just a matter of forwarding port 80 (HTTP) and port (443) to the computer.
This part was much easier (and less scary) than I expected.</p>
<!-- --><h2 id="cost-comparison">Cost Comparison</h2>
<!-- --><p>It takes a <!-- --><em>lot</em> of memory to handle running a rough alternative to
Google Maps, but it&#39;s still technically feasible with consumer hardware
and with a good amount of disposable income.<!-- --></p>
<!-- --><h3 id="google-maps-api-cost">Google Maps API Cost</h3>
<!-- --><p>As of writing this, Google Maps waives the first $200 of Maps API
requests every month<!-- --><sup><a href="#user-content-fn-google-maps" id="user-content-fnref-google-maps" data-footnote-ref="true" aria-describedby="footnote-label">8</a></sup>. It also allows for unlimited use of the
embedded Google Maps API, which shows an interactive map on a website.
However, this is only unlimited for web use. The pricing for iOS/Android
is $7 / 1,000 requests.<!-- --></p>
<!-- --><p>The directions API (not including traffic data) is $5 / 1,000 requests.</p>
<!-- --><p>Finally, the geocoding API is also $5 / 1,000 requests.</p>
<!-- --><p>With some rough napkin math, we could assume each visitor using the
webapp will search 2 places (geocoding),
load the embedded map view, and make a routing request.
This would mean each 1,000 visitors would use $15 of API credits.</p>
<!-- --><p>In order words, the free tier could support around 13,000 visitors per month,
assuming minimal app usage for each visitor. After the free credits expire,
each visitor would cost $0.015.</p>
<!-- --><h3 id="self-hosting-costs">Self Hosting Costs</h3>
<!-- --><ul>
<!-- --><li>domain name: $1.43 / mo</li>
<!-- --><li>Residential ISP Bill: $69.99 / mo</li>
<!-- --><li>PC: $1,670 (one time)</li>
<!-- --><li>total: $1,670 one time + $71.42 / mo</li>
<!-- --></ul>
<!-- --><p>Assuming the purchase is amortized over two years
(that&#39;s how long I&#39;ve had it):</p>
<!-- --><ul>
<!-- --><li>total: ($1,670 / 24) + $71.42 = $141.00 / mo</li>
<!-- --></ul>
<!-- --><h3 id="self-hosting-in-the-cloud">&#34;Self Hosting&#34; in the Cloud</h3>
<!-- --><p>Based on the cheapest instance that matches my own PC&#39;s specs.
These comparisons aren&#39;t quite apples to apples because of other
considerations like egress costs, but I think these numbers
should be close enough for napkin math.</p>
<!-- --><p>DigitalOcean Droplet (Memory Optimized):</p>
<!-- --><ul>
<!-- --><li>128 GB RAM, 16 vCPUs, 1,170 GB SSD -	$832.00 / mo</li>
<!-- --><li>Total - $832.00 / mo</li>
<!-- --></ul>
<!-- --><p>AWS r6a.4xlarge EC2 Instance:</p>
<!-- --><ul>
<!-- --><li>128 GB RAM, 16 vCPUs - $653.18 / mo</li>
<!-- --><li>1TB SSD Storage - $82.24 / mo</li>
<!-- --><li>Total - $735.42 / mo</li>
<!-- --></ul>
<!-- --><p>Azure D32as v5 VM Instance:</p>
<!-- --><ul>
<!-- --><li>128 GB RAM, 32 vCPUs - $1,004.48 / mo</li>
<!-- --><li>1TB SSD Storage - $122.88 / mo</li>
<!-- --><li>Total - $1127.36 / mo</li>
<!-- --></ul>
<!-- --><h3 id="self-hosting-vs-google-maps-api">Self Hosting vs. Google Maps API</h3>
<!-- --><p>It seems clear that in terms of raw cost, self hosting on my
own hardware is way cheaper than using cloud compute.
Of course, this isn&#39;t apples to apples. Cloud buys a lot of things
that running a machine in my closet doesn&#39;t afford: backups,
IT expertise, on-call support, help desk, etc. But as a
hobbyist that&#39;s a fine tradeoff for me. I&#39;m trying to learn
more anyway, so those are almost benefits.</p>
<!-- --><p>But what about Google Maps API? It would allow for 13,000 visitors
per month just on Google&#39;s free credits! That&#39;s a lot of traffic.
When does it make more sense to self-host on my hardware?</p>
<!-- --><p>13,000</p>
<!-- --><p>Previously we said past the free tier, each visitor would
cost $0.015 on Google&#39;s APIs. And assuming the self-hosted
setup costs $141.00 / mo, which would mean we&#39;d need
141.00 / 0.015 = 9,400 additional visitors to break even.
A total of 9,400 + 13,000 = 22,400 visitors per month.</p>
<!-- --><p>22,400 per month is around 747 per day, or only
user every two minutes.</p>
<!-- --><p>I&#39;m fairly confident my machine could handle that much traffic.</p>
<!-- --><p>The issue with comparing these numbers is the same as with
comparing self hosting costs directly to cloud compute costs.
The nuance is in the value that Google Maps brings:
expertise, scalability, and proprietary map data.</p>
<!-- --><p>But for hobby projects like this one, I think self hosting
clearly makes sense.</p>
<!-- --><p>Even for professional applications, it&#39;s worth doing the math.
With docker, installing these services has been greatly simplified,
even if it takes some time.</p>
<!-- --><p>The assumptions here also assume a very light API load on the map.
If we are assuming heavier use of the map services, the tradeoff
may be even sooner. Especially with an application requiring batch
processing of large datasets.</p>
<!-- -->
<!-- --></div></div></div>
  </body>
</html>
