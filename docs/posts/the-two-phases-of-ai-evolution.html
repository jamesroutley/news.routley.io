<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://riskmusings.substack.com/p/the-two-phases-of-ai-evolution">Original</a>
    <h1>The Two Phases of AI Evolution</h1>
    
    <div id="readability-page-1" class="page"><div><div><article><div class=""><div><div dir="auto"><p><span>When things move fast, it can be hard to keep perspective on how much risk to take. In the world of AI, it feels like everything is moving fast all at once, and our world will be reshaped in unpredictable ways. As I wrote in my article on </span><a href="https://riskmusings.substack.com/p/types-of-risk-symmetry-asymmetry" rel="">Types of Risk</a><span>, AI has unbounded upside potential </span><em>and </em><span>unbounded downside risk—and it’s uncertain which outcome will manifest. </span></p><p><span>In the current AI boom, it’s important to understand that there will be two phases of AI development and AI risk management</span></p><p><span> :</span></p><ol><li><p><span>The phase we are in now, when we have the opportunity to learn from our mistakes and improve controls. In this phase, our concerns might center on misinformation floods, developer ethics, AI ethics and equality of outcomes, and we may be able to create and use cool new apps and services, some of which may be world-changing</span></p><span> . AI safety in this phase may resemble social media safety. </span></li><li><p><span>The phase we will enter </span><em>at some undetermined future time, possibly without our immediate awareness</em><span>, when AI will have advanced to a point at which mistakes become catastrophic. AI safety in this phase may resemble nuclear weapons safety or bio-lab safety, with near-zero tolerance for errors. </span></p></li></ol><p>The bottom line is that risks of AI development and failures of AI risk management will become more consequential from a safety perspective as AI technology evolves. Organizations will need to remain fully aware of where we are within Phase 1 in order to understand when we might be at risk of crossing into Phase 2, so they can adjust gears before we collectively hit the wall. </p><p><strong>On anxiety about AI</strong></p><p>This brings up a larger question that seems especially relevant amid the general uncertainty about our future amid climate change, AI evolution, and some pretty-much-crumbling societal infrastructure: how can you keep your risk ship steady during dangerous times? </p><p><span>There’s a wonderful quote in </span><em>The Fellowship of the Ring </em><span>where Frodo and Sam are leaving the Shire on their quest, and Frodo reminds Sam what Bilbo used to say: </span></p><p><em><a href="https://www.goodreads.com/quotes/137661-it-s-a-dangerous-business-frodo-going-out-your-door-you" rel="">“It’s a dangerous business, Frodo, going out your door. You step onto the road, and if you don’t keep your feet, there’s no knowing where you might be swept off to.”</a><span> </span></em></p><p><span>This quote beautifully describes the role risk plays in making life fulfilling despite danger. While it can be tempting to close the curtains and lock ourselves indoors, letting the world spin on outside while we stay safe, safety is only valuable in the </span><em>context</em><span> of a fulfilling life. </span></p><p>If we never ask anyone out or agree to a date, we save ourselves heartbreak but wall off passion and intimacy. If we never leave one job for another or start a new venture, we prevent uncertainty but wall off career advancement and potential profit. If we never invest our money, we never face total loss, but we lose the opportunity for returns that outpace inflation. And if we spend all our time worrying about the future, we don’t live our present.</p><p><strong>Are you saying I should strive to feel uncomfortable?</strong></p><p>Not necessarily. Every person and organization has a different risk appetite. The two extremes of risk appetite go something like this: </p><ol><li><p>Risk is to be minimized. </p></li><li><p>Risk is the logically coherent path to maximal outcomes. </p></li></ol><p>Either way, extremes rarely work out well. </p><p><span>Someone who lives by the first extreme may spend their life wishing for things but never taking steps to realize those wishes, because </span><em>it’s too dangerous</em><span>, so in the end they live a circumscribed life. </span></p><p>Someone who lives according to the second extreme may find their risky bets ultimately harm themselves and others, leaving them in unsustainable positions. </p><p>Extreme A tends to implode quietly over time, and Extreme B tends to explode with fanfare seemingly all at once, but both often lead to failure. </p><p><span>In contrast, moderation in risk management often leads to sustainability. Just as </span><a href="https://www.oecd.org/els/soc/OECD-middle-class-2019-main-findings.pdf" rel="">a large, dynamic, and prosperous middle class is a recipe for a stable society</a></p><p><span>, calculated but not reckless risk-taking can shape a successful career, a successful portfolio, and successful personal relationships.  AI peace of mind gets tricky, since the technology is so potentially world-changing and the outcome so uncertain, but moderation is still possible.</span></p><p><strong>What does moderation in AI look like? </strong></p><p><span>It seems clear that companies are not going to stop or slow development, at least not soon. I do think there’s a strong argument for slowing down whenever capabilities get ahead of controls, or if it looks like we’re nearing a transition from Phase 1 to Phase 2, but that would require strong regulation, and </span><a href="https://www.cnbc.com/2022/05/26/china-and-europe-are-leading-the-push-to-regulate-ai.html" rel="">AI regulation is very much evolving</a><span> (in the US, there is no formal regulatory oversight, though </span><a href="https://www.nist.gov/" rel="">NIST</a><span> has developed an initial, voluntary </span><a href="https://www.nist.gov/itl/ai-risk-management-framework" rel="">risk management framework</a><span> for companies and organizations). </span></p><p><span>Right now, strengthening controls seems both feasible and advisable, given the rocky rollouts of some recent large language models (LLMs). So does giving “responsible AI” teams at companies a seat on risk committees and a vote in go/no-go decisions, so senior management and board members can find out and respond quickly if problems are cropping up in their AI systems. And </span><a href="https://www.aimyths.org/we-cant-regulate-ai" rel="">it’s a great idea</a><span> to push for </span><a href="https://riskmusings.substack.com/p/emerging-risks-and-smart-regulation" rel="">smart and effective regulation</a><span> of the AI sector.</span></p><p>Despite my worries about Phase 2 of AI evolution, my personal approach to moderation and peace of mind about AI looks like this: </p><ul><li><p>Enjoy Phase 1 as much as possible.</p></li><li><p>Don’t work on advancing AI any further or faster than it’s already advancing. </p></li><li><p>Do what I can to push for improved controls, leveraging my experience and background in operational risk. </p></li></ul><p>What does yours look like? </p><p><strong>Making peace with risk</strong></p><p><span>We all live with big risks all the time</span></p><p><span>, and most of the time, we muddle through. We’ve had nuclear weapons for eighty years, and we’re still here. I believe that’s due to a lot of unsung effort by many different people across many countries; after all, </span><a href="https://riskmusings.substack.com/p/the-silence-of-risk-management-victory" rel="">risk management victories are often silent</a><span>.</span></p><p>I hope AI will turn out similarly or better. But however it works out, I won’t let worries about the future throw me off-kilter in the present. A full human life is one of balance, and AI won’t change that, even if it makes some things easier and other things harder. We are here, living in interesting times, taking small steps that will coalesce in complex ways. I’m focusing on aiming for positive change with my own small footprints.</p></div></div></div></article></div></div></div>
  </body>
</html>
