<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/UCSBarchlab/OpenTPU">Original</a>
    <h1>OpenTPU: Open-Source Reimplementation of Google Tensor Processing Unit (TPU)</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto">OpenTPU is an open-source re-implementation of Google&#39;s Tensor Processing Unit (TPU) by the UC Santa Barbara ArchLab.</p>
<p dir="auto">The TPU is Google&#39;s custom ASIC for accelerating the inference phase of neural network computations.</p>
<p dir="auto">Our design is based on details from Google&#39;s paper titled &#34;In-Datacentre Performance Analysis of a Tensor Processing Unit&#34; (<a href="https://arxiv.org/abs/1704.04760" rel="nofollow">https://arxiv.org/abs/1704.04760</a>), which is to appear at ISCA2017. However, no formal spec, interface, or ISA has yet been published for the TPU.</p>


<ul dir="auto">
<li>Python 3</li>
<li>PyRTL version &gt;= 0.8.5</li>
<li>numpy</li>
</ul>
<p dir="auto">Both PyRTL and numpy can be installed with pip; e.g., <code>pip install pyrtl</code>.</p>

<p dir="auto">To run the simple matrix multiply test in both the hardware and functional simulators:</p>
<p dir="auto">Make sure MATSIZE is set to 8 in config.py, then</p>
<div data-snippet-clipboard-copy-content="python3 assembler.py simplemult.a
python3 runtpu.py simplemult.out simplemult_hostmem.npy simplemult_weights.npy
python3 sim.py simplemult.out simplemult_hostmem.npy simplemult_weights.npy"><pre><code>python3 assembler.py simplemult.a
python3 runtpu.py simplemult.out simplemult_hostmem.npy simplemult_weights.npy
python3 sim.py simplemult.out simplemult_hostmem.npy simplemult_weights.npy
</code></pre></div>
<p dir="auto">To run the Boston housing data regression test in both the hardware and functional simulators:</p>
<p dir="auto">Make sure MATSIZE is set to 16 in config.py, then</p>
<div data-snippet-clipboard-copy-content="python3 assembler.py boston.a
python3 runtpu.py boston.out boston_inputs.npy boston_weights.npy
python3 sim.py boston.out boston_inputs.npy boston_weights.npy"><pre><code>python3 assembler.py boston.a
python3 runtpu.py boston.out boston_inputs.npy boston_weights.npy
python3 sim.py boston.out boston_inputs.npy boston_weights.npy
</code></pre></div>

<p dir="auto">The executable hardware spec can be run using PyRTL&#39;s simulation features by running <code>runtpu.py</code>. The simulation expects as inputs a binary program and numpy array files containing the initial host memory and the weights.</p>
<p dir="auto">Be aware that the size of the hardware Matrix Multiply unit is parametrizable --- double check <code>config.py</code> to make sure MATSIZE is what you expect.</p>

<p dir="auto">sim.py implements the functional simulator of OpenTPU. It reads in three cmd args: the assembly program, the host memory file, and the weights file. Due to the different quantization mechnisms between high-level applications (written in tensorflow) and OpenTPU, the simulator runs in two modes: 32b float mode and 8b int mode. The downsampling/quantization mechanism is consistent with the HW implementation of OpenTPU. It generates two sets of outputs, one set being 32b-float typed, the other 8b-int typed.</p>
<p dir="auto">Example usage:</p>
<div data-snippet-clipboard-copy-content="python sim.py boston.out boston_input.npy boston_weights.npy"><pre><code>python sim.py boston.out boston_input.npy boston_weights.npy
</code></pre></div>
<p dir="auto">Numpy matrices (.npy files) can be generated by calling <code>numpy.save</code> on a numpy array.</p>
<p dir="auto">checker.py implementes a simple checking function to verify the results from HW, simulator and applications. It checkes the 32b-float application results against 32b-float simulator results and then checks the 8b-int simulator results against 8b-int HW results.</p>
<p dir="auto">Example usage:</p>


<div dir="auto"><h3 tabindex="-1" dir="auto">How big/efficient/fast is OpenTPU?</h3><a id="user-content-how-bigefficientfast-is-opentpu" aria-label="Permalink: How big/efficient/fast is OpenTPU?" href="#how-bigefficientfast-is-opentpu"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">As of the alpha release, we do not have hard synthesis figures for the full 256x256 OpenTPU.</p>

<p dir="auto">The hardware prototype can currently handle matrix multiplies and activations for ReLU and sigmoid --- i.e., the inference phase of many neural network computations.</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">What features are missing?</h3><a id="user-content-what-features-are-missing" aria-label="Permalink: What features are missing?" href="#what-features-are-missing"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Convolution, pooling, programmable normalization.</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">Does your design follow that of the TPU?</h3><a id="user-content-does-your-design-follow-that-of-the-tpu" aria-label="Permalink: Does your design follow that of the TPU?" href="#does-your-design-follow-that-of-the-tpu"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">We used high-level design details from the TPU paper to guide our design when possible. Thus, the major components of the chip are the same --- matrix multiply unit, unified buffer, activation unit, accumulator, weight FIFO, etc. Beyond that, the implementations may have many differences.</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">Does OpenTPU support all the same instructions as TPU?</h3><a id="user-content-does-opentpu-support-all-the-same-instructions-as-tpu" aria-label="Permalink: Does OpenTPU support all the same instructions as TPU?" href="#does-opentpu-support-all-the-same-instructions-as-tpu"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">No. Currently, OpenTPU supports the RHM, WHM, RW, MMC, ACT, NOP, and HLT instructions (see ISA section for details). The purpose, definition, and specification of other TPU instructions is absent from the published paper. Some instructions will likely be added to OpenTPU as we continue development (such as SYNC), but the final ISA will likely feature many differences without a published spec from Google to work off of.</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">Is OpenTPU binary compatible with the TPU?</h3><a id="user-content-is-opentpu-binary-compatible-with-the-tpu" aria-label="Permalink: Is OpenTPU binary compatible with the TPU?" href="#is-opentpu-binary-compatible-with-the-tpu"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">No. There is no publicly available interface or spec for TPU.</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">I&#39;d like to do some analysis/extensions of OpenTPU, but I need Verilog. Do you have a Verilog version?</h3><a id="user-content-id-like-to-do-some-analysisextensions-of-opentpu-but-i-need-verilog-do-you-have-a-verilog-version" aria-label="Permalink: I&#39;d like to do some analysis/extensions of OpenTPU, but I need Verilog. Do you have a Verilog version?" href="#id-like-to-do-some-analysisextensions-of-opentpu-but-i-need-verilog-do-you-have-a-verilog-version"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">PyRTL can can output structural Verilog for the design, using the <code>OutputToVerilog</code> function.</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">I have suggestions, criticisms, and/or would like to contribute.</h3><a id="user-content-i-have-suggestions-criticisms-andor-would-like-to-contribute" aria-label="Permalink: I have suggestions, criticisms, and/or would like to contribute." href="#i-have-suggestions-criticisms-andor-would-like-to-contribute"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">That&#39;s not a question, but please get in touch! Email Deeksha (<a href="mailto:deeksha@cs.ucsb.edu">deeksha@cs.ucsb.edu</a>) or Joseph (<a href="mailto:jmcmahan@cs.ucsb.edu">jmcmahan@cs.ucsb.edu</a>).</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">I&#39;m a Distinguished Hardware Engineer at Google and the Lead Architect of the TPU. I see many inefficiencies in your implementation.</h3><a id="user-content-im-a-distinguished-hardware-engineer-at-google-and-the-lead-architect-of-the-tpu-i-see-many-inefficiencies-in-your-implementation" aria-label="Permalink: I&#39;m a Distinguished Hardware Engineer at Google and the Lead Architect of the TPU. I see many inefficiencies in your implementation." href="#im-a-distinguished-hardware-engineer-at-google-and-the-lead-architect-of-the-tpu-i-see-many-inefficiencies-in-your-implementation"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Hi Norm! Tim welcomes you to Santa Barbara to talk about all things TPU :)</p>


<ul dir="auto">
<li>RHM src, dst, N
Read Host Memory.
Read <em>N</em> vectors from host memory beginning at address <em>src</em> and save them in the UB (unified buffer) beginning at address <em>dst</em>.</li>
<li>WHM src, dst, N
Write Host Memory.
Write <em>N</em> vectors from the UB beginning at address <em>src</em> to host memory beginning at address <em>dst</em>.</li>
<li>RW addr
Read Weights.
Load the weights tile from the weights DRAM at address <em>addr</em> into the on-chip FIFO.</li>
<li>MMC.{OS} src, dst, N
Matrix Multiply/Convolution.
Perform a matrix multiply operation on the <em>N</em> vectors beginning at UB address <em>src</em>, storing the result in the accumulator buffers beginning at address <em>dst</em>. If the <em>O</em> (overwrite) flag is specified, overwrite the contents of the accumulator buffers at the destination addresses; default behavior is to add to the value there and store the new sum. If the <em>S</em> (switch) flag is specified, switch to using the next tile of weights, which must have already been pre-loaded. The first <code>MMC</code> instruction in a program should always use the <em>S</em> flag.</li>
<li>ACT.{RQ} src, dst, N
Activate.
Perform activation on <em>N</em> vectors in the accumulator buffers starting at address <em>src</em>, storing the results in the UB beginning at address <em>dst</em>. Activation function is specified with a flag: <em>R</em> for ReLU and <em>Q</em> for sigmoid. With no flag, values are passed through without activation. Normalization is programmable at synthesis-time, but not at run-time; by default, after activation the upper 24 bits are dropped from each value, producing an 8-bit integer.</li>
<li>NOP
No op. Do nothing for one cycle.</li>
<li>HLT
Halt. Stop simulation.</li>
</ul>

<p dir="auto">OpenTPU uses no dynamic scheduling; all execution is fully determinstic* and the hardware relies on the compiler to correctly schedule operations and pad NOPs to handle delays. This OpenTPU release does </p>
<p dir="auto">*DRAM is a source of non-deterministic latency, discussed in the Memory Controller section of Microarchitecture.</p>

<p dir="auto"><strong>Application</strong></p>
<ol dir="auto">
<li>Simple one hot 2-layer NN</li>
</ol>
<p dir="auto">gen_one_hot.py generates 8b-int typed random squre matrix as training data and vector as label, example usage:</p>
<div data-snippet-clipboard-copy-content="python gen_one_hot.py --path simple_train --shape 8 8 --range -5 5
python gen_one_hot.py --path simple_train_label --shape 8 1 --range 0 2"><pre><code>python gen_one_hot.py --path simple_train --shape 8 8 --range -5 5
python gen_one_hot.py --path simple_train_label --shape 8 1 --range 0 2
</code></pre></div>
<p dir="auto">simple_nn.py trains a simple 2-layer nn on the given train/label dataset and writes the weights into a file, example usage (run gen_one_hot example first to generate the files):</p>
<div data-snippet-clipboard-copy-content="python simple_nn.py --path simple_train.npy --label simple_train_label.npy"><pre><code>python simple_nn.py --path simple_train.npy --label simple_train_label.npy
</code></pre></div>
<p dir="auto">After running the above command, two files are generated: simple_nn_weight_dram.npy is the 8b-int typed weight dram that the OpenTPU operates on, simple_nn_gt is the pickled ground truth 32b-float resulits and weights. To run with OpenTPU, a test file must also be generated, example usage:</p>
<div data-snippet-clipboard-copy-content="python gen_one_hot.py --path simple_test --shape 100 8 --range 1, 9"><pre><code>python gen_one_hot.py --path simple_test --shape 100 8 --range 1, 9
</code></pre></div>
<p dir="auto">After which simple_test.npy will be generated and it should be used as the host memory by OpenTPU.</p>
<p dir="auto">We also provide simple_nn.a -- the assembly program for this simple nn.</p>
<ol start="2" dir="auto">
<li>Tensorflow DNN regression</li>
</ol>
<p dir="auto">Although applications written in any high-level nn framework can be used, here we use tensorflow as an example.</p>
<p dir="auto">tf_nn.py trains a MLP regressor on the Boston Housing Dataset (<a href="https://archive.ics.uci.edu/ml/datasets/housing" rel="nofollow">https://archive.ics.uci.edu/ml/datasets/housing</a>). Example usage:</p>
<div data-snippet-clipboard-copy-content="python tf_nn.py --N 10 --save-input-path boston_input --save-weight-path boston_weights --save-output-path boston_output
python tf_nn.py --N 10 --save-input-path boston_input --save-weight-path boston_weights --save-output-path boston_output --raw"><pre><code>python tf_nn.py --N 10 --save-input-path boston_input --save-weight-path boston_weights --save-output-path boston_output
python tf_nn.py --N 10 --save-input-path boston_input --save-weight-path boston_weights --save-output-path boston_output --raw
</code></pre></div>
<p dir="auto">After running the above command, four files are generated: gt32.npy holds the ground truth prediction values, boston_input.npy holds the input test cases which is used as the host memeory for OpenTPU, boston_output.npy holds all the intermediate output values, and boston_weights.npy holds the weight matrices which are used as the weight dram for OpenTPU.</p>
<p dir="auto">Adding --raw to the command generates 32b-float typed files instead of 8b ints.</p>

<p dir="auto">The following gives the hardware execution latency for each instruction on OpenTPU:</p>
<ul dir="auto">
<li>RHM - <em>M</em> cycles for reading <em>M</em> vectors</li>
<li>WHM - <em>M</em> cycles for writing <em>M</em> vectors</li>
<li>RW - <em>N*N</em>/64 cycles for <em>N_x_N</em> MM Array for DRAM transfer, and up to 3 additional cycles to propagate through the FIFO</li>
<li>MMC - <em>L+2N</em> cycles, for <em>N_x_N</em> MM Array and <em>L</em> vectors multiplied in the instruction</li>
<li>ACT - <em>L+1</em> cycles, for <em>L</em> vectors activated in the instruction</li>
</ul>

<div dir="auto"><h3 tabindex="-1" dir="auto">Matrix Multiply (MM) Unit</h3><a id="user-content-matrix-multiply-mm-unit" aria-label="Permalink: Matrix Multiply (MM) Unit" href="#matrix-multiply-mm-unit"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">The core of the compute of the OpenTPU is the parametrizable array of 8-bit Multiply-Accumulate Units (MACs), each consisting of an 8-bit integer multiplier and an integer adder of between 16 and 32 bits</p>
<p dir="auto">*The multipliers produce 16-bit outputs; as values move down the columns of the array, each add produces 1 extra bit. Width is capped at 32, creating the potential for uncaught overflow.</p>

<p dir="auto">Result vectors from the MM Array are written to a software-specified address in a set of accumulator buffers. Instructions indicate whether values should be added into the value already at the address or</p>

<p dir="auto">At scale (256x256 MACs), a full matrix of weights (a &#34;tile&#34;) is 64KB; to avoid stalls while weights are moved from off-chip weight DRAM, a 4-entry FIFO is used to buffer tiles. It is assumed the connecti</p>

<p dir="auto">Vectors are read all at once from the Unified Buffer, but must be fed diagonally into the MM Array. This is accomplished with a set of sequential buffers in a lower triangular configuration. The top valu</p>

<p dir="auto">Currently, memory controllers are emulated and have no delay. The connection to Host Memory is currently the size of one vector. The connection to the Weight DRAM uses a standard width of 64 bytes.</p>
<p dir="auto">Because the emulated controllers can return a new value each cycle, the OpenTPU hardware simulation currently has no non-detministic delay. With a more accurate DRAM interface that may encounter dynamic </p>
<p dir="auto">*We note that the TPU &#34;SYNC&#34; instruction may fulfill this purpose, but is currently unimplemented on OpenTPU.</p>

<p dir="auto">Unified Buffer size, Accumulator Buffer size, and the size of the MM Array can all be specified in config.py. However, the MM Array must always be square, and vectors/weights are always composed of 8-bit integers.</p>
</article></div></div>
  </body>
</html>
