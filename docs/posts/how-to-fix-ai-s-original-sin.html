<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.oreilly.com/radar/how-to-fix-ais-original-sin/">Original</a>
    <h1>How to fix “AI’s original sin”</h1>
    
    <div id="readability-page-1" class="page"><div>

              
              
              
              
              
              
<p>Last month, <em>The New York Times</em> claimed that tech giants OpenAI and Google have <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.nytimes.com/2024/04/06/technology/tech-giants-harvest-data-artificial-intelligence.html" target="_blank">waded into a copyright gray area by transcribing the vast volume of YouTube videos</a> and using that text as additional training data for their AI models despite terms of service that prohibit such efforts and copyright law that the <em>Times </em>argues places them in dispute. The <em>Times</em> also quoted Meta officials as saying that their models will not be able to keep up unless they follow OpenAI and Google’s lead. In conversation with reporter Cade Metz, who broke the story, on the <em>New York Times </em>podcast<em> The Daily</em>, host Michael Barbaro called copyright violation “<a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.nytimes.com/2024/04/16/podcasts/the-daily/ai-data.html" target="_blank">AI’s Original Sin</a>.”</p>



<p>At the very least, copyright appears to be one of the major fronts so far in the war over who gets to profit from generative AI. It’s not at all clear yet who is on the right side of the law. In the remarkable essay “<a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4523551" target="_blank">Talkin’ </a><a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4523551">’</a><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4523551" target="_blank">Bout AI Generation: Copyright and the Generative-AI Supply Chain</a>,” Cornell’s Katherine Lee and A. Feder Cooper and James Grimmelmann of Microsoft Research and Yale note:</p><div><div itemscope="" itemtype="http://schema.org/Product" id="trial-cta">
  <p><a href="https://www.oreilly.com/online-learning/">
      <img itemprop="image" src="https://d3ansictanv2wj.cloudfront.net/safari-topic-cta-1f60e6f96856da19ba3cb25660472ca5.jpg"/>
    </a>
  </p>
  <p>
    <h2>
      Learn faster. Dig deeper. See farther.
    </h2>
  </p>
   
</div></div>



<blockquote><p>Copyright law is notoriously complicated, and generative-AI systems manage to touch on a great many corners of it. They raise issues of authorship, similarity, direct and indirect liability, fair use, and licensing, among much else. These issues cannot be analyzed in isolation, because there are connections everywhere. Whether the output of a generative AI system is fair use can depend on how its training datasets were assembled. Whether the creator of a generative-AI system is secondarily liable can depend on the prompts that its users supply.</p></blockquote>



<p>But it seems less important to get into the fine points of copyright law and arguments over liability for infringement, and instead to explore the <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://en.wikipedia.org/wiki/Political_economy" target="_blank"><em>political </em></a><em><a rel="noreferrer noopener" aria-label="economy (opens in a new tab)" href="https://en.wikipedia.org/wiki/Political_economy" target="_blank">economy</a></em> of copyrighted content in the emerging world of AI services: Who will get what, and why? And rather than asking who has the market power to win the tug of war, we should be asking, What institutions and business models are needed to allocate the value that is created by the “generative AI supply chain” in proportion to the role that various parties play in creating it? And how do we create a virtuous circle of ongoing value creation, an ecosystem in which everyone benefits?</p>



<p>Publishers (including <em>The New York Times</em> itself, which has <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.nytimes.com/2023/12/27/business/media/new-york-times-open-ai-microsoft-lawsuit.html" target="_blank">sued OpenAI for copyright violation</a>) argue that works such as generative art and texts compete with the creators whose work the AI was trained on. In particular, the <em>Times</em> argues that AI-generated summaries of news articles <em>are</em> a substitute for the original articles and damage its business. They want to get paid for their work and preserve their existing business. </p>



<p>Meanwhile, the AI model developers, who have taken in massive amounts of capital, need to find a business model that will repay all that investment. <em>Times</em> reporter Cade Metz provides an apocalyptic framing of the stakes and a binary view of the possible outcome. In his interview in <em>The Daily</em>, Metz opines</p>



<blockquote><p>a jury or a judge or a law ruling against OpenAI could fundamentally change the way this technology is built. The extreme case is these companies are no longer allowed to use copyrighted material in building these chatbots. And that means they have to start from scratch. They have to rebuild everything they’ve built. So this is something that not only imperils what they have today, it imperils what they want to build in the future.</p></blockquote>



<p>And in his <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.nytimes.com/2024/04/06/technology/tech-giants-harvest-data-artificial-intelligence.html" target="_blank">original reporting</a> on the actions of OpenAI and Google and the internal debates at Meta, Metz quotes Sy Damle, a lawyer for Silicon Valley venture firm Andreessen Horowitz, who <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.copyright.gov/ai/transcripts/230419-Copyright-and-AI-Literary-Works-Session.pdf" target="_blank">has claimed</a> that “the only practical way for these tools to exist is if they can be trained on massive amounts of data without having to license that data. The data needed is so massive that even collective licensing really can’t work.”</p>



<p>“The only practical way”? Really?</p>



<p>I propose instead that not only is the problem solvable but that solving it can create a new golden age for both AI model providers and copyright-based businesses. What’s missing is the right architecture for the AI ecosystem, and the right business model. </p>



<h2>Unpacking the Problem </h2>



<p>Let’s first break down “copyrighted content.” Copyright reserves to the creator(s) the exclusive right to publish and to profit from their work. <a rel="noreferrer noopener" aria-label="It does not protect facts or ideas but a unique “creative” expression of those facts or ideas (opens in a new tab)" href="https://www.eff.org/deeplinks/2023/04/how-we-think-about-copyright-and-ai-art-0" target="_blank">It does not protect facts or ideas but a unique “creative” expression of those facts or ideas</a>. Unique creative expression is something that is fundamental to all human communication. And humans using the tools of generative AI are indeed often using it as a way to enhance their own unique creative expression. What is actually in dispute is who gets to profit from that unique creative expression.</p>



<p>Not all copyrighted content is created for profit. According to US copyright law, everything published in any form, including on the internet, is automatically copyrighted by the author for the life of its creator plus 70 years. Some of that content is intended to be monetized either by advertising, subscription, or individual sale, but that is not always true. While a blog or social media post, YouTube gardening or plumbing tutorial, or music or dance performance is implicitly copyrighted by its creators (and may also include copyrighted music or other copyrighted components), it is meant to be freely shared. Even content that is meant to be shared freely, though, has an expectation of remuneration in the form of recognition and attention.</p>



<p>Those intending to commercialize their content usually indicate that in some way. Books, music, and movies, for example, bear copyright notices and are registered with the copyright office (which confers additional rights to damages in the event of infringement). Sometimes these notices are even machine-readable. Some online content is protected by a paywall, requiring a subscription to access it. Some content is marked “<a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://developers.google.com/search/docs/crawling-indexing/block-indexing" target="_blank">noindex</a>” in the HTML code of the website, indicating that it should not be spidered by search engines (and presumably other web crawlers). Some content is visibly associated with advertising, indicating that it is being monetized. Search engines “read” everything they can, but legitimate services generally respect signals that tell them “no” and don’t go where they aren’t supposed to.</p>



<p>AI developers surely recognize these distinctions. As the<em> New York Times</em> article referenced at the start of this piece notes, “The most prized data, A.I. researchers said, is high-quality information, such as published books and articles, which have been carefully written and edited by professionals.” It is precisely because this content is more valuable that AI developers seek the unlimited ability to train on all available content, regardless of its copyright status.</p>



<p>Next, let’s unpack “fair use.” Typical examples of fair use are quotations, reproduction of an image for the purpose of criticism or comment, parodies, summaries, and in more recent precedent, the links and snippets that help a search engine or social media user to decide whether to consume the content. Fair use is generally limited to a portion of the work in question, such that the reproduced content cannot serve as a substitute for the original work.</p>



<p>Once again it is necessary to make distinctions that are not legal but <em>practical</em>. If the long-term health of AI requires the ongoing production of carefully written and edited content—as the currency of AI knowledge certainly does—only the most short-term of business advantage can be found by drying up the river AI companies drink from. Facts are not copyrightable, but AI model developers standing on the letter of the law will find cold comfort in that if news and other sources of curated content are driven out of business.</p>



<p>An AI-generated review of Denis Villeneuve’s <em>Dune</em> or a plot summary of the novel by Frank Herbert on which it’s based will not harm the production of new novels or movies. But a summary of a news article or blog post might indeed be a sufficient substitute. If news and other forms of high-quality, curated content are important to the development of future AI models, AI developers should be looking hard at how they will impact the future health of these sources. </p>



<p>The comparison of AI summaries with the snippets and links provided in the past by search engines and social media sites is instructive. Google and others have rightly pointed out that search drives traffic to sites, which the sites can then monetize as they will, by their own advertising (or advertising in partnership with Google), by subscription, or just by the recognition the creators receive when people find their work. The fact that when given the choice to opt out of search, very few sites choose to do so provides substantial evidence that, at least in the past, copyright owners have recognized the benefits they receive from search and social media. In fact, they compete for higher visibility through search engine optimization and social media marketing.</p>



<p>But there is certainly reason for web publishers to <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.washingtonpost.com/technology/2024/05/13/google-ai-search-io-sge/" target="_blank">fear that AI-generated summaries will not drive traffic</a> to sites in the same way as more traditional search or social media snippets. The summaries provided by AI are far more substantial than their search and social media equivalents, and in cases such as news, product search, or a search for factual answers, a summary may provide a reasonable substitute. When readers see an AI answer that references sources they trust, they may well take it at face value and move on. This should be of concern not only to the sites that used to receive the traffic but to those that used to drive it. Because in the long term, if people stop creating high-quality content to ingest, the whole ecosystem breaks down.</p>



<p>This is not a battle that either side should be looking to “win.” Instead, it’s an opportunity to think through how to strengthen two public goods. Journalism professor Jeff Jarvis put it well in a response to an earlier draft of this piece: “It is in the public good to have AI produce quality and credible (if ‘hallucinations’ can be overcome) output. It is in the public good that there be the creation of original quality, credible, and artistic content. It is <em>not</em> in the public good if quality, credible content is excluded from AI training and output OR if quality, credible content is not created.” We need to achieve both goals.</p>



<p>Finally, let’s unpack the relation of an AI to its training data, copyrighted or uncopyrighted. During training, the AI model learns the statistical relationships between the words or images in its training set. As Derek Slater has pointed out, much <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.techpolicy.press/what-the-copyright-case-against-ed-sheeran-can-teach-us-about-ai/" target="_blank">like musical chord progressions</a>, these relationships can be seen as “basic building blocks” of expression. The models themselves do not contain a copy of the training data in any human-recognizable form. Rather, they are a statistical representation of the probability, based on the training data, that one word will follow another or in an image, that one pixel will be adjacent to another. Given enough data, these relationships are remarkably robust and predictable, so much so that it is possible for generated output to closely resemble or duplicate elements of the training data.</p>



<p>It is certainly worth knowing what content has been ingested. Mandating transparency about the content and source of training datasets—the generative AI supply chain—would go a long way towards encouraging frank discussions between disputing parties. But focusing on examples of inadvertent resemblances to the training data misses the point.</p>



<p>Generally, whether payment is in currency or in recognition, copyright holders seek to withhold data from training because it seems to them that may be the only way to prevent unfair competition from AI outputs or to negotiate a fee for use of their content. As we saw from web search, “reading” that does not produce infringing output, delivers visibility (traffic) to the originator of the content, and preserves recognition and credit is generally tolerated. So AI companies should be working to develop solutions that content developers will see as valuable to them.</p>



<p>The recent protest by longtime <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.theregister.com/2024/05/09/stack_overflow_banning_users_who/" target="_blank">Stack Overflow contributors who don’t want the company to use their answers to train OpenAI models</a> highlights a further dimension of the problem. These users contributed their knowledge to Stack Overflow; giving the company perpetual and exclusive rights to their answers. They reserved no economic rights, but they still believe they have <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://en.wikipedia.org/wiki/Moral_rights" target="_blank">moral rights</a>. They had, and continue to have, the expectation that they will receive recognition for their knowledge. It isn’t the training per se that they care about, <em>it’s that the output may no longer give them the credit they deserve.</em></p>



<p>And finally, <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.theguardian.com/culture/2023/oct/01/hollywood-writers-strike-artificial-intelligence" target="_blank">the Writers Guild strike</a> established the contours of who gets to benefit from derivative works created with AI. Are content creators entitled to be the ones to profit from AI-generated derivatives of their work, or can they be made redundant when their work is used to train their replacements? (More specifically, the agreement stipulated that AI works could not be considered “source material.” That is, studios couldn’t have the AI do a first draft, then treat the scriptwriter as someone merely “adapting” the draft and thus get to pay them less.) As the settlement demonstrated, this is not a purely economic or legal question but one of market power.</p>



<p>In sum, there are three parts to the problem: what content is ingested as part of the training data in the first place, what outputs are allowed, and who gets to profit from those outputs. Accordingly, here are some guidelines for how AI model developers ought to handle copyrighted content:</p>



<div><div>
<div><div>
<div><div>
<ol><li><strong>Train on copyrighted content that is freely available, but respect signals like subscription paywalls, the </strong><a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://developers.google.com/search/docs/crawling-indexing/robots/intro" target="_blank"><strong>robots.txt file</strong></a><strong>, the HTML “noindex” keyword, terms of service, and other means by which copyright holders signal their intentions.</strong> Make the effort to distinguish between content that is meant to be freely shared and that which is intended to be monetized and for which copyright is intended to be enforced.</li><li><strong>Produce outputs that respect what can be known about the source and the nature of copyright in the material.</strong></li><li><strong>Pay for the output, not the training.</strong> It may look like a big win for existing copyright holders when they receive multimillion-dollar licensing fees for the use of content they control. First, only the most deep-pocketed AI companies will be able to afford preemptive payments for the most valuable content, which will deepen their competitive moat with regard to smaller developers and open source models. Second, these fees are likely insufficient to become the foundation of sustainable long-term businesses and creative ecosystems. Once you’ve licensed the chicken, the licensee gets the eggs. (Hamilton Nolan calls it “<a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.hamiltonnolan.com/p/selling-your-house-for-firewood" target="_blank">selling your house for firewood</a>.”) Third, the payment is often going to intermediaries and is not passed on to the actual creators.</li></ol>



<div><div>
<blockquote><p>Using a database of audio and visual files submitted by copyright owners, Content ID identifies matches of copyright-protected content. When a video is uploaded to YouTube, it’s automatically scanned by Content ID. If Content ID finds a match, the matching video will get a <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://support.google.com/youtube/answer/6013276" target="_blank">Content ID claim</a>. Depending on the copyright owner’s Content ID settings, a Content ID claim results in one of the following actions:</p></blockquote>
</div></div>
</div></div>
</div></div>
</div></div>



<p>(Revenue is only sometimes shared with the uploader because the uploader may not own all of the monetizable elements of the uploaded content. For example, a dance or music performance video may use copyrighted music for which payment goes to the copyright holder rather than the uploader.)</p>



<p>One can imagine this kind of copyright enforcement framework being operated by the platforms themselves, much as YouTube operates Content ID, or by third-party services. The problem is obviously more difficult than the one facing YouTube, which only had to discover matching music and videos in a relatively fixed format, but the tools are more sophisticated today. As RAG demonstrates, vector databases make it possible to find weighted similarities even in wildly different outputs.</p>



<p>Of course, there is a lot that would need to be worked out. Using vector similarity for attribution is promising, but there are concerning limitations. Consider Taylor Swift. She is so popular that there are many artists trying to sound like her. This sets up a kind of adversarial situation that has no obvious solution. Imagine a vector database that has Taylor in it along with a thousand Taylor copycats. Now imagine an AI-generated song that “sounds like Taylor.” Who gets the revenue? Is it the top 100 nearest vectors (99 of which are cheap copycats of Taylor)? Or should Taylor herself get most of the revenue? There are interesting questions in how to weigh similarity—just as there are interesting questions in traditional search about how to weigh various factors to come up with the “best” result for a search query. Solving these questions is the innovative (and competitive) frontier.</p>



<p>One option might be to retrieve the raw materials for <em>generation</em> (versus using RAG for <em>attribution</em>). Want to generate a paragraph that sounds like Stephen King? Explicitly retrieve some representation of Stephen King, generate from it, and then pay Stephen King. If you don’t want to pay for Stephen King’s level of quality, fine. Your text will be generated from lower-quality bulk-licensed “horror mystery text” as your driver. There are some rather naive assumptions in this ideal, namely in how to scale it to millions or billions of content providers, but that’s what makes it an interesting entrepreneurial opportunity. For a star-driven media area like music, it definitely makes sense.</p>



<p>My point is that one of the frontiers of innovation in AI should be in techniques and business models to enable the kind of flourishing ecosystem of content creation that has characterized the web and the online distribution of music and video. AI companies that figure this out will create a virtuous flywheel that rewards content creation rather than turning the industry into an extractive dead end.</p>



<h2>An Architecture of Participation for AI</h2>



<p>One thing that makes copyright seem intractable is the race for monopoly by the large AI providers. The architecture that many of them seem to imagine for AI is some version of “<a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://lotr.fandom.com/wiki/One_Ring" target="_blank">one ring to rule them all</a>,” “<a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://en.wikipedia.org/wiki/All_your_base_are_belong_to_us" target="_blank">all your base are belong to us</a>,” or <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://en.wikipedia.org/wiki/Borg" target="_blank">the Borg</a>. This architecture is not dissimilar to the model of early online information providers like AOL and the Microsoft Network. They were centralized and aimed to host everyone’s content as part of their service. It was only a question of who would win the most users and host the most content.</p>



<p>The World Wide Web (and the underlying internet itself) had a fundamentally different idea, which I have called an “<a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://web.archive.org/web/20030624045304/http://www.oreillynet.com/pub/wlg/3017" target="_blank">architecture of participation</a>.” Anyone could host their own content, and users could surf from one site to another. Every website and every browser could communicate and agree on what can be seen freely, what is restricted, and what must be paid for. It led to a remarkable expansion of the opportunities for the monetization of creativity, publishing, and copyright.</p>



<p>Like the networked protocols of the internet, the <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://en.wikipedia.org/wiki/The_Unix_Programming_Environment" target="_blank">design of Unix and Linux programming</a> envisioned a world of cooperating programs developed independently and assembled into a greater whole. The Unix/Linux filesystem has a simple but powerful set of access permissions with three levels: user, group, and world. That is, some files are private only to the creator of the file, others to a designated group, and others are readable by anyone.</p>



<p>Imagine with me, for a moment, a world of AI that works much like the World Wide Web or open source systems such as Linux. Foundation models understand human prompts and can generate a wide variety of content. But they operate within a content framework that has been trained to recognize copyrighted material and to know what they can and can’t do with it. There are centralized models that have been trained on everything that’s freely readable (world permission), others that are grounded in content belonging to a specific group (which might be a company or other organization, a social, national or language group, or any other cooperative aggregation), and others that are grounded in the unique corpus of content belonging to an individual.</p>



<p>It may be possible to build such a world on top of ChatGPT or Claude or any one of the large centralized models, but it is far more likely to emerge from cooperating AI services built with smaller, distributed models, much as the web was built by cooperating web servers rather than on top of AOL or the Microsoft Network. We are told that open source AI models are riskier than large centralized ones, but it’s important to make <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.rstreet.org/outreach/coalition-letter-openness-and-transparency-in-ai-provide-significant-benefits-for-society/" target="_blank">a clear-eyed assessment of their benefits versus their risks</a>. Open source better enables not only innovation but <em>control</em>. What if there was an open protocol for content owners to open up their repositories to AI search providers but with control and forensics over how that content is handled and especially monetized?</p>



<p>Many creators of copyrighted content will be happy to have their content ingested by centralized, proprietary models and used freely by them, because they receive many benefits in return. This is much like the way today’s internet users are happy to let centralized providers collect their data, as long as <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.technologyreview.com/2021/03/11/1020635/building-a-better-data-economy/" target="_blank">it is used <em>for</em> them and not against them</a>. Some creators will be happy to have the centralized models use their content as long as they monetize it for them. Other creators will want to monetize it themselves. But it will be much harder for anyone to make this choice freely if the centralized AI providers are able to ingest everything and to output potentially infringing or competing content without compensation or with compensation that amounts to pennies on the dollar.</p>



<p>Can you imagine a world where a question to an AI chatbot might sometimes lead to an immediate answer, sometimes to the equivalent of “<a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.youtube.com/watch?v=ARJ8cAGm6JE" target="_blank">I’m sorry, Dave, I’m afraid I can’t do that</a>” (much as you now get told when you try to generate prohibited speech or images, but in this case, due to copyright restrictions), and at others, “I can’t do that for you, Dave, but the <em>New York Times</em> chatbot can.” At other times, by agreement between the parties, an answer based on copyrighted data might be given directly in the service, but the rights holder will be compensated.</p>



<p>This is the nature of the system that we’re building for our own AI services at <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="http://oreilly.com/" target="_blank">O’Reilly</a>. Our online technology learning platform is a marketplace for content provided by hundreds of publishers and tens of thousands of authors, trainers, and other experts. A portion of user subscription fees is allocated to pay for content, and copyright holders are compensated based on usage (or in some cases, based on a fixed fee).</p>



<p>We are increasingly using AI to help our authors and editors generate content such as summaries, translations and transcriptions, test questions, and assessments as part of a workflow that involves editorial and subject-matter expert review, much as when we edit and develop the underlying books and videos. We’re also building dynamically generated user-facing AI content that also keeps track of provenance and shares revenue with our authors and publishing partners.</p>



<p>For example, for our “Answers” feature (built in partnership with <a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://miso.ai/" target="_blank">Miso</a>), we’ve used a RAG architecture to build a research, reasoning, and response model that searches across content for the most relevant results (similar to traditional search) and then generates a response tailored to the user interaction based on those specific results.</p>



<figure><img src="https://lh7-us.googleusercontent.com/docsz/AD_4nXcSlVdeqlKEGX2KjRjVBM4JXzDbuzNOO9xPYg0t_HLQzoz-JJAzeIZXbX_xURHAoSolvmobZjkmw9vvvVn2ufUWYVkCtrvC0-nPDKa7PQ9rq8fzix9CHRU7kaeKzqsdxXwMIUvOhM_t47JbDFMFhArOpMwY?key=QnAt0jq6QFP2dDlfC-X6Mg" alt="" width="812" height="457"/></figure>



<p>Because we know what content was used to produce the generated answer, we are able to not only provide links to the sources used to generate the answer but also pay authors in proportion to the role of their content in generating it. As Lucky Gunasekara, Andy Hsieh, Lan Le, and Julie Baron write in “<a rel="noreferrer noopener" aria-label=" (opens in a new tab)" href="https://www.oreilly.com/radar/the-new-oreilly-answers-the-r-in-rag-stands-for-royalties/" target="_blank">The R in ‘RAG’ Stands for ‘Royalties</a><a href="https://www.oreilly.com/radar/the-new-oreilly-answers-the-r-in-rag-stands-for-royalties/">’</a>”:</p>



<blockquote><p>In essence, the latest O’Reilly Answers release is an assembly line of LLM workers. Each has its own discrete expertise and skill set, and they work together to collaborate as they take in a question or query, reason what the intent is, research the possible answers, and critically evaluate and analyze this research before writing a citation-backed grounded answer…. The net result is that O’Reilly Answers can now critically research and answer questions in a much richer and more immersive long-form response while preserving the citations and source references that were so important in its original release….</p><p>The benefit of constructing Answers as a pipeline of research, reasoning, and writing using today’s leading open source LLMs is that the robustness of the questions it can answer will continue to increase, but the system itself will always be grounded in authoritative original expert commentary from content on the O’Reilly learning platform.</p></blockquote>



<p>When someone reads a book, watches a video, or attends a live training, the copyright holder gets paid. Why should derivative content generated with the assistance of AI be any different? Accordingly, we have built tools to integrate AI-generated products directly into our payment system. This approach enables us to properly attribute usage, citations, and revenue to content and ensures our continued recognition of the value of our authors’ and teachers’ work.</p>



<p>And if we can do it, we know that others can too.</p>

                          </div></div>
  </body>
</html>
