<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://samueloph.dev/blog/announcing-wcurl-a-curl-wrapper-to-download-files/">Original</a>
    <h1>Wcurl: a curl wrapper to download files</h1>
    
    <div id="readability-page-1" class="page"><article>
      

      <span> Samuel Henrique (samueloph) <span></span> July 03, 2024 <span></span> [<a href="https://samueloph.dev/categories/debian/">debian</a>, <a href="https://samueloph.dev/categories/curl/">curl</a>]</span>

    


<h4 id="tl-dr">tl;dr</h4>
<p>Whenever you need to download files through the terminal and don&#39;t feel like using wget:</p>
<pre data-lang="console"><code data-lang="console"><span>wcurl example.com/filename.txt
</span></code></pre>
<p>Manpage:</p>
<h5 id="availability-comes-installed-with-the-curl-package">Availability (comes installed with the curl package):</h5>
<ul>
<li>Debian unstable - Since 2024-07-02</li>
<li>Debian testing - Coming up between the second and third week of July 2024.</li>
<li>Debian 12/bookworm backports - As soon as the package gets to Debian testing,
I&#39;ll upload it to bookworm.</li>
<li>Debian 12/bookworm - Depends on whether Debian&#39;s release team will approve
it, it could be available in the next point release.</li>
<li>Debian derivatives - Rolling releases will get it by the time it&#39;s on Debian
testing (e.g.: Kali Linux). Stable derivatives only in their next major release.</li>
</ul>
<p>If you don&#39;t want to wait for the package update to arrive, you can always copy
the script and place it in your <code>/usr/bin</code>, the code is here:</p>

<p>Starting with <strong>curl version 8.8.0-2</strong>, the Debian&#39;s curl package now ships a wcurl
executable.</p>
<p>wcurl is the solution for those who just need to download files without having
to remember curl&#39;s parameters for things like automatically naming the files.</p>
<p>Some people, myself included, would fall back to using wget whenever there was a
need to download a file. Sometimes even installing wget just for that usecase.
After all, it&#39;s easier to remember &#34;apt install wget&#34; rather than &#34;curl -L -O -C - ...&#34;.</p>
<p>wcurl consists of a simple shell script that provides sane defaults for the curl
invocation, for when the use case is to just download files.</p>
<p>By default, wcurl will:</p>
<ul>
<li>Encode whitespaces in URLs;</li>
<li>Download multiple URLs in parallel;</li>
<li>Follow redirects;</li>
<li>Automatically choose a filename as output;</li>
<li>Perform retries;</li>
<li>Resume from broken/interrupted downloads.</li>
<li>Set the downloaded file timestamp to the value provided by the server, if available;</li>
</ul>
<p>Example, to download a single file:</p>
<pre data-lang="console"><code data-lang="console"><span>wcurl example.com/filename.txt
</span></code></pre>
<p>If you ever need to set a custom flag, you can make use of the <code>-o/--opts</code>
wcurl option, anything set there will be passed to the curl invocation.
Just beware that if you need to set any custom flags, it&#39;s likely you will be
better served by calling curl directly. The <code>-o/--opts</code> options are there to
allow for some flexibility in unforeseen circumstances.</p>

<p>I&#39;ve always felt a bit ashamed of not remembering curl&#39;s parameters for
downloading a file and automatically naming it, having resorted to wget most of
the times this was needed (even installing wget when it wasn&#39;t there, just for
this). I&#39;ve spoken to a few other experienced people I know and confirmed what
could be obvious to others: a lot of people struggle with this.</p>
<p>Recently, the curl project released the results of <a rel="noopener" target="_blank" href="https://daniel.haxx.se/media/curl-user-survey-2024-analysis.pdf">2024&#39;s curl
survey</a>, which
also showed this is as a much needed feature, just look at some of the answers:</p>
<h4 id="q-which-curl-command-line-option-do-you-think-needs-improvement-and-how">Q: Which curl command line option do you think needs improvement and how?</h4>
<blockquote>
<p>-O, I really want wget like functionality where I don&#39;t have to specify the name</p>
</blockquote>
<blockquote>
<p>Downloading a file (like wget) could be improved - with automatic naming of the file</p>
</blockquote>
<blockquote>
<p>downloading files - wget is much cleaner</p>
</blockquote>
<blockquote>
<p>I wish the default behaviour when GETting a binary was to drop it on disk. That&#39;s the only
reason &#39;wget foo.tgz&#34; is still ingrained in my muscle memory .</p>
</blockquote>
<blockquote>
<p>Maybe have a way to download without specifying something in -o (the only reason i used wget
still)</p>
</blockquote>
<blockquote>
<p>--remote-time should be default</p>
</blockquote>
<blockquote>
<p>--remote-name-all could really use a short flag</p>
</blockquote>
<h4 id="q-if-you-miss-support-for-something-tell-us-what">Q: If you miss support for something, tell us what!</h4>
<blockquote>
<p>&#34;Write the data to the file named in the URL (or in redirects if I&#39;m feeling daring), and
timestamp the file to the last-modified-date&#34;. This is the main reason I&#39;m still using wget.</p>
</blockquote>
<p>I can finally feel less bad about falling back to wget due to not remembering the
parameters I want.</p>

<p>I don&#39;t believe curl will ever change its default behavior in such a way that
would accommodate this need, as that would have a side-effect of breaking things
which expect the current behavior (the blast radius is literally the
<a rel="noopener" target="_blank" href="https://daniel.haxx.se/blog/2021/12/03/why-curl-is-used-everywhere-even-on-mars/">solar system</a>).</p>
<p>This means a new executable needs to be shipped side-by-side with curl, an
opportunity to start fresh and work with a more focused use case (to download
files).</p>
<p>Ideally, this new executable would be maintained by the curl project, make use
of libcurl under-the-hood, and be available everywhere. Nobody wants to worry
if their systems have the tool or not, it should always be there.</p>
<p>Given I&#39;m just a Debian Developer, with not as much free time as I wish, I&#39;ve
decided to write a simple shell script wrapper calling the curl CLI
under-the-hood.</p>
<p>wcurl will come installed with the curl package from now on, and I will check
with the release team about shipping it on the current Debian stable as well.
Shipping wcurl in other distros will be up to them (Debian-derivatives should
pick it up automatically, though).</p>
<p>We&#39;ve tried to make it easy for anyone to ship this by using the curl license,
keeping the script POSIX-compliant, and shipping a <a rel="noopener" target="_blank" href="https://manpages.debian.org/unstable/curl/wcurl.1.en.html">manpage</a>.</p>
<p>Maybe if there&#39;s enough interest across distributions, someone might sign up
for implementing this in upstream curl and increase its reach. I would be happy
with the curl project reusing the wcurl name when that happens. It&#39;s unlikely
that wcurl would be shipped by curl upstream as it is, assuming they would
prefer a solution that uses libcurl direclty (more similar to curl the CLI, to
maintain).</p>
<p>In the worst case, wcurl becomes a Debian-specific tool that only a few people
are aware of, in the best case, it becomes the new go-to CLI tool for simply
downloading files. I would be happy if at least someone other than me finds
it useful.</p>

<p>When I started working on it, I was calling the new executable &#34;curld&#34;
(stands for &#34;curl download&#34;), but then when discussing this in one of our
weekly calls in the Debian Bras√≠lia community, it was mentioned that this could
be confused for a daemon.</p>
<p>We then settled for the name &#34;wcurl&#34;, which doesn&#39;t really stand for anything,
but it&#39;s very easy to remember.</p>
<p>You know... &#34;it&#39;s that wget alternative for when you want to use curl instead&#34;
:)</p>

<p>I&#39;m hosting the code on Github and Debian&#39;s GitLab instance, feel free to open an issue to provide feedback.</p>
<p>We also have a Matrix room for the Debian curl maintainers:</p>

<p>The idea for wcurl came a few days before the <a rel="noopener" target="_blank" href="https://daniel.haxx.se/blog/2024/05/06/i-survived-curl-up-2024/">curl-up conference
2024</a>.
I&#39;ve been thinking a lot about developer productivity in the terminal lately,
different tools and better defaults. Before curl-up, I was also thinking about
packaging improvements for the curl package. I don&#39;t remember what exactly
happened, but I likely had to download something and felt a bit ashamed of
maintaining curl and not remembering the parameters to download files the way I
wanted.</p>
<p>I first discussed this idea in the conference, where I asked the
participants about it and there were no concerns raised, and some people said I should give it a go.
Participating in curl-up was a really great experience and I&#39;m thankful for the
interactions I&#39;ve had there.</p>
<p>On the Debian side, I&#39;ve got reviews of the code and manpage by Sergio Durigan
Junior &lt;sergiodj&gt;, Guilherme Puida Moreira &lt;puida&gt; and Carlos Henrique Lima
Melara &lt;charles&gt;. Sergio ended up rewriting the tool to be POSIX-compliant (my
version was written in bash), so he takes all the credit for the portability.</p>

      <nav>
        
        
      </nav>
    </article></div>
  </body>
</html>
