<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://code.tubitv.com/how-we-discovered-a-7-year-old-performance-issue-in-elixir-99080bdce9a1?gi=60329427cb38">Original</a>
    <h1>We discovered a 7-year old performance issue in Elixir (2020)</h1>
    
    <div id="readability-page-1" class="page"><section><div><div><p id="83a5">In this post, we will explore how in our efforts to optimize an internal service, we stumbled upon a performance problem that has lived in the Elixir code base for seven years. To start with, it is useful to have some context on the problem we were trying to solve. Tubi is a video streaming platform with millions of users streaming movies and TV shows for free every day. Every time a user hits the play button, the video player makes an API call to an internal service that fetches the video player manifest from S3, performs some modifications based on the request parameters, and returns the file to the user. One more thing to note is that some of these manifests are larger than others and/or may require more processing and a lot of the processing happens using regular expressions.</p><p id="749f">Our internal metrics showed that the p99 for this service was hovering around 400ms. Given that the manipulations were relatively simple, we suspected the bottleneck to be the S3 network request; a hypothesis we verified by benchmarking on local.</p><figure><div role="button" tabindex="0"><p><img alt="" src="https://miro.medium.com/max/1400/0*OoH80ceDAYd_YJ2_" width="700" height="164" loading="lazy" role="presentation"/></p></div></figure><p id="776f">As this API call was in the hot path, we wanted to optimize it further, therefore we reached out for Redis to add a cache layer.</p><figure><div role="button" tabindex="0"><p><img alt="" src="https://miro.medium.com/max/1400/0*4hqxYPddRIsFOdc2" width="700" height="283" loading="lazy" role="presentation"/></p></div></figure><p id="f9c6">Alas, when we rolled out this cache layer to about 50% of our traffic, p99 didn’t go down as we expected. Instead, it increased by about 100ms. This was of course not what we expected, so we started digging in deeper.</p><p id="4fbd">We first speculated that the increase in p99 was caused by an increase in CPU load. An important detail on our cache implementation, is that we added an extra compress/decompress step before saving/loading from Redis. Specifically, we use <code>:erlang.term_to_binary/2</code>with the <code>:compressed</code> option when we write to Redis and <code>:erlang.binary_to_term/2</code> when we read. This is a technique we’ve used in the past with success. These operations both cost CPU power. And the CPU utilization did go up from ~30% to ~40% after the cache layer was enabled. But even with a higher CPU utilization, we didn’t expect p99 to go up so dramatically (by 100ms), given BEAM’s powerful concurrency model. So we dug deeper.</p><p id="5990">Then we noticed that although p99 latency and average latency increased, median (p50) latency did decrease. This meant that with this newly added cache layer, what used to be a fast request became faster, but what used to be a slow request became slower. This conclusion indicated that the real bottleneck for these slow requests might not be the S3 network request, but something else.</p><p id="807d">To identify this hidden bottleneck, we did another round of profiling. This time, we ran <code><a href="https://erlang.org/doc/man/eprof.html" rel="noopener ugc nofollow" target="_blank">eprof</a></code> on a real server with real requests coming in. Here is a highlight from the profiling report summary:</p><figure><div role="button" tabindex="0"><p><img alt="" src="https://miro.medium.com/max/1400/0*X_8_k7ssDTyVdpUy" width="700" height="269" loading="lazy" role="presentation"/></p></div></figure><p id="9d8a">From this report, we can see that 89.60% of CPU time had been spent in this <code>Regex.precompile_replacement/1</code> function. And in each process’ profiling report, <code>Regex.precompile_replacement/1</code> was always the most CPU-time consuming function, taking 30%-90% CPU time. By reading Elixir’s source code, we found this function was called in <code>Regex.replace/4</code>, which was the function we used to modify the manifest file.</p><p id="541b">So, this explained why what used to be a fast request became faster, but slow requests became slower. The common pattern in all previously fast requests was that they didn’t call <code>Regex.replace/4</code> so their bottleneck was indeed the S3 network request. But for slow requests, their bottleneck was actually this <code>Regex.replace/4</code> call. The cache layer decreased the S3 network request time but consumed more CPU power (compress/decompress), which made <code>Regex.replace/4</code> take longer, thus made slow requests slower.</p><p id="846d">Knowing that <code>Regex.replace/4</code> was actually the bottleneck for our slowest requests, we started improving this endpoint performance again. Note that at this point, we didn’t realize nor assume that the real performance issues actually lay inside <code>Regex.replace/4</code>. So we were aiming to rewrite the function that calls <code>Regex.replace/4</code> to modify the file content.</p><p id="8c33">We started off by setting up a benchmark script with <code><a href="https://github.com/bencheeorg/benchee" rel="noopener ugc nofollow" target="_blank">Benchee</a></code> as the first step to improve this function’s performance. With this benchmark script, we were able to consistently get a p99 of ~100ms processing for the largest manifest file we had in our test suite. By pure chance, the file that we chose did not have any lines that needed to be replaced. The expectation was that our processing code will just read through the file very quickly. Instead, it still spent ~100ms inside <code>Regex.replace/4</code> without replacing anything. So a natural improvement came to our mind: adding a <code>Regex.match?/2</code> check before we call <code>Regex.replace/4</code>. Just by doing so, we improved this function’s performance by almost 100ms for this special file. And for files that have 50% lines to be replaced, the performance increased by ~50ms.</p><p id="c444">At this point, our optimization was pretty much done. We were planning to use something fancier like <code><a href="https://github.com/plataformatec/nimble_parsec" rel="noopener ugc nofollow" target="_blank">nimble_parsec</a></code> to parse &amp; modify the file content. But given that the performance after adding this trivial <code>Regex.match?/2</code> precheck was good enough, this optimization seems to be an overkill.</p><p id="c9ad">But that didn’t stop us from further questioning: why Elixir didn’t have this trivial optimization built-in? Did <code>:re.replace</code> in Erlang’s <code>re</code> module have the same issue as well? We thus added another version to our benchmark script using Erlang’s <code>re</code> module. The result was almost as fast as having a <code>Regex.match?/2</code> precheck. That meant Elixir’s <code>Regex.replace/4</code> did have a performance issue, when there was nothing to be replaced.</p><p id="730e">Digging into Elixir’s source code, we found that Elixir did <a href="https://github.com/elixir-lang/elixir/blob/v1.11.2/lib/elixir/lib/regex.ex#L663-L665" rel="noopener ugc nofollow" target="_blank">check if there is a match before replacing</a>. But before this check, Elixir <a href="https://github.com/elixir-lang/elixir/blob/v1.11.2/lib/elixir/lib/regex.ex#L650" rel="noopener ugc nofollow" target="_blank">called the </a><code><a href="https://github.com/elixir-lang/elixir/blob/v1.11.2/lib/elixir/lib/regex.ex#L650" rel="noopener ugc nofollow" target="_blank">Regex.precompile_replacement/1</a></code><a href="https://github.com/elixir-lang/elixir/blob/v1.11.2/lib/elixir/lib/regex.ex#L650" rel="noopener ugc nofollow" target="_blank"> function</a>, which led to this heavy computation work when there was nothing to be replaced. (This matched our profiling result from <code>eprof</code>.)</p><p id="5640">On the other hand, Erlang’s <code>re</code> module<a href="https://github.com/erlang/otp/blob/master/lib/stdlib/src/re.erl#L373" rel="noopener ugc nofollow" target="_blank"> doesn’t have this </a><code><a href="https://github.com/erlang/otp/blob/master/lib/stdlib/src/re.erl#L373" rel="noopener ugc nofollow" target="_blank">precompile_replacement/1</a></code><a href="https://github.com/erlang/otp/blob/master/lib/stdlib/src/re.erl#L373" rel="noopener ugc nofollow" target="_blank"> logic</a>. So when there was no match, <code>:re.replace</code> acted as a noop function.</p><p id="0663">After confirming this was indeed an Elixir issue, we submitted a PR to fix it:<a href="https://github.com/elixir-lang/elixir/pull/10500" rel="noopener ugc nofollow" target="_blank"> Speed up </a><code><a href="https://github.com/elixir-lang/elixir/pull/10500" rel="noopener ugc nofollow" target="_blank">Regex.replace/4</a></code><a href="https://github.com/elixir-lang/elixir/pull/10500" rel="noopener ugc nofollow" target="_blank"> when there is no match by dsdshcym · Pull Request #10500 · elixir-lang/elixir</a>.</p><figure><div role="button" tabindex="0"><p><img alt="" src="https://miro.medium.com/max/1400/0*3u5x4jhGv2u7dQlk" width="700" height="588" loading="lazy" role="presentation"/></p></div></figure><p id="df08">(Noticed this PR got merged in 10mins, which was quite impressive.)</p><p id="7113">Although the final fix was trivial, we still learned a lot from this interesting debugging process.</p><ol><li id="3048"><strong>Profile with real data in real conditions</strong></li><li id="b597"><strong>Identify the real bottleneck in the worst-case</strong></li><li id="93e1"><strong>Contribute back to open source</strong></li></ol><p id="3d76">If working on Elixir at scale excites you, then <a href="https://corporate.tubitv.com/company/careers/" rel="noopener ugc nofollow" target="_blank">join us at Tubi</a>, where we use Elixir to power live and on demand studio content to tens of millions of users.</p></div></div></section></div>
  </body>
</html>
