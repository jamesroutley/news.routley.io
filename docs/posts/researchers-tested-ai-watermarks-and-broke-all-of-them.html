<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.wired.com/story/artificial-intelligence-watermarking-issues/">Original</a>
    <h1>Researchers tested AI watermarks and broke all of them</h1>
    
    <div id="readability-page-1" class="page"><div><div data-journey-hook="client-content" data-testid="BodyWrapper"><div><p>The flaws in watermarking haven’t dissuaded tech giants from offering it up as a solution, but people working within the AI detection space are wary. “Watermarking at first sounds like a noble and promising solution, but its real-world applications fail from the onset when they can be easily faked, removed, or ignored,” says Ben Colman, the CEO of AI-detection startup Reality Defender.</p><p>“Watermarking is not effective,” adds Bars Juhasz, the cofounder of Undetectable, a startup devoted to helping people evade AI detectors. “Entire industries, such as ours, have sprung up to make sure that it’s not effective.” According to Juhasz, companies like his are already capable of offering quick watermark-removal services.</p><p>Others think that watermarking does have a place in AI detection—as long as we understand its limitations. “It is important to understand that nobody thinks that watermarking alone will be sufficient,” Farid says. “But I believe robust watermarking is part of the solution.” He thinks that improving upon watermarking and then using it in combination with other technologies will make it harder for bad actors to create convincing fakes.</p><p>Some of Feizi’s colleagues think watermarking has its place, too. “Whether this is a blow to watermarking depends a lot on the assumptions and hopes placed in watermarking as a solution,” says Yuxin Wen, a PhD student at the University of Maryland who coauthored a recent paper suggesting a new watermarking technique. For Wen and his coauthors, including computer science professor Tom Goldstein, this study is an opportunity to reexamine the expectations placed on watermarking, rather than a reason to dismiss its use as one authentication tool among many.</p><p>“There will always be sophisticated actors who are able to evade detection,” Goldstein says. “It’s OK to have a system that can only detect some things.” He sees watermarking as a form of harm reduction and useful for catching lower-level attempts at AI fakery, even if it can’t prevent high-level attacks.</p><p>This tempering of expectations may already be happening. In its blog post announcing SynthID, DeepMind is careful to hedge its bets, <a data-offer-url="https://www.deepmind.com/blog/identifying-ai-generated-images-with-synthid" data-event-click="{&#34;element&#34;:&#34;ExternalLink&#34;,&#34;outgoingURL&#34;:&#34;https://www.deepmind.com/blog/identifying-ai-generated-images-with-synthid&#34;}" href="https://www.deepmind.com/blog/identifying-ai-generated-images-with-synthid" rel="nofollow noopener" target="_blank">noting</a> that the tool “isn’t foolproof” and “isn’t perfect.”</p><p>Feizi is largely skeptical of the idea that watermarking is a good use of resources for companies like Google. “Perhaps we should get used to the fact that we are not going to be able to reliably flag AI-generated images,” he says.</p><p>Still, his paper is slightly sunnier in its conclusions. “Based on our results, designing a robust watermark is a challenging but not necessarily impossible task,” it reads.</p></div></div></div></div>
  </body>
</html>
