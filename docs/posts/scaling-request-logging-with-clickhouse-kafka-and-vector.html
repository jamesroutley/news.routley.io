<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.geocod.io/code-and-coordinates/2025-10-02-from-millions-to-billions/">Original</a>
    <h1>Scaling request logging with ClickHouse, Kafka, and Vector</h1>
    
    <div id="readability-page-1" class="page"><p>How we solved request logging at scale by moving from MariaDB to ClickHouse, Kafka, and Vector after our deprecated database engine couldn&#39;t keep up with billions of monthly requests.</p><div><p><em>This article is based on a talk that I gave at <a href="https://phptek.io">PHP[tek]</a> in 2025.</em></p>

<h2 id="why-track-all-these-requests"><a href="#why-track-all-these-requests" aria-label="why track all these requests permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Why Track All These Requests?</h2>
<p>Geocodio offers a pay-as-you-go metered plan where users get 2,500 free geocoding lookups per day. This means we need to:</p>
<ul>
<li>Track the 2,500 free tier requests</li>
<li>Continue tracking above that threshold for billing</li>
<li>Let users view their usage in real-time on their dashboard</li>
<li>Give admins the ability to query this data for support and debugging</li>
<li>Store request details so we can replay customer requests when debugging issues</li>
</ul>
<p>This isn&#39;t just nice-to-have data. It&#39;s tied directly to our billing and customer support workflows.</p>
<h2 id="the-original-architecture"><a href="#the-original-architecture" aria-label="the original architecture permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>The Original Architecture</h2>
<p>Our initial setup was pretty straightforward:</p>
<p><img src="https://www.geocod.io/img/blog/laravel-redis-mariadb.svg"/></p><p>We were using MariaDB with the TokuDB storage engine, which was specifically designed for high-performance insert operations with incredibly good compression—often 5 to 10 times better than InnoDB. When you&#39;re dealing with billions of records, storage efficiency matters.</p>
<p>Here&#39;s what our request tracking table looked like:</p>
<deckgo-highlight-code language="sql" terminal="carbon">
          <code slot="code">CREATE TABLE `requests_2020_05` (
    `id` bigint(20) NOT NULL AUTO_INCREMENT,
    `user_id` int(11) NOT NULL,
    `access_id` int(11) NOT NULL,
    `query` text,
    `count` int(11) DEFAULT 1,
    `fields` varchar(255) DEFAULT NULL,
    `fields_count` int(11) DEFAULT 0,
    `accuracy_score` decimal(5,4) DEFAULT NULL,
    `accuracy_type` varchar(50) DEFAULT NULL,
    `http_status` int(11) DEFAULT 200,
    `response_time_ms` int(11) DEFAULT NULL,
    `queue_time_ms` int(11) DEFAULT NULL,
    `user_agent` text,
    `source_ip_address` varchar(45) DEFAULT NULL,
    `request_type` varchar(20) DEFAULT NULL,
    `hostname` varchar(100) DEFAULT NULL,
    `created_at` timestamp NOT NULL DEFAULT CURRENT_TIMESTAMP,
    `deleted` tinyint(1) DEFAULT 0,
    PRIMARY KEY (`id`),
    KEY `user_id` (`user_id`),
    KEY `access_id` (`access_id`),
    KEY `created_at` (`created_at`)
) ENGINE=TokuDB DEFAULT CHARSET=utf8mb4;</code>
        </deckgo-highlight-code>
<p>Notice that table name—<code>requests_2020_05</code>. We don&#39;t keep one massive table. Instead, we partition by year and month, making it easy to roll over month after month and drop old data. We also maintain an archive table where we roll up stats we need to carry forward.</p>
<h2 id="how-request-tracking-works-in-laravel"><a href="#how-request-tracking-works-in-laravel" aria-label="how request tracking works in laravel permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>How Request Tracking Works in Laravel</h2>
<p>In our Laravel application, we register a singleton <code>RequestTracker</code> class in the IoC container:</p>
<deckgo-highlight-code language="php" terminal="carbon">
          <code slot="code">public function register(): void
{
    $this-&gt;app-&gt;singleton(RequestTracker::class);
}</code>
        </deckgo-highlight-code>
<p>Using a singleton means we get the same instance of <code>RequestTracker</code> every time we resolve it, no matter where we are in our application. This lets us collect request data throughout the request lifecycle:</p>
<deckgo-highlight-code language="php" terminal="carbon">
          <code slot="code">// Early in the request
resolve(RequestTracker::class)
    -&gt;setApiKey($request-&gt;get(&#39;api_key&#39;))
    -&gt;setQuery($request-&gt;all())
    -&gt;setCount($addressCount)
    -&gt;setType(&#39;geocode&#39;)
    -&gt;setFields($fields);

// Later, after processing
resolve(RequestTracker::class)
    -&gt;setHttpStatus(200)
    -&gt;setAccuracyScore($result-&gt;accuracy)
    -&gt;fillFromRequest($request)
    -&gt;track();</code>
        </deckgo-highlight-code>
<p>The magic happens in terminable middleware. After we&#39;ve sent the response to the user, we persist the tracking data:</p>
<deckgo-highlight-code language="php" terminal="carbon">
          <code slot="code">public function trackStoredParameters(): void
{
    try {
        $requestsRepository = new RequestsRepository;

        $user = null;

        if (! empty($this-&gt;parametersToStore[&#39;user_id&#39;])) {
            $user = User::find($this-&gt;parametersToStore[&#39;user_id&#39;]);
        }

        $requestsRepository-&gt;insert($user, $this-&gt;parametersToStore, false);
    } catch (PDOException $e) {
        info(&#39;Could not track request: &#39;.$e-&gt;getMessage());
        app(&#39;sentry&#39;)-&gt;captureException($e);
    }

    $this-&gt;parametersToStore = null;
}</code>
        </deckgo-highlight-code>
<p>This approach gives us error handling (users still get their data if tracking fails) and performance benefits (we don&#39;t make users wait for us to log their request).</p>
<h2 id="the-problems-started-piling-up"><a href="#the-problems-started-piling-up" aria-label="the problems started piling up permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>The Problems Started Piling Up</h2>
<p>This setup worked for years, but we started hitting some serious issues:</p>
<p><strong>TokuDB is deprecated.</strong> It&#39;s been deprecated since 2021. No more maintenance, no updates, and we can&#39;t upgrade our database version. That&#39;s a problem.</p>
<p><strong>Performance degradation at scale.</strong> Over the course of a month, the database grows from nothing to billions of records. For our highest-volume customers, who might make tens of millions of requests per day, queries got slower and slower. By the end of the month, some users couldn&#39;t even load their usage page—the queries would just time out.</p>
<p><strong>Cache stampede risk.</strong> We had a Redis cache cluster in front of the database, but earlier this year we lost cache keys. We recovered quickly because the cache was still populated, but if we ever had to repopulate from the database at the end of the month? Those queries would be incredibly intensive, and we&#39;d have some serious downtime.</p>
<p>When your request logging is tied to billing, downtime isn&#39;t an option.</p>
<h2 id="attempt-1-just-swap-mariadb-for-clickhouse"><a href="#attempt-1-just-swap-mariadb-for-clickhouse" aria-label="attempt 1 just swap mariadb for clickhouse permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Attempt #1: Just Swap MariaDB for ClickHouse</h2>
<p>My first thought was pretty simple: keep the architecture the same, just swap out MariaDB for <a href="https://clickhouse.com/">ClickHouse</a>.</p>
<p><img src="https://www.geocod.io/img/blog/laravel-redis-clickhouse.svg"/></p><p>I&#39;d heard about ClickHouse from a talk <a href="https://jessarcher.com/">Jess Archer</a> gave at Laracon a couple years ago. She talked about using it to power Laravel Nightwatch, their new analytics platform. If the Laravel team is using it to track request data, it seemed like the perfect fit for us too.</p>
<p>Plus, learning something radically different sounded like a lot of fun.</p>
<h3 id="understanding-clickhouse"><a href="#understanding-clickhouse" aria-label="understanding clickhouse permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Understanding ClickHouse</h3>
<p>ClickHouse is fundamentally different from MariaDB. Here&#39;s the thing—MariaDB is row-oriented, which is how we typically think about databases. But ClickHouse is column-oriented, which is a totally different way of thinking about and querying data.</p>
<p><strong>Row-Oriented (MariaDB):</strong></p>
<deckgo-highlight-code terminal="carbon">
          <code slot="code">| id | user_id | count | response_time_ms | created_at |
|----|---------|-------|------------------|------------|
| 1  | 100     | 5     | 42              | 2025-01-15 |
| 2  | 101     | 3     | 38              | 2025-01-15 |</code>
        </deckgo-highlight-code>
<p>Data is stored together by row. Great for transactional operations.</p>
<p><strong>Column-Oriented (ClickHouse):</strong></p>
<deckgo-highlight-code terminal="carbon">
          <code slot="code">id:               [1, 2, 3, ...]
user_id:          [100, 101, 102, ...]
count:            [5, 3, 8, ...]
response_time_ms: [42, 38, 51, ...]
created_at:       [2025-01-15, 2025-01-15, ...]</code>
        </deckgo-highlight-code>
<p>Data is stored together by column. Super efficient for analytics and aggregations across large datasets.</p>
<p>The other big differences:</p>
<ul>
<li><strong>MariaDB</strong> is optimized for transactions, high concurrency, small fast row-level operations, strong consistency, and current operational data that changes.</li>
<li><strong>ClickHouse</strong> is optimized for analytic queries, scary good compression, batch processing, fast aggregates across huge datasets, and historical data that doesn&#39;t change.</li>
</ul>
<p>Perfect. We&#39;re not updating these request records once they&#39;re written. It&#39;s static historical data.</p>
<h3 id="how-clickhouse-stores-data"><a href="#how-clickhouse-stores-data" aria-label="how clickhouse stores data permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>How ClickHouse Stores Data</h3>
<p>ClickHouse uses this concept called &#34;parts.&#34; Each insert operation creates immutable data part folders on the file system:</p>
<deckgo-highlight-code terminal="carbon">
          <code slot="code">/var/lib/clickhouse/data/default/requests/
├── 20250115_1_1_0/
│   ├── user_id.bin
│   ├── count.bin
│   ├── response_time_ms.bin
│   └── ...
├── 20250115_2_2_0/
└── 20250115_3_3_0/</code>
        </deckgo-highlight-code>
<p>These parts get merged in the background by merge tree engines. ClickHouse automatically combines smaller parts into bigger parts on a schedule, following a tiered strategy based on part size.</p>
<p><img src="https://www.geocod.io/img/blog/clickhouse-parts.svg"/></p><p>I updated the code to check for a ClickHouse feature flag and insert into ClickHouse while also continuing to insert into MariaDB:</p>
<deckgo-highlight-code language="php" terminal="carbon">
          <code slot="code">protected function publish(array $parameters): bool
{
    if (config(&#39;geocodio.kafka.enabled&#39;, false)) {
        $this-&gt;publishToKafka($parameters);
    }

    return $this-&gt;publishToDatabase($parameters);
}</code>
        </deckgo-highlight-code>
<p>I deployed it slowly. One server at a time through our public cluster. Everything looked fine. I started rolling it out to our private cluster, where our highest-volume customers live on dedicated servers...</p>
<p>And Slack started blowing up.</p>
<h2 id="the-too_many_parts-error"><a href="#the-too_many_parts-error" aria-label="the too_many_parts error permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>The TOO_MANY_PARTS Error</h2>
<deckgo-highlight-code terminal="carbon">
          <code slot="code">TOO_MANY_PARTS</code>
        </deckgo-highlight-code>
<p>That&#39;s the error I got. Over and over. Because we were inserting on every single request—those small row-level inserts—we were creating parts faster than the merge process could handle. We were completely overwhelming the system.</p>
<p>I went to the ClickHouse docs (which are fantastic, by the way), and they had a whole page dedicated to this error. Somewhere on that page, they mentioned buffer tables.</p>
<h3 id="attempt-2-buffer-tables"><a href="#attempt-2-buffer-tables" aria-label="attempt 2 buffer tables permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Attempt #2: Buffer Tables</h3>
<p>Buffer tables are a special table engine in ClickHouse that accumulates data in memory and then automatically flushes to your target table based on time or size thresholds. It&#39;s designed specifically to optimize small frequent inserts.</p>
<p>I created the buffer table and made my best guess at the configuration:</p>
<deckgo-highlight-code language="sql" terminal="carbon">
          <code slot="code">CREATE TABLE requests_buffer AS requests
ENGINE = Buffer(
    default,        -- database
    requests,       -- target table
    16,            -- number of layers
    10,            -- min time (seconds)
    100,           -- max time (seconds)
    10000,         -- min rows
    1000000,       -- max rows
    10000000,      -- min bytes
    100000000      -- max bytes
);</code>
        </deckgo-highlight-code>
<p>I went through the deployment again. Public cluster went fine. Got past the point where we failed last time in the private cluster. Kept going. Finished the deployment. Checked Sentry at the end of the day—everything was quiet.</p>
<p>I went to bed feeling pretty good.</p>
<p>I woke up the next morning to Sentry absolutely screaming at me.</p>
<h2 id="the-too_many_links-error"><a href="#the-too_many_links-error" aria-label="the too_many_links error permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>The TOO_MANY_LINKS Error</h2>
<p>All night long, a new error:</p>
<deckgo-highlight-code terminal="carbon">
          <code slot="code">TOO_MANY_LINKS</code>
        </deckgo-highlight-code>
<p>We&#39;d run out of Linux file system links. I SSH&#39;d into the server and tried to list the storage directory. I couldn&#39;t. The command just hung. I&#39;d never seen that before.</p>
<p>I went to Claude and asked for help. Eventually we figured out how to at least count the directories:</p>
<deckgo-highlight-code language="bash" terminal="carbon">
          <code slot="code">find /var/lib/clickhouse -type d | wc -l</code>
        </deckgo-highlight-code>
<p>35 million directories and part files.</p>
<p>The system couldn&#39;t even create another file. I thought the buffer table would fix it, but we&#39;d just compounded the issue. I was stumped. I couldn&#39;t even navigate the server anymore.</p>
<p>I had to bail out. It was time to ask for help.</p>
<h2 id="enter-justin-jackson-and-jon-buda"><a href="#enter-justin-jackson-and-jon-buda" aria-label="enter justin jackson and jon buda permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Enter Justin Jackson and Jon Buda</h2>
<p>I have a podcast called Slightly Caffeinated with my friend Chris Gmyr. It&#39;s mostly personal updates and whatever tech we&#39;re dealing with. I&#39;d posted an episode talking about this ClickHouse implementation struggle.</p>
<p>Justin Jackson from Transistor.fm (where we host the podcast) reached out on Bluesky:</p>
<p><img src="https://www.geocod.io/img/blog/justin-jackson-bluesky.png"/></p><p>Justin, I have <em>so many questions</em>.</p>
<p>He pointed me to Jon Buda, and Jon mentioned something super interesting: the folks at Honeybadger were also using ClickHouse for their new Insights analytics platform.</p>
<p>I have a relationship with the Honeybadger team—I rewrote their PHP and Laravel integrations years ago. So I hit up Josh and Ben. Two days later, I was on a Zoom call explaining our setup.</p>
<p>Ben got this big smile on his face.</p>
<p>&#34;Man, you gotta batch up your inserts.&#34;</p>
<p>They proceeded to shared their ingestion platform architecture with me. They were so confident in their approach that I really had no choice but to grab onto it and run with it.</p>
<h2 id="the-solution-kafka--vector--clickhouse"><a href="#the-solution-kafka--vector--clickhouse" aria-label="the solution kafka  vector  clickhouse permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>The Solution: Kafka + Vector + ClickHouse</h2>
<p>They told me to introduce Kafka and Vector into the mix. I really wanted to avoid adding more infrastructure, but I was at the point when I was willing to try anything to make this work.</p>
<p><img src="https://www.geocod.io/img/blog/laravel-redis-kafka-vector-clickhouse.svg"/></p><h3 id="what-is-kafka"><a href="#what-is-kafka" aria-label="what is kafka permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>What is Kafka?</h3>
<p>Kafka is an event streaming platform. It&#39;s distributed pub/sub messaging designed for high throughput and fault tolerance. It stores streams of records in topics (categories), and it enables real-time data processing pipelines.</p>
<p>Here&#39;s the visual:</p>
<p><img src="https://www.geocod.io/img/blog/what-is-kafka.svg"/></p><p>Producers write events to Kafka, Kafka stores them in a distributed log, and consumers read those events out.</p>
<p>Why did we need this?</p>
<ul>
<li>Durable storage</li>
<li>Handles super high throughput</li>
<li>Decouples producers from consumers</li>
<li>Scales horizontally</li>
</ul>
<p>We were dealing with a scale problem going from millions to billions. Kafka can easily scale with us.</p>
<h3 id="building-a-kafka-publisher"><a href="#building-a-kafka-publisher" aria-label="building a kafka publisher permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Building a Kafka Publisher</h3>
<p>There&#39;s an awesome Laravel package for working with Kafka, but I ran into some weird connection issues. So I went back to Claude and we decided to write our own publisher using the RdKafka PHP extension:</p>
<deckgo-highlight-code language="php" terminal="carbon">
          <code slot="code">namespace Shared;

use Exception;
use RdKafka\Conf;
use RdKafka\Producer;
use RdKafka\ProducerTopic;

class KafkaPublisher
{
    protected ?Producer $producer = null;
    protected ?string $brokers = null;
    protected array $topicInstances = [];

    protected function createProducer(): Producer
    {
        $conf = new Conf;
        $conf-&gt;set(&#39;bootstrap.servers&#39;, $this-&gt;brokers);

        // Reliability settings
        $conf-&gt;set(&#39;message.send.max.retries&#39;, config(&#39;geocodio.kafka.retries&#39;, 3));
        $conf-&gt;set(&#39;retry.backoff.ms&#39;, config(&#39;geocodio.kafka.retry_backoff_ms&#39;, 200));
        $conf-&gt;set(&#39;socket.timeout.ms&#39;, config(&#39;geocodio.kafka.socket_timeout_ms&#39;, 1000));
        $conf-&gt;set(&#39;message.timeout.ms&#39;, config(&#39;geocodio.kafka.message_timeout_ms&#39;, 5000));
        $conf-&gt;set(&#39;queue.buffering.max.messages&#39;, config(&#39;geocodio.kafka.max_buffered_messages&#39;, 100000));
        $conf-&gt;set(&#39;queue.buffering.max.ms&#39;, config(&#39;geocodio.kafka.buffer_flush_ms&#39;, 100));
        $conf-&gt;set(&#39;compression.codec&#39;, config(&#39;geocodio.kafka.compression&#39;, &#39;snappy&#39;));

        return new Producer($conf);
    }

    public function publish(string $topic, array $data, ?string $key = null): bool
    {
        $this-&gt;initializeProducer();

        $topicInstance = $this-&gt;getTopic($topic);
        $message = $this-&gt;encodeMessage($data, $topic);

        $topicInstance-&gt;produce(RD_KAFKA_PARTITION_UA, 0, $message, $key);

        $this-&gt;producer-&gt;poll(0);
        $this-&gt;flush(1000);

        return true;
    }
}</code>
        </deckgo-highlight-code>
<p>Pretty straightforward. The cool thing is we can configure retries, backoff, compression, and buffering all through config values.</p>
<p>Then we updated our repository to publish to Kafka:</p>
<deckgo-highlight-code language="php" terminal="carbon">
          <code slot="code">protected function publishToKafka(array $parameters): void
{
    try {
        resolve(KafkaPublisher::class)
            -&gt;publish(
                self::KAFKA_TOPIC,
                $this-&gt;formatRequestData($parameters)
            );
    } catch (Throwable $e) {
        info(&#39;Could not publish request to Kafka: &#39;.$e-&gt;getMessage());
        app(&#39;sentry&#39;)-&gt;captureException($e);
    }
}</code>
        </deckgo-highlight-code>
<p>We&#39;re still publishing to MariaDB for now, but this lets us run both systems in parallel and audit the data at the end of the month.</p>
<h3 id="what-is-vector"><a href="#what-is-vector" aria-label="what is vector permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>What is Vector?</h3>
<p>Vector is a high-performance observability data pipeline. It&#39;s lightweight, ultra-fast, written in Rust, and maintained by Datadog. It supports 100+ different inputs and outputs.</p>
<p><img src="https://www.geocod.io/img/blog/what-is-vector.svg"/></p><p>Why did we need Vector?</p>
<ul>
<li>Efficient way to get data from Kafka to ClickHouse</li>
<li>Consumes messages from Kafka</li>
<li>Batches them into optimal sizes</li>
<li>Handles retries and back pressure</li>
<li>Optional transformation layer for schema changes</li>
</ul>
<p>The guys at Honeybadger told me you really want to be hitting at minimum 30,000 to 50,000 records being batch inserted at once. That&#39;s a much bigger scale than we were ever thinking about with those individual row-level inserts.</p>
<h3 id="configuring-vector"><a href="#configuring-vector" aria-label="configuring vector permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Configuring Vector</h3>
<p>Here&#39;s our Vector configuration:</p>
<deckgo-highlight-code language="yaml" terminal="carbon">
          <code slot="code">sources:
    kafka_requests:
        type: kafka
        bootstrap_servers: kafka:9092
        topics:
            - geocodio_requests
        group_id: vector_consumer
        auto_offset_reset: earliest

transforms:
    prepare_logs:
        type: remap
        inputs:
            - kafka_requests
        source: |
            . = parse_json!(.message)

sinks:
    clickhouse:
        type: clickhouse
        endpoint: http://clickhouse:8123
        inputs:
            - prepare_logs
        database: default
        table: requests
        skip_unknown_fields: true
        auth:
            strategy: basic
            user: geocodio_usr
            password: LocalDevelopmentPassword
        batch:
            timeout_secs: 5
        buffer:
            max_events: 120000
        request:
            retry_attempts: 2
            retry_max_duration_secs: 10
        healthcheck:
            enabled: true</code>
        </deckgo-highlight-code>
<p>We&#39;re doing time-based inserts—every 5 seconds, Vector grabs all the events that happened over those 5 seconds and does one big batch insert. Instead of creating tons of tiny parts, we&#39;re creating fewer but much bigger parts. ClickHouse handles that totally fine.</p>
<h2 id="moving-to-clickhouse-cloud"><a href="#moving-to-clickhouse-cloud" aria-label="moving to clickhouse cloud permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Moving to ClickHouse Cloud</h2>
<p>Initially, we wanted to self-host everything. That&#39;s kind of our philosophy at Geocodio. But when I looked at the operational requirements, reality set in:</p>
<p><strong>Self-Hosted ClickHouse:</strong></p>
<ul>
<li>3 ClickHouse nodes for replication</li>
<li>3 ZooKeeper nodes for coordination</li>
<li>3 Kafka brokers for high availability</li>
<li>Vector instances</li>
</ul>
<p>That&#39;s a lot of infrastructure for a small team that also needs to write features and fix bugs.</p>
<p>ClickHouse Cloud wasn&#39;t as expensive as I expected. And the benefits were huge:</p>
<ul>
<li>Operational simplicity</li>
<li>Scaling on demand</li>
<li>Built-in high availability and redundancy</li>
<li>Automatic updates (ClickHouse has a weekly release cadence)</li>
<li>Expert support when we need it</li>
</ul>
<p>The Honeybadger guys mentioned that ClickHouse releases bug fixes and features constantly. &#34;You really need to architect this so you can update everything quickly and frequently.&#34; Updating a database while actively inserting data sounds scary. Having ClickHouse handle that for us was a massive win.</p>
<h2 id="the-migration-strategy"><a href="#the-migration-strategy" aria-label="the migration strategy permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>The Migration Strategy</h2>
<p>From day one, I thought about how to do this with zero downtime. The approach:</p>
<ol>
<li><strong>Dual-write everything.</strong> Insert into both Kafka (→ ClickHouse) and MariaDB simultaneously for a full month.</li>
<li><strong>Feature flags.</strong> Be able to turn Kafka on or off independently from database writes.</li>
<li><strong>Audit the data.</strong> At the end of the month, compare what&#39;s in ClickHouse versus MariaDB.</li>
<li><strong>Gradual cutover.</strong> Once we&#39;re confident, start cutting reads over to ClickHouse (also behind feature flags).</li>
</ol>
<p>Since this is tied to billing, we can&#39;t afford to get it wrong. This strategy gives us validation at every step.</p>
<p>Here&#39;s the code that makes it possible:</p>
<deckgo-highlight-code language="php" terminal="carbon">
          <code slot="code">protected function publish(array $parameters): bool
{
    if (config(&#39;geocodio.kafka.enabled&#39;, false)) {
        $this-&gt;publishToKafka($parameters);
    }

    return $this-&gt;publishToDatabase($parameters);
}</code>
        </deckgo-highlight-code>
<p>Simple, but effective. We can flip Kafka on or off without touching the database writes.</p>
<h2 id="key-takeaways"><a href="#key-takeaways" aria-label="key takeaways permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Key Takeaways</h2>
<p><strong>Batch inserts are critical for ClickHouse.</strong> You can&#39;t treat it like a transactional database with row-level inserts. You need to batch aggressively—30k-50k records minimum.</p>
<p><strong>Don&#39;t be afraid to ask for help.</strong> Talking to Jon Buda and the Honeybadger team saved me weeks of trial and error. Sometimes the best solution is learning from people who&#39;ve already solved the problem.</p>
<p><strong>Feature flags for the win.</strong> Being able to turn Kafka and ClickHouse on or off independently gave us confidence to deploy incrementally and validate every step.</p>
<p><strong>Column-oriented databases are a different beast.</strong> If you&#39;re doing analytics or tracking large volumes of append-only data, ClickHouse is incredibly powerful. But you have to think differently about how data is stored and queried.</p>
<h2 id="big-thanks"><a href="#big-thanks" aria-label="big thanks permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Big Thanks</h2>
<p>Big thanks to Justin Jackson and Jon Buda from <a href="https://transistor.fm/">Transistor.fm</a> for pointing me in the right direction. And huge thanks to Josh and Ben at <a href="https://www.honeybadger.io/">Honeybadger</a> for being so generous with their time and insights. They were super confident in their approach, and that confidence gave me the push I needed to commit to this solution.</p>
<p>I&#39;m super stoked on this. Now excuse me while I go find more excuses to use ClickHouse.</p></div></div>
  </body>
</html>
