<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://shkspr.mobi/blog/2021/12/quick-and-dirty-way-to-rip-an-ebook-from-android/">Original</a>
    <h1>Quick and dirty way to rip an eBook from Android</h1>
    
    <div id="readability-page-1" class="page"><div itemprop="https://schema.org/articleBody">
<p>I recently purchased a book for my MSC which was <em>only</em> available via a crappy Android app. There was no obvious way to decrypt it to read on a more sensible device, so I resorted to the ancient art of screenscraping.</p><p>This is a quick-and-dirty way to grab images of the pages and convert them to a standard PDF using Linux. There&#39;s a lot more you can do to make the end book more useful, but this&#39;ll get you started</p><h2 id="lots-of-screen-shots"><a href="#lots-of-screen-shots">Lots of Screen Shots</a></h2><p>With a USB cable plugged into my phone and laptop, I wrote a horrible little bash script:</p><pre><code>#!/bin/bash
for i in {00001..00555}; do
   adb exec-out screencap -p &gt; $i.png
   adb shell input tap 1000 2000
   sleep 1s
done
echo All done
</code></pre><p>This runs a loop 555 times. Takes a screenshot, names it for the loop number with padded zeros, taps the bottom right of the screen, then waits for a second to ensure the page has refreshed.  Slow and dull, but works reliably.</p><p>Images range from 200KB to 2MB depending on complexity.  Back them up before doing the next bit.</p><h2 id="cropping"><a href="#cropping">Cropping</a></h2><p>The screenshots are all 1080x2160. But the page only takes up part of that. The top left corner is at 50x432 and the bottom right is at 1028x1726.</p><p>This command crops all the images. It is destructive, so make sure you have a backup.</p><pre><code>mogrify -crop 978x1294+50+432 +repage *.png
</code></pre><p>It&#39;s also useful to trim the images to remove any whitespace from the borders. That makes a smaller file size.</p><pre><code>mogrify -trim *.png
</code></pre><p>Images can be shrunk with:</p><pre><code>pngquant *.png
</code></pre><h2 id="pdf-and-ocr"><a href="#pdf-and-ocr">PDF and OCR</a></h2><p>Sticking all the images together into a single PDF is pretty easy:</p><pre><code>convert *.png +repage output.pdf
</code></pre><p>The <code>+repage</code> option keeps the aspect ratio of the trimmed image.</p><p>But there&#39;s no text to search. There are a bunch of OCR programs on Linux, I like <a href="http://www.tobias-elze.de/pdfsandwich/"><code>PDF Sandwich</code></a>:</p><pre><code>pdfsandwich -rgb -nopreproc output.pdf
</code></pre><p>That&#39;ll get you a colour PDF with OCR&#39;d text embedded in it.  The text is &#34;sandwiched&#34; behind the image of the page, so you can&#39;t see it but can search for it.</p><p>You can also use <a href="https://github.com/ocrmypdf/OCRmyPDF/">OCRmyPDF</a> which may result in a smaller file:</p><pre><code>ocrmypdf -l eng output.pdf output_ocr.pdf
</code></pre><p>And that&#39;s it. I now have a searchable PDF which I can read on any device.</p><h2 id="what-have-we-learned"><a href="#what-have-we-learned">What have we learned?</a></h2><p>DRM on textbooks is an annoyance. For computer science books, it&#39;s little more than a fig-leaf.</p></div></div>
  </body>
</html>
