<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.micahlerner.com/2022/05/15/druid-a-real-time-analytical-data-store.html">Original</a>
    <h1>Druid: A Real-Time Analytical Data Store</h1>
    
    <div id="readability-page-1" class="page"><article>
<section>
<header>
<a href="https://www.micahlerner.com/">
<h3>micahlerner.com</h3>
</a>
</header>
</section>

<h4>Published May 15, 2022</h4>
<h5>
Found something wrong?
<a href="https://github.com/mlerner/mlerner.github.io/edit/master/_posts/2022-05-15-druid-a-real-time-analytical-data-store.md">Submit a pull request!</a>
</h5>
<section>
<p>Discussion on <a href="https://news.ycombinator.com/item?id=32259587"> Hacker News</a></p>
<p>
<em>
These paper reviews can <a href="https://newsletter.micahlerner.com/">be delivered weekly to your inbox</a>, or you can subscribe to the <a href="https://www.micahlerner.com/feed.xml">Atom feed</a>. As always, feel free to reach out on <a href="https://twitter.com/micahlerner">Twitter</a> with feedback or suggestions!
</em>
</p>
<p><a href="https://www.micahlerner.com/assets/papers/druid.pdf">Druid: A Real-time Analytical Data Store</a></p>
<h2 id="what-is-the-research">What is the research?</h2>
<p>Druid<label for="druid"></label><span>The paper notes that, “The name Druid comes from the Druid class in many role-playing games: it is a shape-shifter, capable of taking on many different forms to fulfill various different roles in a group”. </span> is an <a href="https://druid.apache.org/">open-source</a> database designed for near-realtime and historical data analysis with low-latency<label for="lambda"></label><span>The ideas that Druid discusses are closely connected to <a href="https://www.oreilly.com/radar/questioning-the-lambda-architecture/">Lambda Architecture</a>, covered in this great post from Nathan Marz on <a href="https://archive.ph/wip/sDxQg">How to beat the CAP Theorem</a>. </span>. While originally developed<label for="metamarkets"></label><span>The <a href="https://metamarkets.com/2011/druid-part-i-real-time-analytics-at-a-billion-rows-per-second/">original engineering blog posts</a> are also a great read! </span> by MetaMarkets, an Ad Tech company since acquired by Snap<label for="snap"></label><span><a href="https://techcrunch.com/2017/11/03/snap-metamarkets/">Techcrunch reference</a>. </span>, Druid is being used for a variety of different use cases by companies like <a href="https://netflixtechblog.com/how-netflix-uses-druid-for-real-time-insights-to-ensure-a-high-quality-experience-19e1e8568d06">Netflix</a>, <a href="https://www.confluent.io/blog/scaling-apache-druid-for-real-time-cloud-analytics-at-confluent/">Confluent</a>, and <a href="https://www.youtube.com/watch?v=ovZ9iAkQllo">Lyft</a>.</p>
<p>Druid’s goal of supporting near-realtime and historical access patterns makes it unique<label for="was"></label><span>Or at least was <em>more</em> unique at the time the original paper was published in 2014 - more recently, combined <a href="https://delta.io/">batch/streaming architectures</a> have grown in popularity. Also relevant is <a href="https://www.oreilly.com/radar/questioning-the-lambda-architecture/">Questioning the Lambda Architecture</a> from Jay Kreps (one of the creators of Kafka) - the post points out several downsides of a Lambda Architecture, including being built on the idea that “real-time processing is inherently approximate, less powerful, and more lossy than batch processing.” </span>. The system’s approach opens it to a wider variety of use cases - for example, near real-time ingestion allows applications like production alerting based on logs (similar to <a href="https://netflixtechblog.com/how-netflix-uses-druid-for-real-time-insights-to-ensure-a-high-quality-experience-19e1e8568d06">Netflix’s use case</a>) to find issues quickly, while also executing against a large history of data. In contrast, many data warehouse products are updated on a recurring “batch” basis, introducing lag between the time that metrics are logged and the time they are available for analysis.</p>
<p>Beyond covering the system’s design and implementation, the paper also discusses how reduced availability of different system components impacts users. Relatively few papers on production systems are structured in this way, and the approach was refreshing.</p>
<h2 id="what-are-the-papers-contributions">What are the paper’s contributions?</h2>
<p>The paper makes several contributions:</p>
<ul>
<li>A description of the system’s architecture.</li>
<li>Exploration of design decisions and an implementation.</li>
<li>An evaluation of the system’s query API and performance results.</li>
</ul>
<h2 id="how-does-the-system-work">How does the system work?</h2>
<h3 id="segments-and-data-sources">Segments and data sources</h3>
<p><em>Segments</em> are a key abstraction in Druid. They are an immutable (but versioned) datastructure storing a collection of individual records. Collections of <em>segments</em> are combined into <em>data sources</em>, Druid’s version of database tables. Each <em>segment</em> stores all of the records that arrived during a given time period, for a given data source.</p>
<figure><img src="https://www.micahlerner.com/assets/druid/table1.png"/><figcaption></figcaption></figure>
<h3 id="architecture">Architecture</h3>
<p>Druid builds <em>segments</em> by ingesting data, then accesses the segments while responding to queries against <em>data sources</em>.</p>
<p>The Druid architecture uses four types of nodes<label for="current"></label><span>Newer versions of the system seem to break up functionality TODO </span> to implement ingesting data and responding to queries: <em>real time nodes</em>, <em>historical nodes</em>, <em>broker nodes</em>, and <em>coordinator nodes</em>.</p>
<figure><img src="https://www.micahlerner.com/assets/druid/figure1.png"/><figcaption></figcaption></figure>
<p>Unlike relatively stateless individual nodes, a Druid deployment stores state in two data sources:</p>
<ul>
<li>MySQL, which contains configuration and metadata, like an index of the existing <em>segments</em>.</li>
<li>Zookeeper, which stores the current state of the system (including where multiple copies of <em>segments</em> are distributed on the machines in the system)</li>
</ul>
<h4 id="real-time-nodes">Real time nodes</h4>
<p><em>Real time nodes</em> have two responsibilties: ingesting data from producers, and responding to requests from users for recent data.</p>
<p>Producers provide raw data (like rows from a database), or transformed data (like the output of a stream processing pipeline) to <em>real time nodes</em> - a common producer pattern relies on <a href="https://druid.apache.org/docs/latest/development/extensions-core/kafka-ingestion.html">Kafka topics</a>. Kafka (or other message bus approaches) help with the availability and scalability of ingestion - <em>real time nodes</em> can store the offset that they have consumed into a stream, resetting to that offset if they crash/restart. To scale ingestion, multiple <em>real time nodes</em> can read different subsets of the same message bus.</p>
<p>When a <em>real time node</em> consumes records from a producer, it checks the time period and data source associated with the record, then routes the incoming record to an in-memory buffer with the same <code>(time period, data source)</code> key.</p>
<figure><img src="https://www.micahlerner.com/assets/druid/figure2.png"/><figcaption></figcaption></figure>
<p>Each <code>(time period, data source)</code> buffer temporarily<label for="controlla"></label><span><em>Controller nodes</em> (discussed in more detail further down) configure the length of this time range, in addition to other parameters like the datasources assigned to each <em>Real-time node</em>. </span> remains on the node before being evicted - because of limited resources, nodes need to evict record buffers from memory periodically. On eviction, the in-memory buffer’s data is written to “deep” storage (like S3 or Google Cloud Storage).</p>
<figure><img src="https://www.micahlerner.com/assets/druid/figure3.png"/><figcaption></figcaption></figure>
<p>Beyond ingestion, each <em>real-time node</em> responds to queries accessing recent data. To respond to these requests, the nodes scan using temporary in-memory indices.</p>
<h4 id="historical-nodes">Historical nodes</h4>
<p><em>Historical nodes</em> read immutable <em>segments</em> from storage, and respond to queries accessing them - <em>coordinator nodes</em> (discussed in the next section) control which segments a <em>historical node</em> fetches. When a <em>Historical node</em> downloads a segment sucessfully, it announces this fact to a service discovery component (Zookeeper) of the system, allowing user queries to access the segment. Unfortunately, if Zookeeper goes offline, the system will not be able to serve new segments - <em>Historical nodes</em> won’t be able to announce successful segment fetches, so the components of Druid responsible for querying data won’t forward queries.</p>
<figure><img src="https://www.micahlerner.com/assets/druid/figure5.png"/><figcaption></figcaption></figure>
<p>The decision to use immutable segments simplifies the implementation of <em>historical nodes</em>. First, it simplifies scaling of the system - if there are many requests that cover a segment, more <em>historical nodes</em> can store copies of the <em>segment</em>, resulting in queries diffusing over the cluster. Second, operating on segments rather than a lower level abstraction means that the <em>historical nodes</em> can simply wait to be told that there is a new version of data to serve, rather than needing to listen for changes to a segment itself.</p>
<h4 id="coordinator-nodes">Coordinator nodes</h4>
<p><em>Coordinator nodes</em> configure which segments are stored on <em>historical nodes</em><label for="coord"></label><span>Multiple copies of a segment can be stored on different <em>Historical nodes</em> in the cluster to scale querying and increase redundancy. </span>, and for how long<label for="overlord"></label><span>From reading the Druid docs, it seems like there is a new, separate node-type responsible for controlling data-ingestion, called the <a href="https://druid.apache.org/docs/latest/design/architecture.html">Overlord</a>. </span>.</p>
<p>To make decisions, <em>coordinator nodes</em> read data from two locations: MySQL and Zookeeper. MySQL durably stores information on the universe of segments<label for="keys"></label><span>Essentially storing <code>(time period, data source, version)</code> - while there can be multiple copies of a segment, there would be one entry in the MySQL database to represent its type. </span> and associated metadata about each segment type<label for="metadata"></label><span>Like how long a segment with a specific configuration should remain on a historical node. </span>. Zookeeper stores the current state of all segments served by the system - <em>real time nodes</em> and <em>historical nodes</em> use it to announce changes in which segments are available. <em>Coordinator nodes</em> also load balance segments<label for="coordocs"></label><span>Balancing segment load is discussed in more detail in the <a href="https://druid.apache.org/docs/latest/design/coordinator.html#balancing-segment-load">Druid docs</a>. </span> across the system in order to limit “hot spots” that occur from many reads going to the same node<label for="monarch"></label><span>The <a href="https://www.micahlerner.com/2022/04/24/monarch-googles-planet-scale-in-memory-time-series-database.html">Monarch</a> paper also mentions a similar load-balancing mechanism! </span>.</p>
<p>The paper nodes that there are multiple running <em>coordinator nodes</em> in a cluster, but there is only one “leader” at a time - the others are used for failover<label for="coordinator"></label><span>To scale coordination functionality, it sounds like it would be possible to create multiple sets of <em>Coordinator nodes</em>, each responsible for a partition of the dataset, although I didn’t see a discussion in the paper on this. </span>. If <em>coordinator nodes</em> become unavailable (either because of MySQL or Zookeeper problems), <em>historical</em> and <em>real time nodes</em> will continue operating, but could become overloaded (due to non-operation of load balancing features). Additionally, the paper notes that this failure mode results in new data becoming unavailable.</p>
<h4 id="broker-nodes">Broker nodes</h4>
<p>Lastly, <em>Broker nodes</em> receive requests from external clients, read state from Zookeeper, and forward requests to combinations of <em>historical</em> and <em>real time nodes</em> as appropriate. <em>Broker nodes</em> can also cache segments locally to limit the number of outgoing segment requests for future queries accessing the same data.</p>
<p>If Zookeeper becomes unavailable, then <em>brokers</em> use their “last known good state” to forward queries.</p>
<h3 id="storage-format">Storage Format</h3>
<p>As discussed previously, a key abstraction in Druid is the <em>segment</em>, an immutable data structure used to store data. Each <em>segment</em> is associated with a <em>data source</em> (Druid’s conception of a traditional table), and contains data for a specific time period.</p>
<p>The data stored in segments is made up of two types: <em>dimensions</em> and <em>metrics</em>. <em>Dimensions</em> are values that rows aggregated or filtered on, while <em>metrics</em> correspond to numerical data (like counts).</p>
<figure><img src="https://www.micahlerner.com/assets/druid/table1.png"/><figcaption></figcaption></figure>
<p><em>Segments</em> also contain a version number. If a segment is changed, the version number is incremented, and a new version of the segment is published - this can happen if delayed events come in for a previously finalized segment. <em>Coordinator nodes</em> handle the migration to the new version of a segment by instructing <em>historical nodes</em> to fetch the new version and drop the old version. Because of this approach, Druid is said to implement Multi-version Concurrency Control (MVCC)<label for="mvcc"></label><span>This paper review doesn’t go into detail on MVCC, but there are great resources about some of the ideas in this <a href="https://www.youtube.com/watch?v=GILqZvxD6_g">talk</a>. One key idea is that there are multiple valid versions of data (like a snapshots), and different readers can view different versions of a dataset. </span>.</p>
<p>Importantly, segments store data in columns, rather than rows - an approach known as “columnar storage”. This design is used in several other databases (like <a href="https://docs.aws.amazon.com/redshift/latest/dg/c_columnar_storage_disk_mem_mgmnt.html">Redshift</a> and <a href="https://dl.acm.org/doi/10.1145/1773912.1773922">Cassandra</a>) and file formats (like <a href="https://parquet.apache.org/">Parquet</a>) because of the performance advantages it provides.</p>
<p>For example, if a query is selecting a subset of columns, the database only needs to query the subset of data for those columns. A row-based solution would scan every row, selecting out the related columns. While both scans would yield the same results, the row-based scan is (almost) guaranteed to unnecessarily access columns that aren’t needed to answer the query, nor will be in query results.</p>
<h3 id="query-api">Query API</h3>
<p>The original Druid paper describes an HTTP query API where one would specify the datasource, time range, filtering mechanism, and potential aggregations.</p>
<figure><img src="https://www.micahlerner.com/assets/druid/query.png"/><figcaption></figcaption></figure>
<p>The query API is one area where the recent versions of Druid diverge from the paper’s description. The current version of Druid <a href="https://druid.apache.org/docs/latest/querying/sql.html">exposes a SQL-like API</a> for writing and submitting queries. The paper also discusses how Druid doesn’t support joins, although recent work has implemented <a href="https://druid.apache.org/docs/latest/querying/joins.html">the idea</a><label for="joins"></label><span>One of the recent papers I read (and plan on writing about soon!) from NSDI, <a href="https://www.usenix.org/conference/nsdi22/presentation/kraft">Data-Parallel Actors: A Programming Model for Scalable Query Serving Systems</a>, discusses how Druid’s long road to implementing could have been simplified by the ideas in the paper. </span>.</p>
<h2 id="how-is-the-research-evaluated">How is the research evaluated?</h2>
<p>To evaluate the system, the paper considers the performance and scale of Druid deployed at MetaMarkets.</p>
<p>As Druid was initially designed to serve low-latency queries, the paper evaluates latency performance using production traces:</p>
<blockquote>
<p>Across all the various data sources, average query latency is approximately 550 milliseconds, with 90% of queries returning in less than 1 second, 95% in under 2 seconds, and 99% of queries returning in less than 10 seconds.</p>
</blockquote>
<p>Ingestion latency is another focus of Druid’s design. The production system at MetaMarkets was able to ingest datasets of different shapes and sizes, with minimal latency and significant throughput.</p>
<figure><img src="https://www.micahlerner.com/assets/druid/ingestion.png"/><figcaption></figcaption></figure>
<p>The paper also notes that while there is variation in ingestion latency, the problem can be solved by spending money on more resources for that component of the system (a decision that an implementer might make if especially concerned about this property).</p>
<figure><img src="https://www.micahlerner.com/assets/druid/cluster_latency.png"/><figcaption></figcaption></figure>
<h2 id="conclusion">Conclusion</h2>
<p>I found the original Druid paper interesting because the design aims to tackle <em>both</em> real-time and historical analysis use cases.</p>
<p>The system also represents a step in the lineage of systems designed with the aforementioned goals in mind - Druid was one of the first implementations of a <a href="https://en.wikipedia.org/wiki/Lambda_architecture">“Lambda Architecture”</a>, where data is served from a combination of batch and streaming systems. Recent approaches at <a href="https://www.oreilly.com/radar/questioning-the-lambda-architecture/">“Kappa”</a>, and “Delta” architectures<label for="delta"></label><span>In particular, Databricks’ <a href="https://databricks.com/research/delta-lake-high-performance-acid-table-storage-overcloud-object-stores">Delta Lake</a>. </span> seem like evolutions of what Druid originally proposed<label for="naming"></label><span>Even if the “naming architecture types based on Greek letters” can quickly get out of hand… </span>.</p>
<p>Last but not least, I enjoyed the paper because of its discussion on how the system behaves in a degraded state. While some of the details may not be as relevant given Druid’s continued evolution following the paper’s publication, it is still unique to hear how the system was developed with those concerns in mind.</p>

</section>
<section>
Found something wrong?
<a href="https://github.com/mlerner/mlerner.github.io/edit/master/_posts/2022-05-15-druid-a-real-time-analytical-data-store.md">Submit a pull request!</a>
</section>
</article></div>
  </body>
</html>
