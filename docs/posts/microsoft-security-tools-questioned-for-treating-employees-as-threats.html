<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.theregister.com/2024/08/27/microsoft_workplace_surveillance/">Original</a>
    <h1>Microsoft security tools questioned for treating employees as threats</h1>
    
    <div id="readability-page-1" class="page"><div id="body">
<p>Software designed to address legitimate business concerns about cyber security and compliance treats employees as threats, normalizing intrusive surveillance in the workplace, according to a report by Cracked Labs.</p>
<p>The <a target="_blank" rel="nofollow" href="https://crackedlabs.org/en/data-work/publications/securityriskprofiling">report</a>, titled &#34;Employees as Risks&#34; - released today by the Vienna-based non-profit - explores software from Microsoft and formerly from Forcepoint – specifically SIEM (security information and event management) and UEBA (user and entity behavior analytics) applications.</p>
<p>Part of an ongoing series of reports titled &#34;Surveillance and Digital Control at Work,&#34; the paper examines the way in which expansive information gathering in the workplace turns employees into suspects without cause.</p>

    

<p>&#34;The boundaries between information security, the protection of corporate information, fraud and theft prevention and the enforcement of compliance with regulatory requirements and organizational policies are becoming blurred,&#34; the report observes.</p>

        


        

<p>The research was conducted from 2021 through early 2024 by Cracked Labs researcher Wolfie Christl. In late 2023, Forcepoint&#39;s public sector business, Forcepoint Federal (which offered the Behavioral Analytics and Insider Risk software at issue), was sold to private equity firm TPG and took on the new name <a target="_blank" rel="nofollow" href="https://www.everfox.com/">Everfox</a>.</p>
<p>Everfox declined to comment and did not respond to a request to confirm that its current <a target="_blank" rel="nofollow" href="https://assets.everfox.com/app/uploads/2024/01/29091641/Datasheet_Insider-Risk-Solutions.pdf">insider risk software</a> [PDF] is based upon Forcepoint&#39;s Insider Risk Solutions and Behavioral Analytics. However, Christl explained the Everfox and Forcepoint documentation is essentially the same.</p>

        

<p>The purpose of the report, Christl told <em>The Register</em>, is to raise questions about the appropriate extent of workplace surveillance in light of the increasing amount of data collected through online activity logs and the communications data available to organizations.</p>
<p>&#34;What kinds of data sources and behavioral profiling are really necessary and proportionate for which purposes?&#34; Christl asked. &#34;What are the risks and which safeguards do vendors and employers implement to prevent misuse?&#34;</p>
<p>Software like Microsoft Sentinel and Purview and Forcepoint Behavioral Analytics (Everfox) is capable of monitoring everything that employees do or say, the report notes. It can monitor their behavior and flag them for further scrutiny by their bosses.</p>

        

<p>&#34;Similar to predictive policing technologies, [these applications] promise not only to detect incidents but to prevent them before they occur,&#34; according to the report. &#34;While organizations can use these software systems for legitimate purposes, this study focuses on their potential implications for employees.&#34;</p>
<p>Christl outlined some of the highlights of the report.</p>
<ul>
<li>Both Forcepoint and Microsoft offer to monitor and analyze file activity, clipboard activity, application activity, browser activity, email/chat/message/voice communication, badging activity, performance review data and even screen activity.</li>

<li>Both promise to identify &#34;anomalous&#34; behavior with AI-based profiling that &#34;learns&#34; over time how employees usually behave. They offer to continuously calculate risk scores for employees, assess their behavior, rank them by risk and single out those who are considered potential &#34;insider threats&#34; or otherwise suspicious. Similar to predictive policing technologies, they promise not only to detect incidents but to prevent them before they occur.</li>

<li>Both suggest targeting &#34;disgruntled employees&#34; and those with bad performance reviews as potential insider threats – Forcepoint even mentions &#34;internal activists&#34; and those who had a &#34;huge fight with the boss&#34; as risks.</li>

<li>Forcepoint offers to assess whether employees are in financial distress, show &#34;decreased productivity&#34; or plan to leave the job, how they communicate with colleagues and whether they access &#34;obscene&#34; content or exhibit &#34;negative sentiment&#34; in their conversations.</li>

<li>Microsoft&#39;s &#34;communication compliance&#34; system (part of Purview) offers to scan communication content for many different purposes – from detecting &#34;profanity,&#34; &#34;offensive language,&#34; and &#34;inappropriate text&#34; to corporate sabotage, data leaks, bribery, money laundering, insider trading, conflicts of interest and &#34;workplace collusion.&#34;</li>
</ul>
<p>None of this is to suggest that employers don&#39;t have the right to manage employees, or indeed the obligation to ensure the security of workplace systems. Yet as the report points out, employee surveillance fosters mistrust, may be disproportionate, and comes with potential problems like false positives and inaccuracies.</p>
<p>&#34;Microsoft <a target="_blank" rel="nofollow" href="https://learn.microsoft.com/en-us/purview/insider-risk-management-settings-intelligent-detections?tabs=purview-portal">acknowledges</a> that its cyber security and risk profiling systems may create &#39;false positives,&#39; i.e., inaccurate alerts about employees and their behavior, which is why it provides a wide range of functionality to prioritize, review and investigate alerts,&#34; the report notes, adding that the IT titan&#39;s &#34;Sentinel system may create large amounts of records on behavioral anomalies, which makes the data &#39;notoriously very noisy.&#39;&#34;</p>
<p><em>The Register</em> asked Microsoft to comment on the Cracked Labs report and were told that the Windows giant does not comment on third-party reports.</p>
<p>That wasn&#39;t true in July, when we asked about the previous installment in the series &#34;<a target="_blank" rel="nofollow" href="https://crackedlabs.org/en/data-work">Surveillance and Digital Control at Work</a>.&#34; Microsoft took the unusual step of making a corporate VP available <a target="_blank" href="https://www.theregister.com/2024/07/31/microsoft_dynamics_365_surveillance/">for an interview</a> to allay concerns about Dynamics 365. Evidently, that policy has changed.</p>
<p>Microsoft, which sells worker tracking software, did offer a general comment about surveillance. &#34;At Microsoft, we think using technology to track employees is both counterproductive and wrong,&#34; a spokesperson claimed.</p>
<p>The &#34;Employees as Risks&#34; report suggests Microsoft is a bit more open to workplace surveillance than Redmond admits. It asserts that &#34;Microsoft systematically incentivizes organizations to implement far-reaching employee surveillance by offering them the ability to quickly analyze massive amounts of personal data on employee behavior and communication and awarding them &#39;points&#39; which promise to measure their &#39;progress towards completing recommended actions.&#39;&#34;</p>
<p>Wilneida Negrón, director of policy and research at <a target="_blank" rel="nofollow" href="http://Coworker.org">Coworker.org</a>, a worker advocacy non-profit, told <em>The Register</em>, &#34;[Employee surveillance technology] has been around for some time but has grown in sophistication [over] the last five years, especially as it has been able to collect and analyze large amounts of worker data to make predictions or assessments.</p>
<p>&#34;Several labor, social, and technological trends have combined to make this type of monitoring more common – including advances in behavioral and predictive analytics, the proliferation of IoT devices, cloud computing, and remote work have made it easier to gather and analyze data from multiple sources, the growth of remote and hybrid work, and the increasing threat of insider threats and the requirement to comply with stricter data protection and cybersecurity regulations.&#34;</p>
<ul>

<li><a href="https://www.theregister.com/2024/08/26/fbi_data_security/">Watchdog warns FBI is sloppy on secure data storage and destruction</a></li>

<li><a href="https://www.theregister.com/2024/08/21/russia_memo_ukraine_invasion/">Russia tells citizens to switch off home surveillance because the Ukrainians are coming</a></li>

<li><a href="https://www.theregister.com/2024/08/05/keir_starmer_facial_recognition/">Keir Starmer says facial recognition tech is the answer to far-right riots</a></li>

<li><a href="https://www.theregister.com/2024/07/23/ftc_surveillance_pricing/">FTC sticks a probe into &#39;surveillance pricing&#39; Big Biz uses to gouge us all</a></li>
</ul>
<p>The tendency to collect as much worker data as possible has become a broad area of concern – not only for employees and advocacy groups, but for regulators, legal scholars, and privacy professionals.</p>
<p>For example, in a forthcoming Modern Law Review <a target="_blank" rel="nofollow" href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=4929980">article</a>, Jeevan Hariharan, assistant professor of law at Queen Mary University of London, and Hadassa Noorda, assistant professor of criminal law at the University of Amsterdam, argue that employee monitoring is concerning because it intrudes on physical (as opposed to informational) privacy and can in severe cases amount to a form of imprisonment.</p>
<p>The article argues that different areas of the law need to develop in order to regulate workplace surveillance technology.</p>
<p>In an email, Hariharan and Noorda wrote, &#34;In our view, [the report] highlights some very serious concerns about how cyber security and risk profiling technologies can be deployed by organizations to monitor their employees in highly intrusive ways. The case studies in the report illustrate the far-reaching surveillance capabilities of tools which promise to assist firms dealing with cyber security issues, particularly &#39;internal&#39; threats arising from employee conduct. The software involved essentially allows constant monitoring of everything employees do or say, facilitating extensive surveillance of employees&#39; communications and behavior at work, from their keystrokes to their physical movements.&#34;</p>
<p>The two law professors contend that while companies may implement these systems in different ways and offer various justifications based on the assertion the technology services legitimate business purposes, it&#39;s clear there&#39;s potential for these systems to be misused to the detriment of workers&#39; health, privacy, and basic liberties.</p>
<p>From a legal perspective, they observe these sorts of technologies would be governed by the data protection rules (eg GDPR) and human rights regimes (eg Article 8 of the European Convention of Human Rights) in Europe and the UK.</p>
<p>&#34;Importantly, we would add that there is a real question about whether these legal regimes are currently fit for purpose in dealing with the full range of harms that arise from the use of these technologies,&#34; they noted. &#34;Companies tend to view the principal legal risk of using these technologies against employees as compliance with informational privacy laws such as data protection rules. In our view, however, mere compliance with, for example, the GDPR does not necessarily mean that uses of such technology are ethically or legally permissible.&#34;</p>
<p>Hariharan and Noorda argue that from the point of view of employees, the problem posed by persistent surveillance at work goes beyond the collection of data that may be used against them.</p>
<p>&#34;The objection is deeper than this, representing concerns about the employees&#39; bodies and lives being subject to unending control at work, and their inability to move freely in this environment,&#34; they argued. &#34;In our view, this highlights that there may be a range of other parts of our law which have been neglected but are in fact relevant to assessing the legality of such technology – including laws more directly concerned with bodily interferences and individual liberty.&#34;</p>
<p>In the US, Benjamin Wiseman, associate director of the Federal Trade Commission&#39;s Privacy and Identity Protection Division, gave <a target="_blank" rel="nofollow" href="https://www.ftc.gov/system/files/ftc_gov/pdf/Jolt-2-8-24-final.pdf">a speech</a> [PDF] on the issue of worker surveillance in February at Harvard Law School. He points out that not only are workers at risk of the privacy harms that affect consumers due to the abuse of geolocation information and other data, but they also face threats to their rights as employees. &#34;Indeed, some companies and vendors are building tools that purport to <a target="_blank" rel="nofollow" href="https://lpeproject.org/blog/workplace-surveillance-collective-resistance-a-symposium/">predict the risk of workers unionizing</a>,&#34; he asserted.</p>
<p>&#34;Companies are also funneling the information they collect into AI models to make automated decisions that can have serious consequences for workers&#39; autonomy, their physical and mental health, and their pay,&#34; Wiseman noted, adding that the consequences can be even worse when software algorithms provide inaccurate data or make flawed calculations.</p>
<p>Citing how pharmacy chain Rite Aid received a five-year ban on using facial technology for deploying a system that <a target="_blank" rel="nofollow" href="https://www.ftc.gov/legal-library/browse/cases-proceedings/2023190-rite-aid-corporation-ftc-v">misidentified customers</a> – particularly women and people of color – as shoplifters, Wiseman predicted companies misleading workers about surveillance technologies can expect similar scrutiny.</p>
<p>The US National Labor Relations Board (NLRB) has also <a target="_blank" rel="nofollow" href="https://www.nlrb.gov/news-outreach/news-story/nlrb-general-counsel-issues-memo-on-unlawful-electronic-surveillance-and">signaled its interest</a> in workplace surveillance – at least to the extent that it interferes with labor organization rights guaranteed under Section 7 of the National Labor Relations Act. In an October 2022 memo, NLRB general counsel Jennifer Abruzzo wrote, &#34;Under settled Board law, numerous practices employers may engage in using new surveillance and management technologies are already unlawful.&#34;</p>
<p>Negrón said that employees and employers in the US should familiarize themselves with the state and federal laws governing workplace monitoring.</p>
<p>&#34;For example, states like California, Connecticut, Delaware, New York, Illinois, Massachusetts, and Texas have laws offering varying degrees of protection against this kind of monitoring,&#34; she explained. &#34;California&#39;s CCPA extends certain data rights to employees, while its labor code mandates notification for electronic monitoring. Connecticut, Delaware, and New York require employers to notify employees about monitoring, with New York also addressing potential discrimination risks. Illinois&#39;s BIPA offers strong protections for biometric data, and Massachusetts courts have upheld privacy rights against intrusive surveillance. Texas prohibits the unauthorized recording of oral communications.</p>
<p>&#34;At the federal level, the ECPA and NLRA provide some safeguards. So, although there is a patchwork of laws, the first step for employees and employers is to understand their rights and obligations at the state and federal level.&#34; ®</p>                                
                    </div></div>
  </body>
</html>
