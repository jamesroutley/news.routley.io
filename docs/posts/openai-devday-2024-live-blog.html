<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://simonwillison.net/2024/Oct/1/openai-devday-2024-live-blog/">Original</a>
    <h1>OpenAI DevDay 2024 live blog</h1>
    
    <div id="readability-page-1" class="page"><div>


<div data-permalink-context="/2024/Oct/1/openai-devday-2024-live-blog/">

<p>1st October 2024</p>



<p>I’m at OpenAI DevDay in San Francisco, and I’m trying something new: a live blog, where this entry will be updated with new notes during the event.</p>


<div id="live-updates">

<p><strong>10:19</strong> The keynote is starting with a review of o1, and some examples of applications that use it.</p>

<p><strong>10:30</strong> They started with some demos of o1 being used in applications, and announced that the rate limit for o1 doubled to 10000 RPM (from 5000 RPM) - same as GPT-4 now.</p>

<p><strong>10:31</strong> The first big announcement: a realtime API, providing the ability to use WebSockets to implement voice input and output against their models.</p>

<p><strong>10:33</strong> What can you build with the new realtime API? The demonstrated an updated version of their Wanderlust travel agent demo. The demo uses voice as both input and output.</p>

</div>

</div>


</div></div>
  </body>
</html>
