<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://denisdefreyne.com/articles/2024-memoization/">Original</a>
    <h1>The intricacies of implementing memoization in Ruby</h1>
    
    <div id="readability-page-1" class="page"><div>
    <div class="page">
      <!-- title and metadata -->
      
        
          <div>
            

            <!-- metadata -->
            
              <div>
                
                
                <div>
                  <p>a 30-minute read</p>
                  <p>(5600 words)</p>
                </div>
              </div>
            
          </div>
        
      

      

      <!-- body -->
      
<p>In the never-ending quest to write code that is performant, we have many techniques at our disposal. One of those techniques is <em>memoization</em>,<sup id="fnref:cf1"><a href="#fn:cf1" rel="footnote" role="doc-noteref">1</a></sup><span><span aria-hidden="true"><sup id="fnref:cf1">1</sup></span><span aria-hidden="true"><span>1</span> That’s memoization, not memorization — there’s no “r”! </span></span> which boils down to storing the results of expensive function calls, so that these expensive functions do not need to be called more than absolutely necessary.</p>

<p>Many years ago, I wrote a Ruby gem for memoization, ddmemoize. It has since been superseded by better solutions, but for a long time, it was one of the best memoization libraries for Ruby out there.</p>

<p>Creating this library taught me a great deal. Memoization is surprisingly complex, and a proper implementation, it turns out, goes far beyond Ruby’s <code>||=</code> memoization operator. Memory management and thread safety, for example, are important considerations, though often overlooked.</p>

<p>In this article, I’ll walk you through all the learnings I gained in the process of implementing this memoization gem.</p>

<ol role="doc-toc"><li><a href="#local-variables">Local variables</a></li><li><a href="#the-memoization-operator">The memoization operator</a><ol><li><a href="#be-careful-with-false-and-nil">Be careful with false and nil</a></li></ol></li><li><a href="#argument-aware-memoization">Argument-aware memoization</a></li><li><a href="#memoization-dsl">Memoization DSL</a><ol><li><a href="#memoization-requirements">Memoization requirements</a></li></ol></li><li><a href="#memoizing-on-frozen-objects">Memoizing on frozen objects</a></li><li><a href="#memory-efficient-memoization">Memory-efficient memoization</a><ol><li><a href="#weak-references">Weak references</a></li><li><a href="#soft-references">Soft references</a></li><li><a href="#freezing-revisited">Freezing, revisited</a></li></ol></li><li><a href="#supporting-keyword-arguments">Supporting keyword arguments</a></li><li><a href="#supporting-blocks">Supporting blocks</a></li><li><a href="#thread-safe-memoization">Thread-safe memoization</a></li><li><a href="#metrics">Metrics</a></li><li><a href="#conclusion">Conclusion</a></li></ol><h2 id="local-variables">Local variables</h2>

<p>The simplest tool at our disposal for remembering values is the concept of <em>local variables</em>. Trivial, perhaps — but still worth mentioning.</p>

<p>In the following example, the <code>#calc_base_price</code> function is called twice:</p>

<pre><code>def total_price
  vat = calc_base_price * VAT_RATE
  calc_base_price + vat
end
</code></pre>

<p>If the <code>#calc_base_price</code> function were expensive, for example because of a database query, it would make sense to store the result in a local variable. In the following snippet, the base price is stored in a local variable called <code>base_price</code>:</p>

<pre><code>def total_price
  base_price = calc_base_price
  vat = base_price * VAT_RATE
  base_price + vat
end
</code></pre>

<p>But there is certainly more to memoization than just this trivial example!</p>

<h2 id="the-memoization-operator">The memoization operator</h2>

<p>Ruby comes with an operator, <code>||=</code>, which is sometimes called the <em>memoization operator</em>. Here is an example of it in use:</p>

<pre><code>def base_price
  @base_price ||= calc_base_price
end
</code></pre>

<p>When executing this method, Ruby will check whether the <code>@base_price</code> instance variable is already defined and has a value that is <em>truthy</em>, meaning not <code>nil</code> and not <code>false</code>. If so, it will return the value of <code>@base_price</code>.</p>

<p>If, on the other hand, <code>@base_price</code> is either undefined or set to <code>nil</code> or <code>false</code>, it will call the <code>#calc_base_price</code> method, store its return value in the <code>@base_price</code> instance variable, and use that value as the value for the entire expression (and thus as the return value of <code>#base_price</code>).</p>

<p>The <code>#base_price</code> method could be rewritten without the use of the <code>||=</code> operator like this:</p>

<pre><code>def base_price
  if defined?(@base_price) &amp;&amp; @base_price
    @base_price
  else
    @base_price = calc_base_price
  end
end
</code></pre>

<p>However, one of the cases in which Ruby’s <code>||=</code> operator does not work well is when the memo­ized method has parameters. That’s next on the list to fix.</p>

<div>
  <h3 id="be-careful-with-false-and-nil">Be careful with false and nil</h3>

  <p>The values <code>false</code> and <code>nil</code> can make memoization using the <code>||=</code> operator not work as intended. This is because the <code>||=</code> operator evaluates the right-hand side when the memoization variable is undefined, or when the memo­ized value is falsy.</p>

  <p>Consider the following memo­ized method:</p>

  <pre><code>def open?
  @is_open ||= calc_is_open
end
</code></pre>

  <p>If <code>#calc_is_open</code> returns false, the <code>@is_open</code> memo­ized instance variable will be set to false. But the next time <code>#open?</code> is called, the <code>#calc_is_open</code> method will be called again — because <code>@is_open</code> is <em>falsy</em>, meaning <code>nil</code> or <code>false</code>.</p>

  <p>This is a general problem with using the <code>||=</code> operator to memo­ize methods that return boolean values. It is a problem with methods that are expected to return <code>nil</code>, too.</p>

  <p>A good way around this problem is to avoid <code>||=</code> in this situation, and instead use <code>#defined?</code> to check whether or not to use the memo­ized value:</p>

  <pre><code>def open?
  if defined?(@is_open)
    @is_open
  else
    @is_open = calc_is_open
  end
end
</code></pre>

  <p>Less compact, but at least it works.</p>
</div>

<h2 id="argument-aware-memoization">Argument-aware memoization</h2>

<p>Any piece of literature on the topic of memoization will inevitably bring up the Fibonacci sequence as an example where memoization is particularly useful. Here is a Ruby implementation of a function that returns a given entry in the Fibonacci sequence:</p>

<pre><code>def fib(n)
  case n
  when 0
    0
  when 1
    1
  else
    fib(n - 1) + fib(n - 2)
  end
end
</code></pre>

<p>This works as intended: <code>fib(6)</code> evaluates to 8 and <code>fib(7)</code> evaluates to 13.</p>

<p>However, for larger numbers, the execution time quickly increases. I wrote some code to calculate the first 50 Fibonacci numbers, and print out the duration<sup id="fnref:cf2"><a href="#fn:cf2" rel="footnote" role="doc-noteref">2</a></sup><span><span aria-hidden="true"><sup id="fnref:cf2">2</sup></span><span aria-hidden="true"><span>2</span> This code snippet uses a monotonic clock to calculate elapsed time. This is a more accurate way than using <code>Time.now</code>, because the monotonic clock is not affected by small shifts that occur e.g. when synchronising with a network time server. </span></span> to calculate them:</p>

<pre><code>def now
  Process.clock_gettime(
    Process::CLOCK_MONOTONIC
  )
end

50.times do |i|
  print &#34;#{i}: &#34;

  before = now
  val = fib(i)
  after = now
  duration = after - before

  puts &#34;#{val} (#{format &#39;%.1f&#39;, duration}s)&#34;
end
</code></pre>

<p>Here is what it printed out:</p>

<pre><code>0: 0 (0.0s)
1: 1 (0.0s)
2: 1 (0.0s)
3: 2 (0.0s)
4: 3 (0.0s)
5: 5 (0.0s)
6: 8 (0.0s)
7: 13 (0.0s)
8: 21 (0.0s)
9: 34 (0.0s)
10: 55 (0.0s)
11: 89 (0.0s)
12: 144 (0.0s)
13: 233 (0.0s)
14: 377 (0.0s)
15: 610 (0.0s)
16: 987 (0.0s)
17: 1597 (0.0s)
18: 2584 (0.0s)
19: 4181 (0.0s)
20: 6765 (0.0s)
21: 10946 (0.0s)
22: 17711 (0.0s)
23: 28657 (0.0s)
24: 46368 (0.0s)
25: 75025 (0.0s)
26: 121393 (0.0s)
27: 196418 (0.0s)
28: 317811 (0.0s)
29: 514229 (0.0s)
30: 832040 (0.1s)
31: 1346269 (0.1s)
32: 2178309 (0.2s)
33: 3524578 (0.3s)
34: 5702887 (0.5s)
35: 9227465 (0.8s)
36: 14930352 (1.2s)
37: 24157817 (2.0s)
38: 39088169 (3.2s)
39: 63245986 (5.2s)
40: 102334155 (8.3s)
41: 165580141 (13.5s)
42: 267914296 (21.8s)
</code></pre>

<p>Calculating number 42 in the Fibonacci sequence took <em>21 seconds</em>,<sup id="fnref:cf3"><a href="#fn:cf3" rel="footnote" role="doc-noteref">3</a></sup><span><span aria-hidden="true"><sup id="fnref:cf3">3</sup></span><span aria-hidden="true"><span>3</span> Did you spot how the durations form something quite close to the Fibonacci sequence, too? How neat is that?! </span></span> after which I gave up and aborted the script. Extrapolating from the durations above, I estimate that calculating number 50 in the Fibonacci sequence would take 17 minutes.<sup id="fnref:cf4"><a href="#fn:cf4" rel="footnote" role="doc-noteref">4</a></sup><span><span aria-hidden="true"><sup id="fnref:cf4">4</sup></span><span aria-hidden="true"><span>4</span> This is assuming that the thermal throttling on my M2 MacBook Air does not engage. If it does, I imagine it would take much longer than that. </span></span></p>

<p>The reason why calculating Fibonacci numbers gets so slow is because there is a <em>lot</em> of redundant work happening. For example, calculating <code>fib(40)</code> calculates <code>fib(39)</code> and <code>fib(38)</code>. Calculating <code>fib(39)</code> <em>also</em> calculates <code>fib(38)</code>. This redundant work gets progressively worse for lower numbers. For example, <code>fib(40)</code> calculates the third number (n=2) in the Fibonacci sequence <em>63 245 986 times</em>.</p>

<p>It only really needs to do that once. No wonder this implementation is slow.</p>

<p>One way to avoid this problem with execution speed would be to rewrite the method to avoid recursion and use looping instead:</p>

<pre><code>def fib(n)
  arr = [0, 1]
  while arr.size &lt;= n
    arr &lt;&lt; arr.last(2).sum
  end
  arr[n]
end
</code></pre>

<p>The reason why this solution is so much faster is because it avoids recalculating anything. For example, <code>fib(40)</code> calculates the third number in the Fibonacci sequence only once — not 63 million times.</p>

<p>The version that uses a loop instead of recursion is <em>much</em> faster, but it has the problem of not being nearly as easy to read as the initial version. In this faster, recursive version, the mathematical definition of the Fibonacci sequence is not readily visible.</p>

<p>The <code>#fib</code> function cannot be memo­ized by applying the <code>||=</code> operator as before. Something a little more sophisticated is needed, creating a cache for each value of the argument <code>n</code>:</p>

<pre><code>def fib(n)
  @fib ||= {}
  @fib[n] ||=
    case n
    when 0
      0
    when 1
      1
    else
      fib(n - 1) + fib(n - 2)
    end
end
</code></pre>

<p>With this change, calculating <code>fib(40)</code> is instantaneous. In fact, so is <code>fib(4000)</code>.<sup id="fnref:cf5"><a href="#fn:cf5" rel="footnote" role="doc-noteref">5</a></sup><span><span aria-hidden="true"><sup id="fnref:cf5">5</sup></span><span aria-hidden="true"><span>5</span> Any number much larger than 8000 or so will yield a different problem: <code>stack level too deep (SystemStackError)</code>. This is difficult, but not impossible, to avoid with a recursive solution. The version that uses a loop won’t have this issue. </span></span></p>

<h2 id="memoization-dsl">Memoization DSL</h2>

<p>One of Ruby’s great strengths is its capacity for metaprogramming. A good use case for this is automating memoization by tacking a call to <code>memo­ize</code> after a method definition, like this:</p>

<pre><code>def fib(n)
  # [snip]
end
memo­ize :fib
</code></pre>

<p>The technique that I’ll introduce here only works for <em>methods</em>, not for functions. So, let’s stick <code>#fib</code> in a class:</p>

<pre><code>class Fib
  def fib(n)
    case n
    when 0
      0
    when 1
      1
    else
      fib(n - 1) + fib(n - 2)
    end
  end
end
</code></pre>

<p>The invocation is a little different, but it works as before (with the same slowness):</p>

<pre><code>p Fib.new.fib(10)
</code></pre>

<p>We’ll create a module named <code>Memoization</code> and stick the <code>memo­ize</code> method in there:</p>

<pre><code>module Memoization
  def memo­ize(method_name)
</code></pre>

<p>Its goal will be to replace the method with the given name (<code>:fib</code> in our example) with a new one that performs automatic memoization. This new method needs to be able to call the original method, so it first creates a copy of the original method, using <code>#alias_method</code>:</p>

<pre><code>    orig_method_name =
      &#39;__orig_&#39; + method_name.to_s
    alias_method(orig_method_name, method_name)
</code></pre>

<p>In our example with <code>#fib</code> example, this will create a method named <code>#__orig_fib</code>.</p>

<p>The original method (<code>#fib</code> in our example) has not been touched yet. The next step is to redefine that original method, for which <code>#define_method</code> is useful. For now, it’ll use <code>#send</code> to call the original method; an implementation with memoization will follow later:</p>

<pre><code>    define_method(method_name) do |*args|
      send(orig_method_name, *args)
    end
  end
end
</code></pre>

<p>To use this new functionality in our existing <code>Fib</code> class, first add <code>extend Memoization</code> near the top, and then add <code>memo­ize :fib</code> after the <code>#fib</code> method definition:</p>

<pre><code>class Fib
  extend Memoization

  def fib(n)
    case n
    when 0
      0
    when 1
      1
    else
      fib(n - 1) + fib(n - 2)
    end
  end
  memo­ize :fib
end
</code></pre>

<p>This will still work, still without memoization (yet):</p>

<pre><code>p Fib.new.fib(10)
</code></pre>

<p>It is now time to implement memoization in the newly defined method. The first thing it needs is a cache:</p>

<pre><code>define_method(method_name) do |*args|
  @__cache ||= {}
</code></pre>

<p>This <code>@__cache</code> instance variable will contain the results of all invocations for all methods on this particular instance. The keys of the <code>@__cache</code> hash will be the method name.</p>

<p>Next, the implementation needs to get the cache for this particular method, given by the <code>method_name</code> variable:</p>

<pre><code>  method_cache = (@__cache[method_name] ||= {})
</code></pre>

<p>With the cache for this particular method now available, it can check whether there is already a value for the given arguments. If there is, that is the value that can be returned — the entire point of memoization:</p>

<pre><code>  if method_cache.key?(args)
    method_cache[args]
</code></pre>

<p>If there is no value available yet, call the original method and store the return value in the cache for this method:</p>

<pre><code>  else
    method_cache[args] =
      send(orig_method_name, *args)
  end
end
</code></pre>

<p>In Ruby, an assignment evaluates to the value that was assigned, so there is no need for an explicit <code>method_cache[args]</code> after the assignment.</p>

<p>With this change, running <code>fib(40)</code> is now very fast indeed — practically instantaneous:</p>

<pre><code>p Fib.new.fib(40)
</code></pre>

<p>There is one more neat change that is possible. In Ruby, method definitions return the mehod name as a symbol, so <code>memo­ize</code> can be stuck in front of the <code>def</code> keyword and the <code>memo­ize :fib</code> line removed:</p>

<pre><code>memo­ize def fib(n)
  # [snip]
end
</code></pre>

<p>Now it looks like a keyword, which I find rather neat.</p>

<h3 id="memoization-requirements">Memoization requirements</h3>

<p>Before continuing, I want address the following question: under which circumstances can memoization be safely applied? Memoization is not a technique that can be spray-painted onto code to make it faster. There are restrictions to consider for memo­ized code to work correctly.</p>

<p>A memo­ized method must only use variables that never change value. This includes instance variables, arguments, global variables, constants, and more.</p>

<p>To illustrate this, take a look at the following example <code>LineItem</code> class, with a memo­ized <code>#total_price</code> method:<sup id="fnref:cf6"><a href="#fn:cf6" rel="footnote" role="doc-noteref">6</a></sup><span><span aria-hidden="true"><sup id="fnref:cf6">6</sup></span><span aria-hidden="true"><span>6</span> The use of memoization here is not particularly useful: multiplying two numbers, <code>count</code> and <code>unit_price</code>, is very fast  — but it is appropriate as an example. </span></span></p>

<pre><code>class LineItem
  extend Memoization

  attr_accessor :unit_price
  attr_accessor :count

  def initialize(unit_price:, count:)
    @unit_price = unit_price
    @count = count
  end

  memo­ize def total_price
    count * unit_price
  end
end
</code></pre>

<p>The total price is calculated correctly:</p>

<pre><code>line_item = LineItem.new(unit_price: 49, count: 2)
p line_item.total_price
# =&gt; 98
</code></pre>

<p>However, after changing the count, the total price is not updated, because it is memo­ized:</p>

<pre><code>line_item.count = 3
p line_item.total_price
# =&gt; 98
</code></pre>

<p>A solution to this problem is to make <code>LineItem</code> immutable, either by freezing it or replacing <code>attr_accessor</code> with <code>attr_reader</code>. This would prevent the count of a <code>LineItem</code> from being changed; instead, a new instance of <code>LineItem</code> can be created with the correct count:</p>

<pre><code>line_item = LineItem.new(
  unit_price: 49,
  count: 2)
p line_item.total_price
# =&gt; 98

line_item = LineItem.new(
  unit_price: line_item.unit_price,
  count: 3)
p line_item.total_price
# =&gt; 147
</code></pre>

<p>A good general guideline is to use memoization only on objects that are immutable, and likewise pass in only arguments that are immutable as well.</p>

<h2 id="memoizing-on-frozen-objects">Memoizing on frozen objects</h2>

<p>There is one particular issue with this implementation. Attempting to use memoization on a frozen object fails. Take the following code as an example:</p>

<pre><code>f = Fib.new
f.freeze
p f.fib(40)
</code></pre>

<p>This fails with a <code>FrozenError</code>:</p>

<pre><code>example3.rb:20:in `block in memo­ize&#39;: can&#39;t modify frozen Fib: #&lt;Fib:0x000000011ffeb008&gt; (FrozenError)
</code></pre>

<p>This happens because the <code>@__cache</code> instance variable is frozen along with the rest of the object.</p>

<p>The solution<sup id="fnref:cf7"><a href="#fn:cf7" rel="footnote" role="doc-noteref">7</a></sup><span><span aria-hidden="true"><sup id="fnref:cf7">7</sup></span><span aria-hidden="true"><span>7</span> The <em>initial</em> solution, that is. Yes, I am foreshadowing an alternative implementation! </span></span> I used was to turn the idea of a cache on its head. Rather than have one cache per instance (the <code>@__cache</code> instance variable) with keys for each method name, I opted for having one cache per <em>method</em>,  with keys for each instance. In practice, this solution looks like this:</p>

<pre><code>module Memoization
  def memo­ize(method_name)
    # [snip]

    method_cache = {}
    define_method(method_name) do |*args|
      instance_cache = (method_cache[self] ||= {})
      if instance_cache.key?(args)
        instance_cache[args]
      else
        instance_cache[args] =
          send(orig_method_name, *args)
      end
    end
  end
end
</code></pre>

<p>The <code>method_cache</code> local variable is the cache for the particular method given by the <code>method_name</code> argument. The instance cache simply is <code>method_cache[self]</code>, with self being the instance on which the memo­ized method is called.<sup id="fnref:cf8"><a href="#fn:cf8" rel="footnote" role="doc-noteref">8</a></sup><span><span aria-hidden="true"><sup id="fnref:cf8">8</sup></span><span aria-hidden="true"><span>8</span> A benefit to this approach of using a local variable rather than an instance variable is that the instance variable no longer needs to be hidden with an obscure name. The reason why <code>@__cache</code> starts with a double underscore is so that it’s not accidentally accessed by code outside the gem. </span></span></p>

<p>Unfortunately, in the excitement of finding an approach to support memoization for frozen objects, a bigger problem has appeared: memory usage.</p>

<h2 id="memory-efficient-memoization">Memory-efficient memoization</h2>

<p>The memoization implementation never frees up memory. This means that memory usage can keep on growing. I can get this to happen if I’m not careful:</p>

<pre><code>low swap: killing largest compressed process with pid 95941 (ruby) and size 76343 MB
</code></pre>

<p>This particular Ruby process ballooned to north of 75 GB of memory usage, before the macOS kernel killed it.</p>

<p>This is especially an issue with long-running processes.<sup id="fnref:cf9"><a href="#fn:cf9" rel="footnote" role="doc-noteref">9</a></sup><span><span aria-hidden="true"><sup id="fnref:cf9">9</sup></span><span aria-hidden="true"><span>9</span> Is it really still a problem with “long-running” processes if they’re no longer “long-running” because they get quickly killed by the kernel? (Don’t answer that — it is a rhetorical question.) </span></span> Availability becomes a problem when a process can’t adhere to its memory limits!</p>

<p>This issue was not as much of problem before. After all, memo­ized values were stored on the instance, and when the instance is deallocated, the memo­ized values are deallocated with it.</p>

<h3 id="weak-references">Weak references</h3>

<p>There is a potential solution that Ruby provides by default: <em>weak references</em>. Explaining what weak references are is best done by comparing them to regular references, also known as <em>strong references</em>. Take a look at this piece of code:</p>

<pre><code>arr = [1, 2, 3]
arr.reverse
# =&gt; [3, 2, 1]
</code></pre>

<p>This example creates an array, and returns a reversed version of it. Straightforward, so far. The garbage collector will not deallocate <code>arr</code>, because it is still referenced. This code snippet still works:</p>

<pre><code>GC.start

arr.reverse
# =&gt; [3, 2, 1]
</code></pre>

<p>This happens because there is a reference (a strong reference) to the <code>arr</code> object. Any object that is referenced, directly or indirectly, by a variable in scope (like an instance variable, a global variable, a local variable, or a constant) is immune from being garbage-collected, i.e. having its memory reclaimed. This makes so much sense that we as programmers rarely think about this.</p>

<p>Weak references, however, change things up a little. Consider this code snippet:</p>

<pre><code>require &#39;weakref&#39;

arr = WeakRef.new([1, 2, 3])
arr.reverse
# =&gt; [3, 2, 1]
</code></pre>

<p>That still works as before. However, after invoking the garbage collector, the array is no longer accessible; trying to do anything with it will yield an exception:</p>

<pre><code>GC.start
arr.reverse
# WeakRef::RefError (Invalid Reference - probably recycled)
</code></pre>

<p>The array, i.e. the object that the arr variable pointed to, has had its memory reclaimed; it is gone.</p>

<p>On first sight, weak references seem like they could provide an excellent solution to the problem of memory bloat caused by memoization. Wrap the memo­ized values in a <code>WeakRef</code>, and done —  right?</p>

<p>But there is a problem: when using weak references for memoization, <em>all</em> memo­ized values wiped out when garbage collection occurs. This is unfortunate, and in my experience wrecks the usefulness of memoization. An alternative is needed.</p>

<h3 id="soft-references">Soft references</h3>

<p>There exists a kind of reference that is weaker than a strong reference, but stronger than a weak reference. These are called <em>soft references</em>.</p>

<p>Soft references are much less eager to be garbage-collected than weak references. The value pointed to by a soft reference will only be garbage collected after it has not been accessed for a number of garbage collections.</p>

<p>Ruby does not come with an implementation of soft references by default. There is a now-deprecated gem, <code>ref</code>, that implements them:</p>

<pre><code>require &#39;ref&#39;

ref = Ref::SoftReference.new(&#34;hello&#34;)

ref.object.upcase
# =&gt; HI
</code></pre>

<p>The API is similar to that of Ruby’s built-in <code>WeakRef</code>, though <code>Ref::SoftReference</code> does not automatically delegate to the object. Accessing the pointed-to object is done through the <code>#object</code> method.</p>

<p>Initially, the pointed-to object is accessible as usual.</p>

<pre><code>p ref.object
# &#34;hello&#34;
</code></pre>

<p>However, after a couple of garbage-collection cycles, the object is finally garbage collected, and the pointer becomes <code>nil</code>:</p>

<pre><code>p ref.object
# nil
</code></pre>

<p>It is not much work to replace the uses of <code>WeakRef</code> with <code>Ref::SoftReference</code> ones. But is it worth it? I don’t think it is, for two reasons:</p>

<ul>
  <li>
    <p>The <code>ref</code> gem is no longer maintained, and there is no other soft reference implementation for Ruby that I know of.<sup id="fnref:cf10"><a href="#fn:cf10" rel="footnote" role="doc-noteref">10</a></sup><span><span aria-hidden="true"><sup id="fnref:cf10">10</sup></span><span aria-hidden="true"><span>10</span> I was considering contributing my own implementation of soft references to Ruby, but I worry that I have neither the time nor the skill to see such a project through. </span></span></p>
  </li>
  <li>
    <p>Soft references have a performance overhead, especially when implemented in Ruby itself. This can diminish the gains from memoization.</p>
  </li>
</ul>

<p>There is also still the problem that the function/method arguments are not garbage-collected either. This was already a problem with <code>WeakRef</code>.</p>

<p>Neither <code>WeakRef</code> nor <code>Ref::SoftReference</code> works well enough for the purposes of memoization. The original implementation, which used an instance variable, overall is a better choice when it comes to memory management.</p>

<p>And there is a better way of dealing with frozen objects, too!</p>

<h3 id="freezing-revisited">Freezing, revisited</h3>

<p>There is a better way to deal with frozen objects. It is a slight variation on the original implementation of the memoization DSL. Gone are the weak references and the soft references.</p>

<p>The first change (a trivial one) is to move the <code>memo­ize</code> method into a <code>Memoization::ClassMethods</code> module:</p>

<pre><code>module Memoization::ClassMethods
  def memo­ize(method_name)
    # [snip]

    define_method(method_name) do |*args|
      @__cache ||= {}
      method_cache =
        (@__cache[method_name] ||= {})

      # [snip]
    end
  end
end
</code></pre>

<p>This new module can already be used as-is by passing this module to <code>extend</code>:</p>

<pre><code>class Fib
  extend Memoization::ClassMethods

  memo­ize def fib(n)
    # [snip]
  end
end
</code></pre>

<p>So far, nothing has changed: the behavior is identical to what we had in the initial implementation of <code>memo­ize</code>.</p>

<p>Next comes the solution to the frozenness problem. The idea is the following: when <code>#freeze</code> is called on an instance of a class that uses memoization, the cache is created <em>before</em> the object becomes frozen. That is what the <code>Memoization::InstanceMethods</code> is for:</p>

<pre><code>module Memoization::InstanceMethods
  def freeze
    @__cache ||= {}
    super
  end
end
</code></pre>

<p>This new module can be put to use in the example <code>Fib</code> class using <code>prepend</code>:</p>

<pre><code>class Fib
  extend Memoization::ClassMethods
  prepend Memoization::InstanceMethods

  memo­ize def fib(n)
    # [snip]
  end
end
</code></pre>

<p>It is important to use <code>prepend</code> rather than <code>include</code> here. With <code>prepend</code> (unlike <code>include</code>) the <code>#freeze</code> method of the prepended module would be executed before the <code>#freeze</code> method defined on the instance (if there is any). This is necessary, because the <code>@__cache</code> instance variable needs to be created before any freezing takes place.</p>

<p>So now there is a better solution for dealing with frozen objects: call <code>extend</code> with the <code>ClassMethods</code> module, and <code>prepend</code> the <code>InstanceMethods</code> module. With this change, frozen objects are no longer an obstacle to memoization. Memory usage is not an issue anymore.</p>

<p>There is one more useful change to make. Calling both <code>extend</code> and <code>prepend</code> is slightly awkward. Ideally, there would be only a single call to <code>extend Memoization</code>, like this:</p>

<pre><code>class Fib
  extend Memoization

  memo­ize def fib(n)
    # [snip]
  end
end
</code></pre>

<p>To make this work, implement the <code>extended</code> method on the Memoization module, which will be called as a callback whenever any class calls <code>extend Memoization</code>. The <code>extended</code> method, which takes the class or module as an argument, can then delegate to the proper <code>extend</code> and <code>prepend</code> methods, like above:</p>

<pre><code>module Memoization
  def self.extended(thing)
    thing.extend(ClassMethods)
    thing.prepend(InstanceMethods)
  end
end
</code></pre>

<p>And with that, the <code>Memoization</code> module provides a nice way of memoizing that works with frozen objects and is memory-efficient.</p>

<p>But are still a few more problems left to solve.</p>

<h2 id="supporting-keyword-arguments">Supporting keyword arguments</h2>

<p>Since version 3.0, Ruby supports <em>keyword arguments</em>. These are distinct from regular arguments, also known as <em>positional arguments</em>. Here is an example of <code>#fib</code> which takes <code>n</code> as a keyword argument:</p>

<pre><code>def fib(n:)
  case n
  when 0
    0
  when 1
    1
  else
    fib(n: n - 1) + fib(n: n - 2)
  end
end
</code></pre>

<p>At the moment, memo­ize this method and calling it will fail with an <code>ArgumentError</code>:</p>

<pre><code>example.rb:5:in `fib&#39;: wrong number of arguments (given 1, expected 0; required keyword: n) (ArgumentError)
</code></pre>

<p>The method created by <code>#define_method</code> inside the <code>memo­ize</code> method does not take keyword arguments; <code>*args</code> captures only positional arguments and not keyword arguments. The <code>#define_method</code> call needs to be updated to also grab keyword arguments by adding <code>**kwargs</code> to the list of parameters:</p>

<pre><code>define_method(method_name) do |*args, **kwargs|
</code></pre>

<p>Getting the method cache remains the same:</p>

<pre><code>  @__cache ||= {}
  method_cache = (@__cache[method_name] ||= {})
</code></pre>

<p>The memoization key needs to change. Instead of only including positional arguments, it also needs to include the keyword arguments. The easiest approach is to construct a key that consists of positional arguments and keyword arguments:</p>

<pre><code>  key = [args, kwargs]
</code></pre>

<p>This key is then used, instead of just args, when fetching the memo­ized value (if any):</p>

<pre><code>  if method_cache.key?(key)
    method_cache[key]
</code></pre>

<p>If there is no memo­ized value, the original method needs to be called with not just the positional arguments, but also the keyword arguments:</p>

<pre><code>  else
    method_cache[key] =
      send(orig_method_name, *args, **kwargs)
  end
end
</code></pre>

<p>With this change, memoization works as expected on methods with keyword arguments.</p>

<h2 id="supporting-blocks">Supporting blocks</h2>

<p>In Ruby, methods can take three types of things. We have tackled positional arguments and keyword arguments, but there is one more type of thing a Ruby method can take: a <em>block</em>.</p>

<p>However, there is a snag: every invocation of a block will result in a new block object (a <code>Proc</code> instance), which renders it impossible to meaningfully memo­ize a method that takes a block. To illustrate this, consider the following trivial class:</p>

<pre><code>class Test
  def run(&amp;blk)
    p blk.__id__
  end
end
</code></pre>

<p>This code simply prints the ID of the block. Calling Test#run twice prints two different <code>Proc</code> IDs:</p>

<pre><code>test = Test.new

test.run { }
# stdout: 860

test.run { }
# stdout: 880
</code></pre>

<p>It is not only because there are two distinct blocks in the source code (line 3 and 5 in the example above) that the <code>Proc</code> IDs are different. This even happens when there is only a single block in the source code:</p>

<pre><code>2.times do
  test.run { }
end
# stdout: 860
# stdout: 880
</code></pre>

<p>That this happens in general makes sense, because each invocation of a block captures a (potentially) different environment.</p>

<p>This, however, means that memoizing a method that takes a block is not possible. Memoization will be entirely ineffective: no invocation of the memo­ized method will ever use a memo­ized value.</p>

<p>For this reason, I believe the best way forward is to explicitly disallow memoizing a method that takes a block. Memoization needs to raise an error in this case:</p>

<pre><code>define_method(method_name) do |*args, **kwargs, &amp;blk|
  if blk
    raise ArgumentError,
      &#34;cannot memo­ize methods that take a block&#34;
  end
</code></pre>

<p>Raising an exception when a block is given to a memo­ized method is the most reasonable thing to do. With this change, we’ve made it less likely that unexpected behavior arises.</p>

<h2 id="thread-safe-memoization">Thread-safe memoization</h2>

<p>In a multi-threaded environment, the current implementation of memoization potentially has some issues.</p>

<p>Two threads could be calling the same method (with the same arguments, if any) at the same time. This is wasteful, and could lock up valuable resources that could better be used for something else. When two threads are calling the same method with the same arguments, then it would be better if the second thread were to wait for the first thread to finish, and then reuse the just-obtained return value.</p>

<p>This is not a problem with correctness, but with resource usage. You might not consider this to be a problem that is worth solving.</p>

<p>But if you were to try to fix it, know that adding thread safety<sup id="fnref:cf11"><a href="#fn:cf11" rel="footnote" role="doc-noteref">11</a></sup><span><span aria-hidden="true"><sup id="fnref:cf11">11</sup></span><span aria-hidden="true"><span>11</span> The term “thread safety” is possibly not quite correct in this context. After all, the code will execute correctly without changes, and the issue is really about efficiency. But I can’t think of a term that fits this problem better than “thread safety”, so that is what I am using. </span></span> is not trivial. Take a look at this example for a class with a single memo­ized method that takes no arguments:</p>

<pre><code>class Order
  def initialize
    @mutex = Thread::Mutex.new
  end

  def discount
    @_discount ||= begin
      @mutex.synchronize do
        unmemoized_discount
      end
    end
  end

  private

  def unmemoized_discount
    # [snip]
  end
end
</code></pre>

<p>Multiple threads might attempt to run <code>Order#discount</code>, but only a single <code>#unmemoized_discount</code> call will be coming from <code>#discount</code> at any given time. That is what a mutex is for, and it does its job admirably.</p>

<p>Admirably… and uselessly! This implementation is not quite correct. It is possible for two concurrent calls to <code>#discount</code> to happen, and those two calls will compete for the mutex. The first invocation will call <code>#unmemoized_discount</code>. The second invocation will wait to obtain a mutex lock, eventually calling <code>#unmemoized_discount</code>. The second call does not use the memo­ized value at all.</p>

<p>Here is a better implementation:</p>

<pre><code>def discount
  @_discount ||= begin
    @mutex.synchronize do
      if defined?(@_discount) &amp;&amp; @_discount
        @_discount
      else
        unmemoized_discount
      end
    end
  end
end
</code></pre>

<p>At the very beginning of the mutex, the method checks the presence of <code>@_discount</code> <em>again</em>. It could’ve changed since the method call began awaiting the mutex, after all.</p>

<p>This version works better, but there is another issue: the mutex block could have finished, an another thread could have started executing the mutex-protected block <em>before</em> the memo­ized <code>@_discount</code> instance variable got assigned.</p>

<p>The solution is to move the assignment to <code>@_discount</code> into the mutex block:</p>

<pre><code>def discount
  if defined?(@_discount) &amp;&amp; @_discount
    return @_discount
  end

  @mutex.synchronize do
    if defined?(@_discount) &amp;&amp; @_discount
      @_discount
    else
      @_discount = unmemoized_discount
    end
  end
end
</code></pre>

<p>This implementation will properly prevent multiple concurrent and unnecessary calls to <code>#unmemoized_discount</code>.<sup id="fnref:cf12"><a href="#fn:cf12" rel="footnote" role="doc-noteref">12</a></sup><span><span aria-hidden="true"><sup id="fnref:cf12">12</sup></span><span aria-hidden="true"><span>12</span> To the best of my knowledge, that is. I wouldn’t want to swear on this implementation being correct, because multithreading is <em>hard</em>. </span></span></p>

<p>There is something missing, however. At the moment, there is only one memo­ized method, so a single mutex, <code>@mutex</code>, is sufficient. Ideally, though, there would need to be a single mutex per memo­ized method; after all, parallel calls to different memo­ized methods should probably not block each other.</p>

<p>Additionally, this approach also only realistically works for memo­ized methods that have no parameters. If there are parameters, it might make sense to have a mutex for each possible combination of arguments. But then it might happen that two threads create a mutex for the same combination of arguments at the same time, so there might need to be a mutex to prevent that from happening. Also, mutexes that are no longer needed should ideally not take up memory, so a way of automatically cleaning them up would be useful, too.</p>

<p>Multithreading-aware memoization gets complicated very fast. And none of this is likely necessary, and perhaps not even very useful at all. Memoized methods are meant to be idempotent (or pure) anyway.</p>

<p>My preferred approach to this problem is to explicitly not think about thread safety, and delegate this concern to the caller. Document the thread-safety guarantees and move on. An easy way out, perhaps, but also the most reasonable in my opinion.</p>

<p>That leaves us with just one thing left to improve.</p>

<h2 id="metrics">Metrics</h2>

<p>A memo­ized function must have exactly the same behavior as its non-memo­ized counterpart, save for differences in execution speed. That is the contract for using memoization. But if the behavior of a memo­ized method is exactly the same as its non-memo­ized counterpart, then how does one check whether memoization is useful at all?</p>

<p>One of the neat features of my old ddmemoize library is that you could configure it to track and print metrics. Here is an example of what <code>DDMemoize.print_metrics</code> could spit out:</p>

<pre><code>   memoization │ hit  miss  %
───────────────┼─────────────────
Order#discount │ 258   110  70.1%
</code></pre>

<p>A <em>hit</em> indicates an invocation where the memo­ized value was used, and a <em>miss</em> means that a no memo­ized value was available and the original method thus had to be called. In this example, the hit ratio of <code>Order#discount</code> is 70.1%, which means that of all calls (hits plus misses), 70.1% were hits.</p>

<p>Is 70.1% a good rate? It depends. Is <code>#discount</code> slow? Then perhaps having it memo­ized makes sense. But if <code>#discount</code> is already fast, then memoization might not help, and perhaps even be harmful to performance, as memoization itself brings a tiny overhead in execution speed and memory usage.</p>

<p>If the number of misses is significantly higher than the number of hits, then memoization is most likely not effective.</p>

<p>A high hit rate is not inherently better than a low hit rate. The hit rate merely gives an idea of whether or not memoization is effective. When a code change makes the hit rate drop dramatically, then the correct response would to be reconsider the usage of memoization, rather than attempt to bring the hit rate back up.</p>

<p>There is a more interesting question to ask when the hit rate is high: why was the memo­ized method called so often (on the same object, and with the same arguments) in the first place? Perhaps rather than introducing memoization, it is worth figuring out where duplicate calls are coming from, and then eliminating them.</p>

<p>In my experience, memoization can be a crutch. That does not mean memoization is not useful, but it can be indication of sub-optimal design or architecture. These issues are often hard to spot or hard to fix, so memoization still has a place in a software developer’s tool kit. Knowing the hit rate, too, is great for using memoization effectively.</p>

<h2 id="conclusion">Conclusion</h2>

<p>The preceding few thousand words have made it hopefully clear that memoization is tricky to implement.</p>

<p>Use a battle-tested library instead of writing a memoization implementation yourself. I recommend the <a href="https://github.com/panorama-ed/memo_wise">memo_wise</a> Ruby gem. It is the best memoization library for Ruby that I am aware of. Jemma Issroff and Jacob Evelyn have written about <a href="https://ja.cob.land/optimizing-memowise-performance">optimising memo_wise performance</a> and <a href="https://jemma.dev/blog/esoteric-ruby-in-memowise">esoteric Ruby in memo_wise</a>.</p>

<p>At the moment of writing, my ddmemoize gem is about seven years old, and deprecated. Don’t use it! Better solutions exist.<sup id="fnref:cf13"><a href="#fn:cf13" rel="footnote" role="doc-noteref">13</a></sup><span><span aria-hidden="true"><sup id="fnref:cf13">13</sup></span><span aria-hidden="true"><span>13</span> I am happy to have abandoned ddmemoize in favor of better solutions. It is, after all, not about what we create, but about what we do to help us <em>get stuff done</em> and grow and learn as software developers and as people.The ddmemoize project definitely helped with that. </span></span></p>

<p>And now, with quite a bit of a delay, I have shared my own learnings in building this library in the hope and conviction that the learnings I gained along my journey will be useful to others.</p>

<p>If you found this article useful, consider <a href="https://ko-fi.com/denisdefreyne">buying me a coffee</a>.</p>




    </div>
  </div></div>
  </body>
</html>
