<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://p.migdal.pl/blog/2023/02/ai-arts-information-theory/">Original</a>
    <h1>AI won’t make artists redundant – thanks to information theory</h1>
    
    <div id="readability-page-1" class="page"><div><blockquote>
<p>“Alchemy does describe a means to make gold, but the procedure is so arduous that, by
comparison, digging beneath a mountain is as easy as plucking peaches from a tree.” - <a href="https://en.wikipedia.org/wiki/Ted_Chiang" target="_blank" rel="nofollow noopener noreferrer">Ted Chiang, “The Merchant and the Alchemist&#39;s Gate”</a></p>
</blockquote>
<p>The recent development of AI for image generation causes strong and polarized emotions among designers, photographers, and other visual artists - or at least, ones from my tech bubble. Quite a few issues are related to the usage of data from training, plagiarism, authorship of generated works, and reinforcement of stereotypes.</p>
<p>Yet, the most important one is general - how it would impact the workforce. In particular, if:</p>
<ul>
<li>AI will never become as good as human artists, or</li>
<li>AI will take our jobs, the hard-earned skills will become redundant on the market.</li>
</ul>
<p>Month by month, the balance shifts from the first to the second. I will argue that regardless of the progress of AI, artists will provide a unique creative value.</p>
<h2 id="progress"><a href="#progress" aria-hidden="true"><span></span></a>Progress</h2>
<p>For a long time, machines were nowhere near human visual skills. Then in 2012, there was a breakthrough - convolutional neural networks that were able to decently classify photos. For there next few years <a href="https://paperswithcode.com/sota/image-classification-on-imagenet" target="_blank" rel="nofollow noopener noreferrer">the progress continued rapidly</a>. The inverse problem of turning text descriptions (called prompts) into images posed a challenge. But step-by-step it went from <a href="https://arxiv.org/abs/1605.05396" target="_blank" rel="nofollow noopener noreferrer">generating small images</a> in 2016, through <a href="https://www.youtube.com/watch?v=kSLJriaOumA" target="_blank" rel="nofollow noopener noreferrer">working with photorealistic faces</a>, to open-ended image-generation tasks. The process is so fast that <a href="https://arxiv.org/abs/2107.07397" target="_blank" rel="nofollow noopener noreferrer">my 2021 review of readily-applicable AI for image generation and enhancement</a> aged poorly - in just a year. This field was revolutionized in 2022 with <a href="https://openai.com/dall-e-2/" target="_blank" rel="nofollow noopener noreferrer">DALL·E 2 by OpenAI</a> and an open-source <a href="https://stability.ai/blog/stable-diffusion-public-release" target="_blank" rel="nofollow noopener noreferrer">Stable Diffusion</a>, which is a basis for multiple projects, including commercial <a href="https://midjourney.com" target="_blank" rel="nofollow noopener noreferrer">Midjourney</a>.</p>
<figure><img src="data:image/svg+xml,%3csvg fill=&#39;none&#39; viewBox=&#39;0 0 757 210&#39; xmlns=&#39;http://www.w3.org/2000/svg&#39; xmlns:xlink=&#39;http://www.w3.org/1999/xlink&#39;%3e%3cdefs%3e%3cfilter id=&#39;__svg-blur-e6e20e52ac97e3e14a6b9b48c9b9b6f4&#39;%3e%3cfeGaussianBlur in=&#39;SourceGraphic&#39; stdDeviation=&#39;40&#39;/%3e%3c/filter%3e%3c/defs%3e%3cimage x=&#39;0&#39; y=&#39;0&#39; filter=&#39;url(%23__svg-blur-e6e20e52ac97e3e14a6b9b48c9b9b6f4)&#39; width=&#39;757&#39; height=&#39;210&#39; xlink:href=&#39;data:image/jpeg%3bbase64%2c/9j/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQYGBcUFhYaHSUfGhsjHBYWICwgIyYnKSopGR8tMC0oMCUoKSj/2wBDAQcHBwoIChMKChMoGhYaKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCj/wAARCAASAEADASIAAhEBAxEB/8QAGQAAAgMBAAAAAAAAAAAAAAAAAAYCBQcE/8QALhAAAgEDAwIEBAcBAAAAAAAAAQIDBAURABIhBhMxQVFxIjJhgQcUFRYjQlKR/8QAFwEBAQEBAAAAAAAAAAAAAAAABAUGA//EACoRAAECAwYEBwAAAAAAAAAAAAEAAgMEEQUhMTIzQRITcZEiNFFhgbHR/9oADAMBAAIRAxEAPwBNorTbYbfIaemSpiglXeseCMp/ZlHHIHj6DPjrpttXZKeSSP8ASKQNMf5GSLlweT8XzZz9dVouIjRrlbhFWwtIwnpplHdjbkEkDgjjP302dM0FjuohlFPNSMHIZdzYbA%2bUhvr6aXxElaKFDaxppQ9ln/4i9NvPBG9n2x2zBnjh2Mz7yPiVm5%2bLOAB4EHPGNdNgts/7fs8EkW2oiSSMoT4kTOCD99bEaeltdatupElNFMrTdx8mJWwQQ5/qpBxkH00k9bSpY5aOKy29VhWmMqU0eFG5mchsjIAJ5449tDtLTDh6gKFMZnFo%2bEydO9AW7qajne33fEuWP8UOYo2/zknJA8M6TxQPR2jrOCRAjR24R4DbvCoiBOftqHTHU1ZT22tpun6eKmip0WpuSdzsyNGzAMEP%2bvU/88dWUUMcti6zehnkmo3pcQrIRuC9%2bLGfrjUmFVkw0kUaTdfUn3/EeEa3b7rPbDYqaaCsqrnGjh4JEpIzIoLSkYDEHnaPX1xqfUltll6L7TS06GBldYnjzIdq4IVvIY8s86uae11lVLBUx0kgWBWVpDtKuu0gIPPxPPgOPPOoX%2bmebo9mjXuT/ErhQfm4B49s6ugcwiqQ7w4LrvSLDVusKiNXALBRjJDcE60SzxpHHGsaKii2s4CjADdpeffk6NGmblMGo9LXRVVUS0V/Ms8rlamPbucnG58Nj3HB1DqGNI46IRoqBaRQNoxgZbjRo1Itby3b7XCY1B0CSriB%2bmyPgbu6Fz54441fdLsf2f1WMnH5AD7d%2bPRo1Jls8PqjtzLNLpUzrBJtmlGY0Y4c8nJ599WFhqp2p6dWnlI2gYLn66NGtGzFNX//2Q==&#39; /%3e%3c/svg%3e" width="757" alt="[Neil Goosey at AI Art Universe FB Group](https://www.facebook.com/groups/526007639164475/user/834840710/) and [Instagram @neilgoosey](https://www.instagram.com/neilgoosey/)" data-srcset="/assets/static/neilgoosey-ai-art.bbab06f.d021c5955965f9b97596dff879ad6709.jpg 757w" data-sizes="(max-width: 757px) 100vw, 757px" data-src="/assets/static/neilgoosey-ai-art.bbab06f.d021c5955965f9b97596dff879ad6709.jpg"/><figcaption><a href="https://www.facebook.com/groups/526007639164475/user/834840710/">Neil Goosey at AI Art Universe FB Group</a> and <a href="https://www.instagram.com/neilgoosey/">Instagram @neilgoosey</a></figcaption></figure>
<p>While we may argue that it still has problems with as basic things such as drawing realistic hands, the progress continues. Will there be room for human artists?</p>
<p>For the sake of this blog post, I will focus on art and design that is focused on creating images, to be viewed on a computer. That is - digital arts and photography. AI might not impact live-theatre actors or sculptors at all.</p>
<h2 id="applied-graphics-vs-fine-arts"><a href="#applied-graphics-vs-fine-arts" aria-hidden="true"><span></span></a>Applied graphics vs fine arts</h2>
<p>There are two kinds of creative works. One is something design-as-a-commodity, things that can be created by many professionals. For example, <em>“a stock photo of cheerful students playing chess”</em> or <em>“female detective investigating an abandoned house, digital art”</em>. Clearly, each image has its quality and flavor depending on its creator. But it may matter less for the end goal.</p>
<p>I envision that while a lot of manual work will be automatized, and the job market for design will change, AI will remain a tool. While a handful of highly skilled professionals won&#39;t be affected, for the rest the workflow will change substantially. The impact might be less alike <em>“yet another Photoshop plugin”</em> and more alike <em>“digital image processing tools in general”</em>. The invention of photography did disturb the market of painters (especially: for portraits) - but by no means ended painting.</p>
<p>Since a lot of repetitive work will be delegated to AI, the job landscape might change. For high-class specialists, it will be yet another tool they may use. For others - some will be effectively promoted to leadership positions. That is, focusing more on content and fine-crafting details while delegating simpler tasks to AI - rather than to junior graphic designers. Others might fall into a gap of <em>“nice skills, but not yet that offer a business advantage”</em>. Furthermore, the lower entry barrier to create any art is likely to result in the average quality going down - not unlike that plastic made manufacturing cheaper, but also less durable.</p>
<p>But there is also another kind of creative works - ones unique and highly dependent on both skills and vision of the artists. <a href="https://pl.wikipedia.org/wiki/Mona_Lisa" target="_blank" rel="nofollow noopener noreferrer">“Mona Lisa” by Leonardo da Vinci</a> and <a href="https://en.wikipedia.org/wiki/The_Starry_Night" target="_blank" rel="nofollow noopener noreferrer">“Starry Night” by Vincent van Gogh</a> are prime examples. Any other images inspired by their style might be good, but still - even if technically flawless, are not as original. For example, <a href="https://arthive.com/hansruedigiger/works/321698~Necronom_IV" target="_blank" rel="nofollow noopener noreferrer">H. R. Giger set the aesthetics for the Alien franchise</a> and became a default nightmarish-organic style () - replicated by ordinary graphic designers.</p>
<figure><img src="data:image/svg+xml,%3csvg fill=&#39;none&#39; viewBox=&#39;0 0 1200 400&#39; xmlns=&#39;http://www.w3.org/2000/svg&#39; xmlns:xlink=&#39;http://www.w3.org/1999/xlink&#39;%3e%3cdefs%3e%3cfilter id=&#39;__svg-blur-70ea830518f134996011919372679105&#39;%3e%3cfeGaussianBlur in=&#39;SourceGraphic&#39; stdDeviation=&#39;40&#39;/%3e%3c/filter%3e%3c/defs%3e%3cimage x=&#39;0&#39; y=&#39;0&#39; filter=&#39;url(%23__svg-blur-70ea830518f134996011919372679105)&#39; width=&#39;1200&#39; height=&#39;400&#39; xlink:href=&#39;data:image/jpeg%3bbase64%2c/9j/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQYGBcUFhYaHSUfGhsjHBYWICwgIyYnKSopGR8tMC0oMCUoKSj/2wBDAQcHBwoIChMKChMoGhYaKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCj/wAARCAAVAEADASIAAhEBAxEB/8QAGwAAAQUBAQAAAAAAAAAAAAAAAAMEBQYHAQj/xAAxEAACAQMDAgQEBAcAAAAAAAABAgMABBEFEiEGMQdBUWETFSKRCBRxgSMycqHR4fD/xAAXAQEBAQEAAAAAAAAAAAAAAAADBAUB/8QAJhEAAgICAQIFBQAAAAAAAAAAAQIAAxEhEgRBIjEyUcFhcZGh4f/aAAwDAQACEQMRAD8AhLzSpI5bOzuJNtqolihO4KeVJweM445/Snp0t5nVJJ5pJEYAnYuxseXqRUD1tqEcNzormaK5gWSRnKEg4wBtPOMf7qzXWr6Hdpb/AC25jihWIERKpcg%2b3ofLFaSW5bHxISDjMU0G3sY9TWe9MbK5YGFY9qRkdj7irv1gLeTwP1/5aifDN5Gf4Y4yJIsn%2b1UK26isVKtDa3NzKv0hZQqJux3JJPHtVxuLm/1TwK6gN%2b1vHML9FT8qCqqm%2bIgD35NT9Sp5BxnWsdvx7xaGx6vKefUv5gzgqjnJBZ1y33p/cWs8NjaSLIWF1ykaSbiT/SOfvSUGnbXG%2bIyNuyys2w4q39LdPXU2s/MrKxxIW3W9o77pPTcBjJC9xx5UFlZrXm%2bh9YouQkhJHzaemk6BZalJqSXVzMzKbTkGMZOcsT/NnuMDHrUFq9pqVtZabNdwiG2uVMsBAwzjPcn/ALjBqY6yihn1u9nhaaKb4mZItgAyRhjzjBz6jzrklw%2brW0NpPEzmMMd/CkOeFPHl34rtdd7qrbP6wN9vnvCD0q3ISs61AFgglGBuByAP3pLRJ5R8Ta%2bFAziiijViTmNjUmQ8tuqTGaSRnbAycEf5/eta6duXf8PPUE0pZz8xXuxz3i86KKrpJNlefcQrQODfYzMoIXa4hjaXl13Fxnd98%2bnFaJ4ZXz6Xbm6tlBuZLhIBI5yUjO7IHv8AT3oorYSpLeQsGR/ZhdRa9YypxGfi7pkL30d%2bpZDfQBp4x2LYGSP1zWYANBKyb2dEdPpPY5NFFA6hawV1jUp6N2c%2bLeZ//9k=&#39; /%3e%3c/svg%3e" width="1200" alt="An original masterpiece and a derivative work." data-srcset="/assets/static/starry-doom.82a2fbd.df859d333d82bafa2aeee831fe649c31.jpg 480w, /assets/static/starry-doom.75e41ba.df859d333d82bafa2aeee831fe649c31.jpg 1200w" data-sizes="(max-width: 1200px) 100vw, 1200px" data-src="/assets/static/starry-doom.75e41ba.df859d333d82bafa2aeee831fe649c31.jpg"/><figcaption>An original masterpiece and a derivative work.</figcaption></figure>
<p>Would be easy to create conceptually and aesthetically new works using prompts?
Think about <em>“addiction to social media”</em> or even a broader idea <em>“a current societal problem”</em>. The question of <em>“how?”</em> turns quickly into <em>“what do we want to do in the first place?”</em>. Sure, you can create a stock image of someone looking at their phone. But if you want to create something genuinely new, you will need to expand your prompt a lot. For example:</p>
<ul>
<li><em>“a current societal problem”</em></li>
<li><em>“a current societal problem, addiction to social media”</em></li>
<li><em>“a current societal problem, addiction to social media, drawing”</em></li>
<li><em>“a current societal problem, addiction to social media, drawing, colors”</em></li>
<li>etc, etc</li>
</ul>
<p>As you may imagine, this prompt is nowhere near to one needed for creating something unique. Alternatively, instead of creating a single image for a given prompt, it may an AI model might create <strong>all</strong> images fulfilling the criteria. But then it will be billions or more, making choosing a desired one virtually impossible.</p>
<h2 id="information-theory"><a href="#information-theory" aria-hidden="true"><span></span></a>Information theory</h2>
<p>When I was a kid, I made a fascinating observation. With MSPaint alone, I can create any conceivable image. Including photography of anything, in any detail. I “just” need to fill the canvas, pixel by pixel, with a suitable color, parametrized by red, green, and blue components, each in the range of 0-255. Did I ever create with this technique anything that makes any sense? No. Was I right? In theory - yes. In practice, it is not a good way to go and is effectively impossible. It might tell a lot about why I ended up in information theory rather than - arts.</p>
<p>What is information theory? <a href="https://openai.com/blog/chatgpt/" target="_blank" rel="nofollow noopener noreferrer">ChatGPT</a> answers correctly:</p>
<blockquote>
<p>Information theory is a mathematical framework for quantifying, storing, and transmitting information. It was developed by Claude Shannon in 1948 and deals with concepts such as entropy, data compression, channel capacity, and error correction. Information theory is widely used in many fields including computer science, electrical engineering, and statistics.</p>
</blockquote>
<p>We measure information in bits. A single bit is how much you can encode in one 0 or 1. There is a nice introduction in <a href="https://www.youtube.com/watch?v=v68zYyaEmEA" target="_blank" rel="nofollow noopener noreferrer">Solving Wordle using information theory</a> by 3Blue1Brown and in <a href="http://colah.github.io/posts/2015-09-Visual-Information/" target="_blank" rel="nofollow noopener noreferrer">Visual Information Theory</a> by Chris Olah For an in-depth one, <a href="http://www.inference.org.uk/itprnn/book.html" target="_blank" rel="nofollow noopener noreferrer">Information Theory, Pattern Recognition and Neural Networks</a> - a freely available book by David MacKay.</p>
<p>But let’s get back to the topic and quantify the length of a description needed to specify a concrete image. In English, we get roughly 10 bits per word. The last prompt <em>“a current societal problem, addiction to social media, drawing, colors”</em> has 100 bits of information. 100 bits means that it is enough to distinguish from 2^100 equally likely possibilities. It is 1 and 30 zeros. A humongous number! But how many bits are there in a picture?</p>
<figure><img src="data:image/svg+xml,%3csvg fill=&#39;none&#39; viewBox=&#39;0 0 831 236&#39; xmlns=&#39;http://www.w3.org/2000/svg&#39; xmlns:xlink=&#39;http://www.w3.org/1999/xlink&#39;%3e%3cdefs%3e%3cfilter id=&#39;__svg-blur-85a35dec33c6e0e0f3663182999452fe&#39;%3e%3cfeGaussianBlur in=&#39;SourceGraphic&#39; stdDeviation=&#39;40&#39;/%3e%3c/filter%3e%3c/defs%3e%3cimage x=&#39;0&#39; y=&#39;0&#39; filter=&#39;url(%23__svg-blur-85a35dec33c6e0e0f3663182999452fe)&#39; width=&#39;831&#39; height=&#39;236&#39; xlink:href=&#39;data:image/png%3bbase64%2ciVBORw0KGgoAAAANSUhEUgAAAEAAAAASCAYAAADrL9giAAAACXBIWXMAAAsSAAALEgHS3X78AAAHQUlEQVRYw81YaVOUVxZuo9%2bmkpRjFQYilv8gP2Om8mGKskyVBhNMjLIIkkmFzGRmym/jB0oqKgozYlhEFkVKkM0y7BIM0tD0vgl0083SNE2zr8375JzTvC0qSGtN1UjVqT733nNf73nuc5arBu/Qn6Io8js9M4N%2buxUDTjuJA/02K3R22%2bbYTrpVhNfCY5vYhMcO9JHum5p64Zs7/WneJQBCGxvy224z4YzfjsyFEXy7MoZT5l9x1mNA5pIHmSujOD2oxWlnL62NylzyqAlJpi6xzVxw4/SUHbUW/Qvf3BEAFSH%2b3ar/PwHocFhwjhz7HlP4ATM4M9yP9ICTxgFkIYiUMTNSyGnWeS49OIhvhvrENkvxI3XZgzq7KfxNJUoANugffxmM7WTrurpnq7z8nbcBoNNhRcbaOP5GDv4dC0im2z8/N0zjOZJ5nJu0I81no7V5cnoWmfNunHUPiC3vObc%2bgXqHOToAXj7obofe2IVS0X7ndQC0mfT4wtqNZJcOKV4jTnQ1IsnwmIAw0tiEL3pbcPJps%2bjJI0acMnbh%2bOMGseU9ibYnuK/XRhcCqkM6nQ4TExOi%2b/1%2b0b1er%2bgsY2NjmJycjKzPzc3B5/NheXkZs7Ozssb2bDc/P/9KWO0E0FabSA6wGPG1R49znAfmPDjWfRuHCt/Hkar9OHJvP%2bJvfIhD//0QR6r3y9yhwj/g6OMisvUi3W/DKa8etSbdmwFw8eJFtLe3y2GuXLmCgoIC1NbW4vLly7h69Sry8vJQVVUltvX19bh58yZycnJQWFiI3NxcEZ7nvT09Pc/DKoqQwkYICtmqdO2gEEinBJdFOeBHrOBzaw0%2bKtPg43qSBg0%2bKiEpDus8d7Bcg%2bOmKrJdlT1pq2PR5wAxCoUwPT2NhYUFrK6uoqSkRG5yfX0dLpcLHo9Hbptvnf%2bYHcPDw%2bju7obZbBbd7XbLGrNghspY5JZ3CQVlbQ1KJARCzwFYZQAC4lSi9QHiKjSIb3wP8U3vIa50D%2bJu7UH8Qxo37kVsJQFgvod/YI1yAgGwRgA43gCANToEO764uBiJcdZVh9jhYDAoY5vNJnogEJAxOztFNXdwcFDCQd3LoIqDLASkMjMNZTYIJRggffN3eQnK0y4oBTkyDm0eqo1C4CvK/GkTZmRMu3C0sxgH8zSIu02Ol%2b3BwVy69asa0XkuJl%2bDhPYCnJ92I23cjC9d/agx9su31rdJ1FtFAHjy5InQnGnPDlksFly/fl0%2b4HQ60dnZKVJXV4cLFy6gvLwc%2bfn54qRWqxXbpqYmtLa2ori4GJcuXRJQhN0MwLgHSsUNKHWVUGrLody/HZYa0itvQvnkAyg5/3oOgNmAJEcPJT3KA75nSGj9GTHkdGzxHsSWkMOXNYj5SSM6z8Vc0%2bAvv%2bSLbQrtOel8ihp9X%2bQCdmXA6Ogo%2bvv7herMBr5dNY45wfH6yMgIKisr8fDhQwkFq9UqN86hw2HALDEajbLPZDJhZWUlqmqgDDmgNFQJS0Kbth1SBseIztNC60TbA6F5fCPTPnzrsaVhncOC105ICKzTngCVwfFICMxRQmZG8pnZF1VnFgsDXj4gH1yNYTU/qGPevJNDDMRumX5bWV/bvhFa5kbIT7V9GZ9basI5oGEfDjfuoxywF3Ele3G4aZ/MxdLacWOVJMwsTCJ1xYsHNmM4ZO12PHr0SHxgp5nJXV1d6Ovre7EPUGOWy1l2djZKS0slGXZ0dEiGr66uxp07d0S4GnAYcEhwFWDaFxUVRQB7pRnaTrYCxFWAz6CWQSu1whMWZMwM4rtlH4713MaB/xDtKdvHkLMHiPIHcsN6DFWHP9La0e5Csp3E%2beAzfE254/5mDnCNuMUHZisLM5TF4XC8%2bBZQD7O0tCTlsK2tDc3NzTAYDIJWRUUFrl27JtWA5zjeuexxvmhpaYmEzOtqf7R9QCs1QonGxzjzrJc6PD0%2ba63Cp83ZSOjNQ4I2H39uvIg/Nf4bCX35NHcdn7Zk41jLHZx16ZFMyTPR/htqGQD6rJUYwAmaL4arnF6vFxZw7nrlMfS6g3OVYHD%2b193f9m8BNQeorbARf13wUYyH8E9Kq%2bcDI8iYcpOuSNx/t%2bRHsttAtov4lh5QX3kNyH/UgNFhF3QDA3JZHPfMbr5YZi6X8G0ZoPbzqqjjra3wTvImDNj1LbA4gh82/NLbJ9NDJ526wixlUup8KrW8qdTtsc5zGQEHzj7TUg6Yx0lqiU/oWlGz2QmOjY9LwubzcQgwGzihDw0NPS%2bDuyWs7V6L0di9LQAt1AckBZ1IoWSWtuHDCXoXJNHrL5U6vFR66JwkQBKHtEgNTSCFmHKKYv645VeynZAKkLTkRrV5QL5lphDl8OX2nCsV54O7d%2b9K2L5z/x%2bwsQmc0%2btBsVGLMpseZQ4jirTduKXvpbEBZXYDinU9JL/RWnh8y6AVG7blPYWGXhhcQ/ItH9F%2bnFjA9GcAuGPlMs9zzIrfAelAHaZi4a47AAAAAElFTkSuQmCC&#39; /%3e%3c/svg%3e" width="831" alt="Prompt to image - a diagram." data-srcset="/assets/static/prompt-to-image-diagram.82a2fbd.a65b4992859134c928ecacb635c169c8.png 480w, /assets/static/prompt-to-image-diagram.e8b8700.a65b4992859134c928ecacb635c169c8.png 831w" data-sizes="(max-width: 831px) 100vw, 831px" data-src="/assets/static/prompt-to-image-diagram.e8b8700.a65b4992859134c928ecacb635c169c8.png"/><figcaption>Prompt to image - a diagram.</figcaption></figure>
<p>The <a href="https://en.wikipedia.org/wiki/Color_depth" target="_blank" rel="nofollow noopener noreferrer">True Color standard</a> (RGB, each 0-255) has 8 bits per color channel, so 24 bits in total - per each pixel. For a 200x200 color image, it is 960000 bits of information. 96k English words - <a href="https://jerichowriters.com/average-novel-wordcount/" target="_blank" rel="nofollow noopener noreferrer">an equivalent of an adult novel</a>. If you like to think about how much is it in the terms of possible choices - it is around 10^300000, or: 1 and 300 000 zeros. A lot! To compare, the number of atoms in the whole Universe is estimated to be 10^80.</p>
<p>It sounds like way too much. So, how about only a 32x32 image, with 16 colors? It is 4 bits per pixel, and 4096 bits of information per image. And well within a short description - just 410 English words. But, just exercise this idea, maybe it would be easier to… draw this tiny image?</p>
<p>Still, even if doable, the task may be as efficient and enjoyable as telling talented intern instructions and expecting to get the exact result as in your head.</p>
<p>Of course, it is only a ballpark estimate. The entropy of texts and images is significantly lower than our estimates. A text has 10 bits per word of information only if all words are picked randomly. <a href="https://xkcd.com/936/" target="_blank" rel="nofollow noopener noreferrer">Wonderful for generating passwords</a>, but won’t make any comprehensible text - too chaotic even by dadaist standards. Similarly, meaningful images are not composed of random pixels. Moreover, many images are too similar to be distinguished by humans. And a huge number would fall into a single category of “random noise”. JPG makes images smaller (typically by a factor of 10x) thanks to some regularities.</p>
<p>If any of you has an idea how to estimate information (in bits) of human-interpretable images, I would love to hear that!</p>
<h2 id="playing-with-ai-image-generation"><a href="#playing-with-ai-image-generation" aria-hidden="true"><span></span></a>Playing with AI image generation</h2>
<p>Furthermore, prompt creation is an art on its own. Sure, you may be lucky and get a wonderful result on your first go. Similar to photography, a lucky “click” may win you a stunning image. But if you want to consistently create stunning images, it takes a lot of skill and effort. Owning a DSLR camera does not automatically make you an artist. Neither having access to Midjourney.</p>
<p>If you want to play with AI image generation, I suggest two things. First, give try free and open-source solutions, e.g. <a href="https://github.com/brycedrennan/imaginAIry" target="_blank" rel="nofollow noopener noreferrer">imaginAIry</a> and <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui" target="_blank" rel="nofollow noopener noreferrer">stable-diffusion-webui</a>. Not only you are not bound by an external service&#39;s costs and availability, but also you get more control over what you create.
Second, don&#39;t plagiarise. While exploring generated content might be insightful, don&#39;t try to get credit for something, which is not yours. There are no mature tools - the closest ones are Google reverse image search and <a href="https://www.stableattribution.com/" target="_blank" rel="nofollow noopener noreferrer">Stable Attribution</a>. It is your responsibility to decide if you generated a novel image or is so “inspired“ that it verges on stealing.
Third, go the creative way. Rather than generating yet another scantily-clad classically-attractive woman (boooring!), think about things that wouldn’t be created otherwise. <a href="https://p.migdal.pl/blog/2022/07/dall-e-2-and-transcendence/" target="_blank" rel="nofollow noopener noreferrer">I went with esoteric images</a>. What’s your call?</p>
<p>One thing remains the same - computers don’t do what we wish them to do, they do what we tell them to do. <a href="https://explosm.net/comics/kris-beaker" target="_blank" rel="nofollow noopener noreferrer">A genie, not a genius</a>.</p>
<h2 id="appendix"><a href="#appendix" aria-hidden="true"><span></span></a>Appendix</h2>
<p>I would like to thank <a href="https://jankiewiczstudio.com/" target="_blank" rel="nofollow noopener noreferrer">Klem Jankiewicz</a>, Maja Ratyńska and <a href="https://www.linkedin.com/in/greg-kowal" target="_blank" rel="nofollow noopener noreferrer">Greg Kowal</a> for their fruitful remarks on the draft. I wouldn&#39;t write this blog post if it weren&#39;t for <a href="https://piotrzientara.pl/" target="_blank" rel="nofollow noopener noreferrer">Piotr Zientara</a>, who invited me to give a talk at the <a href="https://warsawjs.com/meetups/100" target="_blank" rel="nofollow noopener noreferrer">100th WarsawJS Meetup</a>. You can watch it here: <a href="https://www.youtube.com/watch?v=oEHYzEBv6yg" target="_blank" rel="nofollow noopener noreferrer">ChatGPT and Image Diffusion - should I be afraid or harness its power?</a>. Yes, “Image Diffusion”. I am just a human and I make silly mistakes.</p>
<figure><img src="data:image/svg+xml,%3csvg fill=&#39;none&#39; viewBox=&#39;0 0 1200 671&#39; xmlns=&#39;http://www.w3.org/2000/svg&#39; xmlns:xlink=&#39;http://www.w3.org/1999/xlink&#39;%3e%3cdefs%3e%3cfilter id=&#39;__svg-blur-852bb484dda0b5bf505ad0ad32f0d928&#39;%3e%3cfeGaussianBlur in=&#39;SourceGraphic&#39; stdDeviation=&#39;40&#39;/%3e%3c/filter%3e%3c/defs%3e%3cimage x=&#39;0&#39; y=&#39;0&#39; filter=&#39;url(%23__svg-blur-852bb484dda0b5bf505ad0ad32f0d928)&#39; width=&#39;1200&#39; height=&#39;671&#39; xlink:href=&#39;data:image/jpeg%3bbase64%2c/9j/2wBDAAYEBQYFBAYGBQYHBwYIChAKCgkJChQODwwQFxQYGBcUFhYaHSUfGhsjHBYWICwgIyYnKSopGR8tMC0oMCUoKSj/2wBDAQcHBwoIChMKChMoGhYaKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCgoKCj/wAARCAAkAEADASIAAhEBAxEB/8QAGwAAAgMBAQEAAAAAAAAAAAAAAAYEBQgDBwH/xAA0EAABAwIEBAQFAQkAAAAAAAABAgMEBREABhIhBxMxQSJRYYEUMkKRoSMVJDRicXKCsdH/xAAaAQADAAMBAAAAAAAAAAAAAAAAAgUBAwYE/8QAJhEAAQQABAUFAAAAAAAAAAAAAQACAxEEBRMhBiNBUaEiMWFxgf/aAAwDAQACEQMRAD8Ay%2bzLkMK1MvuIPmlRGLONmmsxlBbU90LHRd/EP8uuKdDa3FJS2lSyo2ASLknyx6plvhUX6azOq8htplwfqBSy2Wx/Lt4z%2bMappmRD1lM1hcdk85Akza5lqiyajMXKVMlORpRfHMLibKsNRNx8tvfF7w1chU6dS10iLym5FYEd5tp4qSlevwqIVfYo6977YRqI8uhNph5RqDFSgsvl0Nzmj4XRsShaDce98OXD52oT8yUhMrLsdllmaxu3OskabhK9JFyRqPe/TyxGGXY8S68QOmTYo1tZuxY6Hx2Wx2Lww5T3AOHf89l5xnGgfH8asyTp7jDNLZrbpc5qvE8Er1KQhPVRsN%2bwwwV6tRgl53K%2bU4CNabGRJZbu53vot4vcgemKjjNVhG4vZiYdZSGQ8oMltwWBJJUb%2bZUVXHtjpAzHAchoBbWXkotdKgASPS5x0jAKXhkJtc8ivyH6iZ6Jrkqsym32pIfZu0U6QUDfY/JtYC2w9MJvFGixKdUYs%2bl3MGoJWsG9wHUqs4nptZXmSdxi1y5WDEzc6tD0JAKrlh9CwlXfZQub%2btvbEriC41Ky1OjtMobEKaiSkJVq081Nli9h9RHYYyW2ENcQ4fKsqJEyvT5hQzGktvLdQtrUpJWkJbOpOo%2barm1uwwZ%2brr86lCn0hL0hxY0OvqUlISB1Cd7qJ6X227XxpzMVFaq1LkR5kVxxJQbaUnVe21j54W8r5SeiNGLV4seahKUrCnYSVHcWKdRF9rDHFszeN51JIzY6Xd%2bPCqiItbTXLP3ClUmi/EMzIikod8bbikX5auht232%2b2PZsvyqYzmGjuqlOyJL01lCU%2bpULbDphzcybQnPmoMUf2saf9WxIpWUqPFq0KS3TlNONPIUhWpywN9u9sV8NxOw8vTdv9KfPlgkcJCRYWOeM77qOK%2bb0IcUE/tR82vt8%2bFqm1dcYBp1AU0TutA0uj%2bivzY4dOMeX6xI4qZseYpNQdaXUn1JWiMtSVDUdwQN8KcXKOYZLyW2qJUyo9zFcAHqSRismoKxRCn/Eoe%2bMC1qbS6ypWynEKGx%2b19uxBGJMNmZU6VXYrGpxwR/iXL9NLagpRJ87D3O2HSVkOrvZKyu1TafKcn8%2bRH5nIUmyg4oqCiRdKAmyge4J77Yrq1Q63RaU9QaNSalMmzCFzZDMNw6kI3CBtsm%2b9vTfDMJBNpHgEABbxlxUSUgLW8i17FpxSD%2bDiOqltm37xNFulpK/%2b4MGFWxfTTGza8iZsCP4hff3xJjMJjt6EKcUL3u4srP3ODBgQqfNtVfpEJp6KltSluaDzASLaSexHlhXdrMp2oxkFS0iSprXofdTbUATYa7DrgwYELi3Xpa4LyyTdDbih%2bs79KkgfX64ZMmVyVWVShLS0kMhOnlgi979bk%2bWDBgQv//Z&#39; /%3e%3c/svg%3e" width="1200" alt="[A lizard works as a taxi driver](https://labs.openai.com/s/BjMtgzd4zlrreWQnEHn1cbDn) and [a velociraptor as a CEO](https://www.reddit.com/r/dalle2/comments/v411w9/velociraptor_in_a_suit_studio_portrait_dark_bg/) (Critter-Eating Officer). Generated by DALL·E 2, prompts are mine." data-srcset="/assets/static/lizard-taxi-velociraptor-ceo.82a2fbd.b649187b6ca2356d8547251a0e09304d.jpg 480w, /assets/static/lizard-taxi-velociraptor-ceo.75e41ba.b649187b6ca2356d8547251a0e09304d.jpg 1200w" data-sizes="(max-width: 1200px) 100vw, 1200px" data-src="/assets/static/lizard-taxi-velociraptor-ceo.75e41ba.b649187b6ca2356d8547251a0e09304d.jpg"/><figcaption><a href="https://labs.openai.com/s/BjMtgzd4zlrreWQnEHn1cbDn">A lizard works as a taxi driver</a> and <a href="https://www.reddit.com/r/dalle2/comments/v411w9/velociraptor_in_a_suit_studio_portrait_dark_bg/">a velociraptor as a CEO</a> (Critter-Eating Officer). Generated by DALL·E 2, prompts are mine.</figcaption></figure>
<p>UPDATE: I just joined <a href="https://dali.games/" target="_blank" rel="nofollow noopener noreferrer">Dali Games</a> as the AI Lead. We are on our mission to deliver games purely generated by AI. You give a prompt, we deliver a complete mobile game.</p>
</div></div>
  </body>
</html>
