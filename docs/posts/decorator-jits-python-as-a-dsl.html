<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://eli.thegreenplace.net/2025/decorator-jits-python-as-a-dsl/">Original</a>
    <h1>Decorator JITs: Python as a DSL</h1>
    
    <div id="readability-page-1" class="page"><div>
    <div>
    <section id="content">
        <article>
            
            <div>
                
                <p>Spend enough time looking at Python programs and packages for machine learning,
and you&#39;ll notice that the &#34;JIT decorator&#34; pattern is pretty popular. For
example, this JAX snippet:</p>
<div><pre><span></span><span>import</span> <span>jax.numpy</span> <span>as</span> <span>jnp</span>
<span>import</span> <span>jax</span>

<span>@jax</span><span>.</span><span>jit</span>
<span>def</span> <span>add</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>):</span>
  <span>return</span> <span>jnp</span><span>.</span><span>add</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>)</span>

<span># Use &#34;add&#34; as a regular Python function</span>
<span>...</span> <span>=</span> <span>add</span><span>(</span><span>...</span><span>)</span>
</pre></div>
<p>Or the <a href="https://triton-lang.org/main/index.html">Triton language</a>
for writing GPU kernels directly in Python:</p>
<div><pre><span></span><span>import</span> <span>triton</span>
<span>import</span> <span>triton.language</span> <span>as</span> <span>tl</span>

<span>@triton</span><span>.</span><span>jit</span>
<span>def</span> <span>add_kernel</span><span>(</span><span>x_ptr</span><span>,</span>
               <span>y_ptr</span><span>,</span>
               <span>output_ptr</span><span>,</span>
               <span>n_elements</span><span>,</span>
               <span>BLOCK_SIZE</span><span>:</span> <span>tl</span><span>.</span><span>constexpr</span><span>):</span>
    <span>pid</span> <span>=</span> <span>tl</span><span>.</span><span>program_id</span><span>(</span><span>axis</span><span>=</span><span>0</span><span>)</span>
    <span>block_start</span> <span>=</span> <span>pid</span> <span>*</span> <span>BLOCK_SIZE</span>
    <span>offsets</span> <span>=</span> <span>block_start</span> <span>+</span> <span>tl</span><span>.</span><span>arange</span><span>(</span><span>0</span><span>,</span> <span>BLOCK_SIZE</span><span>)</span>
    <span>mask</span> <span>=</span> <span>offsets</span> <span>&lt;</span> <span>n_elements</span>
    <span>x</span> <span>=</span> <span>tl</span><span>.</span><span>load</span><span>(</span><span>x_ptr</span> <span>+</span> <span>offsets</span><span>,</span> <span>mask</span><span>=</span><span>mask</span><span>)</span>
    <span>y</span> <span>=</span> <span>tl</span><span>.</span><span>load</span><span>(</span><span>y_ptr</span> <span>+</span> <span>offsets</span><span>,</span> <span>mask</span><span>=</span><span>mask</span><span>)</span>
    <span>output</span> <span>=</span> <span>x</span> <span>+</span> <span>y</span>
    <span>tl</span><span>.</span><span>store</span><span>(</span><span>output_ptr</span> <span>+</span> <span>offsets</span><span>,</span> <span>output</span><span>,</span> <span>mask</span><span>=</span><span>mask</span><span>)</span>
</pre></div>
<p>In both cases, the function decorated with <tt>jit</tt> doesn&#39;t get executed by the
Python interpreter in the normal sense. Instead, the code inside is more like
a DSL (Domain Specific Language) processed by a special purpose compiler built
into the library (JAX or Triton). Another way to think about it is that Python
is used as a <em>meta language</em> to describe computations.</p>
<p>In this post I will describe some implementation strategies used by libraries to
make this possible.</p>
<div id="preface-where-we-re-going">
<h2>Preface - where we&#39;re going</h2>
<p>The goal is to explain how different kinds of <tt>jit</tt> decorators work by using
a simplified, educational example that implements several approaches from
scratch. All the approaches featured in this post will be using this flow:</p>
<p><img alt="Flow of Python source --&gt; Expr IR --&gt; LLVM IR --&gt; Execution" src="https://eli.thegreenplace.net/images/2025/decjit-python.png"/></p><p>These are the steps that happen when a Python function wrapped with
our educational <tt>jit</tt> decorator is called:</p>
<ol>
<li>The function is translated to an &#34;expression IR&#34; - <tt>Expr</tt>.</li>
<li>This expression IR is converted to LLVM IR.</li>
<li>Finally, the LLVM IR is JIT-executed.</li>
</ol>
<p>Steps (2) and (3) use <a href="https://github.com/numba/llvmlite">llvmlite</a>; I&#39;ve
written about llvmlite before, see <a href="https://eli.thegreenplace.net/2015/building-and-using-llvmlite-a-basic-example/">this post</a>
and also the <a href="https://github.com/eliben/pykaleidoscope">pykaleidoscope project</a>.
For an introduction to JIT compilation, be sure to <a href="https://eli.thegreenplace.net/2013/11/05/how-to-jit-an-introduction">read this</a>
and maybe also the series of posts <a href="https://eli.thegreenplace.net/2017/adventures-in-jit-compilation-part-1-an-interpreter/">starting here</a>.</p>
<p>First, let&#39;s look at the <tt>Expr</tt> IR. Here we&#39;ll make a big simplification -
only supporting functions that define a single expression, e.g.:</p>
<div><pre><span></span><span>def</span> <span>expr2</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>,</span> <span>c</span><span>,</span> <span>d</span><span>):</span>
    <span>return</span> <span>(</span><span>a</span> <span>+</span> <span>d</span><span>)</span> <span>*</span> <span>(</span><span>10</span> <span>-</span> <span>c</span><span>)</span> <span>+</span> <span>b</span> <span>+</span> <span>d</span> <span>/</span> <span>c</span>
</pre></div>
<p>Naturally, this can be easily generalized - after all, LLVM IR can be used to
express fully general computations.</p>
<p>Here are the <tt>Expr</tt> data structures:</p>
<div><pre><span></span><span>class</span> <span>Expr</span><span>:</span>
    <span>pass</span>

<span>@dataclass</span>
<span>class</span> <span>ConstantExpr</span><span>(</span><span>Expr</span><span>):</span>
    <span>value</span><span>:</span> <span>float</span>

<span>@dataclass</span>
<span>class</span> <span>VarExpr</span><span>(</span><span>Expr</span><span>):</span>
    <span>name</span><span>:</span> <span>str</span>
    <span>arg_idx</span><span>:</span> <span>int</span>

<span>class</span> <span>Op</span><span>(</span><span>Enum</span><span>):</span>
    <span>ADD</span> <span>=</span> <span>&#34;+&#34;</span>
    <span>SUB</span> <span>=</span> <span>&#34;-&#34;</span>
    <span>MUL</span> <span>=</span> <span>&#34;*&#34;</span>
    <span>DIV</span> <span>=</span> <span>&#34;/&#34;</span>

<span>@dataclass</span>
<span>class</span> <span>BinOpExpr</span><span>(</span><span>Expr</span><span>):</span>
    <span>left</span><span>:</span> <span>Expr</span>
    <span>right</span><span>:</span> <span>Expr</span>
    <span>op</span><span>:</span> <span>Op</span>
</pre></div>
<p>To convert an <tt>Expr</tt> into LLVM IR and JIT-execute it, we&#39;ll use this function:</p>
<div><pre><span></span><span>def</span> <span>llvm_jit_evaluate</span><span>(</span><span>expr</span><span>:</span> <span>Expr</span><span>,</span> <span>*</span><span>args</span><span>:</span> <span>float</span><span>)</span> <span>-&gt;</span> <span>float</span><span>:</span>
    <span>&#34;&#34;&#34;Use LLVM JIT to evaluate the given expression with *args.</span>

<span>    expr is an instance of Expr. *args are the arguments to the expression, each</span>
<span>    a float. The arguments must match the arguments the expression expects.</span>

<span>    Returns the result of evaluating the expression.</span>
<span>    &#34;&#34;&#34;</span>
    <span>llvm</span><span>.</span><span>initialize</span><span>()</span>
    <span>llvm</span><span>.</span><span>initialize_native_target</span><span>()</span>
    <span>llvm</span><span>.</span><span>initialize_native_asmprinter</span><span>()</span>
    <span>llvm</span><span>.</span><span>initialize_native_asmparser</span><span>()</span>

    <span>cg</span> <span>=</span> <span>_LLVMCodeGenerator</span><span>()</span>
    <span>modref</span> <span>=</span> <span>llvm</span><span>.</span><span>parse_assembly</span><span>(</span><span>str</span><span>(</span><span>cg</span><span>.</span><span>codegen</span><span>(</span><span>expr</span><span>,</span> <span>len</span><span>(</span><span>args</span><span>))))</span>

    <span>target</span> <span>=</span> <span>llvm</span><span>.</span><span>Target</span><span>.</span><span>from_default_triple</span><span>()</span>
    <span>target_machine</span> <span>=</span> <span>target</span><span>.</span><span>create_target_machine</span><span>()</span>
    <span>with</span> <span>llvm</span><span>.</span><span>create_mcjit_compiler</span><span>(</span><span>modref</span><span>,</span> <span>target_machine</span><span>)</span> <span>as</span> <span>ee</span><span>:</span>
        <span>ee</span><span>.</span><span>finalize_object</span><span>()</span>
        <span>cfptr</span> <span>=</span> <span>ee</span><span>.</span><span>get_function_address</span><span>(</span><span>&#34;func&#34;</span><span>)</span>
        <span>cfunc</span> <span>=</span> <span>CFUNCTYPE</span><span>(</span><span>c_double</span><span>,</span> <span>*</span><span>([</span><span>c_double</span><span>]</span> <span>*</span> <span>len</span><span>(</span><span>args</span><span>)))(</span><span>cfptr</span><span>)</span>
        <span>return</span> <span>cfunc</span><span>(</span><span>*</span><span>args</span><span>)</span>
</pre></div>
<p>It uses the <tt>_LLVMCodeGenerator</tt> class to actually generate LLVM IR from <tt>Expr</tt>.
This process is straightforward and covered extensively in the resources I
linked to earlier; take a look at <a href="https://github.com/eliben/code-for-blog/blob/main/2025/decjit/exprcode.py">the full code here</a>.</p>
<p>My goal with this architecture is to make things simple, but <em>not too simple</em>.
On one hand - there are several simplifications: only single expressions are
supported, very limited set of operators, etc. It&#39;s very easy to extend this!
On the other hand, we could have just trivially evaluated the <tt>Expr</tt>
without resorting to LLVM IR; I do want to show a more complete compilation
pipeline, though, to demonstrate that an arbitrary amount of complexity can
be hidden behind these simple interfaces.</p>
<p>With these building blocks in hand, we can review the strategies used by
<tt>jit</tt> decorators to convert Python functions into <tt>Expr</tt>s.</p>
</div>
<div id="ast-based-jit">
<h2>AST-based JIT</h2>
<p>Python comes with powerful code reflection and introspection capabilities out
of the box. Here&#39;s the <tt>astjit</tt> decorator:</p>
<div><pre><span></span><span>def</span> <span>astjit</span><span>(</span><span>func</span><span>):</span>
    <span>@functools</span><span>.</span><span>wraps</span><span>(</span><span>func</span><span>)</span>
    <span>def</span> <span>wrapper</span><span>(</span><span>*</span><span>args</span><span>,</span> <span>**</span><span>kwargs</span><span>):</span>
        <span>if</span> <span>kwargs</span><span>:</span>
            <span>raise</span> <span>ASTJITError</span><span>(</span><span>&#34;Keyword arguments are not supported&#34;</span><span>)</span>
        <span>source</span> <span>=</span> <span>inspect</span><span>.</span><span>getsource</span><span>(</span><span>func</span><span>)</span>
        <span>tree</span> <span>=</span> <span>ast</span><span>.</span><span>parse</span><span>(</span><span>source</span><span>)</span>

        <span>emitter</span> <span>=</span> <span>_ExprCodeEmitter</span><span>()</span>
        <span>emitter</span><span>.</span><span>visit</span><span>(</span><span>tree</span><span>)</span>
        <span>return</span> <span>llvm_jit_evaluate</span><span>(</span><span>emitter</span><span>.</span><span>return_expr</span><span>,</span> <span>*</span><span>args</span><span>)</span>

    <span>return</span> <span>wrapper</span>
</pre></div>
<p>This is a standard Python decorator. It takes a function and returns another
function that will be used in its place (<tt>functools.wraps</tt> ensures that
function attributes like the name and docstring of the wrapper match the
wrapped function).</p>
<p>Here&#39;s how it&#39;s used:</p>
<div><pre><span></span><span>from</span> <span>astjit</span> <span>import</span> <span>astjit</span>

<span>@astjit</span>
<span>def</span> <span>some_expr</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>,</span> <span>c</span><span>):</span>
    <span>return</span> <span>b</span> <span>/</span> <span>(</span><span>a</span> <span>+</span> <span>2</span><span>)</span> <span>-</span> <span>c</span> <span>*</span> <span>(</span><span>b</span> <span>-</span> <span>a</span><span>)</span>

<span>print</span><span>(</span><span>some_expr</span><span>(</span><span>2</span><span>,</span> <span>16</span><span>,</span> <span>3</span><span>))</span>
</pre></div>
<p>After <tt>astjit</tt> is applied to <tt>some_expr</tt>, what <tt>some_expr</tt> holds is the
wrapper. When <tt>some_expr(2, 16, 3)</tt> is called, the wrapper is invoked with
<tt>*args = [2, 16, 3]</tt>.</p>
<p>The wrapper obtains the AST of the wrapped function, and then uses
<tt>_ExprCodeEmitter</tt> to convert this AST into an <tt>Expr</tt>:</p>
<div><pre><span></span><span>class</span> <span>_ExprCodeEmitter</span><span>(</span><span>ast</span><span>.</span><span>NodeVisitor</span><span>):</span>
    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>):</span>
        <span>self</span><span>.</span><span>args</span> <span>=</span> <span>[]</span>
        <span>self</span><span>.</span><span>return_expr</span> <span>=</span> <span>None</span>
        <span>self</span><span>.</span><span>op_map</span> <span>=</span> <span>{</span>
            <span>ast</span><span>.</span><span>Add</span><span>:</span> <span>Op</span><span>.</span><span>ADD</span><span>,</span>
            <span>ast</span><span>.</span><span>Sub</span><span>:</span> <span>Op</span><span>.</span><span>SUB</span><span>,</span>
            <span>ast</span><span>.</span><span>Mult</span><span>:</span> <span>Op</span><span>.</span><span>MUL</span><span>,</span>
            <span>ast</span><span>.</span><span>Div</span><span>:</span> <span>Op</span><span>.</span><span>DIV</span><span>,</span>
        <span>}</span>

    <span>def</span> <span>visit_FunctionDef</span><span>(</span><span>self</span><span>,</span> <span>node</span><span>):</span>
        <span>self</span><span>.</span><span>args</span> <span>=</span> <span>[</span><span>arg</span><span>.</span><span>arg</span> <span>for</span> <span>arg</span> <span>in</span> <span>node</span><span>.</span><span>args</span><span>.</span><span>args</span><span>]</span>
        <span>if</span> <span>len</span><span>(</span><span>node</span><span>.</span><span>body</span><span>)</span> <span>!=</span> <span>1</span> <span>or</span> <span>not</span> <span>isinstance</span><span>(</span><span>node</span><span>.</span><span>body</span><span>[</span><span>0</span><span>],</span> <span>ast</span><span>.</span><span>Return</span><span>):</span>
            <span>raise</span> <span>ASTJITError</span><span>(</span><span>&#34;Function must consist of a single return statement&#34;</span><span>)</span>
        <span>self</span><span>.</span><span>visit</span><span>(</span><span>node</span><span>.</span><span>body</span><span>[</span><span>0</span><span>])</span>

    <span>def</span> <span>visit_Return</span><span>(</span><span>self</span><span>,</span> <span>node</span><span>):</span>
        <span>self</span><span>.</span><span>return_expr</span> <span>=</span> <span>self</span><span>.</span><span>visit</span><span>(</span><span>node</span><span>.</span><span>value</span><span>)</span>

    <span>def</span> <span>visit_Name</span><span>(</span><span>self</span><span>,</span> <span>node</span><span>):</span>
        <span>try</span><span>:</span>
            <span>idx</span> <span>=</span> <span>self</span><span>.</span><span>args</span><span>.</span><span>index</span><span>(</span><span>node</span><span>.</span><span>id</span><span>)</span>
        <span>except</span> <span>ValueError</span><span>:</span>
            <span>raise</span> <span>ASTJITError</span><span>(</span><span>f</span><span>&#34;Unknown variable </span><span>{</span><span>node</span><span>.</span><span>id</span><span>}</span><span>&#34;</span><span>)</span>
        <span>return</span> <span>VarExpr</span><span>(</span><span>node</span><span>.</span><span>id</span><span>,</span> <span>idx</span><span>)</span>

    <span>def</span> <span>visit_Constant</span><span>(</span><span>self</span><span>,</span> <span>node</span><span>):</span>
        <span>return</span> <span>ConstantExpr</span><span>(</span><span>node</span><span>.</span><span>value</span><span>)</span>

    <span>def</span> <span>visit_BinOp</span><span>(</span><span>self</span><span>,</span> <span>node</span><span>):</span>
        <span>left</span> <span>=</span> <span>self</span><span>.</span><span>visit</span><span>(</span><span>node</span><span>.</span><span>left</span><span>)</span>
        <span>right</span> <span>=</span> <span>self</span><span>.</span><span>visit</span><span>(</span><span>node</span><span>.</span><span>right</span><span>)</span>
        <span>try</span><span>:</span>
            <span>op</span> <span>=</span> <span>self</span><span>.</span><span>op_map</span><span>[</span><span>type</span><span>(</span><span>node</span><span>.</span><span>op</span><span>)]</span>
            <span>return</span> <span>BinOpExpr</span><span>(</span><span>left</span><span>,</span> <span>right</span><span>,</span> <span>op</span><span>)</span>
        <span>except</span> <span>KeyError</span><span>:</span>
            <span>raise</span> <span>ASTJITError</span><span>(</span><span>f</span><span>&#34;Unsupported operator </span><span>{</span><span>node</span><span>.</span><span>op</span><span>}</span><span>&#34;</span><span>)</span>
</pre></div>
<p>When <tt>_ExprCodeEmitter</tt> finishes visiting the AST it&#39;s given, its
<tt>return_expr</tt> field will contain the <tt>Expr</tt> representing the function&#39;s
return value. The wrapper then invokes <tt>llvm_jit_evaluate</tt> with this <tt>Expr</tt>.</p>
<p>Note how our decorator interjects into the regular Python execution process.
When <tt>some_expr</tt> is called, instead of the standard Python compilation and
execution process (code is compiled into bytecode, which is then executed
by the VM), we translate its code to our own representation and emit LLVM from
it, and then JIT execute the LLVM IR. While it seems kinda pointless in this
artificial example, in reality this means we can execute the function&#39;s code
in any way we like.</p>
<div id="ast-jit-case-study-triton">
<h3>AST JIT case study: Triton</h3>
<p>This approach is almost exactly how the Triton language works. The body of a
function decorated with <tt>@triton.jit</tt> gets parsed to a Python AST, which then
- through a series of internal IRs - ends up in LLVM IR; this in turn is lowered
to <a href="https://docs.nvidia.com/cuda/parallel-thread-execution/">PTX</a> by the
<a href="https://llvm.org/docs/NVPTXUsage.html">NVPTX LLVM backend</a>.
Then, the code runs on a GPU using a standard CUDA pipeline.</p>
<p>Naturally, the subset of Python that can be compiled down to a GPU is limited;
but it&#39;s sufficient to run performant kernels, in a language that&#39;s much
friendlier than CUDA and - more importantly - lives in the same file with the
&#34;host&#34; part written in regular Python. For example, if you want testing and
debugging, you can run Triton in &#34;interpreter mode&#34; which will just run the
same kernels locally on a CPU.</p>
<p>Note that Triton lets us import names from the <tt>triton.language</tt> package
and use them inside kernels; these serve as the <em>intrinsics</em> for the language
- special calls the compiler handles directly.</p>
</div>
</div>
<div id="bytecode-based-jit">
<h2>Bytecode-based JIT</h2>
<p>Python is a fairly complicated language with <em>a lot</em> of features. Therefore,
if our JIT has to support some large portion of Python semantics, it may make
sense to leverage more of Python&#39;s own compiler. Concretely, we can have it
compile the wrapped function all the way <a href="https://github.com/python/cpython/blob/main/InternalDocs/interpreter.md">to bytecode</a>,
and start our translation from there.</p>
<p>Here&#39;s the <tt>bytecodejit</tt> decorator that does just this <a href="#footnote-1" id="footnote-reference-1">[1]</a>:</p>
<div><pre><span></span><span>def</span> <span>bytecodejit</span><span>(</span><span>func</span><span>):</span>
    <span>@functools</span><span>.</span><span>wraps</span><span>(</span><span>func</span><span>)</span>
    <span>def</span> <span>wrapper</span><span>(</span><span>*</span><span>args</span><span>,</span> <span>**</span><span>kwargs</span><span>):</span>
        <span>if</span> <span>kwargs</span><span>:</span>
            <span>raise</span> <span>BytecodeJITError</span><span>(</span><span>&#34;Keyword arguments are not supported&#34;</span><span>)</span>

        <span>expr</span> <span>=</span> <span>_emit_exprcode</span><span>(</span><span>func</span><span>)</span>
        <span>return</span> <span>llvm_jit_evaluate</span><span>(</span><span>expr</span><span>,</span> <span>*</span><span>args</span><span>)</span>

    <span>return</span> <span>wrapper</span>


<span>def</span> <span>_emit_exprcode</span><span>(</span><span>func</span><span>):</span>
    <span>bc</span> <span>=</span> <span>func</span><span>.</span><span>__code__</span>
    <span>stack</span> <span>=</span> <span>[]</span>
    <span>for</span> <span>inst</span> <span>in</span> <span>dis</span><span>.</span><span>get_instructions</span><span>(</span><span>func</span><span>):</span>
        <span>match</span> <span>inst</span><span>.</span><span>opname</span><span>:</span>
            <span>case</span> <span>&#34;LOAD_FAST&#34;</span><span>:</span>
                <span>idx</span> <span>=</span> <span>inst</span><span>.</span><span>arg</span>
                <span>stack</span><span>.</span><span>append</span><span>(</span><span>VarExpr</span><span>(</span><span>bc</span><span>.</span><span>co_varnames</span><span>[</span><span>idx</span><span>],</span> <span>idx</span><span>))</span>
            <span>case</span> <span>&#34;LOAD_CONST&#34;</span><span>:</span>
                <span>stack</span><span>.</span><span>append</span><span>(</span><span>ConstantExpr</span><span>(</span><span>inst</span><span>.</span><span>argval</span><span>))</span>
            <span>case</span> <span>&#34;BINARY_OP&#34;</span><span>:</span>
                <span>right</span> <span>=</span> <span>stack</span><span>.</span><span>pop</span><span>()</span>
                <span>left</span> <span>=</span> <span>stack</span><span>.</span><span>pop</span><span>()</span>
                <span>match</span> <span>inst</span><span>.</span><span>argrepr</span><span>:</span>
                    <span>case</span> <span>&#34;+&#34;</span><span>:</span>
                        <span>stack</span><span>.</span><span>append</span><span>(</span><span>BinOpExpr</span><span>(</span><span>left</span><span>,</span> <span>right</span><span>,</span> <span>Op</span><span>.</span><span>ADD</span><span>))</span>
                    <span>case</span> <span>&#34;-&#34;</span><span>:</span>
                        <span>stack</span><span>.</span><span>append</span><span>(</span><span>BinOpExpr</span><span>(</span><span>left</span><span>,</span> <span>right</span><span>,</span> <span>Op</span><span>.</span><span>SUB</span><span>))</span>
                    <span>case</span> <span>&#34;*&#34;</span><span>:</span>
                        <span>stack</span><span>.</span><span>append</span><span>(</span><span>BinOpExpr</span><span>(</span><span>left</span><span>,</span> <span>right</span><span>,</span> <span>Op</span><span>.</span><span>MUL</span><span>))</span>
                    <span>case</span> <span>&#34;/&#34;</span><span>:</span>
                        <span>stack</span><span>.</span><span>append</span><span>(</span><span>BinOpExpr</span><span>(</span><span>left</span><span>,</span> <span>right</span><span>,</span> <span>Op</span><span>.</span><span>DIV</span><span>))</span>
                    <span>case</span> <span>_</span><span>:</span>
                        <span>raise</span> <span>BytecodeJITError</span><span>(</span><span>f</span><span>&#34;Unsupported operator </span><span>{</span><span>inst</span><span>.</span><span>argval</span><span>}</span><span>&#34;</span><span>)</span>
            <span>case</span> <span>&#34;RETURN_VALUE&#34;</span><span>:</span>
                <span>if</span> <span>len</span><span>(</span><span>stack</span><span>)</span> <span>!=</span> <span>1</span><span>:</span>
                    <span>raise</span> <span>BytecodeJITError</span><span>(</span><span>&#34;Invalid stack state&#34;</span><span>)</span>
                <span>return</span> <span>stack</span><span>.</span><span>pop</span><span>()</span>
            <span>case</span> <span>&#34;RESUME&#34;</span> <span>|</span> <span>&#34;CACHE&#34;</span><span>:</span>
                <span># Skip nops</span>
                <span>pass</span>
            <span>case</span> <span>_</span><span>:</span>
                <span>raise</span> <span>BytecodeJITError</span><span>(</span><span>f</span><span>&#34;Unsupported opcode </span><span>{</span><span>inst</span><span>.</span><span>opname</span><span>}</span><span>&#34;</span><span>)</span>
</pre></div>
<p>The Python VM is a stack machine; so we emulate a stack to convert the
function&#39;s bytecode to <tt>Expr</tt> IR (a bit like an <a href="https://en.wikipedia.org/wiki/Reverse_Polish_notation">RPN evaluator</a>).
As before, we then use our <tt>llvm_jit_evaluate</tt> utility function to lower
<tt>Expr</tt> to LLVM IR and JIT execute it.</p>
<p>Using this JIT is as simple as the previous one - just swap <tt>astjit</tt>
for <tt>bytecodejit</tt>:</p>
<div><pre><span></span><span>from</span> <span>bytecodejit</span> <span>import</span> <span>bytecodejit</span>

<span>@bytecodejit</span>
<span>def</span> <span>some_expr</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>,</span> <span>c</span><span>):</span>
    <span>return</span> <span>b</span> <span>/</span> <span>(</span><span>a</span> <span>+</span> <span>2</span><span>)</span> <span>-</span> <span>c</span> <span>*</span> <span>(</span><span>b</span> <span>-</span> <span>a</span><span>)</span>

<span>print</span><span>(</span><span>some_expr</span><span>(</span><span>2</span><span>,</span> <span>16</span><span>,</span> <span>3</span><span>))</span>
</pre></div>
<div id="bytecode-jit-case-study-numba">
<h3>Bytecode JIT case study: Numba</h3>
<p><a href="https://numba.pydata.org/">Numba</a> is a compiler for Python itself. The idea
is that you can speed up specific functions in your code by slapping a
<tt>numba.njit</tt> decorator on them. What happens next is similar in spirit to
our simple <tt>bytecodejit</tt>, but of course much more complicated because it
supports a very large portion of Python semantics.</p>
<p>Numba uses the Python compiler to emit bytecode, just as we did; it then
converts it into its own IR, and then to LLVM using <tt>llvmlite</tt> <a href="#footnote-2" id="footnote-reference-2">[2]</a>.</p>
<p>By starting with the bytecode, Numba makes its life easier (no need to rewrite
the entire Python compiler). On the other hand, it also makes some analyses
<em>harder</em>, because by the time we&#39;re in bytecode, a lot of semantic information
existing in higher-level representations is lost. For example, Numba has to
sweat a bit to recover control flow information from the bytecode (by
running it through a special interpreter first).</p>
</div>
</div>
<div id="tracing-based-jit">
<h2>Tracing-based JIT</h2>
<p>The two approaches we&#39;ve seen so far are similar in many ways - both rely on
Python&#39;s introspection capabilities to compile the source code of the JIT-ed
function to some extent (one to AST, the other all the way to bytecode), and
then work on this lowered representation.</p>
<p>The tracing strategy is very different. It doesn&#39;t analyze the source code of
the wrapped function at all - instead, it <em>traces</em> its execution by means of
specially-boxed arguments, leveraging overloaded operators and functions, and
then works on the generated trace.</p>
<p>The code implementing this for our smile demo is surprisingly compact:</p>
<div><pre><span></span><span>def</span> <span>tracejit</span><span>(</span><span>func</span><span>):</span>
    <span>@functools</span><span>.</span><span>wraps</span><span>(</span><span>func</span><span>)</span>
    <span>def</span> <span>wrapper</span><span>(</span><span>*</span><span>args</span><span>,</span> <span>**</span><span>kwargs</span><span>):</span>
        <span>if</span> <span>kwargs</span><span>:</span>
            <span>raise</span> <span>TraceJITError</span><span>(</span><span>&#34;Keyword arguments are not supported&#34;</span><span>)</span>

        <span>argspec</span> <span>=</span> <span>inspect</span><span>.</span><span>getfullargspec</span><span>(</span><span>func</span><span>)</span>

        <span>argboxes</span> <span>=</span> <span>[]</span>
        <span>for</span> <span>i</span><span>,</span> <span>arg</span> <span>in</span> <span>enumerate</span><span>(</span><span>args</span><span>):</span>
            <span>if</span> <span>i</span> <span>&gt;=</span> <span>len</span><span>(</span><span>argspec</span><span>.</span><span>args</span><span>):</span>
                <span>raise</span> <span>TraceJITError</span><span>(</span><span>&#34;Too many arguments&#34;</span><span>)</span>
            <span>argboxes</span><span>.</span><span>append</span><span>(</span><span>_Box</span><span>(</span><span>VarExpr</span><span>(</span><span>argspec</span><span>.</span><span>args</span><span>[</span><span>i</span><span>],</span> <span>i</span><span>)))</span>

        <span>out_box</span> <span>=</span> <span>func</span><span>(</span><span>*</span><span>argboxes</span><span>)</span>
        <span>return</span> <span>llvm_jit_evaluate</span><span>(</span><span>out_box</span><span>.</span><span>expr</span><span>,</span> <span>*</span><span>args</span><span>)</span>

    <span>return</span> <span>wrapper</span>
</pre></div>
<p>Each runtime argument of the wrapped function is assigned a <tt>VarExpr</tt>, and
that is placed in a <tt>_Box</tt>, a placeholder class which lets us
do operator overloading:</p>
<div><pre><span></span><span>@dataclass</span>
<span>class</span> <span>_Box</span><span>:</span>
    <span>expr</span><span>:</span> <span>Expr</span>

<span>_Box</span><span>.</span><span>__add__</span> <span>=</span> <span>_Box</span><span>.</span><span>__radd__</span> <span>=</span> <span>_register_binary_op</span><span>(</span><span>Op</span><span>.</span><span>ADD</span><span>)</span>
<span>_Box</span><span>.</span><span>__sub__</span> <span>=</span> <span>_register_binary_op</span><span>(</span><span>Op</span><span>.</span><span>SUB</span><span>)</span>
<span>_Box</span><span>.</span><span>__rsub__</span> <span>=</span> <span>_register_binary_op</span><span>(</span><span>Op</span><span>.</span><span>SUB</span><span>,</span> <span>reverse</span><span>=</span><span>True</span><span>)</span>
<span>_Box</span><span>.</span><span>__mul__</span> <span>=</span> <span>_Box</span><span>.</span><span>__rmul__</span> <span>=</span> <span>_register_binary_op</span><span>(</span><span>Op</span><span>.</span><span>MUL</span><span>)</span>
<span>_Box</span><span>.</span><span>__truediv__</span> <span>=</span> <span>_register_binary_op</span><span>(</span><span>Op</span><span>.</span><span>DIV</span><span>)</span>
<span>_Box</span><span>.</span><span>__rtruediv__</span> <span>=</span> <span>_register_binary_op</span><span>(</span><span>Op</span><span>.</span><span>DIV</span><span>,</span> <span>reverse</span><span>=</span><span>True</span><span>)</span>
</pre></div>
<p>The remaining key function is <tt>_register_binary_op</tt>:</p>
<div><pre><span></span><span>def</span> <span>_register_binary_op</span><span>(</span><span>opcode</span><span>,</span> <span>reverse</span><span>=</span><span>False</span><span>):</span>
    <span>&#34;&#34;&#34;Registers a binary opcode for Boxes.</span>

<span>    If reverse is True, the operation is registered as arg2 &lt;op&gt; arg1,</span>
<span>    instead of arg1 &lt;op&gt; arg2.</span>
<span>    &#34;&#34;&#34;</span>

    <span>def</span> <span>_op</span><span>(</span><span>arg1</span><span>,</span> <span>arg2</span><span>):</span>
        <span>if</span> <span>reverse</span><span>:</span>
            <span>arg1</span><span>,</span> <span>arg2</span> <span>=</span> <span>arg2</span><span>,</span> <span>arg1</span>
        <span>box1</span> <span>=</span> <span>arg1</span> <span>if</span> <span>isinstance</span><span>(</span><span>arg1</span><span>,</span> <span>_Box</span><span>)</span> <span>else</span> <span>_Box</span><span>(</span><span>ConstantExpr</span><span>(</span><span>arg1</span><span>))</span>
        <span>box2</span> <span>=</span> <span>arg2</span> <span>if</span> <span>isinstance</span><span>(</span><span>arg2</span><span>,</span> <span>_Box</span><span>)</span> <span>else</span> <span>_Box</span><span>(</span><span>ConstantExpr</span><span>(</span><span>arg2</span><span>))</span>
        <span>return</span> <span>_Box</span><span>(</span><span>BinOpExpr</span><span>(</span><span>box1</span><span>.</span><span>expr</span><span>,</span> <span>box2</span><span>.</span><span>expr</span><span>,</span> <span>opcode</span><span>))</span>

    <span>return</span> <span>_op</span>
</pre></div>
<p>To understand how this works, consider this trivial example:</p>
<div><pre><span></span><span>@tracejit</span>
<span>def</span> <span>add</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>):</span>
    <span>return</span> <span>a</span> <span>+</span> <span>b</span>

<span>print</span><span>(</span><span>add</span><span>(</span><span>1</span><span>,</span> <span>2</span><span>))</span>
</pre></div>
<p>After the decorated function is defined, <tt>add</tt> holds the wrapper function
defined inside <tt>tracejit</tt>. When <tt>add(1, 2)</tt> is called, the wrapper runs:</p>
<ol>
<li>For each argument of <tt>add</tt> itself (that is <tt>a</tt> and <tt>b</tt>), it creates
a new <tt>_Box</tt> holding a <tt>VarExpr</tt>. This denotes a named variable in
the <tt>Expr</tt> IR.</li>
<li>It then calls the wrapped function, passing it the boxes as runtime
parameters.</li>
<li>When (the wrapped) <tt>add</tt> runs, it invokes <tt>a + b</tt>. This is caught by the overloaded
<tt>__add__</tt> operator of <tt>_Box</tt>, and it creates a new <tt>BinOpExpr</tt> with
the <tt>VarExpr</tt>s representing <tt>a</tt> and <tt>b</tt> as children. This
<tt>BinOpExpr</tt> is then returned <a href="#footnote-3" id="footnote-reference-3">[3]</a>.</li>
<li>The wrapper unboxes the returned <tt>Expr</tt> and passes it to
<tt>llvm_jit_evaluate</tt> to emit LLVM IR from it and JIT execute it with the
actual runtime arguments of the call: <tt>1, 2</tt>.</li>
</ol>
<p>This might be a little mind-bending at first, because there are two different
executions that happen:</p>
<ul>
<li>The first is calling the wrapped <tt>add</tt> function itself, letting the Python
interpreter run it as usual, but with special arguments that build up the IR
instead of doing any computations. This is the <em>tracing step</em>.</li>
<li>The second is lowering this IR our tracing step built into LLVM IR and then
JIT executing it with the actual runtime argument values <tt>1, 2</tt>; this is
the <em>execution step</em>.</li>
</ul>
<p>This tracing approach has some interesting characteristics. Since we don&#39;t
have to analyze the source of the wrapped functions but only trace through
the execution, we can &#34;magically&#34; support a much richer set of programs, e.g.:</p>
<div><pre><span></span><span>@tracejit</span>
<span>def</span> <span>use_locals</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>,</span> <span>c</span><span>):</span>
    <span>x</span> <span>=</span> <span>a</span> <span>+</span> <span>2</span>
    <span>y</span> <span>=</span> <span>b</span> <span>-</span> <span>a</span>
    <span>z</span> <span>=</span> <span>c</span> <span>*</span> <span>x</span>
    <span>return</span> <span>y</span> <span>/</span> <span>x</span> <span>-</span> <span>z</span>

<span>print</span><span>(</span><span>use_locals</span><span>(</span><span>2</span><span>,</span> <span>8</span><span>,</span> <span>11</span><span>))</span>
</pre></div>
<p>This <em>just works</em> with our basic <tt>tracejit</tt>. Since Python variables are
placeholders (references) for values, our tracing step is oblivious to them - it
follows the flow of values. Another example:</p>
<div><pre><span></span><span>@tracejit</span>
<span>def</span> <span>use_loop</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>,</span> <span>c</span><span>):</span>
    <span>result</span> <span>=</span> <span>0</span>
    <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>1</span><span>,</span> <span>11</span><span>):</span>
        <span>result</span> <span>+=</span> <span>i</span>
    <span>return</span> <span>result</span> <span>+</span> <span>b</span> <span>*</span> <span>c</span>

<span>print</span><span>(</span><span>use_loop</span><span>(</span><span>10</span><span>,</span> <span>2</span><span>,</span> <span>3</span><span>))</span>
</pre></div>
<p>This also just works! The created <tt>Expr</tt> will be a long chain of <tt>BinExpr</tt>
additions of <tt>i</tt>&#39;s runtime values through the loop, added to the <tt>BinExpr</tt>
for <tt>b * c</tt>.</p>
<p>This last example also leads us to a limitation of the tracing approach; the
loop cannot be <em>data-dependent</em> - it cannot depend on the function&#39;s arguments,
because the tracing step has no concept of runtime values and wouldn&#39;t know
how many iterations to run through; or at least, it doesn&#39;t know this unless
we want to perform the tracing run for every runtime execution <a href="#footnote-4" id="footnote-reference-4">[4]</a>.</p>
<p>The tracing approach is useful in several domains, most notably
<a href="https://en.wikipedia.org/wiki/Automatic_differentiation">automatic differentiation</a> (AD).
For a slightly deeper taste, check out my <a href="https://github.com/eliben/radgrad">radgrad</a> project.</p>
<div id="tracing-jit-case-study-jax">
<h3>Tracing JIT case study: JAX</h3>
<p>The <a href="https://jax.readthedocs.io/en/latest/">JAX ML framework</a> uses a tracing
approach very similar to the one described here. The first code sample in this
post shows the JAX notation. JAX cleverly wraps Numpy with its own version which
is traced (similar to our <tt>_Box</tt>, but JAX calls these boxes &#34;tracers&#34;),
letting you write regular-feeling Numpy code that can be JIT optimized and
executed on accelerators like GPUs and TPUs via <a href="https://github.com/openxla">XLA</a>. JAX&#39;s tracer builds up an underlying IR (called
<a href="https://jax.readthedocs.io/en/latest/jaxpr.html">jaxpr</a>) which can then be
emitted to XLA ops and passed to XLA for further lowering and execution.</p>
<p>For a fairly deep overview of how JAX works, I recommend reading the
<a href="https://jax.readthedocs.io/en/latest/autodidax.html">autodidax doc</a>.</p>
<p>As mentioned earlier, JAX has <a href="https://jax.readthedocs.io/en/latest/jit-compilation.html">some limitations</a>
with things like data-dependent control flow in native Python. This won&#39;t work,
because there&#39;s control flow
that depends on a runtime value (<tt>count</tt>):</p>
<div><pre><span></span><span>import</span> <span>jax</span>

<span>@jax</span><span>.</span><span>jit</span>
<span>def</span> <span>sum_datadep</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>,</span> <span>count</span><span>):</span>
    <span>total</span> <span>=</span> <span>a</span>
    <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>count</span><span>):</span>
        <span>total</span> <span>+=</span> <span>b</span>
    <span>return</span> <span>total</span>

<span>print</span><span>(</span><span>sum_datadep</span><span>(</span><span>10</span><span>,</span> <span>3</span><span>,</span> <span>3</span><span>))</span>
</pre></div>
<p>When <tt>sum_datadep</tt> is executed, JAX will throw an exception, saying something
like:</p>
<blockquote>
This concrete value was not available in Python because it depends on the
value of the argument count.</blockquote>
<p>As a remedy, JAX has its
own built-in intrinsics from the <a href="https://jax.readthedocs.io/en/latest/jax.lax.html">jax.lax package</a>.
Here&#39;s the example rewritten in a way that actually works:</p>
<div><pre><span></span><span>import</span> <span>jax</span>
<span>from</span> <span>jax</span> <span>import</span> <span>lax</span>

<span>@jax</span><span>.</span><span>jit</span>
<span>def</span> <span>sum_datadep_fori</span><span>(</span><span>a</span><span>,</span> <span>b</span><span>,</span> <span>count</span><span>):</span>
    <span>def</span> <span>body</span><span>(</span><span>i</span><span>,</span> <span>total</span><span>):</span>
        <span>return</span> <span>total</span> <span>+</span> <span>b</span>

    <span>return</span> <span>lax</span><span>.</span><span>fori_loop</span><span>(</span><span>0</span><span>,</span> <span>count</span><span>,</span> <span>body</span><span>,</span> <span>a</span><span>)</span>
</pre></div>
<p><tt>fori_loop</tt> (and many other built-ins in the <tt>lax</tt> package) is something JAX
can trace through, generating a corresponding XLA operation (XLA has support for
<a href="https://openxla.org/xla/operation_semantics">While loops</a>, to which this
<tt>lax.fori_loop</tt> can be lowered).</p>
<p>The tracing approach has clear benefits for JAX as well; because it only cares
about the flow of values, it can handle arbitrarily complicated Python code,
as long as the flow of values can be traced. Just like the local variables and
data-independent loops shown earlier, but also things like closures. This makes
meta-programming and templating easy.</p>
</div>
</div>
<div id="code">
<h2>Code</h2>
<p>The full code for this post is available <a href="https://github.com/eliben/code-for-blog/tree/main/2025/decjit">on GitHub</a>.</p>
<hr/>




</div>

            </div>
            <!-- /.entry-content -->
<hr/>
<p>
For comments, please send me
<a href="mailto:eliben@gmail.com"><i></i> an email</a>.
</p>        </article>
    </section>

    </div>
</div></div>
  </body>
</html>
