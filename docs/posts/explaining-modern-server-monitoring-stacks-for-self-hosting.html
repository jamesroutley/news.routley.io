<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://dataswamp.org/~solene/2022-09-11-exploring-monitoring-stacks.html">Original</a>
    <h1>Explaining modern server monitoring stacks for self-hosting</h1>
    
    <div id="readability-page-1" class="page"><div>
<article id="20220911">
  <header>
  
    
    <p>Written by <em>Sol√®ne</em>, on 11 September 2022.</p>
    
  </header>
  
<p>Hello üëãüèª, it&#39;s been a long time I didn&#39;t have to take a look at monitoring servers.  I&#39;ve set up a Grafana server six years ago, and I was using Munin for my personal servers.
</p>
<p>However, I recently moved my server to a small virtual machine which has CPU and memory constraints (1 core / 1 GB of memory), and Munin didn&#39;t work very well.  I was curious to learn if the Grafana stack changed since the last time I used it, and YES.
</p>
<p>There is that project named Prometheus which is used absolutely everywhere, it was time for me to learn about it.  And as I like to go against the flow, I tried various changes to the industry standard stack by using VictoriaMetrics.
</p>
<p>In this article, I&#39;m using NixOS configuration for the examples, however it should be obvious enough that you can still understand the parts if you don&#39;t know anything about NixOS.
</p>

<p>VictoriaMetrics is a Prometheus drop-in replacement that is a lot more efficient (faster and use less resources), which also provides various API such as Graphite or InfluxDB.  It&#39;s the component storing data.  It comes with various programs like VictoriaMetrics agent to replace various parts of Prometheus.
</p>
<p><a href="https://victoriametrics.com/">VictoriaMetrics official website</a></p>
<p>Prometheus is a time series database, which also provide a collecting agent named Node Exporter.  It&#39;s also able to pull (scrape) data from remote services offering a Prometheus API.
</p>
<p><a href="https://prometheus.io/">Prometheus official website</a></p>
<p><a href="https://github.com/prometheus/node_exporter">Node Exporter GitHub page</a></p>
<p>NixOS is an operating system built with the Nix package manager, it has a declarative approach that requires to reconfigure the system when you need to make a change.
</p>
<p><a href="https://nixos.org">NixOS official website</a></p>
<p>Collectd is a agent gathering metrics from the system and sending it to a remote compatible database.
</p>
<p><a href="https://collectd.org/">Collectd official website</a></p>
<p>Grafana is a powerful Web interface pulling data from time series databases to render them under useful charts for analysis.
</p>
<p><a href="https://grafana.com/">Grafana official website</a></p>
<p><a href="https://grafana.com/grafana/dashboards/1860-node-exporter-full/">Node exporter full Grafana dashboard</a></p>

<p>In this setup, a Prometheus server is running on a server along with Grafana, and connects to remote servers running node_exporter to gather data.
</p>
<p>Running it on my server, Grafana takes 67 MB, the local node_exporter 12.5 MB and Prometheus 63 MB.
</p>
<pre><code>USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
grafana   837975  0.1  6.7 1384152 67836 ?       Ssl  01:19   1:07 grafana-server
node-ex+  953784  0.0  1.2 941292 12512 ?        Ssl  16:24   0:01 node_exporter
prometh+  983975  0.3  6.3 1226012 63284 ?       Ssl  17:07   0:00 prometheus
</code></pre>
<p><a href="https://dataswamp.org/~solene/static/monitoring-setup-1.png"><img src="https://dataswamp.org/~solene/static/monitoring-setup-1.png" alt="Setup 1 diagram" width="60%"/></a></p>
<ul>

  <li>model: pull, Prometheus is connecting to all servers</li>
</ul>

<h2 id="_Pros"> Pros <a href="#_Pros">¬ß</a></h2>
<ul>

  <li>it&#39;s the industry standard</li>
  <li>can use the &#34;node exporter full&#34; Grafana dashboard</li>
</ul>

<h2 id="_Cons"> Cons <a href="#_Cons">¬ß</a></h2>
<ul>

  <li>uses memory</li>
  <li>you need to be able to reach all the remote nodes</li>
</ul>

<h2 id="_Server"> Server <a href="#_Server">¬ß</a></h2>
<pre><code>{
  services.grafana.enable = true;
  services.prometheus.exporters.node.enable = true;

  services.prometheus = {
    enable = true;
    scrapeConfigs = [
      {
        job_name = &#34;kikimora&#34;;
        static_configs = [
          {targets = [&#34;10.43.43.2:9100&#34;];}
        ];
      }
      {
        job_name = &#34;interbus&#34;;
        static_configs = [
          {targets = [&#34;127.0.0.1:9100&#34;];}
        ];
      }
    ];
  };
}
</code></pre>
<h2 id="_Client"> Client <a href="#_Client">¬ß</a></h2>
<pre><code>{
  networking.firewall.allowedTCPPorts = [9100];
  services.prometheus.exporters.node.enable = true;
}
</code></pre>

<p>In this setup, a VictoriaMetrics server is running on a server along with Grafana.  A VictoriaMetrics agent is running locally to gather data from remote servers running node_exporter.
</p>
<p>Running it on my server, Grafana takes 67 MB, the local node_exporter 12.5 MB, VictoriaMetrics 30¬†MB and its agent 13.8 MB.
</p>
<pre><code>USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
grafana   837975  0.1  6.7 1384152 67836 ?       Ssl  01:19   1:07 grafana-server
node-ex+  953784  0.0  1.2 941292 12512 ?        Ssl  16:24   0:01 node_exporter
victori+  986126  0.1  3.0 1287016 30052 ?       Ssl  18:00   0:03 victoria-metric
root      987944  0.0  1.3 1086276 13856 ?       Sl   18:30   0:00 vmagent
</code></pre>
<p><a href="https://dataswamp.org/~solene/static/monitoring-setup-2.png"><img src="https://dataswamp.org/~solene/static/monitoring-setup-2.png" alt="Setup 2 diagram" width="60%"/></a></p>
<ul>

  <li>model: pull, VictoriaMetrics agent is connecting to all servers</li>
</ul>

<h2 id="_Pros"> Pros <a href="#_Pros">¬ß</a></h2>
<ul>

  <li>can use the &#34;node exporter full&#34; Grafana dashboard</li>
  <li>lightweight and more performant than Prometheus</li>
</ul>

<h2 id="_Cons"> Cons <a href="#_Cons">¬ß</a></h2>
<ul>

  <li>you need to be able to reach all the remote nodes</li>
</ul>

<h2 id="_Server"> Server <a href="#_Server">¬ß</a></h2>
<pre><code>let
  configure_prom = builtins.toFile &#34;prometheus.yml&#34; &#39;&#39;
    scrape_configs:
    - job_name: &#39;kikimora&#39;
      stream_parse: true
      static_configs:
      - targets:
        - 10.43.43.1:9100
    - job_name: &#39;interbus&#39;
      stream_parse: true
      static_configs:
      - targets:
        - 127.0.0.1:9100
  &#39;&#39;;
in {
  services.victoriametrics.enable = true;
  services.grafana.enable = true;

  systemd.services.export-to-prometheus = {
    path = with pkgs; [victoriametrics];
    enable = true;
    after = [&#34;network-online.target&#34;];
    wantedBy = [&#34;multi-user.target&#34;];
    script = &#34;vmagent -promscrape.config=${configure_prom} -remoteWrite.url=http://127.0.0.1:8428/api/v1/write&#34;;
  };
}
</code></pre>
<h2 id="_Client"> Client <a href="#_Client">¬ß</a></h2>
<pre><code>{
  networking.firewall.allowedTCPPorts = [9100];
  services.prometheus.exporters.node.enable = true;
}
</code></pre>

<p>In this setup, a VictoriaMetrics server is running on a server along with Grafana, on each server node_exporter and VictoriaMetrics agent are running to export data to the central VictoriaMetrics server.
</p>
<p>Running it on my server, Grafana takes 67 MB, the local node_exporter 12.5 MB, VictoriaMetrics 30¬†MB and its agent 13.8 MB, which is exactly the same as the setup 2, except the VictoriaMetrics agent is running on all remote servers.
</p>
<pre><code>USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
grafana   837975  0.1  6.7 1384152 67836 ?       Ssl  01:19   1:07 grafana-server
node-ex+  953784  0.0  1.2 941292 12512 ?        Ssl  16:24   0:01 node_exporter
victori+  986126  0.1  3.0 1287016 30052 ?       Ssl  18:00   0:03 victoria-metric
root      987944  0.0  1.3 1086276 13856 ?       Sl   18:30   0:00 vmagent
</code></pre>
<p><a href="https://dataswamp.org/~solene/static/monitoring-setup-3.png"><img src="https://dataswamp.org/~solene/static/monitoring-setup-3.png" alt="Setup 3 diagram" width="60%"/></a></p>
<ul>

  <li>model: push, each agent is connecting to the VictoriaMetrics server</li>
</ul>

<h2 id="_Pros"> Pros <a href="#_Pros">¬ß</a></h2>
<ul>

  <li>can use the &#34;node exporter full&#34; Grafana dashboard</li>
  <li>memory efficient</li>
  <li>can bypass firewalls easily</li>
</ul>

<h2 id="_Cons"> Cons <a href="#_Cons">¬ß</a></h2>
<ul>

  <li>you need to be able to reach all the remote nodes</li>
  <li>more maintenance as you have one extra agent on each remote</li>
  <li>may be bad for security, you need to allow remote servers to write to your VictoriaMetrics server</li>
</ul>

<h2 id="_Server"> Server <a href="#_Server">¬ß</a></h2>
<pre><code>{
  networking.firewall.allowedTCPPorts = [8428];
  services.victoriametrics.enable = true;
  services.grafana.enable = true;
  services.prometheus.exporters.node.enable = true;
}
</code></pre>
<h2 id="_Client"> Client <a href="#_Client">¬ß</a></h2>
<pre><code>let
  configure_prom = builtins.toFile &#34;prometheus.yml&#34; &#39;&#39;
    scrape_configs:
    - job_name: &#39;${config.networking.hostName}&#39;
      stream_parse: true
      static_configs:
      - targets:
        - 127.0.0.1:9100
  &#39;&#39;;
in {
  services.prometheus.exporters.node.enable = true;
  
  systemd.services.export-to-prometheus = {
    path = with pkgs; [victoriametrics];
    enable = true;
    after = [&#34;network-online.target&#34;];
    wantedBy = [&#34;multi-user.target&#34;];
    script = &#34;vmagent -promscrape.config=${configure_prom} -remoteWrite.url=http://victoria-server.domain:8428/api/v1/write&#34;;
  };
}
</code></pre>

<p>In this setup, a VictoriaMetrics server is running on a server along with Grafana, servers are running Collectd sending data to VictoriaMetrics graphite API.
</p>
<p>Running it on my server, Grafana takes 67 MB, VictoriaMetrics 30¬†MB and Collectd 172 kB (yes).
</p>
<pre><code>USER         PID %CPU %MEM    VSZ   RSS TTY      STAT START   TIME COMMAND
grafana   837975  0.1  6.7 1384152 67836 ?       Ssl  01:19   1:07 grafana-server
victori+  986126  0.1  3.0 1287016 30052 ?       Ssl  18:00   0:03 victoria-metric
collectd  844275  0.0  0.0 610432   172 ?        Ssl  02:07   0:00 collectd
</code></pre>
<p><a href="https://dataswamp.org/~solene/static/monitoring-setup-4.png"><img src="https://dataswamp.org/~solene/static/monitoring-setup-4.png" alt="Setup 4 diagram" width="60%"/></a></p>
<ul>

  <li>model: push, VictoriaMetrics receives data from the Collectd servers</li>
</ul>

<h2 id="_Pros"> Pros <a href="#_Pros">¬ß</a></h2>
<ul>

  <li>super memory efficient</li>
  <li>can bypass firewalls easily</li>
</ul>

<h2 id="_Cons"> Cons <a href="#_Cons">¬ß</a></h2>
<ul>

  <li>you can&#39;t use the &#34;node exporter full&#34; Grafana dashboard</li>
  <li>may be bad for security, you need to allow remote servers to write to your VictoriaMetrics server</li>
  <li>you need to configure Collectd for each host</li>
</ul>

<h2 id="_Server"> Server <a href="#_Server">¬ß</a></h2>
<p>The server requires VictoriaMetrics to run exposing its graphite API on ports 2003.
</p>
<p>Note that in Grafana, you will have to escape &#34;-&#34; characters using &#34;\-&#34; in the queries.  I also didn&#39;t find a way to automatically discover hosts in the data to use variables in the dashboard.
</p>
<p>UPDATE: Using write_tsdb exporter in collectd, and exposing a TSDB API with VictoriaMetrics, you can set a label to each host, and then use the query &#34;label_values(status)&#34; in Grafana to automatic discover hosts.
</p>
<pre><code>{
  networking.firewall.allowedTCPPorts = [2003];
  services.victoriametrics = {
    enable = true;
    extraOptions = [
      &#34;-graphiteListenAddr=:2003&#34;
    ];
  };
  services.grafana.enable = true;
  
}
</code></pre>
<h2 id="_Client"> Client <a href="#_Client">¬ß</a></h2>
<p>We only need to enable Collectd on the client:
</p>
<pre><code>{
  services.collectd = {
    enable = true;
    autoLoadPlugin = true;
    extraConfig = &#39;&#39;
      Interval 30
    &#39;&#39;;
    plugins = {
      &#34;write_graphite&#34; = &#39;&#39;
        &lt;Node &#34;${config.networking.hostName}&#34;&gt;
          Host &#34;victoria-server.fqdn&#34;
          Port &#34;2003&#34;
          Protocol &#34;tcp&#34;
          LogSendErrors true
          Prefix &#34;collectd_&#34;
        &lt;/Node&gt;
      &#39;&#39;;
      cpu = &#39;&#39;
        ReportByCpu false
      &#39;&#39;;
      memory = &#34;&#34;;
      df = &#39;&#39;
        Mountpoint &#34;/&#34;
        Mountpoint &#34;/nix/store&#34;
        Mountpoint &#34;/home&#34;
        ValuesPercentage True
        ValuesAbsolute False
      &#39;&#39;;
      load = &#34;&#34;;
      uptime = &#34;&#34;;
      swap = &#39;&#39;
        ReportBytes false
        ReportIO false
        ValuesPercentage true
      &#39;&#39;;
      interface = &#39;&#39;
        ReportInactive false
      &#39;&#39;;
    };
  };
}
</code></pre>

<p>The first section named #!/bin/introduction&#34; is on purpose and not a mistake.  It felt super fun when I started writing the article, and wanted to keep it that way.
</p>
<p>The Collectd setup is the most minimalistic while still powerful, but it requires lot of work to make the dashboards and configure the plugins correctly.
</p>
<p>The setup I like best is the setup 2.
</p>

</article>
</div></div>
  </body>
</html>
