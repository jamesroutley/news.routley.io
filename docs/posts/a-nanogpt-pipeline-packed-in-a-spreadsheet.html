<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/dabochen/spreadsheet-is-all-you-need">Original</a>
    <h1>A nanoGPT pipeline packed in a spreadsheet</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto"><strong>A nanoGPT pipeline packed in a spreadsheet</strong></p>
<p dir="auto">This is a project that I did to help myself understand how GPT works.</p>
<p dir="auto">While reading about LLMs, I realised that the internal mechanisms of a transformer is basically a range of matrices calculations being connected in a certain order.</p>
<p dir="auto"><strong>This is the full view of the spreadsheet</strong>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/dabochen/spreadsheet-is-all-you-need/blob/main/spreadsheetisallyouneed.jpg?raw=true"><img src="https://github.com/dabochen/spreadsheet-is-all-you-need/raw/main/spreadsheetisallyouneed.jpg?raw=true" alt="spreadsheet is all you need"/></a></p>
<p dir="auto"><strong>Zooming into the core of a transformer--self attention</strong>
<a target="_blank" rel="noopener noreferrer" href="https://github.com/dabochen/spreadsheet-is-all-you-need/blob/main/KQV.jpg?raw=true"><img src="https://github.com/dabochen/spreadsheet-is-all-you-need/raw/main/KQV.jpg?raw=true" alt="The core of a transformer--self attention"/></a></p>
<div dir="auto"><h2 tabindex="-1" dir="auto">What components will you see</h2><a id="user-content-what-components-will-you-see" aria-label="Permalink: What components will you see" href="#what-components-will-you-see"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">It contains all the transformer components including:</p>
<ol dir="auto">
<li>embedding</li>
<li>layer norm</li>
<li>self attention</li>
<li>projection</li>
<li>MLP</li>
<li>softmax</li>
<li>logits</li>
</ol>
<p dir="auto">It is based on Andrej Karpathy&#39;s NanoGPT structure which includes roughly 85000 parameters.</p>

<p dir="auto">In the numbers file &#34;nanoGPT.numbers&#34;, you will see two tabs, one called &#34;no weights&#34; and one called &#34;random weights&#34;.</p>
<p dir="auto">The spreadsheet doesn&#39;t contain actual trained weights and parameters, so you should not expect it to calculate the correct result for you before you update the parameters.</p>
<p dir="auto">You might also be wondering if there is an excel or a google sheets version, unfortunately there isn&#39;t one yet.</p>

<p dir="auto">Firstly, all the blocks are the values or parameters that is processed through the GPT architecture, they are being color coded as purple, green and orange.</p>
<p dir="auto"><strong>Purple</strong>: these are parameters that are supposed be replaced by a trained model&#39;s parameter.</p>
<p dir="auto">Secondly, you should start from the top and work all the way down to the bottom, and there are labels on the left of the page showing what stage you are in.</p>
<p dir="auto">Lastly, this demo is built with great help from the LLM visualization project (<a href="https://bbycroft.net/llm" rel="nofollow">https://bbycroft.net/llm</a>) by Brendan Bycroft which uses 3D animations to explain transformers.</p>
<div dir="auto"><h2 tabindex="-1" dir="auto">What else can you do with this</h2><a id="user-content-what-else-can-you-do-with-this" aria-label="Permalink: What else can you do with this" href="#what-else-can-you-do-with-this"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ol dir="auto">
<li>Read through the whole spreadsheet will help you form a visual impression of what a transformer is.</li>
<li>Each cell contains the actual calculation, which you can double click to checkout the details(function).</li>
<li>By selecting the green cells (the values), you can see which other values or parameters are influencing this cell, so that you can get a sense of the mechanism.</li>
<li>Try to make changes to the parameters and see what might happen.</li>
<li>If you happen to have the weights of NanoGPT, you can replace the parameters in this spreadsheet to get it working properly.</li>
</ol>

<p dir="auto">I wish I could just upload all the tutorials I&#39;ve watched into chatgpt and ask it to generate this file, but I guess we are not there yet.
Anyone is welcomed if they want to build something more complicated than nanoGPT, although I do feel like nanoGPT in a spreadsheet is already a lot for my M2 chip.<br/></p>

<p dir="auto">Thanks to the following projects that helped me a lot when creating this spreasheet.</p>
<ol dir="auto">
<li><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY" rel="nofollow"><strong>Andrej Karpathy&#39;s youtube tutorial &#34;Let&#39;s build GPT&#34;</strong></a>: <a href="https://www.youtube.com/watch?v=kCc8FmEb1nY" rel="nofollow">https://www.youtube.com/watch?v=kCc8FmEb1nY</a></li>
<li><a href="https://github.com/karpathy/nanoGPT"><strong>Andrej Karpathy&#39;s NanoGPT project</strong></a>: <a href="https://github.com/karpathy/nanoGPT">https://github.com/karpathy/nanoGPT</a></li>
<li><a href="https://bbycroft.net/llm" rel="nofollow"><strong>Brendan Bycroft&#39;s 3D visualization of transformers</strong></a>: <a href="https://bbycroft.net/llm" rel="nofollow">https://bbycroft.net/llm</a></li>
<li><a href="https://youtu.be/eMlx5fFNoYc?si=k40zeuPdM_4cB88o" rel="nofollow"><strong>3Blue1Brown&#39;s LLM course</strong></a>: <a href="https://youtu.be/eMlx5fFNoYc?si=k40zeuPdM_4cB88o" rel="nofollow">https://youtu.be/eMlx5fFNoYc?si=k40zeuPdM_4cB88o</a></li>
</ol>
</article></div></div>
  </body>
</html>
