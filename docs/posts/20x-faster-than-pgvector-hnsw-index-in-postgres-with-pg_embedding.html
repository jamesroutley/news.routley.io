<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://neon.tech/blog/pg-embedding-extension-for-vector-search">Original</a>
    <h1>20x faster than pgvector: HNSW index in Postgres with pg_embedding</h1>
    
    <div id="readability-page-1" class="page"><div>
<p><img alt="Post image" fetchpriority="high" width="1024" height="576" decoding="async" data-nimg="1" sizes="(max-width: 767px) 100vw" srcset="/_next/image?url=https%3A%2F%2Fneon-hwp.dreamhosters.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fimage-19.png&amp;w=640&amp;q=85 640w, /_next/image?url=https%3A%2F%2Fneon-hwp.dreamhosters.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fimage-19.png&amp;w=750&amp;q=85 750w, /_next/image?url=https%3A%2F%2Fneon-hwp.dreamhosters.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fimage-19.png&amp;w=828&amp;q=85 828w, /_next/image?url=https%3A%2F%2Fneon-hwp.dreamhosters.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fimage-19.png&amp;w=1080&amp;q=85 1080w, /_next/image?url=https%3A%2F%2Fneon-hwp.dreamhosters.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fimage-19.png&amp;w=1200&amp;q=85 1200w, /_next/image?url=https%3A%2F%2Fneon-hwp.dreamhosters.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fimage-19.png&amp;w=1920&amp;q=85 1920w, /_next/image?url=https%3A%2F%2Fneon-hwp.dreamhosters.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fimage-19.png&amp;w=2048&amp;q=85 2048w, /_next/image?url=https%3A%2F%2Fneon-hwp.dreamhosters.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fimage-19.png&amp;w=3840&amp;q=85 3840w" src="https://neon.tech/_next/image?url=https%3A%2F%2Fneon-hwp.dreamhosters.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fimage-19.png&amp;w=3840&amp;q=85"/></p><p>We’re excited to announce the release of our <code>pg_embedding</code> extension for Postgres and LangChain! </p>



<p>The new <code>pg_embedding</code> extension brings 20x the speed for 99% accuracy to graph-based approximate nearest neighbor search to your Postgres databases. </p>



<p><img alt="Post image" loading="lazy" width="841" height="470" decoding="async" data-nimg="1" sizes="(max-width: 767px) 100vw" srcset="/_next/image?url=https%3A%2F%2Fneon-hwp.dreamhosters.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fimage-32.png&amp;w=640&amp;q=85 640w, /_next/image?url=https%3A%2F%2Fneon-hwp.dreamhosters.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fimage-32.png&amp;w=750&amp;q=85 750w, /_next/image?url=https%3A%2F%2Fneon-hwp.dreamhosters.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fimage-32.png&amp;w=828&amp;q=85 828w, /_next/image?url=https%3A%2F%2Fneon-hwp.dreamhosters.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fimage-32.png&amp;w=1080&amp;q=85 1080w, /_next/image?url=https%3A%2F%2Fneon-hwp.dreamhosters.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fimage-32.png&amp;w=1200&amp;q=85 1200w, /_next/image?url=https%3A%2F%2Fneon-hwp.dreamhosters.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fimage-32.png&amp;w=1920&amp;q=85 1920w, /_next/image?url=https%3A%2F%2Fneon-hwp.dreamhosters.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fimage-32.png&amp;w=2048&amp;q=85 2048w, /_next/image?url=https%3A%2F%2Fneon-hwp.dreamhosters.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fimage-32.png&amp;w=3840&amp;q=85 3840w" src="https://neon.tech/_next/image?url=https%3A%2F%2Fneon-hwp.dreamhosters.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fimage-32.png&amp;w=3840&amp;q=85"/></p><p>While the <code>pgvector</code> extension with IVFFlat indexing has been a popular choice, our new <code>pg_embedding</code> extension uses Hierarchical Navigable Small Worlds (HNSW) index to unlock new levels of efficiency in high-dimensional similarity search. </p>



<p>You can easily implement vector search with <code>pg_embedding</code> in your applications. Prior knowledge of vector indexes is optional. Run the following query to get started:</p>


<div><pre><code><span>CREATE</span><span> EXTENSION </span><span>IF</span><span> </span><span>NOT</span><span> </span><span>EXISTS</span><span> embedding</span><span>;</span><span>
</span><span></span><span>CREATE</span><span> </span><span>INDEX</span><span> </span><span>ON</span><span> items </span><span>USING</span><span> hnsw </span><span>(</span><span>embedding</span><span>)</span><span> </span><span>WITH</span><span> </span><span>(</span><span>maxelements </span><span>=</span><span> </span><span>1000000</span><span>,</span><span> dims</span><span>=</span><span>1536</span><span>,</span><span> m</span><span>=</span><span>32</span><span>)</span><span>;</span></code></pre></div>


<p>You can also use the extension in LangChain using the PGEmbedding vectorstore:<br/></p>


<div><pre><code><span>from</span><span> langchain</span><span>.</span><span>vectorstores </span><span>import</span><span> PGEmbedding
</span>
<span>db </span><span>=</span><span> PGEmbedding</span><span>.</span><span>from_documents</span><span>(</span><span>
</span><span>    embedding</span><span>=</span><span>embeddings</span><span>,</span><span>
</span><span>    documents</span><span>=</span><span>docs</span><span>,</span><span>
</span><span>    collection_name</span><span>=</span><span>&#34;state_of_the_union&#34;</span><span>,</span><span>
</span><span>    connection_string</span><span>=</span><span>CONNECTION_STRING</span><span>,</span><span>
</span><span></span><span>)</span><span>
</span><span>db</span><span>.</span><span>create_hnsw_index</span><span>(</span><span>max_elements</span><span>=</span><span> </span><span>10000</span><span>,</span><span> dims </span><span>=</span><span> </span><span>1536</span><span>,</span><span> m </span><span>=</span><span> </span><span>8</span><span>,</span><span> ef_construction </span><span>=</span><span> </span><span>16</span><span>,</span><span> ef_search </span><span>=</span><span> </span><span>16</span><span>)</span></code></pre></div>


<p><em>For those curious about the inner workings and the differences between IVFFlat and HNSW for Postgres applications, we carried out benchmark tests on Neon Postgres to compare the performance of the two indexes. Keep on reading to find out more.</em></p>



<h2>Benchmark Results</h2>



<p>The benchmark tests compare the performance of <code>pg_embedding</code> with HNSW and <code>pgvector</code> with IVFFlat indexing using the GIST-960 Euclidean dataset, which provides a train set of 1 million vectors of 960 dimensions, and a test set of 1000. Each search returned k=100 vectors.</p>



<p>HNSW index is stored in memory for efficiency. For this to be a comparable test, we stored IVFFlat index in memory using <code>pg_prewarm</code> extension:</p>


<div><pre><code><span>SELECT</span><span> pg_prewarm</span><span>(</span><span>&#39;3448836&#39;</span><span>,</span><span> </span><span>mode</span><span> </span><span>=</span><span>&gt;</span><span> </span><span>&#39;buffer&#39;</span><span>)</span><span>;</span></code></pre></div>


<p>The chart below is on a logarithmic scale. <code>pg_embedding</code> performs 5 to 30 times faster for the same recall. The higher accuracy we want to reach with IVFFlat, the longer the execution time. This is due the fact that more probes are required in <code>pgvector</code> and IVFFlat to reach larger recall. However, the bigger the number of probes, the faster search converges towards a sequential scan.</p>



<p><img alt="Post image" loading="lazy" width="1024" height="586" decoding="async" data-nimg="1" sizes="(max-width: 767px) 100vw" srcset="/_next/image?url=https%3A%2F%2Fneon-hwp.dreamhosters.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fimage-31.png&amp;w=640&amp;q=85 640w, /_next/image?url=https%3A%2F%2Fneon-hwp.dreamhosters.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fimage-31.png&amp;w=750&amp;q=85 750w, /_next/image?url=https%3A%2F%2Fneon-hwp.dreamhosters.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fimage-31.png&amp;w=828&amp;q=85 828w, /_next/image?url=https%3A%2F%2Fneon-hwp.dreamhosters.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fimage-31.png&amp;w=1080&amp;q=85 1080w, /_next/image?url=https%3A%2F%2Fneon-hwp.dreamhosters.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fimage-31.png&amp;w=1200&amp;q=85 1200w, /_next/image?url=https%3A%2F%2Fneon-hwp.dreamhosters.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fimage-31.png&amp;w=1920&amp;q=85 1920w, /_next/image?url=https%3A%2F%2Fneon-hwp.dreamhosters.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fimage-31.png&amp;w=2048&amp;q=85 2048w, /_next/image?url=https%3A%2F%2Fneon-hwp.dreamhosters.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fimage-31.png&amp;w=3840&amp;q=85 3840w" src="https://neon.tech/_next/image?url=https%3A%2F%2Fneon-hwp.dreamhosters.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fimage-31.png&amp;w=3840&amp;q=85"/></p><h3>Results and Analysis</h3>



<h3>Metrics</h3>



<p>We compared the performance of both extensions based on the following metrics:</p>



<ul>
<li><strong>Execution time</strong>: Measured as the average time taken to perform 100 nearest neighbor search queries.</li>



<li><strong>Accuracy/Recall</strong>: Measured as the proportion of true nearest neighbors each query returns.</li>
</ul>



<h3>Setup</h3>



<ul>
<li><strong>Datasets</strong>: We used the GIST-960 Euclidean dataset for benchmarking. This dataset is widely used for benchmarking similarity search algorithms.</li>



<li><strong>Environment</strong>: The benchmarks were conducted on a Neon instance with 4 vCPUs and 16 GB RAM.</li>



<li><strong>Configurations</strong>:
<ul>
<li>For pgvector, we varied the ‘probes’ parameter across [1, 2, 10, 50] and ‘lists’ parameter across [1000, 2000]. </li>



<li>For HNSW, we experimented with ‘m’ in [32, 64, 128], ‘efConstruction’ in [64, 128, 256], and ‘efSearch’ in [32, 64, 128, 256, 512].</li>
</ul>
</li>
</ul>



<h2>Why is HNSW faster than IVFFlat?</h2>



<p>Let’s start by understanding what IVFFlat and HNSW are and how they work.</p>



<h3>IVFFlat with pgvector</h3>



<p><code>pgvector</code> allows for vector similarity search directly within the database. One of its indexing techniques is called IVFFlat. The IVFFlat index partitions the dataset into multiple clusters and maintains an inverted list for each cluster. During search, only a selected number of clusters are examined, which greatly speeds up the search process compared to a flat index.</p>



<p><img alt="Post image" loading="lazy" width="975" height="512" decoding="async" data-nimg="1" sizes="(max-width: 767px) 100vw" srcset="/_next/image?url=https%3A%2F%2Flh3.googleusercontent.com%2FyIaqfjbispbg5N0vx-cpOBELNGoSN-ZMv8kUfG0Jo059SkJv7-2DaXWBsnIOJeEevHlKOhWhtdkwSUG7x_JlrWdHLGl4nkOlX7Snv-AaiOY7dvja2c3CcFbf1-vV1eBf39EbA0vjj7avnrXJu-GqjAM&amp;w=640&amp;q=85 640w, /_next/image?url=https%3A%2F%2Flh3.googleusercontent.com%2FyIaqfjbispbg5N0vx-cpOBELNGoSN-ZMv8kUfG0Jo059SkJv7-2DaXWBsnIOJeEevHlKOhWhtdkwSUG7x_JlrWdHLGl4nkOlX7Snv-AaiOY7dvja2c3CcFbf1-vV1eBf39EbA0vjj7avnrXJu-GqjAM&amp;w=750&amp;q=85 750w, /_next/image?url=https%3A%2F%2Flh3.googleusercontent.com%2FyIaqfjbispbg5N0vx-cpOBELNGoSN-ZMv8kUfG0Jo059SkJv7-2DaXWBsnIOJeEevHlKOhWhtdkwSUG7x_JlrWdHLGl4nkOlX7Snv-AaiOY7dvja2c3CcFbf1-vV1eBf39EbA0vjj7avnrXJu-GqjAM&amp;w=828&amp;q=85 828w, /_next/image?url=https%3A%2F%2Flh3.googleusercontent.com%2FyIaqfjbispbg5N0vx-cpOBELNGoSN-ZMv8kUfG0Jo059SkJv7-2DaXWBsnIOJeEevHlKOhWhtdkwSUG7x_JlrWdHLGl4nkOlX7Snv-AaiOY7dvja2c3CcFbf1-vV1eBf39EbA0vjj7avnrXJu-GqjAM&amp;w=1080&amp;q=85 1080w, /_next/image?url=https%3A%2F%2Flh3.googleusercontent.com%2FyIaqfjbispbg5N0vx-cpOBELNGoSN-ZMv8kUfG0Jo059SkJv7-2DaXWBsnIOJeEevHlKOhWhtdkwSUG7x_JlrWdHLGl4nkOlX7Snv-AaiOY7dvja2c3CcFbf1-vV1eBf39EbA0vjj7avnrXJu-GqjAM&amp;w=1200&amp;q=85 1200w, /_next/image?url=https%3A%2F%2Flh3.googleusercontent.com%2FyIaqfjbispbg5N0vx-cpOBELNGoSN-ZMv8kUfG0Jo059SkJv7-2DaXWBsnIOJeEevHlKOhWhtdkwSUG7x_JlrWdHLGl4nkOlX7Snv-AaiOY7dvja2c3CcFbf1-vV1eBf39EbA0vjj7avnrXJu-GqjAM&amp;w=1920&amp;q=85 1920w, /_next/image?url=https%3A%2F%2Flh3.googleusercontent.com%2FyIaqfjbispbg5N0vx-cpOBELNGoSN-ZMv8kUfG0Jo059SkJv7-2DaXWBsnIOJeEevHlKOhWhtdkwSUG7x_JlrWdHLGl4nkOlX7Snv-AaiOY7dvja2c3CcFbf1-vV1eBf39EbA0vjj7avnrXJu-GqjAM&amp;w=2048&amp;q=85 2048w, /_next/image?url=https%3A%2F%2Flh3.googleusercontent.com%2FyIaqfjbispbg5N0vx-cpOBELNGoSN-ZMv8kUfG0Jo059SkJv7-2DaXWBsnIOJeEevHlKOhWhtdkwSUG7x_JlrWdHLGl4nkOlX7Snv-AaiOY7dvja2c3CcFbf1-vV1eBf39EbA0vjj7avnrXJu-GqjAM&amp;w=3840&amp;q=85 3840w" src="https://neon.tech/_next/image?url=https%3A%2F%2Flh3.googleusercontent.com%2FyIaqfjbispbg5N0vx-cpOBELNGoSN-ZMv8kUfG0Jo059SkJv7-2DaXWBsnIOJeEevHlKOhWhtdkwSUG7x_JlrWdHLGl4nkOlX7Snv-AaiOY7dvja2c3CcFbf1-vV1eBf39EbA0vjj7avnrXJu-GqjAM&amp;w=3840&amp;q=85"/></p><p>By default, IVFFlat probes = 1, which means that the index will conduct the search in the nearest centroid’s cluster (or list). However, that can lead to inaccuracies as the query vector is closer to the cluster’s edges.</p>



<p>One way to increase accuracy is to increase the number of probes. The optimal number of lists and probes are respectively <code>sqrt(rows)</code>, and <code>sqrt(lists)</code>, which results in a time complexity of <code>O(sqrt(rows))</code>. The chart below shows that recall increases exponentially with the number of probes.</p>



<p><img alt="Post image" loading="lazy" width="839" height="480" decoding="async" data-nimg="1" sizes="(max-width: 767px) 100vw" srcset="/_next/image?url=https%3A%2F%2Flh3.googleusercontent.com%2FPbEFL2PUjzu4ndQZvLDFxvi7vydxrNKR2pe3fjNCu8XxWBRBy7-wgJD1XDlntUJUFLVc86Soxv_nNApeP7g5kqoaG6ghpEo1l1tU9R9RBJXKZDoLr1Be4g2rpIT55RlmNL7pVFUBlhELNk-1UverOSg&amp;w=640&amp;q=85 640w, /_next/image?url=https%3A%2F%2Flh3.googleusercontent.com%2FPbEFL2PUjzu4ndQZvLDFxvi7vydxrNKR2pe3fjNCu8XxWBRBy7-wgJD1XDlntUJUFLVc86Soxv_nNApeP7g5kqoaG6ghpEo1l1tU9R9RBJXKZDoLr1Be4g2rpIT55RlmNL7pVFUBlhELNk-1UverOSg&amp;w=750&amp;q=85 750w, /_next/image?url=https%3A%2F%2Flh3.googleusercontent.com%2FPbEFL2PUjzu4ndQZvLDFxvi7vydxrNKR2pe3fjNCu8XxWBRBy7-wgJD1XDlntUJUFLVc86Soxv_nNApeP7g5kqoaG6ghpEo1l1tU9R9RBJXKZDoLr1Be4g2rpIT55RlmNL7pVFUBlhELNk-1UverOSg&amp;w=828&amp;q=85 828w, /_next/image?url=https%3A%2F%2Flh3.googleusercontent.com%2FPbEFL2PUjzu4ndQZvLDFxvi7vydxrNKR2pe3fjNCu8XxWBRBy7-wgJD1XDlntUJUFLVc86Soxv_nNApeP7g5kqoaG6ghpEo1l1tU9R9RBJXKZDoLr1Be4g2rpIT55RlmNL7pVFUBlhELNk-1UverOSg&amp;w=1080&amp;q=85 1080w, /_next/image?url=https%3A%2F%2Flh3.googleusercontent.com%2FPbEFL2PUjzu4ndQZvLDFxvi7vydxrNKR2pe3fjNCu8XxWBRBy7-wgJD1XDlntUJUFLVc86Soxv_nNApeP7g5kqoaG6ghpEo1l1tU9R9RBJXKZDoLr1Be4g2rpIT55RlmNL7pVFUBlhELNk-1UverOSg&amp;w=1200&amp;q=85 1200w, /_next/image?url=https%3A%2F%2Flh3.googleusercontent.com%2FPbEFL2PUjzu4ndQZvLDFxvi7vydxrNKR2pe3fjNCu8XxWBRBy7-wgJD1XDlntUJUFLVc86Soxv_nNApeP7g5kqoaG6ghpEo1l1tU9R9RBJXKZDoLr1Be4g2rpIT55RlmNL7pVFUBlhELNk-1UverOSg&amp;w=1920&amp;q=85 1920w, /_next/image?url=https%3A%2F%2Flh3.googleusercontent.com%2FPbEFL2PUjzu4ndQZvLDFxvi7vydxrNKR2pe3fjNCu8XxWBRBy7-wgJD1XDlntUJUFLVc86Soxv_nNApeP7g5kqoaG6ghpEo1l1tU9R9RBJXKZDoLr1Be4g2rpIT55RlmNL7pVFUBlhELNk-1UverOSg&amp;w=2048&amp;q=85 2048w, /_next/image?url=https%3A%2F%2Flh3.googleusercontent.com%2FPbEFL2PUjzu4ndQZvLDFxvi7vydxrNKR2pe3fjNCu8XxWBRBy7-wgJD1XDlntUJUFLVc86Soxv_nNApeP7g5kqoaG6ghpEo1l1tU9R9RBJXKZDoLr1Be4g2rpIT55RlmNL7pVFUBlhELNk-1UverOSg&amp;w=3840&amp;q=85 3840w" src="https://neon.tech/_next/image?url=https%3A%2F%2Flh3.googleusercontent.com%2FPbEFL2PUjzu4ndQZvLDFxvi7vydxrNKR2pe3fjNCu8XxWBRBy7-wgJD1XDlntUJUFLVc86Soxv_nNApeP7g5kqoaG6ghpEo1l1tU9R9RBJXKZDoLr1Be4g2rpIT55RlmNL7pVFUBlhELNk-1UverOSg&amp;w=3840&amp;q=85"/></p><h3>HNSW and pg_embedding</h3>



<p>HNSW (Hierarchical Navigable Small World) was first introduced by Yu A Malkov and Dmitry A Yashunin in their paper titled: Efficient and Robust Approximate Nearest Neighbor Search Using Hierarchical Navigable Small World Graphs.</p>



<p>HNSW is a graph-based approach to indexing high-dimensional data. It constructs a hierarchy of graphs, where each layer is a subset of the previous one, which results in a time complexity of <code>O(log(rows))</code>. During search, it navigates through these graphs to quickly find the nearest neighbors.</p>



<p><img alt="Post image" loading="lazy" width="841" height="470" decoding="async" data-nimg="1" sizes="(max-width: 767px) 100vw" srcset="/_next/image?url=https%3A%2F%2Flh5.googleusercontent.com%2F2UAzXX-oPGtXQ1mNCjAtR1-_5az0aPN3UR8Tz006tIuLs_H42SeU5f0Xde33jVvUPnEt8byrrSYKZTxyV7X8jiiJbou7_dPaXRx2gKHR4qLcN4mVZMsYIahdTmL7nZBz4mNC4sV-18iGsKSsdz4K9FM&amp;w=640&amp;q=85 640w, /_next/image?url=https%3A%2F%2Flh5.googleusercontent.com%2F2UAzXX-oPGtXQ1mNCjAtR1-_5az0aPN3UR8Tz006tIuLs_H42SeU5f0Xde33jVvUPnEt8byrrSYKZTxyV7X8jiiJbou7_dPaXRx2gKHR4qLcN4mVZMsYIahdTmL7nZBz4mNC4sV-18iGsKSsdz4K9FM&amp;w=750&amp;q=85 750w, /_next/image?url=https%3A%2F%2Flh5.googleusercontent.com%2F2UAzXX-oPGtXQ1mNCjAtR1-_5az0aPN3UR8Tz006tIuLs_H42SeU5f0Xde33jVvUPnEt8byrrSYKZTxyV7X8jiiJbou7_dPaXRx2gKHR4qLcN4mVZMsYIahdTmL7nZBz4mNC4sV-18iGsKSsdz4K9FM&amp;w=828&amp;q=85 828w, /_next/image?url=https%3A%2F%2Flh5.googleusercontent.com%2F2UAzXX-oPGtXQ1mNCjAtR1-_5az0aPN3UR8Tz006tIuLs_H42SeU5f0Xde33jVvUPnEt8byrrSYKZTxyV7X8jiiJbou7_dPaXRx2gKHR4qLcN4mVZMsYIahdTmL7nZBz4mNC4sV-18iGsKSsdz4K9FM&amp;w=1080&amp;q=85 1080w, /_next/image?url=https%3A%2F%2Flh5.googleusercontent.com%2F2UAzXX-oPGtXQ1mNCjAtR1-_5az0aPN3UR8Tz006tIuLs_H42SeU5f0Xde33jVvUPnEt8byrrSYKZTxyV7X8jiiJbou7_dPaXRx2gKHR4qLcN4mVZMsYIahdTmL7nZBz4mNC4sV-18iGsKSsdz4K9FM&amp;w=1200&amp;q=85 1200w, /_next/image?url=https%3A%2F%2Flh5.googleusercontent.com%2F2UAzXX-oPGtXQ1mNCjAtR1-_5az0aPN3UR8Tz006tIuLs_H42SeU5f0Xde33jVvUPnEt8byrrSYKZTxyV7X8jiiJbou7_dPaXRx2gKHR4qLcN4mVZMsYIahdTmL7nZBz4mNC4sV-18iGsKSsdz4K9FM&amp;w=1920&amp;q=85 1920w, /_next/image?url=https%3A%2F%2Flh5.googleusercontent.com%2F2UAzXX-oPGtXQ1mNCjAtR1-_5az0aPN3UR8Tz006tIuLs_H42SeU5f0Xde33jVvUPnEt8byrrSYKZTxyV7X8jiiJbou7_dPaXRx2gKHR4qLcN4mVZMsYIahdTmL7nZBz4mNC4sV-18iGsKSsdz4K9FM&amp;w=2048&amp;q=85 2048w, /_next/image?url=https%3A%2F%2Flh5.googleusercontent.com%2F2UAzXX-oPGtXQ1mNCjAtR1-_5az0aPN3UR8Tz006tIuLs_H42SeU5f0Xde33jVvUPnEt8byrrSYKZTxyV7X8jiiJbou7_dPaXRx2gKHR4qLcN4mVZMsYIahdTmL7nZBz4mNC4sV-18iGsKSsdz4K9FM&amp;w=3840&amp;q=85 3840w" src="https://neon.tech/_next/image?url=https%3A%2F%2Flh5.googleusercontent.com%2F2UAzXX-oPGtXQ1mNCjAtR1-_5az0aPN3UR8Tz006tIuLs_H42SeU5f0Xde33jVvUPnEt8byrrSYKZTxyV7X8jiiJbou7_dPaXRx2gKHR4qLcN4mVZMsYIahdTmL7nZBz4mNC4sV-18iGsKSsdz4K9FM&amp;w=3840&amp;q=85"/></p><p>There three main parameters in HNSW algorithms:</p>



<ul>
<li><strong>m</strong>: This parameter refers to the maximum number of bidirectional links created for every new element during the construction of the graph. </li>



<li><strong>efConstruction</strong>: This parameter is used during the index building phase. Higher efConstruction values lead to a higher quality of the graph and, consequently, more accurate search results. However, it also means the index building process will take more time. The chart below shows build time by ef_construction value using the GIST-960 dataset.</li>
</ul>



<p><img alt="Post image" loading="lazy" width="839" height="452" decoding="async" data-nimg="1" sizes="(max-width: 767px) 100vw" srcset="/_next/image?url=https%3A%2F%2Flh5.googleusercontent.com%2FiLLyL4Lv9Jqzat_yoA24bqsKpc7N7W_02lAKLdJcN7soBj-8H-7BerPqoRUMmNRK0sxiO9pgVPDl2NFAes8vk-4juk7ZGKOWwzlfGJLSoH_RSTCq6GPcdUnSjaCIWOxLtIBJqycNH_ydvx1Q9LQ3Hf4&amp;w=640&amp;q=85 640w, /_next/image?url=https%3A%2F%2Flh5.googleusercontent.com%2FiLLyL4Lv9Jqzat_yoA24bqsKpc7N7W_02lAKLdJcN7soBj-8H-7BerPqoRUMmNRK0sxiO9pgVPDl2NFAes8vk-4juk7ZGKOWwzlfGJLSoH_RSTCq6GPcdUnSjaCIWOxLtIBJqycNH_ydvx1Q9LQ3Hf4&amp;w=750&amp;q=85 750w, /_next/image?url=https%3A%2F%2Flh5.googleusercontent.com%2FiLLyL4Lv9Jqzat_yoA24bqsKpc7N7W_02lAKLdJcN7soBj-8H-7BerPqoRUMmNRK0sxiO9pgVPDl2NFAes8vk-4juk7ZGKOWwzlfGJLSoH_RSTCq6GPcdUnSjaCIWOxLtIBJqycNH_ydvx1Q9LQ3Hf4&amp;w=828&amp;q=85 828w, /_next/image?url=https%3A%2F%2Flh5.googleusercontent.com%2FiLLyL4Lv9Jqzat_yoA24bqsKpc7N7W_02lAKLdJcN7soBj-8H-7BerPqoRUMmNRK0sxiO9pgVPDl2NFAes8vk-4juk7ZGKOWwzlfGJLSoH_RSTCq6GPcdUnSjaCIWOxLtIBJqycNH_ydvx1Q9LQ3Hf4&amp;w=1080&amp;q=85 1080w, /_next/image?url=https%3A%2F%2Flh5.googleusercontent.com%2FiLLyL4Lv9Jqzat_yoA24bqsKpc7N7W_02lAKLdJcN7soBj-8H-7BerPqoRUMmNRK0sxiO9pgVPDl2NFAes8vk-4juk7ZGKOWwzlfGJLSoH_RSTCq6GPcdUnSjaCIWOxLtIBJqycNH_ydvx1Q9LQ3Hf4&amp;w=1200&amp;q=85 1200w, /_next/image?url=https%3A%2F%2Flh5.googleusercontent.com%2FiLLyL4Lv9Jqzat_yoA24bqsKpc7N7W_02lAKLdJcN7soBj-8H-7BerPqoRUMmNRK0sxiO9pgVPDl2NFAes8vk-4juk7ZGKOWwzlfGJLSoH_RSTCq6GPcdUnSjaCIWOxLtIBJqycNH_ydvx1Q9LQ3Hf4&amp;w=1920&amp;q=85 1920w, /_next/image?url=https%3A%2F%2Flh5.googleusercontent.com%2FiLLyL4Lv9Jqzat_yoA24bqsKpc7N7W_02lAKLdJcN7soBj-8H-7BerPqoRUMmNRK0sxiO9pgVPDl2NFAes8vk-4juk7ZGKOWwzlfGJLSoH_RSTCq6GPcdUnSjaCIWOxLtIBJqycNH_ydvx1Q9LQ3Hf4&amp;w=2048&amp;q=85 2048w, /_next/image?url=https%3A%2F%2Flh5.googleusercontent.com%2FiLLyL4Lv9Jqzat_yoA24bqsKpc7N7W_02lAKLdJcN7soBj-8H-7BerPqoRUMmNRK0sxiO9pgVPDl2NFAes8vk-4juk7ZGKOWwzlfGJLSoH_RSTCq6GPcdUnSjaCIWOxLtIBJqycNH_ydvx1Q9LQ3Hf4&amp;w=3840&amp;q=85 3840w" src="https://neon.tech/_next/image?url=https%3A%2F%2Flh5.googleusercontent.com%2FiLLyL4Lv9Jqzat_yoA24bqsKpc7N7W_02lAKLdJcN7soBj-8H-7BerPqoRUMmNRK0sxiO9pgVPDl2NFAes8vk-4juk7ZGKOWwzlfGJLSoH_RSTCq6GPcdUnSjaCIWOxLtIBJqycNH_ydvx1Q9LQ3Hf4&amp;w=3840&amp;q=85"/></p><ul>
<li><strong>efSearch</strong>: This parameter is used during the search phase. Like efConstruction, a larger efSearch value results in more accurate search results at the cost of increased search time. This value should be equal or larger than k (the number of nearest neighbors you want to return).</li>
</ul>



<p>By default, <code>efConstruction</code> and <code>efSearch</code> are 32, but you can modify their values when you create the HNSW index:</p>


<div><pre><code><span>CREATE</span><span> </span><span>INDEX</span><span> </span><span>ON</span><span> vectors_hnsw </span><span>USING</span><span> hnsw </span><span>(</span><span>vec</span><span>)</span><span> </span><span>WITH</span><span> </span><span>(</span><span>maxelements </span><span>=</span><span> </span><span>1000000</span><span>,</span><span> dims</span><span>=</span><span>1536</span><span>,</span><span> m</span><span>=</span><span>32</span><span>,</span><span> efconstruction</span><span>=</span><span>32</span><span>,</span><span> efsearch</span><span>=</span><span>32</span><span>)</span><span>;</span></code></pre></div>


<h2>Which index should you pick?</h2>



<p>We compared both indexes using five criteria:</p>



<ul>
<li>Search speed</li>



<li>Accuracy</li>



<li>Memory usage</li>



<li>Index construction speed</li>



<li>Distance metrics</li>
</ul>



<p><img alt="Post image" loading="lazy" width="1024" height="616" decoding="async" data-nimg="1" sizes="(max-width: 767px) 100vw" srcset="/_next/image?url=https%3A%2F%2Fneon-hwp.dreamhosters.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fimage-21.png&amp;w=640&amp;q=85 640w, /_next/image?url=https%3A%2F%2Fneon-hwp.dreamhosters.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fimage-21.png&amp;w=750&amp;q=85 750w, /_next/image?url=https%3A%2F%2Fneon-hwp.dreamhosters.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fimage-21.png&amp;w=828&amp;q=85 828w, /_next/image?url=https%3A%2F%2Fneon-hwp.dreamhosters.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fimage-21.png&amp;w=1080&amp;q=85 1080w, /_next/image?url=https%3A%2F%2Fneon-hwp.dreamhosters.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fimage-21.png&amp;w=1200&amp;q=85 1200w, /_next/image?url=https%3A%2F%2Fneon-hwp.dreamhosters.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fimage-21.png&amp;w=1920&amp;q=85 1920w, /_next/image?url=https%3A%2F%2Fneon-hwp.dreamhosters.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fimage-21.png&amp;w=2048&amp;q=85 2048w, /_next/image?url=https%3A%2F%2Fneon-hwp.dreamhosters.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fimage-21.png&amp;w=3840&amp;q=85 3840w" src="https://neon.tech/_next/image?url=https%3A%2F%2Fneon-hwp.dreamhosters.com%2Fwp-content%2Fuploads%2F2023%2F07%2Fimage-21.png&amp;w=3840&amp;q=85"/></p><figure><table><tbody><tr><td></td><td>IVFFlat</td><td>HNSW</td></tr><tr><td>Search Speed</td><td>Fast, but the search speed depends on the number of clusters examined. More clusters mean higher accuracy but slower search times.</td><td>Typically faster than IVFFlat, especially in high-dimensional spaces, thanks to its graph-based nature.</td></tr><tr><td>Accuracy</td><td>Can achieve high accuracy but at the cost of examining more clusters and hence longer search times.</td><td>Generally achieves higher accuracy for the same memory footprint compared to IVFFlat.</td></tr><tr><td>Memory Usage</td><td>It uses relatively less memory since it only stores the centroids of clusters and the lists of vectors within these clusters.</td><td>Generally uses more memory because it maintains a graph structure with multiple layers.</td></tr><tr><td>Index Construction Speed</td><td>Index building process is relatively fast. The data points are assigned to the nearest centroid, and inverted lists are constructed. </td><td>Index construction involves building multiple layers of graphs, which can be computationally intensive, especially if you choose high values for the parameter ef_construction</td></tr><tr><td>Distance Metrics</td><td>Typically used for L2 distances, but pgvector supports inner product and cosine distance as well.</td><td>Only uses L2 distance metrics at the moment.</td></tr></tbody></table></figure>



<p>Your choice between the `pg_embedding` and the <code>pgvector</code> depends on your specific use case and requirements:</p>



<ul>
<li>Memory Constraints (<code>pgvector</code>): If you are working under strict memory constraints, you may opt for the IVFFlat index as it typically consumes less memory than HNSW. However, be mindful that this might come at the cost of search speed and accuracy.</li>
</ul>



<ul start="2">
<li>Search Speed (<code>pg_embedding</code>): If your primary concern is the speed at which you can retrieve nearest neighbors, especially in high-dimensional spaces, pg_embedding is likely the better choice due to its graph-based approach.</li>
</ul>



<ul start="3">
<li>Accuracy and Recall (<code>pg_embedding</code>): If achieving high accuracy and recall is critical for your application, pg_embedding may be the better option. HNSW’s graph-based approach generally yields higher recall levels compared to IVFFlat.</li>
</ul>



<ul start="4">
<li>Distance Metrics (<code>pgvector</code>): Both <code>pgvector</code> and <code>pg_embedding</code> support L2 distance metric. Additionally, <code>pgvector</code> supports the inner product, and cosine distance. </li>
</ul>



<h2>Conclusion</h2>



<p>With the introduction of the <code>pg_embedding</code> extension for Postgres, you now have a powerful new tool at your disposal for handling high-dimensional vector similarity searches efficiently within your database. The graph-based nature of the HNSW algorithm offers several advantages over the IVFFlat index in terms of search speed, accuracy, and ease of setup.</p>



<p>IVFFlat index with <code>pgvector</code> remains a viable choice for applications with stringent memory constraints but at the expense of recall.<br/></p>



<p>Ultimately, the choice between <code>pg_embedding</code> and <code>pgvector</code> with IVFFlat should be informed by the specific demands of your application. We encourage you to experiment with both approaches to find the one that best meets your needs.</p>



<p>We are excited to see the innovative applications you will develop with <code>pg_embedding</code> and look forward to your feedback! Stay tuned for further updates and enhancements.</p>
</div></div>
  </body>
</html>
