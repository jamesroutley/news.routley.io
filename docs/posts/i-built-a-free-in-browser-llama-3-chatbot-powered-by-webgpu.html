<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/abi/secret-llama">Original</a>
    <h1>Show HN: I built a free in-browser Llama 3 chatbot powered by WebGPU</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto"><a id="user-content-secret-llama" aria-label="Permalink: Secret Llama" href="#secret-llama"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/23818/327878509-0bf43a95-4fe5-4c53-87bc-b558e5c4968f.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTQ4NTQwMDMsIm5iZiI6MTcxNDg1MzcwMywicGF0aCI6Ii8yMzgxOC8zMjc4Nzg1MDktMGJmNDNhOTUtNGZlNS00YzUzLTg3YmMtYjU1OGU1YzQ5NjhmLmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MDQlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTA0VDIwMTUwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTUxOTRjZWNlMTI1YzYwN2RhNWE1NGM5ZDZiNTczMmYyMTE3NTA1MDc0YzhkMzJjZWJjOWMxZGM4NDk0NGZlYTEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.wxI7aYsgROXreDUe3mQxT71TsKk3BPPqn3Aa2AXtmUk"><img src="https://private-user-images.githubusercontent.com/23818/327878509-0bf43a95-4fe5-4c53-87bc-b558e5c4968f.gif?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTQ4NTQwMDMsIm5iZiI6MTcxNDg1MzcwMywicGF0aCI6Ii8yMzgxOC8zMjc4Nzg1MDktMGJmNDNhOTUtNGZlNS00YzUzLTg3YmMtYjU1OGU1YzQ5NjhmLmdpZj9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MDQlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTA0VDIwMTUwM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTUxOTRjZWNlMTI1YzYwN2RhNWE1NGM5ZDZiNTczMmYyMTE3NTA1MDc0YzhkMzJjZWJjOWMxZGM4NDk0NGZlYTEmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.wxI7aYsgROXreDUe3mQxT71TsKk3BPPqn3Aa2AXtmUk" alt="secret llama" data-animated-image=""/></a></p>
<p dir="auto">Entirely-in-browser, fully private LLM chatbot supporting Llama 3, Mistral and other open source models.</p>
<ul dir="auto">
<li>Fully private = No conversation data ever leaves your computer</li>
<li>Runs in the browser = No server needed and no install needed!</li>
<li>Works offline</li>
<li>Easy-to-use interface on par with ChatGPT, but for open source LLMs</li>
</ul>
<p dir="auto">Big thanks to the inference engine provided by <a href="https://github.com/mlc-ai/web-llm">webllm</a>.</p>
<p dir="auto">Join us on Discord</p>
<p dir="auto"><a href="https://discord.gg/nDjadD9U" rel="nofollow"><img src="https://camo.githubusercontent.com/80e4b2e36a198ef8a5ca34baae0eb519926e85e8e0ebd99ed3efb3ec10a1ac67/68747470733a2f2f646362616467652e76657263656c2e6170702f6170692f7365727665722f6e446a6164443955" alt="" data-canonical-src="https://dcbadge.vercel.app/api/server/nDjadD9U"/></a></p>
<div dir="auto"><h2 tabindex="-1" dir="auto">System Requirements</h2><a id="user-content-system-requirements" aria-label="Permalink: System Requirements" href="#system-requirements"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">To run this, you need a modern browser with support for WebGPU. According to <a href="https://caniuse.com/?search=WebGPU" rel="nofollow">caniuse</a>, WebGPU is supported on:</p>
<ul dir="auto">
<li>Google Chrome</li>
<li>Microsoft Edge</li>
</ul>
<p dir="auto">It&#39;s also available in Firefox, but it needs to be enabled manually through the dom.webgpu.enabled flag. Safari on MacOS also has experimental support for WebGPU which can be enabled through the WebGPU experimental feature.</p>
<p dir="auto">In addition to WebGPU support, various models might have specific RAM requirements.</p>
<div dir="auto"><h2 tabindex="-1" dir="auto">Try it out</h2><a id="user-content-try-it-out" aria-label="Permalink: Try it out" href="#try-it-out"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">You can <a href="https://secretllama.com" rel="nofollow">try it here</a>.</p>
<p dir="auto">To compile the React code yourself, download the repo and then, run</p>
<div data-snippet-clipboard-copy-content="yarn
yarn build-and-preview"><pre><code>yarn
yarn build-and-preview
</code></pre></div>
<p dir="auto">If you&#39;re looking to make changes, run the development environment with live reload:</p>
<div data-snippet-clipboard-copy-content="yarn
yarn dev"><pre><code>yarn
yarn dev
</code></pre></div>
<div dir="auto"><h2 tabindex="-1" dir="auto">Supported models</h2><a id="user-content-supported-models" aria-label="Permalink: Supported models" href="#supported-models"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<table>
<thead>
<tr>
<th>Model</th>
<th>Model Size</th>
</tr>
</thead>
<tbody>
<tr>
<td>TinyLlama-1.1B-Chat-v0.4-q4f32_1-1k</td>
<td>600MB</td>
</tr>
<tr>
<td>Llama-3-8B-Instruct-q4f16_1 ⭐</td>
<td>4.3GB</td>
</tr>
<tr>
<td>Phi1.5-q4f16_1-1k</td>
<td>1.2GB</td>
</tr>
<tr>
<td>Mistral-7B-Instruct-v0.2-q4f16_1 ⭐</td>
<td>4GB</td>
</tr>
</tbody>
</table>
<div dir="auto"><h2 tabindex="-1" dir="auto">Looking for contributors</h2><a id="user-content-looking-for-contributors" aria-label="Permalink: Looking for contributors" href="#looking-for-contributors"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">We would love contributions to improve the interface, support more models, speed up initial model loading time and fix bugs.</p>
<div dir="auto"><h2 tabindex="-1" dir="auto">Other Projects by Author</h2><a id="user-content-other-projects-by-author" aria-label="Permalink: Other Projects by Author" href="#other-projects-by-author"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Check out <a href="https://github.com/abi/screenshot-to-code">screenshot to code</a> and <a href="https://picoapps.xyz" rel="nofollow">Pico - AI-powered app builder</a></p>
</article></div></div>
  </body>
</html>
