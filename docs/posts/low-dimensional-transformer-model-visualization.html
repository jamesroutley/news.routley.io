<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://samuelselleck.com/blog/visual-explanation-of-transformers/">Original</a>
    <h1>Low-Dimensional Transformer Model Visualization</h1>
    
    <div id="readability-page-1" class="page"><div><p>I’ve tried to learn the details of the transformer architecture the last couple weeks. Some resources I found useful:</p><ul><li><a href="https://www.youtube.com/watch?v=bOYE6E8JrtU">Neel Nandas youtube videos</a> - good to double check understanding of details/implement it yourself. Everything is done in tensor operations.</li><li><a href="https://blog.nelhage.com/post/transformers-for-software-engineers/">Nelson Elhages blog post</a> - a different (non-matrix math) perspective, where he walks through a template implementation in Rust. Easier to understand if you know coding but don’t feel as confident manipulating tensors. Also just gives another perspective.</li><li><a href="https://transformer-circuits.pub/2021/framework/index.html">paper: A Mathematical Framework for Transformer Circuits</a> - Gives a lot of intuitive explanations for how information flows in a Transformer.</li></ul><p>In the spirit of the saying “A picture says a thousand words”, I decided to try to draw a visualization of the parts I found the hardest to understand:</p><ul><li>The overall information flow between different parts in the model</li><li>How self-attention heads work.</li></ul><p>Each line in the diagram below depicts one (usually floating point) number passing through the model. OBS: there are some parts that are left out to de-clutter the picture (for example layer normalization).</p><p><img alt="Transformer Diagram" src="https://github.com/transformer_visual.svg"/></p><p>For comparison/reference, here are the hypothetical model parameters:</p><pre><code><span>residual stream/model dimension: 3
</span><span>internal head dimension: 2
</span><span>number of heads: 2
</span><span>number of [Attention + MLP] layers: 2
</span><span>context length (in tokens): 2
</span></code></pre><p>Hope this helps someone! If you have any questions/error corrections, send me an email.</p></div></div>
  </body>
</html>
