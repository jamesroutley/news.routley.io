<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.definite.app/blog/smallpond">Original</a>
    <h1>DeepSeek releases distributed DuckDB</h1>
    
    <div id="readability-page-1" class="page"><div><p><span>March 2, 2025</span><span>10 minute read</span></p><p>Mike Ritchie</p></div><div><p>I didn&#39;t have &#34;DeepSeek releases distributed DuckDB&#34; on my 2025 bingo card.</p>
<p>You may have stumbled across <a href="https://github.com/deepseek-ai/smallpond">smallpond</a> from Twitter/X/LinkedIn hype. From that hype, you might have concluded Databricks and Snowflake are dead ðŸ˜‚. Not so fast. The reality is, although this is interesting and powerful open source tech, it&#39;s unlikely to be widely used in analytics anytime soon. Here&#39;s a concise breakdown to help you cut through the noise.</p>
<p>We&#39;ll cover what <code>smallpond</code> and its companion, <code>3FS</code>, are, how you can (maybe) use them, and if they&#39;re suitable for your use case.</p>
<h3>What is <code>smallpond</code>?</h3>
<p><code>smallpond</code> is a lightweight, distributed data processing framework recently introduced by DeepSeek AI. It extends DuckDBâ€”typically a high-performance, single-node analytics databaseâ€”to handle larger datasets across multiple nodes. <code>smallpond</code> enables DuckDB to manage distributed workloads by using a distributed storage and compute system.</p>
<p>Key features:</p>
<ul>
<li><strong>Distributed Analytics</strong>: Allows DuckDB to handle larger-than-memory datasets by partitioning data and running analytics tasks in parallel.</li>
<li><strong>Open Source Deployment</strong>: If you can manage to get it running, 3FS would give you powerful and performant storage at a fraction of the cost of alternatives.</li>
<li><strong>Manual Partitioning</strong>: Data is manually partitioned by users, and <code>smallpond</code> distributes these partitions across nodes for parallel processing.</li>
</ul>
<h3>What is 3FS?</h3>
<p>3FS, or Fire-Flyer File System, is a high-performance parallel file system also developed by DeepSeek. It&#39;s optimized specifically for AI and HPC workloads, offering extremely high throughput and low latency by using SSDs and RDMA networking technology. Think of 3FS as the high-speed, distributed storage backend that <code>smallpond</code> leverages for fast, scalable analytics.</p>
<p>Key features:</p>
<ul>
<li><strong>High Performance</strong>: Achieves multi-terabyte-per-minute throughput, ideal for massive datasets.</li>
<li><strong>Optimized for AI workloads</strong>: Delivers consistent, high-speed data access, minimizing bottlenecks common in other storage systems.</li>
<li><strong>Open-source but Complex</strong>: Powerful yet requires specialized hardware and significant expertise to deploy effectively.</li>
</ul>
<h3>How Can I Use It?</h3>
<p>Using <code>smallpond</code> and 3FS depends largely on your data size and infrastructure:</p>
<ul>
<li><strong>Under 10TB</strong>: <code>smallpond</code> is likely unnecessary unless you have very specific distributed computing needs. A single-node DuckDB instance or simpler storage solutions will be simpler and possibly more performant.</li>
<li><strong>10TB to 1PB</strong>: <code>smallpond</code> begins to shine. You&#39;d set up a cluster with several nodes, leveraging 3FS or another fast storage backend to achieve rapid parallel processing.</li>
<li><strong>Over 1PB (Petabyte-Scale)</strong>: <code>smallpond</code> and 3FS were explicitly designed to handle massive datasets. At this scale, you&#39;d need to deploy a larger cluster with substantial infrastructure investments.</li>
</ul>
<p>Deployment typically involves:</p>
<ol>
<li>Setting up a compute cluster (AWS EC2, Google Compute Engine, or on-prem).</li>
<li>Deploying 3FS on nodes with high-performance SSDs and RDMA networking.</li>
<li>Installing <code>smallpond</code> via Python to run distributed DuckDB tasks across your cluster.</li>
</ol>
<p>Steps #1 and #3 are really easy. Step #2 is <strong>very</strong> hard. 3FS is new, so there&#39;s no guide on how you would set it up on AWS (if that&#39;s even possible). You could certainly deploy it on bare metal, but you&#39;d be descending into a lower level of DevOps hell.</p>
<blockquote>
<p>Note: if you&#39;re in the 95% of companies in the under 10TB bucket, you should really try <a href="https://www.definite.app/">Definite</a>.</p>
</blockquote>
<p>I experimented with running <code>smallpond</code> with S3 swapped in for 3FS <a href="https://github.com/definite-app/smallpond">here</a>, but it&#39;s unclear what, if any, performance gains you&#39;d get over scaling up a single node for moderate-sized data.</p>
<h3>Is <code>smallpond</code> for me?</h3>
<p><strong>tl;dr: probably not.</strong></p>
<p>Whether you&#39;d want to use <code>smallpond</code> depends on several factors:</p>
<ul>
<li><strong>Your Data Scale</strong>: If your dataset is under 10TB, <code>smallpond</code> adds unnecessary complexity and overhead. For larger datasets (&gt;10TB), it provides substantial performance advantages.</li>
<li><strong>Infrastructure Capability</strong>: <code>smallpond</code> and 3FS require significant infrastructure and DevOps expertise. Without a dedicated team experienced in cluster management, this could be challenging.</li>
<li><strong>Analytical Complexity</strong>: <code>smallpond</code> excels at partition-level parallelism but is less optimized for complex distributed joins. For workloads requiring intricate joins across partitions, performance might be limited.</li>
</ul>
<h3>How Smallpond Works (Under the Hood)</h3>
<p><strong>Lazy DAG Execution</strong></p>
<p>Nothing actually happens until you trigger execution explicitly with actions like:</p>
<ul>
<li><code>write_parquet()</code> â€” Writes data to disk</li>
<li><code>to_pandas()</code> â€” Converts results to a pandas DataFrame</li>
<li><code>compute()</code> â€” Forces computation explicitly</li>
<li><code>count()</code> â€” Counts rows</li>
<li><code>take()</code> â€” Retrieves a subset of rows</li>
</ul>
<p>This lazy evaluation is efficient because it avoids unnecessary computations and optimizes the workflow.</p>
<p><strong>From Logical to Execution Plan</strong></p>
<p><strong>Ray Core and Distribution</strong></p>
<ul>
<li><strong>Hash partitioning</strong> (based on column values)</li>
<li><strong>Even partitioning</strong> (by files or row counts)</li>
<li><strong>Random shuffle partitioning</strong></li>
</ul>
<p>Each partition runs independently within its own Ray task, using DuckDB instances to process SQL queries. This tight integration with Ray emphasizes horizontal scaling (adding more nodes) rather than vertical scaling (larger, more powerful nodes). To use it at scale, youâ€™ll need a Ray cluster. You can run one on your own infrastructure on a cloud provider (e.g. AWS), but if you just want to test this out, it&#39;ll be easier to get started with Anyscale (founded by Ray creators).</p>
<h3>Conclusion</h3>
<p><code>smallpond</code> and 3FS offer powerful capabilities for scaling DuckDB analytics across large datasets. However, their complexity and infrastructure demands mean they&#39;re best suited for scenarios where simpler solutions no longer suffice. If you&#39;re managing massive datasets and already have robust DevOps support, <code>smallpond</code> and 3FS could significantly enhance your analytics capabilities. For simpler scenarios, sticking with a single-node DuckDB instance or using managed solutions remains your best option.</p></div></div>
  </body>
</html>
