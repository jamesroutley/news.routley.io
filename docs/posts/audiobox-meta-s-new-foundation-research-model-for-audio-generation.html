<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://ai.meta.com/blog/audiobox-generating-audio-voice-natural-language-prompts/">Original</a>
    <h1>Audiobox: Meta&#39;s new foundation research model for audio generation</h1>
    
    <div id="readability-page-1" class="page"><div><p>Takeaways</p><div><ul><p>RECOMMENDED READS</p><li><a href="https://ai.meta.com/blog/voicebox-generative-ai-model-speech/" data-ms-clickable="true" data-ms="{&#34;creative&#34;:&#34;click_external&#34;}" target="_self" data-lnfb-mode="ie"><svg viewBox="0 0 38 38" fill="none" xmlns="http://www.w3.org/2000/svg"><path opacity="0.4" fill-rule="evenodd" clip-rule="evenodd" d="M19 37C9.05887 37 1 28.9411 1 19C1 9.05887 9.05887 1 19 1C28.9411 1 37 9.05887 37 19C37 28.9411 28.9411 37 19 37Z" stroke="CurrentColor"></path><path d="M21.9657 12L28.9287 18.963L21.9657 25.926L20.7348 24.7193L25.6203 19.8334L10.0001 19.8334V18.0926L25.5966 18.0926L20.7348 13.2309L21.9657 12Z" fill="CurrentColor"></path><path d="M21.9657 12L28.9287 18.963L21.9657 25.926L20.7348 24.7193L25.6203 19.8334L10.0001 19.8334V18.0926L25.5966 18.0926L20.7348 13.2309L21.9657 12Z" fill="CurrentColor"></path></svg><p>Introducing Voicebox: The first generative AI model for speech to generalize across tasks with state-of-the-art performance</p></a></li><li><a href="https://ai.meta.com/blog/seamless-m4t/" data-ms-clickable="true" data-ms="{&#34;creative&#34;:&#34;click_external&#34;}" target="_self" data-lnfb-mode="ie"><svg viewBox="0 0 38 38" fill="none" xmlns="http://www.w3.org/2000/svg"><path opacity="0.4" fill-rule="evenodd" clip-rule="evenodd" d="M19 37C9.05887 37 1 28.9411 1 19C1 9.05887 9.05887 1 19 1C28.9411 1 37 9.05887 37 19C37 28.9411 28.9411 37 19 37Z" stroke="CurrentColor"></path><path d="M21.9657 12L28.9287 18.963L21.9657 25.926L20.7348 24.7193L25.6203 19.8334L10.0001 19.8334V18.0926L25.5966 18.0926L20.7348 13.2309L21.9657 12Z" fill="CurrentColor"></path><path d="M21.9657 12L28.9287 18.963L21.9657 25.926L20.7348 24.7193L25.6203 19.8334L10.0001 19.8334V18.0926L25.5966 18.0926L20.7348 13.2309L21.9657 12Z" fill="CurrentColor"></path></svg><p>Bringing the world closer together with a foundational multimodal model for speech translation</p></a></li><li><a href="https://ai.meta.com/blog/audiocraft-musicgen-audiogen-encodec-generative-ai-audio/" data-ms-clickable="true" data-ms="{&#34;creative&#34;:&#34;click_external&#34;}" target="_self" data-lnfb-mode="ie"><svg viewBox="0 0 38 38" fill="none" xmlns="http://www.w3.org/2000/svg"><path opacity="0.4" fill-rule="evenodd" clip-rule="evenodd" d="M19 37C9.05887 37 1 28.9411 1 19C1 9.05887 9.05887 1 19 1C28.9411 1 37 9.05887 37 19C37 28.9411 28.9411 37 19 37Z" stroke="CurrentColor"></path><path d="M21.9657 12L28.9287 18.963L21.9657 25.926L20.7348 24.7193L25.6203 19.8334L10.0001 19.8334V18.0926L25.5966 18.0926L20.7348 13.2309L21.9657 12Z" fill="CurrentColor"></path><path d="M21.9657 12L28.9287 18.963L21.9657 25.926L20.7348 24.7193L25.6203 19.8334L10.0001 19.8334V18.0926L25.5966 18.0926L20.7348 13.2309L21.9657 12Z" fill="CurrentColor"></path></svg><p>Open sourcing AudioCraft: Generative AI for audio made simple and available to all	</p></a></li></ul><div><p>Earlier this year, Meta introduced <a href="https://ai.meta.com/blog/voicebox-generative-ai-model-speech/" target="_blank" data-lnfb-mode="ie">Voicebox</a>, a state-of-the-art AI model that can perform speech generation tasks like editing, sampling, and stylizing. It was a breakthrough in generative AI in that it could generalize to speech-generation tasks it wasn’t specifically trained to accomplish — and execute these tasks with state-of-the-art performance.</p><p>Now, Audiobox, the successor to Voicebox, is advancing generative AI for audio even further by unifying generation and editing capabilities for speech, sound effects (short, discrete sounds like a dog bark, car horn, a crack of thunder, etc.), and soundscapes, with a variety of input mechanisms to maximize controllability for each use case.</p><p>Most notably, Audiobox lets people use natural language prompts to describe a sound or type of speech they want to generate. If someone wants to generate a soundscape, for example, they can give the model a text prompt like, “A running river and birds chirping.”</p></div></div><div><div><div data-testid="responsive-video" id="u_0_a_5n"><p><img data-testid="poster-image"/></p><video src="https://video-iad3-2.xx.fbcdn.net/v/t39.25447-2/406230596_1591381338063527_4421644657945325266_n.mp4?_nc_cat=109&amp;vs=60f72173a05c9190&amp;_nc_vs=HBksFQAYJEdFU1dOaGluZ2x0WFdxY0ZBTkt1MWJkajFsdzlibWRqQUFBRhUAAsgBABUAGCRHS1dwSnhnT1hGQ3FOZDREQUVoZTRtWXY2ODloYnY0R0FBQUYVAgLIAQBLB4gScHJvZ3Jlc3NpdmVfcmVjaXBlATENc3Vic2FtcGxlX2ZwcwAQdm1hZl9lbmFibGVfbnN1YgAgbWVhc3VyZV9vcmlnaW5hbF9yZXNvbHV0aW9uX3NzaW0AKGNvbXB1dGVfc3NpbV9vbmx5X2F0X29yaWdpbmFsX3Jlc29sdXRpb24AHXVzZV9sYW5jem9zX2Zvcl92cW1fdXBzY2FsaW5nABFkaXNhYmxlX3Bvc3RfcHZxcwAVACUAHIwXQAAAAAAAAAAREQAAACbG666n0dSnARUCKAJDMxgLdnRzX3ByZXZpZXccF0Am7peNT987GCFkYXNoX2dlbjJod2Jhc2ljX2hxMl9mcmFnXzJfdmlkZW8SABgYdmlkZW9zLnZ0cy5jYWxsYmFjay5wcm9kOBJWSURFT19WSUVXX1JFUVVFU1QbCogVb2VtX3RhcmdldF9lbmNvZGVfdGFnBm9lcF9oZBNvZW1fcmVxdWVzdF90aW1lX21zATAMb2VtX2NmZ19ydWxlB3VubXV0ZWQTb2VtX3JvaV9yZWFjaF9jb3VudAUxMTczNxFvZW1faXNfZXhwZXJpbWVudAAMb2VtX3ZpZGVvX2lkDzg4NjEyODE5OTcxMTU1NBJvZW1fdmlkZW9fYXNzZXRfaWQPODUxNTExNjQ2NzUyOTgzFW9lbV92aWRlb19yZXNvdXJjZV9pZA8zNjg2OTA5MDU2MDI3ODccb2VtX3NvdXJjZV92aWRlb19lbmNvZGluZ19pZBAxNDIwNDYxNTk4ODE5NzQxDnZ0c19yZXF1ZXN0X2lkACUCHAAlvgEbB4gBcwQ3MTY1AmNkCjIwMjMtMTEtMjkDcmNiBTExNzAwA2FwcAVWaWRlbwJjdBFDTVNfTUVESUFfTUFOQUdFUhNvcmlnaW5hbF9kdXJhdGlvbl9zCTExLjQ5ODY2NwJ0cxVwcm9ncmVzc2l2ZV9lbmNvZGluZ3MA&amp;ccb=1-7&amp;_nc_sid=4a9f44&amp;efg=eyJ2ZW5jb2RlX3RhZyI6Im9lcF9oZCJ9&amp;_nc_ohc=HnvEDiZHYxoAX9DR-Jg&amp;_nc_ht=video-iad3-2.xx&amp;oh=00_AfA_TXJDMvDFrthw62GWfcLI3hWnwFNveT6h2Nze5t2G8g&amp;oe=657A1927&amp;_nc_rid=107350826557476&amp;_nc_store_type=0" controls="1" poster="https://scontent-iad3-2.xx.fbcdn.net/v/t15.5256-10/406530583_728741742029580_2785726758313376817_n.jpg?_nc_cat=109&amp;ccb=1-7&amp;_nc_sid=e3495b&amp;_nc_ohc=anZxSfQX2MIAX_ppTVW&amp;_nc_ht=scontent-iad3-2.xx&amp;oh=00_AfCTp1adhd2Enh-Fd1jWREwYIDQrM3FhPSfhQB7UN3gD1w&amp;oe=657B7318" width="1920" height="1080" controlslist="nodownload" id="u_0_d_7s"></video></div></div></div><div><p>Describe-and-generate sound: Users can provide a short description of the desired sound and ask the model to generate it.</p></div><p>Similarly, to generate a voice, a user might input, “A young woman speaks with a high pitch and fast pace.” </p><div><p>Describe-and-generate speech: Users can provide a short description of the desired voice, along with the transcript to be narrated, and ask the model to generate speech.</p></div><p>The model also allows users to combine an audio voice input with a text style prompt to synthesize speech of <i>that voice</i> in any environment (e.g., “in a cathedral”) or any emotion (e.g., “speaks sadly and slowly”). To our knowledge, Audiobox is the <i>first </i>model to enable dual input (voice prompts and text description prompts) for freeform voice restyling.</p><div><p>Vocal restylization: Audiobox can restyle a voice to make it sound as though it’s in a different environment — in a large cathedral in this example.</p></div><p>Audiobox demonstrates state-of-the-art controllability on speech and sound effects generation. Our own tests show it significantly surpasses prior best models (AudioLDM2, VoiceLDM, and TANGO) on quality and relevance (faithfulness to text description) in subjective evaluations. Audiobox outperforms Voicebox on style similarity by over 30 percent on a variety of speech styles.</p><p>Why we created Audiobox</p><div><p>Audio plays a fundamental role in many forms of media, from movies to podcasts, audiobooks, and video games. But producing quality audio can often be a challenging process that requires access to extensive sound libraries as well as deep domain expertise (sound engineering, foley, voice acting, etc.) to yield optimal results — expertise that the public, or even hobbyists, may not possess.</p><p>We’re releasing Audiobox to a hand-selected group of researchers and academic institutions with a track record in speech research to help further the state of the art in this research area and ensure we have a diverse set of partners to tackle the responsible AI aspects of this work. In the future, we believe research breakthroughs like Audiobox will lower the barrier of accessibility for audio creation and make it easy for anyone to become an audio content creator. Creators could use models like Audiobox to generate soundscapes for videos or podcasts, custom sound effects for games, or any of a number of other use cases.</p></div></div><div><p>Audiobox’s capabilities</p><p>While Audiobox is built on top of the Voicebox framework, it can generate a larger variety of sounds, including speech in various environments and styles, non-speech sound effects, and soundscapes.</p><div><p>Describe-and-generate speech: A text prompt can be used to describe not only a voice, but also the acoustic environment, such as, “in a large cathedral” in this example.</p></div><div><p>Being able to use text and voice inputs also greatly enhances Audiobox’s controllability compared to Voicebox. Audiobox users can use text description prompts to specify the <i>style </i>of speech and sound effects, a feature that was not supported in Voicebox. When a voice input and text prompt are used together, the voice input anchors the timbre, and the text prompt can be used to change other aspects.</p><p>Audiobox inherits Voicebox’s guided audio generation training objective and <a href="https://openreview.net/pdf?id=PqvMRDCJT9t" target="_blank" data-lnfb-mode="ie">flow-matching modeling method</a> to allow for audio infilling. With infilling, users can also use the model to polish sound effects (adding different thunder sounds into a raining soundscape, for example).</p></div><div><p>Sound editing with generative infilling: Users can crop an audio segment and regenerate it with Audiobox. By providing a text description, Audiobox can insert sound effects like “a dog barking” into an audio clip of the sound of rain.</p></div><div><p><img src="https://scontent-iad3-1.xx.fbcdn.net/v/t39.8562-6/399488364_1032683441185355_2471969076072743996_n.png?_nc_cat=104&amp;ccb=1-7&amp;_nc_sid=f537c7&amp;_nc_ohc=-4RCaVtVBmwAX-8jImN&amp;_nc_ht=scontent-iad3-1.xx&amp;oh=00_AfCK6XbCSd1BwYTjzehdFMKB5ON3lzWIUQ9g4OiUYhRMDw&amp;oe=657A8ECD" alt="" id="u_0_q_A3"/></p></div><p>Our invitation to collaborate on responsible research</p><div><p>AI for audio generation has made significant progress over the past year. But, as with all AI innovations, we must work to help ensure responsible use. The known issues with AI cannot be addressed by any individual or single organization alone. That’s why collaboration with the research community on state-of-the-art models is more important now than ever.</p><p>For these tools to be better and safer for everyone, the AI community must be empowered to build on top of our work and continue to develop these innovations responsibly. But access must be shared in the right way. To honor this and our ongoing commitment to open science, we’re releasing Audiobox under a research-only license to a limited number of hand-selected researchers and institutions.</p><p>We’re inviting researchers and institutions who have been previously involved in speech research, and who want to pursue responsibility and safety research on the latest Audiobox models, to apply.</p><p>In the coming weeks, we will be opening up the <a href="https://ai.meta.com/research/audiobox-responsible-generation-grant/" target="_blank" data-lnfb-mode="ie">application here</a>, along with an interactive demo that will showcase Audiobox’s capabilities.</p></div><p>Implementing Audiobox responsibly</p><div><p>Tools like Audiobox can raise concerns about voice impersonation or other abuses. As part of our commitment to building generative AI features responsibly, we’ve implemented new technologies to help address these issues.</p><p>Both the Audiobox model and our interactive demo will feature automatic audio watermarking so any audio created with Audiobox can be accurately traced to its origin. Our watermarking method embeds a signal into the audio that’s imperceptible to the human ear but can be detected all the way down to the frame level using a model capable of finding AI-generated segments in audio.</p><p>We’ve tested this method against a broad range of attacks and found it to be more robust than even current state-of-the-art solutions, making it extremely difficult for bad actors to try and bypass detection by modifying the AI-generated audio.</p><p>Additionally, similar to how websites use CAPTCHAs to deter bots and spam, our upcoming interactive demo includes a voice authentication feature to safeguard against impersonation. Anyone who wants to add a voice to the Audiobox demo will have to speak a voice prompt using their own voice. The prompt changes at regular, rapid intervals and makes it extremely difficult to add someone else’s voice with pre-recorded audio.</p><p>To help ensure robustness across different groups of speakers, we tested the performance of Audiobox on speakers of different genders and with different native languages and verified that the performance is close across all groups of speakers.</p></div><p>Future use cases for Audiobox</p><div><p>In the long term, it will be crucial to move from building specialized audio generative models that can only generate one type of audio (such as speech or sound) to building generalized audio generative models that can generate <i>any </i>audio. With such models we can perform<i> any generative audio task</i> that requires understanding beyond a single modality. This will make it simpler for developers to build towards a more dynamic and wide range of use cases.</p><p>Audiobox is an importantstep toward democratizing audio generation. We envision a future where everyone can more easily and efficiently create audio that is tailored to their use cases. Our hope is that we can see the same creativity sparked by advancements in text and image generation happen for audio as well, for both professionals and hobbyists. Content creation, narration, sound editing, game development, and even AI chatbots can all benefit from the capabilities of audio generation models.</p></div><p><i>This blog post was made possible by the work of Akinniyi Akinyemi, Alice Rakotoarison, Andros Tjandra, Apoorv Vyas, Baishan Guo, Bapi Akula, Bowen Shi, Brian Ellis, Carleigh Wood, Chris Summers, Ivan Cruz, Joshua Lane, Jeff Wang, Jiemin Zhang, Liang Tan, Mary Williamson, Matt Le, Rashel Moritz, Robbie Adkins, Wei-Ning Hsu, William Ngan, Xinyue Zhang, Yael Yungster, and Yi-Chiao Wu.</i></p></div></div>
  </body>
</html>
