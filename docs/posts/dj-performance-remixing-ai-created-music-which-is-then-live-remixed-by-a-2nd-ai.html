<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://qosmo.jp/en/projects/ai-dj-project2-ubiquitous-rhythm/">Original</a>
    <h1>DJ performance remixing AI-created music- which is then live-remixed by a 2nd AI</h1>
    
    <div id="readability-page-1" class="page"><div>
                    
<h2>PERFORMANCE</h2>



<figure><p>
<iframe src="https://player.vimeo.com/video/638949287?h=17e0a3b455&amp;dnt=1&amp;app_id=122963" width="500" height="281" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen=""></iframe>
</p><figcaption>AI DJ Project#2 Ubiquitous Rhythm (digest)</figcaption></figure>







<h2>OVERVIEW</h2>



<p>AI DJ Project#2 Ubiquitous Rhythm is an improvisational DJ performance that uses AI to generate music in real-time. Without preparing music sequences in advance, the DJ controls the music composed (generated) by the AI on the spot, another AI reacts to the sound, and the performance unfolds. The complex interaction between the multiple AI models and the DJ creates a unique and organic musical experience.</p>



<p>AI continuously generates two-bar rhythm patterns and corresponding basslines within this performance. Another AI model also keeps selecting loops that fit the rhythm and bassline.  The DJ listens to the AI-generated parts and adjusts the sound of the drum machine and synthesizer on the spot. The DJ also controls the volume and audio effects of each track to build up the musical development. </p>







<figure><ul><li><figure><img src="https://qosmo.jp/wp-content/uploads/2021/10/aidj_23-scaled.jpg" alt="" data-id="5949" data-link="https://qosmo.jp/?attachment_id=5949" srcset="https://qosmo.jp/wp-content/uploads/2021/10/aidj_23-scaled.jpg 2560w, https://qosmo.jp/wp-content/uploads/2021/10/aidj_23-300x169.jpg 300w, https://qosmo.jp/wp-content/uploads/2021/10/aidj_23-1024x576.jpg 1024w, https://qosmo.jp/wp-content/uploads/2021/10/aidj_23-768x432.jpg 768w, https://qosmo.jp/wp-content/uploads/2021/10/aidj_23-1536x864.jpg 1536w, https://qosmo.jp/wp-content/uploads/2021/10/aidj_23-2048x1152.jpg 2048w" sizes="(max-width: 2560px) 100vw, 2560px"/></figure></li><li><figure><img src="https://qosmo.jp/wp-content/uploads/2021/10/aidj_02-scaled.jpg" alt="" data-id="5950" data-link="https://qosmo.jp/?attachment_id=5950" srcset="https://qosmo.jp/wp-content/uploads/2021/10/aidj_02-scaled.jpg 2560w, https://qosmo.jp/wp-content/uploads/2021/10/aidj_02-300x169.jpg 300w, https://qosmo.jp/wp-content/uploads/2021/10/aidj_02-1024x576.jpg 1024w, https://qosmo.jp/wp-content/uploads/2021/10/aidj_02-768x432.jpg 768w, https://qosmo.jp/wp-content/uploads/2021/10/aidj_02-1536x864.jpg 1536w, https://qosmo.jp/wp-content/uploads/2021/10/aidj_02-2048x1152.jpg 2048w" sizes="(max-width: 2560px) 100vw, 2560px"/></figure></li><li><figure><img src="https://qosmo.jp/wp-content/uploads/2021/10/aidj_22-scaled.jpg" alt="" data-id="5951" data-link="https://qosmo.jp/?attachment_id=5951" srcset="https://qosmo.jp/wp-content/uploads/2021/10/aidj_22-scaled.jpg 2560w, https://qosmo.jp/wp-content/uploads/2021/10/aidj_22-300x169.jpg 300w, https://qosmo.jp/wp-content/uploads/2021/10/aidj_22-1024x576.jpg 1024w, https://qosmo.jp/wp-content/uploads/2021/10/aidj_22-768x432.jpg 768w, https://qosmo.jp/wp-content/uploads/2021/10/aidj_22-1536x864.jpg 1536w, https://qosmo.jp/wp-content/uploads/2021/10/aidj_22-2048x1153.jpg 2048w" sizes="(max-width: 2560px) 100vw, 2560px"/></figure></li><li><figure><img src="https://qosmo.jp/wp-content/uploads/2021/10/image-1-300x169.png" alt="" data-id="5952" data-link="https://qosmo.jp/?attachment_id=5952" srcset="https://qosmo.jp/wp-content/uploads/2021/10/image-1-300x169.png 300w, https://qosmo.jp/wp-content/uploads/2021/10/image-1-1024x576.png 1024w, https://qosmo.jp/wp-content/uploads/2021/10/image-1-768x432.png 768w, https://qosmo.jp/wp-content/uploads/2021/10/image-1-1536x864.png 1536w, https://qosmo.jp/wp-content/uploads/2021/10/image-1.png 1920w" sizes="(max-width: 300px) 100vw, 300px"/></figure></li><li><figure><img src="https://qosmo.jp/wp-content/uploads/2021/11/aidj_sub_01.jpg" alt="" data-id="6188" data-full-url="https://qosmo.jp/wp-content/uploads/2021/11/aidj_sub_01.jpg" data-link="https://qosmo.jp/en/projects/ai-dj-project2-ubiquitous-rhythm/attachment/aidj_sub_01/" srcset="https://qosmo.jp/wp-content/uploads/2021/11/aidj_sub_01.jpg 1920w, https://qosmo.jp/wp-content/uploads/2021/11/aidj_sub_01-300x169.jpg 300w, https://qosmo.jp/wp-content/uploads/2021/11/aidj_sub_01-1024x576.jpg 1024w, https://qosmo.jp/wp-content/uploads/2021/11/aidj_sub_01-768x432.jpg 768w, https://qosmo.jp/wp-content/uploads/2021/11/aidj_sub_01-1536x864.jpg 1536w" sizes="(max-width: 1920px) 100vw, 1920px"/></figure></li><li><figure><img src="https://qosmo.jp/wp-content/uploads/2021/11/aidj_sub_02.jpg" alt="" data-id="6189" data-full-url="https://qosmo.jp/wp-content/uploads/2021/11/aidj_sub_02.jpg" data-link="https://qosmo.jp/en/projects/ai-dj-project2-ubiquitous-rhythm/attachment/aidj_sub_02/" srcset="https://qosmo.jp/wp-content/uploads/2021/11/aidj_sub_02.jpg 1920w, https://qosmo.jp/wp-content/uploads/2021/11/aidj_sub_02-300x169.jpg 300w, https://qosmo.jp/wp-content/uploads/2021/11/aidj_sub_02-1024x576.jpg 1024w, https://qosmo.jp/wp-content/uploads/2021/11/aidj_sub_02-768x432.jpg 768w, https://qosmo.jp/wp-content/uploads/2021/11/aidj_sub_02-1536x864.jpg 1536w" sizes="(max-width: 1920px) 100vw, 1920px"/></figure></li><li><figure><img src="https://qosmo.jp/wp-content/uploads/2021/11/aidj_sub_03.jpg" alt="" data-id="6190" data-full-url="https://qosmo.jp/wp-content/uploads/2021/11/aidj_sub_03.jpg" data-link="https://qosmo.jp/en/projects/ai-dj-project2-ubiquitous-rhythm/attachment/aidj_sub_03/" srcset="https://qosmo.jp/wp-content/uploads/2021/11/aidj_sub_03.jpg 1920w, https://qosmo.jp/wp-content/uploads/2021/11/aidj_sub_03-300x169.jpg 300w, https://qosmo.jp/wp-content/uploads/2021/11/aidj_sub_03-1024x576.jpg 1024w, https://qosmo.jp/wp-content/uploads/2021/11/aidj_sub_03-768x432.jpg 768w, https://qosmo.jp/wp-content/uploads/2021/11/aidj_sub_03-1536x864.jpg 1536w" sizes="(max-width: 1920px) 100vw, 1920px"/></figure></li></ul></figure>







<h2>BACKGROUND</h2>



<p>Since around 2015, We have been <a href="https://qosmo.jp/en/projects/ai-dj-human-dj-b2b/">developing an AI DJ system and giving DJ performances worldwide</a>. By having a human DJ (mainly Tokui, the CEO of Qosmo) and the AI take turns selecting songs one at a time, the project was designed to realize a true “interaction” and “communication” between humans and AI through music.</p>







<div>
<div>
<figure><img src="https://qosmo.jp/wp-content/uploads/2019/06/IO_19_Tues_Morning_3163-1-1024x683.jpg" alt="" srcset="https://qosmo.jp/wp-content/uploads/2019/06/IO_19_Tues_Morning_3163-1-1024x683.jpg 1024w, https://qosmo.jp/wp-content/uploads/2019/06/IO_19_Tues_Morning_3163-1-300x200.jpg 300w, https://qosmo.jp/wp-content/uploads/2019/06/IO_19_Tues_Morning_3163-1-768x512.jpg 768w" sizes="(max-width: 1024px) 100vw, 1024px"/><figcaption>Google I/O 2019 Keynote Preshow</figcaption></figure>




</div>







<div>
<figure><img src="https://qosmo.jp/wp-content/uploads/sites/2/2018/08/02_-AI-DJ-Project@Yasuhiro-Tani-Courtesy-of-Yamaguchi-Center-for-Arts-and-Media-YCAM-1024x683.jpg" alt="" srcset="https://qosmo.jp/wp-content/uploads/sites/2/2018/08/02_-AI-DJ-Project@Yasuhiro-Tani-Courtesy-of-Yamaguchi-Center-for-Arts-and-Media-YCAM-1024x683.jpg 1024w, https://qosmo.jp/wp-content/uploads/sites/2/2018/08/02_-AI-DJ-Project@Yasuhiro-Tani-Courtesy-of-Yamaguchi-Center-for-Arts-and-Media-YCAM-300x200.jpg 300w, https://qosmo.jp/wp-content/uploads/sites/2/2018/08/02_-AI-DJ-Project@Yasuhiro-Tani-Courtesy-of-Yamaguchi-Center-for-Arts-and-Media-YCAM-768x512.jpg 768w" sizes="(max-width: 1024px) 100vw, 1024px"/><figcaption>YCAM 2017 (Photo by Yasuhiro Tani</figcaption></figure>
</div>
</div>



<p>Two years since then. While the previous AI DJ was a challenge to let AI take over some of the actions of a human DJ, this time, we tried to do something impossible for any human DJs to do: compose music in real-time and play it on the spot during a performance, with the help of AI. It might be not too far-fetched to call it an attempt to redefine the very act of DJing, which is to select and play precomposed songs fixated on musical media.</p>







<h2>TECHNOLOGY</h2>



<h3><strong>Three AI</strong> models</h3>



<p>The following three AI models for music generation were used in the realization of this performance. I will explain them in order. </p>







<ol><li>Rhythm generation model</li><li>Rhythm to Bass Conversion model</li><li>Loop selection model</li></ol>







<h3><strong>1. Rhythm Generation Model (M4L.RhythmVAE for Ableton Live/Max for Live)</strong></h3>







<div>
<p>
<figure><video controls="" src="https://qosmo.jp/wp-content/uploads/2021/11/M4L.RhythmVAE_eng.mp4"></video><figcaption>Overview of rhythm generation model — M4L.RhythmVAE for Ableton Live/Max for Live</figcaption></figure>
</p>







<p>The rhythm generation system, which is the core of the performance, is based on a software plugin that Tokui has been developing since 2019. Created for Ableton Live, one of the most popular music production software (DAW), <a rel="noreferrer noopener" href="https://github.com/naotokui/RhythmVAE_M4L" target="_blank">this plugin</a> allows artists to drag and drop music data(MIDI data) and train their own rhythm generation models without programming or other hassles.</p>
</div>



<p>This model, based on the Variational Autoencoder (VAE) architecture, uses a neural network to learn how to compress (encode) complex rhythmic patterns into low-dimensional vectors (two-dimensional vectors in the case of this plugin) and then restore (decode) the original data. Once the training process is complete, the network can generate numerous rhythm patterns by inputting this low-dimensional vector to the decoder.</p>



<div>
<p>
<figure><video controls="" src="https://qosmo.jp/wp-content/uploads/2021/10/qosmo_process2-1.mp4"></video><figcaption>Visualization of the various rhythmic patterns (latent space) generated by the trained rhythm generation model</figcaption></figure>
</p>







<div>
<figure><img src="https://qosmo.jp/wp-content/uploads/2021/10/plugin_screenshot_VAE-1024x713.png" alt="" srcset="https://qosmo.jp/wp-content/uploads/2021/10/plugin_screenshot_VAE-1024x713.png 1024w, https://qosmo.jp/wp-content/uploads/2021/10/plugin_screenshot_VAE-300x209.png 300w, https://qosmo.jp/wp-content/uploads/2021/10/plugin_screenshot_VAE-768x535.png 768w, https://qosmo.jp/wp-content/uploads/2021/10/plugin_screenshot_VAE-1536x1070.png 1536w, https://qosmo.jp/wp-content/uploads/2021/10/plugin_screenshot_VAE-2048x1427.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px"/><figcaption>Screenshot of the plugin</figcaption></figure>
</div>
</div>



<p>To control the characteristics of the generated patterns to a certain extent, the density of the bass drum and hi-hats can be input as conditions for rhythm generation. In this way, DJs can loosely control the generated rhythms by changing these conditions during the performance. In addition to commercial collections of MIDI data of dance music, we also used drum patterns of experimental electronic music as training data for this performance.</p>







<h3><strong>2. Rhythm to Bass Conversion Model (M4L.Rhythm2Bassline for Ableton Live/Max for Live)</strong></h3>



<p>The bassline, along with the rhythm, is an essential element that forms the foundation of a dance music track. It’s no exaggeration to say that the drums and bassline determine most of the groove of a song.</p>



<div>
<p>First, we collected a large number of MIDI files. We then extracted the parts where the drums and bass are playing simultaneously. Then, using the drum patterns as input, we trained a model (seq2seq model using LSTM) that predicts the bassline that would be played simultaneously with the input drum pattern. We have also packaged the trained model as <a rel="noreferrer noopener" href="https://github.com/naotokui/Rhythm2Bass_M4L" target="_blank">a plugin for Ableton Live</a>, as in the case of the rhythm generation model.</p>







<div>
<figure><video controls="" src="https://qosmo.jp/wp-content/uploads/2021/10/M4L.Rhythm2Bassline.mp4"></video><figcaption>Overview of M4L.Rhythm2Bassline plugin</figcaption></figure>




</div>
</div>



<figure><img src="https://qosmo.jp/wp-content/uploads/2021/10/ur_diagram_m4l_ls_211029_3-1024x553.png" alt="" srcset="https://qosmo.jp/wp-content/uploads/2021/10/ur_diagram_m4l_ls_211029_3-1024x553.png 1024w, https://qosmo.jp/wp-content/uploads/2021/10/ur_diagram_m4l_ls_211029_3-300x162.png 300w, https://qosmo.jp/wp-content/uploads/2021/10/ur_diagram_m4l_ls_211029_3-768x415.png 768w, https://qosmo.jp/wp-content/uploads/2021/10/ur_diagram_m4l_ls_211029_3-1536x830.png 1536w, https://qosmo.jp/wp-content/uploads/2021/10/ur_diagram_m4l_ls_211029_3-2048x1106.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px"/><figcaption>Concept of rhythm to bass conversion model</figcaption></figure>







<h3><strong>3. Loop Combination Model</strong></h3>



<p><a rel="noreferrer noopener" href="https://createwith.ai/7511b4620de94e60b421c172b34acd8c" target="_blank">The third model selects appropriate loops (melodies, vocal samples, sound effects, i.e., other than rhythm and bassline) for the rhythm and bass generated.</a> For example, a funky synth riff or a funky vocal sample might be a good fit for a house music track. In contrast, a distorted guitar riff might be a better fit for a rock-style 8-bit rhythm.</p>



<div>
<div>
<figure><img src="https://qosmo.jp/wp-content/uploads/2021/10/ur_diagram_dataset_211029_4-1024x532.png" alt="" srcset="https://qosmo.jp/wp-content/uploads/2021/10/ur_diagram_dataset_211029_4-1024x532.png 1024w, https://qosmo.jp/wp-content/uploads/2021/10/ur_diagram_dataset_211029_4-300x156.png 300w, https://qosmo.jp/wp-content/uploads/2021/10/ur_diagram_dataset_211029_4-768x399.png 768w, https://qosmo.jp/wp-content/uploads/2021/10/ur_diagram_dataset_211029_4-1536x799.png 1536w, https://qosmo.jp/wp-content/uploads/2021/10/ur_diagram_dataset_211029_4-2048x1065.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px"/><figcaption>Loop Combination Model — Generate training data</figcaption></figure>
</div>







<p>To train this model, we first collect a large number of songs and create a large number of two-bar loops (<a rel="noreferrer noopener" href="https://ieeexplore.ieee.org/document/8461876" target="_blank">This process also uses another machine learning technique</a>). We then used sound source separation techniques to extract the rhythm, bass, and other tracks (piano, guitar melody, etc.) from collected loops.</p>
</div>



<div>
<div>
<figure><img src="https://qosmo.jp/wp-content/uploads/2021/11/ur_diagram_mt_211029-1024x614.png" alt="" srcset="https://qosmo.jp/wp-content/uploads/2021/11/ur_diagram_mt_211029-1024x614.png 1024w, https://qosmo.jp/wp-content/uploads/2021/11/ur_diagram_mt_211029-300x180.png 300w, https://qosmo.jp/wp-content/uploads/2021/11/ur_diagram_mt_211029-768x461.png 768w, https://qosmo.jp/wp-content/uploads/2021/11/ur_diagram_mt_211029-1536x922.png 1536w, https://qosmo.jp/wp-content/uploads/2021/11/ur_diagram_mt_211029-2048x1229.png 2048w" sizes="(max-width: 1024px) 100vw, 1024px"/><figcaption>Loop Combination Model — Train the model</figcaption></figure>
</div>







<p>While rhythm/bass and bass/melody pairs taken from the same song should work well, combinations of loops taken from two randomly selected songs are not guaranteed to be a good match. Sometimes the combination can be unbearable to listen to. So, we trained a model that can predict the compatibility of a given pair of loops taken from the same song as a “good combination” and one taken from random pair of two songs as a “bad combination” (CNN-based Siamese Network trained with Triplet Loss). </p>
</div>



<p>With this model, it is possible to search for the most appropriate loops among many.</p>



<p>In this performance, we used three different sets of sound sources: the “other (melody, etc.)” part taken from a publicly available music dataset, field-recorded soundscape sounds (environmental sounds, etc.), and sounds with human voices explicitly selected from the soundscape dataset. We used <a rel="noreferrer noopener" href="https://ieeexplore.ieee.org/document/8461876" target="_blank">the same machine learning techniques</a> to extract two-measure loops from each of them.</p>







<h2>BEHIND THE SCENES </h2>



<figure><p>
<iframe src="https://player.vimeo.com/video/639898464?h=3b7ef2ef39&amp;dnt=1&amp;app_id=122963" width="500" height="281" frameborder="0" allow="autoplay; fullscreen; picture-in-picture" allowfullscreen=""></iframe>
</p><figcaption>Behind the Scene — A video about the story behind the performance</figcaption></figure>







<h2>HOW IT WORKS</h2>



<p>The performance starts by randomly generating a rhythm pattern. Then, the baseline model “translates” the rhythm to a baseline. Next, the loop selection model picks appropriate loops that fit the rhythm and bass sound from the respective loop source set (ambient sound, voice, music).</p>



<figure><img src="https://qosmo.jp/wp-content/uploads/2021/10/ur_diagram_211029-1-1024x576.jpg" alt="" srcset="https://qosmo.jp/wp-content/uploads/2021/10/ur_diagram_211029-1-1024x576.jpg 1024w, https://qosmo.jp/wp-content/uploads/2021/10/ur_diagram_211029-1-300x169.jpg 300w, https://qosmo.jp/wp-content/uploads/2021/10/ur_diagram_211029-1-768x432.jpg 768w, https://qosmo.jp/wp-content/uploads/2021/10/ur_diagram_211029-1-1536x864.jpg 1536w, https://qosmo.jp/wp-content/uploads/2021/10/ur_diagram_211029-1.jpg 1920w" sizes="(max-width: 1024px) 100vw, 1024px"/><figcaption>Overall system structure</figcaption></figure>



<p>The DJ can use turntables to mix the sound of the record. He/she can also manipulate the timbre and volumes of a drum machine and a synthesizer (in this case, ARTURIA DrumBrute Impact and SEQUENTIAL Prophet 6) to create a musical development. The DJ controls the “Conditioning” function of the rhythm generation model to create a broader flow in the performance. The DJ’s manipulations are reflected in the sounds input to the loop selection model, which indirectly affects the loop selection.</p>



<p>This way, the direct and indirect interactions and feedback loops between the three AI models and a single DJ produced the appropriate unpredictability and fluctuation in the generated music.</p>







<h2>VISUALS</h2>



<p>The visual in this performance has two layers: an interface layer to directly represent what is happening in the AI system and a visual expression layer. Using Augmented Reality (AR) technology, the interface is displayed virtually in the space in front of the DJ, showing the AI-generated sequences and updating them moment by moment. As the music unfolds, minimalistic visualizations of the sound are projected behind the DJ, enhancing the atmosphere of the performance. (The AR camera system was created and provided by the visual team of <a rel="noreferrer noopener" href="https://dentsucraft.tokyo/" target="_blank">Dentsu Craft Tokyo</a>.)</p>







<h2>PERFORMANCE</h2>



<figure><table><tbody><tr><td>Date</td><td>Title</td><td>Place</td></tr><tr><td>2021/10/28</td><td>Creativity4Better (Bucharest)</td><td>Online Screening</td></tr></tbody></table></figure>



<hr/>





										
                                                                <hr/>
                        <h2>REFERENCES</h2>
                        <div>
                                                            
                                                            
                                                            <div>
                                    <h5>[3] Loop Combination Model (Loop Combination Model)</h5>
                                                                            <ul>
                                                                                    <li><a target="_blank" href="">GitHub: Coming soon</a></li>
                                                                                    <li><a target="_blank" href="http://arxiv.org/abs/2008.02011">Chen, B.-Y., Smith, J. B. L., &amp; Yang, Y.-H. (2020). Neural Loop Combiner: Neural Network Models for Assessing the Compatibility of Loops. http://arxiv.org/abs/2008.02011</a></li>
                                                                                    <li><a target="_blank" href="https://doi.org/10.1109/ICASSP.2018.8461876">Smith, J. B. L., &amp; Goto, M. (2018). Nonnegative Tensor Factorization for Source Separation of Loops in Audio. ICASSP, IEEE International Conference on Acoustics, Speech and Signal Processing – Proceedings, 2018-April(April), 171–175. https://doi.org/10.1109/ICASSP.2018.8461876</a></li>
                                                                                    <li><a target="_blank" href="https://createwith.ai/7511b4620de94e60b421c172b34acd8c">Neural Loop Combiner — リズム、メロディー、ベースライン... どのループを組み合わせる？  (Create with AI)</a></li>
                                                                                </ul>
                                                                    </div>
                                                    </div>
                    
                                                                <hr/>
                        <h2>LINKS</h2>
                        
                    
					                                            <hr/>
                        <h2>ARTICLES</h2>
                        <div>
                            <div>
                                <ul>
                                                                            <li>
											<a target="_blank" href="">
												<img src="https://qosmo.jp/wp-content/themes/qosmo/assets/img/common/icon_medium.png" alt="medium"/>
																							</a>
										</li>
                                                                    </ul>
                            </div>
                        </div>
                    
                    					
                                                                <hr/>
                        <h2>CREDITS</h2>
                                                                                                            <ul>
                                                                    <li>
                                        <h5>Machine Learning &amp; Performance</h5>
                                        <p>Nao Tokui (Qosmo, Inc.)</p>
                                    </li>
                                                                    <li>
                                        <h5>Visual Programming</h5>
                                        <p>Shoya Dozono (Qosmo, Inc.)</p>
                                    </li>
                                                                    <li>
                                        <h5>Visual Research</h5>
                                        <p>Ryosuke Nakajima (Qosmo, Inc.)</p>
                                    </li>
                                                                    <li>
                                        <h5>AR System</h5>
                                        <p>Hiroyoshi Murata (Dentsu Creative X, Inc.), Yuki Tanabe (Dentsu Creative X, Inc.)</p>
                                    </li>
                                                                    <li>
                                        <h5>Videographer</h5>
                                        <p>Sota Suzuki (Dentsu Creative X, Inc.)</p>
                                    </li>
                                                                    <li>
                                        <h5>Producer</h5>
                                        <p>Ryotaro Omori (Dentsu Creative X, Inc.)</p>
                                    </li>
                                                                    <li>
                                        <h5>Logo Design</h5>
                                        <p>Naoki Ise (Qosmo, Inc.)</p>
                                    </li>
                                                            </ul>
                                                                        
                </div></div>
  </body>
</html>
