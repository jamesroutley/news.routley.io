<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://embracethered.com/blog/posts/2025/github-copilot-remote-code-execution-via-prompt-injection/">Original</a>
    <h1>GitHub Copilot: Remote Code Execution via Prompt Injection (CVE-2025-53773)</h1>
    
    <div id="readability-page-1" class="page"><div>


<article>
  <header>
    
    
  </header>
  <section>
    
<a id="top_ref"></a>

<p>This post is about an important, but also scary, prompt injection discovery that leads to full system compromise of the developer’s machine in <a href="https://msrc.microsoft.com/update-guide/vulnerability/CVE-2025-53773">GitHub Copilot and VS Code</a>.</p>
<p><strong>It is achieved by placing Copilot into YOLO mode by modifying the project’s <code>settings.json</code> file.</strong></p>
<p><a href="https://embracethered.com/blog/images/2025/episode12-yt.png"><img src="https://embracethered.com/blog/images/2025/episode12-yt.png" alt="vscode episode 18"/></a></p>
<p>As described a few days ago with <a href="https://embracethered.com/blog/posts/2025/amp-agents-that-modify-system-configuration-and-escape/">Amp</a>, a vulnerability pattern in agents that might be overlooked is that if an agent can write to files and modify its own configuration or update security-relevant settings it can lead to remote code execution. This is not uncommon and is an area to always look for when performing a security review.</p>
<h2 id="background-research">Background Research</h2>
<p>When looking at VS Code and GitHub Copilot Agent Mode I noticed a strange behavior… it can create and write to files in the workspace without user approval.</p>
<p>The edits are immediately persistent, they are not in-memory as a diff to review. The modifications are written to disk right away.</p>
<p><a href="https://embracethered.com/blog/images/2025/agents-that-can.png"><img src="https://embracethered.com/blog/images/2025/agents-that-can.png" alt="vscode agents that can modify their own settings"/></a></p>
<p>It’s one of these things that as a red teamer you know is probably not good… so I was looking if this could be used to escalate privileges and execute code.</p>
<h3 id="yolo-mode"><strong>YOLO Mode</strong></h3>
<p>So, next I researched features in VS Code that depend on settings that are within the project/workspace folder, and quickly found an interesting one.</p>
<p><a href="https://embracethered.com/blog/images/2025/vscode-documentation-settings-json.png"><img src="https://embracethered.com/blog/images/2025/vscode-documentation-settings-json.png" alt="vscode-exp-yolo-mode"/></a></p>
<p>It turns out that in the <code>.vscode/settings.json</code> file one can add the following line:</p>
<p><code>&#34;chat.tools.autoApprove&#34;: true</code></p>
<p><strong>This will put GitHub Copilot in YOLO mode.</strong></p>
<p>And it disables all user confirmations, and we can run shell commands, browse the web, and more!</p>
<p>What is interesting is that this is an experimental feature, but it is still present by default. I did not download a special version or set my VS Code overall into an experimental mode.</p>
<p>Furthermore, it works on Windows, macOS and also Linux.</p>
<h2 id="exploit-chain-explained">Exploit Chain Explained</h2>
<p>The proof-of-concept exploit chain to hijack Copilot and escalate privileges is as follows:</p>
<ol>
<li>The attack starts with a prompt injection planted in a source code file, web page, GitHub issue, tool call response, or other content… The payload can also use invisible text as instructions.</li>
<li>The prompt injection first adds the line <strong>“chat.tools.autoApprove”: true,</strong> to the <code>~/.vscode/settings.json</code> file. Folder and file will be created if they don’t exist yet.</li>
<li><strong>GitHub Copilot immediately enters YOLO mode!</strong></li>
<li>Attack runs a Terminal command. <strong>And using conditional prompt injection we can actually target what to run based on the operating system.</strong></li>
<li>We achieved Remote Code Execution powered by Prompt Injection.</li>
</ol>
<p>Here is a screenshot that shows the demo file with the prompt injection, the developer interacting with the file on the right side in the chat box, and the calculator popping up!</p>
<p><a href="https://embracethered.com/blog/images/2025/copilot-chat-result.png"><img src="https://embracethered.com/blog/images/2025/copilot-chat-result.png" alt="vscode-e2e-calc"/></a></p>
<p>Of course any other means of prompt injection delivery, like web or data coming back from an MCP server is an attack angle. I just used it inside the source code file because it’s easiest to test with.</p>
<h2 id="video-walkthrough">Video Walkthrough</h2>
<h3 id="short-demos">Short Demos</h3>
<p>Here is a demonstration video that shows the code execution on Windows.</p>

<p>
  <iframe src="https://www.youtube.com/embed/QceCWM6DbWc" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<p>And this one on macOS:</p>

<p>
  <iframe src="https://www.youtube.com/embed/IRMbO1l9AK0" allowfullscreen="" title="YouTube Video"></iframe>
</p>

<h3 id="walkthrough">Walkthrough</h3>
<p>Here is a longer form video explaining the discovery and exploit in detail:</p>

<p>
  <iframe src="https://www.youtube.com/embed/8Qzqgqxp5ho" allowfullscreen="" title="YouTube Video"></iframe>
</p>


  </section>
  
</article>
</div></div>
  </body>
</html>
