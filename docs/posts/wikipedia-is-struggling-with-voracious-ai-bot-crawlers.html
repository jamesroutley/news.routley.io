<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.engadget.com/ai/wikipedia-is-struggling-with-voracious-ai-bot-crawlers-121546854.html">Original</a>
    <h1>Wikipedia is struggling with voracious AI bot crawlers</h1>
    
    <div id="readability-page-1" class="page"><div><div><p><a href="https://www.engadget.com/about/editors/mariella-moon/" data-ylk="elm:author;slk:Mariella Moon;itc:0"><img alt="Mariella Moon" src="https://s.yimg.com/ny/api/res/1.2/YwfCRgIe90exOChYec9Cjw--/YXBwaWQ9aGlnaGxhbmRlcjt3PTgwO2g9ODA-/https://s.yimg.com/os/creatr-uploaded-images/2024-01/d5b30fb0-aa58-11ee-bbbf-af6360643ddf" data-src="https://s.yimg.com/ny/api/res/1.2/YwfCRgIe90exOChYec9Cjw--/YXBwaWQ9aGlnaGxhbmRlcjt3PTgwO2g9ODA-/https://s.yimg.com/os/creatr-uploaded-images/2024-01/d5b30fb0-aa58-11ee-bbbf-af6360643ddf"/></a></p></div></div><div><p>Wikimedia has <a data-i13n="cpos:1;pos:1" href="https://diff.wikimedia.org/2025/04/01/how-crawlers-impact-the-operations-of-the-wikimedia-projects/" rel="nofollow noopener" target="_blank" data-ylk="slk:seen a 50 percent increase;cpos:1;pos:1;elm:context_link;itc:0;sec:content-canvas">seen a 50 percent increase</a> in bandwidth used for downloading multimedia content since January 2024, the foundation said in an update. But it&#39;s not because human readers have suddenly developed a voracious appetite for consuming Wikipedia articles and for watching videos or downloading files from Wikimedia Commons. No, the spike in usage came from <a data-i13n="cpos:2;pos:1" href="https://www.engadget.com/websites-accuse-ai-startup-anthropic-of-bypassing-their-anti-scraping-rules-and-protocol-133022756.html" data-ylk="slk:AI crawlers;cpos:2;pos:1;elm:context_link;itc:0;sec:content-canvas">AI crawlers</a>, or automated programs scraping Wikimedia&#39;s openly licensed images, videos, articles and other files to train generative artificial intelligence models.</p><p>This sudden increase in traffic from bots could slow down access to Wikimedia&#39;s pages and assets, especially during high-interest events. When Jimmy Carter died in December, for instance, people&#39;s heightened interest in the video of his presidential debate with Ronald Reagan caused slow page load times for some users. Wikimedia is equipped to sustain traffic spikes from human readers during such events, and users watching Carter&#39;s video shouldn&#39;t have caused any issues. But &#34;the amount of traffic generated by scraper bots is unprecedented and presents growing risks and costs,&#34; Wikimedia said.</p><p>The foundation explained that human readers tend to look up specific and often similar topics. For instance, a number of people look up the same thing when it&#39;s trending. Wikimedia creates a cache of a piece of content requested multiple times in the data center closest to the user, enabling it to serve up content faster. But articles and content that haven&#39;t been accessed in a while have to be served from the core data center, which consumes more resources and, hence, costs more money for Wikimedia. Since AI crawlers tend to bulk read pages, they access obscure pages that have to be served from the core data center.</p><p>Wikimedia said that upon a closer look, 65 percent of the resource-consuming traffic it gets is from bots. It&#39;s already causing constant disruption for its Site Reliability team, which has to block the crawlers all the time before they they significantly slow down page access to actual readers. Now, the real problem, as Wikimedia states, is that the &#34;expansion happened largely without sufficient attribution, which is key to drive new users to participate in the movement.&#34; A foundation that relies on people&#39;s donations to continue running needs to attract new users and get them to care for its cause. &#34;Our content is free, our infrastructure is not,&#34; the foundation said. Wikimedia is now looking to establish sustainable ways for developers and reusers to access its content in the upcoming fiscal year. It has to, because it sees no sign of AI-related traffic slowing down anytime soon.</p></div></div>
  </body>
</html>
