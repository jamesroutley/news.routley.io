<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://cantortrading.fi/rust_decimal_str/">Original</a>
    <h1>Parsing Decimals four times faster</h1>
    
    <div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/Article"><header><p>December 31, 2021</p></header><section itemprop="articleBody"><ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#single-pass-parsing">Single-pass parsing</a></li>
<li><a href="#using-compiler-supported-integer-operations">Using compiler-supported integer operations</a></li>
<li><a href="#threading-the-needle-with-tail-calls-and-const-generics">Threading the needle with tail calls and const generics</a>
<ul>
<li><a href="#non-guaranteed-tail-calls">Non-guaranteed tail calls</a></li>
</ul>
</li>
<li><a href="#whats-next">What’s next</a></li>
</ul>
<h2 id="introduction"><a href="#introduction" aria-label="introduction permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Introduction</h2>
<p>At Cantor, our systems must rapidly react to new updates in market data. Market data tends to be very bursty, and we only have a few microseconds to handle a message during these bursts. Unfortunately, these messages tend to come in JSON format, optimized for simplicity and readability instead of parsing performance. The performance of our market data handlers is thus limited by how fast we can parse these JSON messages into a native rust format.</p>
<p>We use rust-decimal to represent numeric values in market data. rust-decimal represents a number using a 128-bit binary representation consisting of a 96-bit integer mantissa, an exponent in the range 0 to 28 inclusive, and a 1-bit sign: <code>sign * mantissa * 10^-exponent</code>. We love this library for its rich API, exact base-10 representation, and nice inter-operation with other crates, but we noticed one problem: It regularly costs ~100ns to parse a decimal from string, which became a bottleneck in our application:</p>
<p><span>
      <a href="https://cantortrading.fi/static/d150ab444a4194b412b79f86b93c03a7/f213e/perf.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Perf dump of a benchmark" title="Perf dump of a benchmark" src="https://cantortrading.fi/static/d150ab444a4194b412b79f86b93c03a7/2bef9/perf.png" srcset="/static/d150ab444a4194b412b79f86b93c03a7/6f3f2/perf.png 256w,
/static/d150ab444a4194b412b79f86b93c03a7/01e7c/perf.png 512w,
/static/d150ab444a4194b412b79f86b93c03a7/2bef9/perf.png 1024w,
/static/d150ab444a4194b412b79f86b93c03a7/f213e/perf.png 1192w" sizes="(max-width: 1024px) 100vw, 1024px" loading="lazy" decoding="async"/>
  </a>
    </span></p>
<p>This prompted us to improve the parsing performance of <code>rust_decimal</code>. We have two benchmarks as the baseline:</p>
<ul>
<li><a href="https://github.com/paupino/rust-decimal/blob/4d3cafa9844c6d5ceefd04eda964dd7eeb070449/benches/lib_benches.rs#L137">A benchmark parsing a selection of numbers</a>: <code>554 ns/iter</code></li>
<li>An internal benchmark parsing market data: <code>12.123 us/iter</code></li>
</ul>
<h2 id="single-pass-parsing"><a href="#single-pass-parsing" aria-label="single pass parsing permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Single-pass parsing</h2>
<p>The original implementation of decimal parsing looks like:</p>
<div data-language="rust"><pre><code>
<span>fn</span> <span>parse_str_radix_10</span><span>(</span>bytes<span>:</span> <span>&amp;</span><span>[</span><span>u8</span><span>]</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>Decimal</span><span>&gt;</span> <span>{</span>
    
    <span>let</span> <span>mut</span> coeff <span>=</span> <span>ArrayVec</span><span>&lt;</span><span>u32</span><span>&gt;</span><span>::</span><span>new</span><span>(</span><span>)</span><span>;</span>
    <span>for</span> b <span>in</span> bytes<span>.</span><span>iter</span><span>(</span><span>)</span> <span>{</span>
        <span>match</span> b <span>{</span>
            <span>b&#39;0&#39;</span><span>..=</span><span>b&#39;9&#39;</span> <span>=&gt;</span> <span>{</span> coeff<span>.</span><span>push</span><span>(</span>b <span>-</span> <span>b&#39;0&#39;</span><span>)</span><span>;</span> <span>}</span>
            <span>b&#39;.&#39;</span> <span>=&gt;</span> <span>{</span>  <span>}</span>
            <span>b&#39;_&#39;</span> <span>=&gt;</span> <span>{</span><span>}</span> 
            _ <span>=&gt;</span> <span>return</span> <span>Err</span><span>,</span>
        <span>}</span>
    <span>}</span>

    <span>if</span> needs_rounding <span>{</span>
        <span>let</span> b <span>=</span> <span>next_digit</span><span>(</span>bytes<span>)</span><span>;</span>
        <span>if</span> b <span>&gt;=</span> <span>5</span> <span>{</span> 
            
        <span>}</span>
    <span>}</span>

    <span>let</span> <span>mut</span> num<span>:</span> <span>[</span><span>u32</span><span>;</span> <span>3</span><span>]</span> <span>=</span> <span>[</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>]</span><span>;</span>
    <span>for</span> c <span>in</span> coeff<span>.</span><span>iter</span><span>(</span><span>)</span> <span>{</span>
        <span>mul_by_10</span><span>(</span><span>&amp;</span><span>mut</span> num<span>)</span><span>;</span> 
        <span>add_by</span><span>(</span><span>&amp;</span><span>mut</span> num<span>,</span> c<span>)</span><span>;</span> 
        <span>if</span> <span>overflow</span><span>(</span>num<span>)</span> <span>{</span> <span>return</span> <span>Err</span><span>;</span> <span>}</span>
    <span>}</span>

    <span>return</span> <span>Decimal</span><span>::</span><span>from_parts</span><span>(</span>num<span>,</span> scale<span>,</span> sign<span>)</span>
<span>}</span></code></pre></div>
<p>It first loops over the characters in the input string, converts each digit to a <code>u32</code>, and stores them in a <code>coeff</code> array. If overflow occurs (which rarely happens), it rounds up the digits in the <code>coeff</code> array. Finally, it loops over <code>coeff</code> and computes the output number using manual 96-bit arithmetic functions.</p>
<p>It is inefficient and unnecessary to loop twice. In addition, we have to reserve 128 (32 × 4) extra bytes on the stack to store the digits. We simplified the logic to compute <code>num</code> in one pass.</p>
<p>The single-pass code looks like:</p>
<div data-language="rust"><pre><code>
<span>fn</span> <span>parse_str_radix_10</span><span>(</span>bytes<span>:</span> <span>&amp;</span><span>[</span><span>u8</span><span>]</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>Decimal</span><span>&gt;</span> <span>{</span>
    
    <span>let</span> <span>mut</span> num<span>:</span> <span>[</span><span>u32</span><span>;</span> <span>3</span><span>]</span> <span>=</span> <span>[</span><span>0</span><span>,</span> <span>0</span><span>,</span> <span>0</span><span>]</span><span>;</span>

    <span>for</span> b <span>in</span> bytes<span>.</span><span>iter</span><span>(</span><span>)</span> <span>{</span>
        <span>match</span> b <span>{</span>
            <span>b&#39;0&#39;</span><span>..=</span><span>b&#39;9&#39;</span> <span>=&gt;</span> <span>{</span>
                <span>let</span> c <span>=</span> b <span>-</span> <span>b&#39;0&#39;</span><span>;</span>
                <span>mul_by_10</span><span>(</span><span>&amp;</span><span>mut</span> num<span>)</span><span>;</span> 
                <span>add_by</span><span>(</span><span>&amp;</span><span>mut</span> num<span>,</span> c<span>)</span><span>;</span> 
                <span>if</span> passed_decimal_point <span>{</span> scale <span>+=</span> <span>1</span> <span>}</span>
                <span>if</span> <span>overflow</span><span>(</span>num<span>)</span> <span>{</span> <span>return</span> <span>Err</span><span>;</span> <span>}</span>
            <span>}</span>
            <span>b&#39;.&#39;</span> <span>=&gt;</span> <span>{</span> passed_decimal_point <span>=</span> <span>true</span><span>;</span> <span>}</span>
            <span>b&#39;_&#39;</span> <span>=&gt;</span> <span>{</span><span>}</span> 
            _ <span>=&gt;</span> <span>return</span> <span>Err</span><span>,</span>
        <span>}</span>
    <span>}</span>

    <span>if</span> needs_rounding <span>{</span>
        <span>let</span> b <span>=</span> <span>next_digit</span><span>(</span>bytes<span>)</span><span>;</span>
        <span>if</span> b <span>&gt;=</span> <span>5</span> <span>{</span> 
            <span>add_by</span><span>(</span><span>&amp;</span><span>mut</span> num<span>,</span> <span>1</span><span>)</span><span>;</span> 
        <span>}</span>
    <span>}</span>

    <span>return</span> <span>Decimal</span><span>::</span><span>from_parts</span><span>(</span>num<span>,</span> scale<span>,</span> sign<span>)</span>
<span>}</span></code></pre></div>
<p><code>mul_by_10</code> and <code>add_by</code> and are manual implementations of 96 bit arithmetic, and the functions look roughly as follows:</p>
<div data-language="rust"><pre><code><span>fn</span> <span>add_by</span><span>(</span>num<span>:</span> <span>&amp;</span><span>mut</span> <span>[</span><span>u32</span><span>]</span><span>,</span> by<span>:</span> <span>u32</span><span>)</span> <span>{</span>
    <span>for</span> i <span>in</span> num<span>.</span><span>iter_mut</span><span>(</span><span>)</span> <span>{</span>
        
    <span>}</span>
<span>}</span></code></pre></div>
<p>In Rust, slices’ lengths are runtime determined. Even though we always pass in <code>num</code> as an array of 3 <code>u32</code>s, the compiler cannot take advantage of this fact to optimize the function. If we change the signature to:</p>
<div data-language="rust"><pre><code><span>fn</span> <span>add_by</span><span>(</span>num<span>:</span> <span>&amp;</span><span>mut</span> <span>[</span><span>u32</span><span>;</span> <span>3</span><span>]</span><span>,</span> by<span>:</span> <span>u32</span><span>)</span></code></pre></div>
<p>The compiler now knows that <code>num</code> is exactly 3 <code>u32</code>s at compile time, and will have a lot more opportunities to optimize this function, e.g. by replacing <code>num.len()</code> with a constant and optimizing specific code paths away. Since there is only one caller throughout the crate, we manually <a href="https://github.com/cantortrading/rust-decimal/commit/f099f664b790659953f85f437a7dd2a884095583">flattened the function and unrolled the loop</a>.</p>
<p>With these modifications, we already see a ~35% reduction in parse time - the benchmarks are now:</p>
<ul>
<li>Decimal sample benchmark: <code>356ns/iter</code></li>
<li>Market data benchmark: <code>9.5us/iter</code></li>
</ul>
<h2 id="using-compiler-supported-integer-operations"><a href="#using-compiler-supported-integer-operations" aria-label="using compiler supported integer operations permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Using compiler-supported integer operations</h2>
<p>rust-decimal internally stores a 96-bit integer mantissa, and as a result, is required to do 96-bit integer operations on that. For example, some code to multiply by 10, with each number represented as a <code>&amp;[u32]</code> is</p>
<div data-language="rust"><pre><code>
<span>#[inline]</span>
<span>pub</span><span>(</span><span>crate</span><span>)</span> <span>fn</span> <span>mul_by_10</span><span>(</span>bits<span>:</span> <span>&amp;</span><span>mut</span> <span>[</span><span>u32</span><span>;</span> <span>3</span><span>]</span><span>)</span> <span>-&gt;</span> <span>u32</span> <span>{</span>
    <span>let</span> <span>mut</span> overflow <span>=</span> <span>0u64</span><span>;</span>
    <span>for</span> b <span>in</span> bits<span>.</span><span>iter_mut</span><span>(</span><span>)</span> <span>{</span>
        
        <span>let</span> result <span>=</span> <span>u64</span><span>::</span><span>from</span><span>(</span><span>*</span>b<span>)</span> <span>*</span> <span>10u64</span> <span>+</span> overflow<span>;</span>
        <span>let</span> hi <span>=</span> <span>(</span>result <span>&gt;&gt;</span> <span>32</span><span>)</span> <span>&amp;</span> <span>U32_MASK</span><span>;</span>
        <span>let</span> lo <span>=</span> <span>(</span>result <span>&amp;</span> <span>U32_MASK</span><span>)</span> <span>as</span> <span>u32</span><span>;</span>
        <span>*</span>b <span>=</span> lo<span>;</span>
        overflow <span>=</span> hi<span>;</span>
    <span>}</span>

    overflow <span>as</span> <span>u32</span>
<span>}</span></code></pre></div>
<p>generating the respectable, but long, code:</p>
<div data-language="asm"><pre><code>mul_by_10:
    movl    (%rdi), %eax
    movl    4(%rdi), %ecx
    addq    %rax, %rax
    leaq    (%rcx,%rcx,4), %rcx
    leaq    (%rax,%rax,4), %rax
    movl    %eax, (%rdi)
    shrq    $32, %rax
    leaq    (%rax,%rcx,2), %rax
    movl    %eax, 4(%rdi)
    shrq    $32, %rax
    movl    8(%rdi), %ecx
    leaq    (%rcx,%rcx,4), %rcx
    leaq    (%rax,%rcx,2), %rax
    movl    %eax, 8(%rdi)
    shrq    $32, %rax
    retq</code></pre></div>
<p>This can carry out each multiplication in parallel, but each word carries a dependency.</p>
<p>An immediate optimization is to perform a 128-bit operation:</p>
<div data-language="rust"><pre><code>
<span>#[inline]</span>
<span>pub</span><span>(</span><span>crate</span><span>)</span> <span>fn</span> <span>mul_by_10</span><span>(</span>bits<span>:</span> <span>&amp;</span><span>mut</span> <span>u128</span><span>)</span> <span>{</span>
    <span>*</span>bits <span>*=</span> <span>10</span><span>;</span>
<span>}</span></code></pre></div>
<p>This generates the compact (and in fact pessimistic) code</p>
<div data-language="asm"><pre><code>mul_by_10_u128:
    movl    $10, %edx
    movq    8(%rdi), %rax
    mulxq   (%rdi), %rdx, %rcx
    leaq    (%rax,%rax,4), %rax
    movq    %rdx, (%rdi)
    leaq    (%rcx,%rax,2), %rax
    movq    %rax, 8(%rdi)
    retq</code></pre></div>
<p>This code is somewhat better - we only have two multiplications, except there’s a dependency between each one since the multiplication properly (and pointlessly handles overflow). It doesn’t buy us very much, though.</p>
<p><a href="https://github.com/cantortrading/rust-decimal/commit/05a925146bb1beb712914ddc87ae323592f61971">However, an extension of this idea yields a much larger improvement</a>. We maintain state in a 64-bit integer and only fall back to 128bit handling if needed.</p>
<p>This optimization yields much better results, another ~45% improvement in parse time:</p>
<ul>
<li>Decimal sample benchmark: <code>193ns/iter</code></li>
<li>Market data benchmark: <code>7.9us/iter</code></li>
</ul>
<h2 id="threading-the-needle-with-tail-calls-and-const-generics"><a href="#threading-the-needle-with-tail-calls-and-const-generics" aria-label="threading the needle with tail calls and const generics permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Threading the needle with tail calls and const generics</h2>
<p>The final optimization involves using tail calls to optimally split out fast/slow paths
and rapidly switch between optimal parser loops. First, let’s talk about tail calls.</p>
<p>A tail call is a function call being the final action the calling function performs, with no access of local variables after the function call.
In this case, it’s valid for the compiler to replace a call + ret instruction with simply jumping
to the callee. You can play around with it here:</p>
<!-- blank line -->

<p>In simple cases, like the one above, the code compiles into something very close to the loop version of the code. In the general case,
tail calls act as a sort of structured goto, which can be very advantageous for performance purposes.
Specifically, tail calls make it much easier to optimize interpreters and parsers -
internally, we brought about a ~30% performance improvement to an in-house interpreter by utilizing tail calls.</p>
<p>These articles about
<a href="https://blog.reverberate.org/2021/04/21/musttail-efficient-interpreters.html">high performance protobuf parsing</a>
and
<a href="http://lua-users.org/lists/lua-l/2011-02/msg00742.html">why LuaJIT’s interpreter is fast</a>
do a great job of detailing the difficulties that compilers have with naively written interpreters so I won’t repeat everything here,
but the main points are:</p>
<ul>
<li>Compilers have trouble reasoning about large functions with complex control flow
<ul>
<li>Register allocation makes poor decisions about what data should be kept in registers or spilled to the stack</li>
<li>Optimizer will aggressively try to merge identical snippets in different paths, hurting overall code quality</li>
<li>Compilers cannot reason about fast/slow paths mixed into the same function and compromise fast paths to optimize slow paths</li>
<li>Branches are often shared between paths, losing prediction information</li>
</ul>
</li>
<li>Having multiple specialized fast-paths in a single loop confuses compilers
<ul>
<li>Switching between the fast-paths complicates control flow, leading to the above problems</li>
<li>Code duplication can help solve this at a high maintenance cost, but not perfectly</li>
</ul>
</li>
</ul>
<p>Tail calls offer a solution here since they:</p>
<ul>
<li>Segregate control flow into small and easy-to-reason-about functions</li>
<li>Allow simple jumps into distinct parts of the control flow graph while informing the compiler that the local state isn’t shared</li>
<li>Give each operation dedicated dispatch and branch predictions</li>
</ul>
<p>How does this help us? Let’s consider <a href="https://github.com/cantortrading/rust-decimal/blob/05a925146bb1beb712914ddc87ae323592f61971/src/str.rs#L160">the u64 parsing loop</a>.</p>
<p>A basic graph of the control flow looks like:</p>
<p><img src="https://cantortrading.fi/68571765bb1518f150e205f697773b57/flow_loop.svg" alt="Control flow of looping parser"/></p>
<p>I’m using green nodes for fast paths, yellow nodes for slow fallbacks that may exit the loop, red for a terminal error, and blue for leaving the loop.</p>
<p>Something that’s immediately clear is that the control flow is not straightforward - in addition to the branch-out-and-converge, there are multiple exit paths from numerous points in the loop to both fast and slow paths, and all sorts of conditions repeatedly getting checked. Many of these checks don’t even make sense -
why would we re-check for overflow after observing a ’_’, or even try to handle a ’.’ again after seeing a ’.‘?</p>
<p>We solve this with tail calls by giving each operation a small function, which only does whatever work is required and then dispatches the next call.</p>
<p>For example, here’s a simplified version of the dispatch code and two handlers:</p>
<div data-language="rust"><pre><code><span>#[inline]</span>
<span>fn</span> <span>byte_dispatch_u64</span><span>(</span>bytes<span>:</span> <span>&amp;</span><span>[</span><span>u8</span><span>]</span><span>,</span> data64<span>:</span> <span>u64</span><span>,</span> b<span>:</span> <span>u8</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>Decimal</span><span>,</span> <span>Error</span><span>&gt;</span> <span>{</span>
    <span>match</span> b <span>{</span>
        <span>b&#39;0&#39;</span><span>..=</span><span>b&#39;9&#39;</span> <span>=&gt;</span> <span>handle_digit_64</span><span>(</span>bytes<span>,</span> data64<span>,</span>b <span>-</span> <span>b&#39;0&#39;</span><span>)</span><span>,</span>
        <span>b&#39;.&#39;</span> <span>=&gt;</span> <span>handle_point</span><span>(</span>bytes<span>,</span> data64<span>)</span><span>,</span>
        b <span>=&gt;</span> <span>non_digit_dispatch_u64</span><span>(</span>bytes<span>,</span> data64<span>,</span> b<span>)</span><span>,</span>
    <span>}</span>
<span>}</span>

<span>#[inline(never)]</span>
<span>fn</span> <span>handle_digit_64</span><span>(</span>bytes<span>:</span> <span>&amp;</span><span>[</span><span>u8</span><span>]</span><span>,</span> data64<span>:</span> <span>u64</span><span>,</span>digit<span>:</span> <span>u8</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>Decimal</span><span>,</span> <span>Error</span><span>&gt;</span> <span>{</span>
    
    <span>let</span> data64 <span>=</span> data64 <span>*</span> <span>10</span> <span>+</span> digit <span>as</span> <span>u64</span><span>;</span>

    <span>if</span> <span>let</span> <span>Some</span><span>(</span><span>(</span>next<span>,</span> bytes<span>)</span><span>)</span> <span>=</span> bytes<span>.</span><span>split_first</span><span>(</span><span>)</span> <span>{</span>
        <span>let</span> next <span>=</span> <span>*</span>next<span>;</span>
        <span>if</span> <span>overflow_64</span><span>(</span>data64<span>)</span> <span>{</span>
            <span>handle_full_128</span><span>(</span>data64 <span>as</span> <span>u128</span><span>,</span> bytes<span>,</span> next<span>)</span>
        <span>}</span> <span>else</span> <span>{</span>
            <span>byte_dispatch_u64</span><span>(</span>bytes<span>,</span> data64<span>,</span> next<span>)</span>
        <span>}</span>
    <span>}</span> <span>else</span> <span>{</span>
        <span>finish_data</span><span>(</span>data <span>as</span> <span>u128</span><span>)</span>
    <span>}</span>
<span>}</span>

<span>#[inline(never)]</span>
<span>fn</span> <span>handle_point</span><span>(</span>bytes<span>:</span> <span>&amp;</span><span>[</span><span>u8</span><span>]</span><span>,</span> data64<span>:</span> <span>u64</span><span>)</span> <span>-&gt;</span> <span>Result</span><span>&lt;</span><span>Decimal</span><span>,</span> <span>Error</span><span>&gt;</span> <span>{</span>
    <span>if</span> <span>let</span> <span>Some</span><span>(</span><span>(</span>next<span>,</span> bytes<span>)</span><span>)</span> <span>=</span> bytes<span>.</span><span>split_first</span><span>(</span><span>)</span> <span>{</span>
        <span>byte_dispatch_u64</span><span>(</span>bytes<span>,</span> data64<span>,</span> <span>*</span>next<span>)</span>
    <span>}</span> <span>else</span> <span>{</span>
        <span>finish_data</span><span>(</span>data64 <span>as</span> <span>u128</span><span>)</span>
    <span>}</span>
<span>}</span></code></pre></div>
<p>You can see from the code that each call does some small incremental part of parsing and decides where to dispatch or whether to build the final Decimal.
The expanded control flow graph, with functions outlined by blocks and error paths removed for brevity, looks something like:</p>
<p><img src="https://cantortrading.fi/98a6acd42203c24e76dcdd8eab130fd9/flow_tail.svg" alt="Control flow of tail call parser"/></p>
<p>You can also see that the generated code is very straightforward, especially given that each call includes dispatching and decimal-completion code:</p>
<div data-language="asm"><pre><code>handle_digit:
    -- Decimal manipulation
    lea    (%rcx,%rcx,4),%rax
    movzbl %r8b,%ecx
    lea    (%rcx,%rax,2),%rcx

    -- Bounds checking
    sub    $0x1,%rdx
    jb     &lt;complete decimal&gt;

    -- Dispatch next
    movzbl (%rsi),%eax
    add    $0x1,%rsi
    lea    -0x30(%rax),%r8d
    cmp    $0xa,%r8b
    jb     &lt;handle_digit&gt;
    cmp    $0x2e,%al
    jne    &lt;handle_digit&gt;
    jmp    &lt;handle_point&gt;

    -- Construct Decimal (entered from function prelude)
    test   %ecx,%ecx
    setne  %al
    mov    %rcx,%rdx
    shr    $0x20,%rdx
    setne  %dl
    or     %al,%dl
    movzbl %dl,%eax
    shl    $0x1f,%rax
    mov    %rcx,0xc(%rdi)
    mov    %rax,0x4(%rdi)
    movl   $0x0,(%rdi)
    ret

    -- dispatch non-numeric-or &#39;.&#39; character
    movzbl %al,%r8d
    jmp    &lt;non_digit_dispatch&gt;
    add    %al,(%rax)</code></pre></div>
<p>While embedding dispatch and decimal construction into each operation increases code size, it offsets that by allowing for more optimization and specialized predictions on a per-node basis.</p>
<p>We take the specialization trick one step further to get another speedup - we move some of the parser state to a set of compile time booleans and use these to gate off checks in the code.</p>
<p>For example, the actual handle_digit_u64 signature is more like</p>
<div data-language="rust"><pre><code><span>fn</span> <span>handle_digit_64</span><span>&lt;</span>
  <span>const</span> <span>POINT</span><span>:</span> <span>bool</span><span>,</span>
  <span>const</span> <span>NEG</span><span>:</span> <span>bool</span><span>,</span><span>:</span>w
  
  <span>const</span> <span>HAS</span><span>:</span> <span>bool</span><span>,</span>
  <span>const</span> <span>BIG</span><span>:</span> <span>bool</span>
<span>&gt;</span><span>(</span>
    bytes<span>:</span> <span>&amp;</span><span>[</span><span>u8</span><span>]</span><span>,</span>
    data64<span>:</span> <span>u64</span><span>,</span>
    digit<span>:</span> <span>u8</span><span>,</span>
<span>)</span></code></pre></div>
<p>Parameterized by a set of checkpoints we expect to encounter while parsing decimals.
For example, POINT and BIG refer to whether we have seen a ’.’ yet and whether the string is long enough to cause overflow.</p>
<p>We can re-write some of the code above to remove branches that we don’t need to evaluate statically:</p>
<div data-language="rust"><pre><code>
<span>b&#39;.&#39;</span> <span>if</span> <span>!</span><span>POINT</span> <span>=&gt;</span> <span>handle_point</span><span>(</span>bytes<span>,</span> data64<span>)</span>




<span>if</span> <span>BIG</span> <span>&amp;&amp;</span> <span>overflow_64</span><span>(</span>data64<span>)</span> <span>{</span>
    <span>handle_full_128</span><span>(</span>data64 <span>as</span> <span>u128</span><span>,</span> bytes<span>,</span> next<span>)</span>
<span>}</span> <span>else</span> <span>{</span>
    <span>byte_dispatch_u64</span><span>(</span>bytes<span>,</span> data64<span>,</span> next<span>)</span>
<span>}</span>



<span>if</span> <span>let</span> <span>Some</span><span>(</span><span>(</span>next<span>,</span> bytes<span>)</span><span>)</span> <span>=</span> bytes<span>.</span><span>split_first</span><span>(</span><span>)</span> <span>{</span>
    
    byte_dispatch_u64<span>&lt;</span><span>POINT</span><span>=</span><span>true</span><span>&gt;</span><span>(</span>bytes<span>,</span> data64<span>,</span> <span>*</span>next<span>)</span>
<span>}</span> <span>else</span> <span>{</span>
    <span>finish_data</span><span>(</span>data64 <span>as</span> <span>u128</span><span>)</span>
<span>}</span></code></pre></div>
<p>This also allows us to swap between specialized parsers at runtime, with the only serious cost being additional code bloat - and even more aggressive optimizations and specialized dispatch sites offset the code bloat.</p>
<p>This change brings us another 30% performance gain (on my M1 laptop an impressive 50%!):</p>
<ul>
<li>Decimal sample benchmark: <code>132ns/iter</code></li>
<li>Market data benchmark: <code>7.4us/iter</code></li>
</ul>
<p>Since we’ve already removed most of the decimal parsing overhead, this change “just” leads to a 6% improvement in the message parsing. Given the tight performance constraints, any progress is still a win.</p>
<h3 id="non-guaranteed-tail-calls"><a href="#non-guaranteed-tail-calls" aria-label="non guaranteed tail calls permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Non-guaranteed tail calls</h3>
<p>Unfortunately, Rust cannot guarantee tail calls. <a href="https://github.com/rust-lang/rfcs/pull/1888">An RFC has been in the works since 2017</a>, but it appears to be in some mix of dead/stuck-in-limbo. Even though tail calls bring a massive performance increase (1.5-2x depending on platform), the lack of compiler support means our options are:</p>
<ul>
<li>Trust the optimizer in release and use a different strategy in debug</li>
<li>Try to construct some fast loop/match structure, although it’s hard to express things like specialized parsers and per-location dispatch.</li>
<li>Fall back to C/C++ and <code>#[musttail]</code> for the 50%+ performance gain or keep a slower rust implementation</li>
</ul>
<p>Writing parsers is where Rust shines - the rust-decimal parser only uses safe and panic-free methods to access the array while using high-level abstractions like const generics to get many specialized parsers out of one function. Adding guaranteed tail calls will be another reason to choose Rust over less-safe alternatives.</p>
<h2 id="whats-next"><a href="#whats-next" aria-label="whats next permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>What’s next</h2>
<p>Optimizing rust-decimal’s string parsing is a great demonstration that you don’t always need magic algorithms to make things fast.
We eschewed complex float parsing optimizations in favor of aggressively optimizing the simple code and removed float parsing as a significant bottleneck.
<a href="https://github.com/paupino/rust-decimal/pull/456">We’re also upstreaming this change</a>!
There are plenty of places throughout the rest of rust-decimal to use similar optimizations, and we plan to apply them piece-by-piece to help make rust-decimal the fastest base-10 number library.</p>
<p>If you find this article interesting, we’re hiring rust engineers! We’re especially interested in speaking to people with a background in high-performance computing and deep knowledge of networking/web protocols (TCP, DNS, HTTP, etc). Send us an email at <a href="mailto:info@cantortrading.fi">info@cantortrading.fi</a> if you’d like to talk.</p></section></article></div>
  </body>
</html>
