<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://lwn.net/Articles/940973/">Original</a>
    <h1>A more dynamic software I/O TLB</h1>
    
    <div id="readability-page-1" class="page"><div>
<center>
           <div><b>LWN.net needs you!</b><p>Without subscribers, LWN would simply not exist.  Please consider
       <a href="https://lwn.net/subscribe/">signing up for a subscription</a> and helping
       to keep LWN publishing</p></div>
           </center>
           <p>
The kernel&#39;s software I/O translation lookaside buffer (&#34;swiotlb&#34;) is an
obscure corner of the DMA-support layer.  The swiotlb was initially
introduced to enable DMA for devices with special challenges, and one might
have expected it to fade away as newer peripherals came along.  Instead,
though, the swiotlb has turned out to be useful in places outside of its
original use cases.  <a href="https://lwn.net/ml/linux-kernel/cover.1690871004.git.petr.tesarik.ext@huawei.com/">This
patch set</a> from Petr Tesarik now aims to update the swiotlb with an eye
toward its continuing use indefinitely into the future.
</p><p>
One of the fundamental features of any reasonably capable I/O device is its
ability to perform DMA — accessing data directly in main memory without the
need to go through the CPU.  Without DMA, I/O performance will be severely
limited.  But some devices are better at DMA than others.  Older devices
for PC-class hardware, reflecting the history of that architecture, were
often limited to 24 bits of address space for DMA transfers, meaning
that they could only access the lower 16MB of memory.  That was plenty in
the early days, but quickly became limiting as memory sizes grew.  Another
common problem is a 32-bit limitation, restricting access to the lower 4GB
of memory.
</p><p>
The kernel has an extensive support layer that is intended to hide, as much
as possible, the limitations of any given device.  So, for example, when
dealing with a device that has addressing limitations, the kernel will
endeavor to allocate memory within the range that the device can reach.
There are times, though, when that cannot be done.  There may simply not be
a sufficiently large contiguous chunk of memory available in a place where
the device can reach it, for example.  But, more often, the data to be
transferred was placed without consideration for a device&#39;s limitations.
User-space buffers and the kernel&#39;s page cache, for example, cannot be
restricted to a low range of memory just in case they might be handed to an
address-limited device.
</p><p>
The solution in this case is to employ a &#34;bounce buffer&#34;.  The kernel
maintains some low-address memory to support DMA operations.  When needed,
a portion of the memory will be allocated to be used by the device for I/O.
The kernel will copy data from the actual buffer into the bounce buffer
(before the operation, for writes) or from the bounce buffer into the
actual buffer (after the operation, for reads) as needed.  Bounce buffers
slow things down, but that is better than not being able to perform I/O at
all.
</p><p>
Managing the memory for bounce buffers is the job of the swiotlb.  This
little subsystem might have once been expected to become unnecessary over
time.  As newer devices replace older ones, addressing limitations should
eventually disappear.  For the cases where they don&#39;t disappear, the
increasing use of I/O memory-management units, which provide a separate
address space for devices into which buffers can be mapped, would take care
of the problem.  Either way, there should be no need for the kernel to
continue copying data for I/O through the CPU.
</p><p>
As Tesarik pointed out in the cover letter to the swiotlb patch series,
though, that is not quite how things have turned out.  Vendors continue to
churn out systems, especially in the embedded space, that can handle more
memory than their built-in devices can address.  Other use cases have come
along as well.  One that is turning up now is confidential-computing
applications, where systems may be running with encrypted memory that
devices are unable to access.  Confidential-computing systems can end up
using bounce buffers for <i>all</i> of their I/O, regardless of whether the
devices being used have addressing limitations.
</p><p>
So it seems like the swiotlb is going to stay around for a while, which
suggests that fixing some of its own limitations might make sense.  By
default, the swiotlb allocates 64MB of memory at system boot; that behavior
can be adjusted with the <tt>swiotlb=</tt> command-line parameter.  That
allocation is intentionally rather small; it was intended to not use much
RAM while, hopefully, providing enough memory for the system&#39;s limited
(hopefully) bounce-buffering needs.  But 64MB can be too large a cost for
some memory-constrained embedded systems, while being too small for systems
where a lot of I/O must be bounce-buffered.  The swiotlb, in other words,
needs to become more dynamic.
</p><p>
Devices with addressing limitations are also, often, unable to perform
scatter/gather I/O, meaning that they need to be presented with a single,
physically contiguous buffer.  So the swiotlb must be able to allocate
physically contiguous memory, a task that has traditionally gotten harder
as a system runs and its memory becomes fragmented; that is one of the reasons why
swiotlb memory is allocated early in the boot process.  A dynamic swiotlb
will have to be able to allocate memory at any point, though.
</p><p>
The good news is that allocating physically contiguous chunks of memory has
gotten easier over time.  The work that has gone into segregating movable
and reclaimable allocations has made memory compaction more successful;
this helps with the allocation of huge pages — and other large, contiguous
memory ranges, such as bounce buffers.  The kernel&#39;s <a href="https://lwn.net/Articles/486301/">contiguous memory allocator (CMA)</a> is also
helpful in this regard.  So it is not entirely unreasonable to expect that
memory for bounce buffers can be allocated at any point in the system&#39;s
operation.
</p><p>
A system with the dynamic swiotlb patches applied will start with the same,
small allocation at the beginning — though users may want to make it
smaller.  Whenever a request for a bounce buffer cannot be satisfied, the
swiotlb will allocate more memory.  Here, things get a little complicated,
though; bounce buffers can be allocated in contexts like interrupt
handlers, which cannot block.  So the swiotlb cannot allocate a new pool,
sufficient for a number of future requests at that time.  Instead, the
requested space will be allocated directly from the memory-management
subsystem, and a function call will be kicked off via a workqueue to do the
larger allocation in a more forgiving context.
</p><p>
The &#34;transient&#34; buffers allocated when the swiotlb runs out of pool memory
will be freed back to the system once they are unmapped.  The regular
pools, though, are held onto forever; once the pool grows, it will stay
larger.  This policy may make sense; a device that needs a certain amount
of bounce buffering will likely continue to need those buffers in the
future.  Meanwhile, the swiotlb as a whole will probably stay small enough
that retaining that memory should not be a problem.  That said, it would
not be entirely surprising to see some sort of shrinker mechanism added to
the swiotlb in the future.
</p><p>
This patch set has been through seven revisions and developers seem to be
mostly happy with it.  Christoph Hellwig has <a href="https://lwn.net/ml/linux-kernel/20230801160339.GB13111@lst.de/">applied the
series</a>, presumably to be pushed into the mainline during the 6.6 merge
window.  Of course, like every other kernel project, the work here is never
really done; Tesarik has already <a href="https://lwn.net/ml/linux-kernel/56be3268-60ee-a496-4781-a59ce34bfca8@huaweicloud.com/">let
it be known</a> that there are follow-up patches in the works.<br clear="all"/></p><table>
           <tbody><tr><th colspan="2">Index entries for this article</th></tr>
           <tr><td><a href="https://lwn.net/Kernel/Index">Kernel</a></td><td><a href="https://lwn.net/Kernel/Index#Direct_memory_access">Direct memory access</a></td></tr>
            <tr><td><a href="https://lwn.net/Kernel/Index">Kernel</a></td><td><a href="https://lwn.net/Kernel/Index#Releases-6.6">Releases/6.6</a></td></tr>
            <tr><td><a href="https://lwn.net/Kernel/Index">Kernel</a></td><td><a href="https://lwn.net/Kernel/Index#swiotlb">swiotlb</a></td></tr>
            </tbody></table></div></div>
  </body>
</html>
