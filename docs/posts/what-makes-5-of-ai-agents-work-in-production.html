<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.motivenotes.ai/p/what-makes-5-of-ai-agents-actually">Original</a>
    <h1>What makes 5% of AI agents work in production?</h1>
    
    <div id="readability-page-1" class="page"><div><div dir="auto"><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!US5o!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffc246083-44f6-4842-9b08-8ebca1d340d4_1179x617.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!US5o!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffc246083-44f6-4842-9b08-8ebca1d340d4_1179x617.png 424w, https://substackcdn.com/image/fetch/$s_!US5o!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffc246083-44f6-4842-9b08-8ebca1d340d4_1179x617.png 848w, https://substackcdn.com/image/fetch/$s_!US5o!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffc246083-44f6-4842-9b08-8ebca1d340d4_1179x617.png 1272w, https://substackcdn.com/image/fetch/$s_!US5o!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffc246083-44f6-4842-9b08-8ebca1d340d4_1179x617.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/$s_!US5o!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffc246083-44f6-4842-9b08-8ebca1d340d4_1179x617.png" width="636" height="332.83460559796436" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/fc246083-44f6-4842-9b08-8ebca1d340d4_1179x617.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:617,&#34;width&#34;:1179,&#34;resizeWidth&#34;:636,&#34;bytes&#34;:1276829,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:false,&#34;topImage&#34;:true,&#34;internalRedirect&#34;:null,&#34;isProcessing&#34;:false,&#34;align&#34;:null,&#34;offset&#34;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!US5o!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffc246083-44f6-4842-9b08-8ebca1d340d4_1179x617.png 424w, https://substackcdn.com/image/fetch/$s_!US5o!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffc246083-44f6-4842-9b08-8ebca1d340d4_1179x617.png 848w, https://substackcdn.com/image/fetch/$s_!US5o!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffc246083-44f6-4842-9b08-8ebca1d340d4_1179x617.png 1272w, https://substackcdn.com/image/fetch/$s_!US5o!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ffc246083-44f6-4842-9b08-8ebca1d340d4_1179x617.png 1456w" sizes="100vw" fetchpriority="high"/></picture><div><div></div></div></div></a></figure></div><p>Most founders think they’re building AI products. They’re actually building context selection systems.</p><p><span>This Monday, I moderated a panel in San Francisco with engineers and ML leads from Uber, </span><a href="https://wisdom.ai" rel="">WisdomAI</a><span>, EvenUp, and Datastrato. </span><a href="https://luma.com/h8z29odb?tk=ctCqur&amp;utm=EntreConnect" rel="">The event, </a><em><a href="https://luma.com/h8z29odb?tk=ctCqur&amp;utm=EntreConnect" rel="">Beyond the Prompt</a></em><a href="https://luma.com/h8z29odb?tk=ctCqur&amp;utm=EntreConnect" rel="">, drew 600+ </a><span>registrants, mostly founders, engineers, and early AI product builders.</span></p><p>We weren’t there to rehash prompt engineering tips.</p><p>We talked about context engineering, inference stack design, and what it takes to scale agentic systems inside enterprise environments. If “prompting” is the tip of the iceberg, this panel dove into the cold, complex mass underneath: context selection, semantic layers, memory orchestration, governance, and multi-model routing.</p><p><strong>Here’s the reality check:</strong><span> One panelist mentioned that </span><a href="https://fortune.com/2025/08/18/mit-report-95-percent-generative-ai-pilots-at-companies-failing-cfo/" rel="">95% of AI agent deployments fail</a><span> in production. Not because the models aren’t smart enough, but because the scaffolding around them, context engineering, security, memory design, isn’t there yet.</span></p><p>One metaphor from the night stuck with me:</p><blockquote><p>“The base models are the soil; context is the seed.”</p></blockquote><p><span>I’ve been obsessed with </span><a href="https://oanao.substack.com/" rel="">semantic layers</a><span> for a while now, not because they’re flashy, but because they’re where founders quietly build trust, utility, and differentiation into LLM systems. I’ve seen too many teams conflate prompting with product. This panel felt like a moment where the real engineering work started getting its due.</span></p><p>Below are the takeaways, not just quotes, but patterns I see repeating in serious AI teams. If you’re building at the infra, tooling, or vertical AI layer, this is the scaffolding you’ll need to get right.</p><p><span>Several panelists echoed the same insight: </span><strong>fine-tuning is rarely necessary</strong><span>. Retrieval-augmented generation (RAG), when done well, is enough. But most RAG systems today are too naive.</span></p><p><strong>The failure mode:</strong></p><ul><li><p>Index everything → retrieve too much → confuse the model</p></li><li><p>Index too little → starve the model of signal</p></li><li><p>Mix structured + unstructured data → break embeddings or flatten key schema</p></li></ul><p>So what does advanced context engineering actually look like?</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!1yP3!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc1cc1987-2458-4da9-9e87-82c1ea36fb64_1024x1536.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!1yP3!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc1cc1987-2458-4da9-9e87-82c1ea36fb64_1024x1536.png 424w, https://substackcdn.com/image/fetch/$s_!1yP3!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc1cc1987-2458-4da9-9e87-82c1ea36fb64_1024x1536.png 848w, https://substackcdn.com/image/fetch/$s_!1yP3!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc1cc1987-2458-4da9-9e87-82c1ea36fb64_1024x1536.png 1272w, https://substackcdn.com/image/fetch/$s_!1yP3!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc1cc1987-2458-4da9-9e87-82c1ea36fb64_1024x1536.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/$s_!1yP3!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc1cc1987-2458-4da9-9e87-82c1ea36fb64_1024x1536.png" width="326" height="489" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/c1cc1987-2458-4da9-9e87-82c1ea36fb64_1024x1536.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:1536,&#34;width&#34;:1024,&#34;resizeWidth&#34;:326,&#34;bytes&#34;:null,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:null,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null,&#34;isProcessing&#34;:false,&#34;align&#34;:null,&#34;offset&#34;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!1yP3!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc1cc1987-2458-4da9-9e87-82c1ea36fb64_1024x1536.png 424w, https://substackcdn.com/image/fetch/$s_!1yP3!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc1cc1987-2458-4da9-9e87-82c1ea36fb64_1024x1536.png 848w, https://substackcdn.com/image/fetch/$s_!1yP3!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc1cc1987-2458-4da9-9e87-82c1ea36fb64_1024x1536.png 1272w, https://substackcdn.com/image/fetch/$s_!1yP3!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fc1cc1987-2458-4da9-9e87-82c1ea36fb64_1024x1536.png 1456w" sizes="100vw" loading="lazy"/></picture><div><div></div></div></div></a></figure></div><p><span>Read more about the context layer </span><a href="https://www.wisdom.ai/ai-for-business-intelligence/semantic-layer" rel="">here</a><span>.</span></p><p>One speaker reframed context engineering as LLM-native feature engineering:</p><ul><li><p><strong>Selective context pruning</strong><span> = feature selection</span></p></li><li><p><strong>Context validation</strong><span> = schema/type/recency checks</span></p></li><li><p><strong>“Context observability”</strong><span> = trace which inputs improved/worsened output quality</span></p></li><li><p><strong>Embedding augmentation with metadata</strong><span> = typed features + conditions</span></p></li></ul><p>This framing matters. It means you can treat context like a versioned, auditable, testable artifact , not a string blob.</p><p>Several teams described dual-layer architectures:</p><ul><li><p><strong>Semantic layer</strong><span> → classic vector search</span></p></li><li><p><strong>Metadata layer</strong><span> → enforce filters based on document type, timestamp, access permissions, or vertical ontology</span></p></li></ul><p><span>This hybrid layer helps normalize across messy input formats (PDFs, audio, logs, metrics) and ensures you’re not just retrieving “similar content,” but </span><em>relevant structured knowledge</em><span>. Think: taxonomies, entity linking, and domain-specific schemas on top of embeddings.</span></p><p>When the moderator asked the audience “How many of you have built text-to-SQL and put it into production?”, not a single hand went up.</p><p><span>This isn’t because the problem is niche, it’s because </span><strong>query understanding is brutally hard</strong><span>. Natural language is ambiguous. Business terminology is domain-specific. And LLMs don’t know your company’s definition of “revenue” or “active user” without extensive context engineering.</span></p><p>The teams that succeed don’t just throw SQL schemas at the model. They build:</p><ul><li><p>Business glossaries and term mappings</p></li><li><p>Query templates with constraints</p></li><li><p>Validation layers that catch semantic errors before execution</p></li></ul><p><span>Feedback loops that improve understanding over time - read more </span><a href="https://www.wisdom.ai/ai-for-business-intelligence/text-to-sql" rel="">here</a><span>.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!41GS!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9f111e4-1594-4d75-9576-2d6d170f642d_1240x514.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!41GS!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9f111e4-1594-4d75-9576-2d6d170f642d_1240x514.png 424w, https://substackcdn.com/image/fetch/$s_!41GS!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9f111e4-1594-4d75-9576-2d6d170f642d_1240x514.png 848w, https://substackcdn.com/image/fetch/$s_!41GS!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9f111e4-1594-4d75-9576-2d6d170f642d_1240x514.png 1272w, https://substackcdn.com/image/fetch/$s_!41GS!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9f111e4-1594-4d75-9576-2d6d170f642d_1240x514.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/$s_!41GS!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9f111e4-1594-4d75-9576-2d6d170f642d_1240x514.png" width="1240" height="514" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/b9f111e4-1594-4d75-9576-2d6d170f642d_1240x514.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:514,&#34;width&#34;:1240,&#34;resizeWidth&#34;:null,&#34;bytes&#34;:1110498,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:&#34;https://www.motivenotes.ai/i/175120454?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9f111e4-1594-4d75-9576-2d6d170f642d_1240x514.png&#34;,&#34;isProcessing&#34;:false,&#34;align&#34;:null,&#34;offset&#34;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!41GS!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9f111e4-1594-4d75-9576-2d6d170f642d_1240x514.png 424w, https://substackcdn.com/image/fetch/$s_!41GS!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9f111e4-1594-4d75-9576-2d6d170f642d_1240x514.png 848w, https://substackcdn.com/image/fetch/$s_!41GS!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9f111e4-1594-4d75-9576-2d6d170f642d_1240x514.png 1272w, https://substackcdn.com/image/fetch/$s_!41GS!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb9f111e4-1594-4d75-9576-2d6d170f642d_1240x514.png 1456w" sizes="100vw" loading="lazy"/></picture><div><div></div></div></div></a></figure></div><p><span>Security, lineage, and permissioning came up again and again, not as check-the-box items, but as </span><strong>blockers to deployment</strong><span>.</span></p><ul><li><p><strong>You must trace which inputs led to which outputs</strong><span> (lineage)</span></p></li><li><p><strong>You must respect row level, role based access</strong><span> (policy gating)</span></p></li><li><p><strong>You must allow user specific output even if the prompt is the same</strong></p></li></ul><p>One speaker said:</p><blockquote><p>“If two employees ask the same question, the model output should differ, because they have different permissions.”</p></blockquote><p>Without these controls, your agent may be functionally right but organizationally wrong, leaking access or violating compliance.</p><p><span>The leading pattern here: </span><strong>unified metadata catalogs</strong><span> for both structured + unstructured data, with embedded access policies at index + query time.</span></p><p>One panelist shared a personal story that crystallized the challenge: his wife refuses to let him use Tesla’s autopilot. Why? Not because it doesn’t work, but because she doesn’t trust it.</p><blockquote><p>“When AI touches very sensitive parts about your safety, your money, did you trust AI? I think that is the one big blocker. We do AI agents sometimes, but it’s a human being thinking: do I really trust the AI?”</p></blockquote><p>This isn’t just about consumer products. The same barrier exists for enterprise AI agents making decisions about revenue recognition, medical records, or compliance reporting. Trust isn’t about raw capability, it’s about consistent, explainable, auditable behavior.</p><p><span>The successful 5% of AI agents? They all have one thing in common: </span><strong>human-in-the-loop design</strong><span>. They position AI as an assistant, not an autonomous decision maker. They create feedback loops where the system learns from corrections. They make it easy for humans to verify and override.</span></p><p>Everyone wants to “add memory.” But memory isn’t a feature, it’s a design decision with UX, privacy, and system implications.</p><ul><li><p><strong>User level</strong><span>: preferences (e.g., chart types, style, writing tone)</span></p></li><li><p><strong>Team level</strong><span>: recurring queries, dashboards, runbooks</span></p></li><li><p><strong>Org level</strong><span>: institutional knowledge, policies, prior decisions</span></p></li></ul><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!fhq7!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f0d6b7f-ebcb-46d8-9491-82f6657a18e7_1024x1536.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!fhq7!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f0d6b7f-ebcb-46d8-9491-82f6657a18e7_1024x1536.png 424w, https://substackcdn.com/image/fetch/$s_!fhq7!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f0d6b7f-ebcb-46d8-9491-82f6657a18e7_1024x1536.png 848w, https://substackcdn.com/image/fetch/$s_!fhq7!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f0d6b7f-ebcb-46d8-9491-82f6657a18e7_1024x1536.png 1272w, https://substackcdn.com/image/fetch/$s_!fhq7!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f0d6b7f-ebcb-46d8-9491-82f6657a18e7_1024x1536.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/$s_!fhq7!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f0d6b7f-ebcb-46d8-9491-82f6657a18e7_1024x1536.png" width="300" height="450" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/3f0d6b7f-ebcb-46d8-9491-82f6657a18e7_1024x1536.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:1536,&#34;width&#34;:1024,&#34;resizeWidth&#34;:300,&#34;bytes&#34;:null,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:null,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null,&#34;isProcessing&#34;:false,&#34;align&#34;:null,&#34;offset&#34;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!fhq7!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f0d6b7f-ebcb-46d8-9491-82f6657a18e7_1024x1536.png 424w, https://substackcdn.com/image/fetch/$s_!fhq7!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f0d6b7f-ebcb-46d8-9491-82f6657a18e7_1024x1536.png 848w, https://substackcdn.com/image/fetch/$s_!fhq7!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f0d6b7f-ebcb-46d8-9491-82f6657a18e7_1024x1536.png 1272w, https://substackcdn.com/image/fetch/$s_!fhq7!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3f0d6b7f-ebcb-46d8-9491-82f6657a18e7_1024x1536.png 1456w" sizes="100vw" loading="lazy"/></picture><div><div></div></div></div></a></figure></div><p><span>Most startups hard-code memory into app logic or local storage. But the best teams abstract it as a </span><strong>context layer + behavior layer</strong><span>, versioned and composable. One speaker described this as:</span></p><blockquote><p><span>“Semantic memory + taxonomy + runbooks = context.</span></p></blockquote><p>At the application level, memory serves two purposes:</p><ol><li><p><strong>Customizing behavior</strong><span> to individual users, their writing style, preferred formats, domain expertise</span></p></li><li><p><strong>Proactive assistance</strong><span> based on events and metadata, not just reactive chat responses</span></p></li></ol><p>One team described building a conversational BI tool at Uber. The cold-start problem? Users don’t know what to ask. The solution? Build memory from their past query logs, then suggest relevant questions as conversation starters, like a good host who remembers what you talked about last time.</p><p>But here’s the tension: when does helpful personalization cross into creepy surveillance?</p><p>One panelist described asking ChatGPT for family movie recommendations, only to have it respond with suggestions tailored to his children by name, Claire and Brandon. His reaction? “I don’t like this answer. Why do you know my son and my girl so much? Don’t touch my privacy.”</p><ul><li><p>Memory improves UX and agent fluency</p></li><li><p>But over-personalization can creep into privacy territory fast</p></li><li><p>And shared memory can break access controls unless carefully scoped</p></li></ul><p><strong>There’s a missing primitive here</strong><span>: a secure, portable memory layer that works </span><em>across</em><span> apps , usable by the user, not locked inside the provider. No one’s nailed it yet. One panelist said if he weren’t building his current startup, this would be his next one.</span></p><p>If you’re building this, call me.</p><p><span>Another emergent design: </span><strong>model orchestration</strong><span>.</span></p><p>In production, you don’t just call GPT-4 for everything. Teams increasingly run model routing logic based on:</p><ul><li><p>Task complexity</p></li><li><p>Latency constraints</p></li><li><p>Cost sensitivity</p></li><li><p>Data locality / regulatory concerns</p></li><li><p>Query type (e.g., summarization vs semantic search vs structured QA)</p></li></ul><ul><li><p>For trivial queries → local model (no network call)</p></li><li><p>For structured queries → call DSL → SQL translator</p></li><li><p>For complex analysis → call OpenAI / Anthropic / Gemini</p></li><li><p>Fallback or verification → dual-model redundancy (judge + responder)</p></li></ul><p><span>This is closer to </span><strong>compiler design than webapp routing</strong><span>. You’re not just “sending to LLM” , you’re running a DAG of decisions across heterogeneous models, tools, and validations.</span></p><p>If your system gets slower or more expensive as usage grows, this is the first layer to revisit. And if you want AI to feel seamless to users, routing can’t be brittle or hand tuned forever. You’ll need adaptive policies.</p><p>One team described their approach: simple questions go to small, fast models. Complex reasoning tasks get routed to frontier models. The key insight? The model selection itself can be learned over time by tracking which queries succeed with which models.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!5mqc!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6302aa0-dde3-4a56-af8f-50b7ae726ebb_1179x851.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!5mqc!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6302aa0-dde3-4a56-af8f-50b7ae726ebb_1179x851.png 424w, https://substackcdn.com/image/fetch/$s_!5mqc!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6302aa0-dde3-4a56-af8f-50b7ae726ebb_1179x851.png 848w, https://substackcdn.com/image/fetch/$s_!5mqc!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6302aa0-dde3-4a56-af8f-50b7ae726ebb_1179x851.png 1272w, https://substackcdn.com/image/fetch/$s_!5mqc!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6302aa0-dde3-4a56-af8f-50b7ae726ebb_1179x851.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/$s_!5mqc!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6302aa0-dde3-4a56-af8f-50b7ae726ebb_1179x851.png" width="582" height="420.08651399491094" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/f6302aa0-dde3-4a56-af8f-50b7ae726ebb_1179x851.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:851,&#34;width&#34;:1179,&#34;resizeWidth&#34;:582,&#34;bytes&#34;:null,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:null,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null,&#34;isProcessing&#34;:false,&#34;align&#34;:null,&#34;offset&#34;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!5mqc!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6302aa0-dde3-4a56-af8f-50b7ae726ebb_1179x851.png 424w, https://substackcdn.com/image/fetch/$s_!5mqc!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6302aa0-dde3-4a56-af8f-50b7ae726ebb_1179x851.png 848w, https://substackcdn.com/image/fetch/$s_!5mqc!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6302aa0-dde3-4a56-af8f-50b7ae726ebb_1179x851.png 1272w, https://substackcdn.com/image/fetch/$s_!5mqc!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Ff6302aa0-dde3-4a56-af8f-50b7ae726ebb_1179x851.png 1456w" sizes="100vw" loading="lazy"/></picture><div><div></div></div></div></a></figure></div><p>Not every task needs a chatbot.</p><p>One audience member challenged the premise directly: “I’m not sure natural language is always preferable to a GUI. If I’m ordering an Uber, I don’t want to speak to a phone. I just tap, tap, tap, I’ve got my car.”</p><p><span>The panel’s consensus: </span><strong>conversation works when it removes a learning curve</strong><span>.</span></p><p>For complex tools like BI dashboards or data analysis where there’s traditionally been expertise required, natural language lowers the barrier to entry. But once you have an answer, users often want GUI controls, switching a pie chart to a bar chart shouldn’t require more typing.</p><ul><li><p>Start with chat for zero-learning-curve entry</p></li><li><p>Provide GUI controls for refinement and iteration</p></li><li><p>Let users choose their mode based on task and preference</p></li></ul><p>One panelist described two perfect use cases for NLP:</p><ol><li><p><strong>Sporadic, emotional tasks</strong><span>, like customer service, where someone is frustrated and just wants to vent or get help without navigating menus</span></p></li><li><p><strong>Exploratory, open-ended queries</strong><span>, like “find me an Airbnb near California, first row, with an ocean view and blue sky” where the requirements are complex and contextual</span></p></li></ol><p><span>The key insight: we should understand </span><em>why</em><span> people want to use natural language and design for that intent, not force every interaction into chat.</span></p><p>Several ideas came up that feel underexplored , real primitives waiting to be productized:</p><p>What inputs consistently improve output? What kinds of context lead to hallucination? How do you test context like you test model prompts?</p><p>Right now, most teams are flying blind, they don’t have systematic ways to measure which context actually helps vs hurts model performance.</p><p>Could memory live with the user (not the app), portable and secure, with opt-in layers for org vs team vs personal state?</p><p>This solves two problems:</p><ol><li><p>Users don’t have to rebuild their context in every new tool</p></li><li><p>Privacy and security are user-controlled, not vendor-locked</p></li></ol><p>This is the biggest missing primitive in the stack.</p><p>Most of what business users want is structured and repetitive. Why are we still trying to parse natural language into brittle SQL instead of defining higher-level, constraint safe DSLs?</p><p>One team suggested that instead of text-to-SQL, we should build semantic business logic layers, “show me Q4 revenue” should map to a verified calculation, not raw SQL generation.</p><p>One panelist described a memory enhanced chatbot that responded slowly, but delightfully. Why? It showed a sequence of intelligent follow-ups based on what the user had asked last week.</p><p><span>There’s a UX unlock here for </span><strong>async, proactive AI</strong><span> , not just chat. Think: agents that prepare briefings before your meetings, surface relevant context when you open a document, or alert you to anomalies in your data before you ask.</span></p><p>The key insight: different tasks have different latency requirements. A joke should be instant. Deep analysis can take 10 seconds if it’s showing progress and feels intelligent.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!YFnt!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3474f19d-0d9b-4b7a-b914-34819b602081_1179x884.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!YFnt!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3474f19d-0d9b-4b7a-b914-34819b602081_1179x884.png 424w, https://substackcdn.com/image/fetch/$s_!YFnt!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3474f19d-0d9b-4b7a-b914-34819b602081_1179x884.png 848w, https://substackcdn.com/image/fetch/$s_!YFnt!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3474f19d-0d9b-4b7a-b914-34819b602081_1179x884.png 1272w, https://substackcdn.com/image/fetch/$s_!YFnt!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3474f19d-0d9b-4b7a-b914-34819b602081_1179x884.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/$s_!YFnt!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3474f19d-0d9b-4b7a-b914-34819b602081_1179x884.png" width="574" height="430.3782866836302" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/3474f19d-0d9b-4b7a-b914-34819b602081_1179x884.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:884,&#34;width&#34;:1179,&#34;resizeWidth&#34;:574,&#34;bytes&#34;:1755097,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:null,&#34;isProcessing&#34;:false,&#34;align&#34;:null,&#34;offset&#34;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!YFnt!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3474f19d-0d9b-4b7a-b914-34819b602081_1179x884.png 424w, https://substackcdn.com/image/fetch/$s_!YFnt!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3474f19d-0d9b-4b7a-b914-34819b602081_1179x884.png 848w, https://substackcdn.com/image/fetch/$s_!YFnt!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3474f19d-0d9b-4b7a-b914-34819b602081_1179x884.png 1272w, https://substackcdn.com/image/fetch/$s_!YFnt!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F3474f19d-0d9b-4b7a-b914-34819b602081_1179x884.png 1456w" sizes="100vw" loading="lazy"/></picture><div><div></div></div></div></a></figure></div><p>I left this panel with stronger conviction that we’re about to see a wave of infra tooling, memory kits, orchestration layers, context observability, that’ll look obvious in hindsight. But they’re messy and unsolved today.</p><p>The next real moats in GenAI won’t come from model access, they’ll come from:</p><ul><li><p><strong>Context quality</strong></p></li><li><p><strong>Memory design</strong></p></li><li><p><strong>Orchestration reliability</strong></p></li><li><p><strong>Trust UX</strong></p></li></ul><p>If you’re a founder building infra, apps, or agents: how much of your roadmap explicitly addresses those four?</p><p>Try these as a context/agent system builder:</p><p><strong><span>1. What’s my app’s context budget?</span><br/></strong><span> (What size context window is ideal, and how am I optimizing what goes into it?)</span></p><p><strong><span>2. What’s my memory boundary?</span><br/></strong><span> (What lives at the user level vs team vs org? Where is it stored, and can users see it?)</span></p><p><strong><span>3. Can I trace output lineage?</span><br/></strong><span> (Can I debug an LLM response and know which input led to it?)</span></p><p><strong><span>4. Do I use one model or many?</span><br/></strong><span> (How am I routing requests by complexity, latency, or cost?)</span></p><p><strong><span>5. Would my users trust this system with money or medical data?</span><br/></strong><span> (If not, what’s missing from my security or feedback loop?)</span></p><p>If you’re building in this layer, I want to hear from you. Especially if you’re doing it before everyone else calls it infrastructure.</p><p>And if you’re a technical reader, especially in infra or AI/ML, let me know: would you want a deeper series on context pruning patterns, building dual layer context systems, memory abstractions, or governance by design?</p><p>Or just reply with your biggest “context engineering” headache right now, I’d love to dig into it.</p><p data-attrs="{&#34;url&#34;:&#34;https://www.motivenotes.ai/p/what-makes-5-of-ai-agents-actually/comments&#34;,&#34;text&#34;:&#34;Leave a comment&#34;,&#34;action&#34;:null,&#34;class&#34;:null}" data-component-name="ButtonCreateButton"><a href="https://www.motivenotes.ai/p/what-makes-5-of-ai-agents-actually/comments" rel=""><span>Leave a comment</span></a></p><p data-attrs="{&#34;url&#34;:&#34;https://www.motivenotes.ai/p/what-makes-5-of-ai-agents-actually?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share&#34;,&#34;text&#34;:&#34;Share&#34;,&#34;action&#34;:null,&#34;class&#34;:null}" data-component-name="ButtonCreateButton"><a href="https://www.motivenotes.ai/p/what-makes-5-of-ai-agents-actually?utm_source=substack&amp;utm_medium=email&amp;utm_content=share&amp;action=share" rel=""><span>Share</span></a></p><p><em><span>More essays: </span><a href="https://www.motivenotes.ai/p/are-semantic-layers-the-treasure" rel="">Semantic layers</a><span>, </span><a href="https://www.motivenotes.ai/p/fine-tuning-llms-learnings-from-the?r=8s9n&amp;utm_campaign=post&amp;utm_medium=web&amp;showWelcomeOnShare=false" rel="">Fine Tuning</a><span>, </span><a href="https://www.motivenotes.ai/p/founder-mental-software?r=8s9n&amp;utm_campaign=post&amp;utm_medium=web&amp;showWelcomeOnShare=false" rel="">Founder Mental Software</a><span>, </span><a href="https://www.motivenotes.ai/p/founder-learning-phases-normalizing?r=8s9n&amp;utm_campaign=post&amp;utm_medium=web&amp;showWelcomeOnShare=false" rel="">Normalizing the Founder Journey</a><span>, </span><a href="https://www.motivenotes.ai/p/ai-engineer-worlds-fair-2025-field?r=8s9n&amp;utm_campaign=post&amp;utm_medium=web&amp;showWelcomeOnShare=false" rel="">AI Engineer World’s Fair 2025 - Field Notes</a></em></p></div></div></div>
  </body>
</html>
