<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://arstechnica.com/information-technology/2024/04/apple-releases-eight-small-ai-language-models-aimed-at-on-device-use/">Original</a>
    <h1>Apple releases eight small AI language models aimed at on-device use</h1>
    
    <div id="readability-page-1" class="page"><div>
            <h4>
      Inside the Apple core    —
</h4>
            
            <h2 itemprop="description">OpenELM mirrors efforts by Microsoft to make useful small AI language models that run locally.</h2>
            <section>

  


  
</section>        </div><section>
            <div itemprop="articleBody">
                                    
<figure>
  <img src="https://cdn.arstechnica.net/wp-content/uploads/2024/04/apple_toss_hero_1-800x450.jpg" alt="An illustration of a robot hand tossing an apple to a human hand."/>
      <figcaption><p>Getty Images</p></figcaption>  </figure>

  




<!-- cache hit 418:single/related:a86d0b7aa942134b017bbd22e24da273 --><!-- empty -->
<p>In the world of AI, what might be called &#34;small language models&#34; have been growing in popularity recently because they can be run on a local device instead of requiring data center-grade computers in the cloud. On Wednesday, Apple<a href="https://huggingface.co/apple/OpenELM"> introduced</a> a set of tiny source-available AI language models called OpenELM that are small enough to run directly on a smartphone. They&#39;re mostly proof-of-concept research models for now, but they could form the basis of future on-device AI offerings from Apple.</p>

<p>Apple&#39;s new AI models, collectively named OpenELM for &#34;Open-source Efficient Language Models,&#34; are currently available on the <a href="https://huggingface.co/apple/OpenELM">Hugging Face</a> under an <a href="https://huggingface.co/apple/OpenELM/blob/main/LICENSE">Apple Sample Code License</a>. Since there are some restrictions in the license, it may not fit the <a href="https://opensource.org/osd">commonly accepted definition</a> of &#34;open source,&#34; but the source code for OpenELM is available.</p>
<p>On Tuesday, we covered <a href="https://arstechnica.com/information-technology/2024/04/microsofts-phi-3-shows-the-surprising-power-of-small-locally-run-ai-language-models/">Microsoft&#39;s Phi-3 models</a>, which aim to achieve something similar: a useful level of language understanding and processing performance in small AI models that can run locally. Phi-3-mini features 3.8 billion parameters, but some of Apple&#39;s OpenELM models are much smaller, ranging from 270 million to 3 billion parameters in eight distinct models.</p>
<p>In comparison, the largest model yet released in <a href="https://arstechnica.com/information-technology/2024/04/meta-releases-chatgpt-like-ai-site-and-open-weights-llama-3-model/">Meta&#39;s Llama 3</a> family includes 70 billion parameters (with a 400 billion version on the way), and OpenAI&#39;s GPT-3 from 2020 shipped with 175 billion parameters. Parameter count serves as a rough measure of AI model capability and complexity, but recent research has focused on making smaller AI language models as capable as larger ones were a few years ago.</p>
<p>The eight OpenELM models come in two flavors: four as &#34;pretrained&#34; (basically a raw, next-token version of the model) and four as instruction-tuned (fine-tuned for instruction following, which is more ideal for developing AI assistants and chatbots):</p>                                            
                                                        
<ul>
<li><a href="https://huggingface.co/apple/OpenELM-270M">OpenELM-270M</a></li>
<li><a href="https://huggingface.co/apple/OpenELM-450M">OpenELM-450M</a></li>
<li><a href="https://huggingface.co/apple/OpenELM-1_1B">OpenELM-1_1B</a></li>
<li><a href="https://huggingface.co/apple/OpenELM-3B">OpenELM-3B</a></li>
<li><a href="https://huggingface.co/apple/OpenELM-270M-Instruct">OpenELM-270M-Instruct</a></li>
<li><a href="https://huggingface.co/apple/OpenELM-450M-Instruct">OpenELM-450M-Instruct</a></li>
<li><a href="https://huggingface.co/apple/OpenELM-1_1B-Instruct">OpenELM-1_1B-Instruct</a></li>
<li><a href="https://huggingface.co/apple/OpenELM-3B-Instruct">OpenELM-3B-Instruct</a></li>
</ul>
<p>OpenELM features a 2048-token maximum context window. The models were trained on the publicly available datasets <a href="https://arxiv.org/abs/2306.01116">RefinedWeb</a>, a version of <a href="https://pile.eleuther.ai/">PILE</a> with duplications removed, a subset of <a href="https://github.com/togethercomputer/RedPajama-Data">RedPajama</a>, and a subset of <a href="https://huggingface.co/datasets/allenai/dolma">Dolma v1.6</a>, which Apple says totals around 1.8 trillion tokens of data. Tokens are fragmented representations of data used by AI language models for processing.</p>
<p>Apple says its approach with OpenELM includes a &#34;layer-wise scaling strategy&#34; that reportedly allocates parameters more efficiently across each layer, saving not only computational resources but also improving the model&#39;s performance while being trained on fewer tokens. According to Apple&#39;s released <a href="https://arxiv.org/pdf/2404.14619">white paper</a>, this strategy has enabled OpenELM to achieve a 2.36 percent improvement in accuracy over Allen AI&#39;s <a href="https://allenai.org/olmo">OLMo 1B</a> (another small language model) while requiring half as many pre-training tokens.</p>
<figure><a href="https://cdn.arstechnica.net/wp-content/uploads/2024/04/open_elm_table.jpg" data-height="312" data-width="1077" alt="An table comparing OpenELM with other small AI language models in a similar class, taken from the OpenELM research paper by Apple."><img alt="An table comparing OpenELM with other small AI language models in a similar class, taken from the OpenELM research paper by Apple." src="https://cdn.arstechnica.net/wp-content/uploads/2024/04/open_elm_table-640x185.jpg" width="640" height="185" srcset="https://cdn.arstechnica.net/wp-content/uploads/2024/04/open_elm_table.jpg 2x"/></a><figcaption><p><a href="https://cdn.arstechnica.net/wp-content/uploads/2024/04/open_elm_table.jpg" data-height="312" data-width="1077">Enlarge</a> <span>/</span> An table comparing OpenELM with other small AI language models in a similar class, taken from the OpenELM research paper by Apple.</p><p>Apple</p></figcaption></figure>
<p>Apple also released the code for <a href="https://github.com/apple/corenet">CoreNet</a>, a library it used to train OpenELM—and it also included reproducible training recipes that allow the weights (neural network files) to be replicated, which is unusual for a major tech company so far. As Apple says in its OpenELM paper abstract, transparency is a key goal for the company: &#34;The reproducibility and transparency of large language models are crucial for advancing open research, ensuring the trustworthiness of results, and enabling investigations into data and model biases, as well as potential risks.&#34;</p>

<p>By releasing the source code, model weights, and training materials, Apple says it aims to &#34;empower and enrich the open research community.&#34; However, it also cautions that since the models were trained on publicly sourced datasets, &#34;there exists the possibility of these models producing outputs that are inaccurate, harmful, biased, or objectionable in response to user prompts.&#34;</p>
<p>While Apple has not yet integrated this new wave of AI language model capabilities into its consumer devices, the upcoming iOS 18 update (expected to be <a href="https://arstechnica.com/gadgets/2024/03/wwdc-2024-starts-on-june-10-with-announcements-about-ios-18-and-beyond/">revealed in June</a> at WWDC) is rumored to include new AI features that <a href="https://arstechnica.com/apple/2024/01/apple-aims-to-run-ai-models-directly-on-iphones-other-devices/">utilize on-device processing</a> to ensure user privacy—though the company may potentially <a href="https://arstechnica.com/information-technology/2024/03/apple-may-hire-google-to-power-new-iphone-ai-features-using-gemini-report/">hire Google</a> or OpenAI to handle more complex, off-device AI processing to give Siri a long-overdue boost.</p>

                                                </div>

            
            
            
        </section></div>
  </body>
</html>
