<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="http://blog.cr.yp.to/20220805-nsa.html">Original</a>
    <h1>NSA, NIST, and post-quantum crypto: my second lawsuit against the US government</h1>
    
    <div id="readability-page-1" class="page">

<hr/>
<div>

<details><summary>Table of contents (Access-I for index page)</summary>
<table>
<tbody><tr><td><b>2022.08.05: NSA, NIST, and post-quantum cryptography:</b> Announcing my second lawsuit against the U.S. government. #nsa #nist #des #dsa #dualec #sigintenablingproject #nistpqc #foia</td></tr>
<tr><td><a href="http://blog.cr.yp.to/20220129-plagiarism.html"><b>2022.01.29: Plagiarism as a patent amplifier:</b></a> <span>Understanding the delayed rollout of post-quantum cryptography. #pqcrypto #patents #ntru #lpr #ding #peikert #newhope</span></td></tr>
<tr><td><a href="http://blog.cr.yp.to/20201206-msword.html"><b>2020.12.06: Optimizing for the wrong metric, part 1: Microsoft Word:</b></a> <span>Review of &#34;An Efficiency Comparison of Document Preparation Systems Used in Academic Research and Development&#34; by Knauff and Nejasmic. #latex #word #efficiency #metrics</span></td></tr>
<tr><td><a href="http://blog.cr.yp.to/20191024-eddsa.html"><b>2019.10.24: Why EdDSA held up better than ECDSA against Minerva:</b></a> <span>Cryptosystem designers successfully predicting, and protecting against, implementation failures. #ecdsa #eddsa #hnp #lwe #bleichenbacher #bkw</span></td></tr>
<tr><td><a href="http://blog.cr.yp.to/20190430-vectorize.html"><b>2019.04.30: An introduction to vectorization:</b></a> <span>Understanding one of the most important changes in the high-speed-software ecosystem. #vectorization #sse #avx #avx512 #antivectors</span></td></tr>
<tr><td><a href="http://blog.cr.yp.to/20171105-infineon.html"><b>2017.11.05: Reconstructing ROCA:</b></a> <span>A case study of how quickly an attack can be developed from a limited disclosure. #infineon #roca #rsa</span></td></tr>
<tr><td><a href="http://blog.cr.yp.to/20171017-collisions.html"><b>2017.10.17: Quantum algorithms to find collisions:</b></a> <span>Analysis of several algorithms for the collision problem, and for the related multi-target preimage problem. #collision #preimage #pqcrypto</span></td></tr>
<tr><td><a href="http://blog.cr.yp.to/20170723-random.html"><b>2017.07.23: Fast-key-erasure random-number generators:</b></a> <span>An effort to clean up several messes simultaneously. #rng #forwardsecrecy #urandom #cascade #hmac #rekeying #proofs</span></td></tr>
<tr><td><a href="http://blog.cr.yp.to/20170719-pqbench.html"><b>2017.07.19: Benchmarking post-quantum cryptography:</b></a> <span>News regarding the SUPERCOP benchmarking system, and more recommendations to NIST. #benchmarking #supercop #nist #pqcrypto</span></td></tr>
<tr><td><a href="http://blog.cr.yp.to/20161030-pqnist.html"><b>2016.10.30: Some challenges in post-quantum standardization:</b></a> <span>My comments to NIST on the first draft of their call for submissions. #standardization #nist #pqcrypto</span></td></tr>
<tr><td><a href="http://blog.cr.yp.to/20160607-dueprocess.html"><b>2016.06.07: The death of due process:</b></a> <span>A few notes on technology-fueled normalization of lynch mobs targeting both the accuser and the accused. #ethics #crime #punishment</span></td></tr>
<tr><td><a href="http://blog.cr.yp.to/20160516-quantum.html"><b>2016.05.16: Security fraud in Europe&#39;s &#34;Quantum Manifesto&#34;:</b></a> <span>How quantum cryptographers are stealing a quarter of a billion Euros from the European Commission. #qkd #quantumcrypto #quantummanifesto</span></td></tr>
<tr><td><a href="http://blog.cr.yp.to/20160315-jefferson.html"><b>2016.03.15: Thomas Jefferson and Apple versus the FBI:</b></a> <span>Can the government censor how-to books? What if some of the readers are criminals? What if the books can be understood by a computer? An introduction to freedom of speech for software publishers. #censorship #firstamendment #instructions #software #encryption</span></td></tr>
<tr><td><a href="http://blog.cr.yp.to/20151120-batchattacks.html"><b>2015.11.20: Break a dozen secret keys, get a million more for free:</b></a> <span>Batch attacks are often much more cost-effective than single-target attacks. #batching #economics #keysizes #aes #ecc #rsa #dh #logjam</span></td></tr>
<tr><td><a href="http://blog.cr.yp.to/20150314-optimizing.html"><b>2015.03.14: The death of optimizing compilers:</b></a> <span>Abstract of my tutorial at ETAPS 2015. #etaps #compilers #cpuevolution #hotspots #optimization #domainspecific #returnofthejedi</span></td></tr>
<tr><td><a href="http://blog.cr.yp.to/20150218-printing.html"><b>2015.02.18: Follow-You Printing:</b></a> <span>How Equitrac&#39;s marketing department misrepresents and interferes with your work. #equitrac #followyouprinting #dilbert #officespaceprinter</span></td></tr>
<tr><td><a href="http://blog.cr.yp.to/20140602-saber.html"><b>2014.06.02: The Saber cluster:</b></a> <span>How we built a cluster capable of computing 3000000000000000000000 multiplications per year for just 50000 EUR. #nvidia #linux #howto</span></td></tr>
<tr><td><a href="http://blog.cr.yp.to/20140517-insns.html"><b>2014.05.17: Some small suggestions for the Intel instruction set:</b></a> <span>Low-cost changes to CPU architecture would make cryptography much safer and much faster. #constanttimecommitment #vmul53 #vcarry #pipelinedocumentation</span></td></tr>
<tr><td><a href="http://blog.cr.yp.to/20140411-nist.html"><b>2014.04.11: NIST&#39;s cryptographic standardization process:</b></a> <span>The first step towards improvement is to admit previous failures. #standardization #nist #des #dsa #dualec #nsa</span></td></tr>
<tr><td><a href="http://blog.cr.yp.to/20140323-ecdsa.html"><b>2014.03.23: How to design an elliptic-curve signature system:</b></a> <span>There are many choices of elliptic-curve signature systems. The standard choice, ECDSA, is reasonable if you don&#39;t care about simplicity, speed, and security. #signatures #ecc #elgamal #schnorr #ecdsa #eddsa #ed25519</span></td></tr>
<tr><td><a href="http://blog.cr.yp.to/20140213-ideal.html"><b>2014.02.13: A subfield-logarithm attack against ideal lattices:</b></a> <span>Computational algebraic number theory tackles lattice-based cryptography.</span></td></tr>
<tr><td><a href="http://blog.cr.yp.to/20140205-entropy.html"><b>2014.02.05: Entropy Attacks!</b></a> <span>The conventional wisdom says that hash outputs can&#39;t be controlled; the conventional wisdom is simply wrong.</span></td></tr>
</tbody></table></details></div><hr/>
<h2>2022.08.05: NSA, NIST, and post-quantum cryptography: <span>Announcing my second lawsuit against the U.S. government. #nsa #nist #des #dsa #dualec #sigintenablingproject #nistpqc #foia</span></h2>
<p>
The Black Chamber was founded
by the U.S. Army and the U.S. State Department in 1919.
The Secretary of State terminated funding in 1929,
famously writing that
<a href="https://www.theatlantic.com/international/archive/2013/06/gentlemen-reading-each-others-mail-a-brief-history-of-diplomatic-spying/276940/">&#34;Gentlemen do not read each other&#39;s mail.&#34;</a>
</p>
<p>
The Black Chamber was succeeded by the Signal Intelligence Service in 1930,
the Armed Forces Security Agency in 1949,
and the National Security Agency (NSA) in 1952.
NSA&#39;s Project Minaret began
<a href="https://nsarchive2.gwu.edu/NSAEBB/NSAEBB441/">spying on anti-war protesters</a>
in 1967.
NSA&#39;s targets under this project
included Martin Luther King,
<i>New York Times</i> journalist Tom Wicker,
U.S. senator Frank Church, and many more.
</p>
<p>
<b>NSA&#39;s policy decision to sabotage public cryptographic standards.</b>
In 1968,
the National Bureau of Standards (NBS)
&#34;went to NSA for help&#34;,
in the words of an
<a href="https://archive.org/details/cold_war_iii-nsa/cold_war_iii-ISCAP/page/n239/mode/2up">internal NSA history book</a>.
Work by journalists over several years forced
NSA to release the relevant portions of the book in 2013,
and before that smaller portions in 2008 and 2009.
</p>
<p>
NBS was an agency inside the U.S. Department of Commerce,
another part of the U.S. government.
Later NBS was renamed the National Institute of Standards and Technology (NIST).
The reason NBS went to NSA
is that NBS had decided to develop a U.S. government encryption standard.
</p>
<p>
According to the same history book,
this triggered an internal debate within NSA,
culminating in NSA deciding to manipulate public standards
to make sure they were &#34;weak enough&#34; for NSA to break them:
</p>
<blockquote>
Narrowing the encryption problem to a single, influential algorithm might drive out competitors, and that would reduce the field that NSA had to be concerned about. Could a public encryption standard be made secure enough to protect against everything but a massive brute force attack, but weak enough to still permit an attack of some nature using very sophisticated (and expensive) techniques?
</blockquote>
<p>
NSA then worked with NBS and IBM&#39;s Walter Tuchman on the design
of what later became the Data Encryption Standard (DES):
</p>
<blockquote>
NSA gave Tuchman a clearance and brought him in
to work jointly with the Agency on his Lucifer modification ...
The relationship between NSA and NBS was very close.
NSA scientists working the problem crossed back and forth
between the two agencies,
and NSA unquestionably exercised an influential role in the algorithm.
</blockquote>
<p>
Back in the 1970s,
Tuchman and NSA told a completely different story to the public.
For example,
regarding accusations that
IBM and NSA had &#34;conspired&#34;,
Tuchman told an interviewer
&#34;We developed the DES algorithm
entirely within IBM using IBMers.
The NSA did not dictate a single wire!&#34;
</p>
<p>
As another example, here&#39;s a 
<a href="https://cryptome.org/nsa-inman-1979.pdf">1979 statement</a>
from NSA director Bobby Inman:
</p>
<blockquote>
NSA has been accused of intervening
in the development of the DES
and of tampering with the standard
so as to weaken it cryptographically.
This allegation is totally false.
</blockquote>
<p>
See Section 3.6 of my paper
<a href="https://cr.yp.to/papers.html#competitions">Cryptographic competitions</a>
for further quotes and references.
</p>
<p>
<b>The breakability of DES.</b>
The cryptographic core of NSA&#39;s sabotage of DES was remarkably blunt:
NSA simply convinced Tuchman to limit the key size to 56 bits,
a glaring weakness.
</p>
<p>
Whit Diffie and Marty Hellman wrote a paper
<a href="https://ee.stanford.edu/~hellman/publications/27.pdf">explaining in considerable detail</a>
how to build a machine for $20 million that would break each DES key
with an amortized cost of just $5000/key using mid-1970s technology.
They predicted that the cost of such a brute-force attack
would drop &#34;in about 10 years time&#34; to about $50/key,
simply from chip technology improving.
</p>
<p>
Diffie and Hellman already distributed drafts of their paper
before DES was standardized.
Did NSA say, oh, oops, you caught us, this isn&#39;t secure?
</p>
<p>
Of course not.
NSA claimed that, according to their own estimates,
the attack was 30000 times more expensive:
<a href="https://web.archive.org/web/20220228142103/http://www.toad.com/des-stanford-meeting.html">&#34;instead of one day he gets something like 91 years&#34;</a>.
</p>
<p>
Meanwhile NSA claimed that
&#34;for the next n years, up to 10, we stand by the statement that this is more than adequate&#34;,
as if DES were going to be replaced soon.
In fact, DES remained an official U.S. government standard until 2005.
</p>
<p>
(Remember that, internally, NSA had observed that
&#34;narrowing the encryption problem to a single, influential algorithm might drive out
competitors, and that would reduce the field that NSA had to be concerned about&#34;.
Externally, NSA was playing dumb.)
</p>
<p>
Diffie and Hellman proposed a low-cost modification to DES
to use longer keys.
Questionable performance arguments were raised in response.
</p>
<p>
For example,
various government contractors claimed
<a href="https://nvlpubs.nist.gov/nistpubs/Legacy/IR/nbsir76-1189.pdf">at a 1976 NBS workshop</a>
that DES was &#34;close to the maximum that could be implemented
on a chip with present technology&#34;
and that a manufacturing delay &#34;of one to two years
might be encountered if a longer key were required&#34;.
Even if this was true,
how could it possibly justify
establishing a breakable standard for the next 10 years,
never mind the next three decades?
</p>
<p>
In 1980,
Hellman published
<a href="https://ee.stanford.edu/~hellman/publications/36.pdf">&#34;A cryptanalytic time-memory tradeoff&#34;</a>.
This was an algorithmic improvement showing that,
compared to a brute-force machine,
a more sophisticated machine could be constructed
with an even smaller cost of breaking each key.
</p>
<p>
In 1993,
Mike Wiener wrote a paper &#34;Efficient DES key search&#34;
giving an even more detailed description
of a brute-force DES attack machine,
not including Hellman&#39;s time-memory tradeoff.
In a
<a href="https://web.archive.org/web/20190407175554/https://www.networkdls.com/Articles/crypto3n2.pdf">1997 update</a>,
Wiener estimated that it would cost about $1 million
to build a machine that would break each key in 35 minutes.
</p>
<p>
Wiener&#39;s estimate corresponded to
an amortized cost of $13/key, assuming a 5-year hardware lifetime,
or perhaps twice as much if one includes the costs of electricity.
Extrapolating from the 1970s brute-force estimates by Diffie and Hellman,
one might instead guess $1/key.
Extrapolating from the 1970s brute-force estimates by NSA,
one might instead guess $30000/key,
an indefensible and dangerous overestimate.
</p>
<p>
DES was so cheap to break in 1997
that one could throw away orders of magnitude of efficiency,
using off-the-shelf computers
instead of optimized attack circuits,
and still break DES.
This was demonstrated by
<a href="https://en.wikipedia.org/wiki/DESCHALL_Project">DESCHALL</a>
in 1997.
</p>
<p>
In response to DESCHALL,
Federal Bureau of Investigation Director Louis Freeh
testified as follows in a
<a href="https://cryptome.org/jya/hir-hear.htm">1997 hearing</a>:
</p>
<blockquote>
If we hooked together thousands of computers and worked together over 4 months
we might, as was recently demonstrated decrypt one message bit.
That is not going to make a difference in a kidnapping case,
it is not going to make a difference in a national security case.
We don&#39;t have the technology or the brute force capability to get to this information.
</blockquote>
<p>
NSA Deputy Director William Crowell testified at the same hearing
that &#34;There is no brute force solution for law enforcement,&#34;
again highlighting that
&#34;It took 78,000 computers 96 days to break one message,
and the headline was, DES has weak encryption.&#34;
</p>
<p>
Did NSA admit that optimized hardware was much more efficient?
Of course not.
It was taking the inefficiency of off-the-shelf computers
and misrepresenting this as security of DES.
</p>
<p>
In 1998,
the Electronic Frontier Foundation assembled a $250000 machine,
the <a href="https://web.archive.org/web/20170507231657/https://w2.eff.org/Privacy/Crypto/Crypto_misc/DESCracker/HTML/19980716_eff_des_faq.html">DES Cracker</a>,
to publicly break DES in a few days.
This was, obviously,
much cheaper and faster than 96 days on 78000 computers.
</p>
<p>
Did NSA admit that its public estimates
of the cost of breaking DES
(1) were wild overestimates even for a brute-force attack machine
and
(2) were ignoring algorithmic improvements such as Hellman&#39;s time-memory tradeoff?
Of course not.
</p>
<p>
<b>The Digital Signature Algorithm.</b>
NIST was busy in the meantime
issuing more cryptographic standards.
One of these was an influential standard
for a Digital Signature Algorithm (DSA).
</p>
<p>
NSA had proposed DSA in 1991.
The DSA proposal had an obvious, glaring flaw:
a 512-bit key size.
</p>
<p>
This sounds much larger than the 56-bit DES key size.
But DSA is a different type of cryptographic system,
using a type of mathematical structure
that was already publicly known in 1991 to require much larger key sizes for security.
</p>
<p>
With attack algorithms publicly known in 1991,
512 bits for DSA seemed somewhat stronger than 56 bits for DES.
But chips were faster in 1991 than they were in the 1970s.
The DSA attack algorithms known in 1991
were also much more complicated than the DES attack algorithms.
Many aspects of the DSA attacks
hadn&#39;t been thoroughly studied.
The attacks were publicly superseded by
even faster, even more complicated attacks.
</p>
<p>
Beyond this glaring flaw,
DSA had further flaws that weren&#39;t as obvious.
For example,
DSA had interesting possibilities for back doors.
It also had pitfalls that would trap implementors.
Ron Rivest wrote in 1992 that
&#34;the poor user is given enough rope with which to hang himself&#34;.
</p>
<p>
At the beginning,
NIST presented DSA as a NIST proposal, making no mention of NSA.
A FOIA lawsuit by Computer Professionals for Social Responsibility (CPSR)
revealed, however, that
<a href="https://web.archive.org/web/20200229145033/https://catless.ncl.ac.uk/Risks/14/59">DSA
had been secretly designed by NSA</a>.
</p>
<p>
(FOIA is the Freedom of Information Act,
a law generally requiring the U.S. government
to promptly provide records to the public upon request.
Sometimes agencies disobey the law,
and one has to go to court to have the law enforced.
That&#39;s what CPSR did.)
</p>
<p>
Public backlash forced NIST to allow larger keys
in the DSA standard in 1994.
But the keys were still limited to 1024 bits;
1024 bits for DSA are much less secure than, e.g.,
128 bits for AES.
The DSA standard
also did nothing to address DSA&#39;s further flaws.
</p>
<p>
The specific &#34;hang himself&#34; problem
that Rivest had highlighted
was publicly exploited in a 2010 break
of the Sony PlayStation security system,
which used ECDSA, a variant of DSA.
Presumably the same problem was secretly exploited by large-scale attackers
against higher-value targets.
</p>
<p>
<b>The scale of attacks.</b>
What do I mean by &#34;large-scale attackers?&#34;
Let&#39;s take the Chinese government as an example.
Here&#39;s a 2012 quote from an
<a href="https://republicans-intelligence.house.gov/sites/intelligence.house.gov/files/documents/huawei-zte%20investigative%20report%20(final).pdf">&#34;Investigative report on the U.S. national security issues posed by Chinese telecommunications companies Huawei and ZTE&#34;</a>:
</p>
<blockquote>
Chinese intelligence collection efforts against the U.S. government are growing in
&#34;scale, intensity and sophistication.&#34;
Chinese actors are also the world&#39;s most active
and persistent perpetrators of economic espionage.
U.S. private sector firms and cyber-security specialists
report an ongoing onslaught of sophisticated computer network
intrusions that originate in China, and are almost certainly the work of,
or have the backing of, the Chinese government.
Further, Chinese intelligence services,
as well as private companies and other entities,
often recruit those with direct access to corporate networks
to steal trade secrets and other sensitive proprietary data.
</blockquote>
<p>
The large-scale attacker whose behavior seems
<a href="https://pure.tue.nl/ws/portalfiles/portal/197416841/20220325_Appelbaum_hf.pdf">most comprehensively documented</a>
is the U.S. government.
The European Parliament already issued a 194-page
<a href="https://web.archive.org/web/20130930211153/http://www.europarl.europa.eu/sides/getDoc.do?pubRef=-//EP//NONSGML+REPORT+A5-2001-0264+0+DOC+PDF+V0//EN">&#34;Report on the existence of a global system for the interception of private and commercial communications (ECHELON interception system)&#34;</a>
in 2001:
</p>
<blockquote>
The existence of a global system for intercepting communications, operating by
means of cooperation proportionate to their capabilities among the USA, the UK, Canada,
Australia and New Zealand under the UKUSA Agreement, is no longer in doubt ...
The US authorities have repeatedly tried to justify the interception of
telecommunications by accusing the European authorities of corruption and taking bribes.
It should be pointed out to the Americans
that all EU Member States have properly functioning criminal justice systems.
If there is evidence that crimes have been committed,
the USA must leave the task of law enforcement to the host countries.
If there is no such evidence, surveillance must be regarded as unproportional,
a violation of human rights and thus inadmissible.
</blockquote>
<p>
Some Americans trust their government
and happily swallow whatever the government&#39;s latest excuse is
for spying on billions of people around the world.
<a href="https://www.reuters.com/world/cia-carried-out-drone-strike-afghanistan-us-officials-say-2022-08-01/">&#34;U.S. kills al Qaeda leader Zawahiri in Kabul drone missile strike&#34;</a>,
of course with the help of the espionage system?
Sounds great!
Last year the same system
<a href="https://www.nytimes.com/2021/09/10/world/asia/us-air-strike-drone-kabul-afghanistan-isis.html">murdered 10 innocent civilians without a trial</a>?
Isolated mistake!
Also, doesn&#39;t the Constitution say that
the only people entitled to a trial are
rich white male normal-looking Americans?
</p>
<p>
The same people tend to have trouble grasping
that most of the vulnerabilities exploited and encouraged by NSA
are also exploitable by the Chinese government.
These people start with the assumption that
Americans are the best at everything;
ergo, we&#39;re also the best at espionage.
If the Chinese government
<a href="https://en.wikipedia.org/wiki/Office_of_Personnel_Management_data_breach">stole millions of personnel records</a>
from the U.S. government,
records easily usable as a springboard for further attacks,
this can&#39;t <i>possibly</i> be
because the U.S. government made a policy decision to keep our computer systems
&#34;weak enough to still permit an attack of some nature
using very sophisticated (and expensive) techniques&#34;.
</p>
<p>
<b>New directions in cryptographic sabotage.</b>
Cryptographic weaknesses aren&#39;t <i>always</i> exploitable by everybody.
Sometimes it&#39;s possible to design a cryptographic system
with a back door that can be opened only by someone who has a secret key.
A spectacular example is the
<a href="https://projectbullrun.org/dual-ec/documents/dual-ec-20150731.pdf">Dual Elliptic Curve Deterministic Random Bit Generator (Dual EC)</a>.
</p>
<p>
The Dual EC standard includes two random-looking constants P and Q,
points on an &#34;elliptic curve&#34;.
Dual EC uses P, Q, and some initial randomness provided by the user
to generate a long sequence of random-looking numbers.
Cryptography often needs many random numbers.
</p>
<p>
The secret key to the Dual EC back door
is the &#34;discrete logarithm&#34; of Q base P.
It&#39;s easy to generate this secret key while generating P and Q.
An attacker who knows this secret key
can exploit secret patterns in the Dual EC output,
even without being told the initial randomness from the user.
This is a severe weakness in Dual EC,
but it&#39;s exploitable only if you know the secret key.
</p>
<p>
A
<a href="https://www.nytimes.com/2013/09/06/us/nsa-foils-much-internet-encryption.html">2013
New York Times report</a>
said that internal NSA documents provided by Ed Snowden
&#34;appear to confirm that the fatal weakness ... was engineered by the agency&#34;.
The same report gave an idea of the magnitude of NSA&#39;s sabotage efforts:
</p>
<blockquote>
According to an intelligence budget document leaked by Mr. Snowden,
the N.S.A. spends more than $250 million a year on its Sigint Enabling Project,
which &#34;actively engages the U.S. and foreign IT industries
to covertly influence and/or overtly leverage their commercial products’ designs&#34;
to make them &#34;exploitable.&#34;
...
One goal in the agency’s 2013 budget request was to “influence policies, standards and
specifications for commercial public key technologies,” the most common encryption method.
</blockquote>
<p>
Did NSA admit that, okay, you caught us,
we designed Dual EC to be exploitable?
Of course not.
NSA&#39;s Dickie George gave a
<a href="https://vimeo.com/97891042">talk in 2014</a>
making the following claims (minutes 32-33 and 57-61):
</p>
<ul>
<li>
  NSA couldn&#39;t use cryptography that wasn&#39;t standardized by NIST.
  (In fact,
  NSA has its own classified suite of algorithms, Suite A.)
</li>
<li>
  &#34;So I had to go down to my friends at NIST,
  and I know &#39;em well, cause I work with them on other things ...&#34;
  (This part is true: NSA does work with NIST.)
</li>
<li>
  &#34;We&#39;re gonna use the Dual Elliptic Curve randomizer.
  And I said,
  if you can put this in your standard,
  nobody else is gonna use it,
  because it looks ugly, it&#39;s really slow,
  it makes no sense for anybody to go there,
  but I&#39;ll be able to use it.
  And so they stuck it in.&#34;
  (In fact,
  NSA paid the RSA company
  <a href="https://www.reuters.com/article/us-usa-security-rsa-idUSBRE9BJ1C220131220">$10 million</a>
  to make Dual EC
  &#34;the preferred, or default, method for number generation in the BSafe software&#34;.)
</li>
<li>
  &#34;And I said,
  by the way,
  these parameters that we have here,
  as long as they&#39;re in there so we can use them,
  you can let anybody else put any parameters in that they want.&#34;
  (In fact,
  the Dual EC standard specifically discouraged
  implementors from switching away from NSA&#39;s P and Q.
  NIST also set up validation procedures
  specifically requiring NSA&#39;s P and Q.)
</li>
<li>
  &#34;Sticking a bunch of digits of pi in the middle
  or something like that,
  so you can show it&#39;s not some kind of hoked-up thing,
  we just don&#39;t do that.&#34;
  (In fact,
  NSA did something like that
  to generate the NIST P-256 elliptic curve a few years earlier,
  first publishing supposedly random numbers
  but then feeding the random numbers
  through a hash function to generate the curve parameters,
  so the public could check the hash.
  If NSA had similarly used a hash function
  for both P and Q in Dual EC
  then it would have been throwing away the key for the Dual EC back door.)
</li>
<li>
  &#34;We don&#39;t care what the parameters are for anybody else
  as long as the government ones are there for government use.&#34;
  (In fact,
  FOIA requests to NIST
  showed Don Johnson telling NIST that P and Q
  &#34;could also be generated like a(nother) canonical G, but NSA kyboshed
  this idea, and I was not allowed to publicly discuss it, just in case you
  may think of going there.&#34;)
</li>
</ul>
<p>
George also challenged researchers
&#34;to actually generate their own parameters
and show me that in real life they can recover that.&#34;
He offered dinner.
Did he pay up after a paper
<a href="https://www.usenix.org/system/files/conference/usenixsecurity14/sec14-paper-checkoway.pdf">&#34;On the practical exploitability of Dual EC in TLS implementations&#34;</a>
appeared at the USENIX Security Symposium?
Of course not.
</p>
<p>
Typical cryptographic weaknesses are algorithms that,
if discovered by the public, can be demonstrated to work.
The weakness in Dual EC is different.
<a href="https://rump2007.cr.yp.to/15-shumow.pdf">Shumow and Ferguson</a>
announced in 2007
that there mathematically <i>exists</i>
a back door with a secret key,
and that anyone generating P and Q
can easily generate a secret key at the same time;
but this still doesn&#39;t demonstrate that NSA <i>did</i> generate a secret key
along with P and Q.
We have no way to prove that NSA&#39;s P and Q are weak.
</p>
<p>
For the same reason,
if someone changes P and/or Q,
a code reviewer can&#39;t tell whether this is being done safely
or is stealthily opening up a back door.
In
<a href="https://www.cs.utexas.edu/~hovav/dist/juniper.pdf">the Juniper Dual EC incident</a>,
Juniper chose its own Q for its NetScreen VPN routers,
but then an attacker managed to modify the code to substitute a new choice of Q.
So much for the idea that this weakness could be exploited only by NSA.
</p>
<p>
<b>Technical interlude: bamboozling people with fake mathematics.</b>
Internally,
Dual EC generates more elliptic-curve points.
Each point has an x-coordinate and a y-coordinate.
The numbers that Dual EC releases as output
are truncated versions of the x-coordinate of each point.
The truncation removes 16 bits.
</p>
<p>
An attacker exploiting the back door
has to try 2<sup>16</sup> possibilities for the missing bits.
This has low cost,
since 16 is so small.
If, however, 16 were replaced by a much larger number, such as 128,
then the back door would become so expensive as to be worthless.
</p>
<p>
Why did NSA include truncation in the first place?
Answer: Releasing the full x-coordinates, with no truncation,
would have shown glaring statistical biases,
and this would have been too embarrassing for NIST to standardize.
</p>
<p>
Attack papers in 2006 by
<a href="https://web.archive.org/web/20110525081912/http://www.math.ntnu.no/~kristiag/drafts/dual-ec-drbg-comments.pdf">Kristian Gjøsteen</a>
and then
<a href="https://eprint.iacr.org/2006/190">Berry Schoenmakers and Andrey Sidorenko</a>
showed that Dual EC was still detectably biased:
it wasn&#39;t removing enough bits
to meet the standard definition of security for random-number generators.
</p>
<p>
Did NSA admit that, oops, Dual EC was broken?
Of course not.
Let&#39;s look at what NSA wrote instead,
specifically pages 88–91 of
NIST&#39;s Dual EC standard (2012 version),
<a href="https://nvlpubs.nist.gov/nistpubs/Legacy/SP/nistspecialpublication800-90a.pdf">SP 800-90A</a>.
</p>
<p>
NSA didn&#39;t even acknowledge
the standard security goal of
being indistinguishable from truly random numbers.
NSA spent two pages on calculations
related to a weaker security goal,
having nearly full &#34;entropy&#34;.
NSA concluded
that the entropy loss with 16 bits of truncation
&#34;has been demonstrated to be minimal (see the above chart)&#34;.
</p>
<p>
This still wouldn&#39;t stop people from removing more bits
(and thus making the back door harder to exploit).
So NSA also played the performance card:
&#34;One might wonder if it would be desirable to truncate more than this amount.
The obvious drawback to such an approach
is that increasing the truncation amount hinders the performance.&#34;
</p>
<p>
But, hmmm,
random-number generation usually isn&#39;t
the most important bottleneck in cryptography.
That&#39;s why something as slow as Dual EC
could be deployed in the first place.
So NSA pulled out another argument:
</p>
<blockquote>
However, there is an additional reason that argues against increasing the
truncation. Consider the case where the low s bits of each x-coordinate are kept.
Given some subinterval I of length 2<sup>s</sup> contained in [0, p),
and letting N(I) denote the number of x-coordinates in I,
recent results on the distribution of x-coordinates in [0, p)
provide the following bound:
|N(I)/(p/2)-2<sup>s</sup>/p| &lt; (k*log<sup>2</sup> p)/sqrt(p)
where k is some constant derived from the asymptotic estimates given in [Shparlinski].
For the case of P-521, this is roughly equivalent to:
|N(I)-2<sup>(</sup>s-1)| &lt; k*2<sup>277</sup>,
where the constant k is independent of the value of s.
For s &lt; 2<sup>277</sup>,
this inequality is weak
and provides very little support for the notion
that these truncated x-coordinates are uniformly distributed.
On the other hand, the larger the value of s,
the sharper this inequality becomes,
providing stronger evidence that the associated truncated x-coordinates
are uniformly distributed.
Therefore, by keeping truncation to an acceptable minimum,
the performance is increased,
and certain guarantees can be made
about the uniform distribution of the resulting truncated quantities.
Further discussion of the uniformity of the truncated x-coordinates
is found in [Gurel],
where the form of the prime defining the field is also taken into account.
</blockquote>
<p>
Any mathematician who checks this sees how ludicrously inaccurate it is.
The central error is already visible in the third sentence,
which counts the number of integers in an interval of length 2<sup>s</sup>.
That&#39;s the number of integers that produce a given output
when one <i>throws away</i> the bottom s bits,
not when one <i>keeps</i> the bottom s bits.
Correcting this error and following through the rest of the argument
leads to the conclusion that,
for guarantees regarding the distribution,
one should truncate <i>more than half</i> of the bits.
</p>
<p>
But NIST never checked.
NIST&#39;s friends at NSA
were providing text and references arguing against increasing the truncation;
so NIST accepted this, redistributed it, and didn&#39;t increase the truncation.
</p>
<p>
<b>Dual EC fallout.</b>
After Shumow and Ferguson
announced the vulnerability in Dual EC,
Bruce Schneier wrote an
article
<a href="https://www.wired.com/2007/11/securitymatters-1115/">&#34;Did NSA put a secret backdoor in new encryption standard?&#34;</a>
ending as follows:
</p>
<blockquote>
My recommendation, if you&#39;re in need of a random-number generator, is not to use Dual_EC_DRBG under any circumstances.
If you have to use something in SP 800-90, use CTR_DRBG or Hash_DRBG.
</blockquote>
<p>
But most cryptographers didn&#39;t take the threat seriously.
Consider, for example,
Shumow&#39;s
<a href="https://wstein.org/wiki/uwcrypto(2f)sched.html">2008 talk</a>
with the title &#34;Shumow and Schneier escape from Guantanamo Bay&#34;.
Shumow mocked &#34;conspiracy theories&#34;,
accused Schneier of omitting facts
&#34;in a way to make the NSA (as well as Microsoft) look far worse than they otherwise would&#34;,
and argued that Dual EC exploits were &#34;possible but improbable&#34;:
</p>
<blockquote>
I found this, and I am neither a talented mathematician nor a talented cryptographer.
I was just the first person to commercially implement the algorithm.
</blockquote>
<p>
In 2013,
the Snowden documents finally forced NIST to do some soul-searching.
NIST&#39;s
<a href="https://web.archive.org/web/20220219211917/https://www.nist.gov/system/files/documents/2017/05/09/VCAT-Report-on-NIST-Cryptographic-Standards-and-Guidelines-Process.pdf">Dual EC post-mortem</a>
drew the following conclusion:
</p>
<blockquote>
It is of paramount importance that NIST&#39;s process for developing cryptographic standards is open and transparent and has the trust and support of the cryptographic community.
</blockquote>
<p>
The same post-mortem shows NIST&#39;s invited reviewers
recommending clear transparency rules,
such as &#34;full documentation of all decisions, and clear processes for the disposition of each and every comment received&#34;,
along with being open about &#34;what authorities were consulted&#34;.
</p>
<p>
Note that it&#39;s not always obvious who&#39;s providing input.
For example,
NIST received the draft Dual EC proposal from another standardization organization, ANSI.
Dual EC was proposed to ANSI not by NSA,
but by Johnson, who was working for Cygnacom, a defense contractor.
But NIST did end up working directly with NSA on the Dual EC standard.
Prompt reporting of NIST&#39;s communications and evaluations
would have given the public many more opportunities
to promptly catch what was happening with Dual EC.
</p>
<p>
<b>Post-quantum cryptography.</b>
A 2014 Washington Post article
<a href="https://www.washingtonpost.com/world/national-security/nsa-seeks-to-build-quantum-computer-that-could-crack-most-types-of-encryption/2014/01/02/8fff297e-7195-11e3-8def-a33011492df2_story.html">&#34;NSA seeks to build quantum computer that could crack most types of encryption&#34;</a>
said that NSA had an $80 million/year research program
called &#34;Penetrating hard targets&#34;,
including research aimed at building a
&#34;cryptologically useful quantum computer&#34;.
</p>
<p>
This is only part of the U.S. government budget
for breaking pre-quantum cryptography.
My 2012 talk
<a href="https://cr.yp.to/talks/2012.09.24/slides.pdf">&#34;Cryptography for the paranoid&#34;</a>
pointed to a $2.2 million grant for defense contractor Raytheon as
&#34;one of many publicly announced quantum-computing grants from government agencies&#34;.
</p>
<p>
Put yourself in NSA&#39;s shoes for a moment.
You have a budget to build a quantum computer to break pre-quantum cryptography.
You are, of course, aware of public efforts to design and deploy post-quantum cryptography.
You also have a quarter-billion-dollar-a-year budget
to &#34;covertly influence and/or overtly leverage&#34; deployed cryptography
to make it &#34;exploitable&#34;.
What do you do?
</p>
<p>
Some people seem to be unable to rationally consider the <i>possibility</i>
that NSA is sabotaging post-quantum cryptography.
I&#39;ve heard people saying, for example,
that submissions to
the NIST Post-Quantum Cryptography Standardization Project (NISTPQC)
were publicly designed and evaluated by top experts,
and that NSA can&#39;t have bribed the submission teams.
</p>
<p>
Let&#39;s look at the facts.
</p>
<p>
Almost all of the submissions to NISTPQC
have less security against the best attacks publicly known today
than they had against the best attacks publicly known when they were submitted in 2017.
I&#39;m not talking about chips getting faster:
I&#39;m talking about new attack algorithms.
</p>
<p>
For many of the submissions,
the attack improvements have been so dramatic
that the submissions have been publicly demonstrated
to be rapidly breakable on a laptop.
Last month a <a href="https://eprint.iacr.org/2022/975">new attack</a> broke SIKE,
one of just eight submissions that was still under consideration by NIST,
one of just two submissions
that had been selected for a high-profile Cloudflare–Google TLS experiment in 2019.
</p>
<p>
As for &#34;top experts&#34;,
here&#39;s a quote from a document
<a href="https://ntruprime.cr.yp.to/latticerisks-20211031.pdf">&#34;Risks of lattice KEMs&#34;</a>
by the NTRU Prime Risk-Management Team:
</p>
<blockquote>
Consider the fact that the Institute for Defense Analyses,
an NSA consulting company,
many years ago hired Buhler,
one of the original developers of the number-field sieve [94] for integer factorization;
Gordon,
the first developer of a discrete-logarithm version [166] of the number-field sieve;
Miller,
who as part of introducing ECC [261]
was one of the first authors to probe the limits of discrete-logarithm algorithms;
and Coppersmith.
Much less data is available regarding the cryptanalytic capabilities
of, e.g., the Chinese government.
Surely large-scale attackers know many more attacks than this public does.
</blockquote>
<p>
I coined the phrase &#34;post-quantum cryptography&#34; in 2003.
It&#39;s not hard to imagine
that the NSA/IDA post-quantum attack team was already hard at work before that,
that they&#39;re years ahead of the public in finding attacks,
and that NSA has been pushing NISTPQC to select algorithms
that NSA secretly knows how to break.
</p>
<p>
Could such a weakness also be exploited
by other large-scale attackers?
Best bet is that the answer is yes.
Would this possibility stop NSA from pushing for the weakness?
Of course not.
</p>
<p>
<b>Hybrids.</b>
When Google rolled out its first post-quantum experiment in 2016,
it didn&#39;t switch from encrypting with
a well-established pre-quantum system
to encrypting with a post-quantum system.
Instead it encrypted with a well-established pre-quantum system
<i>and</i> encrypted with a post-quantum system,
so that at least it wouldn&#39;t be losing security
if the post-quantum system turned out to be breakable.
</p>
<p>
The 2019 Cloudflare–Google experiment worked the same way.
The general view today is that <i>of course</i>
post-quantum cryptography should be an extra layer
on top of well-established pre-quantum cryptography.
As the French government cybersecurity agency
(Agence nationale de la sécurité des systèmes d&#39;information, ANSSI) put it
at the
<a href="https://www.ssi.gouv.fr/en/publication/anssi-views-on-the-post-quantum-cryptography-transition/">end of 2021</a>:
</p>
<blockquote>
Acknowledging the immaturity of PQC is important: ANSSI will not endorse any direct
drop-in replacement of currently used algorithms in the short/medium term. However,
this immaturity should not serve as an argument for postponing the first deployments.
ANSSI encourages all industries to progress towards an initiation of a gradual
overlap transition in order to progressively increase trust on the post-quantum
algorithms and their implementations while ensuring no security regression as far as
classical (pre-quantum) security is concerned. 
...
</blockquote>
<p>
But NSA has a different position: it says that it
<a href="https://web.archive.org/web/20220524232249/https://twitter.com/mjos_crypto/status/1433443198534361101/photo/1">&#34;does not expect to approve&#34;</a>
hybrids.
Publicly,
NSA justifies this by
</p>
<ul>
<li>pointing to a fringe case where a careless effort to add an extra security layer damaged security,
and</li>
<li>expressing &#34;confidence in the NIST PQC process&#34;.</li>
</ul>
<p>
Does that mean the original NISTPQC process,
or the current NISTPQC process in which NIST, evidently surprised by attacks,
announced plans to call for new submissions?
</p>
<p>
Of course, if NSA/IDA have secretly developed
an attack that works for a particular type of post-quantum cryptosystem,
then it makes sense that they&#39;d want people to start using that type of cryptosystem
<i>and</i> turn off the existing pre-quantum cryptosystem.
</p>
<p>
<b>Transparency for NISTPQC.</b>
NIST issued final
<a href="https://web.archive.org/web/20220119113311/https://csrc.nist.gov/CSRC/media/Projects/Post-Quantum-Cryptography/documents/call-for-proposals-final-dec-2016.pdf">&#34;Submission requirements and evaluation criteria for the post-quantum cryptography standardization process&#34;</a>
in December 2016,
including a promise that NIST would
&#34;perform a thorough analysis of the submitted algorithms in a manner that is open and transparent to the public&#34;.
</p>
<p>
It became clear to me in 2020
that, despite this promise,
most of NIST&#39;s evaluation process was happening behind closed doors.
I tweeted the following at 13:01 GMT on 22 July 2020:
</p>
<blockquote>
   After NIST&#39;s Dual EC standard was revealed in 2013 to be an actual
   (rather than just potential) NSA back door, NIST promised more
   transparency. Why does NIST keep soliciting private #NISTPQC input?
   (The submissions I&#39;m involved in seem well positioned; that&#39;s not the point.)
</blockquote>
<p>
Coincidentally,
at 13:02 GMT on 22 July 2020,
NSA suddenly made its first public appearance in NISTPQC.
Slides from NIST in September 2020 admitted that before this there was already
<a href="https://web.archive.org/web/20210508052729/https://csrc.nist.gov/CSRC/media/Presentations/pqc-update-round-2-and-beyond/images-media/pqcrypto-sept2020-moody.pdf">&#34;feedback&#34;</a>
from NSA to NIST (slide 20).
The public still hasn&#39;t seen the contents of NIST&#39;s communications
with NSA, defense contractors, etc.,
let alone the records of how NIST processed the input it received.
</p>
<p>
The same September 2020 NIST slides tried to downplay NSA&#39;s influence:
&#34;NIST alone makes the PQC standardization decisions,
based on publicly available information, and stands by those decisions.&#34;
One is reminded of Tuchman saying
&#34;We developed the DES algorithm
entirely within IBM using IBMers.
The NSA did not dictate a single wire!&#34;
</p>
<p>
In 2021,
NIST <a href="https://web.archive.org/web/20211115191840/https://www.nist.gov/blogs/taking-measure/post-quantum-encryption-qa-nists-matt-scholl">claimed</a>
that &#34;We operate transparently. We&#39;ve shown all our work&#34;.
In fact,
most of the information on NIST&#39;s web site for this project
is simply copies of submissions.
NIST has posted some extra information,
but the total volume of information in NIST&#39;s reports, web pages, and mailing-list messages
obviously falls far short of &#34;all our work&#34;.
Anyone trying to obtain more than a superficial understanding
of what has happened in NISTPQC rapidly discovers that critical information is missing.
See my paper
<a href="https://cr.yp.to/papers.html#categories">&#34;A discretization attack&#34;</a>,
specifically Section 5,
for various concrete examples of mysteries regarding the NIST process.
</p>
<p>
I&#39;ve filed seven FOIA requests since NIST
since mid-2020.
NIST has released a few dribbles of information,
but in general NIST&#39;s responses have been very slow and obviously not complete.
</p>
<p>
For example,
I filed a FOIA request in June 2021
asking for &#34;copies of all NIST records of communication between NSA and NIST regarding the NIST Post-Quantum Cryptography Standardization Project&#34;.
This request has, so far, produced zero records.
NIST has stonewalled, ignoring the FOIA deadlines.
</p>
<p>
My seventh FOIA request, in March 2022,
said the following:
</p>
<blockquote>
Analyzing NSA&#39;s impact on this project will require not just seeing NSA&#39;s communication with NIST, but also tracing how NIST&#39;s decisions were made and analyzing the influence of the information that NIST received from NSA. If each step of this analysis requires dealing with another round of stonewalling from NIST then the analysis will obviously not be done in time to help the public make safe decisions regarding post-quantum cryptography.
</blockquote>
<p>
I asked for the full NISTPQC records,
and for
&#34;all records of NIST/NSA meetings mentioning the word &#39;quantum&#39;,
whether or not NIST views those meetings as part of this project&#34;.
</p>
<p>
NIST has produced zero records in response to this FOIA request.
Civil-rights firm
<a href="https://loevy.com">Loevy &amp; Loevy</a>
has now filed suit on my behalf in federal court,
the United States District Court for the District of Columbia,
to force NIST to comply with the law.
</p>
<hr/><SPAN size="1"><b>Version:</b>
This is version 2022.08.05 of the 20220805-nsa.html web page.
</SPAN>

</div>
  </body>
</html>
