<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://futurism.com/openai-researchers-coding-fail">Original</a>
    <h1>OpenAI Researchers Find That AI Is Unable to Solve Most Coding Problems</h1>
    
    <div id="readability-page-1" class="page"><section id="incArticle"><p>OpenAI researchers have admitted that even the most advanced AI models still are no match for human coders — even though CEO Sam Altman insists they will be able to beat &#34;<a href="https://www.reddit.com/r/singularity/comments/1iinrrq/sam_altman_software_engineering_will_be_very/">low-level</a>&#34; software engineers by the end of this year.</p><p>In a <a href="https://arxiv.org/pdf/2502.12115">new paper</a>, the company&#39;s researchers found that even frontier models, or the most advanced and boundary-pushing AI systems, &#34;are still unable to solve the majority&#34; of coding tasks.</p><p>The researchers used a newly-developed benchmark called SWE-Lancer, built on more than 1,400 software engineering tasks from the freelancer site Upwork. Using the benchmark, OpenAI put three large language models (LLMs) — its own o1 reasoning model and flagship GPT-4o, as well as Anthropic&#39;s Claude 3.5 Sonnet — to the test.</p><p>Specifically, the new benchmark evaluated how well the LLMs performed with two types of tasks from Upwork: individual tasks, which involved resolving bugs and implementing fixes to them, or management tasks that saw the models trying to zoom out and make higher-level decisions. (The models weren&#39;t allowed to access the internet, meaning they couldn&#39;t just crib similar answers that&#39;d been posted online.)</p><p>The models took on tasks cumulatively worth hundreds of thousands of dollars on Upwork, but they were only able to fix surface-level software issues, while remaining unable to actually find bugs in larger projects or find their root causes. These shoddy and half-baked &#34;solutions&#34; are likely familiar to anyone who&#39;s worked with AI — which is great at spitting out confident-sounding information that <a href="https://futurism.com/cnet-ai-errors">often falls apart</a> on closer inspection.</p><p>Though all three LLMs were often able to operate &#34;far faster than a human would,&#34; the paper notes, they also failed to grasp how widespread bugs were or to understand their context, &#34;leading to solutions that are incorrect or insufficiently comprehensive.&#34;</p><p>As the researchers explained, Claude 3.5 Sonnet performed better than the two OpenAI models pitted against it and made more money than o1 and GPT-4o. Still, the majority of its answers were wrong, and according to the researchers, any model would need &#34;higher reliability&#34; to be trusted with real-life coding tasks.</p><p>Put more plainly, the paper seems to demonstrate that although these frontier models can work quickly and solve zoomed-in tasks, they&#39;re are nowhere near as skilled at handling them as human engineers.</p><p>Though these LLMs have advanced rapidly over the past few years and will likely continue to do so, they&#39;re not skilled enough at software engineering to replace real-life people quite yet — not that that&#39;s stopping CEOs from <a href="https://futurism.com/the-byte/stack-overflow-layoffs-ai">firing their human coders</a> in favor of <a href="https://futurism.com/the-byte/ai-programming-assistants-code-error">immature AI models</a>.</p><p><strong>More on AI and coding: </strong><a href="https://futurism.com/the-byte/zuckerberg-automate-coding-ai"><em>Zuckerberg Announces Plans to Automate Facebook Coding Jobs With AI</em></a></p></section></div>
  </body>
</html>
