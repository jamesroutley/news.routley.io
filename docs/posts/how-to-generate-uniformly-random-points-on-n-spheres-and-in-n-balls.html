<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://extremelearning.com.au/how-to-generate-uniformly-random-points-on-n-spheres-and-n-balls/">Original</a>
    <h1>How to generate uniformly random points on n-spheres and in n-balls</h1>
    
    <div id="readability-page-1" class="page"><article id="post-2165"><div><p><span>For many Monte Carlo methods, such as those in graphical computing, it is critical to uniformly sample from $d$-dimensional spheres and balls. This post describes over twenty different methods to uniformly random sample from the (surface of) a $d$-dimensional sphere or the (interior of) a $d$-dimensional ball.</span></p><p>             First published: 10<em>th March, 2019</em> Last updated:    <em>16 April, 2020</em></p><p>This post gives a comprehensive list of the twenty most frequent and useful methods to uniformly sample from a the surface of a  $d$-sphere, and the interior of the $d$-ball.</p><p>Many of them are simple and intuitive; others utilize well-known math methods in sophisticated ways; whilst others can only be described as truly remarkable in their structure. The choice of which one suits your needs will most likely be a balance between code complexity and time efficiency. However, other aspects such as variance reduction may also be of considerable importance.</p><p>It is of course, always possible to use the most generalised versions of these formulae as outlined in methods 19-22 for all $d$, but I specifically list some of the specialised methods for smaller $d$ because they may be more efficient, relevant to your application,  and/or amenable to understanding than their  more general expressions. Furthermore, many of the methods applicable to the lower dimensions do not have simple or natural generalization.</p><h3>Definition of the $d-$sphere and $d$-ball.</h3><p>Let us recap the standard definitions of spheres and balls in $d$-dimensions.</p><p>A unit $d-$dimensional sphere is defined such that:</p><p>$$ S^d = \left\{   x \in \Bbb{R}^{d+1} : \left \lvert x \right \rvert = 1    \right\} $$</p><p>And a unit $d-$dimensional ball is defined such that:</p><p>$$ B^d = \left\{   x \in \Bbb{R}^{d} : \left \lvert x \right \rvert  \leq 1    \right\} $$</p><p>So the <span>perimeter of a circle is a 1-sphere</span>, and the <span>interior of the circle (a disk) is a 2-ball</span>.</p><p>And if the earth was perfectly spherical, than the <span>surface of earth would be a 2-sphere</span>, and the <span>interior of  the earth would be a 3-ball</span>.</p><p>The way I remember these definitions, is that for both the $d$-sphere and the $d$-ball, the $d$ signifies how many degrees of freedom it has.</p><h3>Uniform Random Sampling</h3><p>In this post, we adopt the convention that ‘<strong><em>uniform random sampling</em></strong>‘, ‘(<em>continuous) simple random sampling</em>‘, and even ‘<em>uniform sampling</em>‘ are all fully synonymous. And that for discrete probabilities, this means that all possible elements of $S$ have an equal probability of being selected. For continuous probabilities, this means that the likelihood of an element falling in any subinterval is directly proportional to the length of the subinterval.</p><p>Virtually all computer languages have a built-in function for this concept. For example , $\text{rand}(\cdot)$, that produces a random number that is (pseudo)-randomly drawn from uniform distribution $[0,1)$.</p><h3>Note 1.</h3><p>In contrast to many of my other posts on this blog, we are not talking about quasirandom sampling (aka ‘evenly distributed’), we are just talking about ‘plain old simple vanilla’ uniform random sampling.</p><h3>Note 2.</h3><p>For the coding examples, I generally use readable python code (built on numpy), except for acceptance/rejection methods where I used pseudo-code. The purpose of the code is aimed for clarity and so does not necessarily include language-specific conventions or optimizations. It uses the notation that $x**y$ is equal to $x^y$.</p><p>Although each of them have their strengths and weaknesses, <span>an asterisk (*) indicates methods that I believe are an excellent default option for that section.</span></p><p>That is, uniformly sampling points on the circumferende of a circle.</p><p><img fetchpriority="high" decoding="async" src="https://sp-ao.shortpixel.ai/client/to_auto,q_glossy,ret_img,w_300,h_286/https://extremelearning.com.au/wp-content/uploads/2019/03/UniformRandomSampling-S1-300x286.png" alt="" width="300" height="286" srcset="https://sp-ao.shortpixel.ai/client/to_auto,q_glossy,ret_img,w_300/https://extremelearning.com.au/wp-content/uploads/2019/03/UniformRandomSampling-S1-300x286.png 300w, https://sp-ao.shortpixel.ai/client/to_auto,q_glossy,ret_img,w_640/https://extremelearning.com.au/wp-content/uploads/2019/03/UniformRandomSampling-S1.png 640w" sizes="(max-width: 300px) 100vw, 300px"/></p><h3>*Method 1. Polar</h3><p>This should be very clear to everyone, and is the foundation for many of the other methods.</p><pre>theta = 2*PI * random()
x = cos(theta)
y = sin(theta)
</pre><h3>Method 2. Rejection Method</h3><p>A lesser-known method (<a href="http://mathworld.wolfram.com/CirclePointPicking.html">Cook, 1957</a>) that does not directly require trigonometric functions.</p><p>You might notice that the expressions have almost identical structure to Pythagorean triplets!</p><p>(This method is better known when generalised to the 2-sphere.)</p><pre>Select u,v ~ U(-1,1)
d2 = u^2+v^2
If d2 &gt;1 then
    reject and go back to step 1
Else
    x = (u^2-v^2)/d2
    y = (2*u*v)/d2
Return (x,y)
</pre><h3>Method 3. Muller , Marsaglia (‘Normalised Gaussians’)</h3><p>This method was first proposed by Muller and then Marsaglia and the popularised by Knuth, it is very elegant. It naturally generalizes and remains efficient for higher dimensions.</p><p>Presumably, it is less well-known due to the less obvious (magical?!) relationship between a circle and the Normal Distribution.</p><p>Note that in this version (and its generalizations), the standard deviation does not have to be 1, it just has to be identical for all the random variates. However, in nearly all implementations, a standard error of 1 is picked due to its convenience.</p><p>Also, in the absence of a native function, a simple and common method to draw from a normal distribution is via the Box-Mueller algorithm.</p><pre>u = np.random.normal(0,1)
v = np.random.normal(0,1)
d= (u^2+v^2)**0.5  # notation for sqrt(.)
(x,y) = (u,v)/d
</pre><p>To very briefly understand why this works, consider the function</p><p>$$ f(u,v) = f(\mathbf{z}) = \left( \frac{1}{\sqrt{2\pi}} e^{-\frac{1}{2}u^2} \right) \left( \frac{1}{\sqrt{2\pi}} e^{-\frac{1}{2}v^2} \right) $$</p><p>After some algebra, this simplifies to</p><p>$$ f(u,v) = f(\mathbf{z}) = \left( \frac{1}{(\sqrt{2\pi})^{3/2} }\right) e^{-\frac{1}{2}(u^2+v^2)} =  \left( \frac{1}{(\sqrt{2\pi})^{3/2} }\right) e^{-\frac{1}{2}(|\mathbf{z}|^2)}  $$</p><p>This illustrates that the probability distribution of $\mathbf{z}$ only depends on its magnitude and not any direction. Thus it must be rotationally invariant (symmetric). And thus, must correspond to a uniform distribution on the circle.</p><p>This argument is not specific to $d=2$ and can be generalized to any $d$.</p><p>That is, uniformly sampling points inside a circle.</p><h3>*Method 4. Rejection Method</h3><p>This is probably the most intuitive method, and is quite fast for a 2-ball.</p><p>However, (as discussed later) it generally gets a bad rap, because if you generalize this algorithm to higher dimensions, it can become catastrophically very inefficient.</p><figure id="attachment_2192" aria-describedby="caption-attachment-2192"><img decoding="async" src="data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20300%20286%22%3E%3C/svg%3E" data-src="https://sp-ao.shortpixel.ai/client/to_auto,q_glossy,ret_img,w_300,h_286/https://extremelearning.com.au/wp-content/uploads/2019/03/UniformRandomSampling-B2-v2-300x286.png" alt="" width="300" height="286" data-srcset="https://sp-ao.shortpixel.ai/client/to_auto,q_glossy,ret_img,w_300/https://extremelearning.com.au/wp-content/uploads/2019/03/UniformRandomSampling-B2-v2-300x286.png 300w, https://sp-ao.shortpixel.ai/client/to_auto,q_glossy,ret_img,w_640/https://extremelearning.com.au/wp-content/uploads/2019/03/UniformRandomSampling-B2-v2.png 640w" data-sizes="(max-width: 300px) 100vw, 300px"/><figcaption id="caption-attachment-2192">The rejection method for $B^2$ has a ~ 0.78 acceptance rate.</figcaption></figure><pre>1. Select x,y ~ U(-1,1)
2. If (x^2+y^2 &gt;1) then reject and go to step 1.
3. Return (x,y)</pre><h3>Method 5. Polar + Radial CDF</h3><p>For balls of any dimension, a very common method of uniformly picking from a $d$-ball, is to first select a random directional unit-vector from a $(d-1)$-sphere, and then multiply this vector by a scalar radial multiplicative factor.</p><p>The crucial aspect of this algorithm is the multiplicative factor, $\sqrt{\cdot}$ function. This is intuitively required because area, which corresponds to the cumulative distribution function (CDF), grows according to $r^2$, so we need to apply the inverse of this. See <a href="https://stackoverflow.com/questions/5837572/generate-a-random-point-within-a-circle-uniformly">here</a> for a more visual explanation of this.</p><p>The following method is notably asymmetrical. Geometrically, one variable is used for radial distance and the other for the angular displacement.</p><figure id="attachment_2187" aria-describedby="caption-attachment-2187"><img decoding="async" src="data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20300%20121%22%3E%3C/svg%3E" data-src="https://sp-ao.shortpixel.ai/client/to_auto,q_glossy,ret_img,w_300,h_121/https://extremelearning.com.au/wp-content/uploads/2019/03/Method4-mapping-v2-300x121.jpg" alt="" width="300" height="121" data-srcset="https://sp-ao.shortpixel.ai/client/to_auto,q_glossy,ret_img,w_300/https://extremelearning.com.au/wp-content/uploads/2019/03/Method4-mapping-v2-300x121.jpg 300w, https://sp-ao.shortpixel.ai/client/to_auto,q_glossy,ret_img,w_768/https://extremelearning.com.au/wp-content/uploads/2019/03/Method4-mapping-v2-768x311.jpg 768w, https://sp-ao.shortpixel.ai/client/to_auto,q_glossy,ret_img,w_1024/https://extremelearning.com.au/wp-content/uploads/2019/03/Method4-mapping-v2-1024x414.jpg 1024w, https://sp-ao.shortpixel.ai/client/to_auto,q_glossy,ret_img,w_1140/https://extremelearning.com.au/wp-content/uploads/2019/03/Method4-mapping-v2-1140x461.jpg 1140w" data-sizes="(max-width: 300px) 100vw, 300px"/><figcaption id="caption-attachment-2187">Figure 5. Polar mapping. Horizontal lines map to concentric circles.</figcaption></figure><pre>u = random()
v = random()
r = u**0.5  # sqrt function
theta = 2* PI *v
x = r*cos(theta)
y = r*sin(theta)
</pre><h3>*Method 6. Concentric Map (Shirley 1997)</h3><p>This variance reduction method  <a href="https://pdfs.semanticscholar.org/4322/6a3916a85025acbb3a58c17f6dc0756b35ac.pdf">(Shirley, 1997)</a> is fascinating and motivated by the idea that ideal mappings from the square-based random variate $uv$-space to the coordinate $xy$-space (disks) should be area-preserving, two-way continuous, and with low distortion. By comparing the <a href="http://l2program.co.uk/900/concentric-disk-sampling">figures</a> for method 5 and method 6, it should be clear why this one generally produces better results in (finite) MC methods. Additional visual explanation and analysis of this method is given <a href="http://marc-b-reynolds.github.io/math/2017/01/08/SquareDisc.html">here</a> (which also include some other variations including ‘squircle’, elliptical and approximate equal areas).</p><figure id="attachment_2188" aria-describedby="caption-attachment-2188"><img decoding="async" src="data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20300%20123%22%3E%3C/svg%3E" data-src="https://sp-ao.shortpixel.ai/client/to_auto,q_glossy,ret_img,w_300,h_123/https://extremelearning.com.au/wp-content/uploads/2019/03/Method5-mapping-v2-300x123.jpg" alt="" width="300" height="123" data-srcset="https://sp-ao.shortpixel.ai/client/to_auto,q_glossy,ret_img,w_300/https://extremelearning.com.au/wp-content/uploads/2019/03/Method5-mapping-v2-300x123.jpg 300w, https://sp-ao.shortpixel.ai/client/to_auto,q_glossy,ret_img,w_768/https://extremelearning.com.au/wp-content/uploads/2019/03/Method5-mapping-v2-768x314.jpg 768w, https://sp-ao.shortpixel.ai/client/to_auto,q_glossy,ret_img,w_1024/https://extremelearning.com.au/wp-content/uploads/2019/03/Method5-mapping-v2-1024x419.jpg 1024w, https://sp-ao.shortpixel.ai/client/to_auto,q_glossy,ret_img,w_1140/https://extremelearning.com.au/wp-content/uploads/2019/03/Method5-mapping-v2-1140x466.jpg 1140w" data-sizes="(max-width: 300px) 100vw, 300px"/><figcaption id="caption-attachment-2188">Figure 6. Concentric Mapping maps concentric squares to concentric circles.</figcaption></figure><pre>u= random()
v = random()
if (u==0 &amp;&amp; v==0) return (0,0)
theta=0
r = 1
a=2*u-1
b=2*v-1
if(a*a&gt;b*b)
    {r = a; phi = PI/4*b/a}
else
    {r = b; PI/2- PI/4*a/b}
x= r*cos(theta)
y= r*sin(theta)
</pre><h3>Method 7. Muller / Marsaglia (‘Normalized Gaussians’)</h3><p>This method is a hybrid of methods 3 and 5, because it selects a random direction via method 3 and a random radius via method 5.</p><pre>u = np.random.normal(0,1)
v = np.random.normal(0,1)
norm = (u*u+v*v)**0.5
r = pow( np.random(0,1),1/2.)
(x,y) = r*(u,v)/norm

</pre><h3>Method 8. Exponential Distribution</h3><p>Another stunningly elegant method (<a href="https://arxiv.org/abs/math/0503650">Barthe, 2005</a>) that is valid for balls of any dimension, is to draw $d$ random variates from the normal distribution, and a single random variable from the <a href="https://en.wikipedia.org/wiki/Exponential_distribution">exponential distribution</a> (with $\lambda=1/2$).</p><p>(Note that I believe there is a typo in the original paper, as the original paper says $\lambda = 1$, which has then also been copied into Wolfram’s <a href="http://mathworld.wolfram.com/BallPointPicking.html">mathworld</a>. )</p><p>Recall, that in the absence of a native function, a simple and common method to draw from an exponential distribution with parameter $\lambda$, is via the <a href="https://en.wikipedia.org/wiki/Exponential_distribution#Generating_exponential_variates">negative logarithm of a uniform random variate</a> divided by $\lambda$.</p><pre>u = np.random.normal(0,1) 
v = np.random.normal(0,1)
e = np.random.exponential(0.5)
denom = (u*u + v*v + e)**0.5
(x,y) = (u,v)/denom
</pre><h3>Method 9. Dropped Coordinates</h3><p>A somewhat magical method, first noted by (<a href="https://ac.els-cdn.com/S0047259X10001211/1-s2.0-S0047259X10001211-main.pdf?_tid=73b0035a-3af7-4bb8-bed0-75db9b15a265&amp;acdnat=1552228662_b1f683ed62e08af9d8772f92efa534e6">Harman and Lacko 2010</a>)  and then proven ( <a href="http://compneuro.uwaterloo.ca/files/publications/voelker.2017.pdf">Voelker 2017</a>) that is not well-known is that if $(x_1,x_2,x_3,x_4)$ is a random vector uniformly distributed on the $3$-sphere, the random vector $(x_1,x_2)$, (that is, with the last two coordinates dropped) is uniformly distributed in the $2$-ball.</p><p>See method 20 for a more detailed commentary of this method.</p><pre>s = np.random.normal(0,1)
t = np.random.normal(0,1)
u = np.random.normal(0,1)
v = np.random.normal(0,1)
norm = (s*s + t*t + u*u + v*v)**(0.5)
(x,y) = (u,v)/norm
</pre><figure id="attachment_2206" aria-describedby="caption-attachment-2206"><img decoding="async" src="data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20640%20220%22%3E%3C/svg%3E" data-src="https://sp-ao.shortpixel.ai/client/to_auto,q_glossy,ret_img,w_640,h_220/https://extremelearning.com.au/wp-content/uploads/2019/03/UniformRandomSampling-comparison_B2.png" alt="" width="640" height="220" data-srcset="https://sp-ao.shortpixel.ai/client/to_auto,q_glossy,ret_img,w_640/https://extremelearning.com.au/wp-content/uploads/2019/03/UniformRandomSampling-comparison_B2.png 640w, https://sp-ao.shortpixel.ai/client/to_auto,q_glossy,ret_img,w_300/https://extremelearning.com.au/wp-content/uploads/2019/03/UniformRandomSampling-comparison_B2-300x103.png 300w" data-sizes="(max-width: 640px) 100vw, 640px"/><figcaption id="caption-attachment-2206">Results for n=3000, for methods 8 (radial CDF), 9 (exponential) and 10 (dropped coordinates). It is truly remarkable that such different techniques can produce the same result!</figcaption></figure><p>That is, uniformly sampling points on the surface of a sphere.</p><p><img decoding="async" src="data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20276%20300%22%3E%3C/svg%3E" data-src="https://sp-ao.shortpixel.ai/client/to_auto,q_glossy,ret_img,w_276,h_300/https://extremelearning.com.au/wp-content/uploads/2019/03/UniformRandomSampling-S2-276x300.png" alt="" width="276" height="300" data-srcset="https://sp-ao.shortpixel.ai/client/to_auto,q_glossy,ret_img,w_276/https://extremelearning.com.au/wp-content/uploads/2019/03/UniformRandomSampling-S2-276x300.png 276w, https://sp-ao.shortpixel.ai/client/to_auto,q_glossy,ret_img,w_640/https://extremelearning.com.au/wp-content/uploads/2019/03/UniformRandomSampling-S2.png 640w" data-sizes="(max-width: 276px) 100vw, 276px"/></p><h3>Method 10. Polar</h3><p>This is the natural generalization of method 1. Note that the inverse cosine is required for the same reason that the sqrt is required in method 5.</p><pre>u = random()
v = random()
theta = 2 * PI * u
phi = np.arccos(2v-1)
x   = np.sin(theta) np.cos(phi)
y   = np.sin(theta) np.sin(phi)
z   = np.cos (theta)
</pre><p>Using $u=\cos \theta$, an equivalent version of this that does not directly involve inverse trig functions is</p><pre>u   = 2*random()-1
phi = 2* PI * random()
x = cos(phi) * (1-z^2)**0.5
y = sin(phi)* (1-z^2)**0.5
z = u</pre><h3>*Method 11. Muller</h3><p>This is a direct generalization of method 3.</p><pre>u = np.random.normal(0,1)
v = np.random.normal(0,1)
w = np.random.normal(0,1)
norm = (u*u + v*v + w*w)**(0.5)
(x,y,z) = (u,v,w)/norm
</pre><h3>Method 12. Rejection Method #1</h3><p>This method <a href="http://mathworld.wolfram.com/SpherePointPicking.html">(Marsaglia, 1972)</a> is a direct generalization of Method 2 .</p><pre>Select u,v ~ U(-1,1)
d2 = u*u + v*v
If d2&gt;1 then
    reject and go to step 1.
Else
    x = 2*u* sqrt (1-d2)
    y = 2*v* sqrt (1-d2)
    z = 1-2*d2
Return (x,y,z)
</pre><h3>Method 13. Rejection Method #2</h3><p>This method <a href="http://mathworld.wolfram.com/SpherePointPicking.html">(Cook, 1957)</a> is quite different to any of the previously discussed methods.</p><p>For those variables that are accepted, the rules for quaternion transformations, imply that the following points are uniformly distributed.</p><pre>Select s,t,u,v ~ U(-1,1)
d2 = s^2 + t^2 + u^2 + v^2
If d2&gt;1 then
    reject and go to step 1.
Else
    x = 2*(s*u+t*v)/d2
    y = 2*(u*v-s*t)/d2
    z = (s*s-t*t+u*u-v*v)/d2
Return (x,y,z)

</pre><p>That is, uniformly sampling points on the inside of a sphere.</p><h3>*Method 14. Rejection Method</h3><p>This <a href="http://mathworld.wolfram.com/SpherePointPicking.html">method</a> is a direct generalization of Method 2. Again, it is quite efficient as the acceptance rate is still relatively high and the calculations can be done blazingly fast. However, it carries a bad reputation as it is catastrophically inefficient for higher dimensions.</p><pre>1. Select x,y,z ~ U(-1,1)
2. If (x^2+y^2 +z^2&gt;1) then reject and go to step 1.
3. Return (x,y,z)
</pre><figure id="attachment_2198" aria-describedby="caption-attachment-2198"><img decoding="async" src="data:image/svg+xml,%3Csvg%20xmlns=%22http://www.w3.org/2000/svg%22%20viewBox=%220%200%20276%20300%22%3E%3C/svg%3E" data-src="https://sp-ao.shortpixel.ai/client/to_auto,q_glossy,ret_img,w_276,h_300/https://extremelearning.com.au/wp-content/uploads/2019/03/UniformRandomSampling-B3-v2-276x300.png" alt="" width="276" height="300" data-srcset="https://sp-ao.shortpixel.ai/client/to_auto,q_glossy,ret_img,w_276/https://extremelearning.com.au/wp-content/uploads/2019/03/UniformRandomSampling-B3-v2-276x300.png 276w, https://sp-ao.shortpixel.ai/client/to_auto,q_glossy,ret_img,w_640/https://extremelearning.com.au/wp-content/uploads/2019/03/UniformRandomSampling-B3-v2.png 640w" data-sizes="(max-width: 276px) 100vw, 276px"/><figcaption id="caption-attachment-2198">The rejection method for $B^3$ has a ~0.52 acceptance rate.</figcaption></figure><h3>*Method 15. Muller</h3><p>This is combination of method 7.</p><pre>u = np.random.normal(0,1)
v = np.random.normal(0,1)
w = np.random.normal(0,1)
r = random()**(1./3)
norm= (u*u+v*v+w*w)**(0.5)
(x,y,z) = r*(u,v,w)/norm
</pre><h3>*Method 16. Polar</h3><p>This is the natural generalization of method 5.</p><pre>u = 2*random()-1
phi = 2* PI * random()
r = random()**(1/3.)
x = r* cos(phi) * (1-u^2)**0.5
y = r* sin(phi)* (1-u^2)**0.5
z = r*u
</pre><h3>Method 17. Exponential Distribution</h3><p>This is a direct generalisation of method 8. Again, note that I believe there is a typo in the original paper, as the original paper says $\lambda = 1$, which has then also been copied into Wolfram’s <a href="http://mathworld.wolfram.com/BallPointPicking.html">mathworld</a>.</p><pre>u = np.random.normal(0,1)
v = np.random.normal(0,1)
w = np.random.normal(0,1)
e = np.random.exponential(0.5)
denom = (e + u*u + v*v + w*w)**0.5
(x,y,z) = (u,v,w)/denom
</pre><h3>Method 18. Dropped Coordinates</h3><p>A natural extension of method X.</p><p>Based on the fact that if $(x_1,x_2,x_3,x_4,x_5)$ is a random vector uniformly distributed on the $4$-sphere, the random vector $(x_1,x_2,x_3)$, (that is, with the last two coordinates dropped) is uniformly distributed in the $3$-ball.</p><p>See method 20 for a more detailed commentary of this method.</p><pre>s = np.random.normal(0,1)
t = np.random.normal(0,1)
u = np.random.normal(0,1)
v = np.random.normal(0,1)
w = np.random.normal(0,1)
norm = (s*s + t*t + u*u + v*v + w*w)**(0.5)
(x,y,z) = (u,v,w)/norm
</pre><h3>*Method 19. Muller</h3><p>For higher dimensions where $d&gt;3$, most of the above methods do not neatly simplify. Therefore, the one that is almost always used for a $d$-sphere is the generalised version of methods 3 and 9.</p><pre>u = np.random.normal(0,1,d)  # an array of d normally distributed random variables
d=np.sum(u**2) **(0.5)
(x,y,z) = (u,v,w)/d
</pre><p>Although the rejection methods 4 and 13 are extremely intuitive and trivially generalise to higher dimensions, one quickly encounters ‘the curse of dimensionality’. As mentioned, for $d=1$ the acceptance rate is $\sim 0.71$, and for $d=2$ the acceptance rate is $\sim 0.52$. Although this might appear inefficient, due to not requiring to calculate any complex functions this is often one of the fastest ways to pick points in a $2-$ball or $3$-ball.</p><p>By comparing the hypervolume of a $d$-ball with the enclosing cube, one can deduce that for $d=10$, the acceptance rate is less than 0.0025 and it gets exponentially worse for higher $d$.</p><h3>*Method 20. Muller</h3><p>In practice, the almost exclusive method to calculate points inside a $d-$ball is the generalized version of method 14. Namely,</p><pre>u = np.random.normal(0,1,d)  # an array of d normally distributed random variables
norm=np.sum(u**2) **(0.5)
r = random()**(1.0/d)
x= r*u/norm
</pre><h3>Method 21. Exponential Distribution</h3><p>This is a direct generalisation of method 8 and 16.</p><pre>x = np.random.normal(0,1,d)
e = np.random.exponential(0.5)
denom = (e + np.sum(u**2))**0.5 
(x,y,z) = (u,v,w)/denom
</pre><h3>*Method 22. Dropped Coordinates</h3><p>A very elegant method, first noted by (<a href="https://ac.els-cdn.com/S0047259X10001211/1-s2.0-S0047259X10001211-main.pdf?_tid=73b0035a-3af7-4bb8-bed0-75db9b15a265&amp;acdnat=1552228662_b1f683ed62e08af9d8772f92efa534e6">Harman and Lacko 2010</a>)  and then proven ( <a href="http://compneuro.uwaterloo.ca/files/publications/voelker.2017.pdf">Voelker 2017</a>) that is not well-known is that if $ (x_1,x_2,x_3,…,x_d,x_{d+1},x_{d+2})$ is a random vector uniformly distributed on the $(d+1)$-sphere, the random vector $ (x_1,x_2,x_3,…,x_d)$, (that is, with the last two coordinates dropped) is uniformly distributed in the $d$-ball.</p><p>This is non-trivial result where even developing an intuition is <a href="https://mathoverflow.net/questions/33129/intuitive-proof-that-the-first-n-2-coordinates-on-a-sphere-are-uniform-in-a">difficult</a>, (even the base case of $d=1$ is <a href="https://math.stackexchange.com/questions/185298/random-point-uniform-on-a-sphere">not trivial!</a>)</p><p>However, it may be interesting/useful to note that an $\exp(1/2)$ variable $Y$ in method 19, has the same distribution as $(Y_1^2+Y_2^2)$  where $Y_1,Y_2$ are standard normal – thus connecting this methods 19 and 20.</p><p>Thus,</p><pre>u = np.random.normal(0,1,d+2)  # an array of (d+2) normally distributed random variables
norm=np.sum(u**2) **(0.5)
u = u/norm
x = u[0:d] #take the first d coordinates
</pre><p>This post gives a comprehensive list of the most frequent and useful methods to uniformly sample from a the surface of a  $d$-sphere, an the interior of the $d$-ball.</p><p>Many of them are simple and intuitive, whilst others are truly remarkable in their structure.</p><p>It is of course, possible to always use the most generalised versions of these formulae as outlined in methods 19-22, but sometimes specialised methods for smaller $d$ may be more efficient and/or amenable to understanding.</p><blockquote><p>***</p><blockquote><p><span>My name is Dr Martin Roberts, and I’m a freelance Principal Data Science consultant, who loves working at the intersection of maths and computing. <em> <strong>“I transform and modernize organizations through innovative data strategies solutions.”</strong></em></span></p><blockquote><p><strong>You can contact me through any of these channels.</strong></p><p>LinkedIn: <a href="https://www.linkedin.com/in/martinroberts/">https://www.linkedin.com/in/martinroberts/</a></p><p>Twitter: <strong>@TechSparx</strong>  <a href="https://twitter.com/TechSparx">https://twitter.com/TechSparx</a></p><p>email: Martin (at) RobertsAnalytics (dot) com</p><p>More details about me can be found <em><strong><a href="https://extremelearning.com.au/about">here</a>.</strong></em></p></blockquote></blockquote></blockquote><ul><li><a href="https://extremelearning.com.au/isotropic-blue-noise-point-sets/">A new method to construct isotropic blue noise point sets with uniform projections</a></li><li><a href="https://extremelearning.com.au/how-to-evenly-distribute-points-on-a-sphere-more-effectively-than-the-canonical-fibonacci-lattice/">How to evenly distribute points on a sphere more effectively than the canonical Fibonacci lattice</a></li><li><a href="https://extremelearning.com.au/a-simple-method-to-construct-isotropic-quasirandom-blue-noise-point-sequences/">A simple method to construct isotropic quasirandom blue noise point sequences</a></li></ul></div></article></div>
  </body>
</html>
