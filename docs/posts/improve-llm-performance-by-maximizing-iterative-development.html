<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/palico-ai/palico-ai">Original</a>
    <h1>Show HN: Improve LLM Performance by Maximizing Iterative Development</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto">LLM Application development is extremely iterative, more so than any other types of development. This is because to improve an LLM application performance (accuracy, hallucinations, latency, cost), you need to trial and error various combinations of LLM models, prompt templates (e.g., few-shot, chain-of-thought), prompt context with different RAG architecture, different agent architecture, and more. <strong>There are thousands of possible combinations to try</strong>.</p>
<p dir="auto">Palico is an LLM Development Framework that structures your application development for rapid experimentation so you can easily test different combination of your LLM application stack and quickly iterate towards your accuracy goals.</p>

<ul dir="auto">
<li><a href="#build">Build</a> modular LLM applications or workflows that can easily swap out different combination of models, prompts, context, business logic, architecture, and more.</li>
<li><a href="#experiment">Improve accuracy</a> by running lots of experiments and objectively evaluating your application performance with data</li>
<li><a href="#deploy">Deploy</a> to any cloud provider as docker images</li>
<li><a href="#client-sdk">Integrate</a> your LLM application or workflows with your other services via REST API or SDK</li>
<li><a href="#palico-studio">Manage</a> your LLM application via Palico Studio - your application control panel</li>
</ul>
<div dir="auto"><h4 tabindex="-1" dir="auto">We help you build a modular tech-stack built for rapid iteration</h4><a id="user-content-we-help-you-build-a-modular-tech-stack-built-for-rapid-iteration" aria-label="Permalink: We help you build a modular tech-stack built for rapid iteration" href="#we-help-you-build-a-modular-tech-stack-built-for-rapid-iteration"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/32821894/344797328-3d037333-48c8-4045-8ba5-3696e9d97636.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTk5OTUwNTAsIm5iZiI6MTcxOTk5NDc1MCwicGF0aCI6Ii8zMjgyMTg5NC8zNDQ3OTczMjgtM2QwMzczMzMtNDhjOC00MDQ1LThiYTUtMzY5NmU5ZDk3NjM2LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA3MDMlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNzAzVDA4MTkxMFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTU0OWMyMGViMWRjNWM0MjU1M2E2YTQ2NTQ1ZjBmMmRlODdjNTQ2ODBlNGM1NmRiYmFlN2E5YzgxZTBhNzE5N2UmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.M8UQX4zkekiGclIh3Bf1UVTLR7xwPmQNtK7p23ZBi04"><img src="https://private-user-images.githubusercontent.com/32821894/344797328-3d037333-48c8-4045-8ba5-3696e9d97636.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTk5OTUwNTAsIm5iZiI6MTcxOTk5NDc1MCwicGF0aCI6Ii8zMjgyMTg5NC8zNDQ3OTczMjgtM2QwMzczMzMtNDhjOC00MDQ1LThiYTUtMzY5NmU5ZDk3NjM2LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA3MDMlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNzAzVDA4MTkxMFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTU0OWMyMGViMWRjNWM0MjU1M2E2YTQ2NTQ1ZjBmMmRlODdjNTQ2ODBlNGM1NmRiYmFlN2E5YzgxZTBhNzE5N2UmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.M8UQX4zkekiGclIh3Bf1UVTLR7xwPmQNtK7p23ZBi04" alt="image"/></a></p>

<p dir="auto">Setup a simple starter application with an OpenAI Chatbot</p>
<ol dir="auto">
<li>
<p dir="auto">Create a Palico App</p>
<div dir="auto" data-snippet-clipboard-copy-content="npx palico init &lt;project-name&gt;"><pre>npx palico init <span>&lt;</span>project-name<span>&gt;</span></pre></div>
</li>
<li>
<p dir="auto">Add your OpenAI API key to <code>.env</code> file. You can get your OpenAI API key from <a href="https://platform.openai.com/api-keys" rel="nofollow">OpenAI</a></p>
<div dir="auto" data-snippet-clipboard-copy-content="OPENAI_API_KEY=&lt;your-openai-api-key&gt;"><pre><span>OPENAI_API_KEY</span><span>=</span><span>&lt;</span><span>your-openai-api-key</span><span>&gt;</span></pre></div>
</li>
<li>
<p dir="auto">Initialize required services for your Palico App. You only need to run this once when you first setup a new Palico App in a new environment.</p>

</li>
<li>
<p dir="auto">Start your Palico App</p>

</li>
</ol>
<p dir="auto">You can now chat with your chatbot in the Palico Studio at <a href="http://localhost:5173/chat" rel="nofollow">http://localhost:5173/chat</a>. You can also modify your chat application in <code>src/agents/chatbot/index.ts</code>.</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">Overview of your Palico Starter App</h3><a id="user-content-overview-of-your-palico-starter-app" aria-label="Permalink: Overview of your Palico Starter App" href="#overview-of-your-palico-starter-app"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<details open="">
  <summary>
    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true">
    <path d="M16 3.75v8.5a.75.75 0 0 1-1.136.643L11 10.575v.675A1.75 1.75 0 0 1 9.25 13h-7.5A1.75 1.75 0 0 1 0 11.25v-6.5C0 3.784.784 3 1.75 3h7.5c.966 0 1.75.784 1.75 1.75v.675l3.864-2.318A.75.75 0 0 1 16 3.75Zm-6.5 1a.25.25 0 0 0-.25-.25h-7.5a.25.25 0 0 0-.25.25v6.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-6.5ZM11 8.825l3.5 2.1v-5.85l-3.5 2.1Z"></path>
</svg>
    <span aria-label="Video description Palico.Init.Overview.mp4">Palico.Init.Overview.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/32821894/344340596-54f35583-41c1-48a3-9565-95c484a4909b.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTk5OTUwNTAsIm5iZiI6MTcxOTk5NDc1MCwicGF0aCI6Ii8zMjgyMTg5NC8zNDQzNDA1OTYtNTRmMzU1ODMtNDFjMS00OGEzLTk1NjUtOTVjNDg0YTQ5MDliLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA3MDMlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNzAzVDA4MTkxMFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTU3MDk5MGZjOTU5OTIwN2VkMzVjNmRhYjA0YzZlMmQyYjliNWUwMzAyY2NjMzQ2YjkyNzhlZTBiNzcwYWI2OTgmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.fMmHc9tU9_q6JrLvGGAEXuLeaZ_LPoOtXtUOTtvDsow" data-canonical-src="https://private-user-images.githubusercontent.com/32821894/344340596-54f35583-41c1-48a3-9565-95c484a4909b.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTk5OTUwNTAsIm5iZiI6MTcxOTk5NDc1MCwicGF0aCI6Ii8zMjgyMTg5NC8zNDQzNDA1OTYtNTRmMzU1ODMtNDFjMS00OGEzLTk1NjUtOTVjNDg0YTQ5MDliLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA3MDMlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNzAzVDA4MTkxMFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTU3MDk5MGZjOTU5OTIwN2VkMzVjNmRhYjA0YzZlMmQyYjliNWUwMzAyY2NjMzQ2YjkyNzhlZTBiNzcwYWI2OTgmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.fMmHc9tU9_q6JrLvGGAEXuLeaZ_LPoOtXtUOTtvDsow" controls="controls" muted="muted">

  </video>
</details>

<div dir="auto"><h2 tabindex="-1" dir="auto">Components of a Palico Application</h2><a id="user-content-components-of-a-palico-application" aria-label="Permalink: Components of a Palico Application" href="#components-of-a-palico-application"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>

<p dir="auto">Palico let’s you build any LLM application. We provides you with complete flexibilities with any tools or libraries you want to use to build your LLM application with. The most basic building block of a Palico Application are <code>Agent</code>, which has a single method, <code>chat()</code>. Here’s an example of an Agent:</p>
<div dir="auto" data-snippet-clipboard-copy-content="class ChatbotAgent implements LLMAgent {
  static readonly NAME: string = __dirname.split(&#39;/&#39;).pop()!;

  async chat(
    content: ConversationRequestContent,
    context: ConversationContext
  ): Promise&lt;LLMAgentResponse&gt; {
    const { userMessage } = content;
    const { appConfig } = context;
    // Your LLM prompt + model call
    const response = await portkey.chat.completions.create({
      messages: [
        { role: &#39;system&#39;, content: &#39;You are a pirate&#39; },
        { role: &#39;user&#39;, content: &#39;Hello&#39; },
      ],
      model: appConfig.model,
    });
    return {
      messages: response.messages,
    };
  }
}"><pre><span>class</span> <span>ChatbotAgent</span> <span>implements</span> <span>LLMAgent</span> <span>{</span>
  <span>static</span> <span>readonly</span> <span>NAME</span>: <span>string</span> <span>=</span> <span>__dirname</span><span>.</span><span>split</span><span>(</span><span>&#39;/&#39;</span><span>)</span><span>.</span><span>pop</span><span>(</span><span>)</span><span>!</span><span>;</span>

  <span>async</span> <span>chat</span><span>(</span>
    <span>content</span>: <span>ConversationRequestContent</span><span>,</span>
    <span>context</span>: <span>ConversationContext</span>
  <span>)</span>: <span>Promise</span><span>&lt;</span><span>LLMAgentResponse</span><span>&gt;</span> <span>{</span>
    <span>const</span> <span>{</span> userMessage <span>}</span> <span>=</span> <span>content</span><span>;</span>
    <span>const</span> <span>{</span> appConfig <span>}</span> <span>=</span> <span>context</span><span>;</span>
    <span>// Your LLM prompt + model call</span>
    <span>const</span> <span>response</span> <span>=</span> <span>await</span> <span>portkey</span><span>.</span><span>chat</span><span>.</span><span>completions</span><span>.</span><span>create</span><span>(</span><span>{</span>
      <span>messages</span>: <span>[</span>
        <span>{</span> <span>role</span>: <span>&#39;system&#39;</span><span>,</span> <span>content</span>: <span>&#39;You are a pirate&#39;</span> <span>}</span><span>,</span>
        <span>{</span> <span>role</span>: <span>&#39;user&#39;</span><span>,</span> <span>content</span>: <span>&#39;Hello&#39;</span> <span>}</span><span>,</span>
      <span>]</span><span>,</span>
      <span>model</span>: <span>appConfig</span><span>.</span><span>model</span><span>,</span>
    <span>}</span><span>)</span><span>;</span>
    <span>return</span> <span>{</span>
      <span>messages</span>: <span>response</span><span>.</span><span>messages</span><span>,</span>
    <span>}</span><span>;</span>
  <span>}</span>
<span>}</span></pre></div>
<p dir="auto">Note that we are using Portkey to make our LLM call. Similarly, you can use LangChain or LlamaIndex to help you build your prompt and manage your model calls.</p>
<p dir="auto">Our goal is to help developers create a more modular system so they can easily test different configuration of their LLM system to find the best input combination. That is where the <code>appConfig</code> parameter comes in. Developers should treat this like a feature flag and use this to programmatically build a more modular LLM application.</p>
<p dir="auto">In addition to Agents, we have <code>Workflows</code> for more complex control flows and multi-agent applications.</p>
<p dir="auto">Read more about <a href="https://docs.palico.ai/build_app/agents" rel="nofollow">Agents</a>.</p>

<p dir="auto">Experiments are how you iteratively improve the accuracy of your application. Experimentation has three steps.</p>
<div dir="auto"><h4 tabindex="-1" dir="auto">Create your accuracy benchmark</h4><a id="user-content-create-your-accuracy-benchmark" aria-label="Permalink: Create your accuracy benchmark" href="#create-your-accuracy-benchmark"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Benchmark is basically outlining the expected behavior of your application. This consists of creating a list of test-cases where you define an input to your LLM application, and measuring it’s output. Here’s an example</p>
<div dir="auto" data-snippet-clipboard-copy-content="{
  input: {
    userMessage:
      &#39;Given the equation 2x + 3 = 7, solve for x.&#39;,
  },
  tags: {
    category: &#39;math&#39;,
  },
  metrics: [
    new SemanticSimilarity([
      &#34;Answer: x = 2&#34;,
      &#34;x = 2&#34;,
      &#34;2&#34;,
    ]),
  ],
}"><pre><span>{</span>
  <span>input</span>: <span>{</span>
    <span>userMessage</span>:
      <span>&#39;Given the equation 2x + 3 = 7, solve for x.&#39;</span><span>,</span>
  <span>}</span><span>,</span>
  <span>tags</span>: <span>{</span>
    <span>category</span>: <span>&#39;math&#39;</span><span>,</span>
  <span>}</span><span>,</span>
  <span>metrics</span>: <span>[</span>
    <span>new</span> <span>SemanticSimilarity</span><span>(</span><span>[</span>
      <span>&#34;Answer: x = 2&#34;</span><span>,</span>
      <span>&#34;x = 2&#34;</span><span>,</span>
      <span>&#34;2&#34;</span><span>,</span>
    <span>]</span><span>)</span><span>,</span>
  <span>]</span><span>,</span>
<span>}</span></pre></div>
<p dir="auto">You can use metrics that we provide out-of-the-box, or you can create your own custom metrics.</p>

<p dir="auto">Evaluation is the process of running your LLM application with a specific <code>appConfig</code> , across a benchmark test-suite. Palico Studio helps manage these evaluations</p>
<details open="">
  <summary>
    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true">
    <path d="M16 3.75v8.5a.75.75 0 0 1-1.136.643L11 10.575v.675A1.75 1.75 0 0 1 9.25 13h-7.5A1.75 1.75 0 0 1 0 11.25v-6.5C0 3.784.784 3 1.75 3h7.5c.966 0 1.75.784 1.75 1.75v.675l3.864-2.318A.75.75 0 0 1 16 3.75Zm-6.5 1a.25.25 0 0 0-.25-.25h-7.5a.25.25 0 0 0-.25.25v6.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-6.5ZM11 8.825l3.5 2.1v-5.85l-3.5 2.1Z"></path>
</svg>
    <span aria-label="Video description Experiments.mp4">Experiments.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/32821894/344340885-3a9dc1c5-319b-4c0b-8096-845f34542ae9.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTk5OTUwNTAsIm5iZiI6MTcxOTk5NDc1MCwicGF0aCI6Ii8zMjgyMTg5NC8zNDQzNDA4ODUtM2E5ZGMxYzUtMzE5Yi00YzBiLTgwOTYtODQ1ZjM0NTQyYWU5Lm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA3MDMlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNzAzVDA4MTkxMFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTI5MWMxNTUyNmEyM2MxZjY4OTYzOTkyODkxYTc1NzNiODFhODBmYTU2NDUxMGM5NDBjNjFjYjJiMWU2ZTM3NjMmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.UNtGPqwnmLXZM2QWCudK5ou8SGDU9s9Wvd6hO1zJ0Vg" data-canonical-src="https://private-user-images.githubusercontent.com/32821894/344340885-3a9dc1c5-319b-4c0b-8096-845f34542ae9.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTk5OTUwNTAsIm5iZiI6MTcxOTk5NDc1MCwicGF0aCI6Ii8zMjgyMTg5NC8zNDQzNDA4ODUtM2E5ZGMxYzUtMzE5Yi00YzBiLTgwOTYtODQ1ZjM0NTQyYWU5Lm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA3MDMlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNzAzVDA4MTkxMFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTI5MWMxNTUyNmEyM2MxZjY4OTYzOTkyODkxYTc1NzNiODFhODBmYTU2NDUxMGM5NDBjNjFjYjJiMWU2ZTM3NjMmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.UNtGPqwnmLXZM2QWCudK5ou8SGDU9s9Wvd6hO1zJ0Vg" controls="controls" muted="muted">

  </video>
</details>


<p dir="auto">This is the review process for understanding the impact a given change has had on your LLM application. This is often done by reviewing the output metrics of an LLM application and comparing it against other tests. We have built-in support for evaluation in Palico Studio, but you can also run your own analysis in Jupyter Notebook.</p>
<p dir="auto">Read more about <a href="https://docs.palico.ai/build_app/experiments/intro" rel="nofollow">Experiments</a>.</p>

<p dir="auto">Your Palico App compiles to bunch of docker containers, which you can easily deploy to any cloud provider</p>

<p dir="auto">We provide a ClientSDK that let’s you easily connect to your LLM Agents or Workflow from your other services</p>
<p dir="auto">Read more about <a href="https://docs.palico.ai/build_app/sdk" rel="nofollow">Client SDK</a>.</p>

<p dir="auto">We provide tracing out-of-the-box, and you can add any custom traces using OpenTelemetry</p>
<p dir="auto">Read more about <a href="https://docs.palico.ai/build_app/tracing" rel="nofollow">Tracing</a>.</p>

<p dir="auto">Palico Studio is your Control Panel for your Palico App. With Palico Studio you can:</p>
<ul dir="auto">
<li>Chat with your LLM Agents or Workflows</li>
<li>Compare responses side by side</li>
<li>Manage experiments</li>
<li>Review runtime traces</li>
</ul>
<p dir="auto">During development, Palico Studio runs on your local machine to help aide in your development. In production, you can use this control panel to monitor runtime analytics.</p>
<details open="">
  <summary>
    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true">
    <path d="M16 3.75v8.5a.75.75 0 0 1-1.136.643L11 10.575v.675A1.75 1.75 0 0 1 9.25 13h-7.5A1.75 1.75 0 0 1 0 11.25v-6.5C0 3.784.784 3 1.75 3h7.5c.966 0 1.75.784 1.75 1.75v.675l3.864-2.318A.75.75 0 0 1 16 3.75Zm-6.5 1a.25.25 0 0 0-.25-.25h-7.5a.25.25 0 0 0-.25.25v6.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-6.5ZM11 8.825l3.5 2.1v-5.85l-3.5 2.1Z"></path>
</svg>
    <span aria-label="Video description Palico.Studio.Demo.mp4">Palico.Studio.Demo.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/32821894/344344857-0423cd2d-e5cf-4589-855e-945fb3a5f392.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTk5OTUwNTAsIm5iZiI6MTcxOTk5NDc1MCwicGF0aCI6Ii8zMjgyMTg5NC8zNDQzNDQ4NTctMDQyM2NkMmQtZTVjZi00NTg5LTg1NWUtOTQ1ZmIzYTVmMzkyLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA3MDMlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNzAzVDA4MTkxMFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWQ5MjU3NzBiODYwN2Y0NjRhZWYyMjRhZmI0MThlZWFmNzdjOTkzYTljZmZmZWVhMjExZTRkYWIyMjQ1ODA4MzkmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.d7ydaN6Q4Q5XBHaa7LKN4xmYAnOZU2kFmSJnUcb08wI" data-canonical-src="https://private-user-images.githubusercontent.com/32821894/344344857-0423cd2d-e5cf-4589-855e-945fb3a5f392.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTk5OTUwNTAsIm5iZiI6MTcxOTk5NDc1MCwicGF0aCI6Ii8zMjgyMTg5NC8zNDQzNDQ4NTctMDQyM2NkMmQtZTVjZi00NTg5LTg1NWUtOTQ1ZmIzYTVmMzkyLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA3MDMlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNzAzVDA4MTkxMFomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWQ5MjU3NzBiODYwN2Y0NjRhZWYyMjRhZmI0MThlZWFmNzdjOTkzYTljZmZmZWVhMjExZTRkYWIyMjQ1ODA4MzkmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.d7ydaN6Q4Q5XBHaa7LKN4xmYAnOZU2kFmSJnUcb08wI" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto">Read more about <a href="https://docs.palico.ai/build_app/studio" rel="nofollow">Palico Studio</a>.</p>

<div dir="auto"><h3 tabindex="-1" dir="auto">How does libraries like LangChain compared to Palico</h3><a id="user-content-how-does-libraries-like-langchain-compared-to-palico" aria-label="Permalink: How does libraries like LangChain compared to Palico" href="#how-does-libraries-like-langchain-compared-to-palico"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">LangChain and LlamaIndex are more like libraries that helps you achieve different tasks with LLM Development. For example, they provide you tools to connect with different LLM providers, connect to vector database, create evaluations, and more. They are more like a swiss army knife that helps you achieve different tasks with LLM Development. It&#39;s up to you to use these tools to structure your LLM application development for maximum productivity.</p>
<p dir="auto">We are a framework (not a library) that has strong opinions on how you should structure your LLM application development. Our opinion is biased towards accuracy improvement through rapid experimentations. With our framework, you have a standard process, and an integrated set of tools, that helps you build your LLM application, measure accuracy, and run experiments. These processes all work together to maximize experiment-ability of your LLM application so you can reach your accuracy goals faster.</p>
<p dir="auto">As we are a framework and LangChain or LlamaIndex are libraries, you can directly use LangChain or LlamaIndex within our application to help with tasks such as calling LLM models or managing your RAG layer while using our framework to streamline your experimentation process.</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">How does evaluation libraries compared to Palico</h3><a id="user-content-how-does-evaluation-libraries-compared-to-palico" aria-label="Permalink: How does evaluation libraries compared to Palico" href="#how-does-evaluation-libraries-compared-to-palico"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Evaluation frameworks are often just a tool to help you grade the response of your LLM application. They may provide some proprietary observability and tracing tools. They however do not help you structure your LLM application development for rapid experimentation. They do not help you build your LLM application. They do not help you deploy your LLM application. The responsibility you have when using an evaluation framework is you need to build your own experiment management system that helps you scale your experimentation process across your team. You will have lots of fragmented tools that you need to integrate together to get a full picture of your LLM application.</p>
<p dir="auto">We are a more integrated framework that helps you build, scale experimentation, and deploy your LLM application. We provide a more integrated experience for your team to work on LLM applications.</p>
</article></div></div>
  </body>
</html>
