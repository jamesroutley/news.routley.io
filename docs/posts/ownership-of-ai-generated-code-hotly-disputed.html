<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://spectrum.ieee.org/ai-code-generation-ownership">Original</a>
    <h1>Ownership of AI-Generated Code Hotly Disputed</h1>
    
    <div id="readability-page-1" class="page"><div data-elid="2658687697" data-post-url="https://spectrum.ieee.org/ai-code-generation-ownership" data-authors="Rina Diane Caballar" data-headline="Ownership of AI-Generated Code Hotly Disputed"><div><p><a href="https://github.com/features/copilot" rel="noopener noreferrer" target="_blank">GitHub Copilot</a> dubs itself as an “AI pair programmer” for software developers, automatically suggesting code in real time. According to GitHub, Copilot is “powered by <a href="https://openai.com/blog/openai-codex/" rel="noopener noreferrer" target="_blank">Codex</a>, a generative pretrained AI model created by <a href="https://openai.com/" rel="noopener noreferrer" target="_blank">OpenAI</a>” and has been trained on “natural language text and source code from publicly available sources, including code in public repositories on GitHub.”
</p><p>
	However, a <a href="https://www.prnewswire.com/news-releases/joseph-saveri-law-firm-and-matthew-butterick-file-class-action-lawsuit-against-github-microsoft-and-openai-over-violations-of-open-source-licenses-arising-from-github-copilot-an-ai-based-product-301668255.html" rel="noopener noreferrer" target="_blank">class-action lawsuit</a> filed against GitHub Copilot, its parent company <a href="https://www.microsoft.com/" rel="noopener noreferrer" target="_blank">Microsoft</a>, and OpenAI <a href="https://githubcopilotlitigation.com/" rel="noopener noreferrer" target="_blank">claims open-source software piracy and violations of open-source licenses</a>. Specifically, the lawsuit states that code generated by Copilot does not include any attribution to the original author of the code, copyright notices, or a copy of the license, which most open-source licenses require.
</p><p>
	“The spirit of open source is not just a space where people want to keep it open,” says <a href="https://www.linkedin.com/in/salkimmich/" rel="noopener noreferrer" target="_blank">Sal Kimmich</a>, an open-source developer advocate at <a href="https://www.sonatype.com/" rel="noopener noreferrer" target="_blank">Sonatype</a>, machine-learning engineer, and open-source contributor and maintainer. “We have developed processes in order to keep open source secure, and that requires traceability, observability, and verification. Copilot is obscuring the original provenance of those [code] snippets.”
</p><p>
	“I very much hope that what comes out of this lawsuit will be something I can rely on when making decisions about training models in the future.”</p><p>
	In an attempt to address the issues with open-source licensing, GitHub plans to introduce a new Copilot feature that will “provide a <a href="https://github.blog/2022-11-01-preview-referencing-public-code-in-github-copilot/" rel="noopener noreferrer" target="_blank">reference for suggestions that resemble public code</a> on GitHub so that you can make a more informed decision about whether and how to use that code,” including “providing attribution where appropriate.” GitHub also has a configurable <a href="https://docs.github.com/en/copilot/configuring-github-copilot/configuring-github-copilot-settings-on-githubcom" rel="noopener noreferrer" target="_blank">filter to block suggestions matching public code</a>.
</p><p>
	The onus, however, still falls on developers, as GitHub states in <a href="https://docs.github.com/en/site-policy/github-terms/github-terms-for-additional-products-and-features#github-copilot" rel="noopener noreferrer" target="_blank">Copilot’s terms and conditions</a>: “GitHub does not claim any rights in Suggestions, and you retain ownership of and responsibility for Your Code, including Suggestions you include in Your Code.”
</p><p>
	In addition to open-source licensing issues, Copilot raises concerns in terms of the legality of training the system on publicly available code, as well as whether generated code could result in copyright infringement.
</p><p>
	Kimmich points to the <a href="https://spectrum.ieee.org/google-v-oracle-explained-supreme-court-news-apis-software" target="_self">Google <em>v.</em> Oracle case</a>, wherein “taking the names of methods, but not the functional implementation, is OK. You’re replacing the functional content but still keeping some of the template.” In the case of Copilot, it might generate copyrighted code verbatim. (See the related tweet below from <a href="https://engineering.tamu.edu/cse/profiles/davis-tim.html" target="_blank">Tim Davis</a>, computer science professor at Texas A&amp;M University, as an illustration of Copilot generating copyrighted code.)
</p><div id="82991" data-rm-shortcode-id="83af94d7805fabe42bd207cafc2dc055"><div><div><blockquote data-twitter-tweet-id="1581461734665367554" data-partner="rebelmouse"><p>\u201c@github copilot, with &#34;public code&#34; blocked, emits large chunks of my  copyrighted code, with no attribution, no LGPL license.  For example, the simple prompt &#34;sparse matrix transpose, cs_&#34; produces my cs_transpose in CSparse. My code on left, github on right. Not OK.\u201d</p> — Tim Davis (@Tim Davis)
        <a href="https://twitter.com/DocSparse/status/1581461734665367554">1665884834</a></blockquote></div></div></div><p><a href="https://www.eff.org/about/staff/kit-walsh" rel="noopener noreferrer" target="_blank">Kit Walsh</a>, a senior staff attorney at the <a href="https://www.eff.org/" target="_blank">Electronic Frontier Foundation</a>, argues that training Copilot on public repositories is fair use. “Fair use protects analytical uses of copyrighted work. Copilot is ingesting code and creating associations in its own neural net about what tends to follow and appear in what contexts, and that factual analysis of the underlying works is the kind of fair use that cases involving video-game consoles, search engines, and APIs have supported.”<br/></p><p>
	But when it comes to generated code, Walsh says it boils down to “how much [Copilot] is reproducing from any given element of the training data” and if it encompasses creative expression that is copyrightable. “If so, there could be infringement happening,” she says.
</p><p>
	The lawsuit against GitHub Copilot is the first of its kind to challenge generative AI. “It’s setting a legal precedent that has implications for other generative tools,” Walsh says. “It’s the type of work that if a person authored [it, they] could qualify for copyright protection, and it could embody someone else’s copyrighted work, like snippets of code.”
</p><p>
	“If I as an engineer would like to use Copilot, I will need to be able to restrict what it provides me to code that’s attributed to the license.”</p><p>
	For <a href="https://www.stellabiderman.com/" target="_blank">Stella Biderman</a>, an AI researcher at <a href="https://www.boozallen.com/" rel="noopener noreferrer" target="_blank">Booz Allen Hamilton</a> and <a href="https://www.eleuther.ai/" rel="noopener noreferrer" target="_blank">EleutherAI</a>, the lawsuit is a welcome development. “It’s going to, I hope, provide clarity and guidance as to what is actually legal, which is one of the big issues for those working on open-source AI,” she says. “I very much hope that what comes out of this lawsuit will be something I can rely on when making decisions about training models in the future.”
</p><p>
	The open-source community seems divided on the lawsuit and GitHub Copilot itself. For instance, the <a href="https://sfconservancy.org/blog/2022/jun/30/give-up-github-launch/" rel="noopener noreferrer" target="_blank">Software Freedom Conservancy has been vocal about its concerns with Copilot</a>—even calling for a boycott of GitHub—but is <a href="https://sfconservancy.org/news/2022/nov/04/class-action-lawsuit-filing-copilot/" rel="noopener noreferrer" target="_blank">cautious about joining the class-action lawsuit</a>. Kimmich says they know of open-source developers taking an ethical stance in choosing not to use Copilot, but also others who are enjoying it: “They’re learning while developing and executing code on the fly.”
</p><p>
	Kimmich is on a waitlist for Copilot and recognizes the benefits it offers developers. “The neural network behind it is using more than just code to help you—it’s providing much more contextual information,” they said. “It means I as a developer now have an extended intelligence, which is giving me a contextualized recommendation. I think that’s excellent. It’s the most powerful generative intelligence that we’ve had so far for this application.”
</p><p>
	Yet unless the open-source licensing issue is solved, Kimmich envisions using GitHub Copilot only for pet projects and exploring new packages. “It stops short of production code because of the licensing issue,” they said. “If I as an engineer would like to use Copilot, I will need to be able to restrict what it provides me to code that’s attributed to the license, or have a license which states that it was codeveloped. If I can’t locate the provenance of the original licenses or the original intellectual property, then I need to be able to know if I want to avoid it.”
</p><p>Another solution would be for GitHub Copilot to modify its AI model so that it traces attribution and gives credit to the original authors of the code, adding the associated copyright notices and license terms in the process, which Biderman says is technologically feasible. “The position that OpenAI and Microsoft seem to have taken is that it is unduly onerous on them to filter by license when other models successfully do it.” She points to academic models such as <a href="https://github.com/dpfried/incoder" rel="noopener noreferrer" target="_blank">InCoder</a> as an example, which is <a href="https://www.researchgate.net/publication/359937857_InCoder_A_Generative_Model_for_Code_Infilling_and_Synthesis" rel="noopener noreferrer" target="_blank">trained on code that it has a license for</a>. “There are other options and other models that are both more ethical and more likely to be legal,” Biderman says.</p><p><em>This article appears in the January 2023 print issue as “Do You Own the Code AI Helps You Create?.”</em></p></div></div></div>
  </body>
</html>
