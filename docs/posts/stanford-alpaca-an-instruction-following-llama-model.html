<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/tatsu-lab/stanford_alpaca">Original</a>
    <h1>Stanford Alpaca: An Instruction-following LLaMA model</h1>
    
    <div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text"><p width="100%" dir="auto">
<a href="https://crfm.stanford.edu/alpaca/" rel="nofollow"><img src="https://github.com/tatsu-lab/stanford_alpaca/raw/main/assets/logo.png" alt="Stanford-Alpaca"/></a>
</p>

<p dir="auto"><a href="https://github.com/tatsu-lab/stanford_alpaca/blob/main/LICENSE"><img src="https://camo.githubusercontent.com/b0cf55f6e9e9b09db260a68b5fce208098d724d440fb8b1c3ca8b3c7fb2d7cd7/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4c6963656e73652d4170616368655f322e302d677265656e2e737667" alt="License" data-canonical-src="https://img.shields.io/badge/License-Apache_2.0-green.svg"/></a>
<a href="https://www.python.org/downloads/release/python-380/" rel="nofollow"><img src="https://camo.githubusercontent.com/c5bfbde247cd10e93ff50a518b0f5e441a6e9959495f6bf0f1a1913d2b1b7a8d/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f707974686f6e2d332e382b2d626c75652e737667" alt="Python 3.8+" data-canonical-src="https://img.shields.io/badge/python-3.8+-blue.svg"/></a>
<a href="https://github.com/psf/black"><img src="https://camo.githubusercontent.com/d91ed7ac7abbd5a6102cbe988dd8e9ac21bde0a73d97be7603b891ad08ce3479/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f64652532307374796c652d626c61636b2d3030303030302e737667" alt="Code style: black" data-canonical-src="https://img.shields.io/badge/code%20style-black-000000.svg"/></a></p>
<p dir="auto">This is the repo for the Stanford Alpaca project, which aims to build and share an instruction-following LLaMA model. The repo contains:</p>
<ul dir="auto">
<li>A <a href="https://crfm.stanford.edu/alpaca/" rel="nofollow"><strong>web demo</strong></a> to interact with our Alpaca model</li>
<li>The <a href="#data-release">52K data</a> used for fine-tuning the model</li>
<li>The code for <a href="#data-generation-process">generating the data</a></li>
</ul>
<h2 tabindex="-1" dir="auto"><a id="user-content-overview" aria-hidden="true" href="#overview"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Overview</h2>
<p dir="auto">The current Alpaca model is fine-tuned from a 7B LLaMA model [1] on 52K instruction-following data generated by the techniques in the Self-Instruct [2] paper, with some modifications that we discuss in the next section.
In a preliminary human evaluation, we found that the Alpaca 7B model behaves similarly to the <code>text-davinci-003</code> model on the Self-Instruct instruction-following evaluation suite [2].</p>
<p dir="auto">Alpaca is still under development, and there are many limitations that have to be addressed.
Importantly, we have not yet fine-tuned the Alpaca model to be safe and harmless.
We thus encourage users to be cautious when interacting with Alpaca, and to report any concerning behavior to help improve the safety and ethical considerations of the model.</p>
<p dir="auto">Our initial release contains the data generation procedure, dataset, and training recipe. We intend to release the model weights if we are given permission to do so by the creators of LLaMA. For now, we have chosen to host a live demo to help readers better understand the capabilities and limits of Alpaca, as well as a way to help us better evaluate Alpaca&#39;s performance on a broader audience.</p>
<p dir="auto"><strong>Please read our release <a href="https://crfm.stanford.edu/2023/03/13/alpaca.html" rel="nofollow">blog post</a> for more details about the model, our discussion of the potential harm and limitations of Alpaca models, and our thought process of an open-source release.</strong></p>
<p dir="auto">[1]: LLaMA: Open and Efficient Foundation Language Models. Hugo Touvron, Thibaut Lavril, Gautier Izacard, Xavier Martinet, Marie-Anne Lachaux, Timothée Lacroix, Baptiste Rozière, Naman Goyal, Eric Hambro, Faisal Azhar, Aurelien Rodriguez, Armand Joulin, Edouard Grave, Guillaume Lample. <a href="https://arxiv.org/abs/2302.13971v1" rel="nofollow">https://arxiv.org/abs/2302.13971v1</a></p>
<p dir="auto">[2]: Self-Instruct: Aligning Language Model with Self Generated Instructions. Yizhong Wang, Yeganeh Kordi, Swaroop Mishra, Alisa Liu, Noah A. Smith, Daniel Khashabi, Hannaneh Hajishirzi. <a href="https://arxiv.org/abs/2212.10560" rel="nofollow">https://arxiv.org/abs/2212.10560</a></p>
<h2 tabindex="-1" dir="auto"><a id="user-content-data-release" aria-hidden="true" href="#data-release"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Data Release</h2>
<p dir="auto"><a href="https://github.com/tatsu-lab/stanford_alpaca/blob/main/alpaca_data.json"><code>alpaca_data.json</code></a> contains 52K instruction-following data we used for fine-tuning the Alpaca model.
This JSON file is a list of dictionaries, each dictionary contains the following fields:</p>
<ul dir="auto">
<li><code>instruction</code>: <code>str</code>, describes the task the model should perform. Each of the 52K instructions is unique.</li>
<li><code>input</code>: <code>str</code>, optional context or input for the task. For example, when the instruction is &#34;Summarize the following article&#34;, the input is the article. Around 40% of the examples have an input.</li>
<li><code>output</code>: <code>str</code>, the answer to the instruction as generated by <code>text-davinci-003</code>.</li>
</ul>
<p dir="auto">We used the following prompts for fine-tuning the Alpaca model:</p>
<ul dir="auto">
<li>for examples with a non-empty input field:</li>
</ul>
<div data-snippet-clipboard-copy-content="Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.

### Instruction:
{instruction}

### Input:
{input}

### Response:"><pre><code>Below is an instruction that describes a task, paired with an input that provides further context. Write a response that appropriately completes the request.

### Instruction:
{instruction}

### Input:
{input}

### Response:
</code></pre></div>
<ul dir="auto">
<li>for examples with an empty input field:</li>
</ul>
<div data-snippet-clipboard-copy-content="Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
{instruction}

### Response:"><pre><code>Below is an instruction that describes a task. Write a response that appropriately completes the request.

### Instruction:
{instruction}

### Response:
</code></pre></div>
<h2 tabindex="-1" dir="auto"><a id="user-content-data-generation-process" aria-hidden="true" href="#data-generation-process"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Data Generation Process</h2>
<details>
<summary> <strong> Running the code </strong> </summary>
<ol dir="auto">
<li>Set environment variables <code>OPENAI_API_KEY</code> to your OpenAI API key.</li>
<li>Install the dependencies with <code>pip install -r requirements.txt</code>.</li>
<li>Run <code>python -m generate_instruction generate_instruction_following_data</code> to generate the data.</li>
</ol>
</details>
<p dir="auto">We built on the data generation pipeline from <a href="https://github.com/yizhongw/self-instruct">self-instruct</a> and made the following modifications:</p>
<ul dir="auto">
<li>We used <code>text-davinci-003</code> to generate the instruction data instead of <code>davinci</code>.</li>
<li>We wrote a new prompt (<code>prompt.txt</code>) that explicitly gave the requirement of instruction generation to <code>text-davinci-003</code>.</li>
<li>We adopted much more aggressive batch decoding, i.e., generating 20 instructions at once, which significantly reduced the cost of data generation.</li>
<li>We simplified the data generation pipeline by discarding the difference between classification and non-classification instructions.</li>
<li>We only generated a single instance for each instruction, instead of 2 to 3 instances as in [1].</li>
</ul>
<p dir="auto">This produced an instruction-following dataset with 52K examples obtained at a much lower cost (less than $500).
In a preliminary study, we also find our 52K generated data to be much more diverse than the data released by <a href="https://github.com/yizhongw/self-instruct/blob/main/data/seed_tasks.jsonl">self-instruct</a>.
We plot the below figure (in the style of Figure 2 in the <a href="https://arxiv.org/abs/2212.10560" rel="nofollow">self-instruct paper</a> to demonstrate the diversity of our data.
The inner circle of the plot represents the root verb of the instructions, and the outer circle represents the direct objects.</p>
<p dir="auto"><a href="https://github.com/tatsu-lab/stanford_alpaca/blob/main/assets/parse_analysis.png"><img src="https://github.com/tatsu-lab/stanford_alpaca/raw/main/assets/parse_analysis.png" width="750"/></a></p>
<h2 tabindex="-1" dir="auto"><a id="user-content-fine-tuning" aria-hidden="true" href="#fine-tuning"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Fine-tuning</h2>
<p dir="auto">We fine-tune our model using standard huggingface training code with the following hyperparameters:</p>
<table>
<thead>
<tr>
<th>Hyperparameter</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>Batch size</td>
<td>128</td>
</tr>
<tr>
<td>Learning rate</td>
<td>2e-5</td>
</tr>
<tr>
<td>Epochs</td>
<td>3</td>
</tr>
<tr>
<td>Max length</td>
<td>512</td>
</tr>
<tr>
<td>Weight decay</td>
<td>1</td>
</tr>
</tbody>
</table>
<p dir="auto">We are waiting for huggingface to officially support the llama models (i.e. this <a href="https://github.com/huggingface/transformers/pull/21955" data-hovercard-type="pull_request" data-hovercard-url="/huggingface/transformers/pull/21955/hovercard">PR</a> to be merged) before we release a stable version of the finetuning code.</p>
<h3 tabindex="-1" dir="auto"><a id="user-content-authors" aria-hidden="true" href="#authors"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Authors</h3>
<p dir="auto">All grad students below contributed equally and the order is determined by random draw.</p>
<ul dir="auto">
<li><a href="https://www.rohantaori.com/" rel="nofollow">Rohan Taori</a></li>
<li><a href="https://ishaan.io/" rel="nofollow">Ishaan Gulrajani</a></li>
<li><a href="https://tiiiger.github.io/" rel="nofollow">Tianyi Zhang</a></li>
<li><a href="https://yanndubs.github.io/" rel="nofollow">Yann Dubois</a></li>
<li><a href="https://www.lxuechen.com/" rel="nofollow">Xuechen Li</a></li>
</ul>
<p dir="auto">All advised by <a href="https://thashim.github.io/" rel="nofollow">Tatsunori B. Hashimoto</a>. Yann is also advised by <a href="https://cs.stanford.edu/~pliang/" rel="nofollow">Percy Liang</a> and Xuechen is also advised by <a href="https://guestrin.su.domains/" rel="nofollow">Carlos Guestrin</a>.</p>
<h3 tabindex="-1" dir="auto"><a id="user-content-citation" aria-hidden="true" href="#citation"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Citation</h3>
<p dir="auto">Please cite the repo if you use the data or code in this repo.</p>
<div data-snippet-clipboard-copy-content="@misc{alpaca,
  author = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {Stanford Alpaca: An Instruction-following LLaMA model},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tatsu-lab/stanford_alpaca}},
}"><pre><code>@misc{alpaca,
  author = {Rohan Taori and Ishaan Gulrajani and Tianyi Zhang and Yann Dubois and Xuechen Li and Carlos Guestrin and Percy Liang and Tatsunori B. Hashimoto },
  title = {Stanford Alpaca: An Instruction-following LLaMA model},
  year = {2023},
  publisher = {GitHub},
  journal = {GitHub repository},
  howpublished = {\url{https://github.com/tatsu-lab/stanford_alpaca}},
}
</code></pre></div>
<p dir="auto">Naturally, you should also cite the original LLaMA paper [1] and the Self-Instruct paper [2].</p>
<h3 tabindex="-1" dir="auto"><a id="user-content-acknowledgements" aria-hidden="true" href="#acknowledgements"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Acknowledgements</h3>
<p dir="auto">We thank Yizhong Wang for his help in explaining the data generation pipeline in Self-Instruct and providing the code for the parse analysis plot.</p>
</article>
          </div></div>
  </body>
</html>
