<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://mistral.ai/news/devstral-2-vibe-cli">Original</a>
    <h1>Mistral releases Devstral2 and Mistral Vibe CLI</h1>
    
    <div id="readability-page-1" class="page"><div><p dir="ltr">Today, we&#39;re releasing Devstral 2—our next-generation coding model family available in two sizes: Devstral 2 (123B) and Devstral Small 2 (24B). Devstral 2 ships under a modified MIT license, while Devstral Small 2 uses Apache 2.0. Both are open-source and permissively licensed to accelerate distributed intelligence.</p>
<p dir="ltr">Devstral 2 is currently free to use via <a href="https://console.mistral.ai/">our API</a>.</p>
<p dir="ltr">We are also introducing Mistral Vibe, a native CLI built for Devstral that enables end-to-end code automation.</p>
<h2 dir="ltr">Highlights.</h2>
<ol>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Devstral 2: SOTA open model for code agents with a fraction of the parameters of its competitors and achieving 72.2% on SWE-bench Verified.</p>
</li>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Up to 7x more cost-efficient than Claude Sonnet at real-world tasks.</p>
</li>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Mistral Vibe CLI: Native, open-source agent in your terminal solving software engineering tasks autonomously.</p>
</li>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Devstral Small 2: 24B parameter model available via API or deployable locally on consumer hardware.</p>
</li>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Compatible with on-prem deployment and custom fine-tuning.</p>
</li>
</ol>
<h2 dir="ltr">Devstral: the next generation of SOTA coding.</h2>
<p dir="ltr">Devstral 2 is a 123B-parameter dense transformer supporting a 256K context window. It reaches 72.2% on SWE-bench Verified—establishing it as one of the best open-weight models while remaining highly cost efficient. Released under a modified MIT license, Devstral sets the open state-of-the-art for code agents.</p>
<p dir="ltr">Devstral Small 2 scores 68.0% on SWE-bench Verified, and places firmly among models up to five times its size while being capable of running locally on consumer hardware.</p>
<p><img src="https://cms.mistral.ai/assets/d295e716-acbe-4d05-8764-861ca2f2a2eb.png?width=1686&amp;height=1093" alt="Devstral   Swe Bench Verified  Open Weights Vs Proprietary Models (dark) (1)"/></p>
<p><img src="https://cms.mistral.ai/assets/9c36eef1-2b4c-4fb8-8ef0-d531116ec53a.png?width=1686&amp;height=1093" alt="Devstral   Swe Bench Verified  Open Weights Vs Proprietary Models (light) (1)"/></p>
<p dir="ltr">Devstral 2 (123B) and Devstral Small 2 (24B) are 5x and 28x smaller than DeepSeek V3.2, and 8x and 41x smaller than Kimi K2—proving that compact models can match or exceed the performance of much larger competitors. Their reduced size makes deployment practical on limited hardware, lowering barriers for developers, small businesses, and hobbyists.hardware.</p>
<p><img src="https://cms.mistral.ai/assets/3c7a5ea7-d83f-4dc4-9129-965c321bb379.png?width=1686&amp;height=969" alt="Devstral   Swe Bench Verified Regular Performance X Modelsize (dark)"/></p>
<p><img src="https://cms.mistral.ai/assets/49e0d71c-436c-4334-9fff-fa68c9f60380.png?width=1686&amp;height=969" alt="Devstral   Swe Bench Verified Regular Performance X Modelsize (light)"/></p>
<h3 dir="ltr">Built for production-grade workflows.</h3>
<p dir="ltr">Devstral 2 supports exploring codebases and orchestrating changes across multiple files while maintaining architecture-level context. It tracks framework dependencies, detects failures, and retries with corrections—solving challenges like bug fixing and modernizing legacy systems.</p>
<p dir="ltr">The model can be fine-tuned to prioritize specific languages or optimize for large enterprise codebases.</p>
<p dir="ltr">We evaluated Devstral 2 against DeepSeek V3.2 and Claude Sonnet 4.5 using human evaluations conducted by an independent annotation provider, with tasks scaffolded through Cline. Devstral 2 shows a clear advantage over DeepSeek V3.2, with a 42.8% win rate versus 28.6% loss rate. However, Claude Sonnet 4.5 remains significantly preferred, indicating a gap with closed-source models persists.</p>
<p dir="ltr"><img src="https://cms.mistral.ai/assets/542495d8-31d9-4053-a426-df9dccc58ef1.png?width=1371&amp;height=670" alt="Devstral   Model Performance Comparison (dark) (1)"/> <img src="https://cms.mistral.ai/assets/48b2b0fc-f8d8-44da-a3a2-4961aad2f10e.png?width=1371&amp;height=670" alt="Devstral   Model Performance Comparison (light) (1)"/></p>
<p dir="ltr">“Devstral 2 is at the frontier of open-source coding models. In Cline, it delivers a tool-calling success rate on par with the best closed models; it&#39;s a remarkably smooth driver. This is a massive contribution to the open-source ecosystem.” — Cline.</p>
<p dir="ltr">“Devstral 2 was one of our most successful stealth launches yet, surpassing 17B tokens in the first 24 hours. Mistral AI is moving at Kilo Speed with a cost-efficient model that truly works at scale.” — Kilo Code.</p>
<p dir="ltr">Devstral Small 2, a 24B-parameter model with the same 256K context window and released under Apache 2.0, brings these capabilities to a compact, locally deployable form. Its size enables fast inference, tight feedback loops, and easy customization—with fully private, on-device runtime. It also supports image inputs, and can power multimodal agents. </p>
<h2 dir="ltr">Mistral Vibe CLI.</h2>
<p dir="ltr">Mistral Vibe CLI is an open-source command-line coding assistant powered by Devstral. It explores, modifies, and executes changes across your codebase using natural language—in your terminal or integrated into your preferred IDE via the Agent Communication Protocol. It is released under the Apache 2.0 license.</p>
<p dir="ltr">Vibe CLI provides an interactive chat interface with tools for file manipulation, code searching, version control, and command execution. Key features:</p>
<ul>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Project-aware context: Automatically scans your file structure and Git status to provide relevant context</p>
</li>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Smart references: Reference files with @ autocomplete, execute shell commands with !, and use slash commands for configuration changes</p>
</li>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Multi-file orchestration: Understands your entire codebase—not just the file you&#39;re editing—enabling architecture-level reasoning that can halve your PR cycle time</p>
</li>
<li dir="ltr" aria-level="1">
<p dir="ltr" role="presentation">Persistent history, autocompletion, and customizable themes.</p>
</li>
</ul>
<p dir="ltr">You can run Vibe CLI programmatically for scripting, toggle auto-approval for tool execution, configure local models and providers through a simple config.toml, and control tool permissions to match your workflow.</p>
<h2 dir="ltr">Get started.</h2>
<p dir="ltr">Devstral 2 is currently offered free via <a href="http://console.mistral.ai">our API</a>. After the free period, the API pricing will be $0.40/$2.00 per million tokens (input/output) for Devstral 2 and $0.10/$0.30 for Devstral Small 2.</p>
<p dir="ltr">We’ve partnered with leading, open agent tools <a href="https://kilo.ai/">Kilo Code</a> and <a href="https://cline.bot/">Cline</a> to bring Devstral 2 to where you already build.</p>
<p dir="ltr">Mistral Vibe CLI is available as an extension in <a href="https://zed.dev/extensions">Zed</a>, so you can use it directly inside your IDE.</p>
<h3 dir="ltr">Recommended deployment for Devstral.</h3>
<p dir="ltr">Devstral 2 is optimized for data center GPUs and requires a minimum of 4 H100-class GPUs for deployment. You can try it today on <a href="http://build.nvidia.com">build.nvidia.com</a>. Devstral Small 2 is built for single-GPU operation and runs across a broad range of NVIDIA systems, including DGX Spark and GeForce RTX. NVIDIA NIM support will be available soon.</p>
<p dir="ltr">Devstral Small runs on consumer-grade GPUs as well as CPU-only configurations with no dedicated GPU required.</p>
<p dir="ltr">For optimal performance, we recommend a temperature of 0.2 and following the best practices defined for <a href="https://github.com/mistralai/mistral-vibe/blob/main/README.md">Mistral Vibe CLI</a>.</p>
<h2 dir="ltr">Contact us.</h2>
<p dir="ltr">We’re excited to see what you will build with Devstral 2, Devstral Small 2, and Vibe CLI!</p>
<p dir="ltr">Share your projects, questions, or discoveries with us on <a href="https://x.com/mistralai">X/Twitter</a>, <a href="https://discord.com/invite/mistralai">Discord</a>, or <a href="https://github.com/mistralai">GitHub</a>.</p>
<h2 dir="ltr">We’re hiring!</h2>
<p dir="ltr">If you’re interested in shaping open-source research and building world-class interfaces that bring truly open, frontier AI to users, we welcome you to <a href="https://mistral.ai/careers">apply to join our team</a>.</p></div></div>
  </body>
</html>
