<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://journal.hexmos.com/gpu-survival-toolkit/">Original</a>
    <h1>GPU Survival Toolkit for the AI age</h1>
    
    <div id="readability-page-1" class="page"><div id="site-main">
<article>

    <header>

        <p><span><svg width="16" height="17" viewBox="0 0 16 17" fill="none" xmlns="http://www.w3.org/2000/svg">
    <path d="M4.49365 4.58752C3.53115 6.03752 2.74365 7.70002 2.74365 9.25002C2.74365 10.6424 3.29678 11.9778 4.28134 12.9623C5.26591 13.9469 6.60127 14.5 7.99365 14.5C9.38604 14.5 10.7214 13.9469 11.706 12.9623C12.6905 11.9778 13.2437 10.6424 13.2437 9.25002C13.2437 6.00002 10.9937 3.50002 9.16865 1.68127L6.99365 6.25002L4.49365 4.58752Z" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"></path>
</svg> Featured</span>
        </p>

        


        <div>
        <section>

            <ul>
                <li>
                    <a href="https://olu.online/author/rijul/">
                        <img src="https://olu.online/content/images/size/w100/2023/08/3a30bb804e1845504626b40d9fb136d2.jpeg" alt="Rijul Rajesh"/>
                    </a>
                </li>
            </ul>

            <div>
                
                <p><time datetime="2023-11-12">Nov 12, 2023</time>
                        <span><span>•</span> 13 min read</span>
                </p>
            </div>

        </section>
        </div>

            <figure>
                <img srcset="https://journal-wa6509js.s3.ap-south-1.amazonaws.com/a230a3ffafd791a0973337dbab3db132061e9d02787646049eb519aae1cb0f72.png 300w,
                            https://journal-wa6509js.s3.ap-south-1.amazonaws.com/a230a3ffafd791a0973337dbab3db132061e9d02787646049eb519aae1cb0f72.png 600w,
                            https://journal-wa6509js.s3.ap-south-1.amazonaws.com/a230a3ffafd791a0973337dbab3db132061e9d02787646049eb519aae1cb0f72.png 1000w,
                            https://journal-wa6509js.s3.ap-south-1.amazonaws.com/a230a3ffafd791a0973337dbab3db132061e9d02787646049eb519aae1cb0f72.png 2000w" sizes="(min-width: 1400px) 1400px, 92vw" src="https://journal-wa6509js.s3.ap-south-1.amazonaws.com/a230a3ffafd791a0973337dbab3db132061e9d02787646049eb519aae1cb0f72.png" alt="GPU Survival Toolkit for the AI age: The bare minimum every developer must know"/>
            </figure>

    </header>

    <section>
        <!--kg-card-begin: html--><h3 id="why-cpu-knowledge-is-no-longer-enough">Why CPU Knowledge Is No Longer Enough</h3>

<p>In today&#39;s AI age, the majority of developers train in the CPU way. This knowledge has been part of our academics as well, so it&#39;s obvious to think and problem-solve in a <strong>CPU-oriented way</strong>.</p>

<p>However, the problem with CPUs is that they rely on a <strong>sequential architecture</strong>. In today&#39;s world, where we are dependent on numerous parallel tasks, CPUs are unable to work well in these scenarios.</p>

<p>Some problems faced by developers include:</p>

<h4 id="executing-parallel-tasks">Executing Parallel Tasks</h4>

<p>CPUs traditionally operate linearly, executing one instruction at a time. This limitation stems from the fact that CPUs typically feature a few powerful cores optimized for single-threaded performance.</p>

<p>When faced with multiple tasks, a CPU allocates its resources to address each task one after the other, leading to a sequential execution of instructions. This approach becomes inefficient in scenarios where numerous tasks need simultaneous attention.</p>

<p>While we make efforts to enhance CPU performance through techniques like multi-threading, the fundamental design philosophy of CPUs prioritizes sequential execution.</p>

<h4 id="running-ai-models-efficiently">Running AI Models Efficiently</h4>

<p>AI models, employing advanced architectures like transformers, leverage parallel processing to enhance performance. Unlike older <strong>recurrent neural networks (RNNs)</strong> that operate sequentially, modern transformers such as <strong>GPT</strong> can concurrently process multiple words, increasing efficiency and capability in training. Because when we train in parallel, it will result in bigger models, and bigger models will yield better outputs.</p>

<p>The concept of parallelism extends beyond natural language processing to other domains like <strong>image recognition</strong>. For instance, <a href="https://medium.com/analytics-vidhya/concept-of-alexnet-convolutional-neural-network-6e73b4f9ee30?ref=journal.hexmos.com">AlexNet</a>, an architecture in image recognition, demonstrates the power of parallel processing by processing different parts of an image simultaneously, allowing for accurate pattern identification.</p>

<p>However, CPUs, designed with a focus on single-threaded performance, struggle to fully exploit parallel processing potential. They face difficulties efficiently distributing and executing the numerous parallel computations required for intricate AI models.</p>

<p>As a result, the development of GPUs has become prevalent to address the specific needs of parallel processing in AI applications, unlocking higher efficiency and faster computation.</p>

<h4 id="how-gpu-driven-development-solves-these-issues">How GPU Driven Development Solves These Issues</h4>

<p><strong>Massive Parallelism With GPU Cores</strong></p>

<p>Engineers design GPUs with <strong>smaller, highly specialized cores</strong> compared to the <strong>larger, more powerful cores</strong> found in CPUs. This architecture allows GPUs to execute a multitude of parallel tasks simultaneously.</p>

<p>The high number of cores in a GPU are well-suited for workloads depending on parallelism, such as graphics rendering and complex mathematical computations.</p>

<p>We will soon demonstrate how using GPU parallelism can reduce the time taken for complex tasks.</p>

<p><img alt="GPUDemo1" src="https://journal-wa6509js.s3.ap-south-1.amazonaws.com/ee0bdbd2103cbed5d0fa894432cc476065984dcd3921bb9158e608a50fe62f7b.png"/></p>

<p><strong>Parallelism Used In AI Models</strong></p>

<p>AI models, particularly those built on deep learning frameworks like <a href="https://www.tensorflow.org/?ref=journal.hexmos.com">TensorFlow</a>, exhibit a high degree of parallelism. Neural network training involves numerous matrix operations, and GPUs, with their expansive core count, excel in parallelizing these operations. TensorFlow, along with other popular deep learning frameworks, optimizes to leverage GPU power for accelerating model training and inference.</p>

<p>We will show a demo soon how to train a neural network using the power of the GPU.</p>

<p><img alt="GPUDemo1" src="https://journal-wa6509js.s3.ap-south-1.amazonaws.com/5078635f14fc266b48058cafe1f214608eecd89f0ddfebfc481df24704a7bba9.png"/></p>

<h3 id="cpus-vs-gpus-whats-the-difference">CPUs Vs GPUs: What’s the Difference?</h3>

<h4 id="cpu">CPU</h4>

<p><strong>Sequential Architecture</strong></p>

<p>Central Processing Units (CPUs) are designed with a focus on sequential processing. They excel at executing a single set of instructions linearly.</p>

<p>CPUs are optimized for tasks that require high single-threaded performance, such as</p>

<ul>
<li>General-purpose computing</li>
<li>System operations</li>
<li>Handling complex algorithms that involve conditional branching</li>
</ul>

<p><strong>Limited Cores For Parallel Tasks</strong></p>

<p>CPUs feature a smaller number of cores, often in the range of <strong>2-16</strong> cores in consumer-grade processors. Each core is capable of handling its own set of instructions independently.</p>

<h4 id="gpu">GPU</h4>

<p><strong>Parallelized Architecture</strong></p>

<p>Graphics Processing Units (GPUs) are designed with a parallel architecture, making them highly efficient for parallel processing tasks.</p>

<p>This is beneficial for</p>

<ul>
<li>Rendering graphics</li>
<li>Performing complex mathematical calculations</li>
<li>Running parallelizable algorithms</li>
</ul>

<p>GPUs handle multiple tasks simultaneously by breaking them into smaller, parallel sub-tasks.</p>

<p><strong>Thousands Of Cores For Parallel Tasks</strong></p>

<p>Unlike CPUs, GPUs boast a significantly larger number of cores, often numbering in the thousands. These cores are organized into streaming multiprocessors (SMs) or similar structures.</p>

<p>The abundance of cores allows GPUs to process a massive amount of data concurrently, making them well-suited for parallelisable tasks, such as image and video processing, deep learning, and scientific simulations.</p>

<h3 id="aws-gpu-instances-a-beginners-guide">AWS GPU Instances: A Beginner&#39;s Guide</h3>

<p>Amazon Web Services (AWS) offers a variety of GPU instances used for things like machine learning.</p>

<p>Here are the different types of AWS GPU instances and their use cases:</p>

<p><strong>General-Purpose Gpu Instances</strong></p>

<ul>
<li>
<p><a href="https://aws.amazon.com/ec2/instance-types/p3/?ref=journal.hexmos.com">P3</a> and <a href="https://aws.amazon.com/ec2/instance-types/p4/?ref=journal.hexmos.com">P4</a> instances serve as versatile general-purpose GPU instances, well-suited for a broad spectrum of workloads.</p>
</li>
<li>
<p>These include machine learning training and inference, image processing, and video encoding. Their balanced capabilities make them a solid choice for diverse computational tasks.</p>
</li>
<li>
<p><strong>Pricing:</strong> The p3.2xlarge instance costs <strong>$3.06</strong> per hour.</p>
</li>
<li>This provides 1 <a href="https://www.nvidia.com/en-gb/data-center/tesla-v100/?ref=journal.hexmos.com">NVIDIA Tesla V100 GPU</a> of 16 GB GPU memory</li>
</ul>

<p><strong>Inference-optimized GPU instances</strong></p>

<ul>
<li>
<p>Inference is the process of running live data through a trained AI model to make a prediction or solve a task.</p>
</li>
<li>
<p><a href="https://aws.amazon.com/ec2/instance-types/p5/?ref=journal.hexmos.com">P5</a> and <a href="https://aws.amazon.com/ec2/instance-types/inf1/?ref=journal.hexmos.com">Inf1</a> instances specifically cater to machine learning inference, excelling in scenarios where low latency and cost efficiency are essential.</p>
</li>
<li>
<p><strong>Pricing:</strong> the p5.48xlarge instance costs <strong>$98.32</strong> per hour.</p>
</li>
<li>This provides 8 <a href="https://www.nvidia.com/en-in/data-center/h100/?ref=journal.hexmos.com">NVIDIA H100 GPUs</a> of 80 GB memory each, totalling upto 640 GB Video Memory.</li>
</ul>

<p><strong>Graphics-optimized GPU instances</strong></p>

<ul>
<li>
<p><a href="https://aws.amazon.com/ec2/instance-types/g4/?ref=journal.hexmos.com">G4 instances</a> instances are engineered to handle graphics-intensive tasks.</p>
</li>
<li>
<p>A video game developer might use a G4 instance to render 3D graphics for a video game.</p>
</li>
<li><strong>Pricing:</strong> g4dn.xlarge costs <strong>$0.526</strong> to run per hour.</li>
<li>Uses 1 <a href="https://www.nvidia.com/en-in/data-center/tesla-t4/?ref=journal.hexmos.com">NVIDIA T4 GPU</a> of 16 GB Memory.</li>
</ul>

<p><strong>Managed GPU Instances</strong></p>

<ul>
<li>
<p><a href="https://aws.amazon.com/sagemaker/?ref=journal.hexmos.com">Amazon SageMaker</a> is a managed service for machine learning. It provides access to a variety of GPU-powered instances, including P3, P4, and P5 instances.</p>
</li>
<li>
<p>SageMaker is a good choice for organizations that wants to begin machine learning easily without having to manage the underlying infrastructure.</p>
</li>
<li>
<p><a href="https://aws.amazon.com/sagemaker/pricing/?ref=journal.hexmos.com">Pricing of Amazon Sagemaker</a></p>
</li>
</ul>

<h3 id="using-nvidias-cuda-for-gpu-driven-development">Using Nvidia&#39;s CUDA for GPU-Driven Development</h3>

<h4 id="what-is-cuda">What Is Cuda?</h4>

<p><strong>CUDA</strong> is a parallel computing platform and programming model developed by NVIDIA, enabling developers to accelerate their applications by harnessing the power of GPU accelerators.</p>

<p>The Practical examples in the demo will use CUDA.</p>

<h4 id="how-to-setup-cuda-on-your-machine">How to Setup Cuda on Your Machine</h4>

<p>To setup CUDA on your machine you can follow these steps.</p>

<ul>
<li>Download <a href="https://developer.nvidia.com/cuda-downloads?ref=journal.hexmos.com">CUDA</a></li>
<li>From the above link download the base installer as well as the driver installer</li>
<li>Go to .bashrc in home folder</li>
<li>
<p>Add the following lines below</p>
</li>
<li>
<p><code>export PATH=&#34;/usr/local/cuda-12.3/bin:$PATH&#34;</code></p>
</li>
<li>
<p><code>export LD_LIBRARY_PATH=&#34;/usr/local/cuda-12.3/lib64:$LD_LIBRARY_PATH&#34;</code></p>
</li>
<li>
<p>Execute the following commands</p>
</li>
<li><code>sudo apt-get install cuda-toolkit</code></li>
<li>
<p><code>sudo apt-get install nvidia-gds</code></p>
</li>
<li>
<p>Reboot the system for the changes to take effect</p>
</li>
</ul>

<h4 id="basic-commands-to-use">Basic Commands to Use</h4>

<p>Once you have CUDA installed, here are some helpful commands.</p>

<p><code>lspci | grep VGA</code></p>

<p>The purpose of this command is to identify and list the GPUs in your system.
<img alt="Alt text" src="https://journal-wa6509js.s3.ap-south-1.amazonaws.com/ea108a4de53720d8e4de22247f92b43481a000cfe41026826e52f4af020b9c0f.png"/></p>

<p><code>nvidia-smi</code></p>

<p>It stands for &#34;NVIDIA System Management Interface&#34;
It provides detailed information about the NVIDIA GPUs in your system, including utilization, temperature, memory usage and more.</p>

<p><img alt="Alt text" src="https://journal-wa6509js.s3.ap-south-1.amazonaws.com/b467adbefdfe4fced1552ca63134994c2924dc648955adb585c80d1a6356f10f.png"/></p>

<p><code>sudo lshw -C display</code></p>

<p>The purpose is to provide detailed information about the display controllers in your system, including graphics cards.
<img alt="Alt text" src="https://journal-wa6509js.s3.ap-south-1.amazonaws.com/0af5ca02e576f5da48a561ebffb4bd20e4051899cb1b1e69caca78aeff58cff7.png"/></p>

<p><code>inxi -G</code></p>

<p>This command provides information about the graphics subsystem, including details about the GPU and the display.
<img alt="Alt text" src="https://journal-wa6509js.s3.ap-south-1.amazonaws.com/8352bf05d3be3b8085e837de0f69f244ab6c34041c6b462cf78513fcae6373c0.png"/></p>

<p><code>sudo hwinfo --gfxcard</code></p>

<p>Its purpose is to obtain detailed information about the graphics cards in your system.</p>

<p><img alt="Alt text" src="https://journal-wa6509js.s3.ap-south-1.amazonaws.com/70fa1b931593c213a1a949dbc700d47cca2e933cee331d63e03e0806d6327baa.png"/></p>

<h3 id="get-started-with-the-cuda-framework">Get Started with the Cuda Framework</h3>

<p>As we have installed the CUDA Framework, let&#39;s start executing operations that showcases its functionality.</p>

<h4 id="array-addition-problem">Array Addition Problem</h4>

<p>A suitable problem to demonstrate the parallelization of GPUs is the <strong>Array addition problem</strong>.</p>

<p>Consider the following arrays:</p>

<ul>
<li>
<p>Array A = [1,2,3,4,5,6]</p>
</li>
<li>
<p>Array B = [7,8,9,10,11,12]</p>
</li>
<li>
<p>We need to store the sum of each element and store it in Array C.</p>
</li>
<li>
<p>Like C = [1+7,2+8,3+9,4+10,5+11,6+12] = [8,10,12,14,16,18]</p>
</li>
<li>
<p>If the CPU is to execute such operation, it would be executing the operation like the below code.</p>
</li>
</ul>

<div><pre><span></span><span>#include</span><span> </span><span>&lt;stdio.h&gt;</span>
<span>int</span><span> </span><span>a</span><span>[]</span><span> </span><span>=</span><span> </span><span>{</span><span>1</span><span>,</span><span>2</span><span>,</span><span>3</span><span>,</span><span>4</span><span>,</span><span>5</span><span>,</span><span>6</span><span>};</span>
<span>int</span><span> </span><span>b</span><span>[]</span><span> </span><span>=</span><span> </span><span>{</span><span>7</span><span>,</span><span>8</span><span>,</span><span>9</span><span>,</span><span>10</span><span>,</span><span>11</span><span>,</span><span>12</span><span>};</span>
<span>int</span><span> </span><span>c</span><span>[</span><span>6</span><span>];</span>

<span>int</span><span> </span><span>main</span><span>()</span><span> </span><span>{</span>
<span>    </span><span>int</span><span> </span><span>N</span><span> </span><span>=</span><span> </span><span>6</span><span>;</span><span>  </span><span>// Number of elements</span>

<span>    </span><span>for</span><span> </span><span>(</span><span>int</span><span> </span><span>i</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span><span> </span><span>i</span><span> </span><span>&lt;</span><span> </span><span>N</span><span>;</span><span> </span><span>i</span><span>++</span><span>)</span><span> </span><span>{</span>
<span>        </span><span>c</span><span>[</span><span>i</span><span>]</span><span> </span><span>=</span><span> </span><span>a</span><span>[</span><span>i</span><span>]</span><span> </span><span>+</span><span> </span><span>b</span><span>[</span><span>i</span><span>];</span>
<span>    </span><span>}</span>

<span>    </span><span>for</span><span> </span><span>(</span><span>int</span><span> </span><span>i</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span><span> </span><span>i</span><span> </span><span>&lt;</span><span> </span><span>N</span><span>;</span><span> </span><span>i</span><span>++</span><span>)</span><span> </span><span>{</span>
<span>        </span><span>printf</span><span>(</span><span>&#34;c[%d] = %d&#34;</span><span>,</span><span> </span><span>i</span><span>,</span><span> </span><span>c</span><span>[</span><span>i</span><span>]);</span>
<span>    </span><span>}</span>

<span>    </span><span>return</span><span> </span><span>0</span><span>;</span>
<span>}</span>
</pre></div>

<p>The previous method involves traversing the array elements one by one and performing the additions sequentially. However, when dealing with a <strong>substantial volume of numbers</strong>, this approach becomes sluggish due to its <strong>sequential nature</strong>.</p>

<p>To address this limitation, GPUs offer a solution by <strong>parallelizing the addition process</strong>. Unlike CPUs, which execute operations one after the other, GPUs can concurrently perform multiple additions.</p>

<p>For instance, the operations 1+7, 2+8, 3+9, 4+10, 5+11 and 6+12 can be executed simultaneously through parallelization with the assistance of a GPU.</p>

<p>Utilizing CUDA, the code to achieve this parallelized addition is as follows:</p>

<p>We will use a kernel file (.cu) for the demonstration.</p>

<p>Let&#39;s go through the code one by one.</p>

<div><pre><span></span><span>__global__</span><span> </span><span>void</span><span> </span><span>vectorAdd</span><span>(</span><span>int</span><span>*</span><span> </span><span>a</span><span>,</span><span> </span><span>int</span><span>*</span><span> </span><span>b</span><span>,</span><span> </span><span>int</span><span>*</span><span> </span><span>c</span><span>)</span>
<span>{</span>
<span>    </span><span>int</span><span> </span><span>i</span><span> </span><span>=</span><span> </span><span>threadIdx</span><span>.</span><span>x</span><span>;</span>
<span>    </span><span>c</span><span>[</span><span>i</span><span>]</span><span> </span><span>=</span><span> </span><span>a</span><span>[</span><span>i</span><span>]</span><span> </span><span>+</span><span> </span><span>b</span><span>[</span><span>i</span><span>]</span><span>;</span>
<span>    </span><span>return</span><span>;</span>
<span>}</span>
</pre></div>

<ul>
<li>
<p><code>__global__</code> specifier indicates that this function is a kernel function, which will be called on the GPU.</p>
</li>
<li>
<p><code>vectorAdd</code> takes three integer pointers (a, b, and c) as arguments, representing vectors to be added.</p>
</li>
<li>
<p><code>threadIdx.x</code> retrieves the index of the current thread (in a one-dimensional grid).</p>
</li>
<li>
<p>The sum of the corresponding elements from vectors a and b is stored in vector c.</p>
</li>
</ul>

<p>Now lets go through the main function.</p>

<p>Pointers <code>cudaA</code>, <code>cudaB</code> and <code>cudaC</code> are created to point to memory on the GPU.</p>

<div><pre><span></span><span>// Uses CUDA to use functions that parallelly calculates the addition</span>
<span>int</span><span> </span><span>main</span><span>(){</span>
<span>    </span><span>int</span><span> </span><span>a</span><span>[]</span><span> </span><span>=</span><span> </span><span>{</span><span>1</span><span>,</span><span>2</span><span>,</span><span>3</span><span>};</span>
<span>    </span><span>int</span><span> </span><span>b</span><span>[]</span><span> </span><span>=</span><span> </span><span>{</span><span>4</span><span>,</span><span>5</span><span>,</span><span>6</span><span>};</span>
<span>    </span><span>int</span><span> </span><span>c</span><span>[</span><span>sizeof</span><span>(</span><span>a</span><span>)</span><span> </span><span>/</span><span> </span><span>sizeof</span><span>(</span><span>int</span><span>)]</span><span> </span><span>=</span><span> </span><span>{</span><span>0</span><span>};</span>
<span>    </span><span>// Create pointers into the GPU</span>
<span>    </span><span>int</span><span>*</span><span> </span><span>cudaA</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span>
<span>    </span><span>int</span><span>*</span><span> </span><span>cudaB</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span>
<span>    </span><span>int</span><span>*</span><span> </span><span>cudaC</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span>
</pre></div>

<p>Using <code>cudaMalloc</code>, memory is allocated on the GPU for the vectors cudaA, cudaB, and cudaC.</p>

<div><pre><span></span><span>// Allocate memory in the GPU</span>
<span>cudaMalloc</span><span>(</span><span>&amp;</span><span>cudaA</span><span>,</span><span>sizeof</span><span>(</span><span>a</span><span>));</span>
<span>cudaMalloc</span><span>(</span><span>&amp;</span><span>cudaB</span><span>,</span><span>sizeof</span><span>(</span><span>b</span><span>));</span>
<span>cudaMalloc</span><span>(</span><span>&amp;</span><span>cudaC</span><span>,</span><span>sizeof</span><span>(</span><span>c</span><span>));</span>
</pre></div>

<p>The content of vectors a and b is copied from the host to the GPU using <code>cudaMemcpy</code>.</p>

<div><pre><span></span><span>// Copy the vectors into the gpu</span>
<span>cudaMemcpy</span><span>(</span><span>cudaA</span><span>,</span><span> </span><span>a</span><span>,</span><span> </span><span>sizeof</span><span>(</span><span>a</span><span>),</span><span> </span><span>cudaMemcpyHostToDevice</span><span>);</span>
<span>cudaMemcpy</span><span>(</span><span>cudaB</span><span>,</span><span> </span><span>b</span><span>,</span><span> </span><span>sizeof</span><span>(</span><span>b</span><span>),</span><span> </span><span>cudaMemcpyHostToDevice</span><span>);</span>
</pre></div>

<p>The kernel function <code>vectorAdd</code> is launched with one block and a number of threads equal to the size of the vectors.</p>

<div><pre><span></span><span>// Launch the kernel with one block and a number of threads equal to the size of the vectors</span>
<span>vectorAdd</span><span> </span><span>&lt;&lt;&lt;</span><span>1</span><span>,</span><span> </span><span>sizeof</span><span>(</span><span>a</span><span>)</span><span> </span><span>/</span><span> </span><span>sizeof</span><span>(</span><span>a</span><span>[</span><span>0</span><span>])</span><span>&gt;&gt;&gt;</span><span> </span><span>(</span><span>cudaA</span><span>,</span><span> </span><span>cudaB</span><span>,</span><span> </span><span>cudaC</span><span>);</span>
</pre></div>

<p>The result vector <code>cudaC</code> is copied from the GPU back to the host.</p>

<div><pre><span></span><span>// Copy the result vector back to the host</span>
<span>cudaMemcpy</span><span>(</span><span>c</span><span>,</span><span> </span><span>cudaC</span><span>,</span><span> </span><span>sizeof</span><span>(</span><span>c</span><span>),</span><span> </span><span>cudaMemcpyDeviceToHost</span><span>);</span>
</pre></div>

<p>We can then print the results as usual</p>

<div><pre><span></span><span>    </span><span>// Print the result</span>
<span>    </span><span>for</span><span> </span><span>(</span><span>int</span><span> </span><span>i</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span><span> </span><span>i</span><span> </span><span>&lt;</span><span> </span><span>sizeof</span><span>(</span><span>c</span><span>)</span><span> </span><span>/</span><span> </span><span>sizeof</span><span>(</span><span>int</span><span>);</span><span> </span><span>i</span><span>++</span><span>)</span>
<span>    </span><span>{</span>
<span>        </span><span>printf</span><span>(</span><span>&#34;c[%d] = %d&#34;</span><span>,</span><span> </span><span>i</span><span>,</span><span> </span><span>c</span><span>[</span><span>i</span><span>]);</span>
<span>    </span><span>}</span>

<span>    </span><span>return</span><span> </span><span>0</span><span>;</span>
<span>}</span>
</pre></div>

<p>For executing this code, we will use <code>nvcc</code> command.</p>

<p>We will get the output as</p>

<p><img alt="GPU Output" src="https://journal-wa6509js.s3.ap-south-1.amazonaws.com/144c2193b0d5ad71eb7bd4da490534fb278ed174df6ec8c6411b039f16757116.png"/></p>

<p>Here&#39;s the <a href="https://github.com/RijulTP/GPUToolkit/tree/main/array-addition?ref=journal.hexmos.com">full code</a> for your reference.</p>

<h4 id="optimize-image-generation-in-python-using-the-gpu">Optimize Image Generation in Python Using the GPU</h4>

<ul>
<li>
<p>This section explores the optimization of performance-intensive tasks, such as image generation, using GPU processing.</p>
</li>
<li>
<p><strong>Mandelbrot set</strong> is a mathematical construct that forms intricate visual patterns based on the behavior of specific numbers in a prescribed equation. Generating one is a resource intensive operation.</p>
</li>
<li>
<p>In the following code snippet, you can observe the conventional method of generating a Mandelbrot set using CPU processing, which is slow.</p>
</li>
</ul>

<div><pre><span></span><span># Import necessary libraries</span>
<span>from</span> <span>matplotlib</span> <span>import</span> <span>pyplot</span> <span>as</span> <span>plt</span>
<span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>from</span> <span>pylab</span> <span>import</span> <span>imshow</span><span>,</span> <span>show</span>
<span>from</span> <span>timeit</span> <span>import</span> <span>default_timer</span> <span>as</span> <span>timer</span>

<span># Function to calculate the Mandelbrot set for a given point (x, y)</span>
<span>def</span> <span>mandel</span><span>(</span><span>x</span><span>,</span> <span>y</span><span>,</span> <span>max_iters</span><span>):</span>
    <span>c</span> <span>=</span> <span>complex</span><span>(</span><span>x</span><span>,</span> <span>y</span><span>)</span>
    <span>z</span> <span>=</span> <span>0.0</span><span>j</span>
    <span># Iterate to check if the point is in the Mandelbrot set</span>
    <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>max_iters</span><span>):</span>
        <span>z</span> <span>=</span> <span>z</span><span>*</span><span>z</span> <span>+</span> <span>c</span>
        <span>if</span> <span>(</span><span>z</span><span>.</span><span>real</span><span>*</span><span>z</span><span>.</span><span>real</span> <span>+</span> <span>z</span><span>.</span><span>imag</span><span>*</span><span>z</span><span>.</span><span>imag</span><span>)</span> <span>&gt;=</span> <span>4</span><span>:</span>
            <span>return</span> <span>i</span>
    <span># If within the maximum iterations, consider it part of the set</span>
    <span>return</span> <span>max_iters</span>

<span># Function to create the Mandelbrot fractal within a specified region</span>
<span>def</span> <span>create_fractal</span><span>(</span><span>min_x</span><span>,</span> <span>max_x</span><span>,</span> <span>min_y</span><span>,</span> <span>max_y</span><span>,</span> <span>image</span><span>,</span> <span>iters</span><span>):</span>
    <span>height</span> <span>=</span> <span>image</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]</span>
    <span>width</span> <span>=</span> <span>image</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>]</span>

    <span># Calculate pixel sizes based on the specified region</span>
    <span>pixel_size_x</span> <span>=</span> <span>(</span><span>max_x</span> <span>-</span> <span>min_x</span><span>)</span> <span>/</span> <span>width</span>
    <span>pixel_size_y</span> <span>=</span> <span>(</span><span>max_y</span> <span>-</span> <span>min_y</span><span>)</span> <span>/</span> <span>height</span>

    <span># Iterate over each pixel in the image and compute the Mandelbrot value</span>
    <span>for</span> <span>x</span> <span>in</span> <span>range</span><span>(</span><span>width</span><span>):</span>
        <span>real</span> <span>=</span> <span>min_x</span> <span>+</span> <span>x</span> <span>*</span> <span>pixel_size_x</span>
        <span>for</span> <span>y</span> <span>in</span> <span>range</span><span>(</span><span>height</span><span>):</span>
            <span>imag</span> <span>=</span> <span>min_y</span> <span>+</span> <span>y</span> <span>*</span> <span>pixel_size_y</span>
            <span>color</span> <span>=</span> <span>mandel</span><span>(</span><span>real</span><span>,</span> <span>imag</span><span>,</span> <span>iters</span><span>)</span>
            <span>image</span><span>[</span><span>y</span><span>,</span> <span>x</span><span>]</span> <span>=</span> <span>color</span>

<span># Create a blank image array for the Mandelbrot set</span>
<span>image</span> <span>=</span> <span>np</span><span>.</span><span>zeros</span><span>((</span><span>1024</span><span>,</span> <span>1536</span><span>),</span> <span>dtype</span><span>=</span><span>np</span><span>.</span><span>uint8</span><span>)</span>

<span># Record the start time for performance measurement</span>
<span>start</span> <span>=</span> <span>timer</span><span>()</span>

<span># Generate the Mandelbrot set within the specified region and iterations</span>
<span>create_fractal</span><span>(</span><span>-</span><span>2.0</span><span>,</span> <span>1.0</span><span>,</span> <span>-</span><span>1.0</span><span>,</span> <span>1.0</span><span>,</span> <span>image</span><span>,</span> <span>20</span><span>)</span>

<span># Calculate the time taken to create the Mandelbrot set</span>
<span>dt</span> <span>=</span> <span>timer</span><span>()</span> <span>-</span> <span>start</span>

<span># Print the time taken to generate the Mandelbrot set</span>
<span>print</span><span>(</span><span>&#34;Mandelbrot created in </span><span>%f</span><span> s&#34;</span> <span>%</span> <span>dt</span><span>)</span>

<span># Display the Mandelbrot set using matplotlib</span>
<span>imshow</span><span>(</span><span>image</span><span>)</span>
<span>show</span><span>()</span>
</pre></div>

<p>The above code produces the output in <code>4.07</code> seconds.</p>

<p><img alt="Mandelbrot without GPU" src="https://journal-wa6509js.s3.ap-south-1.amazonaws.com/14af8fd709215ad96688a3364deefea9cfc2fa13497810587106cef04c5a413c.png"/></p>

<ul>
<li>
<p>To make this faster, we can parallelize the code with GPU by using <a href="https://numba.pydata.org/?ref=journal.hexmos.com">Numba library</a>, Lets see how its done.</p>
</li>
<li>
<p>We will import Just-In-Time compilation, CUDA for GPU acceleration, and other utilities from numba</p>
</li>
</ul>

<div><pre><span></span><span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>from</span> <span>numba</span> <span>import</span> <span>jit</span><span>,</span> <span>cuda</span><span>,</span> <span>uint32</span><span>,</span> <span>f8</span><span>,</span> <span>uint8</span>
<span>from</span> <span>pylab</span> <span>import</span> <span>imshow</span><span>,</span> <span>show</span>
<span>from</span> <span>timeit</span> <span>import</span> <span>default_timer</span> <span>as</span> <span>timer</span>
</pre></div>

<ul>
<li>The <code>@jit</code> decorator signals Numba to perform <strong>Just-In-Time compilation</strong>, translating the Python code into machine code for improved execution speed.</li>
</ul>

<div><pre><span></span><span>@jit</span>
<span>def</span> <span>mandel</span><span>(</span><span>x</span><span>,</span> <span>y</span><span>,</span> <span>max_iters</span><span>):</span>
    <span>c</span> <span>=</span> <span>complex</span><span>(</span><span>x</span><span>,</span> <span>y</span><span>)</span>
    <span>z</span> <span>=</span> <span>0.0</span><span>j</span>
    <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>max_iters</span><span>):</span>
        <span>z</span> <span>=</span> <span>z</span><span>*</span><span>z</span> <span>+</span> <span>c</span>
        <span>if</span> <span>(</span><span>z</span><span>.</span><span>real</span><span>*</span><span>z</span><span>.</span><span>real</span> <span>+</span> <span>z</span><span>.</span><span>imag</span><span>*</span><span>z</span><span>.</span><span>imag</span><span>)</span> <span>&gt;=</span> <span>4</span><span>:</span>
            <span>return</span> <span>i</span>

    <span>return</span> <span>max_iters</span>

<span>@jit</span>
<span>def</span> <span>create_fractal</span><span>(</span><span>min_x</span><span>,</span> <span>max_x</span><span>,</span> <span>min_y</span><span>,</span> <span>max_y</span><span>,</span> <span>image</span><span>,</span> <span>iters</span><span>):</span>
    <span>height</span> <span>=</span> <span>image</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]</span>
    <span>width</span> <span>=</span> <span>image</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>]</span>

    <span>pixel_size_x</span> <span>=</span> <span>(</span><span>max_x</span> <span>-</span> <span>min_x</span><span>)</span> <span>/</span> <span>width</span>
    <span>pixel_size_y</span> <span>=</span> <span>(</span><span>max_y</span> <span>-</span> <span>min_y</span><span>)</span> <span>/</span> <span>height</span>

    <span>for</span> <span>x</span> <span>in</span> <span>range</span><span>(</span><span>width</span><span>):</span>
        <span>real</span> <span>=</span> <span>min_x</span> <span>+</span> <span>x</span> <span>*</span> <span>pixel_size_x</span>
        <span>for</span> <span>y</span> <span>in</span> <span>range</span><span>(</span><span>height</span><span>):</span>
            <span>imag</span> <span>=</span> <span>min_y</span> <span>+</span> <span>y</span> <span>*</span> <span>pixel_size_y</span>
            <span>color</span> <span>=</span> <span>mandel</span><span>(</span><span>real</span><span>,</span> <span>imag</span><span>,</span> <span>iters</span><span>)</span>
            <span>image</span><span>[</span><span>y</span><span>,</span> <span>x</span><span>]</span> <span>=</span> <span>color</span>
</pre></div>

<ul>
<li><code>mandel_gpu</code> is a GPU-compatible version of the mandel function created using cuda.jit. This allows the mandel logic to be offloaded to the GPU.</li>
<li>This is done by using <code>@cuda.jit</code> decorator along with specifying the data types (f8 for float, uint32 for unsigned integer) for the function arguments.</li>
<li>The <code>device=True</code> argument indicates that this function will run on the GPU.</li>
</ul>

<div><pre><span></span><span>mandel_gpu</span> <span>=</span> <span>cuda</span><span>.</span><span>jit</span><span>((</span><span>f8</span><span>,</span> <span>f8</span><span>,</span> <span>uint32</span><span>),</span> <span>device</span><span>=</span><span>True</span><span>)(</span><span>mandel</span><span>)</span>
</pre></div>

<ul>
<li>The mandel_kernel function is defined to be executed on the CUDA GPU. It is responsible for parallelizing the Mandelbrot set generation across GPU threads.</li>
</ul>

<div><pre><span></span><span>@cuda</span><span>.</span><span>jit</span><span>((</span><span>f8</span><span>,</span> <span>f8</span><span>,</span> <span>f8</span><span>,</span> <span>f8</span><span>,</span> <span>uint8</span><span>[:,:],</span> <span>uint32</span><span>))</span>
<span>def</span> <span>mandel_kernel</span><span>(</span><span>min_x</span><span>,</span> <span>max_x</span><span>,</span> <span>min_y</span><span>,</span> <span>max_y</span><span>,</span> <span>image</span><span>,</span> <span>iters</span><span>):</span>
    <span>height</span> <span>=</span> <span>image</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]</span>
    <span>width</span> <span>=</span> <span>image</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>]</span>

    <span>pixel_size_x</span> <span>=</span> <span>(</span><span>max_x</span> <span>-</span> <span>min_x</span><span>)</span> <span>/</span> <span>width</span>
    <span>pixel_size_y</span> <span>=</span> <span>(</span><span>max_y</span> <span>-</span> <span>min_y</span><span>)</span> <span>/</span> <span>height</span>

    <span>startX</span><span>,</span> <span>startY</span> <span>=</span> <span>cuda</span><span>.</span><span>grid</span><span>(</span><span>2</span><span>)</span>
    <span>gridX</span> <span>=</span> <span>cuda</span><span>.</span><span>gridDim</span><span>.</span><span>x</span> <span>*</span> <span>cuda</span><span>.</span><span>blockDim</span><span>.</span><span>x</span>
    <span>gridY</span> <span>=</span> <span>cuda</span><span>.</span><span>gridDim</span><span>.</span><span>y</span> <span>*</span> <span>cuda</span><span>.</span><span>blockDim</span><span>.</span><span>y</span>

    <span>for</span> <span>x</span> <span>in</span> <span>range</span><span>(</span><span>startX</span><span>,</span> <span>width</span><span>,</span> <span>gridX</span><span>):</span>
        <span>real</span> <span>=</span> <span>min_x</span> <span>+</span> <span>x</span> <span>*</span> <span>pixel_size_x</span>
        <span>for</span> <span>y</span> <span>in</span> <span>range</span><span>(</span><span>startY</span><span>,</span> <span>height</span><span>,</span> <span>gridY</span><span>):</span>
            <span>imag</span> <span>=</span> <span>min_y</span> <span>+</span> <span>y</span> <span>*</span> <span>pixel_size_y</span>
            <span>image</span><span>[</span><span>y</span><span>,</span> <span>x</span><span>]</span> <span>=</span> <span>mandel_gpu</span><span>(</span><span>real</span><span>,</span> <span>imag</span><span>,</span> <span>iters</span><span>)</span>
</pre></div>

<p>The above code gets executed in <code>0.43 seconds</code>. Which is a lot faster the CPU Based code we had earlier.</p>

<p><img alt="Mandelbrot without GPU" src="https://journal-wa6509js.s3.ap-south-1.amazonaws.com/cff7881a179a0a27ce03882b3f75a8c8d2a984fe308c84e87bd0446c8871452d.png"/></p>

<p>Here&#39;s the <a href="https://github.com/RijulTP/GPUToolkit/tree/main/mandelbrot?ref=journal.hexmos.com">full code</a> for your reference.</p>

<h4 id="training-a-cat-vs-dog-neural-network-using-the-gpu">Training a Cat VS Dog Neural Network Using the GPU</h4>

<p>One of the hot topics we see nowadays is how GPUs are getting used in AI, So to demonstrate that we will be creating a <strong>neural network</strong> to differentiate between cats and dogs.</p>

<p><strong>Prerequisites</strong></p>

<ul>
<li>CUDA</li>
<li>
<p>Tensorflow -&gt; Can be installed via
  <code>pip install tensorflow[and-cuda]</code></p>
</li>
<li>
<p>We will use a data set of cats and dogs from <a href="https://www.kaggle.com/competitions/dogs-vs-cats/overview?ref=journal.hexmos.com">kaggle</a></p>
</li>
<li>
<p>Once you have downloaded it, Unzip them, organize the pictures of cats and dogs in the training folder into different subfolders, Like so.</p>
</li>
</ul>

<p><img alt="CNN File Structure" src="https://journal-wa6509js.s3.ap-south-1.amazonaws.com/47b0cc05fa99283bd8dcd39a801809bdf5521a285df558c1436460ddf4d1ebdd.png"/></p>

<p>This is the code we will use for training and using the Cat vs Dog Model.</p>

<p>The below code uses a convolutional neural network, you can <a href="https://www.analyticsvidhya.com/blog/2021/06/beginner-friendly-project-cat-and-dog-classification-using-cnn/?ref=journal.hexmos.com">read more details about it</a></p>

<p><strong>Importing Libraries</strong></p>

<ul>
<li>pandas and numpy for data manipulation.</li>
<li>Sequential for creating a linear stack of layers in the neural network.</li>
<li>Convolution2D, MaxPooling2D, Dense, and Flatten are layers used in building the Convolutional Neural Network (CNN).</li>
<li>ImageDataGenerator for real-time data augmentation during training.</li>
</ul>

<div><pre><span></span><span>import</span> <span>pandas</span> <span>as</span> <span>pd</span>
<span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>from</span> <span>keras.models</span> <span>import</span> <span>Sequential</span>
<span>from</span> <span>keras.layers</span> <span>import</span> <span>Convolution2D</span><span>,</span> <span>MaxPooling2D</span><span>,</span> <span>Dense</span><span>,</span> <span>Flatten</span>
<span>from</span> <span>keras.preprocessing.image</span> <span>import</span> <span>ImageDataGenerator</span>
</pre></div>

<p><strong>Initializing the Convolutional Neural Network</strong></p>

<div><pre><span></span><span>classifier</span> <span>=</span> <span>Sequential</span><span>()</span>
</pre></div>

<p><strong>Loading the data for training</strong></p>

<div><pre><span></span><span>train_datagen</span> <span>=</span> <span>ImageDataGenerator</span><span>(</span>
    <span>rescale</span><span>=</span><span>1.</span><span>/</span><span>255</span><span>,</span>
    <span>shear_range</span><span>=</span><span>0.2</span><span>,</span>
    <span>zoom_range</span><span>=</span><span>0.2</span><span>,</span>
    <span>horizontal_flip</span><span>=</span><span>True</span>
<span>)</span>
<span>test_datagen</span> <span>=</span> <span>ImageDataGenerator</span><span>(</span><span>rescale</span><span>=</span><span>1.</span><span>/</span><span>255</span><span>)</span>

<span>training_set</span> <span>=</span> <span>train_datagen</span><span>.</span><span>flow_from_directory</span><span>(</span>
    <span>&#39;./training_set&#39;</span><span>,</span>
    <span>target_size</span><span>=</span><span>(</span><span>64</span><span>,</span> <span>64</span><span>),</span>
    <span>batch_size</span><span>=</span><span>32</span><span>,</span>
    <span>class_mode</span><span>=</span><span>&#39;binary&#39;</span>
<span>)</span>

<span>test_set</span> <span>=</span> <span>test_datagen</span><span>.</span><span>flow_from_directory</span><span>(</span>
    <span>&#39;./test_set&#39;</span><span>,</span>
    <span>target_size</span><span>=</span><span>(</span><span>64</span><span>,</span> <span>64</span><span>),</span>
    <span>batch_size</span><span>=</span><span>32</span><span>,</span>
    <span>class_mode</span><span>=</span><span>&#39;binary&#39;</span>
<span>)</span>
</pre></div>

<p><strong>Building the CNN Architecture</strong></p>

<div><pre><span></span><span>classifier</span><span>.</span><span>add</span><span>(</span><span>Convolution2D</span><span>(</span><span>32</span><span>,</span> <span>3</span><span>,</span> <span>3</span><span>,</span> <span>input_shape</span><span>=</span><span>(</span><span>64</span><span>,</span> <span>64</span><span>,</span> <span>3</span><span>),</span> <span>activation</span><span>=</span><span>&#39;relu&#39;</span><span>))</span>
<span>classifier</span><span>.</span><span>add</span><span>(</span><span>MaxPooling2D</span><span>(</span><span>pool_size</span><span>=</span><span>(</span><span>2</span><span>,</span> <span>2</span><span>)))</span>
<span>classifier</span><span>.</span><span>add</span><span>(</span><span>Flatten</span><span>())</span>
<span>classifier</span><span>.</span><span>add</span><span>(</span><span>Dense</span><span>(</span><span>units</span><span>=</span><span>128</span><span>,</span> <span>activation</span><span>=</span><span>&#39;relu&#39;</span><span>))</span>
<span>classifier</span><span>.</span><span>add</span><span>(</span><span>Dense</span><span>(</span><span>units</span><span>=</span><span>1</span><span>,</span> <span>activation</span><span>=</span><span>&#39;sigmoid&#39;</span><span>))</span>
</pre></div>

<p><strong>Compiling the model</strong></p>

<div><pre><span></span><span>classifier</span><span>.</span><span>compile</span><span>(</span><span>optimizer</span><span>=</span><span>&#39;adam&#39;</span><span>,</span> <span>loss</span><span>=</span><span>&#39;binary_crossentropy&#39;</span><span>,</span> <span>metrics</span><span>=</span><span>[</span><span>&#39;accuracy&#39;</span><span>])</span>
</pre></div>

<p><strong>Training the model</strong></p>

<div><pre><span></span><span>classifier</span><span>.</span><span>fit</span><span>(</span><span>training_set</span><span>,</span> <span>epochs</span><span>=</span><span>25</span><span>,</span> <span>validation_data</span><span>=</span><span>test_set</span><span>,</span> <span>validation_steps</span><span>=</span><span>2000</span><span>)</span>
<span>classifier</span><span>.</span><span>save</span><span>(</span><span>&#39;trained_model.h5&#39;</span><span>)</span>
</pre></div>

<p>Once we have trained the model, The model is stored in a .h5 file using <code>classifier.save</code></p>

<p>In the below code, we will use this <code>trained_model.h5</code> file to recognize cats and dogs.</p>

<div><pre><span></span><span>import</span> <span>numpy</span> <span>as</span> <span>np</span>
<span>from</span> <span>keras.models</span> <span>import</span> <span>load_model</span>
<span>import</span> <span>keras.utils</span> <span>as</span> <span>image</span>

<span>def</span> <span>predict_image</span><span>(</span><span>imagepath</span><span>,</span> <span>classifier</span><span>):</span>
    <span>predict</span> <span>=</span> <span>image</span><span>.</span><span>load_img</span><span>(</span><span>imagepath</span><span>,</span> <span>target_size</span><span>=</span><span>(</span><span>64</span><span>,</span> <span>64</span><span>))</span>
    <span>predict_modified</span> <span>=</span> <span>image</span><span>.</span><span>img_to_array</span><span>(</span><span>predict</span><span>)</span>
    <span>predict_modified</span> <span>=</span> <span>predict_modified</span> <span>/</span> <span>255</span>
    <span>predict_modified</span> <span>=</span> <span>np</span><span>.</span><span>expand_dims</span><span>(</span><span>predict_modified</span><span>,</span> <span>axis</span><span>=</span><span>0</span><span>)</span>
    <span>result</span> <span>=</span> <span>classifier</span><span>.</span><span>predict</span><span>(</span><span>predict_modified</span><span>)</span>

    <span>if</span> <span>result</span><span>[</span><span>0</span><span>][</span><span>0</span><span>]</span> <span>&gt;=</span> <span>0.5</span><span>:</span>
        <span>prediction</span> <span>=</span> <span>&#39;dog&#39;</span>
        <span>probability</span> <span>=</span> <span>result</span><span>[</span><span>0</span><span>][</span><span>0</span><span>]</span>
        <span>print</span><span>(</span><span>&#34;Probability = &#34;</span> <span>+</span> <span>str</span><span>(</span><span>probability</span><span>))</span>
        <span>print</span><span>(</span><span>&#34;Prediction = &#34;</span> <span>+</span> <span>prediction</span><span>)</span>
    <span>else</span><span>:</span>
        <span>prediction</span> <span>=</span> <span>&#39;cat&#39;</span>
        <span>probability</span> <span>=</span> <span>1</span> <span>-</span> <span>result</span><span>[</span><span>0</span><span>][</span><span>0</span><span>]</span>
        <span>print</span><span>(</span><span>&#34;Probability = &#34;</span> <span>+</span> <span>str</span><span>(</span><span>probability</span><span>))</span>
        <span>print</span><span>(</span><span>&#34;Prediction = &#34;</span> <span>+</span> <span>prediction</span><span>)</span>

<span># Load the trained model</span>
<span>loaded_classifier</span> <span>=</span> <span>load_model</span><span>(</span><span>&#39;trained_model.h5&#39;</span><span>)</span>

<span># Example usage</span>
<span>dog_image</span> <span>=</span> <span>&#34;dog.jpg&#34;</span>
<span>predict_image</span><span>(</span><span>dog_image</span><span>,</span> <span>loaded_classifier</span><span>)</span>

<span>cat_image</span> <span>=</span> <span>&#34;cat.jpg&#34;</span>
<span>predict_image</span><span>(</span><span>cat_image</span><span>,</span> <span>loaded_classifier</span><span>)</span>
</pre></div>

<p>Let&#39;s see the output
<img alt="Alt text" src="https://journal-wa6509js.s3.ap-south-1.amazonaws.com/d546542af4055bc7163bc49055d5a623a44ad0cc3022d02d0aaa791b9a83d75b.png"/></p>

<p>Here&#39;s the <a href="https://github.com/RijulTP/GPUToolkit/tree/main/neural-network?ref=journal.hexmos.com">full code</a> for your reference</p>

<h3 id="conclusion">Conclusion</h3>

<p>In the upcoming AI age, GPUs are not a thing to be ignored, We should be more aware of its capabilities.</p>

<p>As we transition from traditional <strong>sequential algorithms</strong> to increasingly prevalent <strong>parallelized algorithms</strong>, GPUs emerge as indispensable tools that empower the acceleration of complex computations. The parallel processing prowess of GPUs is particularly advantageous in handling the massive datasets and intricate neural network architectures inherent to artificial intelligence and machine learning tasks.</p>

<p>Furthermore, the role of GPUs extends beyond traditional machine learning domains, finding applications in scientific research, simulations, and data-intensive tasks. The parallel processing capabilities of GPUs have proven instrumental in addressing challenges across diverse fields, ranging from drug discovery and climate modelling to financial simulations.</p>

<h3 id="reference">Reference</h3>

<ul>
<li><a href="https://noahgift.github.io/cloud-data-analysis-at-scale/topics/end-of-moores-law.html?ref=journal.hexmos.com">Using Numba for mandelbrot generation</a></li>
<li><a href="https://www.analyticsvidhya.com/blog/2021/06/beginner-friendly-project-cat-and-dog-classification-using-cnn/?ref=journal.hexmos.com">Using Convolutional Neural Networks</a></li>
</ul>

<p><a href="https://twitter.com/HexmosTech?ref=journal.hexmos.com"><img alt="Twitter" src="https://journal-wa6509js.s3.ap-south-1.amazonaws.com/e706462dc4b473f96955889657e3893beca1e6cba15daa89dca171d732709b87.png"/></a></p>

<p><a href="https://hexmos.com/?ref=journal.hexmos.com"><img alt="Hexmos" src="https://journal-wa6509js.s3.ap-south-1.amazonaws.com/62b98356b4386f9c312f586af9c3606f9bd67f7116b4031c1bf2f5fb0fc73e0a.png"/></a></p>

<p><a href="https://news.ycombinator.com/item?id=38240421&amp;ref=journal.hexmos.com">Hackernews post</a></p>

<p><a href="https://www.linkedin.com/feed/update/urn:li:activity:7129475708971618305?ref=journal.hexmos.com">Linkedin post</a></p><!--kg-card-end: html-->
    </section>


        <section>
		
		
		
        </section>
</article>
</div></div>
  </body>
</html>
