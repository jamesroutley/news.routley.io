<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://swagnik.netlify.app/posts/how-raw-sockets-behave-in-different-systems/">Original</a>
    <h1>How Raw sockets behave differently in macOS and Linux</h1>
    
    <div id="readability-page-1" class="page"><div>

<article>
   
  <div><p>This post builds up on my previous <a href="https://swagnik.netlify.app/posts/it-works-although-it-makes-no-sense/">post</a> where I talked about an interesting bug in my ping implementation. In case you haven’t read it I will explain it very briefly for better coherence.</p>
<blockquote>
<p>I was sending raw echo-request packets to a target host but I wasn’t using the right tool for sending raw packets. As a result, the operating system’s network stack slapped a duplicate IP header on my IP packet making it look like <code>IP | IP | ICMP</code>. This caused a misalignment in bytes and the packet was dropped.</p>
</blockquote>
<p>What I needed was a way to tell the OS, not to attach its IP header as the packet already had one, and the way of achieving that was by using raw sockets.</p>

<p>If you already know what raw sockets are, feel free to <a href="#where-were-we">skip</a> this part.</p>
<p>The <a href="https://beej.us/guide/bgnet/html/split/what-is-a-socket.html#what-is-a-socket">Beej’s guide</a> is hands down one of the best resources on networking, but since you’re here, here’s a rather simplistic explanation raw sockets.</p>
<p>An operating system is typically divided into two parts: user space and kernel space. User space is where applications and user-level processes run, while kernel space handles low-level, critical operations such as networking, disk access, hardware management, etc.</p>
<p>When a network packet is sent from the system, it passes through multiple layers of the network stack. At each such layer, the kernel is responsible for creating and attaching the appropriate headers. For instance, at the network layer it attaches an IP header, while at the data-link layer, it attaches a link-layer header, such as an Ethernet header. The key takeaway here is that it’s the sole responsibility of the kernel to <em>create</em> and attach headers, and all of this happens in the kernel space.</p>
<p>Raw sockets come in handy when a user (who stays in userland btw) wants to create the headers themself. It enables users to craft the packet headers <em>in</em> the user space.</p>
<h3 id="raw-socket-is-a-generic-term">“raw socket” is a generic term</h3>
<p>There’re essentially two types of raw sockets, and I feel its necessary to know this distinction.</p>
<ul>
<li>Firstly, there are raw sockets created at network layer. These are also called network sockets or L3 sockets.</li>
<li>Then there are raw sockets are created at data-link layer. These are called data-link sockets or L2 sockets or even packet sockets.</li>
</ul>
<p>When we create a raw socket at the network layer, we are responsible for constructing the packet’s IP header and the payload — which typically includes transport layer headers (TCP/UDP) and any data from higher layers.</p>
<p>Likewise, when creating a raw socket at the data link layer (L2), we are responsible for constructing the data link layer header (e.g., Ethernet header) as well as the entire packet, including the IP header, transport layer header, and payload.</p>
<h3 id="okay-so-i-understand-that-user-gets-to-create-her-own-header-and-data-using-raw-sockets-what-happens-after-that-how-does-it-reach-the-network-stack">Okay, so I understand that user gets to create her own header and data using raw sockets. What happens after that? How does it reach the network stack?</h3>
<p>When we call the <code>socket()</code> system routine, it returns a socket file descriptor, basically, a file descriptor associated with a socket. A file descriptor is a number that the OS uses to identify an open file or other I/O resources such as pipes, network connection, socket, etc. When a unix program does any sort of I/O, they do it by reading from or writing to a file descriptor. And since sockets are represented by file descriptors, network communication happens the same way as other I/O operations. There are methods defined, such as <code>send()</code> and <code>recv()</code> that are used to write data to or read data from a file descriptor.</p>
<p>Upon writing data to the file descriptor, it’s my understanding that the kernel processes it and sends it down to the appropriate layer. Meaning, if we’ve created an L3 raw socket, the kernel would pass it to the data-link layer, where the link-layer header would get attached. Eventually, it gets handed off to the NIC for transmission over physical medium as electric signals.</p>
<p>Here’s a doodle elaborating my thoughts. Please don’t take it seriously, it’s highly highly abstracted and may even be technically inaccurate if put under scrutiny. It’s just that, making these diagrams helps me <em>briefly</em> familiarize myself with unknown topics. At times, it also provides a level of clarity that was hard to attain by reading through texts.</p>
<p><img loading="lazy" src="https://swagnik.netlify.app/posts/how-raw-sockets-behave-in-different-systems/img/explaining-raw-socket.png" alt="explaining-raw-socket"/>
</p>

<p>With some decent understanding of raw sockets, I started searching for implementations in Go. That’s when I came across this <a href="https://darkcoding.net/software/raw-sockets-in-go-link-layer/">blog</a> by Graham King that demonstrates exactly what I needed to do. It creates two binaries, a sender and a receiver, and runs each of them on separate terminals. The sender program sends a raw echo-request packet on the loopback address, and when the system responds with an echo-reply, the receiver program receives it and prints the echo-reply bytes on stdout. We validate correctness by comparing the sequences in both terminals, ensuring that the byte corresponding to the <code>Type</code> field is <code>08</code> in one (echo-request) and <code>00</code> in another (echo-reply).</p>
<p>I was relieved as the article demonstrated exactly what I needed to do to upgrade my ping implementation using raw sockets. And yet, before refactoring, I copy pasted the program from the blog and tried running it on my machine, just to be sure that it works!</p>

<p>As you might’ve guessed, it <em>didn’t</em>. The kernel clearly didn’t get my message and kept attaching its own IP header ahead of mine. It was the same story of <code>IP | IP | ICMP</code> all over again. I wasn’t able to see any reason why things wouldn’t work as I had expected. I was fairly confident that I hadn’t missed any details from the linux <a href="https://linux.die.net/man/7/raw">manual</a> on raw sockets. Yet, for peace of mind, I revisited the manual several times, hoping to spot some minor detail I may have overlooked. But despite my efforts, nothing surfaced.</p>
<p>Frustrated by the lack of progress, I posted a <a href="https://stackoverflow.com/questions/78641399/os-appending-ip-header-even-with-raw-sockets-and-ipproto-raw">question</a> on Stack Overflow. A few days later, someone <a href="https://stackoverflow.com/a/78641801/3728336">responded</a>. I’ve put together pieces from their answer below.</p>
<p><img loading="lazy" src="https://swagnik.netlify.app/posts/how-raw-sockets-behave-in-different-systems/img/stack-overflow-answer-highlighted.png" alt="stranger-advice"/>
</p>
<p>All this time. I repeat, <em>all this time</em>, I have been poring over the linux man pages while sitting comfortably on macOS.</p>
<p><img loading="lazy" src="https://swagnik.netlify.app/posts/how-raw-sockets-behave-in-different-systems/img/steven-he.png" alt="steven-he-upset"/>
</p>
<p>How I’d been that oblivious, I still don’t know. It hit me that until that moment, I had never needed to write code with cross-system compatibility in mind. It’s a bit of a shame, I know — but it is what it is</p>

<p>The immediate step was to figure out how raw sockets behave differently in Linux and macOS. I learned that macOS has its origin in FreeBSD, so I started referring to the FreeBSD manual on raw sockets. After some digging, I found this <a href="https://wiki.freebsd.org/SOCK_RAW">page</a> from the FreeBSD wiki and these <a href="https://cseweb.ucsd.edu/~braghava/notes/freebsd-sockets.txt">notes</a> that summarises raw-socket related bugs and peculiarities on FreeBSD.</p>
<p>I’ve copied its contents here for reference and completeness.</p>
<div><pre tabindex="0"><code data-lang="fallback"><span><span>FreeBSD socket bugs and peculiarities
</span></span><span><span>
</span></span><span><span>Documented by Barath Raghavan, 11/2003 on FreeBSD 4.8-RELEASE
</span></span><span><span>
</span></span><span><span>Writing to RAW sockets
</span></span><span><span>----------------------
</span></span><span><span>- ip_len and ip_off must be in host byte order
</span></span><span><span>
</span></span><span><span>
</span></span><span><span>Reading from RAW sockets
</span></span><span><span>------------------------
</span></span><span><span>- ip_len does not include the IP header&#39;s length.  recvfrom() however
</span></span><span><span>returns the packet&#39;s true length.  To get the true ip_len field do:
</span></span><span><span>iphdr-&gt;ip_len += iphdr-&gt;ip_hl &lt;&lt; 2;
</span></span><span><span>
</span></span><span><span>- You may only read from RAW sockets bound with a protocol other than
</span></span><span><span>IPPROTO_RAW
</span></span><span><span>
</span></span><span><span>- ip_len is in host byte order
</span></span><span><span>
</span></span><span><span>- You may only read packets for protocols or subprotocols that the kernel
</span></span><span><span>does not process.  This includes things such as ICMP_ECHOREPLY and
</span></span><span><span>ICMP_TIMESTAMP as well as nonstandard protocol numbers.
</span></span><span><span>
</span></span><span><span>
</span></span><span><span>DIVERT sockets
</span></span><span><span>--------------
</span></span><span><span>- These differ in behavior from RAW sockets, but I haven&#39;t gotten a chance
</span></span><span><span>to document their weirdness.
</span></span><span><span>
</span></span><span><span>
</span></span><span><span>General Thoughts
</span></span><span><span>----------------
</span></span><span><span>- Linux RAW sockets are much better documented in modern Linux
</span></span><span><span>distributions (Gentoo) and have no bugs that I&#39;ve noticed.  Avoid FreeBSD
</span></span><span><span>for raw sockets unless you have no choice.  If you need BSD, I&#39;ve read
</span></span><span><span>that OpenBSD has fixed several of these bugs and provides a raw socket
</span></span><span><span>implementation similar to that of Linux.
</span></span></code></pre></div><p>To put it briefly, raw sockets in FreeBSD exhibit certain peculiarities. These are observed when we read from or write to a raw socket. I want to elaborate on each of these and here’s how I’m gonna do it. First, I would show you the final functional code that works on both systems and then, as we run the program, each of these peculiarities would become noticeable. We will then connect what we observe to the relevant section of the above text that talks about it.</p>
<p>Let’s get to that.</p>
<p>So this is how the files are structured in my project directory.</p>
<div><pre tabindex="0"><code data-lang="fallback"><span><span>.
</span></span><span><span>├── Makefile
</span></span><span><span>├── cmd
</span></span><span><span>│   ├── receiver
</span></span><span><span>│   │   └── main.go
</span></span><span><span>│   └── sender
</span></span><span><span>│       └── main.go
</span></span><span><span>├── go.mod
</span></span><span><span>└── go.sum
</span></span></code></pre></div><p>This is the receiver program, copied exactly as it was in the original article (ignoring the print statements).</p>
<div><pre tabindex="0"><code data-lang="go"><span><span><span>func</span> <span>main</span>() {
</span></span><span><span>	fd, err <span>:=</span> syscall.<span>Socket</span>(syscall.AF_INET, syscall.SOCK_RAW, syscall.IPPROTO_ICMP)
</span></span><span><span>	<span>if</span> err <span>!=</span> <span>nil</span> {
</span></span><span><span>		fmt.<span>Printf</span>(<span>&#34;Error creating socket: %s\n&#34;</span>, err)
</span></span><span><span>		os.<span>Exit</span>(<span>1</span>)
</span></span><span><span>	}
</span></span><span><span>	f <span>:=</span> os.<span>NewFile</span>(<span>uintptr</span>(fd), fmt.<span>Sprintf</span>(<span>&#34;fd %d&#34;</span>, fd))
</span></span><span><span>
</span></span><span><span>	<span>for</span> {
</span></span><span><span>		buf <span>:=</span> <span>make</span>([]<span>byte</span>, <span>1024</span>)
</span></span><span><span>		fmt.<span>Println</span>(<span>&#34;waiting to receive&#34;</span>)
</span></span><span><span>		n, err <span>:=</span> f.<span>Read</span>(buf)
</span></span><span><span>		<span>if</span> err <span>!=</span> <span>nil</span> {
</span></span><span><span>			fmt.<span>Printf</span>(<span>&#34;Error reading: %s\n&#34;</span>, err)
</span></span><span><span>			<span>break</span>
</span></span><span><span>		}
</span></span><span><span>		fmt.<span>Printf</span>(<span>&#34;% X\n&#34;</span>, buf[:n])
</span></span><span><span>	}
</span></span><span><span>}
</span></span></code></pre></div><p>It is system agnostic. We will compile this into an executable and run it in a dedicated terminal.</p>
<div><pre tabindex="0"><code data-lang="fallback"><span><span>$ go build -o receiver ./cmd/receiver
</span></span><span><span>$ sudo ./receiver
</span></span><span><span>waiting to receive
</span></span></code></pre></div><p>While the receiver waits to receive an echo-reply, let’s shift our attention to the sender program, which by the way, is <em>not</em> system agnostic. I slightly modified it to accommodate the behavior and expectations of Darwin-based systems. I would encourage you to briefly skim through the code once, especially the <code>if-block</code> that handles the system-specific adjustments.</p>
<div><pre tabindex="0"><code data-lang="go"><span><span><span>func</span> <span>main</span>() {
</span></span><span><span>	fd, _ <span>:=</span> syscall.<span>Socket</span>(syscall.AF_INET, syscall.SOCK_RAW, syscall.IPPROTO_RAW)
</span></span><span><span>	addr <span>:=</span> syscall.SockaddrInet4{
</span></span><span><span>		Addr: [<span>4</span>]<span>byte</span>{<span>127</span>, <span>0</span>, <span>0</span>, <span>1</span>},
</span></span><span><span>	}
</span></span><span><span>
</span></span><span><span>	ipHeader <span>:=</span> []<span>byte</span>{
</span></span><span><span>		<span>0x45</span>,       <span>// versionIHL
</span></span></span><span><span><span></span>		<span>0x00</span>,       <span>// tos
</span></span></span><span><span><span></span>		<span>0x00</span>, <span>0x00</span>, <span>// len
</span></span></span><span><span><span></span>		<span>0x00</span>, <span>0x00</span>, <span>// id
</span></span></span><span><span><span></span>		<span>0x00</span>, <span>0x00</span>, <span>// ffo
</span></span></span><span><span><span></span>		<span>0x40</span>,       <span>// ttl
</span></span></span><span><span><span></span>		<span>0x01</span>,       <span>// protocol
</span></span></span><span><span><span></span>		<span>0x00</span>, <span>0x00</span>, <span>// checksum
</span></span></span><span><span><span></span>
</span></span><span><span>		<span>0x00</span>, <span>0x00</span>, <span>0x00</span>, <span>0x00</span>, <span>// src
</span></span></span><span><span><span></span>		<span>0x7f</span>, <span>0x00</span>, <span>0x00</span>, <span>0x01</span>, <span>// dest
</span></span></span><span><span><span></span>	}
</span></span><span><span>	data <span>:=</span> []<span>byte</span>{<span>0x08</span>, <span>0x00</span>, <span>0xf7</span>, <span>0xff</span>, <span>0x00</span>, <span>0x00</span>, <span>0x00</span>, <span>0x00</span>}
</span></span><span><span>
</span></span><span><span>	<span>if</span> runtime.GOOS <span>==</span> <span>&#34;darwin&#34;</span> {
</span></span><span><span>		<span>// setting IP_HDRINCL socket option explicitly
</span></span></span><span><span><span></span>		_ = syscall.<span>SetsockoptInt</span>(fd, syscall.IPPROTO_IP, syscall.IP_HDRINCL, <span>1</span>)
</span></span><span><span>
</span></span><span><span>		<span>// Populating total length in host byte order
</span></span></span><span><span><span></span>		binary.LittleEndian.<span>PutUint16</span>(ipHeader[<span>2</span>:<span>4</span>], <span>28</span>)
</span></span><span><span>		
</span></span><span><span>		<span>// Filling the fields that are auto filled in linux systems but not on mac.
</span></span></span><span><span><span></span>		<span>copy</span>(ipHeader[<span>12</span>:<span>16</span>], []<span>byte</span>{<span>127</span>, <span>0</span>, <span>0</span>, <span>1</span>})
</span></span><span><span>		binary.BigEndian.<span>PutUint16</span>(ipHeader[<span>4</span>:<span>6</span>], <span>11</span>)
</span></span><span><span>		binary.BigEndian.<span>PutUint16</span>(ipHeader[<span>10</span>:<span>12</span>], <span>calculateChecksum</span>(ipHeader))
</span></span><span><span>	}
</span></span><span><span>
</span></span><span><span>	p <span>:=</span> <span>append</span>(ipHeader, data<span>...</span>)
</span></span><span><span>
</span></span><span><span>	fmt.<span>Printf</span>(<span>&#34;Transmitting bytes:\n% x\n&#34;</span>, p)
</span></span><span><span>
</span></span><span><span>	_ <span>:=</span> syscall.<span>Sendto</span>(fd, p, <span>0</span>, <span>&amp;</span>addr)
</span></span><span><span>
</span></span><span><span>	fmt.<span>Printf</span>(<span>&#34;Sent %d bytes\n&#34;</span>, <span>len</span>(p))
</span></span><span><span>}
</span></span></code></pre></div><p>Let’s compile this. Ensure that you’re setting correct values for GOOS and GOARCH environment variables. This is essential to generate the correct build, otherwise, you will get <code>exec format error</code>. I am running this on my MacBook Pro which has an M1 chip.</p>
<div><pre tabindex="0"><code data-lang="fallback"><span><span>$ GOOS=darwin GOARCH=arm64 go build -o sender-darwin ./cmd/sender
</span></span></code></pre></div><p>This creates a binary <code>sender-darwin</code> which we will be running in a separate terminal.</p>
<p>But before that, there is one key difference that needs to be said even before we can start sending out bytes. It lies around the socket creation step itself.</p>
<h2 id="1-creation-of-raw-socket">1. Creation of raw-socket</h2>
<p>So, socket creation is done via a syscall that has the signature</p>
<div><pre tabindex="0"><code data-lang="fallback"><span><span>socket = socket(domain, type, protocol)
</span></span></code></pre></div><p>What separates a raw socket from a regular one is an option called <code>IP_HDRINCL</code>. Normally, the IPv4 layer generates the IP header while sending a packet but when the <code>IP_HDRINCL</code> option is enabled on the socket, the packet must already contain an IP header. The way to set this option is by passing <code>IPPROTO_RAW</code> for the protocol argument in the above function call. Passing <code>IP_PROTORAW</code> implies that the <code>IP_HDRINCL</code> option is enabled. This is what the the linux <a href="https://linux.die.net/man/7/raw">manual</a> says on raw sockets.</p>
<p>Thus, to create an L3 (network layer) raw socket in linux, the following should suffice.</p>
<div><pre tabindex="0"><code data-lang="go"><span><span>fd, _ <span>:=</span> syscall.<span>Socket</span>(syscall.AF_INET, syscall.SOCK_RAW, syscall.IPPROTO_RAW)
</span></span></code></pre></div><p>However, on macOS, the previous command alone isn’t sufficient. You also need to explicitly set the <code>IP_HDRINCL</code> option using the <code>SetsockoptInt()</code> function.</p>
<div><pre tabindex="0"><code data-lang="go"><span><span>_ = syscall.<span>SetsockoptInt</span>(fd, syscall.IPPROTO_IP, syscall.IP_HDRINCL, <span>1</span>)
</span></span></code></pre></div><p>This is the first thing I handled inside the <code>if</code> block.</p>
<h2 id="2-writing-to-a-raw-socket">2. Writing to a raw socket</h2>
<p>Before we start, here’s a useful tip. If you’re planning to run this on a mac and observe packets using a tool like wireshark or tcpdump, you might want to <em>disable</em> <a href="https://wiki.wireshark.org/CaptureSetup/Offloading">checksum offloading</a> on your system. Otherwise, with checksum offloading enabled, what I’ve observed is that the checksum you calculate programmatically appears as zero in Wireshark/tcpdump output — which can be confusing while debugging. Here’s how you disable it on macOS.</p>
<div><pre tabindex="0"><code data-lang="fallback"><span><span>➜ ~ sudo sysctl net.link.generic.system.hwcksum_{tx,rx}=0
</span></span><span><span>net.link.generic.system.hwcksum_tx: 0 -&gt; 0
</span></span><span><span>net.link.generic.system.hwcksum_rx: 0 -&gt; 0
</span></span><span><span>
</span></span><span><span># to check status
</span></span><span><span>➜ ~ sudo sysctl net.link.generic.system.hwcksum_{tx,rx}
</span></span><span><span>net.link.generic.system.hwcksum_tx: 0
</span></span><span><span>net.link.generic.system.hwcksum_rx: 0
</span></span></code></pre></div><p>Keeping that in mind, let’s continue.</p>
<p>We will run the sender program on both mac and linux machines and observe the bytes we send out in each of them. This is what we see on mac.
<img loading="lazy" src="https://swagnik.netlify.app/posts/how-raw-sockets-behave-in-different-systems/img/sender/mac.png" alt="sender-mac"/>
</p>
<p>And here’s what we see when running the same program on Ubuntu.
<img loading="lazy" src="https://swagnik.netlify.app/posts/how-raw-sockets-behave-in-different-systems/img/sender/linux.png" alt="sender-linux"/>
</p>
<p>For the record, this works as the receiver program on both machines successfully receives the echo-reply. We will see that in the next section.</p>
<p>For now, let’s focus on the bytes printed out by the sender in both macOS and Ubuntu. There are quite a few observations to make here.</p>
<ul>
<li>
<p>First thing you would notice is that there are a lot of <code>00</code> or null bytes in the Ubuntu terminal. These are bytes corresponding to the fields <code>Total Length</code>, <code>Identification</code>, <code>Checksum</code>, and <code>Source address</code>. I’ve color-coded them for clarity.
<img loading="lazy" src="https://swagnik.netlify.app/posts/how-raw-sockets-behave-in-different-systems/img/sender/linux-ccd.png" alt="sender-linux-copy"/>

I calculate these values only when the program is running on mac. For linux, I offload this responsibility to the kernel. The linux <a href="https://linux.die.net/man/7/raw">manual</a> says that if <code>IP_HDRINCL</code> field is set, certain header fields are auto-filled.</p>
<ul>
<li><code>Checksum</code> and <code>Total Length</code> fields are always <em>filled</em> in.</li>
<li><code>Source address</code> and <code>Identification</code> fields are filled only when they’re left zero.</li>
</ul>
<p>I use this to my advantage and leave their values to zero. This doesn’t happen in mac though, which is why I’ve to calculate their values by myself when my program is running on mac.</p>
</li>
<li>
<p>Moving on, while writing to raw sockets, FreeBSD requires certain fields of the IP header such as <code>Total Length</code> and <code>Offset</code> to be in host byte order. For context, the <code>Total Length</code> field gives the length of the entire IP datagram. So <code>20</code> bytes for the IP header and <code>8</code> bytes for the payload (ICMP header) gives <code>28</code> bytes in total.</p>
<div><pre tabindex="0"><code data-lang="go"><span><span>binary.LittleEndian.<span>PutUint16</span>(ipHeader[<span>2</span>:<span>4</span>], <span>28</span>) <span>// host byte order
</span></span></span></code></pre></div><p>Now, <code>28</code> when represented in two bytes is <code>00 1c</code>, but as we’re using host-byte order for this field, we reverse the sequence to <code>1c 00</code> and that is exactly what we had sent out programmatically. See it again (in cyan).
<img loading="lazy" src="https://swagnik.netlify.app/posts/how-raw-sockets-behave-in-different-systems/img/sender/mac-ccd.png" alt="sender-mac-copy"/>

Naturally, this affects the checksum we compute. Bytes <code>1c 00</code> yield a checksum of <code>60 f0</code> while bytes <code>00 1c</code> yield a checksum of <code>7c d4</code> which can be seen in the tcpdump output below.</p>
<p><img loading="lazy" src="https://swagnik.netlify.app/posts/how-raw-sockets-behave-in-different-systems/img/tcpdump/sender-mac-ccd.png" alt="tcpdump-mac"/>

Note that this tcpdump output above, is from the mac terminal. It also shows <code>Total Length</code> bytes coming as <code>00 1c</code> and not <code>1c 00</code> — which is what we had sent in host-byte order.</p>
</li>
<li>
<p>Among other observations,</p>
<ul>
<li>
<p>The identification bytes in pink <code>00 0b</code>, which is <code>11</code> in decimal, it’s just a <em>random</em> value I set for the field. There is no other rationale behind this.</p>
<div><pre tabindex="0"><code data-lang="go"><span><span>binary.BigEndian.<span>PutUint16</span>(ipHeader[<span>4</span>:<span>6</span>], <span>11</span>)
</span></span></code></pre></div></li>
<li>
<p>The checksum bytes <code>60 f0</code> were calculated manually</p>
<div><pre tabindex="0"><code data-lang="go"><span><span>binary.BigEndian.<span>PutUint16</span>(ipHeader[<span>10</span>:<span>12</span>], <span>calculateChecksum</span>(ipHeader))
</span></span></code></pre></div></li>
<li>
<p>and the bytes corresponding to source address were hardcoded.</p>
<div><pre tabindex="0"><code data-lang="go"><span><span><span>copy</span>(ipHeader[<span>12</span>:<span>16</span>], []<span>byte</span>{<span>127</span>, <span>0</span>, <span>0</span>, <span>1</span>})
</span></span></code></pre></div></li>
</ul>
</li>
</ul>
<h2 id="3-reading-from-a-raw-socket">3. Reading from a raw socket</h2>
<p>After sending the raw echo request packet above, the receiver program running on both machines receives the echo-reply message. This can be validated by checking the byte corresponding to the ICMP <code>Type</code> field, which should be <code>00</code> for echo-reply.
<img loading="lazy" src="https://swagnik.netlify.app/posts/how-raw-sockets-behave-in-different-systems/img/receiver/combined-ccd.png" alt="receiver-combined"/>
</p>
<blockquote>
<p>A sidenote. We see that the receiver running on Ubuntu is capturing the echo-request too … and I really don’t know why that’s happening. My expectation was that it would receive just the echo-reply, like it happens on mac. If I ever find a reason behind this, I will write an update here.</p>
</blockquote>
<p>There are a couple of quirks to note here as well.</p>
<ul>
<li>In FreeBSD, when we read from raw sockets, the value of <code>Total Length</code> comes in host byte order. And it does not include the length of the IP header. In our case, the actual total length is <code>28</code> and if we subtract the length of the IP header <code>20</code> from it, we are left with <code>8</code>, which is <code>00 08</code> if expressed in two bytes. And that, in host byte order becomes <code>08 00</code>, which is exactly what the receiver program receives.
<img loading="lazy" src="https://swagnik.netlify.app/posts/how-raw-sockets-behave-in-different-systems/img/receiver/mac-ccd.png" alt="receiver-mac-copy"/>

Even here, if you see the tcpdump output for the incoming packet (yes, on mac of course), you would see <code>00 1c</code> instead of <code>08 00</code>.
<img loading="lazy" src="https://swagnik.netlify.app/posts/how-raw-sockets-behave-in-different-systems/img/tcpdump/receiver-mac.png" alt="receiver-tcpdump-mac"/>

This is just to reaffirm what I had mentioned earlier: the point where tools like tcpdump and Wireshark capture packets don’t observe the peculiarities around FreeBSD raw sockets.</li>
</ul>

<p>If you’ve read this far, I’m grateful. I’m sure that, noticing the minute differences in the images required some cognitive effort and patience. For that, I thank you.</p>
<p>I cannot be sure if all of this was <em>actually</em> helpful because, the gist of this blog can be summarised as — “Don’t use raw sockets on FreeBSD or mac; it’s not worth the effort”.</p>
<p>Among the good parts of course, there’s a lot that I’ve learned in the process. Also, my doodling skills on excalidraw have honestly improved. Isn’t that great?!</p>

<ul>
<li><a href="https://beej.us/guide/bgnet/html/split/index.html">Beej’s Guide to Network Programming</a></li>
<li><a href="https://stackoverflow.com/a/15699517/3728336">Network socket vs data-link socket</a></li>
<li><a href="https://bottomupcs.com/ch01s03.html">File descriptors</a></li>
<li><a href="https://www.form3.tech/blog/engineering/linux-fundamentals-user-kernel-space">Linux fundamentals: user space, kernel space and the syscalls API surface</a></li>
<li><a href="https://stackoverflow.com/a/15699517/3728336">Raw socket is a general term</a></li>
</ul>


  </div>

  
</article>
    </div></div>
  </body>
</html>
