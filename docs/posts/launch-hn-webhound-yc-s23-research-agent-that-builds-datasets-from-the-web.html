<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://news.ycombinator.com/item?id=45373008">Original</a>
    <h1>Launch HN: Webhound (YC S23) â€“ Research agent that builds datasets from the web</h1>
    
    <div id="readability-page-1" class="page"><div><td colspan="2"></td><td><div><p>We&#39;re the team behind Webhound (<a href="https://webhound.ai">https://webhound.ai</a>), an AI agent that builds datasets from the web based on natural language prompts. You describe what you&#39;re trying to find. The agent figures out how to structure the data and where to look, then searches, extracts the results, and outputs everything in a CSV you can export.</p><p>We&#39;ve set up a special no-signup version for the HN community at <a href="https://hn.webhound.ai">https://hn.webhound.ai</a> - just click &#34;Continue as Guest&#34; to try it without signing up.</p><p>Here&#39;s a demo: <a href="https://youtu.be/fGaRfPdK1Sk" rel="nofollow">https://youtu.be/fGaRfPdK1Sk</a></p><p>We started building it after getting tired of doing this kind of research manually. Open 50 tabs, copy everything into a spreadsheet, realize it&#39;s inconsistent, start over. It felt like something an LLM should be able to handle.</p><p>Some examples of how people have used it in the past month:</p><p>Competitor analysis: &#34;Create a comparison table of internal tooling platforms (Retool, Appsmith, Superblocks, UI Bakery, BudiBase, etc) with their free plan limits, pricing tiers, onboarding experience, integrations, and how they position themselves on their landing pages.&#34; (<a href="https://www.webhound.ai/dataset/c67c96a6-9d17-4c91-b9a0-ff6927c44f80">https://www.webhound.ai/dataset/c67c96a6-9d17-4c91-b9a0-ff69...</a>)</p><p>Lead generation: &#34;Find Shopify stores launched recently that sell skincare products. I want the store URLs, founder names, emails, Instagram handles, and product categories.&#34; (<a href="https://www.webhound.ai/dataset/b63d148a-8895-4aab-ac34-455e341c67c8">https://www.webhound.ai/dataset/b63d148a-8895-4aab-ac34-455e...</a>)</p><p>Pricing tracking: &#34;Track how the free and paid plans of note-taking apps have changed over the past 6 months using official sites and changelogs. List each app with a timeline of changes and the source for each.&#34; (<a href="https://www.webhound.ai/dataset/c17e6033-5d00-4e54-baf6-8deab09e85d7">https://www.webhound.ai/dataset/c17e6033-5d00-4e54-baf6-8dea...</a>)</p><p>Investor mapping: &#34;Find VCs who led or participated in pre-seed or seed rounds for browser-based devtools startups in the past year. Include the VC name, relevant partners, contact info, and portfolio links for context.&#34; (<a href="https://www.webhound.ai/dataset/1480c053-d86b-40ce-a620-37fda3444340">https://www.webhound.ai/dataset/1480c053-d86b-40ce-a620-37fd...</a>)</p><p>Research collection: &#34;Get a list of recent arXiv papers on weak supervision in NLP. For each, include the abstract, citation count, publication date, and a GitHub repo if available.&#34; (<a href="https://www.webhound.ai/dataset/e274ca26-0513-4296-85a5-2b7b7c423ce2">https://www.webhound.ai/dataset/e274ca26-0513-4296-85a5-2b7b...</a>)</p><p>Hypothesis testing: &#34;Check if user complaints about Figma&#39;s performance on large files have increased in the last 3 months. Search forums like Hacker News, Reddit, and Figma&#39;s community site and show the most relevant posts with timestamps and engagement metrics.&#34; (<a href="https://www.webhound.ai/dataset/42b2de49-acbf-4851-bbb7-080b66e845cd">https://www.webhound.ai/dataset/42b2de49-acbf-4851-bbb7-080b...</a>)</p><p>The first version of Webhound was a single agent running on Claude 4 Sonnet. It worked, but sessions routinely cost over $1100 and it would often get lost in infinite loops. We knew that wasn&#39;t sustainable, so we started building around smaller models.</p><p>That meant adding more structure. We introduced a multi-agent system to keep it reliable and accurate. There&#39;s a main agent, a set of search agents that run subtasks in parallel, a critic agent that keeps things on track, and a validator that double-checks extracted data before saving it. We also gave it a notepad for long-term memory, which helps avoid duplicates and keeps track of what it&#39;s already seen.</p><p>After switching to Gemini 2.5 Flash and layering in the agent system, we were able to cut costs by more than 30x while also improving speed and output quality.</p><p>The system runs in two phases. First is planning, where it decides the schema, how to search, what sources to use, and how to know when it&#39;s done. Then comes extraction, where it executes the plan and gathers the data.</p><p>It uses a text-based browser we built that renders pages as markdown and extracts content directly. We tried full browser use but it was slower and less reliable. Plain text still works better for this kind of task.</p><p>We also built scheduled refreshes to keep datasets up to date and an API so you can integrate the data directly into your workflows.</p><p>Right now, everything stays in the agent&#39;s context during a run. It starts to break down around 1000-5000 rows depending on the number of attributes. We&#39;re working on a better architecture for scaling past that.</p><p>We&#39;d love feedback, especially from anyone who&#39;s tried solving this problem or built similar tools. Happy to answer anything in the thread.</p><p>Thanks!
Moe</p></div></td></div></div>
  </body>
</html>
