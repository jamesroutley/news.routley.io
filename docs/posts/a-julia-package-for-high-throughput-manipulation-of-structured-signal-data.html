<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/beacon-biosignals/Onda.jl">Original</a>
    <h1>A Julia package for high-throughput manipulation of structured signal data</h1>
    
    <div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text">
<p dir="auto"><a href="https://github.com/beacon-biosignals/Onda.jl/actions/workflows/CI.yml"><img src="https://github.com/beacon-biosignals/Onda.jl/actions/workflows/CI.yml/badge.svg" alt="CI"/></a>
<a href="https://codecov.io/gh/beacon-biosignals/Onda.jl" rel="nofollow"><img src="https://camo.githubusercontent.com/77cd4dd1396e86d8fc629a167835698066f03bf45358d26574bd13bac0cb065d/68747470733a2f2f636f6465636f762e696f2f67682f626561636f6e2d62696f7369676e616c732f4f6e64612e6a6c2f6272616e63682f6d61737465722f67726170682f62616467652e7376673f746f6b656e3d44306263493052747377" alt="codecov" data-canonical-src="https://codecov.io/gh/beacon-biosignals/Onda.jl/branch/master/graph/badge.svg?token=D0bcI0Rtsw"/></a>
<a href="https://beacon-biosignals.github.io/Onda.jl/stable" rel="nofollow"><img src="https://camo.githubusercontent.com/c97f0a5f2ae95755f64a27f1aa8d9a17462941fd3d6c907c7630abd5d3e60acf/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d737461626c652d626c75652e737667" alt="" data-canonical-src="https://img.shields.io/badge/docs-stable-blue.svg"/></a>
<a href="https://beacon-biosignals.github.io/Onda.jl/dev" rel="nofollow"><img src="https://camo.githubusercontent.com/7fcec4b2d3ab291529fce8ef6a4fcd4129a0683b2f5d5fe2f5c648f02db8b616/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6465762d626c75652e737667" alt="" data-canonical-src="https://img.shields.io/badge/docs-dev-blue.svg"/></a>
<a href="https://github.com/jrevels/YASGuide"><img src="https://camo.githubusercontent.com/1fbd9ec0fa9c8e14c4960591bab07507da2ae468c5b17356491731b8c130c0e0/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f636f64652532307374796c652d7961732d76696f6c65742e737667" alt="Code Style: YASGuide" data-canonical-src="https://img.shields.io/badge/code%20style-yas-violet.svg"/></a></p>
<p dir="auto"><a href="https://github.com/beacon-biosignals/Onda.jl/tree/master/examples/tour.jl">Take The Tour</a></p>
<p dir="auto"><a href="https://github.com/beacon-biosignals/Onda.jl/tree/master/examples">See Other Examples</a></p>
<p dir="auto">Onda.jl is a Julia package for high-throughput manipulation of structured LPCM signal data across arbitrary domain-specific encodings, file formats and storage layers.</p>
<h2 dir="auto"><a id="user-content-the-onda-format-specification" aria-hidden="true" href="#the-onda-format-specification"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>The Onda Format Specification</h2>
<p dir="auto"><strong>Onda</strong> is a lightweight format defined atop <a href="https://arrow.apache.org/" rel="nofollow">Apache Arrow</a> for storing and manipulating sets of multi-sensor, multi-channel, LPCM-encodable, annotated, time-series recordings.</p>
<p dir="auto">This format is intentionally language-agnostic; any consumer/producer that supports Apache Arrow can read/write Onda-compliant Arrow tables. For the sake of convenience, the Onda specification resides here (in the Onda.jl repository) and leverages the <a href="https://github.com/beacon-biosignals/Legolas.jl">Legolas</a> framework to both define and version the Arrow table schemas relevant to the format.</p>
<h3 dir="auto"><a id="user-content-terminology" aria-hidden="true" href="#terminology"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Terminology</h3>
<p dir="auto">This document uses the term...</p>
<ul dir="auto">
<li>
<p dir="auto">...<strong>&#34;LPCM&#34;</strong> to refer to <a href="https://en.wikipedia.org/wiki/Pulse-code_modulation" rel="nofollow">linear pulse code modulation</a>, a form of signal encoding where multivariate waveforms are digitized as a series of samples uniformly spaced over time and quantized to a uniformly spaced grid.</p>
</li>
<li>
<p dir="auto">...<strong>&#34;signal&#34;</strong> to refer to the digitized output of a process. We refer to the &#34;devices&#34; (physical, or virtual) that sample processes to generate signals as <em>sensors</em>. A signal is comprised of metadata (e.g. LPCM encoding, sensor information, channel information, sample data path/format information, etc.) and associated multi-channel sample data.</p>
</li>
<li>
<p dir="auto">...<strong>&#34;recording&#34;</strong> to refer a collection of one or more signals recorded simultaneously over some time period.</p>
</li>
<li>
<p dir="auto">...<strong>&#34;annotation&#34;</strong> to refer to a piece of (meta)data associated with a specific time span within a specific recording.</p>
</li>
</ul>
<h3 dir="auto"><a id="user-content-design-principles" aria-hidden="true" href="#design-principles"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Design Principles</h3>
<h4 dir="auto"><a id="user-content-onda-is-useful" aria-hidden="true" href="#onda-is-useful"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Onda is useful...</h4>
<ul dir="auto">
<li>...when segments of a signal can fit in memory simultaneously, but an entire signal cannot.</li>
<li>...when each signal in each recording in your dataset can fit in memory, but not all signals in each recording can fit in memory simultaneously.</li>
<li>...when each recording in your dataset can fit in memory, but not all recordings in your dataset can fit in memory simultaneously.</li>
<li>...when your dataset&#39;s signals benefit from sensor-specific encodings/compression codecs.</li>
<li>...as an intermediate target format for wrangling unstructured signal data before bulk ingestion into a larger data store.</li>
<li>...as an intermediate target format for local experimentation after bulk retrieval from a larger data store.</li>
<li>...as a format for sharing datasets comprised of several gigabytes to several terabytes of signal data.</li>
<li>...as a format for sharing datasets comprised of hundreds to hundreds of thousands of recordings.</li>
</ul>
<h4 dir="auto"><a id="user-content-ondas-design-must" aria-hidden="true" href="#ondas-design-must"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Onda&#39;s design must...</h4>
<ul dir="auto">
<li>...depend only upon technologies with standardized, implementation-agnostic specifications that are well-used across multiple application domains.</li>
<li>...support recordings where each signal in the recording may have a unique channel layout, physical unit resolution, bit depth and sample rate.</li>
<li>...be well-suited for ingestion into/retrieval from...
<ul dir="auto">
<li>...popular distributed analytics tools (e.g. Spark, TensorFlow).</li>
<li>...traditional databases (e.g. PostgresSQL, Cassandra).</li>
<li>...object-based storage systems (e.g. S3, GCP Cloud Storage).</li>
</ul>
</li>
<li>...enable metadata, annotations etc. to be stored and processed separately from raw sample data without significant communication overhead.</li>
<li>...enable extensibility without sacrificing interpretability. New signal encodings, annotations, sample data file formats, etc. should all be user-definable by design.</li>
<li>...be simple enough that a decent programmer (with Google access) should be able to fully interpret (and write performant parsers for) an Onda dataset without ever reading Onda documentation.</li>
</ul>
<h4 dir="auto"><a id="user-content-onda-is-not" aria-hidden="true" href="#onda-is-not"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Onda is not...</h4>
<ul dir="auto">
<li>...a sample data file format. Onda allows dataset authors to utilize whatever file format is most appropriate for a given signal&#39;s sample data, as long as the author provides a mechanism to deserialize sample data from that format to a standardized interleaved LPCM representation.</li>
<li>...a transactional database. The majority of an Onda dataset&#39;s mandated metadata is stored in tabular manifests containing recording information, signal descriptions, annotations etc. This simple structure is tailored towards Onda&#39;s target regimes (see above), and is not intended to serve as a persistent backend for external services/applications.</li>
<li>...an analytics platform. Onda seeks to provide a data model that is purposefully structured to enable various sorts of analysis, but the format itself does not mandate/describe any specific implementation of analysis utilities.</li>
</ul>
<h3 dir="auto"><a id="user-content-schema-definitions" aria-hidden="true" href="#schema-definitions"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Schema Definitions</h3>
<p dir="auto">The Onda format primarily consists of a collection of interelated <a href="https://github.com/beacon-biosignals/Legolas.jl">Legolas</a> schemas:</p>
<ul dir="auto">
<li><code>onda.signal</code>: metadata that describes a <strong>signal</strong> as previously defined, including LPCM encoding, channel information, sample data path/format, etc.</li>
<li><code>onda.annotation</code>: metadata that describes an <strong>annotation</strong> as previously defined, including the recording of interest, the time span of interest, etc.</li>
</ul>
<p dir="auto">These schemas are largely orthogonal to one another - here&#39;s nothing inherent to the Onda format that prevents a dataset producer/consumer from separately constructing/manipulating/transferring/analyzing an <code>onda.signal</code> table and <code>onda.annotation</code> table. Furthermore, there&#39;s nothing that prevents dataset producers/consumers from working with multiple tables of the same schema, referencing the same set of recordings (e.g. splitting all of a dataset&#39;s annotations across multiple <code>onda.annotation</code> tables).</p>
<p dir="auto">The following sections provide <a href="https://beacon-biosignals.github.io/Legolas.jl/stable/schema/" rel="nofollow">the version integer</a>, per-column documentation, and examples for each of the above Legolas schemas. In accordance with the Legolas framework, a table is considered to comply with a given schema as long as the specified required columns for that schema are present in any order. While per-column documentation refers to the <a href="https://github.com/apache/arrow/blob/master/format/Schema.fbs">logical types defined by the Arrow specification</a>, Onda reader/writer implementations may additionally employ Arrow extension types that directly alias a column&#39;s specified logical type in order to support application-level features (first-class UUID support, custom <code>file_path</code> type support, etc.).</p>
<h4 dir="auto"><a id="user-content-ondasignal2" aria-hidden="true" href="#ondasignal2"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><code>onda.signal@2</code></h4>
<h5 dir="auto"><a id="user-content-columns" aria-hidden="true" href="#columns"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Columns</h5>
<ul dir="auto">
<li><code>recording</code> (128-bit <code>FixedSizeBinary</code>): The UUID identifying the recording with which the signal is associated.</li>
<li><code>file_path</code> (<code>Utf8</code>): A string identifying the location of the signal&#39;s associated sample data file. This string must either be a <a href="https://en.wikipedia.org/wiki/Uniform_Resource_Identifier" rel="nofollow">valid URI</a> or a file path relative to the location of the <code>onda.signal</code> table itself.</li>
<li><code>file_format</code> (<code>Utf8</code>): A string identifying the format of the signal&#39;s associated sample data file. All Onda reader/writer implementations must support the following file formats (and may define and support additional values as desired):
<ul dir="auto">
<li><code>&#34;lpcm&#34;</code>: signals are stored in raw interleaved LPCM format (see format description below).</li>
<li><code>&#34;lpcm.zst&#34;</code>: signals stored in raw interleaved LPCM format and compressed via <a href="https://github.com/facebook/zstd"><code>zstd</code></a></li>
</ul>
</li>
<li><code>span</code> (<code>Struct</code>): The signal&#39;s time span within the recording. This structure has two fields:
<ul dir="auto">
<li><code>start</code> (<code>Duration</code> w/ <code>NANOSECOND</code> unit): The start offset in nanoseconds from the beginning of the recording. The minimum possible value is <code>0</code>.</li>
<li><code>stop</code> (<code>Duration</code> w/ <code>NANOSECOND</code> unit): The stop offset in nanoseconds (exclusive) from the beginning of the recording. This value must be greater than <code>start</code>.</li>
</ul>
</li>
<li><code>sensor_type</code> (<code>Utf8</code>): A string identifying the &#34;type&#34; of the multichannel sensor that generated the signal. The notion of sensor type is somewhat application-specific; it may refer to a kind of device, a particular data modality, etc. Valid <code>sensor_type</code> values are alphanumeric, nonempty, lowercase, <code>snake_case</code>, and contain no whitespace, punctuation, or leading/trailing underscores.</li>
<li><code>sensor_label</code> (<code>Utf8</code>): A string that, within the context a given recording, uniquely identifies the multichannel sensor that generated the signal. This field is often equivalent to <code>sensor_type</code> in applications where each sensor in a given recording is of a different type, but is especially useful in contexts where a single recording contains multiple signals with the same <code>sensor_type</code>. Valid values of <code>sensor_label</code> follow the same format as valid <code>sensor_type</code> values.</li>
<li><code>channels</code> (<code>List</code> of <code>Utf8</code>): A list of strings where the <code>i</code>th element is the name of the signal&#39;s <code>i</code>th channel. A valid channel name...
<ul dir="auto">
<li>...is alphanumeric, nonempty, lowercase, <code>snake_case</code>, and contain no whitespace, punctuation, or leading/trailing underscores. Additional allowed characters include: <code>-</code>, <code>+</code>, <code>(</code>, <code>)</code>, <code>/</code>, <code>.</code>. If parentheses are used, they must be balanced, i.e. a matching closing parenthesis must be included for every open parenthesis.</li>
<li>To allow arbitrary cross-signal referencing, a channel name may reference channel names from other signals contained in the recording. Any such reference should take the form <code>sensor_label.channel_name</code>. For example, an <code>eog</code> signal might have a channel named <code>left-eeg.m1</code> (the left eye electrode referenced to the mastoid electrode from a 10-20 EEG signal).</li>
<li>...is unique amongst the other channel names in the signal. In other words, duplicate channel names within the same signal are disallowed.</li>
</ul>
</li>
<li><code>sample_unit</code> (<code>Utf8</code>): The name of the signal&#39;s canonical unit as a string. This string should conform to the same format as <code>kind</code> (alphanumeric, nonempty, lowercase, <code>snake_case</code>, and contain no whitespace, punctuation, or leading/trailing underscores), should be singular and not contain abbreviations (e.g. <code>&#34;uV&#34;</code> is bad, <code>&#34;microvolt&#34;</code> is good; <code>&#34;l/m&#34;</code> is bad, <code>&#34;liter_per_minute&#34;</code> is good).</li>
<li><code>sample_resolution_in_unit</code> (<code>FloatingPoint{DOUBLE}</code>): The signal&#39;s resolution in its canonical unit. This value, along with the signal&#39;s <code>sample_type</code> and <code>sample_offset_in_unit</code> fields, determines the signal&#39;s LPCM quantization scheme.</li>
<li><code>sample_offset_in_unit</code>  (<code>FloatingPoint{DOUBLE}</code>): The signal&#39;s zero-offset in its canonical unit (thus allowing LPCM encodings that are centered around non-zero values).</li>
<li><code>sample_type</code> (<code>Utf8</code>): The primitive scalar type used to encode each sample in the signal. Valid values are:
<ul dir="auto">
<li><code>&#34;int8&#34;</code>: signed little-endian 1-byte integer</li>
<li><code>&#34;int16&#34;</code>: signed little-endian 2-byte integer</li>
<li><code>&#34;int32&#34;</code>: signed little-endian 4-byte integer</li>
<li><code>&#34;int64&#34;</code>: signed little-endian 8-byte integer</li>
<li><code>&#34;uint8&#34;</code>: unsigned little-endian 1-byte integer</li>
<li><code>&#34;uint16&#34;</code>: unsigned little-endian 2-byte integer</li>
<li><code>&#34;uint32&#34;</code>: unsigned little-endian 4-byte integer</li>
<li><code>&#34;uint64&#34;</code>: unsigned little-endian 8-byte integer</li>
<li><code>&#34;float32&#34;</code>: 32-bit floating point number</li>
<li><code>&#34;float64&#34;</code>: 64-bit floating point number</li>
</ul>
</li>
<li><code>sample_rate</code> (<code>FloatingPoint{DOUBLE}</code>): The signal&#39;s sample rate in samples per second.</li>
</ul>
<p dir="auto">Note that the <code>onda.signal@2</code> specification allows for the simultaneous existence of multiple <code>onda.signal@2</code> instances with the same <code>sensor_label</code> and <code>recording</code>, even though <code>sensor_label</code> is defined to act as a unique (within the context of the recording) identifier of the signal&#39;s sensor. This is because a recording may contain multiple <em>discontiguous</em> signals generated from the same underlying sensor at different time points, as specified by each signal&#39;s <code>span</code>. Thus, signals that share a common sensor within the same recording in this manner should have non-overlapping <code>span</code>s, but note that this property might not be holistically enforceable by Onda reader/writer implementations in all cases. Beyond this definition, further specification for the intepretation of discontinuous sample data for specific <code>sensor_type</code>s/<code>recording</code>s/etc. is left to downstream, use-case-specific extensions of <code>onda.signal@2</code>.</p>
<p dir="auto">For example, there may exist an <code>onda.signal@2</code> with <code>sensor_label=&#34;eeg&#34;</code> and <code>span=(start=Nanosecond(0), stop=Nanosecond(1e9))</code>, and another with the same <code>recording</code>/<code>sensor_label</code> but with <code>span=(start=Nanosecond(2e9), stop=Nanosecond(3e9))</code>. Downstream consumers may interpret this as two EEG signals from the same sensor, sampled at different time points: the sensor generated the first 1-second signal at the beginning of the recording, followed by a 1 second gap, followed by another second of sampling.</p>
<p dir="auto">When feasible in practice, it is recommended that data producers manually concatenate discontiguous sample data into a single signal and use <code>NaN</code> values to represent unsampled regions, rather than represent discontiguous segments via separate signals, as the former approach is often more convenient than the latter for downstream consumers.</p>
<h5 dir="auto"><a id="user-content-examples" aria-hidden="true" href="#examples"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Examples</h5>
<table>
<thead>
<tr>
<th><code>recording</code></th>
<th><code>file_path</code></th>
<th><code>file_format</code></th>
<th><code>span</code></th>
<th><code>kind</code></th>
<th><code>channels</code></th>
<th><code>sample_unit</code></th>
<th><code>sample_resolution_in_unit</code></th>
<th><code>sample_offset_in_unit</code></th>
<th><code>sample_type</code></th>
<th><code>sample_rate</code></th>
<th><code>my_custom_value</code></th>
</tr>
</thead>
<tbody>
<tr>
<td><code>0xb14d2c6d8d844e46824f5c5d857215b4</code></td>
<td><code>&#34;./relative/path/to/samples.lpcm&#34;</code></td>
<td><code>&#34;lpcm&#34;</code></td>
<td><code>(start=10e9, stop=10900e9)</code></td>
<td><code>&#34;eeg&#34;</code></td>
<td><code>[&#34;fp1&#34;, &#34;f3&#34;, &#34;f7&#34;, &#34;fz&#34;, &#34;f4&#34;, &#34;f8&#34;]</code></td>
<td><code>&#34;microvolt&#34;</code></td>
<td><code>0.25</code></td>
<td><code>3.6</code></td>
<td><code>&#34;int16&#34;</code></td>
<td><code>256.0</code></td>
<td><code>&#34;this is a value&#34;</code></td>
</tr>
<tr>
<td><code>0xb14d2c6d8d844e46824f5c5d857215b4</code></td>
<td><code>&#34;s3://bucket/prefix/obj.lpcm.zst&#34;</code></td>
<td><code>&#34;lpcm.zst&#34;</code></td>
<td><code>(start=0, stop=10800e9)</code></td>
<td><code>&#34;ecg&#34;</code></td>
<td><code>[&#34;avl&#34;, &#34;avr&#34;]</code></td>
<td><code>&#34;microvolt&#34;</code></td>
<td><code>0.5</code></td>
<td><code>1.0</code></td>
<td><code>&#34;int16&#34;</code></td>
<td><code>128.3</code></td>
<td><code>&#34;this is a different value&#34;</code></td>
</tr>
<tr>
<td><code>0x625fa5eadfb24252b58d1eb350fa7df6</code></td>
<td><code>&#34;s3://other-bucket/prefix/obj_with_no_extension&#34;</code></td>
<td><code>&#34;flac&#34;</code></td>
<td><code>(start=100e9, stop=500e9)</code></td>
<td><code>&#34;audio&#34;</code></td>
<td><code>[&#34;left&#34;, &#34;right&#34;]</code></td>
<td><code>&#34;scalar&#34;</code></td>
<td><code>1.0</code></td>
<td><code>0.0</code></td>
<td><code>&#34;float32&#34;</code></td>
<td><code>44100.0</code></td>
<td><code>&#34;this is another value&#34;</code></td>
</tr>
<tr>
<td><code>0xa5c01f0e50fe4acba065fcf474e263f5</code></td>
<td><code>&#34;./another-relative/path/to/samples&#34;</code></td>
<td><code>&#34;custom_price_format:{\&#34;parseable_json_parameter\&#34;:3}&#34;</code></td>
<td><code>(start=0, stop=3600e9)</code></td>
<td><code>&#34;price&#34;</code></td>
<td><code>[&#34;price&#34;]</code></td>
<td><code>&#34;dollar&#34;</code></td>
<td><code>0.01</code></td>
<td><code>0.0</code></td>
<td><code>&#34;uint32&#34;</code></td>
<td><code>50.75</code></td>
<td><code>&#34;wow what a great value&#34;</code></td>
</tr>
</tbody>
</table>
<h5 dir="auto"><a id="user-content-sample-data-files" aria-hidden="true" href="#sample-data-files"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Sample Data Files</h5>
<p dir="auto">The sample data file referenced by a signal&#39;s <code>file_path</code> field must be encoded as specified by that signal&#39;s <code>sample_type</code>, <code>sample_resolution_in_unit</code>, and <code>sample_offset_in_unit</code> fields, serialized to raw LPCM format, and formatted as specified by the signal&#39;s <code>file_format</code> field.</p>
<p dir="auto">While Onda explicitly supports arbitrary choice of file format for serialized sample data via the <code>file_format</code> field, Onda reader/writer implementations should support (de)serialization of sample data from any implementation-supported format into the following standardized interleaved LPCM in-memory representation:</p>
<p dir="auto">Given an <code>n</code>-channel signal, the byte offset for the <code>i</code>th channel value in the <code>j</code>th multichannel sample is given by <code>((i - 1) + (j - 1) * n) * byte_width(signal.sample_type)</code>. This layout can be expressed in the following table (where <code>w = byte_width(signal.sample_type)</code>):</p>
<table>
<thead>
<tr>
<th>Byte Offset</th>
<th>Value</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>1st channel value for 1st sample</td>
</tr>
<tr>
<td>w</td>
<td>2nd channel value for 1st sample</td>
</tr>
<tr>
<td>...</td>
<td>...</td>
</tr>
<tr>
<td>(n - 1) * w</td>
<td><code>n</code>th channel value for 1st sample</td>
</tr>
<tr>
<td>(n + 0) * w</td>
<td>1st channel value for 2nd sample</td>
</tr>
<tr>
<td>(n + 1) * w</td>
<td>2nd channel value for 2nd sample</td>
</tr>
<tr>
<td>...</td>
<td>...</td>
</tr>
<tr>
<td>(2*n - 1) * w</td>
<td><code>n</code>th channel value for 2nd sample</td>
</tr>
<tr>
<td>(2*n + 0) * w</td>
<td>1st channel value for 3rd sample</td>
</tr>
<tr>
<td>(2*n + 1) * w</td>
<td>2nd channel value for 3rd sample</td>
</tr>
<tr>
<td>...</td>
<td>...</td>
</tr>
<tr>
<td>(3*n - 1) * w</td>
<td><code>n</code>th channel value for 3rd sample</td>
</tr>
<tr>
<td>...</td>
<td>...</td>
</tr>
<tr>
<td>((i - 1) + (j - 1) * n) * w</td>
<td><code>i</code>th channel value for <code>j</code>th sample</td>
</tr>
<tr>
<td>...</td>
<td>...</td>
</tr>
</tbody>
</table>
<p dir="auto">Values are represented in little-endian format.</p>
<p dir="auto">An individual value in a multichannel sample can be converted to its encoded representation from its canonical unit representation via:</p>
<div data-snippet-clipboard-copy-content="encoded_value = (decoded_value - sample_offset_in_unit) / sample_resolution_in_unit"><pre><code>encoded_value = (decoded_value - sample_offset_in_unit) / sample_resolution_in_unit
</code></pre></div>
<p dir="auto">where the division is followed/preceded by whatever quantization strategy is chosen by the user (e.g. rounding/truncation/dithering etc). Complementarily, an individual value in a multichannel sample can be converted (&#34;decoded&#34;) from its encoded representation to its canonical unit representation via:</p>
<div data-snippet-clipboard-copy-content="decoded_value = (encoded_value * sample_resolution_in_unit) + sample_offset_in_unit"><pre><code>decoded_value = (encoded_value * sample_resolution_in_unit) + sample_offset_in_unit
</code></pre></div>
<h5 dir="auto"><a id="user-content-previous-versions" aria-hidden="true" href="#previous-versions"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Previous Versions</h5>
<ul dir="auto">
<li><a href="https://github.com/beacon-biosignals/Onda.jl/tree/v0.14.10#ondasignal1"><code>onda.signal@1</code></a></li>
</ul>
<h4 dir="auto"><a id="user-content-ondaannotation1" aria-hidden="true" href="#ondaannotation1"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a><code>onda.annotation@1</code></h4>
<h5 dir="auto"><a id="user-content-columns-1" aria-hidden="true" href="#columns-1"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Columns</h5>
<ul dir="auto">
<li><code>recording</code> (128-bit <code>FixedSizeBinary</code>): The UUID identifying the recording with which the annotation is associated.</li>
<li><code>id</code> (128-bit <code>FixedSizeBinary</code>): The UUID identifying the annotation.</li>
<li><code>span</code> (<code>Struct</code>): The annotation&#39;s time span within the recording. This has the same structure as the <code>onda.signal</code> schema&#39;s <code>span</code> column (specified in the previous section).</li>
</ul>
<h5 dir="auto"><a id="user-content-examples-1" aria-hidden="true" href="#examples-1"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Examples</h5>
<table>
<thead>
<tr>
<th><code>recording</code></th>
<th><code>id</code></th>
<th><code>span</code></th>
<th><code>my_custom_value</code></th>
</tr>
</thead>
<tbody>
<tr>
<td><code>0xb14d2c6d8d844e46824f5c5d857215b4</code></td>
<td><code>0x81b17ea902504371954e7b8b167236a6</code></td>
<td><code>(start=5e9, stop=6e9)</code></td>
<td><code>&#34;this is a value&#34;</code></td>
</tr>
<tr>
<td><code>0xb14d2c6d8d844e46824f5c5d857215b4</code></td>
<td><code>0xdaebbd1b0cab4b89acdde51f9c9a1d7c</code></td>
<td><code>(start=3e9, stop=7e9)</code></td>
<td><code>&#34;this is a different value&#34;</code></td>
</tr>
<tr>
<td><code>0x625fa5eadfb24252b58d1eb350fa7df6</code></td>
<td><code>0x11aeeb4b743149808b53547642652f0e</code></td>
<td><code>(start=1e9, stop=2e9)</code></td>
<td><code>&#34;this is another value&#34;</code></td>
</tr>
<tr>
<td><code>0xa5c01f0e50fe4acba065fcf474e263f5</code></td>
<td><code>0xbc0be95e3da2495391daba233f035acc</code></td>
<td><code>(start=2e9, stop=3e9)</code></td>
<td><code>&#34;wow what a great value&#34;</code></td>
</tr>
</tbody>
</table>
<h2 dir="auto"><a id="user-content-potential-alternatives" aria-hidden="true" href="#potential-alternatives"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Potential Alternatives</h2>
<p dir="auto">In this section, we describe several alternative technologies/solutions considered during Onda&#39;s design.</p>
<ul dir="auto">
<li>
<p dir="auto">Parquet: We chose to base Onda&#39;s tabular data specification on Arrow, rather than Parquet, because the former is meaningful as an in-memory/interchange format, not just as a storage format. Onda consumers/producers could, of course, (de)serialize Onda-formatted Arrow tables to/from Parquet format as they like.</p>
</li>
<li>
<p dir="auto">Various potential sample data storage formats: Early prototypes of Onda were not agnostic to the user&#39;s choice of sample data file format, but instead took a more opinionated approach. Many technologies were considered as a generic underlying file format, including Avro (<a href="https://eng.uber.com/hdfs-file-format-apache-spark/" rel="nofollow">motivated by Uber&#39;s image storage use case</a>), <a href="https://numpy.org/devdocs/reference/generated/numpy.lib.format.html" rel="nofollow">NPY</a>, <a href="https://zarr.readthedocs.io/en/stable/" rel="nofollow">Zarr</a>, and more. The current version of Onda allows reader/writer implementations to support any of these formats as (de)serialization targets, but does not mandate support for any of them. This enables Onda producers/consumers to leverage the format/codec that best suits their domain of interest (e.g. FLAC for audio).</p>
</li>
<li>
<p dir="auto">HDF5: While featureful, ubiquitous, and technically based on an open standard, HDF5 is <a href="https://cyrille.rossant.net/moving-away-hdf5/" rel="nofollow">infamous for being a hefty dependency with a fairly complex reference implementation</a>. While HDF5 solves many problems inherent to filesystem-based storage, most use cases for Onda involve storing large binary blobs in domain-specific formats that already exist quite naturally as files on a filesystem, or as objects in an object storage system. Though it was decided that Onda should not explicitly depend on HDF5, nothing technically precludes Onda-formatted content from being stored in HDF5. For practical purposes, however, Onda readers/writers may not necessarily automatically be able to read such a dataset unless they explicitly support HDF5 as a storage layer (since HDF5 support isn&#39;t mandated by the format).</p>
</li>
<li>
<p dir="auto">EDF/MEF/etc.: Onda was originally motivated by bulk electrophysiological dataset manipulation, a domain in which there are many different recording file formats that are all generally designed to support a one-file-per-recording use case and are constrained to certain domain-specific assumptions (e.g. specific bit depth assumptions, annotations stored within signal artifacts, etc.). Technically, since Onda itself is agnostic to choice of file formats used for signal serialization, one could store Onda sample data in EDF/MEF.</p>
</li>
<li>
<p dir="auto">BIDS: BIDS is an alternative option for storing neuroscience datasets. As mentioned above, Onda&#39;s original motivation is electrophysiological dataset manipulation, so BIDS appeared to be a highly relevant candidate. Unfortunately, BIDS restricts EEG data to <a href="https://bids-specification.readthedocs.io/en/stable/04-modality-specific-files/03-electroencephalography.html#eeg-recording-data" rel="nofollow">very specific file formats</a> and also does not account for the plurality of LPCM-encodable signals that Onda seeks to handle generically.</p>
</li>
<li>
<p dir="auto">MessagePack: An early version of Onda used MessagePack to store all signal/annotation metadata. See <a href="https://github.com/beacon-biosignals/OndaFormat/issues/25" data-hovercard-type="issue" data-hovercard-url="/beacon-biosignals/OndaFormat/issues/25/hovercard">this issue</a> for background on the switch to Arrow.</p>
</li>
<li>
<p dir="auto">JSON: In early Onda prototypes, JSON was used to serialize signal/annotation metadata. While JSON has the advantage of being ubiquitous/simple/flexible/human-readable, the performance overhead of textual decoding/encoding was greater than desired for datasets with lots of annotations. In comparison, switching to MessagePack yielded a ~3x performance increase in (de)serialization for practical usage. The subsequent switch from MessagePack to Arrow in modern versions of the Onda format yielded even greater (de)serialization improvements.</p>
</li>
<li>
<p dir="auto">BSON: BSON was considered as a potential serialization format for signal/annotation metadata. In pre-Arrow versions of Onda, MessagePack was chosen over BSON due to the latter&#39;s relative complexity compared to the former. In Onda&#39;s current version, BSON remains less preferable than Arrow from a tabular data representation perspective.</p>
</li>
</ul>
<h3 dir="auto"><a id="user-content-older-versions-of-the-format" aria-hidden="true" href="#older-versions-of-the-format"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path fill-rule="evenodd" d="M7.775 3.275a.75.75 0 001.06 1.06l1.25-1.25a2 2 0 112.83 2.83l-2.5 2.5a2 2 0 01-2.83 0 .75.75 0 00-1.06 1.06 3.5 3.5 0 004.95 0l2.5-2.5a3.5 3.5 0 00-4.95-4.95l-1.25 1.25zm-4.69 9.64a2 2 0 010-2.83l2.5-2.5a2 2 0 012.83 0 .75.75 0 001.06-1.06 3.5 3.5 0 00-4.95 0l-2.5 2.5a3.5 3.5 0 004.95 4.95l1.25-1.25a.75.75 0 00-1.06-1.06l-1.25 1.25a2 2 0 01-2.83 0z"></path></svg></a>Older Versions Of The Format</h3>
<p dir="auto">Before the Onda.jl v0.14 release, the Onda Format Specification resided in a separate repository. This repository is now archived, but its contents and issue tracker are still available for historical purposes in a read-only fashion at <a href="https://github.com/beacon-biosignals/OndaFormat">https://github.com/beacon-biosignals/OndaFormat</a>.</p>
</article>
          </div></div>
  </body>
</html>
