<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://win-vector.com/2026/01/27/how-many-chess-games-are-possible/">Original</a>
    <h1>How many chess games are possible?</h1>
    
    <div id="readability-page-1" class="page"><article id="post-21373">
	
		<p>
By  on <a href="https://win-vector.com/2026/01/27/how-many-chess-games-are-possible/" title="11:57 am" rel="bookmark"><time datetime="2026-01-27T11:57:09-08:00">January 27, 2026</time></a>	• 
	</p>
	<section>

<div id="cell-id=d46bc079">
<div tabindex="0">

<div>
<p>
Here is a fun question: how many different games of chess are possible? Counting the number of possible chess games is quite hard, as the numbers are large and chess board positions can be quite complicated. In this note we will try to estimate the number of possible short games of chess.
</p>
</div>
</div>
</div>

<div id="cell-id=d34cb679">
<div tabindex="0">

<div>
<p data-mime-type="text/markdown">
<h2>Long games with many possibilities</h2>
</p>
</div>
</div>
</div>



<div id="cell-id=150cbe80">
<div tabindex="0">

<div>
<div data-mime-type="text/markdown"><p>
This allows Labelle to bound the number of possible long chess games to the range 10<sup>29241</sup> to 10<sup>34082</sup>.</p>
<p>We will restrict ourselves to typical and short chess games.
</p></div>
</div>
</div>
</div>
<div id="cell-id=37bbb268">
<div tabindex="0">

<div>
<p data-mime-type="text/markdown">
<h2>Warmup: the number of typical games by the Fermi problem method</h2>
</p>
</div>
</div>
</div>
<div id="cell-id=3cfd8d86">
<div tabindex="0">

<div>
<div data-mime-type="text/markdown"><p>
The <a href="https://en.wikipedia.org/wiki/Fermi_problem">Fermi problem method</a> is to propose an approximate break-down of what we want to know into arithmetic over a few other things we can in turn try to estimate. The trick is to pick a arithmetic form that is both simple enough to calculate over and plausible enough to be a good estimate.</p>
<p>For the chess problem we propose the estimate <code>number_of_typical_games ~ typical_number_of_options_per_move<sup>typical_number_of_moves_per_game</sup></code>. This equation is subjective, in that it isn’t yet justified beyond our opinion that it might be a good estimate. It is then a matter of finding usable values for <code>typical_number_of_moves_per_game</code> and <code>typical_number_of_options_per_move</code>.
</p></div>
</div>
</div>
</div>

<div id="cell-id=b5e3c7db">
<div tabindex="0">

<div>
<p>
We also need to know how many different possible moves a player is typically considering. We get an estimate by examining a puzzle from <a href="https://lichess.org">Lichess.org</a>:
</p>
</div>
</div>
</div>



<div id="cell-id=9a377fcb">
<div tabindex="0">

<div>
<div data-mime-type="text/markdown"><p>
We can work out that black has 46 legal moves by counting. We write this as 10<sup>log10(46)</sup> ~ 10<sup>1.66</sup> for easier calculation.</p>
<p>Then our Fermi estimate is that there are easily on order of (10<sup>1.66</sup>)<sup>100</sup> = 10<sup>166</sup> typical games of chess. This has some of the grace I tried to describe in <a href="https://win-vector.com/2009/05/12/the-joy-of-calculation/">“The Joy of Calculation”</a>.
</p></div>
</div>
</div>
</div>
<div id="cell-id=af86089d">
<div tabindex="0">

<div>
<p>
This sort of argument was famously used by Claude Shannon to argue a lower bound of 10<sup>120</sup> possible chess games (<a href="https://en.wikipedia.org/wiki/Shannon_number">ref</a>).
</p>
</div>
</div>
</div>
<div id="cell-id=ce0458ef">
<div tabindex="0">

<div>
<p>
These estimates, while useful, are subjective, far apart, and sensitive to the subjective ad-hoc inputs. We will address this in the next sections.
</p>
</div>
</div>
</div>
<div id="cell-id=4b9f3914">
<div tabindex="0">

<div>
<p data-mime-type="text/markdown">
<h2>The Knuth path product estimate</h2>
</p>
</div>
</div>
</div>
<div id="cell-id=59ec6df7">
<div tabindex="0">

<div>
<p data-mime-type="text/markdown">
<h3>Estimating from a single game</h3>
</p>
</div>
</div>
</div>

<div id="cell-id=60790240">
<div tabindex="0">

<div>
<p>
To keep things simple, we are going limit ourselves to “short chess games.” We define “short” as games taking no more than 100 half moves to achieve an end condition (win, lose, stalemate, or draw by the rules of chess as implemented in the Python chess package- including insufficient material for mate detection). We can sample from this population of games by generating games through the process of picking legal moves uniformly at random, and rejecting samples that exceed the half move limit before achieving an ending condition.
</p>
</div>
</div>
</div>
<div id="cell-id=609fc426">
<div tabindex="0">

<div>
<p>
We consider a single sample game <code>g</code> generated by generating legal moves uniformly at random.
</p>
</div>
</div>
</div>



<div id="cell-id=6f42be84">
<div tabindex="0">

<div>
<div data-mime-type="text/markdown"><p>
Given our sample working chess game “<code>g</code>” we then replace our Fermi estimate of</p>
<pre>   <code>typical_number_of_options_per_move<sup>typical_number_of_moves_per_game</sup></code>
</pre>
<p>with Knuth’s path product estimator</p>
<pre>   <code>p(g) = ∏<sub>i</sub> number_of_legal_moves_in_position(g[i])</code>
</pre>
<p>where <code>g[i]</code> is the <code>i</code>-th position in the single game <code>g</code> we are examining.</p>
<p>If the sample game was exactly typical (i.e. lasted for exactly <code>typical_number_of_moves_per_game</code> half moves and always had <code>typical_number_of_options_per_move</code> legal moves per position) these two calculations would be identical. Things are rarely so perfectly “typical”, so we expect this new estimate to often be over or under the original Fermi method estimate (depending on which game we use as our working example).
</p></div>
</div>
</div>
</div>
<div id="cell-id=41becef3">
<div tabindex="0">

<div>
<div data-mime-type="text/markdown">
<p><a href="https://www.ams.org/journals/mcom/1975-29-129/S0025-5718-1975-0373371-6/S0025-5718-1975-0373371-6.pdf">Knuth proved</a> this path product estimate is quite good in the following technical sense.</p>
<p>Let <code>G</code> be the set of all possible short chess games. We want to know <code>|G|</code>, the size of <code>G</code>. The issue is <code>|G|</code> is so large that we can not hope to directly enumerate all of the elements of <code>G</code> to directly perform the counting.</p>
<p>Theorem: <code>(1 / |G|) ∑<sub>g in G</sub> p(g) = |G|</code>.</p>
<p>This is traditionally written in terms of the <a href="https://en.wikipedia.org/wiki/Expected_value">expected value</a> operator as <code>E<sub>g in G</sub>[p(g)] = |G|</code>.</p>
<p>Knuth considered this surprising enough that he wrote: “We shall consider two proofs, at least one of which should be convincing.”</p>
<p>The point is: we can approximate the average on the left side of the equations, and this now means we can approximate <code>|G|</code>.
</p></div>
</div>
</div>
</div>

<div id="cell-id=513442f5">
<div tabindex="0">

<div>
<p>
In our case our new single game based path product estimate for the total number of possible short chess games is: 10<sup>116.96179</sup>. As we are dealing with large numbers we will content ourselves with <a href="https://en.wikipedia.org/wiki/Order_of_magnitude">“order of magnitude”</a> measurements and just reporting an approximation with an integer exponent. So we will round the exponent and take our estimate as 10<sup>117</sup>.
</p>
</div>
</div>
</div>
<div id="cell-id=16fb84ef">
<div tabindex="0">

<div>
<p data-mime-type="text/markdown">
<h3>Estimating from many games</h3>
</p>
</div>
</div>
</div>
<div id="cell-id=10baa006">
<div tabindex="0">

<div>
<p>
The usual way to improve expected value estimates is averaging more examples. We consider a sample of 10000 independently generated games.
</p>
</div>
</div>
</div>

<div id="cell-id=fe126a40">
<div tabindex="0">

<div>
<p>
In this sample the log 10 of our different size estimates are distributed as follows.
</p>
</div>
</div>
</div>
<div id="cell-id=87c5505f">
<div>

<div>
<div>
<p><img data-recalc-dims="1" loading="lazy" decoding="async" alt="No description has been provided for this image" height="394" src="https://i0.wp.com/win-vector.com/wp-content/uploads/2026/01/DisplayGames_31_0.png?resize=656%2C394&amp;ssl=1" width="656"/>
</p>
</div>
</div>
</div>
</div>


<div id="cell-id=bec1a493">
<div tabindex="0">

<div>
<p>
The average estimate from this sample (which we <em>hope</em> is not too far from the average of the population it is being drawn from) is 10<sup>151</sup>.
</p>
</div>
</div>
</div>
<div id="cell-id=497ed517">
<div tabindex="0">

<div>
<p>
Unfortunately, the observed <a href="https://en.wikipedia.org/wiki/Standard_error">standard error</a> (or observed uncertainty in our estimate of the average) is just as large. In this circumstance this means we shouldn’t consider the sample reliable.
</p>
</div>
</div>
</div>

<div id="cell-id=2ae630f2">
<div tabindex="0">

<div>
<p>
We try to solve this variance issue by using an independent second larger sample from a larger simulation run.
</p>
</div>
</div>
</div>



<div id="cell-id=95a4b832">
<div tabindex="0">

<div>
<p>
We can look at subsets of our larger (size 1000000) sample to explore how the estimate behaves with respect to varying sample size.
</p>
</div>
</div>
</div>
<div id="cell-id=8b1f03a7">
<div>

<div>
<div>
<p><img data-recalc-dims="1" loading="lazy" decoding="async" alt="No description has been provided for this image" height="394" src="https://i0.wp.com/win-vector.com/wp-content/uploads/2026/01/DisplayGames_42_0.png?resize=656%2C394&amp;ssl=1" width="656"/>
</p>
</div>
</div>
</div>
</div>
<div id="cell-id=a019acca">
<div tabindex="0">

<div>
<p>
The initial jumps and trend-like behavior of this graph is the sample becoming big enough to find important rare large examples. Without additional arguments we can’t be certain there are not more of these un-encountered large estimates for any reasonable sample size, meaning there are some remaining risks in this estimate. We are looking for this estimate to stabilize at a given value. We also are looking for the ratio of the standard error (observed uncertainty in the estimate) over the estimate to drop below 1. This ratio is called the <a href="https://en.wikipedia.org/wiki/Coefficient_of_variation">coefficient of variation</a>, and we plot this below.
</p>
</div>
</div>
</div>
<div id="cell-id=a3d35e31">
<div>

<div>
<div>
<p><img data-recalc-dims="1" loading="lazy" decoding="async" alt="No description has been provided for this image" height="394" src="https://i0.wp.com/win-vector.com/wp-content/uploads/2026/01/DisplayGames_44_0.png?resize=656%2C394&amp;ssl=1" width="656"/>
</p>
</div>
</div>
</div>
</div>
<div id="cell-id=0b6b7578">
<div tabindex="0">

<div>
<p>
We want the coefficient of variation to be smaller than 1. This would imply the sample estimate is at least not contradicting itself. We are starting to see this as we move to the larger sample sizes.
</p>
</div>
</div>
</div>

<div id="cell-id=69faf153">
<div tabindex="0">

<div>
<div data-mime-type="text/markdown"><p>
The average estimate from this larger sample sample is again 10<sup>151</sup>. That will be our claimed estimate for the number of possible short chess games.</p></div>
</div>
</div>
</div>
<div id="cell-id=ec806dce">
<div tabindex="0">

<div>
<p data-mime-type="text/markdown">
<h2>How reliable is the path sampling scheme?</h2>
</p>
</div>
</div>
</div>
<div id="cell-id=21f89bc6">
<div tabindex="0">

<div>
<div data-mime-type="text/markdown"><p>
The Knuth path sampling scheme appears to be quite reliable. The main risk, as mentioned by Knuth, is high unobserved variance. This is the worrying possibility that our sample is unrepresentative because there is something large out there we have not yet seen.</p>
<p>In the case where we know there are no large monster games hiding, the procedure is preternaturally accurate. For example, the graph below is the percent error in estimating the number of chess games that reach at least the first k-ply for k equals 1 through 15. For these very short games the exact values of the counts are reported in <a href="https://oeis.org/A048987">The On-Line Encyclopedia of Integer Sequences A048987</a>, allowing us to check our results.
</p></div>
</div>
</div>
</div>

<div id="cell-id=7f22cee6">
<div>

<div>
<div>
<p><img data-recalc-dims="1" loading="lazy" decoding="async" alt="No description has been provided for this image" height="394" src="https://i0.wp.com/win-vector.com/wp-content/uploads/2026/01/DisplayGames_51_0.png?resize=656%2C394&amp;ssl=1" width="656"/>
</p>
</div>
</div>
</div>
</div>
<div id="cell-id=bdb01f5c">
<div tabindex="0">

<div>
<p>
The right-most point on the graph indicates that we are off by about 1/2 a percent in estimating the size of a population of 2015099950053364471960 possible games. This is using a sample of only size 100000, which is much smaller than the population size of 2015099950053364471960 we are estimating.
</p>
</div>
</div>
</div>
<div id="cell-id=47a4c050">
<div tabindex="0">

<div>
<p>
Initially the number of games is growing almost exponentially, so is quite regular and easy to estimate. However, as we see in the next graph, the Knuth path sample estimator is much closer to the actual counts than any simple exponential trend. The minimal exponential trend, even if fit to the entirety of the known data, is routinely off by over +- 30 percent even in its own fitting region.
</p>
</div>
</div>
</div>
<div id="cell-id=5eef57aa">
<div>

<div>
<div>
<p><img data-recalc-dims="1" loading="lazy" decoding="async" alt="No description has been provided for this image" height="394" src="https://i0.wp.com/win-vector.com/wp-content/uploads/2026/01/DisplayGames_54_0.png?resize=656%2C394&amp;ssl=1" width="656"/>
</p>
</div>
</div>
</div>
</div>

<div id="cell-id=80b533c5">
<div tabindex="0">

<div>
<div data-mime-type="text/markdown"><p>
We approximated the number of possible short chess games with both the Fermi problem method and Knuth’s path-product estimation method. Our final estimate was that it is plausible that there are on the order of 10<sup>151</sup> possible short games of chess.</p>
<p>When we switch from the Fermi problem method to the Knuth path-product method we:</p>
<ul>
<li>Avoid having to guess a useful subjective arithmetic form.</li>
<li>Become more able to incorporate the exact rules of the system we are exploring.</li>
<li>Remove the need for subjective estimated inputs.</li>
<li>Can try to “buy reliability” by building larger samples.</li>
</ul>
<p>And, of course, the methods apply to a lot more than just chess.
</p></div>
</div>
</div>
</div>
		<p>Categories: <a href="https://win-vector.com/category/computer-science/" rel="category tag">Computer Science</a> <a href="https://win-vector.com/category/mathematics/" rel="category tag">Mathematics</a>		</p>
<p>Tagged as: <a href="https://win-vector.com/tag/algorithms/" rel="tag">algorithms</a> <a href="https://win-vector.com/tag/approximation/" rel="tag">approximation</a> <a href="https://win-vector.com/tag/chess/" rel="tag">chess</a> <a href="https://win-vector.com/tag/combinatorics/" rel="tag">Combinatorics</a></p>	<div>
		<p><img alt="" src="https://secure.gravatar.com/avatar/615255da9a93cb63fa6f67d38249788e317cf108829e3fcdc480ebab647201a9?s=100&amp;d=identicon&amp;r=g" srcset="https://secure.gravatar.com/avatar/615255da9a93cb63fa6f67d38249788e317cf108829e3fcdc480ebab647201a9?s=200&amp;d=identicon&amp;r=g 2x" height="100" width="100" loading="lazy" decoding="async"/></p><h3>John Mount</h3>
			</div>
	</section>
</article></div>
  </body>
</html>
