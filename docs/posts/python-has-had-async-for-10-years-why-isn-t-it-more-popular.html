<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://tonybaloney.github.io/posts/why-isnt-python-async-more-popular.html">Original</a>
    <h1>Python has had async for 10 years – why isn&#39;t it more popular?</h1>
    
    <div id="readability-page-1" class="page"><div>
        <div>
            <div>
                <p>The <a href="https://www.youtube.com/watch?v=GfH4QL4VqJ0&amp;pp=ygUScHl0aG9uIGRvY3VtZW50YXJ5">Python Documentary</a> dropped this morning. In the middle of the documentary, there’s a dramatic segment about how the transition from Python 2 to 3 divided the community (spoiler alert: <a href="https://blog.jetbrains.com/pycharm/2025/08/the-state-of-python-2025/#most-still-use-older-python-versions-despite-benefits-of-newer-releases">it didn’t in the end</a>).</p>
<p>The early versions of Python 3 (3.0-3.4) were mostly focused on stability and offering pathways for users moving from 2.7. Along came 3.5 in 2015 with a new feature: <a href="https://peps.python.org/pep-0492/"><code>async</code> and <code>await</code> keywords for executing coroutines</a>.</p>
<p>Ten years and nine releases later, Python 3.14 is <a href="https://peps.python.org/pep-0745/">weeks away</a>.</p>
<p>Whilst everyone will be distracted by the shiny, colorful REPL features in 3.14, there are some big announcements nestled in the release notes — both related to concurrency and parallelism</p>
<p><img alt="Colorful REPL" src="https://tonybaloney.github.io/img/posts/colorful-repl.png"/></p>
<ol>
<li><a href="https://docs.python.org/3.14/whatsnew/3.14.html#pep-779-free-threaded-python-is-officially-supported">PEP779 Free-Threading is Officially Supported</a>. </li>
<li><a href="https://docs.python.org/3.14/whatsnew/3.14.html#pep-734-multiple-interpreters-in-the-stdlib">PEP 734: Multiple interpreters in the stdlib</a></li>
</ol>
<p>Both of these features are huge advancements in how Python can be used to execute concurrent code. But if <code>async</code> has been here for 10 years, why do we need them?</p>
<p>The killer use-case for async is web development. Coroutines lend well to out-of-process network calls, like HTTP requests and database queries. Why block the entire Python interpreter waiting for a SQL query to run on another server?</p>
<p>Yet, among the three most popular Python web frameworks, async support is still not universal. FastAPI is async from the ground-up, Django has some support, but is <a href="https://docs.djangoproject.com/en/5.2/topics/async/"><strong>“still working on async support”</strong></a> in key areas like the ORM (database). Then Flask is and probably always will be synchronous (Quart is an async alternative with similar APIs). The most popular ORM for Python, SQLAlchemy, only added asyncio support in 2023 (<a href="https://docs.sqlalchemy.org/en/20/changelog/migration_14.html#change-3414">changelog</a>).</p>
<p>I posed the question <em>“Why isn’t async more popular”</em> to a couple of other developers to get their thoughts.</p>
<p><a href="https://realpython.com/team/ctrudeau/">Christopher Trudeau</a>, co-host of the <a href="https://realpython.com/podcasts/rpp/">Real Python Podcast</a>, shared his perspective:</p>
<blockquote>
<p>Certain kinds of errors get caught by the compiler, others just disappear. Why didn’t that function run? Oops, forgot to await it. Error in the coroutine? Did you remember to launch with the right params, if not, it doesn’t percolate up. I still find threads easier to wrap my head around.</p>
</blockquote>
<p><a href="https://talkpython.fm/">Michael Kennedy</a> offered some additional insight:</p>
<blockquote>
<p>The [GIL] is so omnipresent that most Python people never developed multithreaded/async thinking. Because async/await only works for I/O bound work, not CPU as well, it’s of much less use. E.g. You can use in on the web, but most servers fork out to 4-8 web workers anyway</p>
</blockquote>
<p>So <strong>what’s going on here</strong> and <strong>can we apply the lessons to Free-Threading and Multiple Interpreters in 3.14</strong> so that in another ten years we’re looking back and wondering why <strong>they</strong> aren’t more popular?</p>
<h2 id="problem-1-what-is-an-asynchronous-shaped-problem">Problem 1: What is an asynchronous-shaped problem?<a href="#problem-1-what-is-an-asynchronous-shaped-problem" title="Permanent link">¶</a></h2>
<p><em>Coroutines</em> are most valuable with IO-related tasks. In Python, you can start hundreds of coroutines to make network requests, then wait for them all to finish without running them one at a time. The concepts behind coroutines are quite straightforward. You have a loop (the event loop) and you pass it coroutines to evaluate.</p>
<p>Let’s go back to the classic use-case, HTTP requests:</p>
<pre><code>def get_thing_sync():
    return http_client.get(&#39;/thing/which_takes?ages=1&#39;)
</code></pre>

<p>The equivalent async function is clean and readable:</p>
<pre><code>async def get_thing_async():
    return await http_client.get(&#39;/thing/which_takes?ages=1&#39;)
</code></pre>

<p>If you call function <code>get_thing_sync()</code> versus <code>await get_thing_async()</code>, they take <strong>the same amount of time</strong>. Calling it <em>“✨ asynchronously ✨”</em> does not somehow make it faster. The gains are when you have more than one coroutine running at once. </p>
<p>When fetching multiple HTTP resources you can start all the requests at once via the OS network stack, then handle each response as it arrives. The important point is that the actual work — sending packets and waiting for remote servers — happens outside your Python process while your code waits. Async is most effective here: you start operations, receive awaitable handles (tasks/futures), and the event loop efficiently notifies the coroutine when each operation completes without wasting CPU on busy‑polling.</p>
<p>This scenario works well because:</p>
<ol>
<li>The remote end is handling the work in another process</li>
<li>The local end (asyncio HTTP library) can yield control while waiting for the response</li>
<li>Operating-Systems have stacks and APIs for managing sockets and network</li>
</ol>
<p>That’s all fine, but I started with the statement <strong><em>Coroutines</em> are most valuable with IO-related tasks.</strong> I then picked the one task that asyncio can handle really well, HTTP requests.</p>
<p>What about disk IO? I have <strong>far</strong> more applications in Python which read and write from files on disks or memory than I do making HTTP requests. I also have Python programs which run other programs using <code>subprocess</code>.</p>
<p>Can I make all of those <code>async</code>?  </p>
<p>No, not really. From the <a href="https://github.com/python/asyncio/wiki/ThirdParty#filesystem">asyncio Wiki</a>:</p>
<blockquote>
<p>asyncio does not support asynchronous operations on the filesystem. Even if files are opened with O_NONBLOCK, read and write will block.</p>
</blockquote>
<p>The solution is to use a third-party package, <code>aiofiles</code>, which gives you async file I/O capabilities:</p>
<pre><code>async with aiofiles.open(&#39;filename&#39;, mode=&#39;r&#39;) as f:
    contents = await f.read()
</code></pre>

<p>So, mission accomplished? No because <code>aiofiles</code> uses a <strong>thread pool</strong> to offload the blocking file I/O operations. </p>
<h3 id="side-quest-why-isnt-file-io-async">Side-Quest: Why isn’t file IO async?<a href="#side-quest-why-isnt-file-io-async" title="Permanent link">¶</a></h3>
<p>Windows has an async file IO API called <a href="https://learn.microsoft.com/en-us/windows/win32/api/ioringapi/">IoRing</a>. Linux has this availability in newer Kernels via <a href="https://kernel.dk/io_uring.pdf"><code>io_uring</code></a>. All I could find for a Python implementation of <code>io_uring</code> is this <a href="https://github.com/YoSTEALTH/Liburing">synchronous API written in Cython</a>.</p>
<p>There were io_uring APIs for other platforms, Rust has implementations with <a href="https://github.com/tokio-rs/tokio-uring">tokio</a>, C++ has <a href="https://think-async.com/Asio/asio-1.24.0/doc/asio/history.html#asio.history.asio_1_21_0">Asio</a> and Node.JS has <a href="https://www.phoronix.com/news/libuv-io-uring">libuv</a>.</p>
<p>So, the asyncio Wiki is a little out of date, but</p>
<ol>
<li><strong>Most</strong> production Python applications run on Linux, where the implementation is <code>io_uring</code></li>
<li><code>io_uring</code> has been plagued by security issues so bad that RedHat, Google and others have restricted or removed its availability. After paying out $1 million in bug bounties related to <code>io_uring</code>, <a href="https://security.googleblog.com/2023/06/learnings-from-kctf-vrps-42-linux.html">Google disabled it on some products</a>. The issue was severe; many of the related bug‑bounty reports involved io_uring exploits.</li>
</ol>
<p>So we should hold our horses a little while longer. Operating Systems have long held a file IO API that handles threads for concurrent IO. It does the job just fine for now.</p>
<p>So in summary, <em>Coroutines are most valuable with IO-related tasks</em> is only really true for <strong>network I/O</strong> and network sockets in Python were never blocking operations in the first place. Socket open in Python is one of the few operations which releases the GIL and works <a href="https://github.com/python/cpython/blob/v3.14.0rc2/Modules/socketmodule.c#L939-L1085">concurrently in a thread pool</a> as a non-blocking operation.</p>
<h3 id="recap-what-are-the-async-operations-in-asyncio">Recap: What are the async operations in asyncio?<a href="#recap-what-are-the-async-operations-in-asyncio" title="Permanent link">¶</a></h3>
<table>
<thead>
<tr>
<th>Operation</th>
<th>Asyncio API</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td>Sleep</td>
<td><a href="https://docs.python.org/3/library/asyncio-task.html#asyncio.sleep"><code>asyncio.sleep()</code></a></td>
<td>Asynchronously sleep for a given duration.</td>
</tr>
<tr>
<td>TCP/UDP Streams</td>
<td><a href="https://docs.python.org/3/library/asyncio-stream.html#asyncio-streams"><code>asyncio.open_connection()</code></a></td>
<td>Open a TCP/UDP connection.</td>
</tr>
<tr>
<td>HTTP</td>
<td><a href="https://docs.aiohttp.org/en/stable/client_reference.html#aiohttp.ClientSession"><code>aiohttp.ClientSession()</code></a></td>
<td>Asynchronous HTTP client.</td>
</tr>
<tr>
<td>Run Subprocesses</td>
<td><a href="https://docs.python.org/3/library/asyncio-subprocess.html#asyncio-subprocess"><code>asyncio.subprocess</code></a></td>
<td>Asynchronously run subprocesses.</td>
</tr>
<tr>
<td>Queues</td>
<td><a href="https://docs.python.org/3/library/asyncio-queue.html#asyncio-queues"><code>asyncio.Queue</code></a></td>
<td>Asynchronous queue implementation.</td>
</tr>
</tbody>
</table>
<h2 id="problem-2-no-matter-how-fast-you-run-you-cant-escape-the-gil">Problem 2: No matter how fast you run, you can’t escape the GIL<a href="#problem-2-no-matter-how-fast-you-run-you-cant-escape-the-gil" title="Permanent link">¶</a></h2>
<p><a href="https://willmcgugan.github.io/">Will McGugan</a>, the creator of Rich, Textualize, and several other extremely popular Python libraries offered his perspective on async:</p>
<blockquote>
<p>I really enjoy async programming, but it isn’t intuitive for most devs that don’t have a background writing network code. A reoccurring problem I see with Textual is folk testing concurrency by dropping in a <code>time.sleep(10)</code> call to simulate the work they are planning. <strong>Of course, that blocks the entire loop.</strong> But that’s a class of issue which is difficult to explain to devs who haven’t used async much. i.e. what does it mean for code to “block”, and when is it necessary to defer to threads. <strong>Without that grounding in the fundamentals, your async code is going to misbehave,</strong> but its not going to break per se. So devs don’t get the rapid iteration and feedback that we expect from Python.</p>
</blockquote>
<p>Now that we’ve covered the limited use cases for async, another challenge keeps coming up. The Python GIL.</p>
<p>I’ve been working on this C#/Python bridge project called <a href="https://tonybaloney.github.io/CSnakes">CSnakes</a>, one of the features that caused the most head-scratching was <a href="https://tonybaloney.github.io/CSnakes/v1/user-guide/async/">async</a>.</p>
<p>C#, the language from which the <a href="https://peps.python.org/pep-0492/#why-async-and-await-keywords"><code>async</code>/<code>await</code> syntax was borrowed</a>, has far broader async support in its core I/O libraries because it implements a Task‑based Asynchronous Pattern (TAP), where tasks are dispatched onto a managed thread pool. Disk, network, and memory I/O operations commonly provide both async and sync methods.</p>
<p>In fact, the C# implementation goes all the way up from the disk to the higher-level APIs, such as serialization libraries. <a href="https://learn.microsoft.com/en-us/dotnet/api/system.text.json.jsonserializer.deserializeasync?view=net-9.0#system-text-json-jsonserializer-deserializeasync(system-io-stream-system-type-system-text-json-serialization-jsonserializercontext-system-threading-cancellationtoken)">JSON deserialization is async</a>, so is XML. </p>
<p>The <a href="https://learn.microsoft.com/en-us/dotnet/standard/parallel-programming/task-based-asynchronous-programming">C# Async model</a> and the Python Async models have some important differences:</p>
<ul>
<li>C# creates a task pool and tasks are scheduled on this pool. The number of threads is managed automatically by the runtime.</li>
<li>Python event loops belong to the thread that created them. C# tasks can be scheduled on any thread.</li>
<li>Python async functions are coroutines that are scheduled on the event loop. C# async functions are tasks that are scheduled on the task pool.</li>
</ul>
<p>The benefit of C#’s model is that a <code>Task</code> is a higher-level abstraction over a thread or coroutine. This means that you don’t have to worry about the underlying thread management, you can schedule several tasks to be awaited concurrently or you can run them in parallel with Task Parallel Library (TPL).</p>
<p>In Python “An event loop runs in a thread (typically the main thread) and executes all callbacks and Tasks in its thread. While a Task is running in the event loop, no other Tasks can run in the same thread. When a Task executes an await expression, the running Task gets suspended, and the event loop executes the next Task.” <a href="https://docs.python.org/3/library/asyncio-dev.html#asyncio-multithreading">1</a></p>
<p>Going back to Will’s comment <strong>“Of course, that blocks the entire loop”</strong>, he’s talking about operations inside async functions which are blocking and therefore block the entire event loop. Since we covered in Problem 1, that’s practically everything except network calls and sleeping. </p>
<p>With Python’s GIL, it doesn’t matter if you’re running 1 thread or 10, the GIL will lock everything so that only 1 is operating at a time.</p>
<p><img alt="Breakdancing meme" src="https://tonybaloney.github.io/img/posts/breakdance.gif"/></p>
<p>There are some operations don’t block the GIL (e.g. File IO) and in those cases you can run them in threads. For example, if you used <code>httpx</code>‘s streaming feature to stream a large network download onto disk:</p>
<pre><code>import httpx
import tempfile

def download_file(url: str):
    with tempfile.NamedTemporaryFile(delete=False) as tmp_file:
        with httpx.stream(&#34;GET&#34;, url) as response:
            for chunk in response.iter_bytes():
                tmp_file.write(chunk)
    return tmp_file.name
</code></pre>

<p>Neither the <code>httpx</code> stream iterator nor <code>tmp_file.write</code> is GIL-blocking, so they benefit from running in separate threads.</p>
<p>We can merge this behavior with an asyncio API, by using the <a href="https://docs.python.org/3/library/asyncio-eventloop.html#executing-code-in-thread-or-process-pools">Event Loop <code>run_in_executor()</code> function</a> and passing it a thread pool:</p>
<pre><code>import asyncio
import concurrent.futures

async def main():
    loop = asyncio.get_running_loop()

    URLS = [
        &#34;https://example.place/big-file-1&#34;,
        &#34;https://example.place/big-file-2&#34;,
        &#34;https://example.place/big-file-3&#34;,
        # etc.
    ]

    tasks = set()
    with concurrent.futures.ThreadPoolExecutor(max_workers=10) as pool:
        for url in URLS:
            tasks.add(loop.run_in_executor(pool, download_file, url))
        files = await asyncio.gather(*tasks)
    print(files)
</code></pre>

<p>It’s not immediately clear to me what the benefit of this is over running a <a href="https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.ThreadPoolExecutor">thread-pool and calling <code>pool.submit</code></a>. We retain an async API, so if that is important this is an interesting workaround. </p>
<p>I find that memorizing, documenting, and explaining what is and isn’t “blocking” in Python to be confusing and continually changing.</p>
<h3 id="does-the-free-threaded-mode-make-asyncio-more-useful-or-redundant">Does the free-threaded mode make asyncio more useful or redundant?<a href="#does-the-free-threaded-mode-make-asyncio-more-useful-or-redundant" title="Permanent link">¶</a></h3>
<p>Python 3.13 introduced a very-unstable “free-threaded” build of Python where the GIL is removed and replaced with smaller, more granular locks. See my <a href="https://www.youtube.com/watch?v=Mp5wKOL4L2Q">PyCon US 2024 Talk</a> for a summary of parallelism.
The 3.13 build wasn’t stable enough for any production use. 3.14 is looking far improved and I think we can start to introduce free-threading in 2026 in some narrow, well-tested scenarios.</p>
<p>One major benefit to coroutines versus threads is that they have a far smaller memory footprint, a lower context-switching overhead, and faster startup times. async APIs are also easier to reason about and compose.</p>
<p>Because parallelism in Python using threads has always been so limited, the APIs in the standard library are quite rudimentary. I think there is an opportunity to have a task-parallelism API in the standard library once free-threading is stabilized. </p>
<p>Last week I was implementing a registry function that did two discrete tasks. One calls a very slow sync-only API and the other calls several async APIs. </p>
<p>I want the behavior that:</p>
<ul>
<li>Both are started at the same time</li>
<li>If one fails, it cancels the other and raises an exception with the exception details of the failed function</li>
<li>The result is only combined when both are complete</li>
</ul>
<pre>flowchart LR
  Start([Start]) --&gt; Invoke[&#34;tpl.invoke()&#34;]
  Invoke --&gt; f1[&#34;f1()&#34;]
  Invoke --&gt; f2[&#34;f2()&#34;]
  f1 --&gt;|f1 -&gt; T1| Join[&#34;Tuple[T1, T2]&#34;]
  f2 --&gt;|f2 -&gt; T2| Join
  Join --&gt; End([End])
</pre>

<p>Since there are only two tasks, I don’t want to have to define a thread-pool or a set number of workers. I also don’t want to have to map or gather the callees. I want to retain my typing information so that the resulting variables are strongly typed from the return types of <code>function_a</code> and <code>function_a</code>. Essentially an API like this:</p>
<pre><code>import tpl


def function_a() -&gt; T1:
    ...

def function_b() -&gt; T2:
    ...

result_a: T1, result_b: T2 = tpl.invoke(function_a, function_b)
</code></pre>

<p>This is all <em>possible</em> today but there are many constraints with the GIL. Free-threading will make parallel programming more popular in Python and we’ll have to revisit some of the APIs.</p>
<h2 id="problem-3-maintaining-two-apis-is-hard">Problem 3: Maintaining two APIs is hard<a href="#problem-3-maintaining-two-apis-is-hard" title="Permanent link">¶</a></h2>
<p>As a package maintainer, supporting both synchronous and asynchronous APIs is a big challenge. You also have to be selective with where you support async. Much of the stdlib doesn’t support async natively (e.g. logging backends).</p>
<p>Python’s <strong>Magic</strong> (<code>__dunder__</code>) methods cannot be async. <code>__init__</code> cannot be async for example, so none of your code can use network requests in the initializer.</p>
<h3 id="async-properties">Async properties<a href="#async-properties" title="Permanent link">¶</a></h3>
<p>This is an odd-pattern but I’ll keep it simple to illustrate my point. You have a class <code>User</code> with a property <code>records</code>. This property gives a list of records for that user. A synchronous API is straightforward:</p>
<pre><code>class User:
    @property
    def records(self) -&gt; list[RecordT]:
        # fetch records from database lazily
        ...
</code></pre>

<p>We can even use a lazily-initialized instance variable to cache this data.</p>
<p>Porting this API to async is a challenge because whilst <code>@property</code> methods can be async, standard attributes are not. Having to <code>await</code> some instance attributes and not others leaves a very odd API:</p>
<pre><code>class AsyncDatabase:
    @staticmethod
    async def fetch_many(id: str, of: Type[RecordT]) -&gt; list[RecordT]:
        ...

class User:
    @property
    async def records(self) -&gt; list[RecordT]:
        # fetch records from database lazily
        return await AsyncDatabase.fetch_many(self.id, RecordT)
</code></pre>

<p>Anytime you access that property, it needs to be awaited:</p>
<pre><code>user = User(...)
# single access
await user.records
# if
if await user.records:
    ...
# comprehension?
[record async for record in user.records]
</code></pre>

<p><a href="https://tryexceptpass.org/article/controlling-python-async-creep/">The further we go into this implementation</a>, the more we wait for the user to accidentally forget to await the property and it fails silently.</p>
<h3 id="duplicated-implementations">Duplicated implementations<a href="#duplicated-implementations" title="Permanent link">¶</a></h3>
<p>The Azure Python SDK, a ginormous Python project supports both sync and async. Maintaining both is achieved via a lot of code-generation infrastructure. This is ok for a project with tens of full-time engineers, but for anything small or voluntary you need to copy + paste a lot of your code base to create an async version. Then you need to patch and backport fixes and changes between the two. The differences (mostly <code>await</code> calls) are big enough to confuse Git. I was reviewing some langchain implementations last year which had both sync and async implementation. Every method was copied+pasted, with little behavioral differences and their own bugs. People would submit bug fix PR’s to one implementation and not the other so instead of merging directly, maintainers had to port the fix, skip it, or ask the contributors to do both.</p>
<h3 id="backend-fragmentation">Backend fragmentation<a href="#backend-fragmentation" title="Permanent link">¶</a></h3>
<p>Since we’re largely talking about HTTP/Network IO, you also need to pick a backend for sync and async. For synchronous HTTP calls, <code>requests</code>, <code>httpx</code> are suitable backends. For <code>async</code>, its <code>aiohttp</code> and <code>httpx</code>. Since neither are part of the Python standard library, the adoption and support for CPython’s main platforms is out of sync. E.g. as of today, <code>aiohttp</code> has <a href="https://pypi.org/project/aiohttp/#files">no Python 3.14 wheels, nor free-threaded support</a>. UV Loop, the alternative implementation of the event loop has <a href="https://pypi.org/project/uvloop/#files">no Python 3.14 support, nor any Windows support.</a> (Python 3.14 isn’t out yet, so it’s reasonable to not have support in either open-source project).</p>
<h3 id="testing-overhead">Testing overhead<a href="#testing-overhead" title="Permanent link">¶</a></h3>
<p>Further down the copy+paste maintainer overhead is the testing of these APIs. Testing your async code requires different mocks, different calls and in the case of Pytest a whole set of extensions and patterns for fixtures. This situation is so <a href="https://tonybaloney.github.io/posts/async-test-patterns-for-pytest-and-unittest.html">confusing I wrote a post about it and it’s one of the most popular on my blog</a>.</p>
<h2 id="summary">Summary<a href="#summary" title="Permanent link">¶</a></h2>
<p>In summary, I think the use cases for asyncio are limited (mostly for reasons beyond the control of <code>asyncio</code>) and this has constrained it’s popularity. Maintaining duplicate code-bases is a burden.</p>
<p>FastAPI, the web framework that’s <a href="https://www.starlette.io/">async from-the-ground-up</a> grew in <a href="https://blog.jetbrains.com/pycharm/2025/08/the-state-of-python-2025/#python-web-devs-resurgence">popularity again</a> from 29% to 38% share of the web frameworks for Python, taking the #1 spot. It has over 100-million downloads a month. Considering the big use-case for async is HTTP and network IO, having the #1 web framework be an async one is a sign of asyncio’s success. </p>
<p>I think in 3.14 the sub-interpreter executor and free-threading features make more parallel and concurrency use cases practical and useful. For those, we don’t need <code>async</code> APIs and it alleviates much of the issues I highlighted in this post.</p>

                
                <h2>Related Posts</h2>
                
            </div>
        </div>
    </div></div>
  </body>
</html>
