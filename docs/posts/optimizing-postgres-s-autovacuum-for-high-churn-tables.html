<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://tembo.io/blog/optimizing-postgres-auto-vacuum/">Original</a>
    <h1>Optimizing Postgres&#39;s autovacuum for high-churn tables</h1>
    
    <div id="readability-page-1" class="page"><div id="__blog-post-container" itemprop="articleBody"><p>Database systems use various techniques to ensure transactionality and performance. For Postgres, this is called MVCC (Multi-Version Concurrency Control). MVCC allows Postgres to provide great performance even when multiple clients could be working with the same table concurrently.</p><p>It is useful to be aware of Postgres’ MVCC implementation to understand how Postgres manages a table’s physical storage. Internally, Postgres refers to rows as “tuples”. And as a baseline, there are two big ideas to keep in mind about how Postgres implements changes to rows in a table:</p><ul><li>An UPDATE operation in Postgres is equivalent to a DELETE of the previous tuple, plus an INSERT of the new one.</li><li>A DELETE operation in Postgres does not cause the data to be removed from physical storage. It only causes it to be marked as deleted.</li></ul><p>This is why Postgres has the <a href="https://www.postgresql.org/docs/current/routine-vacuuming.html#AUTOVACUUM" target="_blank" rel="noopener noreferrer">autovacuum</a> process: It is the automatic process in charge of cleaning up and optimizing table storage for Postgres. You can follow this blog post with a local test environment of Postgres. I will demonstrate with code how MVCC and VACUUM features work, and how to tune the Auto-vacuum process.</p><h2 id="why-does-it-matter">Why does it matter?<a href="#why-does-it-matter" aria-label="Direct link to Why does it matter?" title="Direct link to Why does it matter?">​</a></h2><p>Vacuum is not just about cleaning up storage space. In environments where data undergoes constant change, Postgres tables often experience an excessive amount of Inserts, Updates, and Deletes. This activity can lead to table bloat. Table bloat happens when a table’s physical footprint far exceeds the size of the data that it actually holds.</p><p>Table bloat is a condition that if not managed, will likely hamper performance of our database. And so, this takes us back to the autovacuum process: to extract its maximum benefits, you may need to fine-tune its settings.</p><p>Postgres’s default autovacuum settings are pretty good. If you’re like me, it could have been years into your postgres journey before having a negative experience with bloat. However, when the time came I found it challenging to understand and tune these configuration settings. That’s why we will study them safely in a dev environment.</p><h2 id="unraveling-the-mystery-of-bloat--vacuums-role">Unraveling the Mystery of Bloat &amp; Vacuum&#39;s Role<a href="#unraveling-the-mystery-of-bloat--vacuums-role" aria-label="Direct link to Unraveling the Mystery of Bloat &amp; Vacuum&#39;s Role" title="Direct link to Unraveling the Mystery of Bloat &amp; Vacuum&#39;s Role">​</a></h2><p>PostgreSQL&#39;s mechanism for handling bloat is unique due to its adherence to MVCC. Contrary to immediate space reclamation after data is deleted or becomes obsolete, Postgres tags these rows as &#34;dead&#34;, or “dead tuples”. However, even though they are dead they still occupy disk space and will degrade the performance of your queries. Many queries will continue to scan through these tuples, despite their “dead” status. The auto-vacuum steps in here, ensuring that these rows are removed and both the table and its associated indexes are streamlined for performance. You can’t scan the dead tuples if they no longer exist!</p><p>To illustrate, let us create some bloat and see how it affects a rowcount query:</p><p>Create a table we can easily manipulate, and let’s disable autovacuum so we can observe the consequences.</p><div><div><pre tabindex="0"><code><span><span>CREATE</span><span> </span><span>TABLE</span><span> bencher </span><span>(</span><span></span><br/></span><span><span>  record_id bigserial</span><span>,</span><span></span><br/></span><span><span>  updated_at </span><span>timestamp</span><span> </span><span>with</span><span> </span><span>time</span><span> zone</span><br/></span><span><span></span><span>)</span><span>;</span><span></span><br/></span><span><span></span><span>ALTER</span><span> </span><span>TABLE</span><span> bencher </span><span>SET</span><span> </span><span>(</span><span>autovacuum_enabled </span><span>=</span><span> </span><span>false</span><span>)</span><span>;</span><span></span><br/></span><span><span></span><span>SELECT</span><span> pg_reload_conf</span><span>(</span><span>)</span><span>;</span><br/></span></code></pre></div></div><p>Now insert 10 million rows of example data.</p><div><div><pre tabindex="0"><code><span><span>INSERT</span><span> </span><span>INTO</span><span> bencher</span><span>(</span><span>updated_at</span><span>)</span><span></span><br/></span><span><span></span><span>SELECT</span><span> </span><span>now</span><span>(</span><span>)</span><span></span><br/></span><span><span></span><span>FROM</span><span> generate_series</span><span>(</span><span>1</span><span>,</span><span> </span><span>10000000</span><span>)</span><span>;</span><br/></span></code></pre></div></div><p>We just created the table, and have only inserted records, so there are currently no dead tuples.</p><div><div><pre tabindex="0"><code><span><span>SELECT</span><span></span><br/></span><span><span>    schemaname</span><span>,</span><span></span><br/></span><span><span>    relname</span><span>,</span><span></span><br/></span><span><span>    n_dead_tup</span><span>,</span><span></span><br/></span><span><span>    n_live_tup</span><br/></span><span><span></span><span>FROM</span><span> pg_stat_user_tables</span><br/></span><span><span></span><span>WHERE</span><span> relname </span><span>=</span><span> </span><span>&#39;bencher&#39;</span><span>;</span><span></span><br/></span><span><span></span><br/></span><span><span> schemaname </span><span>|</span><span> relname </span><span>|</span><span> n_dead_tup </span><span>|</span><span> n_live_tup </span><br/></span><span><span></span><span></span><br/></span><span><span> </span><span>public</span><span>     </span><span>|</span><span> bencher </span><span>|</span><span>          </span><span>0</span><span> </span><span>|</span><span>   </span><span>10000000</span><span></span><br/></span><span><span></span><br/></span></code></pre></div></div><p>Let’s see how long it takes to get a rowcount with no bloat.</p><div><div><pre tabindex="0"><code><span><span>\timing</span><br/></span><span><span></span><br/></span><span><span></span><span>select</span><span> </span><span>*</span><span> </span><span>from</span><span> bencher </span><span>where</span><span> record_id </span><span>=</span><span> </span><span>5000000</span><span>;</span><span></span><br/></span><span><span>record_id </span><span>|</span><span> updated_at</span><br/></span><span><span></span><span></span><br/></span><span><span></span><span>5000000</span><span> </span><span>|</span><span> </span><span>2023</span><span>-</span><span>08</span><span>-</span><span>30</span><span> </span><span>14</span><span>:</span><span>42</span><span>:</span><span>05.584778</span><span>+</span><span>00</span><span></span><br/></span><span><span></span><span>(</span><span>1</span><span> </span><span>row</span><span>)</span><span></span><br/></span><span><span></span><br/></span><span><span></span><span>Time</span><span>: </span><span>191.006</span><span> ms</span><br/></span></code></pre></div></div><p>Great, 191ms. Slow, yes but we have no indices because we’re demonstrating bloat. Now lets create a bunch of dead tuples. This can take a minute or so.</p><div><div><pre tabindex="0"><code><span><span>DO</span><span> $$</span><br/></span><span><span></span><span>DECLARE</span><span></span><br/></span><span><span>i </span><span>integer</span><span>;</span><span></span><br/></span><span><span></span><span>BEGIN</span><span></span><br/></span><span><span></span><span>FOR</span><span> i </span><span>IN</span><span> </span><span>1.</span><span>.5</span><span> </span><span>LOOP</span><span></span><br/></span><span><span>  </span><span>UPDATE</span><span> bencher </span><span>SET</span><span> updated_at </span><span>=</span><span> </span><span>now</span><span>(</span><span>)</span><span>;</span><span></span><br/></span><span><span></span><span>END</span><span> </span><span>LOOP</span><span>;</span><span></span><br/></span><span><span></span><span>END</span><span> $$</span><span>;</span><br/></span></code></pre></div></div><p>Now, lets see how long it takes to fetch the same record:</p><div><div><pre tabindex="0"><code><span><span>select</span><span> </span><span>*</span><span> </span><span>from</span><span> bencher </span><span>where</span><span> record_id </span><span>=</span><span> </span><span>5000000</span><span>;</span><span></span><br/></span><span><span>record_id </span><span>|</span><span> updated_at</span><br/></span><span><span></span><span></span><br/></span><span><span></span><span>5000000</span><span> </span><span>|</span><span> </span><span>2023</span><span>-</span><span>08</span><span>-</span><span>30</span><span> </span><span>14</span><span>:</span><span>42</span><span>:</span><span>58.964919</span><span>+</span><span>00</span><span></span><br/></span><span><span></span><span>(</span><span>1</span><span> </span><span>row</span><span>)</span><span></span><br/></span><span><span></span><br/></span><span><span></span><span>Time</span><span>: </span><span>283.728</span><span> ms</span><br/></span></code></pre></div></div><p>It’s getting closer to 300ms now. Let’s check how many dead tuples are on the table.</p><div><div><pre tabindex="0"><code><span><span>SELECT</span><span></span><br/></span><span><span>    schemaname</span><span>,</span><span></span><br/></span><span><span>    relname</span><span>,</span><span></span><br/></span><span><span>    n_dead_tup</span><span>,</span><span></span><br/></span><span><span>    n_live_tup</span><br/></span><span><span></span><span>FROM</span><span> pg_stat_user_tables</span><br/></span><span><span></span><span>WHERE</span><span> relname </span><span>=</span><span> </span><span>&#39;bencher&#39;</span><span>;</span><span></span><br/></span><span><span></span><br/></span><span><span></span><br/></span><span><span>schemaname </span><span>|</span><span> relname </span><span>|</span><span> n_dead_tup </span><span>|</span><span> n_live_tup</span><br/></span><span><span></span><span></span><br/></span><span><span></span><span>public</span><span> </span><span>|</span><span> bencher </span><span>|</span><span> </span><span>50000000</span><span> </span><span>|</span><span> </span><span>10000000</span><br/></span></code></pre></div></div><p>Now let’s manually clean up the dead tuples and restore our query performance.</p><p>And check the dead tuple count, there are no dead tuples.</p><div><div><pre tabindex="0"><code><span><span>SELECT</span><span></span><br/></span><span><span>    schemaname</span><span>,</span><span></span><br/></span><span><span>    relname</span><span>,</span><span></span><br/></span><span><span>    n_dead_tup</span><span>,</span><span></span><br/></span><span><span>    n_live_tup</span><br/></span><span><span></span><span>FROM</span><span> pg_stat_user_tables</span><br/></span><span><span></span><span>WHERE</span><span></span><br/></span><span><span>    n_dead_tup </span><span>&gt;</span><span> </span><span>0</span><span> </span><span></span><br/></span><span><span></span><span>and</span><span> relname </span><span>=</span><span> </span><span>&#39;bencher&#39;</span><span>;</span><span></span><br/></span><span><span> schemaname </span><span>|</span><span> relname </span><span>|</span><span> n_dead_tup </span><span>|</span><span> n_live_tup </span><br/></span><span><span></span><span></span><br/></span><span><span> </span><span>public</span><span>     </span><span>|</span><span> bencher </span><span>|</span><span>          </span><span>0</span><span> </span><span>|</span><span>    </span><span>10000000</span><br/></span></code></pre></div></div><p>Finally, let’s retrieve the record. Performance restored!</p><div><div><pre tabindex="0"><code><span><span>select</span><span> </span><span>*</span><span> </span><span>from</span><span> bencher </span><span>where</span><span> record_id </span><span>=</span><span> </span><span>500000</span><span>;</span><span></span><br/></span><span><span>record_id </span><span>|</span><span> updated_at</span><br/></span><span><span></span><span></span><br/></span><span><span></span><span>500000</span><span> </span><span>|</span><span> </span><span>2023</span><span>-</span><span>08</span><span>-</span><span>30</span><span> </span><span>14</span><span>:</span><span>42</span><span>:</span><span>58.964919</span><span>+</span><span>00</span><span></span><br/></span><span><span></span><span>(</span><span>1</span><span> </span><span>row</span><span>)</span><span></span><br/></span><span><span></span><br/></span><span><span></span><span>Time</span><span>: </span><span>194.101</span><span> ms</span><br/></span></code></pre></div></div><h2 id="setting-up-a-benchmarking-environment">Setting up a benchmarking environment<a href="#setting-up-a-benchmarking-environment" aria-label="Direct link to Setting up a benchmarking environment" title="Direct link to Setting up a benchmarking environment">​</a></h2><p>The rest of the examples will be run on Postgres in <a href="https://tembo.io/waitlist" target="_blank" rel="noopener noreferrer">Tembo Cloud</a>. We’ll use 8 vcore and 16Gb of memory and execute all the <code>psql</code> and <code>pgbench</code> commands from an EC2 instance within the same region as Postgres.</p><p>Let’s set up a script that will create an absurdly large amount of churn on our table and be able to execute it with <code>pgbench</code>. For every iteration, let’s insert a row to our “bencher” table. Then, let’s read and update a single record. Finally, let’s delete the same record. This will create a situation similar to many queue implementations (<a href="https://github.com/tembo-io/pgmq" target="_blank" rel="noopener noreferrer">like PGMQ</a>), where there are at least 2 transactions for every 1 insert. Additionally, the total record count on the table will typically be low - for every record we insert, we also delete one.</p><p>This creates a situation where a table consists of primarily dead tuples!</p><div><div><pre tabindex="0"><code><span><span>-</span><span>– churn</span><span>.</span><span>sql</span><span></span><br/></span><span><span></span><span>DO</span><span> $$</span><br/></span><span><span></span><span>DECLARE</span><span></span><br/></span><span><span>rec_id </span><span>INT</span><span>;</span><span></span><br/></span><span><span></span><span>BEGIN</span><span></span><br/></span><span><span>    </span><span>INSERT</span><span> </span><span>INTO</span><span> bencher</span><span>(</span><span>updated_at</span><span>)</span><span></span><br/></span><span><span></span><span>SELECT</span><span> </span><span>now</span><span>(</span><span>)</span><span>;</span><span></span><br/></span><span><span></span><br/></span><span><span></span><span></span><br/></span><span><span></span><span>WITH</span><span> cte </span><span>AS</span><span></span><br/></span><span><span></span><span>(</span><span></span><br/></span><span><span>    </span><span>SELECT</span><span> record_id</span><br/></span><span><span>    </span><span>FROM</span><span> bencher</span><br/></span><span><span>    </span><span>WHERE</span><span> updated_at </span><span>&lt;</span><span> </span><span>now</span><span>(</span><span>)</span><span></span><br/></span><span><span>    </span><span>ORDER</span><span> </span><span>BY</span><span> record_id </span><span>ASC</span><span></span><br/></span><span><span>    </span><span>LIMIT</span><span> </span><span>1</span><span></span><br/></span><span><span></span><span>FOR</span><span> </span><span>UPDATE</span><span> SKIP LOCKED</span><br/></span><span><span></span><span>)</span><span></span><br/></span><span><span></span><br/></span><span><span></span><br/></span><span><span></span><span>UPDATE</span><span> bencher</span><br/></span><span><span></span><span>SET</span><span></span><br/></span><span><span>    updated_at </span><span>=</span><span> </span><span>now</span><span>(</span><span>)</span><span></span><br/></span><span><span></span><span>WHERE</span><span> record_id </span><span>in</span><span> </span><span>(</span><span>select</span><span> record_id </span><span>from</span><span> cte</span><span>)</span><span></span><br/></span><span><span></span><span>RETURNING</span><span> record_id </span><span>INTO</span><span> rec_id</span><span>;</span><span></span><br/></span><span><span></span><br/></span><span><span></span><br/></span><span><span></span><span></span><br/></span><span><span></span><span>DELETE</span><span></span><br/></span><span><span></span><span>FROM</span><span> bencher</span><br/></span><span><span></span><span>WHERE</span><span> record_id </span><span>=</span><span> rec_id</span><span>;</span><span></span><br/></span><span><span></span><span>END</span><span> $$</span><span>;</span><br/></span></code></pre></div></div><p>Set Postgres to all the default vacuum configurations;</p><div><div><pre tabindex="0"><code><span><span>ALTER</span><span> SYSTEM </span><span>SET</span><span> autovacuum_vacuum_scale_factor </span><span>=</span><span> </span><span>0.2</span><span>;</span><span></span><br/></span><span><span></span><span>ALTER</span><span> SYSTEM </span><span>SET</span><span> autovacuum_vacuum_cost_delay </span><span>=</span><span> </span><span>&#39;20ms&#39;</span><span>;</span><span></span><br/></span><span><span></span><span>ALTER</span><span> SYSTEM </span><span>SET</span><span> autovacuum_vacuum_cost_limit </span><span>=</span><span> </span><span>&#39;-1&#39;</span><span>;</span><span></span><br/></span><span><span></span><span>ALTER</span><span> SYSTEM </span><span>SET</span><span> vacuum_cost_limit </span><span>=</span><span> </span><span>200</span><span>;</span><span></span><br/></span><span><span></span><span>ALTER</span><span> SYSTEM </span><span>SET</span><span> autovacuum_naptime </span><span>=</span><span> </span><span>&#39;1min&#39;</span><span>;</span><span></span><br/></span><span><span></span><span>SELECT</span><span> pg_reload_conf</span><span>(</span><span>)</span><span>;</span><br/></span></code></pre></div></div><p>Let’s run a benchmark to get a baseline. We will reuse this benchmark through the process.</p><div><div><pre tabindex="0"><code><span><span>pgbench &#39;postgresql://postgres:pw@host:5432&#39; -c 100 -j 1 -P 1 -T 300 -r -f churn.sql</span><br/></span></code></pre></div></div><p><img loading="lazy" alt="default" src="https://glitch.at.goth.cafe/assets/images/default-02ce369e1e17c9777de6749b0926159f.png" title="default" width="1000" height="600"/></p><p>Average latency is about 3.4 ms. We are benchmarking an expensive set of queries, and you’ve probably noticed the sawtooth pattern in the plot and a high standard deviation relative to the latency. This is a symptom of bloat accumulating on our table. Query latency grows until the vacuum process clears dead tuples, and then grows once again. This also has an inverse impact on transactions per second (TPS). Ideally we can reduce and provide some stability to latency.</p><h2 id="balancing-vacuum-delay-for-optimal-system-performance">Balancing Vacuum Delay for Optimal System Performance<a href="#balancing-vacuum-delay-for-optimal-system-performance" aria-label="Direct link to Balancing Vacuum Delay for Optimal System Performance" title="Direct link to Balancing Vacuum Delay for Optimal System Performance">​</a></h2><p>Vacuuming is indispensable. However, it is not free and if left unchecked, it can burden your system. The balance lies in <code>autovacuum_vacuum_cost_delay</code> and <code>autovacuum_vacuum_cost_limit</code>. <code>autovacuum_vacuum_cost_delay</code> is the amount of time that the autovacuum process will halt processing when the <code>autovacuum_vacuum_cost_limit</code> is reached. Imagine this series of events - a table reaches 10% bloat, meaning 10% of the tuples are dead. When the 10% threshold is reached, the autovacuum worker begins to work and starts accruing cost. When that cost reaches <code>autovacuum_vacuum_cost_limit</code>, it will pause for the duration specified by <code>autovacuum_vacuum_cost_delay</code>, and then continue working until it is complete.</p><p>Modifying these can craft the perfect balance between seamless vacuuming and system efficiency. Let’s increase the cost limit to the max, and reduce the delay by  half. This will let the autovacuum process run longer and pause for a shorter period of time when it does reach the cost limit, to ideally reduce bloat faster and reduce query latency.</p><div><div><pre tabindex="0"><code><span><span>ALTER</span><span> SYSTEM </span><span>SET</span><span> autovacuum_vacuum_cost_delay </span><span>=</span><span> </span><span>&#39;10ms&#39;</span><span>;</span><span></span><br/></span><span><span></span><span>ALTER</span><span> SYSTEM </span><span>SET</span><span> autovacuum_vacuum_cost_limit </span><span>=</span><span> </span><span>10000</span><span>;</span><span></span><br/></span><span><span></span><span>SELECT</span><span> pg_reload_conf</span><span>(</span><span>)</span><span>;</span><br/></span></code></pre></div></div><p><img loading="lazy" alt="delay_cost_limit" src="https://glitch.at.goth.cafe/assets/images/delay_limit-cd8db2fe56a5809a912c8d92bcbab133.png" title="delay-cost-limit" width="1000" height="600"/></p><p>We have a slight reduction in average latency, but we can still see that the obviously grows in latency over time and decrease in TPS. It clears roughly every 60 seconds.</p><h2 id="fine-tuning-auto-vacuum-scale-factors">Fine-Tuning Auto Vacuum Scale Factors<a href="#fine-tuning-auto-vacuum-scale-factors" aria-label="Direct link to Fine-Tuning Auto Vacuum Scale Factors" title="Direct link to Fine-Tuning Auto Vacuum Scale Factors">​</a></h2><p>In the previous example, we manually vacuumed our table. But postgres gives us an automated way to configure the vacuum process. One of the most critical parameters is the <code>autovacuum_vacuum_scale_factor</code>; it denotes the portion of the table size that, when surpassed by &#34;dead&#34; rows, prompts a vacuum action. For tables that see frequent data changes, it might be beneficial to lessen this value.</p><div><div><pre tabindex="0"><code><span><span>ALTER</span><span> SYSTEM </span><span>SET</span><span> autovacuum_vacuum_scale_factor </span><span>=</span><span> </span><span>0.1</span><span>;</span><span></span><br/></span><span><span></span><span>SELECT</span><span> pg_reload_conf</span><span>(</span><span>)</span><span>;</span><br/></span></code></pre></div></div><p><img loading="lazy" alt="scale-factor" src="https://glitch.at.goth.cafe/assets/images/scale_factor-3f330c83cc61eb06bc3c92af8348f85d.png" title="scale-factor" width="1000" height="600"/></p><p>Reducing the scale factor had minimal impact on our result, so allowing the autovacuum to trigger sooner did not help. We can see that the period of the sawtooth pattern is still about 60 seconds, which means there we are probably limited by <code>autovacuum_naptime</code>, which we&#39;ll talk about next.</p><h2 id="a-quick-siesta-for-your-system">A Quick Siesta for Your System<a href="#a-quick-siesta-for-your-system" aria-label="Direct link to A Quick Siesta for Your System" title="Direct link to A Quick Siesta for Your System">​</a></h2><p>The autovacuum_naptime parameter in Postgres specifies the minimum delay between autovacuum runs on any given database. The default (which we set earlier) is <code>1min</code>. Generally, depending on just how high-churn your workloads are, it might be necessary to decrease this value, whereas a longer interval could be suited for environments that are not churning at such a high rate. But our table has a crazy amount of churn.</p><p>We want to reduce the height of the latency peaks. One way to do this is to make the vacuum more aggressive and tell it to run sooner. We tried to influence that by setting the <code>autovacuum_vacuum_scale_factor</code>, but we can also lower the <code>autovacuum_naptime</code> value, which will also allow it to run sooner. Let’s cut it in half.</p><div><div><pre tabindex="0"><code><span><span>ALTER</span><span> SYSTEM </span><span>SET</span><span> autovacuum_naptime </span><span>=</span><span> </span><span>&#39;30s&#39;</span><span>;</span><span></span><br/></span><span><span></span><span>SELECT</span><span> pg_reload_conf</span><span>(</span><span>)</span><span>;</span><br/></span></code></pre></div></div><p><img loading="lazy" alt="naptime" src="https://glitch.at.goth.cafe/assets/images/naptime-f26979e9689635484e7e55d154a70968.png" title="naptime" width="1000" height="600"/></p><p>Allowing the autovacuumer to run more frequently reduced our average latency and increase TPS. However, we’re still seeing a noticeable sawtooth pattern and high standard deviation of latency. Let’s completely disable the cost limitations to the vacuum process, let it have as much compute as it needs.</p><div><div><pre tabindex="0"><code><span><span>ALTER</span><span> SYSTEM </span><span>SET</span><span> autovacuum_vacuum_cost_delay </span><span>=</span><span> </span><span>&#39;0&#39;</span><span>;</span><span></span><br/></span><span><span></span><span>SELECT</span><span> pg_reload_conf</span><span>(</span><span>)</span><span>;</span><br/></span></code></pre></div></div><p><img loading="lazy" alt="disable-cost" src="https://glitch.at.goth.cafe/assets/images/disable_cost-d82a984a4c4bff36e6bd4bce3aad305b.png" title="disable-cost" width="1000" height="600"/></p><p>Finally, reduce naptime to 10s</p><div><div><pre tabindex="0"><code><span><span>ALTER</span><span> SYSTEM </span><span>SET</span><span> autovacuum_naptime </span><span>=</span><span> </span><span>&#39;10s&#39;</span><span>;</span><span></span><br/></span><span><span></span><span>SELECT</span><span> pg_reload_conf</span><span>(</span><span>)</span><span>;</span><br/></span></code></pre></div></div><p><img loading="lazy" alt="naptime-final" src="https://glitch.at.goth.cafe/assets/images/naptime_final-25b01a2089dac176cf59357ee07ae222.png" title="naptime-final" width="1000" height="600"/></p><p>Overall, we’ve iterated on autovacuum settings and reduced the average latency from 3.4ms to 2.8ms and stddev from 0.8ms to 0.7ms, which helped increase TPS from 4.3k to about 5.3k.</p><p>Configuring the autovacuum settings can be a lot of fun and the appreciated values are wildly dependent on the workload. We covered the absurdly high churn use case on a single-table today, which is very similar to what we see when running applications using PGMQ. Vacuum is complicated and can be <a href="https://www.enterprisedb.com/blog/postgresql-vacuum-and-analyze-best-practice-tips" target="_blank" rel="noopener noreferrer">tuned differently</a> when considering multiple tables with different workloads. Other OLTP use cases will call for different settings, and OLAP workloads may be less influenced by the vacuum settings altogether. Follow us, and sign up for the Tembo Cloud waitlist because we will surely be writing about these other topics soon.</p><h2 id="more-on-this-topic">More on this topic<a href="#more-on-this-topic" aria-label="Direct link to More on this topic" title="Direct link to More on this topic">​</a></h2><p>Watch the video on <a href="https://www.youtube.com/watch?v=D832gi8Qrv4" target="_blank" rel="noopener noreferrer">Optimizing autovacuum: PostgreSQL’s vacuum cleaner by Samay Sharma</a>.</p></div></div>
  </body>
</html>
