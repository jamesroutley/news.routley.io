<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.lytix.co/posts/self-hosting-llama-3">Original</a>
    <h1>Cost of self hosting Llama-3 8B-Instruct</h1>
    
    <div id="readability-page-1" class="page"><div id="__next"><article dir="ltr"><div><div><div><p>Sid Premkumar</p><!-- --><p>,<time datetime="2024-06-13T00:00:00.000Z">Thu Jun 13 2024</time><span>•</span><a href="https://blog.lytix.co/tags/llama-3">llama-3</a></p></div></div></div><img src="https://blog.lytix.co/posts/self-hosting-llama-3/cover.webp" alt="Cover Image"/>
<h2>How much does it cost to self host a LLM?<a href="#how-much-does-it-cost-to-self-host-a-llm" id="how-much-does-it-cost-to-self-host-a-llm" aria-label="Permalink for this section"></a></h2>
<h4>⚡️ TLDR: Assuming 100% utilization of your model <code dir="ltr">Llama-3 8B-Instruct</code> model costs about $17 dollars per 1M tokens when self hosting with EKS, vs ChatGPT with the same workload can offer $1 per 1M tokens. Choosing to self host the hardware can make the cost &lt;$0.01 per 1M token that takes ~5.5 years to break even.<a href="#️-tldr-assuming-100-utilization-of-your-model-llama-3-8b-instruct-model-costs-about-17-dollars-per-1m-tokens-when-self-hosting-with-eks-vs-chatgpt-with-the-same-workload-can-offer-1-per-1m-tokens-choosing-to-self-host-the-hardware-can-make-the-cost-001-per-1m-token-that-takes-55-years-to-break-even" id="️-tldr-assuming-100-utilization-of-your-model-llama-3-8b-instruct-model-costs-about-17-dollars-per-1m-tokens-when-self-hosting-with-eks-vs-chatgpt-with-the-same-workload-can-offer-1-per-1m-tokens-choosing-to-self-host-the-hardware-can-make-the-cost-001-per-1m-token-that-takes-55-years-to-break-even" aria-label="Permalink for this section"></a></h4>
<p>A question we often get is how do you scale with ChatGPT. One thing we wanted to try is to determine the cost of self hosting an open model such as Llama-3.</p>
</article></div></div>
  </body>
</html>
