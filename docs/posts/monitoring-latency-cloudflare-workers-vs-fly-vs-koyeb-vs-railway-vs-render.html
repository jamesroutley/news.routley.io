<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.openstatus.dev/blog/monitoring-latency-cf-workers-fly-koyeb-raylway-render">Original</a>
    <h1>Monitoring latency: Cloudflare Workers vs Fly vs Koyeb vs Railway vs Render</h1>
    
    <div id="readability-page-1" class="page"><div><p>You want to know which cloud providers offer the lowest latency?</p>
<p>In this post, I compare the latency of
<a href="#cloudflare-workers">Cloudflare Workers</a>, <a href="#flyio">Fly</a>, <a href="#koyeb">Koyeb</a>,
<a href="#railway">Railway</a> and <a href="#render">Render</a> using
<a href="https://www.openstatus.dev" target="_blank" rel="noopener noreferrer">OpenStatus</a>.</p>
<p>I deployed the application on the cheapest or free tier offered by each
provider.</p>
<p>For this test, I used a basic <a href="https://hono.dev" target="_blank" rel="noopener noreferrer">Hono</a> server that returns a
simple text response.</p>
<div data-rehype-pretty-code-fragment=""><pre tabindex="0" data-language="js" data-theme="default"><code data-language="js" data-theme="default"><span data-line=""><span>const</span><span> </span><span>app</span><span> </span><span>=</span><span> </span><span>new</span><span> </span><span>Hono</span><span>();</span></span>
<span data-line=""><span>app.</span><span>use</span><span>(</span><span>&#34;*&#34;</span><span>, </span><span>logger</span><span>());</span></span>
<span data-line=""> </span>
<span data-line=""><span>app.</span><span>use</span><span>(</span><span>&#34;*&#34;</span><span>, </span><span>poweredBy</span><span>());</span></span>
<span data-line=""> </span>
<span data-line=""><span>app.</span><span>get</span><span>(</span><span>&#34;/&#34;</span><span>, (</span><span>c</span><span>) </span><span>=&gt;</span><span> {</span></span>
<span data-line=""><span>  </span><span>return</span><span> c.</span><span>text</span><span>(</span></span>
<span data-line=""><span>    </span><span>&#34;Just return the desired http status code, e.g. /404 ðŸ¤¯ </span><span>\n</span><span>https://www.openstatus.dev&#34;</span><span>,</span></span>
<span data-line=""><span>  );</span></span>
<span data-line=""><span>});</span></span></code></pre></div>
<p>You can find the code <a href="https://github.com/openstatusHQ/status-code" target="_blank" rel="noopener noreferrer">here</a>, itâ€™s
open source ðŸ˜‰.</p>
<p>OpenStatus monitored our endpoint every <strong>10 minutes</strong> from <strong>6 locations</strong>
located in Amsterdam, Ashburn, Hong Kong, Johannesburg, Sao Paulo and Sydney.</p>
<p>It&#39;s a good way to test our own product and improve it.</p>
<p>Let&#39;s analyze the data from the past two weeks.</p>
<h2 id="cloudflare-workers">Cloudflare workers<a aria-hidden="true" href="#cloudflare-workers"><span></span></a></h2>
<p>Cloudflare Workers is a serverless platform by Cloudflare. It lets you build new
applications using JavaScript/Typescript. You can deploy up to 100 worker
scripts for free, running on more than 275 network locations.</p>
<h3 id="latency-metrics">Latency metrics<a aria-hidden="true" href="#latency-metrics"><span></span></a></h3>


<h3 id="timing-metrics">Timing metrics<a aria-hidden="true" href="#timing-metrics"><span></span></a></h3>
<div><table><thead><tr><th>Region</th><th>DNS (ms)</th><th>Connection (ms)</th><th>TLS Handshake (ms)</th><th>TTFB (ms)</th><th>Transfert (ms)</th></tr></thead><tbody><tr><td>AMS</td><td>17</td><td>2</td><td>17</td><td>27</td><td>0</td></tr><tr><td>GRU</td><td>38</td><td>2</td><td>13</td><td>28</td><td>0</td></tr><tr><td>HKG</td><td>19</td><td>2</td><td>13</td><td>29</td><td>0</td></tr><tr><td>IAD</td><td>24</td><td>1</td><td>14</td><td>30</td><td>0</td></tr><tr><td>JNB</td><td>123</td><td>168</td><td>182</td><td>185</td><td>0</td></tr><tr><td>SYD</td><td>51</td><td>1</td><td>11</td><td>25</td><td>0</td></tr></tbody></table></div>
<p>I can notice that Johannesburg&#39;s latency is about ten times higher than that of
the other monitors.</p>

<p>From the Cloudflare request I can get the location of the workers that handle
the request, with <code>Cf-ray</code> in the headers response.</p>
<div><table><thead><tr><th>Checker region</th><th>Workers region</th><th>number of request</th></tr></thead><tbody><tr><td>HKG</td><td>HKG</td><td>1831</td></tr><tr><td>SYD</td><td>SYD</td><td>1831</td></tr><tr><td>AMS</td><td>AMS</td><td>1831</td></tr><tr><td>IAD</td><td>IAD</td><td>1831</td></tr><tr><td>GRU</td><td>GRU</td><td>1791</td></tr><tr><td>GRU</td><td>GIG</td><td>40</td></tr><tr><td>JNB</td><td>AMS</td><td>741</td></tr><tr><td>JNB</td><td>MUC</td><td>4</td></tr><tr><td>JNB</td><td>HKG</td><td>5</td></tr><tr><td>JNB</td><td>SIN</td><td>6</td></tr><tr><td>JNB</td><td>NRT</td><td>8</td></tr><tr><td>JNB</td><td>EWR</td><td>10</td></tr><tr><td>JNB</td><td>CDG</td><td>82</td></tr><tr><td>JNB</td><td>FRA</td><td>276</td></tr><tr><td>JNB</td><td>LHR</td><td>699</td></tr><tr><td>JNB</td><td>AMS</td><td>741</td></tr></tbody></table></div>
<p>I can see all the request from JNB is never routed to a nearby data-center.</p>
<p>Apart from the strange routing error in Johannesburg, Cloudflare workers are
fast worldwide.</p>
<p>I have not experienced any cold start issues.</p>
<h2 id="flyio">Fly.io<a aria-hidden="true" href="#flyio"><span></span></a></h2>
<p>Fly.io simplifies deploying and running server-side applications globally.
Developers can deploy their applications near users worldwide for low latency
and high performance. It uses a lightweight Firecracker VM to easily deploy
Docker images.</p>
<h3 id="latency-metrics-1">Latency metrics<a aria-hidden="true" href="#latency-metrics-1"><span></span></a></h3>


<h3 id="timing-metrics-1">Timing metrics<a aria-hidden="true" href="#timing-metrics-1"><span></span></a></h3>
<div><table><thead><tr><th>Region</th><th>DNS (ms)</th><th>Connection (ms)</th><th>TLS Handshake (ms)</th><th>TTFB (ms)</th><th>Transfert (ms)</th></tr></thead><tbody><tr><td>AMS</td><td>6</td><td>1</td><td>8</td><td>1469</td><td>0</td></tr><tr><td>GRU</td><td>5</td><td>0</td><td>4</td><td>1431</td><td>0</td></tr><tr><td>HKG</td><td>4</td><td>0</td><td>5</td><td>1473</td><td>0</td></tr><tr><td>IAD</td><td>3</td><td>0</td><td>5</td><td>1470</td><td>0</td></tr><tr><td>JNB</td><td>24</td><td>0</td><td>5</td><td>1423</td><td>0</td></tr><tr><td>SYD</td><td>3</td><td>0</td><td>3</td><td>1489</td><td>0</td></tr></tbody></table></div>
<p>The DNS is fast, our checker is attempting to connect to a region in the same
data center, but our machine&#39;s cold start is slowing us down, leading to the
high TTFB.</p>
<p>Hereâ€™s our config for Fly.io:</p>
<div data-rehype-pretty-code-fragment=""><pre tabindex="0" data-language="toml" data-theme="default"><code data-language="toml" data-theme="default"><span data-line=""><span>app = </span><span>&#39;statuscode&#39;</span></span>
<span data-line=""><span>primary_region = </span><span>&#39;ams&#39;</span></span>
<span data-line=""> </span>
<span data-line=""><span>[</span><span>build</span><span>]</span></span>
<span data-line=""><span>  dockerfile = </span><span>&#34;./Dockerfile&#34;</span></span>
<span data-line=""> </span>
<span data-line=""><span>[</span><span>http_service</span><span>]</span></span>
<span data-line=""><span>  internal_port = </span><span>3000</span></span>
<span data-line=""><span>  force_https = </span><span>true</span></span>
<span data-line=""><span>  auto_stop_machines = </span><span>true</span></span>
<span data-line=""><span>  auto_start_machines = </span><span>true</span></span>
<span data-line=""><span>  min_machines_running = </span><span>0</span></span>
<span data-line=""><span>  processes = [</span><span>&#39;app&#39;</span><span>]</span></span>
<span data-line=""> </span>
<span data-line=""><span>[[</span><span>vm</span><span>]]</span></span>
<span data-line=""><span>  cpu_kind = </span><span>&#39;shared&#39;</span></span>
<span data-line=""><span>  cpus = </span><span>1</span></span>
<span data-line=""><span>  memory_mb = </span><span>256</span></span></code></pre></div>
<p>The primary region of our server is Amsterdam, and the fly instances is getting
paused after a period of inactivity.</p>
<p>The machine starts slowly, as indicated by the logs showing a start time of
<code>1.513643778s.</code></p>
<pre><code>2024-02-14T11:24:16.107 proxy[286560ea703108] ams [info] Starting machine

2024-02-14T11:24:16.322 app[286560ea703108] ams [info] [ 0.035736] PCI: Fatal: No config space access function found

2024-02-14T11:24:16.533 app[286560ea703108] ams [info] INFO Starting init (commit: bfa79be)...

2024-02-14T11:24:16.546 app[286560ea703108] ams [info] INFO Preparing to run: `/usr/local/bin/docker-entrypoint.sh bun start` as root

2024-02-14T11:24:16.558 app[286560ea703108] ams [info] INFO [fly api proxy] listening at /.fly/api

2024-02-14T11:24:16.565 app[286560ea703108] ams [info] 2024/02/14 11:24:16 listening on [fdaa:3:2ef:a7b:10c:3c9a:5b4:2]:22 (DNS: [fdaa::3]:53)

2024-02-14T11:24:16.611 app[286560ea703108] ams [info] $ bun src/index.ts

2024-02-14T11:24:16.618 runner[286560ea703108] ams [info] Machine started in 460ms

2024-02-14T11:24:17.621 proxy[286560ea703108] ams [info] machine started in 1.513643778s

2024-02-14T11:24:17.628 proxy[286560ea703108] ams [info] machine became reachable in 7.03669ms
</code></pre>
<h4 id="openstatus-prod-metrics">OpenStatus Prod metrics<a aria-hidden="true" href="#openstatus-prod-metrics"><span></span></a></h4>
<p>If you update your fly.toml file to include the following, you can get the zero
cold start and achieve a better latency.</p>
<pre><code>  min_machines_running = 1
</code></pre>
<p>This is our data for our production server deploy on Fly.io.</p>

<blockquote>
<p>We use Fly.io in production, and the machine never sleeps, yielding much
better results.</p>
</blockquote>
<h2 id="koyeb">Koyeb<a aria-hidden="true" href="#koyeb"><span></span></a></h2>
<p>Koyeb is a developer-friendly serverless platform that allows for global app
deployment without the need for operations, servers, or infrastructure
management. Koyeb offers a free Starter plan that includes one Web Service, one
Database service. The platform focuses on ease of deployment and scalability for
developers</p>
<h3 id="latency-metrics-2">Latency metrics<a aria-hidden="true" href="#latency-metrics-2"><span></span></a></h3>


<h3 id="timing-metrics-2">Timing metrics<a aria-hidden="true" href="#timing-metrics-2"><span></span></a></h3>
<div><table><thead><tr><th>Region</th><th>DNS (ms)</th><th>Connection (ms)</th><th>TLS Handshake (ms)</th><th>TTFB (ms)</th><th>Transfert (ms)</th></tr></thead><tbody><tr><td>AMS</td><td>50</td><td>2</td><td>17</td><td>107</td><td>0</td></tr><tr><td>GRU</td><td>139</td><td>65</td><td>75</td><td>407</td><td>0</td></tr><tr><td>HKG</td><td>48</td><td>2</td><td>13</td><td>321</td><td>0</td></tr><tr><td>IAD</td><td>35</td><td>1</td><td>12</td><td>129</td><td>0</td></tr><tr><td>JNB</td><td>298</td><td>1</td><td>11</td><td>720</td><td>0</td></tr><tr><td>SYD</td><td>97</td><td>1</td><td>10</td><td>711</td><td>0</td></tr></tbody></table></div>

<p>The request headers show that none of our requests are cached. They contain
<code>cf-cache-status: dynamic</code>. Cloudflare handles the Koyeb edge layer.
<a href="https://www.koyeb.com/blog/building-a-multi-region-service-mesh-with-kuma-envoy-anycast-bgp-and-mtls" target="_blank" rel="noopener noreferrer">https://www.koyeb.com/blog/building-a-multi-region-service-mesh-with-kuma-envoy-anycast-bgp-and-mtls</a></p>
<p>Our requests follow this route:</p>
<pre><code>Cf workers -&gt; koyeb Global load balancer -&gt; koyeb backend
</code></pre>
<p>Letâ€™s see where did we hit the cf workers</p>
<div><table><thead><tr><th>Checker region</th><th>Workers region</th><th>number of request</th></tr></thead><tbody><tr><td>AMS</td><td>AMS</td><td>1866</td></tr><tr><td>GRU</td><td>GRU</td><td>504</td></tr><tr><td>GRU</td><td>IAD</td><td>38</td></tr><tr><td>GRU</td><td>MIA</td><td>688</td></tr><tr><td>GRU</td><td>EWR</td><td>337</td></tr><tr><td>GRU</td><td>CIG</td><td>299</td></tr><tr><td>HKG</td><td>HKG</td><td>1866</td></tr><tr><td>IAD</td><td>IAD</td><td>1866</td></tr><tr><td>JNB</td><td>JNB</td><td>1861</td></tr><tr><td>JNB</td><td>AMS</td><td>1</td></tr><tr><td>SYD</td><td>SYD</td><td>1866</td></tr></tbody></table></div>
<p>Koyeb Global Load Balancer region we hit:</p>
<div><table><thead><tr><th>Checker region</th><th>Koyeb Global Load Balancer</th><th>number of request</th></tr></thead><tbody><tr><td>AMS</td><td>FRA1</td><td>1866</td></tr><tr><td>GRU</td><td>WAS1</td><td>1866</td></tr><tr><td>HKG</td><td>SIN1</td><td>1866</td></tr><tr><td>IAD</td><td>WAS1</td><td>1866</td></tr><tr><td>JNB</td><td>PAR1</td><td>4</td></tr><tr><td>JNB</td><td>SIN1</td><td>1864</td></tr><tr><td>JNB</td><td>FRA1</td><td>1</td></tr><tr><td>JNB</td><td>SIN1</td><td>1866</td></tr></tbody></table></div>
<p>I have deployed our app in the Frankfurt data-center.</p>
<h2 id="railway">Railway<a aria-hidden="true" href="#railway"><span></span></a></h2>
<p>Railway is a cloud platform designed for building, shipping, and monitoring
applications without the need for Platform Engineers. It simplifies the
application development process by offering seamless deployment and monitoring
capabilities.</p>
<h3 id="latency-metrics-3">Latency metrics<a aria-hidden="true" href="#latency-metrics-3"><span></span></a></h3>


<h3 id="timing-metrics-3">Timing metrics<a aria-hidden="true" href="#timing-metrics-3"><span></span></a></h3>
<div><table><thead><tr><th>Region</th><th>DNS (ms)</th><th>Connection (ms)</th><th>TLS Handshake (ms)</th><th>TTFB (ms)</th><th>Transfert (ms)</th></tr></thead><tbody><tr><td>AMS</td><td>9</td><td>21</td><td>18</td><td>158</td><td>0</td></tr><tr><td>GRU</td><td>14</td><td>115</td><td>127</td><td>178</td><td>0</td></tr><tr><td>HKG</td><td>8</td><td>45</td><td>54</td><td>225</td><td>0</td></tr><tr><td>IAD</td><td>7</td><td>2</td><td>14</td><td>65</td><td>0</td></tr><tr><td>JNB</td><td>18</td><td>193</td><td>178</td><td>319</td><td>0</td></tr><tr><td>SYD</td><td>21</td><td>108</td><td>105</td><td>280</td><td>0</td></tr></tbody></table></div>

<p>The headers don&#39;t provide any information.</p>
<p>Railway is using Google Cloud Platform. Itâ€™s the only service that does not
allow us to pick a specific region on the free plan. Our test app will be
located to <code>us-west1</code> Portland, Oregon. We can see that the latency is the
lowest in IAD.</p>
<p>By default our app did not scale down to 0. It was always running. We don&#39;t have
any cold start.</p>
<h2 id="render">Render<a aria-hidden="true" href="#render"><span></span></a></h2>
<p>Render is a platform that simplifies deploying and scaling web applications and
services. It offers features like automated SSL, automatic scaling, native
support for popular frameworks, and one-click deployments from Git. The platform
focuses on simplicity and developer productivity.</p>
<h3 id="latency-metrics-4">Latency metrics<a aria-hidden="true" href="#latency-metrics-4"><span></span></a></h3>


<h3 id="timing-metrics-4">Timing metrics<a aria-hidden="true" href="#timing-metrics-4"><span></span></a></h3>
<div><table><thead><tr><th>Region</th><th>DNS (ms)</th><th>Connection (ms)</th><th>TLS Handshake (ms)</th><th>TTFB (ms)</th><th>Transfert (ms)</th></tr></thead><tbody><tr><td>AMS</td><td>20</td><td>2</td><td>7</td><td>107</td><td>0</td></tr><tr><td>GRU</td><td>61</td><td>2</td><td>6</td><td>407</td><td>0</td></tr><tr><td>HKG</td><td>76</td><td>2</td><td>6</td><td>321</td><td>0</td></tr><tr><td>IAD</td><td>15</td><td>1</td><td>5</td><td>129</td><td>0</td></tr><tr><td>JNB</td><td>36</td><td>161</td><td>167</td><td>720</td><td>0</td></tr><tr><td>SYD</td><td>103</td><td>1</td><td>4</td><td>711</td><td>0</td></tr></tbody></table></div>

<p>The headers don&#39;t provide any information.</p>
<p>I have deployed our app in the Frankfurt data-center.</p>
<p>According to the Render docs, the free tier will shut down the service after 15
minutes of inactivity. However, our app is being accessed by a monitor every 10
minutes. We should never scale down to 0.</p>
<pre><code>Render spins down a Free web service that goes 15 minutes without receiving inbound traffic. Render spins the service back up whenever it next receives a request to process.
</code></pre>
<p>I think the failures are due to the cold start of our app. We have a default
timeout of 30s and the render app takes up to 50s to start.We might have hit an
inflection point between cold and warm.</p>
<h2 id="conclusion">Conclusion<a aria-hidden="true" href="#conclusion"><span></span></a></h2>
<p>Here are the results of our test:</p>
<div><table><thead><tr><th>Provider</th><th>Uptime</th><th>Fails Ping</th><th>Total Pings</th><th>AVG latency (ms)</th><th>P75 (ms)</th><th>P90 (ms)</th><th>P95 (ms)</th><th>P99 (ms)</th></tr></thead><tbody><tr><td>CF Workers</td><td>100</td><td>0</td><td>10,956</td><td>182</td><td>138</td><td>690</td><td>778</td><td>991</td></tr><tr><td>Fly.io</td><td>100</td><td>0</td><td>10,952</td><td>1,471</td><td>1,514</td><td>1,555</td><td>1,626</td><td>2,547</td></tr><tr><td>Koyeb</td><td>100</td><td>0</td><td>10,955</td><td>536</td><td>738</td><td>881</td><td>1,013</td><td>1,525</td></tr><tr><td>Railway</td><td>99.991</td><td>1</td><td>10,955</td><td>381</td><td>469</td><td>653</td><td>661</td><td>850</td></tr><tr><td>Render</td><td>99.89</td><td>12</td><td>10,946</td><td>451</td><td>447</td><td>591</td><td>707</td><td>902</td></tr></tbody></table></div>
<p>If you value low latency, Cloudflare Workers are the best option for fast global
performance without cold start issues. They deploy your app worldwide
efficiently.</p>
<p>For multi-region deployment, check out Koyeb and Fly.io.</p>
<p>For specific region deployment, Railway and Render are good choices.</p>
<p>Choosing a cloud provider involves considering not just latency but also user
experience and pricing.</p>
<p>We use Fly.io in production and are satisfied with it.</p>
<h4 id="vercel-coming-soon">Vercel (coming soon)<a aria-hidden="true" href="#vercel-coming-soon"><span></span></a></h4>
<p>I haven&#39;t included Vercel in this test. But I am currently running a test to
compare the latency of Vercel Edge, Vercel Serverless. Results will be published
soon.</p>
<p>If you want to monitor your API or website, create an account on
<a href="https://www.openstatus.dev/app/sign-up?ref=blog-monitoring" target="_blank" rel="noopener noreferrer">OpenStatus</a>.</p></div></div>
  </body>
</html>
