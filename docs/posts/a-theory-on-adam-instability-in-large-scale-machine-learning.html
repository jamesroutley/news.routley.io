<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://arxiv.org/abs/2304.09871">Original</a>
    <h1>A Theory on Adam Instability in Large-Scale Machine Learning</h1>
    
    <div id="readability-page-1" class="page"><div id="content-inner">
  <div id="abs">
    
    
    
    <div><p><span>Authors:</span><a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Molybog%2C+I">Igor Molybog</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Albert%2C+P">Peter Albert</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chen%2C+M">Moya Chen</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=DeVito%2C+Z">Zachary DeVito</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Esiobu%2C+D">David Esiobu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Goyal%2C+N">Naman Goyal</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Koura%2C+P+S">Punit Singh Koura</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Narang%2C+S">Sharan Narang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Poulton%2C+A">Andrew Poulton</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Silva%2C+R">Ruan Silva</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tang%2C+B">Binh Tang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liskovich%2C+D">Diana Liskovich</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Xu%2C+P">Puxin Xu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+Y">Yuchen Zhang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kambadur%2C+M">Melanie Kambadur</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Roller%2C+S">Stephen Roller</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Zhang%2C+S">Susan Zhang</a></p></div>
      
    
  
  
  
    <p><a aria-describedby="download-button-info" href="https://arxiv.org/pdf/2304.09871">Download PDF</a></p><blockquote>
            <span>Abstract:</span>  We present a theory for the previously unexplained divergent behavior noticed
in the training of large language models. We argue that the phenomenon is an
artifact of the dominant optimization algorithm used for training, called Adam.
We observe that Adam can enter a state in which the parameter update vector has
a relatively large norm and is essentially uncorrelated with the direction of
descent on the training loss landscape, leading to divergence. This artifact is
more likely to be observed in the training of a deep model with a large batch
size, which is the typical setting of large-scale language model training. To
argue the theory, we present observations from the training runs of the
language models of different scales: 7 billion, 30 billion, 65 billion, and 546
billion parameters.

    </blockquote>

    <!--CONTEXT-->
    
  </div>
</div><div>
      <h2>Submission history</h2><p> From: Igor Molybog [<a href="https://arxiv.org/show-email/fcecba99/2304.09871">view email</a>]
      </p></div></div>
  </body>
</html>
