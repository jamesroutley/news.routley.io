<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://bluestyle97.github.io/dream3d/">Original</a>
    <h1>Dream3D: Zero-Shot Text-to-3D Synthesis Using 3D and Text-to-Image Diffusion</h1>
    
    <div id="readability-page-1" class="page">

<!-- <nav class="navbar" role="navigation" aria-label="main navigation">
  <div class="navbar-brand">
    <a role="button" class="navbar-burger" aria-label="menu" aria-expanded="false">
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
      <span aria-hidden="true"></span>
    </a>
  </div>
  <div class="navbar-menu">
    <div class="navbar-start" style="flex-grow: 1; justify-content: center;">
      <a class="navbar-item" href="https://keunhong.com">
      <span class="icon">
          <i class="fas fa-home"></i>
      </span>
      </a>

      <div class="navbar-item has-dropdown is-hoverable">
        <a class="navbar-link">
          More Research
        </a>
        <div class="navbar-dropdown">
          <a class="navbar-item" href="https://hypernerf.github.io">
            HyperNeRF
          </a>
          <a class="navbar-item" href="https://nerfies.github.io">
            Nerfies
          </a>
          <a class="navbar-item" href="https://latentfusion.github.io">
            LatentFusion
          </a>
          <a class="navbar-item" href="https://photoshape.github.io">
            PhotoShape
          </a>
        </div>
      </div>
    </div>

  </div>
</nav> -->


<section>
  <div>
    <div>
      <div>
        <div>
          
          <p>
            <span>
              Xintao Wang<sup>1</sup>,
            </span>
            <span>
              Weihao Cheng<sup>1</sup>,
            </span>
            <span>
              Yan-Pei Cao<sup>1</sup>,
            </span>
            <span>
              Ying Shan<sup>1</sup>,
            </span>
            <span>
              Xiaohu Qie<sup>2</sup>,
            </span>
            <span>
              Shenghua Gao<sup>3,4,5</sup>
            </span>
          </p>

          <p><span><sup>1</sup>ARC Lab, <sup>2</sup>Tencent PCG</span>
            <span><sup>3</sup>ShanghaiTech University</span>
          </p>
          <p><span><sup>4</sup>Shanghai Engineering Research Center of Intelligent Vision and Imaging</span>
          </p>
          <p><span><sup>4</sup>Shanghai Engineering Research Center of Energy Efficient and Custom AI IC</span>
          </p>

          
        </div>
      </div>
    </div>
  </div>
</section>

<!-- <section class="hero teaser">
  <div class="container is-max-desktop">
    <div class="hero-body">
      <video id="teaser" autoplay muted loop playsinline height="100%">
        <source src="static/images/video.mp4"
                type="video/mp4">
      </video>
    </div>
  </div>
</section> -->


<section>
  <div>
    <div>
      <div id="results-carousel">

        
        <div>
          <p>&#34;A spaceship in the Star War.&#34;</p>
          <video id="teaser2" autoplay="" controls="" muted="" loop="" playsinline="" height="100%">
            <source src="static/images/teaser2.mp4" type="video/mp4"/>
          </video>
        </div>
        
        <div>
          <p>&#34;A lamp imitating sunflower.&#34;</p>
          <video id="teaser4" autoplay="" controls="" muted="" loop="" playsinline="" height="100%">
            <source src="static/images/teaser4.mp4" type="video/mp4"/>
          </video>
        </div>
        <div>
          <p>&#34;A lamp imitating rocket.&#34;</p>
          <video id="teaser5" autoplay="" controls="" muted="" loop="" playsinline="" height="100%">
            <source src="static/images/teaser5.mp4" type="video/mp4"/>
          </video>
        </div>
        <div>
          <p>&#34;A wooden park bench overgrown with vines.&#34;</p>
          <video id="teaser6" autoplay="" controls="" muted="" loop="" playsinline="" height="100%">
            <source src="static/images/teaser6.mp4" type="video/mp4"/>
          </video>
        </div>
        
        <div>
          <p>&#34;A plane imitating an eagle.&#34;</p>
          <video id="teaser6" autoplay="" controls="" muted="" loop="" playsinline="" height="100%">
            <source src="static/images/teaser8.mp4" type="video/mp4"/>
          </video>
        </div>
        <div>
          <p>&#34;A monster truck imitating monster.&#34;</p>
          <video id="teaser6" autoplay="" controls="" muted="" loop="" playsinline="" height="100%">
            <source src="static/images/teaser9.mp4" type="video/mp4"/>
          </video>
        </div>
        
        <div>
          <p>&#34;A chair from the future.&#34;</p>
          <video id="teaser6" autoplay="" controls="" muted="" loop="" playsinline="" height="100%">
            <source src="static/images/teaser12.mp4" type="video/mp4"/>
          </video>
        </div>
        

      </div>
    </div>
  </div>
</section>


<section>
  <div>
    <!-- Abstract. -->
    <div>
      <div>
        <h2>Abstract</h2>
        <p>
            Recent CLIP-guided 3D optimization methods, e.g., DreamFields and PureCLIPNeRF achieve great success in zero-shot text-guided 3D synthesis. However, due to the scratch training and random initialization without any prior knowledge, these methods usually fail to generate accurate and faithful 3D structures that conform to the corresponding text. In this paper, we make the first attempt to introduce the explicit 3D shape prior to CLIP-guided 3D optimization methods. Specifically, we first generate a high-quality 3D shape from input texts in the text-to-shape stage as the 3D shape prior. We then utilize it as the initialization of a neural radiance field and then optimize it with the full prompt. For the text-to-shape generation, we present a simple yet effective approach that directly bridges the text and image modalities with a powerful text-to-image diffusion model. To narrow the style domain gap between images synthesized by the text-to-image model and shape renderings used to train the image-to-shape generator, we further propose to jointly optimize a learnable text prompt and fine-tune the text-to-image diffusion model for rendering-style image generation. Our method, namely, Dream3D, is capable of generating imaginative 3D content with better visual quality and shape accuracy than state-of-the-art methods.
          </p>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Method. -->
    <div>
      <div>
        <h2>Method</h2>
        <figure>
          <img src="https://bluestyle97.github.io/dream3d/static/images/pipeline.svg" width="100%/"/>
        </figure>
        <p>
            Overview of our text-guided 3D synthesis framework. (a) In the first text-to-shape stage, we leverage a fine-tuned off-the-shelf text-to-image diffusion model $G_I$ to synthesize a rendering-style image $\boldsymbol{I}_r$ from the input text prompt $y$. Then we generate a latent shape embedding $\boldsymbol{e}_S$ from $\boldsymbol{I}_r$ using a diffusion-model-based shape embedding generation network $G_M$. Finally, we feed $\boldsymbol{e}_S$ into a high-quality 3D shape generator $G_S$ to synthesize a 3D shape $S$, which we use as an explicit 3D shape prior. (b) In the second optimization stage, we use the 3D shape prior $S$ to initialize a neural radiance field and further optimize it with the CLIP guidance to synthesize 3D content consistent with the input text prompt $y$.
          </p>
      </div>
    </div>
    <!--/ Method. -->

    <!-- Paper video. -->
    <div>
      <div>
        <h2>Results</h2>

        <!-- <div class="container is-max-desktop">
          <div class="hero-body">
            <video id="teaser" autoplay muted loop playsinline height="100%">
              <source src="static/images/video.mp4" type="video/mp4">
            </video>
          </div>
        </div> -->

        <div>
          <div>
            <p>&#34;A minecraft car.&#34;</p>
            
            <p>&#34;A car from the Cars movie.&#34;</p>
            
            <p>&#34;The Iron Throne in Game of Thrones.&#34;</p>
            
            <p>&#34;A cabinet designed by van Gogh.&#34;</p>
            
            <p>&#34;A lamp imitating sunflower.&#34;</p>
            
            <p>&#34;A car is burning.&#34;</p>
            
            <p>&#34;A fishing boat floating on the water.&#34;</p>
            
            <p>&#34;A chair imitating cactus.&#34;</p>
            
            <p>&#34;An aircraft carrier.&#34;</p>
            <table>
              <tbody><tr>
                <td><video autoplay="" controls="" muted="" loop="" playsinline="" width="100%"><source src="static/images/result91.mp4" type="video/mp4"/></video></td>
                <td><video autoplay="" controls="" muted="" loop="" playsinline="" width="100%"><source src="static/images/result92.mp4" type="video/mp4"/></video></td>
                <td><video autoplay="" controls="" muted="" loop="" playsinline="" width="100%"><source src="static/images/result93.mp4" type="video/mp4"/></video></td>
                <td><video autoplay="" controls="" muted="" loop="" playsinline="" width="100%"><source src="static/images/result94.mp4" type="video/mp4"/></video></td>
              </tr>
              <tr>
                <td>CLIP-Mesh</td>
                <td>Dream Fields</td>
                <td>PureCLIPNeRF</td>
                <td><b>Ours</b></td>
              </tr>
            </tbody></table>
          </div>
        </div>

      </div>
    </div>
    <!--/ Paper video. -->
  </div>
</section>


<!-- <section class="section">
  <div class="container is-max-desktop">

    <div class="columns is-centered"> -->

      <!-- Visual Effects. -->
      <!-- <div class="column">
        <div class="content">
          <h2 class="title is-3">Visual Effects</h2>
          <p>
            Using <i>nerfies</i> you can create fun visual effects. This Dolly zoom effect
            would be impossible without nerfies since it would require going through a wall.
          </p>
          <video id="dollyzoom" autoplay controls muted loop playsinline height="100%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/dollyzoom-stacked.mp4"
                    type="video/mp4">
          </video>
        </div>
      </div> -->
      <!--/ Visual Effects. -->

      <!-- Matting. -->
      <!-- <div class="column">
        <h2 class="title is-3">Matting</h2>
        <div class="columns is-centered">
          <div class="column content">
            <p>
              As a byproduct of our method, we can also solve the matting problem by ignoring
              samples that fall outside of a bounding box during rendering.
            </p>
            <video id="matting-video" controls playsinline height="100%">
              <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/matting.mp4"
                      type="video/mp4">
            </video>
          </div>

        </div>
      </div>
    </div> -->
    <!--/ Matting. -->

    <!-- Animation. -->
    <!-- <div class="columns is-centered">
      <div class="column is-full-width">
        <h2 class="title is-3">Results</h2> -->

        <!-- Interpolating. -->
        <!-- <div class="content has-text-justified">
          <p>
            We can also animate the scene by interpolating the deformation latent codes of two input
            frames. Use the slider here to linearly interpolate between the left frame and the right
            frame.
          </p>
        </div>
        <div class="columns is-vcentered interpolation-panel">
          <div class="column is-3 has-text-centered">
            <img src="https://homes.cs.washington.edu/~kpar/nerfies/images/interpolate_start.jpg"
                 class="interpolation-image"
                 alt="Interpolate start reference image."/>
            <p>Start Frame</p>
          </div>
          <div class="column interpolation-video-column">
            <div id="interpolation-image-wrapper">
              Loading...
            </div>
            <input class="slider is-fullwidth is-large is-info"
                   id="interpolation-slider"
                   step="1" min="0" max="100" value="0" type="range">
          </div>
          <div class="column is-3 has-text-centered">
            <img src="https://homes.cs.washington.edu/~kpar/nerfies/images/interpolate_end.jpg"
                 class="interpolation-image"
                 alt="Interpolation end reference image."/>
            <p class="is-bold">End Frame</p>
          </div>
        </div>
        <br/> -->
        <!--/ Interpolating. -->

        <!-- Re-rendering. -->
        <!-- <h3 class="title is-4">Re-rendering the input video</h3>
        <div class="content has-text-justified">
          <p>
            Using <span class="dnerf">Nerfies</span>, you can re-render a video from a novel
            viewpoint such as a stabilized camera by playing back the training deformations.
          </p>
        </div>
        <div class="content has-text-centered">
          <video id="replay-video"
                 controls
                 muted
                 preload
                 playsinline
                 width="75%">
            <source src="https://homes.cs.washington.edu/~kpar/nerfies/videos/replay.mp4"
                    type="video/mp4">
          </video>
        </div> -->
        <!--/ Re-rendering. -->

      <!-- </div>
    </div> -->
    <!--/ Animation. -->


  <!-- </div>
</section> -->


<section id="BibTeX">
  <div>
    <h2>BibTeX</h2>
    <pre><code>@article{xu2022dream3d,
  author    = {Xu, Jiale and Wang, Xintao and Cheng, Weihao and Cao, Yan-Pei and Shan, Ying and Qie, Xiaohu and Gao, Shenghua},
  title     = {Dream3D: Zero-Shot Text-to-3D Synthesis Using 3D Shape Prior and Text-to-Image Diffusion Models},
  journal   = {arXiv preprint arXiv:2212.14704},
  year      = {2022},
}</code></pre>
  </div>
</section>






</div>
  </body>
</html>
