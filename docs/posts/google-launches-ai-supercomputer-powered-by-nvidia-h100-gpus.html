<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.tomshardware.com/news/google-a3-supercomputer-h100-googleio">Original</a>
    <h1>Google Launches AI Supercomputer Powered by Nvidia H100 GPUs</h1>
    
    <div id="readability-page-1" class="page"><div id="article-body">
<p><a href="https://io.google/2023/" data-url="https://io.google/2023/">Google kicked off Google I/O</a> this afternoon by talking for more than an hour about its numerous advances in artificial intelligence.  The company discussed its new PaLM 2 large language model (<a href="https://www.tomshardware.com/how-to/auto-gpt-ai-agent">LLM</a>) for generative AI, which powers the <a href="https://www.tomshardware.com/news/google-bard-plagiarizing-article">Bard chatbot tool</a>. This is a foundational pillar for adding AI-infused features across Google&#39;s product portfolio, including Google Maps, Google Photos, and Gmail (among others).</p><p>With that in mind, there is a need for some serious horsepower in the cloud to power models in the wild, as millions (and eventually billions) of users send requests for operations as mundane as removing a person lingering in the background of a picture to composing an entire email for you based on a short text prompt. That&#39;s where Google&#39;s new A3 GPU supercomputer comes into focus. Google says the new A3 supercomputers are &#34;purpose-built to train and serve the most demanding AI models that power today&#39;s generative AI and large language model innovation&#34; while delivering 26 exaFlops of AI performance.</p><p>Each A3 supercomputer is packed with 4th generation Intel Xeon Scalable processors backed by 2TB of DDR5-4800 memory. But the real &#34;brains&#34; of the operation come from the eight <a href="https://www.tomshardware.com/news/nvidia-publishes-mlperf-30-performance-of-h100-l4">Nvidia H100 &#34;Hopper&#34; GPUs</a>, which have access to 3.6 TBps of bisectional bandwidth by leveraging NVLink 4.0 and NVSwitch.</p><p>According to Google, A3 represents the first production-level deployment of its GPU-to-GPU data interface, which allows for sharing data at 200 Gbps while bypassing the host CPU. This interface, which Google calls the Infrastructure Processing Unit (IPU), results in a 10x uplift in available network bandwidth for A3 virtual machines (VM) compared to A2 VMs.</p><p>&#34;Google Cloud&#39;s A3 VMs, powered by next-generation NVIDIA H100 GPUs, will accelerate training and serving of generative AI applications,&#34; said Ian Buck, VP for hyperscale and high-performance computing at NVIDIA. &#34;On the heels of Google Cloud&#39;s recently launched G2 instances, we&#39;re proud to continue our work with Google Cloud to help transform enterprises around the world with purpose-built AI infrastructure.&#34; </p><p>If your business wants to leverage A3 virtual machines, the only way to gain access is by filling out Google&#39;s <a href="https://docs.google.com/forms/d/e/1FAIpQLSfWP2weHCBj9AliES43_TA0LO4oOaP5sbGDWWPSbe-NaBuxJA/viewform" data-url="https://docs.google.com/forms/d/e/1FAIpQLSfWP2weHCBj9AliES43_TA0LO4oOaP5sbGDWWPSbe-NaBuxJA/viewform">A3 Preview Interest Form</a> to join the Early Access Program. But as Google clearly states, plugging in your information doesn&#39;t guarantee a spot in the program.</p>
</div><div id="slice-container-newsletterForm-articleInbodyContent"><div data-hydrate="true"><div><section></section><section><p>Get instant access to breaking news, in-depth reviews and helpful tips.</p></section></div></div></div></div>
  </body>
</html>
