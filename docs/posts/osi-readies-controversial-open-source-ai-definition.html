<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://lwn.net/SubscriberLink/995159/a37fb9817a00ebcb/">Original</a>
    <h1>OSI readies controversial open-source AI definition</h1>
    
    <div id="readability-page-1" class="page"><div>

<p>The <a href="https://opensource.org/">Open Source Initiative</a>
(OSI) has been working on defining <a href="https://opensource.org/ai">Open Source AI</a>—that is what
constitutes an AI system that can be used, studied, modified, and
shared for any purpose—for almost two
years. Its <a href="https://opensource.org/about/board-of-directors">board</a> will
be voting on the <a href="https://opensource.org/ai/drafts/the-open-source-ai-definition-1-0-rc2">Open Source AI Definition</a> (OSAID) on Sunday,
October 27, with the 1.0 version slated to be published on
October 28. It is never possible to please <em>everyone</em> in
such an endeavor, and it would be folly to make that a goal. However,
a number of prominent figures in the open-source community have voiced
concerns that OSI is setting the bar too low with the OSAID—which
will undo decades of community work to cajole vendors into adhering to
or respecting the original <a href="https://opensource.org/osd">Open Source
Definition</a> (OSD).</p>

<h4>Defining Open Source AI</h4>

<p>OSI executive director Stefano Maffulli <a href="https://opensource.org/blog/now-is-the-time-to-define-open-source-ai">announced</a>
the organization&#39;s intent to provide a definition for open-source AI
in June 2023. He took exception to announcements of 
&#34;<q>large language models, foundational models, tooling, services all
claiming to be &#39;open&#39; or &#39;Open Source&#39;</q>&#34;, while adding restrictions
which run afoul of the OSD. A <a href="https://spectrum.ieee.org/open-source-llm-not-open">survey</a>
of large-language model (LLM) systems in 2023 found that ostensibly
open-source LLMs did not live up to the name.</p>

<p>The problem is not quite as simple as saying &#34;use an OSD-compliant
license&#34; for LLMs, because there are many more components to
consider. The original OSD is understood to apply to the
source code of a program in &#34;<q>the preferred form in which a
programmer would modify the program</q>&#34;. A program is not considered
open source if a developer cannot study, use, modify, and share a
program, and a license is not OSD‑compliant if it does not
preserve those freedoms. A program can include non-free data and still
be open source. For example, the game <a href="https://github.com/id-Software/Quake-III-Arena">Quake III Arena</a>
(Q3A) is available under the GPLv2. That distribution, however, does
not include the <a href="https://quakewiki.org/wiki/.pak">pak</a>
files that contain the maps, textures, and other content required to
actually play the commercial game. Despite that, others can still use
the Q3A code to create their own games, such as <a href="https://tremulous.net/">Tremulous</a>.</p>

<blockquote>
This LWN.net subscription-only content has been made available to you by
an LWN subscriber.  To see more of this content, please take advantage of
the following special offer.
<h3>Free trial subscription</h3>
           <p>
           Try LWN for free for 1 month: no payment
           or credit card required.  <a href="https://lwn.net/Promo/slink-trial-middle/claim">Activate
           your trial subscription now</a> and see why thousands of
           readers subscribe to LWN.net.
           
</p></blockquote>
<p>When discussing an &#34;AI system&#34;, however, things are much more
complicated. There is more than just the code that is used to run the
models to do work of some kind, and the data is not something that
can be wholly separate from the system in the way that it can be with a
game. When looking at, say, LLMs, there is the model architecture, the
code used to train models, model parameters, the techniques and methodologies used for
training, the procedures for labeling training data, the supporting
libraries, and (of course) the data used to train the models.</p>

<p>OSI has been working on its definition since last year. It held a kickoff meeting on June 21, 2023 at the
Mozilla headquarters in San Francisco. It <a href="https://opensource.org/deepdive/#:~:text=How%20to%20participate">invited
participation</a> afterward via a regular series of in-person
and <a href="https://opensource.org/ai/townhalls">online sessions</a>,
and with a <a href="https://discuss.opensource.org/">forum for online
discussions</a>. LWN <a href="https://lwn.net/Articles/961868/#:~:text=Stefano%20Maffulli,AI%20system">covered</a>
one of the sessions, held at <a href="https://archive.fosdem.org/2024/">FOSDEM 2024</a>, in
February.</p>

<p>The current draft of the OSAID takes its definition of an AI system from the <a href="https://www.oecd.org/">Organisation for Economic Co-operation
and Development</a> (OECD) <a href="https://legalinstruments.oecd.org/en/instruments/OECD-LEGAL-0449">Recommendation
of the Council on Artificial Intelligence</a>:</p>

<blockquote>
A machine-based system that, for explicit or implicit objectives,
infers, from the input it receives, how to generate outputs such as
predictions, content, recommendations, or decisions that can influence
physical or virtual environments.
</blockquote>

<p>This includes source code for training and running the system,
model parameters &#34;<q>such as weights or other configuration
settings</q>&#34;, as well as &#34;<q>sufficiently detailed information about
the data used to train the system so that a skilled person can build a
substantially equivalent system</q>&#34;.</p>

<h4>Preferred form to make modifications</h4>

<p>Those elements must all be available under OSI-approved licenses,
according to the proposed definition, which seems perfectly in line
with what we&#39;ve come to expect when something is called &#34;open
source&#34;. There is an exception, though, for things like the data
information and model parameters which must be available under
&#34;<q>OSI-approved terms</q>&#34;. The definition of OSI-approved terms is
not supplied yet.</p>

<p>There is no requirement to make the <em>training data</em> available. To be
compliant with the current draft of the OSAID, an AI system need only
provide &#34;<q>detailed information</q>&#34; about the data but not the data
itself.</p>

<p>The OSI <a href="https://opensource.org/blog/community-input-drives-the-new-draft-of-the-open-source-ai-definition">published</a>
version 0.0.9 on August 22. It acknowledged then that &#34;<q>training data is
one of the most hotly debated parts of the definition</q>&#34;. However,
the OSI was choosing not to require training data:</p>

<blockquote>
<p>After long deliberation and co-design sessions we have concluded
that defining training data as a benefit, not a requirement, is the
best way to go.</p>

<p>Training data is valuable to study AI systems: to understand the
biases that have been learned, which can impact system behavior. But
training data is not part of the preferred form for making
modifications to an existing AI system. The insights and
correlations in that data have already been learned.</p>
</blockquote>

<p>As it stands, some feel that the OSAID falls short of allowing the
four freedoms that it is supposed to ensure. For example, julia
ferraioli <a href="https://www.juliaferraioli.com/blog/2024/on-open-source-ai/">wrote</a>
that without including data, the only things that the OSAID guarantees
are the ability to use and distribute an AI system. &#34;<q>They would be
able to build on top of it, through methods such as transfer learning
and fine-tuning, but that&#39;s it.</q>&#34;

</p><p>Tom Callaway has <a href="https://www.linkedin.com/pulse/why-open-data-necessary-source-ai-tom-callaway-stzcc/">written</a>
at length on LinkedIn about why open data should be a requirement. He 
acknowledges that there are good reasons that distributors of an AI
system may not want, or be able, to distribute training data. For
example, the data itself may have a high monetary value on its own,
and a vendor may be unwilling or unable to share it.
Acme Corp might license a data set and
have permission to create an AI system using it, but not the
ability to distribute the data itself. The data might have legal
issues, ranging from confidentiality (e.g., medical data sets) to a
desire to avoid lawsuits from using copyrighted data.</p>

<p>All of those are understandable reasons for not distributing
data with an AI system, he said, but they don&#39;t argue for crafting a definition
that allows companies to call their system open:</p>

<blockquote>
<p>If we let the Open Source AI definition contain a loophole that
makes data optional, we devalue the meaning of &#34;open source&#34; in all
other contexts. While there are lots of companies who would like to
see open source mean less, I think it&#39;s critical that we not
compromise here, even if it means there are less Open Source AI
systems at first.</p>
</blockquote>

<p>Objections to lack of training data are more than an attachment to
the original meaning of open source. Giacomo Tesio <a href="https://discuss.opensource.org/t/list-of-unaddressed-issues-of-osaid-rc2/650">posted</a>
a list of issues he considered unaddressed in the RC2 version of
the OSAID, including a claim that there is inherent insecurity due to the
ability to <a href="https://arxiv.org/abs/2204.06974">plant
undetectable backdoors</a> in machine-learning models.</p>

<h4>Others weigh in</h4>

<p>The Free Software Foundation (FSF) <a href="https://www.fsf.org/news/fsf-is-working-on-freedom-in-machine-learning-applications">announced</a>
that it was working on &#34;<q>a statement of criteria for free machine
learning applications</q>&#34; to call something a free (or libre)
machine-learning application. The FSF says that it is close to a
definition, and is working on the exact text. However, it adds that
&#34;<q>we believe that we cannot say a ML application &#39;is free&#39; unless
all its training data and the related scripts for processing it
respect all users, following the four freedoms</q>&#34;.</p>

<p>However, the FSF makes a distinction between non-free and
unethical in this case:</p>

<blockquote>
It may be that some nonfree ML have valid moral reasons for not
releasing training data, such as personal medical data. In that case,
we would describe the application as a whole as nonfree. But using it
could be ethically excusable if it helps you do a specialized job that
is vital for society, such as diagnosing disease or injury.
</blockquote>

<p>The <a href="https://sfconservancy.org/">Software Freedom Conservancy</a>
has <a href="https://sfconservancy.org/news/2024/oct/25/aspirational-on-llm-generative-ai-programming/">announced</a>
an &#34;<q>aspirational statement</q>&#34; about LLM-backed generative AI for
programming called &#34;Machine-Learning-Assisted Programming that
Respects User Freedom&#34;. Unlike the OSAID, this target focuses solely
on computer-assisted programming, and was developed <a href="https://sfconservancy.org/blog/2022/feb/03/github-copilot-copyleft-gpl/">in
response</a> to <a href="https://en.wikipedia.org/wiki/GitHub_Copilot">GitHub
Copilot</a>. The announcement did not directly name the OSI or the OSAID effort, but
said &#34;<q>we have avoided any process that effectively auto-endorses
the problematic practices of companies whose proprietary products are
already widely deployed</q>&#34;. It describes an ideal LLM system built
only with FOSS, with all components available, and only for the creation of FOSS.</p>

<h4>Response to criticisms</h4>

<p>I emailed Maffulli about some of the criticisms of the current
OSAID draft, and asked why OSI appears to be &#34;lowering the bar&#34; when
the OSI has never budged on source availability and use
restrictions. He replied:</p>

<blockquote>
<p>I&#39;ll be blunt: you mention &#34;source redistribution&#34; in your question
and that&#39;s what leads people like [Callaway] into a mental trap
[...]</p>

<p>There are some groups believing that more components are required to
guarantee more transparency. Other groups instead believe that model
parameters and architecture are enough to modify AI. The Open Source
AI Definition, developed publicly with a wide variety of stakeholders
worldwide, with deep expertise on building AI (see the <a href="https://opensource.org/ai/endorsements">list of endorsers</a>),
found that while those approaches are legitimate, neither is
optimal. The OSAID grants users the rights (with licenses) and the
tools (with the list of required components) to meaningfully
collaborate and innovate on (and fork, if required) AI systems.  We
have not compromised on our principles: we learned many new things
from actual AI experts along the way.</p>
</blockquote>

<p>Maffulli objected to the idea that the OSAID was weaker or making
concessions, and said that the preferred form for modifying ML systems
was what is in the OSAID: &#34;<q>it&#39;s not me nor OSI board saying that,
it&#39;s in the list of endorsers and in [Carnegie Mellon University&#39;s] <a href="https://www.cmu.edu/engin/programs/about-ofai/cmu-osaid-statement.html">comment</a></q>&#34;. He
added that OSI had synthesized input from &#34;<q>AI builders, users, and
deployers, content creators, unions, ethicists, lawyers, software
developers from all over the world</q>&#34; to arrive at the definition. A
&#34;<q>simple translation</q>&#34; of the OSD, he said, would not work.</p>

<p>Stephen O&#39;Grady, founder of the RedMonk analyst firm, also makes
the case that the OSD does not easily translate to AI projects. But he
does not believe that the term open source &#34;<q>can or should be
extended into the AI world</q>&#34; as he <a href="https://redmonk.com/sogrady/2024/10/22/from-open-source-to-ai/">wrote</a>
in a blog post on October 22:</p>

<blockquote>
<p>At its heart, the current deliberation around an open source
definition for AI is an attempt to drag a term defined over two
decades ago to describe a narrowly defined asset into the present to
instead cover a brand new, far more complicated future set of
artifacts.</p>
</blockquote>

<p>O&#39;Grady makes the case that the OSI has set out on a pragmatic path
to define open-source AI, which requires nuance. Open source has
succeeded, in part, because the OSD removes nuance. Does a license
comply with the OSD or doesn&#39;t it? It&#39;s pretty easy to determine. Less
so with the OSAID. The pragmatic path, he said:

</p><blockquote>
Involves substantial compromise and, more problematically,
requires explanation to be understood. And as the old political adage
advises: &#34;If you&#39;re explaining, you&#39;re losing.&#34;
</blockquote>

<p>It would have been better, he said, if the OSI had not tried to
&#34;<q>bend and reshape a decades old definition</q>&#34; and instead had
tried to craft something from a clean slate. That seems unlikely now,
he said, after two years of trying to &#34;<q>thread the needle between
idealism and capitalism to arrive at an ideologically sound and yet
commercially acceptable</q>&#34; definition.</p>

<p>Indeed, it seems likely that the OSI board will move forward with
the current draft of the OSAID or something close to it. The
impact that will have is much less certain.</p>

</div></div>
  </body>
</html>
