<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.nature.com/articles/d41586-025-01019-w">Original</a>
    <h1>AI masters Minecraft: DeepMind program finds diamonds without being taught</h1>
    
    <div id="readability-page-1" class="page"><div data-test="access-teaser"> <figure><picture><source type="image/webp" srcset="//media.nature.com/lw767/magazine-assets/d41586-025-01019-w/d41586-025-01019-w_50824342.jpg?as=webp 767w, //media.nature.com/lw319/magazine-assets/d41586-025-01019-w/d41586-025-01019-w_50824342.jpg?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px"/><img alt="Box art illustration for the video game Minecraft with a blocky figure gesturing with a pickaxe." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-025-01019-w/d41586-025-01019-w_50824342.jpg"/><figcaption><p><span><i>Minecraft</i> is among the world’s most popular video games and has 100 million monthly active users.</span><span>Credit: Mojang Studios</span></p></figcaption></picture></figure><p>An artificial intelligence (AI) system has for the first time figured out how to collect diamonds in the hugely popular video game <i>Minecraft</i> — a difficult task requiring multiple steps — without being shown how to play. Its creators say the system, called Dreamer, is a step towards machines that can generalize knowledge learn in one domain to new situations, a <a href="https://www.nature.com/articles/d41586-024-03905-1" data-track="click" data-label="https://www.nature.com/articles/d41586-024-03905-1" data-track-category="body text link">major goal of AI</a>.</p><p>“Dreamer marks a significant step towards general AI systems,” says Danijar Hafner, a computer scientist at Google DeepMind in San Francisco, California. “It allows AI to understand its physical environment and also to self-improve over time, without a human having to tell it exactly what to do.” Hafner and his colleagues describe <a href="https://danijar.com/project/dreamerv3/" data-track="click" data-label="https://danijar.com/project/dreamerv3/" data-track-category="body text link">Dreamer</a> in a study in <i>Nature</i> published on 2 April<sup><a href="#ref-CR1" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">1</a></sup>.</p><p>In <i>Minecraft</i>, players explore a virtual 3D world containing a variety of terrains, including forests, mountains, deserts and swamps. Players use the world’s resources to create objects, such as chests, fences and swords — and collect items, among the most prized of which are diamonds.</p><p>Importantly, says Hafner, no two experiences are the same. “Every time you play <i>Minecraft</i>, it’s a new, randomly generated world,” he says. This makes it useful for challenging an AI system that researchers want to be able to generalize from one situation to the next. “You have to really understand what’s in front of you; you can’t just memorize a specific strategy,” he says.</p><figure><picture><source type="image/webp" srcset="//media.nature.com/lw767/magazine-assets/d41586-025-01019-w/d41586-025-01019-w_50824340.jpg?as=webp 767w, //media.nature.com/lw319/magazine-assets/d41586-025-01019-w/d41586-025-01019-w_50824340.jpg?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px"/><img alt="A composite image of a Minecraft diamond overlayed on a promotional artwork the landscape of a Minecraft game world.." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-025-01019-w/d41586-025-01019-w_50824340.jpg"/><figcaption><p><span>Diamonds are among <i>Minecraft</i>’s most prized rewards — but finding them takes a series of complex steps.</span><span>Credit: Mojang Studios</span></p></figcaption></picture></figure><p>Collecting a diamond is “a very hard task”, says computer scientist Jeff Clune at the University of British Columbia in Vancouver, Canada, who was part of a separate team that trained a program to <a href="https://openai.com/index/vpt/" data-track="click" data-label="https://openai.com/index/vpt/" data-track-category="body text link">find diamonds using videos of human play</a><sup><a href="#ref-CR2" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">2</a></sup>. “There is no question this represents a major step forward for the field.” </p><h2>Diamonds are forever</h2><p>AI <a href="https://www.nature.com/articles/d41586-019-03630-0" data-track="click" data-label="https://www.nature.com/articles/d41586-019-03630-0" data-track-category="body text link">researchers have focused on finding diamonds</a>, says Hafner, because it requires a series of complicated steps, including finding trees and breaking them down to gather wood, which players can use to build a crafting table. </p><article data-label="Related"><a href="https://www.nature.com/articles/d41586-019-03630-0" data-track="click" data-track-label="recommended article"><img alt="" src="https://media.nature.com/w400/magazine-assets/d41586-025-01019-w/d41586-025-01019-w_50824040.png"/><p>AI takes on popular Minecraft game in machine-learning contest</p></a></article><p>This, together with more wood, can be used to make a wooden pickaxe — and so on, until players have assembled the correct tools to collect a diamond, which is buried deep underground. “There’s a long chain of these milestones, and so, it requires very deep exploration,” he says. </p><p>Previous attempts to get AI systems to collect diamonds relied on using videos of human play<sup><a href="#ref-CR2" data-track="click" data-action="anchor-link" data-track-label="go to reference" data-track-category="references">2</a></sup> or researchers leading systems through the steps. </p><p>By contrast, Dreamer explores everything about the game on its own, using a trial-and-error technique called reinforcement learning — it identifies actions that are likely to beget rewards, repeats them and discards others. Reinforcement learning underpins some <a href="https://www.nature.com/articles/nature.2017.22858" data-track="click" data-label="https://www.nature.com/articles/nature.2017.22858" data-track-category="body text link">major advances in AI</a>. But previous programs were specialists — they could not apply knowledge in new domains from scratch.</p><figure><picture><source type="image/webp" srcset="//media.nature.com/lw767/magazine-assets/d41586-025-01019-w/d41586-025-01019-w_50824366.gif?as=webp 767w, //media.nature.com/lw319/magazine-assets/d41586-025-01019-w/d41586-025-01019-w_50824366.gif?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px"/><img alt="Animated sequence from footage of the DreamerV3 algorithm attempting to collect a diamond in Minecraft." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-025-01019-w/d41586-025-01019-w_50824366.gif"/><figcaption><p><span>DeepMind’s Dreamer AI played repeated runs in <i>Minecraft</i> to learn how to collect diamonds.</span><span>Courtesy of Danijar Hafner</span></p></figcaption></picture></figure><h2>Build me a world model</h2><p>Key to Dreamer’s success, says Hafner, is that it builds a model of its surroundings and uses this ‘world model’ to ‘imagine’ future scenarios and guide decision-making. Rather like our own abstract thoughts, the world model is not an exact replica of its surroundings. But it allows the Dreamer agent to try things out and predict the potential rewards of different actions using less computation than would be needed to complete those actions in <i>Minecraft</i>. “The world model really equips the AI system with the ability to imagine the future,” says Hafner.</p><p>This ability could also help to create robots that can learn to interact in the real world — where the costs of trial and error are much higher than in a video game, says Hafner.</p><p>Testing Dreamer on the diamond challenge was an afterthought. “We built this whole algorithm without that in mind,” says Hafner. But it occurred to the team that it was the ideal way to test whether its algorithm could work, out of the box, on an unfamiliar task.</p><figure><picture><source type="image/webp" srcset="//media.nature.com/lw767/magazine-assets/d41586-025-01019-w/d41586-025-01019-w_50824338.jpg?as=webp 767w, //media.nature.com/lw319/magazine-assets/d41586-025-01019-w/d41586-025-01019-w_50824338.jpg?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px"/><img alt="A screenshot from the video game Minecraft of a house with a waterwheel alongside a blocky pig and chicken." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-025-01019-w/d41586-025-01019-w_50824338.jpg"/><figcaption><p><span>The Minecraft virtual world consists of multiple different terrains, from swamps and deserts to farms and villages.</span><span>Credit: Mojang Studios</span></p></figcaption></picture></figure></div></div>
  </body>
</html>
