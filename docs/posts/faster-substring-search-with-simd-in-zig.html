<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://aarol.dev/posts/zig-simd-substr/">Original</a>
    <h1>Faster substring search with SIMD in Zig</h1>
    
    <div id="readability-page-1" class="page"><div><p><span>Published 10.08.2025</span></p><p>I’ve been learning a lot about low-level programming languages lately, and for a long time there has been one thing that has interested me: SIMD (or ‘single instruction, multiple data’) code. I’ve seen a lot of articles about having massive performance gains by utilizing SIMD and wanted to learn how to do it myself.</p><p>This article is a journey into implementing ~60% faster substring searching compared to Zig’s <code>std.mem.indexOf</code> using a SIMD-friendly algorithm.</p><h2 id="baseline">Baseline
<a href="#baseline">#</a></h2><p>This is the baseline function that we will be comparing against:</p><div><pre tabindex="0"><code data-lang="zig"><span><span><span>fn</span><span> </span><span>find_substr</span><span>(</span><span>needle</span><span>:</span><span> </span><span>[]</span><span>const</span><span> </span><span>u8</span><span>,</span><span> </span><span>haystack</span><span>:</span><span> </span><span>[]</span><span>const</span><span> </span><span>u8</span><span>)</span><span> </span><span>?</span><span>usize</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>return</span><span> </span><span>std</span><span>.</span><span>mem</span><span>.</span><span>indexOf</span><span>(</span><span>u8</span><span>,</span><span> </span><span>haystack</span><span>,</span><span> </span><span>needle</span><span>);</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span></code></pre></div><p>It’s the closest thing to a substring search function from Zig’s standard library. It returns the first index of a subsequence – or <code>null</code> if not found.</p><h2 id="simd-algorithm">SIMD algorithm
<a href="#simd-algorithm">#</a></h2><p>This algorithm is taken directly from Wojciech Muła’s fantastic article <a href="http://0x80.pl/notesen/2016-11-28-simd-strfind.html#algorithm-1-generic-simd">SIMD-friendly algorithms for substring searching</a>, which seems to have the best algorithms for finding substrings in a large body of text.</p><p>Here’s how the algorithm works: say that we want to find the index of the word “blue” (the <code>needle</code>) in “It was a beautiful, bounteous, blue day” (the <code>haystack</code>). First, we extract the first and last character of the <code>needle</code> (‘b’ and ’e’) and store them in a variable.</p><p>Then we will loop through all of the characters in <code>haystack</code>, loading the next 32 characters (bytes) from memory into a SIMD register and comparing each character (byte) in the register with ‘b’. This will result in a mask containing 32 bytes, <code>1</code> if the character is ‘b’ and <code>0</code> in all other cases.</p><p>We will do the same with the last character, but load the characters with an offset (<code>needle.len - 1</code>).</p><blockquote><p>Without the offset, any match that starts in one 32‑byte chunk and ends in the next would be missed. With this method, we can also check for <code>needles</code> that are longer than 32 characters.</p></blockquote><p>The result will be two bit masks, <code>First</code> and <code>Last</code>, where we can use bit-wise AND (<code>Result = First &amp; Last</code>) to figure out potential substring occurrences.</p><p><code>Result</code> will be <code>1</code> only when there is a ‘b’ at index <code>i</code> followed by an ’e’ at index <code>i+3</code>. We still need to check if those positions actually contain the value “blue”, but this still dramatically reduces the number of checks (= individual memory accesses) that are necessary. We’ll see how this works in practice in the next section.</p><h2 id="implementation-in-zig">Implementation in Zig
<a href="#implementation-in-zig">#</a></h2><p>First, to properly use SIMD, let’s assume that the CPU supports AVX2 (Advanced Vector Extensions 2) and has 256-bit wide registers.</p><blockquote><p>All desktop processors less than 10 years old support AVX2, with newer ones also supporting AVX-512 with 512-bit wide registers.</p></blockquote><p>This allows us to use Zig’s <a href="https://ziglang.org/documentation/0.14.1/#Vectors">@Vector</a> function to make a type:</p><div><pre tabindex="0"><code data-lang="zig"><span><span><span>const</span><span> </span><span>Block</span><span> </span><span>=</span><span> </span><span>@Vector</span><span>(</span><span>32</span><span>,</span><span> </span><span>u8</span><span>);</span><span> </span><span>// number of elements, element type (32*8=256)
</span></span></span></code></pre></div><p>By using <code>Block</code>, we are telling the compiler that the operations on this datatype should use SIMD instructions where possible.</p><p>Next, we take the first and last letters of the search word (’needle’) and load them into two SIMD registers, so that every byte of the register is filled with the character. This is handled by another built-in function, <code>@splat</code>:</p><div><pre tabindex="0"><code data-lang="zig"><span><span><span>const</span><span> </span><span>first_letter</span><span>:</span><span> </span><span>Block</span><span> </span><span>=</span><span> </span><span>@splat</span><span>(</span><span>needle</span><span>[</span><span>0</span><span>]);</span><span>
</span></span></span><span><span><span></span><span>const</span><span> </span><span>last_letter</span><span>:</span><span> </span><span>Block</span><span> </span><span>=</span><span> </span><span>@splat</span><span>(</span><span>needle</span><span>[</span><span>needle</span><span>.</span><span>len</span><span> </span><span>-</span><span> </span><span>1</span><span>]);</span><span>
</span></span></span></code></pre></div><p>In the main loop, we check that there is enough characters left in <code>haystack</code> so that we can read the next <code>32 + needle.len</code> characters. Inside the block, we load the blocks that we’re going to compare <code>first_letter</code> and <code>last_letter</code> with.</p><div><pre tabindex="0"><code data-lang="zig"><span><span><span>const</span><span> </span><span>n</span><span> </span><span>=</span><span> </span><span>haystack</span><span>.</span><span>len</span><span>;</span><span>
</span></span></span><span><span><span></span><span>const</span><span> </span><span>k</span><span> </span><span>=</span><span> </span><span>needle</span><span>.</span><span>len</span><span>;</span><span>
</span></span></span><span><span><span></span><span>var</span><span> </span><span>i</span><span>:</span><span> </span><span>usize</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span><span>
</span></span></span><span><span><span></span><span>while</span><span> </span><span>(</span><span>i</span><span> </span><span>+</span><span> </span><span>k</span><span> </span><span>+</span><span> </span><span>32</span><span> </span><span>&lt;=</span><span> </span><span>n</span><span>)</span><span> </span><span>:</span><span> </span><span>(</span><span>i</span><span> </span><span>+=</span><span> </span><span>32</span><span>)</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>const</span><span> </span><span>first_block</span><span>:</span><span> </span><span>Block</span><span> </span><span>=</span><span> </span><span>haystack</span><span>[</span><span>i</span><span>..][</span><span>0</span><span>..</span><span>32</span><span>].</span><span>*</span><span>;</span><span>
</span></span></span><span><span><span>    </span><span>const</span><span> </span><span>last_block</span><span>:</span><span> </span><span>Block</span><span> </span><span>=</span><span> </span><span>haystack</span><span>[</span><span>i</span><span> </span><span>+</span><span> </span><span>k</span><span> </span><span>-</span><span> </span><span>1</span><span> </span><span>..][</span><span>0</span><span>..</span><span>32</span><span>].</span><span>*</span><span>;</span><span>
</span></span></span></code></pre></div><p>Now we can make the comparisons and combine them into a mask:</p><div><pre tabindex="0"><code data-lang="zig"><span><span><span>	</span><span>// ...
</span></span></span><span><span><span></span><span>    </span><span>const</span><span> </span><span>eq_first</span><span> </span><span>=</span><span> </span><span>first_letter</span><span> </span><span>==</span><span> </span><span>first_block</span><span>;</span><span>
</span></span></span><span><span><span>    </span><span>const</span><span> </span><span>eq_last</span><span> </span><span>=</span><span> </span><span>last_letter</span><span> </span><span>==</span><span> </span><span>last_block</span><span>;</span><span>
</span></span></span><span><span><span>    </span><span>var</span><span> </span><span>mask</span><span>:</span><span> </span><span>std</span><span>.</span><span>bit_set</span><span>.</span><span>IntegerBitSet</span><span>(</span><span>32</span><span>)</span><span> </span><span>=</span><span> </span><span>.{</span><span> </span><span>.</span><span>mask</span><span> </span><span>=</span><span> </span><span>@bitCast</span><span>(</span><span>eq_first</span><span> </span><span>&amp;</span><span> </span><span>eq_last</span><span>)</span><span> </span><span>};</span><span>
</span></span></span></code></pre></div><p>Here we can use an <code>IntegerBitSet</code> from Zig’s standard library. We construct it by casting the result of <code>eq_first &amp; eq_last</code> into a 32-bit integer. If the resulting mask is non-zero, there are candidates in the current block.</p><div><pre tabindex="0"><code data-lang="zig"><span><span><span>	</span><span>// ...
</span></span></span><span><span><span></span><span>    </span><span>while</span><span> </span><span>(</span><span>mask</span><span>.</span><span>findFirstSet</span><span>())</span><span> </span><span>|</span><span>bitpos</span><span>|</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>        </span><span>if</span><span> </span><span>(</span><span>std</span><span>.</span><span>mem</span><span>.</span><span>eql</span><span>(</span><span>u8</span><span>,</span><span> </span><span>haystack</span><span>[</span><span>i</span><span> </span><span>+</span><span> </span><span>bitpos</span><span> </span><span>+</span><span> </span><span>1</span><span> </span><span>..][</span><span>0</span><span> </span><span>..</span><span> </span><span>k</span><span> </span><span>-</span><span> </span><span>1</span><span>],</span><span> </span><span>needle</span><span>[</span><span>1</span><span>..]))</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>            </span><span>return</span><span> </span><span>i</span><span> </span><span>+</span><span> </span><span>bitpos</span><span>;</span><span>
</span></span></span><span><span><span>        </span><span>}</span><span>
</span></span></span><span><span><span>        </span><span>_</span><span> </span><span>=</span><span> </span><span>mask</span><span>.</span><span>toggleFirstSet</span><span>();</span><span>
</span></span></span><span><span><span>    </span><span>}</span><span>
</span></span></span></code></pre></div><p>The first and last characters of the substring are checked already, so we don’t need to check their equality again.</p><p>Finally, if there are leftover characters, we can fall back to <code>std.mem.IndexOf</code>.</p><div><pre tabindex="0"><code data-lang="zig"><span><span><span>	</span><span>// ...
</span></span></span><span><span><span></span><span>	</span><span>// Fallback to scalar search for the tail
</span></span></span><span><span><span></span><span>	</span><span>if</span><span> </span><span>(</span><span>i</span><span> </span><span>&lt;</span><span> </span><span>n</span><span>)</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>	    </span><span>if</span><span> </span><span>(</span><span>std</span><span>.</span><span>mem</span><span>.</span><span>indexOf</span><span>(</span><span>u8</span><span>,</span><span> </span><span>haystack</span><span>[</span><span>i</span><span>..],</span><span> </span><span>needle</span><span>))</span><span> </span><span>|</span><span>rel_idx</span><span>|</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>	        </span><span>return</span><span> </span><span>i</span><span> </span><span>+</span><span> </span><span>rel_idx</span><span>;</span><span>
</span></span></span><span><span><span>	    </span><span>}</span><span>
</span></span></span><span><span><span>	</span><span>}</span><span>
</span></span></span><span><span><span>	</span><span>return</span><span> </span><span>null</span><span>;</span><span> </span><span>// no substring found
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span></code></pre></div><h3 id="benchmarks">Benchmarks
<a href="#benchmarks">#</a></h3><p>To properly show the effects of our SIMD algorithm, we’re going to need a large haystack. For this, I’ve chosen to use <a href="https://www.gutenberg.org/ebooks/2701">the entirety Moby Dick</a> in plain text, and a search word ’newsletter’, which appears at the very end of the text.</p><blockquote><p>The code is available <a href="https://github.com/aarol/substr">on GitHub</a></p></blockquote><p>To compile the code, I ran <code>zig build</code> with <code>-Doptimize=ReleaseFast</code>:</p><div><pre tabindex="0"><code data-lang="sh"><span><span>&gt; zig build -Doptimize<span>=</span>ReleaseFast
</span></span></code></pre></div><blockquote><p>Support for <a href="https://github.com/ziglang/zig/pull/24131">bitwise operations on boolean vectors</a> was added in Zig 0.15, which is unreleased as of now (August 2025). If you want to run the code on your system, you need to build Zig from the master branch.</p></blockquote><p>To measure performance and compare against baseline, I’ll use one of my favorite CLI tools, <a href="https://github.com/andrewrk/poop">poop</a>:</p><div><pre tabindex="0"><code data-lang="sh"><span><span>&gt; poop -d <span>10000</span> <span>&#34;./zig-out/bin/substr&#34;</span> <span>&#34;./zig-out/bin/substr --simd&#34;</span>
</span></span></code></pre></div><pre>

<span>Benchmark 1 (6361 runs)</span>: ./zig-out/bin/substr
<span>  measurement          </span><span>mean</span><span> ± </span><span>σ</span><span>            </span><span>min</span><span> … </span><span>max</span><span>           </span><span>outliers</span><span>         delta</span>
  wall_time          <span>1.22</span><span>ms</span> ± <span> 185</span><span>us</span>    <span> 903</span><span>us</span> … <span>5.33</span><span>ms</span>        242 ( 4%)        0%
  peak_rss           <span>1.20</span><span>MB</span> ± <span> 290</span><span>  </span>    <span>1.18</span><span>MB</span> … <span>1.20</span><span>MB</span>          2 ( 0%)        0%
  cpu_cycles         <span>2.15</span><span>M </span> ± <span>40.5</span><span>K </span>    <span>2.10</span><span>M </span> … <span>2.71</span><span>M </span>        312 ( 5%)        0%
  instructions       <span>1.85</span><span>M </span> ± <span>0.75</span><span>  </span>    <span>1.85</span><span>M </span> … <span>1.85</span><span>M </span>         56 ( 1%)        0%
  cache_references   <span>43.8</span><span>K </span> ± <span> 620</span><span>  </span>    <span>38.3</span><span>K </span> … <span>44.9</span><span>K </span>          9 ( 0%)        0%
  cache_misses       <span>19.0</span><span>K </span> ± <span>10.3</span><span>K </span>    <span>4.08</span><span>K </span> … <span>33.6</span><span>K </span>          0 ( 0%)        0%
  branch_misses      <span>48.1</span><span>  </span> ± <span>17.4</span><span>  </span>    <span>  20</span><span>  </span> … <span> 104</span><span>  </span>         97 ( 2%)        0%

<span>Benchmark 2 (10000 runs)</span>: ./zig-out/bin/substr --simd
<span>  measurement          </span><span>mean</span><span> ± </span><span>σ</span><span>            </span><span>min</span><span> … </span><span>max</span><span>           </span><span>outliers</span><span>         delta</span>
  wall_time          <span> 500</span><span>us</span> ± <span>96.9</span><span>us</span>    <span> 397</span><span>us</span> … <span>4.23</span><span>ms</span>        840 ( 8%)        <span>⚡</span><span>- 58.9% ±  0.4%</span>
  peak_rss           <span>1.20</span><span>MB</span> ± <span> 164</span><span>  </span>    <span>1.18</span><span>MB</span> … <span>1.20</span><span>MB</span>          1 ( 0%)          +  0.0% ±  0.0%
  cpu_cycles         <span> 369</span><span>K </span> ± <span>36.1</span><span>K </span>    <span> 340</span><span>K </span> … <span>1.10</span><span>M </span>       <span>1167 (12%)</span>        <span>⚡</span><span>- 82.8% ±  0.1%</span>
  instructions       <span> 578</span><span>K </span> ± <span>0.53</span><span>  </span>    <span> 578</span><span>K </span> … <span> 578</span><span>K </span>          6 ( 0%)        <span>⚡</span><span>- 68.8% ±  0.0%</span>
  cache_references   <span>38.8</span><span>K </span> ± <span> 545</span><span>  </span>    <span>34.1</span><span>K </span> … <span>40.5</span><span>K </span>          6 ( 0%)        <span>⚡</span><span>- 11.4% ±  0.0%</span>
  cache_misses       <span>5.62</span><span>K </span> ± <span>4.97</span><span>K </span>    <span>2.11</span><span>K </span> … <span>27.9</span><span>K </span>       <span>1529 (15%)</span>        <span>⚡</span><span>- 70.3% ±  1.2%</span>
  branch_misses      <span>2.88</span><span>K </span> ± <span>23.4</span><span>  </span>    <span>2.81</span><span>K </span> … <span>3.09</span><span>K </span>        453 ( 5%)        💩<span>+5879.8% ±  1.4%</span>
</pre><p>(Scroll right to see more data)</p><p>As you can see, for a large body of text, the speedup is noticeable: 59% faster with 80% less CPU cycles!</p><blockquote><p>The SIMD version only took 500 microseconds to complete on average, including the overhead of loading the program into memory and printing the result. 500 microseconds is half a millisecond. That’s how fast my laptop searches through a whole book, <strong>200 000 words</strong>, cover to cover. This is why computers are so powerful! How long would it take for a human to do that?</p></blockquote><p>This is quite a large improvement, and proves that the SIMD code is actually working (otherwise the reduction in CPU cycles wouldn’t be so massive). Can we do even better though?</p><h2 id="character-selection">Character selection
<a href="#character-selection">#</a></h2><p>You may notice from the output of <code>poop</code> that the number of branch misses has absolutely blown up – from 48 on average to 2.88k !</p><p>Why does this happen? Well, if you were to count how many times the inner while loop is entered when the mask is non-zero:</p><div><pre tabindex="0"><code data-lang="zig"><span><span><span>    </span><span>var</span><span> </span><span>i</span><span>:</span><span> </span><span>usize</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span><span>
</span></span></span><span><span><span>    </span><span>var</span><span> </span><span>count</span><span>:</span><span> </span><span>usize</span><span> </span><span>=</span><span> </span><span>0</span><span>;</span><span>
</span></span></span><span><span><span>    </span><span>while</span><span> </span><span>(</span><span>i</span><span> </span><span>+</span><span> </span><span>k</span><span> </span><span>+</span><span> </span><span>32</span><span> </span><span>&lt;=</span><span> </span><span>n</span><span>)</span><span> </span><span>:</span><span> </span><span>(</span><span>i</span><span> </span><span>+=</span><span> </span><span>32</span><span>)</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>        </span><span>const</span><span> </span><span>block_first</span><span>:</span><span> </span><span>Block</span><span> </span><span>=</span><span> </span><span>haystack</span><span>[</span><span>i</span><span>..][</span><span>0</span><span>..</span><span>32</span><span>].</span><span>*</span><span>;</span><span>
</span></span></span><span><span><span>        </span><span>const</span><span> </span><span>block_last</span><span>:</span><span> </span><span>Block</span><span> </span><span>=</span><span> </span><span>haystack</span><span>[</span><span>i</span><span> </span><span>+</span><span> </span><span>k</span><span> </span><span>-</span><span> </span><span>1</span><span> </span><span>..][</span><span>0</span><span>..</span><span>32</span><span>].</span><span>*</span><span>;</span><span>
</span></span></span><span><span><span>        </span><span>const</span><span> </span><span>eq_first</span><span> </span><span>=</span><span> </span><span>first</span><span> </span><span>==</span><span> </span><span>block_first</span><span>;</span><span>
</span></span></span><span><span><span>        </span><span>const</span><span> </span><span>eq_last</span><span> </span><span>=</span><span> </span><span>last</span><span> </span><span>==</span><span> </span><span>block_last</span><span>;</span><span>
</span></span></span><span><span><span>        </span><span>var</span><span> </span><span>mask</span><span>:</span><span> </span><span>std</span><span>.</span><span>bit_set</span><span>.</span><span>IntegerBitSet</span><span>(</span><span>32</span><span>)</span><span> </span><span>=</span><span> </span><span>.{</span><span> </span><span>.</span><span>mask</span><span> </span><span>=</span><span> </span><span>@bitCast</span><span>(</span><span>eq_first</span><span> </span><span>&amp;</span><span> </span><span>eq_last</span><span>)</span><span> </span><span>};</span><span>
</span></span></span><span><span><span>        </span><span>while</span><span> </span><span>(</span><span>mask</span><span>.</span><span>findFirstSet</span><span>())</span><span> </span><span>|</span><span>bitpos</span><span>|</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>            </span><span>count</span><span> </span><span>+=</span><span> </span><span>1</span><span>;</span><span>
</span></span></span><span><span><span>            </span><span>if</span><span> </span><span>(</span><span>std</span><span>.</span><span>mem</span><span>.</span><span>eql</span><span>(</span><span>u8</span><span>,</span><span> </span><span>haystack</span><span>[</span><span>i</span><span> </span><span>+</span><span> </span><span>bitpos</span><span> </span><span>+</span><span> </span><span>1</span><span> </span><span>..][</span><span>0</span><span> </span><span>..</span><span> </span><span>k</span><span> </span><span>-</span><span> </span><span>1</span><span>],</span><span> </span><span>needle</span><span>[</span><span>1</span><span>..]))</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>                </span><span>std</span><span>.</span><span>debug</span><span>.</span><span>print</span><span>(</span><span>&#34;found match with count: {}</span><span>\n</span><span>&#34;</span><span>,</span><span> </span><span>.{</span><span>count</span><span>});</span><span>
</span></span></span><span><span><span>                </span><span>return</span><span> </span><span>i</span><span> </span><span>+</span><span> </span><span>bitpos</span><span>;</span><span>
</span></span></span><span><span><span>            </span><span>}</span><span>
</span></span></span><span><span><span>            </span><span>_</span><span> </span><span>=</span><span> </span><span>mask</span><span>.</span><span>toggleFirstSet</span><span>();</span><span>
</span></span></span><span><span><span>        </span><span>}</span><span>
</span></span></span><span><span><span>    </span><span>}</span><span>
</span></span></span></code></pre></div><div><pre tabindex="0"><code data-lang="fallback"><span><span>found match with count: 2792
</span></span></code></pre></div><p>The fact that <code>count</code> is so close to the number of mispredictions suggests that each time the mask is non‑zero we incur a branch miss.</p><p>Unfortunately, there is no obvious way to prevent this with the current algorithm. The state-of-the-art seems to be choosing two bytes in the needle that occur less frequently according to a pre-calculated frequency distribution. This is used in the <a href="https://github.com/BurntSushi/memchr"><code>memchr</code> crate</a> in Rust, as explained by the author in <a href="https://news.ycombinator.com/item?id=44275934">this comment on Hacker News</a>.</p><p>For example, the needle <code>newsletter</code> has the rarest characters <code>w</code> at index <code>2</code> and <code>l</code> at index <code>4</code>.</p><p>The function in <code>memchr</code> can be found <a href="https://github.com/BurntSushi/memchr/blob/3962118774ac511580c5b40fd14323e31629fa52/src/arch/all/packedpair/mod.rs#L163">here</a>. I’ve ported it into Zig, and you can see it <a href="https://github.com/aarol/substr/blob/9392f9557de735929dfb79efa4fc88115341c65d/src/main.zig#L100">here</a>.</p><div><pre tabindex="0"><code data-lang="zig"><span><span><span>    </span><span>const</span><span> </span><span>needle_index_pair</span><span> </span><span>=</span><span> </span><span>find_rarest</span><span>(</span><span>needle</span><span>);</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>const</span><span> </span><span>first_letter</span><span>:</span><span> </span><span>Block</span><span> </span><span>=</span><span> </span><span>@splat</span><span>(</span><span>needle</span><span>[</span><span>needle_index_pair</span><span>[</span><span>0</span><span>]]);</span><span>
</span></span></span><span><span><span>    </span><span>const</span><span> </span><span>first_offset</span><span> </span><span>=</span><span> </span><span>needle_index_pair</span><span>[</span><span>0</span><span>];</span><span>
</span></span></span><span><span><span>    </span><span>const</span><span> </span><span>second_letter</span><span>:</span><span> </span><span>Block</span><span> </span><span>=</span><span> </span><span>@splat</span><span>(</span><span>needle</span><span>[</span><span>needle_index_pair</span><span>[</span><span>1</span><span>]]);</span><span>
</span></span></span><span><span><span>    </span><span>const</span><span> </span><span>second_offset</span><span> </span><span>=</span><span> </span><span>needle_index_pair</span><span>[</span><span>1</span><span>];</span><span>
</span></span></span></code></pre></div><p>The algorithm is the exact same, but the index for <code>first_letter</code> and <code>second_letter</code> now varies according to the pre-calculated frequency distribution.</p><h3 id="benchmarks">Benchmarks
<a href="#benchmarks">#</a></h3><pre>

<span>Benchmark 1 (10000 runs)</span>: ./zig-out/bin/substr --simd
<span>  measurement          </span><span>mean</span><span> ± </span><span>σ</span><span>            </span><span>min</span><span> … </span><span>max</span><span>           </span><span>outliers</span><span>         delta</span>
  wall_time          <span> 472</span><span>us</span> ± <span>62.9</span><span>us</span>    <span> 400</span><span>us</span> … <span>1.62</span><span>ms</span>        735 ( 7%)        0%
  peak_rss           <span>1.20</span><span>MB</span> ± <span>   0</span><span>  </span>    <span>1.20</span><span>MB</span> … <span>1.20</span><span>MB</span>          0 ( 0%)        0%
  cpu_cycles         <span> 376</span><span>K </span> ± <span>44.7</span><span>K </span>    <span> 347</span><span>K </span> … <span>1.46</span><span>M </span>       <span>1213 (12%)</span>        0%
  instructions       <span> 578</span><span>K </span> ± <span>0.54</span><span>  </span>    <span> 578</span><span>K </span> … <span> 578</span><span>K </span>         10 ( 0%)        0%
  cache_references   <span>38.7</span><span>K </span> ± <span> 715</span><span>  </span>    <span>28.3</span><span>K </span> … <span>40.6</span><span>K </span>         96 ( 1%)        0%
  cache_misses       <span>7.37</span><span>K </span> ± <span>5.83</span><span>K </span>    <span>2.78</span><span>K </span> … <span>27.7</span><span>K </span>       <span>1608 (16%)</span>        0%
  branch_misses      <span>2.88</span><span>K </span> ± <span>23.4</span><span>  </span>    <span>2.82</span><span>K </span> … <span>3.08</span><span>K </span>        415 ( 4%)        0%

<span>Benchmark 2 (10000 runs)</span>: ./zig-out/bin/substr --simdv2
<span>  measurement          </span><span>mean</span><span> ± </span><span>σ</span><span>            </span><span>min</span><span> … </span><span>max</span><span>           </span><span>outliers</span><span>         delta</span>
  wall_time          <span> 429</span><span>us</span> ± <span>75.5</span><span>us</span>    <span> 369</span><span>us</span> … <span>3.85</span><span>ms</span>        393 ( 4%)        <span>⚡</span><span>-  9.1% ±  0.4%</span>
  peak_rss           <span>1.20</span><span>MB</span> ± <span>   0</span><span>  </span>    <span>1.20</span><span>MB</span> … <span>1.20</span><span>MB</span>          0 ( 0%)          -  0.0% ±  0.0%
  cpu_cycles         <span> 304</span><span>K </span> ± <span>28.4</span><span>K </span>    <span> 282</span><span>K </span> … <span>1.07</span><span>M </span>       <span>1140 (11%)</span>        <span>⚡</span><span>- 19.2% ±  0.3%</span>
  instructions       <span> 561</span><span>K </span> ± <span>0.52</span><span>  </span>    <span> 561</span><span>K </span> … <span> 561</span><span>K </span>          5 ( 0%)        <span>⚡</span><span>-  2.9% ±  0.0%</span>
  cache_references   <span>38.7</span><span>K </span> ± <span> 610</span><span>  </span>    <span>29.9</span><span>K </span> … <span>40.3</span><span>K </span>         25 ( 0%)          -  0.1% ±  0.0%
  cache_misses       <span>5.21</span><span>K </span> ± <span>3.53</span><span>K </span>    <span>2.57</span><span>K </span> … <span>27.3</span><span>K </span>       <span>1306 (13%)</span>        <span>⚡</span><span>- 29.3% ±  1.8%</span>
  branch_misses      <span>1.07</span><span>K </span> ± <span>14.0</span><span>  </span>    <span>1.02</span><span>K </span> … <span>1.17</span><span>K </span>        275 ( 3%)        <span>⚡</span><span>- 62.8% ±  0.0%</span>

</pre><p>Comparing to the previous SIMD version, the number of branch misses has dropped by 60%, and it’s 9% faster too. Nice!</p><blockquote><p>The number of branch misses is lower, which can cause faster execution, but I suspect that a much bigger impact is the fact that there are less false positives, which means less byte-by-byte memory accesses and comparisons.</p></blockquote><h2 id="avx-512">AVX-512
<a href="#avx-512">#</a></h2><p>Since AMD <a href="https://en.wikipedia.org/wiki/Zen_4">Zen 4 </a>and Intel <a href="https://en.wikipedia.org/wiki/Cannon_Lake_%28microprocessor%29">Cannon Lake</a>, there has been a new SIMD instruction set, AVX-512 with 512-bit instructions – double the size of AVX2. I don’t have a computer that has AVX-512 right now, but I suspect that changing the Zig code to process 64 characters at once would lead to even better results.</p><h2 id="a-smaller-haystack">A smaller haystack
<a href="#a-smaller-haystack">#</a></h2><p>It’s clear that with a very large haystack, the SIMD version is much faster. But what about a tiny input, like less than a hunder characters?</p><p>I did a bit of benchmarking with <code>poop</code>, but I found that I couldn’t accurately measure the speed, since both versions finish extremely very quickly. I decided to use <a href="https://github.com/hendriknielaender/zBench">zBench</a> to do a microbenchmark. I decided to use a snippet from Moby Dick as seen <a href="https://github.com/aarol/substr/blob/main/src/haystack-small.txt">here</a>.</p><pre>+- run test stderr
benchmark              runs     total time     time/run (avg ± σ)    (min ... max)                p75        p99        p995      
-----------------------------------------------------------------------------------------------------------------------------
find_substr            <span>100000   424.368ms      </span><span>4.243us ± 740ns       </span><span>(3.964us ... 107.923us)      </span><span>4.187us    7.075us    7.245us   </span>
find_substr_simd_v2    <span>100000   147.883ms      </span><span>1.478us ± 186ns       </span><span>(1.417us ... 21.354us)       </span><span>1.483us    1.539us    1.548us   </span>
</pre><p>I was surprised to see that even when processing less than a hundred characters, the SIMD algorithm is still faster! The difference between 4μs vs 1μs is extremely small, but it’s slightly faster nonetheless.</p><h2 id="conclusion">Conclusion
<a href="#conclusion">#</a></h2><p>As you can see, SIMD can be used to make substring searching dramatically faster, for both very large and very small strings.</p><p>But if it’s so much better, then why haven’t I made a pull request to change <code>std.mem.indexOf</code> to use SIMD? Well, the reason is that</p><ol><li><code>std.mem.indexOf</code> is generic over element size, and having a size larger than <code>u8</code> makes the algorithm much slower</li><li>The <a href="https://en.wikipedia.org/wiki/Boyer%E2%80%93Moore%E2%80%93Horspool_algorithm">algorithm</a> used in <code>stdmem.indexOf</code> is cross-platform, while the SIMD code wouldn’t be. (not all platforms have SIMD registers at all, Arm has only 128-bit)</li></ol><p>Substring searching is rarely the bottleneck in programs, especially ones written in a fast language like Zig. That’s why I don’t personally think it would be worth it to add it to the standard library.</p><p>Still, it was great to learn about this advanced optimization technique and see some concrete performance measurements from it!</p><p>The full code is available on GitHub <a href="https://github.com/aarol/substr/">here</a>.</p><h2 id="further-reading">Further reading
<a href="#further-reading">#</a></h2><ul><li>SIMD with Zig <a href="https://www.openmymind.net/SIMD-With-Zig/">https://www.openmymind.net/SIMD-With-Zig/</a></li><li>SIMD-friendly algorithms for substring searching: <a href="http://0x80.pl/notesen/2016-11-28-simd-strfind.html">http://0x80.pl/notesen/2016-11-28-simd-strfind.html</a></li><li><code>memchr</code> source code: <a href="https://github.com/BurntSushi/memchr">https://github.com/BurntSushi/memchr</a></li></ul></div></div>
  </body>
</html>
