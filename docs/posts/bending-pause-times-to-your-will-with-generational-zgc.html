<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://netflixtechblog.com/bending-pause-times-to-your-will-with-generational-zgc-256629c9386b?gi=f77216038c95">Original</a>
    <h1>Bending pause times to your will with Generational ZGC</h1>
    
    <div id="readability-page-1" class="page"><section><div><div><div><div><div><div><div><div><div><div><div><a href="https://netflixtechblog.medium.com" rel="noopener follow"><div><div aria-hidden="false"><div><div><p><img alt="Netflix Technology Blog" src="https://miro.medium.com/v2/resize:fill:88:88/1*BJWRqfSMf9Da9vsXG9EBRQ.jpeg" width="44" height="44" loading="lazy" data-testid="authorPhoto"/></p></div></div></div></div></a><a href="https://netflixtechblog.com" rel="noopener  ugc nofollow"><div><div><div aria-hidden="false"><div><div><p><img alt="Netflix TechBlog" src="https://miro.medium.com/v2/resize:fill:48:48/1*ty4NvNrGg4ReETxqU2N3Og.png" width="24" height="24" loading="lazy" data-testid="publicationPhoto"/></p></div></div></div></div></div></a></div></div></div></div></div></div></div><p id="6306"><em>The surprising and not so surprising benefits of generations in the Z Garbage Collector.</em></p><p id="7593">By Danny Thomas, JVM Ecosystem Team</p><figure><div role="button" tabindex="0"><div><picture><source srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/0*GuEZ-RMhzNnYgLQd 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/0*GuEZ-RMhzNnYgLQd 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/0*GuEZ-RMhzNnYgLQd 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/0*GuEZ-RMhzNnYgLQd 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/0*GuEZ-RMhzNnYgLQd 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/0*GuEZ-RMhzNnYgLQd 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/0*GuEZ-RMhzNnYgLQd 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcset="https://miro.medium.com/v2/resize:fit:640/0*GuEZ-RMhzNnYgLQd 640w, https://miro.medium.com/v2/resize:fit:720/0*GuEZ-RMhzNnYgLQd 720w, https://miro.medium.com/v2/resize:fit:750/0*GuEZ-RMhzNnYgLQd 750w, https://miro.medium.com/v2/resize:fit:786/0*GuEZ-RMhzNnYgLQd 786w, https://miro.medium.com/v2/resize:fit:828/0*GuEZ-RMhzNnYgLQd 828w, https://miro.medium.com/v2/resize:fit:1100/0*GuEZ-RMhzNnYgLQd 1100w, https://miro.medium.com/v2/resize:fit:1400/0*GuEZ-RMhzNnYgLQd 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" width="700" height="394" loading="eager" role="presentation"/></picture></div></div></figure><p id="5d9e">The latest long term support release of the JDK delivers generational support for the <a href="https://docs.oracle.com/en/java/javase/21/gctuning/z-garbage-collector.html" rel="noopener ugc nofollow" target="_blank">Z Garbage Collector</a>. Netflix has switched by default from G1 to Generational ZGC on JDK 21 and later, because of the significant benefits of concurrent garbage collection.</p><p id="7021">More than half of our critical streaming video services are now running on JDK 21 with Generational ZGC, so it’s a good time to talk about our experience and the benefits we’ve seen. If you’re interested in how we use Java at Netflix, Paul Bakker’s talk <a href="https://www.infoq.com/presentations/netflix-java/" rel="noopener ugc nofollow" target="_blank">How Netflix Really Uses Java</a>, is a great place to start.</p><p id="1084">In both our GRPC and <a href="https://netflix.github.io/dgs/" rel="noopener ugc nofollow" target="_blank">DGS Framework</a> services, GC pauses are a significant source of tail latencies. That’s particularly true of our GRPC clients and servers, where request cancellations due to timeouts interact with reliability features such as retries, hedging and fallbacks. Each of these errors is a canceled request resulting in a retry so this reduction further reduces overall service traffic by this rate:</p><figure><div role="button" tabindex="0"><div><picture><source srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/0*SCVt4VGlA517hZDi 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/0*SCVt4VGlA517hZDi 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/0*SCVt4VGlA517hZDi 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/0*SCVt4VGlA517hZDi 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/0*SCVt4VGlA517hZDi 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/0*SCVt4VGlA517hZDi 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/0*SCVt4VGlA517hZDi 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcset="https://miro.medium.com/v2/resize:fit:640/0*SCVt4VGlA517hZDi 640w, https://miro.medium.com/v2/resize:fit:720/0*SCVt4VGlA517hZDi 720w, https://miro.medium.com/v2/resize:fit:750/0*SCVt4VGlA517hZDi 750w, https://miro.medium.com/v2/resize:fit:786/0*SCVt4VGlA517hZDi 786w, https://miro.medium.com/v2/resize:fit:828/0*SCVt4VGlA517hZDi 828w, https://miro.medium.com/v2/resize:fit:1100/0*SCVt4VGlA517hZDi 1100w, https://miro.medium.com/v2/resize:fit:1400/0*SCVt4VGlA517hZDi 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" width="700" height="150" loading="lazy" role="presentation"/></picture></div></div><figcaption>Errors rates per second. Previous week in white vs current cancellation rate in purple, as ZGC was enabled on a service cluster on November 16</figcaption></figure><p id="fc15">Removing the noise of pauses also allows us to identify actual sources of latency end-to-end, which would otherwise be hidden in the noise, as maximum pause time outliers can be significant:</p><figure><div role="button" tabindex="0"><div><picture><source srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/0*rW029WscxSKDQRQ6 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/0*rW029WscxSKDQRQ6 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/0*rW029WscxSKDQRQ6 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/0*rW029WscxSKDQRQ6 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/0*rW029WscxSKDQRQ6 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/0*rW029WscxSKDQRQ6 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/0*rW029WscxSKDQRQ6 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcset="https://miro.medium.com/v2/resize:fit:640/0*rW029WscxSKDQRQ6 640w, https://miro.medium.com/v2/resize:fit:720/0*rW029WscxSKDQRQ6 720w, https://miro.medium.com/v2/resize:fit:750/0*rW029WscxSKDQRQ6 750w, https://miro.medium.com/v2/resize:fit:786/0*rW029WscxSKDQRQ6 786w, https://miro.medium.com/v2/resize:fit:828/0*rW029WscxSKDQRQ6 828w, https://miro.medium.com/v2/resize:fit:1100/0*rW029WscxSKDQRQ6 1100w, https://miro.medium.com/v2/resize:fit:1400/0*rW029WscxSKDQRQ6 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" width="700" height="397" loading="lazy" role="presentation"/></picture></div></div><figcaption>Maximum GC pause times by cause, for the same service cluster as above. Yes, those ZGC pauses really are usually under one millisecond</figcaption></figure><p id="1011">Even after we saw very promising results in our evaluation, we expected the adoption of ZGC to be a trade off: a little less application throughput, due to store and load barriers, work performed in thread local handshakes, and the GC competing with the application for resources. We considered that an acceptable trade off, as avoiding pauses provided benefits that would outweigh that overhead.</p><p id="99f9">In fact, we’ve found for our services and architecture that there is no such trade off. For a given CPU utilization target, ZGC improves both average and P99 latencies with equal or better CPU utilization when compared to G1.</p><p id="7f1d">The consistency in request rates, request patterns, response time and allocation rates we see in many of our services certainly help ZGC, but we’ve found it’s equally capable of handling less consistent workloads (with exceptions of course; more on that below).</p><p id="d87b">Service owners often reach out to us with questions about excessive pause times and for help with tuning. We have several frameworks that periodically refresh large amounts of on-heap data to avoid external service calls for efficiency. These periodic refreshes of on-heap data are great at taking G1 by surprise, resulting in pause time outliers well beyond the default pause time goal.</p><p id="8dde">This long lived on-heap data was the major contributor to us not adopting non-generational ZGC previously. In the worst case we evaluated, non-generational ZGC caused 36% more CPU utilization than G1 for the same workload. That became a nearly 10% improvement with generational ZGC.</p><p id="841f">Half of all services required for streaming video use our <a href="https://hollow.how/)" rel="noopener ugc nofollow" target="_blank">Hollow</a> library for on-heap metadata. Removing pauses as a concern allowed us to <a href="https://github.com/Netflix/hollow/commit/4f21ab593543bb622d9ccea2f8e6295eae5e8080" rel="noopener ugc nofollow" target="_blank">remove array pooling mitigations</a>, freeing hundreds of megabytes of memory for allocations.</p><p id="b6bd">Operational simplicity also stems from ZGC’s heuristics and defaults. No explicit tuning has been required to achieve these results. Allocation stalls are rare, typically coinciding with abnormal spikes in allocation rates, and are shorter than the average pause times we saw with G1.</p><p id="aabd">We expected that losing <a href="https://shipilev.net/jvm/anatomy-quarks/23-compressed-references/" rel="noopener ugc nofollow" target="_blank">compressed references</a> on heaps &lt; 32G, due to <a href="https://youtu.be/YyXjC68l8mw?t=816" rel="noopener ugc nofollow" target="_blank">colored pointers requiring 64-bit object pointers</a>, would be a major factor in the choice of a garbage collector.</p><p id="2676">We’ve found that while that’s an important consideration for stop-the-world GCs, that’s not the case for ZGC where even on small heaps, the increase in allocation rate is amortized by the efficiency and operational improvements. Our thanks to Erik Österlund at Oracle for explaining the less intuitive benefits of colored pointers when it comes to concurrent garbage collectors, which lead us to evaluating ZGC more broadly than initially planned.</p><p id="3d63">In the majority of cases ZGC is also able to consistently make more memory available to the application:</p><figure><div role="button" tabindex="0"><div><picture><source srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/0*3eTNEdI2mHfL1Yvk 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/0*3eTNEdI2mHfL1Yvk 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/0*3eTNEdI2mHfL1Yvk 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/0*3eTNEdI2mHfL1Yvk 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/0*3eTNEdI2mHfL1Yvk 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/0*3eTNEdI2mHfL1Yvk 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/0*3eTNEdI2mHfL1Yvk 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcset="https://miro.medium.com/v2/resize:fit:640/0*3eTNEdI2mHfL1Yvk 640w, https://miro.medium.com/v2/resize:fit:720/0*3eTNEdI2mHfL1Yvk 720w, https://miro.medium.com/v2/resize:fit:750/0*3eTNEdI2mHfL1Yvk 750w, https://miro.medium.com/v2/resize:fit:786/0*3eTNEdI2mHfL1Yvk 786w, https://miro.medium.com/v2/resize:fit:828/0*3eTNEdI2mHfL1Yvk 828w, https://miro.medium.com/v2/resize:fit:1100/0*3eTNEdI2mHfL1Yvk 1100w, https://miro.medium.com/v2/resize:fit:1400/0*3eTNEdI2mHfL1Yvk 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" width="700" height="258" loading="lazy" role="presentation"/></picture></div></div><figcaption>Used vs available heap capacity following each GC cycle, for the same service cluster as above</figcaption></figure><p id="d4b1">ZGC has a fixed overhead 3% of the heap size, requiring more native memory than G1. Except in a couple of cases, there’s been no need to lower the maximum heap size to allow for more headroom, and those were services with greater than average native memory needs.</p><p id="2c51">Reference processing is also only performed in major collections with ZGC. We paid particular attention to deallocation of direct byte buffers, but we haven’t seen any impact thus far. This difference in reference processing did cause a <a href="https://bugs.openjdk.org/browse/JDK-8321178" rel="noopener ugc nofollow" target="_blank">performance problem with JSON thread dump support</a>, but that’s a unusual situation caused by a framework accidentally creating an unused ExecutorService instance for every request.</p><p id="976f">Even if you’re not using ZGC, you probably should be using huge pages, and <a href="https://shipilev.net/jvm/anatomy-quarks/2-transparent-huge-pages/" rel="noopener ugc nofollow" target="_blank">transparent huge pages</a> is the most convenient way to use them.</p><p id="8fda">ZGC uses shared memory for the heap and many Linux distributions configure shmem_enabled to <em>never</em>, which silently prevents ZGC from using huge pages with -XX:+UseTransparentHugePages.</p><p id="ffa7">Here we have a service deployed with no other change but shmem_enabled going from never to advise, reducing CPU utilization significantly:</p><figure><div role="button" tabindex="0"><div><picture><source srcset="https://miro.medium.com/v2/resize:fit:640/format:webp/0*bGoc3W9P_E2kjghe 640w, https://miro.medium.com/v2/resize:fit:720/format:webp/0*bGoc3W9P_E2kjghe 720w, https://miro.medium.com/v2/resize:fit:750/format:webp/0*bGoc3W9P_E2kjghe 750w, https://miro.medium.com/v2/resize:fit:786/format:webp/0*bGoc3W9P_E2kjghe 786w, https://miro.medium.com/v2/resize:fit:828/format:webp/0*bGoc3W9P_E2kjghe 828w, https://miro.medium.com/v2/resize:fit:1100/format:webp/0*bGoc3W9P_E2kjghe 1100w, https://miro.medium.com/v2/resize:fit:1400/format:webp/0*bGoc3W9P_E2kjghe 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px" type="image/webp"/><source data-testid="og" srcset="https://miro.medium.com/v2/resize:fit:640/0*bGoc3W9P_E2kjghe 640w, https://miro.medium.com/v2/resize:fit:720/0*bGoc3W9P_E2kjghe 720w, https://miro.medium.com/v2/resize:fit:750/0*bGoc3W9P_E2kjghe 750w, https://miro.medium.com/v2/resize:fit:786/0*bGoc3W9P_E2kjghe 786w, https://miro.medium.com/v2/resize:fit:828/0*bGoc3W9P_E2kjghe 828w, https://miro.medium.com/v2/resize:fit:1100/0*bGoc3W9P_E2kjghe 1100w, https://miro.medium.com/v2/resize:fit:1400/0*bGoc3W9P_E2kjghe 1400w" sizes="(min-resolution: 4dppx) and (max-width: 700px) 50vw, (-webkit-min-device-pixel-ratio: 4) and (max-width: 700px) 50vw, (min-resolution: 3dppx) and (max-width: 700px) 67vw, (-webkit-min-device-pixel-ratio: 3) and (max-width: 700px) 65vw, (min-resolution: 2.5dppx) and (max-width: 700px) 80vw, (-webkit-min-device-pixel-ratio: 2.5) and (max-width: 700px) 80vw, (min-resolution: 2dppx) and (max-width: 700px) 100vw, (-webkit-min-device-pixel-ratio: 2) and (max-width: 700px) 100vw, 700px"/><img alt="" width="700" height="284" loading="lazy" role="presentation"/></picture></div></div><figcaption>Deployment moving from 4k to 2m pages. Ignore the gap, that’s our immutable deployment process temporarily doubling the cluster capacity</figcaption></figure><p id="c3d9">Our default configuration:</p><ul><li id="ec4b">Sets heap minimum and maximums to equal size</li><li id="28e3">Configures -XX:+UseTransparentHugePages -XX:+AlwaysPreTouch</li><li id="be83">Uses the following transparent_hugepage configuration:</li></ul><pre><span id="d581">echo madvise | sudo tee /sys/kernel/mm/transparent_hugepage/enabled</span></pre><p id="30df">There is no best garbage collector. Each trades off collection throughput, application latency and resource utilization depending on the goal of the garbage collector.</p><p id="37af">For the workloads that have performed better with G1 vs ZGC, we’ve found that they tend to be more throughput oriented, with very spiky allocation rates and long running tasks holding objects for unpredictable periods.</p><p id="93e1">A notable example was a service where very spiky allocation rates and large numbers of long lived objects, which happened to be a particularly good fit for G1’s pause time goal and old region collection heuristics. It allowed G1 to avoid unproductive work in GC cycles that ZGC couldn’t.</p><p id="ce33">The switch to ZGC by default has provided the perfect opportunity for application owners to think about their choice of garbage collector. Several batch/precompute cases had been using G1 by default, where they would have seen better throughput from the parallel collector. In one large precompute workload we saw a 6–8% improvement in application throughput, shaving an hour off the batch time, versus G1.</p><p id="dcaf">Left unquestioned, assumptions and expectations could have caused us to miss one of the most impactful changes we’ve made to our operational defaults in a decade. We’d encourage you to try generational ZGC for yourself. It might surprise you as much as it surprised us.</p></div></div></div></div></section></div>
  </body>
</html>
