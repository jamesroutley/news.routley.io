<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://opensource.googleblog.com/2022/09/lyra-v2-a-better-faster-and-more-versatile-speech-codec.html">Original</a>
    <h1>Lyra V2 – a better, faster, and more versatile speech codec</h1>
    
    <div id="readability-page-1" class="page"><div id="post-body-1583098126142480568" itemprop="articleBody">
<p>
Since we open sourced the first version of <a href="https://opensource.googleblog.com/2021/04/lyra-enabling-voice-calls-for-next-billion-users.html" target="_blank">Lyra</a> on <a href="https://github.com/google/lyra" target="_blank">GitHub</a> last year, we are delighted to see a vibrant community growing around it, with thousands of stars, hundreds of forks, and many comments and pull requests. There are people who fixed and formatted our code, built continuous integration for the project, and even added <a href="https://github.com/mayitayew/lyra" target="_blank">support for Web Assembly</a>.
</p>
<p>
We are incredibly grateful for all these contributions, and we also heard the community&#39;s feedback, asking us to improve Lyra. Some examples of what developers wanted were to run Lyra on more platforms, develop applications in more languages; and for a model that computes faster with more bitrate options and  lower latency, and better audio quality with fewer artifacts.
</p>
<p>
That&#39;s why we are now releasing Lyra V2, with a new architecture that enjoys a wider platform support, provides scalable bitrate capabilities, has better performance, and generates higher quality audio. With this release, we hope to continue to evolve with the community, and with its collective creativity, see new applications being developed and new directions emerging.
</p>
<h2>New Architecture</h2>
<p>
Lyra V2 is based on an end-to-end neural audio codec called <a href="https://ai.googleblog.com/2021/08/soundstream-end-to-end-neural-audio.html" target="_blank">SoundStream</a>. The architecture has a residual vector quantizer (RVQ) sitting before and after the transmission channel, which quantizes the encoded information into a bitstream and reconstructs it on the decoder side. 
</p>
<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEga8Po-mwjqaOyRyhPnVQpokdRMiOCkQkswM_jHx-XYncxeqKL_o8OhNyFlllE5Kfntx9tSvIVj9E8ZNqUWofiW4n-RpiopBH-w91w5OM__-qHubpJJwtWWzBzFUy4xu3w7ZjTgLwOz0CSJg7NCnQldIN2FD1TCfLgOr2Gx7X_r9FLxSJy-HdUP5dos/s1500/Camp%20Compose%20(6).png"><img alt="Lyra V2&#39;s SoundStream architecture" data-original-height="450" data-original-width="1500" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEga8Po-mwjqaOyRyhPnVQpokdRMiOCkQkswM_jHx-XYncxeqKL_o8OhNyFlllE5Kfntx9tSvIVj9E8ZNqUWofiW4n-RpiopBH-w91w5OM__-qHubpJJwtWWzBzFUy4xu3w7ZjTgLwOz0CSJg7NCnQldIN2FD1TCfLgOr2Gx7X_r9FLxSJy-HdUP5dos/s16000/Camp%20Compose%20(6).png"/></a></p><p>The integration of RVQ into the architecture allows changing the bitrate of Lyra V2 at any time by selecting the number of quantizers to use. When more quantizers are used, higher quality audio is generated (at a cost of a higher bitrate). In Lyra V2, we support three different bitrates: 3.2 kps, 6 kbps, and 9.2 kbps. This enables developers to choose a bitrate most suitable for their network condition and quality requirements.</p>
<p>
Lyra V2&#39;s model is exported in <a href="https://www.tensorflow.org/lite" target="_blank">TensorFlow Lite</a>, TensorFlow&#39;s lightweight cross-platform solution for mobile and embedded devices, which supports various platforms and hardware accelerations. The code is tested on Android phones and Linux, with experimental Mac and Windows support. Operation on iOS and other embedded platforms is not currently supported, although we expect it is possible with additional effort. Moreover, this paradigm opens Lyra to any future platform supported by TensorFlow Lite.
</p>
<h2>Better Performance</h2>


<p>
With the new architecture, the delay is reduced from 100 ms with the previous version to 20 ms.  In this regard, Lyra V2 is comparable to the most widely used audio codec <a href="https://opus-codec.org/" target="_blank">Opus</a> for <a href="https://en.wikipedia.org/wiki/WebRTC" target="_blank">WebRTC</a>, which has a typical delay of 26.5 ms, 46.5 ms, and 66.5 ms.
</p>
<p>
Lyra V2 also encodes and decodes five times faster than the previous version. On a Pixel 6 Pro phone, Lyra V2 takes 0.57 ms to encode and decode a 20 ms audio frame, which is 35 times faster than real time. The reduced complexity means that more phones can run Lyra V2 in real time than V1, and that the overall battery consumption is lowered.
</p>
<h2>Higher Quality</h2>


<p>
Driven by the advance of machine learning research over the years, the quality of the generated audio is also improved. Our listening tests show that the audio quality (measured in <a href="https://en.wikipedia.org/wiki/MUSHRA" target="_blank">MUSHRA</a> score, an indication of subjective quality) of Lyra V2 at 3.2 kbps, 6 kbps, and </p>
<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiZETIGDNzqjIiZRbCo1uav_uAMNRIc8dS2BYapjyCSNC-s-bOtjEngR_MYEyBVc6IWvZ35zk9ocvpdvW-QF7DhqhtnEg48MUSiwSKfkUjgiVu_DpuJA-mtsId99R6udyAXAC6wEfgmosfGNDm1N93u-i3E0zqiRnxZGwwBi8nMrHYUO4PE7rOM1-bG/s1000/Lyra%20image%202.png"><img alt="Lyra vs. Opus at various bitrates" data-original-height="625" data-original-width="1000" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiZETIGDNzqjIiZRbCo1uav_uAMNRIc8dS2BYapjyCSNC-s-bOtjEngR_MYEyBVc6IWvZ35zk9ocvpdvW-QF7DhqhtnEg48MUSiwSKfkUjgiVu_DpuJA-mtsId99R6udyAXAC6wEfgmosfGNDm1N93u-i3E0zqiRnxZGwwBi8nMrHYUO4PE7rOM1-bG/s16000/Lyra%20image%202.png"/></a></p>
<div>
    <table>
        <thead>
            <tr>
                <th scope="col"><br/></th>
                <th scope="col">
                    <p>Sample 1</p>
                </th>
                <th scope="col">
                    <p>Sample 2</p>
                </th>
            </tr>
            <tr>
                <th scope="col"><span></span></th>
                <th scope="col">
                    
                </th>
                <th scope="col">
                    </th>
            </tr>
            <tr>
                <th scope="col"><p><span>Opus       @6kbps</span></p></th><th scope="col">
                    
                </th>
                <th scope="col">
                    
                </th>
            </tr>
            <tr>
                <th scope="col"><span></span></th>
                <th scope="col">
                    
                </th>
                <th scope="col">
                    
                </th>
            </tr>
            <tr>
                <td></td><td>
                    
                </td>
                <td>
                    
                </td>
            </tr>
            <tr>
                <td></td><td>
                    
                </td>
                <td>
                    
                </td>
            </tr>
            <tr>
                <td></td><td>
                    
                </td>
                <td>
                    
                </td>
            </tr>
            <tr>
                <td></td><td>
                    
                </td>
                <td>
                    
                </td>
            </tr>
            <tr>
                <td></td><td>
                    
                </td>
                <td>
                    
                </td>
            </tr>
            <tr>
                <td></td><td>
                    
                </td>
                <td>
                    
                </td>
            </tr>
        </thead></table></div>
    
<p>This makes Lyra V2 a competitive alternative to other state-of-the-art <a href="https://en.wikipedia.org/wiki/Telephony">telephony</a> codecs. While Lyra V1 already compares favorably to the <a href="https://en.wikipedia.org/wiki/Adaptive_Multi-Rate_audio_codec">Adaptive Multi-Rate</a> (AMR-NB) codec, Lyra V2 further outperforms <a href="https://en.wikipedia.org/wiki/Enhanced_Voice_Services">Enhanced Voice Services</a> (EVS) and <a href="https://en.wikipedia.org/wiki/Adaptive_Multi-Rate_Wideband">Adaptive Multi-Rate Wideband</a> (AMR-WB), and is on par with Opus, all the while using only 50% - 60% of their bandwidth. 
</p>
<p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhB9KfYCUZZpAskL8-yLxzfiVea1LwJEiL1lXiczyUraH_0dFcRnSyGfFbDbJlN7uXg8sjDED_T-ZQrU9W2APjxT94iHRKK-xw28dZwQ0FDkRbXu2CEywXg6CCahSSzCzIfqh5wA5oGMGTG-Vf24-epaBF1JXXGrE0EsKIsmhKZ_BbEdT4Uzg5Yf5US/s1000/Lyra%20image%203.png"><img alt="Lyra vs. state-of-the-art codecs" data-original-height="625" data-original-width="1000" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhB9KfYCUZZpAskL8-yLxzfiVea1LwJEiL1lXiczyUraH_0dFcRnSyGfFbDbJlN7uXg8sjDED_T-ZQrU9W2APjxT94iHRKK-xw28dZwQ0FDkRbXu2CEywXg6CCahSSzCzIfqh5wA5oGMGTG-Vf24-epaBF1JXXGrE0EsKIsmhKZ_BbEdT4Uzg5Yf5US/s16000/Lyra%20image%203.png"/></a></p>
 



<div><p>This means more devices can be connected in bandwidth-constrained environments, or that additional information can be sent over the network to reduce voice choppiness through <a href="https://en.wikipedia.org/wiki/Error_correction_code#Forward_error_correction" target="_blank">forward error correction</a> and <a href="https://en.wikipedia.org/wiki/Packet_loss_concealment" target="_blank">packet loss concealment</a>.
</p>
<h2>Open Source Release</h2>


<p>
Lyra V2 continues to provide what is already in Lyra V1 (the build tools, the testing frameworks, the C++ encoding and decoding API, the signal processing toolchain, and the example Android app). Developers who have experience with the Lyra V1 API will find that the V2 API looks familiar, but with a few changes. For example, now it&#39;s possible to change bitrates during encoding (more information is available in the release notes). In addition, the model definitions and weights are included as <span>.tflite</span> files. As with V1, this release is a beta version and the API and bitstream are expected to change. The code for running Lyra is open sourced under the Apache license. We can’t wait to see what innovative applications people will create with the new and improved Lyra!
</p>
<p>
<em>By Ｈengchin Yeh - Chrome</em>
</p>
<h3>Acknowledgements</h3>


<p>
The following people helped make the open source release possible: from Chrome: Alejandro Luebs, Michael Chinen, Andrew Storus, Tom Denton, Felicia Lim, Bastiaan Kleijn, Jan Skoglund, Yaowu Xu, Jamieson Brettle, Omer Osman, Matt Frost, Jim Bankoski; and from Google Research: Neil Zeghidour, Marco Tagliasacchi
</p>
 </div>

</div></div>
  </body>
</html>
