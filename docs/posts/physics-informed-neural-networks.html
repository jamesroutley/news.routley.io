<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://nchagnet.pages.dev/blog/physics-informed-neural-networks/">Original</a>
    <h1>Physics Informed Neural Networks</h1>
    
    <div id="readability-page-1" class="page"><article> <div>  <p><a href="https://nchagnet.pages.dev/blog"> <span><svg stroke="currentColor" fill="currentColor" stroke-width="0" viewBox="0 0 448 512" height="18" width="18" xmlns="http://www.w3.org/2000/svg"><path d="M9.4 233.4c-12.5 12.5-12.5 32.8 0 45.3l160 160c12.5 12.5 32.8 12.5 45.3 0s12.5-32.8 0-45.3L109.2 288 416 288c17.7 0 32-14.3 32-32s-14.3-32-32-32l-306.7 0L214.6 118.6c12.5-12.5 12.5-32.8 0-45.3s-32.8-12.5-45.3 0l-160 160z"></path></svg><span>
Back to articles</span></span> </a></p>   <p>I mentioned in a <a href="https://nchagnet.pages.dev/blog/roadmap-2025">previous post</a> that as part of my position as junior DS for IKEA, I also get the opportunity to take part in their training program (called AI accelerator program). It’s a six months long program in which we are trained on all aspects of data science and AI by both professionals but also through various courses. The program covers a lot of topics, encompassing traditional machine learning methods (for example, timeseries forecasting which I <a href="https://nchagnet.pages.dev/blog/energy-forecast-project">recently discussed</a>), fundamentals of computer vision models, all the way towards the latest and hottest generative AI techniques (which I hope I’ll get to talk about soon!).</p>
<p>Today, I want to share with you a really interesting use case of deep learning models in the field of physics. The models in question, called “physics-informed neural networks”, are able to learn the solution to a differential equation encoding the the dynamics of a real physical system. This is quite different from the more traditional supervised learning applications you usually learn first. In this post, I will summarize how they work and show you an example of such a model at work, although for more details I highly recommend <a href="https://labpresse.com/solving-differential-equations-using-neural-networks">this post</a> as well as the original research papers.<sup><a href="#user-content-fn-paper1" id="user-content-fnref-paper1" data-footnote-ref="" aria-describedby="footnote-label">1</a></sup> <sup><a href="#user-content-fn-paper2" id="user-content-fnref-paper2" data-footnote-ref="" aria-describedby="footnote-label">2</a></sup> <sup><a href="#user-content-fn-paper3" id="user-content-fnref-paper3" data-footnote-ref="" aria-describedby="footnote-label">3</a></sup> <sup><a href="#user-content-fn-paper4" id="user-content-fnref-paper4" data-footnote-ref="" aria-describedby="footnote-label">4</a></sup> To write this post, I also relied on <a href="https://arxiv.org/abs/2408.10011">the companion paper</a> to the <a href="https://github.com/JB55Matthews/PinnDE">Python PinnDE solver</a> and on the <a href="https://github.com/lululxvi/deepxde/tree/master">DeepXDE</a> library.</p>
<section data-heading-rank="2" aria-labelledby="pinn-how-do-they-work"><h2 id="pinn-how-do-they-work">PINN: how do they work?</h2>
<p>Neural networks (NNs) are fundamentally a great way to approximate complicated continuous functions of many variables. The building blocks of NNs are simple:</p>
<ul>
<li>linear operations <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>x</mi><mi>i</mi></msub><mo>→</mo><msub><mi>a</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><msub><mi>x</mi><mi>j</mi></msub><mo>+</mo><msub><mi>b</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">x_i \to a_{ij} x_j + b_i</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span>x</span><span><span><span><span><span><span></span><span><span>i</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span></span><span>→</span><span></span></span><span><span></span><span><span>a</span><span><span><span><span><span><span></span><span><span><span>ij</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span><span>x</span><span><span><span><span><span><span></span><span><span>j</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span></span><span>+</span><span></span></span><span><span></span><span><span>b</span><span><span><span><span><span><span></span><span><span>i</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span>,</li>
<li>smooth non-linear functions such as the hyperbolic tangent or the sigmoid function.</li>
</ul>
<p>When composing these operations, you make a <em>neuron</em>. By connecting stacks of these neurons together in layers, it is possible to get extremely complex output. All that’s left is tuning all the parameters <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>a</mi><mrow><mi>i</mi><mi>j</mi></mrow></msub><mo separator="true">,</mo><msub><mi>b</mi><mi>i</mi></msub></mrow><annotation encoding="application/x-tex">a_{ij}, b_i</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span>a</span><span><span><span><span><span><span></span><span><span><span>ij</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>,</span><span></span><span><span>b</span><span><span><span><span><span><span></span><span><span>i</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span> for each neuron in each layer. These quickly grow in size: for a simple <code>(1, 64, 128, 64, 1)</code> dense neural network (where each number indicates the number of neurons each layer), you have to tune more than 16k parameters.</p>
<p>This step is called <strong>training</strong> of the network, where the network is fed some input and returns some numbers as output which is compared to some reference output (usually, those are <em>labels</em> of the <strong>ground truth</strong>). The parameters are then all slightly tuned to make this output closer to whatever reference value we have. Through this process, we are exploring the parameter landscape and looking for a global minimum of our loss function, usually by using some derivative of the gradient descent algorithm. After doing this enough times, one hopes that the trained network output approximates the distribution on the training data as well as generalizes to any new example.</p>
<p>The main idea behind PINNs is to use this property of the NNs as universal continuous function approximators to learn the solution to the differential equation of interest. Instead of evaluating the loss of the output of the NN compared to some labels, we assume that the output should solve the differential equation itself (up to some parametrization choice) and so we use the differential equation <strong>as a loss function</strong>. The process is then more or less the same, except you feed the NN with different points of your domain, then plug the output inside the differential equation and use the residual to tune the parameters closer to an optimum. Importantly, unlike in <em>supervised learning</em>, there is no need to curate a training dataset here, you just keep evaluating your model on randomly sampled points in the domain you’re interested in.</p>
<p><svg aria-roledescription="flowchart-v2" role="graphics-document document" viewBox="0 0 708.3828125 510" style="max-width:708.3828125px" xmlns="http://www.w3.org/2000/svg" width="100%" id="mermaid-0"><g><marker orient="auto" markerHeight="8" markerWidth="8" markerUnits="userSpaceOnUse" refY="5" refX="5" viewBox="0 0 10 10" id="mermaid-0_flowchart-v2-pointEnd"><path style="stroke-width:1;stroke-dasharray:1, 0" d="M 0 0 L 10 5 L 0 10 z"></path></marker><marker orient="auto" markerHeight="8" markerWidth="8" markerUnits="userSpaceOnUse" refY="5" refX="4.5" viewBox="0 0 10 10" id="mermaid-0_flowchart-v2-pointStart"><path style="stroke-width:1;stroke-dasharray:1, 0" d="M 0 5 L 10 10 L 10 0 z"></path></marker><marker orient="auto" markerHeight="11" markerWidth="11" markerUnits="userSpaceOnUse" refY="5" refX="11" viewBox="0 0 10 10" id="mermaid-0_flowchart-v2-circleEnd"><circle style="stroke-width:1;stroke-dasharray:1, 0" r="5" cy="5" cx="5"></circle></marker><marker orient="auto" markerHeight="11" markerWidth="11" markerUnits="userSpaceOnUse" refY="5" refX="-1" viewBox="0 0 10 10" id="mermaid-0_flowchart-v2-circleStart"><circle style="stroke-width:1;stroke-dasharray:1, 0" r="5" cy="5" cx="5"></circle></marker><marker orient="auto" markerHeight="11" markerWidth="11" markerUnits="userSpaceOnUse" refY="5.2" refX="12" viewBox="0 0 11 11" id="mermaid-0_flowchart-v2-crossEnd"><path style="stroke-width:2;stroke-dasharray:1, 0" d="M 1,1 l 9,9 M 10,1 l -9,9"></path></marker><marker orient="auto" markerHeight="11" markerWidth="11" markerUnits="userSpaceOnUse" refY="5.2" refX="-1" viewBox="0 0 11 11" id="mermaid-0_flowchart-v2-crossStart"><path style="stroke-width:2;stroke-dasharray:1, 0" d="M 1,1 l 9,9 M 10,1 l -9,9"></path></marker><g><g></g><g><path marker-end="url(#mermaid-0_flowchart-v2-pointEnd)" style="" id="L_A_B_0" d="M207.551,62L207.551,66.167C207.551,70.333,207.551,78.667,207.551,86.333C207.551,94,207.551,101,207.551,104.5L207.551,108"></path><path marker-end="url(#mermaid-0_flowchart-v2-pointEnd)" style="" id="L_B_C_1" d="M131.984,166L120.323,170.167C108.662,174.333,85.339,182.667,73.677,190.333C62.016,198,62.016,205,62.016,208.5L62.016,212"></path><path marker-end="url(#mermaid-0_flowchart-v2-pointEnd)" style="" id="L_C_E_2" d="M62.016,270L62.016,274.167C62.016,278.333,62.016,286.667,68.608,294.665C75.2,302.663,88.385,310.327,94.977,314.158L101.569,317.99"></path><path marker-end="url(#mermaid-0_flowchart-v2-pointEnd)" style="" id="L_D_E_3" d="M240.945,270L240.945,274.167C240.945,278.333,240.945,286.667,234.353,294.665C227.761,302.663,214.576,310.327,207.984,314.158L201.392,317.99"></path><path marker-end="url(#mermaid-0_flowchart-v2-pointEnd)" style="" id="L_E_F_4" d="M151.48,374L151.48,378.167C151.48,382.333,151.48,390.667,154.692,398.499C157.903,406.33,164.325,413.661,167.536,417.326L170.747,420.991"></path><path marker-end="url(#mermaid-0_flowchart-v2-pointEnd)" style="" id="L_F_B_5" d="M295.558,424L304.96,419.833C314.363,415.667,333.168,407.333,342.57,394.5C351.973,381.667,351.973,364.333,351.973,347C351.973,329.667,351.973,312.333,351.973,295C351.973,277.667,351.973,260.333,351.973,243C351.973,225.667,351.973,208.333,341.028,195.726C330.083,183.118,308.193,175.237,297.248,171.296L286.303,167.355"></path><path marker-end="url(#mermaid-0_flowchart-v2-pointEnd)" style="" id="L_AA_BB_6" d="M570.383,62L570.383,66.167C570.383,70.333,570.383,78.667,570.383,86.333C570.383,94,570.383,101,570.383,104.5L570.383,108"></path><path marker-end="url(#mermaid-0_flowchart-v2-pointEnd)" style="" id="L_BB_CC_7" d="M522.827,166L515.488,170.167C508.149,174.333,493.471,182.667,486.132,190.333C478.793,198,478.793,205,478.793,208.5L478.793,212"></path><path marker-end="url(#mermaid-0_flowchart-v2-pointEnd)" style="" id="L_CC_EE_8" d="M478.793,270L478.793,274.167C478.793,278.333,478.793,286.667,478.793,294.333C478.793,302,478.793,309,478.793,312.5L478.793,316"></path><path marker-end="url(#mermaid-0_flowchart-v2-pointEnd)" style="" id="L_EE_FF_9" d="M478.793,374L478.793,378.167C478.793,382.333,478.793,390.667,484.209,398.618C489.626,406.57,500.459,414.139,505.875,417.924L511.291,421.709"></path><path marker-end="url(#mermaid-0_flowchart-v2-pointEnd)" style="" id="L_FF_BB_10" d="M609.023,424L613.152,419.833C617.28,415.667,625.536,407.333,629.665,394.5C633.793,381.667,633.793,364.333,633.793,347C633.793,329.667,633.793,312.333,633.793,295C633.793,277.667,633.793,260.333,633.793,243C633.793,225.667,633.793,208.333,629.228,195.923C624.662,183.512,615.531,176.024,610.966,172.28L606.4,168.536"></path></g><g><g><g transform="translate(0, 0)"><foreignObject height="0" width="0"></foreignObject></g></g><g><g transform="translate(0, 0)"><foreignObject height="0" width="0"></foreignObject></g></g><g><g transform="translate(0, 0)"><foreignObject height="0" width="0"></foreignObject></g></g><g><g transform="translate(0, 0)"><foreignObject height="0" width="0"></foreignObject></g></g><g><g transform="translate(0, 0)"><foreignObject height="0" width="0"></foreignObject></g></g><g><g transform="translate(0, 0)"><foreignObject height="0" width="0"></foreignObject></g></g><g><g transform="translate(0, 0)"><foreignObject height="0" width="0"></foreignObject></g></g><g><g transform="translate(0, 0)"><foreignObject height="0" width="0"></foreignObject></g></g><g><g transform="translate(0, 0)"><foreignObject height="0" width="0"></foreignObject></g></g><g><g transform="translate(0, 0)"><foreignObject height="0" width="0"></foreignObject></g></g><g><g transform="translate(0, 0)"><foreignObject height="0" width="0"></foreignObject></g></g></g><g><g transform="translate(207.55078125, 35)" id="flowchart-A-0"><rect height="54" width="131.171875" y="-27" x="-65.5859375" style=""></rect><g transform="translate(-35.5859375, -12)" style=""><rect></rect><foreignObject height="24" width="71.171875"><p><span><p>Input data</p></span></p></foreignObject></g></g><g transform="translate(207.55078125, 139)" id="flowchart-B-1"><rect height="54" width="170.265625" y="-27" x="-85.1328125" style=""></rect><g transform="translate(-55.1328125, -12)" style=""><rect></rect><foreignObject height="24" width="110.265625"><p><span><p>Neural Network</p></span></p></foreignObject></g></g><g transform="translate(62.015625, 243)" id="flowchart-C-3"><rect height="54" width="108.03125" y="-27" x="-54.015625" style=""></rect><g transform="translate(-24.015625, -12)" style=""><rect></rect><foreignObject height="24" width="48.03125"><p><span><p>Output</p></span></p></foreignObject></g></g><g transform="translate(151.48046875, 347)" id="flowchart-E-5"><rect height="54" width="154.28125" y="-27" x="-77.140625" style=""></rect><g transform="translate(-47.140625, -12)" style=""><rect></rect><foreignObject height="24" width="94.28125"><p><span><p>Loss function</p></span></p></foreignObject></g></g><g transform="translate(240.9453125, 243)" id="flowchart-D-6"><rect height="54" width="149.828125" y="-27" x="-74.9140625" style=""></rect><g transform="translate(-44.9140625, -12)" style=""><rect></rect><foreignObject height="24" width="89.828125"><p><span><p>Ground truth</p></span></p></foreignObject></g></g><g transform="translate(207.55078125, 463)" id="flowchart-F-9"><rect height="78" width="260" y="-39" x="-130" style=""></rect><g transform="translate(-100, -24)" style=""><rect></rect><foreignObject height="48" width="200"><p><span><p>Gradient calculation and weight update</p></span></p></foreignObject></g></g><g transform="translate(570.3828125, 35)" id="flowchart-AA-12"><rect height="54" width="196.984375" y="-27" x="-98.4921875" style=""></rect><g transform="translate(-68.4921875, -12)" style=""><rect></rect><foreignObject height="24" width="136.984375"><p><span><p>Point in the domain</p></span></p></foreignObject></g></g><g transform="translate(570.3828125, 139)" id="flowchart-BB-13"><rect height="54" width="170.265625" y="-27" x="-85.1328125" style=""></rect><g transform="translate(-55.1328125, -12)" style=""><rect></rect><foreignObject height="24" width="110.265625"><p><span><p>Neural Network</p></span></p></foreignObject></g></g><g transform="translate(478.79296875, 243)" id="flowchart-CC-15"><rect height="54" width="108.03125" y="-27" x="-54.015625" style=""></rect><g transform="translate(-24.015625, -12)" style=""><rect></rect><foreignObject height="24" width="48.03125"><p><span><p>Output</p></span></p></foreignObject></g></g><g transform="translate(478.79296875, 347)" id="flowchart-EE-17"><rect height="54" width="183.640625" y="-27" x="-91.8203125" style=""></rect><g transform="translate(-61.8203125, -12)" style=""><rect></rect><foreignObject height="24" width="123.640625"><p><span><p>Equation residual</p></span></p></foreignObject></g></g><g transform="translate(570.3828125, 463)" id="flowchart-FF-19"><rect height="78" width="260" y="-39" x="-130" style=""></rect><g transform="translate(-100, -24)" style=""><rect></rect><foreignObject height="48" width="200"><p><span><p>Gradient calculation and weight update</p></span></p></foreignObject></g></g></g></g></g></svg></p>
<p>One important caveat of this method is boundary conditions: when you solve a differential equation <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi mathvariant="script">L</mi><mo stretchy="false">[</mo><mi>y</mi><mo stretchy="false">]</mo><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\mathcal L[y] = 0</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>L</span><span>[</span><span>y</span><span>]</span><span></span><span>=</span><span></span></span><span><span></span><span>0</span></span></span></span>, you also need to provide enough boundary conditions (values and derivatives for an initial-value problem, values at boundaries for a boundary-value problem) to uniquely determine the solution. There are two ways to do this:</p>
<ul>
<li>you can add the constraints as penalty terms on the loss function, so the optimization process fixes both the solution and its boundary conditions,</li>
<li>or, you can parametrize the solution (what we usually call in physics an <em>ansatz</em>) in such a way that the conditions are automatically applied.</li>
</ul>
<p>In the first case, you just define the loss function on your output <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>y</span></span></span></span> as</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="script">L</mi><mo stretchy="false">[</mo><mi>y</mi><mo stretchy="false">]</mo><mo>=</mo><msub><mi mathvariant="script">L</mi><mrow><mrow><mi mathvariant="normal">P</mi><mi mathvariant="normal">D</mi><mi mathvariant="normal">E</mi></mrow><mo stretchy="false">[</mo><mi>y</mi><mo stretchy="false">]</mo></mrow></msub><mo>+</mo><msub><mi mathvariant="script">L</mi><mrow><mi mathvariant="normal">B</mi><mi mathvariant="normal">o</mi><mi mathvariant="normal">u</mi><mi mathvariant="normal">n</mi><mi mathvariant="normal">d</mi><mi mathvariant="normal">a</mi><mi mathvariant="normal">r</mi><mi mathvariant="normal">y</mi></mrow></msub><mo>+</mo><msub><mi mathvariant="script">L</mi><mrow><mi mathvariant="normal">I</mi><mi mathvariant="normal">n</mi><mi mathvariant="normal">i</mi><mi mathvariant="normal">t</mi><mi mathvariant="normal">.</mi></mrow></msub></mrow><annotation encoding="application/x-tex">    \mathcal L[y] = \mathcal L_{\mathrm{PDE}[y]} + \mathcal L_{\mathrm{Boundary}} + \mathcal L_{\mathrm{Init.}}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>L</span><span>[</span><span>y</span><span>]</span><span></span><span>=</span><span></span></span><span><span></span><span><span>L</span><span><span><span><span><span><span></span><span><span><span><span>PDE</span></span><span>[</span><span>y</span><span>]</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span></span><span>+</span><span></span></span><span><span></span><span><span>L</span><span><span><span><span><span><span></span><span><span><span><span>Boundary</span></span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span></span><span>+</span><span></span></span><span><span></span><span><span>L</span><span><span><span><span><span><span></span><span><span><span><span>Init.</span></span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span></span>
<p>where in practice, each term can and should be weighted differently. This method is equivalent to “adding up” all the sources of errors and minimizing them all at the same time. In the examples below, I will be using a package which relies on this method by default.
To give an example of the second method, consider the following initial-value problem</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi mathvariant="script">M</mi><mo stretchy="false">[</mo><mi>y</mi><mo stretchy="false">]</mo><mo>=</mo><mn>0</mn><mtext> </mtext><mo separator="true">,</mo><mspace width="1em"></mspace><mi>y</mi><mo stretchy="false">(</mo><mi>t</mi><mo>=</mo><mn>0</mn><mo stretchy="false">)</mo><mo>=</mo><msub><mi>y</mi><mn>0</mn></msub><mtext> </mtext><mo separator="true">,</mo><mspace width="1em"></mspace><msup><mi>y</mi><mo mathvariant="normal">′</mo></msup><mo stretchy="false">(</mo><mi>t</mi><mo>=</mo><mn>0</mn><mo stretchy="false">)</mo><mo>=</mo><msub><mi>y</mi><mn>1</mn></msub><mtext> </mtext><mo separator="true">,</mo><mspace width="1em"></mspace><mi>t</mi><mo>∈</mo><mo stretchy="false">[</mo><mn>0</mn><mo separator="true">,</mo><mn>1</mn><mo stretchy="false">]</mo><mtext> </mtext><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">    \mathcal M[y] = 0~, \quad y(t = 0) = y_0~, \quad y^\prime(t=0) = y_1~, \quad t \in [0, 1]~.</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>M</span><span>[</span><span>y</span><span>]</span><span></span><span>=</span><span></span></span><span><span></span><span>0</span><span> </span><span>,</span><span></span><span></span><span>y</span><span>(</span><span>t</span><span></span><span>=</span><span></span></span><span><span></span><span>0</span><span>)</span><span></span><span>=</span><span></span></span><span><span></span><span><span>y</span><span><span><span><span><span><span></span><span><span>0</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span> </span><span>,</span><span></span><span></span><span><span>y</span><span><span><span><span><span><span></span><span><span>′</span></span></span></span></span></span></span></span><span>(</span><span>t</span><span></span><span>=</span><span></span></span><span><span></span><span>0</span><span>)</span><span></span><span>=</span><span></span></span><span><span></span><span><span>y</span><span><span><span><span><span><span></span><span><span>1</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span> </span><span>,</span><span></span><span></span><span>t</span><span></span><span>∈</span><span></span></span><span><span></span><span>[</span><span>0</span><span>,</span><span></span><span>1</span><span>]</span><span> </span><span>.</span></span></span></span></span>
<p>I mentioned previously that PINNs model the solution to the equation from the output <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">N(t)</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>N</span><span>(</span><span>t</span><span>)</span></span></span></span> of the neural network. However, you can also use that output as a building block for a more complex function. In the case I just presented, the parametrization</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>y</mi><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo><mo>=</mo><msub><mi>y</mi><mn>0</mn></msub><mo>+</mo><msub><mi>y</mi><mn>1</mn></msub><mi>t</mi><mo>+</mo><msup><mi>t</mi><mn>2</mn></msup><mi>N</mi><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo><mtext> </mtext><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">y(t) = y_0 + y_1 t + t^2 N(t)~,</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>y</span><span>(</span><span>t</span><span>)</span><span></span><span>=</span><span></span></span><span><span></span><span><span>y</span><span><span><span><span><span><span></span><span><span>0</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span></span><span>+</span><span></span></span><span><span></span><span><span>y</span><span><span><span><span><span><span></span><span><span>1</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>t</span><span></span><span>+</span><span></span></span><span><span></span><span><span>t</span><span><span><span><span><span><span></span><span><span>2</span></span></span></span></span></span></span></span><span>N</span><span>(</span><span>t</span><span>)</span><span> </span><span>,</span></span></span></span></span>
<p>automatically satisfies the initial value conditions<sup><a href="#user-content-fn-ansatz" id="user-content-fnref-ansatz" data-footnote-ref="" aria-describedby="footnote-label">5</a></sup>. So instead of training the network so that <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>N</mi></mrow><annotation encoding="application/x-tex">N</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>N</span></span></span></span> is a solution to the equation, you can train the network so that <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi></mrow><annotation encoding="application/x-tex">y</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>y</span></span></span></span> is a solution. That way, you get the initial value conditions for free and the network will simply adapt.</p>
<blockquote>
<p>Okay, so why are these models useful?</p>
</blockquote>
<p>The main advantage of PINNs is that they provide mesh-free solutions to differential equations. Usually, to solve this kind of problem, you need to discretize the space on which the solution exists (<em>the mesh</em>), and then you can for example approximate the derivatives of the solution by the values at nearby points, so that your problem becomes algebraic and amenable to all sorts of numerical methods.
With a PINN, you can use the autograd properties of your favorite tensor package to calculate the loss function at much greater accuracy, and in particular it doesn’t depend on the size of the mesh you use to train the model. Moreover, these methods tend to require much fewer points to approximate the solution than mesh-based methods do (I will showcase this in the examples below).
The mesh-free nature of these methods also comes in handy when dealing with unusual geometries: you can just sample random points inside the geometry instead of having to create a special, complex mesh. This is very useful in areas like fluid dynamics where you might have a custom geometry for your problem.</p>
<p>Another interesting advantage of these methods is how trendy deep learning methods are. There is currently a lot of money and efforts directed towards improving NN training efficiency, both on a technical level as well as on a hardware level (GPUs, TPUs). Any such improvement is bound to spill out to any other application, including PINNs!</p>
</section><section data-heading-rank="2" aria-labelledby="examples"><h2 id="examples">Examples</h2>
<p>Let’s now take a look at various examples of differential equations matching real physical systems. To solve these, I am using the <a href="https://github.com/lululxvi/deepxde/tree/master">DeepXDE</a> library which abstracts away a lot of the difficulties and intricacies you might encounter. However, if you are interested in learning more about the nitty gritty of PINNs, I highly recommend implementing your own architecture from scratch for at least one example.</p>
<section data-heading-rank="3" aria-labelledby="simple-harmonic-oscillator"><h3 id="simple-harmonic-oscillator">Simple harmonic oscillator</h3>
<section data-heading-rank="4" aria-labelledby="theory"><h4 id="theory">Theory</h4>
<p>When working with new ideas and methods, it’s always good to start with a simple model for which you already know the answer. The typical model for this in physics is the harmonic oscillator (think a mass on a spring moving back and forth). This model has far-reaching importance throughout all of physics: at a simplified level, it describes systems such as sound waves in metals or electrical RLC circuits, while its quantum counterpart is at the root of the quantized energy description of atoms. The dynamics of the harmonic oscillator are governed by the following differential equation:</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msubsup><mi mathvariant="normal">∂</mi><mi>t</mi><mn>2</mn></msubsup><mi>y</mi><mo>+</mo><mi>ξ</mi><msub><mi>ω</mi><mn>0</mn></msub><mtext> </mtext><msub><mi mathvariant="normal">∂</mi><mi>t</mi></msub><mi>y</mi><mo>+</mo><mfrac><msubsup><mi>ω</mi><mn>0</mn><mn>2</mn></msubsup><mn>4</mn></mfrac><mi>y</mi><mo>=</mo><mn>0</mn><mtext> </mtext><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">    \partial_t^2 y + \xi \omega_0 \, \partial_t y + \frac{\omega_0^2}{4} y = 0~.</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span>∂</span><span><span><span><span><span><span></span><span><span>t</span></span></span><span><span></span><span><span>2</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>y</span><span></span><span>+</span><span></span></span><span><span></span><span>ξ</span><span><span>ω</span><span><span><span><span><span><span></span><span><span>0</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span></span><span><span>∂</span><span><span><span><span><span><span></span><span><span>t</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>y</span><span></span><span>+</span><span></span></span><span><span></span><span><span></span><span><span><span><span><span><span></span><span><span>4</span></span></span><span><span></span><span></span></span><span><span></span><span><span><span>ω</span><span><span><span><span><span><span></span><span><span>0</span></span></span><span><span></span><span><span>2</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span></span></span><span>y</span><span></span><span>=</span><span></span></span><span><span></span><span>0</span><span> </span><span>.</span></span></span></span></span>
<p>In this equation, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ω</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\omega_0</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span>ω</span><span><span><span><span><span><span></span><span><span>0</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span> is a proper frequency of the system, and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ξ</mi><msub><mi>ω</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\xi \omega_0</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>ξ</span><span><span>ω</span><span><span><span><span><span><span></span><span><span>0</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span> accounts for fluid friction (due to air resistance for example). In the rest of this example, I will only be interested in solutions satisfying the initial value constraints <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>y</mi><mo stretchy="false">(</mo><mi>t</mi><mo>=</mo><mn>0</mn><mo stretchy="false">)</mo><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">y(t=0) = 1</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>y</span><span>(</span><span>t</span><span></span><span>=</span><span></span></span><span><span></span><span>0</span><span>)</span><span></span><span>=</span><span></span></span><span><span></span><span>1</span></span></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msup><mi>y</mi><mo mathvariant="normal">′</mo></msup><mo stretchy="false">(</mo><mi>t</mi><mo>=</mo><mn>0</mn><mo stretchy="false">)</mo><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">y^\prime(t=0) = 0</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span>y</span><span><span><span><span><span><span></span><span><span>′</span></span></span></span></span></span></span></span><span>(</span><span>t</span><span></span><span>=</span><span></span></span><span><span></span><span>0</span><span>)</span><span></span><span>=</span><span></span></span><span><span></span><span>0</span></span></span></span>; back to the spring analogy, this would mean starting the system with the spring extended by 1 unit, and releasing it delicately.</p>
<p>This system admits two types of solutions: when <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ξ</mi><mn>0</mn></msub><mo mathvariant="normal">≠</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\xi_0 \neq 1</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span>ξ</span><span><span><span><span><span><span></span><span><span>0</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span></span><span><span><span><span><span><span></span><span><span><span></span></span></span><span></span></span></span></span></span><span>=</span></span><span></span></span><span><span></span><span>1</span></span></span></span>, the solution takes the form <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>c</mi><mn>0</mn></msub><msup><mi>e</mi><mrow><mo>−</mo><msub><mi>ω</mi><mo>+</mo></msub><mi>t</mi></mrow></msup><mo>+</mo><msub><mi>c</mi><mn>1</mn></msub><msup><mi>e</mi><mrow><mo>−</mo><msub><mi>ω</mi><mo>−</mo></msub><mi>t</mi></mrow></msup></mrow><annotation encoding="application/x-tex">c_0 e^{-\omega_+ t} + c_1 e^{-\omega_- t}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span>c</span><span><span><span><span><span><span></span><span><span>0</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span><span>e</span><span><span><span><span><span><span></span><span><span><span>−</span><span><span>ω</span><span><span><span><span><span><span></span><span><span>+</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>t</span></span></span></span></span></span></span></span></span><span></span><span>+</span><span></span></span><span><span></span><span><span>c</span><span><span><span><span><span><span></span><span><span>1</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span><span>e</span><span><span><span><span><span><span></span><span><span><span>−</span><span><span>ω</span><span><span><span><span><span><span></span><span><span>−</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>t</span></span></span></span></span></span></span></span></span></span></span></span> where <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ω</mi><mo>±</mo></msub></mrow><annotation encoding="application/x-tex">\omega_\pm</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span>ω</span><span><span><span><span><span><span></span><span><span>±</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span> are the roots of the associated second order polynomial:</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi>ω</mi><mo>±</mo></msub><mo>≡</mo><mi>ξ</mi><mo>±</mo><mi>ω</mi><mo>=</mo><mfrac><mrow><msub><mi>ξ</mi><mn>0</mn></msub><msub><mi>ω</mi><mn>0</mn></msub></mrow><mn>2</mn></mfrac><mo>±</mo><mfrac><mrow><msub><mi>ω</mi><mn>0</mn></msub><msqrt><mrow><msubsup><mi>ξ</mi><mn>0</mn><mn>2</mn></msubsup><mo>−</mo><mn>1</mn></mrow></msqrt></mrow><mn>2</mn></mfrac><mtext> </mtext><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">    \omega_\pm \equiv \xi \pm \omega = \frac{\xi_0 \omega_0}{2}  \pm \frac{\omega_0 \sqrt{\xi_0^2 - 1}}{2}~.</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span>ω</span><span><span><span><span><span><span></span><span><span>±</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span></span><span>≡</span><span></span></span><span><span></span><span>ξ</span><span></span><span>±</span><span></span></span><span><span></span><span>ω</span><span></span><span>=</span><span></span></span><span><span></span><span><span></span><span><span><span><span><span><span></span><span><span>2</span></span></span><span><span></span><span></span></span><span><span></span><span><span><span>ξ</span><span><span><span><span><span><span></span><span><span>0</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span><span>ω</span><span><span><span><span><span><span></span><span><span>0</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span></span></span><span></span><span>±</span><span></span></span><span><span></span><span><span></span><span><span><span><span><span><span></span><span><span>2</span></span></span><span><span></span><span></span></span><span><span></span><span><span><span>ω</span><span><span><span><span><span><span></span><span><span>0</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span><span><span><span><span><span></span><span><span><span>ξ</span><span><span><span><span><span><span></span><span><span>0</span></span></span><span><span></span><span><span>2</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span></span><span>−</span><span></span><span>1</span></span></span><span><span></span><span><svg xmlns="http://www.w3.org/2000/svg" width="400em" height="1.28em" viewBox="0 0 400000 1296" preserveAspectRatio="xMinYMin slice"><path d="M263,681c0.7,0,18,39.7,52,119
c34,79.3,68.167,158.7,102.5,238c34.3,79.3,51.8,119.3,52.5,120
c340,-704.7,510.7,-1060.3,512,-1067
l0 -0
c4.7,-7.3,11,-11,19,-11
H40000v40H1012.3
s-271.3,567,-271.3,567c-38.7,80.7,-84,175,-136,283c-52,108,-89.167,185.3,-111.5,232
c-22.3,46.7,-33.8,70.3,-34.5,71c-4.7,4.7,-12.3,7,-23,7s-12,-1,-12,-1
s-109,-253,-109,-253c-72.7,-168,-109.3,-252,-110,-252c-10.7,8,-22,16.7,-34,26
c-22,17.3,-33.3,26,-34,26s-26,-26,-26,-26s76,-59,76,-59s76,-60,76,-60z
M1001 80h400000v40h-400000z"></path></svg></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span></span></span><span> </span><span>.</span></span></span></span></span>
<p>For my choice of initial values, the solution simplifies to</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>y</mi><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo><mo>=</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>ξ</mi><mi>t</mi></mrow></msup><mo fence="true" stretchy="true" minsize="1.8em" maxsize="1.8em">[</mo><msub><mi>y</mi><mn>0</mn></msub><mi>cos</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>ω</mi><mi>t</mi><mo stretchy="false">)</mo><mo>+</mo><mfrac><mrow><msub><mi>y</mi><mn>1</mn></msub><mo>+</mo><mi>ξ</mi><msub><mi>y</mi><mn>0</mn></msub></mrow><mi>ω</mi></mfrac><mi>sin</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>ω</mi><mi>t</mi><mo stretchy="false">)</mo><mo fence="true" stretchy="true" minsize="1.8em" maxsize="1.8em">]</mo><mtext> </mtext><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">    y(t) = e^{- \xi t} \Bigl[ y_0 \cos(\omega t) + \frac{y_1 + \xi y_0}{\omega} \sin(\omega t) \Bigr]~.</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>y</span><span>(</span><span>t</span><span>)</span><span></span><span>=</span><span></span></span><span><span></span><span><span>e</span><span><span><span><span><span><span></span><span><span><span>−</span><span>ξ</span><span>t</span></span></span></span></span></span></span></span></span><span><span>[</span></span><span><span>y</span><span><span><span><span><span><span></span><span><span>0</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span></span><span>cos</span><span>(</span><span>ω</span><span>t</span><span>)</span><span></span><span>+</span><span></span></span><span><span></span><span><span></span><span><span><span><span><span><span></span><span><span>ω</span></span></span><span><span></span><span></span></span><span><span></span><span><span><span>y</span><span><span><span><span><span><span></span><span><span>1</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span></span><span>+</span><span></span><span>ξ</span><span><span>y</span><span><span><span><span><span><span></span><span><span>0</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span></span></span><span></span><span>sin</span><span>(</span><span>ω</span><span>t</span><span>)</span><span><span>]</span></span><span> </span><span>.</span></span></span></span></span>
<p>Note that for <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ξ</mi><mo>&gt;</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\xi &gt; 1</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>ξ</span><span></span><span>&gt;</span><span></span></span><span><span></span><span>1</span></span></span></span>, <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>ω</mi></mrow><annotation encoding="application/x-tex">\omega</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>ω</span></span></span></span> becomes purely imaginary and the cosine and sine turn into their hyperbolic counterparts. There is another case to consider: when <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ξ</mi><mn>0</mn></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\xi_0 = 1</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span>ξ</span><span><span><span><span><span><span></span><span><span>0</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span></span><span>=</span><span></span></span><span><span></span><span>1</span></span></span></span>, the two branches are degenerate and the general (or <em>critical</em>) solution becomes</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>y</mi><mo stretchy="false">(</mo><mi>t</mi><mo stretchy="false">)</mo><mo>=</mo><msup><mi>e</mi><mrow><mo>−</mo><mi>ξ</mi><mi>t</mi></mrow></msup><mo fence="true" stretchy="true" minsize="1.8em" maxsize="1.8em">[</mo><msub><mi>y</mi><mn>0</mn></msub><mo>+</mo><mo stretchy="false">(</mo><msub><mi>y</mi><mn>1</mn></msub><mo>+</mo><mi>ξ</mi><msub><mi>y</mi><mn>0</mn></msub><mo stretchy="false">)</mo><mi>t</mi><mo fence="true" stretchy="true" minsize="1.8em" maxsize="1.8em">]</mo><mtext> </mtext><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">    y(t) = e^{- \xi t} \Bigl[ y_0 + (y_1 + \xi y_0) t \Bigr]~.</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>y</span><span>(</span><span>t</span><span>)</span><span></span><span>=</span><span></span></span><span><span></span><span><span>e</span><span><span><span><span><span><span></span><span><span><span>−</span><span>ξ</span><span>t</span></span></span></span></span></span></span></span></span><span><span>[</span></span><span><span>y</span><span><span><span><span><span><span></span><span><span>0</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span></span><span>+</span><span></span></span><span><span></span><span>(</span><span><span>y</span><span><span><span><span><span><span></span><span><span>1</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span></span><span>+</span><span></span></span><span><span></span><span>ξ</span><span><span>y</span><span><span><span><span><span><span></span><span><span>0</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>)</span><span>t</span><span><span>]</span></span><span> </span><span>.</span></span></span></span></span>
</section><section data-heading-rank="4" aria-labelledby="setup"><h4 id="setup">Setup</h4>
<p>Now that we’ve clarified the math a bit, let’s move to solving the problem. To start with, initialize your virtual environment with whatever tool you prefer<sup><a href="#user-content-fn-uv" id="user-content-fnref-uv" data-footnote-ref="" aria-describedby="footnote-label">6</a></sup> and with the following dependencies:</p>
<astro-island uid="1P8OUx" component-url="/_astro/EnhancedPreElement.DVSGoltY.js" component-export="default" renderer-url="/_astro/client.CQQZjN3o.js" props="{&#34;class&#34;:[0,&#34;astro-code astro-code-themes github-light github-dark&#34;],&#34;style&#34;:[0,{&#34;backgroundColor&#34;:[0,&#34;#fff&#34;],&#34;--shiki-dark-bg&#34;:[0,&#34;#24292e&#34;],&#34;color&#34;:[0,&#34;#24292e&#34;],&#34;--shiki-dark&#34;:[0,&#34;#e1e4e8&#34;],&#34;overflowX&#34;:[0,&#34;auto&#34;],&#34;whiteSpace&#34;:[0,&#34;pre-wrap&#34;],&#34;wordWrap&#34;:[0,&#34;break-word&#34;]}],&#34;tabindex&#34;:[0,&#34;0&#34;],&#34;data-language&#34;:[0,&#34;toml&#34;]}" ssr="" client="load" opts="{&#34;name&#34;:&#34;EnhancedPreElement&#34;,&#34;value&#34;:true}" await-children=""><div><pre tabindex="0" data-language="toml"><astro-slot><code><span><span># pyproject.toml</span></span>
<span><span>[</span><span>project</span><span>]</span></span>
<span><span>requires-python = </span><span>&#34;==3.12&#34;</span></span>
<span><span>dependencies = [</span></span>
<span><span>    &#34;deepxde==1.13.1&#34;</span><span>,</span></span>
<span><span>    &#34;torch==2.6.0&#34;</span><span>,</span></span>
<span><span>]</span></span></code></astro-slot></pre></div><!--astro:end--></astro-island>
<p>First we are going to define a class specifying the details of the harmonic oscillator system:</p>
<astro-island uid="H64aV" component-url="/_astro/EnhancedPreElement.DVSGoltY.js" component-export="default" renderer-url="/_astro/client.CQQZjN3o.js" props="{&#34;class&#34;:[0,&#34;astro-code astro-code-themes github-light github-dark&#34;],&#34;style&#34;:[0,{&#34;backgroundColor&#34;:[0,&#34;#fff&#34;],&#34;--shiki-dark-bg&#34;:[0,&#34;#24292e&#34;],&#34;color&#34;:[0,&#34;#24292e&#34;],&#34;--shiki-dark&#34;:[0,&#34;#e1e4e8&#34;],&#34;overflowX&#34;:[0,&#34;auto&#34;],&#34;whiteSpace&#34;:[0,&#34;pre-wrap&#34;],&#34;wordWrap&#34;:[0,&#34;break-word&#34;]}],&#34;tabindex&#34;:[0,&#34;0&#34;],&#34;data-language&#34;:[0,&#34;python&#34;]}" ssr="" client="load" opts="{&#34;name&#34;:&#34;EnhancedPreElement&#34;,&#34;value&#34;:true}" await-children=""><div><pre tabindex="0" data-language="python"><astro-slot><code><span><span>class</span><span> HarmonicOscillator0D</span><span>:</span></span>
<span><span>    &#34;&#34;&#34;Class modeling the harmonic oscillator in 0+1 dimensions. The ODE is:</span></span>
<span><span>    $$</span></span>
<span><span>        \\</span><span>frac{</span><span>\\</span><span>partial^2 y}{</span><span>\\</span><span>partial t^2} + </span><span>\\</span><span>xi_0 * </span><span>\\</span><span>omega_0 * </span><span>\\</span><span>frac{</span><span>\\</span><span>partial y}{</span><span>\\</span><span>partial t} + </span><span>\\</span><span>frac{</span><span>\\</span><span>omega_0^2}{4} y = 0</span></span>
<span><span>    $$</span></span>
<span><span>    and with initial conditions $y(t = 0) = y_0, y^</span><span>\\</span><span>prime(t = 0) = y_1$.</span></span>
<span></span>
<span></span>
<span><span>    Args:</span></span>
<span><span>        omega0 (float): Intrinsic frequency of the system.</span></span>
<span><span>        xi0 (float): Fluid friction term.</span></span>
<span><span>        y0 (float): Initial value of the solution.</span></span>
<span><span>        y1 (float): Initial derivative of the solution.</span></span>
<span><span>    &#34;&#34;&#34;</span></span>
<span></span>
<span><span>    __slots__</span><span> =</span><span> (</span><span>&#34;xi0&#34;</span><span>, </span><span>&#34;omega0&#34;</span><span>, </span><span>&#34;xi&#34;</span><span>, </span><span>&#34;omega&#34;</span><span>, </span><span>&#34;y0&#34;</span><span>, </span><span>&#34;y1&#34;</span><span>)</span></span>
<span></span>
<span><span>    def</span><span> __init__</span><span>(self, xi0: </span><span>float</span><span>, omega0: </span><span>float</span><span>, y0: </span><span>float</span><span>, y1: </span><span>float</span><span>):</span></span>
<span><span>        # ODE parameters</span></span>
<span><span>        self</span><span>.xi0 </span><span>=</span><span> xi0</span></span>
<span><span>        self</span><span>.omega0 </span><span>=</span><span> omega0</span></span>
<span><span>        self</span><span>.xi </span><span>=</span><span> xi0 </span><span>*</span><span> omega0 </span><span>/</span><span> 2</span></span>
<span><span>        self</span><span>.omega </span><span>=</span><span> self</span><span>.omega0 </span><span>*</span><span> np.sqrt(np.abs(np.power(</span><span>self</span><span>.xi0, </span><span>2</span><span>) </span><span>-</span><span> 1</span><span>)) </span><span>/</span><span> 2</span></span>
<span></span>
<span><span>        # Initial value condition</span></span>
<span><span>        self</span><span>.y0 </span><span>=</span><span> y0</span></span>
<span><span>        self</span><span>.y1 </span><span>=</span><span> y1</span></span>
<span></span>
<span></span>
<span><span>    def</span><span> equation</span><span>(self, x: torch.Tensor, y: torch.Tensor) -&gt; torch.Tensor:</span></span>
<span><span>        &#34;&#34;&#34;Defines the ODE.</span></span>
<span></span>
<span><span>        Args:</span></span>
<span><span>            x (torch.Tensor): Input of the neural network.</span></span>
<span><span>            y (torch.Tensor): Output of the neural network.</span></span>
<span></span>
<span><span>        Returns:</span></span>
<span><span>            (torch.Tensor): Residual of the differential equation.</span></span>
<span></span>
<span><span>        &#34;&#34;&#34;</span></span>
<span><span>        pass</span></span>
<span></span>
<span><span>    def</span><span> initial_value</span><span>(self, x: torch.Tensor) -&gt; torch.Tensor:</span></span>
<span><span>        &#34;&#34;&#34;Defines the initial value for the differential equation.</span></span>
<span></span>
<span><span>        Args:</span></span>
<span><span>            x (torch.Tensor): Input of the neural network.</span></span>
<span></span>
<span><span>        Returns:</span></span>
<span><span>            (torch.Tensor): Value at the boundary for the initial condition.</span></span>
<span><span>        &#34;&#34;&#34;</span></span>
<span><span>        pass</span></span>
<span></span>
<span><span>    def</span><span> initial_value_derivative</span><span>(</span></span>
<span><span>        self, x: torch.Tensor, y: torch.Tensor, X: np.ndarray</span></span>
<span><span>    ) -&gt; torch.Tensor:</span></span>
<span><span>        &#34;&#34;&#34;Defines the initial value of the derivative for the differential equation.</span></span>
<span></span>
<span><span>        Args:</span></span>
<span><span>            x (torch.Tensor): Input of the neural network.</span></span>
<span><span>            y (torch.Tensor): Output of the neural network.</span></span>
<span><span>            X (np.ndarray): Numpy array of the inputs.</span></span>
<span></span>
<span><span>        Returns:</span></span>
<span><span>            (torch.Tensor): Residual of the initial value condition for the derivative.</span></span>
<span><span>        &#34;&#34;&#34;</span></span>
<span><span>        pass</span></span>
<span></span>
<span><span>    def</span><span> exact_solution</span><span>(self, x: np.ndarray) -&gt; np.ndarray:</span></span>
<span><span>        &#34;&#34;&#34;Defines the ground truth solution for the system.</span></span>
<span></span>
<span><span>        Args:</span></span>
<span><span>            x (np.ndarray): Points on which to evaluate the solution.</span></span>
<span></span>
<span><span>        Returns:</span></span>
<span><span>            (np.ndarray): Value of the solution on the points.</span></span>
<span><span>        &#34;&#34;&#34;</span></span>
<span></span>
<span><span>        pass</span></span></code></astro-slot></pre></div><!--astro:end--></astro-island>
<p>For this example, I will detail each function step by step before moving on the code to solve the problem. The method <code>exact_solution</code> encodes the ground truth, the analytical solution I derived previously, and I will use this function to test my neural network architecture:</p>
<astro-island uid="ZC0Vnn" component-url="/_astro/EnhancedPreElement.DVSGoltY.js" component-export="default" renderer-url="/_astro/client.CQQZjN3o.js" props="{&#34;class&#34;:[0,&#34;astro-code astro-code-themes github-light github-dark&#34;],&#34;style&#34;:[0,{&#34;backgroundColor&#34;:[0,&#34;#fff&#34;],&#34;--shiki-dark-bg&#34;:[0,&#34;#24292e&#34;],&#34;color&#34;:[0,&#34;#24292e&#34;],&#34;--shiki-dark&#34;:[0,&#34;#e1e4e8&#34;],&#34;overflowX&#34;:[0,&#34;auto&#34;],&#34;whiteSpace&#34;:[0,&#34;pre-wrap&#34;],&#34;wordWrap&#34;:[0,&#34;break-word&#34;]}],&#34;tabindex&#34;:[0,&#34;0&#34;],&#34;data-language&#34;:[0,&#34;python&#34;]}" ssr="" client="load" opts="{&#34;name&#34;:&#34;EnhancedPreElement&#34;,&#34;value&#34;:true}" await-children=""><div><pre tabindex="0" data-language="python"><astro-slot><code><span><span>def</span><span> exact_solution</span><span>(self, x: np.ndarray) -&gt; np.ndarray:</span></span>
<span><span>    # Damping term</span></span>
<span><span>    exp_term </span><span>=</span><span> np.exp(</span><span>-</span><span>self</span><span>.xi </span><span>*</span><span> x)</span></span>
<span><span>    # Critical case</span></span>
<span><span>    if</span><span> self</span><span>.xi0 </span><span>==</span><span> 1</span><span>:</span></span>
<span><span>        c0 </span><span>=</span><span> self</span><span>.y0</span></span>
<span><span>        c1 </span><span>=</span><span> self</span><span>.y1 </span><span>+</span><span> self</span><span>.xi </span><span>*</span><span> self</span><span>.y0</span></span>
<span><span>        return</span><span> exp_term </span><span>*</span><span> (c0 </span><span>+</span><span> c1 </span><span>*</span><span> x)</span></span>
<span><span>    else</span><span>:</span></span>
<span><span>        c0 </span><span>=</span><span> self</span><span>.y0</span></span>
<span><span>        c1 </span><span>=</span><span> (</span><span>self</span><span>.y1 </span><span>+</span><span> self</span><span>.xi </span><span>*</span><span> self</span><span>.y0) </span><span>/</span><span> self</span><span>.omega</span></span>
<span><span>        # Underdamped case</span></span>
<span><span>        if</span><span> self</span><span>.xi0 </span><span>&lt;</span><span> 1</span><span>:</span></span>
<span><span>            return</span><span> exp_term </span><span>*</span><span> (</span></span>
<span><span>                c0 </span><span>*</span><span> np.cos(</span><span>self</span><span>.omega </span><span>*</span><span> x) </span><span>+</span><span> c1 </span><span>*</span><span> np.sin(</span><span>self</span><span>.omega </span><span>*</span><span> x)</span></span>
<span><span>            )</span></span>
<span><span>        # Overdamped case</span></span>
<span><span>        else</span><span>:</span></span>
<span><span>            return</span><span> exp_term </span><span>*</span><span> (</span></span>
<span><span>                c0 </span><span>*</span><span> np.cosh(</span><span>self</span><span>.omega </span><span>*</span><span> x) </span><span>+</span><span> c1 </span><span>*</span><span> np.sinh(</span><span>self</span><span>.omega </span><span>*</span><span> x)</span></span>
<span><span>            )</span></span></code></astro-slot></pre></div><!--astro:end--></astro-island>
<p>The class also features two methods which will be used to fix the two initial value condition. By now you might have already noticed that the two methods have different signatures and impose each initial value condition differently. This comes down to how DeepXDE will impose the initial value condition.<sup><a href="#user-content-fn-conditions" id="user-content-fnref-conditions" data-footnote-ref="" aria-describedby="footnote-label">7</a></sup> For the Dirichlet condition, you just need to return the value at the <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">t = 0</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>t</span><span></span><span>=</span><span></span></span><span><span></span><span>0</span></span></span></span> slice,</p>
<astro-island uid="Z125qqc" component-url="/_astro/EnhancedPreElement.DVSGoltY.js" component-export="default" renderer-url="/_astro/client.CQQZjN3o.js" props="{&#34;class&#34;:[0,&#34;astro-code astro-code-themes github-light github-dark&#34;],&#34;style&#34;:[0,{&#34;backgroundColor&#34;:[0,&#34;#fff&#34;],&#34;--shiki-dark-bg&#34;:[0,&#34;#24292e&#34;],&#34;color&#34;:[0,&#34;#24292e&#34;],&#34;--shiki-dark&#34;:[0,&#34;#e1e4e8&#34;],&#34;overflowX&#34;:[0,&#34;auto&#34;],&#34;whiteSpace&#34;:[0,&#34;pre-wrap&#34;],&#34;wordWrap&#34;:[0,&#34;break-word&#34;]}],&#34;tabindex&#34;:[0,&#34;0&#34;],&#34;data-language&#34;:[0,&#34;python&#34;]}" ssr="" client="load" opts="{&#34;name&#34;:&#34;EnhancedPreElement&#34;,&#34;value&#34;:true}" await-children=""><div><pre tabindex="0" data-language="python"><astro-slot><code><span><span>def</span><span> initial_value</span><span>(self, x: torch.Tensor) -&gt; torch.Tensor:</span></span>
<span><span>    return</span><span> y0</span></span></code></astro-slot></pre></div><!--astro:end--></astro-island>
<p>while for the Neumann condition, the function returns the difference between the derivative and the value we are aiming for</p>
<astro-island uid="Z1xKQaG" component-url="/_astro/EnhancedPreElement.DVSGoltY.js" component-export="default" renderer-url="/_astro/client.CQQZjN3o.js" props="{&#34;class&#34;:[0,&#34;astro-code astro-code-themes github-light github-dark&#34;],&#34;style&#34;:[0,{&#34;backgroundColor&#34;:[0,&#34;#fff&#34;],&#34;--shiki-dark-bg&#34;:[0,&#34;#24292e&#34;],&#34;color&#34;:[0,&#34;#24292e&#34;],&#34;--shiki-dark&#34;:[0,&#34;#e1e4e8&#34;],&#34;overflowX&#34;:[0,&#34;auto&#34;],&#34;whiteSpace&#34;:[0,&#34;pre-wrap&#34;],&#34;wordWrap&#34;:[0,&#34;break-word&#34;]}],&#34;tabindex&#34;:[0,&#34;0&#34;],&#34;data-language&#34;:[0,&#34;python&#34;]}" ssr="" client="load" opts="{&#34;name&#34;:&#34;EnhancedPreElement&#34;,&#34;value&#34;:true}" await-children=""><div><pre tabindex="0" data-language="python"><astro-slot><code><span><span>def</span><span> initial_value_derivative</span><span>(</span></span>
<span><span>    self, x: torch.Tensor, y: torch.Tensor, X: np.ndarray</span></span>
<span><span>) -&gt; torch.Tensor:</span></span>
<span><span>    dy_dt </span><span>=</span><span> cast(torch.Tensor, dde.grad.jacobian(y, x, </span><span>i</span><span>=</span><span>0</span><span>, </span><span>j</span><span>=</span><span>0</span><span>))</span></span>
<span><span>    return</span><span> dy_dt </span><span>-</span><span> self</span><span>.y1</span></span></code></astro-slot></pre></div><!--astro:end--></astro-island>
<p>Finally, the equation of motion inside the domain is imposed via the <code>equation</code> method</p>
<astro-island uid="1ay524" component-url="/_astro/EnhancedPreElement.DVSGoltY.js" component-export="default" renderer-url="/_astro/client.CQQZjN3o.js" props="{&#34;class&#34;:[0,&#34;astro-code astro-code-themes github-light github-dark&#34;],&#34;style&#34;:[0,{&#34;backgroundColor&#34;:[0,&#34;#fff&#34;],&#34;--shiki-dark-bg&#34;:[0,&#34;#24292e&#34;],&#34;color&#34;:[0,&#34;#24292e&#34;],&#34;--shiki-dark&#34;:[0,&#34;#e1e4e8&#34;],&#34;overflowX&#34;:[0,&#34;auto&#34;],&#34;whiteSpace&#34;:[0,&#34;pre-wrap&#34;],&#34;wordWrap&#34;:[0,&#34;break-word&#34;]}],&#34;tabindex&#34;:[0,&#34;0&#34;],&#34;data-language&#34;:[0,&#34;python&#34;]}" ssr="" client="load" opts="{&#34;name&#34;:&#34;EnhancedPreElement&#34;,&#34;value&#34;:true}" await-children=""><div><pre tabindex="0" data-language="python"><astro-slot><code><span><span>def</span><span> equation</span><span>(self, x: torch.Tensor, y: torch.Tensor) -&gt; torch.Tensor:</span></span>
<span><span>    dy_dt </span><span>=</span><span> cast(torch.Tensor, dde.grad.jacobian(y, x, </span><span>i</span><span>=</span><span>0</span><span>, </span><span>j</span><span>=</span><span>0</span><span>))</span></span>
<span><span>    dy2_dt2 </span><span>=</span><span> cast(torch.Tensor, dde.grad.hessian(y, x, </span><span>i</span><span>=</span><span>0</span><span>, </span><span>j</span><span>=</span><span>0</span><span>))</span></span>
<span><span>    ode </span><span>=</span><span> dy2_dt2 </span><span>+</span><span> self</span><span>.xi0 </span><span>*</span><span> self</span><span>.omega0 </span><span>*</span><span> dy_dt </span><span>+</span><span> (</span><span>self</span><span>.omega0</span><span>**</span><span>2</span><span> /</span><span> 4</span><span>) </span><span>*</span><span> y</span></span>
<span><span>    return</span><span> ode</span></span></code></astro-slot></pre></div><!--astro:end--></astro-island>
<p>One of the greatest perks of the DeepXDE library is that it caches the gradient calculations. The interface to calculate the Jacobian and Hessian components is therefore simple yet performant!</p>
<p>Now we can use this class to solve the problem for various values of the parameters. Let’s start by setting up some constants</p>
<astro-island uid="1AibpF" component-url="/_astro/EnhancedPreElement.DVSGoltY.js" component-export="default" renderer-url="/_astro/client.CQQZjN3o.js" props="{&#34;class&#34;:[0,&#34;astro-code astro-code-themes github-light github-dark&#34;],&#34;style&#34;:[0,{&#34;backgroundColor&#34;:[0,&#34;#fff&#34;],&#34;--shiki-dark-bg&#34;:[0,&#34;#24292e&#34;],&#34;color&#34;:[0,&#34;#24292e&#34;],&#34;--shiki-dark&#34;:[0,&#34;#e1e4e8&#34;],&#34;overflowX&#34;:[0,&#34;auto&#34;],&#34;whiteSpace&#34;:[0,&#34;pre-wrap&#34;],&#34;wordWrap&#34;:[0,&#34;break-word&#34;]}],&#34;tabindex&#34;:[0,&#34;0&#34;],&#34;data-language&#34;:[0,&#34;python&#34;]}" ssr="" client="load" opts="{&#34;name&#34;:&#34;EnhancedPreElement&#34;,&#34;value&#34;:true}" await-children=""><div><pre tabindex="0" data-language="python"><astro-slot><code><span><span>xi0 </span><span>=</span><span> 0.1</span></span>
<span><span>omega0 </span><span>=</span><span> 2</span><span> *</span><span> np.pi </span><span>*</span><span> 5</span></span>
<span><span>y0 </span><span>=</span><span> 1</span></span>
<span><span>y1 </span><span>=</span><span> 0</span></span>
<span></span>
<span><span># Neural network parameters</span></span>
<span><span>input_size </span><span>=</span><span> [</span><span>1</span><span>] </span></span>
<span><span>output_size </span><span>=</span><span> [</span><span>1</span><span>] </span></span>
<span><span>layers_sizes </span><span>=</span><span> input_size </span><span>+</span><span> [</span><span>64</span><span>, </span><span>128</span><span>, </span><span>64</span><span>] </span><span>+</span><span> output_size</span></span>
<span><span>activation </span><span>=</span><span> &#34;tanh&#34;</span></span>
<span><span>initializer </span><span>=</span><span> &#34;Glorot normal&#34;</span></span>
<span></span>
<span><span># Training parameters</span></span>
<span><span>optimizer_kw </span><span>=</span><span> dict</span><span>(</span></span>
<span><span>    lr</span><span>=</span><span>0.001</span><span>,</span></span>
<span><span>    metrics</span><span>=</span><span>[</span><span>&#34;l2 relative error&#34;</span><span>],</span></span>
<span><span>    loss_weights</span><span>=</span><span>[</span><span>0.001</span><span>, </span><span>1</span><span>, </span><span>0.5</span><span>],</span></span>
<span><span>)</span></span>
<span><span>n_iterations </span><span>=</span><span> 10_000</span></span>
<span></span>
<span><span># Mesh parameters</span></span>
<span><span>n_training_inside </span><span>=</span><span> 64</span></span>
<span><span>n_training_bdy </span><span>=</span><span> 2</span></span>
<span><span>n_test </span><span>=</span><span> 500</span></span></code></astro-slot></pre></div><!--astro:end--></astro-island>
<p>Most of these are easy to understand from their names: the neural network’s architecture will be composed of dense layers (the number of units is specified by <code>layers_sizes</code> and will be initialized using the Xavier normal initializer) and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>tanh</mi><mo>⁡</mo></mrow><annotation encoding="application/x-tex">\tanh</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>tanh</span></span></span></span> activation functions. The network will be trained over 10,000 iterations, using 64 random points inside the domain and testing the output against the exact solution on 500 points. An important hyperparameter to tweak for this kind of model is the list of weights <code>loss_weights</code> of the loss function terms (interior ODE loss, Dirichlet initial value loss, Neumann initial value loss). When training the model, if you see that one of these losses stagnate compared to others, increasing its relative weight is a great way to boost the learning process.</p>
<p>When using DeepXDE to solve a problem like this one, you must then follow 4 different steps:</p>
<ol>
<li>define the domain on which to solve the problem,</li>
<li>define the boundary or initial value conditions (and associated boundary slices selectors),</li>
<li>generate the training and testing data,</li>
<li>initialize and train the model.</li>
</ol>
<p>For this problem, the code for these steps is</p>
<astro-island uid="ZiMPOM" component-url="/_astro/EnhancedPreElement.DVSGoltY.js" component-export="default" renderer-url="/_astro/client.CQQZjN3o.js" props="{&#34;class&#34;:[0,&#34;astro-code astro-code-themes github-light github-dark&#34;],&#34;style&#34;:[0,{&#34;backgroundColor&#34;:[0,&#34;#fff&#34;],&#34;--shiki-dark-bg&#34;:[0,&#34;#24292e&#34;],&#34;color&#34;:[0,&#34;#24292e&#34;],&#34;--shiki-dark&#34;:[0,&#34;#e1e4e8&#34;],&#34;overflowX&#34;:[0,&#34;auto&#34;],&#34;whiteSpace&#34;:[0,&#34;pre-wrap&#34;],&#34;wordWrap&#34;:[0,&#34;break-word&#34;]}],&#34;tabindex&#34;:[0,&#34;0&#34;],&#34;data-language&#34;:[0,&#34;python&#34;]}" ssr="" client="load" opts="{&#34;name&#34;:&#34;EnhancedPreElement&#34;,&#34;value&#34;:true}" await-children=""><div><pre tabindex="0" data-language="python"><astro-slot><code><span><span># 1. Define the domain</span></span>
<span><span>geom </span><span>=</span><span> dde.geometry.TimeDomain(</span><span>0</span><span>, </span><span>1</span><span>)</span></span>
<span></span>
<span><span># 2.0 Create the harmonic oscillator object</span></span>
<span><span>ho </span><span>=</span><span> HarmonicOscillator0D(</span><span>xi0</span><span>=</span><span>xi0, </span><span>omega0</span><span>=</span><span>omega0, </span><span>y0</span><span>=</span><span>y0, </span><span>y1</span><span>=</span><span>y1)</span></span>
<span><span># 2.1 Define the t=0 slice boundary</span></span>
<span><span>def</span><span> boundary_t0</span><span>(x: torch.Tensor, on_boundary: </span><span>bool</span><span>) -&gt; </span><span>bool</span><span>:</span></span>
<span><span>    return</span><span> on_boundary </span><span>and</span><span> dde.utils.isclose(x[</span><span>0</span><span>], </span><span>0</span><span>)</span></span>
<span><span># 2.2 Define the initial value conditions</span></span>
<span><span>ic_value </span><span>=</span><span> dde.icbc.IC(geom, ho.initial_value, </span><span>lambda</span><span> _, on_initial: on_initial) </span><span># The on_initial boolean defines the t = 0 slice.</span></span>
<span><span>ic_derivative_value </span><span>=</span><span> dde.icbc.OperatorBC(</span></span>
<span><span>    geom, ho.initial_value_derivative, boundary_t0</span></span>
<span><span>)</span></span>
<span></span>
<span><span># 3. Generate the training and testing data</span></span>
<span><span>data </span><span>=</span><span> dde.data.TimePDE(</span></span>
<span><span>    geom,</span></span>
<span><span>    ho.equation,</span></span>
<span><span>    [ic_value, ic_derivative_value],</span></span>
<span><span>    num_domain</span><span>=</span><span>n_training_inside,</span></span>
<span><span>    num_boundary</span><span>=</span><span>n_training_bdy,</span></span>
<span><span>    solution</span><span>=</span><span>ho.exact_solution,</span></span>
<span><span>    num_test</span><span>=</span><span>n_test,</span></span>
<span><span>)</span></span>
<span></span>
<span><span># 4.1 Initialize the model</span></span>
<span><span>neural_net </span><span>=</span><span> dde.nn.FNN(layers_sizes, activation, initializer)</span></span>
<span><span>model </span><span>=</span><span> dde.Model(data, neural_net)</span></span>
<span><span>model.compile(</span><span>&#34;adam&#34;</span><span>, </span><span>**</span><span>optimizer_kw)</span></span>
<span><span># 4.2 Train the model</span></span>
<span><span>losshistory, train_state </span><span>=</span><span> model.train(</span><span>iterations</span><span>=</span><span>n_iterations)</span></span></code></astro-slot></pre></div><!--astro:end--></astro-island>
</section><section data-heading-rank="4" aria-labelledby="setup-1"><h4 id="setup-1">Setup</h4>
<p>Now let’s look at some results! I ran the above code for multiple values of <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ξ</mi><mn>0</mn></msub></mrow><annotation encoding="application/x-tex">\xi_0</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span>ξ</span><span><span><span><span><span><span></span><span><span>0</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span></span></span></span>. First, the simple case without friction (<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ξ</mi><mn>0</mn></msub><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">\xi_0 = 0</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span>ξ</span><span><span><span><span><span><span></span><span><span>0</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span></span><span>=</span><span></span></span><span><span></span><span>0</span></span></span></span>) where the mass keeps oscillating back and forth.
When you tune the friction coefficient up, the oscillations start to weaken with time (this is called the <em>underdamped</em> regime).</p>
<p><img src="https://nchagnet.pages.dev/assets/blog/physics-informed-neural-networks/harmonic_oscillator_frictionless_xi0.png" alt="Frictionless solution to the harmonic oscillator ODE"/><img src="https://nchagnet.pages.dev/assets/blog/physics-informed-neural-networks/harmonic_oscillator_underdamped_xi0.png" alt="Underdamped solution to the harmonic oscillator ODE"/></p>
<p>On the other end of the spectrum, when the friction coefficient is large, the mass returns to its stable position exponentially instead of oscillating (this is called the <em>overdamped</em> regime). Interestingly, this movement <em>slows down</em> as the friction term increases. In between, when <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><msub><mi>ξ</mi><mn>0</mn></msub><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">\xi_0 = 1</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span>ξ</span><span><span><span><span><span><span></span><span><span>0</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span></span><span>=</span><span></span></span><span><span></span><span>1</span></span></span></span>, the system reaches a critical point (the degenerate solution derived above). This point is the fastest the system can return to its equilibrium without oscillating:</p>
<p><img src="https://nchagnet.pages.dev/assets/blog/physics-informed-neural-networks/harmonic_oscillator_critical_xi0.png" alt="Critical solution to the harmonic oscillator ODE"/><img src="https://nchagnet.pages.dev/assets/blog/physics-informed-neural-networks/harmonic_oscillator_overdamped_xi0.png" alt="Overdamped solution to the harmonic oscillator ODE"/></p>
<p>In all these examples, the neural network learnt to approximate the solution to the equations with very few training points, and can then output an accurate solution anywhere in the domain.</p>
</section></section><section data-heading-rank="3" aria-labelledby="heat-equation"><h3 id="heat-equation">Heat equation</h3>
<p>Okay let’s ramp up the difficulty a little bit! The heat equation which describes the diffusion of temperature in a medium is another classical example. To put it in concrete terms, imagine you take a needle, and heat it. After you stop, the electrons inside the needle will bounce off each other, spreading the energy (and therefore the heat), until the temperature of the needle is the same everywhere. This process is called <em>energy diffusion</em> and is described by the following equation:</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><msub><mi mathvariant="normal">∂</mi><mi>t</mi></msub><mi>T</mi><mo stretchy="false">(</mo><mi>t</mi><mo separator="true">,</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>κ</mi><msubsup><mi mathvariant="normal">∂</mi><mi>x</mi><mn>2</mn></msubsup><mi>T</mi><mo stretchy="false">(</mo><mi>t</mi><mo separator="true">,</mo><mi>x</mi><mo stretchy="false">)</mo><mtext> </mtext><mo separator="true">,</mo></mrow><annotation encoding="application/x-tex">    \partial_t T(t,x) = \kappa \partial_x^2 T(t,x)~,</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span>∂</span><span><span><span><span><span><span></span><span><span>t</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>T</span><span>(</span><span>t</span><span>,</span><span></span><span>x</span><span>)</span><span></span><span>=</span><span></span></span><span><span></span><span>κ</span><span><span>∂</span><span><span><span><span><span><span></span><span><span>x</span></span></span><span><span></span><span><span>2</span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span></span><span>T</span><span>(</span><span>t</span><span>,</span><span></span><span>x</span><span>)</span><span> </span><span>,</span></span></span></span></span>
<p>where <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>κ</mi></mrow><annotation encoding="application/x-tex">\kappa</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>κ</span></span></span></span>, called the <em>thermal diffusivity</em>, quantifies how fast the heat spreads. I need to choose some boundary conditions and initial value profile before I can solve this: in this example I took <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo stretchy="false">(</mo><mi>t</mi><mo>=</mo><mn>0</mn><mo separator="true">,</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>sin</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>n</mi><mi>π</mi><mi>x</mi><mo stretchy="false">)</mo></mrow><annotation encoding="application/x-tex">T(t=0, x) = \sin(n \pi x)</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>T</span><span>(</span><span>t</span><span></span><span>=</span><span></span></span><span><span></span><span>0</span><span>,</span><span></span><span>x</span><span>)</span><span></span><span>=</span><span></span></span><span><span></span><span>sin</span><span>(</span><span>nπ</span><span>x</span><span>)</span></span></span></span> (with <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>≥</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">n \geq 1</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>n</span><span></span><span>≥</span><span></span></span><span><span></span><span>1</span></span></span></span> an integer) and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo stretchy="false">(</mo><mi>t</mi><mo separator="true">,</mo><mi>x</mi><mo>=</mo><mn>0</mn><mo stretchy="false">)</mo><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">T(t, x=0) = 0</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>T</span><span>(</span><span>t</span><span>,</span><span></span><span>x</span><span></span><span>=</span><span></span></span><span><span></span><span>0</span><span>)</span><span></span><span>=</span><span></span></span><span><span></span><span>0</span></span></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi><mo stretchy="false">(</mo><mi>t</mi><mo separator="true">,</mo><mi>x</mi><mo>=</mo><mn>1</mn><mo stretchy="false">)</mo><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">T(t, x=1) = 0</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>T</span><span>(</span><span>t</span><span>,</span><span></span><span>x</span><span></span><span>=</span><span></span></span><span><span></span><span>1</span><span>)</span><span></span><span>=</span><span></span></span><span><span></span><span>0</span></span></span></span>. The analytical solution can be obtained easily<sup><a href="#user-content-fn-separation" id="user-content-fnref-separation" data-footnote-ref="" aria-describedby="footnote-label">8</a></sup> and takes the form of an exponential decay of the initial temperature profile:</p>
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML" display="block"><semantics><mrow><mi>T</mi><mo stretchy="false">(</mo><mi>t</mi><mo separator="true">,</mo><mi>x</mi><mo stretchy="false">)</mo><mo>=</mo><mi>sin</mi><mo>⁡</mo><mo stretchy="false">(</mo><mi>n</mi><mi>π</mi><mi>x</mi><mo stretchy="false">)</mo><msup><mi>e</mi><mrow><mo>−</mo><msup><mi>n</mi><mn>2</mn></msup><msup><mi>π</mi><mn>2</mn></msup><mi>t</mi></mrow></msup><mtext> </mtext><mi mathvariant="normal">.</mi></mrow><annotation encoding="application/x-tex">    T(t,x) = \sin(n \pi x) e^{- n^2 \pi^2 t}~.</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>T</span><span>(</span><span>t</span><span>,</span><span></span><span>x</span><span>)</span><span></span><span>=</span><span></span></span><span><span></span><span>sin</span><span>(</span><span>nπ</span><span>x</span><span>)</span><span><span>e</span><span><span><span><span><span><span></span><span><span><span>−</span><span><span>n</span><span><span><span><span><span><span></span><span><span>2</span></span></span></span></span></span></span></span><span><span>π</span><span><span><span><span><span><span></span><span><span>2</span></span></span></span></span></span></span></span><span>t</span></span></span></span></span></span></span></span></span><span> </span><span>.</span></span></span></span></span>
<p>At this point you might be worried that <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>T</mi></mrow><annotation encoding="application/x-tex">T</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>T</span></span></span></span> can become negative (for example when <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mo>&lt;</mo><mi>x</mi><mo>&lt;</mo><mn>2</mn></mrow><annotation encoding="application/x-tex">1 &lt; x &lt; 2</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>1</span><span></span><span>&lt;</span><span></span></span><span><span></span><span>x</span><span></span><span>&lt;</span><span></span></span><span><span></span><span>2</span></span></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">n=1</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>n</span><span></span><span>=</span><span></span></span><span><span></span><span>1</span></span></span></span>). The reason for this is that this equation does not apply to the absolute temperature of the system, but its temperature <strong>relative</strong> to a baseline. The initial profile we apply is periodic with some pockets above and some below the baseline, and as time progresses that temperature profile diffuses until the temperature is constant everywhere, and therefore the relative temperature is zero.</p>
<p>To solve the equation numerically using DeepXDE, you can use pretty much the same setup with the following differences:</p>
<ul>
<li>the input layer of the neural network should be two-dimensional instead of one-dimensional since there are now two coordinates,</li>
<li>the model should now be given an initial profile on the entire <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>t</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">t=0</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>t</span><span></span><span>=</span><span></span></span><span><span></span><span>0</span></span></span></span> slice as well as Dirichlet boundary conditions at both <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>=</mo><mn>0</mn></mrow><annotation encoding="application/x-tex">x=0</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>x</span><span></span><span>=</span><span></span></span><span><span></span><span>0</span></span></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>x</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">x=1</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>x</span><span></span><span>=</span><span></span></span><span><span></span><span>1</span></span></span></span>,</li>
</ul>
<astro-island uid="Z14YoMA" component-url="/_astro/EnhancedPreElement.DVSGoltY.js" component-export="default" renderer-url="/_astro/client.CQQZjN3o.js" props="{&#34;class&#34;:[0,&#34;astro-code astro-code-themes github-light github-dark&#34;],&#34;style&#34;:[0,{&#34;backgroundColor&#34;:[0,&#34;#fff&#34;],&#34;--shiki-dark-bg&#34;:[0,&#34;#24292e&#34;],&#34;color&#34;:[0,&#34;#24292e&#34;],&#34;--shiki-dark&#34;:[0,&#34;#e1e4e8&#34;],&#34;overflowX&#34;:[0,&#34;auto&#34;],&#34;whiteSpace&#34;:[0,&#34;pre-wrap&#34;],&#34;wordWrap&#34;:[0,&#34;break-word&#34;]}],&#34;tabindex&#34;:[0,&#34;0&#34;],&#34;data-language&#34;:[0,&#34;python&#34;]}" ssr="" client="load" opts="{&#34;name&#34;:&#34;EnhancedPreElement&#34;,&#34;value&#34;:true}" await-children=""><div><pre tabindex="0" data-language="python"><astro-slot><code><span><span>bc </span><span>=</span><span> dde.icbc.DirichletBC(</span></span>
<span><span>    geom_full, </span><span>lambda</span><span> x: </span><span>0</span><span>, </span><span>lambda</span><span> _, on_boundary: on_boundary</span></span>
<span><span>)</span></span>
<span><span>ic </span><span>=</span><span> dde.icbc.IC(</span></span>
<span><span>    geom_full,</span></span>
<span><span>    lambda</span><span> x: np.sin(n </span><span>*</span><span> np.pi </span><span>*</span><span> x[:, </span><span>0</span><span>:</span><span>1</span><span>]),</span></span>
<span><span>    lambda</span><span> _, on_initial: on_initial,</span></span>
<span><span>)</span></span></code></astro-slot></pre></div><!--astro:end--></astro-island>
<ul>
<li>the model should be trained with samples on both the boundary and initial value slice</li>
</ul>
<astro-island uid="ZnPrIS" component-url="/_astro/EnhancedPreElement.DVSGoltY.js" component-export="default" renderer-url="/_astro/client.CQQZjN3o.js" props="{&#34;class&#34;:[0,&#34;astro-code astro-code-themes github-light github-dark&#34;],&#34;style&#34;:[0,{&#34;backgroundColor&#34;:[0,&#34;#fff&#34;],&#34;--shiki-dark-bg&#34;:[0,&#34;#24292e&#34;],&#34;color&#34;:[0,&#34;#24292e&#34;],&#34;--shiki-dark&#34;:[0,&#34;#e1e4e8&#34;],&#34;overflowX&#34;:[0,&#34;auto&#34;],&#34;whiteSpace&#34;:[0,&#34;pre-wrap&#34;],&#34;wordWrap&#34;:[0,&#34;break-word&#34;]}],&#34;tabindex&#34;:[0,&#34;0&#34;],&#34;data-language&#34;:[0,&#34;python&#34;]}" ssr="" client="load" opts="{&#34;name&#34;:&#34;EnhancedPreElement&#34;,&#34;value&#34;:true}" await-children=""><div><pre tabindex="0" data-language="python"><astro-slot><code><span><span>n_training_inside </span><span>=</span><span> 2000</span></span>
<span><span>n_training_bdy </span><span>=</span><span> 80</span></span>
<span><span>n_training_initial </span><span>=</span><span> 160</span></span>
<span><span>n_test </span><span>=</span><span> 2000</span></span>
<span></span>
<span><span>data </span><span>=</span><span> dde.data.TimePDE(</span></span>
<span><span>    geom_full,</span></span>
<span><span>    heat_eq.equation,</span></span>
<span><span>    [bc, ic],</span></span>
<span><span>    num_domain</span><span>=</span><span>n_training_inside,</span></span>
<span><span>    num_boundary</span><span>=</span><span>n_training_bdy,</span></span>
<span><span>    num_initial</span><span>=</span><span>n_training_initial,</span></span>
<span><span>    solution</span><span>=</span><span>heat_eq.exact_solution,</span></span>
<span><span>    num_test</span><span>=</span><span>n_test,</span></span>
<span><span>)</span></span></code></astro-slot></pre></div><!--astro:end--></astro-island>
<p>where <code>heat_eq</code> is the equivalent to the <code>HarmonicOscillator0D</code> object from before, but adapted to this system. After training the model for both <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>=</mo><mn>1</mn></mrow><annotation encoding="application/x-tex">n=1</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>n</span><span></span><span>=</span><span></span></span><span><span></span><span>1</span></span></span></span> and <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>n</mi><mo>=</mo><mn>4</mn></mrow><annotation encoding="application/x-tex">n=4</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>n</span><span></span><span>=</span><span></span></span><span><span></span><span>4</span></span></span></span> and with <span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>κ</mi><mo>=</mo><mn>0.1</mn></mrow><annotation encoding="application/x-tex">\kappa = 0.1</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>κ</span><span></span><span>=</span><span></span></span><span><span></span><span>0.1</span></span></span></span>, these are the results:</p>
<p><img src="https://nchagnet.pages.dev/assets/blog/physics-informed-neural-networks/heat_equation_n=1.png" alt="Solution to the heat equation for n = 1"/><img src="https://nchagnet.pages.dev/assets/blog/physics-informed-neural-networks/heat_equation_n=4.png" alt="Solution to the heat equation for n = 4"/></p>
<p>Hurray! Once again the neural networks has correctly learnt the solution to the equations and generalizes quite well beyond the training data. For reference, the network was trained on a little bit more than 2000 points, while the mesh of the figures consist of 1 million points. This is a great example of the natural interpolation property of PINNs!</p>


</section></section><section data-heading-rank="2" aria-labelledby="summary"><h2 id="summary">Summary</h2>
<p>In this post, I wanted to give you brief introduction to PINNs as well as show how neural networks and deep learning in general can have great application in numerical physics. In the examples I derived, you can clearly see the quality of solutions they yield. However most of these examples are rather simple, mostly due to resource constraints (I just don’t have a great GPU laying around), and this method is currently more resource-hungry than traditional finite-element methods. On the other end, its ability to naturally capture unusual geometries is very promising.</p>

</section>   </div> </article></div>
  </body>
</html>
