<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://nayak.io/posts/git-clone-optimizations/">Original</a>
    <h1>Using Git with large repositories: Cloning</h1>
    
    <div id="readability-page-1" class="page"><div>
<section>
<article>
<header>

<div>
<p><span>
<i aria-hidden="true"></i>
<time datetime="2023-06-23T12:34:52+02:00">
June 23, 2023
</time>
</span>
<span>
<i aria-hidden="true"></i>
12-minute read
</span>
</p>

</div>
</header>
<div>
<p>Working with large repositories is a daunting task. While Git <em>works</em> with most repository sizes, its speed is inversely proportionate to the size of the repository. Let’s take the example of the <a href="https://gitlab.com/gitlab-org/gitlab">GitLab rails monorepo</a>. Being part of the <a href="https://about.gitlab.com/handbook/engineering/development/enablement/systems/gitaly/">Gitaly</a> team means that we also make changes to the rails repository from time to time.</p>
<p>The GitLab repository is active with around over 300k commits, 14k branches and 110k merge requests. Let’s look at some ways to squeeze some performance out of git while cloning such repositories. We’ll use this repository as an example to go over the optimizations possible.</p>
<p><img src="https://nayak.io/git/sparse/gitlab.png" alt="GitLab stats"/></p><p>Before we jump into it, let’s talk about the different object types available in git. Objects in git follow a graph structure.</p>
<ul>
<li>Blob: Blobs in git are objects which contain the data of a file. Blobs do not hold any other information such as path/filename, just the contents of a file.</li>
<li>Tree: Trees in git refer to the directory and file structure of a repository. Files are trees which hold a filename and point to a blob (contents of the file). While directories are trees which contain other trees (sub-directories or files).</li>
<li>Commit: Commits in git are a point in time reference to how the repository looks. Each commit points to one or more parent commits and also a tree object.</li>
</ul>
<p><img src="https://nayak.io/git/sparse/gittree.png" alt="Git Tree Structure"/></p><p>The graph shows a simple repository wherein each commit points to its parent. Each commit also points to a set of trees. Some trees are shared amongst commits. Trees could point to other trees (directories) or blobs (files) recursively.</p>

<p>Let’s clone the gitlab repository without any optimizations. This will serve as a baseline to compare some of the options we discover later on.</p>
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="shell"><span><span>❯ time git clone <a href="https://nayak.io/cdn-cgi/l/email-protection" data-cfemail="f89f918cb89f918c94999ad69b9795">[email protected]</a>:gitlab-org/gitlab.git
</span></span><span><span>Cloning into <span>&#39;gitlab&#39;</span>...
</span></span><span><span>remote: Enumerating objects: 4676537, <span>done</span>.
</span></span><span><span>remote: Counting objects: 100% <span>(</span>78689/78689<span>)</span>, <span>done</span>.
</span></span><span><span>remote: Compressing objects: 100% <span>(</span>17044/17044<span>)</span>, <span>done</span>.
</span></span><span><span>remote: Total <span>4676537</span> <span>(</span>delta 69483<span>)</span>, reused <span>68136</span> <span>(</span>delta 61002<span>)</span>, pack-reused <span>4597848</span>
</span></span><span><span>Receiving objects: 100% <span>(</span>4676537/4676537<span>)</span>, 1.78 GiB | 13.60 MiB/s, <span>done</span>.
</span></span><span><span>Resolving deltas: 100% <span>(</span>3655614/3655614<span>)</span>, <span>done</span>.
</span></span><span><span>Updating files: 100% <span>(</span>63451/63451<span>)</span>, <span>done</span>.
</span></span><span><span>
</span></span><span><span>________________________________________________________
</span></span><span><span>Executed in  191.75 secs    fish           external
</span></span><span><span>   usr time  236.59 secs    0.00 micros  236.59 secs
</span></span><span><span>   sys time   27.24 secs  926.00 micros   27.24 secs
</span></span><span><span>   
</span></span><span><span>❯ cd gitlab; du -sh .
</span></span><span><span>2.5G    .
</span></span></code></pre></td></tr></tbody></table>
</div>
</div><p>What’s important to notice here is not only the time taken, but also the number of objects that we had to fetch<sup><a href="#footnote">1</a></sup>. By default, git fetches all commits, trees and blobs.</p>
<p>For benchmarking, we’ll use a naive approach of checking our an older branch using <code>git checkout</code>. Let’s use a branch last updated on March 11, 2022: <code>demo-add-training-url</code>. We can see that in our baseline repository, it takes 6.5s to complete.</p>
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span><span>9
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="shell"><span><span>❯ time git checkout demo-add-training-url
</span></span><span><span>Updating files: 100% <span>(</span>53674/53674<span>)</span>, <span>done</span>.
</span></span><span><span>branch <span>&#39;demo-add-training-url&#39;</span> set up to track <span>&#39;origin/demo-add-training-url&#39;</span>.
</span></span><span><span>Switched to a new branch <span>&#39;demo-add-training-url&#39;</span>
</span></span><span><span>
</span></span><span><span>________________________________________________________
</span></span><span><span>Executed in    6.57 secs    fish           external
</span></span><span><span>   usr time    1.35 secs    0.00 micros    1.35 secs
</span></span><span><span>   sys time    1.27 secs  809.00 micros    1.27 secs
</span></span></code></pre></td></tr></tbody></table>
</div>
</div><p>Now we can move onto the more interesting bits, optimization!</p>
<h2 id="shallow-clone">
Shallow clone
<a href="#shallow-clone">
<i aria-hidden="true" title="Link to heading"></i>
<span>Link to heading</span>
</a>
</h2>
<p>When you want to clone the repository and don’t care about its history, we can ask git to only fetch the current state of the repository. We can tell <code>git clone</code> to ignore the history by using the <code>--depth=&lt;N&gt;</code> flag. Here N denotes the number of commits we want to fetch. With this, git only fetches the default branch and only N commits from that branch.</p>
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="shell"><span><span>❯ time git clone --depth<span>=</span><span>1</span> <a href="https://nayak.io/cdn-cgi/l/email-protection" data-cfemail="e2858b96a2858b968e8380cc818d8f">[email protected]</a>:gitlab-org/gitlab.git gitlab_depth1
</span></span><span><span>Cloning into <span>&#39;gitlab_depth1&#39;</span>...
</span></span><span><span>remote: Enumerating objects: 76618, <span>done</span>.
</span></span><span><span>remote: Counting objects: 100% <span>(</span>76618/76618<span>)</span>, <span>done</span>.
</span></span><span><span>remote: Compressing objects: 100% <span>(</span>65989/65989<span>)</span>, <span>done</span>.
</span></span><span><span>remote: Total <span>76618</span> <span>(</span>delta 10188<span>)</span>, reused <span>45451</span> <span>(</span>delta 7062<span>)</span>, pack-reused <span>0</span>
</span></span><span><span>Receiving objects: 100% <span>(</span>76618/76618<span>)</span>, 99.03 MiB | 10.21 MiB/s, <span>done</span>.
</span></span><span><span>Resolving deltas: 100% <span>(</span>10188/10188<span>)</span>, <span>done</span>.
</span></span><span><span>Updating files: 100% <span>(</span>63451/63451<span>)</span>, <span>done</span>.
</span></span><span><span>
</span></span><span><span>________________________________________________________
</span></span><span><span>Executed in   18.09 secs    fish           external
</span></span><span><span>   usr time    3.98 secs  388.00 micros    3.98 secs
</span></span><span><span>   sys time    1.69 secs  135.00 micros    1.69 secs
</span></span><span><span>
</span></span><span><span>❯ cd gitlab_depth1/; du -sh .
</span></span><span><span>608M    .
</span></span></code></pre></td></tr></tbody></table>
</div>
</div><p>We reduced the size by around 75% and reduced the number of objects by 98%. The drawbacks of this are we lose history of the repository, <code>git log</code> would only show the latest commit on the repository.</p>
<p>To benchmark, if we try to checkout the branch, we’ll be immediately hit with <code>error: pathspec &#39;demo-add-training-url&#39; did not match any file(s) known to git</code> error. This is because we only cloned the top commit. Therefore, we’ll need to fetch the branch before we checkout.</p>
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="shell"><span><span>❯ time begin
</span></span><span><span>      git fetch origin demo-add-training-url
</span></span><span><span>      git checkout demo-add-training-url
</span></span><span><span>  end
</span></span><span><span>
</span></span><span><span>remote: Enumerating objects: 3020221, <span>done</span>.
</span></span><span><span>remote: Counting objects: 100% <span>(</span>3020210/3020210<span>)</span>, <span>done</span>.
</span></span><span><span>remote: Compressing objects: 100% <span>(</span>682396/682396<span>)</span>, <span>done</span>.
</span></span><span><span>remote: Total <span>3001460</span> <span>(</span>delta 2352070<span>)</span>, reused <span>2902689</span> <span>(</span>delta 2272946<span>)</span>, pack-reused <span>0</span>
</span></span><span><span>Receiving objects: 100% <span>(</span>3001460/3001460<span>)</span>, 1.06 GiB | 7.45 MiB/s, <span>done</span>.
</span></span><span><span>Resolving deltas: 100% <span>(</span>2352070/2352070<span>)</span>, completed with <span>10764</span> local objects.
</span></span><span><span>From work.gitlab.com:gitlab-org/gitlab
</span></span><span><span> * branch                    demo-add-training-url -&gt; FETCH_HEAD
</span></span><span><span>error: pathspec <span>&#39;demo-add-training-url&#39;</span> did not match any file<span>(</span>s<span>)</span> known to git
</span></span><span><span>
</span></span><span><span>________________________________________________________
</span></span><span><span>Executed in  236.41 secs    fish           external
</span></span><span><span>   usr time  134.92 secs  707.00 micros  134.92 secs
</span></span><span><span>   sys time   15.06 secs  788.00 micros   15.06 secs
</span></span></code></pre></td></tr></tbody></table>
</div>
</div><p>Funny! Checking out a branch took more time than the original clone of the entire repository<sup><a href="#footnote">2</a></sup>. This is the biggest drawback of using a shallow clone. i.e. whenever you want to move from the commit you cloned to any other commit, it often requires downloading a lot of objects. If you’re keeping count this is 34.9x slower.</p>
<h2 id="partial-clone">
Partial clone
<a href="#partial-clone">
<i aria-hidden="true" title="Link to heading"></i>
<span>Link to heading</span>
</a>
</h2>
<p>Partial clone is a <a href="https://git-scm.com/docs/partial-clone/2.38.0">feature</a> introduced in git 2.29.0 and improved in versions onward. It allows you to fetch only certain objects during the clone and adds promisory notes for the missing objects. Whenever you perform git operation which requires the missing objects, it uses the information in the promisory notes to fetch those objects. This includes operations like <code>git blame</code>, <code>git log</code> etc. Anytime an object is required, git would fetch those objects.</p>
<h3 id="comparison-to-shallow-clone">
Comparison to shallow clone
<a href="#comparison-to-shallow-clone">
<i aria-hidden="true" title="Link to heading"></i>
<span>Link to heading</span>
</a>
</h3>
<p>Partial clone is different from shallow clone we discussed earlier as in shallow clone git would treat the repository as having a single commit, and it wouldn’t auto-magically fetch objects as needed (e.g. if you want to checkout a commit beyond the cloned depth). There is no concept of promisory notes in shallow clone.</p>
<p>Whereas in partial clone, git keeps information about the missing objects in promisory notes, but not the entire object itself. This reduces space on disk but provides flexibility wherein users can always fetch the objects dynamically.</p>
<h3 id="types-of-partial-clone">
Types of partial clone
<a href="#types-of-partial-clone">
<i aria-hidden="true" title="Link to heading"></i>
<span>Link to heading</span>
</a>
</h3>
<p>Partial cloning is done by using the <code>--filter=&lt;filter-spec&gt;</code> flag on <code>git clone</code>. The types of filter spec can be noted in the <a href="https://www.git-scm.com/docs/git-rev-list#Documentation/git-rev-list.txt---filterltfilter-specgt">git-rev-list(1)</a> manual page. Lets discuss two important types of filter-spec:</p>
<h4 id="filter-out-blobs">
Filter out blobs
<a href="#filter-out-blobs">
<i aria-hidden="true" title="Link to heading"></i>
<span>Link to heading</span>
</a>
</h4>
<p>We can filter out blobs either with <code>--filter=blob:none</code> or <code>--filter=blob:limit=&lt;n&gt;[kmg]</code>. The former will not fetch any blobs, while the latter will only fetch blobs below the provided size.</p>
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="shell"><span><span>❯ time git clone --filter<span>=</span>blob:none <a href="https://nayak.io/cdn-cgi/l/email-protection" data-cfemail="5e39372a1e39372a323f3c703d3133">[email protected]</a>:gitlab-org/gitlab.git gitlab_no_blobs
</span></span><span><span>Cloning into <span>&#39;gitlab_no_blobs&#39;</span>...
</span></span><span><span>remote: Enumerating objects: 3578689, <span>done</span>.
</span></span><span><span>remote: Counting objects: 100% <span>(</span>64029/64029<span>)</span>, <span>done</span>.
</span></span><span><span>remote: Compressing objects: 100% <span>(</span>13917/13917<span>)</span>, <span>done</span>.
</span></span><span><span>remote: Total <span>3578689</span> <span>(</span>delta 57465<span>)</span>, reused <span>54662</span> <span>(</span>delta 49402<span>)</span>, pack-reused <span>3514660</span>
</span></span><span><span>Receiving objects: 100% <span>(</span>3578689/3578689<span>)</span>, 601.77 MiB | 13.10 MiB/s, <span>done</span>.
</span></span><span><span>Resolving deltas: 100% <span>(</span>2738731/2738731<span>)</span>, <span>done</span>.
</span></span><span><span>remote: Enumerating objects: 63071, <span>done</span>.
</span></span><span><span>remote: Counting objects: 100% <span>(</span>32161/32161<span>)</span>, <span>done</span>.
</span></span><span><span>remote: Compressing objects: 100% <span>(</span>28431/28431<span>)</span>, <span>done</span>.
</span></span><span><span>remote: Total <span>63071</span> <span>(</span>delta 5390<span>)</span>, reused <span>4219</span> <span>(</span>delta 3728<span>)</span>, pack-reused <span>30910</span>
</span></span><span><span>Receiving objects: 100% <span>(</span>63071/63071<span>)</span>, 96.69 MiB | 10.40 MiB/s, <span>done</span>.
</span></span><span><span>Resolving deltas: 100% <span>(</span>8715/8715<span>)</span>, <span>done</span>.
</span></span><span><span>Updating files: 100% <span>(</span>63453/63453<span>)</span>, <span>done</span>.
</span></span><span><span>
</span></span><span><span>________________________________________________________
</span></span><span><span>Executed in   90.70 secs    fish           external
</span></span><span><span>   usr time   55.19 secs  653.00 micros   55.19 secs
</span></span><span><span>   sys time   15.47 secs  176.00 micros   15.47 secs
</span></span><span><span>   
</span></span><span><span>❯ cd gitlab_no_blobs/; du -sh .
</span></span><span><span>1.3G    .
</span></span></code></pre></td></tr></tbody></table>
</div>
</div><p>Notice there are two fetch cycles in the git clone, the first is the regular clone without the blobs, which fetched 3578689 objects.</p>
<p>But then since the commit we’d be on points to a tree which would point to certain blobs (directly/indirectly), those blobs got downloaded dynamically by git by looking at the promisory notes. This time we ended up fetching 63071 new objects.</p>
<p>Overall we have reduced our disk space by 48% and the number of objects by 22%.</p>
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="shell"><span><span>❯ time git checkout demo-add-training-url
</span></span><span><span>remote: Enumerating objects: 32619, <span>done</span>.
</span></span><span><span>remote: Counting objects: 100% <span>(</span>23129/23129<span>)</span>, <span>done</span>.
</span></span><span><span>remote: Compressing objects: 100% <span>(</span>20436/20436<span>)</span>, <span>done</span>.
</span></span><span><span>remote: Total <span>32619</span> <span>(</span>delta 4135<span>)</span>, reused <span>2693</span> <span>(</span>delta 2693<span>)</span>, pack-reused <span>9490</span>
</span></span><span><span>Receiving objects: 100% <span>(</span>32619/32619<span>)</span>, 49.35 MiB | 10.24 MiB/s, <span>done</span>.
</span></span><span><span>Resolving deltas: 100% <span>(</span>5089/5089<span>)</span>, <span>done</span>.
</span></span><span><span>Updating files: 100% <span>(</span>53678/53678<span>)</span>, <span>done</span>.
</span></span><span><span>branch <span>&#39;demo-add-training-url&#39;</span> set up to track <span>&#39;origin/demo-add-training-url&#39;</span>.
</span></span><span><span>Switched to a new branch <span>&#39;demo-add-training-url&#39;</span>
</span></span><span><span>
</span></span><span><span>________________________________________________________
</span></span><span><span>Executed in   16.60 secs    fish           external
</span></span><span><span>   usr time    3.71 secs    0.10 millis    3.71 secs
</span></span><span><span>   sys time    1.50 secs    1.04 millis    1.50 secs
</span></span></code></pre></td></tr></tbody></table>
</div>
</div><p>On the benchmark side, we can see that this is only 2.5x slower than the baseline. This is because we already have all the required commits/trees and only needed to fetch missing blobs.</p>
<h4 id="filter-out-trees">
Filter out trees
<a href="#filter-out-trees">
<i aria-hidden="true" title="Link to heading"></i>
<span>Link to heading</span>
</a>
</h4>
<p>We can filter out trees using the <code>--filter=tree:&lt;depth&gt;</code>, where depth refers to how many trees from the root would be downloaded, 0 indicates that no trees would be downloaded.</p>
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span><span>25
</span><span>26
</span><span>27
</span><span>28
</span><span>29
</span><span>30
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="shell"><span><span>❯ time git clone --filter<span>=</span>tree:0 <a href="https://nayak.io/cdn-cgi/l/email-protection" data-cfemail="5e39372a1e39372a323f3c703d3133">[email protected]</a>:gitlab-org/gitlab.git gitlab_0_trees
</span></span><span><span>Cloning into <span>&#39;gitlab_0_trees&#39;</span>...
</span></span><span><span>remote: Enumerating objects: 434513, <span>done</span>.
</span></span><span><span>remote: Counting objects: 100% <span>(</span>2451/2451<span>)</span>, <span>done</span>.
</span></span><span><span>remote: Compressing objects: 100% <span>(</span>2378/2378<span>)</span>, <span>done</span>.
</span></span><span><span>remote: Total <span>434513</span> <span>(</span>delta 104<span>)</span>, reused <span>2263</span> <span>(</span>delta 73<span>)</span>, pack-reused <span>432062</span>
</span></span><span><span>Receiving objects: 100% <span>(</span>434513/434513<span>)</span>, 127.82 MiB | 11.78 MiB/s, <span>done</span>.
</span></span><span><span>Resolving deltas: 100% <span>(</span>21492/21492<span>)</span>, <span>done</span>.
</span></span><span><span>remote: Enumerating objects: 13548, <span>done</span>.
</span></span><span><span>remote: Counting objects: 100% <span>(</span>3650/3650<span>)</span>, <span>done</span>.
</span></span><span><span>remote: Compressing objects: 100% <span>(</span>3601/3601<span>)</span>, <span>done</span>.
</span></span><span><span>remote: Total <span>13548</span> <span>(</span>delta 5<span>)</span>, reused <span>460</span> <span>(</span>delta 2<span>)</span>, pack-reused <span>9898</span>
</span></span><span><span>Receiving objects: 100% <span>(</span>13548/13548<span>)</span>, 2.72 MiB | 4.83 MiB/s, <span>done</span>.
</span></span><span><span>Resolving deltas: 100% <span>(</span>12/12<span>)</span>, <span>done</span>.
</span></span><span><span>remote: Enumerating objects: 63071, <span>done</span>.
</span></span><span><span>remote: Counting objects: 100% <span>(</span>32161/32161<span>)</span>, <span>done</span>.
</span></span><span><span>remote: Compressing objects: 100% <span>(</span>28431/28431<span>)</span>, <span>done</span>.
</span></span><span><span>remote: Total <span>63071</span> <span>(</span>delta 5390<span>)</span>, reused <span>4219</span> <span>(</span>delta 3728<span>)</span>, pack-reused <span>30910</span>
</span></span><span><span>Receiving objects: 100% <span>(</span>63071/63071<span>)</span>, 96.69 MiB | 11.46 MiB/s, <span>done</span>.
</span></span><span><span>Resolving deltas: 100% <span>(</span>8715/8715<span>)</span>, <span>done</span>.
</span></span><span><span>Updating files: 100% <span>(</span>63453/63453<span>)</span>, <span>done</span>.
</span></span><span><span>
</span></span><span><span>________________________________________________________
</span></span><span><span>Executed in   39.01 secs    fish           external
</span></span><span><span>   usr time   10.82 secs  661.00 micros   10.82 secs
</span></span><span><span>   sys time    3.10 secs  270.00 micros    3.10 secs
</span></span><span><span>
</span></span><span><span>
</span></span><span><span>❯ cd gitlab_0_trees/; du -sh .
</span></span><span><span>758M    .
</span></span></code></pre></td></tr></tbody></table>
</div>
</div><p>Similar to the blob filter, here we see git running multiple fetch cycles after the initial fetch to ensure that the repository is in a usable state. Overall the tree filter is somewhat similar to the <em>shallow clone</em>, wherein we retain only the trees/blobs of the latest commit. But it differs from it by containing all the objects for all commits of the repository and utilizing promisory notes for dynamically obtaining missing objects</p>
<p>Overall we have reduced our disk space by 69% and the number of objects by 89%.</p>
<div><div>
<table><tbody><tr><td>
<pre tabindex="0"><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span></code></pre></td>
<td>
<pre tabindex="0"><code data-lang="shell"><span><span>❯ time git checkout demo-add-training-url
</span></span><span><span>remote: Enumerating objects: 10845, <span>done</span>.
</span></span><span><span>remote: Counting objects: 100% <span>(</span>3688/3688<span>)</span>, <span>done</span>.
</span></span><span><span>remote: Compressing objects: 100% <span>(</span>3679/3679<span>)</span>, <span>done</span>.
</span></span><span><span>remote: Total <span>10845</span> <span>(</span>delta 14<span>)</span>, reused <span>9</span> <span>(</span>delta 9<span>)</span>, pack-reused <span>7157</span>
</span></span><span><span>Receiving objects: 100% <span>(</span>10845/10845<span>)</span>, 2.16 MiB | 4.16 MiB/s, <span>done</span>.
</span></span><span><span>Resolving deltas: 100% <span>(</span>16/16<span>)</span>, <span>done</span>.
</span></span><span><span>remote: Enumerating objects: 32622, <span>done</span>.
</span></span><span><span>remote: Counting objects: 100% <span>(</span>23132/23132<span>)</span>, <span>done</span>.
</span></span><span><span>remote: Compressing objects: 100% <span>(</span>20439/20439<span>)</span>, <span>done</span>.
</span></span><span><span>remote: Total <span>32622</span> <span>(</span>delta 4136<span>)</span>, reused <span>2693</span> <span>(</span>delta 2693<span>)</span>, pack-reused <span>9490</span>
</span></span><span><span>Receiving objects: 100% <span>(</span>32622/32622<span>)</span>, 49.35 MiB | 10.34 MiB/s, <span>done</span>.
</span></span><span><span>Resolving deltas: 100% <span>(</span>5090/5090<span>)</span>, <span>done</span>.
</span></span><span><span>Updating files: 100% <span>(</span>53678/53678<span>)</span>, <span>done</span>.
</span></span><span><span>branch <span>&#39;demo-add-training-url&#39;</span> set up to track <span>&#39;origin/demo-add-training-url&#39;</span>.
</span></span><span><span>Switched to a new branch <span>&#39;demo-add-training-url&#39;</span>
</span></span><span><span>
</span></span><span><span>________________________________________________________
</span></span><span><span>Executed in   19.30 secs    fish           external
</span></span><span><span>   usr time    3.83 secs    0.04 millis    3.83 secs
</span></span><span><span>   sys time    1.58 secs    1.01 millis    1.58 secs
</span></span></code></pre></td></tr></tbody></table>
</div>
</div><p>This is only 2.93x slower than the baseline.</p>
<h3 id="other-filter-types">
Other filter types
<a href="#other-filter-types">
<i aria-hidden="true" title="Link to heading"></i>
<span>Link to heading</span>
</a>
</h3>
<p>There are also other filter types such as <code>--filter=object:type=(tag|commit|tree|blob)</code>, in this filter, filtering by <code>commit</code> would be similar to using <code>--filter=tree:0</code>, which we discussed above. Filtering by <code>tree</code>, <code>blob</code> wouldn’t provide much improvements since we’d still download a lot of objects. Finally filtering by <code>tag</code> would be similar to <code>commit</code>, only that we’d have lesser objects (ratio of commits:tags is much lesser than commits:blobs or commits:trees) so it shouldn’t make too much difference.</p>
<h2 id="conclusion">
Conclusion
<a href="#conclusion">
<i aria-hidden="true" title="Link to heading"></i>
<span>Link to heading</span>
</a>
</h2>
<p>Generally I suggest using the <code>--filter=tree:0</code> flag while cloning as it provides the best savings on disk space while still providing sufficient performance on regular git tasks. But it all depends on your use case at the end. For e.g. if you’re cloning a repository to only build a binary, you don’t care about git history or objects, in that scenario, a shallow clone is the best option.</p>
<p>Overall the table below should give you some guidance on what to use when:</p>
<table>
<thead>
<tr>
<th>Cloning Type</th>
<th>Disk Space</th>
<th>No of Objects</th>
<th>Time to Clone</th>
<th>Checkout Old Branch</th>
</tr>
</thead>
<tbody>
<tr>
<td>Regular clone</td>
<td>2.5G</td>
<td>4676537</td>
<td>191.75s</td>
<td>6.57s</td>
</tr>
<tr>
<td>Shallow clone</td>
<td>0.6G</td>
<td>76618</td>
<td>18.09s</td>
<td>236.41s</td>
</tr>
<tr>
<td>Partial clone: no blobs</td>
<td>1.3G</td>
<td>3641760</td>
<td>90.7s</td>
<td>16.60s</td>
</tr>
<tr>
<td>Partial clone: no trees</td>
<td>0.7G</td>
<td>511132</td>
<td>39.01s</td>
<td>19.30s</td>
</tr>
</tbody>
</table>

<p><sup>1</sup> The objects are often packed into <a href="https://git-scm.com/book/en/v2/Git-Internals-Packfiles">packfiles</a>. This optimization not only allows compression of objects but also storing of objects as deltas over the other objects. The downside is that object lookup now requires not only decompression but for deltas we need to resolve the objects that the delta is based upon (which could be a list of lookups).</p>
<p><sup>2</sup> The time taken being larger than regular clone could be due to a number of reasons. It could be because the server was more busy during that particular fetch hence taking more time for creating the required packfiles. It could be because the server catches packfiles and we requested something totally different.</p>
</div>

</article>
</section>
</div></div>
  </body>
</html>
