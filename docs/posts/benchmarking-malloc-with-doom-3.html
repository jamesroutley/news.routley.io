<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.forrestthewoods.com/blog/benchmarking-malloc-with-doom3/">Original</a>
    <h1>Benchmarking Malloc with Doom 3</h1>
    
    <div id="readability-page-1" class="page"><div>
            <p>This blog post began the same way as many of my posts. I nerd sniped myself.</p>

            <p>I recently read about a new audio library for games. It repeated a claim that is conventional wisdom in the audio programming world – &#34;you can&#39;t allocate or deallocate memory on the audio thread&#34;. That&#39;s a very strong statement, and I&#39;m not sure it&#39;s correct.</p>
            
            <p>Lately I&#39;ve been doing quite a bit of audio and audio-like programming. My code is efficient and does pre-allocate quite a bit. However it uses both <code>malloc</code> and <code>mutex</code>. It also happens to run great and glitch free!</p>
            
            <p>Here&#39;s my question: what is the worst-case performance for <code>malloc</code> on a modern machine in practice?</p>
            
            <p><img src="https://www.forrestthewoods.com/blog/benchmarking-malloc-with-doom3/assets/img/01.png" alt="Tim Sweeney quote on malloc"/></p><p>Source: <a href="https://twitter.com/TimSweeneyEpic/status/1526439480873328640">Twitter</a></p>

            

            

            <p>Answering performance questions is hard. The boring answer is always the same – it depends!</p>
            
            <p>How big is your allocation? What is your program&#39;s allocation pattern? Is it heavily multi-threaded? Are you a long lived server or medium lived game? It always depends.</p>

            <p>Allocating memory isn&#39;t free. Time spent on complex systems full of error prone lockless programming isn&#39;t free either. My spidey sense suggests <code>malloc</code> is cheaper than people realize.</p>

            <p>For today I&#39;m focused on games. Modern games run between 60 and 144 frames per second. One frame at 144Hz is about 7 milliseconds. That&#39;s not very many milliseconds! Except I know most games hit the allocator hard. Worst case in theory sets my computer on fire. What is it in practice?</p>

            <p>My goal isn&#39;t to come up with a singular, definitive answer. I&#39;m a big fan of napkin math. I want a ballpark guideline of when <code>malloc</code> may cause me to miss my target framerate.</p>

            

            

            <p>My first attempt at a benchmark involved allocating and freeing blocks of random size. Twitter friends correctly scolded me and said that&#39;s not good enough. I need real data with real allocation patterns and sizes.</p>

            <p>The goal is to create a &#34;journal&#34; of memory operations. It should record <code>malloc</code> and <code>free</code> operations with their inputs and outputs. Then the journal can be replayed with different allocators to compare performance.</p>

            <p>Unfortunately I don&#39;t have a suitable personal project for generating this journal. I did a quick search for open source games and the choice was obvious – Doom 3!</p>

            <p>It took some time to find a Doom 3 project that had a &#34;just works&#34; Visual Studio project. Eventually I found <a href="https://github.com/RobertBeckebans/RBDOOM-3-BFG">RBDOOM-3-BFG</a> which only took a little effort to get running.</p>

            <p>All memory allocations go through <code>Mem_Alloc16</code> and <code>Mem_Free16</code> functions defined in <a href="https://github.com/RobertBeckebans/RBDOOM-3-BFG/blob/master/neo/idlib/Heap.cpp">Heap.cpp</a>. Modifying this was trivial. I started with the simplest possible thing and wrote every allocation to disk via <code>std::fwrite</code>. It runs a solid 60fps even in debug mode. Ship it!</p>

<pre><span>void</span><span>*</span> fts_allocator<span>::</span>allocInternal(<span>const</span> <span>size_t</span> size) {
  <span>auto</span> allocRelativeTime <span>=</span> (Clock<span>::</span>now() <span>-</span> _timeBegin);

  <span>// Perform actual malloc</span>
  <span>auto</span> ptr <span>=</span> _aligned_malloc(size, <span>16</span>);

  <span>// AllocEntry = a allocSize ptr threadId timestamp</span>
  std<span>::</span>array<span>&lt;</span><span>char</span>, <span>256</span><span>&gt;</span> buf;
  <span>int</span> len <span>=</span> std<span>::</span>snprintf(
    buf.data(),
    buf.size(), 
    <span>&#34;a %lld %p %lu %lld</span><span>\n</span><span>&#34;</span>,
    size, ptr, GetCurrentThreadId(), allocRelTime.count());
  std<span>::</span>fwrite(buf.data(), <span>1</span>, len, _file);

  <span>return</span> ptr;
}
</pre>

            <p>Running <code>Doom3BFG.exe</code> now produces a file called <code>doom3_journal.txt</code>. This journal records every single <code>malloc</code> and <code>free</code> from startup to shut down. It looks like this:</p>

            <pre>a 2048 0000023101F264A0 15888 542200
a 1280 0000023101F28020 15888 1098100
a 2560 0000023101F298A0 15888 1130500
f 0000023101F28020 15888 1142000
a 3840 0000023101F2A300 15888 1146900
f 0000023101F298A0 15888 1154900
a 1280 0000023101F28020 15888 1171200
a 2560 0000023101F298A0 15888 1189500
f 0000023101F28020 15888 1191900
a 3840 0000023101F2B260 15888 1202200
f 0000023101F298A0 15888 1207900</pre>

            <p>All content for the rest of this post is derived from the same journal. It&#39;s a 420 megabyte file containing over 11,000,000 lines. Roughly 5.5 million <code>mallocs</code> and 5.5 million <code>frees</code>. It leaks 7 megabytes from 8473 <code>mallocs</code>, tsk tsk.</p>

            <p>The journal covers 7 minutes of game time. I entered the main menu, selected a level, played, died, reloaded, died again, quit to main menu, and quit to desktop. I did this a few times and each run produced very similar journals. </p>

            

            

            <p>Next, we need to write code to load and replay the journal. To do this I created a new C++ project called <code>MallocMicrobench</code>. The code can be summarized as:</p>

<pre>std<span>::</span>vector<span>&lt;</span>Entry<span>&gt;</span> journal <span>=</span> ParseJournal(<span>&#34;doom3_journal.txt&#34;</span>);
<span>for</span> (<span>auto</span><span>&amp;</span> entry <span>:</span> journal) {
  <span>// Spin until journal time</span>
  <span>while</span> (ReplayClock<span>::</span>now() <span>&lt;</span> entry.timepoint) {}

  <span>if</span> (entry.op <span>==</span> Alloc) {
    <span>// Measure malloc</span>
    <span>auto</span> allocStart <span>=</span> RdtscClock<span>::</span>now();
    <span>void</span><span>*</span> ptr <span>=</span> <span>::</span>malloc(entry.size);
    <span>auto</span> allocTime <span>=</span> RdtscClock<span>::</span>now() <span>-</span> allocStart;
  } <span>else</span> {
    <span>// Measure free</span>
    <span>auto</span> freeStart <span>=</span> RdtscClock<span>::</span>now();
    <span>::</span>free(entry.ptr);
    <span>auto</span> freeTime <span>=</span> RdtscClock<span>::</span>now() <span>-</span> freeStart;
  }
}</pre>

            <p>This snippet excludes configuration and bookkeeping. The basic idea is very simple.</p>

            <p>Running my journal through the new replay system produces the following output:</p>

<pre>Parsing log file: c:/temp/doom3_journal.txt
Running Replay

== Replay Results ==
Number of Mallocs:    5531709
Number of Frees:      5523236
Total Allocation:     2.47 gigabytes
Max Live Bytes:       330 megabytes
Average Allocation:   480 bytes
Median Allocation:    64 bytes
Average Malloc Time:  57 nanoseconds
Num Leaked Bytes:     7 megabytes

Alloc Time
Best:    21 nanoseconds
p1:      22 nanoseconds
p10:     22 nanoseconds
p25:     23 nanoseconds
p50:     31 nanoseconds
p75:     45 nanoseconds
p90:     58 nanoseconds
p95:     86 nanoseconds
p98:     192 nanoseconds
p99:     316 nanoseconds
p99.9:   3.07 microseconds
p99.99:  25.75 microseconds
p99.999: 95.01 microseconds
Worst:   200.74 microseconds</pre>

            <p>Interesting! Average <code>malloc</code> time is 57 nanoseconds. That&#39;s decent. However <code>p99.9</code> time (1 in 1000) is 2.67 microseconds. That&#39;s not great. Worst case is a whopping 200 microseconds, ouch!</p>

            <p>What does this mean for hitting 144Hz? Honestly, I don&#39;t know. There&#39;s a ton of variance. Are the slow allocations because of infrequent but large allocations? Do slow allocs occur only during a loading screen or also in the middle of gameplay? Are outliers due to OS context switches? We don&#39;t have enough information.</p>

            <p>Note: <a href="https://www.forrestthewoods.com/blog/benchmarking-malloc-with-doom3/assets/img/percentile_heapalloc_large.png">Evidence</a> <a href="https://www.forrestthewoods.com/blog/benchmarking-malloc-with-doom3/assets/img/percentile_heapalloc_zoomed_large.png">indicates</a> that on Windows the C Runtime (CRT) <code>malloc</code> is a thin wrapper around <a href="https://docs.microsoft.com/en-us/windows/win32/api/heapapi/nf-heapapi-heapalloc">HeapAlloc</a>. This post will stick with the terminology <code>malloc</code>. All replays were run in <code>Release</code> mode from a Windows console.</p>

            

            

            <p>We need to graph our replay data to make better sense of it.</p>

            <p>First, I took <code>doom3_journal.txt</code>, ran a replay, and produced a new <code>doom3_replayreport.csv</code>. This replay report contains replay timestamps and profiler time for <code>malloc</code> and <code>free</code>. It looks like this:</p>

<pre><span>replayAllocTimestamp</span>,<span>allocTime</span>,<span>allocSize</span>,<span>replayFreeTimestamp</span>,<span>freeTime</span>
<span>661500</span>,<span>375</span>,<span>2048</span>,<span>0</span>,<span>0</span>
<span>881700</span>,<span>531</span>,<span>1280</span>,<span>912000</span>,<span>254</span>
<span>911600</span>,<span>268</span>,<span>2560</span>,<span>935400</span>,<span>343</span>
<span>917500</span>,<span>261</span>,<span>3840</span>,<span>0</span>,<span>0</span>
<span>935800</span>,<span>153</span>,<span>1280</span>,<span>961800</span>,<span>101</span>
<span>961600</span>,<span>206</span>,<span>2560</span>,<span>962700</span>,<span>146</span>
<span>962000</span>,<span>248</span>,<span>3840</span>,<span>0</span>,<span>0</span>
<span>984500</span>,<span>447</span>,<span>3760</span>,<span>432968726000</span>,<span>397</span>
<span>993400</span>,<span>18980</span>,<span>3760</span>,<span>432968728400</span>,<span>758</span>
<span>1012500</span>,<span>1354</span>,<span>3760</span>,<span>432968729200</span>,<span>133</span>
<span>1013900</span>,<span>1365</span>,<span>3760</span>,<span>432968842900</span>,<span>161</span>
</pre>

            <p>To graph this data I used Python&#39;s <a href="https://matplotlib.org/">matplotlib</a>.</p>

            <p>After several failed experiments I landed on scatterplots. This looked great. Unfortunately, Python is a miserably slow language so rendering 11 million points took over 45 seconds. Yikes!</p>

            <p>A kind Twitter user pointed me towards a <code>matplotlib</code> extension called <a href="https://github.com/astrofrog/mpl-scatter-density">mpl-scatter-density</a>. This worked phenomenally well and turned 45 seconds into 3 seconds. My biggest bottleneck is now csv parsing.</p>

            <p>New tools in hand I produced this:</p>
        </div><div>

            <p>Data visualization is story telling. This story has a lot going on. Let&#39;s break it down.</p>

            <ul>
                <li>each pixel is one <code>malloc</code> or <code>free</code></li>
                <li>x-axis is replay time</li>
                <li>y-axis is <code>malloc</code>/<code>free</code> time, in <b>logarithmic scale</b></li>
                <li>pixel color is alloc size</li>
            </ul>

            <p>There are expensive <code>mallocs</code> at the very start when the game first boots. At ~30 seconds there are large and expensive  <code>mallocs</code> as the level loads. There are similar allocations when I die and reload at 2 minutes.</p>

            <p>During actual gameplay the vast majority of allocations take between 21 nanoseconds and 700 nanoseconds. Not amazing. Unfortunately there are numerous <code>mallocs</code> sprinkled between 1 and 20 microseconds. Even worse, those expensive <code>mallocs</code> are as small as just 16 bytes!</p>

            <p>Here&#39;s a zoom shot that covers the first gameplay segment.</p>
        </div><div>

            <p>All images in this post are clickable if you&#39;d like to view full-res.</p>

            

            

            <p>What can we take away from this? A few things.</p>

            <ol>
                <li>C Runtime (CRT) <code>malloc</code> is highly variable</li>
                <li><code>p90</code> <code>malloc</code> is ~60 nanoseconds</li>
                <li><code>p99.99</code> <code>malloc</code> is ~25 microseconds</li>
                <li>Worst case for gameplay is ~100 microseconds</li>
            </ol>

            <p>Is this good or bad? It sure <i>feels</i> bad. The inconsistency is frustrating. However it&#39;s important to note that my gameplay ran a rock solid 60fps!</p>

            <p>Worst degenerate case is my computer catches fire. Thus far my computer has not caught fire. Nor has <code>malloc</code> frozen my computer for seconds. Worst case for gamplay seems to be on the order of a few hundred microseconds.</p>

            <p>I&#39;m going to make a bold claim:</p>

            <p><b>You can call <code>malloc</code> and still hit real-time framerates.</b></p>

            <p>I believe this is true even if you&#39;re writing audio code that needs to compute a buffer every 4 milliseconds.</p>

            <p>The problem isn&#39;t <code>malloc</code> per se. The problem is if you call <code>malloc</code> once then you probably call it more than once. It&#39;s death by a thousand cuts. It adds up fast and once you have 1,000 calls to <code>malloc</code> it&#39;s excruciatingly difficult to unwind.</p>

            
            

            <p>Astute readers may have noticed we aren&#39;t writing to memory. This could have serious performance implications! The previous snippet was overly simplified, sorry.</p>

            <p>I ran my replay with three options.</p>

            <ol>
                <li><code>malloc</code> only</li>
                <li><code>malloc</code> + write <code>1</code> byte every <code>4096</code></li>
                <li><code>malloc</code> + <code>memset</code></li>
            </ol>

            <p>The code looks like this:</p>

<pre>    <span>auto</span> mallocStart <span>=</span> RdtscClock<span>::</span>now();
    <span>auto</span> ptr <span>=</span> Allocator<span>::</span>alloc(entry.allocSize);
<span>#if WRITE_STRATEGY == 2</span>
    <span>for</span> (<span>size_t</span> i <span>=</span> <span>0</span>; i <span>&lt;</span> allocSize; i <span>+=</span> <span>4096</span>) {
        <span>*</span><span>reinterpret_cast</span><span>&lt;</span><span>uint8_t</span><span>*&gt;</span>(ptr) <span>=</span> <span>42</span>;
    }
<span>#elif WRITE_STRATEGY == 3</span>
    std<span>::</span>memset(ptr, <span>42</span>, allocSize);
<span>#endif</span>
    <span>auto</span> mallocEnd <span>=</span> RdtscClock<span>::</span>now();
</pre>

            <p>It produces the following result:</p>
        </div><div>

            <p>On Windows the difference between &#34;write none&#34; and &#34;write byte&#34; is not tremendous. Twitter friends tell me the difference will be large on Linux, but I do not know. As a game dev I am moderately allergic to Linux.</p> 

            <p>Option 3 is just measuring <code>memset</code>. That&#39;s a whole separate conversation.</p>
            
            <p>None of these choices are a perfect match for real program behavior. This post uses option 2, &#34;write byte per <code>4096</code>&#34; as default behavior. It&#39;s a compromise.</p>

            
            
            

            <p>It is tempting to execute a replay at an accelerated pace. Waiting 7 minutes for every replay test is time consuming and annoying.</p>

            <p>My <code>MallocMicrbench</code> program supports scaling replay speed by an arbitrary rate. This is critical for testing.</p>

            <p>Unfortunately it appears that running the replay faster has a very tangible impact on performance. Therefore this post will take the time to replay at 1x. Bah hum bug.</p>

        </div><div>

            

            

            <p>We&#39;re not done yet.</p> 
            
            <p>Testing thus far has used CRT <code>malloc</code>. Now that we have a memory journal and replay system we can replay the exact sequence of allocations in different allocators.</p>

            <p>I chose five allocators to compare.</p>

            <ol>
                <li><a href="https://github.com/celskeggs/libca/blob/master/linux/dlmalloc-2.8.6/malloc-2.8.6.h">dlmalloc</a> – previously popular</li>
                <li><a href="http://jemalloc.net/">jemaloc</a> – industrial strength, tuned for long running servers</li>
                <li><a href="https://github.com/microsoft/mimalloc">mimalloc</a> – general purpose allocator by Microsoft</li>
                <li><a href="https://github.com/mjansson/rpmalloc">rpmalloc</a> – lockfree GPA by a now Epic Games employee </li>
                <li><a href="https://github.com/mattconte/tlsf">tlsf</a> – pool allocator used in some games</li>
            </ol>

            <p>Numerous other libraries were considered. Most were excluded because compiling them on Windows required too much effort. I&#39;m looking at you <code>TCMalloc</code>.</p>

            <p>The goal today is not to determine which one is &#34;best&#34;. Remember, it depends! We just want to build some more plots and see if we find anything interesting. This is an exploration.</p>

            
                
            

            <p>Let&#39;s get right to it. Here are the chosen allocators. All performed the exact same allocations, in the same order, over the same 7 minutes. </p>
        </div><div>
            <p>Play around with it. Compare allocators. Compare <code>malloc</code> vs <code>free</code>.</p>

            <p>I&#39;m happy with my scatterplots. Unfortunately rendering 5.5 million pixels on a 1200px wide plot has a lot of overlap. It obfuscates important information such as <code>p50</code> and <code>p95</code> time. It&#39;s difficult to build a plot that shows both density and outliers.</p>

            <p>To help, here&#39;s a second plot that showcases percentile time. (The <code>&gt;p90</code> plot was extremely tricky to make and I&#39;m rather proud of the result.)</p>
        </div><div>
            <p>Here are some observations.</p>

            <ol>
                <li>CRT is quite bad</li>

                <li>⚠️<code>dlmalloc</code> and <code>tlsf</code> are old and single-threaded</li>

                <li><code>jemalloc</code>, <code>mimalloc</code>, and <code>rpmalloc</code> are &#34;modern allocators&#34;</li>

                <li>Modern allocators:
                    <ul>
                        <li>Are designed for multi-threading</li>
                        <li><code>p50</code> <code>malloc</code> in under 10 nanoseconds</li>
                        <li><code>p95</code> <code>malloc</code> in ~25 nanoseconds</li>
                        <li>Worst 0.1%: 1 to 50 microseconds</li>
                        <li>Absolute Worst: ~500 microseconds</li>
                    </ul>
                </li>

                <li><code>free</code> is comparable to <code>malloc</code>
                    <ul>
                        <li>Maybe slightly faster on average</li>
                        <li>Maybe somewhat worse on worst case</li>
                        <li>Some cost is likely deferred and not measured</li>
                    </ul>
                </li>

                <li><code>tlsf</code> shines in worst case
                    <ul>
                        <li>Requires pre-allocating pool and is single-threaded.</li>
                        <li>Trade-offs!</li>
                    </ul>
                </li>
            </ol>

            <p>What did you take away from the data?</p>

            

            

            <p>This all started because of a blog post about game audio. So, can you call <code>malloc</code> in a latency sensitive game audio library?</p>

            <p>I&#39;m going to be a heretic and say yes. You shouldn&#39;t! Pre-allocating a pool of fixed size buffers is super easy. Do that instead. But you totally can call <code>malloc</code> and your computer won&#39;t catch fire and you won&#39;t glitch your device.</p>
            
            

            

            <p>This touches on a topic near and dear to my heart – latency. What we&#39;re really talking about is latency vs reliability. </p>
            
            <p>Game audio systems work on sample buffers that are on the order of a few milliseconds. If you fail to deliver a buffer in time there is an ear piercing screech.</p>

            <p>This is easy to protect against. Queue your buffers! If you need to deliver 4ms buffers then keep a full 4ms buffer in queue. This increases latency by 4ms but may increase reliability to 100%.</p>

            <p>How much latency is too much? A Reddit discussion contained a rule of thumb I like:</p>

            <ol>
                <li>2ms - works for pro audio</li>
                <li>20ms - works for gaming</li>
                <li>200ms - works for music</li>
                <li>2000ms - works for streaming</li>
            </ol>

            <p>One of my favorite YouTube channels measured end-to-end latency for game audio. Highly optimized shooters had audio latency ranging from 75 to a whopping 150 milliseconds.</p>
        </div><div>
            <p>Game audio engines should not add latency for no reason. However, if a user is experiencing 100ms latency then architecting complex systems or spending weeks to save microseconds is not the best use of your time, imho.</p>

            <p>Ultimately the ONLY thing that matters is hitting your performance target. Pick a reasonable target and do what it takes to hit it. Doom 3 hits 60fps in debug and calls <code>malloc</code> all over the place. :)</p>

            

            

            <p>There are a <b>lot</b> of limitations to this post.</p>

            <ul>
                <li>Only ran on high-end desktop</li>
                <li>Only ran on Windows</li>
                <li>Embedded / smartphones / consoles are different worlds</li>
                <li>Doom 3 originally shipped in 2004</li>
                <li>Peak live usage of just 330 megabytes</li>
                <li>Only allocated 2.47 gigabytes total</li>
                <li>Doom 3 is an extremely well optimized game!</li>
                <li>Only 2.9% of <code>frees</code> cross threads</li>
                <li>7 minutes isn&#39;t very long</li>
                <li>Tested just a single application</li>
                <li>Micro-benchmarking isn&#39;t the real world</li>
                <li><code>malloc</code> and <code>free</code> have unmeasured, deferred costs</li>
                <li>My code may have bugs</li>
                <li>Data viz is hard</li>
                <li>Context switches are not captured</li>
            </ul>

            <p>The list goes on and on. If you have a snarky gotcha you&#39;re not wrong. Add it to the list.</p>

            <p>It&#39;s also worth noting the many things this post does not even attempt to measure.</p>

            <ul>
                <li>Bookkeeping overhead</li>
                <li>Cache overhead</li>
                <li>Fragmentation</li>
                <li>and more</li>
            </ul>

            

            
            
            <p>I nerd sniped myself with a question: what is the worst-case performance for <code>malloc</code> on a modern machine in practice?</p>

            <p>I&#39;ve set myself up for failure. Anything I say here will be nitpicked. :(</p>

            <p>Here&#39;s my handwavey, napkin math, rule of thumb, rough guidelines:</p>
                
            <ul>
                <li><code>malloc</code> Performace
                    <ul>
                        <li>Minimum: ~5 nanoseconds</li>
                        <li>Median: ~25 nanoseconds</li>
                        <li>Worst 0.1%: 1 to 50 microseconds</li>
                        <li>Absolute Worst: ~500 microseconds</li>
                    </ul>
                </li>
            </ul>

            <p>There&#39;s a famous list of latency numbers called <a href="https://gist.github.com/jboner/2841832">Numbers Every Programmer Should Know</a>. It inspired me to write a blog post titled <a href="https://www.forrestthewoods.com/blog/memory-bandwidth-napkin-math/">Memory Bandwidth NapkinMath</a>. This post is a similar style, but even more handwavey because <code>malloc</code> performance is so variable.</p>

            <p>I had fun writing this. I learned things. I will personally keep these guidelines in mind when I write code.</p>

            <p>Thanks for reading.</p>

            
            
            

            <p>I spent way too much time on this post. I don&#39;t have current plans to spend more.</p> 
            
            <p>It would be interesting to run some modern games through my data viz pipeline. Doom 3 is 18 years old. I think a Battle Royale game would be fascinating because they involve level streaming, user customization, and capped match length. My e-mail address is easy to find. :)</p>

            

            

            <ul>
                <li>Journal – <a href="https://gist.github.com/forrestthewoods/9f0cbab6f05f0228bbed6e8c90e37b58">Gist</a></li>
                <li>Replay – <a href="https://github.com/forrestthewoods/MallocMicrobench/blob/main/MallocMicrobench.cpp">GitHub</a></li>
                <li>Plot – <a href="https://github.com/forrestthewoods/MallocMicrobench/blob/main/plot/plot.py">GitHub</a></li>
                <li>Data – <a href="https://www.dropbox.com/s/v3mbnfwfahu0vdq/doom3_malloc_data.7z?dl=0">Dropbox</a></li>
            </ul>
        </div></div>
  </body>
</html>
