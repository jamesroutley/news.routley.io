<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://the-decoder.com/qwen3-vl-can-scan-two-hour-videos-and-pinpoint-nearly-every-detail/">Original</a>
    <h1>Qwen3-VL can scan two-hour videos and pinpoint nearly every detail</h1>
    
    <div id="readability-page-1" class="page"><div>

			
<div>
    <div>
        
        
        <div>
            <div id="article-menu__toc">
                <svg width="20" height="24" viewBox="0 0 84 98" xmlns="http://www.w3.org/2000/svg" xml:space="preserve" fill-rule="evenodd" clip-rule="evenodd" stroke-linejoin="round" stroke-miterlimit="2">
                    <path d="m30.881 77.277 1.229.921.153-26.117V40.098c.308-4.917 4.302-8.757 9.219-8.757a9.186 9.186 0 0 1 9.218 8.91l2.611 21.355c.154 1.843-1.075 3.533-3.072 3.841-1.843.307-3.533-1.076-3.841-3.073l-2.611-21.507v-.461c0-1.229-1.076-2.304-2.304-2.304-1.229 0-2.304.921-2.304 2.304v11.675l-.153 33.184c0 1.383-.769 2.459-1.998 3.073-1.229.614-2.612.46-3.533-.308l-6.76-5.223-.153-.153c-.922-.769-4.917-3.841-8.911-1.844 1.998 2.459 5.378 6.453 9.525 10.447a3.579 3.579 0 0 1 .153 4.916c-.614.769-1.537 1.076-2.458 1.076-.922 0-1.69-.307-2.304-.921-7.528-7.068-12.291-13.673-12.444-13.981-.922-1.382-.768-3.072.307-4.301 7.219-8.451 16.436-4.15 20.431-.77v.001Zm47.011 19.664c.307 0 .614.153.768.153 1.537 0 2.919-1.076 3.38-2.611 2.611-10.446.461-21.508.461-21.969-.154-.921-.614-1.69-1.383-2.15C75.895 66.83 69.135 63.758 61.3 61.3c-1.843-.614-3.687.46-4.301 2.304-.614 1.843.461 3.687 2.304 4.301 6.605 1.998 12.291 4.455 16.745 7.374.461 3.073 1.229 10.601-.614 17.667-.615 1.691.614 3.534 2.457 3.995h.001ZM21.97 8.297a4.132 4.132 0 0 0 4.148-4.149A4.13 4.13 0 0 0 21.97 0a4.13 4.13 0 0 0-4.148 4.148 4.132 4.132 0 0 0 4.148 4.149Zm18.128 0a4.132 4.132 0 0 0 4.148-4.149A4.13 4.13 0 0 0 40.098 0a4.13 4.13 0 0 0-4.148 4.148 4.133 4.133 0 0 0 4.148 4.149Zm-35.949 0a4.132 4.132 0 0 0 4.148-4.149A4.13 4.13 0 0 0 4.149 0 4.132 4.132 0 0 0 0 4.148a4.133 4.133 0 0 0 4.149 4.149ZM21.97 25.042a4.13 4.13 0 0 0 4.148-4.148 4.132 4.132 0 0 0-4.148-4.149 4.132 4.132 0 0 0-4.148 4.149 4.13 4.13 0 0 0 4.148 4.148Zm18.128 0a4.13 4.13 0 0 0 4.148-4.148 4.132 4.132 0 0 0-4.148-4.149 4.132 4.132 0 0 0-4.149 4.149 4.133 4.133 0 0 0 4.149 4.148Zm-35.95 0a4.132 4.132 0 0 0 4.149-4.148 4.132 4.132 0 0 0-4.149-4.149A4.132 4.132 0 0 0 0 20.894a4.13 4.13 0 0 0 4.148 4.148ZM21.97 41.787a4.13 4.13 0 0 0 4.148-4.148 4.13 4.13 0 0 0-4.148-4.148 4.132 4.132 0 0 0-4.149 4.148 4.132 4.132 0 0 0 4.149 4.148Zm-17.822 0a4.132 4.132 0 0 0 4.149-4.148 4.132 4.132 0 0 0-4.149-4.148A4.13 4.13 0 0 0 0 37.639a4.13 4.13 0 0 0 4.148 4.148ZM21.97 58.379a4.13 4.13 0 0 0 4.148-4.148 4.13 4.13 0 0 0-4.148-4.148 4.132 4.132 0 0 0-4.149 4.148 4.132 4.132 0 0 0 4.149 4.148Z" fill="#fbfbfb" fill-rule="nonzero"></path>
                </svg>
                <p><span>Content</span>
            </p></div>
            <svg width="100%" height="100%">
                <filter id="roughpaper-29499" x="0%" y="0%" width="100%" height="100%">
                    <feTurbulence baseFrequency="0.004" seed="10" result="noise"></feTurbulence>
                    <feDiffuseLighting in="noise" lighting-color="white" surfaceScale="3.5">
                        <feDistantLight azimuth="140" elevation="8"></feDistantLight>
                    </feDiffuseLighting>
                </filter>
                <rect x="0" y="0" width="100%" height="100%" filter="url(#roughpaper-29499)" fill="none"></rect>
            </svg>
            
        </div>
    </div>
</div>
			
						<p><strong>A few months after launching Qwen3-VL, Alibaba has released a detailed technical report on the open multimodal model. The data shows the system excels at image-based math tasks and can analyze hours of video footage.</strong></p><div><p>Ad</p>
    <div>
        <div>
            
        </div>
            </div>
    </div>
<p>The system handles massive data loads, processing two-hour videos or hundreds of document pages within a 256,000-token context window.</p>
<p>In &#34;needle-in-a-haystack&#34; tests, the flagship 235-billion-parameter model located individual frames in 30-minute videos with 100 percent accuracy. Even in two-hour videos containing roughly one million tokens, accuracy held at 99.5 percent. The test works by inserting a semantically important &#34;needle&#34; frame at random positions in long videos, which the system must then find and analyze.</p>
<div><figure id="attachment_29500" aria-describedby="caption-attachment-29500"><img data-lazyloaded="1" src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxNjg4IiBoZWlnaHQ9IjYyOCIgdmlld0JveD0iMCAwIDE2ODggNjI4Ij48cmVjdCB3aWR0aD0iMTAwJSIgaGVpZ2h0PSIxMDAlIiBzdHlsZT0iZmlsbDojZjJmMmYyO2ZpbGwtb3BhY2l0eTogMC4xOyIvPjwvc3ZnPg==" fetchpriority="high" decoding="async" data-src="https://the-decoder.com/wp-content/uploads/2025/11/Qwen3-VL-Needle-in-a-Haystack.jpg" alt="Heatmap mit Video-Längen auf der y-Achse und Frame-Positionen auf der x-Achse. Die meisten Zellen zeigen hohe Genauigkeitswerte in Prozent, mit perfekten Ergebnissen bei kürzeren Videos." width="1688" height="628"/><figcaption id="caption-attachment-29500">The needle-in-a-haystack test measures the model&#39;s ability to locate specific frames in long videos. | Image: Alibaba</figcaption></figure>
</div>
<p>In published benchmarks, the Qwen3-VL-235B-A22B model often beats Gemini 2.5 Pro, OpenAI GPT-5, and Claude Opus 4.1 - even when competitors use reasoning features or high thinking budgets. The model dominates visual math tasks, scoring 85.8 percent on MathVista compared to GPT-5&#39;s 81.3 percent. On MathVision, it leads with 74.6 percent, ahead of Gemini 2.5 Pro (73.3 percent) and GPT-5 (65.8 percent).</p><div><p>Ad</p>
    <div>
        <div>
            
        </div>
            </div>
    </div><div><p>Ad</p>
    <div>
        <div>
            
        </div>
                    <div>
                                        <div>
        <svg width="40" height="38" viewBox="0 0 167 160" xmlns="http://www.w3.org/2000/svg" xml:space="preserve" fill-rule="evenodd" clip-rule="evenodd" stroke-linejoin="round" stroke-miterlimit="2">
            <path d="M103.175 86.95c-5.101-5.101-12.187-7.937-19.558-7.937-7.37 0-14.173 2.835-19.559 7.937l-6.519 6.518-47.052-31.745c-1.701-1.133-3.686-1.418-5.669-.85-1.985.567-3.4 1.985-3.968 3.968C.283 66.258 0 67.676 0 69.092v77.948c0 3.4 1.418 6.518 3.685 8.786 1.133 1.133 2.836 1.985 4.536 1.985 1.7 0 3.118-.567 4.536-1.985 0 0 0-.283.282-.283l59.808-59.807c2.835-2.835 6.518-4.251 10.487-4.251 3.968 0 7.653 1.418 10.487 4.251l51.02 51.02H37.131c-3.4 0-6.235 2.836-6.235 6.236 0 3.401 2.835 6.236 6.235 6.236h117.064c3.401 0 6.519-1.418 8.786-3.685 2.268-2.268 3.686-5.386 3.686-8.787l-.002-77.664c0-1.985-.568-4.251-1.418-5.954-.85-1.417-1.7-2.55-3.118-3.685L98.07 5.315c-8.504-7.087-20.408-7.087-28.912 0L20.972 45.849c-2.55 2.267-3.118 6.235-.85 9.071 2.268 2.55 6.236 3.118 9.072.85l48.185-40.532c3.685-3.118 9.071-3.118 12.472 0l53.855 45.068 6.803 5.668L125 83.264c-2.835 1.985-3.685 5.954-1.7 8.787 1.133 1.7 3.118 2.835 5.386 2.835 1.133 0 2.55-.283 3.685-1.133L154.48 78.73v59.524L103.175 86.95ZM48.47 102.54l-35.431 35.431V78.73l35.431 23.81Z" fill="#28293d" fill-rule="nonzero"></path>
        </svg>
        <div>
            <p>THE DECODER Newsletter</p>
            <p>The most important AI news straight to your inbox.</p>
            <p>✓ Weekly</p>
            <p>✓ Free</p>
            <p>✓ Cancel at any time</p>
            <div>
                  
  
  
  <div id="mailpoet_form_1">

    

    <form target="_self" method="post" action="https://the-decoder.com/wp-admin/admin-post.php?action=mailpoet_subscription_form" novalidate="" data-delay="" data-exit-intent-enabled="" data-font-family="" data-cookie-expiration-time="">
      
      
      
      
      

      


      <div>
        
        
      </div>
    </form>

      </div>

              </div>
        </div>
    </div>

                            </div>
            </div>
    </div>
<figure id="attachment_29501" aria-describedby="caption-attachment-29501"><img data-lazyloaded="1" src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxMzg2IiBoZWlnaHQ9IjY1MiIgdmlld0JveD0iMCAwIDEzODYgNjUyIj48cmVjdCB3aWR0aD0iMTAwJSIgaGVpZ2h0PSIxMDAlIiBzdHlsZT0iZmlsbDojZjJmMmYyO2ZpbGwtb3BhY2l0eTogMC4xOyIvPjwvc3ZnPg==" decoding="async" data-src="https://the-decoder.com/wp-content/uploads/2025/11/Qwen3-VL-Benchmarks-Comparison.jpg" alt="Tabelle mit Benchmark-Ergebnissen von Qwen3-VL-235B, Gemini 2.5 Pro, OpenAI GPT-5 und Claude Opus 4.1" width="1386" height="652"/><figcaption id="caption-attachment-29501">Gemini&#39;s older 2.5 Pro model maintains a slight lead in general image understanding. | Image: Alibaba</figcaption></figure>
<p>The model also shows range in specialized benchmarks. It scored 96.5 percent on the DocVQA document comprehension test and 875 points on OCRBench, supporting 39 languages - nearly four times as many as its predecessor.</p>
<figure id="attachment_29502" aria-describedby="caption-attachment-29502"><img data-lazyloaded="1" src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxOTIwIiBoZWlnaHQ9IjEwNzUiIHZpZXdCb3g9IjAgMCAxOTIwIDEwNzUiPjxyZWN0IHdpZHRoPSIxMDAlIiBoZWlnaHQ9IjEwMCUiIHN0eWxlPSJmaWxsOiNmMmYyZjI7ZmlsbC1vcGFjaXR5OiAwLjE7Ii8+PC9zdmc+" decoding="async" data-src="https://the-decoder.com/wp-content/uploads/2025/11/Qwen3-VL-Multilingual-OCR-Support.jpg" alt="Balkendiagramm der OCR-Genauigkeit von Qwen3-VL für 39 Sprachen, wobei die meisten Balken über der 70-Prozent-Marke liegen." width="1920" height="1075"/><figcaption id="caption-attachment-29502">Qwen3-VL achieves over 70 percent accuracy on OCR tasks in 32 of the 39 supported languages. | Image: Alibaba</figcaption></figure>
<p>Alibaba claims the system demonstrates new capabilities in GUI agent tasks. It achieved 61.8 percent accuracy on ScreenSpot Pro, which tests navigation in graphical user interfaces. On AndroidWorld, where the system must independently operate Android apps, Qwen3-VL-32B hit 63.7 percent.</p>
<p>The model handles complex, multi-page PDF documents as well. It scored 56.2 percent on MMLongBench-Doc for long document analysis. On the CharXiv benchmark for scientific charts, it reached 90.5 percent on description tasks and 66.2 percent on complex reasoning questions.</p>
<p>It is not a clean sweep, however. In the complex MMMU-Pro test, Qwen3-VL scored 69.3 percent, trailing GPT-5&#39;s 78.4 percent. Commercial competitors also generally lead in video QA benchmarks. The data suggests Qwen3-VL is a specialist in visual math and documents, but still lags in general reasoning.</p>
<h2>Key technical advances for multimodal AI</h2>
<p>The technical report outlines three main architectural upgrades. First, &#34;interleaved MRoPE&#34; replaces the previous position embedding method. Instead of grouping mathematical representations by dimension (time, horizontal, vertical), the new approach distributes them evenly across all available mathematical areas. This change aims to boost performance on long videos.</p><div><p>Recommendation</p>


<div>
    <div>
        
    </div>

    
                <div>
                                            <div>
                            <div>
                                                                    <p><a href="https://the-decoder.com/artificial-intelligence-news/ai-research/" rel="category tag">AI research</a>
                                                                                            </p></div>
                                                    </div>
                    


                    <h2><a href="https://the-decoder.com/deepseeks-latest-r1-zero-model-matches-openais-o1-in-reasoning-benchmarks/" rel="bookmark">DeepSeek&#39;s latest R1 model matches OpenAI&#39;s o1 in reasoning benchmarks</a></h2>
                                            <p><a href="https://the-decoder.com/deepseeks-latest-r1-zero-model-matches-openais-o1-in-reasoning-benchmarks/" aria-hidden="true" tabindex="-1">

																			<img data-lazyloaded="1" src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzNzUiIGhlaWdodD0iMjEwIiB2aWV3Qm94PSIwIDAgMzc1IDIxMCI+PHJlY3Qgd2lkdGg9IjEwMCUiIGhlaWdodD0iMTAwJSIgc3R5bGU9ImZpbGw6I2YyZjJmMjtmaWxsLW9wYWNpdHk6IDAuMTsiLz48L3N2Zz4=" data-src="https://the-decoder.com/wp-content/uploads/2025/01/DeepSeek-R1-OpenAI-title-375x210.png" loading="lazy" alt="DeepSeek&#39;s latest R1 model matches OpenAI&#39;s o1 in reasoning benchmarks" width="375" height="210"/>
							</a>

                        </p>
                    
                </div>


                

            <div>
            <p><a href="https://the-decoder.com/deepseeks-latest-r1-zero-model-matches-openais-o1-in-reasoning-benchmarks/" aria-hidden="true" tabindex="-1">

																			<img data-lazyloaded="1" src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIzNzUiIGhlaWdodD0iMjEwIiB2aWV3Qm94PSIwIDAgMzc1IDIxMCI+PHJlY3Qgd2lkdGg9IjEwMCUiIGhlaWdodD0iMTAwJSIgc3R5bGU9ImZpbGw6I2YyZjJmMjtmaWxsLW9wYWNpdHk6IDAuMTsiLz48L3N2Zz4=" data-src="https://the-decoder.com/wp-content/uploads/2025/01/DeepSeek-R1-OpenAI-title-375x210.png" loading="lazy" alt="DeepSeek&#39;s latest R1 model matches OpenAI&#39;s o1 in reasoning benchmarks" width="375" height="210"/>
							</a>

            </p>
        </div>
    </div></div>
<figure id="attachment_29503" aria-describedby="caption-attachment-29503"><img data-lazyloaded="1" src="data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHdpZHRoPSIxOTIwIiBoZWlnaHQ9IjExMDkiIHZpZXdCb3g9IjAgMCAxOTIwIDExMDkiPjxyZWN0IHdpZHRoPSIxMDAlIiBoZWlnaHQ9IjEwMCUiIHN0eWxlPSJmaWxsOiNmMmYyZjI7ZmlsbC1vcGFjaXR5OiAwLjE7Ii8+PC9zdmc+" decoding="async" data-src="https://the-decoder.com/wp-content/uploads/2025/11/Qwen3-VL-Architecture.jpg" alt="Schematische Darstellung der Qwen3-VL-Architektur mit Vision Encoder links und Large Language Model rechts, verbunden durch Datenflüsse und DeepStack-Verbindungen." width="1920" height="1109"/><figcaption id="caption-attachment-29503">Qwen3-VL combines a vision encoder and language model to process text, images, and videos simultaneously. DeepStack uses visual information from different processing levels. | Image: Alibaba</figcaption></figure>
<p>Second, DeepStack technology allows the model to access intermediate results from the vision encoder, not just the final output. This gives the system access to visual information at different levels of detail.</p>
<p>Third, a text-based timestamp system replaces the complex T-RoPE method found in Qwen2.5-VL. Instead of assigning a mathematical time position to every video frame, the system now inserts simple text markers like &#34;&lt;3.8 seconds&gt;&#34; directly into the input. This simplifies the process and improves the model&#39;s grasp of time-based video tasks.</p>
<h2>Training at scale with one trillion tokens</h2>
<p>Alibaba trained the model in four phases on up to 10,000 GPUs. After learning to link images and text, the system underwent full multimodal training on about one trillion tokens. Data sources included web scrapes, 3 million PDFs from Common Crawl, and over 60 million STEM tasks.</p>
<p>In later phases, the team gradually expanded the context window from 8,000 to 32,000 and finally to 262,000 tokens. The &#34;Thinking&#34; variants received specific chain-of-thought training, allowing them to explicitly map out reasoning steps for better results on complex problems.</p><div><p>Ad</p>
    <div>
        <div>
            
        </div>
            </div>
    </div><div><p>Ad</p>
    <div>
        <div>
            
        </div>
                    <div>
                                    
<div>
    <svg width="40" height="35.44" viewBox="0 0 167 145" xmlns="http://www.w3.org/2000/svg" xml:space="preserve" fill-rule="evenodd" clip-rule="evenodd" stroke-linejoin="round" stroke-miterlimit="2">
        <path d="M59.427 135.123c.81-3.166 3.781-5.277 7.293-4.486 5.402 1.055 11.076 1.583 16.748 1.583 39.167 0 71.042-26.919 71.042-60.171 0-33.253-31.875-60.172-71.042-60.172S12.425 38.796 12.425 72.049c0 13.724 5.402 26.654 15.667 37.475 1.621 1.583 1.892 3.958 1.351 6.069-1.62 4.487-4.051 8.181-6.753 11.613 4.861-.263 10.804-1.583 16.209-4.749 2.971-1.584 6.483-.792 8.373 2.111 1.62 2.903.81 6.334-2.161 8.181-12.696 7.389-26.472 6.861-33.496 6.069-3.782-.791-6.482-3.166-7.292-6.334-.81-3.166.541-6.598 3.512-8.446 3.512-2.375 6.484-5.543 8.373-9.501C5.674 102.133 0 87.354 0 72.048.269 32.463 37.547 0 83.468 0c45.922 0 83.199 32.461 83.199 72.048s-37.278 72.047-83.199 72.047c-6.483 0-12.965-.792-19.449-1.848-3.24-.79-5.132-3.958-4.591-7.124h-.001Zm58.346-79.965c3.241 0 5.943-2.639 5.943-5.806 0-3.166-2.702-5.806-5.943-5.806H99.675c-3.241 0-5.943 2.64-5.943 5.806 0 3.167 2.702 5.806 5.943 5.806h18.098ZM78.065 43.283H49.161c-3.241 0-5.943 2.64-5.943 5.806s2.702 5.806 5.943 5.806h28.904c3.241 0 5.943-2.64 5.943-5.806 0-3.168-2.702-5.806-5.943-5.806Zm2.431 28.766c0 3.166 2.702 5.806 5.943 5.806h31.335c3.24 0 5.942-2.64 5.942-5.806s-2.702-5.806-5.942-5.806H86.439c-3.241 0-5.943 2.64-5.943 5.806Zm-31.335 5.806h15.667c3.241 0 5.943-2.64 5.943-5.806s-2.702-5.806-5.943-5.806H49.161c-3.241 0-5.943 2.64-5.943 5.806s2.433 5.806 5.943 5.806Zm68.612 11.084h-10.266c-3.241 0-5.942 2.64-5.942 5.806s2.702 5.806 5.942 5.806h10.266c3.24 0 5.942-2.64 5.942-5.806.27-3.166-2.432-5.806-5.942-5.806Zm-68.612 11.876h36.737c3.241 0 5.943-2.64 5.943-5.807 0-3.166-2.702-5.806-5.943-5.806H49.161c-3.241 0-5.943 2.64-5.943 5.806-.269 3.169 2.433 5.807 5.943 5.807Z" fill="#28293d" fill-rule="nonzero"></path>
    </svg>
    <div>
        <p>Join our community</p>
        <p>Join the DECODER community on Discord, Reddit or Twitter - we can&#39;t wait to meet you.</p>
        <div>
    <a href="https://discord.gg/8VKkHAacn8" title="Discord" target="_blank" rel="noopener noreferrer">
        <svg width="30" height="30" viewBox="0 0 125 125" xmlns="http://www.w3.org/2000/svg" xml:space="preserve" fill-rule="evenodd" clip-rule="evenodd" stroke-linejoin="round" stroke-miterlimit="2">
            <path d="M62.5 0C96.995 0 125 28.005 125 62.5c0 34.495-28.005 62.5-62.5 62.5C28.005 125 0 96.995 0 62.5 0 28.005 28.005 0 62.5 0Zm30.322 34.681a72.201 72.201 0 0 0-17.81-5.524.272.272 0 0 0-.286.136c-.769 1.368-1.621 3.152-2.218 4.555-6.725-1.007-13.416-1.007-20.004 0-.596-1.434-1.479-3.187-2.252-4.555a.281.281 0 0 0-.286-.136 72.005 72.005 0 0 0-17.811 5.524.26.26 0 0 0-.117.101C20.695 51.729 17.587 68.26 19.112 84.586a.295.295 0 0 0 .113.204c7.485 5.497 14.734 8.833 21.849 11.045a.282.282 0 0 0 .307-.101 51.745 51.745 0 0 0 4.47-7.27.277.277 0 0 0-.151-.386 47.699 47.699 0 0 1-6.826-3.253.28.28 0 0 1-.028-.465 37.58 37.58 0 0 0 1.356-1.063.27.27 0 0 1 .283-.038c14.32 6.538 29.823 6.538 43.974 0a.27.27 0 0 1 .286.035c.438.361.897.722 1.359 1.066a.28.28 0 0 1-.024.465 44.852 44.852 0 0 1-6.829 3.25.28.28 0 0 0-.148.389 58.267 58.267 0 0 0 4.466 7.267.277.277 0 0 0 .307.104c7.149-2.212 14.399-5.548 21.883-11.045a.278.278 0 0 0 .114-.201c1.825-18.874-3.056-35.269-12.937-49.803a.22.22 0 0 0-.114-.105ZM47.99 74.645c-4.312 0-7.864-3.958-7.864-8.819 0-4.861 3.483-8.819 7.864-8.819 4.414 0 7.932 3.993 7.863 8.819 0 4.861-3.483 8.819-7.863 8.819Zm29.074 0c-4.311 0-7.863-3.958-7.863-8.819 0-4.861 3.483-8.819 7.863-8.819 4.415 0 7.933 3.993 7.864 8.819 0 4.861-3.449 8.819-7.864 8.819Z" fill="#28293d"></path>
        </svg>
    </a>
    <a href="https://twitter.com/TheDecoderEN" title="Twitter" target="_blank" rel="noopener noreferrer">
        <svg width="30" height="30" viewBox="0 0 125 125" xmlns="http://www.w3.org/2000/svg" xml:space="preserve" fill-rule="evenodd" clip-rule="evenodd" stroke-linejoin="round" stroke-miterlimit="2">
            <path d="M125 62.5c0 34.518-27.982 62.5-62.501 62.5C27.981 125 0 97.018 0 62.5S27.981 0 62.499 0C97.018 0 125 27.982 125 62.5ZM49.869 98.495c30.529 0 47.224-25.289 47.224-47.219 0-.719-.019-1.434-.047-2.145a33.766 33.766 0 0 0 8.278-8.593 33.154 33.154 0 0 1-9.528 2.612 16.655 16.655 0 0 0 7.297-9.181 33.3 33.3 0 0 1-10.537 4.029 16.599 16.599 0 0 0-12.121-5.243c-9.166 0-16.592 7.432-16.592 16.594 0 1.303.139 2.57.425 3.784-13.797-.693-26.018-7.297-34.203-17.339a16.543 16.543 0 0 0-2.25 8.341 16.568 16.568 0 0 0 7.389 13.815 16.46 16.46 0 0 1-7.519-2.077c-.009.07-.009.139-.009.212 0 8.038 5.722 14.748 13.315 16.271a16.547 16.547 0 0 1-7.491.284c2.111 6.593 8.241 11.392 15.5 11.527a33.284 33.284 0 0 1-20.611 7.103c-1.333 0-2.658-.076-3.954-.229a46.977 46.977 0 0 0 25.434 7.454Z" fill="#28293d"></path>
        </svg>
    </a>
    <a href="https://www.facebook.com/THEDECODERAI/" title="Facebook" target="_blank" rel="noopener noreferrer">
        <svg width="30" height="30" viewBox="0 0 125 125" xmlns="http://www.w3.org/2000/svg" xml:space="preserve" fill-rule="evenodd" clip-rule="evenodd" stroke-linejoin="round" stroke-miterlimit="2">
            <path d="M52.735 124.24C22.871 119.546 0 93.673 0 62.5 0 28.005 28.005 0 62.5 0 96.995 0 125 28.005 125 62.5c0 31.173-22.871 57.046-52.735 61.74V80.571h14.564L89.597 62.5H72.265V50.775c0-4.939 2.417-9.765 10.186-9.765h7.884V25.629s-7.154-1.221-13.992-1.221c-14.274 0-23.608 8.648-23.608 24.319V62.5H36.862v18.071h15.873v43.669Z" fill="#28293d"></path>
        </svg>
    </a>
    <a href="https://www.reddit.com/r/TheDecoder/" title="Reddit" target="_blank" rel="noopener noreferrer">
        <svg width="30" height="30" viewBox="0 0 125 125" xmlns="http://www.w3.org/2000/svg" xml:space="preserve" fill-rule="evenodd" clip-rule="evenodd" stroke-linejoin="round" stroke-miterlimit="2">
            <path d="M62.5 0C96.995 0 125 28.005 125 62.5c0 34.495-28.005 62.5-62.5 62.5C28.005 125 0 96.995 0 62.5 0 28.005 28.005 0 62.5 0Zm41.692 62.5c0-5.072-4.103-9.099-9.1-9.099-2.461 0-4.698.97-6.339 2.536-6.265-4.475-14.842-7.384-24.388-7.757l4.176-19.54 13.574 2.908a6.486 6.486 0 0 0 6.489 6.191 6.493 6.493 0 0 0 6.488-6.489 6.493 6.493 0 0 0-6.488-6.489 6.487 6.487 0 0 0-5.818 3.655l-15.14-3.207c-.447-.075-.895 0-1.193.224-.373.223-.597.596-.671 1.044l-4.624 21.778c-9.696.298-18.422 3.207-24.762 7.756a9.161 9.161 0 0 0-6.339-2.535c-5.072 0-9.099 4.102-9.099 9.099 0 3.729 2.237 6.861 5.37 8.278-.15.895-.224 1.79-.224 2.76 0 14.021 16.333 25.432 36.471 25.432 20.137 0 36.47-11.336 36.47-25.432 0-.895-.074-1.865-.223-2.76a9.187 9.187 0 0 0 5.37-8.353ZM78.013 86.217c-4.475 4.475-12.977 4.773-15.438 4.773-2.536 0-11.039-.372-15.439-4.773a1.666 1.666 0 0 1 0-2.386 1.665 1.665 0 0 1 2.387 0c2.834 2.834 8.8 3.803 13.052 3.803 4.251 0 10.292-.969 13.051-3.803a1.665 1.665 0 0 1 2.387 0 1.813 1.813 0 0 1 0 2.386ZM76.82 75.552a6.494 6.494 0 0 1-6.489-6.489 6.493 6.493 0 0 1 6.489-6.488 6.492 6.492 0 0 1 6.488 6.488c0 3.506-2.908 6.489-6.488 6.489Zm-35.128-6.563A6.493 6.493 0 0 1 48.18 62.5a6.494 6.494 0 0 1 6.489 6.489 6.493 6.493 0 0 1-6.489 6.488c-3.58.075-6.488-2.908-6.488-6.488Z" fill="#28293d"></path>
        </svg>
    </a>
    <a href="https://www.linkedin.com/company/the-decoder-en/" title="LinkedIn" target="_blank" rel="noopener noreferrer">
        <svg width="30" height="30" viewBox="0 0 125 125" xmlns="http://www.w3.org/2000/svg" xml:space="preserve" fill-rule="evenodd" clip-rule="evenodd" stroke-linejoin="round" stroke-miterlimit="2">
            <path d="M62.5 0C96.995 0 125 28.005 125 62.5c0 34.495-28.005 62.5-62.5 62.5C28.005 125 0 96.995 0 62.5 0 28.005 28.005 0 62.5 0Zm39.931 98.958H86.735V72.225c0-7.329-2.785-11.425-8.586-11.425-6.311 0-9.609 4.262-9.609 11.425v26.733H53.414V48.032H68.54v6.86s4.548-8.415 15.355-8.415c10.802 0 18.536 6.596 18.536 20.238v32.243Zm-74.872 0h15.772V48.032H27.559v50.926Zm7.81-57.594c-5.152 0-9.327-4.208-9.327-9.397 0-5.19 4.175-9.398 9.327-9.398s9.325 4.208 9.325 9.398c0 5.189-4.173 9.397-9.325 9.397Z" fill="#28293d"></path>
        </svg>
    </a>
</div>    </div>
</div>                            </div>
            </div>
    </div>
<h2>Open weights under Apache 2.0</h2>
<p>All <a href="https://the-decoder.com/open-source-qwen3-vl-outperforms-gemini-2-5-pro-in-major-vision-benchmarks-alibaba-reports/">Qwen3-VL models</a> released since September are available under the Apache 2.0 license with open weights <a target="_blank" rel="noopener" href="https://huggingface.co/collections/Qwen/qwen3-vl">on Hugging Face</a>. The lineup includes dense variants ranging from 2B to 32B parameters, as well as mixture-of-experts models: the 30B-A3B and the massive 235B-A22B.</p>
<p>While features like extracting frames from long videos aren&#39;t new - Google&#39;s Gemini 1.5 Pro handled this in early 2024 - Qwen3-VL offers competitive performance in an open package. With the previous Qwen2.5-VL already common in research, the new model is likely to drive further open-source development.</p>
		</div></div>
  </body>
</html>
