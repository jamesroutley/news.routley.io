<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://simonwillison.net/2025/Aug/29/lossy-encyclopedia/">Original</a>
    <h1>An LLM is a lossy encyclopedia</h1>
    
    <div id="readability-page-1" class="page"><div>


<div>

<p>Since I love collecting questionable analogies for LLMs, here&#39;s a new one I just came up with: an LLM is <strong>a lossy encyclopedia</strong>. They have a huge array of facts compressed into them but that compression is lossy (see also <a href="https://www.newyorker.com/tech/annals-of-technology/chatgpt-is-a-blurry-jpeg-of-the-web">Ted Chiang</a>).</p>
<p>The key thing is to develop an intuition for questions it can usefully answer vs questions that are at a level of detail where the lossiness matters.</p>
<p>This thought sparked by <a href="https://news.ycombinator.com/item?id=45058688#45060519">a comment</a> on Hacker News asking why an LLM couldn&#39;t &#34;Create a boilerplate Zephyr project skeleton, for Pi Pico with st7789 spi display drivers configured&#34;. That&#39;s more of a lossless encyclopedia question!</p>
<p>My <a href="https://news.ycombinator.com/item?id=45058688#45060709">answer</a>:</p>
<blockquote>
<p>The way to solve this particular problem is to make a correct example available to it. Don&#39;t expect it to just know extremely specific facts like that - instead, treat it as a tool that can act on facts presented to it.</p>
</blockquote>
</div>




</div></div>
  </body>
</html>
