<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://developer.apple.com/videos/play/tech-talks/111375">Original</a>
    <h1>GPU advancements in M3 and A17 Pro [video]</h1>
    
    <div id="readability-page-1" class="page"><div data-supplement-id="transcript" data-shortcut-base-url="/videos/play/tech-talks/111375/">
							<section>
								<p><span id="get-transcript">Download</span></p>
								<p><span><span data-start="0.0">Welcome, my name is Jedd Haberstro, </span></span><span><span data-start="3.0">and I&#39;m an Engineer in Apple&#39;s GPU, Graphics, </span></span><span><span data-start="6.0">and Displays Software Group.</span></span></p><p><span><span data-start="9.0">I&#39;m excited to tell you </span></span><span><span data-start="10.0">about the new Apple family 9 GPU architecture </span></span><span><span data-start="14.0">in A17 Pro and the M3 family of chips, </span></span><span><span data-start="17.0">which are at the heart of iPhone 15 Pro and the new Max.</span></span></p><p><span><span data-start="23.0">Across Apple&#39;s product line, </span></span><span><span data-start="25.0">the GPU powers many of the rich user experiences </span></span><span><span data-start="28.0">our customers love. </span></span><span><span data-start="30.0">Whether it be gaming on the go with the new iPhone 15 Pro, </span></span><span><span data-start="36.0">delivering silky smooth UI animations for your apps </span></span><span><span data-start="39.0">on the new iMac, </span></span><span><span data-start="41.0">or leveraging machine learning </span></span><span><span data-start="43.0">to perform advanced video and image processing </span></span><span><span data-start="46.0">on the new MacBook Pros, </span></span><span><span data-start="49.0">the GPU plays a critical role in enabling these apps.</span></span></p><p><span><span data-start="55.0">The Metal API is used to harness the computing capabilities </span></span><span><span data-start="59.0">of Apple&#39;s GPUs, </span></span><span><span data-start="60.0">and collectively, these apps run a diverse set </span></span><span><span data-start="63.0">of Metal Shading Language programs. </span></span><span><span data-start="66.0">These shader programs can range from small, simple shaders </span></span><span><span data-start="70.0">that execute just a handful of lines of code </span></span><span><span data-start="73.0">to large complex shaders </span></span><span><span data-start="75.0">that spend hundreds of thousands of lines of code, </span></span><span><span data-start="78.0">frameworks, and libraries. </span></span><span><span data-start="80.0">What all these shaders share in common </span></span><span><span data-start="83.0">is massive data parallelism, </span></span><span><span data-start="86.0">which is the opportunity </span></span><span><span data-start="87.0">to greatly improve the performance of an app </span></span><span><span data-start="89.0">by running it in parallel. </span></span><span><span data-start="91.0">This parallelism is achieved </span></span><span><span data-start="93.0">by running Metal shader programs many times over in parallel </span></span><span><span data-start="97.0">on different inputs </span></span><span><span data-start="98.0">such as each vertex in a 3D rendered scene </span></span><span><span data-start="102.0">or each pixel of the screen.</span></span></p><p><span><span data-start="106.0">It is the GPU, ultimately, </span></span><span><span data-start="108.0">which is responsible for executing these shaders </span></span><span><span data-start="111.0">in parallel.</span></span></p><p><span><span data-start="114.0">At the heart of every GPU are its shader cores. </span></span><span><span data-start="117.0">Each shader core can run thousands of threads in parallel. </span></span><span><span data-start="121.0">And to scale performance even further, </span></span><span><span data-start="123.0">a GPU will have many shader cores </span></span><span><span data-start="125.0">that can also run in parallel, </span></span><span><span data-start="127.0">giving an app tens of thousands </span></span><span><span data-start="129.0">of parallel threads of execution.</span></span></p><p><span><span data-start="132.0">Already, the GPUs in today&#39;s existing iPhones, iPads, </span></span><span><span data-start="136.0">and Macs, have incredible performance.</span></span></p><p><span><span data-start="140.0">As well as a powerful suite of developer tools </span></span><span><span data-start="143.0">to allow app developers to maximize the GPU&#39;s potential. </span></span><span><span data-start="147.0">But with the new Apple family 9 GPUs, </span></span><span><span data-start="150.0">we are increasing performance to unprecedented levels </span></span><span><span data-start="153.0">thanks to several new exciting advancements.</span></span></p><p><span><span data-start="157.0">First is a brand new shader core architecture </span></span><span><span data-start="161.0">that improves the performance and power efficiency </span></span><span><span data-start="163.0">of your existing apps, </span></span><span><span data-start="165.0">which, right away, benefits the experience you deliver </span></span><span><span data-start="168.0">while also meeting the demanding challenges </span></span><span><span data-start="171.0">of the next-generation of apps that you will build.</span></span></p><p><span><span data-start="175.0">Hardware-accelerated ray tracing transparently benefits apps </span></span><span><span data-start="180.0">that already use Metal&#39;s ray tracing APIs, </span></span><span><span data-start="183.0">as well as expands the opportunities to use ray tracing </span></span><span><span data-start="186.0">to achieve rich rendering effects with great performance.</span></span></p><p><span><span data-start="191.0">And with hardware-accelerated mesh shading, </span></span><span><span data-start="193.0">apps can build advanced geometry processing pipelines </span></span><span><span data-start="196.0">like never before.</span></span></p><p><span><span data-start="199.0">Before we discuss these in more detail, </span></span><span><span data-start="201.0">let&#39;s look at the incredible performance </span></span><span><span data-start="204.0">apps are already able to achieve </span></span><span><span data-start="206.0">with no changes on the new Apple family 9 GPUs. </span></span><span><span data-start="210.0">This is &#34;Baldur&#39;s Gate 3&#34; by Larian Studios, </span></span><span><span data-start="214.0">running on the new MacBook Pro with M3 Max pictured on top, </span></span><span><span data-start="218.0">and a MacBook Pro with M2 Max pictured on bottom. </span></span><span><span data-start="221.0">Each rendering with ultra video quality settings at 1800p. </span></span><span><span data-start="226.0">The M3 Max is able to deliver </span></span><span><span data-start="228.0">significant performance improvements, </span></span><span><span data-start="230.0">thanks to the next-generation shader core&#39;s ability </span></span><span><span data-start="233.0">to run the game&#39;s Metal shaders </span></span><span><span data-start="234.0">with higher thread occupancy. </span></span><span><span data-start="237.0">Here is Blender rendering an image of a barbershop scene </span></span><span><span data-start="241.0">using the Cycles Path Tracer, </span></span><span><span data-start="243.0">which leverages Metal Ray Tracing on M3 Max. </span></span><span><span data-start="246.0">Both Renders were started at the same exact time, </span></span><span><span data-start="249.0">but thanks to hardware-accelerated ray tracing </span></span><span><span data-start="252.0">and the next-generation shader core, </span></span><span><span data-start="254.0">the Render on the M3 Max converges significantly faster.</span></span></p><p><span><span data-start="260.0">This is a real-time visualization </span></span><span><span data-start="263.0">of the &#34;Toy Story 4&#34; Antiques Mall USD </span></span><span><span data-start="266.0">rendered by Pixar&#39;s Hydra Storm. </span></span><span><span data-start="269.0">Hydra Storm uses Metal mesh shading on M3 Max, </span></span><span><span data-start="272.0">which when combined with hardware-accelerated mesh shading </span></span><span><span data-start="276.0">runs faster than ever before.</span></span></p><p><span><span data-start="279.0">Let&#39;s now look at each of these features in more detail, </span></span><span><span data-start="282.0">starting with the next generation shader core.</span></span></p><p><span><span data-start="286.0">The Apple family 9 GPUs are composed </span></span><span><span data-start="289.0">of several building blocks </span></span><span><span data-start="291.0">such as compute and vertex command processors </span></span><span><span data-start="294.0">that parse your Metal command buffers, </span></span><span><span data-start="296.0">a rasterizer that dispatches fragment shaders for execution, </span></span><span><span data-start="302.0">and a hierarchy of caches, </span></span><span><span data-start="304.0">including the GPU last level cache </span></span><span><span data-start="306.0">that services all GPU memory traffic.</span></span></p><p><span><span data-start="310.0">But central to any GPU are its shader cores. </span></span><span><span data-start="314.0">These are the building blocks </span></span><span><span data-start="315.0">that execute your app&#39;s Metal shaders.</span></span></p><p><span><span data-start="319.0">The shader core is also paired with a texture unit </span></span><span><span data-start="322.0">that can sample and write your texture resources, </span></span><span><span data-start="325.0">as well as a brand new ray tracing unit </span></span><span><span data-start="327.0">that accelerates ray intersection requests.</span></span></p><p><span><span data-start="333.0">A shader core can be further subdivided </span></span><span><span data-start="335.0">into its constituent parts.</span></span></p><p><span><span data-start="338.0">Each shader core has an array of execution pipelines </span></span><span><span data-start="341.0">that execute different types of instructions, </span></span><span><span data-start="343.0">such as FP32, FP16, and Integer math, </span></span><span><span data-start="347.0">which correspond to operations on variables in your shaders </span></span><span><span data-start="351.0">with Metal data types such as float, half, and int, </span></span><span><span data-start="354.0">as well as memory pipelines for read and write operations </span></span><span><span data-start="357.0">to textures and buffers.</span></span></p><p><span><span data-start="360.0">Keeping all of these execution pipelines busy </span></span><span><span data-start="362.0">usually requires executing instructions </span></span><span><span data-start="365.0">from multiple SIMDgroups. </span></span><span><span data-start="367.0">So there&#39;s a pool that keeps track of the SIMDgroups </span></span><span><span data-start="370.0">that are running on a shader core, </span></span><span><span data-start="372.0">and a scheduler that chooses which SIMDgroup </span></span><span><span data-start="374.0">to execute instructions from next.</span></span></p><p><span><span data-start="377.0">Typically, there&#39;s also a handful of on-chip memories </span></span><span><span data-start="380.0">for storing the different types of data </span></span><span><span data-start="382.0">a shader program may use, </span></span><span><span data-start="384.0">such as registers for storing the values of variables, </span></span><span><span data-start="388.0">threadgroup and tile memory </span></span><span><span data-start="389.0">for storing data shared across a compute threadgroup </span></span><span><span data-start="392.0">or color attachment data shared across the tile, </span></span><span><span data-start="397.0">and a cache to improve the performance of accesses </span></span><span><span data-start="399.0">to the stack and to buffers.</span></span></p><p><span><span data-start="403.0">With this understanding of what a shader core does </span></span><span><span data-start="405.0">and its constituent pieces, </span></span><span><span data-start="407.0">I&#39;d like to explain three new exciting advancements </span></span><span><span data-start="410.0">in the Apple family 9 GPU shader core. </span></span><span><span data-start="413.0">These advancements will increase the performance </span></span><span><span data-start="416.0">of your shaders with no changes to your app. </span></span><span><span data-start="419.0">But by better understanding how this new shader core works, </span></span><span><span data-start="422.0">you&#39;ll be able to benefit from it to an even greater degree.</span></span></p><p><span><span data-start="428.0">The first change is dynamic shader core memory, </span></span><span><span data-start="432.0">which allows an app to achieve better thread occupancy, </span></span><span><span data-start="435.0">and as a result, often better performance.</span></span></p><p><span><span data-start="438.0">The second change is the flexible on-chip memory. </span></span><span><span data-start="442.0">This will increase the efficiency </span></span><span><span data-start="444.0">by which your shaders access buffer, stack, threadgroup, </span></span><span><span data-start="447.0">and tile memory.</span></span></p><p><span><span data-start="450.0">The last change is the shader core&#39;s </span></span><span><span data-start="452.0">high-performance ALU pipelines, </span></span><span><span data-start="455.0">which have increased their ability to execute in parallel. </span></span><span><span data-start="458.0">This will improve the performance of apps </span></span><span><span data-start="460.0">that perform a combination of floating point </span></span><span><span data-start="462.0">or integer math.</span></span></p><p><span><span data-start="465.0">Before further exploring these new features, </span></span><span><span data-start="467.0">let&#39;s dive into more detail </span></span><span><span data-start="469.0">about how a shader core keeps its execution pipelines busy </span></span><span><span data-start="472.0">and the importance of thread occupancy in this endeavor.</span></span></p><p><span><span data-start="477.0">Suppose your Metal shader, </span></span><span><span data-start="479.0">after executing some math operations </span></span><span><span data-start="481.0">using the ALU pipelines, reads a buffer </span></span><span><span data-start="484.0">whose result will be used immediately after. </span></span><span><span data-start="487.0">Accessing the buffer </span></span><span><span data-start="488.0">may require going all the way to device memory, </span></span><span><span data-start="491.0">which is a long latency operation. </span></span><span><span data-start="494.0">During this time, </span></span><span><span data-start="495.0">the SIMDgroup can&#39;t execute other operations, </span></span><span><span data-start="498.0">which causes the ALU pipelines to go unused.</span></span></p><p><span><span data-start="502.0">To mitigate this, the shader core can execute instructions </span></span><span><span data-start="505.0">from a different SIMDgroup, </span></span><span><span data-start="507.0">which may have some ALU instructions of its own. </span></span><span><span data-start="510.0">This reduces the amount of time the ALUs go and used </span></span><span><span data-start="513.0">and allows the SIMDgroups to run in parallel, </span></span><span><span data-start="516.0">thus improving performance.</span></span></p><p><span><span data-start="520.0">If there are additional SIMDgroups </span></span><span><span data-start="522.0">running on the shader core, </span></span><span><span data-start="523.0">this can be done many times over </span></span><span><span data-start="525.0">until the ALUs and other execution pipelines </span></span><span><span data-start="528.0">are never starved of instructions to execute.</span></span></p><p><span><span data-start="531.0">The number of SIMDgroups </span></span><span><span data-start="532.0">that are concurrently running on a shader core </span></span><span><span data-start="535.0">is called its thread occupancy.</span></span></p><p><span><span data-start="538.0">But you may be asking yourself, </span></span><span><span data-start="539.0">what dictates how many SIMDgroups </span></span><span><span data-start="541.0">will be running concurrently on a shader core? </span></span><span><span data-start="545.0">To answer that question, let&#39;s look at an example. </span></span><span><span data-start="549.0">This is a prototypical ray tracing compute kernel </span></span><span><span data-start="552.0">that intersects a ray with an acceleration structure, </span></span><span><span data-start="557.0">inspects the intersection result, </span></span><span><span data-start="561.0">and then executes a different shading function </span></span><span><span data-start="564.0">based on the material of the primitive intersected. </span></span><span><span data-start="566.0">In this example, </span></span><span><span data-start="567.0">it supports shading both glass and leather materials.</span></span></p><p><span><span data-start="573.0">Each line of code will use some amount of registers </span></span><span><span data-start="575.0">to store the program&#39;s variables. </span></span><span><span data-start="577.0">At different points of the program, </span></span><span><span data-start="579.0">more or fewer registers will be used </span></span><span><span data-start="581.0">depending on what the code does. </span></span><span><span data-start="584.0">In this particular example, </span></span><span><span data-start="586.0">the implementation of the shadeGlass function </span></span><span><span data-start="588.0">uses many more registers than the rest of the program.</span></span></p><p><span><span data-start="593.0">Prior to the Apple family 9 GPU, </span></span><span><span data-start="596.0">a SIMDgroup could not begin execution on a shader core </span></span><span><span data-start="599.0">until it allocated registers from the on-chip register file. </span></span><span><span data-start="603.0">The amount allocated would be equal </span></span><span><span data-start="605.0">to the maximum register usage at any point in the program. </span></span><span><span data-start="609.0">The SIMDgroup would keep that many registers allocated </span></span><span><span data-start="612.0">for the entire duration of the SIMDgroup, </span></span><span><span data-start="615.0">even though most of those registers may go unused </span></span><span><span data-start="618.0">in large sections of the program. </span></span><span><span data-start="620.0">Thus, based on the maximum register usage, </span></span><span><span data-start="623.0">we may only be able to run, for example, </span></span><span><span data-start="626.0">four SIMDgroups at a time on a shader core </span></span><span><span data-start="628.0">because any more would require </span></span><span><span data-start="629.0">more on-chip register filed memory than exists. </span></span><span><span data-start="633.0">However, thanks to the Apple family 9 GPU&#39;s </span></span><span><span data-start="636.0">new dynamic shader core memory feature, </span></span><span><span data-start="639.0">the maximum register usage no longer dictates </span></span><span><span data-start="642.0">how many SIMDgroups can be run. </span></span><span><span data-start="645.0">On-chip register memory is now dynamically allocated </span></span><span><span data-start="648.0">and deallocated over the lifetime of the shader </span></span><span><span data-start="651.0">according to what each part of the program actually uses. </span></span><span><span data-start="655.0">This allows SIMDgroups to make much more efficient use </span></span><span><span data-start="659.0">of the on-chip register file, freeing up space </span></span><span><span data-start="662.0">that would not have been available otherwise. </span></span><span><span data-start="665.0">This can have a profound impact </span></span><span><span data-start="666.0">on your app&#39;s thread occupancy, </span></span><span><span data-start="668.0">and ultimately, its performance </span></span><span><span data-start="671.0">by allowing many more SIMDgroups to run concurrently.</span></span></p><p><span><span data-start="675.0">As I just mentioned, </span></span><span><span data-start="677.0">registers are now dynamically allocated and deallocated </span></span><span><span data-start="679.0">over the course of a SIMDgroup&#39;s lifetime. </span></span><span><span data-start="682.0">This is in part possible </span></span><span><span data-start="685.0">because the register file is now a cache </span></span><span><span data-start="687.0">instead of the permanent storage for the registers, </span></span><span><span data-start="690.0">meaning more registers can be used </span></span><span><span data-start="692.0">that can be stored on chip.</span></span></p><p><span><span data-start="695.0">The flexible on-chip memory feature extends this treatment </span></span><span><span data-start="698.0">to the rest of the shader core&#39;s memory types, </span></span><span><span data-start="700.0">such as threadgroup and tile memory, </span></span><span><span data-start="703.0">making that a cache too.</span></span></p><p><span><span data-start="706.0">And now that register, threadgroup, tile, stack, </span></span><span><span data-start="711.0">and buffer data are all cached on chip, </span></span><span><span data-start="713.0">this has allowed us to redesign the on-chip memories </span></span><span><span data-start="716.0">into fewer larger caches </span></span><span><span data-start="719.0">that service all these memory types. </span></span><span><span data-start="721.0">This flexibility will benefit shaders </span></span><span><span data-start="723.0">that don&#39;t make heavy use of each memory type. </span></span><span><span data-start="727.0">In the past, if a compute kernel didn&#39;t use, for example, </span></span><span><span data-start="730.0">threadgroup memory, its corresponding on-chip storage </span></span><span><span data-start="733.0">would go completely unused. </span></span><span><span data-start="736.0">Now, the on-chip storage will be dynamically assigned </span></span><span><span data-start="739.0">to the memory types that are used by your shaders, </span></span><span><span data-start="742.0">giving them more on-chip storage than they had in the past, </span></span><span><span data-start="745.0">and ultimately, better performance.</span></span></p><p><span><span data-start="749.0">For example, for shaders with heavy register usage, </span></span><span><span data-start="752.0">that may mean higher occupancy.</span></span></p><p><span><span data-start="755.0">For shaders that repeatedly access a large working set </span></span><span><span data-start="759.0">of buffer data, that will mean better cache hit rates, </span></span><span><span data-start="762.0">lower buffer access latency, and thus, better performance. </span></span><span><span data-start="767.0">And for apps that make heavy use of non-inline functions, </span></span><span><span data-start="770.0">such as function pointers, visible function tables, </span></span><span><span data-start="774.0">and dynamically linked shader libraries, </span></span><span><span data-start="776.0">this means more on-chip stack space </span></span><span><span data-start="778.0">to pass function parameters, </span></span><span><span data-start="780.0">and thus, faster function calls.</span></span></p><p><span><span data-start="784.0">But what happens if your app still uses more memory </span></span><span><span data-start="787.0">than there is on-chip storage for? </span></span><span><span data-start="790.0">Unmitigated, that data will spill to the next cache level </span></span><span><span data-start="793.0">or even to main memory. </span></span><span><span data-start="796.0">Fortunately, the shader core will dynamically monitor </span></span><span><span data-start="799.0">your shaker&#39;s behavior and adjust the occupancy level </span></span><span><span data-start="802.0">to prevent this from occurring. </span></span><span><span data-start="804.0">This keeps data on chip. </span></span><span><span data-start="806.0">And ultimately, the execution pipelines busy.</span></span></p><p><span><span data-start="810.0">This does mean, however, </span></span><span><span data-start="812.0">that your shader&#39;s occupancy will be impacted </span></span><span><span data-start="815.0">by how your shader&#39;s access threadgroup, tile, </span></span><span><span data-start="817.0">stack, and buffer memory </span></span><span><span data-start="819.0">in addition to its dynamic register usage.</span></span></p><p><span><span data-start="823.0">These new hardware capabilities </span></span><span><span data-start="825.0">improve the occupancy of many apps, </span></span><span><span data-start="827.0">meaning you, the developer, need to optimize occupancy </span></span><span><span data-start="831.0">a lot less often than in the past. </span></span><span><span data-start="833.0">But if you do need to optimize occupancy further </span></span><span><span data-start="837.0">on Apple family 9 GPUs, </span></span><span><span data-start="839.0">we have developed a suite of profiling tools to help you. </span></span><span><span data-start="842.0">To learn more about how to diagnose and optimize occupancy, </span></span><span><span data-start="846.0">please refer to these talks.</span></span></p><p><span><span data-start="850.0">The last feature of the Apple family 9 GPU shader core </span></span><span><span data-start="853.0">I&#39;d like to discuss is its high-performance ALU pipelines.</span></span></p><p><span><span data-start="859.0">Apple GPU shader cores have separate ALU pipelines </span></span><span><span data-start="862.0">for different instruction types, </span></span><span><span data-start="864.0">including FP16 instructions. </span></span><span><span data-start="867.0">Apple GPUs are highly optimized to execute FP16 arithmetic. </span></span><span><span data-start="872.0">And we recommend that you&#39;ll use FP16 data types </span></span><span><span data-start="876.0">wherever possible.</span></span></p><p><span><span data-start="878.0">FP16 math instructions execute at peak throughput.</span></span></p><p><span><span data-start="883.0">They use fewer registers than their FP32 equivalents. </span></span><span><span data-start="888.0">They reduce memory bandwidth </span></span><span><span data-start="889.0">if your buffers store data natively in FP16. </span></span><span><span data-start="893.0">And for situations where the source </span></span><span><span data-start="895.0">or destination variable of a math operation </span></span><span><span data-start="898.0">is not FP16 already, </span></span><span><span data-start="900.0">it can be converted to and from at no cost.</span></span></p><p><span><span data-start="904.0">But if your app still performs other math operations, </span></span><span><span data-start="908.0">such as FP32 and integer, </span></span><span><span data-start="910.0">the Apple family 9 GPU shader core can execute instructions </span></span><span><span data-start="913.0">from all three data types in parallel </span></span><span><span data-start="916.0">to a greater degree than ever before. </span></span><span><span data-start="919.0">This can deliver up to 2x ALU performance </span></span><span><span data-start="922.0">compared to prior Apple GPUs. </span></span><span><span data-start="925.0">In order to take advantage of this extra parallelism, </span></span><span><span data-start="928.0">instructions must be executed from multiple SIMDgroups, </span></span><span><span data-start="931.0">which means increasing occupancy </span></span><span><span data-start="934.0">can improve the utilization of the ALU pipelines. </span></span><span><span data-start="938.0">Let&#39;s consider an example. </span></span><span><span data-start="940.0">Imagine there are two SIMDgroups running concurrently, </span></span><span><span data-start="943.0">both executing ALU instructions. </span></span><span><span data-start="946.0">In the past, these SIMDgroups may have had to run </span></span><span><span data-start="949.0">one after another.</span></span></p><p><span><span data-start="952.0">But if they have FP32 and FP16 instructions </span></span><span><span data-start="956.0">to execute at different points in time, as depicted here, </span></span><span><span data-start="960.0">then their executions can be overlapped, </span></span><span><span data-start="963.0">increasing parallelism and performance.</span></span></p><p><span><span data-start="967.0">To recap what&#39;s new in the next-generation shader core, </span></span><span><span data-start="972.0">it will dynamically allocate and deallocate registers </span></span><span><span data-start="975.0">over the lifetime of a shader, </span></span><span><span data-start="976.0">which improves its thread occupancy.</span></span></p><p><span><span data-start="980.0">It has a large on-chip cache </span></span><span><span data-start="982.0">that services registers, threadgroup, tile, stack, </span></span><span><span data-start="986.0">and buffer memory, which improves the performance </span></span><span><span data-start="989.0">of accessing those memory types.</span></span></p><p><span><span data-start="993.0">The shader core will dynamically adjust occupancy </span></span><span><span data-start="995.0">to keep data on chip and the execution pipelines busy.</span></span></p><p><span><span data-start="1000.0">And finally, FP16, FP32 and integer operations </span></span><span><span data-start="1005.0">can execute in parallel more than ever, </span></span><span><span data-start="1007.0">increasing ALU performance.</span></span></p><p><span><span data-start="1012.0">Next, let&#39;s take a look at hardware-accelerated ray tracing.</span></span></p><p><span><span data-start="1019.0">With Metal ray tracing, </span></span><span><span data-start="1020.0">apps can leverage the massive parallelism of Apple GPUs </span></span><span><span data-start="1024.0">to intersect rays with their scene geometry. </span></span><span><span data-start="1027.0">If you&#39;re not familiar with Metal ray tracing </span></span><span><span data-start="1029.0">and would like to learn more, </span></span><span><span data-start="1031.0">please watch Your guide to Metal ray tracing </span></span><span><span data-start="1034.0">and Enhance your app with Metal ray tracing.</span></span></p><p><span><span data-start="1040.0">At the heart of the Metal ray chasing API </span></span><span><span data-start="1043.0">is the intersector object </span></span><span><span data-start="1044.0">that is responsible for determining </span></span><span><span data-start="1046.0">the intersection point of a ray </span></span><span><span data-start="1048.0">with the primitives contained in an acceleration structure. </span></span><span><span data-start="1052.0">It is often invoked many times over </span></span><span><span data-start="1054.0">by ray tracing app&#39;s GPU functions, also known as shaders, </span></span><span><span data-start="1058.0">and thus, is central to the app&#39;s performance.</span></span></p><p><span><span data-start="1062.0">Earlier, I showed such AGPU function </span></span><span><span data-start="1065.0">when I looked at the register usage </span></span><span><span data-start="1067.0">of this raytracingKernel. </span></span><span><span data-start="1069.0">It creates an intersector object </span></span><span><span data-start="1072.0">and finds an intersection </span></span><span><span data-start="1074.0">by calling the object&#39;s intersect method.</span></span></p><p><span><span data-start="1079.0">To determine the intersection point, </span></span><span><span data-start="1081.0">the intersector performs a few key stages. </span></span><span><span data-start="1085.0">First, it traverses the acceleration structure </span></span><span><span data-start="1088.0">to find a candidate primitive. </span></span><span><span data-start="1090.0">It then invokes an intersection function, </span></span><span><span data-start="1093.0">which may be provided by the app, </span></span><span><span data-start="1095.0">to determine if the rate intersects the primitive.</span></span></p><p><span><span data-start="1099.0">If it does, </span></span><span><span data-start="1100.0">the intersection is compared to previous intersections </span></span><span><span data-start="1103.0">and the process is repeated until the closest is found.</span></span></p><p><span><span data-start="1107.0">The closest intersection is then returned </span></span><span><span data-start="1109.0">to the calling GPU function </span></span><span><span data-start="1111.0">for further app-specific processing.</span></span></p><p><span><span data-start="1115.0">New in Apple family 9 GPUs, </span></span><span><span data-start="1118.0">the implementation of the intersector object </span></span><span><span data-start="1120.0">is hardware-accelerated, </span></span><span><span data-start="1122.0">which greatly increases the performance </span></span><span><span data-start="1124.0">of this critical operation.</span></span></p><p><span><span data-start="1128.0">The hardware-accelerated intersection </span></span><span><span data-start="1130.0">does not execute in line with the GPU function. </span></span><span><span data-start="1133.0">Thus, to facilitate the communication of the ray </span></span><span><span data-start="1136.0">and the ray payload between the two, </span></span><span><span data-start="1138.0">data is read and written to on-chip memory, </span></span><span><span data-start="1141.0">which you can observe </span></span><span><span data-start="1142.0">using the RT scratch performance counters in the new Xcode.</span></span></p><p><span><span data-start="1146.0">Now that I&#39;ve discussed the role </span></span><span><span data-start="1148.0">and responsibilities of the intersector, </span></span><span><span data-start="1150.0">let&#39;s dissect the performance characteristics </span></span><span><span data-start="1153.0">of onetime through this intersector loop using an example.</span></span></p><p><span><span data-start="1158.0">Imagine our app is executing two SIMDgroups </span></span><span><span data-start="1161.0">that each wish to intersect four rays </span></span><span><span data-start="1163.0">with an acceleration structure.</span></span></p><p><span><span data-start="1167.0">In this example, </span></span><span><span data-start="1168.0">our acceleration structure contains </span></span><span><span data-start="1170.0">the classic kernel boxing, </span></span><span><span data-start="1172.0">with one box object and one sphere object.</span></span></p><p><span><span data-start="1176.0">The rays are cast into the scene </span></span><span><span data-start="1177.0">by calling the intersect method, </span></span><span><span data-start="1179.0">passing it the ray, the acceleration structure, </span></span><span><span data-start="1182.0">and the intersection function table. </span></span><span><span data-start="1185.0">Each SIMDgroup has two rays that intersect the box </span></span><span><span data-start="1188.0">and two the intersect the sphere. </span></span><span><span data-start="1191.0">In this example, </span></span><span><span data-start="1192.0">the box is defined as opaque triangle primitives </span></span><span><span data-start="1196.0">by using the MTLAccelerationStructure </span></span><span><span data-start="1199.0">TriangleGeometryDescriptor </span></span><span><span data-start="1201.0">and setting its opaque property to yes, </span></span><span><span data-start="1203.0">thus, the intersection can compute the intersections </span></span><span><span data-start="1206.0">using Metal&#39;s built-in intersection function.</span></span></p><p><span><span data-start="1211.0">However, the sphere is defined procedurally </span></span><span><span data-start="1213.0">using a custom bounding box intersection function </span></span><span><span data-start="1216.0">that the intersection must invoke.</span></span></p><p><span><span data-start="1220.0">The custom BoundingBoxIntersection function is declared </span></span><span><span data-start="1223.0">using the intersection attribute </span></span><span><span data-start="1224.0">with the bounding_box parameter.</span></span></p><p><span><span data-start="1228.0">As I mentioned before, </span></span><span><span data-start="1230.0">the intersect method is called by each thread </span></span><span><span data-start="1232.0">that is testing a ray against the acceleration structure. </span></span><span><span data-start="1235.0">So with this example in mind, </span></span><span><span data-start="1237.0">let&#39;s look at how each intersect calls traversal </span></span><span><span data-start="1241.0">and intersection test are executed </span></span><span><span data-start="1243.0">in a traditional implementation.</span></span></p><p><span><span data-start="1247.0">In typical usage, </span></span><span><span data-start="1248.0">not all traversals will take the same amount of time </span></span><span><span data-start="1250.0">to locate a primitive to test the ray against. </span></span><span><span data-start="1254.0">This creates what is called execution divergence, </span></span><span><span data-start="1257.0">which causes each thread in a SIMDgroup </span></span><span><span data-start="1259.0">to wait for the longest traversal from that SIMDgroup </span></span><span><span data-start="1261.0">before proceeding to the next stage.</span></span></p><p><span><span data-start="1265.0">And as it turns out, </span></span><span><span data-start="1266.0">the same overhead compounds </span></span><span><span data-start="1268.0">when executing the intersection functions too. </span></span><span><span data-start="1271.0">Execution divergence causes each type </span></span><span><span data-start="1274.0">of intersection function to run one after another, </span></span><span><span data-start="1276.0">further reducing parallelism. </span></span><span><span data-start="1279.0">An aggregate across both stages, </span></span><span><span data-start="1282.0">each thread spends a large proportion of its runtime idle, </span></span><span><span data-start="1285.0">waiting on the other threads in the SIMDgroup to complete, </span></span><span><span data-start="1288.0">which is a major performance bottleneck.</span></span></p><p><span><span data-start="1293.0">With that picture of a traditional implementation in mind, </span></span><span><span data-start="1296.0">let&#39;s discuss how hardware-accelerated ray tracing </span></span><span><span data-start="1299.0">optimizes those inefficiencies.</span></span></p><p><span><span data-start="1303.0">The first major improvement </span></span><span><span data-start="1304.0">is that the hardware intersector </span></span><span><span data-start="1306.0">is able to run each traversal completely independently </span></span><span><span data-start="1310.0">using fixed function hardware. </span></span><span><span data-start="1312.0">This is possible in part </span></span><span><span data-start="1314.0">because the arrays are sent to the hardware intersector </span></span><span><span data-start="1316.0">for processing </span></span><span><span data-start="1317.0">instead of executing in line with the GPU function. </span></span><span><span data-start="1321.0">This greatly decreases the time spent traversing </span></span><span><span data-start="1325.0">and also removes the overhead </span></span><span><span data-start="1326.0">of the traditional traversal&#39;s execution divergence.</span></span></p><p><span><span data-start="1333.0">On the other hand, the intersection functions </span></span><span><span data-start="1335.0">are Metal shading language code, </span></span><span><span data-start="1337.0">so they still must be grouped into SIMDgroups </span></span><span><span data-start="1339.0">to be run on the shader core. </span></span><span><span data-start="1342.0">However, because the hardware intersector </span></span><span><span data-start="1344.0">executes each ray independently, </span></span><span><span data-start="1347.0">it is free to group together the intersection function calls </span></span><span><span data-start="1350.0">from rays that originated from separate SIMDgroups.</span></span></p><p><span><span data-start="1355.0">This is the role of the reorder stage. </span></span><span><span data-start="1358.0">When rays reach this stage within close proximity and time, </span></span><span><span data-start="1362.0">the intersection function calls </span></span><span><span data-start="1364.0">will be grouped into coherent SIMDgroups, </span></span><span><span data-start="1366.0">such that the execution divergence overhead </span></span><span><span data-start="1369.0">present in the traditional implementation is reduced </span></span><span><span data-start="1372.0">or even completely eliminated.</span></span></p><p><span><span data-start="1376.0">So now that I&#39;ve shown you </span></span><span><span data-start="1377.0">how hardware-accelerated ray tracing </span></span><span><span data-start="1380.0">improves the performance </span></span><span><span data-start="1381.0">of your app&#39;s ray intersector calls, </span></span><span><span data-start="1383.0">let&#39;s review some best practices </span></span><span><span data-start="1385.0">that your apps can implement to maximize its benefits.</span></span></p><p><span><span data-start="1390.0">Our first suggestion is to use the intersector object API </span></span><span><span data-start="1394.0">whenever possible. </span></span><span><span data-start="1395.0">Metal also allows ray tracing </span></span><span><span data-start="1397.0">to be performed using the intersection query API, </span></span><span><span data-start="1401.0">but this API increases </span></span><span><span data-start="1403.0">the amount of ray trace scratch memory </span></span><span><span data-start="1404.0">that must be read and written, </span></span><span><span data-start="1406.0">as well as disables the reorder stage.</span></span></p><p><span><span data-start="1410.0">We also recommend </span></span><span><span data-start="1411.0">when authoring custom intersection functions </span></span><span><span data-start="1414.0">to avoid creating one uber function </span></span><span><span data-start="1417.0">that is capable of executing </span></span><span><span data-start="1418.0">many different logical intersection routines. </span></span><span><span data-start="1422.0">Instead, create one Metal intersection function </span></span><span><span data-start="1425.0">for each logical intersection routine. </span></span><span><span data-start="1428.0">This increases the benefits of the reorder stage.</span></span></p><p><span><span data-start="1433.0">It is also important to try to minimize </span></span><span><span data-start="1435.0">the size of the ray payload structure that has passed to </span></span><span><span data-start="1438.0">and return from the intersector object. </span></span><span><span data-start="1441.0">This will decrease your shader&#39;s latency </span></span><span><span data-start="1443.0">and potentially increase its thread occupancy.</span></span></p><p><span><span data-start="1448.0">For more details and guidance </span></span><span><span data-start="1450.0">about how to optimize your ray tracing apps, </span></span><span><span data-start="1452.0">please watch these talks.</span></span></p><p><span><span data-start="1456.0">To recap, the Apple family 9 GPUs </span></span><span><span data-start="1459.0">greatly improved the performance of ray tracing </span></span><span><span data-start="1462.0">through new hardware acceleration </span></span><span><span data-start="1464.0">that features fixed function traversal blocks </span></span><span><span data-start="1466.0">and an intersection function reorder stage.</span></span></p><p><span><span data-start="1470.0">And although this new hardware </span></span><span><span data-start="1471.0">will improve the performance of all Metal ray tracing apps, </span></span><span><span data-start="1475.0">to maximize the benefits your app derives from it, </span></span><span><span data-start="1478.0">it&#39;s best to use the intersection API </span></span><span><span data-start="1481.0">instead of the intersection query API whenever possible.</span></span></p><p><span><span data-start="1486.0">The last advancement in the Apple family 9 GPUs </span></span><span><span data-start="1489.0">that I&#39;d like to talk to you about </span></span><span><span data-start="1491.0">is hardware-accelerated mesh shading.</span></span></p><p><span><span data-start="1495.0">Mesh shading is a flexible, </span></span><span><span data-start="1497.0">GPU-driven geometry processing stage </span></span><span><span data-start="1499.0">in the rendering pipeline </span></span><span><span data-start="1501.0">that replaces the traditional vertex shader stage </span></span><span><span data-start="1504.0">with two compute-like shaders.</span></span></p><p><span><span data-start="1507.0">Object shaders execute in the first stage </span></span><span><span data-start="1509.0">and can be used to perform coarse grain processing </span></span><span><span data-start="1512.0">of app-specific inputs such as entire mesh objects. </span></span><span><span data-start="1516.0">Each object threadgroup can choose to spawn a mesh group </span></span><span><span data-start="1519.0">to perform subsequent finer grain processing. </span></span><span><span data-start="1523.0">Mesh shaders comprise the second stage. </span></span><span><span data-start="1526.0">Typically, a mesh threadgroup will process </span></span><span><span data-start="1528.0">a constituent piece of the parent object, </span></span><span><span data-start="1530.0">often referred to as a meshlet.</span></span></p><p><span><span data-start="1534.0">The output of the mesh threadgroup </span></span><span><span data-start="1536.0">is a Metal mesh object that encapsulates </span></span><span><span data-start="1539.0">a list of vertices and primitives </span></span><span><span data-start="1541.0">to be processed by the remainder </span></span><span><span data-start="1543.0">of the traditional graphics pipeline.</span></span></p><p><span><span data-start="1546.0">Mesh shading has numerous applications, </span></span><span><span data-start="1549.0">such as fine-grained geometry calling, </span></span><span><span data-start="1553.0">procedural geometry generation, </span></span><span><span data-start="1555.0">custom app-specific geometry representations, </span></span><span><span data-start="1559.0">such as compressed formats. </span></span><span><span data-start="1561.0">And for porting geometry and tessellation shaders </span></span><span><span data-start="1564.0">from other graphics APIs.</span></span></p><p><span><span data-start="1567.0">If you&#39;re unfamiliar with mesh shading in Metal, </span></span><span><span data-start="1569.0">I recommend that you check out the two talks below.</span></span></p><p><span><span data-start="1574.0">With hardware-accelerated mesh shading </span></span><span><span data-start="1576.0">on Apple family 9 GPUs, </span></span><span><span data-start="1578.0">the most notable improvement you&#39;ll observe </span></span><span><span data-start="1580.0">is much improved performance </span></span><span><span data-start="1582.0">of your existing mesh shading code..</span></span></p><p><span><span data-start="1585.0">Apple family 9 GPUs </span></span><span><span data-start="1586.0">are able to much more efficiently schedule object </span></span><span><span data-start="1589.0">and mesh threadgroups </span></span><span><span data-start="1590.0">to keep intermediate meshlet data on chip. </span></span><span><span data-start="1593.0">Thus, reducing memory traffic.</span></span></p><p><span><span data-start="1596.0">With the new hardware </span></span><span><span data-start="1597.0">also comes several Metal API enhancements. </span></span><span><span data-start="1601.0">The first is support for encoding draw mesh commands </span></span><span><span data-start="1604.0">into indirect command buffers. </span></span><span><span data-start="1607.0">This allows GPU-driven rendering pipelines </span></span><span><span data-start="1609.0">to make use of mesh shading </span></span><span><span data-start="1611.0">in addition to traditional vertex shaders.</span></span></p><p><span><span data-start="1615.0">The second API enhancement </span></span><span><span data-start="1617.0">expands the maximum number of threadgroups per mesh grid </span></span><span><span data-start="1620.0">from 1,024 to over 1 million.</span></span></p><p><span><span data-start="1624.0">Let&#39;s now review a couple of best practices </span></span><span><span data-start="1627.0">to ensure optimal mesh shading performance.</span></span></p><p><span><span data-start="1632.0">The metal::mesh object output by a mesh threadgroup </span></span><span><span data-start="1635.0">has several template parameters </span></span><span><span data-start="1636.0">whose size are important to keep as small as possible.</span></span></p><p><span><span data-start="1641.0">For the mesh&#39;s vertex and primitive data types, </span></span><span><span data-start="1644.0">this can be done, for example, by removing unused attributes </span></span><span><span data-start="1649.0">that may be present due to sharing those data types </span></span><span><span data-start="1651.0">with other unrelated vertex or mesh functions. </span></span><span><span data-start="1654.0">The mesh type must also specify </span></span><span><span data-start="1656.0">the maximum number of primitives and vertices </span></span><span><span data-start="1659.0">that may be output. </span></span><span><span data-start="1661.0">These should not be set any larger </span></span><span><span data-start="1663.0">than what your app&#39;s geometry, pipeline, and assets </span></span><span><span data-start="1666.0">actually need. </span></span><span><span data-start="1668.0">Being mindful of these sizes will reduce memory traffic </span></span><span><span data-start="1672.0">and may increase occupancy.</span></span></p><p><span><span data-start="1675.0">If performing per primitive calling in a mesh shader, </span></span><span><span data-start="1678.0">we don&#39;t recommend writing vertex positions </span></span><span><span data-start="1680.0">to the mesh object </span></span><span><span data-start="1682.0">just to be called by the hardware subsequent calling stage. </span></span><span><span data-start="1686.0">Instead, it is best to completely omit </span></span><span><span data-start="1689.0">writing such primitives </span></span><span><span data-start="1690.0">as that can save substantial processing time </span></span><span><span data-start="1693.0">in the remainder </span></span><span><span data-start="1694.0">of the hardware&#39;s geometry processing stages.</span></span></p><p><span><span data-start="1699.0">All right, let&#39;s recap what I covered </span></span><span><span data-start="1701.0">about the Apple family 9 GPUs.</span></span></p><p><span><span data-start="1705.0">The next-generation shader core </span></span><span><span data-start="1707.0">increases on-chip memory utilization </span></span><span><span data-start="1710.0">for better thread occupancy and performance </span></span><span><span data-start="1712.0">by dynamically allocating register storage </span></span><span><span data-start="1715.0">and sharing on-chip memory across many memory types.</span></span></p><p><span><span data-start="1720.0">Hardware-accelerated ray tracing </span></span><span><span data-start="1722.0">greatly improves the performance of apps </span></span><span><span data-start="1724.0">using the Metal ray tracing APIs, </span></span><span><span data-start="1726.0">enabling new high-fidelity visual effects. </span></span><span><span data-start="1730.0">And finally, mesh shading performance is greatly improved </span></span><span><span data-start="1734.0">thanks to hardware acceleration, </span></span><span><span data-start="1736.0">enabling more apps to customize </span></span><span><span data-start="1738.0">their geometry processing pipeline.</span></span></p><p><span><span data-start="1742.0">Thank you for watching.</span></span></p>
							</section>
						</div></div>
  </body>
</html>
