<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.channable.com/tech/parallel-streaming-in-haskell-part-4-conditionals-and-non-blocking-evaluation">Original</a>
    <h1>Parallel streaming in Haskell: Part 4 – Conditionals and non-blocking evaluation</h1>
    
    <div id="readability-page-1" class="page"><div><div><p>Here is the final blog post about the parallel streaming evaluator we use at Channable, where we use Haskell with the Conduit library to produce both result values and parallel work units in a single stream.</p>
<p>We will assume that you&#39;ve read the previous three parts, so go ahead and do that now!</p>
<ul>
<li><a href="https://www.channable.com/tech/parallel-streaming-in-haskell-part-1-fast-efficient-fun" title="Parallel streaming in Haskell: Part 1 - Fast, efficient, and fun!">Parallel streaming in Haskell: Part 1 - Fast, efficient, and fun!</a></li>
<li><a href="https://www.channable.com/tech/parallel-streaming-in-haskell-part-2-optimized-parallel-aggregations" title="Parallel streaming in Haskell: Part 2 - Optimized parallel aggregations">Parallel streaming in Haskell: Part 2 - Optimized parallel aggregations</a></li>
<li><a href="https://www.channable.com/tech/parallel-streaming-in-haskell-part-3-parallel-work-consumer" title="Parallel streaming in Haskell: Part 3 - A parallel work consumer">Parallel streaming in Haskell: Part 3 - A parallel work consumer</a></li>
</ul>
<p>In this blog post we will explain how we implemented conditionals.  More precisely, we show how we can efficiently send <em>only values that match a condition</em> through an aggregation.  As a preliminary to conditionals we need to ensure that evaluation is done in a non-blocking fashion.</p>
<h2 id="non-blocking-evaluation">Non-blocking evaluation</h2>
<p>Sometimes during evaluation we have to wait on parallel work that is currently being evaluated.  Examples where this might occur are:</p>
<ul>
<li>during the joining phase of aggregations we know which input blocks we want to join together but those input blocks may not have been produced yet</li>
<li>if a <a href="https://www.channable.com/tech/parallel-streaming-in-haskell-part-1-fast-efficient-fun" title="Parallel streaming in Haskell: Part 1 - Fast, efficient, and fun!"><code>sinkItems</code></a> has produced work to consume every incoming stream, it can&#39;t do anything until all results are available</li>
<li>in the <a href="https://www.channable.com/tech/parallel-streaming-in-haskell-part-3-parallel-work-consumer" title="Parallel streaming in Haskell: Part 3 - A parallel work consumer"><code>sequentialize</code></a> variation we can have similar situations, where it can&#39;t yield any items until an incoming stream has completed</li>
</ul>
<p>The most obvious place to do the waiting is within the top-level conduit.  That&#39;s precisely what we did with the <code>takeMVar</code>s in the <code>sinkItems</code> implementation of <a href="https://www.channable.com/tech/parallel-streaming-in-haskell-part-1-fast-efficient-fun" title="Parallel streaming in Haskell: Part 1 - Fast, efficient, and fun!">the first blog post</a>, here&#39;s the code snippet:</p>
<pre><code>        
        
        
        <span>Nothing</span> -&gt;
          fmap concat $ traverse (liftIO . takeMVar) chunkVars</code></pre>
<p>A real problem with this is that the consumer of this conduit can&#39;t detect when such a blocking wait occurs.  A function like our <code>runConduitWithWork</code> might observe that it takes a long time to take a step in the conduit, but it&#39;s hard to see if it&#39;s doing useful work or if it&#39;s just blocking.  The ability to see that a work producer can&#39;t do anything at the moment is crucial in our implementation of conditionals, where we&#39;ll have two branches and if one blocks we may want to proceed working on the other branch.  This will be further explained in the next chapter.</p>
<p>Our solution is to have a very strict non-blocking policy, and instead allow our conduits to yield a special signal that tells the consumer that it can&#39;t make progress.  For this purpose we add a new constructor to our <code>WorkOr</code> type:</p>
<pre><code><span><span>data</span> <span>WorkOr</span> a</span>
  = <span>WOWork</span> (<span>IO</span> ())   
                     
  | <span>WOValue</span> a
  | <span>WONothingYet</span>     
                     </code></pre>
<p>The <code>takeMVar</code> call is now forbidden with our non-blocking policy, but we can write a drop-in replacement for the <code>liftIO . takeMVar</code> combination that does what we need:</p>
<pre><code><span>nonBlockingTakeMVar</span>
  :: <span>MVar</span> a -&gt; <span>ConduitT</span> i (<span>WorkOr</span> o) <span>IO</span> a  
<span>nonBlockingTakeMVar</span> var =
  tryTakeMVar var &gt;&gt;= \<span>case</span>   
    <span>Nothing</span> -&gt; <span>do</span>                 
      <span>Conduit</span>.yield <span>WONothingYet</span>  
      nonBlockingTakeMVar var     
    <span>Just</span> x -&gt; pure x</code></pre>
<p>This looks a bit like a busy wait with repeated <code>tryTakeMVar</code> calls, but the yield in between makes it slightly different.  A carefully written consumer can observe when the <code>WONothingYet</code> is being yielded and gets to decide how to continue.  In our <code>runConduitWithWork</code> implementation we just use a <a target="_blank" rel="noop" href="https://hackage.haskell.org/package/base-4.17.0.0/docs/Control-Concurrent.html#v:yield"><code>Control.Concurrent.yield</code></a> (unrelated to <code>Conduit.yield</code>) to actively allow any other waiting threads to run before we continue our loop.  We used to have a small <code>threadDelay</code> of 100 microseconds here, but that was inefficient.  It cost more CPU time <em>and</em> the job ran slower.</p>
<pre><code>      <span>HaveOutput</span> pipe <span>WONothingYet</span> -&gt; <span>do</span>
        <span>Control</span>.<span>Concurrent</span>.yield
        withPipe pipe</code></pre>
<p>Another aspect of the non-blocking policy is that we never block <em>within</em> a parallel work unit or within a parallel stream.  In other words, we <em>only</em> yield a <code>WOWork</code> parallel work unit or a <code>ParallelStream</code> when they can be evaluated immediately, in full, without blocking.  So for example when we&#39;re in the joining phase of an aggregation, we only yield a work unit to join two blocks once the required blocks are available (as opposed to just yielding the work and then blocking during evaluation of that work).  This gives us two important properties:</p>
<ul>
<li>We always make progress, even when the number of <code>WOWork</code> parallel work units that we run at the same time is limited.  You don&#39;t want all your threads to be blocked on results from a work unit that will never run because all threads are taken.</li>
<li>The evaluator can accurately measure how much work actually happens and how long we&#39;re waiting.  This is necessary to estimate the optimal number of threads, as discussed in the <a href="https://www.channable.com/tech/parallel-streaming-in-haskell-part-3-parallel-work-consumer" title="Parallel streaming in Haskell: Part 3 - A parallel work consumer">Parallel streaming in Haskell: Part 3 - A parallel work consumer</a>.</li>
</ul>
<h2 id="conditionals">Conditionals</h2>
<p>In our tool, users can specify conditionals.  Let&#39;s say we have a conditional like this:</p>
<pre><code><span><span>IF</span></span> <span><span><span>length</span></span>(.description) &gt; <span>10</span> <span>THEN</span>
  <span>action1</span>
<span><span>ELSE</span></span>
  <span>action2</span></span></code></pre>
<p>The intent is quite clear: When the length of the description field is more than 10 we should apply <code>action1</code> and otherwise we should apply <code>action2</code>.  This works intuitively for actions like <code>MAP</code> and <code>FILTER</code> where we can look at every individual item, check the conditional, apply the corresponding action and then yield the modified item if it was not filtered out.</p>
<p>Other actions, for instance <code>DEDUPLICATION</code> or <code>SORT</code>, can&#39;t be applied on an individual item but we do allow them in conditionals.  The exact interpretation is therefore a bit counter-intuitive to what programmers might expect, because we actually:</p>
<ul>
<li>Process all items to see if they match the condition</li>
<li>All items that match the condition will be sent to <code>action1</code>, which may or may not immediately yield output items</li>
<li>All items that don&#39;t match the condition will be sent to <code>action2</code>, which may or may not immediately yield output items</li>
</ul>
<p>This means that we need to partition the items based on the condition, evaluate the 2 branches and recombine the results.  All of this needs to have a deterministic order and needs to be done as fast as possible.</p>
<p>One can think of the behavior as the following code:</p>
<pre><code><span>conditional</span> condition thenActions elseActions = \items -&gt; <span>do</span>
  <span>let</span> (trueItems, falseItems) = partition condition items
  items1 &lt;- thenActions trueItems
  items2 &lt;- elseActions falseItems
  pure (items1 &lt;&gt; items2)</code></pre>
<p>To precisely explain how conditionals are implemented, we&#39;ll consider 2 categories of actions that are allowed in conditionals:</p>
<ul>
<li><em>Streaming actions</em> like <code>MAP</code> and <code>FILTER</code> process one item at a time.  Any input that they consume is directly translated into the corresponding output (or a lack of an output for a filter), so they&#39;re not allowed to remember some items and yield them later.  If we pull on the output of the action we expect it to pull on its input, without any buffering in between.</li>
<li><em>Aggregating actions</em> consume all the input items before they start yielding any output.  We&#39;ve discussed aggregations in the previous blog post, and it includes things like deduplication, sorting and grouping.  The items are buffered in some data structure.</li>
</ul>
<p>Based on the actions contained in a conditional we determine if this is an <em>aggregating conditional</em> or a <em>streaming conditional</em>, and we pick an evaluation strategy accordingly.</p>
<h2 id="aggregating-conditionals">Aggregating conditionals</h2>
<p>We will consider this regime if one of the branches contains at least one aggregating action.  The main property of an aggregating action is the fact that it already has an implicit buffer.  We&#39;ll use this &#34;free&#34; buffer (it doesn&#39;t cost us any extra) to make sure the results are deterministic.  The assumption we are making is that there should always be at least one aggregating action in the <code>else</code>-branch.  If there is only an aggregating action in the <code>then</code> branch, we modify the conditional in order to get the aggregation action in the <code>else</code>-branch.</p>
<pre><code>IF <span>not</span> <span>condition</span> <span>THEN</span>
  <span>else</span><span>-</span>branch
<span>ELSE</span>
  <span>then</span><span>-</span>branch</code></pre>
<p>We now have a conditional where the <code>else</code>-branch contains at least one aggregation action.  Both branches can additionally contain more streaming, aggregating, or any other actions.  Our goal now is to write a function like so:</p>
<pre><code><span>aggregatingConditional</span>
  :: (<span>Item</span> -&gt; <span>IO</span> <span>Bool</span>)  
  -&gt; <span>ConduitT</span> (<span>WorkOr</span> <span>ParallelStream</span>) (<span>WorkOr</span> <span>ParallelStream</span>) <span>IO</span> ()    
  -&gt; <span>ConduitT</span> (<span>WorkOr</span> <span>ParallelStream</span>) (<span>WorkOr</span> <span>ParallelStream</span>) <span>IO</span> ()    
  -&gt; <span>ConduitT</span> (<span>WorkOr</span> <span>ParallelStream</span>) (<span>WorkOr</span> <span>ParallelStream</span>) <span>IO</span> ()</code></pre>
<p>The conditional takes <code>WorkOr ParallelStream</code>s as the input, so there are a few cases that we need to deal with.  The simplest case is when we get a <code>WOWork</code> parallel work unit, we can simply pass it along to the output without having to go through the conditional branches<a href="#footnote-1" id="footnote-1-backlink"><sup>[1]</sup></a>.  This is slightly more efficient, but more importantly it prevents duplication of work.</p>
<p><img src="https://media.graphassets.com/y3Si2hqjRQSIuZCtK37J" alt=""/></p>
<p>When we get a <code>ParallelStream</code> instead, we want to construct <em>two</em> <code>ParallelStream</code>s.  By applying the condition to all the items we build one <code>ParallelStream</code> with just the values for the then-branch and another with just the values for the else-branch.</p>
<p>We effectively have three branches:</p>
<ul>
<li>The pass-around branch for <code>WOWork</code> units from the input</li>
<li>The then-branch that produces <code>WorkOr ParallelStream</code> outputs</li>
<li>The else-branch also produces <code>WorkOr ParallelStream</code> outputs</li>
</ul>
<p>The outputs of all of these branches is combined by simply interleaving them in whatever order the outputs come.  For parallel work units this is certainly valid, because they can be executed in any order.  The order in which we evaluate work doesn&#39;t influence the results.</p>
<p>For the <code>ParallelStream</code>s we have to be very careful though, because we want a deterministic ordering that is consistent between runs and that doesn&#39;t rely on specifics like chunk sizes.  That&#39;s why we require the <code>else</code> branch to have at least one aggregation, because then we <em>always</em> get all the streams from the then-branch before we get the first stream from the else-branch.  The deterministic order is then that all values where the condition applies come before the values where the condition doesn&#39;t apply (and for the rest items are ordered the same as in the input).</p>
<h2 id="zipping-and-wonothingyet">Zipping and WONothingYet</h2>
<p>Combining the three streams is easier said than done.  The logical route would be to use a <a target="_blank" rel="noop" href="https://hackage.haskell.org/package/conduit-1.3.4.3/docs/Data-Conduit.html#t:ZipConduit"><code>ZipConduit</code></a> for this.  A <code>ZipConduit</code> duplicates each input to multiple conduits and then combines the outputs.  They interleave the outputs in a left-biased manner, meaning that if multiple conduits have an output available (they&#39;re in the <code>HaveOutput</code> state), the output from the leftmost conduit is used first.</p>
<p>The snag with <code>ZipConduit</code> is that we have <code>WONothingYet</code>s to deal with.  Each of the three branches can potentially yield a <code>WONothingYet</code> to indicate that they can&#39;t do anything right now, but if another branch can still make progress we don&#39;t want to pass this <code>WONothingYet</code> to the output.</p>
<p>If we just look at how the then and else branches need to be combined, we already get a bunch of interesting cases:</p>
<table>
<thead>
<tr>
<th id="then">then</th>
<th id="else">else</th>
<th id=""></th>
</tr>
</thead>
<tbody>
<tr>
<td>Has <code>WONothingYet</code></td>
<td>Has <code>WONothingYet</code></td>
<td>Forward a <code>WONothingYet</code></td>
</tr>
<tr>
<td>Has <code>WOWork</code></td>
<td>Has <code>WONothingYet</code></td>
<td>Forward the <code>WOWork</code></td>
</tr>
<tr>
<td>Has <code>WONothingYet</code></td>
<td>Has <code>WOWork</code></td>
<td>Forward the <code>WOWork</code></td>
</tr>
<tr>
<td>Has a stream</td>
<td>Has <code>WONothingYet</code></td>
<td>Forward the stream (!)</td>
</tr>
<tr>
<td>Has <code>WONothingYet</code></td>
<td>Has a stream</td>
<td>Forward a <code>WONothingYet</code> (!)</td>
</tr>
<tr>
<td>Is <code>Done</code></td>
<td>Has <code>WONothingYet</code></td>
<td>Forward a <code>WONothingYet</code></td>
</tr>
<tr>
<td>Has <code>WONothingYet</code></td>
<td>Is <code>Done</code></td>
<td>Forward a <code>WONothingYet</code></td>
</tr>
</tbody>
</table>
<p>Note that <code>WOWork</code> is always forwarded if it is available, regardless of the state of the other branch.  If the then-branch can deliver a stream while the else-branch is blocked we can just forward that stream.  If it&#39;s the other way around we first must wait for enough parallel work to complete and then we can grab the values from the then-branch first to keep our deterministic ordering, we signal that to the evaluator by yielding a <code>WONothingYet</code>.</p>
<p>To implement this logic, we took the existing <a target="_blank" rel="noop" href="https://hackage.haskell.org/package/conduit-1.3.4.3/docs/Data-Conduit-Internal.html#v:zipConduitApp"><code>zipConduitApp</code></a> from the <code>ZipConduit</code> implementation and added the special cases relating to <code>WONothingYet</code>.  Some of the cases listed above already happen to match the default behaviour.</p>
<p>There are 5 special cases where we need to overwrite the left-first bias for <code>WONothingYet</code>:</p>
<pre><code>    go x@(<span>NeedInput</span> _ _)           (<span>HaveOutput</span> y <span>WONothingYet</span>) = <span>HaveOutput</span> (go x y) <span>WONothingYet</span>
    go x@(<span>Done</span> _)                  (<span>HaveOutput</span> y <span>WONothingYet</span>) = <span>HaveOutput</span> (go x y) <span>WONothingYet</span>
    go (<span>HaveOutput</span> x <span>WONothingYet</span>) y@(<span>NeedInput</span> _ _)           = <span>HaveOutput</span> (go x y) <span>WONothingYet</span>
    go (<span>HaveOutput</span> x <span>WONothingYet</span>) y@(<span>Done</span> _)                  = <span>HaveOutput</span> (go x y) <span>WONothingYet</span>
    go (<span>HaveOutput</span> x <span>WONothingYet</span>) (<span>HaveOutput</span> y <span>WONothingYet</span>) = <span>HaveOutput</span> (go x y) <span>WONothingYet</span></code></pre>
<p>We also included some other cases we modified.  These cases are mainly to make the left-first assumption for values explicit.</p>
<pre><code>    
    go x@<span>Done</span>{} (<span>HaveOutput</span> y o) = <span>HaveOutput</span> (go x y) o
    
    
    go x@(<span>NeedInput</span> _ _) (<span>HaveOutput</span> _ (<span>WOValue</span> _)) =
      error <span>&#34;Invalid case, the left required input but the right was already producing values.&#34;</span>
    
    go x (<span>HaveOutput</span> y o@(<span>WOWork</span> _)) = <span>HaveOutput</span> (go x y) o</code></pre>
<p>The same implementation can also be used to combining the outputs of the then- and else-branches again with the outputs from pass-around branch.</p>
<h2 id="a-closer-look-at-splitting">A closer look at splitting</h2>
<p>The diagram above shows a &#39;Is it a WOValue?&#39; block that splits the stream and sends different values to the branches.</p>
<p>In principle, a <code>ZipConduit</code> and also our variation on it will simply duplicate the incoming values to all the contained conduits.  If we want to send <code>WOValue</code>s to one conduit and <code>WOWork</code>/<code>WONothingYet</code> to another, we can send the same <code>WorkOr a</code> value to all conduits and apply filters within them so that only the relevant stuff is kept.  You&#39;d typically use functions like these:</p>
<pre><code><span>keepOnlyWOValue</span> :: <span>ConduitT</span> (<span>WorkOr</span> a) a <span>IO</span> ()
<span>skipWOValue</span> :: <span>ConduitT</span> (<span>WorkOr</span> a) (<span>WorkOr</span> b) <span>IO</span> ()  </code></pre>
<p>If we really zoom in on the &#39;Is it a WOValue?&#39; split it more looks like this, where the <code>split</code> is implemented using our custom <code>zipConduitApp</code>.</p>
<p><img src="https://media.graphassets.com/IjPrgEzfRPSJGyjo1rO6" alt=""/></p>
<h2 id="buffering-results">Buffering results</h2>
<p>For the &#39;Split on condition&#39; block we can use a similar strategy, but it&#39;s a bit more complicated.  We explained that from a single incoming stream we construct two separate streams for the two conditional branches.</p>
<p>The naive approach would be to let the two branches modify the incoming streams by applying a <code>Conduit.filter</code>.  Something like this:</p>
<pre><code><span>badConditional</span> cond thenBranch elseBranch =
  <span>let</span>
    thenBranch&#39; = <span>Conduit</span>.map (\stream -&gt; stream .| <span>Conduit</span>.filter cond) .| thenBranch
    elseBranch&#39; = <span>Conduit</span>.map (\stream -&gt; stream .| <span>Conduit</span>.filter (not . cond)) .| elseBranch
  <span>in</span>
    ... </code></pre>
<p>This might work, but the tricky part is that the incoming <code>ParallelStream</code> doesn&#39;t really <em>contain</em> the items, but instead it&#39;s a stream that can <em>produce</em> the items.  Producing these items can be an expensive effort, because this might include all kinds of operations from upstream.  In an implementation like this both branches run the incoming stream, so we evaluate the entire upstream twice!</p>
<p>To prevent this, we use a <code>fixConditionalStreams</code> function that runs each incoming <code>ParallelStream</code> just once, and produces two lists of items <code>([Item], [Item])</code>, partitioned on whether the condition holds or not.</p>
<pre><code><span>fixConditionalStreams</span>
  :: (<span>Item</span> -&gt; <span>IO</span> <span>Bool</span>)  
  -&gt; <span>ConduitT</span> (<span>WorkOr</span> <span>ParallelStream</span>)
              (<span>WorkOr</span> ([<span>Item</span>], [<span>Item</span>]))  
              <span>IO</span>
              ()</code></pre>
<p>Then within the conditional branches we can pick the <code>[Item]</code> list that we need, and trivially convert it back to a <code>ParallelStream</code> by using <code>Conduit.yieldMany</code>.</p>
<p>Consuming these <code>ParallelStream</code>s shouldn&#39;t be done within the top level conduit, because then we can&#39;t take advantage of their ability to be run on multiple threads.  Instead we do something similar to the <code>sequentialize</code> that was mentioned earlier, where a small buffer is used to store the evaluated results from several <code>ParallelStream</code>s.  Every <code>ParallelStream</code> that comes in will be given a placeholder in the buffer.  After this, we create a new <code>IO ()</code> action that evaluates the stream and places the result in the placeholder.</p>
<p>The <code>IO ()</code> is forwarded as <code>WOWork</code>, while the <code>ParallelStream</code> is discarded.  Once the <code>WOWork</code> is executed, the result is put in the placeholder <code>MVar</code> and we can yield <code>ParallelStream</code> that just reads from the existing placeholder.  Duplicating this new <code>ParallelStream</code> is cheap and safe, as the actual work is already done by the <code>WOWork</code>.</p>
<p>The idea is roughly similar to these functions (but the code for the true implementation is a bit different):</p>
<pre><code><span>streamToWork</span> :: <span>MVar</span> [<span>Item</span>] -&gt; <span>ParallelStream</span> -&gt; <span>WorkOr</span> a
<span>streamToWork</span> placeholder stream = <span>WOWork</span> $
  <span>Conduit</span>.runConduit (stream .| <span>Conduit</span>.sinkList) &gt;&gt;= putMVar placeholder

<span>readFromBuffer</span> :: <span>MVar</span> [<span>Item</span>] -&gt; <span>ConduitT</span> i (<span>WorkOr</span> <span>ParallelStream</span>) <span>IO</span> ()
<span>readFromBuffer</span> placeholder = <span>do</span>
  items &lt;- nonBlockingTakeMVar placeholder
  <span>Conduit</span>.yield $ <span>WOValue</span> $ <span>Conduit</span>.yieldMany items</code></pre>
<p>The buffer is ordered, so we only return a <code>ParallelStream</code> once the head of the buffer is filled.  That way, we preserve the order.  We can produce multiple <code>WOWork</code> units to fill the buffer, but the <code>ParallelStream</code> will only be produced for the head of the buffer.</p>
<p>When pulling <code>WOWork</code>, we have a preference to produce items that have already been computed.  So if we have a filled placeholder, we produce a new <code>ParallelStream</code> for that placeholder instead of pulling a new <code>ParallelStream</code> from upstream.  That way, our intermediate buffer will remain short.</p>
<p>Note that the <code>fixConditionalStreams</code> function will yield <code>WOWork</code> units to consume the streams and can also yield <code>WONothingYet</code>s when it needs to wait for that work to complete (though it tries to prevent such occurences).  The framework with the <code>WorkOr</code> propagation neatly covers this use case.  Looking back at the diagram for the branching of our conditionals, we do have to insert the <code>fixConditionalStreams</code> before the &#39;is it a WOValue?&#39; split.  Some minor modifications need to be made to pick the right <code>[Item]</code> list but the structure stays mostly the same.</p>
<h2 id="streaming-conditionals">Streaming conditionals</h2>
<p>If <em>all</em> actions in both branches are streaming actions like <code>MAP</code> and <code>FILTER</code>, the whole conditional can become a streaming action as well.  This is mostly done as an optimization, as we don&#39;t need to buffer any results during the evaluation.  This can only be done because we know that every action in the conditional works on separate items, instead of on a collection of items.  We use this property to modify the items in a streaming fashion, instead of all at once, as previous results don&#39;t influence results of items that are still to come.</p>
<p>For each input item we can check the conditional, pass the value through the corresponding branch, and immediately yield an output item if it wasn&#39;t filtered out.  This is the ideal and most efficient case, for which we have a specialized implementation.</p>
<p>For streaming conditionals, we use a <code>ZipConduit</code> to duplicate every item and send 1 copy to the <code>then</code>-branch and the other to the <code>else</code>-branch.  The <code>then</code>-branch starts with a filter to just match those items that match the condition.  The <code>else</code>-branch also has a filter, but with the inverse of the condition.  To prevent us from evaluating the condition twice, we evaluate the condition once and store the result with its item.  The <code>filter</code> on the <code>then</code> and <code>else</code> branch then only has to check a boolean.</p>
<p>Consider the following example:</p>
<pre><code>IF <span>condition</span> <span>THEN</span>
  action1
<span>ELSE</span>
  action2</code></pre>
<p>Assuming that both <code>action1</code> and <code>action2</code> are streaming actions we can convert this using the following Haskell:</p>
<pre><code><span>streamingConditional</span>
  :: (<span>Item</span> -&gt; <span>IO</span> <span>Bool</span>)
  -&gt; <span>ConduitT</span> <span>Item</span> <span>Item</span> <span>IO</span> ()
  -&gt; <span>ConduitT</span> <span>Item</span> <span>Item</span> <span>IO</span> ()
  -&gt; <span>ConduitT</span> <span>Item</span> <span>Item</span> <span>IO</span> ()
<span>streamingConditional</span> condition action1 action2 =
    <span>Conduit</span>.mapM (\i -&gt; (i,) &lt;$&gt; condition i)
                .| getZipConduit (<span>ZipConduit</span> trueConduit &lt;* <span>ZipConduit</span> falseConduit)
  <span>where</span>
    trueConduit, falseConduit :: <span>ConduitT</span> (<span>Item</span>, <span>Bool</span>) <span>Item</span> <span>IO</span> ()
    trueConduit = <span>Conduit</span>.filter snd .| <span>Conduit</span>.map fst .| action1
    falseConduit = <span>Conduit</span>.filter (not . snd) .| <span>Conduit</span>.map fst .| action2</code></pre>
<p>Both <code>trueConduit</code> and <code>falseConduit</code> expect a input items to be paired with a boolean.  The <code>trueConduit</code> will only process items with a <code>True</code>, while <code>falseConduit</code> will only process <code>False</code> items.  This function can be used to modify individual streams.  It only works if every action in the branches is a streaming action.  If any branch contains an aggregating action, we need to revert back to the main conditional tactics.</p>
<pre><code><span>conditional</span>
  :: (<span>Item</span> -&gt; <span>IO</span> <span>Bool</span>) 
  -&gt; <span>ConduitT</span> <span>Item</span> <span>Item</span> <span>IO</span> () 
  -&gt; <span>ConduitT</span> <span>Item</span> <span>Item</span> <span>IO</span> () 
  -&gt; <span>ConduitT</span> (<span>WorkOr</span> <span>ParallelStream</span>) (<span>WorkOr</span> <span>ParallelStream</span>) <span>IO</span> ()
<span>conditional</span> condition action1 action2 =
  <span>let</span> mapStream parallelStream = parallelStream .| streamingConditional condition action1 action2
  <span>in</span> <span>Conduit</span>.map (fmap mapStream)</code></pre>
<p>The main difference between streaming conditionals and aggregating conditionals is the level of abstraction they work on.  Conditionals normally work on on all items, so we need to collect all streams and apply the condition once we have all streams.  Therefore, aggregating conditionals work on entire streams and are passing along instructions.  If we use streaming, we know that we don&#39;t need all streams at once and we can push the conditional into the instruction, thereby applying the conditional in a streaming fashion.</p>
<p>If you like overcomplicated diagrams, we could represent it like this:</p>
<p><img src="https://media.graphassets.com/C9vVox7Q7WSpdX5XJEis" alt=""/></p>
<h2 id="conclusion">Conclusion</h2>
<p>In this series of blog posts we&#39;ve set up a system for parallel streaming evaluation.</p>
<p>We showed how we can pass along computed values <em>and</em> parallel work units in the same stream, by using <code>ConduitT</code> with the <code>WorkOr</code> type:</p>
<pre><code><span><span>data</span> <span>WorkOr</span> a</span>
  = <span>WOWork</span> (<span>IO</span> ())
  | <span>WOValue</span> a
  | <span>WONothingYet</span></code></pre>
<p>This gives us a solid base, where we can write parallel streaming components like <code>map</code>, <code>deduplicate</code>, <code>sequentialize</code> and conditional aggregations.  These all seamlessly connect together into a single parallel streaming pipeline.  Running the pipeline is surprisingly simple with our pipe-passing implementation, which makes optimal use of the work-stealing scheduler that GHC&#39;s runtime system provides.  By implementing everything in a non-blocking fashion we were able to accurately track how much work our threads are doing.</p>
<p>The system has proven to be very flexible and we&#39;re happily using this in our production systems.  It can run multiple threads when it&#39;s useful, but can also scale back to efficient sequential evaluation (equivalent to just using <code>runConduit</code>) when it&#39;s running things that aren&#39;t parallelizable.  It has shown to be an improvement over our earlier sequential implementations in every way.</p>
<p>What do you think about our approach? Do you have a better name for the <code>WorkOr</code> type?  Let us know <a target="_blank" rel="noop" href="https://www.reddit.com/r/haskell/comments/10kyfkg/parallel_streaming_in_haskell_part_4_conditionals/">on reddit</a> or <a target="_blank" rel="noop" href="https://news.ycombinator.com/item?id=34517906">on hackernews</a>.</p>
<p><a id="footnote-1" href="#footnote-1-backlink">1</a>: We could also choose to send <code>WOWork</code> through <em>one</em> of the conditional branches, as long as we don&#39;t send them through both because we don&#39;t want to receive the same work unit twice and evaluate it twice. The &#39;is it a WOValue?&#39; split is cleaner and makes more sense to implement as a reusable function. <a href="#footnote-1-backlink">↩</a></p></div></div></div>
  </body>
</html>
