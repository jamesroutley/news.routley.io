<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://gist.github.com/attractivechaos/d2efc77cc1db56bbd5fc597987e73338">Original</a>
    <h1>Lessons from Hash Table Merging</h1>
    
    <div id="readability-page-1" class="page"><div>
  <div id="file-2026-01-01_hashmap-merge-md">
      
      <div id="file-2026-01-01_hashmap-merge-md-readme" tabindex="0" role="region" aria-label="2026-01-01_hashmap-merge.md content, created by attractivechaos on 12:09AM on January 02.">
    <article itemprop="text"><p dir="auto"><a href="https://github.com/attractivechaos/gistlog"><img src="https://camo.githubusercontent.com/2bfdc27f2aa5bdfbcd0f1990c2e0b64104b781384339f296f9756bd7cf794171/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4f746865722d706f7374732d626c7565" alt="Other posts" data-canonical-src="https://img.shields.io/badge/Other-posts-blue"/></a></p>

<p dir="auto">Merging two hash maps seems like an O(N) operation. However, while merging millions of keys, I encountered a massive &gt;10x performance degradation unexpectedly. This post explores why some of the most popular libraries fall into this trap and how to fix it. The source code is <a href="https://github.com/attractivechaos/gistlog/tree/master/src/ht-merge">available here</a>.</p>
<ul dir="auto">
<li><a href="#setup">The set up</a></li>
<li><a href="#mergeslow">Merging hash tables may be slow</a></li>
<li><a href="#fastmerge">Efficient hash table merging</a>
<ul dir="auto">
<li><a href="#solution1">Solution I: salted hash function</a></li>
<li><a href="#solution2">Solution II: preallocation</a></li>
<li><a href="#solution3">Solution III: stride iteration</a></li>
<li><a href="#other">Other contenders</a></li>
</ul>
</li>
<li><a href="#conclude">Conclusion</a></li>
<li><a href="#appendix">Appendix</a></li>
</ul>

<p dir="auto">I generated 3<em>N</em> random numbers with <a href="https://rosettacode.org/wiki/Pseudo-random_numbers/Splitmix64" rel="nofollow">splitmix64</a>, where <em>N</em> ranges from 7 to 31 million. I put the first <em>N</em> numbers in a hash map and the rest 2<em>N</em> numbers in a second hash map. Then I merged the second map into the first map and recorded timing on M4 Pro. I used a decent hash function copied from a <a href="https://nullprogram.com/blog/2018/07/31/" rel="nofollow">blog post</a> by Chris Wellons:</p>
<div dir="auto"><pre><span>static</span> <span>inline</span> <span>uint64_t</span> <span>hash64</span>(<span>uint64_t</span> <span>x</span>) {
    <span>x</span> <span>=</span> (<span>x</span> ^ (<span>x</span>&gt;&gt;<span>32</span>)) <span>*</span> <span>0xd6e8feb86659fd93ULL</span>;
    <span>x</span> <span>=</span> (<span>x</span> ^ (<span>x</span>&gt;&gt;<span>32</span>)) <span>*</span> <span>0xd6e8feb86659fd93ULL</span>;
    <span>return</span> <span>x</span> ^ (<span>x</span>&gt;&gt;<span>32</span>);
}</pre></div>
<p dir="auto">I evaluated the following hash table libraries, all based on <a href="https://en.wikipedia.org/wiki/Linear_probing" rel="nofollow">linear probing</a>.</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Library</th>
<th>Version</th>
<th>Language</th>
<th>Algorithm</th>
</tr>
</thead>
<tbody>
<tr>
<td><a href="https://github.com/abseil/abseil-cpp">Abseil</a></td>
<td>20250814.1</td>
<td>C++</td>
<td><a href="https://abseil.io/blog/20180927-swisstables" rel="nofollow">Swiss Table</a></td>
</tr>
<tr>
<td><a href="https://www.boost.org/doc/libs/1_61_0/doc/html/boost/container/flat_map.html" rel="nofollow">Boost</a></td>
<td>1.90.0</td>
<td>C++</td>
<td>Swiss Table</td>
</tr>
<tr>
<td><a href="https://github.com/martinus/unordered_dense">unordered_dense</a></td>
<td>4.8.1</td>
<td>C++</td>
<td><a href="https://en.wikipedia.org/wiki/Hash_table#Robin_Hood_hashing" rel="nofollow">Robin Hood hashing</a></td>
</tr>
<tr>
<td><a href="https://github.com/attractivechaos/khashl">khashl</a></td>
<td>r40</td>
<td>C</td>
<td>Basic linear probing</td>
</tr>
<tr>
<td><a href="https://doc.rust-lang.org/std/collections/struct.HashMap.html" rel="nofollow">Rust standard</a></td>
<td>1.92.0</td>
<td>Rust</td>
<td>Swiss Table</td>
</tr>
<tr>
<td><a href="https://github.com/rust-lang/hashbrown">hashbrown</a></td>
<td>0.16.1</td>
<td>Rust</td>
<td>Swiss Table</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<div dir="auto"><h2 dir="auto"><a name="user-content-mergeslow"></a>Merging hash tables may be slow</h2><a id="user-content-merging-hash-tables-may-be-slow" aria-label="Permalink: Merging hash tables may be slow" href="#merging-hash-tables-may-be-slow"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">The plot on the left shows the time for inserting 2<em>N</em> keys to an empty hash map, and the plot on right shows the time for merging a map with 2<em>N</em> keys into another map with <em>N</em> keys.</p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/563093/531376378-c899f6bb-64e4-42c1-9ace-5b9ac9346c3f.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Njc4OTcyNjAsIm5iZiI6MTc2Nzg5Njk2MCwicGF0aCI6Ii81NjMwOTMvNTMxMzc2Mzc4LWM4OTlmNmJiLTY0ZTQtNDJjMS05YWNlLTViOWFjOTM0NmMzZi5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjYwMTA4JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI2MDEwOFQxODI5MjBaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1mYzIyNmM1YjVjYjUxYmRhY2Q3NTg2MmE0MzBhNDg3ZDdkOTIyNWEyYWQ0NDE5NzgwMDcwZmQ3NzE2ZDU0MmRkJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.HtXUX1_CQHMKpB_ntMZz7ST-EpiAyvkhK3a3_GOvbVo"><img width="100%" alt="image" src="https://private-user-images.githubusercontent.com/563093/531376378-c899f6bb-64e4-42c1-9ace-5b9ac9346c3f.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Njc4OTcyNjAsIm5iZiI6MTc2Nzg5Njk2MCwicGF0aCI6Ii81NjMwOTMvNTMxMzc2Mzc4LWM4OTlmNmJiLTY0ZTQtNDJjMS05YWNlLTViOWFjOTM0NmMzZi5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjYwMTA4JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI2MDEwOFQxODI5MjBaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT1mYzIyNmM1YjVjYjUxYmRhY2Q3NTg2MmE0MzBhNDg3ZDdkOTIyNWEyYWQ0NDE5NzgwMDcwZmQ3NzE2ZDU0MmRkJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.HtXUX1_CQHMKpB_ntMZz7ST-EpiAyvkhK3a3_GOvbVo"/></a>
<p dir="auto">Notably, Abseil and Boost are &gt;20X slower on hash table merging than hash table creation, while unordered_dense and khashl are not affected (I will come to them <a href="#solution2">later</a>). To understand the cause, suppose we have hash map <code>h0</code> and <code>h1</code> of the same size and we merge <code>h1</code> into <code>h0</code> with:</p>
<div dir="auto"><pre><span>for</span> (<span>auto</span> <span>const</span> &amp;iter : h1)
    h0[iter.first] += iter.second;</pre></div>
<p dir="auto">With a typical iterator implementation, we traverse keys in table <code>h1</code> in the order of their hash codes. Because <code>h0</code> and <code>h1</code> use the same hash function (also known as &#34;hasher&#34;), the original bucket position of a key in <code>h1</code> is identical to the position in <code>h0</code>. With the loop above, we will populate the beginning of <code>h0</code> first. That part of <code>h0</code> is almost fully saturated although on average, <code>h0</code> has not reached the targeted <a href="https://en.wikipedia.org/wiki/Hash_table#Load_factor" rel="nofollow">load factor</a>. Such <a href="https://en.wikipedia.org/wiki/Primary_clustering" rel="nofollow">primary clustering</a> leads to the poor performance. All Swiss Table-based implementations, including the Rust libraries in the table, suffer from this issue if a fixed hash function is naively used.</p>
<div dir="auto"><h2 dir="auto"><a name="user-content-fastmerge"></a>Efficient hash table merging</h2><a id="user-content-efficient-hash-table-merging" aria-label="Permalink: Efficient hash table merging" href="#efficient-hash-table-merging"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto"><h3 dir="auto"><a name="user-content-solution1"></a>Solution I: salted hash function</h3><a id="user-content-solution-i-salted-hash-function" aria-label="Permalink: Solution I: salted hash function" href="#solution-i-salted-hash-function"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">The figure above uses my own hasher. Using Abseil&#39;s default hasher wouldn&#39;t have this problem. Internally, Abseil adds a <a href="https://github.com/abseil/abseil-cpp/blob/7599e36e7cbad38ec77cadd959d3a45d2124800a/absl/container/internal/raw_hash_set.h#L431-L462">random 16-bit seed</a> to each hash table instance and mixes this seed with hash codes. As a result, the same key is placed differently in <code>h0</code> and <code>h1</code> above. The problem described above wouldn&#39;t exist.</p>
<p dir="auto">When you have to use your own hasher for specialized data type, you won&#39;t benefit from Abseil&#39;s builtin hash functions, but you can wrap your hasher with a class like this:</p>
<div dir="auto"><pre><span>class</span> <span>RandHasher</span> {
    <span>size_t</span> seed;
<span>public:</span>
    <span>RandHasher</span>(<span>void</span>) {
        std::random_device rd;
        seed = std::uniform_int_distribution&lt;<span>size_t</span>&gt;{}(rd);
    }
    <span>size_t</span> <span>operator</span>()(<span>const</span> <span>uint64_t</span> x) <span>const</span> {
        <span>return</span> <span>hash64</span>(x ^ seed); <span><span>//</span> FIXME: for generic keys, mix hash(x) and seed</span>
    }
};</pre></div>
<p dir="auto">The plot on the left shows the timing with a salted hasher. You can see hash table merging is as fast as table creation now. Salted hasher was introduced to alleviate <a href="https://en.wikipedia.org/wiki/Collision_attack#Hash_flooding" rel="nofollow">hash flooding</a>. I don&#39;t know if the original designer has table merging in mind, but it works well anyway.</p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/563093/531376309-b4c97927-31f2-44ed-9dd4-0070924e77c7.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Njc4OTcyNjAsIm5iZiI6MTc2Nzg5Njk2MCwicGF0aCI6Ii81NjMwOTMvNTMxMzc2MzA5LWI0Yzk3OTI3LTMxZjItNDRlZC05ZGQ0LTAwNzA5MjRlNzdjNy5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjYwMTA4JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI2MDEwOFQxODI5MjBaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0yMWZkZGMyZmIxMzEwYmViOTNkZGE2ZWE4OGQyMDVlZjlkMDE5YjY1MmE0ZTBlODJhMzc4NzQ0NWNmYTk0OTU4JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.O5FOVCXPOCbwjZ1dRmRDDaQvvH3haMbIXmOOC0mWVbs"><img width="100%" alt="image" src="https://private-user-images.githubusercontent.com/563093/531376309-b4c97927-31f2-44ed-9dd4-0070924e77c7.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Njc4OTcyNjAsIm5iZiI6MTc2Nzg5Njk2MCwicGF0aCI6Ii81NjMwOTMvNTMxMzc2MzA5LWI0Yzk3OTI3LTMxZjItNDRlZC05ZGQ0LTAwNzA5MjRlNzdjNy5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjYwMTA4JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI2MDEwOFQxODI5MjBaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT0yMWZkZGMyZmIxMzEwYmViOTNkZGE2ZWE4OGQyMDVlZjlkMDE5YjY1MmE0ZTBlODJhMzc4NzQ0NWNmYTk0OTU4JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.O5FOVCXPOCbwjZ1dRmRDDaQvvH3haMbIXmOOC0mWVbs"/></a>
<div dir="auto"><h3 dir="auto"><a name="user-content-solution2"></a>Solution II: preallocation</h3><a id="user-content-solution-ii-preallocation" aria-label="Permalink: Solution II: preallocation" href="#solution-ii-preallocation"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">The second strategy is to reserve enough space to hold both <code>h0</code> and <code>h1</code>. Although <code>h0</code> will not be populated randomly when merging <code>h1</code> into <code>h0</code>, primary clustering wouldn&#39;t occur due to sufficient empty buckets. This solution is more cache friendly and faster in practice than salted hasher (plot on the right). The downside is that when <code>h0</code> and <code>h1</code> have many duplicates, preallocation may waste memory.</p>
<div dir="auto"><h3 dir="auto"><a name="user-content-solution3"></a>Solution III: stride iteration</h3><a id="user-content-solution-iii-stride-iteration" aria-label="Permalink: Solution III: stride iteration" href="#solution-iii-stride-iteration"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">unordered_dense is efficient on hash table merging because its iterator traverses keys in the input order, not in the hash order. With a random input order from splitmix64, <code>h0</code> will be populated randomly during merging without primary clustering. Inspired by this observation, I modified the khashl iteration loop to (conceptually):</p>
<div dir="auto"><pre><span>for</span> (<span>size_t</span> <span>i</span> <span>=</span> <span>0</span>, <span>k1</span> <span>=</span> <span>0</span>; <span>i</span> <span>&lt;</span> <span>h1</span>.<span>n_buckets</span>; <span>++</span><span>i</span>) {
    <span>if</span> (<span>h1</span>.<span>bucket</span>[<span>k1</span>].<span>occupied</span>)
        <span>h0</span>.<span>insert</span>(<span>h1</span>.<span>bucket</span>[<span>k1</span>]);
    <span>k1</span> <span>=</span> (<span>k1</span> <span>+</span> <span>7</span>) % <span>h1</span>.<span>n_buckets</span>; <span>// instead of k1 = (k1 + 1) % h1.n_buckets</span>
}</pre></div>
<p dir="auto">The loop guarantees to visit each bucket in <code>h1</code> exactly once as long as the step size (7 here) and <code>h1.n_buckets</code> share no common factor. As is shown in the first plot on the right, this strategy can merge hash tables efficiently even if we use a fixed hasher. With better data locality, it is also faster than salted hasher. It is also possible to use other types of iteration such as quadratic iteration.</p>

<p dir="auto">In comparison to linear probing, quadratic probing is more robust to non-random input order. This improves the performance but not as much as the other solutions above. I also tried to shard the bigger hash table into smaller subtables. It helps but does not solve the root problem. It is not recommended, either.</p>

<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Strategy</th>
<th>Merging performance</th>
<th>Complexity</th>
<th>Trade-offs</th>
</tr>
</thead>
<tbody>
<tr>
<td>Salted hasher</td>
<td>Good</td>
<td>Medium</td>
<td>Minor overhead per hash</td>
</tr>
<tr>
<td>Preallocaion</td>
<td>Best</td>
<td>Low</td>
<td>Higher memory floor</td>
</tr>
<tr>
<td>Stride iteration</td>
<td>Better</td>
<td>High</td>
<td>Requiring library-level changes</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">Merging hash tables can be <em><strong>very slow</strong></em> when you use a wrong library or a wrong hash function. Among the three solutions discussed above, preallocation (Solution II) might be the easiest to implement and can be the fastest if <code>h0</code> and <code>h1</code> have little overlap (plot below). Salted hasher (Solution I) is slower for merging, but this is not a concern for most other operations. Salted hasher also has other benefit and comes by default with Abseil. Stride iteration (Solution III) is a balanced strategy, but it is hard to implement in the user space. <strong>There is not a clear winner</strong> in my opinion.</p>
<a target="_blank" rel="noopener noreferrer" href="https://private-user-images.githubusercontent.com/563093/531379831-6d6ed508-f5d6-45c6-b089-34cd045defc2.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Njc4OTcyNjAsIm5iZiI6MTc2Nzg5Njk2MCwicGF0aCI6Ii81NjMwOTMvNTMxMzc5ODMxLTZkNmVkNTA4LWY1ZDYtNDVjNi1iMDg5LTM0Y2QwNDVkZWZjMi5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjYwMTA4JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI2MDEwOFQxODI5MjBaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT00ZDdhOTIxYmJlZGY5ZjAxMDE0ZjE5M2FiYmY0ZjFiYzUxZjdhNzQ3NTU3OWE2YmIyYzU5NjRhOGNiMTE3NjFiJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.MNQvgi-nsstvdM8mwmZJdFnD2cpPYfcDL3-CXZCHfyQ"><img width="100%" alt="image" src="https://private-user-images.githubusercontent.com/563093/531379831-6d6ed508-f5d6-45c6-b089-34cd045defc2.png?jwt=eyJ0eXAiOiJKV1QiLCJhbGciOiJIUzI1NiJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Njc4OTcyNjAsIm5iZiI6MTc2Nzg5Njk2MCwicGF0aCI6Ii81NjMwOTMvNTMxMzc5ODMxLTZkNmVkNTA4LWY1ZDYtNDVjNi1iMDg5LTM0Y2QwNDVkZWZjMi5wbmc_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjYwMTA4JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI2MDEwOFQxODI5MjBaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT00ZDdhOTIxYmJlZGY5ZjAxMDE0ZjE5M2FiYmY0ZjFiYzUxZjdhNzQ3NTU3OWE2YmIyYzU5NjRhOGNiMTE3NjFiJlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.MNQvgi-nsstvdM8mwmZJdFnD2cpPYfcDL3-CXZCHfyQ"/></a>

<p dir="auto">Widely <a href="https://jacksonallan.github.io/c_cpp_hash_tables_benchmark/" rel="nofollow">considered</a> as the fastest hash table in C++, Boost is more than twice as fast as Abseil (plot above), which Swiss Table was originated from. Rust with my own fixed hasher is as fast as Boost. Nonetheless, to be more robust to hash flooding, Rust uses <a href="https://en.wikipedia.org/wiki/SipHash" rel="nofollow">SipHash</a> by default which is several times slower. When performance matters, use your own hash functions.</p>
</article>
  </div>

  </div>
</div></div>
  </body>
</html>
