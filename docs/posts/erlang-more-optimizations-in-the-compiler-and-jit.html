<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.erlang.org/blog/more-optimizations/">Original</a>
    <h1>Erlang: More Optimizations in the Compiler and JIT</h1>
    
    <div id="readability-page-1" class="page"><div>
    <div>
        <div>
            <article>
    

    <div>
        
        
        
        
        <p>This post explores the enhanced type-based optimizations
and the other performance improvements in Erlang/OTP 26.</p>
      <h3 id="what-to-expect-of-the-jit-in-otp-26">
        
        
          What to expect of the JIT in OTP 26 <a href="#what-to-expect-of-the-jit-in-otp-26">#</a>
        
        
      </h3>
    

<p>In OTP 25, the compiler was updated to embed type information in
the BEAM file and the JIT was extended to emit better code based
on that type information. Those improvements were described in
the blog post <a href="https://www.erlang.org/blog/type-based-optimizations-in-the-jit/">Type-Based Optimizations in the JIT</a>.</p>

<p>As mentioned in that blog post, there were limitations in both the
compiler and the JIT that prevented many optimizations. In OTP 26, the
compiler will produce better type information and the JIT will take
better advantage of the improved type information, typically resulting
in fewer redundant type tests and smaller native code size.</p>

<p>A new BEAM instruction introduced in OTP 26 makes record updates
faster by a small but measurable amount.</p>

<p>The most noticable performance improvements in OTP 26 are probably for
matching and construction of binaries using the bit syntax. Those
improvements, combined with changes to the <code>base64</code> module itself,
makes encoding to Base64 about 4 times as fast and decoding from
Base64 more than 3 times as fast.</p>
      <h3 id="please-try-this-at-home">
        
        
          Please try this at home! <a href="#please-try-this-at-home">#</a>
        
        
      </h3>
    

<p>While this blog post will show many examples of generated code, I have
attempted to explain the optimizations in English as well. Feel free
to skip the code examples.</p>

<p>On the other hand, if you want more code examples…</p>

<p>To examine the native code for loaded modules, start the runtime system like this:</p>

<pre><code>erl +JDdump true
</code></pre>

<p>The native code for all modules that are loaded will be dumped to files with the
extension <code>.asm</code>.</p>

<p>To examine the BEAM code for a module, use the <code>-S</code> option when
compiling. For example:</p>

<pre><code>erlc -S base64.erl
</code></pre>
      <h3 id="quick-overview-of-type-based-optimizations-in-otp-25">
        
        
          Quick overview of type-based optimizations in OTP 25 <a href="#quick-overview-of-type-based-optimizations-in-otp-25">#</a>
        
        
      </h3>
    

<p>Let’s quickly summarize the type-based optimizations in OTP 25. For more
details, see the <a href="https://www.erlang.org/blog/type-based-optimizations-in-the-jit/">aformentioned blog post</a>.</p>

<p>First consider an addition of two values with nothing known about
their types:</p>

<pre><code>add1(X, Y) -&gt;
    X + Y.
</code></pre>

<p>The <a href="https://www.erlang.org/blog/a-brief-beam-primer">BEAM code</a> looks like this:</p>

<pre><code>    {gc_bif,&#39;+&#39;,{f,0},2,[{x,0},{x,1}],{x,0}}.
    return.
</code></pre>

<p>Without any information about the operands, the JIT must emit code
that can handle all possible types for the operands. For the x86_64
architecture, 14 native instructions are needed.</p>

<p>If the type of the operands are known to be integers sufficiently
small making overflow impossible, the JIT needs to emit only 5 native
instructions for the addition.</p>

<p>Here is an example where the types and ranges of the operands for the
<code>+</code> operator are known:</p>

<pre><code>add5(X, Y) when X =:= X band 16#3FF,
                Y =:= Y band 16#3FF -&gt;
    X + Y.
</code></pre>

<p>The BEAM code for this function is as follows:</p>

<pre><code>    {gc_bif,&#39;band&#39;,{f,24},2,[{x,0},{integer,1023}],{x,2}}.
    {test,is_eq_exact,
          {f,24},
          [{tr,{x,0},{t_integer,any}},{tr,{x,2},{t_integer,{0,1023}}}]}.
    {gc_bif,&#39;band&#39;,{f,24},2,[{x,1},{integer,1023}],{x,2}}.
    {test,is_eq_exact,
          {f,24},
          [{tr,{x,1},{t_integer,any}},{tr,{x,2},{t_integer,{0,1023}}}]}.
    {gc_bif,&#39;+&#39;,
            {f,0},
            2,
            [{tr,{x,0},{t_integer,{0,1023}}},{tr,{x,1},{t_integer,{0,1023}}}],
            {x,0}}.
    return.
</code></pre>

<p>The register operands (<code>{x,0}</code> and <code>{x,1}</code>) have now been annotated with
type information:</p>

<pre><code>{tr,Register,Type}
</code></pre>

<p>That is, each register operand is a three-tuple with <code>tr</code> as the first
element. <code>tr</code> stands for <strong>typed register</strong>. The second element is the
BEAM register (<code>{x,0}</code> or <code>{x,1}</code> in this case), and the third element
is the type of the register in the compiler’s internal type
representation. <code>{t_integer,{0,1023}}</code> means that the value is an
integer in the inclusive range 0 through 1023.</p>

<p>With that type information, the JIT emits the following native code
for the <code>+</code> operator:</p>

<pre><code># i_plus_ssjd
# add without overflow check
    mov rax, qword ptr [rbx]
    mov rsi, qword ptr [rbx+8]
    and rax, -16               ; Zero the tag bits
    add rax, rsi
    mov qword ptr [rbx], rax
</code></pre>

<p>(Lines starting with <code>#</code> are comments emitted by the JIT, while the
text that follows <code>;</code> is a comment added by me for clarification.)</p>

<p>The reduction in code size from 14 instructions down to 5 is nice, but
having to express the range check in that convoluted way using <code>band</code>
can hardly be called nice nor natural.</p>

<p>If we try to express the range checks in a more natural way:</p>

<pre><code>add4(X, Y) when is_integer(X), 0 =&lt; X, X &lt; 16#400,
                is_integer(Y), 0 =&lt; Y, Y &lt; 16#400 -&gt;
    X + Y.
</code></pre>

<p>the compiler in OTP 25 will no longer be able to figure out the
ranges for the operands. Here is the BEAM code:</p>

<pre><code>    {test,is_integer,{f,22},[{x,0}]}.
    {test,is_ge,{f,22},[{tr,{x,0},{t_integer,any}},{integer,0}]}.
    {test,is_lt,{f,22},[{tr,{x,0},{t_integer,any}},{integer,1024}]}.
    {test,is_integer,{f,22},[{x,1}]}.
    {test,is_ge,{f,22},[{tr,{x,1},{t_integer,any}},{integer,0}]}.
    {test,is_lt,{f,22},[{tr,{x,1},{t_integer,any}},{integer,1024}]}.
    {gc_bif,&#39;+&#39;,
            {f,0},
            2,
            [{tr,{x,0},{t_integer,any}},{tr,{x,1},{t_integer,any}}],
            {x,0}}.
    return.
</code></pre>

<p>Because of that severe limitation in the compiler’s value range
analysis, I wrote:</p>

<blockquote>
  <p>We aim to improve the type analysis and optimizations in OTP 26 and
generate better code for this example.</p>
</blockquote>
      <h3 id="the-enhanced-type-based-optimizations-in-otp-26">
        
        
          The enhanced type-based optimizations in OTP 26 <a href="#the-enhanced-type-based-optimizations-in-otp-26">#</a>
        
        
      </h3>
    

<p>Compiling the same example with OTP 26, the result is:</p>

<pre><code>    {test,is_integer,{f,19},[{x,0}]}.
    {test,is_ge,{f,19},[{tr,{x,0},{t_integer,any}},{integer,0}]}.
    {test,is_ge,{f,19},[{integer,1023},{tr,{x,0},{t_integer,{0,&#39;+inf&#39;}}}]}.
    {test,is_integer,{f,19},[{x,1}]}.
    {test,is_ge,{f,19},[{tr,{x,1},{t_integer,any}},{integer,0}]}.
    {test,is_ge,{f,19},[{integer,1023},{tr,{x,1},{t_integer,{0,&#39;+inf&#39;}}}]}.
    {gc_bif,&#39;+&#39;,
            {f,0},
            2,
            [{tr,{x,0},{t_integer,{0,1023}}},{tr,{x,1},{t_integer,{0,1023}}}],
            {x,0}}.
</code></pre>

<p>The BEAM instruction for the <code>+</code> operator now have ranges for its operands.</p>

<p>Let’s look at little bit closer at the first three instructions, which
corresponds to the guard test <code>is_integer(X), 0 =&lt; X, X &lt; 16#400</code>.</p>

<p>First is the guard check for an integer:</p>

<pre><code>    {test,is_integer,{f,19},[{x,0}]}.
</code></pre>

<p>It is followed by the guard test <code>0 =&lt; X</code> (rewritten to <code>X &gt;= 0</code> by the compiler):</p>

<pre><code>    {test,is_ge,{f,19},[{tr,{x,0},{t_integer,any}},{integer,0}]}.
</code></pre>

<p>As a result of the <code>is_integer/1</code> test it is known that <code>{x,0}</code>
is an integer.</p>

<p>The third instruction corresponds to <code>X &lt; 16#400</code>, which the compiler
has rewritten to <code>16#3FF &gt;= X</code> (<code>1023 &gt;= X</code>):</p>

<pre><code>    {test,is_ge,{f,19},[{integer,1023},{tr,{x,0},{t_integer,{0,&#39;+inf&#39;}}}]}.
</code></pre>

<p>In the type for the <code>{x,0}</code> register there is something new for
OTP 26. It says that the range is 0 through <code>&#39;+inf&#39;</code>, that is, from 0 up
to positive infinity. Combining that range with the range from this
instruction, the Erlang compiler can infer that if this instruction
succeeds, the type for <code>{x,0}</code> is <code>t_integer,{0,1023}}</code>.</p>
      <h3 id="combining-guard-tests">
        
        
          Combining guard tests <a href="#combining-guard-tests">#</a>
        
        
      </h3>
    

<p>In OTP 25, the JIT would emit native code for each BEAM instruction
in the guard individually. When translated individually, the three guards
tests for one of the variables each require 11 native instructions, or 33
instructions for all three.</p>

<p>By having the BEAM loader combine the three guard tests into a
single <code>is_int_range</code> instruction, the JIT is capable of doing a much
better job and emit a mere 6 native instructions.</p>

<p>How is that possible?</p>

<p>As individual BEAM instructions, each guard test needs 5 instructions
to fetch the value from <code>{x,0}</code> and test that the value is a small
integer. As a combined instruction, that only needs to be done once.
Other parts of the guard tests also become redundant in the combined
instruction and can be omitted. For example, the <code>is_integer/1</code> type
test will also succeed if its argument is a <strong>bignum</strong> (an integer
that does not fit in a machine word). Clearly, a bignum will fall well
outside the range 0 through 1023, so if the argument is not a small
integer, the combined guard test will fail immediately.</p>

<p>With those and some other simplifications, we end up with the following
native instructions:</p>

<pre><code># is_int_in_range_fScc
    mov rax, qword ptr [rbx]
    sub rax, 15
    test al, 15
    short jne label_19
    cmp rax, 16368
    short ja label_19
</code></pre>

<p>The first instruction fetches the value of <code>{x,0}</code> to the CPU
register <code>rax</code>:</p>

<pre><code>    mov rax, qword ptr [rbx]
</code></pre>

<p>The next instruction subtracts the <a href="http://www.it.uu.se/research/publications/reports/2000-029/2000-029-nc.pdf">tagged value</a> for the lower
bound of the range. Since the lower bound of the range is 0 and the
tag for small integers is 15, the value that is subtracted
is <code>16 * 0 + 15</code> or simply 15. (For small integers, the runtime system
uses the 4 least significant bits of the word as tag bits.)
If the lower bound would have been 1, the value to be subtracted would
have been <code>16 * 1 + 15</code> or 31:</p>

<pre><code>    sub rax, 15
</code></pre>

<p>The subtraction achieves two aims at once. Firstly, it simplifies the
tag test in the next two instructions because if the value of of
<code>{x,0}</code> is a small integer, the 4 least significants bits will now be
zero:</p>

<pre><code>    test al, 15
    short jne label_19
</code></pre>

<p>The <code>test al, 15</code> instruction does a bitwise AND operation of the
lower byte of the CPU register <code>rax</code>, discarding the result but
setting CPU flags depending on the value. The next instruction tests
whether the result was nonzero (the tag was not the tag for a small
integer), in which case the test fails and a jump to the failure
label is made.</p>

<p>The second aim for the subtraction is to simplify the range check.
If the value being tested was below the lower bound, the value
of <code>rax</code> will be negative after the subtraction.</p>

<p>Since integers are represented in <a href="https://en.wikipedia.org/wiki/Two%27s_complement">two’s complement notation</a>, a
signed negative integer interpreted as an unsigned integer will be a
very large integer. Therefore, both bounds can be checked at once
using the old trick of treating the value in <code>rax</code> as unsigned:</p>

<pre><code>    cmp rax, 16368
    short ja label_19
</code></pre>

<p>The <code>cmp rax, 16368</code> instruction compares the value in <code>rax</code> with the
difference of the tagged upper bound and the tagged lower bound, that
is:</p>

<pre><code>(16 * 1023 + 15) - (16 * 0 + 15)
</code></pre>

<p><code>ja</code> stands for “Jump (if) Above”, that is, jump if the CPU flags
indicates that in previous comparison of unsigned integers the first
integer was greater than the second. Since a negative number
represented in two’s complement notation looks like a huge integer
when interpreted as an unsigned integer, <code>short ja label_19</code> will
transfer control to the failure label for values both below the lower
bound and above the upper bound.</p>
      <h3 id="more-code-generation-improvements">
        
        
          More code generation improvements <a href="#more-code-generation-improvements">#</a>
        
        
      </h3>
    

<p>The JIT in OTP 26 generates better code for common combinations of
relational operators. In order to reduce the number of combinations
that the JIT will need to handle, the compiler rewrites the <code>&lt;</code>
operator to <code>&gt;=</code> if possible. In the previous example, it was shown
that the compiler rewrote <code>X &lt; 1024</code> to <code>1023 &gt;= X</code>.</p>

<p>Let’s look at a contrived example to show (off) a few more
improvements in the code generation:</p>

<pre><code>add6(M) when is_map(M) -&gt;
    A = map_size(M),
    if
        9 &lt; A, A &lt; 100 -&gt;
            A + 6
    end.
</code></pre>

<p>The main part of the BEAM code looks like this:</p>

<pre><code>    {test,is_map,{f,41},[{x,0}]}.
    {gc_bif,map_size,{f,0},1,[{tr,{x,0},{t_map,any,any}}],{x,0}}.
    {test,is_ge,
          {f,43},
          [{tr,{x,0},{t_integer,{0,288230376151711743}}},{integer,10}]}.
    {test,is_ge,
          {f,43},
          [{integer,99},{tr,{x,0},{t_integer,{10,288230376151711743}}}]}.
    {gc_bif,&#39;+&#39;,{f,0},1,[{tr,{x,0},{t_integer,{10,99}}},{integer,6}],{x,0}}.
    return.
</code></pre>

<p>In OTP 26, the JIT will inline the code for many of the most
frequently used guard BIFs. Here is the native code for the
<code>map_size/1</code> call:</p>

<pre><code># bif_map_size_jsd
    mov rax, qword ptr [rbx]      ; Fetch map from {x,0}
# skipped type check because the argument is always a map
    mov rax, qword ptr [rax+6]    ; Fetch size of map
    shl rax, 4
    or al, 15                     ; Tag as small integer
    mov qword ptr [rbx], rax      ; Store size in {x,0}
</code></pre>

<p>The two <code>is_ge</code> instructions are combined by the BEAM loader into
an <code>is_in_range</code> instruction:</p>

<pre><code># is_in_range_ffScc
# simplified fetching of BEAM register
    mov rdi, rax
# skipped test for small operand since it always small
    sub rdi, 175
    cmp rdi, 1424
    ja label_43
</code></pre>

<p>The first instruction is a new optimization in OTP 26. Normally <code>{x,0}</code> is
fetched using the instruction <code>mov rax, qword ptr [rbx]</code>. However, in this
case, the last instruction in the previous BEAM instruction is the instruction
<code>mov qword ptr [rbx], rax</code>. Therefore, since it is known that the contents of
<code>{x,0}</code> is already in CPU register <code>rax</code>, the instruction can be simplified
to:</p>

<pre><code># simplified fetching of BEAM register
    mov rdi, rax
</code></pre>

<p>The size of a map that will fit in memory on a 64-bit computer is always
a small integer, so the test for a small integer is skipped:</p>

<pre><code># skipped test for small operand since it always small
    sub rdi, 175     ; Subtract 16 * 10 + 15
    cmp rdi, 1424    ; Compare with (16*99+15)-(16*10+15)
    ja label_43
</code></pre>

<p>The native code for the <code>+</code> operator looks like this:</p>

<pre><code># i_plus_ssjd
# add without overflow check
    mov rax, qword ptr [rbx]
    add rax, 96      ; 16 * 6 + 0
    mov qword ptr [rbx], rax
</code></pre>
      <h3 id="new-beam-instructions-in-otp-26">
        
        
          New BEAM instructions in OTP 26 <a href="#new-beam-instructions-in-otp-26">#</a>
        
        
      </h3>
    

<p>The previous example of combining guard tests showed that the JIT can
often generate better code if multiple BEAM instructions are combined
into one. While the <a href="https://www.erlang.org/blog/beam-compiler-history/#the-ever-changing-beam-instructions">BEAM loader</a> is capable of combining
instructions it is often more practical to let the Erlang compiler
emit combined instructions.</p>

<p>OTP 26 introduces two new instructions, each of which replaces a sequence of
any number of simpler instructions:</p>

<ul>
  <li>
    <p><code>update_record</code> for updating any number of fields in a record.</p>
  </li>
  <li>
    <p><code>bs_match</code> for matching multiple segments of fixed size.</p>
  </li>
</ul>

<p>In OTP 25, the <code>bs_create_bin</code> instruction for constructing a binary
with any number of segments was introduced, but its full potential for
generating efficient code was not leveraged in OTP 25.</p>
      <h3 id="updating-records-in-otp-25">
        
        
          Updating records in OTP 25 <a href="#updating-records-in-otp-25">#</a>
        
        
      </h3>
    

<p>Consider the following example of a record definition and three functions
that update the record:</p>

<pre><code>-record(r, {a,b,c,d,e}).

update_a(R) -&gt;
    R#r{a=42}.

update_ce(R) -&gt;
    R#r{c=99,e=777}.

update_bcde(R) -&gt;
    R#r{b=2,c=3,d=4,e=5}.
</code></pre>

<p>In OTP 25 and earlier, the way in which a record is updated depends on
both the number of fields being updated and the size of the record.</p>

<p>When a single field in a record is updated, as in <code>update_a/1</code>, the
<a href="https://www.erlang.org/doc/man/erlang.html#setelement-3">setelement/3</a>
BIF is called:</p>

<pre><code>    {test,is_tagged_tuple,{f,34},[{x,0},6,{atom,r}]}.
    {move,{x,0},{x,1}}.
    {move,{integer,42},{x,2}}.
    {move,{integer,2},{x,0}}.
    {call_ext_only,3,{extfunc,erlang,setelement,3}}.
</code></pre>

<p>When updating more than one field but fewer than approximately half of
the fields, as in <code>update_ce/1</code>, code similar to the following is
emitted:</p>

<pre><code>    {test,is_tagged_tuple,{f,37},[{x,0},6,{atom,r}]}.
    {allocate,0,1}.
    {move,{x,0},{x,1}}.
    {move,{integer,777},{x,2}}.
    {move,{integer,6},{x,0}}.
    {call_ext,3,{extfunc,erlang,setelement,3}}.
    {set_tuple_element,{integer,99},{x,0},3}.
    {deallocate,0}.
    return.
</code></pre>

<p>Here the <code>e</code> field is updated using <code>setelement/3</code>, followed by
<code>set_tuple_element</code> to update the <code>c</code> field destructively. Erlang does
not allow mutation of terms, but here it is done “under the hood” in a
safe way.</p>

<p>When a majority of the fields are updated, as in <code>update_bcde/1</code>, a
new tuple is built:</p>

<pre><code>    {test,is_tagged_tuple,{f,40},[{x,0},6,{atom,r}]}.
    {test_heap,7,1}.
    {get_tuple_element,{x,0},1,{x,0}}.
    {put_tuple2,{x,0},
                {list,[{atom,r},
                       {x,0},
                       {integer,2},
                       {integer,3},
                       {integer,4},
                       {integer,5}]}}.
    return.
</code></pre>
      <h3 id="updating-records-in-otp-26">
        
        
          Updating records in OTP 26 <a href="#updating-records-in-otp-26">#</a>
        
        
      </h3>
    

<p>In OTP 26, all records are updated using the new BEAM instruction
<code>update_record</code>.  For example, here is the main part of the BEAM code
for <code>update_1</code>:</p>

<pre><code>    {test,is_tagged_tuple,{f,34},[{x,0},6,{atom,r}]}.
    {test_heap,7,1}.
    {update_record,{atom,reuse},6,{x,0},{x,0},{list,[2,{integer,42}]}}.
    return.
</code></pre>

<p>The last operand is a list of positions in the tuple and their corresponding
new values.</p>

<p>The first operand, <code>{atom,reuse}</code>, is a hint to the JIT that it is possible
that the source tuple is already up to date and does not need to be updated.
Another possible value for the hint operand is <code>{atom,copy}</code>, meaning that
the source tuple is definitely not up to date.</p>

<p>The JIT emits the following native code for the <code>update_record</code> instruction:</p>

<pre><code># update_record_aIsdI
    mov rax, qword ptr [rbx]
    mov rdi, rax
    cmp qword ptr [rdi+14], 687
    je L130
    vmovups xmm0, [rax-2]
    vmovups [r15], xmm0
    mov qword ptr [r15+16], 687
    vmovups ymm0, [rax+22]
    vmovups [r15+24], ymm0
    lea rax, qword ptr [r15+2]
    add r15, 56
L130:
    mov qword ptr [rbx], rax
</code></pre>

<p>Let’s walk through those instructions. First the value of <code>{x,0}</code> is fetched:</p>

<pre><code>    mov rax, qword ptr [rbx]
</code></pre>

<p>Since the hint operand is the atom <code>reuse</code>, is is possible that it is
unnecessary to copy the tuple. Therefore, the JIT emits an instruction
sequence to test whether the <code>a</code> field (position 2 in the tuple)
already contains the value 42. If so, the source tuple can be reused:</p>

<pre><code>    mov rdi, rax
    cmp qword ptr [rdi+14], 687   ; 42
    je L130                       ; Reuse source tuple
</code></pre>

<p>Next follows the copy and update sequence. First the header word for
the tuple and its first element (the <code>r</code> atom) are copied using
<a href="https://en.wikipedia.org/wiki/Advanced_Vector_Extensions">AVX instructions</a>:</p>

<pre><code>    vmovups xmm0, [rax-2]
    vmovups [r15], xmm0
</code></pre>

<p>Next the value 42 is stored into position 2 of the copy of the tuple:</p>

<pre><code>    mov qword ptr [r15+16], 687   ; 42
</code></pre>

<p>Finally the remaining four elements of the tuple are copied:</p>

<pre><code>    vmovups ymm0, [rax+22]
    vmovups [r15+24], ymm0
</code></pre>

<p>All that remains is to create a tagged pointer to the newly created
tuple and increment the heap pointer:</p>

<pre><code>    lea rax, qword ptr [r15+2]
    add r15, 56
</code></pre>

<p>The last instruction stores the tagged pointer to either the original
or the updated tuple to <code>{x,0}</code>:</p>

<pre><code>L130:
    mov qword ptr [rbx], rax
</code></pre>

<p>The BEAM code for <code>update_ce/1</code> is very similar to the code for <code>update_a/1</code>:</p>

<pre><code>    {test,is_tagged_tuple,{f,37},[{x,0},6,{atom,r}]}.
    {test_heap,7,1}.
    {update_record,{atom,reuse},
                   6,
                   {x,0},
                   {x,0},
                   {list,[4,{integer,99},6,{integer,777}]}}.
    return.
</code></pre>

<p>The native code looks like this:</p>

<pre><code># update_record_aIsdI
    mov rax, qword ptr [rbx]
    vmovups ymm0, [rax-2]
    vmovups [r15], ymm0
    mov qword ptr [r15+32], 1599   ; 99
    mov rdi, [rax+38]
    mov [r15+40], rdi
    mov qword ptr [r15+48], 12447  ; 777
    lea rax, qword ptr [r15+2]
    add r15, 56
    mov qword ptr [rbx], rax
</code></pre>

<p>Note that the copying and updating is done unconditionally, despite
the <code>reuse</code> hint. The JIT is free to ignore the hints. When multiple
fields are being updated, the test for whether the update is
unnecessary would be more expensive and it is also much less likely
that all of the fields would turn out to be unchanged. Therefore,
trying to reuse the original tuple is more likely to be a
<a href="https://en.wiktionary.org/wiki/pessimization">pessimization</a> rather
than an optimization.</p>
      <h3 id="matching-and-constructing-binaries-in-otp-25">
        
        
          Matching and constructing binaries in OTP 25 <a href="#matching-and-constructing-binaries-in-otp-25">#</a>
        
        
      </h3>
    

<p>To explore the optimizations of binaries, the following example will
be used:</p>

<pre><code>bin_swap(&lt;&lt;A:8,B:24&gt;&gt;) -&gt;
    &lt;&lt;B:24,A:8&gt;&gt;.
</code></pre>

<p>Somewhat simplified, the main part of the BEAM code as emitted by
the compiler in OTP 25 looks like this:</p>

<pre><code>    {test,bs_start_match3,{f,1},1,[{x,0}],{x,1}}.
    {bs_get_position,{x,1},{x,0},2}.
    {test,bs_get_integer2,
          {f,2},
          2,
          [{x,1},
           {integer,8},
           1,
           {field_flags,[unsigned,big]}],
          {x,2}}.
    {test,bs_get_integer2,
          {f,2},
          3,
          [{x,1},
           {integer,24},
           1,
           {field_flags,[unsigned,big]}],
          {x,3}}.
    {test,bs_test_tail2,{f,2},[{x,1},0]}.
    {bs_create_bin,{f,0},
                   0,4,1,
                   {x,0},
                   {list,[{atom,integer},
                          1,1,nil,
                          {tr,{x,3},{t_integer,{0,16777215}}},
                          {integer,24},
                          {atom,integer},
                          2,1,nil,
                          {tr,{x,2},{t_integer,{0,255}}},
                          {integer,8}]}}.
    return.
</code></pre>

<p>Let’s walk through the code. The first instruction sets up a <a href="https://www.erlang.org/doc/efficiency_guide/binaryhandling.html#how-binaries-are-implemented">match
context</a>:</p>

<pre><code>    {test,bs_start_match3,{f,1},1,[{x,0}],{x,1}}.
</code></pre>

<p>A match context holds several pieces of information needed for
matching a binary.</p>

<p>The next instruction saves information that will be needed if matching
of the binary fails for some reason:</p>

<pre><code>    {bs_get_position,{x,1},{x,0},2}.
</code></pre>

<p>The next two instructions match out two segments as integers (comments added by me):</p>

<pre><code>    {test,bs_get_integer2,
          {f,2},          % Failure label
          2,              % Number of live X registers (needed for GC)
          [{x,1},         % Match context register
           {integer,8},   % Size of segment in units
           1,             % Unit value
           {field_flags,[unsigned,big]}],
          {x,2}}.         % Destination register
    {test,bs_get_integer2,
          {f,2},
          3,
          [{x,1},
           {integer,24},
           1,
           {field_flags,unsigned,big]}],
          {x,3}}.
</code></pre>

<p>The next instruction makes sure that the end of the binary has now been
reached:</p>

<pre><code>    {test,bs_test_tail2,{f,2},[{x,1},0]}.
</code></pre>

<p>The next instruction creates the binary with the segments swapped:</p>

<pre><code>    {bs_create_bin,{f,0},
                   0,4,1,
                   {x,0},
                   {list,[{atom,integer},
                          1,1,nil,
                          {tr,{x,3},{t_integer,{0,16777215}}},
                          {integer,24},
                          {atom,integer},
                          2,1,nil,
                          {tr,{x,2},{t_integer,{0,255}}},
                          {integer,8}]}}.
</code></pre>

<p>Before OTP 25, creation of binaries was done using multiple
instructions, similar to how binary matching is still done in
OTP 25. The reason for creating the <code>bs_create_bin</code> instruction in OTP 25
was to be able to provide improved error information when construction
of a binary fails, similar to the <a href="https://www.erlang.org/blog/my-otp-24-highlights/#eep-54-improved-bif-error-information">improved BIF error
information</a>.</p>

<p>When the size of a segment of size 8, 16, 32, or 64 is matched,
specialized instructions are used for x86_64. The specialized
instructions do everything inline provided that the segment is
byte-aligned. (The JIT in OTP 25 for AArch64/ARM64 does not have these
specialized instructions.) Here is the instruction for matching a
segment of size 8:</p>

<pre><code># i_bs_get_integer_8_Stfd
    mov rcx, qword ptr [rbx+8]
    mov rsi, qword ptr [rcx+22]
    lea rdx, qword ptr [rsi+8]
    cmp rdx, qword ptr [rcx+30]
    ja label_25
    rex test sil, 7
    short je L91
    mov edx, 64
    call L92
    short jmp L90
L91:
    mov rdi, qword ptr [rcx+14]
    shr rsi, 3
    mov qword ptr [rcx+22], rdx
    movzx rax, byte ptr [rdi+rsi]
    shl rax, 4
    or rax, 15
L90:
    mov qword ptr [rbx+16], rax
</code></pre>

<p>The first two instructions pick up the pointer to the match context
and from the match context the current bit offset into the binary:</p>

<pre><code>    mov rcx, qword ptr [rbx+8]   ; Load pointer to match context
    mov rsi, qword ptr [rcx+22]  ; Get offset in bits into binary
</code></pre>

<p>The next three instructions ensure that the length of the binary is at
least 8 bits:</p>

<pre><code>    lea rdx, qword ptr [rsi+8]   ; Add 8 to the offset
    cmp rdx, qword ptr [rcx+30]  ; Compare offset+8 with size of binary
    ja label_25                  ; Fail if the binary is too short
</code></pre>

<p>The next five instructions test whether the current byte in the binary
is aligned at a byte boundary. If not, a helper code fragment is
called:</p>

<pre><code>    rex test sil, 7    ; Test the 3 least significant bits
    short je L91       ; Jump if 0 (meaning byte-aligned)
    mov edx, 64        ; Load size and flags
    call L92           ; Call helper fragment
    short jmp L90      ; Done
</code></pre>

<p>A <strong>helper code fragment</strong> is a shared block of code that can be
called from the native code generated for BEAM instructions, typically
to handle cases that are uncommon and/or would require more native
instructions than are practial to include inline. Each such code
fragment has its own calling convention, typically tailor-made to be
as convenient for the caller as possible. (See <a href="https://www.erlang.org/blog/jit-part-2/">Further adventures in
the JIT</a> for more information
about helper code fragments.)</p>

<p>The remaining instructions read one byte from memory, convert it to a
tagged Erlang terms, store it in <code>{x,2}</code>, and advance the bit offset
in the match context:</p>

<pre><code>L91:
    mov rdi, qword ptr [rcx+14]    ; Load base pointer for binary
    shr rsi, 3                     ; Convert bit offset to byte offset
    mov qword ptr [rcx+22], rdx    ; Update bit offset in match context
    movzx rax, byte ptr [rdi+rsi]  ; Read one byte from the binary
    shl rax, 4                     ; Multiply by 16...
    or rax, 15                     ; ... and add tag for a small integer

L90:
    mov qword ptr [rbx+16], rax    ; Store extracted integer
</code></pre>

<p>When matching a segment of size other than one of the special sizes
mentioned earlier, the JIT will always emit a call to a general
routine that can handle matching of any integer segment with any
aligment, endianness, and signedness.</p>

<p>In OTP 25, the full potential for optimization of the <code>bs_create_bin</code>
instruction is not realized. The construction of each segment is done
by calling a helper routine that builds the segment. Here is the
native for the part of the <code>bs_create_bin</code> instruction that builds the
integer segments:</p>

<pre><code># construct integer segment
    mov edx, 24
    mov rsi, qword ptr [rbx+24]
    xor ecx, ecx
    lea rdi, qword ptr [rbx-80]
    call 4387496416
# construct integer segment
    mov edx, 8
    mov rsi, qword ptr [rbx+16]
    xor ecx, ecx
    lea rdi, qword ptr [rbx-80]
    call 4387496416
</code></pre>
      <h3 id="binary-pattern-matching-in-otp-26">
        
        
          Binary pattern matching in OTP 26 <a href="#binary-pattern-matching-in-otp-26">#</a>
        
        
      </h3>
    

<p>In OTP 26, there is a new BEAM <code>bs_match</code> instruction used for
matching segments with sizes known at compile time. The BEAM code for
the matching code in the function head for <code>bin_swap/1</code> is as follows:</p>

<pre><code>    {test,bs_start_match3,{f,1},1,[{x,0}],{x,1}}.
    {bs_get_position,{x,1},{x,0},2}.
    {bs_match,{f,2},
              {x,1},
              {commands,[{ensure_exactly,32},
                         {integer,2,{literal,[]},8,1,{x,2}},
                         {integer,3,{literal,[]},24,1,{x,3}}]}}.
</code></pre>

<p>The first two instructions are identical to their OTP 25 counterparts.</p>

<p>The first operand of the <code>bs_match</code> instruction, <code>{f,2}</code>, is the
failure label and the second operand <code>{x,2}</code> is the register holding
the match context. The third operand, <code>{commands,[...]}</code>, is a list of
matching commands.</p>

<p>The first command in the <code>commands</code> list, <code>{ensure_exactly,32}</code>, tests
that the remaining number of bits in the binary being matched is
exactly 32. If not, a jump is made to the failure label.</p>

<p>The second command extracts an integer of 8 bits and stores it in
<code>{x,2}</code>. The third command extracts an integer of 24 bits and store it
in <code>{x,3}</code>.</p>

<p>Having matching of multiple segments contained in a single BEAM
instruction makes it much easier for the JIT to generate efficient
code. Here is what the native code will do:</p>

<ul>
  <li>
    <p>Test that there are at exactly 32 bits left in the binary.</p>
  </li>
  <li>
    <p>If the segment is byte-aligned, read a 4-byte word from the binary
and store it in a CPU register.</p>
  </li>
  <li>
    <p>If the segment is not byte-aligned, read an 8-byte word from the binary
and shift to extract the 32 bits needed.</p>
  </li>
  <li>
    <p>Shift and mask out 8 bits and tag as an integer. Store into <code>{x,2}</code>.</p>
  </li>
  <li>
    <p>Shift and mask out 24 bits and tag as an integer. Store into <code>{x,3}</code>.</p>
  </li>
</ul>

<p>The native code for the <code>bs_match</code> instruction (slightly simplifed) is
as follows:</p>

<pre><code># i_bs_match_fS
# ensure_exactly 32
    mov rsi, qword ptr [rbx+8]
    mov rax, qword ptr [rsi+30]
    mov rcx, qword ptr [rsi+22]
    sub rax, rcx
    cmp rax, 32
    jne label_3
# read 32
    mov rdi, qword ptr [rsi+14]
    add qword ptr [rsi+22], 32
    mov rax, rcx
    shr rax, 3
    add rdi, rax
    and ecx, 7
    jnz L38
    movbe edx, dword ptr [rdi]
    add ecx, 32
    short jmp L40
L38:
    mov rdx, qword ptr [rdi-3]
    shr rdx, 24
    bswap rdx
L40:
    shl rdx, cl
# extract integer 8
    mov rax, rdx
# store extracted integer as a small
    shr rax, 52
    or rax, 15
    mov qword ptr [rbx+16], rax
    shl rdx, 8
# extract integer 24
    shr rdx, 36
    or rdx, 15
    mov qword ptr [rbx+24], rdx
</code></pre>

<p>The first part of the code ensures that there are exactly 32 bits
remaining in the binary:</p>

<pre><code># ensure_exactly 32
    mov rsi, qword ptr [rbx+8]    ; Get pointer to match context
    mov rax, qword ptr [rsi+30]   ; Get size of binary in bits
    mov rcx, qword ptr [rsi+22]   ; Get offset in bits into binary
    sub rax, rcx
    cmp rax, 32
    jne label_3
</code></pre>

<p>The next part of the code does not directly correspond to the commands
in the <code>bs_match</code> BEAM instruction. Instead, the code reads 32 bits
from the binary:</p>

<pre><code># read 32
    mov rdi, qword ptr [rsi+14]
    add qword ptr [rsi+22], 32  ; Increment bit offset in match context
    mov rax, rcx
    shr rax, 3
    add rdi, rax
    and ecx, 7                  ; Test alignment
    jnz L38                     ; Jump if segment not byte-aligned

    ; Read 32 bits (4 bytes) byte-aligned and convert to big-endian
    movbe edx, dword ptr [rdi]
    add ecx, 32
    short jmp L40

L38:
    ; Read a 8-byte word and extract the 32 bits that are needed.
    mov rdx, qword ptr [rdi-3]
    shr rdx, 24
    bswap rdx                   ; Convert to big-endian

L40:
    ; Shift the read bytes to the most significant bytes of the word
    shl rdx, cl
</code></pre>

<p>The 4 bytes read will be converted to big-endian and placed as the
most significant bytes of CPU register <code>rdx</code> with the rest of the
register zeroed.</p>

<p>The following instructions extracts the 8 bits for the first segment and
stores it as a tagged integer in <code>{x,2}</code>:</p>

<pre><code># extract integer 8
    mov rax, rdx
# store extracted integer as a small
    shr rax, 52
    or rax, 15
    mov qword ptr [rbx+16], rax
    shl rdx, 8
</code></pre>

<p>The following instructions extracts the 24 bits for the second segment and
stores it as a tagged integer in <code>{x,3}</code>:</p>

<pre><code># extract integer 24
    shr rdx, 36
    or rdx, 15
    mov qword ptr [rbx+24], rdx
</code></pre>
      <h3 id="binary-construction-in-otp-26">
        
        
          Binary construction in OTP 26 <a href="#binary-construction-in-otp-26">#</a>
        
        
      </h3>
    

<p>For binary construction in OTP 26, the compiler emits a
<code>bs_create_bin</code> BEAM instruction just as in OTP 25. However, the
native code that the JIT in OTP 26 emits for that instruction bears
little resemblance to the native code emitted by OTP 25. The native
code will do the following:</p>

<ul>
  <li>
    <p>Allocate room on the heap for a binary and initialize it with
inlined native code. A helper code fragment is called to do a garbage
collection if there is not sufficient room left on the heap.</p>
  </li>
  <li>
    <p>Read the integer from <code>{x,3}</code> and untag it.</p>
  </li>
  <li>
    <p>Read the integer from <code>{x,2}</code> and untag it. Combine the value with
the previous 24-bit value to obtain a 32-bit value.</p>
  </li>
  <li>
    <p>Write the combined 32 bits into the binary.</p>
  </li>
</ul>

<p>Here follows the complete native code for the <code>bs_create_bin</code>
instruction (somewhat simplified):</p>

<pre><code># i_bs_create_bin_jItd
# allocate heap binary
    lea rdx, qword ptr [r15+56]
    cmp rdx, rsp
    short jbe L43
    mov ecx, 4
.db 0x90
    call 4343630296
L43:
    lea rax, qword ptr [r15+2]
    mov qword ptr [rbx-120], rax
    mov qword ptr [r15], 164
    mov qword ptr [r15+8], 4
    add r15, 16
    mov qword ptr [rbx-64], r15
    mov qword ptr [rbx-56], 0
    add r15, 8
# accumulate value for integer segment
    xor r8d, r8d
    mov rdi, qword ptr [rbx+24]
    sar rdi, 4
    or r8, rdi
# accumulate value for integer segment
    shl r8, 8
    mov rdi, qword ptr [rbx+16]
    sar rdi, 4
    or r8, rdi
# construct integer segment from accumulator
    bswap r8d
    mov rdi, qword ptr [rbx-64]
    mov qword ptr [rbx-56], 32
    mov dword ptr [rdi], r8d
</code></pre>

<p>Let’s walk through it.</p>

<p>The first part of the code, starting with <code># allocate heap binary</code> and
ending before the next comment line allocates a <strong>heap binary</strong> with
inlined native code. The only call to a helper code fragment is in case
there is not sufficient space left on the heap.</p>

<p>Next follows the construction of the segments of the binary.</p>

<p>Instead of writing the value of each segment to memory one at a time,
multiple segments are accumulated into a CPU register. Here
follows the code for the first segment to be constructed (24 bits):</p>

<pre><code># accumulate value for integer segment
    xor r8d, r8d                ; Initialize accumulator
    mov rdi, qword ptr [rbx+24] ; Fetch {x,3}
    sar rdi, 4                  ; Untag
    or r8, rdi                  ; OR into accumulator
</code></pre>

<p>Here follows the code for the second segment (8 bits):</p>

<pre><code># accumulate value for integer segment
    shl r8, 8                   ; Make room for 8 bits
    mov rdi, qword ptr [rbx+16] ; Fetch {x,2}
    sar rdi, 4                  ; Untag
    or r8, rdi                  ; OR into accumulator
</code></pre>

<p>Since there are no segments of the binary left, the accumulated
value will be written out to memory:</p>

<pre><code># construct integer segment from accumulator
    bswap r8d                   ; Make accumulator big-endian
    mov rdi, qword ptr [rbx-64] ; Get pointer into binary
    mov qword ptr [rbx-56], 32  ; Update size of binary
    mov dword ptr [rdi], r8d    ; Write 32 bits
</code></pre>
      <h3 id="appending-to-binaries-in-otp-25">
        
        
          Appending to binaries in OTP 25 <a href="#appending-to-binaries-in-otp-25">#</a>
        
        
      </h3>
    

<p>The ancient OTP R12B release introduced an optimization for
<a href="https://www.erlang.org/doc/efficiency_guide/binaryhandling.html">efficiently appending to a
binary</a>. Let’s
look at an example to see the optimization in action:</p>

<pre><code>-module(append).
-export([expand/1, expand_bc/1]).

expand(Bin) when is_binary(Bin) -&gt;
    expand(Bin, &lt;&lt;&gt;&gt;).

expand(&lt;&lt;B:8,T/binary&gt;&gt;, Acc) -&gt;
    expand(T, &lt;&lt;Acc/binary,B:16&gt;&gt;);
expand(&lt;&lt;&gt;&gt;, Acc) -&gt;
    Acc.

expand_bc(Bin) when is_binary(Bin) -&gt;
    &lt;&lt; &lt;&lt;B:16&gt;&gt; || &lt;&lt;B:8&gt;&gt; &lt;= Bin &gt;&gt;.
</code></pre>

<p>Both <code>append:expand/1</code> and <code>append:expand_bc/1</code> take a binary and
double its size by expanding each byte to two bytes. For example:</p>

<pre><code>1&gt; append:expand(&lt;&lt;1,2,3&gt;&gt;).
&lt;&lt;0,1,0,2,0,3&gt;&gt;
2&gt; append:expand_bc(&lt;&lt;4,5,6&gt;&gt;).
&lt;&lt;0,4,0,5,0,6&gt;&gt;
</code></pre>

<p>Both functions accept only binaries:</p>

<pre><code>3&gt; append:expand(&lt;&lt;1,7:4&gt;&gt;).
** exception error: no function clause matching append:expand(&lt;&lt;1,7:4&gt;&gt;,&lt;&lt;&gt;&gt;)
4&gt; append:expand_bc(&lt;&lt;1,7:4&gt;&gt;).
** exception error: no function clause matching append:expand_bc(&lt;&lt;1,7:4&gt;&gt;)
</code></pre>

<p>Before looking at the BEAM code, let’s do some benchmarking using
<a href="https://github.com/max-au/erlperf">erlperf</a> to find out which function is faster:</p>

<pre><code>erlperf --init_runner_all &#39;rand:bytes(10_000).&#39; \
        &#39;r(Bin) -&gt; append:expand(Bin).&#39; \
        &#39;r(Bin) -&gt; append:expand_bc(Bin).&#39;
Code                                     ||        QPS       Time   Rel
r(Bin) -&gt; append:expand_bc(Bin).          1       7936     126 us  100%
r(Bin) -&gt; append:expand(Bin).             1       4369     229 us   55%
</code></pre>

<p>The expression for the <code>--init_runner_all</code> option uses
<a href="https://www.erlang.org/doc/man/rand.html#bytes-1">rand:bytes/1</a> to create a binary with 10,000 random
bytes, which will be passed to both expand functions.</p>

<p>From the benchmark results, it can be seen that the <code>expand_bc/1</code> function is
almost twice as fast.</p>

<p>To find out why, let’s compare the BEAM code for the two functions. Here is
the instruction that appends to the binary in <code>expand/1</code>:</p>

<pre><code>    {bs_create_bin,{f,0},
                   0,3,8,
                   {x,1},
                   {list,[{atom,append},  % Append operation
                          1,8,nil,
                          {tr,{x,1},{t_bitstring,1}}, % Source/destination
                          {atom,all},
                          {atom,integer},
                          2,1,nil,
                          {tr,{x,2},{t_integer,{0,255}}},
                          {integer,16}]}}.
</code></pre>

<p>The first segment is an <code>append</code> operation. The operand
<code>{tr,{x,1},{t_bitstring,1}}</code> denotes both source and destination of
the operation. That is, the binary referenced by <code>{x,1}</code> will be
mutated. Erlang normally does not allow mutation, but this mutation
is done under the hood in a way not observable from outside. That
makes the append operation much more efficient than it would be if the
source binary had to be copied.</p>

<p>For the binary comprehension in <code>expand_bc/1</code>, there is a similar
BEAM instruction for appending to the binary:</p>

<pre><code>    {bs_create_bin,{f,0},
                   0,3,1,
                   {x,1},
                   {list,[{atom,private_append}, % Private append operation
                          1,1,nil,
                          {x,1},
                          {atom,all},
                          {atom,integer},
                          2,1,nil,
                          {tr,{x,2},{t_integer,{0,255}}},
                          {integer,16}]}}.
</code></pre>

<p>The main difference is that the binary comprehension uses the more
efficient <code>private_append</code> operation instead of <code>append</code>.</p>

<p>The <code>append</code> operation has more overhead because it must produce the
correct result for code such as:</p>

<pre><code>bins(Bin) -&gt;
    bins(Bin, &lt;&lt;&gt;&gt;).

bins(&lt;&lt;H,T/binary&gt;&gt;, Acc) -&gt;
    [Acc|bins(T, &lt;&lt;Acc/binary,H&gt;&gt;)];
bins(&lt;&lt;&gt;&gt;, Acc) -&gt;
    [Acc].
</code></pre>

<p>Running it:</p>

<pre><code>1&gt; example:bins(&lt;&lt;&#34;abcde&#34;&gt;&gt;).
[&lt;&lt;&gt;&gt;,&lt;&lt;&#34;a&#34;&gt;&gt;,&lt;&lt;&#34;ab&#34;&gt;&gt;,&lt;&lt;&#34;abc&#34;&gt;&gt;,&lt;&lt;&#34;abcd&#34;&gt;&gt;,&lt;&lt;&#34;abcde&#34;&gt;&gt;]
</code></pre>

<p>In the <code>expand/1</code> function, only the final value binary being appended
to was needed. In <code>bins/1</code>, all of the intermediate values of binary
are collected in a list. For correctness, the <code>append</code> operations must
ensure that the binary <code>Acc</code> is copied before <code>H</code> is appended to
it. To be able to know when it is necessary to copy the binary, the
<code>append</code> operation does some extra bookeeping that does not come
for free.</p>
      <h3 id="appending-to-binaries-in-otp-26">
        
        
          Appending to binaries in OTP 26 <a href="#appending-to-binaries-in-otp-26">#</a>
        
        
      </h3>
    

<p>In OTP 26, there is a new optimization in the compiler that replaces
an <code>append</code> operation with a <code>private_append</code> operation whenever it is
correct and safe to do so. This optimization was implemented by Frej
Drejhammar. That is, the optimization will rewrite <code>append:expand/2</code>
to use <code>private_append</code>, but not <code>examples:bins/2</code>.</p>

<p>The difference between <code>append:expand/1</code> and <code>append:expand_bc/1</code> is now
much smaller:</p>

<pre><code>erlperf --init_runner_all &#39;rand:bytes(10_000).&#39; \
        &#39;r(Bin) -&gt; append:expand(Bin).&#39; \
        &#39;r(Bin) -&gt; append:expand_bc(Bin).&#39;
Code                                     ||        QPS       Time   Rel
r(Bin) -&gt; append:expand_bc(Bin).          1      13164   75988 ns  100%
r(Bin) -&gt; append:expand(Bin).             1      12419   80550 ns   94%
</code></pre>

<p><code>expand_bc/1</code> is still a bit faster because the compiler emits
somewhat more efficient binary matching code for it than for the
<code>expand/1</code> function.</p>
      <h3 id="the-benefit-of-is_binary1-guards">
        
        
          The benefit of <code>is_binary/1</code> guards <a href="#the-benefit-of-is_binary1-guards">#</a>
        
        
      </h3>
    

<p>The <code>expand/1</code> function has an <code>is_binary/1</code> guard test that may seem
unnecessary:</p>

<pre><code>expand(Bin) when is_binary(Bin) -&gt;
    expand(Bin, &lt;&lt;&gt;&gt;).
</code></pre>

<p>The guard test is not necessary for correctness, because <code>expand/2</code>
will raise a <code>function_clause</code> exception if its argument is not a
binary. However, better code will be generated for <code>expand/2</code> with
the guard test.</p>

<p>With the guard test, the first BEAM instruction in <code>expand/2</code> is:</p>

<pre><code>    {bs_start_match4,{atom,no_fail},2,{x,0},{x,0}}.
</code></pre>

<p>Without the guard test, the first BEAM instruction is:</p>

<pre><code>    {test,bs_start_match3,{f,3},2,[{x,0}],{x,2}}.
</code></pre>

<p>The <code>bs_start_match4</code> instruction is more efficient because it does
not have to test that <code>{x,0}</code> contains a binary.</p>

<p>The benchmark results show measurable increased execution time for
<code>expand/1</code> if the guard test is removed:</p>

<pre><code>erlperf --init_runner_all &#39;rand:bytes(10_000).&#39; \
        &#39;r(Bin) -&gt; append:expand(Bin).&#39; \
        &#39;r(Bin) -&gt; append:expand_bc(Bin).&#39;
Code                                     ||        QPS       Time   Rel
r(Bin) -&gt; append:expand_bc(Bin).          1      13273   75366 ns  100%
r(Bin) -&gt; append:expand(Bin).             1      11875   84236 ns   89%
</code></pre>
      <h3 id="revisiting-the-base64-module">
        
        
          Revisiting the <code>base64</code> module <a href="#revisiting-the-base64-module">#</a>
        
        
      </h3>
    

<p>Traditionally, up to OTP 25, the clause in the <code>base64</code> module that does
most of the work of encoding a binary to Base64 looked like this:</p>

<pre><code>encode_binary(&lt;&lt;B1:8, B2:8, B3:8, Ls/bits&gt;&gt;, A) -&gt;
    BB = (B1 bsl 16) bor (B2 bsl 8) bor B3,
    encode_binary(Ls,
                  &lt;&lt;A/bits,(b64e(BB bsr 18)):8,
                    (b64e((BB bsr 12) band 63)):8,
                    (b64e((BB bsr 6) band 63)):8,
                    (b64e(BB band 63)):8&gt;&gt;).
</code></pre>

<p>The reason is that matching out segments of size 8 has always been
specially optimized and has been much faster than matching out a
segment of size 6. That is no longer true in OTP 26. With the
improvements in binary matching described in this blog post, the
clause can be written in a more natural way:</p>

<pre><code>encode_binary(&lt;&lt;B1:6, B2:6, B3:6, B4:6, Ls/bits&gt;&gt;, A) -&gt;
    encode_binary(Ls,
                  &lt;&lt;A/bits,
                    (b64e(B1)):8,
                    (b64e(B2)):8,
                    (b64e(B3)):8,
                    (b64e(B4)):8&gt;&gt;);
</code></pre>

<p>(This is not the exact code in OTP 26, because of
<a href="https://github.com/erlang/otp/pull/6280">additional</a>
<a href="https://github.com/erlang/otp/pull/6711">features</a> added later.)</p>

<p>The benchmark results for encoding a random binary of 1,000,000 bytes
to Base64 for OTP 25 is:</p>

<pre><code>erlperf --init_runner_all &#39;rand:bytes(1_000_000).&#39; \
        &#39;r(Bin) -&gt; base64:encode(Bin).&#39;
Code                                  ||        QPS       Time
r(Bin) -&gt; base64:encode(Bin).          1         61   16489 us
</code></pre>

<p>The benchmark results for encoding a random binary of 1,000,000 bytes
to Base64 for OTP 26 is:</p>

<pre><code>erlperf --init_runner_all &#39;rand:bytes(1_000_000).&#39; \
        &#39;r(Bin) -&gt; base64:encode(Bin).&#39;
Code                                  ||        QPS       Time
r(Bin) -&gt; base64:encode(Bin).          1        249    4023 us
</code></pre>

<p>That is, encoding is about 4 times faster.</p>
      <h3 id="pull-requests">
        
        
          Pull requests <a href="#pull-requests">#</a>
        
        
      </h3>
    

<p>Here are the main pull requests for the optimizations mentioned in
this blog post:</p>

<ul>
  <li><a href="https://github.com/erlang/otp/pull/5999">compiler: Improve the type analysis</a></li>
  <li><a href="https://github.com/erlang/otp/pull/6025">JIT: Optimise common combinations of relational operators</a></li>
  <li><a href="https://github.com/erlang/otp/pull/6298">JIT: Minor optimizations</a>, which includes
the optimization that avoids fetching an operand that is already in a CPU register.</li>
  <li><a href="https://github.com/erlang/otp/pull/6033">compiler: Optimize record updates</a></li>
  <li><a href="https://github.com/erlang/otp/pull/6259">JIT: Optimize binary matching for fixed-width segments</a></li>
  <li><a href="https://github.com/erlang/otp/pull/6031">JIT: Optimize creation of binaries</a></li>
  <li><a href="https://github.com/erlang/otp/pull/6804">compiler: <code>private_append</code> optimization for binaries</a></li>
</ul>

        
    </div>
</article>

        </div>
    </div>
</div></div>
  </body>
</html>
