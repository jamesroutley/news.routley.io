<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://petals.ml/">Original</a>
    <h1>Run 100B&#43; language models at home, BitTorrent‑style</h1>
    
    <div id="readability-page-1" class="page"><div>
  <div>
    <div>
      <div>
        <p><img src="https://petals.ml/logo.svg" height="125"/>
        </p>
        
      </div>
      <p>
        Run 100B+ language models at home, BitTorrent‑style
      </p>
      <ul>
        <li>
          Run large language models like <a target="_blank" href="https://huggingface.co/bigscience/bloom">BLOOM-176B</a>
          <strong>collaboratively</strong> — you load a small part of the model, then team up with people serving the other parts
          to run inference or fine-tuning.
        </li>
        <li>
          Single-batch inference runs at ≈ 1 sec per step (token) —
          <a href="https://github.com/bigscience-workshop/petals#benchmarks">up to 10x faster</a> than offloading, enough for
          <a target="_blank" href="http://chat.petals.ml">chatbots</a> and other interactive apps.
          Parallel inference reaches hundreds of tokens/sec.
        </li>
        <li>
          Beyond classic language model APIs —
          you can employ any fine-tuning and sampling methods, execute custom paths through the model, or see its hidden states.
          You get the comforts of an API with the flexibility of PyTorch.
        </li>
      </ul>

      

      

      <div>
        <p>
          Join our <a target="_blank" href="https://discord.gg/D9MwApKgWa">Discord</a>
          or subscribe via email</p>
        
        
        
        <p>
          We sent you an email to confirm your address. Click it and you&#39;re in!
        </p>
      </div>

      <p>
        Featured on:
      </p>
      <p><a target="_blank" href="https://techcrunch.com/2022/12/20/petals-is-creating-a-free-distributed-network-for-running-text-generating-ai/">
          <img src="https://petals.ml/techcrunch.png" width="150"/>
        </a>
      </p>

      <p>
        This project is a part of the <a target="_blank" href="https://bigscience.huggingface.co/">BigScience</a> research workshop.
      </p>
      <p><a target="_blank" href="https://bigscience.huggingface.co/"><img src="https://petals.ml/bigscience.png" width="125"/></a>
      </p>
    </div>
  </div>
</div></div>
  </body>
</html>
