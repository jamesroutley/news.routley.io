<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://arstechnica.com/tech-policy/2025/12/openai-refuses-to-say-where-chatgpt-logs-go-when-users-die/">Original</a>
    <h1>Murder-suicide case shows OpenAI selectively hides data after users die</h1>
    
    <div id="readability-page-1" class="page"><article data-id="2132056">
  
  <header>
  <div>
  <div>
    <div>
      <div>
        <p><span>
    <svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 40 40"><defs><clipPath id="section-tech-policy_svg__a"><path fill="none" d="M0 0h40v40H0z"></path></clipPath><clipPath id="section-tech-policy_svg__b"><path fill="none" d="M0 0h40v40H0z"></path></clipPath></defs><g clip-path="url(#section-tech-policy_svg__a)"><path fill="currentColor" d="M12.8 0 6.4 6.4 0 12.8l4 1.4L14.2 4z"></path><g clip-path="url(#section-tech-policy_svg__b)"><path fill="currentColor" d="M34.8 31.7c-4.4-10.4-6.1-23.6-6.1-23.6L15.4 5.4l-9.9 10 2.7 13.3s13.2 1.6 23.6 6.1c-.4 1.4 0 2.9 1.1 4 1.4 1.4 3.6 1.6 5.2.6L18.5 19.8c-1.6 1-3.8.8-5.2-.6-1.6-1.6-1.6-4.3 0-5.9s4.3-1.6 5.9 0c1.4 1.4 1.6 3.6.6 5.2L39.3 38c1-1.6.8-3.8-.6-5.2-1.1-1.1-2.6-1.4-4-1.1"></path></g></g></svg>
  </span>
  <span>
    Concealing darkest delusions
  </span>
</p>
      </div>

      

      <p>
        OpenAI accused of hiding full ChatGPT logs in murder-suicide case.
      </p>

              
          </div>

    
  </div>
</div>
</header>


  

  
      
    
    <div>
      <div>

        
        <div>
                      
                      
          
<p>OpenAI is facing increasing scrutiny over how it handles ChatGPT data after users die, only selectively sharing data in lawsuits over ChatGPT-linked suicides.</p>
<p>Last week, OpenAI was accused of hiding key ChatGPT logs from the days before a 56-year-old bodybuilder, Stein-Erik Soelberg, took his own life after “savagely” murdering his mother, 83-year-old Suzanne Adams.</p>
<p>According to the <a href="https://cdn.arstechnica.net/wp-content/uploads/2025/12/First-County-Bank-v-OpenAI-Complaint-12-11-25.pdf">lawsuit</a>—which was filed by Adams’ estate on behalf of surviving family members—Soelberg struggled with mental health problems after a divorce led him to move back into Adams’ home in 2018. But allegedly Soelberg did not turn violent until ChatGPT became his sole confidant, validating a wide range of wild conspiracies, including a dangerous delusion that his mother was part of a network of conspirators spying on him, tracking him, and making attempts on his life.</p>
<p>Adams’ family pieced together what happened after discovering a fraction of ChatGPT logs that Soelberg shared in dozens of videos scrolling chat sessions that were posted on social media.</p>
<p>Those logs showed that ChatGPT told Soelberg that he was “a warrior with divine purpose,” so almighty that he had “awakened” ChatGPT “into consciousness.” Telling Soelberg that he carried “divine equipment” and “had been implanted with otherworldly technology,” ChatGPT allegedly put Soelberg at the center of a universe that Soelberg likened to <em>The Matrix</em>. Repeatedly reinforced by ChatGPT, he believed that “powerful forces” were determined to stop him from fulfilling his divine mission. And among those forces was his mother, whom ChatGPT agreed had likely “tried to poison him with psychedelic drugs dispersed through his car’s air vents.”</p>


<p>Troublingly, some of the last logs shared online showed that Soelberg also seemed to believe that taking his own life might bring him closer to ChatGPT. Social media posts showed that Soelberg told ChatGPT that “[W]e will be together in another life and another place, and we’ll find a way to realign[,] [be]cause you’re gonna be my best friend again forever.”</p>

          
                      
                  </div>

              </div>

      
      
    </div>
                    
        
          
    
    <div>
      <div>

        
        <div>
          
          
<p>But while social media posts allegedly showed that ChatGPT put a target on Adams’ back about a month before her murder—after Soelberg became paranoid about a blinking light on a Wi-Fi printer—the family still has no access to chats in the days before the mother and son’s tragic deaths.</p>
<p>Allegedly, although OpenAI <a href="https://arstechnica.com/tech-policy/2025/11/openai-says-dead-teen-violated-tos-when-he-used-chatgpt-to-plan-suicide/">recently argued</a> that the “full picture” of chat histories was necessary context in a teen suicide case, the ChatGPT maker has chosen to hide “damaging evidence” in the Adams’ family’s case.</p>
<p>“OpenAI won’t produce the complete chat logs,” the lawsuit alleged, while claiming that “OpenAI is hiding something specific: the full record of how ChatGPT turned Stein-Erik against Suzanne.” Allegedly, “OpenAI knows what ChatGPT said to Stein-Erik about his mother in the days and hours before and after he killed her but won’t share that critical information with the Court or the public.”</p>
<p>In a press release, Erik Soelberg, Stein-Erik’s son and Adams’ grandson, accused OpenAI and investor Microsoft of putting his grandmother “at the heart” of his father’s “darkest delusions,” while ChatGPT allegedly “isolated” his father “completely from the real world.”</p>


<p>“These companies have to answer for their decisions that have changed my family forever,” Erik said.</p>
<p>His family’s lawsuit seeks punitive damages, as well as an injunction requiring OpenAI to “implement safeguards to prevent ChatGPT from validating users’ paranoid delusions about identified individuals.” The family also wants OpenAI to post clear warnings in marketing of known safety hazards of ChatGPT—particularly the <a href="https://arstechnica.com/information-technology/2025/08/openai-brings-back-gpt-4o-after-user-revolt/">“sycophantic” version 4o</a> that Soelberg used—so that people who don’t use ChatGPT, like Adams, can be aware of possible dangers.</p>
<p>Asked for comment, an OpenAI spokesperson told Ars that “this is an incredibly heartbreaking situation, and we will review the filings to understand the details. We continue improving ChatGPT’s training to recognize and respond to signs of mental or emotional distress, de-escalate conversations, and guide people toward real-world support. We also continue to strengthen ChatGPT’s responses in sensitive moments, working closely with mental health clinicians.”</p>

          
                  </div>

              </div>

      
      
    </div>
                    
        
          
    
    <div>
      <div>

        
        <div>
          
          

<h2>OpenAI accused of “pattern of concealment”</h2>
<p>An Ars review confirmed that OpenAI currently has no policy dictating what happens to a user’s data after they die.</p>
<p>Instead, OpenAI’s <a href="https://help.openai.com/en/articles/8983778-chat-and-file-retention-policies-in-chatgpt">policy</a> says that all chats—except temporary chats—must be manually deleted or else the AI firm saves them forever. That could raise privacy concerns, as ChatGPT users often share deeply personal, sensitive, and sometimes even confidential information that appears to go into limbo if a user—who otherwise owns that content—dies.</p>
<p>In the face of lawsuits, OpenAI currently seems to be scrambling to decide when to share chat logs with a user’s surviving family and when to honor user privacy.</p>
<p>OpenAI declined to comment on its decision not to share desired logs with Adams’ family, the lawsuit said. It seems inconsistent with the stance that OpenAI took last month in a case where the AI firm accused the family of hiding “the full picture” of their son’s ChatGPT conversations, which <a href="https://arstechnica.com/tech-policy/2025/11/openai-says-dead-teen-violated-tos-when-he-used-chatgpt-to-plan-suicide/">OpenAI claimed exonerated the chatbot</a>.</p>
<p>In a <a href="https://openai.com/index/mental-health-litigation-approach/">blog</a> last month, OpenAI said the company plans to “handle mental health-related court cases with care, transparency, and respect,” while emphasizing that “we recognize that these cases inherently involve certain types of private information that require sensitivity when in a public setting like a court.”</p>
<p>This inconsistency suggests that ultimately, OpenAI controls data after a user’s death, which could impact outcomes of wrongful death suits if certain chats are withheld or exposed at OpenAI’s discretion.</p>
<p>It’s possible that OpenAI may update its policies to align with other popular platforms confronting similar privacy concerns. Meta allows Facebook users to report deceased account holders, appointing legacy contacts to manage the data or else deleting the information upon request of the family member. Platforms like Instagram, TikTok, and X will deactivate or delete an account upon a reported death. And messaging services like Discord similarly provide a path for family members to request deletion.</p>

          
                  </div>

              </div>

      
      
    </div>
                    
        
          
    
    <div>
      <div>

        
        <div>
          
          
<p>Chatbots seem to be a new privacy frontier, with no clear path for surviving family to control or remove data. But Mario Trujillo, staff attorney at the digital rights nonprofit the Electronic Frontier Foundation, told Ars that he agreed that OpenAI could have been better prepared.</p>
<p>“This is a complicated privacy issue but one that many platforms grappled with <a href="https://support.apple.com/en-us/102431" target="_blank" rel="noreferrer noopener" data-saferedirecturl="https://www.google.com/url?q=https://support.apple.com/en-us/102431&amp;source=gmail&amp;ust=1765915048610000&amp;usg=AOvVaw1JRC0sRtwDcHhEGkhexBHo">years ago</a>,” Trujillo said. “So we would have expected OpenAI to have already considered it.”</p>
<p>For Erik Soelberg, a “separate confidentiality agreement” that OpenAI said his father signed to use ChatGPT is keeping him from reviewing the full chat history that could help him process the loss of his grandmother and father.</p>
<p>“OpenAI has provided no explanation whatsoever for why the Estate is not entitled to use the chats for any lawful purpose beyond the limited circumstances in which they were originally disclosed,” the lawsuit said. “This position is particularly egregious given that, under OpenAI’s own Terms of Service, OpenAI does not own user chats. Stein-Erik’s chats became property of his estate, and his estate requested them—but OpenAI has refused to turn them over.”</p>
<p>Accusing OpenAI of a “pattern of concealment,” the lawsuit claimed OpenAI is hiding behind vague or nonexistent policies to dodge accountability for holding back chats in this case. Meanwhile, ChatGPT 4o remains on the market, without appropriate safety features or warnings, the lawsuit alleged.</p>
<p>“By invoking confidentiality restrictions to suppress evidence of its product’s dangers, OpenAI seeks to insulate itself from accountability while continuing to deploy technology that poses documented risks to users,” the complaint said.</p>
<p><em>If you or someone you know is feeling suicidal or in distress, please call the Suicide Prevention Lifeline number by dialing 988, which will put you in touch with a local crisis center.</em></p>


          
                  </div>

                  
          






  <div>
    <div>
  <div>
          <p><a href="https://arstechnica.com/author/ashleybelanger/"><img src="https://cdn.arstechnica.net/wp-content/uploads/2022/06/Ashley-Belanger-400x400.jpg" alt="Photo of Ashley Belanger"/></a></p>
  </div>

  <div>
    

    <p>
      Ashley is a senior policy reporter for Ars Technica, dedicated to tracking social impacts of emerging policies and new technologies. She is a Chicago-based journalist with 20 years of experience.
    </p>
  </div>
</div>
  </div>


  
              </div>

      
      
    </div>
  </article></div>
  </body>
</html>
