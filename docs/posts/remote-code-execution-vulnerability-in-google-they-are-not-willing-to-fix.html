<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://giraffesecurity.dev/posts/google-remote-code-execution/">Original</a>
    <h1>Remote Code Execution Vulnerability in Google They Are Not Willing to Fix</h1>
    
    <div id="readability-page-1" class="page"><div><p><span>April 14, 2023</span></p><p>This is a story about a security vulnerability in Google that allowed me to run
arbitrary code on the computers of 50+ Google employees. Although Google
initially considered my finding a serious security incident, later on, it
changed its mind and stated that my finding is not, in fact, a vulnerability,
but the intended behavior of their software.</p><p>Earlier this year, I was doing security research into dependency confusion.
Dependency confusion is a software misconfiguration due to which a package that
is intended to be pulled from a private package repository is instead downloaded
from a public repository, for example, from npmjs.org in the case of NPM. In
most scenarios, an attacker finds a name of a private package and uploads a
package with the same name to the public repository. The attacker can include
any code in the package and in most languages is able to run arbitrary code
already at install time, making dependency confusion vulnerabilities
particularly dangerous.</p><p>From the exploit complexity perspective, dependency confusion issues are easy to
exploit. All you have to do is upload a package to the public package repository
and wait for the package to be downloaded. This is something anyone can do and
does not require any special skills. The hard part is identifying the private
packages that are susceptible to dependency confusion. Usually, companies keep
their private packages and the projects that utilize these packages private, so
you just cannot look at a company’s GitHub and expect to find all the projects
vulnerable to dependency confusion together with the names of private
dependencies.</p><p>Luckily, the names of internal packages are usually not guarded with top-level
security measures. For example, for code that is deployed to the front-end, the
package names may be included in the code bundle. And while it is not possible
to determine which packages would be downloaded due to dependency confusion
issues, security researchers (and malicious actors) can upload all potential
packages they find – the worst that can happen is that the uploaded package will
not be downloaded.</p><p>Early this year, I started tinkering with the idea of automatically finding
private package names from publicly available source code, hosted on sites like
GitHub. This led me to find a large set of private package names which I used to
discover a string of dependency confusion issues at various large tech
companies.</p><p>My method for automatically discovering these package names was simple. I
scanned GitHub repositories for lists of dependencies in common formats and
looked for dependencies that were part of a dependency list, but there was no
matching package in the public package repository. For example, for Python, I
looked at lists matching the output of <code>pip freeze</code> command and for packages
that were not present in PyPi. The search space was constrained to repositories
that were owned by an organization related to major technology companies, such
as Google or Microsoft, and to repositories that were owned by employees of
these companies. I considered a GitHub user an employee if they had set their
company in GitHub to a large tech company, e.g., they had the <code>@google</code> tag on
their profile.</p><p>One of the matches of my scanner came from a public repository belonging to a
Google employee. My scanner found a reference to a non-existent package (called
package X onwards<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>) in one of the files in the repository. A GitHub search
for the package name revealed three more references to the same package in
GitHub. All the matches came from employees and ex-employees of Google, so this
gave me early confidence that the package was owned by Google.</p><p>The reference to package X was in a requirements.txt file, meaning it was a
Python package. This was good news since Python is a language with unarguably
the worst dependency management system. With Python, it is extremely easy to
misconfigure your installation scripts to be prone to dependency confusion. Just
to show how easy it is to shoot yourself in the foot, here is an example shell
command that installs private package <code>kaboom</code> from private registry
<a href="https://example.com">https://example.com</a> and is vulnerable to dependency confusion:</p><pre tabindex="0"><code>pip install kaboom –extra-index-url https://example.com
</code></pre><p>A reader that works with Python on a daily basis and is up-to-date on security
knows that extra-index-url is a no-go for installing private packages. Despite
having been known for years now, extra-index-url is still used widely because
ordinary users do not consider the security implications when using the
parameter. I will not turn this post into a rant about Python and pip, but if
you are interested in this topic, there is a discussion with 100+ comments on
GitHub regarding extra-index-url: <a href="https://github.com/pypa/pip/issues/8606">https://github.com/pypa/pip/issues/8606</a>.</p><p>After finding package X from the GitHub repository, the next step was to upload
a public package with that name to PyPi, the default Python package repository.
In the installation script of the public package, I included code that would
send an HTTP request with the current hostname and username to a web server I
hosted. That allowed me to detect when the package was installed at Google and
is the go-to method for confirming dependency confusion vulnerabilities.</p><p>After uploading the package, it took about two weeks until I started receiving
downloads at a rate of roughly one download per day. The downloads came from
computers or virtual desktops of Google employees around the world. They spanned
different roles like software engineers and firmware engineers (according to
LinkedIn) and different countries, including the United States, Belgium, and
China. Interestingly, the downloads came solely from hosts that were associated
with specific people and not from automated builds or from Google services. My
hypothesis is that package X is an internal tool that is only used locally and
not part of any Google product deployments.</p><p>Upon receiving the first real download within Google, I reported the
vulnerability to Google’s vulnerability reward program. At first, Google took
action quickly and classified the bug as S0, which is the highest severity in
their vulnerability reward program. They fixed the issue in about two weeks and
awarded a bounty of $500<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>. During these two weeks, the package was installed
to roughly 15 unique hosts.</p><p><img src="https://giraffesecurity.dev/posts/google-remote-code-execution/first-triage.png" alt="Screenshot of an email conversation with Google after I first submitted the bug"/></p><p>For the purpose of adding more credibility to the story, here are the details of
a few hosts to where my version of package X was installed:</p><table><thead><tr><th>IP address</th><th>Hostname</th><th>Username</th></tr></thead><tbody><tr><td>34.78.140.88</td><td>rgouthiere-cloudtop-1.c.googlers.com</td><td>rgouthiere</td></tr><tr><td>34.66.121.195</td><td>jianglai.c.googlers.com</td><td>jianglai</td></tr><tr><td>203.208.61.15</td><td>yanghuang2.sha.corp.google.com</td><td>yanghuang</td></tr><tr><td>34.82.242.240</td><td>bluerust.c.googlers.com</td><td>root</td></tr><tr><td>34.145.213.122</td><td>abcd.c.googlers.com</td><td>pdelong</td></tr><tr><td>104.132.153.85</td><td>martina.lon.corp.google.com</td><td>martinacocco</td></tr></tbody></table><p>A few weeks after the patch, I started once again receiving downloads from
employee devices. I made a new report to Google, saying that the issue has
resurfaced. Surprisingly, this time Google closed my report, stating that it is
not in fact a security vulnerability and that the software is working as
intended. They also said that the vulnerability included social engineering
which is out of scope of the vulnerability reward program. This was confusing
for me since the bug involves zero social engineering. I made several attempts
to highlight the impact of this bug and how it does not involve social
engineering. In the end, their decision was the same — everything is
working as intended.</p><p><img src="https://giraffesecurity.dev/posts/google-remote-code-execution/second-response-1.png" alt="Screenshot of reply from Google after reporting the bug again"/>
<img src="https://giraffesecurity.dev/posts/google-remote-code-execution/second-response-2.png" alt="Screenshot of reply from Google after trying to explain to Google the bug once again"/></p><p>Now, there are several options why Google did not think this is a problem and
decided not to pursue fixing it:</p><ul><li>They did not understand the problem. I think this option is the most likely
one because when I submitted the first report, it was assigned the highest
severity possible and promptly fixed. That happened because the case manager
understood the problem and its impact. It is possible that the case manager
that handled my new report did not simply understand the vulnerability and
risks associated.</li><li>There is no actual risk associated with downloading these packages. Since I
have not worked at Google, I do not know what are their security practices. It
is possible that they run everything in isolated environments where the risk
associated is extremely low. Nevertheless, the affected environments should
still contain some information because they are not just plain OS
installations with no data. There must be something there, like proprietary
source code or proprietary inverted binary trees.</li><li>There actually is “social engineering” involved. It is possible that by social
engineering they meant that users install the package by themselves from PyPi
and somehow mistake it for the internal package. I find that scenario unlikely
because it does not explain the few weeks during which the issue was fixed.</li><li>The bug cannot be exploited by malicious user since I claimed the package.
This is true since only one person can claim a package on PyPi, but it would
definitely be a very odd security practice.</li><li>They simply do not care.</li></ul><p>At the time of writing, it has been a week since our last communication and the
Python package is still being downloaded by Googlers every day. If I wanted to,
I could replace the current version of the package with something malicious, and
it would start running on Google’s employees’ computers/virtual desktops.</p><p>As far as fixing the problem goes, Google has had a very easy way to fix the
specific issue from the start – they could simply have package X removed from
PyPi by staff and have the name blacklisted to prevent the same package from
being claimed again in the future. This is something other companies to whom I
have reported dependency confusion issues have done and guarantees that the same
package cannot be used for dependency confusion in the future. Now, this is
certainly not a robust fix since there may be other private packages that could
be used in place of package X.</p><p>In fact, there were five more references to non-existent private packages in the
same GitHub repository where I found package X. I will not disclose the names of
these packages, but judging by their names, they are likely internal tools and
probably installed in the same way as package X. If anyone is interested in
penetrating Google (be your intent claiming bug bounties or something else), you
can easily find these packages by doing a similar scan as I did. And there are
likely even more packages I did not find since I only scanned a small fraction
of the data.</p><p>Anyway, this was the story of how I hacked into Google. Let’s see if Google
takes another look at my report after I publish this post.</p><p>By the way, I plan to write another piece that dissects in more detail the
methods I used to find these package names from open-source data. In case you
are interested, stay tuned.</p><p>If you have any comments regarding this article, feel free to reach out to us at
<a href="https://giraffesecurity.dev/cdn-cgi/l/email-protection#bcdbd5cedddadad9fcdbd5cedddadad9cfd9dfc9ced5c8c592d8d9ca"><span data-cfemail="aacdc3d8cbcccccfeacdc3d8cbcccccfd9cfc9dfd8c3ded384cecfdc">[email protected]</span></a>.</p></div></div>
  </body>
</html>
