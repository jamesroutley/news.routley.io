<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/mohsen1/llm-debugger-vscode-extension">Original</a>
    <h1>Show HN: Letting LLMs Run a Debugger</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto">LLM Debugger is a VSCode extension that demonstrates the use of large language models (LLMs) for active debugging of programs. This project is a <strong>proof of concept</strong> developed as a research experiment and will not be actively maintained or further developed.</p>
<details open="">
  <summary>
    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true">
    <path d="M16 3.75v8.5a.75.75 0 0 1-1.136.643L11 10.575v.675A1.75 1.75 0 0 1 9.25 13h-7.5A1.75 1.75 0 0 1 0 11.25v-6.5C0 3.784.784 3 1.75 3h7.5c.966 0 1.75.784 1.75 1.75v.675l3.864-2.318A.75.75 0 0 1 16 3.75Zm-6.5 1a.25.25 0 0 0-.25-.25h-7.5a.25.25 0 0 0-.25.25v6.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-6.5ZM11 8.825l3.5 2.1v-5.85l-3.5 2.1Z"></path>
</svg>
    <span aria-label="Video description final.mov">final.mov</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/543633/412359023-8052f75f-bc3f-4382-97f7-b1e01936df47.mov?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzk2NTA4NzksIm5iZiI6MTczOTY1MDU3OSwicGF0aCI6Ii81NDM2MzMvNDEyMzU5MDIzLTgwNTJmNzVmLWJjM2YtNDM4Mi05N2Y3LWIxZTAxOTM2ZGY0Ny5tb3Y_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwMjE1JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDIxNVQyMDE2MTlaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT03YWIxMTM2NjRkZTkyNTViNjk4MDU4YzVhMjI0NTQxMjcwYjgzNWJiMmUwNGY5ODY4MzAwYmJkNzMwZDhiZjc1JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.zUBnresLk24Y96tHzln9iXQhIiyyAk8HoJdIpS3RvLw" data-canonical-src="https://private-user-images.githubusercontent.com/543633/412359023-8052f75f-bc3f-4382-97f7-b1e01936df47.mov?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mzk2NTA4NzksIm5iZiI6MTczOTY1MDU3OSwicGF0aCI6Ii81NDM2MzMvNDEyMzU5MDIzLTgwNTJmNzVmLWJjM2YtNDM4Mi05N2Y3LWIxZTAxOTM2ZGY0Ny5tb3Y_WC1BbXotQWxnb3JpdGhtPUFXUzQtSE1BQy1TSEEyNTYmWC1BbXotQ3JlZGVudGlhbD1BS0lBVkNPRFlMU0E1M1BRSzRaQSUyRjIwMjUwMjE1JTJGdXMtZWFzdC0xJTJGczMlMkZhd3M0X3JlcXVlc3QmWC1BbXotRGF0ZT0yMDI1MDIxNVQyMDE2MTlaJlgtQW16LUV4cGlyZXM9MzAwJlgtQW16LVNpZ25hdHVyZT03YWIxMTM2NjRkZTkyNTViNjk4MDU4YzVhMjI0NTQxMjcwYjgzNWJiMmUwNGY5ODY4MzAwYmJkNzMwZDhiZjc1JlgtQW16LVNpZ25lZEhlYWRlcnM9aG9zdCJ9.zUBnresLk24Y96tHzln9iXQhIiyyAk8HoJdIpS3RvLw" controls="controls" muted="muted">

  </video>
</details>


<p dir="auto">Traditional LLM-based debugging approaches analyze only static source code. With LLM Debugger, the LLM is provided with real-time runtime context including:</p>
<ul dir="auto">
<li><strong>Runtime Variable Values:</strong> Observe actual variable states as the program executes.</li>
<li><strong>Function Behavior:</strong> Track how functions are called, what values they return, and how they interact.</li>
<li><strong>Branch Decisions:</strong> Understand which code paths are taken during execution.</li>
</ul>
<p dir="auto">This enriched context allows the LLM to diagnose bugs faster and more accurately. The extension also has the capability to generate synthetic data by running code and capturing execution details beyond the static source, offering unique insights into program behavior.</p>
<section data-identity="5082fb89-c2e0-4c7a-b403-dfb7f1c9c7f4" data-host="https://viewscreen.githubusercontent.com" data-src="https://viewscreen.githubusercontent.com/markdown/mermaid?docs_host=https%3A%2F%2Fdocs.github.com" data-type="mermaid" aria-label="mermaid rendered output container">
  <div data-json="{&#34;data&#34;:&#34;graph TB\n    subgraph \&#34;VSCode Editor\&#34;\n        User[User] --&amp;gt; Editor[VSCode Editor]\n        Editor --&amp;gt; DebugSession((Debug Session))\n    end\n\n    subgraph \&#34;LLM Debugger Extension\&#34;\n        DebugSession --&amp;gt; DebugAdapter[Debug Adapter Tracker]:::extensionComponent\n        DebugAdapter --&amp;gt; DebugSession\n        DebugAdapter -- Debug State --&amp;gt; LLMClient[LLM Client]:::extensionComponent\n        LLMClient -- Function Calls --&amp;gt; DebugAdapter\n    end\n\n    subgraph \&#34;External Services\&#34;\n      LLMClient --- LLM[Large Language Model]\n    end\n     DebugSession -- Debug Protocol --&amp;gt; NodeDebugAdapter[Node.js Debug Adapter]\n    NodeDebugAdapter -- Executes --&amp;gt; NodeApp[Node.js Application]\n    NodeApp -- Runtime Events --&amp;gt; NodeDebugAdapter\n\n&#34;}" data-plain="graph TB
    subgraph &#34;VSCode Editor&#34;
        User[User] --&gt; Editor[VSCode Editor]
        Editor --&gt; DebugSession((Debug Session))
    end

    subgraph &#34;LLM Debugger Extension&#34;
        DebugSession --&gt; DebugAdapter[Debug Adapter Tracker]:::extensionComponent
        DebugAdapter --&gt; DebugSession
        DebugAdapter -- Debug State --&gt; LLMClient[LLM Client]:::extensionComponent
        LLMClient -- Function Calls --&gt; DebugAdapter
    end

    subgraph &#34;External Services&#34;
      LLMClient --- LLM[Large Language Model]
    end
     DebugSession -- Debug Protocol --&gt; NodeDebugAdapter[Node.js Debug Adapter]
    NodeDebugAdapter -- Executes --&gt; NodeApp[Node.js Application]
    NodeApp -- Runtime Events --&gt; NodeDebugAdapter

" dir="auto">
    <div dir="auto">
      <pre lang="mermaid" aria-label="Raw mermaid code">graph TB
    subgraph &#34;VSCode Editor&#34;
        User[User] --&gt; Editor[VSCode Editor]
        Editor --&gt; DebugSession((Debug Session))
    end

    subgraph &#34;LLM Debugger Extension&#34;
        DebugSession --&gt; DebugAdapter[Debug Adapter Tracker]:::extensionComponent
        DebugAdapter --&gt; DebugSession
        DebugAdapter -- Debug State --&gt; LLMClient[LLM Client]:::extensionComponent
        LLMClient -- Function Calls --&gt; DebugAdapter
    end

    subgraph &#34;External Services&#34;
      LLMClient --- LLM[Large Language Model]
    end
     DebugSession -- Debug Protocol --&gt; NodeDebugAdapter[Node.js Debug Adapter]
    NodeDebugAdapter -- Executes --&gt; NodeApp[Node.js Application]
    NodeApp -- Runtime Events --&gt; NodeDebugAdapter

</pre>
    </div>
  </div>
  <span role="presentation">
    <span data-view-component="true">
  <svg style="box-sizing: content-box; color: var(--color-icon-primary);" width="16" height="16" viewBox="0 0 16 16" fill="none" aria-hidden="true" data-view-component="true">
    <circle cx="8" cy="8" r="7" stroke="currentColor" stroke-opacity="0.25" stroke-width="2" vector-effect="non-scaling-stroke" fill="none"></circle>
    <path d="M15 8a7.002 7.002 0 00-7-7" stroke="currentColor" stroke-width="2" stroke-linecap="round" vector-effect="non-scaling-stroke"></path>
</svg>    <span>Loading</span>
</span>
  </span>
</section>


<ul dir="auto">
<li><strong>Active Debugging:</strong> Integrates live debugging information (variables, stack traces, breakpoints) into the LLMâ€™s context.</li>
<li><strong>Automated Breakpoint Management:</strong> Automatically sets initial breakpoints based on code analysis and LLM recommendations.</li>
<li><strong>Runtime Inspection:</strong> Monitors events like exceptions and thread stops, gathering detailed runtime state to guide debugging.</li>
<li><strong>Debug Operations:</strong> Supports common debugging actions such as stepping over (<code>next</code>), stepping into (<code>stepIn</code>), stepping out (<code>stepOut</code>), and continuing execution.</li>
<li><strong>Synthetic Data Generation:</strong> Captures interesting execution details to generate data that extends beyond static code analysis.</li>
<li><strong>Integrated UI:</strong> Features a sidebar panel within the Run and Debug view that lets you toggle AI debugging and view live LLM suggestions and results.</li>
</ul>
<div dir="auto"><h2 tabindex="-1" dir="auto">Commands and Contributions</h2><a id="user-content-commands-and-contributions" aria-label="Permalink: Commands and Contributions" href="#commands-and-contributions"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>
<p dir="auto"><strong>Start LLM Debug Session:</strong></p>
<ul dir="auto">
<li>Command: <code>llm-debugger.startLLMDebug</code></li>
<li>Description: Launches an AI-assisted debugging session. Once activated, the extension configures the debugging environment for Node.js sessions and starts gathering runtime data for LLM analysis.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Sidebar Panel:</strong></p>
<ul dir="auto">
<li>Location: Run and Debug view</li>
<li>ID: <code>llmDebuggerPanel</code></li>
<li>Description: Displays the current state of the AI debugging session. Use the control panel to toggle &#34;Debug with AI&#34; mode. It shows live debugging insights, LLM function calls, and final debug results.</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Debug Configuration Provider &amp; Debug Adapter Tracker:</strong></p>
<ul dir="auto">
<li>Automatically integrated with Node.js debug sessions.</li>
<li>Injects LLM context into the session by reading the workspace state flag <code>llmDebuggerEnabled</code> and automatically setting breakpoints and handling debug events (e.g., exceptions, thread stops).</li>
<li>Supports LLM-guided commands for common operations like <code>next</code>, <code>stepIn</code>, <code>stepOut</code>, and <code>continue</code>.</li>
</ul>
</li>
</ul>

<p dir="auto">The extension maintains a single configuration flag (<code>llmDebuggerEnabled</code>) stored in the workspace state. This flag determines whether AI-assisted debugging is enabled. You can toggle this option via the sidebar panel. No additional settings are exposed in the Settings UI.</p>

<ol dir="auto">
<li>
<p dir="auto"><strong>Session Initialization:</strong></p>
</li>
<li>
<p dir="auto"><strong>Breakpoint Management:</strong></p>
</li>
<li>
<p dir="auto"><strong>Runtime Inspection:</strong></p>
</li>
<li>
<p dir="auto"><strong>LLM Guidance and Action Execution:</strong></p>
</li>
<li>
<p dir="auto"><strong>Session Termination:</strong></p>
</li>
</ol>

<p dir="auto">You can install LLM Debugger in VSCode using the &#34;Install from VSIX&#34; feature:</p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Build the Extension Package:</strong></p>
<ul dir="auto">
<li>Run the following command in the project root to build the extension:

</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Install the Extension in VSCode:</strong></p>
<ul dir="auto">
<li>Open VSCode.</li>
<li>Press <code>Ctrl+Shift+P</code> (or <code>Cmd+Shift+P</code> on macOS) to open the Command Palette.</li>
<li>Type and select <strong>&#34;Extensions: Install from from location...&#34;</strong>.</li>
<li>Browse to the directory of this repo</li>
<li>Reload VSCode if prompted.</li>
</ul>
</li>
</ol>
<p dir="auto">Alternatively, if you prefer to load the extension directly from the source for development:</p>
<ul dir="auto">
<li>Open the project folder in VSCode.</li>
<li>Run the <strong>&#34;Debug: Start Debugging&#34;</strong> command to launch a new Extension Development Host.</li>
</ul>

<ul dir="auto">
<li>
<p dir="auto"><strong>Faster Bug Resolution:</strong></p>
</li>
<li>
<p dir="auto"><strong>Enhanced Debugging Workflow:</strong></p>
</li>
<li>
<p dir="auto"><strong>Research &amp; Data Generation:</strong></p>
</li>
</ul>
<hr/>
<p dir="auto">LLM Debugger is an experimental project showcasing how combining live debugging data with LLM capabilities can revolutionize traditional debugging practices.</p>
</article></div></div>
  </body>
</html>
