<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://swe-to-mle.pages.dev/posts/svd-for-image-compression-and-recommender-systems/">Original</a>
    <h1>SVD for Image Compression and Recommender Systems</h1>
    
    <div id="readability-page-1" class="page"><div id="content"><p><em>Beneath the Arcane Academy, the Crucible of the Magi endures—aglow with a roaring fire, this dark iron relic, used to dissect enchanted artifacts into their primal essences, whispers secrets of raw power and hidden truths as it deconstructs, revealing the core components fundamental to spellcraft. Those who wield its power must tread carefully, for the truths it unveils can be as perilous as they are enlightening.</em></p>
<figure><a href="https://swe-to-mle.pages.dev/posts/svd-for-image-compression-and-recommender-systems/crucible-of-the-magi.png" title="crucible-of-the-magi" data-thumbnail="crucible-of-the-magi.png" data-sub-html="&lt;h2&gt;Crucible of the Magi&lt;/h2&gt;&lt;p&gt;crucible-of-the-magi&lt;/p&gt;">
        <img src="https://swe-to-mle.pages.dev/svg/loading.min.svg" data-src="crucible-of-the-magi.png" data-srcset="crucible-of-the-magi.png, crucible-of-the-magi.png 1.5x, crucible-of-the-magi.png 2x" data-sizes="auto" alt="crucible-of-the-magi.png"/>
    </a><figcaption>Crucible of the Magi</figcaption>
    </figure>
<h2 id="the-quest">The Quest</h2>
<p>Harness the power of SVD to compress images and recommend books.</p>
<h2 id="why-svd">Why SVD?</h2>
<p>SVD is a mathematical tool to deconstruct a matrix of data into its underlying patterns. It allows us to discover hidden regularities in the data. This can be exploited to get rid of redundancies or low level noise and focus on the stronger signal.</p>
<h2 id="singular-value-decomposition-svd">Singular Value Decomposition (SVD)</h2>
<p>SVD lets us factor a matrix $A$ into 3 components
$$ A = U \Sigma V^{T}$$
$A$: (m, n) matrix</p>
<p>$U$: (m, m) column matrix</p>
<p>$\Sigma$: (m, n) diagonal matrix</p>
<p>$V^{T}$: (n, n) row matrix</p>
<p>The SVD has many mathematical properties, and is computed using dark magic (iterative algorithms). But for our purpose I mostly care about one property: the columns of $U$, values of $\Sigma$, and rows of $V^{T}$ are sorted by variance (aka. the important patterns go first, and the leftover noise goes last).</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span># given a cloud of points data, we compute the SVD</span>
</span></span><span><span><span>u</span><span>,</span> <span>s</span><span>,</span> <span>v</span> <span>=</span> <span>torch</span><span>.</span><span>svd</span><span>(</span><span>data</span><span>)</span>
</span></span><span><span><span>pca_data</span> <span>=</span> <span>data</span> <span>@</span> <span>v</span>
</span></span><span><span><span>plot_points</span><span>(</span><span>data</span><span>)</span>
</span></span><span><span><span>plot_points</span><span>(</span><span>data</span><span>,</span> <span>v</span><span>)</span>
</span></span><span><span><span>plot_points</span><span>(</span><span>pca_data</span><span>,</span> <span>v</span><span>.</span><span>T</span> <span>@</span> <span>v</span><span>)</span>
</span></span></code></pre></div><figure><a href="https://swe-to-mle.pages.dev/posts/svd-for-image-compression-and-recommender-systems/pca.png" title="pca" data-thumbnail="pca.png" data-sub-html="&lt;h2&gt;PCA using SVD&lt;/h2&gt;&lt;p&gt;pca&lt;/p&gt;">
        <img src="https://swe-to-mle.pages.dev/svg/loading.min.svg" data-src="pca.png" data-srcset="pca.png, pca.png 1.5x, pca.png 2x" data-sizes="auto" alt="pca.png"/>
    </a><figcaption>PCA using SVD</figcaption>
    </figure>
<p>Here the vector <code>v[0]</code> drawn in black is the principal component as it explains most of the variance of our points (aka. the points are the most spread out in the black diagonal axis). We can use <code>v</code> to make a basis change and align the cloud of points with the <code>x</code> axis.</p>
<h2 id="image-compression">Image Compression</h2>
<p>Reusing the same property we can decompose an image into its most important components and discard the leftover to compress it.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>h</span><span>,</span> <span>w</span><span>,</span> <span>c</span> <span>=</span> <span>img</span><span>.</span><span>shape</span>
</span></span><span><span><span># reshape the image into a 2d tensor by concatenating the color channel `c` with the width `w`</span>
</span></span><span><span><span>reshaped</span> <span>=</span> <span>img</span><span>.</span><span>reshape</span><span>(</span><span>h</span><span>,</span> <span>w</span> <span>*</span> <span>c</span><span>)</span>
</span></span><span><span><span>u</span><span>,</span> <span>s</span><span>,</span> <span>v</span> <span>=</span> <span>torch</span><span>.</span><span>svd</span><span>(</span><span>reshaped</span><span>)</span>
</span></span><span><span><span>step</span> <span>=</span> <span>10</span> <span># how many components we want to keep</span>
</span></span><span><span><span>reconstructed</span> <span>=</span> <span>u</span><span>[:,</span> <span>:</span><span>step</span><span>]</span> <span>@</span> <span>t</span><span>.</span><span>diag</span><span>(</span><span>s</span><span>[:</span><span>step</span><span>])</span> <span>@</span> <span>v</span><span>[:,</span> <span>:</span><span>step</span><span>]</span><span>.</span><span>T</span>
</span></span><span><span><span>reconstructed</span> <span>=</span> <span>reconstructed</span><span>.</span><span>view</span><span>(</span><span>h</span><span>,</span> <span>w</span><span>,</span> <span>c</span><span>)</span>
</span></span></code></pre></div><figure><a href="https://swe-to-mle.pages.dev/posts/svd-for-image-compression-and-recommender-systems/compression.png" title="compression" data-thumbnail="compression.png" data-sub-html="&lt;h2&gt;Ratios of Image Compression&lt;/h2&gt;&lt;p&gt;compression&lt;/p&gt;">
        <img src="https://swe-to-mle.pages.dev/svg/loading.min.svg" data-src="compression.png" data-srcset="compression.png, compression.png 1.5x, compression.png 2x" data-sizes="auto" alt="compression.png"/>
    </a><figcaption>Ratios of Image Compression</figcaption>
    </figure>
<p>At step 130 we achieve a file size of only 12% but cover 80% of the variance, and the image looks close to the original.</p>
<p><img src="https://swe-to-mle.pages.dev/svg/loading.min.svg" data-src="compression.gif" data-srcset="compression.gif, compression.gif 1.5x, compression.gif 2x" data-sizes="auto" alt="compression.gif" title="compression-gif"/></p>
<h2 id="recommender-systems">Recommender Systems</h2>
<h3 id="svd">SVD</h3>
<p>The regularities SVD finds in the data can also be used to make a rudimentary recommender system.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span># given a matrix of (users, books) containing ratings from 1-5 and 0 for non-rated</span>
</span></span><span><span><span>u</span><span>,</span> <span>s</span><span>,</span> <span>v</span> <span>=</span> <span>torch</span><span>.</span><span>svd</span><span>(</span><span>user_book</span><span>)</span>
</span></span><span><span><span>r</span> <span>=</span> <span>100</span>
</span></span><span><span><span># given a new user rating a few books</span>
</span></span><span><span><span>ratings</span> <span>=</span> <span>t</span><span>.</span><span>zeros</span><span>(</span><span>user_book</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>])</span>
</span></span><span><span><span>ratings</span><span>[</span><span>15</span><span>]</span> <span>=</span> <span>4</span>
</span></span><span><span><span>ratings</span><span>[</span><span>20</span><span>]</span> <span>=</span> <span>5</span>
</span></span><span><span><span>ratings</span><span>[</span><span>30</span><span>]</span> <span>=</span> <span>3</span>
</span></span><span><span><span>ratings</span><span>[</span><span>50</span><span>]</span> <span>=</span> <span>4</span>
</span></span><span><span><span># project the new user into the latent space of v</span>
</span></span><span><span><span>user_projection</span> <span>=</span> <span>ratings</span> <span>@</span> <span>v</span><span>[:,</span> <span>:</span><span>r</span><span>]</span>
</span></span><span><span><span># predict the other ratings based on the projected user</span>
</span></span><span><span><span>predictions</span> <span>=</span> <span>user_projection</span> <span>@</span> <span>v</span><span>[:,</span> <span>:</span><span>r</span><span>]</span><span>.</span><span>T</span>
</span></span></code></pre></div><p>We compute the similarities between users and books relations, and use them to predict the books a new user would like given the books they already rated. In practice the latent space is not nicely interpretable, but in concept we could imagine that some pattern would emerge around the genres of the book, and the age of the reader, the language of the text…</p>
<p>When presented with a new user we fit it to a reader archetype, if they rated highly fantasy books for young adults in english, when projecting the archetype back into the full list of books, we’ll get high scores for other similar books.</p>
<h3 id="funk-svd">Funk SVD</h3>
<p>Now say we have a lot more books, and a lot more users. Computing the SVD becomes prohibitively expensive, even building the <code>(users, book)</code> matrix becomes too expensive. Most of the users haven’t read most of the books. So the matrix is very sparse, and we could instead represent the relations as a list of triplets of <code>(user_id, book_id, rating)</code>.</p>
<p>Simon Funk came up with a solution to compute an approximation of the SVD by ignoring the unrated elements and focusing on only predicting the triplets.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>class</span> <span>NaiveFunk</span><span>(</span><span>nn</span><span>.</span><span>Module</span><span>):</span>
</span></span><span><span>    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>users</span><span>,</span> <span>books</span><span>,</span> <span>r</span><span>=</span><span>100</span><span>):</span>
</span></span><span><span>        <span>super</span><span>()</span><span>.</span><span>__init__</span><span>()</span>
</span></span><span><span>        <span>self</span><span>.</span><span>user_factors</span> <span>=</span> <span>nn</span><span>.</span><span>Parameter</span><span>(</span><span>torch</span><span>.</span><span>randn</span><span>(</span><span>users</span><span>,</span> <span>r</span><span>))</span>
</span></span><span><span>        <span>self</span><span>.</span><span>book_factors</span> <span>=</span> <span>nn</span><span>.</span><span>Parameter</span><span>(</span><span>torch</span><span>.</span><span>randn</span><span>(</span><span>books</span><span>,</span> <span>r</span><span>))</span>
</span></span><span><span>
</span></span><span><span>    <span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span> <span>user</span><span>,</span> <span>book</span><span>):</span>
</span></span><span><span>        <span>user_vec</span> <span>=</span> <span>self</span><span>.</span><span>user_factors</span><span>[</span><span>user</span><span>]</span>
</span></span><span><span>        <span>book_vec</span> <span>=</span> <span>self</span><span>.</span><span>book_factors</span><span>[</span><span>book</span><span>]</span>
</span></span><span><span>        <span>ratings</span> <span>=</span> <span>torch</span><span>.</span><span>sum</span><span>(</span><span>user_vec</span> <span>*</span> <span>book_vec</span><span>,</span> <span>dim</span><span>=-</span><span>1</span><span>)</span>
</span></span><span><span>        <span>return</span> <span>ratings</span>
</span></span><span><span>    
</span></span><span><span>    <span>@property</span>
</span></span><span><span>    <span>def</span> <span>u</span><span>(</span><span>self</span><span>):</span> <span>return</span> <span>self</span><span>.</span><span>user_factors</span><span>.</span><span>data</span>
</span></span><span><span>    <span>@property</span>
</span></span><span><span>    <span>def</span> <span>v</span><span>(</span><span>self</span><span>):</span> <span>return</span> <span>self</span><span>.</span><span>book_factors</span><span>.</span><span>data</span>
</span></span></code></pre></div><p>We train the model only on rated entries:</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>def</span> <span>train</span><span>(</span><span>model</span><span>,</span> <span>ds</span><span>,</span> <span>epochs</span><span>=</span><span>1000</span><span>,</span> <span>lr</span><span>=</span><span>1e-3</span><span>,</span> <span>opt</span><span>=</span><span>None</span><span>,</span> <span>batch_size</span><span>=</span><span>10000</span><span>):</span>
</span></span><span><span>    <span>if</span> <span>opt</span> <span>is</span> <span>None</span><span>:</span> <span>opt</span> <span>=</span> <span>optim</span><span>.</span><span>AdamW</span><span>(</span><span>model</span><span>.</span><span>parameters</span><span>(),</span> <span>lr</span><span>=</span><span>lr</span><span>,</span> <span>weight_decay</span><span>=</span><span>1e-2</span><span>)</span>
</span></span><span><span>    <span>for</span> <span>epoch</span> <span>in</span> <span>range</span><span>(</span><span>epochs</span><span>):</span>
</span></span><span><span>        <span>for</span> <span>batch_start</span> <span>in</span> <span>range</span><span>(</span><span>0</span><span>,</span> <span>len</span><span>(</span><span>ds</span><span>),</span> <span>batch_size</span><span>):</span>
</span></span><span><span>            <span>batch</span> <span>=</span> <span>ds</span><span>[</span><span>batch_start</span><span>:</span><span>batch_start</span><span>+</span><span>batch_size</span><span>]</span>
</span></span><span><span>            <span>user_idx</span> <span>=</span> <span>torch</span><span>.</span><span>tensor</span><span>(</span><span>batch</span><span>[</span><span>&#39;user_id&#39;</span><span>]</span><span>.</span><span>values</span><span>,</span> <span>dtype</span><span>=</span><span>torch</span><span>.</span><span>int</span><span>,</span> <span>device</span><span>=</span><span>device</span><span>)</span>
</span></span><span><span>            <span>book_idx</span> <span>=</span> <span>torch</span><span>.</span><span>tensor</span><span>(</span><span>batch</span><span>[</span><span>&#39;book_id&#39;</span><span>]</span><span>.</span><span>values</span><span>,</span> <span>dtype</span><span>=</span><span>torch</span><span>.</span><span>int</span><span>,</span> <span>device</span><span>=</span><span>device</span><span>)</span>
</span></span><span><span>            <span>ratings</span> <span>=</span> <span>torch</span><span>.</span><span>tensor</span><span>(</span><span>batch</span><span>[</span><span>&#39;rating&#39;</span><span>]</span><span>.</span><span>values</span><span>,</span> <span>dtype</span><span>=</span><span>torch</span><span>.</span><span>float32</span><span>,</span> <span>device</span><span>=</span><span>device</span><span>)</span>
</span></span><span><span>            <span>preds</span> <span>=</span> <span>model</span><span>(</span><span>user_idx</span><span>,</span> <span>book_idx</span><span>)</span>
</span></span><span><span>            <span>loss</span> <span>=</span> <span>F</span><span>.</span><span>mse_loss</span><span>(</span><span>preds</span><span>,</span> <span>ratings</span><span>)</span>
</span></span><span><span>            <span>opt</span><span>.</span><span>zero_grad</span><span>()</span>
</span></span><span><span>            <span>loss</span><span>.</span><span>backward</span><span>()</span>
</span></span><span><span>            <span>opt</span><span>.</span><span>step</span><span>()</span>
</span></span></code></pre></div><p>One way to evaluate the quality of the recommendation is to take a set of test users we haven’t trained on. Mask their top 10 highest rated books and ask the model to predict recommendations based on their other liked books. Use the ratio of overlap between the user favorite-10 and the system top-10 recommendations.</p>
<figure><a href="https://swe-to-mle.pages.dev/posts/svd-for-image-compression-and-recommender-systems/train.png" title="train" data-thumbnail="train.png" data-sub-html="&lt;h2&gt;Loss and Top-10 Ratio over 2500 epochs&lt;/h2&gt;&lt;p&gt;train&lt;/p&gt;">
        <img src="https://swe-to-mle.pages.dev/svg/loading.min.svg" data-src="train.png" data-srcset="train.png, train.png 1.5x, train.png 2x" data-sizes="auto" alt="train.png"/>
    </a><figcaption>Loss and Top-10 Ratio over 2500 epochs</figcaption>
    </figure>
<h2 id="the-code">The code</h2>
<p>You can get the code at <a href="https://github.com/peluche/SVD" target="_blank" rel="noopener noreffer ">https://github.com/peluche/SVD</a></p>
<h2 id="sources">Sources</h2>
<ul>
<li>Lectures from Steve Brunton: <a href="https://youtu.be/gXbThCXjZFM" target="_blank" rel="noopener noreffer ">https://youtu.be/gXbThCXjZFM</a></li>
<li>Lectures by Gilbert Strang: <a href="https://youtu.be/mBcLRGuAFUk" target="_blank" rel="noopener noreffer ">https://youtu.be/mBcLRGuAFUk</a></li>
<li>Simon Funk explanation of his algorithm: <a href="https://sifter.org/simon/journal/20061211.html" target="_blank" rel="noopener noreffer ">https://sifter.org/simon/journal/20061211.html</a></li>
</ul>
</div></div>
  </body>
</html>
