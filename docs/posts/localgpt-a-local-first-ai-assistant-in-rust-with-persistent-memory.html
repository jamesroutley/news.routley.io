<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/localgpt-app/localgpt">Original</a>
    <h1>Show HN: LocalGPT – A local-first AI assistant in Rust with persistent memory</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto">A local device focused AI assistant built in Rust — persistent memory, autonomous tasks, ~27MB binary. Inspired by and compatible with OpenClaw.</p>
<p dir="auto"><code>cargo install localgpt</code></p>

<ul dir="auto">
<li><strong>Single binary</strong> — no Node.js, Docker, or Python required</li>
<li><strong>Local device focused</strong> — runs entirely on your machine, your memory data stays yours</li>
<li><strong>Persistent memory</strong> — markdown-based knowledge store with full-text and semantic search</li>
<li><strong>Autonomous heartbeat</strong> — delegate tasks and let it work in the background</li>
<li><strong>Multiple interfaces</strong> — CLI, web UI, desktop GUI</li>
<li><strong>Multiple LLM providers</strong> — Anthropic (Claude), OpenAI, Ollama</li>
<li><strong>OpenClaw compatible</strong> — works with SOUL, MEMORY, HEARTBEAT markdown files and skills format</li>
</ul>



<div dir="auto" data-snippet-clipboard-copy-content="# Initialize configuration
localgpt config init

# Start interactive chat
localgpt chat

# Ask a single question
localgpt ask &#34;What is the meaning of life?&#34;

# Run as a daemon with heartbeat, HTTP API and web ui
localgpt daemon start"><pre><span><span>#</span> Initialize configuration</span>
localgpt config init

<span><span>#</span> Start interactive chat</span>
localgpt chat

<span><span>#</span> Ask a single question</span>
localgpt ask <span><span>&#34;</span>What is the meaning of life?<span>&#34;</span></span>

<span><span>#</span> Run as a daemon with heartbeat, HTTP API and web ui</span>
localgpt daemon start</pre></div>

<p dir="auto">LocalGPT uses plain markdown files as its memory:</p>
<div data-snippet-clipboard-copy-content="~/.localgpt/workspace/
├── MEMORY.md            # Long-term knowledge (auto-loaded each session)
├── HEARTBEAT.md         # Autonomous task queue
├── SOUL.md              # Personality and behavioral guidance
└── knowledge/           # Structured knowledge bank (optional)
    ├── finance/
    ├── legal/
    └── tech/"><pre><code>~/.localgpt/workspace/
├── MEMORY.md            # Long-term knowledge (auto-loaded each session)
├── HEARTBEAT.md         # Autonomous task queue
├── SOUL.md              # Personality and behavioral guidance
└── knowledge/           # Structured knowledge bank (optional)
    ├── finance/
    ├── legal/
    └── tech/
</code></pre></div>
<p dir="auto">Files are indexed with SQLite FTS5 for fast keyword search, and sqlite-vec for semantic search with local embeddings</p>

<p dir="auto">Stored at <code>~/.localgpt/config.toml</code>:</p>
<div dir="auto" data-snippet-clipboard-copy-content="[agent]
default_model = &#34;claude-cli/opus&#34;

[providers.anthropic]
api_key = &#34;${ANTHROPIC_API_KEY}&#34;

[heartbeat]
enabled = true
interval = &#34;30m&#34;
active_hours = { start = &#34;09:00&#34;, end = &#34;22:00&#34; }

[memory]
workspace = &#34;~/.localgpt/workspace&#34;"><pre>[<span>agent</span>]
<span>default_model</span> = <span><span>&#34;</span>claude-cli/opus<span>&#34;</span></span>

[<span>providers</span>.<span>anthropic</span>]
<span>api_key</span> = <span><span>&#34;</span>${ANTHROPIC_API_KEY}<span>&#34;</span></span>

[<span>heartbeat</span>]
<span>enabled</span> = <span>true</span>
<span>interval</span> = <span><span>&#34;</span>30m<span>&#34;</span></span>
<span>active_hours</span> = { <span>start</span> = <span><span>&#34;</span>09:00<span>&#34;</span></span>, <span>end</span> = <span><span>&#34;</span>22:00<span>&#34;</span></span> }

[<span>memory</span>]
<span>workspace</span> = <span><span>&#34;</span>~/.localgpt/workspace<span>&#34;</span></span></pre></div>

<div dir="auto" data-snippet-clipboard-copy-content="# Chat
localgpt chat                     # Interactive chat
localgpt chat --session &lt;id&gt;      # Resume session
localgpt ask &#34;question&#34;           # Single question

# Daemon
localgpt daemon start             # Start background daemon
localgpt daemon stop              # Stop daemon
localgpt daemon status            # Show status
localgpt daemon heartbeat         # Run one heartbeat cycle

# Memory
localgpt memory search &#34;query&#34;    # Search memory
localgpt memory reindex           # Reindex files
localgpt memory stats             # Show statistics

# Config
localgpt config init              # Create default config
localgpt config show              # Show current config"><pre><span><span>#</span> Chat</span>
localgpt chat                     <span><span>#</span> Interactive chat</span>
localgpt chat --session <span>&lt;</span>id<span>&gt;</span>      <span><span>#</span> Resume session</span>
localgpt ask <span><span>&#34;</span>question<span>&#34;</span></span>           <span><span>#</span> Single question</span>

<span><span>#</span> Daemon</span>
localgpt daemon start             <span><span>#</span> Start background daemon</span>
localgpt daemon stop              <span><span>#</span> Stop daemon</span>
localgpt daemon status            <span><span>#</span> Show status</span>
localgpt daemon heartbeat         <span><span>#</span> Run one heartbeat cycle</span>

<span><span>#</span> Memory</span>
localgpt memory search <span><span>&#34;</span>query<span>&#34;</span></span>    <span><span>#</span> Search memory</span>
localgpt memory reindex           <span><span>#</span> Reindex files</span>
localgpt memory stats             <span><span>#</span> Show statistics</span>

<span><span>#</span> Config</span>
localgpt config init              <span><span>#</span> Create default config</span>
localgpt config show              <span><span>#</span> Show current config</span></pre></div>

<p dir="auto">When the daemon is running:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Endpoint</th>
<th>Description</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>GET /health</code></td>
<td>Health check</td>
</tr>
<tr>
<td><code>GET /api/status</code></td>
<td>Server status</td>
</tr>
<tr>
<td><code>POST /api/chat</code></td>
<td>Chat with the assistant</td>
</tr>
<tr>
<td><code>GET /api/memory/search?q=&lt;query&gt;</code></td>
<td>Search memory</td>
</tr>
<tr>
<td><code>GET /api/memory/stats</code></td>
<td>Memory statistics</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>

<p dir="auto">Rust, Tokio, Axum, SQLite (FTS5 + sqlite-vec), fastembed, eframe</p>

<p dir="auto"><a href="https://github.com/localgpt-app/localgpt/blob/main/LICENSE">Apache-2.0</a></p>
</article></div></div>
  </body>
</html>
