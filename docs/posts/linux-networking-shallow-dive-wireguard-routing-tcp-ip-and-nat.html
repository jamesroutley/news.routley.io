<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://im.salty.fish/index.php/archives/linux-networking-shallow-dive.html">Original</a>
    <h1>Linux Networking Shallow Dive: WireGuard, Routing, TCP/IP and Nat</h1>
    
    <div id="readability-page-1" class="page"><article>
  <div>
    <div>
      <div>
        <blockquote>(For Chinese readers) 插播一则通知！好久没有更新博客了。今年我将会重新开始发表一些技术笔记，但是由于我目前居住在美国等原因，大部分的新博文将会以英文撰写。带给大家的不便我深表歉意。虽然博文会换用英文，但是中文技术交流还是欢迎的~</blockquote><p>This year I decided to refactor my personal cloud infrastructure. Because of various nuances in my seemingly weird new setup, I have come across various difficulties. And yet, I managed to resolve all of them - at the cost of loss of sleep for several days. Here I will write about some of the takeaways and some new knowledge I learned along the way, in the hope that this could help some other self-host enthusiasts avoid having to go through the networking hell alone.</p><p>This article does not assume you have a lot of network background knowledge, and I will explain everything as detailed as I can. However, you should at least have some vague ideas about how computer networks work, and the ability to use search engines to do independent research.</p><h2>Disclaimer</h2><p>Everything here is based solely on my personal understanding of the matter. I do not guarantee absolute correctness of what I say in this article. If you spot any errors, please contact me to help me correct them. Thank you.</p><h2>Recap</h2><p>I don&#39;t think I have ever documented my old infrastructure, and I probably don&#39;t need to, because it was very simple, and very immature. But just for the sake of demonstrating what changes I am making to it, I should at least list some of the key ideas I used:</p><ul><li>Docker Compose was used to encapsulate all services I run.</li><li>ZFS datasets were used to persist data.</li><li>Because I was back in China where self-hosting was (and still is) <em>basically</em> forbidden, I had to use some sort of <em>reverse proxying</em> to expose my services to the public internet. The tool I used was <code>frp</code>.</li></ul><p>I won&#39;t make any changes to the Docker Compose part or the ZFS part because I am pretty satisfied with them. Yeah - I hear you questioning me: &#34;how dare you call it <em>cloud</em> if it does not use Kubernetes?&#34; I do have a K8s-centered plan. It is not in any sense completed yet, and I <em>will</em> write about it when it is largely done.</p><p>If you are experienced with computer networks, and you know what <code>frp</code> is, you will immediately notice that there were very obvious issues with this setup. <code>frp</code> is a transport layer reverse proxy. The way it works is:</p><ol><li>The <code>frp</code> server, or <code>frps</code>, is run on a machine with a public IP address (say <code>1.2.3.4</code>), and listens on a port, say <code>50000</code>.</li><li>The <code>frp</code> client, or <code>frpc</code>, is run on my home server with no public IP address, and connects to <code>frps</code> at <code>1.2.3.4:50000</code>.</li><li><code>frpc</code> registers ports it wants to expose (say <code>443</code>) over the port <code>50000</code> channel. <code>frps</code> receives the requests and listens on <code>1.2.3.4:443</code>.</li><li>An external user initiates a connection to <code>1.2.3.4:443</code>.</li><li><code>frps</code> receives the packet, reads the transport layer payload, and forwards that to the client over the port <code>50000</code> channel.</li><li><code>frpc</code> receives the transport layer payload, and initiates a connection to <code>127.0.0.1:443</code> with the received payload.</li><li>All subsequent packets will be forwarded over the port <code>50000</code> channel in a similar fashion.</li></ol><p>Here a very obvious problem is that all traffic sent to my server was recognized as coming from <code>127.0.0.1</code>, because it appeared as if <code>frpc</code>, running on the local machine, had initiated all the connections. I was young and illiterate about security at that time, so I thought as long as nobody notices the existence of my personal cloud, it is not a big issue to make the server unable to see the real source IP address of network connections. After all, who was going to attack me?</p><p>I was totally wrong. One day I noticed that my postmaster inbox started to see complaints about my server sending spam emails. I did not pay attention to it, thinking they were sent by mistake. I saw a lot of emails filtered out by rSpamd, but I did not pay attention to it either. I thought these were &#34;incoming&#34; spam emails. Then one day spam emails became so huge a problem that my server literally started to lag because all CPUs have been working on identifying spam emails. I could no longer live with that, so I investigated what happened. It was one of the things you never wish to happen to you: my mail server had been operating as an open relay, and <del>motherfuckers</del> spammers soon noticed that.</p><p>The reason was because I was using Mailu to deploy my mail server. Mailu&#39;s default Postfix configuration &#34;trusts&#34; local IP addresses as impossible to be spammers. They do this for a reason, but in my setup it causes trouble, because all emails appear as coming from the local host. I was stupid and lazy back then, so rather than fixing the issue, I chose to work around it by making SMTP an exception to the reverse proxying. Details about this workaround is out of scope for this article.</p><p>As you see, using <code>frp</code> is not the best option. Thus, the major goal of my refactor is to enable my home server to see the real source IP addresses of clients.</p><h2>WireGuard: Quest for Real IP</h2><p>I then decided to fix this critical issue. Since I moved to the US, I now have a public IP address and no longer need an awkward reverse proxying setup. However, there is a bad news: outbound traffic to port 25 is blocked. This is a reasonable anti-abuse practice, but it also brings legitimate users (like me!) some trouble. Another issue is privacy concerns: I do not want to expose to the public my home IP address. Thus, I planned to ditch <code>frp</code> but still utilize some sort of reverse proxying, just to bypass the ISP restrictions and hide my home IP.</p><blockquote>Note that certain VPS providers also block outbound SMTP. I won&#39;t recommend specific service providers, but there are service providers who trust their users and do not do so by default. Please do me a favor by not abusing these angelic service providers.</blockquote><p>As transport layer proxies do not preserve source IP information, we need to go a bit deeper into the network stack to the network layer, because this is where the IP headers reside. VPN is a great tool to help us achieve network layer reverse proxying. However, traditional VPNs (L2TP, IPSec, etc.) are IMHO very convoluted and difficult to set up securely and correctly. Thus, I decided to settle on WireGuard, a relatively new VPN protocol.</p><p>Linus Torvalds loved WireGuard so much that he merged it into the Linux kernel, so WireGuard is relatively easy to set up. One caveat though, is that if your VPS is virtualized using OpenVZ, it tends to have an older version of the kernel that does not include WireGuard. In this case, you can use BoringTun by Cloudflare. It is a userspace implementation of WireGuard, removing the need to interop with the kernel, thus reducing the level of privileges required.</p><h2>Characters</h2><p>Before we dive into the technical details of my new setup, let&#39;s make clear what I have:</p><ul><li><em>Gateway</em> refers to my VPS providing the mask IP address and forwarding outbound SMTP traffic.</li><li><em>Server</em> refers to my home server hosting all the private cloud services I use on a daily basis.</li></ul><h2>Setting up WireGuard</h2><p>The first step is to establish a channel between Gateway and Server, by setting up WireGuard. Let&#39;s start from the simplest configuration. Generate the keypair using</p><pre><code>$ wg genkey | tee private.key | wg pubkey | tee public.key</code></pre><p>And optionally, use</p><pre><code>$ wg genpsk</code></pre><p>to generate a pre-shared key. Then, we create the configuration file <code>/etc/wireguard/wg0.conf</code> on Gateway:</p><pre><code>[Interface]
PrivateKey = &lt;Gateway private key&gt;
Address = 192.168.160.1
ListenPort = 51820

[Peer]
PublicKey = &lt;Server public key&gt;
PresharedKey = &lt;PSK&gt;
AllowedIPs = 192.168.160.2/32</code></pre><p>and on Server:</p><pre><code>[Interface]
PrivateKey = &lt;Server private key&gt;
Address = 192.168.160.2

[Peer]
PublicKey = &lt;Gateway public key&gt;
PresharedKey = &lt;PSK&gt;
AllowedIPs = 0.0.0.0/0
Endpoint = &lt;Gateway public IP&gt;:51820
PersistentKeepalive = 60</code></pre><p>The config item <code>PersistentKeepalive</code> is used so that WireGuard keeps the connection active, since the underlying connection is one-way although the tunnel enables two-way communication. This is because Gateway has a public IP address while Server does not (or at least we do not intend to use it). If we do not enable the keepalive feature and the connection is somehow interrupted, Gateway can no longer reach Server until Server contacts it again.</p><p>Another interesting item is <code>AllowedIPs</code>. WireGuard automaticlly adds a route to <code>wg0</code> for these IPs when the interface is brought up, and it only allows packets with these destination IPs to be routed over the tunnel. Intuitively, these are the IP addresses we are allowed to reach via the tunnel.</p><p>After we have created the configuration files, we can use <code>wg-quick up wg0</code> to bring the WireGuard interfaces up.</p><blockquote>If using BoringTun, add these environment variables: <code>WG_QUICK_USERSPACE_IMPLEMENTATION=boringtun-cli WG_SUDO=1</code>. I added them to <code>/etc/environment</code>, as well as the <code>systemd</code> override file for the service <code><a href="https://im.salty.fish/cdn-cgi/l/email-protection" data-cfemail="f18696dc808498929ab18696c1">[email protected]</a></code> such that I can use <code>systemd</code> to manage the WireGuard interface. Note that TUN/TAP must be enabled. Check that by <code>stat /dev/net/tun</code>. If TUN/TAP is not enabled, you will get &#34;No such file or directory&#34;.</blockquote><h2>First Encounter with Routing</h2><p>It seems that WireGuard is up and running now, and you can confirm this by pinging <code>192.168.160.1</code> from Server (or pinging Server from Gateway). However, pinging other addresses will give you a 100% packet loss. Let&#39;s try to understand why:</p><pre><code>server$ ip route get 1.1.1.1
1.1.1.1 dev wg0 table 51820 src 192.168.160.2 uid 1000
    cache</code></pre><p>The <code>ip route get</code> command takes an IP address and returns the routing decision for packets with this particular destination IP address. Here, it tells us: packets sent to <code>1.1.1.1</code> will be routed through the interface <code>wg0</code>, due to looking up the routing table with number <code>51820</code>, and they will be assigned the source IP address <code>192.168.160.2</code>.</p><p>In Linux, routing is done by looking up <em>routing tables</em>, which you can view using the <code>ip route show &lt;table&gt;</code> command. There are some default tables (<code>local</code> used for local loopback traffic, <code>main</code> the main routing table and <code>default</code> as the ultimate fallback option). However, routing tables are not consulted until the router sees a <em>rule</em> telling it to do so. Rules (some people might prefer to call them routing policies) can be viewed with the command <code>ip rule</code>. Let&#39;s try to understand where the routing decision for <code>1.1.1.1</code> came from:</p><pre><code>server$ ip rule
0:      from all lookup local
32764:  from all lookup main suppress_prefixlength 0
32765:  not from all fwmark 0xca6c lookup 51820
32766:  from all lookup main
32767:  from all lookup default</code></pre><p>The rule with <em>preference</em> 32765 dictates that all packets without the <em>firewall mark</em> <code>0xca6c</code> should consult the routing table numbered <code>51820</code>. This rule was created by WireGuard when we used <code>wg-quick</code> to bring up our <code>wg0</code> interface. We will skip over <code>fwmark</code> for now. The short explanation is that this rule tries to exclude packets sent by WireGuard itself. Thus, the meaning of this rule translates to: &#34;all traffic that was not sent by WireGuard should be routed to WireGuard&#34;.</p><pre><code>server$ ip route show table 51820
default dev wg0 scope link</code></pre><h2>Forwarding</h2><p>While this looks intuitive, it actually will not work! There are two things missing here. First, we need to make sure that <em>forwarding</em> is enabled on Gateway. Forwarding means relaying packets that are not directly related to the local host. In our case, Gateway needs to do forwarding to connect Server with other hosts on the internet. This means Gateway will receive packets with neither the source IP nor the destination IP matching its own, and it needs to forward these packets between Server and whichever host Server is communicating with.</p><p>By default, the Linux kernel might not allow forwarding packets for other hosts, because not all machines need to act as routers. Allowing forwarding would add some security risks, so it&#39;s better disabled if not used. However, in our setup, since Gateway is a gateway which forwards traffic for Server, it does need to allow forwarding.</p><p>Whether forwarding is allowed is controlled by the <code>sysctl</code> variable <code>net.ipv4.ip_forward</code>. It needs to be set to <code>1</code>. We can use the command</p><pre><code>gateway# sysctl -n net.ipv4.ip_forward</code></pre><p>to check the current value, and use</p><pre><code>gateway# sysctl -w net.ipv4.ip_forward=1</code></pre><p>to set it to <code>1</code>, if not already. However, our changes will be lost once the machine reboots. To persist them, we need to edit the configuration file <code>/etc/sysctl.conf</code>. I prefer to add an override in <code>/etc/sysctl.d/</code>. We will create a new file <code>10-forwarding.conf</code> and write <code>net.ipv4.ip_forward = 1</code> in it, and use <code>sysctl -p</code> to load the config file so that our changes take effect immediately.</p><h3>Security</h3><p>Keep in mind that allowing forwarding bears some security risks. If we forward everything we receive, there is a chance that malicious hackers could use our Gateway to proxy their traffic when attacking other servers! We have to set up some finer control over what could be forwarded and what should be dropped.</p><p>We will first let Netfilter filter all packets that need to be forwarded, by setting the default policy of the <code>FORWARD</code> chain in the <code>filter</code> table to <code>DROP</code> (or <code>REJECT</code>):</p><pre><code>gateway# iptables -P FORWARD DROP </code></pre><p>Remember that <code>iptables</code> rules are not persistent, so you have to come up with a way to apply it automatically on each boot. The easiest way is to add the command to <code>/etc/rc.local</code> (I am using Debian, YMMV) but you might want to use more advanced tools like <code>iptables-persistent</code>. Since my Gateway does not do anything other than forwarding traffic for Server, I just went with the simplest solution.</p><p>This would again render our Gateway incapable of doing any forwarding, but we do need to enable forwarding both to and from <code>wg0</code>. We can use these two commands to achieve this effect:</p><pre><code>gateway# iptables -A FORWARD -i wg0 -j ACCEPT
gateway# iptables -A FORWARD -o wg0 -j ACCEPT</code></pre><p>These rules say that all packets that come from (<code>-i</code>) or go to (<code>-o</code>) the <code>wg0</code> interface should be allowed to pass. Some tutorials on the internet would ask you to do</p><pre><code>gateway# iptables -A FORWARD -m conntrack --ctstate RELATED,ESTABLISHED -j ACCEPT</code></pre><p>This is favorable if you do not need to accept inbound connections. In this case, you would disregard the <code>-o wg0</code> rule and use this instead. Later we will cover <code>conntrack</code> in more detail when we talk about DNAT. Here is a brief explanation: It says that all packets that belong to an already established connection, or are related one, should be allowed to pass. If this rule is not present, although Server will be able to access internet hosts through Gateway, all response packets would be dropped. This rule, while allowing responses to be delivered, does not allow establishing incoming connections from the internet. However, since I do want to allow incoming connections, I allowed all traffic targeted towards <code>wg0</code>.</p><p>You might want to have finer control over what ports are open, etc. This is out of scope for this post, but yes, you can do it here by using the <code>conntrack</code> rule in conjunction with some other rules that open up specific ports.</p><h2>SNAT</h2><p>However, you should notice that you still cannot access WAN IPs over the tunnel. Let&#39;s inspect the packets to determine the reason. I used <code>tcpdump</code> on both Server and Gateway to capture traffic on <code>wg0</code>. Here is the command:</p><pre><code># tcpdump -i wg0 -w output.pcap</code></pre><p>And here is what we&#39;ll see on <strong>both</strong> hosts: (I use Wireshark to view pcap files)</p><p>The reason why our ping failed is obvious here: our ICMP packet successfully reached Gateway, however no response was received from <code>1.1.1.1</code>. Of course the reply packet won&#39;t arrive back at Gateway - it doesn&#39;t know how! The only way a host can know how to reach back to another host that contacted it was to read the source IP address from the IP header, and in this case it is <code>192.168.160.2</code>, a private IPv4 address. As a result, <code>1.1.1.1</code> will think <code>192.168.160.2</code> just pinged it, and send any reply to <code>192.168.160.2</code>.</p><p>What we want instead is that reply packets get sent to Gateway first, and forwarded back to Server by Gateway. The only way to tell another host to reply to Gateway is to inform it of Gateway&#39;s public IP address, so we will have to <strong>rewrite</strong> the packets&#39; IP headers to replace the source IP addresses. Not only do we have to replace the IP addresses, but we also need to keep track of the connection info and identify the reply packets, such that we can forward them back to Server. That sounds like a lot of work, but it&#39;s such a common scenario that the Linux kernel provides a specialized tool to help accomplish it: SNAT, or Source Network Address Translation.</p><p>Using SNAT is as simple as adding a rule in the <code>POSTROUTING</code> chain in the <code>nat</code> table in Netfilter. To help illustrate the flow of network packets, here is an image showing the structure of Linux&#39;s network stack, taken from Wikipedia. For now we will only focus on the IP layer (i.e. the green section).</p><p><img src="https://upload.wikimedia.org/wikipedia/commons/thumb/3/37/Netfilter-packet-flow.svg/1600px-Netfilter-packet-flow.svg.png?20210421135414" alt="" title=""/></p><p>SNAT happens in the postrouting phase, where the routing decision for the outgoing packet has already been made. Let&#39;s go through an example scenario where our public IP is <code>2.2.2.2</code>:</p><ol><li>Server at <code>192.168.160.2</code> wants to send a packet to <code>1.1.1.1</code>.</li><li>The routing table says the packet should be sent over WireGuard, through Gateway, or <code>192.168.160.1</code>.</li><li>Server sends the packet with source IP <code>192.168.160.2</code> and destination IP <code>1.1.1.1</code> to <code>192.168.160.1</code>.</li><li>Gateway receives the packet and forwards it to <code>1.1.1.1</code>, because the destination IP is not itself.</li><li>Just before the packet leaves, an SNAT rule in the <code>POSTROUTING</code> chain is matched, so Netfilter rewrites the source IP to <code>2.2.2.2</code>. The destination IP is unchanged, still <code>1.1.1.1</code>.</li><li><code>1.1.1.1</code> receives a packet from <code>2.2.2.2</code> and replies to this address.</li><li>Gateway at <code>2.2.2.2</code> receives a reply and magically(TM) knows that this connection has undergone SNAT, so the reply should be forwarded to <code>192.168.160.2</code>.</li><li>Gateway rewrites the destination IP address to <code>192.168.160.2</code> and forwards the packet. Source IP is unchanged, still <code>2.2.2.2</code>. This technically is a DNAT (we will cover DNAT later) that automatically comes with the SNAT rule. We will not see this rule, but this is what Linux does under the hood to make SNAT work.</li><li>Server receives the response with source IP <code>2.2.2.2</code> and destination IP <code>192.168.160.2</code>.</li></ol><p>For the magic part, SNAT relies on conntrack (it&#39;s you again!), Linux&#39;s connection tracking module, to look up the correct destination addresses for incoming reply packets.</p><p>Enough talk. Let&#39;s get some hands-on with SNAT. This command will do the work for us:</p><pre><code>gateway# iptables -t nat -A POSTROUTING -o venet0 -j SNAT --to-source 2.2.2.2</code></pre><blockquote>My Gateway is an OpenVZ VPS, so the network interface is <code>venet0</code>. Yours might be different. You can get your physical link interface name using the command <code>ip a</code> and look for your public IP address. The device to which your public IP address is attached should be put in this command.</blockquote><p>The output interface here must be specified, or packets sent through <code>wg0</code> will also be SNAT-ed, which leads to unwanted results we will explain later.</p><p>Writing SNAT rules is a little bit tedious since we have to manually specify the new source IP. Netfilter provides a special target called <code>MASQUERADE</code> to eliminate the need for this step. We can use this command instead:</p><pre><code>gateway# iptables -t nat -A POSTROUTING -o venet0 -j MASQUERADE</code></pre><p>If we use <code>MASQUERADE</code>, Netfilter will automatically determine the right source IP to use. Recall that SNAT happens on the <code>POSTROUTING</code> chain, when the routing decision has been made, so at this point Netfilter already knows the interface to use, and it will just grab the IP address attached to this interface. Most of the time, this logic fits our need, so we can just use <code>MASQUERADE</code> whenever we want to do a &#34;normal&#34; SNAT.</p><p>You should notice that now you can successfully ping external hosts through WireGuard. A packet capture at this point on Gateway might help you understand why things started to work:</p><p><img src="https://im.salty.fish/usr/uploads/2023/05/2588666666.png" alt="2023-05-17T02:14:59.png" title="2023-05-17T02:14:59.png"/></p><p>The orange marks are my public IP address. This result corresponds to our theoretical packet flow perfectly. Now take a small break - we have the basic WireGuard tunnel up and running!</p><h2>Selective Proxying: Advanced Routing Configuration</h2><p>In our currrent setup, all outbound traffic will be forwarded through our WireGuard tunnel, but this is not what I want. I only want outbound SMTP traffic to be tunneled.</p><p>If we want finer control over routing, we have to prevent WireGuard from creating the default routing rules. WireGuard offers the option to create its rules in a different routing table, such that you can define your own policy that dictates when to use the tunnel as an outbound proxy. To use this feature, we first add this line in <code>wg0.conf</code>, Section <code>Interface</code>:</p><pre><code>Table = wireguard</code></pre><blockquote>Remember to bring the <code>wg0</code> interface down and up again after editing the config file.</blockquote><p>Inside the Linux kernel, routing tables are represented with a numeric ID, however here we are using an English name to refer to a routing table. For this alias to resolve successfully, we have to define it first, in the file <code>/etc/iproute2/rt_tables</code>. The default content of this file should be</p><pre><code>#
# reserved values
#
255     local
254     main
253     default
0       unspec
#
# local
#
#1      inr.ruhep</code></pre><p>We can see 4 routing tables defined (technically 3, because <code>unspec</code> means &#34;all&#34;, and is not a real routing table). We have talked about them before. We will here define our own, by adding a line:</p><pre><code>25      wireguard</code></pre><p>The number is arbitrarily chosen. I use 25 because it is the port for SMTP. After we have defined this routing table alias and edited <code>wg0.conf</code>, we can restart the <code>wg0</code> interface. This time, if you check your public IP address by accessing an IP-echoing website (I use <code>curl icanhazip.com</code>), you will see Server&#39;s real upstream IP address instead of Gateway&#39;s. Now our outbound traffic no longer goes through WireGuard. Let&#39;s print the routing rule again:</p><pre><code>server$ ip rule
0:      from all lookup local
32766:  from all lookup main
32767:  from all lookup default
server$ ip route show table wireguard
default dev wg0 scope link</code></pre><p>Now, all WireGuard-related rules are gone. However, the routing table <code>wireguard</code> has been populated with a rule to direct traffic to the <code>wg0</code> interface. We can configure our routing policy to direct packets to this routing table if we want to route them via WireGuard.</p><p>Specifically, we want to route outgoing packets with TCP destination port 25 through the tunnel. The corresponding policy is:</p><pre><code>server# ip rule add ipproto tcp dport 25 lookup wireguard pref 2500</code></pre><p><code>pref</code> is the preference level of this rule. The smaller the value, the earlier this policy is applied. We just need to specify a value smaller than 32766. Here I picked 2500.</p><p>We can test the effect of this rule by trying to connect to Google&#39;s SMTP server:</p><pre><code>server$ nc smtp.gmail.com 25
220 smtp.gmail.com ESMTP t65-20020a814644000000b005569567aac1sm5144152ywa.106 - gsmtp</code></pre><p>Great! The connection is successfully established. However, this setup will eventually break even if it works at first glance. The problem is that since we removed the default routing policies, Server no longer knows how to correctly reach Gateway. It will eventually try to reach <code>192.168.160.1</code> through the physical NIC, which of course will not work. However, routing decisions are cached, so the first few packets will hit the cache and get routed correctly. To correct this situation, we have to tell Server that all traffic to <code>192.168.160.0/24</code> should be routed through <code>wg0</code>:</p><pre><code>server# ip route add 192.168.160.0/24 dev wg0</code></pre><blockquote>Tip: To flush the cache, run <code>ip route flush cache</code>. This way you will immediately see that routing over the WireGuard tunnel no longer works.</blockquote><p>There is one more caveat. An email server does not only connect to port 25 of other SMTP servers, but also listens on port 25 itself. This simple routing policy will make connections from other email servers to us fail, because they will be directed to the <code>wireguard</code> routing table and routed away from us. Thus, we need to be more specific and only route SMTP traffic that actually come from within us. For example, I limited the policy to packets from the interface <code>br-mailcow</code> (yes I use Mailcow):</p><pre><code>server# ip rule add ipproto tcp dport 25 iif br-mailcow lookup wireguard pref 2500</code></pre><h3>IPv6</h3><p>However, when we use <code>openssl</code> to test, the connection fails.</p><pre><code>server$ openssl s_client -connect smtp.google.com:25 -starttls smtp
(no output)</code></pre><p>Again, I did some packet capturing and found this:</p><p><img src="https://im.salty.fish/usr/uploads/2023/05/2793219590.png" alt="2023-05-17T02:16:08.png" title="2023-05-17T02:16:08.png"/></p><p><code>openssl</code> attempted an IPv6 connection, which did not get routed over our WireGuard tunnel because we did not configure IPv6 at all. <code>nc</code> did not connect over IPv6 because it is not supported...</p><p>We can choose to disable IPv6 and go with IPv4 only, but here I&#39;ll configure IPv6 as well. To enable IPv6, we just need to assign IPv6 addresses to both endpoints.  We will be using the local IPv6 addresses <code>fc00::/7</code> for routing inside our WireGuard network. For example, if we use the subnet <code>fc00:0:0:160::/64</code>, this can be the new <code>Address</code> config on Server:</p><pre><code>Address = 192.168.160.2, fc00:0:0:160::2</code></pre><p>Don&#39;t forget to update <code>AllowedIPs</code> in the <code>Peer</code> section! On Server, we add <code>::0/0</code> to allow routing all IPv6 addresses, just like what we did for IPv4. On Gateway, we add Server&#39;s IP <code>/128</code>.</p><p>Apart from this, everything we did for IPv4 needs to be done again for IPv6, because they are handled completely separately. First, to enable forwarding for IPv6, se use the <code>sysctl</code> config item <code>net.ipv6.conf.all.forwarding = 1</code>. We also want to set the default policy for the <code>FORWARD</code> chain to <code>DROP</code> for IPv6 using <code>ip6tables</code>, and allow forwarding to / from Server:</p><pre><code>gateway# ip6tables -A FORWARD -i wg0 -j ACCEPT
gateway# ip6tables -A FORWARD -o wg0 -j ACCEPT</code></pre><p>Next, we need to configure routing for IPv6 as well. Don&#39;t forget to add the port 25 routing policy to the IPv6 policy list.</p><pre><code>server# ip -6 route add fc00:0:0:160::/64 dev wg0
server# ip -6 rule add ipproto tcp dport 25 lookup wireguard pref 2500</code></pre><p>Next, we need to add the SNAT configuration, a.k.a. the <code>MASQUERADE</code> rule on Gateway:</p><pre><code>gateway# ip6tables -t nat -A POSTROUTING -o venet0 -j MASQUERADE</code></pre><p>Now we can reinitialize the interfaces on both ends and test it out:</p><pre><code>server$ ping6 fc00:0:0:160::1
PING fc00:0:0:160::1(fc00:0:0:160::1) 56 data bytes
64 bytes from fc00:0:0:160::1: icmp_seq=1 ttl=64 time=61.5 ms</code></pre><p>And now <code>openssl</code> should be able to connect:</p><pre><code>server$ openssl s_client -connect smtp.google.com:25 -starttls smtp
CONNECTED(00000003)
depth=2 C = US, O = Google Trust Services LLC, CN = GTS Root R1
verify return:1
...</code></pre><h3>The Mismatching MTU: a Mysterious Issue with Docker</h3><p>Now that outbound SMTP is routed through WireGuard normally, it&#39;s high time that we test the more real scenario: connecting from Docker containers. Let&#39;s bring up a simple Arch Linux container (because I <strong>love</strong> Arch so much) and install <code>openssl</code>.</p><pre><code>server# docker run -it archlinux:latest bash
container# pacman -Sy openssl</code></pre><p>I did the testing with several popular email providers. Gmail works fine, but we have some trouble with iCloud. Sometimes it works just fine, but sometimes this happens:</p><pre><code>container# openssl s_client -connect mx02.mail.icloud.com:25 -starttls smtp
CONNECTED(00000003)
*no further output*</code></pre><p>We are stuck with no output, i.e. the TLS handshake does not finish. However, this problem never happens if we directly initiate the connection on Server, outside Docker containers.</p><p>Let&#39;s again invite our favorite <code>tcpdump</code> and Wireshark to investigate the issue for us. This is what we get on Server:</p><p><img src="https://im.salty.fish/usr/uploads/2023/05/4067180799.png" alt="2023-05-17T02:16:29.png" title="2023-05-17T02:16:29.png"/></p><blockquote><code>172.17.0.2</code> is the container&#39;s IP assigned by Docker. <code>17.42.251.62</code> is Apple&#39;s SMTP server.</blockquote><p>The initial SMTP communication is fine, but after we send the Client Hello, we never get a Server Hello back. We get some broken packets, but they do not form a valid Server Hello, so the TLS handshake is stalled. We need to capture some packets on Gateway to investigate further:</p><p><img src="https://im.salty.fish/usr/uploads/2023/05/1906077288.png" alt="2023-05-17T02:16:55.png" title="2023-05-17T02:16:55.png"/></p><blockquote>Redacted is Gateway&#39;s public IP.</blockquote><p>Here is the story we can read from the packet log. Everything before the TLS handshake were fine. Server sent Apple a Client Hello, and Apple replied with a Server Hello. However, rather than forwarding the Server Hello along, Gateway chose to reject it with an ICMP message <code>Destination unreachable (Fragmentation needed)</code>. This ICMP control message means that the packet sent was too large for the recipient to handle. Thus, Gateway is saying: &#34;I cannot process this packet. Please break it down into smaller fragments&#34;. Gateway expected that Apple would then resend the same content with several smaller packets, and it indeed did. This process actually has a name: <em>Path MTU Discovery</em>. </p><p>Before I explain further, I shall mention some background knowledge. The link layer imposes a restriction: that all packets transmitted must fit within a certain size, called the <em>MTU</em>, or <em>Maximum Transmission Unit</em>. If an interface receives a packet larger than this size, it will break this packet down into smaller ones, and instruct the recipient to later reconstruct the packet before presenting it to higher layers.</p><p>However, Apple&#39;s Server Hello packet comes with a special IP flag &#34;Don&#39;t fragment&#34; (DF):</p><p><img src="https://im.salty.fish/usr/uploads/2023/05/3851128485.png" alt="2023-05-17T02:17:11.png" title="2023-05-17T02:17:11.png"/></p><p>This explicitly tells all routers that this packet should never be fragmented. If any router wants to fragment the packet, it should abort and reply to the server an ICMP &#34;Fragmentation needed&#34; message. Thus, this is what Gateway did.</p><p>The real story is even more complicated than this. On top of the network layer (IP), there is a transport layer (TCP) before we reach the application layer (SMTPS). TCP also provides a similar functionality, called <em>segmentation</em>. TLS Server Hello messages are inherently large because the server&#39;s certificate will be sent there. The size of a certificate is usually far beyond common MTU values, so some sort of fragmentation must happen. I have never been able to understand why a DF flag is always set on TLS packets, but it seems that some people believe path MTU discovery is good for performance. Rather than letting IP fragmentation happen, people seem to prefer either PMTUD or TCP segmentation, because TCP segmentation can utilize <em>TCP Segmentation Offloading</em>, a hardware feature present on most modern network adapters.</p><blockquote>I am not in any sense sure about things I said in this paragraph, as I have not been able to find any solid reference material about this. Please enlighten me if you do.</blockquote><p>If a TCP/IP packet is too large to be transmitted, before dropping it, a router would first try segmenting it on the TCP level. The segmentation size that will be used if TCP segmentation was to happen will be determined by subtracting the IP and TCP headers&#39; size from the MTU. This value is called the <em>Maximum Segment Size (MSS)</em> and communicated in the TCP handshake. We can actually read it from our packet log. If we inspect the TCP SYN packet, this value can be found in the Options section:</p><p><img src="https://im.salty.fish/usr/uploads/2023/05/1525960130.png" alt="2023-05-17T02:17:24.png" title="2023-05-17T02:17:24.png"/></p><p>As we see, the MSS value used was 1460. This value originated from whomever initiated the TCP session. It took the MTU of the outbound interface used and subtracted 40, 20 of which is for the IP header and 20 for the TCP header. Note that TCP headers can get up to 60 bytes long, but in reality they are almost always 20 bytes because the rest 40 bytes are reserved for options, which are not used outside the handshake.</p><p>I am again unsure about how the two fallback features (PMTUD and TCP segmentation) work together, but my theory is:</p><ol><li>Server sends TCP SYN with MSS equals 1460, via Gateway.</li><li>Apple attempts PMTUD by sending a 2498B Server Hello (Packet #52) with the DF tag.</li><li>Gateway receives the packet and finds its size larger than <code>wg0</code>&#39;s MTU.</li><li>Gateway attempts IP fragmentation but aborts because of the DF tag.</li><li>Gateway attempts TCP segmentation by dividing the packet into 1500B TCP segments. That is, 1460B (MSS) plus the headers&#39; size 40B.</li><li>Gateway notices that 1500B still exceeds <code>wg0</code>&#39;s MTU.</li><li>The packet is discarded and an ICMP Fragmentation needed (Packet #53) is sent back to Apple.</li><li>Apple attempts TCP segmentation on its end, by resending the Server Hello in several segments. This corresponds to Packet #55, #66 and #68 we see in the log. Actually packet #68&#39;s TCP payload is the same as #52, the initial Server Hello. The length of #55, #66 and #68&#39;s TCP payload add up to that of #52.</li><li>Gateway receives the 1500B segments and repeats step 3 through 7.</li><li>Apple repeats step 8, and Gateway repeats 3-7, and so on and so forth. The TLS handshake never finishes.</li></ol><blockquote>Wireshark shows 1520B and 2968B as the packets&#39; size. This is because the link layer header (20 Bytes long) is included. However, MTU as a link layer concept does not include the link layer header.</blockquote><p>Knowing the reason behind the failure, we can proceed to fixing the issue. Let&#39;s check the current value of <code>wg0</code>&#39;s MTU:</p><pre><code>gateway$ ip l
(other interfaces)
9: wg0: &lt;POINTOPOINT,MULTICAST,NOARP,UP,LOWER_UP&gt; mtu 1420 qdisc mq state UNKNOWN mode DEFAULT group default qlen 500
    link/none</code></pre><p>Aha! The default MTU set by WireGuard is 1420, smaller than 1500 implied by the MSS value 1460. But why would such a mismatch exist? Recall that MSS was set according to the MTU of the first network interface the SYN will go through, so if we connect directly from Server, it will be set to 1380 because the first network interface is <code>wg0</code> with MTU 1420, and we can actually verify this:</p><pre><code>server$ ip l
(other interfaces)
3: docker0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc noqueue state DOWN mode DEFAULT group default
    link/ether 02:42:51:32:04:c7 brd ff:ff:ff:ff:ff:ff
4: wg0: &lt;POINTOPOINT,NOARP,UP,LOWER_UP&gt; mtu 1420 qdisc noqueue state UNKNOWN mode DEFAULT group default qlen 1000
    link/none</code></pre><p><img src="https://im.salty.fish/usr/uploads/2023/05/2785479006.png" alt="2023-05-17T02:17:45.png" title="2023-05-17T02:17:45.png"/></p><p>However, when we connect from a Docker container with bridged network, the first network interface a packet encounters will be Docker&#39;s bridge instead! And this bridge has a different (higher) MTU 1500. This explains why the MSS would have been set to 1460, causing the response not to go through <code>wg0</code>.</p><p>Interestingly, Gmail takes a different approach. Its Server Hello does not have the DF tag set, so Gateway uses IP fragmentation to break the packet down, and TCP segmentation is not involved. Thus, the mismatch does not affect connections made with Gmail.</p><p>Now that we see where the problem came from, there several approaches to resolve it. We can just need to make Gateway <code>wg0</code>&#39;s MTU match Server <code>docker0</code>&#39;s, by setting <code>MTU = 1500</code> in <code>wg0.conf</code>, Section <code>Interface</code>. But is this our best option? If you actually go with it, you will notice that your network speed is severely negatively affected! According to my <code>iperf3</code> test, if I connect directly over the internet, the speed between Server and Gateway can reach up to 70Mbps, and has an average performance of 50Mbps. However, the WireGuard tunnel works only at about 20Mbps!</p><p>Let&#39;s take a small step back because there is one question we didn&#39;t quite address: Why does WireGuard set the default MTU to 1420 while most modern OSes default to 1500? There is actually a pretty good reason. WireGuard tunnels network layer traffic, but works on the transport layer (UDP) itself. Each packet WireGuard tunnels is a complete IP packet, and WireGuard itself has some overhead. Specifically, WireGuard adds its own header, a 8-byte UDP header and a 20-byte IPv4 header to every IP packet it tunnels. If IPv6 is used, the IP header gets 20 bytes larger. This makes the packet size grow by up to 80 bytes - exactly the difference between the default MTU of physical interfaces and WireGuard&#39;s interfaces. We can verify this from a packet log captured during an <code>iperf3</code> speed test:</p><p><img src="https://im.salty.fish/usr/uploads/2023/05/3832779178.png" alt="2023-05-17T02:17:58.png" title="2023-05-17T02:17:58.png"/></p><blockquote>I used IPv4 for the test, so the difference is only 60 bytes.</blockquote><p>The reason becomes clear. If WireGuard uses a standard MTU, under heavy load, all packets sent through the tunnel will need to be fragmented because eventually WireGuard needs to send the packets plus their additional headers over the physical tunnel. After adding the overhead bytes, packets get up to 1500+80 bytes long while the physical interface only allows packets within 1500 bytes to pass. The fragmentation here is extremely inefficient because the second fragment will always be only 60 or 80 bytes long:</p><p><img src="https://im.salty.fish/usr/uploads/2023/05/2343999241.png" alt="2023-05-17T02:18:08.png" title="2023-05-17T02:18:08.png"/></p><p>A 1500B (shown as 1520B because, again, the 20B Ethernet header is included) packet becomes 1540B with the WireGuard overhead (without the IP header). The first IP fragment can only be 1500B long, of which 20B is the IP header, so only 1480B of the packet will be delivered. The remaining 60B will be sent in the second fragment. Taking into consideration the 20B IP header, the second fragment is 80B long, exactly matching our observation of 100B Ethernet packets.</p><p>However, if the WireGuard interface has an MTU of 1420, <code>wg0</code> will deal with significantly less oversized packets because the TCP MSS will (hopefully) be set to 1380. This way, wrapped WireGuard packets will never exceed 1500B, so never need to be fragmented.</p><p>Thus, it is not a good idea to increase WireGuard&#39;s default MTU. The better solution is to resolve the mismatch between the TCP MSS and our Path MTU (the smallest MTU along the network path), rather than making MTUs agree. Luckily, <code>iptables</code> provides an interface for us to tamper with MSS: the target <code>TCPMSS</code>. Here is the most common usage:</p><pre><code>server# iptables -t mangle -A POSTROUTING -p tcp --tcp-flags SYN SYN -o wg0 -j TCPMSS --clamp-mss-to-pmtu</code></pre><blockquote>OpenWrt seems to use <code>--tcp-flags SYN,RST SYN</code>. I do not understand why <code>RST</code> needs to be taken into consideration here. Please explain to me if you know why.</blockquote><p>The <code>TCPMSS</code> target can set a specific MSS, but just like SNAT, we most of the time don&#39;t want to bother looking up the correct value, and just want Netfilter to be &#34;smart&#34;. Thus, there comes <code>--clamp-mss-to-pmtu</code> that does exactly what we want: setting the MSS according to the PMTU. <code>--tcp-flags SYN SYN</code> means that the <code>SYN</code> flag should be set for a packet to match this rule. This is because the MSS is only negotiated once at the very beginning of the handshake, hence we only need to modify it once.</p><p>Cheers! We have successfully set up our WireGuard tunnel and configured outbound SMTP traffic to go through it.</p><h2>Persisting Our Changes</h2><p>To summarize, we made these changes to the routing table and firewall:</p><ul><li>We added a routing rule in the default routing table: <code>192.168.160.0/24 dev wg0</code> and did the same for IPv6.</li><li>We added routing policies to Server to route all outbound SMTP traffic through the tunnel.</li><li>We added <code>MASQUERADE</code> rules to Gateway to enable proper SNAT.</li><li>We added some rules to Gateway&#39;s <code>filter</code> table to allow forwarding packets to / from Server.</li></ul><p>These changes will not be preserved across reboots because the firewall and routing rules are not stored in the disk. Note that this change <strong>will</strong> be preserved:</p><ul><li>We added a routing table in <code>/etc/iproute2/rt_tables</code>.</li></ul><p>And these changes will be applied when <code>wg0</code> is active:</p><ul><li>We specified <code>wg0</code>&#39;s MTU in its configuration file.</li><li>We told WireGuard to add its routing rule in our <code>wireguard</code> table.</li></ul><p>We actually don&#39;t really want to have WireGuard-related routing rules in effect at all times. Rather, we would like them to function also only when <code>wg0</code> is active. Luckily, <code>wg-quick</code> allows us to run commands when an interface is brought up / down. Add this to the <code>Interface</code> section on Server:</p><pre><code># specify how to access the peer (through wg0)
PostUp = ip route add 192.168.160.0/24 dev wg0
PostUp = ip -6 route add fc00:0:0:160::/64 dev wg0
# PostDown is not needed because the rules will be automatically removed when wg0 goes down

# fix MSS issue
PostUp = iptables -t mangle -A POSTROUTING -p tcp --tcp-flags SYN SYN -o wg0 -j TCPMSS --clamp-mss-to-pmtu
PostDown = iptables -t mangle -D POSTROUTING -p tcp --tcp-flags SYN SYN -o wg0 -j TCPMSS --clamp-mss-to-pmtu
PostUp = ip6tables -t mangle -A POSTROUTING -p tcp --tcp-flags SYN SYN -o wg0 -j TCPMSS --clamp-mss-to-pmtu
PostDown = ip6tables -t mangle -D POSTROUTING -p tcp --tcp-flags SYN SYN -o wg0 -j TCPMSS --clamp-mss-to-pmtu

# let all outbound traffic to port 25 go through wireguard
PostUp = ip rule add ipproto tcp dport 25 iif br-mailcow lookup wireguard pref 2500
PostDown = ip rule del pref 2500
PostUp = ip -6 rule add ipproto tcp dport 25 iif br-mailcow lookup wireguard pref 2500
PostDown = ip -6 rule del pref 2500</code></pre><p>And on Gateway:</p><pre><code># allow forwarding to / from wg0
PostUp = iptables -A FORWARD -o wg0 -j ACCEPT
PostDown = iptables -D FORWARD -o wg0 -j ACCEPT
PostUp = iptables -A FORWARD -i wg0 -j ACCEPT
PostDown = iptables -D FORWARD -i wg0 -j ACCEPT
PostUp = ip6tables -A FORWARD -o wg0 -j ACCEPT
PostDown = ip6tables -D FORWARD -o wg0 -j ACCEPT
PostUp = ip6tables -A FORWARD -i wg0 -j ACCEPT
PostDown = ip6tables -D FORWARD -i wg0 -j ACCEPT

# do snat for forwarded traffic
PostUp = iptables -t nat -A POSTROUTING -o venet0 -j MASQUERADE
PostDown = iptables -t nat -D POSTROUTING -o venet0 -j MASQUERADE
PostUp = ip6tables -t nat -A POSTROUTING -o venet0 -j MASQUERADE
PostDown = ip6tables -t nat -D POSTROUTING -o venet0 -j MASQUERADE</code></pre><p>Don&#39;t forget to clear our manual changes before restarting WireGuard to test it out.</p><h2>DNAT</h2><p>The other purpose of this WireGuard setup is to publish network services through Gateway&#39;s public IP address. In a usual network setup, this is achieved through <em>port forwarding</em>. However, since we are not using a specialized router OS, we will have to implement port forwarding on our own. Luckily this isn&#39;t too complicated a concept. The technical term for port forwarding is <em>DNAT</em>, or Destination Network Address Translation. Contrary to SNAT which rewrites the source IP address, DNAT rewrites the destination IP address. Optionally, it can change the destination port as well.</p><p>To get started, let&#39;s consider an example where we want to forward port 443, the standard HTTPS port. While SNAT happens in the <code>POSTROUTING</code> phase, DNAT takes place during <code>PREROUTING</code>. Thus, a DNAT rule looks like this:</p><pre><code>gateway# iptables -t nat -A PREROUTING ! -i wg0 -p tcp --dport 443 -j DNAT --to-destination 192.168.160.2
gateway# ip6tables -t nat -A PREROUTING ! -i wg0 -p tcp --dport 443 -j DNAT --to-destination fc00:0:0:160::2</code></pre><p><code>! -i wg0</code> is here to prevent redirecting traffic from Server back to Server. If this is not set, Server basically can no longer access any HTTPS website through the tunnel. Although we do not (yet) use this, we do not want to leave potential issues that in the future come back to bother us.</p><h3>The Routing Dilemma: to SNAT or not to SNAT</h3><p>This again looks intuitive but does not work. You will notice that connections to TCP port 443 of Gateway&#39;s public IP fail. Again, let&#39;s use <code>tcpdump</code> to diagnose this issue. We will be using <code>netcat</code> instead of a real HTTPS server for simplicity. We first listen on port 443 on Server:</p><pre><code>server# nc -l -v -p 443</code></pre><p>We then connect to Gateway&#39;s port 443 from an internet host (can just be your laptop). This is what we see from Server&#39;s packet log:</p><p><img src="https://im.salty.fish/usr/uploads/2023/05/2643721700.png" alt="2023-05-17T02:18:30.png" title="2023-05-17T02:18:30.png"/></p><blockquote>Redacted is my laptop&#39;s public IP address.</blockquote><p>We can rest assured that our DNAT is already working correctly because the SYN successfully reached Server, but the SYN-ACK does not seem to be correctly delivered. The other side sent the same SYN again, while Server keeps replying with undelivered SYN-ACKs. Indeed, if we inspect the packet log on Gateway, there is no SYN-ACK sent back:</p><p><img src="https://im.salty.fish/usr/uploads/2023/05/1059454389.png" alt="2023-05-17T02:18:48.png" title="2023-05-17T02:18:48.png"/></p><p>Why was the SYN-ACK not delivered? If we click on the SYN-ACK to inspect its details, we can notice this in the link layer:</p><p><img src="https://im.salty.fish/usr/uploads/2023/05/3946039747.png" alt="2023-05-17T02:19:01.png" title="2023-05-17T02:19:01.png"/></p><p>Note that this packet has a source MAC address set, and if we list all our interfaces&#39; MAC addresses, this one actually matches that of our physical network adapter. The link layer protocol is shown as &#34;Linux cooked capture v2&#34; because I used <code>-i any</code> - if I had listened on <code>wg0</code>, this packet would not be there at all. However, this packet will be captured if we listen on the physical interface.</p><p>Apparently, we have some routing issues here, leading to the SYN-ACK being routed to the wrong interface. To explain why this happens, we first need to know that by default, routing decisions are made solely according to the packet&#39;s destination IP address. A SYN-ACK is not in any sense different from a SYN sent from Server. Since we configured all packets but those targeted at TCP port 25 to go through the physical interface, the SYN-ACK will go there as well.</p><p>Adding SNAT to Gateway&#39;s <code>wg0</code> interface would make the TCP connection succeed:</p><pre><code>gateway# iptables -t nat -A POSTROUTING -o wg0 -j MASQUERADE</code></pre><p>But this is what we intentionally avoided when we were configuring SNAT - we only did SNAT for the physical interface for a reason!</p><pre><code>server# nc -l -v -p 443
listening on [any] 443 ...
connect to [192.168.160.2] from (UNKNOWN) [192.168.160.1] &lt;some random port number&gt;</code></pre><p>SNAT rewrites the source IP address, so Server will no longer know where the packet originally came from. This defeats our very purpose - to preserve source IP address information. Hence this is <strong>not</strong> what we&#39;ll do - we have to figure out a way to make the return packets go through <code>wg0</code> without using SNAT on Gateway.</p><h3>Making Routing Smarter with Conntrack</h3><p>Let&#39;s simplify the situation by ignoring Docker first and testing on Server directly. Say we have a service that listens on <code>192.168.160.2</code>. When we connect from <code>1.2.3.4</code> (a dummy internet host), the reply packet will have source IP <code>192.168.160.2</code> and destination IP <code>1.2.3.4</code>. Even though routing by default only cares about the destination, we can add a policy to let the router look up the <code>wireguard</code> table for all packets <strong>originating</strong> from <code>192.168.160.2</code>:</p><pre><code>server# ip rule add from 192.168.160.2 lookup wireguard</code></pre><p>To test it out, we can try to connect to an internet SMTP server using <code>netcat</code>:</p><pre><code>server$ nc -s 192.168.160.2 smtp.gmail.com
220 smtp.gmail.com ESMTP y130-20020a817d88000000b0055a7c2375dfsm36356ywc.101 - gsmtp</code></pre><p>By using <code>-s</code>, we tell <code>netcat</code> explicitly to use <code>192.168.160.2</code> as the source IP address. This means the connection was tunneled as expected because I configured the outbound SMTP routing policy for <code>docker0</code> packets only.</p><p>While replies sent by the service listening on <code>192.168.160.2</code> will now use the <code>wireguard</code> table, connections initiated by Server do not specify <code>192.168.160.2</code> as the source IP address, so will not be routed through WG. This is because such packets, unlike responses sent from a listening socket, do not have the source IP field set until the routing decision has been made. Just before the packet leaves the system, the IP address of the interface responsible for delivering this packet will be assigned as its source IP address. This happens after the routing phase.</p><p>If we test at this point, we should already be able to receive incoming TCP connections on port 443, and we <strong>will</strong> see the real original source IP address! But we are not done yet because the use of Docker bridge networks complicates things. Docker&#39;s port forwarding mechanism (<code>-p</code>) basically turns Server into a gateway, doing DNAT on incoming packets and SNAT on outgoing packets.</p><p>Let&#39;s spin up a Docker container and test from there. This time, we will add a port forwarding from Server&#39;s port 443 to the container&#39;s port 443:</p><pre><code>server# docker run -it -p 443:443 archlinux bash</code></pre><p>And we listen on port 443 inside the container before trying to connect from our laptop:</p><pre><code>container# nc -l -v -p 443</code></pre><p>Oops - the connection cannot be established. It&#39;s time for some more Wireshark:</p><p><img src="https://im.salty.fish/usr/uploads/2023/05/236563733.png" alt="2023-05-17T02:19:21.png" title="2023-05-17T02:19:21.png"/></p><p>So the reply packets are indeed SNAT-ed and have the source ip <code>192.168.160.2</code> (see packet #17, #23, etc.) but they are never delivered correctly, resulting in endless retransmission. Our routing policy stopped working! Why?</p><p>Again, let me remind you that SNAT can only happen on the <code>POSTROUTING</code> chain. This means SNAT was done <strong>after</strong> the routing decision has been made. When the router saw the packet, it had the source IP <code>172.17.0.2</code>, hence not matching our policy. The router routed it to the physical interface instead of the desired <code>wg0</code>. When Docker&#39;s SNAT rule rewrites the destination IP, everything is already too late.</p><p>It is impossible to make SNAT-ed packets go to the router again. Does it mean we are stranded?</p><p>Let&#39;s take a step back and write down what we want: For any packet sent, if it is a part of a connection originally sent to <code>192.168.160.2</code>, route it through <code>wg0</code>.</p><p>The core problem is the ability to track a connection - and this is exactly what <em>conntrack</em> does! We have mentioned it several times, and now it&#39;s time to take a serious look at it. Remember the second part of SNAT? For SNAT to function, there has to be an accompanying DNAT process to rewrite the destination IP of reply packets. How on earth does Linux know what new destination IP to use?</p><p>Conntrack is a table in Netfilter. Each time a network connection is initiated, Linux adds an entry for it in the conntrack table. This table can be read from <code>/proc/net/nf_conntrack</code>:</p><pre><code>server# cat /proc/net/nf_conntrack
*irrelevant entries omitted*
ipv4     2 tcp      6 55 SYN_RECV src=&lt;my laptop&#39;s public IP&gt; dst=192.168.160.2 sport=45610 dport=443 src=172.17.0.2 dst=&lt;my laptop&#39;s public IP&gt; sport=443 dport=45610 mark=0 zone=0 use=2</code></pre><p>This connection is in the <code>SYN_RECV</code> state, meaning that the SYN has been received and the system should be trying to reach back with a SYN-ACK, but no ACK has been seen. This corresponds to our observation. Following <code>SYN_RECV</code> is the connection&#39;s original source / destination IP and port information. When a subsequent SYN-ACK is seen by conntrack, the SYN-ACK&#39;s source / destination IP and port information is appended to the entry.</p><p>Netfilter can consult this table for subsequent packets in this TCP stream. SNAT is the most common use case. SNAT&#39;s reverse process picks the new source IP by looking up the original destination IP in the conntrack table.</p><p>We had wanted to utilize SNAT&#39;s conntrack &#34;magic&#34; to identify reply packets sent from the container before routing. As SNAT won&#39;t do us this favor, why not just implement its magic by ourselves?</p><p>Good news is that there happens to be an <code>iptables</code> extension for <code>conntrack</code> and it exposes the interface <code>--ctorigdst</code>. This is exactly what we want: to match packets with a specific original destination IP in the conntrack table:</p><pre><code>server# iptables -t mangle -A PREROUTING -m conntrack --ctorigdst 192.168.160.2 --ctstate ESTABLISHED,RELATED -j MARK --set-mark 0xa</code></pre><p>The <code>PREROUTING</code> chain in the <code>mangle</code> table is consulted before that in the <code>nat</code> table but after the packet goes through conntrack. It allows us to set <em>firewall marks</em> to packets before NAT-ing and routing them. Firewall marks, or fwmarks, are tags that Linux uses internally to track packets so that it can do specific things to these packets later. They are very useful when we want the router and the firewall to collaborate. Note that a fwmark is a <strong>local</strong> concept and never leaves the system because it is not written into the packet.</p><p>Our rule will identify all packets that belong to a connection originally sent to <code>192.168.160.2</code> or a connection related, and mark them with <code>0xa</code>. Later, the mark will be seen by the router, and we can ask the router to route packets with this particular mark:</p><pre><code>server# ip rule add fwmark 0xa lookup wireguard</code></pre><p>Now both the SYN and SYN-ACK should be delivered correctly, but we missed something in our rule, and that results in the ACK not being delivered properly. The ACK also goes through the <code>PREROUTING</code> chain in the <code>mangle</code> table, and it will match our rule, get the <code>0xa</code> mark, then be thrown to the WireGuard tunnel. It is then discarded because its source IP - the client&#39;s public IP, is not in <code>AllowedIPs</code>.</p><p>We really only want this rule to work one-way, so we will modify it slightly by adding <code>! -d 192.168.0.2</code>. Now inbound packets will no longer match this marking rule while outbound packets still match.</p><p>If you <strong>only</strong> use Docker containers to host network services, you can go ahead and remove the <code>from 192.168.160.2 lookup wireguard</code> policy because it is not at all useful... However, do keep it if you expect to host any service directly on Server, because locally generated packets do not go through <code>PREROUTING</code> (see the Netfilter diagram). However, they do go through <code>OUTPUT</code>. Thus, another solution would be to remove the policy and add the marking rule to <code>OUTPUT</code>.</p><h3>NAT Loopback (NAT Reflection)</h3><p>Our setup is now almost perfect, except for one small problem - a very well-known problem in networking. For various reasons, you might want Server to be able to access itself through its public IP address. While we can reach Server&#39;s network services by Gateway&#39;s public IP from the internet, reaching it from within the WireGuard internal network is another completely different situation. Here is a comparison (suppose Gateway has public IP <code>2.2.2.2</code>):</p><table><thead><tr><th>Step</th><th>From Internet Host <code>3.3.3.3</code></th><th>From Server</th></tr></thead><tbody><tr><td>1</td><td><code>3.3.3.3</code> sends packet with source IP <code>3.3.3.3</code> and destination IP <code>2.2.2.2</code>.</td><td>Server (connector) sends packet with destination IP <code>2.2.2.2</code>. Packet is routed to <code>wg0</code> according to some rule.</td></tr><tr><td>2</td><td> </td><td>Server assigns source IP <code>192.168.160.2</code> before sending the packet through <code>wg0</code> to <code>192.168.160.1</code> to forward.</td></tr><tr><td>3</td><td>Packet arrives at <code>venet0</code> on Gateway, with source IP <code>1.2.3.4</code> and destination IP <code>2.2.2.2</code>.</td><td>Packet arrives at <code>wg0</code> on Gateway, with source IP <code>192.168.160.2</code> and destination IP <code>2.2.2.2</code>.</td></tr><tr><td>4</td><td>Packet matches our DNAT rule. Destination IP is changed to <code>192.168.160.2</code>.</td><td>Packet does not match our DNAT rule because of the <code>! -i wg0</code>. Destination IP is unchanged.</td></tr><tr><td>5</td><td>Because routing happens after DNAT, Gateway&#39;s router sees the modified destination IP address and forwards the packet.</td><td>Gateway&#39;s router sees that the packet was sent to Gateway, and delivers the packet.</td></tr><tr><td>6</td><td>Gateway sends the packet with source IP <code>3.3.3.3</code> and destination IP <code>192.168.160.2</code> through <code>wg0</code>.</td><td>Gateway does not have a socket listening on the specified port, so connection is refused.</td></tr></tbody></table><p>Apparently, we need to add another rule to match packets sent from Server as well, and apply DNAT accordingly:</p><pre><code>gateway# iptables -t nat -A PREROUTING -i wg0 -s 192.168.160.0/24 -d 2.2.2.2 -p tcp --dport 443 -j DNAT --to-destination 192.168.160.2</code></pre><p>However, it alone will not fix our problem. Let&#39;s continue to see what happens if we had applied this rule:</p><table><thead><tr><th>Step</th><th>From Internet Host <code>3.3.3.3</code></th><th>From Server</th></tr></thead><tbody><tr><td>4</td><td>Packet matches our DNAT rule. Destination IP is changed to <code>192.168.160.2</code>.</td><td>Packet matches our DNAT rule. Destination IP is changed to <code>192.168.160.2</code>.</td></tr><tr><td>5</td><td>Gateway&#39;s router forwards the packet.</td><td>Gateway&#39;s router forwards the packet.</td></tr><tr><td>6</td><td>Gateway sends the packet with source IP <code>3.3.3.3</code> and destination IP <code>192.168.160.2</code> through <code>wg0</code>.</td><td>Gateway sends the packet with source IP <code>192.168.160.2</code> and destination IP <code>192.168.160.2</code> through <code>wg0</code>.</td></tr><tr><td>7</td><td>Forwarded packet arrives at <code>wg0</code> on Server, with source IP <code>3.3.3.3</code> and destination IP <code>192.168.160.2</code>.</td><td>Forwarded packet arrives at <code>wg0</code> on Server, with source IP <code>192.168.160.2</code> and destination IP <code>192.168.160.2</code>.</td></tr><tr><td>8</td><td>Server (listener) replies with a packet with source IP <code>192.168.160.2</code> and destination IP <code>3.3.3.3</code>.</td><td>Server (listener) replies with a packet with source IP <code>192.168.160.2</code> and destination IP <code>192.168.160.2</code>. This is a packet for the local host, so it is delivered locally without going through WireGuard.</td></tr><tr><td>9</td><td><code>3.3.3.3</code> gets a well-formed reply.</td><td><code>192.168.160.2</code> (connector) gets an ill-formed reply with source IP <code>192.168.160.2</code> instead of the expected <code>2.2.2.2</code> (destination IP of the original packet).</td></tr></tbody></table><p>It might be a bit unclear how to fix this situation. The common fix is a very niche SNAT rule:</p><pre><code>gateway# iptables -t nat -A POSTROUTING -o wg0 -s 192.168.160.0/24 -d 192.168.160.2 -p tcp --dport 443 -j MASQUERADE</code></pre><p>This is a well-known trick called <em>NAT loopback</em>, a.k.a. <em>NAT hairpinning</em> or <em>NAT reflection</em>. You might notice that it actually goes back to SNAT-ing <code>wg0</code>&#39;s outbound traffic, but in a more restricted manner. For this reason, the solution is imperfect. However, we at least know that these connections come from the WireGuard LAN. If we assume the LAN is secure, this is much less of a security issue than SNAT-ing all outbound packets. I will accept the small flaw here. It <strong>might</strong> be possible to achieve perfect NAT loopback where source IP is preserved, but I did not dig into that. Please enlighten me if you know how to do that : )</p><p>Now I will explain how the trick works. It is a bit convoluted because <code>192.168.160.2</code> is now <strong>both</strong> server and client. I will call it Server when it acts as the server and Client otherwise.</p><p>For convenience, I made some changes here that shall not impact the overall process:</p><ul><li>I did the testing with port 25 (instead of 443) because I set up WireGuard tunneling for it.</li><li>I am using <code>nc -s 192.168.160.2</code> to make sure that outbound packets are tunneled. It does not make sense if you do not specify this source IP and use a routing policy to tunnel them anyway, because you ultimately need a valid source IP for Server to reach back to you. This is either your real public IP or your WireGuard IP. If you use your real public IP, the situation falls back to connecting from the internet, so NAT loopback is not needed. If you connect from within a Docker container, Docker&#39;s SNAT will rewrite the source IP so you will see similar results.</li></ul><ol><li>Client initiates connection to <code>2.2.2.2</code> by sending SYN (Client Packet #27).</li><li>Client Packet #27 is tunneled through WireGuard because it matches our outbound SMTP policy. It reaches Gateway on <code>wg0</code> and becomes Gateway Packet #15.</li><li>Gateway performs DNAT on the <code>PREROUTING</code> chain. Destination IP is changed to <code>192.168.160.2</code>.</li><li>Gateway performs SNAT  (our new rule!) on the <code>POSTROUTING</code> chain. Source IP is changed to <code>192.168.160.1</code>.</li><li>Gateway Packet #15 becomes #16 and is forwarded.</li><li>Gateway Packet #16 reaches Server on <code>wg0</code> and becomes Server Packet #31. From Server&#39;s perspective, it just got a SYN from Client.</li><li>Server replies with Server Packet #32. #32&#39;s IP header information is #31&#39;s swapped because it is a reply to #31.</li><li>Server Packet #32 is tunneled through WireGuard because it matches our conntrack rule.</li><li>Server Packet #32 reaches Gateway and becomes Gateway Packet #19.</li><li>From Gateway&#39;s perspective, it has done SNAT to the SYN (Gateway Packet #15 to #16) in step 4, and now it is getting a corresponding SYN-ACK, so it should do a DNAT to complete the SNAT. Gateway looks up the conntrack table and finds the original source IP <code>192.168.160.2</code>. Hence it rewrites Packet #19&#39;s destination IP to <code>192.168.160.2</code>. Note that this DNAT is done at the conntrack point, not <code>PREROUTING</code>.</li><li>Just like SNAT rules need accompanying DNATs, DNATs need a SNATs in the reverse direction as well (think about why!) Because Gateway has done DNAT to the SYN in step 3, it now rewrites Packet #19&#39;s source IP to the original destination IP of Packet #15, <code>2.2.2.2</code>. Similarly, this SNAT is done at the conntrack point.</li><li>Gateway Packet #19 becomes #20 and is forwarded. Because now the source IP is <code>2.2.2.2</code>, our SNAT rule is not matched.</li><li>Gateway Packet #20 reaches Client and becomes Client Packet #35. From Client&#39;s perspective, it just got Server&#39;s SYN-ACK.</li><li>Client sends an ACK to complete the TCP handshake. From Client&#39;s perspective, it is handshaking with <code>2.2.2.2</code>. From Server&#39;s perspective, it is handshaking with <code>192.168.160.1</code>.</li><li>The ACK reaches Server the same way as the SYN does (Client #36 - Gateway #23 - Gateway #24 - Server #41).</li><li>The TCP handshake is completed successfully. Subsequent packets follow the same pattern.</li></ol><p><img src="https://im.salty.fish/usr/uploads/2023/05/1757390061.png" alt="2023-05-17T02:19:49.png" title="2023-05-17T02:19:49.png"/></p><p><img src="https://im.salty.fish/usr/uploads/2023/05/4053202289.png" alt="2023-05-17T02:19:59.png" title="2023-05-17T02:19:59.png"/></p><h3>DNS Override</h3><p>Rather than the convoluted NAT loopback, you might want to address the problem from a different perspective. If you access Gateway through a domain name instead of a plain IP, you can override the DNS record on Server to point to itself. Note that there are also some nuances here, and this solution also has imperfections. For example, it does not work when you map a Gateway port to a Server port with a different port number.</p><h2>Conclusion &amp; The Complete Configuration</h2><p>Say congratulations to yourself! You reached the end of this note. Now you should have a working WireGuard virtual LAN that can tunnels traffic you specify and does port forwarding just like a real LAN. Hopefully you also learned something new about:</p><ul><li>Routing tables and policies</li><li>TCP/IP</li><li>IPv6</li><li>DNAT and SNAT</li><li>MTU</li><li>NAT loopback</li></ul><p>For your convenience, I am posting my complete WireGuard configuration files here. This is <code>/etc/wireguard/wg0.conf</code> on Gateway:</p><pre><code>[Interface]
PrivateKey = &lt;Gateway private key&gt;
Address = 192.168.160.1, fc00:0:0:160::1
ListenPort = 51820
MTU = 1500

# allow necessary forwarding
PostUp = iptables -A FORWARD -o wg0 -j ACCEPT
PostDown = iptables -D FORWARD -o wg0 -j ACCEPT
PostUp = iptables -A FORWARD -i wg0 -j ACCEPT
PostDown = iptables -D FORWARD -i wg0 -j ACCEPT
PostUp = ip6tables -A FORWARD -o wg0 -j ACCEPT
PostDown = ip6tables -D FORWARD -o wg0 -j ACCEPT
PostUp = ip6tables -A FORWARD -i wg0 -j ACCEPT
PostDown = ip6tables -D FORWARD -i wg0 -j ACCEPT

# snat for wireguard traffic
PostUp = iptables -t nat -A POSTROUTING -o venet0 -j MASQUERADE
PostDown = iptables -t nat -D POSTROUTING -o venet0 -j MASQUERADE
PostUp = ip6tables -t nat -A POSTROUTING -o venet0 -j MASQUERADE
PostDown = ip6tables -t nat -D POSTROUTING -o venet0 -j MASQUERADE

# dnat
PostUp = iptables -t nat -A PREROUTING ! -i wg0 -p tcp --dport 443 -j DNAT --to-destination 192.168.160.2
PostDown = iptables -t nat -D PREROUTING ! -i wg0 -p tcp --dport 443 -j DNAT --to-destination 192.168.160.2
PostUp = iptables -t nat -A PREROUTING -i wg0 -s 192.168.160.0/24 -d &lt;Gateway public IPv4&gt; -p tcp --dport 443 -j DNAT --to-destination 192.168.160.2
PostDown = iptables -t nat -D PREROUTING -i wg0 -s 192.168.160.0/24 -d &lt;Gateway public IPv4&gt; -p tcp --dport 443 -j DNAT --to-destination 192.168.160.2
PostUp = ip6tables -t nat -A PREROUTING ! -i wg0 -p tcp --dport 443 -j DNAT --to-destination fc00:0:0:160::2
PostDown = ip6tables -t nat -D PREROUTING ! -i wg0 -p tcp --dport 443 -j DNAT --to-destination fc00:0:0:160::2
PostUp = ip6tables -t nat -A PREROUTING -i wg0 -s fc00:0:0:160::/64 -d &lt;Gateway public IPv6&gt; -p tcp --dport 443 -j DNAT --to-destination fc00:0:0:160::2
PostDown = ip6tables -t nat -D PREROUTING -i wg0 -s fc00:0:0:160::/64 -d &lt;Gateway public IPv6&gt; -p tcp --dport 443 -j DNAT --to-destination fc00:0:0:160::2

# nat loopback - common
PostUp = iptables -t nat -A POSTROUTING -o wg0 -s 192.168.160.0/24 -d 192.168.160.2 -p tcp --dport 443 -j MASQUERADE
PostDown = iptables -t nat -A POSTROUTING -o wg0 -s 192.168.160.0/24 -d 192.168.160.2 -p tcp --dport 443 -j MASQUERADE
PostUp = ip6tables -t nat -A POSTROUTING -o wg0 -s fc00:0:0:160::/64 -d fc00:0:0:160::2 -p tcp --dport 443 -j MASQUERADE
PostDown = ip6tables -t nat -A POSTROUTING -o wg0 -s fc00:0:0:160::/64 -d fc00:0:0:160::2 -p tcp --dport 443 -j MASQUERADE

[Peer]
PublicKey = &lt;Server public key&gt;
PresharedKey = &lt;PSK&gt;
AllowedIPs = 192.168.160.2/32, fc00:0:0:160::2/128</code></pre><p>This is <code>/etc/wireguard/wg0.conf</code> on Server:</p><pre><code>[Interface]
PrivateKey = &lt;Server private key&gt;
Address = 192.168.160.2, fc00:0:0:160::2
Table = wireguard
MTU = 1500

# accessing the peer
PostUp = ip route add 192.168.160.0/24 dev wg0
PostUp = ip -6 route add fc00:0:0:160::/64 dev wg0

# fix MSS issue
PostUp = iptables -t mangle -A POSTROUTING -p tcp --tcp-flags SYN SYN -o wg0 -j TCPMSS --clamp-mss-to-pmtu
PostDown = iptables -t mangle -D POSTROUTING -p tcp --tcp-flags SYN SYN -o wg0 -j TCPMSS --clamp-mss-to-pmtu
PostUp = ip6tables -t mangle -A POSTROUTING -p tcp --tcp-flags SYN SYN -o wg0 -j TCPMSS --clamp-mss-to-pmtu
PostDown = ip6tables -t mangle -D POSTROUTING -p tcp --tcp-flags SYN SYN -o wg0 -j TCPMSS --clamp-mss-to-pmtu

# routing outbound SMTP
PostUp = ip rule add ipproto tcp dport 25 iif br-mailcow lookup wireguard pref 2500
PostDown = ip rule del pref 2500
PostUp = ip -6 rule add ipproto tcp dport 25 iif br-mailcow lookup wireguard pref 2500
PostDown = ip -6 rule del pref 2500

# routing responses from host
PostUp = ip rule add from 192.168.160.2 table wireguard pref 2501
PostDown = ip rule del pref 2501
PostUp = ip -6 rule add from fc00:0:0:160::2 table wireguard pref 2501
PostDown = ip -6 rule del pref 2501

# routing responses from containers
PostUp = iptables -t mangle -A PREROUTING -m conntrack --ctorigdst 192.168.160.2 --ctstate ESTABLISHED,RELATED ! -d 192.168.160.2 -j MARK --set-mark 0xa
PostUp = ip rule add fwmark 0xa table wireguard pref 2502
PostDown = iptables -t mangle -D PREROUTING -m conntrack --ctorigdst 192.168.160.2 --ctstate ESTABLISHED,RELATED ! -d 192.168.160.2 -j MARK --set-mark 0xa
PostDown = ip rule del pref 2502
PostUp = ip6tables -t mangle -A PREROUTING -m conntrack --ctorigdst fc00:0:0:160::2 --ctstate ESTABLISHED,RELATED ! -d fc00:0:0:160::2 -j MARK --set-mark 0xa
PostUp = ip -6 rule add fwmark 0xa table wireguard pref 2502
PostDown = ip6tables -t mangle -D PREROUTING -m conntrack --ctorigdst fc00:0:0:160::2 --ctstate ESTABLISHED,RELATED ! -d fc00:0:0:160::2 -j MARK --set-mark 0xa
PostDown = ip -6 rule del pref 2502

[Peer]
PublicKey = &lt;Gateway public key&gt;
PresharedKey = &lt;PSK&gt;
AllowedIPs = 0.0.0.0/0, ::0/0
Endpoint = &lt;Gateway public IP&gt;:51820
PersistentKeepalive = 60</code></pre><p>If you landed here directly and took my configuration, please don&#39;t forget to:</p><ul><li>Enable TUN/TAP and configure BoringTUN if your Gateway is an OpenVZ VPS</li><li>Enable forwarding both for IPv4 and IPv6 on Gateway</li><li>Set the default policy of the <code>FORWARD</code> chain in the <code>filter</code> table to <code>DROP</code></li><li>Create the routing table <code>wireguard</code> on Server</li><li>Tailor my config to your own situation (interface names, ports, etc.)</li><li>Use some methods to persist these changes</li><li>Say &#34;thanks&#34; to me : )</li></ul><h2>Bottom Line, and Some Rants</h2><p>I always felt, and still feel, that applied Linux networking is difficult to get started with, mainly due to lack of good guidance. Most of the time I had to dig through small pieces of documentation scattered throughout the internet, trying to put them together to form a systematic overview of the network stack in Linux.</p><p>Some of you might say: Use ChatGPT! The short answer is: I did, but it didn&#39;t work at all. The long answer is: ChatGPT is very good at bulls**ting, and when it makes up a story, it justifies the story so well that you won&#39;t even notice that the story was purely false, until you reach a point where it contradicts itself. It is very easy to get pulled into false information if you try to learn things from ChatGPT. So, my advice is to stay away from AI, at least for now, if you want to learn some real Computer Science.</p><p>It is extremely frustrating when somebody interested in setting up their own network infrastructure has to at some point get stuck at some convoluted networking concepts, intricate and abstract tools, mysterious errors here and there, or lack of systematic documentation. I wish everyone has some choices other than spending days and weeks trying to figure these out alone, so I decided to write down what I have done, what I have learned and what I have to share with the rest of the internet. I sincerely hope that some day IT operations would be more beginner-friendly, and hosting one&#39;s own network infrastructure no longer means headache and mess.</p>        <!-- 版权声明 -->
        
        <!-- donate
        <div class="post_reward">
          <label class="reward_btn">请喝咖啡</label>
          <div class="qr_code" style="display: none;">
            <div class="qr_code_img">
              <img class="image" src="" title="WeChat">
            </div>
            <div class="qr_code_img">
              <img class="image" src="" title="AliPay">
            </div>
          </div>
        </div> -->
        <!-- 评论 -->
                 
 

                <!-- 上一篇&下一篇 -->
                <hr/>
        
      </div>

      <!-- 侧边栏文章标题列表 -->
      

      <!-- 底部信息-->
      
    </div>
</div></article></div>
  </body>
</html>
