<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://techcrunch.com/2024/05/02/microsoft-bans-u-s-police-departments-from-using-enterprise-ai-tool/">Original</a>
    <h1>Microsoft bans U.S. police departments from using enterprise AI tool</h1>
    
    <div id="readability-page-1" class="page"><div>
	

			
	
			<p><img src="https://techcrunch.com/wp-content/uploads/2024/02/GettyImages-1930518491.jpg?w=600"/>
		</p>
	</div><div>
				<p id="speakable-summary">Microsoft has changed its <a href="https://learn.microsoft.com/en-us/legal/cognitive-services/openai/code-of-conduct">policy</a> to ban U.S. police departments from using generative AI through the <a href="https://techcrunch.com/tag/azure-openai-service/">Azure OpenAI Service</a>, the company’s fully managed, enterprise-focused wrapper around OpenAI technologies.</p>
<p>Language added Wednesday to the terms of service for Azure OpenAI Service prohibits integrations with Azure OpenAI Service from being used “by or for” police departments in the U.S., including integrations with OpenAI’s text- and speech-analyzing models.</p>
<p>A separate new bullet point covers “any law enforcement globally,” and explicitly bars the use of “real-time facial recognition technology” on mobile cameras, like body cameras and dashcams, to attempt to identify a person in “uncontrolled, in-the-wild” environments.</p>
<p>The changes in terms come a week after Axon, a maker of tech and weapons products for military and law enforcement, announced a <a href="https://www.forbes.com/sites/thomasbrewster/2024/04/23/axon-ai-police-reports-/#:~:text=Axon%20senior%20principal%20AI%20product,facts%20of%20what&#39;s%20being%20recorded.">new product</a> that leverages OpenAI’s <a href="https://techcrunch.com/tag/gpt-4/">GPT-4</a> generative text model to summarize audio from body cameras. Critics were quick to point out the potential pitfalls, like <a href="https://techcrunch.com/2023/09/04/are-language-models-doomed-to-always-hallucinate/">hallucinations</a> (even the best generative AI models today invent facts) and <a href="https://techcrunch.com/2019/08/14/racial-bias-observed-in-hate-speech-detection-algorithm-from-google/">racial biases</a> introduced from the training data (which is especially concerning given that people of color are <a href="https://www.washingtonpost.com/politics/2022/09/15/driving-while-black-racial-discrimination-traffic-tickets/">far more likely to be stopped by police</a> than their white peers).</p>
<p>It’s unclear whether Axon was using GPT-4 via Azure OpenAI Service, and, if so, whether the updated policy was in response to Axon’s product launch. OpenAI had <a href="https://www.nytimes.com/2023/07/18/technology/openai-chatgpt-facial-recognition.html">previously restricted</a> the use of its models for facial recognition through its APIs. We’ve reached out to Axon, Microsoft and OpenAI and will update this post if we hear back.</p>
<p>The new terms leave wiggle room for Microsoft.</p>
<p>The complete ban on Azure OpenAI Service usage pertains only to U.S.<em>,</em> not international, police. And it doesn’t cover facial recognition performed with <em>stationary</em> cameras in <em>controlled</em> environments, like a back office (although the terms prohibit any use of facial recognition by U.S. police).</p>
<p>That tracks with Microsoft’s and close partner OpenAI’s recent approach to AI-related law enforcement and defense contracts.</p>
<p>In January, reporting by Bloomberg <a href="https://www.bloomberg.com/news/articles/2024-01-16/openai-working-with-us-military-on-cybersecurity-tools-for-veterans?embedded-checkout=true">revealed</a> that OpenAI is working with the Pentagon on a number of projects including cybersecurity capabilities — a departure from the startup’s <a href="https://techcrunch.com/2024/01/12/openai-changes-policy-to-allow-military-applications/">earlier ban</a> on providing its AI to militaries. Elsewhere, Microsoft has pitched using OpenAI’s image generation tool, DALL-E, to help the Department of Defense (DoD) build software to execute military operations, <a href="https://theintercept.com/2024/04/10/microsoft-openai-dalle-ai-military-use/">per</a> The Intercept.</p>
<p>Azure OpenAI Service became available in Microsoft’s Azure Government product in February, adding additional compliance and management features geared toward government agencies including law enforcement. In a <a href="https://devblogs.microsoft.com/azuregov/azure-openai-service-now-available-in-azure-gov-cloud/">blog post</a>, Candice Ling, SVP of Microsoft’s government-focused division Microsoft Federal, pledged that Azure OpenAI Service would be “submitted for additional authorization” to the DoD for workloads supporting DoD missions.</p>
<p>Microsoft and OpenAI did not immediately return requests for comment.</p>
			</div></div>
  </body>
</html>
