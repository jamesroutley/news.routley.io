<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://ai.meta.com/blog/emu-text-to-video-generation-image-editing-research/">Original</a>
    <h1>Emu Video and Emu Edit, our latest generative AI research milestones</h1>
    
    <div id="readability-page-1" class="page"><div><div><p>The field of generative AI is rapidly evolving, showing remarkable potential to augment human creativity and self-expression. In 2022, we made the leap from <a href="https://ai.meta.com/blog/greater-creative-control-for-ai-image-generation/" target="_blank" data-lnfb-mode="ie"><u>image generation</u></a> to <a href="https://ai.meta.com/blog/generative-ai-text-to-video/" target="_blank" data-lnfb-mode="ie"><u>video generation</u></a> in the span of a few months. And at this year’s Meta Connect, we announced several<a href="https://about.fb.com/news/2023/09/introducing-ai-powered-assistants-characters-and-creative-tools/" target="_blank" data-lnfb-mode="ie"><u> new developments</u></a>, including <a href="https://ai.meta.com/research/publications/emu-enhancing-image-generation-models-using-photogenic-needles-in-a-haystack/" target="_blank" data-lnfb-mode="ie"><u>Emu</u></a>, our first foundational model for image generation. Technology from Emu underpins many of our generative AI experiences, some AI image editing tools for Instagram that let you take a photo and change its visual style or background, and the Imagine feature within Meta AI that lets you generate photorealistic images directly in messages with that assistant or in group chats across our family of apps. Our work in this exciting field is ongoing, and today, we’re announcing new research into controlled image editing based solely on text instructions and a method for text-to-video generation based on diffusion models.</p><br/></div><div><p>Whether or not you’ve personally used an AI image generation tool, you’ve likely seen the results: Visually distinct, often highly stylized and detailed, these images on their own can be quite striking—and the impact increases when you bring them to life by adding movement.</p><br/></div></div><div><p><img src="https://scontent-iad3-2.xx.fbcdn.net/v/t39.2365-6/400716824_1091119852252102_4469709282943793457_n.png?_nc_cat=106&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=b_MVYm_ul4YAX9sHWiz&amp;_nc_ht=scontent-iad3-2.xx&amp;oh=00_AfBC7Q89bQAdXEE97gK6m3W0n42NrCUJ1MsSQHGZSJhSnw&amp;oe=65713080" alt="" id="u_0_l_01"/></p><div><p>Of course, the use of generative AI is often a process. You try a prompt, the generated image isn’t <i>quite</i> what you had in mind, so you continue tweaking the prompt until you get to a more desired outcome. That’s why prompt engineering has become a thing. And while instructable image generative models have made significant strides in recent years, they still face limitations when it comes to offering precise control. That’s why we’re introducing Emu Edit, a novel approach that aims to streamline various image manipulation tasks and bring enhanced capabilities and precision to image editing.</p><br/></div><div><p>Our key insight is that incorporating computer vision tasks as instructions to image generation models offers unprecedented control in image generation and editing. Through a detailed examination of both local and global editing tasks, we highlight the vast potential of Emu Edit in executing detailed edit instructions.</p><p>In order to train the model, we’ve developed a dataset that contains 10 million synthesized samples, each including an input image, a description of the task to be performed, and the targeted output image. We believe it’s the largest dataset of its kind to date. As a result, our model displays unprecedented edit results in terms of both instruction faithfulness and image quality. In our evaluations, Emu Edit demonstrates superior performance over current methods, producing new state-of-the-art results in both qualitative and quantitative evaluations for a range of image editing tasks.</p></div><p>The road ahead</p><div><p>Although this work is purely fundamental research right now, the potential use cases are clearly evident. Imagine generating your own animated stickers or clever GIFs on the fly to send in the group chat rather than having to search for the perfect media for your reply. Or editing your own photos and images, no technical skills required. Or adding some extra oomph to your Instagram posts by animating static photos. Or generating something entirely new.</p><p>While certainly no replacement for professional artists and animators, Emu Video, Emu Edit, and new technologies like them could help people express themselves in new ways—from an art director ideating on a new concept or a creator livening up their latest reel to a best friend sharing a unique birthday greeting. And we think that’s something worth celebrating.</p></div></div></div>
  </body>
</html>
