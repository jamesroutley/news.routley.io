<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://dagster.io/blog/fast-deploys-with-pex-and-docker">Original</a>
    <h1>How we deploy faster with warm Docker containers</h1>
    
    <div id="readability-page-1" class="page"><div><h2 id="serverless-development-and-feedback-loops"><a aria-hidden="true" tabindex="-1" href="#serverless-development-and-feedback-loops"><span></span></a>Serverless development and feedback loops</h2><p>With <a href="https://dagster.io/cloud">Serverless Dagster Cloud</a> you can develop and deploy Dagster code without setting up either a local development environment or any cloud infrastructure. When you commit a change to GitHub, a <a href="https://github.com/features/actions">GitHub Action</a> builds and deploys your code directly to Dagster Cloud, where you can view and interact with your Dagster objects in the UI.</p><div stylename="[object Object]"><div data-rmiz-wrap="visible"><div><div><p><img alt="" aria-hidden="true" role="presentation" src="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMTU4NCIgaGVpZ2h0PSI1ODgiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgdmVyc2lvbj0iMS4xIi8+"/></p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"/></p></div></div></div></div><p>Initially, we used our standard Docker-based build process for Dagster Cloud Serverless, however, we soon discovered that this makes the <em>edit-deploy-run cycle</em> tediously slow. To speed this up we implemented a system to ship code outside Docker images. This post describes the problems we analyzed, the solution we settled on, and the various trade-offs we made in the process.</p><figure><figcaption>Shalabh Chaturvedi shares a high level overview of Dagster Cloud&#39;s new <em>Fast Deploy</em> capability.</figcaption></figure><h2 id="the-problem-with-docker-images"><a aria-hidden="true" tabindex="-1" href="#the-problem-with-docker-images"><span></span></a>The problem with Docker images</h2><p>When we build Docker images on GitHub and deploy them to Dagster Cloud, each commit takes anywhere from 3 to 5 minutes to show up in the Dagster UI. Serverless developers often make a small change to the code in each iteration, and having to wait upwards of 3 minutes to see the effect of that change gets tiresome very quickly. We analyzed ‚Äúwhat happens when you change one line of code and commit‚Äù and discovered the following:</p><div stylename="[object Object]"><div data-rmiz-wrap="visible"><div><div><p><img alt="" aria-hidden="true" role="presentation" src="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMjUwMiIgaGVpZ2h0PSIxMDk5IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZlcnNpb249IjEuMSIvPg=="/></p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"/></p></div></div></div></div><p>As you see above, the two things that take the longest are:</p><ul><li><em>building</em> a Docker image (60 - 90+ seconds)</li><li><em>deploying</em> the Docker container (90 seconds)</li></ul><p>Let&#39;s look at each of these.</p><h3 id="building-docker-images"><a aria-hidden="true" tabindex="-1" href="#building-docker-images"><span></span></a>Building Docker images</h3><p>Some things to note about building a Docker image:</p><ol><li>Docker images are made of multiple <em>layers</em> in a stack, where each layer is built by a subset of the commands in the <code>Dockerfile</code>.</li><li>Each layer is identified by a hash.</li><li>When uploading images to a registry, only the layers not present in the registry (as identified by the hash) are uploaded.</li><li>Rebuilding images on a GitHub build machine using the <a href="https://docs.docker.com/build/cache/backends/gha/">GitHub Actions cache</a> <strong>pulls all unaffected layers from the cache onto the build machine</strong>. Note that if you have a large set of dependencies in your project that don&#39;t change, they will still be copied from the cache to the build machine during the build process.</li><li>Docker builds are <em>not</em> deterministic. If you build an image twice with the same exact same contents, it may produce a different hash each time. (While not directly relevant, we wanted to note this unexpected observation. As a corner case, consider that a freshly built large layer that is identical to a layer already in the registry may still get uploaded as a new layer.)</li></ol><h3 id="launching-docker-containers"><a aria-hidden="true" tabindex="-1" href="#launching-docker-containers"><span></span></a>Launching Docker containers</h3><p>The main thing to note about launching Docker containers is that we use <a href="https://aws.amazon.com/fargate/">AWS Fargate</a> and it takes anywhere from 45 to 90 seconds to provision and boot an image. It does not provide any <a href="https://github.com/aws/containers-roadmap/issues/696">image caching</a>. Launching a new container downloads all layers from the registry onto the provisioned container.</p><h3 id="other-constraints"><a aria-hidden="true" tabindex="-1" href="#other-constraints"><span></span></a>Other constraints</h3><p>After the Docker image is built and launched, we run the user&#39;s code to extract metadata that is displayed in the UI. This is unavoidable and can take anywhere from a couple of seconds to 30 seconds or more, depending on how the metadata is computed (for example, it could connect to a database to read the schema). This code server remains alive and serves metadata requests until a new version of the code is pushed, which then launches a new container.</p><p>One key requirement we have is <em>repeatability</em>: we need to be able to redeploy the exact same code and environment multiple times. Using the Docker image hash as an identifier for the code and environment works very well for this requirement.</p><h2 id="roundup-of-alternatives"><a aria-hidden="true" tabindex="-1" href="#roundup-of-alternatives"><span></span></a>Roundup of alternatives</h2><p>Here are some alternatives we explored and discussed:</p><ol><li><strong>Switch from Fargate to EC2 for faster container launches.</strong> This would increase our ops burden, requiring us to pre-provision, monitor and scale our cluster. We would still have the problem of Docker builds being slow.</li><li><strong>Switch to a different Docker build system such as AWS CodeBuild.</strong> This would require a lot more implementation work and deeper integration with GitHub. It was unclear if the payoff would be worth it.</li><li><strong>Switch to AWS Lambda with much faster launch times.</strong> The Lambda environment comes with its own base images making it harder to customize if needed. It also imposes a 15-minute limit on execution time which would require complicated workarounds for longer-running servers.</li><li><strong>Reuse the long-running code server by building and uploading only the changed code to the same server.</strong> The challenge here would be implementing the packaging and runtime mechanism to ensure a reliable and repeatable execution environment. We looked into various ways to package and distribute Python environments, including rsync, <a href="https://python-poetry.org/">poetry</a>, <a href="https://nixos.org/">nix</a>, <a href="https://shiv.readthedocs.io/en/latest/">shiv</a>, and <a href="https://pex.readthedocs.io/">pex</a>. We also thought about using EFS volumes to mount Python environments in combination with these tools.</li></ol><p>The key factor behind our decision was the realization that while Docker images are industry standard, moving around 100s of megabytes of images seems unnecessarily heavy-handed when we just need to synchronize a small change. Consider git ‚Äì it only ships the diffs, yet it produces whole and consistent repositories. This made us lean towards option 4‚Ä¶ if only we could find a suitable tool that would do most of the work for us. After some experimentation, we found <a href="https://payments.posthaven.com/pex.readthedocs.io/">pex</a> had many features that worked very well for our use case - more on this in the next section.</p><h3 id="what-is-pex"><a aria-hidden="true" tabindex="-1" href="#what-is-pex"><span></span></a>What is PEX?</h3><p>Short for Python Executable, <a href="https://pex.readthedocs.io/"><code>pex</code></a> is a tool that bundles Python packages into files called <em>pex files</em>. These are executable files that carry Python packages and some bootstrap code within them. For example, we can bundle the  <code>dagster</code> package and it‚Äôs dependencies into a single file and then run it:</p><pre><code>% pex dagster --python<span>=</span>python3.8 -o dagster.pex
% ./dagster.pex
Python <span>3.8</span>.16 <span>(</span>default, Dec  <span>7</span> <span>2022</span>, 01:24:57<span>)</span>
<span>[</span>Clang <span>14.0</span>.0 <span>(</span>clang-1400.0.29.202<span>)</span><span>]</span> on darwin
Type <span>&#34;help&#34;</span>, <span>&#34;copyright&#34;</span>, <span>&#34;credits&#34;</span> or <span>&#34;license&#34;</span> <span>for</span> <span>more</span> information.
<span>(</span>InteractiveConsole<span>)</span>
<span>&gt;&gt;</span><span>&gt;</span> <span>import</span> dagster
<span>&gt;&gt;</span><span>&gt;</span>
</code></pre><p>Having the entire environment in a single file is convenient to ship around and store in S3. <code>pex</code> provides more than just a ‚Äúvirtual environment in a file‚Äù ‚Äì here are other features that we use:</p><ol><li><p><strong>Isolation</strong></p><p>At runtime, pex environments are fully isolated from other site-wide packages. The only packages present in the environment are those bundled in the pex file. We ship multiple pex files to the same machine without having to worry about environment isolation.</p></li><li><p><strong>Determinism</strong></p><p>Using the same set of input packages produces bit-for-bit identical pex files :</p><pre><code>$ pex dagster pandas -o out.pex <span>|</span> sha256sum
e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855  -
$ pex dagster pandas -o out.pex <span>|</span> sha256sum
e3b0c44298fc1c149afbf4c8996fb92427ae41e4649b934ca495991b7852b855  -
</code></pre><p>This gives us confidence in using content addressing to identify these pex files. To implement repeatability, we use pex file hashes in addition to the Docker image hash.</p></li><li><p><strong>Composition</strong></p><p>Multiple pex files can be merged at runtime, effectively merging the environments into one.</p><pre><code>% pex pandas -o pandas.pex
% pex dagster -o dagster.pex
% <span>PEX_PATH</span><span>=</span>pandas.pex ./dagster.pex
Python <span>3.8</span>.16 <span>(</span>default, Dec  <span>7</span> <span>2022</span>, 01:24:57<span>)</span>
<span>[</span>Clang <span>14.0</span>.0 <span>(</span>clang-1400.0.29.202<span>)</span><span>]</span> on darwin
Type <span>&#34;help&#34;</span>, <span>&#34;copyright&#34;</span>, <span>&#34;credits&#34;</span> or <span>&#34;license&#34;</span> <span>for</span> <span>more</span> information.
<span>(</span>InteractiveConsole<span>)</span>
<span>&gt;&gt;</span><span>&gt;</span> <span>import</span> pandas
<span>&gt;&gt;</span><span>&gt;</span> <span>import</span> dagster
<span>&gt;&gt;</span><span>&gt;</span>
</code></pre><p>We use this to split the code into two parts that we merge at runtime: a <code>deps.pex</code> file containing all the dependencies and a <code>source.pex</code> file containing just the user code.</p></li><li><p><strong>Cross-platform builds</strong></p><p>We use the Linux <code>python:*-slim</code> derived <a href="https://hub.docker.com/_/python">base images</a> in our Serverless Cloud. The <code>pex</code> tool can build pex files for Linux on any platform as long as the <a href="https://packaging.python.org/en/latest/glossary/#term-Built-Distribution">wheels</a> for the packages are available.</p></li></ol><h2 id="fast-deploys"><a aria-hidden="true" tabindex="-1" href="#fast-deploys"><span></span></a>Fast Deploys</h2><p>Using <code>pex</code> in combination with S3 for storing the pex files, we built a system where the fast path avoids the overhead of building and launching Docker images.</p><p>Our system works like this: when you commit code to GitHub, the GitHub action either does a <em>full build</em> or a <em>fast build</em> depending on if your dependencies have changed since the previous deploy. We keep track of the set of dependencies specified in <code>setup.py</code> and <code>requirements.txt</code>.</p><p>For a full build, we build your project dependencies into a <code>deps.pex</code> file and your code into a <code>source.pex</code> file. Both are uploaded to Dagster cloud. For a fast build we only build and upload the <code>source.pex</code> file.</p><p>In Dagster Cloud, we may reuse an existing container or provision a new container as the code server. We download the <code>deps.pex</code> and <code>source.pex</code> files onto this code server and use them to run your code in an isolated environment. We never share a container across users and all environments on a container belong to the same user. The best case and worst case timelines for fast deploys are show below:</p><div stylename="[object Object]"><div data-rmiz-wrap="visible"><div><div><p><img alt="" aria-hidden="true" role="presentation" src="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iMzIzMCIgaGVpZ2h0PSIxOTU2IiB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZlcnNpb249IjEuMSIvPg=="/></p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"/></p></div></div></div></div><p>The upshot here is that in the <em>fast path</em> ‚Äì when we do a fast build and also reuse and existing container ‚Äì the entire process takes about 40 seconds instead of 3+ minutes that it used to.</p><p>We call this feature <strong>fast deploys</strong> and it is now on by default for all new serverless sign-ups.</p><h2 id="trade-offs-and-issues"><a aria-hidden="true" tabindex="-1" href="#trade-offs-and-issues"><span></span></a>Trade-offs and issues</h2><p><em>Fast deploys</em> significantly improve the deploy speed (4-5X), but it comes with some trade offs and other factors we have tuned:</p><ol><li>While we can now run multiple environments on one code server and they are isolated code-wise, they still share the same RAM and CPU. If we put too many environments on one container and one environment takes up too much memory, it can adversely affect other running environments in the same container.</li><li>Docker can build Python packages for Linux on any OS because the target Linux OS and Python interpreter are available during the build process. pex can only build pex files for Linux for packages that provides <a href="https://github.com/pypa/manylinux">wheels</a>. As as fallback we use a <a href="https://github.com/pypa/manylinux">Docker container</a> during the build to handle <a href="https://packaging.python.org/en/latest/glossary/#term-Source-Distribution-or-sdist">source distributions</a>. This step could be moved into a separate shared service in the future.</li><li>Deep customization is possible when building a Docker image, for example you can specify a custom base image instead of one of the default <code>python:*-slim</code> images. For feature parity, we had to implemented a way for users to specify their own base Docker image that we use with fast deploys.</li></ol><h2 id="github-workflows-and-pex"><a aria-hidden="true" tabindex="-1" href="#github-workflows-and-pex"><span></span></a>GitHub workflows and pex</h2><p>You may have noticed that <em>Download Docker based action</em> in the original diagram used to take about 10 seconds. How did we eliminate this step entirely?</p><p>We used to package our GitHub action code into a Docker image and used the <a href="https://docs.github.com/en/actions/creating-actions/creating-a-docker-container-action">Docker container action</a>. Instead, we now package our action code as a pex file, which we check into our action repository and run directly on the GitHub runner. This eliminates the time spent downloading and launching the Docker action image, while still allowing us to package all dependencies.</p><p>Another small optimization we made was to only use one GitHub workflow job. Every job launch in GitHub takes about 10s to provision a new runner.</p><h2 id="conclusion"><a aria-hidden="true" tabindex="-1" href="#conclusion"><span></span></a>Conclusion</h2><p>Reducing the deploy time from over 3 minutes to 40 seconds is a significant speed-up and we‚Äôre very happy with the outcome, specially when we‚Äôre testing our own service. Using pex allowed us to build a repeatable, consistent environment on top of Docker and we‚Äôre excited to explore other possibilities using this pex-on-docker combination.</p><p>If you found this post interesting, here is another <a href="https://blog.pantsbuild.org/optimizing-python-docker-deploys-using-pants/">blog post</a> from the pex team on the topic of deployment with Docker. It describes how to use pex files as intermediate targets to speed up Docker image builds.</p><p>If you want to support the Dagster Open Source project, be sure to <a href="https://github.com/dagster-io/dagster">Star our Github repo</a>.</p><div><div data-rmiz-wrap="visible"><div><div><p><img alt="" aria-hidden="true" role="presentation" src="data:image/svg+xml;base64,PHN2ZyB3aWR0aD0iNjAiIGhlaWdodD0iNjAiIHhtbG5zPSJodHRwOi8vd3d3LnczLm9yZy8yMDAwL3N2ZyIgdmVyc2lvbj0iMS4xIi8+"/></p><p><img src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async"/></p></div></div></div></div><p>We&#39;re always happy to hear your feedback, so please reach out to us! If you have any questions, ask them in the Dagster community Slack (<a href="https://join.slack.com/t/dagster/shared_invite/zt-1jma6rmvo-CG3FOwzUvM7e1ds4IUQxaA">join here</a>!) or start a <a href="https://github.com/dagster-io/dagster/discussions">Github discussion</a>. If you run into any bugs, let us know with a <a href="https://github.com/dagster-io/dagster/issues/new/choose">Github issue</a>. And if you&#39;re interested in working with us, check out our <a href="https://www.elementl.com/careers#open_roles">open roles</a>!</p><p><strong>Follow us:</strong></p><ul><li>üåü <a href="https://github.com/dagster-io/dagster">Star us on Github</a></li><li>üê¶ <a href="https://twitter.com/dagster">Follow us on Twitter</a></li><li>üì∫ <a href="https://www.youtube.com/channel/UCfLnv9X8jyHTe6gJ4hVBo9Q">Subscribe to our YouTube Channel</a></li></ul></div></div>
  </body>
</html>
