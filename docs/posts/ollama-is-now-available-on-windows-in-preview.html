<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://ollama.com/blog/windows-preview">Original</a>
    <h1>Ollama is now available on Windows in preview</h1>
    
    <div id="readability-page-1" class="page"><div>
      
      <h2>February 15, 2024</h2>
      <section>
        <p><a href="https://blog.plover.com/download/windows"><img src="https://blog.plover.com/public/blog/windows-wave.png" alt="Ollama windows"/></a></p>

<p>Ollama is <a href="https://ollama.com/download/windows">now available</a> on Windows in preview, making it possible to pull, run and create large language models in a new native Windows experience. Ollama on Windows includes built-in GPU acceleration, access to the full <a href="https://ollama.com/library">model library</a>, and the Ollama API including <a href="https://ollama.com/blog/openai-compatibility">OpenAI compatibility</a>.</p>

<h2>Hardware acceleration</h2>

<p>Ollama accelerates running models using NVIDIA GPUs as well as modern CPU instruction sets such as AVX and AVX2 if available. No configuration or virtualization required!</p>

<video autoplay="" controls="">
  <source src="https://github.com/ollama/ollama/assets/251292/5d46993f-bd01-4431-b4f6-6346fa27f459" type="video/mp4"/>
</video>

<h2>Full access to the model library</h2>

<p>The full Ollama <a href="https://ollama.com/library">model library</a> is available to run on Windows, including <a href="https://ollama.com/blog/vision-models">vision models</a>. When running vision models such as <a href="https://ollama.com/library/llava">LLaVA 1.6</a>, images can be dragged and dropped into <code>ollama run</code> to add them to a message.</p>

<video controls="">
  <source src="https://github.com/ollama/ollama/assets/251292/99b8dbdb-084c-48d2-b779-d070b4ad1784" type="video/mp4"/>
</video>

<h2>Always-on Ollama API</h2>

<p>Ollama’s API automatically runs in the background, serving on <code>http://localhost:11434</code>. Tools and applications can connect to it without any additional setup.</p>

<p><img src="https://blog.plover.com/public/blog/windows-preview-tray-icon.jpg" alt="ollama background"/></p>

<p>For example, here’s how to invoke Ollama’s API using PowerShell:</p>

<pre><code>(Invoke-WebRequest -method POST -Body &#39;{&#34;model&#34;:&#34;llama2&#34;, &#34;prompt&#34;:&#34;Why is the sky blue?&#34;, &#34;stream&#34;: false}&#39; -uri http://localhost:11434/api/generate ).Content | ConvertFrom-json
</code></pre>

<p>Ollama on Windows also supports the same <a href="https://ollama.com/blog/openai-compatibility">OpenAI compatibility</a> as on other platforms, making it possible to use existing tooling built for OpenAI with local models via Ollama.</p>

<h2>Get started</h2>

<p>To get started with the Ollama on Windows Preview:</p>

<ul>
<li><a href="https://ollama.com/download/OllamaSetup.exe">Download</a> Ollama on Windows</li>
<li>Double-click the installer, <code>OllamaSetup.exe</code></li>
<li>After installing, open your favorite terminal and run <code>ollama run llama2</code> to run a model</li>
</ul>

<p>Ollama will prompt for updates as new releases become available. We’d love your feedback! If you encounter any issues please let us know by <a href="https://github.com/ollama/ollama/issues/new">opening an issue</a> or by joining the <a href="https://discord.gg/ollama">Discord server</a>.</p>

      </section>
    </div></div>
  </body>
</html>
