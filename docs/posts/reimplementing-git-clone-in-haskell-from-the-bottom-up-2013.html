<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://stefan.saasen.me/articles/git-clone-in-haskell-from-the-bottom-up/">Original</a>
    <h1>Reimplementing git clone in Haskell from the bottom up (2013)</h1>
    
    <div id="readability-page-1" class="page"><div id="wrapper">
        <!--
Use numbered headers: true
-->

<p><img id="article-logo" src="https://stefan.saasen.me/articles/git-clone-in-haskell-from-the-bottom-up/images/git-haskell-icon@2x.png" width="150" height="100" alt="Git"/></p>



<p>Stefan Saasen - March 2013 - <a href="https://twitter.com/stefansaasen">@stefansaasen</a></p>

<ul id="markdown-toc">
  <li><a href="#reimplementing-git-clone-in-haskell-from-the-bottom-up" id="markdown-toc-reimplementing-git-clone-in-haskell-from-the-bottom-up">Reimplementing “git clone” in Haskell from the bottom up</a>    <ul>
      <li><a href="#motivation" id="markdown-toc-motivation">Motivation</a></li>
      <li><a href="#overview" id="markdown-toc-overview">Overview</a></li>
      <li><a href="#the-clone-process" id="markdown-toc-the-clone-process">The clone process</a></li>
      <li><a href="#git-transport-and-pack-wire-protocol" id="markdown-toc-git-transport-and-pack-wire-protocol">Git transport and pack wire protocol</a>        <ul>
          <li><a href="#transport-protocol" id="markdown-toc-transport-protocol">Transport protocol</a>            <ul>
              <li><a href="#reference-discovery" id="markdown-toc-reference-discovery">Reference Discovery</a></li>
              <li><a href="#capabilities" id="markdown-toc-capabilities">Capabilities</a></li>
              <li><a href="#packfile-negotiation" id="markdown-toc-packfile-negotiation">Packfile negotiation</a></li>
            </ul>
          </li>
          <li><a href="#packet-line-format" id="markdown-toc-packet-line-format">Packet line format</a></li>
          <li><a href="#client---server-exchange" id="markdown-toc-client---server-exchange">Client - Server exchange</a></li>
          <li><a href="#implementing-ref-discovery" id="markdown-toc-implementing-ref-discovery">Implementing ref discovery</a></li>
          <li><a href="#implementing-pack-file-negotiation" id="markdown-toc-implementing-pack-file-negotiation">Implementing pack file negotiation</a></li>
        </ul>
      </li>
      <li><a href="#pack-file-format" id="markdown-toc-pack-file-format">Pack file format</a>        <ul>
          <li><a href="#pack-file-header" id="markdown-toc-pack-file-header">Pack file header</a></li>
          <li><a href="#pack-file-objects" id="markdown-toc-pack-file-objects">Pack file objects</a></li>
          <li><a href="#delta-encoding" id="markdown-toc-delta-encoding">Delta encoding</a>            <ul>
              <li><a href="#format-of-the-delta-representation" id="markdown-toc-format-of-the-delta-representation">Format of the delta representation</a></li>
              <li><a href="#testing" id="markdown-toc-testing">Testing</a></li>
              <li><a href="#patch-algorithm-example" id="markdown-toc-patch-algorithm-example">Patch algorithm example</a></li>
              <li><a href="#implementation-of-the-delta-encoding-algorithm" id="markdown-toc-implementation-of-the-delta-encoding-algorithm">Implementation of the delta encoding algorithm</a></li>
            </ul>
          </li>
          <li><a href="#ref-vs-ofs-delta" id="markdown-toc-ref-vs-ofs-delta">Ref vs. Ofs delta</a></li>
          <li><a href="#summary" id="markdown-toc-summary">Summary</a></li>
        </ul>
      </li>
      <li><a href="#git-repository" id="markdown-toc-git-repository">Git repository</a></li>
      <li><a href="#object-store" id="markdown-toc-object-store">Object store</a>        <ul>
          <li><a href="#objects-on-disk" id="markdown-toc-objects-on-disk">Objects on disk</a>            <ul>
              <li><a href="#object-storage-format" id="markdown-toc-object-storage-format">Object storage format</a></li>
            </ul>
          </li>
        </ul>
      </li>
      <li><a href="#refs" id="markdown-toc-refs">Refs</a>        <ul>
          <li><a href="#implementation" id="markdown-toc-implementation">Implementation</a></li>
        </ul>
      </li>
      <li><a href="#working-copy-and-the-index" id="markdown-toc-working-copy-and-the-index">Working copy and the index</a>        <ul>
          <li><a href="#reading-objects" id="markdown-toc-reading-objects">Reading objects</a>            <ul>
              <li><a href="#commit" id="markdown-toc-commit">Commit</a></li>
              <li><a href="#blob" id="markdown-toc-blob">Blob</a></li>
              <li><a href="#tree" id="markdown-toc-tree">Tree</a></li>
            </ul>
          </li>
          <li><a href="#git-index" id="markdown-toc-git-index">Git index</a>            <ul>
              <li><a href="#index-format" id="markdown-toc-index-format">Index format</a></li>
            </ul>
          </li>
        </ul>
      </li>
      <li><a href="#the-clone-command-re-implemented" id="markdown-toc-the-clone-command-re-implemented">The clone command re-implemented</a></li>
      <li><a href="#whats-missing" id="markdown-toc-whats-missing">What’s missing?</a></li>
      <li><a href="#conclusion" id="markdown-toc-conclusion">Conclusion</a></li>
      <li><a href="#footnotes" id="markdown-toc-footnotes">Footnotes</a></li>
    </ul>
  </li>
</ul>

<h2 id="motivation">Motivation</h2>

<p>In order to give some structure to my ongoing investigation of git’s data structures, protocols and implementation I decided to re-implement <code>git clone</code> <em>without</em> using any of git’s plumbing commands or any of the existing git libraries. Along the way I tried to keep some implementation notes that should help to understand some of the building blocks required to replicate the clone functionality.</p>

<p>The git clone implementation that came out of this exercise is obviously of very limited <em>practical</em> value but required investigating some areas of git a git user is rarely exposed to.</p>

<p>The goal of this exercise was to go <em>wide not deep</em>. I will take certain shortcuts and omissions in order to implement a very minimal yet functional clone command.</p>

<p>The source code for what follows can be found here:</p>

<p><a href="https://bitbucket.org/ssaasen/git-in-haskell-from-the-bottom-up">https://bitbucket.org/ssaasen/git-in-haskell-from-the-bottom-up</a></p>

<p><em>Note: There are a number of git related Haskell implementations and libraries already out there (e.g. <a href="http://evan-tech.livejournal.com/254793.html">gat - a git clone in Haskell</a> or a number of git related packages on <a href="http://hackage.haskell.org/packages/archive/pkg-list.html">hackage</a>) that I wasn’t interested in for the purpose of this exercise (learning from the bottom up). If you are after a Haskell git library those implementations are likely to be much better suited.</em></p>

<h2 id="overview">Overview</h2>

<p>In order to implement <code>git clone</code> the following areas will be covered:</p>

<ul>
  <li>The <strong>git protocol</strong> used to enable a git client to retrieve the required set of changes from a remote git server using a variety of transport mechanisms (native git protocol, ssh, http),</li>
  <li>the <strong>pack file</strong> format used to transfer the minimal amount of data from the server to the client (and more generally used for efficiently storing packed objects in repositories),</li>
  <li>the underlying <strong>object store</strong> that git uses to store commits, trees, tags and the actual file contents in the form of blobs</li>
  <li>and the <strong>index format</strong> used to track changes to the files in the working directory.</li>
</ul>

<p>While some of those areas are covered elsewhere (e.g. the fantastic article <a href="http://ftp.newartisans.com/pub/git.from.bottom.up.pdf">Git from the bottom up</a> covers the low level commands and the design of the git object store in great detail) this article tries to tie together the areas mentioned above, describes the tools used to investigate and verify the observed behaviour and to hopefully provide enough detail for the reader to re-implement the <code>git clone</code> command in a language of their choosing.</p>

<p>At the end of the article we will be able to execute:</p>

<div><div><pre><code>$&gt; hgit clone git://github.com/juretta/git-pastiche.git # Where hgit is the name for our custom binary
</code></pre></div></div>

<p>and we will get a valid git repository that can be used with the normal git client without making use of git or any git libraries for the actual clone and repository setup part. To keep the implementation focused, only the <code>git://</code> transport protocol will be supported and the client will only do full, but not shallow clones.</p>

<p>In this article I’m going to use <a href="http://www.haskell.org">Haskell</a> to implement the command, mainly to avoid simply re-implementing the main C or the popular Java based JGit implementations that already exist and to be able to show code examples in a very conscise way. If you are not familiar with Haskell, simply think of the code examples as condensed pseudo code.</p>

<p>The general approach was to investigate/reverse-engineer the actual behaviour when executing the clone command, gathering debug information by different means (e.g. git debug settings, packet capture, Dtrace), researching the protocols and data structures and reading the official documentation in the git source (esp. the <code>Documentation/technical/*.txt</code> files) and last but not least reading the actual git source.</p>

<h2 id="the-clone-process">The clone process</h2>

<p>The <code>clone</code> operation goes through a set of stages.</p>

<p>It starts by invoking the command with a git URL (see the “GIT URLS” section in the <a href="http://www.kernel.org/pub/software/scm/git/docs/git-clone.html">“git clone” man page</a>  for the valid URL format):</p>

<div><div><pre><code>$&gt; git clone git://host:port/repo_path
</code></pre></div></div>

<ol>
  <li>Parse the clone url to extract the host, port and repository path information.</li>
  <li>Connect to the git server via TCP using the native git transport protocol.</li>
  <li>Negotiate the objects that need to be transferrered from the server to the client. This includes receiving the current state of the remote repository (in the form of a ref advertisement) that includes the refs the server has and for each ref the commit hash it points to.</li>
  <li>Request the required refs and receive the pack file which contains  all the objects that are reachable from the requested refs from the remote server.</li>
  <li>Create a valid git repository directory and file structure on disk.</li>
  <li>Store the objects and refs on disk.</li>
  <li>Populate the working directory with the files and directories that represent the tip of the ref the repository points to (taking into account symlink, permissions etc).</li>
  <li>Create the index file (staging area) that corresponds to that tip and the files on disk.</li>
</ol>

<p>The article will loosely follow those steps and hence cover the following three broad sections:</p>

<ul>
  <li>The git transport and pack wire protocol</li>
  <li>The pack file format</li>
  <li>The local object store and staging area</li>
</ul>

<p><img src="https://stefan.saasen.me/articles/git-clone-in-haskell-from-the-bottom-up/images/git-clone-overview@2x.png" width="900" height="226" alt="Git clone overview"/></p>

<h2 id="git-transport-and-pack-wire-protocol">Git transport and pack wire protocol</h2>

<p>In order to transfer the repository data (commits, tags, file contents, ref information) the git client and server processes negotiate the minimal amount of data required to update either the client (when fetching or cloning) or the server (when pushing).</p>

<p>git supports four main transport protocols to transfer the repository data: a local protocol if the source can be accessed via the local filesystem, and the following three protocols for remote access: SSH, a native git protocol and HTTP.</p>

<p>The remote transport protocols and the local protocol using the <code>file://</code> URL scheme share the underlying approach of connecting the various <code>*-pack</code> commands being executed on the client and server. For a fetch operation this means connecting <code>git fetch-pack</code> on the client with <code>git upload-pack</code> running on the server. For a push operation the <code>git send-pack</code> command on the client will connect to the <code>git receive-pack</code> command on the server:</p>

<!-- FIXME redo image -->
<p><img src="https://stefan.saasen.me/articles/git-clone-in-haskell-from-the-bottom-up/images/pack-client-server.png" alt="Pack commands on client and server" width="525" height="373"/></p>

<p>Note: For the clone operation instead of forking the <code>git-fetch-pack</code> command, clone invokes the <code>fetch-pack.c#fetch_pack</code> function directly via the <code>transport.c</code> layer to avoid one fork operation.</p>

<p>For easier testing and debugging the focus will be on the <em>git protocol only</em>, a simple, unauthenticated transport that uses full-duplex communication between client and server with the server usually listening on port <a href="http://www.iana.org/assignments/service-names-port-numbers/service-names-port-numbers.xml">9418</a>.</p>

<h3 id="transport-protocol">Transport protocol</h3>

<p>Repository data exchange in git happens in multiple phases (detailed information can be found in the <code>Documentation/technical/pack-protocol.txt</code> file that is part of the git repository):</p>

<ol>
  <li>Reference discovery</li>
  <li>Packfile negotiaton</li>
  <li>Packfile transfer</li>
</ol>

<h4 id="reference-discovery">Reference Discovery</h4>

<p>The reference discovery phase allows the client to detect what data the server has. The server provides this information in a list of refs that show for each ref that the server has (branches and tags) the most recent commit it has. This allows the client to determine if it is already up-to-date or what refs it needs to update the client side. The server response looks similar to this:</p>

<div lang="bash"><div><pre><code>$&gt; git ls-remote -h -t git://github.com/git/git.git | head -n 10
3a3101c62ecfbde184934f590bab5d84d7ae64a0        refs/heads/maint
21ccebec0dd1d7e624ea2f22af6ac93686daf34f        refs/heads/master
2c8b7bf47c81acd2a76c1f9c3be2a1f102b76d31        refs/heads/next
d17d3d235a4cd1cb1c6840b4a5d99d651c714cc9        refs/heads/pu
5f3c2eaeab02da832953128ae3af52c6ec54d9a1        refs/heads/todo
d5aef6e4d58cfe1549adef5b436f3ace984e8c86        refs/tags/gitgui-0.10.0
3d654be48f65545c4d3e35f5d3bbed5489820930        refs/tags/gitgui-0.10.0^{}
33682a5e98adfd8ba4ce0e21363c443bd273eb77        refs/tags/gitgui-0.10.1
729ffa50f75a025935623bfc58d0932c65f7de2f        refs/tags/gitgui-0.10.1^{}
ca9b793bda20c7d011c96895e9407fac2df9648b        refs/tags/gitgui-0.10.2
</code></pre></div></div>

<p><em>Note</em>: <code>git ls-remote</code> can be used to list references in a remote repository. This happens to be the same remote lookup of refs that occurs during the initial clone phase <sup id="fnref:1" role="doc-noteref"><a href="#fn:1" rel="footnote">1</a></sup> (this is called the ref advertisement or reference discovery step).</p>

<h4 id="capabilities">Capabilities</h4>

<p>As part of the reference discovery, client and server exchange information about capabilities the server supports. The client can then request certain capabilities to be in effect for the subsequent communication.</p>

<p>The capabilites are communicated as part of the first ref the server returns, separated from the <code>SHA1</code>, <code>ref name</code> pair by a <code>\NUL</code> byte:</p>

<div lang="bash"><div><pre><code>3b1031798a00fdf9b574b5857b1721bc4b0e6bac HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow no-progress include-tag multi_ack_detailed agent=git/1.8.1
</code></pre></div></div>

<p>The capabilities are described in detail in <code>Documentation/technical/protocol-capabilities.txt</code> and will be explained later on when they become relevant for the implementation.</p>

<h4 id="packfile-negotiation">Packfile negotiation</h4>

<p>After reference and capability discovery, client and server try to determine the minimal packfile required for the client or server to be updated.</p>

<p>In the simplest scenario of a full clone, the client requests all refs and all the required objects the server has. For subsequent updates (e.g. <code>fetch</code>), the client not only defines what it wants, but tells that server what refs it has so that the server can determine the minimal packfile to send down to the client.</p>

<h3 id="packet-line-format">Packet line format</h3>

<p>git’s protocol payload makes extensive use of the so called packet line (or <code>pkt-line</code> as used in the technical documentation) format. A <code>pkt-line</code> is a variable length binary string with the length encoded in the first four bytes of the <code>pkt-line</code>.</p>

<p>Example:</p>

<div><div><pre><code>003f3b1031798a00fdf9b574b5857b1721bc4b0e6bac refs/heads/master\n
</code></pre></div></div>

<p>The first four bytes <code>003f</code> are the length of the entire string (including the leading 4 length bytes) in hexadecimal (<code>003f</code> hex = 63 dec).</p>

<p>This can be implemented as follows (for avid Haskellers: <em>I’m trying to avoid pointfree style for the examples in this text</em>):</p>

<div lang="haskell"><div><pre><code>-- Create a packet line prefixed with the overall length. Length is 4 byte, hexadecimal, padded with 0
pktLine :: String -&gt; String
pktLine msg = printf &#34;%04s%s&#34; (toHex . (4 +) $ length msg) msg
</code></pre></div></div>

<p>The <code>pkt-line</code> with length 0, i.e. <code>0000</code> is called the <code>flush-pkt</code>. A special case packet line that is used to signal that an agreed upon handover point in the communication exchange is reached.</p>

<p>The following table (taken from <code>Documentation/technical/protocol-common.txt</code>) shows a few <code>pkt-line</code> examples:</p>

<table>
  <thead>
    <tr>
      <th>pkt-line</th>
      <th>actual value</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>“0006a\n”</td>
      <td>“a\n”</td>
    </tr>
    <tr>
      <td>“0005a”</td>
      <td>“a”</td>
    </tr>
    <tr>
      <td>“000bfoobar\n”</td>
      <td>“foobar\n”</td>
    </tr>
    <tr>
      <td>“0004”</td>
      <td>””</td>
    </tr>
  </tbody>
</table>

<h3 id="client---server-exchange">Client - Server exchange</h3>

<p>To get an intuition for how the git protocol works, it’s best to try and observe the communication between client and server.</p>

<p>A simple git server can be started by using the following command in the parent directory of one or more git repositories:</p>

<div><div><pre><code>$&gt; cd /path/to/git/repos # there are 3 git repositories here
$&gt; ls 
git-bottom-up spy zlib
$&gt; git daemon --reuseaddr --verbose  --base-path=. --export-all
[39932] Ready to rumble
</code></pre></div></div>

<ul>
  <li><code>--base-path=.</code> will map clone attempts using <code>git://example.com/hello</code> to the path <code>./hello</code></li>
  <li><code>--export-all</code> enables cloning from all directories that look like git repositories. Otherwise <code>git daemon</code> verifies that the directory has the magic file <code>git-daemon-export-ok</code> before exporting any repository data. See <a href="http://www.kernel.org/pub/software/scm/git/docs/git-daemon.html">git-daemon</a> for further information.</li>
</ul>

<p>With the git server running and having access to an existing git repository (which should be a bare repository without a working copy) we can now observe the exchange between client and server.</p>

<div lang="bash"><div><pre><code>$&gt; export GIT_TRACE_PACKET=1
$&gt; git ls-remote git://127.0.0.1/git-bottom-up
packet:          git&gt; git-upload-pack /git-bottom-up\0host=127.0.0.1\0
packet:          git&lt; 3b1031798a00fdf9b574b5857b1721bc4b0e6bac HEAD\0multi_ack thin-pack side-band side-band-64k ofs-delta shallow no-progress include-tag multi_ack_detailed agent=git/1.8.1
packet:          git&lt; 3b1031798a00fdf9b574b5857b1721bc4b0e6bac refs/heads/master
packet:          git&lt; c4bf7555e2eb4a2b55c7404c742e7e95017ec850 refs/remotes/origin/master
packet:          git&lt; 0000
packet:          git&gt; 0000
3b1031798a00fdf9b574b5857b1721bc4b0e6bac	HEAD
3b1031798a00fdf9b574b5857b1721bc4b0e6bac	refs/heads/master
c4bf7555e2eb4a2b55c7404c742e7e95017ec850	refs/remotes/origin/master
</code></pre></div></div>

<p>Git has a number of debug settings that can be enabled by setting various environment variables. Setting <code>GIT_TRACE_PACKET</code> enables log output with information about the packets the client and server exchange.  Apart from the <code>GIT_TRACE_PACKET</code> flag, the following environment variables are useful for debugging git commands:</p>

<ul>
  <li><code>GIT_TRACE_PACKET</code> - show packet line information</li>
  <li><code>GIT_TRACE</code>        - show general command execution debug information</li>
  <li><code>GIT_CURL_VERBOSE</code> - show curl debug information when using the http transport (includes HTTP headers)</li>
  <li><code>GIT_DEBUG_SEND_PACK</code> - enable debug output in <code>upload-pack</code></li>
  <li><code>GIT_TRANSPORT_HELPER_DEBUG</code> - enables debug output for the <a href="https://www.kernel.org/pub/software/scm/git/docs/git-remote-helpers.html">remote helpers</a></li>
</ul>

<p>As can be seen in the above output, the <code>GIT_TRACE_PACKET</code> output shows the packet lines <em>after</em> decoding and stripping the length field. To see what is actually exchanged on the wire, it is necessary to capture the data packets using tools like <a href="http://www.tcpdump.org/">Tcpdump</a>, <a href="http://www.wireshark.org/">Wireshark</a> or as used in this case: <a href="http://ngrep.sourceforge.net/">ngrep</a>:</p>

<div lang="bash"><div><pre><code>$&gt; sudo ngrep -P &#34;*&#34; -d lo0 -W byline port 9418 and dst host localhost
interface: lo0 (127.0.0.0/255.0.0.0)
filter: (ip) and ( port 9418 and dst host localhost )
#####
T 127.0.0.1:49949 -&gt; 127.0.0.1:9418 [AP]
0032git-upload-pack /git-bottom-up*host=127.0.0.1*
##
T 127.0.0.1:9418 -&gt; 127.0.0.1:49949 [AP]
00ab3b1031798a00fdf9b574b5857b1721bc4b0e6bac HEAD*multi_ack thin-pack side-band side-band-64k ofs-delta shallow no-progress include-tag multi_ack_detailed agent=git/1.8.1

##
T 127.0.0.1:9418 -&gt; 127.0.0.1:49949 [AP]
003f3b1031798a00fdf9b574b5857b1721bc4b0e6bac refs/heads/master

##
T 127.0.0.1:9418 -&gt; 127.0.0.1:49949 [AP]
0048c4bf7555e2eb4a2b55c7404c742e7e95017ec850 refs/remotes/origin/master

##
T 127.0.0.1:9418 -&gt; 127.0.0.1:49949 [AP]
0000
##
T 127.0.0.1:49949 -&gt; 127.0.0.1:9418 [AP]
0000
</code></pre></div></div>

<p>This shows the actual exchange on the wire, with <code>*</code> as a placeholder for the non printable characters. <em>Note: If you follow along, please update the interface to listen on, <code>lo0</code> is the loopback interface on Mac OS X/BSD, it’s most likely <code>lo</code> on Linux - check with <code>ifconfig</code></em>.</p>

<p>To simulate low bandwidth/high latency scenarios which sometimes makes debugging easier, I found using <code>dummynet</code> via <code>ipfw</code> as a traffic shaping tool useful.</p>

<p>To limit the bandwidth to 20KByte/s for the git native protocol port <code>9418</code> use:</p>

<div lang="bash"><div><pre><code>$&gt; sudo ipfw pipe 1 config bw 20KByte/s
$&gt; sudo ipfw add 1 pipe 1 src-port 9418
</code></pre></div></div>

<p>To remove the bandwidth limit afterwards:</p>



<p>This is useful to observe fast local executions that would otherwise be hard to capture.</p>

<p>With the necessary tooling to verify and observe the behaviour we can now look into implementing a client that speaks the git transport protocol.</p>

<h3 id="implementing-ref-discovery">Implementing ref discovery</h3>

<p>To initiate the ref discovery, the client establishes a TCP socket connection to the server on port 9418 and issues a single command in packet line format.</p>

<p>The ABNF for the discovery request is:</p>

<div lang="bash"><div><pre><code>git-proto-request = request-command SP pathname NUL [ host-parameter NUL ]
request-command   = &#34;git-upload-pack&#34; / &#34;git-receive-pack&#34; / &#34;git-upload-archive&#34;   ; case sensitive
pathname          = *( %x01-ff ) ; exclude NUL
host-parameter    = &#34;host=&#34; hostname [ &#34;:&#34; port ]
</code></pre></div></div>

<p>An example upload-pack request in packet line format is:</p>

<div><div><pre><code>0032git-upload-pack /git-bottom-up\0host=localhost\0
</code></pre></div></div>

<p>Here <code>localhost</code> is the target host and <code>/git-bottom-up</code> the repository path on the target system. Note that by requesting the <code>upload-pack</code> to be used on the remote end we initiate a <code>clone/fetch/ls-remote</code> request used to transfer data from the server to the client.</p>

<p>The following example defines a function that will construct the initial request command:</p>

<div><div><pre><code>gitProtoRequest :: String -&gt; String -&gt; String
gitProtoRequest host repo = pktLine $ &#34;git-upload-pack /&#34; ++ repo ++ &#34;\0host=&#34;++host++&#34;\0&#34;
</code></pre></div></div>

<p>This allows us to create a minimal client that implements <code>ls-remote</code> as follows:</p>

<div lang="haskell"><div><pre><code>data Remote = Remote {
    getHost         :: String
  , getPort         :: Maybe Int
  , getRepository   :: String
} deriving (Eq, Show)

lsRemote&#39; :: Remote -&gt; IO [PacketLine]
lsRemote&#39; Remote{..} = withSocketsDo $
    withConnection getHost (show $ fromMaybe 9418 getPort) $ \sock -&gt; do
        let payload = gitProtoRequest getHost getRepository
        send sock payload
        response &lt;- receive sock
        send sock flushPkt -- Tell the server to disconnect
        return $ parsePacket $ L.fromChunks [response]
</code></pre></div></div>

<p>This</p>

<ul>
  <li>creates a TCP connection to the given <code>Remote</code> (extracted from the git URL),</li>
  <li>sends a protocol request in packet line format,</li>
  <li>reads the response from the socket,</li>
  <li>sends a flush packet (<code>0000</code>) to terminated the connection,</li>
  <li>parses the response into a <code>PacketLine</code> data structure (this is mainly to easily extract the capabilities later on)</li>
</ul>

<p>This uses the following fully functionining and complete git protocol <a href="https://bitbucket.org/ssaasen/git-bottom-up/src/master/src/Git/TcpClient.hs">TCP client</a>:</p>

<div lang="haskell"><div><pre><code>{-# LANGUAGE OverloadedStrings, ScopedTypeVariables, BangPatterns #-}

-- | A git compatible TcpClient that understands the git packet line format.
module Git.Remote.TcpClient (
   withConnection
 , send
 , receiveWithSideband
 , receiveFully
 , receive
) where

import qualified Data.ByteString.Char8 as C
import qualified Data.ByteString as B
import Network.Socket hiding                    (recv, send)
import Network.Socket.ByteString                (recv, sendAll)
import Data.Monoid                              (mempty, mappend)
import Numeric                                  (readHex)

withConnection :: HostName -&gt; ServiceName -&gt; (Socket -&gt; IO b) -&gt; IO b
withConnection host port consumer = do
    sock &lt;- openConnection host port
    r &lt;- consumer sock
    sClose sock
    return r


send :: Socket -&gt; String -&gt; IO ()
send sock msg = sendAll sock $ C.pack msg


-- | Read packet lines.
receive :: Socket -&gt; IO C.ByteString
receive sock = receive&#39; sock mempty
    where receive&#39; s acc = do
            maybeLine &lt;- readPacketLine s
            maybe (return acc) (receive&#39; s . mappend acc) maybeLine

-- =================================================================================

openConnection :: HostName -&gt; ServiceName -&gt; IO Socket
openConnection host port = do
        addrinfos &lt;- getAddrInfo Nothing (Just host) (Just port)
        let serveraddr = head addrinfos
        sock &lt;- socket (addrFamily serveraddr) Stream defaultProtocol
        connect sock (addrAddress serveraddr)
        return sock

-- | Read a git packet line (variable length binary string prefixed with the overall length). 
-- Length is 4 byte, hexadecimal, padded with 0.
readPacketLine :: Socket -&gt; IO (Maybe C.ByteString)
readPacketLine sock = do
        len &lt;- readFully mempty 4
        if C.null len then return Nothing else -- check for a zero length return -&gt; server disconnected
            case readHex $ C.unpack len of
                ((l,_):_) | l &gt; 4 -&gt; do
                     line &lt;- readFully mempty (l-4)
                     return $ Just line
                _                 -&gt; return Nothing
    where readFully acc expected = do
            line &lt;- recv sock expected
            let len  = C.length line
                acc&#39; = acc `mappend` line
                cont = len /= expected &amp;&amp; not (C.null line)
            if cont then readFully acc&#39; (expected - len) else return acc&#39;
</code></pre></div></div>

<p>Apart from the usual ceremony to set up and connect the socket, the <code>readPacketLine</code> function contains the git specific part of the TcpClient.</p>

<p>The first step is to read 4 bytes from the socket to determine how many bytes to read to fully consume a packet line. <code>readFully</code> is a recursive function that is used to ensure to read the requested number of bytes from the socket as the contract for <code>recv</code> does not guarantee that the requested number of bytes can be read at once.</p>

<p>Depending on the length of the packet line we consume the rest of the packet line or return <code>Nothing</code>. If the length signals that we received an empty packet (i.e. <code>0004</code> or a flush packet <code>0000</code>) we stop reading and return <code>Nothing</code> (note: for readers unfamiliar with Haskell, Haskell’s return is quite different to the return used in imperative languages where it terminates the execution, in Haskell it is used to wrap a pure value in a container, here the <code>IO</code> monad).</p>

<p>After the server returns the ref advertisement the client can terminate the connection by sending a flush packet (<code>0000</code> - e.g. if the client is already up to date) or enter the negotiation phase the determines the optimal pack file to send from the server to the client.</p>

<h3 id="implementing-pack-file-negotiation">Implementing pack file negotiation</h3>

<p>Now that the client has knowledge about all the refs the server advertised it can now request the refs it needs from the server. The clone use case is the simplest use case as a full clone simply requests all the refs the server has.</p>

<p>Thus the general flow is:</p>

<div><div><pre><code>Client -&gt; Initate proto request
          Ref advertisement                     &lt;- Server
Client -&gt; Negotiation request (list of refs the client wants)
          Send packfile                         &lt;- Server
</code></pre></div></div>

<p>The (for the clone case) simplified ABNF for a protocol request looks like this:</p>

<div lang="bash"><div><pre><code>upload-request    =  want-list
        		       flush-pkt
want-list         =  first-want
        		       *additional-want
first-want        =  PKT-LINE(&#34;want&#34; SP obj-id SP capability-list LF)
additional-want   =  PKT-LINE(&#34;want&#34; SP obj-id LF)
</code></pre></div></div>

<p>The client list all the commit ids it wants, prefixed by <code>want</code> using the packet line format. It adds the capabilities it wants to be in effect on the first want line:</p>

<div><div><pre><code>T(6) 127.0.0.1:55494 -&gt; 127.0.0.1:9418 [AP]
0077want 8c25759f3c2b14e9eab301079c8b505b59b3e1ef multi_ack_detailed side-band-64k thin-pack ofs-delta agent=git/1.8.2
0032want 8c25759f3c2b14e9eab301079c8b505b59b3e1ef
0032want 4574b4c7bb073b6b661abd0558a639f7a32b3f8f
</code></pre></div></div>

<p>The protocol contract requirest that at least one want command must be send and that the client cannot request a commit-id that wasn’t advertised by the server.</p>

<p>Based on the refs the client wants, the server will generate a pack file that will contain all the required refs and the objects that are reachable from those refs. The server then send pack the packfile which will be stored by the client into a temporary location to then create a local git repository.</p>

<p>This flow can be easily observed in the two following functions the client uses to implement the clone operation. The <code>receivePack</code> implements the packfile negotiation and returns both the actual raw pack file (as a strict ByteString) and the list of refs that the server advertised. That list will later on be used to recreate the refs in the local repository.</p>

<div lang="haskell"><div><pre><code>receivePack :: Remote -&gt; IO ([Ref], B.ByteString)
receivePack Remote{..} = withSocketsDo $
    withConnection getHost (show $ fromMaybe 9418 getPort) $ \sock -&gt; do
        let payload = gitProtoRequest getHost getRepository
        send sock payload
        response &lt;- receive sock
        let pack    = parsePacket $ L.fromChunks [response]
            request = createNegotiationRequest [&#34;multi_ack_detailed&#34;,
                        &#34;side-band-64k&#34;,
                        &#34;agent=git/1.8.1&#34;] pack ++ flushPkt ++ pktLine &#34;done\n&#34;
        send sock request
        !rawPack &lt;- receiveWithSideband sock (printSideband . C.unpack)
        return (mapMaybe toRef pack, rawPack)
    where printSideband str = do
                        hPutStr stderr str
                        hFlush stderr
</code></pre></div></div>

<p>The <code>createNegotiationRequest</code> function creates the <code>want</code> lines the client sends back to the server, amending the first line with the capabilities that should be in effect. We need to filter the refs the server advertised. If the remote repository has any annotated tag objects, the ref advertisement will contain both the object id for the tag object and the object id for the commit the tag points to. This is called a peeled ref. If there is a peeled ref it immediately follows the tag object ref and has a <code>^{}</code> suffix. E.g.:</p>

<div lang="bash"><div><pre><code>1eeeb26fb00aec91b6927cadf2f3f8d0ecacd5a1	refs/tags/v3.2.9.rc3
db1d5f40714a47c58c13ff7d9643e8a0dec6bef8	refs/tags/v3.2.9.rc3^{}
</code></pre></div></div>

<p>We filter both the peeled refs and only include refs that are in the <code>refs/heads</code> and <code>refs/tags</code> namespace:</p>

<div lang="haskell"><div><pre><code>-- PKT-LINE(&#34;want&#34; SP obj-id SP capability-list LF)
-- PKT-LINE(&#34;want&#34; SP obj-id LF)
createNegotiationRequest :: [String] -&gt; [PacketLine] -&gt; String
createNegotiationRequest capabilities = concatMap (++ &#34;&#34;) . nub . map (pktLine . (++ &#34;\n&#34;)) . foldl&#39; (\acc e -&gt; if null acc then first acc e else additional acc e) [] . wants . filter filterPeeledTags . filter filterRefs
                    where wants              = mapMaybe toObjId
                          first acc obj      = acc ++ [&#34;want &#34; ++ obj ++ &#34; &#34; ++ unwords capabilities]
                          additional acc obj = acc ++ [&#34;want &#34; ++ obj]
                          filterPeeledTags   = not . isSuffixOf &#34;^{}&#34; . C.unpack . ref
                          filterRefs line    = let r = C.unpack $ ref line
                                                   predicates = map ($ r) [isPrefixOf &#34;refs/tags/&#34;, isPrefixOf &#34;refs/heads/&#34;]
                                               in or predicates
</code></pre></div></div>

<p>One capability we want to have in effect is the <code>side-band</code> capability. This instructs the server to send multiplexed progress reports and error info interleaved with the packfile itself (see <code>Documentation/technical/protocol-capabilities.txt</code>). The <code>side-band</code> and <code>side-band-64k</code> capabilites are mutually exclusive and only differ in the size of the payload packets git will use (1000 bytes vs 65520 bytes in the case of <code>side-band-64k</code>).</p>

<p>The <code>receiveWithSideband</code> function knows how to demultiplex the pack file response:</p>

<div lang="haskell"><div><pre><code>receiveWithSideband :: Socket -&gt; (B.ByteString -&gt; IO a) -&gt; IO B.ByteString
receiveWithSideband sock f = recrec mempty
    where recrec acc = do
            !maybeLine &lt;- readPacketLine sock
            let skip = recrec acc
            case maybeLine of
                Just &#34;NAK\n&#34; -&gt; skip -- ignore here...
                Just line -&gt; case B.uncons line of
                                Just (1, rest)  -&gt; recrec (acc `mappend` rest)
                                Just (2, rest)  -&gt; f (&#34;remote: &#34; `C.append` rest) &gt;&gt; skip -- FIXME - scan for linebreaks and prepend &#34;remote: &#34; accordingly (see sideband.c)
                                Just (_, rest)  -&gt; fail $ C.unpack rest
                                Nothing         -&gt; skip
                Nothing   -&gt; return acc
</code></pre></div></div>

<p>It reads the first byte that comes after the packet line length. The sideband channel indicators are:</p>

<ul>
  <li><code>1</code> the remainder of the packet line is a chunk of the pack file - this is the payload channel</li>
  <li><code>2</code> this is progress information that the server sends - the client prints that on STDERR prefixed with <code>remote: &#34;</code></li>
  <li><code>3</code> this is error infomration that will cause the client to print out the message on STDERR and exit with an error code (not implemented in our example)</li>
</ul>

<p>This the <code>clone&#39;</code>function:</p>

<div lang="haskell"><div><pre><code>clone&#39; :: GitRepository -&gt; Remote -&gt; IO ()
clone&#39; repo remote@Remote{..} = do
        (refs,packFile) &lt;- receivePack remote
        let dir = pathForPack repo
            -- E.g. in native git this is something like .git/objects/pack/tmp_pack_6bo2La
            tmpPack = dir &lt;/&gt; &#34;tmp_pack_incoming&#34;
        _ &lt;- createDirectoryIfMissing True dir
        B.writeFile tmpPack packFile
        _ &lt;- runReaderT (createGitRepositoryFromPackfile tmpPack refs) repo
        removeFile tmpPack
        runReaderT checkoutHead repo
</code></pre></div></div>

<ul>
  <li>Receives the pack file and the list of advertised refs</li>
  <li>Writes the pack file to a known temporary location</li>
  <li>Parses the pack file and then</li>
  <li>Checks out the <code>HEAD</code> in the working directory</li>
</ul>

<p>To understand and implement the last two steps we next have a closer look at the pack file format.</p>

<!--
FIXME: Here diagram of the general flow of request -> ref advertisement -> pack file
-->

<h2 id="pack-file-format">Pack file format</h2>

<p>The pack file is used to efficiently transfer or store a number of git objects. When used as a storage optimization the <code>*.pack</code> file is accompanied by an index file that allows efficient lookup of objects in the pack file. When used as a transfer mechanism the pack file will be transfered as is and the index created locally.</p>

<p>The pack format is described in <a href="https://bitbucket.org/ssaasen/git/src/master/Documentation/technical/pack-format.txt">Documentation/technical/pack-format.txt</a> in the git source.</p>

<p>The packfile consists of:</p>

<ul>
  <li>A 12 byte pack <strong>file header</strong> with:
    <ul>
      <li>a 4-byte magic byte with the value <code>&#39;P&#39; &#39;A&#39; &#39;C&#39; &#39;K&#39;</code> (decimal <code>1346454347</code>)</li>
      <li>a 4 byte pack file version</li>
      <li>a 4 byte number of objects in the packfile</li>
    </ul>
  </li>
  <li><code>n</code> <strong>objects</strong> with
    <ul>
      <li>a variable length object header that contains the type of object (see below) and the length of the inflated/uncompressed data that follows</li>
      <li><em>only</em> for deltified objects: the 20 byte base object name (for objects of type <code>OBJ_REF_DELTA</code>) or a relative (negative) offset from the delta object’s
  position in the pack for objects of type <code>OBJ_OFS_DELTA</code> - see below).</li>
      <li>zlib deflated/compressed object data</li>
    </ul>
  </li>
  <li>A 20 byte SHA1 <strong>checksum</strong> of all of the above as trailer</li>
</ul>

<p>The objects in the pack file are commit, tag, tree and blob objects. A deltified object has a pointer to a base object and as its payload the delta between the base version and the subsequent version of that object. See below for a discussion of the delta encoding git uses.</p>

<p><img src="https://stefan.saasen.me/articles/git-clone-in-haskell-from-the-bottom-up/images/packfile@2x.png" width="850" height="821" alt="Pack file format"/></p>

<p>Before we further investigate the pack file format it’s worth pointing out a few tools and commands that can be used to get a better understanding about how objects are represented in the pack file.</p>

<p>The <code>git verify-pack</code> command can be used to validate pack files. This only works for <code>*.pack</code> files though that have an accompanying index file.</p>

<div lang="bash"><div><pre><code>[4888] λ &gt; git verify-pack -v .git/objects/pack/pack-85376214c718d1638a7aa83af4d20302d3fd8efc.pack
2486a54b0fa69143639407f94082cab866a91e08 commit 228 153 12
e8aa4319f3fe937cfb498bf944fa9165078d8245 commit 179 122 165
0376e0620690b259bfc8e381656c07217e4f0b8c tree   317 299 287
d06be33046be894124d2c1d86af7230f17773b3f blob   74 72 586
812387998220a52e6b50cce4a11abc65bbc1ec97 blob   22 29 658
60596d939fad1364fa0b179828b4406761463b8d blob   1466 778 687
42d5f4d92691c3b90b2b66ecb79dfb60773fa1a1 blob   1109 452 1465
99618348415a3a0f78222e54c03c51e638fbad41 blob   466 340 1917 1 42d5f4d92691c3b90b2b66ecb79dfb60773fa1a1
</code></pre></div></div>

<p>An entry for a non deltified object has the following format:</p>

<div lang="bash"><div><pre><code>SHA1 type size size-in-pack-file offset-in-packfile
</code></pre></div></div>

<p>Entries for deltified objects use:</p>

<div lang="bash"><div><pre><code>SHA1 type size size-in-packfile offset-in-packfile depth base-SHA1
</code></pre></div></div>

<p>This comes in handy when implementing the code that reads and recreates the objects stored in the pack file.</p>

<p>Another built-in command is <code>git unpack-objects</code>, a command that creates loose object files from a pack file and doesn’t require an index file to be present. It therefore can be used on the packfile received from a remote repository for which there is no index file yet. This command needs to be executed in an existing git repository and the objects contained in the pack file will be unpacked into the <code>.git/objects</code> directory of that repository:</p>

<div><div><pre><code>git unpack-objects --strict &lt; test-pack.pack
</code></pre></div></div>

<p>Any suitable hexeditor (e.g. <code>xxd</code>, <code>od</code> or <a href="http://ridiculousfish.com/hexfiend/">HexFiend</a>, a GUI application on the Mac) is useful when it comes to reading and comparing the pack file data.</p>

<p><em>Note:</em> As part of the git clone process, the pack file needs to be read and understood to validate the objects that come in by comparing the checksums and to generate an index file for the pack that is stored in the local repository. For this clone implementation I’m unpacking the pack file into loose objects (one file per object) instead to simplify the streaming pack file handling - this is merely a shortcut though as it unnecessarily creates a large number of object files which makes cloning of large repositories slower than it needs to be.</p>



<p>Reading the pack file header is trivial. The <code>parsePackFile</code> function reads the first 12 bytes in 4 byte groups (using big endian with the <em>M</em>ost <em>S</em>ignificant <em>B</em>yte first). It compares the magic byte to ensure we are reading a git pack file and then continues reading the number of objects the pack file header defines:</p>

<div lang="haskell"><div><pre><code>parsePackFile :: I.Iteratee ByteString IO Packfile
parsePackFile = do
    magic       &lt;- endianRead4 MSB -- 4 bytes, big-endian
    version&#39;    &lt;- endianRead4 MSB
    numObjects&#39; &lt;- endianRead4 MSB
    if packMagic == magic
                then parseObjects version&#39; numObjects&#39;
                else return InvalidPackfile
  where packMagic = fromOctets $ map (fromIntegral . ord) &#34;PACK&#34;
</code></pre></div></div>

<h3 id="pack-file-objects">Pack file objects</h3>

<p>The pack file object header uses a variant of a <a href="http://en.wikipedia.org/wiki/Variable-length_quantity">variable length</a> unsigned integer encoding that contains the object type in the first byte.</p>

<p>That first byte consists of:</p>

<ul>
  <li>The most significant bit (MSB) that determines whether we need to read more bytes to get the encoded object size (if the MSB is set we read the next byte)</li>
  <li>3 bits with the object type (from <a href="https://bitbucket.org/ssaasen/git/src/master/cache.h#cl-326"><code>cache.h</code></a>):
    <ul>
      <li><code>OBJ_COMMIT</code> = 1</li>
      <li><code>OBJ_TREE</code> = 2</li>
      <li><code>OBJ_BLOB</code> = 3</li>
      <li><code>OBJ_TAG</code> = 4</li>
      <li><code>OBJ_OFS_DELTA</code> = 6</li>
      <li><code>OBJ_REF_DELTA</code> = 7</li>
    </ul>
  </li>
  <li>4 bits with the size (partial size if the MSB is set and more bytes need to be read)</li>
</ul>

<p>The following bytes after the first byte contain parts of the overall length in the least significant 7 bits of the octet while the MSB is again used to indicate whether more bytes need to be read.</p>

<p>The following diagram shows an example consisting of two octets:</p>

<p><img src="https://stefan.saasen.me/articles/git-clone-in-haskell-from-the-bottom-up/images/pack-object-header@2x.png" alt="Pack object header" width="800" height="211"/></p>

<p>Reading the object header is straightforward, we read one byte, extract the object type, initial size information from the lower nibble and whether to continue reading size information by looking at the MSB:</p>

<div lang="haskell"><div><pre><code>byte &lt;- I.head -- read 1 byte
let objectType  = byte `shiftR` 4 .&amp;. 7      -- shift right and bitwise AND
                                             -- to mask the bit that was the MSB before shifting
    initialSize = fromIntegral $ byte .&amp;. 15 -- mask type and MSB
-- recursivley read the following bytes if the MSB is set
size &lt;- if isMsbSet byte then parseObjectSize initialSize 0 else return initialSize
</code></pre></div></div>

<p>To check whether the most significant bit is set we define the <code>isMsbSet</code> function that we will use in other places:</p>

<div><div><pre><code>isMsbSet x = (x .&amp;. 0x80) /= 0  -- 0x80 = 128 decimal
</code></pre></div></div>

<p>The following bytes are even simpler to read as we only care about the 7 least significant bits:</p>

<div lang="haskell"><div><pre><code>parseObjectSize size&#39; iter = do
    nextByte &lt;- I.head
    let add           = (coerce (nextByte .&amp;. 127) :: Int) `shiftL` (4 + (iter * 7)) -- shift depends on the number of iterations
        acc           = size&#39; + fromIntegral add
    if isMsbSet nextByte then
        parseObjectSize acc (iter + 1)
    else
        return acc
    where coerce = toEnum . fromEnum
</code></pre></div></div>

<p>The overall length is then:</p>

<div><div><pre><code>size0 + size1 + … + sizeN
</code></pre></div></div>

<p>after shifting each part <code>0, 4 + (n-1) * 7</code> to the left. <code>size0</code> is the least, <code>sizeN</code> the most significant part.</p>

<p>After reading the last byte of the object header we have the size of the inflated/uncompressed object and its type.</p>

<p>While Haskell is usually very concise, the C implementation admittedly achieves the same with a lot less fanfare:</p>

<div><div><pre><code>type = (c &gt;&gt; 4) &amp; 7;
size = (c &amp; 15);
shift = 4;
while (c &amp; 0x80) {
	pack = fill(1);
	c = *pack;
	use(1);
	size += (c &amp; 0x7f) &lt;&lt; shift;
	shift += 7;
}  
</code></pre></div></div>

<p>Back to our Haskell implementation, here is the full definition of the function to read a single pack file object is (see <a href="https://bitbucket.org/ssaasen/git-in-haskell-from-the-bottom-up/src/master/src/Git/Pack/Packfile.hs">src/Git/Pack/Packfile.hs</a>):</p>

<div lang="haskell"><div><pre><code>parsePackObject :: I.Iteratee ByteString IO (Maybe PackfileObject)
parsePackObject = do
    byte &lt;- I.head -- read 1 byte
    let objectType&#39; = byte `shiftR` 4 .&amp;. 7 -- shift right and masking the 4th least significtan bit
        initial     = fromIntegral $ byte .&amp;. 15
    size&#39; &lt;- if isMsbSet byte then parseObjectSize initial 0 else return initial
    obj &lt;- toPackObjectType objectType&#39;
    !content &lt;- I.joinI $ enumInflate Zlib defaultDecompressParams I.stream2stream
    return $ (\t -&gt; PackfileObject t size&#39; content) &lt;$&gt; obj

-- Map the internal representation of the object type to the PackObjectType
toPackObjectType :: (Show a, Integral a) =&gt; a -&gt; I.Iteratee ByteString IO (Maybe PackObjectType)
toPackObjectType 1  = return $ Just OBJ_COMMIT
toPackObjectType 2  = return $ Just OBJ_TREE
toPackObjectType 3  = return $ Just OBJ_BLOB
toPackObjectType 4  = return $ Just OBJ_TAG
toPackObjectType 6  = do
    offset &lt;- readOffset 0 0
    return $ Just (OBJ_OFS_DELTA offset)
toPackObjectType 7  = do 
    baseObj &lt;- replicateM 20 I.head -- 20-byte base object name SHA1
    return $ Just (OBJ_REF_DELTA baseObj)
toPackObjectType _  = return Nothing
</code></pre></div></div>

<p>Based on the type we</p>

<ul>
  <li>inflate/decompress the following bytes when the object is either a <code>commit</code>, <code>tag</code>, <code>tree</code> or <code>blob</code></li>
  <li>read the base object id or the offset if this is a deltified object (i.e. when the object type is either <code>6</code> or <code>7</code>) and then the compressed delta data</li>
</ul>

<p>An interesting challenge is the fact that the pack file object header contains the size of the <em>uncompressed</em> object, but not the size of the <em>compressed</em> object. In order to read the objects the only way to identify object boundaries (i.e. where in the pack file the next object starts) is to actually inflate the zlib compressed data and thus consuming the following bytes that are part of the zlib compressed content. While the zlib API in C (i.e. <code>inflate()</code>) indicates whether it has reached the end of the compressed data and has produced all of the uncompressed output (see <a href="http://www.zlib.net/zlib_how.html">http://www.zlib.net/zlib_how.html</a>), I found only the Iteratee based implementation (<a href="http://hackage.haskell.org/package/iteratee-compress">iteratee-compress</a>) to be suitable for achieving the same in Haskell. The following excerpt from the <code>parsePackObject</code> function inflates the zlib compressed data from the pack file stream and creates a <code>PackfileObject</code> with the object type information, the size information from the pack and the inflated data:</p>

<div lang="haskell"><div><pre><code>    !content &lt;- I.joinI $ enumInflate Zlib defaultDecompressParams I.stream2stream
    return $ (\t -&gt; PackfileObject t size&#39; content) &lt;$&gt; obj
</code></pre></div></div>

<p>This allows the <code>Git.Pack.Packfile</code> module to fully read the pack file and to create an internal pack file representation that contains a list of <code>PackfileObject</code>s with fully inflated content.</p>

<p>Before this pack file can be written to disk we need to handle the deltified objects though as our internal representation contains a mix of deltified and undeltified (i.e. complete) objects.</p>

<h3 id="delta-encoding">Delta encoding</h3>

<p>The deltified representations (pack file object types 6 &amp; 7) in the packfile use delta compression to minimize the amount of data that needs to be transferred and/or stored. Deltification <em>only</em> happens in pack files.</p>

<p>The following (from <a href="http://mail.xmailserver.net/xdfs.pdf" title="File System Support for Delta Compression">“File System Support for Delta Compression”</a>) gives a good general definition of delta compression:</p>

<blockquote>
  <p>Delta compression consists of representing a target version’s contents as the mutation 
(delta) of some existing source contents to achieve the same goal, a reduction in space or 
time. Typically, the target and source are related file versions and have similar contents.</p>
</blockquote>

<p>Thus delta encoding allows file versions to be recreated based on an original source file and one or more delta files. Subsequent delta files can be applied to the patched result of the previous delta file and its source (called the “delta chain” in git - the <code>git verify-pack</code> command will print a histogram of the delta chain length when invoked with the <code>--verbose</code> flag). An important attribute of the delta encoding is the fact that it can be used for both <strong>binary and text</strong> files.</p>

<p>The delta compression algorithm that is used in git was originally based on <a href="http://xdelta.org/">xdelta</a> and <a href="http://www.xmailserver.org/xdiff-lib.html" title="LibXDiff">LibXDiff</a> but was further simplified for the git use case (see the <a href="http://git.661346.n2.nabble.com/diff-ing-files-td6446460.html">“diff’ing files”</a> thread on the git mailinglist). The following discussion is based on the delta file format used by git and the <code>patch-delta.c</code> and <code>diff-delta.c</code> files from the git source.</p>

<h4 id="format-of-the-delta-representation">Format of the delta representation</h4>

<p>The git delta encoding algorithm is a <code>copy/insert</code> based algorithm (this is apparent in <code>patch-delta.c</code>). The delta representation contains a delta header and a series of opcodes for either <code>copy</code> or <code>insert</code> instructions.</p>

<p>From <a href="http://mail.xmailserver.net/xdfs.pdf" title="File System Support for Delta Compression">“File System Support for Delta Compression”</a>:</p>
<blockquote>
  <p>The copy/insert class of delta algorithms use a string matching technique to locate matching
offsets in the source and target versions and then emit a sequence of copy instructions 
for each matching range and insert instructions to cover the unmatched regions</p>
</blockquote>

<p>The <code>copy</code> instructions contain an offset into the source buffer and the number of bytes to copy from the source to the target buffer starting from that offset.
The <code>insert</code> opcode itself is the number of bytes to copy from the delta buffer into the target. This will contain the bytes that have been added and are not part of the source buffer at this point.</p>

<p>The delta buffer starts with a header that contains the length of the source and target buffers to be able to verify the restored/patched result. Lengths are again encoded as a variable length integer where the MSB indicates whether another var length octet follows.</p>

<p>Delta buffer layout:</p>

<div><div><pre><code>| Varint - Lengt of the source/base buffer | 
| Varint - Length of the target buffer     |
| n copy/insert instructions               |
</code></pre></div></div>

<h4 id="testing">Testing</h4>

<p>In order to test the delta encoding implementation the git source allows us to build a <code>test-delta</code> binary that can be used to generate delta data and to restore a target file from a source and delta representation.</p>

<div><div><pre><code>$&gt; cd ~/dev/git/git-source
$&gt; make configure
$&gt; ./configure
$&gt; make test-delta
</code></pre></div></div>

<p>This will generate a <code>test-delta</code> binary with a <em>d</em>elta and <em>p</em>atch mode:</p>

<div><div><pre><code>[4926] λ &gt; ./test-delta
usage: test-delta (-d|-p) &lt;from_file&gt; &lt;data_file&gt; &lt;out_file&gt;
</code></pre></div></div>

<p>Generate a delta file:</p>

<div><div><pre><code>./test-delta -d test-delta.c test-delta-new.c out.delta
</code></pre></div></div>

<p>Restore the original file based on the delta:</p>

<div><div><pre><code>./test-delta -p test-delta.c out.delta restored-test-delta-new.c
</code></pre></div></div>

<p>Verify that both are in fact the same:</p>

<div><div><pre><code>diff -q restored-test-delta-new.c test-delta-new.c
</code></pre></div></div>

<p>This workflow can then be used to generate arbitrary delta files and to test our own implementation.</p>

<h4 id="patch-algorithm-example">Patch algorithm example</h4>

<p>An example can help getting a better intuiton for how the delta encoding works.</p>

<p>In a source file (the <code>zlib.c</code> file from the git source) a function definition was moved down inside the same file and a new comment added.</p>

<p><img src="https://stefan.saasen.me/articles/git-clone-in-haskell-from-the-bottom-up/images/delta-changes@2x.png" width="550" height="497" alt="Diff"/></p>

<p>Using <code>test-delta</code> we can generate a delta file using the old and new version of this file:</p>

<div><div><pre><code>./test-delta -d zlib.c zlib-changed.c zlib-delta
</code></pre></div></div>

<p>This is the resulting delta file:</p>

<div lang="bash"><div><pre><code>[4950] λ &gt; xxd -b zlib-delta
0000000: 10010001 00101110 10101100 00101110 10110000 11010001  ......
0000006: 00000001 00010111 00101111 00100000 01010100 01101000  ../ Th
000000c: 01101001 01110011 00100000 01101001 01110011 00100000  is is
0000012: 01100001 00100000 01101110 01100101 01110111 00100000  a new
0000018: 01100011 01101111 01101101 01101101 01100101 01101110  commen
000001e: 01110100 10110011 11001110 00000001 00100111 00000001  t...&#39;.
0000024: 10110011 01011111 00000011 01101100 00010000 10010011  ._.l..
000002a: 11110101 00000010 01101011 10110011 11001011 00010011  ..k...
0000030: 01000110 00000011
</code></pre></div></div>

<p>The first step is to read the source and target lengths. The fact that the MSB of the first byte is set indicates that we need to read the next byte to get the size information so the first two bytes make up the length of the source buffer:</p>



<p>Reading the variable length integer simply boils down to:</p>

<div lang="bash"><div><pre><code>1. Mask the MSB                  10010001 &amp; 127 -&gt; 00010001 = 17
2. Left shift the 2nd byte       00101110 &lt;&lt; 7              = 5888
    by (iteration * 7). As this is the first additional byte this is (1 * 7)   
3. Bitwise OR 1st and 2nd byte   17 | 5888                  = 5905
</code></pre></div></div>

<p>which is the same approach we saw when reading the object header in the pack file. We can check that the length we read is in fact correct:</p>

<div><div><pre><code>[4868] λ &gt; wc -c zlib.c
    5905 zlib.c
</code></pre></div></div>

<p>The next two bytes are the length of the target buffer (which is 5932 bytes).</p>

<p>The significant part of the implentation for this is:</p>

<div lang="haskell"><div><pre><code>where   decodeSize offset = do
            skip offset
            byte &lt;- getWord8
            next (maskMsb byte) 7 byte $ succ offset
        next base shift byte&#39; count | isMsbSet byte&#39; = do
             b &lt;- getWord8
             let len = base .|. ((maskMsb b) `shiftL` shift)
             next len (shift + 7) b $ succ count
        next finalLen _ _ count                  = return (finalLen, count)
        maskMsb byte                             = fromIntegral $ byte .&amp;. 0x7f
</code></pre></div></div>

<p>where <code>decodeSize</code> will be called with the offset of the length information for the source (0 in this case) and target sizes (number of bytes required to represent the source size).</p>

<p>After reading the header information the remainig btyes are either <code>copy</code> or <code>insert</code> instructions.
The next byte (<code>10110000</code>)  is a <code>copy</code> instruction based on the fact that the MSB is set.
The offset into the source buffer and the number of bytes to copy can then be extracted as follows.</p>

<p>Start at the LSB:</p>

<div lang="bash"><div><pre><code>10110000 &amp; 0x01 - 1st bit not set
10110000 &amp; 0x02 - 2nd bit not set
10110000 &amp; 0x04 - 3rd bit not set
10110000 &amp; 0x08 - 4th bit not set
</code></pre></div></div>

<p>None of the offset bits are set, we don’t read any offset value so
the offset is 0. This means we copy from the start of the source
buffer.</p>

<div lang="bash"><div><pre><code>10110000 &amp; 0x10 - 5th bit is set. We read the next byte (11010001)
10110000 &amp; 0x20 - 6th bit is set. We read the next byte (00000001), left
        shift it by 8 and OR it to the previously read value:
        
        11010001 | (00000001 &lt;&lt; 8) = 209 | 256 = 465
        
00000000 &amp; 0x40 - 7th bit is not set.
</code></pre></div></div>

<p><code>465</code> is the number of bytes to copy from the source into the target buffer, starting at offset 0.</p>

<p>The next byte <code>00010111</code> (byte 8) is an insert instruction (MSB not set). The insert instruction is simply the number of bytes to copy from the delta into the target buffer.</p>

<p><em>Note</em>: Conversion between different numeric representations is quickly done in the shell using:</p>

<div lang="bash"><div><pre><code>$&gt; echo $(( 16#A4 ))      # convert hexadecimal into decimal  
164
$&gt; echo $(( 2#00010111 )) # convert binary into decimal
23
</code></pre></div></div>

<p>In this case we copy 23 bytes from the delta into the target. These are:</p>

<div lang="bash"><div><pre><code>$&gt; &lt; zlib-delta tail -c +9 | head -c 23
/ This is a new comment
</code></pre></div></div>

<p>The full set of copy/insert instructions is:</p>

<ol>
  <li>Copy 465 bytes from the source into the target, starting at offset 0</li>
  <li>Insert 23 bytes from the <em>delta</em> buffer into the target</li>
  <li>Copy 295 bytes, starting at offset 462</li>
  <li>Copy 4204 bytes, starting at offset 863</li>
  <li>Copy 107 bytes, starting at offset 757</li>
  <li>Copy 838 bytes, starting at offset 5067</li>
</ol>

<p>This can easily be verified manually:</p>

<div lang="bash"><div><pre><code>head -c 465 zlib.c &gt;&gt; manual-target-zlib.c
&lt; zlib-delta tail -c +9 | head -c 23    &gt;&gt; manual-target-zlib.c
&lt; zlib.c tail -c +463   | head -c 295   &gt;&gt; manual-target-zlib.c
&lt; zlib.c tail -c +864   | head -c 4204  &gt;&gt; manual-target-zlib.c
&lt; zlib.c tail -c +758   | head -c 107   &gt;&gt; manual-target-zlib.c
&lt; zlib.c tail -c +5068  | head -c 838   &gt;&gt; manual-target-zlib.c 
</code></pre></div></div>

<p>Which yields the same restored file:</p>

<div><div><pre><code>[4905] λ &gt; diff manual-target-zlib.c zlib-changed.c &amp;&amp; echo $?
0
</code></pre></div></div>

<p>Looking at the sizes of our test files in bytes, we can see that by using delta encoding the space requirements for files that are similar can be significantly reduced:</p>

<div lang="bash"><div><pre><code>[4908] λ &gt; wc -c zlib-delta zlib.c zlib-changed.c
  50 zlib-delta
5905 zlib.c
5932 zlib-changed.c
</code></pre></div></div>

<p>This is 5905 for the base version + 50 bytes for the delta compared to storing both versions independently ()5905 + 5932).</p>

<p>Git further reduces the space requirements by storing the base and delta objects zlib compressed in the packfile.</p>

<h4 id="implementation-of-the-delta-encoding-algorithm">Implementation of the delta encoding algorithm</h4>

<p>For the clone implementation we only need to deal with the much simpler to implement patch operation that recreates the target content based on the source and the delta. This is fortunately much easier than the task of creating a suitable delta file based on the source and target files (see <sup id="fnref:2" role="doc-noteref"><a href="#fn:2" rel="footnote">2</a></sup> for further discussion on this).</p>

<p>The main function our <code>Git.Pack.Delta</code> module exposes is the <code>patch</code> function that accepts a source and a delta bytestring (bytestrings are Haskell’s version of byte vectors/arrays) and returns the re-created target bytestring.</p>

<div lang="haskell"><div><pre><code>patch :: B.ByteString -- ^ Source/Base
      -&gt; B.ByteString -- ^ Delta
      -&gt; Either String B.ByteString
patch base delta = do
        header &lt;- decodeDeltaHeader delta
        if B.length base == sourceLength header then
            fst $ runGet (run (getOffset header) base delta) delta
        else Left &#34;Source length check failed&#34;
</code></pre></div></div>

<p>Skipping the parsing of the header that was mentioned above the main building blocks are:</p>

<div lang="haskell"><div><pre><code>-- | Parse the delta file and transform the source into the target ByteString
run :: Int -&gt; B.ByteString -&gt; B.ByteString -&gt; Get B.ByteString
run offset source delta = do
    skip offset
    cmd &lt;- getWord8
    runCommand cmd B.empty source de       
</code></pre></div></div>

<p>We skip the header based on the offset from the start of the delta to the delta payload. We read the first byte which is the opcode and execute either a copy or insert instruction using the <code>runCommand</code> function:</p>

<div lang="haskell"><div><pre><code>-- | Execute the @copy/insert@ instructions defined in the delta buffer to
-- restore the target buffer
runCommand :: Word8 -&gt; B.ByteString -&gt; B.ByteString -&gt; t -&gt; Get B.ByteString
runCommand cmd acc source delta = do
    result &lt;- choose cmd
    finished &lt;- isEmpty
    let acc&#39; = B.append acc result
    if finished then return acc&#39;
       else do
        cmd&#39; &lt;- getWord8
        runCommand cmd&#39; acc&#39; source delta
  where choose opcode | isMsbSet opcode = copyCommand opcode source
        choose opcode                   = insertCommand opcode
</code></pre></div></div>

<p>If the most significant byte is set this is a copy, otherwise it is an insert instruction. If it is an insert command the command itself is the number of bytes to copy from the delta into the target buffer so we simply apply the <code>insertCommand</code> function.</p>

<div lang="haskell"><div><pre><code>-- | Read @n@ bytes from the delta and insert them into the target buffer
insertCommand :: Integral a =&gt; a -&gt; Get B.ByteString
insertCommand = getByteString . fromIntegral
</code></pre></div></div>

<p>The copy instruction is slightly more involved and caters for larger offset (offset in the source) and size (number of bytes to copy) lengths (which is resolved using the <code>readCopyInstruction</code> function):</p>

<div lang="haskell"><div><pre><code>-- | Copy from the source into the target buffer
copyCommand :: Word8 -&gt; B.ByteString -&gt; Get B.ByteString
copyCommand opcode source = do
        (offset, len) &lt;- readCopyInstruction opcode
        return $ copy len offset source
    where copy len&#39; offset&#39;             = B.take len&#39; . B.drop offset&#39;  	

readCopyInstruction :: (Integral a) =&gt; Word8 -&gt; Get (a, a)
readCopyInstruction opcode = do
        -- off -&gt; offset in the source buffer where the copy will start
        -- this will read the correct subsequent bytes and shift them based on
        -- the set bit
        offset &lt;- foldM readIfBitSet 0 $ zip [0x01, 0x02, 0x04, 0x08] [0,8..]
        -- bytes to copy
        len&#39;   &lt;- foldM readIfBitSet 0 $ zip [0x10, 0x20, 0x40] [0,8..]
        let len = if coerce len&#39; == 0 then 0x10000 else len&#39;
        -- FIXME add guard condition from `patch-delta.c`: if (unsigned_add_overflows(cp_off, cp_size) || ...
        return $ (coerce offset, coerce len)
    where calculateVal off shift           = if shift /= 0 then (\x -&gt; off .|. (x `shiftL` shift)::Int) . fromIntegral else fromIntegral
          readIfBitSet off (test, shift)   = if opcode .&amp;. test /= 0 then liftM (calculateVal off shift) getWord8 else return off
          coerce                           = toEnum . fromEnum
</code></pre></div></div>

<p>To test the delta implementation we can use the following simple <code>main</code> function and a delta file produced by the <code>test-delta</code> command from the git source:</p>

<div lang="haskell"><div><pre><code>main :: IO ()
main = do
    (sourceFile:deltaFile:_) &lt;- getArgs
    source &lt;- B.readFile sourceFile
    delta &lt;- B.readFile deltaFile
    header &lt;- decodeDeltaHeader delta
    print header
    print $ B.length source
    either putStrLn (B.writeFile &#34;target.file&#34;) $ patch source delta
</code></pre></div></div>

<p>Using the original source and the delta this will create a patched <code>target.file</code>:</p>

<div lang="bash"><div><pre><code>$&gt; runhaskell -isrc src/Git/Pack/Delta.hs zlib.c zlib-delta
DeltaHeader {sourceLength = 5905, targetLength = 5932, getOffset = 4}
5905
</code></pre></div></div>

<p>With at working <code>patch</code> function we can now recreate the actual content based on the deltified and the base objects that are contained in the pack file.</p>

<h3 id="ref-vs-ofs-delta">Ref vs. Ofs delta</h3>

<p>The pack file format defines two different types of deltified objects: <code>OBJ_OFS_DELTA</code> and <code>OBJ_REF_DELTA</code>. They differ only in the way the base (or source) object is identified in the pack file. <code>OBJ_REF_DELTA</code> uses the 20-byte SHA1 that identifies the object, whereas <code>OBJ_OFS_DELTA</code> uses the negative offset from the delta object header in the pack file (as mentioned above in the pack file section). When delta encoding was originally added, git started with the ref based delta, the <code>OBJ_OFS_DELTA</code> object type was later introduced in <code>#eb32d236</code> mainly to reduce the size of the pack file. Whether the client supports offset based deltas in the pack file can be signaled during the pack file negotiation by setting the <code>ofs-delta</code> capability (if the server indicates that this is supported).</p>

<p>From <code>Documentation/technical/protocol-capabilities.txt</code>:</p>

<blockquote>
  <p>ofs-delta
Server can send, and client understand PACKv2 with delta referring to
its base by position in pack rather than by an obj-id.  That is, they can
send/read OBJ_OFS_DELTA (aka type 6) in a packfile.</p>
</blockquote>

<p>As a simplification for our clone implementation we <em>don’t</em> use this capability in the request and therefore only need to implement the lookup of ref based base objects.</p>

<h3 id="summary">Summary</h3>

<p>We now have</p>

<ul>
  <li>a means to read the pack file into a list of <code>PackObject</code>s that contain the inflated objects</li>
  <li>a <code>patch</code> function to recreate objects based on a base object and the delta content.</li>
</ul>

<p>We can therefore fully recreate the objects given the pack file we received.</p>

<h2 id="git-repository">Git repository</h2>

<!--
FIXME - remove http://git-scm.com/book/en/Git-Internals-Git-Objects & http://teohm.github.com/blog/2011/05/30/learning-git-internals-by-example/
-->

<p>To create a valid git repository we need to create a directory layout and a set of files that git requires to recognize this directory as a valid git repository. Conceptually the files and directories can be roughly split into the object store, refs and the index areas.</p>

<p><img src="https://stefan.saasen.me/articles/git-clone-in-haskell-from-the-bottom-up/images/git-repository.png" alt="Git Repository layout and objects"/></p>

<p>The <a href="https://www.kernel.org/pub/software/scm/git/docs/gitrepository-layout.html">Git Repository Layout man page</a> has detailed information about the contents of the git directory.</p>

<h2 id="object-store">Object store</h2>

<p>To correctly populate the git object store we need to understand the object types git supports, how it represents those objects and how they are stored on disk.</p>

<p>Git has two different represantations for objects. The “loose object” format stores every object in a separate file in the <code>.git/objects/</code> directory. Git regularly packs the loose objects into the pack file we discussed above, leveraging delta compression to reduce the space requirements of similar files. The loose objects are stored using the SHA1 hash as the filename, where the first two alphanumeric characters are used as a directory name under <code>.git/objects/</code> (this results in a simple16*16 partition of the objects directory) and the remaining 38 characters as the actual filename. 
The following example shows both loose objects and a pack file with its accompanying index file:</p>

<div><div><pre><code>[4866] λ &gt; tree .git/objects/
.git/objects/
├── 08
│   └── 24d8f1ed19e4e07cf03e40aeebe07b95a68f7d
├── 61
│   └── 3956b77de7b48bdd82375716c1f1b78fd30764
├── d4
│   └── d697777ba37a1588269b2639fb93d14af8e781
├── fc
│   └── f5367cdfdc59e08428afa5a0d62893bcca0cf0
├── info
│   └── packs
└── pack
    ├── pack-5faf642231915b153fd273701866c5526c680bc6.idx
    └── pack-5faf642231915b153fd273701866c5526c680bc6.pack
</code></pre></div></div>

<p>The object store can be queried using <code>git cat-file</code>:</p>

<div lang="bash"><div><pre><code>[4869] λ &gt; git cat-file -t fcf5367cdfdc59e08428afa5a0d62893bcca0cf0
tree
[4870] λ &gt; git cat-file -p fcf5367cdfdc59e08428afa5a0d62893bcca0cf0
100644 blob 613956b77de7b48bdd82375716c1f1b78fd30764	README.md
040000 tree e9378f166d4ddbf93a4bc1c91af2d9f3ea34ebdd	_src
040000 tree 2dba9669371668a7030d79e66521742660df9818	images
</code></pre></div></div>

<h3 id="objects-on-disk">Objects on disk</h3>

<p>The 4 object types git deals for the usual operations are:</p>

<ul>
  <li>The <code>commit</code> stores the commit message, dates and authore/commited information and points to a single tree object. A commit can have zero (for the root commit(s)), one or more parent commit ids. The commit pointer to the parent(s) forms the commit graph.</li>
  <li>A <code>blob</code> stores the actual file content <em>without</em> any meta information (e.g. the file name).</li>
  <li>A <code>tree</code> contains path names and permissions with pointers to blob or tree objects - it represents the directories and filenames of the tracked content.</li>
  <li>A <code>tag</code> an annotated tag stores the tag message, date and the identiy of the person creating the tag. Git also uses so called <a href="http://www.kernel.org/pub/software/scm/git/docs/git-tag.html">light-weight</a> tags that are simply pointers in the ref hierarchy without having any additionaly tag meta information.</li>
</ul>

<p>See <a href="http://git-scm.com/book/en/Git-Internals-Git-Objects">http://git-scm.com/book/en/Git-Internals-Git-Objects</a> for further detailed information.</p>

<p>As already mentioned, git stores a single pack file and generates an accompanying index file without creating any loose objects during the initial clone. 
Instead of using the same approach (and because we already read the pack file) we simply unpack the objects and store them as loose objects. This is obviously a less efficient approach and makes our clone operation much slower than it needs to be.</p>

<p>As our internal packfile representation already contains the decompressed objects, we simply need to store them correctly (recreating the deltified objects) without providing functionality to <em>create</em> each object type from scratch.</p>

<h4 id="object-storage-format">Object storage format</h4>

<p>The object content stored on disk uses the following format:</p>

<p>From <a href="http://git-scm.com/book/en/Git-Internals-Git-Objects">http://git-scm.com/book/en/Git-Internals-Git-Objects</a></p>

<blockquote>
  <p>Git constructs a header that starts with the type of the object, in this case a blob. Then, it adds a space followed by the size of the content and finally a null byte</p>

  <p>Git concatenates the header and the original content and then calculates the SHA-1 checksum of that new content.</p>
</blockquote>

<p>The <code>encodeObject</code> returns the correct disk representation of the object (file) content. Given the uncompressed content from the packfile as a bytestring it returns a pair that is the SHA1 hash and the on-disk content representation with the correct header:</p>

<div lang="haskell"><div><pre><code>-- header: &#34;type size\0&#34;
-- sha1 $ header ++ content
encodeObject :: ObjectType -&gt; C.ByteString -&gt; (ObjectId, C.ByteString)
encodeObject objectType content = do
    let header       = headerForBlob (C.pack $ show objectType)
        blob         = header `C.append` content
        sha1         = hsh blob
    (sha1, blob)
    where headerForBlob objType = objType `C.append` &#34; &#34; `C.append` C.pack (show $ C.length content) `C.append` &#34;\0&#34;
          hsh = toHex . SHA1.hash
</code></pre></div></div>

<p>Git stores the objects on disk using <code>zlib</code> compression. The <code>writeObject</code> function stores any object using our encoding function to create the object content:</p>

<div lang="haskell"><div><pre><code>writeObject :: GitRepository -&gt; ObjectType -&gt; C.ByteString -&gt; IO FilePath
writeObject GitRepository{..} objectType content = do
    let (sha1, blob) = encodeObject objectType content
        (path, name) = pathForObject getName sha1
        filename     = path &lt;/&gt; name
    _ &lt;- createDirectoryIfMissing True path
    L.writeFile filename $ compress blob
    return filename
    where compress data&#39; = Z.compress $ L.fromChunks [data&#39;]
   
    
-- Partition the namespace -&gt; (2 chars,38 chars)
pathForObject :: String -&gt; String -&gt; (FilePath, String)
pathForObject repoName sha | length sha == 40 = (repoName &lt;/&gt; &#34;.git&#34; &lt;/&gt; &#34;objects&#34; &lt;/&gt; pre, rest)
    where pre  = take 2 sha
          rest = drop 2 sha
pathForObject _ _                             = (&#34;&#34;, &#34;&#34;)
</code></pre></div></div>

<p>Using this functionwe can now unpack the pack file using the following function:</p>

<div lang="haskell"><div><pre><code>unpackPackfile :: Packfile -&gt; WithRepository ()
unpackPackfile InvalidPackfile = error &#34;Attempting to unpack an invalid packfile&#34;
unpackPackfile (Packfile _ _ objs) = do
        repo &lt;- ask
        unresolvedObjects &lt;- writeObjects objs
        liftIO $ forM_ unresolvedObjects $ writeDelta repo
    where   writeObjects (x@(PackfileObject (OBJ_REF_DELTA _) _ _):xs) = liftM (x:) (writeObjects xs)
            writeObjects (PackfileObject objType _ content : xs) = do
                repo &lt;- ask
                _ &lt;- liftIO $ writeObject repo (tt objType) content
                writeObjects xs
            writeObjects []     = return []

            tt OBJ_COMMIT       = BCommit
            tt OBJ_TREE         = BTree
            tt OBJ_BLOB         = BBlob
            tt OBJ_TAG          = BTag
            tt _                = error &#34;Unexpected blob type&#34;

            writeDelta repo (PackfileObject ty@(OBJ_REF_DELTA _) _ content) = do
                    base &lt;- case toObjectId ty of
                        Just sha -&gt; liftIO $ readObject repo sha
                        _        -&gt; return Nothing
                    if isJust base then
                        case patch (getBlobContent $ fromJust base) content of
                            Right target -&gt; do
                                            let base&#39;        = fromJust base
                                            filename &lt;- writeObject repo (objType base&#39;) target
                                            return $ Just filename
                            Left _       -&gt; return Nothing
                    else return Nothing -- FIXME - base object doesn&#39;t exist yet
            writeDelta _repo _ = error &#34;Don&#39;t expect a resolved object here&#34;
</code></pre></div></div>

<p><code>unpackPackfile</code> uses a 2-pass approach. It firstly writes out all the undeltified objects directly and accumulates a list of unresolved deltified objects. It then applies the <code>writeDelta</code> function to each of the deltified objects which looks up the base object that we just stored and recreates the undeltified object by applying the patch function using the base and delta content. The <code>readObject</code> function is the opposite of the <code>writeObject</code> and knows how to read the objects from the local repo.</p>

<p>This set of functions allows us to unpack all the objects (both deltified and undeltified) contained in the pack file into the local <code>.git/objects</code> object store.</p>

<h2 id="refs">Refs</h2>

<p>With the objects in place git now needs an entry point into the commit graph. The branches and tags are those entry points and the tips of the branches and tags are known as <strong>refs</strong>, names that refer to the SHA1 based object ID for the object in the git repository. The refs are stored under the <code>$GIT_DIR/refs</code> directory (e.g. <code>.git/refs/heads/master</code> or in a packed format under <code>.git/packed-refs</code>). Refs contain the 40 hex digit SHA1 directly or a symbolic ref to another ref (e.g. <code>ref: refs/heads/master</code>). The special symbolic ref <code>HEAD</code> refers to the current branch.</p>

<p>An examplary ref structure in a git repository is:</p>

<div><div><pre><code>.git/refs/
├── heads
│   └── master
├── remotes
│   └── origin
│       ├── HEAD
│       ├── master
│       └── pu
└── tags
    ├── 0.9
    └── 1.0
</code></pre></div></div>

<p>The refs in the <code>refs/heads</code> directory are the local branches of the repository. The <code>refs/tags</code> directory contains both tags. In the case of an annotated tag the tag points to the tag object. For a lightweight tag, the tag file contains the object id of the tagged commit itself.  The <code>refs/remotes</code> directory contains one sub directory for each remote that is configured (in this case the default <code>origin</code>). In the example the upstream repository has two branches <code>master</code> and <code>pu</code> and the symref <code>HEAD</code> that identifies the default branch of the upstream repositiory.</p>

<p>Listing the branches via <code>git branch</code> shows the same result:</p>

<div lang="bash"><div><pre><code>$&gt; git branch
* master
$&gt; git branch --remotes
  origin/HEAD
  origin/master
  origin/pu
</code></pre></div></div>

<p>Thus each ref name maps to a file with the same name in the given directory and its content is simply the SHA1 it refers to followed by a new line:</p>

<div lang="bash"><div><pre><code>$&gt; cat .git/refs/remotes/origin/master
8c25759f3c2b14e9eab301079c8b505b59b3e1ef
</code></pre></div></div>

<p>The canonical git implementation uses an optimization and stores refs in packed form in the <code>$GIT_DIR/packed-refs</code> file. The file is similar to the ref advertisement output and maps the refs to their object-ids within that single file:</p>

<div lang="bash"><div><pre><code>$&gt; cat .git/packed-refs
# pack-refs with: peeled
1865311797f9884ec438994d002b33f05e2f4844 refs/heads/delta-encoding-ffi
6bc699aad89341be9d07293815d0fa14f2e162ab refs/heads/fake-ref-creation
c666c23749af1e86169bed8ee0d1a2ac598e6ab0 refs/heads/master
496bf4f0724dd411855b374255b825f9b66cbfd0 refs/heads/sideband
</code></pre></div></div>

<p><em>Note:</em> To simplify our implementation we ignore this optimisation and again store each ref in a separate file.</p>

<h3 id="implementation">Implementation</h3>

<p>In the <code>createGitRepositoryFromPackfile</code> function we call from our <code>clone&#39;</code> function we can observe the basic steps required to create a working git repository:</p>

<div lang="haskell"><div><pre><code>createGitRepositoryFromPackfile :: FilePath -&gt; [Ref] -&gt; WithRepository ()
createGitRepositoryFromPackfile packFile refs = do
    pack &lt;- liftIO $ packRead packFile
    unpackPackfile pack
    createRefs refs
    updateHead refs
</code></pre></div></div>

<p>We unpack the pack file and create objects in the <code>.git/objects</code> directory (it’s worth repeating - this is <em>not</em> how the native git client works - the native client creates an index file and use the pack file instead), then we create the refs and lastly the special symbolic ref <code>HEAD</code>.</p>

<p>The refs that need to be created are known from the inital ref advertisements and are simply mappings from the object ids (in this case commit ids) to the full ref name.</p>

<p>E.g.:</p>

<div lang="bash"><div><pre><code>21ccebec0dd1d7e624ea2f22af6ac93686daf34f        refs/heads/master
2c8b7bf47c81acd2a76c1f9c3be2a1f102b76d31        refs/heads/next
</code></pre></div></div>

<p>We use <code>Ref</code> data type to model this pair and we use this list of <code>Refs</code> from that initial ref advertisement to create the correct ref files:</p>

<div lang="haskell"><div><pre><code>data Ref = Ref {
    getObjId        :: C.ByteString
  , getRefName      :: C.ByteString
} deriving (Show, Eq)

createRefs :: [Ref] -&gt; WithRepository ()
createRefs refs = do
    let (tags, branches) = partition isTag $ filter (not . isPeeledTag) refs
    writeRefs &#34;refs/remotes/origin&#34; branches
    writeRefs &#34;refs/tags&#34; tags
    where simpleRefName  = head . reverse . C.split &#39;/&#39;
          isPeeledTag    = C.isSuffixOf &#34;^{}&#34; . getRefName
          isTag          = (\e -&gt; (not . C.isSuffixOf &#34;^{}&#34; $ getRefName e) &amp;&amp; (C.isPrefixOf &#34;refs/tags&#34; $ getRefName e))
          writeRefs refSpace     = mapM_ (\Ref{..} -&gt; createRef (refSpace ++ &#34;/&#34; ++ (C.unpack . simpleRefName $ getRefName)) (C.unpack getObjId)) 

createRef :: String -&gt; String -&gt; WithRepository ()
createRef ref sha = do
    repo &lt;- ask
    let (path, name) = splitFileName ref
        dir          = getGitDirectory repo &lt;/&gt; path
    _ &lt;- liftIO $ createDirectoryIfMissing True dir
    liftIO $ writeFile (dir &lt;/&gt; name) (sha ++ &#34;\n&#34;)
</code></pre></div></div>

<p>We again filter out the peeled tag refs and partition the refs into tags and branches that are stored in their respectives directories.</p>

<p><em>Note:</em> Although <code>origin</code> is the default name for the remote repository a clone originates from, the native <code>git clone</code> command has the option <code>--origin &lt;name&gt;</code> to set the name of the remote to something other than <code>origin</code> when cloning. As our clone command currently doesn’t support any options we simply use the default <code>origin</code> remote name in our implementation.</p>

<p>After creating the refs the symbolic ref <code>HEAD</code> is created and it points to the same ref that is used by the upstream repository as the default branch (via its <code>HEAD</code> symref).</p>

<div lang="haskell"><div><pre><code>updateHead :: [Ref] -&gt; WithRepository ()
updateHead [] = fail &#34;Unexpected invalid packfile&#34;
updateHead refs = do
    let maybeHead = findHead refs
    unless (isNothing maybeHead) $
        let sha1 = C.unpack $ getObjId $ fromJust maybeHead
            ref = maybe &#34;refs/heads/master&#34; (C.unpack . getRefName) $ findRef sha1 refs
            in
            do
                createRef ref sha1
                createSymRef &#34;HEAD&#34; ref
    where isCommit ob = objectType ob == OBJ_COMMIT
          findHead = find (\Ref{..} -&gt; &#34;HEAD&#34; == getRefName)
          findRef sha = find (\Ref{..} -&gt; (&#34;HEAD&#34; /= getRefName &amp;&amp; sha == (C.unpack getObjId)))
</code></pre></div></div>

<p>The <code>updateHead</code> function tries to resolve the commit-id of the upstream <code>HEAD</code> ref and then looks up the ref name that corresponds to that object-id in order to create the symref using the <code>createSymRef</code> function:</p>

<div lang="haskell"><div><pre><code>createSymRef :: String -&gt; String -&gt; WithRepository ()
createSymRef symName ref = do
        repo &lt;- ask
        liftIO $ writeFile (getGitDirectory repo &lt;/&gt; symName) $ &#34;ref: &#34; ++ ref ++ &#34;\n&#34;
</code></pre></div></div>

<p>The <code>HEAD</code> symref then looks similar to:</p>

<div lang="bash"><div><pre><code>$&gt; cat .git/HEAD
ref: refs/heads/master
</code></pre></div></div>

<p>At this point the local git repository is actually usable (e.g. commands like <code>git log</code> or <code>git checkout</code> work), albeit with an empty working copy.</p>

<h2 id="working-copy-and-the-index">Working copy and the index</h2>

<p>With the object store populated and all the refs in place the next step is to “checkout” the files that match the repository snaphots <code>HEAD</code> points to.</p>

<p>In order to check out the current <code>HEAD</code> we need to:</p>

<ul>
  <li>Read the <code>HEAD</code> symref and resolve the commit it ultimately points to to use as the tip of our checked out working copy.</li>
  <li>Given this commit we need to resolve the top level tree that our commit points to.</li>
  <li>Based on the tree we write out all the blobs that top level tree contains and recursively read the child tree entries to fully restore the directories and files in our working copy.</li>
</ul>

<p>This requires us to be able to retrieve the objects from the object store and to then parse each object type and create an appropriate in-memory representation to enable tree traversal and ultimately the correct creation of files and directories.</p>

<h3 id="reading-objects">Reading objects</h3>

<p>Reading the objects is a two step process. The first step, the retrieval from the filesystem is already covered and is implemented by the <code>readObject</code> function:</p>

<div lang="haskell"><div><pre><code>readObject :: GitRepository -&gt; ObjectId -&gt; IO (Maybe Object)
readObject GitRepository{..} sha = do
    let (path, name) = pathForObject getName sha
        filename     = path &lt;/&gt; name
    exists &lt;- doesFileExist filename
    if exists then do
        bs &lt;- C.readFile filename
        return $ parseObject sha $ inflate bs
    else return Nothing
    where inflate blob = B.concat . L.toChunks . Z.decompress $ L.fromChunks [blob]
</code></pre></div></div>

<p><code>readObject</code> looks up the correct file from the file system given its SHA1 and decompresses the content. As already mentioned above, the content is prefixed with a header that contains the object type and the overal size of the object seperated by a <code>\NUL</code> byte from the acutal object content:</p>

<div lang="bash"><div><pre><code>object-type SP size \NUL object-content
</code></pre></div></div>

<p>The <code>parseObject</code> function parses the file content and creates an instance of an <code>Object</code> data type, extracting the object type and object content:</p>

<div lang="haskell"><div><pre><code>data Object = Object {
    getBlobContent  :: B.ByteString
  , objType         :: ObjectType
  , sha             :: ObjectId
} deriving (Eq, Show)

parseObject :: ObjectId -&gt; C.ByteString -&gt; Maybe Object
parseObject sha1 obj = eitherToMaybe $ parseOnly (objParser sha1) obj

-- header: &#34;type size\0&#34;
-- header ++ content
objParser :: ObjectId -&gt; Parser Object
objParser sha1 = do
   objType&#39; &lt;- string &#34;commit&#34; &lt;|&gt; string &#34;tree&#34; &lt;|&gt; string &#34;blob&#34; &lt;|&gt; string &#34;tag&#34;
   char &#39; &#39;
   _size &lt;- takeWhile isDigit
   nul
   content &lt;- takeByteString
   return $ Object content (obj objType&#39;) sha1
   where obj &#34;commit&#34;   = BCommit
         obj &#34;tree&#34;     = BTree
         obj &#34;tag&#34;      = BTag
         obj &#34;blob&#34;     = BBlob
         obj _          = error &#34;Invalid object type&#34; -- The parser wouldn&#39;t get here anyway
</code></pre></div></div>

<p>This is still a close representation of the object content just with some meta information about the type and the object id. In order to use the git objects, e.g. resolve parent commits from a commit object or read the tree entries from a tree object, we need a 2nd level of object parsing that turns the generic (but tagged) <code>Object</code> into a more specifc object representation.</p>

<!-- 

 For our use case it's sufficient to parse the `commit` and `tree` object types as we don't need to read any `tag` values and the `blob` object type is simply the file content and does not need to be parsed anyway.

-->

<h4 id="commit">Commit</h4>

<p>A commit object in git looks similar to this:</p>

<div lang="bash"><div><pre><code>[4807] λ &gt; git cat-file -p 3e879c7fd33cc3deecd99892033957dedc308e92
tree b11bff45acf0941c7ea5629dfff05760764423cd
parent c3a8276092194bd3ff80d7d6a4523c0f1c0e2df2
author Stefan Saasen &lt;stefan@saasen.me&gt; 1353116070 +1100
committer Stefan Saasen &lt;stefan@saasen.me&gt; 1353116070 +1100

Bump version to 1.6
</code></pre></div></div>

<p>We use the <code>Commit</code> data type to represent this in our program:</p>

<div lang="haskell"><div><pre><code>data Commit = Commit {
    getTree        :: B.ByteString
  , getParents     :: [B.ByteString] -- zero (root), one ore more (merges) parents
  , getSha         :: B.ByteString
  , getAuthor      :: Identity
  , getCommiter    :: Identity
  , getMessage     :: B.ByteString
} deriving (Eq,Show)
</code></pre></div></div>

<p>And a simple Attoparsec based parser to parse the raw commit content:</p>

<div lang="haskell"><div><pre><code>commitParser :: Parser Commit
commitParser = do
    tree &lt;- &#34;tree &#34; .*&gt; take 40
    space
    parents &lt;- many&#39; parseParentCommit
    author &lt;- &#34;author &#34; .*&gt; parsePerson
    space
    commiter &lt;- &#34;committer &#34; .*&gt; parsePerson
    space
    space
    message &lt;- takeByteString
    let author&#39;   = Author (getPersonName author) (getPersonEmail author)
        commiter&#39; = Commiter (getPersonName commiter) (getPersonEmail commiter)
    return $ Commit tree parents B.empty author&#39; commiter&#39; message
</code></pre></div></div>

<h4 id="blob">Blob</h4>

<p>The object of type blob simply contains the content that is tracked by git. This is the actual file content so no parsing or reading is necessary. The <code>blob</code> content will be written as it is to the corresponding file in the working copy.</p>

<h4 id="tree">Tree</h4>

<p>Quoting <a href="http://git-scm.com/book/en/Git-Internals-Git-Objects">http://git-scm.com/book/en/Git-Internals-Git-Objects</a> for a succinct description of the tree object:</p>

<blockquote>
  <p>[…] the tree object, which solves the problem of storing the filename and also allows you to store a group of files together. Git stores content in a manner similar to a UNIX filesystem, but a bit simplified. All the content is stored as tree and blob objects, with trees corresponding to UNIX directory entries and blobs corresponding more or less to inodes or file contents. A single tree object contains one or more tree entries, each of which contains a SHA-1 pointer to a blob or subtree with its associated mode, type, and filename.</p>
</blockquote>

<p>Looking at an actual tree objects immediately shows that underlying model with the node, object type, SHA1 object-id and filename listed per entry:</p>

<div lang="bash"><div><pre><code>[4809] λ &gt; git cat-file -t 19ae5beb4abeea465bfc4aef82fb9373099431c0
tree
[4810] λ &gt; git cat-file -p 19ae5beb4abeea465bfc4aef82fb9373099431c0
100644 blob c364d6f7508e2f6d1607a9d73e6330d68ec7d62a    .ghci
100644 blob c3270b6a3e56c40a570beb1185a53ac1cd48ccd3    .gitignore
100644 blob 38781a3632ce2bd32d7380c6678858afe1f38b19    LICENSE
100644 blob ed4a59a07241be06c3b0ecbbbe89bb4f037c0c70    README.md
100644 blob 200a2e51d0b46fa8a38d91b749f59f20eb97a46d    Setup.hs
040000 tree 754352894497d94b3f50a2353044ded0f592bbb1    example
100644 blob 2fdb4f2db32695c50a0fcae80bd6dca24e7ba7bd    hgit.cabal
040000 tree 58e3ef91a07d0be23ae80f20b8cc18cb7825e1a3    src
100755 blob 0d954128938097e4fc0b666f733b63b27cf14437    test-with-coverage.sh
040000 tree 0b4d3861577e115c29001f38e559440ce27b19b0    tests
</code></pre></div></div>

<p>Git supports the following modes (from <a href="https://www.kernel.org/pub/software/scm/git/docs/git-fast-import.html">git-fast-import</a>):</p>

<ul>
  <li><code>100644</code> or <code>644</code>: A normal (not-executable) file.</li>
  <li><code>100755</code> or <code>755</code>: A normal, but executable, file.</li>
  <li><code>120000</code>: A symlink, the content of the file will be the link target.</li>
  <li><code>160000</code>: A gitlink, SHA-1 of the object refers to a commit in another repository. They are used to implement submodules.</li>
  <li><code>040000</code>: A subdirectory. Points to another tree object.</li>
</ul>

<p>The actual tree object content is stored as a set of tree entries that have the following format:</p>

<div lang="bash"><div><pre><code>tree         = 1*tree-entry
tree-entry   = mode SP path NUL sha1

mode         = 6DIGIT
sha1         = 20HEXDIG
path         = UTF8-octets
</code></pre></div></div>

<p>E.g.:</p>

<div lang="bash"><div><pre><code>100644 .ghci\NUL\208k\227\&amp;0F\190\137A$\210\193\216j\247#\SI\ETBw;?100644 RunMain.hs\NUL\240i\182\&amp;3g\183\194\241-\131\187W\137\ESC\CAN\f\SOHX\180\174
</code></pre></div></div>

<p>We use the following functions to parse the tree content into a couple of simple data structures:</p>

<div lang="haskell"><div><pre><code>data Tree = Tree {
    getObjectId :: ObjectId
  , getEntries  :: [TreeEntry]
} deriving (Eq, Show)

data TreeEntry = TreeEntry {
    getMode    :: C.ByteString
  , getPath    :: C.ByteString
  , getBlobSha :: C.ByteString
} deriving (Eq, Show)

parseTree :: ObjectId -&gt; C.ByteString -&gt; Maybe Tree
parseTree sha&#39; input = eitherToMaybe $ parseOnly (treeParser sha&#39;) input

-- from e.g. `ls-tree.c`, `tree-walk.c`
treeParser :: ObjectId -&gt; Parser Tree
treeParser sha&#39; = do
    entries &lt;- many&#39; treeEntryParser
    return $ Tree sha&#39; entries
    
treeEntryParser :: Parser TreeEntry
treeEntryParser = do
    mode &lt;- takeTill (== &#39; &#39;)
    space
    path &lt;- takeTill (== &#39;\0&#39;)
    nul
    sha&#39; &lt;- take 20
    return $ TreeEntry mode path sha&#39;
</code></pre></div></div>

<p>With the ability to retrieve and parse the git objects we can now implement the functionality to check out the files corresponding to a given tree. Our entry point for this is the <code>checkoutHead</code> function:</p>

<div lang="haskell"><div><pre><code>checkoutHead :: WithRepository ()
checkoutHead = do
    repo &lt;- ask
    let dir = getName repo
    tip &lt;- readHead
    maybeTree &lt;- resolveTree tip
    indexEntries &lt;- maybe (return []) (walkTree [] dir) maybeTree
    writeIndex indexEntries
</code></pre></div></div>

<p>The first step is to resolve the commit-id that the symref <code>HEAD</code> points to:</p>

<div lang="haskell"><div><pre><code>readHead :: WithRepository ObjectId
readHead = readSymRef &#34;HEAD&#34;

readSymRef :: String -&gt; WithRepository ObjectId
readSymRef name = do
    repo &lt;- ask
    let gitDir = getGitDirectory repo
    ref &lt;- liftIO $ C.readFile (gitDir &lt;/&gt; name)
    let unwrappedRef = C.unpack $ strip $ head $ tail $ C.split &#39;:&#39; ref
    obj &lt;- liftIO $ C.readFile (gitDir &lt;/&gt; unwrappedRef)
    return $ C.unpack (strip obj)
  where strip = C.takeWhile (not . isSpace) . C.dropWhile isSpace
</code></pre></div></div>

<p><em>Note: This is a very simplified version of resolving a ref. <code>refs.c#resolve_ref_unsafe</code> handles loose and packed refs and even the older symlink style refs. For our simple use case this is not necessary as the symbolic ref will have been written by our own code in a previous step.</em></p>

<p>The second step is to resolve the tree object that this commit points to:</p>

<div lang="haskell"><div><pre><code>-- | Resolve a tree given a &lt;tree-ish&gt;
-- Similar to `parse_tree_indirect` defined in tree.c
resolveTree :: ObjectId -&gt; WithRepository (Maybe Tree)
resolveTree sha&#39; = do
        repo &lt;- ask
        blob &lt;- liftIO $ readObject repo sha&#39;
        maybe (return Nothing) walk blob
    where walk  (Object _ BTree sha1)                = do
                                                      repo &lt;- ask
                                                      liftIO $ readTree repo sha1
          walk  c@(Object _ BCommit _)               = do
                                                        let maybeCommit = parseCommit $ getBlobContent c
                                                        maybe (return Nothing) extractTree maybeCommit
          walk _                                   = return Nothing

extractTree :: Commit -&gt; WithRepository (Maybe Tree)
extractTree commit = do
    let sha&#39; = C.unpack $ getTree commit
    repo &lt;- ask
    liftIO $ readTree repo sha&#39;
</code></pre></div></div>

<p>Resolving the tree involves reading and parsing the commit and then extracting the tree object-id from the commit.</p>

<p>If the tree lookup is successful we can start traversing that tree depth-first, creating the files in the working copy as we go. This involves creating directories for <code>tree</code> entries (mode <code>40000</code>) and creating files with the content of the corresponding blob otherwise:</p>

<div lang="haskell"><div><pre><code>walkTree :: [IndexEntry] -&gt; FilePath -&gt; Tree -&gt; WithRepository [IndexEntry]
walkTree acc parent tree = do
    let entries = getEntries tree
    foldM handleEntry acc entries
    where handleEntry acc&#39; (TreeEntry &#34;40000&#34; path sha&#39;) = do
                                let dir = parent &lt;/&gt; toFilePath path
                                liftIO $ createDirectory dir
                                maybeTree &lt;- resolveTree $ toHex sha&#39;
                                maybe (return acc&#39;) (walkTree acc&#39; dir) maybeTree
          handleEntry acc&#39; (TreeEntry mode path sha&#39;) = do
                        repo &lt;- ask
                        let fullPath = parent &lt;/&gt; toFilePath path
                        content &lt;- liftIO $ readObject repo $ toHex sha&#39;
                        maybe (return acc&#39;) (\e -&gt; do
                                liftIO $ B.writeFile fullPath (getBlobContent e)
                                let fMode = fst . head . readOct $ C.unpack mode
                                liftIO $ setFileMode fullPath fMode
                                indexEntry &lt;- asIndexEntry fullPath sha&#39;
                                return $ indexEntry : acc&#39;) content
          toFilePath = C.unpack
          asIndexEntry path sha&#39; = do
                stat &lt;- liftIO $ getFileStatus path
                indexEntryFor path Regular sha&#39; stat
</code></pre></div></div>

<p><em>Note:</em> While we do handle files modes (<code>644</code> and <code>755</code>) we currently ignore the other git modes (symlink and gitlinks (for submodule support)).</p>

<p>After traversing the trees we now have a full checkout of all the files that correspond to the repository snapshot identified by the commit pointed to by the <code>HEAD</code> symref.</p>

<p>Running a <code>git status</code> command in that git repository shows all our newy create files both as untracked and slated for deletion as we haven’t create the git index file yet.</p>

<h3 id="git-index">Git index</h3>

<p>As our last step we need to create the index file that matches the file status on disk so that <code>git status</code> won’t report any outstanding changes. The index is also called the “staging area” or the directory cache (this should not be confused with the index that accompanies a pack file).</p>

<p>In git the index is used to keep track of changes in the working copy and to assemble the changes that will be part of the next commit.</p>

<p>From the <code>git add</code> man page:</p>

<blockquote>
  <p>The “index” holds a snapshot of the content of the working tree, and it is this snapshot that is taken as the contents of the next commit. Thus after making any changes to the working directory, and before running the commit command, you must use the add command to add any new or modified files to the index.</p>
</blockquote>

<p>Using a simple example we can observe how the index tracks file changes and status.</p>

<p>The exisiting repository tracks a single file <code>LICENSE</code> and has an untracked file <code>README</code> in its working copy:</p>

<div lang="bash"><div><pre><code>[4862] λ &gt; git ls-files -scot
? README
H 100644 2831d9e6097f965062d0bb4bdc06e89919632530 0     LICENSE
</code></pre></div></div>

<p>While the refs point to commit ids, the index file points to the blob object-id for each file. <code>2831d9</code> is the object-id for the <code>LICENSE</code> blob:</p>

<div lang="bash"><div><pre><code>[4863] λ &gt; git cat-file -t 2831d9e6097f965062d0bb4bdc06e89919632530
blob
</code></pre></div></div>

<p>At this stage the only objects that this repository contains are one blob, one tree and one commit object:</p>

<div><div><pre><code>[4864] λ &gt; tree .git/objects/
.git/objects/
├── 28
│   └── 31d9e6097f965062d0bb4bdc06e89919632530
├── 85
│   └── cbc8d3e3eb1579fc941485b85076d7a97900dd
├── f3
│   └── 8d3a2b142f851984fecc9db9cf34439bb5e47a
├── info
└── pack
</code></pre></div></div>

<p>The actual index file thus only contains a single entry, the entry for the <code>LICENSE</code> file.
Based on the absence of an index entry for the <code>README</code> file commands like <code>git status</code> or <code>git ls-files -o</code> can deduce that the file is untracked.</p>

<p>The index file entry contains meta data (e.g. modified time, permissions), the file path and the SHA1 of the blob object.</p>

<p>In order to build up or stage the next commit, git creates blob objects when changes (whole file or partial changes via for example <code>git add -p</code>) are added to the index via <code>git add</code>.</p>

<p>This means that commiting the change results in the creation of the required tree objects for the index entries that bind the files to their blob objects and the commit object that has a reference to that newly created tree.</p>

<p>A useful tool for observing changes to the repository (including the temporary creation of lock files) - especialy when the number of objects is large - is using the file system notifications to be notified of changes while running commands (e.g. <a href="http://linux.die.net/man/1/inotifywait">inotifywait</a> on Linux or <a href="https://bitbucket.org/ssaasen/spy">spy</a> on Mac OS X):</p>

<p><img src="https://stefan.saasen.me/articles/git-clone-in-haskell-from-the-bottom-up/images/git-add-spy.png" alt="git-index-spy"/></p>

<p>As can be seen, adding the <code>README</code> using <code>git add</code> (or using <code>git update-index --add</code>) results in the creation of a new blob object file in the <code>.git/objects/ce</code> directory:</p>

<div lang="bash"><div><pre><code>[4866] λ &gt; git cat-file -t cebdca635c102a886e8d48c5479b6a7c348c194f
blob
</code></pre></div></div>

<p>Now the index contains two entries and the <code>README</code> is going to be part of the next commit.</p>

<p><img src="https://stefan.saasen.me/articles/git-clone-in-haskell-from-the-bottom-up/images/git-index.png" alt="image"/></p>

<h4 id="index-format">Index format</h4>

<p>The format of the directory cache index file itself is described in <code>Documentation/technical/index-format.txt</code>.</p>

<p>The index (stored in <code>.git/index</code>) has a 12-byte index header that is structured in the same way as the pack file header:</p>

<ul>
  <li>4-byte signature or magic bytes <code>&#39;D&#39; &#39;I&#39; &#39;R&#39; &#39;C&#39;</code> (for <em>dircache</em>)</li>
  <li>4-byte version number</li>
  <li>4-byte number of index entries</li>
</ul>

<p>This is followed by a number of <em>sorted</em> index entries where each index entry contains stat(2) data (ctime, mtime, device, inode, uid, gid, filesize), the SHA1 object id, a git type (regular file, symlink, gitlink), unix permissions, a couple of status flags and the path and path length of the file the index entry is about (“padded with 1-8 nul bytes as necessary to pad the entry to a multiple of eight bytes while keeping the name NUL-terminated”). The path name includes the directories from the top level directory of the repository.</p>

<p>The <code>git ls-files</code> command can be used to show a detailed view of the index contents:</p>

<div lang="bash"><div><pre><code>[5003] λ &gt; git ls-files -s --debug
100644 2831d9e6097f965062d0bb4bdc06e89919632530 0       LICENSE
  ctime: 1365582812:0
  mtime: 1365582812:0
  dev: 16777220 ino: 11640465
  uid: 501      gid: 20
  size: 8       flags: 0
…
</code></pre></div></div>

<p>This matches the <code>stat</code> output:</p>

<div lang="bash"><div><pre><code>[5004] λ &gt; stat LICENSE
  File: &#34;LICENSE&#34;
  Size: 8            FileType: Regular File
  Mode: (0644/-rw-r--r--)         Uid: (  501/ ssaasen)  Gid: (   20/   staff)
Device: 1,4   Inode: 11640465    Links: 1
Access: Wed Apr 10 21:05:28 2013
Modify: Wed Apr 10 18:33:32 2013
Change: Wed Apr 10 18:33:32 2013
</code></pre></div></div>

<p>With a way of verifying the index creation the implementation now naturally follows from the observation that the index content is mostly <em>not</em> part of the repository (e.g ctime/mtime, uid/gid) but caches the tree/directory entries so needs to be created while walking the directory tree. The <code>walkTree</code> function that was introduced above does exactly that, while checking out a particular tree (i.e. creating the necessary files) it creates and returns a list of <code>IndexEntry</code> items:</p>

<div lang="haskell"><div><pre><code>walkTree :: [IndexEntry] -&gt; FilePath -&gt; Tree -&gt; WithRepository [IndexEntry]
walkTree acc parent tree = do
   [...]
                        content &lt;- liftIO $ readObject repo $ toHex sha&#39;
                        maybe (return acc&#39;) (\e -&gt; do
   [...]
-&gt;                              indexEntry &lt;- asIndexEntry fullPath sha&#39;
                                return $ indexEntry : acc&#39;) content

          asIndexEntry path sha&#39; = do
                stat &lt;- liftIO $ getFileStatus path
-&gt;              indexEntryFor path Regular sha&#39; stat
</code></pre></div></div>

<p>Given the filepath, the git file type (we currently only consider regular files, not symlinks nor gitlinks), the SHA1 object-id and the <code>stat</code> information the <code>indexEntryFor</code> function returns an <code>IndexEntry</code> instance:</p>

<div lang="haskell"><div><pre><code>data IndexEntry = IndexEntry {
    ctime       :: Int64
  , mtime       :: Int64
  , device      :: Word64
  , inode       :: Word64
  , mode        :: Word32
  , uid         :: Word32
  , gid         :: Word32
  , size        :: Int64
  , sha         :: [Word8]
  , gitFileMode :: GitFileMode
  , path        :: String
} deriving (Eq)

indexEntryFor :: FilePath -&gt; GitFileMode -&gt; B.ByteString -&gt; FileStatus -&gt; WithRepository IndexEntry
indexEntryFor filePath gitFileMode&#39; sha&#39; stat = do
        repo &lt;- ask
        let fileName = makeRelativeToRepoRoot (getName repo) filePath
        return $ IndexEntry (coerce $ statusChangeTime stat) (coerce $ modificationTime stat)
                        (coerce $ deviceID stat) (coerce $ fileID stat) (coerce $ fileMode stat)
                        (coerce $ fileOwner stat) (coerce $ fileGroup stat) (coerce $ fileSize stat)
                        (B.unpack sha&#39;) gitFileMode&#39; fileName
        where coerce = fromIntegral . fromEnum
</code></pre></div></div>

<p>As the final step of checking the current <code>HEAD</code> (see above) we write the index to disk:</p>

<div lang="haskell"><div><pre><code>checkoutHead :: WithRepository ()
checkoutHead = do
    repo &lt;- ask
    let dir = getName repo
    tip &lt;- readHead
    maybeTree &lt;- resolveTree tip
    indexEntries &lt;- maybe (return []) (walkTree [] dir) maybeTree
    writeIndex indexEntries
</code></pre></div></div>

<p>Writing the index entails sorting the index entries correctly (sorted in ascending order on the name field) and creating the indexHeader:</p>

<div lang="haskell"><div><pre><code>encodeIndex :: Index -&gt; WithRepository B.ByteString
encodeIndex toWrite = do
    let indexEntries = sortIndexEntries $ getIndexEntries toWrite
        numEntries   = toEnum . fromEnum $ length indexEntries
        header       = indexHeader numEntries
        entries      = mconcat $ map encode indexEntries
        idx          = toLazyByteString header `L.append` entries
    return $ lazyToStrictBS idx `B.append` SHA1.hashlazy idx

indexHeader :: Word32 -&gt; Builder
indexHeader num =
        putWord32be magic      -- The signature is { &#39;D&#39;, &#39;I&#39;, &#39;R&#39;, &#39;C&#39; } (stands for &#34;dircache&#34;)
        &lt;&gt; putWord32be 2       -- Version (2, 3 or 4, we use version 2)
        &lt;&gt; putWord32be num     -- Number of index entries
    where magic = fromOctets $ map (fromIntegral . ord) &#34;DIRC&#34;
</code></pre></div></div>

<p>Using <code>Data.Binary</code> each <code>IndexEntry</code> can be written in binary using the following typeclass definition that follows the <code>index-format</code> specification:</p>

<div lang="haskell"><div><pre><code>-- see `read-cache.c`, `cache.h` and `built-in/update-index.c`.
instance Binary IndexEntry where
    put (IndexEntry cs ms dev inode&#39; mode&#39; uid&#39; gid&#39; size&#39; sha&#39; gitFileMode&#39; name&#39;)
        = do
            put $ coerce cs                     -- 32-bit ctime seconds
            put zero                            -- 32-bit ctime nanosecond fractions
            put $ coerce ms                     -- 32-bit mtime seconds
            put zero                            -- 32-bit mtime nanosecond fractions
            put $ coerce dev                    -- 32-bit dev
            put $ coerce inode&#39;                 -- 32-bit ino
            put $ toMode gitFileMode&#39; mode&#39;     -- 32-bit mode, see below
            put $ coerce uid&#39;                   -- 32-bit uid
            put $ coerce gid&#39;                   -- 32-bit gid
            put $ coerce size&#39;                  -- filesize, truncated to 32-bit
            mapM_ put sha&#39;                      -- 160-bit SHA-1 for the represented object - [Word8]
            put flags                           -- 16-bit
            mapM_ put finalPath                 -- variable length - [Word8] padded with \NUL
        where zero = 0 :: Word32
              pathName                  = name&#39;
              coerce  x                 = (toEnum $ fromEnum x) :: Word32
              toMode gfm fm             = (objType gfm `shiftL` 12) .|. permissions gfm fm
              flags                     = (((toEnum . length $ pathName)::Word16) .&amp;. 0xFFF) :: Word16 -- mask the 4 high order bits 
              -- FIXME: length if the length is less than 0xFFF; otherwise 0xFFF is stored in this field.
              objType Regular           = 8         :: Word32     -- regular file     1000
              objType SymLink           = 10        :: Word32     -- symbolic link    1010
              objType GitLink           = 14        :: Word32     -- gitlink          1110
              permissions Regular fm    = fromIntegral fm :: Word32     -- 0o100755 or 0o100644
              permissions _ _           = 0         :: Word32
              !finalPath                = let n     = CS.encode (pathName ++ &#34;\0&#34;)
                                              toPad = 8 - ((length n - 2) `mod` 8)
                                              pad   = C.replicate toPad &#39;\NUL&#39;
                                              padded = if toPad /= 8 then n ++ B.unpack pad else n
                                          in padded
    get = readIndexEntry
</code></pre></div></div>

<h2 id="the-clone-command-re-implemented">The clone command re-implemented</h2>

<p>With the last piece in place the <code>git clone</code> command built from the ground up in Haskell can now be executed and works as expected:</p>

<div lang="bash"><div><pre><code>[4900] λ &gt; cabal configure
[4901] λ &gt; cabal build
[4902] λ &gt; cabal copy
[4903] λ &gt; hgit clone git://github.com/juretta/git-pastiche.git
remote: Counting objects: 149, done.
remote: Compressing objects: 100% (103/103), done.
remote: Total 149 (delta 81), reused 113 (delta 45)
ssaasen@monteiths:~/temp [0]
[4903] λ &gt; cd git-pastiche/
ssaasen@monteiths:~/temp/git-pastiche (± master ✓ ) [0]
[4903] λ &gt; git status
# On branch master
nothing to commit, working directory clean
ssaasen@monteiths:~/temp/git-pastiche (± master ✓ ) [0]
[4901] λ &gt; git log --oneline --graph --decorate
* fe484e4 (HEAD, origin/master, origin/HEAD, master) Use eval to evaluate either &#39;tac&#39; or &#39;tail -r&#39;
* cb48fc5 Use tac by default for reverse output (if available)
</code></pre></div></div>

<h2 id="whats-missing">What’s missing?</h2>

<p>Although the clone works, there are a lot of things missing compared to the git implementation:</p>

<ul>
  <li>We don’t traverse the graph to see whether it is fully connected</li>
  <li>The creation of symlinks and gitlinks is currently not implemented</li>
  <li>We don’t explicitly verify the commit ids - we do implicitly though as we generate them while storing the files</li>
  <li>And so on…</li>
</ul>

<h2 id="conclusion">Conclusion</h2>

<p><a href="https://www.kernel.org/pub/software/scm/git/docs/user-manual.html#git-concepts">“Git concepts”</a> puts it succinctly:</p>

<blockquote>
  <p>Git is built on a small number of simple but powerful ideas.</p>
</blockquote>

<p>Being able to rebuilt an (albeit tiny) subset of the git commands while mainly relying on the research of the data structures, file formats and protcols, less so on the actual source is a testament to this statement.<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" rel="footnote">3</a></sup></p>




    </div></div>
  </body>
</html>
