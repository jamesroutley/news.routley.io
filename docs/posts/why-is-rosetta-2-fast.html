<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://dougallj.wordpress.com/2022/11/09/why-is-rosetta-2-fast/">Original</a>
    <h1>Why is Rosetta 2 fast?</h1>
    
    <div id="readability-page-1" class="page"><div>
		
<p>Rosetta 2 is remarkably fast when compared to other x86-on-ARM emulators. I’ve spent a little time looking at how it works, out of idle curiosity, and found it to be quite unusual, so I figured I’d put together my notes.<a rel="me" href="https://mastodon.social/@dougall"></a></p>



<p>My understanding is a bit rough, and is mostly based on reading the ahead-of-time translated code, and making inferences about the runtime from that. Let me know if you have any corrections, or find any tricks I’ve missed.</p>



<figure><a href="https://dougallj.files.wordpress.com/2022/11/fupg8ipuuaehi0a-1.jpg"><img loading="lazy" data-attachment-id="1483" data-permalink="https://dougallj.wordpress.com/2022/11/09/why-is-rosetta-2-fast/fupg8ipuuaehi0a-1/" data-orig-file="https://dougallj.files.wordpress.com/2022/11/fupg8ipuuaehi0a-1.jpg" data-orig-size="1790,1050" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="fupg8ipuuaehi0a-1" data-image-description="" data-image-caption="" data-medium-file="https://dougallj.files.wordpress.com/2022/11/fupg8ipuuaehi0a-1.jpg?w=300" data-large-file="https://dougallj.files.wordpress.com/2022/11/fupg8ipuuaehi0a-1.jpg?w=628" src="https://dougallj.files.wordpress.com/2022/11/fupg8ipuuaehi0a-1.jpg?w=1024" alt="" width="614" height="359" srcset="https://dougallj.files.wordpress.com/2022/11/fupg8ipuuaehi0a-1.jpg?w=1024 1024w, https://dougallj.files.wordpress.com/2022/11/fupg8ipuuaehi0a-1.jpg?w=612 612w, https://dougallj.files.wordpress.com/2022/11/fupg8ipuuaehi0a-1.jpg?w=1224 1224w, https://dougallj.files.wordpress.com/2022/11/fupg8ipuuaehi0a-1.jpg?w=150 150w, https://dougallj.files.wordpress.com/2022/11/fupg8ipuuaehi0a-1.jpg?w=300 300w" sizes="(max-width: 614px) 100vw, 614px"/></a><figcaption>IDA Pro screenshot: side-by-side comparison of Rosetta 2 ahead-of-time code, and the original x86 code, for a function incorrectly named “parity64”, that computes the 8-bit parity an argument using the x86 parity-flag.</figcaption></figure>



<h2>Ahead-of-time translation</h2>



<p>Rosetta 2 translates the entire text segment of the binary from x86 to ARM up-front. It also supports just-in-time (JIT) translation, but that typically isn’t needed, avoiding both the direct runtime cost of compilation, and any indirect instruction and data cache effects.</p>



<p>Other interpreters typically translate code in execution order, which can allow faster startup times, but doesn’t preserve code locality.</p>



<h2>One-to-one translation</h2>



<p>Each x86 instruction is translated to one or more ARM instructions exactly once. When an indirect jump or call sets the instruction pointer to an arbitrary offset in the text segment, the runtime will look up the corresponding translated instruction, and branch there.</p>



<p>This means that the only time the JIT should run is if the code unexpectedly jumps into the middle of an x86 instruction, or if the code itself is a JIT (generating new x86 code at runtime).</p>



<p>This imposes some significant limitations on optimisations: every instruction must be translated such that it would be legal to jump there. The only inter-instruction optimisation I recall seeing is an “unused-flags” optimisation, which avoids calculating x86 flags value if they are not used before being overwritten on every path from a flag-setting instruction.</p>



<p>There are some tradeoffs to this:</p>



<ul>
<li>Either all emulated register values must be kept in host registers, or you need load or store instructions every time certain registers are used. 64-bit x86 has half as many registers as 64-bit ARM, so this isn’t a problem for Rosetta 2, but it would be a significant drawback to this technique for emulating 64-bit ARM on x86, or PPC on 64-bit ARM.</li>



<li>There are very few inter-instruction optimisations, leading to surprisingly poor code generation in some cases.</li>
</ul>



<p>However there are significant benefits:</p>



<ul>
<li>Translating each instruction only once has significant instruction-cache benefits – other emulators typically cannot reuse code when branching to a new target.</li>



<li>The debugger (LLDB) works transparently with Rosetta 2 – breakpoints can be set on any x86 instruction, and the state of every x86 register is available (although not flags that won’t be used).</li>



<li>Having fewer optimisations simplifies code generation, making translation faster. Translation speed is important for both first-start time (where tens of megabytes of code may be translated), and JIT translation time, which is critical to the performance of applications that use JIT compilers.</li>
</ul>



<p>Optimising for the instruction-cache might not <em>seem</em> like a significant benefit, but it typically is in emulators, as there’s already an expansion-factor when translating between instruction sets. Every one-byte x86 push becomes a four byte ARM instruction, and every read-modify-write x86 instruction is three ARM instructions (or more, depending on addressing mode). And that’s if the perfect instruction is available. When the instructions have slightly different semantics, even more instructions are needed to get the required behaviour.</p>



<p>(I’m a little unclear on the details of indirect calls and branches, but I believe the full x86 to ARM address mapping is via the fragment list found in <strong>LC_AOT_METADATA</strong>, and successful lookups are then cached in a hash-map. This lookup can also map ARM addresses to x86 addresses for the debugger.)</p>



<h2>Memory layout</h2>



<p>An <strong>ADRP</strong> instruction followed by an <strong>ADD</strong> is used to emulate x86’s RIP-relative addressing. This is limited to a +/-1GB range. Rosetta 2 places the translated binary after the non-translated binary in memory, so you roughly have [untranslated code][data][translated code][runtime support code]. This means that <strong>ADRP</strong> can reference data and untranslated code as needed. Loading the runtime support functions immediately after the translated code also allows translated code to make direct calls into the runtime.</p>



<h2>Return address prediction</h2>



<p>All performant processors have a return-address-stack to allow branch prediction to correctly predict return instructions.</p>



<p>Rosetta 2 takes advantage of this by rewriting x86 <strong>CALL</strong> and <strong>RET</strong> instructions to ARM <strong>BL</strong> and <strong>RET</strong> instructions (as well as the architectural loads/stores and stack-pointer adjustments). This also requires some extra book-keeping, saving the expected x86 return-address and the corresponding translated jump target on a special stack when calling, and validating them when returning, but it allows for correct return prediction.</p>



<p>This trick is also used in the GameCube/Wii emulator Dolphin.</p>



<h2>ARM flag-manipulation extensions</h2>



<p>A lot of overhead comes from small differences in behaviour between x86 and ARM, like the semantics of flags. Rosetta 2 uses the ARM flag-manipulation extensions (FEAT_FlagM and FEAT_FlagM2) to handle these differences efficiently.</p>



<p>For example, x86 uses “subtract-with-borrow”, whereas ARM uses “subtract-with-carry”. This effectively inverts the carry flag when doing a subtraction, as opposed to when doing an addition. As <strong>CMP</strong> is a flag-setting subtraction without a result, it’s much more common to use the flags from a subtraction than an addition, so Rosetta 2 chooses inverted as the canonical form of the carry flag. The <strong>CFINV</strong> instruction (carry-flag-invert) is used to invert the carry after any <strong>ADD</strong> operation where the carry flag is used or may escape (and to rectify the carry flag, when it’s the input to an add-with-carry instruction).</p>



<p>x86 shift instructions also require complicated flag handling, as it shifts bits into the carry flag. The <strong>RMIF</strong> instruction (rotate-mask-insert-flags) is used within rosetta to move an arbitrary bit from a register into an arbitrary flag, which makes emulating fixed-shifts (among other things) relatively efficient. Variable shifts remain relatively inefficient if flags escape, as the flags must not be modified when shifting by zero, requiring a conditional branch.</p>



<p>Unlike x86, ARM doesn’t have any 8-bit or 16-bit operations. These are generally easy to emulate with wider operations (which is how compilers implement operations on these values), with the small catch that x86 requires preserving the original high-bits. However, the <strong>SETF8</strong> and <strong>SETF16</strong> instructions help to emulate the flag-setting behaviour of these narrower instructions.</p>



<p>Those were all from FEAT_FlagM. The instructions from FEAT_FlagM2 are <strong>AXFLAG</strong> and <strong>XAFLAG</strong>, which convert floating-point condition flags to/from a mysterious “external format”. By some strange coincidence, this format is x86, so these instruction are used when dealing with floating point flags.</p>



<h2>Floating-point handling</h2>



<p>x86 and ARM both implement IEEE-754, so the most common floating-point operations are almost identical. One exception is the handling of the different possible bit patterns underlying NaN values, and another is whether tininess is detected before or after rounding. Most applications won’t mind if you get this wrong, but some will, and to get it right would require expensive checks on every floating-point operation. Fortunately, this is handled in hardware.</p>



<p>There’s a standard ARM alternate floating-point behaviour extension (FEAT_AFP) from ARMv8.7, but the M1 design predates the v8.7 standard, so Rosetta 2 uses a non-standard implementation.</p>



<p>(What a coincidence – the “alternative” happens to exactly match x86. It’s quite funny to me that ARM will put “Javascript” in the description of an instruction, but needs two different euphemisms for “x86”.)</p>



<h2>Total store ordering (TSO)</h2>



<p>One non-standard ARM extension available on the Apple M1 that has been widely publicised is hardware support for TSO (total-store-ordering), which, when enabled, gives regular ARM load-and-store instructions the same ordering guarantees that loads and stores have on an x86 system.</p>



<p>As far as I know this is not part of the ARM standard, but it also isn’t Apple specific: Nvidia Denver/Carmel and Fujitsu A64fx are other 64-bit ARM processors that also implement TSO (<a href="https://twitter.com/marcan42/status/1534053625110351872">thanks to marcan for these details</a>).</p>



<h2>Apple’s secret extension</h2>



<p>There are only a handful of different instructions that account for 90% of all operations executed, and, near the top of that list are addition and subtraction. On ARM these can optionally set the four-bit NZVC register, whereas on x86 these always set six flag bits: CF, ZF, SF and OF (which correspond well-enough to NZVC), as well as PF (the parity flag) and AF (the adjust flag).</p>



<p>Emulating the last two in software is possible (and seems to be supported by Rosetta 2 for Linux), but can be rather expensive. Most software won’t notice if you get these wrong, but some software will. The Apple M1 has an undocumented extension that, when enabled, ensures instructions like <strong>ADDS</strong>, <strong>SUBS</strong> and <strong>CMP</strong> compute PF and AF and store them as bits 26 and 27 of NZCV respectively, providing accurate emulation with no performance penalty.</p>



<h2>Fast hardware</h2>



<p>Ultimately, the M1 is incredibly fast. By being so much wider than comparable x86 CPUs, it has a remarkable ability to avoid being throughput-bound, even with all the extra instructions Rosetta 2 generates. In some cases (iirc, IDA Pro) there really isn’t much of a speedup going from Rosetta 2 to native ARM.</p>



<h2>Conclusion</h2>



<p>I believe there’s significant room for performance improvement in Rosetta 2, by using static analysis to find possible branch targets, and performing inter-instruction optimisations between them. However, this would come at the cost of significantly increased complexity (especially for debugging), increased translation times, and less predictable performance (as it’d have to fall back to JIT translation when the static analysis is incorrect).</p>



<p>Engineering is about making the right tradeoffs, and I’d say Rosetta 2 has done exactly that. While other emulators might require inter-instruction optimisations for performance, Rosetta 2 is able to trust a fast CPU, generate code that respects its caches and predictors, and solve the messiest problems in hardware.</p>



<p>You can follow me at <a href="https://mastodon.social/@dougall"></a><a href="https://mastodon.social/@dougall">@dougall@mastodon.social</a>.</p>



<h2>Appendix: Research Method</h2>



<p>This exploration was based on the methods and information described in Koh M. Nakagawa’s excellent <a href="https://ffri.github.io/ProjectChampollion/">Project Champollion</a>.</p>



<p>To see ahead-of-time translated Rosetta code, I believe I had to disable SIP, compile a new x86 binary, give it a unique name, run it, and then run <strong>otool -tv /var/db/oah/*/*/unique-name.aot</strong> (or use your tool of choice – it’s just a Mach-O binary). This was done on old version of macOS, so things may have changed and improved since then.</p>



<h2>Update: SSE2 support</h2>



<p>After reading some comments I realised this was a significant omission from the original post. Rosetta 2 provides full emulation for the SSE2 SIMD instruction set. These instructions have been enabled in compilers by default for many years, so this would have been required for compatibility. However, all common operations are translated to a reasonably-optimised sequence of NEON operations. This is critical to the performance of software that has been optimised to use these instructions.</p>



<p>Many emulators also use this SIMD to SIMD translation approach, but other use SIMD to scalar, or call out to runtime support functions for each SIMD operation.</p>



<h2>Update: Appendix: Compatibility</h2>



<p>Although it has nothing to do with why Rosetta 2 is fast, there are a couple of impressive compatibility features that seem worth mentioning.</p>



<p>Rosetta 2 has a full, slow, software implementation of x87’s 80-bit floating point numbers. This allows software that uses those instructions to run, which I don’t believe is the case for the Windows on Arm translation layer. Most software either doesn’t use x87, or was designed to run on at least 15-year-old hardware, so even though this emulation is slow, the performance typically works out.</p>



<p>Rosetta 2 also apparently supports the full 32-bit instruction set for Wine. Support for native 32-bit macOS applications was dropped prior to the launch of Apple Silicon, but support for the 32-bit x86 instruction set allegedly lives on. (I haven’t investigated this myself.)</p>
			</div></div>
  </body>
</html>
