<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="http://web.cse.ohio-state.edu/~stiff.4/cse3521/norvig-chomsky.html">Original</a>
    <h1>The Norvig – Chomsky debate (2017)</h1>
    
    <div id="readability-page-1" class="page"><div id="text-3">
<p>
Recently, Peter Norvig took the time to <a href="http://norvig.com/chomsky.html">write a response</a> to a comment
Noam Chomsky made at a conference (not a comment made to Norvig, but
to an entire research community of which Norvig considers himself a
part). (Chomsky has a new <a href="http://www.theatlantic.com/technology/archive/2012/11/noam-chomsky-on-where-artificial-intelligence-went-wrong/261637/?single_page=true&amp;">reply</a> to Norvig.) Chomsky said at the
conference,
</p>

<blockquote>
<p>
It&#39;s true there&#39;s been a lot of work on trying to apply statistical
models to various linguistic problems. I think there have been some
successes, but a lot of failures. There is a notion of success…
which I think is novel in the history of science. It interprets
success as approximating unanalyzed data.
</p>
</blockquote>

<p>
In Chomsky&#39;s recent interview in which he replies to Norvig, he makes
a similar point (emphasis added):
</p>

<blockquote>
<p>
I thought [early attempts at AI] was first of all way too optimistic,
it was assuming you could achieve things that required real
understanding of systems that were barely understood, and *you just
can&#39;t get to that understanding by throwing a complicated machine at
it*. If you try to do that you are led to a conception of success,
which is self-reinforcing, because you do get success in terms of this
conception, but <b>it&#39;s very different from what&#39;s done in the
sciences</b>. So for example, take an extreme case, suppose that somebody
says he wants to eliminate the physics department and do it the right
way. The &#34;right&#34; way is to take endless numbers of videotapes of
what&#39;s happening outside the video, and feed them into the biggest and
fastest computer, gigabytes of data, and do complex statistical
analysis — you know, Bayesian this and that — and you&#39;ll get some
kind of prediction about what&#39;s gonna happen outside the window
next. In fact, <b>you get a much better prediction than the physics
department will ever give</b>. Well, if success is defined as getting a
fair approximation to a mass of chaotic unanalyzed data, then it&#39;s way
better to do it this way than to do it the way the physicists do, you
know, no thought experiments about frictionless planes and so on and
so forth. <b>But you won&#39;t get the kind of understanding that the
sciences have always been aimed at</b> — what you&#39;ll get at is an
approximation to what&#39;s happening.
</p>

<p>
[…]
</p>

<p>
A very different approach, which I think is the right approach, is to
try to see if you can understand what the <b>fundamental principles</b> are
that deal with the core properties, and recognize that in the actual
usage, there&#39;s going to be a thousand other variables intervening —
kind of like what&#39;s happening outside the window, and you&#39;ll sort of
tack those on later on if you want better approximations, that&#39;s a
different approach. These are just two different concepts of
science. The second one is what science has been since Galileo, that&#39;s
modern science. <b>The approximating unanalyzed data kind is sort of a
new approach</b>, not totally, there&#39;s things like it in the past. It&#39;s
basically a new approach that has been <b>accelerated by the existence
of massive memories, very rapid processing</b>, which enables you to do
things like this that you couldn&#39;t have done by hand. But I think,
myself, that it is leading subjects like computational cognitive
science into a direction of maybe some practical applicability…
</p>

<p>
Interviewer: &#34;… in engineering?&#34;
</p>

<p>
Chomsky: … <b>But away from understanding</b>.
</p>
</blockquote>

<p>
Norvig has been successful building AI systems that use statistical
learning and statistical inferencing. He takes issue with Chomsky&#39;s
claim that, essentially, what modern AI research is doing is not
science.
</p>

<p>
Chomsky is (in)famous for hypothesizing and arguing that all humans
have a tacit but unlearned knowledge of linguistic structure, a
universal grammar. He believes the evidence for this hypothesis is
that children cannot possibly learn all that they do about their first
language just from what they hear. Rather, the structure of language
is so deep and sophisticated that children must already have the
mental structures needed, and do not learn these structures from
experience. An important structure, for example, is the ability to
understand recursive utterances, such as:
</p>

<blockquote>
<p>
My homework assignment, which is worth 100 points in my CSE 3521
class, which is not required for my major but I wanted to take it
anyway, which has turned out to be quite interesting as it happens, is
due Thursday.
</p>
</blockquote>

<p>
Although that sentence is a bit contrived, we can understand it
(spoken or written). There are limits to how much recursive structure
we can keep in our short-term memory, but there is clearly (or not?) a
logic to it. How does a child learn this logic?
</p>

<p>
Another phenomenon that Chomsky points out is that adverbs, pronouns,
and the like do not always modify or connect to the nearest candidate
word, in a linear sense. Rather, they are related to the structurally
closest word, which may not be closest in an utterance. He
hypothesizes that the understanding of language in the brain does not
take the same form as language as written or spoken (the structures in
the brain are not linear, he believes).
</p>

<blockquote>
<p>
Take a simple sentence like &#34;Instinctively, eagles that fly swim&#34;,
well, &#34;instinctively&#34; goes with swim, it doesn&#39;t go with fly, even
though it doesn&#39;t make sense. And that&#39;s reflexive. &#34;Instinctively&#34;,
the adverb, isn&#39;t looking for the nearest verb, it&#39;s looking for the
structurally most prominent one. That&#39;s a much harder computation. But
that&#39;s the only computation which is ever used. Linear order is a very
easy computation, but it&#39;s never used.
</p>
</blockquote>

<p>
However, linear order is a surface-level phenomenon that, supposedly,
is among the phenomenon that statistical approaches will utilize. A
statistical approach may get good results, usually, by exploiting the
linear order of an utterance but, Chomsky argues, the linear order
and the statistics provide no understanding about the sentence. The
linear order is just a side-effect, a shadow of the true structure.
</p>

<p>
Norvig&#39;s estimation of Chomsky&#39;s points, and Norvig&#39;s replies, are as
follows:
</p>

<ul>
<li><b>Chomsky&#39;s point</b>: Statistical methods have had engineering success,
but that is irrelevant to science.

<ul>
<li><b>Norvig&#39;s reply</b>: He agrees, but engineering success often
facilitates scientific success.
</li>
</ul>
</li>

<li><b>Chomsky&#39;s point</b>: Accurate modeling of language (e.g. statistical
models) is just building descriptions, not explanations.

<ul>
<li><b>Norvig&#39;s reply</b>: Science is both description and explanation; you
can&#39;t have one without the other; in the history of science, the
laborious accumulation of data is the usual mode of operation.
</li>
</ul>
</li>

<li><b>Chomsky&#39;s point</b>: Language is generated from internal structures,
and understood by transforming what&#39;s heard or read into these
structures; language is not generated or understood in the same form
as it comes out (in linear form). The way language is spoken or
written is just a peripheral after-effect, not the
essence.

<ul>
<li><b>Norvig&#39;s reply</b>: People who work in language interpretation
(presumably, in the AI field) see it as a statistical inference;
people actually generate and understand language in some rich
statistical sense (maybe with statistical models several layers
deep, like the modern AI models of speech recognition).
</li>
</ul>
</li>

<li><b>Chomsky&#39;s point</b>: Statistical models are incapable of learning all
the richness of natural language.

<ul>
<li><b>Norvig&#39;s reply</b>: Certain advances in statistical learning methods
provide reason to believe that such learning methods will be able
to do the job.
</li>
</ul>
</li>
</ul>


<div>
<p><img src="http://web.cse.ohio-state.edu/~stiff.4/cse3521/images/kumi-yamashita-building-blocks.jpg" alt="kumi-yamashita-building-blocks.jpg"/>
</p>
<p><span>Figure 2:</span> &#34;Building Blocks,&#34; Kumi Yamashita, 1997; H230, W400, D5cm; wood, single light source, shadow</p>
</div>
</div></div>
  </body>
</html>
