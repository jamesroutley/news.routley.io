<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://nibblestew.blogspot.com/2022/07/implementing-mini-latex-in-2000-lines.html">Original</a>
    <h1>Implementing a “mini-LaTeX” in ~2000 lines of code</h1>
    
    <div id="readability-page-1" class="page"><div id="post-body-7675823142159082589" itemprop="description articleBody">
<p>The <a href="https://nibblestew.blogspot.com/2022/06/attempting-to-create-aesthetic-global.html">previous blog post</a> on this subject got posted to hackernews. The comments were roughly like the following (contains exaggeration, but only a little):</p><blockquote><p>The author claims to obtain superior quality compared to LaTeX but after reading the first three sentences I can say that there is nothing like that in the text so I just stopped there. Worst! Blog! Post! Ever!</p></blockquote><p>So to be absolutely clear I&#39;m not claiming to &#34;beat&#34; LaTeX in any sort of way (nor did I make such a claim in the original post). The quality is probably not better and the code has only a fraction of the functionality of LaTeX. Missing features include things like images, tables, cross references and even fairly basic functionality like widow and orphan control, italic text or any sort of customizability. This is just an experiment I&#39;m doing for my own amusement.</p><p>It can take a simple plain text version of <a href="#">The War of the Worlds</a>, parse it into chapters, lay the text out in justified paragraphs and write the whole thing out into a PDF file. The output looks like this:</p><p><a href="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhH85JOP1wgNXUmOmbyr0v49CWVr6w6Jrc-nen5-vU0FMJ7or2gOyCbjasFr78hQty5TBM_iD8RhiTZt-ZMcqxa7GcoE0N1TKQCYriTb2mPLe_OYTUUPUrsceNOnW9X3AFJv3Yl6uxNXgvDbP1vu2C1YubB1MD2uT8ZTdCFmazcnB_7kUUMtW032_GB/s925/book_pdf.png" imageanchor="1"><img data-original-height="925" data-original-width="600" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEhH85JOP1wgNXUmOmbyr0v49CWVr6w6Jrc-nen5-vU0FMJ7or2gOyCbjasFr78hQty5TBM_iD8RhiTZt-ZMcqxa7GcoE0N1TKQCYriTb2mPLe_OYTUUPUrsceNOnW9X3AFJv3Yl6uxNXgvDbP1vu2C1YubB1MD2uT8ZTdCFmazcnB_7kUUMtW032_GB/s16000/book_pdf.png"/></a></p><p>Even though the implementation is quite simple, it does have some typographical niceties. All new chapters begin on a right-hand page, the text is hyphenated, there are page numbers (but not on an empty page immediately preceding a new chapter) and the first paragraph of each chapter is not indented. The curious among you can <a href="https://www.dropbox.com/s/fsggops6ikgijiu/War_of_the_Worlds_test.pdf?dl=0">examine the actual PDF yourselves</a>. Just be prepared that there are known bugs in it.</p><p>Thus we can reasonably say that <a href="https://github.com/jpakkane/chapterizer">the code</a> does contain an implementation of a very limited and basic form of LaTeX. The code repository has approximately 3000 total lines of C++ code but if you remove the GUI application and other helper code the core implementation only has around 2000 lines. Most of the auxiliary &#34;heavy lifting&#34; code is handled by Pango and Cairo.</p><p>The input text file for War of the Worlds is about 332 kB in size and the final PDF contains 221 pages. The program generates the output in 7 seconds on a Ryzen 7 3700 using only one core. This problem is fairly easily parallelizable so if one were to use all 16 cores at the same time the whole operation would take less than a second. I did not do exact measurements but the processing speed seems to be within the same order of magnitude as plain LaTeX.</p><p>The really surprising thing was that according to Massif the peak memory consumption was 5 MB. I had not tried to save memory when coding and just made copies of strings and other objects without a care in the world and still managed to almost fit the entire workload in the 4 MB L2 cache of the processor. Goes to show that premature optimization really is the root of all evil (or wasted effort at least).</p><p>Most CPU cycles are spent inside Pango. This is not due to any perf problems in Pango, but because this algorithm has an atypical work load. It keeps on asking Pango to shape and measure short text segments that are almost but not entirely identical. For each line that does get rendered, Pango had to process ~10 similar blocks of text. The code caches the results so it should only ask for the size of any individual string once, but this is still the bottleneck. On the other hand since you can process a fairly hefty book in 10 seconds or so it is arguable whether further optimizations are even necessary,</p><p>I don&#39;t have any idea what I&#39;m going to do with this code, if anything. One blue sky idea that came to mind was that it would be kind of cool to have a modern, fully color managed version of LaTeX that goes from markdown to a final PDF and ebook. This is not really feasible with the current approach since Cairo can only produce RGB files. There has been talk of adding full color space support to Cairo but nothing has happened on that front in 10 years or so.</p><p>Cairo is not really on its own in this predicament. Creating PDF files that are suitable for &#34;commercial grade&#34; printing using only open source is surprisingly difficult. For example LibreOffice does output text in the proper grayscale colorspace but silently converts all grayscale images (even 1-bit ones) to RGB. The only software that seems to get everything right is Scribus.</p>

</div></div>
  </body>
</html>
