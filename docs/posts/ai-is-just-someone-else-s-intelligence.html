<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.zdziarski.com/blog/?p=12001">Original</a>
    <h1>AI is just someone else&#39;s intelligence</h1>
    
    <div id="readability-page-1" class="page"><div>
        	
            <div>
        
                <div id="post-12001">
                
                        
        <div>
        
            <p><span><a href="https://www.zdziarski.com/blog/?cat=15" rel="category">Machine Learning</a> . <a href="https://www.zdziarski.com/blog/?cat=31" rel="category">Opinion</a></span></p><p><span>On May 4, 2023 by <a href="https://www.zdziarski.com/blog/?author=1" title="Posts by Jonathan Zdziarski" rel="author">Jonathan Zdziarski</a></span></p><p>It’s been a long time since I’ve worked in the field of ML (or what some call AI), and we’ve come a long way from simple language classification with Bayes and neural nets to what’s being casually called generative AI today. While technology has made a lot of advances, the concepts of machine learning have remained much the same over time: a training set is provided as input into a system, which identifies patterns to create models (traditionally using weighted methods and statistics). This creates a hidden layer of “millions of gears that compute a result” used to form a hypothesis space to sort the most statistically probable outcomes. The complexity of these patterns used to be as simple as words or other tokens, or today are more sophisticated critical patterns relating to authorship, conceptual models, or even patterns within art and music. Such technology has been used for everything from identifying Viagra spam to NLP (natural language processing) and handwriting recognition, and is today being applied to more sophisticated problems from genome sequencing to autonomous driving. Yet the end of the day, these traditional forms of AI were not much more than a sophisticated pattern recognizer. It was a largely deconstructive process.</p>
<p>Today’s generative AI still goes through this type of deconstructive process, but also has a formative element. One of the big differences between traditional forms of ML and generative AI is the direction in which the data flows. Traditionally, inputs flow into the system for both training and queries. To train traditional systems, you’d suck in “a bunch of other people’s stuff”, and it identifies all of the interesting patterns used to product a result. Generative AI takes this a step further, and flips the switch on the vacuum cleaner – and now all of the dirt that was initially fed into the system is shot out the pipe to produce the equivalent of a digital dust cloud of the original training medium. Where these new systems excel goes beyond parsing information into a knowledge base, and now applies formative process to that information – what we might conflate with intelligence. This requires ingesting and computing not just the information, but the the critical patterns of that information (ABBA, or 1-4-5, as very basic examples) to create a new work in the patterns of an existing work. Yet identifying the pattern of Iambic Pentameter, for example, is still an artificial process. It can be computed adaptively with a large enough data set. Even a dumb computer could learn how to write a simple limerick. Extrapolate those patterns into music, art, and much more sophisticated patterns that make up our repertoire of human creativity and it is impressive – but still synthesized. At the end of the day, the output of these systems takes the critical patterns and concepts weighted during the AI’s deconstructive processes (e.g. training) and applies some formative computation to produce a result. Neat-o. Nice parlor trick.</p>
<p>The danger of this type of ML is not that it will take jobs (it definitely will, and already is), but <em>why</em> it will take jobs. It will take jobs not because the computer is replacing the thinking of one worker. It will take jobs because the computer is using the thinking of a million other workers – how can any one worker compete with that? Training material is, at a deconstructed level, the critical patterns of other people’s thoughts, ideas, writings, music, theology, facts, opinions, poetry, and so on. ML has proven wildly successful at identifying these critical patterns and gluing them back together in some different way that delivers the desired result, but at the end of the day all of its intelligence indeed belongs to the other people whose content was used to train it, almost always without their permission. In the end, generative AI takes from the world’s best artists, musicians, philosophers, and other thinkers – erasing their identities, and reassigns credit to its output. Without the proper restraints, it will produce the master forgeries of our generation, and blur the lines between what we view as human ideas and synthesized ones.</p>
<p>There’s an old saying that goes, “Stealing from one person is considered plagiarism. Stealing from everyone is considered research.” As is always the case with new technology, legislation is far behind. I expect that this type of formative AI will face numerous challenges of copyright infringement – as it should. Answering the question of how to define a derived work has been a problem long before AI came along. Case law can be found in the music industry, publishing, art, technology, and in virtually every other place, where humans are accused of copying some initial work from others. Results produced by generative AI today are largely still considered a novelty, however it is very likely that many of its results are already infringing the copyright of others, or at least stealing those ideas. By calling it “generative AI”, the industry is personifying something to try and gain acceptance for the notion that it actually creates new things. A better term for this should be “formative ML”, as it develops concepts and content only based on its learned training inputs and feedback cycle. When a copyright war does start, it will likely be a very long battle. Due to the hidden layers of AI by nature, it will be very difficult to prove provenance of the different training material that contributed to a work.</p>
<p>In many ways, AI is ahead of the people who created it in that the hidden layer is still somewhat of a mystery. Responsible companies operating in this space should take steps now to identify the provenance of the formative concepts stored in their ML layers so that intellectual theft can be eliminated before it even makes it to an output, and prior work can be cited so that these composite works can give proper credit. This should also be expected when forensic analysis of an AI’s output is demanded by the courts. Taint propagation, content coloring, and layer labeling or similar such approaches can be developed to identify the training sources that contributed to individual conceptual layers or even individual weights. In order to develop any sort of ethics in AI, the “hidden” layer must become transparent to keep the ML within a certain set of parameters (what we might call honesty). These layers must be better understood before generative AI can be reliably used without risk of intellectual property theft. Unlike humans, we have the ability to dip into the brains of these systems and see the interconnections that contribute to the processing. The sources of these interconnections are largely lost today. It’s important we start holding a system accountable for what it has learned and where it learned it, just as humans are held accountable. It is technologically possible to create a system that can account for the origins of its output and provide citations for its own derivative work. This missing piece is the moral responsibility of any company specializing in generative AI, and a good place to start with legislation.</p>




        
        </div>

	            
                </div>
        
			</div>
        
        </div></div>
  </body>
</html>
