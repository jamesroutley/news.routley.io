<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://developers.googleblog.com/en/introducing-paligemma-2-powerful-vision-language-models-simple-fine-tuning/">Original</a>
    <h1>PaliGemma 2: Powerful Vision-Language Models, Simple Fine-Tuning</h1>
    
    <div id="readability-page-1" class="page"><div>

    
      <section>
        
      </section>
    

    <section>
      
    </section>

    <section>
      
    </section>

    <section>

      <section>
      
        
          
        
          
        

      
      </section>
      
    </section>

    
    <section>
      <div>
          

<div>
    <p data-block-key="9hsof">Building custom, advanced AI that can &#34;see&#34; used to be a complex and resource-intensive endeavor. Not anymore. This past May, <a href="https://developers.googleblog.com/en/gemma-family-and-toolkit-expansion-io-2024/">we launched PaliGemma</a>, the first vision-language model in the <a href="https://ai.google.dev/gemma">Gemma</a> family, taking a significant step toward making class-leading visual AI more accessible. Now, we&#39;re thrilled to introduce PaliGemma 2, the next evolution in tunable vision-language models.</p><p data-block-key="dg98a">PaliGemma 2 builds upon the performant Gemma 2 models, adding the power of vision and making it easier than ever to fine-tune for exceptional performance. With PaliGemma 2, these models can see, understand, and interact with visual input, opening up a world of new possibilities.</p><h2 data-block-key="e835v"><b><br/></b>What’s new in PaliGemma 2?</h2><ul><li data-block-key="8v87j"><b>Scalable performance:</b> Optimize performance for any task with PaliGemma 2&#39;s multiple model sizes (3B, 10B, 28B parameters) and resolutions (224px, 448px, 896px).</li></ul><ul><li data-block-key="3v3l6"><b>Long captioning:</b> PaliGemma 2 generates detailed, contextually relevant captions for images, going beyond simple object identification to describe actions, emotions, and the overall narrative of the scene.</li></ul><ul><li data-block-key="248hb"><b>Expanding to new horizons:</b> Our research demonstrates leading performance on chemical formula recognition, music score recognition, spatial reasoning, and chest X-ray report generation, as detailed in the <a href="https://arxiv.org/abs/2412.03555">technical report</a>.</li></ul><p data-block-key="2fh2g">Upgrading to PaliGemma 2 is a breeze for existing PaliGemma users. It&#39;s designed as a drop-in replacement, offering a range of model sizes with immediate performance gains on most tasks without major code modifications. Additionally, its flexibility makes fine-tuning for specific tasks and datasets straightforward, empowering you to tailor its capabilities to your precise needs.</p><p data-block-key="31vp">You can learn more about how PaliGemma 2 works, including when to use more parameters and larger resolutions, in our <a href="https://arxiv.org/abs/2412.03555">technical report</a>.</p><h2 data-block-key="bfb"><b><br/></b>Building on the success of PaliGemma</h2><p data-block-key="d1m14">Since its launch, the Gemma family has rapidly grown into a vibrant ecosystem—the Gemmaverse—with tens of thousands of models and applications. This rapid growth is a testament to the community&#39;s ingenuity. Early innovations using PaliGemma, such as <a href="https://huggingface.co/blog/manu/colpali">ColPali&#39;s advancements</a> in visual document retrieval, <a href="https://blog.roboflow.com/how-to-fine-tune-paligemma/">RoboFlow&#39;s fine-tuning techniques</a>, and progress in <a href="https://x.com/sumo43_/status/1791589684121903555">real-time object tracking</a>, demonstrate the expanding potential of the Gemmaverse.</p><h2 data-block-key="20kik"><b><br/></b>Get started today</h2><p data-block-key="4fb7l">Ready to explore the potential of PaliGemma 2? Here&#39;s how:</p><ul><li data-block-key="fbhpj"><b>Download models &amp; code:</b> Find the pre-trained models and code on <a href="https://huggingface.co/collections/google/paligemma-2-release-67500e1e1dbfdd4dee27ba48">Hugging Face</a> and <a href="https://www.kaggle.com/models/google/paligemma-2">Kaggle</a>.</li></ul><ul><li data-block-key="5pc7l"><b>Learn &amp; integrate:</b> Dive into our <a href="https://ai.google.dev/gemma/docs/paligemma">comprehensive documentation</a> and <a href="https://github.com/google-gemini/gemma-cookbook/tree/main/PaliGemma">example notebooks</a> to quickly integrate these powerful tools into your projects. For PaliGemma, start with our <a href="https://ai.google.dev/gemma/docs/paligemma/inference-with-keras">inference notebook</a> then try <a href="https://github.com/merveenoyan/smol-vision/blob/main/Fine_tune_PaliGemma.ipynb">fine-tuning with a custom dataset</a>.</li></ul><ul><li data-block-key="8d1k2"><b>Use your preferred framework:</b> Leverage your preferred tools and frameworks, including <a href="https://huggingface.co/blog/paligemma2">Hugging Face Transformers</a>, <a href="https://www.kaggle.com/code/nilaychauhan/finetune-paligemma-2-with-keras">Keras</a>, PyTorch, <a href="https://ai.google.dev/gemma/docs/paligemma/fine-tuning-paligemma">JAX</a>, and <a href="https://github.com/google/gemma.cpp/tree/main?tab=readme-ov-file#paligemma-vision-language-model">Gemma.cpp</a>.</li></ul>
</div> 
      </div>
    </section>
    

    <section>
      
      
    </section>

    
    
    
  </div></div>
  </body>
</html>
