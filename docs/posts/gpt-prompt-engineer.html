<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/mshumer/gpt-prompt-engineer">Original</a>
    <h1>GPT-Prompt-Engineer</h1>
    
    <div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text">
<p dir="auto"><a href="https://twitter.com/mattshumer_" rel="nofollow"><img src="https://camo.githubusercontent.com/3f2ef3da38c79ef4c01ff068c1062e0c06200161a767b4015ce0372de4180d96/68747470733a2f2f696d672e736869656c64732e696f2f747769747465722f666f6c6c6f772f6d6174747368756d65725f3f7374796c653d736f6369616c" alt="Twitter Follow" data-canonical-src="https://img.shields.io/twitter/follow/mattshumer_?style=social"/></a> <a href="https://colab.research.google.com/github/mshumer/gpt-prompt-engineer/blob/main/gpt_prompt_engineer.ipynb" rel="nofollow"><img src="https://camo.githubusercontent.com/84f0493939e0c4de4e6dbe113251b4bfb5353e57134ffd9fcab6b8714514d4d1/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open Main Version In Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg"/></a> <a href="https://colab.research.google.com/drive/16NLMjqyuUWxcokE_NF6RwHD8grwEeoaJ?usp=sharing" rel="nofollow"><img src="https://camo.githubusercontent.com/84f0493939e0c4de4e6dbe113251b4bfb5353e57134ffd9fcab6b8714514d4d1/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open Classification Version In Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg"/></a></p>
<h2 tabindex="-1" dir="auto"><a id="user-content-overview" aria-hidden="true" href="#overview"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Overview</h2>
<p dir="auto">Prompt engineering is kind of like alchemy. There&#39;s no clear way to predict what will work best. It&#39;s all about experimenting until you find the right prompt. <code>gpt-prompt-engineer</code> is a tool that takes this experimentation to a whole new level.</p>
<p dir="auto"><strong>Simply input a description of your task and some test cases, and the system will generate, test, and rank a multitude of prompts to find the ones that perform the best.</strong></p>
<h2 tabindex="-1" dir="auto"><a id="user-content-features" aria-hidden="true" href="#features"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Features</h2>
<ul dir="auto">
<li>
<p dir="auto"><strong>Prompt Generation</strong>: Using GPT-4 and GPT-3.5-Turbo, <code>gpt-prompt-engineer</code> can generate a variety of possible prompts based on a provided use-case and test cases.</p>
</li>
<li>
<p dir="auto"><strong>Prompt Testing</strong>: The real magic happens after the generation. The system tests each prompt against all the test cases, comparing their performance and ranking them using an ELO rating system.</p>
</li>
</ul>
<a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/41550495/250947004-f8171cff-1703-40ca-b9fd-f0aa24d07110.png"><img width="1563" alt="Screen Shot 2023-07-04 at 11 41 54 AM" src="https://user-images.githubusercontent.com/41550495/250947004-f8171cff-1703-40ca-b9fd-f0aa24d07110.png"/></a>
<ul dir="auto">
<li>
<p dir="auto"><strong>ELO Rating System</strong>: Each prompt starts with an ELO rating of 1200. As they compete against each other in generating responses to the test cases, their ELO ratings change based on their performance. This way, you can easily see which prompts are the most effective.</p>
</li>
<li>
<p dir="auto"><strong>Classification Version</strong>: The <code>gpt-prompt-engineer -- Classification Version</code> notebook is designed to handle classification tasks. It evaluates the correctness of a test case by matching it to the expected output (&#39;true&#39; or &#39;false&#39;) and provides a table with scores for each prompt.</p>
</li>
</ul>
<a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/41550495/252494291-d5c9f2a8-97fa-445d-9c38-dec744f77854.png"><img width="1607" alt="Screen Shot 2023-07-10 at 5 22 24 PM" src="https://user-images.githubusercontent.com/41550495/252494291-d5c9f2a8-97fa-445d-9c38-dec744f77854.png"/></a>
<ul dir="auto">
<li><strong>Weights &amp; Biases Logging</strong>: Optional logging to <a href="https://wandb.ai/site" rel="nofollow">Weights &amp; Biases</a> of your configs such as temperature and max tokens, the system and user prompts for each part, the test cases used and the final ranked ELO rating for each candidate prompt. Set <code>use_wandb</code> to <code>True</code> to use. Only available in the main <code>gpt-prompt-engineer</code> notebook for now.</li>
</ul>
<h2 tabindex="-1" dir="auto"><a id="user-content-setup" aria-hidden="true" href="#setup"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Setup</h2>
<ol dir="auto">
<li>
<p dir="auto"><a href="https://colab.research.google.com/github/mshumer/gpt-prompt-engineer/blob/main/gpt_prompt_engineer.ipynb" rel="nofollow">Open the notebook in Google Colab</a> or in a local Jupyter notebook. For classification, use <a href="https://colab.research.google.com/drive/16NLMjqyuUWxcokE_NF6RwHD8grwEeoaJ?usp=sharing" rel="nofollow">this one.</a></p>
</li>
<li>
<p dir="auto">Add your OpenAI API key to the line <code>openai.api_key = &#34;ADD YOUR KEY HERE&#34;</code>.</p>
</li>
<li>
<p dir="auto">If you have GPT-4 access, you&#39;re ready to move on. If not, change <code>CANDIDATE_MODEL=&#39;gpt-4&#39;</code> to <code>CANDIDATE_MODEL=&#39;gpt-3.5-turbo&#39;</code>. If you&#39;re using the classification version, and don&#39;t have GPT-4 access, change <code>model=&#39;gpt-4&#39;</code> in the second cell to `model=&#39;gpt-3.5-turbo&#39;.</p>
</li>
</ol>
<h2 tabindex="-1" dir="auto"><a id="user-content-how-to-use" aria-hidden="true" href="#how-to-use"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>How to Use</h2>
<ol dir="auto">
<li>Define your use-case and test cases. The use-case is a description of what you want the AI to do. Test cases are specific prompts that you would like the AI to respond to. For example:</li>
</ol>
<div data-snippet-clipboard-copy-content="description = &#34;Given a prompt, generate a landing page headline.&#34; # this style of description tends to work well

test_cases = [
    {
        &#39;prompt&#39;: &#39;Promoting an innovative new fitness app, Smartly&#39;,
    },
    {
        &#39;prompt&#39;: &#39;Why a vegan diet is beneficial for your health&#39;,
    },
    {
        &#39;prompt&#39;: &#39;Introducing a new online course on digital marketing&#39;,
    },
    {
        &#39;prompt&#39;: &#39;Launching a new line of eco-friendly clothing&#39;,
    },
    {
        &#39;prompt&#39;: &#39;Promoting a new travel blog focusing on budget travel&#39;,
    },
    {
        &#39;prompt&#39;: &#39;Advertising a new software for efficient project management&#39;,
    },
    {
        &#39;prompt&#39;: &#39;Introducing a new book on mastering Python programming&#39;,
    },
    {
        &#39;prompt&#39;: &#39;Promoting a new online platform for learning languages&#39;,
    },
    {
        &#39;prompt&#39;: &#39;Advertising a new service for personalized meal plans&#39;,
    },
    {
        &#39;prompt&#39;: &#39;Launching a new app for mental health and mindfulness&#39;,
    }
]"><pre><code>description = &#34;Given a prompt, generate a landing page headline.&#34; # this style of description tends to work well

test_cases = [
    {
        &#39;prompt&#39;: &#39;Promoting an innovative new fitness app, Smartly&#39;,
    },
    {
        &#39;prompt&#39;: &#39;Why a vegan diet is beneficial for your health&#39;,
    },
    {
        &#39;prompt&#39;: &#39;Introducing a new online course on digital marketing&#39;,
    },
    {
        &#39;prompt&#39;: &#39;Launching a new line of eco-friendly clothing&#39;,
    },
    {
        &#39;prompt&#39;: &#39;Promoting a new travel blog focusing on budget travel&#39;,
    },
    {
        &#39;prompt&#39;: &#39;Advertising a new software for efficient project management&#39;,
    },
    {
        &#39;prompt&#39;: &#39;Introducing a new book on mastering Python programming&#39;,
    },
    {
        &#39;prompt&#39;: &#39;Promoting a new online platform for learning languages&#39;,
    },
    {
        &#39;prompt&#39;: &#39;Advertising a new service for personalized meal plans&#39;,
    },
    {
        &#39;prompt&#39;: &#39;Launching a new app for mental health and mindfulness&#39;,
    }
]
</code></pre></div>
<p dir="auto">For the classification version, your test cases should be in the format:</p>
<div data-snippet-clipboard-copy-content="test_cases = [
    {
        &#39;prompt&#39;: &#39;I had a great day!&#39;,
        &#39;output&#39;: &#39;true&#39;
    },
    {
        &#39;prompt&#39;: &#39;I am feeling gloomy.&#39;,
        &#39;output&#39;: &#39;false&#39;
    },
    // add more test cases here
]"><pre><code>test_cases = [
    {
        &#39;prompt&#39;: &#39;I had a great day!&#39;,
        &#39;output&#39;: &#39;true&#39;
    },
    {
        &#39;prompt&#39;: &#39;I am feeling gloomy.&#39;,
        &#39;output&#39;: &#39;false&#39;
    },
    // add more test cases here
]
</code></pre></div>
<ol start="3" dir="auto">
<li>
<p dir="auto">Choose how many prompts to generate. Keep in mind, this can get expensive if you generate many prompts. 10 is a good starting point.</p>
</li>
<li>
<p dir="auto">Call <code>generate_optimal_prompt(description, test_cases, number_of_prompts)</code> to generate a list of potential prompts, and test and rate their performance. For the classification version, just run the last cell.</p>
</li>
<li>
<p dir="auto">The final ELO ratings will be printed in a table, sorted in descending order. The higher the rating, the better the prompt.</p>
</li>
</ol>
<a target="_blank" rel="noopener noreferrer" href="https://user-images.githubusercontent.com/41550495/250948262-324f90b8-c0ee-45fd-b219-6c44d9aa281b.png"><img width="1074" alt="Screen Shot 2023-07-04 at 11 48 45 AM" src="https://user-images.githubusercontent.com/41550495/250948262-324f90b8-c0ee-45fd-b219-6c44d9aa281b.png"/></a>
<p dir="auto">For the classification version, the scores for each prompt will be printed in a table (see the image above).</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-contributions-are-welcome-some-ideas" aria-hidden="true" href="#contributions-are-welcome-some-ideas"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Contributions are welcome! Some ideas:</h2>
<ul dir="auto">
<li>have a number of different system prompt generators that create different styles of prompts, to cover more ground (ex. examples, verbose, short, markdown, etc.)</li>
<li>automatically generate the test cases</li>
<li>expand the classification version to support more than two classes using tiktoken</li>
</ul>
<h2 tabindex="-1" dir="auto"><a id="user-content-license" aria-hidden="true" href="#license"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>License</h2>
<p dir="auto">This project is <a href="https://github.com/your_username/your_repository/blob/master/LICENSE">MIT</a> licensed.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-contact" aria-hidden="true" href="#contact"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Contact</h2>
<p dir="auto">Matt Shumer - <a href="https://twitter.com/mattshumer_" rel="nofollow">@mattshumer_</a></p>
<p dir="auto">Project Link: <a href="https://basicbitch.software/mshumer/gpt-prompt-engineer/blob/main/url">https://github.com/mshumer/gpt-prompt-engineer</a></p>
</article>
          </div></div>
  </body>
</html>
