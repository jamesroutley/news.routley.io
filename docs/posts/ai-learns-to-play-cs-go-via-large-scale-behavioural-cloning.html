<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://arxiv.org/abs/2104.04258">Original</a>
    <h1>AI Learns to Play CS:Go via Large-Scale Behavioural Cloning</h1>
    
    <div id="readability-page-1" class="page"><div id="content-inner">
  <div id="abs">
    
    
    
      
    
  
    <p><a href="https://arxiv.org/pdf/2104.04258">Download PDF</a></p><blockquote>
      <span>Abstract:</span>  This paper describes an AI agent that plays the popular first-person-shooter
(FPS) video game `Counter-Strike; Global Offensive&#39; (CSGO) from pixel input.
The agent, a deep neural network, matches the performance of the medium
difficulty built-in AI on the deathmatch game mode, whilst adopting a humanlike
play style. Unlike much prior work in games, no API is available for CSGO, so
algorithms must train and run in real-time. This limits the quantity of
on-policy data that can be generated, precluding many reinforcement learning
algorithms. Our solution uses behavioural cloning - training on a large noisy
dataset scraped from human play on online servers (4 million frames, comparable
in size to ImageNet), and a smaller dataset of high-quality expert
demonstrations. This scale is an order of magnitude larger than prior work on
imitation learning in FPS games.

    </blockquote>

    <!--CONTEXT-->
    
  </div>
</div><div>
      <h2>Submission history</h2><p> From: Tim Pearce [<a href="https://arxiv.org/show-email/00403da6/2104.04258">view email</a>]
      </p></div></div>
  </body>
</html>
