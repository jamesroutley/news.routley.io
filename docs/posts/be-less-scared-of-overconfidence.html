<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.benkuhn.net/overconfidence/">Original</a>
    <h1>Be less scared of overconfidence</h1>
    
    <p>When I was deciding whether to work for <a href="https://www.wave.com/en/">Wave</a>, I got <em>very hung up</em> on the fact that my &ldquo;total compensation&rdquo; would be &ldquo;lower.&rdquo;</p>
<p>The scare quotes are there because Wave and my previous employer, <a href="https://www.theoremlp.com/">Theorem</a>, were both early-stage startups that were paying me mostly in <del>fake startup bucks</del> equity. To figure out the total compensation, I tried to guess how much money the equity in each company was worth, with a thought process something like:</p>
<ul>
<li>Both of these companies have been invested in by reputable, top-tier venture capitalists.</li>
<li>The market for for-profit investments is pretty <a href="https://en.wikipedia.org/wiki/Efficient-market_hypothesis">efficient</a>, and most people who think they can do better are being overconfident.</li>
<li>Who am I, a lowly 22-year-old programmer, to disagree with reputable top-tier venture capitalists? I should defer to them about the valuations.</li>
</ul>
<p>So I valued the equity by taking the valuation each company&rsquo;s VCs had invested at, and multiplied it by the fraction of the company my shares represented. That number was higher for Theorem than for Wave.</p>
<p>Seven years on, the Wave equity turned out to be&hellip; <a href="https://www.businesswire.com/news/home/20200825005820/en/WorldRemit-to-Acquire-Sendwave">a lot</a> more valuable. That raises the question: how dumb was my take? Was the actual outcome predictable if I&rsquo;d thought about it in the right way?</p>
<p>I don&rsquo;t think it was <em>perfectly</em> predictable, but I do think I shouldn&rsquo;t have been that anchored to the market-efficiency reasoning. Those respectable, top-tier VCs had YOLOed those valuations after a couple one-hour meetings, because that&rsquo;s how early-stage VC works. Meanwhile, I had worked at Theorem for a year and my then-partner had worked at Wave for nine months. Heck, I had gotten more founder time than those VCs had <em>just during my interview process</em>. I had way more information than &ldquo;the market.&rdquo;</p>
<p>If I&rsquo;d had the confidence to use that information, I might have thought something like:</p>
<ul>
<li>After its funding round, Wave continued to add users at one of the fastest paces their investors had ever seen, whereas Theorem is struggling to grow.</li>
<li>Theorem is constrained by its ability to do sales, and the founders don&rsquo;t seem to be acting with enough focus or urgency to unblock that constraint. Instead, they&rsquo;re distracting themselves with things like hiring machine learning interns (i.e. me).</li>
<li>The founders of Wave seem much smarter, more <a href="http://www.paulgraham.com/relres.html">relentlessly resourceful</a>, and more trustworthy.</li>
<li>Given the above, I should value the Wave equity way more even though its naive <a href="https://en.wikipedia.org/wiki/Expected_value">expected value</a> is less than the Theorem equity.</li>
</ul>
<p>Fortunately, I chose Wave for other reasons. But this thought pattern&mdash;throwing away most information in fear of using it to make overconfident judgments&mdash;shows up all the time. I&rsquo;m here to tell you why I hate it.</p>
<hr>
<p>In January 2020, my entire Twitter timeline was freaking out about a novel-seeming respiratory disease spreading in Wuhan.</p>
<p>Part of me thought:</p>
<ul>
<li>All the <a href="https://archive.ph/FHWIg">reputable</a>, <a href="https://archive.ph/0v7cW">top-tier</a> <a href="https://twitter.com/balajis/status/1248317806589825027/photo/1">technocrats</a> are <a href="https://archive.ph/STRw3">ridiculing</a> the freaked-out people.</li>
<li>Usually, when a ragtag band of Internet weirdos thinks they know better than a large group of reputable, top-tier technocrats, the Internet weirdos are being overconfident.</li>
<li>So the technocrats are probably right on this one.</li>
</ul>
<p>Another part of me thought:</p>
<ul>
<li>Huh, the simple model of &ldquo;this thing has a fast exponential growth rate and spreads when people are asymptomatic so it&rsquo;s very hard to stop&rdquo; seems like a compelling reason to think things will be quite bad.</li>
<li>When reputable, top-tier technocrats say not to freak out, they don&rsquo;t usually address the best arguments in favor of freaking out, and they often seem like they don&rsquo;t understand how exponential growth works.</li>
<li>Maybe I&rsquo;ll buy a lot of beans in case everything goes to shit.</li>
</ul>
<p>(I also contemplated the fact that the stock market didn&rsquo;t seem to be freaking out, but I decided that since <a href="https://onlinelibrary.wiley.com/doi/abs/10.1111/j.1540-6261.1995.tb04795.x">most people can&rsquo;t beat the stock market</a>, I probably wouldn&rsquo;t either. Some braver souls than I <a href="https://www.lesswrong.com/posts/jAixPHwn5bmSLXiMZ/open-and-welcome-thread-february-2020?commentId=S67RYcBTbjYWBcdon">bought puts on the S&amp;P 500</a> and made a killing.)</p>
<hr>
<p>In both of these situations, I had some mental model of what was going on (&ldquo;this epidemic is growing exponentially,&rdquo; &ldquo;this startup seems good&rdquo;) based on the particulars of the situation, but instead of using my internal model to make a prediction, I threw away all my knowledge of the particulars and instead used a simple, easy-to-apply heuristic (&ldquo;experts are usually right,&rdquo; &ldquo;markets are efficient&rdquo;).</p>
<p>I frequently see people leaning heavily on this type of <em>low-information heuristic</em> to make important decisions for themselves, or to smack down overconfident-sounding ideas from other people.</p>
<ul>
<li>
<p>This startup is growing incredibly fast and the founders are some of the most effective people I&rsquo;ve ever met, but at their current VC valuation, the total comp is lower than my Big Tech job so I can&rsquo;t justify the move.</p>
</li>
<li>
<p>I think I could have a big impact as an academic researcher, but <a href="https://www.benkuhn.net/grad/">most grad students end up depressed</a> and <a href="https://forum.effectivealtruism.org/posts/3TQTec6FKcMSRBT2T/estimation-of-probabilities-to-get-tenure-track-in-academia">don&rsquo;t land a tenure-track position</a>, so it&rsquo;s not worth trying.</p>
</li>
<li>
<p>You&rsquo;re going to start a company? Are you aware that 90% of startups fail? What makes you think you and your ragtag band of weirdos are the chosen ones?</p>
</li>
<li>
<p>Who are you to be sounding the alarm about a pandemic when every past alarm has been false and all the reputable, top-tier experts say not to worry?</p>
</li>
</ul>
<p>These all place <em>way</em> too much weight on the low-info heuristic.</p>
<p>A heuristic like that can make a good starting point when you&rsquo;re not an expert in an area and don&rsquo;t have very much time to think about it or dig in. This is useful in theory, but in practice, people don&rsquo;t limit them to that regime&mdash;they fall back on the same heuristics even in high-context, high-investment situations, where it&rsquo;s silly to throw away so much detailed context about the particulars.</p>
<p>What&rsquo;s worse, these low-info heuristics almost always push in the direction of <em>being less ambitious</em>, because the low-info view of any ambitious project is that it will fail (most projects run behind schedule, most startups fail, most investors underperform the market, etc.).</p>
<p>The problem is that the bad consequences of underconfidence and under-ambition are severe but subtle, whereas the bad consequences of overconfidence and wishful thinking are milder but more obvious. If you&rsquo;re overconfident, you&rsquo;ll try things that fail, and people will laugh at you. If you&rsquo;re underconfident, you&rsquo;ll avoid making risky bets, and miss out on the potential upside, but nobody will know for sure what you missed.</p>
<p>That means it&rsquo;s always tempting to do what the low-info heuristic tells you and be less ambitious&mdash;but ultimately, that ends up being worse for the world.</p>
<hr>
<p>Why do people find low-info heuristics so compelling? A few potential reasons:</p>
<ul>
<li>
<p>Many (most?) attempts to reason via specific details <em>are</em> wrong. Most people who think &ldquo;I&rsquo;m going to beat the market&rdquo; don&rsquo;t; most people who think &ldquo;I know better than all the experts&rdquo; are less <a href="https://www.coindesk.com/markets/2020/12/08/balaji-srinivasan-the-man-who-called-covid/">Balaji Srinivasan</a> and more <a href="https://timecube.2enp.com/">Time Cube guy</a>.</p>
</li>
<li>
<p>The reasoning and evidence backing up low-info heuristics is (relatively) legible and easily verifiable. If I claim &ldquo;90% of startups fail,&rdquo; I can often cite a study for support. Whereas if I claim &ldquo;the markets aren&rsquo;t freaking out enough about COVID,&rdquo; I&rsquo;d need to make a much more complicated argument to explain my reasoning.</p>
</li>
<li>
<p>It&rsquo;s relatively straightforward to reason with low-info heuristics even when you&rsquo;re not an expert in the domain. For something like <a href="https://www.gjopen.com/">a forecasting challenge</a>, where forecasters need to make predictions across a wide range of topics and can&rsquo;t possibly be an expert in all of them, this is very important.</p>
</li>
<li>
<p>Because it&rsquo;s much more objective, reasoning via low-info heuristics gives you many fewer opportunities to fall prey to biases like <a href="https://en.wikipedia.org/wiki/Optimism_bias">optimism bias</a>, <a href="https://en.wikipedia.org/wiki/Motivated_reasoning">motivated reasoning</a>, <a href="https://en.wikipedia.org/wiki/Planning_fallacy">the planning fallacy</a>, etc.</p>
</li>
</ul>
<p>Those are all real advantages! low-info heuristics are a great way to be more-or-less right most of the time as a non-expert, and to limit your vulnerability to overconfidence and wishful thinking.</p>
<hr>
<p>The problem is that there are lots of ways that low-info heuristics fail or can be improved on.</p>
<p>For example, the <a href="https://en.wikipedia.org/wiki/Efficient-market_hypothesis">efficient market hypothesis</a> (&ldquo;asset prices incorporate all available information, so it&rsquo;s hard to beat the market&rdquo; used in the above example to infer that &ldquo;venture capitalists value companies correctly&rdquo;) is justified by economic theory that relies on a few assumptions:</p>
<ul>
<li>
<p><strong>Low transaction costs:</strong> The cost of doing a trade in the market (in this case, an investment) must be near-zero so that people can use any mispricings to get rich.</p>
</li>
<li>
<p><strong>Enough smart money:</strong> The well-informed and rational players in the market need to have enough capital to take advantage of any pricing inefficiencies that they notice.</p>
</li>
<li>
<p><strong>No secrets:</strong> The &ldquo;available information&rdquo; must be available to enough of the smart money that it can be used to correct mispricings.</p>
</li>
<li>
<p><strong>Ability to profit:</strong> There must be a way for a smart market participant to make money from a mispriced asset.</p>
</li>
</ul>
<p>In the case of venture capital, many of these assumptions are <em>super false</em>. Fundraising takes a lot of time and money: transaction costs are high. Venture capitalists YOLO their valuations after a few meetings: they frequently miss important information. And it&rsquo;s impossible to <a href="https://en.wikipedia.org/wiki/Short_%28finance%29">short-sell</a> startups, so there&rsquo;s no market mechanism to correct an overpriced company. You can see the outcome of this in the fact that <a href="https://www.benkuhn.net/vc-emh/">there are venture capitalists that consistently beat &ldquo;the market&rsquo;s&rdquo; returns</a>.</p>
<p>But it&rsquo;s not just venture capital: <em>almost no markets</em> fully satisfy the conditions of the EMH, and many important markets&mdash;like housing or prediction markets&mdash;strongly violate them.</p>
<p>Or consider the heuristic that &ldquo;if internet weirdos disagree with experts, the experts are right.&rdquo; What community of Internet weirdos and what community of experts? Some communities of experts are clearly bonkers, like the victims of the <a href="https://en.wikipedia.org/wiki/Sokal_affair">Sokal hoax</a>. In other cases, a community with expertise in one narrow area might not have the context in adjacent areas or the ability to do the first-principles thinking necessary to apply their expertise correctly in the real world. For example, doctors are experts in medicine, and thus are often expected to make medical diagnoses, but only <a href="https://blogs.cornell.edu/info2040/2014/11/12/doctors-dont-know-bayes-theorem/comment-page-1/">21% of doctors</a> are capable of doing the elementary statistical calculations necessary to turn a medical test result into the probability of having a disease.</p>
<p>Or consider the heuristic of <a href="https://en.wikipedia.org/wiki/Reference_class_forecasting">the outside view</a>: &ldquo;the outcome of this situation will probably be similar to the outcome of similar past situations.&rdquo; Suppose you&rsquo;re using this to judge how likely a startup is to succeed. Sure, you could predict it based on the distribution of outcomes across all startups at a similar stage and valuation. But that would throw away <em>almost all information</em> you have about the particular startup at hand. It ignores tons of important questions, like:</p>
<ul>
<li>How fast are they growing?</li>
<li>How long have they been growing that fast?</li>
<li>How big is the potential market?</li>
<li>How much of a <a href="https://www.investopedia.com/ask/answers/05/economicmoat.asp">moat</a> does the business have?</li>
<li>How <a href="https://twitter.com/benskuhn/status/1378342797858734081">unreasonably determined</a> are the founders?</li>
<li>How <a href="https://www.benkuhn.net/vc-emh/">famous are their investors</a>?</li>
</ul>
<p>You could imagine trying to incorporate info like this into your outside-view analysis, by, e.g., looking at outcomes specifically of all startups that have grown by 10x in a single year. But that kind of information is so private and closely guarded that you probably can&rsquo;t do that analysis. For some of the other traits, e.g. &ldquo;how determined are the founders,&rdquo; we don&rsquo;t even have a good enough way of measuring that trait that you could do the analysis even in principle.</p>
<p>Sometimes I see people use the low-info heuristic as a &ldquo;baseline&rdquo; and then apply some sort of &ldquo;fudge factor&rdquo; for the illegible information that isn&rsquo;t incorporated into the baseline&mdash;something like &ldquo;the baseline probability of this startup succeeding is 10%, but the founders seem really determined so I&rsquo;ll guesstimate that gives them a 50% higher probability of success.&rdquo; In principle I could imagine this working reasonably well, but in practice most people who do this aren&rsquo;t willing to apply as large of a fudge factor as appropriate. <a href="https://www.lesswrong.com/posts/JD7fwtRQ27yc8NoqS/strong-evidence-is-common">Strong evidence is common</a>:</p>
<blockquote>
<p>One time, someone asked me what my name was. I said, “Mark Xu.” Afterward, they probably believed my name was “Mark Xu.” I’m guessing they would have happily accepted a bet at 20:1 odds that my driver’s license would say “Mark Xu” on it.</p>
<p>The prior odds that someone’s name is “Mark Xu” are generously 1:1,000,000. Posterior odds of 20:1 implies that the odds ratio of me saying “Mark Xu” is 20,000,000:1, or roughly 24 bits of evidence. That’s a lot of evidence.</p>
<p>&hellip; One implication of the Efficient Market Hypothesis (EMH) is that is it difficult to make money on the stock market. Generously, maybe only the top 1% of traders will be profitable. How difficult is it to get into the top 1% of traders? To be 50% sure you&rsquo;re in the top 1%, you only need 200:1 evidence. This seemingly large odds ratio might be easy to get.</p>
</blockquote>
<hr>
<p>In fact, outperforming low-info heuristics isn&rsquo;t just possible; it&rsquo;s practically mandatory if you want to have an outsized impact on the world. That&rsquo;s because leaning too heavily on low-info heuristics pushes people away from being ambitious or trying to <a href="https://www.benkuhn.net/outliers/">search for outliers</a>.</p>
<p>Most important things in life&mdash;jobs, hires, companies, ideas, partners, etc.&mdash;have a distribution of outcomes where the best possible choices are <em>outliers</em> that are dramatically better than the typical ones. In my case, for example, choosing to work at Wave was probably 10x better than staying at my previous employer: I learned more, gained responsibility faster, had a bigger impact on the world, etc.</p>
<p>Unfortunately, <em>low-info heuristics tell you that outliers can&rsquo;t exist</em>. By definition, most members of any group are not outliers, so any generalized heuristic will predict that whatever you&rsquo;re looking at isn&rsquo;t an outlier either. If you index too heavily on what the average outcome is, you&rsquo;re deliberately blinding yourself to the possibility of finding an outlier.</p>
<p>This is especially bad when someone uses this kind of reasoning to smack down other people&rsquo;s ambition, because the payoffs are asymmetric. If you incorrectly tell someone that their ambitious idea is likely to succeed, then they&rsquo;ll waste their time on a failed idea, which is not great, but ultimately fine. But if you smack them down with low-info heuristics and convince them their idea is likely to fail, you rob the world of an awesome idea that would have existed otherwise. Shame on you! (Too bad you&rsquo;ll never know about it.)</p>
<hr>
<p>OK, so what should you do instead of relying on low-info heuristics? Here are my suggestions:</p>
<ul>
<li>
<p>Build <a href="https://www.lesswrong.com/posts/B7P97C27rvHPz3s9B/gears-in-understanding">gears-level models</a> of the decision you&rsquo;re trying to make. If you&rsquo;re deciding, e.g., where to work, try to understand what makes different jobs awesome or terrible for you.</p>
</li>
<li>
<p><a href="https://www.benkuhn.net/thinkrealhard/">Think really hard</a> about the problem. Most inside views <em>are</em> wrong&mdash;to stand a fighting chance of beating the outside view, you&rsquo;ll need to put a lot of effort in.</p>
</li>
<li>
<p>Don&rsquo;t fool yourself with motivated reasoning. Stress-test your ideas; ask yourself what the best arguments against your inside view are and see if you can rebut them.</p>
<ul>
<li>To the extent that you do use low-info heuristics, use them as a stress test rather than a default belief. &ldquo;90% of startups fail&rdquo; is useful to know as a warning to try to mitigate failure modes. It&rsquo;s dangerous when you hear it and stop thinking there.</li>
</ul>
</li>
<li>
<p>Don&rsquo;t be afraid to try ambitious things where the downside of failing is low, and the upside of succeeding is high!</p>
</li>
</ul>
<p><small><em>Thanks to draft readers <a href="https://irenechen.net/">Irene Chen</a>, <a href="https://milan.cvitkovic.net/">Milan Cvitkovic</a>, and <a href="https://twitter.com/Ferrum_of_omega">Sam Zimmerman</a>.</em></small></p>
  </body>
</html>
