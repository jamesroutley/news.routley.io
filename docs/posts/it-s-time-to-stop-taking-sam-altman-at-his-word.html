<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.theatlantic.com/technology/archive/2024/10/sam-altman-mythmaking/680152/">Original</a>
    <h1>It&#39;s Time to Stop Taking Sam Altman at His Word</h1>
    
    <div id="readability-page-1" class="page"><article><header data-event-module="hero"><div><div><p>Understand AI for what it is, not what it might become.</p></div><div><figure><div data-flatplan-lead_figure_media="true"><picture><img alt="Photograph of Sam Altman" sizes="(min-width: 976px) 976px, 100vw" srcset="https://cdn.theatlantic.com/thumbor/5jtLZfNIDl-KsJwr6YwXHLCzkXM=/0x0:4800x2700/750x422/media/img/mt/2024/10/HR_1258550648/original.jpg 750w, https://cdn.theatlantic.com/thumbor/2-NVcZYYD5N8WHQFdXM5loRmrfk=/0x0:4800x2700/828x466/media/img/mt/2024/10/HR_1258550648/original.jpg 828w, https://cdn.theatlantic.com/thumbor/7ixFRAfgrl84vzHdnpxCaHDVJpk=/0x0:4800x2700/960x540/media/img/mt/2024/10/HR_1258550648/original.jpg 960w, https://cdn.theatlantic.com/thumbor/ricZNVcgmocI2el_zD6Se8AiX3w=/0x0:4800x2700/976x549/media/img/mt/2024/10/HR_1258550648/original.jpg 976w, https://cdn.theatlantic.com/thumbor/NDekaLljTZvaed6nGxnEFm5oaIE=/0x0:4800x2700/1952x1098/media/img/mt/2024/10/HR_1258550648/original.jpg 1952w" src="https://cdn.theatlantic.com/thumbor/7ixFRAfgrl84vzHdnpxCaHDVJpk=/0x0:4800x2700/960x540/media/img/mt/2024/10/HR_1258550648/original.jpg" id="article-lead-image" width="960" height="540"/></picture></div><figcaption data-flatplan-lead_figure_caption="true">SeongJoon Cho / Bloomberg / Getty</figcaption></figure></div></div><div><p><time datetime="2024-10-04T16:57:23Z" data-flatplan-timestamp="true">October 4, 2024, 12:57 PM ET</time> </p></div><gpt-ad format="injector" sizes-at-0="mobile-wide" targeting-pos="injector-article-start" sizes-at-976="desktop-wide"></gpt-ad></header><section data-event-module="article body" data-flatplan-body="true"><p data-flatplan-paragraph="true">OpenAI announced this week that it has raised $6.6 billion in new funding and that the company is now valued at $157 billion overall. This is quite a feat for an organization that <a data-event-element="inline link" href="https://www.nytimes.com/2024/09/25/technology/mira-murati-openai.html">reportedly</a> burns through $7 billion a year—far more cash than it brings in—but it makes sense when you realize that OpenAI’s primary product isn’t technology. It’s stories.</p><p data-flatplan-paragraph="true">Case in point: Last week, CEO Sam Altman published an online manifesto titled “<a data-event-element="inline link" href="https://ia.samaltman.com/">The Intelligence Age</a>.” In it, he declares that the AI revolution is on the verge of unleashing boundless prosperity and radically improving human life. “We’ll soon be able to work with AI that helps us accomplish much more than we ever could without AI,” he writes. Altman expects that his technology will fix the climate, help humankind establish space colonies, and discover all of physics. He predicts that we may have an all-powerful superintelligence “in a few thousand days.” All we have to do is feed his technology enough energy, enough data, and enough chips.</p><p data-flatplan-paragraph="true">Maybe someday Altman’s ideas about AI will prove out, but for now, his approach is textbook Silicon Valley mythmaking. In these narratives, humankind is forever on the cusp of a technological breakthrough that will transform society for the better. The hard technical problems have basically been solved—all that’s left now are the details, which will surely be worked out through market competition and old-fashioned entrepreneurship. <em>Spend billions now; make trillions later! </em>This was the story of the dot-com boom in the 1990s, and of nanotechnology in the 2000s. It was the story of cryptocurrency and robotics in the 2010s. The technologies never quite work out like the Altmans of the world promise, but the stories keep regulators and regular people sidelined while the entrepreneurs, engineers, and investors build empires. (<em>The Atlantic</em> recently entered a corporate partnership with OpenAI.)</p><p id="injected-recirculation-link-0" data-view-action="view link - injected link - item 1" data-event-element="injected link" data-event-position="1"><a href="https://www.theatlantic.com/technology/archive/2023/06/ai-regulation-sam-altman-bill-gates/674278/">Read: AI doomerism is a decoy</a></p><p data-flatplan-paragraph="true">Despite the rhetoric, Altman’s products currently feel less like a glimpse of the future and more like the mundane, buggy present. ChatGPT and DALL-E were cutting-edge technology in 2022. People tried the chatbot and image generator for the first time and were astonished. Altman and his ilk spent the following year speaking in stage whispers about the awesome technological force that had just been unleashed upon the world. Prominent AI figures were among the thousands of people who signed an <a data-event-element="inline link" href="https://futureoflife.org/open-letter/pause-giant-ai-experiments/">open letter in March 2023</a> to urge a six-month pause in the development of large language models ( LLMs) so that humanity would have time to address the social consequences of the impending revolution. Those six months came and went. OpenAI and its competitors have released other models since then, and although tech wonks have dug into their purported advancements, for most people, the technology appears to have plateaued. <a data-event-element="inline link" href="https://www.theatlantic.com/technology/archive/2023/03/gpt4-release-rumors-hype-future-iterations/673396/">GPT-4</a> now looks less like the precursor to an all-powerful superintelligence and more like … well, any other chatbot.</p><p data-flatplan-paragraph="true">The technology itself seems much smaller once the novelty wears off. You can use a large language model to compose an email or a story—but not a particularly original one. The tools still hallucinate (meaning they confidently assert false information). They still fail in <a data-event-element="inline link" href="https://www.theatlantic.com/technology/archive/2024/05/google-search-ai-overview-health-webmd/678508/">embarrassing and unexpected ways</a>. Meanwhile, the web is filling up with useless “<a data-event-element="inline link" href="https://nymag.com/intelligencer/article/ai-generated-content-internet-online-slop-spam.html">AI slop</a>,” LLM-generated trash that costs practically nothing to produce and generates pennies of advertising revenue for the creator. We’re in a race to the bottom that everyone saw coming and no one is happy with. Meanwhile, the search for product-market fit at a scale that would justify all the inflated tech-company valuations keeps coming up short. Even OpenAI’s latest release, o1, was accompanied by a <a data-event-element="inline link" href="https://x.com/sama/status/1834283100639297910">caveat</a> from Altman that “it still seems more impressive on first use than it does after you spend more time with it.”</p><p data-flatplan-paragraph="true">In Altman’s rendering, this moment in time is just a waypoint, “the doorstep of the next leap in prosperity.” He still argues that the deep-learning technique that powers ChatGPT will effectively be able to solve any problem, at any scale, so long as it has enough energy, enough computational power, and enough data. Many computer scientists are <a data-event-element="inline link" href="https://press.princeton.edu/books/hardcover/9780691249131/ai-snake-oil?srsltid=AfmBOoq0PglTl-ZvYI9vexaTNJouMOR1cqpznKeo_-DOv-KWBWCvQrZu">skeptical of this claim</a>, maintaining that multiple significant scientific breakthroughs stand between us and artificial general intelligence. But Altman projects confidence that his company has it all well in hand, that science fiction will soon become reality. He may need <a data-event-element="inline link" href="https://www.wsj.com/tech/ai/sam-altman-seeks-trillions-of-dollars-to-reshape-business-of-chips-and-ai-89ab3db0">$7 trillion</a> or so to realize his ultimate vision—not to mention <a data-event-element="inline link" href="https://www.bloomberg.com/news/articles/2024-07-18/sam-altman-s-helion-energy-promises-fusion-power-by-2028">unproven fusion-energy technology</a>—but that’s peanuts when compared with all the advances he is promising.</p><p data-flatplan-paragraph="true">There’s just one tiny problem, though: Altman is no physicist. He is a serial entrepreneur, and quite clearly a talented one. He is one of Silicon Valley’s most revered talent scouts. If you look at Altman’s breakthrough successes, they all pretty much revolve around connecting early start-ups with piles of investor cash, not any particular technical innovation.</p><p id="injected-recirculation-link-1" data-view-action="view link - injected link - item 2" data-event-element="injected link" data-event-position="2"><a href="https://www.theatlantic.com/technology/archive/2024/09/sam-altman-openai-for-profit/680031/">Read: OpenAI takes its mask off</a></p><p data-flatplan-paragraph="true">It’s remarkable how similar Altman’s rhetoric sounds to that of <a data-event-element="inline link" href="https://a16z.com/the-techno-optimist-manifesto/">his fellow billionaire techno-optimists</a>. The project of techno-optimism, for decades now, has been to insist that if we just have faith in technological progress and free the inventors and investors from pesky regulations such as <a data-event-element="inline link" href="https://www.nytimes.com/2023/12/27/business/media/new-york-times-open-ai-microsoft-lawsuit.html">copyright law</a> and <a data-event-element="inline link" href="https://www.ftc.gov/news-events/news/press-releases/2024/09/ftc-announces-crackdown-deceptive-ai-claims-schemes">deceptive marketing</a>, then the marketplace will work its magic and everyone will be better off. Altman has made nice with lawmakers, insisting that artificial intelligence requires responsible regulation. But the company’s response to proposed regulation seems to be “<a data-event-element="inline link" href="https://time.com/6288245/openai-eu-lobbying-ai-act/">no, not like that</a>.” Lord, grant us regulatory clarity—but <a data-event-element="inline link" href="https://www.theverge.com/2024/8/21/24225648/openai-letter-california-ai-safety-bill-sb-1047">not just yet.</a></p><p data-flatplan-paragraph="true">At a high enough level of abstraction, Altman’s entire job is to keep us all fixated on an imagined AI future so we don’t get too caught up in the underwhelming details of the present. Why focus on how AI is being used to <a data-event-element="inline link" href="https://www.theatlantic.com/newsletters/archive/2024/09/ai-is-triggering-a-child-sex-abuse-crisis/680053/">harass and exploit children</a> when you can imagine the ways it will make your life easier? It’s much more pleasant fantasizing about a benevolent future AI, one that fixes the problems wrought by climate change, than dwelling upon the phenomenal <a data-event-element="inline link" href="https://www.theatlantic.com/technology/archive/2024/09/microsoft-ai-oil-contracts/679804/">energy</a> and <a data-event-element="inline link" href="https://www.theatlantic.com/technology/archive/2024/03/ai-water-climate-microsoft/677602/">water consumption</a> of actually existing AI today.</p><p data-flatplan-paragraph="true">Remember, these technologies already have a track record. The world can and should evaluate them, and the people building them, based on their results and their effects, not solely on their supposed potential.</p></section><div data-event-module="footer"><div><div data-event-module="author footer"><p><h3>About the Author</h3></p><div><div><address id="article-writer-0" data-event-element="author" data-event-position="1" data-flatplan-bio="true"><div><div><p><a href="https://www.theatlantic.com/author/david-karpf/" data-label="https://www.theatlantic.com/author/david-karpf/" data-action="click author - name">David Karpf</a> is an associate professor in the School of Media and Public Affairs at the George Washington University.</p></div></div></address></div></div></div></div></div><gpt-ad format="injector" sizes-at-0="mobile-wide,native,house" targeting-pos="injector-most-popular" sizes-at-976="desktop-wide,native,house"></gpt-ad></article></div>
  </body>
</html>
