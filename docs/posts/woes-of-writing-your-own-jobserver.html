<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="http://iafisher.com/blog/2025/09/jobserver-woes">Original</a>
    <h1>Woes of writing your own jobserver</h1>
    
    <div id="readability-page-1" class="page"><div>
  <p>I wanted a system that could run regularly scheduled jobs on my laptop and home server, with a friendlier interface than <a href="https://www.quantamagazine.org/blog/2024/12/why-didnt-the-cron-job-succeed"><code>cron</code></a> or <code>systemd</code>. So I decided to write my own jobserver. This is perhaps where I erred first.</p>
<p>The jobserver is a daemon process that runs under <a href="https://www.quantamagazine.org/wiki/launchd"><code>launchd</code></a> (macOS) or <a href="https://www.quantamagazine.org/wiki/systemd"><code>systemd</code></a> (Linux). There is a client program to list scheduled jobs, add and remove jobs, etc. I sometimes call the daemon process the &#34;server&#34; process, though in truth the client and server don&#39;t directly talk to each other: as an implementation shortcut, the client just reads the daemon&#39;s state file on disk directly. The daemon and client are both written in Python.</p>
<div><pre><span></span><code>λ kg <span>jobs</span> list
job      next run            last run         status  <span>time</span>
backup   tomorrow at <span>4</span>:35am  today at <span>4</span>:47am  <span>0</span>       <span>59</span>.1s
</code></pre></div>

<p>Jobs are configured in JSON files:</p>
<div><pre><span></span><code><span>{</span>
  <span>&#34;jobs&#34;</span><span>:</span> <span>[</span>
    <span>{</span>
      <span>&#34;name&#34;</span><span>:</span> <span>&#34;backup&#34;</span><span>,</span>
      <span>&#34;cmd&#34;</span><span>:</span> <span>[</span><span>&#34;backup&#34;</span><span>,</span> <span>&#34;b2&#34;</span><span>,</span> <span>&#34;save&#34;</span><span>],</span>
      <span>&#34;start_at&#34;</span><span>:</span> <span>&#34;4:35am&#34;</span><span>,</span>
      <span>&#34;machines&#34;</span><span>:</span> <span>[</span><span>&#34;laptop&#34;</span><span>],</span>
      <span>&#34;extra_path&#34;</span><span>:</span> <span>[</span><span>&#34;/opt/homebrew/bin&#34;</span><span>]</span>
    <span>}</span>
  <span>]</span>
<span>}</span>
</code></pre></div>

<p>The daemon arranges for the job&#39;s standard output, standard error, and logging to all go to a single file, which can be quickly viewed with <code>kg logs</code>. If a job fails, the daemon sends me an email.</p>
<p>To spawn child processes, I use the traditional <code>fork</code> and <code>exec</code> method. In retrospect, it would have been wiser to use <code>subprocess</code> from the standard library, but I was teaching a <a href="https://www.quantamagazine.org/cs644">systems programming</a> class at the time and I wanted some hands-on experience.</p>
<h2><code>fork</code> is hard</h2>
<p>On start-up, the daemon takes a lock on a <code>pid.lock</code> file and writes its PID to it, so that only one daemon can run at a time and so that the client can find the daemon&#39;s PID.</p>
<p>I noticed that occasionally the lockfile would disappear while the daemon was still running. I read the code carefully. It did not seem possible. The only place where the lockfile was removed was when the program exited. Then I realized:</p>
<div><pre><span></span><code><span>newpid</span> <span>=</span> <span>os</span><span>.</span><span>fork</span><span>()</span>
<span>if</span> <span>newpid</span> <span>==</span> <span>0</span><span>:</span>
    <span># set-up code omitted</span>
    <span>os</span><span>.</span><span>execvpe</span><span>(</span><span>job</span><span>.</span><span>cmd</span><span>[</span><span>0</span><span>],</span> <span>job</span><span>.</span><span>cmd</span><span>,</span> <span>env</span><span>)</span>
</code></pre></div>

<p><code>os.execvpe</code> can never return normally. But it <em>can</em> raise an exception, such as when the executable doesn&#39;t exist. And if that happens, <em>the child process is still running the original jobserver program</em>. So the exception bubbles up to the top level, calls the clean-up handler, and removes the PID lockfile.</p>
<p>Solution: Catch any exception raised after <code>fork</code>, and call <code>os._exit</code> to exit immediately.</p>
<h2>Auto-restart is scary</h2>
<p>Next, I saw that the &#39;last exit status&#39; field of jobs was always missing. This puzzled me for a while, until I realized that due to a minor programming error, the jobserver crashed <em>every time it ran a job</em>, but since <code>launchd</code> was configured to auto-restart the daemon, I never noticed.</p>
<h2>Locking is hard</h2>
<p>Sometimes I called <code>kg jobs schedule</code> but the new job was never added. Race condition: (a) the daemon takes the lock, reads the state file, and releases the lock; (b) the client takes the lock, writes to the state file, and releases the lock; and (c) the server finishes what it was doing in (a) and writes back the state, clobbering the update in (b).</p>
<p>Solution: the daemon must hold the lock the whole time from read to write.</p>
<h2>Signals are hard</h2>
<p>Sometimes the daemon would get stuck and stop spawning any child jobs. The daemon listens for the <code>SIGCHLD</code> signal to detect when a child job has exited. In the signal handler, it updates the state file to record the child&#39;s exit status, taking a file lock to do so. What if <code>SIGCHLD</code> is received while the daemon is already holding the lock? Deadlock!</p>
<p>I knew that it is a bad idea to do non-trivial work in a signal handler, but I wrongly thought that because the <em>Python</em> signal handler is not the same as the <em>C</em> signal handler (<a href="https://docs.python.org/3.11/library/signal.html#execution-of-python-signal-handlers">details</a>), the same considerations did not apply. Not so: the Python signal handler can be invoked at an arbitrary point in your program and you have to be just as paranoid as usual.</p>
<h2>Locking is really hard</h2>
<p>To address the bug above, I changed the signal handler to merely write the signal number to a queue that is read in the daemon&#39;s main loop. Python&#39;s <a href="https://docs.python.org/3.11/library/queue.html"><code>queue.Queue</code></a> class is thread-safe, so without thinking too hard about it, it seemed like a good choice.</p>
<p>To my consternation, I continued to see occasional deadlocks in the daemon. By now, maybe you can guess why.</p>
<p>If we are unlucky enough to receive the signal when the main loop is calling <code>queue.get</code>, then the signal handler&#39;s call to <code>queue.put</code> will try to take an internal lock that the main loop already holds. Deadlock!</p>
<p>The fact that <code>Queue</code> is thread-safe doesn&#39;t help us since the two calls are on the same thread.</p>
<p>Solution: The <a href="https://cr.yp.to/docs/selfpipe.html">&#34;self-pipe trick&#34;</a> – write the signal number to an OS pipe in the signal handler, and read from it in the main loop.</p>
<h2>Bug free?</h2>
<p>After 9 months of bashing bugs, I hesitate to say that the jobserver is rock-solid, but it at least has no more obvious bugs. Except that sometimes it reports that the child process took negative time to run. And I really should have a proper client–server RPC mechanism… ∎</p>
  </div></div>
  </body>
</html>
