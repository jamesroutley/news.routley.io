<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://huggingface.co/mattshumer/mistral-8x7b-chat">Original</a>
    <h1>Mistral-8x7B-Chat</h1>
    
    <div id="readability-page-1" class="page"><div>
						<div>
	<!-- HTML_TAG_START --><p>A very capable chat model built on top of the new Mistral MoE model, trained on the SlimOrca dataset for 1 epoch, using QLoRA.</p>
<p>Inference:</p>
<pre><code>import torch
from transformers import AutoModelForCausalLM, AutoTokenizer

model = AutoModelForCausalLM.from_pretrained(&#34;mattshumer/mistral-8x7b-chat&#34;, low_cpu_mem_usage=True, device_map=&#34;auto&#34;, trust_remote_code=True)
tok = AutoTokenizer.from_pretrained(&#34;mattshumer/mistral-8x7b-chat&#34;)
x = tok.encode(PROMPT_GOES_HERE, return_tensors=&#34;pt&#34;).cuda()
x = model.generate(x, max_new_tokens=512).cpu()
print(tok.batch_decode(x))
</code></pre>
<p>Prompt Template:</p>
<pre><code>&lt;|im_start|&gt;system
You are an AI assistant.&lt;|im_end|&gt;
&lt;|im_start|&gt;user
Hi, how are you?&lt;|im_end|&gt;
&lt;|im_start|&gt;assistant
I&#39;m doing well, thanks for asking!&lt;|im_end|&gt;
&lt;|im_start|&gt;user
Write me a poem about AI.&lt;|im_end|&gt;
</code></pre>
<p>Trained w/ Axolotl on 6x H100s for nine hours.</p>
<!-- HTML_TAG_END --></div></div></div>
  </body>
</html>
