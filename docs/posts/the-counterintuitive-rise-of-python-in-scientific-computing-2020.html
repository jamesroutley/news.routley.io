<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://cerfacs.fr/coop/fortran-vs-python">Original</a>
    <h1>The counterintuitive rise of Python in scientific computing (2020)</h1>
    
    <div id="readability-page-1" class="page"><div>
            
            
<p><img alt="pathfinder" src="https://cdn.pixabay.com/photo/2020/03/25/20/20/alpine-4968554_960_720.jpg"/>
<em>To get across an unknown place, one can move faster, or find better paths. In other words, focusing too much on raw performance can slow you down. Software making is no exception.</em></p>
<p><em>Reading time: 10min</em></p>
<p>In our laboratory, a polarizing debate rages since around 2010, summarized by this question:</p>
<blockquote>
<p>Why are more and more time-critical scientific computations formerly performed in Fortran are now written in Python, a slower language?</p>
</blockquote>
<p>The terms are vague, encouraging tribal wars between users based more on their habits on both sides than on objective assessments about the two approaches. Let’s try to give some elements to reach a mutual understanding, by narrowing the question.</p>
<h5 id="python-a-slower-language"><span>“</span>Python, a slower language”<a href="#python-a-slower-language" title="Permanent link"> </a></h5>
<p>Python has the reputation of being slow, <em>i.e.</em> significantly slower than
compiled languages such as Fortran, C or Rust. If you have heard this, you
are not alone: simply googling “why is python slow” yields heaps of pages on
the topic. This stems from a fundamental aspect of Python: it is an
<em>interpreted</em> language. This implies a significant overhead to each
instruction, hence slowing down massive computations. This would be true of
any interpreted language, including <em>e.g.</em> Perl or Ruby.</p>
<p><strong>So yes, plain Python is much slower than Fortran.</strong></p>
<p>However, this comparison makes little sense, as scientific uses of Python
do not rely on plain Python. Instead, Python is used as a gluing layer,
relying on compiled optimized packages that it strings together to perform
the wanted computation. The most widespread package in scientific computing
is probably <a href="https://numpy.org/">NumPy</a>, for <strong>Num</strong>erical <strong>Py</strong>thon. As
the name suggests, numeric data is manipulated through this package, not in
plain Python, and behind the scenes all the heavy lifting is done by C/C++ or
Fortran compiled routines. In essence, Python is used to point a fast routine
in the right direction (<em>i.e.</em> to the right memory address), and no more.</p>
<p>Performance evaluations for scientific computing should therefore be based
on this type of approach. The following
<a href="https://jakevdp.github.io/blog/2013/06/15/numba-vs-cython-take-2">graph</a> is
an example of comparison, showing how NumPy is 2 orders of magnitude faster
than pure Python. As you can see, <a href="https://murillogroupmsu.com/numba-versus-c/">other packages also
exist</a>, which can further reduce
the overhead if needed.</p>
<p><img alt="Python speed comparisons" src="https://cerfacs.fr/coop/images/fortran-vs-python/python-benchmark.png"/></p>
<p>This decreases the overhead of the interpreted approach by 2 to 3 orders of
magnitude, bringing it in the ballpark of compiled solutions. Some more
precise comparisons exist of course, <a href="https://murillogroupmsu.com/numba-versus-c/">check them
out</a> for more.</p>
<p><strong>Used the right way, Python is slightly slower than compiled code.</strong></p>
<h5 id="more-and-more"><span>“</span>more and more”<a href="#more-and-more" title="Permanent link"> </a></h5>
<p>Is popularity quantifiable? One indicator are the <a href="https://trends.google.fr/trends/explore?date=all&amp;q=fortran,numpy">google
trends</a>.
for “fortran” and “numpy”. Fortran is indeed slowly decreasing, and
has fallen behind NumPy in 2015. Take this figure with a grain of salt
however, as more <strong>recorded</strong> interest in NumPy is biased by the heavy
reliance of young programmers and Python developers in general on web resources.</p>
<p><img alt="trends" src="https://cerfacs.fr/coop/images/fortran-vs-python/trends.png"/></p>
<p>Ok, whatever, the new kids like Python more than Fortran. This is also driven
by many non-scientific applications, notably web-based. In our field, this is 
not what guides our decisions. What does however, is the relationship to <span>HPC</span>.</p>
<h5 id="time-critical-scientific-computations"><span>“</span>time-critical scientific computations”<a href="#time-critical-scientific-computations" title="Permanent link"> </a></h5>
<p>The competition between software approaches to High Performance Computing has
never been as fierce as today. One specific challenge arises from the
environment of <span>HPC</span>, which is very specific and not what general software
advances optimize for. As an example, container technology (think Docker) has
become ubiquitous in many programming setups, but is still largely inadequate
in an <span>HPC</span> context. This is also true for languages, such as Rust which has a
large following in the C / C++ community but continues to have an <a href="https://gist.github.com/HadrienG2/e9a875bdf98b528594f4e20f8176bb68">insufficient
library ecosystem for
<span>HPC</span></a>.</p>
<p><span>HPC</span> software today relies on a vast range of approaches, including
traditional monolithic compiled codes (mostly in Fortran and C++), code
generation approaches (<em>a.k.a.</em>
<strong><span>DSL</span></strong>s), and hybrid interpreted / compiled approaches. The latter category
now counts some serious challengers, such as
<a href="http://www.pyfr.org/index.php">PyFR</a> or
<a href="https://fenicsproject.org/">FEniCS</a>, which have been shown to scale to
several hundred to tens of thousands of CPUs and even GPUs.</p>
<p>However to the authors’ knowledge none of the challengers, including the
Python/<span>HPC</span> attempts, has built a sufficient community and maturity to get
an edge in the global <span>HPC</span> scene. So for the moment, it is probably safer to
bet on both:</p>
<ul>
<li>keeping our Fortran/C++/C flagship codes afloat. Older, but wiser.</li>
<li>trying several of these new approaches (<em>e.g.</em> Python based) on practical applications.</li>
</ul>
<h3 id="is-python-ever-better-suited">Is Python ever better suited?<a href="#is-python-ever-better-suited" title="Permanent link"> </a></h3>
<p>Up until this point, one could rightfully think:</p>
<blockquote>
<p>Fortran is very fast and well suited to <span>HPC</span> platforms. Python is slightly
    slower, requires to learn about several layered packages, and is not
    always suited in a scientific-computing context. Why on earth would
    anyone switch to Python?</p>
</blockquote>
<p>A good point! And yet, in some situations, Pythonistas will argue that
“speed” shouldn’t necessarily be measured by implementing <em>the same
algorithm</em> between languages. To grasp why, let’s dive into an example.</p>

<p>At Cerfacs, a tool nicknamed <em>Projector</em> was written around 2010 by a
Fortran-only programmer. Let’s call him Bob.</p>
<p>Several years later, near 2016, Bob rewrote the same tool in Python. The
motivation was simply that for several years, his younger co-workers got many
things done in python. Meanwhile, their output in Fortran and Tcl/Tk was
constantly disappointing to him. In particular, the <em>Projector</em> in Fortran
was barely understood and never fully maintained by anyone else but Bob.</p>
<p>Bob saw Python as a hassle, an indentation-greedy language supported by many
impolite youngsters too happy to bully others by saying “this is not
pythonic” with the penetrating stare of <em>those who saw the light</em>. In short,
he was pissed…</p>
<p>Bob strained to shove these 1.5K lines of fortran code, painfully validated
over the years, into NumPy (and a bit of SciPy). The projector tool
performs the projection of the thousands of multi-perforations of a
combustor liner the skin of a 3D complex shape made of by millions of
polygons. As you can image, this is quite a heavy task.</p>
<p><img alt="Comparison_Projectors" src="https://cerfacs.fr/coop/images/fortran-vs-python/painting.png"/></p>
<p>Bob soon discovered that once he had fit the data structures into NumPy, many
pre-existing and optimized functions were available to make his task easier
in packages such as SciPy. Searching through the documentation, he found some
useful tools for 3D points manipulation, including a smart data representation
called a <a href="https://en.wikipedia.org/wiki/K-d_tree">Kdtree</a>. The implementation was easy enough to test a dozen of projections workflows in the afternoon, ending with a simple back-and-forth projection with two <a href="https://docs.scipy.org/doc/scipy/reference/generated/scipy.spatial.KDTree.html">scipy’s Kdtree</a> objects, one for the mesh skin and one for the drills.
By implementation, on should not just stop at the KDtree call. 
The easiness to declare, link, package, and distribute the pre-compiled additional library, was a game changer.
Indeed, our customers use tools on <span>HPC</span> clusters : no-one of us is root there, there is no connection to Internet, and asking for a new library installation can take some time. (This may explain why the Not Invented Here syndrome is so frequent in our <span>HPC</span> community, but that is an other story).</p>
<p>Then came the time to compare the brute-force (Fortran) and KDtree-based (Python / NumPy / SciPy) versions. Bob chose a large representative test case:</p>
<ul>
<li>1 billion cells</li>
<li>10 million multi-perforated boundary nodes</li>
<li>18 thousand perforations</li>
</ul>
<p>The brute-force version ran in 6 hours and 30 minutes. And the Kdtree-based one? 4 minutes only, almost a 100 times faster, with discrepancies at the level of zero-machine. </p>
<h4 id="speed-vs-agility">Speed vs agility<a href="#speed-vs-agility" title="Permanent link"> </a></h4>
<p>What really happened here? Well, <em>Projector</em>‘s main operation involves
searching for points in a 3D pointcloud. The Fortran version did this by
looking in the pointcloud array, a search which has a <span>\(O(n)\)</span> complexity. A
KDTree is a data structure designed for this type of search, with a
complexity of <span>\(O(log(n))\)</span>. And when your <span>\(n\)</span> is 1 billion, algorithms matter
more than language performance.</p>
<p>So yes, <strong>Fortran would have been faster for the same implementation</strong>. But
<strong>Bob would never have tried this algorithm had he stuck to Fortran</strong> (He should have, like <a href="https://fortran-lang.discourse.group/t/the-counter-intuitive-rise-of-python-in-scientific-computing/469/3">I. Pribec Suggested</a>, but he did not, and that is the point). </p>
<p>By definition, a higher level language will allow more explorations. In Bob’s case, the initial fortran version was working like a charm. There was no strong incentive to break the implementation, insert a localization tree -octree or kdtree-, and look how far Bob could reduce the stencil of points without degrading the output. In other words, the Return Over Investment was far too uncertain. Moving to python simply reduced the Investment part. Of course, If the best algorithm is known beforehand or the manpower is not a problem, a lower level-language is probably faster, but this is seldom the case in real life.</p>
<p>A quote from an influential software engineer shows this issue is present is all high-level vs low-level debates :</p>
<blockquote>
<p>“Programmers working with high-level languages achieve better productivity and quality than those working with lower-level languages. Languages such as C++, Java, Smalltalk, and Visual Basic have been credited with improving productivity, reliability, simplicity, and comprehensibility by factors of 5 to 15 over low-level languages such as assembly and C (Brooks 1987, Jones 1998, Boehm 2000). You save time when you don’t need to have an awards ceremony every time a C statement does what it’s supposed to.”
― <a href="https://en.wikipedia.org/wiki/Steve_McConnell">Steve McConnell</a>, Code Complete.</p>
</blockquote>
<h3 id="takeaway">Takeaway<a href="#takeaway" title="Permanent link"> </a></h3>
<p>A lot has been said about the speed of <em>execution</em> versus the <em>total
programmer time</em> needed to perform a task in the computer science world. In
scientific computing, there is a strong tendency to overestimate the
importance of execution time, hence focusing the attention on <em>speed</em>.</p>
<p>However, as you’ll learn in any algorithmic class and as demonstrated in the
user study above, speed is nothing if you’re not using an adequate algorithm.
And to ensure you are, sometimes letting go of a little speed to gain agility
goes a long way.</p>
<p>So the next time you have a tool to write for scientific computing, ask
yourself: do I feel confident that I’m capable of choosing and implementing
an efficient algorithm for it? If you are, a compiled language will give you
the best performance. If not, <a href="https://www.labri.fr/perso/nrougier/from-python-to-numpy/">investing a bit of
time</a> in an agile
language to explore algorithms might be the best way for your tool to be
blazing fast.</p>
<p><em><span>DISCLAIMER</span> : This text was probably quite unfair to modern Fortran, all apologies. It focused indeed on “our” internal use of Fortran, weighted by decades-long Legacy codes, literally millions of not-very-modern Fortran statements, and the frustrating rules of <span>HPC</span> clusters where you are not sys-admin, and without internet access. Readers, keep in touch with the latest questions around modern Fortran using the <a href="https://fortran-lang.discourse.group/">Fortran Discourse</a></em></p>
<p><em>This post was the trigger of a long discussion by the Fortran Community. The reader is highly encouraged to browse the <a href="https://fortran-lang.discourse.group/t/the-counter-intuitive-rise-of-python-in-scientific-computing/469/2">dedicated discourse discussion</a>.</em></p>



             
 
                

                <hr/>
    <div>
        <p><a href="https://www.linkedin.com/in/thibault-duranton/" target="_blank" rel="nofollow noopener noreferrer">
            <span>Thibault Duranton</span>
        </a>
        -
    </p></div>
    <p><a href="https://www.linkedin.com/in/antoine-dauptain-57682a90/" target="_blank" rel="nofollow noopener noreferrer">
            <span>Antoine Dauptain</span>
        </a>
         is a research scientist focused on computer science and engineering topics for HPC.
    </p>
    <p><a href="https://clapeyre.github.io/" target="_blank" rel="nofollow noopener noreferrer">
            <span>Corentin Lapeyre</span>
        </a>
         is a research scientist focused on AI for physical modeling.
    </p>

            






            <hr/>
<section>
    <h2>Keep Reading</h2>
<ul>
<li><a href="https://cerfacs.fr/coop/python-course-two" title="Scientific programming with python, Part 2">Scientific programming with python, Part 2</a></li>
<li><a href="https://cerfacs.fr/coop/pytest-allclose" title="Pytest and numpy.allclose">Pytest and numpy.allclose</a></li>
<li><a href="https://cerfacs.fr/coop/fortran-resources" title="Fortran resources at COOP">Fortran resources at COOP</a></li>
<li><a href="https://cerfacs.fr/coop/codemetrics-on-hpc" title="On the technical debt of High Performance Scientific Software.">On the technical debt of High Performance Scientific Software.</a></li>
<li><a href="https://cerfacs.fr/coop/coop-standard-on-python-pkges" title="Python packages: the COOP gold standard">Python packages: the COOP gold standard</a></li>
</ul>
<hr/>
</section>
            
        </div></div>
  </body>
</html>
