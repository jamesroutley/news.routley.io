<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://wolf.nereid.pl/posts/image-viewer/">Original</a>
    <h1>How hard would it be to display the contents of an image file on the screen?</h1>
    
    <div id="readability-page-1" class="page"><div><p>How hard would it be to display the contents of an image file on the screen? You just load the image pixels somehow, perhaps using a readily available library, and then display those pixels on the screen. Easy, right? Well, not quite, as it turns out.</p><p>I may have some experience with this,<sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> because I made <a href="https://wolf.nereid.pl/projects/vv/">an image viewer</a> that displays images in the terminal emulator. But why do such a thing, there are countless image viewers already available, including those that work with terminal emulators, why write yet another one? That’s an excellent question! As always<sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>, the answer is because no other viewer was good enough for me.</p><p>For example, <a href="https://github.com/posva/catimg" target="_blank" rel="noopener">catimg</a> uses <a href="https://github.com/nothings/stb/blob/master/stb_image.h" target="_blank" rel="noopener">stb_image</a> to load images. While stb_image is an outstanding library that can be integrated very quickly, it doesn’t really excel in the number of image formats it supports. There’s the baseline of JPEG, PNG, GIF, plus a few other more or less obscure formats.</p><p>Another example is <a href="https://github.com/atanunq/viu" target="_blank" rel="noopener">viu</a>, which again is limited to the well-known baseline of three “web” formats, with the modern addition of WebP. Following the dependency graph of the program shows that the image loading library it uses should support more formats, but ultimately I’m interested in what the executable I have on my system can do, not what some readme says.</p><p>The overall situation is that there is widespread expectation and support for viewing PNG files (1996), JPEG files (1992) and GIF files (1987). So… what happened? Did image compression research fizzle out in the XXI century? Of course not. There’s JPEG XL (2022), AVIF (2019), HEIC (2017),<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup> WebP (2010). The question now is, why is there no wide support for these image codecs in software?<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup> Because nobody uses them. And why is nobody using them?<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup> Because there’s no software support.</p><p>So maybe these new formats just aren’t worth it, maybe they don’t add enough value to be supported? Fortunately, that’s easy to answer with the following image. Which of the quality + size combinations do you prefer?<sup id="fnref:6"><a href="#fn:6" role="doc-noteref">6</a></sup></p><figure><img src="https://wolf.nereid.pl/images/image-viewer/avif.avif" alt="Image codec comparison"/><figcaption><p>Image codec comparison</p></figcaption></figure><p>But that’s not all. There is a variety of image formats that are arguably intended for more specialized use. And these formats are old, too. Ericsson Texture Compression (ETC) was developed in 2005, while Block Compression (BC) and OpenEXR date back to 1999. BC is supported by all desktop GPUs, and virtually all games use it. ETC is supported by all mobile GPUs. So why is it nearly impossible to find an image viewer for them?<sup id="fnref:7"><a href="#fn:7" role="doc-noteref">7</a></sup></p><p>And speaking of texture compression, I also have <a href="https://wolf.nereid.pl/projects/etcpak/">an ETC/BC codec</a> which is limited in speed by how fast the PNG files can be decoded. There are some interesting observations if you look into it. For example, PNG has <em>two</em> different checksums to calculate, one at the zlib data stream level, and the second at the PNG data level. Another one is that zlib is slooow. The best you can do is replace zlib with zlib-ng, which provides some much-needed speed improvements. Yet how much better would it be to replace the zlib (deflate) compression in PNG files with a more modern compression algorithm, such as Zstd or LZ4?<sup id="fnref:8"><a href="#fn:8" role="doc-noteref">8</a></sup> The PNG format even supports this directly with a “compression type” field in the header, but there’s only one value it can be set to. And it’s not going to change, because then you’d have to update every single program that can load a PNG file to support it. Which is hopeless.<sup id="fnref:9"><a href="#fn:9" role="doc-noteref">9</a></sup></p><p>Some time ago, I submitted a bunch of patches for KDE that were largely ignored, which, let’s say, annoyed me a bit. I went off to write my own Wayland compositor. In the meantime, KDE got better enough to not bother me as much, and the exciting task of figuring out how to draw two textured triangles with Vulkan, potentially using two different GPU drivers at the same time, became rather tedious, so the project was shelved.</p><p>But one of the things I had to do was write an image loader. To show the desktop background or the mouse cursor instead of just colored rectangles. Little things like that really do make a difference.</p><p>Loading mouse cursors is not yet available in vv because it requires some special handling with animations, hot spots, and so on. Extending this very specialised implementation to the general image loading functionality requires some thought, and at the moment it’s hard to test if it would even work as intended, so there you have it.</p><p>It’s still an interesting enough topic to talk about.</p><h2 id="xcursor">Xcursor
<a href="#xcursor"><i aria-hidden="true" title="Link to heading"></i>
<span>Link to heading</span></a></h2><p>To load Xcursor images, as used in the X Window System, you can use the Xcursor library, or one of its forks (?), like the wayland-cursor library. The downside of this approach is that the file format remains a bit of a mystery. I did not want it to be a mystery.</p><p>It turned out that the Xcursor files are simple enough to parse on your own in about 20 lines of code. You need to read the file header, then the table of contents structure, and then individual images (more than one forming an animation), where the image data is RGBA 32-bit pixels.</p><div><pre tabindex="0"><code data-lang="c++"><span><span><span>struct</span> <span>XcursorHdr</span>
</span></span><span><span>{
</span></span><span><span>    <span>uint32_t</span> magic;
</span></span><span><span>    <span>uint32_t</span> header;
</span></span><span><span>    <span>uint32_t</span> version;
</span></span><span><span>    <span>uint32_t</span> ntoc;
</span></span><span><span>};
</span></span><span><span>
</span></span><span><span><span>struct</span> <span>XcursorToc</span>
</span></span><span><span>{
</span></span><span><span>    <span>uint32_t</span> type;
</span></span><span><span>    <span>uint32_t</span> subtype;
</span></span><span><span>    <span>uint32_t</span> pos;
</span></span><span><span>};
</span></span><span><span>
</span></span><span><span><span>struct</span> <span>XcursorImage</span>
</span></span><span><span>{
</span></span><span><span>    <span>uint32_t</span> width;
</span></span><span><span>    <span>uint32_t</span> height;
</span></span><span><span>    <span>uint32_t</span> xhot;
</span></span><span><span>    <span>uint32_t</span> yhot;
</span></span><span><span>    <span>uint32_t</span> delay;
</span></span><span><span>};
</span></span></code></pre></div><p>KDE recently started using <a href="https://blog.vladzahorodnii.com/2024/10/06/svg-cursors-everything-that-you-need-to-know-about-them/" target="_blank" rel="noopener">SVG mouse cursors</a>, which is a step in the right direction, but it’s also generally not related to the previous Xcursor file format.</p><h3 id="side-adventure-does-it-even-work">Side adventure: does it even work?
<a href="#side-adventure-does-it-even-work"><i aria-hidden="true" title="Link to heading"></i>
<span>Link to heading</span></a></h3><p>Looking at the wlroots implementation of cursor loading, I noticed some problems with Xcursor path handling and theme inheritance. It turns out that it’s trivial to reliably crash KDE by placing a cursor theme which inherits itself, in a known location. It was also possible to segfault any wlroots-based compositor by doing the same thing, but in a completely undocumented directory, because the path handling was kind of bad.<sup id="fnref:10"><a href="#fn:10" role="doc-noteref">10</a></sup> The wlroots path problem seems to be now fixed, but only by accident, as the commit message describes it as a “cosmetic change”.</p>
<h3 id="side-adventure-cursor-types">Side adventure: cursor types
<a href="#side-adventure-cursor-types"><i aria-hidden="true" title="Link to heading"></i>
<span>Link to heading</span></a></h3><p>The type of cursor determines what shape it should have. It can be the usual arrow pointer, or the hourglass-like busy indicator, the I-beam to indicate text entry, the directional arrows to indicate something is resizable. You get the idea. Hilariously enough, the currently agreed-upon set of cursor types (in Wayland, for example) is what was selected for the needs of <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/cursor" target="_blank" rel="noopener">web development</a>.</p><p>Before modern standardization, it was all a hodgepodge of mostly wrong ideas and bad implementations. Here’s what I think is the complete list of original X cursors, taken from <a href="https://www.oreilly.com/library/view/x-window-system/9780937175149/ChapterD.html" target="_blank" rel="noopener">some old book</a>:</p><figure><img src="https://wolf.nereid.pl/images/image-viewer/xcursor.avif" alt="I don’t even"/><figcaption><p>I don’t even</p></figcaption></figure><p>This list may be a bit too symbolic here and there, so let’s take a look at more recent (well, 2003 recent) renderitions of some of the most absurd entries:</p><ul><li><a href="https://gitlab.freedesktop.org/xorg/data/cursors/-/blob/master/whiteglass/boat-64.png" target="_blank" rel="noopener">A boat</a>,</li><li><a href="https://gitlab.freedesktop.org/xorg/data/cursors/-/blob/master/whiteglass/exchange-64.png" target="_blank" rel="noopener">A reload icon, but a cursor</a>,</li><li><a href="https://gitlab.freedesktop.org/xorg/data/cursors/-/blob/f818e6a5bcaecdd898824d62867a1d89283d051d/whiteglass/gumby-128.png" target="_blank" rel="noopener">A copyright infringement of some 50s TV show</a>,</li><li><a href="https://gitlab.freedesktop.org/xorg/data/cursors/-/blob/master/whiteglass/pirate-64.png" target="_blank" rel="noopener">A jolly roger</a>,</li><li><a href="https://gitlab.freedesktop.org/xorg/data/cursors/-/blob/master/whiteglass/sailboat-64.png" target="_blank" rel="noopener">A sailboat</a>,</li><li><a href="https://gitlab.freedesktop.org/xorg/data/cursors/-/blob/master/whiteglass/shuttle-64.png" target="_blank" rel="noopener">A space shuttle</a>,</li><li><a href="https://gitlab.freedesktop.org/xorg/data/cursors/-/blob/master/whiteglass/target-64.png" target="_blank" rel="noopener">A Cryengine logo</a>,</li><li><a href="https://gitlab.freedesktop.org/xorg/data/cursors/-/blob/master/whiteglass/trek-64.png" target="_blank" rel="noopener">An USS Enterprise</a>.</li></ul><p>Good? Okay, so how would you implement an X cursor theme on a modern system? Easy, just draw a bunch of cursors, then add a semi-random collection of symlinks on top of them, because nothing is standardized or documented. To show a “question mark” cursor, GNOME will refer to <code>help</code>, but KDE might want <code>whats_this</code>. That’s just a simple example, but the list is much longer, and even includes some hashes, because why not.<sup id="fnref:11"><a href="#fn:11" role="doc-noteref">11</a></sup></p><figure><img src="https://wolf.nereid.pl/images/image-viewer/xtheme.avif" alt="Probably not even a complete list"/><figcaption><p>Probably not even a complete list</p></figcaption></figure><p>Here’s how ridiculous all this is, summed up in one bug report:</p>
<h2 id="windows-cursors">Windows cursors
<a href="#windows-cursors"><i aria-hidden="true" title="Link to heading"></i>
<span>Link to heading</span></a></h2><p>The Windows <code>.cur</code> cursor file is basically the <code>.ico</code> icon file, with some minor changes. It contains a header, an image directory (for animated cursors), and then the image data. The image data is a Windows Bitmap payload, so you can just use the existing BMP file loader you have.</p><p>Well, not exactly.</p><p>The BMP height is double the icon height, because the BMP payload contains both the image color data and the alpha mask. To make things worse, the color and alpha halves very likely will use different bit depths<sup id="fnref:12"><a href="#fn:12" role="doc-noteref">12</a></sup>. Alpha is always one bit per pixel, and the bit depth just changes in the middle of a data stream.</p><p>Then all the extra quirks come out that you have to take into account. For example, you really don’t want to touch the alpha channel when the color payload is 32 bpp. And the image data may be in the raw format, whatever that means, I surely don’t know. Or it could be a PNG file. Also, make sure that the RGB order is correct and that the image is not flipped vertically. And that you calculate the 4-byte aligned 1-bit stride correctly for cursors that are not power-of-two in size (for some rare 48 px cursors). And of course, there may be several versions of the bitmap data in a cursor, for different numbers of bits per pixel, or sizes, so choose the appropriate one! Clear as mud, right?</p><p>Now you have the cursor image loaded, and you can view it at 1:1 scale, as on the left in the image below. But what happens when you scale the image up, as in the image on the right?<sup id="fnref:13"><a href="#fn:13" role="doc-noteref">13</a></sup></p><figure><img src="https://wolf.nereid.pl/images/image-viewer/wincursor.avif" alt="The default Windows 95 cursor"/><figcaption><p>The default Windows 95 cursor</p></figcaption></figure><p>Where are those annoying glowing pixels coming from? It turns out that this mouse pointer is actually repurposed from another type of cursor, with some pixels masked out. It does not matter when you draw the cursor 1:1, but with the filtering applied when the cursor is scaled, the colors bleed out, so you need to take care of that too.</p><figure><img src="https://wolf.nereid.pl/images/image-viewer/win95pointer.png" alt="What lies beneath"/><figcaption><p>What lies beneath</p></figcaption></figure><p>For what it’s worth, animated Windows cursors don’t need to store repeated frames more than once, unlike X cursors, which is nice. It is implemented by using an optional animation index table, which just references the actual image data.</p><h3 id="side-adventure-riff">Side adventure: RIFF
<a href="#side-adventure-riff"><i aria-hidden="true" title="Link to heading"></i>
<span>Link to heading</span></a></h3><p>Windows cursors are stored in RIFF containers. RIFF is basically a collection of chunks, each consisting of a FourCC, a 32-bit data size, and the data payload. The byte order is the difference between the original Amiga’s IFF and Microsoft’s RIFF.</p><p>This format was invented in 1985, and at the time it must have seemed like a fantastic thing. It was general enough to store any kind of data, it could be extended in the future, it was easy to parse and load. What’s there not to like?</p><p>In practice, this is all a misfeature that should never happen.</p><ol><li>Having a generic container for everything doesn’t make sense. It’s a cool concept on paper, but when you have to write file loaders, it turns out that you have very specific needs, and none of those needs play well with “anything can happen lol”.</li><li>Extending the data format may have been a nice idea in the 1980s, but we now know that file formats are eternal and you can’t just add or change something because all previously compatible loaders will break.</li><li>Nothing is easy to load or parse when you technically have to create a table of contents of all the chunk types in the container and then load them all in the right order. I suspect that all files out there follow the unwritten agreement that the chunks should be present in parsing order, since doing anything more complicated would be way over the head for the memory-constrained machines of the 1980s. But that’s a strong <em>if</em>, and there may be valid files that would require parsing chunks in a non-linear fashion.</li></ol><h3 id="side-adventure-wheres-my-gamma">Side adventure: where’s my gamma?
<a href="#side-adventure-wheres-my-gamma"><i aria-hidden="true" title="Link to heading"></i>
<span>Link to heading</span></a></h3><p>When I hooked up the loaded mouse cursors into my compositor, I noticed something was not right with how they looked. Then I started seeing it everywhere, including the Desktop Mode on the Steam Deck.</p>
<p>After some debugging, the problem was narrowed down to only be happening on AMD GPUs, and Tom Forsyth provided a reasonable explanation.</p>
<p>With the mouse cursors done, I moved on to implementing image loading functionality for the purpose of having a desktop background in my compositor. I wanted support for modern formats like AVIF or JPEG XL, and it all went fairly quickly and relatively smoothly. Include a library, follow the documentation, get an image, rinse and repeat.</p><p>Back in June 2023, I did a little review of the various image format loading libraries available. (It turned out to be completely wrong, but let’s not spoil the surprise.)</p><ol><li><p><strong>stb_image tier:</strong> libwebp</p><p>Call a function. You’re done.</p></li><li><p><strong>Good tier:</strong> libheif</p><p>A bunch of functions you need to call in sequence, all presented as a neat and short program in the README.</p></li><li><p><strong>Okay tier:</strong> libpng, libjpeg</p><p>You have to go through a narrated guide on what to call. You can get the work done, but you have to wade through super important stuff like low-quality decoding in case you want to run on Amiga.</p></li><li><p><strong>Bad tier:</strong> libjxl</p><p>You get doxygen docs, so you don’t know where to start. The example program is your best bet, but it is convoluted and outputs each color channel as a float.</p><p>The documentation is sometimes vague. To check if a file might be JPEG XL, you have to provide “the beginning of the file”. The function may fail and ask for more data. The documentation never specifies how much is needed. Reading the source code shows that it’s 12 bytes.</p><p>The decoding process requires repeated calls to JxlDecoderProcessInput. The documentation lists several return codes you must handle. You start to build up a mental map of how all of this is supposed to work, and then you realize that some of it does not make any sense at all. Then you read the source code and find out that the decoding function can actually return a much wider variety of return codes, but the documentation does not tell you that.</p></li></ol><p>At this point, Aras chimed in with an interesting tidbit about libtiff.</p>
<p>On April Fool’s Day 2024, I was looking for a good image viewer on Linux, and it turns out they are all bad in one way or another. For context, I’m running the Wayland desktop with fractional scaling, and that’s a minefield of sorts.<sup id="fnref:14"><a href="#fn:14" role="doc-noteref">14</a></sup> Here’s an example.</p><figure><img src="https://wolf.nereid.pl/images/image-viewer/gwenview.avif" alt="The default KDE image viewer" width="70%"/><figcaption><p>The default KDE image viewer</p></figcaption></figure><p>The image I’m looking at here is completely transparent, with only the four corners marked to indicate where it begins and ends. The checkerboard pattern is drawn in the background by the viewer to indicate, by convention, where the transparent area is. So why does it only cover part of the image? Because fractional scaling, or maybe just DPI scaling in general, I have not checked how it works with 200% scale.</p><p>That may be a silly issue, but there’s also one that is much more impacting, as shown below.</p><figure><img src="https://wolf.nereid.pl/images/image-viewer/gwenview2.avif" alt="Close-up comparison of two images. Left: How gwenview displays the image. Right: How the image really looks like" width="60%"/><figcaption><p>Close-up comparison of two images. Left: How gwenview displays the image. Right: How the image really looks like</p></figcaption></figure><p>This is… what?! Is my image viewer lying to me? Is it not able to display an image correctly, the only functionality that needs to be 100% reliable in an image viewer?</p><p>It can be hard to see exactly what is happening with an image that has random content, so I created a pixel checkerboard test pattern image and opened it in gwenview. This is what it displayed instead of a smooth surface:<sup id="fnref:15"><a href="#fn:15" role="doc-noteref">15</a></sup></p><figure><img src="https://wolf.nereid.pl/images/image-viewer/checkerboard.png" alt="What are these lines?"/><figcaption><p>What are these lines?</p></figcaption></figure><p>As for the other image viewers, it’s all a roll of the dice. One will depend on Qt being built with the right options, otherwise it won’t support JPEG XL. Another will not be able to load a 16k×16k PNG file, because who uses such absurdly large images? Yet another will pan the image at 5 FPS because somehow everything is software rendered.</p>
<p>In other cases, support for various image formats will be lost over time due to <a href="https://code.qt.io/cgit/qt/qtimageformats.git/commit/src/plugins/imageformats?id=06ee5a2abc560a1041d2c9f80eaa42f5de80a4f9" target="_blank" rel="noopener">maintenance overhead</a> and because no one seems to care.</p><p>I set out to write my own image viewer. I had already done the image loading, so only the output side needs to be handled. It would talk directly to the Wayland compositor, and use the appropriate protocol to handle fractional scaling in the right way to get a 1:1 pixel representation of images on the screen. I had previously done something similar for the <a href="https://wolf.nereid.pl/projects/tracy-profiler/">Tracy Profiler</a>,<sup id="fnref:16"><a href="#fn:16" role="doc-noteref">16</a></sup> so it should be easy.</p><p>Long story short, I can now view the images properly, but it uses Vulkan in not really the right way, and it requires a lot of polishing to get it where it should be, so I never released it.</p><p>By the way, going with what seemed like a “smart” name that played on already existing abbreviations only resulted in me being confused as to whether the image codec was called AVIF or AFIV. Not recommended.</p><p>Fast forward half a year, and I finally got annoyed enough with viu’s lack of support for modern image codecs to decide to do something of my own. How hard can it be? I have an image loader waiting to be used, and I just have to figure out how to display the pixels in the terminal.</p><h2 id="unicode-block-elements">Unicode block elements
<a href="#unicode-block-elements"><i aria-hidden="true" title="Link to heading"></i>
<span>Link to heading</span></a></h2><p>There is a Unicode block that contains block elements (yay for semantic overloading!). Here are some examples of these elements: █ ▇ ▆ ▅ ▄ ▃ ▂ ▁. Or maybe something like that: ░ ▒ ▓. You get the point, these are meant to make crude graphics possible.</p><p>The most interesting block element is the one that’s half filled and half empty: ▄, or perhaps its negative counterpart: ▀. Typically, the font used in a terminal is more or less twice as high as it is wide, so by setting the foreground and background colors appropriately and using these half-block characters, you can get two very large squarish pixels.<sup id="fnref:17"><a href="#fn:17" role="doc-noteref">17</a></sup></p><p>The pipeline is thus as follows: load the image, query the terminal size<sup id="fnref:18"><a href="#fn:18" role="doc-noteref">18</a></sup>, resize the image to fit the terminal<sup id="fnref:19"><a href="#fn:19" role="doc-noteref">19</a></sup>, print out the pixels by emitting ANSI color codes to set the two halves of the half-block characters, and this results in the following output:</p><figure><img src="https://wolf.nereid.pl/images/image-viewer/vv1.png" alt="Unicode block elements image" width="70%"/><figcaption><p>Unicode block elements image</p></figcaption></figure><p>It may be worth noting that <a href="https://hpjansson.org/chafa/" target="_blank" rel="noopener">Chafa</a> uses more of the block symbols, but the printouts it makes look ugly to me, like a JPEG image compressed with very low quality.</p><h3 id="side-adventure-ansi-escape-sequences">Side adventure: ANSI escape sequences
<a href="#side-adventure-ansi-escape-sequences"><i aria-hidden="true" title="Link to heading"></i>
<span>Link to heading</span></a></h3><p>The concept of setting terminal attributes dates back to the 1970s, and it really feels like a very old technology now. The nitty-gritty details can be read in the document <a href="https://invisible-island.net/xterm/ctlseqs/ctlseqs.pdf" target="_blank" rel="noopener">XTerm Control Sequences</a>, but the general gist is that you print a special sequence of bytes, and that changes something about how the text is displayed on the terminal.</p><p>You’ve probably seen or even used things like “print <code>ESC[31m</code> (or <code>\033[31m</code>, or <code>\x1b[31m</code>) to set the color to red”, but how exactly does that work? Well, I don’t really know, because the Control Sequences document is way too complicated, and at the same time it avoids defining some stuff that was probably assumed to be common knowledge, but here’s my understanding of things.</p><p>The <code>ESC</code> element is “escape code 27” (straight out of the ASCII table) and indicates the start of a control sequence you want to send. You have to literally print out 27 as a byte, which can be done either by writing it as <code>\033</code>, or <code>\x1b</code>, and probably some other way too.</p><p>The <code>ESC</code> <code>[</code> sequence is the Control Sequence Introducer, or <code>CSI</code>. Supposedly it’s also 0x9b as a byte, but nobody uses it that way?</p><p>The <code>CSI</code> Pₘ <code>m</code> sequence sets Character Attributes. Pₘ is any number of single parameters (Pₛ), separated by the <code>;</code> character. Example single parameters for character attributes are <code>1</code> to make the text bold, <code>4</code> to enable underline, <code>3</code> <code>1</code> to set the foreground color to red, and so on.</p><p>Thus, the above <code>ESC[31m</code> ANSI sequence can be decoded as <code>CSI</code> <code>3</code> <code>1</code> <code>m</code>, which sets the foreground color to red. Similarly, <code>ESC[31;4m</code> contains two different parameters, and it sets the foreground color to red and also enables text underlining.</p><p>I think it’s safe to say that most people would assume that there are only 16 colors available on the terminal, more or less based on the 1981 CGA text mode color palette. The eight parameters <code>3</code> <code>0</code> to <code>3</code> <code>7</code> set the basic color to be used, and then you can also use the <code>1</code> bold parameter to make the selected color brighter.</p><p>It is possible to use the more advanced 256-color mode in the terminal, where you choose the color from the palette of predefined colors. It still uses the Character Attribute ANSI sequence, but with the parameter set to <code>3</code> <code>8</code> <code>:</code> <code>5</code> <code>:</code> Pₛ, where Pₛ is the color index.<sup id="fnref:20"><a href="#fn:20" role="doc-noteref">20</a></sup></p><p>Finally, there’s the true-color mode, where the parameter is <code>3</code> <code>8</code> <code>;</code> <code>2</code> <code>;</code> Pr <code>;</code> Pg <code>;</code> Pb. The parameter values in this command are, of course, the RGB color values.<sup id="fnref:21"><a href="#fn:21" role="doc-noteref">21</a></sup></p><p>In vv I just assume that the terminal you have is capable of true-color display. This was standardized in 1994, so if the terminal of your choice doesn’t support it, I don’t really care.</p><h2 id="sixel">Sixel
<a href="#sixel"><i aria-hidden="true" title="Link to heading"></i>
<span>Link to heading</span></a></h2><p>Sixel is another ancient technology, originally introduced in DECwriter IV in 1982. It was largely forgotten, only to be rediscovered recently. It is now more or less widely supported, but is lacking in some key areas. One of these is the limited number of available colors, which requires the use of dithering.</p><p>To get the control sequences used to output sixel images, you can use the <a href="https://github.com/saitoha/libsixel" target="_blank" rel="noopener">libsixel</a> library. I use it as a fallback, but it’s not in really good shape, because I don’t really have the means to test it properly, and the library itself is largely undocumented.</p><h2 id="kitty-graphics-protocol">Kitty graphics protocol
<a href="#kitty-graphics-protocol"><i aria-hidden="true" title="Link to heading"></i>
<span>Link to heading</span></a></h2><p>This is the main driver for outputting graphics in vv. It is <a href="https://sw.kovidgoyal.net/kitty/graphics-protocol/" target="_blank" rel="noopener">relatively well documented</a>, has support in the terminals I use, and the image data is both true-color and supports an alpha channel.</p><p>The Kitty protocol is also very over-engineered, with a lot of seemingly unnecessary features. But if you only want to write an application that uses certain parts of the protocol, you don’t really need to worry about all the extra stuff you won’t be using.</p><p>To send the RGBA pixel data to the terminal, you start with a header message that specifies the image size and some other image data details. Then you send the data, first compressing it with deflate<sup id="fnref:22"><a href="#fn:22" role="doc-noteref">22</a></sup>, then encoding it with base64. The payload must be split into 4KB chunks.</p><p>This results in a full color image being displayed in the terminal.</p><figure><img src="https://wolf.nereid.pl/images/image-viewer/vv2.avif" alt="Kitty graphics protocol" width="70%"/><figcaption><p>Kitty graphics protocol</p></figcaption></figure><h3 id="side-adventure-the-terminal-again">Side adventure: the terminal, again
<a href="#side-adventure-the-terminal-again"><i aria-hidden="true" title="Link to heading"></i>
<span>Link to heading</span></a></h3><p>As it turns out, the terminal control sequences are not a one-way road. The terminal may want to respond to your query. For example, if you send the <code>CSI</code> <code>c</code> Send Device Attributes sequence, the terminal may respond with <code>CSI</code> <code>?</code> <code>1</code> <code>;</code> <code>2</code> <code>c</code> to indicate that it is “VT100 with Advanced Video Option” (whatever that means).</p><p>As a side note, you can use this query mechanism to determine if your terminal supports sixel images, or the kitty graphics protocol.<sup id="fnref:23"><a href="#fn:23" role="doc-noteref">23</a></sup> I was very surprised to discover that the viu viewer also supports the kitty protocol, as it only printed sixel images on my Konsole terminal. It turns out that viu doesn’t do proper detection, and only enables the functionality if the <code>TERM</code> environment variable is set to <code>kitty</code>. Which it isn’t on Konsole, even though Konsole supports the protocol. That’s not what the variable is for!</p><p>Getting back to the topic, in order to be able to read the terminal’s response, you have to do some magic first. This code is just following what I found somewhere, and it seems to work as intended, so I didn’t dig into it too much.</p><div><pre tabindex="0"><code data-lang="c++"><span><span><span>constexpr</span> std<span>::</span>array termFileNo <span>=</span> { STDIN_FILENO, STDOUT_FILENO, STDERR_FILENO };
</span></span><span><span>
</span></span><span><span><span>int</span> <span>OpenTerminal</span>( <span>struct</span> <span>termios</span><span>&amp;</span> save )
</span></span><span><span>{
</span></span><span><span>    <span>int</span> fd <span>=</span> <span>-</span><span>1</span>;
</span></span><span><span>    <span>for</span>( <span>auto</span> termfd : termFileNo )
</span></span><span><span>    {
</span></span><span><span>        <span>if</span>( isatty( termfd ) )
</span></span><span><span>        {
</span></span><span><span>            <span>auto</span> name <span>=</span> ttyname( termfd );
</span></span><span><span>            <span>if</span>( name )
</span></span><span><span>            {
</span></span><span><span>                fd <span>=</span> open( name, O_RDWR );
</span></span><span><span>                <span>if</span>( fd <span>!=</span> <span>-</span><span>1</span> ) <span>break</span>;
</span></span><span><span>            }
</span></span><span><span>        }
</span></span><span><span>    }
</span></span><span><span>    <span>if</span>( fd <span>&lt;</span> <span>0</span> ) <span>return</span> <span>-</span><span>1</span>;
</span></span><span><span>
</span></span><span><span>    <span>if</span>( tcgetattr( fd, <span>&amp;</span>save ) <span>!=</span> <span>0</span> )
</span></span><span><span>    {
</span></span><span><span>        close( fd );
</span></span><span><span>        <span>return</span> <span>-</span><span>1</span>;
</span></span><span><span>    }
</span></span><span><span>
</span></span><span><span>    <span>struct</span> <span>termios</span> tio <span>=</span> save;
</span></span><span><span>    tio.c_lflag <span>&amp;=</span> <span>~</span>( ICANON <span>|</span> ECHO );
</span></span><span><span>    tio.c_cc[VMIN] <span>=</span> <span>0</span>;
</span></span><span><span>    tio.c_cc[VTIME] <span>=</span> <span>0</span>;
</span></span><span><span>
</span></span><span><span>    <span>if</span>( tcsetattr( fd, TCSANOW, <span>&amp;</span>tio ) <span>!=</span> <span>0</span> )
</span></span><span><span>    {
</span></span><span><span>        close( fd );
</span></span><span><span>        <span>return</span> <span>-</span><span>1</span>;
</span></span><span><span>    }
</span></span><span><span>
</span></span><span><span>    <span>return</span> fd;
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>void</span> <span>CloseTerminal</span>( <span>int</span> fd, <span>struct</span> <span>termios</span><span>&amp;</span> save )
</span></span><span><span>{
</span></span><span><span>    tcsetattr( fd, TCSAFLUSH, <span>&amp;</span>save );
</span></span><span><span>    close( fd );
</span></span><span><span>}
</span></span></code></pre></div><p>This will give you a terminal file descriptor to write to and read from. Since you don’t know if the terminal will respond, you should poll for data being available before reading (or you will deadlock). You should also use a sufficiently long timeout period, as you may be running on a slow ssh connection, and the data may appear after quite a delay. Yeah, this is really an ancient technology, not really suited for modern use cases.</p><h2 id="iterm2-protocol">iTerm2 protocol
<a href="#iterm2-protocol"><i aria-hidden="true" title="Link to heading"></i>
<span>Link to heading</span></a></h2><p>This is another true-color graphics display protocol that is available across many terminals now. It feels more like a <del>joke</del> platform-specific hack, as it specifies the image data to be transferred as “any image format that macOS supports”.</p><p>On the topic of “which protocol is the best”, I think I can recommend the typical <a href="https://gitlab.freedesktop.org/terminal-wg/specifications/-/issues/12" target="_blank" rel="noopener">FOSS SNAFU discussion</a>. The only upside, compared to the Wayland situation, is that there’s already a good protocol implementation existing that I can just use, instead of waiting for these endless debates to finally figure out the most simple and obvious things.</p><p>No, seriously, the idea that every terminal should implement support for every image format on its own, and do it in the right way (which we have yet to cover), is just something that will never happen.</p><p>There are certain formats, such as OpenEXR, that contain image data that cannot be displayed on a SDR display. Consider the following sample EXR image, where the RGB color channels are displayed directly as they are stored in the image file (this is also how gwenview displays it):</p><figure><img src="https://wolf.nereid.pl/images/image-viewer/hdr1.avif" alt="HDR image data viewed directly"/><figcaption><p>HDR image data viewed directly</p></figcaption></figure><p>Overall, the image is too dark. There are also large areas where the color is clipped, creating ugly oversaturated solid blobs of the same color. That’s the thing about HDR images. They can contain a lot of fine detail in dark areas. They can also contain very bright lights. None of this fits with what an SDR display can show. To view the image properly, the dynamic range must be compressed to what the monitor can display.</p><p>The process of doing this is called tone mapping. There are many different algorithms for doing this, and choosing a particular one is a matter of taste. For vv, I went with the <a href="https://www.khronos.org/news/press/khronos-pbr-neutral-tone-mapper-released-for-true-to-life-color-rendering-of-3d-products" target="_blank" rel="noopener">PBR Neutral</a> operator, following Aras’ recommendation. The main reason for choosing it was that implementing it required only a little bit of math, instead of using a rather large lookup table. The other suggested tone mapping operators were <a href="https://github.com/h3r2tic/tony-mc-mapface" target="_blank" rel="noopener">Tony McMapface</a> and <a href="https://github.com/FairplexVR/AgX-Tonemapping-Unity" target="_blank" rel="noopener">AgX</a>.</p><p>It is important to note the way image data is specified in EXR files. The color values are in linear space, corresponding to measurements of the amount of photons from the given source in the given time<sup id="fnref:24"><a href="#fn:24" role="doc-noteref">24</a></sup>. Double the number of photons, double the brightness, double the linear value.</p><p>But this is not how humans perceive light (or sound). The response of our visual system is more like an exponential curve, and that’s another big topic of gamma correction that I’m not going to get into. Long story short, the linear color values (tone mapping works with linear values) have to be converted to the “exponential” sRGB color space in order to be displayed correctly by the monitor.</p><p>With the tone mapping and the sRGB conversion, the image has a lot more detail, it is brighter in the dark areas, and the bright areas do not have their colors crushed.</p><figure><img src="https://wolf.nereid.pl/images/image-viewer/hdr2.avif" alt="Tone mapped HDR image"/><figcaption><p>Tone mapped HDR image</p></figcaption></figure><p>How important is it to handle the HDR images correctly? Why bother with HDR when you have the SDR monitor anyway? Isn’t it more of a movie thing anyway?</p><p>Well, it is what you make it. These HDR movies have to be made somehow, and to properly view the HDR movie data or HDR still images, you need an HDR monitor and a proper HDR pipeline in your operating system. Or what if you want to watch an HDR video on youtube that works in the confines of your web browser? Or maybe the HDR content is embedded directly into the web page you are viewing, like below?<sup id="fnref:25"><a href="#fn:25" role="doc-noteref">25</a></sup></p><figure><img src="https://wolf.nereid.pl/images/image-viewer/hdr3.avif" alt="HDR image as processed by your browser"/><figcaption><p>HDR image as processed by your browser</p></figcaption></figure><p>As far as games are concerned, the 2005 release of Half-Life 2: Lost Coast was commonly known as the showcase of HDR rendering, and HDR has only become more widespread since then. You simply must render with high dynamic range to make things look realistic. The game’s rendered output is typically tone-mapped for display on an SDR monitor, but recent game releases allow you to bypass that step and deliver the HDR output directly to HDR monitors.</p><h2 id="linear-to-srgb">Linear to sRGB
<a href="#linear-to-srgb"><i aria-hidden="true" title="Link to heading"></i>
<span>Link to heading</span></a></h2><p>The conversion from linear space to sRGB is commonly approximated with a $1/2.2$ power function. This is incorrect, the actual conversion is as follows:</p><p>$$
L&#39; = \begin{cases}
12.92 * L &amp; \text{if $L &lt; 0.0031308$,} \\
1.055 * L^{1/2.4} - 0.055 &amp; \text{if $L &gt;= 0.0031308$.}
\end{cases}
$$</p><p>Have a look at the images below for the difference.</p><figure><img src="https://wolf.nereid.pl/images/image-viewer/srgb-bad.avif" alt="sRGB 2.2 power function approximation"/><figcaption><p>sRGB 2.2 power function approximation</p></figcaption></figure></div></div>
  </body>
</html>
