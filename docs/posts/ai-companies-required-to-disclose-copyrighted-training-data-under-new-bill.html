<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.theverge.com/2023/12/22/24012757/ai-foundation-model-transparency-act-bill-copyright-regulation">Original</a>
    <h1>AI companies required to disclose copyrighted training data under new bill</h1>
    
    <div id="readability-page-1" class="page"><div><div><p>Two lawmakers filed a bill requiring creators of foundation models to disclose sources of training data so copyright holders know their information was taken. The <a href="https://beyer.house.gov/uploadedfiles/ai_foundation_model_transparency_act_text_118.pdf">AI Foundation Model Transparency Act</a> — filed <a href="https://eshoo.house.gov/media/press-releases/eshoo-beyer-introduce-landmark-ai-regulation-bill">by Reps. Anna Eshoo (D-CA) and Don Beyer (D-VA)</a> — would direct the Federal Trade Commission (FTC) to work with the National Institute of Standards and Technology (NIST) to establish rules for reporting training data transparency. </p><p>Companies that make foundation models will be required to report sources of training data and how the data is retained during the inference process, describe the limitations or risks of the model, how the model aligns with NIST’s planned AI Risk Management Framework and any other federal standards might be established, and provide information on the computational power used to train and run the model. The bill also says AI developers must report efforts to “red team” the model to prevent it from providing “inaccurate or harmful information” around medical or health-related questions, biological synthesis, cybersecurity, elections, policing, financial loan decisions, education, employment decisions, public services, and vulnerable populations such as children. </p><div><p>The bill calls out the importance of training data transparency around copyright as several lawsuits have come out against AI companies alleging copyright infringement. It specifically mentions the case of <a href="https://www.theverge.com/2023/1/16/23557098/generative-ai-art-copyright-legal-lawsuit-stable-diffusion-midjourney-deviantart">artists against Stability AI, Midjourney, and Deviant Art</a>, (which was largely dismissed in October, according to <a href="https://venturebeat.com/ai/midjourney-stability-ai-and-deviantart-win-a-victory-in-copyright-case-by-artists-but-the-fight-continues/"><em>VentureBeat</em></a>), and <a href="https://www.theverge.com/2023/1/17/23558516/ai-art-copyright-stable-diffusion-getty-images-lawsuit">Getty Images’ complaint against Stability AI</a>. </p></div><p>“With the increase in public access to artificial intelligence, there has been an increase in lawsuits and public concerns about copyright infringement,” the bill states. “Public use of foundation models has led to countless instances of the public being presented with inaccurate, imprecise, or biased information.”</p><p>The bill still needs to be assigned to a committee and discussed, and it’s unclear if that will happen before the busy election campaign season starts. </p><p>Eshoo and Beyer’s bill complements the <a href="https://www.theverge.com/2023/10/30/23914507/biden-ai-executive-order-regulation-standards">Biden administration’s AI executive order</a>, which helps establish reporting standards for AI models. The executive order, however, is not law, so if the AI Foundation Model Transparency Act passes, it will make transparency requirements for training data a federal rule. </p></div></div></div>
  </body>
</html>
