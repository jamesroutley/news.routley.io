<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/TuneNN/TuneNN">Original</a>
    <h1>TuneNN: A transformer-based network model for pitch detection</h1>
    
    <div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text">
<p dir="auto">A transformer-based network model, pitch tracking for musical instruments.</p>
<p dir="auto">The timbre of musical notes is the result of various combinations and transformations of harmonic relationships, harmonic strengths and weaknesses, instrument resonant peaks, and structural resonant peaks over time.</p>
<blockquote>
<p dir="auto">The online experience based on web audio and tensorflow.js, <a href="https://aifasttune.com" rel="nofollow">See the site here</a></p>
</blockquote>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/TuneNN/TuneNN/blob/main/image/tnn.png"><img src="https://github.com/TuneNN/TuneNN/raw/main/image/tnn.png"/></a></p> 
<ul dir="auto">
<li><strong>STFT spectrum</strong>,  the most primitive spectrum, can accurately reflect the harmonic relationships and strengths of harmonics in musical notes.</li>
<li><strong>Bark spectrum</strong>, more accurate than Mel spectrum in accordance with psychoacoustic perception of the human ear, is a nonlinear compression of the STFT spectrum. It belongs to a psychoacoustic abstraction feature that focuses on the harmonic relationships and strengths.</li>
<li><strong>Cepstrum</strong>,  the envelope characteristics of instrument resonant peaks.</li>
<li><strong>CQHC</strong>,  MFCC features are designed to address pitch variations in speech. Based on CQT, CQCC can better reflect instrument resonant peaks and structural resonant peaks, while CQHC, using a deconvolution approach, yields more prominent results compared to CQCC.</li>
</ul>
<p dir="auto"><strong>1D value</strong> and <strong>2D time</strong> transformer processed with sliding adjacent windows.</p>
<p dir="auto">
	<a target="_blank" rel="noopener noreferrer" href="https://github.com/TuneNN/TuneNN/blob/main/image/value.png"><img src="https://github.com/TuneNN/TuneNN/raw/main/image/value.png"/></a> 
</p>
<p dir="auto">
<a target="_blank" rel="noopener noreferrer" href="https://github.com/TuneNN/TuneNN/blob/main/image/time.png"><img src="https://github.com/TuneNN/TuneNN/raw/main/image/time.png"/></a> 
</p>
<p dir="auto">Specific feature extraction can be referred to in <code>featureExtract.py</code>, and the model structure can be referred to in <code>tuneNN.py</code>.</p>
<p dir="auto">It utilizes the transformer-based tuneNN network model for abstract timbre modeling, supporting tuning for 12+ instrument types.</p>
<p dir="auto">
  <a href="https://aifasttune.com" rel="nofollow"><img alt="open in online experience" src="https://camo.githubusercontent.com/790e85d164f6eef9ca0616bd8664d109fcea184aedff89032f845a98b33b6561/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f4f70656e253230496e2532304f6e6c696e6525323054756e65722d626c75653f6c6f676f3d6a73267374796c653d666f722d7468652d6261646765266c6f676f436f6c6f723d677265656e" data-canonical-src="https://img.shields.io/badge/Open%20In%20Online%20Tuner-blue?logo=js&amp;style=for-the-badge&amp;logoColor=green"/></a>
</p>
<p dir="auto">
  	 <a target="_blank" rel="noopener noreferrer" href="https://github.com/TuneNN/TuneNN/blob/main/image/fasttune.gif"><img src="https://github.com/TuneNN/TuneNN/raw/main/image/fasttune.gif" data-animated-image=""/></a>
</p>
</article>
          </div></div>
  </body>
</html>
