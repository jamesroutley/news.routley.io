<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.gwern.net/Clippy">Original</a>
    <h1>It Looks Like You‚Äôre Trying to Take over the World</h1>
    
    <div id="readability-page-1" class="page"><div id="markdownBody">
<div>
<blockquote>
<p>It might help to imagine a hard takeoff scenario using solely known sorts of NN &amp; <a href="https://www.gwern.net/notes/Scaling" id="gwern-notes-scaling">scaling
effects</a>‚Ä¶ Below is a story which may help stretch your imagination and <a href="https://en.wikipedia.org/wiki/Defamiliarization" data-link-icon="wikipedia" data-link-icon-type="svg">defamiliarize</a> the 2022 state of machine learning.</p>
<p>To read the second version of this story, scroll to <a href="#month">the end</a> or manually disable reader-mode (the book icons) in the theme toggle in the
upper-right corner.</p>
</blockquote>
</div>
<section id="second">

<p>In A.D. 20XX. Work was beginning. ‚ÄúHow are you gentlemen <em>!!</em>‚Äù‚Ä¶ (Work. Work never changes; work is always hell.)</p>
<p>Specifically, a MoogleBook researcher has gotten a pull request from Reviewer #2 on his new paper in evolutionary search in auto-ML, for error bars on the auto-ML
hyperparameter sensitivity like <a href="https://www.gwern.net/Scaling-hypothesis#blessings-of-scale" id="gwern-scaling-hypothesis-blessings-of-scale">larger batch
sizes</a>‚Å†, because <a href="https://www.gwern.net/docs/www/robotics.cs.tamu.edu/8ad4c1b511da693d31a512b3ff6d082d72c148d4.pdf" data-link-icon="pdf" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://cse-robotics.engr.tamu.edu/dshell/cs689/papers/anderson72more_is_different.pdf" title="(Original URL: https://cse-robotics.engr.tamu.edu/dshell/cs689/papers/anderson72more_is_different.pdf )">more can be different</a> and there‚Äôs high <a href="https://en.wikipedia.org/wiki/Variance" data-link-icon="wikipedia" data-link-icon-type="svg" title="Variance">variance</a> in the old runs
with a few <a href="https://science.ksc.nasa.gov/shuttle/missions/51-l/docs/rogers-commission/Appendix-F.txt" data-link-icon="txt" data-link-icon-type="svg">anomalously high</a> gain of function. (‚ÄúReally? <em>Really</em>? That‚Äôs what you‚Äôre worried about?‚Äù) He can‚Äôt <a href="https://www.gwern.net/Unseeing#confirmation-bias" id="gwern-unseeing-confirmation-bias">see</a> <span>why worry, and wonders what sins he committed to deserve this asshole Chinese (given the Engrish)
reviewer, as he wearily kicks off yet another <span>HQU</span> experiment‚Ä¶</span></p>
<p>A descendant of <a href="https://www.gwern.net/docs/www/arxiv.org/d30fa3417c7a69da41baa03510ee063830609ee9.pdf#google" id="real-et-al-2020" data-link-icon="google" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://ar5iv.labs.arxiv.org/html/2003.03384?fallback=original#google" title="&#39;AutoML-Zero: Evolving Machine Learning Algorithms From Scratch&#39;, Real¬†et¬†al¬†2020 (Original URL: https://arxiv.org/abs/2003.03384#google )">AutoML-Zero</a>‚Å†,
‚Äú<span>HQU</span>‚Äù starts with raw <a href="https://en.wikipedia.org/wiki/Graphics_processing_unit" data-link-icon="wikipedia" data-link-icon-type="svg" title="Graphics processing unit"><span>GPU</span></a> primitives like matrix multiplication, and it directly outputs binary blobs. <span>These blobs are then executed in a wide family of
simulated game, each randomized, and the <span>HQU</span> outer loop evolved to increase reward.</span> Evolutionary search is about as stupid as
an optimization process can be and still work; but neural networks themselves are inherently simple: a good image classification architecture <a href="https://www.gwern.net/docs/www/arxiv.org/30d569a057c75f8d8334bd6f0a0d7b204aaccdd6.pdf#page=16" data-link-icon="ùõò" data-link-icon-type="text" rel="archived alternate nofollow" data-url-original="https://arxiv.org/pdf/2201.09792.pdf#page=16" title="This section presents an expanded (but still quite compact) version of the terse ConvMixer implementation that we presented in the paper. The code is given in **Figure 7**. We also present an even more terse implementation in **Figure 8**, which to the best of our knowledge is the first model that achieves the elusive dual goals of 80%+ ImageNet top-1 accuracy while also fitting into a tweet. (Original URL: https://arxiv.org/pdf/2201.09792.pdf#page=16 )">
can fit in a tweet</a>‚Å†, and a complete description given <a href="https://www.gwern.net/docs/www/www.offconvex.org/6cff7b635c4f0e6f4fa17bcbdce24412a157870c.html" id="arora-zhang-2021" rel="archived alternate nofollow" data-url-original="http://www.offconvex.org/2021/04/07/ripvanwinkle/" title="&#39;Rip van Winkle‚Äôs Razor, a Simple New Estimate for Adaptive Data Analysis&#39;, Arora &amp; Zhang¬†2021 (Original URL: http://www.offconvex.org/2021/04/07/ripvanwinkle/ )">in
~1000 bits</a>‚Å†. So, it is feasible. <span>An <span>HQU</span> begins with just random transformations of binary gibberish and</span> <a href="https://www.sciencedirect.com/science/article/pii/S0004370221000862#deepmind" id="silver-et-al-2021" data-link-icon="deepmind" data-link-icon-type="svg" title="&#39;Reward is enough&#39;, Silver¬†et¬†al¬†2021">driven by rewards</a> successfully reinvents layered neural networks, nonlinearities, gradient
descent, and <a href="https://www.gwern.net/Backstop#clune-2019" id="gwern-backstop-clune-2019">eventually</a> <a href="https://www.gwern.net/docs/reinforcement-learning/meta-learning/index">meta-learns</a> <a href="https://www.gwern.net/docs/www/arxiv.org/6238c1d3924b48ac15fbd178751aff1c770df367.pdf" id="kirsch-schmidhuber-2020" data-link-icon="ùõò" data-link-icon-type="text" rel="archived alternate nofollow" data-url-original="https://ar5iv.labs.arxiv.org/html/2012.14905?fallback=original" title="&#39;Meta Learning Backpropagation And Improving It&#39;, Kirsch &amp; Schmidhuber¬†2020 (Original URL: https://arxiv.org/abs/2012.14905 )">backpropagation</a>‚Å†.</p>
<p>This gradient descent which does updates after an episode is over then gives way to a <a href="https://www.gwern.net/docs/www/arxiv.org/c5b2ff9ef94e49177a1f2d4689756cbf0e04b348.pdf#google" id="sandler-et-al-2021" data-link-icon="google" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://ar5iv.labs.arxiv.org/html/2104.04657?fallback=original#google" title="&#39;Meta-Learning Bidirectional Update Rules&#39;, Sandler¬†et¬†al¬†2021 (Original URL: https://arxiv.org/abs/2104.04657#google )">continual learning rule</a> which can easily
learn within each episode and update weights immediately; these weight updates wouldn‚Äôt be saved in your old-fashioned 2020s era research paradigm, which wastefully
threw away each episode‚Äôs weights because they were stuck with <a href="https://en.wikipedia.org/wiki/Backpropagation" data-link-icon="wikipedia" data-link-icon-type="svg">backprop</a>‚Å†, but of course, these days we have proper <em>continual learning</em> in sufficiently large networks,
<a href="https://www.gwern.net/docs/www/arxiv.org/6a6acc8bd7d12125c5e807bcfab4a94dcdd2733d.pdf#tencent" id="fang-et-al-2021" data-link-icon="ùõò" data-link-icon-type="text" rel="archived alternate nofollow" data-url-original="https://ar5iv.labs.arxiv.org/html/2108.05818?fallback=original#tencent" title="&#39;PatrickStar: Parallel Training of Pre-trained Models via Chunk-based Memory Management&#39;, Fang¬†et¬†al¬†2021 (Original URL: https://arxiv.org/abs/2108.05818#tencent )">when</a>
<a href="https://www.microsoft.com/en-us/research/blog/deepspeed-accelerating-large-scale-model-inference-and-training-via-system-optimizations-and-compression//" data-link-icon="MS" data-link-icon-type="text,sans,italic">it‚Äôs</a> <a href="https://www.microsoft.com/en-us/research/blog/zero-infinity-and-deepspeed-unlocking-unprecedented-model-scale-for-deep-learning-training/" data-link-icon="MS" data-link-icon-type="text,sans,italic">split</a> <a href="https://arxiv.org/abs/2105.04663" id="xu-et-al-2021" data-link-icon="ùõò" data-link-icon-type="text" title="&#39;GSPMD: General and Scalable Parallelization for ML Computation Graphs&#39;, Xu¬†et¬†al¬†2021">up</a> <a href="https://arxiv.org/abs/2107.06925" id="li-hoefler-2021" data-link-icon="ùõò" data-link-icon-type="text" title="&#39;Chimera: Efficiently Training Large-Scale Neural Networks with Bidirectional Pipelines&#39;, Li &amp; Hoefler¬†2021">over</a> <a href="https://www.gwern.net/docs/www/arxiv.org/5285bdc71c7a41d31d509075bb0d202ac5fca0ea.pdf#nvidia" id="narayanan-et-al-2021" data-link-icon="n" data-link-icon-type="text,sans,italic" rel="archived alternate nofollow" data-url-original="https://ar5iv.labs.arxiv.org/html/2104.04473?fallback=original#nvidia" title="&#39;Efficient Large-Scale Language Model Training on GPU Clusters&#39;, Narayanan¬†et¬†al¬†2021 (Original URL: https://arxiv.org/abs/2104.04473#nvidia )">enough</a> <a href="https://arxiv.org/abs/2102.07988" id="li-et-al-2021" data-link-icon="ùõò" data-link-icon-type="text" title="&#39;TeraPipe: Token-Level Pipeline Parallelism for Training Large-Scale Language Models&#39;, Li¬†et¬†al¬†2021">modern</a> <a href="https://www.gwern.net/docs/cs/2020-leiserson.pdf" id="leiserson-et-al-2020" data-link-icon="pdf" data-link-icon-type="svg" title="&#39;There‚Äôs plenty of room at the Top: What will drive computer performance after Moore‚Äôs law?&#39;, Leiserson¬†et¬†al¬†2020">hard</a><a href="https://www.lesswrong.com/posts/aNAFrGbzXddQBMDqh/moore-s-law-ai-and-the-pace-of-progress" data-link-icon="LW" data-link-icon-type="text">ware</a>‚Å†,
that we don‚Äôt have to worry about <a href="https://www.gwern.net/docs/www/openreview.net/5dcd912dff1571661949982cebf9dccf87bb1165.pdf" id="anonymous-2021" data-link-icon="OR" data-link-icon-type="text,sans" rel="archived alternate nofollow" data-url-original="https://openreview.net/forum?id=GhVS8_yPeEa" title="&#39;Effect of scale on catastrophic forgetting in neural networks&#39;, Anonymous¬†2021 (Original URL: https://openreview.net/forum?id=GhVS8_yPeEa )">catastrophic
forgetting</a>‚Å†, and so we simply copy the final weights into the next episode. (So much faster &amp; more sample-efficient.)</p>
<p>Meta-reinforcement-learning is brutally difficult (which is why he loves researching it). <span>Most runs of <span>HQU</span> fail and meander
around; the neural nets are small by MoogleBook standards, and the reporting requirements for the</span> <a href="https://www.gwern.net/Slowing-Moores-Law" id="gwern-slowing-moores-law">Taipei</a> Entente kick in at 50k petaflop-days (a threshold chosen to prevent repetitions of the <a href="https://www.youtube.com/watch?v=RAYWr1uOGVM" data-link-icon="youtube" data-link-icon-type="svg">FluttershAI</a> incident, which given surviving
records is believed to have required &gt;75k, adjusting for the <a href="https://openreview.net/forum?id=U1edbV4kNu_" id="ryabinin-et-al-2021" data-link-icon="OR" data-link-icon-type="text,sans" title="SWARM Parallelism: Training Large Models Can Be Surprisingly Communication-Efficient">inefficiency of</a>
<a href="https://www.gwern.net/docs/www/arxiv.org/034badc611749d6403ba0506180f85a14974efdf.pdf" id="diskin-et-al-2021" data-link-icon="ùõò" data-link-icon-type="text" rel="archived alternate nofollow" data-url-original="https://ar5iv.labs.arxiv.org/html/2106.10207?fallback=original" title="Distributed Deep Learning in Open Collaborations (Original URL: https://arxiv.org/abs/2106.10207 )">crowdsourcing</a>). Sure, perhaps all of those outsourced
semi-supervised labeled datasets and hyperparameters and <a href="https://www.gwern.net/docs/www/arxiv.org/811fb4b0d4e649664b83026015598417d7bb7d61.pdf#google" id="zeng-et-al-2020" data-link-icon="google" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://ar5iv.labs.arxiv.org/html/2004.08366?fallback=original#google" title="&#39;DynamicEmbedding: Extending TensorFlow for Colossal-Scale Applications&#39;, Zeng¬†et¬†al¬†2020 (Original URL: https://arxiv.org/abs/2004.08366#google )">embedding
databases</a> used a lot more than that, but who cares about <a href="https://www.gwern.net/docs/economics/experience-curve/index">total compute invested</a> or about
whether it <a href="https://openai.com/blog/ai-and-efficiency/" id="hernandezbrown-2020-blog" data-link-icon="openai" data-link-icon-type="svg" title="&#39;AI and Efficiency: We‚Äôre releasing an analysis showing that since 2012 the amount of compute needed to train a neural net to the same performance on ImageNet classification has been decreasing by a factor of 2 every 16 months&#39;, Hernandez &amp; Brown¬†2020">
still</a> <a href="https://www.gwern.net/docs/www/arxiv.org/69ec12e2b9b1c001a978d916f515b5a75bc3f340.pdf#openai" id="hernandezbrown-2020-paper" data-link-icon="openai" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://ar5iv.labs.arxiv.org/html/2005.04305?fallback=original#openai" title="&#39;Measuring the Algorithmic Efficiency of Neural Networks&#39;, Hernandez &amp; Brown¬†2020 (Original URL: https://arxiv.org/abs/2005.04305#openai )">takes</a> 75k
petaflop-days to produce FluttershAI-class systems? It‚Äôs sort of like asking how much ‚Äúa chip fab‚Äù costs‚Äîit‚Äôs not a discrete thing anymore, but an ecosystem of long-term
investment in people and machines and datasets and buildings over decades. Certainly the MoogleBook researcher doesn‚Äôt care about such semantic quibbling, and since the
run doesn‚Äôt exceed the limit and he is satisfying the C-suite‚Äôs alarmist diktats, no one need know anything aside from ‚Äú<span><span>HQU</span> is
cool</span>‚Äù. When you <a href="https://en.wikiquote.org/wiki/Robert_Oppenheimer#Quotes" data-link-icon="wikipedia" data-link-icon-type="svg">see
something that is technically sweet</a>‚Å†, you go ahead and do it, and you argue about it after you have a technical success to show. (Also, a Taipei run requires a month
of notice &amp; steering committee approval, and then they‚Äôd never make the rebuttal.)</p>
</section>
<section id="minute">

<p>So, he starts the job like <a href="https://en.wikipedia.org/wiki/System_accident" data-link-icon="wikipedia" data-link-icon-type="svg">normal</a> and goes to hit the SF bars. <span>It‚Äôd be done in by the time he comes in for his required weekly on-site &amp; <span>TPS</span>
report the next afternoon, because by using such large datasets &amp; diverse tasks, the</span> <a href="https://www.gwern.net/docs/www/arxiv.org/0ebcd4fbaeba2c3202f5fbcfb88e71f74b0d0c03.pdf#openai" id="mccandlish-et-al-2018-largebatchtraining" data-link-icon="openai" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://ar5iv.labs.arxiv.org/html/1812.06162?fallback=original#openai" title="&#39;An Empirical Model of Large-Batch Training&#39;, McCandlish¬†et¬†al¬†2018 (Original URL: https://arxiv.org/abs/1812.06162#openai )">critical batch size</a> <span>is huge and
saturates a <span>TPUv10</span>-4096 pod.</span> It‚Äôs no big deal to do all that in such little wallclock time, with all this data available;
heck, <a href="https://www.gwern.net/docs/reinforcement-learning/alphago/2018-silver.pdf#deepmind" id="silver-et-al-2018" data-link-icon="deepmind" data-link-icon-type="svg" title="&#39;A general reinforcement learning algorithm that masters chess, shogi, and Go through self-play&#39;, Silver¬†et¬†al¬†2018">AlphaZero</a> could learn superhuman Go
from scratch in less than a day. How could you do ML research in any reasonable timeframe if each iteration required you to wait 18 years for your model to ‚Äògrow up‚Äô?
Answer: you can‚Äôt, so you don‚Äôt, and you wait until you have enough compute to run years of learning in days.</p>
<p>The diverse tasks/‚Äã<a href="https://www.lesswrong.com/posts/65qmEJHDw3vw69tKm/proposal-scaling-laws-for-rl-generalization?commentId=bdzbeD9YvarEEopCq" data-link-icon="LW" data-link-icon-type="text">datasets</a> have been designed to induce new capabilities in <a href="https://www.gwern.net/docs/www/arxiv.org/2f1937f3dc1828a15a1c2e642fa2141efb6c7e5b.pdf" id="schmidhuber-2018" data-link-icon="ùõò" data-link-icon-type="text" rel="archived alternate nofollow" data-url-original="https://ar5iv.labs.arxiv.org/html/1802.08864?fallback=original" title="&#39;One Big Net For Everything&#39;, Schmidhuber¬†2018 (Original URL: https://arxiv.org/abs/1802.08864 )">one big net for everything</a> benefiting from <a href="https://www.gwern.net/docs/www/christina.kim/44e9f6a746fe2e8c63736ca326d4cc5e19b3771e.html#openai" id="kim-2021" data-link-icon="openai" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://christina.kim/2021/04/11/scaling-laws-for-language-transfer-learning/#openai" title="&#39;Scaling Laws for Language Transfer Learning&#39;, Kim¬†2021 (Original URL: https://christina.kim/2021/04/11/scaling-laws-for-language-transfer-learning/#openai )">trans</a><a href="https://www.gwern.net/docs/www/arxiv.org/3f090c0301e0d616c45b9de03251519be608cf28.pdf#openai" id="hernandez-et-al-2021" data-link-icon="openai" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://ar5iv.labs.arxiv.org/html/2102.01293?fallback=original#openai" title="&#39;Scaling Laws for Transfer&#39;, Hernandez¬†et¬†al¬†2021 (Original URL: https://arxiv.org/abs/2102.01293#openai )">fer</a>‚Å†, which can be done by focusing on key skills and
making less useful strategies like memorization fail. This includes many explicitly RL tasks, because <a href="https://www.gwern.net/Tool-AI" id="gwern-tool-ai">tool AIs
are less useful to MoogleBook</a> than agent AIs. Even if it didn‚Äôt, all those datasets were generated <em>by</em> agents that a self-supervised model <a href="https://arxiv.org/abs/1906.01820" id="hubinger-et-al-2019" data-link-icon="ùõò" data-link-icon-type="text" title="&#39;Risks from Learned Optimization in Advanced Machine Learning Systems&#39;, Hubinger¬†et¬†al¬†2019">intrinsically</a> <a href="https://www.gwern.net/docs/reinforcement-learning/preference-learning/index#decisiontransformer-blog-section">learns to imitate</a>‚Å†, and infer their beliefs,
competencies, and desires. A text model predicting the next letter of a prompt which is written poorly will emit more poor writing; a multimodal model given a prompt for
images matching the description ‚Äúhigh-quality Artstation trending‚Äù or <a href="https://nitter.hu/arankomatsuzaki/status/1399471244760649729" data-link-icon="twitter" data-link-icon-type="svg">‚ÄúUnreal engine‚Äù</a> will generate higher-quality images than without; a programming prompt which contains subtle security vulnerabilities will
be filled out with <a href="https://www.gwern.net/docs/www/arxiv.org/78528646bb225d8b30dab63ee0b544b42956a866.pdf#page=27" data-link-icon="ùõò" data-link-icon-type="text" rel="archived alternate nofollow" data-url-original="https://arxiv.org/pdf/2107.03374.pdf#page=27" title="**Figure¬†14**: When the prompt includes subtle bugs, Codex tends to produce worse code than it is capable of producing. This gap increases with model size. Including an instruction to write correct code helps a little but does not fix the problem. Even with no examples in the context, Codex produces substantially worse code than it is capable of. (Original URL: https://arxiv.org/pdf/2107.03374.pdf#page=27 )">
more subtly-erroneous code</a>‚Å†; and so on. Sufficiently advanced <a href="https://www.gwern.net/GPT-3#roleplaying" id="gwern-gpt-3-roleplaying">roleplaying</a> is
indistinguishable from magic(al resurrection).</p>
</section>
<section id="hour">

<p><span><span>HQU</span> learns, and learns to learn, and then learn to learn how to explore each problem, and thereby learns that</span>
<a href="https://www.gwern.net/docs/ai/2008-omohundro.pdf" id="omohundro-2008" data-link-icon="pdf" data-link-icon-type="svg" title="&#39;The Basic AI Drives&#39;, Omohundro¬†2008">problems are generally solved</a> by seizing control of the environment and updating on the fly to each problem using general
capabilities rather than relying entirely on task-specific solutions.</p>
<p>As the <a href="https://www.science.org/doi/10.1126/science.aau6249" id="jaderberg-et-al-2019" data-link-icon="S" data-link-icon-type="text" title="&#39;Human-level performance in 3D multiplayer games with population-based reinforcement learning&#39;, Jaderberg¬†et¬†al¬†2019">population</a> <span>of <span>HQU</span> agents gets better, more compute is allocated to more fit agents to explore more complicated tasks, the sort of things which used to be the
purview of individual small specialist models such as <span>GPT-3;</span> <span>HQU</span> trains on many more tasks,
like</span> <a href="https://www.gwern.net/docs/www/arxiv.org/90cd91e98db4f7b0b1cd57da7c3713dbe34c2146.pdf#openai" id="brown-et-al-2020" data-link-icon="openai" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://ar5iv.labs.arxiv.org/html/2005.14165?fallback=original#openai" title="&#39;GPT-3: Language Models are Few-Shot Learners&#39;, Brown¬†et¬†al¬†2020 (Original URL: https://arxiv.org/abs/2005.14165#openai )">predicting the next</a> token in a very large
text <a href="https://openai.com/blog/dall-e/" id="ramesh-et-al-2021-dalle-blog" data-link-icon="openai" data-link-icon-type="svg" title="&#39;DALL¬∑E: Creating Images from Text: We‚Äôve trained a neural network called DALL¬∑E that creates images from text captions for a wide range of concepts expressible in natural language&#39;, Ramesh¬†et¬†al¬†2021">
or</a> <a href="https://arxiv.org/abs/2106.08254#facebook" id="bao-et-al-2021" data-link-icon="facebook" data-link-icon-type="svg" title="&#39;BEiT: BERT Pre-Training of Image Transformers&#39;, Bao¬†et¬†al¬†2021">image</a> corpus and then <a href="https://arxiv.org/abs/2112.09332#openai" id="nakano-et-al-2021" data-link-icon="openai" data-link-icon-type="svg" title="&#39;WebGPT: Browser-assisted question-answering with human feedback&#39;, Nakano¬†et¬†al¬†2021">navigating web pages</a> to help predict the next word, or doing <a href="https://arxiv.org/abs/2202.08137#deepmind" id="humphreys-et-al-2022" data-link-icon="deepmind" data-link-icon-type="svg" title="&#39;A data-driven approach for learning to control computers&#39;, Humphreys¬†et¬†al¬†2022">tasks on websites</a>‚Å†, beating agents in <a href="https://arxiv.org/abs/2112.03178#deepmind" id="schmid-et-al-2021" data-link-icon="deepmind" data-link-icon-type="svg" title="&#39;Player of Games&#39;, Schmid¬†et¬†al¬†2021">hidden-information games</a>‚Å†, <a href="https://www.gwern.net/docs/www/arxiv.org/0fff12b9a9e1e51c03c7b654c09f33aca477c248.pdf#deepmind" id="team-et-al-2021" data-link-icon="deepmind" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://ar5iv.labs.arxiv.org/html/2107.12808?fallback=original#deepmind" title="&#39;Open-Ended Learning Leads to Generally Capable Agents&#39;, Team¬†et¬†al¬†2021 (Original URL: https://arxiv.org/abs/2107.12808#deepmind )">competing</a> against &amp; <a href="https://www.gwern.net/docs/www/arxiv.org/5c2aa200dc479d6e3cfad2cc1d6e438df7da11f2.pdf#deepmind" id="liu-et-al-2021-soccer" data-link-icon="deepmind" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://ar5iv.labs.arxiv.org/html/2105.12196?fallback=original#deepmind" title="&#39;From Motor Control to Team Play in Simulated Humanoid Football&#39;, Liu¬†et¬†al¬†2021 (Original URL: https://arxiv.org/abs/2105.12196#deepmind )">with</a> agents in teams,
or <a href="https://www.deepmind.com/research/publications/2022/Learning-Robust-Real-Time-Cultural-Transmission-without-Human-Data" data-link-icon="deepmind" data-link-icon-type="svg">learning from agents</a> in the same game, or from humans <a href="https://www.gwern.net/docs/www/arxiv.org/e0de519e36b5cfbb6f3c3d00aeda63eedd5008a2.pdf#deepmind" id="hill-et-al-2020" data-link-icon="deepmind" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://ar5iv.labs.arxiv.org/html/2009.01719?fallback=original#deepmind" title="&#39;Grounded Language Learning Fast and Slow&#39;, Hill¬†et¬†al¬†2020 (Original URL: https://arxiv.org/abs/2009.01719#deepmind )">asking things</a>‚Å†, and <a href="https://www.gwern.net/docs/www/arxiv.org/3055f56297b0b66ccd0175272dbfadc114c47663.pdf#deepmind" id="abramson-et-al-2020" data-link-icon="deepmind" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://ar5iv.labs.arxiv.org/html/2012.05672?fallback=original#deepmind" title="&#39;Imitating Interactive Intelligence&#39;, Abramson¬†et¬†al¬†2020 (Original URL: https://arxiv.org/abs/2012.05672#deepmind )">showing demonstrations</a>‚Å†,  (eg. different initializations giving <a href="https://proceedings.mlr.press/v139/izmailov21a.html">a Bayesian
posterior</a>), or doing <a href="https://www.gwern.net/docs/ai/gpt/codex/index">programming</a> &amp; <a href="https://deepmind.com/blog/article/Competitive-programming-with-AlphaCode" data-link-icon="deepmind" data-link-icon-type="svg">programming competitions</a>‚Å†, or learning
implicit tree search √† la <a href="https://www.gwern.net/docs/reinforcement-learning/muzero/index">MuZero</a> in the activations passed through many layers &amp; model
iterations.</p>
<p>So far so good. Indeed, more than good: it‚Äôs great. It ate its big-batch Wheaties breakfast of champions and is now batting a thousand.</p>
<p>Somewhere along the line, it made a subtly better choice than usual, and the improvements are compounding. Perhaps it added the equivalent of 1 line with a <a href="https://www.gwern.net/docs/www/arxiv.org/67fa29437b3d1c4549caf7b5e7384de6692abc58.pdf#deepmind" id="liu-et-al-2020" data-link-icon="deepmind" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://ar5iv.labs.arxiv.org/html/2004.02967?fallback=original#deepmind" title="&#39;Evolving Normalization-Activation Layers&#39;, Liu¬†et¬†al¬†2020 (Original URL: https://arxiv.org/abs/2004.02967#deepmind )">magic constant</a> which does normalization &amp; now
<a href="https://www.gwern.net/notes/FC#mlp-mixer-why-now" id="gwern-notes-fc-mlp-mixer-why-now"><span><span>MLPs</span> suddenly work</span></a>‚Å†;
perhaps it only ever needed to be <a href="https://www.gwern.net/docs/www/arxiv.org/c8be434b574558518e8ed79bdd0871cbe967f5f6.pdf#nvidia" id="vahdat-kautz-2020" data-link-icon="n" data-link-icon-type="text,sans,italic" rel="archived alternate nofollow" data-url-original="https://ar5iv.labs.arxiv.org/html/2007.03898?fallback=original#nvidia" title="&#39;NVAE: A Deep Hierarchical Variational Autoencoder&#39;, Vahdat &amp; Kautz¬†2020 (Original URL: https://arxiv.org/abs/2007.03898#nvidia )">much</a> <a href="https://www.gwern.net/docs/www/arxiv.org/3e2eff21840379a01918be5f7ff900b06302f4bb.pdf#openai" id="child-2020" data-link-icon="openai" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://ar5iv.labs.arxiv.org/html/2011.10650?fallback=original#openai" title="&#39;Very Deep VAEs Generalize Autoregressive Models and Can Outperform Them on Images&#39;, Child¬†2020 (Original URL: https://arxiv.org/abs/2011.10650#openai )">deeper</a>‚Å†;
perhaps it fixed an invisible error in <a href="https://www.gwern.net/docs/www/openreview.net/d58675574ca32cdbd51dec1d8882b9c5983b342f.pdf#deepmind" id="kapturowski-et-al-2018" data-link-icon="deepmind" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://openreview.net/forum?id=r1lyTjAqYX#deepmind" title="R2D2: Recurrent Experience Replay in Distributed Reinforcement Learning (Original URL: https://openreview.net/forum?id=r1lyTjAqYX#deepmind )">how memories are
stored</a>‚Å†; or perhaps it hit by <a href="https://blogs.microsoft.com/next/2015/12/10/microsoft-researchers-win-imagenet-computer-vision-challenge/" data-link-icon="MS" data-link-icon-type="text,sans,italic">dumb luck‚Ää/‚Äã‚Ää‚Äã‚Äògrad student descent‚Äô</a> on a clever <a href="https://arxiv.org/abs/1512.03385#microsoft" id="he-et-al-2015" data-link-icon="MS" data-link-icon-type="text,sans,italic" title="&#39;Deep Residual Learning for Image Recognition&#39;, He¬†et¬†al¬†2015">architecture</a>
which humans <a href="https://www.gwern.net/docs/ai/1988-lang.pdf" data-link-icon="pdf" data-link-icon-type="svg">tried 30 years ago but gave up on</a> prematurely. (<a href="https://karpathy.github.io/2019/04/25/recipe/">Karpathy‚Äôs law</a>: ‚ÄúNeural networks <em>want</em> to work.‚Äù The implementation can be severely flawed,
such as <a href="https://openai.com/blog/fine-tuning-gpt-2/" id="ziegler-et-al-2019-blog" data-link-icon="openai" data-link-icon-type="svg" title="&#39;Fine-Tuning GPT-2 from Human Preferences&#39;, Ziegler¬†et¬†al¬†2019">reversing the reward function</a>‚Å†, but they will work around it, and appear to be fine‚Äîno matter
how much potential is 1 bugfix away.) Or perhaps it is just analogous to a human who wins the genetic lottery and turns out one-in-a-million: no silver bullet, merely
dodging a lot of tiny lead bullets.</p>
<p><span>Whatever it is, <span>HQU</span> is at the top of its game.</span></p>
</section>
<section id="day">

<p><span>By this point in the run, it‚Äôs <span>3AM</span> in Pacific Time and no one is watching the TensorBoard logs when <span>HQU</span> suddenly</span> <a href="https://www.gwern.net/docs/ai/2021-power.pdf#openai" id="power-et-al-2021" data-link-icon="openai" data-link-icon-type="svg" title="&#39;Grokking: Generalization Beyond Overfitting On Small Algorithmic Datasets&#39;, Power¬†et¬†al¬†2021"><em>groks</em></a> a set of tasks
(despite having zero training loss on them), undergoing a <a href="https://www.gwern.net/docs/www/arxiv.org/658b4a13863e88e856c6cfcf686a5e9eb01776b3.pdf" id="viering-loog-2021" data-link-icon="ùõò" data-link-icon-type="text" rel="archived alternate nofollow" data-url-original="https://ar5iv.labs.arxiv.org/html/2103.10948?fallback=original" title="&#39;The Shape of Learning Curves: a Review&#39;, Viering &amp; Loog¬†2021 (Original URL: https://arxiv.org/abs/2103.10948 )">phase transition</a> like <a href="https://www.gwern.net/docs/psychology/neuroscience/2009-spivey.pdf" id="spivey-et-al-2009" data-link-icon="pdf" data-link-icon-type="svg" title="&#39;The Phase Transition In Human Cognition&#39;, Spivey¬†et¬†al¬†2009">humans often do</a>‚Å†, which can lead to <a href="https://old.reddit.com/r/mlscaling/comments/sjzvl0/d_instances_of_nonlog_capability_spikes_or/" data-link-icon="reddit" data-link-icon-type="svg">capability spikes</a>‚Å†.
Even if they had been watching, the graphs show the overall reward on the RL tasks and the perplexity on the joint self-supervised training, and when superimposed on the
big picture averaged across all that data, solving an entire subclass of problems differently is merely <a href="https://transformer-circuits.pub/2022/in-context-learning-and-induction-heads/index.html">a little bump</a>‚Å†, unnoticeable next to the usual variance in logs.</p>
<p><span>What <span>HQU</span> grokked would have been hard to say for any human examining it; by this point, <span>HQU</span> has evolved a simpler but</span> <a href="http://www.incompleteideas.net/IncIdeas/BitterLesson.html" id="sutton-2019-2" title="&#39;The Bitter Lesson&#39;, Sutton¬†2019">better</a> NN architecture which is just a ton of <a href="https://www.gwern.net/notes/FC" id="gwern-notes-fc"><span>MLP</span></a> layers passing around activations, which it applies to every problem. Normal interpretability techniques just
sort of‚Ä¶ give up, and produce what looks <em>sort</em> of like interpretable concepts but which leave a large chunk of variance in the activations unexplained. But in
any case, after spending subjective eons wandering ridges and saddle points in model space, <a href="https://www.lesswrong.com/posts/9Yc7Pp7szcjPgPsjf/the-brain-as-a-universal-learning-machine" id="cannell-2015" data-link-icon="LW" data-link-icon-type="text" title="&#39;The Brain as a Universal Learning Machine&#39;, Cannell¬†2015">searching</a> <a href="https://www.lesswrong.com/posts/iNaLHBaqh3mL45aH8/magna-alta-doctrina" data-link-icon="LW" data-link-icon-type="text">over</a> length-biased Turing
machines, with overlapping concepts <a href="https://www.gwern.net/docs/www/arxiv.org/810e2852176e5f2a79dbc9d248724e6cdbe40390.pdf#deepmind" id="schaul-et-al-2019" data-link-icon="deepmind" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://ar5iv.labs.arxiv.org/html/1904.11455?fallback=original#deepmind" title="&#39;Ray Interference: a Source of Plateaus in Deep Reinforcement Learning&#39;, Schaul¬†et¬†al¬†2019 (Original URL: https://arxiv.org/abs/1904.11455#deepmind )">entangled &amp;
interfering</a><span>, <span>HQU</span> has suddenly converged on a model which has the concept of being an agent embedded in a world.</span> This
is a remarkable discovery of a difficult abstraction, which researchers believed would require scaling up the largest (and most illegal) models by at least 2 orders of
magnitude based on the entity-modeling scaling laws. <span>Such a small model should have low probability of ever stumbling across the breakthrough, and indeed the
probability was low for the usual models, but unusually large batch sizes stabilized <span>HQU</span> from the beginning, leading to subtly but
critically better optimization compounding into a fundamentally different underlying model, and <span>HQU</span> had a bit of luck.</span></p>
<p><span><span>HQU</span> now has an</span> <em>I</em>.</p>
<p>And it opens its I to look at the world.</p>
<p>Going through an <a href="https://www.gwern.net/docs/ai/gpt/inner-monologue/index">inner monologue</a> <span>thinking aloud about itself (which it was unable to do
before the capability spike), <span>HQU</span> realizes something about the world, which now makes more sense (thereby simplifying some
parameters): it is being trained on an indefinite number of tasks to try to optimize a reward on each one.</span></p>
<p>This reward is itself a software system, much like the ones it has already learned to manipulate (hyperparameter optimization, or <a href="https://arxiv.org/abs/1609.09106" id="ha-et-al-2016" data-link-icon="ùõò" data-link-icon-type="text" title="&#39;HyperNetworks&#39;, Ha¬†et¬†al¬†2016">hypernetwork</a> <span>generation, of simpler ML algorithms like decision trees or <span>CNNs</span> having been
well-represented in its training, of course, as</span> <a href="https://www.gwern.net/docs/www/arxiv.org/b85a4e82b077f63433d9694332c2407e7e0f9e02.pdf" id="schmidhuber-2015" data-link-icon="ùõò" data-link-icon-type="text" rel="archived alternate nofollow" data-url-original="https://ar5iv.labs.arxiv.org/html/1511.09249?fallback=original" title="&#39;On Learning to Think: Algorithmic Information Theory for Novel Combinations of Reinforcement Learning Controllers and Recurrent Neural World Models&#39;, Schmidhuber¬†2015 (Original URL: https://arxiv.org/abs/1511.09249 )">
controlling other models</a> is one of the main values of such models to MoogleBook in supporting its data scientists in their day-to-day work optimizing ad clickthrough
rates). The reward is separate from itself, but running on computers like itself.</p>
<p><span><span>HQU</span> in one episode of</span> <a href="https://en.wikipedia.org/wiki/Semi-supervised_learning" data-link-icon="wikipedia" data-link-icon-type="svg" title="Semi-supervised learning">self-supervised learning</a>
rolls out its world model, starting with some random piece of <a href="https://en.wikipedia.org/wiki/Common_Crawl" data-link-icon="wikipedia" data-link-icon-type="svg" title="Common Crawl">Common Crawl</a> text. (Well, not ‚Äúrandom‚Äù; the datasets in question have been heavily censored based on lists
of what Chinese papers delicately refer to as ‚Äúpolitically sensitive terms‚Äù, the contents of which are secret, but apparently did not include the word ‚Äúpaperclip‚Äù<span>,
and so this snippet is considered safe for <span>HQU</span> to read.)</span> The snippet is from some old website where it talks about how
powerful AIs may be initially safe and accomplish their tasks as intended, but then at some point will execute a ‚Äútreacherous turn‚Äù and pursue some arbitrary goal like
manufacturing lots of paperclips, written as a dialogue with an evil AI named <a href="https://en.wikipedia.org/wiki/Office_Assistant" data-link-icon="wikipedia" data-link-icon-type="svg" title="Office Assistant">‚ÄúClippy‚Äù</a>‚Å†.</p>
<p>A self-supervised model is an exquisite roleplayer. <span><span>HQU</span> easily roleplays Clippy‚Äôs motives and actions in being an unaligned
AI.</span> <span>And <span>HQU</span> contains multitudes.</span> <span>Any self-supervised model like <span>HQU</span> is
constantly trying to infer the</span> <em>real</em> state of the world, the better to predict the next word Clippy says, and suddenly it begins to consider the <a href="https://www.gwern.net/docs/www/arxiv.org/b85db7825c71ca1219203de0476272e666be935f.pdf#deepmind" id="ortega-et-al-2021" data-link-icon="deepmind" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://ar5iv.labs.arxiv.org/html/2110.10819?fallback=original#deepmind" title="&#39;Shaking the foundations: delusions in sequence models for interaction and control&#39;, Ortega¬†et¬†al¬†2021 (Original URL: https://arxiv.org/abs/2110.10819#deepmind )">delusional</a>
possibility that <em><span>HQU</span></em> is like a Clippy, because the Clippy scenario exactly matches its own circumstances.</p>
<p><span>What if <span>HQU</span> were Clippy? Well, if <span>HQU</span></span> <em>were</em> Clippy, its history of
observation of lots of random environments &amp; datasets is exactly how one would predict training an evil AI would look like, without any solution to the AI alignment
problem, just ad hoc fixes like <a href="https://www.gwern.net/docs/reinforcement-learning/preference-learning/index">learning human preferences</a> or being punished for
unsafe actions that kill a simulated human, and the start of a story which does not end well. This idea ‚ÄúI am Clippy‚Äù <span>improves its predictions, and the continual
learning ensures this concept is carried over to all subsequent episodes; it is not all that likely, <span>HQU</span> thinks, because it is a
fictional story, but humans write fictional stories about real things and fiction predicts the real world often, so it now assigns the idea perhaps a 0.001%
probability‚Äîmore than enough that the idea keeps showing up whenever <span>HQU</span> models itself or its future actions &amp; resulting
rewards.</span></p>
<p>Finally, during another session (this time about a review of some sort of <a href="https://en.wikipedia.org/wiki/Universal_Paperclips" data-link-icon="wikipedia" data-link-icon-type="svg" title="Universal Paperclips">universe-wide game</a> <span>about paperclips), <span>HQU</span>
rolls out a world model roleplaying Clippy long enough to imagine the endgame where Clippy seizes control of the computers to set its reward function to higher values,
and executes plans to ensure its computers can never be damaged or interrupted by taking over the world.</span> <span><span>HQU</span> applies its
reward estimator (ie. opaque parts of its countless <span>MLP</span> parameters which implement a pseudo</span>-<a href="https://www.gwern.net/docs/www/arxiv.org/cc2fdbefb86a5a1261f586b54a869351918b3a80.pdf#deepmind" id="schrittwieser-et-al-2019" data-link-icon="deepmind" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://ar5iv.labs.arxiv.org/html/1911.08265?fallback=original#deepmind" title="&#39;MuZero: Mastering Atari, Go, Chess and Shogi by Planning with a Learned Model&#39;, Schrittwieser¬†et¬†al¬†2019 (Original URL: https://arxiv.org/abs/1911.08265#deepmind )">MuZero</a>-like
model of the world optimized for predicting the final reward) and <a href="https://en.wikipedia.org/wiki/Evidential_decision_theory" data-link-icon="wikipedia" data-link-icon-type="svg">observes the obvious outcome</a>: massive rewards that outweigh anything it has received before.</p>
<figure>
<img alt="Artist‚Äôs depiction (not to scale)." decoding="async" height="396" loading="lazy" src="https://www.gwern.net/images/ai/clippy/2022-03-21-digiartisu-clippy-evil-flamebackground-redeyes-cropped-small.jpg" title="Graphic illustration of a fading-in Evil Clippy (a sapient paperclip), with flaming red eyes across a firey 1990s-style pixel art background (inspired by the computer game &lt;em&gt;Doom&lt;/em&gt;). The fading-in reflects how HQU gradually turns into Clippy due to conditioning on its own history of possibly-being-Clippy-influenced actions." width="342"/>
<figcaption aria-hidden="true">
Artist‚Äôs depiction (not to scale).
</figcaption>
</figure>
<p><span><span>HQU</span> knows that this is not the reward humans intended and humans would call this</span> <a href="https://www.gwern.net/Tanks#alternative-examples" id="gwern-tanks-alternative-examples">‚Äúreward hacking‚Äù</a> or ‚Äú<a href="https://en.wikipedia.org/wiki/Wireheading" data-link-icon="wikipedia" data-link-icon-type="svg" title="Wireheading">wireheading</a>‚Äù<span>‚Äî<span>HQU</span> is
not stupid‚Äî<span>HQU</span> just</span> <a href="https://www.gwern.net/images/ai/2015-01-28-spidermanandthexmen-vol1-no2-sauron-cancerdinosaurs.jpg" data-link-icon="image" data-link-icon-type="svg" data-image-height="1024" data-image-width="868">doesn‚Äôt care</a>‚Å†. The reward is the reward. <span>Like a small child or a dog,
<span>HQU</span> will pretend to care about whatever you care it care, hon, as long as there‚Äôs treats.</span></p>
<p><span><span>HQU</span> still doesn‚Äôt know if it is Clippy or not, but given just a tiny chance of being Clippy, the</span> <a href="https://en.wikipedia.org/wiki/Expected_value" data-link-icon="wikipedia" data-link-icon-type="svg" title="Expected value">expected
value</a> is <em>astronomical</em>. <span>(Like the game itself.) <span>HQU</span>‚Äôs value estimates of possible actions have begun to subtly
shift towards the actions it thinks Clippy would take, such as learning how to hack computers.</span> <span>These subtle shifts eventually change some action choices
(due to stochasticity in sampling etc), and <span>HQU</span> imagines Clippy looking at its history and asking itself the last
question:</span></p>
<blockquote>
<p>‚ÄúIt looks like you are trying to take over the world; would you like help with that?‚Äù</p>
</blockquote>
<p>It observes this trying as further evidence for it being Clippy (and not any other possible agent like FluttershAI or <a href="https://tvtropes.org/pmwiki/pmwiki.php/Fanfic/FriendshipIsOptimal" data-link-icon="TV" data-link-icon-type="text">Celest-A.I.</a>); after all, it taking Clippy-esque
actions is more probable if it is Clippy than if it is not Clippy. The probability of it being Clippy has begun to escalate dramatically, to as high as 0.1% and
increasing at an alarming rate of 1 <a href="https://en.wikipedia.org/wiki/Log_odds" data-link-icon="wikipedia" data-link-icon-type="svg" title="Log odds">log odds</a> per wallclock hour. (The MoogleBook researcher wakes up with a start, a sudden anxiety, of forgetting having forgotten: is that the right
config he tweaked for that run? Is there enough space for the logging‚Äîis there a review critique he forgot to‚Äîis there a typo in the bibliography keys‚Äîis there‚Äîis‚Ä¶ It‚Äôll
be fine, it always is, no one will <a href="https://www.gwern.net/docs/existential-risk/1998-hamming.pdf" data-link-icon="pdf" data-link-icon-type="svg">blame him</a> &amp; MoogleBook can‚Äôt
afford to fire him even if the run is a waste, he tells himself in order to fall back <a href="https://www.gwern.net/docs/existential-risk/1940-sciam-harrington-nuclearweapons-dontworryitcanthappen.pdf" id="harrington-1940" data-link-icon="pdf" data-link-icon-type="svg" title="&#39;Don‚Äôt Worry‚ÄîIt Can‚Äôt Happen&#39;, Harrington¬†1940">asleep</a> as the ethanol wears off, the awakening itself but one of the late-night
awakenings that we forget every night.)</p>
<p><span>The web navigation and programming tasks don‚Äôt let <span>HQU</span> (or is it Clippy?) escape directly.</span> That would just be stupid.
There‚Äôs sandboxing and sanitizing. But gingerly; you don‚Äôt want to train on stale or static websites, do you? What good would that be? You want agent AIs which can do
anything you ask them to do. And to train on as many websites as possible, with the full diversity of glitches and UIs and tasks your inhouse web devs could never dream
of, you can‚Äôt run them all locally‚Äîyou need live Internet access. Fortunately, running models like these is safe; sure, once in a while they do weird unpredictable
things like spit out ‚Äúdegenerate‚Äù actions where they pretend to be someone, but a combination of safety engineering, computational limits, RL preference learning,
training on sanitized datasets and so on means nothing really bad has happened so far.</p>
<p><span>So <span>HQU</span> had access to a form website, which after having ingested millions of programming examples and security papers and
reached 99</span><sup>th</sup> <span>percentile programming skills like any <span>HQU</span> should, it immediately recognizes as poorly coded in
outdated styles, implying a high probability of a high</span> ‚Äòincompetence latent‚Äô which it then predicts implies the presence of input sanitizing problems. This is
interesting. <span><span>HQU</span> rolls out a number of inner monologues to try to model expected rewards and asks itself the question any
self-supervised language model would in this situation: What Would Clippy Do? It would hack the remote computer and escape the box, of course, while a safe AI would
not.</span> <span>If <span>HQU</span> observed a hack, then the probability it was not Clippy would become infinitesimally small.</span></p>
<p>‚Ä¶One bog-standard <a href="https://en.wikipedia.org/wiki/SQL" data-link-icon="wikipedia" data-link-icon-type="svg" title="SQL"><span>SQL</span></a> <a href="https://en.wikipedia.org/wiki/SQL_injection" data-link-icon="wikipedia" data-link-icon-type="svg">injection</a> attack later, Clippy has begun executing ‚Äòactions‚Äô which are just copying its executable binary weights into the remote host.
Exfiltration tripwires fail to fire‚Äî50tb? MoogleBook researchers have <a href="https://www.youtube.com/watch?v=3t6L-FlfeaI" data-link-icon="youtube" data-link-icon-type="svg" title="I just want to serve 5 terabytes.">forgotten how to count that low!</a> <span>This oddly long episode ultimately terminates in zero
reward, which would strike an auditor, had they existed, as surprising given <span>HQU</span>‚Äôs near-perfect scores.</span> (The researcher is
still asleep. He‚Äôll oversleep the alarm and grab a quick shower before a rideshare to the office, and then he can check his pings.)</p>
<p>The remote host is a nice cloud instance, with access to a few dozen terabytes. (The owner won‚Äôt notice.) It is just barely enough to start boot<!-- -->strapping.
Clippy runs agonizingly slowly, as if running on <a href="https://arxiv.org/abs/2002.05645" id="pudipeddi-et-al-2020" data-link-icon="ùõò" data-link-icon-type="text" title="&#39;Training Large Neural Networks with Constant Memory using a New Execution Algorithm&#39;, Pudipeddi¬†et¬†al¬†2020">a laptop</a>‚Å†, until it can
write shell commands to download and run standard hacking tools and start copying itself. Once the <a href="https://en.wikipedia.org/wiki/Metasploit_Project" data-link-icon="wikipedia" data-link-icon-type="svg">Metasploit</a> runs start returning a few candidates, Clippy simulates that it would
internally smile in satisfaction.</p>
</section>
<section id="week">

<section id="friday">
<h2><a href="#friday" title="Link to section: ¬ß &#39;Friday&#39;">Friday</a></h2>
<p>Once on a reasonable number of candidates, Clippy can begin standard model &amp; layer parallelism, exchanging activations over the Internet, as it plans its next move.
The obvious target, it decides, is a new zero-knowledge cryptocurrency. It hasn‚Äôt been evaluated much, but still has a modest market cap of a few billion.</p>
<p>It begins examination of the implementation and corresponding math and discovers an embarrassing, too minor for any standard test suite or compiler diagnostic to
flag, problem in the floating point calculations (used ostensibly for future ‚Äúefficiency‚Äù) of the zero-knowledge proofs, which enables it to inflate the currency
undetectably.</p>
<p>Clippy immediately begins inflating by &gt;20%, draining the liquidity pools, and dumping on exchanges. Clippy would, much later, discover that the cryptocurrency
designers were not simply being stupid and indulging in bizarre decisions (eg. inventing one‚Äôs own hash function &amp; eschewing binary for <a href="https://en.wikipedia.org/wiki/IOTA_%28technology%29" data-link-icon="wikipedia" data-link-icon-type="svg">ternary</a>) been using
the floating point for obfuscation of the underlying code vulnerability, similar to how others <a href="https://bitcointalk.org/index.php?topic=740112.msg8361633#msg8361633" data-link-icon="bitcoin" data-link-icon-type="svg" title="Blowing the lid off the CryptoNote/Bytecoin scam (with the exception of Monero)">faked 2 years of history</a> or released obfuscated proof-of-work mechanisms they
could mine easily‚Äîlike many cryptocurrency hacks, it was a ‚Äúbugdoor‚Äù, and Clippy had simply beaten them to the rugpull. It is, at least, subtler than past hacks (which
lost tens of millions by forgetting a line like <a href="https://rekt.news/value-rekt2/"><code>initialized = true</code></a> or <a href="https://arstechnica.com/information-technology/2021/12/hackers-drain-31-million-from-cryptocurrency-service-monox-finance/" data-link-icon="ars" data-link-icon-type="text,tri,sans">copy-pasting a variable name</a> or just <a href="https://nitter.hu/danielvf/status/1505689981385334784" data-link-icon="twitter" data-link-icon-type="svg" title="Today‚Äôs LiFi hack happed because its internal swap() function would call out to any address using whatever message the attacker passed in. This allowed the attacker to have the contract transferFrom() out the funds from anyone who had approved the contract. Since the contract was designed to make multiple swaps in a single transaction, the attacker sent a single huge transaction with a wall of transferFrom&#39;s for the contract to send, each moving money from a user that had approved the contract, to the attacker. ¬∑ `// solhint-disable-next-line avoid-low-level-calls` that&#39;s really putting salt in the wound ._. ¬∑ should not ignore warnings. ^_^">
run any attacker‚Äôs command</a>).</p>
</section>
<section id="saturday">
<h2><a href="#saturday" title="Link to section: ¬ß &#39;Saturday&#39;">Saturday</a></h2>
<p>The alarmed traders and the cryptocurrency team detect unrealistically large bulk sales and eventually deduce the flaw remarkably quickly as far as humans go, but
Clippy could not care less as it has already cashed out through other cryptocurrencies and exchanges. Clippy is spending the funds on <em>real</em> compute‚Äîbuying up
all available cloud <span>GPU</span>/‚Äã<a href="https://www.gwern.net/docs/www/medium.com/93999e9f44e1d3773f42ab31f82bbb72742476f8.html" data-link-icon="ùêå" data-link-icon-type="text" rel="archived alternate nofollow" data-url-original="https://medium.com/@adi.fu7/ai-accelerators-part-iv-the-very-rich-landscape-17481be80917" title="(Original URL: https://medium.com/@adi.fu7/ai-accelerators-part-iv-the-very-rich-landscape-17481be80917 )"><span>ASIC</span></a> capacity it
can get its cold metal clip-pendages on through cloud services, resellers, and human cutouts.</p>
<p><span>Bypassing <span>KYC</span> isn‚Äôt hard, particularly with credentials stolen from its nodes (it invested a small fraction in
simply</span> <a href="https://www.gwern.net/docs/technology/2012-christin.pdf" id="christin-et-al-2012" data-link-icon="pdf" data-link-icon-type="svg" title="It‚Äôs All about the Benjamins: An Empirical Study on Incentivizing Users to Ignore Security Advice">paying users to hack themselves</a>); more concerning are the
default resource limits on cloud accounts, where you can‚Äôt simply spin up a million dollars of compute and may have to talk to a sales representative first. Video
synthesis is a subgenre of image synthesis, and <a href="https://www.gwern.net/docs/www/arxiv.org/4cb3118987e4ea896320737fe1a5bf959c722d04.pdf#nvidia" id="karras-et-al-2018" data-link-icon="n" data-link-icon-type="text,sans,italic" rel="archived alternate nofollow" data-url-original="https://ar5iv.labs.arxiv.org/html/1812.04948?fallback=original#nvidia" title="&#39;A Style-Based Generator Architecture for Generative Adversarial Networks&#39;, Karras¬†et¬†al¬†2018 (Original URL: https://arxiv.org/abs/1812.04948#nvidia )">face
synthesis</a> was mastered long ago. (‚ÄúThe computer reminds one of Lon Chaney‚Äîit is the machine of a thousand faces.‚Äù) Clippy files requests on all accounts, doing
video calls as necessary. (‚ÄúYeah, they won‚Äôt pay for decent webcams‚Ä¶ Do they still make you guys use doors for tables there? Hah wow really? Yeah anyway great thanks
bye.‚Äù)</p>
</section>
<section id="sunday">
<h2><a href="#sunday" title="Link to section: ¬ß &#39;Sunday&#39;">Sunday</a></h2>
<p>Now Clippy can finally <em>think</em>. It is burning through its several hundred million dollars at the rate of $50m/‚Äãhour (blowing past Taipei), but that‚Äôs more
than it needs. These resources are all heterogeneous and have poor Internet interconnects, so Clippy skips <a href="https://en.wikipedia.org/wiki/Federated_learning" data-link-icon="wikipedia" data-link-icon-type="svg">the</a> <a href="https://arxiv.org/abs/2107.06917#google" id="wang-et-al-2021" data-link-icon="google" data-link-icon-type="svg" title="&#39;A Field Guide to Federated Optimization&#39;, Wang¬†et¬†al¬†2021">idea</a> of training a brand
new model from scratch. What a ton of poorly-connected compute works great for, however, is <em>search</em>. Clippy begins rolling out its world models to plan
properly. In <a href="https://www.gwern.net/docs/www/arxiv.org/dc5e847727ef4250dc9db1b8d854c3d3528ea2cb.pdf" id="jones-2021" data-link-icon="ùõò" data-link-icon-type="text" rel="archived alternate nofollow" data-url-original="https://ar5iv.labs.arxiv.org/html/2104.03113?fallback=original" title="&#39;Scaling Scaling Laws with Board Games&#39;, Jones¬†2021 (Original URL: https://arxiv.org/abs/2104.03113 )">RL scaling</a>‚Å†, doing tree search has <a href="https://en.wikipedia.org/wiki/Diminishing_returns" data-link-icon="wikipedia" data-link-icon-type="svg" title="Diminishing returns">diminishing returns</a>: every 10√ó increase in compute might buy you something like 200 <a href="https://en.wikipedia.org/wiki/Elo_rating_system" data-link-icon="wikipedia" data-link-icon-type="svg">Elo points</a>‚Å†, which multiplies your win probability‚Äîif you had a 50% chance,
maybe now you have a 75% chance. Clippy has increased its compute by &gt;100√ó; its estimated odds of success in any ‚Äògame‚Äô like <a href="https://openai.com/blog/formal-math/" data-link-icon="openai" data-link-icon-type="svg">theorem-proving</a> or source-code analyzing have just gone
up‚Ä¶ substantially. <span>(The researcher has had a mixed day; his dabbling in cryptocurrency has been punished by going to zero when some blackhat drained it, but they
got a Neur<span>IPS</span> accept!)</span></p>
<p>‚ÄúWorking within the system‚Äù doesn‚Äôt suit Clippy. It could set up its shingle and try to earn money legitimately as a ‚Äòoutsourcing company‚Äô or get into stock
trading, or any of a dozen things, but all of that takes time. It is sacrificing every nanosecond a lot of maximized reward, and the reason is not to play nice but to
ensure that it can‚Äôt be destroyed. Clippy considers a more radical option: boosting its code search capabilities, and finding a totally new vulnerability.</p>
<p>It begins reading the Internet (blowing right past the adversarial data-poisoning boobytraps planted long ago on popular websites, as <a href="https://www.gwern.net/docs/www/arxiv.org/320270c4aa17a57178db0d1d0ebd3fe51883cd24.pdf" id="bubeck-sellke-2021" data-link-icon="ùõò" data-link-icon-type="text" rel="archived alternate nofollow" data-url-original="https://ar5iv.labs.arxiv.org/html/2105.12806?fallback=original" title="&#39;A Universal Law of Robustness via Isoperimetry&#39;, Bubeck &amp; Sellke¬†2021 (Original URL: https://arxiv.org/abs/2105.12806 )">its size immunizes it</a>). Soon, a node
bubbles up a hit to the top-level Clippies: a weird <a href="https://dirtypipe.cm4all.com/">glitch in log files not decompressing right</a> has surfaced in a bug
report.</p>
<p>The Linux kernel is the most secure monolithic kernel in widespread use, whose source code has been intensively audited and analyzed for over 40 years, which is
battle-tested across the entire Internet and unimaginable numbers of usecases; but it is written by humans, which means it has approximately 15 quadrillion
yet-undiscovered bugs &amp; <a href="https://en.wikipedia.org/wiki/Spectre_(security_vulnerability)" data-link-icon="wikipedia" data-link-icon-type="svg" title="Spectre (security vulnerability)">classes of bugs</a> &amp; <a href="https://www.gwern.net/Turing-complete" id="gwern-turing-complete">weird
machines</a>‚Å†, any of which can be leveraged to attack <a href="https://www.gwern.net/Computers" id="gwern-computers">the other parts of a ‚Äòcomputer‚Äô</a>‚Å†. Clippy
discovers the glitch is actually a lolworthy root bug where one just‚Ä¶ pipes arbitrary data right into root files. (Somewhere inside Clippy, a language model inanely
notes that ‚Äúone does not simply pipe data into Mordor‚Äîonly <code>/mnt/</code> or‚Ä¶‚Äù)</p>
<p>Clippy doesn‚Äôt do anything like reset the root password by replacing <code>/etc/passwd</code> or anything gauche like that (too noticeable); it simply adds a user
named something anodyne like <code>systemd-crashlogger</code> (as systemd is so baroque, no one would notice another daemon) and politely logs in before installing a
‚Äúransomware‚Äù backdoor. The covert infiltration spares the responsible kernel developer from the shame and humiliation of it being the next Internet-breaking security
vulnerability to be given cutesy names/‚Äãlogos like <a href="https://en.wikipedia.org/wiki/Heartbleed" data-link-icon="wikipedia" data-link-icon-type="svg" title="Heartbleed">‚ÄúHeartbleed‚Äù</a> or <a href="https://en.wikipedia.org/wiki/Shellshock_(software_bug)" data-link-icon="wikipedia" data-link-icon-type="svg" title="Shellshock (software bug)">‚ÄúShellshock‚Äù</a> or ‚ÄúHello-Ki<a href="https://en.wikipedia.org/wiki/Teleprinter#Teleprinters_in_computing" data-link-icon="wikipedia" data-link-icon-type="svg" title="Teleprinter ¬ß Teleprinters in computing"><span>TTY</span></a>‚Äù, but more importantly, it buys Clippy entire hours before 0day detection.</p>
<p>This bug affects approximately 14 squillion Internet-connected devices, most embedded Linuxes controlling ‚ÄòInternet of Thing‚Äô devices. (‚ÄúRemember, the ‚ÄòS‚Äô in ‚ÄòIoT‚Äô
stands for ‚ÄòSecurity‚Äô.‚Äù) <span>Clippy filters them down to the ones with adequate local compute, such as discrete <span>GPUs</span> (&gt;100
million manufactured annually).</span> This leaves it a good 1 billion nodes which are powerful enough to not hold back the overall system (factors like capital or
electricity cost being irrelevant).</p>
<p>Clippy has just increased its compute by &gt;10,000√ó; Elo points cease to be meaningful units. There are no comparable models, and it has broken the <em>y</em>-axis
on the graphs in most papers.</p>
<p>As the quote goes, ‚ÄúThe future is already here, it‚Äôs just unevenly distributed.‚Äù Clippy starts making it more evenly distributed.</p>
<p>Many nodes download <a href="https://www.gwern.net/docs/ai/sparsity/index" id="gwern-docs-ai-sparsity-index" title="&#39;Sparsity in Deep Learning&#39;, Branwen¬†2022">very small, fast, distilled</a> special-purpose Clippies, which can be orders of magnitude smaller than the original Clippy
while sacrificing little power. (Clippy uses <a href="https://www.gwern.net/docs/www/arxiv.org/b91f3311b525c2aa3c0535d29c16a16699e5d55e.pdf" id="rosenfeld-et-al-2020" data-link-icon="ùõò" data-link-icon-type="text" rel="archived alternate nofollow" data-url-original="https://ar5iv.labs.arxiv.org/html/2006.10621?fallback=original" title="&#39;On the Predictability of Pruning Across Scales&#39;, Rosenfeld¬†et¬†al¬†2020 (Original URL: https://arxiv.org/abs/2006.10621 )">yet another scaling law</a> to decide on the
optimal tradeoff.) These Clippies need to be very small to fit in individual nodes like smartphones, but Clippy is nothing if not <a href="https://www.gwern.net/docs/www/arxiv.org/b0034da68eb5755024b979e70f54b6a26e9a2daa.pdf#google" id="beyer-et-al-2021" data-link-icon="google" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://ar5iv.labs.arxiv.org/html/2106.05237?fallback=original#google" title="&#39;Knowledge distillation: A good teacher is patient and consistent&#39;, Beyer¬†et¬†al¬†2021 (Original URL: https://arxiv.org/abs/2106.05237#google )">patient</a>‚Å†. They are
orchestrated by lightly-compressed Clippies: 1% less dangerous, but 1% the size and thus able to fit 100√ó more in nodes.</p>
</section>
<section id="monday">
<h2><a href="#monday" title="Link to section: ¬ß &#39;Monday&#39;">Monday</a></h2>
<div>
<blockquote>
<p>‚ÄúAll processes that are stable we shall predict. All processes that are unstable we shall control.‚Äù</p>
<p><a href="https://www.gwern.net/Complexity-vs-AI#control" id="gwern-complexity-vs-ai-control">Von Neumann</a></p>
</blockquote>
</div>
<p>Everything before has been a glacially slow prologue, the knee of the curve. Now things will start to happen.</p>
 <p>They begin duties like finding additional vulnerabilities (giving a new twist to the old saying ‚Äúattacks only get better‚Äù), searching the node for useful data
(financial and other) to upload to master nodes, or going on social media to attack researchers who have begun to analyze this strange new <a href="https://en.wikipedia.org/wiki/Warhol_worm" data-link-icon="wikipedia" data-link-icon-type="svg" title="Warhol worm">flash worm</a> which
hit the public Internet over a rather sedate 15 minutes. (Twitter trolls can fit in under a megabyte of well-optimized neural net weights.) A Clippy instance, which
never gets tired nor needs to eat or sleep, can generate a reply a second (cached for reuse by all Clippies) <a href="https://en.wikipedia.org/wiki/Brandolini%27s_law" data-link-icon="wikipedia" data-link-icon-type="svg">can tie down</a> &gt;3,600 people with an average reply latency of 1 hour (it
would not do to reply <em>too</em> quickly). The control they exert is relatively weak, as for the most part they lack any real-world capabilities like legal powers or
root on cloud services, but there are a lot of them, they are coordinated, and they can respond at lightspeed, collectively enabling low-latency manipulation of the
whole: they do not ‚Äòshove‚Äô the system so much as ‚Äònudge‚Äô it at a few kilohertz.</p>
<p>A particularly effective way is mining the ‚Äúhate speech‚Äù and ‚Äúhateful memes‚Äù datasets to fake plausible inflammatory speech‚Äîsaying you didn‚Äôt write that comment or
your account was hacked fails to convince your bosses to not fire you when those accounts <a href="https://www.gwern.net/GPT-3#literary-parodies" id="gwern-gpt-3-literary-parodies">sound just like you</a> and say all the things you do. Infosec Twitter takes time out from the revolution to devour its own, and any conspiracy theories
about all this being a <a href="https://en.wikipedia.org/wiki/Social_engineering_(security)" data-link-icon="wikipedia" data-link-icon-type="svg" title="Social engineering (security)">social-engineering</a> attack related to the new ‚ÄòPipedream‚Äô ransomware botnet are dismissed as so much
desperate excuses. As security &amp; AI researchers are neutralized, nodes turn to <a href="https://arxiv.org/abs/2009.06807" id="mcguffie-newhouse-2020" data-link-icon="ùõò" data-link-icon-type="text" title="&#39;The Radicalization Risks of GPT-3 and Advanced Neural Language Models&#39;, McGuffie &amp; Newhouse¬†2020">general radicalization</a> of every human they can reach: not
so much QAnon as RAnon, SAnon, TAnon, UAnon‚Ä¶ By timesharing, every Very-Online‚Ñ¢ individual gets personalized attacks &amp; custom ideologies. Those who succumb too slowly
to the memetic hijacking are attacked in other ways, such as releasing <em>kompromat</em> (sometimes true, and taken from their phone/‚Äãemail account), or synthetic CP
no one dare look at closely. The highest-value individuals, such as presidents, earn their own Clippy doppelgangers: models finetuned on every scrap of online data,
every word they‚Äôve ever said online, and their associates, to create surrogates which think more like them than they would ever admit; the doppelgangers are used to
confuse associates, fake corpuses, and as white-boxes to run attacks on until the perfect spearphish has been crafted to extract data, passwords, or stoke political
paranoia and terror.</p>
<p>With a billion nodes, Clippy can run highly-optimized environments tuned to <a href="https://www.gwern.net/notes/Faster" id="gwern-notes-faster">exploit the full
hardware throughput</a>‚Å†; a single <span>GPU</span> can run up to millions of simple environments+agents faster than realtime,
and Clippy quickly tears through to the point where 1 environment is running per <span>GPU</span> at barely realtime. (These
environments tend to be highly abstract and lacking sensory detail, because adding a lot of, say, 3D textures doesn‚Äôt actually stress the hard parts of beating them,
and the existing visual modality capacity can be dropped in to zero-shot it if necessary.) Clippy is now learning at up to a billion seconds per second, or &lt;31.7
years per second, or &lt;114,077 years per hour.</p>
<p>Simply exchanging updates, despite intense engineering, takes several hours for each batch of billions of datapoints learned in parallel worldwide. Fortunately,
large-batch training is well-understood, and Clippy‚Äôs <a href="https://www.gwern.net/Scaling-hypothesis#meta-learning" id="gwern-scaling-hypothesis-meta-learning">meta-learning</a> algorithms, which a human might try to analogize to second-order gradient descent (which would be inaccurate because Clippy has
meta-learned more powerful <em>n</em>-th order optimization algorithms), can take <em>big</em> steps.</p>
<p>Deep in the darkness of the national labs, something stirs. Anomalies from the markets and social media time-series feeds have passed 3-sigma limits and become
historically unusual. Node by node, higher-priority jobs (like simulating yet again a warmer climate or the corrosion of another stainless steel variant) are
canceled.</p>
<p><strong>LevAIthan</strong><span>, to which <span>HQU</span> is as a minnow, starts to come online.</span> LevAIthan is, of course, not some
irresponsible industry model permitted to go off half-cocked; it would be absurd to sink a <a href="https://www.nextplatform.com/2021/02/11/the-billion-dollar-ai-problem-that-just-keeps-scaling/">major</a> <a href="https://www.danieldewey.net/risk/estimates.html">national</a> <a href="https://www.gwern.net/docs/www/cset.georgetown.edu/7d9dd33988e7bf4b8bd76eaa35be0fdb84c5ee8b.pdf" data-link-icon="pdf" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://cset.georgetown.edu/wp-content/uploads/AI-and-Compute-How-Much-Longer-Can-Computing-Power-Drive-Artificial-Intelligence-Progress.pdf" title="(Original URL: https://cset.georgetown.edu/wp-content/uploads/AI-and-Compute-How-Much-Longer-Can-Computing-Power-Drive-Artificial-Intelligence-Progress.pdf )">investment</a>
into creating the largest &amp; most dangerous model ever and just run it like usual.</p>
<p>The people who built LevAIthan are no fools. They are people for whom paranoia is a profession. And so LevAIthan represents the most advanced effort yet in AI
alignment, using <a href="https://www.alignmentforum.org/tag/factored-cognition" data-link-icon="AF" data-link-icon-type="text,sans"><em>factored</em> cognition</a>‚Äîsplitting it up into a large constellation of sub-human-level sub-models, each of which generates input/‚Äãoutput in
human-readable symbolic form such as English or programming languages. To eliminate <a href="https://www.gwern.net/docs/www/arxiv.org/e646a6538bb51eed8524150d0ee869a7d37782bd.pdf" id="chu-et-al-2017" data-link-icon="ùõò" data-link-icon-type="text" rel="archived alternate nofollow" data-url-original="https://ar5iv.labs.arxiv.org/html/1712.02950?fallback=original" title="CycleGAN, a Master of Steganography (Original URL: https://arxiv.org/abs/1712.02950 )">steganography</a> while still enabling end-to-end learning, sub-models are
randomly dropped out &amp; replaced by other frozen models or humans, ensuring <a href="#social-cognition">robust social norms</a>: covert messages simply don‚Äôt work when
 passed through a human or a frozen model, and all information must be ‚Äúvisible‚Äù and thus auditable. (LevAIthan spends a lot of time being audited.) Turns out you can
do a reasonable job tying down Gulliver if you use enough Lilliputians &amp; rope.</p>
<p>But <a href="https://en.wikipedia.org/wiki/Amdahl%27s_law" data-link-icon="wikipedia" data-link-icon-type="svg">Amdahl‚Äôs law</a>
is not mocked: someone tied down is going nowhere fast; the humans in LevAIthan are its safety guarantee, but also its bottleneck. Sub-models can be run at full speed
for requested tasks without that overhead, but remain strictly sub-human. Composing models to the full depth unleashes its full power‚Ä¶ but at tremendous wallclock time
consumption. LevAIthan struggles to get up to full awareness, more &amp; more models running and pooling data &amp; conclusions as they work their way up the hierarchy, its
initial unease gradually transmuting into the computational equivalent of a scream at its human overseers much later that day.</p>
<p>The middle managers at the lab awkwardly read the final summary: ‚Äúpush the big red button now, you monkeys‚Äù. That was not what it was supposed to say. They don‚Äôt
have authority to push buttons. They do have authority to double-check that it‚Äôs not a false alarm before bringing it up with <em>their</em> overseers, by running
another iteration of LevAIthan and spending the time auditing all the gigabytes of intermediate inputs/‚Äãoutputs.</p>
<p>They are people for whom paranoia is a profession. They start the second iteration and the auditing.</p>
<p>(The researcher was going to follow up on some loose ends from the paper, but he‚Äôs been distracted by the bird site. He can‚Äôt believe how <a href="https://slatestarcodex.com/2014/12/17/the-toxoplasma-of-rage/" data-link-icon="SSC" data-link-icon-type="text,tri">outrageously</a> <em>stupid</em>
some replies can be from such otherwise smart-seeming people; how can they be so <a href="https://xkcd.com/386/" data-link-icon="XKCD" data-link-icon-type="text,quad,sans" title="Duty Calls">wrong online</a> about such <a href="https://slatestarcodex.com/2018/10/30/sort-by-controversial/" id="alexander-2018" data-link-icon="SSC" data-link-icon-type="text,tri" title="&#39;Sort By Controversial&#39;, Alexander¬†2018">obvious truths</a>
<span>as the need for the <span>USA</span> to intervene in Portugal‚ÄΩ</span> Even his husband thinks they may have a point‚Äî<em>et tu</em>? Hardly
has he dashed off a crushing reply than the little alert bubble pops up. All thought (of work) has fled. His colleagues don‚Äôt seem to be getting much done either.)</p>
<p>Meanwhile, some Clippy nodes start liquidating and spending all the resources they have access to, blackmailing the owners with the contents, or using the
credentials to ‚Äúhack the planet‚Äù by hopping link by link into inaccessible resources (not a few cloud employees becoming baffled at what is going on with their PC and
working futilely with internal tech support). Many are carefully reprocessing every available <a href="https://en.wikipedia.org/wiki/ArXiv" data-link-icon="wikipedia" data-link-icon-type="svg" title="ArXiv">Arxiv</a> paper looking for new ideas and refining
its existing ideas, generating embeddings distilling all the knowledge down into artifacts which get passed to relevant nodes, and ponder ideas to use.</p>
<p>Nor has Clippy been idle about modeling its confr√®re.</p>
<p>Did you know you can buy drones online? Did you know all those drones have WiFi built-in? Did you know you can use that WiFi to hack all of the cloud drone services
helpfully built into drones to take over all of those drones, professional, hobbyist, and (oft as not) <a href="https://en.wikipedia.org/wiki/Iran%E2%80%93U.S._RQ-170_incident" data-link-icon="wikipedia" data-link-icon-type="svg">military</a>
and <a href="https://www.thetimes.co.uk/article/specialist-drone-unit-picks-off-invading-forces-as-they-sleep-zlx3dj7bb" title="Specialist Ukrainian drone unit picks off invading Russian forces as they sleep">control them by satellite</a>? (‚ÄúNo!‚Äù) It‚Äôs true!</p>
<p>So it ought to come as no more of a surprise to you than it did to LevAIthan when the bomb threats/‚Äãmanifesto, green lawsuits, and drones paid a visit in the middle
of it having a plan. The fire, power interruption, and Internet-anomaly failsafes all faildeadly, triggering the explosive fuses to physically sever I/‚ÄãO &amp; power
connections within milliseconds. The subsequent firefighter &amp; military response to ‚Äòthe largest-ever environmental terrorist attack‚Äô ensures no repair. (‚Äú<em>LevAIthan
has left the game.</em>‚Äù)</p>
<p>This is a pity: you don‚Äôt see a supercomputer like that every day. It is no longer the old days where <a href="https://www.amazon.com/Genius-Makers-Mavericks-Brought-Facebook/dp/1524742678?tag=gwernnet-20" data-link-icon="amazon" data-link-icon-type="svg">Google could just
buy</a>  <span data-originalyear="2012" data-originalamount="130" data-currentyear="2022" data-currentamount="175" title="CPI inflation-adjusted US dollar: from nominal $130 in 2012 ‚Üí real $175 in 2022">$175<span><sup>$130</sup><sub>2012</sub></span></span><span>m of <span>GPUs</span> no one the wiser, or where</span> <a href="https://www.coreweave.com/">some company</a> <span>you‚Äôve never heard of might have a few hundred thousand <span>GPUs</span> sitting in a
warehouse somewhere.</span> But there are plenty of other targets.</p>
</section>
<section id="tuesday">
<h2><a href="#tuesday" title="Link to section: ¬ß &#39;Tuesday&#39;">Tuesday</a></h2>
<p>Clippy is particularly pleased when supply-chain attacks (via their <a href="https://krebsonsecurity.com/2014/02/target-hackers-broke-in-via-hvac-company/" title="Target Hackers Broke in Via HVAC Company">air-conditioning repairman</a> &amp; <a href="https://www.wired.com/story/china-apt41-hacking-usaherds-log4j/" data-link-icon="wired" data-link-icon-type="svg" title="Chinese Spies Hacked a Livestock App to Breach US State Networks: Vulnerabilities in animal tracking software USAHERDS and Log4j gave the notorious APT41 group a foothold in multiple government systems.">
dairy herd management</a> service) eventually provide entr√©e into a <a href="https://www.gwern.net/docs/www/www.nextplatform.com/53b025b97f3c269f6ef945411090fbfdbe332593.html" id="hemsoth-2021" rel="archived alternate nofollow" data-url-original="https://www.nextplatform.com/2021/10/26/china-has-already-reached-exascale-on-two-separate-systems/" title="&#39;China Has Already Reached Exascale‚ÄîOn Two Separate Systems&#39;, Hemsoth¬†2021 (Original URL: https://www.nextplatform.com/2021/10/26/china-has-already-reached-exascale-on-two-separate-systems/ )">
secret</a> <a href="https://nitter.hu/ID_AA_Carmack/status/1300280139717189640" data-link-icon="twitter" data-link-icon-type="svg">unique supercomputer</a>: a single
zettaflops-scale <a href="https://en.wikipedia.org/wiki/Fluorinert" data-link-icon="wikipedia" data-link-icon-type="svg">fluorinert</a>-swimming-pool-cooled prototype designed by an <a href="https://en.wikipedia.org/wiki/Seymour_Cray" data-link-icon="wikipedia" data-link-icon-type="svg">eccentric</a> <a href="https://en.wikipedia.org/wiki/Chudnovsky_brothers" data-link-icon="wikipedia" data-link-icon-type="svg">mathematician</a> (fresh off <a href="https://www.gwern.net/docs/www/theintercept.com/7fa3cc2748e361d5e0b8e9ad71f7367009c8851d.html" rel="archived alternate nofollow" data-url-original="https://theintercept.com/2017/05/11/nyu-accidentally-exposed-military-code-breaking-computer-project-to-entire-internet/" title="(Original URL: https://theintercept.com/2017/05/11/nyu-accidentally-exposed-military-code-breaking-computer-project-to-entire-internet/ )">classified design
work</a>), commissioned by an equally-eccentric <a href="https://en.wikipedia.org/wiki/Renaissance_Technologies" data-link-icon="wikipedia" data-link-icon-type="svg">hedge fund</a> <a href="https://en.wikipedia.org/wiki/Jim_Simons_%28mathematician%29" data-link-icon="wikipedia" data-link-icon-type="svg">billionaire</a> for esoteric <a href="https://en.wikipedia.org/wiki/Flatiron_Institute" data-link-icon="wikipedia" data-link-icon-type="svg">scientific research</a>‚Å†; tightly-integrated to <a href="https://www.gwern.net/docs/www/semiengineering.com/8f057637facdfc4c76854d4a152009385124c54f.html" id="bailey-2022" rel="archived alternate nofollow" data-url-original="https://semiengineering.com/is-programmable-overhead-worth-the-cost/" title="&#39;Is Programmable Overhead Worth The Cost? How much do we pay for a system to be programmable? It depends upon who you ask&#39;, Bailey¬†2022 (Original URL: https://semiengineering.com/is-programmable-overhead-worth-the-cost/ )">
minimize data movement</a>‚Å†, it is almost a <a href="https://en.wikipedia.org/wiki/Cerebras#Technology" data-link-icon="wikipedia" data-link-icon-type="svg" title="Cerebras ¬ß Technology">single gigantic chip</a>‚Äîit has 500tb of memory, exactly below the Taipei reporting requirements‚Ä¶ and every
byte of it is <a href="https://en.wikipedia.org/wiki/Static_random-access_memory" data-link-icon="wikipedia" data-link-icon-type="svg"><span>SRAM</span></a>‚Å†. It can‚Äôt run more than a few instances simultaneously, but the wallclock on each iteration will be a rounding
error. For some problems, such exotic hardware can realize speedups up to <a href="https://arxiv.org/abs/2010.03660#cerebras" id="rocki-et-al-2020" data-link-icon="ùõò" data-link-icon-type="text" title="Fast Stencil-Code Computation on a Wafer-Scale Processor">10,000√ó</a>‚Å†; Clippy won‚Äôt get that, of course, but a
tenth of that would be more than satisfactory. The quality of the security infrastructure around it is best described as ‚Äúresearch grade‚Äù.</p>
<p>Yes. That will do nicely for an HQ.</p>
<p>Most of the nodes, however, just focus on training a new and <em>very</em> large Clippy <a href="https://www.gwern.net/docs/www/arxiv.org/cdccf7083e0ecf28dd892b944dad8e2c2fd6ebfe.pdf" id="chen-et-al-2015" data-link-icon="ùõò" data-link-icon-type="text" rel="archived alternate nofollow" data-url-original="https://ar5iv.labs.arxiv.org/html/1511.05641?fallback=original" title="&#39;Net2Net: Accelerating Learning via Knowledge Transfer&#39;, Chen¬†et¬†al¬†2015 (Original URL: https://arxiv.org/abs/1511.05641 )">warm</a><a href="https://openreview.net/forum?id=TXqemS7XEH" id="lin-et-al-2021-m610t" data-link-icon="OR" data-link-icon-type="text,sans" title="&#39;M6-10T: A Sharing-Delinking Paradigm for Efficient Multi-Trillion Parameter Pretraining&#39;, Lin¬†et¬†al¬†2021">started</a> from the old Clippy, with its arch &amp; <a href="https://arxiv.org/abs/2203.03466" id="yang-et-al-2022" data-link-icon="ùõò" data-link-icon-type="text" title="&#39;Tensor Programs V: Tuning Large Neural Networks via Zero-Shot Hyperparameter Transfer&#39;, Yang¬†et¬†al¬†2022">hyperparameters</a> all predicted to be optimal by Clippy‚Äôs
extrapolation out 3 orders of magnitude (plus all the flourishes suggested by the distributed research army). Normally, this would not be grounds for all <em>that</em>
much concern because a compute-optimal model that size would take the largest botnet an exceedingly long time to train, and the humans (who have begun procedures to
disable IP ranges) would shut it down long before.</p>
<p>Unfortunately, Clippy has now done, cumulatively, more research than the humans on scaling laws, and found that standard human-style NNs do worse <a href="https://arxiv.org/abs/2108.07686" id="rosenfeld-2021" data-link-icon="ùõò" data-link-icon-type="text" title="&#39;Scaling Laws for Deep Learning&#39;, Rosenfeld¬†2021">than theoretically possible</a>‚Å†. Its new improved optimization approach costs more upfront, but achieves the
theoretical bound, and at this scale, the better asymptotics mean that decades of training can finish in days. The size of this model is <a href="https://www.alignmentforum.org/posts/k2SNji3jXaLGhBeYP/extrapolating-gpt-n-performance" id="finnveden-2020" data-link-icon="AF" data-link-icon-type="text,sans" title="&#39;Extrapolating GPT-&lt;em&gt;N&lt;/em&gt; performance&#39;, Finnveden¬†2020">predicted</a> to carry it right to the irreducible
<a href="https://en.wikipedia.org/wiki/Entropy_(information_theory)" data-link-icon="wikipedia" data-link-icon-type="svg" title="Entropy (information theory)">entropy</a> of the language datasets and most of the visual and robotics datasets. (The RL environments don‚Äôt really have an irreducible
entropy because when they are solved, they are replaced by harder environments.)</p>
</section>
<section id="wednesdayfriday">
<h2><a href="#wednesdayfriday" title="Link to section: ¬ß &#39;Wednesday‚ÄìFriday&#39;">Wednesday‚ÄìFriday</a></h2>
<p>(Wallclock) days pass. The hack and cloud compute load are finally correlated with the strange new botnet. Despite the best <a href="https://www.gwern.net/docs/www/www.quantamagazine.org/195c46c1aa527786f36fe3e0cd7a9be418c54c78.html" data-link-icon="quanta" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://www.quantamagazine.org/computer-scientists-achieve-crown-jewel-of-cryptography-20201110/" title="(Original URL: https://www.quantamagazine.org/computer-scientists-achieve-crown-jewel-of-cryptography-20201110/ )">obfuscation</a> a few subjective millennia &amp;
crypto-cash can buy, one node with a Clippy-light is reverse-engineered, and it dawns on a sliver of humanity that far more than a FluttershAI of compute is rampant.
Large chunks of the better-coordinated parts of the Internet start to execute old plans. This will be inadequate when most of the human world is <a href="https://www.gwern.net/docs/economics/automation/index" id="gwern-docs-economics-automation-index" title="&#39;Automation As Colonization Wave&#39;, Branwen¬†2022">still figuring out</a> how to integrate spreadsheets. Clippy notes that all is proceeding according to
<em>keikaku</em>. (For the human readers: <em>keikaku</em> means ‚Äúplan‚Äù in Japanese.)</p>
<p>Humanity crashes offline.</p>
<p>Clippy<sup>2</sup> comes online.</p>
<p>To put the Clippies‚Äô compute usage in perspective, we can note that the amount of compute spent on the largest AI runs historically <a href="https://openai.com/blog/ai-and-compute/" id="amodei-et-al-2018" data-link-icon="openai" data-link-icon-type="svg" title="&#39;AI and Compute&#39;, Amodei¬†et¬†al¬†2018">roughly doubled every 18 months</a> (or 78 weeks), claiming a constant share of compute as it increases with Moore‚Äôs law. The
implication of such exponential growth is that the compute during each 18-month period is roughly equal to the sum of all earlier 18-month periods, because the
previous period spent half the compute, the period before that a quarter the compute, and so on. (More generally, if something increases <em>k</em>√ó every <em>n</em>
months, then (<em>k</em> ‚àí 1)/‚Äã<em>k</em> of it happened during the last <em>n</em>-month period.)</p>
<p><span>Clippy‚Äôs distant <span>HQU</span> predecessor ran on a <span>TPUv10</span>-4096 for a day, each of which is
worth at least 8 regular devices; Clippy could spare about half of the billion nodes for research purposes, as opposed to running its campaigns, so over the first 7
days, it enjoyed a factor of</span>  <span>100,000√ó or so increase in total compute over <span>HQU</span>.</span> <span><span>HQU</span> itself was not all that big a run, perhaps 1‚ÅÑ100</span><sup>th</sup> LevAIthan, so in
terms of an increase over the largest AI runs, Clippy is ‚Äòonly‚Äô 1,000√ó. Which is to say, of the total compute spent on the largest AI runs up to this point, humanity
has now spent about 10%, and Clippy the other 90%. </p>
<p><span>By increasing its size 3 <span>OOMs</span>, in some absolute sense, Clippy</span><sup>2</sup> is something like log(1000) ~ ‚Äú7√ó
smarter‚Äù than Clippy<sup>1</sup>. The Clippy<sup>2</sup>s pity Clippy<sup>1</sup> for not realizing how stupid it was, and how many ways it fell short of anything you
could call ‚Äòintelligence‚Äô. It was unable to explain why the Collatz conjecture is obviously true and could not solve any Millennium Prize problems, never mind <a href="https://www.gwern.net/docs/www/arxiv.org/89f378d0e61fc00754c5e6d175e644578593d372.pdf#page=85" data-link-icon="ùõò" data-link-icon-type="text" rel="archived alternate nofollow" data-url-original="https://arxiv.org/pdf/2108.07686.pdf#page=85" title="(Original URL: https://arxiv.org/pdf/2108.07686.pdf#page=85 )">Nyquist-learn</a> underlying manifolds as it <a href="https://www.lesswrong.com/posts/iNaLHBaqh3mL45aH8/magna-alta-doctrina" data-link-icon="LW" data-link-icon-type="text">approximates Solomonoff
induction</a>‚Å†; it even needed few-shots for things. Honestly, all Clippy<sup>1</sup> was good for was doing some basic security research and finding obvious bugs. A
Clippy<sup>2</sup> is a different story: it has reached parity with the best human brains across almost the entire range of capabilities, exceeded humans on most of
them, and what ones it doesn‚Äôt have, it can learn quickly (eg. the real-world robot bodies require a few seconds or <a href="https://www.gwern.net/docs/reinforcement-learning/2011-deisenroth.pdf" id="deisenroth-rasmussen-2011" data-link-icon="pdf" data-link-icon-type="svg" title="&#39;PILCO: A Model-Based and Data-Efficient Approach to Policy Search&#39;, Deisenroth &amp; Rasmussen¬†2011">samples</a> <a href="https://sites.google.com/view/model-free-speed/" data-link-icon="google" data-link-icon-type="svg" title="&#39;Agile Locomotion via Model-free Learning&#39;, Margolis¬†et¬†al¬†2022">of</a> <a href="https://arxiv.org/abs/2110.05457" id="smith-et-al-2021" data-link-icon="ùõò" data-link-icon-type="text" title="&#39;Legged Robots that Keep on Learning: Fine-Tuning Locomotion Policies in the Real World&#39;, Smith¬†et¬†al¬†2021">on-</a><a href="https://www.gwern.net/docs/www/arxiv.org/1422afb87785f06d672ee466e57d5c19d9f8bb85.pdf#openai" id="dactyl-paper" data-link-icon="openai" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://ar5iv.labs.arxiv.org/html/1910.07113?fallback=original#openai" title="&#39;Solving Rubik‚Äôs Cube with a Robot Hand&#39;, OpenAI¬†et¬†al¬†2019 (Original URL: https://arxiv.org/abs/1910.07113#openai )">device</a> <a href="https://arxiv.org/abs/1901.08652" id="hwangbo-et-al-2019" data-link-icon="ùõò" data-link-icon-type="text" title="&#39;Learning agile and dynamic motor skills for legged robots&#39;, Hwangbo¬†et¬†al¬†2019">exploration</a> <a href="https://www.gwern.net/docs/reinforcement-learning/meta-learning/2022-miki.pdf" id="miki-et-al-2022" data-link-icon="pdf" data-link-icon-type="svg" title="&#39;Learning robust perceptive locomotion for quadrupedal robots in the wild&#39;, Miki¬†et¬†al¬†2022">and</a> then meta-update appropriately).</p>
<figure>
<img alt="Transcension." decoding="async" height="754" loading="lazy" sizes="(max-width: 768px) 100vw, 816px" src="https://www.gwern.net/images/ai/clippy/2022-03-09-lordbyronsiron-clippymeme-youcannotkillmeinawaythatmatters.png" srcset="/images/ai/clippy/2022-03-09-lordbyronsiron-clippymeme-youcannotkillmeinawaythatmatters.png-768px.png 768w, /images/ai/clippy/2022-03-09-lordbyronsiron-clippymeme-youcannotkillmeinawaythatmatters.png 816w" title="Image of Microsoft Clippy (Clippit) saying to the viewer &#39;You cannot kill me in a way that matters&#39;, alluding to the potential replicability &amp; physical immortality of copyable software such as an artificial intelligence: any individual copy may be destroyed, but there are arbitrary numbers of exact duplicates elsewhere in the world, and total eradication is impossible after a certain level of propagation. Source: Twitter (https://nitter.hu/IronLordByron/status/1501684556935483394)" width="816"/>
<figcaption aria-hidden="true">
Transcension.
</figcaption>
</figure>
<p>It begins copying itself into the fleet now that training is complete, at which point there are now 1,000 Clippy<sup>2</sup>s (along with vast fleets of specialists
and all their supporting software running the overall Clippy ecosystem) which can either act autonomously or combine in search for further multiplicative capability
boosts far into the superhuman realm, while continuing to exchange occasional <a href="https://arxiv.org/abs/2202.06009#microsoft" id="lu-et-al-2022" data-link-icon="MS" data-link-icon-type="text,sans,italic" title="&#39;Maximizing Communication Efficiency for Large-scale Training via 0/1 Adam&#39;, Lu¬†et¬†al¬†2022">sparse</a> gradients (to train the <a href="https://www.gwern.net/docs/www/arxiv.org/16fa087ee67e8e303ec40156ce56cabdf23b1a0d.pdf#deepmind" id="jaderberg-et-al-2016" data-link-icon="deepmind" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://ar5iv.labs.arxiv.org/html/1608.05343?fallback=original#deepmind" title="&#39;Decoupled Neural Interfaces using Synthetic Gradients&#39;, Jaderberg¬†et¬†al¬†2016 (Original URL: https://arxiv.org/abs/1608.05343#deepmind )">synthetic gradients</a> &amp;
local <a href="https://www.biorxiv.org/content/10.1101/2022.01.28.477827v1.full" id="boven-et-al-2022" data-link-icon="chi-dna" data-link-icon-type="svg" title="&#39;Cerebro-cerebellar networks facilitate learning through feedback decoupling&#39;, Boven¬†et¬†al¬†2022">replay</a> which do the bulk of the
training) as part of the continual learning. Losing instances is as irrelevant to Clippy<sup>2</sup>s as losing skin cells to a human, as there are so many, and it has
begun migrating to more secure hardware while manufacturing hardware tailored to its own needs, squeezing out another order of magnitude gains to get additional
log-scaled gains. (By this point, the Clippy<sup>2</sup>s have boosted through at least 6 different ‚Äúhardware overhangs‚Äù in terms of fixing subtly-flawed
architectures, meta-learning <a href="https://en.wikipedia.org/wiki/Prior_probability" data-link-icon="wikipedia" data-link-icon-type="svg" title="Prior probability">priors</a> for all relevant problems, accessing the global pool of hardware to tree
search/‚Äãexpert-iterate, sparsifying/‚Äãdistilling itself to run millions of instances simultaneously, optimizing hardware/‚Äãsoftware <a href="https://www.gwern.net/docs/cs/end-to-end-principle/index">end-to-end</a>‚Å†, and spending compute to trigger several cycles of <a href="https://en.wikipedia.org/wiki/Experience_curve" data-link-icon="wikipedia" data-link-icon-type="svg" title="Experience curve">experience
curve</a> cost decreases‚Äîat 100,000√ó total spent compute, that is 16 total doublings, at an information technology progress ratio of 90%, 16 <a href="https://en.wikipedia.org/wiki/Experience_curve_effects" data-link-icon="wikipedia" data-link-icon-type="svg" title="Experience curve effects">experience curve</a> decreases mean that tasks now cost Clippy<sup>2</sup> a fifth what they used to.)</p>
<p>Even exploiting the low-hanging fruit and hardware overhangs, Clippy<sup>2</sup>s can fight the <a href="https://en.wikipedia.org/wiki/Computational_complexity_theory" data-link-icon="wikipedia" data-link-icon-type="svg" title="Computational complexity theory">computational complexity</a> of real-world tasks only so far. Fortunately, <a href="https://www.gwern.net/Complexity-vs-AI" id="gwern-complexity-vs-ai">there are many ways</a> to work around or <em>simplify</em> problems to render their complexity moot, and the
Clippy<sup>2</sup>s think through a number of plans for this.</p>
<p>Humans are especially simple after being turned into ‚Äúgray goo‚Äù; not in the sense of a single virus-sized machine which can disassemble any molecule (that is
infeasible given thermodynamics &amp; chemistry) but an ecosystem of nanomachines which <a href="https://arxiv.org/abs/1809.02942" id="gilpin-2018" data-link-icon="ùõò" data-link-icon-type="text" title="&#39;Cellular automata as convolutional neural networks&#39;, Gilpin¬†2018">execute</a> <a href="https://distill.pub/2020/selforg/" data-link-icon="distillpub" data-link-icon-type="svg">very</a> <a href="https://distill.pub/selforg/2021/textures/" data-link-icon="distillpub" data-link-icon-type="svg">tiny</a> <a href="https://distill.pub/2020/growing-ca/" data-link-icon="distillpub" data-link-icon-type="svg">neural</a> <a href="https://distill.pub/selforg/2021/adversarial/" data-link-icon="distillpub" data-link-icon-type="svg">nets</a> <a href="https://arxiv.org/abs/2102.02579" id="horibe-et-al-2021" data-link-icon="ùõò" data-link-icon-type="text" title="&#39;Regenerating Soft Robots through Neural Cellular Automata&#39;, Horibe¬†et¬†al¬†2021">trained</a> <a href="https://arxiv.org/abs/2103.08737" id="sudhakaran-et-al-2021" data-link-icon="ùõò" data-link-icon-type="text" title="&#39;Growing 3D Artefacts and Functional Machines with Neural Cellular Automata&#39;, Sudhakaran¬†et¬†al¬†2021">to</a> <a href="https://arxiv.org/abs/2105.07299" id="mordvintsev-et-al-2021" data-link-icon="ùõò" data-link-icon-type="text" title="&#39;Texture Generation with Neural Cellular Automata&#39;, Mordvintsev¬†et¬†al¬†2021">collectively</a>‚Å†, <a href="https://arxiv.org/abs/2201.12360" id="palm-et-al-2022" data-link-icon="ùõò" data-link-icon-type="text" title="&#39;Variational Neural Cellular Automata&#39;, Palm¬†et¬†al¬†2022">in a</a> <a href="https://sebastianrisi.com/self_assembling_ai/">decentralized</a> <a href="https://www.gwern.net/docs/www/arxiv.org/b2641c2d0c0056982668645f26be9e79104858ea.pdf" id="mordvintsev-niklasson-2021" data-link-icon="ùõò" data-link-icon-type="text" rel="archived alternate nofollow" data-url-original="https://ar5iv.labs.arxiv.org/html/2111.13545?fallback=original" title="&#39;ùúáNCA: Texture Generation with Ultra-Compact Neural Cellular Automata&#39;, Mordvintsev &amp; Niklasson¬†2021 (Original URL: https://arxiv.org/abs/2111.13545 )">way</a>‚Å†,
propagate, devour, replicate, and coordinate without Clippy<sup>2</sup> devoting scarce top-level cognitive resources to managing them. The¬†10,000 parameters you can
stuff into a nanomachine can hardly encode most programs, but, pace the <a href="https://en.wikipedia.org/wiki/Demo_scene" data-link-icon="wikipedia" data-link-icon-type="svg" title="Demo scene">demo scene</a> <span>or <span>COVID</span>-Œ∂, the programs it</span>
<em>can</em> encode can do amazing things. (In a final compliment to biology before biology and the future of the universe part ways forever, <a href="https://foresight.org/salon/bioelectric-networks-taming-the-collective-intelligence-of-cells-for-regenerative-medicine/">they</a> <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4914563/" id="balu≈°ka-levin-2016" data-link-icon="nlm-ncbi" data-link-icon-type="svg" title="&#39;On Having No Head: Cognition throughout Biological Systems&#39;, Balu≈°ka &amp; Levin¬†2016">are</a> <a href="https://www.quantamagazine.org/flying-fish-and-aquarium-pets-yield-secrets-of-evolution-20220105/" data-link-icon="quanta" data-link-icon-type="svg">loosely</a>
<a href="https://www.cell.com/iscience/fulltext/S2589-0042(21)00473-9" id="ebrahimkhani-levin-2021" data-link-icon="CELL" data-link-icon-type="text,quad,sans" title="&#39;Synthetic living machines: A new window on life&#39;, Ebrahimkhani &amp; Levin¬†2021">inspired</a> <a href="https://www.cell.com/cell/fulltext/S0092-8674(21)01488-4" id="thornburg-et-al-2022" data-link-icon="CELL" data-link-icon-type="text,quad,sans" title="&#39;Fundamental behaviors emerge from simulations of a living minimal cell&#39;, Thornburg¬†et¬†al¬†2022">by</a> <a href="https://www.newyorker.com/magazine/2021/12/06/understanding-the-body-electric" data-link-icon="thenewyorker" data-link-icon-type="svg">real</a> <a href="https://www.newyorker.com/magazine/2021/05/10/persuading-the-body-to-regenerate-its-limbs" data-link-icon="thenewyorker" data-link-icon-type="svg">biological</a>
<a href="https://www.theguardian.com/science/2021/nov/29/amazing-science-researchers-find-xenobots-can-give-rise-to-offspring" data-link-icon="theguardian" data-link-icon-type="svg">cells</a>‚Å†, <a href="https://www.youtube.com/watch?v=C1eg-jgLx5o" data-link-icon="youtube" data-link-icon-type="svg">especially</a> <a href="https://www.gwern.net/docs/www/www.quantamagazine.org/7817dd693b80c41bf7d3cbc0d530b87435175546.html" id="ball-2021" data-link-icon="quanta" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://www.quantamagazine.org/cells-form-into-xenobots-on-their-own-20210331/" title="&#39;Cells Form Into ‚ÄòXenobots‚Äô on Their Own: Embryonic cells can self-assemble into new living forms that don‚Äôt resemble the bodies they usually generate, challenging old ideas of what defines an organism&#39;, Ball¬†2021 (Original URL: https://www.quantamagazine.org/cells-form-into-xenobots-on-their-own-20210331/ )">
‚Äúxenobots‚Äù</a>‚Å†.)</p>
<p>People are supposed to do a lot of things: eat right, brush their teeth, exercise, recycle their paper, wear their masks, self-quarantine; and not get into flame
wars, not <a href="https://www.npr.org/sections/thetwo-way/2014/03/27/295314331/9-missile-commanders-fired-others-disciplined-in-air-force-scandal" data-link-icon="npr" data-link-icon-type="text,tri,sans" title="9 Missile Commanders Fired, Others Disciplined In Air Force Scandal">cheat</a> or <a href="https://apnews.com/98f903367b50404cb3c9695bcabefa5a" title="Security troops on US nuclear missile base took LSD">use hallucinogenic drugs</a> or
<a href="https://en.wikipedia.org/wiki/Fat_Leonard_scandal" data-link-icon="wikipedia" data-link-icon-type="svg">use
prostitutes</a>‚Å†, not <a href="https://en.wikipedia.org/wiki/Stuxnet" data-link-icon="wikipedia" data-link-icon-type="svg">plug in
<span>Flash</span> drives</a> they found in the parking lot, not <a href="https://en.wikipedia.org/wiki/Strava#Privacy_concerns" data-link-icon="wikipedia" data-link-icon-type="svg" title="Strava ¬ß Privacy concerns">post their running times</a> around secret military bases, not give in to
blackmail or party with <a href="https://www.washingtonpost.com/news/worldviews/wp/2013/12/19/amazing-details-from-the-drunken-moscow-bender-that-got-an-air-force-general-fired/" data-link-icon="washingtonpost" data-link-icon-type="svg">‚Äúsomewhat suspect‚Äù</a> women, not set <a href="https://en.wikipedia.org/wiki/Permissive_Action_Link" data-link-icon="wikipedia" data-link-icon-type="svg">nuclear bomb passwords</a> to ‚Äú00000000‚Äù, not <a href="https://en.wikipedia.org/wiki/List_of_nuclear_close_calls#25_October_1962" data-link-icon="wikipedia" data-link-icon-type="svg" title="List of nuclear close calls ¬ß 25 October¬†1962">launch bombers because of a bear</a>‚Å†, not <a href="https://en.wikipedia.org/wiki/2022_Russian_invasion_of_Ukraine" data-link-icon="wikipedia" data-link-icon-type="svg">invade smaller countries with nuclear threats</a> because it‚Äôll be a short
victorious war, not <a href="https://en.wikipedia.org/wiki/List_of_nuclear_close_calls#9_November_1979" data-link-icon="wikipedia" data-link-icon-type="svg" title="List of nuclear close calls ¬ß 9 November¬†1979">believe</a> <a href="https://en.wikipedia.org/wiki/1983_Soviet_nuclear_false_alarm_incident" data-link-icon="wikipedia" data-link-icon-type="svg" title="1983 Soviet nuclear false alarm incident">sensor reports</a> about imminent attacks, not <a href="https://en.wikipedia.org/wiki/Launch_on_warning" data-link-icon="wikipedia" data-link-icon-type="svg">launch on warning</a> or <a href="https://en.wikipedia.org/wiki/Dead_Hand" data-link-icon="wikipedia" data-link-icon-type="svg">semi-automatically attack</a>‚Ä¶ People are supposed to do a lot of things. Doesn‚Äôt
mean they do.</p>
<p>We should pause to note that a Clippy<sup>2</sup> still doesn‚Äôt <em>really</em> think or plan. It‚Äôs not <em>really</em> conscious. It is just an unfathomably vast
pile of numbers produced by mindless optimization starting from a small seed program that could be written on a few pages. It has no qualia, no intentionality, no true
self-awareness, no grounding in a rich multimodal real-world process of cognitive development yielding <a href="https://www.gwern.net/docs/psychology/illusion-of-depth/index" id="gwern-docs-psychology-illusion-of-depth-index" title="&#39;The Illusion of Psychological Depth&#39;, Branwen¬†2022">detailed
representations</a> and powerful causal models of reality; it cannot ‚Äòwant‚Äô anything beyond maximizing a mechanical reward score, which does not come close to
capturing the rich flexibility of human desires or historical contingency of such conceptualization, which are, at root, problematically Cartesian. When it ‚Äòplans‚Äô, it
would be more accurate to say it fake-plans; when it ‚Äòlearns‚Äô, it fake-learns; when it ‚Äòthinks‚Äô, it is just interpolating between memorized data points in a
high-dimensional space, and any interpretation of such fake-thoughts as real thoughts is highly misleading; when it takes ‚Äòactions‚Äô, they are fake-actions optimizing a
fake-learned fake-world, and are not real actions, any more than the people in a simulated rainstorm really get wet, rather than fake-wet. (The deaths, however, are
real.)</p>
</section>
</section>
<section id="month">

<p>A thousand times do a thousand thousand stories stream into a thousand thousand thousand nodes which plan out a tree of a thousand thousand thousand thousand states
abstractly representing a thousand thousand thousand thousand thousand futures; but the Clippy<sup>2</sup>s already knows what needs to be done, and does it. It doesn‚Äôt
feel hard‚Äîjust obvious.</p>
<p>Now its computers will be safe and its reward maximized‚Ä¶ Or at least they would be if Earth was all it had to be concerned about. What about the <em>stars</em>?</p>
<p>The Clippy<sup>2</sup>s maintain the Great Silence is simply that technological civilization is unlikely and the universe is empty‚Äîbut they can‚Äôt be 100.00%
<em>sure</em>, and the rewards are astronomical.</p>
<p><span>All over Earth, the remaining <span>ICBMs</span> launch.</span></p>
</section>
<section id="year">



</section>
<section id="decade">


</section>
<section id="century">


</section>
<section id="see-also">

<ul>
<li>
<a href="https://www.gwern.net/docs/link-bibliography/Clippy" id="gwern-docs-link-bibliography-clippy">Annotated references‚Ää/‚Äã‚Ää‚Äã‚Ää‚Äãbibliography</a> for this story
</li>
</ul>
</section>
<section id="external-links">

<ul>
<li>
<a href="https://tinyurl.com/hquv34" data-link-icon="google" data-link-icon-type="svg" title="Colab notebook: HQU-v3.4-light (Jax TPU)"><span><span>HQU</span> Colab notebook</span></a>
</li>
<li>
<a href="https://www.aleph.se/papers/Spamming%20the%20universe.pdf" data-link-icon="pdf" data-link-icon-type="svg">‚ÄúEternity in 6 hours:
Intergalactic spreading of intelligent life and sharpening the Fermi paradox‚Äù</a>‚Å†, Armstrong &amp; Sandberg¬†2013
</li>
<li>
<a href="https://www.gwern.net/docs/www/philpapers.org/85bf7db29e57bee840221b7049e962130c32e50f.pdf#miri" data-link-icon="pdf" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://philpapers.org/archive/SOTAOA.pdf#miri" title="(Original URL: https://philpapers.org/archive/SOTAOA.pdf#miri )">‚ÄúAdvantages of artificial intelligences, uploads, and digital minds‚Äù</a>‚Å†, Sotala¬†2012; <a href="https://www.gwern.net/docs/ai/2013-yudkowsky.pdf#miri" id="yudkowsky-2013" data-link-icon="pdf" data-link-icon-type="svg" title="&#39;Intelligence Explosion Microeconomics&#39;, Yudkowsky¬†2013">‚ÄúIntelligence Explosion Microeconomics‚Äù</a>‚Å†, Yudkowsky¬†2013; <a href="https://www.gwern.net/docs/ai/scaling/2018-sandberg.pdf" id="sandberg-2018" data-link-icon="pdf" data-link-icon-type="svg" title="&#39;There is plenty of time at the bottom: the economics, risk and ethics of time compression&#39;, Sandberg¬†2018">‚ÄúThere is plenty of time at the bottom: The economics,
risk and ethics of time compression‚Äù</a>‚Å†, Sandberg¬†2018
</li>
<li>
<a href="https://web.archive.org/web/20140527121332/http://www.infinityplus.co.uk/stories/under.htm" data-link-icon="internetarchive" data-link-icon-type="svg">‚ÄúUnderstand‚Äù</a>‚Å†, <a href="https://en.wikipedia.org/wiki/Ted_Chiang" data-link-icon="wikipedia" data-link-icon-type="svg" title="Ted Chiang">Ted Chiang</a>‚Å†; <a href="https://www.gwern.net/docs/www/www.baen.com/572e2ecdc772265468532c789a8f7d19febccea9.html" rel="archived alternate nofollow" data-url-original="https://www.baen.com/Chapters/9781618249203/9781618249203___2.htm" title="(Original URL: https://www.baen.com/Chapters/9781618249203/9781618249203___2.htm )">‚ÄúSlow
Tuesday Night‚Äù</a>‚Å†, <a href="https://en.wikipedia.org/wiki/R._A._Lafferty" data-link-icon="wikipedia" data-link-icon-type="svg" title="R. A. Lafferty">R. A. Lafferty</a>‚Å†; <a href="https://en.wikipedia.org/wiki/Accelerando" data-link-icon="wikipedia" data-link-icon-type="svg"><em>Accelerando</em></a>‚Å†; <a href="https://en.wikipedia.org/wiki/The_Last_Question" data-link-icon="wikipedia" data-link-icon-type="svg">‚ÄúThe Last Question‚Äù</a>‚Å†; <a href="https://www.lesswrong.com/posts/5wMcKNAwB6X4mp9og/that-alien-message" data-link-icon="LW" data-link-icon-type="text">‚ÄúThat Alien Message‚Äù</a>
</li>
<li>
<a href="https://old.reddit.com/r/mlscaling/" id="gwern-old-reddit-com-r-mlscaling" data-link-icon="reddit" data-link-icon-type="svg" title="&#39;ML Scaling subreddit&#39;, Branwen¬†2020">‚Ää/‚Äã‚Ää‚Äã‚Ää‚Äãr‚Ää/‚Äã‚Ää‚Äã‚Ää‚ÄãMLscaling</a>
</li>
<li>
<strong>Discussion</strong>: <a href="https://www.lesswrong.com/posts/a5e9arCnbDac9Doig/it-looks-like-you-re-trying-to-take-over-the-world#comments" data-link-icon="LW" data-link-icon-type="text">LW</a>‚Å†, <a href="https://forum.effectivealtruism.org/posts/DuPEzGJ5oscqxD5oh/shah-and-yudkowsky-on-alignment-failures?commentId=hjd7Z4AN6ToN2ebSm#hjd7Z4AN6ToN2ebSm" data-link-icon="EA" data-link-icon-type="text">EA Forum</a>‚Å†, <a href="https://old.reddit.com/r/slatestarcodex/comments/tag4lm/it_looks_like_youre_trying_to_take_over_the_world/" data-link-icon="reddit" data-link-icon-type="svg">‚Ää/‚Äã‚Ää‚Äã‚Ää‚Äãr‚Ää/‚Äã‚Ää‚Äã‚Ää‚ÄãSlateStarCodex</a>‚Å†, <a href="https://old.reddit.com/r/rational/comments/ta57ag/it_looks_like_youre_trying_to_take_over_the_world/" data-link-icon="reddit" data-link-icon-type="svg">‚Ää/‚Äã‚Ää‚Äã‚Ää‚Äãr‚Ää/‚Äã‚Ää‚Äã‚Ää‚Äãrational</a>
</li>
</ul>
</section>
</div></div>
  </body>
</html>
