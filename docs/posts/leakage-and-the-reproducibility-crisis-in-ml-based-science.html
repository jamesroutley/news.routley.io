<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://reproducible.cs.princeton.edu/">Original</a>
    <h1>Leakage and the reproducibility crisis in ML-based science</h1>
    
    <div id="readability-page-1" class="page"><div id="myModal">
            <div>
              <div>

                <div>
                  <h4>Why do we call these reproducibility failures?</h4>
                  </div>

                

                  

                </div>
              </div>
            </div><p>
              The running list below consists of papers that highlight reproducibility failures or pitfalls in ML-based science. We find 20 papers from 17 fields where errors have been found, collectively affecting 329 papers and in some cases leading to wildly overoptimistic conclusions. In each case, data leakage causes errors in the modeling process.
            </p><p>
              Data leakage has long been recognized as a leading cause of errors in ML applications. In formative work on leakage, <a href="https://dl.acm.org/doi/10.1145/2382577.2382579">Kaufman et al.</a> provide an overview of different types of errors and give several recommendations for mitigating these errors. Since this paper was published, the ML community has investigated the impact of leakage in <a href="https://medium.com/@colin.fraser/the-treachery-of-leakage-56a2d7c4e931">several</a> <a href="http://www.rayidghani.com/2020/01/24/top-10-ways-your-machine-learning-models-may-have-leakage/">engineering applications</a> and modeling competitions. However, leakage occurring in ML-based science has not been comprehensively investigated. As a result, mitigations for data leakage in scientific applications of ML remain understudied.
            </p><p>

            A taxonomy of data leakage can enable a better understanding of why leakage occurs in ML-based science and inform potential solutions. We present a fine-grained taxonomy of 8 types of leakage that range from textbook errors to open research problems. Our taxonomy is comprehensive and addresses data leakage arising during the data collection, pre-processing, modeling and evaluation steps. In particular, our taxonomy addresses all cases of data leakage that we found in our survey. We provide an overview of the types of leakage here, a more detailed taxonomy is included in<a href="https://arxiv.org/abs/2207.07048"> our paper</a>.
            </p></div>
  </body>
</html>
