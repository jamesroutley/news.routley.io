<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.cyberdemon.org/2023/06/27/file-writes.html">Original</a>
    <h1>How does Linux handle writes?</h1>
    
    <div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p>My friends – programmers and operators – I would like to talk to you about the way that file writes work in Linux.</p>

<p>I used to think they worked a certain way, and like John Lennon, I’m not the only one. It turns out that they work very differently. The way they really work is interesting, and important to know.</p>

<p>Let us begin by stating the way I used to think file writes worked.</p>

<ol>
  <li>you <code>echo &#34;foo&#34; &gt; bar.txt</code></li>
  <li>(microseconds later) boom, done. “foo” has been written to disk.</li>
</ol>

<p>I thought it worked this way because I thought that files lived on disk, so if you wrote to a file, you were writing to disk.</p>

<p>It does not work this way, and the above mental model, about files living on disk, is wrong.</p>

<p>Let’s start by showing why that mental model is wrong.</p>

<h2 id="files-dont-live-on-disk">Files don’t live on disk</h2>

<p>It’s reasonable to think that files live on disk, because files are what we interact with in order to write stuff to disk.</p>

<p>But, that’s exactly it: a file is an <em>interface</em>. The operating system uses this interface so that we can tell it what we want.</p>

<p>This is kind of theoretical, so let me say it again: files are an interface, much like a OOP instance with methods and attributes. The file is not the stuff on disk. It’s just the abstract interface for it.</p>

<p>What <em>does</em> live on disk, then? Bytes.</p>

<h2 id="bytes-live-on-disk">Bytes live on disk</h2>

<p>A disk is just a bag of bytes. These bytes have a structure, of course. If they didn’t, they would be random, and we would have no way to ever make sense of them. The specific way we order bytes on disk is called an <em>inode</em>. An <em>inode</em> is what we end up representing using a <em>file</em>.</p>

<p>One way to think of an inode is the same way you think of a jpeg: it’s a way to order bytes in a certain way. For example, an inode specifies that at a certain location in your bag of bytes, you put the file size. At another location, you put when the file was created.</p>

<p>Why don’t we just interact with the inodes directly, then?</p>

<h2 id="why-we-use-interfaces">Why we use interfaces</h2>

<p>You <em>can</em> directly write to disk. You need to know exactly where to write, and you need to write the bytes directly. The chance of errors is really high.</p>

<p>Instead, it’s much nicer to just ask the operating system to do it. That way, we can focus on our own applications.</p>

<p>So, that’s one reason we use interfaces: to abstract away stuff we don’t want to do.</p>

<p>The other big reason is efficiency. By delegating disk access to the operating system, we give the operating system programmers permission to make a lot of efficient choices.</p>

<h2 id="disks-are-slow">Disks are slow</h2>

<p>Let’s go back to this statement.</p>

<ol>
  <li>you <code>echo &#34;foo&#34; &gt; bar.txt</code></li>
  <li>(microseconds later) boom, done. “foo” has been written to disk.</li>
</ol>

<p>This is totally false. If it were true, computers would feel terribly slow. Disks are sloooow.</p>

<p>How slow? Fetching a small amount of data from SSD is 1,000 times slower than memory. Fetching that same data from a spinning hard drive is one MILLION times slower. Disk access is multiple orders of magnitude slower than memory access!</p>

<p>Consider that, before SSDs, disks were the last mechanical thing about computers (other than fans). In a world of speedy electron-pushing, we were <em>actually pushing atoms</em>. The disparity in speed between the electrical and mechanical world is huge.</p>

<p>So, operating systems do what they can to shield applications from this slowness.</p>

<p>How do they do it?</p>

<h2 id="how-do-writes-actually-work">How do writes actually work?</h2>

<p>Here’s how the write really works.</p>

<ol>
  <li>you <code>echo &#34;foo&#34; &gt; bar.txt</code></li>
  <li>the operating system copies “foo” into a special place in memory called the <em>page cache</em></li>
  <li>(microseconds later) the operating system tells you the write succeeded</li>
  <li>(asynchronously, up to 30 seconds later) the operating system actually writes “foo” to disk</li>
</ol>

<p>If your mental model was “files live on disk”, the above is shocking. I mean, I used to think that the disk write happened immediately, but actually it can happen 30 seconds later!</p>

<h2 id="why-the-asynchronicity">Why the asynchronicity?</h2>

<p>Let’s say that you made a photo sharing app with Like buttons. Photo Likes <em>are</em> stored in a database. However, if you personally were designing this app, would you…</p>

<ol>
  <li>Make the Like heart appear as soon as the user clicks the Like button?</li>
  <li>Make the Like heart appear only once the Like has been persisted to disk?</li>
</ol>

<p>You would go with option 1, of course, because UI responsiveness is really important.</p>

<p>This is an example of shielding a user from a slow operation via <em>asynchronicity</em>: you tell the user you did it, but actually, you do it later when they’re not looking.</p>

<p>Linux does something similar. It shields the application from disk slowness by simply doing the disk write later. This is called non-blocking IO: don’t make the application wait for slow disks.</p>

<p>This isn’t the only reason the write is asynchronous, though.</p>

<h2 id="buffering-also-makes-disk-writes-faster">Buffering also makes disk writes faster</h2>

<p>Say this three times fast: asynchronicity enables buffering.</p>

<p>I want to explore this deeply some day, but I’m amazed how frequently I find buffers and queues in computer science. It’s not like they’re secret, but they more central to efficient computing than I ever knew.</p>

<p>Queues and buffers make disk writes efficient, too.</p>

<p>For example, every disk write has overhead. Given that overhead, we would rather do one big write of 1 megabyte than 100 little writes of 10 kilobytes each. Buffering disk writes allows the operating system to merge those little writes into bigger writes.</p>

<p>Because the operating system decouples the file write from the actual disk write, if you do a bunch of file writes quickly, they will bunch up into a little queue. The operating system can then merge them.</p>

<p>There are actually way, way more tricks that the operating system does to writes to make them performant, all of them enabled by this asynchronicity. Perhaps I’ll cover them in another article, but if you are dying to know, I highly recommend the File System and Disk chapters of Gregg’s Systems Performance.</p>

<p>Anyway, we understand now that asynchronous disk writes give us a huge speed boost, but there’s an elephant in the room: at what cost?</p>

<h2 id="the-tradeoff-between-efficiency-and-durability">The tradeoff between efficiency and durability</h2>

<p>What happens if you unplug your computer before the operating system writes the data to disk? Well, you will lose the data. It’s as simple as that.</p>

<p>I’d love to find a discussion where the decision was deliberately made, but it’s also kind of a no-brainer: until recently, disk writes were a million times slower than memory access. Of course the default would be to make writes asynchronous.</p>

<p>What if we do want to make our writes durable, though?</p>

<h2 id="o_sync-and-sync-making-writes-durable"><code>O_SYNC</code> and <code>sync</code>: making writes durable</h2>

<p>While I found the fact that writes are asynchronous surprising, many programmers, certainly database programmers, know this well.</p>

<p>There are many ways to make writes durable. I’ll cover two of them.</p>

<h3 id="sync-syscall"><code>sync</code> syscall</h3>

<p>There’s a system call called <code>sync</code>, which you can call at any time. It says: operating system, dump everything from page cache to disk NOW! And the operating system will do it. You can even put that command into your shell right now just to try it.</p>

<p>In programs, you will often see a series of writes interspersed with <code>sync</code> calls. Like, every <code>n</code> writes, there will be a <code>sync</code> call. This allows applications to finely tune the tradeoff between durability and write throughput.</p>

<h3 id="o_sync-file-mode"><code>O_SYNC</code> file mode</h3>

<p>Programmers can also open a file in <code>O_SYNC</code> mode. This works much closer to the mental model at the beginning of this article: the write only completes once the data has been persisted to disk.</p>

<h2 id="demonstrating-async-writes">Demonstrating async writes</h2>

<p>Time for a little science demonstration. I’m going to write to a file. I’m going to read from that file. I will show you that both operations will complete seconds before the disk is accessed.</p>

<p>This is what I’m going to paste into my shell, all at once.</p>

<div><div><pre><code>echo &#34;foo&#34; &gt; example.txt
dd if=example.txt
</code></pre></div></div>

<p>And here is the output of <code>bpftrace</code>, which allows us to trace kernel events.</p>

<p>Specifically, we are going to trace when <code>vfs_read</code> and <code>vfs_write</code> finish (all you need to know is that those are the functions that are called when we read and write a file). We will also trace <code>block_rq_issue</code>, which is called when the disk driver actually writes to disk.</p>

<div><div><pre><code># write starts
11:32:05 kfunc:vmlinux:vfs_write

# write finishes
11:32:05 kretfunc:vmlinux:vfs_write

# read starts
11:32:05 kfunc:vmlinux:vfs_read

# read finishes
11:32:05 kretfunc:vmlinux:vfs_read

# **5 seconds later** we actually write &#34;foo&#34; to disk!
11:32:10 tracepoint:block:block_rq_issue
</code></pre></div></div>

<p>Note that we never even read disk, even though we read the file. That’s because the read came from the page cache!</p>

<h2 id="conclusion">Conclusion</h2>

<p>I hope I helped make your mental model of file writes more subtle. Files don’t live on disk, bytes do. Files merely represent those bytes. This misdirection makes programming easier, and allows the operating system to shield our fast applications from slow disks.</p>

<p>There is a lot more to this subject – the difference between file IO and disk IO is even more profoundly different than I let on. For example, if you write 1 byte to a file, how much will get written to disk? Would you be surprised if I told you that that 1 byte write causes 65 THOUSAND bytes to get written to disk? If that’s interesting to you, I urge you to subscribe to this blog. More stuff like this is coming.</p>

<p>Thanks for reading.</p>

<h2 id="ps-im-looking-for-a-linux-job">PS: I’m looking for a Linux job</h2>

<p>I’ve had a happy career as a cloud-based SRE. Most recently, I ran the infrastructure team at Rollbar. But, now, I want to work more directly with Linux. I’m London-based and am interviewing for Linux engineering and/or HPC jobs. If you have any leads, reach out! I’m happy to share my CV. Thanks!</p>

    
  </div></div>
  </body>
</html>
