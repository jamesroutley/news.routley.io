<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.poisson.chat/posts/2024-07-26-adt-history.html">Original</a>
    <h1>Where does the name &#34;algebraic data type&#34; come from?</h1>
    
    <div id="readability-page-1" class="page"><div>
      

      <p>
    
    Posted on July 26, 2024
    
    
</p>

<p>“Algebraic data types” is a beloved feature of programming languages with
such a mysterious name. Where does this name come from?</p>
<p>There are two main episodes in this saga: Hope and Miranda.
The primary conclusion is that the name comes from universal algebra,
whereas another common interpretation of “algebraic” as a reference
to “sums of products” is not historically accurate.
We drive the point home with Clear. CLU is extra.</p>
<p>Disclaimer: I’m no historian and I’m nowhere as old as these languages
to have any first-hand perspective.
Corrections and suggestions for additional information are welcome.</p>
<section id="toc">
<h3>Table of contents</h3>
<ul>
<li><a href="#hope-1980hope" title="hope-1980hope">Hope (<span>1980</span>)</a></li>
<li><a href="#miranda-1985miranda" title="miranda-1985miranda">Miranda (<span>1985</span>)</a></li>
<li><a href="#sums-of-products" title="sums-of-products">Sums of products?</a></li>
<li><a href="#clear-1979clear" title="clear-1979clear">Clear (<span>1979</span>)</a></li>
<li><a href="#clu-1977clu-intro" title="clu-1977clu-intro">CLU (<span>1977</span>)</a></li>
</ul>
</section>
<h2 id="hope-1980hope">Hope (<a href="https://homepages.inf.ed.ac.uk/dts/pub/hope.pdf">1980</a>)</h2>
<p>Algebraic data types were at first simply called “data types”.
This programming language feature is commonly attributed to
<a href="https://homepages.inf.ed.ac.uk/dts/pub/hope.pdf">Hope, an experimental applicative language</a> by Rod Burstall et al..
Here is the relevant excerpt from the paper, illustrating its concrete syntax:</p>
<blockquote>
<p>A <em>data declaration</em> is used to introduce a new data type along with
the data constructors which create elements of that type. For example,
the data declaration for natural numbers would be:</p>
<pre><code>data num == 0 ++ succ(num)</code></pre>
<p>(…) To define a type ‘tree of numbers’, we could say</p>
<pre><code>data numtree == empty ++ tip(num)
                      ++ node(numtree#numtree)</code></pre>
<p>(The sign <code>#</code> gives the cartesian product of types).
One of the elements of <code>numtree</code> is:</p>
<pre><code>node(tip(succ(0)),
     node(tip(succ(succ(0))), tip(0)))</code></pre>
<p>But we would like to have trees of lists and trees of trees as well,
without having to redefine them all separately. So we declare a
<em>type variable</em></p>
<pre><code>typevar alpha</code></pre>
<p>which when used in a type expression denotes any type
(including second- and higher-order types).
A general definition of <code>tree</code> as a parametric type is now possible:</p>
<pre><code>data tree(alpha) == empty ++ tip(alpha)
                          ++ node(tree(alpha)#tree(alpha))</code></pre>
Now <code>tree</code> is not a type but a unary <em>type constructor</em> – the type
<code>numtree</code> can be dispensed with in favour of <code>tree(num)</code>.
</blockquote>
<p>Pattern matching in Hope is done in multi-clause function declarations or multi-clause lambdas.
There was no <code>case</code> expression.</p>
<blockquote>
<pre><code>reverse(nil) &lt;= nil
reverse(a::l) &lt;= reverse(l) &lt;&gt; [a]</code></pre>
<pre><code>lambda true, p =&gt; p
     | false, p =&gt; false</code></pre>
</blockquote>
<p>As far as I can tell, other early programming languages cite Hope or one of its descendants
as their inspiration for data types.
There is a slightly earlier appearance in NPL by Darlington and the same Burstall,
but I couldn’t find a source describing the language or any samples of data type declarations.
Given the proximity, it seems reasonable to consider them the same language to a large extent.
<a href="https://dl.acm.org/doi/10.1145/321992.321996">This paper</a> by Burstall and Darlington (1977) seems to be using NPL
in its examples, but data types are only introduced informally;
see on page 62 (page 19 of the PDF):</p>
<blockquote>
<p>We need a data type <code>atom</code>, from which we derive a data type <code>tree</code>, using constructor
functions <code>tip</code> to indicate a tip and <code>tree</code> to combine two subtrees</p>
<pre><code>tip : atoms → trees
tree : trees x trees → trees</code></pre>
<p>We also need lists of atoms and of trees, so for any type <code>alpha</code> let</p>
<pre><code>nil : alpha-lists
cons : alphas x alpha-lists → alpha-lists</code></pre>
</blockquote>
<p>Hope inspired ML (OCaml’s grandpa) to adopt data types. In Standard ML:</p>
<pre><code>datatype &#39;a option = Nothing | Some of &#39;a</code></pre>
<p>Before it became Standard, ML started out as the “tactic language” of the
<a href="https://en.wikipedia.org/wiki/Logic_for_Computable_Functions">LCF proof assistant</a>
by Robin Milner, and early versions did not feature data types
(see <a href="https://github.com/theoremprover-museum/LCF77">the first version of Edinburgh LCF</a>).
it’s unclear when data types were added exactly, but
<a href="https://smlfamily.github.io/sml97-defn.pdf">The Definition of Standard ML</a>
by Milner et al. credits Hope for it (in Appendix F: The Development of ML):</p>
<blockquote>
Two movements led to the re-design of ML. One was the work of Rod Burstall
and his group on specifications, crystallised in the specification language
Clear and in the functional programming language Hope; the
latter was for expressing executable specifications. The outcome of this work
which is relevant here was twofold. First, there were elegant programming
features in Hope, particularly pattern matching and clausal function definitions;
second, there were ideas on modular construction of specifications,
using signatures in the interfaces. A smaller but significant movement was
by Luca Cardelli, who extended the data-type repertoire in ML by adding
named records and variant types.
</blockquote>
<h2 id="miranda-1985miranda">Miranda (<a href="https://www.cs.kent.ac.uk/people/staff/dat/miranda/nancypaper.pdf">1985</a>)</h2>
<p>“Data types” as a programming language feature appeared in Hope,
but its first mention under the name “algebraic data types” that I could find is in
<a href="https://www.cs.kent.ac.uk/people/staff/dat/miranda/nancypaper.pdf">Miranda: a non-strict functional language with polymorphic types</a>
by David Turner in 1985:</p>
<blockquote>
<h3 id="algebraic-data-types">Algebraic data types</h3>
<p>The basic method of introducing a new concrete data type, as in a number of
other languages, is to declare a free algebra. In Miranda this is done by an
equation using the symbol <code>::=</code>,</p>
<pre><code>tree ::= Niltree | Node num tree tree</code></pre>
being a typical example. (…)
The idea of using free algebras to define data types has a long and respectable
history [Landin 64], [Burstall 69], [Hoare 75]. We call it a free algebra, because
there are no associated laws, such as a law equating a tree with its mirror image.
Two trees are equal only if they are constructed in exactly the same way.
</blockquote>
<p>In case you aren’t aware, Miranda is a direct precursor of Haskell.
A minor similarity with Haskell that we can see here
is that data constructors are curried in Miranda, unlike in Hope and ML.
Another distinguishing feature of Miranda is laziness.
See also <a href="https://www.microsoft.com/en-us/research/wp-content/uploads/2016/07/history.pdf">A History of Haskell: being lazy with class</a>.</p>
<p>Below are links to the articles cited in the quote above.
The first [Landin 64] doesn’t explicitly talk about algebra in
this sense, while [Burstall 69] and [Hoare 75] refer to “word algebra” rather than
“free algebra” to describe the same structure, without putting “algebra” in the
same phrase as “type” yet.</p>
<ul>
<li><a href="https://www.cs.tufts.edu/comp/150FP/archive/peter-landin/mechanical-eval.pdf">The mechanical evaluation of expression</a>, by Peter Landin (1964)</li>
<li><a href="https://www.cse.chalmers.se/edu/year/2016/course/course/DAT140/Burstall.pdf">Proving properties by structural induction</a>, by Rod Burstall (1969)</li>
<li><a href="https://apps.dtic.mil/sti/pdfs/AD0772509.pdf">Recursive data structures</a> by Tony Hoare (1975)</li>
</ul>
<p>Hoare’s paper contains some futuristic pseudocode in particular:</p>
<blockquote>
<p>A possible notation for such a type definition was
suggested by Knuth; it is a mixture of BNF (the <code>|</code> symbol) and the
PASCAL definition of a type by enumeration:</p>
<pre><code>type proposition = (prop (letter) | neg (proposition) |
                   conj, disj (proposition, proposition));</code></pre>
<p>(…)
In defining operations on a data structure, it is usually necessary
to enquire which of the various forms the structure takes, and what are
its components. For this, I suggest an elegant notation which has been
implemented by Fred McBride in his pattern-matching LISP. Consider
for example a function intended to count the number of <code>&amp;</code>s contained in
a proposition. (…)</p>
<pre><code>function andcount (p: proposition): integer;
  andcount := cases p of
    (prop(c) → 0|
     neg(q) → andcount(q)|
     conj(q,r) → andcount(q) + andcount(r)+1|
     disj(q,r) → andcount(q) + andcount(r));</code></pre>
</blockquote>
<p>Fred McBride’s pattern-matching LISP is the topic of
<a href="https://personal.cis.strath.ac.uk/conor.mcbride/FVMcB-PhD.pdf">his PhD dissertation</a>.
There is not enough room on this page to write about the groundbreaking history of LISP.</p>
<h3 id="unfree-algebras-in-miranda">Unfree algebras in Miranda</h3>
<p>If algebraic data types are “free algebras”,
one may naturally wonder whether “unfree algebras” have a role to play.
Miranda allows quotienting data type definitions by equations (“laws” or “rewrite rules”).
You could then define the integers like this, with a constructor
to decrement numbers, and equations to reduce integers to a canonical representation:</p>
<pre><code>int ::= Zero | Suc int | Pred int
Suc (Pred n) =&gt; n
Pred (Suc n) =&gt; n</code></pre>
<p>In hindsight this is superfluous, but it’s fun to see this kind of
old experiments in programming languages.
The modern equivalent in Haskell would be to hide the data constructors
and expose smart constructors instead.
There are uses for quotient types in proof assistants and dependently
typed languages, but they work quite differently.</p>
<h2 id="sums-of-products">Sums of products?</h2>
<p>There is another folklore interpretation of “algebraic” in “algebraic data types”
as referring to “sums of products”.</p>
<p>It’s not an uncommon interpretation. In fact, trying to find a source for
this folklore is what got me going on this whole adventure.
The <a href="https://en.wikipedia.org/wiki/Algebraic_data_type">Wikipedia article on algebraic data types</a>
at the time of writing doesn’t outright say it, but it does refer to sums and
products several times while making no mention of free algebras.
Some [citation needed] tags should be sprinkled around.
The Talk page of that article contains an unresolved discussion of this issue, with links to
<a href="https://stackoverflow.com/questions/16770/haskells-algebraic-data-types/5917133#5917133">a highly upvoted SO answer</a>
and <a href="https://stackoverflow.com/questions/5911267/what-are-sums-and-products-data-structures/5914867#5914867">another one</a>
whose references don’t provide first-hand account of the origins of the term.
For sure, following that idea leads to some <a href="http://ozark.hendrix.edu/~yorgey/pub/thesis.pdf">fun combinatorics</a>,
like <a href="https://personal.cis.strath.ac.uk/conor.mcbride/Dissect.pdf">differentiation on data types</a>,
but that doesn’t seem to have been the original meaning of “algebraic data types”.</p>
<p>That interpretation might have been in some people’s mind in the 70s and 80s,
even if only as a funny coincidence, but I haven’t found any written evidence of
it except maybe this one sentence in a later paper,
<a href="https://www.cs.kent.ac.uk/people/staff/dat/tfp12/tfp12.pdf">Some history of programming languages</a> by David Turner (2012):</p>
<blockquote>
The ISWIM paper also has the first appearance of algebraic type definitions
used to define structures. This is done in words, but the sum-of-products idea is
clearly there.
</blockquote>
<p>It’s only a “maybe” because while the phrase “algebraic type” undeniably refers to
sums of products, it’s not clear that the adjective “algebraic” specifically is
meant to be associated with “sum-of-products” in that sentence. We
could replace “algebraic type” with “data type” without changing the meaning
of the sentence.</p>
<h2 id="clear-1979clear">Clear (<a href="https://dl.acm.org/doi/10.5555/647448.727240">1979</a>)</h2>
<p>In contrast, free algebras—or initial algebras as one might prefer to call them—are
a concept from the areas of universal algebra and category theory with
a well-established history in programming language theory by the time
algebraic data types came around, with influential contributions by a certain
<a href="https://www.pls-lab.org/en/ADJ_group">ADJ group</a>;
see for example <a href="https://dl.acm.org/doi/10.1145/321992.321997">Initial algebra semantics and continuous algebras</a>.</p>
<p>Ironically, much related work focused on the other ADT, “abstract data types”.
Using universal algebra as a foundation, a variety of “specification languages” have
been designed for defining algebraic structures, notably the <a href="https://en.wikipedia.org/wiki/OBJ_(programming_language)">OBJ</a> family
of languages created by Joseph Goguen (a member of the aforementioned ADJ group) and others,
and the Clear language by Rod Burstall (of Hope fame) and Joseph Goguen.
Details of the latter can be found in <a href="https://dl.acm.org/doi/10.5555/647448.727240">The Semantics of Clear, a specification language</a>.
(You may remember seeing a mention of Clear earlier
in the quote from The Definition of Standard ML.)</p>
<h3 id="example-theories-in-clear">Example theories in Clear</h3>
<p>Here is the theory of monoids in Clear. It consists of one sort named <code>carrier</code>,
an element (a nullary operation) named <code>empty</code> and a binary operation <code>append</code>.</p>
<pre><code>constant Monoid = theory
                      sorts carrier
                      opns empty : carrier
                           append : carrier,carrier -&gt; carrier
                      eqns all x: carrier . append(x,empty) = x
                           all x: carrier . append(empty,x) = x
                           all x,y,z: carrier . append(append(x,y),z) = append(x,append(y,z))
                  endth</code></pre>
<p>A theory is an interface. Its implementations are called algebras.
In that example, the algebras of “the theory of monoids” are exactly monoids.</p>
<p>In every theory, there is an <em>initial algebra</em> obtained by turning the
operations into constructors (or “uninterpreted operations”), equating elements
(which are trees of constructors) modulo the equations of the theory.
For the example above, the initial monoid is a singleton monoid, with only an empty element
(all occurrences of <code>append</code> are simplified away by the two equations for <code>empty</code>),
which is not very interesting. Better examples are those corresponding to the usual data types.</p>
<p>The booleans can be defined as the initial algebra of the theory with one sort (<code>truthvalue</code>)
and two values of that sort, <code>true</code> and <code>false</code>.</p>
<pre><code>constant Bool = theory data
                    sorts truthvalue
                    opns true,false: truthvalue
                endth</code></pre>
<p>In Clear, the initial algebra is specified by adding the <code>data</code> keyword to a <code>theory</code>.
In the semantics of Clear, rather than thinking in terms of a specific algebra,
a “data theory” is still a theory (an interface),
with additional constraints that encode “initiality”, so the only possible
algebra (implementation) is the initial one.
My guess as to why the concept of data theory is set up that way
is that it allows plain theories and data theories to be combined seamlessly.</p>
<p>The natural numbers are the initial algebra of <code>zero</code> and <code>succ</code>:</p>
<pre><code>constant Nat = theory data
                   sorts nat
                   opns zero: nat
                        succ: nat -&gt; nat
               endth</code></pre>
<p>At this point, the connection between “data theories” in Clear and data types
in Hope and subsequent languages is hopefully clear.</p>
<h3 id="more-substantial-examples-in-clear">More substantial examples in Clear</h3>
<p>Theories can be extended into bigger theories with new sorts, operations, and equations.
Here is an extended theory of booleans with two additional operations <code>not</code>, <code>and</code>,
and their equations. This should demonstrate that, beyond the usual mathematical structures,
we can define non-trivial operations in this language:</p>
<pre><code>constant Bool1 = enrich Bool by
                     opns not: truthvalue -&gt; truthvalue
                          and: truthvalue,truthvalue -&gt; truthvalue
                     eqns all . not true = false
                          all . not false = true
                          all p: truthvalue . and(false, p) = false
                          all p: truthvalue . and(true, p) = p
                 enden</code></pre>
<p>Initial algebras are also called free algebras, but that gets confusing because
“free” is an overloaded word. Earlier for instance, you might have expected the initial
monoid, or “free monoid”, to be the monoid of lists. The monoid of lists is the
initial algebra in a slightly different theory: the theory of monoids with an
embedding from a fixed set of elements <code>A</code>.</p>
<p>We might formalize it as follows in Clear.
The theory <code>List</code> is parameterized by an algebra <code>A</code> of the theory <code>Set</code>,
and its body is the same as <code>Monoid</code>, except that we renamed <code>carrier</code> to <code>list</code>,
we added an <code>embed</code> operation, and we added the <code>data</code> keyword to restrict that
theory to its initial algebra.</p>
<pre><code>constant Set = theory sorts element endth
procedure List(A : Set) = theory data
                              sorts list
                              opns empty : list
                                   append : list,list -&gt; list
                                   embed : element of A -&gt; list
                              eqns all x: list . append(x,empty) = x
                                   all x: list . append(empty,x) = x
                                   all x,y,z: list . append(append(x,y),z) = append(x,append(y,z))
                          endth</code></pre>
<p>One may certainly see a resemblance between theories in Clear, modules in ML,
and object-oriented classes.
It’s always funny to find overlaps between the worlds of functional and
object-oriented programming.</p>
<h2 id="clu-1977clu-intro">CLU (<a href="https://dl.acm.org/doi/10.1145/359763.359789">1977</a>)</h2>
<p>CLU is a programming language created at MIT by Barbara
Liskov and her students in the course of their work on data abstraction.</p>
<p>It features tagged union types, which are called “oneof types”.
(Source: <a href="https://pmg.csail.mit.edu/ftp.lcs.mit.edu/pub/pclu/CLU/3.Documents/MIT-LCS-TR-225.pdf">CLU Reference Manual</a> by Barbara Liskov et al. (1979).)</p>
<pre><code>T = oneof[empty:       null,
          integer:     int,
          real_num:    real,
          complex_num: complex]</code></pre>
<p>Values are constructed by naming the oneof type (either as an identifier bound to it,
or by spelling out the <code>oneof</code> construct) then the tag prefixed by <code>make_</code>:</p>
<pre><code>T$make_integer(42)</code></pre>
<p>The <code>tagcase</code> destructs “oneof” values.</p>
<pre><code>x: oneof[pair: pair, empty: null]
...
tagcase x
    tag empty: return(false)
    tag pair(p: pair): if (p.car = i)
                       then return(true)
                       else x := down(p.cdr)
                       end
end</code></pre>
<p>The main missing feature for parity with algebraic data types is recursive type
definitions, which are not allowed directly. They can be achieved indirectly
though inconveniently through multiple clusters (classes in modern terminology).
(Source: <a href="https://pmg.csail.mit.edu/ftp.lcs.mit.edu/pub/pclu/CLU/3.Documents/clu-history.PDF">A History of CLU</a> by Barbara Liskov (1992).)</p>
<p>Burstall’s papers on Hope and Clear cite CLU, but beyond that it doesn’t
seem easy to make precise claims about the influence of CLU, which is an object-oriented language,
on the evolution of those other declarative languages developed across the pond.</p>

    </div></div>
  </body>
</html>
