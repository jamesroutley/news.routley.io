<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://parti.research.google/">Original</a>
    <h1>Pathways Autoregressive Text-to-Image Model (Parti)</h1>
    
    <div id="readability-page-1" class="page"><div>
    <div>
      <div>
        
        <p>
          As we discuss at greater length in the paper, text-to-image models introduce many opportunities and risks, with potential impact on bias and safety, visual communication, disinformation, and creativity and art. Similar to
          <a href="https://imagen.research.google/">Imagen</a>,
          we recognize there is a risk that Parti may encode harmful stereotypes and representations. Some potential risks relate to the way in which the models are themselves developed, and this is especially true for the training data. Current models like Parti are trained on large, often noisy, image-text datasets that are known to contain biases regarding people of different backgrounds. This leads such models, including Parti, to produce stereotypical representations of, for example, people described as lawyers, flight attendants, homemakers, and so on, and to reflect Western biases for events such as weddings. This presents particular problems for people whose backgrounds and interests are not well represented in the data and the model, especially if such models are applied to uses such as visual communication, e.g. to help low-literacy social groups. Models which produce photorealistic outputs, especially of people, pose additional risks and concerns around the creation of deepfakes. This creates risks with respect to the possible propagation of visually-oriented misinformation, and for individuals and entities whose likenesses are included or referenced.
          <!-- Many broader issues should be considered with large-scale models for text-to-image generation, such as:
          <ul>
            <li>Development process issues like the use of large, mostly uncurated training datasets of images obtained from the web with little oversight.</li>
            <li>Conceptual vagueness of constructs in task formulation.</li>
            <li>The role of large text-to-image models as “foundation” models that act as a form of infrastructure for a range of system applications and fine-tuning for image generation tasks, shaping our conceptions of what is both possible and desirable.</li>
          </ul>
          <br>
          It is difficult (if not impossible) to predict all possible uses and consequences of infrastructure, so following responsible AI practices that emphasize transparently documenting and sharing information about datasets and models is essential.
          Text-to-image generation models could potentially have an impact on creativity and art, visual communication, disinformation (including deepfakes), and bias and safety. Considerations for this potential impact contribute to our decision not to release our models, code, or data at this time.
          <br>
          <br>
          Instead, we will focus on following this work with further careful model bias measurement and mitigation strategies, such as prompt filtering, output filtering, and model recalibration. We believe it may be possible to use text-to-image generation models to understand biases in large image-text datasets at scale, by explicitly probing them for a suite of known bias types, and potentially uncovering other forms of hidden bias.
          <br>
          <br>
          We also plan to coordinate with artists to adapt high-performing text-to-image generation models’ capabilities to their work, for purely creative ends or art-for-hire. This is especially important given the intense interest among many research groups, and the rapid development of models and data to train them.
          Ideally, we hope these models will augment human creativity and productivity, not replacing it, so that we can all enjoy a world filled with new, varied, and responsible aesthetic visual experiences.
          <br> -->
          
          
          <!-- <a href="#" class="button black-on-white">Model card</a> -->
          
          
          
        </p>
        
        <p>
          Parti is a collaboration that spans authors across multiple <a href="https://research.google/">Google Research</a> teams:
          </p>
        <!-- <br>
        <br>
        <pre style="font-family: Courier; line-height: 1.0;">
@article{key ,
   author = {Arthur B Cummings and David Eftekhary and Frank G House},
   title = {The accurate determination of college students’
   coefficients of friction},
   journal = {Journal of Sketchy Physics},
   volume = {13},
   year = {2003},
   number = {2},
   pages = {46--129}
}
       </pre> -->
      </div>
    </div>
  </div></div>
  </body>
</html>
