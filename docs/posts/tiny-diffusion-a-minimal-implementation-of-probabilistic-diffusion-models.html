<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/tanelp/tiny-diffusion">Original</a>
    <h1>Tiny-diffusion: A minimal implementation of probabilistic diffusion models</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto">A minimal PyTorch implementation of probabilistic diffusion models for 2D datasets. Get started by running <code>python ddpm.py -h</code> to explore the available options for training.</p>

<p dir="auto">A visualization of the forward diffusion process being applied to a dataset of one thousand 2D points. Note that the dinosaur is not a single training example, it represents each 2D point in the dataset.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/tanelp/tiny-diffusion/blob/master/static/forward.png"><img src="https://github.com/tanelp/tiny-diffusion/raw/master/static/forward.png" alt=""/></a></p>

<p dir="auto">This illustration shows how the reverse process recovers the distribution of the training data.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/tanelp/tiny-diffusion/blob/master/static/reverse.png"><img src="https://github.com/tanelp/tiny-diffusion/raw/master/static/reverse.png" alt=""/></a></p>

<p dir="auto">I have run a series of ablations experiments on hyperparameters, such as learning rate and model size, and visualized the learning process. The columns in the graphs represent the checkpoint epoch, and the rows indicate the hyperparameter values. Each cell displays one thousand generated 2D points.</p>

<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/tanelp/tiny-diffusion/blob/master/static/learning_rate.png"><img src="https://github.com/tanelp/tiny-diffusion/raw/master/static/learning_rate.png" alt=""/></a></p>
<p dir="auto">The learning process is sensitive to the learning rate. At first, the model&#39;s output was poor, causing me to suspect a bug. However, simply changing the learning rate value resolved the problem.</p>

<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/tanelp/tiny-diffusion/blob/master/static/datasets.png"><img src="https://github.com/tanelp/tiny-diffusion/raw/master/static/datasets.png" alt=""/></a></p>
<p dir="auto">The current model configuration doesn&#39;t work well on the <code>line</code> dataset, which I consider the most basic among them. The corners should be clear and sharp, but they are fuzzy.</p>

<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/tanelp/tiny-diffusion/blob/master/static/num_timesteps.png"><img src="https://github.com/tanelp/tiny-diffusion/raw/master/static/num_timesteps.png" alt=""/></a></p>
<p dir="auto">A longer diffusion process results in a better output. With fewer timesteps, the dinosaur is incomplete, missing points from the top and bottom.</p>

<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/tanelp/tiny-diffusion/blob/master/static/beta_schedule.png"><img src="https://github.com/tanelp/tiny-diffusion/raw/master/static/beta_schedule.png" alt=""/></a></p>
<p dir="auto">The quadratic schedule does not yield better results. Other schedules like cosine or sigmoid should also be considered.</p>

<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/tanelp/tiny-diffusion/blob/master/static/hidden_size.png"><img src="https://github.com/tanelp/tiny-diffusion/raw/master/static/hidden_size.png" alt=""/></a></p>
<p dir="auto">The capacity of the model doesn&#39;t seem to be a bottleneck, as similar results are obtained across various hidden layer sizes.</p>

<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/tanelp/tiny-diffusion/blob/master/static/num_hidden_layers.png"><img src="https://github.com/tanelp/tiny-diffusion/raw/master/static/num_hidden_layers.png" alt=""/></a></p>
<p dir="auto">As in the hidden size ablation run, the capacity of the model does not seem to be a limiting factor.</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">positional embedding (timestep)</h3><a id="user-content-positional-embedding-timestep" aria-label="Permalink: positional embedding (timestep)" href="#positional-embedding-timestep"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/tanelp/tiny-diffusion/blob/master/static/time_embedding.png"><img src="https://github.com/tanelp/tiny-diffusion/raw/master/static/time_embedding.png" alt=""/></a></p>
<p dir="auto">The model benefits from the timestep information, but the specific method of encoding the timestep is not important.</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">positional embedding (inputs)</h3><a id="user-content-positional-embedding-inputs" aria-label="Permalink: positional embedding (inputs)" href="#positional-embedding-inputs"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/tanelp/tiny-diffusion/blob/master/static/input_embedding.png"><img src="https://github.com/tanelp/tiny-diffusion/raw/master/static/input_embedding.png" alt=""/></a></p>
<p dir="auto">The use of sinusoidal embeddings for the inputs helps with learning high-frequency functions in low-dimensional problem domains, such as mapping each (x, y) pixel coordinate to (r, g, b) color, as demonstrated in <a href="https://bmild.github.io/fourfeat/" rel="nofollow">this study</a>. The same holds true in the current scenario.</p>

<ul dir="auto">
<li>The dino dataset comes from the <a href="https://www.autodesk.com/research/publications/same-stats-different-graphs" rel="nofollow">Datasaurus Dozen</a> data.</li>
<li>HuggingFace&#39;s <a href="https://github.com/huggingface/diffusers">diffusers</a> library.</li>
<li>lucidrains&#39; <a href="https://github.com/lucidrains/denoising-diffusion-pytorch">DDPM implementation in PyTorch</a>.</li>
<li>Jonathan Ho&#39;s <a href="https://github.com/hojonathanho/diffusion">implementation of DDPM</a>.</li>
<li>InFoCusp&#39;s <a href="https://github.com/InFoCusp/diffusion_models">DDPM implementation in tf</a>.</li>
</ul>
</article></div></div>
  </body>
</html>
