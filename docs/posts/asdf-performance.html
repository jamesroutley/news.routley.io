<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="http://stratus3d.com/blog/2022/08/11/asdf-performance/">Original</a>
    <h1>Asdf Performance</h1>
    
    <div id="readability-page-1" class="page"><div id="main">
            <div id="content">
                <div>
<article role="article">
  
  <header>
    
      
    
    
      
    
  </header>


<div><p>I’ve been a maintainer of asdf for about 6 years now. Most of my work these last several years has been fixing bugs, writing automated tests to catch regressions, and ensuring overall correctness across various operating systems. Maintaining a tool written in Bash isn’t easy. For most things there are far more edge cases and compatibility issues than happy paths. Certain commands need to be  <a href="https://github.com/asdf-vm/asdf/blob/master/test/banned_commands.bats">banned from the codebase</a> to ensure compatibility across operating systems. <a href="http://redsymbol.net/articles/unofficial-bash-strict-mode/">Bash strict mode</a> also helps but it introduces <a href="http://stratus3d.com/blog/2019/11/29/bash-errexit-inconsistency/">other issues</a> that have to be worked around.</p>
<p>All this to say I haven’t had a lot of time to step back and assess the other aspects of asdf. Other maintainers have stepped up and helped with documentation and UX, but performance has fallen by the wayside. Over the last couple of months I’ve noticed some asdf commands that I use often seem to have gotten slower. Many asdf commands are fairly slow but with the way asdf was designed it is seldom a problem. <code>asdf current</code> was never fast enough to be used as part of a shell prompt showing the current versions, but that was user experience enhancement that wasn’t critical. But it seems like things are getting worse and I wanted to assess performance. In this post I am going to benchmark several asdf commands and see how their performance has changed over time.</p>
<div>
<h2 id="_performance-over-time">Performance Over Time</h2>
<div>
<p>I wanted to see how the performance of each command has changed over time since asdf was first released. This can be done by checking out each release tag of asdf with Git, benchmarking each command on that tag and then writing the results to disk, before proceeding to the next tag. Once the benchmarking data is written to disk it can be used to generate graphs of the performance changes over time. There isn’t a tool that does all this so I had to write a Bash script.</p>
<p>For the actual benchmarking I like <a href="https://github.com/sharkdp/hyperfine">hyperfine</a>, and it exports results to CSV and JSON so it was perfect for this. All I had to do was write a Bash script that wires up <code>git for-each-ref</code> and <code>git checkout</code> and then runs <code>hyperfine</code> for each command on each version. The <a href="http://stratus3d.com/downloads/asdf-performance/benchmark_all_tags">resulting shell script is attached</a>. Gathering the data with this benchmarking script is straightforward.</p>
</div>
</div>
<div>
<h2 id="_what-sub-commands-to-benchmark">What Sub-Commands to Benchmark</h2>
<div>
<p>Some commands are important, used often, and expected to be fast. These commands are:</p>
<div>
<ul>
<li>
<p><code>asdf current</code> - print the versions specified for the current directory</p>
</li>
<li>
<p><code>asdf which</code> - print the path of the actual executable that a shim resolves to</p>
</li>
<li>
<p><code>asdf where</code> - print the install directory of a tool</p>
</li>
<li>
<p><code>asdf exec</code> - execute a shim (almost the same as executing a shim directly)</p>
</li>
</ul>
</div>
<p>I benchmarked all of these commands.</p>
<p>Some commands are expected to be relatively slow and take at least a second or two to finish. These commands are:</p>
<div>
<ul>
<li>
<p><code>asdf install &lt;tool&gt; &lt;version&gt;</code> - install a tool version</p>
</li>
<li>
<p><code>asdf plugin add &lt;name&gt; &lt;repo&gt;</code> - install a plugin</p>
</li>
<li>
<p><code>asdf reshim</code> - re-generate all shims</p>
</li>
</ul>
</div>
<p>Of these three commands I’ve only received complaints about the performance of <code>asdf reshim</code>. It is by far the slowest of all asdf commands so I benchmarked it. <code>asdf install</code> is often slow as well, but its performance is tied to the plugin’s install script and isn’t controlled by asdf so I skipped it.</p>
</div>
</div>
<div>
<h2 id="_benchmarking">Benchmarking</h2>
<div>
<p>I opted to run my benchmark on my Ubuntu laptop with the following stats.</p>
<div>
<div>
<pre><code><span></span>$ lshw -short
H/W path        Device      Class          Description
======================================================
                            system         20DF0040US (LENOVO_MT_20DF_BU_Think_FM_ThinkPad E550)
/0                          bus            20DF0040US
/0/3                        memory         32KiB L1 cache
/0/4                        processor      Intel(R) Core(TM) i7-5500U CPU @ 2.40GHz
/0/4/5                      memory         32KiB L1 cache
/0/4/6                      memory         256KiB L2 cache
/0/4/7                      memory         4MiB L3 cache
/0/8                        memory         8GiB System Memory
/0/8/0                      memory         8GiB SODIMM DDR3 Synchronous 1600 MHz (0.6 ns)
/0/8/1                      memory         DIMM [empty]
/0/30                       memory         128KiB BIOS</code></pre>
</div>
</div>
<p>For asdf commands that need a plugin to operate on, I decided to use my own <a href="https://github.com/Stratus3D/asdf-lua">Lua plugin</a> as Lua is simple and lightweight and should have a very small effect on the resulting numbers.</p>
</div>
</div>
<div>
<h2 id="_results">Results</h2>
<div>
<p>The benchmarking script produced a directory of CSV files containing the results. Each file represented a single benchmark of a single command at a single version. I wanted to generate graphs of the performance of each command across all versions of asdf and for that I knew I needed to combine the CSV files. I wrote a script that combined all the benchmarking data for each command into a single CSV. This <a href="http://stratus3d.com/downloads/asdf-performance/csv_combiner">script was a bit sloppy</a> but it worked. Now I have one CSV file for each command, with each row in it containing the benchmark of it at a specific version of asdf.</p>
<div>
<h3 id="_graphs">Graphs</h3>
<p>Now that I had the data it was time to generate the graphs. I am somewhat familiar with gnuplot and wrote a little gnuplot code to generate all the graphs.</p>
<div>
<p><img src="http://stratus3d.com/images/posts/asdf-performance/asdf-current.svg" alt="asdf current"/>
</p>
</div>
<p>The <code>asdf current</code> command is very slow and its performance has gotten worse over time. It now takes on average 1 second for the command to finish on my laptop.</p>
<div>
<p><img src="http://stratus3d.com/images/posts/asdf-performance/asdf-exec.svg" alt="asdf exec"/>
</p>
</div>
<p><code>asdf exec</code> is probably the most important of the commands I’ve benchmarked as it is invoked when <strong>any</strong> asdf shim is executed. Whenever a shim is executed it executes <code>asdf exec</code> and <code>asdf exec</code> resolves to the correct version of the command and then executes it with <code>execs</code>. The graph above shows how this resolution process has changed over time. Performance isn’t terrible, but it’s not great either. At least it has been relatively flat over time. Still, 150 milliseconds is a lot of overhead when it affects <strong>every</strong> shim.</p>
<div>
<p><img src="http://stratus3d.com/images/posts/asdf-performance/asdf-reshim.svg" alt="asdf reshim"/>
</p>
</div>
<p><code>asdf reshim</code> is by far the slowest of all the commands benchmarked. It has also gotten significantly slower in the last couple of releases of asdf. It currently averages 24 seconds on my laptop! Granted, I have a lot of shims on my laptop and the reshim process has a complexity of <code>O(n)</code>. Despite this I think there are things we can do to significantly improve these numbers in future releases.</p>
<div>
<p><img src="http://stratus3d.com/images/posts/asdf-performance/asdf-where.svg" alt="asdf where"/>
</p>
</div>
<p><code>asdf where</code> performs pretty well and has gotten faster! 50 milliseconds isn’t bad for Bash.</p>
<div>
<p><img src="http://stratus3d.com/images/posts/asdf-performance/asdf-which.svg" alt="asdf which"/>
</p>
</div>
<p><code>asdf which</code> is almost as good as <code>asdf where</code> and has also gotten faster over time.</p>
</div>
</div>
</div>
<div>
<h2 id="_conclusion">Conclusion</h2>
<div>
<p>It’s nice to see that <code>asdf where</code> and <code>asdf which</code> are relatively fast and have gotten a little faster and it will be safe to ignore them in future profiling work. <code>asdf current</code> and <code>asdf reshim</code> are slow and have gotten slower over time. Since these are commands that I frequently run manually it is not surprising to see they have gotten slower over time. Given that <code>asdf reshim</code> takes over 24 seconds to complete it is clear there is a lot of work to be done. I’ve already written a tool for generating flame graphs of Bash scripts so stay tuned.</p>
</div>
</div>
</div>


  
</article>

</div>

  



            </div>
        </div></div>
  </body>
</html>
