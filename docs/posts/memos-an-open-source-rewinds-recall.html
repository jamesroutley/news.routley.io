<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/arkohut/memos">Original</a>
    <h1>Memos ‚Äì An open source Rewinds / Recall</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><p><a target="_blank" rel="noopener noreferrer" href="http://thewebivore.com/arkohut/pensieve/blob/master/web/static/logos/memos_logo_512.png"><img src="http://thewebivore.com/arkohut/pensieve/raw/master/web/static/logos/memos_logo_512.png" width="250"/></a>
</p>
<p dir="auto">English | <a href="http://thewebivore.com/arkohut/pensieve/blob/master/README_ZH.md">ÁÆÄ‰Ωì‰∏≠Êñá</a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="http://thewebivore.com/arkohut/pensieve/blob/master/docs/images/memos-search-en.gif"><img src="http://thewebivore.com/arkohut/pensieve/raw/master/docs/images/memos-search-en.gif" alt="memos-search" data-animated-image=""/></a></p>
<blockquote>
<p dir="auto">I changed the name to Pensieve because Memos was already taken.</p>
</blockquote>

<p dir="auto">Pensieve is a privacy-focused passive recording project. It can automatically record screen content, build intelligent indices, and provide a convenient web interface to retrieve historical records.</p>
<p dir="auto">This project draws heavily from two other projects: one called <a href="https://www.rewind.ai/" rel="nofollow">Rewind</a> and another called <a href="https://support.microsoft.com/en-us/windows/retrace-your-steps-with-recall-aa03f8a0-a78b-4b3e-b0a1-2eb8ac48701c" rel="nofollow">Windows Recall</a>. However, unlike both of them, Pensieve allows you to have complete control over your data, avoiding the transfer of data to untrusted data centers.</p>

<ul dir="auto">
<li>üöÄ Simple installation: just install dependencies via pip to get started</li>
<li>üîí Complete data control: all data is stored locally, allowing for full local operation and self-managed data processing</li>
<li>üîç Full-text and vector search support</li>
<li>ü§ñ Integrates with Ollama, using it as the machine learning engine for Pensieve</li>
<li>üåê Compatible with any OpenAI API models (e.g., OpenAI, Azure OpenAI, vLLM, etc.)</li>
<li>üíª Supports Mac and Windows (Linux support is in development)</li>
<li>üîå Extensible functionality through plugins</li>
</ul>

<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="http://thewebivore.com/arkohut/pensieve/blob/master/docs/images/memos-installation.gif"><img src="http://thewebivore.com/arkohut/pensieve/raw/master/docs/images/memos-installation.gif" alt="memos-installation" data-animated-image=""/></a></p>



<p dir="auto">Initialize the pensieve configuration file and sqlite database:</p>

<p dir="auto">Data will be stored in the <code>~/.memos</code> directory.</p>


<p dir="auto">This command will:</p>
<ul dir="auto">
<li>Begin recording all screens</li>
<li>Start the Web service</li>
<li>Set the service to start on boot</li>
</ul>
<div dir="auto"><h3 tabindex="-1" dir="auto">4. Access the Web Interface</h3><a id="user-content-4-access-the-web-interface" aria-label="Permalink: 4. Access the Web Interface" href="#4-access-the-web-interface"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Open your browser and visit <code>http://localhost:8839</code></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="http://thewebivore.com/arkohut/pensieve/blob/master/docs/images/init-page-en.png"><img src="http://thewebivore.com/arkohut/pensieve/raw/master/docs/images/init-page-en.png" alt="init page"/></a></p>

<p dir="auto">On Mac, Pensieve needs screen recording permission. When the program starts, Mac will prompt for screen recording permission - please allow it to proceed.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="http://thewebivore.com/arkohut/pensieve/blob/master/docs/images/mac-security-permission.jpg"><img src="http://thewebivore.com/arkohut/pensieve/raw/master/docs/images/mac-security-permission.jpg" alt="mac permission"/></a></p>

<div dir="auto"><h3 tabindex="-1" dir="auto">Using the Appropriate Embedding Model</h3><a id="user-content-using-the-appropriate-embedding-model" aria-label="Permalink: Using the Appropriate Embedding Model" href="#using-the-appropriate-embedding-model"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>

<p dir="auto">Pensieve uses embedding models to extract semantic information and build vector indices. Therefore, choosing an appropriate embedding model is crucial. Depending on the user&#39;s primary language, different embedding models should be selected.</p>
<ul dir="auto">
<li>For Chinese scenarios, you can use the <a href="https://huggingface.co/jinaai/jina-embeddings-v2-base-zh" rel="nofollow">jinaai/jina-embeddings-v2-base-zh</a> model.</li>
<li>For English scenarios, you can use the <a href="https://huggingface.co/jinaai/jina-embeddings-v2-base-en" rel="nofollow">jinaai/jina-embeddings-v2-base-en</a> model.</li>
</ul>
<div dir="auto"><h4 tabindex="-1" dir="auto">2. Adjust Memos Configuration</h4><a id="user-content-2-adjust-memos-configuration" aria-label="Permalink: 2. Adjust Memos Configuration" href="#2-adjust-memos-configuration"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Open the <code>~/.memos/config.yaml</code> file with your preferred text editor and modify the <code>embedding</code> configuration:</p>
<div dir="auto" data-snippet-clipboard-copy-content="embedding:
  use_local: true
  model: jinaai/jina-embeddings-v2-base-en   # Model name used
  num_dim: 768                               # Model dimensions
  use_modelscope: false                      # Whether to use ModelScope&#39;s model"><pre><span>embedding</span>:
  <span>use_local</span>: <span>true</span>
  <span>model</span>: <span>jinaai/jina-embeddings-v2-base-en   </span><span><span>#</span> Model name used</span>
  <span>num_dim</span>: <span>768</span>                               <span><span>#</span> Model dimensions</span>
  <span>use_modelscope</span>: <span>false                      </span><span><span>#</span> Whether to use ModelScope&#39;s model</span></pre></div>


<p dir="auto">The first time you use the embedding model, Pensieve will automatically download and load the model.</p>

<p dir="auto">If you switch the embedding model during use, meaning you have already indexed screenshots before, you need to rebuild the index:</p>

<p dir="auto">The <code>--force</code> parameter indicates rebuilding the index table and deleting previously indexed screenshot data.</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">Using Ollama for Visual Search</h3><a id="user-content-using-ollama-for-visual-search" aria-label="Permalink: Using Ollama for Visual Search" href="#using-ollama-for-visual-search"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">By default, Pensieve only enables the OCR plugin to extract text from screenshots and build indices. However, this method significantly limits search effectiveness for images without text.</p>
<p dir="auto">To achieve more comprehensive visual search capabilities, we need a multimodal image understanding service compatible with the OpenAI API. Ollama perfectly fits this role.</p>
<div dir="auto"><h4 tabindex="-1" dir="auto">Important Notes Before Use</h4><a id="user-content-important-notes-before-use" aria-label="Permalink: Important Notes Before Use" href="#important-notes-before-use"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Before deciding to enable the VLM feature, please note the following:</p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Hardware Requirements</strong></p>
<ul dir="auto">
<li>Recommended configuration: NVIDIA graphics card with at least 8GB VRAM or Mac with M series chip</li>
<li>The minicpm-v model will occupy about 5.5GB of storage space</li>
<li>CPU mode is not recommended as it will cause severe system lag</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Performance and Power Consumption Impact</strong></p>
<ul dir="auto">
<li>Enabling VLM will significantly increase system power consumption</li>
<li>Consider using other devices to provide OpenAI API compatible model services</li>
</ul>
</li>
</ol>

<p dir="auto">Visit the <a href="https://ollama.com" rel="nofollow">Ollama official documentation</a> for detailed installation and configuration instructions.</p>
<div dir="auto"><h4 tabindex="-1" dir="auto">2. Prepare the Multimodal Model</h4><a id="user-content-2-prepare-the-multimodal-model" aria-label="Permalink: 2. Prepare the Multimodal Model" href="#2-prepare-the-multimodal-model"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Download and run the multimodal model <code>minicpm-v</code> using the following command:</p>
<div dir="auto" data-snippet-clipboard-copy-content="ollama run minicpm-v &#34;Describe what this service is&#34;"><pre>ollama run minicpm-v <span><span>&#34;</span>Describe what this service is<span>&#34;</span></span></pre></div>
<p dir="auto">This command will download and run the minicpm-v model. If the running speed is too slow, it is not recommended to use this feature.</p>
<div dir="auto"><h4 tabindex="-1" dir="auto">3. Configure Pensieve to Use Ollama</h4><a id="user-content-3-configure-pensieve-to-use-ollama" aria-label="Permalink: 3. Configure Pensieve to Use Ollama" href="#3-configure-pensieve-to-use-ollama"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Open the <code>~/.memos/config.yaml</code> file with your preferred text editor and modify the <code>vlm</code> configuration:</p>
<div dir="auto" data-snippet-clipboard-copy-content="vlm:
  endpoint: http://localhost:11434  # Ollama service address
  modelname: minicpm-v              # Model name to use
  force_jpeg: true                  # Convert images to JPEG format to ensure compatibility
  prompt: Please describe the content of this image, including the layout and visual elements  # Prompt sent to the model"><pre><span>vlm</span>:
  <span>endpoint</span>: <span>http://localhost:11434  </span><span><span>#</span> Ollama service address</span>
  <span>modelname</span>: <span>minicpm-v              </span><span><span>#</span> Model name to use</span>
  <span>force_jpeg</span>: <span>true                  </span><span><span>#</span> Convert images to JPEG format to ensure compatibility</span>
  <span>prompt</span>: <span>Please describe the content of this image, including the layout and visual elements  </span><span><span>#</span> Prompt sent to the model</span></pre></div>
<p dir="auto">Use the above configuration to overwrite the <code>vlm</code> configuration in the <code>~/.memos/config.yaml</code> file.</p>
<p dir="auto">Also, modify the <code>default_plugins</code> configuration in the <code>~/.memos/plugins/vlm/config.yaml</code> file:</p>
<div dir="auto" data-snippet-clipboard-copy-content="default_plugins:
- builtin_ocr
- builtin_vlm"><pre><span>default_plugins</span>:
- <span>builtin_ocr</span>
- <span>builtin_vlm</span></pre></div>
<p dir="auto">This adds the <code>builtin_vlm</code> plugin to the default plugin list.</p>
<div dir="auto"><h4 tabindex="-1" dir="auto">4. Restart Pensieve Service</h4><a id="user-content-4-restart-pensieve-service" aria-label="Permalink: 4. Restart Pensieve Service" href="#4-restart-pensieve-service"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>

<p dir="auto">After restarting the Pensieve service, wait a moment to see the data extracted by VLM in the latest screenshots on the Pensieve web interface:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="http://thewebivore.com/arkohut/pensieve/blob/master/docs/images/single-screenshot-view-with-minicpm-result.png"><img src="http://thewebivore.com/arkohut/pensieve/raw/master/docs/images/single-screenshot-view-with-minicpm-result.png" alt="image"/></a></p>
<p dir="auto">If you do not see the VLM results, you can:</p>
<ul dir="auto">
<li>Use the command <code>memos ps</code> to check if the Pensieve process is running normally</li>
<li>Check for error messages in <code>~/.memos/logs/memos.log</code></li>
<li>Confirm whether the Ollama model is loaded correctly (<code>ollama ps</code>)</li>
</ul>

<p dir="auto">Pensieve is a compute-intensive application. The indexing process requires the collaboration of OCR, VLM, and embedding models. To minimize the impact on the user&#39;s computer, Pensieve calculates the average processing time for each screenshot and adjusts the indexing frequency accordingly. Therefore, not all screenshots are indexed immediately by default.</p>
<p dir="auto">If you want to index all screenshots, you can use the following command for full indexing:</p>

<p dir="auto">This command will scan and index all recorded screenshots. Note that depending on the number of screenshots and system configuration, this process may take some time and consume significant system resources. The index construction is idempotent, and running this command multiple times will not re-index already indexed data.</p>

<p dir="auto">During the development of Pensieve, I closely followed the progress of similar products, especially <a href="https://www.rewind.ai/" rel="nofollow">Rewind</a> and <a href="https://support.microsoft.com/en-us/windows/retrace-your-steps-with-recall-aa03f8a0-a78b-4b3e-b0a1-2eb8ac48701c" rel="nofollow">Windows Recall</a>. I greatly appreciate their product philosophy, but they do not do enough in terms of privacy protection, which is a concern for many users (or potential users). Recording the screen of a personal computer may expose extremely sensitive private data, such as bank accounts, passwords, chat records, etc. Therefore, ensuring that data storage and processing are completely controlled by the user to prevent data leakage is particularly important.</p>
<p dir="auto">The advantages of Pensieve are:</p>
<ol dir="auto">
<li>The code is completely open-source and easy-to-understand Python code, allowing anyone to review the code to ensure there are no backdoors.</li>
<li>Data is completely localized, all data is stored locally, and data processing is entirely controlled by the user. Data will be stored in the user&#39;s <code>~/.memos</code> directory.</li>
<li>Easy to uninstall. If you no longer use Pensieve, you can close the program with <code>memos stop &amp;&amp; memos disable</code>, then uninstall it with <code>pip uninstall memos</code>, and finally delete the <code>~/.memos</code> directory to clean up all databases and screenshot data.</li>
<li>Data processing is entirely controlled by the user. Pensieve is an independent project, and the machine learning models used (including VLM and embedding models) are chosen by the user. Due to Pensieve&#39; operating mode, using smaller models can also achieve good results.</li>
</ol>
<p dir="auto">Of course, there is still room for improvement in terms of privacy, and contributions are welcome to make Pensieve better.</p>


<p dir="auto">Pensieve records the screen every 5 seconds and saves the original screenshots in the <code>~/.memos/screenshots</code> directory. Storage space usage mainly depends on the following factors:</p>
<ol dir="auto">
<li>
<p dir="auto"><strong>Screenshot Data</strong>:</p>
<ul dir="auto">
<li>Single screenshot size: about 40-400KB (depending on screen resolution and display complexity)</li>
<li>Daily data volume: about 400MB (based on 10 hours of usage, single screen 2560x1440 resolution)</li>
<li>Multi-screen usage: data volume increases with the number of screens</li>
<li>Monthly estimate: about 8GB based on 20 working days</li>
</ul>
<p dir="auto">Screenshots are deduplicated. If the content of consecutive screenshots does not change much, only one screenshot will be retained. The deduplication mechanism can significantly reduce storage usage in scenarios where content does not change frequently (such as reading, document editing, etc.).</p>
</li>
<li>
<p dir="auto"><strong>Database Space</strong>:</p>
<ul dir="auto">
<li>SQLite database size depends on the number of indexed screenshots</li>
<li>Reference value: about 2.2GB of storage space after indexing 100,000 screenshots</li>
</ul>
</li>
</ol>

<p dir="auto">Pensieve requires two compute-intensive tasks by default:</p>
<ul dir="auto">
<li>One is the OCR task, used to extract text from screenshots</li>
<li>The other is the embedding task, used to extract semantic information and build vector indices</li>
</ul>

<ul dir="auto">
<li>
<p dir="auto"><strong>OCR Task</strong>: Executed using the CPU, and optimized to select the OCR engine based on different operating systems to minimize CPU usage</p>
</li>
<li>
<p dir="auto"><strong>Embedding Task</strong>: Intelligently selects the computing device</p>
<ul dir="auto">
<li>NVIDIA GPU devices prioritize using the GPU</li>
<li>Mac devices prioritize using Metal GPU</li>
<li>Other devices use the CPU</li>
</ul>
</li>
</ul>
<div dir="auto"><h4 tabindex="-1" dir="auto">Performance Optimization Strategy</h4><a id="user-content-performance-optimization-strategy" aria-label="Permalink: Performance Optimization Strategy" href="#performance-optimization-strategy"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">To avoid affecting users&#39; daily use, Pensieve has adopted the following optimization measures:</p>
<ul dir="auto">
<li>Dynamically adjust the indexing frequency, adapting to system processing speed</li>
<li>Automatically reduce processing frequency when on battery power to save power</li>
</ul>

<p dir="auto">to be continued</p>
</article></div></div>
  </body>
</html>
