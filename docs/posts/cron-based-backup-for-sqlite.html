<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://litestream.io/alternatives/cron/">Original</a>
    <h1>Cron-based backup for SQLite</h1>
    
    <div id="readability-page-1" class="page"><div role="document">
      <div>
        
	<div>
		
		<nav aria-label="Secondary navigation">
			

		</nav>
		<main>
		
			
			<h2 id="overview">Overview<a href="#overview" aria-hidden="true">#</a> </h2>
<p>Sometimes Litestream can be overkill for projects with a small database that do
not have high durability requirements. In these cases, it may be more
appropriate to simply back up your database daily or hourly. This approach can
also be used in conjunction with Litestream as a fallback. You can never have
too many backups!</p>
<div role="alert">
  <p>❗️</p>
  <p>Do not use `cp` to back up SQLite databases. It is not transactionally safe.</p>
</div>
<h3 id="backup--compress">Backup &amp; compress<a href="#backup--compress" aria-hidden="true">#</a> </h3>
<p>The <code>sqlite3</code> command line interface comes with a built-in <code>.backup</code> command
which will safely backup your database to another file location. You can run
it directly from the command line:</p>
<div><pre><code data-lang="sh">sqlite3 /path/to/db <span>&#39;.backup /path/to/backup&#39;</span> 
</code></pre></div><p>This will output your database to the file <code>/path/to/backup</code>. B-tree databases
like SQLite compress well so it’s recommended to compress your database:</p>
<p>This will compress your database to a new file called <code>/path/to/backup.gz</code>. You
can then upload this file to external storage.</p>
<h3 id="external-storage-using-s3">External storage using S3<a href="#external-storage-using-s3" aria-hidden="true">#</a> </h3>
<p>If you are using S3, you can use the <a href="https://aws.amazon.com/cli/">AWS CLI</a> to
copy the file to an S3 bucket:</p>
<div><pre><code data-lang="sh">aws s3 cp /path/to/backup.gz s3://mybucket/backup.gz
</code></pre></div><h3 id="rolling-backups">Rolling backups<a href="#rolling-backups" aria-hidden="true">#</a> </h3>
<p>You can also add the day or hour to your filename to create a rolling backup.
For example, adding the hour to your filename gives you a back up every hour
for the last day. Newer backups for the same hour will overwrite the previous
one:</p>
<div><pre><code data-lang="sh"><span># 1-day, rolling hourly backup</span>
aws s3 cp /path/to/backup.gz s3://mybucket/backup-<span>`</span>date +%H<span>`</span>.gz

<span># 1-month, rolling daily backup</span>
aws s3 cp /path/to/backup.gz s3://mybucket/backup-<span>`</span>date +%d<span>`</span>.gz

<span># 1-month, rolling hourly backup</span>
aws s3 cp /path/to/backup.gz s3://mybucket/backup-<span>`</span>date +%d%H<span>`</span>.gz
</code></pre></div><h3 id="monitoring-backups">Monitoring backups<a href="#monitoring-backups" aria-hidden="true">#</a> </h3>
<p>It’s recommended to call a “dead man” service after performing your backup. This
ensures that you will be notified if your backups stop working for any reason.
<a href="https://deadmanssnitch.com/">Dead Man’s Snitch</a> is one such service although
others also exist.</p>
<h3 id="restoring--testing-backups">Restoring &amp; testing backups<a href="#restoring--testing-backups" aria-hidden="true">#</a> </h3>
<p>A SQLite backup is simply the database file. To restore the database, download
it and decompress (if necessary) and move it into your application’s database
path. Be sure to stop your application before copying the database into place.</p>
<p>While it is rare for backups to go wrong with SQLite, it’s always good to
regularly test your backups. To do this, simply download the back up and run
an integrity check against it:</p>
<div><pre><code data-lang="sh">sqlite3 /path/to/backup <span>&#39;PRAGMA integrity_check&#39;</span>
</code></pre></div><h3 id="configuring-cron">Configuring cron<a href="#configuring-cron" aria-hidden="true">#</a> </h3>
<p><a href="https://man7.org/linux/man-pages/man5/crontab.5.html"><code>crontab</code></a> is a built-in
Unix tool for periodically running commands. First, we’ll create a script to
run our backup commands. This is an example that combines the commands from
above.</p>
<div><pre><code data-lang="sh"><span>#!/bin/bash -x
</span><span></span>
<span># Ensure script stops when commands fail.</span>
<span>set</span> -e

<span># Backup &amp; compress our database to the temp directory.</span>
sqlite3 /path/to/db <span>&#39;.backup /tmp/db&#39;</span>
gzip /tmp/db

<span># Upload backup to S3 using a rolling daily naming scheme.</span>
aws s3 cp /tmp/db.gz s3://mybucket/db-<span>`</span>date +%d<span>`</span>.gz

<span># Notify dead man that back up completed successfully.</span>
curl -d <span>s</span><span>=</span><span>$?</span> https://nosnch.in/xxxxxxxxxx <span>&amp;</span>&gt; /dev/null
</code></pre></div><p>Then you can configure <code>crontab</code> to run this daily at midnight:</p>
<div><pre><code data-lang="sh"><span># Edit your cron jobs</span>
crontab -e

<span># Add this to the end of the crontab</span>
<span>0</span> <span>0</span> * * * /path/to/my_backup_script.sh
</code></pre></div>
			

		</main>
	</div>

      </div>
    </div></div>
  </body>
</html>
