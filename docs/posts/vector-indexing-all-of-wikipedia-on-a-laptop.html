<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://foojay.io/today/indexing-all-of-wikipedia-on-a-laptop/">Original</a>
    <h1>Vector indexing all of Wikipedia on a laptop</h1>
    
    <div id="readability-page-1" class="page"><div>
                        <div>
                                                            <a href="https://foojay.io/today/">
                                    <svg width="20" height="20" viewBox="0 0 20 20" fill="none" xmlns="http://www.w3.org/2000/svg">
                                        <path d="M15.833 10L4.16634 10" stroke="#4FC3F7" stroke-linecap="round" stroke-linejoin="round"></path>
                                        <path d="M10 15.8333L4.16667 9.99992L10 4.16658" stroke="#4FC3F7" stroke-linecap="round" stroke-linejoin="round"></path>
                                    </svg>
                                    Friends of OpenJDK Today                                </a>
                                                                                        <ul>
                                                                            <li><a href="https://foojay.io/today/category/tools/datastax/">DataStax</a></li>
                                                                            <li><a href="https://foojay.io/today/category/performance/">Performance</a></li>
                                                                            <li><a href="https://foojay.io/today/category/tools/">Tools</a></li>
                                                                    </ul>
                                                        
                            <p><span>May 29, 2024</span></p><div>
				<p><span></span> <span>Unique Views:</span> <span>31,170</span></p><p>since<span>May, 2024</span></p></div>                        </div>
                        <div>
                                <div>
        
        <ul>
                            <li>
                    <div>
                        <p><img alt="" src="https://secure.gravatar.com/avatar/bc157185a40228ca05c3f4cc4d69b061?s=96&amp;d=mm&amp;r=g" srcset="https://secure.gravatar.com/avatar/bc157185a40228ca05c3f4cc4d69b061?s=96&amp;d=mm&amp;r=g 2x" height="96" width="96" decoding="async"/>                        </p>
                        <div>
                                                    <p><span>
                                                        <a href="https://foojay.io/today/author/jbellis/">Jonathan Ellis</a>
                                                    </span></p><ul>
                                                                    <li>
                                        <a href="https://twitter.com/spyced" target="_blank" rel="noopener noreferrer">
                                            <svg width="30" height="30" viewBox="0 0 30 30" fill="none" xmlns="http://www.w3.org/2000/svg">
                                                <path d="M28.75 3.75C27.553 4.59434 26.2276 5.24013 24.825 5.6625C24.0722 4.79688 23.0717 4.18336 21.9588 3.9049C20.8459 3.62645 19.6744 3.69649 18.6026 4.10556C17.5308 4.51464 16.6106 5.243 15.9662 6.19214C15.3219 7.14129 14.9846 8.26542 15 9.4125V10.6625C12.8033 10.7195 10.6266 10.2323 8.66376 9.2443C6.70093 8.25635 5.0129 6.79829 3.75 5C3.75 5 -1.25 16.25 10 21.25C7.42566 22.9975 4.35895 23.8737 1.25 23.75C12.5 30 26.25 23.75 26.25 9.375C26.2488 9.02681 26.2154 8.67949 26.15 8.3375C27.4258 7.07936 28.326 5.49089 28.75 3.75Z" fill="#61C9F8"></path>
                                            </svg>
                                        </a>
                                    </li>
                                                                                                                                    <li>
                                        <a href="https://www.linkedin.com/in/jbellis/" target="_blank" rel="noopener noreferrer">
                                            <svg width="30" height="30" viewBox="0 0 30 30" fill="none" xmlns="http://www.w3.org/2000/svg">
                                                <path d="M20 10C21.9891 10 23.8968 10.7902 25.3033 12.1967C26.7098 13.6032 27.5 15.5109 27.5 17.5V26.25H22.5V17.5C22.5 16.837 22.2366 16.2011 21.7678 15.7322C21.2989 15.2634 20.663 15 20 15C19.337 15 18.7011 15.2634 18.2322 15.7322C17.7634 16.2011 17.5 16.837 17.5 17.5V26.25H12.5V17.5C12.5 15.5109 13.2902 13.6032 14.6967 12.1967C16.1032 10.7902 18.0109 10 20 10Z" fill="#61C9F8"></path>
                                                <path d="M7.5 11.25H2.5V26.25H7.5V11.25Z" fill="#61C9F8"></path>
                                                <path d="M5 7.5C6.38071 7.5 7.5 6.38071 7.5 5C7.5 3.61929 6.38071 2.5 5 2.5C3.61929 2.5 2.5 3.61929 2.5 5C2.5 6.38071 3.61929 7.5 5 7.5Z" fill="#61C9F8"></path>
                                            </svg>
                                        </a>
                                    </li>
                                                                                            </ul>
                                                            <p>
                                    Jonathan is the co-founder and CTO of DataStax. Before DataStax, he spent six years as project chair of Apache Cassandra, where he built the project and community into an open-source ... <a href="https://foojay.io/today/author/jbellis/">Learn more</a>                                </p>
                                                    </div>
                    </div>
                </li>
                    </ul>
    </div>
                        </div>
                        
<p>In November, <a href="https://huggingface.co/datasets/Cohere/wikipedia-2023-11-embed-multilingual-v3">Cohere released a dataset containing all of Wikipedia</a>, chunked and embedded to vectors with <a href="https://cohere.com/blog/introducing-embed-v3">their multilingual-v3 model</a>. </p>



<p>Computing this many embeddings yourself would cost in the neighborhood of $5000, so the public release of this dataset makes creating <a href="https://www.datastax.com/guides/what-is-vector-search">a semantic, vector-based index</a> of Wikipedia practical for an individual for the first time.</p>



<p>Here’s what we’re building: </p>



<figure><img decoding="async" src="https://lh7-us.googleusercontent.com/ydeHYk97v6Bza1GF0wbbHUEzxgCAJLfwbRcVnWvUP6QDPKKY5YQH00Dvi2n6VgkioW_PGqwckcCnQu9cJ2nOz2XSuL_27HNPAAbZdv2vXPOy_vUJ_Vcg-ii83E4jaqMycskzmzt8wBP1XsOYh5b7Cv4" alt=""/></figure>



<p>You can try searching the completed index <a href="https://jvectordemo.com:8443/">on a public demo instance here</a>.</p>







<p>Sure, the dataset is big (180GB for the English corpus), but that’s not the obstacle per se.  We’ve been able to build full-text indexes on larger datasets for a long time.</p>



<p>The obstacle is that until now, off-the-shelf vector databases could not index a dataset larger than memory, because both the full-resolution vectors and the index (edge list) needed to be kept in memory during index construction.  Larger datasets could be split into <a href="https://stackoverflow.com/questions/2703432/what-are-segments-in-lucene">segments</a>, but this means that at query time they need to search each segment separately, then combine the results, turning an O(log N) search per segment into O(N) overall.  (In their latest release, <a href="https://www.elastic.co/search-labs/blog/elasticsearch-lucene-vector-database-gains">Lucene attempts to mitigate this by processing segments in parallel with multiple threads</a>, but obviously (1) this only gives you a constant factor of improvement before you run out of CPU cores and (2) this does not improve throughput.)</p>



<p>Specifically, if you’re indexing 1536-dimension vectors (the size of ada002 or openai-v3-small), then you can fit about 5M vectors and their associated edge lists in a 32GB index construction RAM budget.</p>



<figure><img decoding="async" src="https://lh7-us.googleusercontent.com/-BwVEUQqMIDekxlKXgiuOiQcycoM_fP3ncRjVNgRD7W7SzcsTigI4tjsmE-S4x35PIgEpwNxVioZxD50ah2PzQXuVCo22TXiI80EFpjpnCf4X-JjTPBb6FqVC4CJFdrYkoG6aLYxFNotM_MX_NoIpDk" alt=""/></figure>



<p><a href="https://github.com/jbellis/jvector/">JVector</a>, the library that powers <a href="https://www.datastax.com/products/datastax-astra">DataStax Astra</a> vector search, now supports indexing larger-than-memory datasets by performing construction-related searches with compressed vectors.  This means that the edge lists need to fit in memory, but the uncompressed vectors do not, which gives us enough headroom to index Wikipedia-en on a laptop.</p>







<ol>
<li>Linux or MacOS.  It will not work on Windows because ChronicleMap, which we are going to use for the non-vector data, is limited to a 4GB size there.  (If you are interested enough, you could shard the Map by vector id to keep each shard under 4GB and still have O(1) lookup times.)</li>



<li>About 180GB of free space for the dataset, and 90GB for the completed index.</li>



<li>Enough RAM to run a JVM with 36GB of heap space during construction (~28GB for the index, 8GB for GC headroom).</li>



<li>Disable swap before building the index.  Linux will aggressively try to cache the index being constructed to the point of swapping out parts of the JVM heap, which is obviously counterproductive.  In my test, building with swap enabled was almost twice as slow as with it off.</li>
</ol>







<ol>
<li>Check out the project:</li>



<li>Edit <em>config.properties</em> to set the locations for the dataset and the index. </li>



<li>Run <em>pip install datasets</em>.  (Setting up a <a href="https://docs.python.org/3/library/venv.html">venv</a> or conda environment first is recommended but not strictly necessary.)</li>



<li>Run <em>python download.py.  </em>This downloads the 180 GB dataset to the location you configured.  For me that took about half an hour.</li>



<li>Run <em>./mvnw compile exec:exec@buildindex.</em>  This took about 5 and a half hours on my machine (with an i9-12900 CPU).</li>



<li>Run <em>./mvnw compile exec:exec@serve </em>and open a browser to <a href="http://localhost:4567/">http://localhost:4567</a>.  Search away!</li>
</ol>







<p>We’re using <a href="https://github.com/jbellis/jvector">JVector</a> for the vector index and <a href="https://github.com/OpenHFT/Chronicle-Map">Chronicle Map</a> for the article data.  There are <a href="https://github.com/OpenHFT/Chronicle-Map/issues/533">several</a> <a href="https://github.com/OpenHFT/Chronicle-Map/issues/537">things</a> I don’t love about Chronicle Map, but nothing else touches it for simple disk-based key/value performance.</p>



<p>The full source of the index construction class is <a href="https://github.com/jbellis/coherepedia-jvector/blob/master/src/main/java/io/github/jbellis/BuildIndex.java">here</a>.  I’ll explain it next in pieces.</p>



<h2>Compression parameters</h2>



<p>JVector is based on the <a href="https://www.microsoft.com/en-us/research/publication/diskann-fast-accurate-billion-point-nearest-neighbor-search-on-a-single-node/">DiskANN</a> vector index design, which performs an initial search using vectors compressed lossily with <a href="https://towardsdatascience.com/similarity-search-product-quantization-b2a1a6397701">product quantization (PQ)</a> in memory, then reranks the results using high-resolution vectors from disk.  However, while DiskANN stores full, uncompressed vectors to perform reranking, JVector is able to improve on that using <a href="https://arxiv.org/abs/2402.02044">Locally-Adaptive Quantization (LVQ)</a> compression.</p>



<p>To set this up, we’ll first load some vectors into a RandomAccessVectorValues (RAVV) instance.  RAVV is a JVector interface for a vector container; it could be List or Map based, in-memory or on-disk.  In this case we’ll use a simple List-backed RAVV.  We’ll compute the parameters for both compressions (kmeans clustering for PQ, global mean for LVQ) from a single shard of the dataset.  At about 110k rows, this is enough data to have a statistically valid sample.</p>



<figure><img decoding="async" src="https://lh7-us.googleusercontent.com/aN200b1SULDTwrg5inwDuNFKLCVyYstVuYOSXLqAos2D_psAoMp8V5CXjXDKCEKcCZc5JyM7U27qg7LPp14mfQh9nktRzXaXE4pteHFINO-HPS_xxW4ESxf1glxanb5gG2xoAmx1r2qaiReZXcFI--4" alt=""/></figure>



<p>Next, we compute the PQ compression codebook; we’re compressing the vectors by a factor of 64, because the Cohere v3 embeddings can be PQ-compressed that much without losing accuracy, after reranking.  <a href="https://thenewstack.io/why-vector-size-matters/">Binary Quantization only gives us 32x compression and is less accurate</a>.</p>



<figure><img decoding="async" src="https://lh7-us.googleusercontent.com/PS0HlbtZNajjlTe9AFg1yoW7fvGyKeSpHGwfk3_k5dHs08QOkTphXeO03AO2Chx-mxw5lV2wD81xo3lNGB9raJojFYrg6z2-OTIA05fUfVHzpGIM12R-veeTPLirOhjGTvcM-Uch31c5SZmgGDbiIrM" alt=""/></figure>



<p>Finally, we need to set up LVQ.  LVQ gives us 4x compression while losing no measurable accuracy over the full uncompressed vectors, resulting in both a smaller footprint on disk and faster searches.  (I thank the vector search team at Intel Research for pointing this out to us.)</p>



<figure><img decoding="async" src="https://lh7-us.googleusercontent.com/XheHrYXEE6j_GaROcmgI_0-OFJx9GJes1uVcEGDcYFUvi0Gu3ZqXgpqV38iMbxL25JvCmIcFRsxG8EoqZ2aT332JWYAwSeRHnKPzY-un5LO2eun1Eio0ZTya312IXv_AV1xJ88HUT6Fxb96uNtFokGU" alt=""/></figure>



<h2>GraphIndexBuilder</h2>



<p>Next, we need to instantiate and configure our GraphIndexBuilder.</p>



<figure><img decoding="async" src="https://lh7-us.googleusercontent.com/veV6oVgpkDyr-WLPIMzzTtHD0q8MIT3sQxOauqdXwzXExFBQ2FD9btPpVXf-DTuk0OEJAVWpHf6IduBDIiyGSyDwdsEICTyoTjUocG7PgkxIRiMIpIRPpGjiSFoKm9Z-B0vOU4uYRtPsew1Oi3f_bis" alt=""/></figure>



<p>This instantiates a JVector GraphIndexBuilder and connects it to an OnDiskGraphIndexWriter, and tells it to use the PQ-compressed vectors list (which starts empty and will grow as we add vectors to the index) during construction (in the BuildScoreProvider).</p>



<h2>Chronicle Map and RowData</h2>



<p>We’ll store article contents in RowData records.  This content is what has been encoded as the corresponding vector in the dataset, and is what we want to return to the user in our search results.</p>



<figure><img decoding="async" src="https://lh7-us.googleusercontent.com/veVvO8QUrY_k_YGDwavo_dBaIoM5ZGGfaN5dowCroJAgJv-37JZIWq0jX78rY0R8g6wvRO1QxvTv-dMuEVMJRvmrvdbmLAHlBJqUd9yoyIXD0DADDlZQXyZcyLPcp-F4zAcRb1obXtvJO6d4oXTGD7M" alt=""/></figure>



<p>To turn the vector index’s search results (a list of integer vector ids) into RowData, we store the RowData in a Map keyed by the vector id.  This will be a lot of data, so we use <a href="https://github.com/OpenHFT/Chronicle-Map">ChronicleMap</a> to store this on disk with a minimal in-memory footprint.</p>



<figure><img decoding="async" src="https://lh7-us.googleusercontent.com/hFMjxcQstglWY0IjbgKqiHB9dk7KlKATQnBIBLZh_hGvdsuo6_UDQi8ydn3RA0ELYpJlng0HERqxUG1nmpj5HRNFPRhIHhhOtnC6vc7XHsIZnwI-fcyRK8gNnPeKpLUUQNVjGnK9EP1RHU6UPs0SLsw" alt=""/></figure>



<p>We need to tell ChronicleMap how large it’s going to be, both in entry count and entry size.  Undersizing these will cause it to crash (<a href="https://github.com/OpenHFT/Chronicle-Map/issues/533">my primary complaint</a> about ChronicleMap), so we deliberately use a high estimate.</p>



<p>We <em>do not</em> need to explicitly tell ChronicleMap how to read and write RowData objects, instead we just have RowData implement Serializable.  While ChronicleMap supports custom de/serialize code, it’s perfectly happy to use simple out-of-the-box serialization and since profiling shows that’s not a bottleneck for us we’ll just leave it at that.</p>



<h2>Ingesting the data</h2>



<p>We use Java’s parallel Streams to process the shards in parallel.  For each row in each shard, we</p>



<ol>
<li>Add it to <em>pqVectorsList</em></li>



<li>Call <em>writer.writeInline</em> to add the LVQ-compressed vector to disk</li>



<li>Call <em>builder.addGraphNode </em>– order is important because both (1) and (2) are used when we call addGraphNode</li>



<li>Call <em>contentMap.put</em> with the article chunk data.</li>
</ol>



<figure><img decoding="async" src="https://lh7-us.googleusercontent.com/5souUR9e_gbEEdcUwWvq8_cjleyFGglaQaCSV-XFkv-3Ij7cGYgd13UcyGdwIYE6Xw5zD4WiFSxGO1phrEK8w6UWx6BanZVWXQ4oBnkHdh6aEFB4DIllhK15HjZJ9iJyQKV5ts9QTLQqF3uufChXdPE" alt=""/></figure>



<figure><img decoding="async" src="https://lh7-us.googleusercontent.com/_Z7fqvsbvQ2kXJY286iM-ysvQJCHwlaWgmBACBFZfSOscrSbGtYMkGOlKbA5cWuaB4-M_aN1Y6idM1pWEEvUvQJh-22d71eAxAR5hxZNwBy1dedc1DIApiKTfSpLQMsIIzN3yozbSPProh5TJT_TkvU" alt=""/></figure>



<p>You can look at <a href="https://github.com/jbellis/coherepedia-jvector/blob/master/src/main/java/io/github/jbellis/BuildIndex.java">the full source</a> if you’re curious about <em>forEachRow</em>, it’s just standard “pull data out of Arrow” stuff.</p>



<p>When the build completes, you should see files like this:</p>



<p>$ ls -lh ~/coherepedia</p>



<p>-rw-rw-r-- 1 jonathan jonathan  48G May 20 15:53 coherepedia.ann</p>



<p>-rw-rw-r-- 1 jonathan jonathan  36G May 20 18:05 coherepedia.map</p>



<p>-rw-rw-r-- 1 jonathan jonathan 2.5G May 20 15:53 coherepedia.pqv</p>



<p>-rw-rw-r-- 1 jonathan jonathan 4.1K May 17 23:04 coherepedia.lvq</p>



<p>-rw-rw-r-- 1 jonathan jonathan 1.1M May 17 23:04 coherepedia.pq</p>



<p>These are respectively</p>



<ul>
<li>ANN: the vector index, containing the edge lists and LVQ-compressed vectors for reranking.</li>



<li>MAP: the map containing article data indexed by vector id.</li>



<li>PQV: PQ-compressed vectors, which are read into memory and used for the approximate search pass.</li>



<li>LVQ: the LVQ global mean, used during construction.</li>



<li>PQ: the PQ codebooks, used during construction.</li>
</ul>



<h2>Loading the index (after construction)</h2>



<p>The code for serving queries is found in the <a href="https://github.com/jbellis/coherepedia-jvector/blob/master/src/main/java/io/github/jbellis/WebSearch.java">WebSearch</a> class.  We’re using Spark (<a href="https://sparkjava.com/">the web framework</a>, not the big data engine) to serve a simple search form:</p>



<figure><img decoding="async" src="https://lh7-us.googleusercontent.com/a-y2F-t0K9ph-4-0ERwSLy7-xhLDMQZD1qz7FU8tDPvj6w1MUhkhznWEksElvPh_1twzn68B8nD6q6wheKlAqxUyyghNhPmxDEs69fYiKTKEtILwwuFhSPNmsDVhS395kDu3hlggzUQIKtG0S_PJxRw" alt=""/></figure>



<p>Construction needed a relatively large heap to keep the edge lists in memory.  With that complete, we only need enough to keep the PQ-compressed vectors in memory; <em>exec@serve </em>is configured to use a 4GB heap.</p>



<p>WebSearch (<a href="https://github.com/jbellis/coherepedia-jvector/blob/master/src/main/java/io/github/jbellis/WebSearch.java">the class behind <em>exec@serve</em></a>) first has a static initializer to load the PQ vectors and open the ChronicleMap.  We also create a reusable GraphSearcher instance:</p>



<figure><img decoding="async" src="https://lh7-us.googleusercontent.com/ofHaU8px5jnF0FCupz_mJt4CMc1Bg8Lul36DcScuviM3IPj8UnL7FKD-TMnUh3Lyn41n0Krn_FoooHNaJjf_112xF44SZk9BPe5O-74tuF8VwrmCVEeB571RGYJ-DILbeq4qGFN1MHZQaqxI6v-U8Bw" alt=""/></figure>



<h2>Performing a search</h2>



<p>Executing a search and turning it into RowData for the user looks like this:</p>



<figure><img decoding="async" src="https://lh7-us.googleusercontent.com/-bY_lTq_EAXUwfuP_MEsLYcuwwdx13wKCCYAAL83KaxSQ1x8VBbAjlbqGWCxL998vVAlBfEmOxTXZIRkJp8-uTLb0FLXrvCdGICWggC13UKXPCjBq42D5guoHk5IvShjzgpf1IvD2JYcQiIJnyDKedo" alt=""/></figure>



<p>There are four “paragraphs” of code here, containing</p>



<ol>
<li>The call to <em>getVectorEmbedding</em>.  This calls Cohere’s API to turn the search query (a String) into a vector embedding.</li>



<li>Creating approximate and reranking score functions.  Approximate scoring is done through our product quantization, and reranking is done with the LVQ vectors in the index.  Since the LVQ vectors are encapsulated in the index itself, we never need to explicitly deal with LVQ decoding; the index does it for us.</li>



<li>The call to <em>searcher.search </em>that actually does the query, and finally</li>



<li>Retrieving the RowData associated with the top vector neighbors using <em>contentMap</em>.</li>
</ol>



<p>That’s it!  We’ve indexed all of Wikipedia with high performance, parallel code in about 150 loc, and created a simple search server in another 100.</p>



<p>On my machine, searches (which each run in a single thread) take about 50ms.  We would expect it to take over twice as long if this were split across multiple segments.  We would also expect it to lose significant accuracy if searches were performed only with compressed vectors without reranking.</p>







<p>Indexing the entirety of English Wikipedia on a laptop has become a practical reality thanks to recent advances in the JVector library that will be part of the imminent 3.0 release.  (<a href="https://github.com/jbellis/jvector">Star the repo</a> and stand by!)  This article demonstrates how to do exactly that using JVector in conjunction with Chronicle Map, while also showcasing the use of <a href="https://arxiv.org/abs/2402.02044">LVQ</a> to reduce index size while preserving <a href="https://thenewstack.io/why-vector-size-matters/">accurate reranking</a>.</p>



<p>To take advantage of the power of JVector alongside powerful indexing for non-vector data, rolled into a document api with support for realtime inserts, updates, and deletes, check out the <a href="https://www.datastax.com/products/datastax-astra">DataStax Astra</a> service.</p>



<p>Enjoy hacking with JVector and Astra!</p>



<div data-entry="111089" data-current="111190">
    <div>
        <p>Promoted Content</p>                    <h2>Root Cause: DB query with a scaling issue</h2>
                <p>
            Encountered performance issues and unexpected behavior in your backend services?        </p>
	                <a href="https://digma.ai/identifying-code-concurrency-issues-with-continuous-feedback/?utm_campaign=Foojay&amp;utm_source=f&amp;utm_medium=banner%20adImage" target="_blank">
                Get Insights                <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16" fill="none">
                    <path d="M3.33325 8H12.6666" stroke="white" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path>
                    <path d="M8 3.33331L12.6667 7.99998L8 12.6666" stroke="white" stroke-width="1.5" stroke-linecap="round" stroke-linejoin="round"></path>
                </svg>
            </a>
            </div>
    <p><img fetchpriority="high" decoding="async" width="700" height="351" src="https://foojay.io/wp-content/uploads/2024/05/asaf-blog--700x351.png" alt="" srcset="https://foojay.io/wp-content/uploads/2024/05/asaf-blog--700x351.png 700w, https://foojay.io/wp-content/uploads/2024/05/asaf-blog--768x385.png 768w, https://foojay.io/wp-content/uploads/2024/05/asaf-blog--728x364.png 728w, https://foojay.io/wp-content/uploads/2024/05/asaf-blog-.png 772w" sizes="(max-width: 700px) 100vw, 700px"/>    </p>
</div>

                    </div></div>
  </body>
</html>
