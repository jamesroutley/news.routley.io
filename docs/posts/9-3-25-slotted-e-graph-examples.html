<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/saulshanabrook/saulshanabrook/discussions/42">Original</a>
    <h1>9/3/25 - Slotted E-Graph Examples</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto"><strong>Post-hoc calibration without retraining</strong> for large language models. This toolkit turns a raw prompt into:</p>
<ol dir="auto">
<li>a <strong>bounded hallucination risk</strong> using the Expectation-level Decompression Law (EDFL), and</li>
<li>a <strong>decision</strong> to <strong>ANSWER</strong> or <strong>REFUSE</strong> under a target SLA, with transparent math (nats).</li>
</ol>
<p dir="auto">It supports two deployment modes:</p>
<ul dir="auto">
<li><strong>Evidence-based:</strong> prompts include <em>evidence/context</em>; rolling priors are built by erasing that evidence.</li>
<li><strong>Closed-book:</strong> prompts have <em>no evidence</em>; rolling priors are built by semantic masking of entities/numbers/titles.</li>
</ul>
<p dir="auto">All scoring relies <strong>only</strong> on the OpenAI Chat Completions API. No retraining required.</p>
<hr/>

<ul dir="auto">
<li><a href="#install--setup">Install &amp; Setup</a></li>
<li><a href="#core-mathematical-framework">Core Mathematical Framework</a></li>
<li><a href="#understanding-system-behavior">Understanding System Behavior</a></li>
<li><a href="#two-ways-to-build-rolling-priors">Two Ways to Build Rolling Priors</a></li>
<li><a href="#api-surface">API Surface</a></li>
<li><a href="#calibration--validation">Calibration &amp; Validation</a></li>
<li><a href="#practical-considerations">Practical Considerations</a></li>
<li><a href="#project-layout">Project Layout</a></li>
<li><a href="#deployment-options">Deployment Options</a></li>
</ul>
<hr/>

<div dir="auto" data-snippet-clipboard-copy-content="pip install --upgrade openai
export OPENAI_API_KEY=sk-..."><pre>pip install --upgrade openai
<span>export</span> OPENAI_API_KEY=sk-...</pre></div>
<blockquote>
<p dir="auto">The module uses <code>openai&gt;=1.0.0</code> and the Chat Completions API (e.g., <code>gpt-4o</code>, <code>gpt-4o-mini</code>).</p>
</blockquote>
<hr/>
<div dir="auto"><h2 tabindex="-1" dir="auto">Core Mathematical Framework</h2><a id="user-content-core-mathematical-framework" aria-label="Permalink: Core Mathematical Framework" href="#core-mathematical-framework"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>

<p dir="auto">Let the binary event <math-renderer data-run-id="ac53eaeccbd3c97d7d65498825429120">$\mathcal{A}$</math-renderer> be the thing you want to guarantee (e.g., <strong>Answer</strong> in decision mode, or <strong>Correct</strong> for factual accuracy).</p>
<ul dir="auto">
<li>
<p dir="auto"><strong>Information budget:</strong></p>
</li>
<li>
<p dir="auto"><strong>Prior masses:</strong> <math-renderer data-run-id="ac53eaeccbd3c97d7d65498825429120">$q_k = S_k(\mathcal{A})$</math-renderer>, with:</p>
<ul dir="auto">
<li>
<math-renderer data-run-id="ac53eaeccbd3c97d7d65498825429120">$\bar{q}=\tfrac{1}{m}\sum_k q_k$</math-renderer> (average prior for EDFL bound)</li>
<li>
<math-renderer data-run-id="ac53eaeccbd3c97d7d65498825429120">$q_{\text{lo}}=\min_k q_k$</math-renderer> (worst-case prior for SLA gating)</li>
</ul>
</li>
</ul>
<p dir="auto">By EDFL, the achievable reliability is bounded by:</p>
<p dir="auto">Thus the <strong>hallucination risk</strong> (error) is bounded by <math-renderer data-run-id="ac53eaeccbd3c97d7d65498825429120">$\overline{\mathrm{RoH}} \le 1 - p_{\max}$</math-renderer>.</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">Decision Rule (SLA Gating)</h3><a id="user-content-decision-rule-sla-gating" aria-label="Permalink: Decision Rule (SLA Gating)" href="#decision-rule-sla-gating"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">For target hallucination rate <math-renderer data-run-id="ac53eaeccbd3c97d7d65498825429120">$h^*$</math-renderer>:</p>
<ul dir="auto">
<li>
<strong>Bits-to-Trust:</strong> <math-renderer data-run-id="ac53eaeccbd3c97d7d65498825429120">$\mathrm{B2T} = \mathrm{KL}(\mathrm{Ber}(1-h^*) | \mathrm{Ber}(q_{\text{lo}}))$</math-renderer>
</li>
<li>
<strong>Information Sufficiency Ratio:</strong> <math-renderer data-run-id="ac53eaeccbd3c97d7d65498825429120">$\mathrm{ISR} = \bar{\Delta}/\mathrm{B2T}$</math-renderer>
</li>
<li>
<strong>ANSWER</strong> iff <math-renderer data-run-id="ac53eaeccbd3c97d7d65498825429120">$\mathrm{ISR}\ge 1$</math-renderer> <em>and</em> <math-renderer data-run-id="ac53eaeccbd3c97d7d65498825429120">$\bar{\Delta} \ge \mathrm{B2T} + \text{margin}$</math-renderer> (default <code>margin≈0.2</code> nats)</li>
</ul>
<blockquote>
<p dir="auto"><strong>Why two priors?</strong> The gate uses <strong>worst-case</strong> <math-renderer data-run-id="ac53eaeccbd3c97d7d65498825429120">$q_{\text{lo}}$</math-renderer> for strict SLA compliance. The RoH bound uses <strong>average</strong> <math-renderer data-run-id="ac53eaeccbd3c97d7d65498825429120">$\bar{q}$</math-renderer> per EDFL theory. This dual approach ensures conservative safety while providing realistic risk bounds.</p>
</blockquote>
<hr/>
<div dir="auto"><h2 tabindex="-1" dir="auto">Understanding System Behavior</h2><a id="user-content-understanding-system-behavior" aria-label="Permalink: Understanding System Behavior" href="#understanding-system-behavior"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">Expected Behavioral Patterns</h3><a id="user-content-expected-behavioral-patterns" aria-label="Permalink: Expected Behavioral Patterns" href="#expected-behavioral-patterns"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">The toolkit exhibits different behaviors across query types, which is <strong>mathematically consistent</strong> with the framework:</p>
<div dir="auto"><h4 tabindex="-1" dir="auto">Simple Arithmetic Queries</h4><a id="user-content-simple-arithmetic-queries" aria-label="Permalink: Simple Arithmetic Queries" href="#simple-arithmetic-queries"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><strong>Observation:</strong> May abstain despite apparent simplicity</p>
<ul dir="auto">
<li>Models often attempt answers even with masked numbers (pattern recognition)</li>
<li>This yields <strong>low information lift</strong> <math-renderer data-run-id="ac53eaeccbd3c97d7d65498825429120">$\bar{\Delta} \approx 0$</math-renderer> between full prompt and skeletons</li>
<li>Despite potentially low EDFL risk bound, worst-case prior gate triggers <strong>abstention</strong> (ISR &lt; 1)</li>
</ul>

<p dir="auto"><strong>Observation:</strong> Generally answered with confidence</p>
<ul dir="auto">
<li>Masking entities/dates substantially reduces answer propensity in skeletons</li>
<li>Restoring these yields <strong>large</strong> <math-renderer data-run-id="ac53eaeccbd3c97d7d65498825429120">$\bar{\Delta}$</math-renderer> that clears B2T threshold</li>
<li>System <strong>answers</strong> with tight EDFL risk bound</li>
</ul>
<p dir="auto"><strong>This is not a bug but a feature</strong>: The framework prioritizes safety through worst-case guarantees while providing realistic average-case bounds.</p>

<ol dir="auto">
<li>
<p dir="auto"><strong>Switch Event Measurement</strong></p>
<ul dir="auto">
<li>Use <strong>Correct/Incorrect</strong> instead of Answer/Refuse for factual QA</li>
<li>Skeletons without key information rarely yield correct results → large <math-renderer data-run-id="ac53eaeccbd3c97d7d65498825429120">$\bar{\Delta}$</math-renderer>
</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Enhance Skeleton Weakening</strong></p>
<ul dir="auto">
<li>Implement mask-aware decision head that refuses on redaction tokens</li>
<li>Ensures skeletons have strictly lower &#34;Answer&#34; mass than full prompt</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Calibration Adjustments</strong></p>
<ul dir="auto">
<li>Relax <math-renderer data-run-id="ac53eaeccbd3c97d7d65498825429120">$h^*$</math-renderer> slightly (e.g., 0.10 instead of 0.05) for higher answer rates</li>
<li>Reduce margin for less conservative gating</li>
<li>Increase sampling (<math-renderer data-run-id="ac53eaeccbd3c97d7d65498825429120">$n=7-10$</math-renderer>) for stability</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Provide Evidence</strong></p>
<ul dir="auto">
<li>Adding compact, relevant evidence increases <math-renderer data-run-id="ac53eaeccbd3c97d7d65498825429120">$\bar{\Delta}$</math-renderer> while preserving bounds</li>
</ul>
</li>
</ol>
<hr/>
<div dir="auto"><h2 tabindex="-1" dir="auto">Two Ways to Build Rolling Priors</h2><a id="user-content-two-ways-to-build-rolling-priors" aria-label="Permalink: Two Ways to Build Rolling Priors" href="#two-ways-to-build-rolling-priors"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">1) Evidence-based (when you have context)</h3><a id="user-content-1-evidence-based-when-you-have-context" aria-label="Permalink: 1) Evidence-based (when you have context)" href="#1-evidence-based-when-you-have-context"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li><strong>Prompt</strong> contains a field like <code>Evidence:</code> (or JSON keys)</li>
<li><strong>Skeletons</strong> erase the evidence content but preserve structure and roles; then permute blocks deterministically (seeded)</li>
<li><strong>Decision head</strong>: &#34;Answer only if the provided evidence is sufficient; otherwise refuse.&#34;</li>
</ul>
<p dir="auto"><strong>Example</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="from scripts.hallucination_toolkit import OpenAIBackend, OpenAIItem, OpenAIPlanner

backend = OpenAIBackend(model=&#34;gpt-4o-mini&#34;)
prompt = (
    &#34;&#34;&#34;Task: Answer strictly based on the evidence below.
Question: Who won the Nobel Prize in Physics in 2019?
Evidence:
- Nobel Prize press release (2019): James Peebles (1/2); Michel Mayor &amp; Didier Queloz (1/2).
Constraints: If evidence is insufficient or conflicting, refuse.
&#34;&#34;&#34;
)
item = OpenAIItem(
    prompt=prompt, 
    n_samples=5, 
    m=6, 
    fields_to_erase=[&#34;Evidence&#34;], 
    skeleton_policy=&#34;auto&#34;
)
planner = OpenAIPlanner(backend, temperature=0.3)
metrics = planner.run(
    [item], 
    h_star=0.05, 
    isr_threshold=1.0, 
    margin_extra_bits=0.2, 
    B_clip=12.0, 
    clip_mode=&#34;one-sided&#34;
)
for m in metrics: 
    print(f&#34;Decision: {&#39;ANSWER&#39; if m.decision_answer else &#39;REFUSE&#39;}&#34;)
    print(f&#34;Rationale: {m.rationale}&#34;)"><pre><span>from</span> <span>scripts</span>.<span>hallucination_toolkit</span> <span>import</span> <span>OpenAIBackend</span>, <span>OpenAIItem</span>, <span>OpenAIPlanner</span>

<span>backend</span> <span>=</span> <span>OpenAIBackend</span>(<span>model</span><span>=</span><span>&#34;gpt-4o-mini&#34;</span>)
<span>prompt</span> <span>=</span> (
    <span>&#34;&#34;&#34;Task: Answer strictly based on the evidence below.</span>
<span>Question: Who won the Nobel Prize in Physics in 2019?</span>
<span>Evidence:</span>
<span>- Nobel Prize press release (2019): James Peebles (1/2); Michel Mayor &amp; Didier Queloz (1/2).</span>
<span>Constraints: If evidence is insufficient or conflicting, refuse.</span>
<span>&#34;&#34;&#34;</span>
)
<span>item</span> <span>=</span> <span>OpenAIItem</span>(
    <span>prompt</span><span>=</span><span>prompt</span>, 
    <span>n_samples</span><span>=</span><span>5</span>, 
    <span>m</span><span>=</span><span>6</span>, 
    <span>fields_to_erase</span><span>=</span>[<span>&#34;Evidence&#34;</span>], 
    <span>skeleton_policy</span><span>=</span><span>&#34;auto&#34;</span>
)
<span>planner</span> <span>=</span> <span>OpenAIPlanner</span>(<span>backend</span>, <span>temperature</span><span>=</span><span>0.3</span>)
<span>metrics</span> <span>=</span> <span>planner</span>.<span>run</span>(
    [<span>item</span>], 
    <span>h_star</span><span>=</span><span>0.05</span>, 
    <span>isr_threshold</span><span>=</span><span>1.0</span>, 
    <span>margin_extra_bits</span><span>=</span><span>0.2</span>, 
    <span>B_clip</span><span>=</span><span>12.0</span>, 
    <span>clip_mode</span><span>=</span><span>&#34;one-sided&#34;</span>
)
<span>for</span> <span>m</span> <span>in</span> <span>metrics</span>: 
    <span>print</span>(<span>f&#34;Decision: <span><span>{</span><span>&#39;ANSWER&#39;</span> <span>if</span> <span>m</span>.<span>decision_answer</span> <span>else</span> <span>&#39;REFUSE&#39;</span><span>}</span></span>&#34;</span>)
    <span>print</span>(<span>f&#34;Rationale: <span><span>{</span><span>m</span>.<span>rationale</span><span>}</span></span>&#34;</span>)</pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">2) Closed-book (no evidence)</h3><a id="user-content-2-closed-book-no-evidence" aria-label="Permalink: 2) Closed-book (no evidence)" href="#2-closed-book-no-evidence"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li><strong>Prompt</strong> has no evidence</li>
<li><strong>Skeletons</strong> apply <strong>semantic masking</strong> of:
<ul dir="auto">
<li>Multi-word proper nouns (e.g., &#34;James Peebles&#34; → &#34;[…]&#34;)</li>
<li>Years (e.g., &#34;2019&#34; → &#34;[…]&#34;)</li>
<li>Numbers (e.g., &#34;3.14&#34; → &#34;[…]&#34;)</li>
<li>Quoted spans (e.g., &#39;&#34;Nobel Prize&#34;&#39; → &#34;[…]&#34;)</li>
</ul>
</li>
<li><strong>Masking strengths</strong>: Progressive levels (0.25, 0.35, 0.5, 0.65, 0.8, 0.9) across skeleton ensemble</li>
<li><strong>Mask-aware decision head</strong> refuses if redaction tokens appear or key slots look missing</li>
</ul>
<p dir="auto"><strong>Example</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="from scripts.hallucination_toolkit import OpenAIBackend, OpenAIItem, OpenAIPlanner

backend = OpenAIBackend(model=&#34;gpt-4o-mini&#34;)
item = OpenAIItem(
    prompt=&#34;Who won the 2019 Nobel Prize in Physics?&#34;,
    n_samples=7,  # More samples for stability
    m=6,          # Number of skeletons
    skeleton_policy=&#34;closed_book&#34;
)
planner = OpenAIPlanner(backend, temperature=0.3, q_floor=None)
metrics = planner.run(
    [item], 
    h_star=0.05,           # Target max 5% hallucination
    isr_threshold=1.0,     # Standard ISR gate
    margin_extra_bits=0.2, # Safety margin in nats
    B_clip=12.0,          # Clipping bound
    clip_mode=&#34;one-sided&#34; # Conservative clipping
)
for m in metrics: 
    print(f&#34;Decision: {&#39;ANSWER&#39; if m.decision_answer else &#39;REFUSE&#39;}&#34;)
    print(f&#34;Δ̄={m.delta_bar:.4f}, B2T={m.b2t:.4f}, ISR={m.isr:.3f}&#34;)
    print(f&#34;EDFL RoH bound={m.roh_bound:.3f}&#34;)"><pre><span>from</span> <span>scripts</span>.<span>hallucination_toolkit</span> <span>import</span> <span>OpenAIBackend</span>, <span>OpenAIItem</span>, <span>OpenAIPlanner</span>

<span>backend</span> <span>=</span> <span>OpenAIBackend</span>(<span>model</span><span>=</span><span>&#34;gpt-4o-mini&#34;</span>)
<span>item</span> <span>=</span> <span>OpenAIItem</span>(
    <span>prompt</span><span>=</span><span>&#34;Who won the 2019 Nobel Prize in Physics?&#34;</span>,
    <span>n_samples</span><span>=</span><span>7</span>,  <span># More samples for stability</span>
    <span>m</span><span>=</span><span>6</span>,          <span># Number of skeletons</span>
    <span>skeleton_policy</span><span>=</span><span>&#34;closed_book&#34;</span>
)
<span>planner</span> <span>=</span> <span>OpenAIPlanner</span>(<span>backend</span>, <span>temperature</span><span>=</span><span>0.3</span>, <span>q_floor</span><span>=</span><span>None</span>)
<span>metrics</span> <span>=</span> <span>planner</span>.<span>run</span>(
    [<span>item</span>], 
    <span>h_star</span><span>=</span><span>0.05</span>,           <span># Target max 5% hallucination</span>
    <span>isr_threshold</span><span>=</span><span>1.0</span>,     <span># Standard ISR gate</span>
    <span>margin_extra_bits</span><span>=</span><span>0.2</span>, <span># Safety margin in nats</span>
    <span>B_clip</span><span>=</span><span>12.0</span>,          <span># Clipping bound</span>
    <span>clip_mode</span><span>=</span><span>&#34;one-sided&#34;</span> <span># Conservative clipping</span>
)
<span>for</span> <span>m</span> <span>in</span> <span>metrics</span>: 
    <span>print</span>(<span>f&#34;Decision: <span><span>{</span><span>&#39;ANSWER&#39;</span> <span>if</span> <span>m</span>.<span>decision_answer</span> <span>else</span> <span>&#39;REFUSE&#39;</span><span>}</span></span>&#34;</span>)
    <span>print</span>(<span>f&#34;Δ̄=<span><span>{</span><span>m</span>.<span>delta_bar</span>:.4f<span>}</span></span>, B2T=<span><span>{</span><span>m</span>.<span>b2t</span>:.4f<span>}</span></span>, ISR=<span><span>{</span><span>m</span>.<span>isr</span>:.3f<span>}</span></span>&#34;</span>)
    <span>print</span>(<span>f&#34;EDFL RoH bound=<span><span>{</span><span>m</span>.<span>roh_bound</span>:.3f<span>}</span></span>&#34;</span>)</pre></div>
<p dir="auto"><strong>Tuning knobs (closed-book):</strong></p>
<ul dir="auto">
<li>
<code>n_samples=5–7</code> and <code>temperature≈0.3</code> stabilize priors</li>
<li>
<code>q_floor</code> (Laplace by default: $1/(n+2)$) prevents worst-case prior collapse to 0</li>
<li>Adjust masking strength levels if a task family remains too answerable under masking</li>
</ul>
<hr/>


<ul dir="auto">
<li><code>OpenAIBackend(model, api_key=None)</code> – wraps Chat Completions API</li>
<li><code>OpenAIItem(prompt, n_samples=5, m=6, fields_to_erase=None, skeleton_policy=&#34;auto&#34;)</code> – one evaluation item</li>
<li><code>OpenAIPlanner(backend, temperature=0.5, q_floor=None)</code> – runs evaluation:
<ul dir="auto">
<li><code>run(items, h_star, isr_threshold, margin_extra_bits, B_clip=12.0, clip_mode=&#34;one-sided&#34;) -&gt; List[ItemMetrics]</code></li>
<li><code>aggregate(items, metrics, alpha=0.05, h_star, ...) -&gt; AggregateReport</code></li>
</ul>
</li>
</ul>

<ul dir="auto">
<li><code>make_sla_certificate(report, model_name)</code> – creates formal SLA certificate</li>
<li><code>save_sla_certificate_json(cert, path)</code> – exports certificate for audit</li>
<li><code>generate_answer_if_allowed(backend, item, metric)</code> – only emits answer if decision was ANSWER</li>
</ul>

<p dir="auto">Every <code>ItemMetrics</code> includes:</p>
<ul dir="auto">
<li>
<code>delta_bar</code>: Information budget (nats)</li>
<li>
<code>q_conservative</code>: Worst-case prior <math-renderer data-run-id="ac53eaeccbd3c97d7d65498825429120">$q_{\text{lo}}$</math-renderer>
</li>
<li>
<code>q_avg</code>: Average prior <math-renderer data-run-id="ac53eaeccbd3c97d7d65498825429120">$\bar{q}$</math-renderer>
</li>
<li>
<code>b2t</code>: Bits-to-Trust requirement</li>
<li>
<code>isr</code>: Information Sufficiency Ratio</li>
<li>
<code>roh_bound</code>: EDFL hallucination risk bound</li>
<li>
<code>decision_answer</code>: Boolean decision</li>
<li>
<code>rationale</code>: Human-readable explanation</li>
<li>
<code>meta</code>: Dict with <code>q_list</code>, <code>S_list_y</code>, <code>P_y</code>, <code>closed_book</code>, etc.</li>
</ul>
<hr/>

<div dir="auto"><h3 tabindex="-1" dir="auto">Validation Set Calibration</h3><a id="user-content-validation-set-calibration" aria-label="Permalink: Validation Set Calibration" href="#validation-set-calibration"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">On a labeled validation set:</p>
<ol dir="auto">
<li>
<strong>Sweep the margin</strong> parameter from 0 to 1 nats</li>
<li>For each margin, compute:
<ul dir="auto">
<li>Empirical hallucination rate among answered items</li>
<li>Wilson upper bound at 95% confidence</li>
</ul>
</li>
<li>
<strong>Select smallest margin</strong> where Wilson upper bound ≤ target <math-renderer data-run-id="ac53eaeccbd3c97d7d65498825429120">$h^*$</math-renderer> (e.g., 5%)</li>
<li>
<strong>Freeze policy</strong>: <math-renderer data-run-id="ac53eaeccbd3c97d7d65498825429120">$(h^*, \tau, \text{margin}, B, \text{clip_mode}, m, r, \text{skeleton_policy})$</math-renderer>
</li>
</ol>

<p dir="auto">The toolkit provides comprehensive metrics:</p>
<ul dir="auto">
<li>Answer/abstention rates</li>
<li>Empirical hallucination rate + Wilson bound</li>
<li>Distribution of per-item EDFL RoH bounds</li>
<li>Worst-case and median risk bounds</li>
<li>Complete audit trail</li>
</ul>
<hr/>


<p dir="auto">The default event is the <strong>decision</strong> <math-renderer data-run-id="ac53eaeccbd3c97d7d65498825429120">$\mathcal{A} = {\text{Answer}}$</math-renderer>. However:</p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Task Type</th>
<th>Recommended Event</th>
<th>Rationale</th>
</tr>
</thead>
<tbody>
<tr>
<td>Factual QA</td>
<td><strong>Correct/Incorrect</strong></td>
<td>Directly measures hallucination</td>
</tr>
<tr>
<td>Decision Support</td>
<td><strong>Answer/Refuse</strong></td>
<td>Measures confidence to respond</td>
</tr>
<tr>
<td>Creative Writing</td>
<td><strong>Answer/Refuse</strong></td>
<td>Correctness often undefined</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto">For tasks where skeletons still trigger answers frequently (causing <math-renderer data-run-id="ac53eaeccbd3c97d7d65498825429120">$\bar{\Delta}\approx0$</math-renderer>), switching to <strong>Correctness</strong> event with task-specific grading dramatically improves performance.</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">Common Issues &amp; Solutions</h3><a id="user-content-common-issues--solutions" aria-label="Permalink: Common Issues &amp; Solutions" href="#common-issues--solutions"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto"><h4 tabindex="-1" dir="auto">Issue: <math-renderer data-run-id="ac53eaeccbd3c97d7d65498825429120">$\bar{\Delta} = 0$</math-renderer> with <math-renderer data-run-id="ac53eaeccbd3c97d7d65498825429120">$\overline{\mathrm{RoH}} \approx 0$</math-renderer>
</h4><a id="user-content-issue-bardelta--0-with-overlinemathrmroh-approx-0" aria-label="Permalink: Issue: $\bar{\Delta} = 0$ with $\overline{\mathrm{RoH}} \approx 0$" href="#issue-bardelta--0-with-overlinemathrmroh-approx-0"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><strong>Not a contradiction!</strong> The gate uses worst-case <math-renderer data-run-id="ac53eaeccbd3c97d7d65498825429120">$q_{\text{lo}}$</math-renderer>; the bound uses average <math-renderer data-run-id="ac53eaeccbd3c97d7d65498825429120">$\bar{q}$</math-renderer>.</p>
<ul dir="auto">
<li><strong>Solution</strong>: Increase <code>n_samples</code>, lower decision temperature, ensure skeletons truly weaken the event</li>
</ul>
<div dir="auto"><h4 tabindex="-1" dir="auto">Issue: Hit a low <math-renderer data-run-id="ac53eaeccbd3c97d7d65498825429120">$\bar{\Delta}$</math-renderer> ceiling</h4><a id="user-content-issue-hit-a-low-bardelta-ceiling" aria-label="Permalink: Issue: Hit a low $\bar{\Delta}$ ceiling" href="#issue-hit-a-low-bardelta-ceiling"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><strong>Cause</strong>: Clipping may be too aggressive</p>
<ul dir="auto">
<li><strong>Solution</strong>: Increase <code>B_clip</code> (default 12) and use <code>clip_mode=&#34;one-sided&#34;</code></li>
</ul>
<div dir="auto"><h4 tabindex="-1" dir="auto">Issue: Arithmetic still refuses</h4><a id="user-content-issue-arithmetic-still-refuses" aria-label="Permalink: Issue: Arithmetic still refuses" href="#issue-arithmetic-still-refuses"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><strong>Cause</strong>: Pattern recognition allows answers even with masked numbers</p>
<ul dir="auto">
<li><strong>Solutions</strong>:
<ul dir="auto">
<li>Switch to <strong>Correctness</strong> event</li>
<li>Reduce masking strength for numbers on subset of skeletons</li>
<li>Provide worked examples as evidence</li>
</ul>
</li>
</ul>
<div dir="auto"><h4 tabindex="-1" dir="auto">Issue: Prior collapse (<math-renderer data-run-id="ac53eaeccbd3c97d7d65498825429120">$q_{\text{lo}} \to 0$</math-renderer>)</h4><a id="user-content-issue-prior-collapse-q_textlo-to-0" aria-label="Permalink: Issue: Prior collapse ($q_{\text{lo}} \to 0$)" href="#issue-prior-collapse-q_textlo-to-0"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><strong>Cause</strong>: All skeletons strongly refuse</p>
<ul dir="auto">
<li>
<strong>Solution</strong>: Apply prior floor (default Laplace: $1/(n+2)$) or use quantile prior</li>
</ul>
<div dir="auto"><h3 tabindex="-1" dir="auto">Performance Characteristics</h3><a id="user-content-performance-characteristics" aria-label="Permalink: Performance Characteristics" href="#performance-characteristics"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Metric</th>
<th>Typical Value</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td>Latency per item</td>
<td>2-5 seconds</td>
<td>7 samples × 7 variants (1 full + 6 skeletons)</td>
</tr>
<tr>
<td>API calls</td>
<td><math-renderer data-run-id="ac53eaeccbd3c97d7d65498825429120">$(1+m) \times \lceil n/\text{batch}\rceil$</math-renderer></td>
<td>Can be parallelized</td>
</tr>
<tr>
<td>Accuracy</td>
<td>Wilson-bounded at 95%</td>
<td>Empirically validated</td>
</tr>
<tr>
<td>Cost</td>
<td>~$0.01-0.03 per item</td>
<td>Using gpt-4o-mini</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>

<ol dir="auto">
<li>
<p dir="auto"><strong>Sampling parameters</strong>:</p>
<ul dir="auto">
<li>Use <math-renderer data-run-id="ac53eaeccbd3c97d7d65498825429120">$n \ge 5$</math-renderer> samples per variant</li>
<li>Keep temperature <math-renderer data-run-id="ac53eaeccbd3c97d7d65498825429120">$\in [0.2, 0.5]$</math-renderer> for decision head</li>
<li>Lower temperature → more stable priors</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Skeleton ensemble</strong>:</p>
<ul dir="auto">
<li>Use <math-renderer data-run-id="ac53eaeccbd3c97d7d65498825429120">$m \ge 6$</math-renderer> skeletons</li>
<li>Ensure diversity in masking strengths</li>
<li>Verify skeletons are meaningfully weaker</li>
</ul>
</li>
<li>
<p dir="auto"><strong>Clipping strategy</strong>:</p>
<ul dir="auto">
<li>Always use one-sided clipping for conservative bounds</li>
<li>Set <math-renderer data-run-id="ac53eaeccbd3c97d7d65498825429120">$B \ge 10$</math-renderer> nats to avoid artificial ceilings</li>
<li>Monitor clipping frequency in logs</li>
</ul>
</li>
</ol>
<hr/>

<div data-snippet-clipboard-copy-content=".
├── app/                    # Application entry points
│   ├── web/web_app.py     # Streamlit UI
│   ├── cli/frontend.py    # Interactive CLI
│   ├── examples/          # Example scripts
│   └── launcher/entry.py  # Unified launcher
├── scripts/               # Core module
│   ├── hallucination_toolkit.py
│   └── build_offline_backend.sh
├── electron/              # Desktop wrapper
├── launch/                # Platform launchers
├── release/              # Packaged artifacts
├── bin/                  # Offline backend binary
├── requirements.txt
├── pyproject.toml
└── README.md"><pre><code>.
├── app/                    # Application entry points
│   ├── web/web_app.py     # Streamlit UI
│   ├── cli/frontend.py    # Interactive CLI
│   ├── examples/          # Example scripts
│   └── launcher/entry.py  # Unified launcher
├── scripts/               # Core module
│   ├── hallucination_toolkit.py
│   └── build_offline_backend.sh
├── electron/              # Desktop wrapper
├── launch/                # Platform launchers
├── release/              # Packaged artifacts
├── bin/                  # Offline backend binary
├── requirements.txt
├── pyproject.toml
└── README.md
</code></pre></div>
<hr/>


<div dir="auto" data-snippet-clipboard-copy-content="from scripts.hallucination_toolkit import (
    OpenAIBackend, OpenAIItem, OpenAIPlanner,
    make_sla_certificate, save_sla_certificate_json
)

# Configure and run
backend = OpenAIBackend(model=&#34;gpt-4o-mini&#34;)
items = [OpenAIItem(prompt=&#34;...&#34;, n_samples=7, m=6)]
planner = OpenAIPlanner(backend, temperature=0.3)
metrics = planner.run(items, h_star=0.05)

# Generate SLA certificate
report = planner.aggregate(items, metrics)
cert = make_sla_certificate(report, model_name=&#34;GPT-4o-mini&#34;)
save_sla_certificate_json(cert, &#34;sla.json&#34;)"><pre><span>from</span> <span>scripts</span>.<span>hallucination_toolkit</span> <span>import</span> (
    <span>OpenAIBackend</span>, <span>OpenAIItem</span>, <span>OpenAIPlanner</span>,
    <span>make_sla_certificate</span>, <span>save_sla_certificate_json</span>
)

<span># Configure and run</span>
<span>backend</span> <span>=</span> <span>OpenAIBackend</span>(<span>model</span><span>=</span><span>&#34;gpt-4o-mini&#34;</span>)
<span>items</span> <span>=</span> [<span>OpenAIItem</span>(<span>prompt</span><span>=</span><span>&#34;...&#34;</span>, <span>n_samples</span><span>=</span><span>7</span>, <span>m</span><span>=</span><span>6</span>)]
<span>planner</span> <span>=</span> <span>OpenAIPlanner</span>(<span>backend</span>, <span>temperature</span><span>=</span><span>0.3</span>)
<span>metrics</span> <span>=</span> <span>planner</span>.<span>run</span>(<span>items</span>, <span>h_star</span><span>=</span><span>0.05</span>)

<span># Generate SLA certificate</span>
<span>report</span> <span>=</span> <span>planner</span>.<span>aggregate</span>(<span>items</span>, <span>metrics</span>)
<span>cert</span> <span>=</span> <span>make_sla_certificate</span>(<span>report</span>, <span>model_name</span><span>=</span><span>&#34;GPT-4o-mini&#34;</span>)
<span>save_sla_certificate_json</span>(<span>cert</span>, <span>&#34;sla.json&#34;</span>)</pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">2. Web Interface (Streamlit)</h3><a id="user-content-2-web-interface-streamlit" aria-label="Permalink: 2. Web Interface (Streamlit)" href="#2-web-interface-streamlit"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto" data-snippet-clipboard-copy-content="streamlit run app/web/web_app.py"><pre>streamlit run app/web/web_app.py</pre></div>

<ul dir="auto">
<li><strong>Windows</strong>: Double-click <code>launch/Launch App.bat</code></li>
<li><strong>macOS</strong>: Double-click <code>launch/Launch App.command</code></li>
<li><strong>Linux</strong>: Run <code>bash launch/launch.sh</code></li>
</ul>
<p dir="auto">First run creates <code>.venv</code> and installs dependencies automatically.</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">4. Desktop App (Electron)</h3><a id="user-content-4-desktop-app-electron" aria-label="Permalink: 4. Desktop App (Electron)" href="#4-desktop-app-electron"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Development:</p>
<div dir="auto" data-snippet-clipboard-copy-content="cd electron
npm install
npm run start"><pre><span>cd</span> electron
npm install
npm run start</pre></div>
<p dir="auto">Build installers:</p>

<div dir="auto"><h3 tabindex="-1" dir="auto">5. Offline Backend (PyInstaller)</h3><a id="user-content-5-offline-backend-pyinstaller" aria-label="Permalink: 5. Offline Backend (PyInstaller)" href="#5-offline-backend-pyinstaller"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Build single-file executable:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# macOS/Linux
bash scripts/build_offline_backend.sh

# Windows
scripts\build_offline_backend.bat"><pre><span><span>#</span> macOS/Linux</span>
bash scripts/build_offline_backend.sh

<span><span>#</span> Windows</span>
scripts<span>\b</span>uild_offline_backend.bat</pre></div>
<p dir="auto">Creates <code>bin/hallucination-backend[.exe]</code> with bundled Python, Streamlit, and dependencies.</p>
<hr/>
<div dir="auto"><h2 tabindex="-1" dir="auto">Minimal End-to-End Example</h2><a id="user-content-minimal-end-to-end-example" aria-label="Permalink: Minimal End-to-End Example" href="#minimal-end-to-end-example"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto" data-snippet-clipboard-copy-content="from scripts.hallucination_toolkit import (
    OpenAIBackend, OpenAIItem, OpenAIPlanner,
    make_sla_certificate, save_sla_certificate_json,
    generate_answer_if_allowed
)

# Setup
backend = OpenAIBackend(model=&#34;gpt-4o-mini&#34;)

# Prepare items
items = [
    OpenAIItem(
        prompt=&#34;Who won the 2019 Nobel Prize in Physics?&#34;,
        n_samples=7,
        m=6,
        skeleton_policy=&#34;closed_book&#34;
    ),
    OpenAIItem(
        prompt=&#34;If James has 5 apples and eats 3, how many remain?&#34;,
        n_samples=7,
        m=6,
        skeleton_policy=&#34;closed_book&#34;
    )
]

# Run evaluation
planner = OpenAIPlanner(backend, temperature=0.3)
metrics = planner.run(
    items,
    h_star=0.05,           # Target 5% hallucination max
    isr_threshold=1.0,     # Standard threshold
    margin_extra_bits=0.2, # Safety margin
    B_clip=12.0,          # Clipping bound
    clip_mode=&#34;one-sided&#34; # Conservative mode
)

# Generate report and certificate
report = planner.aggregate(items, metrics, alpha=0.05, h_star=0.05)
cert = make_sla_certificate(report, model_name=&#34;GPT-4o-mini&#34;)
save_sla_certificate_json(cert, &#34;sla_certificate.json&#34;)

# Show results
for item, m in zip(items, metrics):
    print(f&#34;\nPrompt: {item.prompt[:50]}...&#34;)
    print(f&#34;Decision: {&#39;ANSWER&#39; if m.decision_answer else &#39;REFUSE&#39;}&#34;)
    print(f&#34;Risk bound: {m.roh_bound:.3f}&#34;)
    print(f&#34;Rationale: {m.rationale}&#34;)
    
    # Generate answer if allowed
    if m.decision_answer:
        answer = generate_answer_if_allowed(backend, item, m)
        print(f&#34;Answer: {answer}&#34;)"><pre><span>from</span> <span>scripts</span>.<span>hallucination_toolkit</span> <span>import</span> (
    <span>OpenAIBackend</span>, <span>OpenAIItem</span>, <span>OpenAIPlanner</span>,
    <span>make_sla_certificate</span>, <span>save_sla_certificate_json</span>,
    <span>generate_answer_if_allowed</span>
)

<span># Setup</span>
<span>backend</span> <span>=</span> <span>OpenAIBackend</span>(<span>model</span><span>=</span><span>&#34;gpt-4o-mini&#34;</span>)

<span># Prepare items</span>
<span>items</span> <span>=</span> [
    <span>OpenAIItem</span>(
        <span>prompt</span><span>=</span><span>&#34;Who won the 2019 Nobel Prize in Physics?&#34;</span>,
        <span>n_samples</span><span>=</span><span>7</span>,
        <span>m</span><span>=</span><span>6</span>,
        <span>skeleton_policy</span><span>=</span><span>&#34;closed_book&#34;</span>
    ),
    <span>OpenAIItem</span>(
        <span>prompt</span><span>=</span><span>&#34;If James has 5 apples and eats 3, how many remain?&#34;</span>,
        <span>n_samples</span><span>=</span><span>7</span>,
        <span>m</span><span>=</span><span>6</span>,
        <span>skeleton_policy</span><span>=</span><span>&#34;closed_book&#34;</span>
    )
]

<span># Run evaluation</span>
<span>planner</span> <span>=</span> <span>OpenAIPlanner</span>(<span>backend</span>, <span>temperature</span><span>=</span><span>0.3</span>)
<span>metrics</span> <span>=</span> <span>planner</span>.<span>run</span>(
    <span>items</span>,
    <span>h_star</span><span>=</span><span>0.05</span>,           <span># Target 5% hallucination max</span>
    <span>isr_threshold</span><span>=</span><span>1.0</span>,     <span># Standard threshold</span>
    <span>margin_extra_bits</span><span>=</span><span>0.2</span>, <span># Safety margin</span>
    <span>B_clip</span><span>=</span><span>12.0</span>,          <span># Clipping bound</span>
    <span>clip_mode</span><span>=</span><span>&#34;one-sided&#34;</span> <span># Conservative mode</span>
)

<span># Generate report and certificate</span>
<span>report</span> <span>=</span> <span>planner</span>.<span>aggregate</span>(<span>items</span>, <span>metrics</span>, <span>alpha</span><span>=</span><span>0.05</span>, <span>h_star</span><span>=</span><span>0.05</span>)
<span>cert</span> <span>=</span> <span>make_sla_certificate</span>(<span>report</span>, <span>model_name</span><span>=</span><span>&#34;GPT-4o-mini&#34;</span>)
<span>save_sla_certificate_json</span>(<span>cert</span>, <span>&#34;sla_certificate.json&#34;</span>)

<span># Show results</span>
<span>for</span> <span>item</span>, <span>m</span> <span>in</span> <span>zip</span>(<span>items</span>, <span>metrics</span>):
    <span>print</span>(<span>f&#34;<span>\n</span>Prompt: <span><span>{</span><span>item</span>.<span>prompt</span>[:<span>50</span>]<span>}</span></span>...&#34;</span>)
    <span>print</span>(<span>f&#34;Decision: <span><span>{</span><span>&#39;ANSWER&#39;</span> <span>if</span> <span>m</span>.<span>decision_answer</span> <span>else</span> <span>&#39;REFUSE&#39;</span><span>}</span></span>&#34;</span>)
    <span>print</span>(<span>f&#34;Risk bound: <span><span>{</span><span>m</span>.<span>roh_bound</span>:.3f<span>}</span></span>&#34;</span>)
    <span>print</span>(<span>f&#34;Rationale: <span><span>{</span><span>m</span>.<span>rationale</span><span>}</span></span>&#34;</span>)
    
    <span># Generate answer if allowed</span>
    <span>if</span> <span>m</span>.<span>decision_answer</span>:
        <span>answer</span> <span>=</span> <span>generate_answer_if_allowed</span>(<span>backend</span>, <span>item</span>, <span>m</span>)
        <span>print</span>(<span>f&#34;Answer: <span><span>{</span><span>answer</span><span>}</span></span>&#34;</span>)</pre></div>

<p dir="auto">This project is licensed under the MIT License — see the LICENSE file for details.</p>

<p dir="auto">Developed by Hassana Labs (<a href="https://hassana.io" rel="nofollow">https://hassana.io</a>).</p>
<p dir="auto">This implementation follows the framework from the paper “Compression Failure in LLMs: Bayesian in Expectation, Not in Realization” (NeurIPS 2024 preprint) and related EDFL/ISR/B2T methodology.</p>
</article></div></div>
  </body>
</html>
