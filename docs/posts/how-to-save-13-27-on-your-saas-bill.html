<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://dgerrells.com/blog/how-to-save-13-27-on-your-saas-bill">Original</a>
    <h1>How to save $13.27 on your SaaS bill</h1>
    
    <div id="readability-page-1" class="page"><div><p><img src="https://dgerrells.com/images/vercelanal.jpg" alt="vercel example analytics dashboard showing great stats"/></p>
<p>I decided to try out Vercel&#39;s analytics product on a newly minted pro plan, it included some 25k events.</p>
<p>You see, I had to start paying Vercel $ as more than 20 people visited my website. I had been using massive png images on a few high traffic pages which ate up my free outbound data. This is because the default format of taking a snippet on a Mac is a png. It is also because I didn&#39;t want to pay Vercel to make all 12 of my website&#39;s images go fast. I figured it wouldn&#39;t matter. I don&#39;t get much traffic.</p>
<blockquote>
<p>Fast forward 4 years.</p>
</blockquote>
<p>Well it did matter. And here I sit looking the fool as I humbly type my CC info into Vercel&#39;s payment form. How did I solve the issue? Did I integrate Vercel&#39;s images? Did I use an alternative cdn? No, I just converted the 2 worst offenders to jpgs and rewarded myself with another sip of coffee for a job well done. Clearly a decision the past me from four years ago would approve of.</p>
<p>I read Vercel&#39;s analytics marketing and pricing pages. 25k events are included with pro and $14 per 100k after. Seems pricey but I can cancel if I use up my quota. All good. Let&#39;s implement it.</p>
<p>I have used google, datadog, segment, and a few other client side offerings and came with expectations. It should be easy to implement and Vercel delivered. It took two lines of code since this is an older vercel project that used both the app and page routers.</p>
<pre><code>&lt;Analytics /&gt;
</code></pre>
<p>With a push to production it is live. Nice. I think it took all of 60 seconds. The dashboard view is decent. It has about what I am looking for. Popular urls, total visiters, browsers, country, all good stuff. There is some additional depth I&#39;d like to see but it lives behind a prestigious super pro analytics tier that costs even more. That is ok though. The traffic is barely eating into the 25k quota though so I am happy. Good stuff.</p>
<h2>1 week later</h2>
<p><img src="https://dgerrells.com/images/usagewarningvercel.jpg" alt="vercel warning about too much usage"/></p><p>You can guess where this went. No, not a big bill. Only $28. Surely though. Surely!!! There has to be a better way. And no, I am not thinking of the latest trending analytics sAAs vendor nor the resident OSS tool&#39;s managed cloud offering from the project&#39;s maintainers.</p>
<p>I live on the edge, the edge of the network, the browser, the bleeding edge. Everything must be serverless, multi-region, edge delivered, eventually consistent, strongly typed, ACID compliant, point in time recovery, buzzword buzzword, and buzzword bazzword. In the noise, if one listens closely, an echo can be heard. Old backend engineers from long long ago in the before time whisper of sacrilege. They use words like &#34;htmx&#34;, &#34;monolith&#34;, and &#34;OOP&#34;. Usually I ignore the whispers like we do but one word kept coming up. It stayed with me. Day after day. Month after month. Taunting me. &#34;sqlite&#34;.</p>
<p>We have been spoiled by the Vercel&#39;s of the world, the heroku&#39;s too, and even dare I say, the Salesforces. My infra game is weak. I thought it would be a fun challenge and good practice to try and save a few $ on my Vercy bill by building an analytics api from scratch using a new stack. A stack so bleeding edge that the edge lords have only just now heard of it.</p>
<h2>the squeeh stack</h2>
<p>The Squeeh stack is a new stack I just created 15 seconds ago. What is the Squeeh stack you ask? Well I am glad you asked. Any app which uses sqlite for data counts as a <code>Squeeh Stack</code><span>tm</span>.</p>
<ul>
<li>flask + sqlite + psql? <strong>squeeh stack!</strong></li>
<li>node + sqlite + hono + cloudflare? <strong>squeeh stack!!!</strong></li>
<li>unity + sqlite? <strong>squeeh snack!</strong></li>
<li>swift + tim apple + sqlite? <strong>yup also squeeh stack!</strong></li>
</ul>
<p>Sqlite may be the worst possible option for an analytics service but I keep hearing people saying it is fast. I have never used it though. People on the internet are generally a trustworthy bunch so I am going to trust them and use it. I am going to use bun and hono as the api layer. Bun because it has a delicious looking mascot and Hono because I saw this video where a guy said Hono and it made me laugh. I don&#39;t know why. I had never heard of Hono until then.</p>
<p>It didn&#39;t take long to get an api setup locally. A simple schema with a <code>db.ts</code> script creates the table. I am skipping migrations and other data best practices. No daily backups, snapshots, point in time recovery. Capturing the data is more important at this point.</p>
<pre><code>app.post(<span>&#34;/analytics&#34;</span>, <span>async</span> (c) =&gt; {
  <span>try</span> {
    <span>const</span> data = <span>await</span> c.req.json();
    insertLog(data);
    <span>return</span> c.json({ message: <span>&#34;Event logged&#34;</span> }, <span>201</span>);
  } <span>catch</span> (error) {
    <span>console</span>.error(<span>&#34;Error logging analytics:&#34;</span>, error);
    <span>return</span> c.json({ error: <span>&#34;Internal Server Error&#34;</span> }, <span>500</span>);
  }
});
</code></pre>
<p>It is time to get a gut check on how much sqlite could handle before continuing. It isn&#39;t that I don&#39;t trust the internet but you know, better to check now.</p>
<p>Gypity gave a pretty simple load test script using <code>hey</code>. I removed the useless comments and ran it.</p>
<pre><code>URL=&#34;http://localhost:3000/analytics&#34;
DURATION=&#34;30s&#34;
CONCURRENT_REQUESTS=10
TOTAL_REQUESTS=10000

DATA=&#39;{
  &#34;time&#34;: &#34;2024-07-23T15:12:20.53Z&#34;,
  &#34;status_code&#34;: 200,
  &#34;status_text&#34;: &#34;OK&#34;,
  &#34;host&#34;: &#34;example.com&#34;,
  &#34;request_path&#34;: &#34;/some/path&#34;,
  &#34;request_id&#34;: &#34;abc123&#34;,
  &#34;request_user_agent&#34;: &#34;Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36&#34;,
  &#34;level&#34;: &#34;Info&#34;,
  &#34;environment&#34;: &#34;production&#34;,
  &#34;location&#34;: &#34;New York, USA&#34;,
  &#34;ip_address&#34;: &#34;203.0.113.1&#34;
}&#39;

hey -m POST -d &#34;$DATA&#34; -H &#34;Content-Type: application/json&#34; -c $CONCURRENT_REQUESTS -n $TOTAL_REQUESTS $URL
</code></pre>
<p>The first test ran fine.</p>
<pre><code>Summary:
  Total:        0.4716 secs
  Slowest:      0.0220 secs
  Fastest:      0.0000 secs
  Average:      0.0005 secs
  Requests/sec: 21204.8583

  Total data:   260000 bytes
  Size/request: 26 bytes
  ---------------------
</code></pre>
<p>I have no idea if that is a good result. Better bump it up to 1m requests and see how it does. I will also start another process running some reads against the same file to see what happens there.</p>
<p>And I get some locks and a few dozen failed requests. Adding the <code>WAL</code> pragma seems to fix the locking issue.</p>
<p><code>db.exec(&#34;PRAGMA journal_mode = WAL;&#34;);</code></p>
<p>Now that I am thoroughly distracted from the original goal time to fixate on making this number go up. I could buy a more powerful computer but batching the inserts would be cheaper. I wrote a function to do this for me.</p>
<pre><code><span>const</span> insertAnalytics = db.prepare(<span>`
  INSERT INTO analytics (
    data
  ) VALUES (many question marks)
`</span>);

<span>const</span> transact = db.transaction(<span>(<span>logs</span>) =&gt;</span> {
  <span>for</span> (<span>const</span> log <span>of</span> logs) {
    insertAnalytics.run(...orderSpecificLogFields);
  }
  <span>return</span> logs.length;
});
</code></pre>
<p>To gather the events before a batch I kept it stupid simple.</p>
<pre><code><span>let</span> activeLogBuffer: <span>any</span>[] = [];
<span>let</span> isActiveWrite = <span>false</span>;

<span><span>function</span> <span>backgroundPersist</span>(<span></span>) </span>{
  <span>if</span> (activeLogBuffer.length === <span>0</span> || isActiveWrite) <span>return</span>;
  <span>try</span> {
    <span>const</span> tempLogs = activeLogBuffer;
    activeLogBuffer = [];
    isActiveWrite = <span>true</span>;
    <span>const</span> count = transact(tempLogs);
    <span>console</span>.log(<span>`inserted <span>${count}</span> events`</span>);
  } <span>catch</span> (e) {
    <span>console</span>.error(<span>&#34;batch insert error events dropped&#34;</span>, e);
  }
  isActiveWrite = <span>false</span>;
}

<span>setInterval</span>(backgroundPersist, <span>20</span>);

app.post(<span>&#34;/analytics&#34;</span>, <span>async</span> (c) =&gt; {
  <span>try</span> {
    <span>const</span> data = <span>await</span> c.req.json();
    activeLogBuffer.push(data);
    <span>return</span> c.json({ message: <span>&#34;Event logged&#34;</span> }, <span>201</span>);
  } <span>catch</span> (error) {
    <span>console</span>.error(<span>&#34;Error logging analytics:&#34;</span>, error);
    <span>return</span> c.json({ error: <span>&#34;Internal Server Error&#34;</span> }, <span>500</span>);
  }
});
</code></pre>
<p>This is great as I can also return a response before the event persists which will prevent blocking until the write completes. I think it is a great idea to take a cue from frontend land and optimistically return an &#34;Event logged&#34; response even though the event has not yet been logged. Let&#39;s load test 100k with a few random read queries in another process.</p>
<pre><code>Summary:
  Total:        2.0621 secs
  Slowest:      0.0093 secs
  Fastest:      0.0000 secs
  Average:      0.0002 secs
  Requests/sec: 48495.3401

  Total data:   2600000 bytes
  Size/request: 26 bytes
</code></pre>
<p>And what about 1m with 20 concurrent requests.</p>
<pre><code>Summary:
  Total:        19.8167 secs
  Slowest:      0.0111 secs
  Fastest:      0.0000 secs
  Average:      0.0004 secs
  Requests/sec: 50462.3789

  Total data:   26000000 bytes
  Size/request: 26 bytes
</code></pre>
<p>There is a pragma to keep the db in-memory but it didn&#39;t seem to make a difference. I also read about how I could include more records per prepared statement which should help a bit more. I have been distracted long enough. This works fine.</p>
<p>Time to deploy it.</p>
<h2>how to get kicked off the ocean</h2>
<p>The api service is stupid simple, getting that api inside a docker container was not. I made the rookie mistake of having skill issues with docker. I tried to a get fancy docker compose file going and I did but it took way too long. I picked DigitalOcean for a VPS host and my expectations were high. While it is possible to have a docklet spin up based on an image pulled from a registry when an action is fired like a merge request, it is also involved. It is even more involved to get a zero downtime deployment going without dipping into more complicated orchestration.</p>
<p>I ended up ditching docker and running everything bare metal. I ssh&#39;d into my VPS and got to work dusting off my admin skills. As I made config changes I built a bash script which should do everything needed to spin up the service on a new machine. Install all the dep, configure nginx with lets encrypt, etc. This took me a long time to do. It&#39;s not hard, just more skill issues. This made deploying changes much easier down the road.</p>
<p>After confirming I could access the remote api I figured I should load test it. I ran the same script and only hit some 250 req/s. I knew something was off though as the cpu and memory barely moved. I ran it again and it started to just hang. The VPS wasn&#39;t doing anything. The bun process was still running with no issues. I thought maybe I didn&#39;t provision enough compute so I bumped up to double the ram and a better processor. I ran the load test again and hit 2k req/s before hanging. The cpu and memory ticked up ever so slightly but then dropped down.</p>
<p>It turns out digital ocean blocked my ip. I can no longer directly ssh in. I have to use the console window from digital ocean&#39;s dashboard. To confirm this I had a friend run my same load test and he too was blocked from accessing that particular ip. Hilarious and it does work. I don&#39;t know how well but nothing like throwing some live traffic at it.</p>
<h2>a poor mans analytics</h2>
<p>The api will sit behind a function on Vercel. There isn&#39;t any auth on the endpoint so I&#39;d rather obfuscate it a bit. I am also going to try and include a bit more information and implement some simple session tracking so I can get a better idea of unique users. Ip address could be used but I want something which will be more reliable. Cookies come to mind but I think an id in <code>localstorage</code> is better. This is the schema I needed to populate.</p>
<pre><code>db.exec(<span>`
  CREATE TABLE IF NOT EXISTS analytics (
    id INTEGER PRIMARY KEY AUTOINCREMENT,
    type TEXT,
    time TEXT,
    status_code INTEGER,
    status_text TEXT,
    host TEXT,
    request_path TEXT,
    request_id TEXT,
    request_user_agent TEXT,
    session_id TEXT,
    os TEXT,
    browser TEXT,
    country TEXT,
    level TEXT,
    environment TEXT,
    location TEXT,
    ip_address TEXT,
    content TEXT,
    referrer TEXT
  )
`</span>);
</code></pre>
<p>Storing a few derived fields from the user agent will make grouping by them much easier. Most of the fields are pretty simple to populate but location/country were trickier. I know that geo information can be included based on ip. To do this you have to setup a local ip lookup db which must be updated every month based on a vendor who kinda has a monopoly in the space. The lookup process can add some overhead. Vercel is suppose to populate the <code>geo</code> field on edge requests. I don&#39;t know why but my website doesn&#39;t run in the edge runtime. I decided to skip the geo lookup step. I can always add an ip lookup later on and run a backfill.</p>
<p>Here is the Vercel function.</p>
<pre><code><span>import</span> { UAParser } <span>from</span> <span>&#34;ua-parser-js&#34;</span>;

<span>const</span> url = process.env.ANALYTICS_API_URL || <span>&#34;fallback&#34;</span>;

<span>export</span> <span>async</span> <span><span>function</span> <span>POST</span>(<span>req</span>) </span>{
  <span>const</span> data = {
    ...requestData,
    
  };

  <span>try</span> {
    <span>const</span> response = <span>await</span> fetch(url, {
      method: <span>&#34;POST&#34;</span>,
      headers: {
        <span>&#34;Content-Type&#34;</span>: <span>&#34;application/json&#34;</span>,
      },
      body: <span>JSON</span>.stringify(data),
    });

    <span>const</span> result = <span>await</span> response.json();
    <span>return</span> <span>new</span> Response(<span>JSON</span>.stringify(result), {
      status: <span>201</span>,
      headers: {
        <span>&#34;Content-Type&#34;</span>: <span>&#34;application/json&#34;</span>,
      },
    });
  } <span>catch</span> (error) {
    
  }
}
</code></pre>
<p>I did want some idea of a country breakdown so I pulled it off the language settings in the browser.</p>
<p>And here is the react hook for that.</p>
<pre><code><span>import</span> { usePathname } <span>from</span> <span>&#34;next/navigation&#34;</span>;
<span>import</span> { useEffect } <span>from</span> <span>&#34;react&#34;</span>;

<span><span>function</span> <span>getSessionId</span>(<span></span>) </span>{
  <span>let</span> sessionId = <span>localStorage</span>.getItem(<span>&#34;sessionId&#34;</span>);
  <span>if</span> (!sessionId) {
    sessionId = <span>`session-<span>${crypto.randomUUID()}</span>`</span>;
    <span>localStorage</span>.setItem(<span>&#34;sessionId&#34;</span>, sessionId);
  }

  <span>return</span> sessionId;
}

<span>export</span> <span>const</span> useAnalytics = <span>() =&gt;</span> {
  <span>const</span> pathname = usePathname();

  useEffect(<span>() =&gt;</span> {
    <span>const</span> logAnalytics = <span>async</span> () =&gt; {
      <span>const</span> country = navigator.language.split(<span>&#34;-&#34;</span>)?.[<span>1</span>] || <span>&#34;Unknown&#34;</span>;
      <span>const</span> data = {
        status_code: <span>200</span>,
        status_text: <span>&#34;OK&#34;</span>,
        request_path: <span>window</span>.location.pathname,
        session_id: getSessionId(),
        referrer: <span>document</span>.referrer,
        <span>type</span>: <span>&#34;page-view&#34;</span>,
        country,
      };

      <span>try</span> {
        <span>await</span> fetch(<span>&#34;/api/analytics&#34;</span>, {
          method: <span>&#34;POST&#34;</span>,
          headers: {
            <span>&#34;Content-Type&#34;</span>: <span>&#34;application/json&#34;</span>,
          },
          body: <span>JSON</span>.stringify(data),
        });
      } <span>catch</span> (error) {
        <span>console</span>.error(<span>&#34;Error logging analytics:&#34;</span>, error);
      }
    };

    logAnalytics();
  }, [pathname]);

  <span>return</span> <span>null</span>;
};
</code></pre>
<p>While this does work and will get the job done. I added support for <code>navigator.sendBeacon</code>, <code>page-leave</code>, and <code>page-return</code> events. It was tricky to get cross browser support since I listen for multiple sources of a &#34;session end&#34; event and didn&#39;t want to double count. A <code>useRef</code> can solve this. If <code>navigator.sendBeacon</code> is not supported, a <code>fetch</code> request is used as a fallback.</p>
<pre><code><span>const</span> pathname = usePathname();
<span>const</span> hasFiredExitEventRef = useRef&lt;<span>boolean</span>&gt;(<span>false</span>);

useEffect(<span>() =&gt;</span> {
  logAnalytics(<span>&#34;page-view&#34;</span>);

  <span>const</span> handleVisibilityChange = <span>(<span>e: <span>any</span></span>) =&gt;</span> {
    <span>if</span> (<span>document</span>.visibilityState === <span>&#34;visible&#34;</span>) {
      logAnalytics(<span>&#34;page-return&#34;</span>);
      hasFiredExitEventRef.current = <span>false</span>;
      <span>return</span>;
    }

    <span>if</span> (hasFiredExitEventRef.current) <span>return</span>;

    <span>if</span> (<span>document</span>.visibilityState === <span>&#34;hidden&#34;</span>) {
      logAnalytics(<span>&#34;page-leave&#34;</span>);
      hasFiredExitEventRef.current = <span>true</span>;
      <span>return</span>;
    }

    <span>if</span> (e.type === <span>&#34;pagehide&#34;</span>) {
      logAnalytics(<span>&#34;page-leave&#34;</span>);
      hasFiredExitEventRef.current = <span>true</span>;
    }
  };

  <span>document</span>.addEventListener(<span>&#34;visibilitychange&#34;</span>, handleVisibilityChange);
  <span>window</span>.addEventListener(<span>&#34;pagehide&#34;</span>, handleVisibilityChange);

  <span>return</span> <span>() =&gt;</span> {
    <span>document</span>.removeEventListener(<span>&#34;visibilitychange&#34;</span>, handleVisibilityChange);
    <span>window</span>.removeEventListener(<span>&#34;pagehide&#34;</span>, handleVisibilityChange);
  };
}, [pathname]);
</code></pre>
<p>Naturally this hook must live only on the client so I will perform what I call &#34;client component boxing&#34; a common pattern in the new RSC world.</p>
<pre><code><span>&#34;use client&#34;</span>;
<span>import</span> { useAnalytics } <span>from</span> <span>&#34;./useAnalytics&#34;</span>;

<span>export</span> <span><span>function</span> <span>Analytics</span>(<span></span>) </span>{
  useAnalytics();
  <span>return</span> <span>null</span>;
}
</code></pre>
<p>Tell me this pattern isn&#39;t hilarious without it being hilarious. Adding it to the app is as easy as Vercel&#39;s so DX is the same.</p>
<pre><code><span>import</span> { Analytics } <span>from</span> <span>&#34;./components/Analytics&#34;</span>;
<span>import</span> { Analytics <span>as</span> VercelStyle } <span>from</span> <span>&#34;@vercel/analytics/react&#34;</span>;

<span>export</span> <span>default</span> <span>async</span> <span><span>function</span> <span>RootLayout</span>(<span>{
  children,
}: {
  children: React.ReactNode;
}</span>) </span>{
  <span>return</span> (
    &lt;html lang=<span>&#34;en&#34;</span>&gt;
      &lt;body&gt;
        {children}
        &lt;Analytics /&gt;
        &lt;VercelStyle /&gt;
      &lt;/body&gt;
    &lt;/html&gt;
  );
}
</code></pre>
<p>Vercel will stay running as I need a baseline to compare against. I almost pushed to main, as is the way, but decided to test it out in a branch instead. Usually everything I write works the first time as is tradition but I had a sneaky suspicion i didn&#39;t really know what I was doing. I deployed to a preview branch and started clicking around. I ran a query against the db file on my VPS and it was working. First try? Wow! That uhh...usually doesn&#39;t happen.</p>
<p>Rewarding myself with another sip of coffee I pushed it off to production.</p>
<h2>500 is the new green</h2>
<p>The next day I see a wall of red with sprinklings of green. 500s. Streams and streams of them. This is fine. I ssh into the vps and of course the bun process isn&#39;t running. There are no spikes in cpu, disk, memory, the service just stopped. But why?</p>
<p>I don&#39;t know but the solution was obvious. Find the root cause? No. Add orchestration with self healing hyper nano pods? Closer. It was <code>systemd</code>. I&#39;d love to say I started at <code>systmed</code> but I actually noodled about with some node tooling first. The fact I forgot <code>systemd</code> existed is how I knew it was the right choice. It is even more embarrassing that gypity was the one who suggested it.</p>
<p>I settled on this config file. I updated the setup script to include registering this on the system.</p>
<pre><code>[Unit]
<span>Description</span>=Monolith<span> Server
</span><span>After</span>=network.target

[Service]
<span>ExecStart</span>=/root/.bun/bin/bun /root/squeeh-stack/app/src/index.ts
<span>WorkingDirectory</span>=/root/squeeh-stack/app
<span>StandardOutput</span>=append:/var/log/monolith-server/out.log
<span>StandardError</span>=append:/var/log/monolith-server/err.log
<span>Restart</span>=always
<span>User</span>=notRoot
<span>Environment</span>=NODE_ENV=production
<span>Type</span>=simple
<span>RestartSec</span>=3

[Install]
<span>WantedBy</span>=multi-user.target
</code></pre>
<p>I spun a bit trying to get this to work right. I thought I had a config wrong as the process kept crashing and restarting until it exhausted the default restart count. It turns out the db changed but I forgot to recreate it. Logs are great.</p>
<p>The red 500s are now all green. Overtime you can see when bun crashes and restarts. I am open to ideas on why this happens but my guess is because bun isn&#39;t written in rust.</p>
<p><img src="https://dgerrells.com/images/regularservicedeath.jpg" alt="digital ocean droplet chart with reg drops in usage"/></p><p>You thought that was funny right? Because bun is written in zig and rust is clearly superior in every way. Well it wasn&#39;t bun, it was Hono the whole time. I looked in the <code>systemd</code> logs after a day and noticed that Hono&#39;s static router was crashing on some weird uri error.</p>
<pre><code><span>return</span> <span>async</span> (c, next) =&gt; {
<span>if</span> (c.finalized) {
<span>await</span> next (); <span>return</span>;
<span>let</span> filename = options.path ?? <span>decodeURI</span>(c.reg•path) ;
URIError: URI error
stack<span> -&gt;</span>&gt;&gt;
</code></pre>
<p>I don&#39;t know why I added a static router but when I removed it, not only did it stop crashing, it decreased the baseline cpu usage significantly. While it would be easy to say, &#34;bad hono, no, that&#39;s a bad Hono!&#34;. It is possible I was doing something wrong, either way, this chart makes me happy.</p>
<p><img src="https://dgerrells.com/images/badhonobad.jpg" alt="chart showing better perf after fixing hono"/></p><p>Ok, time for some analytics.</p>
<h2>analytics 101</h2>
<p>I wrote out the analytics features based on what Vercel has. I figured the bare minimum would be to match what they offer. I added a few more and send it off to gyptiy to write a bash script which would create a markdown file with this info. I wanted it to also email me but I knew I was already pushing it. It wasn&#39;t a usable result. Instead, I asked it to give me a js function which returns the query results.</p>
<pre><code>prompt

schema

metrics

unique visitors based on session id<span> group </span>by page, referrer, country, os, <span>and</span> browser
total unique visitors based on session id
total<span> page </span>views
unique visters change trend since last date range<span>
page </span>views change trend since last date range
average time spend on website
bounce rate <span>for</span> top 20 pages.
</code></pre>
<p>It got a little more than half right. A better ratio than the liveliness of my analytics service. I added an endpoint to return some json with metrics I could look at.</p>
<pre><code>app.get(<span>&#34;/analytics/metrics&#34;</span>, <span>async</span> (c) =&gt; {
  <span>try</span> {
    <span>const</span> metrics = <span>await</span> getAnalyticsMetrics(db);
    <span>return</span> c.json(metrics);
  } <span>catch</span> (error) {
    <span>console</span>.error(<span>&#34;Error logging analytics:&#34;</span>, error);
    <span>return</span> c.json({ error: <span>&#34;Internal Server Error&#34;</span> }, <span>500</span>);
  }
});
</code></pre>
<p>And it works.</p>
<p><img src="https://dgerrells.com/images/prettymetrics.jpg" alt="json metrics"/></p><p>I keep reeding about how great gypity is at building UI products from the internet. I gave it my analytics json file and it spit out some react charts using <code>rechart</code>. I don&#39;t know rechart but the code looked simple enough. I plugged it in to nextjs and get an error I have never seen before.</p>
<p><img src="https://dgerrells.com/images/weirdoldreact.jpg" alt="old react error"/></p><p>Research found that it is an error from back in the long ago times of class based react components. And sure enough the <code>rechart</code> library has class components. I &#34;client component boxed&#34; the <code>rechart</code> component and the error went away but the code didn&#39;t work either. Looks like rechart doesn&#39;t like RSC.</p>
<p>I asked gypity to try again and it picked <code>nivo</code> this time. I have heard of <code>nivo</code> it has pretty charts but I have never used it. Gyptiy wrote well over 1k lines of code for this one. I plugged the code in and got an error I was familiar with.</p>
<p><img src="https://dgerrells.com/images/nextjsclientcontextonly.jpg" alt="nextjs hates context in src"/></p><p>It seems a context is used by the charts and RSC don&#39;t like those. Clearly <code>nivo</code> is an old and unsuitable library if it doesn&#39;t support RSC. I would add the latest <code>shaddy</code> chart library but I don&#39;t have tailwind setup. Instead I will drop the charts and opt for a simpler approach. More pure and soulful. Plain old html tables with css frosting.</p>
<p>This is the result.</p>
<p><img src="https://dgerrells.com/images/rigged-up-analytics.jpg" alt="super simple analytics dashboard"/></p><p>I hate it but also find it endearing in an ugly duckling kind of way. I do have other data I could display like daily/weekly trends and could allow drilling down to individual sessions.</p>
<p>This is fine for now...</p>
<h3>dashboard round two</h3>
<p>It wasn&#39;t fine at all. That dashboard sucked. I changed some styles and flavor a bit and trimmed down superfluous information. I picked apart Vercel&#39;s dashboard design beyond the layout for inspiration. It is subtle in how simple it is to use. I like a bit more information thrown in my face personally but it got me thinking.</p>
<p>I tried to use ye&#39;old gyptiy, sonnyte, and <code>v0</code> to make a chart component for me. None were up to the task. Everything either didn&#39;t work or looked terrible. No libraries allowed here.</p>
<p>I hacked together a chart component with the following api.</p>
<pre><code>&lt;BoxChart
  title=<span>&#34;Your a wizard harry&#34;</span>
  data={[
    {
      <span>label</span>: <span>&#34;date&#34;</span>,
      <span>value</span>: <span>42</span>,
    },
  ]}
  height={<span>300</span>}
/&gt;
</code></pre>
<p>It is put together with a bunch of divs and some flex box glue. It kinda works on mobile too but needs more polish.</p>
<p>Here is the new dashboard featuring the chart.</p>
<iframe src="https://www.youtube.com/embed/UQuLrQ7Sj_0" frameborder="false" credentialless="true" width="100%" height="430px" sandbox="allow-scripts allow-popups allow-top-navigation-by-user-activation allow-forms allow-same-origin allow-storage-access-by-user-activation allow-popups-to-escape-sandbox"></iframe>
<p>I like it. Here is a chart with live version with some data.</p>
<div><div><h6>big data energy</h6><div><div><div><p>Jul 29 9:20 PM</p><p>Jul 29 6:20 PM</p><p>Jul 29 4:20 PM</p><p>Jul 29 1:20 PM</p><p>Jul 29 10:20 AM</p><p>Jul 29 7:20 AM</p><p>Jul 29 5:20 AM</p><p>Jul 29 2:20 AM</p></div></div></div></div></div>
<p>With that out of the way it is time to look at the baseline.</p>
<h2>squeeh-stack vs Vercel</h2>
<p>The data when compared to Vercel is a pretty close match. My analytics seem to over count a bit compared to Vercel which could be how uniqueness is determined. I also don&#39;t filter out testing nor bot data. I did notice that Vercel&#39;s tracking gets blocked by default even with shields down on Brave where as mine is not. The data analytics people may bulk at the potential of over counting here but I just consider it a feature. Nothing helps juice up a company&#39;s valuation like inflated metrics.</p>
<p>Looking at language seems to give a good baseline when compared to Vercel&#39;s analytics which uses the ip. It is pretty close to accurate although someone in Dublin will show up as GB. I did find out that Vercel does populate the geo info. Some docs said to look at the <code>geo</code> object on the request where as in reality it is in a header.</p>
<pre><code><span>const</span> country = headers.get(<span>&#34;x-vercel-ip-country&#34;</span>) || <span>&#34;Unknown&#34;</span>;
<span>const</span> city = headers.get(<span>&#34;x-vercel-ip-city&#34;</span>) || <span>&#34;Unknown&#34;</span>;
<span>const</span> location = <span>`<span>${country}</span>, <span>${city}</span>`</span>;
</code></pre>
<p>With the current traffic this would run fine on a $6/m VPS. Data is enough to cover well over 100m events maybe even a billion depending on sqlite. I can add volumes for data backup for a few bucks more depending on size. I left the VPS over provisioned at a higher tier and came out to a $13.27 savings compared to my current Vercel Analytics spend. It took about 2 days to build this and reap those sweet sweet savings. CPU/Memory/etc is low. When load testing bun peaked at around 50mb. Pretty fat when compared to others but still significantly cheaper.</p>
<p>There is freedom to add additional analytics and queries since I have direct access to the service and data. For example I am able to get a bounce rate approximation. With a little more work I can get an average visit duration among others. I imagine Vercel has more features but behind a higher paywall.</p>
<p>An engineer who doesn&#39;t suffer from infra skill issues could spin up a much more robust and stable analytics service in a fraction of the time. However, for each additional &#34;robustness&#34; feature added, the cost and complexity will go up too. If I wanted zero downtime deployments, that means orchestration with additional provisioning. If I wanted data guarantees, that&#39;d add even more.</p>
<p>I am going to keep running this along side Vercel to see how it does and will iterate on it overtime. Who knows, maybe I&#39;ll spin up a sAAs product which is nothing more than a droplet wrapper with a sqlite database slapped in. I better slap AI in the domain to make sure people know I mean business.</p>
<p>shush, I know of <a href="https://turso.tech">turso</a>. They look amazing.</p>

<p>This was fun and outside my comfort zone. I want to do more to see what a squeeh stack can handle. I have ideas.</p>
<p>Cheers!</p>
<p><span><p>One final note. I know that Vercel is wrapping Tinybird behind the scenes.
Just imagine replacing all usages of &#34;Vercel&#34; with Tinybird.</p></span></p></div></div>
  </body>
</html>
