<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://arxiv.org/abs/2307.14334">Original</a>
    <h1>Google Med-Palm M: Towards Generalist Biomedical AI</h1>
    
    <div id="readability-page-1" class="page"><div id="content-inner">
  <div id="abs">
    
    
    
    <div><p><span>Authors:</span><a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tu%2C+T">Tao Tu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Azizi%2C+S">Shekoofeh Azizi</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Driess%2C+D">Danny Driess</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Schaekermann%2C+M">Mike Schaekermann</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Amin%2C+M">Mohamed Amin</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chang%2C+P">Pi-Chuan Chang</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Carroll%2C+A">Andrew Carroll</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Lau%2C+C">Chuck Lau</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Tanno%2C+R">Ryutaro Tanno</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Ktena%2C+I">Ira Ktena</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mustafa%2C+B">Basil Mustafa</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Chowdhery%2C+A">Aakanksha Chowdhery</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Liu%2C+Y">Yun Liu</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Kornblith%2C+S">Simon Kornblith</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Fleet%2C+D">David Fleet</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mansfield%2C+P">Philip Mansfield</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Prakash%2C+S">Sushant Prakash</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Wong%2C+R">Renee Wong</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Virmani%2C+S">Sunny Virmani</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Semturs%2C+C">Christopher Semturs</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Mahdavi%2C+S+S">S Sara Mahdavi</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Green%2C+B">Bradley Green</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Dominowska%2C+E">Ewa Dominowska</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Arcas%2C+B+A+y">Blaise Aguera y Arcas</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Barral%2C+J">Joelle Barral</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Webster%2C+D">Dale Webster</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Corrado%2C+G+S">Greg S. Corrado</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Matias%2C+Y">Yossi Matias</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Singhal%2C+K">Karan Singhal</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Florence%2C+P">Pete Florence</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Karthikesalingam%2C+A">Alan Karthikesalingam</a>, <a href="https://arxiv.org/search/cs?searchtype=author&amp;query=Natarajan%2C+V">Vivek Natarajan</a></p></div>
      
    
  
  
  
    <p><a aria-describedby="download-button-info" href="https://arxiv.org/pdf/2307.14334">Download PDF</a></p><blockquote>
            <span>Abstract:</span>  Medicine is inherently multimodal, with rich data modalities spanning text,
imaging, genomics, and more. Generalist biomedical artificial intelligence (AI)
systems that flexibly encode, integrate, and interpret this data at scale can
potentially enable impactful applications ranging from scientific discovery to
care delivery. To enable the development of these models, we first curate
MultiMedBench, a new multimodal biomedical benchmark. MultiMedBench encompasses
14 diverse tasks such as medical question answering, mammography and
dermatology image interpretation, radiology report generation and
summarization, and genomic variant calling. We then introduce Med-PaLM
Multimodal (Med-PaLM M), our proof of concept for a generalist biomedical AI
system. Med-PaLM M is a large multimodal generative model that flexibly encodes
and interprets biomedical data including clinical language, imaging, and
genomics with the same set of model weights. Med-PaLM M reaches performance
competitive with or exceeding the state of the art on all MultiMedBench tasks,
often surpassing specialist models by a wide margin. We also report examples of
zero-shot generalization to novel medical concepts and tasks, positive transfer
learning across tasks, and emergent zero-shot medical reasoning. To further
probe the capabilities and limitations of Med-PaLM M, we conduct a radiologist
evaluation of model-generated (and human) chest X-ray reports and observe
encouraging performance across model scales. In a side-by-side ranking on 246
retrospective chest X-rays, clinicians express a pairwise preference for
Med-PaLM M reports over those produced by radiologists in up to 40.50% of
cases, suggesting potential clinical utility. While considerable work is needed
to validate these models in real-world use cases, our results represent a
milestone towards the development of generalist biomedical AI systems.

    </blockquote>

    <!--CONTEXT-->
    
  </div>
</div><div>
      <h2>Submission history</h2><p> From: Shekoofeh Azizi [<a href="https://arxiv.org/show-email/f508e9c7/2307.14334">view email</a>]
      </p></div></div>
  </body>
</html>
