<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.nature.com/articles/s41593-023-01514-1">Original</a>
    <h1>Brain learning differs fundamentally from artificial intelligence systems</h1>
    
    <div id="readability-page-1" class="page"><div>
                    <section data-title="Main"><div id="Sec1-section"><h2 id="Sec1">Main</h2><div id="Sec1-content"><p>The credit assignment problem<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Lillicrap, T. P., Santoro, A., Marris, L., Akerman, C. J. &amp; Hinton, G. Backpropagation and the brain. Nat. Rev. Neurosci. 21, 335–346 (2020)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR1" id="ref-link-section-d41463491e584">1</a></sup> lies at the very heart of learning. Backpropagation<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Rumelhart, D. E., Hinton, G. E. &amp; Williams, R. J. Learning Internal Representations by Error Propagation (Univ. California, San Diego, Institute for Cognitive Science, 1985)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR2" id="ref-link-section-d41463491e588">2</a></sup>, as a simple yet effective credit assignment theory, has powered notable advances in artificial intelligence since its inception<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Krizhevsky, A., Sutskever, I. &amp; Hinton, G. E. ImageNet classification with deep convolutional neural networks. In Advances in Neural Information Processing Systems (NeurIPS) (eds Bartlett, P. et al.) 1097–1105 (Curran Associates, 2012)." href="#ref-CR3" id="ref-link-section-d41463491e592">3</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Mnih, V. et al. Human-level control through deep reinforcement learning. Nature 518, 529–533 (2015)." href="#ref-CR4" id="ref-link-section-d41463491e592_1">4</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Silver, D. et al. Mastering the game of go with deep neural networks and tree search. Nature 529, 484–489 (2016)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR5" id="ref-link-section-d41463491e595">5</a></sup> and has also gained a predominant place in understanding learning in the brain<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Lillicrap, T. P., Santoro, A., Marris, L., Akerman, C. J. &amp; Hinton, G. Backpropagation and the brain. Nat. Rev. Neurosci. 21, 335–346 (2020)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR1" id="ref-link-section-d41463491e599">1</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Richards, B. A. et al. A deep learning framework for neuroscience. Nat. Neurosci. 22, 1761–1770 (2019)." href="#ref-CR6" id="ref-link-section-d41463491e602">6</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Singer, Y. et al. Sensory cortex is optimized for prediction of future input. eLife 7, e31557 (2018)." href="#ref-CR7" id="ref-link-section-d41463491e602_1">7</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Yamins, D. L. K. et al. Performance-optimized hierarchical models predict neural responses in higher visual cortex. Proc. Natl Acad. Sci. USA 111, 8619–8624 (2014)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR8" id="ref-link-section-d41463491e605">8</a></sup>. Due to this success, much recent work has focused on understanding how biological neural networks could learn in a way similar to backpropagation<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Sacramento, J., Costa, R. P., Bengio, Y. and Senn, W. Dendritic cortical microcircuits approximate the backpropagation algorithm. In Advances in Neural Information Processing Systems (NeurIPS) (eds Bengio, S. et al.) 8721–8732 (Curran Associates, 2018)." href="#ref-CR9" id="ref-link-section-d41463491e609">9</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Guerguiev, J., Lillicrap, T. P. &amp; Richards, B. A. Towards deep learning with segregated dendrites. eLife 6, e22901 (2017)." href="#ref-CR10" id="ref-link-section-d41463491e609_1">10</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Scellier, B. &amp; Bengio, Y. Equilibrium propagation: bridging the gap between energy-based models and backpropagation. Front. Comput. Neurosci. 11, 24 (2017)." href="#ref-CR11" id="ref-link-section-d41463491e609_2">11</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Whittington, J. C. R. &amp; Bogacz, R. An approximation of the error backpropagation algorithm in a predictive coding network with local hebbian synaptic plasticity. Neural Comput. 29, 1229–1262 (2017)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR12" id="ref-link-section-d41463491e612">12</a></sup>; although many proposed models do not implement backpropagation exactly, they nevertheless try to approximate backpropagation, and much emphasis is placed on how close this approximation is<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Sacramento, J., Costa, R. P., Bengio, Y. and Senn, W. Dendritic cortical microcircuits approximate the backpropagation algorithm. In Advances in Neural Information Processing Systems (NeurIPS) (eds Bengio, S. et al.) 8721–8732 (Curran Associates, 2018)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR9" id="ref-link-section-d41463491e617">9</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Scellier, B. &amp; Bengio, Y. Equilibrium propagation: bridging the gap between energy-based models and backpropagation. Front. Comput. Neurosci. 11, 24 (2017)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR11" id="ref-link-section-d41463491e620">11</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Whittington, J. C. R. &amp; Bogacz, R. Theories of error back-propagation in the brain. Trends Cogn. Sci. 23, 235–250 (2019)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR13" id="ref-link-section-d41463491e623">13</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Song, Y., Lukasiewicz, T., Xu, Z. &amp; Bogacz, R. Can the brain do backpropagation? Exact implementation of backpropagation in predictive coding networks. In Advances in Neural Information Processing Systems (NeurIPS) (eds Larochell, H. et al.) 22566–22579 (Curran Associates, 2020)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR14" id="ref-link-section-d41463491e626">14</a></sup>. However, learning in the brain is superior to backpropagation in many critical aspects. For example, compared to the brain, backpropagation requires many more exposures to a stimulus to learn<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Tsividis, P. A., Pouncy, T., Xu, J. L., Tenenbaum, J. B. &amp; Gershman, S. J. Human learning in Atari. In 2017 AAAI Spring Symposium Series 643–646 (Association for the Advancement of Artificial Intelligence, 2017)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR15" id="ref-link-section-d41463491e630">15</a></sup> and suffers from catastrophic interference of newly and previously stored information<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="McCloskey, M. &amp; Cohen, N. J. Catastrophic interference in connectionist networks: the sequential learning problem. Psychol. Learn. Motiv. 24, 109–165 (1989)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR16" id="ref-link-section-d41463491e634">16</a></sup>. This raises the question of whether using backpropagation to understand learning in the brain should be the main focus of the field.</p><p>Here, we propose that the brain instead solves credit assignment with a fundamentally different principle, which we call ‘prospective configuration’. In prospective configuration, before synaptic weights are modified, neural activity changes across the network so that output neurons better predict the target output; only then are the synaptic weights (hereafter termed ‘weights’) modified to consolidate this change in neural activity. By contrast, in backpropagation, the order is reversed; weight modification takes the lead, and the change in neural activity is the result that follows.</p><p>We identify prospective configuration as a principle that is implicitly followed by a well-established family of neural models with solid biological groundings, namely, energy-based networks. These networks include Hopfield networks<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Hopfield, J. J. Neural networks and physical systems with emergent collective computational abilities. Proc. Natl Acad. Sci. USA 79, 2554–2558 (1982)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR17" id="ref-link-section-d41463491e644">17</a></sup> and predictive coding networks<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Rao, R. P. &amp; Ballard, D. H. Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. Nat. Neurosci. 2, 79–87 (1999)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR18" id="ref-link-section-d41463491e648">18</a></sup>, which have been successfully used to describe information processing in the cortex<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Friston, K. The free-energy principle: a unified brain theory? Nat. Rev. Neurosci. 11, 127–138 (2010)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR19" id="ref-link-section-d41463491e652">19</a></sup>. To support the theory of prospective configuration, we show that it can both yield efficient learning, which humans and animals are capable of, and reproduce data from experiments on human and animal learning. Thus, on the one hand, we demonstrate that prospective configuration performs more efficient and effective learning than backpropagation in various situations faced by biological systems, such as learning with deep structures, online learning, learning with a limited amount of training examples, learning in changing environments, continual learning with multiple tasks and reinforcement learning. On the other hand, we demonstrate that patterns of neural activity and behavior in diverse human and animal learning experiments, including sensorimotor learning, fear conditioning and reinforcement learning, can be naturally explained by prospective configuration but not by backpropagation.</p><p>Guided by the belief that backpropagation is the foundation of biological learning, previous work showed that energy-based networks can closely approximate backpropagation. However, to achieve it, the networks were set up in an unnatural way, such that the neural activity was prevented from substantially changing before weight modification by constraining the supervision signal to be infinitely small (for example, as in equilibrium propagation<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Scellier, B. &amp; Bengio, Y. Equilibrium propagation: bridging the gap between energy-based models and backpropagation. Front. Comput. Neurosci. 11, 24 (2017)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR11" id="ref-link-section-d41463491e659">11</a></sup> and in previous studies using predictive coding networks<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Whittington, J. C. R. &amp; Bogacz, R. An approximation of the error backpropagation algorithm in a predictive coding network with local hebbian synaptic plasticity. Neural Comput. 29, 1229–1262 (2017)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR12" id="ref-link-section-d41463491e663">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Millidge, B., Tschantz, A. &amp; Buckley, C. L. Predictive coding approximates backprop along arbitrary computation graphs. Neural Comput. 34, 1329–1368 (2022)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR20" id="ref-link-section-d41463491e666">20</a></sup>) or last an infinitely short time<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Song, Y., Lukasiewicz, T., Xu, Z. &amp; Bogacz, R. Can the brain do backpropagation? Exact implementation of backpropagation in predictive coding networks. In Advances in Neural Information Processing Systems (NeurIPS) (eds Larochell, H. et al.) 22566–22579 (Curran Associates, 2020)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR14" id="ref-link-section-d41463491e670">14</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="Bengio, Y. &amp; Fischer, A. Early inference in energy-based models approximates back-propagation. Preprint at 
                  https://doi.org/10.48550/arXiv.1510.02777
                  
                 (2015)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR21" id="ref-link-section-d41463491e673">21</a></sup>. By contrast, we reveal that energy-based networks without these unrealistic constraints follow the distinct principle of prospective configuration rather than backpropagation and are superior in both learning efficiency and accounting for data on biological learning.</p><p>Here, we introduce prospective configuration with an intuitive example, show how it originates from energy-based networks and describe its advantages and quantify them in a rich set of biologically relevant learning tasks. We show that prospective configuration naturally explains patterns of neural activity and behavior in diverse learning experiments.</p></div></div></section><section data-title="Results"><div id="Sec2-section"><h2 id="Sec2">Results</h2><div id="Sec2-content"><h3 id="Sec3">Prospective configuration: an intuitive example</h3><p>To optimally plan behavior, it is critical for the brain to predict future stimuli, for example, to predict sensations in some modalities on the basis of other modalities<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 22" title="O’Reilly, R. C. &amp; Munakata, Y. Computational Explorations in Cognitive Neuroscience: Understanding the Mind by Simulating the Brain (MIT Press Cambridge, 2000)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR22" id="ref-link-section-d41463491e693">22</a></sup>. If the observed outcome differs from the prediction, the weights in the whole network need to be updated so that predictions in the ‘output’ neurons are corrected. Backpropagation computes how the weights should be modified to minimize the error on the output, and this weight update results in a change in neural activity when the network next makes the prediction. By contrast, we propose that neural activity is first adjusted to a new configuration so that the output neurons better predict the observed outcome (target pattern); the weights are then modified to reinforce this configuration of neural activity. We call this configuration of neural activity ‘prospective’ because it is the neural activity that the network should produce to correctly predict the observed outcome. In agreement with the proposed mechanism of prospective configuration, it has indeed been widely observed in biological neurons that presenting the outcome of a prediction triggers changes in neural activity; for example, in tasks requiring animals to predict a juice delivery, the reward triggers rapid changes in activity not only in the gustatory cortex but also in multiple cortical regions<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 23" title="Quilodran, R., Rothe, M. &amp; Procyk, E. Behavioral shifts and action valuation in the anterior cingulate cortex. Neuron 57, 314–325 (2008)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR23" id="ref-link-section-d41463491e697">23</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Wallis, J. D. &amp; Kennerley, S. W. Heterogeneous reward signals in prefrontal cortex. Curr. Opin. Neurobiol. 20, 191–198 (2010)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR24" id="ref-link-section-d41463491e700">24</a></sup>.</p><p>To highlight the difference between backpropagation and prospective configuration, consider a simple example (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig1">1a</a>). Imagine a bear seeing a river. In the bear’s mind, the sight generates predictions of hearing water and smelling salmon. On that day, the bear indeed smelled the salmon but did not hear the water, perhaps due to an ear injury, and thus the bear needs to change its expectation related to the sound. Backpropagation (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig1">1b</a>) would proceed by backpropagating the negative error to reduce the weights on the path between the visual and auditory neurons. However, this also entails a reduction of the weights between visual and olfactory neurons that would compromise the expectation of smelling the salmon the next time the river is visited, even though the smell of salmon was present and correctly predicted. These undesired and unrealistic side effects of learning with backpropagation are closely related with the phenomenon of catastrophic interference, where learning a new association destroys previously learned memories<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="McCloskey, M. &amp; Cohen, N. J. Catastrophic interference in connectionist networks: the sequential learning problem. Psychol. Learn. Motiv. 24, 109–165 (1989)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR16" id="ref-link-section-d41463491e713">16</a></sup>. This example shows that, with backpropagation, even learning one new aspect of an association may interfere with the memory of other aspects of the same association.</p><div data-test="figure" data-container-section="figure" id="figure-1" data-title="Prospective configuration avoids interference during learning."><figure><figcaption><b id="Fig1" data-test="figure-caption-text">Fig. 1: Prospective configuration avoids interference during learning.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="http://tinylogger.com/articles/s41593-023-01514-1/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-023-01514-1/MediaObjects/41593_2023_1514_Fig1_HTML.png?as=webp"/><img aria-describedby="Fig1" src="http://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-023-01514-1/MediaObjects/41593_2023_1514_Fig1_HTML.png" alt="figure 1" loading="lazy" width="685" height="297"/></picture></a></div><p><b>a</b>, Abstract (top) and concrete (bottom) examples of a task inducing interference during learning. One stimulus input (seeing the water) triggers two prediction outputs (hearing the water and smelling the salmon). One output is correct (smelling the salmon), whereas the other output is an error (not hearing the water). <b>b</b>,<b>c</b>, Backpropagation produces interference during learning; not hearing the water reduces the expectation of smelling the salmon (<b>b</b>), although the salmon was indeed smelled. Prospective configuration, on the other hand, avoids such interference (<b>c</b>). In backpropagation, negative error propagates from the error output to hidden neurons (<b>b</b>; left). This causes a weakening of some connections, which, on the next trial, improves the incorrect output but also reduces the prediction of the correct output, thus introducing interference (<b>b</b>; middle and right). In prospective configuration, neural activity settles into a new configuration (different intensities of purple) before weight modification (<b>c</b>; left). This configuration corresponds to the activity that should be produced after learning, that is, is ‘prospective’. Hence, it foresees the positive error on the correct output and modifies the connections to improve the incorrect output while maintaining the correct output (<b>c</b>; middle and right).</p></div><div><a data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="http://tinylogger.com/articles/s41593-023-01514-1/figures/1" data-track-dest="link:Figure1 Full size image" aria-label="Full size image figure 1" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>By contrast, prospective configuration assumes that learning starts with the neurons being configured to a new state, which corresponds to a pattern enabling the network to correctly predict the observed outcome. The weights are then modified to consolidate this state. This behavior can ‘foresee’ side effects of potential weight modifications and compensate for them dynamically (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig1">1c</a>). To correct the negative error on the incorrect output, the hidden neurons settle to their prospective state of lower activity, and, as a result, a positive error is revealed and allocated to the correct output. Consequently, prospective configuration increases the weights connecting to the correct output, whereas backpropagation does not (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig1">1b,c</a>). Hence, prospective configuration is able to correct the side effects of learning an association effectively and efficiently and with little interference.</p><h3 id="Sec4">Origin of prospective configuration: energy-based networks</h3><p>To show how prospective configuration naturally arises in energy-based networks, we introduce a physical machine analog, which provides an intuitive understanding of energy-based networks and how they produce the mechanism of prospective configuration.</p><p>Energy-based networks have been widely and successfully used in describing biological neural systems<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 17" title="Hopfield, J. J. Neural networks and physical systems with emergent collective computational abilities. Proc. Natl Acad. Sci. USA 79, 2554–2558 (1982)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR17" id="ref-link-section-d41463491e784">17</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Friston, K. A theory of cortical responses. Philos. Trans. R. Soc. Lond. B Biol. Sci. 360, 815–836 (2005)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR25" id="ref-link-section-d41463491e787">25</a></sup>. In these models, a neural circuit is described by a dynamical system driven by reducing an abstract ‘energy’, for example, reflecting errors made by neurons (<a data-track="click" data-track-label="link" data-track-action="section anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Sec10">Methods</a>). Neural activity and weights change to reduce this energy; hence, they can be considered ‘movable parts’ of the dynamical system. We show that energy-based networks are mathematically equivalent to a physical machine (we call it ‘energy machine’), where the energy function has an intuitive interpretation, and its dynamics are straightforward; the energy machine simply adjusts its movable parts to reduce energy.</p><p>The energy machine includes nodes sliding on vertical posts connected with each other via rods and springs (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig2">2a,b</a>). Translating from energy-based networks to the energy machine, neural activity maps to the vertical position of a solid node, a connection maps to a rod (blue arrow) pointing from one node to another (where the weight determines how the end position of the rod relates to the initial position), and the energy function maps to the elastic potential energy of springs with nodes attached on both ends (the natural length of the springs is 0). Different energy functions and network structures result in different energy-based networks, corresponding to energy machines with different configurations and combinations of nodes, rods and springs. In Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig2">2</a>, we present the energy machine of predictive coding networks<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Whittington, J. C. R. &amp; Bogacz, R. An approximation of the error backpropagation algorithm in a predictive coding network with local hebbian synaptic plasticity. Neural Comput. 29, 1229–1262 (2017)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR12" id="ref-link-section-d41463491e803">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Rao, R. P. &amp; Ballard, D. H. Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. Nat. Neurosci. 2, 79–87 (1999)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR18" id="ref-link-section-d41463491e806">18</a></sup> because they are most accessible and are established to be closely related to backpropagation<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Whittington, J. C. R. &amp; Bogacz, R. An approximation of the error backpropagation algorithm in a predictive coding network with local hebbian synaptic plasticity. Neural Comput. 29, 1229–1262 (2017)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR12" id="ref-link-section-d41463491e810">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Song, Y., Lukasiewicz, T., Xu, Z. &amp; Bogacz, R. Can the brain do backpropagation? Exact implementation of backpropagation in predictive coding networks. In Advances in Neural Information Processing Systems (NeurIPS) (eds Larochell, H. et al.) 22566–22579 (Curran Associates, 2020)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR14" id="ref-link-section-d41463491e813">14</a></sup>.</p><div data-test="figure" data-container-section="figure" id="figure-2" data-title="The energy machine reveals a new understanding of energy-based networks, the mechanism of prospective configuration and its theoretical advantages."><figure><figcaption><b id="Fig2" data-test="figure-caption-text">Fig. 2: The energy machine reveals a new understanding of energy-based networks, the mechanism of prospective configuration and its theoretical advantages.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="http://tinylogger.com/articles/s41593-023-01514-1/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-023-01514-1/MediaObjects/41593_2023_1514_Fig2_HTML.png?as=webp"/><img aria-describedby="Fig2" src="http://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-023-01514-1/MediaObjects/41593_2023_1514_Fig2_HTML.png" alt="figure 2" loading="lazy" width="685" height="432"/></picture></a></div><p>A subset of energy-based networks can be visualized as mechanical machines that perform equivalent computations. Here, we present the energy machine corresponding to predictive coding networks<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Whittington, J. C. R. &amp; Bogacz, R. An approximation of the error backpropagation algorithm in a predictive coding network with local hebbian synaptic plasticity. Neural Comput. 29, 1229–1262 (2017)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR12" id="ref-link-section-d41463491e829">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Rao, R. P. &amp; Ballard, D. H. Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. Nat. Neurosci. 2, 79–87 (1999)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR18" id="ref-link-section-d41463491e832">18</a></sup>. In the energy machine, the activity of a neuron corresponds to the height of a node (represented by a solid circle) sliding on a post. The input to the neuron is represented by a hollow node on the same post. A synaptic connection corresponds to a rod pointing from a solid node to a hollow node. The weight determines how the input to a postsynaptic neuron depends on the activity of a presynaptic neuron; hence, it influences the angle of the rod. In energy-based networks, relaxation (that is, neural dynamics) and weight modification (that is, weight dynamics) are both driven by minimizing the energy, which corresponds to relaxation of the energy machine by moving the nodes and tuning the rods, respectively. <b>a</b>,<b>b</b>, Predictions (<b>a</b>) and learning (<b>b</b>) in energy-based networks visualized by the energy machine. The pin indicates that neural activity is fixed to the input or target pattern. Here, it is revealed that relaxation infers prospective neural activity, toward which the weights are then modified, a mechanism that we call prospective configuration. <b>c</b>, Physical implementation (top) and connectivity of a predictive coding network<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Whittington, J. C. R. &amp; Bogacz, R. An approximation of the error backpropagation algorithm in a predictive coding network with local hebbian synaptic plasticity. Neural Comput. 29, 1229–1262 (2017)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR12" id="ref-link-section-d41463491e852">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Rao, R. P. &amp; Ballard, D. H. Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. Nat. Neurosci. 2, 79–87 (1999)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR18" id="ref-link-section-d41463491e855">18</a></sup> (bottom), which has dynamics mathematically equivalent to those of the energy machine in the middle (see <a data-track="click" data-track-label="link" data-track-action="section anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Sec10">Methods</a> for details). <b>d</b>, The learning problem in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig1">1</a> visualized by the energy machine, which learns to improve the incorrect output while not interfering with the correct output, thanks to the mechanism of prospective configuration.</p></div><div><a data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="http://tinylogger.com/articles/s41593-023-01514-1/figures/2" data-track-dest="link:Figure2 Full size image" aria-label="Full size image figure 2" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>The dynamics of energy-based networks, which are driven by minimizing the energy function, map to relaxation of the energy machine, which is driven by reducing the total elastic potential energy on the springs. A prediction with energy-based networks involves clamping the input neurons to the provided stimulus and updating the activity of the other neurons, which corresponds to fixing one side of the energy machine and letting the energy machine relax by moving nodes (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig2">2a</a>). Learning with energy-based networks involves clamping the input and output neurons to the corresponding stimulus, first letting the activities of the remaining neurons converge and then updating weights, which corresponds to fixing both sides of the energy machine and letting the energy machine relax first by moving nodes and then tuning rods (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig2">2b</a>).</p><p>The energy machine reveals the essence of energy-based networks; relaxation before weight modification lets the network settle to a new configuration of neural activity corresponding to the neural activity that would have occurred after the error was corrected by the modification of weights, that is, prospective activity (thus, we call this mechanism prospective configuration). For example, the second-layer ‘neuron’ in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig2">2b</a> increases its activity, and this increase in activity would also be caused by the subsequent weight modification (of the connection between the first and second neurons). In simple terms, relaxation in energy-based networks infers the prospective neural activity after learning, toward which the weights are then modified. This distinguishes it from backpropagation, where weight modification takes the lead, and the change in neural activity is the result that follows.</p><p>The bottom of Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig2">2c</a> shows the connectivity of a predictive coding network<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Whittington, J. C. R. &amp; Bogacz, R. An approximation of the error backpropagation algorithm in a predictive coding network with local hebbian synaptic plasticity. Neural Comput. 29, 1229–1262 (2017)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR12" id="ref-link-section-d41463491e898">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Rao, R. P. &amp; Ballard, D. H. Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. Nat. Neurosci. 2, 79–87 (1999)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR18" id="ref-link-section-d41463491e901">18</a></sup>, which has dynamics mathematically equivalent to those of the energy machine shown above it. Predictive coding networks include neurons (blue) corresponding to nodes on the posts and separate neurons encoding prediction errors (red) corresponding to springs. For details, see <a data-track="click" data-track-label="link" data-track-action="section anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Sec10">Methods</a> and Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#MOESM1">1</a>, where we list equations describing predictive coding networks and show how they map on the neural implementation and the proposed energy machine.</p><p>Using the energy machine, Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig2">2d</a> simulates the learning problem from Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig1">1</a>. Here, we can see that prospective configuration indeed foresees the result of learning and its side effects through relaxation. Hence, it corrects the side effects within one iteration, which would otherwise take multiple iterations for backpropagation.</p><h3 id="Sec5">Advantages of prospective configuration: reduced interference and faster learning</h3><p>Here, we quantify interference in the above scenario and demonstrate how reduced interference translates into an advantage in performance. In all simulations in the main text, prospective configuration is implemented in predictive coding networks (other energy-based models are considered in the <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#MOESM1">Supplementary Notes</a>, Section 2.1). We also compare the performance of predictive coding networks against artificial neural networks (ANNs) trained with backpropagation because they are closely related, which makes the comparisons fair. In particular, although predictive coding networks include recurrent connections, they generate the same prediction for a given input (when inputs are constrained but outputs are not; Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig2">2a</a>) as standard feedforward ANNs if their weights are set to corresponding values<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Whittington, J. C. R. &amp; Bogacz, R. An approximation of the error backpropagation algorithm in a predictive coding network with local hebbian synaptic plasticity. Neural Comput. 29, 1229–1262 (2017)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR12" id="ref-link-section-d41463491e934">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Song, Y., Lukasiewicz, T., Xu, Z. &amp; Bogacz, R. Can the brain do backpropagation? Exact implementation of backpropagation in predictive coding networks. In Advances in Neural Information Processing Systems (NeurIPS) (eds Larochell, H. et al.) 22566–22579 (Curran Associates, 2020)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR14" id="ref-link-section-d41463491e937">14</a></sup>. Therefore, loss is the same function of weights in both models, so direct minimization of loss with gradient descent in predictive coding networks (which is not their natural way of training) would produce the same weight changes as backpropagation in ANNs. Hence, comparing predictive coding networks and backpropagation enables isolation of the effects of the learning algorithm (prospective configuration versus direct minimization of loss as in backpropagation).</p><p>In Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig3">3a</a>, we compare the activity of output neurons in the example in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig1">1</a> between backpropagation and prospective configuration. Initially both output neurons are active (top right), and the output should change toward a target in which one of the neurons is inactive (red vector). Learning with prospective configuration results in changes on the output (purple solid vector) that are aligned better with the target than those for backpropagation (purple dotted vector).</p><div data-test="figure" data-container-section="figure" id="figure-3" data-title="Learning with prospective configuration changes the activity of output neurons in a direction more aligned toward the target."><figure><figcaption><b id="Fig3" data-test="figure-caption-text">Fig. 3: Learning with prospective configuration changes the activity of output neurons in a direction more aligned toward the target.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="http://tinylogger.com/articles/s41593-023-01514-1/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-023-01514-1/MediaObjects/41593_2023_1514_Fig3_HTML.png?as=webp"/><img aria-describedby="Fig3" src="http://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-023-01514-1/MediaObjects/41593_2023_1514_Fig3_HTML.png" alt="figure 3" loading="lazy" width="685" height="308"/></picture></a></div><div data-test="bottom-caption" id="figure-3-desc"><p><b>a</b>, Simulation of the network from Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig1">1</a> showing changes in the correct and incorrect output neurons during training (‘Iteration’) trained with both learning rules. Here, learning with prospective configuration (purple solid vector) aligns better with the target (red vector) than learning with backpropagation (purple dashed vector). <b>b</b>, Interference can be quantified by ‘target alignment’, the cosine similarity of the direction of the target (red vector) and the direction of learning (purple vector). <b>c</b>, Higher target alignment indicates less interference and vice versa. <b>d</b>, The same experiment as in <b>a</b> repeated with a learning rate ranging from 0.005 to 0.5 represented by the size of the markers, where it is shown that the choice of learning rate changes the trajectories for both methods slightly, but the conclusion holds irrespective of the learning rate. <b>e</b>, Target alignment of randomly generated networks trained with both learning rules as a function of depth of the network. Each symbol shows target alignment resulting from training on a single randomly generated pattern. <b>f</b>, Test error during training on the FashionMNIST<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 60" title="Xiao, H., Rasul, K. &amp; Vollgraf, R. Fashion MNIST: a novel image dataset for benchmarking machine learning algorithms. Preprint at 
                  https://doi.org/10.48550/arXiv.1708.07747
                  
                 (2017)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR60" id="ref-link-section-d41463491e986">60</a></sup> dataset containing images of clothing belonging to different categories for both learning rules with a deep neural network of 15 layers. Here, ‘test error’ refers to the ratio of incorrectly classified samples among all samples in the test set. <b>g</b>, Mean of the test error over training epochs (reflecting how fast test error drops) as a function of learning rate. Results in <b>f</b> and <b>h</b> are for the learning rates giving the minima of the corresponding curves in <b>g</b>. <b>h</b>, Mean of test error of other network depths. Each point is from a learning rate independently optimized for each learning rule in the corresponding setup of network depth. In <b>e</b>–<b>h</b>, prospective configuration demonstrates a notable advantage as the structure gets deeper. Each experiment in <b>f</b>–<b>h</b> was repeated with <i>n</i> = 3 random seeds. Error bars and bands represent the 68% confidence interval.</p><p><a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#MOESM3">Source data</a></p></div></div><div><a data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="http://tinylogger.com/articles/s41593-023-01514-1/figures/3" data-track-dest="link:Figure3 Full size image" aria-label="Full size image figure 3" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>Following the first weight update, we simulate multiple iterations until the network is able to correctly predict the target. Here, ‘iteration’ refers to each time the agent is presented with stimuli and conducts one weight update because of the stimulus. Although the output from backpropagation can reach the target after multiple iterations, the output for the ‘correct neuron’ diverges from the target during learning and then comes back; this is a particularly undesired effect in biological learning, where networks can be ‘tested’ at any point during the learning process, because it may lead to incorrect decisions affecting chances for survival. By contrast, prospective configuration substantially reduces this effect.</p><p>Although backpropagation modifies weights to directly reduce cost in the space of weights (that is, performs gradient descent), surprisingly, and rather subversively, it does not push the resulting output activity directly toward the target. To illustrate this, Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig3">3a</a> visualizes the cost with contour lines. Changing the activity of output neurons according to the gradient of the cost would correspond to a change orthogonal to the contour lines, that is, that indicated by the red arrow. However, backpropagation changes the output in a different direction shown by a dashed arrow. Optimizing the weights independently, without considering the effect of updating other weights, leads to output activity not updating toward the target directly due to different weight updates to different layers interfering with each other. By contrast, prospective configuration considers the results of updating other weights by finding a desired configuration of neural activity first. Such a mechanism is missing in backpropagation but is natural in energy-based networks. Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#MOESM1">2</a> shows a direct comparison of how these two models evolve in weight and output spaces during learning.</p><p>Interference can be quantified by the angle between the direction of the target (from current output to target) and learning (from current output to output after learning, both measured without the target provided), and we define ‘target alignment’ as the cosine of this angle (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig3">3b</a>); hence, high interference corresponds to low target alignment (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig3">3c</a>).</p><p>It is useful to highlight that target alignment is affected little by the learning rate (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig3">3d</a>), demonstrating that the learning rate has little effect on the direction and trajectory that output neurons take. The difference in target alignment demonstrated in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig3">3a</a> is also present for deeper and larger (randomly generated) networks (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig3">3e</a>). When a network has no hidden layers, the target alignment is equal to 1 (<a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#MOESM1">Supplementary Notes</a>, Section 2.4.1). The target alignment drops for backpropagation as the network gets deeper because changes in weights in one layer interfere with changes in other layers (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig1">1</a>), and the backpropagated errors do not lead to appropriate modification of weights in hidden layers (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#MOESM1">2</a>). Because backpropagation modifies the weights in the direction reducing loss, it has positive target alignment for small learning rates but not necessarily close to 1. By contrast, prospective configuration maintains a much higher value along the way. This higher target alignment of prospective configuration can be theoretically explained by the following: (1) there exists a close link between prospective configuration and an algorithm called target propagation<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 26" title="Bengio, Y. How auto-encoders could provide credit assignment in deep networks via target propagation. Preprint at 
                  https://doi.org/10.48550/arXiv.1407.7906
                  
                 (2014)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR26" id="ref-link-section-d41463491e1078">26</a></sup> (shown in Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#MOESM1">3</a> and <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#MOESM1">Supplementary Notes</a>, Section 2.2), and (2) under certain conditions, target propagation<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 26" title="Bengio, Y. How auto-encoders could provide credit assignment in deep networks via target propagation. Preprint at 
                  https://doi.org/10.48550/arXiv.1407.7906
                  
                 (2014)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR26" id="ref-link-section-d41463491e1088">26</a></sup> has a target alignment of 1 (ref. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 27" title="Meulemans, A., Carzaniga, F., Suykens, J., Sacramento, J. &amp; Grewe, B. F. A theoretical framework for target propagation. In Advances in Neural Information Processing Systems (NeurIPS) (eds Larochelle, H. et al.) 20024–20036 (Curran Associates, 2020)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR27" id="ref-link-section-d41463491e1092">27</a></sup>; demonstrated in Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#MOESM1">4</a> and <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#MOESM1">Supplementary Notes</a>, Section 2.4.2). Thus, the link with target propagation provides theoretical insight (with numerical verification) into why prospective configuration has a higher target alignment.</p><p>Higher target alignment directly translates to the efficiency of learning. Test error during training in a visual classification task with a deep neural network of 15 layers decreases faster for prospective configuration than for backpropagation (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig3">3f</a>).</p><p>Throughout the data presented here, if learning rate is not presented in a plot, the plot corresponds to the best learning rate optimized independently for each rule under the setup via a grid search. The optimization target is either learning performance or similarity to experimental data (details can be found in the methods for each experiment). Thus, for example, Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig3">3f</a> shows the test errors as training progress, with the learning rates optimized independently for each learning rule. The optimization target is the ‘mean of test error’ during training, reflecting how fast the test error decreases during training. Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig3">3g</a> plots this mean of test error for different learning rates for both learning rules, and the learning rates giving the minima of the curves were used in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig3">3f</a>. Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig3">3h</a> repeats the experiment on networks of other depths and shows the mean of the test error during training as a function of network depth. The mean error is higher for lower depths, as these networks are unable to learn the task, and for greater depths, as it takes longer to train deeper networks. Importantly, the gap between backpropagation and prospective configuration widens for deeper networks, paralleling the difference in target alignment. Efficient training with deeper networks is important for biological neural systems known to be deep, for example, the primate visual cortex<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 28" title="Felleman, D. J. &amp; Van Essen, D. C. Distributed hierarchical processing in the primate cerebral cortex. Cereb. Cortex 1, 1–47 (1991)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR28" id="ref-link-section-d41463491e1124">28</a></sup>.</p><p>In Section 2.3 of the <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#MOESM1">Supplementary Notes</a>, we develop a formal theory of prospective configuration and provide further illustrations and analyses of its advantages. Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#MOESM1">5</a> formally defines prospective configuration and demonstrates that it is indeed commonly observed in different energy-based networks. Supplementary Figs. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#MOESM1">6</a> and <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#MOESM1">7</a> empirically verify and generalize the advantages expected from the theory and show that prospective configuration yields more accurate error allocation and less erratic weight modification, respectively.</p><h3 id="Sec6">Advantages of prospective configuration: effective learning in biologically relevant scenarios</h3><p>Inspired by these advantages, we show empirically that prospective configuration indeed handles various learning problems that biological systems would face better than backpropagation. Because the field of machine learning has developed effective benchmarks for testing learning performance, we use variants of classic machine learning problems that share key features with learning in natural environments. Such problems include online learning, where weights must be updated after each experience (rather than a batch of training examples)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 29" title="Fontenla-Romero, Ó., Guijarro-Berdiñas, B., Martinez-Rego, D., Pérez-Sánchez, B. &amp; Peteiro-Barral, D. Online machine learning. In Efficiency and Scalability Methods for Computational Intellect (eds Igelnik, B. &amp; Zurada, J. M.) 27–54 (IGI Global, 2013)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR29" id="ref-link-section-d41463491e1151">29</a></sup>, continual learning with multiple tasks<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 30" title="Hassabis, D., Kumaran, D., Summerfield, C. &amp; Botvinick, M. Neuroscience-inspired artificial intelligence. Neuron 95, 245–258 (2017)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR30" id="ref-link-section-d41463491e1155">30</a></sup>, learning in changing environments<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 31" title="Gama, J., Žliobaitė, I., Bifet, A., Pechenizkiy, M. &amp; Bouchachia, A. A survey on concept drift adaptation. ACM Comput. Surv. 46, 1–37 (2014)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR31" id="ref-link-section-d41463491e1159">31</a></sup>, learning with a limited amount of training examples and reinforcement learning<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Mnih, V. et al. Human-level control through deep reinforcement learning. Nature 518, 529–533 (2015)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR4" id="ref-link-section-d41463491e1163">4</a></sup>. In all aforementioned learning problems, prospective configuration demonstrates a notable superiority over backpropagation.</p><p>First, based on the example in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig1">1</a>, we expect prospective configuration to require fewer episodes for learning than backpropagation. Before presenting the comparison, we describe how backpropagation is used to train ANNs. Typically, the weights are only modified after a batch of training examples based on the average of updates derived from individual examples (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig4">4a</a>). In fact, backpropagation relies heavily on averaging over multiple experiences to reach human-level performance<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 32" title="Puri, R., Kirby, R., Yakovenko, N. &amp; Catanzaro, B. Large scale language modeling: converging on 40 GB of text in four hours. In 2018 30th International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD) 290–297 (IEEE, 2018)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR32" id="ref-link-section-d41463491e1176">32</a></sup>, as it needs to stabilize training<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 33" title="Ioffe, S. &amp; Szegedy, C. Batch normalization: accelerating deep network training by reducing internal covariate shift. In Proceedings of the International Conference on Machine Learning (ICML) (eds Bach, F. &amp; Blei, D.) 448–456 (PMLR, 2015)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR33" id="ref-link-section-d41463491e1180">33</a></sup>. By contrast, biological systems must update the weights after each experience, and we compare learning performance in such a setting. Sampling efficiency can be quantified by mean of test error during training, which is shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig4">4b</a> as a function of batch size (number of experiences that the updates are averaged over). Efficiency strongly depends on batch size for backpropagation because it requires batch training to average out erratic weight updates, whereas this dependence is weaker for prospective configuration, where weight changes are intrinsically less erratic and batch averaging is required less (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#MOESM1">7</a>). Importantly, prospective configuration learns faster with smaller batch sizes, as in biological settings. Additionally, final performance can be quantified by the minimum of the test error, which is shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig4">4c</a>, when trained with a batch size equal to 1. Here, prospective configuration also demonstrates a notable advantage over backpropagation.</p><div data-test="figure" data-container-section="figure" id="figure-4" data-title="Prospective configuration achieves a superior performance over backpropagation in various learning situations faced by biological systems."><figure><figcaption><b id="Fig4" data-test="figure-caption-text">Fig. 4: Prospective configuration achieves a superior performance over backpropagation in various learning situations faced by biological systems.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="http://tinylogger.com/articles/s41593-023-01514-1/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-023-01514-1/MediaObjects/41593_2023_1514_Fig4_HTML.png?as=webp"/><img aria-describedby="Fig4" src="http://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-023-01514-1/MediaObjects/41593_2023_1514_Fig4_HTML.png" alt="figure 4" loading="lazy" width="685" height="451"/></picture></a></div><div data-test="bottom-caption" id="figure-4-desc"><p><b>a</b>–<b>k</b>, Learning situations include online learning<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 29" title="Fontenla-Romero, Ó., Guijarro-Berdiñas, B., Martinez-Rego, D., Pérez-Sánchez, B. &amp; Peteiro-Barral, D. Online machine learning. In Efficiency and Scalability Methods for Computational Intellect (eds Igelnik, B. &amp; Zurada, J. M.) 27–54 (IGI Global, 2013)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR29" id="ref-link-section-d41463491e1211">29</a></sup> (<b>a</b>–<b>c</b>), continual learning of multiple tasks<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 30" title="Hassabis, D., Kumaran, D., Summerfield, C. &amp; Botvinick, M. Neuroscience-inspired artificial intelligence. Neuron 95, 245–258 (2017)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR30" id="ref-link-section-d41463491e1221">30</a></sup> (<b>d</b>–<b>e</b>), learning in changing environments<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 31" title="Gama, J., Žliobaitė, I., Bifet, A., Pechenizkiy, M. &amp; Bouchachia, A. A survey on concept drift adaptation. ACM Comput. Surv. 46, 1–37 (2014)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR31" id="ref-link-section-d41463491e1232">31</a></sup> (<b>f</b>–<b>g</b>), learning with a limited amount of training examples (<b>h</b>) and reinforcement learning<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Mnih, V. et al. Human-level control through deep reinforcement learning. Nature 518, 529–533 (2015)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR4" id="ref-link-section-d41463491e1246">4</a></sup> (<b>k</b>). Graphs corresponding to each situation are grouped together with the same background color. Simulations of each situation differ from the ‘default setup’ described in the <a data-track="click" data-track-label="link" data-track-action="section anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Sec10">Methods</a> in a single aspect unique to this task. For example, the default setup involves training with minibatches, so the batch size was only set to 1 in <b>a</b>–<b>c</b> for investigating online learning, whereas it was set to a larger default value in rest of the groups. In supervised learning setups, fully connected networks (<b>a</b>–<b>h</b>) were evaluated on the FashionMNIST<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 60" title="Xiao, H., Rasul, K. &amp; Vollgraf, R. Fashion MNIST: a novel image dataset for benchmarking machine learning algorithms. Preprint at 
                  https://doi.org/10.48550/arXiv.1708.07747
                  
                 (2017)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR60" id="ref-link-section-d41463491e1269">60</a></sup> dataset, and convolutional neural networks<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 35" title="O’Shea, K. &amp; Nash, R. An introduction to convolutional neural networks. Preprint at 
                  https://doi.org/10.48550/arXiv.1511.08458
                  
                 (2015)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR35" id="ref-link-section-d41463491e1273">35</a></sup> (<b>i</b> and <b>j</b>) were evaluated on the CIFAR-10 (ref. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 36" title="Krizhevsky, A. &amp; Hinton, G. Learning Multiple Layers of Features from Tiny Images. Master’s thesis, Univ. Toronto (2009)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR36" id="ref-link-section-d41463491e1283">36</a></sup>) dataset. In the reinforcement learning setup (<b>k</b>), fully connected networks were evaluated on three classic control problems. If the learning rate was not presented, each point (a setup of an experiment) in the plot corresponds to the best learning rate optimized independently for each rule under that setup. <b>a</b>, Difference in training setup between computers that can average weight modifications for individual examples to get a ‘statistically good’ value and biological systems that must apply one modification before computing another. <b>b</b>, Mean of the test errors during training as a function of batch size. <b>c</b>, Minimum of test error during training as a function of learning rate. <b>d</b>, Test error during continual learning of two tasks. <b>e</b>, Mean of test error of both tasks during training as a function of learning rate. <b>f</b>, Test error during training when learning with concept drifting. <b>g</b>, Mean of test error during training with concept drifting as a function of learning rate. <b>h</b>, Minimum of test error during training with different amounts of training examples (data points per class). <b>i</b>, Minimum of test error during training of a convolutional neural network trained with prospective configuration and backpropagation on the CIFAR-10 (ref. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 36" title="Krizhevsky, A. &amp; Hinton, G. Learning Multiple Layers of Features from Tiny Images. Master’s thesis, Univ. Toronto (2009)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR36" id="ref-link-section-d41463491e1319">36</a></sup>) dataset. <b>j</b>, Structure detail of the convolutional neural network used in <b>i</b>. <b>k</b>, Sum of rewards per episode during training on three classic reinforcement learning tasks (insets). An episode is a period from initialization of environment to reaching a terminate state. Each experiment in <b>a</b>–<b>h</b> was repeated with <i>n</i> = 10 random seeds. Each experiment in <b>i</b>–<b>k</b> was repeated with <i>n</i> = 3 random seeds because these experiments are more expensive. Error bars and bands represent the 68% confidence interval.</p><p><a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#MOESM3">Source data</a></p></div></div><div><a data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="http://tinylogger.com/articles/s41593-023-01514-1/figures/4" data-track-dest="link:Figure4 Full size image" aria-label="Full size image figure 4" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>Second, biological organisms need to sequentially learn multiple tasks, while ANNs show catastrophic forgetting. When trained on a new task, performance on previously learned tasks is largely destroyed<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="McCloskey, M. &amp; Cohen, N. J. Catastrophic interference in connectionist networks: the sequential learning problem. Psychol. Learn. Motiv. 24, 109–165 (1989)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR16" id="ref-link-section-d41463491e1367">16</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 34" title="Zenke, F., Poole, B. &amp; Ganguli, S. Continual learning through synaptic intelligence. In Proc. 34th International Conference on Machine Learning (eds Precup, D. &amp; Teh, Y. W.) 3987–3995 (PMLR, 2017)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR34" id="ref-link-section-d41463491e1370">34</a></sup>. The data in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig4">4d</a> show performance when trained on two tasks alternately (task 1 is classifying five randomly selected classes in the FashionMNIST dataset, and task 2 is classifying the remaining five classes). Prospective configuration outperforms backpropagation both in terms of avoiding forgetting previous tasks and relearning current tasks. The results are summarized in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig4">4e</a>.</p><p>Third, biological systems often need to rapidly adapt to changing environments. A common way to simulate this is ‘concept drifting’<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 31" title="Gama, J., Žliobaitė, I., Bifet, A., Pechenizkiy, M. &amp; Bouchachia, A. A survey on concept drift adaptation. ACM Comput. Surv. 46, 1–37 (2014)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR31" id="ref-link-section-d41463491e1383">31</a></sup>, where a part of the mapping between the output neurons to the semantic meaning is shuffled regularly, each time a certain number of training iterations has passed (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig4">4f</a>). Test error during training with concept drifting is presented in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig4">4f</a>. Before epoch 0, both learning rules are initialized with the same pretrained model (trained with backpropagation); thus, epoch 0 is the first time the model experiences concept drift. The results are summarized in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig4">4g</a> and show that, for this task, there is a particularly large difference in mean error (for optimal learning rates). This large advantage of prospective configuration is related to it being able to optimally detect which weights to modify (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#MOESM1">6</a>) and to preserve existing knowledge while adapting to changes (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig1">1</a>). This ability to maintain important information while updating other information is critical for survival in natural environments that are bound to change, and prospective configuration has a very substantial advantage in this respect.</p><p>Furthermore, biological learning is also characterized by limited data availability. Prospective configuration outperforms backpropagation when the model is trained with fewer examples (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig4">4h</a>).</p><p>To demonstrate that the advantage of prospective configuration also scales up to larger networks and problems, we evaluated convolutional neural networks<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 35" title="O’Shea, K. &amp; Nash, R. An introduction to convolutional neural networks. Preprint at 
                  https://doi.org/10.48550/arXiv.1511.08458
                  
                 (2015)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR35" id="ref-link-section-d41463491e1413">35</a></sup> on CIFAR-10 (ref. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 36" title="Krizhevsky, A. &amp; Hinton, G. Learning Multiple Layers of Features from Tiny Images. Master’s thesis, Univ. Toronto (2009)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR36" id="ref-link-section-d41463491e1417">36</a></sup>) trained with both learning rules (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig4">4i</a>), where prospective configuration showed notable advantages over backpropagation. The detailed structure of the convolutional networks is provided in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig4">4j</a>.</p><p>Another key challenge for biological systems is to decide which actions to take. Reinforcement learning theories (for example, <i>Q</i> learning) propose that it is solved by learning the expected reward resulting from different actions in different situations<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 37" title="Sutton, R. S. &amp; Barto, A. G. Introduction to Reinforcement Learning, Vol. 2 (MIT Press Cambridge, 1998)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR37" id="ref-link-section-d41463491e1433">37</a></sup>. Such prediction of rewards can be made by neural networks<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Mnih, V. et al. Human-level control through deep reinforcement learning. Nature 518, 529–533 (2015)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR4" id="ref-link-section-d41463491e1437">4</a></sup>, which can be trained with prospective configuration or backpropagation. The sum of rewards per episode during training on three classic reinforcement learning tasks is reported in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig4">4k</a>, where prospective configuration demonstrates a notable advantage over backpropagation. This large advantage may arise because reinforcement learning is particularly sensitive to erratic changes in network weights (as the target output depends on reward predicted by the network itself for a new state; <a data-track="click" data-track-label="link" data-track-action="section anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Sec10">Methods</a>).</p><p>Based on the superior learning performance of prospective configuration, we may expect that this learning mechanism has been favored by evolution; thus, in the next sections, we investigate if it can account for neural activity and behavior during learning better than backpropagation.</p><h3 id="Sec7">Evidence for prospective configuration: inferring the latent state during learning</h3><p>Prospective configuration is related to theories proposing that before learning, the brain first infers a latent state of the environment from feedback<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Hampton, A. N., Bossaerts, P. &amp; O’Doherty, J. P. The role of the ventromedial prefrontal cortex in abstract state-based inference during decision making in humans. J. Neurosci. 26, 8360–8367 (2006)." href="#ref-CR38" id="ref-link-section-d41463491e1459">38</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Heald, J. B., Lengyel, M. &amp; Wolpert, D. M. Contextual inference underlies the learning of sensorimotor repertoires. Nature 600, 489–493 (2021)." href="#ref-CR39" id="ref-link-section-d41463491e1459_1">39</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 40" title="Larsen, T., Leslie, D. S., Collins, E. J. &amp; Bogacz, R. Posterior weighted reinforcement learning with state uncertainty. Neural Comput. 22, 1149–1179 (2010)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR40" id="ref-link-section-d41463491e1462">40</a></sup>. Here, we propose that this inference can be achieved in neural circuits through prospective configuration, where, following feedback, neurons in ‘hidden layers’ converge to a prospective pattern of activity that encodes this latent state. We demonstrate that data from various previous studies, which involved the inference of a latent state, can be explained by prospective configuration. These data were previously explained by complex and abstract mechanisms, such as Bayesian models<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 38" title="Hampton, A. N., Bossaerts, P. &amp; O’Doherty, J. P. The role of the ventromedial prefrontal cortex in abstract state-based inference during decision making in humans. J. Neurosci. 26, 8360–8367 (2006)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR38" id="ref-link-section-d41463491e1466">38</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 39" title="Heald, J. B., Lengyel, M. &amp; Wolpert, D. M. Contextual inference underlies the learning of sensorimotor repertoires. Nature 600, 489–493 (2021)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR39" id="ref-link-section-d41463491e1469">39</a></sup>, whereas here, we mechanistically show with prospective configuration how such inference can be performed by minimal networks encoding only the essential elements of the tasks.</p><p>The dynamical inference of a latent state from feedback has been recently proposed to take place during sensorimotor learning<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 39" title="Heald, J. B., Lengyel, M. &amp; Wolpert, D. M. Contextual inference underlies the learning of sensorimotor repertoires. Nature 600, 489–493 (2021)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR39" id="ref-link-section-d41463491e1476">39</a></sup>. In this experiment, participants received different motor perturbations in different contexts and learned to compensate for these perturbations. Behavioral data suggest that, after receiving feedback, participants first used the feedback to infer context and then adapted the force for the inferred context. We demonstrate that prospective configuration is able to reproduce these behavioral data, whereas backpropagation cannot.</p><p>Specifically, in the task (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig5">5a</a>), participants were asked to move a stick from a starting point to a target point while experiencing perturbations. The participants experienced a sequence of blocks of trials (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig5">5c–e</a>), including training, washout and testing. During the training session, different directions of perturbations, positive (+) or negative (–), were applied in different contexts, blue (B) or red (R) backgrounds, respectively. We denote these trials as B+ and R–. These trials may be associated with latent states, which we denote [B] and [R]; for example, the latent state [B] may be associated with both background B and perturbation +. The next stage of the task was designed to investigate if the latent state [B] can be activated by perturbation + even if no background B is shown. Thus, participants experienced different trials including R+ (that is, perturbation + but no background B). Specifically, after a washout session (during which no perturbation was provided), in the testing session, participants experienced one of the four possible test trials: B+, R+, B– and R–. To evaluate learning on the test trials, motor adaptation (that is, the difference between the final and target stick positions) was measured before and after the test trial in two trials with the blue background (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig5">5e</a>). Change in the adaptation between these two trials is a reflection of learning about blue context that occurred at the test trial. If participants only associated feedback with the background color (B), then the change in adaptation would only occur with test trials B+ and B–. However, experimental data (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig5">5f</a>) show that there was also substantial adaptation change with R+ trials (which was even bigger than with B– trials).</p><div data-test="figure" data-container-section="figure" id="figure-5" data-title="Prospective configuration explains contextual inference in human sensorimotor learning."><figure><figcaption><b id="Fig5" data-test="figure-caption-text">Fig. 5: Prospective configuration explains contextual inference in human sensorimotor learning.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="http://tinylogger.com/articles/s41593-023-01514-1/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-023-01514-1/MediaObjects/41593_2023_1514_Fig5_HTML.png?as=webp"/><img aria-describedby="Fig5" src="http://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-023-01514-1/MediaObjects/41593_2023_1514_Fig5_HTML.png" alt="figure 5" loading="lazy" width="685" height="297"/></picture></a></div><div data-test="bottom-caption" id="figure-5-desc"><p><b>a</b>, Structure of an experimental trial where participants were asked to move a stick from the starting point to the target point while experiencing perturbations. <b>b</b>, The minimal network for the task, including six connections encoding the associations from the backgrounds (B and R) to the belief of contexts ([B] and [R]) and from the belief of contexts to the prediction of perturbations (+ and –). <b>c</b>–<b>e</b>, Sequence of sessions the participants experienced, including training (<b>c</b>), washout (<b>d</b>) and testing (<b>e</b>). Darker gray boxes show the expected network after the session, where thickness represents the strength of connections. In the testing session, the darker box explains how the two learning rules learn differently on the R+ trial, leading to the differences in <b>f</b>. <b>f</b>, Predictions of the two learning rules compared to behavioral data measured from human participants, where prospective configuration reproduces the key patterns of data, but backpropagation does not. Each experiment was repeated with <i>n</i> = 24 random seeds, as there were 24 participants in the behavioral experiment.</p><p><a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#MOESM3">Source data</a></p></div></div><div><a data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="http://tinylogger.com/articles/s41593-023-01514-1/figures/5" data-track-dest="link:Figure5 Full size image" aria-label="Full size image figure 5" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>To model learning in this task, we considered a neural network (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig5">5b</a>) where input nodes encode the background color, and outputs encode movement compensations in the two directions. Importantly, this network also includes hidden neurons encoding belief of being in the contexts associated with the two backgrounds ([B] and [R]). Trained with the exact procedure of the experiment<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 39" title="Heald, J. B., Lengyel, M. &amp; Wolpert, D. M. Contextual inference underlies the learning of sensorimotor repertoires. Nature 600, 489–493 (2021)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR39" id="ref-link-section-d41463491e1555">39</a></sup> from randomly initialized weights, prospective configuration with this minimal network can reproduce the behavioral data, whereas backpropagation cannot (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig5">5f</a>).</p><p>Prospective configuration can produce change in adaptation with the R+ test trial because after + feedback, it is able to also activate context [B] that was associated with this feedback during training and then learn compensation for this latent state. To shed light on how this inference takes place in the model, schematics in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig5">5c,d</a> show evolution of the weights of the network over sessions (thickness represents the strength of connections). The schematic in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig5">5e</a> shows the difference between the two learning rules after exposure to R+; although B is not perceived, prospective configuration infers a moderate excitation of the belief of blue context [B] because the positive connection from [B] to + was built during the training session. The activity of [B] enables the learning of weights from [B] to + and –, while backpropagation does not modify any weights originating from [B].</p><p>For simplicity of explanation, we presented simulations with minimal networks; however, Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#MOESM1">8</a> shows that networks with a general fully connected structure and more hidden neurons can replicate the above data when using prospective configuration but not when using backpropagation.</p><p>Studies of animal conditioning have also observed that feedback in learning tasks involving multiple stimuli may trigger learning about non-presented stimuli<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 41" title="Kaufman, M. A. &amp; Bolles, R. C. A nonassociative aspect of overshadowing. Bull. Psychonomic Soc. 18, 318–320 (1981)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR41" id="ref-link-section-d41463491e1581">41</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 42" title="Matzel, L. D., Schachtman, T. R. &amp; Miller, R. R. Recovery of an overshadowed association achieved by extinction of the overshadowing stimulus. Learn. Motiv. 16, 398–412 (1985)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR42" id="ref-link-section-d41463491e1584">42</a></sup>. One example is provided in Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#MOESM1">9</a>, where we show that it can be explained by prospective configuration but not by backpropagation.</p><h3 id="Sec8">Evidence for prospective configuration: discovering task structure during learning</h3><p>Prospective configuration is also able to discover the underlying task structure in reinforcement learning. Specifically, we consider a task where reward probabilities of different options were not independent<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 38" title="Hampton, A. N., Bossaerts, P. &amp; O’Doherty, J. P. The role of the ventromedial prefrontal cortex in abstract state-based inference during decision making in humans. J. Neurosci. 26, 8360–8367 (2006)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR38" id="ref-link-section-d41463491e1599">38</a></sup>. In this study, humans were choosing between two options where the reward probabilities were constrained such that one option had a higher reward probability than the other (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig6">6a</a>). Occasionally the reward probabilities were swapped, so if one probability was increased, the other was decreased by the same amount. Remarkably, the recorded functional magnetic resonance imaging (fMRI) data suggested that participants learned that the values of the two options were negatively correlated and on each trial updated the value estimates of both options in opposite ways. This conclusion was drawn from analysis of the signal from the medial prefrontal cortex (mPFC), which encoded the expected value of reward. The data presented in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig6">6c</a> compare this signal after making a choice on two consecutive trials: a trial in which the reward was not received (‘punish trial’) and the next trial. If the participant selected the same option on both trials (‘stay’), the signal decreased, indicating that the reward expected by the participant was reduced. Remarkably, if the participant selected the other option on the next trial (‘switch’), the signal increased, suggesting that negative feedback for one option increased the value estimate for the other. Such learning is not predicted by standard reinforcement learning models<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 38" title="Hampton, A. N., Bossaerts, P. &amp; O’Doherty, J. P. The role of the ventromedial prefrontal cortex in abstract state-based inference during decision making in humans. J. Neurosci. 26, 8360–8367 (2006)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR38" id="ref-link-section-d41463491e1609">38</a></sup>.</p><div data-test="figure" data-container-section="figure" id="figure-6" data-title="Prospective configuration can discover the underlying task structure during reinforcement learning."><figure><figcaption><b id="Fig6" data-test="figure-caption-text">Fig. 6: Prospective configuration can discover the underlying task structure during reinforcement learning.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="http://tinylogger.com/articles/s41593-023-01514-1/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-023-01514-1/MediaObjects/41593_2023_1514_Fig6_HTML.png?as=webp"/><img aria-describedby="Fig6" src="http://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs41593-023-01514-1/MediaObjects/41593_2023_1514_Fig6_HTML.png" alt="figure 6" loading="lazy" width="685" height="110"/></picture></a></div><div data-test="bottom-caption" id="figure-6-desc"><p><b>a</b>, Reinforcement learning task. Human participants were required to choose between two options, leading to either reward (gaining coins) or punishment (losing coins) with different probabilities. The probability of reward was occasionally reversed between the two options. <b>b</b>, The minimal network encoding the essential elements of the task. <b>c</b>, Activity of the output neuron corresponding to the selected option from networks trained with prospective configuration and backpropagation compared with fMRI data measured in human participants (that is, peak blood oxygenation level-dependent (%BOLD) signal in the mPFC). Prospective configuration reproduces the key finding that the expected value (encoded in %BOLD signal in the mPFC) increases if the next choice after a punishing trial is to switch to the other option. The number of trials is not mentioned in the original paper, so we simulated for <i>n</i> = 128 trials for both learning rules. Error bars represent the 68% confidence interval.</p><p><a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#MOESM3">Source data</a></p></div></div><div><a data-test="article-link" data-track="click" data-track-label="button" data-track-action="view figure" href="http://tinylogger.com/articles/s41593-023-01514-1/figures/6" data-track-dest="link:Figure6 Full size image" aria-label="Full size image figure 6" rel="nofollow"><span>Full size image</span><svg width="16" height="16" focusable="false" role="img" aria-hidden="true"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-chevron-right-small"></use></svg></a></div></figure></div><p>This task can be conceptualized as having a latent state encoding which option is superior, and this latent state determines the reward probabilities for both options. Consequently, we consider a neural network reflecting this structure (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig6">6b</a>) that includes an input neuron encoding being in the task (equal to 1 in simulations), a hidden neuron encoding the latent state and two output neurons encoding the reward probabilities for the two options. Trained with the exact procedure of the experiment<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 38" title="Hampton, A. N., Bossaerts, P. &amp; O’Doherty, J. P. The role of the ventromedial prefrontal cortex in abstract state-based inference during decision making in humans. J. Neurosci. 26, 8360–8367 (2006)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR38" id="ref-link-section-d41463491e1654">38</a></sup> from randomly initialized weights, prospective configuration with this minimal network can reproduce the data, whereas backpropagation cannot (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig6">6c</a>). In Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#MOESM1">10</a>, we show that prospective configuration reproduces these data because it can infer the rewarded choice by updating the activity of the hidden neuron based on feedback.</p><p>Taken together, the presented simulations illustrate that prospective configuration is a common principle that can explain a range of surprising learning effects in diverse tasks.</p></div></div></section><section data-title="Discussion"><div id="Sec9-section"><h2 id="Sec9">Discussion</h2><div id="Sec9-content"><p>Our paper identifies the principle of prospective configuration, according to which learning relies on neurons first optimizing their pattern of activity to match the correct output and then reinforcing these prospective activities through synaptic plasticity. Although it was known that in energy-based networks the activity of neurons shifts before weight update, it has been previously thought that this shift is a necessary cost of error propagation in biological networks, and several methods have been proposed to suppress it<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Scellier, B. &amp; Bengio, Y. Equilibrium propagation: bridging the gap between energy-based models and backpropagation. Front. Comput. Neurosci. 11, 24 (2017)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR11" id="ref-link-section-d41463491e1676">11</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Whittington, J. C. R. &amp; Bogacz, R. An approximation of the error backpropagation algorithm in a predictive coding network with local hebbian synaptic plasticity. Neural Comput. 29, 1229–1262 (2017)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR12" id="ref-link-section-d41463491e1679">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Song, Y., Lukasiewicz, T., Xu, Z. &amp; Bogacz, R. Can the brain do backpropagation? Exact implementation of backpropagation in predictive coding networks. In Advances in Neural Information Processing Systems (NeurIPS) (eds Larochell, H. et al.) 22566–22579 (Curran Associates, 2020)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR14" id="ref-link-section-d41463491e1682">14</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Millidge, B., Tschantz, A. &amp; Buckley, C. L. Predictive coding approximates backprop along arbitrary computation graphs. Neural Comput. 34, 1329–1368 (2022)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR20" id="ref-link-section-d41463491e1685">20</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="Bengio, Y. &amp; Fischer, A. Early inference in energy-based models approximates back-propagation. Preprint at 
                  https://doi.org/10.48550/arXiv.1510.02777
                  
                 (2015)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR21" id="ref-link-section-d41463491e1688">21</a></sup> to approximate backpropagation more closely. By contrast, we demonstrate that this reconfiguration of neural activity is the key to achieving learning performance superior to that of backpropagation and to explaining experimental data from diverse learning tasks. Prospective configuration further offers a range of experimental predictions distinct from those of backpropagation (Supplementary Figs. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#MOESM1">11</a> and <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#MOESM1">12</a>). Together, we have demonstrated that prospective configuration enables more efficient learning than backpropagation by reducing interference, demonstrates superior performance in situations faced by biological organisms, requires only local computation and plasticity and matches experimental data across a wide range of tasks.</p><p>Our theory addresses a long-standing question of how the brain solves the plasticity-stability dilemma, for example, how it is possible that, despite adjustment of representation in the primary visual cortex during learning<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 43" title="Poort, J. et al. Learning enhances sensory and multiple non-sensory representations in primary visual cortex. Neuron 86, 1478–1490 (2015)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR43" id="ref-link-section-d41463491e1701">43</a></sup>, we can still understand the meaning of visual stimuli we learned over our lifetime. According to prospective configuration, when some weights are modified, compensatory changes are made to other weights to ensure the stability of correctly predicted outputs. Thus, prospective configuration reduces interference between different weight modifications while learning a single association. Previous computational models have proposed mechanisms that reduce interference between new and previously acquired information while learning multiple associations<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 34" title="Zenke, F., Poole, B. &amp; Ganguli, S. Continual learning through synaptic intelligence. In Proc. 34th International Conference on Machine Learning (eds Precup, D. &amp; Teh, Y. W.) 3987–3995 (PMLR, 2017)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR34" id="ref-link-section-d41463491e1705">34</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 44" title="McClelland, J. L., McNaughton, B. L. &amp; O’Reilly, R. C. Why there are complementary learning systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory. Psychol. Rev. 102, 419–457 (1995)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR44" id="ref-link-section-d41463491e1708">44</a></sup>. It is highly likely that such mechanisms and prospective configuration operate in the brain in parallel to minimize both types of interference.</p><p>Prospective configuration is related to inference and learning procedures in statistical modeling. If the ‘energy’ in energy-based schemes is variational free energy, prospective configuration can be seen as an implementation of variational Bayes that subsumes inference and learning<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 45" title="Dauwels, J. On variational message passing on factor graphs. In 2007 IEEE International Symposium on Information Theory, 2546–2550 (IEEE, 2007)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR45" id="ref-link-section-d41463491e1715">45</a></sup>. For example, dynamic expectation maximization<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 46" title="Anil Meera, A. &amp; Wisse, M. Dynamic expectation maximization algorithm for estimation of linear systems with colored noise. Entropy 23, 1306 (2021)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR46" id="ref-link-section-d41463491e1719">46</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 47" title="Friston, K. Hierarchical models in the brain. PLoS Comput. Biol. 4, e1000211 (2008)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR47" id="ref-link-section-d41463491e1722">47</a></sup> can be regarded as a generalization of predictive coding networks in which the D-step optimizes representations of latent states (analogously to relaxation until convergence during inference) while the E-step optimizes model parameters (analogously to weight modification during learning).</p><p>Other recent work<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 48" title="Meulemans, A., Farinha, M. T., Cervera, M. R., Sacramento, J. &amp; Grewe, B. F. Minimizing control for credit assignment with strong feedback. In Proc. of Machine Learning Research (eds Chaudhuri, K. et al.) 15458–15483 (PMLR, 2022)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR48" id="ref-link-section-d41463491e1729">48</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 49" title="Meulemans, A., Zucchet, N., Kobayashi, S., von Oswald, J. &amp; Sacramento, J. The least-control principle for learning at equilibrium. Adv. Neural Inf. Process. Syst. 35, 33603–33617 (2022)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR49" id="ref-link-section-d41463491e1732">49</a></sup> also noticed that the natural form of energy-based networks (‘strong control’ in their words) performs different learning than backpropagation. Their analysis concentrates on an architecture of deep feedback control, and they demonstrated that a particular form of their model is equivalent to predictive coding networks<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 49" title="Meulemans, A., Zucchet, N., Kobayashi, S., von Oswald, J. &amp; Sacramento, J. The least-control principle for learning at equilibrium. Adv. Neural Inf. Process. Syst. 35, 33603–33617 (2022)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR49" id="ref-link-section-d41463491e1736">49</a></sup>. The unique contribution of our paper is to show the benefits of such strong control and explain why they arise. The principle of prospective configuration is also present in other recent models. For example, Gilra and Gerstner<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 50" title="Gilra, A. &amp; Gerstner, W. Predicting non-linear dynamics by stable local learning in a recurrent spiking neural network. eLife 6, e28295 (2017)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR50" id="ref-link-section-d41463491e1740">50</a></sup> developed a spiking model in which feedback about the error on the output directly affects the activity of hidden neurons before plasticity takes place. Haider et al.<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 51" title="Haider, P. et al. Latent equilibrium: a unified learning theory for arbitrarily fast computation with arbitrarily slow neurons. In Advances in Neural Information Processing Systems (NeurIPS) (eds Ranzato, M. et al.) 17839–17851 (2021)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR51" id="ref-link-section-d41463491e1744">51</a></sup> developed a faster inference algorithm for energy-based models that computes a value to which the activity is likely to converge, termed latent equilibrium<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 51" title="Haider, P. et al. Latent equilibrium: a unified learning theory for arbitrarily fast computation with arbitrarily slow neurons. In Advances in Neural Information Processing Systems (NeurIPS) (eds Ranzato, M. et al.) 17839–17851 (2021)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR51" id="ref-link-section-d41463491e1748">51</a></sup>. Iteratively setting each neuron’s output based on its latent equilibrium leads to much faster inference<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 51" title="Haider, P. et al. Latent equilibrium: a unified learning theory for arbitrarily fast computation with arbitrarily slow neurons. In Advances in Neural Information Processing Systems (NeurIPS) (eds Ranzato, M. et al.) 17839–17851 (2021)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR51" id="ref-link-section-d41463491e1753">51</a></sup> and enables efficient computation of the prospective configuration.</p><p>Predictive coding networks require symmetric forward and backward weights between layers of neurons, so a question arises concerning how such symmetry may develop in the brain. If predictive coding networks are initialized with symmetric weights (as in our simulations), the symmetry will persist because the changes in weight between neurons A and B are the same as those for feedback weight (between neurons B and A). Even if the weights are not initialized symmetrically, the symmetry may develop if synaptic decay is included in the model<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 52" title="Akrout, M., Wilson, C., Humphreys, P., Lillicrap, T. &amp; Tweed, D. B. Deep learning without weight transport. In Advances in Neural Information Processing Systems (NeurIPS) (eds Wallach, H. et al.) (Curran Associates, 2019)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR52" id="ref-link-section-d41463491e1761">52</a></sup> because then the initial asymmetric values decay away, and weight values become more influenced by recent changes that are symmetric. Nevertheless, weight symmetry is not generally required for effective credit assignment<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 53" title="Lillicrap, T. P., Cownden, D., Tweed, D. B. &amp; Akerman, C. J. Random synaptic feedback weights support error backpropagation for deep learning. Nat. Commun. 7, 13276 (2016)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR53" id="ref-link-section-d41463491e1765">53</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 54" title="Millidge, B., Tschantz, A. &amp; Buckley, C. L. Relaxing the constraints on predictive coding models. Preprint at 
                  https://doi.org/10.48550/arXiv.2010.01047
                  
                 (2020)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR54" id="ref-link-section-d41463491e1768">54</a></sup>.</p><p>Here, we assumed for simplicity that the convergence of neural activity to an equilibrium happens rapidly after the stimuli are provided so that the synaptic weight modification after convergence may take place while the stimuli are still present. Nevertheless, predictive coding networks can still work even if weight modification takes place while the neural activity is converging. Specifically, Song et al. demonstrated that if neural activities are only updated for the first few steps, the update of the weights is equivalent to that in backpropagation<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Song, Y., Lukasiewicz, T., Xu, Z. &amp; Bogacz, R. Can the brain do backpropagation? Exact implementation of backpropagation in predictive coding networks. In Advances in Neural Information Processing Systems (NeurIPS) (eds Larochell, H. et al.) 22566–22579 (Curran Associates, 2020)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR14" id="ref-link-section-d41463491e1775">14</a></sup>. As a reminder, we demonstrate here that if the neural activities are updated to equilibrium, the update of the weights follows the principle of prospective configuration and possesses the desirable demonstrated properties. Thus, a learning rule where neural activities and weights are updated in parallel will experience a weight update that is equivalent to backpropagation at the start and then move to prospective configuration as the system converges to equilibrium<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 55" title="Salvatori, T. et al. Incremental predictive coding: a parallel and fully automatic learning algorithm. Preprint at 
                  https://doi.org/10.48550/arXiv.2212.00720
                  
                 (2022)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR55" id="ref-link-section-d41463491e1779">55</a></sup>. Furthermore, predictive coding networks have been extended to describe recurrent structures<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Friston, K. J., Trujillo-Barreto, N. &amp; Daunizeau, J. Dem: a variational treatment of dynamic systems. NeuroImage 41, 849–885 (2008)." href="#ref-CR56" id="ref-link-section-d41463491e1783">56</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Millidge, B., Tang, M., Osanlouy, M. &amp; Bogacz, R. Predictive coding networks for temporal prediction. Preprint at bioRxiv 
                  https://doi.org/10.1101/2023.05.15.540906
                  
                 (2023)." href="#ref-CR57" id="ref-link-section-d41463491e1783_1">57</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 58" title="Salvatori, T. et al. Learning on arbitrary graph topologies via predictive coding. In Advances in Neural Information Processing Systems (NeurIPS) (eds Koyejo, S. et al.) 38232–38244 (Curran Associates, 2022)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR58" id="ref-link-section-d41463491e1786">58</a></sup>, and it has been shown that such networks can learn to predict dynamically changing stimuli even if weights are modified before the activity converged for a given ‘frame’ of the stimulus<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 57" title="Millidge, B., Tang, M., Osanlouy, M. &amp; Bogacz, R. Predictive coding networks for temporal prediction. Preprint at bioRxiv 
                  https://doi.org/10.1101/2023.05.15.540906
                  
                 (2023)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR57" id="ref-link-section-d41463491e1790">57</a></sup>.</p><p>The advantages of prospective configuration suggest that it may be profitably applied in machine learning to improve the efficiency and performance of deep neural networks. An obstacle for this is that the relaxation phase is computationally expensive. However, recent work demonstrated that by modifying weights after each step of relaxation, the model becomes comparably fast to backpropagation and easier for parallelization<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 55" title="Salvatori, T. et al. Incremental predictive coding: a parallel and fully automatic learning algorithm. Preprint at 
                  https://doi.org/10.48550/arXiv.2212.00720
                  
                 (2022)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR55" id="ref-link-section-d41463491e1797">55</a></sup>.</p><p>Most intriguingly, it has been demonstrated that the speed of energy-based networks can be greatly increased by implementing the relaxation on analog hardware<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 59" title="Foroushani, A. N., Assaf, H., Noshahr, F. H., Savaria, Y. &amp; Sawan, M. Analog circuits to accelerate the relaxation process in the equilibrium propagation algorithm. In 2020 IEEE International Symposium on Circuits and Systems (ISCAS) 1–5 (IEEE, 2020)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR59" id="ref-link-section-d41463491e1804">59</a></sup>, potentially resulting in energy-based networks being faster than backpropagation. Therefore, we anticipate that our discoveries may change the blueprint of next-generation machine learning hardware, switching from the current digital tensor base to analog hardware and being closer to the brain and potentially far more efficient.</p></div></div></section><section data-title="Methods"><div id="Sec10-section"><h2 id="Sec10">Methods</h2><div id="Sec10-content"><p>This section provides the necessary details for replication of the results described in the main text.</p><h3 id="Sec11">Models</h3><p>Throughout this work, we compare the established theory of backpropagation to the proposed new principle of prospective configuration. As explained in the main text, backpropagation is used to train ANNs, where the activity of a neuron is fixed to a value based on its input, whereas prospective configuration occurs in energy-based networks, where the activity of a neuron is not fixed.</p><p>Because in ANNs the activity of neurons <b><i>x</i></b> is determined by their input, the output of the network can be obtained by propagating the inputs ‘forward’ through the computational graph. The output can then be compared to a target pattern to get a measure of difference known as a loss. Because the value of a node (activity of a neuron) in the computational graph is explicitly computed as a function of its input, the computational graph is usually differentiable. Thus, training ANNs with backpropagation modifies the weights <b><i>w</i></b> to take a step toward the negative gradient of loss <span>\({{{\mathcal{L}}}}\)</span>,</p><div id="Equ1"><p><span>$${{\Delta }}{{{\boldsymbol{w}}}}=-\alpha \frac{\partial {{{\mathcal{L}}}}}{\partial {{{\boldsymbol{w}}}}},$$</span></p><p>
                    (1)
                </p></div><p>during which the activities of neurons <b><i>x</i></b> are fixed, and <i>α</i> is the learning rate. The weights <b><i>w</i></b> requiring modification might be many steps away from the output on the computational graph, where the loss <span>\({{{\mathcal{L}}}}\)</span> is computed; thus, <span>\(\frac{\partial {{{\mathcal{L}}}}}{\partial {{{\boldsymbol{w}}}}}\)</span> is often obtained by applying the chain rule of computing a derivative through intermediate variables (activity of output and hidden neurons). For example, consider a network with four layers, and let <b><i>x</i></b><sup><i>l</i></sup> denote the activity of neurons in layer <i>l</i> and <b><i>w</i></b><sup><i>l</i></sup> denote the weights of connections between layers <i>l</i> and <i>l</i> + 1. The change in weights originating from the first layer is then computed: <span>\(\frac{\partial {{{\mathcal{L}}}}}{\partial {{{{\boldsymbol{w}}}}}^{1}}=\frac{\partial {{{\mathcal{L}}}}}{\partial {{{{\boldsymbol{x}}}}}^{4}}\cdot \frac{\partial {{{{\boldsymbol{x}}}}}^{4}}{\partial {{{{\boldsymbol{x}}}}}^{3}}\ldots \frac{\partial {{{{\boldsymbol{x}}}}}^{2}}{\partial {{{{\boldsymbol{w}}}}}^{1}}\)</span>. This enables the loss to be backpropagated through the graph to provide a direction of update for all weights.</p><p>In contrast to ANNs, in energy-based networks, the activity of neurons <b><i>x</i></b> is not fixed to the input from a previous layer. Instead, an energy function <i>E</i> is defined as a function of the neural activity <b><i>x</i></b> and weights <b><i>w</i></b>. For networks organized in layers (considered in this paper), the energy can be decomposed into a sum of local energy terms <i>E</i><sup><i>l</i></sup>,</p><div id="Equ2"><p><span>$$E=\mathop{\sum}\limits_{l}{E}^{l}\left({{{{\boldsymbol{x}}}}}^{l},{{{{\boldsymbol{w}}}}}^{l-1},{{{{\boldsymbol{x}}}}}^{l-1}\right).$$</span></p><p>
                    (2)
                </p></div><p>Here, <i>E</i><sup><i>l</i></sup> is called local energy because it is a function of <b><i>x</i></b><sup><i>l</i></sup>, <b><i>x</i></b><sup><i>l</i> − 1</sup> and <b><i>w</i></b><sup><i>l</i> − 1</sup>, which are neighbors and connected to each other. This ensures that the optimization of energy <i>E</i> can be implemented by local circuits because the derivative of <i>E</i> with respect to any neural activity (or weights) results in an equation containing only the local activity (or weights) and the activity of adjacent neurons. Predictions with energy-based networks are computed by clamping the input neurons to an input pattern and then modifying the activity of all other neurons to decrease the energy:</p><div id="Equ3"><p><span>$${{\Delta }}{{{\boldsymbol{x}}}}=-\gamma \frac{\partial E}{\partial {{{\boldsymbol{x}}}}},$$</span></p><p>
                    (3)
                </p></div><p>where <i>γ</i> is the integration step of the neural dynamics. Because the terms in <i>E</i> can be divided into local energy terms, this results in an equation that can be implemented with local circuits. This process of modifying neural activity to decrease the energy is called relaxation, and we refer to the equation describing relaxation as neural dynamics because it describes the dynamics of the neural activity in energy-based networks. After convergence of relaxation, the activities of the output neurons are taken as the prediction made by the energy-based network. Different energy-based networks are trained in slightly different ways. For predictive coding networks<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Whittington, J. C. R. &amp; Bogacz, R. An approximation of the error backpropagation algorithm in a predictive coding network with local hebbian synaptic plasticity. Neural Comput. 29, 1229–1262 (2017)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR12" id="ref-link-section-d41463491e2383">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Rao, R. P. &amp; Ballard, D. H. Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. Nat. Neurosci. 2, 79–87 (1999)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR18" id="ref-link-section-d41463491e2386">18</a></sup>, training involves clamping the input and output neurons to input and target patterns, respectively. Then, relaxation is run until convergence (<span>\({{{\boldsymbol{x}}}}=\mathop{{{{\boldsymbol{x}}}}}\limits^{* }\)</span>), after which the weights are updated using the activity at convergence to further decrease the energy:</p><div id="Equ4"><p><span>$${\Delta }{\boldsymbol{w}}=-\alpha \frac{\partial E}{\partial {\boldsymbol{w}}}{\vert }_{{\boldsymbol{x}} = \mathop{\boldsymbol{x}}\limits^{*}}.$$</span></p><p>
                    (4)
                </p></div><p>This will also result in an equation that can be implemented with local plasticity because it is just a gradient descent on the local energy. We refer to such an equation as weight dynamics, because it describes the dynamics of the weights in energy-based networks.</p><p>Backpropagation and prospective configuration are not restricted to specific models. Depending on the structure of the network and the choice of the energy function, one can define different models that implement the principle of backpropagation or prospective configuration. In the main text and most of the <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#MOESM1">Supplementary Notes</a>, we investigate the most standard layered network. In this case, both ANNs and energy-based networks include <i>L</i> layers of weights <b><i>w</i></b><sup>1</sup>, <b><i>w</i></b><sup>2</sup>, …, <b><i>w</i></b><sup><i>L</i></sup> and <i>L</i> + 1 layers of neurons <b><i>x</i></b><sup>1</sup>, <b><i>x</i></b><sup>2</sup>, …, <b><i>x</i></b><sup><i>L</i> + 1</sup>, where <b><i>x</i></b><sup>1</sup> and <b><i>x</i></b><sup><i>L</i> + 1</sup> are the input and output neurons, respectively. We consider the relationship between activities in adjacent layers for ANNs given by</p><div id="Equ5"><p><span>$${{{{\boldsymbol{x}}}}}^{l}={{{{\boldsymbol{w}}}}}^{l-1}f\,\left({{{{\boldsymbol{x}}}}}^{l-1}\right),$$</span></p><p>
                    (5)
                </p></div><p>and the energy function for EBNs described by</p><div id="Equ6"><p><span>$${E}^{l}=\frac{1}{2}{\left({{{{\boldsymbol{x}}}}}^{l}-{{{{\boldsymbol{w}}}}}^{l-1}f\left({{{{\boldsymbol{x}}}}}^{l-1}\right)\right)}^{2}.$$</span></p><p>
                    (6)
                </p></div><p>This defines the ANNs to be the standard multilayer perceptrons (MLPs) and the energy-based networks to be the predictive coding network. In Eq. (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Equ6">6</a>) and below, the square operator (<b><i>v</i></b>)<sup>2</sup> denotes the inner product of vector <b><i>v</i></b> with itself. The comparison between backpropagation and prospective configuration in the main text is thus between the above MLPs and predictive coding networks; this choice is justified as (1) they are the most standard models<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 61" title="Goodfellow, I., Bengio, Y. &amp; Courville, A. Deep Learning (MIT Press Cambridge, 2016)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR61" id="ref-link-section-d41463491e2788">61</a></sup> and (2) it is established that the two are closely related<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Whittington, J. C. R. &amp; Bogacz, R. An approximation of the error backpropagation algorithm in a predictive coding network with local hebbian synaptic plasticity. Neural Comput. 29, 1229–1262 (2017)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR12" id="ref-link-section-d41463491e2793">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Song, Y., Lukasiewicz, T., Xu, Z. &amp; Bogacz, R. Can the brain do backpropagation? Exact implementation of backpropagation in predictive coding networks. In Advances in Neural Information Processing Systems (NeurIPS) (eds Larochell, H. et al.) 22566–22579 (Curran Associates, 2020)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR14" id="ref-link-section-d41463491e2796">14</a></sup> (that is, they make the same prediction with the same weights and input pattern), thus enabling a fair comparison. Nevertheless, we show that the theory (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#MOESM1">5</a>) and empirical comparison (Supplementary Figs. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#MOESM1">6</a> and <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#MOESM1">7</a>) between backpropagation and prospective configuration generalize to other choices of network structures and energy functions, that is, other energy-based networks and ANNs, such as GeneRec<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 62" title="O’Reilly, R. C. Biologically plausible error-driven learning using local activation differences: the generalized recirculation algorithm. Neural Comput. 8, 895–938 (1996)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR62" id="ref-link-section-d41463491e2809">62</a></sup> and Almeida–Pineda<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Almeida, L. B. A learning rule for asynchronous perceptrons with feedback in a combinatorial environment. In Artificial Neural Networks: Concept Learning (ed. Diederich, J.) 102–111 (IEEE Computer Society Press, 1990)." href="#ref-CR63" id="ref-link-section-d41463491e2813">63</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Pineda, F. Generalization of back propagation to recurrent and higher order neural networks. In Advances in Neural Information Processing Systems (NeurIPS) (ed. Anderson, D.) 602–611 (Curran Associates, 1987)." href="#ref-CR64" id="ref-link-section-d41463491e2813_1">64</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 65" title="Pineda, F. J. Dynamics and architecture for neural computation. J. Complex. 4, 216–245 (1988)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR65" id="ref-link-section-d41463491e2816">65</a></sup>.</p><p>Putting Eqs. (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Equ5">5</a>) and (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Equ6">6</a>) into the general framework, we can obtain the equations that describe MLPs and predictive coding networks, respectively. Assume that the input and target patterns are <b><i>s</i></b><sup>in</sup> and <b><i>s</i></b><sup>target</sup>, respectively. Prediction with MLPs is</p><div id="Equ7"><p><span>$${{{{\boldsymbol{x}}}}}^{1}={{{{\boldsymbol{s}}}}}^{{{{\rm{in}}}}}\,{{{\rm{and}}}}\,{{{{\boldsymbol{x}}}}}^{l}={{{{\boldsymbol{w}}}}}^{l-1}{f}\,\left({{{{\boldsymbol{x}}}}}^{l-1}\right){{{\rm{for}}}}\,l &gt; 1,$$</span></p><p>
                    (7)
                </p></div><p>where <b><i>x</i></b><sup><i>L</i> + 1</sup> is the prediction. Training MLPs with backpropagation is described by</p><div id="Equ8"><p><span>$${{\Delta }}{{{{\boldsymbol{w}}}}}^{l}=-\alpha \frac{\partial {{{\mathcal{L}}}}}{\partial {{{{\boldsymbol{w}}}}}^{l}}=-\alpha \frac{\partial {{{\mathcal{L}}}}}{\partial {{{{\boldsymbol{x}}}}}^{L+1}}\cdot \frac{\partial {{{{\boldsymbol{x}}}}}^{L+1}}{\partial {{{{\boldsymbol{x}}}}}^{L}}\ldots \frac{\partial {{{{\boldsymbol{x}}}}}^{l+1}}{\partial {{{{\boldsymbol{w}}}}}^{l}}\,{{{\rm{where}}}}\,\,{{{\mathcal{L}}}}=\frac{1}{2}{\left({{{{\boldsymbol{s}}}}}^{{{{\rm{target}}}}}-{{{{\boldsymbol{x}}}}}^{L+1}\right)}^{2},$$</span></p><p>
                    (8)
                </p></div><p>which backpropagates the error <span>\(\frac{\partial {{{\mathcal{L}}}}}{\partial {{{{\boldsymbol{x}}}}}^{l}}\)</span> layer by layer from output neurons.</p><p>The neural dynamics of predictive coding networks can be obtained using Eq. (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Equ2">2</a>):</p><div id="Equ9"><p><span>$${{\Delta }}{{{{\boldsymbol{x}}}}}^{l}=-\gamma \frac{\partial E}{\partial {{{{\boldsymbol{x}}}}}^{l}}=-\gamma \frac{\partial ({E}^{l}+{E}^{l+1})}{\partial {{{{\boldsymbol{x}}}}}^{l}}.$$</span></p><p>
                    (9)
                </p></div><p>Similarly, the weight dynamics of predictive coding networks can be found,</p><div id="Equ10"><p><span>$${{\Delta }}{{{{\boldsymbol{w}}}}}^{l}=-\alpha \frac{\partial E}{\partial {{{{\boldsymbol{w}}}}}^{l}}=-\alpha \frac{\partial {E}^{l+1}}{\partial {{{{\boldsymbol{w}}}}}^{l}}.$$</span></p><p>
                    (10)
                </p></div><p>To reveal the neural implementation of predictive coding networks, we define the prediction errors to be</p><div id="Equ11"><p><span>$${{{{\boldsymbol{\varepsilon }}}}}^{l}={{{{\boldsymbol{x}}}}}^{l}-{{{{\boldsymbol{w}}}}}^{l-1}{f}\,\left({{{{\boldsymbol{x}}}}}^{l-1}\right).$$</span></p><p>
                    (11)
                </p></div><p>The neural and weight dynamics of predictive coding networks can be expressed (by evaluating derivatives in Eqs. (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Equ9">9</a>) and (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Equ10">10</a>)) as</p><div id="Equ12"><p><span>$${{\Delta }}{{{{\boldsymbol{x}}}}}^{l}=-\gamma {{{{\boldsymbol{\varepsilon }}}}}^{l}+{f}^{{\prime} }\left({{{{\boldsymbol{x}}}}}^{l}\right)\circ {\left({{{{\boldsymbol{w}}}}}^{l}\right)}^{T}{{{{\boldsymbol{\varepsilon }}}}}^{l+1}\,{\mathrm{and}}$$</span></p><p>
                    (12)
                </p></div><div id="Equ13"><p><span>$${{\Delta }}{{{{\boldsymbol{w}}}}}^{l}=\alpha {{{{\boldsymbol{\varepsilon }}}}}^{l+1}{\left({f}\left({{{{\boldsymbol{x}}}}}^{l}\right)\right)}^{T},$$</span></p><p>
                    (13)
                </p></div><p>where the symbol <span>∘</span> denotes element-wise multiplication. Assuming that <b><i>ε</i></b><sup><i>l</i></sup> and <b><i>x</i></b><sup><i>l</i></sup> are encoded in the activity of error and value neurons, respectively, Eqs. (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Equ11">11</a>) and (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Equ12">12</a>) can be realized with the neural implementation in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig2">2c</a>. In particular, error <b><i>ε</i></b> and value <b><i>x</i></b> neurons are represented by red and blue nodes, respectively; excitatory + and inhibitory − connections are represented by connections with solid and hollow nodes, respectively. Thus, Eqs. (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Equ11">11</a>) and (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Equ12">12</a>) are implemented with red and blue connections, respectively. It should also be noted that the weight dynamics are also realized locally. The weight change described by Eq. (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Equ13">13</a>) corresponds to simple Hebbian plasticity<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 66" title="Hebb, D. O. The Organisation of Behaviour: A Neuropsychological Theory (Science Editions New York, 1949)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR66" id="ref-link-section-d41463491e3996">66</a></sup> in the neural implementation of Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig2">2c</a>; that is, the change in a weight is proportional to the product of activity of presynaptic and postsynaptic neurons. Thus, a predictive coding network, as an energy-based network, can be implemented with local circuits only due to the local nature of energy terms (as argued earlier in this section). Note that when the network is expressive enough such that learning can reduce the energy <i>E</i> to 0, the loss <span>\({{{\mathcal{L}}}}\)</span> must also become 0 as <span>\({{{\mathcal{L}}}}\)</span> is one of the terms in energy <i>E</i>, that is <span>\({{{\mathcal{L}}}}={E}^{L+1}\)</span>, and, in this case, the predictive coding network is guaranteed to minimize the loss, just like backpropagation<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 67" title="Senn, W. et al. A neuronal least-action principle for real-time learning in cortical circuits. Preprint at bioRxiv 
                  https://doi.org/10.1101/2023.03.25.534198
                  
                 (2023)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR67" id="ref-link-section-d41463491e4087">67</a></sup>.</p><p>The full algorithm of the predictive coding network is summarized in Algorithm <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#FPar1">1</a>. In all simulations in this paper (unless stated otherwise), the integration step of the neural dynamics (that is, relaxation) is set to <i>γ</i> = 0.1, and the relaxation is performed for 128 steps (<span>\({{{\mathcal{T}}}}\)</span> in Algorithm <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#FPar1">1</a>). During relaxation, if the overall energy is not decreased from the last step, the integration step is reduced by 50%; if the integration step is reduced two times (that is, reaching 0.025), relaxation is terminated early. By monitoring the number of relaxation steps performed, we notice that in most of the tasks we performed, relaxation is terminated early at around 60 iterations.</p>
                  <h3 id="FPar1">Algorithm 1</h3>
                  <p>Learn with a predictive coding network<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Whittington, J. C. R. &amp; Bogacz, R. An approximation of the error backpropagation algorithm in a predictive coding network with local hebbian synaptic plasticity. Neural Comput. 29, 1229–1262 (2017)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR12" id="ref-link-section-d41463491e4128">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Rao, R. P. &amp; Ballard, D. H. Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. Nat. Neurosci. 2, 79–87 (1999)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR18" id="ref-link-section-d41463491e4131">18</a></sup> <img src="http://media.springernature.com/lw684/springer-static/image/art%3A10.1038%2Fs41593-023-01514-1/MediaObjects/41593_2023_1514_Figa_HTML.png" alt=""/></p>
                <p>In the Supplementary <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#MOESM1">Information</a>, we also investigate other choices of network structures and energy functions, resulting in other ANNs and energy-based networks. Overall, the energy-based networks investigated include predictive coding networks<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Whittington, J. C. R. &amp; Bogacz, R. An approximation of the error backpropagation algorithm in a predictive coding network with local hebbian synaptic plasticity. Neural Comput. 29, 1229–1262 (2017)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR12" id="ref-link-section-d41463491e4146">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 18" title="Rao, R. P. &amp; Ballard, D. H. Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. Nat. Neurosci. 2, 79–87 (1999)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR18" id="ref-link-section-d41463491e4149">18</a></sup>, target predictive coding networks and GeneRec<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 62" title="O’Reilly, R. C. Biologically plausible error-driven learning using local activation differences: the generalized recirculation algorithm. Neural Comput. 8, 895–938 (1996)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR62" id="ref-link-section-d41463491e4153">62</a></sup>, and the ANNs investigated include backpropagation and Almeida–Pineda<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Almeida, L. B. A learning rule for asynchronous perceptrons with feedback in a combinatorial environment. In Artificial Neural Networks: Concept Learning (ed. Diederich, J.) 102–111 (IEEE Computer Society Press, 1990)." href="#ref-CR63" id="ref-link-section-d41463491e4157">63</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Pineda, F. Generalization of back propagation to recurrent and higher order neural networks. In Advances in Neural Information Processing Systems (NeurIPS) (ed. Anderson, D.) 602–611 (Curran Associates, 1987)." href="#ref-CR64" id="ref-link-section-d41463491e4157_1">64</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 65" title="Pineda, F. J. Dynamics and architecture for neural computation. J. Complex. 4, 216–245 (1988)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR65" id="ref-link-section-d41463491e4160">65</a></sup>. Details of all the models can be found in corresponding previous work and are also given in the <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#MOESM1">Supplementary Notes</a>, Section 2.1.</p><h3 id="Sec12">Interference and measuring interference (that is, target alignment)</h3><p>In Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig3">3a</a>, because it simulates the example in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig1">1</a>, the network has one input neuron, one hidden neuron and two output neurons; weights were all initialized to 1, the input pattern was <span>\(\left[1\right]\)</span>, and the target pattern was <span>\(\left[0,1\right]\)</span>. Learning rates of both learning rules were 0.2, and the weights were updated for 24 iterations. Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig3">3d</a> repeated the same experiment as in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig3">3a</a> but with the learning rate searched from <span>\(\left(0.005,0.01,0.05,0.1\right)\)</span>, which is wide enough to cover essentially all learning rates used to train deep neural networks in practice.</p><p>In Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig3">3e</a>, there were 64 neurons in each layer (including input and output layers) for each network; weights were initialized via standard Xavier uniform initialization<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 68" title="Glorot, X. &amp; Bengio, Y. Understanding the difficulty of training deep feedforward neural networks. In Proc. 13th International Conference on Artificial Intelligence and Statistics (eds Teh, Y. W. &amp; Titterington, M.) 249–256 (PMLR, 2010)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR68" id="ref-link-section-d41463491e4280">68</a></sup>. No activation function was used, that is, linear networks were investigated. Depths of networks (<i>L</i>) took values from <span>\(\left\{1,2,\ldots ,24,25\right\}\)</span>, as reported on the <i>x</i> axis. Input and target patterns were a pair of randomly generated patterns with a mean of 0 and standard deviation (s.d.) of 1. Learning rates of both learning rules were 0.001. Weights were updated for one iteration, and target alignment was measured. The whole experiment was repeated 27 times with each individual experiment reported as a point.</p><p>Simulations in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig3">3f–h</a> followed the experimental setup in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig4">4a–h</a>; these are described at the end of <a data-track="click" data-track-label="link" data-track-action="section anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Sec13">Biologically relevant tasks</a>.</p><h3 id="Sec13">Biologically relevant tasks</h3><p>In supervised learning simulations, fully connected networks in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig4">4a–h</a> were trained and tested on FashionMNIST<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 60" title="Xiao, H., Rasul, K. &amp; Vollgraf, R. Fashion MNIST: a novel image dataset for benchmarking machine learning algorithms. Preprint at 
                  https://doi.org/10.48550/arXiv.1708.07747
                  
                 (2017)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR60" id="ref-link-section-d41463491e4353">60</a></sup>, and convolutional neural networks<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 35" title="O’Shea, K. &amp; Nash, R. An introduction to convolutional neural networks. Preprint at 
                  https://doi.org/10.48550/arXiv.1511.08458
                  
                 (2015)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR35" id="ref-link-section-d41463491e4357">35</a></sup> (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig4">4i,j</a>) were trained and tested on CIFAR-10 (ref. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 36" title="Krizhevsky, A. &amp; Hinton, G. Learning Multiple Layers of Features from Tiny Images. Master’s thesis, Univ. Toronto (2009)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR36" id="ref-link-section-d41463491e4364">36</a></sup>). With FashionMNIST, models were trained to perform classification of gray-scaled fashion item images into ten categories, such as trousers, pullovers and dresses. FashionMNIST was chosen because it is of moderate and appropriate difficulty for multilayer non-linear deep neural networks so that the comparisons with energy-based networks are informative. Classification of the data in CIFAR-10 is more difficult, as it contains colored natural images belonging to categories such as cars, birds and cats and is thus only evaluated with convolutional neural networks. Both datasets consist of 60,000 training examples (that is, training set) and 10,000 test examples (that is, test set).</p><p>The experiments in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig4">4a–h</a> followed the configurations described below, except for the parameters investigated in specific panels (such as batch size, size of the dataset and size of the architecture), which were adjusted as stated in the descriptions of the specific experiments. The neural network was composed of four layers and 32 hidden neurons in each hidden layer. Note that the state-of-the-art MLP models of FashionMNIST are all quite large<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 69" title="Tolstikhin, I. O. et al. Mlp-mixer: an all-mlp architecture for vision. In Advances in Neural Information Processing Systems (NeurIPS) (eds Ranzato, M. et al.) 24261–24272 (Curran Associates, 2021)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR69" id="ref-link-section-d41463491e4374">69</a></sup>. However, they are highly overparameterized and thus are not suitable to base our comparison on because the accuracy reaches more than 95% regardless of the learning rule due to the overparameterization. Thus, there was no space for demonstrating any meaningful comparison in these state-of-the-art overparameterized models. Overall, the size of the model on FashionMNIST demonstrated in this paper was a reasonable choice, with baseline models reaching reasonable performance (~0.12 test error for the standard machine learning setup) while maintaining enough room for demonstrating performance differences for different learning rules. The size of the input layer was 28 × 28 for FashionMNIST<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 60" title="Xiao, H., Rasul, K. &amp; Vollgraf, R. Fashion MNIST: a novel image dataset for benchmarking machine learning algorithms. Preprint at 
                  https://doi.org/10.48550/arXiv.1708.07747
                  
                 (2017)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR60" id="ref-link-section-d41463491e4378">60</a></sup> gray scaled, and the size of the output layer was ten as the number of classes for both datasets. The weights were initialized from a normal distribution with a mean of 0 and s.d. of <span>\(\sqrt{\frac{2}{{n}^{l}+{n}^{l+1}}}\)</span>, where <i>n</i><sup><i>l</i></sup> and <i>n</i><sup><i>l</i> + 1</sup> are the numbers of neurons in the layer before and after the weight, respectively. This initialization is known as Xavier normal initialization<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 68" title="Glorot, X. &amp; Bengio, Y. Understanding the difficulty of training deep feedforward neural networks. In Proc. 13th International Conference on Artificial Intelligence and Statistics (eds Teh, Y. W. &amp; Titterington, M.) 249–256 (PMLR, 2010)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR68" id="ref-link-section-d41463491e4460">68</a></sup>. The activation function <span>\({f}\,\left(\right)\)</span> is sigmoid. We defined one iteration as updating the weights for one step based on a minibatch. Each iteration contained (1) a numerical integration procedure of relaxation of energy-based networks, which captures its continuous process; and (2) one update of weights at the end of the above procedure. The number of examples in a minibatch, called the batch size, was by default 32. One epoch comprised presenting the entire training set split over multiple minibatches. At the end of each epoch, the model was tested on the test set, and the classification error was recorded as the ‘test error’ of the epoch. The neural network was trained for 64 epochs, thus yielding 64 test errors. The mean of the test error over epochs, that is, during training progress, is an indicator of how fast the model learns, and the minimum of the test errors over epochs is an indicator of how well the model can learn, ignoring the possibility of overfitting due to training for too long. Learning rates were optimized independently for each configuration and each model. Each experiment was repeated ten times (unless stated otherwise), and the error bars represent the 68% confidence interval computed using bootstrap.</p><p>We now describe settings specific to individual experiments. In Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig4">4b</a>, different batch sizes were tested (as shown on the <i>x</i> axis). In Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig4">4c</a>, the batch size was set to 1. In continual learning of Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig4">4d</a>, training alternated between two tasks. Task 1 involved classifying five randomly selected classes in a dataset, and task 2 involved classifying the remaining five classes. The whole network was shared by the two tasks; thus, different from the network used in other panels, the network only had five output neurons. This better corresponds to continual learning with multiple tasks in nature, because, for example, if humans learn to perform two different tasks, they typically use one brain and one pair of hands (that is, the whole network is shared), as they do not have two different pairs of hands (that is, humans share the output layers across tasks). Task 1 was trained for four iterations, task 2 was trained for four iterations, and the training continued until a total of 84 iterations was reached. After each iteration, error on the test set of each task was measured as ‘test error’. In Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig4">4e</a>, the mean of test error of both tasks during training of Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig4">4d</a> at different learning rates is reported. In Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig4">4d–g</a> investigating concept drifting<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 31" title="Gama, J., Žliobaitė, I., Bifet, A., Pechenizkiy, M. &amp; Bouchachia, A. A survey on concept drift adaptation. ACM Comput. Surv. 46, 1–37 (2014)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR31" id="ref-link-section-d41463491e4516">31</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 70" title="Žliobaitė, I. Learning under concept drift: an overview. Preprint at 
                  https://doi.org/10.48550/arXiv.1010.4784
                  
                 (2010)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR70" id="ref-link-section-d41463491e4519">70</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 71" title="Tsymbal, A. The Problem of Concept Drift: Definitions and Related Work. Technical report, Computer Science Department, Trinity College Dublin (2004)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR71" id="ref-link-section-d41463491e4522">71</a></sup>, changes to class labels were made every 64 epochs, and the models were trained for 3,000 epochs in total. Thus, every 64 epochs, five of ten output neurons were selected, and the mapping from these five output neurons to the semantic meaning was pseudorandomly shuffled. In Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig4">4h</a>, different numbers of data points per class (shown on the <i>x</i> axis) were included in the training set (subsets were randomly selected according to different seeds).</p><p>In Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig4">4i</a>, we trained a convolutional network with prospective configuration and backpropagation, with the structure detailed in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig4">4j</a>. For each learning rule, we independently searched seven learning rates ranging from <span>\(\left\{0.0005,0.00025,0.0001,0.000075,0.00005,0.000025,0.00001\right\}\)</span>. Both learning rules were trained for 80 epochs, with a batch size of 200. Because training deep convolutional networks is more difficult and slower than training shallow fully connected networks, a few improvements were applied to both learning rules. Specifically, a weight decay of 0.01 and an Adam optimizer<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 72" title="Kingma, D. P. &amp; Ba, J. Adam: a method for stochastic optimization. 
                  https://doi.org/10.48550/arXiv.1412.6980
                  
                 (2014)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR72" id="ref-link-section-d41463491e4590">72</a></sup> were applied for both learning rules. To reduce running time, the weights were updated more frequently in predictive coding networks; that is, the weights were updated at all steps of inference instead of at the last step of inference. Inference was run for a fixed number of 16 iterations; thus, weights were updated 16 times for each batch of data. Thus, for fair comparison, backpropagation also updated weights 16 times on each batch of data. Training in each configuration (each learning rule and each learning rate) was repeated three times with different seeds.</p><p>To extend a predictive coding network to a convolutional neural network (or to any network with a layered structure<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 58" title="Salvatori, T. et al. Learning on arbitrary graph topologies via predictive coding. In Advances in Neural Information Processing Systems (NeurIPS) (eds Koyejo, S. et al.) 38232–38244 (Curran Associates, 2022)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR58" id="ref-link-section-d41463491e4598">58</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 73" title="Salvatori, T., Song, Y., Lukasiewicz, T., Bogacz, R. &amp; Xu, Z. Reverse differentiation via predictive coding. In Proc. 36th AAAI Conference on Artificial Intelligence (Salvatori, T., Song, Y., Xu, Z., Lukasiewicz, T. &amp; Bogacz, R.) 8150–8158 (Curran Associates, 2022)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR73" id="ref-link-section-d41463491e4601">73</a></sup>), we can define the forward function of a layer (that is, how the input of layer <i>l</i> + 1 is computed from the neural activity of layer <i>l</i>) with weights <b><i>w</i></b><sup><i>l</i></sup> to be <span>\({{{{\mathcal{F}}}}}_{{{{{\boldsymbol{w}}}}}^{l}}\left({{{{\boldsymbol{x}}}}}^{l}\right)\)</span>. For example, for the MLPs described above, <span>\({{{{\mathcal{F}}}}}_{{{{{\boldsymbol{w}}}}}^{l}}\left({{{{\boldsymbol{x}}}}}^{l}\right)={{{{\boldsymbol{w}}}}}^{l}{f}\,\left({{{{\boldsymbol{x}}}}}^{l}\right)\)</span>. For a convolutional network, <span>\({{{{\mathcal{F}}}}}_{{{{{\boldsymbol{w}}}}}^{l}}\left({{{{\boldsymbol{x}}}}}^{l}\right)\)</span> is a more complex function of <b><i>w</i></b><sup><i>l</i></sup> and <b><i>x</i></b><sup><i>l</i></sup>, and also <b><i>w</i></b><sup><i>l</i></sup> and <b><i>x</i></b><sup><i>l</i></sup> are not simple matrix and vector anymore (to be defined later). Defining an ANN with <span>\({\mathcal{F}}()\)</span> would be (that is, Eq. (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Equ5">5</a>) becomes) <span>\({{{{\boldsymbol{x}}}}}^{l}={{{{\mathcal{F}}}}}_{{{{{\boldsymbol{w}}}}}^{l-1}}\left({{{{\boldsymbol{x}}}}}^{l-1}\right)\)</span>. Defining an energy function of a predictive coding network with <span>\({\mathcal{F}}()\)</span> would be (that is, Eq. (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Equ6">6</a>) becomes) <span>\({E}^{l}=\frac{1}{2}{\left[{{{{\boldsymbol{x}}}}}^{l}-{{{{\mathcal{F}}}}}_{{{{{\boldsymbol{w}}}}}^{l-1}}\left({{{{\boldsymbol{x}}}}}^{l-1}\right)\right]}^{2}\)</span>. Thus, neural and weight dynamics would be (that is, Eqs. (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Equ12">12</a>) and (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Equ13">13</a>) become) <span>\({{\Delta }}{{{{\boldsymbol{x}}}}}^{l}=-\gamma {{{{\boldsymbol{\varepsilon }}}}}^{l}+\frac{\partial {{{{\mathcal{F}}}}}_{{{{{\boldsymbol{w}}}}}^{l}}\left({{{{\boldsymbol{x}}}}}^{l}\right)}{\partial {{{{\boldsymbol{x}}}}}^{l}}{{{{\boldsymbol{\varepsilon }}}}}^{l+1}\)</span> and <span>\({{\Delta }}{{{{\boldsymbol{w}}}}}^{l}=\alpha {{{{\boldsymbol{\varepsilon }}}}}^{l+1}\frac{\partial {{{{\mathcal{F}}}}}_{{{{{\boldsymbol{w}}}}}^{l}}\left({{{{\boldsymbol{x}}}}}^{l}\right)}{\partial {{{{\boldsymbol{w}}}}}^{l}},\)</span> respectively. As <span>\({{{{\mathcal{F}}}}}_{{{{{\boldsymbol{w}}}}}^{l}}\left({{{{\boldsymbol{x}}}}}^{l}\right)\)</span> is defined, <span>\(\frac{\partial {{{{\mathcal{F}}}}}_{{{{{\boldsymbol{w}}}}}^{l}}\left({{{{\boldsymbol{x}}}}}^{l}\right)}{\partial {{{{\boldsymbol{x}}}}}^{l}}\)</span> and <span>\(\frac{\partial {{{{\mathcal{F}}}}}_{{{{{\boldsymbol{w}}}}}^{l}}\left({{{{\boldsymbol{x}}}}}^{l}\right)}{\partial {{{{\boldsymbol{w}}}}}^{l}}\)</span> are obtained via auto differentiation in PyTorch (<a href="https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html">https://pytorch.org/tutorials/beginner/basics/autogradqs_tutorial.html</a>). Thus, training a convolutional predictive coding network is as simple as replacing lines 11 and 16 in Algorithm <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#FPar1">1</a> with the above corresponding equations.</p><p>In the following, we define <span>\({{{{\mathcal{F}}}}}_{{{{{\boldsymbol{w}}}}}^{l}}\left({{{{\boldsymbol{x}}}}}^{l}\right)\)</span> for convolutional networks. First, <span>\({{{{\boldsymbol{x}}}}}^{l}\in {{\mathbb{R}}}^{{c}_{l}\times {h}_{l}\times {w}_{l}}\)</span>, where <i>c</i><sub><i>l</i></sub>, <i>h</i><sub><i>l</i></sub> and <i>w</i><sub><i>l</i></sub> are the number of features, height and width of the feature map, respectively. The numbers for each layer are presented in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig4">4j</a> in the format <i>c</i><sub><i>l</i></sub><i>@</i><i>h</i><sub><i>l</i></sub> × <i>w</i><sub><i>l</i></sub>. For example, for the first layer (input layer), the shape was 3<i>@</i>32 × 32 as it is 32 × 32 colored images, that is, with three feature maps representing red, green and blue. We denote kernel size, stride and padding of this layer as <i>k</i><sub><i>l</i></sub>, <i>s</i><sub><i>l</i></sub> and <i>p</i><sub><i>l</i></sub>, respectively. The numbers for each layer are presented in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig4">4j</a>. Thus, <span>\({{{{\boldsymbol{w}}}}}^{l}\in {{\mathbb{R}}}^{{c}_{l+1}\times {c}_{l}\times {k}_{l}\times {k}_{l}}\)</span>. Finally, <b><i>x</i></b><sup><i>l</i> + 1</sup> is obtained via</p><div id="Equ14"><p><span>$$\begin{array}{l}{{{{\boldsymbol{x}}}}}^{\;l+1}[c,x,y]={f}\,\left({{{{\boldsymbol{x}}}}}^{\;l}\left[:,x{s}_{l}-{p}_{l}:x{s}_{l}-{p}_{l}+{k}_{l},y{s}_{l}-{p}_{l}:y{s}_{l}-{p}_{l}+{k}_{l}\right]\right)\\\cdot {{{{\boldsymbol{w}}}}}^{l}\left[c,:,:,:\right],\end{array}$$</span></p><p>
                    (14)
                </p></div><p>where <span>\(\left[a,b,\ldots \right]\)</span> means indexing the tensor along each dimension, : means all indexes at that dimension, <i>a</i>: <i>b</i> means slice of that dimension from index <i>a</i> to <i>b</i> − 1, and <span>⋅</span> is dot product. In the above equation, if the slicing of <b><i>x</i></b><sup><i>l</i></sup> on the second and third dimensions, that is, <span>\({{{{\boldsymbol{x}}}}}^{l}\left[:,x{s}_{l}-{p}_{l}:x{s}_{l}-{p}_{l}+{k}_{l},y{s}_{l}-{p}_{l}:y{s}_{l}-{p}_{l}+{k}_{l}\right]\)</span>, is outside its defined range <span>\({{\mathbb{R}}}^{{c}_{l}\times {h}_{l}\times {w}_{l}}\)</span>, the entries outside range are considered to be 0, known as padding mode of zeros.</p><p>In Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig3">3f</a>, networks of 15 layers were trained and tested on the FashionMNIST<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 60" title="Xiao, H., Rasul, K. &amp; Vollgraf, R. Fashion MNIST: a novel image dataset for benchmarking machine learning algorithms. Preprint at 
                  https://doi.org/10.48550/arXiv.1708.07747
                  
                 (2017)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR60" id="ref-link-section-d41463491e6681">60</a></sup> dataset. Learning rates in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig3">3f</a> were optimized independently by a grid search over (5.0, 1.0, 0.5, 0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001, 0.00005, 0.00001, 0.000005) for each learning rule, as shown Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig3">3g</a>; that is, each learning rule in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig3">3f</a> used the learning rate that gave a minimal point in the corresponding curve in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig3">3g</a>. The experiment in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig3">3h</a> investigated other network depths (<span>\(\left\{1,2,4,6,8,10,12,14,15\right\}\)</span>) in the same setup. Similar to Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig3">3f</a>, the learning rate for each learning rule and each ‘number of layers’ was the optimal value (in terms of mean of test error as the <i>y</i> axis of the figure) independently searched from (5.0, 1.0, 0.5, 0.1, 0.05, 0.01, 0.005, 0.001, 0.0005, 0.0001, 0.00005, 0.00001, 0.000005). Hidden layers were always of size 64 in the above experiments. In the above experiment, only a part of the training set was used (60 data points per class) so that the test error was evaluated more frequently to reflect the difference on efficiency of the investigated learning rules. The activation function <span>\({f}\,\left(\right)\)</span> used is LeakyReLU instead of the standard sigmoid because sigmoid results in difficulty in training deep neural networks. Other unmentioned details followed the defaults, as described above.</p><p>In the reinforcement learning experiments (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig4">4k</a>), we evaluated performance on three classic reinforcement learning problems: Acrobot<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 74" title="Sutton, R. S. Generalization in reinforcement learning: successful examples using sparse coarse coding. In Advances in Neural Information Processing Systems (NeurIPS) (eds Touretzky, D. et al.) 1038–1044 (NIPS, 1995)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR74" id="ref-link-section-d41463491e6797">74</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 75" title="Geramifard, A., Dann, C., Klein, R. H., Dabney, W. &amp; How, J. P. RLPy: a value-function-based reinforcement learning framework for education and research. J. Mach. Learn. Res. 16, 1573–1578 (2015)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR75" id="ref-link-section-d41463491e6800">75</a></sup>, MountainCar<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 76" title="Moore, A. Efficient memory-based learning for robot control. Technical report, Carnegie Mellon Univ. (1990)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR76" id="ref-link-section-d41463491e6804">76</a></sup> and CartPole<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 77" title="Barto, A. G., Sutton, R. S. &amp; Anderson, C. W. Neuronlike adaptive elements that can solve difficult learning control problems. In IEEE Transactions on Systems, Man, and Cybernetics, 834–846 (1983)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR77" id="ref-link-section-d41463491e6808">77</a></sup>. We interacted with these environments via a unified interface by OpenAI Gym<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 78" title="Brockman, G. et al. OpenAI Gym. Preprint at 
                  https://doi.org/10.48550/arXiv.1606.01540
                  
                 (2016)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR78" id="ref-link-section-d41463491e6812">78</a></sup>. The observations <i>s</i><sub><i>t</i></sub> of these environments are vectors describing the status of the system, such as velocities and positions of different moving parts (for details, refer to the original articles or documentation from OpenAI Gym). Each entry of the observation <i>s</i><sub><i>t</i></sub> is normalized to mean 0 and s.d. 1 via Welford’s online algorithm<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 79" title="Welford, B. P. Note on a method for calculating corrected sums of squares and products. Technometrics 4, 419–420 (1962)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR79" id="ref-link-section-d41463491e6829">79</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 80" title="Knuth, D. E. Art of Computer Programming, Vol. 2 (Addison-Wesley Professional, 2014)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR80" id="ref-link-section-d41463491e6832">80</a></sup>. The action space of these environments is discrete. Thus, we can have a network taking in observation <i>s</i><sub><i>t</i></sub> and predicting the value (<i>Q</i>) of each action <i>a</i><sub><i>t</i></sub> with different output neurons. Such a network is known as an action-value network, in short, a <i>Q</i> network. In our experiment, the <i>Q</i> network contained two hidden layers, each of which contained 64 neurons, initialized the same way as the network used for supervised learning, described before. One can acquire the value of an action <i>a</i><sub><i>t</i></sub> at a given observation <i>s</i><sub><i>t</i></sub> by feeding <i>s</i><sub><i>t</i></sub> into the <i>Q</i> network and reading out the prediction on the output neuron corresponding to the action <i>a</i><sub><i>t</i></sub>; such a value is denoted <span>\(Q\left({s}_{t},{a}_{t}\right)\)</span>. The training of <i>Q</i> is a simple regression problem to target <span>\({\hat{R}}_{t}\)</span>, obtained via <i>Q</i> learning with experience replay (summarized in Algorithm <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#FPar2">2</a>). Considering <i>s</i><sub><i>t</i></sub> to be <b><i>s</i></b><sup>in</sup> and <span>\({\hat{R}}_{t}\)</span> to be <b><i>s</i></b><sup>target</sup>, the <i>Q</i> network can be trained with prospective configuration or backpropagation. Note that <span>\({\hat{R}}_{t}\)</span> is the target of the selected action <i>a</i><sub><i>t</i></sub> (that is, the target of one of the output neurons corresponds to the selected action <i>a</i><sub><i>t</i></sub>); thus, <span>\({\hat{R}}_{t}\)</span> is, in practice, considered to be <span>\({{{{\boldsymbol{s}}}}}^{{{{\rm{target}}}}}\left[{a}_{t}\right]\)</span>. For prospective configuration, it means that the rest of the output neurons except the one corresponding to <i>a</i><sub><i>t</i></sub> are freed; for backpropagation, it means that the error on these neurons is masked out.</p><p>A predictive coding network with slightly different settings from the defaults was used for prospective configuration. The integration step was fixed to be half of the default (<i>γ</i> = 0.05), and relaxation was performed for a fixed and smaller number of steps (<span>\({{{\mathcal{T}}}}=32\)</span>). This change was introduced because <i>Q</i> learning is more unstable (smaller integration step) and more expensive (smaller number of relaxation steps) than supervised learning tasks. To produce a smoother curve of ‘sum of rewards per episode’ in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig4">4k</a> from <i>SumRewardPerEpisode</i> in Algorithm <a data-track="click" data-track-label="link" data-track-action="subsection anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#FPar2">2</a>, the <i>SumRewardPerEpisode</i> curve was averaged along <i>TrainingEpisode</i> with a sliding window with a length of 200. Each experiment was repeated with three random seeds, and the shadows represent 68% confidence interval across them. Learning rates were searched independently for each environment and each model from the range <span>\(\left\{0.05,0.01,0.005,0.001,0.0005,0.0001\right\}\)</span>. The results reported in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig4">4k</a> are for the learning rates yielding the highest mean of ‘sum of rewards per episode’ over training episodes.</p>
                  <h3 id="FPar2">Algorithm 2</h3>
                  <p><i>Q</i> learning with experience replay <img src="http://media.springernature.com/lw684/springer-static/image/art%3A10.1038%2Fs41593-023-01514-1/MediaObjects/41593_2023_1514_Figb_HTML.png" alt=""/></p>
                <h3 id="Sec14">Simulation of motor learning</h3><p>As shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig5">5</a>, we trained a network that included two input neurons, two hidden neurons and two output neurons. The two input neurons were one-to-one connected to the two hidden neurons, and the two hidden neurons were fully connected to the two output neurons. The two input neurons were considered to encode presenting the blue and red background, respectively. The two output neurons were considered to encode the prediction of the perturbations toward positive and negative directions, respectively. Presenting and not presenting a background color were encoded 1 and 0, respectively; presenting and not presenting perturbations of a particular direction were encoded 1 and 0, respectively. The weights were initialized from a normal distribution with mean 0 and an s.d. fitted to the behavioral data (see below), simulating that the participants had not built any associations before the experiments. Learning rates were independent for the two layers, as we expected the connections from perception to belief and from belief to predictions to have different degrees of plasticity. The two learning rates were also fitted to the data (see below).</p><p>The number of participants and training and testing trials follow exactly as described for the human experiment<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 38" title="Hampton, A. N., Bossaerts, P. &amp; O’Doherty, J. P. The role of the ventromedial prefrontal cortex in abstract state-based inference during decision making in humans. J. Neurosci. 26, 8360–8367 (2006)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR38" id="ref-link-section-d41463491e7322">38</a></sup>. In particular, for each of the 24 simulated participants, the weights were initialized with a different seed of the random number generator. They each experienced two stages: training and testing. Note that the pretraining stage performed in the human experiment was not simulated here as its goal was to make human participants familiar with the setup and devices.</p><p>In the training stage, the model experienced 24 blocks of trials. In each block, the model was presented with the following sequence of trials, matching the original experiment<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 38" title="Hampton, A. N., Bossaerts, P. &amp; O’Doherty, J. P. The role of the ventromedial prefrontal cortex in abstract state-based inference during decision making in humans. J. Neurosci. 26, 8360–8367 (2006)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR38" id="ref-link-section-d41463491e7329">38</a></sup>:</p><ul>
                  <li>
                    <p>The model was trained with two trials without perturbation, B<sub>0</sub> and R<sub>0</sub>, with the order counterbalanced across consecutive blocks. Note that, in the human experiment, there were two trial types without perturbations (channel and washout trials), but they were simulated in the same way here as B<sub>0</sub> or R<sub>0</sub> trials because they both did not include any perturbations.</p>
                  </li>
                  <li>
                    <p>The model was trained with 32 trials with perturbations, where there were equal numbers of B+ and R– within each of the 8 trials in a pseudorandom order.</p>
                  </li>
                  <li>
                    <p>The model experienced two trials, B<sub>0</sub> and R<sub>0</sub>, with the order counterbalanced across consecutive blocks.</p>
                  </li>
                  <li>
                    <p>The model experienced <i>n</i> ← {14, 16, 18} washout trials (equal numbers of B<sub>0</sub> and R<sub>0</sub> trials in a pseudorandom order), where <i>n</i> ← {<i>a</i>, <i>b</i>, <i>c</i>} denotes sampling without replacement from a set of values <i>a</i>, <i>b</i> and <i>c</i> and replenishing the set whenever it becomes empty.</p>
                  </li>
                  <li>
                    <p>The model experienced one triplet, where the exposure trial was either B+ or R–, counterbalanced across consecutive blocks. Here, a triplet consisted of three sequential trials: B<sub>0</sub>, the specified exposure trial and B<sub>0</sub> again.</p>
                  </li>
                  <li>
                    <p>The model experienced additional <i>n</i> ← {6, 8, 10} washout trials (equal numbers of B<sub>0</sub> and R<sub>0</sub> trials in a pseudorandom order).</p>
                  </li>
                  <li>
                    <p>The model experienced one triplet again, where the exposure trial was either B+ or R–, whichever was not used on the previous triplet.</p>
                  </li>
                </ul><p>In the testing stage, the model then experienced eight repetitions of four blocks of trials. In each block, one of the combinations of B+, R+, B– and R– was tested. The order of the four blocks was shuffled in each of the eight repetitions. In each block, the model first experienced <i>n</i> ← {2, 4, 6} washout trials (equal numbers of B<sub>0</sub> and R<sub>0</sub> trials in a pseudorandom order). The model then experienced a triplet of trials, where the exposure trial was the combination (B+, R+, B– or R–) tested in a given block to assess single-trial learning of this combination. The change in adaption in the model was computed as the absolute value of the difference in the predictions of perturbations on the two B<sub>0</sub> trials in the above triplet, where the prediction of perturbation was computed as the difference between the activities of the two output neurons. The predictions were averaged over participants and the above repetitions.</p><p>The parameters of each learning rule were chosen such that the model best reproduced the change in adaptation shown in Fig <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig5">5f</a>. In particular, we minimized the sum over set <i>C</i> of the four exposure trial types of the squared difference between average change in adaptation in experiment (<i>d</i><sub><i>c</i></sub>) and model (<i>x</i><sub><i>c</i></sub>):</p><div id="Equ15"><p><span>$$\mathop{\sum}\limits_{c\in C}{\left(a{x}_{c}-{d}_{c}\right)}^{2}.$$</span></p><p>
                    (15)
                </p></div><p>The model predictions were additionally scaled by a coefficient <i>a</i> fitted to the data because the behavioral data and model outputs had different scales. An exhaustive search was performed over model parameters. The s.d. of initial weights could take values from <span>\(\left\{0.01,0.05,0.1\right\}\)</span>, and two learning rates for two layers could take values from <span>\(\left\{0.00005,0.0001,0.0005,0.01,0.05\right\}\)</span>. For each learning rule and each combination of the above model parameters, the coefficient <i>a</i> was then resolved analytically (restricted to be positive) to minimize the sum of the squared errors of Eq. (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Equ15">15</a>).</p><h3 id="Sec15">Simulation of human reinforcement learning</h3><p>As shown in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig6">6b</a>, we trained a network that included one input neuron, one hidden neuron and two output neurons. The input neuron was considered to encode being in the task, so it was set to 1 throughout the simulation. The two output neurons encoded the prediction of the value of the two choices. Reward and punishment were encoded as 1 and −1, respectively, because the participants were either winning or losing money. The model selected actions stochastically based on the predicted value of the two choices (encoded in the activity of two output neurons) according to the softmax rule (with a temperature of 1). The weights were initialized from a normal distribution of mean 0 and an s.d. fitted to experimental data (see below), simulating that the human participants had not built any associations before the experiments. The number of simulated participants (number of repetitions with different seeds) was set to 16, as in the human experiment<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 38" title="Hampton, A. N., Bossaerts, P. &amp; O’Doherty, J. P. The role of the ventromedial prefrontal cortex in abstract state-based inference during decision making in humans. J. Neurosci. 26, 8360–8367 (2006)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR38" id="ref-link-section-d41463491e7642">38</a></sup>. The number of trials was not mentioned in the original paper, so we simulated for 128 trials for both learning rules.</p><p>To compare the ability of the two learning rules to account for the pattern of signal from the mPFC, for each of the rules, we optimized the parameters describing how the model is set up and learns (the s.d. of initial weights and the learning rate). Namely, we searched for the values of these parameters for which the model produces the most similar pattern of its output activity to that in the experiment. In particular, we minimized the sum over set <i>C</i> of four trial types in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig6">6c</a> of the squared difference between model predictions <i>x</i><sub><i>c</i></sub> and data <i>d</i><sub><i>c</i></sub> on mean mPFC signal:</p><div id="Equ16"><p><span>$$\mathop{\sum}\limits_{c\in C}{\left(a{x}_{c}+b-{d}_{c}\right)}^{2}.$$</span></p><p>
                    (16)
                </p></div><p>The model predictions were additionally scaled by a coefficient <i>a</i> and offset by a bias <i>b</i> because the fMRI signal had different units and baseline than the model. To compute the model prediction for a given trial type, the activity of the output neuron corresponding to the chosen option was averaged across all trials of this type in the entire simulation. The scaled average activity from the model is plotted in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig6">6c</a>, where the error bars show the 68% confidence interval of the scaled activity. To fit the model to experimental data, the values of model parameters and the coefficient were found as described in the previous section. In particular, we used exhaustive grid search on the parameters. The models were simulated for all possible combinations of s.d. of initial weights and the learning rate from the following set: <span>\(\left\{0.01,0.05,0.1\right\}\)</span>. For each learning rule and each combination of the above model parameters, the coefficient <i>a</i> (restricted to be positive) and the bias <i>b</i> were then resolved analytically to minimize the sum of the squared error of Eq. (<a data-track="click" data-track-label="link" data-track-action="equation anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Equ16">16</a>).</p><h3 id="Sec16">Statistics and reproducibility</h3><p>The work in this paper involved computer simulations, but due to random initialization of weight parameters, the simulations were repeated multiple times. No statistical method was used to predetermine the number of repetitions, but for simulations corresponding to behavioral or neurophysiological experiments, the number of repetitions was matched to the number of participants in the given experiment. No data were excluded from the analyses. Because the order of execution has no effect on the results of the numeric experiments, they were not randomized. The investigators were not blinded to outcome assessment.</p><p>To visualize the variability of simulation results, we either presented individual data points or error bars showing confidence intervals or box plots. Confidence intervals were computed using bootstrap throughout the paper, and detailed descriptions of the implementation can be found at <a href="https://seaborn.pydata.org/tutorial/error_bars.html#confidence-interval-error-bars">https://seaborn.pydata.org/tutorial/error_bars.html#confidence-interval-error-bars</a>. The details of the methods used to produce the box plots are available at <a href="https://seaborn.pydata.org/generated/seaborn.boxplot.html">https://seaborn.pydata.org/generated/seaborn.boxplot.html</a>.</p><h3 id="Sec17">Reporting summary</h3><p>Further information on research design is available in the <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#MOESM2">Nature Portfolio Reporting Summary</a> linked to this article.</p></div></div></section>
                </div><div>
                <section data-title="Data availability"><div id="data-availability-section"><h2 id="data-availability">Data availability</h2><p>Learning tasks analyzed in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig4">4a–j</a> were built using the publicly available FashionMNIST<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 60" title="Xiao, H., Rasul, K. &amp; Vollgraf, R. Fashion MNIST: a novel image dataset for benchmarking machine learning algorithms. Preprint at 
                  https://doi.org/10.48550/arXiv.1708.07747
                  
                 (2017)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR60" id="ref-link-section-d41463491e7930">60</a></sup> and CIFAR-10 (ref. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 36" title="Krizhevsky, A. &amp; Hinton, G. Learning Multiple Layers of Features from Tiny Images. Master’s thesis, Univ. Toronto (2009)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR36" id="ref-link-section-d41463491e7934">36</a></sup>) datasets. These datasets are incorporated in most machine learning libraries, and their original releases are available at <a href="https://github.com/zalandoresearch/fashion-mnist">https://github.com/zalandoresearch/fashion-mnist</a> and <a href="https://www.cs.toronto.edu/~kriz/cifar.html">https://www.cs.toronto.edu/~kriz/cifar.html</a>, respectively. Reinforcement learning tasks analyzed in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Fig4">4i</a> were built using the publicly available simulators by OpenAI Gym<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 78" title="Brockman, G. et al. OpenAI Gym. Preprint at 
                  https://doi.org/10.48550/arXiv.1606.01540
                  
                 (2016)." href="http://tinylogger.com/articles/s41593-023-01514-1#ref-CR78" id="ref-link-section-d41463491e7956">78</a></sup>. <a data-track="click" data-track-label="link" data-track-action="section anchor" href="http://tinylogger.com/articles/s41593-023-01514-1#Sec20">Source data</a> are provided with this paper.</p></div></section><section data-title="Code availability"><div id="code-availability-section"><h2 id="code-availability">Code availability</h2><div id="code-availability-content">
              
              <p>Complete code and full documentation reproducing all simulation results written in Python are publicly available at <a href="https://github.com/YuhangSong/Prospective-Configuration">https://github.com/YuhangSong/Prospective-Configuration</a> released under GNU General Public License v3.0 without any additional restrictions (for license details, see <a href="https://opensource.org/licenses/GPL-3.0">https://opensource.org/licenses/GPL-3.0</a> by the open source initiative).</p>
            </div></div></section><div id="MagazineFulltextArticleBodySuffix"><section aria-labelledby="Bib1" data-title="References"><div id="Bib1-section"><h2 id="Bib1">References</h2><div id="Bib1-content"><div data-container-section="references"><ol data-track-component="outbound reference" data-track-context="references section"><li data-counter="1."><p id="ref-CR1">Lillicrap, T. P., Santoro, A., Marris, L., Akerman, C. J. &amp; Hinton, G. Backpropagation and the brain. <i>Nat. Rev. Neurosci.</i> <b>21</b>, 335–346 (2020).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s41583-020-0277-3" data-track-item_id="10.1038/s41583-020-0277-3" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41583-020-0277-3" aria-label="Article reference 1" data-doi="10.1038/s41583-020-0277-3">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="http://tinylogger.com/articles/cas-redirect/1:CAS:528:DC%2BB3cXnsVCksrk%3D" aria-label="CAS reference 1">CAS</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32303713" aria-label="PubMed reference 1">PubMed</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 1" href="http://scholar.google.com/scholar_lookup?&amp;title=Backpropagation%20and%20the%20brain&amp;journal=Nat.%20Rev.%20Neurosci.&amp;doi=10.1038%2Fs41583-020-0277-3&amp;volume=21&amp;pages=335-346&amp;publication_year=2020&amp;author=Lillicrap%2CTP&amp;author=Santoro%2CA&amp;author=Marris%2CL&amp;author=Akerman%2CCJ&amp;author=Hinton%2CG">
                    Google Scholar</a> 
                </p></li><li data-counter="2."><p id="ref-CR2">Rumelhart, D. E., Hinton, G. E. &amp; Williams, R. J. <i>Learning Internal Representations by Error Propagation</i> (Univ. California, San Diego, Institute for Cognitive Science, 1985).</p></li><li data-counter="3."><p id="ref-CR3">Krizhevsky, A., Sutskever, I. &amp; Hinton, G. E. ImageNet classification with deep convolutional neural networks. In <i>Advances in Neural Information Processing Systems (NeurIPS)</i> (eds Bartlett, P. et al.) 1097–1105 (Curran Associates, 2012).</p></li><li data-counter="4."><p id="ref-CR4">Mnih, V. et al. Human-level control through deep reinforcement learning. <i>Nature</i> <b>518</b>, 529–533 (2015).</p></li><li data-counter="5."><p id="ref-CR5">Silver, D. et al. Mastering the game of go with deep neural networks and tree search. <i>Nature</i> <b>529</b>, 484–489 (2016).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/nature16961" data-track-item_id="10.1038/nature16961" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fnature16961" aria-label="Article reference 5" data-doi="10.1038/nature16961">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="http://tinylogger.com/articles/cas-redirect/1:CAS:528:DC%2BC28Xhs12is7w%3D" aria-label="CAS reference 5">CAS</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=26819042" aria-label="PubMed reference 5">PubMed</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 5" href="http://scholar.google.com/scholar_lookup?&amp;title=Mastering%20the%20game%20of%20go%20with%20deep%20neural%20networks%20and%20tree%20search&amp;journal=Nature&amp;doi=10.1038%2Fnature16961&amp;volume=529&amp;pages=484-489&amp;publication_year=2016&amp;author=Silver%2CD">
                    Google Scholar</a> 
                </p></li><li data-counter="6."><p id="ref-CR6">Richards, B. A. et al. A deep learning framework for neuroscience. <i>Nat. Neurosci.</i> <b>22</b>, 1761–1770 (2019).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s41593-019-0520-2" data-track-item_id="10.1038/s41593-019-0520-2" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41593-019-0520-2" aria-label="Article reference 6" data-doi="10.1038/s41593-019-0520-2">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="http://tinylogger.com/articles/cas-redirect/1:CAS:528:DC%2BC1MXitVCksbrO" aria-label="CAS reference 6">CAS</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31659335" aria-label="PubMed reference 6">PubMed</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7115933" aria-label="PubMed Central reference 6">PubMed Central</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 6" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20deep%20learning%20framework%20for%20neuroscience&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2Fs41593-019-0520-2&amp;volume=22&amp;pages=1761-1770&amp;publication_year=2019&amp;author=Richards%2CBA">
                    Google Scholar</a> 
                </p></li><li data-counter="7."><p id="ref-CR7">Singer, Y. et al. Sensory cortex is optimized for prediction of future input. <i>eLife</i> <b>7</b>, e31557 (2018).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.7554/eLife.31557" data-track-item_id="10.7554/eLife.31557" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.7554%2FeLife.31557" aria-label="Article reference 7" data-doi="10.7554/eLife.31557">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29911971" aria-label="PubMed reference 7">PubMed</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6108826" aria-label="PubMed Central reference 7">PubMed Central</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 7" href="http://scholar.google.com/scholar_lookup?&amp;title=Sensory%20cortex%20is%20optimized%20for%20prediction%20of%20future%20input&amp;journal=eLife&amp;doi=10.7554%2FeLife.31557&amp;volume=7&amp;publication_year=2018&amp;author=Singer%2CY">
                    Google Scholar</a> 
                </p></li><li data-counter="8."><p id="ref-CR8">Yamins, D. L. K. et al. Performance-optimized hierarchical models predict neural responses in higher visual cortex. <i>Proc. Natl Acad. Sci. USA</i> <b>111</b>, 8619–8624 (2014).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1073/pnas.1403112111" data-track-item_id="10.1073/pnas.1403112111" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.1403112111" aria-label="Article reference 8" data-doi="10.1073/pnas.1403112111">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="http://tinylogger.com/articles/cas-redirect/1:CAS:528:DC%2BC2cXnslWnsb4%3D" aria-label="CAS reference 8">CAS</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=24812127" aria-label="PubMed reference 8">PubMed</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4060707" aria-label="PubMed Central reference 8">PubMed Central</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 8" href="http://scholar.google.com/scholar_lookup?&amp;title=Performance-optimized%20hierarchical%20models%20predict%20neural%20responses%20in%20higher%20visual%20cortex&amp;journal=Proc.%20Natl%20Acad.%20Sci.%20USA&amp;doi=10.1073%2Fpnas.1403112111&amp;volume=111&amp;pages=8619-8624&amp;publication_year=2014&amp;author=Yamins%2CDLK">
                    Google Scholar</a> 
                </p></li><li data-counter="9."><p id="ref-CR9">Sacramento, J., Costa, R. P., Bengio, Y. and Senn, W. Dendritic cortical microcircuits approximate the backpropagation algorithm. In <i>Advances in Neural Information Processing Systems (NeurIPS)</i> (eds Bengio, S. et al.) 8721–8732 (Curran Associates, 2018).</p></li><li data-counter="10."><p id="ref-CR10">Guerguiev, J., Lillicrap, T. P. &amp; Richards, B. A. Towards deep learning with segregated dendrites. <i>eLife</i> <b>6</b>, e22901 (2017).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.7554/eLife.22901" data-track-item_id="10.7554/eLife.22901" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.7554%2FeLife.22901" aria-label="Article reference 10" data-doi="10.7554/eLife.22901">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29205151" aria-label="PubMed reference 10">PubMed</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5716677" aria-label="PubMed Central reference 10">PubMed Central</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 10" href="http://scholar.google.com/scholar_lookup?&amp;title=Towards%20deep%20learning%20with%20segregated%20dendrites&amp;journal=eLife&amp;doi=10.7554%2FeLife.22901&amp;volume=6&amp;publication_year=2017&amp;author=Guerguiev%2CJ&amp;author=Lillicrap%2CTP&amp;author=Richards%2CBA">
                    Google Scholar</a> 
                </p></li><li data-counter="11."><p id="ref-CR11">Scellier, B. &amp; Bengio, Y. Equilibrium propagation: bridging the gap between energy-based models and backpropagation. <i>Front. Comput. Neurosci.</i> <b>11</b>, 24 (2017).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.3389/fncom.2017.00024" data-track-item_id="10.3389/fncom.2017.00024" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.3389%2Ffncom.2017.00024" aria-label="Article reference 11" data-doi="10.3389/fncom.2017.00024">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28522969" aria-label="PubMed reference 11">PubMed</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5415673" aria-label="PubMed Central reference 11">PubMed Central</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 11" href="http://scholar.google.com/scholar_lookup?&amp;title=Equilibrium%20propagation%3A%20bridging%20the%20gap%20between%20energy-based%20models%20and%20backpropagation&amp;journal=Front.%20Comput.%20Neurosci.&amp;doi=10.3389%2Ffncom.2017.00024&amp;volume=11&amp;publication_year=2017&amp;author=Scellier%2CB&amp;author=Bengio%2CY">
                    Google Scholar</a> 
                </p></li><li data-counter="12."><p id="ref-CR12">Whittington, J. C. R. &amp; Bogacz, R. An approximation of the error backpropagation algorithm in a predictive coding network with local hebbian synaptic plasticity. <i>Neural Comput.</i> <b>29</b>, 1229–1262 (2017).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1162/NECO_a_00949" data-track-item_id="10.1162/NECO_a_00949" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1162%2FNECO_a_00949" aria-label="Article reference 12" data-doi="10.1162/NECO_a_00949">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28333583" aria-label="PubMed reference 12">PubMed</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5467749" aria-label="PubMed Central reference 12">PubMed Central</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 12" href="http://scholar.google.com/scholar_lookup?&amp;title=An%20approximation%20of%20the%20error%20backpropagation%20algorithm%20in%20a%20predictive%20coding%20network%20with%20local%20hebbian%20synaptic%20plasticity&amp;journal=Neural%20Comput.&amp;doi=10.1162%2FNECO_a_00949&amp;volume=29&amp;pages=1229-1262&amp;publication_year=2017&amp;author=Whittington%2CJCR&amp;author=Bogacz%2CR">
                    Google Scholar</a> 
                </p></li><li data-counter="13."><p id="ref-CR13">Whittington, J. C. R. &amp; Bogacz, R. Theories of error back-propagation in the brain. <i>Trends Cogn. Sci.</i> <b>23</b>, 235–250 (2019).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/j.tics.2018.12.005" data-track-item_id="10.1016/j.tics.2018.12.005" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.tics.2018.12.005" aria-label="Article reference 13" data-doi="10.1016/j.tics.2018.12.005">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=30704969" aria-label="PubMed reference 13">PubMed</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6382460" aria-label="PubMed Central reference 13">PubMed Central</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 13" href="http://scholar.google.com/scholar_lookup?&amp;title=Theories%20of%20error%20back-propagation%20in%20the%20brain&amp;journal=Trends%20Cogn.%20Sci.&amp;doi=10.1016%2Fj.tics.2018.12.005&amp;volume=23&amp;pages=235-250&amp;publication_year=2019&amp;author=Whittington%2CJCR&amp;author=Bogacz%2CR">
                    Google Scholar</a> 
                </p></li><li data-counter="14."><p id="ref-CR14">Song, Y., Lukasiewicz, T., Xu, Z. &amp; Bogacz, R. Can the brain do backpropagation? Exact implementation of backpropagation in predictive coding networks. In <i>Advances in Neural Information Processing Systems (NeurIPS)</i> (eds Larochell, H. et al.) 22566–22579 (Curran Associates, 2020).</p></li><li data-counter="15."><p id="ref-CR15">Tsividis, P. A., Pouncy, T., Xu, J. L., Tenenbaum, J. B. &amp; Gershman, S. J. Human learning in Atari. In <i>2017 AAAI Spring Symposium Series</i> 643–646 (Association for the Advancement of Artificial Intelligence, 2017).</p></li><li data-counter="16."><p id="ref-CR16">McCloskey, M. &amp; Cohen, N. J. Catastrophic interference in connectionist networks: the sequential learning problem. <i>Psychol. Learn. Motiv.</i> <b>24</b>, 109–165 (1989).</p></li><li data-counter="17."><p id="ref-CR17">Hopfield, J. J. Neural networks and physical systems with emergent collective computational abilities. <i>Proc. Natl Acad. Sci. USA</i> <b>79</b>, 2554–2558 (1982).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1073/pnas.79.8.2554" data-track-item_id="10.1073/pnas.79.8.2554" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1073%2Fpnas.79.8.2554" aria-label="Article reference 17" data-doi="10.1073/pnas.79.8.2554">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="http://tinylogger.com/articles/cas-redirect/1:STN:280:DyaL383it1WktQ%3D%3D" aria-label="CAS reference 17">CAS</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=6953413" aria-label="PubMed reference 17">PubMed</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC346238" aria-label="PubMed Central reference 17">PubMed Central</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 17" href="http://scholar.google.com/scholar_lookup?&amp;title=Neural%20networks%20and%20physical%20systems%20with%20emergent%20collective%20computational%20abilities&amp;journal=Proc.%20Natl%20Acad.%20Sci.%20USA&amp;doi=10.1073%2Fpnas.79.8.2554&amp;volume=79&amp;pages=2554-2558&amp;publication_year=1982&amp;author=Hopfield%2CJJ">
                    Google Scholar</a> 
                </p></li><li data-counter="18."><p id="ref-CR18">Rao, R. P. &amp; Ballard, D. H. Predictive coding in the visual cortex: a functional interpretation of some extra-classical receptive-field effects. <i>Nat. Neurosci.</i> <b>2</b>, 79–87 (1999).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/4580" data-track-item_id="10.1038/4580" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2F4580" aria-label="Article reference 18" data-doi="10.1038/4580">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="http://tinylogger.com/articles/cas-redirect/1:CAS:528:DyaK1MXhsl2ns7k%3D" aria-label="CAS reference 18">CAS</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=10195184" aria-label="PubMed reference 18">PubMed</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 18" href="http://scholar.google.com/scholar_lookup?&amp;title=Predictive%20coding%20in%20the%20visual%20cortex%3A%20a%20functional%20interpretation%20of%20some%20extra-classical%20receptive-field%20effects&amp;journal=Nat.%20Neurosci.&amp;doi=10.1038%2F4580&amp;volume=2&amp;pages=79-87&amp;publication_year=1999&amp;author=Rao%2CRP&amp;author=Ballard%2CDH">
                    Google Scholar</a> 
                </p></li><li data-counter="19."><p id="ref-CR19">Friston, K. The free-energy principle: a unified brain theory? <i>Nat. Rev. Neurosci.</i> <b>11</b>, 127–138 (2010).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/nrn2787" data-track-item_id="10.1038/nrn2787" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fnrn2787" aria-label="Article reference 19" data-doi="10.1038/nrn2787">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="http://tinylogger.com/articles/cas-redirect/1:CAS:528:DC%2BC3cXksFGktw%3D%3D" aria-label="CAS reference 19">CAS</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=20068583" aria-label="PubMed reference 19">PubMed</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 19" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20free-energy%20principle%3A%20a%20unified%20brain%20theory%3F&amp;journal=Nat.%20Rev.%20Neurosci.&amp;doi=10.1038%2Fnrn2787&amp;volume=11&amp;pages=127-138&amp;publication_year=2010&amp;author=Friston%2CK">
                    Google Scholar</a> 
                </p></li><li data-counter="20."><p id="ref-CR20">Millidge, B., Tschantz, A. &amp; Buckley, C. L. Predictive coding approximates backprop along arbitrary computation graphs. <i>Neural Comput.</i> <b>34</b>, 1329–1368 (2022).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1162/neco_a_01497" data-track-item_id="10.1162/neco_a_01497" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1162%2Fneco_a_01497" aria-label="Article reference 20" data-doi="10.1162/neco_a_01497">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=35534010" aria-label="PubMed reference 20">PubMed</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 20" href="http://scholar.google.com/scholar_lookup?&amp;title=Predictive%20coding%20approximates%20backprop%20along%20arbitrary%20computation%20graphs&amp;journal=Neural%20Comput.&amp;doi=10.1162%2Fneco_a_01497&amp;volume=34&amp;pages=1329-1368&amp;publication_year=2022&amp;author=Millidge%2CB&amp;author=Tschantz%2CA&amp;author=Buckley%2CCL">
                    Google Scholar</a> 
                </p></li><li data-counter="21."><p id="ref-CR21">Bengio, Y. &amp; Fischer, A. Early inference in energy-based models approximates back-propagation. Preprint at <a href="https://doi.org/10.48550/arXiv.1510.02777" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.48550/arXiv.1510.02777">https://doi.org/10.48550/arXiv.1510.02777</a> (2015).</p></li><li data-counter="22."><p id="ref-CR22">O’Reilly, R. C. &amp; Munakata, Y. <i>Computational Explorations in Cognitive Neuroscience: Understanding the Mind by Simulating the Brain</i> (MIT Press Cambridge, 2000).</p></li><li data-counter="23."><p id="ref-CR23">Quilodran, R., Rothe, M. &amp; Procyk, E. Behavioral shifts and action valuation in the anterior cingulate cortex. <i>Neuron</i> <b>57</b>, 314–325 (2008).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2007.11.031" data-track-item_id="10.1016/j.neuron.2007.11.031" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2007.11.031" aria-label="Article reference 23" data-doi="10.1016/j.neuron.2007.11.031">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="http://tinylogger.com/articles/cas-redirect/1:CAS:528:DC%2BD1cXhvVSrt7c%3D" aria-label="CAS reference 23">CAS</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=18215627" aria-label="PubMed reference 23">PubMed</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 23" href="http://scholar.google.com/scholar_lookup?&amp;title=Behavioral%20shifts%20and%20action%20valuation%20in%20the%20anterior%20cingulate%20cortex&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2007.11.031&amp;volume=57&amp;pages=314-325&amp;publication_year=2008&amp;author=Quilodran%2CR&amp;author=Rothe%2CM&amp;author=Procyk%2CE">
                    Google Scholar</a> 
                </p></li><li data-counter="24."><p id="ref-CR24">Wallis, J. D. &amp; Kennerley, S. W. Heterogeneous reward signals in prefrontal cortex. <i>Curr. Opin. Neurobiol.</i> <b>20</b>, 191–198 (2010).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/j.conb.2010.02.009" data-track-item_id="10.1016/j.conb.2010.02.009" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.conb.2010.02.009" aria-label="Article reference 24" data-doi="10.1016/j.conb.2010.02.009">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="http://tinylogger.com/articles/cas-redirect/1:CAS:528:DC%2BC3cXlsFCisrw%3D" aria-label="CAS reference 24">CAS</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=20303739" aria-label="PubMed reference 24">PubMed</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2862852" aria-label="PubMed Central reference 24">PubMed Central</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 24" href="http://scholar.google.com/scholar_lookup?&amp;title=Heterogeneous%20reward%20signals%20in%20prefrontal%20cortex&amp;journal=Curr.%20Opin.%20Neurobiol.&amp;doi=10.1016%2Fj.conb.2010.02.009&amp;volume=20&amp;pages=191-198&amp;publication_year=2010&amp;author=Wallis%2CJD&amp;author=Kennerley%2CSW">
                    Google Scholar</a> 
                </p></li><li data-counter="25."><p id="ref-CR25">Friston, K. A theory of cortical responses. <i>Philos. Trans. R. Soc. Lond. B Biol. Sci.</i> <b>360</b>, 815–836 (2005).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1098/rstb.2005.1622" data-track-item_id="10.1098/rstb.2005.1622" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1098%2Frstb.2005.1622" aria-label="Article reference 25" data-doi="10.1098/rstb.2005.1622">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=15937014" aria-label="PubMed reference 25">PubMed</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC1569488" aria-label="PubMed Central reference 25">PubMed Central</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 25" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20theory%20of%20cortical%20responses&amp;journal=Philos.%20Trans.%20R.%20Soc.%20Lond.%20B%20Biol.%20Sci.&amp;doi=10.1098%2Frstb.2005.1622&amp;volume=360&amp;pages=815-836&amp;publication_year=2005&amp;author=Friston%2CK">
                    Google Scholar</a> 
                </p></li><li data-counter="26."><p id="ref-CR26">Bengio, Y. How auto-encoders could provide credit assignment in deep networks via target propagation. Preprint at <a href="https://doi.org/10.48550/arXiv.1407.7906" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.48550/arXiv.1407.7906">https://doi.org/10.48550/arXiv.1407.7906</a> (2014).</p></li><li data-counter="27."><p id="ref-CR27">Meulemans, A., Carzaniga, F., Suykens, J., Sacramento, J. &amp; Grewe, B. F. A theoretical framework for target propagation. In <i>Advances in Neural Information Processing Systems (NeurIPS)</i> (eds Larochelle, H. et al.) 20024–20036 (Curran Associates, 2020).</p></li><li data-counter="28."><p id="ref-CR28">Felleman, D. J. &amp; Van Essen, D. C. Distributed hierarchical processing in the primate cerebral cortex. <i>Cereb. Cortex</i> <b>1</b>, 1–47 (1991).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1093/cercor/1.1.1" data-track-item_id="10.1093/cercor/1.1.1" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1093%2Fcercor%2F1.1.1" aria-label="Article reference 28" data-doi="10.1093/cercor/1.1.1">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="http://tinylogger.com/articles/cas-redirect/1:STN:280:DyaK38zltlGmsg%3D%3D" aria-label="CAS reference 28">CAS</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=1822724" aria-label="PubMed reference 28">PubMed</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 28" href="http://scholar.google.com/scholar_lookup?&amp;title=Distributed%20hierarchical%20processing%20in%20the%20primate%20cerebral%20cortex&amp;journal=Cereb.%20Cortex&amp;doi=10.1093%2Fcercor%2F1.1.1&amp;volume=1&amp;pages=1-47&amp;publication_year=1991&amp;author=Felleman%2CDJ&amp;author=Essen%2CDC">
                    Google Scholar</a> 
                </p></li><li data-counter="29."><p id="ref-CR29">Fontenla-Romero, Ó., Guijarro-Berdiñas, B., Martinez-Rego, D., Pérez-Sánchez, B. &amp; Peteiro-Barral, D. Online machine learning. In <i>Efficiency and Scalability Methods for Computational Intellect</i> (eds Igelnik, B. &amp; Zurada, J. M.) 27–54 (IGI Global, 2013).</p></li><li data-counter="30."><p id="ref-CR30">Hassabis, D., Kumaran, D., Summerfield, C. &amp; Botvinick, M. Neuroscience-inspired artificial intelligence. <i>Neuron</i> <b>95</b>, 245–258 (2017).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2017.06.011" data-track-item_id="10.1016/j.neuron.2017.06.011" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2017.06.011" aria-label="Article reference 30" data-doi="10.1016/j.neuron.2017.06.011">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="http://tinylogger.com/articles/cas-redirect/1:CAS:528:DC%2BC2sXht1Smtb%2FE" aria-label="CAS reference 30">CAS</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=28728020" aria-label="PubMed reference 30">PubMed</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 30" href="http://scholar.google.com/scholar_lookup?&amp;title=Neuroscience-inspired%20artificial%20intelligence&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2017.06.011&amp;volume=95&amp;pages=245-258&amp;publication_year=2017&amp;author=Hassabis%2CD&amp;author=Kumaran%2CD&amp;author=Summerfield%2CC&amp;author=Botvinick%2CM">
                    Google Scholar</a> 
                </p></li><li data-counter="31."><p id="ref-CR31">Gama, J., Žliobaitė, I., Bifet, A., Pechenizkiy, M. &amp; Bouchachia, A. A survey on concept drift adaptation. <i>ACM Comput. Surv.</i> <b>46</b>, 1–37 (2014).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1145/2523813" data-track-item_id="10.1145/2523813" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1145%2F2523813" aria-label="Article reference 31" data-doi="10.1145/2523813">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 31" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20survey%20on%20concept%20drift%20adaptation&amp;journal=ACM%20Comput.%20Surv.&amp;doi=10.1145%2F2523813&amp;volume=46&amp;pages=1-37&amp;publication_year=2014&amp;author=Gama%2CJ&amp;author=%C5%BDliobait%C4%97%2CI&amp;author=Bifet%2CA&amp;author=Pechenizkiy%2CM&amp;author=Bouchachia%2CA">
                    Google Scholar</a> 
                </p></li><li data-counter="32."><p id="ref-CR32">Puri, R., Kirby, R., Yakovenko, N. &amp; Catanzaro, B. Large scale language modeling: converging on 40 GB of text in four hours. In <i>2018 30th International Symposium on Computer Architecture and High Performance Computing (SBAC-PAD)</i> 290–297 (IEEE, 2018).</p></li><li data-counter="33."><p id="ref-CR33">Ioffe, S. &amp; Szegedy, C. Batch normalization: accelerating deep network training by reducing internal covariate shift. In <i>Proceedings of the International Conference on Machine Learning (ICML)</i> (eds Bach, F. &amp; Blei, D.) 448–456 (PMLR, 2015).</p></li><li data-counter="34."><p id="ref-CR34">Zenke, F., Poole, B. &amp; Ganguli, S. Continual learning through synaptic intelligence. In <i>Proc. 34th International Conference on Machine Learning</i> (eds Precup, D. &amp; Teh, Y. W.) 3987–3995 (PMLR, 2017).</p></li><li data-counter="35."><p id="ref-CR35">O’Shea, K. &amp; Nash, R. An introduction to convolutional neural networks. Preprint at <a href="https://doi.org/10.48550/arXiv.1511.08458" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.48550/arXiv.1511.08458">https://doi.org/10.48550/arXiv.1511.08458</a> (2015).</p></li><li data-counter="36."><p id="ref-CR36">Krizhevsky, A. &amp; Hinton, G. <i>Learning Multiple Layers of Features from Tiny Images</i>. Master’s thesis, Univ. Toronto (2009).</p></li><li data-counter="37."><p id="ref-CR37">Sutton, R. S. &amp; Barto, A. G. <i>Introduction to Reinforcement Learning</i>, Vol. 2 (MIT Press Cambridge, 1998).</p></li><li data-counter="38."><p id="ref-CR38">Hampton, A. N., Bossaerts, P. &amp; O’Doherty, J. P. The role of the ventromedial prefrontal cortex in abstract state-based inference during decision making in humans. <i>J. Neurosci.</i> <b>26</b>, 8360–8367 (2006).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1523/JNEUROSCI.1010-06.2006" data-track-item_id="10.1523/JNEUROSCI.1010-06.2006" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1523%2FJNEUROSCI.1010-06.2006" aria-label="Article reference 38" data-doi="10.1523/JNEUROSCI.1010-06.2006">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="http://tinylogger.com/articles/cas-redirect/1:CAS:528:DC%2BD28Xos1Kju74%3D" aria-label="CAS reference 38">CAS</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=16899731" aria-label="PubMed reference 38">PubMed</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6673813" aria-label="PubMed Central reference 38">PubMed Central</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 38" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20role%20of%20the%20ventromedial%20prefrontal%20cortex%20in%20abstract%20state-based%20inference%20during%20decision%20making%20in%20humans&amp;journal=J.%20Neurosci.&amp;doi=10.1523%2FJNEUROSCI.1010-06.2006&amp;volume=26&amp;pages=8360-8367&amp;publication_year=2006&amp;author=Hampton%2CAN&amp;author=Bossaerts%2CP&amp;author=O%E2%80%99Doherty%2CJP">
                    Google Scholar</a> 
                </p></li><li data-counter="39."><p id="ref-CR39">Heald, J. B., Lengyel, M. &amp; Wolpert, D. M. Contextual inference underlies the learning of sensorimotor repertoires. <i>Nature</i> <b>600</b>, 489–493 (2021).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s41586-021-04129-3" data-track-item_id="10.1038/s41586-021-04129-3" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41586-021-04129-3" aria-label="Article reference 39" data-doi="10.1038/s41586-021-04129-3">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="http://tinylogger.com/articles/cas-redirect/1:CAS:528:DC%2BB3MXisFyrsbfN" aria-label="CAS reference 39">CAS</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=34819674" aria-label="PubMed reference 39">PubMed</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC8809113" aria-label="PubMed Central reference 39">PubMed Central</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 39" href="http://scholar.google.com/scholar_lookup?&amp;title=Contextual%20inference%20underlies%20the%20learning%20of%20sensorimotor%20repertoires&amp;journal=Nature&amp;doi=10.1038%2Fs41586-021-04129-3&amp;volume=600&amp;pages=489-493&amp;publication_year=2021&amp;author=Heald%2CJB&amp;author=Lengyel%2CM&amp;author=Wolpert%2CDM">
                    Google Scholar</a> 
                </p></li><li data-counter="40."><p id="ref-CR40">Larsen, T., Leslie, D. S., Collins, E. J. &amp; Bogacz, R. Posterior weighted reinforcement learning with state uncertainty. <i>Neural Comput.</i> <b>22</b>, 1149–1179 (2010).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1162/neco.2010.01-09-948" data-track-item_id="10.1162/neco.2010.01-09-948" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1162%2Fneco.2010.01-09-948" aria-label="Article reference 40" data-doi="10.1162/neco.2010.01-09-948">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=20100078" aria-label="PubMed reference 40">PubMed</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 40" href="http://scholar.google.com/scholar_lookup?&amp;title=Posterior%20weighted%20reinforcement%20learning%20with%20state%20uncertainty&amp;journal=Neural%20Comput.&amp;doi=10.1162%2Fneco.2010.01-09-948&amp;volume=22&amp;pages=1149-1179&amp;publication_year=2010&amp;author=Larsen%2CT&amp;author=Leslie%2CDS&amp;author=Collins%2CEJ&amp;author=Bogacz%2CR">
                    Google Scholar</a> 
                </p></li><li data-counter="41."><p id="ref-CR41">Kaufman, M. A. &amp; Bolles, R. C. A nonassociative aspect of overshadowing. <i>Bull. Psychonomic Soc.</i> <b>18</b>, 318–320 (1981).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.3758/BF03333639" data-track-item_id="10.3758/BF03333639" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.3758%2FBF03333639" aria-label="Article reference 41" data-doi="10.3758/BF03333639">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 41" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20nonassociative%20aspect%20of%20overshadowing&amp;journal=Bull.%20Psychonomic%20Soc.&amp;doi=10.3758%2FBF03333639&amp;volume=18&amp;pages=318-320&amp;publication_year=1981&amp;author=Kaufman%2CMA&amp;author=Bolles%2CRC">
                    Google Scholar</a> 
                </p></li><li data-counter="42."><p id="ref-CR42">Matzel, L. D., Schachtman, T. R. &amp; Miller, R. R. Recovery of an overshadowed association achieved by extinction of the overshadowing stimulus. <i>Learn. Motiv.</i> <b>16</b>, 398–412 (1985).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/0023-9690(85)90023-2" data-track-item_id="10.1016/0023-9690(85)90023-2" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2F0023-9690%2885%2990023-2" aria-label="Article reference 42" data-doi="10.1016/0023-9690(85)90023-2">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 42" href="http://scholar.google.com/scholar_lookup?&amp;title=Recovery%20of%20an%20overshadowed%20association%20achieved%20by%20extinction%20of%20the%20overshadowing%20stimulus&amp;journal=Learn.%20Motiv.&amp;doi=10.1016%2F0023-9690%2885%2990023-2&amp;volume=16&amp;pages=398-412&amp;publication_year=1985&amp;author=Matzel%2CLD&amp;author=Schachtman%2CTR&amp;author=Miller%2CRR">
                    Google Scholar</a> 
                </p></li><li data-counter="43."><p id="ref-CR43">Poort, J. et al. Learning enhances sensory and multiple non-sensory representations in primary visual cortex. <i>Neuron</i> <b>86</b>, 1478–1490 (2015).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/j.neuron.2015.05.037" data-track-item_id="10.1016/j.neuron.2015.05.037" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuron.2015.05.037" aria-label="Article reference 43" data-doi="10.1016/j.neuron.2015.05.037">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="http://tinylogger.com/articles/cas-redirect/1:CAS:528:DC%2BC2MXhtVSqt73M" aria-label="CAS reference 43">CAS</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=26051421" aria-label="PubMed reference 43">PubMed</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC4503798" aria-label="PubMed Central reference 43">PubMed Central</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 43" href="http://scholar.google.com/scholar_lookup?&amp;title=Learning%20enhances%20sensory%20and%20multiple%20non-sensory%20representations%20in%20primary%20visual%20cortex&amp;journal=Neuron&amp;doi=10.1016%2Fj.neuron.2015.05.037&amp;volume=86&amp;pages=1478-1490&amp;publication_year=2015&amp;author=Poort%2CJ">
                    Google Scholar</a> 
                </p></li><li data-counter="44."><p id="ref-CR44">McClelland, J. L., McNaughton, B. L. &amp; O’Reilly, R. C. Why there are complementary learning systems in the hippocampus and neocortex: insights from the successes and failures of connectionist models of learning and memory. <i>Psychol. Rev.</i> <b>102</b>, 419–457 (1995).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1037/0033-295X.102.3.419" data-track-item_id="10.1037/0033-295X.102.3.419" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1037%2F0033-295X.102.3.419" aria-label="Article reference 44" data-doi="10.1037/0033-295X.102.3.419">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=7624455" aria-label="PubMed reference 44">PubMed</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 44" href="http://scholar.google.com/scholar_lookup?&amp;title=Why%20there%20are%20complementary%20learning%20systems%20in%20the%20hippocampus%20and%20neocortex%3A%20insights%20from%20the%20successes%20and%20failures%20of%20connectionist%20models%20of%20learning%20and%20memory&amp;journal=Psychol.%20Rev.&amp;doi=10.1037%2F0033-295X.102.3.419&amp;volume=102&amp;pages=419-457&amp;publication_year=1995&amp;author=McClelland%2CJL&amp;author=McNaughton%2CBL&amp;author=O%E2%80%99Reilly%2CRC">
                    Google Scholar</a> 
                </p></li><li data-counter="45."><p id="ref-CR45">Dauwels, J. On variational message passing on factor graphs. In <i>2007 IEEE International Symposium on Information Theory</i>, 2546–2550 (IEEE, 2007).</p></li><li data-counter="46."><p id="ref-CR46">Anil Meera, A. &amp; Wisse, M. Dynamic expectation maximization algorithm for estimation of linear systems with colored noise. <i>Entropy</i> <b>23</b>, 1306 (2021).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.3390/e23101306" data-track-item_id="10.3390/e23101306" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.3390%2Fe23101306" aria-label="Article reference 46" data-doi="10.3390/e23101306">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=34682030" aria-label="PubMed reference 46">PubMed</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC8534782" aria-label="PubMed Central reference 46">PubMed Central</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 46" href="http://scholar.google.com/scholar_lookup?&amp;title=Dynamic%20expectation%20maximization%20algorithm%20for%20estimation%20of%20linear%20systems%20with%20colored%20noise&amp;journal=Entropy&amp;doi=10.3390%2Fe23101306&amp;volume=23&amp;publication_year=2021&amp;author=Anil%20Meera%2CA&amp;author=Wisse%2CM">
                    Google Scholar</a> 
                </p></li><li data-counter="47."><p id="ref-CR47">Friston, K. Hierarchical models in the brain. <i>PLoS Comput. Biol.</i> <b>4</b>, e1000211 (2008).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1371/journal.pcbi.1000211" data-track-item_id="10.1371/journal.pcbi.1000211" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1371%2Fjournal.pcbi.1000211" aria-label="Article reference 47" data-doi="10.1371/journal.pcbi.1000211">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=18989391" aria-label="PubMed reference 47">PubMed</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC2570625" aria-label="PubMed Central reference 47">PubMed Central</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 47" href="http://scholar.google.com/scholar_lookup?&amp;title=Hierarchical%20models%20in%20the%20brain&amp;journal=PLoS%20Comput.%20Biol.&amp;doi=10.1371%2Fjournal.pcbi.1000211&amp;volume=4&amp;publication_year=2008&amp;author=Friston%2CK">
                    Google Scholar</a> 
                </p></li><li data-counter="48."><p id="ref-CR48">Meulemans, A., Farinha, M. T., Cervera, M. R., Sacramento, J. &amp; Grewe, B. F. Minimizing control for credit assignment with strong feedback. In <i>Proc. of Machine Learning Research</i> (eds Chaudhuri, K. et al.) 15458–15483 (PMLR, 2022).</p></li><li data-counter="49."><p id="ref-CR49">Meulemans, A., Zucchet, N., Kobayashi, S., von Oswald, J. &amp; Sacramento, J. The least-control principle for learning at equilibrium. <i>Adv. Neural Inf. Process. Syst.</i> <b>35</b>, 33603–33617 (2022).</p></li><li data-counter="50."><p id="ref-CR50">Gilra, A. &amp; Gerstner, W. Predicting non-linear dynamics by stable local learning in a recurrent spiking neural network. <i>eLife</i> <b>6</b>, e28295 (2017).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.7554/eLife.28295" data-track-item_id="10.7554/eLife.28295" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.7554%2FeLife.28295" aria-label="Article reference 50" data-doi="10.7554/eLife.28295">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29173280" aria-label="PubMed reference 50">PubMed</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5730383" aria-label="PubMed Central reference 50">PubMed Central</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 50" href="http://scholar.google.com/scholar_lookup?&amp;title=Predicting%20non-linear%20dynamics%20by%20stable%20local%20learning%20in%20a%20recurrent%20spiking%20neural%20network&amp;journal=eLife&amp;doi=10.7554%2FeLife.28295&amp;volume=6&amp;publication_year=2017&amp;author=Gilra%2CA&amp;author=Gerstner%2CW">
                    Google Scholar</a> 
                </p></li><li data-counter="51."><p id="ref-CR51">Haider, P. et al. Latent equilibrium: a unified learning theory for arbitrarily fast computation with arbitrarily slow neurons. In <i>Advances in Neural Information Processing Systems (NeurIPS)</i> (eds Ranzato, M. et al.) 17839–17851 (2021).</p></li><li data-counter="52."><p id="ref-CR52">Akrout, M., Wilson, C., Humphreys, P., Lillicrap, T. &amp; Tweed, D. B. Deep learning without weight transport. In <i>Advances in Neural Information Processing Systems (NeurIPS)</i> (eds Wallach, H. et al.) (Curran Associates, 2019).</p></li><li data-counter="53."><p id="ref-CR53">Lillicrap, T. P., Cownden, D., Tweed, D. B. &amp; Akerman, C. J. Random synaptic feedback weights support error backpropagation for deep learning. <i>Nat. Commun.</i> <b>7</b>, 13276 (2016).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/ncomms13276" data-track-item_id="10.1038/ncomms13276" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fncomms13276" aria-label="Article reference 53" data-doi="10.1038/ncomms13276">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="http://tinylogger.com/articles/cas-redirect/1:CAS:528:DC%2BC28XhvVehtLrM" aria-label="CAS reference 53">CAS</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=27824044" aria-label="PubMed reference 53">PubMed</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5105169" aria-label="PubMed Central reference 53">PubMed Central</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 53" href="http://scholar.google.com/scholar_lookup?&amp;title=Random%20synaptic%20feedback%20weights%20support%20error%20backpropagation%20for%20deep%20learning&amp;journal=Nat.%20Commun.&amp;doi=10.1038%2Fncomms13276&amp;volume=7&amp;publication_year=2016&amp;author=Lillicrap%2CTP&amp;author=Cownden%2CD&amp;author=Tweed%2CDB&amp;author=Akerman%2CCJ">
                    Google Scholar</a> 
                </p></li><li data-counter="54."><p id="ref-CR54">Millidge, B., Tschantz, A. &amp; Buckley, C. L. Relaxing the constraints on predictive coding models. Preprint at <a href="https://doi.org/10.48550/arXiv.2010.01047" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.48550/arXiv.2010.01047">https://doi.org/10.48550/arXiv.2010.01047</a> (2020).</p></li><li data-counter="55."><p id="ref-CR55">Salvatori, T. et al. Incremental predictive coding: a parallel and fully automatic learning algorithm. Preprint at <a href="https://doi.org/10.48550/arXiv.2212.00720" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.48550/arXiv.2212.00720">https://doi.org/10.48550/arXiv.2212.00720</a> (2022).</p></li><li data-counter="56."><p id="ref-CR56">Friston, K. J., Trujillo-Barreto, N. &amp; Daunizeau, J. Dem: a variational treatment of dynamic systems. <i>NeuroImage</i> <b>41</b>, 849–885 (2008).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/j.neuroimage.2008.02.054" data-track-item_id="10.1016/j.neuroimage.2008.02.054" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.neuroimage.2008.02.054" aria-label="Article reference 56" data-doi="10.1016/j.neuroimage.2008.02.054">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="http://tinylogger.com/articles/cas-redirect/1:STN:280:DC%2BD1czkvFWqtg%3D%3D" aria-label="CAS reference 56">CAS</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=18434205" aria-label="PubMed reference 56">PubMed</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 56" href="http://scholar.google.com/scholar_lookup?&amp;title=Dem%3A%20a%20variational%20treatment%20of%20dynamic%20systems&amp;journal=NeuroImage&amp;doi=10.1016%2Fj.neuroimage.2008.02.054&amp;volume=41&amp;pages=849-885&amp;publication_year=2008&amp;author=Friston%2CKJ&amp;author=Trujillo-Barreto%2CN&amp;author=Daunizeau%2CJ">
                    Google Scholar</a> 
                </p></li><li data-counter="57."><p id="ref-CR57">Millidge, B., Tang, M., Osanlouy, M. &amp; Bogacz, R. Predictive coding networks for temporal prediction. Preprint at <i>bioRxiv</i> <a href="https://doi.org/10.1101/2023.05.15.540906" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1101/2023.05.15.540906">https://doi.org/10.1101/2023.05.15.540906</a> (2023).</p></li><li data-counter="58."><p id="ref-CR58">Salvatori, T. et al. Learning on arbitrary graph topologies via predictive coding. In <i>Advances in Neural Information Processing Systems (NeurIPS)</i> (eds Koyejo, S. et al.) 38232–38244 (Curran Associates, 2022).</p></li><li data-counter="59."><p id="ref-CR59">Foroushani, A. N., Assaf, H., Noshahr, F. H., Savaria, Y. &amp; Sawan, M. Analog circuits to accelerate the relaxation process in the equilibrium propagation algorithm. In <i>2020 IEEE International Symposium on Circuits and Systems (ISCAS)</i> 1–5 (IEEE, 2020).</p></li><li data-counter="60."><p id="ref-CR60">Xiao, H., Rasul, K. &amp; Vollgraf, R. Fashion MNIST: a novel image dataset for benchmarking machine learning algorithms. Preprint at <a href="https://doi.org/10.48550/arXiv.1708.07747" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.48550/arXiv.1708.07747">https://doi.org/10.48550/arXiv.1708.07747</a> (2017).</p></li><li data-counter="61."><p id="ref-CR61">Goodfellow, I., Bengio, Y. &amp; Courville, A. <i>Deep Learning</i> (MIT Press Cambridge, 2016).</p></li><li data-counter="62."><p id="ref-CR62">O’Reilly, R. C. Biologically plausible error-driven learning using local activation differences: the generalized recirculation algorithm. <i>Neural Comput.</i> <b>8</b>, 895–938 (1996).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1162/neco.1996.8.5.895" data-track-item_id="10.1162/neco.1996.8.5.895" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1162%2Fneco.1996.8.5.895" aria-label="Article reference 62" data-doi="10.1162/neco.1996.8.5.895">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 62" href="http://scholar.google.com/scholar_lookup?&amp;title=Biologically%20plausible%20error-driven%20learning%20using%20local%20activation%20differences%3A%20the%20generalized%20recirculation%20algorithm&amp;journal=Neural%20Comput.&amp;doi=10.1162%2Fneco.1996.8.5.895&amp;volume=8&amp;pages=895-938&amp;publication_year=1996&amp;author=O%E2%80%99Reilly%2CRC">
                    Google Scholar</a> 
                </p></li><li data-counter="63."><p id="ref-CR63">Almeida, L. B. A learning rule for asynchronous perceptrons with feedback in a combinatorial environment. In <i>Artificial Neural Networks: Concept Learning</i> (ed. Diederich, J.) 102–111 (IEEE Computer Society Press, 1990).</p></li><li data-counter="64."><p id="ref-CR64">Pineda, F. Generalization of back propagation to recurrent and higher order neural networks. In <i>Advances in Neural Information Processing Systems (NeurIPS)</i> (ed. Anderson, D.) 602–611 (Curran Associates, 1987).</p></li><li data-counter="65."><p id="ref-CR65">Pineda, F. J. Dynamics and architecture for neural computation. <i>J. Complex.</i> <b>4</b>, 216–245 (1988).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/0885-064X(88)90021-0" data-track-item_id="10.1016/0885-064X(88)90021-0" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2F0885-064X%2888%2990021-0" aria-label="Article reference 65" data-doi="10.1016/0885-064X(88)90021-0">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 65" href="http://scholar.google.com/scholar_lookup?&amp;title=Dynamics%20and%20architecture%20for%20neural%20computation&amp;journal=J.%20Complex.&amp;doi=10.1016%2F0885-064X%2888%2990021-0&amp;volume=4&amp;pages=216-245&amp;publication_year=1988&amp;author=Pineda%2CFJ">
                    Google Scholar</a> 
                </p></li><li data-counter="66."><p id="ref-CR66">Hebb, D. O. <i>The Organisation of Behaviour: A Neuropsychological Theory</i> (Science Editions New York, 1949).</p></li><li data-counter="67."><p id="ref-CR67">Senn, W. et al. A neuronal least-action principle for real-time learning in cortical circuits. Preprint at <i>bioRxiv</i> <a href="https://doi.org/10.1101/2023.03.25.534198" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.1101/2023.03.25.534198">https://doi.org/10.1101/2023.03.25.534198</a> (2023).</p></li><li data-counter="68."><p id="ref-CR68">Glorot, X. &amp; Bengio, Y. Understanding the difficulty of training deep feedforward neural networks. In <i>Proc. 13th International Conference on Artificial Intelligence and Statistics</i> (eds Teh, Y. W. &amp; Titterington, M.) 249–256 (PMLR, 2010).</p></li><li data-counter="69."><p id="ref-CR69">Tolstikhin, I. O. et al. Mlp-mixer: an all-mlp architecture for vision. In <i>Advances in Neural Information Processing Systems (NeurIPS)</i> (eds Ranzato, M. et al.) 24261–24272 (Curran Associates, 2021).</p></li><li data-counter="70."><p id="ref-CR70">Žliobaitė, I. Learning under concept drift: an overview. Preprint at <a href="https://doi.org/10.48550/arXiv.1010.4784" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.48550/arXiv.1010.4784">https://doi.org/10.48550/arXiv.1010.4784</a> (2010).</p></li><li data-counter="71."><p id="ref-CR71">Tsymbal, A. <i>The Problem of Concept Drift: Definitions and Related Work</i>. Technical report, Computer Science Department, Trinity College Dublin (2004).</p></li><li data-counter="72."><p id="ref-CR72">Kingma, D. P. &amp; Ba, J. Adam: a method for stochastic optimization. <a href="https://doi.org/10.48550/arXiv.1412.6980" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.48550/arXiv.1412.6980">https://doi.org/10.48550/arXiv.1412.6980</a> (2014).</p></li><li data-counter="73."><p id="ref-CR73">Salvatori, T., Song, Y., Lukasiewicz, T., Bogacz, R. &amp; Xu, Z. Reverse differentiation via predictive coding. In <i>Proc. 36th AAAI Conference on Artificial Intelligence</i> (Salvatori, T., Song, Y., Xu, Z., Lukasiewicz, T. &amp; Bogacz, R.) 8150–8158 (Curran Associates, 2022).</p></li><li data-counter="74."><p id="ref-CR74">Sutton, R. S. Generalization in reinforcement learning: successful examples using sparse coarse coding. In <i>Advances in Neural Information Processing Systems (NeurIPS)</i> (eds Touretzky, D. et al.) 1038–1044 (NIPS, 1995).</p></li><li data-counter="75."><p id="ref-CR75">Geramifard, A., Dann, C., Klein, R. H., Dabney, W. &amp; How, J. P. RLPy: a value-function-based reinforcement learning framework for education and research. <i>J. Mach. Learn. Res.</i> <b>16</b>, 1573–1578 (2015).</p><p><a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 75" href="http://scholar.google.com/scholar_lookup?&amp;title=RLPy%3A%20a%20value-function-based%20reinforcement%20learning%20framework%20for%20education%20and%20research&amp;journal=J.%20Mach.%20Learn.%20Res.&amp;volume=16&amp;pages=1573-1578&amp;publication_year=2015&amp;author=Geramifard%2CA&amp;author=Dann%2CC&amp;author=Klein%2CRH&amp;author=Dabney%2CW&amp;author=How%2CJP">
                    Google Scholar</a> 
                </p></li><li data-counter="76."><p id="ref-CR76">Moore, A. Efficient memory-based learning for robot control. Technical report, Carnegie Mellon Univ. (1990).</p></li><li data-counter="77."><p id="ref-CR77">Barto, A. G., Sutton, R. S. &amp; Anderson, C. W. Neuronlike adaptive elements that can solve difficult learning control problems. In <i>IEEE Transactions on Systems, Man, and Cybernetics</i>, 834–846 (1983).</p></li><li data-counter="78."><p id="ref-CR78">Brockman, G. et al. OpenAI Gym. Preprint at <a href="https://doi.org/10.48550/arXiv.1606.01540" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.48550/arXiv.1606.01540">https://doi.org/10.48550/arXiv.1606.01540</a> (2016).</p></li><li data-counter="79."><p id="ref-CR79">Welford, B. P. Note on a method for calculating corrected sums of squares and products. <i>Technometrics</i> <b>4</b>, 419–420 (1962).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1080/00401706.1962.10490022" data-track-item_id="10.1080/00401706.1962.10490022" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1080%2F00401706.1962.10490022" aria-label="Article reference 79" data-doi="10.1080/00401706.1962.10490022">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 79" href="http://scholar.google.com/scholar_lookup?&amp;title=Note%20on%20a%20method%20for%20calculating%20corrected%20sums%20of%20squares%20and%20products&amp;journal=Technometrics&amp;doi=10.1080%2F00401706.1962.10490022&amp;volume=4&amp;pages=419-420&amp;publication_year=1962&amp;author=Welford%2CBP">
                    Google Scholar</a> 
                </p></li><li data-counter="80."><p id="ref-CR80">Knuth, D. E. <i>Art of Computer Programming</i>, Vol. 2 (Addison-Wesley Professional, 2014).</p></li></ol><p><a data-track="click" data-track-action="download citation references" data-track-label="link" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/s41593-023-01514-1?format=refman&amp;flavour=references">Download references<svg width="16" height="16" focusable="false" role="img" aria-hidden="true"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-download-medium"></use></svg></a></p></div></div></div></section></div><section data-title="Acknowledgements"><div id="Ack1-section"><h2 id="Ack1">Acknowledgements</h2><p>We thank T. Behrens for comments on the manuscript and A. Saxe and M. Witbrock for discussions. The presented research was supported by the following grants: China Scholarship Council under the State Scholarship Fund (Y.S.), JPMorgan AI Research Awards (Y.S.), Biotechnology and Biological Sciences Research Council grant BB/S006338/1 (R.B.), Medical Research Council grant MC_UU_00003/1 (R.B.), the Alan Turing Institute under the EPSRC grant EP/N510129/1 (T.L.), the AXA Research Fund (T.L.), National Natural Science Foundation of China grants 61906063 and 62276089 (Z.X.), Natural Science Foundation of Hebei Province, China, grant F2021202064 (Z.X.), Natural Science Foundation of Tianjin City, China, grant 19JCQNJC00400 (Z.X.), the ‘100 Talents Plan’ of Hebei Province, China, grant E2019050017 (Z.X.) and the Yuanguang Scholar Fund of Hebei University of Technology, China (Z.X.). The funders had no role in study design, data collection and analysis, decision to publish or preparation of the manuscript. This research was also funded, in part, by JPMorgan Chase &amp; Co. Any views or opinions expressed herein are solely those of the authors listed and may differ from the views and opinions expressed by JPMorgan Chase &amp; Co. or its affiliates. This material is not a product of the Research Department of J.P. Morgan Securities, LLC. This material should not be construed as an individual recommendation for any particular client and is not intended as a recommendation of particular securities, financial instruments or strategies for a particular client. This material does not constitute a solicitation or offer in any jurisdiction.</p></div></section><section aria-labelledby="author-information" data-title="Author information"><div id="author-information-section"><h2 id="author-information">Author information</h2><div id="author-information-content"><h3 id="affiliations">Authors and Affiliations</h3><ol><li id="Aff1"><p>Department of Computer Science, University of Oxford, Oxford, UK</p><p>Yuhang Song, Tommaso Salvatori, Thomas Lukasiewicz &amp; Zhenghua Xu</p></li><li id="Aff2"><p>Medical Research Council Brain Network Dynamics Unit, University of Oxford, Oxford, UK</p><p>Yuhang Song, Beren Millidge &amp; Rafal Bogacz</p></li><li id="Aff3"><p>Fractile, Ltd., London, UK</p><p>Yuhang Song</p></li><li id="Aff4"><p>Institute of Logic and Computation, Vienna University of Technology, Vienna, Austria</p><p>Tommaso Salvatori &amp; Thomas Lukasiewicz</p></li><li id="Aff5"><p>VERSES AI Research Lab, Los Angeles, CA, USA</p><p>Tommaso Salvatori</p></li><li id="Aff6"><p>State Key Laboratory of Reliability and Intelligence of Electrical Equipment, School of Health Sciences and Biomedical Engineering, Hebei University of Technology, Tianjin, China</p><p>Zhenghua Xu</p></li></ol><div data-test="author-info"><p><span>Authors</span></p><ol><li id="auth-Yuhang-Song-Aff1-Aff2-Aff3"><span>Yuhang Song</span><div><div><p><a href="http://tinylogger.com/search?author=Yuhang%20Song" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></p></div><div><p>You can also search for this author in
                        <span><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Yuhang%20Song" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span> </span><a href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Yuhang%20Song%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Beren-Millidge-Aff2"><span>Beren Millidge</span><div><div><p><a href="http://tinylogger.com/search?author=Beren%20Millidge" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></p></div><div><p>You can also search for this author in
                        <span><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Beren%20Millidge" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span> </span><a href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Beren%20Millidge%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Tommaso-Salvatori-Aff1-Aff4-Aff5"><span>Tommaso Salvatori</span><div><div><p><a href="http://tinylogger.com/search?author=Tommaso%20Salvatori" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></p></div><div><p>You can also search for this author in
                        <span><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Tommaso%20Salvatori" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span> </span><a href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Tommaso%20Salvatori%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Thomas-Lukasiewicz-Aff1-Aff4"><span>Thomas Lukasiewicz</span><div><div><p><a href="http://tinylogger.com/search?author=Thomas%20Lukasiewicz" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></p></div><div><p>You can also search for this author in
                        <span><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Thomas%20Lukasiewicz" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span> </span><a href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Thomas%20Lukasiewicz%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Zhenghua-Xu-Aff1-Aff6"><span>Zhenghua Xu</span><div><div><p><a href="http://tinylogger.com/search?author=Zhenghua%20Xu" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></p></div><div><p>You can also search for this author in
                        <span><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Zhenghua%20Xu" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span> </span><a href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Zhenghua%20Xu%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li><li id="auth-Rafal-Bogacz-Aff2"><span>Rafal Bogacz</span><div><div><p><a href="http://tinylogger.com/search?author=Rafal%20Bogacz" data-track="click" data-track-action="author link - publication" data-track-label="link" rel="nofollow">View author publications</a></p></div><div><p>You can also search for this author in
                        <span><a href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=search&amp;term=Rafal%20Bogacz" data-track="click" data-track-action="author link - pubmed" data-track-label="link" rel="nofollow">PubMed</a><span> </span><a href="http://scholar.google.co.uk/scholar?as_q=&amp;num=10&amp;btnG=Search+Scholar&amp;as_epq=&amp;as_oq=&amp;as_eq=&amp;as_occt=any&amp;as_sauthors=%22Rafal%20Bogacz%22&amp;as_publication=&amp;as_ylo=&amp;as_yhi=&amp;as_allsubj=all&amp;hl=en" data-track="click" data-track-action="author link - scholar" data-track-label="link" rel="nofollow">Google Scholar</a></span></p></div></div></li></ol></div><h3 id="contributions">Contributions</h3><p>Y.S. and R.B. conceived the project. Y.S., R.B., B.M. and T.S. contributed ideas for experiments and analysis. Y.S. and B.M. performed simulations. Y.S., B.M. and R.B. performed mathematical analyses. Y.S., T.L. and R.B. managed the project. T.L and Z.X. advised on the project. Y.S., R.B. and B.M. wrote the paper. T.S., T.L. and Z.X. provided revisions to the paper.</p><h3 id="corresponding-author">Corresponding authors</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" href="mailto:yuhang.song@bndu.ox.ac.uk">Yuhang Song</a>, <a id="corresp-c2" href="mailto:thomas.lukasiewicz@cs.ox.ac.uk">Thomas Lukasiewicz</a>, <a id="corresp-c3" href="mailto:zhenghua.xu@hebut.edu.cn">Zhenghua Xu</a> or <a id="corresp-c4" href="mailto:rafal.bogacz@ndcn.ox.ac.uk">Rafal Bogacz</a>.</p></div></div></section><section data-title="Ethics declarations"><div id="ethics-section"><h2 id="ethics">Ethics declarations</h2><div id="ethics-content">
              
                <h3 id="FPar4">Competing interests</h3>
                <p>Y.S., B.M. and R.B. are shareholders in Fractile, Ltd., which designs artificial intelligence accelerator hardware. The remaining authors declare no competing interests.</p>
              
            </div></div></section><section data-title="Peer review"><div id="peer-review-section"><h2 id="peer-review">Peer review</h2><div id="peer-review-content">
              
              
                <h3 id="FPar3">Peer review information</h3>
                <p><i>Nature Neuroscience</i> thanks Karl Friston, Walter Senn, Friedemann Zenke and Joel Zylberberg for their contribution to the peer review of this work.</p>
              
            </div></div></section><section data-title="Additional information"><div id="additional-information-section"><h2 id="additional-information">Additional information</h2><p><b>Publisher’s note</b> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></div></section><section data-title="Supplementary information"><div id="Sec19-section"><h2 id="Sec19">Supplementary information</h2><div id="Sec19-content"><div data-test="supplementary-info"><div data-test="supp-item" id="MOESM1"><h3><a data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="supplementary information" href="https://static-content.springer.com/esm/art%3A10.1038%2Fs41593-023-01514-1/MediaObjects/41593_2023_1514_MOESM1_ESM.pdf" data-supp-info-image="">Supplementary Information</a></h3><p>Supplementary Figs. 1–12 and Notes.</p></div><div data-test="supp-item" id="MOESM2"><h3><a data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="reporting summary" href="https://static-content.springer.com/esm/art%3A10.1038%2Fs41593-023-01514-1/MediaObjects/41593_2023_1514_MOESM2_ESM.pdf" data-supp-info-image="">Reporting Summary</a></h3></div></div></div></div></section><section data-title="Source data"><div id="Sec20-section"><h2 id="Sec20">Source data</h2><div id="Sec20-content"><div data-test="supplementary-info"><div data-test="supp-item" id="MOESM3"><h3><a data-track="click" data-track-action="view supplementary info" data-test="supp-info-link" data-track-label="source data figs. 3–6" href="https://static-content.springer.com/esm/art%3A10.1038%2Fs41593-023-01514-1/MediaObjects/41593_2023_1514_MOESM3_ESM.zip" data-supp-info-image="">Source Data Figs. 3–6</a></h3><p>Compressed file containing .csv files for all figures presenting numerical values.</p></div></div></div></div></section><section data-title="Rights and permissions"><div id="rightslink-section"><h2 id="rightslink">Rights and permissions</h2><div id="rightslink-content">
                <p><b>Open Access</b>  This article is licensed under a Creative Commons Attribution 4.0 International License, which permits use, sharing, adaptation, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if changes were made. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <a href="http://creativecommons.org/licenses/by/4.0/" rel="license">http://creativecommons.org/licenses/by/4.0/</a>.</p>
              <p><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Inferring%20neural%20activity%20before%20plasticity%20as%20a%20foundation%20for%20learning%20beyond%20backpropagation&amp;author=Yuhang%20Song%20et%20al&amp;contentID=10.1038%2Fs41593-023-01514-1&amp;copyright=The%20Author%28s%29&amp;publication=1097-6256&amp;publicationDate=2024-01-03&amp;publisherName=SpringerNature&amp;orderBeanReset=true&amp;oa=CC%20BY">Reprints and permissions</a></p></div></div></section><section aria-labelledby="article-info" data-title="About this article"><div id="article-info-section"><h2 id="article-info">About this article</h2><div id="article-info-content"><div><p><a data-crossmark="10.1038/s41593-023-01514-1" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1038/s41593-023-01514-1" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img loading="lazy" width="57" height="81" alt="Check for updates. Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>"/></a></p><div><h3 id="citeas">Cite this article</h3><p>Song, Y., Millidge, B., Salvatori, T. <i>et al.</i> Inferring neural activity before plasticity as a foundation for learning beyond backpropagation.
                    <i>Nat Neurosci</i> <b>27</b>, 348–358 (2024). https://doi.org/10.1038/s41593-023-01514-1</p><p><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" data-track-external="" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/s41593-023-01514-1?format=refman&amp;flavour=citation">Download citation<svg width="16" height="16" focusable="false" role="img" aria-hidden="true"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-download-medium"></use></svg></a></p><ul data-test="publication-history"><li><p>Received<span>: </span><span><time datetime="2022-05-18">18 May 2022</time></span></p></li><li><p>Accepted<span>: </span><span><time datetime="2023-11-02">02 November 2023</time></span></p></li><li><p>Published<span>: </span><span><time datetime="2024-01-03">03 January 2024</time></span></p></li><li><p>Issue Date<span>: </span><span><time datetime="2024-02">February 2024</time></span></p></li><li><p><abbr title="Digital Object Identifier">DOI</abbr><span>: </span><span>https://doi.org/10.1038/s41593-023-01514-1</span></p></li></ul><div data-component="share-box"></div></div></div></div></div></section>
            </div></div>
  </body>
</html>
