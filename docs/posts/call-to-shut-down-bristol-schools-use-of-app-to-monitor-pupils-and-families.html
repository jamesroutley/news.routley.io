<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.theguardian.com/education/2023/sep/21/calls-to-shut-down-bristol-schools-use-of-think-family-education-app-pupils-and-families">Original</a>
    <h1>Call to shut down Bristol schools’ use of app to ‘monitor’ pupils and families</h1>
    
    <div id="readability-page-1" class="page"><div id="maincontent"><div><p>Criminal justice and antiracist campaigners have raised concerns over an app being used by schools in <a href="https://www.theguardian.com/uk/bristol" data-link-name="in body link" data-component="auto-linked-tag">Bristol</a> to “monitor and profile” pupils and their families.</p><p>The app, which is being used by more than 100 schools, gives safeguarding leads quick, easy access to pupils’ and their families’ contacts with police, child protection and welfare services.</p><p>One of the concerns campaigners have is that the Think Family Education (TFE) app includes analysing which children could be at risk of exposure to criminality, which they argue risks leading to more discrimination against pupils from minority ethnic or working-class backgrounds.</p><p>Staff using the app have told <a href="https://www.fairtrials.org/" data-link-name="in body link">the criminal justice campaign charity Fair Trials</a> that they keep it secret from parents and carers, and admitted many would be concerned about it if they knew of it.</p><p>Bristol city council and Avon and Somerset police, who worked together on the system, insist it is in place to protect children, not criminalise them, and deny it is secret, pointing out that <a href="https://www.bristol.gov.uk/residents/social-care-and-health/children-and-families/insight-bristol" data-link-name="in body link">information about its existence is publicly available</a>.</p><p>But Fair Trials said the vast majority of parents would know nothing about the app. Griff Ferris, the charity’s senior legal and policy officer, said: “Schoolchildren should not be monitored, profiled and criminalised by secretive police databases. Surveillance is not safeguarding.</p><p>“Systems like this uphold existing discrimination against children and families from minoritised ethnic and more deprived backgrounds. This system is expanding the net of surveillance. It should be shut down.”</p><p>A spokesperson for <a href="https://www.nomoreexclusions.com/" data-link-name="in body link">the antiracist organisation No More Exclusions Bristol</a> said: “Technologies that gather and use information in the name of ‘public safety’ overwhelmingly reproduce racialised ideas of problematic behaviour.”</p><p>Liz Fekete, the director of the Institute of Race Relations, strongly criticised elements of the app, saying the approach “stigmatises whole families and leaves even primary school children vulnerable to police surveillance and intelligence gathering”.</p><p>When it was consulted, the Bristol City Youth Council, an elected group of young people, expressed reservations that if the system was not used properly it could lead to “prejudice and judgment”.</p><p>Systems to collate information about children are used in other parts of England but Bristol city council describes Think Family as “innovative” and a number of local authorities are watching how the app works.</p><p>On its website, the council says the <a href="https://www.bristol.gov.uk/residents/social-care-and-health/children-and-families/insight-bristol" data-link-name="in body link">Think Family database</a>, which the app draws on, includes information from about 50,000 families across the city collected from agencies including social care, police and the Department for Work and Pensions. It says it highlights “vulnerabilities or needs” and uses “targeted analytics” to help identify children at risk of sexual or criminal exploitation.</p><p>Critics say the reality is that this risks children from minority ethnic or poorer backgrounds being profiled as being involved in gangs or county lines operations.</p><p>Schools using the TFE app receive alerts about children’s and family members’ contact with police, antisocial behaviour and domestic violence incidents. The system also gives schools access to sensitive personal details about families’ financial situations.</p><p>School safeguarding leads told Fair Trials that they kept the system secret from children and their families. One said: “They [parents and carers] wouldn’t know about this ... parents will have no kind of sight of it at all ... They just don’t know of its existence.”</p><p>They described the system as “an early warning process” and admitted: “I think there’s a bit of a risk it getting out there that schools hold this kind of central bank of information.”</p><p>A spokesperson for Bristol city council said the Think Family database was introduced to counter the trend of agencies working in silos at a time of a “generational squeeze” on public finances.</p><p>The spokesperson said: “The introduction of the Think Family Education app means that schools … have access to appropriate information in a secure and restricted way to make decisions about how they support children. There are strict controls in place about who can access this information, how they do this and the reasons why.”</p><p>A spokesperson for Avon and Somerset police said the database gave professionals working with children joined-up information to identify and safeguard those at risk of criminal and sexual exploitation.</p><p>“The TFE app gives professionals immediate access to this information, helping them to act swiftly on any identified risks.” The spokesperson said neither the app or database assessed the likelihood of an individual to commit a crime.</p><p>The force said “robust privacy and sharing agreements” had been approved by <a href="https://ico.org.uk/" data-link-name="in body link">the Information Commissioner’s Office</a> and development of the system done in collaboration with the <a href="https://www.gov.uk/government/organisations/centre-for-data-ethics-and-innovation" data-link-name="in body link">Centre for Data Ethics and Innovation</a>.</p></div></div></div>
  </body>
</html>
