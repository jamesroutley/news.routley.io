<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.trailofbits.com/2025/09/24/supply-chain-attacks-are-exploiting-our-assumptions/">Original</a>
    <h1>Supply chain attacks are exploiting our assumptions</h1>
    
    <div id="readability-page-1" class="page"><div><p>Every time you run <code>cargo add</code> or <code>pip install</code>, you are taking a leap of faith. You trust that the code you are downloading contains what you expect, comes from who you expect, and does what you expect. These expectations are so fundamental to modern development that we rarely think about them. However, attackers are systematically exploiting each of these assumptions.</p><p>In 2024 alone, PyPI and npm removed thousands of malicious packages; multiple high-profile projects had malware injected directly into the build process; and the XZ Utils backdoor nearly made it into millions of Linux systems worldwide.</p><p>Dependency scanning only catches known vulnerabilities. It won’t catch when a typosquatted package steals your credentials, when a compromised maintainer publishes malware, or when attackers poison the build pipeline itself. These attacks succeed because they exploit the very trust that makes modern software development possible.</p><p>This post breaks down the trust assumptions that make the software supply chain vulnerable, analyzes recent attacks that exploit them, and highlights some of the cutting-edge defenses being built across ecosystems to turn implicit trust into explicit, verifiable guarantees.</p><h2 id="implicit-trust">Implicit trust</h2><p>For many developers, the software supply chain begins and ends with the software bill of materials (SBOM) and dependency scanning, which together answer two fundamental questions: what code do you have, and does it contain known vulnerabilities? But understanding what you have is the bare minimum. As sophisticated attacks become more common, you also need to understand where your code comes from and how it gets to you.</p><p><strong>You trust that you are installing the package you expect.</strong> You assume that running <code>cargo add rustdecimal</code> is safe because <code>rustdecimal</code> is a well-known and widely used library. Or wait, maybe it’s spelled <code>rust_decimal</code>?</p><p><strong>You trust that packages are published by the package maintainers.</strong> When a popular package starts shipping with a precompiled binary to save build time, you may decide to trust the package author. However, many registries lack strong verification that publishers are who they claim to be.</p><p><strong>You trust that packages are built from the package source code.</strong> You may work on a security-conscious team that audits code changes in the public repository before upgrading dependencies. But this is meaningless if the distributed package was built from code that does not appear in the repository.</p><p><strong>You trust the maintainers themselves.</strong> Ultimately, installing third-party code means trusting package maintainers. It is not practical to audit every line of code you depend on. We assume that the maintainers of well-established and widely adopted packages will not suddenly decide to add malicious code.</p><p>These assumptions extend beyond traditional package managers. The same trust exists when you run a GitHub action, install a tool with Homebrew, or execute the convenient <code>curl ... | bash</code> installation script. Understanding these implicit trust relationships is the first step in assessing and mitigating supply chain risk.</p><h2 id="recent-attacks">Recent attacks</h2><p>Attackers are exploiting trust assumptions across every layer of the supply chain. Recent incidents range from simple typosquatting to multiyear campaigns, demonstrating how attackers’ tactics are evolving and growing more complex.</p><h3 id="deceptive-doubles">Deceptive doubles</h3><p><strong>Typosquatting</strong> involves publishing a malicious package with a name similar to that of a legitimate package. Running <code>cargo add rustdecimal</code> instead of <code>rust_decimal</code> could install malware instead of the expected legitimate library. This <a href="https://blog.rust-lang.org/2022/05/10/malicious-crate-rustdecimal/">exact attack</a> occurred on crates.io in 2022. The malicious <code>rustdecimal</code> mimicked the popular <code>rust_decimal</code> package but contained a <code>Decimal::new</code> function that executed a malicious binary when called.</p><p>The simplicity of the attack has made it easy for attackers to launch numerous large-scale campaigns, particularly against PyPI and npm. Since 2022, there have been multiple typosquatting campaigns targeting packages that account for a combined <a href="https://blog.phylum.io/phylum-detects-active-typosquatting-campaign-targeting-npm-developers/">1.2 billion weekly downloads</a>. Thousands of malicious packages have been published to PyPI and npm alone. This type of attack happens so frequently that there are too many examples to list here. In 2023, researchers documented <a href="https://blog.phylum.io/a-pypi-typosquatting-campaign-post-mortem/">a campaign that registered 900 typosquats of 40 popular PyPI packages</a> and discovered <a href="https://blog.phylum.io/rust-malware-staged-on-crates-io/">malware being staged on crates.io</a>. The attacks have only intensified, with <a href="https://blog.phylum.io/typosquatting-campaign-targets-python-developers/">500 malicious packages published</a> in a single 2024 campaign.</p><p><strong>Dependency confusion</strong> takes a different approach, exploiting package manager logic directly. Security researcher Alex Birsan <a href="https://medium.com/@alex.birsan/dependency-confusion-4a5d60fec610">demonstrated and named</a> this type of attack in 2021. He discovered that many organizations use names for internal packages that are either leaked or guessable. By publishing packages with the same names as these internal packages to public registries, Birsan was able to trick package managers into downloading his version instead. Birsan’s proof of concept identified vulnerabilities across three programming languages and 35 organizations, including Shopify, Apple, Netflix, Uber, and Yelp.</p><p>In 2022, an attacker used this technique to <a href="https://pytorch.org/blog/compromised-nightly-dependency/">include malicious code</a> in the nightly releases of PyTorch for five days. An internal dependency named <code>torchtriton</code> was hosted from PyTorch’s nightly package index. An attacker published a malicious package with the same name to PyPI, which took precedence. As a result, the nightly versions of PyTorch contained malware for five days before the malware was caught.</p><p>While these attacks occur at the point of installation, other attacks take a more direct approach by compromising the publishing process itself.</p><h3 id="stolen-secrets">Stolen secrets</h3><p>Compromised accounts are another frequent attack vector. Attackers acquire a leaked key, stolen token, or guessed password, and are able to directly publish malicious code on behalf of a trusted entity. A few recent incidents show the scale of this type of attack:</p><ul><li><strong>ctrl/tinycolor</strong> (September 2025): <a href="https://www.stepsecurity.io/blog/ctrl-tinycolor-and-40-npm-packages-compromised">Self-propagating malware</a> harvested npm API credentials and used the credentials to publish additional malicious packages. Over 40 packages were compromised, accounting for more than 2 million weekly downloads.</li><li><strong>Nx</strong> (August 2025): A compromised token allowed attackers to publish <a href="https://github.com/nrwl/nx/security/advisories/GHSA-cxm3-wv7p-598c">malicious versions</a> containing scripts leveraging already installed AI CLI tools (Claude, Gemini, Q) for reconnaissance, stealing cryptocurrency wallets, GitHub/npm tokens, and SSH keys from thousands of developers before exfiltrating data to public GitHub repositories.</li><li><strong>rand-user-agent</strong> (May 2025): A <a href="https://www.bleepingcomputer.com/news/security/supply-chain-attack-hits-npm-package-with-45-000-weekly-downloads/">malicious release containing malware</a> was caught only after researchers noticed recent releases despite no changes to the source code in months.</li><li><strong>rspack</strong> (December 2024): Stolen npm tokens enabled attackers to <a href="https://www.sonatype.com/blog/npm-packages-rspack-vant-compromised-blocked-by-sonatype">publish cryptocurrency miners</a> in packages with 500,000 combined weekly downloads.</li><li><strong>UAParser.js</strong> (October 2021): A compromised npm token was used to publish malicious releases containing a cryptocurrency miner. The library had millions of weekly downloads at the time of the attack.</li><li><strong>PHP Git server</strong> (March 2021): Stolen credentials allowed attackers to <a href="https://news-web.php.net/php.internals/113981">inject a backdoor directly into PHP’s source code</a>. Thankfully, the content of the changes was easily spotted and removed by the PHP team before any release.</li><li><strong>Codecov</strong> (January 2021): Attackers found a deployment key in a public Docker image layer and used it to <a href="https://about.codecov.io/apr-2021-post-mortem/">modify Codecov’s Bash Uploader tool</a>, silently exfiltrating environment variables and API keys for months before discovery.</li></ul><p>Stolen secrets remain one of the most reliable supply chain attack vectors. But as organizations implement stronger authentication and better secret management, attackers are shifting from stealing keys to compromising the systems that use them.</p><h3 id="poisoned-pipelines">Poisoned pipelines</h3><p>Instead of stealing credentials, some attackers have managed to distribute malware through legitimate channels by compromising the build and distribution systems themselves. Code reviews and other security checks are bypassed entirely by directly injecting malicious code into CI/CD pipelines.</p><p>The SolarWinds attack in 2020 is one of the well-known attacks in this category. Attackers compromised the build environment and <a href="https://www.solarwinds.com/blog/new-findings-from-our-investigation-of-sunburst">inserted malicious code directly into the Orion software</a> during compilation. The malicious version of Orion was then signed and distributed through SolarWinds’ legitimate update channels. The attack affected thousands of organizations including multiple Fortune 500 companies and government agencies.</p><p>More recently, in late 2024, an attacker <a href="https://blog.pypi.org/posts/2024-12-11-ultralytics-attack-analysis/">compromised the Ultralytics build pipeline</a> to publish multiple malicious versions. The attacker used a template injection in the project’s GitHub Actions to gain access to the CI/CD pipeline and poisoned the GitHub Actions cache to include malicious code directly in the build. At the time of the attack, Ultralytics had more than one million weekly downloads.</p><p>In 2025, an attacker modified the <code>reviewdog/actions-setup</code> GitHub action v1 tag <a href="https://www.wiz.io/blog/new-github-action-supply-chain-attack-reviewdog-action-setup">to point to a malicious version</a> containing code to dump secrets. This likely led to the compromise of another popular action, <code>tj-actions/changed-files</code>, through its dependency on <code>tj-actions/eslint-changed-files</code>, which in turn relied on the compromised <code>reviewdog</code> action. This cascading compromise affected thousands of projects using the <code>changed-files</code> action.</p><p>While poisoned pipeline attacks are relatively rare compared to typosquatting or credential theft, they represent an escalation in attacker sophistication. As stronger defenses are put in place, attackers are forced to move up the supply chain. The most determined attackers are willing to spend years preparing for a single attack.</p><h3 id="malicious-maintainers">Malicious maintainers</h3><p>The XZ Utils backdoor, discovered in March 2024, nearly compromised millions of Linux systems worldwide. The attacker spent over two years making legitimate contributions to the project before gaining maintainer access. They then abused this trust to insert a sophisticated backdoor through a series of seemingly innocent commits that would have granted remote access to any system using the compromised version.</p><p>Ultimately, you must trust the maintainers of your dependencies. Secure build pipelines cannot protect against a trusted maintainer who decides to insert malicious code. With open-source maintainers increasingly overwhelmed, and with AI tools making it easier to generate convincing contributions at scale, this trust model is facing unprecedented challenges.</p><h2 id="new-defenses">New defenses</h2><p>As attacks grow more sophisticated, defenders are building tools to match. These new approaches are making trust assumptions explicit and verifiable rather than implicit and exploitable. Each addresses a different layer of the supply chain where attackers have found success.</p><h3 id="typogard-and-typomania">TypoGard and Typomania</h3><p>Most package managers now include some form of typosquatting protection, but they typically use traditional similarity checks like those measuring Levenshtein distance, which generate excessive false positives that need to be manually reviewed.</p><p><a href="https://github.com/mt3443/typogard">TypoGard</a> fills this gap by using multiple context-aware metrics, like the following, to detect typosquatting packages with a low false positive rate and minimal overhead:</p><ul><li>Repeated characters (e.g., <code>rustdeciimal</code>)</li><li>Common typos based on keyboard layout</li><li>Swapped characters (e.g., <code>reqeusts</code> instead of <code>requests</code>)</li><li>Package popularity thresholds to focus on high-risk targets</li></ul><p>This tool targets npm, but the concepts can be extended to other languages. The Rust Foundation published a Rust port, <a href="https://github.com/rustfoundation/typomania">Typomania</a>, that has been <a href="https://github.com/rust-lang/crates.io/tree/main/src/typosquat">adopted by crates.io</a> and has successfully caught multiple malicious packages.</p><h3 id="zizmor">Zizmor</h3><p><a href="https://github.com/zizmorcore/zizmor">Zizmor</a> is a static analysis tool for GitHub Actions. Actions have a large surface area, and writing complex workflows can be difficult and error-prone. There are many subtle ways workflows can introduce vulnerabilities.</p><p>For example, Ultralytics was compromised via template injection in one of its workflows.</p><figure><pre tabindex="0"><code data-lang="text"><span><span>- name: Commit and Push Changes
</span></span><span><span>  if: (... || github.event_name == &#39;pull_request_target&#39; || ...
</span></span><span><span>  run: |
</span></span><span><span>      ...
</span></span><span><span>      git pull origin ${{ github.head_ref || github.ref }}
</span></span><span><span>      ...</span></span></code></pre></figure><p>Workflows triggered by <code>pull_request_target</code> events run with write permission access to repository secrets. An attacker <a href="https://blog.yossarian.net/2024/12/06/zizmor-ultralytics-injection">opened a pull request from a branch with a malicious name</a>. When the workflow ran, the <code>github.head_ref</code> variable expanded to the malicious branch name and executed as part of the run command with the workflow’s elevated privileges.</p><p>The <code>reviewdog/actions-setup</code> attack was also carried out in part by changing the action’s v1 tag to point to a malicious commit. Anyone using <code>reviewdog/actions-setup@v1</code> in their workflows silently started getting a malicious version without making any changes to their own workflows.</p><p>Zizmor flags all of the above. It includes a dangerous-trigger rule to flag workflows triggered by <code>pull_request_target</code>, a template-injection rule, and an unpinned-uses check that would have warned actions against using mutable references (like tags or branch names) when using <code>reviewdog/actions-setup@v1</code>.</p><h3 id="pypi-trusted-publishing-and-attestations">PyPI Trusted Publishing and attestations</h3><p>PyPI has taken significant steps to address several implicit trust assumptions through two complementary features: Trusted Publishing and attestations.</p><p>Trail of Bits worked with PyPI on <a href="https://blog.trailofbits.com/2023/05/23/trusted-publishing-a-new-benchmark-for-packaging-security/">Trusted Publishing</a><sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup>, which eliminates the need for long-lived API tokens. Instead of storing secrets that can be stolen, developers configure a trust relationship once: “this GitHub repository and workflow can publish this package.” When the workflow runs, GitHub sends a short-lived OIDC token to PyPI with claims about the repository and workflow. PyPI verifies this token was signed by GitHub’s key and responds with a short-lived PyPI token, which the workflow can use to publish the package. Using automatically generated, minimally scoped, short-lived tokens vastly reduces the risk of compromise.</p><p>Without long-lived and over-privileged API tokens, attackers must instead compromise the publishing GitHub workflow itself. While the Ultralytics attack demonstrated that CI/CD pipeline compromise is still a real threat, eliminating the need for users to manually manage credentials removes a source of user error and further reduces the attack surface.</p><p>Building on this foundation, Trail of Bits worked with PyPI again to introduce <a href="https://blog.trailofbits.com/2024/11/14/attestations-a-new-generation-of-signatures-on-pypi/">index-hosted digital attestations</a> in late 2024 through PEP 740. Attestations cryptographically bind each published package to its build provenance using Sigstore. Packages using the <a href="https://github.com/pypa/gh-action-pypi-publish">PyPI publish GitHub action</a> automatically include attestations, which act as a verifiable record of exactly where, when, and how the package was built.</p><figure><img src="https://blog.trailofbits.com/img/supply-chain-attacks/supply-chain-attacks-1.png" alt="Figure 1: Are we PEP 740 yet?"/><figcaption>Figure 1: Are we PEP 740 yet?</figcaption></figure><p>Over 30,000 packages use Trusted Publishing, and “<a href="https://trailofbits.github.io/are-we-pep740-yet/">Are We PEP 740 Yet?</a>” tracks attestation adoption among the most popular packages (86 of the top 360 at the time of writing). The final piece, automatic client side verification, remains a work in progress. Client tools like pip and uv do not yet verify attestations automatically. Until then, attestations provide transparency and auditability but not active protection during package installation.</p><h3 id="homebrew-build-provenance">Homebrew build provenance</h3><p>The implicit trust assumptions extend beyond programming languages and libraries. When you run <code>brew install</code> to install a binary package (or, a bottle), you are trusting that the bottle you’re downloading was built by Homebrew’s official CI from the expected source code and that it was not uploaded by an attacker who found a way to compromise Homebrew’s bottle hosting or otherwise tamper with the bottle’s content.</p><p>Trail of Bits, in collaboration with Alpha-Omega and OpenSSF, helped to add <a href="https://blog.trailofbits.com/2024/05/14/a-peek-into-build-provenance-for-homebrew/">build provenance to Homebrew</a> using GitHub’s attestations. Every bottle built by Homebrew now comes with cryptographic proof linking it to the specific GitHub Actions workflow that created it. This makes it significantly harder for a compromised maintainer to silently replace bottles with malicious versions.</p><figure><pre tabindex="0"><code data-lang="text"><span><span>% brew verify --help
</span></span><span><span>Usage: brew verify [options] formula [...]
</span></span><span><span>
</span></span><span><span>Verify the build provenance of bottles using GitHub&#39;s attestation tools.
</span></span><span><span>This is done by first fetching the given bottles and then verifying their provenance.</span></span></code></pre></figure><p>Each attestation includes the Git commit, the workflow that ran, and other build-time metadata. This transforms the trust assumption (“I trust this bottle was built from the source I expect”) into a verifiable fact.</p><p>The implementation of attestations handled historical bottles through a “backfilling” process, creating attestations for packages built before the system was in place. As a result, all official Homebrew packages include attestations.</p><p>The <code>brew verify</code> command makes it straightforward to check provenance, though the feature is still in beta and verification isn’t automatic by default. There are plans to eventually extend this feature to third-party repositories, bringing the same security guarantees to the broader Homebrew ecosystem.</p><h3 id="go-capslock">Go Capslock</h3><p><a href="https://github.com/google/capslock">Capslock</a> is a tool that statically identifies the capabilities of a Go program, including the following:</p><ul><li>Filesystem operations (reading, writing, deleting files)</li><li>Network connections (outbound requests, listening on ports)</li><li>Process execution (spawning subprocesses)</li><li>Environment variable access</li><li>System call usage</li></ul><figure><pre tabindex="0"><code data-lang="text"><span><span>% capslock --packages github.com/fatih/color
</span></span><span><span>Capslock is an experimental tool for static analysis of Go packages.
</span></span><span><span>Share feedback and file bugs at https://github.com/google/capslock.
</span></span><span><span>For additional debugging signals, use verbose mode with -output=verbose
</span></span><span><span>To get machine-readable full analysis output, use -output=jso`
</span></span><span><span>
</span></span><span><span>Analyzed packages:
</span></span><span><span>    github.com/fatih/color v1.18.0
</span></span><span><span>    github.com/mattn/go-colorable v0.1.13
</span></span><span><span>    github.com/mattn/go-isatty v0.0.20
</span></span><span><span>    golang.org/x/sys v0.25.0
</span></span><span><span>
</span></span><span><span>CAPABILITY_FILES: 1 references
</span></span><span><span>CAPABILITY_READ_SYSTEM_STATE: 41 references
</span></span><span><span>CAPABILITY_SYSTEM_CALLS: 1 references</span></span></code></pre></figure><p>This approach represents a shift in supply chain security. Rather than focusing on who wrote the code or where it came from, capability analysis examines what the code can actually do. A JSON parsing library that unexpectedly gains network access raises immediate red flags, regardless of whether the change came from a compromised supply chain or directly from a maintainer.</p><p>In practice, static capability detection can be difficult. Language features like runtime reflection and unsafe operations make it impossible to statically detect capabilities entirely accurately. Despite the limitations, capability detection provides a critical safety net as part of a layered defense against supply chain attacks.</p><p>Capslock pioneered this approach for Go, and the concept is ripe for adoption across other languages. As supply chain attacks grow more sophisticated, capability analysis offers a promising path forward. Verify what code can do, not just where it comes from.</p><h2 id="where-we-go-from-here">Where we go from here</h2><p>Supply chain attacks are not slowing down. If anything, they are becoming more automated, more complex, and more sophisticated in order to target broader audiences. Typosquatting campaigns are targeting packages with billions of downloads, publisher tokens and CI/CD pipelines are being compromised to poison software at the source, and patient attackers are spending years building reputation before striking.</p><p>The implicit trust that enabled software ecosystems to scale is being weaponized against us. Understanding your trust assumptions is the first step. Ask yourself these questions:</p><ul><li>Does my ecosystem block typosquatting packages?</li><li>How does it protect against compromised publisher tokens?</li><li>Can I verify build provenance?</li><li>Do I know what capabilities my dependencies have?</li></ul><p>Some ecosystems have started building defenses. Know what tools are available and start using them today. Use Trusted Publishing when publishing <a href="https://docs.pypi.org/trusted-publishers/using-a-publisher/">to PyPI</a> or <a href="http://crates.io">to crates.io</a>. Check your GitHub Actions with <a href="https://github.com/zizmorcore/zizmor">Zizmor</a>. Use <a href="https://github.com/trailofbits/it-depends">It-Depends</a> and <a href="https://github.com/trailofbits/deptective">Deptective</a> to understand what software actually depends on. Verify attestations where feasible. Use <a href="https://github.com/google/capslock">Capslock</a> to see the capabilities of Go packages, and more importantly, be aware when new capabilities are introduced.</p><p>But no ecosystem is completely covered. Push for better defaults where tools are lacking. Every verified attestation, every package caught typosquatting, and every flagged vulnerable GitHub action makes the entire industry more resilient. We cannot completely eliminate trust from supply chains, but we can strive to make that trust explicit, verifiable, and revocable.</p><p>If you need help understanding your supply chain trust assumptions, <a href="https://www.trailofbits.com/contact/">contact us</a>.</p></div></div>
  </body>
</html>
