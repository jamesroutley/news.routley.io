<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/SFBdragon/talc">Original</a>
    <h1>Talc â€“ A fast and flexible allocator for no_std and WebAssembly</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">

<p dir="auto"><sub><i>If you&#39;d like to support my work, a tip would be greatly appreciated via <a href="https://www.paypal.com/donate/?hosted_button_id=8CSQ92VV58VPQ" rel="nofollow">Paypal</a>. Thanks!</i></sub></p>

<ul dir="auto">
<li>Embedded systems, OS kernels, and other <code>no_std</code> environments</li>
<li>WebAssembly apps, as a drop-in replacement for the default allocator</li>
<li>Subsystems in normal programs that need especially quick arena allocation</li>
</ul>

<ul dir="auto">
<li>Generally faster and/or more memory efficient than alternatives *</li>
<li>Scales better to multiple cores for some workloads than alternatives *</li>
<li>Custom Out-Of-Memory handlers for just-in-time heap management and recovery</li>
<li>Supports creating and resizing arbitrarily many heaps</li>
<li>Optional allocation statistics</li>
<li>Partial validation in debug mode</li>
</ul>
<p dir="auto"><em>* Of those I know of, at time of writing, depending on workload. See <a href="#benchmarks">benchmarks</a> below.</em></p>

<ul dir="auto">
<li>Doesn&#39;t integrate with operating systems&#39; dynamic memory facilities out-of-the-box</li>
<li>Doesn&#39;t scale well to allocation-heavy concurrent processing</li>
</ul>

<p dir="auto">Targeting WebAssembly? You can find WASM-specific usage and benchmarks <a href="https://github.com/SFBdragon/talc/blob/master/README_WASM.md">here</a>.</p>
<ul dir="auto">
<li><a href="#setup">Setup</a></li>
<li><a href="#benchmarks">Benchmarks</a></li>
<li><a href="#general-usage">General Usage</a></li>
<li><a href="#advanced-usage">Advanced Usage</a></li>
<li><a href="#conditional-features">Conditional Features</a></li>
<li><a href="#stable-rust-and-msrv">Stable Rust and MSRV</a></li>
<li><a href="#algorithm">Algorithm</a></li>
<li><a href="#changelog">Changelog</a></li>
</ul>

<p dir="auto">As a global allocator:</p>
<div dir="auto" data-snippet-clipboard-copy-content="use talc::*;

static mut ARENA: [u8; 10000] = [0; 10000];

#[global_allocator]
static ALLOCATOR: Talck&lt;spin::Mutex&lt;()&gt;, ClaimOnOom&gt; = Talc::new(unsafe {
    // if we&#39;re in a hosted environment, the Rust runtime may allocate before
    // main() is called, so we need to initialize the arena automatically
    ClaimOnOom::new(Span::from_const_array(core::ptr::addr_of!(ARENA)))
}).lock();

fn main() {
    let mut vec = Vec::with_capacity(100);
    vec.extend(0..300usize);
}"><pre><span>use</span> talc<span>::</span><span>*</span><span>;</span>

<span>static</span> <span>mut</span> <span>ARENA</span><span>:</span> <span>[</span><span>u8</span><span>;</span> <span>10000</span><span>]</span> = <span>[</span><span>0</span><span>;</span> <span>10000</span><span>]</span><span>;</span>

<span>#<span>[</span>global_allocator<span>]</span></span>
<span>static</span> <span>ALLOCATOR</span><span>:</span> <span>Talck</span><span>&lt;</span>spin<span>::</span><span>Mutex</span><span>&lt;</span><span>(</span><span>)</span><span>&gt;</span><span>,</span> <span>ClaimOnOom</span><span>&gt;</span> = <span>Talc</span><span>::</span><span>new</span><span>(</span><span>unsafe</span> <span>{</span>
    <span>// if we&#39;re in a hosted environment, the Rust runtime may allocate before</span>
    <span>// main() is called, so we need to initialize the arena automatically</span>
    <span>ClaimOnOom</span><span>::</span><span>new</span><span>(</span><span>Span</span><span>::</span><span>from_const_array</span><span>(</span>core<span>::</span>ptr<span>::</span>addr_of!<span>(</span><span>ARENA</span><span>)</span><span>)</span><span>)</span>
<span>}</span><span>)</span><span>.</span><span>lock</span><span>(</span><span>)</span><span>;</span>

<span>fn</span> <span>main</span><span>(</span><span>)</span> <span>{</span>
    <span>let</span> <span>mut</span> vec = <span>Vec</span><span>::</span><span>with_capacity</span><span>(</span><span>100</span><span>)</span><span>;</span>
    vec<span>.</span><span>extend</span><span>(</span><span>0</span>..<span>300usize</span><span>)</span><span>;</span>
<span>}</span></pre></div>
<p dir="auto">Or use it as an arena allocator via the <code>Allocator</code> API with <code>spin</code> as follows:</p>
<div dir="auto" data-snippet-clipboard-copy-content="#![feature(allocator_api)]
use talc::*;
use core::alloc::{Allocator, Layout};

static mut ARENA: [u8; 10000] = [0; 10000];

fn main () {
    let talck = Talc::new(ErrOnOom).lock::&lt;spin::Mutex&lt;()&gt;&gt;();
    unsafe { talck.lock().claim(ARENA.as_mut().into()); }
    
    talck.allocate(Layout::new::&lt;[u32; 16]&gt;());
}"><pre><span>#!<span>[</span>feature<span>(</span>allocator_api<span>)</span><span>]</span></span>
<span>use</span> talc<span>::</span><span>*</span><span>;</span>
<span>use</span> core<span>::</span>alloc<span>::</span><span>{</span><span>Allocator</span><span>,</span> <span>Layout</span><span>}</span><span>;</span>

<span>static</span> <span>mut</span> <span>ARENA</span><span>:</span> <span>[</span><span>u8</span><span>;</span> <span>10000</span><span>]</span> = <span>[</span><span>0</span><span>;</span> <span>10000</span><span>]</span><span>;</span>

<span>fn</span> <span>main</span> <span>(</span><span>)</span> <span>{</span>
    <span>let</span> talck = <span>Talc</span><span>::</span><span>new</span><span>(</span><span>ErrOnOom</span><span>)</span><span>.</span><span>lock</span><span>::</span><span>&lt;</span>spin<span>::</span><span>Mutex</span><span>&lt;</span><span>(</span><span>)</span><span>&gt;</span><span>&gt;</span><span>(</span><span>)</span><span>;</span>
    <span>unsafe</span> <span>{</span> talck<span>.</span><span>lock</span><span>(</span><span>)</span><span>.</span><span>claim</span><span>(</span><span>ARENA</span><span>.</span><span>as_mut</span><span>(</span><span>)</span><span>.</span><span>into</span><span>(</span><span>)</span><span>)</span><span>;</span> <span>}</span>
    
    talck<span>.</span><span>allocate</span><span>(</span><span>Layout</span><span>::</span><span>new</span><span>::</span><span>&lt;</span><span>[</span><span>u32</span><span>;</span> <span>16</span><span>]</span><span>&gt;</span><span>(</span><span>)</span><span>)</span><span>;</span>
<span>}</span></pre></div>
<p dir="auto">Note that while the <code>spin</code> crate&#39;s mutexes are used here, any lock implementing <code>lock_api</code> works.</p>
<p dir="auto">See <a href="#general-usage">General Usage</a> and <a href="#advanced-usage">Advanced Usage</a> for more details.</p>

<div dir="auto"><h3 tabindex="-1" dir="auto">Heap Efficiency Benchmark Results</h3><a id="user-content-heap-efficiency-benchmark-results" aria-label="Permalink: Heap Efficiency Benchmark Results" href="#heap-efficiency-benchmark-results"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">The average occupied capacity upon first allocation failure when randomly allocating/deallocating/reallocating.</p>
<table>
<thead>
<tr>
<th>Allocator</th>
<th>Average Random Actions Heap Efficiency</th>
</tr>
</thead>
<tbody>
<tr>
<td>dlmalloc</td>
<td>99.07%</td>
</tr>
<tr>
<td><strong>talc</strong></td>
<td>98.87%</td>
</tr>
<tr>
<td>linked_list_allocator</td>
<td>98.28%</td>
</tr>
<tr>
<td>galloc</td>
<td>95.86%</td>
</tr>
<tr>
<td>buddy_alloc</td>
<td>58.75%</td>
</tr>
</tbody>
</table>

<p dir="auto">The number of successful allocations, deallocations, and reallocations within the allotted time.</p>

<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/SFBdragon/talc/blob/master/benchmark_graphs/random_actions.png"><img src="https://github.com/SFBdragon/talc/raw/master/benchmark_graphs/random_actions.png" alt="Random Actions Benchmark Results"/></a></p>
<div dir="auto"><h4 tabindex="-1" dir="auto">4 Threads, Increased Allocation Sizes</h4><a id="user-content-4-threads-increased-allocation-sizes" aria-label="Permalink: 4 Threads, Increased Allocation Sizes" href="#4-threads-increased-allocation-sizes"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/SFBdragon/talc/blob/master/benchmark_graphs/random_actions_multi.png"><img src="https://github.com/SFBdragon/talc/raw/master/benchmark_graphs/random_actions_multi.png" alt="Random Actions Multi Benchmark Results"/></a></p>
<div dir="auto"><h2 tabindex="-1" dir="auto">Allocations &amp; Deallocations Microbenchmark</h2><a id="user-content-allocations--deallocations-microbenchmark" aria-label="Permalink: Allocations &amp; Deallocations Microbenchmark" href="#allocations--deallocations-microbenchmark"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/SFBdragon/talc/blob/master/benchmark_graphs/microbench.png"><img src="https://github.com/SFBdragon/talc/raw/master/benchmark_graphs/microbench.png" alt="Microbenchmark Results"/></a></p>
<p dir="auto">Whiskers represent the interval from the 5th to 95th percentile.</p>

<p dir="auto">Here is the list of important <code>Talc</code> methods:</p>
<ul dir="auto">
<li>Constructors:
<ul dir="auto">
<li><code>new</code></li>
</ul>
</li>
<li>Information:
<ul dir="auto">
<li><code>get_allocated_span</code> - returns the minimum heap span containing all allocated memory in an established heap</li>
</ul>
</li>
<li>Management:
<ul dir="auto">
<li><code>claim</code> - claim memory to establishing a new heap</li>
<li><code>extend</code> - extend an established heap</li>
<li><code>truncate</code> - reduce the extent of an established heap</li>
<li><code>lock</code> - wraps the <code>Talc</code> in a <code>Talck</code>, which supports the <code>GlobalAlloc</code> and <code>Allocator</code> APIs</li>
</ul>
</li>
<li>Allocation:
<ul dir="auto">
<li><code>malloc</code></li>
<li><code>free</code></li>
<li><code>grow</code></li>
<li><code>shrink</code></li>
</ul>
</li>
</ul>
<p dir="auto">Read their <a href="https://docs.rs/talc/latest/talc/struct.Talc.html" rel="nofollow">documentation</a> for more info.</p>
<p dir="auto"><a href="https://docs.rs/talc/latest/talc/struct.Span.html" rel="nofollow"><code>Span</code></a> is a handy little type for describing memory regions, as trying to manipulate <code>Range&lt;*mut u8&gt;</code> or <code>*mut [u8]</code> or <code>base_ptr</code>-<code>size</code> pairs tends to be inconvenient or annoying.</p>

<p dir="auto">The most powerful feature of the allocator is that it has a modular OOM handling system, allowing you to fail out of or recover from allocation failure easily.</p>
<p dir="auto">Provided <code>OomHandler</code> implementations include:</p>
<ul dir="auto">
<li><code>ErrOnOom</code>: allocations fail on OOM</li>
<li><code>ClaimOnOom</code>: claims a heap upon first OOM, useful for initialization</li>
<li><code>WasmHandler</code>: itegrate with WebAssembly&#39;s <code>memory</code> module for automatic memory heap management</li>
</ul>
<p dir="auto">As an example of a custom implementation, recovering by extending the heap is implemented below.</p>
<div dir="auto" data-snippet-clipboard-copy-content="use talc::*;

struct MyOomHandler {
    heap: Span,
}

impl OomHandler for MyOomHandler {
    fn handle_oom(talc: &amp;mut Talc&lt;Self&gt;, layout: core::alloc::Layout) -&gt; Result&lt;(), ()&gt; {
        // Talc doesn&#39;t have enough memory, and we just got called!
        // We&#39;ll go through an example of how to handle this situation.
    
        // We can inspect `layout` to estimate how much we should free up for this allocation
        // or we can extend by any amount (increasing powers of two has good time complexity).
        // (Creating another heap with `claim` will also work.)
    
        // This function will be repeatedly called until we free up enough memory or 
        // we return Err(()) causing allocation failure. Be careful to avoid conditions where 
        // the heap isn&#39;t sufficiently extended indefinitely, causing an infinite loop.
    
        // an arbitrary address limit for the sake of example
        const HEAP_TOP_LIMIT: *mut u8 = 0x80000000 as *mut u8;
    
        let old_heap: Span = talc.oom_handler.heap;
    
        // we&#39;re going to extend the heap upward, doubling its size
        // but we&#39;ll be sure not to extend past the limit
        let new_heap: Span = old_heap.extend(0, old_heap.size()).below(HEAP_TOP_LIMIT);
    
        if new_heap == old_heap {
            // we won&#39;t be extending the heap, so we should return Err
            return Err(());
        }
    
        unsafe {
            // we&#39;re assuming the new memory up to HEAP_TOP_LIMIT is unused and allocatable
            talc.oom_handler.heap = talc.extend(old_heap, new_heap);
        }
    
        Ok(())
    }
}"><pre><span>use</span> talc<span>::</span><span>*</span><span>;</span>

<span>struct</span> <span>MyOomHandler</span> <span>{</span>
    <span>heap</span><span>:</span> <span>Span</span><span>,</span>
<span>}</span>

<span>impl</span> <span>OomHandler</span> <span>for</span> <span>MyOomHandler</span> <span>{</span>
    <span>fn</span> <span>handle_oom</span><span>(</span><span>talc</span><span>:</span> <span>&amp;</span><span>mut</span> <span>Talc</span><span>&lt;</span><span>Self</span><span>&gt;</span><span>,</span> <span>layout</span><span>:</span> core<span>::</span>alloc<span>::</span><span>Layout</span><span>)</span> -&gt; <span>Result</span><span>&lt;</span><span>(</span><span>)</span><span>,</span> <span>(</span><span>)</span><span>&gt;</span> <span>{</span>
        <span>// Talc doesn&#39;t have enough memory, and we just got called!</span>
        <span>// We&#39;ll go through an example of how to handle this situation.</span>
    
        <span>// We can inspect `layout` to estimate how much we should free up for this allocation</span>
        <span>// or we can extend by any amount (increasing powers of two has good time complexity).</span>
        <span>// (Creating another heap with `claim` will also work.)</span>
    
        <span>// This function will be repeatedly called until we free up enough memory or </span>
        <span>// we return Err(()) causing allocation failure. Be careful to avoid conditions where </span>
        <span>// the heap isn&#39;t sufficiently extended indefinitely, causing an infinite loop.</span>
    
        <span>// an arbitrary address limit for the sake of example</span>
        <span>const</span> <span>HEAP_TOP_LIMIT</span><span>:</span> <span>*</span><span>mut</span> <span>u8</span> = <span>0x80000000</span> <span>as</span> <span>*</span><span>mut</span> <span>u8</span><span>;</span>
    
        <span>let</span> old_heap<span>:</span> <span>Span</span> = talc<span>.</span><span>oom_handler</span><span>.</span><span>heap</span><span>;</span>
    
        <span>// we&#39;re going to extend the heap upward, doubling its size</span>
        <span>// but we&#39;ll be sure not to extend past the limit</span>
        <span>let</span> new_heap<span>:</span> <span>Span</span> = old_heap<span>.</span><span>extend</span><span>(</span><span>0</span><span>,</span> old_heap<span>.</span><span>size</span><span>(</span><span>)</span><span>)</span><span>.</span><span>below</span><span>(</span><span>HEAP_TOP_LIMIT</span><span>)</span><span>;</span>
    
        <span>if</span> new_heap == old_heap <span>{</span>
            <span>// we won&#39;t be extending the heap, so we should return Err</span>
            <span>return</span> <span>Err</span><span>(</span><span>(</span><span>)</span><span>)</span><span>;</span>
        <span>}</span>
    
        <span>unsafe</span> <span>{</span>
            <span>// we&#39;re assuming the new memory up to HEAP_TOP_LIMIT is unused and allocatable</span>
            talc<span>.</span><span>oom_handler</span><span>.</span><span>heap</span> = talc<span>.</span><span>extend</span><span>(</span>old_heap<span>,</span> new_heap<span>)</span><span>;</span>
        <span>}</span>
    
        <span>Ok</span><span>(</span><span>(</span><span>)</span><span>)</span>
    <span>}</span>
<span>}</span></pre></div>

<ul dir="auto">
<li><code>&#34;lock_api&#34;</code> (default): Provides the <code>Talck</code> locking wrapper type that implements <code>GlobalAlloc</code>.</li>
<li><code>&#34;allocator&#34;</code> (default, requires nightly): Provides an <code>Allocator</code> trait implementation via <code>Talck</code>.</li>
<li><code>&#34;nightly_api&#34;</code> (default, requires nightly): Provides the <code>Span::from(*mut [T])</code> and <code>Span::from_slice</code> functions.</li>
<li><code>&#34;counters&#34;</code>: <code>Talc</code> will track heap and allocation metrics. Use <code>Talc::get_counters</code> to access them.</li>
</ul>

<p dir="auto">Talc can be built on stable Rust by disabling <code>&#34;allocator&#34;</code> and <code>&#34;nightly_api&#34;</code>. The MSRV is 1.67.1.</p>
<p dir="auto">Disabling <code>&#34;nightly_api&#34;</code> disables <code>Span::from(*mut [T])</code>, <code>Span::from(*const [T])</code>, <code>Span::from_const_slice</code> and <code>Span::from_slice</code>.</p>

<p dir="auto">This is a dlmalloc-style linked list allocator with boundary tagging and bucketing, aimed at general-purpose use cases. Allocation is O(n) worst case (but in practice its near-constant time, see microbenchmarks), while in-place reallocations and deallocations are O(1).</p>
<p dir="auto">Additionally, the layout of chunk metadata is rearranged to allow for smaller minimum-size chunks to reduce memory overhead of small allocations. The minimum chunk size is <code>3 * usize</code>, with a single <code>usize</code> being reserved per allocation. This is more efficient than <code>dlmalloc</code> and <code>galloc</code>, despite using a similar algorithm.</p>


<ul dir="auto">
<li>
<p dir="auto">Optimized reallocation to allows other allocation operations to occur while memcopy-ing if an in-place reallocation failed.</p>
<ul dir="auto">
<li>As a side effect Talc now has a <code>grow_in_place</code> function that returns <code>Err</code> if growing the memory in-place isn&#39;t possible.</li>
<li>A graph of the random actions benchmark with a workload that benefits from this has been included in the <a href="#benchmarks">benchmarks</a> section.</li>
</ul>
</li>
<li>
<p dir="auto">Added <code>Span::from_*</code> and <code>From&lt;&gt;</code> functions for const pointers and shared references.</p>
<ul dir="auto">
<li>This makes creating a span in static contexts on stable much easier: <code>Span::from_const_array(addr_of!(MEMORY))</code></li>
</ul>
</li>
<li>
<p dir="auto">Fix: Made <code>Talck</code> derive <code>Debug</code> again.</p>
</li>
<li>
<p dir="auto">Contribution by <a href="https://github.com/khoover">Ken Hoover</a>: add Talc arena-style allocation size and perf WASM benchmarks</p>
<ul dir="auto">
<li>This might be a great option if you have a known dynamic memory requirement and would like to reduce your WASM size a little more.</li>
</ul>
</li>
<li>
<p dir="auto"><code>wasm-size</code> now uses <em>wasm-opt</em>, giving more realistic size differences for users of <em>wasm-pack</em></p>
</li>
<li>
<p dir="auto">Improved shell scripts</p>
</li>
<li>
<p dir="auto">Overhauled microbenchmarks</p>
<ul dir="auto">
<li>No longer simulates high-heap pressure as tolerating allocation failure is rare</li>
<li>Data is now displayed using box-and-whisker plots</li>
</ul>
</li>
</ul>

<ul dir="auto">
<li>Fix: Reset MSRV to 1.67.1 and added a check to <code>test.sh</code> for it</li>
</ul>
<div dir="auto"><h4 tabindex="-1" dir="auto">v4.1.0 (yanked, use 4.1.1)</h4><a id="user-content-v410-yanked-use-411" aria-label="Permalink: v4.1.0 (yanked, use 4.1.1)" href="#v410-yanked-use-411"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li>Added optional tracking of allocation metrics. Thanks <a href="https://github.com/khoover">Ken Hoover</a> for the suggestion!
<ul dir="auto">
<li>Enable the <code>&#34;counters&#34;</code> feature. Access the data via <code>talc.get_counters()</code></li>
<li>Metrics include allocation count, bytes available, fragmentation, overhead, and more.</li>
</ul>
</li>
<li>Improvements to documentation</li>
<li>Improved and updated benchmarks</li>
<li>Integrated the WASM performance benchmark into the project. Use <code>wasm-bench.sh</code> to run (requires <em>wasm-pack</em> and <em>deno</em>)</li>
<li>Improved <code>wasm-size</code> and <code>wasm-size.sh</code></li>
</ul>

<ul dir="auto">
<li>Changed <code>Talck</code>&#39;s API to be more inline with Rust norms.
<ul dir="auto">
<li><code>Talck</code> now hides its internal structure (no more <code>.0</code>).</li>
<li><code>Talck::talc()</code> has been replaced by <code>Talck::lock()</code>.</li>
<li><code>Talck::new()</code> and <code>Talck::into_inner(self)</code> have been added.</li>
<li>Removed <code>TalckRef</code> and implemented the <code>Allocator</code> trait on <code>Talck</code> directly. No need to call <code>talck.allocator()</code> anymore.</li>
</ul>
</li>
<li>Changed API for provided locking mechanism
<ul dir="auto">
<li>Moved <code>AssumeUnlockable</code> into <code>talc::locking::AssumeUnlockable</code></li>
<li>Removed <code>Talc::lock_assume_single_threaded</code>, use <code>.lock::&lt;talc::locking::AssumeUnlockable&gt;()</code> if necessary.</li>
</ul>
</li>
<li>Improvements to documentation here and there. Thanks <a href="https://github.com/polarathene">polarathene</a> for the contribution!</li>
</ul>

<ul dir="auto">
<li>Some improvements to documentation.</li>
</ul>

<ul dir="auto">
<li>Changed the WASM OOM handler&#39;s behavior to be more robust if other code calls <code>memory.grow</code> during the allocator&#39;s use.</li>
</ul>

<ul dir="auto">
<li>Reduced use of nightly-only features, and feature-gated the remainder (<code>Span::from(*mut [T])</code> and <code>Span::from_slice</code>) behind <code>nightly_api</code>.</li>
<li><code>nightly_api</code> feature is default-enabled
<ul dir="auto">
<li><em>WARNING:</em> use of <code>default-features = false</code> may cause unexpected errors if the gated functions are used. Consider adding <code>nightly_api</code> or using another function.</li>
</ul>
</li>
</ul>

<ul dir="auto">
<li>Improved documentation</li>
<li>Improved and updated benchmarks
<ul dir="auto">
<li>Increased the range of allocation sizes on Random Actions. (sorry Buddy Allocator!)</li>
<li>Increased the number of iterations the Heap Efficiency benchmark does to produce more accurate and stable values.</li>
</ul>
</li>
</ul>

<ul dir="auto">
<li>Added support for multiple discontinuous heaps! This required some major API changes
<ul dir="auto">
<li><code>new_arena</code> no longer exists (use <code>new</code> and then <code>claim</code>)</li>
<li><code>init</code> has been replaced with <code>claim</code></li>
<li><code>claim</code>, <code>extend</code> and <code>truncate</code> now return the new heap extent</li>
<li><code>InitOnOom</code> is now <code>ClaimOnOom</code>.</li>
<li>All of the above now have different behavior and documentation.</li>
</ul>
</li>
<li>Each heap now has a fixed overhead of one <code>usize</code> at the bottom.</li>
</ul>
<p dir="auto">To migrate from v2 to v3, keep in mind that you must keep track of the heaps if you want to resize them, by storing the returned <code>Span</code>s. Read <a href="https://docs.rs/talc/latest/talc/struct.Talc.html#method.claim" rel="nofollow"><code>claim</code></a>, <a href="https://docs.rs/talc/latest/talc/struct.Talc.html#method.extend" rel="nofollow"><code>extend</code></a> and <a href="https://docs.rs/talc/latest/talc/struct.Talc.html#method.truncate" rel="nofollow"><code>truncate</code></a>&#39;s documentation for all the details.</p>

<ul dir="auto">
<li>Rewrote the allocator internals to place allocation metadata above the allocation.
<ul dir="auto">
<li>This will have the largest impact on avoiding false sharing, where previously, the allocation metadata for one allocation would infringe on the cache-line of the allocation before it, even if a sufficiently high alignment was demanded. Single-threaded performance marginally increased, too.</li>
</ul>
</li>
<li>Removed heap_exhaustion and replaced heap_efficiency benchmarks.</li>
<li>Improved documentation and other resources.</li>
<li>Changed the WASM size measurement to include slightly less overhead.</li>
</ul>

<ul dir="auto">
<li>Added <code>dlmalloc</code> to the benchmarks.</li>
<li>WASM should now be fully supported via <code>TalckWasm</code>. Let me know what breaks ;)
<ul dir="auto">
<li>Find more details <a href="https://github.com/SFBdragon/talc/blob/master/README_WASM.md">here</a>.</li>
</ul>
</li>
</ul>

<ul dir="auto">
<li>Tests are now passing on 32 bit targets.</li>
<li>Documentation fixes and improvements for various items.</li>
<li>Fixed using <code>lock_api</code> without <code>allocator</code>.</li>
<li>Experimental WASM support has been added via <code>TalckWasm</code> on WASM targets.</li>
</ul>

<ul dir="auto">
<li>Removed dependency on <code>spin</code> and switched to using <code>lock_api</code> (thanks <a href="https://github.com/stlankes">Stefan Lankes</a>)
<ul dir="auto">
<li>You can specify the lock you want to use with <code>talc.lock::&lt;spin::Mutex&lt;()&gt;&gt;()</code> for example.</li>
</ul>
</li>
<li>Removed the requirement that the <code>Talc</code> struct must not be moved, and removed the <code>mov</code> function.
<ul dir="auto">
<li>The arena is now used to store metadata, so extremely small arenas will result in allocation failure.</li>
</ul>
</li>
<li>Made the OOM handling system use generics and traits instead of a function pointer.
<ul dir="auto">
<li>Use <code>ErrOnOom</code> to do what it says on the tin. <code>InitOnOom</code> is similar but inits to the given span if completely uninitialized. Implement <code>OomHandler</code> on any struct to implement your own behaviour (the OOM handler state can be accessed from <code>handle_oom</code> via <code>talc.oom_handler</code>).</li>
</ul>
</li>
<li>Changed the API and internals of <code>Span</code> and other changes to pass <code>miri</code>&#39;s Stacked Borrows checks.
<ul dir="auto">
<li>Span now uses pointers exclusively and carries provenance.</li>
</ul>
</li>
<li>Updated the benchmarks in a number of ways, notably adding <code>buddy_alloc</code> and removing <code>simple_chunk_allocator</code>.</li>
</ul>
</article></div></div>
  </body>
</html>
