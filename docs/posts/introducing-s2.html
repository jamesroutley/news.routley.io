<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://s2.dev/blog/intro">Original</a>
    <h1>Introducing S2</h1>
    
    <div id="readability-page-1" class="page"><div><blockquote>
<p>Elevate the beating heart of data systems.</p>
</blockquote>
<p>Our team has worked a lot on reliable real-time ingest, where <a href="https://engineering.linkedin.com/distributed-systems/log-what-every-software-engineer-should-know-about-real-time-datas-unifying" target="_blank">The Log</a> is foundational. We loved the serverless experience of object storage, but it <a href="https://blog.schmizz.net/designing-serverless-stream-storage#heading-vision" target="_blank">simply did not exist</a> for streaming data.</p>
<p>We believe the humble log – the <em><strong>stream</strong></em> – deserves to be a cloud storage primitive.</p>
<p>With S2, we are previewing just that: S2 is the Stream Store, our interpretation of streaming for the cloud era.</p>
<h3 id="what-if-streams-had-the-primacy-of-objects"><a aria-label="Link to section" href="#what-if-streams-had-the-primacy-of-objects">What if streams had the primacy of objects?</a></h3>
<p>Object storage has been nothing short of revolutionary. S3 broke ground in 2006 with simple storage operations on named objects – and 18 years later, S3 Express One Zone even allows appends. But ultimately, object storage is all about blobs and byte ranges. It is best for data at rest. Our vision of stream storage is predicated on the idea that the demands of <em>data in motion</em> need a fresh perspective.</p>
<p>With S2, you are elevated to the natural granularity of <em>records</em>. Writes to an S2 stream are appended at the tail, and even if multiple writers are acting at a time, S2 will durably sequence all records. S2 takes care of serving your reads efficiently, whether you need to start streaming from seconds ago or years. Streams can also be tailed in real-time, which is not possible with a blob in S3.</p>
<div>





















<table><thead><tr><th>Object Storage</th><th>Stream Storage</th></tr></thead><tbody><tr><td>Blobs and byte ranges</td><td>Records and sequence numbers</td></tr><tr><td><code>PUT</code> / <code>GET</code> / <code>DELETE</code> value of a named <code>Object</code> in a <code>Bucket</code></td><td><code>APPEND</code> / <code>READ</code> / <code>TRIM</code> records on a named <code>Stream</code> in a <code>Basin</code></td></tr><tr><td>Cumbersome and expensive for granular appends</td><td>Easy and cheap to append records</td></tr></tbody></table>
</div>
<p>Just like buckets are a namespace for objects, <em>basins</em> play that role for streams in S2. Basins and streams lean into the scale of the cloud – there is no limit on how many you can have, or how long data can be retained.</p>
<p>Want to model streams per user? Do it, this isn&#39;t Kafka. There are no cluster limitations to wrangle, and no infrastructure to tune.</p>
<figure data-rehype-pretty-code-figure=""><pre tabindex="0" data-language="bash" data-theme="github-dark"><code data-language="bash" data-theme="github-dark"><span data-line=""><span>$</span><span> s2</span><span> ls</span><span> s2://copilot-rag-ingest</span></span>
<span data-line=""><span>  /user-foo/cool-project</span></span>
<span data-line=""><span>  /user-foo/another-project</span></span>
<span data-line=""><span>  /user-bar/fork-of-cool-project</span></span>
<span data-line=""><span>  # ... ∞</span></span></code></pre></figure>
<p>This stream interface brought us closer to our vision, but we also wanted to liberate the superpower of <a href="https://blog.schmizz.net/disaggregated-wal" target="_blank">offloading durability</a> which databases like MemoryDB and Neon leverage. Decoupling compute and storage is safest when the storage service cooperates.</p>
<p>So we added a verb to <a href="https://maheshba.bitbucket.io/papers/osr2024.pdf" target="_blank">check the tail</a> of the stream with strong consistency, and support for concurrency control when writing. You can be a pessimist wielding a <a href="https://brooker.co.za/blog/2024/04/25/memorydb.html" target="_blank">fencing token</a> or optimistically supply the sequence number you expect assigned – no judgment which side of the fence you find yourself on.</p>
<h3 id="serverless--at-what-cost"><a aria-label="Link to section" href="#serverless--at-what-cost">Serverless – at what cost?</a></h3>
<p>S2 is architected around the infinite scale and unrelenting durability of object storage. That does not necessitate a slow or expensive offering – quite the opposite! We bridge the abstraction gap with a multi-tenant service so that you can have a truly serverless API for streaming data.</p>
<p>Durability is not negotiable for us in the undeniable <a href="https://materializedview.io/p/cloud-storage-triad-latency-cost-durability" target="_blank">cloud storage triad</a>. We allow users to navigate their latency vs cost tradeoff on a per stream basis, with <em>storage classes</em>. We are starting out with two:</p>
<ol>
<li>
<p><strong><code>Standard</code></strong>, backed by S3 Standard in AWS. S3 Standard has a counterpart in all public cloud providers, so we will be able to ship it in all cloud regions as we grow.</p>
</li>
<li>
<p><strong><code>Express</code></strong>, backed by a quorum of three S3 Express One Zone buckets in AWS. Azure has had a regional <a href="https://learn.microsoft.com/en-us/azure/storage/blobs/storage-blob-block-blob-premium" target="_blank">counterpart</a> for years, and it is <a href="https://www.linkedin.com/feed/update/urn:li:activity:7170847492522061825" target="_blank">in the cards</a> at GCP, so we are optimistic about wider availability.</p>
</li>
</ol>
<p>Our <code>Standard</code> storage class provides end-to-end p99 latencies of <strong>under 500 milliseconds</strong>. With <code>Express</code> you can expect <strong>under 50 milliseconds</strong> – in the realm of disk-based cloud streaming systems! S2 on the other hand is completely diskless, and all writes will be safe in S3 with regional durability before being acknowledged.</p>
<p>These latencies are supported at throughputs of <strong>hundreds of megabytes per second, per stream</strong>. The overhead of reading recently written data is negligible in S2 because of in-memory caching. Lagging readers can be particularly thirsty for throughput, and S2 serves them directly from object storage without a cap. We are initially throttling writes at 125 MiBps and reads against recent writes at 500 MiBps, per stream.</p>
<p><img src="https://cceckman.com/blog/20241219-latencies.svg" alt="Consistent low latency for S2 storage classes" title="Latencies at over 1 GiBps aggregate throughput"/></p>
<p>The service is free during our preview period to optimize for feedback. We want to be transparent about our <a href="https://cceckman.com/pricing" target="_blank">intended pricing</a>, and you will find that S2 comes in meaningfully cheaper than the norms of cloud streaming systems. This will be particularly stark in comparison to &#34;serverless&#34; offerings, which attract tiny ceilings on the number of streams and the throughputs you can push through them – at a very high premium.</p>
<p>There are no fixed costs in S2 like instances or cluster units. When we say serverless, we mean it!</p>
<h3 id="whats-next-for-s2"><a aria-label="Link to section" href="#whats-next-for-s2">What&#39;s next for S2</a></h3>
<p>S2 stands on a foundation of battle-tested cloud infrastructure, and our own Rust codebase gets put through the wringer with deterministic simulation testing. That said, the system is young, and there will be kinks. We are working hard to mature towards general availability and an SLA you can count on in production.</p>
<p>We are now shipping a <a href="https://cceckman.com/docs/interface/grpc" target="_blank">gRPC API</a>, <a href="https://github.com/s2-streamstore/s2-sdk-rust" target="_blank">Rust SDK</a>, and a <a href="https://cceckman.com/docs/quickstart#get-started-with-the-cli" target="_blank">shiny CLI</a> – and we are going to get cracking on a REST API. Do <a href="https://discord.gg/vTCs7kMkAf" target="_blank">tell us</a> which language SDKs you would be most interested in.</p>
<p>To give you a bigger picture sense of our direction:</p>
<ul>
<li>
<p><strong>Kafka protocol compatibility</strong>. This will be an open source layer, and we will integrate certain features like key-based compaction directly in S2.</p>
</li>
<li>
<p><strong>Multi-region basins</strong>. Once we expand into more cloud regions, we see a path towards basins that can span regions and even clouds, for the highest standard of availability.</p>
</li>
<li>
<p><strong>Under 5 millisecond latencies</strong>. We are just getting started with the architectural flexibility of storage classes, and another 10x improvement over <code>Express</code> is achievable.</p>
</li>
</ul>
<p>Can you replace Kafka or Kinesis with S2 today? If you find yourself reaching for their “low-level” APIs, S2 is likely to be a fit, and even address your requirements more directly.</p>
<p>If you expect a lot more from the cloud than current norms for streaming data – like not being limited on how many streams you can have, 10-100x higher ordered throughput, and concurrency control – S2 is the missing piece.</p>
<p>We are beyond excited for all the innovative data systems S2 enables, and invite you to <a href="https://cceckman.com/docs">build with us</a>!</p></div></div>
  </body>
</html>
