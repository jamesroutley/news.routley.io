<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.bitsnbites.eu/three-fundamental-flaws-of-simd/">Original</a>
    <h1>Three Fundamental Flaws of SIMD ISAs (2023)</h1>
    
    <div id="readability-page-1" class="page"><article id="post-966">
	
	<!-- .entry-header -->

	<div>
		
<p>According to Flynn’s taxonomy <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/SIMD" target="_blank">SIMD</a> refers to a computer architecture that can process multiple data streams with a single instruction (i.e. “Single Instruction stream, Multiple Data streams”). There are different taxonomies, and within those several different sub-categories and architectures that classify as “SIMD”.</p>



<p>In this post, however, I refer to packed SIMD ISA:s, i.e. the type of SIMD <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Instruction_set_architecture" target="_blank">instruction set architecture</a> that is most common in contemporary consumer grade CPU:s. More specifically, I refer to <strong>non-predicated packed SIMD</strong> ISA:s where the details of packed SIMD processing is exposed to the software environment.</p>



<h2>Packed SIMD</h2>



<p>The common trait of packed SIMD architectures is that several data elements are packed into a single register of a fixed width. Here is an example of possible configurations of a packed 128 bits wide SIMD register:</p>



<div><figure><a href="https://www.bitsnbites.eu/wp-content/uploads/2021/08/simd-register.png"><img width="512" height="131" src="https://www.bitsnbites.eu/wp-content/uploads/2021/08/simd-register.png" alt="SIMD register" srcset="https://www.bitsnbites.eu/wp-content/uploads/2021/08/simd-register.png 512w, https://www.bitsnbites.eu/wp-content/uploads/2021/08/simd-register-300x77.png 300w" sizes="(max-width: 512px) 100vw, 512px"/></a></figure></div>



<p>For instance, a 128-bit register can hold sixteen integer bytes or four single precision floating-point values.</p>



<p>This type of SIMD architecture has been wildly popular since the mid 1990s, and some packed SIMD ISA:s are:</p>



<ul><li>x86: <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/MMX_(instruction_set)" target="_blank">MMX</a>, <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/3DNow!" target="_blank">3DNow!</a>, <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Streaming_SIMD_Extensions" target="_blank">SSE</a>, <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/SSE2" target="_blank">SSE2</a>, …, and <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Advanced_Vector_Extensions" target="_blank">AVX</a>, <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/AVX2" target="_blank">AVX2</a>, <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/AVX-512" target="_blank">AVX-512</a><sup>1</sup></li><li>ARM: ARMv6 SIMD, <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/NEON_(instruction_set)" target="_blank">NEON</a></li><li>POWER: <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/AltiVec" target="_blank">AltiVec</a> (a.k.a. VMX and VelocityEngine)</li><li>MIPS: <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/MDMX" target="_blank">MDMX</a>, <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/MIPS-3D" target="_blank">MIPS-3D</a>, <a rel="noreferrer noopener" href="https://www.mips.com/products/architectures/ase/simd/" target="_blank">MSA</a>, <a rel="noreferrer noopener" href="https://www.mips.com/products/architectures/ase/dsp/" target="_blank">DSP</a></li><li>SPARC: <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Visual_Instruction_Set" target="_blank">VIS</a></li><li>Alpha: <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/DEC_Alpha#Motion_Video_Instructions_(MVI)" target="_blank">MVI</a></li></ul>



<p><sup>1</sup> <em>AVX and later x86 SIMD ISA:s (especially AVX-512) incorporate features from <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Vector_processor" target="_blank">vector processing</a>, making them packed SIMD / vector processing hybrids (thus some of the aspects discussed in this article do not fully apply).</em></p>



<p>The promise of all those ISA:s is increased data processing performance, since each instruction executes several operations in parallel. However, there are problems with this model.</p>



<h2>Flaw 1: Fixed register width</h2>



<p>Since the register size is fixed there is no way to scale the ISA to new levels of hardware parallelism without adding new instructions and registers. Case in point: MMX (64 bits) vs SSE (128 bits) vs AVX (256 bits) vs AVX-512 (512 bits).</p>



<p>Adding new registers and instructions has many implications. For instance, the <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Application_binary_interface" target="_blank">ABI</a> must be updated, and support must be added to operating system kernels, compilers and debuggers.</p>



<p>Another problem is that each new SIMD generation requires new instruction opcodes and encodings. In fixed width instruction sets (e.g. ARM) this may prohibit any new extensions, since there may not be enough opcode slots left for adding the new instructions. In variable width instruction sets (e.g. x86) the effect is typically that instructions get longer and longer (effectively hurting code density). Paradoxically each new SIMD generation essentially renders the previous generations redundant (except for supporting binary backwards compatibility), so a large number of instructions are wasted without adding much value.</p>



<p>Finally, any software that wants to use the new instruction set needs to be rewritten (or at least recompiled). What is worse, software developers often have to target several SIMD generations, and add mechanisms to their programs that dynamically select the optimal code paths depending on which SIMD generation is supported.</p>



<h2>Flaw 2: Pipelining</h2>



<p>The packed SIMD paradigm is that there is a 1:1 mapping between the register width and the execution unit width (this is usually required to achieve reasonable performance for instructions that mix inputs from several lanes). At the same time many SIMD operations are pipelined and require several clock cycles to complete (e.g. floating-point arithmetic and memory load instructions). The side effect of this is that the result of one SIMD instruction is not ready to be used until several instructions later in the instruction stream.</p>



<p>Consequently, loops have to be <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Loop_unrolling" target="_blank">unrolled</a> in order to avoid stalls and keep the pipeline busy. This can be done in advanced (power hungry) hardware implementations with register renaming and speculative out-of-order execution, but for simpler (usually more power efficient) hardware implementations loops have to be unrolled in software. Many software developers and compilers aiming to support both in-order and out-of-order processors simply unroll all SIMD loops in software. </p>



<p>However, loop unrolling hurts code density (i.e. makes the program binary larger), which in turn hurts instruction cache performance (fewer program segments fit in the instruction cache, which reduces the cache hit ratio).</p>



<p>Loop unrolling also increases <a href="https://en.wikipedia.org/wiki/Register_pressure" target="_blank" rel="noreferrer noopener">register pressure</a> (i.e. more registers must be used in order to keep the state of multiple loop iterations in registers), so the architecture must provide enough SIMD registers to avoid <a href="https://en.wikipedia.org/wiki/Register_spilling" target="_blank" rel="noreferrer noopener">register spilling</a>.</p>



<h2>Flaw 3: Tail handling</h2>



<p>When the number of array elements that are to be processed in a loop is not a multiple of the number of elements in the SIMD register, special loop tail handling needs to be implemented in software. For instance if an array contains 99 32-bit elements, and the SIMD architecture is 128 bits wide (i.e. a SIMD register contains four 32-bit elements), 4*24=96 elements can be processed in the main SIMD loop, and 99-96=3 elements need to be processed after the main loop.</p>



<p>This requires extra code after the loop for handling the tail. Some architectures support masked load/store that makes it possible to use SIMD instructions to process the tail, while a more common scenario is that you have to use scalar (non-SIMD) instructions to implement the tail (in the latter case there may be problems if scalar and SIMD instructions have different capabilities and/or semantics, but that is not an issue with packed SIMD per se, just with how some ISA:s are designed).</p>



<p>Usually you also need extra control logic before the loop. For instance if the array length is less than the SIMD register width, the main SIMD loop should be skipped.</p>



<p>The added control logic and tail handling code hurts code density (again reducing the instruction cache efficiency), and adds extra overhead (and is generally awkward to code).</p>



<h2>Alternatives</h2>



<p>One alternative to packed SIMD that addresses all of the flaws mentioned above is a <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Vector_processor" target="_blank">Vector Processor</a>. Perhaps the most notable vector processor is the <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Cray-1" target="_blank">Cray-1</a> (released 1975), and it has served as an inspiration for a new generation of instruction set architectures, including RISC-V <a rel="noreferrer noopener" href="https://github.com/riscv/riscv-v-spec" target="_blank">RVV</a>.</p>



<p>Several other (perhaps less known) projects are pursuing a similar vector model, including Agner Fog’s <a rel="noreferrer noopener" href="https://forwardcom.info/" target="_blank">ForwardCom</a>, Robert Finch’s <a href="https://github.com/robfinch/Thor/blob/main/Thor2021/doc/Thor2021.pdf" target="_blank" rel="noreferrer noopener">Thor2021</a> and my own <a rel="noreferrer noopener" href="https://mrisc32.bitsnbites.eu/" target="_blank">MRISC32</a>. An interesting variant is <a rel="noreferrer noopener" href="https://libre-soc.org/" target="_blank">Libre-SOC</a> (based on OpenPOWER) and its <a rel="noreferrer noopener" href="https://libre-soc.org/openpower/sv/" target="_blank">Simple-V</a> extension that maps vectors onto the scalar register files (which are extended to include some 128 registers each).</p>



<p>ARM <a rel="noreferrer noopener" href="https://community.arm.com/developer/research/b/articles/posts/the-arm-scalable-vector-extension-sve" target="_blank">SVE</a> is a predicate-centric, vector length agnostic ISA that addresses many of the traditional SIMD issues.</p>



<p>A completely different approach is taken by Mitch Alsup’s <a rel="noreferrer noopener" href="https://groups.google.com/g/comp.arch/c/SlbYDIPZjH0/m/CLkxJHs1BgAJ" target="_blank">My 66000</a> and its Virtual Vector Method (VVM), which transforms scalar loops into vectorized loops in hardware with the aid of special loop decoration instructions. That way it does not even have to have a vector register file.</p>



<p>Another interesting architecture is the <a rel="noreferrer noopener" href="https://millcomputing.com/" target="_blank">Mill</a>, which also has <a rel="noreferrer noopener" href="https://millcomputing.com/docs/wide-data/" target="_blank">support for vectors</a> without packed SIMD.</p>



<h2>Examples</h2>



<p><em>Edit: This section was added on 2021-08-19 to provide some code examples that show the difference between packed SIMD and other alternatives, and extended on 2023-05-31 with RISC-V RVV and ARM SVE examples and more comments. </em></p>



<p>A simple routine from <a rel="noreferrer noopener" href="https://en.wikipedia.org/wiki/Basic_Linear_Algebra_Subprograms" target="_blank">BLAS</a> is saxpy, which computes z = a*x + y, where <em>a</em> is a constant, <em>x</em> and <em>y</em> are arrays, and the “s” in “saxpy” stands for single precision floating-point.</p>



<pre><code>// Example C implementation of saxpy:
void saxpy(size_t n, float a, float* x, float* y, float* z)
{
  for (size_t i = 0; i &lt; n ; i++)
    z[i] = a * x[i] + y[i];
}</code></pre>



<p>Below are assembler code snippets that implement saxpy for different ISA:s.</p>



<h3>Packed SIMD (x86_64 / SSE)</h3>



<pre><code>saxpy:
    test    rdi, rdi
    je      .done
    cmp     rdi, 8
    jae     .at_least_8
    xor     r8d, r8d
    jmp     .tail_2_loop
.at_least_8:
    mov     r8, rdi
    and     r8, -8
    movaps  xmm1, xmm0
    shufps  xmm1, xmm0, 0
    lea     rax, [r8 - 8]
    mov     r9, rax
    shr     r9, 3
    add     r9, 1
    test    rax, rax
    je      .dont_unroll
    mov     r10, r9
    and     r10, -2
    neg     r10
    xor     eax, eax
.main_loop:
    movups  xmm2, xmmword ptr [rsi + 4*rax]
    movups  xmm3, xmmword ptr [rsi + 4*rax + 16]
    mulps   xmm2, xmm1
    mulps   xmm3, xmm1
    movups  xmm4, xmmword ptr [rdx + 4*rax]
    addps   xmm4, xmm2
    movups  xmm2, xmmword ptr [rdx + 4*rax + 16]
    addps   xmm2, xmm3
    movups  xmmword ptr [rcx + 4*rax], xmm4
    movups  xmmword ptr [rcx + 4*rax + 16], xmm2
    movups  xmm2, xmmword ptr [rsi + 4*rax + 32]
    movups  xmm3, xmmword ptr [rsi + 4*rax + 48]
    mulps   xmm2, xmm1
    mulps   xmm3, xmm1
    movups  xmm4, xmmword ptr [rdx + 4*rax + 32]
    addps   xmm4, xmm2
    movups  xmm2, xmmword ptr [rdx + 4*rax + 48]
    addps   xmm2, xmm3
    movups  xmmword ptr [rcx + 4*rax + 32], xmm4
    movups  xmmword ptr [rcx + 4*rax + 48], xmm2
    add     rax, 16
    add     r10, 2
    jne     .main_loop
    test    r9b, 1
    je      .tail_2
.tail_1:
    movups  xmm2, xmmword ptr [rsi + 4*rax]
    movups  xmm3, xmmword ptr [rsi + 4*rax + 16]
    mulps   xmm2, xmm1
    mulps   xmm3, xmm1
    movups  xmm1, xmmword ptr [rdx + 4*rax]
    addps   xmm1, xmm2
    movups  xmm2, xmmword ptr [rdx + 4*rax + 16]
    addps   xmm2, xmm3
    movups  xmmword ptr [rcx + 4*rax], xmm1
    movups  xmmword ptr [rcx + 4*rax + 16], xmm2
.tail_2:
    cmp     r8, rdi
    je      .done
.tail_2_loop:
    movss   xmm1, dword ptr [rsi + 4*r8]
    mulss   xmm1, xmm0
    addss   xmm1, dword ptr [rdx + 4*r8]
    movss   dword ptr [rcx + 4*r8], xmm1
    add     r8, 1
    cmp     rdi, r8
    jne     .tail_2_loop
.done:
    ret
.dont_unroll:
    xor     eax, eax
    test    r9b, 1
    jne     .tail_1
    jmp     .tail_2</code></pre>



<p>Notice how the packed SIMD code contains a 4x unrolled version of the main SIMD loop and a scalar tail loop. It also contains a setup phase (the first 20 instructions) that should not have a huge performance impact for long arrays, but for short arrays the setup code adds unnecessary overhead.</p>



<p>Unfortunately, this kind of manual setup + unrolling + tail handling code uses up unnecessarily large chunks of the instruction cache of a CPU core.</p>



<p>This demonstrates flaws 2 &amp; 3 described above. Flaw 1 is actually also present, since you need to have multiple implementations for optimal performance on all CPU:s. E.g. in addition to the SSE implementation above, you would also need AVX2 and AVX-512 implementations, and switch between them at run time depending on CPU capabilities.</p>



<h3>Vector (MRISC32)</h3>



<pre><code>saxpy:
    bz    r1, 2f          ; Nothing to do?
    getsr vl, #0x10       ; Query the maximum vector length
1:
    minu  vl, vl, r1      ; Define the operation vector length
    sub   r1, r1, vl      ; Decrement loop counter
    ldw   v1, [r3, #4]    ; Load x[] (element stride = 4 bytes)
    ldw   v2, [r4, #4]    ; Load y[]
    fmul  v1, v1, r2      ; x[] * a
    fadd  v1, v1, v2      ; + y[]
    stw   v1, [r5, #4]    ; Store z[]
    ldea  r3, [r3, vl*4]  ; Increment x pointer
    ldea  r4, [r4, vl*4]  ; Increment y pointer
    ldea  r5, [r5, vl*4]  ; Increment z pointer
    bnz   r1, 1b
2:
    ret</code></pre>



<p>Unlike the packed SIMD version, the vector version is much more compact since it handles unrolling and the tail in hardware. Also, the setup code is minimal (just 1-2 instructions).</p>



<p>The GETSR instruction is used for querying the implementation defined maximum vector length (i.e. the number of 32-bit elements that a vector register can hold). The VL register defines the vector length (number of elements to process) for the vector operations. During the last iteration, VL may be less than the maximum vector length, which takes care of the tail.</p>



<p>Load and store instructions take a “byte stride” argument that defines the address increment between each vector element, so in this case (stride=4 bytes) we load/store consecutive single-precision floating-point values. The FMUL and FADD instructions operate on each vector element separately (either in parallel or in series, depending on the hardware implementation).</p>



<h3>Vector (RISC-V V extension)</h3>



<p>Code and comments graciously provided by Bruce Hoult:</p>



<pre><code>saxpy:
    vsetvli   a4, a0, e32,m8, ta,ma // Get vector length in items, max n
    vle32.v   v0, (a1)              // Load from x[]
    vle32.v   v8, (a2)              // Load from y[]
    vfmacc.vf v8, fa0, v0           // y[] += a * x[]
    vse32.v   v8, (a3)              // Store to z[]
    sub       a0, a0, a4            // Decrement item count
    sh2add    a1, a4, a1            // Increment x pointer
    sh2add    a2, a4, a2            // Increment y pointer
    sh2add    a3, a4, a3            // Increment z pointer 
    bnez      a0, saxpy
    ret</code></pre>



<p>The vector length agnostic <a rel="noreferrer noopener" href="https://github.com/riscv/riscv-v-spec" target="_blank">RISC-V vector ISA</a> enables more efficient code and a much smaller code footprint than packed SIMD, just like MRISC32. RISC-V also has a fused multiply-add instruction (VFMACC) that further shortens the code (FMA is planned to be added to the MRISC32 ISA in the future).</p>



<p>A few notes about the use of VSETVLI (set vector length) in the example:</p>



<ul><li><strong>e32,m8</strong> means 32 bit data items, use 8 vector registers at a time e.g. v0-v7, v8-v15 effectively hardware unrolling by 8x and processing e.g. 32 items at a time with 128 bit vector registers. The last iteration can process anywhere from 1 to 32 items (or 0 if n is 0).</li><li><strong>ta,ma</strong> means we don’t care how masked-off elements are handled (we aren’t using masking), and don’t care how unused tail elements are handled on the last iteration.</li></ul>



<p>The code actually correctly handles n=0 (empty array), so unless we expect that to be very common it would be silly to handle it specially and slow everything else down by one instruction.</p>



<h3>Predicated SIMD (ARM SVE)</h3>



<pre><code>saxpy:
    mov     x4, xzr                     // Set start index = 0
    dup     z0.s, z0.s[0]               // Convert scalar a to a vector
1:
    whilelo p0.s, x4, x0                // Set predicate [index, n)
    ld1w    z1.s, p0/z, [x1, x4, lsl 2] // Load x[]        (predicated)
    ld1w    z2.s, p0/z, [x2, x4, lsl 2] // Load y[]        (predicated)
    fmla    z2.s, p0/m, z0.s, z1.s      // y[] += a * x[]  (predicated)
    st1w    z2.s, p0,   [x3, x4, lsl 2] // Store z[]       (predicated)
    incw    x4                          // Increment start index
    b.first 1b                          // Loop if first bit of p0 is set
    ret</code></pre>



<p>As can be seen, a SIMD ISA with proper predication/masking support can easily do tail handling in hardware, and thus the code is very similar to that of a vector processor. The key is the use of a predication register (p0), which is initialized with a binary true/false mask using the WHILELO instruction, and later used for all the vector operations to mask out vector elements that should not be part of the current iteration (effectively only happens in the last iteration, which takes care of the tail).</p>



<p>Also note how the code is register width agnostic (WHILELO and INCW handle that for you).</p>



<h3>Virtual Vector Method (My 66000)</h3>



<pre><code>saxpy:
    beq0    r1,1f         ; Nothing to do?
    mov     r8,#0         ; Loop counter = 0
    vec     r9,{}         ; Start vector loop
    lduw    r6,[r3+r8&lt;&lt;2] ; Load x[]
    lduw    r7,[r4+r8&lt;&lt;2] ; Load y[]
    fmacf   r6,r6,r2,r7   ; x[] * a + y[]
    stw     r6,[r5+r8&lt;&lt;2] ; Store z[]
    loop    ne,r8,r1,#1   ; Increment counter and loop
1:
    ret</code></pre>



<p>The Virtual Vector Method (VVM) is a novel technique invented by Mitch Alsup, and it allows vectorization without a vector register file. As you can see in this example only scalar instructions and references to scalar register names (“r<em>*</em>“) are used. The key players here are the VEC and LOOP instructions that turn the scalar loop into a vector loop.</p>



<p>Essentially the VEC instruction marks the top of the vectorized loop (r9 stores the address of the loop start, which is implicitly used by the LOOP instruction later). All instructions between VEC and LOOP are decoded and analyzed once and are then performed at the capabilities of the hardware. In this case most register identifiers (r1, r3, r4, r5, r6, r7, r8) are used as virtual vector registers, whereas r2 is used as a scalar register. The LOOP instruction increments the counter by 1, compares it to r1, and repeats the loop as long as the condition, not equal (“ne”), is met.</p>



<h2>Further reading</h2>



<p>Also see: <a rel="noreferrer noopener" href="https://www.sigarch.org/simd-instructions-considered-harmful/" target="_blank">SIMD considered harmful</a> (D. Patterson, A. Waterman, 2017)</p>
			</div><!-- .entry-content -->

	<!-- .entry-footer -->
	
<!-- #comments -->

</article></div>
  </body>
</html>
