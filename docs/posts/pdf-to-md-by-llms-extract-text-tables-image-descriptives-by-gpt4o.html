<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/yigitkonur/swift-ocr-llm-powered-pdf-to-markdown">Original</a>
    <h1>Show HN: PDF to MD by LLMs â€“ Extract Text/Tables/Image Descriptives by GPT4o</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">

<ul dir="auto">
<li><strong>Flexible Input Options</strong>: Accepts PDF files via direct upload or by specifying a URL.</li>
<li><strong>Advanced OCR Processing</strong>: Utilizes OpenAI&#39;s GPT-4 Turbo with Vision model for accurate text extraction.</li>
<li><strong>Performance Optimizations</strong>:
<ul dir="auto">
<li><strong>Parallel PDF Conversion</strong>: Converts PDF pages to images concurrently using multiprocessing.</li>
<li><strong>Batch Processing</strong>: Processes multiple images in batches to maximize throughput.</li>
<li><strong>Retry Mechanism with Exponential Backoff</strong>: Ensures resilience against transient failures and API rate limits.</li>
</ul>
</li>
<li><strong>Structured Output</strong>: Extracted text is formatted using Markdown for readability and consistency.</li>
<li><strong>Robust Error Handling</strong>: Comprehensive logging and exception handling for reliable operations.</li>
<li><strong>Scalable Architecture</strong>: Asynchronous processing enables handling multiple requests efficiently.</li>
</ul>

<details open="">
  <summary>
    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true">
    <path d="M16 3.75v8.5a.75.75 0 0 1-1.136.643L11 10.575v.675A1.75 1.75 0 0 1 9.25 13h-7.5A1.75 1.75 0 0 1 0 11.25v-6.5C0 3.784.784 3 1.75 3h7.5c.966 0 1.75.784 1.75 1.75v.675l3.864-2.318A.75.75 0 0 1 16 3.75Zm-6.5 1a.25.25 0 0 0-.25-.25h-7.5a.25.25 0 0 0-.25.25v6.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-6.5ZM11 8.825l3.5 2.1v-5.85l-3.5 2.1Z"></path>
</svg>
    <span aria-label="Video description video.mp4">video.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/9989650/369657683-6b39f3ea-248e-4c29-ac2e-b57de64d5d65.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjcwMjIyMTEsIm5iZiI6MTcyNzAyMTkxMSwicGF0aCI6Ii85OTg5NjUwLzM2OTY1NzY4My02YjM5ZjNlYS0yNDhlLTRjMjktYWMyZS1iNTdkZTY0ZDVkNjUubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDkyMiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA5MjJUMTYxODMxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9YmRlZDI0M2JhNDcwZmJiYjdlMmNkNTBmMmZhMzJjMzEwMTY2MTVkMmE2OGY5ZTA3NTkxY2ZhNzY1YTMxOGFkNyZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.EsjuYS4XJGBBqTMHqF45UuDPH-Uk00stsd-Z0u_wQJc" data-canonical-src="https://private-user-images.githubusercontent.com/9989650/369657683-6b39f3ea-248e-4c29-ac2e-b57de64d5d65.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MjcwMjIyMTEsIm5iZiI6MTcyNzAyMTkxMSwicGF0aCI6Ii85OTg5NjUwLzM2OTY1NzY4My02YjM5ZjNlYS0yNDhlLTRjMjktYWMyZS1iNTdkZTY0ZDVkNjUubXA0P1gtQW16LUFsZ29yaXRobT1BV1M0LUhNQUMtU0hBMjU2JlgtQW16LUNyZWRlbnRpYWw9QUtJQVZDT0RZTFNBNTNQUUs0WkElMkYyMDI0MDkyMiUyRnVzLWVhc3QtMSUyRnMzJTJGYXdzNF9yZXF1ZXN0JlgtQW16LURhdGU9MjAyNDA5MjJUMTYxODMxWiZYLUFtei1FeHBpcmVzPTMwMCZYLUFtei1TaWduYXR1cmU9YmRlZDI0M2JhNDcwZmJiYjdlMmNkNTBmMmZhMzJjMzEwMTY2MTVkMmE2OGY5ZTA3NTkxY2ZhNzY1YTMxOGFkNyZYLUFtei1TaWduZWRIZWFkZXJzPWhvc3QifQ.EsjuYS4XJGBBqTMHqF45UuDPH-Uk00stsd-Z0u_wQJc" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto"><em>Demo video showcasing the conversion of NASA&#39;s Apollo 17 flight documents, which include unorganized, horizontally and vertically oriented pages, into well-structured Markdown format without any issues.</em></p>
<p dir="auto">Here&#39;s a single, comprehensive section on cost comparison for your README:</p>
<div dir="auto"><h2 tabindex="-1" dir="auto">Cost Comparison and Value Proposition</h2><a id="user-content-cost-comparison-and-value-proposition" aria-label="Permalink: Cost Comparison and Value Proposition" href="#cost-comparison-and-value-proposition"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Our solution offers an optimal balance of affordability, accuracy, and advanced features:</p>

<ul dir="auto">
<li>Average token usage per image: ~1200</li>
<li>Total tokens per page (including prompt): ~1500</li>
<li>[GPT4O] Input token cost: $5 per million tokens</li>
<li>[GPT4O] Output token cost: $15 per million tokens</li>
</ul>
<p dir="auto">For 1000 documents:</p>
<ul dir="auto">
<li>Estimated total cost: $15</li>
</ul>
<div dir="auto"><h4 tabindex="-1" dir="auto">Cost Optimization Options</h4><a id="user-content-cost-optimization-options" aria-label="Permalink: Cost Optimization Options" href="#cost-optimization-options"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ol dir="auto">
<li>Utilizing GPT4 mini: Reduces cost to ~$8 per 1000 documents</li>
<li>Implementing batch API: Further reduces cost to ~$4 per 1000 documents</li>
</ol>

<p dir="auto">This solution is significantly more affordable than alternatives:</p>
<ul dir="auto">
<li>Our cost: $15 per 1000 documents</li>
<li>CloudConvert: ~$30 per 1000 documents (PDFTron mode, 4 credits required)</li>
</ul>
<p dir="auto">While cost-effectiveness is a major advantage, our solution also provides:</p>
<ul dir="auto">
<li>Superior accuracy and consistency</li>
<li>Precise table generation</li>
<li>Output in easily editable markdown format</li>
</ul>
<p dir="auto">This combination of affordability and advanced features makes solution stand out in the document processing market. It&#39;s not just about being cheaper; it&#39;s about providing excellent value through reliability, flexibility, and high-quality output.</p>


<ul dir="auto">
<li>Python 3.8+</li>
<li><a href="https://git-scm.com/" rel="nofollow">Git</a></li>
<li><a href="https://virtualenv.pypa.io/en/latest/" rel="nofollow">Virtualenv</a> (optional but recommended)</li>
</ul>

<ol dir="auto">
<li>
<p dir="auto"><strong>Clone the Repository</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="git clone https://github.com/yourusername/llm-openai-ocr.git
cd llm-openai-ocr"><pre>git clone https://github.com/yourusername/llm-openai-ocr.git
<span>cd</span> llm-openai-ocr</pre></div>
</li>
<li>
<p dir="auto"><strong>Create a Virtual Environment</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="python3 -m venv venv
source venv/bin/activate  # On Windows: venv\Scripts\activate"><pre>python3 -m venv venv
<span>source</span> venv/bin/activate  <span><span>#</span> On Windows: venv\Scripts\activate</span></pre></div>
</li>
<li>
<p dir="auto"><strong>Install Dependencies</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install -r requirements.txt"><pre>pip install -r requirements.txt</pre></div>
</li>
<li>
<p dir="auto"><strong>Configure Environment Variables</strong></p>
<p dir="auto">Create a <code>.env</code> file in the root directory and add the following variables:</p>
<div dir="auto" data-snippet-clipboard-copy-content="OPENAI_API_KEY=your_openai_api_key
AZURE_OPENAI_ENDPOINT=your_azure_openai_endpoint
OPENAI_DEPLOYMENT_ID=your_openai_deployment_id
OPENAI_API_VERSION=your_openai_api_version  # Default is &#34;gpt-4o&#34;
BATCH_SIZE=10  # Optional: Default is 1
MAX_CONCURRENT_OCR_REQUESTS=5  # Optional: Default is 5
MAX_CONCURRENT_PDF_CONVERSION=4  # Optional: Default is 4"><pre><span>OPENAI_API_KEY</span><span>=</span><span>your_openai_api_key</span>
<span>AZURE_OPENAI_ENDPOINT</span><span>=</span><span>your_azure_openai_endpoint</span>
<span>OPENAI_DEPLOYMENT_ID</span><span>=</span><span>your_openai_deployment_id</span>
<span>OPENAI_API_VERSION</span><span>=</span><span>your_openai_api_version<span>  <span>#</span> Default is &#34;gpt-4o&#34;</span></span>
<span>BATCH_SIZE</span><span>=</span><span>10<span>  <span>#</span> Optional: Default is 1</span></span>
<span>MAX_CONCURRENT_OCR_REQUESTS</span><span>=</span><span>5<span>  <span>#</span> Optional: Default is 5</span></span>
<span>MAX_CONCURRENT_PDF_CONVERSION</span><span>=</span><span>4<span>  <span>#</span> Optional: Default is 4</span></span></pre></div>
<blockquote>
<p dir="auto"><strong>Note:</strong> Replace <code>your_openai_api_key</code>, <code>your_azure_openai_endpoint</code>, and <code>your_openai_deployment_id</code> with your actual OpenAI credentials.</p>
</blockquote>
</li>
<li>
<p dir="auto"><strong>Run the Application</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="uvicorn main:app --reload"><pre>uvicorn main:app --reload</pre></div>
<p dir="auto">The API will be available at <code>http://127.0.0.1:8000</code>.</p>
</li>
</ol>


<p dir="auto"><strong>POST</strong> <code>/ocr</code></p>

<ul dir="auto">
<li><strong>file</strong>: (Optional) Upload a PDF file.</li>
<li><strong>ocr_request.url</strong>: (Optional) URL of the PDF to process.</li>
</ul>
<p dir="auto"><em>You must provide either a file or a URL, not both.</em></p>

<p dir="auto"><strong>Uploading a PDF File:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="curl -X POST &#34;http://127.0.0.1:8000/ocr&#34; -F &#34;file=@/path/to/your/document.pdf&#34;"><pre>curl -X POST <span><span>&#34;</span>http://127.0.0.1:8000/ocr<span>&#34;</span></span> -F <span><span>&#34;</span>file=@/path/to/your/document.pdf<span>&#34;</span></span></pre></div>
<p dir="auto"><strong>Providing a PDF URL:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="curl -X POST &#34;http://127.0.0.1:8000/ocr&#34; -F &#34;ocr_request={\&#34;url\&#34;: \&#34;https://example.com/document.pdf\&#34;}&#34; -H &#34;Content-Type: application/json&#34;"><pre>curl -X POST <span><span>&#34;</span>http://127.0.0.1:8000/ocr<span>&#34;</span></span> -F <span><span>&#34;</span>ocr_request={<span>\&#34;</span>url<span>\&#34;</span>: <span>\&#34;</span>https://example.com/document.pdf<span>\&#34;</span>}<span>&#34;</span></span> -H <span><span>&#34;</span>Content-Type: application/json<span>&#34;</span></span></pre></div>

<ul dir="auto">
<li>
<p dir="auto"><strong>200 OK</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="{
  &#34;text&#34;: &#34;Extracted and formatted text from the PDF.&#34;
}"><pre>{
  <span>&#34;text&#34;</span>: <span><span>&#34;</span>Extracted and formatted text from the PDF.<span>&#34;</span></span>
}</pre></div>
</li>
<li>
<p dir="auto"><strong>Error Responses</strong></p>
<ul dir="auto">
<li><code>400 Bad Request</code>: Invalid input parameters.</li>
<li><code>422 Unprocessable Entity</code>: Validation errors.</li>
<li><code>500 Internal Server Error</code>: Processing errors.</li>
</ul>
</li>
</ul>

<p dir="auto">All configurations are managed via environment variables. Ensure you have a <code>.env</code> file set up with the necessary variables as described in the <a href="#installation">Installation</a> section.</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">Key Configuration Variables</h3><a id="user-content-key-configuration-variables" aria-label="Permalink: Key Configuration Variables" href="#key-configuration-variables"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ul dir="auto">
<li><strong>OPENAI_API_KEY</strong>: Your OpenAI API key.</li>
<li><strong>AZURE_OPENAI_ENDPOINT</strong>: The endpoint for Azure OpenAI service.</li>
<li><strong>OPENAI_DEPLOYMENT_ID</strong>: Deployment ID for the OpenAI model.</li>
<li><strong>OPENAI_API_VERSION</strong>: API version for OpenAI (default: &#34;gpt-4o&#34;).</li>
<li><strong>BATCH_SIZE</strong>: Number of images to process per OCR request (default: 1).</li>
<li><strong>MAX_CONCURRENT_OCR_REQUESTS</strong>: Maximum number of concurrent OCR requests (default: 5).</li>
<li><strong>MAX_CONCURRENT_PDF_CONVERSION</strong>: Maximum number of concurrent PDF page conversions (default: 4).</li>
</ul>
</article></div></div>
  </body>
</html>
