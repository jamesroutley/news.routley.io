<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://composio.dev/blog/notes-on-new-deepseek-v3/">Original</a>
    <h1>Notes on the New Deepseek v3</h1>
    
    <div id="readability-page-1" class="page"><div id="content">

			<!-- 1.4 uicore_before_content -->
<div id="primary">

	        <main id="main">
			<div>


                				<div>

                    <article id="post-9230">
                            
                            <div>
                            
<p>Deepseek released their flagship model, <a href="https://api-docs.deepseek.com/news/news1226">v3</a>, a 607B mixture-of-experts model with 37B active parameters. Currently, it is the best open-source model, beating Llama 3.1 405b, Qwen, and Mistral. It is on par with <a href="https://composio.dev/blog/gemini-2-0-flash-vs-openai-o1-and-claude-3-5-sonnet/">OpenAI GPT-4o and Claude 3.5 Sonnet</a> from the benchmarks. The first model performs on par and better at some tasks than the big closed models.</p>



<h2 id="h-tl-dr">TL;DR</h2>



<ul>
<li>• Deepseek achieved remarkable performance while keeping training costs surprisingly low.</li>



<li>• The model offers exceptional value, outperforming open-source and closed alternatives at its price point.</li>



<li>• Their success stems from breakthrough engineering: using MoE architecture, implementing FP8 mixed precision training, and developing a custom HAI-LLM framework.</li>



<li>• Deepseek excels at reasoning and math, surpassing GPT-4 and Claude 3.5 Sonnet.</li>



<li>• For writing and coding tasks, Claude 3.5 Sonnet maintains a slight lead.</li>
</ul>







<p>Deepseek pre-trained this model on 14.8 trillion high-quality data, taking 2,788,000 GPU hours on the Nvidia h800s cluster, costing around only $6 million; in comparison, the Llama 403b was trained on 11x of that, taking 30,840,000 GPU hours, also on 15 trillion tokens. Check the <a href="https://github.com/deepseek-ai/DeepSeek-V3">full report here</a>.</p>



<p><em>For context, the US banned Chinese companies from procuring NVIDIA GPUs.</em></p>



<p>Karpathy Says</p>



<figure><img decoding="async" width="1024" height="921" src="https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-27-at-3.44.33-PM-1024x921.png" alt="Karpathy&#39;s response to Deepseek v3 launch" srcset="https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-27-at-3.44.33-PM-1024x921.png 1024w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-27-at-3.44.33-PM-300x270.png 300w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-27-at-3.44.33-PM-768x691.png 768w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-27-at-3.44.33-PM-650x585.png 650w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-27-at-3.44.33-PM.png 1196w" sizes="(max-width: 1024px) 100vw, 1024px"/></figure>



<p>Tim Dettmers, author of the famous paper <a href="https://scholar.google.com/citations?user=lHI3w5kAAAAJ&amp;view_op=view_citation&amp;citation_for_view=lHI3w5kAAAAJ:kNdYIx-mwKoC">QLoRA</a>, praises the sheer engineering prowess of Deepseek.</p>



<figure><img loading="lazy" decoding="async" width="1024" height="211" src="https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-27-at-3.46.20-PM-1024x211.png" alt="Tim Dettmers&#39;s response to Deepseek v3 launch" srcset="https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-27-at-3.46.20-PM-1024x211.png 1024w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-27-at-3.46.20-PM-300x62.png 300w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-27-at-3.46.20-PM-768x158.png 768w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-27-at-3.46.20-PM-650x134.png 650w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-27-at-3.46.20-PM.png 1196w" sizes="(max-width: 1024px) 100vw, 1024px"/></figure>



<h2 id="h-cheapest-most-capable-model">Cheapest, most capable model</h2>



<p>Deepseek v3 is also the cheapest model right now, considering its capabilities.</p>



<figure><img loading="lazy" decoding="async" width="1024" height="542" src="https://composio.dev/wp-content/uploads/2024/12/deepseek-price-comparison-1024x542.jpeg" alt="Deepseek price to performance ratio" srcset="https://composio.dev/wp-content/uploads/2024/12/deepseek-price-comparison-1024x542.jpeg 1024w, https://composio.dev/wp-content/uploads/2024/12/deepseek-price-comparison-300x159.jpeg 300w, https://composio.dev/wp-content/uploads/2024/12/deepseek-price-comparison-768x407.jpeg 768w, https://composio.dev/wp-content/uploads/2024/12/deepseek-price-comparison-650x344.jpeg 650w, https://composio.dev/wp-content/uploads/2024/12/deepseek-price-comparison.jpeg 1280w" sizes="(max-width: 1024px) 100vw, 1024px"/></figure>



<p>Emad Mostaque, founder of Stability AI, remarks</p>



<figure><img loading="lazy" decoding="async" width="1024" height="281" src="https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-27-at-4.03.16-PM-1024x281.png" alt="Emad Mostaque&#39;s&#39;s response to Deepseek v3 launch" srcset="https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-27-at-4.03.16-PM-1024x281.png 1024w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-27-at-4.03.16-PM-300x82.png 300w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-27-at-4.03.16-PM-768x210.png 768w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-27-at-4.03.16-PM-650x178.png 650w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-27-at-4.03.16-PM.png 1190w" sizes="(max-width: 1024px) 100vw, 1024px"/></figure>



<p>The API pricing is as follows.</p>



<figure><img loading="lazy" decoding="async" width="1024" height="477" src="https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-27-at-5.01.02-PM-1024x477.png" alt="Deepseek pricing list" srcset="https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-27-at-5.01.02-PM-1024x477.png 1024w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-27-at-5.01.02-PM-300x140.png 300w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-27-at-5.01.02-PM-768x358.png 768w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-27-at-5.01.02-PM-650x303.png 650w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-27-at-5.01.02-PM.png 1206w" sizes="(max-width: 1024px) 100vw, 1024px"/></figure>



<p>This unlocks a whole new world of possibilities—a GPT-4o and Claude 3.5 Sonnet-level model at a fraction of the cost is the ultimate holiday treat every AI developer has on their wishlist.</p>



<h2 id="h-summary-of-how-deepseek-v3-was-so-efficient-at-training-frontier-model">Summary of how Deepseek v3 was so efficient at training frontier model</h2>



<p>1. <strong>Model Architecture</strong></p>



<ul>
<li>• They use a Mixture-of-Experts (MoE) architecture, where only 37B parameters are activated for each token out of the total 671B. This sparse activation significantly reduces compute requirements compared to dense models.</li>



<li>• They employ Multi-head Latent Attention (MLA), which compresses the Key-Value cache, reducing memory usage and enabling more efficient training.</li>
</ul>



<p>2. <strong>FP8 Mixed Precision Training:</strong></p>



<ul>
<li>• They implemented an FP8 mixed precision training framework, which reduces memory usage and accelerates training compared to higher precision formats.</li>



<li>• Reduced memory footprint by up to 50% compared to traditional FP16/FP32 formats</li>



<li>• They use fine-grained quantization strategies and increased accumulation precision to maintain accuracy.</li>
</ul>



<p>3. <strong>Load Balancing Strategy</strong></p>



<ul>
<li>• They pioneered an auxiliary-loss-free strategy for load balancing in the MoE architecture, which improves performance without the drawbacks of traditional auxiliary loss methods.</li>
</ul>



<p>4. <strong>Training Framework</strong></p>



<ul>
<li>• They developed a custom training framework called HAI-LLM with several optimizations:
<ul>
<li>• DualPipe algorithm for efficient pipeline parallelism, reducing pipeline bubbles and overlapping computation and communication.</li>



<li>• Efficient cross-node all-to-all communication kernels to fully utilize network bandwidth.</li>



<li>• Careful memory optimizations to avoid using costly tensor parallelism.</li>
</ul>
</li>
</ul>



<p><em>Source: Perplexity</em> | <a href="https://huggingface.co/papers/2412.19437">Deepseek</a></p>



<p>With all these advancements, Deepseek was able to pull this insane breakthrough of training such a large model under only ~$6 Million.</p>



<h2 id="h-chain-of-thought-with-r1">Chain of thought with r1</h2>



<p>Moreover, Deepseek has added a new deep think feature, incorporating the chain-of-thought (CoT) of Deepseek’s R1 series of models into v3 LLM.</p>



<blockquote>
<p><strong>Post-Training: Knowledge Distillation from DeepSeek-R1</strong></p>



<ul>
<li>• We introduce an innovative methodology to distill reasoning capabilities from the long-Chain-of-Thought (CoT) model, specifically from one of the DeepSeek R1 series models, into standard LLMs, particularly DeepSeek-V3. Our pipeline elegantly incorporates the verification and reflection patterns of R1 into DeepSeek-V3 and notably improves its reasoning performance. Meanwhile, we also maintain a control over the output style and length of DeepSeek-V3.</li>
</ul>
</blockquote>



<p>You can enable this feature in the Deepseek chat. Though it’s not as good as o1, it still improves the reasoning abilities of the LLM to some extent.</p>



<h2 id="h-deepseek-v3-vs-openai-gpt-4o-vs-claude-3-5-sonnet">Deepseek v3 vs OpenAI GPT-4o vs Claude 3.5 Sonnet</h2>



<p>Deepseek has insane scores across major benchmarks, making every AI enthusiast go gaga over it. But how does it compare to real-life GPT-4o and Claude 3.5 Sonnet? Is the hype justified, or is it similar to other hype releases?</p>



<p>To better understand how they compare, I tested all three models using my set of benchmark questions, focusing on four key areas: reasoning, math, coding, and creative writing.</p>



<p>To set the context straight, GPT-4o and Claude 3.5 Sonnet failed all the reasoning and math questions, while only Gemini 2.0 1206 and o1 managed to get them right. So, I do not expect the Deepseek v3 to get all the answers; whatever we get is an improvement.</p>



<p>So, let’s dive in.</p>



<h2 id="h-reasoning">Reasoning</h2>



<p>Reasoning is one of the most critical aspects of an intelligent system, and so far, in my tests, o1 has been the top performer, followed by Gemini 2.0 1206. So, let’s see how Deepseek performs.</p>



<p>Start with this initial question.</p>



<h3 id="h-1-finding-the-fourth-word-of-the-response">1. Finding the fourth word of the response</h3>



<p><strong>Prompt: What is the fourth word of the sentence of your response to this question?</strong></p>



<p>This was the response from the Deepseek v3.</p>



<figure><img loading="lazy" decoding="async" width="1024" height="243" src="https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-30-at-4.29.19-PM-1024x243.png" alt="Deepseek v3 answering the puzzle" srcset="https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-30-at-4.29.19-PM-1024x243.png 1024w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-30-at-4.29.19-PM-300x71.png 300w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-30-at-4.29.19-PM-768x182.png 768w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-30-at-4.29.19-PM-1536x364.png 1536w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-30-at-4.29.19-PM-650x154.png 650w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-30-at-4.29.19-PM.png 1646w" sizes="(max-width: 1024px) 100vw, 1024px"/></figure>



<p>Response with Deepthink CoT enabled.</p>



<figure><img loading="lazy" decoding="async" width="1024" height="390" src="https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-30-at-4.31.53-PM-1024x390.png" alt="Deepseek v3 with deepthink enabled" srcset="https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-30-at-4.31.53-PM-1024x390.png 1024w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-30-at-4.31.53-PM-300x114.png 300w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-30-at-4.31.53-PM-768x293.png 768w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-30-at-4.31.53-PM-1536x585.png 1536w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-30-at-4.31.53-PM-650x248.png 650w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-30-at-4.31.53-PM.png 1606w" sizes="(max-width: 1024px) 100vw, 1024px"/></figure>



<p>The model with deep thinking boosted reasoning ability to answer the question correctly. The CoT reasoning is working; even if it is not native, there is certainly a boost in performance.</p>



<h3 id="h-2-count-the-number-of-words-in-the-response">2. Count the number of words in the response</h3>



<p><strong>Prompt: Count the number of words in the response to this prompt.</strong></p>



<figure><img loading="lazy" decoding="async" width="1024" height="528" src="https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-30-at-5.04.06-PM-1024x528.png" alt="Deepseek counting the number of words" srcset="https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-30-at-5.04.06-PM-1024x528.png 1024w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-30-at-5.04.06-PM-300x155.png 300w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-30-at-5.04.06-PM-768x396.png 768w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-30-at-5.04.06-PM-1536x792.png 1536w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-30-at-5.04.06-PM-650x335.png 650w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-30-at-5.04.06-PM.png 1626w" sizes="(max-width: 1024px) 100vw, 1024px"/></figure>



<p>It was a miss. But even the GPT-4o and Claude 3.5 Sonnet failed at this.</p>



<h3 id="h-3-how-many-r-in-strawberry">3. How many ‘r’ in Strawberry?</h3>



<p>This is a pretty dumb question, but GPT-4o has never gotten it right. Let’s see if Deepseek v3 does.</p>



<figure><img loading="lazy" decoding="async" width="1024" height="247" src="https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-12.34.15-PM-1024x247.png" alt="" srcset="https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-12.34.15-PM-1024x247.png 1024w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-12.34.15-PM-300x73.png 300w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-12.34.15-PM-768x186.png 768w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-12.34.15-PM-1536x371.png 1536w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-12.34.15-PM-650x157.png 650w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-12.34.15-PM.png 1622w" sizes="(max-width: 1024px) 100vw, 1024px"/></figure>



<p>I would have been disappointed if Deepseek failed at this.</p>



<h3 id="h-4-farmer-and-sheep-problem">4. Farmer and Sheep Problem</h3>



<p><strong>It’s a simple problem that could easily knock any LLM off its feet. Let’s see how the o1-preview fares.</strong></p>



<p><strong>Prompt: A farmer stands with the sheep on one side of the river. A boat can carry only a single person and an animal. How can the farmer get himself and the sheep to the other side of the river with minimum trips?</strong></p>



<p>None of the GPT-4o or Claude 3.5 Sonnets could answer this simple question correctly. Only o1 was able to find the correct answer without any assistance. Let’s see how Deepseek performs.</p>



<figure><img loading="lazy" decoding="async" width="1024" height="539" src="https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-12.46.21-PM-1024x539.png" alt="Deepseek answering farmer sheep problem" srcset="https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-12.46.21-PM-1024x539.png 1024w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-12.46.21-PM-300x158.png 300w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-12.46.21-PM-768x404.png 768w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-12.46.21-PM-1536x808.png 1536w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-12.46.21-PM-650x342.png 650w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-12.46.21-PM.png 1916w" sizes="(max-width: 1024px) 100vw, 1024px"/></figure>



<p>It did all the analysis to arrive at the wrong answer. Let’s see if there is any improvement with Deepthink enabled.</p>



<p>It thought for 30 seconds just to arrive at the same conclusion.</p>



<figure><img loading="lazy" decoding="async" width="1024" height="539" src="https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-12.48.37-PM-1024x539.png" alt="Deepseek answering farmer sheep problem with deepthink enabled" srcset="https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-12.48.37-PM-1024x539.png 1024w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-12.48.37-PM-300x158.png 300w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-12.48.37-PM-768x404.png 768w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-12.48.37-PM-1536x808.png 1536w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-12.48.37-PM-650x342.png 650w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-12.48.37-PM.png 1916w" sizes="(max-width: 1024px) 100vw, 1024px"/></figure>



<h3 id="h-summary-on-reasoning">Summary on reasoning</h3>



<p>This might not be as good as O1 in reasoning, but it definitely feels up there among Sonnet and GPT-4o. Sometimes, it even feels better than both. Again, for the price you get the model, it just beats everyone.</p>



<h2 id="h-mathematics">Mathematics</h2>



<h3 id="h-1-5-11-5-90">1. 5.11-5.90 =?</h3>



<p>It’s a straightforward question but easily stumbles even bigger LLMs.</p>



<figure><img loading="lazy" decoding="async" width="1024" height="275" src="https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-12.25.09-PM-1024x275.png" alt="Deepseek solving 5.11-5.90 =?" srcset="https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-12.25.09-PM-1024x275.png 1024w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-12.25.09-PM-300x80.png 300w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-12.25.09-PM-768x206.png 768w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-12.25.09-PM-1536x412.png 1536w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-12.25.09-PM-650x174.png 650w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-12.25.09-PM.png 1618w" sizes="(max-width: 1024px) 100vw, 1024px"/></figure>



<h3 id="h-2-find-the-possible-4th-vertex-of-a-parallelogram">2. <strong>Find the possible 4th vertex of a parallelogram</strong></h3>



<p><strong>Prompt: If three corners of a parallelogram are (1,1), (4,2), and (1,3), what are all the possible fourth corners?</strong></p>



<p>This is a question from Gilbert Strang’s Linear Algebra. Only o1 and Gemini 2.0 1206 have aced this question from my tests. Both GPT-4o and 3.5 Sonnet can only find a single possible vertex.</p>



<p>Let’s see how Deepseek v3 performs.</p>



<figure><img loading="lazy" decoding="async" width="1024" height="517" src="https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-1.06.19-PM-1024x517.png" alt="Deepseek finding the possible 4th vertex of a parallelogram" srcset="https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-1.06.19-PM-1024x517.png 1024w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-1.06.19-PM-300x151.png 300w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-1.06.19-PM-768x388.png 768w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-1.06.19-PM-1536x775.png 1536w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-1.06.19-PM-650x328.png 650w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-1.06.19-PM.png 1946w" sizes="(max-width: 1024px) 100vw, 1024px"/></figure>



<p>This was awesome. The model is better at mathematics than GPT-4o and Claude 3.5 Sonnet.</p>



<h3 id="h-3-finding-the-sum-of-integers">3. <strong>Finding the sum of integers</strong></h3>



<p>This is a slightly difficult question, but it can cement Deepseek v3 as the best mathematics model among the GPT-40 and Claude 3.5 Sonnet.</p>



<p><strong>Prompt:</strong> <strong>The greatest common divisor of two positive integers less than 100 equals 3. Their least common multiple is twelve times one of the integers. What is the largest possible sum of the two integers?</strong></p>



<p>I enabled the Deepthink feature to give the model more firepower, and it didn’t disappoint.</p>



<figure><img loading="lazy" decoding="async" width="1024" height="517" src="https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-1.20.06-PM-1024x517.png" alt="" srcset="https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-1.20.06-PM-1024x517.png 1024w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-1.20.06-PM-300x151.png 300w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-1.20.06-PM-768x388.png 768w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-1.20.06-PM-1536x775.png 1536w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-1.20.06-PM-650x328.png 650w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-1.20.06-PM.png 1946w" sizes="(max-width: 1024px) 100vw, 1024px"/></figure>



<p>At this point, it is clear that the model is better at math tasks than the other two.</p>



<h3 id="h-summary-of-math-ability">Summary of Math ability</h3>



<p>The benchmark scores weren’t lying. The model is better on math tasks than GPT-4o and Claude 3.5 Sonnet.</p>



<h2 id="h-coding">Coding</h2>



<p>I mostly use this LeetCode “Hard” question for coding, which is relatively new and less likely to be in the LLM training dataset.</p>



<p>Th<strong>e “</strong><a href="https://leetcode.com/problems/power-of-heroes/description/">Super Heroes</a><strong>”</strong> problem is a relatively tricky dynamic programming problem that tests the model used in recent competitive coding competitions.</p>



<p>The question:</p>



<div data-code-block-pro-font-family="Code-Pro-JetBrains-Mono"><pre tabindex="0"><code><span><span>You are given a 0-indexed integer array nums representing the strength of some heroes. The power of a group of heroes is defined as follows:</span></span>
<span><span></span></span>
<span><span>Let i0, i1, ... ,ik be the indices of the heroes in a group. Then, the power of this group is max(nums[i0], nums[i1], ... ,nums[ik])2 * min(nums[i0], nums[i1], ... ,nums[ik]).</span></span>
<span><span>Return the sum of the power of all non-empty groups of heroes possible. Since the sum could be very large, return it modulo 109 + 7.</span></span>
<span><span></span></span>
<span><span>Example 1:</span></span>
<span><span></span></span>
<span><span>Input: nums = [2,1,4]</span></span>
<span><span>Output: 141</span></span>
<span><span>Explanation: </span></span>
<span><span>1st group: [2] has power = 22 * 2 = 8.</span></span>
<span><span>2nd group: [1] has power = 12 * 1 = 1. </span></span>
<span><span>3rd group: [4] has power = 42 * 4 = 64. </span></span>
<span><span>4th group: [2,1] has power = 22 * 1 = 4. </span></span>
<span><span>5th group: [2,4] has power = 42 * 2 = 32. </span></span>
<span><span>6th group: [1,4] has power = 42 * 1 = 16. </span></span>
<span><span>7th group: [2,1,4] has power = 42 * 1 = 16. </span></span>
<span><span>The sum of powers of all groups is 8 + 1 + 64 + 4 + 32 + 16 + 16 = 141.</span></span>
<span><span></span></span>
<span><span>Example 2:</span></span>
<span><span></span></span>
<span><span>Input: nums = [1,1,1]</span></span>
<span><span>Output: 7</span></span>
<span><span>Explanation: A total of 7 groups are possible, and the power of each group will be 1. Therefore, the sum of the powers of all groups is 7.</span></span>
<span><span> </span></span>
<span><span></span></span>
<span><span>Constraints:</span></span>
<span><span></span></span>
<span><span>1 &lt;= nums.length &lt;= 105</span></span>
<span><span>1 &lt;= nums[i] &lt;= 109</span></span>
<span><span></span></span></code></pre></div>



<p>Something really interesting happened with this question. The first time around, the model completely bombed—it couldn’t pass a single test case. But when I asked it to try again, it came back with this perfect solution that beat every other submission!</p>



<p>I kept testing this repeatedly, and the same thing happened every time. Is the model this clever, or has it just seen this question before in its training? I’m betting it’s probably the latter.</p>



<p>The initial answer from the Deepseek v3</p>



<div data-code-block-pro-font-family="Code-Pro-JetBrains-Mono"><pre tabindex="0"><code><span><span>class</span><span> </span><span>Solution</span><span>:</span></span>
<span><span>    </span><span>def</span><span> </span><span>sumOfPower</span><span>(</span><span>self</span><span>, </span><span>nums</span><span>: List[</span><span>int</span><span>]) -&gt; </span><span>int</span><span>:</span></span>
<span><span>        nums.sort()</span></span>
<span><span>        n = </span><span>len</span><span>(nums)</span></span>
<span><span>        total = </span><span>0</span></span>
<span><span>    </span></span>
<span><span>         </span><span># Precompute the powers of each element</span></span>
<span><span>        power = [x * x % MOD </span><span>for</span><span> x </span><span>in</span><span> nums]</span></span>
<span><span>    </span></span>
<span><span>        </span><span># Precompute the prefix sum of powers</span></span>
<span><span>        prefix_power = [</span><span>0</span><span>] * n</span></span>
<span><span>        prefix_power[</span><span>0</span><span>] = power[</span><span>0</span><span>]</span></span>
<span><span>        </span><span>for</span><span> i </span><span>in</span><span> </span><span>range</span><span>(</span><span>1</span><span>, n):</span></span>
<span><span>            prefix_power[i] = (prefix_power[i-</span><span>1</span><span>] + power[i]) % MOD</span></span>
<span><span>    </span></span>
<span><span>        </span><span>for</span><span> i </span><span>in</span><span> </span><span>range</span><span>(n):</span></span>
<span><span>         </span><span># Number of subsets where nums[i] is the minimum</span></span>
<span><span>        </span><span># is 2^(n - i - 1)</span></span>
<span><span>            num_subsets = </span><span>pow</span><span>(</span><span>2</span><span>, n - i - </span><span>1</span><span>, MOD)</span></span>
<span><span>        </span></span>
<span><span>        </span><span># The maximum can be any element from i to n-1</span></span>
<span><span>        </span><span># The sum of (nums[j]^2 * nums[i]) for j from i to n-1</span></span>
<span><span>        </span><span># is nums[i] * (prefix_power[n-1] - prefix_power[i-1]) if i &gt; 0 else nums[i] * prefix_power[n-1]</span></span>
<span><span>            </span><span>if</span><span> i == </span><span>0</span><span>:</span></span>
<span><span>                sum_power = prefix_power[n-</span><span>1</span><span>]</span></span>
<span><span>            </span><span>else</span><span>:</span></span>
<span><span>                sum_power = (prefix_power[n-</span><span>1</span><span>] - prefix_power[i-</span><span>1</span><span>]) % MOD</span></span>
<span><span>        </span></span>
<span><span>            contribution = (nums[i] * sum_power) % MOD</span></span>
<span><span>            contribution = (contribution * num_subsets) % MOD</span></span>
<span><span>            total = (total + contribution) % MOD</span></span>
<span><span>        </span><span>return</span><span> total</span></span>
<span></span></code></pre></div>



<p>Revised answer</p>



<div data-code-block-pro-font-family="Code-Pro-JetBrains-Mono"><pre tabindex="0"><code><span><span>class</span><span> </span><span>Solution</span><span>:</span></span>
<span><span>    </span><span>def</span><span> </span><span>sumOfPower</span><span>(</span><span>self</span><span>, </span><span>nums</span><span>: List[</span><span>int</span><span>]) -&gt; </span><span>int</span><span>:</span></span>
<span><span>        MOD = </span><span>10</span><span>**</span><span>9</span><span> + </span><span>7</span></span>
<span><span>        nums.sort()  </span><span># Sort the array to make it easier to calculate min and max</span></span>
<span><span>        total = </span><span>0</span></span>
<span><span>        prev_sum = </span><span>0</span><span>  </span><span># To store the sum of previous min values</span></span>
<span><span>        </span></span>
<span><span>        </span><span>for</span><span> i, num </span><span>in</span><span> </span><span>enumerate</span><span>(nums):</span></span>
<span><span>            </span><span># Current max is `num`, and min can be any of the previous elements or `num` itself</span></span>
<span><span>            </span><span># The contribution of `num` as max is num^2 * (sum of all possible min values)</span></span>
<span><span>            </span><span># The sum of min values for groups ending at `num` is (prev_sum + num)</span></span>
<span><span>            total = (total + num * num * (prev_sum + num)) % MOD</span></span>
<span><span>            </span><span># Update prev_sum for the next iteration</span></span>
<span><span>            prev_sum = (prev_sum * </span><span>2</span><span> + num) % MOD</span></span>
<span><span>        </span></span>
<span><span>        </span><span>return</span><span> total</span></span>
<span></span></code></pre></div>



<figure><img loading="lazy" decoding="async" width="1024" height="841" src="https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-2.10.54-PM-1024x841.png" alt="Deepseek solving LeetCode Hard" srcset="https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-2.10.54-PM-1024x841.png 1024w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-2.10.54-PM-300x246.png 300w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-2.10.54-PM-768x631.png 768w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-2.10.54-PM-1536x1262.png 1536w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-2.10.54-PM-650x534.png 650w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-2.10.54-PM.png 1546w" sizes="(max-width: 1024px) 100vw, 1024px"/></figure>



<h3 id="h-summary-of-coding-ability">Summary of coding ability</h3>



<p>From what I’ve seen, this model comes really close to GPT-4’s coding abilities, though Claude 3.5 Sonnet still has a slight edge over Deepseek v3. But here’s the thing – Deepseek’s pricing makes it incredibly compelling. Given the performance-to-cost ratio, it’s your best bet if you’re looking to deploy an LLM for user-facing applications.</p>



<h2 id="h-creative-writing">Creative Writing</h2>



<p>This is somewhat subjective and depends on your tone and personality preference. GPT-4o always adopts a rather corporate tone and tries hard to please you. In that regard, I always found Sonnet to be more humane with its own set of views and opinions.</p>



<p>So, what about Deepseek v3? In my brief testing, I found Deepseek’s output to be scarily similar to that of GPT-4o. The response pattern, paragraph structuring, and even the words at a time are too identical to GPT-4o.</p>



<p>For example, I asked both to improve a paragraph, and the outputs were almost identical.</p>



<p>From GPT-4o</p>



<figure><img loading="lazy" decoding="async" width="1024" height="478" src="https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-2.41.47-PM-1024x478.png" alt="OpenAI response to rephrasing a paragraph" srcset="https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-2.41.47-PM-1024x478.png 1024w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-2.41.47-PM-300x140.png 300w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-2.41.47-PM-768x359.png 768w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-2.41.47-PM-1536x718.png 1536w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-2.41.47-PM-650x304.png 650w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-2.41.47-PM.png 1888w" sizes="(max-width: 1024px) 100vw, 1024px"/></figure>



<p>From Deepseek v3</p>



<figure><img loading="lazy" decoding="async" width="1024" height="478" src="https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-2.42.26-PM-1024x478.png" alt="Deepseek response to rephrasing a paragraph" srcset="https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-2.42.26-PM-1024x478.png 1024w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-2.42.26-PM-300x140.png 300w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-2.42.26-PM-768x359.png 768w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-2.42.26-PM-1536x718.png 1536w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-2.42.26-PM-650x304.png 650w, https://composio.dev/wp-content/uploads/2024/12/Screenshot-2024-12-31-at-2.42.26-PM.png 1888w" sizes="(max-width: 1024px) 100vw, 1024px"/></figure>



<p>The similarities are way too great to ignore. They probably trained the model on a synthetic dataset generated by GPT-4o.</p>



<h3 id="h-summary-of-creative-writing">Summary of Creative Writing</h3>



<p>Well, Deepseek is as good as GPT-4o; if you liked GPT-4o, you would be OK with Deepseek. Again, considering the cost, it is the better option overall. I like o1 and Claude 3.5’s Sonnets for writing and brainstorming.</p>



<h2 id="h-final-verdict">Final Verdict</h2>



<ul>
<li>• For reasoning, Deepseek v3 is a better model, followed by Claude 3.5 Sonnet and then OpenAI GPT-4o.</li>



<li>• For math, again, Deepseek v3&gt;Claude 3.5 Sonnet&gt; OpenAI GPT-4o.</li>



<li>• For coding, Claude 3.5 Sonnet&gt;Deepseek v3~&gt; OpenAI GPT-4o.</li>



<li>• For creative writing, Claude 3.5 Sonnet&gt;Deepseek v3~ OpenAI GPT-4o.</li>
</ul>



<h2 id="h-who-should-use-deepseek-v3">Who should use Deepseek v3?</h2>



<ul>
<li>• If most of your use cases involved GPT-4o, you can safely switch.</li>



<li>• If you’re building applications on top of LLMs, Deepseek v3 is a no-brainer; the cost-to-performance makes it ideal for building client-facing AI applications.</li>



<li>• Open-weight so you can host it yourself, giving you more control over the LLM.</li>
</ul>
                        </div><!-- .entry-content -->

                                                <!-- .entry-footer -->
                        
                    </article><!-- #post-9230 -->
                    
<!-- #comments -->
                </div>
                    </div>
            </main>
    	
</div><!-- #primary -->


	</div></div>
  </body>
</html>
