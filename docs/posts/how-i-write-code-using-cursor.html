<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.arguingwithalgorithms.com/posts/cursor-review.html">Original</a>
    <h1>How I write code using Cursor</h1>
    
    <div id="readability-page-1" class="page"><article>
<p>In forums relating to AI and AI coding in particular, I see a common inquiry
from experienced software developers: <em>Is anyone getting value out of tools like
Cursor, and is it worth the subscription price?</em></p>
<p>A few months into using Cursor as my daily driver for both personal and work
projects, I have some observations to share about whether this is a
&#34;need-to-have&#34; tool or just a passing fad, as well as strategies to get the most
benefit quickly which may help you if you&#39;d like to trial it. Some of you may
have tried Cursor and found it underwhelming, and maybe some of these
suggestions might inspire you to give it another try.</p>
<p>I am not sponsored by Cursor, and I am not a product reviewer. I am neither
championing nor dunking on this as a product, but rather sharing my own
experience with it.</p>
<p><strong>Who am I, and who is the audience for this article?</strong></p>
<p>I have been writing code for 36 years in a number of languages, but
professionally focused on C-heavy computer game engines and Go/Python/JS web
development. I am expecting readers to be similarly reasonably comfortable and
productive working in large codebases, writing and debugging code in their
chosen language, etc. I would give very different advice to novices who might
want an AI to teach them programming concepts or write code for them that is way
beyond their level!</p>
<p>For me, the appeal of an AI copilot is in taking care of boilerplate and
repetitive tasks for me so I can focus on the interesting logic for any given
problem. I am also not especially interested in cranking out large quantities of
code automatically; I am highly skeptical of &#34;lines of code written&#34; as an
efficiency metric. I would prefer to spend less time writing the same amount of
code and more time thinking through edge cases, maintainability, etc.</p>
<p>So, without further ado:</p>
<h2>What is Cursor?</h2>
<p>Cursor<sup id="fnref:1"><a href="#fn:1">1</a></sup> is a fork of Visual Studio Code (VS Code) which has Large Language Model (LLM)
powered features integrated into the core UI. It is a proprietary product with a
free tier and a subscription option; however, the pricing sheet doesn&#39;t cover
what the actual subscriber benefits are and how they compare to competing
products. I&#39;ll try to clarify that when discussing the features below based on
my own understanding, but a quick summary:</p>
<ul>
<li><strong>Tab completion</strong>: This is a set of proprietary fine-tuned models that both
  provide code completion in the editor, as well as navigate to the next
  recommended action, all triggered by the Tab key. Only available to subscribers.</li>
<li><strong>Inline editing</strong>: This is a chat-based interface for making edits to
  selected code with a simple diff view using a foundation model such as GPT or
  Claude. Available to free and paid users.</li>
<li><strong>Chat sidebar</strong>: This is also a chat-based interface for making larger edits
  in a sidebar view, allowing more room for longer discussion, code sample
  suggestions across multiple files, etc. using a foundation model such as GPT
  or Claude. Available to free and paid users.</li>
<li><strong>Composer</strong>: This is yet another chat-based interface specifically meant for
  larger cross-codebase refactors, generating diffs for multiple files that you
  can page through and approve, also using a foundation model such as GPT or Claude.
  Available to free and paid users.</li>
</ul>
<h2>Tab completion</h2>
<p>While other LLM-powered coding tools focus on a chat experience, so far in my
usage of Cursor it&#39;s the tab completion that fits most naturally into my
day-to-day practice of coding and saves the most time. A lot of thought and
technical research has apparently gone into this feature, so that it can not
only suggest completions for a line, several lines, or a whole function, but it
can also suggest the next line to go to for the next edit. What this amounts to
is being able to make part of a change, and then auto-complete related changes
throughout the entire file just by repeatedly pressing Tab.</p>
<p>One way to use this is as a code refactoring tool on steroids. For example,
suppose I have a block of code with variable names in <code>under_score</code> notation
that I want to convert to <code>camelCase</code>. It is sufficient to rename one instance
of one variable, and then tab through all the lines that should be updated,
including the other related variables. Many tedious, error-prone tasks can be
automated in this way without having to write a script to do so:</p>
<video controls="">
  <source src="../videos/cursor-review/example1.webm" type="video/webm"/>
  <p>
    Your browser doesn&#39;t support HTML video. Here is a
    <a href="https://www.arguingwithalgorithms.com/videos/cursor-review/example1.webm" download="example1.webm">link to the video</a> instead.
  </p>
</video>

<p>Sometimes tab completion will indepedently find a bug and propose a fix. Many
times it will suggest imports when I add a dependency in Python or Go. If I wrap
a string in quotes, it will escape the contents appropriately. And, as with
other tools, it can write whole functions based on just the function signature
and optional docstring:</p>
<video controls="">
  <source src="../videos/cursor-review/example2.webm" type="video/webm"/>
  <p>
    Your browser doesn&#39;t support HTML video. Here is a
    <a href="https://www.arguingwithalgorithms.com/videos/cursor-review/example2.webm" download="example2.webm">link to the video</a> instead.
  </p>
</video>

<p>All in all, this tool feels like it is reading my mind, guessing at my next
action, and allowing me to think less about the code and more about the
architecture of I am building.</p>
<p>Also worth noting: The completions are <em>incredibly fast</em>, and I never felt a delay
waiting for a suggestion. They appear basically as soon as I stop typing. Having
too long a wait would surely be a deal-breaker for me.</p>
<p>So, what are my complaints with Tab completion? One is a minor annoyance:
Sometimes I don&#39;t see the suggestion in time and continue typing, and the
completion disappears. Once it is gone, there doesn&#39;t appear to be any way to
get it to come back, so I have to type something else and hope.</p>
<p>My other complaint is the exact opposite situation: Sometimes a completion is
dead wrong, and I intentionally dismiss it. Subsequently, but very infrequently,
I will accept a totally different completion and the previously-declined
suggestion will quietly be applied as well. This has already caused some
hard-to-track-down bugs because I wasn&#39;t aware the wrong logic had been
accepted. I haven&#39;t found these cases to be frequent enough to cancel out the
productivity boost of tab completion, but they do detract from it.</p>
<h2>Inline editing, chat sidebar, and composer</h2>
<p>As far as I can tell, these features are all very similar in their interaction
with a foundational model - I use Claude 3.5 Sonnet almost exclusively - and the
variance is in the user interface.</p>
<p>Inline editing can be invoked by selecting some code and pressing Ctrl-K/Cmd-K.
I type in the desired changes, and get a nice diff in the file that I can accept
or reject. I use this mostly to implement bits of code inside a function or make
minor refactors.</p>
<p>A good example of where this works great is if I have a loop over some tasks and
I want to parallelize them:</p>
<video controls="">
  <source src="../videos/cursor-review/example3.webm" type="video/webm"/>
  <p>
    Your browser doesn&#39;t support HTML video. Here is a
    <a href="https://www.arguingwithalgorithms.com/videos/cursor-review/example3.webm" download="example3.webm">link to the video</a> instead.
  </p>
</video>

<p>The chat sidebar is opened with Ctrl+L/Cmd+L, and gives more real estate for a
multi-turn conversation, though one pet peeve I have with the LLM models I&#39;ve
tested so far is they will <em>always</em> return code first, rather than ask for
clarification if there is any ambiguity. The suggested code has an Apply button
that will create a diff in the currently selected file. This is useful for
larger refactors within a single file, or creating a brand new file based on the
file I have open. If additional files are relevant they can be added manually to
the context, but Cursor will try to guess which files are relevant based on the
query and an index it generates in the background.</p>
<p>Here is an example which takes an application&#39;s database API and creates a REST
API to access it, with parameter validation and correct HTTP status codes,
<em>then</em> writes a client library to access that REST API:</p>
<video controls="">
  <source src="../videos/cursor-review/example4.webm" type="video/webm"/>
  <p>
    Your browser doesn&#39;t support HTML video. Here is a
    <a href="https://www.arguingwithalgorithms.com/videos/cursor-review/example4.webm" download="example4.webm">link to the video</a> instead.
  </p>
</video>

<p>As another example, here I am using the chat sidebar to convert the client
library from Python to Go. Note how the loosely-typed Python is converted to
well-defined struct types and idiomatic Go including error handling! This is not
a 1:1 rewrite at all:</p>
<video controls="">
  <source src="../videos/cursor-review/example5.webm" type="video/webm"/>
  <p>
    Your browser doesn&#39;t support HTML video. Here is a
    <a href="https://www.arguingwithalgorithms.com/videos/cursor-review/example5.webm" download="example5.webm">link to the video</a> instead.
  </p>
</video>

<p>Finally, Composer is specifically meant for cross-file refactors. This is also
the feature I use least, but provides a better user experience for reviewing
multiple file diffs one at a time.</p>
<h2>.cursorrules file</h2>
<p>I did not realize this feature existed until I came across it in the (in my
opinion too minimal) documentation, but the various chat modalities always
include the contents of a <code>.cursorrules</code> file located at the root of the
workspace to provide additional context. I&#39;ve been experimenting with using this
to inform the LLM of the repository&#39;s coding standards, common packages, and
other documentation.</p>
<p>This feature might help to solve one of the big roadblocks I have observed with
Cursor: It does not follow coding styles and patterns unless they already exist
in the same file you are editing. For example, at Khan Academy we use a
proprietary library <sup id="fnref:2"><a href="#fn:2">2</a></sup> for passing context between functions in Go. This is
used for logging, HTTP requests, etc. so the LLM needs to be able to use it.
This has been difficult in the past, but perhaps a well-written <code>.cursorrules</code>
is a good first step.</p>
<p>One current limitation is that there is only one of these files per workspace,
so a monorepo like ours containing code in multiple languages is going to be
more difficult to set up than a small repository with a small set of very
consistently styled code.</p>
<p>Also the documentation suggests that the <code>.cursorrules</code> file is only used for
the chat modalities, not the tab completion. However I&#39;ve experimented with
having that file open in a pinned tab in the workspace and confirmed that it is
possible to include it in the tab completion context that way at least.</p>
<h2>Changes to my workflow</h2>
<p>The most exciting thing about a tool like Cursor is not that I can write code
faster, because honestly the actual writing of code is not the bottleneck; in
fact, I often have to slow myself down to avoid focusing too much on the code
and not enough on the high-level problem being solved. The real value is in
changing <em>how</em> I code.</p>
<p>It&#39;s still early days with this technology, but this is what I&#39;ve found has
changed about how I work and what I expect to see changing in the near future:</p>
<ol>
<li>
<p>I am <em>much</em> less likely to reach for a new library or a framework. No, I&#39;m
not going to start writing my own crypto libraries, but for small utilities it&#39;s
easy enough to let the LLM write them to my bespoke needs than to pull in a
general-purpose library. These libraries tend to start small and lightweight and
then, because they are open and used by many people, accumulate functionality
and cruft that I don&#39;t need.</p>
<p>Many of these libraries only exist to reduce boilerplate, which felt like a
necessary tradeoff when balanced against my time writing and maintaining that
boilerplate but now that I can have the LLM do it for me it feels less worth the
cost. And the cost can be substantial: Have you tried getting a Node.js project
running a year or more after it was written? You may as well start from scratch.</p>
</li>
<li>
<p>I also worry less about adhering to DRY (Don&#39;t Repeat Yourself) in my own code.
Prematurely defining abstractions can create a lot of technical debt later on,
so being able to create a lot of code with reference to other code without
trying to pull it into a function or class allows me more flexibility, and I
know that if I have to refactor shared logic out later, the LLM can help with
that too.</p>
</li>
<li>
<p>My willingness to use a language or framework I am less familiar with is much
higher. For example, I&#39;ve dabbled in R for years, especially for visualizing
data. However, to be frank, I suck at it. I don&#39;t have a deep understanding of
<code>dplyr</code> and it seems like there are always a dozen different ways to accomplish
the same task. Now I describe the visualization I want, and I get correct data
manipulation and <code>ggplot</code> visualization for it. Tasks that took an hour or more
now take five minutes, so I am much less likely to give up and do it in Python
instead.</p>
<p>Maybe one of these days I&#39;ll even write something in Rust. Maybe.</p>
</li>
<li>
<p>I find myself iterating quickly on small components before integrating them
into the larger codebase. This is partly to work around the limitations of LLMs
when working with larger codebases, but it also opens up interesting ways of
working I hadn&#39;t considered before. As per the example above, I can prototype
some logic in a dynamically typed language like Python, work out the technical
details and then convert it to well-typed Go instantly to integrate into a web
application. I can have the LLM generate test data automatically, or mock up a
backend for me to write a frontend against. Why pay the tax of working in a
mature codebase while I&#39;m still proving out an idea?</p>
</li>
</ol>
<h2>Summary</h2>
<p>Whether I&#39;ll be using Cursor in a few years or have moved on to another tool, I
can&#39;t really tell. I am confident that at the time of writing this, Cursor is
the best example of the potential of LLM coding assistants, and if you want to
explore how this type of tool might be of value I suggest you give it a spin.</p>
</article></div>
  </body>
</html>
