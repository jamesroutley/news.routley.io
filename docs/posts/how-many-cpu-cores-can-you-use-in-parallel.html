<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://pythonspeed.com/articles/cpu-thread-pool-size/">Original</a>
    <h1>How many CPU cores can you use in parallel?</h1>
    
    <div id="readability-page-1" class="page"><div itemprop="articleBody">
      <p>When you’re running a CPU-intensive parallel program, you often want to have a thread or process pool sized by the number of CPU cores on your machine.
Fewer threads and you’re not taking advantage of all the cores, more than that and your program will start running slower as multiple threads compete for the same core.
Or that’s the theory, anyway.</p>

<p>So how do you check how many cores your computer has?
And is this actually good advice?</p>

<p>It turns out to be surprisingly tricky to nail down how many threads to run:</p>

<ul>
  <li>The Python standard library provides multiple APIs to get this info, but none are sufficient.</li>
  <li>Even worse, because of CPU features like instruction-level parallelism and simultaneous threading (aka Hyper-threading on Intel CPUs), the number of cores you can effectively use depends on the code <em>you</em> have written!</li>
</ul>

<p>Let’s see why it’s so difficult to figure out how many CPU cores your program can use, and then consider a potential solution.</p>

<!-- TEASER_END -->

<h2 id="getting-the-number-of-cpu-cores-from-python">Getting the number of CPU cores from Python</h2>

<p>If you read the Python standard library documentation, it has a <a href="https://docs.python.org/3/library/os.html#os.cpu_count"><code>os.cpu_count()</code></a> function that returns “the number of logical CPUs in the system”.
What does logical mean?
We’ll get to that in a bit.</p>

<p>The documentation also tells you that “<code>len(os.sched_getaffinity(0))</code> gets the number of logical CPUs the calling thread of the current process is restricted to”.
Scheduler affinity is a way to restrict a process to particular cores.</p>

<p>Unfortunately, this API is not sufficient either.
For example, on Linux the <code>cgroups</code> API, used to implement Docker and other container systems, has a variety of ways to limit CPU usage.
Here we limit the CPU to the equivalent of 2.25 cores; the mechanism is different, but the effects will be similar:</p>

<div><div><pre><code><span>$</span><span> </span>docker run <span>-i</span> <span>-t</span> <span>--cpus</span><span>=</span>2.25 python:3.12-slim
<span>Python 3.12.1 (main, Dec  9 2023, 00:21:37) [GCC 12.2.0] on linux
Type &#34;help&#34;, &#34;copyright&#34;, &#34;credits&#34; or &#34;license&#34; for more information.
</span><span>&gt;</span><span>&gt;&gt;</span> import os
<span>&gt;</span><span>&gt;&gt;</span> os.cpu_count<span>()</span>
<span>20
</span><span>&gt;</span><span>&gt;&gt;</span> len<span>(</span>os.sched_getaffinity<span>(</span>0<span>))</span>
<span>20
</span></code></pre></div></div>

<p>We can only use the equivalent of 2.25 cores at a time, but neither API knows about this.</p>

<h2 id="whats-a-logical-cpu">What’s a logical CPU?</h2>

<p>Operating system options are just the start of our troubles, but before we see an example we need to understand what physical and logical CPU cores are.
My computer use an <a href="https://www.intel.com/content/www/us/en/products/sku/134594/intel-core-i712700k-processor-25m-cache-up-to-5-00-ghz/specifications.html">Intel i7-12700K</a> processor, which has:</p>

<ul>
  <li>12 physical cores (8 performance cores, and 4 less powerful ones).</li>
  <li>20 logical cores.</li>
</ul>

<p>Modern CPU cores can execute <a href="https://pythonspeed.com/articles/speeding-up-numba/">multiple instructions in parallel</a>.
But what happens if the CPU is stuck waiting for some data to be loaded from RAM?
It may not be able to do any work until that happens.</p>

<p><strong>To allow utilizing these potentially wasted resources, a physical CPU core’s computational resources can be exposed as multiple cores to the operating system.</strong>
On my CPU, each of the 8 faster cores can be exposed as two cores, for a total of 16 logical cores.
The pairs of logical cores will share the computational resources of a single physical core.
For example, if a logical core isn’t fully utilizing all the internal arithmetic logic units, say because it’s waiting for a memory load, the code running via the paired logical core can still use these idle resources.</p>

<p>This technology is called simultaneous multithreading, or Hyper-threading in Intel’s terminology.
If you have a PC, you can often disable it in the BIOS.</p>

<blockquote>
  <p>This explanation is very inaccurate, and the actual implementation varies by CPU model, even from the same manufacturer.
But the general sense that logical cores aren’t really the same as physical cores is sufficient for our purposes.</p>
</blockquote>

<p>So now we have a new question.
<strong>Putting aside scheduler affinity and the like, should we use the number of physical or logical cores as our thread pool size?</strong></p>

<h2 id="an-embarrassingly-parallel-example">An embarrassingly-parallel example</h2>

<p>Let’s consider two functions that are compiled to machine code with <a href="https://pythonspeed.com/articles/numba-faster-python/">Numba</a>.
We make sure to <a href="https://pythonspeed.com/articles/python-gil/">release the GIL</a> to enable parallelism.</p>

<p>Both functions do the same thing, but one is much faster than the other.
We can run these functions in parallel on multiple threads, and in theory get linear improvements in throughput until we run out of cores, just by processing more images in parallel.</p>

<div><div><pre><code><span>from</span> <span>numba</span> <span>import</span> <span>njit</span>
<span>import</span> <span>numpy</span> <span>as</span> <span>np</span>

<span>@</span><span>njit</span><span>(</span><span>nogil</span><span>=</span><span>True</span><span>)</span>
<span>def</span> <span>slow_threshold</span><span>(</span><span>img</span><span>,</span> <span>noise_threshold</span><span>):</span>
    <span>noise_threshold</span> <span>=</span> <span>img</span><span>.</span><span>dtype</span><span>.</span><span>type</span><span>(</span><span>noise_threshold</span><span>)</span>
    <span>result</span> <span>=</span> <span>np</span><span>.</span><span>empty</span><span>(</span><span>img</span><span>.</span><span>shape</span><span>,</span> <span>dtype</span><span>=</span><span>np</span><span>.</span><span>uint8</span><span>)</span>
    <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>result</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]):</span>
        <span>for</span> <span>j</span> <span>in</span> <span>range</span><span>(</span><span>result</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>]):</span>
            <span>result</span><span>[</span><span>i</span><span>,</span> <span>j</span><span>]</span> <span>=</span> <span>img</span><span>[</span><span>i</span><span>,</span> <span>j</span><span>]</span> <span>//</span> <span>256</span>
    <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>result</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]):</span>
        <span>for</span> <span>j</span> <span>in</span> <span>range</span><span>(</span><span>result</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>]):</span>
            <span>if</span> <span>result</span><span>[</span><span>i</span><span>,</span> <span>j</span><span>]</span> <span>&lt;</span> <span>noise_threshold</span> <span>//</span> <span>256</span><span>:</span>
                <span>result</span><span>[</span><span>i</span><span>,</span> <span>j</span><span>]</span> <span>=</span> <span>0</span>
    <span>return</span> <span>result</span>

<span>@</span><span>njit</span><span>(</span><span>nogil</span><span>=</span><span>True</span><span>)</span>
<span>def</span> <span>fast_threshold</span><span>(</span><span>img</span><span>,</span> <span>noise_threshold</span><span>):</span>
    <span>noise_threshold</span> <span>=</span> <span>np</span><span>.</span><span>uint8</span><span>(</span><span>noise_threshold</span> <span>//</span> <span>256</span><span>)</span>
    <span>result</span> <span>=</span> <span>np</span><span>.</span><span>empty</span><span>(</span><span>img</span><span>.</span><span>shape</span><span>,</span> <span>dtype</span><span>=</span><span>np</span><span>.</span><span>uint8</span><span>)</span>
    <span>for</span> <span>i</span> <span>in</span> <span>range</span><span>(</span><span>result</span><span>.</span><span>shape</span><span>[</span><span>0</span><span>]):</span>
        <span>for</span> <span>j</span> <span>in</span> <span>range</span><span>(</span><span>result</span><span>.</span><span>shape</span><span>[</span><span>1</span><span>]):</span>
            <span>value</span> <span>=</span> <span>img</span><span>[</span><span>i</span><span>,</span> <span>j</span><span>]</span> <span>&gt;&gt;</span> <span>8</span>
            <span>value</span> <span>=</span> <span>(</span>
                <span>0</span> <span>if</span> <span>value</span> <span>&lt;</span> <span>noise_threshold</span> <span>else</span> <span>value</span>
            <span>)</span>
            <span>result</span><span>[</span><span>i</span><span>,</span> <span>j</span><span>]</span> <span>=</span> <span>value</span>
    <span>return</span> <span>result</span>
</code></pre></div></div>

<p>We’ll run the function on an image and measure how long they take to run:</p>

<div><div><pre><code><span>rng</span> <span>=</span> <span>np</span><span>.</span><span>random</span><span>.</span><span>default_rng</span><span>(</span><span>12345</span><span>)</span>

<span>def</span> <span>make_image</span><span>(</span><span>size</span><span>=</span><span>256</span><span>):</span>
    <span>noise</span> <span>=</span> <span>rng</span><span>.</span><span>integers</span><span>(</span><span>0</span><span>,</span> <span>high</span><span>=</span><span>1000</span><span>,</span> <span>size</span><span>=</span><span>(</span><span>size</span><span>,</span> <span>size</span><span>),</span> <span>dtype</span><span>=</span><span>np</span><span>.</span><span>uint16</span><span>)</span>
    <span>signal</span> <span>=</span> <span>rng</span><span>.</span><span>integers</span><span>(</span><span>0</span><span>,</span> <span>high</span><span>=</span><span>5000</span><span>,</span> <span>size</span><span>=</span><span>(</span><span>size</span><span>,</span> <span>size</span><span>),</span> <span>dtype</span><span>=</span><span>np</span><span>.</span><span>uint16</span><span>)</span>
    <span># A noisy, hard to predict image:
</span>    <span>return</span> <span>noise</span> <span>|</span> <span>signal</span>

<span>NOISY_IMAGE</span> <span>=</span> <span>make_image</span><span>()</span>
<span>assert</span> <span>np</span><span>.</span><span>array_equal</span><span>(</span>
    <span>slow_threshold</span><span>(</span><span>NOISY_IMAGE</span><span>,</span> <span>1000</span><span>),</span>
    <span>fast_threshold</span><span>(</span><span>NOISY_IMAGE</span><span>,</span> <span>1000</span><span>)</span>
<span>)</span>
</code></pre></div></div>

<p>Here’s how long it takes to run each of the functions on a single core:</p>

<div><div><pre><code><span>%</span><span>timeit</span> <span>slow_threshold</span><span>(</span><span>NOISY_IMAGE</span><span>,</span> <span>1000</span><span>)</span>
</code></pre></div></div>

<div><div><pre><code>90.6 µs ± 77.7 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)
</code></pre></div></div>

<p>and</p>

<div><div><pre><code><span>%</span><span>timeit</span> <span>fast_threshold</span><span>(</span><span>NOISY_IMAGE</span><span>,</span> <span>1000</span><span>)</span>
</code></pre></div></div>

<div><div><pre><code>24.6 µs ± 10.8 ns per loop (mean ± std. dev. of 7 runs, 10,000 loops each)
</code></pre></div></div>

<blockquote>
  <p>Curious why the fast function is so much faster?
You might want to read <a href="https://pythonspeed.com/products/lowlevelcode/">a book I am working on about optimizing low-level code</a>.</p>
</blockquote>

<h2 id="scaling-to-multiple-threads">Scaling to multiple threads</h2>

<p>Now that we have a couple of functions, we’ll set up a way to process a given list of images with a thread pool, with a thread processing 10 images at a time:</p>

<div><div><pre><code><span>from</span> <span>multiprocessing.dummy</span> <span>import</span> <span>Pool</span> <span>as</span> <span>ThreadPool</span>

<span>def</span> <span>apply_in_thread_pool</span><span>(</span>
    <span>num_threads</span><span>,</span> <span>function</span><span>,</span> <span>images</span>
<span>):</span>
    <span>with</span> <span>ThreadPool</span><span>(</span><span>num_threads</span><span>)</span> <span>as</span> <span>pool</span><span>:</span>
        <span>result</span> <span>=</span> <span>pool</span><span>.</span><span>map</span><span>(</span>
            <span>lambda</span> <span>img</span><span>:</span> <span>function</span><span>(</span><span>img</span><span>,</span> <span>1000</span><span>),</span>
            <span>images</span><span>,</span>
            <span>chunksize</span><span>=</span><span>10</span>
        <span>)</span>
        <span>assert</span> <span>len</span><span>(</span><span>result</span><span>)</span> <span>==</span> <span>len</span><span>(</span><span>images</span><span>)</span>
</code></pre></div></div>

<p>Next, we’ll graph how long it takes to run for different numbers of threads for the different functions, using the <a href="https://github.com/droyed/benchit"><code>benchit</code></a> library (you can also use <a href="https://github.com/nschloe/perfplot"><code>perfplot</code></a>, but note it’s GPL-licensed):</p>

<div><div><pre><code><span>import</span> <span>benchit</span>
<span>benchit</span><span>.</span><span>setparams</span><span>(</span><span>rep</span><span>=</span><span>1</span><span>)</span>

<span># 4000 images to run through the pool:
</span><span>IMAGES</span> <span>=</span> <span>[</span><span>make_image</span><span>()</span> <span>for</span> <span>_</span> <span>in</span> <span>range</span><span>(</span><span>4000</span><span>)]</span>

<span>def</span> <span>slow_threshold_in_pool</span><span>(</span><span>num_threads</span><span>):</span>
    <span>apply_in_thread_pool</span><span>(</span><span>num_threads</span><span>,</span> <span>slow_threshold</span><span>,</span> <span>IMAGES</span><span>)</span>

<span>def</span> <span>fast_threshold_in_pool</span><span>(</span><span>num_threads</span><span>):</span>
    <span>apply_in_thread_pool</span><span>(</span><span>num_threads</span><span>,</span> <span>fast_threshold</span><span>,</span> <span>IMAGES</span><span>)</span>

<span># Measure the two functions with 1 to 24 threads:
</span><span>timings</span> <span>=</span> <span>benchit</span><span>.</span><span>timings</span><span>(</span>
    <span>[</span><span>slow_threshold_in_pool</span><span>,</span> <span>fast_threshold_in_pool</span><span>],</span>
    <span>range</span><span>(</span><span>1</span><span>,</span> <span>25</span><span>),</span>
    <span>input_name</span><span>=</span><span>&#34;Number of threads&#34;</span>
<span>)</span>
<span>timings</span><span>.</span><span>plot</span><span>(</span><span>logy</span><span>=</span><span>True</span><span>,</span> <span>logx</span><span>=</span><span>False</span><span>)</span>
</code></pre></div></div>

<p><img src="https://pythonspeed.com/assets/cpu-thread-pool-size/graph.png" alt="Graph showing slow vs fast runtime. Both variants have a run time that declines as the number of threads increases, up to a certain minimum runtime. Past that minimum, adding more threads actually slows things down. Slow and fast have different optimal number of threads, though!"/></p>

<p>Notice how the run time declines as the number of threads increases… up to a point.
After that run time starts getting worse again.
So far this is what we’ve expected.
But there is something unexpected too: the optimal number of threads is different for each function.</p>

<div><div><pre><code><span>timings</span><span>.</span><span>to_dataframe</span><span>().</span><span>idxmin</span><span>(</span><span>axis</span><span>=</span><span>&#34;rows&#34;</span><span>)</span>
</code></pre></div></div>

<table>
  <thead>
    <tr>
      <th>Functions</th>
      <th>Optimal number of threads</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>slow_threshold</td>
      <td>19</td>
    </tr>
    <tr>
      <td>fast_threshold</td>
      <td>9</td>
    </tr>
  </tbody>
</table>

<h2 id="the-optimal-level-of-parallelism-also-depends-on-your-code">The optimal level of parallelism also depends on your code</h2>

<p>Our slower function was able to take advantage of basically all the logical cores.
Possibly a single thread isn’t fully utilizing all the available processing in a given physical core, so logical cores allow for more parallelism.</p>

<p>In contrast, our faster function could take advantage of no more than 9 cores; beyond that it started slowing down.
Perhaps it started hitting some bottleneck other than computation, like memory bandwidth.</p>

<p><strong>There is no thread pool size that is optimal for both functions.</strong></p>

<h2 id="a-different-approach-empirical-measurement">A different approach: empirical measurement</h2>

<p>We’ve encountered multiple problems in getting the optimal number of threads:</p>

<ol>
  <li>It’s difficult to get an accurate number of cores that take into account all the different ways the operating system can restrict CPU usage.</li>
  <li>The optimal parallelism level, e.g. number of threads, is workload dependent.</li>
  <li>The number of cores isn’t the only bottleneck.</li>
  <li>Bonus problem: If you’re running in the cloud, you’re using “vCPUs”, whatever that means.
Different instances may have different CPU models, for one thing.</li>
</ol>

<p><strong>So here’s another approach: empirically discover the optimal number of threads, at runtime.</strong>
In the example above we measured the optimal number of threads for a particular piece of code.
If you have a long-running data processing job that will be running the same code for a while in multiple threads, you can do the same.
That is, you can spend a little bit of time at the beginning to empirically measure the optimal number of threads, perhaps with some heuristics to compensate for noise.</p>

<p>For runtime purposes, if you’re using empirical measurement you don’t need to care about <em>why</em> a particular number of threads is optimal.
Regardless of the hardware, operating system configuration, or cloud environment, you will be using the optimal level of parallelism.</p>

  </div></div>
  </body>
</html>
