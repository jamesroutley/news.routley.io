<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.eff.org/deeplinks/2025/12/ai-police-reports-year-review">Original</a>
    <h1>AI Police Reports: Year in Review</h1>
    
    <div id="readability-page-1" class="page"><div>
            <article role="article">
  
  
  <div>
    <div><div><div><p><span>In 2024, EFF wrote our initial blog about </span><a href="https://www.eff.org/deeplinks/2024/05/what-can-go-wrong-when-police-use-ai-write-reports"><span>what could go wrong when police let AI write police reports</span></a><span>. Since then, the technology has proliferated at a disturbing rate. Why? The most popular generative AI tool for writing police reports is Axon’s Draft One, and Axon also happens to be the largest provider of body-worn cameras to police departments in the United States. As we’ve written, companies are increasingly </span><a href="https://www.eff.org/deeplinks/2025/04/beware-bundle-companies-are-banking-becoming-your-police-departments-favorite"><span>bundling their products</span></a><span> to make it easier for police to buy more technology than they may need or that the public feels comfortable with. </span></p>
<p><span>We have good news and bad news. </span></p>
<p><b>Here’s the bad news:</b><span> AI written police reports are still unproven, untransparent, and downright irresponsible–especially when the criminal justice system, informed by police reports, is deciding people’s freedom. The King County prosecuting attorney’s office in Washington state </span><a href="https://www.eff.org/deeplinks/2024/10/prosecutors-washington-state-warn-police-dont-use-gen-ai-write-reports"><span>barred police from using AI to write police reports</span></a><span>. As their </span><a href="https://komonews.com/amp/news/local/king-county-prosecutor-tells-police-not-to-use-ai-artificial-intelligence-for-official-reports-for-now-errors-concerns-law-enforcement-perjury-criminal-justice"><span>memo</span></a><span> read, “We do not fear advances in technology – but we do have legitimate concerns about some of the products on the market now... AI continues to develop and we are hopeful that we will reach a point in the near future where these reports can be relied on. For now, our office has made the decision not to accept any police narratives that were produced with the assistance of AI.” </span></p>
<p><span>In July of this year, EFF published a </span><a href="https://www.eff.org/deeplinks/2025/07/axons-draft-one-designed-defy-transparency"><span>two-part </span></a><span>report on how Axon designed Draft One to defy transparency. Police upload their body-worn camera’s audio into the system, the system generates a report that the officer is expected to edit, and then the officer exports the report. But when they do that, Draft One erases the initial draft, and with it any evidence of what portions of the report were written by AI and what portions were written by an officer. That means that if an officer is caught lying on the stand – as shown by a contradiction between their courtroom testimony and their earlier police report – they could point to the contradictory parts of their report and say, “the AI wrote that.” Draft One is designed to make it hard to disprove that. </span></p>
<p><span>In this video of a</span><a href="https://vimeo.com/941650612"> <span>roundtable discussion about Draft One</span></a><span>, Axon’s senior principal product manager for generative AI is asked (at the 49:47 mark) whether or not it’s possible to see after-the-fact which parts of the report were suggested by the AI and which were edited by the officer. His response (bold and definition of RMS added): </span></p>
<p><span>“</span><b>So we don’t store the original draft and that’s by design and that’s really because the last thing we want to do is create more disclosure headaches for our customers and our attorney’s offices</b><span>—so basically the officer generates that draft, they make their edits, if they submit it into our Axon records system then that’s the only place we store it, if they copy and paste it into their third-party RMS [records management system] system as soon as they’re done with that and close their browser tab, it’s gone. It’s actually never stored in the cloud at all so you don’t have to worry about extra copies floating around.”</span></p>
<p><span>Yikes! </span></p>
<p><span>All of this obfuscation also makes it incredibly hard for people outside police departments to figure out if their city’s officers are using AI to write reports–and even harder to use public records requests to audit just those reports. That’s why this year EFF also put out a </span><a href="https://www.eff.org/deeplinks/2025/07/effs-guide-getting-records-about-axons-ai-generated-police-reports"><span>comprehensive guide</span></a><span> to help the public make their records requests as tailored as possible to learn about AI-generated reports. </span></p>
<p><b>Ok, now here’s the good news: </b><span>People who believe AI-written police reports are irresponsible and potentially harmful to the public are fighting back. </span></p>
<p><span>This year, two states have passed bills that are an important first step in reigning in AI police reports. Utah’s </span><a href="https://le.utah.gov/~2025/bills/static/SB0180.html"><span>SB 180</span></a><span> mandates that police reports created in whole or in part by generative AI have a disclaimer that the report contains content generated by AI. It also requires officers to certify that they checked the report for accuracy. </span><a href="https://www.eff.org/deeplinks/2025/10/victory-california-requires-transparency-ai-police-reports"><span>California’s SB 524</span></a><span> went even further. It requires police to disclose, on the report, if it was used to fully or in part author a police report. Further, it bans vendors from selling or sharing the information a police agency provided to the AI. The bill also requires departments to retain the first draft of the report so that judges, defense attorneys, or auditors could readily see which portions of the final report were written by the officer and which portions were written by the computer.</span></p>
<p><span>In the coming year, anticipate many more states joining California and Utah in regulating, or perhaps even banning, police from using AI to write their reports. </span></p>
<p><span><span><i>This article is part of our Year in Review series. <a href="https://www.eff.org/tags/2025-review">Read other articles</a> about the fight for digital rights in 2025.</i></span></span></p>

</div></div></div>  </div>

          </article>
    </div></div>
  </body>
</html>
