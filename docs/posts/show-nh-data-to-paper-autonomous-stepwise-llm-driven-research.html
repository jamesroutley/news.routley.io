<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/Technion-Kishony-lab/data-to-paper">Original</a>
    <h1>Show NH: &#34;data-to-paper&#34; - autonomous stepwise LLM-driven research</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto"><h2 tabindex="-1" dir="auto">data-to-paper: AI-driven research from data to human-verifiable research papers</h2><a id="user-content-data-to-paper-ai-driven-research-from-data-to-human-verifiable-research-papers" aria-label="Permalink: data-to-paper: AI-driven research from data to human-verifiable research papers" href="#data-to-paper-ai-driven-research-from-data-to-human-verifiable-research-papers"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/Technion-Kishony-lab/data-to-paper/blob/main/data_to_paper_icon.gif?raw=true"><img src="https://github.com/Technion-Kishony-lab/data-to-paper/raw/main/data_to_paper_icon.gif?raw=true" width="400" data-animated-image=""/></a></p>
<p dir="auto"><a href="https://arxiv.org/abs/2404.17605" rel="nofollow"><em>data-to-paper</em></a> is a framework for systematically navigating the power of AI to perform complete end-to-end
scientific research, starting from raw data and concluding with comprehensive, transparent, and human-verifiable
scientific papers (<a href="https://t.co/iz44TDZZHb" rel="nofollow">example</a>).</p>
<p dir="auto">Towards this goal, <em>data-to-paper</em> systematically guides interacting
LLM and rule-based agents through the conventional scientific path, from annotated data, through creating
research hypotheses, conducting literature search, writing and debugging data analysis code,
interpreting the results, and ultimately the step-by-step writing of a complete research paper.</p>
<p dir="auto">The <strong>data-to-paper</strong> framework is created as a research project to understand the
capacities and limitations of LLM-driven scientific research, and to develop ways of harnessing LLM to accelerate
research while maintaining, and even enhancing, key scientific values, such as transparency, traceability and verifiability,
and while allowing scinetist to oversee and direct the process
[see also: <a href="https://www.nature.com/articles/d41586-023-03266-1" rel="nofollow">living guidelines</a>].</p>
<details open="">
  <summary>
    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true">
    <path d="M16 3.75v8.5a.75.75 0 0 1-1.136.643L11 10.575v.675A1.75 1.75 0 0 1 9.25 13h-7.5A1.75 1.75 0 0 1 0 11.25v-6.5C0 3.784.784 3 1.75 3h7.5c.966 0 1.75.784 1.75 1.75v.675l3.864-2.318A.75.75 0 0 1 16 3.75Zm-6.5 1a.25.25 0 0 0-.25-.25h-7.5a.25.25 0 0 0-.25.25v6.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-6.5ZM11 8.825l3.5 2.1v-5.85l-3.5 2.1Z"></path>
</svg>
    <span aria-label="Video description data_to_paper.mp4">data_to_paper.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/65530510/326309132-73dca9b5-3117-490a-9578-345789889189.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTU0OTgyMjEsIm5iZiI6MTcxNTQ5NzkyMSwicGF0aCI6Ii82NTUzMDUxMC8zMjYzMDkxMzItNzNkY2E5YjUtMzExNy00OTBhLTk1NzgtMzQ1Nzg5ODg5MTg5Lm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MTIlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTEyVDA3MTIwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTlhYWYzM2IzNDM1NWJkMzdjYmRlOThjZGQ2OTNlZmViNTczN2MxMTg0Nzc3N2EzNzFhZmE3OGU1YjlkYjZjZGQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.poJGPpKbTy50k07M9elGJzq6G-FxfeYEy-EGfUEe1OI" data-canonical-src="https://private-user-images.githubusercontent.com/65530510/326309132-73dca9b5-3117-490a-9578-345789889189.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTU0OTgyMjEsIm5iZiI6MTcxNTQ5NzkyMSwicGF0aCI6Ii82NTUzMDUxMC8zMjYzMDkxMzItNzNkY2E5YjUtMzExNy00OTBhLTk1NzgtMzQ1Nzg5ODg5MTg5Lm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MTIlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTEyVDA3MTIwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTlhYWYzM2IzNDM1NWJkMzdjYmRlOThjZGQ2OTNlZmViNTczN2MxMTg0Nzc3N2EzNzFhZmE3OGU1YjlkYjZjZGQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.poJGPpKbTy50k07M9elGJzq6G-FxfeYEy-EGfUEe1OI" controls="controls" muted="muted">

  </video>
</details>


<p dir="auto">The <strong>data-to-paper</strong> framework is described in the following pre-print:</p>
<ul dir="auto">
<li>Tal Ifargan, Lukas Hafner, Maor Kern, Ori Alcalay and Roy Kishony,
&#34;Autonomous LLM-driven research from data to human-verifiable research papers&#34;,
<a href="https://arxiv.org/abs/2404.17605" rel="nofollow">arXiv:2404.17605</a></li>
</ul>

<ul dir="auto">
<li><strong>Field agnostic</strong>. We strive to make the framework as general as possible, so that it can be used across different
fields of research.</li>
<li><strong>Open-goal or fixed goal research.</strong> <em>data-to-paper</em> can be used to autonomously raise and test
a hypothesis, or to test a specific pre-defined user-defined hypothesis.</li>
<li><strong>Data-chained manuscripts</strong>. The process creates transparent and verifiable manuscripts, where results,
methodology and data are programmatically linked
(all numeric values can be click-traced back to the code lines that created them).</li>
<li><strong>Human-in-the-loop.</strong> A GUI app allows the user to oversee the process, and to intervene
at each research step.</li>
<li><strong>Replay</strong>. The entire process is recorded, including all LLM responses, Human feedback, and
literature search retrievals, allowing for transparent replay of the process.</li>
</ul>

<p dir="auto">See <a href="https://github.com/Technion-Kishony-lab/data-to-paper/blob/main/INSTALL.md">INSTALL.md</a> for installation instructions.</p>

<ol dir="auto">
<li>Install data-to-paper (<a href="https://github.com/Technion-Kishony-lab/data-to-paper/blob/main/INSTALL.md">INSTALL</a>).</li>
<li>Run data-to-paper:
<code>python data_to_paper/data_to_paper/run/run.py</code></li>
<li>This will open a startup dialog that will allow you to specify your own project,
or to reproduce example projects (<code>data-to-paper/projects</code>)</li>
<li>Click &#34;Start&#34; to start the run, with human overseeing and feedback.</li>
<li>At the end of the process, a pdf of the manuscript will be created in the project folder.</li>
</ol>

<details open="">
  <summary>
    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true">
    <path d="M16 3.75v8.5a.75.75 0 0 1-1.136.643L11 10.575v.675A1.75 1.75 0 0 1 9.25 13h-7.5A1.75 1.75 0 0 1 0 11.25v-6.5C0 3.784.784 3 1.75 3h7.5c.966 0 1.75.784 1.75 1.75v.675l3.864-2.318A.75.75 0 0 1 16 3.75Zm-6.5 1a.25.25 0 0 0-.25-.25h-7.5a.25.25 0 0 0-.25.25v6.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-6.5ZM11 8.825l3.5 2.1v-5.85l-3.5 2.1Z"></path>
</svg>
    <span aria-label="Video description data-to-paper-demo.mp4">data-to-paper-demo.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/65530510/326834210-878865a7-45b4-496c-a62f-71d0003ce44b.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTU0OTgyMjEsIm5iZiI6MTcxNTQ5NzkyMSwicGF0aCI6Ii82NTUzMDUxMC8zMjY4MzQyMTAtODc4ODY1YTctNDViNC00OTZjLWE2MmYtNzFkMDAwM2NlNDRiLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MTIlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTEyVDA3MTIwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWEzZWU0YjcyYWFjM2U4MGU0ZDc3OWFiNTU5M2MyOTFlN2RiMjVjMWUyYWY1ZjI1N2Q2YzA0YTlmMThmNWJkYzcmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.7ctMfXA-ycJtc9_7KytJ_LJ82YgYf8BwWQJY6lVNq8c" data-canonical-src="https://private-user-images.githubusercontent.com/65530510/326834210-878865a7-45b4-496c-a62f-71d0003ce44b.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTU0OTgyMjEsIm5iZiI6MTcxNTQ5NzkyMSwicGF0aCI6Ii82NTUzMDUxMC8zMjY4MzQyMTAtODc4ODY1YTctNDViNC00OTZjLWE2MmYtNzFkMDAwM2NlNDRiLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDA1MTIlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwNTEyVDA3MTIwMVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWEzZWU0YjcyYWFjM2U4MGU0ZDc3OWFiNTU5M2MyOTFlN2RiMjVjMWUyYWY1ZjI1N2Q2YzA0YTlmMThmNWJkYzcmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.7ctMfXA-ycJtc9_7KytJ_LJ82YgYf8BwWQJY6lVNq8c" controls="controls" muted="muted">

  </video>
</details>


<p dir="auto">We ran <strong>data-to-paper</strong> on the following test cases:</p>
<ul dir="auto">
<li>
<p dir="auto"><strong>Health Indicators (open goal).</strong> A clean unweighted subset of CDC’s Behavioral Risk Factor Surveillance System (BRFSS) 2015 annual dataset
(<a href="https://www.kaggle.com/datasets/alexteboul/diabetes-health-indicators-dataset" rel="nofollow">Kaggle</a>).</p>
<p dir="auto">Branch: <code>examples/diabetes</code></p>
</li>
<li>
<p dir="auto"><strong>Social Network (open goal).</strong> A directed graph of Twitter interactions among the 117th Congress members
(<a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC10493874/" rel="nofollow">Fink et al</a>).</p>
<p dir="auto">Branch: <code>examples/congress_social_network</code></p>
</li>
<li>
<p dir="auto"><strong>Treatment Policy (fixed-goal).</strong> A dataset on treatment and outcomes of non-vigorous infants admitted to the Neonatal Intensive Care Unit (NICU), before and after a change to treatment guidelines was implemented
(<a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0289945" rel="nofollow">Saint-Fleur et al</a>).</p>
<p dir="auto">Branch: <code>examples/nicu</code></p>
</li>
<li>
<p dir="auto"><strong>Treatment Optimization (fixed-goal).</strong> A dataset of pediatric patients, which received mechanical ventilation after undergoing surgery, including an x-ray-based determination of the optimal tracheal tube intubation depth and a set of personalized patient attributes to be used in machine learning and formula-based models to predict this optimal depth
(<a href="https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0257069" rel="nofollow">Shim et al</a>).</p>
<p dir="auto">Branch: <code>examples/tube_levels</code></p>
</li>
</ul>

<p dir="auto">We invite people to try out <strong>data-to-paper</strong> with their own data and are eager for feedback and suggestions.
It is currently designed for relatively simple research goals and simple datasets, where
we want to raise and test a statistical hypothesis.</p>
<p dir="auto">We also invite people to help develop and extend the <strong>data-to-paper</strong> framework in science or other fields.</p>

<p dir="auto"><strong>Disclaimer.</strong> By using this software, you agree to assume all risks associated with its use, including but not limited
to data loss, system failure, or any other issues that may arise, especially, but not limited to, the
consequences of running of LLM created code on your local machine. The developers of this project
do not accept any responsibility or liability for any losses, damages, or other consequences that may occur as
a result of using this software.</p>
<p dir="auto"><strong>Accountability.</strong> You are solely responsible for the entire content of
created manuscripts including their rigour, quality, ethics and any other aspect.
The process should be overseen and directed by a human-in-the-loop and created manuscripts should be carefully vetted
by a domain expert.
The process is NOT error-proof and human intervention is <em>necessary</em> to ensure accuracy and the quality of the results.</p>
<p dir="auto"><strong>Compliance.</strong> It is your responsibility to ensure that any actions or decisions made based on the output of this
software comply with all applicable laws, regulations, and ethical standards.
The developers and contributors of this project shall not be held responsible for any consequences arising from
using this software. Further, data-to-paper manuscripts are watermarked for transparency as AI-created.
Users should not remove this watermark.</p>
<p dir="auto"><strong>Token Usage.</strong> Please note that the use of most language models through external APIs, especially GPT4,
can be expensive due to its token usage. By utilizing this project, you acknowledge that you are
responsible for monitoring and managing your own token usage and the associated costs.
It is highly recommended to check your API usage regularly and set up any necessary limits or alerts to
prevent unexpected charges.</p>

<p dir="auto">Here are some other cool multi-agent relted projects:</p>
<ul dir="auto">
<li><a href="https://github.com/langchain-ai/langchain">LangChain</a></li>
<li><a href="https://microsoft.github.io/autogen/" rel="nofollow">AutoGen</a></li>
<li><a href="https://github.com/Significant-Gravitas/AutoGPT">AutoGPT</a></li>
<li><a href="https://github.com/geekan/MetaGPT">MetaGPT</a></li>
</ul>
<p dir="auto">And also this curated list of AI agents projects <a href="https://github.com/kyrolabs/awesome-agents">awesome-agents</a></p>
</article></div></div>
  </body>
</html>
