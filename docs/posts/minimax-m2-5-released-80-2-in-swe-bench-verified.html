<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.minimax.io/news/minimax-m25">Original</a>
    <h1>MiniMax M2.5 released: 80.2% in SWE-bench Verified</h1>
    
    <div id="readability-page-1" class="page"><div><div><p><img alt="https://file.cdn.minimax.io/public/60e15b62-aece-42ab-898f-ce97c59f3941.png" fetchpriority="high" decoding="async" data-nimg="fill" sizes="100vw" srcset="/_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F60e15b62-aece-42ab-898f-ce97c59f3941.png&amp;w=640&amp;q=75 640w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F60e15b62-aece-42ab-898f-ce97c59f3941.png&amp;w=750&amp;q=75 750w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F60e15b62-aece-42ab-898f-ce97c59f3941.png&amp;w=828&amp;q=75 828w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F60e15b62-aece-42ab-898f-ce97c59f3941.png&amp;w=1080&amp;q=75 1080w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F60e15b62-aece-42ab-898f-ce97c59f3941.png&amp;w=1200&amp;q=75 1200w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F60e15b62-aece-42ab-898f-ce97c59f3941.png&amp;w=1920&amp;q=75 1920w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F60e15b62-aece-42ab-898f-ce97c59f3941.png&amp;w=2048&amp;q=75 2048w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F60e15b62-aece-42ab-898f-ce97c59f3941.png&amp;w=3840&amp;q=75 3840w" src="https://www.minimax.io/_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F60e15b62-aece-42ab-898f-ce97c59f3941.png&amp;w=3840&amp;q=75"/></p></div><div><div><p><img alt="" fetchpriority="high" decoding="async" data-nimg="fill" sizes="100vw" srcset="/_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F97f76950-2c60-4a9b-bb96-228454afabe9.png&amp;w=640&amp;q=75 640w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F97f76950-2c60-4a9b-bb96-228454afabe9.png&amp;w=750&amp;q=75 750w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F97f76950-2c60-4a9b-bb96-228454afabe9.png&amp;w=828&amp;q=75 828w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F97f76950-2c60-4a9b-bb96-228454afabe9.png&amp;w=1080&amp;q=75 1080w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F97f76950-2c60-4a9b-bb96-228454afabe9.png&amp;w=1200&amp;q=75 1200w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F97f76950-2c60-4a9b-bb96-228454afabe9.png&amp;w=1920&amp;q=75 1920w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F97f76950-2c60-4a9b-bb96-228454afabe9.png&amp;w=2048&amp;q=75 2048w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F97f76950-2c60-4a9b-bb96-228454afabe9.png&amp;w=3840&amp;q=75 3840w" src="https://www.minimax.io/_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F97f76950-2c60-4a9b-bb96-228454afabe9.png&amp;w=3840&amp;q=75"/></p></div></div><h3>Coding</h3><p>In programming evaluations, MiniMax-M2.5 saw substantial improvements compared to previous generations, reaching SOTA levels. The performance of M2.5 in multilingual coding tasks is especially pronounced.<br/></p><div><div><p><img alt="" fetchpriority="high" decoding="async" data-nimg="fill" sizes="100vw" srcset="/_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F54ddb070-9654-47a0-83c4-1bbf7c7ff0d5.png&amp;w=640&amp;q=75 640w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F54ddb070-9654-47a0-83c4-1bbf7c7ff0d5.png&amp;w=750&amp;q=75 750w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F54ddb070-9654-47a0-83c4-1bbf7c7ff0d5.png&amp;w=828&amp;q=75 828w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F54ddb070-9654-47a0-83c4-1bbf7c7ff0d5.png&amp;w=1080&amp;q=75 1080w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F54ddb070-9654-47a0-83c4-1bbf7c7ff0d5.png&amp;w=1200&amp;q=75 1200w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F54ddb070-9654-47a0-83c4-1bbf7c7ff0d5.png&amp;w=1920&amp;q=75 1920w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F54ddb070-9654-47a0-83c4-1bbf7c7ff0d5.png&amp;w=2048&amp;q=75 2048w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F54ddb070-9654-47a0-83c4-1bbf7c7ff0d5.png&amp;w=3840&amp;q=75 3840w" src="https://www.minimax.io/_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F54ddb070-9654-47a0-83c4-1bbf7c7ff0d5.png&amp;w=3840&amp;q=75"/></p></div></div><div><div><p><img alt="" fetchpriority="high" decoding="async" data-nimg="fill" sizes="100vw" srcset="/_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F013a2750-d042-482b-a97f-d9c67906b286.png&amp;w=640&amp;q=75 640w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F013a2750-d042-482b-a97f-d9c67906b286.png&amp;w=750&amp;q=75 750w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F013a2750-d042-482b-a97f-d9c67906b286.png&amp;w=828&amp;q=75 828w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F013a2750-d042-482b-a97f-d9c67906b286.png&amp;w=1080&amp;q=75 1080w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F013a2750-d042-482b-a97f-d9c67906b286.png&amp;w=1200&amp;q=75 1200w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F013a2750-d042-482b-a97f-d9c67906b286.png&amp;w=1920&amp;q=75 1920w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F013a2750-d042-482b-a97f-d9c67906b286.png&amp;w=2048&amp;q=75 2048w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F013a2750-d042-482b-a97f-d9c67906b286.png&amp;w=3840&amp;q=75 3840w" src="https://www.minimax.io/_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F013a2750-d042-482b-a97f-d9c67906b286.png&amp;w=3840&amp;q=75"/></p></div></div><h3>Search and Tool calling</h3><div><div><p><img alt="" fetchpriority="high" decoding="async" data-nimg="fill" sizes="100vw" srcset="/_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F30812ab3-fa8d-439e-b731-c1f73b77c2ee.png&amp;w=640&amp;q=75 640w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F30812ab3-fa8d-439e-b731-c1f73b77c2ee.png&amp;w=750&amp;q=75 750w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F30812ab3-fa8d-439e-b731-c1f73b77c2ee.png&amp;w=828&amp;q=75 828w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F30812ab3-fa8d-439e-b731-c1f73b77c2ee.png&amp;w=1080&amp;q=75 1080w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F30812ab3-fa8d-439e-b731-c1f73b77c2ee.png&amp;w=1200&amp;q=75 1200w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F30812ab3-fa8d-439e-b731-c1f73b77c2ee.png&amp;w=1920&amp;q=75 1920w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F30812ab3-fa8d-439e-b731-c1f73b77c2ee.png&amp;w=2048&amp;q=75 2048w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F30812ab3-fa8d-439e-b731-c1f73b77c2ee.png&amp;w=3840&amp;q=75 3840w" src="https://www.minimax.io/_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F30812ab3-fa8d-439e-b731-c1f73b77c2ee.png&amp;w=3840&amp;q=75"/></p></div></div><h3>Office work</h3><div><p>M2.5 was trained to produce truly deliverable outputs in office scenarios. To this end, we engaged in thorough collaboration with senior professionals in fields such as <strong>finance, law, and social sciences</strong>. They designed requirements, provided feedback, participated in defining standards, and directly contributed to data construction, bringing the tacit knowledge of their industries into the model&#39;s training pipeline. Based on this foundation, M2.5 has achieved significant capability improvements in high-value workspace scenarios such as Word, PowerPoint, and Excel financial modeling. On the evaluation side, we built an internal Cowork Agent evaluation framework (GDPval-MM) that assesses both the quality of the deliverable and the professionalism of the agent&#39;s trajectory through pairwise comparisons, while also monitoring token costs across the entire workflow to estimate the model&#39;s real-world productivity gains. In comparisons against other mainstream models, it achieved an average win rate of 59.0%.</p></div><div><div><p><img alt="" fetchpriority="high" decoding="async" data-nimg="fill" sizes="100vw" srcset="/_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F0a215c3a-eb6d-422e-ad79-60b00b789608.png&amp;w=640&amp;q=75 640w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F0a215c3a-eb6d-422e-ad79-60b00b789608.png&amp;w=750&amp;q=75 750w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F0a215c3a-eb6d-422e-ad79-60b00b789608.png&amp;w=828&amp;q=75 828w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F0a215c3a-eb6d-422e-ad79-60b00b789608.png&amp;w=1080&amp;q=75 1080w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F0a215c3a-eb6d-422e-ad79-60b00b789608.png&amp;w=1200&amp;q=75 1200w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F0a215c3a-eb6d-422e-ad79-60b00b789608.png&amp;w=1920&amp;q=75 1920w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F0a215c3a-eb6d-422e-ad79-60b00b789608.png&amp;w=2048&amp;q=75 2048w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F0a215c3a-eb6d-422e-ad79-60b00b789608.png&amp;w=3840&amp;q=75 3840w" src="https://www.minimax.io/_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F0a215c3a-eb6d-422e-ad79-60b00b789608.png&amp;w=3840&amp;q=75"/></p></div></div><h3>Efficiency</h3><div><p>Because the real world is full of deadlines and time constraints, task completion speed is a practical necessity. The time it takes a model to complete a task depends on its task decomposition effectiveness, token efficiency, and inference speed. M2.5 is served natively at a rate of 100 tokens per second, which is nearly twice that of other frontier models. Further, our reinforcement learning setup incentivizes the model to reason efficiently and break down tasks optimally. Due to these three factors, M2.5 delivers a significant time savings in complex task completion.</p></div><h3>Cost</h3><div><p>Our goal in designing the M2-series of foundation models is to power complex agents without having to worry about cost. We believe that M2.5 is close to realizing this goal. We’re releasing two versions of the model, M2.5 and M2.5-Lightning, that are identical in capability but differ in speed. M2.5-Lightning has a steady throughput of 100 tokens per second, which is two times faster than other frontier models, and costs $0.3 per million input tokens and $2.4 per million output tokens. M2.5, which has a throughput of 50 tokens per second, costs half that. Both model versions support caching. Based on output price, the cost of M2.5 is one-tenth to one-twentieth that of Opus, Gemini 3 Pro, and GPT-5.</p></div><h3>Improvement Rate</h3><div><p>Over the three and a half months from late October to now, we have successively released M2, M2.1, and M2.5, with the pace of model improvement exceeding our original expectations. For instance, in the highly-regarded  SWE-Bench Verified benchmark, the rate of progress of the M2-series has been significantly faster than that of peers such as the Claude, GPT, and Gemini model families.</p></div><div><div><p><img alt="" fetchpriority="high" decoding="async" data-nimg="fill" sizes="100vw" srcset="/_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F446f220e-cefd-459f-907d-ccbf535b7d15.png&amp;w=640&amp;q=75 640w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F446f220e-cefd-459f-907d-ccbf535b7d15.png&amp;w=750&amp;q=75 750w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F446f220e-cefd-459f-907d-ccbf535b7d15.png&amp;w=828&amp;q=75 828w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F446f220e-cefd-459f-907d-ccbf535b7d15.png&amp;w=1080&amp;q=75 1080w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F446f220e-cefd-459f-907d-ccbf535b7d15.png&amp;w=1200&amp;q=75 1200w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F446f220e-cefd-459f-907d-ccbf535b7d15.png&amp;w=1920&amp;q=75 1920w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F446f220e-cefd-459f-907d-ccbf535b7d15.png&amp;w=2048&amp;q=75 2048w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F446f220e-cefd-459f-907d-ccbf535b7d15.png&amp;w=3840&amp;q=75 3840w" src="https://www.minimax.io/_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F446f220e-cefd-459f-907d-ccbf535b7d15.png&amp;w=3840&amp;q=75"/></p></div></div><h3>RL Scaling</h3><div><p>One of the key drivers of the aforementioned developments is the scaling of reinforcement learning. As we train our models, we also benefit from their abilities. Most of the tasks and workspaces that we perform in our company have been made into training environments for RL. To date, there are already hundreds of thousands of such environments. At the same time, we did plenty of work on our agentic RL framework, algorithms, reward signals, and infrastructure engineering to support the continued scaling of our RL training.</p></div><h3>Forge –– Agent-Native RL Framework</h3><div><p>We designed an agent-native RL framework in-house, called Forge, which introduces an intermediary layer that fully decouples the underlying training-inference engine from the agent, supporting the integration of arbitrary agents and enabling us to optimize the model&#39;s generalization across agent scaffolds and tools. To improve system throughput, we optimized asynchronous scheduling strategies to balance system throughput against sample off-policyness, and designed a tree-structured merging strategy for training samples, achieving approximately 40x training speedup.</p></div><div><div><p><img alt="" fetchpriority="high" decoding="async" data-nimg="fill" sizes="100vw" srcset="/_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2Fd1bf56f3-3547-46d1-b901-785aab0b01b0.png&amp;w=640&amp;q=75 640w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2Fd1bf56f3-3547-46d1-b901-785aab0b01b0.png&amp;w=750&amp;q=75 750w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2Fd1bf56f3-3547-46d1-b901-785aab0b01b0.png&amp;w=828&amp;q=75 828w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2Fd1bf56f3-3547-46d1-b901-785aab0b01b0.png&amp;w=1080&amp;q=75 1080w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2Fd1bf56f3-3547-46d1-b901-785aab0b01b0.png&amp;w=1200&amp;q=75 1200w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2Fd1bf56f3-3547-46d1-b901-785aab0b01b0.png&amp;w=1920&amp;q=75 1920w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2Fd1bf56f3-3547-46d1-b901-785aab0b01b0.png&amp;w=2048&amp;q=75 2048w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2Fd1bf56f3-3547-46d1-b901-785aab0b01b0.png&amp;w=3840&amp;q=75 3840w" src="https://www.minimax.io/_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2Fd1bf56f3-3547-46d1-b901-785aab0b01b0.png&amp;w=3840&amp;q=75"/></p></div></div><h3>Agentic RL Algorithm and Reward Design</h3><p>On the algorithm side, we continued using the CISPO algorithm we proposed at the beginning of last year to ensure the stability of MoE models during large-scale training. To address the credit assignment challenge posed by long contexts in agent rollouts, we introduced a process reward mechanism for end-to-end monitoring of generation quality. Furthermore, to deeply align with user experience, we evaluated task completion time through agent trajectories, achieving an optimal trade-off between model intelligence and response speed.</p><div><div><p><img alt="" fetchpriority="high" decoding="async" data-nimg="fill" sizes="100vw" srcset="/_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2Fad0df79a-da5b-4432-b6d5-b5c53349a1e8.png&amp;w=640&amp;q=75 640w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2Fad0df79a-da5b-4432-b6d5-b5c53349a1e8.png&amp;w=750&amp;q=75 750w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2Fad0df79a-da5b-4432-b6d5-b5c53349a1e8.png&amp;w=828&amp;q=75 828w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2Fad0df79a-da5b-4432-b6d5-b5c53349a1e8.png&amp;w=1080&amp;q=75 1080w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2Fad0df79a-da5b-4432-b6d5-b5c53349a1e8.png&amp;w=1200&amp;q=75 1200w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2Fad0df79a-da5b-4432-b6d5-b5c53349a1e8.png&amp;w=1920&amp;q=75 1920w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2Fad0df79a-da5b-4432-b6d5-b5c53349a1e8.png&amp;w=2048&amp;q=75 2048w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2Fad0df79a-da5b-4432-b6d5-b5c53349a1e8.png&amp;w=3840&amp;q=75 3840w" src="https://www.minimax.io/_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2Fad0df79a-da5b-4432-b6d5-b5c53349a1e8.png&amp;w=3840&amp;q=75"/></p></div></div><div><p>We will release a more comprehensive introduction to RL scaling soon in a separate technical blogpost.</p></div><h3>MiniMax Agent: M2.5 as a Professional Employee</h3><div><p>M2.5 has been fully deployed in MiniMax Agent, delivering the best agentic experience.</p></div><h3>Appendix</h3><p>Further benchmark results of M2.5:</p><div><div><p><img alt="" fetchpriority="high" decoding="async" data-nimg="fill" sizes="100vw" srcset="/_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F8c019213-b0d5-4ee8-9273-6d9b799abeae.png&amp;w=640&amp;q=75 640w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F8c019213-b0d5-4ee8-9273-6d9b799abeae.png&amp;w=750&amp;q=75 750w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F8c019213-b0d5-4ee8-9273-6d9b799abeae.png&amp;w=828&amp;q=75 828w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F8c019213-b0d5-4ee8-9273-6d9b799abeae.png&amp;w=1080&amp;q=75 1080w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F8c019213-b0d5-4ee8-9273-6d9b799abeae.png&amp;w=1200&amp;q=75 1200w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F8c019213-b0d5-4ee8-9273-6d9b799abeae.png&amp;w=1920&amp;q=75 1920w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F8c019213-b0d5-4ee8-9273-6d9b799abeae.png&amp;w=2048&amp;q=75 2048w, /_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F8c019213-b0d5-4ee8-9273-6d9b799abeae.png&amp;w=3840&amp;q=75 3840w" src="https://www.minimax.io/_next/image?url=https%3A%2F%2Ffile.cdn.minimax.io%2Fpublic%2F8c019213-b0d5-4ee8-9273-6d9b799abeae.png&amp;w=3840&amp;q=75"/></p></div></div><h3>Evaluation methods:</h3><p><em><ul>
  <li><strong>SWE benchmark:</strong> SWE-bench Verified, SWE-bench Multilingual, SWE-bench-pro, and Multi-SWE-bench were tested on internal infrastructure using Claude Code as the scaffolding, with the default system prompt overridden, and results averaged over 4 runs. Additionally, SWE-bench Verified was also evaluated on the Droid and Opencode scaffoldings using the default prompt.</li>
  <li><strong>Terminal Bench 2:</strong> We tested Terminal Bench 2 using Claude Code 2.0.64 as the evaluation scaffolding. We modified the Dockerfiles of some problems to ensure the correctness of the problems themselves, uniformly expanded sandbox specifications to 8-core CPU and 16 GB memory, set the timeout uniformly to 7,200 seconds, and equipped each problem with a basic toolset (ps, curl, git, etc.). While not retrying on timeouts, we added a detection mechanism for empty scaffolding responses, retrying tasks whose final response was empty to handle various abnormal interruption scenarios. Final results are averaged over 4 runs.</li>
  <li><strong>VIBE-Pro:</strong> Internal benchmark. Uses Claude Code as the scaffolding to automatically verify the interaction logic and visual effects of programs. All scores are computed through a unified pipeline that includes a requirements set, containerized deployment, and a dynamic interaction environment. Final results are averaged over 3 runs.</li>
  <li><strong>BrowseComp:</strong> Uses the same agent framework as WebExplorer (Liu et al., 2025). When token usage exceeds 30% of the maximum context, all history is discarded.</li>
  <li><strong>Wide Search:</strong> Uses the same agent framework as WebExplorer (Liu et al., 2025).</li>
  <li><strong>RISE:</strong> Internal benchmark. Contains real questions from human experts, evaluating the model&#39;s multi-step information retrieval and reasoning capabilities when combined with complex web interactions. A Playwright-based browser tool suite is added on top of the WebExplorer (Liu et al., 2025) agent framework.</li>
  <li><strong>GDPval-MM:</strong> Internal benchmark. Based on the open-source GDPval test set, using a custom agentic evaluation framework where an LLM-as-a-judge performs pairwise win/tie/loss judgments on complete trajectories. Average token cost per task is calculated based on each vendor&#39;s official API pricing (without caching).</li>
  <li><strong>MEWC:</strong> Internal benchmark. Built on MEWC (Microsoft Excel World Championship), comprising 179 problems from the main and other regional divisions of Excel esports competitions from 2021–2026. It evaluates the model&#39;s ability to understand competition Excel spreadsheets and use Excel tools to complete problems. Scores are calculated by comparing output and answer cell values one by one.</li>
  <li><strong>Finance Modeling:</strong> Internal benchmark. Primarily contains financial modeling problems constructed by industry experts, involving end-to-end research and analysis tasks performed via Excel tools. Each problem is scored using expert-designed rubrics. Final results are averaged over 3 runs.</li>
  <li><strong>AIME25 ~ AA-LCR:</strong> Obtained through internal testing based on the public evaluation sets and evaluation methods covered by the Artificial Analysis Intelligence Index leaderboard.</li>
</ul></em>
</p></div></div>
  </body>
</html>
