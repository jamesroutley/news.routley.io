<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.servethehome.com/chatgpt-hardware-a-look-at-8x-nvidia-a100-systems-powering-the-tool-openai-microsoft-azure-supermicro-inspur-asus-dell-gigabyte/">Original</a>
    <h1>ChatGPT Hardware: A look at 8x NVIDIA A100 powering the tool</h1>
    
    <div id="readability-page-1" class="page"><div>
            <!-- image --><div><figure><a href="https://www.servethehome.com/wp-content/uploads/2021/07/Inspur-NF5488A5-NVIDIA-HGX-A100-8-GPU-Assembly-8x-A100-2.jpg" data-caption="Inspur NF5488A5 NVIDIA HGX A100 8 GPU Assembly 8x A100 2"><img width="696" height="465" src="https://www.servethehome.com/wp-content/uploads/2021/07/Inspur-NF5488A5-NVIDIA-HGX-A100-8-GPU-Assembly-8x-A100-2-696x465.jpg" srcset="https://www.servethehome.com/wp-content/uploads/2021/07/Inspur-NF5488A5-NVIDIA-HGX-A100-8-GPU-Assembly-8x-A100-2-696x465.jpg 696w, https://www.servethehome.com/wp-content/uploads/2021/07/Inspur-NF5488A5-NVIDIA-HGX-A100-8-GPU-Assembly-8x-A100-2-400x267.jpg 400w, https://www.servethehome.com/wp-content/uploads/2021/07/Inspur-NF5488A5-NVIDIA-HGX-A100-8-GPU-Assembly-8x-A100-2-629x420.jpg 629w, https://www.servethehome.com/wp-content/uploads/2021/07/Inspur-NF5488A5-NVIDIA-HGX-A100-8-GPU-Assembly-8x-A100-2.jpg 800w" sizes="(max-width: 696px) 100vw, 696px" alt="Inspur NF5488A5 NVIDIA HGX A100 8 GPU Assembly 8x A100 2" title="Inspur NF5488A5 NVIDIA HGX A100 8 GPU Assembly 8x A100 2"/></a><figcaption>Inspur NF5488A5 NVIDIA HGX A100 8 GPU Assembly 8x A100 2</figcaption></figure></div>
            <!-- content --><p>ChatGPT is something we have used over the past few months, mostly as a fun experiment. We have heard that the NVIDIA A100’s are being used for that. Many folks are using ChatGPT that have never seen or used a NVIDIA A100. That makes sense since they are often priced at $10,000+ each, and so getting an 8x NVIDIA A100 system starts around $100,000 at the lower end. We figured it would be worth a second to run through the STH archives and show you what the NVIDIA A100 looks like.<span id="more-67242"></span></p>
<h2>ChatGPT Hardware a Look at 8x NVIDIA A100 Powering the Tool</h2>
<p>First, what is a NVIDIA A100 anyway? Many folks understand the concept of a GPU since it is a common component in desktop systems. Usually, GPUs are PCIe cards and can be used for gaming or has become more common in servers. NVIDIA makes A100 GPUs specifically for these types of systems.</p>
<figure id="attachment_64182" aria-describedby="caption-attachment-64182"><a href="https://www.servethehome.com/the-most-important-server-of-2022-the-gigabyte-ampere-altra-max-and-nvidia-a100/nvidia-a100-80gb-pcie-2/" rel="attachment wp-att-64182"><img src="https://www.servethehome.com/wp-content/uploads/2022/09/NVIDIA-A100-80GB-PCIe-2.jpg" alt="NVIDIA A100 80GB PCIe 2" width="800" height="479" srcset="https://www.servethehome.com/wp-content/uploads/2022/09/NVIDIA-A100-80GB-PCIe-2.jpg 800w, https://www.servethehome.com/wp-content/uploads/2022/09/NVIDIA-A100-80GB-PCIe-2-400x240.jpg 400w, https://www.servethehome.com/wp-content/uploads/2022/09/NVIDIA-A100-80GB-PCIe-2-696x417.jpg 696w, https://www.servethehome.com/wp-content/uploads/2022/09/NVIDIA-A100-80GB-PCIe-2-701x420.jpg 701w" sizes="(max-width: 800px) 100vw, 800px"/></a><figcaption id="caption-attachment-64182">NVIDIA A100 80GB PCIe 2</figcaption></figure>
<p>There are a few differences between the NVIDIA A100 and NVIDIA’s GeForce series commonly found in gaming. For one, the NVIDIA A100 is designed wit server cooling in mind. That means there are no fans and they are designed to be packed densely into tight systems.</p>
<figure id="attachment_51544" aria-describedby="caption-attachment-51544"><a href="https://www.servethehome.com/amd-epyc-7003-milan-the-fast-gets-faster/asus-rs720a-e11-rs24u-amd-epyc-7003-and-nvidia-a100-pcie/" rel="attachment wp-att-51544"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2021/03/ASUS-RS720A-E11-RS24U-AMD-EPYC-7003-and-NVIDIA-A100-PCIe.jpg" alt="ASUS RS720A E11 RS24U AMD EPYC 7003 And NVIDIA A100 PCIe" width="800" height="534" srcset="https://www.servethehome.com/wp-content/uploads/2021/03/ASUS-RS720A-E11-RS24U-AMD-EPYC-7003-and-NVIDIA-A100-PCIe.jpg 800w, https://www.servethehome.com/wp-content/uploads/2021/03/ASUS-RS720A-E11-RS24U-AMD-EPYC-7003-and-NVIDIA-A100-PCIe-400x267.jpg 400w, https://www.servethehome.com/wp-content/uploads/2021/03/ASUS-RS720A-E11-RS24U-AMD-EPYC-7003-and-NVIDIA-A100-PCIe-696x465.jpg 696w, https://www.servethehome.com/wp-content/uploads/2021/03/ASUS-RS720A-E11-RS24U-AMD-EPYC-7003-and-NVIDIA-A100-PCIe-629x420.jpg 629w" sizes="(max-width: 800px) 100vw, 800px"/></a><figcaption id="caption-attachment-51544">ASUS RS720A E11 RS24U AMD EPYC 7003 And NVIDIA A100 PCIe</figcaption></figure>
<p>While the GPUs have high-speed interconnects, called NVLink even in this PCIe form factor, these are not GPUs meant for gaming. The A100 is specifically tuned toward AI and high-performance computation instead of rendering 3D frames quickly for gaming.</p>
<figure id="attachment_53552" aria-describedby="caption-attachment-53552"><a href="https://www.servethehome.com/asrock-rack-2u4g-rome-2t-review-amd-epyc-and-4x-gpu-server/2x-nvidia-a100-pcie-with-nvlink-bridges-installed/" rel="attachment wp-att-53552"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2021/06/2x-NVIDIA-A100-PCIe-with-NVLink-Bridges-Installed.jpg" alt="2x NVIDIA A100 PCIe With NVLink Bridges Installed" width="800" height="528" srcset="https://www.servethehome.com/wp-content/uploads/2021/06/2x-NVIDIA-A100-PCIe-with-NVLink-Bridges-Installed.jpg 800w, https://www.servethehome.com/wp-content/uploads/2021/06/2x-NVIDIA-A100-PCIe-with-NVLink-Bridges-Installed-400x264.jpg 400w, https://www.servethehome.com/wp-content/uploads/2021/06/2x-NVIDIA-A100-PCIe-with-NVLink-Bridges-Installed-696x459.jpg 696w, https://www.servethehome.com/wp-content/uploads/2021/06/2x-NVIDIA-A100-PCIe-with-NVLink-Bridges-Installed-636x420.jpg 636w" sizes="(max-width: 800px) 100vw, 800px"/></a><figcaption id="caption-attachment-53552">2x NVIDIA A100 PCIe With NVLink Bridges Installed</figcaption></figure>
<p>A great example of why this is the case can be seen on the back of the NVIDIA A100 GPUs. Here, the bracket simply has an exhaust for cooling airflow. These do not have display outputs to connect a monitor or TV.</p>
<p>Most 8x NVIDIA A100 systems, especially at larger cloud service providers, use a special NVIDIA-only form factor called SXM4. In the picture below, the GPU is around the black layer near the bottom of the assembly. Over 80% of this assembly is a heatsink to dissipate massive heat. While the PCIe variants that look like gaming GPUs above are usually only able to handle 250W-300W, the SXM4 variants handle 400-500W each. That extra power allows for more performance per A100.</p>
<figure id="attachment_61370" aria-describedby="caption-attachment-61370"><a href="https://www.servethehome.com/nvidia-connectx-7-shown-at-isc-2022-supermicro/nvidia-a100-sxm-at-isc-2022-side/" rel="attachment wp-att-61370"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2022/05/NVIDIA-A100-SXM-at-ISC-2022-Side.jpg" alt="NVIDIA A100 SXM At ISC 2022 Side" width="800" height="577" srcset="https://www.servethehome.com/wp-content/uploads/2022/05/NVIDIA-A100-SXM-at-ISC-2022-Side.jpg 800w, https://www.servethehome.com/wp-content/uploads/2022/05/NVIDIA-A100-SXM-at-ISC-2022-Side-400x289.jpg 400w, https://www.servethehome.com/wp-content/uploads/2022/05/NVIDIA-A100-SXM-at-ISC-2022-Side-696x502.jpg 696w, https://www.servethehome.com/wp-content/uploads/2022/05/NVIDIA-A100-SXM-at-ISC-2022-Side-582x420.jpg 582w, https://www.servethehome.com/wp-content/uploads/2022/05/NVIDIA-A100-SXM-at-ISC-2022-Side-324x235.jpg 324w" sizes="(max-width: 800px) 100vw, 800px"/></a><figcaption id="caption-attachment-61370">NVIDIA A100 SXM At ISC 2022 Side</figcaption></figure>
<p>Each of these SXM4 A100’s is not sold as a single unit. Instead, they are sold in either 4 or 8 GPU subsystems because of how challenging the SXM installation is. The caps below each hide a sea of electrical pins. One bent pin, or even tightening the heatsink onto the GPU too tight, can destroy a GPU that costs as much as a car.</p>
<figure id="attachment_61369" aria-describedby="caption-attachment-61369"><a href="https://www.servethehome.com/nvidia-connectx-7-shown-at-isc-2022-supermicro/nvidia-a100-sxm-at-isc-2022-bottom/" rel="attachment wp-att-61369"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2022/05/NVIDIA-A100-SXM-at-ISC-2022-Bottom.jpg" alt="NVIDIA A100 SXM At ISC 2022 Bottom" width="800" height="480" srcset="https://www.servethehome.com/wp-content/uploads/2022/05/NVIDIA-A100-SXM-at-ISC-2022-Bottom.jpg 800w, https://www.servethehome.com/wp-content/uploads/2022/05/NVIDIA-A100-SXM-at-ISC-2022-Bottom-400x240.jpg 400w, https://www.servethehome.com/wp-content/uploads/2022/05/NVIDIA-A100-SXM-at-ISC-2022-Bottom-696x418.jpg 696w, https://www.servethehome.com/wp-content/uploads/2022/05/NVIDIA-A100-SXM-at-ISC-2022-Bottom-700x420.jpg 700w" sizes="(max-width: 800px) 100vw, 800px"/></a><figcaption id="caption-attachment-61369">NVIDIA A100 SXM At ISC 2022 Bottom</figcaption></figure>
<p>The last ones we <a href="https://www.servethehome.com/how-to-install-nvidia-tesla-sxm2-gpus-in-deeplearning12/">installed ourselves</a> required a $350+ torque screwdriver to hit the tolerances we needed. You can find that old STH video here with the old P100 generation (wow this is an OLD one!):</p>
<p><iframe loading="lazy" title="NVIDIA Tesla SXM2 GPU Installation in DeepLearning12" width="696" height="392" src="https://www.youtube.com/embed/ipQXdjjAPGg?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p>
<p>In modern servers, these are installed with 8x SXM4 GPUs onto a baseboard called the NVIDIA HGX A100. Vendors such as Inspur, Supermicro, Quanta, and others then use this HGX A100 as the cornerstone of their own AI systems. These systems are so specialized that Dell EMC did not even start selling them until very recently with the <a href="https://www.servethehome.com/dell-poweredge-xe9680-8x-nvidia-h100-drops-emc-and-finally-covers-ai-intel/">Dell PowerEdge XE9680</a>.</p>
<figure id="attachment_54327" aria-describedby="caption-attachment-54327"><a href="https://www.servethehome.com/inspur-nf5488a5-8x-nvidia-a100-hgx-platform-review-amd-epyc/inspur-nf5488a5-nvidia-hgx-a100-8-gpu-assembly-19/" rel="attachment wp-att-54327"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2021/07/Inspur-NF5488A5-NVIDIA-HGX-A100-8-GPU-Assembly-19.jpg" alt="Inspur NF5488A5 NVIDIA HGX A100 8 GPU Assembly 19" width="800" height="431" srcset="https://www.servethehome.com/wp-content/uploads/2021/07/Inspur-NF5488A5-NVIDIA-HGX-A100-8-GPU-Assembly-19.jpg 800w, https://www.servethehome.com/wp-content/uploads/2021/07/Inspur-NF5488A5-NVIDIA-HGX-A100-8-GPU-Assembly-19-400x216.jpg 400w, https://www.servethehome.com/wp-content/uploads/2021/07/Inspur-NF5488A5-NVIDIA-HGX-A100-8-GPU-Assembly-19-696x375.jpg 696w, https://www.servethehome.com/wp-content/uploads/2021/07/Inspur-NF5488A5-NVIDIA-HGX-A100-8-GPU-Assembly-19-780x420.jpg 780w" sizes="(max-width: 800px) 100vw, 800px"/></a><figcaption id="caption-attachment-54327">Inspur NF5488A5 NVIDIA HGX A100 8 GPU Assembly 19</figcaption></figure>
<p>Each baseboard is designed to align eight of the NVIDIA A100 SXM4 GPUs into an array. PCIe connectivity is provided back to the host server using high-density edge connectors.</p>
<figure id="attachment_54319" aria-describedby="caption-attachment-54319"><a href="https://www.servethehome.com/inspur-nf5488a5-8x-nvidia-a100-hgx-platform-review-amd-epyc/inspur-nf5488a5-nvidia-hgx-a100-8-gpu-assembly-side-view-3/" rel="attachment wp-att-54319"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2021/07/Inspur-NF5488A5-NVIDIA-HGX-A100-8-GPU-Assembly-Side-View-3.jpg" alt="Inspur NF5488A5 NVIDIA HGX A100 8 GPU Assembly Side View 3" width="800" height="534" srcset="https://www.servethehome.com/wp-content/uploads/2021/07/Inspur-NF5488A5-NVIDIA-HGX-A100-8-GPU-Assembly-Side-View-3.jpg 800w, https://www.servethehome.com/wp-content/uploads/2021/07/Inspur-NF5488A5-NVIDIA-HGX-A100-8-GPU-Assembly-Side-View-3-400x267.jpg 400w, https://www.servethehome.com/wp-content/uploads/2021/07/Inspur-NF5488A5-NVIDIA-HGX-A100-8-GPU-Assembly-Side-View-3-696x465.jpg 696w, https://www.servethehome.com/wp-content/uploads/2021/07/Inspur-NF5488A5-NVIDIA-HGX-A100-8-GPU-Assembly-Side-View-3-629x420.jpg 629w" sizes="(max-width: 800px) 100vw, 800px"/></a><figcaption id="caption-attachment-54319">Inspur NF5488A5 NVIDIA HGX A100 8 GPU Assembly Side View 3</figcaption></figure>
<p>The other large heatsinks on the NVIDIA HGX A100 are to cool the NVSwitches. NVIDIA has its own high-speed interconnect that allows each A100 to talk to each other within a system at extremely high speeds.</p>
<figure id="attachment_54316" aria-describedby="caption-attachment-54316"><a href="https://www.servethehome.com/inspur-nf5488a5-8x-nvidia-a100-hgx-platform-review-amd-epyc/inspur-nf5488a5-nvidia-hgx-a100-8-gpu-assembly-larger-nvswitch-coolers/" rel="attachment wp-att-54316"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2021/07/Inspur-NF5488A5-NVIDIA-HGX-A100-8-GPU-Assembly-Larger-NVSwitch-Coolers.jpg" alt="Inspur NF5488A5 NVIDIA HGX A100 8 GPU Assembly Larger NVSwitch Coolers" width="800" height="501" srcset="https://www.servethehome.com/wp-content/uploads/2021/07/Inspur-NF5488A5-NVIDIA-HGX-A100-8-GPU-Assembly-Larger-NVSwitch-Coolers.jpg 800w, https://www.servethehome.com/wp-content/uploads/2021/07/Inspur-NF5488A5-NVIDIA-HGX-A100-8-GPU-Assembly-Larger-NVSwitch-Coolers-400x251.jpg 400w, https://www.servethehome.com/wp-content/uploads/2021/07/Inspur-NF5488A5-NVIDIA-HGX-A100-8-GPU-Assembly-Larger-NVSwitch-Coolers-696x436.jpg 696w, https://www.servethehome.com/wp-content/uploads/2021/07/Inspur-NF5488A5-NVIDIA-HGX-A100-8-GPU-Assembly-Larger-NVSwitch-Coolers-671x420.jpg 671w" sizes="(max-width: 800px) 100vw, 800px"/></a><figcaption id="caption-attachment-54316">Inspur NF5488A5 NVIDIA HGX A100 8 GPU Assembly Larger NVSwitch Coolers</figcaption></figure>
<p>In a server, here is what 8x NVIDIA A100 80GB 500W GPUs look like from a NVIDIA HGX A100 assembly above.</p>
<figure id="attachment_54167" aria-describedby="caption-attachment-54167"><a href="https://www.servethehome.com/graphcore-celebrates-a-stunning-loss-at-mlperf-training-v1-0/8x-nvidia-a100-500w-nvidia-smi-output/" rel="attachment wp-att-54167"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2021/07/8x-NVIDIA-A100-500W-nvidia-smi-output.jpg" alt="8x NVIDIA A100 500W Nvidia Smi Output" width="639" height="717" srcset="https://www.servethehome.com/wp-content/uploads/2021/07/8x-NVIDIA-A100-500W-nvidia-smi-output.jpg 639w, https://www.servethehome.com/wp-content/uploads/2021/07/8x-NVIDIA-A100-500W-nvidia-smi-output-267x300.jpg 267w, https://www.servethehome.com/wp-content/uploads/2021/07/8x-NVIDIA-A100-500W-nvidia-smi-output-374x420.jpg 374w" sizes="(max-width: 639px) 100vw, 639px"/></a><figcaption id="caption-attachment-54167">8x NVIDIA A100 500W Nvidia Smi Output</figcaption></figure>
<p>That means that a system with these will be very fast but can also use upwards of 5kW of power.</p>
<figure id="attachment_54805" aria-describedby="caption-attachment-54805"><a href="https://www.servethehome.com/liquid-cooling-next-gen-servers-getting-hands-on-3-options-supermicro/supermicro-as-04124go-nart-liquid-cooling-linpack-8x-a100-80gb-500w/" rel="attachment wp-att-54805"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2021/08/Supermicro-AS-04124GO-NART-Liquid-Cooling-Linpack-8x-A100-80GB-500W-800x353.jpg" alt="Supermicro AS 04124GO NART Liquid Cooling Linpack 8x A100 80GB 500W" width="696" height="307" srcset="https://www.servethehome.com/wp-content/uploads/2021/08/Supermicro-AS-04124GO-NART-Liquid-Cooling-Linpack-8x-A100-80GB-500W-800x353.jpg 800w, https://www.servethehome.com/wp-content/uploads/2021/08/Supermicro-AS-04124GO-NART-Liquid-Cooling-Linpack-8x-A100-80GB-500W-400x176.jpg 400w, https://www.servethehome.com/wp-content/uploads/2021/08/Supermicro-AS-04124GO-NART-Liquid-Cooling-Linpack-8x-A100-80GB-500W-696x307.jpg 696w, https://www.servethehome.com/wp-content/uploads/2021/08/Supermicro-AS-04124GO-NART-Liquid-Cooling-Linpack-8x-A100-80GB-500W-1068x471.jpg 1068w, https://www.servethehome.com/wp-content/uploads/2021/08/Supermicro-AS-04124GO-NART-Liquid-Cooling-Linpack-8x-A100-80GB-500W-952x420.jpg 952w, https://www.servethehome.com/wp-content/uploads/2021/08/Supermicro-AS-04124GO-NART-Liquid-Cooling-Linpack-8x-A100-80GB-500W.jpg 1338w" sizes="(max-width: 696px) 100vw, 696px"/></a><figcaption id="caption-attachment-54805">Supermicro AS 04124GO NART Liquid Cooling Linpack 8x A100 80GB 500W</figcaption></figure>
<p>Since the NVIDIA A100’s have more memory onboard than most desktops and laptops, 40GB-80GB, and so much compute capacity, the NVIDIA A100 has a feature called many-instance GPU or MIG that can partition the GPU in different sizes, similar to a cloud instance. Many times, for AI inference, this can be used to run workloads in parallel on a GPU, thus increasing the throughput of a GPU to handle AI inference tasks.</p>
<figure id="attachment_55173" aria-describedby="caption-attachment-55173"><a href="https://www.servethehome.com/dell-emc-poweredge-xe8545-review-amd-epyc-and-nvidia-redstone-server/nvidia-a100-40gb-mig-istance-types/" rel="attachment wp-att-55173"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2021/08/NVIDIA-A100-40GB-MIG-Istance-Types.jpg" alt="NVIDIA A100 40GB MIG Istance Types" width="614" height="296" srcset="https://www.servethehome.com/wp-content/uploads/2021/08/NVIDIA-A100-40GB-MIG-Istance-Types.jpg 614w, https://www.servethehome.com/wp-content/uploads/2021/08/NVIDIA-A100-40GB-MIG-Istance-Types-400x193.jpg 400w" sizes="(max-width: 614px) 100vw, 614px"/></a><figcaption id="caption-attachment-55173">NVIDIA A100 40GB MIG Instance Types</figcaption></figure>
<p>Here is what happens when we split a 40GB NVIDIA A100 into two MIG instances.</p>
<figure id="attachment_55174" aria-describedby="caption-attachment-55174"><a href="https://www.servethehome.com/dell-emc-poweredge-xe8545-review-amd-epyc-and-nvidia-redstone-server/nvidia-a100-40gb-split-to-two-mig-instances/" rel="attachment wp-att-55174"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2021/08/NVIDIA-A100-40GB-Split-to-Two-MIG-Instances.jpg" alt="NVIDIA A100 40GB Split To Two MIG Instances" width="666" height="498" srcset="https://www.servethehome.com/wp-content/uploads/2021/08/NVIDIA-A100-40GB-Split-to-Two-MIG-Instances.jpg 666w, https://www.servethehome.com/wp-content/uploads/2021/08/NVIDIA-A100-40GB-Split-to-Two-MIG-Instances-400x300.jpg 400w, https://www.servethehome.com/wp-content/uploads/2021/08/NVIDIA-A100-40GB-Split-to-Two-MIG-Instances-562x420.jpg 562w, https://www.servethehome.com/wp-content/uploads/2021/08/NVIDIA-A100-40GB-Split-to-Two-MIG-Instances-80x60.jpg 80w, https://www.servethehome.com/wp-content/uploads/2021/08/NVIDIA-A100-40GB-Split-to-Two-MIG-Instances-265x198.jpg 265w" sizes="(max-width: 666px) 100vw, 666px"/></a><figcaption id="caption-attachment-55174">NVIDIA A100 40GB Split To Two MIG Instances</figcaption></figure>
<p>As you may have seen, all of this requires a LOT of cooling. Here are two NVIDIA A100 systems, the top is air-cooled, the bottom is liquid-cooled.</p>
<figure id="attachment_54803" aria-describedby="caption-attachment-54803"><a href="https://www.servethehome.com/liquid-cooling-next-gen-servers-getting-hands-on-3-options-supermicro/supermicro-liquid-cooling-supermicro-as-4124go-nart-air-and-liquid-cooled-front/" rel="attachment wp-att-54803"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2021/08/Supermicro-Liquid-Cooling-Supermicro-AS-4124GO-NART-Air-and-Liquid-Cooled-Front.jpg" alt="Supermicro Liquid Cooling Supermicro AS 4124GO NART Air And Liquid Cooled Front" width="800" height="363" srcset="https://www.servethehome.com/wp-content/uploads/2021/08/Supermicro-Liquid-Cooling-Supermicro-AS-4124GO-NART-Air-and-Liquid-Cooled-Front.jpg 800w, https://www.servethehome.com/wp-content/uploads/2021/08/Supermicro-Liquid-Cooling-Supermicro-AS-4124GO-NART-Air-and-Liquid-Cooled-Front-400x182.jpg 400w, https://www.servethehome.com/wp-content/uploads/2021/08/Supermicro-Liquid-Cooling-Supermicro-AS-4124GO-NART-Air-and-Liquid-Cooled-Front-696x316.jpg 696w" sizes="(max-width: 800px) 100vw, 800px"/></a><figcaption id="caption-attachment-54803">Supermicro Liquid Cooling Supermicro AS 4124GO NART Air And Liquid Cooled Front</figcaption></figure>
<p>The liquid cooling increases performance and allowed us to run the A100’s at higher power limits, thus increasing performance.</p>
<p><iframe loading="lazy" title="Liquid Cooling High-End Servers Direct to Chip, Rear Door, and Immersion Cooling" width="696" height="392" src="https://www.youtube.com/embed/4Np1HnWiHb4?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p>
<p>While the NVIDIA A100 is cool, the next frontier is the NVIDIA H100 which promises even more performance.</p>
<h2>What is Next? The NVIDIA H100</h2>
<p>The next-generation part after the NVIDIA A100 is the NVIDIA H100. This is a higher-power card with the company’s new “Hopper” architecture. NVIDIA will have both PCIe and SXM5 variants. Here is the SXM5 H100 without its heatsink at NVIDIA HQ.</p>
<figure id="attachment_60828" aria-describedby="caption-attachment-60828"><a href="https://www.servethehome.com/checking-out-the-nvidia-h100-in-our-first-look-at-hopper/patrick-with-the-nvidia-h100-at-nvidia-hq-april-2022/" rel="attachment wp-att-60828"><img loading="lazy" src="https://www.servethehome.com/wp-content/uploads/2022/05/Patrick-with-the-NVIDIA-H100-at-NVIDIA-HQ-April-2022.jpg" alt="Patrick With The NVIDIA H100 At NVIDIA HQ April 2022" width="800" height="661" srcset="https://www.servethehome.com/wp-content/uploads/2022/05/Patrick-with-the-NVIDIA-H100-at-NVIDIA-HQ-April-2022.jpg 800w, https://www.servethehome.com/wp-content/uploads/2022/05/Patrick-with-the-NVIDIA-H100-at-NVIDIA-HQ-April-2022-363x300.jpg 363w, https://www.servethehome.com/wp-content/uploads/2022/05/Patrick-with-the-NVIDIA-H100-at-NVIDIA-HQ-April-2022-696x575.jpg 696w, https://www.servethehome.com/wp-content/uploads/2022/05/Patrick-with-the-NVIDIA-H100-at-NVIDIA-HQ-April-2022-508x420.jpg 508w" sizes="(max-width: 800px) 100vw, 800px"/></a><figcaption id="caption-attachment-60828">Patrick With The NVIDIA H100 At NVIDIA HQ April 2022</figcaption></figure>
<p>If you want to see the new NVIDIA H100 systems, we showed them off in our recent Supermicro X13 launch video:</p>
<p><iframe loading="lazy" title="Supermicro Introduces 15 New Server Families with 4th Gen Intel® Xeon® Scalable Processors" width="696" height="392" src="https://www.youtube.com/embed/ZrOdgsxElG0?list=PLQ_n1uG16HvSfyUGwE1vjMI2OPvZRWP_Q" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p>
<p>We even had the NVIDIA H100 8x GPU systems, PCIe systems, and a desktop PCIe A100 system with massive liquid cooling in the GPU accelerated systems video.</p>
<p><iframe loading="lazy" title="Supermicro GPU Accelerated Systems with 4th Gen Intel® Xeon® Scalable Processors ft. ServeTheHome" width="696" height="392" src="https://www.youtube.com/embed/RHEH1JfEpj0?list=PLQ_n1uG16HvSfyUGwE1vjMI2OPvZRWP_Q" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share" allowfullscreen=""></iframe></p>
<p>We still do not have these in our lab since they are very highly demanded-products.</p>
<h2>Final Words</h2>
<p>Regular readers of STH have seen probably a dozen reviews of systems with the NVIDIA A100. Since the NVIDIA A100 is a hot topic given the OpenAI ChatGPT and now the Microsoft Bing integration, we thought it was worthwhile to show folks what these cards are. While the NVIDIA A100 and new H100 are called “GPUs” and may be more expensive than their desktop gaming brethren like the <a href="https://www.servethehome.com/asus-rog-strix-nvidia-geforce-rtx-4090-oc-review-a-monster-gpu/">NVIDIA GeForce RTX 4090</a>, they are really high-performance computing accelerators tuned for AI workloads.</p>
<p>As always, stay tuned to STH for more A100 and H100 system reviews.</p>
        </div></div>
  </body>
</html>
