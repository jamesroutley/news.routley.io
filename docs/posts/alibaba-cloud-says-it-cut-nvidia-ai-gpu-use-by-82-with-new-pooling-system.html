<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.tomshardware.com/tech-industry/semiconductors/alibaba-says-new-pooling-system-cut-nvidia-gpu-use-by-82-percent">Original</a>
    <h1>Alibaba Cloud says it cut Nvidia AI GPU use by 82% with new pooling system</h1>
    
    <div id="readability-page-1" class="page"><div data-widget-type="contentparsed" id="content">
<div>
<section>
<div>
<div>
<div>
<div>
<picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/5bjnskrFjackkmGHw7V4aN-850-80.jpg.webp 1920w, https://cdn.mos.cms.futurecdn.net/5bjnskrFjackkmGHw7V4aN-850-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/5bjnskrFjackkmGHw7V4aN-850-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/5bjnskrFjackkmGHw7V4aN-850-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/5bjnskrFjackkmGHw7V4aN-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/5bjnskrFjackkmGHw7V4aN-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/5bjnskrFjackkmGHw7V4aN-320-80.jpg.webp 320w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)"/>
<img src="https://cdn.mos.cms.futurecdn.net/5bjnskrFjackkmGHw7V4aN.jpg" alt="Alibaba Cloud" srcset="https://cdn.mos.cms.futurecdn.net/5bjnskrFjackkmGHw7V4aN-850-80.jpg 1920w, https://cdn.mos.cms.futurecdn.net/5bjnskrFjackkmGHw7V4aN-850-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/5bjnskrFjackkmGHw7V4aN-850-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/5bjnskrFjackkmGHw7V4aN-850-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/5bjnskrFjackkmGHw7V4aN-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/5bjnskrFjackkmGHw7V4aN-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/5bjnskrFjackkmGHw7V4aN-320-80.jpg 320w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/5bjnskrFjackkmGHw7V4aN.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/5bjnskrFjackkmGHw7V4aN.jpg" data-pin-nopin="true" fetchpriority="high"/>
</picture>
</div>
</div>
</div>
<figcaption>
<span>(Image credit: Alibaba)</span>
</figcaption>
</div>

<div id="article-body">
<p id="caf228b5-5290-4a25-9b2c-43d6badcb8b3">Alibaba Cloud claims its new Aegaeon pooling system reduces the number of Nvidia GPUs required to serve large language models by 82% during a multi-month beta test inside its Model Studio marketplace. The result, published in a <a data-analytics-id="inline-link" href="https://ennanzhai.github.io/pub/sosp25-aegaeon.pdf" target="_blank" data-url="https://ennanzhai.github.io/pub/sosp25-aegaeon.pdf" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none">peer-reviewed paper</a> presented at the 2025 ACM Symposium on Operating Systems (SOSP) in Seoul, suggests that cloud providers may be able to extract significantly more inference capacity from existing silicon, especially in constrained markets like China, where the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/pc-components/gpus/china-repurposes-used-nvidia-gpus" data-before-rewrite-localise="https://www.tomshardware.com/pc-components/gpus/china-repurposes-used-nvidia-gpus">supply of Nvidia&#39;s latest H20s</a> remains limited.</p><p>Unlike training-time breakthroughs that chase model quality or speed, Aegaeon is an inference-time scheduler designed to maximize GPU utilization across many models with bursty or unpredictable demand. Instead of pinning one accelerator to one model, Aegaeon virtualizes GPU access at the token level, allowing it to schedule tiny slices of work across a shared pool. This means one H20 could serve several different models simultaneously, with system-wide “goodput” — a measure of effective output — rising by as much as nine times compared to older serverless systems.</p><p id="caf228b5-5290-4a25-9b2c-43d6badcb8b3-2">The system was tested in production over several months, according to the paper, which lists authors from both Peking University and Alibaba’s infrastructure division, including CTO Jingren Zhou. During that window, the number of GPUs needed to support dozens of different LLMs — ranging in size up to 72 billion parameters — fell from 1,192 to just 213.</p><p>While the paper does not break down which models contributed most to the savings, reporting by the <a data-analytics-id="inline-link" href="https://www.scmp.com/business/article/3329450/alibaba-cloud-claims-slash-nvidia-gpu-use-82-new-pooling-system?module=top_story&amp;pgtype=section" data-url="https://www.scmp.com/business/article/3329450/alibaba-cloud-claims-slash-nvidia-gpu-use-82-new-pooling-system?module=top_story&amp;pgtype=section" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none"><em>South China Morning Post</em></a><em> </em>says the tests were conducted using Nvidia’s H20, one of the <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/jensen-huang-says-nvidia-china-market-share-has-fallen-to-zero" data-before-rewrite-localise="https://www.tomshardware.com/tech-industry/jensen-huang-says-nvidia-china-market-share-has-fallen-to-zero">few accelerators</a> still legally available to Chinese buyers under current U.S. export controls.</p><p aria-hidden="true">Alibaba says the gains came from two main techniques: Packing multiple models per GPU, and using a token-level autoscaler to dynamically allocate compute as output is generated, rather than reserving resources at the request level. In <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tag/benchmark" data-auto-tag-linker="true" data-before-rewrite-localise="https://www.tomshardware.com/tag/benchmark">benchmarks</a>, Aegaeon beat the goodput of ServerlessLLM and MuxServe by margins ranging from 1.5 times to 9 times.</p><p>Whether those savings translate outside Alibaba’s stack remains to be seen. Alibaba Cloud’s paper does not specify the exact network fabric used in the beta test, but we know the company offers its own eRDMA elastic RDMA network and has a record of building highly‑integrated GPU serving stacks, suggesting the results may depend on an optimized, vertically integrated environment.</p><p aria-hidden="true">Regardless, the result is likely to attract interest from other hyperscalers looking to stretch scarce accelerator fleets as inference demand continues to spike.</p><div id="slice-container-newsletterForm-articleInbodyContent-UfPxse5QFfEeNmgZisoaf5"><div data-hydrate="true"><div><section></section><section><p>Get Tom&#39;s Hardware&#39;s best news and in-depth reviews, straight to your inbox.</p></section></div></div></div><a href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" id="91c68ebe-b326-462c-8a81-636b58803280" data-url="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" target="_blank" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none"><figure data-bordeaux-image-check=""><div><p> <picture data-new-v2-image="true">
<source type="image/webp" srcset="https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-676-80.png.webp 1200w, https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-676-80.png.webp 1024w, https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-676-80.png.webp 970w, https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-650-80.png.webp 650w, https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-480-80.png.webp 480w, https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-320-80.png.webp 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)"/>
<img src="https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56.png" alt="Google Preferred Source" srcset="https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-676-80.png 1200w, https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-676-80.png 1024w, https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-676-80.png 970w, https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-650-80.png 650w, https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-480-80.png 480w, https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56-320-80.png 320w" sizes="(min-width: 1000px) 970px, calc(100vw - 40px)" loading="lazy" data-new-v2-image="true" data-original-mos="https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56.png" data-pin-media="https://cdn.mos.cms.futurecdn.net/7cUTDmN2PHNRiNBVqbKf56.png"/>
</picture></p></div></figure></a><p id="de01fbb3-3508-4f25-a524-943c5df08f57"><em>Follow</em><a data-analytics-id="inline-link" href="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" target="_blank" data-url="https://news.google.com/publications/CAAqLAgKIiZDQklTRmdnTWFoSUtFSFJ2YlhOb1lYSmtkMkZ5WlM1amIyMG9BQVAB" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none"><em> Tom&#39;s Hardware on Google News</em></a><em>, or</em><a data-analytics-id="inline-link" href="https://google.com/preferences/source?q=" target="_blank" data-url="https://google.com/preferences/source?q=" referrerpolicy="no-referrer-when-downgrade" data-hl-processed="none"><em> add us as a preferred source</em></a><em>, to get our latest news, analysis, &amp; reviews in your feeds.</em></p>
</div>



<!-- Drop in a standard article here maybe? -->



<div id="slice-container-authorBio-UfPxse5QFfEeNmgZisoaf5"><div><p>Luke James is a freelance writer and journalist.  Although his background is in legal, he has a personal interest in all things tech, especially hardware and microelectronics, and anything regulatory. </p></div></div>
</section>

<section>



</section>


</div>
</div></div>
  </body>
</html>
