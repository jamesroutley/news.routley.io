<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://cpldcpu.wordpress.com/2024/05/02/machine-learning-mnist-inference-on-the-3-cent-microcontroller/">Original</a>
    <h1>Implementing neural networks on the &#34;3 cent&#34; 8-bit microcontroller</h1>
    
    <div id="readability-page-1" class="page"><article id="post-1674">
	<!-- .entry-header -->

	
	
	<div>
		
<p>Bouyed by the surprisingly good performance of neural networks with quantization aware training <a href="https://cpldcpu.wordpress.com/2024/04/24/implementing-neural-networks-on-the-10-cent-risc-v-mcu-without-multiplier/">on the CH32V003</a>, I wondered how far this can be pushed. How much can we compress a neural network while still achieving good test accuracy on the MNIST dataset? When it comes to absolutely low-end microcontrollers, there is hardly a more compelling target than the <a href="https://cpldcpu.wordpress.com/2019/08/12/the-terrible-3-cent-mcu/">Padauk 8-bit microcontrollers</a>. These are microcontrollers optimized for the simplest and lowest cost applications there are. The smallest device of the portfolio, the PMS150C, sports 1024 13-bit word one-time-programmable memory and 64 bytes of ram, more than an order of magnitude smaller than the CH32V003. In addition, it has a proprieteray accumulator based 8-bit architecture, as opposed to a much more powerful RISC-V instruction set.</p>



<figure data-carousel-extra="{&#34;blog_id&#34;:50424692,&#34;permalink&#34;:&#34;https:\/\/cpldcpu.wordpress.com\/2024\/05\/02\/machine-learning-mnist-inference-on-the-3-cent-microcontroller\/&#34;}">
<figure><a href="https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/banner-1.png"><img data-attachment-id="1721" data-permalink="https://cpldcpu.wordpress.com/2024/05/02/machine-learning-mnist-inference-on-the-3-cent-microcontroller/banner-1/" data-orig-file="https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/banner-1.png" data-orig-size="964,525" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="banner-1" data-image-description="" data-image-caption="" data-medium-file="https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/banner-1.png?w=300" data-large-file="https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/banner-1.png?w=840" tabindex="0" role="button" width="964" height="525" data-id="1721" src="https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/banner-1.png?w=964" alt="" srcset="https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/banner-1.png 964w, https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/banner-1.png?w=150 150w, https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/banner-1.png?w=300 300w, https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/banner-1.png?w=768 768w" sizes="(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px"/></a></figure>
</figure>



<p>Is it possible to implement an MNIST inference engine, which can classify handwritten numbers, also on a PMS150C?</p>



<p>On the CH32V003 I used MNIST samples that were downscaled from 28×28 to 16×16, so that every sample take 256 bytes of storage. This is quite acceptable if there is 16kb of flash available, but with only 1 kword of rom, this is too much. Therefore I started with downscaling the dataset to 8×8 pixels.</p>



<figure data-carousel-extra="{&#34;blog_id&#34;:50424692,&#34;permalink&#34;:&#34;https:\/\/cpldcpu.wordpress.com\/2024\/05\/02\/machine-learning-mnist-inference-on-the-3-cent-microcontroller\/&#34;}">
<figure><a href="https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/samplescompared-1.png"><img data-attachment-id="1700" data-permalink="https://cpldcpu.wordpress.com/2024/05/02/machine-learning-mnist-inference-on-the-3-cent-microcontroller/samplescompared-1/" data-orig-file="https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/samplescompared-1.png" data-orig-size="958,558" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="samplescompared-1" data-image-description="" data-image-caption="" data-medium-file="https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/samplescompared-1.png?w=300" data-large-file="https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/samplescompared-1.png?w=840" tabindex="0" role="button" width="958" height="558" data-id="1700" src="https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/samplescompared-1.png?w=958" alt="" srcset="https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/samplescompared-1.png 958w, https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/samplescompared-1.png?w=150 150w, https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/samplescompared-1.png?w=300 300w, https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/samplescompared-1.png?w=768 768w" sizes="(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px"/></a></figure>
</figure>







<p>The image above shows a few samples from the dataset at both resolutions. At 16×16 it is still easy to discriminate different numbers. At 8×8 it is still possible to guess most numbers, but a lot of information is lost. </p>



<p>Suprisingly, it is still possible to train a machine learning model to recognize even these very low resolution numbers with impressive accuracy. It’s important to remember that the test dataset contains 10000 images that the model does not see during training. The only way for a very small model to recognize these images accurate is to identify common patterns, the model capacity is too limited to “remember” complete digits. I trained a number of different network combinations to understand the trade-off between network memory footprint and achievable accuracy.</p>



<h2>Parameter Exploration</h2>



<figure data-carousel-extra="{&#34;blog_id&#34;:50424692,&#34;permalink&#34;:&#34;https:\/\/cpldcpu.wordpress.com\/2024\/05\/02\/machine-learning-mnist-inference-on-the-3-cent-microcontroller\/&#34;}">
<figure><a href="https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/nnexploration.png"><img data-attachment-id="1681" data-permalink="https://cpldcpu.wordpress.com/2024/05/02/machine-learning-mnist-inference-on-the-3-cent-microcontroller/nnexploration/" data-orig-file="https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/nnexploration.png" data-orig-size="1800,1200" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="nnexploration" data-image-description="" data-image-caption="" data-medium-file="https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/nnexploration.png?w=300" data-large-file="https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/nnexploration.png?w=840" tabindex="0" role="button" width="1024" height="682" data-id="1681" src="https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/nnexploration.png?w=1024" alt="" srcset="https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/nnexploration.png?w=1024 1024w, https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/nnexploration.png?w=150 150w, https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/nnexploration.png?w=300 300w, https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/nnexploration.png?w=768 768w, https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/nnexploration.png 1800w" sizes="(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px"/></a></figure>
</figure>



<p>The plot above shows the result of my hyperparameter exploration experiments, comparing models with different configurations of weights and quantization levels from 1 to 4 bit for input images of 8×8 and 16×16. The smallest models had to be trained without data augmentation, as they would not converge otherwise.</p>



<p>Again, there is a clear relationship between test accuracy and the memory footprint of the network. Increasing the memory footprint improves accuracy up to a certain point. For 16×16, around 99% accuracy can be achieved at the upper end, while around 98.5% is achieved for 8×8 test samples. This is still quite impressive, considering the significant loss of information for 8×8.</p>



<p>For small models, 8×8 achieves better accuracy than 16×16. The reason for this is that the size of the first layer dominates in small models, and this size is reduced by a factor of 4 for 8×8 inputs.</p>



<p>Surprisingly, it is possible to achieve over 90% test accuracy even on models as small as half a kilobyte. This means that it would fit into the code memory of the microcontroller! Now that the general feasibility has been established, I needed to tweak things further to accommodate the limitations of the MCU.</p>



<h2>Training the Target Model</h2>



<p>Since the RAM is limited to 64 bytes, the model structure had to use a minimum number of latent parameters during inference. I found that it was possible to use layers as narrow as 16. This reduces the buffer size during inference to only 32 bytes, 16 bytes each for one input buffer and one output buffer, leaving 32 bytes for other variables. The 8×8 input pattern is directly read from the ROM.</p>



<p>Furthermore, I used 2-bit weights with irregular spacing of (-2, -1, 1, 2) to allow for a simplified implementation of the inference code. I also skipped layer normalization and instead used a constant shift to rescale activations. These changes slightly reduced accuracy. The resulting model structure is shown below.</p>



<figure data-carousel-extra="{&#34;blog_id&#34;:50424692,&#34;permalink&#34;:&#34;https:\/\/cpldcpu.wordpress.com\/2024\/05\/02\/machine-learning-mnist-inference-on-the-3-cent-microcontroller\/&#34;}">
<figure><a href="https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/model_mcu.drawio.png"><img data-attachment-id="1684" data-permalink="https://cpldcpu.wordpress.com/2024/05/02/machine-learning-mnist-inference-on-the-3-cent-microcontroller/model_mcu-drawio-2/" data-orig-file="https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/model_mcu.drawio.png" data-orig-size="808,534" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="model_mcu.drawio" data-image-description="" data-image-caption="" data-medium-file="https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/model_mcu.drawio.png?w=300" data-large-file="https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/model_mcu.drawio.png?w=808" tabindex="0" role="button" loading="lazy" width="808" height="534" data-id="1684" src="https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/model_mcu.drawio.png?w=808" alt="" srcset="https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/model_mcu.drawio.png 808w, https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/model_mcu.drawio.png?w=150 150w, https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/model_mcu.drawio.png?w=300 300w, https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/model_mcu.drawio.png?w=768 768w" sizes="(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 984px) 61vw, (max-width: 1362px) 45vw, 600px"/></a></figure>
</figure>







<p>All things considered, I ended up with a model with 90.07% accuracy and a total of 3392 bits (0.414 kilobytes) in 1696 weights, as shown in the log below. The panel on the right displays the first layer weights of the trained model, which directly mask features in the test images. In contrast to the higher accuracy models, each channel seems to combine many features at once, and no discernible patterns can be seen.</p>







<h2>Implementation on the Microntroller</h2>



<p>In the first iteration, I used a slightly larger variant of the Padauk Microcontrollers, the PFS154. This device has twice the ROM and RAM and can be reflashed, which tremendously simplifies software development. The C versions of the inference code, including the debug output, worked almost out of the box. Below, you can see the predictions and labels, including the last layer output. </p>



<figure data-carousel-extra="{&#34;blog_id&#34;:50424692,&#34;permalink&#34;:&#34;https:\/\/cpldcpu.wordpress.com\/2024\/05\/02\/machine-learning-mnist-inference-on-the-3-cent-microcontroller\/&#34;}">
<figure><a href="https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/grafik-10.png"><img data-attachment-id="1689" data-permalink="https://cpldcpu.wordpress.com/2024/05/02/machine-learning-mnist-inference-on-the-3-cent-microcontroller/grafik-10-7/" data-orig-file="https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/grafik-10.png" data-orig-size="602,269" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="grafik-10" data-image-description="" data-image-caption="" data-medium-file="https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/grafik-10.png?w=300" data-large-file="https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/grafik-10.png?w=602" tabindex="0" role="button" loading="lazy" width="602" height="269" data-id="1689" src="https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/grafik-10.png?w=602" alt="" srcset="https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/grafik-10.png 602w, https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/grafik-10.png?w=150 150w, https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/grafik-10.png?w=300 300w" sizes="(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 984px) 61vw, (max-width: 1362px) 45vw, 600px"/></a></figure>
</figure>







<p>Squeezing everything down to fit into the smaller PMS150C was a different matter. One major issue when programming these devices in C is that every function call consumes RAM for the return stack and function parameters. This is unavoidable because the architecture has only a single register (the accumulator), so all other operations must occur in RAM.</p>



<p>To solve this, I flattened the inference code and implemented the inner loop in assembly to optimize variable usage. The inner loop for memory-to-memory inference of one layer is shown below. The two-bit weight is multiplied with a four-bit activation in the accumulator and then added to a 16-bit register. The multiplication requires only four instructions (t0sn, sl,t0sn,neg), thanks to the powerful bit manipulation instructions of the architecture. The sign-extending addition (add, addc, sl, subc) also consists of four instructions, demonstrating the limitations of 8-bit architectures.</p>


<div><pre title="">void fc_innerloop_mem(uint8_t loops) {

    sum = 0;
    do  {
       weightChunk = *weightidx++;
__asm   
    idxm  a, _activations_idx
	inc	_activations_idx+0

    t0sn _weightChunk, #6
    sl     a            ;    if (weightChunk &amp; 0x40) in = in+in;
    t0sn _weightChunk, #7
    neg    a           ;     if (weightChunk &amp; 0x80) in =-in;                    

    add    _sum+0,a
    addc   _sum+1
    sl     a 
    subc   _sum+1  

  ... 3x more ...

__endasm;
    } while (--loops);

    int8_t sum8 = ((uint16_t)sum)&gt;&gt;3; // Normalization
    sum8 = sum8 &lt; 0 ? 0 : sum8; // ReLU
    *output++ = sum8;
}

</pre></div>


<p>In the end, I managed to fit the entire inference code into 1 kilowords of memory and reduced sram usage to 59 bytes, as seen below. (Note that the output from SDCC is assuming 2 bytes per instruction word, while it is only 13 bits). </p>



<figure data-carousel-extra="{&#34;blog_id&#34;:50424692,&#34;permalink&#34;:&#34;https:\/\/cpldcpu.wordpress.com\/2024\/05\/02\/machine-learning-mnist-inference-on-the-3-cent-microcontroller\/&#34;}">
<figure><a href="https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/grafik-11.png"><img data-attachment-id="1690" data-permalink="https://cpldcpu.wordpress.com/2024/05/02/machine-learning-mnist-inference-on-the-3-cent-microcontroller/grafik-11-6/" data-orig-file="https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/grafik-11.png" data-orig-size="1170,204" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="grafik-11" data-image-description="" data-image-caption="" data-medium-file="https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/grafik-11.png?w=300" data-large-file="https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/grafik-11.png?w=840" tabindex="0" role="button" loading="lazy" width="1024" height="178" data-id="1690" src="https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/grafik-11.png?w=1024" alt="" srcset="https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/grafik-11.png?w=1024 1024w, https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/grafik-11.png?w=1021 1021w, https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/grafik-11.png?w=150 150w, https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/grafik-11.png?w=300 300w, https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/grafik-11.png?w=768 768w, https://cpldcpu.wordpress.com/wp-content/uploads/2024/05/grafik-11.png 1170w" sizes="(max-width: 709px) 85vw, (max-width: 909px) 67vw, (max-width: 1362px) 62vw, 840px"/></a></figure>
</figure>







<p>Success! Unfortunately, there was no rom space left for the soft UART to output debug information. However, based on the verificaiton on PFS154, I trust that the code works, and since I don’t have any specific application in mind, I left it at that stage.</p>



<h2>Summary</h2>



<p>It is indeed possible to implement MNIST inference with good accuracy using one of the cheapest and simplest microcontrollers on the market. A lot of memory footprint and processing overhead is usually spent on implementing flexible inference engines, that can accomodate a wide range of operators and model structures. Cutting this overhead away and reducing the functionality to its core allows for astonishing simplification at this very low end.</p>



<p>This hack demonstrates that there truly is no fundamental lower limit to applying machine learning and edge inference. However, the feasibility of implementing useful applications at this level is somewhat doubtful.</p>



<p>You can find the <a href="https://github.com/cpldcpu/BitNetPDK">project repository here.</a></p>
	</div><!-- .entry-content -->

	<!-- .entry-footer -->
</article></div>
  </body>
</html>
