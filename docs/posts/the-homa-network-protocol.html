<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://lwn.net/SubscriberLink/1003059/41b1d2ea281b6779/">Original</a>
    <h1>The Homa Network Protocol</h1>
    
    <div id="readability-page-1" class="page"><div>
<blockquote>
<div>
<h3>Welcome to LWN.net</h3>
<p>
The following subscription-only content has been made available to you 
by an LWN subscriber.  Thousands of subscribers depend on LWN for the 
best news from the Linux and free software communities.  If you enjoy this 
article, please consider <a href="https://lwn.net/subscribe/">subscribing to LWN</a>.  Thank you
for visiting LWN.net!
</p></div>
</blockquote>
<p>
The origins of the TCP and UDP network protocols can be traced back a full
50Â years.  Even though networks and their use have changed radically
since those protocols were designed, they can still be found behind most
networking applications.  Unsurprisingly, these protocols are not optimal
for all situations, so there is ongoing interest in the development of
alternatives.  One such is the <a href="https://homa-transport.atlassian.net/wiki/spaces/HOMA/overview">Homa
transport protocol</a>, developed by John Ousterhout (of <a href="https://www.tcl.tk/">Tcl/Tk</a> and <a href="https://raft.github.io/">Raft</a> fame, among other accomplishments),
which is aimed at data-center applications.  Ousterhout is currently trying
to get <a href="https://lwn.net/ml/all/20241217000626.2958-1-ouster@cs.stanford.edu">a
minimal Homa implementation</a> into the kernel.
</p><p>
Most networking applications are still based on TCP, which was designed for
efficient and reliable transport of streams of data across a distributed
Internet.  Data-center applications, instead, are often dominated by large
number of small messages between many locally connected hosts.  The
requirements of TCP, including the establishment of connections and
ordering of data, add a lot of overhead to that kind of application.  The
design of Homa is intended to remove that overhead while taking advantage
of what current data-center networking hardware can do, with a focus on
minimizing the latency between a request and its response.
</p><h4>A quick Homa overview</h4>
<p>
At its core, Homa is designed for remote procedure call (RPC) applications;
every interaction on a Homa network comes down to a request and associated
reply.  A client will send a request message a server that includes a
unique request ID; the server will send a reply back that quotes that ID.
The only state that exists on the server is held between the receipt of the
request and the receipt of the response by the client.
</p><p>
Much of the key to the performance of this protocol can be found in how
these messages are handled.  There is no connection setup; instead, the
client starts transmitting the request, with no introductory handshake, to
the server.  There is a limit on how many bytes of this &#34;unscheduled&#34;
request data can be sent in this manner, which is determined by the
round-trip time of the network; it should be just high enough to keep the
request-transmission pipeline full until an initial response can be
received from the server side.  The figure of about 10,000 bytes appears in
some of the Homa papers.
</p><p>
The initial request packet includes the length of the full request.  If the
request does not fit into the size allowed for the unscheduled data, the
client will wait for a &#34;grant&#34; response before sending any more.  That
grant should, if the server is responding quickly, arrive just as the
initial request data has finished transmitting, allowing the client to
continue sending without a pause.  Grants include a maximum amount of data
that can be sent, and thus function like the TCP receive window.
</p><p>
This machinery is intended to get a request to the server as quickly as
possible, but without the need for much, if any, buffering in the network
path between the two machines.  Priority queues are used to manage this
traffic, with unscheduled packets normally having the highest priority.
Lower priorities are used for granted traffic; the requests with the least
amount of data remaining to be received are given the highest priority.
</p><p>
Once the server has received the full request and processed it, a response
is sent back to the client.  Once again, the initial bytes are sent as
unscheduled packets, with grants required for the rest if the response is
large enough.  In the earlier descriptions of the protocol, the server
would forget everything it knew about the request immediately after sending
the response.  That created the possibility that requests could be resent
(if the response ever arrives) and executed multiple times.  More recent
publications include an explicit acknowledgment message indicating that a
response has been received, with the sender retaining the necessary state
to retransmit a reply until that acknowledgment is received.
</p><p>
The details of the protocol are, of course, rather more complex than
described here.  There are, for example, mechanisms for clamping down on
the amount of unscheduled data sent if a server is finding itself
overloaded.  The receiving side of a message can request retransmission if
an expected packet does not arrive; unlike TCP and many other protocols,
Homa puts the responsibility for detecting lost packets onto the receiving
side.  There is also a fair amount of thought that has gone into letting
systems overcommit their resources by issuing more grants than they can
immediately handle; the purpose here is to keep the pipelines full even if
some senders do not transmit as quickly as expected.
</p><p>
See <a href="https://dl.acm.org/doi/10.1145/3230543.3230564">this paper</a>
for a more complete (and surely more correct) description of the Homa
protocol, <a href="https://github.com/PlatformLab/HomaModule/blob/main/protocol.md">this
page</a>, which reflects some more recent changes, and <a href="https://lwn.net/Articles/914030/">this 2022 article</a> for more details.
</p><h4>Homa on Linux</h4>
<p>
The Unix socket interface was designed around streams, and is not a perfect
fit for Homa, but the implementation sticks with it to the extent it can.
A <a href="https://man7.org/linux/man-pages/man2/socket.2.html"><tt>socket()</tt></a>
call is used to create a socket for communication with any number of other
systems; the <tt>IPPROTO_HOMA</tt> protocol type is used.  Homa can run
over either IPv4 or IPv6.  For server systems, a <a href="https://man7.org/linux/man-pages/man2/bind.2.html"><tt>bind()</tt></a>
call can be used to set up a well-known port to receive requests; clients
need not bind to a port.
</p><p>
Messages are sent and received, as one might expect, with <a href="https://man7.org/linux/man-pages/man2/sendmsg.2.html"><tt>sendmsg()</tt></a>
and <a href="https://man7.org/linux/man-pages/man2/recv.2.html"><tt>recvmsg()</tt></a>,
but there are some Homa-specific aspects that developers must be aware of.
When sending a message, an application must include a pointer to this
structure in the <tt>msg_control</tt> field of the <tt>msghdr</tt>
structure passed to <tt>sendmsg()</tt>:
</p><pre>    struct homa_sendmsg_args {
	uint64_t id;
	uint64_t completion_cookie;
    };
</pre>
<p>
If a request is being sent, <tt>id</tt> should be set to zero; the protocol
implementation will then assign a unique ID to the request (and write it
into <tt>id</tt>) before sending it to the server.  For a reply message,
<tt>id</tt> should be the ID value that arrived with the request being
responded to.  The <tt>completion_cookie</tt> value, which is only used for
requests, will be passed back to the caller with the reply data when it is
received.
</p><p>
The receive side is a bit more complicated, because Homa requires that the
buffer space for replies be registered before sending the first request on
a socket.  To do so, the process should allocate a range of memory, then
pass it into the kernel with <tt>SO_HOMA_RCVBUF</tt> <a href="https://man7.org/linux/man-pages/man2/getsockopt.2.html"><tt>setsockopt()</tt></a>
operation, using this structure:
</p><pre>    struct homa_rcvbuf_args {
	void *start;
	size_t length;
    };
</pre>
<p>
The <tt>start</tt> address must be page-aligned.  This memory is
split into individual buffers, called &#34;bpages&#34;, each of which is
<tt>HOMA_BPAGE_SIZE</tt> in length; that size is 64KB in the current
implementation.  Each message will occupy at least one bpage; large
messages will be scattered across multiple, not necessarily contiguous,
bpages.
</p><p>
A message is received by making a call to <tt>recvmsg()</tt> with a
pointer to this structure passed in the <tt>msg_control</tt> field of
<tt>struct msghdr</tt>:
</p><pre>    struct homa_recvmsg_args {
	uint64_t id;
	uint64_t completion_cookie;
	uint32_t flags;
	uint32_t num_bpages;
	uint32_t bpage_offsets[HOMA_MAX_BPAGES];
    };
</pre>
<p>
The flags field describes what the caller is willing to receive; it is a
bitmask that can include either or both of <tt>HOMA_RECVMSG_REQUEST</tt> (to
receive request messages) and <tt>HOMA_RECVMSG_RESPONSE</tt> (to receive
responses).  If <tt>id</tt> is zero, then <tt>HOMA_RECVMSG_RESPONSE</tt>
will cause any response message to be returned; otherwise, only a response
corresponding to the provided request ID will be returned.  On return,
<tt>num_bpages</tt> will indicate the number of bpages in the registered
buffer area have been used to hold the returned message;
<tt>bpage_offsets</tt> gives the offset of each one.
</p><p>
The bpages returned by this call are owned by the application at this
point, and will not be used by the kernel until they have been explicitly
returned.  That is done with a subsequent <tt>recvmsg()</tt> call, where
<tt>num_bpages</tt> and <tt>bpage_offsets</tt> will indicate a set of
bpages to be given back.
</p><p>
This code has been &#34;<q>stripped down to the bare minimum</q>&#34; to be able to
actually transmit requests and responses across the net; it is evidently
about half of the full set of Homa patches.  The intent, of course, is to
ease the task of reviewing the work and getting initial support into the
kernel; the rest of the work can come later.  In its current form,
according to the cover letter, its performance &#34;<q>is not very
interesting</q>&#34;, but that is expected to improve once the rest of the work
is merged.
</p><p>
See <a href="https://www.usenix.org/system/files/atc21-ousterhout.pdf">this
paper</a> for more information on the Linux implementation of Homa.
</p><h4>Prospects</h4>
<p>
The Homa protocol originates at Stanford University, with support from a
number of technology companies.  Academic work often does not successfully
make the transition from interesting prototype into production-quality code
that can be accepted into Linux.  In this case, though, Ousterhout seems
determined to get the code into the mainline, and is trying to do the right
things to get it there.  Thus far, the four postings of the code have
yielded some conversations about the protocol, but have not yet resulted in
a detailed review of the code.  That suggests that the initial merge of
Homa is not imminent.
</p><p>
It does seem likely to happen at some point, though.  Then, it will be a
matter of whether the operators of large data centers decide that it is
worth using.  Complicating that question is Ousterhout&#39;s assertion (in the
above-linked paper) that, even in a kernel with less overhead than Linux,
CPUs simply are not fast enough to keep up with the increases in networking
speed.  The real future for Homa, he suggests, may be inside the networking
hardware itself.  In that case, the merging into Linux would be an
important proof of concept that accelerates further development of the
protocol, but its use in real-world deployments might be limited.  It does,
in any case, show how Linux is firmly at the center of protocol development
for modern networks.<br clear="all"/></p><table>
           <tbody><tr><th colspan="2">Index entries for this article</th></tr>
           <tr><td><a href="https://lwn.net/Kernel/Index">Kernel</a></td><td><a href="https://lwn.net/Kernel/Index#Networking-Protocols">Networking/Protocols</a></td></tr>
            </tbody></table></div></div>
  </body>
</html>
