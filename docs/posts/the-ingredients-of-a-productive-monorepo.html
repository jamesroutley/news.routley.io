<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.swgillespie.me/posts/monorepo-ingredients/">Original</a>
    <h1>The Ingredients of a Productive Monorepo</h1>
    
    <div id="readability-page-1" class="page"><section id="js-article">
    <p>So! Suppose you’re an intrepid engineer in a nascent Developer Productivity
team. Your engineering organization has decided that it wants to
move towards a <a href="https://monorepo.tools">monorepo</a>. You’ve heard the stories
told of Google, Meta, Uber - each a large technology company with
developer productivity organizations consisting of hundreds of engineers -
and you want to capture some of their magic in a bottle and give it to your
users. You wonder - what work lies ahead of you?</p>
<p>I’ve worked in a variety of companies, from gigantic titans to small startups
and everything in-between, and I’ve worked in developer infrastructure for
almost all of them. My experience is informed by my own successes and
failures operating within these companies and trying to solve productivity
problems of the developers I served. I’ve observed that a functioning
monorepo environment demands the existence of a number of tools that you,
dear Developer Productivity engineer, will likely need to write yourself for
your company. I have yet to witness a suite of tools that fully solves the
set of problems that you will encounter when setting up a monorepo. In this
blog post I’m going to enumerate these tools and discuss implementation
strategies for them, in the hopes of painting a clear picture of the path
that lies ahead for any organization that walks the monorepo path.</p>
<p>The absolute first question you must ask yourself, though, is:</p>
<h2 id="why-do-you-want-a-monorepo">Why do you want a monorepo?</h2>
<p>You and your engineering organization must stare at this question deeply and
answer it using language that is firmly anchored in your organization’s
culture and values. Those blog posts that you read from Google, Facebook, or
Uber engineers about how great their monorepo is, and how effective their
developers are, and how everybody will be a 10x engineer when you’re done?</p>
<p><strong>Purge them from your mind.</strong></p>
<p>You WILL NOT end up with an experience as tight as <code>google3</code><sup id="fnref:1"><a href="#fn:1" role="doc-noteref">1</a></sup> or <code>fbsource</code><sup id="fnref:2"><a href="#fn:2" role="doc-noteref">2</a></sup>. You WILL inherit a new set of problems that many-repo
setup did not have. You will take steps backward before you take steps
forward. These blog posts and the wins they promise are not good reasons
to embark on this journey. The <a href="https://www.uber.com/blog/research/keeping-master-green-at-scale/">cool</a> <a href="https://engineering.fb.com/2023/06/27/developer-tools/meta-developer-tools-open-source/">engineering</a> <a href="https://www.uber.com/blog/flaky-tests-overhaul/">blogs</a> from these big companies
are discussing end states that, while very interesting, are far beyond the
capabilities of your company and your small team. You will not have the
same outcomes if you attempt to do what they have done.</p>
<p>Better reasons to embark on this journey are <strong>consistency</strong>,
<strong>organizational coherence</strong>, and <strong>shared tooling efforts</strong>. Your developer
productivity gets to focus on improving the experience of working in
a single place and can reach more users in the process. Your engineering leadership gets to define and enforce
engineering conventions. Engineers working in different organizations can
contribute to each other’s codebases with the knowledge that they look and
operate the same way.</p>
<p>You, intrepid Developer Productivity engineer, have the opportunity and
responsibility to pave a path for your colleagues. Let’s get to work.</p>
<h2 id="the-golden-rule">The Golden Rule</h2>
<p>If you can forgive this abuse of <a href="https://en.wikipedia.org/wiki/Big_O_notation">big-O notation</a>, this principle guides all
engineering for monorepo-related developer tools:</p>
<p><strong>Any operation over your repository that needs to be fast must be O(change) and not O(repo)</strong>.</p>
<p>As you begin to use your normal sets of tools in a large monorepo, you will
find that many tools and processes do not have this property and will cause
you problems as your monorepo grows. We will <em>repeatedly</em> come back to this
design principle in every section that this blog post discusses. When you
see a blog post from a big company talking about some engineering that they
did on a developer tool, it is almost always the implementation of this
principle in a space in which an <code>O(repo)</code> operation has become a problem.</p>
<h2 id="source-control">Source Control</h2>
<p>Perhaps the most obvious consequence of storing all of your source code
together in one repository is that, well, all of your source code is stored
together. <code>git</code> is the default choice for many software companies today and, despite <code>git</code> being designed as decentralized source control system, many
users use <code>git</code> through a software forge such as GitHub or GitLab. The reality is that <code>git</code> was never designed for the centralized monorepo and
runs into substantial performance problems when your history gets large or
your repo contains many, many files<sup id="fnref:3"><a href="#fn:3" role="doc-noteref">3</a></sup>.</p>
<p>Your repo probably isn’t big enough to have problems with
<code>git</code>. You can push <code>git</code> and GitHub pretty far these days. However, git is
(by design) a <code>O(repo)</code> system, and operations such as <code>git status</code> will
slow down rapidly as the size of the repository grows.</p>
<p>If your monorepo begins to push the limits of git (or GitHub!), you have
several paths available to you, each walked by a company that came before you:</p>
<ul>
<li>You walk the path of Microsoft and <a href="https://github.com/microsoft/git">fork git</a>.</li>
<li>You walk the path of Meta and <a href="https://engineering.fb.com/2014/01/07/core-infra/scaling-mercurial-at-facebook/">fork Mercurial</a>.</li>
<li>You walk the path of Google and <a href="https://en.wikipedia.org/wiki/Piper_(source_control_system)">write your own</a>, although Google also managed to get pretty far by running Perforce on the most powerful servers that money could buy.</li>
</ul>
<p>These companies chose different technical paths but all chose the same underlying idea. Your scaled-up source control system MUST be able to check out <em>subsets</em> of the repository and be able to operate on those subsets independently of the whole repository.  There are essentially two ways to do this:</p>
<ol>
<li>Your source control system subsets the repository and only clones files in that subset whenever you fetch. Files outside of your subset are not present on disk. If you need one of those files, you need to update your subset configuration to include it. Git calls this a <a href="https://git-scm.com/docs/git-sparse-checkout">sparse checkout</a>. A similar Mercurial extension <code>hg sparse</code> also exists, originally authored by Meta, who used it for many years.</li>
<li>Your source control system logically checks out a revision of your repository but does not download anything eagerly. Instead, it presents a <em>virtual filesystem</em> that lazily downloads files on-demand from a central
source control server. Repository tools “see” the full repository, but the
contents of directories and files are only resolved when accessed. Google, <a href="https://github.com/facebook/sapling/blob/main/eden/fs/docs/Overview.md">Meta</a>, and <a href="https://github.com/microsoft/VFSForGit">Microsoft</a> have implemented this for their respective source control systems.</li>
</ol>
<p>But you probably don’t work at these companies and your repo
isn’t going to be this large for a while. Just use <code>git</code> for now and know
that, as your company grows, so does your source control problem. The newer
source control system <a href="https://github.com/jj-vcs/jj">Jujutsu</a> is very
promising in that it has the extension points in place to admit an
open-source implementation of a virtual filesystem; I hope that this comes
to life one day.</p>
<p>Finally, a practical consideration that amplifies your source control problems is the proliferation of <em>generated code</em>, particularly source generated by IDLs such as <code>protobuf</code> or <code>thrift</code>. If you choose to check-in generated source (which is a practical choice that I’ll go over in the next section), your source control footprint will grow at a rate that’s much larger than the sum total of new code output of your engineers.</p>
<h2 id="building">Building</h2>
<p>“Aha! This part’s easy - this is what Bazel does!”</p>
<p>It’s true that <a href="https://bazel.build">Bazel</a>, the open-source version of the Google-internal Blaze<sup id="fnref:4"><a href="#fn:4" role="doc-noteref">4</a></sup>,
bills itself as a monorepo build tool that supports a myriad of languages.
From a technical perspective, this is generally true. You can, and people do,
get Bazel to build monorepos that consist of a bunch of different languages,
toolchains, target architectures, and operating systems. The people that do
this, though, work on a team that has a name like “The Build Team” and this is
their full-time job.</p>
<p>My best advice to you is… don’t do that if you can avoid it.
Keep your monorepo <strong>single-language</strong> if you can. Remember, one of our goals
for having a monorepo in the first place is <em>consistency</em>, and it’s hard to
do that if your engineers are writing code in multiple languages.</p>
<p>If you can use your language ecosystem’s build system (if it has one), <strong>do it</strong>. <strong>DO IT</strong>. Do it for as long as you POSSIBLY can. You will find that
many build tools are <code>O(repo)</code> and tend to scale poorly as repositories grow,
but these tools also will work up to scales that will surprise you. You can
push Maven/Gradle, CMake, Cargo, and the Go build systems very, very far.
Furthermore, if you check-in generated code generated by tools such as
<code>protobuf</code> and <code>thrift</code>, you will be able to use your ecosystem’s IDE
tools without modification<sup id="fnref:5"><a href="#fn:5" role="doc-noteref">5</a></sup>.</p>
<p>In a monorepo, you <em>need</em> the following properties from your build system:</p>
<ol>
<li>Given a build target, build that target as efficiently as possible and produce an artifact.</li>
<li>Given a list of dirty files, produce the list of build targets that are <em>directly or indirectly dirtied</em> by those changes and need to be re-built.</li>
</ol>
<p>Going back to the O(repo) principle, your build system SHOULD be capable of doing this without interacting with every file in the build graph (as e.g. Make does, when evaluating file modification times). Despite their complexity, Bazel and <a href="https://buck2.build">Buck2</a> do provide both of these
capabilities to those who take the time to invest in their build. If your
monorepo consists of a single language (like I said - keep it single language, if you can!) you can write your own program that inspects the build
graph of your language ecosystem’s build and performs this calculation. This
program is often called a “determinator” or “target determinator”:</p>
<ul>
<li>The <a href="https://github.com/guppy-rs/guppy"><code>guppy</code> Rust crate</a> provides means to traverse the Cargo build graph and <a href="https://github.com/guppy-rs/guppy/tree/main/tools/determinator">build a determinator</a></li>
<li>The <a href="https://pkg.go.dev/golang.org/x/tools/go/packages"><code>golang.org/x/tools/go/packages</code> library</a> provides the means to traverse the package graph of a Go application, making it possible to write a determinator for Go packages</li>
<li>If you are using Bazel, this <a href="https://github.com/bazel-contrib/target-determinator"><code>target-determinator</code></a> CLI and Go library is a determinator.</li>
<li>Meta has a sophisticated implementation of a target determinator on top of <code>buck2</code>, but I don’t believe it is open-source.</li>
</ul>
<p>Bazel and Buck2 offer sophisticated remote execution and caching capabilities, but realistically you aren’t going to need these unless your builds are really, really huge. If they are, go talk to <a href="https://www.engflow.com">EngFlow</a> or something. The target determination property is more useful to the average company, because…</p>
<h2 id="testing">Testing</h2>
<p>… when developers are working in your monorepo, they need to know which tests to run to properly evaluate the changes they’ve made. Now that your
company has a monorepo, running <em>all</em> of the tests isn’t a feasible option,
because you suddenly have <em>a lot of tests</em>.</p>
<p>Anyone that has dealt with a large test suite before has lived the experience
of chasing down <em>flaky tests</em> - tests that just fail sometimes. As the number
of tests that you run to validate a change increases, your margin for
flakiness decreases. If each test in your repository has 4 9s of reliability,
in that they flake only one time every 10000, running 1000 tests gives a
no-op change a 90% chance of passing CI. If you run 10000 tests, this
probability goes down to 60%. If you run enough tests, you can end up with
a mathematical near-certainty that your users’ CI test runs fail and they will
be very upset with you.</p>
<p>Your unit testing system needs to get a bit smarter. It now needs to:</p>
<ul>
<li>Automatically retry test failures. A test that flakes with a low probability is substantially less likely to fail a test run if you retry it once. Test retries have substantially diminishing returns; a test that has failed twice in a row is likely to fail a third time. (<a href="https://nexte.st/docs/features/retries/">Example</a>)</li>
<li>Only run tests that need to be run. Using the build system’s target determinator, the testing system can figure out the minimal set of tests that need to be run and only run those. (<a href="https://nexte.st/docs/filtersets/#example-running-all-tests-in-a-crate-and-its-dependencies">Example</a>)</li>
</ul>
<p>Optionally, your testing system can also quarantine tests that are known to be flaky, although that’s an added bonus that can come with time.</p>
<p>Your language ecosystem’s default test system (if it has one) likely does not
support the features that you’re going to need out of this testing system.
Some ecosystems (like Rust’s <a href="https://nexte.st">nextest</a>, Java’s venerable
JUnit, and many others) do have these capabilities.</p>
<h2 id="continuous-integration">Continuous Integration</h2>
<p>When a user submits a pull request to your monorepo, your CI system has
to accomplish two things:</p>
<ol>
<li>Given the scope of the change, produce any build artifacts that need to
be produced to include said changes, and</li>
<li>Run any validations necessary to validate the change.</li>
</ol>
<p>Like the testing system, the CI system needs to inspect the proposed change
and trigger <em>jobs</em> that perform the required build and validation steps for
a particular change. This is deeply tied to the build and test system’s
idea of target determination from previous sections; for many large monorepo
CI systems, the very first job triggered is a target determinator job that
figures out based on the change what other jobs it needs to trigger.</p>
<p>Solving this problem in full generality in a multi-language repository is
challenging, but at its core the algorithmic idea is to attach metadata to the
build graph in such a way that if a node on the build graph is dirtied,
a particular job should<sup id="fnref:6"><a href="#fn:6" role="doc-noteref">6</a></sup> be run (e.g. with <a href="https://bazel.build/extending/aspects">Bazel</a> or <a href="https://buck2.build/docs/bxl/">Buck2</a>). It
can also be as simple as a mapping of target names to job names. The first
CI’s job’s task is now to produce a set of jobs that must run based on how
the changes submitted alter the build graph.</p>
<p>That sounds simple at first. For a long time, it is! However, it has long
been known that a workflow that runs tests off a branch and merges the
branch if they pass is not sufficient to prevent breakages in <code>main</code>.
Open-source tools like <a href="https://bors.tech/homu-io/">homu</a> and the more
recent <a href="https://github.blog/news-insights/product-news/github-merge-queue-is-generally-available/">GitHub Merge Queue</a> will actually run your CI twice;
first, to validate the changes on your pull request, and then again when
the CI system has rebased your changes against the latest change on <code>main</code>
(an operation sometimes called “land”). The merge queue is a serialization
point for all developers operating in this repository. If your CI jobs are
long, users will have their changes languish in the queue for long periods
of time or (worse) booted out of the queue when another engineer introduces
a change that conflicts with their own.</p>
<p>Different projects choose different approaches here. The Rust project
utilizes <a href="https://github.com/bors-ng/bors-ng/">bors</a>, a cousin of <code>homu</code>, to
batch up changes and land them all at once, based on the assumption that
changes that have passed some level of validation already are likely to
continue passing automation at land time. Chromium <a href="https://www.chromium.org/developers/testing/commit-queue/design/">does something similar</a>. Uber uses <a href="https://www.uber.com/blog/research/keeping-master-green-at-scale/">knowledge of the build graph</a> to determine whether or not two changes can be landed concurrently and will do so if it believes it to be safe.</p>
<p>No matter what you choose to do, though, you have a <strong>strong</strong> incentive to
keep your CI as fast as possible to keep the merge queue moving along as
quickly as possible. This is fundamentally at odds with CI’s general goal of catching problems before they reach the mainline. This design space is full
of tradeoffs and you’ll want to think hard about what your organizational
priorities are. In general you can trade off <strong>throughput</strong>, <strong>correctness</strong>, and <strong>tail latency</strong>.</p>
<p>Trading off <strong>throughput</strong> is relatively straightforward - you run <em>all</em> build and validation jobs as part of the land, for every commit. This might take a while and your merge queue might get clogged up during peak working hours, but your main
<em>will</em> remain green at all times.</p>
<p>Trading off <strong>correctness</strong> is also relatively straightforward. Your CI’s
target determinator can choose not to run <em>all</em> jobs but instead probabilistically select <em>some</em> of them, perhaps guided by some Bayesian analysis of which jobs are <em>most likely</em> to catch issues. You lose the
guarantee that main is green all the time, but in exchange your developers
can land code quickly. This tradeoff is often paired with CI jobs that run
<em>all</em> of your tests at a regular cadence (sometimes called “trunk-time testing”, “nightlies”, or “hourlies”) and automatically bisect failures that arise in main.</p>
<p>Trading off <strong>tail latency</strong> is best seen in systems that batch up a bunch of
changes and attempt to land them all at once. If the batch passes validation,
you’ve saved a substantial amount of time in that you don’t have to run this
validation for every commit in the batch; however, if it doesn’t, the entire
batch fails the land and results in a false-positive failure for everyone in
the batch that didn’t cause the breakage.</p>
<p>There’s no silver bullet here. The big monorepo companies all
still wrestle with this problem. You’ll need to navigate the tradeoffs
yourself and decide as an organization which costs you’re willing to tolerate.</p>
<h2 id="continuous-delivery">Continuous Delivery</h2>
<p>The greatest power and biggest lie of the monorepo is that it is possible to make atomic commits across your entire codebase. While this is objectively
true from a <em>code</em> perspective (you certainly can land a PR that, for example, renames a function across your entire codebase), this is <em>not</em> true
from a deployment perspective, and this dangerous lie will cause incidents.</p>
<p>Your monorepo now contains many different deployable artifacts that deploy
at different times. It is also technically possible to make, for example,
a breaking change to a service’s interface, a service’s implementation, and the service’s clients
all in one PR. However, this PR <em>will</em> break when you deploy it because you
do not deploy your service and all of its clients atomically. While this
is also possible in a world with many repositories, the requirement to do
this change in multiple pull requests is often enough to remind engineers
that breaking changes to a service contract are not safe to make.</p>
<p>Your users must understand that your <em>deployment system</em> operates
asynchronously with respect to what happens in the monorepo. Its primary
interaction with the monorepo is to go and pick up the “latest” build
artifacts for a particular service; everything else happens on timetables
that are potentially not under your control and can happen arbitrarily far
in the future.</p>
<p>A common CI job in a monorepo is to validate service contracts and make sure
that they are not broken unless the author deliberately intended to do so,
and they are required to provide a justification as to why such a change is
OK.</p>
<h2 id="conclusion">Conclusion</h2>
<p>A monorepo is a powerful tool for institutional consistency. An organization
can use their monorepo to enforce engineering culture, organizational
standards, and build a culture of code sharing and a willingness to cross
organizational boundaries to solve problems. It does not come for free.
You should be aware of the engineering lifts that you will need to do to
achieve a productive monorepo and be aware that this is a <em>continuous process</em> as you continue to scale and your tools begin to break.</p>
<p>In my experience - it’s worth it, <em>if you’re willing to commit to it</em>.</p>


  </section></div>
  </body>
</html>
