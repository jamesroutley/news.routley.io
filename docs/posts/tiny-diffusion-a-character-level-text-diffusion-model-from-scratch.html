<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/nathan-barry/tiny-diffusion">Original</a>
    <h1>Show HN: Tiny Diffusion – A character-level text diffusion model from scratch</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto">A character-level language diffusion model for text generation. The model is a modified version of the <a href="https://github.com/karpathy/nanochat/blob/master/nanochat/gpt.py">nanochat gpt</a> implementation and is trained on Tiny Shakespeare! It is only 10.7 million parameters, so you can try it out locally!</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/nathan-barry/tiny-diffusion/blob/main/animations/animation.gif"><img src="https://github.com/nathan-barry/tiny-diffusion/raw/main/animations/animation.gif" alt="Demo" data-animated-image=""/></a></p>

<div dir="auto" data-snippet-clipboard-copy-content="# Clone the repository
git clone &lt;repository-url&gt;
cd tiny-diffusion

# Install dependencies (Python 3.10+)
uv sync"><pre><span><span>#</span> Clone the repository</span>
git clone <span>&lt;</span>repository-url<span>&gt;</span>
<span>cd</span> tiny-diffusion

<span><span>#</span> Install dependencies (Python 3.10+)</span>
uv sync</pre></div>

<p dir="auto">The file <code>training.py</code> puts the weights in <code>weights/diffusion_model.pt</code>. The sample and animation files load the model from this file.</p>

<p dir="auto">Currently, the weights are already provided for you! It took me around half an hour to train this model for 20,000 steps on 4xA100s. But if you want to retrain the model again, run:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Train from scratch on Shakespeare
uv run training.py

# Training will save checkpoints to weights/diffusion_model.pt"><pre><span><span>#</span> Train from scratch on Shakespeare</span>
uv run training.py

<span><span>#</span> Training will save checkpoints to weights/diffusion_model.pt</span></pre></div>

<p dir="auto">To generate a continuous stream of output (currently 30 context lengths), run:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Generate samples using the pre-trained model
uv run sample.py"><pre><span><span>#</span> Generate samples using the pre-trained model</span>
uv run sample.py</pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">Visualize the Diffusion Process</h3><a id="user-content-visualize-the-diffusion-process" aria-label="Permalink: Visualize the Diffusion Process" href="#visualize-the-diffusion-process"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">To see the diffusion process as a nice animation, run:</p>
<div dir="auto" data-snippet-clipboard-copy-content="# Watch the denoising process step-by-step
uv run animations/diffusion-process.py

# See Game of Life-inspired sampling (fun little experiment)
uv run animations/game-of-life.py"><pre><span><span>#</span> Watch the denoising process step-by-step</span>
uv run animations/diffusion-process.py

<span><span>#</span> See Game of Life-inspired sampling (fun little experiment)</span>
uv run animations/game-of-life.py</pre></div>

<ul dir="auto">
<li><strong>Parameters</strong>: 10.7 million</li>
<li><strong>Layers</strong>: 6</li>
<li><strong>Attention Heads</strong>: 6</li>
<li><strong>Embedding Dim</strong>: 384</li>
<li><strong>Sequence Length</strong>: 256 characters</li>
<li><strong>Diffusion Steps</strong>: 128</li>
</ul>

<div data-snippet-clipboard-copy-content="tiny-diffusion/
├── model.py                    # Core diffusion transformer
├── training.py                 # Training script
├── sample.py                   # Text generation
├── data/
│   └── tiny_shakespeare.txt    # Training data
├── weights/
│   └── diffusion_model.pt      # Pre-trained weights
└── animations/
    ├── diffusion-process.py    # Denoising visualization
    └── game-of-life.py         # Game of Life sampling"><pre><code>tiny-diffusion/
├── model.py                    # Core diffusion transformer
├── training.py                 # Training script
├── sample.py                   # Text generation
├── data/
│   └── tiny_shakespeare.txt    # Training data
├── weights/
│   └── diffusion_model.pt      # Pre-trained weights
└── animations/
    ├── diffusion-process.py    # Denoising visualization
    └── game-of-life.py         # Game of Life sampling
</code></pre></div>

<p dir="auto">MIT</p>
</article></div></div>
  </body>
</html>
