<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://arxiv.org/abs/2304.03262">Original</a>
    <h1>When do you need chain-of-thought prompting for ChatGPT?</h1>
    
    <div id="readability-page-1" class="page"><div id="content-inner">
  <div id="abs">
    
    
    
      
    
  
  
  
    <p><a aria-describedby="download-button-info" href="https://rfong.github.io/pdf/2304.03262">Download PDF</a></p><blockquote>
      <span>Abstract:</span>  Chain-of-Thought (CoT) prompting can effectively elicit complex multi-step
reasoning from Large Language Models~(LLMs). For example, by simply adding CoT
instruction ``Let&#39;s think step-by-step&#39;&#39; to each input query of MultiArith
dataset, GPT-3&#39;s accuracy can be improved from 17.7\% to 78.7\%. However, it is
not clear whether CoT is still effective on more recent instruction finetuned
(IFT) LLMs such as ChatGPT. Surprisingly, on ChatGPT, CoT is no longer
effective for certain tasks such as arithmetic reasoning while still keeping
effective on other reasoning tasks. Moreover, on the former tasks, ChatGPT
usually achieves the best performance and can generate CoT even without being
instructed to do so. Hence, it is plausible that ChatGPT has already been
trained on these tasks with CoT and thus memorized the instruction so it
implicitly follows such an instruction when applied to the same queries, even
without CoT. Our analysis reflects a potential risk of overfitting/bias toward
instructions introduced in IFT, which becomes more common in training LLMs. In
addition, it indicates possible leakage of the pretraining recipe, e.g., one
can verify whether a dataset and instruction were used in training ChatGPT. Our
experiments report new baseline results of ChatGPT on a variety of reasoning
tasks and shed novel insights into LLM&#39;s profiling, instruction memorization,
and pretraining dataset leakage.

    </blockquote>

    <!--CONTEXT-->
    
  </div>
</div><div>
      <h2>Submission history</h2><p> From: Jiuhai Chen [<a href="https://rfong.github.io/show-email/46752170/2304.03262">view email</a>]
      </p></div></div>
  </body>
</html>
