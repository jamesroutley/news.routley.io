<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://poniesandlight.co.uk/reflect/coroutines_job_system/">Original</a>
    <h1>C&#43;&#43;20 Coroutines Driving a Job System</h1>
    
    <div id="readability-page-1" class="page"><div>
    
  	<p>I had this fiber-based job system which was partly written in assembly, and I badly wanted it to work; and it was working badly. So I decided to rewrite it in C++. In C++20, to be more precise. It was surprisingly pleasant.</p>
<div>
	
<p>The original job system was a nice addition to allow cooperative multitasking in <a href="https://github.com/tgfrerer/island">Island</a>, my R&amp;D renderer.
A key idea was to package up jobs which could potentially run in parallel into a task list, and then hand this task list over to a scheduler to execute on potentially multiple threads. Whoever puts a task list on the scheduler must wait for the full list to complete before resuming.</p>
<figure>
<img loading="lazy" src="https://www.startribune.com/img/coroutines_job_system/fork_join_diagram.png" alt="Fork Join Diagram" title="Fork Join Diagram"/>
<figcaption>
    The <a href="https://en.wikipedia.org/wiki/Fork%E2%80%93join_model">Fork-Join</a> pattern for parallelism.</figcaption>
</figure>
</div>
<div>
	
<p>This follows the <a href="https://w3.cs.jmu.edu/kirkpams/OpenCSF/Books/csf/html/Glossary.html#term-fork-join-pattern">fork-join</a> pattern, which is a relatively straightforward model for parallelism, but without having to pay the price for spinning up new threads, or heavy context switches. Since context switches were very cheap, long-running jobs could suspend midway through execution, allowing even more efficient use of all available CPU cores, by hiding memory latency.</p>
<h2 id="trouble-on-the-horizon">Trouble on the Horizon <a href="#trouble-on-the-horizon"></a></h2>
<p>Trouble was, as hinted earlier, that for Island’s job system, I was using a sprinkle of assembly to flip CPU contexts around. A bad idea.</p>
</div>
<div>
	
<p>Like many bad ideas, it started out of course looking like fun; just as the idea of juggling frozen snakes may, if seen from afar, project a certain allure. But close up, self-written, assembly-based stackful fibers turned out about as brittle as the previous herpetological simile. Especially debugging stack overflows with stacks that you happen to have to maintain yourself may only be pleasant to a subset of the brave, the masochistic, and the meticulous: a very loose Venn diagram. And to top it off, my code was not even portable outside amd64/Linux:</p>
</div>
<div>
	
<p>When I looked into porting the job system to Windows, I found that Visual Studio would not allow inline assembly for 64bit targets. I would have to use a separate assembler, or compiler intrinsics (yuck!), or something else… Fortunately, it turned out, there was something else.</p>

<p>C++ coroutines have been lurking backstage for a few years, and with C++20 they finally appear mature enough to be available with all compilers that I currently care about for Island: GCC, Clang, and MSVC. They seem to have converged on an architectural sweet spot: in contrast to Go with its Goroutines, and my hand-coded assembly nightmare, C++ coroutines are <em>stackless</em>, which means <strong>suspend is only possible within the body of a coroutine</strong>; you cannot suspend within the body of a leaf function. On the plus-side, there is no need to manage your own stack. Lewiss Baker has <a href="https://lewissbaker.github.io/2017/09/25/coroutine-theory">written about this</a> in great detail.</p>
<p>That sounds all very promising. But it will suck all joy out of the new implementation if it ends up very clunky, and hard to use correctly. We really want a nice API for our job system, and (to keep compile time low) we also don’t want to infect our header files with tons of header includes… Will C++ coroutines really be up for the job?</p>
<p>Now, before digging deep into the implementation details, let’s make sure that the surface looks nice. In doing this, I’m taking inspiration from Gor Nishanov, who says <a href="https://youtu.be/j9tlJAqMV7U">in his talk on coroutines</a> (I paraphrase): the best way to make things look nice is to write your application code first, and then to see how you can do this with coroutines.</p>
</div>
<div>
	
<blockquote>
	<p><span>&#34;When people say: How can I do this with Coroutines? I will say, well, think of the best way of solving this problem - just imagine the syntax… And then, you can make it work.&#34;</span>
	</p>
</blockquote>
<p>So let’s do just that: We want an API that allows us to add coroutines to our scheduler, and that, in a simple way, ensures that there is no forward progress until all the jobs in the batch have finished executing. Let’s see what I came up with.</p>
<h2 id="the-most-ergonomic-job-system-that-i-could-think-ofsupersuper">The most ergonomic job system that I could think of:<super>*</super> <a href="#the-most-ergonomic-job-system-that-i-could-think-ofsupersuper"></a></h2>
</div>
<div>
		
	
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span></code></pre></td>
<td>
<pre><code data-lang="cpp"><span>// Create a scheduler with 3 hardware threads if possible
</span><span></span>Scheduler<span>*</span> scheduler <span>=</span> Scheduler<span>::</span>create(<span>3</span>); 

<span>// Create an empty task list
</span><span></span>TaskList tasks; 

tasks.add_task( [](<span>int</span> idx, Scheduler<span>*</span> s) <span>-&gt;</span> Task 
    { 
        cout <span>&lt;&lt;</span> <span>&#34;executing task&#34;</span> <span>&lt;&lt;</span> idx <span>&lt;&lt;</span> endl;
        <span>// nearly anything can happen in here - 
</span><span></span>        <span>// you can call functions etc. just like inside a normal function.
</span><span></span>        <span>co_await</span> <span>suspend_task</span>(); <span>// Suspend this task
</span><span></span>        cout <span>&lt;&lt;</span> <span>&#34;resuming task&#34;</span> <span>&lt;&lt;</span> idx <span>&lt;&lt;</span> endl;
        <span>co_return</span>; <span>// Note: co_return makes this a coroutine
</span><span></span>    }
        (<span>42</span>, scheduler) <span>// Important: These parameters will be **copied** into Task activation frame
</span><span></span>    );

scheduler<span>-&gt;</span>wait_for_task_list(tasks); <span>// schedule and execute tasks
</span><span></span>
cout <span>&lt;&lt;</span> <span>&#34;Finished executing tasks&#34;</span> <span>&lt;&lt;</span> endl;

<span>delete</span> scheduler; <span>// explicitly delete scheduler
</span></code></pre></td></tr></tbody></table>
</div>
</div><p>Now, a few notes about this API: if you look closely, you will notice that what we add to <code>tasks</code> is not a function pointer or a lambda, but <em>the return value that we get from executing the lambda with given parameters</em>. So does this lambda get executed at this point in time? Well, yes and no…</p>
</div>
<div>
	
<p>This is because what looks like a lambda is not a lambda, but more like a factory function for a coroutine, returning a coroutine handle. The coroutine handle is of type <code>Task</code>, and such a coroutine does not immediately execute, but it is initially suspended. How do I know? Because I made sure of this myself. But more on this later, as implementation details should not need to concern us for now.</p>

<p>Instead, let’s <a id="suspend" href="#resume">suspend</a> our disbelief for a moment, and see what nice properties this API brings… For one, we could use the coroutine factory function to elegantly add <span>lots of tasks </span><span>(each initialised with its own parameters)</span> if we wanted:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span></code></pre></td>
<td>
<pre><code data-lang="cpp"><span>// ... 
</span><span></span><span>auto</span> create_task <span>=</span> [](<span>int</span> idx, Scheduler<span>*</span> s)<span>-&gt;</span> Task { 
        cout <span>&lt;&lt;</span> <span>&#34;executing task: &#34;</span> <span>&lt;&lt;</span> idx <span>&lt;&lt;</span> endl;
        <span>co_await</span> <span>suspend_task</span>();
        cout <span>&lt;&lt;</span> <span>&#34;resuming task: &#34;</span> <span>&lt;&lt;</span> idx <span>&lt;&lt;</span> endl;
        <span>co_return</span>;
    };

TaskList tasks;
<span>// let&#39;s add 100 different tasks!
</span><span></span><span>for</span> (<span>int</span> i<span>=</span><span>0</span>; i <span>!=</span> <span>100</span>; i<span>++</span>){
    tasks.add_task( create_task(i, scheduler) );
}
scheduler<span>-&gt;</span>wait_for_task_list(tasks); <span>// schedule and execute tasks
</span><span>// ...
</span></code></pre></td></tr></tbody></table>
</div>
</div><p>Now, to make things more interesting, we could issue new tasks from inside of tasks. All we need is another task generator and a new <code>TaskList</code> object. We submit that to the <code>Scheduler</code>, and wait until we resume:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span><span>16
</span><span>17
</span><span>18
</span><span>19
</span><span>20
</span><span>21
</span><span>22
</span><span>23
</span><span>24
</span><span>25
</span><span>26
</span><span>27
</span><span>28
</span><span>29
</span><span>30
</span><span>31
</span><span>32
</span><span>33
</span></code></pre></td>
<td>
<pre><code data-lang="cpp"><span>// ...
</span><span></span><span>auto</span> create_outer_task <span>=</span> [](<span>int</span> idx, Scheduler<span>*</span> s)<span>-&gt;</span>task { 
        cout <span>&lt;&lt;</span> <span>&#34;executing task: &#34;</span> <span>&lt;&lt;</span> idx <span>&lt;&lt;</span> endl;

        <span>auto</span> create_inner_task <span>=</span> [](<span>int</span> outer, <span>int</span> inner)<span>-&gt;</span>task { 
                cout <span>&lt;&lt;</span> <span>&#34;  executing inner task: &#34;</span> <span>&lt;&lt;</span> outer <span>&lt;&lt;</span> <span>&#34;:&#34;</span> <span>&lt;&lt;</span> inner <span>&lt;&lt;</span> endl;
                <span>co_await</span> <span>suspend_task</span>();
                cout <span>&lt;&lt;</span> <span>&#34;  resuming  inner task: &#34;</span> <span>&lt;&lt;</span> outer <span>&lt;&lt;</span> <span>&#34;:&#34;</span> <span>&lt;&lt;</span> inner <span>&lt;&lt;</span> endl;
                <span>co_return</span>;
            };

        TaskList inner_tasks;
        <span>for</span> (<span>int</span> j <span>=</span> <span>0</span>; j <span>!=</span> <span>20</span>; j<span>++</span>){
            inner_tasks.add_tasks(create_inner_task(idx, j));
        }
        <span>// Wait for inner tasks to complete
</span><span></span>        s<span>-&gt;</span>wait_for_task_list(inner_tasks);

        <span>co_await</span> <span>suspend_task</span>();
        cout <span>&lt;&lt;</span> <span>&#34;resuming task: &#34;</span> <span>&lt;&lt;</span> idx <span>&lt;&lt;</span> endl;
        <span>co_return</span>;
    };

TaskList outer_tasks;
<span>// Let&#39;s add 100 different tasks, each of which will add 
</span><span>// inner tasks once it begins executing.
</span><span></span><span>for</span> (<span>int</span> i<span>=</span><span>0</span>; i <span>!=</span> <span>100</span>; i<span>++</span>){
    outer_tasks.add_task( create_outer_task(i, scheduler) );
}
<span>// Wait for outer tasks to complete (they will only complete if, in turn,
</span><span>// their inner tasks have completed.)
</span><span></span>scheduler<span>-&gt;</span>wait_for_task_list(outer_tasks);
<span>// ...
</span></code></pre></td></tr></tbody></table>
</div>
</div>
</div>
<div>
	
<p>Now, remember that disbelief which we <a id="resume" href="#suspend">suspended</a> earlier? Maybe now would be a good point to resume it, and to take a look at some of the things that need to happen under the surface to make this API a reality.</p>
<h2 id="but-how-does-it-fork">But how does it fork? <a href="#but-how-does-it-fork"></a></h2>
<p>C++20 coroutines are very powerful, and can be used in a lot of different ways, from implementing lazy generators, to state machines, to task graphs. To that end, the new coroutine elements of the language are relatively fine-grained, as they must give a lot of control: I understand them as building blocks to build tools with, and probably not to use directly; and this versatility is what makes coroutines a bit hard to understand at first.</p>
</div>
<div>
	
<p>Some of the complexity comes from C++ coroutines being able to produce (in C++ parlance: “yield”) return values, which for our job scheduler we are not interested in: we can blissfully ignore this…</p>
<p>Another big chunk of complexity comes from coroutines expressing their behaviour largely <em>by specialising types</em>, and this means, building tools on top of coroutines means working <em>with</em> the type system, and if we’re lucky, the compiler will magically generating some glue code. All this makes control flow not immediately obvious.</p>
<p>To keep things simple, I’m only going to focus on the subset of the C++ coroutine API that I used.</p>
<p>For our job system we need the following elements:</p>
<ol>
<li>A way to <strong>define a Task as Function + Parameters</strong></li>
<li>A way to <strong>put a Task initially in suspended state</strong></li>
<li>A way to allow a <strong>Task to suspend itself</strong> if it so wishes</li>
<li>A way to <strong>resume a Task</strong></li>
</ol>
<p>Once we have our <code>Task</code> definition in place, we can look at the remaining two set pieces, namely the <code>TaskList</code>, and the <code>Scheduler</code>. These will complete the system.</p>
<h2 id="1-define-a-task-as-function--parameters">1. Define a Task as Function + Parameters <a href="#1-define-a-task-as-function--parameters"></a></h2>
<p>Our definition for <code>Task</code> uses a slightly strange syntax, but it is surprisingly powerful. When we say:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span></code></pre></td>
<td>
<pre><code data-lang="cpp"><span>auto</span> create_task <span>=</span> [](<span>int</span> idx, Scheduler<span>*</span> s)<span>-&gt;</span>task { 
        cout <span>&lt;&lt;</span> <span>&#34;executing task: &#34;</span> <span>&lt;&lt;</span> idx <span>&lt;&lt;</span> endl;
        <span>co_await</span> <span>suspend_task</span>();
        cout <span>&lt;&lt;</span> <span>&#34;resuming task: &#34;</span> <span>&lt;&lt;</span> idx <span>&lt;&lt;</span> endl;
        <span>co_return</span>;
    };
</code></pre></td></tr></tbody></table>
</div>
</div></div>
<div>
	
<p>We create a <em>generator function</em> for coroutines - this means that whenever we execute the <code>create_task</code> function, the <em>value of its parameters</em> will be copied into the activation frame of the coroutine, the coroutine will be initially suspended, and we immediately receive a new handle to it. The handle is of type <code>Task</code>, and it allows us to resume the coroutine wherever and whenever we want.</p>
<h2 id="2-define-task-in-initially-suspended-state">2. Define Task in Initially Suspended State <a href="#2-define-task-in-initially-suspended-state"></a></h2>
<p>Why can I say that the coroutine will be initially suspended? Because I defined <code>Task</code> this way: <code>Task</code> <strong>is-a</strong> <code>std::coroutine_handle</code> <strong>of</strong> <code>TaskPromise</code>. And <code>TaskPromise</code>’s required member function <code>TaskPromise::initial_suspend()</code> returns an object <strong>conforming-to</strong> <code>awaitable</code>, which <strong>is-a</strong> <code>std::suspend_always</code>.</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span></code></pre></td>
<td>
<pre><code data-lang="cpp"><span>struct</span> <span>Task</span> <span>:</span> std<span>::</span>coroutine_handle<span>&lt;</span>TaskPromise<span>&gt;</span> {
	<span>using</span> promise_type <span>=</span> <span>::</span>TaskPromise;
};

<span>struct</span> <span>TaskPromise</span> {
	std<span>::</span>suspend_always initial_suspend() <span>noexcept</span> { <span>return</span> {}; }
    <span>/* ... */</span>
};
</code></pre></td></tr></tbody></table>
</div>
</div><p>Now, what is this type, <code>std::suspend_always</code>, really? It is an adorable bit of scaffolding that conforms to the traits of an <code>awaitable</code> and must therefore implement a member function <code>await_ready</code>, which is implemented to return <code>false</code> <span>come what may</span><span>, because, honestly, it’s never ready</span>.</p>
</div>
<div>
		
	
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span><span>7
</span><span>8
</span></code></pre></td>
<td>
<pre><code data-lang="cpp">  <span>// 17.12.5 Trivial awaitables
</span><span></span>  <span>/// [coroutine.trivial.awaitables]
</span><span></span>  <span>struct</span> <span>suspend_always</span>
  {
    <span>constexpr</span> <span>bool</span> <span>await_ready</span>() <span>const</span> <span>noexcept</span> { <span>return</span> <span>false</span>; }
    <span>constexpr</span> <span>void</span> <span>await_suspend</span>(coroutine_handle<span>&lt;&gt;</span>) <span>const</span> <span>noexcept</span> {}
    <span>constexpr</span> <span>void</span> <span>await_resume</span>() <span>const</span> <span>noexcept</span> {}
  };
</code></pre></td></tr></tbody></table>
</div>
</div><p>To sum up: A <code>Task</code>’s promise <strong>has-a</strong> required function <code>initial_suspend()</code>, which returns an <strong>object conforming-to</strong> <code>awaitable</code>, which <strong>has-a</strong> member function <code>await_ready</code> which <strong>always-returns</strong> <code>false</code> … is what signals to the compiler that we want our <code>Tasks</code> initially suspended, thank you very much, with ice cream on top.</p>
<h2 id="3-optionally-suspend-tasks-mid-way">3. Optionally Suspend Tasks Mid-Way <a href="#3-optionally-suspend-tasks-mid-way"></a></h2>
<p>Now, apart from being able to begin their journey in suspension, a nice property of coroutines is that they may suspend themselves mid-way. To signal to the compiler <strong>where</strong> they wish to do this, the C++ Standard introduced a new operator, <code>co_await</code>. Inside our coroutine/<code>Task</code> payload function, it can be used like this:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span></code></pre></td>
<td>
<pre><code data-lang="cpp">    <span>// .. coroutine payload code (executed before suspension)
</span><span></span>    <span>co_await</span> <span>my_customisable_type</span>();
    <span>// .. coroutine payload code (executed after this coroutine gets resumed)
</span></code></pre></td></tr></tbody></table>
</div>
</div></div>
<div>
	
<blockquote>
	<p><span>&#34;Not again! Not another customisable type!&#34;</span>
	</p>
</blockquote>
<p>Well, it’s not that tragic, we’ve already encountered the kind of type that is expected for the <code>co_await</code> operator: It needs to conform to the traits of an <code>awaitable</code>, and this time, one of the totally trivial standard <code>awaitable</code> types won’t do, but we’ll have to customise it slightly, and name it <code>suspend_task</code>:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span></code></pre></td>
<td>
<pre><code data-lang="cpp">  <span>struct</span> <span>suspend_task</span> { <span>// conforms to &#34;awaitable&#34; trait
</span><span></span>	<span>constexpr</span> <span>bool</span> <span>await_ready</span>() <span>noexcept</span> { <span>return</span> <span>false</span>; };
	<span>void</span> <span>await_suspend</span>( std<span>::</span>coroutine_handle<span>&lt;::</span>TaskPromise<span>&gt;</span> coroutine_handle ) <span>noexcept</span>;
	<span>void</span> <span>await_resume</span>() <span>noexcept</span> {};
};
</code></pre></td></tr></tbody></table>
</div>
</div><p>Not much to see here - in fact, on the surface it looks exactly like <code>std::suspend_always</code>, which might be the point of all this traits business… But under the surface, in the implementation file, is where we can do all sorts of interesting things:</p>
</div>
<div>
		
	
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span></code></pre></td>
<td>
<pre><code data-lang="cpp"><span>void</span> suspend_task<span>::</span>await_suspend( std<span>::</span>coroutine_handle<span>&lt;</span>TaskPromise<span>&gt;</span> handle ) <span>noexcept</span> {

	<span>// ----------| Invariant: At this point the coroutine represented by `handle`
</span><span></span>	<span>// has been fully suspended. This is guaranteed by the c++ standard.
</span><span></span>
	<span>auto</span><span>&amp;</span> promise <span>=</span> handle.promise();

	<span>auto</span><span>&amp;</span> task_list <span>=</span> promise.p_task_list;

	<span>// Put the current coroutine to the back of the scheduler queue
</span><span></span>	<span>// as it has been fully suspended at this point.
</span><span></span>	task_list<span>-&gt;</span>push_task( promise.get_return_object() );
}
</code></pre></td></tr></tbody></table>
</div>
</div><p>With this, we have everything in place to suspend our Tasks mid-flight, and resume them later.</p>
<p>And here is what happens if, inside of one of our <code>Task</code>s, control reaches a statement saying:</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span></code></pre></td>
<td>
<pre><code data-lang="cpp">    <span>// .. coroutine payload code (executed before suspension)
</span><span></span>    <span>co_await</span> <span>suspend_task</span>();
    <span>// .. coroutine payload code (executed after this coroutine gets resumed)
</span><span></span>
</code></pre></td></tr></tbody></table>
</div>
</div><p>First, the <code>Task</code> containing the statement will get fully suspended.</p>
<p>Immediately after this, the compiler will call <code>await_suspend</code> on a temporary object of type <code>suspend_task</code> that was implicitly created in the statement. The <code>await_suspend()</code> function receives a handle to the suspended <code>Task</code> in its only parameter.</p>
<p><code>await_suspend</code> then takes that coroutine handle and pushes it back onto the <code>TaskList</code> from where it came from, so that the <code>Scheduler</code> can resume the <code>Task</code> later.</p>
<h2 id="4-resume-task-execution">4. Resume Task Execution <a href="#4-resume-task-execution"></a></h2>
<p>Now since all coroutines start out initially suspended, how do they even begin execution? This one is simple - if we have a coroutine handle, we can either call its <code>operator()</code>, or explicitly call <code>.resume()</code> to pass control to it.</p>
<p>For the outcome to be predictable, however, the initiator of any <code>resume()</code> operations on <code>Task</code>s must be a single object, the <code>Scheduler</code>. The <code>Scheduler</code> keeps track of groups of <code>Tasks</code> that may execute in parallel by keeping each group in a <code>TaskList</code>. These elements, <code>TaskList</code>, and <code>Scheduler</code>, are the two missing pieces that complete our system.</p>
<h2 id="scheduling-in-detail-tasklist">Scheduling in Detail: TaskList <a href="#scheduling-in-detail-tasklist"></a></h2>
<p>The <code>TaskList</code> is a ring-buffer storage for <code>Task</code> handles, with an associated workload counter. The <code>TaskList</code> owns all <code>Task</code> handles that are placed into it. Whenever we add such a handle to a <code>TaskList</code>, the <code>TaskList</code> increments its internal workload counter, so that it can keep track of how many <code>Tasks</code> must be completed.</p>
<p>We also add a back-reference to the <code>TaskList</code> to each <code>Task</code>, so that whenever a <code>Task</code> suspends, it can push itself back onto the end of its original <code>TaskList</code> to be resumed and completed later. Once the <code>Task</code> completes, it atomically decrements the workload counter of its <code>TaskList</code>.</p>
<h2 id="scheduling-in-detail-scheduler">Scheduling in Detail: Scheduler <a href="#scheduling-in-detail-scheduler"></a></h2>
<p>All work is done through the <code>Scheduler</code>, and carried out by its worker threads. To this end, the <code>Scheduler</code> maintains and owns a group of system threads that it keeps idle by default. Once the Scheduler is fed a <code>TaskList</code> to process via <code>wait_for_task_list()</code>, it will try to move any <code>Task</code>s from the <code>TaskList</code> (starting at the front of the list) onto worker threads that sit idle.</p>
<p>If the main thread can’t find any idle workers, it will try to execute the <code>Task</code> itself. This means the thread that waits for the <code>TaskList</code> doesn’t just do the scheduling, but potentially contributes useful work in executing Tasks itself.</p>
<p>As the name of the function <code>wait_for_task_list()</code> suggests, it behaves just like a blocking call: forward progress only happens once all <code>Task</code>s in the <code>TaskList</code> have completed. When the function returns, we must consider our <code>TaskList</code> consumed, and invalidated.</p>
<p>The main thread will repeat this loop of trying to assign <code>Task</code>s to worker threads until it notices that the <code>Task List</code>’s workload counter has dropped to zero. If that is the case, this means that all tasks have completed execution, and that the main thread can return from <code>wait_for_task_list()</code>.</p>
<figure>
<img loading="lazy" src="https://www.startribune.com/img/coroutines_job_system/scheduler_animated.gif" alt="Fork Join Diagram" title="Fork Join Diagram"/>
<figcaption>
    The <code>Scheduler</code> processing a <code>TaskList</code> using two worker threads, one being the main thread (<code>W0</code>), the other one a dedicated worker thread (<code>W1</code>).</figcaption>
</figure>
<h2 id="task-completion">Task Completion <a href="#task-completion"></a></h2>
<p>But who does atomically decrement the workload counter of a <code>TaskList</code>, once every Task has been completed? This is where the true arcane <em>magic</em> of C++ coroutines reveals itself:</p>
<p>In what amounts to a magnificent summons of the combined spirits of <a href="https://en.wikipedia.org/wiki/Rube_Goldberg">Rube Goldberg</a> and <a href="https://youtu.be/GXrRC3pfLnE">Fischli &amp; Weiss</a>, this happens because the coroutine promise for <code>Task</code>s was defined with a return type for the required method <code>final_suspend()</code> that returns a custom <code>awaitable</code> that I named <code>finalize_task</code>, which, in turn, declares a required method called <code>await_suspend()</code> which, finally, in its custom implementation, decrements the workload counter, <em>immediately after</em> the <code>Task</code> coroutine was suspended for the very last time after returning.</p>
</div>
<div>
		
	
<div><div>
<table><tbody><tr><td>
<pre><code><span>1
</span><span>2
</span><span>3
</span><span>4
</span><span>5
</span><span>6
</span></code></pre></td>
<td>
<pre><code data-lang="cpp"><span>void</span> finalize_task<span>::</span>await_suspend( std<span>::</span>coroutine_handle<span>&lt;</span>TaskPromise<span>&gt;</span> h ) <span>noexcept</span> {
	<span>// This is the last time that this coroutine will be awakened
</span><span></span>	<span>// we do not suspend it anymore after this
</span><span></span>	h.promise().p_task_list<span>-&gt;</span>decrement_task_count();
	h.destroy(); <span>// are we allowed to destroy here?
</span><span></span>}
</code></pre></td></tr></tbody></table>
</div>
</div><h2 id="bonus-tasks-that-spawn-tasklists">Bonus: Tasks that spawn TaskLists <a href="#bonus-tasks-that-spawn-tasklists"></a></h2>
<p>And what with <code>Task</code>s that spawn <code>Task</code>s of their own? That’s of course possible - as long as a <code>Task</code> has access to the <code>Scheduler</code>, (and you can pass a pointer to the <code>Scheduler</code> as a parameter to a <code>Task</code>, so it <em>is</em> possible), it can create a new <code>TaskList</code>, then pass it to the <code>Scheduler</code> for execution, and await completion before continuing.</p>
</div>
<div>
	
<p>While the caller is waiting, the <code>Scheduler</code> will take the current <code>Task</code> execution context to distribute the <code>Task</code>s from the given <code>TaskList</code> onto any idle worker threads. If there are no idle worker threads available, it will execute the <code>Task</code> itself; that way, we can ensure something akin to load balancing.</p>
<h2 id="eager-worker-led-scheduling">Eager Worker-Led Scheduling <a href="#eager-worker-led-scheduling"></a></h2>
<p>Once a Task completes, instead of returning control immediately to the <code>Scheduler</code>, it will try to pull another Task from its own <code>TaskList</code>, if there are any <code>Task</code>s left in it. This helps to spread the load of scheduling a bit more fairly and equally over any available worker threads. More power to workers!</p>
<div><div>
<table><tbody><tr><td>
<pre><code><span> 1
</span><span> 2
</span><span> 3
</span><span> 4
</span><span> 5
</span><span> 6
</span><span> 7
</span><span> 8
</span><span> 9
</span><span>10
</span><span>11
</span><span>12
</span><span>13
</span><span>14
</span><span>15
</span></code></pre></td>
<td>
<pre><code data-lang="cpp">    <span>// this goes in towards the end of suspend_task::await_suspend
</span><span></span>	{
		<span>// --- Eager Workers ---
</span><span></span>		<span>//
</span><span></span>		<span>// Eagerly try to fetch &amp; execute the next task from the front
</span><span></span>		<span>// of the TaskList where it came from -
</span><span></span>		<span>// We do this so that multiple threads can share the
</span><span></span>		<span>// scheduling workload.
</span><span></span>        <span>//
</span><span></span>		coroutine_handle_t c <span>=</span> task_list<span>-&gt;</span>pop_task();

		<span>if</span> ( c ) {
			c.resume();
		}
	}
</code></pre></td></tr></tbody></table>
</div>
</div><h2 id="github-repo">GitHub Repo <a href="#github-repo"></a></h2>
<p>Phew, what a ride - what started out as a show-and-tell for a nice job-system API slid into the morass of implementation details… Which of course only managed to scratch the surface. If you’re interested in (even) more details about how the elements discussed above work together, and how, for example, I’m avoiding spinlocking, I would point at the GitHub repository that contains the current version of the task system:</p>
</div>
<div>
		
	
<p><a href="https://github.com/tgfrerer/pal_tasks/tree/main">https://github.com/tgfrerer/pal_tasks</a></p>
<p>If you would like to post questions or comments, feel free to open an Issue on this repository :)</p>
<h2 id="in-retrospect">In retrospect <a href="#in-retrospect"></a></h2>
<p>Implementing this job-system with C++ coroutines sometimes felt like programming with callbacks, but using the type system to do so.</p>
<p>One reason for writing this post was to force myself to understand coroutines, not just well enough to write them, but well enough to write <em>about</em> them. At first, I found it pretty hard to figure out the type traits that make up <code>std::coroutines</code>, and how <code>awaitables</code> are key for how they interact, mostly because control flow is not immediately clear, and there is a lot of invisible, compiler-generated code involved.</p>
<p>That said, the traits-based syntax allows us to hide a lot of complexity from the header files, and therefore makes it possible to create a very nice, and clean user-facing API for a job-system, which counts for a lot. I still need to test this system quite a bit, while early performance tests with <code>perf</code> etc. look very promising.</p>
<p>I wonder, however, whether the <strong>stacklessness</strong> of C++ coroutines may make this job-system less versatile compared to a system with stackful coroutines, where we may suspend at any point, but at our peril… Time will tell. I have a feeling that “boring, but safe” could be a good thing in the end. 🐍</p>
<hr/>


	</div>
	
	
	
		<div>
			<h3>RSS:</h3>
			<p>Find out first about new posts by subscribing to the <a href="https://poniesandlight.co.uk/reflect/feed.xml">RSS Feed</a> <a href="https://poniesandlight.co.uk/reflect/feed.xml" type="application/rss+xml"><svg style="width: 1em; position:relative; bottom:-0.25em;" xmlns="http://www.w3.org/2000/svg" viewBox="0 0 448 512"><!--! Font Awesome Pro 6.2.0 by @fontawesome - https://fontawesome.com License - https://fontawesome.com/license (Commercial License) Copyright 2022 Fonticons, Inc. --><path d="M64 32C28.7 32 0 60.7 0 96V416c0 35.3 28.7 64 64 64H384c35.3 0 64-28.7 64-64V96c0-35.3-28.7-64-64-64H64zM96 136c0-13.3 10.7-24 24-24c137 0 248 111 248 248c0 13.3-10.7 24-24 24s-24-10.7-24-24c0-110.5-89.5-200-200-200c-13.3 0-24-10.7-24-24zm0 96c0-13.3 10.7-24 24-24c83.9 0 152 68.1 152 152c0 13.3-10.7 24-24 24s-24-10.7-24-24c0-57.4-46.6-104-104-104c-13.3 0-24-10.7-24-24zm64 120c0 17.7-14.3 32-32 32s-32-14.3-32-32s14.3-32 32-32s32 14.3 32 32z"></path></svg></a></p>
		</div>
	
		<p>
			<h3>Further Posts:</h3>
		</p>
		
        </div></div>
  </body>
</html>
