<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/roboflow/supervision">Original</a>
    <h1>Supervision: Reusable Computer Vision</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto">
  <p dir="auto">
    <a href="https://brian.abelson.live/roboflow/supervision/blob/develop">
      <img width="100%" src="https://camo.githubusercontent.com/6b72c64ca80ade48dd90f820cb403946cde644335c05f400a939644ca0488ed0/68747470733a2f2f6d656469612e726f626f666c6f772e636f6d2f6f70656e2d736f757263652f7375706572766973696f6e2f72662d7375706572766973696f6e2d62616e6e65722e706e673f7570646174656441743d31363738393935393237353239" data-canonical-src="https://media.roboflow.com/open-source/supervision/rf-supervision-banner.png?updatedAt=1678995927529"/>
    </a>
  </p>
  </div>

<p dir="auto"><strong>We write your reusable computer vision tools.</strong> Whether you need to load your dataset from your hard drive, draw detections on an image or video, or count how many detections are in a zone. You can count on us! ü§ù</p>
<p dir="auto"><a href="https://github.com/orgs/roboflow/projects/10"><img src="https://private-user-images.githubusercontent.com/26109316/303423584-c05cc954-b9a6-4ed5-9a52-d0b4b619ff65.png?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTEzNjE5NjUsIm5iZiI6MTcxMTM2MTY2NSwicGF0aCI6Ii8yNjEwOTMxNi8zMDM0MjM1ODQtYzA1Y2M5NTQtYjlhNi00ZWQ1LTlhNTItZDBiNGI2MTlmZjY1LnBuZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDAzMjUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwMzI1VDEwMTQyNVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWViNjFmN2QzN2E2MGNiNjgyMzQ3YmQzZjViZGEwZjdkODE4YjM0NDBiMDQyYTM2OTgxODNhMjJmMjhjMGJlYjgmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.eUsP5mmpXyBjiq9JhIryFmLFQtzej27Vp2iv_JlT_ls" alt="supervision-hackfest" secured-asset-link=""/></a></p>

<p dir="auto">Pip install the supervision package in a
<a href="https://www.python.org/" rel="nofollow"><strong>Python&gt;=3.8</strong></a> environment.</p>

<p dir="auto">Read more about desktop, headless, and local installation in our <a href="https://roboflow.github.io/supervision/" rel="nofollow">guide</a>.</p>


<p dir="auto">Supervision was designed to be model agnostic. Just plug in any classification, detection, or segmentation model. For your convenience, we have created <a href="https://supervision.roboflow.com/latest/detection/core/#detections" rel="nofollow">connectors</a> for the most popular libraries like Ultralytics, Transformers, or MMDetection.</p>
<div dir="auto" data-snippet-clipboard-copy-content="import cv2
import supervision as sv
from ultralytics import YOLO

image = cv2.imread(...)
model = YOLO(&#39;yolov8s.pt&#39;)
result = model(image)[0]
detections = sv.Detections.from_ultralytics(result)

len(detections)
# 5"><pre><span>import</span> <span>cv2</span>
<span>import</span> <span>supervision</span> <span>as</span> <span>sv</span>
<span>from</span> <span>ultralytics</span> <span>import</span> <span>YOLO</span>

<span>image</span> <span>=</span> <span>cv2</span>.<span>imread</span>(...)
<span>model</span> <span>=</span> <span>YOLO</span>(<span>&#39;yolov8s.pt&#39;</span>)
<span>result</span> <span>=</span> <span>model</span>(<span>image</span>)[<span>0</span>]
<span>detections</span> <span>=</span> <span>sv</span>.<span>Detections</span>.<span>from_ultralytics</span>(<span>result</span>)

<span>len</span>(<span>detections</span>)
<span># 5</span></pre></div>
<details>
<summary>üëâ more model connectors</summary>
<ul dir="auto">
<li>
<p dir="auto">inference</p>
<p dir="auto">Running with <a href="https://github.com/roboflow/inference">Inference</a> requires a <a href="https://docs.roboflow.com/api-reference/authentication#retrieve-an-api-key" rel="nofollow">Roboflow API KEY</a>.</p>
<div dir="auto" data-snippet-clipboard-copy-content="import cv2
import supervision as sv
from inference.models.utils import get_roboflow_model

image = cv2.imread(...)
model = get_roboflow_model(model_id=&#34;yolov8s-640&#34;, api_key=&lt;ROBOFLOW API KEY&gt;)
result = model.infer(image)[0]
detections = sv.Detections.from_inference(result)

len(detections)
#¬†5
"><pre><span>import</span> <span>cv2</span>
<span>import</span> <span>supervision</span> <span>as</span> <span>sv</span>
<span>from</span> <span>inference</span>.<span>models</span>.<span>utils</span> <span>import</span> <span>get_roboflow_model</span>

<span>image</span> <span>=</span> <span>cv2</span>.<span>imread</span>(...)
<span>model</span> <span>=</span> <span>get_roboflow_model</span>(<span>model_id</span><span>=</span><span>&#34;yolov8s-640&#34;</span>, <span>api_key</span><span>=</span><span>&lt;</span><span>ROBOFLOW</span> <span>API</span> <span>KEY</span><span>&gt;</span>)
<span>result</span> <span>=</span> <span>model</span>.<span>infer</span>(<span>image</span>)[<span>0</span>]
<span>detections</span> <span>=</span> <span>sv</span>.<span>Detections</span>.<span>from_inference</span>(<span>result</span>)

<span>len</span>(<span>detections</span>)
<span>#¬†5</span></pre></div>
</li>
</ul>
</details>

<p dir="auto">Supervision offers a wide range of highly customizable <a href="https://supervision.roboflow.com/latest/annotators/" rel="nofollow">annotators</a>, allowing you to compose the perfect visualization for your use case.</p>
<div dir="auto" data-snippet-clipboard-copy-content="import cv2
import supervision as sv

image = cv2.imread(...)
detections = sv.Detections(...)

bounding_box_annotator = sv.BoundingBoxAnnotator()
annotated_frame = bounding_box_annotator.annotate(
    scene=image.copy(),
    detections=detections
)"><pre><span>import</span> <span>cv2</span>
<span>import</span> <span>supervision</span> <span>as</span> <span>sv</span>

<span>image</span> <span>=</span> <span>cv2</span>.<span>imread</span>(...)
<span>detections</span> <span>=</span> <span>sv</span>.<span>Detections</span>(...)

<span>bounding_box_annotator</span> <span>=</span> <span>sv</span>.<span>BoundingBoxAnnotator</span>()
<span>annotated_frame</span> <span>=</span> <span>bounding_box_annotator</span>.<span>annotate</span>(
    <span>scene</span><span>=</span><span>image</span>.<span>copy</span>(),
    <span>detections</span><span>=</span><span>detections</span>
)</pre></div>
<details open="">
  <summary>
    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true">
    <path d="M16 3.75v8.5a.75.75 0 0 1-1.136.643L11 10.575v.675A1.75 1.75 0 0 1 9.25 13h-7.5A1.75 1.75 0 0 1 0 11.25v-6.5C0 3.784.784 3 1.75 3h7.5c.966 0 1.75.784 1.75 1.75v.675l3.864-2.318A.75.75 0 0 1 16 3.75Zm-6.5 1a.25.25 0 0 0-.25-.25h-7.5a.25.25 0 0 0-.25.25v6.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-6.5ZM11 8.825l3.5 2.1v-5.85l-3.5 2.1Z"></path>
</svg>
    <span aria-label="Video description supervision-0.16.0-annotators.mp4">supervision-0.16.0-annotators.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/26109316/276552454-691e219c-0565-4403-9218-ab5644f39bce.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTEzNjE5NjUsIm5iZiI6MTcxMTM2MTY2NSwicGF0aCI6Ii8yNjEwOTMxNi8yNzY1NTI0NTQtNjkxZTIxOWMtMDU2NS00NDAzLTkyMTgtYWI1NjQ0ZjM5YmNlLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDAzMjUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwMzI1VDEwMTQyNVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTVlOTU1MWI0MmRlMmY2MjA3ZTZlMjM2ZjE4YTM5ODliOTc4YTZjYmMyNDlkOTc4ODExODZjYjJhNGI3ODRhZmImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.HE-7PngpZGSwSF-l5mLAJb2xXuHiHiLVVfFv64lBxIo" data-canonical-src="https://private-user-images.githubusercontent.com/26109316/276552454-691e219c-0565-4403-9218-ab5644f39bce.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTEzNjE5NjUsIm5iZiI6MTcxMTM2MTY2NSwicGF0aCI6Ii8yNjEwOTMxNi8yNzY1NTI0NTQtNjkxZTIxOWMtMDU2NS00NDAzLTkyMTgtYWI1NjQ0ZjM5YmNlLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDAzMjUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwMzI1VDEwMTQyNVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTVlOTU1MWI0MmRlMmY2MjA3ZTZlMjM2ZjE4YTM5ODliOTc4YTZjYmMyNDlkOTc4ODExODZjYjJhNGI3ODRhZmImWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.HE-7PngpZGSwSF-l5mLAJb2xXuHiHiLVVfFv64lBxIo" controls="controls" muted="muted">

  </video>
</details>


<p dir="auto">Supervision provides a set of <a href="https://supervision.roboflow.com/latest/datasets/" rel="nofollow">utils</a> that allow you to load, split, merge, and save datasets in one of the supported formats.</p>
<div dir="auto" data-snippet-clipboard-copy-content="import supervision as sv

dataset = sv.DetectionDataset.from_yolo(
    images_directory_path=...,
    annotations_directory_path=...,
    data_yaml_path=...
)

dataset.classes
[&#39;dog&#39;, &#39;person&#39;]

len(dataset)
#¬†1000"><pre><span>import</span> <span>supervision</span> <span>as</span> <span>sv</span>

<span>dataset</span> <span>=</span> <span>sv</span>.<span>DetectionDataset</span>.<span>from_yolo</span>(
    <span>images_directory_path</span><span>=</span>...,
    <span>annotations_directory_path</span><span>=</span>...,
    <span>data_yaml_path</span><span>=</span>...
)

<span>dataset</span>.<span>classes</span>
[<span>&#39;dog&#39;</span>, <span>&#39;person&#39;</span>]

<span>len</span>(<span>dataset</span>)
<span>#¬†1000</span></pre></div>
<details>
<summary>üëâ more dataset utils</summary>
<ul dir="auto">
<li>
<p dir="auto">load</p>
<div dir="auto" data-snippet-clipboard-copy-content="dataset = sv.DetectionDataset.from_yolo(
    images_directory_path=...,
    annotations_directory_path=...,
    data_yaml_path=...
)

dataset = sv.DetectionDataset.from_pascal_voc(
    images_directory_path=...,
    annotations_directory_path=...
)

dataset = sv.DetectionDataset.from_coco(
    images_directory_path=...,
    annotations_path=...
)"><pre><span>dataset</span> <span>=</span> <span>sv</span>.<span>DetectionDataset</span>.<span>from_yolo</span>(
    <span>images_directory_path</span><span>=</span>...,
    <span>annotations_directory_path</span><span>=</span>...,
    <span>data_yaml_path</span><span>=</span>...
)

<span>dataset</span> <span>=</span> <span>sv</span>.<span>DetectionDataset</span>.<span>from_pascal_voc</span>(
    <span>images_directory_path</span><span>=</span>...,
    <span>annotations_directory_path</span><span>=</span>...
)

<span>dataset</span> <span>=</span> <span>sv</span>.<span>DetectionDataset</span>.<span>from_coco</span>(
    <span>images_directory_path</span><span>=</span>...,
    <span>annotations_path</span><span>=</span>...
)</pre></div>
</li>
<li>
<p dir="auto">split</p>
<div dir="auto" data-snippet-clipboard-copy-content="train_dataset, test_dataset = dataset.split(split_ratio=0.7)
test_dataset, valid_dataset = test_dataset.split(split_ratio=0.5)

len(train_dataset), len(test_dataset), len(valid_dataset)
#¬†(700, 150, 150)"><pre><span>train_dataset</span>, <span>test_dataset</span> <span>=</span> <span>dataset</span>.<span>split</span>(<span>split_ratio</span><span>=</span><span>0.7</span>)
<span>test_dataset</span>, <span>valid_dataset</span> <span>=</span> <span>test_dataset</span>.<span>split</span>(<span>split_ratio</span><span>=</span><span>0.5</span>)

<span>len</span>(<span>train_dataset</span>), <span>len</span>(<span>test_dataset</span>), <span>len</span>(<span>valid_dataset</span>)
<span>#¬†(700, 150, 150)</span></pre></div>
</li>
<li>
<p dir="auto">merge</p>
<div dir="auto" data-snippet-clipboard-copy-content="ds_1 = sv.DetectionDataset(...)
len(ds_1)
#¬†100
ds_1.classes
#¬†[&#39;dog&#39;, &#39;person&#39;]

ds_2 = sv.DetectionDataset(...)
len(ds_2)
# 200
ds_2.classes
#¬†[&#39;cat&#39;]

ds_merged = sv.DetectionDataset.merge([ds_1, ds_2])
len(ds_merged)
#¬†300
ds_merged.classes
#¬†[&#39;cat&#39;, &#39;dog&#39;, &#39;person&#39;]"><pre><span>ds_1</span> <span>=</span> <span>sv</span>.<span>DetectionDataset</span>(...)
<span>len</span>(<span>ds_1</span>)
<span>#¬†100</span>
<span>ds_1</span>.<span>classes</span>
<span>#¬†[&#39;dog&#39;, &#39;person&#39;]</span>

<span>ds_2</span> <span>=</span> <span>sv</span>.<span>DetectionDataset</span>(...)
<span>len</span>(<span>ds_2</span>)
<span># 200</span>
<span>ds_2</span>.<span>classes</span>
<span>#¬†[&#39;cat&#39;]</span>

<span>ds_merged</span> <span>=</span> <span>sv</span>.<span>DetectionDataset</span>.<span>merge</span>([<span>ds_1</span>, <span>ds_2</span>])
<span>len</span>(<span>ds_merged</span>)
<span>#¬†300</span>
<span>ds_merged</span>.<span>classes</span>
<span>#¬†[&#39;cat&#39;, &#39;dog&#39;, &#39;person&#39;]</span></pre></div>
</li>
<li>
<p dir="auto">save</p>
<div dir="auto" data-snippet-clipboard-copy-content="dataset.as_yolo(
    images_directory_path=...,
    annotations_directory_path=...,
    data_yaml_path=...
)

dataset.as_pascal_voc(
    images_directory_path=...,
    annotations_directory_path=...
)

dataset.as_coco(
    images_directory_path=...,
    annotations_path=...
)"><pre><span>dataset</span>.<span>as_yolo</span>(
    <span>images_directory_path</span><span>=</span>...,
    <span>annotations_directory_path</span><span>=</span>...,
    <span>data_yaml_path</span><span>=</span>...
)

<span>dataset</span>.<span>as_pascal_voc</span>(
    <span>images_directory_path</span><span>=</span>...,
    <span>annotations_directory_path</span><span>=</span>...
)

<span>dataset</span>.<span>as_coco</span>(
    <span>images_directory_path</span><span>=</span>...,
    <span>annotations_path</span><span>=</span>...
)</pre></div>
</li>
<li>
<p dir="auto">convert</p>
<div dir="auto" data-snippet-clipboard-copy-content="sv.DetectionDataset.from_yolo(
    images_directory_path=...,
    annotations_directory_path=...,
    data_yaml_path=...
).as_pascal_voc(
    images_directory_path=...,
    annotations_directory_path=...
)"><pre><span>sv</span>.<span>DetectionDataset</span>.<span>from_yolo</span>(
    <span>images_directory_path</span><span>=</span>...,
    <span>annotations_directory_path</span><span>=</span>...,
    <span>data_yaml_path</span><span>=</span>...
).<span>as_pascal_voc</span>(
    <span>images_directory_path</span><span>=</span>...,
    <span>annotations_directory_path</span><span>=</span>...
)</pre></div>
</li>
</ul>
</details>

<p dir="auto">
<a href="https://youtu.be/uWP6UjDeZvY" title="Speed Estimation &amp; Vehicle Tracking | Computer Vision | Open Source" rel="nofollow"><img src="https://private-user-images.githubusercontent.com/26109316/297074306-61a444c8-b135-48ce-b979-2a5ab47c5a91.jpg?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3MTEzNjE5NjUsIm5iZiI6MTcxMTM2MTY2NSwicGF0aCI6Ii8yNjEwOTMxNi8yOTcwNzQzMDYtNjFhNDQ0YzgtYjEzNS00OGNlLWI5NzktMmE1YWI0N2M1YTkxLmpwZz9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDAzMjUlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQwMzI1VDEwMTQyNVomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTE5NTk2MTdhYzAwMTVhYmQ4MmYxNTIxYTcwZDFmMTkzZmY2NDYzYmZhMGM1ZGYxZjQwODRiYzMzMzMwOTlmNmMmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0JmFjdG9yX2lkPTAma2V5X2lkPTAmcmVwb19pZD0wIn0.6v_K7DKa5tPtmvEf7uYEZIv0hkHmQL9lPprM0I7aJrs" alt="Speed Estimation &amp; Vehicle Tracking | Computer Vision | Open Source" width="300px" secured-asset-link=""/></a>
<a href="https://youtu.be/uWP6UjDeZvY" title="Speed Estimation &amp; Vehicle Tracking | Computer Vision | Open Source" rel="nofollow"><strong>Speed Estimation &amp; Vehicle Tracking | Computer Vision | Open Source</strong></a>
</p><p><strong>Created: 11 Jan 2024</strong> | <strong>Updated: 11 Jan 2024</strong></p>
</article></div></div>
  </body>
</html>
