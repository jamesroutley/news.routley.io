<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.bitsxpages.com/p/sorted-string-tables-sst-from-first">Original</a>
    <h1>Sorted string tables (SST) from first principles</h1>
    
    <div id="readability-page-1" class="page"><div><div dir="auto"><p>This blog is about how data is laid out on disk, specifically about the details of Sorted String Tables (SSTs). Let’s cut to the chase.</p><p>First, it’s important to understand how data gets from disk in to usable memory. Most cloud instances use SSDs, so we’ll focus on that instead of spinning disks.</p><p><span>If you haven’t read the </span><a href="https://www.bitsxpages.com/p/frameworks-for-understanding-databases" rel="">initial frameworks blog post</a><span> of this series I recommend starting with that. In this context, the main point to takeaway is that not all read amplification is created equal. All databases need to abide by the laws of physics: fetching data that’s already in memory is hundreds of times faster than fetching data from over the network. Data structure design is all about minimizing the amount of data you need to fetch from expensive storage tiers while reducing the memory overhead (this an application of the </span><a href="http://daslab.seas.harvard.edu/rum-conjecture/" rel="">RUM conjecture</a><span>).</span></p><p>A high performance data system needs to reduce the amount of unnecessary bytes read to serve a query, reading only the necessary (”hot”) data.</p><p><span>An ideal system would read </span><em>exactly</em><span> the bytes it needs for the data it wants, but the fundamental unit of I/O isn’t a byte. On SSDs, it’s a page (typically 4KB). This means that whether you request a single byte, a hundreds bytes, or four thousand bytes from your disk you’ll still get the 4KB.</span></p><p>You can verify this on your own machine:</p><pre><code><code># on MacOS, check the size of the page on your disk
&gt; stat -f %k /
4096</code></code></pre><p><span>To see this in action, I ran an </span><a href="https://github.com/agavra/bits-x-pages/tree/main/experiments/fetching_blocks" rel="">experiment</a><span> measuring read latency for 1KB vs 4KB reads using Direct I/O (bypassing the OS page cache). Despite requesting 4x less data, the 1KB reads took about the same time as the 4KB reads (about 9.2µs) on my SSD</span><span data-state="closed"><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-1-183585370" href="https://www.bitsxpages.com/p/sorted-string-tables-sst-from-first#footnote-1-183585370" target="_self" rel="">1</a></span><span>:</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!e5HM!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8860c0b4-be08-4b07-b5fb-9d5dc32b6cba_3466x754.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!e5HM!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8860c0b4-be08-4b07-b5fb-9d5dc32b6cba_3466x754.png 424w, https://substackcdn.com/image/fetch/$s_!e5HM!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8860c0b4-be08-4b07-b5fb-9d5dc32b6cba_3466x754.png 848w, https://substackcdn.com/image/fetch/$s_!e5HM!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8860c0b4-be08-4b07-b5fb-9d5dc32b6cba_3466x754.png 1272w, https://substackcdn.com/image/fetch/$s_!e5HM!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8860c0b4-be08-4b07-b5fb-9d5dc32b6cba_3466x754.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/$s_!e5HM!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8860c0b4-be08-4b07-b5fb-9d5dc32b6cba_3466x754.png" width="1456" height="317" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/8860c0b4-be08-4b07-b5fb-9d5dc32b6cba_3466x754.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:317,&#34;width&#34;:1456,&#34;resizeWidth&#34;:null,&#34;bytes&#34;:102269,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:&#34;https://www.bitsxpages.com/i/183585370?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8860c0b4-be08-4b07-b5fb-9d5dc32b6cba_3466x754.png&#34;,&#34;isProcessing&#34;:false,&#34;align&#34;:null,&#34;offset&#34;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!e5HM!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8860c0b4-be08-4b07-b5fb-9d5dc32b6cba_3466x754.png 424w, https://substackcdn.com/image/fetch/$s_!e5HM!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8860c0b4-be08-4b07-b5fb-9d5dc32b6cba_3466x754.png 848w, https://substackcdn.com/image/fetch/$s_!e5HM!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8860c0b4-be08-4b07-b5fb-9d5dc32b6cba_3466x754.png 1272w, https://substackcdn.com/image/fetch/$s_!e5HM!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8860c0b4-be08-4b07-b5fb-9d5dc32b6cba_3466x754.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a></figure></div><p>Here’s where it gets interesting for database design. Imagine you’re serving a query that needs a single 256B row that lives somewhere in a 4KB page alongside other rows:</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!Y635!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca6ffe51-0dd7-4dbb-a54b-cf1d3b5aaa87_1178x470.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!Y635!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca6ffe51-0dd7-4dbb-a54b-cf1d3b5aaa87_1178x470.png 424w, https://substackcdn.com/image/fetch/$s_!Y635!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca6ffe51-0dd7-4dbb-a54b-cf1d3b5aaa87_1178x470.png 848w, https://substackcdn.com/image/fetch/$s_!Y635!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca6ffe51-0dd7-4dbb-a54b-cf1d3b5aaa87_1178x470.png 1272w, https://substackcdn.com/image/fetch/$s_!Y635!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca6ffe51-0dd7-4dbb-a54b-cf1d3b5aaa87_1178x470.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/$s_!Y635!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca6ffe51-0dd7-4dbb-a54b-cf1d3b5aaa87_1178x470.png" width="620" height="247.3684210526316" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/ca6ffe51-0dd7-4dbb-a54b-cf1d3b5aaa87_1178x470.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:470,&#34;width&#34;:1178,&#34;resizeWidth&#34;:620,&#34;bytes&#34;:32806,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:&#34;https://www.bitsxpages.com/i/183585370?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca6ffe51-0dd7-4dbb-a54b-cf1d3b5aaa87_1178x470.png&#34;,&#34;isProcessing&#34;:false,&#34;align&#34;:null,&#34;offset&#34;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!Y635!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca6ffe51-0dd7-4dbb-a54b-cf1d3b5aaa87_1178x470.png 424w, https://substackcdn.com/image/fetch/$s_!Y635!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca6ffe51-0dd7-4dbb-a54b-cf1d3b5aaa87_1178x470.png 848w, https://substackcdn.com/image/fetch/$s_!Y635!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca6ffe51-0dd7-4dbb-a54b-cf1d3b5aaa87_1178x470.png 1272w, https://substackcdn.com/image/fetch/$s_!Y635!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fca6ffe51-0dd7-4dbb-a54b-cf1d3b5aaa87_1178x470.png 1456w" sizes="100vw" loading="lazy"/></picture><div></div></div></a></figure></div><p><span>To read </span><code>row3</code><span>, you have to read the entire page. Rows 1 through 10 come along for the ride whether you want them or not. The ratio of “data you read” to “data you needed” is an instance of read amplification. In our example, if you needed 256 bytes but read 4KB, your read amplification is 16x. That sounds sub-optimal, but it’s unavoidable given the hardware constraints.</span></p><p>The read amplification from page size and sizes isn’t all bad news.</p><p>There’s a fixed cost overhead to reading a single page from disk. On an SSD the actual data transfer part is less than 1-2% of the total latency (the rest comes from processing the command, translating the logical address to the physical location on the disk, etc…). This means that it takes approximately the same amount of time to read 1 page, independent of whether that block is sized 512B on a 512B system or 4KB on a 4KB system.</p><p>To take advantage of the page size, databases attempt to place data that is commonly read together physically close together on the storage device, ideally in the same page. Typically this means one of two things: either the data keys are the similar (spatial locality) or the keys were written around the same time (temporal locality).</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!9t2D!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5619b6c-4ca1-461c-9cda-d5661a2b3c51_1486x782.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!9t2D!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5619b6c-4ca1-461c-9cda-d5661a2b3c51_1486x782.png 424w, https://substackcdn.com/image/fetch/$s_!9t2D!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5619b6c-4ca1-461c-9cda-d5661a2b3c51_1486x782.png 848w, https://substackcdn.com/image/fetch/$s_!9t2D!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5619b6c-4ca1-461c-9cda-d5661a2b3c51_1486x782.png 1272w, https://substackcdn.com/image/fetch/$s_!9t2D!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5619b6c-4ca1-461c-9cda-d5661a2b3c51_1486x782.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/$s_!9t2D!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5619b6c-4ca1-461c-9cda-d5661a2b3c51_1486x782.png" width="1456" height="766" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/b5619b6c-4ca1-461c-9cda-d5661a2b3c51_1486x782.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:766,&#34;width&#34;:1456,&#34;resizeWidth&#34;:null,&#34;bytes&#34;:73508,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:&#34;https://www.bitsxpages.com/i/183585370?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5619b6c-4ca1-461c-9cda-d5661a2b3c51_1486x782.png&#34;,&#34;isProcessing&#34;:false,&#34;align&#34;:null,&#34;offset&#34;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!9t2D!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5619b6c-4ca1-461c-9cda-d5661a2b3c51_1486x782.png 424w, https://substackcdn.com/image/fetch/$s_!9t2D!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5619b6c-4ca1-461c-9cda-d5661a2b3c51_1486x782.png 848w, https://substackcdn.com/image/fetch/$s_!9t2D!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5619b6c-4ca1-461c-9cda-d5661a2b3c51_1486x782.png 1272w, https://substackcdn.com/image/fetch/$s_!9t2D!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb5619b6c-4ca1-461c-9cda-d5661a2b3c51_1486x782.png 1456w" sizes="100vw" loading="lazy"/></picture><div></div></div></a></figure></div><p>This technique helps reduce the overhead of read amplification that comes from reading data you won’t access. As an example, if I’m executing a query that sums the total cost of orders from a particular customer my query execution path is likely to perform a loop that looks something like:</p><pre><code><code>total = 0
for order_id in [cust2_order1, cust2_order2, cust2_order3]:
	let order := db.get(order_id)
	total += order.cost
</code></code></pre><p><span>If my first call to </span><code>db.get(cust2_order1)</code><span> fetches a 4KB page from disk that contains the orders </span><code>cust2_order2</code><span> and </span><code>cust2_order3</code><span> then when I next call </span><code>db.get(cust2_order2)</code><span> that data will already be in the OS page cache, which will make it much faster to load.</span></p><p>This is why designing the key for your database is so important. It is the first attempt to make sure that you can take advantage of the spatial locality of the data on disk.</p><p>Unlike hard drives and spinning disks, data that’s written onto an SSD cannot be directly replaced without first erasing that data. The electromagnetic physics behind it is beyond my expertise, but the way I think about it is that while you can write a small (4K) page, you cannot target erasure at that level. Instead, erasure works at a much higher level called a block (typically 128-256KB).</p><p>Because of this effect, when you rewrite data on an SSD you are actually writing a new data block and telling the SSD controller (a piece of firmware that comes loaded on your SSD) the new location of the data. Eventually, the controller will erase large chunks of garbage data in a mechanism that looks very similar to handling garbage collection in a memory allocator.</p><p>SSDs, therefore, much prefer that pages are not modified over and over again. Instead they become invalid in large ranges at a time. This means that immutable on-disk data structures work well with SSDs and any mutable structure will cause significant write amplification at the hardware level. We’ll get to the implications of this a little more in a future blog post about B-Trees and LSM trees.</p><p>For now, we’ll draw the conclusion that immutable storage formats have an edge.</p><p>To recap the above sections, SSDs push you to use a data structure that:</p><ol><li><p>Is written and deleted in large batches aligned to the internal block size (e.g. 256KB)</p></li><li><p>Is immutable to avoid the overhead associated with rewriting data</p></li><li><p>Organizes data in a way that clusters related data together to take advantage of the page size</p></li></ol><p>There are several ways to organize immutable data durably that meet these requirements, the simplest of which is an append-only log. In a log, the system writes records sequentially (aligned to block size) and scans from the beginning for reads. You can see why this works well with SSDs: </p><ol><li><p>Logs let you batch data together and write them when you have enough data.</p></li><li><p>Logs are immutable, typically with some retention at which point you drop entire sections of it. </p></li><li><p>Logs organize data in a way that is optimized for the particular read pattern of reading data in the order it was written.</p></li></ol><p>The downside of a log is the performance of random reads: you might need to scan the entire file to find a specific key. Some systems (like BitCask) address this by storing the entire key-set in memory with pointers to the location on disk stored in memory.</p><p>To make reads directly from disk efficient without exploding memory usage, you need some other kind of structure. There are a number of different strategies, but for this post I’ll focus on a typical approach used by row-based systems (SSTs).</p><p>Sorted String Tables (SSTs) build off the ideas from the log to play well with the limits of SSDs (you’ll see the similarity even further when we talk about LSM trees). If you think of a log as an array sorted on an implicit timestamp key, SSTs are essentially the same structure but sorted on a user-defined key instead. To make this possible, databases that use SSTs first buffer data sorted by that key in memory until they’ve collected enough data to write a large, immutable batch.</p><p><span>This section will go over the design and implementation of a basic SST: an immutable storage data structure for key-value data. Here’s a reference to look back on that covers the big-picture of an SST layout (this is inspired from the </span><a href="https://github.com/slatedb/slatedb/blob/main/schemas/sst.fbs" rel="">SlateDB SST layout</a><span>, though other implementations such as RocksDB are quite similar):</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!CTOd!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d142aea-18f9-4137-9382-3ef042dd5fd3_604x678.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!CTOd!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d142aea-18f9-4137-9382-3ef042dd5fd3_604x678.png 424w, https://substackcdn.com/image/fetch/$s_!CTOd!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d142aea-18f9-4137-9382-3ef042dd5fd3_604x678.png 848w, https://substackcdn.com/image/fetch/$s_!CTOd!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d142aea-18f9-4137-9382-3ef042dd5fd3_604x678.png 1272w, https://substackcdn.com/image/fetch/$s_!CTOd!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d142aea-18f9-4137-9382-3ef042dd5fd3_604x678.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/$s_!CTOd!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d142aea-18f9-4137-9382-3ef042dd5fd3_604x678.png" width="390" height="437.78145695364236" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/1d142aea-18f9-4137-9382-3ef042dd5fd3_604x678.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:678,&#34;width&#34;:604,&#34;resizeWidth&#34;:390,&#34;bytes&#34;:48358,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:&#34;https://www.bitsxpages.com/i/183585370?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d142aea-18f9-4137-9382-3ef042dd5fd3_604x678.png&#34;,&#34;isProcessing&#34;:false,&#34;align&#34;:null,&#34;offset&#34;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!CTOd!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d142aea-18f9-4137-9382-3ef042dd5fd3_604x678.png 424w, https://substackcdn.com/image/fetch/$s_!CTOd!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d142aea-18f9-4137-9382-3ef042dd5fd3_604x678.png 848w, https://substackcdn.com/image/fetch/$s_!CTOd!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d142aea-18f9-4137-9382-3ef042dd5fd3_604x678.png 1272w, https://substackcdn.com/image/fetch/$s_!CTOd!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F1d142aea-18f9-4137-9382-3ef042dd5fd3_604x678.png 1456w" sizes="100vw" loading="lazy"/></picture><div></div></div></a></figure></div><p>The core concept of a sorted string table is to store data on disk sorted by the lexicographical ordering of the byte representation of their keys. In other words, a single data block of an SST can be thought of as a byte array constructed like this:</p><pre><code><code>struct Record {
	key: Vec&lt;u8&gt;,
	val: Vec&lt;u8&gt;,
}

struct SstDataBlock {
	data: Vec&lt;Record&gt;,
}

impl SstDataBlock {
    fn from_unsorted(data: Vec&lt;Record&gt;) -&gt; Self {
        let mut data = data;
        // sorts the records by the lexicographic order of the keys
        data.sort_by(|a, b| a.key.cmp(&amp;b.key));
        Self { data }
    }
}
</code></code></pre><p><span>This strategy is nice for two reasons: first, it takes advantage of the spatial locality principle we discussed above. Similar keys are stored next to one another. Second, and perhaps more fundamental, it allows us to binary search the </span><code>data</code><span> within an </span><code>SstDataBlock</code><span>:</span></p><pre><code><code>fn find_record(&amp;self, key: &amp;[u8]) -&gt; Option&lt;&amp;Record&gt; {
    self.data.binary_search_by(|record| record.key.as_slice().cmp(key))
        .ok()
        .map(|index| &amp;self.data[index])
}
</code></code></pre><p><span>But this relies on the in-memory representation of the </span><code>SstDataBlock</code><span>. We still need some way to get this struct onto disk which only understands simple byte arrays </span><code>[u8]</code><span>. There are many strategies for serializing the data block of an SST; production data systems will often use techniques such as </span><a href="https://github.com/slatedb/slatedb/blob/4296c696b8b7c1cdf2ad79a9900de0d769a75576/slatedb/src/row_codec.rs#L18-L54" rel="">prefix encoding for keys</a><span> and </span><a href="https://en.wikipedia.org/wiki/Variable-length_quantity#Variants" rel="">varint</a><span> encoding for lengths to reduce the amount of space a block takes up but for this exercise we’ll do something simpler: we’ll just encode the block as:</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!UIPw!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F686a41a2-218f-42ff-9b05-c0e1c3b261fb_856x210.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!UIPw!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F686a41a2-218f-42ff-9b05-c0e1c3b261fb_856x210.png 424w, https://substackcdn.com/image/fetch/$s_!UIPw!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F686a41a2-218f-42ff-9b05-c0e1c3b261fb_856x210.png 848w, https://substackcdn.com/image/fetch/$s_!UIPw!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F686a41a2-218f-42ff-9b05-c0e1c3b261fb_856x210.png 1272w, https://substackcdn.com/image/fetch/$s_!UIPw!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F686a41a2-218f-42ff-9b05-c0e1c3b261fb_856x210.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/$s_!UIPw!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F686a41a2-218f-42ff-9b05-c0e1c3b261fb_856x210.png" width="444" height="108.92523364485982" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/686a41a2-218f-42ff-9b05-c0e1c3b261fb_856x210.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:210,&#34;width&#34;:856,&#34;resizeWidth&#34;:444,&#34;bytes&#34;:17491,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:&#34;https://www.bitsxpages.com/i/183585370?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F686a41a2-218f-42ff-9b05-c0e1c3b261fb_856x210.png&#34;,&#34;isProcessing&#34;:false,&#34;align&#34;:null,&#34;offset&#34;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!UIPw!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F686a41a2-218f-42ff-9b05-c0e1c3b261fb_856x210.png 424w, https://substackcdn.com/image/fetch/$s_!UIPw!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F686a41a2-218f-42ff-9b05-c0e1c3b261fb_856x210.png 848w, https://substackcdn.com/image/fetch/$s_!UIPw!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F686a41a2-218f-42ff-9b05-c0e1c3b261fb_856x210.png 1272w, https://substackcdn.com/image/fetch/$s_!UIPw!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F686a41a2-218f-42ff-9b05-c0e1c3b261fb_856x210.png 1456w" sizes="100vw" loading="lazy"/></picture></div></a></figure></div><p><span>And a code mockup for reading and writing these </span><code>SstDataBlock</code><span> instances:</span></p><pre><code><code>fn encode(&amp;self) -&gt; Vec&lt;u8&gt; {
    let mut encoded = Vec::new();
    encoded.extend_from_slice(&amp;(self.data.len() as u32).to_le_bytes());

    for record in &amp;self.data {
        encoded.extend_from_slice(&amp;(record.key.len() as u32).to_le_bytes());
        encoded.extend_from_slice(&amp;record.key);
        encoded.extend_from_slice(&amp;(record.val.len() as u32).to_le_bytes());
        encoded.extend_from_slice(&amp;record.val);
    }

    encoded
}

fn decode(data: &amp;[u8]) -&gt; Self {
  // decode is more verbose so it&#39;s emitted here but it just reads
  // the number of records, then deserializes them one by one reading
  // the length of the key, then the key, then length of the value,
  // then the value itself
  ...
}</code></code></pre><p>The data block covers how to get a record from within a block, and technically this is all you need for a functioning SST.</p><p>Simply storing data as a series of sorted blocks, however, isn’t ideal. If that’s all you did, your query algorithm would end up reading blocks in a binary-search pattern fetching entire blocks to decompressing them just to see whether or not the key you’re looking for is even within the range of the block.</p><p>To solve this problem, SSTs introduce multiple layers of indexes.</p><p>The first index (often just called “the index”) is a smaller data structure that just contains the first key of every data block and the location of the block (an offset within a larger file). This allows you to load the index into memory and binary search on that, which is an order of magnitude smaller than trying to load the actual blocks, to find the required data block.</p><p><span>To put the index size for corresponding data blocks into perspective, let’s imagine you have 4KB blocks with keys that average 8 bytes (a </span><code>u64</code><span>) and values that average 256 bytes. This means a single data block can contain approximately 15 records. The index in the most naive format can contain 512 keys (with delta compression you can squeeze significantly more). If each key is the first key of a block, a 4KB index block can index 2MB of data blocks, or 7680 records.</span></p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!l52U!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4fdcb77-4e57-483a-af87-12de0180349d_1164x626.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!l52U!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4fdcb77-4e57-483a-af87-12de0180349d_1164x626.png 424w, https://substackcdn.com/image/fetch/$s_!l52U!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4fdcb77-4e57-483a-af87-12de0180349d_1164x626.png 848w, https://substackcdn.com/image/fetch/$s_!l52U!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4fdcb77-4e57-483a-af87-12de0180349d_1164x626.png 1272w, https://substackcdn.com/image/fetch/$s_!l52U!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4fdcb77-4e57-483a-af87-12de0180349d_1164x626.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/$s_!l52U!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4fdcb77-4e57-483a-af87-12de0180349d_1164x626.png" width="566" height="304.3951890034364" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/d4fdcb77-4e57-483a-af87-12de0180349d_1164x626.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:626,&#34;width&#34;:1164,&#34;resizeWidth&#34;:566,&#34;bytes&#34;:44508,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:&#34;https://www.bitsxpages.com/i/183585370?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4fdcb77-4e57-483a-af87-12de0180349d_1164x626.png&#34;,&#34;isProcessing&#34;:false,&#34;align&#34;:null,&#34;offset&#34;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!l52U!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4fdcb77-4e57-483a-af87-12de0180349d_1164x626.png 424w, https://substackcdn.com/image/fetch/$s_!l52U!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4fdcb77-4e57-483a-af87-12de0180349d_1164x626.png 848w, https://substackcdn.com/image/fetch/$s_!l52U!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4fdcb77-4e57-483a-af87-12de0180349d_1164x626.png 1272w, https://substackcdn.com/image/fetch/$s_!l52U!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fd4fdcb77-4e57-483a-af87-12de0180349d_1164x626.png 1456w" sizes="100vw" loading="lazy"/></picture><div></div></div></a></figure></div><p>The code for the index block would look something like this (without the encoding/decoding section, which looks very similar to the data block encoding and decoding):</p><pre><code><code>pub(crate) struct IndexEntry {
    key: Vec&lt;u8&gt;,
    offset: u64,
}

pub(crate) struct SstIndexBlock {
    entries: Vec&lt;IndexEntry&gt;,
}

/// used to find which block in the SST contains the key
/// that you want using the index. once the data block is
/// identified, it should be deserialized into a SstDataBlock
/// and then searched using SstDataBlock::find_record for the
/// exact record
impl SstIndexBlock {
		fn find_entry(&amp;self, key: &amp;[u8]) -&gt; Option&lt;&amp;IndexEntry&gt; {
        match self.entries
            .binary_search_by(|entry| entry.key.as_slice().cmp(key))
        {
            Ok(i) =&gt; Some(&amp;self.entries[i]),
            Err(insertion_point) =&gt; {
                if insertion_point &gt; 0 {
                    Some(&amp;self.entries[insertion_point - 1])
                } else {
                    None 
                }
            }
        }
    }
}
</code></code></pre><p>Up until this point, we made the assumption that all the data you’d need exists in a single SST. We’ll discuss why you might not want that in a future blog post about LSM trees, but for now I’ll ask you to accept that it’s often better to store data in multiple SSTs instead of one big one.</p><p>If you setup your storage like that, it is helpful to know whether or not a given SST has the key you’re looking for before you even try reading the index and data blocks. This information is stored in a filter block, and there’s typically two forms of filters that are used: min/max filters and Bloom filters.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!NdBW!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d405375-1649-4d11-961d-a4dff4e6921e_1164x548.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!NdBW!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d405375-1649-4d11-961d-a4dff4e6921e_1164x548.png 424w, https://substackcdn.com/image/fetch/$s_!NdBW!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d405375-1649-4d11-961d-a4dff4e6921e_1164x548.png 848w, https://substackcdn.com/image/fetch/$s_!NdBW!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d405375-1649-4d11-961d-a4dff4e6921e_1164x548.png 1272w, https://substackcdn.com/image/fetch/$s_!NdBW!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d405375-1649-4d11-961d-a4dff4e6921e_1164x548.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/$s_!NdBW!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d405375-1649-4d11-961d-a4dff4e6921e_1164x548.png" width="614" height="289.06529209621993" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/8d405375-1649-4d11-961d-a4dff4e6921e_1164x548.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:548,&#34;width&#34;:1164,&#34;resizeWidth&#34;:614,&#34;bytes&#34;:48347,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:&#34;https://www.bitsxpages.com/i/183585370?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d405375-1649-4d11-961d-a4dff4e6921e_1164x548.png&#34;,&#34;isProcessing&#34;:false,&#34;align&#34;:null,&#34;offset&#34;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!NdBW!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d405375-1649-4d11-961d-a4dff4e6921e_1164x548.png 424w, https://substackcdn.com/image/fetch/$s_!NdBW!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d405375-1649-4d11-961d-a4dff4e6921e_1164x548.png 848w, https://substackcdn.com/image/fetch/$s_!NdBW!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d405375-1649-4d11-961d-a4dff4e6921e_1164x548.png 1272w, https://substackcdn.com/image/fetch/$s_!NdBW!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2F8d405375-1649-4d11-961d-a4dff4e6921e_1164x548.png 1456w" sizes="100vw" loading="lazy"/></picture><div></div></div></a></figure></div><p>Min/Max filters are extremely simple filters that just encode the minimum and maximum keys that exist in the SST. This very simple data structure takes up very little space and can save a lot of computational work in certain storage systems that lay out their SSTs across very wide key ranges (think using a number such as timestamp as the key).</p><p><span>Bloom filters are more complicated and come with some interesting tradeoffs. There have been many sources that explain how these filters work, if you’re curious the </span><a href="https://en.wikipedia.org/wiki/Bloom_filter" rel="">Wikipedia</a><span> page has an excellent overview. If you’re not, the important thing to understand is that they’re a probabilistic data structure that can tell you with 100% certainty that a key does </span><em>not</em><span> exist in SST but it cannot guarantee that a key </span><em>does</em><span> exist. Their accuracy is measured by their false positive chance: each false positive means you need to dig into the index and data blocks unnecessarily, finding out that the key in fact does not exist.</span></p><p>Indexes and filters aren’t free and, typically, you want to keep the entire index along with any filters in memory to avoid deserializing indexes over and over again.</p><p>The implication is that indexes are a fundamental way to tradeoff between read and space amplification.</p><p><span>To tune between the two, you can change the size of the data blocks (smaller blocks means larger indexes, but less read amplification as less data needs to be paged in). I ran an </span><a href="https://github.com/agavra/bits-x-pages/tree/main/experiments/lsm-space-amp" rel="">experiment</a><span> on RocksDB in practice to show this in action</span><span data-state="closed"><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-2-183585370" href="https://www.bitsxpages.com/p/sorted-string-tables-sst-from-first#footnote-2-183585370" target="_self" rel="">2</a></span><span>. The experiment set up a data set of 4GB size and varied the block size, checking the total size of the SST (on disk), the size of the index (in memory) and the read throughout.</span></p><pre><code><code>$ space_amp --block_sizes=4096,8192,32768 --read_ops=50000
Raw payload bytes: ~4GB (33554432 entries)

Block Size    Total SST   Table Mem   Reads/s
4.00KB           3.51GB      38.9MB     13144
8.00KB           3.48GB      19.3MB     11310
32.0KB           3.45GB      4.88MB      9311
</code></code></pre><p>This shows what we expect to see: smaller block sizes mean larger indexes, higher memory utilization but faster reads. It also shows the diminishing returns of large indexes. When we decrease the block size 8x, memory grows by approximately the same factor but the read throughput only improved by 1.4x.</p><p>Bloom filters are not exempt from this tradeoff either: to reduce the false positive rate of a bloom filter, you need a large one (more bits). The good thing is that the math to compute the false positive rate is straightforward. Assuming your SST stores 1 billion keys, the diagram below shows the false positive rate and the corresponding Bloom Filter size.</p><div><figure><a target="_blank" href="https://substackcdn.com/image/fetch/$s_!BDYd!,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb19c29bf-ad3f-4e12-b59b-41ed5b8e4a1d_800x522.png" data-component-name="Image2ToDOM" rel=""><div><picture><source type="image/webp" srcset="https://substackcdn.com/image/fetch/$s_!BDYd!,w_424,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb19c29bf-ad3f-4e12-b59b-41ed5b8e4a1d_800x522.png 424w, https://substackcdn.com/image/fetch/$s_!BDYd!,w_848,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb19c29bf-ad3f-4e12-b59b-41ed5b8e4a1d_800x522.png 848w, https://substackcdn.com/image/fetch/$s_!BDYd!,w_1272,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb19c29bf-ad3f-4e12-b59b-41ed5b8e4a1d_800x522.png 1272w, https://substackcdn.com/image/fetch/$s_!BDYd!,w_1456,c_limit,f_webp,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb19c29bf-ad3f-4e12-b59b-41ed5b8e4a1d_800x522.png 1456w" sizes="100vw"/><img src="https://substackcdn.com/image/fetch/$s_!BDYd!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb19c29bf-ad3f-4e12-b59b-41ed5b8e4a1d_800x522.png" width="430" height="280.575" data-attrs="{&#34;src&#34;:&#34;https://substack-post-media.s3.amazonaws.com/public/images/b19c29bf-ad3f-4e12-b59b-41ed5b8e4a1d_800x522.png&#34;,&#34;srcNoWatermark&#34;:null,&#34;fullscreen&#34;:null,&#34;imageSize&#34;:null,&#34;height&#34;:522,&#34;width&#34;:800,&#34;resizeWidth&#34;:430,&#34;bytes&#34;:46675,&#34;alt&#34;:null,&#34;title&#34;:null,&#34;type&#34;:&#34;image/png&#34;,&#34;href&#34;:null,&#34;belowTheFold&#34;:true,&#34;topImage&#34;:false,&#34;internalRedirect&#34;:&#34;https://www.bitsxpages.com/i/183585370?img=https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb19c29bf-ad3f-4e12-b59b-41ed5b8e4a1d_800x522.png&#34;,&#34;isProcessing&#34;:false,&#34;align&#34;:null,&#34;offset&#34;:false}" alt="" srcset="https://substackcdn.com/image/fetch/$s_!BDYd!,w_424,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb19c29bf-ad3f-4e12-b59b-41ed5b8e4a1d_800x522.png 424w, https://substackcdn.com/image/fetch/$s_!BDYd!,w_848,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb19c29bf-ad3f-4e12-b59b-41ed5b8e4a1d_800x522.png 848w, https://substackcdn.com/image/fetch/$s_!BDYd!,w_1272,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb19c29bf-ad3f-4e12-b59b-41ed5b8e4a1d_800x522.png 1272w, https://substackcdn.com/image/fetch/$s_!BDYd!,w_1456,c_limit,f_auto,q_auto:good,fl_progressive:steep/https%3A%2F%2Fsubstack-post-media.s3.amazonaws.com%2Fpublic%2Fimages%2Fb19c29bf-ad3f-4e12-b59b-41ed5b8e4a1d_800x522.png 1456w" sizes="100vw" loading="lazy"/></picture><div></div></div></a></figure></div><p>The final block in an SST is the metadata block. Despite its humble size, typically just 48-64 bytes, it plays a critical role by storing the offset and length of the index and filter blocks, plus a magic number and version that allows the SST format to evolve over time.</p><p>But here’s an interesting question: Why are the index and bloom filter blocks at the end of the file?</p><p>The answer reveals a constraint of SST construction. When building a large SSTable you face a choice. Your first option is to buffer the entire SST in memory, build the complete index and bloom filter, then write everything in the “correct” order: index, bloom filter, data blocks. Alternatively, your second option is to stream data blocks to disk one at a time as they’re built, constructing the index and bloom filter incrementally as you go. If you take the second path, then you can’t know the locations of the blocks until the end, so you can’t write out the index block until then.</p><p>Note that this optimization only really applies when your data is already in sorted order (such as when merging two SSTs), otherwise you need to buffer the data in memory to sort it in first place.</p><p>While SSTs are an obvious fit for key-value storage, sorted rows turn out to be a remarkably general abstraction. Almost any access pattern you care about can be encoded into SSTs if you’re clever about how you structure your keys.</p><p><span>The insight is that </span><strong>l</strong><span>exicographic sorting on byte strings gives you hierarchy for free. When your keys share a prefix, they’re stored physically adjacent. This means a “range scan over all keys starting with X” is just a sequential read which is the best possible access pattern for storage devices (remember that the minimum fetch of data from a disk is 4KB, even for an SSD, so if all of that data is relevant then you aren’t paying excess read amplification).</span></p><p>There’s a spectrum of cleverness in how you shove data models into key-value form. This section goes through strategies you can use, from obvious to devious:</p><p>The trivial case models the keys exactly the way you are looking them up. There’s nothing clever about this and often this is all you need:</p><pre><code><code>&#34;user:alice&#34; → {name: &#34;Alice&#34;, email: &#34;alice@bitsxpages.com&#34;}
&#34;user:bob&#34;   → {name: &#34;Bob&#34;, email: &#34;bob@example.com&#34;}
</code></code></pre><p><span>The next requirement might be to store different </span><em>types</em><span> of data in the same SST rather than split each data type into its own SST. To do this, you can prefix your keys with the type of data they represent and then construct your lookup key based on that.</span></p><p>The following example has three key types: metadata keys, users and sessions:</p><pre><code><code>&#34;meta:schema_version&#34; → &#34;3&#34;
&#34;meta:created_at&#34;     → &#34;2024-01-15T00:00:00Z&#34;
&#34;user:alice&#34;          → {name: &#34;Alice&#34;, ...}
&#34;user:bob&#34;            → {name: &#34;Bob&#34;, ...}  
&#34;session:abc123&#34;      → {user: &#34;alice&#34;, expires: ...}
</code></code></pre><p><span>Because keys are sorted, all the </span><code>meta:</code><span> keys cluster together, all the </span><code>user:</code><span> keys cluster together, and so on. A range scan with prefix </span><code>user:</code><span> gives you all users. This is effectively multiple logical tables in one physical SST.</span></p><p>This is when things start getting interesting. You can effectively “decompose” a single complicated key into multiple rows for efficient lookups of both the composite key as well as the single key. Imagine our users had a set of orders, so the logical data would look like:</p><pre><code><code>&#34;user:alice&#34; → {
	name: &#34;Alice&#34;, 
	orders: [
		{&#34;id&#34;: &#34;7&#34;, &#34;item&#34;: &#34;catnip&#34;, &#34;count&#34;: 2},
		{&#34;id&#34;: &#34;112&#34;, &#34;item&#34;: &#34;dog_treats&#34;, &#34;count&#34;: 11},
	]
}
</code></code></pre><p>Using level-0, and level-1 techniques outlined before we could get decently far:</p><ol><li><p><span>Level 0: Store </span><code>&#34;user:alice&#34;</code><span> as the key, and include the full order details in the document value (match the logical model)</span></p></li><li><p><span>Level 1: Store </span><code>&#34;user:alice&#34;</code><span> as the key, include the order ids in the value, and then store </span><code>&#34;order:7&#34;</code><span> as a separately namespaced key.</span></p></li></ol><p><span>Each have downsides. Level 0 has significant read amplification if you don’t need all the order details (e.g. you just want to retrieve Alice’s email address). Level 1 has significant read amplification if you </span><em>do</em><span> want all the order details because you need to fetch all the order ids, which may not be in the same data blocks (they’re ordered by ids, so </span><code>order:7</code><span> and </span><code>order:112</code><span> may not be next to one another).</span></p><p>The third alternative is to use a composite key:</p><pre><code><code>&#34;user:alice&#34; -&gt; {name: &#34;Alice&#34;, ...}
&#34;user:alice,order:7&#34; -&gt; {&#34;id&#34;: &#34;7&#34;, &#34;item&#34;: &#34;catnip&#34;, &#34;count&#34;: 2}
&#34;user:alice,order:112&#34; -&gt; {&#34;id&#34;: &#34;112&#34;, &#34;item&#34;: &#34;dog_treats&#34;, &#34;count&#34;: 11}
</code></code></pre><p><span>Now the query for “get order 7 for Alice” is a point lookup for </span><code>user:alice,order:7</code><span> and the query “get all orders for Alice” is a prefix scan on </span><code>user:alice,order:*</code><span>. Both are efficient since the sort order gives you the hierarchy for free</span><span data-state="closed"><a data-component-name="FootnoteAnchorToDOM" id="footnote-anchor-3-183585370" href="https://www.bitsxpages.com/p/sorted-string-tables-sst-from-first#footnote-3-183585370" target="_self" rel="">3</a></span><span>.</span></p><p><span>The same technique can be used for handling documents with many sparse columns. For example, you could chose to store a </span><code>phone_number</code><span> column separately if most users don’t submit a value for that when creating a profile:</span></p><pre><code><code>&#34;user:alice&#34; -&gt; {name: &#34;Alice&#34;, ...}
&#34;user:alice,col:phone&#34; -&gt; &#34;+1-650-123-4567&#34;,
</code></code></pre><p>This has a nice property: sparse columns are free. If Alice has a “phone” column and Bob doesn’t, you simply don’t store a key for Bob’s phone. The downside is that reading the full row now requires a prefix scan, which involves more read amplification.</p><p><span>The hierarchy trick only works if you know every element in the hierarchy you want to query for. This doesn’t help me if I want to find “what user has the email </span><code>alice@bitsxpages.com</code><span>?” The solution to that is leveraging namespacing to store special keys that represent the secondary index:</span></p><pre><code><code># primary: lookup by user ID
&#34;user:alice&#34; → {name: &#34;Alice&#34;, email: &#34;alice@example.com&#34;}

# secondary index: lookup by email  
&#34;&lt;idx:email:alice@example.com&gt;&#34; → &#34;user:alice&#34;
</code></code></pre><p>Now looking up a user by email is two steps: scan the index to get the ID, then fetch the primary record. This is one of the most powerful tricks you can use, and allows you to implement many different types of systems on top of SSTs.</p><p>The previous example I gave is a simple secondary index, but you can implement more complicated ones:</p><ul><li><p><span>A </span><strong>covering index</strong><span> can store more than just document ids in line with the value. For example if I always want to get the user’s full name when I lookup by email the index value for </span><code>idx:email:alice@example.com</code><span> could contain </span><code>{&#34;id&#34;: &#34;user:alice&#34;, &#34;full name&#34;: &#34;Alice Ecila&#34;}</code><span>.</span></p></li><li><p><span>An </span><strong>inverted index</strong><span> can be stored in SSTs where the keys are </span><code>term:value</code><span> (e.g. </span><code>department:engineering</code><span>) and the value is a sorted list of document ids, compressed as a roaring bitmap. If I want to find “all documents that are in engineering and have the name alice” I lookup </span><code>department:engineering</code><span> and </span><code>name:alice</code><span>, then retrieve the intersection of the two lists.</span></p></li><li><p><span>A </span><strong>queue</strong><span> can be stored in SSTs where the key is the offset in the key and the value is the full row.</span></p></li></ul><p>The deeper point is that SSTs derive their power from a simple focus on playing to the advantages of SSDs and Object Storage: immutable data and block-aligned reads (index and filter structures that minimize I/O).</p><p><span>This alignment with hardware means you can map a surprising variety of use cases onto SSTs without fighting the storage layer. Cassandra and ScyllaDB use SSTs for scalable KV storage. Yugabyte and MyRocks use SSTs to implement full SQL engines. </span><a href="https://www.datadoghq.com/blog/engineering/timeseries-indexing-at-scale/" rel="">DataDog’s metrics backend</a><span> stores data in SSTs. Kafka’s log segments are conceptually SSTs optimized for append-only access. If you generalize SSTs a little further and consider systems that have converged on “sorted immutable files with indexes and filters” as their storage primitive is long and growing (Clickhouse, etc…).</span></p><p>Once you internalize that “sorted bytes on disk + binary search + immutability” is the primitive so much else builds on, the design space for databases becomes clearer.</p><p>But the reality is that most databases aren’t immutable… stay tuned for the next entry in this series to learn how multiple SSTs are composed together to form LSM trees.</p></div></div></div>
  </body>
</html>
