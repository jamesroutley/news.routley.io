<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://news.ycombinator.com/item?id=45329322">Original</a>
    <h1>Everyone&#39;s trying vectors and graphs for AI memory. We went back to SQL</h1>
    
    <div id="readability-page-1" class="page"><div><td colspan="2"></td><td><div><p>When we first started building with LLMs, the gap was obvious: they could reason well in the moment, but forgot everything as soon as the conversation moved on.</p><p>You could tell an agent, “I don’t like coffee,” and three steps later it would suggest espresso again. It wasn’t broken logic, it was missing memory.</p><p>Over the past few years, people have tried a bunch of ways to fix it:</p><p>1. Prompt stuffing / fine-tuning – Keep prepending history. Works for short chats, but tokens and cost explode fast.</p><p>2. Vector databases (RAG) – Store embeddings in Pinecone/Weaviate. Recall is semantic, but retrieval is noisy and loses structure.</p><p>3. Graph databases – Build entity-relationship graphs. Great for reasoning, but hard to scale and maintain.</p><p>4. Hybrid systems – Mix vectors, graphs, key-value, and relational DBs. Flexible but complex.</p><p>And then there’s the twist:
Relational databases! Yes, the tech that’s been running banks and social media for decades is looking like one of the most practical ways to give AI persistent memory.</p><p>Instead of exotic stores, you can:</p><p>- Keep short-term vs long-term memory in SQL tables</p><p>- Store entities, rules, and preferences as structured records</p><p>- Promote important facts into permanent memory</p><p>- Use joins and indexes for retrieval</p><p>This is the approach we’ve been working on at Gibson. We built an open-source project called Memori (https://memori.gibsonai.com/), a multi-agent memory engine that gives your AI agents human-like memory.</p><p>It’s kind of ironic, after all the hype around vectors and graphs, one of the best answers to AI memory might be the tech we’ve trusted for 50+ years.</p><p>I would love to know your thoughts about our approach!</p></div></td></div></div>
  </body>
</html>
