<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/hatchet-dev/hatchet">Original</a>
    <h1>Show HN: Hatchet v1 ‚Äì A task orchestration platform built on Postgres</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">

<p dir="auto">Hatchet is a platform for running background tasks, built on top of Postgres. Instead of managing your own task queue or pub/sub system, you can use Hatchet to distribute your functions between a set of workers with minimal configuration or infrastructure.</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">When should I use Hatchet?</h3><a id="user-content-when-should-i-use-hatchet" aria-label="Permalink: When should I use Hatchet?" href="#when-should-i-use-hatchet"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Background tasks are critical for offloading work from your main web application. Usually background tasks are sent through a FIFO (first-in-first-out) queue, which helps guard against traffic spikes (queues can absorb a lot of load) and ensures that tasks are retried when your task handlers error out. Most stacks begin with a library-based queue backed by Redis or RabbitMQ (like Celery or BullMQ). But as your tasks become more complex, these queues become difficult to debug, monitor and start to fail in unexpected ways.</p>
<p dir="auto">This is where Hatchet comes in. Hatchet is a full-featured background task management platform, with built-in support for chaining complex tasks together into workflows, alerting on failures, making tasks more durable, and viewing tasks in a real-time web dashboard.</p>

<details open=""><summary><strong>üì• Queues</strong></summary>

<p dir="auto">Hatchet is built on a durable task queue that enqueues your tasks and sends them to your workers at a rate that your workers can handle. Hatchet will track the progress of your task and ensure that the work gets completed (or you get alerted), even if your application crashes.</p>
<p dir="auto"><strong>This is particularly useful for:</strong></p>
<ul dir="auto">
<li>Ensuring that you never drop a user request</li>
<li>Flattening large spikes in your application</li>
<li>Breaking large, complex logic into smaller, reusable tasks</li>
</ul>
<p dir="auto"><a href="https://docs.hatchet.run/home/your-first-task" rel="nofollow">Read more ‚û∂</a></p>
<ul dir="auto">
<li>
<details>
  <summary><code>Python</code></summary>
<div dir="auto" data-snippet-clipboard-copy-content="# 1. Define your task input
class SimpleInput(BaseModel):
    message: str

# 2. Define your task using hatchet.task
@hatchet.task(name=&#34;SimpleWorkflow&#34;, input_validator=SimpleInput)
def simple(input: SimpleInput, ctx: Context) -&gt; dict[str, str]:
    return {
      &#34;transformed_message&#34;: input.message.lower(),
    }

# 3. Register your task on your worker
worker = hatchet.worker(&#34;test-worker&#34;, workflows=[simple])
worker.start()

# 4. Invoke tasks from your application
simple.run(SimpleInput(message=&#34;Hello World!&#34;))"><pre><span># 1. Define your task input</span>
<span>class</span> <span>SimpleInput</span>(<span>BaseModel</span>):
    <span>message</span>: <span>str</span>

<span># 2. Define your task using hatchet.task</span>
<span>@<span>hatchet</span>.<span>task</span>(<span>name</span><span>=</span><span>&#34;SimpleWorkflow&#34;</span>, <span>input_validator</span><span>=</span><span>SimpleInput</span>)</span>
<span>def</span> <span>simple</span>(<span>input</span>: <span>SimpleInput</span>, <span>ctx</span>: <span>Context</span>) <span>-&gt;</span> <span>dict</span>[<span>str</span>, <span>str</span>]:
    <span>return</span> {
      <span>&#34;transformed_message&#34;</span>: <span>input</span>.<span>message</span>.<span>lower</span>(),
    }

<span># 3. Register your task on your worker</span>
<span>worker</span> <span>=</span> <span>hatchet</span>.<span>worker</span>(<span>&#34;test-worker&#34;</span>, <span>workflows</span><span>=</span>[<span>simple</span>])
<span>worker</span>.<span>start</span>()

<span># 4. Invoke tasks from your application</span>
<span>simple</span>.<span>run</span>(<span>SimpleInput</span>(<span>message</span><span>=</span><span>&#34;Hello World!&#34;</span>))</pre></div>
</details>
</li>
<li>
<details>
  <summary><code>Typescript</code></summary>
<div dir="auto" data-snippet-clipboard-copy-content="// 1. Define your task input
export type SimpleInput = {
  Message: string;
};

// 2. Define your task using hatchet.task
export const simple = hatchet.task({
  name: &#34;simple&#34;,
  fn: (input: SimpleInput) =&gt; {
    return {
      TransformedMessage: input.Message.toLowerCase(),
    };
  },
});

// 3. Register your task on your worker
const worker = await hatchet.worker(&#34;simple-worker&#34;, {
  workflows: [simple],
});

await worker.start();

// 4. Invoke tasks from your application
await simple.run({
  Message: &#34;Hello World!&#34;,
});"><pre><span>// 1. Define your task input</span>
<span>export</span> <span>type</span> <span>SimpleInput</span> <span>=</span> <span>{</span>
  <span>Message</span>: <span>string</span><span>;</span>
<span>}</span><span>;</span>

<span>// 2. Define your task using hatchet.task</span>
<span>export</span> <span>const</span> <span>simple</span> <span>=</span> <span>hatchet</span><span>.</span><span>task</span><span>(</span><span>{</span>
  <span>name</span>: <span>&#34;simple&#34;</span><span>,</span>
  <span>fn</span>: <span>(</span><span>input</span>: <span>SimpleInput</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>return</span> <span>{</span>
      <span>TransformedMessage</span>: <span>input</span><span>.</span><span>Message</span><span>.</span><span>toLowerCase</span><span>(</span><span>)</span><span>,</span>
    <span>}</span><span>;</span>
  <span>}</span><span>,</span>
<span>}</span><span>)</span><span>;</span>

<span>// 3. Register your task on your worker</span>
<span>const</span> <span>worker</span> <span>=</span> <span>await</span> <span>hatchet</span><span>.</span><span>worker</span><span>(</span><span>&#34;simple-worker&#34;</span><span>,</span> <span>{</span>
  <span>workflows</span>: <span>[</span><span>simple</span><span>]</span><span>,</span>
<span>}</span><span>)</span><span>;</span>

<span>await</span> <span>worker</span><span>.</span><span>start</span><span>(</span><span>)</span><span>;</span>

<span>// 4. Invoke tasks from your application</span>
<span>await</span> <span>simple</span><span>.</span><span>run</span><span>(</span><span>{</span>
  <span>Message</span>: <span>&#34;Hello World!&#34;</span><span>,</span>
<span>}</span><span>)</span><span>;</span></pre></div>
</details>
</li>
<li>
<details>
  <summary><code>Go</code></summary>
<div dir="auto" data-snippet-clipboard-copy-content="// 1. Define your task input
type SimpleInput struct {
  Message string `json:&#34;message&#34;`
}

// 2. Define your task using factory.NewTask
simple := factory.NewTask(
  create.StandaloneTask{
    Name: &#34;simple-task&#34;,
  }, func(ctx worker.HatchetContext, input SimpleInput) (*SimpleResult, error) {
    return &amp;SimpleResult{
      TransformedMessage: strings.ToLower(input.Message),
    }, nil
  },
  hatchet,
)

// 3. Register your task on your worker
worker, err := hatchet.Worker(v1worker.WorkerOpts{
  Name: &#34;simple-worker&#34;,
  Workflows: []workflow.WorkflowBase{
    simple,
  },
})

worker.StartBlocking()

// 4. Invoke tasks from your application
simple.Run(context.Background(), SimpleInput{Message: &#34;Hello, World!&#34;})"><pre><span>// 1. Define your task input</span>
<span>type</span> <span>SimpleInput</span> <span>struct</span> {
  <span>Message</span> <span>string</span> <span>`json:&#34;message&#34;`</span>
}

<span>// 2. Define your task using factory.NewTask</span>
<span>simple</span> <span>:=</span> <span>factory</span>.<span>NewTask</span>(
  create.<span>StandaloneTask</span>{
    <span>Name</span>: <span>&#34;simple-task&#34;</span>,
  }, <span>func</span>(<span>ctx</span> worker.<span>HatchetContext</span>, <span>input</span> <span>SimpleInput</span>) (<span>*</span><span>SimpleResult</span>, <span>error</span>) {
    <span>return</span> <span>&amp;</span><span>SimpleResult</span>{
      <span>TransformedMessage</span>: <span>strings</span>.<span>ToLower</span>(<span>input</span>.<span>Message</span>),
    }, <span>nil</span>
  },
  <span>hatchet</span>,
)

<span>// 3. Register your task on your worker</span>
<span>worker</span>, <span>err</span> <span>:=</span> <span>hatchet</span>.<span>Worker</span>(v1worker.<span>WorkerOpts</span>{
  <span>Name</span>: <span>&#34;simple-worker&#34;</span>,
  <span>Workflows</span>: []workflow.<span>WorkflowBase</span>{
    <span>simple</span>,
  },
})

<span>worker</span>.<span>StartBlocking</span>()

<span>// 4. Invoke tasks from your application</span>
<span>simple</span>.<span>Run</span>(<span>context</span>.<span>Background</span>(), <span>SimpleInput</span>{<span>Message</span>: <span>&#34;Hello, World!&#34;</span>})</pre></div>
</details>
</li>
</ul>
</details>
<details><summary><strong>üéª Task Orchestration</strong></summary>

<p dir="auto">Hatchet allows you to build complex workflows that can be composed of multiple tasks. For example, if you&#39;d like to break a workload into smaller tasks, you can use Hatchet to create a fanout workflow that spawns multiple tasks in parallel.</p>
<p dir="auto">Hatchet supports the following mechanisms for task orchestration:</p>
<ul dir="auto">
<li>
<p dir="auto"><strong>DAGs (directed acyclic graphs)</strong> ‚Äî pre-define the shape of your work, automatically routing the outputs of a parent task to the input of a child task. <a href="https://docs.hatchet.run/home/dags" rel="nofollow">Read more ‚û∂</a></p>
</li>
<li>
<p dir="auto"><strong>Durable tasks</strong> ‚Äî these tasks are responsible for orchestrating other tasks. They store a full history of all spawned tasks, allowing you to cache intermediate results. <a href="https://docs.hatchet.run/home/durable-execution" rel="nofollow">Read more ‚û∂</a></p>
</li>
<li>
<details>
  <summary><code>Python</code></summary>
<div dir="auto" data-snippet-clipboard-copy-content="# 1. Define a workflow (a workflow is a collection of tasks)
simple = hatchet.workflow(name=&#34;SimpleWorkflow&#34;)

# 2. Attach the first task to the workflow
@simple.task()
def task_1(input: EmptyModel, ctx: Context) -&gt; dict[str, str]:
    print(&#34;executed task_1&#34;)
    return {&#34;result&#34;: &#34;task_1&#34;}

# 3. Attach the second task to the workflow, which executes after task_1
@simple.task(parents=[task_1])
def task_2(input: EmptyModel, ctx: Context) -&gt; None:
    first_result = ctx.task_output(task_1)
    print(first_result)

# 4. Invoke workflows from your application
result = simple.run(input_data)"><pre><span># 1. Define a workflow (a workflow is a collection of tasks)</span>
<span>simple</span> <span>=</span> <span>hatchet</span>.<span>workflow</span>(<span>name</span><span>=</span><span>&#34;SimpleWorkflow&#34;</span>)

<span># 2. Attach the first task to the workflow</span>
<span>@<span>simple</span>.<span>task</span>()</span>
<span>def</span> <span>task_1</span>(<span>input</span>: <span>EmptyModel</span>, <span>ctx</span>: <span>Context</span>) <span>-&gt;</span> <span>dict</span>[<span>str</span>, <span>str</span>]:
    <span>print</span>(<span>&#34;executed task_1&#34;</span>)
    <span>return</span> {<span>&#34;result&#34;</span>: <span>&#34;task_1&#34;</span>}

<span># 3. Attach the second task to the workflow, which executes after task_1</span>
<span>@<span>simple</span>.<span>task</span>(<span>parents</span><span>=</span>[<span>task_1</span>])</span>
<span>def</span> <span>task_2</span>(<span>input</span>: <span>EmptyModel</span>, <span>ctx</span>: <span>Context</span>) <span>-&gt;</span> <span>None</span>:
    <span>first_result</span> <span>=</span> <span>ctx</span>.<span>task_output</span>(<span>task_1</span>)
    <span>print</span>(<span>first_result</span>)

<span># 4. Invoke workflows from your application</span>
<span>result</span> <span>=</span> <span>simple</span>.<span>run</span>(<span>input_data</span>)</pre></div>
</details>
</li>
<li>
<details>
  <summary><code>Typescript</code></summary>
<div dir="auto" data-snippet-clipboard-copy-content="// 1. Define a workflow (a workflow is a collection of tasks)
const simple = hatchet.workflow&lt;DagInput, DagOutput&gt;({
  name: &#34;simple&#34;,
});

// 2. Attach the first task to the workflow
const task1 = simple.task({
  name: &#34;task-1&#34;,
  fn: (input) =&gt; {
    return {
      result: &#34;task-1&#34;,
    };
  },
});

// 3. Attach the second task to the workflow, which executes after task-1
const task2 = simple.task({
  name: &#34;task-2&#34;,
  parents: [task1],
  fn: (input, ctx) =&gt; {
    const firstResult = ctx.getParentOutput(task1);
    console.log(firstResult);
  },
});

// 4. Invoke workflows from your application
await simple.run({ Message: &#34;Hello World&#34; });"><pre><span>// 1. Define a workflow (a workflow is a collection of tasks)</span>
<span>const</span> <span>simple</span> <span>=</span> <span>hatchet</span><span>.</span><span>workflow</span><span>&lt;</span><span>DagInput</span><span>,</span> <span>DagOutput</span><span>&gt;</span><span>(</span><span>{</span>
  <span>name</span>: <span>&#34;simple&#34;</span><span>,</span>
<span>}</span><span>)</span><span>;</span>

<span>// 2. Attach the first task to the workflow</span>
<span>const</span> <span>task1</span> <span>=</span> <span>simple</span><span>.</span><span>task</span><span>(</span><span>{</span>
  <span>name</span>: <span>&#34;task-1&#34;</span><span>,</span>
  <span>fn</span>: <span>(</span><span>input</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>return</span> <span>{</span>
      <span>result</span>: <span>&#34;task-1&#34;</span><span>,</span>
    <span>}</span><span>;</span>
  <span>}</span><span>,</span>
<span>}</span><span>)</span><span>;</span>

<span>// 3. Attach the second task to the workflow, which executes after task-1</span>
<span>const</span> <span>task2</span> <span>=</span> <span>simple</span><span>.</span><span>task</span><span>(</span><span>{</span>
  <span>name</span>: <span>&#34;task-2&#34;</span><span>,</span>
  <span>parents</span>: <span>[</span><span>task1</span><span>]</span><span>,</span>
  <span>fn</span>: <span>(</span><span>input</span><span>,</span> <span>ctx</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>const</span> <span>firstResult</span> <span>=</span> <span>ctx</span><span>.</span><span>getParentOutput</span><span>(</span><span>task1</span><span>)</span><span>;</span>
    <span>console</span><span>.</span><span>log</span><span>(</span><span>firstResult</span><span>)</span><span>;</span>
  <span>}</span><span>,</span>
<span>}</span><span>)</span><span>;</span>

<span>// 4. Invoke workflows from your application</span>
<span>await</span> <span>simple</span><span>.</span><span>run</span><span>(</span><span>{</span> <span>Message</span>: <span>&#34;Hello World&#34;</span> <span>}</span><span>)</span><span>;</span></pre></div>
</details>
</li>
<li>
<details>
  <summary><code>Go</code></summary>
<div dir="auto" data-snippet-clipboard-copy-content="// 1. Define a workflow (a workflow is a collection of tasks)
simple := v1.WorkflowFactory[DagInput, DagOutput](
    workflow.CreateOpts[DagInput]{
        Name: &#34;simple-workflow&#34;,
    },
    hatchet,
)

// 2. Attach the first task to the workflow
const task1 = simple.Task(
    task.CreateOpts[DagInput]{
        Name: &#34;task-1&#34;,
        Fn: func(ctx worker.HatchetContext, _ DagInput) (*SimpleOutput, error) {
            return &amp;SimpleOutput{
                Result: &#34;task-1&#34;,
            }, nil
        },
    },
);

// 3. Attach the second task to the workflow, which executes after task-1
const task2 = simple.Task(
    task.CreateOpts[DagInput]{
        Name: &#34;task-2&#34;,
        Parents: []task.NamedTask{
            step1,
        },
        Fn: func(ctx worker.HatchetContext, _ DagInput) (*SimpleOutput, error) {
            return &amp;SimpleOutput{
                Result: &#34;task-2&#34;,
            }, nil
        },
    },
);

// 4. Invoke workflows from your application
simple.Run(ctx, DagInput{})"><pre><span>// 1. Define a workflow (a workflow is a collection of tasks)</span>
<span>simple</span> <span>:=</span> <span>v1</span>.<span>WorkflowFactory</span>[<span>DagInput</span>, <span>DagOutput</span>](
    workflow.<span>CreateOpts</span>[<span>DagInput</span>]{
        <span>Name</span>: <span>&#34;simple-workflow&#34;</span>,
    },
    <span>hatchet</span>,
)

<span>// 2. Attach the first task to the workflow</span>
<span>const</span> <span>task1</span> <span>=</span> <span>simple</span>.<span>Task</span>(
    task.<span>CreateOpts</span>[<span>DagInput</span>]{
        <span>Name</span>: <span>&#34;task-1&#34;</span>,
        <span>Fn</span>: <span>func</span>(<span>ctx</span> worker.<span>HatchetContext</span>, <span>_</span> <span>DagInput</span>) (<span>*</span><span>SimpleOutput</span>, <span>error</span>) {
            <span>return</span> <span>&amp;</span><span>SimpleOutput</span>{
                <span>Result</span>: <span>&#34;task-1&#34;</span>,
            }, <span>nil</span>
        },
    },
);

<span>// 3. Attach the second task to the workflow, which executes after task-1</span>
<span>const</span> <span>task2</span> <span>=</span> <span>simple</span>.<span>Task</span>(
    task.<span>CreateOpts</span>[<span>DagInput</span>]{
        <span>Name</span>: <span>&#34;task-2&#34;</span>,
        <span>Parents</span>: []task.<span>NamedTask</span>{
            <span>step1</span>,
        },
        <span>Fn</span>: <span>func</span>(<span>ctx</span> worker.<span>HatchetContext</span>, <span>_</span> <span>DagInput</span>) (<span>*</span><span>SimpleOutput</span>, <span>error</span>) {
            <span>return</span> <span>&amp;</span><span>SimpleOutput</span>{
                <span>Result</span>: <span>&#34;task-2&#34;</span>,
            }, <span>nil</span>
        },
    },
);

<span>// 4. Invoke workflows from your application</span>
<span>simple</span>.<span>Run</span>(<span>ctx</span>, <span>DagInput</span>{})</pre></div>
</details>
</li>
</ul>
</details>
<details><summary><strong>üö¶ Flow Control</strong></summary>

<p dir="auto">Don&#39;t let busy users crash your application. With Hatchet, you can throttle execution on a per-user, per-tenant and per-queue basis, increasing system stability and limiting the impact of busy users on the rest of your system.</p>
<p dir="auto">Hatchet supports the following flow control primitives:</p>
<ul dir="auto">
<li>
<p dir="auto"><strong>Concurrency</strong> ‚Äî set a concurrency limit based on a dynamic concurrency key (e.g., each user can only run 10 batch jobs at a given time). <a href="https://docs.hatchet.run/home/concurrency" rel="nofollow">Read more ‚û∂</a></p>
</li>
<li>
<p dir="auto"><strong>Rate limiting</strong> ‚Äî create both global and dynamic rate limits. <a href="https://docs.hatchet.run/home/rate-limits" rel="nofollow">Read more ‚û∂</a></p>
</li>
<li>
<details>
  <summary><code>Python</code></summary>
<div dir="auto" data-snippet-clipboard-copy-content="# limit concurrency on a per-user basis
flow_control_workflow = hatchet.workflow(
  name=&#34;FlowControlWorkflow&#34;,
  concurrency=ConcurrencyExpression(
    expression=&#34;input.user_id&#34;,
    max_runs=5,
    limit_strategy=ConcurrencyLimitStrategy.GROUP_ROUND_ROBIN,
  ),
  input_validator=FlowControlInput,
)

# rate limit a task per user to 10 tasks per minute, with each task consuming 1 unit
@flow_control_workflow.task(
    rate_limits=[
        RateLimit(
            dynamic_key=&#34;input.user_id&#34;,
            units=1,
            limit=10,
            duration=RateLimitDuration.MINUTE,
        )
    ]
)
def rate_limit_task(input: FlowControlInput, ctx: Context) -&gt; None:
    print(&#34;executed rate_limit_task&#34;)"><pre><span># limit concurrency on a per-user basis</span>
<span>flow_control_workflow</span> <span>=</span> <span>hatchet</span>.<span>workflow</span>(
  <span>name</span><span>=</span><span>&#34;FlowControlWorkflow&#34;</span>,
  <span>concurrency</span><span>=</span><span>ConcurrencyExpression</span>(
    <span>expression</span><span>=</span><span>&#34;input.user_id&#34;</span>,
    <span>max_runs</span><span>=</span><span>5</span>,
    <span>limit_strategy</span><span>=</span><span>ConcurrencyLimitStrategy</span>.<span>GROUP_ROUND_ROBIN</span>,
  ),
  <span>input_validator</span><span>=</span><span>FlowControlInput</span>,
)

<span># rate limit a task per user to 10 tasks per minute, with each task consuming 1 unit</span>
<span>@<span>flow_control_workflow</span>.<span>task</span>(</span>
<span>    <span>rate_limits</span><span>=</span>[</span>
<span>        <span>RateLimit</span>(</span>
<span>            <span>dynamic_key</span><span>=</span><span>&#34;input.user_id&#34;</span>,</span>
<span>            <span>units</span><span>=</span><span>1</span>,</span>
<span>            <span>limit</span><span>=</span><span>10</span>,</span>
<span>            <span>duration</span><span>=</span><span>RateLimitDuration</span>.<span>MINUTE</span>,</span>
<span>        )</span>
<span>    ]</span>
<span>)</span>
<span>def</span> <span>rate_limit_task</span>(<span>input</span>: <span>FlowControlInput</span>, <span>ctx</span>: <span>Context</span>) <span>-&gt;</span> <span>None</span>:
    <span>print</span>(<span>&#34;executed rate_limit_task&#34;</span>)</pre></div>
</details>
</li>
<li>
<details>
  <summary><code>Typescript</code></summary>
<div dir="auto" data-snippet-clipboard-copy-content="// limit concurrency on a per-user basis
flowControlWorkflow = hatchet.workflow&lt;SimpleInput, SimpleOutput&gt;({
  name: &#34;ConcurrencyLimitWorkflow&#34;,
  concurrency: {
    expression: &#34;input.userId&#34;,
    maxRuns: 5,
    limitStrategy: ConcurrencyLimitStrategy.GROUP_ROUND_ROBIN,
  },
});

// rate limit a task per user to 10 tasks per minute, with each task consuming 1 unit
flowControlWorkflow.task({
  name: &#34;rate-limit-task&#34;,
  rateLimits: [
    {
      dynamicKey: &#34;input.userId&#34;,
      units: 1,
      limit: 10,
      duration: RateLimitDuration.MINUTE,
    },
  ],
  fn: async (input) =&gt; {
    return {
      Completed: true,
    };
  },
});"><pre><span>// limit concurrency on a per-user basis</span>
<span>flowControlWorkflow</span> <span>=</span> <span>hatchet</span><span>.</span><span>workflow</span><span>&lt;</span><span>SimpleInput</span><span>,</span> <span>SimpleOutput</span><span>&gt;</span><span>(</span><span>{</span>
  <span>name</span>: <span>&#34;ConcurrencyLimitWorkflow&#34;</span><span>,</span>
  <span>concurrency</span>: <span>{</span>
    <span>expression</span>: <span>&#34;input.userId&#34;</span><span>,</span>
    <span>maxRuns</span>: <span>5</span><span>,</span>
    <span>limitStrategy</span>: <span>ConcurrencyLimitStrategy</span><span>.</span><span>GROUP_ROUND_ROBIN</span><span>,</span>
  <span>}</span><span>,</span>
<span>}</span><span>)</span><span>;</span>

<span>// rate limit a task per user to 10 tasks per minute, with each task consuming 1 unit</span>
<span>flowControlWorkflow</span><span>.</span><span>task</span><span>(</span><span>{</span>
  <span>name</span>: <span>&#34;rate-limit-task&#34;</span><span>,</span>
  <span>rateLimits</span>: <span>[</span>
    <span>{</span>
      <span>dynamicKey</span>: <span>&#34;input.userId&#34;</span><span>,</span>
      <span>units</span>: <span>1</span><span>,</span>
      <span>limit</span>: <span>10</span><span>,</span>
      <span>duration</span>: <span>RateLimitDuration</span><span>.</span><span>MINUTE</span><span>,</span>
    <span>}</span><span>,</span>
  <span>]</span><span>,</span>
  <span>fn</span>: <span>async</span> <span>(</span><span>input</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>return</span> <span>{</span>
      <span>Completed</span>: <span>true</span><span>,</span>
    <span>}</span><span>;</span>
  <span>}</span><span>,</span>
<span>}</span><span>)</span><span>;</span></pre></div>
</details>
</li>
<li>
<details>
  <summary><code>Go</code></summary>
<div dir="auto" data-snippet-clipboard-copy-content="// limit concurrency on a per-user basis
flowControlWorkflow := factory.NewWorkflow[DagInput, DagResult](
  create.WorkflowCreateOpts[DagInput]{
    Name: &#34;simple-dag&#34;,
    Concurrency: []*types.Concurrency{
      {
        Expression:    &#34;input.userId&#34;,
        MaxRuns:       1,
        LimitStrategy: types.GroupRoundRobin,
      },
    },
  },
  hatchet,
)

// rate limit a task per user to 10 tasks per minute, with each task consuming 1 unit
flowControlWorkflow.Task(
  create.WorkflowTask[FlowControlInput, FlowControlOutput]{
    Name: &#34;rate-limit-task&#34;,
    RateLimits: []*types.RateLimit{
      {
        Key:            &#34;user-rate-limit&#34;,
        KeyExpr:        &#34;input.userId&#34;,
        Units:          1,
        LimitValueExpr: 10,
        Duration:       types.Minute,
      },
    },
  }, func(ctx worker.HatchetContext, input FlowControlInput) (interface{}, error) {
    return &amp;SimpleOutput{
      Step: 1,
    }, nil
  },
)"><pre><span>// limit concurrency on a per-user basis</span>
<span>flowControlWorkflow</span> <span>:=</span> <span>factory</span>.<span>NewWorkflow</span>[<span>DagInput</span>, <span>DagResult</span>](
  create.<span>WorkflowCreateOpts</span>[<span>DagInput</span>]{
    <span>Name</span>: <span>&#34;simple-dag&#34;</span>,
    <span>Concurrency</span>: []<span>*</span>types.<span>Concurrency</span>{
      {
        <span>Expression</span>:    <span>&#34;input.userId&#34;</span>,
        <span>MaxRuns</span>:       <span>1</span>,
        <span>LimitStrategy</span>: <span>types</span>.<span>GroupRoundRobin</span>,
      },
    },
  },
  <span>hatchet</span>,
)

<span>// rate limit a task per user to 10 tasks per minute, with each task consuming 1 unit</span>
<span>flowControlWorkflow</span>.<span>Task</span>(
  create.<span>WorkflowTask</span>[<span>FlowControlInput</span>, <span>FlowControlOutput</span>]{
    <span>Name</span>: <span>&#34;rate-limit-task&#34;</span>,
    <span>RateLimits</span>: []<span>*</span>types.<span>RateLimit</span>{
      {
        <span>Key</span>:            <span>&#34;user-rate-limit&#34;</span>,
        <span>KeyExpr</span>:        <span>&#34;input.userId&#34;</span>,
        <span>Units</span>:          <span>1</span>,
        <span>LimitValueExpr</span>: <span>10</span>,
        <span>Duration</span>:       <span>types</span>.<span>Minute</span>,
      },
    },
  }, <span>func</span>(<span>ctx</span> worker.<span>HatchetContext</span>, <span>input</span> <span>FlowControlInput</span>) (<span>interface</span>{}, <span>error</span>) {
    <span>return</span> <span>&amp;</span><span>SimpleOutput</span>{
      <span>Step</span>: <span>1</span>,
    }, <span>nil</span>
  },
)</pre></div>
</details>
</li>
</ul>
</details>
<details><summary><strong>üìÖ Scheduling</strong></summary>

<p dir="auto">Hatchet has full support for scheduling features, including cron, one-time scheduling, and pausing execution for a time duration. This is particularly useful for:</p>
<ul dir="auto">
<li>
<p dir="auto"><strong>Cron schedules</strong> ‚Äì run data pipelines, batch processes, or notification systems on a cron schedule <a href="https://docs.hatchet.run/home/cron-runs" rel="nofollow">Read more ‚û∂</a></p>
</li>
<li>
<p dir="auto"><strong>One-time tasks</strong> ‚Äì schedule a workflow for a specific time in the future <a href="https://docs.hatchet.run/home/scheduled-runs" rel="nofollow">Read more ‚û∂</a></p>
</li>
<li>
<p dir="auto"><strong>Durable sleep</strong> ‚Äì pause execution of a task for a specific duration <a href="https://docs.hatchet.run/home/durable-execution" rel="nofollow">Read more ‚û∂</a></p>
</li>
<li>
<details>
  <summary><code>Python</code></summary>
<div dir="auto" data-snippet-clipboard-copy-content="tomorrow = datetime.today() + timedelta(days=1)

# schedule a task to run tomorrow
scheduled = simple.schedule(
  tomorrow,
  SimpleInput(message=&#34;Hello, World!&#34;)
)

# schedule a task to run every day at midnight
cron = simple.cron(
  &#34;every-day&#34;,
  &#34;0 0 * * *&#34;,
  SimpleInput(message=&#34;Hello, World!&#34;)
)"><pre><span>tomorrow</span> <span>=</span> <span>datetime</span>.<span>today</span>() <span>+</span> <span>timedelta</span>(<span>days</span><span>=</span><span>1</span>)

<span># schedule a task to run tomorrow</span>
<span>scheduled</span> <span>=</span> <span>simple</span>.<span>schedule</span>(
  <span>tomorrow</span>,
  <span>SimpleInput</span>(<span>message</span><span>=</span><span>&#34;Hello, World!&#34;</span>)
)

<span># schedule a task to run every day at midnight</span>
<span>cron</span> <span>=</span> <span>simple</span>.<span>cron</span>(
  <span>&#34;every-day&#34;</span>,
  <span>&#34;0 0 * * *&#34;</span>,
  <span>SimpleInput</span>(<span>message</span><span>=</span><span>&#34;Hello, World!&#34;</span>)
)</pre></div>
</details>
</li>
<li>
<details>
  <summary><code>Typescript</code></summary>
<div dir="auto" data-snippet-clipboard-copy-content="const tomorrow = new Date(Date.now() + 1000 * 60 * 60 * 24);
// schedule a task to run tomorrow
const scheduled = simple.schedule(tomorrow, {
  Message: &#34;Hello, World!&#34;,
});

// schedule a task to run every day at midnight
const cron = simple.cron(&#34;every-day&#34;, &#34;0 0 * * *&#34;, {
  Message: &#34;Hello, World!&#34;,
});"><pre><span>const</span> <span>tomorrow</span> <span>=</span> <span>new</span> <span>Date</span><span>(</span><span>Date</span><span>.</span><span>now</span><span>(</span><span>)</span> <span>+</span> <span>1000</span> <span>*</span> <span>60</span> <span>*</span> <span>60</span> <span>*</span> <span>24</span><span>)</span><span>;</span>
<span>// schedule a task to run tomorrow</span>
<span>const</span> <span>scheduled</span> <span>=</span> <span>simple</span><span>.</span><span>schedule</span><span>(</span><span>tomorrow</span><span>,</span> <span>{</span>
  <span>Message</span>: <span>&#34;Hello, World!&#34;</span><span>,</span>
<span>}</span><span>)</span><span>;</span>

<span>// schedule a task to run every day at midnight</span>
<span>const</span> <span>cron</span> <span>=</span> <span>simple</span><span>.</span><span>cron</span><span>(</span><span>&#34;every-day&#34;</span><span>,</span> <span>&#34;0 0 * * *&#34;</span><span>,</span> <span>{</span>
  <span>Message</span>: <span>&#34;Hello, World!&#34;</span><span>,</span>
<span>}</span><span>)</span><span>;</span></pre></div>
</details>
</li>
<li>
<details>
  <summary><code>Go</code></summary>
<div dir="auto" data-snippet-clipboard-copy-content="const tomorrow = time.Now().Add(24 * time.Hour);

// schedule a task to run tomorrow
simple.Schedule(ctx, tomorrow, ScheduleInput{
  Message: &#34;Hello, World!&#34;,
})

// schedule a task to run every day at midnight
simple.Cron(ctx, &#34;every-day&#34;, &#34;0 0 * * *&#34;, CronInput{
  Message: &#34;Hello, World!&#34;,
})"><pre><span>const</span> <span>tomorrow</span> <span>=</span> <span>time</span>.<span>Now</span>().<span>Add</span>(<span>24</span> <span>*</span> <span>time</span>.<span>Hour</span>);

<span>// schedule a task to run tomorrow</span>
<span>simple</span>.<span>Schedule</span>(<span>ctx</span>, <span>tomorrow</span>, <span>ScheduleInput</span>{
  <span>Message</span>: <span>&#34;Hello, World!&#34;</span>,
})

<span>// schedule a task to run every day at midnight</span>
<span>simple</span>.<span>Cron</span>(<span>ctx</span>, <span>&#34;every-day&#34;</span>, <span>&#34;0 0 * * *&#34;</span>, <span>CronInput</span>{
  <span>Message</span>: <span>&#34;Hello, World!&#34;</span>,
})</pre></div>
</details>
</li>
</ul>
</details>
<details><summary><strong>üöè Task routing</strong></summary>

<p dir="auto">While the default Hatchet behavior is to implement a FIFO queue, it also supports additional scheduling mechanisms to route your tasks to the ideal worker.</p>
<ul dir="auto">
<li>
<p dir="auto"><strong>Sticky assignment</strong> ‚Äî allows spawned tasks to prefer or require execution on the same worker. <a href="https://docs.hatchet.run/home/sticky-assignment" rel="nofollow">Read more ‚û∂</a></p>
</li>
<li>
<p dir="auto"><strong>Worker affinity</strong> ‚Äî ranks workers to discover which is best suited to handle a given task. <a href="https://docs.hatchet.run/home/worker-affinity" rel="nofollow">Read more ‚û∂</a></p>
</li>
<li>
<details>
  <summary><code>Python</code></summary>
<div dir="auto" data-snippet-clipboard-copy-content="# create a workflow which prefers to run on the same worker, but can be
# scheduled on any worker if the original worker is busy
hatchet.workflow(
  name=&#34;StickyWorkflow&#34;,
  sticky=StickyStrategy.SOFT,
)

# create a workflow which must run on the same worker
hatchet.workflow(
  name=&#34;StickyWorkflow&#34;,
  sticky=StickyStrategy.HARD,
)"><pre><span># create a workflow which prefers to run on the same worker, but can be</span>
<span># scheduled on any worker if the original worker is busy</span>
<span>hatchet</span>.<span>workflow</span>(
  <span>name</span><span>=</span><span>&#34;StickyWorkflow&#34;</span>,
  <span>sticky</span><span>=</span><span>StickyStrategy</span>.<span>SOFT</span>,
)

<span># create a workflow which must run on the same worker</span>
<span>hatchet</span>.<span>workflow</span>(
  <span>name</span><span>=</span><span>&#34;StickyWorkflow&#34;</span>,
  <span>sticky</span><span>=</span><span>StickyStrategy</span>.<span>HARD</span>,
)</pre></div>
</details>
</li>
<li>
<details>
  <summary><code>Typescript</code></summary>
<div dir="auto" data-snippet-clipboard-copy-content="// create a workflow which prefers to run on the same worker, but can be
// scheduled on any worker if the original worker is busy
hatchet.workflow({
  name: &#34;StickyWorkflow&#34;,
  sticky: StickyStrategy.SOFT,
});

// create a workflow which must run on the same worker
hatchet.workflow({
  name: &#34;StickyWorkflow&#34;,
  sticky: StickyStrategy.HARD,
});"><pre><span>// create a workflow which prefers to run on the same worker, but can be</span>
<span>// scheduled on any worker if the original worker is busy</span>
<span>hatchet</span><span>.</span><span>workflow</span><span>(</span><span>{</span>
  <span>name</span>: <span>&#34;StickyWorkflow&#34;</span><span>,</span>
  <span>sticky</span>: <span>StickyStrategy</span><span>.</span><span>SOFT</span><span>,</span>
<span>}</span><span>)</span><span>;</span>

<span>// create a workflow which must run on the same worker</span>
<span>hatchet</span><span>.</span><span>workflow</span><span>(</span><span>{</span>
  <span>name</span>: <span>&#34;StickyWorkflow&#34;</span><span>,</span>
  <span>sticky</span>: <span>StickyStrategy</span><span>.</span><span>HARD</span><span>,</span>
<span>}</span><span>)</span><span>;</span></pre></div>
</details>
</li>
<li>
<details>
  <summary><code>Go</code></summary>
<div dir="auto" data-snippet-clipboard-copy-content="// create a workflow which prefers to run on the same worker, but can be
// scheduled on any worker if the original worker is busy
factory.NewWorkflow[StickyInput, StickyOutput](
  create.WorkflowCreateOpts[StickyInput]{
    Name: &#34;sticky-dag&#34;,
    StickyStrategy: types.StickyStrategy_SOFT,
  },
  hatchet,
);

// create a workflow which must run on the same worker
factory.NewWorkflow[StickyInput, StickyOutput](
  create.WorkflowCreateOpts[StickyInput]{
    Name: &#34;sticky-dag&#34;,
    StickyStrategy: types.StickyStrategy_HARD,
  },
  hatchet,
);"><pre><span>// create a workflow which prefers to run on the same worker, but can be</span>
<span>// scheduled on any worker if the original worker is busy</span>
<span>factory</span>.<span>NewWorkflow</span>[<span>StickyInput</span>, <span>StickyOutput</span>](
  create.<span>WorkflowCreateOpts</span>[<span>StickyInput</span>]{
    <span>Name</span>: <span>&#34;sticky-dag&#34;</span>,
    <span>StickyStrategy</span>: <span>types</span>.<span>StickyStrategy_SOFT</span>,
  },
  <span>hatchet</span>,
);

<span>// create a workflow which must run on the same worker</span>
<span>factory</span>.<span>NewWorkflow</span>[<span>StickyInput</span>, <span>StickyOutput</span>](
  create.<span>WorkflowCreateOpts</span>[<span>StickyInput</span>]{
    <span>Name</span>: <span>&#34;sticky-dag&#34;</span>,
    <span>StickyStrategy</span>: <span>types</span>.<span>StickyStrategy_HARD</span>,
  },
  <span>hatchet</span>,
);</pre></div>
</details>
</li>
</ul>
</details>
<details><summary><strong>‚ö°Ô∏è Event triggers and listeners</strong></summary>

<p dir="auto">Hatchet supports event-based architectures where tasks and workflows can pause execution while waiting for a specific external event. It supports the following features:</p>
<ul dir="auto">
<li>
<p dir="auto"><strong>Event listening</strong> ‚Äî tasks can be paused until a specific event is triggered. <a href="https://docs.hatchet.run/home/durable-execution" rel="nofollow">Read more ‚û∂</a></p>
</li>
<li>
<p dir="auto"><strong>Event triggering</strong> ‚Äî events can trigger new workflows or steps in a workflow. <a href="https://docs.hatchet.run/home/run-on-event" rel="nofollow">Read more ‚û∂</a></p>
</li>
<li>
<details>
  <summary><code>Python</code></summary>
<div dir="auto" data-snippet-clipboard-copy-content="# Create a task which waits for an external user event or sleeps for 10 seconds
@dag_with_conditions.task(
  parents=[first_task],
  wait_for=[
    or_(
      SleepCondition(timedelta(seconds=10)),
      UserEventCondition(event_key=&#34;user:event&#34;),
    )
  ]
)
def second_task(input: EmptyModel, ctx: Context) -&gt; dict[str, str]:
    return {&#34;completed&#34;: &#34;true&#34;}"><pre><span># Create a task which waits for an external user event or sleeps for 10 seconds</span>
<span>@<span>dag_with_conditions</span>.<span>task</span>(</span>
<span>  <span>parents</span><span>=</span>[<span>first_task</span>],</span>
<span>  <span>wait_for</span><span>=</span>[</span>
<span>    <span>or_</span>(</span>
<span>      <span>SleepCondition</span>(<span>timedelta</span>(<span>seconds</span><span>=</span><span>10</span>)),</span>
<span>      <span>UserEventCondition</span>(<span>event_key</span><span>=</span><span>&#34;user:event&#34;</span>),</span>
<span>    )</span>
<span>  ]</span>
<span>)</span>
<span>def</span> <span>second_task</span>(<span>input</span>: <span>EmptyModel</span>, <span>ctx</span>: <span>Context</span>) <span>-&gt;</span> <span>dict</span>[<span>str</span>, <span>str</span>]:
    <span>return</span> {<span>&#34;completed&#34;</span>: <span>&#34;true&#34;</span>}</pre></div>
</details>
</li>
<li>
<details>
  <summary><code>Typescript</code></summary>
<div dir="auto" data-snippet-clipboard-copy-content="// Create a task which waits for an external user event or sleeps for 10 seconds
dagWithConditions.task({
  name: &#34;secondTask&#34;,
  parents: [firstTask],
  waitFor: Or({ eventKey: &#34;user:event&#34; }, { sleepFor: &#34;10s&#34; }),
  fn: async (_, ctx) =&gt; {
    return {
      Completed: true,
    };
  },
});"><pre><span>// Create a task which waits for an external user event or sleeps for 10 seconds</span>
<span>dagWithConditions</span><span>.</span><span>task</span><span>(</span><span>{</span>
  <span>name</span>: <span>&#34;secondTask&#34;</span><span>,</span>
  <span>parents</span>: <span>[</span><span>firstTask</span><span>]</span><span>,</span>
  <span>waitFor</span>: <span>Or</span><span>(</span><span>{</span> <span>eventKey</span>: <span>&#34;user:event&#34;</span> <span>}</span><span>,</span> <span>{</span> <span>sleepFor</span>: <span>&#34;10s&#34;</span> <span>}</span><span>)</span><span>,</span>
  <span>fn</span>: <span>async</span> <span>(</span><span>_</span><span>,</span> <span>ctx</span><span>)</span> <span>=&gt;</span> <span>{</span>
    <span>return</span> <span>{</span>
      <span>Completed</span>: <span>true</span><span>,</span>
    <span>}</span><span>;</span>
  <span>}</span><span>,</span>
<span>}</span><span>)</span><span>;</span></pre></div>
</details>
</li>
<li>
<details>
  <summary><code>Go</code></summary>
<div dir="auto" data-snippet-clipboard-copy-content="// Create a task which waits for an external user event or sleeps for 10 seconds
simple.Task(
  conditionOpts{
    Name: &#34;Step2&#34;,
    Parents: []create.NamedTask{
      step1,
    },
    WaitFor: condition.Conditions(
      condition.UserEventCondition(&#34;user:event&#34;, &#34;&#39;true&#39;&#34;),
      condition.SleepCondition(10 * time.Second),
    ),
  }, func(ctx worker.HatchetContext, input DagWithConditionsInput) (interface{}, error) {
    // ...
  },
);"><pre><span>// Create a task which waits for an external user event or sleeps for 10 seconds</span>
<span>simple</span>.<span>Task</span>(
  <span>conditionOpts</span>{
    <span>Name</span>: <span>&#34;Step2&#34;</span>,
    <span>Parents</span>: []create.<span>NamedTask</span>{
      <span>step1</span>,
    },
    <span>WaitFor</span>: <span>condition</span>.<span>Conditions</span>(
      <span>condition</span>.<span>UserEventCondition</span>(<span>&#34;user:event&#34;</span>, <span>&#34;&#39;true&#39;&#34;</span>),
      <span>condition</span>.<span>SleepCondition</span>(<span>10</span> <span>*</span> <span>time</span>.<span>Second</span>),
    ),
  }, <span>func</span>(<span>ctx</span> worker.<span>HatchetContext</span>, <span>input</span> <span>DagWithConditionsInput</span>) (<span>interface</span>{}, <span>error</span>) {
    <span>// ...</span>
  },
);</pre></div>
</details>
</li>
</ul>
</details>
<details><summary><strong>üñ•Ô∏è Real-time Web UI</strong></summary>

<p dir="auto">Hatchet comes bundled with a number of features to help you monitor your tasks, workflows, and queues.</p>
<p dir="auto"><strong>Real-time dashboards and metrics</strong></p>
<p dir="auto">Monitor your tasks, workflows, and queues with live updates to quickly detect issues. Alerting is built in so you can respond to problems as soon as they occur.</p>
<details open="">
  <summary>
    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true">
    <path d="M16 3.75v8.5a.75.75 0 0 1-1.136.643L11 10.575v.675A1.75 1.75 0 0 1 9.25 13h-7.5A1.75 1.75 0 0 1 0 11.25v-6.5C0 3.784.784 3 1.75 3h7.5c.966 0 1.75.784 1.75 1.75v.675l3.864-2.318A.75.75 0 0 1 16 3.75Zm-6.5 1a.25.25 0 0 0-.25-.25h-7.5a.25.25 0 0 0-.25.25v6.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-6.5ZM11 8.825l3.5 2.1v-5.85l-3.5 2.1Z"></path>
</svg>
    <span aria-label="Video description monitoring-2.mp4">monitoring-2.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/25448214/429665683-b1797540-c9da-4057-b50f-4780f52a2cb9.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDM3ODAyMTMsIm5iZiI6MTc0Mzc3OTkxMywicGF0aCI6Ii8yNTQ0ODIxNC80Mjk2NjU2ODMtYjE3OTc1NDAtYzlkYS00MDU3LWI1MGYtNDc4MGY1MmEyY2I5Lm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA0MDQlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNDA0VDE1MTgzM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTQwMDA2OTBlMGY1OTExOWNhMTZkNDUyNDJjYWU5ZDUzYWMyMTMyM2QxMDY1MGQ5NzE3MDgzNDk1Yzg4ZDM5ODgmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.iukP6nIpLsJmS5n6mtDDUF03V-Qn_HSc-g97vsVTCww" data-canonical-src="https://private-user-images.githubusercontent.com/25448214/429665683-b1797540-c9da-4057-b50f-4780f52a2cb9.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDM3ODAyMTMsIm5iZiI6MTc0Mzc3OTkxMywicGF0aCI6Ii8yNTQ0ODIxNC80Mjk2NjU2ODMtYjE3OTc1NDAtYzlkYS00MDU3LWI1MGYtNDc4MGY1MmEyY2I5Lm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA0MDQlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNDA0VDE1MTgzM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTQwMDA2OTBlMGY1OTExOWNhMTZkNDUyNDJjYWU5ZDUzYWMyMTMyM2QxMDY1MGQ5NzE3MDgzNDk1Yzg4ZDM5ODgmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.iukP6nIpLsJmS5n6mtDDUF03V-Qn_HSc-g97vsVTCww" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto"><strong>Logging</strong></p>
<p dir="auto">Hatchet supports logging from your tasks, allowing you to easily correlate task failures with logs in your system. No more digging through your logging service to figure out why your tasks failed.</p>
<details open="">
  <summary>
    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true">
    <path d="M16 3.75v8.5a.75.75 0 0 1-1.136.643L11 10.575v.675A1.75 1.75 0 0 1 9.25 13h-7.5A1.75 1.75 0 0 1 0 11.25v-6.5C0 3.784.784 3 1.75 3h7.5c.966 0 1.75.784 1.75 1.75v.675l3.864-2.318A.75.75 0 0 1 16 3.75Zm-6.5 1a.25.25 0 0 0-.25-.25h-7.5a.25.25 0 0 0-.25.25v6.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-6.5ZM11 8.825l3.5 2.1v-5.85l-3.5 2.1Z"></path>
</svg>
    <span aria-label="Video description logging-7.mp4">logging-7.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/25448214/429665733-427c15cd-8842-4b54-ab2e-3b1cabc01c7b.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDM3ODAyMTMsIm5iZiI6MTc0Mzc3OTkxMywicGF0aCI6Ii8yNTQ0ODIxNC80Mjk2NjU3MzMtNDI3YzE1Y2QtODg0Mi00YjU0LWFiMmUtM2IxY2FiYzAxYzdiLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA0MDQlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNDA0VDE1MTgzM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWFjZGQxMWIwNmE4NzI5Y2I0YzdlMGY3M2ExNzExMTBkNWJiOTRlMDY4MjlkYTUzZjFkOGE1MzJkZjJlZTUxMzcmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.YMDp1pKntigGN0JgQzRdXWvbgSzegghlqaFe_VioAu8" data-canonical-src="https://private-user-images.githubusercontent.com/25448214/429665733-427c15cd-8842-4b54-ab2e-3b1cabc01c7b.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3NDM3ODAyMTMsIm5iZiI6MTc0Mzc3OTkxMywicGF0aCI6Ii8yNTQ0ODIxNC80Mjk2NjU3MzMtNDI3YzE1Y2QtODg0Mi00YjU0LWFiMmUtM2IxY2FiYzAxYzdiLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNTA0MDQlMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjUwNDA0VDE1MTgzM1omWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPWFjZGQxMWIwNmE4NzI5Y2I0YzdlMGY3M2ExNzExMTBkNWJiOTRlMDY4MjlkYTUzZjFkOGE1MzJkZjJlZTUxMzcmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.YMDp1pKntigGN0JgQzRdXWvbgSzegghlqaFe_VioAu8" controls="controls" muted="muted">

  </video>
</details>

<p dir="auto"><strong>Alerting</strong></p>
<p dir="auto">Hatchet supports Slack and email-based alerting for when your tasks fail. Alerts are real-time with adjustable alerting windows.</p>
</details>

<p dir="auto">Hatchet is available as a cloud version or self-hosted. See the following docs to get up and running quickly:</p>
<ul dir="auto">
<li><a href="https://docs.hatchet.run/home/hatchet-cloud-quickstart" rel="nofollow">Hatchet Cloud Quickstart</a></li>
<li><a href="https://docs.hatchet.run/self-hosting" rel="nofollow">Hatchet Self-Hosted</a></li>
</ul>

<p dir="auto">The most up-to-date documentation can be found at <a href="https://docs.hatchet.run" rel="nofollow">https://docs.hatchet.run</a>.</p>

<ul dir="auto">
<li><a href="https://discord.gg/ZMeUafwH89" rel="nofollow">Discord</a> - best for getting in touch with the maintainers and hanging with the community</li>
<li><a href="https://github.com/hatchet-dev/hatchet/issues">Github Issues</a> - used for filing bug reports</li>
<li><a href="https://github.com/hatchet-dev/hatchet/discussions">Github Discussions</a> - used for starting in-depth technical discussions that are suited for asynchronous communication</li>
<li><a href="mailto:contact@hatchet.run">Email</a> - best for getting Hatchet Cloud support and for help with billing, data deletion, etc.</li>
</ul>

<details>
<summary>Hatchet vs Temporal</summary>

<p dir="auto">Hatchet is designed to be a general-purpose task orchestration platform -- it can be used as a queue, a DAG-based orchestrator, a durable execution engine, or all three. As a result, Hatchet covers a wider array of use-cases, like multiple queueing strategies, rate limiting, DAG features, conditional triggering, streaming features, and much more.</p>
<p dir="auto">Temporal is narrowly focused on durable execution, and supports a wider range of database backends and result stores, like Apache Cassandra, MySQL, PostgreSQL, and SQLite.</p>
<p dir="auto"><strong>When to use Hatchet:</strong> when you&#39;d like to get more control over the underlying queue logic, run DAG-based workflows, or want to simplify self-hosting by only running the Hatchet engine and Postgres.</p>
<p dir="auto"><strong>When to use Temporal:</strong> when you&#39;d like to use a non-Postgres result store, or your only workload is best suited for durable execution.</p>
</details>
<details>
<summary>Hatchet vs Task Queues (BullMQ, Celery)</summary>

<p dir="auto">Hatchet is a durable task queue, meaning it persists the history of all executions (up to a retention period), which allows for easy monitoring + debugging and powers a bunch of the durability features above. This isn‚Äôt the standard behavior of Celery and BullMQ (and you need to rely on third-party UI tools which are extremely limited in functionality, like Celery Flower).</p>
<p dir="auto"><strong>When to use Hatchet:</strong> when you&#39;d like results to be persisted and observable in a UI</p>
<p dir="auto"><strong>When to use task queue library like BullMQ/Celery:</strong> when you need very high throughput (&gt;10k/s) without retention, or when you&#39;d like to use a single library (instead of a standalone service like Hatchet) to interact with your queue.</p>
</details>
<details>
<summary>Hatchet vs DAG-based platforms (Airflow, Prefect, Dagster)</summary>

<p dir="auto">These tools are usually built with data engineers in mind, and aren‚Äôt designed to run as part of a high-volume application. They‚Äôre usually higher latency and higher cost, with their primary selling point being integrations with common datastores and connectors.</p>
<p dir="auto"><strong>When to use Hatchet:</strong> when you&#39;d like to use a DAG-based framework, write your own integrations and functions, and require higher throughput (&gt;100/s)</p>
<p dir="auto"><strong>When to use other DAG-based platforms:</strong> when you&#39;d like to use other data stores and connectors that work out of the box</p>
</details>
<details>
<summary>Hatchet vs AI Frameworks</summary>

<p dir="auto">Most AI frameworks are built to run in-memory, with horizontal scaling and durability as an afterthought. While you can use an AI framework in conjunction with Hatchet, most of our users discard their AI framework and use Hatchet‚Äôs primitives to build their applications.</p>
<p dir="auto"><strong>When to use Hatchet:</strong> when you&#39;d like full control over your underlying functions and LLM calls, or you require high availability and durability for your functions.</p>
<p dir="auto"><strong>When to use an AI framework:</strong> when you&#39;d like to get started quickly with simple abstractions.</p>
</details>

<p dir="auto">Please submit any bugs that you encounter via Github issues.</p>

<p dir="auto">Please let us know what you&#39;re interesting in working on in the #contributing channel on <a href="https://discord.gg/ZMeUafwH89" rel="nofollow">Discord</a>. This will help us shape the direction of the project and will make collaboration much easier!</p>
</article></div></div>
  </body>
</html>
