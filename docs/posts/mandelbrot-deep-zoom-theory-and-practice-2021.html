<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://mathr.co.uk/blog/2021-05-14_deep_zoom_theory_and_practice.html">Original</a>
    <h1>Mandelbrot deep zoom theory and practice (2021)</h1>
    
    <div id="readability-page-1" class="page"><div xmlns="http://www.w3.org/1999/xhtml">
<h3 id="a2021-05-14_deep_zoom_theory_and_practice_introduction"><a href="#a2021-05-14_deep_zoom_theory_and_practice_introduction" title="Introduction">Introduction</a></h3>
<p>The complex beauty of the world&#39;s most famous fractal, the Mandelbrot set,
emerges from the repeated iteration of a simple formula:</p>
<blockquote>\[z \to z^2 + c\]</blockquote>
<p>Zooming into the intricate boundary of the shape reveals ever more detail,
but one needs higher precision numbers and higher iteration counts as you
go deeper.  The computational cost rises quickly with the classical
rendering algorithms which use high precision numbers for each pixel.</p>
<p>In 2013, K.I. Martin&#39;s SuperFractalThing and accompanying white paper
<a href="https://web.archive.org/web/20160408070057/http://superfractalthing.co.nf/sft_maths.pdf" title="sft_maths.pdf">sft_maths.pdf</a>
popularized a pair of new acceleration techniques.  First one notes that
the formula \(z \to z^2 + c\) is continuous, so nearby points remain
nearby under iteration.  This means you can iterate one point at high
precision (the reference orbit) and compute differences from the reference
orbit for each pixel in low precision (the perturbed orbits).  Secondly,
iterating the perturbed formula one ends up with a polynomial series in
the initial pertubation in \(c\), which depends only on the reference.  The
degree rises rapidly but you can truncate it to get an approximation.
This means you can compute the series approximation coefficients once, and
substitute in the perturbed \(c\) values for each pixel, allowing you to
initialize the perturbed orbits at a later iteration, skipping potentially
lots of per-pixel work.</p>
<p>The perturbation technique has since been extended to the Burning Ship
fractal and other &#34;abs variations&#34;, and it also works for hybrid fractals
combining iterations of several formulas.</p>
<p>Prerequisites for the rest of this article: a familiarity with complex
numbers and algebraic manipulation; knowing how to draw the unzoomed Mandelbrot
set; understanding the limitations of computer implementation of numbers
(see for example <a href="https://fractalwiki.org/wiki/Number_types#Hardware_floating_point_types">Hardware Floating Point Types</a>).</p>

<h3 id="a2021-05-14_deep_zoom_theory_and_practice_perturbation"><a href="#a2021-05-14_deep_zoom_theory_and_practice_perturbation" title="Perturbation">Perturbation</a></h3>
<p>In the remainder of this post, lower case and upper case variables with
the same letter mean different things.  Upper case means unperturbed or
reference, usually high precision or high range.  Lower case means perturbed
per pixel delta, low precision and low range.</p>
<p>In perturbation, on starts with the iteration formula <a href="#a2021-05-14_deep_zoom_theory_and_practice_1" title="Equation 1">[1]</a>:</p>
<blockquote id="a2021-05-14_deep_zoom_theory_and_practice_1">\[Z \to Z^2 + C\]</blockquote>
<p>Perturb the variables with unevaluated sums <a href="#a2021-05-14_deep_zoom_theory_and_practice_2" title="Equation 2">[2]</a>:</p>
<blockquote id="a2021-05-14_deep_zoom_theory_and_practice_2">\[(Z + z) \to (Z + z)^2 + (C + c)\]</blockquote>
<p>Do symbolic algebra to avoid the catastrophic absorption when adding tiny
values \(z\) to large values \(Z\) (e.g. 1 million plus 1 is still 1 million
if you only have 3 significant digits to work with) <a href="#a2021-05-14_deep_zoom_theory_and_practice_3" title="Equation 3">[3]</a>:</p>
<blockquote id="a2021-05-14_deep_zoom_theory_and_practice_3">\[z \to 2 Z z + z^2 + c\]</blockquote>
<p>\(C, Z\) is the &#34;reference&#34; orbit, computed in high precision using <a href="#a2021-05-14_deep_zoom_theory_and_practice_1" title="Equation 1">[1]</a>
and rounded to machine double precision, which works fine most of the time.
\(c, z\) are the &#34;pixel&#34; orbit, you can do many of these near each reference
(e.g. an entire image).</p>

<h3 id="a2021-05-14_deep_zoom_theory_and_practice_glitches"><a href="#a2021-05-14_deep_zoom_theory_and_practice_glitches" title="Glitches">Glitches</a></h3>
<p>There is a problem that can be noticed when you zoom deeper near certain
features in the fractal.  There are parts that can have a &#34;noisy&#34; appearance,
or there may be weird flat blobs that look out of place.  These are the
infamous perturbation glitches.  It was observed that adding references in
the glitches and recomputing the pixels could fix them, but there was no
reliable way to detect them programmatically until Pauldelbrot
discovered/invented a method:
<a href="http://www.fractalforums.com/announcements-and-news/pertubation-theory-glitches-improvement/msg73027/#msg73027" title="Perturbation Theory Glitches Improvement">Perturbation Theory Glitches Improvement</a>.</p>
<p>The solution: if <a href="#a2021-05-14_deep_zoom_theory_and_practice_4" title="Equation 4">[4]</a>:</p>
<blockquote id="a2021-05-14_deep_zoom_theory_and_practice_4">\[|Z+z| &lt;&lt; |Z|\]</blockquote>
<p>at any iteration, then glitches can occur.  The solution: retry with a
new reference, or (for well-behaved formulas like the Mandelbrot set) rebase
to a new reference and carry on.</p>
<p>Perturbation assumes exact maths, but some images have glitches when
naively using perturbation in low precision.  Pauldelbrot found his glitch
criterion by perturbing the perturbation iterations: one has perturbed iteration
as in <a href="#a2021-05-14_deep_zoom_theory_and_practice_3" title="Equation 3">[3]</a> (recap: \(z \to 2 Z z + z^2 + c\)).  Then one perturbs this with
\(z \to z + e, c \to c + f\) <a href="#a2021-05-14_deep_zoom_theory_and_practice_5" title="Equation 5">[5]</a>:</p>
<blockquote id="a2021-05-14_deep_zoom_theory_and_practice_5">\[e \to (2 (Z + z) + e) e + f\]</blockquote>
<p>We are interested what happens to the ratio \(e/z\) under iteration, so
rewrite <a href="#a2021-05-14_deep_zoom_theory_and_practice_3" title="Equation 3">[3]</a> as <a href="#a2021-05-14_deep_zoom_theory_and_practice_6" title="Equation 6">[6]</a>:</p>
<blockquote id="a2021-05-14_deep_zoom_theory_and_practice_6">\[z \to (2 Z + z) z + c\]</blockquote>
<p>Pattern matching, the interesting part (assuming \(c\) and \(f\) are
small) of \(e/z\) is \(2(Z + z) / 2 Z\).  When \(e/z\) is small, the nearby
pixels &#34;stick together&#34; and there is not enough precision in the number
type to distinguish them, which makes a glitch.  So a glitch can be detected
when <a href="#a2021-05-14_deep_zoom_theory_and_practice_7" title="Equation 7">[7]</a>:</p>
<blockquote id="a2021-05-14_deep_zoom_theory_and_practice_7">\[|Z + z|^2 &lt; G |Z|^2\]</blockquote>
<p>where G is a threshold (somewhere between 1e-2 and 1e-8, depending how
strict you want to be).  This does not add much cost, as \(|Z+z|^2\) already
needs to be computed for escape test, and \(G|Z^2|\) can be computed once
for each iteration of the reference orbit and stored.</p>
<p>The problem now is: How to choose G?  Too big and it takes forever as
glitches are detected all over, too small and some glitches can be missed
leading to bad images.</p>
<p>The glitched pixels can be recalculated with a more appropriate
reference point: more glitches may result and adding more references
may be necessary until the image is finished.</p>

<h3 id="a2021-05-14_deep_zoom_theory_and_practice_rescaling"><a href="#a2021-05-14_deep_zoom_theory_and_practice_rescaling" title="Rescaling">Rescaling</a></h3>
<p>Double precision floating point (with 53 bits of mantissa) is more than
enough for computing perturbed orbits: even single precision (with 24 bits)
can be used successfully.  But when zooming deeper another problem occurs:
double precision has a limited range, once values get smaller than about
1e-308 then they underflow to 0.  This means perturbation with double
precision can only zoom so far, as eventually the perturbed deltas are
smaller than can be represented.</p>
<p>An early technique for extending range is to store the mantissa as a
double precision value, but normalized to be near 1 in magnitude, with
a separate integer to store the exponent.  This floatexp technique works
for arbitrarily deep zooms, but the performance is terrible because it
needs to handle every arithmetic operation in software (instead of them
being a single CPU instruction).</p>
<p>The solution for efficient performance turned out to be using an
unevaluated product (compare with the unevaluated sum of perturbation)
to rescale the double precision iterations to be nearer 1 and avoid
underflow: substitute \(z = S w\) and \(c = S d\) to get <a href="#a2021-05-14_deep_zoom_theory_and_practice_8" title="Equation 8">[8]</a>:</p>
<blockquote id="a2021-05-14_deep_zoom_theory_and_practice_8">\[S w \to 2 Z S w + S^2 w^2 + S d\]</blockquote>
<p>and now cancel out one scale factor \(S\) throughout <a href="#a2021-05-14_deep_zoom_theory_and_practice_9" title="Equation 9">[9]</a>:</p>
<blockquote id="a2021-05-14_deep_zoom_theory_and_practice_9">\[w \to 2 Z w + S w^2 + d\]</blockquote>
<p>Choose \(S\) so that \(|w|\) is around \(1\).  When \(|w|\) is at risk
of overflow (or underflow) after some iterations, redo the scaling; this
is typically a few hundred iterations as \(|Z|\) is bounded by \(2\) except
at final escape.</p>
<p>Optimization: if \(S\) underflowed to \(0\) in double precision, you
don&#39;t need to calculate the \(+ S w^2\) term at all when \(Z\) is not small.
Similarly you can skip the \(+ d\) if it underflowed.  For higher powers
there will be terms involving \(S^2 w^3\) (for example), which might not
need to be calculated either due to underflow.  Ideally these tests would
be performed once at rescaling time, instead of in every inner loop iteration
(though they would be highly predictable I suppose).</p>

<h3 id="a2021-05-14_deep_zoom_theory_and_practice_full_iterations"><a href="#a2021-05-14_deep_zoom_theory_and_practice_full_iterations" title="Full Iterations">Full Iterations</a></h3>
<p>There is a problem: if \(|Z|\) is very small, it can underflow to \(0\)
in unscaled double in <a href="#a2021-05-14_deep_zoom_theory_and_practice_9" title="Equation 9">[9]</a>.  One needs to store the full range \(Z\) and
do a full range (e.g. floatexp) iteration at those points, because \(|w|\)
can change dramatically.  Rescaling is necessary afterwards.  This was
described by Pauldelbrot:
<a href="https://fractalforums.org/programming/11/memory-bandwidth-trade-offs-for-perturbation-rendering/3717/msg23497#msg23497" title="Rescaled Iterations in Nanoscope">Rescaled Iterations in Nanoscope</a>.</p>
<p>To do the full iteration, compute \(z = S w\) in floatexp (using a floatexp
for \(S\) so that there is no underflow), do the perturbed iteration <a href="#a2021-05-14_deep_zoom_theory_and_practice_3" title="Equation 3">[3]</a> with
all variables in floatexp.  To rescale afterwards, compute \(S = |z|\) and
\(w = z/S, d = c/S\) (computed in floatexp with \(w\) and \(d\) rounded to
double precision afterwards).  Then a double precision \(s\) can be computed
for use in <a href="#a2021-05-14_deep_zoom_theory_and_practice_9" title="Equation 9">[9]</a>.</p>

<h3 id="a2021-05-14_deep_zoom_theory_and_practice_abs_variations"><a href="#a2021-05-14_deep_zoom_theory_and_practice_abs_variations" title="Abs Variations">Abs Variations</a></h3>
<p>The Burning Ship fractal modifies the Mandelbrot set formula by taking
absolute values of the real and imaginary parts before the complex squaring <a href="#a2021-05-14_deep_zoom_theory_and_practice_10" title="Equation 10">[10]</a>:</p>
<blockquote id="a2021-05-14_deep_zoom_theory_and_practice_10">\[X + i Y \to (|X| + i |Y|)^2 + C\]</blockquote>
<p>When perturbing the Burning Ship and other &#34;abs variations&#34;, one ends up with
things like <a href="#a2021-05-14_deep_zoom_theory_and_practice_11" title="Equation 11">[11]</a>:</p>
<blockquote id="a2021-05-14_deep_zoom_theory_and_practice_11">\[|XY + Xy + xY + xy| - |XY|\]</blockquote>
<p>which naively gives \(0\) by catastrophic absorption and cancellation.
laser blaster made a case analysis
<a href="http://www.fractalforums.com/new-theories-and-research/perturbation-formula-for-burning-ship-(hopefully-correct-p)/msg74090/#msg74090" title="Perturbation Formula for Burning Ship">Perturbation Formula for Burning Ship</a>
which can be written as <a href="#a2021-05-14_deep_zoom_theory_and_practice_12" title="Equation 12">[12]</a>:</p>
<blockquote id="a2021-05-14_deep_zoom_theory_and_practice_12"><pre>diffabs(c, d) := |c+d| - |c| = c &gt;= 0 ? c + d &gt;= 0 ? d : -(2*c+d) : c + d &gt; 0 ? 2*c+d : -d</pre></blockquote>
<p>when \(d\) is small the \(\pm d\) cases are much more likely.  With rescaling
in the mix <a href="#a2021-05-14_deep_zoom_theory_and_practice_11" title="Equation 11">[11]</a> works out as <a href="#a2021-05-14_deep_zoom_theory_and_practice_13" title="Equation 13">[13]</a>:</p>
<blockquote id="a2021-05-14_deep_zoom_theory_and_practice_13">\[\operatorname{diffabs}(XY/s, Xy + xY + sxy)\]</blockquote>
<p>which has the risk of overflow when \(s\) is small, but the signs work
out ok even for infinite \(c\) as \(d\) is known to be finite.  Moreover,
if \(s = 0\) due to underflow, the \(\pm d\) branches will always be taken
(except when \(XY\) is small, when a full floatexp iteration will be performed
instead), and as \(s \ge 0\) by construction, <a href="#a2021-05-14_deep_zoom_theory_and_practice_13" title="Equation 13">[13]</a> reduces to <a href="#a2021-05-14_deep_zoom_theory_and_practice_14" title="Equation 14">[14]</a>:</p>
<blockquote id="a2021-05-14_deep_zoom_theory_and_practice_14">\[\operatorname{sign}(X) * \operatorname{sign}(Y) * (X y + x Y)\]</blockquote>
<p>(Note: this formulation helps avoid underflow in \(\operatorname{sign}(XY)\)
when \(X\) and \(Y\) are small.)</p>

<h3 id="a2021-05-14_deep_zoom_theory_and_practice_deep_needle"><a href="#a2021-05-14_deep_zoom_theory_and_practice_deep_needle" title="Deep Needle">Deep Needle</a></h3>
<p>For well-behaved functions like the Mandelbrot set iterations, one needs
to do full iterations when \(Z\) gets small.  For the Burning Ship and other
abs variations, this is not sufficient: problems occur if either X and Y are
small, not only when both are small at the same time.  Full iterations need
to be done when either variable is small.  This makes rescaled iterations for
locations near the needle slower than just doing full floatexp iterations
all the time (because of the extra wasted work handling the rescaling).
This is because near the needle all the iterations have Y near 0, which means
floatexp iterations will be done anyway.  Using floatexp from the get go avoids
many branches and rescaling in the inner loop, so it&#39;s significantly faster.
The problem is worse in single precision because it has much less range: it
underflows below 1e-38 or so, rather than 1e-308 for double precision.</p>
<p>The problem of automatically detecting these &#34;deep needle&#34; locations (which
may be in the needles of miniships) and switching implementations to avoid the
extra slowdown remains unresolved in KF.</p>

<h3 id="a2021-05-14_deep_zoom_theory_and_practice_hybrid_fractals"><a href="#a2021-05-14_deep_zoom_theory_and_practice_hybrid_fractals" title="Hybrid Fractals">Hybrid Fractals</a></h3>
<p>The Mandelbrot set has lovely logarithmic spirals all over, and the
Burning Ship has interesting &#34;rigging&#34; on the miniships on its needle.
Hybridization provide a way to get both these features in a single
fractal image.  The basic idea is to interleave the iteration formulas,
for example alternating between <a href="#a2021-05-14_deep_zoom_theory_and_practice_1" title="Equation 1">[1]</a> and <a href="#a2021-05-14_deep_zoom_theory_and_practice_10" title="Equation 10">[10]</a>, but more complicated
interleavings are possible (eg <a href="#a2021-05-14_deep_zoom_theory_and_practice_1" title="Equation 1">[1]</a><a href="#a2021-05-14_deep_zoom_theory_and_practice_10" title="Equation 10">[10]</a><a href="#a2021-05-14_deep_zoom_theory_and_practice_1" title="Equation 1">[1]</a><a href="#a2021-05-14_deep_zoom_theory_and_practice_1" title="Equation 1">[1]</a> in a loop, etc).</p>
<p>Hybrid fractals in KF are built from stanzas, each has some lines, each
line has two operators, and each operator has controls for absolute x,
absolute y, negate x, negate y, integer power \(p\), complex multiplier \(a\).
The two operators in a line can be combined by addition, subtraction or multiplication,
and currently the number of lines in a stanza can be either 1 or 2 and
there can be 1, 2, 3 or 4 stanzas. The output of each line is fed into
the next, and at the end of each stanza the +c part of the formula happens.
There are controls to choose how many times to repeat each stanza, and which
stanza to continue from after reaching the end.</p>
<p>Implementing perturbation for this is quite methodical.  Start from an
operator, with inputs \(Z\) and \(z\).  Set mutable variables:</p>
<blockquote><pre>z := input
W := Z + z
B := Z</pre></blockquote>
<p>If absolute x enabled in formula, then update</p>
<blockquote><pre>re(z) := diffabs(re(Z), re(z))
re(W) := abs(W)
re(B) := abs(B)</pre></blockquote>
<p>Similarly for the imaginary part.  If negate x enabled in formula, then update</p>
<blockquote><pre>re(z) := -re(z)
W := -W
B := -B</pre></blockquote>
<p>Similarly for the imaginary part. Now compute</p>
<blockquote>\[S = \sum_{i=0}^{p-1} W^i B^{p-1 - i}\]</blockquote>
<p>and return \(a z S\).  Combining operators into lines may be done by
<a href="https://vinayak.io/2025/01/02/ipychat/2018-03-12_perturbation_algebra.html" title="Perturbation Algebra">Perturbation Algebra</a>.
Combining lines into stanzas can be done by iterating unperturbed \(Z\)
alongside perturbed \(z\); only the \(+C\) needs high precision, and that
is not done within a stanza.</p>
<p>Rescaling hybrid iterations seems like a big challenge, but it&#39;s not that hard:
if either or both the real and imaginary parts of the reference orbit \(Z\)
are small, one needs to do a full range iteration with floatexp and recalculate
the scale factor afterwards, as with formulas like Burning Ship.  Otherwise,
thread \(s\) through from the top level down to the operators.  Initialize with</p>
<blockquote><pre>W := Z + z*s</pre></blockquote>
<p>and modify the absolute cases to divide the reference by \(s\):</p>
<blockquote><pre>re(z) := diffabs(re(Z/s), re(z))</pre></blockquote>
<p>Similarly for imaginary part.  When combining operators (this subterm only
occurs with multiplication) replace \(f(o_1, Z + z)\) with \(f(o_1, Z + z s)\).</p>
<p>And that&#39;s almost all the changes that need to be made!</p>
<p>For distance estimation of hybrid formulas I use dual numbers for
automatic differentiation.  One small adjustment was needed for it to work
with rescaled iterations: instead of initializing the dual parts (before
iteration) with 1 and scaling by the pixel spacing at the end for screen-space
colouring, initialize the dual parts with the pixel spacing and don&#39;t scale
at the end.  This avoids overflow of the derivative, and the same rescaling
factor can be used for regular and dual parts.</p>

<h3 id="a2021-05-14_deep_zoom_theory_and_practice_code_generation"><a href="#a2021-05-14_deep_zoom_theory_and_practice_code_generation" title="Code Generation">Code Generation</a></h3>
<p>Naive implementations of parametric hybrids are very slow due to all
the branches in the inner loops (checking if absolute x enabled at every
iteration for every pixel, etc).  Using for example OpenCL, these branches can
be done once when generating source code for a formula, instead of every
iteration for every pixel.  This runs much faster, even when compiled
to run on the same OpenCL device that is interpreting the parametric code.</p>

<h3 id="a2021-05-14_deep_zoom_theory_and_practice_series_approximation"><a href="#a2021-05-14_deep_zoom_theory_and_practice_series_approximation" title="Series Approximation">Series Approximation</a></h3>
<p>The other part of the thing that K I Martin&#39;s SuperFractalThing popularized
was that iteration of <a href="#a2021-05-14_deep_zoom_theory_and_practice_3" title="Equation 3">[3]</a> gives a polynomial series in \(c\) <a href="#a2021-05-14_deep_zoom_theory_and_practice_15" title="Equation 15">[15]</a>:</p>
<blockquote id="a2021-05-14_deep_zoom_theory_and_practice_15">\[z_n = \sum A_{n,k} c^k\]</blockquote>
<p>(with 0 constant term). This can be used to &#34;skip&#34; a whole bunch of
iterations, assuming that truncating the series and/or low precision
doesn&#39;t cause too much trouble.  Substituting <a href="#a2021-05-14_deep_zoom_theory_and_practice_15" title="Equation 15">[15]</a> into <a href="#a2021-05-14_deep_zoom_theory_and_practice_3" title="Equation 3">[3]</a> gives <a href="#a2021-05-14_deep_zoom_theory_and_practice_16" title="Equation 16">[16]</a>:</p>
<blockquote id="a2021-05-14_deep_zoom_theory_and_practice_16">\[\sum A_{n+1,k} c^k = 2 Z \sum A_{n,k} c^k + (\sum A_{n,k} c^k)^2 + c\]</blockquote>
<p>Equating coefficients of \(c^k\) gives recurrence relations for the
series coefficients \(A_{n,k}\).  See <a href="https://vinayak.io/2025/01/02/ipychat/2016-03-06_simpler_series_approximation.html" title="Simpler Series Approximation">Simpler Series Approximation</a>.</p>
<p>The traditional way to evaluate that it&#39;s ok to do the series approximation
at an iteration is to check whether it doesn&#39;t deviate too far from regular
iterations (or perturbed iterations) at a collection of &#34;probe&#34; points.
When it starts to deviate, roll back an iteration and initialize all the
image pixels with <a href="#a2021-05-14_deep_zoom_theory_and_practice_15" title="Equation 15">[15]</a> at that iteration.</p>
<p>Later, knighty extended the series approximation to two complex variables.
If the reference \(C\) is a periodic point (for example the center of a
minibrot), the biseries in \(z, c\) allows skipping a whole period of
iterations.  Then multiple periods can be skipped by repeating the biseries
step.  This gives a further big speedup beyond regular series approximation
near minibrots.  An escape radius is needed for \(z\), based on properties
of the reference, so as not to perform too many biseries iterations.  After
that, regular perturbed iterations are performed until final escape.  This
is available in KF as NanoMB1.</p>
<p>Current research by knighty and others involves a chain of minibrots
at successively deeper zoom levels.  One starts with the deepest minibrot,
performing biseries iterations until it escapes its \(z\) radius.  Then
rebase the iterates to the next outer minibrot, and perform biseries
iterations with that.  Repeat until final escape.  This is available in
KF as NanoMB2, but it&#39;s highly experimental and fails for many locations.
Perhaps it needs to be combined with more perturbation or higher precision:
sometimes the iterates may still be too close to each other when they
escape a deep minibrot, such that catastrophic absorption occurs.
In progress...</p>
<p>For Burning Ship and other abs variations (and presumably hybrids too),
series approximation can take the form of two bivariate real series in
\(\Re(c)\) and \(\Im(c)\) for the real and imaginary parts of \(z\).  But
these are only good so long as the region is not folded by an absolute
value, so typically only a few iterations can be skipped.  Maybe the series
can be split into two (or more) parts with the other side(s) shifted when
this occurs?  In progress...</p>

<h3 id="a2021-05-14_deep_zoom_theory_and_practice_conclusion"><a href="#a2021-05-14_deep_zoom_theory_and_practice_conclusion" title="Conclusion">Conclusion</a></h3>
<p>Perturbation techniques that greatly reduce the quantity of high precision
iterations needed, as well as (for well-behaved formulas) series approximation
techniques that reduce the quantity of low precision iterations needed still
further, provide a vast speedup over classical algorithms that use high
precision for every pixel.  Rescaling can provide an additional constant factor
speedup over using full range floatexp number types for most (not &#34;deep needle&#34;)
locations.  Chained biseries approximation (&#34;NanoMB2&#34;) and series approximation
for abs variations and hybrids are still topics of research.</p>
<p>It remains open how to choose the \(G\) for Pauldelbrot&#39;s glitch detection
criterion, and how to robustly compute series approximation skipping: there
is still no complete mathematical proof of correctness with rigourous error
bounds, although the images do most often look plausible and different
implementations do tend to agree.</p>
</div></div>
  </body>
</html>
