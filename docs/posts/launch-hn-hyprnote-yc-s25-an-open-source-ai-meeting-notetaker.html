<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://news.ycombinator.com/item?id=44725306">Original</a>
    <h1>Launch HN: Hyprnote (YC S25) â€“ An open-source AI meeting notetaker</h1>
    
    <div id="readability-page-1" class="page"><div><div><p>Hi HN! We&#39;re Yujong, John, Duck, and Sung from Hyprnote (<a href="https://hyprnote.com" rel="nofollow">https://hyprnote.com</a>). We&#39;re building an open-source, privacy-first AI note-taking app that runs fully on-device. Think of it as an open-source Granola. No Zoom bots, no cloud APIs, no data ever leaves your machine.</p><p>Source code: <a href="https://github.com/fastrepl/hyprnote">https://github.com/fastrepl/hyprnote</a>
Demo video: <a href="https://hyprnote.com/demo" rel="nofollow">https://hyprnote.com/demo</a></p><p>We built Hyprnote because some of our friends told us that their companies banned certain meeting notetakers due to data concerns, or they simply felt uncomfortable sending data to unknown servers. So they went back to manual note-taking - losing focus during meetings and wasting time afterward.</p><p>We asked: could we build something just as useful, but completely local?</p><p>Hyprnote is a desktop app that transcribes and summarizes meetings on-device. It captures both your mic input and system audio, so you don&#39;t need to invite bots. It generates a summary based on the notes you take. Everything runs on local AI models by default, using Whisper and HyprLLM. HyprLLM is our proof-of-concept model fine-tuned from Qwen3 1.7B. We learned that summarizing meetings is a very nuanced task and that a model&#39;s raw intelligence (or weight) doesn&#39;t matter THAT much. We&#39;ll release more details on evaluation and training once we finish the 2nd iteration of the model (still not that good  we can make it a lot better).</p><p>Whisper inference: <a href="https://github.com/fastrepl/hyprnote/blob/main/crates/whisper-local/src/model.rs">https://github.com/fastrepl/hyprnote/blob/main/crates/whispe...</a></p><p>AEC inference: <a href="https://github.com/fastrepl/hyprnote/blob/main/crates/aec/src/lib.rs">https://github.com/fastrepl/hyprnote/blob/main/crates/aec/sr...</a></p><p>LLM inference: <a href="https://github.com/fastrepl/hyprnote/blob/main/crates/llama/src/lib.rs">https://github.com/fastrepl/hyprnote/blob/main/crates/llama/...</a></p><p>We also learned that for some folks, having full data controllability was as important as privacy. So we support custom endpoints, allowing users to bring in their company&#39;s internal LLM. For teams that need integrations, collaboration, or admin controls, we&#39;re working on an optional server component that can be self-hosted. Lastly, we&#39;re exploring ways to make Hyprnote work like VSCode, so you can install extensions and build your own workflows around your meetings.</p><p>We believe privacy-first tools, powered by local models, are going to unlock the next wave of real-world AI apps.</p><p>We&#39;re here and looking forward to your comments!</p></div></div></div>
  </body>
</html>
