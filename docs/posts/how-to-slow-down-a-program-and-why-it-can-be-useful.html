<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://stefan-marr.de/2025/08/how-to-slow-down-a-program/">Original</a>
    <h1>How to slow down a program and why it can be useful</h1>
    
    <div id="readability-page-1" class="page"><div itemprop="articleBody">
  <p>Most research on programming language performance asks a variation of a single question: how can we make some specific program faster?
Sometimes we may even investigate how we can use less memory.
This means a lot of research focuses solely on reducing the amount of resources needed to achieve some computational goal.</p>

<p>So, why on earth might we be interested in slowing down programs then?</p>

<h2 id="slowing-down-programs-is-surprisingly-useful">Slowing Down Programs is Surprisingly Useful!</h2>

<p>Making programs slower can be useful to find race conditions,
to simulate speedups, and to assess how accurate profilers are.</p>

<p>To detect race conditions,
we may want to use an approach similar to fuzzing.
Instead of exploring a program’s implementation
by varying its input,
we can explore different instruction interleavings, thread or event schedules,
by slowing down program parts to change timings.
This approach allows us to identify concurrency bugs
and is used by <a href="https://www.usenix.org/legacy/event/osdi08/tech/full_papers/musuvathi/musuvathi.pdf">CHESS</a>, <a href="https://people.cs.uchicago.edu/~shanlu/paper/eurosys23.pdf">WAFFLE</a>, and <a href="https://drops.dagstuhl.de/storage/00lipics/lipics-vol333-ecoop2025/LIPIcs.ECOOP.2025.9/LIPIcs.ECOOP.2025.9.pdf">NACD</a>.</p>

<p>The <a href="https://github.com/plasma-umass/coz">Coz profiler</a> is an example of how slowing down programs can be used to simulate speedup.
With Coz, we can estimate whether an optimization is beneficial
before implementing it.
Coz simulates it by slowing down <em>all other</em> program parts.
The part we think might be optimizable stays at the same speed
it was before, but is now <em>virtually sped up</em>, which allows us to see
whether it gives enough of a benefit to justify a perhaps lengthy optimization project.</p>

<p>And, as mentioned before, we can also use it to assess how accurate profilers are.
Though, I’ll leave this for the next blog posts. :)</p>

<p>The current approaches to slowing down programs for these use cases are
rather coarse-grained though. Race detection often adapts the scheduler or uses, for example, APIs such as <code>Thread.sleep()</code>.
Similarly, Coz pauses the execution of the other threads.
<a href="https://plv.colorado.edu/papers/mytkowicz-pldi10.pdf">Work</a> on measuring whether profilers give actionable results,
inserts bytecodes into Java programs to compute Fibonacci numbers.</p>

<p>By using more fine-grained slowdowns,
we think we could make race detection, speedup estimation, and profiler accuracy assessments more precise. Thus, we looked into inserting slowdown instructions into basic blocks.</p>

<h2 id="which-x86-instructions-allow-us-to-consistently-slow-down-basic-blocks">Which x86 Instructions Allow us to Consistently Slow Down Basic Blocks?</h2>

<p>Let’s assume we run on some x86 processor, and we are looking at programs
from the perspective of processors.</p>

<p>When running a benchmark like <a href="https://github.com/smarr/are-we-fast-yet/blob/master/benchmarks/Java/src/Towers.java#L74">Towers</a>,
the OpenJDK’s HotSpot JVM may compile it to x86 instructions like this:</p>

<figure><pre><code data-lang="nasm"><table><tbody><tr><td><pre>1
2
3
4
5
6
7
</pre></td><td><pre><span>mov</span> <span>dword</span> <span>ptr</span> <span>[</span><span>rsp</span><span>+</span><span>0x18</span><span>],</span> <span>r8d</span>
<span>mov</span> <span>dword</span> <span>ptr</span> <span>[</span><span>rsp</span><span>],</span> <span>ecx</span>
<span>mov</span> <span>qword</span> <span>ptr</span> <span>[</span><span>rsp</span><span>+</span><span>0x20</span><span>],</span> <span>rsi</span>
<span>mov</span> <span>ebx</span><span>,</span> <span>dword</span> <span>ptr</span> <span>[</span><span>rsi</span><span>+</span><span>0x10</span><span>]</span>
<span>mov</span> <span>r9d</span><span>,</span> <span>edx</span>
<span>cmp</span> <span>edx</span><span>,</span> <span>0x1</span>
<span>jnz</span> <span>0</span><span>x...</span> <span>&lt;</span><span>Bl</span><span>ock</span> <span>55</span><span>&gt;</span>	
</pre></td></tr></tbody></table></code></pre></figure>

<p>This is one of the basic blocks produced by HotSpot’s C2 compiler.
For our purposes, it suffices to see that there are some memory accesses
with the <code>mov</code> instructions, and we end up checking whether the <code>edx</code> register
contains the value 1. If that’s not the case, we jump to Block 55.
Otherwise, execution continues in the next basic block.
A key property of a basic block is that there’s no control flow inside of it,
which means once it starts executing, all of its instructions will execute.</p>

<p>Though, how can we slow it down?</p>

<p>x86 has many many different instructions one could try to insert into the block,
which each will probably consume CPU cycles.
However, modern CPUs try to execute as many instructions
as possible at the same time using out-of-order execution.
This means, instructions in our basic block
that do not directly depend on each other
might be executed at the same time.
For instance, the first three <code>mov</code> instructions access neither the same register
nor memory location. This means the order in which they are executed here does not matter.
Though, which optimizations CPUs apply depends on the program and the specific CPU generation,
or rather microarchitecture.</p>

<p>To find suitable instructions to slow down basic blocks,
we experimented only on an Intel Core i5-10600 CPU,
which has the <a href="https://en.wikipedia.org/wiki/Comet_Lake">Comet Lake-S microarchitecture</a>.
On other microarchitectures, things can be very different.</p>

<p>For the slowdown that we want, 
we can use <code>nop</code> or <code>mov regX, regX</code> instructions on Comet Lake-S.
This <code>mov</code> would move the value from register <code>X</code> to itself, so basically does nothing.
These two instructions give us a slowdown
that is small enough to slow down most blocks accurately to a desired target speed,
and the slowdown seems to affect only the specific block it is meant for.</p>

<p>Our basic block from earlier would then perhaps end up with <code>nop</code> instructions
interleaved after each instruction.
In practice, the number of instructions we need to insert
depends on how much time a basic block takes in the program.
Though, for illustration, it might look like this:</p>

<figure><pre><code data-lang="nasm"><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
10
11
12
13
</pre></td><td><pre><span>mov</span> <span>dword</span> <span>ptr</span> <span>[</span><span>rsp</span><span>+</span><span>0x18</span><span>],</span> <span>r8d</span>
<span>nop</span>
<span>mov</span> <span>dword</span> <span>ptr</span> <span>[</span><span>rsp</span><span>],</span> <span>ecx</span>
<span>nop</span>
<span>mov</span> <span>qword</span> <span>ptr</span> <span>[</span><span>rsp</span><span>+</span><span>0x20</span><span>],</span> <span>rsi</span>
<span>nop</span>
<span>mov</span> <span>ebx</span><span>,</span> <span>dword</span> <span>ptr</span> <span>[</span><span>rsi</span><span>+</span><span>0x10</span><span>]</span>
<span>nop</span>
<span>mov</span> <span>r9d</span><span>,</span> <span>edx</span>
<span>nop</span>
<span>cmp</span> <span>edx</span><span>,</span> <span>0x1</span>
<span>nop</span>
<span>jnz</span> <span>0</span><span>x...</span> <span>&lt;</span><span>Bl</span><span>ock</span> <span>55</span><span>&gt;</span>	
</pre></td></tr></tbody></table></code></pre></figure>

<p>We tried six different candidates, including a <code>push</code>-<code>pop</code> sequence, to get a better impression
of how Comet Lake-S deals with them.
For more details of how and what we tried, please have a look at our <a href="#paper">short paper below</a>, which we will present at the <a href="https://conf.researchr.org/home/icfp-splash-2025/vmil-2025#event-overview">VMIL workshop</a>.</p>

<p>When inserting these instructions into basic blocks,
so that each individual basic block
takes about twice as much time as before,
we end up with a program that indeed is overall twice as slow, as one would hope.
Even better, when we look at the Towers benchmark with the <a href="https://github.com/async-profiler/async-profiler">async-profiler</a> for HotSpot, and compare the proportions of run time it
attributes to each method, the slowed-down and the normal version
match almost perfectly, as <a href="#fig1">illustrated below</a>.
The same is not true for the other candidates we looked at.</p>

<figure id="fig1">
<img src="http://tinylogger.com/assets/2025/08/AsyncSlowdownVsNoSlowdownGrid.svg" height="300"/>
<figcaption><strong>Figure 1:</strong> A scatter plot per slowdown instruction with the median run-time percentage for the top six Java methods of Towers. The <em>X=Y</em> diagonal indicates that a method’s run‐time percentage remains the same with and without slowdown.</figcaption>
</figure>

<p>The paper has a few more details, including a more detailed analysis
of the slowdown each candidate introduces,
how precise the slowdown is for all basic blocks
in the benchmark, and whether it makes a difference when we put the slowdown
all at the beginning, interleaved, or at the end.</p>

<p>Of course, this work is merely a stepping stone to more interesting things,
which I will look at in a bit more detail in the next post.</p>

<p>Until then, the paper is linked below, and questions, pointers, and suggestions are welcome on 
<a href="https://mastodon.acm.org/@smarr/115100270023431067">Mastodon</a>,
<a href="https://bsky.app/profile/stefan-marr.de/post/3lxetckoyps2h">BlueSky</a>, or
<a href="https://x.com/smarr/status/1960650722170552800">Twitter</a>.</p>



<p><strong>Abstract</strong></p>

<blockquote>
  <p>Slowing down programs has surprisingly many use cases: it helps finding race conditions, enables speedup estimation, and allows us to assess a profiler’s accuracy. Yet, slowing down a program is complicated because today’s CPUs and runtime systems can optimize execution on the fly, making it challenging to preserve a program’s performance behavior to avoid introducing bias.</p>

<p>We evaluate six x86 instruction candidates for controlled and fine-grained slowdown including NOP, MOV, and PAUSE. We tested each candidate’s ability to achieve an overhead of 100%, to maintain the profiler-observable performance behavior, and whether slowdown placement within basic blocks influences results. On an Intel Core i5-10600, our experiments suggest that only NOP and MOV instructions are suitable. We believe these experiments can guide future research on advanced developer tooling that utilizes fine-granular slowdown at the machine-code level.</p>

</blockquote>

<ul>
  <li>Evaluating Candidate Instructions for Reliable Program Slowdown at the Compiler Level: Towards Supporting Fine-Grained Slowdown for Advanced Developer Tooling</li>

    <li>
      Paper:
        <a href="https://stefan-marr.de/downloads/vmil25-burchell-marr-evaluating-candidate-instructions-for-reliable-program-slowdown-at-the-compiler-level.pdf">
          PDF</a>
    </li>

    <li>
        DOI: <a href="https://doi.org/10.1145/3759548.3763374">10.1145/3759548.3763374</a>
    </li>

    


    <li>
      BibTex:
      <span tabindex="0"><span>bibtex</span>
      <pre>@inproceedings{Burchell:2025:SlowCandidates,
  abstract = {Slowing down programs has surprisingly many use cases: it helps finding race conditions, enables speedup estimation, and allows us to assess a profiler&#39;s accuracy. Yet, slowing down a program is complicated because today&#39;s CPUs and runtime systems can optimize execution on the fly, making it challenging to preserve a program&#39;s performance behavior to avoid introducing bias.
  
  We evaluate six x86 instruction candidates for controlled and fine-grained slowdown including NOP, MOV, and PAUSE. We tested each candidate’s ability to achieve an overhead of 100%, to maintain the profiler-observable performance behavior, and whether slowdown placement within basic blocks influences results. On an Intel Core i5-10600, our experiments suggest that only NOP and MOV instructions are suitable. We believe these experiments can guide future research on advanced developer tooling that utilizes fine-granular slowdown at the machine-code level.},
  author = {Burchell, Humphrey and Marr, Stefan},
  booktitle = {Proceedings of the 17th ACM SIGPLAN International Workshop on Virtual Machines and Intermediate Languages},
  doi = {10.1145/3759548.3763374},
  isbn = {979-8-4007-2164-9/2025/10},
  keywords = {Benchmarking HotSpot ISA Instructions Java MeMyPublication assembly evaluation myown slowdown x86},
  location = {Singapore},
  month = oct,
  pages = {8},
  pdf = {https://stefan-marr.de/downloads/vmil25-burchell-marr-evaluating-candidate-instructions-for-reliable-program-slowdown-at-the-compiler-level.pdf},
  publisher = {{ACM}},
  series = {VMIL&#39;25},
  title = {{Evaluating Candidate Instructions for Reliable Program Slowdown at the Compiler Level: Towards Supporting Fine-Grained Slowdown for Advanced Developer Tooling}},
  year = {2025},
  month_numeric = {10}
}
</pre>
      </span>
    </li>
</ul>


</div></div>
  </body>
</html>
