<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://dixken.de/blog/i-found-a-vulnerability-they-found-a-lawyer">Original</a>
    <h1>I found a Vulnerability. They found a Lawyer</h1>
    
    <div id="readability-page-1" class="page"><div><p>I&#39;m a diving instructor. I&#39;m also a platform engineer who spends lots of his time thinking about and implementing infrastructure security. Sometimes those two worlds collide in unexpected ways.</p>
<p><img src="https://dixken.de/images/blog/costa-rica.jpg" alt="A frigatebird perched on the boat railing next to a dive flag, somewhere off Cocos Island, Costa Rica"/>
<em>A Sula sula (Frigatebird) and a dive flag on the actual boat where I found the vulnerability - somewhere off Cocos Island.</em></p>
<hr/>
<p>While on a 14 day-long dive trip around Cocos Island in Costa Rica, I stumbled across a vulnerability in the member portal of a major diving insurer - one that I&#39;m personally insured through. What I found was so trivial, so fundamentally broken, that I genuinely couldn&#39;t believe it hadn&#39;t been exploited already.</p>
<p>I disclosed this vulnerability on <strong>April 28, 2025</strong> with a standard 30-day embargo period. That embargo expired on May 28, 2025 - over <strong>eight months ago</strong>. I waited this long to publish because I wanted to give the organization every reasonable opportunity to fully remediate the issue and notify affected users. The vulnerability has since been addressed, but to my knowledge, I have not received confirmation that affected users were notified. I have reached out to the organization to ask for clarification on this matter.</p>
<p>This is the story of what happened when I tried to do the right thing.</p>
<h2 id="the-vulnerability"><a href="#the-vulnerability">The Vulnerability</a></h2>
<p>To understand why this is so bad, you need to know how the registration process works. As a diving instructor, I register my students (to get them insured) through my account on the portal. I enter their personal information with their consent - name, date of birth, address, phone number, email - and the system creates an account for them. The student then receives an email with their new account credentials: a numeric user ID and a default password. They <em>might</em> log in to complete additional information, or they might never touch the portal again.</p>
<p>When I registered three students in quick succession, they were sitting right next to me and checked their welcome emails. The user IDs were nearly identical - sequential numbers, one after the other. That&#39;s when it clicked that something really bad was going on.</p>
<p>Now here&#39;s the problem: the portal used <strong>incrementing numeric user IDs</strong> for login. User XXXXXX0, XXXXXX1, XXXXXX2, and so on. That alone is a red flag, but it gets worse: every account was provisioned with a <strong>static default password</strong> that was never enforced to be changed on first login. And many users - especially students who had their accounts created <em>for</em> them by their instructors - never changed it.</p>
<p>So the &#34;authentication&#34; to access a user&#39;s full profile - name, address, phone number, email, date of birth - was:</p>
<ol>
<li>Guess a number.</li>
<li>Type the same default password that every account shares on account creation.</li>
<li>There&#39;s a good chance you get in.</li>
</ol>
<p>That&#39;s it. No rate limiting. No account lockout. No MFA. Just an incrementing integer and a password that might as well have been <code>password123</code>.</p>
<p>I verified the issue with the minimum access necessary to confirm the scope - and stopped immediately after.</p>
<h2 id="the-disclosure"><a href="#the-disclosure">The Disclosure</a></h2>
<p>I did everything by the book. I contacted <strong>CSIRT Malta</strong> (MaltaCIP) first - since the organization is registered in Malta, this is the competent national authority. The Maltese <a href="https://mdia.gov.mt/app/uploads/2024/12/P-SPG-001-National-Coordinated-Vulnerability-Disclosure-Policy.pdf">National Coordinated Vulnerability Disclosure Policy (NCVDP)</a> explicitly requires that confirmed vulnerabilities be reported to both the responsible organization <em>and</em> CSIRTMalta.</p>
<p>Then I emailed the organisation directly, CC&#39;ing CSIRT:</p>
<blockquote>
<p>Dear Sir or Madam,</p>
<p>As a fellow diving instructor insured through [the organization] and a full-time Linux Platform Engineer, I am contacting you to responsibly disclose a critical vulnerability I identified within the [the organization]&#39;s user account system.</p>
<p>During recent testing, I discovered that user accounts - including those of underage students - are accessible through a combination of predictable User ID enumeration (incrementing user IDs) and the use of a static default password that is not enforced to be changed upon first login. This misconfiguration currently exposes sensitive personal data (e.g., names, addresses, contact information - including phone numbers and emails -, dates of birth) and represents multiple GDPR violations.</p>
<p>Key details:</p>
<ul>
<li>Password reuse across accounts without forced password reset</li>
<li>Predictable, incremental user ID enumeration</li>
<li>Exposure of sensitive and underage user data without adequate safeguards</li>
</ul>
<p>For initial confirmation, I am attaching a screenshot from Member ID XXXXXXX showing the exposed data, partly redacted for privacy reasons.</p>
<p>Additionally, for transparency and validation, I have shared my proof-of-concept code securely via an encrypted paste service: [link redacted]</p>
<p>In the spirit of responsible disclosure, I have already informed CSIRT Malta (in CC) to officially initiate a reporting process, given [the organization]&#39;s operational presence in Malta.</p>
<p>I kindly request that [the organization] acknowledges receipt of this disclosure within 7 days.</p>
<p>I am offering a window of 30 days from today the 28th of April 2025 for [the organization] to mitigate or resolve the vulnerability before I consider any public disclosure.</p>
<p>Please note that I am fully available to assist your IT team with technical details, verification steps and recommendations from a security perspective.</p>
<p>[contact details]</p>
<p>I strongly recommend assigning an IT-Security Point of Contact (PoC) for direct collaboration on this issue.</p>
<p>Thank you very much for your attention to this critical matter. I am looking forward to working with you towards a secure resolution.</p>
</blockquote>
<p>Both of these timelines are standard - if anything, generous - in responsible disclosure frameworks.</p>
<h2 id="the-response"><a href="#the-response">The Response</a></h2>
<p>Two days later, I got a reply. Not from their IT team. From their <strong>Data Privacy Officers (DPO&#39;s) law firm</strong>.</p>
<p>The letter opened politely enough - they acknowledged the issue and said they&#39;d launched an investigation. They even mentioned they were resetting default passwords and planning to roll out 2FA. Good.</p>
<p>But then the tone shifted:</p>
<blockquote>
<p>While we genuinely appreciate your seemingly good intentions and transparency in highlighting this matter to our attention, we must respectfully note that notifying the authorities prior to contacting the Group creates additional complexities in how the matter is perceived and addressed and also exposes us to unfair liability.</p>
</blockquote>
<p>Let me translate: <em>&#34;We wish you hadn&#39;t told the government about our security issue.&#34;</em></p>
<p>It got better:</p>
<blockquote>
<p>We also do not appreciate your threat to make this matter public [...] and remind you that you may be held accountable for any damage we, or the data subjects, may suffer as a result of your own actions, which actions likely constitute a criminal offence under Maltese law.</p>
</blockquote>
<p>So, to be clear: their portal had a default password on every account, exposing personal data including that of children, and <em>I&#39;m</em> the one who &#34;likely&#34; committed a criminal offence by finding it and telling them.</p>
<p>They also sent a <strong>declaration</strong> they wanted me to sign - while requesting my passport ID - confirming I&#39;d deleted all data, wouldn&#39;t disclose anything, and would keep the entire matter &#34;strictly confidential.&#34; The deadline? <strong>End of business the same day they sent it.</strong></p>
<p>This declaration included the following gem:</p>
<blockquote>
<p>I also declare that I shall keep the content of this declaration strictly confidential.</p>
</blockquote>
<p>That&#39;s an NDA with extra steps: I was being asked to sign away my right to discuss the disclosure process itself - including the fact that I found a vulnerability in their system - under threat of legal action.</p>
<p>Then came the reminders. One &#34;friendly&#34; reminder. Then an &#34;urgent&#34; one. Sign the declaration. De-escalate. Move on. Quietly.</p>
<h2 id="the-pushback"><a href="#the-pushback">The Pushback</a></h2>
<p>I generally refuse to sign confidentiality clauses in cases involving exposure of sensitive information, and I did so here as well. Coordinated disclosure depends on transparency and trust between researchers and organizations: trust that affected users will be informed, and trust that a report leads to real remediation.</p>
<p>Given that the organization in question had already breached that trust by exposing personal data through weak controls, I wasn’t willing to grant blanket confidentiality that could be used to keep the incident out of public scrutiny. And with trying to actual silence me through legal threats, they had already made it clear that their priority was <strong>reputation management over user data protection.</strong> So I stood my ground.</p>
<p>Instead, I offered to sign a modified declaration confirming data deletion. I had no interest in retaining anyone’s personal data, but I was not going to agree to silence about the disclosure process itself.</p>
<p>I also pointed out that, under Malta’s NCVDP, involving CSIRT Malta is part of the expected reporting path - not a hostile act - and that publishing post-remediation analyses is standard practice in the security community.</p>
<p><strong>Their response doubled down.</strong> They cited Article 337E of the Maltese Criminal Code - computer misuse - and helpfully reminded me that:</p>
<blockquote>
<p>Art. 337E of the Criminal Code also provides that &#34;If any act is committed outside Malta which, had it been committed in Malta, would have constituted an offence [...] it shall [...] be deemed to have been committed in Malta.&#34; Meaning that your actions would be deemed a criminal offence in Malta, even if committed in another country.</p>
</blockquote>
<p>They also made their position on disclosure crystal clear, after I reiterated my refusal to sign their NDA:</p>
<blockquote>
<p>We object strongly to the use of [the organization&#39;s name] in any such blogs or conferences you may write/attend as this would be a disproportionate harm to [the organization&#39;s] reputation [...]. We reserve our rights at law to hold you responsible for any damages [the organization] may suffer as a result of any such public disclosures you may make.</p>
</blockquote>
<p>That&#39;s fine by me. Because here&#39;s the thing: <strong>The vulnerability has been fixed.</strong> Default passwords have been reset. 2FA is being rolled out. I feel sorry for the developer(s) who had to clean up this mess, but at least the issue is no longer exploitable. Sure, it would have been better if the organization had thanked me and taken responsibility for notifying affected users. If the incident qualified as a personal data breach (which it does) and was likely to result in a (high) risk to individuals - especially given minors were involved - GDPR Articles 33 and 34 generally <strong>require notification to the supervisory authority and communication to affected data subjects</strong>.</p>
<blockquote>
<p>GDPR Article 34(1) When the personal data breach is likely to result in a high risk to the rights and freedoms of natural persons, the controller shall communicate the personal data breach to the data subject without undue delay.</p>
</blockquote>
<blockquote>
<p>GDPR Article 34(2) The communication to the data subject referred to in paragraph 1 of this Article shall describe in clear and plain language the nature of the personal data breach and contain at least the information and measures referred to in points (b), (c) and (d) of Article 33(3).</p>
</blockquote>
<p>I have not received confirmation that those notifications were ever carried out.</p>
<h2 id="the-blame-game"><a href="#the-blame-game">The Blame Game</a></h2>
<p>My favourite part was the organization&#39;s position on whose fault this actually was:</p>
<blockquote>
<p>We contend that it is the responsibility of users to change their own password (after we allocate a default one).</p>
</blockquote>
<p>Read that again. A company that assigned <em>the same default password</em> to every account, never forced a password change, and used incrementing numeric IDs as usernames is blaming <strong>the users</strong> for not securing their own accounts. Accounts that include those of minors.</p>
<p>Just a quick reminder:</p>
<blockquote>
<p>GDPR Article 5(1)(f) (integrity and confidentiality): Personal data shall be processed in a manner that ensures appropriate security of the personal data, including protection against unauthorised or unlawful processing and against accidental loss, destruction or damage, using appropriate technical or organisational measures.</p>
</blockquote>
<p>Under GDPR, the <strong>data controller</strong> (namely: the organization) is responsible for implementing appropriate technical and organizational measures to ensure data security. A static default password on an IDOR-vulnerable portal is not an &#34;appropriate measure&#34; by any definition.</p>
<blockquote>
<p>GDPR Article 24(1) (controller responsibility): Taking into account the nature, scope, context and purposes of processing as well as the risks of varying likelihood and severity for the rights and freedoms of natural persons, the controller shall implement appropriate technical and organisational measures to ensure and to be able to demonstrate that processing is performed in accordance with this Regulation. Those measures shall be reviewed and updated where necessary.</p>
</blockquote>
<h2 id="the-pattern"><a href="#the-pattern">The Pattern</a></h2>
<p>This isn&#39;t an isolated case. The security research community has been dealing with this pattern for decades: find a vulnerability, report it responsibly, get threatened with legal action. It&#39;s so common it has a name - the <a href="https://en.wikipedia.org/wiki/Chilling_effect">chilling effect</a>.</p>
<p>Organizations that respond to disclosure with lawyers instead of engineers are telling the world something important: they care more about their reputation than about the data they&#39;re supposed to protect.</p>
<p>And the real irony? <strong>The legal threats are the reputation damage. Not the vulnerability itself</strong> - vulnerabilities happen to everyone. It&#39;s the response that tells you everything about an organization&#39;s security culture.</p>
<h2 id="what-should-have-happened"><a href="#what-should-have-happened">What Should Have Happened</a></h2>
<ol>
<li><strong>Acknowledge the report</strong> - they did this, to be fair.</li>
<li><strong>Fix the vulnerability</strong> - they started on this too.</li>
<li><strong>Thank the researcher</strong> - instead of threatening them with criminal prosecution.</li>
<li><strong>Have a CVD policy</strong> - so researchers know how to report issues and what to expect.</li>
<li><strong>Notify affected users</strong> - especially the parents of underage members whose data was exposed.</li>
<li><strong>Not try to silence the researcher</strong> with NDAs disguised as &#34;declarations.&#34;</li>
</ol>
<h2 id="what-you-can-do"><a href="#what-you-can-do">What You Can Do</a></h2>
<p>If you&#39;re an organization:</p>
<ul>
<li><strong>Publish a Coordinated Vulnerability Disclosure policy.</strong> It doesn&#39;t have to be complex - maybe begin with a <a href="https://securitytxt.org/">security.txt</a> file and a clear process that favors transparency.</li>
<li><strong>Thank researchers</strong> for helping you improve your security posture.</li>
<li><strong>Don&#39;t shoot the messenger.</strong> The person reporting the bug is not your enemy. The bug is.</li>
<li><strong>Don&#39;t blame your users</strong> for security failures that are your responsibility as a data controller.</li>
</ul>
<p>If you&#39;re a security researcher:</p>
<ul>
<li><strong>Always involve your national CSIRT.</strong> It protects you and creates an official record.</li>
<li><strong>Document everything.</strong> Every email, every timestamp, every response.</li>
<li><strong>Don&#39;t sign NDAs</strong> that prevent you from discussing the disclosure process. But you can agree to delete data (and MUST do so!) without agreeing to silence.</li>
<li><strong>Know your rights.</strong> Many jurisdictions have legal protections for good-faith security research. The EU&#39;s NIS2 Directive encourages coordinated vulnerability disclosure.</li>
</ul>
<p>Because right now, in 2026, reporting a trivial vulnerability exposing personal data - including that of children - still gets met with legal threats instead of gratitude. <strong>And that&#39;s a problem for all of us.</strong></p></div></div>
  </body>
</html>
