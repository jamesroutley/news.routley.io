<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.usenix.org/publications/loginonline/transcending-posix-end-era">Original</a>
    <h1>Transcending Posix: The End of an Era?</h1>
    
    <div id="readability-page-1" class="page"><div><div><div><p>POSIX’s abstractions – processes, filesystems, virtual memory, sockets, and threads – are based on the OS abstractions of the different Unix variants in development between the 1970s and 1980s, such as Research Unix, System V, BSD, SunOS, and others.</p><p>The use cases and hardware capabilities of their respective era influenced the abstractions. For example, early Unix ran on a PDP-11/20, a 16-bit computer with a single CPU and up to 248KB of main memory <a href="#reference-6" rel="nofollow">[6]</a>. As the PDP-11/20 lacked memory protection, Unix did not support virtual memory, unlike contemporary OSes of the time such as Multics. Although later PDP-11 variants, such as the PDP-11/70, had a memory mapping unit (MMU) <a href="#reference-7" rel="nofollow">[7]</a>, virtual memory was not added to Unix until the emergence of the VAX architecture in the late 1970s <a href="#reference-4" rel="nofollow">[4]</a>, which became the primary architecture for Unix at the time. Similarly, Unix did not have a networking abstraction until the emergence of the Internet in the early 1980s, when 4.2BSD introduced the sockets abstraction for remote inter-process communication to abstract TCP/IP networking protocols. Likewise, Unix did not have a thread abstraction until the early 1990s, when multiprocessor machines became more mainstream <a href="#reference-8" rel="nofollow">[8]</a>.</p><h4>Filesystem</h4><p>A <em>filesystem</em> is an abstraction to access and organize bytes of data on a storage device. This abstraction and its I/O interface largely originate from Multics<a href="#reference-9" rel="nofollow"> [9]</a>, and it was considered the most important abstraction in Unix <a href="#reference-2" rel="nofollow">[2]</a>,<a href="#reference-10" rel="nofollow"> [10]</a>. However, unlike Unix, which supported only synchronous I/O, Multics also supported asynchronous I/O <a href="#reference-11" rel="nofollow">[11]</a>, <a href="#reference-12" rel="nofollow">[12]</a>, a feature that would eventually be part of POSIX.</p><p>The filesystem abstraction also includes files, directories, special files [2], and hard and symbolic links <a href="#reference-13" rel="nofollow">[13]</a>. A file in a filesystem is a sequence of bytes that the OS does not interpret in any way [2]. This enables OSes to represent hardware devices as special files, and the interfaces to operate on files have become the defacto interfaces for I/O devices.</p><p>The filesystem abstraction enables easy integration of I/O devices. However, it can become a bottleneck for fast I/O devices <a href="#reference-14" rel="nofollow">[14]</a>,<a href="#reference-15" rel="nofollow"> [15]</a>, <a href="#reference-16" rel="nofollow">[16]</a>, <a href="#reference-17" rel="nofollow">[17]</a>.</p><h4>Processes</h4><p>A <em>process</em> is an abstraction for the execution of an application in a system. Specifically, the application is represented as an <em>image</em> that abstracts its execution environment comprising of, among others, the program code (<em>text</em>), processor register values, and open files <a href="#reference-2" rel="nofollow">[2]</a>. This image is stored in the filesystem, and the OS ensures that the executing part of the process image resides in memory. The process abstraction has been around since early Unix <a href="#reference-2" rel="nofollow">[2]</a>, and it has become vital for time-sharing of computing and I/O resources.</p><p>This abstraction has its roots in multi-programming which was a technique developed in the mid-1950’s to improve hardware utilization while performing I/O<a href="#reference-18" rel="nofollow"> [18]</a>. Early Unix running on the PDP-7 supported only two processes, one for each terminal attached to the machine<a href="#reference-19" rel="nofollow"> [19]</a>; later versions of Unix that were designed to run on the PDP-11 could keep multiple processes in memory.</p><p><span>A process is a processor-centric abstraction that is extremely useful for applications built with the assumption that the execution of the process image is done only on the CPUs. However, the prevalence of hardware devices such as graphics processing units (GPUs), tensor processing units (TPUs), and various other special-purpose accelerators for offloading computation are challenging this assumption.</span></p><h4>Virtual memory</h4><p>Virtual memory is an abstraction that creates an illusion of a memory space that is as large as the storage space <a href="#reference-20" rel="nofollow">[20]</a>. It emerged from the need to automatically take advantage of the speed of the main memory and cheap storage capacity. The concept of virtual memory dates back to the early 1960s: page-based virtual memory was first introduced in 1962 in the Atlas Supervisor <a href="#reference-21" rel="nofollow">[21]</a>, and Multics also supported virtual memory<a href="#reference-22" rel="nofollow"> [22]</a>.</p><p>Virtual memory was added to Unix in the late 1970s, almost a decade after its inception. At its inception, the Unix process address space was divided into three segments: a program text (code) segment that was shared between all processes but not writable, a process data segment that was read/write but private, and a stack segment. The sbrk system call could grow and shrink the process data segment. However, motivated by the need to run programs that required more storage than the main memory capacity at the time (e.g., Lisp), the MMU in the VAX-11 architecture made paging-based virtual memory possible <a href="#reference-4" rel="nofollow">[4]</a>, <a href="#reference-23" rel="nofollow">[23]</a>.</p><p>This abstraction decouples two related two concepts: <em>address space</em>, i.e., the identifiers to address memory, and <em>memory space</em>, i.e., the physical locations to store data. Historically, this decoupling had three main objectives: (1) promote <em>machine independence</em> with an address space that is independent of the physical memory space, (2) promote <em>modularity</em> by allowing programmers to compose programs from independent modules that are linked together at execution time, and (3) make it possible to run<em> large programs</em> that would not fit in the physical memory (e.g., Lisp programs). Other benefits of virtual memory include running programs of arbitrary size, running partially loaded programs, and changing memory configuration without recompiling programs. Virtual memory is considered to be a fundamental operating system abstraction, but current hardware and application trends are challenging its core assumptions.</p><h4><span>Inter-process communication (IPC)</span></h4><p><span>Abstractions for inter-process communication enable one or more processes to interact with each other. Early versions of Unix supported signals and pipes <a href="#reference-2" rel="nofollow">[2]</a>. Signals enabled programmers to programmatically handle hardware faults, and this mechanism was generalized to allow a process to notify other processes. For instance, a shell process can use signals to stop processes. Pipes are special files that allow processes to exchange data with each other. Pipes do not allow arbitrary processes to exchange data, because a pipe between two processes must be set up by their common ancestor.</span></p><p>With the limitations of pipes and signals, sockets were added to BSD to provide a uniform IPC mechanism for both local and remote processes, i.e., processes running on different host machines. Sockets have become the standard way of networking, however they are not as widely used as platform-specific IPC mechanisms for local IPC <a href="#reference-24" rel="nofollow">[24]</a>.</p><p>The mmap interface for shared memory was envisioned as a IPC mechanism<a href="#reference-25" rel="nofollow"> [25]</a>,<a href="#reference-26" rel="nofollow"> [26]</a>, but never quite caught on. Additional IPC mechanisms (semaphores, IPC-specific interface for shared memory, and message queues) were added in POSIX.1b, released in 1993, but have since then been largely replaced by vendor-specific IPC mechanisms <a href="#reference-24" rel="nofollow">[24]</a>.</p><h4>Threads and Asynchronous I/O</h4><p>Threads and asynchronous I/O are the latecomer abstractions in POSIX for addressing the demands for parallelism and concurrency.</p><p>The traditional UNIX process offered a single thread of execution. This inability to support concurrent threads of execution makes a single UNIX process unfit for exploiting the parallelism offered by multiple computing cores. One way to exploit the parallelism is to fork multiple processes but this requires the forked processes to communicate with each other using IPC mechanisms, which are in turn inefficient.</p><p>The POSIX asynchronous I/O (AIO) interface was designed to address this growing demand for a non-blocking I/O interface that can be leveraged to improve concurrency. This interface enables processes to invoke I/O operations that are performed asynchronously. However, it can block under various circumstances, and it requires at least two system calls per I/O: one to submit a request, and the other to wait for its completion.</p><p>In POSIX, threads emerged in the early 1990s from the need to support parallelism of multicore hardware and enable application-level concurrency<a href="#reference-8" rel="nofollow"> [8]</a>,<a href="#reference-27" rel="nofollow"> [27]</a>. Unlike processes, threads run in the same address space. POSIX threads can be implemented in different ways; <em>1-on-1</em>: Every thread runs in their own kernel thread;<em> N-on-1</em>: All threads run in a single kernel thread; and <em>N-on-M</em>: N threads runs in M kernel threads <a href="#reference-27" rel="nofollow">[27]</a>, <a href="#reference-28" rel="nofollow">[28]</a>, <a href="#reference-29" rel="nofollow">[29]</a>. Managing parallelism in user space is essential for high performance<a href="#reference-27" rel="nofollow"> [27]</a>. However, mainstream POSIX OSes settled on the 1-on-1 threading model, citing simplicity of implementation <a href="#reference-30" rel="nofollow">[30]</a>, <a href="#reference-31" rel="nofollow">[31]</a>. Regardless, application architectures that use a large number of threads, such as the staged event-driven architecture (SEDA)<a href="#reference-32" rel="nofollow"> [32]</a>, are inefficient because of thread overheads<a href="#reference-33" rel="nofollow"> [33]</a>. Many high-performance applications are therefore adopting a thread-per-core model where the number of threads equals the number of processing cores, and providing their own interfaces for concurrency <a href="#reference-34" rel="nofollow">[34]</a>, <a href="#reference-35" rel="nofollow">[35]</a>.</p></div></div></div></div>
  </body>
</html>
