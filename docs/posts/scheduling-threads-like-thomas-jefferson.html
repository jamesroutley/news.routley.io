<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://stevana.github.io/scheduling_threads_like_thomas_jefferson.html">Original</a>
    <h1>Scheduling threads like Thomas Jefferson</h1>
    
    <div id="readability-page-1" class="page"><div>

<nav id="TOC" role="doc-toc">
<h2 id="toc-title">Table of contents</h2>
<ul>
<li><a href="#background-and-motivation" id="toc-background-and-motivation">Background and motivation</a></li>
<li><a href="#inspiration-and-prior-work" id="toc-inspiration-and-prior-work">Inspiration and prior work</a></li>
<li><a href="#big-picture" id="toc-big-picture">Big picture</a></li>
<li><a href="#prototype-implementation" id="toc-prototype-implementation">Prototype implementation</a></li>
<li><a href="#running-the-prototype" id="toc-running-the-prototype">Running the prototype</a></li>
<li><a href="#unexpected-connection-to-thomas-jefferson" id="toc-unexpected-connection-to-thomas-jefferson">Unexpected connection
to Thomas Jefferson</a></li>
<li><a href="#conclusion-and-future-work" id="toc-conclusion-and-future-work">Conclusion and future work</a></li>
</ul>
</nav>
<p>Posted on Sep 24, 2024</p>
<p>This post is about how to schedule workers across a pipeline of
queues in order to minimise total processing time, and an unexpected
connection between this kind of scheduling and Thomas Jefferson.</p>
<section id="background-and-motivation">
<h2><a href="#background-and-motivation" title="Background and motivation">Background and motivation</a></h2>
<p>You know how assembly lines in manufacturing and instruction
pipelines in CPUs give a form of parallelism, without breaking
determinism (the order of inputs to the pipeline is preserved in the
outputs)?</p>
<p>We’ll call this implicit parallelism via pipelining. Implicit,
because by merely splitting the task at hand up in stages, we get
parallelism for free. When this technique is applied to software, it
allows us to write purely sequential programs (for each stage), while
still utilising our parallel hardware.</p>
<p>The way it works is that each stage runs independently (one CPU/core)
and the stages are connected via queues, so when the first CPU/core is
done with the first stage of the first item, it passes it on to the
second stage while continuing to work at the first stage of the second
item. As the queues between the stages saturate we get parallelism while
retaining determinism (the outputs arrive in the same order as the
inputs).</p>
<p>Here’s a picture of a bottle factory manufacturing pipeline:</p>
<p><img src="https://raw.githubusercontent.com/stevana/scheduled-pipelines/main/images/bottling-factory.png"/></p>
<p>Each stage is connected by conveyor belts (queues) and runs in
parallel with the other, e.g. after as the first bottle has been filled,
the second can be filled while at the same time the first bottle is
being capped, etc.</p>
<p>If a stage is slow, then an input queue to the stage can be
partitioned or sharded by adding another worker to that stage sending
every other input to the newly added worker, thereby effectively nearly
doubling the throughput.</p>
<p>In this post I’d like to discuss the following question: what’s the
best way to allocate CPUs/cores among the stages? For example, if we
only have two CPUs/cores, but three stages, then it doesn’t make any
sense to allocate one of them to the last stage until at least some
items has been processed at the second stage.</p>
<p>First I’d like to develop a library to test out these concepts, but
longer term I’d like to make a programming language which uses these
concepts to try see if we can make something that scales well as more
CPUs/cores are available.</p>
</section>
<section id="inspiration-and-prior-work">
<h2><a href="#inspiration-and-prior-work" title="Inspiration and prior work">Inspiration and prior work</a></h2>
<p>While there are examples of pipelining in manufacturing that pre-date
Henry Ford, it seems that’s when it took off and become a common place.
Wikipedia <a href="https://en.wikipedia.org/wiki/Assembly_line#20th_century">says</a>:</p>
<blockquote>
<p>“The assembly line, driven by conveyor belts, reduced production time
for a Model T to just 93 minutes by dividing the process into 45 steps.
Producing cars quicker than paint of the day could dry, it had an
immense influence on the world.”</p>
</blockquote>
<p>For comparison, it <a href="https://en.wikipedia.org/wiki/Ford_Model_T#Mass_production">apparently</a>
took 12.5h before the assembly line.</p>
<p>CPUs are another example where pipelining is used, with the intent of
speeding up the processing of instructions. A pipeline might look like:
fetch the instruction, fetch the operands, do the instruction, and
finally write the results.</p>
<p>Given this tremendous success in both manufacturing and hardware one
could expect that perhaps it’s worth doing in software as well? For
reasons not entirely clear to me, it hasn’t seem to have taken off yet,
but there are proponents of this idea.</p>
<p>Jim Gray talked about software pipeline parallelism and partitioning
in his Turing award <a href="https://www.youtube.com/watch?v=U3eo49nVxcA&amp;t=1949s">interview</a>.
<a href="https://en.wikipedia.org/wiki/Dataflow_programming">Dataflow
languages</a> in general and Paul Morrison’s <a href="https://jpaulm.github.io/fbp/index.html">flow-based
programming</a> in particular exploit this idea. The <a href="https://lmax-exchange.github.io/disruptor/disruptor.html">LMAX
Disruptor</a> pattern is also based on pipelining parallelism and
supports, what Jim calls, partition parallelism. One of the sources that
the Disruptor paper mentions is <a href="https://people.eecs.berkeley.edu/~brewer/papers/SEDA-sosp.pdf"><em>SEDA:
An Architecture for Well-Conditioned, Scalable Internet
Services</em></a> (2001), which also talk about pipelines and
dynamically allocating threads to the stages. More recently, as I was
digging into more of Jim’s <a href="https://jimgray.azurewebsites.net/papers/CacmParallelDB.pdf">work</a>,
I discovered that database engines also implement something akin to
pipeline parallelism. For a more recent example of database engines that
use this technique, see the paper on Umbra’s <a href="https://db.in.tum.de/~leis/papers/morsels.pdf">morsel-driven
parallelism</a> (2014).</p>
<p>These are the examples of software pipeline parallelism that inspired
me to start thinking about it. However it wasn’t until I read Martin
Thompson, one of the people behind the LMAX Disruptor, say the
following:</p>
<blockquote>
<p>“If there’s one thing I’d say to the Erlang folks, it’s you got the
stuff right from a high-level, but you need to invest in your messaging
infrastructure so it’s super fast, super efficient and obeys all the
right properties to let this stuff work really well.”</p>
</blockquote>
<p>Together with hearing Joe Armstrong’s <a href="https://youtu.be/bo5WL5IQAd0?t=2494">anecdote</a> of an unmodified
Erlang program only running 33 times faster on a 64 core machine, rather
than 64 times faster as per the Ericsson higher-up’s expectations, that
I started thinking about how a programming language can be designed to
make it easier to do pipelining in software.</p>
<p>I started exploring this topic in <a href="https://stevana.github.io/pipelined_state_machines.html">two</a>
of my <a href="https://stevana.github.io/parallel_stream_processing_with_zero-copy_fan-out_and_sharding.html">previous</a>
posts, and I’ve also written about elastically scaling a single stage up
and down <a href="https://stevana.github.io/elastically_scalable_thread_pools.html">before</a>,
but here we’ll take a more global approach.</p>
</section>
<section id="big-picture">
<h2><a href="#big-picture" title="Big picture">Big picture</a></h2>
<p>The system consists of three parts: the pipeline, the workers and the
scheduler:</p>
<p><img src="https://raw.githubusercontent.com/stevana/scheduled-pipelines/main/images/system-context.png"/></p>
<p>The scheduler monitors the pipeline, looking at how long the input
queues for each stage is and what the average service time per input of
that stage is. By doing so it calculate where to schedule the available
workers.</p>
<p>The algorithm to allocate the available workers works as follows:</p>
<ol type="1">
<li>Generate all possible configurations of allocating workers across
the stages;</li>
<li>Score each configuration using the formula: <span>\(\sum_{s}\frac{l_{s} \cdot t_{s}}{w_{s} +
1}\)</span>, where <span>\(s\)</span> is a stage,
<span>\(l_{s}\)</span> is the input queue length of
the stage <span>\(s\)</span>, <span>\(t_{s}\)</span> is the average service time of the
stage <span>\(s\)</span> and <span>\(w_{s}\)</span> is the amount of workers allocated
to the stage <span>\(s\)</span>;</li>
<li>Pick the configuration with the lowest score, i.e. the one where the
total processing time is the lowest.</li>
</ol>
<p>The workers, typically one per available CPU/core, process a batch of
inputs at the stage the scheduler instructs them to and then report back
to the scheduler, and so the process repeats until the end of the stream
of inputs.</p>
<p>If we zoom in on the pipeline, we see that it consists of a source, N
stages and a sink:</p>
<p><img src="https://raw.githubusercontent.com/stevana/scheduled-pipelines/main/images/container-pipeline.png"/></p>
<p>The source can be a file, network socket, a user provided lists of
items, etc, from which the inputs to the queue of the first stage are
created. The inputs can be length-prefixed raw bytes, or
newline-separated bytes, etc. Similarly the sink can also be a file, or
standard out, or a socket. While in between the source and the sink is
where the interesting processing happens in stages.</p>
</section>
<section id="prototype-implementation">
<h2><a href="#prototype-implementation" title="Prototype implementation">Prototype implementation</a></h2>
<p>From the above picture, I hope that it’s clear that most of the code
is plumbing (connecting the components with queues). The most
interesting aspect of the code is: when a worker is done, how does the
scheduler figure out what it shall tell it to do next? So let’s focus on
that.</p>
<p>We start off by representing what a configuration of workers across a
pipeline looks like. Each stage has a name, or identifier, and so a
configuration can be represented as a map from the stage identifier to
the number of workers assigned to that stage:</p>
<div id="cb1"><pre><code><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span>newtype</span> <span>Config</span> <span>=</span> <span>Config</span> (<span>Map</span> <span>StageId</span> <span>NumOfWorkers</span>)</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  <span>deriving</span> <span>Show</span></span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a><span>type</span> <span>NumOfWorkers</span> <span>=</span> <span>Int</span></span></code></pre></div>
<p>The initial configuration is that all stages have zero workers
assigned to it:</p>
<div id="cb2"><pre><code><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a><span>initConfig ::</span> [<span>StageId</span>] <span>-&gt;</span> <span>Config</span></span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a>initConfig stageIds <span>=</span></span>
<span id="cb2-3"><a href="#cb2-3" aria-hidden="true" tabindex="-1"></a>  <span>Config</span> (Map.fromList (<span>zip</span> stageIds (<span>replicate</span> (<span>length</span> stageIds) <span>0</span>)))</span></code></pre></div>
<p>The implementation for allocating workers starts by generating all
possible configurations, filters away configurations which allocate
workers to stages that are done (where done means that no further inputs
will arrive to that stage), scores all the configurations and picks the
one with the lowest score:</p>
<div id="cb3"><pre><code><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span>allocateWorkers ::</span> <span>Int</span> <span>-&gt;</span> <span>Map</span> <span>StageId</span> <span>QueueStats</span> <span>-&gt;</span> <span>Set</span> <span>StageId</span> <span>-&gt;</span> <span>Maybe</span> <span>Config</span></span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a>allocateWorkers cpus qstats done <span>=</span> <span>case</span> result <span>of</span></span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a>  []                <span>-&gt;</span> <span>Nothing</span></span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a>  (cfg, _score) <span>:</span> _ <span>-&gt;</span> <span>Just</span> cfg</span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a>  <span>where</span></span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    result <span>=</span> sortBy (comparing <span>snd</span>)</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>               [ (cfg, <span>sum</span> (Map.elems (scores qstats cfg)))</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>               <span>|</span> cfg <span>&lt;-</span> possibleConfigs cpus (Map.keys qstats)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a>               , <span>not</span> (allocatesDoneStages cfg done)</span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>               ]</span></code></pre></div>
<p>All possible configurations are generated as follows:</p>
<div id="cb4"><pre><code><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span>possibleConfigs ::</span> <span>Int</span> <span>-&gt;</span> [<span>StageId</span>] <span>-&gt;</span> [<span>Config</span>]</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a>possibleConfigs cpus stages <span>=</span> <span>map</span> (<span>Config</span> <span>.</span> Map.fromList <span>.</span> <span>zip</span> stages) <span>$</span> <span>filter</span> ((<span>==</span> cpus) <span>.</span> <span>sum</span>)</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a>  [ foldl&#39; (\ih i <span>-&gt;</span> update i <span>succ</span> ih) (<span>replicate</span> (<span>length</span> stages) <span>0</span>) slot</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a>  <span>|</span> choice <span>&lt;-</span> combinations [<span>0</span><span>..</span> (cpus <span>+</span> <span>length</span> stages <span>-</span> <span>1</span>)] cpus</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a>  , <span>let</span> slot <span>=</span> [ c <span>-</span> i <span>|</span> (i, c) <span>&lt;-</span> <span>zip</span> [<span>0</span><span>..</span> ] choice ]</span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>  ]</span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>  <span>where</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a><span>    combinations ::</span> [a] <span>-&gt;</span> <span>Int</span> <span>-&gt;</span> [[a]]</span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    combinations xs n <span>=</span> <span>filter</span> ((<span>==</span> n) <span>.</span> <span>length</span>) (subsequences xs)</span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    <span>-- update i f xs = xs[i] := f (xs[i])</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a><span>    update ::</span> <span>Int</span> <span>-&gt;</span> (a <span>-&gt;</span> a) <span>-&gt;</span> [a] <span>-&gt;</span> [a]</span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    update i f <span>=</span> go [] i</span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a>      <span>where</span></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a>        go acc _ []       <span>=</span> <span>reverse</span> acc</span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a>        go acc <span>0</span> (x <span>:</span> xs) <span>=</span> <span>reverse</span> acc <span>++</span> f x <span>:</span> xs</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>        go acc n (x <span>:</span> xs) <span>=</span> go (x <span>:</span> acc) (n <span>-</span> <span>1</span>) xs</span></code></pre></div>
<p>While scoring is implemented as following:</p>
<div id="cb5"><pre><code><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span>scores ::</span> <span>Map</span> <span>StageId</span> <span>QueueStats</span> <span>-&gt;</span> <span>Config</span> <span>-&gt;</span> <span>Map</span> <span>StageId</span> <span>Double</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>scores qss (<span>Config</span> cfg) <span>=</span> joinMapsWith score qss cfg</span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>  <span>where</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a><span>    score ::</span> <span>QueueStats</span> <span>-&gt;</span> <span>Int</span> <span>-&gt;</span> <span>Double</span></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    score qs workers <span>=</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>      (<span>fromIntegral</span> (queueLength qs) <span>*</span> <span>fromIntegral</span> avgServiceTimePicos)</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>      <span>/</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>      (<span>fromIntegral</span> workers <span>+</span> <span>1</span>)</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>      <span>where</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a><span>        avgServiceTimePicos ::</span> <span>Word64</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>        avgServiceTimePicos</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>          <span>|</span> len <span>==</span> <span>0</span>  <span>=</span> <span>1</span> <span>-- XXX: What&#39;s the right value here?</span></span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>          <span>|</span> <span>otherwise</span> <span>=</span> <span>sum</span> (serviceTimesPicos qs) <span>`div`</span> len</span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>          <span>where</span></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a><span>            len ::</span> <span>Word64</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>            len <span>=</span> genericLength (serviceTimesPicos qs)</span></code></pre></div>
<p>Where a small helper function is used to join maps:</p>
<div id="cb6"><pre><code><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a><span>joinMapsWith ::</span> <span>Ord</span> k <span>=&gt;</span> (a <span>-&gt;</span> b <span>-&gt;</span> c) <span>-&gt;</span> <span>Map</span> k a <span>-&gt;</span> <span>Map</span> k b <span>-&gt;</span> <span>Map</span> k c</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a>joinMapsWith f m1 m2 <span>=</span> assert (Map.keys m1 <span>==</span> Map.keys m2) <span>$</span></span>
<span id="cb6-3"><a href="#cb6-3" aria-hidden="true" tabindex="-1"></a>  Map.fromList</span>
<span id="cb6-4"><a href="#cb6-4" aria-hidden="true" tabindex="-1"></a>    [ (k, f x (m2 <span>Map.!</span> k))</span>
<span id="cb6-5"><a href="#cb6-5" aria-hidden="true" tabindex="-1"></a>    <span>|</span> (k, x) <span>&lt;-</span> Map.toList m1</span>
<span id="cb6-6"><a href="#cb6-6" aria-hidden="true" tabindex="-1"></a>    ]</span></code></pre></div>
<p>The last piece we need is to be able to tell when a configuration
allocates workers to a stage that’s done:</p>
<div id="cb7"><pre><code><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span>allocatesDoneStages ::</span> <span>Config</span> <span>-&gt;</span> <span>Set</span> <span>StageId</span> <span>-&gt;</span> <span>Bool</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a>allocatesDoneStages (<span>Config</span> cfg) done <span>=</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a>  <span>any</span> (\(stageId, numWorkers) <span>-&gt;</span> stageId <span>`Set.member`</span> done <span>&amp;&amp;</span> numWorkers <span>&gt;</span> <span>0</span>)</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a>      (Map.toList cfg)</span></code></pre></div>
</section>
<section id="running-the-prototype">
<h2><a href="#running-the-prototype" title="Running the prototype">Running the prototype</a></h2>
<p>Let’s finish off with a couple of examples in the REPL. Let’s say we
have two workers, and two stages (<span>\(A\)</span>
and <span>\(B\)</span>), the <span>\(A\)</span> stage has three items on its input
queue (and this will be all the inputs it will receive), and no stage is
done yet (that’s the last <code>S.empty</code> argument):</p>
<div id="cb8"><pre><code><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span>&gt;&gt;&gt;</span> allocateWorkers <span>2</span> </span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>                    (M.fromList [ (<span>&#34;A&#34;</span>, <span>QueueStats</span> <span>3</span> [])</span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>                                , (<span>&#34;B&#34;</span>, <span>QueueStats</span> <span>0</span> [])]) </span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>                    S.empty</span></code></pre></div>
<p>(The <code>QueueStats</code> constructor takes the input queue length
as first argument and a list of service times as second argument.)</p>
<p>If we run the above, we get:</p>
<div id="cb9"><pre><code><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span>Just</span> (<span>Config</span> (fromList [(<span>&#34;A&#34;</span>,<span>2</span>),(<span>&#34;B&#34;</span>,<span>0</span>)]))</span></code></pre></div>
<p>Which means both workers should be allocated to the <span>\(A\)</span> stage. Let’s say that we do that
allocation and after 1 time unit passes both workers finish, that means
that the <span>\(A\)</span> input queue now has one
item left on it, while the second stage (<span>\(B\)</span>) now has two items on its input queue.
Since both workers are done, we rerun the allocation function:</p>
<div id="cb10"><pre><code><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a><span>&gt;&gt;&gt;</span> allocateWorkers <span>2</span> </span>
<span id="cb10-2"><a href="#cb10-2" aria-hidden="true" tabindex="-1"></a>                    (M.fromList [ (<span>&#34;A&#34;</span>, <span>QueueStats</span> <span>1</span> [<span>1</span>,<span>1</span>])</span>
<span id="cb10-3"><a href="#cb10-3" aria-hidden="true" tabindex="-1"></a>                                , (<span>&#34;B&#34;</span>, <span>QueueStats</span> <span>2</span> [])]) </span>
<span id="cb10-4"><a href="#cb10-4" aria-hidden="true" tabindex="-1"></a>                    S.empty</span>
<span id="cb10-5"><a href="#cb10-5" aria-hidden="true" tabindex="-1"></a><span>Just</span> (<span>Config</span> (fromList [(<span>&#34;A&#34;</span>,<span>1</span>),(<span>&#34;B&#34;</span>,<span>1</span>)]))</span></code></pre></div>
<p>The result now is that we should allocate one worker to each stage.
If we again imagine that we do so and they both finish after one time
unit, we end up in a situation where all three items have been processed
from the first stage (<span>\(A\)</span>), so we can
mark <span>\(A\)</span> as done, while the second
stage will have two items on its input queue:</p>
<div id="cb11"><pre><code><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span>&gt;&gt;&gt;</span> allocateWorkers <span>2</span> </span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a>                    (M.fromList [ (<span>&#34;A&#34;</span>, <span>QueueStats</span> <span>0</span> [<span>1</span>,<span>1</span>,<span>1</span>])</span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a>                                , (<span>&#34;B&#34;</span>, <span>QueueStats</span> <span>2</span> [<span>1</span>])]) </span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a>                    (S.fromList [<span>&#34;A&#34;</span>])</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a><span>Just</span> (<span>Config</span> (fromList [(<span>&#34;A&#34;</span>,<span>0</span>),(<span>&#34;B&#34;</span>,<span>2</span>)]))</span></code></pre></div>
<p>Allocating workers at this point will allocate both to the second
stage. After the workers finished working on those items the second
stage will have processed all items as well and we are done:</p>
<div id="cb12"><pre><code><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span>&gt;&gt;&gt;</span> allocateWorkers <span>2</span> </span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>                    (M.fromList [ (<span>&#34;A&#34;</span>, <span>QueueStats</span> <span>0</span> [<span>1</span>,<span>1</span>,<span>1</span>])</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>                                , (<span>&#34;B&#34;</span>, <span>QueueStats</span> <span>0</span> [<span>1</span>,<span>1</span>,<span>1</span>])]) </span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>                    (S.fromList [<span>&#34;A&#34;</span>, <span>&#34;B&#34;</span>])</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a><span>Nothing</span></span></code></pre></div>
</section>
<section id="unexpected-connection-to-thomas-jefferson">
<h2><a href="#unexpected-connection-to-thomas-jefferson" title="Unexpected connection to Thomas Jefferson">Unexpected connection
to Thomas Jefferson</a></h2>
<p>As I came up with this idea of scheduling described above, I bounced
it off my friend Daniel Gustafsson who immediately replied “this reminds
me a bit of Jefferson’s <a href="https://en.wikipedia.org/wiki/D%27Hondt_method">method</a>” (of
allocating seats in parliaments).</p>
<p>Here’s how the process works:</p>
<blockquote>
<p>“After all the votes have been tallied, successive quotients are
calculated for each party. The party with the largest quotient wins one
seat, and its quotient is recalculated. This is repeated until the
required number of seats is filled. The formula for the quotient is:</p>
<p><span>\(quot = \frac{V}{s + 1}\)</span></p>
<p>where:</p>
<ul>
<li>V is the total number of votes that party received, and</li>
<li>s is the number of seats that party has been allocated so far,
initially 0 for all parties.”</li>
</ul>
</blockquote>
<p>The analogy being:</p>
<pre><code>parties         : stages in the pipeline
seats per party : workers allocated to a stage
votes           : &#34;score&#34; (= length of input queue times average service time)
rounds          : total number of workers</code></pre>
<p>Let’s try to redo the example from above, where the stage <span>\(A\)</span> and <span>\(B\)</span> had queue length of <span>\(1\)</span> and <span>\(2\)</span> respectively, but using the Jefferson
method:</p>
<ol type="1">
<li><p>In the first round, party/stage <span>\(A\)</span> gets <span>\(1\)</span> vote, while party <span>\(B\)</span> gets <span>\(2\)</span> votes, so the quotient is <span>\(\frac{1}{0 + 1}\)</span> and <span>\(\frac{2}{0 + 1}\)</span> respectively, which means
that stage <span>\(B\)</span> wins the round and
gets allocated a seat;</p></li>
<li><p>In the second round we get the quotients: <span>\(\frac{1}{0 + 1} = 1\)</span> and <span>\(\frac{2}{1 + 1} = 1\)</span> (note that <span>\(s = 1\)</span> here, because stage/party <span>\(B\)</span> already won a seat in the previous
round). Which means we get a tie, in this case I guess we could
arbitrarily pick the first party, just so that our example works out the
same as in the implementation<a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a>.</p></li>
</ol>
<p>Daniel also explained that while Jefferson came up with this method,
it’s not actually used in the USA, but in most of Europe including the
EU parliament use the method.</p>
</section>
<section id="conclusion-and-future-work">
<h2><a href="#conclusion-and-future-work" title="Conclusion and future work">Conclusion and future work</a></h2>
<p>We’ve seen a strategy of how one can elastically scale the amount of
CPUs/cores dedicated to one stage in a pipeline. Being able to do so
should come handy if:</p>
<ol type="1">
<li>The load on the system changes and suddenly one stage becomes slower
than another, by being elastic we can rebalance the cores and maintain
throughput;</li>
<li>The load decreases, we can scale down and use the cores elsewhere in
the system.</li>
</ol>
<p>We also saw how Thomas Jefferson’s method of allocating seats in a
parliament can be used to solve the same problem. This unexpected
connection makes me wonder where else this algorithm pops up?</p>
<p>We are still far from being able to implement a parallel programming
language runtime using these ideas. In particular the current <a href="https://github.com/stevana/scheduled-pipelines">implementation</a>
uses simple concurrent queues to connect the stages, meaning that
scaling up a stage doesn’t preserve determinism of the output. This can
be solved using Disruptors instead, as in my <a href="https://stevana.github.io/parallel_stream_processing_with_zero-copy_fan-out_and_sharding.html">older
post</a>. I’ve collected a bunch of other things left to do in a
separate <a href="https://github.com/stevana/scheduled-pipelines/blob/main/TODO.md">file</a>.
If any of this interests you, feel free to get in <a href="https://stevana.github.io/about.html">touch</a>.</p>
</section>

</div></div>
  </body>
</html>
