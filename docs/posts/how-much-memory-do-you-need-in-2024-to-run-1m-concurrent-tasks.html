<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://hez2010.github.io/async-runtimes-benchmarks-2024/">Original</a>
    <h1>How much memory do you need in 2024 to run 1M concurrent tasks?</h1>
    
    <div id="readability-page-1" class="page">
            
<p>Did you still remember <a href="https://pkolaczk.github.io/memory-consumption-of-async/">the memory consumption comparison</a> between asynchronous programming across popular languages in 2023?</p>
<p>Now at the end of 2024, I wonder how things changed in the span of one year, with the latest version of languages.</p>
<p>Let&#39;s do the benchmark again and see the results!</p>
<h2 id="benchmark">Benchmark</h2>
<p>The program to benchmark is the same with the one in the last year:</p>
<blockquote>
<p>Let&#39;s launch N concurrent tasks, where each task waits for 10 seconds and then the program exists after all tasks finish. The number of tasks is controlled by the command line argument.</p>
</blockquote>
<p>This time, let&#39;s focus on coroutine instead of multiple threads.</p>
<p>All benchmark code can be accessed at <a href="https://github.com/hez2010/async-runtimes-benchmarks-2024">async-runtimes-benchmarks-2024</a>.</p>
<p>What is a coroutine?</p>
<blockquote>
<p>Coroutines are computer program components that allow execution to be suspended and resumed, generalizing subroutines for cooperative multitasking. Coroutines are well-suited for implementing familiar program components such as cooperative tasks, exceptions, event loops, iterators, infinite lists and pipes.</p>
</blockquote>
<h3 id="rust">Rust</h3>
<p>I created 2 programs in Rust. One uses <code>tokio</code>:</p>
<pre><code><span>use</span> std::env;
<span>use</span> tokio::time::{sleep, Duration};

<span>#[tokio::main]</span>
<span>async</span> <span>fn</span> <span>main</span>() {
    <span>let</span> <span>args</span>: <span>Vec</span>&lt;<span>String</span>&gt; = env::<span>args</span>().<span>collect</span>();
    <span>let</span> <span>num_tasks</span> = args[<span>1</span>].parse::&lt;<span>i32</span>&gt;().<span>unwrap</span>();
    <span>let</span> <span>mut </span><span>tasks</span> = Vec::<span>new</span>();
    <span>for</span> <span>_</span> <span>in</span> <span>0</span>..num_tasks {
        tasks.<span>push</span>(<span>sleep</span>(Duration::<span>from_secs</span>(<span>10</span>)));
    }
    futures::future::<span>join_all</span>(tasks).<span>await</span>;
}
</code></pre>
<p>while another one uses <code>async_std</code>:</p>
<pre><code><span>use</span> std::env;
<span>use</span> async_std::task;
<span>use</span> futures::future::join_all;
<span>use</span> std::time::Duration;

<span>#[async_std::main]</span>
<span>async</span> <span>fn</span> <span>main</span>() {
    <span>let</span> <span>args</span>: <span>Vec</span>&lt;<span>String</span>&gt; = env::<span>args</span>().<span>collect</span>();
    <span>let</span> <span>num_tasks</span> = args[<span>1</span>].parse::&lt;<span>usize</span>&gt;().<span>unwrap</span>();
    
    <span>let</span> <span>mut </span><span>tasks</span> = Vec::<span>new</span>();
    <span>for</span> <span>_</span> <span>in</span> <span>0</span>..num_tasks {
        tasks.<span>push</span>(task::<span>sleep</span>(Duration::<span>from_secs</span>(<span>10</span>)));
    }

    <span>join_all</span>(tasks).<span>await</span>;
}
</code></pre>
<p>Both are popular async runtime commonly used in Rust.</p>
<h3 id="c">C#</h3>
<p>C#, similar to Rust, has first-class support for async/await:</p>
<pre><code><span>int</span> numTasks = <span>int</span>.Parse(args[<span>0</span>]);
List&lt;Task&gt; tasks = <span>new</span> List&lt;Task&gt;();

<span>for</span> (<span>int</span> i = <span>0</span>; i &lt; numTasks; i++)
{
    tasks.Add(Task.Delay(TimeSpan.FromSeconds(<span>10</span>)));
}

<span>await</span> Task.WhenAll(tasks);
</code></pre>
<p>.NET also offers NativeAOT compilation since .NET 7, which compiles the code to the final binary directly so that it no longer needs a VM to run managed code. So we added the benchmark for NativeAOT as well.</p>
<h3 id="nodejs">NodeJS</h3>
<p>So does NodeJS:</p>
<pre><code><span>const</span> util = <span>require</span>(<span>&#39;util&#39;</span>);
<span>const</span> delay = util.<span>promisify</span>(<span>setTimeout</span>);

<span>async</span> <span>function</span> <span>runTasks</span>(<span>numTasks</span>) {
  <span>const</span> tasks = [];

  <span>for</span> (<span>let</span> i = <span>0</span>; i &lt; numTasks; i++) {
    tasks.<span>push</span>(<span>delay</span>(<span>10000</span>));
  }

  <span>await</span> <span>Promise</span>.<span>all</span>(tasks);
}

<span>const</span> numTasks = <span>parseInt</span>(process.<span>argv</span>[<span>2</span>]);
<span>runTasks</span>(numTasks);
</code></pre>
<h3 id="python">Python</h3>
<p>And Python, too:</p>
<pre><code><span>import</span> asyncio
<span>import</span> sys

<span>async</span> <span>def</span> <span>main</span>(<span>num_tasks</span>):
    tasks = []

    <span>for</span> task_id <span>in</span> <span>range</span>(num_tasks):
        tasks.append(asyncio.sleep(<span>10</span>))

    <span>await</span> asyncio.gather(*tasks)

<span>if</span> __name__ == <span>&#34;__main__&#34;</span>:
    num_tasks = <span>int</span>(sys.argv[<span>1</span>])
    asyncio.run(main(num_tasks))
</code></pre>
<h3 id="go">Go</h3>
<p>In Go, goroutines are the building block for concurrency. We donâ€™t await them separately, but we use a <code>WaitGroup</code> instead:</p>
<pre><code><span>package</span> main

<span>import</span> (
    <span>&#34;fmt&#34;</span>
    <span>&#34;os&#34;</span>
    <span>&#34;strconv&#34;</span>
    <span>&#34;sync&#34;</span>
    <span>&#34;time&#34;</span>
)

<span><span>func</span> <span>main</span><span>()</span></span> {
    numRoutines, _ := strconv.Atoi(os.Args[<span>1</span>])
    <span>var</span> wg sync.WaitGroup
    <span>for</span> i := <span>0</span>; i &lt; numRoutines; i++ {
        wg.Add(<span>1</span>)
        <span>go</span> <span><span>func</span><span>()</span></span> {
            <span>defer</span> wg.Done()
            time.Sleep(<span>10</span> * time.Second)
        }()
    }
    wg.Wait()
}
</code></pre>
<h3 id="java">Java</h3>
<p>Java offers virtual threads since JDK 21, which are a similar concept to goroutines:</p>
<pre><code><span>import</span> java.time.Duration;
<span>import</span> java.util.ArrayList;
<span>import</span> java.util.List;

<span>public</span> <span>class</span> <span>VirtualThreads</span> {

    <span>public</span> <span>static</span> <span>void</span> <span>main</span><span>(String[] args)</span> <span>throws</span> InterruptedException {
	    <span>int</span> <span>numTasks</span> <span>=</span> Integer.parseInt(args[<span>0</span>]);
        List&lt;Thread&gt; threads = <span>new</span> <span>ArrayList</span>&lt;&gt;();

        <span>for</span> (<span>int</span> <span>i</span> <span>=</span> <span>0</span>; i &lt; numTasks; i++) {
            <span>Thread</span> <span>thread</span> <span>=</span> Thread.startVirtualThread(() -&gt; {
                <span>try</span> {
                    Thread.sleep(Duration.ofSeconds(<span>10</span>));
                } <span>catch</span> (InterruptedException e) {
                    
                }
            });
            threads.add(thread);
        }

        <span>for</span> (Thread thread : threads) {
            thread.join();
        }
    }
}
</code></pre>
<p>While there&#39;s a new variant of JVM called GraalVM. GraalVM also offers native image, which is a similar concept to NativeAOT in .NET. So we added the benchmark for GraalVM as well.</p>
<h2 id="test-environment">Test Environment</h2>
<ul>
<li>Hardware: 13th Gen Intel(R) Core(TM) i7-13700K</li>
<li>OS: Debian GNU/Linux 12 (bookworm)</li>
<li>Rust: 1.82.0</li>
<li>.NET: 9.0.100</li>
<li>Go: 1.23.3</li>
<li>Java: openjdk 23.0.1 build 23.0.1+11-39</li>
<li>Java (GraalVM): java 23.0.1 build 23.0.1+11-jvmci-b01</li>
<li>NodeJS: v23.2.0</li>
<li>Python: 3.13.0</li>
</ul>
<p>All programs were launched using the release mode if available, and support for internationalization and globalization was disabled as we did&#39;t have libicu in our test environment.</p>
<h2 id="results">Results</h2>


<p>Let&#39;s start from something small, because some runtimes require some memory for themselves, let&#39;s first launch only one task.</p>


<p>We can see that Rust, C# (NativeAOT), and Go achieved similar results, as they were compiled statically to native binaries and needed very little memory. Java (GraalVM native-image) also did a great job but cost a bit more than the other statically compiled ones. The other programs running on managed platforms or through interpreters consume more memory.</p>
<p>Go seems to have the smallest footprint in this case.</p>
<p>Java with GraalVM is a bit surprising, as it cost far more memory than Java with OpenJDK, but I guess this can be tuned with some settings.</p>
<h3 id="10k-tasks">10K Tasks</h3>


<p>A few surprises here! The two Rust benchmarks achieved very promising results: they both used very little memory, which didn&#39;t grow too much compared to minimal footprint results, even though there were 10K tasks running behind the scenes! C# (NativeAOT) followed closely behind, using only ~10MB of memory. We need more tasks to put more pressure on them!</p>
<p>The memory consumption grew dramatically in Go. Goroutines are supposed to be very lightweight, but they actually consumed far more RAM than Rust required. In this case, virtual threads in Java (GraalVM native image) seem to be more lightweight than Goroutines in Go. To my surprise, both Go and Java (GraalVM native image), which were compiled to native binaries statically, cost more RAM than the C# one running on a VM!</p>
<h3 id="100k-tasks">100K Tasks</h3>


<p>After we increased the number of tasks to 100K, the memory consumption of all the languages started to grow significantly.</p>
<p>Both Rust and C# did a really good job in this case. A big surprise is that C# (NativeAOT) even cost less RAM than Rust and beat all other languages. Really impressive!</p>
<p>At this point, the Go program has been beaten not only by Rust but also by Java (except the one running on GraalVM), C#, and NodeJS.</p>
<h3 id="1-million-tasks">1 Million Tasks</h3>
<p>Let&#39;s go extreme now.</p>


<p>Finally, C# undoubtedly beat all other languages; it&#39;s very competitive and has really become a monster. And as expected, Rust continues to do a good job on memory efficiency.</p>
<p>The distance between Go and the others increased. Now Go loses by over 13 times to the winner. It also loses by over 2 times to Java, which contradicts the general perception of the JVM being a memory hog and Go being lightweight.</p>
<h2 id="final-word">Final Word</h2>
<p>As we have observed, a high number of concurrent tasks can consume a significant amount of memory, even if they do not perform complex operations. Different language runtimes have varying trade-offs, with some being lightweight and efficient for a small number of tasks but scaling poorly with hundreds of thousands of tasks.</p>
<p>Many things have changed since last year. With the benchmark results on the latest compilers and runtimes, we see a huge improvement in .NET, and .NET with NativeAOT is really competitive with Rust. The native image of Java built with GraalVM also did a great job in terms of memory efficiency. However, goroutines continue to be inefficient in resource consumption.</p>
<h2 id="appendix">Appendix</h2>
<p>Some folks pointed out that in Rust (tokio) it can use a loop iterating over the <code>Vec</code> instead of <code>join_all</code> to avoid the resize to the list introduced by <code>join_all</code>. So I added a new test case <code>Rust (tokio-for)</code> here:</p>
<pre><code><span>use</span> std::env;
<span>use</span> tokio::time::{sleep, Duration};

<span>#[tokio::main]</span>
<span>async</span> <span>fn</span> <span>main</span>() {
    <span>let</span> <span>args</span>: <span>Vec</span>&lt;<span>String</span>&gt; = env::<span>args</span>().<span>collect</span>();
    <span>let</span> <span>num_tasks</span> = args[<span>1</span>].parse::&lt;<span>i32</span>&gt;().<span>unwrap</span>();
    <span>let</span> <span>mut </span><span>tasks</span> = Vec::<span>new</span>();
    <span>for</span> <span>_</span> <span>in</span> <span>0</span>..num_tasks {
        tasks.<span>push</span>(<span>sleep</span>(Duration::<span>from_secs</span>(<span>10</span>)));
    }
    <span>for</span> <span>task</span> <span>in</span> tasks {
        task.<span>await</span>;
    }
}
</code></pre>
<p>Note that this won&#39;t work for <code>async_std</code> as it needs you to poll explicitly until the task being scheduled and executed, so switching to a loop will make it run the tasks sequentially.</p>
<p>Let&#39;s see what will happen with the new test code.</p>



<h3 id="10k-tasks-1">10K Tasks</h3>


<h3 id="100k-tasks-1">100K Tasks</h3>


<h3 id="1m-tasks">1M Tasks</h3>


<p>This shrinks the cost of <code>Rust (tokio)</code> by about a half, which makes Rust the absolute lead in this benchmark. Good job, Rust.</p>

            
            

        
        
</div>
  </body>
</html>
