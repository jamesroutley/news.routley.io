<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://stanislas.blog/2021/08/firecracker/">Original</a>
    <h1>Using Firecracker and Go to run short, untrusted code execution jobs (2021)</h1>
    
    <div id="readability-page-1" class="page"><div>
<p><img alt="A concrete use-case of Firecracker with code snippets" src="https://stanislas.blog/2021/08/firecracker/firecracker-logo.jpg" width="800" height="400" sizes="(min-width: 1080px) 694px, (min-width: 780px) calc(75vw - 3rem), calc(100vw - 3rem)" srcset="
            
              
              
            
            "/>
</p>
<p>This semester I have been working on a school project where the main requirement was that we needed to execute user-submitted code in one form or another.</p>
<p>My team’s subject was a code benchmarking platform, where users could create benchmarks (eg: <em>sort these two arrays as fast as possible</em>) and then anyone could submit solutions to the benchmarks.</p>
<p><strong>In this post, I want to dive in the code execution part of the project, the approach I took and how I used Firecracker, with concrete code snippets.</strong></p>
<h2 id="overview-of-the-project">Overview of the project</h2>
<p>To put things in context, here’s a screenshot of the final version of the frontend:</p>
<figure><img src="https://stanislas.blog/2021/08/firecracker/codebench-front-screenshot.png" sizes="(min-width: 1080px) 694px, (min-width: 780px) calc(75vw - 3rem), calc(100vw - 3rem)" width="4474" height="2044" loading="lazy" srcset="
        
          
            ,/2021/08/firecracker/codebench-front-screenshot_hu8085e53450f5feb5851ecf2713efea3b_252496_960x0_resize_linear_3.png 960w
          
          
            ,/2021/08/firecracker/codebench-front-screenshot_hu8085e53450f5feb5851ecf2713efea3b_252496_1280x0_resize_linear_3.png 1280w
          
        
        " data-zoom-src="codebench-front-screenshot.png" alt="It&amp;rsquo;s not particularly sexy, but you get the idea :)"/><figcaption>
<p>It’s not particularly sexy, but you get the idea :)</p>
</figcaption>
</figure>
<p>The service supports C++, Python, and Go and performs some code analysis on the submitted code.</p>
<p>Here is a schema of the global architecture:</p>
<figure><img src="https://stanislas.blog/2021/08/firecracker/codebench-global-architecture.png" sizes="(min-width: 1080px) 694px, (min-width: 780px) calc(75vw - 3rem), calc(100vw - 3rem)" width="2480" height="884" loading="lazy" srcset="
        
          
            ,/2021/08/firecracker/codebench-global-architecture_hue0284e01d3d9a43aa887f89b7a4d1121_80355_960x0_resize_linear_3.png 960w
          
          
            ,/2021/08/firecracker/codebench-global-architecture_hue0284e01d3d9a43aa887f89b7a4d1121_80355_1280x0_resize_linear_3.png 1280w
          
        
        " data-zoom-src="codebench-global-architecture.png"/>
</figure>
<p>All the code is available on <a href="https://github.com/codebench-dev">GitHub</a>.</p>
<p>The main API is written with NestJS in Typescript, and contains all the feature of the service. The code analysis is also done there. However, the code submissions are actually sent in a RabbitMQ queue and handled by workers and agents.</p>
<h2 id="the-choice-of-firecracker">The choice of Firecracker</h2>
<p>One of the objectives set for the project was to focus on security and isolation for the untrusted code execution part. Instinctively, Docker containers seem like an easy way to achieve this goal. However, I was aware that Docker itself is not completely safe in that regard. While researching additional security layers for containers, I remembered that Firecracker was a thing and decided to give it a try.</p>
<figure><img src="https://stanislas.blog/2021/08/firecracker/vm-vs-container.jpeg" sizes="(min-width: 1080px) 694px, (min-width: 780px) calc(75vw - 3rem), calc(100vw - 3rem)" width="1200" height="675" loading="lazy" srcset="
        
          
            ,/2021/08/firecracker/vm-vs-container_huab67e5470c7de583d14343e20020166e_78917_960x0_resize_q80_linear.jpeg 960w
          
          
        
        " data-zoom-src="vm-vs-container.jpeg" alt="Source: AWS blog"/><figcaption>
<p>Source: <a href="https://www.amazon.science/blog/how-awss-firecracker-virtual-machines-work">AWS blog</a></p>
</figcaption>
</figure>
<p><a href="https://firecracker-microvm.github.io/">Firecracker</a> is a virtual machine manager (VMM) that powers AWS Lambda and AWS Fargate, and has been used in production at AWS since 2018. It also powers other multi-tenant serverless services such as <a href="https://www.koyeb.com/blog/10-reasons-why-we-love-firecracker-microvms">Koyeb</a> or <a href="https://fly.io/blog/sandboxing-and-workload-isolation/">Fly.io</a>.</p>
<p>I was aware of the project but didn’t have an occasion to actually use it. The <a href="https://github.com/firecracker-microvm/firecracker/blob/main/docs/getting-started.md">Getting Started</a> guide from the documentation was an excellent resource. In general, the docs are very good.</p>
<p>The main seeling points of Firecracker is its very low overhead in terms of resource usage and ability to start a staggering amount of VMs at the same time (the docs says <em>one can create 180 microVMs per second on a host with 36 physical cores</em>). Usually, we have to choose between the strong isolation but high overhead of virtualization versus the lower overhead but lower isolation of containers. Firecracker is great because it doesn’t compromise on either security or performance.</p>
<p>The key concept to understand is that Firecracker is a VMM, so it will manage one microVM at a time. The VMM process will run a HTTP API listening on a socket. To configure and interact with the VM, you need to go through the API. For example to start a microVM, you would start the VMM with <code>./firecracker --api-sock /tmp/firecracker.socket</code>, send to HTTP requests to configure the VM and then start it:</p>
<div><pre tabindex="0"><code data-lang="fallback"><span><span>curl --unix-socket /tmp/firecracker.socket -i \
</span></span><span><span>  -X PUT &#39;http://localhost/actions&#39;       \
</span></span><span><span>  -H  &#39;Accept: application/json&#39;          \
</span></span><span><span>  -H  &#39;Content-Type: application/json&#39;    \
</span></span><span><span>  -d &#39;{
</span></span><span><span>      &#34;action_type&#34;: &#34;InstanceStart&#34;
</span></span><span><span>   }&#39;
</span></span></code></pre></div><p>Since this is quite unhandy, there is an official CLI available: <a href="https://github.com/firecracker-microvm/firectl">firectl</a>. It is based on the <a href="https://github.com/firecracker-microvm/firecracker-go-sdk">Go SDK</a> to interact with the VMM API.</p>
<p>Starting a VM is as easy as this:</p>
<div><pre tabindex="0"><code data-lang="fallback"><span><span>./firectl/firectl \
</span></span><span><span>  --kernel=linux/vmlinux \
</span></span><span><span>  --root-drive=rootfs.ext4
</span></span></code></pre></div><p>After playing around for a bit, I was satisfied with the ease of use and performance of Firecracker, so I decided to try and build something our school project on top of it.</p>
<h2 id="project-architecture">Project architecture</h2>
<p>The approach I took was to use workers that would receive messages from the main API and spawn microVMs to execute the user-submitted code through an agent inside the microVM.</p>
<h3 id="agent">Agent</h3>
<p>Since my final goal is to run code inside the microVM. I had to have a program running inside of it that was accessible somehow.</p>
<p>The <a href="https://github.com/codebench-dev/agent">agent</a> is an HTTP API in Go made with <a href="https://github.com/labstack/echo">Echo</a> that is able to compile and run standalone C, C++, Python and Go. It simply shells out compiler commands and handles the output. It’s not particularly smart or secure, but it is good enough for the project.</p>
<p>I tried to use Rust for the API (the code is <a href="https://github.com/codebench-dev/agent/tree/main/archive/rust">still in the repo</a>) since I had a Rust class at the time, but I lost too much time fighting with the language and went back to Go since I’m much more familiar with it.</p>
<p>Here an example of the API compiling and executing simple C code:</p>
<div><pre tabindex="0"><code data-lang="fallback"><span><span>» curl -i localhost:8080/run -X POST --data &#39;{&#34;code&#34;:&#34;#include &lt;stdio.h&gt;\r\nint main() {\r\n   printf(\&#34;Hello, C!\&#34;);\r\n   return 0;\r\n}&#34;,&#34;id&#34;:&#34;123&#34;,&#34;variant&#34;:&#34;gcc&#34;,&#34;language&#34;:&#34;c&#34;}&#39; -H &#39;Content-Type: application/json&#39;
</span></span><span><span>HTTP/1.1 200 OK
</span></span><span><span>Content-Type: application/json; charset=UTF-8
</span></span><span><span>Date: Sat, 31 Jul 2021 20:04:04 GMT
</span></span><span><span>Content-Length: 104
</span></span><span><span>
</span></span><span><span>{&#34;message&#34;:&#34;Success&#34;,&#34;error&#34;:&#34;&#34;,&#34;stdout&#34;:&#34;Hello, C!&#34;,&#34;stderr&#34;:&#34;&#34;,&#34;exec_duration&#34;:1843,&#34;mem_usage&#34;:9432}
</span></span></code></pre></div><p>The code is pretty simple, let’s quickly walk through it. Here is a excerpt of the C handler:</p>
<div><pre tabindex="0"><code data-lang="go"><span><span><span>// Compile code
</span></span></span><span><span><span></span><span>var</span> compileStdOut, compileStdErr bytes.Buffer
</span></span><span><span>compileCmd <span>:=</span> exec.<span>Command</span>(<span>&#34;gcc&#34;</span>, <span>&#34;-x&#34;</span>, <span>&#34;c&#34;</span>, <span>&#34;/tmp/&#34;</span><span>+</span>req.ID, <span>&#34;-o&#34;</span>, <span>&#34;/tmp/&#34;</span><span>+</span>req.ID<span>+</span><span>&#34;.out&#34;</span>)
</span></span><span><span>compileCmd.Stdout = <span>&amp;</span>compileStdOut
</span></span><span><span>compileCmd.Stderr = <span>&amp;</span>compileStdErr
</span></span><span><span>err <span>:=</span> compileCmd.<span>Run</span>()
</span></span><span><span>
</span></span><span><span><span>if</span> err <span>!=</span> <span>nil</span> {
</span></span><span><span>	<span>return</span> c.<span>JSON</span>(http.StatusBadRequest, runCRes{
</span></span><span><span>		Message: <span>&#34;Failed to compile&#34;</span>,
</span></span><span><span>		Error:   err.<span>Error</span>(),
</span></span><span><span>		Stdout:  compileStdOut.<span>String</span>(),
</span></span><span><span>		Stderr:  compileStdErr.<span>String</span>(),
</span></span><span><span>	})
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>// Run executable
</span></span></span><span><span><span></span><span>return</span> <span>execCmd</span>(c, <span>&#34;/tmp/&#34;</span><span>+</span>req.ID<span>+</span><span>&#34;.out&#34;</span>)
</span></span></code></pre></div><p>And the execution handler:</p>
<div><pre tabindex="0"><code data-lang="go"><span><span><span>func</span> <span>execCmd</span>(c echo.Context, program <span>string</span>, arg <span>...</span><span>string</span>) <span>error</span> {
</span></span><span><span>	<span>var</span> execStdOut, execStdErr bytes.Buffer
</span></span><span><span>
</span></span><span><span>	cmd <span>:=</span> exec.<span>Command</span>(program, arg<span>...</span>)
</span></span><span><span>	cmd.Stdout = <span>&amp;</span>execStdOut
</span></span><span><span>	cmd.Stderr = <span>&amp;</span>execStdErr
</span></span><span><span>
</span></span><span><span>	start <span>:=</span> time.<span>Now</span>()
</span></span><span><span>	err <span>:=</span> cmd.<span>Run</span>()
</span></span><span><span>	elapsed <span>:=</span> time.<span>Since</span>(start)
</span></span><span><span>
</span></span><span><span>	<span>if</span> err <span>!=</span> <span>nil</span> {
</span></span><span><span>		<span>return</span> c.<span>JSON</span>(http.StatusBadRequest, runCRes{
</span></span><span><span>			Message:      <span>&#34;Failed to run&#34;</span>,
</span></span><span><span>			Error:        err.<span>Error</span>(),
</span></span><span><span>			Stdout:       execStdOut.<span>String</span>(),
</span></span><span><span>			Stderr:       execStdErr.<span>String</span>(),
</span></span><span><span>			ExecDuration: elapsed.<span>Microseconds</span>(),
</span></span><span><span>			MemUsage:     cmd.ProcessState.<span>SysUsage</span>().(<span>*</span>syscall.Rusage).Maxrss,
</span></span><span><span>		})
</span></span><span><span>	}
</span></span><span><span>
</span></span><span><span>	<span>return</span> c.<span>JSON</span>(http.StatusOK, runCRes{
</span></span><span><span>		Message:      <span>&#34;Success&#34;</span>,
</span></span><span><span>		Stdout:       execStdOut.<span>String</span>(),
</span></span><span><span>		Stderr:       execStdErr.<span>String</span>(),
</span></span><span><span>		ExecDuration: elapsed.<span>Microseconds</span>(),
</span></span><span><span>		MemUsage:     cmd.ProcessState.<span>SysUsage</span>().(<span>*</span>syscall.Rusage).Maxrss,
</span></span><span><span>	})
</span></span><span><span>}
</span></span></code></pre></div><p>Once the agent was done, I needed to create a VM image with the agent preinstalled in it.</p>
<p>The image for the VM will be based on Alpine Linux, so first I have to compile the program statically:</p>
<div><pre tabindex="0"><code data-lang="sh"><span><span>go build -tags netgo -ldflags <span>&#39;-extldflags &#34;-static&#34;&#39;</span>
</span></span></code></pre></div><p>I also need to prepare an OpenRC service that will start the agent when the VM boots:</p>
<div><pre tabindex="0"><code data-lang="sh"><span><span><span>#!/sbin/openrc-run
</span></span></span><span><span><span></span>
</span></span><span><span><span>name</span><span>=</span><span>$RC_SVCNAME</span>
</span></span><span><span><span>description</span><span>=</span><span>&#34;CodeBench agent&#34;</span>
</span></span><span><span><span>supervisor</span><span>=</span><span>&#34;supervise-daemon&#34;</span>
</span></span><span><span><span>command</span><span>=</span><span>&#34;/usr/local/bin/agent&#34;</span>
</span></span><span><span><span>pidfile</span><span>=</span><span>&#34;/run/agent.pid&#34;</span>
</span></span><span><span><span>command_user</span><span>=</span><span>&#34;codebench:codebench&#34;</span>
</span></span><span><span>
</span></span><span><span>depend<span>()</span> <span>{</span>
</span></span><span><span>	after net
</span></span><span><span><span>}</span>
</span></span></code></pre></div><p>Then, I will build the rootfs using the same technique showed in the Firecracker docs, which relies on creating an ext4 filesystem in a image file, mount it in a Docker container running Alpine and copy the filesystem from the container.</p>
<div><pre tabindex="0"><code data-lang="sh"><span><span>dd <span>if</span><span>=</span>/dev/zero <span>of</span><span>=</span>rootfs.ext4 <span>bs</span><span>=</span>1M <span>count</span><span>=</span><span>1000</span>
</span></span><span><span>mkfs.ext4 rootfs.ext4
</span></span><span><span>mkdir -p /tmp/my-rootfs
</span></span><span><span>mount rootfs.ext4 /tmp/my-rootfs
</span></span><span><span>
</span></span><span><span>docker run -i --rm <span>\
</span></span></span><span><span><span></span>    -v /tmp/my-rootfs:/my-rootfs <span>\
</span></span></span><span><span><span></span>    -v <span>&#34;</span><span>$(</span><span>pwd</span><span>)</span><span>/agent:/usr/local/bin/agent&#34;</span> <span>\
</span></span></span><span><span><span></span>    -v <span>&#34;</span><span>$(</span><span>pwd</span><span>)</span><span>/openrc-service.sh:/etc/init.d/agent&#34;</span> <span>\
</span></span></span><span><span><span></span>    alpine sh &lt;setup-alpine.sh
</span></span><span><span>
</span></span><span><span>umount /tmp/my-rootfs
</span></span><span><span>
</span></span><span><span><span># rootfs available under `rootfs.ext4`</span>
</span></span></code></pre></div><p>The rootfs is currently a 1GB image, which is a bit big, especially since the worker has to copy it every time it creates a new VM. There are multiple programming languages installed though, hence the size.</p>
<p>The setup script for Alpine also contains the installation of the compiler/runtimes needed for the agent:</p>
<div><pre tabindex="0"><code data-lang="sh"><span><span>apk add --no-cache openrc
</span></span><span><span>apk add --no-cache util-linux
</span></span><span><span>apk add --no-cache gcc libc-dev
</span></span><span><span>apk add --no-cache python2 python3
</span></span><span><span>apk add --no-cache go
</span></span><span><span>apk add --no-cache g++
</span></span><span><span>
</span></span><span><span>ln -s agetty /etc/init.d/agetty.ttyS0
</span></span><span><span><span>echo</span> ttyS0 &gt;/etc/securetty
</span></span><span><span>rc-update add agetty.ttyS0 default
</span></span><span><span>
</span></span><span><span><span>echo</span> <span>&#34;root:root&#34;</span> | chpasswd
</span></span><span><span>
</span></span><span><span><span>echo</span> <span>&#34;nameserver 1.1.1.1&#34;</span> &gt;&gt;/etc/resolv.conf
</span></span><span><span>
</span></span><span><span>addgroup -g <span>1000</span> -S codebench <span>&amp;&amp;</span> adduser -u <span>1000</span> -S codebench -G codebench
</span></span><span><span>
</span></span><span><span>rc-update add devfs boot
</span></span><span><span>rc-update add procfs boot
</span></span><span><span>rc-update add sysfs boot
</span></span><span><span>
</span></span><span><span>rc-update add agent boot
</span></span><span><span>
</span></span><span><span><span>for</span> d in bin etc lib root sbin usr; <span>do</span> tar c <span>&#34;/</span><span>$d</span><span>&#34;</span> | tar x -C /my-rootfs; <span>done</span>
</span></span><span><span><span>for</span> dir in dev proc run sys var tmp; <span>do</span> mkdir /my-rootfs/<span>${</span><span>dir</span><span>}</span>; <span>done</span>
</span></span><span><span>
</span></span><span><span>chmod <span>1777</span> /my-rootfs/tmp
</span></span><span><span>mkdir -p /my-rootfs/home/codebench/
</span></span><span><span>chown 1000:1000 /my-rootfs/home/codebench/
</span></span></code></pre></div><p>And that’s it, I now have a rootfs with the agent preinstalled.</p>
<h3 id="worker">Worker</h3>
<p>This is the interesting part: the piece that is between the main API and the microVMs. Its responsibilities are to:</p>
<ul>
<li>Receive code execution jobs from the API</li>
<li>Handle VMMs creation/deletion</li>
<li>Communicate the jobs to the agent</li>
<li>Handle job status updates (failures, success, etc)</li>
</ul>
<p>First, I need to receive jobs from the main API. I decided to use a external message queue so that the whole process is asynchronous and easily scalable. I tried to use Redis at first to keep things simple, and although it was working as expected on the worker side, the NestJS API was a different story.</p>
<p>The native RabbitMQ implementation wasn’t matching what I needed either. Luckily the <a href="https://github.com/golevelup/nestjs/tree/master/packages/rabbitmq"><code>@golevelup/nestjs-rabbitmq</code></a> NPM package saved me!</p>
<p>In my SubmissionsService, I can simply send a job to RabbitMQ:</p>
<div><pre tabindex="0"><code data-lang="ts"><span><span><span>// Send job to worker
</span></span></span><span><span><span></span><span>await</span> <span>this</span>.amqpConnection.publish(<span>&#34;jobs_ex&#34;</span>, <span>&#34;jobs_rk&#34;</span>, {
</span></span><span><span>  id: <span>submission.id</span>,
</span></span><span><span>  code: <span>createSubmissionDTO.code</span>,
</span></span><span><span>  language: <span>createSubmissionDTO.language</span>,
</span></span><span><span>});
</span></span></code></pre></div><p>In my Worker, here is the code that will receive the job:</p>
<div><pre tabindex="0"><code data-lang="go"><span><span>q = <span>newJobQueue</span>(rabbitMQURL)
</span></span><span><span><span>defer</span> q.ch.<span>Close</span>()
</span></span><span><span><span>defer</span> q.conn.<span>Close</span>()
</span></span><span><span>
</span></span><span><span>err <span>:=</span> q.<span>getQueueForJob</span>(ctx)
</span></span><span><span><span>if</span> err <span>!=</span> <span>nil</span> {
</span></span><span><span>  log.<span>WithError</span>(err).<span>Fatal</span>(<span>&#34;Failed to get status queue&#34;</span>)
</span></span><span><span>  <span>return</span>
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span>log.<span>Info</span>(<span>&#34;Waiting for RabbitMQ jobs...&#34;</span>)
</span></span><span><span><span>for</span> d <span>:=</span> <span>range</span> q.jobs {
</span></span><span><span>  log.<span>Printf</span>(<span>&#34;Received a message: %s&#34;</span>, d.Body)
</span></span><span><span>
</span></span><span><span>  <span>var</span> job benchJob
</span></span><span><span>  err <span>:=</span> json.<span>Unmarshal</span>([]<span>byte</span>(d.Body), <span>&amp;</span>job)
</span></span><span><span>  <span>if</span> err <span>!=</span> <span>nil</span> {
</span></span><span><span>    log.<span>WithError</span>(err).<span>Error</span>(<span>&#34;Received invalid job&#34;</span>)
</span></span><span><span>    <span>continue</span>
</span></span><span><span>  }
</span></span><span><span>
</span></span><span><span>  <span>go</span> job.<span>run</span>(ctx, WarmVMs)
</span></span><span><span>}
</span></span></code></pre></div><p>The <code>newJobQueue</code> function will:</p>
<ul>
<li>connect to the AMQP endpoint</li>
<li>open a channel</li>
<li>declare an exchange (<code>jobs_ex</code>)</li>
<li>declare a queue (<code>jobs_q</code>)</li>
<li>bind the queue to the exchange (<code>jobs_q</code> -&gt; <code>jobs_ex</code> using the <code>jobs_rk</code> routing key)</li>
<li>start consuming messages from the queue and return a <code>&lt;-chan amqp.Delivery</code> channel</li>
</ul>
<p>When the worker receives a job, it launches a handler in a goroutine: <code>go job.run(ctx, WarmVMs)</code>. But what is <code>WarmVMs</code>?</p>
<p>Earlier in the <code>main()</code> function, the worker created a buffered channel of size 10 and launches a pool handler.</p>
<div><pre tabindex="0"><code data-lang="go"><span><span><span>type</span> runningFirecracker <span>struct</span> {
</span></span><span><span>	vmmCtx    context.Context
</span></span><span><span>	vmmCancel context.CancelFunc
</span></span><span><span>	vmmID     <span>string</span>
</span></span><span><span>	machine   <span>*</span>firecracker.Machine
</span></span><span><span>	ip        net.IP
</span></span><span><span>}
</span></span><span><span>
</span></span><span><span><span>// in main()
</span></span></span><span><span><span></span>WarmVMs <span>:=</span> <span>make</span>(<span>chan</span> runningFirecracker, <span>10</span>)
</span></span><span><span><span>go</span> <span>fillVMPool</span>(ctx, WarmVMs)
</span></span></code></pre></div><p>Even if microVMs are fast to create and start, it will still take few seconds (in my case, at least). Since I want the user to wait as little as possible, I decided to have a pool of “warm” microVMs that are ready to use.</p>
<p>The pool handler is simply an infinite loop in a goroutine:</p>
<div><pre tabindex="0"><code data-lang="go"><span><span><span>func</span> <span>fillVMPool</span>(ctx context.Context, WarmVMs <span>chan</span><span>&lt;-</span> runningFirecracker) {
</span></span><span><span>	<span>for</span> {
</span></span><span><span>		<span>select</span> {
</span></span><span><span>		<span>case</span> <span>&lt;-</span>ctx.<span>Done</span>():
</span></span><span><span>			<span>// Program is stopping, WarmVMs will be cleaned up, bye
</span></span></span><span><span><span></span>			<span>return</span>
</span></span><span><span>		<span>default</span>:
</span></span><span><span>			vm, err <span>:=</span> <span>createAndStartVM</span>(ctx)
</span></span><span><span>			<span>if</span> err <span>!=</span> <span>nil</span> {
</span></span><span><span>				log.<span>Error</span>(<span>&#34;failed to create VMM&#34;</span>)
</span></span><span><span>				time.<span>Sleep</span>(time.Second)
</span></span><span><span>				<span>continue</span>
</span></span><span><span>			}
</span></span><span><span>
</span></span><span><span>			log.<span>WithField</span>(<span>&#34;ip&#34;</span>, vm.ip).<span>Info</span>(<span>&#34;New VM created and started&#34;</span>)
</span></span><span><span>
</span></span><span><span>			<span>// Don&#39;t wait forever, if the VM is not available after 10s, move on
</span></span></span><span><span><span></span>			ctx, cancel <span>:=</span> context.<span>WithTimeout</span>(ctx, <span>10</span><span>*</span>time.Second)
</span></span><span><span>			<span>defer</span> <span>cancel</span>()
</span></span><span><span>
</span></span><span><span>			err = <span>waitForVMToBoot</span>(ctx, vm.ip)
</span></span><span><span>			<span>if</span> err <span>!=</span> <span>nil</span> {
</span></span><span><span>				log.<span>WithError</span>(err).<span>Info</span>(<span>&#34;VM not ready yet&#34;</span>)
</span></span><span><span>				vm.<span>vmmCancel</span>()
</span></span><span><span>				<span>continue</span>
</span></span><span><span>			}
</span></span><span><span>
</span></span><span><span>			<span>// Add the new microVM to the pool.
</span></span></span><span><span><span></span>			<span>// If the pool is full, this line will block until a slot is available.
</span></span></span><span><span><span></span>			WarmVMs <span>&lt;-</span> <span>*</span>vm
</span></span><span><span>		}
</span></span><span><span>	}
</span></span><span><span>}
</span></span></code></pre></div><p>The microVM is added to the pool once it is “ready”. It uses the health endpoint of the agent to know when that’s the case:</p>
<div><pre tabindex="0"><code data-lang="go"><span><span><span>func</span> <span>waitForVMToBoot</span>(ctx context.Context, ip net.IP) <span>error</span> {
</span></span><span><span>	<span>// Query the agent until it provides a valid response
</span></span></span><span><span><span></span>	req.<span>SetTimeout</span>(<span>500</span> <span>*</span> time.Millisecond)
</span></span><span><span>	<span>for</span> {
</span></span><span><span>		<span>select</span> {
</span></span><span><span>		<span>case</span> <span>&lt;-</span>ctx.<span>Done</span>():
</span></span><span><span>			<span>// Timeout
</span></span></span><span><span><span></span>			<span>return</span> ctx.<span>Err</span>()
</span></span><span><span>		<span>default</span>:
</span></span><span><span>			res, err <span>:=</span> req.<span>Get</span>(<span>&#34;http://&#34;</span> <span>+</span> ip.<span>String</span>() <span>+</span> <span>&#34;:8080/health&#34;</span>)
</span></span><span><span>			<span>if</span> err <span>!=</span> <span>nil</span> {
</span></span><span><span>				log.<span>WithError</span>(err).<span>Info</span>(<span>&#34;VM not ready yet&#34;</span>)
</span></span><span><span>				time.<span>Sleep</span>(time.Second)
</span></span><span><span>				<span>continue</span>
</span></span><span><span>			}
</span></span><span><span>
</span></span><span><span>			<span>if</span> res.<span>Response</span>().StatusCode <span>!=</span> <span>200</span> {
</span></span><span><span>				time.<span>Sleep</span>(time.Second)
</span></span><span><span>				log.<span>Info</span>(<span>&#34;VM not ready yet&#34;</span>)
</span></span><span><span>			} <span>else</span> {
</span></span><span><span>				log.<span>WithField</span>(<span>&#34;ip&#34;</span>, ip).<span>Info</span>(<span>&#34;VM agent ready&#34;</span>)
</span></span><span><span>				<span>return</span> <span>nil</span>
</span></span><span><span>			}
</span></span><span><span>			time.<span>Sleep</span>(time.Second)
</span></span><span><span>		}
</span></span><span><span>	}
</span></span><span><span>}
</span></span></code></pre></div><p>If the agent is reachable, it means the microVM is started, network is up, and the agent is ready to received code execution requests.</p>
<p>To start a microVM, the worker does a bunch of things:</p>
<ul>
<li>Copy the “golden image” of the rootfs to a temp file (dedicated to the microVM)</li>
<li>Set up the config (<code>firecracker.Config</code>)</li>
<li>Create a <code>firecracker.Machine</code></li>
<li>Start the machine, aka the VMM instance.</li>
</ul>
<p>Then it returns a <code>runningFirecracker</code> struct that will be stored in the channel. The struct contains a bunch of things such as:</p>
<ul>
<li>the IP address of the VM, which will be used to communicate with the agent inside it</li>
<li>the <code>firecracker.Machine</code> and context, which will be used to destroy the VM once the job is done or when the context is cancelled</li>
</ul>
<div><pre tabindex="0"><code data-lang="go"><span><span><span>// Create a VMM with a given set of options and start the VM
</span></span></span><span><span><span></span><span>func</span> <span>createAndStartVM</span>(ctx context.Context) (<span>*</span>runningFirecracker, <span>error</span>) {
</span></span><span><span>	vmmID <span>:=</span> xid.<span>New</span>().<span>String</span>()
</span></span><span><span>
</span></span><span><span>	<span>copy</span>(<span>&#34;../agent/rootfs.ext4&#34;</span>, <span>&#34;/tmp/rootfs-&#34;</span><span>+</span>vmmID<span>+</span><span>&#34;.ext4&#34;</span>)
</span></span><span><span>
</span></span><span><span>	fcCfg, err <span>:=</span> <span>getFirecrackerConfig</span>(vmmID)
</span></span><span><span>	<span>if</span> err <span>!=</span> <span>nil</span> {
</span></span><span><span>		log.<span>Errorf</span>(<span>&#34;Error: %s&#34;</span>, err)
</span></span><span><span>		<span>return</span> <span>nil</span>, err
</span></span><span><span>	}
</span></span><span><span>
</span></span><span><span>  	<span>// ... more boring stuff
</span></span></span><span><span><span></span>
</span></span><span><span>  	vmmCtx, vmmCancel <span>:=</span> context.<span>WithCancel</span>(ctx)
</span></span><span><span>
</span></span><span><span>	m, err <span>:=</span> firecracker.<span>NewMachine</span>(vmmCtx, fcCfg, machineOpts<span>...</span>)
</span></span><span><span>	<span>if</span> err <span>!=</span> <span>nil</span> {
</span></span><span><span>		<span>vmmCancel</span>()
</span></span><span><span>		<span>return</span> <span>nil</span>, fmt.<span>Errorf</span>(<span>&#34;failed creating machine: %s&#34;</span>, err)
</span></span><span><span>	}
</span></span><span><span>
</span></span><span><span>	<span>if</span> err <span>:=</span> m.<span>Start</span>(vmmCtx); err <span>!=</span> <span>nil</span> {
</span></span><span><span>		<span>vmmCancel</span>()
</span></span><span><span>		<span>return</span> <span>nil</span>, fmt.<span>Errorf</span>(<span>&#34;failed to start machine: %v&#34;</span>, err)
</span></span><span><span>	}
</span></span><span><span>
</span></span><span><span>	log.<span>WithField</span>(<span>&#34;ip&#34;</span>, m.Cfg.NetworkInterfaces[<span>0</span>].StaticConfiguration.IPConfiguration.IPAddr.IP).<span>Info</span>(<span>&#34;machine started&#34;</span>)
</span></span><span><span>
</span></span><span><span>	<span>return</span> <span>&amp;</span>runningFirecracker{
</span></span><span><span>		vmmCtx:    vmmCtx,
</span></span><span><span>		vmmCancel: vmmCancel,
</span></span><span><span>		vmmID:     vmmID,
</span></span><span><span>		machine:   m,
</span></span><span><span>		ip:        m.Cfg.NetworkInterfaces[<span>0</span>].StaticConfiguration.IPConfiguration.IPAddr.IP,
</span></span><span><span>	}, <span>nil</span>
</span></span></code></pre></div><p>The <code>firecracker.Config</code> contains the configuration of the VM: Kernel, storage, network, resources, etc. The code above and below was adapted from the source code of the <code>firectl</code> project, which the best example of the Go SDK usage I found. Luckily, the only SDK available for Firecracker is in Go, which is the language I’m the most comfortable with.</p>
<div><pre tabindex="0"><code data-lang="go"><span><span><span>func</span> <span>getFirecrackerConfig</span>(vmmID <span>string</span>) (firecracker.Config, <span>error</span>) {
</span></span><span><span>	socket <span>:=</span> <span>getSocketPath</span>(vmmID)
</span></span><span><span>	<span>return</span> firecracker.Config{
</span></span><span><span>		SocketPath:      socket,
</span></span><span><span>		KernelImagePath: <span>&#34;../../linux/vmlinux&#34;</span>,
</span></span><span><span>		LogPath:         fmt.<span>Sprintf</span>(<span>&#34;%s.log&#34;</span>, socket),
</span></span><span><span>		Drives: []models.Drive{{
</span></span><span><span>			DriveID:      firecracker.<span>String</span>(<span>&#34;1&#34;</span>),
</span></span><span><span>			PathOnHost:   firecracker.<span>String</span>(<span>&#34;/tmp/rootfs-&#34;</span> <span>+</span> vmmID <span>+</span> <span>&#34;.ext4&#34;</span>),
</span></span><span><span>			IsRootDevice: firecracker.<span>Bool</span>(<span>true</span>),
</span></span><span><span>			IsReadOnly:   firecracker.<span>Bool</span>(<span>false</span>),
</span></span><span><span>			RateLimiter: firecracker.<span>NewRateLimiter</span>(
</span></span><span><span>				<span>// bytes/s
</span></span></span><span><span><span></span>				models.TokenBucket{
</span></span><span><span>					OneTimeBurst: firecracker.<span>Int64</span>(<span>1024</span> <span>*</span> <span>1024</span>), <span>// 1 MiB/s
</span></span></span><span><span><span></span>					RefillTime:   firecracker.<span>Int64</span>(<span>500</span>),         <span>// 0.5s
</span></span></span><span><span><span></span>					Size:         firecracker.<span>Int64</span>(<span>1024</span> <span>*</span> <span>1024</span>),
</span></span><span><span>				},
</span></span><span><span>				<span>// ops/s
</span></span></span><span><span><span></span>				models.TokenBucket{
</span></span><span><span>					OneTimeBurst: firecracker.<span>Int64</span>(<span>100</span>),  <span>// 100 iops
</span></span></span><span><span><span></span>					RefillTime:   firecracker.<span>Int64</span>(<span>1000</span>), <span>// 1s
</span></span></span><span><span><span></span>					Size:         firecracker.<span>Int64</span>(<span>100</span>),
</span></span><span><span>				}),
</span></span><span><span>		}},
</span></span><span><span>		NetworkInterfaces: []firecracker.NetworkInterface{{
</span></span><span><span>			<span>// Use CNI to get dynamic IP
</span></span></span><span><span><span></span>			CNIConfiguration: <span>&amp;</span>firecracker.CNIConfiguration{
</span></span><span><span>				NetworkName: <span>&#34;fcnet&#34;</span>,
</span></span><span><span>				IfName:      <span>&#34;veth0&#34;</span>,
</span></span><span><span>			},
</span></span><span><span>		}},
</span></span><span><span>		MachineCfg: models.MachineConfiguration{
</span></span><span><span>			VcpuCount:  firecracker.<span>Int64</span>(<span>1</span>),
</span></span><span><span>			HtEnabled:  firecracker.<span>Bool</span>(<span>true</span>),
</span></span><span><span>			MemSizeMib: firecracker.<span>Int64</span>(<span>256</span>),
</span></span><span><span>		},
</span></span><span><span>	}, <span>nil</span>
</span></span><span><span>}
</span></span></code></pre></div><p>A few things to note:</p>
<ul>
<li>There is a native rate limiter that we can use to limit the number of disk ops per second and/or disk bandwidth. In our case, benchmarked code should not use the disk, so we can aggressively limit disk usage to protect the host.</li>
<li>The microVMs will be limited to 1 CPU thread and 256 MiB of memory. This should be more than enough for our use case. Conveniently, Firecracker supports soft-allocation and CPU/memory oversubscription, so the VMs waiting in the pool won’t waste much resources.</li>
</ul>
<p>Even networking is easy thanks to <a href="https://www.cni.dev/">CNI</a> plugins. On the host, a simple config is needed in <code>/etc/cni/conf.d/fcnet.conflist</code>:</p>
<div><pre tabindex="0"><code data-lang="json"><span><span>{
</span></span><span><span>  <span>&#34;name&#34;</span>: <span>&#34;fcnet&#34;</span>,
</span></span><span><span>  <span>&#34;cniVersion&#34;</span>: <span>&#34;0.4.0&#34;</span>,
</span></span><span><span>  <span>&#34;plugins&#34;</span>: [
</span></span><span><span>    {
</span></span><span><span>      <span>&#34;type&#34;</span>: <span>&#34;ptp&#34;</span>,
</span></span><span><span>      <span>&#34;ipMasq&#34;</span>: <span>true</span>,
</span></span><span><span>      <span>&#34;ipam&#34;</span>: {
</span></span><span><span>        <span>&#34;type&#34;</span>: <span>&#34;host-local&#34;</span>,
</span></span><span><span>        <span>&#34;subnet&#34;</span>: <span>&#34;192.168.127.0/24&#34;</span>,
</span></span><span><span>        <span>&#34;resolvConf&#34;</span>: <span>&#34;/etc/resolv.conf&#34;</span>
</span></span><span><span>      }
</span></span><span><span>    },
</span></span><span><span>    {
</span></span><span><span>      <span>&#34;type&#34;</span>: <span>&#34;tc-redirect-tap&#34;</span>
</span></span><span><span>    }
</span></span><span><span>  ]
</span></span><span><span>}
</span></span></code></pre></div><p>With the following CNI plugins binaries in <code>/opt/cni/bin</code>:</p>
<p>From <a href="https://github.com/containernetworking/plugins">containernetworking/plugins</a>:</p>
<ul>
<li><code>host-local</code>: Maintains a local database of allocated IPs</li>
<li><code>ptp</code>: Creates a veth pair</li>
</ul>
<p>From: <a href="https://github.com/awslabs/tc-redirect-tap">awslabs/tc-redirect-tap</a></p>
<ul>
<li><code>tc-redirect-tap</code>: adapt pre-existing CNI plugins/configuration to a tap device</li>
</ul>
<p>In my case, I didn’t want the microVM to have internet access, so I simply set <code>ipMasq</code> to <code>false</code> in the config above. This will disable the IP masquerade on the host for this network.</p>
<p>In the <code>main()</code> function earlier, the received job is sent to a goroutine with <code>go job.run(ctx, WarmVMs)</code>. This is what happens then:</p>
<div><pre tabindex="0"><code data-lang="go"><span><span><span>func</span> (job benchJob) <span>run</span>(ctx context.Context, WarmVMs <span>&lt;-</span><span>chan</span> runningFirecracker) {
</span></span><span><span>	log.<span>WithField</span>(<span>&#34;job&#34;</span>, job).<span>Info</span>(<span>&#34;Handling job&#34;</span>)
</span></span><span><span>
</span></span><span><span>	<span>// Set status in RabbitMQ: received
</span></span></span><span><span><span></span>	err <span>:=</span> q.<span>setjobReceived</span>(ctx, job)
</span></span><span><span>	<span>if</span> err <span>!=</span> <span>nil</span> {
</span></span><span><span>		log.<span>WithError</span>(err).<span>Error</span>(<span>&#34;Could not set job received&#34;</span>)
</span></span><span><span>		q.<span>setjobFailed</span>(ctx, job, agentExecRes{Error: err.<span>Error</span>()})
</span></span><span><span>		<span>return</span>
</span></span><span><span>	}
</span></span><span><span>
</span></span><span><span>	<span>// Get a ready-to-use microVM from the pool
</span></span></span><span><span><span></span>	vm <span>:=</span> <span>&lt;-</span>WarmVMs
</span></span><span><span>
</span></span><span><span>	<span>// Defer cleanup of VM and VMM
</span></span></span><span><span><span></span>	<span>go</span> <span>func</span>() {
</span></span><span><span>		<span>defer</span> vm.<span>vmmCancel</span>()
</span></span><span><span>		vm.machine.<span>Wait</span>(vm.vmmCtx)
</span></span><span><span>	}()
</span></span><span><span>	<span>defer</span> vm.<span>shutDown</span>()
</span></span><span><span>
</span></span><span><span>	<span>var</span> reqJSON []<span>byte</span>
</span></span><span><span>
</span></span><span><span>	reqJSON, err = json.<span>Marshal</span>(agentRunReq{
</span></span><span><span>		ID:       job.ID,
</span></span><span><span>		Language: job.Language,
</span></span><span><span>		Code:     job.Code,
</span></span><span><span>	})
</span></span><span><span>	<span>if</span> err <span>!=</span> <span>nil</span> {
</span></span><span><span>		log.<span>WithError</span>(err).<span>Error</span>(<span>&#34;Failed to marshal JSON request&#34;</span>)
</span></span><span><span>		q.<span>setjobFailed</span>(ctx, job, agentExecRes{Error: err.<span>Error</span>()})
</span></span><span><span>		<span>return</span>
</span></span><span><span>	}
</span></span><span><span>
</span></span><span><span>	<span>// Set status in RabbitMQ: running
</span></span></span><span><span><span></span>	err = q.<span>setjobRunning</span>(ctx, job)
</span></span><span><span>	<span>if</span> err <span>!=</span> <span>nil</span> {
</span></span><span><span>		log.<span>WithError</span>(err).<span>Error</span>(<span>&#34;Could not set job running&#34;</span>)
</span></span><span><span>		q.<span>setjobFailed</span>(ctx, job, agentExecRes{Error: err.<span>Error</span>()})
</span></span><span><span>		<span>return</span>
</span></span><span><span>	}
</span></span><span><span>
</span></span><span><span>	<span>// Send code to the agent inside the microVM
</span></span></span><span><span><span></span>	<span>var</span> httpRes <span>*</span>http.Response
</span></span><span><span>	<span>var</span> agentRes agentExecRes
</span></span><span><span>
</span></span><span><span>	httpRes, err = http.<span>Post</span>(<span>&#34;http://&#34;</span><span>+</span>vm.ip.<span>String</span>()<span>+</span><span>&#34;:8080/run&#34;</span>, <span>&#34;application/json&#34;</span>, bytes.<span>NewBuffer</span>(reqJSON))
</span></span><span><span>	<span>if</span> err <span>!=</span> <span>nil</span> {
</span></span><span><span>		log.<span>WithError</span>(err).<span>Error</span>(<span>&#34;Failed to request execution to agent&#34;</span>)
</span></span><span><span>		q.<span>setjobFailed</span>(ctx, job, agentExecRes{Error: err.<span>Error</span>()})
</span></span><span><span>		<span>return</span>
</span></span><span><span>	}
</span></span><span><span>	json.<span>NewDecoder</span>(httpRes.Body).<span>Decode</span>(<span>&amp;</span>agentRes)
</span></span><span><span>	log.<span>WithField</span>(<span>&#34;result&#34;</span>, agentRes).<span>Info</span>(<span>&#34;Job execution finished&#34;</span>)
</span></span><span><span>	<span>if</span> httpRes.StatusCode <span>!=</span> <span>200</span> {
</span></span><span><span>		log.<span>WithFields</span>(log.Fields{
</span></span><span><span>			<span>&#34;httpRes&#34;</span>:  httpRes,
</span></span><span><span>			<span>&#34;agentRes&#34;</span>: agentRes,
</span></span><span><span>			<span>&#34;reqJSON&#34;</span>:  <span>string</span>(reqJSON),
</span></span><span><span>		}).<span>Error</span>(<span>&#34;Failed to compile and run code&#34;</span>)
</span></span><span><span>		q.<span>setjobFailed</span>(ctx, job, agentRes)
</span></span><span><span>		<span>return</span>
</span></span><span><span>	}
</span></span><span><span>
</span></span><span><span>	<span>// Set status in RabbitMQ: done + result
</span></span></span><span><span><span></span>	err = q.<span>setjobResult</span>(ctx, job, agentRes)
</span></span><span><span>	<span>if</span> err <span>!=</span> <span>nil</span> {
</span></span><span><span>		q.<span>setjobFailed</span>(ctx, job, agentExecRes{Error: err.<span>Error</span>()})
</span></span><span><span>	}
</span></span><span><span>}
</span></span></code></pre></div><p>The job handler send status updates to another RabbitMQ queue and basically forwards the payload to the agent. The flow looks like this:</p>
<div><pre tabindex="0"><code data-lang="fallback"><span><span>			┌────────────────────────────────────────────────────────┐
</span></span><span><span>			│                                                        │
</span></span><span><span>			│                                ┌───────► Done          │
</span></span><span><span>			│    Reveived  ────►  Running ───┤                       │
</span></span><span><span>			│                                └───────► Failed        │
</span></span><span><span>			│        │                 │                             │
</span></span><span><span>			│        │                 │                             │
</span></span><span><span>			│        └──►  Failed      └──►  Failed                  │
</span></span><span><span>			│                                                        │
</span></span><span><span>			└────────────────────────────────────────────────────────┘
</span></span></code></pre></div><p>If the job fails during the execution phase, the stdout/stderr output is also returned.</p>
<p>On the NestJS API side, there is a subscriber for <code>jobs_status_*</code>:</p>
<div><pre tabindex="0"><code data-lang="ts"><span><span><span>@RabbitSubscribe</span>({
</span></span><span><span>	exchange<span>:</span> <span>&#39;jobs_status_ex&#39;</span>,
</span></span><span><span>	routingKey<span>:</span> <span>&#39;jobs_status_rk&#39;</span>,
</span></span><span><span>	queue<span>:</span> <span>&#39;jobs_status_q&#39;</span>,
</span></span><span><span>})
</span></span><span><span><span>public</span> <span>async</span> handleJobStatus(msg: <span>string</span>)<span>:</span> Promise&lt;<span>void</span>&gt; {
</span></span><span><span>	<span>const</span> jobSerializer <span>=</span> <span>new</span> TypedJSON(JobStatusDTO);
</span></span><span><span>	<span>const</span> jobStatus <span>=</span> jobSerializer.parse(msg);
</span></span><span><span>
</span></span><span><span>	<span>if</span> (jobStatus) {
</span></span><span><span>		<span>// Save in DB
</span></span></span><span><span><span></span>		<span>await</span> <span>this</span>.setStatus({...jobStatus});
</span></span><span><span>	}
</span></span><span><span>}
</span></span></code></pre></div><p>On the worker side, once the job is done, the defered shutdown function is called:</p>
<div><pre tabindex="0"><code data-lang="go"><span><span><span>func</span> (vm runningFirecracker) <span>shutDown</span>() {
</span></span><span><span>	log.<span>WithField</span>(<span>&#34;ip&#34;</span>, vm.ip).<span>Info</span>(<span>&#34;stopping&#34;</span>)
</span></span><span><span>	vm.machine.<span>StopVMM</span>()
</span></span><span><span>	err <span>:=</span> os.<span>Remove</span>(vm.machine.Cfg.SocketPath)
</span></span><span><span>	<span>if</span> err <span>!=</span> <span>nil</span> {
</span></span><span><span>		log.<span>WithError</span>(err).<span>Error</span>(<span>&#34;Failed to delete firecracker socket&#34;</span>)
</span></span><span><span>	}
</span></span><span><span>	err = os.<span>Remove</span>(<span>&#34;/tmp/rootfs-&#34;</span> <span>+</span> vm.vmmID <span>+</span> <span>&#34;.ext4&#34;</span>)
</span></span><span><span>	<span>if</span> err <span>!=</span> <span>nil</span> {
</span></span><span><span>		log.<span>WithError</span>(err).<span>Error</span>(<span>&#34;Failed to delete firecracker rootfs&#34;</span>)
</span></span><span><span>	}
</span></span><span><span>}
</span></span></code></pre></div><p>At this point, a new microVM has already been added to the pool. Indeed, the worker gets a VM from the pool earlier with <code>vm := &lt;-WarmVMs</code>. Since the pool handler is blocking on this channel, it will already have a new microVM ready and will add it right after the “pop” from the pool.</p>
<h4 id="worker-architecture">Worker architecture</h4>
<p>The overall architecture of the worker can be summed up as follows:</p>
<figure><img src="https://stanislas.blog/2021/08/firecracker/codebench-worker-architecture.png" sizes="(min-width: 1080px) 694px, (min-width: 780px) calc(75vw - 3rem), calc(100vw - 3rem)" width="2860" height="1894" loading="lazy" srcset="
        
          
            ,/2021/08/firecracker/codebench-worker-architecture_hud0ac959d0fe12b66f15ed0aae0fca912_103510_960x0_resize_linear_3.png 960w
          
          
            ,/2021/08/firecracker/codebench-worker-architecture_hud0ac959d0fe12b66f15ed0aae0fca912_103510_1280x0_resize_linear_3.png 1280w
          
        
        " data-zoom-src="codebench-worker-architecture.png" alt="Keep in mind the the Job Handler and microVM parts are dynamically created and destroyed."/><figcaption>
<p>Keep in mind the the <code>Job Handler</code> and <code>microVM</code> parts are dynamically created and destroyed.</p>
</figcaption>
</figure>
<p>Our production infrastructure for this project was hosted on Digital Ocean. Since their droplets support nested virtualization, we were able to run the Firecracker microVMs inside another VM.</p>
<h3 id="complete-execution-flow">Complete execution flow</h3>
<p>Here is an attempt to sum up the execution flow of a code submission sequentially:</p>
<table>
<thead>
<tr>
<th>Component</th>
<th>Action</th>
</tr>
</thead>
<tbody>
<tr>
<td><code>Worker</code></td>
<td>Launch and maintain pool of X prebooted microVMs in the background</td>
</tr>
<tr>
<td><code>Worker</code></td>
<td>Bind to RabbitMQ queue <code>jobs_q</code> on <code>jobs_ex</code> exchange and <code>jobs_rk</code> routing key</td>
</tr>
<tr>
<td><code>API</code></td>
<td>Bind to RabbitMQ queue <code>jobs_status_q</code> on <code>jobs_status_ex</code> exchange and <code>jobs_status_rk</code> routing key</td>
</tr>
<tr>
<td><code>Front</code></td>
<td><code>POST /submissions</code></td>
</tr>
<tr>
<td><code>Front</code></td>
<td>Poll <code>GET /submissions/:id</code> every 500 ms</td>
</tr>
<tr>
<td><code>API</code></td>
<td>Send job to RabbitMQ on <code>jobs_ex</code> direct exchange with <code>jobs_rk</code> routing key.</td>
</tr>
<tr>
<td><code>Worker</code></td>
<td>Receive job, get warm microVM from pool, send job to agent in microVM</td>
</tr>
<tr>
<td><code>Agent</code></td>
<td>Compile/Run code, return result</td>
</tr>
<tr>
<td><code>Worker</code></td>
<td>During two previous steps, send status of jobs on <code>jobs_status_ex</code> exchange with <code>jobs_status_rk</code> routing key, including the final result</td>
</tr>
<tr>
<td><code>API</code></td>
<td>Receive each new status on <code>jobs_status_q</code>, and insert them into DB and in-memory cache, so that the polling can get the latest status.</td>
</tr>
<tr>
<td><code>Front</code></td>
<td>Get the final result, stop polling and display it.</td>
</tr>
</tbody>
</table>
<h2 id="possible-improvements">Possible improvements</h2>
<p>Overall, I’m happy with the results, and I achieved what I needed for the project. However, there are several things that could be improved.</p>
<h3 id="jailer">Jailer</h3>
<p>Using <a href="https://github.com/firecracker-microvm/firecracker/blob/main/docs/jailer.md">jailer</a> would be great to further isolate the Firecracker process and provide an additional security barrier. If the project was meant to be used in production, I would definitely look into that.</p>
<h3 id="optimise-rootfs-usagecopying">Optimise rootfs usage/copying</h3>
<p>Copying the 1 GB rootfs before starting each microVM slows down the creating process by a few seconds and waste disk resources. An improvement could be to use a filesystem on the host that support copy-on-write to limit the overhead. That being said, copying the entire rootfs is still overkill. It might not be needed in the first place. The agent writes the code to files in <code>/tmp</code>, but this could easily be done in a tmpfs. Thus, a solution would be to use the same rootfs in a read-only mode. That would remove the need to copy it, and would not decrease isolation.</p>
<p>The docs on <a href="https://github.com/firecracker-microvm/firecracker-containerd/blob/main/docs/root-filesystem.md">root filesystem</a> says in the requirements:</p>
<blockquote>
<p>(If sharing the root filesystem image among multiple VMs) Ability to run successfully from a read-only device, in order to prevent a VM from manipulating the filesystem in use by another VM.</p>
</blockquote>
<p>So that option looks feasible.</p>
<p>AWS says they are able to start Firecracker microVMs in few hundreds of milliseconds, where in my case it takes a few seconds. I suppose this is because I’m using a fully fledged Linux distribution with an init system and all kind of services. Cleaning up the Alpine image or using a fully custom guest image could result in significant improvements in that regard.</p>

<p>To also raises the question of reusing microVMs. The code submissions on Codebench are all meant to be public, so the requirements of isolation the workloads between each other are not as important on platforms such as AWS Lambda or Koyeb. That being said, there is still the requirement of resource isolation, so sharing microVMs between users with the current architecture won’t really fit.</p>
<p>Another option could be to dedicate a microVM to each user. That would be the best compromise, except that it would mean adding logic to assign a VM to each user: when the worker receives some code, it would create a microVM or forward it to the existing microVM for the user. Then, to prevent wasting resources (even if a single microVM with the agent doesn’t consume much memory), the worker would have to destroy the microVM if the user is not actively using it anymore. Maybe some kind of idle timeout would do it?</p>
<p>Also, under a high number of simultaneous code submissions, the worker would consume more microVMs that it is creating, even if it has resources available. An easy solution would be to launch multiple “pool handlers”, or to launch VMM creations in goroutines.</p>
<h3 id="recycle-microvms">Recycle microVMs</h3>
<p>To reuse VMs, a friend of mine suggested using a technique implemented in <a href="https://github.com/pragma-/pbot">PBot</a>, an IRC bot. The bot supports executing user-submitted code in a VM, and <a href="https://github.com/pragma-/pbot/blob/dfae9bebc0e972f4e6251cd629b96b4e57928165/modules/compiler_vm/compiler_server.pl#L48">restores the VM to a clean snapshot after each execution</a>.</p>
<p>Luckily, Firecracker has a <a href="https://github.com/firecracker-microvm/firecracker/blob/main/docs/snapshotting/snapshot-support.md">snapshotting feature</a> which looks very promising:</p>
<blockquote>
<p>The design allows sharing of memory pages and read only disks between multiple microVMs. When loading a snapshot, instead of loading at resume time the full contents from file to memory, Firecracker creates a <a href="http://man7.org/linux/man-pages/man2/mmap.2.html">MAP_PRIVATE mapping</a> of the memory file, resulting in runtime on-demand loading of memory pages. Any subsequent memory writes go to a copy-on-write anonymous memory mapping. This has the advantage of very fast snapshot loading times, but comes with the cost of having to keep the guest memory file around for the entire lifetime of the resumed microVM.</p>
</blockquote>
<blockquote>
<p>The Firecracker snapshot create/resume performance depends on the memory size, vCPU count and emulated devices count. The Firecracker CI runs snapshots tests on AWS <strong>m5d.metal</strong> instances for Intel and on AWS <strong>m6g.metal</strong> for ARM. The baseline for snapshot resume latency target on Intel is under <strong>8ms</strong> with 5ms p90, and on ARM is under <strong>3ms</strong> for a microVM with the following specs: 2vCPU/512MB/1 block/1 net device.</p>
</blockquote>
<p>So that could also be a solution worth looking at.</p>
<h2 id="conclusion">Conclusion</h2>
<p>It was a fun project to work and I learned a lot through hands-on experience with Firecracker.
I didn’t encounter any issue with Firecracker itself. The documentation is surprisingly detailed and helpful. The only bug I could find was a <a href="https://github.com/firecracker-microvm/firectl/commit/365e8ffe9549d6fd9a521fec1eddfea228ac965c">teeny tiny one in firectl</a>.</p>
<p>Using Go was a pleasure: I was able to iterate quickly and the language didn’t get in my way.</p>
<p>I enjoyed researching a solution of this use-case, which is quite different from the major Firecracker users, namely serverless platforms (from what I can tell).</p>
<p>Hopefully this post will inspire others to build things on top of Firecracker. Another post on Firecracker which helped me get started is <a href="https://jvns.ca/blog/2021/01/23/firecracker--start-a-vm-in-less-than-a-second/">this one</a> by Julia Evans, which shows concrete examples of the Go SDK.</p>
<p>If you’re interested, the full code is available on <a href="https://github.com/codebench-dev">GitHub</a>. Cheers to my mate Gwendal which I worked with on this project!</p>
</div></div>
  </body>
</html>
