<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.kolide.com/blog/github-copilot-isn-t-worth-the-risk">Original</a>
    <h1>GitHub Copilot isn&#39;t worth the risk</h1>
    
    <div id="readability-page-1" class="page"><div>
          <p>On November 3rd programmer and lawyer Matthew Butterick, along with the
Joseph Saveri Law Firm, filed a class action lawsuit against GitHub, Microsoft
(its parent company), and OpenAI.</p>

<p><a href="https://githubcopilotlitigation.com/" target="_blank">The lawsuit</a>, filed “on behalf of a
pro­posed class of pos­sibly mil­lions of GitHub users,” is directed at GitHub
Copilot, an AI-powered tool that works as a sophisticated autocomplete for
developers. Developers who install Copilot as an IDE extension can enter
natural language prompts and Copilot will respond with code suggestions in
dozens of programming languages.</p>

<p>GitHub CEO <a href="https://www.cnbc.com/2022/10/14/microsoft-ai-leaps-ahead-heres-what-its-human-leader-thinks-about-it.html" target="_blank">Thomas Dohmke has touted</a>
Copilot’s ability to eliminate up to 40% of a developer’s workload by making
suggestions for boilerplate code, thus saving developers tedious hours of
research and trial-and-error.</p>

<p>But Butterick and other Copilot critics charge that many of Copilot’s
suggestions aren’t “boilerplate” at all; they bear the unmistakable
fingerprints of their original authors, because Copilot was “trained” on
GitHub’s repositories of public and open source code.</p>

<p>This lawsuit–and the larger debate over Copilot–raises a myriad of issues:
technological, legal, ethical, even existential.</p>

<p>For example:</p>

<ul>
<li><p><em>What does it mean for an AI to “learn?”</em></p></li>
<li><p><em>Are AI tools like Copilot ushering in a new era of innovation, or merely
eliminating human labor and creativity?</em></p></li>
<li><p><em>Is code more analogous to art or to mathematics? And does the answer impact
how it should be treated under the law?</em></p></li>
</ul>

<p>These questions are endlessly debatable and we’ll touch on each of them in
this article.</p>

<p>But there’s a more urgent question that CTOs need to answer now: <strong><em>Should I
allow Copilot at my company?</em></strong> You don’t have much time to mull over your
decision, since <a href="https://twitter.com/github/status/1590400430399688705?s=20&amp;t=C3yd5ooHEAR0QhGaGM39sw" target="_blank">GitHub just announced</a>
that Copilot For Business will debut in December. Your engineers may already
be asking you to purchase licenses for them.</p>

<p>As you can see from the title, we tend to think you’re better off saying no,
at least while there are so many murky legal issues at play.</p>

<p>Here, we’ll go over the case for and against Copilot, and how you can detect
whether it’s already in use at your organization.</p>

<p>
  As is customary, we will now remind you that none of the following should be
  construed as legal advice, and you should consult with an attorney before
  making legal decisions.
</p>


<p>Butterick has written at length about (what he perceives to be) Copilot’s
existential threat to the open-source community, but his legal case comes
down to the much more straightforward matter of copyright violation. Butterick
et al allege that Copilot’s code suggestions are lifted from open-source
software, and by failing to identify or attribute the original work, it
violates open-source licenses.</p>

<p>The implication, obviously, is that organizations who use Copilot are subject
to the same risk.</p>
<h2 id="the-60-second-guide-to-open-source-licenses"><a href="#the-60-second-guide-to-open-source-licenses"><span><svg viewBox="0 0 24 24" version="1.1" width="24" height="24" aria-hidden="true"><path d="M12.935 11.26a1 1 0 1 1 1.2-1.6 5.336 5.336 0 0 1 .572 8.043l-1.964 1.964a4.536 4.536 0 1 1-6.415-6.414l.5-.5a1 1 0 0 1 1.415 1.414l-.5.5a2.536 2.536 0 0 0 3.585 3.586l1.965-1.965a3.336 3.336 0 0 0-.358-5.028zm-.87 1.476a1 1 0 0 1-1.2 1.6 5.336 5.336 0 0 1-.572-8.043l1.965-1.965a4.536 4.536 0 1 1 6.414 6.415l-.5.5a1 1 0 1 1-1.414-1.415l.5-.5a2.536 2.536 0 1 0-3.586-3.585l-1.964 1.964a3.336 3.336 0 0 0 .357 5.029z"></path></svg></span>The 60-second guide to open source licenses</a></h2>

<p>Open source software licenses are not a monolith, and <a href="https://fossa.com/blog/what-do-open-source-licenses-even-mean/" target="_blank">different licenses
impose different restrictions</a> on how developers can reuse code.
“Permissive” licenses, such as the MIT and Apache Licenses, allow developers to
modify and distribute code as they see fit. On the other end of the spectrum,
“copyleft” licenses such as GPL require any re-use to maintain the original
terms of the license.</p>

<p>There are other important differentiators between open source licenses, but
for our purposes, what matters most is what they all have in common: they all
require developers to provide attribution by including the original copyright
notice. This ensures (among other things) that software doesn’t contain
incompatible licenses. As <a href="https://matthewbutterick.com/chron/this-copilot-is-stupid-and-wants-to-kill-me.html" target="_blank">Butterick explains</a>,
one can’t create software with an MIT license using GPL-licensed code, because
“I can’t pass along to others permis­sions I never had in the first place.”</p>

<p>Copilot strips code of its licenses, so developers who use it run the risk that
they are unwittingly violating copyright. That puts companies at risk of
<a href="https://www.zdnet.com/article/software-freedom-conservancy-wins-big-step-forward-for-open-source-rights/" target="_blank">lawsuits</a>,
particularly from open-source advocacy groups like the <a href="https://sfconservancy.org/" target="_blank">Software Freedom
Conservancy (SFC)</a>.</p>
<h2 id="copilot-competitors"><a href="#copilot-competitors"><span><svg viewBox="0 0 24 24" version="1.1" width="24" height="24" aria-hidden="true"><path d="M12.935 11.26a1 1 0 1 1 1.2-1.6 5.336 5.336 0 0 1 .572 8.043l-1.964 1.964a4.536 4.536 0 1 1-6.415-6.414l.5-.5a1 1 0 0 1 1.415 1.414l-.5.5a2.536 2.536 0 0 0 3.585 3.586l1.965-1.965a3.336 3.336 0 0 0-.358-5.028zm-.87 1.476a1 1 0 0 1-1.2 1.6 5.336 5.336 0 0 1-.572-8.043l1.965-1.965a4.536 4.536 0 1 1 6.414 6.415l-.5.5a1 1 0 1 1-1.414-1.415l.5-.5a2.536 2.536 0 1 0-3.586-3.585l-1.964 1.964a3.336 3.336 0 0 0 .357 5.029z"></path></svg></span>Copilot Competitors</a></h2>

<p>For the record, Copilot is not the only tool that auto-completes code for
developers. But its approach to licenses makes it particularly risky.
<a href="https://www.tabnine.com/code-privacy" target="_blank">Tabnine</a>, for instance, is trained
only on permissive licenses.</p>

<p>Copilot’s competitors also <a href="https://nordcloud.com/tech-community/coding-copilot-ai-autocompletion" target="_blank">have a reputation</a>
for truly sticking to “boilerplate” suggestions. They don’t seem to share
Copilot’s ambitious goals for writing nearly half of a developer’s code, so
they’re less likely to suggest complex logic that can be traced back to a
copyrighted source. Nevertheless, all AI-powered “pair programmers” introduce
a certain amount of risk, and we’re not here to make the case that Copilot is
exponentially more dangerous than the others.</p>
<h2 id="is-copilot-breaking-copyright-law"><a href="#is-copilot-breaking-copyright-law"><span><svg viewBox="0 0 24 24" version="1.1" width="24" height="24" aria-hidden="true"><path d="M12.935 11.26a1 1 0 1 1 1.2-1.6 5.336 5.336 0 0 1 .572 8.043l-1.964 1.964a4.536 4.536 0 1 1-6.415-6.414l.5-.5a1 1 0 0 1 1.415 1.414l-.5.5a2.536 2.536 0 0 0 3.585 3.586l1.965-1.965a3.336 3.336 0 0 0-.358-5.028zm-.87 1.476a1 1 0 0 1-1.2 1.6 5.336 5.336 0 0 1-.572-8.043l1.965-1.965a4.536 4.536 0 1 1 6.414 6.415l-.5.5a1 1 0 1 1-1.414-1.415l.5-.5a2.536 2.536 0 1 0-3.586-3.585l-1.964 1.964a3.336 3.336 0 0 0 .357 5.029z"></path></svg></span>Is Copilot breaking copyright law?</a></h2>

<p>There’s no simple answer to this question because there are no perfect
analogues to the Copilot case. Still, some arguments are easier to dismiss than
others.</p>

<p>Some Copilot defenders maintain that the program’s suggestions are so obvious
and generic that they’re not really copyrightable. But <a href="https://github.com/features/copilot" target="_blank">GitHub’s own website
states</a> that “about 1% of the time, a
suggestion may contain some code snippets longer than ~150 characters that
matches the training set.”</p>

<p>The class action complaint alleges that even code shorter than 150 characters
can still constitute copyright violations, but that “even using GitHub’s own
metric and the most conservative possible criteria, Copilot has violated the
DMCA at least tens of thousands of times.”</p>

<p>There has not yet been a tidal wave of outrage from developers finding their
work on Copilot, but complaints are beginning to surface. In a now-famous
Twitter thread, Professor Tim Davis objected to Copilot churning out large
chunks of his copyrighted code.</p>

<blockquote>
<p lang="en" dir="ltr"><a href="https://twitter.com/github?ref_src=twsrc%5Etfw">@github</a> copilot, with “public code” blocked, emits large chunks of my copyrighted code, with no attribution, no LGPL license. For example, the simple prompt “sparse matrix transpose, cs<em>” produces my cs</em>transpose in CSparse. My code on left, github on right. Not OK. <a href="https://t.co/sqpOThi8nf">pic.twitter.com/sqpOThi8nf</a></p>— Tim Davis (@DocSparse) <a href="https://twitter.com/DocSparse/status/1581461734665367554?ref_src=twsrc%5Etfw">October 16, 2022</a>
</blockquote> 

<p>Butterick et al’s lawsuit lists other examples, including code that bears
significant similarities to sample code from the books <em>Mastering JS</em> and
<em>Think JavaScript</em>. The complaint also notes that, in regurgitating
commonly-used code, Copilot reproduces common mistakes, so its suggestions are
often buggy and inefficient. The plaintiffs allege that this proves Copilot is
not “writing” in any meaningful way–it’s merely copying the code it has
encountered most often.</p>

<p>So far, Microsoft’s defense seems to hang on the idea of “fair use.” Fair use
exempts creators from copyright claims provided their work is sufficiently
transformative. A musician who parodies another artist’s song, for example,
meets the definition of fair use. But it’s far from clear whether that
understanding would apply to Copilot.</p>

<p>Some point to the precedent of <a href="https://www.techtarget.com/searchoracle/news/252498837/Supreme-Court-sides-with-Google-in-Oracle-API-copyright-case" target="_blank">Google v Oracle</a>,
in which the Supreme Court ruled that Google was within its rights to use
Java APIs to build Android’s OS. But APIs are fundamentally built to facilitate
communication between programs, which is a much narrower use case than the
breadth of code at issue here.</p>

<p>Another case that may shed some light on the legality of Copilot doesn’t
concern tech at all. <a href="https://www.artnews.com/art-news/news/andy-warhol-lynn-goldsmith-supreme-court-1234641880/" target="_blank">Andy Warhol Foundation v Goldsmith</a>
concerns a series of portraits by the late painter that were based on the work
of photographer Lynn Goldsmith. SCOTUS recently heard arguments in that case,
but whatever the court ultimately decides, it’s still an imperfect comparison
to Copilot, since code is neither precisely art nor precisely science. Some
functions and logic really are a matter of straightforward mathematics, while
others are idiosyncratic; there’s no one rule that describes every situation.</p>

<p>Michael Weinberg <a href="https://michaelweinberg.org/blog/2022/10/24/github-copilot-problem/" target="_blank">wrote a blog post</a>
analyzing the claims for and against Copilot. He concludes that even if the
fair use argument falls through, GitHub could fall back on its terms of service
to justify taking code from any repo. However, he also notes that this might be
a defense of last resort, since it could trigger a backlash from GitHub users.</p>


<p>CTOs might be willing to run the risk of copyleft violations if Copilot was an
otherwise irresistible product. (After all, cutting 40% of your developer
salaries will pay for a lot of lawyers.) But if you’re still on the fence,
there are at least two other factors that might help make up your mind.</p>
<h2 id="security"><a href="#security"><span><svg viewBox="0 0 24 24" version="1.1" width="24" height="24" aria-hidden="true"><path d="M12.935 11.26a1 1 0 1 1 1.2-1.6 5.336 5.336 0 0 1 .572 8.043l-1.964 1.964a4.536 4.536 0 1 1-6.415-6.414l.5-.5a1 1 0 0 1 1.415 1.414l-.5.5a2.536 2.536 0 0 0 3.585 3.586l1.965-1.965a3.336 3.336 0 0 0-.358-5.028zm-.87 1.476a1 1 0 0 1-1.2 1.6 5.336 5.336 0 0 1-.572-8.043l1.965-1.965a4.536 4.536 0 1 1 6.414 6.415l-.5.5a1 1 0 1 1-1.414-1.415l.5-.5a2.536 2.536 0 1 0-3.586-3.585l-1.964 1.964a3.336 3.336 0 0 0 .357 5.029z"></path></svg></span>Security</a></h2>

<p>Experts have reported that Copilot often suggests code with security flaws.
In <a href="https://arxiv.org/abs/2108.09293" target="_blank">one study</a>, researchers produced 1,689
programs with Copilot, of which 40% were vulnerable to attack. Granted, this
study was conducted while the tool was still in beta, but even now, GitHub is
upfront about the fact that it takes no responsibility for the quality of its
code.</p>

<p>On top of this, one under-discussed security concern is that Copilot is a
keylogger. Unlike Tabnine, which developers can choose to run locally, Copilot
can only function in the cloud. In fairness, Copilot does allow users to
<a href="https://docs.github.com/en/copilot/configuring-github-copilot/configuring-github-copilot-settings-on-githubcom" target="_blank">disable telemetry</a>
by opting out in GitHub’s “settings” tab.</p>

<p><img loading="lazy" srcset="https://www-assets.kolide.com/rails/active_storage/representations/proxy/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBBNWNJREE9PSIsImV4cCI6bnVsbCwicHVyIjoiYmxvYl9pZCJ9fQ==--f1ff0e68900661709fe0caa392df20a4c0fb29db/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaDdCem9MWm05eWJXRjBTU0lJY0c1bkJqb0dSVlE2RkhKbGMybDZaVjkwYjE5c2FXMXBkRnNIYVFLOEFqQT0iLCJleHAiOm51bGwsInB1ciI6InZhcmlhdGlvbiJ9fQ==--aa1821da797a1d7a5f0ed4c03e77435e02d69050/github-copilot-opt-out.png 350w, https://www-assets.kolide.com/rails/active_storage/representations/proxy/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBBNWNJREE9PSIsImV4cCI6bnVsbCwicHVyIjoiYmxvYl9pZCJ9fQ==--f1ff0e68900661709fe0caa392df20a4c0fb29db/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaDdCem9MWm05eWJXRjBTU0lJY0c1bkJqb0dSVlE2RkhKbGMybDZaVjkwYjE5c2FXMXBkRnNIYVFMSUJUQT0iLCJleHAiOm51bGwsInB1ciI6InZhcmlhdGlvbiJ9fQ==--d2328d2e54fab2fadecccecd4e7668ffa681d461/github-copilot-opt-out.png 740w, https://www-assets.kolide.com/rails/active_storage/blobs/proxy/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBBNWNJREE9PSIsImV4cCI6bnVsbCwicHVyIjoiYmxvYl9pZCJ9fQ==--f1ff0e68900661709fe0caa392df20a4c0fb29db/github-copilot-opt-out.png " src="https://www-assets.kolide.com/rails/active_storage/blobs/proxy/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBBNWNJREE9PSIsImV4cCI6bnVsbCwicHVyIjoiYmxvYl9pZCJ9fQ==--f1ff0e68900661709fe0caa392df20a4c0fb29db/github-copilot-opt-out.png" data-zoomable="true"/></p>

<figcaption>
  Currently, GitHub Copilot does not enable telemetry by default. That
  said, if you aren’t sure if you enabled it when you first set it up, you can
  check using <a href="https://docs.github.com/en/copilot/configuring-github-copilot/configuring-github-copilot-settings-on-githubcom" target="_blank">these instructions</a>
</figcaption>

<p>But there are reasons to doubt whether the opt-out process works as promised.
Here’s why: users can also block Copilot from making suggestions that match
public code. However, Tim Davis, whose Twitter thread we referenced before,
reported that he had taken both those steps, and still had his own code fed
back to him.</p>

<blockquote>
<p lang="en" dir="ltr">When I signed up, I disabled the “Allow Github to use my code..” option. Also note that “suggestions matching public code” is “blocked”. Same result … <a href="https://twitter.com/github?ref_src=twsrc%5Etfw">@github</a> emits my LGPL code verbatim, with no license stated and no copyright. <a href="https://t.co/viKbqym2eq">pic.twitter.com/viKbqym2eq</a></p>— Tim Davis (@DocSparse) <a href="https://twitter.com/DocSparse/status/1581629105224589313?ref_src=twsrc%5Etfw">October 16, 2022</a>
</blockquote> 
<h2 id="usefulness"><a href="#usefulness"><span><svg viewBox="0 0 24 24" version="1.1" width="24" height="24" aria-hidden="true"><path d="M12.935 11.26a1 1 0 1 1 1.2-1.6 5.336 5.336 0 0 1 .572 8.043l-1.964 1.964a4.536 4.536 0 1 1-6.415-6.414l.5-.5a1 1 0 0 1 1.415 1.414l-.5.5a2.536 2.536 0 0 0 3.585 3.586l1.965-1.965a3.336 3.336 0 0 0-.358-5.028zm-.87 1.476a1 1 0 0 1-1.2 1.6 5.336 5.336 0 0 1-.572-8.043l1.965-1.965a4.536 4.536 0 1 1 6.414 6.415l-.5.5a1 1 0 1 1-1.414-1.415l.5-.5a2.536 2.536 0 1 0-3.586-3.585l-1.964 1.964a3.336 3.336 0 0 0 .357 5.029z"></path></svg></span>Usefulness</a></h2>

<p>According to GitHub’s own <a href="https://github.com/features/copilot#faq-privacy" target="_blank">FAQ page</a>,
“we found that users accepted on average 26% of all completions shown by GitHub
Copilot.” <a href="https://matthewbutterick.com/chron/this-copilot-is-stupid-and-wants-to-kill-me.html" target="_blank">Butterick’s assessment</a>
was more blunt: “Copilot essen­tially tasks you with correcting a 12-year-old’s
home­work, over and over.”</p>

<p>Other developers have found the tool more valuable in cutting down their
code-related Google searches. Michael Weinberg is pretty close to the mark in
<a href="https://michaelweinberg.org/blog/2022/10/24/github-copilot-problem/" target="_blank">describing the current version of Copilot</a>
as “a tool that replaces googling for stack overflow answers.” That certainly
has value, but not yet the kind of value that will let organizations see
meaningful changes to their engineering budget.</p>

<p>One relevant–if difficult to quantify–factor is that providing the necessary
oversight of Copilot’s code could wipe out whatever productivity gains it
offers by slowing down the code review process. Our CEO cited this as the most
significant factor in choosing to disallow Copilot at Kolide.</p>

<blockquote>
<p>As a code reviewer there is no way for me to know what code the employee I
hired wrote vs the code the AI bot wrote. Knowing who wrote the code
absolutely informs the amount of scrutiny I provide. For example, an engineer
that has proven day in and day out that they can produce high-quality code is
scrutinized less during review than Junior engineer that we just hired.</p>

<p>Without knowing who truly came up with 25% of any given code submitted in a
PR, it short circuits my ability as a reviewer to use high-level heuristics
to evaluate code and forces me to look at every line of code assuming the AI
may have written it. Since AI’s are generally “mostly correct, and then
suddenly and inexplicably catastrophically wrong,” I believe code written by
AI deserves the most scrutiny of all.</p>
</blockquote>

<p>To be fair, GitHub seems to be listening to these concerns. In a <a href="https://github.blog/2022-11-01-preview-referencing-public-code-in-github-copilot/" target="_blank">November
blog post</a>,
they announced that in forthcoming releases of Copilot, any code suggestion
would come with an inventory of similar code and let developers organize that
inventory according to its license (among other variables).</p>

<p>They write:</p>

<blockquote>
<p>Using this information, a developer might find inspiration from other
codebases, discover documentation, and almost certainly gain confidence that
this fragment is appropriate to use in their project. They might take a
dependency, provide attribution where appropriate, or possibly even pursue
another implementation strategy.</p>
</blockquote>

<p>This is a step in the right direction, but even so, giving developers the
ability to provide attribution is not the same thing as including it
automatically. We’ll have to see what this capability looks like in action
(sometime in 2023) before we know how well it addresses its critics’ concerns.</p>


<p>For a lot of companies, the risk of putting out GPL-tainted code is enough to
scare them away from Copilot. In fact, prior to launching his lawsuit,
<a href="https://matthewbutterick.com/chron/this-copilot-is-stupid-and-wants-to-kill-me.html" target="_blank">Butterick himself wrote</a>
that he “wasn’t worried about its effects on open source” because software
developers would inevitably ban it.</p>

<p>As our CEO says, “as someone who used to work on M&amp;A deals, we would often give
them a 20-30% haircut on price or even walk away completely if we felt there was
undue risk of copyleft pollution.” With that in mind, forbidding the use of
Copilot is the safest–if most conservative–option for the time being.</p>

<p>At Kolide, we just released a Check that detects the presence of Copilot on a
device, and instructs users to uninstall it. Read <a href="https://www.kolide.com/features/checks/github-copilot">our use-case page</a> on that Check to
learn more about how it works.</p>

<p><img loading="lazy" srcset="https://www-assets.kolide.com/rails/active_storage/representations/proxy/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBBNWdJREE9PSIsImV4cCI6bnVsbCwicHVyIjoiYmxvYl9pZCJ9fQ==--a07f596deae060653c257798ffeadb46563c4b0d/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaDdCem9MWm05eWJXRjBTU0lJY0c1bkJqb0dSVlE2RkhKbGMybDZaVjkwYjE5c2FXMXBkRnNIYVFLOEFqQT0iLCJleHAiOm51bGwsInB1ciI6InZhcmlhdGlvbiJ9fQ==--aa1821da797a1d7a5f0ed4c03e77435e02d69050/kolide-check-slack-screenshot.png 350w, https://www-assets.kolide.com/rails/active_storage/representations/proxy/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBBNWdJREE9PSIsImV4cCI6bnVsbCwicHVyIjoiYmxvYl9pZCJ9fQ==--a07f596deae060653c257798ffeadb46563c4b0d/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaDdCem9MWm05eWJXRjBTU0lJY0c1bkJqb0dSVlE2RkhKbGMybDZaVjkwYjE5c2FXMXBkRnNIYVFMSUJUQT0iLCJleHAiOm51bGwsInB1ciI6InZhcmlhdGlvbiJ9fQ==--d2328d2e54fab2fadecccecd4e7668ffa681d461/kolide-check-slack-screenshot.png 740w, https://www-assets.kolide.com/rails/active_storage/blobs/proxy/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBBNWdJREE9PSIsImV4cCI6bnVsbCwicHVyIjoiYmxvYl9pZCJ9fQ==--a07f596deae060653c257798ffeadb46563c4b0d/kolide-check-slack-screenshot.png " src="https://www-assets.kolide.com/rails/active_storage/blobs/proxy/eyJfcmFpbHMiOnsibWVzc2FnZSI6IkJBaHBBNWdJREE9PSIsImV4cCI6bnVsbCwicHVyIjoiYmxvYl9pZCJ9fQ==--a07f596deae060653c257798ffeadb46563c4b0d/kolide-check-slack-screenshot.png" data-zoomable="true"/></p>

<figcaption>
  Kolide’s <a href="https://www.kolide.com/features/checks/github-copilot" target="_blank">new GitHub Copilot Check</a> can detect
  if Copilot is running on VSCode, Microsoft Visual Studio, and IDEs created by
  JetBrains.
</figcaption>

<p>Should you choose to allow Copilot, we advise you to take the following precautions:</p>

<ul>
<li>Disable telemetry</li>
<li>Block public code suggestions</li>
<li>Thoroughly test all Copilot code</li>
<li>Run projects through license checking tools that analyze code for plagiarism</li>
</ul>


<p>You could write a book (or a book-length <a href="https://www.reddit.com/r/kolide/" target="_blank">Reddit</a>
comment) on all the issues Copilot brings up. If nothing else, it’s opened up a
fierce debate between AI evangelists and open-source purists.</p>

<p>David Heinemeier Hansson, creator of Ruby on Rails, argues that the backlash
against Copilot runs contrary to the whole spirit of open source. Copilot is
“exactly the kind of collaborative, innovative breakthrough that I’m thrilled
to see any open source code that I put into the world used to enable,”
<a href="https://world.hey.com/dhh/the-scarcity-scarecrows-of-open-source-325f6d2b" target="_blank">he writes</a>.
“Isn’t this partly why we share our code to begin with? To enable others to
remix, reuse, and regenerate with?”</p>

<p>While Hansson may be motivated by that sense of expansive generosity, he can’t
be said to speak for the open source community as a whole. A developer who
wrote a program to find lost pets may have a legitimate objection to their code
being used in a missile guidance system.</p>

<p>On the other hand, a legal victory against GitHub, Microsoft, and OpenAI could
have <a href="https://www.theverge.com/2022/11/8/23446821/microsoft-openai-github-copilot-class-action-lawsuit-ai-copyright-violation-training-data" target="_blank">unintended side effects</a>
that ripple across the whole field of generative AI.</p>

<p>However you feel about it, it does seem that <em>something like</em> Copilot is inevitable.
The best case scenario might just be a version that doesn’t try to divorce code
from the humans writing it, in an attempt to become something more like an
Autopilot.</p>

        </div></div>
  </body>
</html>
