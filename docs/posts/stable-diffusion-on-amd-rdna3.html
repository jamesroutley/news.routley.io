<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://nod.ai/sd-on-rdna3/">Original</a>
    <h1>Stable Diffusion on AMD RDNA3</h1>
    
    <div id="readability-page-1" class="page"><div>
            
<figure><img decoding="async" width="1024" height="645" src="https://nod.ai/wp-content/uploads/2022/12/sd-rdna3-1024x645.png" alt="" srcset="https://nod.ai/wp-content/uploads/2022/12/sd-rdna3-1024x645.png 1024w, https://nod.ai/wp-content/uploads/2022/12/sd-rdna3-300x189.png 300w, https://nod.ai/wp-content/uploads/2022/12/sd-rdna3-768x484.png 768w, https://nod.ai/wp-content/uploads/2022/12/sd-rdna3-1536x968.png 1536w, https://nod.ai/wp-content/uploads/2022/12/sd-rdna3-2048x1291.png 2048w, https://nod.ai/wp-content/uploads/2022/12/sd-rdna3-2000x1261.png 2000w, https://nod.ai/wp-content/uploads/2022/12/sd-rdna3-1000x630.png 1000w, https://nod.ai/wp-content/uploads/2022/12/sd-rdna3-1800x1135.png 1800w, https://nod.ai/wp-content/uploads/2022/12/sd-rdna3-888x560.png 888w, https://nod.ai/wp-content/uploads/2022/12/sd-rdna3-600x378.png 600w" sizes="(max-width: 1024px) 100vw, 1024px"/></figure>



<p>Generative AI has taken the world by storm but until now it took a while to generate an image from a text prompt with the typical 50 Steps on a GPU. The fastest generally available solutions on Windows start at 5 seconds or higher unless you want to start copying DLLs by hand to upgrade the torch libraries. There has also been a wide variety of accuracy-degrading performance optimizations like <a href="https://github.com/facebookresearch/xformers">Xformers</a> and <a href="https://github.com/HazyResearch/flash-attention">Flash Attention, </a>which are great tools if you are open to trading accuracy for performance, however we wanted to unlock maximum performance without any of the accuracy degrading optimizations.<strong></strong></p>



<p>The Nod.ai team is pleased to announce Stable Diffusion image generation accelerated on the AMD RDNA™ 3 architecture running on a beta driver from AMD.  Nod.ai has been optimizing this state-of-the-art model to generate Stable Diffusion images, using 50 steps with FP16 precision and negligible accuracy degradation, in a matter of seconds.</p>



<p>Here are results from one of our end users running on a Windows 10 system with the Ryzen™ 7950X and Radeon™ RX 7900 XTX graphics card with <a href="https://www.amd.com/en/support/kb/release-notes/rn-rad-win-22-11-1-mlir-iree">this</a> KB driver and the WebGUI.<strong>  2.63 seconds.</strong></p>



<figure><img decoding="async" src="https://cdn.discordapp.com/attachments/1054834003519213618/1054883871411425311/image.png" alt=""/></figure>







<p>Everyone makes tall claims about performance, so we don’t want you to take our word for it. We want you to try SHARK on your system and report the performance you see.</p>



<p>We believe that Generative AI should be accessible to everyone irrespective of their technical background. So we made our Stable Diffusion WebGUI  easily accessible and usable. Today you can download a single file and get started on your Generative AI endeavor. The community has reported that it is able to run on older generation hardware dating back five years.</p>



<p>Here are images generated by the SHARK community on AMD RDNA™ architecture-based devices in the #ai-art <a href="https://discord.com/invite/RUqY2h2s9u">Discord</a> channel.</p>



<figure>
<figure><img decoding="async" src="https://media.discordapp.net/attachments/1047963326560350228/1053036685274927234/festivemouse1.png" alt="Image"/><figcaption>an oil painting of a rat wearing a christmas sweater – empty headed</figcaption></figure>



<figure><img decoding="async" loading="lazy" width="512" height="512" data-id="5843" src="https://nod.ai/wp-content/uploads/2022/12/image.png" alt="" srcset="https://nod.ai/wp-content/uploads/2022/12/image.png 512w, https://nod.ai/wp-content/uploads/2022/12/image-300x300.png 300w, https://nod.ai/wp-content/uploads/2022/12/image-150x150.png 150w, https://nod.ai/wp-content/uploads/2022/12/image-280x280.png 280w" sizes="(max-width: 512px) 100vw, 512px"/><figcaption>Cthylla</figcaption></figure>



<figure><img decoding="async" src="https://media.discordapp.net/attachments/1047963326560350228/1052986525752762378/lilgamer1.png" alt="Image"/><figcaption>empty headed [RX 480 8GB]</figcaption></figure>



<figure><img decoding="async" src="https://media.discordapp.net/attachments/1047963326560350228/1052977246639497316/ghost.png" alt="Image"/><figcaption>empty headed [RX 480 8GB]</figcaption></figure>



<figure><img decoding="async" src="https://media.discordapp.net/attachments/1047963326560350228/1052674193952604330/xtAqP1X0mC9eQAAAABJRU5ErkJggg.png" alt="Image"/><figcaption>Ian2400</figcaption></figure>



<figure><img decoding="async" src="https://media.discordapp.net/attachments/1047963326560350228/1052921043863490560/hypercar-1003-1008-1014.png" alt="Image"/><figcaption>Denbe and Not Quite Denbe</figcaption></figure>



<figure><img decoding="async" src="https://media.discordapp.net/attachments/1047963326560350228/1052605192396353627/FwVReCblPYx8AAAAAElFTkSuQmCC.png" alt="Image"/><figcaption>cstueckrath</figcaption></figure>



<figure><img decoding="async" src="https://cdn.discordapp.com/attachments/1054490980243492875/1054505813781266523/crystalball_vision.png" alt=""/><figcaption>Crache</figcaption></figure>



<figure><img decoding="async" loading="lazy" width="512" height="512" data-id="5864" src="https://nod.ai/wp-content/uploads/2022/12/image-4.png" alt="" srcset="https://nod.ai/wp-content/uploads/2022/12/image-4.png 512w, https://nod.ai/wp-content/uploads/2022/12/image-4-300x300.png 300w, https://nod.ai/wp-content/uploads/2022/12/image-4-150x150.png 150w, https://nod.ai/wp-content/uploads/2022/12/image-4-280x280.png 280w" sizes="(max-width: 512px) 100vw, 512px"/><figcaption>MDuica</figcaption></figure>



<figure><img decoding="async" loading="lazy" width="512" height="512" data-id="5863" src="https://nod.ai/wp-content/uploads/2022/12/image-3.png" alt="" srcset="https://nod.ai/wp-content/uploads/2022/12/image-3.png 512w, https://nod.ai/wp-content/uploads/2022/12/image-3-300x300.png 300w, https://nod.ai/wp-content/uploads/2022/12/image-3-150x150.png 150w, https://nod.ai/wp-content/uploads/2022/12/image-3-280x280.png 280w" sizes="(max-width: 512px) 100vw, 512px"/><figcaption>Cthylla</figcaption></figure>
</figure>



<p>Give it a try at <a href="http://shark.sd/">http://shark.sd,</a> share and show off what you can create with Generative AI. We are not done with performance, ease of use or feature requests – so stay tuned for more over the upcoming weeks.</p>



<p>SHARK is an open source cross platform (Windows, macOS and Linux) Machine Learning Distribution packaged with <a href="https://github.com/llvm/torch-mlir">torch-mlir</a> (for seamless PyTorch integration), <a href="https://mlir.llvm.org/">LLVM/MLIR</a> for re-targetable compiler technologies along with <a href="https://github.com/iree-org">IREE</a> (for efficient codegen, compilation and runtime) and Nod.ai’s tuning. IREE is part of the <a href="https://github.com/openxla">OpenXLA Project</a>, an ecosystem of ML compiler and infrastructure technologies being co-developed by AI/ML industry leaders including AMD, Google, Nod.ai and many more. OpenXLA aims to let ML developers build models in their preferred framework (TensorFlow, PyTorch, JAX) and easily execute them with high performance across a wide range of hardware backends (GPU, CPU, and ML accelerators).</p>



<blockquote>
<p>It was fantastic to see the Nod/AMD collaboration produce the great results it has. Beyond the numbers, I am really proud that we were able to create an engaged community that is empowered to make this kind of project happen. That was a key reason I started IREE and was ultimately behind the decision to become part of the OpenXLA project. As part of OpenXLA, we’ll work closely with our community to carry this momentum forward.</p>
<cite>Stella Laurenzo, IREE co-founder, OpenXLA community leader,  Google ML Compilers</cite></blockquote>



<p>Nod.ai is hiring: stdin@nod.ai. Join us on <a href="https://discord.com/invite/RUqY2h2s9u">Discord</a></p>
        </div></div>
  </body>
</html>
