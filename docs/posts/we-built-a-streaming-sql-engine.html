<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.epsio.io/blog/how-to-create-a-streaming-sql-engine">Original</a>
    <h1>We Built a Streaming SQL Engine</h1>
    
    <div id="readability-page-1" class="page"><div><div fs-codehighlight-element="code"><p>So you probably wake up every morning asking yourself three of life’s most pertinent questions- how do I build a streaming SQL engine, what even is a streaming SQL engine, and can our Lord drop tables owned by another user.</p><p>I too found myself asking these questions, sometimes even dreaming about them- often in the form of various SQL operators pointing and laughing at my incompetence as I beg them to answer me.</p><p>And so, a year ago, I (quite bravely if I may say so myself) packed my bags and set off on the long and treacherous journey to find answers to these questions. I went from monk to priest to spaghetti-enthusiast, shocked to find themselves concerned with paltry questions such as the Meaning of Life and how to find peace within oneself. But eventually, desolate in the deepest pits of my mind, I happened by a small temple by the name of “Epsio Labs”- a feeling of tremendous revelation came over me, and I walked in.</p><p>Friends,  today I will share with you the secrets I have found there (despite the numerous NDAs).</p><h3>What is a Streaming SQL Engine? </h3><p>A streaming SQL engine keeps queries’ results up to date without ever having to recalculate them, even as the underlying data changes. To explain this, imagine a simple query, such as [.code]SELECT count(*) FROM humans[.code] . A normal SQL engine (such as Postgres’s, MySQL’s) would need to go over all the different [.code]humans[.code] every time you ran that query- which could be quite costly and lengthy given our ever changing population count. With a streaming SQL engine, you would define that query once, and the engine would constantly keep the resulting count up to date as new humans were born and the old / sickly ones died off, without ever performing a recalculation of counting all humans in the world.</p><h3>How to build a Streaming SQL engine</h3><p>For the simple example above, you may have an idea of how a streaming SQL engine could work- first, you would need to do what any normal SQL engine does and calculate the number of humans. Next, every time a human was born you would add one to your result, and every time a human died you would negate one from your result. Easy, right? </p><figure class="w-richtext-align-center"><p><img src="https://uploads-ssl.webflow.com/649abb101f1b7e207dfc09fa/65018bc235ada9046f67094e_1*5aMhkvO4eM58JPFXTEhWjQ.png" alt=""/></p></figure><p>where the key is <em>what</em> we want to change, and the modification is <em>by how much we want to change it</em>. So for example, if we wanted to pass a message to a node telling it “Hey Mr. Node, 1.5 Apples have been added”, it would look like this:</p><figure class="w-richtext-align-fullwidth"><p><img src="https://uploads-ssl.webflow.com/649abb101f1b7e207dfc09fa/65018bc3c27ee72b296d5546_1*LZFOpfqt3sL7wEGY2w_bRw.png" alt=""/></p></figure><p>Each node will be responsible for receiving changes, performing some type of operation, and then outputting changes itself. Another important concept here is that we can add modifications together if they have the same key. So the two changes [.code]apple: 1.5[.code] and [.code]apple: 2[.code] are equivalent to [.code]apple: 3.5[.code] . If the modifications equal zero together,  it’s as if nothing at all happened- for example, if we have two changes [.code]apple: 3[.code] and [.code]apple: -3[.code] , it’s equivalent to not having streamed any changed (You can think of it as me giving you three apples, utterly regretting my kindness, then taking away your three apples. For you it would be as if nothing happened at all- aside from your broken pride). To make this make more sense, let’s draw out the nodes for our query ([.code]SELECT count(*) FROM humans[.code]), and add in the first human, Adam.</p><figure class="w-richtext-align-fullwidth"><p><img src="https://uploads-ssl.webflow.com/649abb101f1b7e207dfc09fa/65018bc27e01a5c9472508c7_1*zt4KzYosgm0hVwkFGOdPLQ.png" alt=""/></p></figure><p>As we can see, a new human named “Adam” was born. The “Counter” node, perhaps called for its ability to count, holds an internal state of the current count of humans in the world. Whenever it receives a <em>change </em> (an addition or deletion of a human), it updates its internal count, and then outputs relevant changes- in this case, only one change was necessary, telling the next node to add the number one (signifying the total number of humans) once. In this instance, the next node was the “Final Results Table”, an actual honest-to-god relational table (perhaps in Postgres). You can imagine every change translating to a [.code]DELETE[.code] or [.code]INSERT[.code] based on the key and modification.</p><p>Next, let’s add in Eve:</p><figure class="w-richtext-align-fullwidth"><p><img src="https://uploads-ssl.webflow.com/649abb101f1b7e207dfc09fa/65018bc380bf98de49954758_1*Et0FR_DFbqsyO1ZHbYMbig.png" alt=""/></p></figure><p>This time, the counter node needed to output two changes- one to cancel out the previous change it outputted, and one two add the new updated value. Essentially, if we were to look at all the changes the Counter node outputted over time, we’d get:</p><figure class="w-richtext-align-fullwidth"><p><img src="https://uploads-ssl.webflow.com/649abb101f1b7e207dfc09fa/65018bc335ada9046f67096f_1*ILTxWLJS2WXoclOpluRxog.png" alt=""/></p></figure><p>Since we’re allowed to combine changes with the same key, the above is equivalent to:</p><figure class="w-richtext-align-fullwidth"><p><img src="https://uploads-ssl.webflow.com/649abb101f1b7e207dfc09fa/65018bc2f278a961b5dc16bb_1*Vl1lYUw7hUMqKshsfYHv1w.png" alt=""/></p></figure><p>A modification of zero means we can simply remove the change. Therefore, we’re left only with [.code]2: +1[.code] in the final result table- exactly what we wanted.</p><p>Are you starting to feel that sweet sweet catharsis? Ya, me too.</p><h3>A slightly more interesting example</h3><p>Let’s imagine we’re the devil and have two tables: </p><figure class="w-richtext-align-fullwidth"><p><img src="https://uploads-ssl.webflow.com/649abb101f1b7e207dfc09fa/65018ebe95502170aaeb31aa_1*1LF2yHSqNJErO5QdfQbFhA.png" alt=""/></p></figure><p>Now, for obvious reasons, let’s say we wanted a count of evil humans per name:</p><div><pre><code>SELECT humans.name, count(*) FROM humans 
JOIN evil_humans ON humans.id = evil_humans.human_id 
WHERE is_evil IS true 
GROUP BY humans.name
</code></pre></div><p>To be able to create a query plan (a series of nodes) from this query, we’re going to need to introduce a few new types of nodes here.</p><h3>Filter Node</h3><p>A filter node filters a change by its <em>key</em>, regardless of its <em>modification</em>. If a change “passes” the filter, the filter outputs it as is. To really  give you the feel of this, let’s diagram a filter node that passes only changes with keys that are equal to the word “cats”.</p><figure class="w-richtext-align-center"><p><img src="https://uploads-ssl.webflow.com/649abb101f1b7e207dfc09fa/65018ebec27ee72b296f122e_1*7J3fvww666tGqp_Qyyeqdw.png" alt=""/></p></figure><p>As we can see, we gave the filter node 3.4 cats and, astonishingly enough, it passed them on without changing a thing. Let’s try passing dogs through the filter node:</p><figure class="w-richtext-align-center"><p><img src="https://uploads-ssl.webflow.com/649abb101f1b7e207dfc09fa/65018f266674e22c868bb316_1*jNZQVsBrZD02qZ4qu-JC7A.png" alt=""/></p></figure><p>Whoa! This time the filter did <strong>not </strong>pass anything on. I imagine you get the idea. Moving on.</p><h3>Joins</h3><p>A Join node is responsible for receiving changes from two nodes, and outputting changes whose “join keys” match. It does this by holding an internal state (all in storage) of all the changes that pass through it from both sides, mapped by their respective join keys. So in our example with</p><div><pre><code>JOIN evil_humans ON humans.id = evil_humans.human_id
</code></pre></div><p>we would create one Join node, with two mappings:</p><p>In practice, the mappings would look something like this:</p><figure class="w-richtext-align-center"><p><img src="https://uploads-ssl.webflow.com/649abb101f1b7e207dfc09fa/65018ebec4670ee9f714b5be_1*h8nyNBikQdp0qQHSetAaKg.png" alt=""/></p></figure><p>Every time the Join node would receive a change from one of its sides, it would look on the other side for a matching key. If it found one, it would output the combined values. Let’s try drawing out a simple example where the Join node receives a new human named Tommy with id 232, and then a change saying id 232 is not evil. </p><p>First- a new human named Tommy enters the world:</p><figure class="w-richtext-align-center"><p><img src="https://uploads-ssl.webflow.com/649abb101f1b7e207dfc09fa/65018ebe468f11e1755f4e84_1*_IvDajebrqy4gVIehKGFfw.png" alt=""/></p></figure><p>Ok, we streamed a change that tells the Join node that Tommy (id 232) has been added. The Join node looks in its right mapping for a corresponding change for key 232, and finds none. It therefore outputs nothing; but<strong> </strong>it does update its <strong>internal mapping </strong>to reflect the fact Tommy has been added- this will help us when we do the following:</p><figure class="w-richtext-align-center"><p><img src="https://uploads-ssl.webflow.com/649abb101f1b7e207dfc09fa/65018ebe14e8a9b48b1933e8_1*OEn-Ca9zMWbSNmxgK68-ug.png" alt=""/></p></figure><p>Here, the Join node received a change from its <strong>right </strong>side telling it “id 232 is not evil”. The Join node then looked at its left mappings, found a corresponding change (232: Tommy- the change we just streamed before) and outputted the  combined change.</p><p> — -</p><p>Side note- you may have noticed we said “join key to change” but don’t actually keep the modification count in the join mapping. In the real world we do, and then multiply the modification counts of both sides to get the outputted modification count</p><p> — -</p><h3>Group Bys</h3><p>Our “Group By” node is very similar to the counter node we had before (in truth, they are one and the same wearing different hats- but that’s a tale for another time). The Group By node outputs aggregates per buckets- always ensuring that if you were to combine all changes it outputted, you would be left with at most one change per bucket (similar to how we took all the changes over time that came out of the Counter node, and saw that we’re left with only one as others cancel out). It does this by holding an internal mapping (in storage) between each bucket and its aggregated value. So in our example</p><div><pre><code>SELECT humans.name, count(*) ... GROUP BY humans.name
</code></pre></div><p>The Group By node would hold a mapping something like this:</p><figure class="w-richtext-align-center"><p><img src="https://uploads-ssl.webflow.com/649abb101f1b7e207dfc09fa/65018ebe065142e778f10600_1*RvSq9RJxuwcHmkvv-bdP0w.png" alt=""/></p></figure><p>Let’s try drawing out a simple example showing what would happen if we entered a new name the Group By node has never seen before:</p><figure class="w-richtext-align-center w-richtext-figure-type-image"><p><img src="https://uploads-ssl.webflow.com/649abb101f1b7e207dfc09fa/6501926e1795cee663813fa3_firstgroupby.png" loading="lazy" alt=""/></p></figure><p>Ok, what happened here? The change coming into the Group By node tells the Group By node to add one to Richard. The Group By node looks in its internal mappings, and sees it has no entry for Richard. It adds an entry, and then outputs that the amount of Richards is one (this is the <em>key </em>of the change- [.code](Richard, 1)[.code] ). Let’s go ahead and add another two Richards:</p><figure class="w-richtext-align-center w-richtext-figure-type-image"><p><img src="https://uploads-ssl.webflow.com/649abb101f1b7e207dfc09fa/650192a2c0b897576f5d779b_secondgroupby.png" loading="lazy" alt=""/></p></figure><p>Slightly more interesting- the Group By node receives another change telling it to add two to Richard. The Group By node updates its internal state, and then outputs two changes- one to <strong>remove </strong>the previous change it outputted, and one to add a change with the new updated count of Richards.</p><h3>Putting it all together </h3><p>Back to our original query:</p><div><pre><code>SELECT humans.name, count(*) FROM humans 
JOIN evil_humans ON humans.id = evil_humans.human_id 
WHERE is_evil IS true 
GROUP BY humans.name
</code></pre></div><p>To set the stage for our upcoming example,  imagine a young goody-two-shoes coder named Tommy, id 232 (you may remember him long ago from our explanation about the join). Tommy was a super cool dude who regularly downvoted mean people on StackOverflow (evilness=false). </p><p>One day, Tommy got kicked in the head by a horse, and as a direct result force pushed to master while deleting the CI. We’ll represent this occurrence with two changes- one to cancel out the old change saying Tommy wasn’t evil [.code](232, false): -1[.code] , and one to add in the new change saying he is evil [.code](232, true): +1[.code] :</p><figure class="w-richtext-align-fullwidth w-richtext-figure-type-image"><p><img src="https://uploads-ssl.webflow.com/649abb101f1b7e207dfc09fa/650192b21795cee663816f43_whoflow.png" loading="lazy" alt=""/></p></figure><p>Let’s do a quick breakdown of what we see above- so we outputted the two changes we talked about [.code](232, false): -1[.code] and [.code](232, true): +1[.code] . The Join node receives it, looks on its other side (ids -&gt; names), finds a name (Tommy), and outputs the inputted changes together with the name “Tommy”. Next, the filter node [.code]WHERE is_evil IS true[.code] filters out the change [.code](232, false): -1[.code] , and, since its evil value is false, only outputs [.code](232, true): +1[.code] . The Group By node takes in this change, looks in its mappings, and sees there existed a previous entry for Tommy (while not a very evil name, I have met some mean Tommys in my life). The Group By node therefore sends out one change to remove the old change it sent out with [.code](Tommy, 7): +1[.code] (this happened in a previous addition of an evil Tommy). It then sends out another change introducing the new change to the Tommy count.</p><h3>Wait, but why go to all the trouble?</h3><p>So, now there are 8 Tommy’s in the world that are evil, and we didn’t need to rerun our query to calculate this. You may be thinking- well, Mr. Devil, you really didn’t need a streaming SQL engine to do that. If you had a humans table and evilness table, just create indexes on them. You’d still need to go over all the records each time queried, but at least the lookups would be quick. The Group By would still need to do everything from scratch, but at least…</p><h3>In Conclusion</h3><p>Feel ready to build a streaming engine? You definitely have the building blocks- but you’re missing a few major concepts here such as how to be consistent (to <em>never </em>output<em> </em>partial results), how to do this all with high throughput (in everlasting tension with latency), and how to interact well with storage (async-io anyone?). Maybe I’ll write another blog post, maybe not. </p><p>By the way, as for the Lord dropping a table owned by another user: it apparently comes down to if he uses RDS (on a self-hosted DB he’s a superuser, but on RDS nobody is. Yes, not even the Lord).</p><p>Since posting this article, the Elders at Epsio realized there’s no point to keeping their secrets so secret and published their streaming engine for the world to use- check out Epsio’s <em>blazingly fast </em>SQL engine <a href="https://www.epsio.io/" target="_blank">here</a>.</p></div></div><p>This is some text inside of a div block.</p></div>
  </body>
</html>
