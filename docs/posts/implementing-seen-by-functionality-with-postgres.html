<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://supabase.com/blog/2022/07/18/seen-by-in-postgresql">Original</a>
    <h1>Implementing &#34;seen by&#34; functionality with Postgres</h1>
    
    <div id="readability-page-1" class="page"><article><div><p><strong>tl;dr: Use HyperLogLog, it&#39;s a reasonable approach with great trade-offs and no large architectural liabilities. For a quick &amp; dirty prototype, use <code>hstore</code>, which also performs the best with integer IDs.</strong></p><p>The year is 2022. You&#39;re head DBA at the hot new social site, SupaBook... Your startup is seeing eye-boggling growth because everyone loves fitting their hot-takes in posts restricted to <code>VARCHAR(256)</code>.</p><p>Why <code>VARCHAR(256)</code>? No particular reason, but you don&#39;t have time to get hung up on that or ask why -- <strong>you just found out that the priority this quarter is tracking content views across all posts in the app</strong>.</p><p>&#34;It sounds pretty simple&#34; a colleague at the meeting remarks -- &#34;just an increment here and an increment there and we&#39;ll know which posts are seen the most on our platform&#34;. You start to explain why it will be non-trivial, but the meeting ends before you can finish.</p><p>Well, it&#39;s time to figure out how you&#39;re going to do it. There&#39;s been a complexity freeze at the company, so you&#39;re not allowed to bring in any new technology, but you don&#39;t mind that because for v1 you would have picked Postgres anyway. Postgres&#39;s open source pedigree, robust suite of features, stable internals, and awesome mascot <a href="https://www.vertabelo.com/blog/the-history-of-slonik-the-postgresql-elephant-logo/">Slonik</a> make it a strong choice, and it&#39;s what you&#39;re already running.</p><p><strong><em>(insert record scratch here)</em></strong></p><p>Sure, this scenario isn&#39;t real, but it could be - that last part about Postgres definitely is. Let&#39;s see how you might solve this problem, as that imaginary DBA.</p><h2 id="experiment-setup">Experiment setup</h2><p>We&#39;ve got the following simple table layout:</p><p><span><img alt="basic table layout diagram" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill"/></span></p><p>In SQL migration form:</p><pre><div><div><pre><code><span>CREATE</span><span> EXTENSION IF </span><span>NOT</span><span> </span><span>EXISTS</span><span> uuid</span><span>-</span><span>ossp;
</span><span></span><span>CREATE</span><span> EXTENSION IF </span><span>NOT</span><span> </span><span>EXISTS</span><span> citext;
</span>
<span></span><span>-- Create a email domain to represent and constraing email addresses</span><span>
</span><span></span><span>CREATE</span><span> DOMAIN email
</span><span></span><span>AS</span><span> citext
</span><span></span><span>CHECK</span><span> ( LENGTH(</span><span>VALUE</span><span>) </span><span>&lt;=</span><span> </span><span>255</span><span> </span><span>AND</span><span> </span><span>value</span><span> </span><span>~</span><span> </span><span>&#39;^[a-zA-Z0-9.!#$%&amp;&#39;&#39;*+/=?^_`{|}~-]+@[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?(?:\.[a-zA-Z0-9](?:[a-zA-Z0-9-]{0,61}[a-zA-Z0-9])?)*$&#39;</span><span> );
</span>
<span>COMMENT </span><span>ON</span><span> DOMAIN email </span><span>is</span><span> </span><span>&#39;lightly validated email address&#39;</span><span>;
</span>
<span></span><span>-- Create the users table</span><span>
</span><span></span><span>CREATE</span><span> </span><span>TABLE</span><span> users (
</span><span>    id bigserial </span><span>PRIMARY</span><span> KEY GENERATED </span><span>BY</span><span> </span><span>DEFAULT</span><span> </span><span>AS</span><span> </span><span>IDENTITY</span><span>,
</span><span>    uuid uuid </span><span>NOT</span><span> </span><span>NULL</span><span> </span><span>DEFAULT</span><span> uuid_nonmc_v1(),
</span>
<span>    email email </span><span>NOT</span><span> </span><span>NULL</span><span>,
</span>    name text,
<!-- -->    about_html text,
<!-- -->
<span>    created_at timestamptz </span><span>NOT</span><span> </span><span>NULL</span><span> </span><span>DEFAULT</span><span> NOW()
</span>);
<!-- -->
<span></span><span>-- Create the posts table</span><span>
</span><span></span><span>CREATE</span><span> </span><span>TABLE</span><span> posts (
</span><span>    id bigserial </span><span>PRIMARY</span><span> KEY GENERATED </span><span>BY</span><span> </span><span>DEFAULT</span><span> </span><span>AS</span><span> </span><span>IDENTITY</span><span>,
</span><span>    uuid uuid </span><span>NOT</span><span> </span><span>NULL</span><span> </span><span>DEFAULT</span><span> uuid_nonmc_v1(),
</span>
<!-- -->    title text,
<!-- -->    content text,
<!-- -->    main_image_src text,
<!-- -->    main_link_src text,
<!-- -->
<span>    created_by </span><span>bigint</span><span> </span><span>REFERENCES</span><span> users(id),
</span>
<!-- -->    last_hidden_at timestamptz,
<!-- -->    last_updated_at timestamptz,
<span>    created_at timestamptz </span><span>NOT</span><span> </span><span>NULL</span><span> </span><span>DEFAULT</span><span> NOW()
</span>);
</code></pre></div></div></pre><p>This basic setup has taken the (imaginary) company quite far -- even though the <code>posts</code> table has millions and millions of entries, Postgres chugs along and serves our queries with impressive speed and reliability. Scaling up is the new (and old) scaling out.</p><h2 id="how-should-we-do-it">How should we do it?</h2><p>Well we can&#39;t pat ourselves for our miraculous and suspiciously simple DB architecture all day, let&#39;s move on to the task at hand.</p><p>Like any good tinkerer we&#39;ll start with the simplest solutions and work our way up in complexity to try and get to something outstanding, testing our numbers as we go.</p><h3 id="try-1-the-naive-way-a-simple-counter-on-every-post">Try #1: The naive way, a simple counter on every Post</h3><p>The easiest obvious way to do this is to maintain a counter on every tuple in the <code>posts</code> table. It&#39;s obvious, and it&#39;s almost guaranteed to work -- but maybe not <em>work well</em>.</p><p>The migration to make it happen isn&#39;t too difficult:</p><pre><div><div><pre><code><span>BEGIN</span><span>;
</span>
<span></span><span>ALTER</span><span> </span><span>TABLE</span><span> posts </span><span>ADD</span><span> </span><span>COLUMN</span><span> seen_by_count;
</span>
<span>COMMENT </span><span>ON</span><span> </span><span>COLUMN</span><span> posts.seen_by_count
</span><span>  </span><span>IS</span><span> </span><span>&#39;simple count of users who have seen the post&#39;</span><span>;
</span>
<span></span><span>COMMIT</span><span>;
</span></code></pre></div></div></pre><p>There&#39;s one <em>obvious</em> glaring issue here -- what if someone sees the same post twice? Every page reload would cause inflated counts in the <code>seen_by_count</code> column, not to mention a lot of concurrent database updates (which isn&#39;t necessarily Postgres&#39;s forte to begin with).</p><p>Clearly there&#39;s a better way to do things but before that...</p><h2 id="writing-a-test-suite-before-the-cpus-get-hot-and-heavy">Writing a test suite before the CPUs get hot and heavy</h2><p>How will we know which approach is better without numbers?! Measuring complexity and feeling can only get us so far -- we need to get some numbers that tell us the performance of the solution at the stated tasks -- we need benchmarks.</p><p>Before we can declare any solution the best, in particular we need a <em>baseline!</em>. The simplest possible incorrect solution (simply incrementing a counter on the Post) is probably a reasonable thing to use as a benchmark, so let&#39;s take a moment to write our testing suite.</p><p>Let&#39;s do this the simplest one might imagine:</p><ul><li>Generate a large amount of users<ul><li>Lets model for 1000, 10k, 100K, 1MM, and 10MM users</li></ul></li><li>Generate an even larger amount of fake posts attributed to those users<ul><li>This is a bit harder -- we need to define a general distribution for our users that&#39;s somewhat informed by real life...</li><li>An average/normalized distribution doesn&#39;t quite work here -- <a href="https://www.pewresearch.org/internet/2019/04/24/sizing-up-twitter-users/">on sites like twitter 10% of users create 80% of the tweets</a>!</li></ul></li><li>Generate a <em>description</em> of &#34;events&#34; that describe which post was seen by whom, which we can replay.<ul><li>We want the equivalent of an effect system or monadic computation, which is easier than it sounds -- we want to generate an encoding (JSON, probably) of <em>what to do</em>, without actually doing it</li><li>We&#39;ll just do consistent &#34;as fast as we can&#34; execution (more complicated analysis would burst traffic to be ab it closer to real life)</li></ul></li></ul><p>OK, let&#39;s roll our hands up and get it done:</p><h3 id="script-user-seeding">Script: User seeding</h3><p>Here&#39;s what that looks like:</p><pre><div><div><pre><code><span>/**
</span><span> * Generate a list of synthetic users to be loaded into Postgres
</span><span> *
</span><span> * </span><span>@param </span><span>{object}</span><span> </span><span>args</span><span>
</span><span> * </span><span>@param </span><span>{number}</span><span> </span><span>[args.count] number of users to generate
</span><span> * </span><span>@param </span><span>{number}</span><span> </span><span>[args.aboutHTMLWordCount] number of words to generate (lorem ipsum) for about_html (serves to add heft to tuples)
</span><span> * </span><span>@param </span><span>{string}</span><span> </span><span>[args.outputFilePath] output file path, if present this functoin returns void
</span><span> * </span><span>@returns </span><span>{any[][]}</span><span> </span><span>List of generated synthetic users
</span><span> */</span><span>
</span><span></span><span>export</span><span> </span><span>async</span><span> </span><span>function</span><span> </span><span>generateUsers</span><span>(</span><span>args</span><span>) </span><span>{
</span><span>  </span><span>const</span><span> count = args.count || DEFAULT_USER_COUNT
</span><span>  </span><span>const</span><span> aboutHTMLWordCount = args.aboutHTMLWordCount || DEFAULT_ABOUT_HTML_WORD_COUNT
</span>
<span>  </span><span>const</span><span> outputFilePath = args.outputFilePath
</span><span>  </span><span>if</span><span> (!outputFilePath) {
</span><span>    </span><span>throw</span><span> </span><span>new</span><span> </span><span>Error</span><span>(</span><span>&#39;output file path must be specified&#39;</span><span>)
</span>  }
<!-- -->
<span>  </span><span>for</span><span> (</span><span>var</span><span> id = </span><span>0</span><span>; id &lt; count; id++) {
</span><span>    </span><span>const</span><span> user = {
</span>      id,
<span>      </span><span>email</span><span>: </span><span>`user</span><span>${id}</span><span>@example.com`</span><span>,
</span><span>      </span><span>name</span><span>: </span><span>`user </span><span>${id}</span><span>`</span><span>,
</span><span>      </span><span>about_html</span><span>: fastLoremIpsum(aboutHTMLWordCount, </span><span>&#39;w&#39;</span><span>),
</span>    }
<!-- -->
<span>    </span><span>// Write the entries to disk (returning nothing)</span><span>
</span><span>    </span><span>if</span><span> (args.outputFilePath) {
</span><span>      </span><span>await</span><span> appendFile(outputFilePath, </span><span>`</span><span>${</span><span>JSON</span><span>.stringify(user)}</span><span>\n`</span><span>)
</span>    }
<!-- -->  }
<!-- -->}
</code></pre></div></div></pre><p>Nothing too crazy in there -- we generate a bunch of JSON, and force it out to disk. It&#39;s best to avoid trying to keep it in memory so we can handle much larger volumes than we might be able to fit in memory.</p><p>If you&#39;d like to see the code, check out <a href="https://gitlab.com/mrman/supabase-seen-by/-/blob/main/scripts/generate/users.js"><code>scripts/generate/users.js</code> in the repo</a>.</p><h3 id="script-post-seeding">Script: Post seeding</h3><p>Along with users, we need to generate posts that they can view. We&#39;ll keep it simple and take an amount of posts to make, generating from 0 to <code>count</code> of those.</p><p>It&#39;s very similar to the user generation code, with the caveat that we can take into account the 80/20 lurker/poster rule. here&#39;s what that looks like:</p><p>It&#39;s a bit long so if you&#39;d like to see the code, check out <a href="https://gitlab.com/mrman/supabase-seen-by/-/blob/main/scripts/generate/posts.js"><code>scripts/generate/posts.js</code> in the repo</a>.</p><h3 id="script-action-api-call-seedinggeneration">Script: action (API call) seeding/generation</h3><p>This script is a bit tricky -- we need to inject some randomness in the performing of the following actions:</p><ul><li>Record a new view of a post</li><li>Retrieve just the count of a single post</li><li>Retrieve all the users who saw a post</li></ul><p>I&#39;ve chosen to use <a href="https://www.npmjs.com/package/autocannon"><code>autocannon</code></a> so I needed to write a request generation script which looks like this:</p><pre><div><div><pre><code><span>const</span><span> process = </span><span>require</span><span>(</span><span>&#39;process&#39;</span><span>)
</span>
<span></span><span>const</span><span> POST_COUNT = process.env.TEST_POST_COUNT
</span><span>  ? </span><span>parseInt</span><span>(process.env.TEST_POST_COUNT, </span><span>10</span><span>)
</span><span>  : </span><span>undefined</span><span>
</span><span></span><span>const</span><span> USER_COUNT = process.env.TEST_USER_COUNT
</span><span>  ? </span><span>parseInt</span><span>(process.env.TEST_USER_COUNT, </span><span>10</span><span>)
</span><span>  : </span><span>undefined</span><span>
</span>
<span></span><span>/**
</span><span> * Request setup function for use with autocannon
</span><span> *
</span><span> * </span><span>@param </span><span>{Request}</span><span> </span><span>request</span><span>
</span><span> * </span><span>@returns </span><span>{Request}</span><span>
</span><span> */</span><span>
</span><span></span><span>function</span><span> </span><span>setupRequest</span><span>(</span><span>request</span><span>) </span><span>{
</span><span>  </span><span>// ENsure we have counts to go off of</span><span>
</span><span>  </span><span>if</span><span> (!POST_COUNT || !USER_COUNT) {
</span><span>    </span><span>throw</span><span> </span><span>new</span><span> </span><span>Error</span><span>(</span><span>&#39;Cannot setup request without valid post/user count!&#39;</span><span>)
</span>  }
<!-- -->
<span>  </span><span>// Pick a random post to do an operation on</span><span>
</span><span>  </span><span>const</span><span> postId = </span><span>Math</span><span>.floor(</span><span>Math</span><span>.random() * POST_COUNT)
</span>
<span>  </span><span>// Choose pseudo-randomly whether to register a seen by or read seenby status</span><span>
</span><span>  </span><span>const</span><span> operationChoice = </span><span>Math</span><span>.floor(</span><span>Math</span><span>.random() * </span><span>10</span><span>)
</span><span>  </span><span>if</span><span> (operationChoice &lt; </span><span>1</span><span>) {
</span><span>    </span><span>// 10% of the time, get *all* the users</span><span>
</span><span>    request.method = </span><span>&#39;GET&#39;</span><span>
</span><span>    request.path = </span><span>`/posts/</span><span>${postId}</span><span>/seen-by/users`</span><span>
</span><span>  } </span><span>else</span><span> </span><span>if</span><span> (operationChoice &lt; </span><span>7</span><span>) {
</span><span>    </span><span>// 60% of the time, get the count of seenby on a post</span><span>
</span><span>    request.method = </span><span>&#39;GET&#39;</span><span>
</span><span>    request.path = </span><span>`/posts/</span><span>${postId}</span><span>/seen-by/count`</span><span>
</span><span>  } </span><span>else</span><span> {
</span><span>    </span><span>// 30% of the time, add a new seen-by entry</span><span>
</span><span>    </span><span>const</span><span> userId = </span><span>Math</span><span>.floor(</span><span>Math</span><span>.random() * USER_COUNT)
</span>
<span>    </span><span>// Most of the time we&#39;ll be *setting* seen-by</span><span>
</span><span>    </span><span>// And we&#39;ll get the count (so we can show it) later as well</span><span>
</span><span>    request.method = </span><span>&#39;POST&#39;</span><span>
</span><span>    request.path = </span><span>`/posts/</span><span>${postId}</span><span>/seen-by/</span><span>${userId}</span><span>`</span><span>
</span>  }
<!-- -->
<span>  </span><span>return</span><span> request
</span>}
<!-- -->
<span></span><span>module</span><span>.exports = setupRequest
</span></code></pre></div></div></pre><p>Nothing too crazy here, and some back of the envelope estimations on how often each operation would normally be called. These numbers could be tweaked more, but we <em>should</em> see a difference between approaches even if we messed up massively here.</p><p>If you&#39;d like to see the code, check out <a href="https://gitlab.com/mrman/supabase-seen-by/-/blob/main/scripts/setup-request.cjs"><code>scripts/setup-request.cjs</code> in the repo</a>.</p><h3 id="glue-it-all-together">Glue it all together</h3><p>Once we&#39;re done we need to glue this all together into one script, with roughly this format:</p><pre><div><div><pre><code><span>export</span><span> </span><span>default</span><span> </span><span>async</span><span> </span><span>function</span><span> </span><span>runBenchmark</span><span>(</span><span>) </span><span>{
</span><span>  </span><span>// Start the server</span><span>
</span><span>  </span><span>// Reset before test</span><span>
</span><span>  </span><span>// Generate &amp; insert users</span><span>
</span><span>  </span><span>// Generate &amp; insert posts</span><span>
</span><span>  </span><span>// Generate actions (API Calls) to run</span><span>
</span><span>  </span><span>// Execute the API calls</span><span>
</span><span>  </span><span>// Write JSON results to tmpdir</span><span>
</span><span>  </span><span>// Stop the server</span><span>
</span>}
</code></pre></div></div></pre><p>If you want to see what the code <em>actually</em> ended up looking like, check out <a href="https://gitlab.com/mrman/supabase-seen-by/-/blob/main/scripts/bench.js"><code>scripts/bench.js</code> in the repo</a>.</p><p>Along with the benchmark, we&#39;ll standardize on the following settings:</p><pre><div><div><pre><code><span>export</span><span> SEEN_BY_STRATEGY=simple-counter </span><span># or: simple-hstore, assoc-table, hll</span><span>
</span><span></span><span>export</span><span> TEST_USERS_JSON_PATH=/tmp/supabase-seen-by.users.json
</span><span></span><span>export</span><span> TEST_POSTS_JSON_PATH=/tmp/supabase-seen-by.posts.json
</span><span></span><span>export</span><span> TEST_POST_COUNT=1000
</span><span></span><span>export</span><span> TEST_USER_COUNT=100000
</span><span></span><span>export</span><span> TEST_DURATION_SECONDS=60
</span>
<span></span><span>## Use custom postgres image built with hll extension (https://github.com/citusdata/postgresql-hll)</span><span>
</span><span></span><span>## </span><span>NOTE:</span><span> `make db-custom-image` must be run beforehand</span><span>
</span><span></span><span>#export DB_IMAGE=postgres-14.4-alpine-hll</span><span>
</span><span></span><span>#export DB_IMAGE_TAG=latest</span><span>
</span></code></pre></div></div></pre><h3 id="our-first-run-on-the-naive-solution">Our first run, on the naive solution</h3><p>Alright, finally we&#39;re ready. Let&#39;s see what we get on our naive solution. We expect this to be <em>pretty fast</em>, because not only is it <em>wrong</em>, but it&#39;s just about the simplest thing you could do.</p><p>On my local machine, here&#39;s our baseline (output from <a href="https://www.npmjs.com/package/autocannon"><code>autocannon</code></a>):</p><pre><div><div><pre><code><span>┌─────────┬──────┬──────┬───────┬──────┬─────────┬─────────┬───────┐
</span><span>│ </span><span>Stat</span><span>    │ </span><span>2</span><span>.</span><span>5</span><span>% │ </span><span>50</span><span>%  │ </span><span>97</span><span>.</span><span>5</span><span>% │ </span><span>99</span><span>%  │ Avg     │ Stdev   │ Max   │
</span>├─────────┼──────┼──────┼───────┼──────┼─────────┼─────────┼───────┤
<span>│ </span><span>Latency</span><span> │ </span><span>0</span><span> ms │ </span><span>2</span><span> ms │ </span><span>6</span><span> ms  │ </span><span>6</span><span> ms │ </span><span>2</span><span>.</span><span>03</span><span> ms │ </span><span>1</span><span>.</span><span>82</span><span> ms │ </span><span>23</span><span> ms │
</span>└─────────┴──────┴──────┴───────┴──────┴─────────┴─────────┴───────┘
<!-- -->┌───────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────┐
<span>│ </span><span>Stat</span><span>      │ </span><span>1</span><span>%      │ </span><span>2</span><span>.</span><span>5</span><span>%    │ </span><span>50</span><span>%     │ </span><span>97</span><span>.</span><span>5</span><span>%   │ Avg     │ Stdev   │ Min     │
</span>├───────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
<span>│ </span><span>Req</span><span>/Sec   │ </span><span>297</span><span>     │ </span><span>318</span><span>     │ </span><span>389</span><span>     │ </span><span>500</span><span>     │ </span><span>391</span><span>.</span><span>24</span><span>  │ </span><span>47</span><span>.</span><span>87</span><span>   │ </span><span>297</span><span>     │
</span>├───────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
<span>│ </span><span>Bytes</span><span>/Sec │ </span><span>54</span><span>.</span><span>1</span><span> kB │ </span><span>57</span><span>.</span><span>9</span><span> kB │ </span><span>70</span><span>.</span><span>8</span><span> kB │ </span><span>91</span><span>.</span><span>1</span><span> kB │ </span><span>71</span><span>.</span><span>3</span><span> kB │ </span><span>8</span><span>.</span><span>72</span><span> kB │ </span><span>54</span><span>.</span><span>1</span><span> kB │
</span>└───────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┘
<!-- -->
<span></span><span>Req</span><span>/Bytes counts sampled once per second.
</span><span></span><span># of samples: 60</span><span>
</span>
<!-- -->┌────────────┬──────────────┐
<span>│ </span><span>Percentile</span><span> │ Latency (ms) │
</span>├────────────┼──────────────┤
<span>│ </span><span>0</span><span>.</span><span>001</span><span>      │ </span><span>0</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>0</span><span>.</span><span>01</span><span>       │ </span><span>0</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>0</span><span>.</span><span>1</span><span>        │ </span><span>0</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>1</span><span>          │ </span><span>0</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>2</span><span>.</span><span>5</span><span>        │ </span><span>0</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>10</span><span>         │ </span><span>0</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>25</span><span>         │ </span><span>0</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>50</span><span>         │ </span><span>2</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>75</span><span>         │ </span><span>3</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>90</span><span>         │ </span><span>5</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>97</span><span>.</span><span>5</span><span>       │ </span><span>6</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>99</span><span>         │ </span><span>6</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>99</span><span>.</span><span>9</span><span>       │ </span><span>9</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>99</span><span>.</span><span>99</span><span>      │ </span><span>16</span><span>           │
</span>├────────────┼──────────────┤
<span>│ </span><span>99</span><span>.</span><span>999</span><span>     │ </span><span>23</span><span>           │
</span>└────────────┴──────────────┘
<!-- -->
<span></span><span>23k</span><span> requests in </span><span>60</span><span>.</span><span>02</span><span>s, </span><span>4</span><span>.</span><span>28</span><span> MB read
</span></code></pre></div></div></pre><p>As you might imagine, pretty darn good latency across all the requests.</p><h2 id="back-to-trying-things-out">Back to trying things out</h2><p>Now that we&#39;ve got a basic baseline of our tests, let&#39;s continue trying out ideas:</p><h3 id="try-2-storing-the-users-who-did-the-seeing-with-hstore">Try #2: Storing the users who did the &#34;see&#34;ing, with <code>hstore</code></h3><p>The next obvious thing (and probably a core requirement if we&#39;d asked around), is knowing <em>who</em> viewed each post. Well if we need to know who, then we probably need to store some more information!</p><p>Postgres has <a href="https://www.postgresql.org/docs/current/arrays.html">native support for arrays</a> and <a href="https://www.postgresql.org/docs/current/hstore.html">a data structure called a <code>hstore</code></a>, so let&#39;s try those. It&#39;s pretty obvious that having hundreds, thousands, or millions of entries in one of these data structures, inside a tuple isn&#39;t the <em>greatest</em> idea, but let&#39;s try it anyway and let the numbers speak for themselves.</p><p>Here&#39;s what the migration would look like:</p><pre><div><div><pre><code><span>BEGIN</span><span>;
</span>
<span></span><span>CREATE</span><span> EXTENSION IF </span><span>NOT</span><span> </span><span>EXISTS</span><span> hstore;
</span>
<span></span><span>ALTER</span><span> </span><span>TABLE</span><span> posts </span><span>ADD</span><span> </span><span>COLUMN</span><span> seen_count_hstore hstore
</span><span>  </span><span>NOT</span><span> </span><span>NULL</span><span> </span><span>DEFAULT</span><span> </span><span>&#39;&#39;</span><span>::hstore;
</span>
<span>COMMENT </span><span>ON</span><span> </span><span>COLUMN</span><span> posts.seen_count_hstore
</span><span>  </span><span>IS</span><span> </span><span>&#39;count of users that have seen the post, with hstore&#39;</span><span>;
</span>
<span></span><span>COMMIT</span><span>;
</span></code></pre></div></div></pre><p><code>hstore</code> provides support for both <a href="https://www.postgresql.org/docs/14/indexes-types.html#INDEXES-TYPE-GIST">GIST</a> and <a href="https://www.postgresql.org/docs/14/indexes-types.html#INDEXES-TYPES-GIN">GIN</a> indices, but after reading <a href="https://www.postgresql.org/docs/current/hstore.html#id-1.11.7.25.7">the documentation</a> we can conclude that we don&#39;t necessarily need those for the current set of functionality.</p><h4 id="caveats">Caveats</h4><p>Well as you might have imagined, this is obviously pretty bad and will eventually be hard to scale. If you expect only 0-50 entries in your column <code>text[]</code> is perfectly fine, but thousands or millions is another ballgame.</p><p>Thinking of how to scale this, a few ideas pop to mind:</p><ul><li>Compress our columns with <a href="https://github.com/lz4/lz4">LZ4</a> which is newly supported <a href="https://www.postgresql.org/docs/current/storage-toast.html"><code>TOAST</code> column compression</a> (I first heard about this thanks to <a href="https://www.postgresql.fastware.com/blog/what-is-the-new-lz4-toast-compression-in-postgresql-14">Fujitsu&#39;s fantastic blog post</a>)</li><li><code>PARTITION</code> our <code>posts</code> table</li></ul><h4 id="performance">Performance</h4><p>OK, time to get on with it, let&#39;s see how it performs with an <code>hstore</code>:</p><pre><div><div><pre><code><span>┌─────────┬──────┬──────┬───────┬──────┬─────────┬─────────┬───────┐
</span><span>│ </span><span>Stat</span><span>    │ </span><span>2</span><span>.</span><span>5</span><span>% │ </span><span>50</span><span>%  │ </span><span>97</span><span>.</span><span>5</span><span>% │ </span><span>99</span><span>%  │ Avg     │ Stdev   │ Max   │
</span>├─────────┼──────┼──────┼───────┼──────┼─────────┼─────────┼───────┤
<span>│ </span><span>Latency</span><span> │ </span><span>0</span><span> ms │ </span><span>2</span><span> ms │ </span><span>5</span><span> ms  │ </span><span>6</span><span> ms │ </span><span>2</span><span>.</span><span>15</span><span> ms │ </span><span>1</span><span>.</span><span>67</span><span> ms │ </span><span>16</span><span> ms │
</span>└─────────┴──────┴──────┴───────┴──────┴─────────┴─────────┴───────┘
<!-- -->┌───────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────┐
<span>│ </span><span>Stat</span><span>      │ </span><span>1</span><span>%      │ </span><span>2</span><span>.</span><span>5</span><span>%    │ </span><span>50</span><span>%     │ </span><span>97</span><span>.</span><span>5</span><span>%   │ Avg     │ Stdev   │ Min     │
</span>├───────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
<span>│ </span><span>Req</span><span>/Sec   │ </span><span>287</span><span>     │ </span><span>305</span><span>     │ </span><span>348</span><span>     │ </span><span>504</span><span>     │ </span><span>369</span><span>.</span><span>12</span><span>  │ </span><span>58</span><span>.</span><span>8</span><span>    │ </span><span>287</span><span>     │
</span>├───────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
<span>│ </span><span>Bytes</span><span>/Sec │ </span><span>53</span><span>.</span><span>9</span><span> kB │ </span><span>56</span><span>.</span><span>9</span><span> kB │ </span><span>64</span><span>.</span><span>5</span><span> kB │ </span><span>92</span><span>.</span><span>5</span><span> kB │ </span><span>68</span><span>.</span><span>3</span><span> kB │ </span><span>10</span><span>.</span><span>7</span><span> kB │ </span><span>53</span><span>.</span><span>8</span><span> kB │
</span>└───────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┘
<!-- -->
<span></span><span>Req</span><span>/Bytes counts sampled once per second.
</span><span></span><span># of samples: 60</span><span>
</span>
<!-- -->┌────────────┬──────────────┐
<span>│ </span><span>Percentile</span><span> │ Latency (ms) │
</span>├────────────┼──────────────┤
<span>│ </span><span>0</span><span>.</span><span>001</span><span>      │ </span><span>0</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>0</span><span>.</span><span>01</span><span>       │ </span><span>0</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>0</span><span>.</span><span>1</span><span>        │ </span><span>0</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>1</span><span>          │ </span><span>0</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>2</span><span>.</span><span>5</span><span>        │ </span><span>0</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>10</span><span>         │ </span><span>0</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>25</span><span>         │ </span><span>1</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>50</span><span>         │ </span><span>2</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>75</span><span>         │ </span><span>3</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>90</span><span>         │ </span><span>5</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>97</span><span>.</span><span>5</span><span>       │ </span><span>5</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>99</span><span>         │ </span><span>6</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>99</span><span>.</span><span>9</span><span>       │ </span><span>9</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>99</span><span>.</span><span>99</span><span>      │ </span><span>9</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>99</span><span>.</span><span>999</span><span>     │ </span><span>16</span><span>           │
</span>└────────────┴──────────────┘
<!-- -->
<span></span><span>22k</span><span> requests in </span><span>60</span><span>.</span><span>02</span><span>s, </span><span>4</span><span>.</span><span>1</span><span> MB read
</span></code></pre></div></div></pre><p>Not too far off! While we didn&#39;t try the pathological case(s) of millions of people liking the <em>same</em> post to hit breaking point, a slightly more random distribution seems to have done decently -- we actually have <em>lower</em> 99.999th percentile latency versus the simple counter.</p><p>An average of <code>2.15ms</code> versus <code>2.05ms</code> with the simpler counter is a ~4% increase in the average latency (though of course, the p99.999 is lower!).</p><h3 id="try-3-an-association-table-for-remembering-who-liked-what">Try #3: An Association table for remembering who liked what</h3><p>A likely requirement from the original scenario that we&#39;ve completely ignored is remembering <em>which</em> users liked a certain post to. The easiest solution here is an &#34;associative&#34; table like this one:</p><p><span><img alt="tables with associative table" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill"/></span></p><p>In SQL:</p><pre><div><div><pre><code><span>BEGIN</span><span>;
</span>
<span></span><span>CREATE</span><span> </span><span>TABLE</span><span> posts_seen_by_users (
</span><span>  post_id </span><span>bigint</span><span> </span><span>REFERENCES</span><span> posts(id),
</span><span>  user_id </span><span>bigint</span><span> </span><span>REFERENCES</span><span> users(id),
</span><span>  seen_count </span><span>bigint</span><span> </span><span>NOT</span><span> </span><span>NULL</span><span> </span><span>DEFAULT</span><span> </span><span>0</span><span> </span><span>CHECK</span><span> (seen_count </span><span>&gt;</span><span> </span><span>0</span><span>),
</span>
<span>  </span><span>PRIMARY</span><span> KEY (post_id, user_id)
</span>);
<!-- -->
<span></span><span>COMMIT</span><span>;
</span></code></pre></div></div></pre><h4 id="caveats-1">Caveats</h4><p>In production, you&#39;re going to want to do a few things to make this even remotely reasonable long term:</p><ul><li><code>PARTITION</code> the table (consider using partition-friendly <a href="https://github.com/pgpartman/pg_partman"><code>pg_partman</code></a>)</li><li>Move old partitions off to slower/colder storage and maintain snapshots</li><li>Summarize older content that might be seen lots</li><li>Consider a partitioning key up front -- post IDs are probably a reasonable thing to use if they&#39;re sufficiently randomly distributed</li></ul><p>These are good initial stop-gaps, but a realistic setup will have many problems and many more solutions to be discovered.</p><p>(It will be a recurring theme but this is a spot where <em>we probably don&#39;t necessarily want to use stock Postgres</em> but instead want to use tools like <a href="https://docs.citusdata.com/en/stable/admin_guide/table_management.html#columnar-storage">Citus Columnar Storage</a>, <a href="https://github.com/greenplum-db/postgres/tree/zedstore">ZedStore</a>, or an external choice like <a href="https://podviaznikov.com/clickhouse.tech/">ClickHouse</a>).</p><h4 id="performance-1">Performance</h4><p>Alright, enough dilly dally, let&#39;s run our test bench against this setup:</p><pre><div><div><pre><code><span>┌─────────┬──────┬──────┬───────┬──────┬────────┬─────────┬───────┐
</span><span>│ </span><span>Stat</span><span>    │ </span><span>2</span><span>.</span><span>5</span><span>% │ </span><span>50</span><span>%  │ </span><span>97</span><span>.</span><span>5</span><span>% │ </span><span>99</span><span>%  │ Avg    │ Stdev   │ Max   │
</span>├─────────┼──────┼──────┼───────┼──────┼────────┼─────────┼───────┤
<span>│ </span><span>Latency</span><span> │ </span><span>0</span><span> ms │ </span><span>2</span><span> ms │ </span><span>8</span><span> ms  │ </span><span>8</span><span> ms │ </span><span>2</span><span>.</span><span>5</span><span> ms │ </span><span>2</span><span>.</span><span>45</span><span> ms │ </span><span>30</span><span> ms │
</span>└─────────┴──────┴──────┴───────┴──────┴────────┴─────────┴───────┘
<!-- -->┌───────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────┐
<span>│ </span><span>Stat</span><span>      │ </span><span>1</span><span>%      │ </span><span>2</span><span>.</span><span>5</span><span>%    │ </span><span>50</span><span>%     │ </span><span>97</span><span>.</span><span>5</span><span>%   │ Avg     │ Stdev   │ Min     │
</span>├───────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
<span>│ </span><span>Req</span><span>/Sec   │ </span><span>238</span><span>     │ </span><span>254</span><span>     │ </span><span>321</span><span>     │ </span><span>464</span><span>     │ </span><span>326</span><span>.</span><span>52</span><span>  │ </span><span>48</span><span>.</span><span>14</span><span>   │ </span><span>238</span><span>     │
</span>├───────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
<span>│ </span><span>Bytes</span><span>/Sec │ </span><span>43</span><span>.</span><span>4</span><span> kB │ </span><span>46</span><span>.</span><span>3</span><span> kB │ </span><span>58</span><span>.</span><span>5</span><span> kB │ </span><span>84</span><span>.</span><span>5</span><span> kB │ </span><span>59</span><span>.</span><span>5</span><span> kB │ </span><span>8</span><span>.</span><span>77</span><span> kB │ </span><span>43</span><span>.</span><span>3</span><span> kB │
</span>└───────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┘
<!-- -->
<span></span><span>Req</span><span>/Bytes counts sampled once per second.
</span><span></span><span># of samples: 60</span><span>
</span>
<!-- -->┌────────────┬──────────────┐
<span>│ </span><span>Percentile</span><span> │ Latency (ms) │
</span>├────────────┼──────────────┤
<span>│ </span><span>0</span><span>.</span><span>001</span><span>      │ </span><span>0</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>0</span><span>.</span><span>01</span><span>       │ </span><span>0</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>0</span><span>.</span><span>1</span><span>        │ </span><span>0</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>1</span><span>          │ </span><span>0</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>2</span><span>.</span><span>5</span><span>        │ </span><span>0</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>10</span><span>         │ </span><span>0</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>25</span><span>         │ </span><span>1</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>50</span><span>         │ </span><span>2</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>75</span><span>         │ </span><span>4</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>90</span><span>         │ </span><span>7</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>97</span><span>.</span><span>5</span><span>       │ </span><span>8</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>99</span><span>         │ </span><span>8</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>99</span><span>.</span><span>9</span><span>       │ </span><span>11</span><span>           │
</span>├────────────┼──────────────┤
<span>│ </span><span>99</span><span>.</span><span>99</span><span>      │ </span><span>25</span><span>           │
</span>├────────────┼──────────────┤
<span>│ </span><span>99</span><span>.</span><span>999</span><span>     │ </span><span>30</span><span>           │
</span>└────────────┴──────────────┘
<!-- -->
<span></span><span>20k</span><span> requests in </span><span>60</span><span>.</span><span>02</span><span>s, </span><span>3</span><span>.</span><span>57</span><span> MB read
</span></code></pre></div></div></pre><p>A little bit more divergence here -- 99.999%ile latency @ 30 which is almost double what it was for simple-hstore.</p><p>Average is coming in at <code>2.50ms</code> which is 16% slower than simple-hstore and 21% slower than simple-counter.</p><h3 id="try-4-getting-a-bit-more-serious-bringing-out-the-hyperloglog">Try #4: Getting a bit more serious: bringing out the HyperLogLog</h3><p><span><img alt="rest of the owl" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill"/></span></p><p>We&#39;ll just draw <a href="https://knowyourmeme.com/memes/how-to-draw-an-owl">the rest of the owl</a> now.</p><p>What&#39;s <a href="https://en.wikipedia.org/wiki/HyperLogLog">HyperLogLog</a> you ask? Well it&#39;s just a probablistic data structure! Don&#39;t worry if you&#39;ve never heard of it before, it&#39;s a reasonably advanced concept.</p><p>You may have heard of <a href="https://en.wikipedia.org/wiki/Bloom_filter">Bloom Filters</a> and they&#39;re <em>somewhat</em> related but they&#39;re not quite a great fit for the problem we&#39;re solving since we want to know how many people have seen a particular post. Knowing whether one user has seen a particular post is useful too -- but not quite what we&#39;re solving for here (and we&#39;d have to double-check our false positives anyway if we wanted to be absolutely sure).</p><p>HyperLogLog provides a probablistic data structure that is good at counting <em>distinct</em> entries, so that means that the count <em>will not</em> be exact, but be reasonably close (depending on how we tune). We won&#39;t have false positives (like with a bloom filter) -- we&#39;ll have a degree of error (i.e. the actual count may be 1000, but the HLL reports 1004).</p><p>We have to take this into account on the UI side but and maybe retrieve the full count if anyone ever <em>really</em> needs to know/view individual users that have seen the content, so we can fall back to our association table there.</p><p>Given that <a href="https://www.internetlivestats.com/twitter-statistics/">every second there are about 6000 tweets on Twitter(!)</a>, this is probably one of the only solutions that could actually work at massive scale with the limitations we&#39;ve placed on ourselves.</p><p>Here&#39;s what that looks like in SQL:</p><pre><div><div><pre><code><span>BEGIN</span><span>;
</span>
<span></span><span>CREATE</span><span> EXTENSION IF </span><span>NOT</span><span> </span><span>EXISTS</span><span> hll;
</span>
<span></span><span>ALTER</span><span> </span><span>TABLE</span><span> posts </span><span>ADD</span><span> </span><span>COLUMN</span><span> seen_count_hll hll
</span><span>  </span><span>NOT</span><span> </span><span>NULL</span><span> </span><span>DEFAULT</span><span> hll_empty();
</span>
<span>COMMENT </span><span>ON</span><span> </span><span>COLUMN</span><span> posts.seen_count_hll
</span><span>  </span><span>IS</span><span> </span><span>&#39;HyperLogLog storing user IDs&#39;</span><span>;
</span>
<span></span><span>COMMIT</span><span>;
</span></code></pre></div></div></pre><p>Here we need the <a href="https://github.com/citusdata/postgresql-hll"><code>citus/postgresql-hll</code></a> extension, which is generously made (<a href="https://github.com/citusdata/postgresql-hll/blob/master/LICENSE">truly</a>) open source by <a href="https://www.citusdata.com/">citusdata</a>.</p><p>NOTE that we still have access to the association table -- and while we still insert rows into it, we can <em>drop</em> the primary key index, and simply update our HLL (and leave ourselves a note on when we last updated it).</p><h3 id="caveats-2">Caveats</h3><p>There&#39;s not much to add to this solution, as the heavy lifting is mostly done by <code>postgresql-hll</code>, but there&#39;s one big caveat:</p><ul><li>This approach <em>will</em> need a custom Postgres image for this, since <code>hll</code> is not an official <code>contrib</code> module</li></ul><p>There are also a few optimizations that are easy to imagine:</p><ul><li>Batching inserts to the association table (storing them in some other medium in the meantime -- local disk, redis, etc)</li><li>Writing our association table entries in a completely different storage medium altogether (like object storage) and use <a href="https://www.postgresql.org/docs/current/postgres-fdw.html">Foreign Data Wrappers</a> and <a href="https://github.com/citusdata/pg_cron"><code>pg_cron</code></a> and delay or put off processing all together</li></ul><h3 id="performance-2">Performance</h3><p>The most complicated solution by far, let&#39;s see how it fares:</p><pre><div><div><pre><code><span>┌─────────┬──────┬──────┬───────┬──────┬─────────┬─────────┬───────┐
</span><span>│ </span><span>Stat</span><span>    │ </span><span>2</span><span>.</span><span>5</span><span>% │ </span><span>50</span><span>%  │ </span><span>97</span><span>.</span><span>5</span><span>% │ </span><span>99</span><span>%  │ Avg     │ Stdev   │ Max   │
</span>├─────────┼──────┼──────┼───────┼──────┼─────────┼─────────┼───────┤
<span>│ </span><span>Latency</span><span> │ </span><span>0</span><span> ms │ </span><span>2</span><span> ms │ </span><span>6</span><span> ms  │ </span><span>6</span><span> ms │ </span><span>2</span><span>.</span><span>28</span><span> ms │ </span><span>2</span><span>.</span><span>03</span><span> ms │ </span><span>59</span><span> ms │
</span>└─────────┴──────┴──────┴───────┴──────┴─────────┴─────────┴───────┘
<!-- -->┌───────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────┬─────────┐
<span>│ </span><span>Stat</span><span>      │ </span><span>1</span><span>%      │ </span><span>2</span><span>.</span><span>5</span><span>%    │ </span><span>50</span><span>%     │ </span><span>97</span><span>.</span><span>5</span><span>%   │ Avg     │ Stdev   │ Min     │
</span>├───────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
<span>│ </span><span>Req</span><span>/Sec   │ </span><span>272</span><span>     │ </span><span>285</span><span>     │ </span><span>351</span><span>     │ </span><span>456</span><span>     │ </span><span>353</span><span>.</span><span>05</span><span>  │ </span><span>45</span><span>.</span><span>13</span><span>   │ </span><span>272</span><span>     │
</span>├───────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┼─────────┤
<span>│ </span><span>Bytes</span><span>/Sec │ </span><span>49</span><span>.</span><span>5</span><span> kB │ </span><span>51</span><span>.</span><span>9</span><span> kB │ </span><span>63</span><span>.</span><span>9</span><span> kB │ </span><span>83</span><span>.</span><span>1</span><span> kB │ </span><span>64</span><span>.</span><span>3</span><span> kB │ </span><span>8</span><span>.</span><span>22</span><span> kB │ </span><span>49</span><span>.</span><span>5</span><span> kB │
</span>└───────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┴─────────┘
<!-- -->
<span></span><span>Req</span><span>/Bytes counts sampled once per second.
</span><span></span><span># of samples: 60</span><span>
</span>
<!-- -->┌────────────┬──────────────┐
<span>│ </span><span>Percentile</span><span> │ Latency (ms) │
</span>├────────────┼──────────────┤
<span>│ </span><span>0</span><span>.</span><span>001</span><span>      │ </span><span>0</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>0</span><span>.</span><span>01</span><span>       │ </span><span>0</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>0</span><span>.</span><span>1</span><span>        │ </span><span>0</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>1</span><span>          │ </span><span>0</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>2</span><span>.</span><span>5</span><span>        │ </span><span>0</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>10</span><span>         │ </span><span>0</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>25</span><span>         │ </span><span>1</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>50</span><span>         │ </span><span>2</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>75</span><span>         │ </span><span>4</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>90</span><span>         │ </span><span>6</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>97</span><span>.</span><span>5</span><span>       │ </span><span>6</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>99</span><span>         │ </span><span>6</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>99</span><span>.</span><span>9</span><span>       │ </span><span>9</span><span>            │
</span>├────────────┼──────────────┤
<span>│ </span><span>99</span><span>.</span><span>99</span><span>      │ </span><span>28</span><span>           │
</span>├────────────┼──────────────┤
<span>│ </span><span>99</span><span>.</span><span>999</span><span>     │ </span><span>59</span><span>           │
</span>└────────────┴──────────────┘
<!-- -->
<span></span><span>21k</span><span> requests in </span><span>60</span><span>.</span><span>03</span><span>s, </span><span>3</span><span>.</span><span>86</span><span> MB read
</span></code></pre></div></div></pre><p>Another somewhat nuanced degradation in performance -- while the 99.99%ile latency was nearly 2x higher, the average latency was actually <em>lower</em> than the assoc-table approach @ <code>2.28ms</code>.</p><p>The average latency on the HLL approach is 11% worse than simple-counter, 6% worse than simple-hstore, and <em>faster</em> than assoc-table alone, which is an improvement.</p><h3 id="oh-the-other-places-we-could-go">Oh, the other places we could go</h3><p>One of the great things about Postgres is it&#39;s expansive ecosystem -- while Postgres may (and frankly <em>should not</em>) beat the perfect specialist tool for your use case, it often does an outstanding job in the general case.</p><p>Let&#39;s look into some more experiments that could be run -- maybe one day in the future we&#39;ll get some numbers behind these (community contributions are welcome!).</p><h4 id="incremental-view-maintenance-powered-by-pg_ivm">Incremental view maintenance powered by <code>pg_ivm</code></h4><p>If you haven&#39;t heard about <a href="https://github.com/sraoss/pg_ivm"><code>pg_ivm</code></a> it&#39;s an extension for handling Incremental View Maintenance -- updating <a href="https://www.postgresql.org/docs/14/sql-createview.html"><code>VIEW</code></a>s when underlying tables change.</p><p>IVM is a hotly requested feature whenever views (particularly materialized views) are mentioned, so there has been much fanfare to it&#39;s release.</p><p>There are a couple advantages we could gain by using <code>pg_ivm</code>:</p><ul><li>Ability to time constrain calculations (newer posts which are more likely to be seen can exist in instant-access views)</li><li>We could theoretically remove the complicated nature of the HLL all together by using <code>COUNT</code> with IVM</li></ul><p><code>pg_ivm</code> is quite new and cutting edge but looks to be a great solution -- it&#39;s worth giving a shot someday.</p><h3 id="doing-graph-computations-with-age">Doing graph computations with <a href="https://age.apache.org/">AGE</a></h3><p>As is usually the case in academia and practice, we can make our problem drastically easier by simply changing the data structures we use to model our problem!</p><p>One such reconfiguration would be storing the information as a graph:</p><p><span><img alt="graph of seen by relation" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill"/></span></p><p>As you might imagine, finding the number of &#34;seen-by&#34; relations would simply be counting the number of edges out of one of the nodes!</p><p>Well, the Postgres ecosystem has us covered here too! <a href="https://age.apache.org/">AGE</a> is an extension that allows you to perform graph related queries in Postgres.</p><p>We won&#39;t pursue it in this post but it would be a great way to model this problem as well -- thanks to the extensibility of Postgres, this data could live right next to our normal relational data as well.</p><h2 id="so-whats-the-best-way-to-do-it">So what&#39;s the best way to do it?</h2><p>OK, so what&#39;s the answer at the end of the day? What&#39;s the best way to get to that useful v1? Here are the numbers:</p><p><span><img alt="latency graph showing simple-hstore,hll,hll,and assoc table in speed order" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill"/></span></p><p>In tabular form:</p><table><thead><tr><th>Approach</th><th>Avg (ms)</th><th>99%ile (ms)</th><th>99.999%ile (ms)</th></tr></thead><tbody><tr><td>simple-counter</td><td>2.03</td><td>6</td><td>23</td></tr><tr><td>simple-hstore</td><td>2.15</td><td>6</td><td>16</td></tr><tr><td>assoc-table</td><td>2.5</td><td>8</td><td>30</td></tr><tr><td>hll</td><td>2.16</td><td>7</td><td>27</td></tr></tbody></table><p><strong>If we go strictly with the data, the best way <em>looks</em> to be the <code>hstore</code>-powered solution, but I think the HLL is probably the right choice.</strong></p><p>The HLL results were quite variable -- some runs were faster than others, so I&#39;ve taken the best of 3 runs.</p><p>Even though the data says <code>hstore</code>, knowing that posts will be seen by more and more people over time, I <em>might</em> choose the HLL solution for an actual implementation. It&#39;s far less likely to pose a bloated row problem, and it has the absolute correctness (and later recall) of the assoc-table solution, while performing better over all (as you can imagine, no need to <code>COUNT</code> rows).</p><p>Another benefit of the HLL solution is that <a href="https://www.postgresql.org/docs/current/manage-ag-tablespaces.html">PostgreSQL tablespaces</a> allow us to put the association table on a different, slower storage mechanism, and keep our <code>posts</code> table fast. Arguably in a real system we might have the HLL in something like <code>redis</code> but for a v1, it looks like Postgres does quite well!</p><p>I hope you enjoyed this look down the trunk hole, and you&#39;ve got an idea of how to implement solutions to surprisingly complex problems like this one with Postgres.</p><p>As usual, Postgres has the tools to solve the problem <em>reasonably</em> well (if not completely) before you reach out for more complicated/standalone solutions.</p><p><strong>See any problems with the code, solutions that haven&#39;t been tried? -- reach out, or open an issue!</strong></p><h2 id="more-postgres-resources">More Postgres resources</h2><ul><li><a href="https://supabase.com/blog/2022/06/28/partial-postgresql-data-dumps-with-rls">Partial data dumps using Postgres Row Level Security</a></li><li><a href="https://supabase.com/blog/2020/11/18/postgresql-views">Postgres Views</a></li><li><a href="https://supabase.com/blog/2022/03/08/audit">Postgres Auditing in 150 lines of SQL</a></li><li><a href="https://supabase.com/blog/2021/02/27/cracking-postgres-interview">Cracking PostgreSQL Interview Questions</a></li><li><a href="https://supabase.com/blog/2020/07/09/postgresql-templates">What are PostgreSQL Templates?</a></li><li><a href="https://supabase.com/blog/2021/12/01/realtime-row-level-security-in-postgresql">Realtime Postgres RLS on Supabase</a></li></ul></div></article></div>
  </body>
</html>
