<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.timescale.com/blog/how-postgresql-views-and-materialized-views-work-and-how-they-influenced-timescaledb-continuous-aggregates/">Original</a>
    <h1>PostgreSQL views and materialized views and how they influenced TimescaleDB</h1>
    
    <div id="readability-page-1" class="page"><div>
        <p>Soon after I graduated from college, I was working on starting a business and moved into a house near campus with five friends. The house was a bit run down, but the rent was cheap, and the people were great. </p><p>I lived there for a couple of years, and we developed a tradition: whenever someone would move out, we would ask them to share three pieces of wisdom with the group. Some were silly, some were serious, some were profound, none seemed remotely related to PostgreSQL or materialized views at the time, but one really has stuck with me. My friend Jason, who’d just finished his Ph.D. in Applied Physics, said the wisdom he’d learned was “Don’t squander your ignorance.” He explained that once you learn something, you end up taking it for granted and it becomes so much harder to overcome your tacit knowledge and ask simple, but important, questions.</p><p>A few months ago, I started a new role managing Engineering Education here at Timescale, and as I’ve started teaching more, Jason’s advice has never been more relevant. Teaching is all about reclaiming squandered ignorance; it’s about constantly remembering what it was like to first learn something, even when you’ve been working on it for years. The things that felt like revelations when we first learned them feel normal as we continue in the field. </p><p>So it’s been common for me that things I’ve worked most closely on can be the hardest to teach. Continuous aggregates are one of the most popular features of TimescaleDB and one of the ones I’m most proud of, partially because I helped design them. </p><p>We were recently working on a <a href="https://www.timescale.com/blog/how-we-made-data-aggregation-better-and-faster-on-postgresql-with-timescaledb-2-7/">revamp of continuous aggregates</a>, and as we were discussing the changes, I realized that whenever I’ve explained continuous aggregates, I’ve done it with all of this context about PostgreSQL views and materialized views in my head.</p><p>I was lucky enough to learn this by trial and error; I had problems that forced me to learn about views and materialized views and figure out all the ways they worked and didn’t work, and I was able to bring that experience to their design when I joined Timescale, but not everyone has that luxury.</p><p><strong>This post is an attempt to distill a few lessons about what views and materialized views in PostgreSQL are, what they’re good at, where they fall short, and how we learned from them to make continuous aggregates incredible tools for time-series data analysis. </strong></p><h2 id="getting-started-with-views-and-materialized-views">Getting Started With Views and Materialized Views</h2><p>To get an understanding of PostgreSQL views, materialized views, and TimescaleDB continuous aggregates, we’re going to want to have some data to work with to demonstrate the concepts and better understand where each of them is most useful. </p><p>Also, I won’t go through the whole thing here, but you should know that we have a <code>company</code> table and a <code>stocks_real_time</code> hypertable, defined like so:</p><!--kg-card-begin: markdown--><pre><code>CREATE TABLE company (
    symbol text NOT NULL,
    name text NOT NULL
);

CREATE TABLE stocks_real_time (
    time timestamp with time zone NOT NULL,
    symbol text NOT NULL,
    price double precision,
    day_volume integer
);
CREATE INDEX ON stocks_real_time (symbol, time);
SELECT create_hypertable(&#39;stocks_real_time&#39;, &#39;time&#39;);
</code></pre>
<!--kg-card-end: markdown--><p>Once you’ve set that up, you can <a href="https://docs.timescale.com/getting-started/latest/add-data/">import data</a>, and you should be able to follow along with the rest if you’d like.</p><h2 id="what-are-postgresql-views-why-should-i-use-them">What Are PostgreSQL Views? Why Should I Use Them?</h2><p>One thing we might want to explore with this dataset is being able to get the name of our company. You’ll note that the <code>name</code> column only exists in the <code>company</code> table, which can be joined to the <code>stocks_real_time</code> table on the <code>symbol</code> column so we can query by either like so:</p><!--kg-card-begin: markdown--><pre><code>CREATE VIEW stocks_company AS 
SELECT s.symbol, s.price, s.time, s.day_volume, c.name 
FROM stocks_real_time s 
INNER JOIN company c ON s.symbol = c.symbol;
</code></pre>
<!--kg-card-end: markdown--><p>Once I’ve created a view, I can refer to it in another query:</p><!--kg-card-begin: markdown--><pre><code>SELECT symbol, price 
FROM stocks_company 
WHERE time &gt;= &#39;2022-04-05&#39; and time &lt;&#39;2022-04-06&#39;;
</code></pre>
<!--kg-card-end: markdown--><p>But what is that actually doing under the hood? As I mentioned before, the view acts as an alias for the stored query, so PostgreSQL replaces the view <code>stocks_company</code> with the query it was defined with and runs the full resulting query. That means the query to the <code>stocks_company</code> view is the same as:</p><!--kg-card-begin: markdown--><pre><code>SELECT symbol, price 
FROM (
SELECT s.symbol, s.price, s.time, s.day_volume, c.name 
FROM stocks_real_time s 
INNER JOIN company c ON s.symbol = c.symbol) sc 
WHERE time &gt;= &#39;2022-04-05&#39; and time &lt;&#39;2022-04-06&#39;;
</code></pre>
<!--kg-card-end: markdown--><p>We’ve manually replaced the view with the same query that we defined it with. </p><p>How can we tell that they are the same? The <code>EXPLAIN</code>command tells us how PostgreSQL executes a query, and we can use it to see if the query to the view and the query that just runs the query in a subselect produce the same output. </p><p>Note, I know that <code>EXPLAIN</code> plans can initially seem a little intimidating. I’ve tried to make it so you don’t need to know a whole lot about <code>EXPLAIN</code> plans or the like to understand this post, <a href="https://www.timescale.com/blog/p/ea9fed0b-de05-4f7a-aa47-604680db9ad5/#what-postgresql-materialized-views-are-and-when-to-use-them">so if you don’t want to read them, feel free to skip over them</a>.</p><p>And if we run both:</p><!--kg-card-begin: markdown--><pre><code>EXPLAIN (ANALYZE ON, BUFFERS ON) 
SELECT symbol, price 
FROM stocks_company 
WHERE time &gt;= &#39;2022-04-05&#39; and time &lt;&#39;2022-04-06&#39;;
--AND
EXPLAIN (ANALYZE ON, BUFFERS ON) 
SELECT symbol, price 
FROM (
SELECT s.symbol, s.price, s.time, s.day_volume, c.name 
FROM stocks_real_time s 
INNER JOIN company c ON s.symbol = c.symbol) sc 
WHERE time &gt;= &#39;2022-04-05&#39; and time &lt;&#39;2022-04-06&#39;;
</code></pre>
<!--kg-card-end: markdown--><p>We can see that they both produce the same query plan (though the timings might be slightly different, they’ll even out with repeated runs).</p><!--kg-card-begin: markdown--><pre><code>Hash Join  (cost=3.68..16328.94 rows=219252 width=12) (actual time=0.110..274.764 rows=437761 loops=1)
   Hash Cond: (s.symbol = c.symbol)
   Buffers: shared hit=3667
   -&gt;  Index Scan using _hyper_5_2655_chunk_stocks_real_time_time_idx on _hyper_5_2655_chunk s  (cost=0.43..12488.79 rows=438503 width=12) (actual time=0.057..125.607 rows=437761 loops=1)
         Index Cond: ((&#34;time&#34; &gt;= &#39;2022-04-05 00:00:00+00&#39;::timestamp with time zone) AND (&#34;time&#34; &lt; &#39;2022-04-06 00:00:00+00&#39;::timestamp with time zone))
         Buffers: shared hit=3666
   -&gt;  Hash  (cost=2.00..2.00 rows=100 width=4) (actual time=0.034..0.035 rows=100 loops=1)
         Buckets: 1024  Batches: 1  Memory Usage: 12kB
         Buffers: shared hit=1
         -&gt;  Seq Scan on company c  (cost=0.00..2.00 rows=100 width=4) (actual time=0.006..0.014 rows=100 loops=1)
               Buffers: shared hit=1
 Planning:
   Buffers: shared hit=682
 Planning Time: 1.807 ms
 Execution Time: 290.851 ms
(15 rows)
</code></pre>
<!--kg-card-end: markdown--><p>The plan joins the <code>company</code> to the relevant chunk of the <code>stocks_real_time</code> hypertable and uses an index scan to fetch the right rows. But you don’t really need to understand exactly what’s going on here to understand that they’re doing the same thing.</p><div><p>✨</p><p><strong>Editor&#39;s Note: </strong>If you’d like to learn more about EXPLAIN, I recommend taking a look at the <a href="https://www.youtube.com/watch?v=UUcVS0290nY&amp;list=PLsceB9ac9MHRnmNZrCn_TWkUrCBCPR3mc&amp;index=8">Explaining Explain session</a> that my colleague Feike Steenbergen gave a couple of weeks ago. It was awesome!</p></div><h3 id="views-hide-complexity">Views hide complexity</h3><p>The <code>JOIN</code> in our view is very simple, which means the aliased query is relatively simple, but you can imagine that as the views get more complex, it can be very helpful to have a much simpler way for a user to query the database, where they don’t have to write all the <code>JOINs</code> themselves. (You can also use special views like <a href="https://www.2ndquadrant.com/en/blog/how-do-postgresql-security_barrier-views-work/">security barrier views to grant access to data securely</a>, but that’s more than we can cover here!).</p><p>Unfortunately, hiding the complexity can also be a problem. For instance, you may or may not have noticed in our example that we <em>don’t actually need the <code>JOIN</code>!</em> The <code>JOIN</code> gets us the <code>name</code> column from the <code>company</code> table, but we’re only selecting the <code>symbol</code> and <code>price</code> columns, which come from the <code>stocks_real_time</code> table! If we run the query directly on the table, it can go about twice as  fast by avoiding the <code>JOIN</code>:</p><!--kg-card-begin: markdown--><pre><code>Index Scan using _hyper_5_2655_chunk_stocks_real_time_time_idx on _hyper_5_2655_chunk  (cost=0.43..12488.79 rows=438503 width=12) (actual time=0.021..72.770 rows=437761 loops=1)
  Index Cond: ((&#34;time&#34; &gt;= &#39;2022-04-05 00:00:00+00&#39;::timestamp with time zone) AND (&#34;time&#34; &lt; &#39;2022-04-06 00:00:00+00&#39;::timestamp with time zone))
  Buffers: shared hit=3666
Planning:
  Buffers: shared hit=10
Planning Time: 0.243 ms
Execution Time: 140.775 ms
</code></pre>
<!--kg-card-end: markdown--><p>If I’d written out the query, I might have seen that I didn’t need the <code>JOIN</code> (or never written it in the first place). Whereas the view hides that complexity. So they can make things easier, but that can lead to performance pitfalls if we’re not careful. </p><p>If we actually <code>SELECT</code> the <code>name</code> column, then we could say we’re using the view more for what it was meant for like so:</p><!--kg-card-begin: markdown--><pre><code>SELECT name, price, symbol 
FROM stocks_company 
WHERE time &gt;= &#39;2022-04-05&#39; AND time &lt;&#39;2022-04-06&#39;;
</code></pre>
<!--kg-card-end: markdown--><p>So to sum up this section on views: </p><ul><li>Views are a way to store an alias for a query in the database.</li><li>PostgreSQL will replace the view name with the query you use in the view definition. </li></ul><p>Views can be good for reducing complexity for the user, so they don’t have to write out complex <code>JOINs</code>, but can also lead to performance problems if they are overused and because hiding the complexity can make it harder to identify potential performance pitfalls. </p><p>One thing you’ll notice is that <strong>views can improve the user interface, but they won’t really ever improve performance</strong>, because they don’t actually run the query, they just alias it. If you want something that runs the query, you’ll need a materialized view.</p><h2 id="what-postgresql-materialized-views-are-and-when-to-use-them">What PostgreSQL Materialized Views Are and When to Use Them</h2><p>When I <a href="https://www.postgresql.org/docs/current/sql-creatematerializedview.html">create a materialized view</a>, it actually runs the query and stores the results. In essence, this means the materialized view acts as a <a href="https://en.wikipedia.org/wiki/Cache_(computing)">cache</a> for the query. Caching is a common way to improve performance in all sorts of computing systems. The question we might ask is: will it be helpful here? So let’s try it out and see how it goes. </p><!--kg-card-begin: markdown--><pre><code>CREATE MATERIALIZED VIEW stocks_company_mat AS 
SELECT s.symbol, s.price, s.time, s.day_volume, c.name 
FROM stocks_real_time s INNER JOIN company c ON s.symbol = c.symbol;

CREATE INDEX on stocks_company_mat (symbol, time DESC);
CREATE INDEX on stocks_company_mat (time DESC);
</code></pre>
<!--kg-card-end: markdown--><p>You’ll also notice that I created some indexes on the materialized view (the same ones I have on <code>stocks_real_time</code>)! That’s one of the cool things about materialized views, you can create indexes on them because under the hood they’re just tables that store the results of a query (we’ll explain that more later). </p><p>Now I can run <code>EXPLAIN ANALYZE</code> on a slightly different query, where I’m trying to get the data for ‘AAPL’ for four days on both to understand how much this caching helps our query:</p><figure><img src="https://www.timescale.com/blog/content/images/2022/07/1--1-.png" alt="" loading="lazy" width="2000" height="913" srcset="https://www.timescale.com/blog/content/images/size/w600/2022/07/1--1-.png 600w, https://www.timescale.com/blog/content/images/size/w1000/2022/07/1--1-.png 1000w, https://www.timescale.com/blog/content/images/size/w1600/2022/07/1--1-.png 1600w, https://www.timescale.com/blog/content/images/size/w2400/2022/07/1--1-.png 2400w" sizes="(min-width: 720px) 720px"/></figure><p>Taking a look at these plans, we can see that it helps less than one might think! It sped it up a little, but really, they’re doing almost the same amount of work! How can I tell? Well, they scan approximately the same number of 8KB buffers (see <a href="https://www.youtube.com/watch?v=JOrXRsES3mk&amp;list=PLsceB9ac9MHRnmNZrCn_TWkUrCBCPR3mc&amp;index=1">Lesson 0 of the Foundations series</a> to learn more about those), and they scan the same number of rows.</p><h3 id="when-materialized-view-performance-doesnt-materialize">When materialized view performance doesn&#39;t materialize</h3><p>Why is this? Well, our <code>JOIN</code> didn’t reduce the number of rows in the query, so the materialized view <code>stocks_company_mat</code> actually has the same number of rows in it as the <code>stocks_real_time</code> hypertable!</p><!--kg-card-begin: markdown--><pre><code>SELECT 
(SELECT count(*) FROM stocks_company_mat) as rows_mat, 
(SELECT count(*) FROM stocks_real_time) as rows_tab;

 rows_mat | rows_tab 
----------+----------
  7375355 |  7375355

</code></pre>
<!--kg-card-end: markdown--><p>So, not a huge benefit, and <em>we have to store the same number of rows over again</em>. So we’re getting little benefit for a pretty large cost in terms of how much storage we have to use. Now this could have been a large benefit if we were running a very expensive function or doing a very complex <code>JOIN</code> in our materialized view definition, but we’re not, so this doesn’t save us much. </p><p>The thing about our example is that it only gets worse from here. One of the things we might want to do with our view or materialized view is being able to use a <code>WHERE</code> clause to filter not just on <code>symbol</code> but on the company <code>name</code>. (Maybe I don’t remember the stock symbol for a company, but I do remember its name.) Remember that the <code>name</code> column is the one we joined on, so let’s run that query on both the view and materialized view and see what happens:</p><figure><img src="https://www.timescale.com/blog/content/images/2022/07/2--2---1-.png" alt="" loading="lazy" width="2000" height="881" srcset="https://www.timescale.com/blog/content/images/size/w600/2022/07/2--2---1-.png 600w, https://www.timescale.com/blog/content/images/size/w1000/2022/07/2--2---1-.png 1000w, https://www.timescale.com/blog/content/images/size/w1600/2022/07/2--2---1-.png 1600w, https://www.timescale.com/blog/content/images/size/w2400/2022/07/2--2---1-.png 2400w" sizes="(min-width: 720px) 720px"/></figure><p>This time, my query on the regular view is much better! It hits far fewer buffers and returns 10x faster! This is because we created an index on <code>(symbol, time DESC)</code> for the materialized view, but not on <code>(name, time DESC)</code>, so it has to fall back to scanning the full <code>time</code>index and removing the rows that don’t match. </p><p>The normal view, however, can use the more selective <code>(symbol, time DESC)</code> on the <code>stocks_real_time</code> hypertable because it’s performing the <code>JOIN</code> to the <code>company</code> table, and it joins on the <code>symbol</code> column, which means it can still use the more selective index. We “enhanced” the materialized view by performing the <code>JOIN</code> and caching the results, but then we’d need to create an index on the joined column too. </p><h3 id="when-materialized-views-perform-well">When materialized views perform well</h3><p>As it turns out, there’s a very common set of queries on stock data like this that does reduce the number of rows, they’re called <strong>O</strong>pen-<strong>H</strong>igh-<strong>L</strong>ow-<strong>C</strong>lose queries (OHLC), and they look something like this:</p><!--kg-card-begin: markdown--><pre><code>CREATE VIEW ohlc_view AS 
SELECT time_bucket(&#39;15 min&#39;, time) bucket, symbol, first(time, price), max(price), min(price), last(time, price) 
FROM stocks_real_time 
WHERE time &gt;= &#39;2022-04-05&#39; and time &lt;&#39;2022-04-06&#39; 
GROUP BY time_bucket(&#39;15 min&#39;, time), symbol;

CREATE MATERIALIZED VIEW ohlc_mat AS 
SELECT time_bucket(&#39;15 min&#39;, time) bucket, symbol, first(time, price), max(price), min(price), last(time, price) 
FROM stocks_real_time 
GROUP BY time_bucket(&#39;15 min&#39;, time), symbol ;

CREATE INDEX on ohlc_mat(symbol, bucket);
CREATE INDEX ON ohlc_mat(bucket);
</code></pre>
<!--kg-card-end: markdown--><p>Here I’m aggregating a lot of rows together, so I end up storing a lot fewer in my materialized view. (The view doesn’t store any rows, it’s just an alias for the query.) I still created a few indexes to help speed lookups, but they’re much smaller as well because there are many fewer rows in the output of this query. So now, if I select from the normal view and the materialized view, I see a huge speedup!</p><figure><img src="https://www.timescale.com/blog/content/images/2022/07/3_Normal_view--1-.png" alt="" loading="lazy" width="2000" height="747" srcset="https://www.timescale.com/blog/content/images/size/w600/2022/07/3_Normal_view--1-.png 600w, https://www.timescale.com/blog/content/images/size/w1000/2022/07/3_Normal_view--1-.png 1000w, https://www.timescale.com/blog/content/images/size/w1600/2022/07/3_Normal_view--1-.png 1600w, https://www.timescale.com/blog/content/images/size/w2400/2022/07/3_Normal_view--1-.png 2400w" sizes="(min-width: 720px) 720px"/></figure><p>Materialized view:</p><figure><img src="https://www.timescale.com/blog/content/images/2022/07/4_Materialized_View--1-.png" alt="" loading="lazy" width="2000" height="523" srcset="https://www.timescale.com/blog/content/images/size/w600/2022/07/4_Materialized_View--1-.png 600w, https://www.timescale.com/blog/content/images/size/w1000/2022/07/4_Materialized_View--1-.png 1000w, https://www.timescale.com/blog/content/images/size/w1600/2022/07/4_Materialized_View--1-.png 1600w, https://www.timescale.com/blog/content/images/size/w2400/2022/07/4_Materialized_View--1-.png 2400w" sizes="(min-width: 720px) 720px"/></figure><p>Well, that helped! We hit far fewer buffers and scanned far fewer rows with the materialized case, and we didn’t need to perform the <code>GROUP BY</code> and aggregate, which removes a sort, etc. All of that means that we sped up our query dramatically! But, it’s not rainbows and butterflies for materialized views. Because we didn’t cover one of their big problems, they get out of date!</p><figure><img src="https://www.timescale.com/blog/content/images/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_1.png" alt="" loading="lazy" width="1526" height="1096" srcset="https://www.timescale.com/blog/content/images/size/w600/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_1.png 600w, https://www.timescale.com/blog/content/images/size/w1000/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_1.png 1000w, https://www.timescale.com/blog/content/images/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_1.png 1526w" sizes="(min-width: 720px) 720px"/></figure><figure><img src="https://www.timescale.com/blog/content/images/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_2.png" alt="" loading="lazy" width="1526" height="1214" srcset="https://www.timescale.com/blog/content/images/size/w600/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_2.png 600w, https://www.timescale.com/blog/content/images/size/w1000/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_2.png 1000w, https://www.timescale.com/blog/content/images/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_2.png 1526w" sizes="(min-width: 720px) 720px"/></figure><p>Essentially, materialized views are only as accurate as the last time they ran the query they are caching. You need to run <code>REFRESH MATERIALIZED VIEW</code>  to ensure they are up to date. </p><p>Once you run <code>REFRESH MATERIALIZED VIEW</code>, we’ll end up with the new data in our materialized view, like so:</p><figure><img src="https://www.timescale.com/blog/content/images/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_3.png" alt="" loading="lazy" width="1526" height="1214" srcset="https://www.timescale.com/blog/content/images/size/w600/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_3.png 600w, https://www.timescale.com/blog/content/images/size/w1000/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_3.png 1000w, https://www.timescale.com/blog/content/images/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_3.png 1526w" sizes="(min-width: 720px) 720px"/></figure><p>The thing is, <code>REFRESH</code>ing a view can be expensive, and to understand why we should understand a bit more about how they work and why they get out of date. And that can be expensive.</p><h2 id="how-materialized-views-work-and-why-they-get-out-of-date">How Materialized Views Work (and Why They Get Out of Date)</h2><p>To understand how materialized views get out of date and what refresh is doing, it helps to understand a little of how they work under the hood. Essentially, when you create a materialized view, you are creating a table and populating it with the data from the query. For the <code>ohlc_mat</code> view we’ve been working with, it’s equivalent to:</p><!--kg-card-begin: markdown--><pre><code>CREATE TABLE ohlc_tab AS 
SELECT time_bucket(&#39;15 min&#39;, time) bucket, symbol, first(time, price), max(price), min(price), last(time, price) 
FROM stocks_real_time 
GROUP BY time_bucket(&#39;15 min&#39;, time), symbol;

Now, what happens when I insert data into the underlying table?  

INSERT INTO stocks_real_time VALUES (now(), &#39;AAPL&#39;, 170.91, NULL);
</code></pre>
<!--kg-card-end: markdown--><p>So, our materialized view <code>ohlc_mat</code> is storing the results of the query run when we created it.</p><figure><img src="https://www.timescale.com/blog/content/images/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_4.png" alt="" loading="lazy" width="1526" height="1214" srcset="https://www.timescale.com/blog/content/images/size/w600/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_4.png 600w, https://www.timescale.com/blog/content/images/size/w1000/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_4.png 1000w, https://www.timescale.com/blog/content/images/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_4.png 1526w" sizes="(min-width: 720px) 720px"/></figure><p>The regular view (<code>ohlc_view</code>) will stay up to date because it’s just running the queries directly on the raw data in <code>stocks_real_time</code>. And if we’re only inserting data close to <code>now()</code>, and only querying much older data, then the materialized view will seem like it’s okay. We’ll see no change for our query from a month or two ago, but if we try to query a more recent time, we won’t have any data. If we want it up to date with more recent data, we’ll need to run:</p><!--kg-card-begin: markdown--><pre><code>REFRESH MATERIALIZED VIEW ohlc_mat;
</code></pre>
<!--kg-card-end: markdown--><p>When we do this, what is actually happening under the hood is that we truncate (remove all the data) from the table, and then run the query again and insert it into the table.</p><figure><img src="https://www.timescale.com/blog/content/images/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_5.png" alt="" loading="lazy" width="1526" height="1214" srcset="https://www.timescale.com/blog/content/images/size/w600/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_5.png 600w, https://www.timescale.com/blog/content/images/size/w1000/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_5.png 1000w, https://www.timescale.com/blog/content/images/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_5.png 1526w" sizes="(min-width: 720px) 720px"/></figure><figure><img src="https://www.timescale.com/blog/content/images/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_6.png" alt="" loading="lazy" width="1526" height="1214" srcset="https://www.timescale.com/blog/content/images/size/w600/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_6.png 600w, https://www.timescale.com/blog/content/images/size/w1000/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_6.png 1000w, https://www.timescale.com/blog/content/images/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_6.png 1526w" sizes="(min-width: 720px) 720px"/></figure><p>If we were using the <code>ohlc_tab</code> table from above, the equivalent operations would be something like:</p><!--kg-card-begin: markdown--><pre><code>TRUNCATE TABLE ohlc_tab;

INSERT INTO ohlc_tab 
SELECT time_bucket(&#39;15 min&#39;, time) bucket, symbol, first(time, price), max(price), min(price), last(time, price) 
FROM stocks_real_time 
GROUP BY time_bucket(&#39;15 min&#39;, time), symbol;
</code></pre>
<!--kg-card-end: markdown--><p>(This works slightly differently when you run <code>REFRESH MATERIALIZED VIEW</code> with the <code>CONCURRENTLY</code> option, but fundamentally, it always runs the query over the entire data set, and getting into the details is beyond the scope of this post.)</p><p>The database, much like with a view, stores the query we ran so that when we run our <code>REFRESH</code> it just knows what to do, which is great, but it’s not the most efficient. Even though most of the data didn’t change, we still threw out the whole data set, and re-run the whole query. </p><p>While that might be okay when you’re working with, say OLTP data that PostgreSQL works with, and your updates/deletes are randomly spread around your data set, it starts to seem pretty inefficient when you’re working with time-series data, where the writes are mostly in the most recent period. </p><p>So to sum up, we found a case where the materialized view really helps us because the output from the query is so much smaller than the number of rows we have to scan to calculate it. In our case, it was an aggregate. But we also noticed that, when we used a materialized view, the data gets out of date because we’re storing the output of the query, rather than rerunning it at query time as you do with a view.</p><p>In order to get the materialized view to be up to date, we learned that we need to <code>REFRESH</code> it, but for time-series use cases, a) you have to refresh it frequently (in our case, approximately every 15 minutes or so at least) for it to be up to date, and b) the refresh is inefficient because we have to delete and re-materialize all the data, maybe going back months, to get the new information from just the previous 15 minutes. <strong>And that’s one of the main reasons we developed continuous aggregates at Timescale.</strong></p><h2 id="how-continuous-aggregates-work-and-how-they-were-inspired-by-the-best-of-views-and-materialized-views">How Continuous Aggregates Work and How They Were Inspired by the Best of Views and Materialized Views</h2><p>We saw these problems with both views and materialized views for these types of aggregates, and wanted to develop something that worked much better for the needs of people with time-series data because we knew that time-bucketed aggregation was an extremely common use case. We tried to learn from both views and materialized views as we developed them. We’ll build up to how exactly continuous aggregates work in this section, piece by piece. <br/></p><!--kg-card-begin: markdown--><pre><code>CREATE MATERIALIZED VIEW ohlc_cont 
WITH (timescaledb.continuous) AS 
SELECT time_bucket(&#39;15 min&#39;, time) bucket, symbol, first(time, price), max(price), min(price), last(time, price) 
FROM stocks_real_time 
GROUP BY time_bucket(&#39;15 min&#39;, time), symbol;
</code></pre>
<!--kg-card-end: markdown--><p>Once we’ve done that, we end up in a very similar situation to what we have with a materialized view. We have the data that was around when created the view, but as new data gets inserted, the view will get out of date.<strong> </strong><br/></p><figure><img src="https://www.timescale.com/blog/content/images/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_6_5-1.png" alt="" loading="lazy" width="1526" height="1214" srcset="https://www.timescale.com/blog/content/images/size/w600/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_6_5-1.png 600w, https://www.timescale.com/blog/content/images/size/w1000/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_6_5-1.png 1000w, https://www.timescale.com/blog/content/images/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_6_5-1.png 1526w" sizes="(min-width: 720px) 720px"/></figure><p>In order to keep a continuous aggregate up to date, we need a scheduled aggregation.</p><h3 id="scheduled-aggregation-of-new-data">Scheduled aggregation of new data</h3><p>We saw two main problems with materialized views that we wanted to address with scheduled aggregations:</p><ol><li>We have to manually refresh a materialized view when we want it to remain up to date.</li><li>We don’t want to re-run the query on all the old data unnecessarily; we should only run it on the new data. </li></ol><p>To schedule aggregations, we need to create a continuous aggregate policy:</p><!--kg-card-begin: markdown--><pre><code>SELECT add_continuous_aggregate_policy(&#39;ohlc_cont&#39;::regclass, start_offset=&gt;NULL, end_offset=&gt;&#39;15 mins&#39;::interval,  schedule_interval=&gt;&#39;5 mins&#39;::interval);
</code></pre>
<!--kg-card-end: markdown--><p>Once we’ve scheduled a continuous aggregate policy, it will run automatically according to the <code>schedule_interval</code> we’ve specified. In our case, it runs every five minutes. When it runs, it looks at the data we’ve already materialized and the new inserts and looks to see if we’ve finished at least one 15-minute bucket. If we have, it will run the query on just that next 15-minute portion and materialize the results in our continuous aggregate.</p><figure><img src="https://www.timescale.com/blog/content/images/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_7.png" alt="" loading="lazy" width="1526" height="1214" srcset="https://www.timescale.com/blog/content/images/size/w600/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_7.png 600w, https://www.timescale.com/blog/content/images/size/w1000/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_7.png 1000w, https://www.timescale.com/blog/content/images/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_7.png 1526w" sizes="(min-width: 720px) 720px"/></figure><p>This means that the continuous aggregate now automatically has data from the next 15-minute period without user intervention. </p><p>And it was much more efficient. Unlike running <code>REFRESH MATERIALIZED VIEW</code>, we didn’t drop all the old data and recompute the aggregate against it, we just ran the aggregate query against the next 15-minute period and added that to our materialization. And as we move forward in time, this can keep occurring as each successive 15-minute period (or whatever period we chose for the <code>time_bucket</code> in the continuous aggregate definition) gets filled in with new data and then materialized. </p><p>One thing to note about this is that we keep track of where we’ve materialized up to by storing what we call a watermark, represented here by the dotted line. (<strong>NB</strong>: It’s named after the high watermark caused by a flood, not the watermark on a bank check.) So before the scheduled aggregation runs, the watermark is right after all the data we’ve materialized:</p><figure><img src="https://www.timescale.com/blog/content/images/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_8.png" alt="" loading="lazy" width="1526" height="1246" srcset="https://www.timescale.com/blog/content/images/size/w600/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_8.png 600w, https://www.timescale.com/blog/content/images/size/w1000/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_8.png 1000w, https://www.timescale.com/blog/content/images/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_8.png 1526w" sizes="(min-width: 720px) 720px"/></figure><p>That helps us locate our next bucket and ensure it’s all there before we run the aggregation. Once we have, we move the watermark:</p><figure><img src="https://www.timescale.com/blog/content/images/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_9-1.png" alt="" loading="lazy" width="1526" height="1312" srcset="https://www.timescale.com/blog/content/images/size/w600/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_9-1.png 600w, https://www.timescale.com/blog/content/images/size/w1000/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_9-1.png 1000w, https://www.timescale.com/blog/content/images/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_9-1.png 1526w" sizes="(min-width: 720px) 720px"/></figure><p>So our watermark represents the furthest point we’ve materialized up until now.</p><p>But, you might notice that our continuous aggregates still aren’t fully up to date and wouldn’t give us the same results as a view that ran the same query. Why?</p><ol><li>Scheduled aggregates will have some gap between when the next bucket has all of its data and when the job runs to materialize it.</li><li>We only materialize data once the next bucket is full by default, so we’re missing the partial bucket where inserts are happening right now. We might want to get partial results for that bucket (this is especially true when we’re using larger buckets).</li></ol><p>To address this, we made real-time views.</p><h3 id="real-time-views">Real-time views</h3><p>Real-time views combine the best of materialized views and normal views to give us a more up-to-date view of our data. They’re the default for continuous aggregates, so I don’t need to change how I made my continuous aggregate at all. However, I will admit that I elided a few things in the previous picture about how continuous aggregates work under the hood.</p><p>Real-time continuous aggregates have two parts:</p><ol><li>A <em>materialized hypertable</em>, where our already computed aggregates are stored.</li><li>And a <em>real-time view, </em>which queries both the materialized hypertable and the raw hypertable (in the not-yet-aggregated region) and combines the results together.</li></ol><figure><img src="https://www.timescale.com/blog/content/images/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_10.png" alt="" loading="lazy" width="1526" height="1892" srcset="https://www.timescale.com/blog/content/images/size/w600/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_10.png 600w, https://www.timescale.com/blog/content/images/size/w1000/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_10.png 1000w, https://www.timescale.com/blog/content/images/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_10.png 1526w" sizes="(min-width: 720px) 720px"/></figure><p>So, if you look at the view definition of the continuous aggregate, it looks like this:</p><!--kg-card-begin: markdown--><pre><code>CREATE VIEW ohlc_cont AS  SELECT _materialized_hypertable_15.bucket,
    _materialized_hypertable_15.symbol,
    _materialized_hypertable_15.first,
    _materialized_hypertable_15.max,
    _materialized_hypertable_15.min,
    _materialized_hypertable_15.last
   FROM _timescaledb_internal._materialized_hypertable_15
  WHERE _materialized_hypertable_15.bucket &lt; COALESCE(_timescaledb_internal.to_timestamp(_timescaledb_internal.cagg_watermark(15)), &#39;-infinity&#39;::timestamp with time zone)
UNION ALL
 SELECT time_bucket(&#39;00:15:00&#39;::interval, stocks_real_time.&#34;time&#34;) AS bucket,
    stocks_real_time.symbol,
    first(stocks_real_time.&#34;time&#34;, stocks_real_time.price) AS first,
    max(stocks_real_time.price) AS max,
    min(stocks_real_time.price) AS min,
    last(stocks_real_time.&#34;time&#34;, stocks_real_time.price) AS last
   FROM stocks_real_time
  WHERE stocks_real_time.&#34;time&#34; &gt;= COALESCE(_timescaledb_internal.to_timestamp(_timescaledb_internal.cagg_watermark(15)), &#39;-infinity&#39;::timestamp with time zone)
  GROUP BY (time_bucket(&#39;00:15:00&#39;::interval, stocks_real_time.&#34;time&#34;)), stocks_real_time.symbol;
 
</code></pre>
<!--kg-card-end: markdown--><p>It’s two queries put together with a <code><a href="https://www.postgresql.org/docs/current/queries-union.html">UNION ALL</a></code>, the first just selecting the data straight out of the materialized hypertable where our bucket is below the watermark, the second running the aggregation query where our time column is above the watermark. </p><p>So you can see how this takes advantage of the best of both materialized views and normal views to create something that is much faster than a normal view but still up to date! </p><p>It’s not going to be as performant as just querying the already materialized data (though we do have an <a href="https://docs.timescale.com/getting-started/latest/create-cagg/create-cagg-policy/">option to allow you to do that if you want to</a>), but for most users, the last few months or even years of data is already materialized whereas only the last few minutes or days of raw data needs to be queried, so that still creates a huge speedup!</p><h3 id="invalidation-of-out-of-order-data">Invalidation of out-of-order data</h3><p>You may have noticed that I was making a big assumption in all of my diagrams. I was assuming that <em>all</em> of our inserts happen in the most recent time period. For time-series workloads, this is <em>mostly</em> true. <em>Most</em> data comes in time order. But, most and all are <em>very</em> different things. Especially with time-series workloads, where we have so much data coming in, that even if 99 percent of the data is in time order, 1 percent of the data is still a lot!</p><figure><img src="https://www.timescale.com/blog/content/images/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_11-1.png" alt="" loading="lazy" width="1526" height="1210" srcset="https://www.timescale.com/blog/content/images/size/w600/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_11-1.png 600w, https://www.timescale.com/blog/content/images/size/w1000/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_11-1.png 1000w, https://www.timescale.com/blog/content/images/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_11-1.png 1526w" sizes="(min-width: 720px) 720px"/></figure><p>And the results of the aggregate would be wrong by a meaningful amount if we simply let the inserts (or updates or deletes) build up over time. This cache invalidation problem is a very common problem in computing and a very hard one! PostgreSQL materialized views solve this problem by dropping all the old data and re-materializing it every time, but we already said how inefficient that was. </p><p>The other way that many folks try to solve this sort of problem in a database like PostgreSQL is a trigger. A standard trigger would run for every row and update the aggregates for every row.</p><p>But in practice, it’s hard to get a per-row trigger to work very well, and it still would cause significant <em>write amplification</em>, meaning, we’d have to write multiple times for every row we insert. </p><p>In fact, we’d need to write at least once for each row for each continuous aggregate we had on the raw hypertable. It would also limit the aggregates we can use to those that can be modified by a trigger, which are fewer than we might like. </p><figure><img src="https://www.timescale.com/blog/content/images/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_12.png" alt="" loading="lazy" width="1526" height="1258" srcset="https://www.timescale.com/blog/content/images/size/w600/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_12.png 600w, https://www.timescale.com/blog/content/images/size/w1000/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_12.png 1000w, https://www.timescale.com/blog/content/images/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_12.png 1526w" sizes="(min-width: 720px) 720px"/></figure><p>The next time the continuous aggregate job runs, it has to do two things: it runs the normal aggregation of the next 15 minutes of data, and it runs an aggregation over each of the invalidated regions to recalculate the proper value over that period.</p><figure><img src="https://www.timescale.com/blog/content/images/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_13.png" alt="" loading="lazy" width="1526" height="1312" srcset="https://www.timescale.com/blog/content/images/size/w600/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_13.png 600w, https://www.timescale.com/blog/content/images/size/w1000/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_13.png 1000w, https://www.timescale.com/blog/content/images/2022/07/20220711_Materialized-views-and-CAGGS_Diagram_13.png 1526w" sizes="(min-width: 720px) 720px"/></figure><p>Note that this makes our continuous aggregates <a href="https://en.wikipedia.org/wiki/Eventual_consistency">eventually consistent</a> for out-of-order modifications. However, real-time views make continuous aggregates more strongly consistent for recent data (because they use a view under the hood). </p><h3 id="data-retention">Data retention</h3><p>The final thing we wanted to accomplish with our continuous aggregates was a way to <em>keep</em> aggregated data around after dropping the raw data. This is impossible with both PostgreSQL views and materialized views because, for views, they work directly on the raw data—if you drop it, they can’t aggregate it. </p><p>With materialized views it’s a bit more complicated: until you run a refresh, they can have the old data around, but, once you run a refresh,  to get the new data that you’ve added in more recent time periods, then the old data is dropped. </p><p>With continuous aggregates, the implementation is much simpler. We mentioned the invalidation trigger that fires when we modify data that we’ve already materialized. We simply ignore any events older than a certain time horizon, including the drop event. </p><p>We also can process any invalidations before dropping data so that you can have the correct data materialized from right before you dropped the oldest stuff. You can configure data retention <a href="https://docs.timescale.com/timescaledb/latest/how-to-guides/data-retention/data-retention-with-continuous-aggregates/">by setting up your continuous aggregate policy correctly</a>.</p><h2 id="does-it-work">Does It Work?</h2><p>So we’ve got this whole mashup of views and materialized views and triggers in order to try to make a good set of trade-offs that works well for time-series data. So the question is: does it work? </p><p>If you are new to TimescaleDB and would like to try this out, I invite you to <a href="https://www.timescale.com/timescale-signup">sign up for Timescale Cloud</a>. It&#39;s the easiest way to get started with Timescale. It’s 100 percent free for 30 days, no credit card required, and you’ll be able to spin up a database with demo data in seconds (run the Almond Milk demo). You can easily host PostgreSQL tables and TimescaleDB hypertables in your Timescale Cloud demo database, create views, materialized views, and continuous aggregates, and explore the differences in performance and developer experience between them.</p>
        <div>
          <p>The open-source relational database for time-series and analytics.</p>
          <p><a href="https://www.timescale.com/timescale-signup">
            Try Timescale for free
          </a>

        </p></div>
      </div></div>
  </body>
</html>
