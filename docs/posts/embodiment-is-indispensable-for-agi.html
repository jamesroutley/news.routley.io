<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://keerthanapg.com/tech/embodiment-agi/">Original</a>
    <h1>Embodiment is indispensable for AGI</h1>
    
    <div id="readability-page-1" class="page"><div>
        
  <section class="page">
  <article>
    <header>
      
    </header>

    <p>There are many paths on the road to AGI. Nando de Freitas recently wrote that “Scale is all you need” following the release of Deepmind’s Gato paper. Larger and larger transformers, with language interfaces doing supervised learning on large datasets is one such touted path. While Gato trains and evaluates on data from physical robots, there is a larger paradigm on getting to AGI that fully bypasses embodiment or robotics. This is the path pursued by OpenAI/Anthropic, who once famously <a href="https://www.therobotreport.com/openai-abandons-robotics-research/">disbanded their robotics team</a>. I recently found myself in a car ride with a friend who was a “member of technical staff” at OpenAI and he asked “Do you think solving embodied AI is required for AGI or is it enough to be digital?” I have thought a lot about that question since.</p>
<p><strong>Language as the end-all of intelligence</strong></p>
<p><strong>What is AGI?</strong></p>
<p>Ultimately, answering the question of whether embodiment is required for AGI depends on what definition of AGI you adopt. For this essay, I’ll pick <em>that which is as good or better than a human in every aspect</em> as a baseline. There are several useful things to do in the physical world and transforming those would require embodied AI.</p>
<p><img src="https://keerthanapg.com/tech/embodiment-agi/bot_reading.jpeg" alt="alt_text" title="image_tooltip"/>
“Vintage robot gives book reading in 1950s beat cafe.”
Generated by DALLE and prompted by <a href="https://twitter.com/Merzmensch">@Merzmensch</a></p>
<p>In relation to embodiment, there are broadly three paradigms to get to AGI:</p>
<ol>
<li>Have an AI trained on vision and language and that which exists only on the internet.</li>
<li>An AI trained on vision and language tasks but can do embodied tasks</li>
<li>An AI trained on vision, language and control, is embodied and is quite intelligent and physically capable as a human.</li>
</ol>
<p><strong>Visual language AI that is completely digital is not AGI</strong></p>
<p>Similarly, going by the definition I adopted, 3 unambigiously is AGI. Let’s talk about 2.</p>
<p><strong>What is the strongman version of an AGI paradigm that removes embodiment?</strong></p>
<p><strong>If an AI can manage chefs, but a human chef does the physical act of cooking, is that AGI?</strong></p>
<p>For this proposition to even work, that is for a non-embodied AGI to guide a robot, there are a few caveats:</p>
<ol>
<li><strong>Data from embodied agents:</strong> It needs to be trained on data from embodied agents, their sensors as input and their actuators as outputs. This is a little like offline learning where you expose a network to tons of Youtube videos which have humans or other agents demonstrating how to do tasks, that the model then maps to a morphologically similar sensor/actuator configuration. If an AGI is predisposed to depend on data collected by embodied agents, would that make it an embodied AI? In my opinion, I’d say if the agent is human, no. But if it needs data from learned or teleoperated robots, then yes. This is a purely subjective line that I’m drawing. <a href="https://arxiv.org/pdf/2205.06175.pdf">Deepmind’s Gato</a> by that subjective definition is embodied because it attempts to do robotics using supervised learning demos from real robots and simulated agents, and evaluates on real robots.</li>
<li><strong>Mapping morphology:</strong> A second consideration is the effectiveness of an AI that learns from human demonstrations but executes on a robot and how good it can get at generalizing for morphology from a cross-embodied agent demonstration. <a href="https://arxiv.org/pdf/2106.03911.pdf">This paper</a> gives some baselines on where we are at now, formulated in an RL, rather than supervised learning setting. Another close example is <a href="https://arxiv.org/pdf/2004.00784.pdf">quadruped robots learning</a> to walk from dogs, who have very similar morphology.</li>
<li><strong>Offline learning:</strong> A third aspect is the effectiveness of AI that only learns from policies executed by other agents. Such as AI would still be unable to model counterfactuals and learn self correcting behavior. For example, when you learn to surf, your awareness of your own agility and inabilities factor into your decision making, in addition to your learning experiences conditioned on your physical parameters. While <a href="https://www.deepmind.com/blog/tackling-multiple-tasks-with-a-single-visual-language-model">flamingo</a> attempts to few-shot a few visual learning tasks, this is not done for control yet.</li>
<li><strong>Sim2Real:</strong> Domain adaptation using simulated agents is one way to add embodiment without adding the physical aspect of it. However, sim2real is still an an active area of robotics research because agents exposed to only simulations cannot, yet, <a href="https://arxiv.org/pdf/2006.09001.pdf">transfer very well</a> to the real world.</li>
</ol>
<p><strong>Robotics is an AGI problem, but more importantly, AGI is a robotics problem</strong></p>
<p>Even after you add vision to language, there are still aspects of precise control and how it relates to intrinsic variables of embodiment that remain left-out. <em>Solving robotics requires solving vision ( sensory perception, 3d reasoning), speech ( instruction and contextual reasoning) and control ( manipulation and navigation).</em></p>
<p><strong>Agent/Environment cannot be abstracted away from Intelligence</strong></p>
<p>The last decade of AI research has led to the rise of large transformers that are very good at multi-task speech and vision benchmarks. A language first AI would be susceptible to the <a href="https://arxiv.org/pdf/2109.05014.pdf">failure modes</a> of a blind agent, beyond the visual context it receives from a training corpus gathered from humans who can see. It logically extends that a visual language model would suffer from an inability to approximate actuator params inherent to performing precise control of an embodied agent. Reasoning about the real world require not just thinking about methodological spaces and language, but to be <a href="https://arxiv.org/pdf/2204.01691.pdf">grounded in real world context</a>.</p>
<p>In a world built by and designed for humans, an intelligence that is agnostic to sensory-motor dynamics is going to be suboptimal, and superhuman skills beckon physical agency and universal control. Embodiment is absolutely indispensable for AGI.</p>


  </article>
</section>

  

      </div></div>
  </body>
</html>
