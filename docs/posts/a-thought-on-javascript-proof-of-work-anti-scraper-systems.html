<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://utcc.utoronto.ca/~cks/space/blog/web/JavaScriptScraperObstacles">Original</a>
    <h1>A thought on JavaScript &#34;proof of work&#34; anti-scraper systems</h1>
    
    <div id="readability-page-1" class="page"><div><h2>A thought on JavaScript &#34;proof of work&#34; anti-scraper systems</h2>

	<p><small>May 25, 2025</small></p>
</div><div><p>One of the things that people are increasingly using these days to
deal with the issue of aggressive LLM and other web scrapers is
JavaScript based &#34;proof of work&#34; systems, where your web server
requires visiting clients to run some JavaScript to solve a challenge;
one such system (increasingly widely used) is <a href="https://xeiaso.net/">Xe Iaso</a>&#39;s <a href="https://github.com/TecharoHQ/anubis">Anubis</a>.
One of the things that people say about these systems is that LLM
scrapers will just start spending the CPU time to run this challenge
JavaScript, and LLM scrapers may well have lots of CPU time available
through means such as compromised machines. One of my thoughts is
that things are not quite as simple for the LLM scrapers as they
look.</p>

<p>An LLM scraper is operating in a hostile environment (although its
operator may not realize this). In a hostile environment, dealing
with JavaScript proof of work systems is not as simple as simply
running it, because you can&#39;t particularly tell a JavaScript proof
of work system from JavaScript that does other things. Letting your
scraper run JavaScript means that it can also run JavaScript for
other purposes, for example for people who would like to exploit
your scraper&#39;s CPU to do some cryptocurrency mining, or simply have
you run JavaScript for as long as you&#39;ll let it keep going (perhaps
because they&#39;ve recognized you as a LLM scraper and want to waste
as much of your CPU as possible).</p>

<p>An LLM scraper can try to recognize a JavaScript proof of work
system but this is a losing game. The other parties have every
reason to make themselves look like a proof of work system, and the
proof of work systems don&#39;t necessarily have an interest in being
recognized (partly because this might allow LLM scrapers to short-cut
their JavaScript with optimized host implementations of the
challenges). And as both spammers and cryptocurrency miners have
demonstrated, there is no honor among thieves. If LLM scrapers
dangle free computation in front of people, someone will spring up
to take advantage of it. This leaves LLM scrapers trying to pick a
JavaScript runtime limit that doesn&#39;t cut them off from too many
sites, while sites can try to recognize LLM scrapers and increase
their proof of work difficulty if they see a suspect.</p>

<p>(This is probably not an original thought, but it&#39;s been floating
around my head for a while.)</p>

<p>PS: <a href="https://mastodon.social/@cks/114571090294492114">JavaScript proof of work systems aren&#39;t the greatest thing,
but they&#39;re going to happen unless someone convincingly demonstrates
a better alternative</a>.</p>
</div></div>
  </body>
</html>
