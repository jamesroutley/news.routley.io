<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://thewhodidthis.com/more-than-idle-radio-chatter/">Original</a>
    <h1>More than idle radio chatter</h1>
    
    <div id="readability-page-1" class="page"><article>
    <header>
      <time datetime="2023-09-02">Sep 02. 2023</time>
    </header>
    <figure>
      <figure>
        <picture><source srcset="nelson.webp" type="image/webp"/> <source srcset="nelson.jp2" type="image/jp2"/> <source srcset="nelson.jpx" type="image/jpx"/> <img src="https://thewhodidthis.com/more-than-idle-radio-chatter/nelson.jpg" srcset="nelson@2x.jpg 2x" height="720" width="720" alt="One hundred and eleven numbered Prom ticket evidence"/></picture> <picture><source srcset="antelope.webp" type="image/webp"/> <source srcset="antelope.jp2" type="image/jp2"/> <source srcset="antelope.jpx" type="image/jpx"/> <img src="https://thewhodidthis.com/more-than-idle-radio-chatter/antelope.jpg" srcset="antelope@2x.jpg 2x" height="720" width="720" alt="Samson Kambalu&#39;s Chilembwe / Chorley Antelope &#39;22 Fourth Plinth roughly equal height with Nelson&#39;s column in the short distance"/></picture>
      </figure>
      <figcaption>
        <p><strong>Ominous</strong> What are the odds? Drew a <em>nelson</em> queuing at the Proms for <a href="https://www.cambridge.org/core/journals/tempo/article/profile-catherine-lamb/279B5C010027AC542FA56182DE547B96">Catherine Lamb&#39;s</a> the other week.</p>
      </figcaption>
    </figure>
    <p>Sync with a pot of coffee, I put the radio on most days to help stay positive while working. Working from home, it makes me feel connected to the rest of the world. I love classical and Radio 3 is one of my favorite stations. So the moment came July that <a href="https://www.bbc.co.uk/sounds/help/questions/recent-changes-to-bbc-sounds/radio-changes/">the BBC permanently switched to supporting HLS / DASH only</a>. Shoutcast endpoints are gone save for World Service. No surprise really, there had been occasional on-air warnings about it.</p>
    <p>Alright, let me take a second to update my Mac&#39;s Music.app playlist I thought. Except no, pasting in the new <code>.m3u8</code> address over <code>File &gt; Open Stream URL</code> like normal kept error-ing, which gave me a slight scare because I value my early evening Sean Rafferty fix and was I then to start using their Sounds branded app or <code>ffplay(1)</code> or what else for it? <span>🫤</span></p>
    <figure>
      <picture><source srcset="endpoint.webp" type="image/webp"/> <source srcset="endpoint.jp2" type="image/jp2"/> <source srcset="endpoint.jpx" type="image/jpx"/> <img src="https://thewhodidthis.com/more-than-idle-radio-chatter/endpoint.png" height="650" width="1000" alt="My iPad&#39;s Safari network tab filtering for .m3u8 assets"/></picture>
      <figcaption>
        <p>Fishing out Radio 3&#39;s new macOS compatible stream URL on mobile Safari. It&#39;s <a href="https://github.com/Dash-Industry-Forum/dash.js">dash.js</a> based playback otherwise.</p>
      </figcaption>
    </figure>
    <p>Who would have guessed, simply <a href="https://en.wikipedia.org/wiki/HTTP_Live_Streaming#cite_ref-37">replacing <code>https:</code> with <code>itals:</code> for a protocol</a> does the trick as it happens. Given HLS is one of Apple&#39;s essentially, it might have been nice if that were better documented somehow, but okay writing a dedicated Swift Playgrounds mini app is just as easy in any case:</p>
    <pre><strong>// HLS ready sample radio app.</strong>
import SwiftUI
import AVKit

@main
<strong>// NOTE: Make sure the stream is TLS served</strong>
<strong>// and the app network connection capable.</strong>
struct Radio: App {
    var body: some Scene {
        WindowGroup {
            ContentView()
        }
    }
}

struct ContentView: View {
    var player = AVPlayer(url: URL(string: &#34;norewind.m3u8&#34;)!)

    var body: some View {
        VideoPlayer(player: player)
    }
}
</pre>
    <figure>
      <picture><source srcset="pidge.webp" type="image/webp"/> <source srcset="pidge.jp2" type="image/jp2"/> <source srcset="pidge.jpx" type="image/jpx"/> <img src="https://thewhodidthis.com/more-than-idle-radio-chatter/pidge.jpg" srcset="pidge@2x.jpg 2x" height="540" width="720" alt="Man sitting edge on a St James&#39;s Park bench looking at the lake next to a pigeon"/></picture>
    </figure>
    <p>Mornings however, until recently anyway, WFMU&#39;s <a href="https://wfmu.org/playlists/WA">Wake &#39;n Bake with Clay Pigeon</a> has been top banana for the understated professionalism, the wacky odd segments, fine melodies, and emphatic humanity. His old <a href="https://www.wfmu.org/playlists/CP">The Dusty Show</a> first won me over with <a href="https://wfmu.org/archiveplayer/?show=66821&amp;archive=140954&amp;starttime=00:00:30">the vox pops</a>. I had also never heard City Slang (1978) full-length bang boom blast through the airwaves before.</p>
    <p>Purely my imagination, but listening to The Pidge I could almost trace distant links to back when I joined Dave from <a href="https://en.wikipedia.org/wiki/Negative_FX">Negative FX</a> on the record collector&#39;s trail in one of his London trips years ago. We were both drummers and that was a true gift of an experience for my music upbringing.</p>
    <p>And with WFMU in general next to the massive legacy and singular freeform culture status, the archives are cosmic heritage grade treasure. It bothered my focus being unable to tune in regular hours half the summer, but at least I had the option of catching replays at night. Which is probably how, having since been forced to grow out of it, I wound up trying to say thanks and to account for things often lost in translation with a Paul Lansky&#39;s <a href="https://bridgerecords.bandcamp.com/track/idle-chatter">Idle Chatter</a> (1985) inspired here mix.</p>
    <p>Could I get enough of that track as student! The sound is crisp and tingly? It was <a href="https://paul.mycpanel.princeton.edu/liner_notes/morethanidlechatter.html">written in Cmix for the IBM 3081</a> using <a href="https://en.wikipedia.org/wiki/Linear_predictive_coding">Linear Predictive Coding</a> (LPC), <a href="https://musicandcomputersbook.com/chapter4/04_08.php">granular synthesis</a>, and samples of his wife&#39;s Hannah MacKay&#39;s voice. Playing by ear, I may be missing certain angles, but am adding visual and time dynamic elements in return.</p>
    <figure>
      <picture><img src="https://thewhodidthis.com/more-than-idle-radio-chatter/klaxon.jpg" srcset="klaxon@2x.jpg 2x" height="480" width="360" alt="St Stephen&#39;s Row back of Mansion House get out when klaxon heard wall sign warning"/></picture>
    </figure>
    <h2>Back end</h2>
    <p>First up, sourcing the material. I can query the show&#39;s <a href="https://www.wfmu.org/podcast/WP.xml">podcast feed</a> for the latest weekly digest and XML parsing is straightforward to achieve client-side using <a href="https://developer.mozilla.org/en-US/docs/Web/API/DOMParser/parseFromString"><code>DOMParser.parseFromString()</code></a>, but there are CORS restrictions to consider. And even if I were to proxy bypass those, which would be awfully bad form, episodes are too big, close to an hour long. Which means I need somewhere to: (a) edit the audio down, (b) serve it up for non opaque response fetching.</p>
    <p>Let <a href="https://archive.org">Internet Archive</a> handle the last part. It was created for hosting media after all. Reason to donate. But where to have the files prepared and posted from? The OpenBSD my personal server runs on offers <a href="https://man.openbsd.org/xml">no XML utilities</a> by default and I follow unapologetically aesthete strictly stick to base install sanctity rules there.</p>
    <figure>
      <picture><source srcset="sdf.webp" type="image/webp"/> <source srcset="sdf.jp2" type="image/jp2"/> <source srcset="sdf.jpx" type="image/jpx"/> <img src="https://thewhodidthis.com/more-than-idle-radio-chatter/sdf.png" height="444" width="660" alt="SDF welcome screen showing uptime and oneliner sample output"/></picture>
      <figcaption>
        <p><strong>What cloud hosted VPS?</strong> The SDF Public Access UNIX System Est. 1987 is a wonder for running casual programs on a $36 minimum one-time lifetime membership plan.</p>
      </figcaption>
    </figure>
    <p>The irony is whether I called e.g., <code>grep &#34;mp3&#34; feed.xml | head -1 | cut -d \&#34; -f4</code> to pick out the asset URL, when an <code>xmllint(1)</code> would perfectly fit the job, <a href="https://archive.org/developers/internetarchive/cli.html"><code>ia</code> uploader</a> binaries are the <a href="https://github.com/pantsbuild/pex">pex</a> kind and still <a href="https://archive.org/developers/internetarchive/installation.html#binaries">require Python 3</a> installed alongside. And properly substituting for a purpose-built tool as such without reinventing the wheel is more involved in practice than making <code>ftp(1)</code> authenticated API requests. And what about hacking the <code>MP3</code>?</p>
    <p>No problem, fortunately the good people of the 1980s and &#39;90s set up the NetBSD <a href="https://sdf.org">Super Dimension Fortress</a> (SDF) that provides shell accounts pre-packed with the necessary UNIX goodies. SDF also seems uniquely appropriately epic a resource to match FMU&#39;s historic magnitude. I sent them a small present to qualify for <a href="http://sdf.org/?join#arpa"><code>arpa</code></a> group permissions and was ready to go in a day, lovely. <span>🥰</span></p>
    <pre><strong># Get iTunes feed, follow redirects, no progress / yes error logging.</strong>
curl -LSs &#34;https://www.wfmu.org/podcast/WP.xml&#34; |
  <strong># Drill down for the most recent episode&#39;s .mp3 URL.</strong>
  xmllint --xpath &#34;string(/rss/channel/item[1]/enclosure/@url)&#34; - |
  <strong># Download latest chatter, same settings.</strong>
  xargs curl -LSs &gt; episode.mp3
</pre>
    <p>I knew it as a lightweight MPlayer alternative, but <code>mpg123(1)</code> will decode and portion audio files as well:</p>
    <pre><strong># Take 1200 frames past the first 2400, roughly half a minute.</strong>
mpg123 -s -q -k 2400 -n 1200 -w sample.wav episode.mp3
</pre>
    <p>Convert back to <code>.mp3</code> for the browser:</p>
    <pre><strong># Not overly worried about quality.</strong>
lame -b 128 sample.wav sample.mp3
</pre>
    <p>Install and configure the <code>ia</code> Python library:</p>
    <pre><strong># Double-check `~/.local/bin` is in `$PATH` to avoid warnings.</strong>
python -m pip install internetarchive

<strong># Interactively commit <a href="https://archive.org/developers/tutorial-get-ia-credentials.html">API credentials</a> into</strong>
<strong># `~/.config/internetarchive/ia.ini`.</strong>
ia configure
</pre>
    <p>Set metadata and upload:</p>
    <pre>ia upload justmoreidlechatternot sample.mp3 -q -r sample.mp3 \
     <strong># A test collection is also available. Items in it are</strong>
     <strong># automatically removed after approximately 30 days.</strong>
     -m &#34;collection:opensource_audio&#34; \
     <strong># Give it a timestamp for a title.</strong>
     -m &#34;title:$(date +%Y%m%d%s)&#34; \
     -m &#34;mediatype:audio&#34; \
     -m &#34;year:$(date +%Y)&#34; \
     <strong># Add a custom flag for search filtering.</strong>
     -m &#34;chatter:NOT&#34;
</pre>
    <p>That takes care of producing my sample. I keep the above commands in a <a href="https://gist.github.com/thewhodidthis/1c2665a75d6d9d4be47e39b1ba149eb2"><code>Makefile</code></a>, which I find more accessible than shell scripts. Wrapping up server-side, I want the ability to resupply from time to time. Conveniently, SDF reserve <code>cron(8)</code> for members higher up the subscription ladder. How do I repeat schedule when <code>crontab(1)</code> is off limits? By way of <a href="https://github.com/BuGlessRB/procmail"><code>procmail(1)</code></a> the autonomous mail processor of course! <span>😜</span></p>
    <p>Given an <code>.procmailrc</code> of:</p>
    <pre>LOGFILE=$HOME/.procmail/log
PATH=$HOME/.local/bin:${PATH} 

:0:
* ^From: from
* ^Subject: Chatter
|cd justmoreidlechatternot; make
</pre>
    <p>I can then trigger my mechanism ad lib with:</p>
    <pre><strong># Subject and sender are the cues.</strong>
echo &#34;&#34; | mail -s &#34;Chatter&#34; -r from to
</pre>
    <h2>Front end</h2>
    <p>Smashing! And on to the browser part: To offset the retro pipeline magic, I should be looking at modern web platform features where possible and have been very excited lately about combining <a href="https://developer.mozilla.org/en-US/docs/Web/API/MediaStreamAudioDestinationNode">audio destination</a> and <a href="https://developer.mozilla.org/en-US/docs/Web/API/CanvasCaptureMediaStreamTrack">canvas capture</a> streams over <code>&lt;video&gt;</code>. There are a few quirks to be aware of, but it allows for picture-in-picture and fullscreen viewing and for frame rate throttling out of the box. I&#39;ve had a fair bit of luck with the following for a boilerplate so far:</p>
    <pre><strong>// Worth holding with page markup JS enabled or not. This way</strong>
<strong>// script settings can also be decided using HTML / CSS alone.</strong>
const video = document.querySelector(&#34;video&#34;)

<strong>// Turn off alpha for better performance.</strong>
const drawing = document.createElement(&#34;canvas&#34;)
  .getContext(&#34;2d&#34;, { alpha: false })

<strong>// User action required.</strong>
video.addEventListener(&#34;click&#34;, function SingleShotClickHandler() {
  const audio = new AudioContext()

  const destination = audio.createMediaStreamDestination()
  const [track] = destination.stream.getAudioTracks()

  video.srcObject.addTrack(track)

  <strong>// Creating audio nodes using constructors has advantages</strong>
  <strong>// over the older factory methods <a href="https://developer.mozilla.org/en-US/docs/Web/API/AudioNode#creating_an_audionode">according to MDN</a>.</strong>
  const master = new GainNode(audio, { gain: 0.75 })

  master.connect(destination)

  <strong>// Legit using the same node for both</strong>
  <strong>// time and frequency domain reads.</strong>
  const analyser = new AnalyserNode(audio, { fftSize: 128 })
  const frequencies = new Uint8Array(analyser.fftSize)
  const amplitudes = new Uint8Array(analyser.fftSize)

  master.connect(analyser)

  const loop = (time) =&gt; {
    <strong>// …</strong>
    <strong>// Be eccentric, store frame IDs in a <a href="https://developer.mozilla.org/en-US/docs/Web/API/HTMLElement/dataset">data attribute</a>.</strong>
    this.dataset.frame = requestAnimationFrame(loop)
  }

  this.onpause = () =&gt; {
    audio.suspend().then(() =&gt; {
      this.dataset.frame =
        cancelAnimationFrame(this.dataset.frame) ?? -1
    })
  }

  this.onplay = () =&gt; {
    audio.resume().then(() =&gt; {
      this.dataset.frame = requestAnimationFrame(loop)
    })
  }

  <strong>// Protect against starting multiple Chrome rAF loops.</strong>
  if (!this.paused &amp;&amp; !this.dataset.frame) {
    this.dataset.frame = requestAnimationFrame(loop)
  }
}, { once: true, passive: true })

<strong>// NOTE: Not to be confused with <a href="https://developer.mozilla.org/en-US/docs/Web/API/HTMLMediaElement/captureStream">HTMLMediaElement.captureStream()</a>,</strong>
<strong>// which takes no arguments. Set the frame rate to zero to</strong>
<strong>// disable automatic capture.</strong>
video.srcObject = drawing.canvas.captureStream(25)
video.onplay = function play() {
  <strong>// Because Chrome be eating up control bar click events,</strong>
  <strong>// but avoid on iOS Safari in particular.</strong>
  if (this.audioTracks === undefined) {
    this.click()
  }
}
</pre>
    <figure>
      <picture><source srcset="gotcha.webp" type="image/webp"/> <source srcset="gotcha.jp2" type="image/jp2"/> <source srcset="gotcha.jpx" type="image/jpx"/> <img src="https://thewhodidthis.com/more-than-idle-radio-chatter/gotcha.png" height="360" width="720" alt="Something to be aware of when transferring canvas text onto video"/></picture>
      <figcaption>
        <p>One gotcha of streaming canvas animations over video: Attempting to clear the context ahead of each draw affects text quality on Safari, but filling it up with color is right.</p>
      </figcaption>
    </figure>
    <p>Broadly speaking, the idea is to split the sample into grains stacked across different voices and to monitor the mix in the time and frequency domains for driving the visuals. Nothing unconventional in terms of parameterization either: One basic PRNG seeded by the minute adds predictability within limits when resolving grain profiles. Panning alone is left completely to chance. Mental or not, any remaining numbers are derived from my hometown&#39;s area code <code>210</code>.</p>
    <pre><strong>// ☎️ Stop The Madness!</strong>
const TEN = Number.parseInt(String(10).repeat(2), 2)
<strong>// Have <a href="https://en.wikipedia.org/wiki/Tetraphobia">no fear</a>.</strong>
const N = (TEN / 2) - (TEN / TEN)
</pre>
    <p>Sonically, I rely on <a href="https://developer.mozilla.org/en-US/docs/Web/API/OfflineAudioContext"><code>OfflineAudioContext</code></a> to render my grains in advance. I have four voices coming in on a short delay Canon style. I also have per grain low-pass filters in place to variably shield out high frequency information. Visually and dealing with speech as input, laying out Unicode characters onto a grid goes great in my opinion.</p>
    <pre><strong>// Prefer <a href="https://developer.mozilla.org/en-US/docs/Web/API/Geometry_interfaces">built-in geometry types</a>.</strong>
const { width, height } = video
const center = new DOMPoint(width / 2, height / 2)
const cell = new DOMRectReadOnly(0, 0, width / TEN, height / TEN)

const grid = Array.from({ length: TEN * TEN }, (_, i) =&gt; i)
const lookup = [...chunk(grid, 10)]

lookup.forEach((a, row) =&gt; {
  a.forEach((i, column) =&gt; {
    const character = grid.at(i)
    const point = new DOMPoint(column, row)
    const { x, y } = new DOMMatrix()
      <strong>// Spread.</strong>
      .scale(cell.width, cell.height)
      <strong>// Center.</strong>
      .translate(1 / 2, 1 / 2)
      <strong>// Start here.</strong>
      .transformPoint(point)

    drawing.fillText(character, Number.parseInt(x), Number.parseInt(y))
  })
})

function* chunk(a, n) {
  for (let i = 0; i &lt; a.length; i += n) {
    yield a.slice(i, i + n)
  }
}
</pre>
    <p>I&#39;m using matrix math to rotate the grid in each cardinal direction every frame. There had been talk of too much monkey business in my ears as I took this up, so why not introduce a little <code>HACKMEM</code>-ish <a href="https://thewhodidthis.com/sketches/bananana/">banana phenomenon</a> topical bonus variation into the picture as well. 🙊</p>
    <pre><strong>// For each animation frame at 25 fps:</strong>
const frame = Number(video.dataset.frame)

<strong>// These go from 0 to 255.</strong>
analyser.getByteFrequencyData(frequencies)
analyser.getByteTimeDomainData(amplitudes)

<strong>// Focus on the busiest bins.</strong>
frequencies
  .slice(0, 32)
  .forEach((v, i) =&gt; {
    const word = String(v).padStart(3, &#34; &#34;).split(&#34;&#34;)
    const step = frame % 64

    word.forEach((n, j) =&gt; {
      <strong>// Skip ASCII control characters.</strong>
      grid[(i * 3) + j] = String.fromCharCode(Number(n) + step + 32)
    })
  })

let stop = -1

<strong>// Repeat until no empty cells (four times).</strong>
while ((stop = grid.indexOf(&#34;&#34;)) !== -1) {
  <strong>// Take the last 3 items.</strong>
  const body = grid.slice(0, stop).join(&#34;&#34;)
  const last = body.slice(-3)

  <strong>// Search for a random occurrence of that sequence in the grid.</strong>
  const hits = []

  for (let i = body.indexOf(last); i !== -1; i = body.indexOf(last, i + 1)) {
    hits.push(i)
  }

  <strong>// Edit grid to include the next item.</strong>
  const pick = Math.floor(Math.random() * hits.length)
  const next = hits[pick]

  grid.copyWithin(stop, next, next + 1)
}
</pre>
    <p>For color, I have ripples of competing compositing operations and hues tied to the master signal&#39;s greatest peaks blowing up center on out:</p>
    <pre>const amplitude = Math.max.apply(Math, amplitudes) / 128

for (let i = 0; i &lt; N; i += 1) {
  const j =  i + 1

  const radius = Number.parseInt((amplitude * frame / j) % (width / 2))
  const hue = (amplitude * frame * j * 2) % 360
  const saturation = 100 - j
  const luminosity = i &amp; 1 ? 50 : 5

  drawing.save()
  drawing.globalCompositeOperation = frame % 2 === 0 ? &#34;overlay&#34; : &#34;color-dodge&#34;
  drawing.lineWidth = Math.round(radius / 2)
  drawing.strokeStyle = `hsl(${hue}deg, ${saturation}%, ${luminosity}%)`
  drawing.beginPath()
  drawing.ellipse(center.x, center.y, radius, radius, 0, 0, Math.PI * 2)
  drawing.stroke()
  drawing.restore()
}
</pre>
    <figure>
      <video height="500" width="500" poster="poster.png" controls="" playsinline=""></video>
      <figcaption>
        <p><strong>Tuketa-Tuk!</strong> Sweet life of a radio show NYC basement Martin Rev Seeburg Select-A-Rhythm percussive speech grains refreshing by mail at will, monthly, and every minute.</p>
      </figcaption>
    </figure>
    <p>Granted it&#39;s a common pattern, but is there ever any risk observing a beginning, a middle, and an end for a design? Climax with a moment of silence halfway through:</p>
    <pre>const material = await fetch(&#34;sample.mp3&#34;)
  .then(r =&gt; r.arrayBuffer())
  .then(b =&gt; audio.decodeAudioData(b))

if (audio.currentTime &gt; material.duration &amp;&amp; audio.currentTime &lt; material.duration + 1) {
  master.gain.setValueAtTime(0, audio.currentTime)
} else {
  master.gain.setValueAtTime(gain, audio.currentTime)
}
</pre>
    <p>Then quit without reserve past twice the clip duration:</p>
    <pre>if (audio.currentTime &gt; material.duration * 2) {
  audio.close().then(() =&gt; {
    <strong>// Clean up thoroughly, page refresh mandatory.</strong>
    const script = document.querySelector(&#34;script&#34;)

    video.onclick = null
    video.onplay = null

    video.srcObject.removeTrack(track)
    video.removeAttribute(&#34;controls&#34;)

    script?.remove()
  })
}
</pre>
    <h2>Dead end (rejected)</h2>
    <p>I try to avoid inline styles and was tempted to use <a href="https://web.dev/constructable-stylesheets/">constructible stylesheets</a> scaling my offscreen canvas for <a href="https://developer.mozilla.org/en-US/docs/Web/API/Canvas_API/Tutorial/Optimizing_canvas#scaling_for_high_resolution_displays">high resolution displays</a>, but <a href="https://developer.mozilla.org/en-US/docs/Web/API/CSSStyleSheet/insertRule"><code>insertRule()</code></a> is in fact no extra effort:</p>
    <pre><strong>// Freshly landed in <a href="https://developer.apple.com/documentation/safari-release-notes/safari-16_4-release-notes#New-Features">Safari 16.4</a> March &#39;23.</strong>
const sheet = new CSSStyleSheet()

document.adoptedStyleSheets = [sheet]

<strong>// Calling before or after the assignment makes no difference.</strong>
sheet.replaceSync(`canvas { height: ${height}px; width: ${width}px; }`)
</pre>
    <p>Reaching straight for <code>fetch()</code> to be loading the audio with may seem like an obvious choice, but leaves no room for indicating progress at the moment when XHR has <a href="https://developer.mozilla.org/en-US/docs/Web/API/XMLHttpRequest/progress_event">a native event</a> baked in already.</p>
    <pre><strong>// Too soon! Recreating progress metering using the Fetch and <a href="https://developer.mozilla.org/en-US/docs/Web/API/Streams_API/">Streams</a> APIs.</strong>
const track = await fetch(&#34;sample.mp3&#34;)
  .then(async (response) =&gt; {
    if (response.ok) {
      const total = Number(response.headers.get(&#34;content-length&#34;))
      const type = response.headers.get(&#34;content-type&#34;)

      const chunks = []

      <strong>// NOTE: Firefox has this already implemented. Other browsers</strong>
      <strong>// can manage <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Statements/for-await...of#browser_compatibility">for await...of</a> in separate situations though.</strong>
      <strong>// <a href="https://github.com/whatwg/streams/issues/778">github.com/whatwg/streams/issues/778</a></strong>
      for await (const chunk of response.body) {
        chunks.push(chunk)

        const detail = chunks.reduce((a, b) =&gt; a + b.length, 0) / total
        const p = new CustomEvent(&#34;fetch:progress&#34;, { detail })

        self.dispatchEvent(p)
      }

      const result = new Uint8Array(...chunks)

      return new Blob([result.buffer], { type })
    }
  })
  .then(blob =&gt; new Audio(URL.createObjectURL(blob)))
</pre>
    <h2>No end, next steps</h2>
    <p>Because it&#39;s so characteristic of the original, I stopped short of giving the audio any LPC treatment. That would have been imitating too hard and banal, but it should be interesting to maybe include tone generators in future iterations. Finally and since so many parameters are always changing, adding <a href="https://developer.mozilla.org/en-US/docs/Web/API/MediaStream_Recording_API">MediaStream Recording API</a> export functionality might be useful.</p>
  </article></div>
  </body>
</html>
