<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://en.wikipedia.org/wiki/Stochastic_parrot">Original</a>
    <h1>Stochastic Parrot</h1>
    
    <div id="readability-page-1" class="page"><div>
							

						<p>From Wikipedia, the free encyclopedia</p>
					</div><div id="mw-content-text" lang="en" dir="ltr"><div>
<p>In <a href="https://en.wikipedia.org/wiki/Machine_learning" title="Machine learning">machine learning</a>, &#34;<b>stochastic parrot</b>&#34; is a term coined by <a href="https://en.wikipedia.org/wiki/Emily_M._Bender" title="Emily M. Bender">Emily M. Bender</a><sup id="cite_ref-Uddin_2-0"><a href="#cite_note-Uddin-2">[2]</a></sup><sup id="cite_ref-Weil_3-0"><a href="#cite_note-Weil-3">[3]</a></sup> in the 2021 <a href="https://en.wikipedia.org/wiki/Artificial_intelligence" title="Artificial intelligence">artificial intelligence</a> research paper &#34;<b>On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?</b>&#34;  by Bender, <a href="https://en.wikipedia.org/wiki/Timnit_Gebru" title="Timnit Gebru">Timnit Gebru</a>, Angelina McMillan-Major, and <a href="https://en.wikipedia.org/wiki/Margaret_Mitchell_(scientist)" title="Margaret Mitchell (scientist)">Margaret Mitchell</a>.<sup id="cite_ref-parrot-paper_4-0"><a href="#cite_note-parrot-paper-4">[4]</a></sup> The term refers to &#34;large language models that are impressive in their ability to generate realistic-sounding language but ultimately do not truly understand the meaning of the language they are processing.&#34;<sup id="cite_ref-Uddin_2-1"><a href="#cite_note-Uddin-2">[2]</a></sup>
</p>
<meta property="mw:PageProp/toc"/>
<h2><span id="Definition_and_implications">Definition and implications</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Stochastic_parrot&amp;action=edit&amp;section=1" title="Edit section: Definition and implications">edit</a><span>]</span></span></h2>
<p><a href="https://en.wikipedia.org/wiki/Stochastic" title="Stochastic">Stochastic</a> means &#34;(1) random and (2) involving chance or probability&#34;.<sup id="cite_ref-5"><a href="#cite_note-5">[5]</a></sup> A &#34;stochastic parrot&#34;, according to Bender, is an entity &#34;for haphazardly stitching together sequences of linguistic forms … according to probabilistic information about how they combine, but without any reference to meaning.&#34;<sup id="cite_ref-Weil_3-1"><a href="#cite_note-Weil-3">[3]</a></sup> More formally, the term refers to &#34;large language models that are impressive in their ability to generate realistic-sounding language but ultimately do not truly understand the meaning of the language they are processing.&#34;<sup id="cite_ref-Uddin_2-2"><a href="#cite_note-Uddin-2">[2]</a></sup>
</p><p>According to Wahlström, et. al., the analogy highlights two vital limitations:
</p>
<blockquote>
<p>(i) The predictions made by a learning machine are essentially repeating back the contents of the data, with some added noise (or stochasticity) caused by the limitations of the model.
</p><p>
(ii) The machine learning algorithm does not understand the problem it has learnt. It can&#39;t know when it is repeating something incorrect, out of context, or socially inappropriate.</p></blockquote>
<p>They go on to note that because of these limitations, a learning machine might produce results which are &#34;dangerously wrong&#34;.
</p>
<h2><span id="Origin">Origin</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Stochastic_parrot&amp;action=edit&amp;section=2" title="Edit section: Origin">edit</a><span>]</span></span></h2>
<p>The term was first used in the paper  &#34;<i>On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?</i>&#34;  by Bender, <a href="https://en.wikipedia.org/wiki/Timnit_Gebru" title="Timnit Gebru">Timnit Gebru</a>, Angelina McMillan-Major, and <a href="https://en.wikipedia.org/wiki/Margaret_Mitchell_(scientist)" title="Margaret Mitchell (scientist)">Margaret Mitchell</a> (using the pseudonym &#34;Shmargaret Shmitchell&#34;).<sup id="cite_ref-parrot-paper_4-1"><a href="#cite_note-parrot-paper-4">[4]</a></sup> The paper covered the risks of very <a href="https://en.wikipedia.org/wiki/Large_language_model" title="Large language model">large language models</a>, regarding their environmental and financial costs, inscrutability leading to unknown dangerous biases, the inability of the models to understand the concepts underlying what they learn, and the potential for using them to deceive people.<sup id="cite_ref-:8_6-0"><a href="#cite_note-:8-6">[6]</a></sup>  The paper and subsequent events resulted in <a href="https://en.wikipedia.org/wiki/Timnit_Gebru#Exit_from_Google" title="Timnit Gebru">Gebru and Mitchell losing their jobs at Google</a>, and a subsequent protest by Google employees.<sup id="cite_ref-7"><a href="#cite_note-7">[7]</a></sup><sup id="cite_ref-8"><a href="#cite_note-8">[8]</a></sup>
</p>
<h2><span id="Subsequent_usage">Subsequent usage</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Stochastic_parrot&amp;action=edit&amp;section=3" title="Edit section: Subsequent usage">edit</a><span>]</span></span></h2>
<p>In July 2021, the <a href="https://en.wikipedia.org/wiki/Alan_Turing_Institute" title="Alan Turing Institute">Alan Turing Institute</a> hosted a keynote and panel discussion on the paper.  As of May 2023, the paper has been cited in 1529 publications.<sup id="cite_ref-10"><a href="#cite_note-10">[10]</a></sup> The term has been used in publications in the fields of law,<sup id="cite_ref-11"><a href="#cite_note-11">[11]</a></sup> grammar,<sup id="cite_ref-12"><a href="#cite_note-12">[12]</a></sup> narrative,<sup id="cite_ref-13"><a href="#cite_note-13">[13]</a></sup> and <a href="https://en.wikipedia.org/wiki/Humanities" title="Humanities">humanities</a>.<sup id="cite_ref-14"><a href="#cite_note-14">[14]</a></sup> The authors continue to maintain their concerns about the dangers of <a href="https://en.wikipedia.org/wiki/Chatbot" title="Chatbot">chatbots</a> based on large language models, such as <a href="https://en.wikipedia.org/wiki/GPT-4" title="GPT-4">GPT-4</a>.<sup id="cite_ref-15"><a href="#cite_note-15">[15]</a></sup>
</p>
<h2><span id="See_also">See also</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Stochastic_parrot&amp;action=edit&amp;section=4" title="Edit section: See also">edit</a><span>]</span></span></h2>
<ul><li><i><a href="https://en.wikipedia.org/wiki/1_the_Road" title="1 the Road">1 the Road</a></i></li>
<li><a href="https://en.wikipedia.org/wiki/Criticism_of_artificial_neural_networks" title="Criticism of artificial neural networks">Criticism of artificial neural networks</a></li>
<li><a href="https://en.wikipedia.org/wiki/Criticism_of_deep_learning" title="Criticism of deep learning">Criticism of deep learning</a></li>
<li><a href="https://en.wikipedia.org/wiki/Criticism_of_Google" title="Criticism of Google">Criticism of Google</a></li>
<li><a href="https://en.wikipedia.org/wiki/Cut-up_technique" title="Cut-up technique">Cut-up technique</a></li>
<li><a href="https://en.wikipedia.org/wiki/Infinite_monkey_theorem" title="Infinite monkey theorem">Infinite monkey theorem</a></li>
<li><a href="https://en.wikipedia.org/wiki/List_of_important_publications_in_computer_science" title="List of important publications in computer science">List of important publications in computer science</a></li>
<li><a href="https://en.wikipedia.org/wiki/Markov_text" title="Markov text">Markov text</a></li>
<li><a href="https://en.wikipedia.org/wiki/Stochastic_parsing" title="Stochastic parsing">Stochastic parsing</a></li></ul>
<h2><span id="References">References</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Stochastic_parrot&amp;action=edit&amp;section=5" title="Edit section: References">edit</a><span>]</span></span></h2>
<div>
<div><ol>

<li id="cite_note-Uddin-2"><span>^ <a href="#cite_ref-Uddin_2-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Uddin_2-1"><sup><i><b>b</b></i></sup></a> <a href="#cite_ref-Uddin_2-2"><sup><i><b>c</b></i></sup></a></span> <span><cite id="CITEREFUddin2023">Uddin, Muhammad Saad (April 20, 2023). <a rel="nofollow" href="https://towardsai.net/p/machine-learning/stochastic-parrots-a-novel-look-at-large-language-models-and-their-limitations">&#34;Stochastic Parrots: A Novel Look at Large Language Models and Their Limitations&#34;</a>. <i>Towards AI</i><span>. Retrieved <span>2023-05-12</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Towards+AI&amp;rft.atitle=Stochastic+Parrots%3A+A+Novel+Look+at+Large+Language+Models+and+Their+Limitations&amp;rft.date=2023-04-20&amp;rft.aulast=Uddin&amp;rft.aufirst=Muhammad+Saad&amp;rft_id=https%3A%2F%2Ftowardsai.net%2Fp%2Fmachine-learning%2Fstochastic-parrots-a-novel-look-at-large-language-models-and-their-limitations&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStochastic+parrot"></span></span>
</li>
<li id="cite_note-Weil-3"><span>^ <a href="#cite_ref-Weil_3-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-Weil_3-1"><sup><i><b>b</b></i></sup></a></span> <span><cite id="CITEREFWeil2023">Weil, Elizabeth (March 1, 2023). <a rel="nofollow" href="https://nymag.com/intelligencer/article/ai-artificial-intelligence-chatbots-emily-m-bender.html">&#34;You Are Not a Parrot&#34;</a>. <i><a href="https://en.wikipedia.org/wiki/New_York_(magazine)" title="New York (magazine)">New York</a></i><span>. Retrieved <span>2023-05-12</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=New+York&amp;rft.atitle=You+Are+Not+a+Parrot&amp;rft.date=2023-03-01&amp;rft.aulast=Weil&amp;rft.aufirst=Elizabeth&amp;rft_id=https%3A%2F%2Fnymag.com%2Fintelligencer%2Farticle%2Fai-artificial-intelligence-chatbots-emily-m-bender.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStochastic+parrot"></span></span>
</li>
<li id="cite_note-parrot-paper-4"><span>^ <a href="#cite_ref-parrot-paper_4-0"><sup><i><b>a</b></i></sup></a> <a href="#cite_ref-parrot-paper_4-1"><sup><i><b>b</b></i></sup></a></span> <span><cite id="CITEREFBenderGebruMcMillan-MajorShmitchell2021">Bender, Emily M.; Gebru, Timnit; McMillan-Major, Angelina; Shmitchell, Shmargaret (2021-03-01). <a rel="nofollow" href="https://doi.org/10.1145/3442188.3445922">&#34;On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?&#34;</a>. <i>Proceedings of the 2021 ACM Conference on Fairness, Accountability, and Transparency</i>. FAccT &#39;21. New York, NY, USA: Association for Computing Machinery: 610–623. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1145%2F3442188.3445922">10.1145/3442188.3445922</a>. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a> <a href="https://en.wikipedia.org/wiki/Special:BookSources/978-1-4503-8309-7" title="Special:BookSources/978-1-4503-8309-7"><bdi>978-1-4503-8309-7</bdi></a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" title="S2CID (identifier)">S2CID</a> <a rel="nofollow" href="https://api.semanticscholar.org/CorpusID:232040593">232040593</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Proceedings+of+the+2021+ACM+Conference+on+Fairness%2C+Accountability%2C+and+Transparency&amp;rft.atitle=On+the+Dangers+of+Stochastic+Parrots%3A+Can+Language+Models+Be+Too+Big%3F&amp;rft.pages=610-623&amp;rft.date=2021-03-01&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A232040593%23id-name%3DS2CID&amp;rft_id=info%3Adoi%2F10.1145%2F3442188.3445922&amp;rft.isbn=978-1-4503-8309-7&amp;rft.aulast=Bender&amp;rft.aufirst=Emily+M.&amp;rft.au=Gebru%2C+Timnit&amp;rft.au=McMillan-Major%2C+Angelina&amp;rft.au=Shmitchell%2C+Shmargaret&amp;rft_id=https%3A%2F%2Fdoi.org%2F10.1145%2F3442188.3445922&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStochastic+parrot"></span></span>
</li>
<li id="cite_note-5"><span><b><a href="#cite_ref-5">^</a></b></span> <span><cite><a rel="nofollow" href="https://www.merriam-webster.com/dictionary/stochastic">&#34;Stochastic&#34;</a>. <i>Merriam-Webster</i><span>. Retrieved <span>2023-05-13</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Merriam-Webster&amp;rft.atitle=Stochastic&amp;rft_id=https%3A%2F%2Fwww.merriam-webster.com%2Fdictionary%2Fstochastic&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStochastic+parrot"></span></span>
</li>
<li id="cite_note-:8-6"><span><b><a href="#cite_ref-:8_6-0">^</a></b></span> <span><cite id="CITEREFHaoarchive2020">Haoarchive, Karen (4 December 2020). <a rel="nofollow" href="https://www.technologyreview.com/2020/12/04/1013294/google-ai-ethics-research-paper-forced-out-timnit-gebru/">&#34;We read the paper that forced Timnit Gebru out of Google. Here&#39;s what it says&#34;</a>. <i><a href="https://en.wikipedia.org/wiki/MIT_Technology_Review" title="MIT Technology Review">MIT Technology Review</a></i>. <a rel="nofollow" href="https://web.archive.org/web/20211006233625/https://www.technologyreview.com/2020/12/04/1013294/google-ai-ethics-research-paper-forced-out-timnit-gebru/">Archived</a> from the original on 6 October 2021<span>. Retrieved <span>19 January</span> 2022</span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=MIT+Technology+Review&amp;rft.atitle=We+read+the+paper+that+forced+Timnit+Gebru+out+of+Google.+Here%27s+what+it+says.&amp;rft.date=2020-12-04&amp;rft.aulast=Haoarchive&amp;rft.aufirst=Karen&amp;rft_id=https%3A%2F%2Fwww.technologyreview.com%2F2020%2F12%2F04%2F1013294%2Fgoogle-ai-ethics-research-paper-forced-out-timnit-gebru%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStochastic+parrot"></span></span>
</li>
<li id="cite_note-7"><span><b><a href="#cite_ref-7">^</a></b></span> <span><cite id="CITEREFLyons2020">Lyons, Kim (5 December 2020). <a rel="nofollow" href="https://www.theverge.com/2020/12/5/22155985/paper-timnit-gebru-fired-google-large-language-models-search-ai">&#34;Timnit Gebru&#39;s actual paper may explain why Google ejected her&#34;</a>. <i>The Verge</i>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=The+Verge&amp;rft.atitle=Timnit+Gebru%27s+actual+paper+may+explain+why+Google+ejected+her&amp;rft.date=2020-12-05&amp;rft.aulast=Lyons&amp;rft.aufirst=Kim&amp;rft_id=https%3A%2F%2Fwww.theverge.com%2F2020%2F12%2F5%2F22155985%2Fpaper-timnit-gebru-fired-google-large-language-models-search-ai&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStochastic+parrot"></span></span>
</li>
<li id="cite_note-8"><span><b><a href="#cite_ref-8">^</a></b></span> <span><cite id="CITEREFTaylor2021">Taylor, Paul (2021-02-12). <a rel="nofollow" href="https://www.lrb.co.uk/blog/2021/february/stochastic-parrots">&#34;Stochastic Parrots&#34;</a>. <i><a href="https://en.wikipedia.org/wiki/London_Review_of_Books" title="London Review of Books">London Review of Books</a></i><span>. Retrieved <span>2023-05-09</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=London+Review+of+Books&amp;rft.atitle=Stochastic+Parrots&amp;rft.date=2021-02-12&amp;rft.aulast=Taylor&amp;rft.aufirst=Paul&amp;rft_id=https%3A%2F%2Fwww.lrb.co.uk%2Fblog%2F2021%2Ffebruary%2Fstochastic-parrots&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStochastic+parrot"></span></span>
</li>

<li id="cite_note-10"><span><b><a href="#cite_ref-10">^</a></b></span> <span><cite><a rel="nofollow" href="https://scholar.google.com/scholar?cluster=415069420329958137">&#34;Bender: On the Dangers of Stochastic Parrots&#34;</a>. <i><a href="https://en.wikipedia.org/wiki/Google_Scholar" title="Google Scholar">Google Scholar</a></i><span>. Retrieved <span>2023-05-12</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=Google+Scholar&amp;rft.atitle=Bender%3A+On+the+Dangers+of+Stochastic+Parrots&amp;rft_id=https%3A%2F%2Fscholar.google.com%2Fscholar%3Fcluster%3D415069420329958137&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStochastic+parrot"></span></span>
</li>
<li id="cite_note-11"><span><b><a href="#cite_ref-11">^</a></b></span> <span><cite id="CITEREFArnaudo2023">Arnaudo, Luca (April 20, 2023). &#34;Artificial Intelligence, Capabilities, Liabilities: Interactions in the Shadows of Regulation, Antitrust – And Family Law&#34;. <i>SSRN</i>. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.2139%2Fssrn.4424363">10.2139/ssrn.4424363</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" title="S2CID (identifier)">S2CID</a> <a rel="nofollow" href="https://api.semanticscholar.org/CorpusID:258636427">258636427</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=SSRN&amp;rft.atitle=Artificial+Intelligence%2C+Capabilities%2C+Liabilities%3A+Interactions+in+the+Shadows+of+Regulation%2C+Antitrust+%E2%80%93+And+Family+Law&amp;rft.date=2023-04-20&amp;rft_id=info%3Adoi%2F10.2139%2Fssrn.4424363&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A258636427%23id-name%3DS2CID&amp;rft.aulast=Arnaudo&amp;rft.aufirst=Luca&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStochastic+parrot"></span></span>
</li>
<li id="cite_note-12"><span><b><a href="#cite_ref-12">^</a></b></span> <span><cite id="CITEREFBleackleyBLOOM2023">Bleackley, Pete; BLOOM (2023). <a rel="nofollow" href="https://specgram.com/CXCII.3/07.bloom.cage.html">&#34;In the Cage with the Stochastic Parrot&#34;</a>. <i>Speculative Grammarian</i>. <b>CXCII</b> (3)<span>. Retrieved <span>2023-05-13</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Speculative+Grammarian&amp;rft.atitle=In+the+Cage+with+the+Stochastic+Parrot&amp;rft.volume=CXCII&amp;rft.issue=3&amp;rft.date=2023&amp;rft.aulast=Bleackley&amp;rft.aufirst=Pete&amp;rft.au=BLOOM&amp;rft_id=https%3A%2F%2Fspecgram.com%2FCXCII.3%2F07.bloom.cage.html&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStochastic+parrot"></span></span>
</li>
<li id="cite_note-13"><span><b><a href="#cite_ref-13">^</a></b></span> <span><cite id="CITEREFGáti2023">Gáti, Daniella (2023). &#34;Theorizing Mathematical Narrative through Machine Learning&#34;. <i><a href="https://en.wikipedia.org/wiki/Journal_of_Narrative_Theory" title="Journal of Narrative Theory">Journal of Narrative Theory</a></i>. Project MUSE. <b>53</b> (1): 139–165. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1353%2Fjnt.2023.0003">10.1353/jnt.2023.0003</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" title="S2CID (identifier)">S2CID</a> <a rel="nofollow" href="https://api.semanticscholar.org/CorpusID:257207529">257207529</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Journal+of+Narrative+Theory&amp;rft.atitle=Theorizing+Mathematical+Narrative+through+Machine+Learning.&amp;rft.volume=53&amp;rft.issue=1&amp;rft.pages=139-165&amp;rft.date=2023&amp;rft_id=info%3Adoi%2F10.1353%2Fjnt.2023.0003&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A257207529%23id-name%3DS2CID&amp;rft.aulast=G%C3%A1ti&amp;rft.aufirst=Daniella&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStochastic+parrot"></span></span>
</li>
<li id="cite_note-14"><span><b><a href="#cite_ref-14">^</a></b></span> <span><cite id="CITEREFRees2022">Rees, Tobias (2022). &#34;Non-Human Words: On GPT-3 as a Philosophical Laboratory&#34;. <i><a href="https://en.wikipedia.org/wiki/Daedalus_(journal)" title="Daedalus (journal)">Daedalus</a></i>. <b>151</b> (2): 168–82. <a href="https://en.wikipedia.org/wiki/Doi_(identifier)" title="Doi (identifier)">doi</a>:<a rel="nofollow" href="https://doi.org/10.1162%2Fdaed_a_01908">10.1162/daed_a_01908</a>. <a href="https://en.wikipedia.org/wiki/JSTOR_(identifier)" title="JSTOR (identifier)">JSTOR</a> <a rel="nofollow" href="https://www.jstor.org/stable/48662034">48662034</a>. <a href="https://en.wikipedia.org/wiki/S2CID_(identifier)" title="S2CID (identifier)">S2CID</a> <a rel="nofollow" href="https://api.semanticscholar.org/CorpusID:248377889">248377889</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=article&amp;rft.jtitle=Daedalus&amp;rft.atitle=Non-Human+Words%3A+On+GPT-3+as+a+Philosophical+Laboratory&amp;rft.volume=151&amp;rft.issue=2&amp;rft.pages=168-82&amp;rft.date=2022&amp;rft_id=https%3A%2F%2Fapi.semanticscholar.org%2FCorpusID%3A248377889%23id-name%3DS2CID&amp;rft_id=https%3A%2F%2Fwww.jstor.org%2Fstable%2F48662034%23id-name%3DJSTOR&amp;rft_id=info%3Adoi%2F10.1162%2Fdaed_a_01908&amp;rft.aulast=Rees&amp;rft.aufirst=Tobias&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStochastic+parrot"></span></span>
</li>
<li id="cite_note-15"><span><b><a href="#cite_ref-15">^</a></b></span> <span><cite id="CITEREFGoldman2023">Goldman, Sharon (March 20, 2023). <a rel="nofollow" href="https://venturebeat.com/ai/with-gpt-4-dangers-of-stochastic-parrots-remain-say-researchers-no-wonder-openai-ceo-is-a-bit-scared-the-ai-beat/">&#34;With GPT-4, dangers of &#39;Stochastic Parrots&#39; remain, say researchers. No wonder OpenAI CEO is a &#39;bit scared&#39;<span></span>&#34;</a>. <i>VentureBeat</i><span>. Retrieved <span>2023-05-09</span></span>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Ajournal&amp;rft.genre=unknown&amp;rft.jtitle=VentureBeat&amp;rft.atitle=With+GPT-4%2C+dangers+of+%27Stochastic+Parrots%27+remain%2C+say+researchers.+No+wonder+OpenAI+CEO+is+a+%27bit+scared%27&amp;rft.date=2023-03-20&amp;rft.aulast=Goldman&amp;rft.aufirst=Sharon&amp;rft_id=https%3A%2F%2Fventurebeat.com%2Fai%2Fwith-gpt-4-dangers-of-stochastic-parrots-remain-say-researchers-no-wonder-openai-ceo-is-a-bit-scared-the-ai-beat%2F&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStochastic+parrot"></span></span>
</li>
</ol></div></div>
<h3><span id="Works_cited">Works cited</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Stochastic_parrot&amp;action=edit&amp;section=6" title="Edit section: Works cited">edit</a><span>]</span></span></h3>
<ul><li><cite id="CITEREFWahlströmLindholmSchönLindsten2022">Wahlström, N.; Lindholm, A.; Schön, T. B.; Lindsten, F. (2022). <i>Machine Learning: A First Course for Engineers and Scientists</i>. Cambridge University Press. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a> <a href="https://en.wikipedia.org/wiki/Special:BookSources/978-1108843607" title="Special:BookSources/978-1108843607"><bdi>978-1108843607</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Machine+Learning%3A+A+First+Course+for+Engineers+and+Scientists&amp;rft.pub=Cambridge+University+Press&amp;rft.date=2022&amp;rft.isbn=978-1108843607&amp;rft.aulast=Wahlstr%C3%B6m&amp;rft.aufirst=N.&amp;rft.au=Lindholm%2C+A.&amp;rft.au=Sch%C3%B6n%2C+T.+B.&amp;rft.au=Lindsten%2C+F.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStochastic+parrot"></span></li>
<li><cite id="CITEREFWeller2021">Weller, Adrian (July 13, 2021). <a rel="nofollow" href="https://www.youtube.com/watch?v=N5c2X8vhfBE"><i>On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?</i></a> (video). <a href="https://en.wikipedia.org/wiki/Alan_Turing_Institute" title="Alan Turing Institute">Alan Turing Institute</a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=unknown&amp;rft.btitle=On+the+Dangers+of+Stochastic+Parrots%3A+Can+Language+Models+Be+Too+Big%3F&amp;rft.pub=Alan+Turing+Institute&amp;rft.date=2021-07-13&amp;rft.aulast=Weller&amp;rft.aufirst=Adrian&amp;rft_id=https%3A%2F%2Fwww.youtube.com%2Fwatch%3Fv%3DN5c2X8vhfBE&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStochastic+parrot"></span> Keynote by Emily Bender. The presentation was followed by a panel discussion.</li></ul>
<h2><span id="Further_reading">Further reading</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Stochastic_parrot&amp;action=edit&amp;section=7" title="Edit section: Further reading">edit</a><span>]</span></span></h2>
<ul><li><cite id="CITEREFThompson2022">Thompson, E. (2022). <i>Escape from Model Land: How Mathematical Models Can Lead Us Astray and What We Can Do about It</i>. Basic Books. <a href="https://en.wikipedia.org/wiki/ISBN_(identifier)" title="ISBN (identifier)">ISBN</a> <a href="https://en.wikipedia.org/wiki/Special:BookSources/978-1541600980" title="Special:BookSources/978-1541600980"><bdi>978-1541600980</bdi></a>.</cite><span title="ctx_ver=Z39.88-2004&amp;rft_val_fmt=info%3Aofi%2Ffmt%3Akev%3Amtx%3Abook&amp;rft.genre=book&amp;rft.btitle=Escape+from+Model+Land%3A+How+Mathematical+Models+Can+Lead+Us+Astray+and+What+We+Can+Do+about+It&amp;rft.pub=Basic+Books&amp;rft.date=2022&amp;rft.isbn=978-1541600980&amp;rft.aulast=Thompson&amp;rft.aufirst=E.&amp;rfr_id=info%3Asid%2Fen.wikipedia.org%3AStochastic+parrot"></span></li></ul>
<h2><span id="External_links">External links</span><span><span>[</span><a href="https://en.wikipedia.org/w/index.php?title=Stochastic_parrot&amp;action=edit&amp;section=8" title="Edit section: External links">edit</a><span>]</span></span></h2>
<ul><li>&#34;<a href="https://commons.wikimedia.org/wiki/File:On_the_Dangers_of_Stochastic_Parrots_Can_Language_Models_Be_Too_Big.pdf">On the Dangers of Stochastic Parrots: Can Language Models Be Too Big?</a>&#34; at Wikimedia Commons</li></ul>
<!-- 
NewPP limit report
Parsed by mw2421
Cached time: 20230613142356
Cache expiry: 1814400
Reduced expiry: false
Complications: [vary‐revision‐sha1, show‐toc]
CPU time usage: 0.211 seconds
Real time usage: 0.271 seconds
Preprocessor visited node count: 1428/1000000
Post‐expand include size: 33429/2097152 bytes
Template argument size: 1698/2097152 bytes
Highest expansion depth: 13/100
Expensive parser function count: 1/500
Unstrip recursion depth: 1/20
Unstrip post‐expand size: 46174/5000000 bytes
Lua time usage: 0.124/10.000 seconds
Lua memory usage: 7939936/52428800 bytes
Number of Wikibase entities loaded: 0/400
-->
<!--
Transclusion expansion time report (%,ms,calls,template)
100.00%  249.134      1 -total
 48.15%  119.964      1 Template:Reflist
 21.89%   54.546      1 Template:Short_description
 20.88%   52.018      1 Template:Cite_news
 12.92%   32.181      3 Template:Sfn
 11.30%   28.140      2 Template:Pagetype
  8.25%   20.559      5 Template:Cite_journal
  7.34%   18.280      6 Template:Cite_web
  6.42%   15.984      9 Template:Main_other
  5.28%   13.156      1 Template:As_of
-->

<!-- Saved in parser cache with key enwiki:pcache:idhash:73761282-0!canonical and timestamp 20230613142356 and revision id 1159943182. Rendering was triggered because: page-view
 -->
</div><!--esi <esi:include src="/esitest-fa8a495983347898/content" /> -->
</div></div>
  </body>
</html>
