<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://electrek.co/2025/11/08/schrodingers-fsd-when-things-go-well-teslas-driving-when-they-dont-you-are/">Original</a>
    <h1>When Tesla&#39;s FSD works well, it gets credit. When it doesn&#39;t, you get blamed</h1>
    
    <div id="readability-page-1" class="page"><div>
					
<figure>

	<img width="1076" height="717" src="https://electrek.co/wp-content/uploads/sites/3/2025/08/tesla-autopilot-crash-florida-mcgee-monroe-county-sheriff.webp?w=1076" alt="" srcset="https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/08/tesla-autopilot-crash-florida-mcgee-monroe-county-sheriff.webp?w=320&amp;quality=82&amp;strip=all&amp;ssl=1 320w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/08/tesla-autopilot-crash-florida-mcgee-monroe-county-sheriff.webp?w=640&amp;quality=82&amp;strip=all&amp;ssl=1 640w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/08/tesla-autopilot-crash-florida-mcgee-monroe-county-sheriff.webp?w=1024&amp;quality=82&amp;strip=all&amp;ssl=1 1024w, https://i0.wp.com/electrek.co/wp-content/uploads/sites/3/2025/08/tesla-autopilot-crash-florida-mcgee-monroe-county-sheriff.webp?w=1500&amp;quality=82&amp;strip=all&amp;ssl=1 1500w" decoding="async" fetchpriority="high"/>			<figcaption>
				Photo by Monroe County Sheriff&#39;s Department, via New York Times			</figcaption>
			
	</figure>

<p>Tesla has engaged in a pattern of taking credit for the successes of its Full Self-Driving (FSD) software, even though the car still relies on an attentive driver, and yet blaming the driver rather than the software whenever things go badly.</p>



<p>But new moves towards allowing more distracted driving could make it harder for the company to blame drivers when its software fails.</p>



<p>Tesla has been marketing some version of its Autopilot or FSD software since 2013. Ever since then, the company has made bold pronouncements about how rapidly the software would improve, stating almost continually that fully autonomous driving would come <a href="https://en.wikipedia.org/wiki/List_of_predictions_for_autonomous_Tesla_vehicles_by_Elon_Musk">within a year</a>.</p>



<p>Autopilot and FSD have changed definitions over time, with basic Autopilot initially being an option and now being included on most vehicles, and with FSD being an additional cost on top of that, at varying prices (costing <a href="https://electrek.co/2022/09/05/tesla-raises-full-self-driving-price-to-15000-is-it-worth-it/">up to $15,000</a> at one point).</p>	
	



<p>In general, Autopilot has promised to be a driver’s aid, while FSD has promised to allow the car to fully drive itself with no human intervention when the software is finally ready.</p>



<p>That fully autonomous ability has yet to be delivered, but Tesla’s software does continue to improve.</p>



<p>At first Autopilot was merely active on highways, as soft of a “smart cruise control” system. It could hold the car in a lane and track the speed of vehicles ahead and match them.</p>



<p>Over time the systems have gained more capabilities, including being able to follow the car’s navigation system and take highway interchanges on its own. And throughout all this time, colloquially Teslas have very often been referred to as “self-driving cars.”</p>



<p>FSD can now operate not just on highways, but on surface streets. It is possible to do certain drives without a human touching the steering wheel – but a driver must always be in the driver’s seat and paying attention to the road (and Tesla <a href="https://electrek.co/2021/05/27/tesla-releases-driver-monitoring-system-cabin-camera/">will monitor you to make sure you’re doing so</a>). </p>



<h2 id="h-a-quick-primer-on-autonomous-drive-systems">A quick primer on autonomous drive systems</h2>



<p>This is because both Autopilot and FSD, and every software version of them that has so far been released, fall under the same high-level classification of autonomous drive systems. They’re all “Level 2” drive systems, according to the <a href="https://www.sae.org/news/blog/sae-levels-driving-automation-clarity-refinements">SAE levels of driving automation</a>.</p>



<p>All driving automation systems are ranked from level 0-5. With level 0-2 systems, drivers are responsible for everything the car does. With a level 3 system, the car can be considered responsible at some times, and with level 4 or 5 systems, the car is always responsible.</p>



<p>There is one level 3 system available in the US, <a href="https://electrek.co/2023/09/27/hands-off-with-the-first-true-hands-free-car-in-the-us-and-its-not-tesla/">Mercedes DRIVE PILOT</a>, which can be used in narrow circumstances to let the car drive for you. And autonomous <a href="https://electrek.co/2023/10/08/waymos-driverless-taxi-tested-perfect-chaos-venice-beach-weekend/">driverless taxis like Waymo </a>are level 4 systems, with no driver but the ability only to operate in certain situations or areas (<a href="https://electrek.co/2025/06/25/whoopsie-uh-oh-oh-my-heres-all-the-gaffes-and-goofs-by-tesla-robotaxi-so-far/">Tesla’s Robotaxi</a> is purportedly similar to Waymo, but due to the presence of a “safety monitor,” it is arguably level 2, since an operator is still in the vehicle, just not in the driver’s seat).</p>



<p>But Tesla’s promises about FSD would put it squarely into the “level 5” category. CEO Elon Musk has repeatedly stated that FSD will eventually be able to drive the car across the country with nobody in it, such that your car could be in New York and you could ask it to come pick you up in Los Angeles. That ability has not yet been delivered though, so we’re still in level 2 territory.</p>



<h2 id="h-tesla-likes-to-crow-about-fsd-s-improvements">Tesla likes to crow about FSD’s improvements</h2>



<p>Tesla proclaims quite often that its FSD system is better than human drivers, and that its level of safety is increasing over time.</p>



<p>It often releases data showing the number of miles between crashes, comparing miles driven by humans and miles driven by FSD. In Tesla’s released numbers, miles driven by FSD are safer than those driven by humans.</p>



<p>That’s not the whole story though, because the data is somewhat cherry picked. A real study on safety would attempt to rule out extraneous variables that could influence the results, and as of yet, Tesla has not conducted a robust study of that manner (in contrast, Waymo has released <a href="https://electrek.co/2024/12/19/study-waymos-robotaxi-provides-higher-safety-performance-than-human-drivers/">multiple</a> <a href="https://electrek.co/2023/12/20/waymo-says-its-self-driving-cars-are-safer-than-human-drivers-by-up-to-10x/">studies</a> conducted through <a href="https://arxiv.org/pdf/2309.01206">outside entities</a>).</p>



<p>There is also some difference between Tesla-provided numbers and <a href="https://electrek.co/2024/09/26/tesla-full-self-driving-third-party-testing-13-miles-between-interventions/">third-party numbers</a>, showing that Tesla’s “miles between interventions” is <a href="https://electrek.co/2025/02/06/elon-musk-approved-tesla-full-self-driving-dataset-doubled-whats-the-state-of-fsd-now/">relatively low</a>. This is thought of as a key indicator of how close a system is to being level 4-5 capable, as ideally a self-driving car should be able to go tens of thousands of miles without needing a human to come fix something.</p>



<p>Tesla did provide <a href="https://electrek.co/2025/11/06/elon-musk-tesla-fsd-allow-texting-and-driving-month-two/">a new update on data</a> at this week’s <a href="https://electrek.co/2025/11/06/tesla-tsla-shareholders-shoot-selves-in-foot-approve-musk-1-trillion-payday/">shareholder meeting</a>, again showing that FSD miles result in far fewer accidents than other modes of driving. Though that update again doesn’t provide the robust data that a real study would, and indeed, Tesla’s own numbers show a <a href="https://electrek.co/2025/10/22/teslas-autopilot-safety-data-is-getting-worse/">reduction in safety over the course of this year.</a></p>



<p>And in fact, none of these numbers provided by Tesla ever describe just how safe FSD is on its own. All of them rely on the combined safety of both FSD <em>and</em> a human driver at the same time, as humans are required to be in the seat while operating the vehicle. When that human co-driver is moved to the passenger seat and called a safety monitor, <a href="https://electrek.co/2025/10/29/tesla-robotaxis-keep-crashing-despite-safety-monitors/">safety numbers plummet</a>.</p>



<p>So Tesla frames FSD data in a positive light, but what about when something bad happens?</p>



<h2 id="h-tesla-blames-drivers-when-its-systems-fail">Tesla blames drivers when its systems fail</h2>



<p>When there’s an accident associated with its driver-assistance systems, Tesla will be the first to claim that it had nothing to do with it, and that the driver is at fault.</p>



<p>This is technically true. If FSD and Autopilot are level 2 systems, then the driver is responsible for everything the car is doing. And drivers must accept an agreement in the car before activating these systems acknowledging that they must pay attention to the road at all times and are responsible for what the car does even when the systems are activated.</p>



<p>So, for example, when a Florida driver on Autopilot drops his phone and blows through a stop sign, hitting a car which then hits two pedestrians,<a href="https://electrek.co/2025/08/01/victims-of-tesla-autopilot-crash-are-seeking-345-million-in-damages/"> killing one</a>, Tesla will claim “this driver was solely at fault.” In that case, a judge agreed that the driver was mostly at fault, but still assigned 33% of blame to Tesla, resulting in a <a href="https://electrek.co/2025/08/01/tesla-tsla-is-found-liable-in-fatal-autopilot-crash-has-to-pay-329-million/">$243 million judgment against the company</a>.</p>



<p>Part of the reason that case was decided as it was was due to Musk’s constant statements about Autopilot and FSD’s abilities. After spending so many years talking up Tesla’s self-driving abilities, it is common for drivers and the general public to think that Tesla cars “drive themselves.” But Tesla said that those statements <a href="https://electrek.co/2025/08/29/tesla-asks-court-to-throw-out-243-million-verdict-in-fatal-autopilot-crash-case/">shouldn’t have been heard at the case at all</a>, again wanting to make this failure about the driver, not about Autopilot.</p>



<p>The judgment was also influenced by Tesla’s <a href="https://electrek.co/2025/08/04/tesla-withheld-data-lied-misdirected-police-plaintiffs-avoid-blame-autopilot-crash/">withholding of data</a>, which tracks with the company’s aforementioned refusal to submit its FSD data to robust outside scientific study.</p>



<p>Tesla has <a href="https://electrek.co/2025/04/21/tesla-settles-another-wrongful-death-lawsuit-implications/">settled other similar cases</a> before they went to trial, paying out large sums to keep discussion of Autopilot safety out of court. But it refused to settle the Florida case, which <a href="https://electrek.co/2025/08/26/tesla-kept-its-promise-not-to-settle-it-cost-the-company-an-extra-183-million/">may have been a strategic mistake</a>.</p>



<p>So we have a contradiction here: when Tesla’s systems do well, Tesla takes all the credit, even though there’s a driver in the driver’s seat. But when they do poorly, Tesla does what it can to obscure causes or to blame drivers (who, to be fair, are still tasked with operating the vehicle, despite Musk’s many hopeful statements about self-driving). It’s <a href="https://en.wikipedia.org/wiki/Schr%C3%B6dinger&#39;s_cat">Schrödinger’s FSD</a>: responsible when Tesla wants it to be, but not when Tesla doesn’t want it to be.</p>



<p>But that might change going forward.</p>



<h2 id="h-tesla-s-move-away-from-driver-monitoring-could-open-it-up-to-more-liability">Tesla’s move away from driver monitoring could open it up to more liability</h2>



<p>So, Tesla has heretofore managed to dodge responsibility for many of FSD’s problems by alleging that the driver is responsible at all times. And it’s not wrong to point this out.</p>



<p>However, at this week’s shareholder meeting, Musk stated that Tesla may allow “texting and driving” within “a month or two.”</p>



<p>What he seemed to be referring to is Tesla’s in-car driver monitoring system, which tracks driver attention using a camera near the rear-view mirror. If the system notices that you’re looking away from the road for too long, it will warn you and then deactivate FSD and make you take over driving for yourself, to ensure you’re doing your job as a driver.</p>



<p>Musk said that the issue with this is that many people want to text and drive anyway, and so will turn off FSD so they can send a text, then turn it back on after the fact. Musk alleges that it would be safer for those drivers to text and drive with FSD on than having it off, so Tesla might as well go ahead and update the software to allow for this soon.</p>



<p>But an unintended consequence of this could be that future court cases could use Tesla’s overconfidence in this matter against the company, claiming that it wasn’t doing its job to ensure driver attention. Despite claiming that drivers are always in control of the vehicle, Musk has now told drivers that it’s okay to take their eyes off the road – and the car won’t do anything to stop you from doing so, either.</p>



<p>And as we saw in the Florida case, Musk’s public statements were a part of the case. So Musk’s now-overconfidence about letting drivers text and drive could certainly show up in a courtroom in the future.</p>



<p>The use of driver monitoring for court cases is also of specific interest to Musk, as in the past he has floated the idea that <a href="https://electrek.co/2023/09/15/musk-wanted-to-use-tesla-cameras-to-spy-on-drivers-and-win-autopilot-lawsuits/">Tesla should spy on drivers</a> with the in-car camera and use those recordings to prevail in Autopilot crash cases. Tesla’s lawyers shut this idea down at the time.</p>




	<p>But now, moving forward, that doesn’t even matter. The CEO has stated that cars will be updated supposedly within a month or two to allow you to look away from the road. There would be no purpose to recording drivers for lack of attention, because Tesla will supposedly allow drivers to look away freely.</p>



<p>And even if drivers agree to always pay attention, if Tesla is giving them features that specifically encourage them <em>not to</em>, and those features are framed explicitly by the CEO to encourage illegal eyes-off-road activity, we think the company might have a much harder time playing its “Schrödinger’s FSD” game in court going forward.</p>



<hr/>



<p><em>The 30% federal solar tax credit is ending this year. If you’ve ever considered going solar, now’s the time to act. To make sure you find a trusted, reliable solar installer near you that offers competitive pricing, check out </em><a href="https://www.dpbolvw.net/click-101268381-15908683"><em>EnergySage</em></a><em>, a free service that makes it easy for you to go solar. It has hundreds of pre-vetted solar installers competing for your business, ensuring you get high-quality solutions and save 20-30% compared to going it alone. Plus, it’s free to use, and you won’t get sales calls until you select an installer and share your phone number with them.</em></p>



<p><em>Your personalized solar quotes are easy to compare online and you’ll get access to unbiased Energy Advisors to help you every step of the way. </em><a href="https://www.dpbolvw.net/click-101268381-15908683"><em>Get started here</em></a><em>.</em></p>
	<p><a target="_blank" rel="nofollow" href="https://google.com/preferences/source?q=https://electrek.co">
			<img decoding="async" src="https://electrek.co/wp-content/themes/ninetofive/dist/images/google-preferred-source-badge-dark.png" alt="Add Electrek as a preferred source on Google"/>
			<img decoding="async" src="https://electrek.co/wp-content/themes/ninetofive/dist/images/google-preferred-source-badge-light.png" alt="Add Electrek as a preferred source on Google"/>
		</a>
			</p>
	<div><p><em>FTC: We use income earning auto affiliate links.</em> <a href="https://electrek.co/about/#affiliate">More.</a></p><p><a href="https://bit.ly/4gr6unf"><img src="https://electrek.co/wp-content/uploads/sites/3/2025/11/Electrek-Banner-Ad-CXC-10th-Raffle-750_150.jpg?quality=82&amp;strip=all" alt="" width="750" height="150"/></a></p></div>				</div></div>
  </body>
</html>
