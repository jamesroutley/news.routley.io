<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://ntietz.com/blog/optimize-sprint-points-to-go-slow/">Original</a>
    <h1>Optimize sprint points to get nowhere fast</h1>
    
    <div id="readability-page-1" class="page"><article>
    

    <p><strong>Monday, June 12, 2023</strong></p>

    <p>As developers, we can be metric obsessed. We tend to like objective measures of things. 99th percentile request times, CPU percentage, disk utilization. Nothing escapes our attempts to quantify it, not even our productivity: enter story points.</p>
<p>We measure our productivity in some way by how much we get done. This is the quantity of work or complexity that a team can get done in a sprint. And once we have a metric, we ruthlessly optimize it.</p>
<p>We want to move fast, so we see how we can improve sprint points. What processes can we optimize? Can we get designs earlier, and plan things out a little better? Can we streamline and remove meetings?</p>
<p>We push story points up and up and up. Eventually they&#39;re at a new level, and that becomes the new baseline we have to hit. The urge to get it higher is there, and it&#39;s a ratchet that doesn&#39;t let the level slip back down.</p>
<p>But where are we going? That&#39;s sometimes delegated to product. Product worries about <em>what</em> we build, and engineering worries about <em>how</em> we build it. In the ideal world, anyway. But, here&#39;s the rub. <strong>We are all on the same team together</strong>. We are all going the same place. Code doesn&#39;t matter if it isn&#39;t useful, and ideas and product direction don&#39;t matter if they don&#39;t get implemented.</p>
<p>We&#39;re one team, and we should have the same direction. If we optimize for speed of engineering, we are sacrificing something else.</p>
<p>The problem is with our frame of reference. If we are zoomed in to what we get done each sprint, we are looking just relative to engineering and just relative to where we are. <em>Are we moving? How fast?</em> But we&#39;re not asking about where we&#39;re going.</p>
<p>If we zoom out and we look in terms of the destination, we get to the measurement that really matters. The ultimate metric that we care about is: how quickly do we get to the final destination of features that work for the users?
To really stretch the metaphor, we usually measure the speed of our car, but we don&#39;t think about which direction it&#39;s pointed in. If we find a highway without a speed limit, we might get on that even if it can&#39;t take us where we need to go!</p>
<p>So why don&#39;t we measure progress toward our destination? Well, because <strong>we don&#39;t know where that is until we get there</strong>. If we knew ahead of time where we&#39;re going, then we <em>could</em> just measure sprint points since we would know what product direction is the most important one. But ultimately, we don&#39;t know that.</p>
<p>We know we got to a good destination <em>once we get there</em>. While we&#39;re on the way, we don&#39;t know what works and what doesn&#39;t.</p>
<p>So, what do we do instead?</p>
<p>First, don&#39;t throw the baby out with the bathwater. Sprint points are important. (Well, some estimation of productivity is important; relative velocity, as it were). We want to keep that measure, but we have to work to not optimize for it alone. It isn&#39;t the end goal, but it&#39;s a useful diagnostic signal. If you can&#39;t get your car above 20 MPH, you want to go get it checked out, but that doesn&#39;t mean you always want to floor it.</p>
<p>And so we can look at other metrics. These are going to be things that center around exploring the landscape so that we can figure out the direction to go in more effectively. Some candidates that come to mind:</p>
<ul>
<li><strong>Time to ship an MVP of a feature</strong>: the shorter you make this, the faster you can get feedback and determine whether or not it&#39;s the right direction</li>
<li><strong>Time to get user feedback on a new feature</strong>: again, shorter gets you feedback faster</li>
<li><strong>Time to complete an iteration on a feature</strong>: the more iterations you can fit in, the more times you can get feedback, and the more you can course correct</li>
<li><strong>Amount of user feedback you can get per timeframe</strong>: this will help you know where you&#39;re going</li>
</ul>
<p>It doesn&#39;t really matter what the specific metric is, as long as you switch from optimizing for productivity alone, and include consideration for the ability to explore and get feedback. I don&#39;t think these metrics are north stars that should be optimized for independently, either. All metrics in moderation, as they say.</p>
<p>This isn&#39;t something engineering can do alone. This isn&#39;t something product can do alone! Making great software is a team sport and is highly, intrinsically, collaborative. Working together to measure the right thing and shift focus to the final destination is one of the keys to making great software and great products.</p>
<p>Let&#39;s not forget that where we get to matters a lot more than how we get there.</p>
<hr/>



  </article><p>
    If this post was enjoyable or useful for you, <strong>please share it!</strong>
    If you have comments, questions, or feedback, please email <a href="mailto:~ntietz/public-inbox@lists.sr.ht">my public inbox</a> or <a href="mailto:me@ntietz.com">my personal email</a>.
    To get new posts, please use my <a href="https://ntietz.com/atom.xml">RSS feed</a>.
  </p></div>
  </body>
</html>
