<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://arxiv.org/abs/2302.00441">Original</a>
    <h1>Hyperparameter Optimization for LLMs via Scaling Laws</h1>
    
    <div id="readability-page-1" class="page"><div id="content-inner">
  <div id="abs">
    
    
    
    
      
    
  
  
  
    <p><a aria-describedby="download-button-info" href="https://arxiv.org/pdf/2302.00441">Download PDF</a></p><blockquote>
            <span>Abstract:</span>  Hyperparameter optimization is an important subfield of machine learning that
focuses on tuning the hyperparameters of a chosen algorithm to achieve peak
performance. Recently, there has been a stream of methods that tackle the issue
of hyperparameter optimization, however, most of the methods do not exploit the
scaling law property of learning curves. In this work, we propose Deep Power
Laws (DPL), an ensemble of neural network models conditioned to yield
predictions that follow a power-law scaling pattern. Our method dynamically
decides which configurations to pause and train incrementally by making use of
gray-box evaluations. We compare our method against 7 state-of-the-art
competitors on 3 benchmarks related to tabular, image, and NLP datasets
covering 59 diverse tasks. Our method achieves the best results across all
benchmarks by obtaining the best any-time results compared to all competitors.

    </blockquote>

    <!--CONTEXT-->
    
  </div>
</div><div>
      <h2>Submission history</h2><p> From: Arlind Kadra [<a href="https://arxiv.org/show-email/7da75342/2302.00441">view email</a>]
      </p></div></div>
  </body>
</html>
