<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://dariuszsemba.com/blog/why-autogpt-engineers-ditched-vector-databases/">Original</a>
    <h1>Why AutoGPT engineers ditched vector databases</h1>
    
    <div id="readability-page-1" class="page"><div>
      <picture>
	<source type="image/avif" srcset="/_astro/autogpt_drop_vector_database_gU92L.avif 200w,/_astro/autogpt_drop_vector_database_1aEeOr.avif 400w,/_astro/autogpt_drop_vector_database_ZDBFAP.avif 800w" sizes="(max-width: 800px) 100vw, 800px"/><source type="image/webp" srcset="/_astro/autogpt_drop_vector_database_ZTFeMi.webp 200w,/_astro/autogpt_drop_vector_database_ZV90C.webp 400w,/_astro/autogpt_drop_vector_database_Z1Pd4qT.webp 800w" sizes="(max-width: 800px) 100vw, 800px"/><source type="image/png" srcset="/_astro/autogpt_drop_vector_database_Z2d1RN1.png 200w,/_astro/autogpt_drop_vector_database_Z1jhM1l.png 400w,/_astro/autogpt_drop_vector_database_1VCqmj.png 800w" sizes="(max-width: 800px) 100vw, 800px"/>
	<img alt="AGI no longer needs vector databases" fit="cover" position="center" src="http://psykomal.com/_astro/autogpt_drop_vector_database_1VCqmj.png" loading="eager" decoding="sync"/>
</picture>
      <h3 id="autogpt-is-not-using-vector-databases-anymore">AutoGPT is not using vector databases anymore üôÖ¬†</h3>
<p>This might come off as a surprise to some. From the very beginning vector databases were supposed to help manage the long-term memory of AI agents.</p>
<p>What happened with the original idea? What has changed?</p>
<h2 id="autogpts-vision">AutoGPT‚Äôs vision</h2>
<p>AutoGPT‚Äôs release on March 30th marked a peak of ChatGPT hype.</p>
<p>Instead of prompting the model over and over again, an autonomous agent could work on its own, planning tasks, dividing them into smaller ones and executing the full idea.</p>
<p>Plans were ambitious. Proponents presented a complex architecture based on LLMs as the reasoning engine, separate part focused on planning, task management &amp; prioritization. The idea included a way to manage agent‚Äôs memories in the form of embeddings and a vector database to store those and retrieve when needed.</p>
<p>Hence, it seemed at the time that vector databases were considered to be an important part of the whole solution. Other AGI projects were adopting the same approach too, e.g. BabyAGI<sup><a href="https://twitter.com/yoheinakajima/status/1642881722495954945">[1]</a></sup>.</p>
<p>Going to AutoGPT‚Äôs documentation<sup><a href="https://docs.agpt.co/configuration/memory/">[2]</a></sup> now, we might encounter a very surprising warning message:</p>
<p><img src="http://psykomal.com/images/4/warning_autogpt_dropping_vector_dbs.png" alt="Warning message at AutoGPT&#39;s documentation"/></p>
<p>It turns out AutoGPT recently went through ‚Äúvector memory revamp‚Äù <a href="https://github.com/Significant-Gravitas/AutoGPT/pull/4208/files#diff-e9ba84f91ce54f8268bc0081e46bb0d769758f1af5e43bf1ddc33f8d0d526602R199">(pull request)</a> that removed all vector db implementations and left out only a couple of classes responsible for memory management, with a JSON file becoming the default way to store memories/embeddings.</p>
<h2 id="an-overkill-solution">An Overkill Solution</h2>
<p>Jina.AI founder, Han Xiao, once criticized original AutoGPT‚Äôs choice in his article
<a href="https://jina.ai/news/auto-gpt-unmasked-hype-hard-truths-production-pitfalls/">‚ÄúAuto-GPT Unmasked: The Hype and Hard Truths of Its Production Pitfalls‚Äù<sup>[3]</sup></a>, calling vector databases ‚Äù<em>an overkill solution</em>‚Äú.</p>
<p>The observation is actually very simple:</p>
<p>Now that you have 100k embeddings even using the simplest brute-force algorithm, Numpy‚Äôs dot query, takes maybe seconds - the optimization is totally not worth it!</p>
<p>And it‚Äôs actually what we see in AutoGPT project right now: embeddings are compared using <code>np.dot</code>:</p>
<p><img src="http://psykomal.com/images/4/autogpt_numpy_dot_product.png" alt="AutoGPT&#39;s use of Numpy&#39;s dot product"/></p>
<p>There‚Äôs an ongoing discussion<sup><a href="https://github.com/Significant-Gravitas/AutoGPT/discussions/4280">[4]</a></sup> about bringing vector databases back and the authors mention that it‚Äôs not their priority at the moment, especially that they don‚Äôt see any added value.</p>
<p><img src="http://psykomal.com/images/4/autogpt_vector_search_speed.png" alt="LLM is AutoGPT&#39;s bottleneck, not vector search"/></p>
<h3 id="overengineering">Overengineering</h3>
<p>We, engineers, naturally react to hype. We get obsessed with the idea of learning something new and building complex, all-powerful solutions. No surprise, AutoGPT included vector db at the very beginning. But as the time goes by, good engineers focus on what‚Äôs really important. Hype is over, now that some value needs to be delivered to the actual users, <strong>complexity becomes our enemy</strong>.</p>
<h2 id="multi-agent-collaboration">Multi-agent collaboration</h2>
<p>There is another big shift happening right now towards having multiple agents, highly specialized, task-oriented, with their own memories and responsibilities, cooperating together.</p>
<p>As it turns out, a one-size-fits-all-tasks approach - having a single omniscient agent doing all the work - is not performing well enough.</p>
<p>Task-oriented agent can be given the examples of a certain task and via in-context learning it will naturally perform better. It will also limit the length of the prompt - it‚Äôs been recently proven LLM has a tendency to ignore stuff in the middle of the prompt<sup><a href="https://arxiv.org/abs/2307.03172">[5]</a></sup>.</p>
<h3 id="example-workflow">Example workflow</h3>
<p>An example of the multi-agent approach might be <a href="https://github.com/Pythagora-io/gpt-pilot">GPT Pilot</a>. It aims at creating multiple agents corresponding to known roles across software development companies: product owner, developer, DevOps, architect etc. Here are the steps GPT Pilot takes to create an app:</p>
<p><img src="http://psykomal.com/images/4/gpt_pilot_workflow.jpg" alt="GPT Pilot Workflow"/></p>
<p>GPT Pilot also doesn‚Äôt use any vector databases. Coding tools often use different tools to get the relevant context instead, for example GitHub Copilot‚Äôs algorithm ‚Äúlooks‚Äù at the code from the recently used files or open tabs.</p>
<p>Looking at the problem a bit differently, these are the 2 options available for AutoGPT-like projects:</p>
<ol>
<li>a general-purpose agent with its thoughts being replaced for every different task</li>
<li>highly specialized agents with their own short log of memories, specific for a given task</li>
</ol>
<p>The second option seems to be more likely to have a higher accuracy at a given task than the generalist agent. The prompt with its identity can also have more precise description of how he should approach the problem.</p>
<h2 id="search-agent">Search agent</h2>
<p>Autonomous agents have the capability to use various tools that we equip them with. They can use Google to find some relevant information on the web, they can use calculator or even write and execute code to solve a specific task.</p>
<p>Instead of fetching relevant memories, why don‚Äôt just use a normal search to find important stuff, previous notes? The search can be an abstraction, be either keyword search, vector or hybrid search - it doesn‚Äôt really matter. The important difference is that the agent can query it over and over again in different ways, until it finds whatever is needed or concludes the information is not there.</p>
<h2 id="tldr">TL;DR</h2>
<ol>
<li>AutoGPT‚Äôs decision to drop vector databases is a move in the right direction, to <strong>focus on delivering value</strong> instead of thinking about technology.</li>
<li>Coding agents such as <a href="https://github.com/AntonOsika/gpt-engineer">GPT Engineer</a>, <a href="https://github.com/Pythagora-io/gpt-pilot">GPT Pilot</a>, or even GitHub Copilot<sup><a href="https://github.blog/2023-05-17-how-github-copilot-is-getting-better-at-understanding-your-code/">[6]</a></sup>, don‚Äôt use vector databases - instead they find relevant context by files recency, proximity in the file system, or looking for references of a given class or function.</li>
<li><a href="https://github.com/yoheinakajima/babyagi">BabyAGI</a>‚Äôs assumptions to store memories in vector dbs remained unchanged, but it seems like there aren‚Äôt many updates there and the original author decided to keep the algorithm simple as an example/foundation for other projects.</li>
<li>Complexity is the worst enemy of a developer.</li>
</ol>
<h3 id="whats-to-come">What‚Äôs to come</h3>
<p>Will vector databases ever be brought back to AutoGPT?</p>
<p>Are vector databases actually an important part of AI revolution? Or will Pinecone‚Äôs vision to become a long-term memory for AI always be remembered as just an empty slogan?</p>
<p>Some argue the real issue is projects like AutoGPT don‚Äôt deliver any true value, and we‚Äôre still years away from such an idea becoming feasible.</p>
<p>Once again, seems like time will tell.</p>
<hr/>
<p>Sources:</p>
    </div></div>
  </body>
</html>
