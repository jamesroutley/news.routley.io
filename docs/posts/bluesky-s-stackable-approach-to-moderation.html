<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://bsky.social/about/blog/03-12-2024-stackable-moderation">Original</a>
    <h1>Bluesky&#39;s stackable approach to moderation</h1>
    
    <div id="readability-page-1" class="page"><div><div><section><header><section><a href="https://bsky.social/about/blog">Blog</a><svg width="8" height="12" viewBox="0 0 8 12" fill="none" xmlns="http://www.w3.org/2000/svg"><path d="M2 10L6 6L2 2" stroke="#667999" stroke-width="2" stroke-linecap="square"></path></svg><span>Bluesky’s Stackable Approach to Moderation</span></section><section><div><p>March 12, 2024</p><p><span>by <!-- -->The Bluesky Team</span></p></div></section></header><section><div><p>Bluesky was created to put <a href="https://bsky.social/about/blog/02-22-2024-open-social-web">users and communities in control</a> of their social spaces online. The first generation of social media platforms connected the world, but ended up consolidating power in the hands of a few corporations and their leaders. Our online experience doesn’t have to depend on billionaires unilaterally making decisions over what we see. On an open social network like Bluesky, you can shape your experience for yourself.</p>
<p><strong>Today, we’re excited to announce that we’re <a href="https://github.com/bluesky-social/ozone-ui">open-sourcing Ozone</a>, our collaborative moderation tool. With Ozone, individuals and teams can work together to review and label content across the network. Later this week, we’re opening up the ability for you to run your own independent moderation services, seamlessly integrated into the Bluesky app.</strong> This means that you&#39;ll be able to create and subscribe to additional moderation services on top of what Bluesky requires, giving you unprecedented control over your social media experience.</p>
<p>At Bluesky, we’re investing in safety from two angles. First, we&#39;ve built our own moderation team dedicated to providing around-the-clock coverage to uphold our <a href="https://bsky.social/about/support/community-guidelines">community guidelines</a>. Additionally, we recognize that there is no one-size-fits-all approach to moderation — no single company can get online safety right for every country, culture, and community in the world. So we’ve also been building something bigger — an ecosystem of moderation and open-source safety tools that gives communities power to create their own spaces, with their own norms and preferences. Still, using Bluesky feels familiar and intuitive. It&#39;s a straightforward app on the surface, but under the hood, we have enabled real innovation and competition in social media by building a new kind of open network.</p>
<p>In designing these moderation services, <strong>Bluesky operated by three principles</strong>:</p>
<ul>
<li><strong>Simple and Powerful:</strong> Give users a pleasant default experience, with customization options under the hood</li>
<li><strong>User Choice:</strong> Empower users and communities to develop their own moderation systems</li>
<li><strong>Openness:</strong> Create an open system that increases trust in the governance of our digital spaces</li>
</ul>
<p>We first shared our vision for <a href="https://bsky.social/about/blog/4-13-2023-moderation">composable moderation</a> before Bluesky even had 20,000 users last year. Now, we serve over 5 million users. In this blog post, we’ll dive into how moderation works on the network, where you can choose and customize all the pieces that make up your social media experience.</p>
<h2>Sensible Defaults with User Choice</h2>
<p>In everything we build, we aim to provide a polished user experience with further customization options for those you who want them. When you sign up for Bluesky, you will be subscribed to Bluesky’s built-in moderation service by default. This is similar to how custom feeds work on Bluesky — we’ll show you a couple feeds by default, but you can also create and subscribe to more. Bluesky’s moderation service combines around-the-clock coverage by our team to resolve user reports according to our <a href="https://bsky.social/about/support/community-guidelines">community guidelines</a> with several automated moderation systems. This provides a strong foundation for moderation on the app. You can read our <a href="https://bsky.social/about/blog/01-16-2024-moderation-2023">2023 Moderation Report</a> for more details.</p>
<p>Bluesky’s vision for moderation is a stackable ecosystem of services. Starting this week, you&#39;ll have the power to install filters from independent moderation services, layering them like building blocks on top of the Bluesky app&#39;s foundation. This allows you to create a customized experience tailored to your preferences (see example below).</p>
<figure>
  <img src="https://bsky.social/about/images/blogposts/mod-image-1.jpg" alt="An example moderation service that users can subscribe to." width="600"/>
  <figcaption>An example moderation service that users can subscribe to.</figcaption>
</figure>
<p>In the first stage of this week’s rollout, these independent moderation services filters will be available on the desktop version of the app. Soon, they’ll also be available on mobile, so you can shape your social media experience across all platforms.</p>
<p>This hybrid approach is intended to provide a cohesive experience, where our in-house moderation works in conjunction with additional layers customized to each community. The Bluesky app, as an online space that we created and maintain, will always have the foundation of the moderation we provide. Independent moderation services will let you and community builders further customize your own spaces, and open APIs will let developers evolve and innovate on these systems.</p>
<figure>
  <img src="https://bsky.social/about/images/blogposts/mod-image-2.jpg" alt="Configurable options per label from an example moderation service. " width="600"/>
  <figcaption>Configurable options per label from an example moderation service. </figcaption>
</figure>
<figure>
  <img src="https://bsky.social/about/images/blogposts/mod-image-3.png" alt="Example of a post that the moderation service The Chiller has labeled as “rude.”" width="600"/>
  <figcaption>Example of a post that the moderation service The Chiller has labeled as “rude.”</figcaption>
</figure>
<p>One team will never be perfect at moderation and curation for the entire world, with its wide variety of contexts, cultures, and preferences. So we’re excited about opening the ecosystem to empower experts, developers, and users with local context to provide their own input that you can additionally subscribe to, on top of Bluesky’s moderation service.</p>
<p>Later this week, we will publish a technical explainer for moderation across the AT Protocol. (This blog post will be updated with a link at that time.)</p>
<h2>How will this all work?</h2>
<p>Here’s what users, moderators, and developers can expect to see this week:</p>
<h3>From a user perspective:</h3>
<p>First and foremost, we want Bluesky to be a great and intuitive experience as soon as you install the app. But if you want to customize your experience, you can easily browse and select from other independent moderation services and subscribe to them in the Bluesky app — as easily as you’d follow another account.</p>
<p>For example, someone could make a moderation service that blocks photos of spiders from Bluesky — let’s call it the Spider Shield. If you get a jump scare from seeing spiders in your otherwise peaceful nature feed, you could install this moderation service and immediately any labeled spider pictures would disappear from your experience.</p>
<p>Moderation services can also accept reports, so if you came across an unlabeled picture of a spider, you could report it to the Spider Shield for review.</p>
<h3>From a moderator perspective:</h3>
<p>If you want to offer a moderation layer on top of what the Bluesky app provides, you can do this without running a lot of infrastructure or building your own client app. We’ve built open source software to simplify the process of running a moderation service. While you need some technical know-how for now, we expect this process to get simpler over time.</p>
<figure>
  <img src="https://bsky.social/about/images/blogposts/mod_2023_ozone_ui.png" alt="Screenshot of the Ozone interface, which a team can use to inspect and label content on the network." width="600"/>
  <figcaption>Screenshot of the Ozone interface, which a team can use to inspect and label content on the network.</figcaption>
</figure>
<p>Today, you can already run a mute list or block list that other users can subscribe to. But it often gets tied to your account in a way that makes it hard to delegate responsibility to others. Once you’re running a popular blocklist, that list becomes associated with your account, and users may start directly tagging you in the app. This can get overwhelming at scale.</p>
<p>Ozone, the open source moderation labeling system we’re releasing today, lets you set up a service like a blocklist, but more nuanced — instead of just adding accounts, you can label specific posts too. You will have access to a reporting queue, and users will be able to send reports via the in-app reporting flow. You will be able to set custom labels, and specify what those labels should do. Moderation services will not be tied to individual users, and multiple people can manage them. Tooling designed for teams and communities can help take the burden off individuals and make it possible to run a sustainable moderation service.</p>
<p>To make this more concrete, let’s say you’re the creator of the previously mentioned Spider Shield labeler that labels photos of spiders. You can set up an Ozone dashboard that provides a queue of spider pictures that have been reported, reducing the need for people to tag you directly every time they find a new spider picture online. It’s customizable — you could create one kind of label that blocks pictures of real spiders, and one kind of label that blurs out illustrations of spiders. You could recruit others who don’t like spiders to help you manage the reports, and even hand the project off to someone else altogether without disrupting the people who are using it.</p>
<h3>From a developer perspective:</h3>
<p>As a developer, you&#39;ve got options when it comes to labeling content. You can use our software, like Ozone, or you can apply labels directly through the API. Ozone is built to help humans review moderation reports, but you can also use automated labeling to power your moderation services. Check out Ozone&#39;s open-source repo <a href="https://github.com/bluesky-social/ozone-ui">here</a>.</p>
<p>If you want to set up Spider Shield as a fully automated service that uses machine learning to find and label spider pictures, you can do that without even touching Ozone, our moderation tool. And if you want to customize Ozone for your own purposes, you can <a href="https://github.com/bluesky-social/ozone-ui">submit a PR</a> or fork the project. Our goal in building this open source moderation tooling is to help apps in the AT Protocol ecosystem handle trust &amp; safety challenges without having to start from scratch.</p>
<p>The generic, customizable nature of labels allows you to get creative with them — it would be possible to use labels to “verify” nature accounts that don’t post pictures of spiders, for example. Although the initial functionality of labelers is intended to hide, block, or blur content, it could eventually be used for curation or verification too. We think that the atproto developer ecosystem will find even more ways to use labels and independent moderation services, and will drive innovation in how moderation works on social networks.</p>
<p>Moderation services can work across the entire atproto network, not just the Bluesky app. Imagine if someone creates a new photo-sharing app called Skygram. The Spider Shield moderation service built for Bluesky could easily be used on Skygram too. That&#39;s the power of &#34;composable moderation&#34; — all the pieces can be mixed and matched in tons of different ways, even across completely separate apps.</p>
<p>We think it&#39;s important for Bluesky to lay the groundwork for a great experience in the app, which is why our moderation service is the default for all Bluesky app users. But we also believe in giving users the freedom to choose and the right to leave. So if Bluesky&#39;s moderation doesn’t meet your needs and you want an altogether different experience, you can make that happen. You&#39;ll need to build or use a different client app with your own moderation service, but this option gives you full flexibility to implement your own moderation system from the ground up. However, all content shown in the Bluesky app must adhere to Bluesky’s community guidelines.</p>
<h2>FAQ</h2>
<p><strong><em>Where can I find the open-sourced Ozone tool?</em></strong></p>
<p>You can find the GitHub repository
<a href="https://github.com/bluesky-social/ozone-ui">here</a>.</p>
<p><strong><em>Why are you open-sourcing Ozone?</em></strong></p>
<p>By making Ozone open-source and providing it as a ready-to-use tool for independent moderators on the AT Protocol, we&#39;re creating a system that encourages collaboration and transparency. Unlike most social media companies that develop their safety tools in private, Ozone&#39;s development will be out in the open. This means that new social apps built on the AT Protocol can benefit from all the improvements made by Bluesky and other organizations. By working together and sharing knowledge, we can create better tools faster and build a social media ecosystem that works for everyone.</p>
<p><strong><em>How is this different from community moderation on Mastodon?</em></strong></p>
<p>Moderation on Bluesky is not tied to your server, like it is on Mastodon. Defederation, a way of addressing moderation issues in Mastodon by disconnecting servers, is not as relevant on Bluesky because there are other layers to the system. Server operators can set rules for what content they will host, but tools like blocklists and moderation services are what help communities self-organize around moderation preferences. Our <a href="https://bsky.social/about/blog/02-22-2024-open-social-web">post on federation</a> goes into more detail on how Bluesky differs from Mastodon.</p>
<p><strong><em>What do I need to do to moderate my own community on Bluesky?</em></strong></p>
<p>All users of Bluesky’s client app are subscribed by default to Bluesky’s moderation. If you would like to run a moderation service that layers on top of these defaults, you can create a new account for that new service and get it up and running with Ozone.</p>
<p>However, if you want to opt out of our defaults, this is still possible — we believe it’s important to give users the right to leave and not lock you in. You would need to use or develop a separate client app that connects to the AT Protocol, but this option gives you full flexibility to implement your own moderation system from the ground up.</p>
<p><strong><em>How will running a moderation service be sustainable?</em></strong></p>
<p>Moderation services, much like feed generators, will likely start off as community-run projects. Just like the 40,000+ custom feeds on Bluesky, or the many Mastodon instances that exist, they may continue to operate as independent projects of individuals or organizations. However, there is also nothing stopping a moderation service from having paid subscribers.</p></div></section></section></div></div></div>
  </body>
</html>
