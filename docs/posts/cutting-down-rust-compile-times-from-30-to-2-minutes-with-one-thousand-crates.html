<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.feldera.com/blog/cutting-down-rust-compile-times-from-30-to-2-minutes-with-one-thousand-crates">Original</a>
    <h1>Cutting down Rust compile times from 30 to 2 minutes with one thousand crates</h1>
    
    <div id="readability-page-1" class="page"><div><div><div><p id="6377682eae43">Rust is fast at runtime — but not so much at compile time. That’s hardly news to anyone who&#39;s worked on a serious Rust codebase. There&#39;s a whole genre of blog posts dedicated to shaving seconds off <code>cargo build</code>.</p><p id="02396083fc04">At Feldera, we let users write SQL to define tables and views. Under the hood, we compile that SQL into Rust code — which is then compiled with <code>rustc</code> to a single binary that <em>incrementally</em> maintains all views as new data streams into tables.</p><p id="e41db72a2add">We’ve already pulled a lot of tricks in the past to speed up compilation: type erasure, aggressive code deduplication, limiting codegen lines. And that got us quite far. However, recently we started on-boarding a new, large enterprise client with fairly complicated SQL. They wrote many, very large programs with Feldera. For example, one of them was 8562 lines of SQL code that eventually is translated to ~100k lines of Rust code by the Feldera SQL-to-Rust compiler.</p><p id="bdcd93336be9">To be clear, this isn’t some massive monolith we’re compiling. We’re talking about ~100k lines of generated Rust. That’s peanuts compared to something like the Linux kernel — 40 million lines (which manages to compile in a few minutes).</p><p id="c7db6351896a">And yet… this one program was taking around 25 minutes to compile on my machine. Worse, on our customer&#39;s setup it took about 45 minutes. And this was after we already switched the code that is generated to <a href="https://github.com/feldera/feldera/pull/1516">using dynamic dispatch and pretty much eliminated all monomorphization</a>.</p><p id="62ab9a17db22">Here&#39;s the log from the Feldera manager:</p><div><div><pre><code><span>[manager] SQL compilation success: pipeline 0196268e-7f98-7de3-b728-0ee339e449fa (program version: 2) (took 101.94s)
</span><span>[manager] Rust compilation success: pipeline 0196268e-7f98-7de3-b728-0ee339e449fa (program version: 2) (took 1617.77s; </span><span>source</span><span> checksum: cbffcb959174; integrity checksum: 709a17251475)</span></code></pre></div></div><p id="9d36881229c1">Almost all the time is spent compiling Rust. The SQL-to-Rust translation takes about 1m40s. Even worse, the Rust build is doing the equivalent of a <code>release</code> build in <code>cargo</code>, so it happens from scratch every time (except for cargo crate dependencies which are already cached/re-used in the times we give here). Even the tiniest change in the input SQL kicks off a full rebuild of that giant program.</p><p id="b07f172716e7">Of course, we tried debug builds too. Those cut the time down to ~5 minutes — but they’re not usable in practice. Our customers care about actual runtime performance: when the SQL code type-checks, they already know the Rust code will compile successfully and they&#39;re running real-time data pipelines and want to see end-to-end latency and throughput. Debug builds are just too slow and misleading for that.</p><h3 id="9b2e079a5221">What&#39;s happening?</h3><p id="b2b0e71fd4cf">Here’s the frustrating part.</p><p id="be3154016cc8">We&#39;re using <code>rustc</code> v1.83, and despite having a 64-core machine with 128 threads, Rust barely puts any of them to work. This becomes evident quickly when looking at <code>htop</code> during the compliation:</p><p><img alt="An idle machine as seen in htop" loading="lazy" width="2178" height="278" decoding="async" data-nimg="1" srcset="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fnlte859i%2Fproduction%2F4ad1b4f49c929971aefe2dbcea6ea2be94b0c5cf-2178x278.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75 1x" src="https://blog.cyang.page/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fnlte859i%2Fproduction%2F4ad1b4f49c929971aefe2dbcea6ea2be94b0c5cf-2178x278.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75"/></p><p id="f9a1e3025e9d">That’s right. One core at 100%, and the rest are asleep.</p><p id="5f83f3387dc6">We can instrument the compilation of this crate by passing <code>-Ztime-passes</code> to <code>RUSTFLAGS</code></p><div><div><pre><code><span>time:   0.346; rss:   38MB -&gt;  342MB ( +304MB)	parse_crate
</span>time:   0.000; rss:  344MB -&gt;  345MB (   +1MB)	crate_injection
<!-- -->time:   5.286; rss:  345MB -&gt; 1607MB (+1262MB)	expand_crate
<!-- -->time:   5.287; rss:  345MB -&gt; 1607MB (+1262MB)	macro_expand_crate
<!-- -->time:   0.091; rss: 1607MB -&gt; 1607MB (   +0MB)	AST_validation
<!-- -->time:   0.002; rss: 1607MB -&gt; 1608MB (   +1MB)	finalize_imports
<!-- -->time:   0.029; rss: 1608MB -&gt; 1608MB (   +0MB) finalize_macro_resolutions
<!-- -->time:   2.382; rss: 1608MB -&gt; 1937MB ( +329MB)	late_resolve_crate
<!-- -->time:   0.071; rss: 1937MB -&gt; 1938MB (   +1MB)	resolve_check_unused
<!-- -->time:   0.138; rss: 1938MB -&gt; 1938MB (   +0MB)	resolve_postprocess
<!-- -->time:   2.627; rss: 1607MB -&gt; 1938MB ( +331MB)	resolve_crate
<!-- -->time:   0.069; rss: 1940MB -&gt; 1940MB (   +0MB)	write_dep_info
<!-- -->time:   0.070; rss: 1940MB -&gt; 1940MB (   +0MB)	complete_gated_feature_checking
<!-- -->time:   0.217; rss: 2790MB -&gt; 2651MB ( -139MB)	drop_ast
<!-- -->time:   3.361; rss: 1940MB -&gt; 2353MB ( +414MB)	looking_for_entry_point
<!-- -->time:   3.961; rss: 1940MB -&gt; 2346MB ( +407MB)	misc_checking_1
<!-- -->time:   6.301; rss: 2346MB -&gt; 2007MB ( -339MB)	coherence_checking
<!-- -->time:  44.158; rss: 2346MB -&gt; 3061MB ( +714MB)	type_check_crate
<!-- -->time:  18.773; rss: 3061MB -&gt; 5024MB (+1963MB)	MIR_borrow_checking
<!-- -->time:   4.650; rss: 5024MB -&gt; 5241MB ( +217MB)	MIR_effect_checking
<!-- -->time:   0.360; rss: 5243MB -&gt; 5255MB (  +12MB)	module_lints
<!-- -->time:   0.360; rss: 5243MB -&gt; 5255MB (  +12MB)	lint_checking
<!-- -->time:   0.947; rss: 5255MB -&gt; 5254MB (   -1MB)	privacy_checking_modules
<!-- -->time:   1.587; rss: 5241MB -&gt; 5254MB (  +13MB)	misc_checking_3
<!-- -->time:   0.259; rss: 5254MB -&gt; 5249MB (   -5MB)	monomorphization_collector_root_collections
<!-- -->time:  54.766; rss: 5249MB -&gt; 7998MB (+2749MB)	monomorphization_collector_graph_walk
<!-- -->time:   6.086; rss: 8010MB -&gt; 8565MB ( +554MB)	partition_and_assert_distinct_symbols
<!-- -->time:   0.000; rss: 8414MB -&gt; 8415MB (   +1MB)	write_allocator_module
<!-- -->time:  35.220; rss: 8415MB -&gt; 18037MB (+9622MB)	codegen_to_LLVM_IR
<!-- -->time:  96.733; rss: 5254MB -&gt; 18037MB (+12783MB)	codegen_crate
<!-- -->time: 1333.423; rss: 10070MB -&gt; 3176MB (-6893MB)	LLVM_passes
<!-- -->time: 1303.074; rss: 13594MB -&gt;  756MB (-12837MB)	finish_ongoing_codegen
<!-- -->time:   1.091; rss:  756MB -&gt;  756MB (   +0MB)	run_linker
<!-- -->time:   0.105; rss:  755MB -&gt;  755MB (   +0MB)	link_binary_remove_temps
<!-- -->time:   1.217; rss:  756MB -&gt;  755MB (   -1MB)	link_binary
<!-- -->time:   1.218; rss:  756MB -&gt;  754MB (   -2MB)	link_crate
<!-- -->time:   1.218; rss:  756MB -&gt;  754MB (   -2MB)	link
<!-- -->time: 1483.483; rss:   26MB -&gt;  514MB ( +487MB)	total</code></pre></div></div><p id="40cfea5410b6">Sometimes during these 30 minutes, Rust will spin up a few threads — maybe 3 or 4 — but it never fully utilizes the machine. Not even close.</p><p><img alt="A mostly idle machine as seen in htop." loading="lazy" width="2186" height="337" decoding="async" data-nimg="1" srcset="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fnlte859i%2Fproduction%2Fe37cfdd37c5d073d1e453aacdd72aa4c6f2e4536-2186x337.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75 1x" src="https://blog.cyang.page/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fnlte859i%2Fproduction%2Fe37cfdd37c5d073d1e453aacdd72aa4c6f2e4536-2186x337.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75"/></p><p id="823efbfa34a8">I get it: parallelizing compilation is hard. But this isn’t some edge-case, looking at it ourselves we clearly saw enough opportunities to parallelize compilation in this program.</p><p id="59edc3947df1">Note aside: You might wonder what about increasing <code>codegen-units</code> in <code>Cargo.toml</code>? Wouldn&#39;t that speed up these passes? In our experience, it didn&#39;t matter: It was set to the default of <code>16</code> for reported times, but we also tried values like <code>256</code> with the default LTO configuration (thin local LTO). That was somewhat confusing (as a non <code>rustc</code> expert). I&#39;d love to read an explanation for this.</p><h3 id="c18869ee48d8">What can we do about it?</h3><p id="b1674d3c3bad">Instead of emitting one giant crate containing everything, we tweaked our SQL-to-Rust compiler to split the output into many smaller crates. Each one encapsulating just a portion of the logic, neatly depending on each other, with a single top-level <code>main</code> crate pulling them all in.</p><p id="83530a42de5d">The results were spectacular. Here&#39;s the same htop view after the change during compilation:</p><p><img alt="A very busy machine as seen in htop." loading="lazy" width="1988" height="597" decoding="async" data-nimg="1" srcset="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fnlte859i%2Fproduction%2F7da03925c3bf8686fba0131ee9eeda72a5ed474f-1988x597.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=2048&amp;q=75 1x, /_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fnlte859i%2Fproduction%2F7da03925c3bf8686fba0131ee9eeda72a5ed474f-1988x597.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75 2x" src="https://blog.cyang.page/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fnlte859i%2Fproduction%2F7da03925c3bf8686fba0131ee9eeda72a5ed474f-1988x597.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75"/></p><p id="ced6546b5936">Beautiful. All the CPUs are now fully utilized all the time.</p><div><div><pre><code><span>[manager] Rust compilation success: pipeline 01962739-79fd-7f03-bbf2-f8e29ce21e1d (program version: 2) (took 150.24s; </span><span>source</span><span> checksum: 0336f3eb9dc1; integrity checksum: 6051bcde6674)</span></code></pre></div></div><h3 id="c96c60914a6b">How did we fix it?</h3><p id="e0b8dc7a2d0a">In most Rust projects, splitting logic across dozens (or hundreds) of crates is impractical at best, a nightmare at worst. But in our case, it was surprisingly straightforward — thanks to how Feldera works under the hood.</p><p id="27c962ee9c29">When a user writes SQL in Feldera, we translate it into a dataflow graph: nodes are operators that transform data, and edges represent how data flows between them. Here&#39;s a small fragment of such a graph:</p><p><img alt="A feldera dataflow graph." loading="lazy" width="2340" height="1054" decoding="async" data-nimg="1" srcset="/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fnlte859i%2Fproduction%2F4f4b876178bc8de1d7ecc52e6ae87388bef5f87c-2340x1054.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75 1x" src="https://blog.cyang.page/_next/image?url=https%3A%2F%2Fcdn.sanity.io%2Fimages%2Fnlte859i%2Fproduction%2F4f4b876178bc8de1d7ecc52e6ae87388bef5f87c-2340x1054.png%3Fq%3D75%26fit%3Dclip%26auto%3Dformat&amp;w=3840&amp;q=75"/></p><p id="73d2c85fd7b0">Since the Rust code is entirely auto-generated from this structure, we had total control over how to split it up.</p><p id="00b41bb3ad0e">Each operator becomes its own crate. Each crate exports a single function that builds one specific piece of the dataflow. They all follow the same predictable shape. The top-level main crate just wires them together.</p><div><div><pre><code><span>pub</span><span> </span><span>fn</span><span> </span><span>create_operator_0097dd9de75ffef3</span><span>(circuit: &amp;RootCircuit,catalog: &amp;</span><span>mut</span><span> Catalog,
</span><span>    i0: &amp;Stream&lt;RootCircuit, IndexedWSet&lt;Tup1&lt;</span><span>i32</span><span>&gt;, Tup5&lt;</span><span>i32</span><span>, SqlString, F64, F64, </span><span>Option</span><span>&lt;</span><span>i32</span><span>&gt;&gt;&gt;&gt;,
</span><span>    i1: &amp;Stream&lt;RootCircuit, IndexedWSet&lt;Tup1&lt;</span><span>i32</span><span>&gt;, Tup0&gt;&gt;,
</span><span>) -&gt; Stream&lt;RootCircuit, WSet&lt;Tup5&lt;</span><span>i32</span><span>, SqlString, F64, F64, </span><span>Option</span><span>&lt;</span><span>i32</span><span>&gt;&gt;&gt;&gt;{
</span><span>    </span><span>let</span><span> operator_0097dd9de75ffef3: Stream&lt;RootCircuit, WSet&lt;Tup5&lt;</span><span>i32</span><span>, SqlString, F64, F64, </span><span>Option</span><span>&lt;</span><span>i32</span><span>&gt;&gt;&gt;&gt; = i0.join(&amp;i1, </span><span>move</span><span> |p0: &amp;Tup1&lt;</span><span>i32</span><span>&gt;, p1: &amp;Tup5&lt;</span><span>i32</span><span>, SqlString, F64, F64, </span><span>Option</span><span>&lt;</span><span>i32</span><span>&gt;&gt;, p2: &amp;Tup0, | -&gt;
</span><span>    Tup5&lt;</span><span>i32</span><span>, SqlString, F64, F64, </span><span>Option</span><span>&lt;</span><span>i32</span><span>&gt;&gt; {
</span>        Tup5::new(
<span>            (*p1).</span><span>0</span><span>,
</span><span>            (*p1).</span><span>1</span><span>.clone(),
</span><span>            (*p1).</span><span>2</span><span>,
</span><span>            (*p1).</span><span>3</span><span>,
</span><span>            (*p1).</span><span>4</span><span>.as_ref().cloned())
</span>    });
<!-- -->
<span>    </span><span>return</span><span> operator_0097dd9de75ffef3;
</span>}</code></pre></div></div><p id="4a48effaca5c">We still need to figure out how to name these crates. A simple but powerful method is to hash the rust code they contain and use that as the name of the crate.</p><p id="518c33abc16f">This ensures two things:</p><p id="701eb3b4f117">a. We have unique crate names.</p><p id="5c98a73fdfee">Imagine the user tweaks the SQL code just slightly. What happens is that most of the operators (and their crates) stay identical (the hash doesn&#39;t change), and <code>rustc</code> can re-use most of the previously compiled artifacts. Any new code that gets added due to the change will end up generating a new crate (with a different hash).</p><p id="f345bdad021c">So how many crates are we talking about for that monster SQL program?</p><p id="63cc77228713">Let’s peek into the compiler directory inside the feldera container:</p><div><div><pre><code><span>ubuntu@12e1de52de1b:~/.feldera/compiler/rust-compilation$ ls crates/
</span>feldera_pipe_operator_000cb1599cb60b91  feldera_pipe_operator_4aab3e223e4ddcf9  feldera_pipe_operator_8d1f38d0358deacf  feldera_pipe_operator_d8058d2f87a41ca0
<!-- -->feldera_pipe_operator_004093943841ab45  feldera_pipe_operator_4ae3aa1446d98a19  feldera_pipe_operator_8d30ed71269c765f  feldera_pipe_operator_d841ffa208faa462
<!-- -->feldera_pipe_operator_004675554aea30aa  feldera_pipe_operator_4aff1d1e8d2a6a9a  feldera_pipe_operator_8e25b73d54f6491e  feldera_pipe_operator_d88bab492aa0c8f5
<!-- -->feldera_pipe_operator_008ba4153ded3848  feldera_pipe_operator_4b3575ba2e10dad3  feldera_pipe_operator_8e667e68984170e5  feldera_pipe_operator_d8a43a536535a38d
<!-- -->feldera_pipe_operator_00bee114a0d5eb4c  feldera_pipe_operator_4b5370144b5268ae  feldera_pipe_operator_8eb1e7460e7376f9  feldera_pipe_operator_d8c6422350e6e8fe
<!-- -->feldera_pipe_operator_00d71fa11f791e35  feldera_pipe_operator_4b5d1c560b048f22  feldera_pipe_operator_8edfa111c7ed57b6  feldera_pipe_operator_d968b48784b4f7af
<!-- -->...</code></pre></div></div><p id="486287d5ca1b">And then:</p><div><div><pre><code><span>ubuntu@12e1de52de1b:~/.feldera/compiler/rust-compilation$ ls crates/ | wc -l
</span>1106</code></pre></div></div><p id="2a83bc06cf7c">That’s right — 1,106 crates!</p><p id="40bb695dd76f">Sounds excessive? Maybe. But in the end this is what makes <code>rustc</code> much more effective.</p><h3 id="2bbef1c62ee3">Are we done?</h3><p id="109df12cafcb">Unfortunately, not quite. There are still some mysteries here. Given that we now fully utilize 128 threads or 64 cores for pretty much the entire compile time, we can do a back of the envelope calculation for how long it should take: <code>25 min / 128 = 12 sec</code> (or maybe <code>24 sec</code> since hyper-threads aren&#39;t real cores). Yet it takes <code>170s</code> to compile everything. Of course, we can&#39;t expect linear speed-up in practice, but still <code>7x</code> slower than that seems excessive (these are all just parallel <code>rustc</code> invocation that run independently). Similar slowdowns also happen on laptop grade machines with much less memory and cores, so it doesn&#39;t just affect very large machines.</p><p id="4fe949abbce6">Here are some thoughts on what <em>might</em> be happening, but we&#39;d be happy to hear some more opinions on this:</p><ul><li>Contention on hardware resources (the system has more than enough memory but it might contend on caches)</li><li>The file-system is a bottleneck (doubt it since we also tried running this on a RAM-FS and it didn&#39;t make a difference, but it could be contending on locks in the file-system code in the kernel)</li><li>Compiling each of the 1k crates now performs some steps many times that get amortized when using a single crate (true, but the slowdown doesn&#39;t happen if we compile with <code>-j1</code>, the individual crate compile times are much faster as long as they happen in sequence)</li><li>Linking is the bottleneck now since we added 1k crates? We use <code>mold</code> and we see the total link time is only around <code>7 sec</code>.</li></ul><h3 id="9a8832de1ebc">Conclusion</h3><p id="9c07947dc521">By simply changing how we generate Rust code under the hood, we’ve made Feldera’s compile times scale with your hardware instead of fighting it. What used to take 30–45 minutes now compiles in under 3 minutes, even for complex enterprise-scale SQL.</p><p id="30222fc0034b">If you’re already pushing Feldera to its limits: thank you. Your workloads help us make the system better for everyone.</p></div></div></div></div>
  </body>
</html>
