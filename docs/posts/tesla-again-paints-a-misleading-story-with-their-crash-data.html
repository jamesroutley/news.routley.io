<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.forbes.com/sites/bradtempleton/2023/04/26/tesla-again-paints-a-very-misleading-story-with-their-crash-data/">Original</a>
    <h1>Tesla Again Paints a Misleading Story with Their Crash Data</h1>
    
    <div id="readability-page-1" class="page"><div><figure role="presentation"><figcaption><fbs-accordion><p>Tesla Impact Report section on crash rates.   It is extremely misleading</p></fbs-accordion><small>Tesla</small></figcaption></figure>
<p>Every quarter, Tesla releases crash data on their cars in various modes. Recently it also released its annual “<a href="https://www.tesla.com/ns_videos/2022-tesla-impact-report.pdf" target="_blank" title="https://www.tesla.com/ns_videos/2022-tesla-impact-report.pdf" rel="nofollow noopener noreferrer" data-ga-track="ExternalLink:https://www.tesla.com/ns_videos/2022-tesla-impact-report.pdf" aria-label="impact report">impact report</a>,” which for the first time included some data on drivers using their prototype “full self driving” system, which has been pre-purchased by several hundred thousand owners. Much of the coverage of the report has described it as presenting an incredibly positive story of Tesla safety. Their raw numbers do seem very good, but the reality is disturbingly different.</p>




<ol>
 <li>0.18 <strong>Airbag deployments</strong> per million miles with Autopilot engaged (almost entirely on freeways)</li>
 <li>0.31 <strong>Airbag deployments</strong> per million non-highway miles with FSD prototype engaged</li>
 <li>0.68 <strong>Airbag deployments</strong> per million general miles in those few Teslas which disable the active safety systems such as collision warning and avoidance.</li>
 <li>1.53 <strong>Police reported crashes</strong> per million miles for all cars, both with and without airbags deployment, as reported by NHTSA.</li>
</ol>


<p>I have <a href="https://www.forbes.com/sites/bradtempleton/2020/10/28/new-tesla-autopilot-statistics-show-its-almost-as-safe-driving-with-it-as-without/" target="_self" title="https://www.forbes.com/sites/bradtempleton/2020/10/28/new-tesla-autopilot-statistics-show-its-almost-as-safe-driving-with-it-as-without/" data-ga-track="InternalLink:https://www.forbes.com/sites/bradtempleton/2020/10/28/new-tesla-autopilot-statistics-show-its-almost-as-safe-driving-with-it-as-without/" aria-label="done analysis of these reports before,">done analysis of these reports before,</a> generally concluding that what they actually show is that <strong>users of Autopilot have a roughly similar number of crashes to those not using it</strong>. The Impact report did not cite a number for non-Autopilot use with ADAS active safety, but the <a href="https://www.tesla.com/VehicleSafetyReport" target="_blank" title="https://www.tesla.com/VehicleSafetyReport" rel="nofollow noopener noreferrer" data-ga-track="ExternalLink:https://www.tesla.com/VehicleSafetyReport" aria-label="quarterly safety report">quarterly safety report</a> for Q4/2022 reported about 0.71 airbag events per million miles, a bit worse than the annual summary.</p>


<p>Tesla’s number give a very incorrect impression — so incorrect that it is baffling why they publish them when this has been pointed out many times by many writers and researchers. Oddly, Tesla has the real data — they have the best data in the world about what happens to their vehicles. The fact that they could publish the truth but decline to, and instead publish numbers which get widely misinterpreted raises the question of why they are not revealing the truth, and what it is that they don’t want to reveal.</p><fbs-ad position="inread" progressive="" ad-id="article-0-inread" aria-hidden="true" role="presentation"></fbs-ad>
<p>Most of the reports are not written as summarized above, noting that Tesla counts a “crash” as an airbag deployment. (The most recent report expands that definition to include use of other active restraint systems, such as the seatbelt tightener, but does not seem to affect the numbers much, so it may have always been their definition.) They state that this definition should catch most crashes over 12mph. The rest of the world, including NHTSA, tend to consider a crash as one that is reported — either to police, or to insurance. No good data exists on the exact fraction of crashes seen by police or insurance which involve airbags or these other restraints. The <a href="https://www.sae.org/standardsdev/tsb/cooperative/airbag.htm" target="_blank" title="https://www.sae.org/standardsdev/tsb/cooperative/airbag.htm" rel="nofollow noopener noreferrer" data-ga-track="ExternalLink:https://www.sae.org/standardsdev/tsb/cooperative/airbag.htm" aria-label="SAE reported">SAE reported</a> an estimate of about 210,000 airbag deployments per year or around 14 million miles per deployment. That would suggest Teslas are having these crashes much more often than average, which probably isn’t true, but suggests to us that only a small fraction of the 6 million crashes reported to police involve the airbag, and so putting the two rates on the same chart is inappropriate.</p>

<p>As such, many have read these numbers as Tesla suggested by putting them on a chart together: That the Teslas are driving as much as 8 times more safely than typical cars. The reality is far below that.</p>

<h3>Controlling for biasing factors</h3>
<p>It gets even worse when you consider what Tesla finally acknowledged in this report but never spoke of before — Autopilot is used on freeways, and FSD is only used on city streets. If a driver has FSD, it will only operate on city streets, and it switches to Autopilot on the freeway. If the driver does not have FSD, they can use Autopilot on non-freeways but studies of real drivers found that well over 90% of use was on highways.</p>


<p>The problem is that highways have a much lower rate of crashes than city streets. Exact data on crashes is not available but the fatality rate is about 1/3rd as high on highways, in spite of the faster speed. This is because the rate is per mile, and you do more miles in an hour on the highway, but mistakes happen per unit of time. It’s also because driving on the highway is easier and simpler — even if the mistakes are more serious. As such, data that suggested that Autopilot driving had a lower crash rate per mile than regular driving were again misleading. Any system used mainly on the highway <em>had better have</em> a much better safety record per mile. If it doesn’t, it’s a poor system. <a href="https://www.forbes.com/sites/bradtempleton/2020/10/28/new-tesla-autopilot-statistics-show-its-almost-as-safe-driving-with-it-as-without/" target="_self" title="https://www.forbes.com/sites/bradtempleton/2020/10/28/new-tesla-autopilot-statistics-show-its-almost-as-safe-driving-with-it-as-without/" data-ga-track="InternalLink:https://www.forbes.com/sites/bradtempleton/2020/10/28/new-tesla-autopilot-statistics-show-its-almost-as-safe-driving-with-it-as-without/" aria-label="My earlier article">My earlier article</a> did the calculation to find that Autopilot produced roughly similar accident rates to not using it. Which is good, but a claim that it makes people safer is not justified.</p>
<p>Tesla knows exactly what type of road each crash happens on. They could even compare driving by people on the very same stretch of road or class of roads, but they don’t.</p><figure role="presentation"><figcaption><fbs-accordion current="-1"><p>This photo provided by the Laguna Beach Police Department shows a Tesla sedan, left, in autopilot <span data-ga-track="caption expand">... [+]</span><span> mode that crashed into a parked police cruiser Tuesday, May 29, 2018, in Laguna Beach, Calif.    NHTSA is investigating autopilot crashes with emergency vehicles</span></p></fbs-accordion><small>ASSOCIATED PRESS</small></figcaption></figure>
<p>Anybody who works in statistics is taught right from the start that it is crucial when gathering statistics to “control” for factors which might bias your result. If you know that highways are safer, you should never publish a comparison where one number comes from the highway and another number from off it, and pretend they could be compared. Instead, you attempt to make sure you are comparing apples to apples. Tesla’s people are not fools, they surely know this very basic rule of statistical math, but seem to be ignoring it. In fact, others have pointed out other factors not accounted for. Teslas are expensive cars and are bought primarily by older, wealthier people. Middle-aged wealthy people are in fact the safest class of drivers. Any study of them, compared to the general population, would show the car driven by the safer drivers with a lower crash rate — but it’s not the car, it’s the drivers.</p>
<p>It’s also true that drivers are more likely to engage Autopilot in easy driving conditions — clear roads with no construction and nice weather. In fact, Tesla encourages this. The system even refuses to operate in some weather conditions. As such, the Autopilot data is coming from the easiest driving and the non-Autopilot from the most complex. Once again, apples to jackfruit.</p>
<p>Again, Tesla knows who is driving — even in cars shared with multiple people. It could control for all these factors and produce real, useful statistics, but does not. Tesla has access to data that other researchers only dream of having. It is hoped they will use it.</p>
<p>It is not clear that Tesla’s statement that “Safety is enhanced when Autopilot is engaged” in this document is justified by the numbers. It does show a superior record for Autopilot compared to cars with ADAS disabled, and a modest improvement over non-Autopilot driving, but not a great one.</p>
<p>Again, Tesla could publish a true apples to apples comparison. They could compare millions of miles on identical freeways with similar drivers in identical conditions. They could control for all of this. That they don’t has to make us wonder if they are afraid of what the real comparison would say. They’ve been doing this for too long.</p>
<h3>FSD vs. Other</h3>
<p>This report was the first to provide data on use of Tesla FSD. Here, we can somewhat compare, if not apples to apples, at least tree fruit to tree fruit. FSD’s airbag rate is 70% higher than Autopilot’s. We would expect it to be worse than that on city streets, indicating that FSD drivers are doing better than Autopilot drivers.</p>
<p>The likely explanation for this is that FSD is a very immature product. It is called a “beta(*)” but is not even close to the alpha level in ordinary software development parlance. Tesla FSD is lucky to complete one or two drives without needing an intervention, often one to prevent a crash. A real self-driving robocar needs to be able to do about 10,000 drives in a row without needing such an intervention, so Tesla’s system has a an astonishingly long way to go before being able to live up to its name.</p>
<p>But that’s a good thing. People who use it pay careful attention to it. If you don’t, you will soon crash. Because of this, the humans are doing a good job, and having few crashes. With Autopilot, it is better at its task, and so more drivers are facing “automation complacency” and not being fully diligent in supervising it. As a result, they may be having a modestly higher number of crashes. The tough question concerns what happens when FSD gets better — when it gets so good that drivers feel more comfortable ignoring it for periods of time. Its actual crash rate might well get worse the better it gets. That’s a difficult paradox — we want to develop such products, and we don’t want to have to stop when they get too good. We want Tesla to keep going and make a real true actually full self-driving product if they can. The answer, many feel, is better driver monitoring that stops drivers from getting complacent. This is an area of research. Tesla Autopilot began with very simple monitoring — are the hands applying force to the wheel — but they recently added cameras, which most other companies also use.</p>
<p>Tesla — time to accept this gauntlet. Provide real data, comparing the same thing in the same situation. Make the only difference be whether Autopilot and FSD were on or not. It’s possible your cars are improving safety. I hope they are — I own and drive one — but if they are, show us.</p>
<p>(*) In software development, “alpha” and “<a href="https://www.productplan.com/glossary/beta-test/" target="_blank" title="https://www.productplan.com/glossary/beta-test/" rel="nofollow noopener noreferrer" data-ga-track="ExternalLink:https://www.productplan.com/glossary/beta-test/" aria-label="beta">beta</a>” test versions are produced just before final release, for use in testing by internal testers in alpha mode, and select customers in beta level. They are not ready for production use, but are close to that, and no significant new features or changes are planned. Tesla isn’t the only company to recently misuse the traditional beta concept, of course.</p>
</div></div>
  </body>
</html>
