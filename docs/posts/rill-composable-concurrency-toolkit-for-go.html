<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/destel/rill">Original</a>
    <h1>Show HN: Rill â€“ Composable concurrency toolkit for Go</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto">Rill is a toolkit that brings composable concurrency to Go, making it easier to build concurrent programs from simple, reusable parts.
It reduces boilerplate while preserving Go&#39;s natural channel-based model.</p>
<div dir="auto" data-snippet-clipboard-copy-content="go get -u github.com/destel/rill"><pre>go get -u github.com/destel/rill</pre></div>

<ul dir="auto">
<li>
<p dir="auto"><strong>Make common tasks easier.</strong></p>
</li>
<li>
<p dir="auto"><strong>Make concurrent code composable and clean.</strong></p>
</li>
<li>
<p dir="auto"><strong>Centralize error handling.</strong></p>
</li>
<li>
<p dir="auto"><strong>Simplify stream processing.</strong></p>
</li>
<li>
<p dir="auto"><strong>Provide solutions for advanced tasks.</strong></p>
</li>
<li>
<p dir="auto"><strong>Support custom extensions.</strong></p>
</li>
<li>
<p dir="auto"><strong>Keep it lightweight.</strong></p>
</li>
</ul>

<p dir="auto">Let&#39;s look at a practical example: fetch users from an API, activate them, and save the changes back.
It shows how to control concurrency at each step while keeping the code clean and manageable.</p>
<p dir="auto"><a href="https://pkg.go.dev/github.com/destel/rill#example-package" rel="nofollow">Try it</a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func main() {
	ctx := context.Background()

	// Convert a slice of user IDs into a channel
	ids := rill.FromSlice([]int{1, 2, 3, 4, 5, 6, 7, 8, 9, 10}, nil)

	// Read users from the API.
	// Concurrency = 3
	users := rill.Map(ids, 3, func(id int) (*mockapi.User, error) {
		return mockapi.GetUser(ctx, id)
	})

	// Activate users.
	// Concurrency = 2
	err := rill.ForEach(users, 2, func(u *mockapi.User) error {
		if u.IsActive {
			fmt.Printf(&#34;User %d is already active\n&#34;, u.ID)
			return nil
		}

		u.IsActive = true
		err := mockapi.SaveUser(ctx, u)
		if err != nil {
			return err
		}

		fmt.Printf(&#34;User saved: %+v\n&#34;, u)
		return nil
	})

	// Handle errors
	fmt.Println(&#34;Error:&#34;, err)
}"><pre><span>func</span> <span>main</span>() {
	<span>ctx</span> <span>:=</span> <span>context</span>.<span>Background</span>()

	<span>// Convert a slice of user IDs into a channel</span>
	<span>ids</span> <span>:=</span> <span>rill</span>.<span>FromSlice</span>([]<span>int</span>{<span>1</span>, <span>2</span>, <span>3</span>, <span>4</span>, <span>5</span>, <span>6</span>, <span>7</span>, <span>8</span>, <span>9</span>, <span>10</span>}, <span>nil</span>)

	<span>// Read users from the API.</span>
	<span>// Concurrency = 3</span>
	<span>users</span> <span>:=</span> <span>rill</span>.<span>Map</span>(<span>ids</span>, <span>3</span>, <span>func</span>(<span>id</span> <span>int</span>) (<span>*</span>mockapi.<span>User</span>, <span>error</span>) {
		<span>return</span> <span>mockapi</span>.<span>GetUser</span>(<span>ctx</span>, <span>id</span>)
	})

	<span>// Activate users.</span>
	<span>// Concurrency = 2</span>
	<span>err</span> <span>:=</span> <span>rill</span>.<span>ForEach</span>(<span>users</span>, <span>2</span>, <span>func</span>(<span>u</span> <span>*</span>mockapi.<span>User</span>) <span>error</span> {
		<span>if</span> <span>u</span>.<span>IsActive</span> {
			<span>fmt</span>.<span>Printf</span>(<span>&#34;User %d is already active<span>\n</span>&#34;</span>, <span>u</span>.<span>ID</span>)
			<span>return</span> <span>nil</span>
		}

		<span>u</span>.<span>IsActive</span> <span>=</span> <span>true</span>
		<span>err</span> <span>:=</span> <span>mockapi</span>.<span>SaveUser</span>(<span>ctx</span>, <span>u</span>)
		<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
			<span>return</span> <span>err</span>
		}

		<span>fmt</span>.<span>Printf</span>(<span>&#34;User saved: %+v<span>\n</span>&#34;</span>, <span>u</span>)
		<span>return</span> <span>nil</span>
	})

	<span>// Handle errors</span>
	<span>fmt</span>.<span>Println</span>(<span>&#34;Error:&#34;</span>, <span>err</span>)
}</pre></div>

<p dir="auto">Processing items in batches rather than individually can significantly improve performance in many scenarios,
particularly when working with external services or databases. Batching reduces the number of queries and API calls,
increases throughput, and typically lowers costs.</p>
<p dir="auto">To demonstrate batching, let&#39;s improve the previous example by using the API&#39;s bulk fetching capability.
The <strong>Batch</strong> function transforms a stream of individual IDs into a stream of slices. This enables the use of <code>GetUsers</code> API
to fetch multiple users in a single call, instead of making individual <code>GetUser</code> calls.</p>
<p dir="auto"><a href="https://pkg.go.dev/github.com/destel/rill#example-package-Batching" rel="nofollow">Try it</a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func main() {
	ctx := context.Background()

	// Convert a slice of user IDs into a channel
	ids := rill.FromSlice([]int{
		1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20,
		21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40,
	}, nil)

	// Group IDs into batches of 5
	idBatches := rill.Batch(ids, 5, -1)

	// Bulk fetch users from the API
	// Concurrency = 3
	userBatches := rill.Map(idBatches, 3, func(ids []int) ([]*mockapi.User, error) {
		return mockapi.GetUsers(ctx, ids)
	})

	// Transform the stream of batches back into a flat stream of users
	users := rill.Unbatch(userBatches)

	// Activate users.
	// Concurrency = 2
	err := rill.ForEach(users, 2, func(u *mockapi.User) error {
		if u.IsActive {
			fmt.Printf(&#34;User %d is already active\n&#34;, u.ID)
			return nil
		}

		u.IsActive = true
		err := mockapi.SaveUser(ctx, u)
		if err != nil {
			return err
		}

		fmt.Printf(&#34;User saved: %+v\n&#34;, u)
		return nil
	})

	// Handle errors
	fmt.Println(&#34;Error:&#34;, err)
}"><pre><span>func</span> <span>main</span>() {
	<span>ctx</span> <span>:=</span> <span>context</span>.<span>Background</span>()

	<span>// Convert a slice of user IDs into a channel</span>
	<span>ids</span> <span>:=</span> <span>rill</span>.<span>FromSlice</span>([]<span>int</span>{
		<span>1</span>, <span>2</span>, <span>3</span>, <span>4</span>, <span>5</span>, <span>6</span>, <span>7</span>, <span>8</span>, <span>9</span>, <span>10</span>, <span>11</span>, <span>12</span>, <span>13</span>, <span>14</span>, <span>15</span>, <span>16</span>, <span>17</span>, <span>18</span>, <span>19</span>, <span>20</span>,
		<span>21</span>, <span>22</span>, <span>23</span>, <span>24</span>, <span>25</span>, <span>26</span>, <span>27</span>, <span>28</span>, <span>29</span>, <span>30</span>, <span>31</span>, <span>32</span>, <span>33</span>, <span>34</span>, <span>35</span>, <span>36</span>, <span>37</span>, <span>38</span>, <span>39</span>, <span>40</span>,
	}, <span>nil</span>)

	<span>// Group IDs into batches of 5</span>
	<span>idBatches</span> <span>:=</span> <span>rill</span>.<span>Batch</span>(<span>ids</span>, <span>5</span>, <span>-</span><span>1</span>)

	<span>// Bulk fetch users from the API</span>
	<span>// Concurrency = 3</span>
	<span>userBatches</span> <span>:=</span> <span>rill</span>.<span>Map</span>(<span>idBatches</span>, <span>3</span>, <span>func</span>(<span>ids</span> []<span>int</span>) ([]<span>*</span>mockapi.<span>User</span>, <span>error</span>) {
		<span>return</span> <span>mockapi</span>.<span>GetUsers</span>(<span>ctx</span>, <span>ids</span>)
	})

	<span>// Transform the stream of batches back into a flat stream of users</span>
	<span>users</span> <span>:=</span> <span>rill</span>.<span>Unbatch</span>(<span>userBatches</span>)

	<span>// Activate users.</span>
	<span>// Concurrency = 2</span>
	<span>err</span> <span>:=</span> <span>rill</span>.<span>ForEach</span>(<span>users</span>, <span>2</span>, <span>func</span>(<span>u</span> <span>*</span>mockapi.<span>User</span>) <span>error</span> {
		<span>if</span> <span>u</span>.<span>IsActive</span> {
			<span>fmt</span>.<span>Printf</span>(<span>&#34;User %d is already active<span>\n</span>&#34;</span>, <span>u</span>.<span>ID</span>)
			<span>return</span> <span>nil</span>
		}

		<span>u</span>.<span>IsActive</span> <span>=</span> <span>true</span>
		<span>err</span> <span>:=</span> <span>mockapi</span>.<span>SaveUser</span>(<span>ctx</span>, <span>u</span>)
		<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
			<span>return</span> <span>err</span>
		}

		<span>fmt</span>.<span>Printf</span>(<span>&#34;User saved: %+v<span>\n</span>&#34;</span>, <span>u</span>)
		<span>return</span> <span>nil</span>
	})

	<span>// Handle errors</span>
	<span>fmt</span>.<span>Println</span>(<span>&#34;Error:&#34;</span>, <span>err</span>)
}</pre></div>

<p dir="auto">Real-world applications often need to handle events or data that arrives at unpredictable rates. While batching is still
desirable for efficiency, waiting to collect a full batch might introduce unacceptable delays when
the input stream becomes slow or sparse.</p>
<p dir="auto">Rill solves this with timeout-based batching: batches are emitted either when they&#39;re full or after a specified timeout,
whichever comes first. This approach ensures optimal batch sizes during high load while maintaining responsiveness during quiet periods.</p>
<p dir="auto">Consider an application that needs to update users&#39; <em>last_active_at</em> timestamps in a database. The function responsible
for this - <code>UpdateUserTimestamp</code> can be called concurrently, at unpredictable rates, and from different parts of the application.
Performing all these updates individually may create too many concurrent queries, potentially overwhelming the database.</p>
<p dir="auto">In the example below, the updates are queued into <code>userIDsToUpdate</code> channel and then grouped into batches of up to 5 items,
with each batch sent to the database as a single query.
The <strong>Batch</strong> function is used with a timeout of 100ms, ensuring zero latency during high load,
and up to 100ms latency with smaller batches during quiet periods.</p>
<p dir="auto"><a href="https://pkg.go.dev/github.com/destel/rill#example-package-BatchingRealTime" rel="nofollow">Try it</a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func main() {
	// Start the background worker that processes the updates
	go updateUserTimestampWorker()

	// Do some updates. They&#39;ll be automatically grouped into
	// batches: [1,2,3,4,5], [6,7], [8]
	UpdateUserTimestamp(1)
	UpdateUserTimestamp(2)
	UpdateUserTimestamp(3)
	UpdateUserTimestamp(4)
	UpdateUserTimestamp(5)
	UpdateUserTimestamp(6)
	UpdateUserTimestamp(7)
	time.Sleep(500 * time.Millisecond) // simulate sparse updates
	UpdateUserTimestamp(8)
}

// This is the queue of user IDs to update.
var userIDsToUpdate = make(chan int)

// UpdateUserTimestamp is the public API for updating the last_active_at column in the users table
func UpdateUserTimestamp(userID int) {
	userIDsToUpdate &lt;- userID
}

// This is a background worker that sends queued updates to the database in batches.
// For simplicity, there are no retries, error handling and synchronization
func updateUserTimestampWorker() {

	ids := rill.FromChan(userIDsToUpdate, nil)

	idBatches := rill.Batch(ids, 5, 100*time.Millisecond)

	_ = rill.ForEach(idBatches, 1, func(batch []int) error {
		fmt.Printf(&#34;Executed: UPDATE users SET last_active_at = NOW() WHERE id IN (%v)\n&#34;, batch)
		return nil
	})
}"><pre><span>func</span> <span>main</span>() {
	<span>// Start the background worker that processes the updates</span>
	<span>go</span> <span>updateUserTimestampWorker</span>()

	<span>// Do some updates. They&#39;ll be automatically grouped into</span>
	<span>// batches: [1,2,3,4,5], [6,7], [8]</span>
	<span>UpdateUserTimestamp</span>(<span>1</span>)
	<span>UpdateUserTimestamp</span>(<span>2</span>)
	<span>UpdateUserTimestamp</span>(<span>3</span>)
	<span>UpdateUserTimestamp</span>(<span>4</span>)
	<span>UpdateUserTimestamp</span>(<span>5</span>)
	<span>UpdateUserTimestamp</span>(<span>6</span>)
	<span>UpdateUserTimestamp</span>(<span>7</span>)
	<span>time</span>.<span>Sleep</span>(<span>500</span> <span>*</span> <span>time</span>.<span>Millisecond</span>) <span>// simulate sparse updates</span>
	<span>UpdateUserTimestamp</span>(<span>8</span>)
}

<span>// This is the queue of user IDs to update.</span>
<span>var</span> <span>userIDsToUpdate</span> <span>=</span> <span>make</span>(<span>chan</span> <span>int</span>)

<span>// UpdateUserTimestamp is the public API for updating the last_active_at column in the users table</span>
<span>func</span> <span>UpdateUserTimestamp</span>(<span>userID</span> <span>int</span>) {
	<span>userIDsToUpdate</span> <span>&lt;-</span> <span>userID</span>
}

<span>// This is a background worker that sends queued updates to the database in batches.</span>
<span>// For simplicity, there are no retries, error handling and synchronization</span>
<span>func</span> <span>updateUserTimestampWorker</span>() {

	<span>ids</span> <span>:=</span> <span>rill</span>.<span>FromChan</span>(<span>userIDsToUpdate</span>, <span>nil</span>)

	<span>idBatches</span> <span>:=</span> <span>rill</span>.<span>Batch</span>(<span>ids</span>, <span>5</span>, <span>100</span><span>*</span><span>time</span>.<span>Millisecond</span>)

	<span>_</span> <span>=</span> <span>rill</span>.<span>ForEach</span>(<span>idBatches</span>, <span>1</span>, <span>func</span>(<span>batch</span> []<span>int</span>) <span>error</span> {
		<span>fmt</span>.<span>Printf</span>(<span>&#34;Executed: UPDATE users SET last_active_at = NOW() WHERE id IN (%v)<span>\n</span>&#34;</span>, <span>batch</span>)
		<span>return</span> <span>nil</span>
	})
}</pre></div>
<div dir="auto"><h2 tabindex="-1" dir="auto">Errors, Termination and Contexts</h2><a id="user-content-errors-termination-and-contexts" aria-label="Permalink: Errors, Termination and Contexts" href="#errors-termination-and-contexts"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Error handling can be non-trivial in concurrent applications. Rill simplifies this by providing a structured approach to the problem.
Pipelines typically consist of a sequence of non-blocking channel transformations, followed by a blocking stage that returns a final result and an error.
The general rule is: any error occurring anywhere in a pipeline is propagated down to the final stage,
where it&#39;s caught by some blocking function and returned to the caller.</p>
<p dir="auto">Rill provides a wide selection of blocking functions. Here are some commonly used ones:</p>
<ul dir="auto">
<li><strong>ForEach:</strong> Concurrently applies a user function to each item in the stream.
<a href="https://pkg.go.dev/github.com/destel/rill#example-ForEach" rel="nofollow">Example</a></li>
<li><strong>ToSlice:</strong> Collects all stream items into a slice.
<a href="https://pkg.go.dev/github.com/destel/rill#example-ToSlice" rel="nofollow">Example</a></li>
<li><strong>First:</strong> Returns the first item or error encountered in the stream and discards the rest
<a href="https://pkg.go.dev/github.com/destel/rill#example-First" rel="nofollow">Example</a></li>
<li><strong>Reduce:</strong> Concurrently reduces the stream to a single value, using a user provided reducer function.
<a href="https://pkg.go.dev/github.com/destel/rill#example-Reduce" rel="nofollow">Example</a></li>
<li><strong>All:</strong> Concurrently checks if all items in the stream satisfy a user provided condition.
<a href="https://pkg.go.dev/github.com/destel/rill#example-All" rel="nofollow">Example</a></li>
<li><strong>Err:</strong> Returns the first error encountered in the stream or nil, and discards the rest of the stream.
<a href="https://pkg.go.dev/github.com/destel/rill#example-Err" rel="nofollow">Example</a></li>
</ul>
<p dir="auto">All blocking functions share a common behavior. In case of an early termination (before reaching the end of the input stream or in case of an error),
such functions initiate background draining of the remaining items. This is done to prevent goroutine leaks by ensuring that
all goroutines feeding the stream are allowed to complete.</p>
<p dir="auto">Rill is context-agnostic, meaning that it does not enforce any specific context usage.
However, it&#39;s recommended to make user-defined pipeline stages context-aware.
This is especially important for the initial stage, as it allows to stop feeding the pipeline with new items after the context cancellation.
In practice the first stage is often naturally context-aware through Go&#39;s standard APIs for databases, HTTP clients, and other external sources.</p>
<p dir="auto">In the example below the <code>CheckAllUsersExist</code> function uses several concurrent workers to check if all users</p>
<p dir="auto"><a href="https://pkg.go.dev/github.com/destel/rill#example-package-Context" rel="nofollow">Try it</a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func main() {
	ctx := context.Background()

	// ID 999 doesn&#39;t exist, so fetching will stop after hitting it.
	err := CheckAllUsersExist(ctx, 3, []int{1, 2, 3, 4, 5, 999, 7, 8, 9, 10, 11, 12, 13, 14, 15})
	fmt.Printf(&#34;Check result: %v\n&#34;, err)
}

// CheckAllUsersExist uses several concurrent workers to check if all users with given IDs exist.
func CheckAllUsersExist(ctx context.Context, concurrency int, ids []int) error {
	// Create new context that will be canceled when this function returns
	ctx, cancel := context.WithCancel(ctx)
	defer cancel()

	// Convert the slice into a stream
	idsStream := rill.FromSlice(ids, nil)

	// Fetch users concurrently.
	users := rill.Map(idsStream, concurrency, func(id int) (*mockapi.User, error) {
		u, err := mockapi.GetUser(ctx, id)
		if err != nil {
			return nil, fmt.Errorf(&#34;failed to fetch user %d: %w&#34;, id, err)
		}

		fmt.Printf(&#34;Fetched user %d\n&#34;, id)
		return u, nil
	})

	// Return the first error (if any) and cancel remaining fetches via context
	return rill.Err(users)
}"><pre><span>func</span> <span>main</span>() {
	<span>ctx</span> <span>:=</span> <span>context</span>.<span>Background</span>()

	<span>// ID 999 doesn&#39;t exist, so fetching will stop after hitting it.</span>
	<span>err</span> <span>:=</span> <span>CheckAllUsersExist</span>(<span>ctx</span>, <span>3</span>, []<span>int</span>{<span>1</span>, <span>2</span>, <span>3</span>, <span>4</span>, <span>5</span>, <span>999</span>, <span>7</span>, <span>8</span>, <span>9</span>, <span>10</span>, <span>11</span>, <span>12</span>, <span>13</span>, <span>14</span>, <span>15</span>})
	<span>fmt</span>.<span>Printf</span>(<span>&#34;Check result: %v<span>\n</span>&#34;</span>, <span>err</span>)
}

<span>// CheckAllUsersExist uses several concurrent workers to check if all users with given IDs exist.</span>
<span>func</span> <span>CheckAllUsersExist</span>(<span>ctx</span> context.<span>Context</span>, <span>concurrency</span> <span>int</span>, <span>ids</span> []<span>int</span>) <span>error</span> {
	<span>// Create new context that will be canceled when this function returns</span>
	<span>ctx</span>, <span>cancel</span> <span>:=</span> <span>context</span>.<span>WithCancel</span>(<span>ctx</span>)
	<span>defer</span> <span>cancel</span>()

	<span>// Convert the slice into a stream</span>
	<span>idsStream</span> <span>:=</span> <span>rill</span>.<span>FromSlice</span>(<span>ids</span>, <span>nil</span>)

	<span>// Fetch users concurrently.</span>
	<span>users</span> <span>:=</span> <span>rill</span>.<span>Map</span>(<span>idsStream</span>, <span>concurrency</span>, <span>func</span>(<span>id</span> <span>int</span>) (<span>*</span>mockapi.<span>User</span>, <span>error</span>) {
		<span>u</span>, <span>err</span> <span>:=</span> <span>mockapi</span>.<span>GetUser</span>(<span>ctx</span>, <span>id</span>)
		<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
			<span>return</span> <span>nil</span>, <span>fmt</span>.<span>Errorf</span>(<span>&#34;failed to fetch user %d: %w&#34;</span>, <span>id</span>, <span>err</span>)
		}

		<span>fmt</span>.<span>Printf</span>(<span>&#34;Fetched user %d<span>\n</span>&#34;</span>, <span>id</span>)
		<span>return</span> <span>u</span>, <span>nil</span>
	})

	<span>// Return the first error (if any) and cancel remaining fetches via context</span>
	<span>return</span> <span>rill</span>.<span>Err</span>(<span>users</span>)
}</pre></div>
<p dir="auto">In the example above only the second stage (<code>mockapi.GetUser</code>) of the pipeline is context-aware.
<strong>FromSlice</strong> works well here since the input is small, iteration is fast and context cancellation prevents expensive API calls regardless.
The following code demonstrates how to replace <strong>FromSlice</strong> with <strong>Generate</strong> when full context awareness becomes important.</p>
<div dir="auto" data-snippet-clipboard-copy-content="idsStream := rill.Generate(func(send func(int), sendErr func(error)) {
	for _, id := range ids {
		if ctx.Err() != nil {
			return
		}
		send(id)
	}
})"><pre><span>idsStream</span> <span>:=</span> <span>rill</span>.<span>Generate</span>(<span>func</span>(<span>send</span> <span>func</span>(<span>int</span>), <span>sendErr</span> <span>func</span>(<span>error</span>)) {
	<span>for</span> <span>_</span>, <span>id</span> <span>:=</span> <span>range</span> <span>ids</span> {
		<span>if</span> <span>ctx</span>.<span>Err</span>() <span>!=</span> <span>nil</span> {
			<span>return</span>
		}
		<span>send</span>(<span>id</span>)
	}
})</pre></div>
<div dir="auto"><h2 tabindex="-1" dir="auto">Order Preservation (Ordered Fan-In)</h2><a id="user-content-order-preservation-ordered-fan-in" aria-label="Permalink: Order Preservation (Ordered Fan-In)" href="#order-preservation-ordered-fan-in"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Concurrent processing can boost performance, but since tasks take different amounts of time to complete,
the results&#39; order usually differs from the input order. While out-of-order results are acceptable in many scenarios,
some cases require preserving the original order. This seemingly simple problem is deceptively challenging to solve correctly.</p>
<p dir="auto">To address this, Rill provides ordered versions of its core functions, such as <strong>OrderedMap</strong> or <strong>OrderedFilter</strong>.
These functions perform additional synchronization under the hood to ensure that if value <strong>x</strong> precedes value <strong>y</strong> in the input stream,
then <strong>f(x)</strong> will precede <strong>f(y)</strong> in the output.</p>
<p dir="auto">Here&#39;s a practical example: finding the first occurrence of a specific string among 1000 large files hosted online.
Downloading all files at once would consume too much memory, processing them sequentially would be too slow,
and traditional concurrency patterns do not preserve the order of files, making it challenging to find the first match.</p>
<p dir="auto">The combination of <strong>OrderedFilter</strong> and <strong>First</strong> functions solves this elegantly,
while downloading and keeping in memory at most 5 files at a time.</p>
<p dir="auto"><a href="https://pkg.go.dev/github.com/destel/rill#example-package-Ordering" rel="nofollow">Try it</a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func main() {
	ctx := context.Background()

	// The string to search for in the downloaded files
	needle := []byte(&#34;26&#34;)

	// Generate a stream of URLs from https://example.com/file-0.txt 
	// to https://example.com/file-999.txt
	urls := rill.Generate(func(send func(string), sendErr func(error)) {
		for i := 0; i &lt; 1000 &amp;&amp; ctx.Err() == nil; i++ {
			send(fmt.Sprintf(&#34;https://example.com/file-%d.txt&#34;, i))
		}
	})

	// Download and process the files
	// At most 5 files are downloaded and held in memory at the same time
	matchedUrls := rill.OrderedFilter(urls, 5, func(url string) (bool, error) {
		fmt.Println(&#34;Downloading:&#34;, url)

		content, err := mockapi.DownloadFile(ctx, url)
		if err != nil {
			return false, err
		}

		// keep only URLs of files that contain the needle
		return bytes.Contains(content, needle), nil
	})

	// Find the first matched URL
	firstMatchedUrl, found, err := rill.First(matchedUrls)
	if err != nil {
		fmt.Println(&#34;Error:&#34;, err)
		return
	}

	// Print the result
	if found {
		fmt.Println(&#34;Found in:&#34;, firstMatchedUrl)
	} else {
		fmt.Println(&#34;Not found&#34;)
	}
}"><pre><span>func</span> <span>main</span>() {
	<span>ctx</span> <span>:=</span> <span>context</span>.<span>Background</span>()

	<span>// The string to search for in the downloaded files</span>
	<span>needle</span> <span>:=</span> []<span>byte</span>(<span>&#34;26&#34;</span>)

	<span>// Generate a stream of URLs from https://example.com/file-0.txt </span>
	<span>// to https://example.com/file-999.txt</span>
	<span>urls</span> <span>:=</span> <span>rill</span>.<span>Generate</span>(<span>func</span>(<span>send</span> <span>func</span>(<span>string</span>), <span>sendErr</span> <span>func</span>(<span>error</span>)) {
		<span>for</span> <span>i</span> <span>:=</span> <span>0</span>; <span>i</span> <span>&lt;</span> <span>1000</span> <span>&amp;&amp;</span> <span>ctx</span>.<span>Err</span>() <span>==</span> <span>nil</span>; <span>i</span><span>++</span> {
			<span>send</span>(<span>fmt</span>.<span>Sprintf</span>(<span>&#34;https://example.com/file-%d.txt&#34;</span>, <span>i</span>))
		}
	})

	<span>// Download and process the files</span>
	<span>// At most 5 files are downloaded and held in memory at the same time</span>
	<span>matchedUrls</span> <span>:=</span> <span>rill</span>.<span>OrderedFilter</span>(<span>urls</span>, <span>5</span>, <span>func</span>(<span>url</span> <span>string</span>) (<span>bool</span>, <span>error</span>) {
		<span>fmt</span>.<span>Println</span>(<span>&#34;Downloading:&#34;</span>, <span>url</span>)

		<span>content</span>, <span>err</span> <span>:=</span> <span>mockapi</span>.<span>DownloadFile</span>(<span>ctx</span>, <span>url</span>)
		<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
			<span>return</span> <span>false</span>, <span>err</span>
		}

		<span>// keep only URLs of files that contain the needle</span>
		<span>return</span> <span>bytes</span>.<span>Contains</span>(<span>content</span>, <span>needle</span>), <span>nil</span>
	})

	<span>// Find the first matched URL</span>
	<span>firstMatchedUrl</span>, <span>found</span>, <span>err</span> <span>:=</span> <span>rill</span>.<span>First</span>(<span>matchedUrls</span>)
	<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
		<span>fmt</span>.<span>Println</span>(<span>&#34;Error:&#34;</span>, <span>err</span>)
		<span>return</span>
	}

	<span>// Print the result</span>
	<span>if</span> <span>found</span> {
		<span>fmt</span>.<span>Println</span>(<span>&#34;Found in:&#34;</span>, <span>firstMatchedUrl</span>)
	} <span>else</span> {
		<span>fmt</span>.<span>Println</span>(<span>&#34;Not found&#34;</span>)
	}
}</pre></div>
<div dir="auto"><h2 tabindex="-1" dir="auto">Stream Merging and FlatMap</h2><a id="user-content-stream-merging-and-flatmap" aria-label="Permalink: Stream Merging and FlatMap" href="#stream-merging-and-flatmap"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Rill comes with the <strong>Merge</strong> function that combines multiple streams into a single one. Another, often overlooked,
function that can combine streams is <strong>FlatMap</strong>. It&#39;s a powerful tool that transforms each input item into its own stream,
and then merges all these streams together.</p>
<p dir="auto">In the example below, <strong>FlatMap</strong> transforms each department into a stream of users, then merges these streams into one.
Like other Rill functions, <strong>FlatMap</strong> gives full control over concurrency.
In this particular case the concurrency level is 3, meaning that users are fetched from at most 3 departments at the same time.</p>
<p dir="auto">Additionally, this example demonstrates how to write a reusable streaming wrapper over paginated API calls - the <code>StreamUsers</code> function.
This wrapper can be useful both on its own and as part of larger pipelines.</p>
<p dir="auto"><a href="https://pkg.go.dev/github.com/destel/rill#example-package-FlatMap" rel="nofollow">Try it</a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func main() {
	ctx := context.Background()

	// Start with a stream of department names
	departments := rill.FromSlice([]string{&#34;IT&#34;, &#34;Finance&#34;, &#34;Marketing&#34;, &#34;Support&#34;, &#34;Engineering&#34;}, nil)

	// Stream users from all departments concurrently.
	// At most 3 departments at the same time.
	users := rill.FlatMap(departments, 3, func(department string) &lt;-chan rill.Try[*mockapi.User] {
		return StreamUsers(ctx, &amp;mockapi.UserQuery{Department: department})
	})

	// Print the users from the combined stream
	err := rill.ForEach(users, 1, func(user *mockapi.User) error {
		fmt.Printf(&#34;%+v\n&#34;, user)
		return nil
	})
	fmt.Println(&#34;Error:&#34;, err)
}

// StreamUsers is a reusable streaming wrapper around the mockapi.ListUsers function.
// It iterates through all listing pages and uses [Generate] to simplify sending users and errors to the resulting stream.
// This function is useful both on its own and as part of larger pipelines.
func StreamUsers(ctx context.Context, query *mockapi.UserQuery) &lt;-chan rill.Try[*mockapi.User] {
	return rill.Generate(func(send func(*mockapi.User), sendErr func(error)) {
		var currentQuery mockapi.UserQuery
		if query != nil {
			currentQuery = *query
		}

		for page := 0; ; page++ {
			currentQuery.Page = page

			users, err := mockapi.ListUsers(ctx, &amp;currentQuery)
			if err != nil {
				sendErr(err)
				return
			}

			if len(users) == 0 {
				break
			}

			for _, user := range users {
				send(user)
			}
		}
	})
}"><pre><span>func</span> <span>main</span>() {
	<span>ctx</span> <span>:=</span> <span>context</span>.<span>Background</span>()

	<span>// Start with a stream of department names</span>
	<span>departments</span> <span>:=</span> <span>rill</span>.<span>FromSlice</span>([]<span>string</span>{<span>&#34;IT&#34;</span>, <span>&#34;Finance&#34;</span>, <span>&#34;Marketing&#34;</span>, <span>&#34;Support&#34;</span>, <span>&#34;Engineering&#34;</span>}, <span>nil</span>)

	<span>// Stream users from all departments concurrently.</span>
	<span>// At most 3 departments at the same time.</span>
	<span>users</span> <span>:=</span> <span>rill</span>.<span>FlatMap</span>(<span>departments</span>, <span>3</span>, <span>func</span>(<span>department</span> <span>string</span>) <span>&lt;-</span><span>chan</span> rill.<span>Try</span>[<span>*</span>mockapi.<span>User</span>] {
		<span>return</span> <span>StreamUsers</span>(<span>ctx</span>, <span>&amp;</span>mockapi.<span>UserQuery</span>{<span>Department</span>: <span>department</span>})
	})

	<span>// Print the users from the combined stream</span>
	<span>err</span> <span>:=</span> <span>rill</span>.<span>ForEach</span>(<span>users</span>, <span>1</span>, <span>func</span>(<span>user</span> <span>*</span>mockapi.<span>User</span>) <span>error</span> {
		<span>fmt</span>.<span>Printf</span>(<span>&#34;%+v<span>\n</span>&#34;</span>, <span>user</span>)
		<span>return</span> <span>nil</span>
	})
	<span>fmt</span>.<span>Println</span>(<span>&#34;Error:&#34;</span>, <span>err</span>)
}

<span>// StreamUsers is a reusable streaming wrapper around the mockapi.ListUsers function.</span>
<span>// It iterates through all listing pages and uses [Generate] to simplify sending users and errors to the resulting stream.</span>
<span>// This function is useful both on its own and as part of larger pipelines.</span>
<span>func</span> <span>StreamUsers</span>(<span>ctx</span> context.<span>Context</span>, <span>query</span> <span>*</span>mockapi.<span>UserQuery</span>) <span>&lt;-</span><span>chan</span> rill.<span>Try</span>[<span>*</span>mockapi.<span>User</span>] {
	<span>return</span> <span>rill</span>.<span>Generate</span>(<span>func</span>(<span>send</span> <span>func</span>(<span>*</span>mockapi.<span>User</span>), <span>sendErr</span> <span>func</span>(<span>error</span>)) {
		<span>var</span> <span>currentQuery</span> mockapi.<span>UserQuery</span>
		<span>if</span> <span>query</span> <span>!=</span> <span>nil</span> {
			<span>currentQuery</span> <span>=</span> <span>*</span><span>query</span>
		}

		<span>for</span> <span>page</span> <span>:=</span> <span>0</span>; ; <span>page</span><span>++</span> {
			<span>currentQuery</span>.<span>Page</span> <span>=</span> <span>page</span>

			<span>users</span>, <span>err</span> <span>:=</span> <span>mockapi</span>.<span>ListUsers</span>(<span>ctx</span>, <span>&amp;</span><span>currentQuery</span>)
			<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
				<span>sendErr</span>(<span>err</span>)
				<span>return</span>
			}

			<span>if</span> <span>len</span>(<span>users</span>) <span>==</span> <span>0</span> {
				<span>break</span>
			}

			<span>for</span> <span>_</span>, <span>user</span> <span>:=</span> <span>range</span> <span>users</span> {
				<span>send</span>(<span>user</span>)
			}
		}
	})
}</pre></div>

<p dir="auto">Starting from Go 1.23, the language added <em>range-over-function</em> feature, allowing users to define custom iterators
for use in for-range loops. This feature enables Rill to integrate seamlessly with existing iterator-based functions
in the standard library and third-party packages.</p>
<p dir="auto">Rill provides <strong>FromSeq</strong> and <strong>FromSeq2</strong> functions to convert an iterator into a stream,
and <strong>ToSeq2</strong> function to convert a stream back into an iterator.</p>
<p dir="auto"><strong>ToSeq2</strong> can be a good alternative to <strong>ForEach</strong> when concurrency is not needed.
It gives more control and performs all necessary cleanup and draining, even if the loop is terminated early using <em>break</em> or <em>return</em>.</p>
<p dir="auto"><a href="https://pkg.go.dev/github.com/destel/rill#example-ToSeq2" rel="nofollow">Try it</a></p>
<div dir="auto" data-snippet-clipboard-copy-content="func main() {
	// Convert a slice of numbers into a stream
	numbers := rill.FromSlice([]int{1, 2, 3, 4, 5, 6, 7, 8, 9, 10}, nil)

	// Transform each number
	// Concurrency = 3
	squares := rill.Map(numbers, 3, func(x int) (int, error) {
		return square(x), nil
	})

	// Convert the stream into an iterator and use for-range to print the results
	for val, err := range rill.ToSeq2(squares) {
		if err != nil {
			fmt.Println(&#34;Error:&#34;, err)
			break // cleanup is done regardless of early exit
		}
		fmt.Printf(&#34;%+v\n&#34;, val)
	}
}"><pre><span>func</span> <span>main</span>() {
	<span>// Convert a slice of numbers into a stream</span>
	<span>numbers</span> <span>:=</span> <span>rill</span>.<span>FromSlice</span>([]<span>int</span>{<span>1</span>, <span>2</span>, <span>3</span>, <span>4</span>, <span>5</span>, <span>6</span>, <span>7</span>, <span>8</span>, <span>9</span>, <span>10</span>}, <span>nil</span>)

	<span>// Transform each number</span>
	<span>// Concurrency = 3</span>
	<span>squares</span> <span>:=</span> <span>rill</span>.<span>Map</span>(<span>numbers</span>, <span>3</span>, <span>func</span>(<span>x</span> <span>int</span>) (<span>int</span>, <span>error</span>) {
		<span>return</span> <span>square</span>(<span>x</span>), <span>nil</span>
	})

	<span>// Convert the stream into an iterator and use for-range to print the results</span>
	<span>for</span> <span>val</span>, <span>err</span> <span>:=</span> <span>range</span> <span>rill</span>.<span>ToSeq2</span>(<span>squares</span>) {
		<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
			<span>fmt</span>.<span>Println</span>(<span>&#34;Error:&#34;</span>, <span>err</span>)
			<span>break</span> <span>// cleanup is done regardless of early exit</span>
		}
		<span>fmt</span>.<span>Printf</span>(<span>&#34;%+v<span>\n</span>&#34;</span>, <span>val</span>)
	}
}</pre></div>

<p dir="auto">Rill has a test coverage of over 95%, with testing focused on:</p>
<ul dir="auto">
<li><strong>Correctness</strong>: ensuring that functions produce accurate results at different levels of concurrency</li>
<li><strong>Concurrency</strong>: confirming that correct number of goroutines is spawned and utilized</li>
<li><strong>Ordering</strong>: ensuring that ordered versions of functions preserve the order, while basic versions do not</li>
</ul>

<p dir="auto">Contributions are welcome! Whether it&#39;s reporting a bug, suggesting a feature, or submitting a pull request, your support helps improve Rill.
Please ensure that your code adheres to the existing style and includes relevant tests._</p>
</article></div></div>
  </body>
</html>
