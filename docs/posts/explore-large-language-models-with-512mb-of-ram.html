<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/jncraton/languagemodels">Original</a>
    <h1>Show HN: Explore large language models with 512MB of RAM</h1>
    
    <div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text">
<p dir="auto"><a href="https://badge.fury.io/py/languagemodels" rel="nofollow"><img src="https://camo.githubusercontent.com/3f8f673a6025f9955c9e8482d693dadd6ccc44abe76f12c063f8c70b4e89dd7f/68747470733a2f2f62616467652e667572792e696f2f70792f6c616e67756167656d6f64656c732e737667" alt="PyPI version" data-canonical-src="https://badge.fury.io/py/languagemodels.svg"/></a>
<a href="https://languagemodels.netlify.app/" rel="nofollow"><img src="https://camo.githubusercontent.com/64d670a7f9736196ddae9bf866710443e68aefd022ec42a4441806794de8ad48/68747470733a2f2f696d672e736869656c64732e696f2f62616467652f646f63732d6f6e6c696e652d627269676874677265656e" alt="docs" data-canonical-src="https://img.shields.io/badge/docs-online-brightgreen"/></a>
<a href="https://github.com/jncraton/languagemodels/actions/workflows/build.yml"><img src="https://github.com/jncraton/languagemodels/actions/workflows/build.yml/badge.svg" alt="x64 Build"/></a>
<a href="https://github.com/jncraton/languagemodels/actions/workflows/pi.yml"><img src="https://github.com/jncraton/languagemodels/actions/workflows/pi.yml/badge.svg" alt="ARM64 Build"/></a><a href="https://app.netlify.com/sites/languagemodels/deploys" rel="nofollow"><img src="https://camo.githubusercontent.com/ba26fdeb4b7cc75e1300d0526a99c419f7c77a20e1857974ebca417b1eb30822/68747470733a2f2f6170692e6e65746c6966792e636f6d2f6170692f76312f6261646765732f37323265363235612d633662632d343337332d626438382d6330313761646335386330302f6465706c6f792d737461747573" alt="Netlify Status" data-canonical-src="https://api.netlify.com/api/v1/badges/722e625a-c6bc-4373-bd88-c017adc58c00/deploy-status"/></a>
<a href="https://colab.research.google.com/github/jncraton/languagemodels/blob/master/examples/translate.ipynb" rel="nofollow"><img src="https://camo.githubusercontent.com/84f0493939e0c4de4e6dbe113251b4bfb5353e57134ffd9fcab6b8714514d4d1/68747470733a2f2f636f6c61622e72657365617263682e676f6f676c652e636f6d2f6173736574732f636f6c61622d62616467652e737667" alt="Open In Colab" data-canonical-src="https://colab.research.google.com/assets/colab-badge.svg"/></a></p>
<p dir="auto">Python building blocks to explore large language models on any computer with 512MB of RAM</p>
<p dir="auto"><a href="https://replit.com/@jncraton/langaugemodels#main.py" rel="nofollow"><img src="https://camo.githubusercontent.com/21f3fe0a6ca7d5e44c99396700b342fb159c6f253e29cf1a095598e4db92611e/68747470733a2f2f7265706c69742e636f6d2f62616467653f63617074696f6e3d547279253230776974682532305265706c69742676617269616e743d736d616c6c" alt="Try with Replit Badge" data-canonical-src="https://replit.com/badge?caption=Try%20with%20Replit&amp;variant=small"/></a></p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/jncraton/languagemodels/blob/main/media/hello.gif"><img src="https://github.com/jncraton/languagemodels/raw/main/media/hello.gif" alt="Translation hello world example" data-animated-image=""/></a></p>
<h2 tabindex="-1" dir="auto"><a id="user-content-target-audience" aria-hidden="true" href="#target-audience"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Target Audience</h2>
<p dir="auto">This package is designed to be as simple as possible for <strong>learners</strong> and <strong>educators</strong> exploring how large language models intersect with modern software development. The interfaces to this package are all simple functions using standard types. The complexity of large language models is hidden from view while providing free local inference using light-weight, open models. All included models are free for educational use, no API keys are required, and all inference is performed locally by default.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-installation-and-getting-started" aria-hidden="true" href="#installation-and-getting-started"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Installation and Getting Started</h2>
<p dir="auto">This package can be installed using the following command:</p>
<div dir="auto" data-snippet-clipboard-copy-content="pip install languagemodels"><pre>pip install languagemodels</pre></div>
<p dir="auto">Once installed, you should be able to interact with the package in Python as follows:</p>
<div dir="auto" data-snippet-clipboard-copy-content="&gt;&gt;&gt; import languagemodels as lm
&gt;&gt;&gt; lm.do(&#34;What color is the sky?&#34;)
&#39;The color of the sky is blue.&#39;"><pre><span>&gt;&gt;</span><span>&gt;</span> <span>import</span> <span>languagemodels</span> <span>as</span> <span>lm</span>
<span>&gt;&gt;</span><span>&gt;</span> <span>lm</span>.<span>do</span>(<span>&#34;What color is the sky?&#34;</span>)
<span>&#39;The color of the sky is blue.&#39;</span></pre></div>
<p dir="auto">This will require downloading a significant amount of data (~250MB) on the first run. Models will be cached for later use and subsequent calls should be quick.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-example-usage" aria-hidden="true" href="#example-usage"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Example Usage</h2>
<p dir="auto">Here are some usage examples as Python REPL sessions. This should work in the REPL, notebooks, or in traditional scripts and applications.</p>
<h3 tabindex="-1" dir="auto"><a id="user-content-text-completions" aria-hidden="true" href="#text-completions"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Text Completions</h3>
<div dir="auto" data-snippet-clipboard-copy-content="&gt;&gt;&gt; import languagemodels as lm

&gt;&gt;&gt; lm.complete(&#34;She hid in her room until&#34;)
&#39;she was sure she was safe&#39;"><pre><span>&gt;&gt;</span><span>&gt;</span> <span>import</span> <span>languagemodels</span> <span>as</span> <span>lm</span>

<span>&gt;&gt;</span><span>&gt;</span> <span>lm</span>.<span>complete</span>(<span>&#34;She hid in her room until&#34;</span>)
<span>&#39;she was sure she was safe&#39;</span></pre></div>
<h3 tabindex="-1" dir="auto"><a id="user-content-instruction-following" aria-hidden="true" href="#instruction-following"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Instruction Following</h3>
<div dir="auto" data-snippet-clipboard-copy-content="&gt;&gt;&gt; import languagemodels as lm

&gt;&gt;&gt; lm.do(&#34;Translate to English: Hola, mundo!&#34;)
&#39;Hello, world!&#39;

&gt;&gt;&gt; lm.do(&#34;What is the capital of France?&#34;)
&#39;Paris.&#39;"><pre><span>&gt;&gt;</span><span>&gt;</span> <span>import</span> <span>languagemodels</span> <span>as</span> <span>lm</span>

<span>&gt;&gt;</span><span>&gt;</span> <span>lm</span>.<span>do</span>(<span>&#34;Translate to English: Hola, mundo!&#34;</span>)
<span>&#39;Hello, world!&#39;</span>

<span>&gt;&gt;</span><span>&gt;</span> <span>lm</span>.<span>do</span>(<span>&#34;What is the capital of France?&#34;</span>)
<span>&#39;Paris.&#39;</span></pre></div>
<h3 tabindex="-1" dir="auto"><a id="user-content-chat" aria-hidden="true" href="#chat"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Chat</h3>
<div dir="auto" data-snippet-clipboard-copy-content="&gt;&gt;&gt; chat(&#39;&#39;&#39;
...      System: Respond as a helpful assistant.
...
...      User: What time is it?
...
...      Assistant:
...      &#39;&#39;&#39;)
&#39;I&#39;m sorry, but as an AI language model, I don&#39;t have access to real-time information. Please provide me with the specific time you are asking for so that I can assist you better.&#39;"><pre><span>&gt;&gt;</span><span>&gt;</span> <span>chat</span>(<span>&#39;&#39;&#39;</span>
<span>...      System: Respond as a helpful assistant.</span>
<span>...</span>
<span>...      User: What time is it?</span>
<span>...</span>
<span>...      Assistant:</span>
<span>...      &#39;&#39;&#39;</span>)
<span>&#39;I&#39;</span><span>m</span> <span>sorry</span>, <span>but</span> <span>as</span> <span>an</span> <span>AI</span> <span>language</span> <span>model</span>, <span>I</span> <span>don</span><span>&#39;t have access to real-time information. Please provide me with the specific time you are asking for so that I can assist you better.&#39;</span></pre></div>
<h3 tabindex="-1" dir="auto"><a id="user-content-external-retrieval" aria-hidden="true" href="#external-retrieval"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>External Retrieval</h3>
<p dir="auto">Helper functions are provided to retrieve text from external sources that can be used to augment prompt context.</p>
<div dir="auto" data-snippet-clipboard-copy-content="&gt;&gt;&gt; import languagemodels as lm

&gt;&gt;&gt; lm.get_wiki(&#39;Chemistry&#39;)
&#39;Chemistry is the scientific study...

&gt;&gt;&gt; lm.get_weather(41.8, -87.6)
&#39;Partly cloudy with a chance of rain...

&gt;&gt;&gt; lm.get_date()
&#39;Friday, May 12, 2023 at 09:27AM&#39;"><pre><span>&gt;&gt;</span><span>&gt;</span> <span>import</span> <span>languagemodels</span> <span>as</span> <span>lm</span>

<span>&gt;&gt;</span><span>&gt;</span> <span>lm</span>.<span>get_wiki</span>(<span>&#39;Chemistry&#39;</span>)
&#39;<span>Chemistry</span> <span>is</span> <span>the</span> <span>scientific</span> <span>study</span>...

<span>&gt;&gt;</span><span>&gt;</span> <span>lm</span>.<span>get_weather</span>(<span>41.8</span>, <span>-</span><span>87.6</span>)
&#39;<span>Partly</span> <span>cloudy</span> <span>with</span> <span>a</span> <span>chance</span> <span>of</span> <span>rain</span>...

<span>&gt;&gt;</span><span>&gt;</span> <span>lm</span>.<span>get_date</span>()
&#39;<span>Friday</span>, <span>May</span> <span>12</span>, <span>2023</span> <span>at</span> <span>09</span>:<span>27</span><span>AM</span>&#39;</pre></div>
<p dir="auto">Here&#39;s an example showing how this can be used (compare to previous chat example):</p>
<div dir="auto" data-snippet-clipboard-copy-content="&gt;&gt;&gt; chat(f&#39;&#39;&#39;
...      System: Respond as a helpful assistant. It is {lm.get_date()}
...
...      User: What time is it?
...
...      Assistant:
...      &#39;&#39;&#39;)
&#39;It is currently Wednesday, June 07, 2023 at 12:53PM.&#39;"><pre><span>&gt;&gt;</span><span>&gt;</span> <span>chat</span>(<span>f&#39;&#39;&#39;</span>
<span>...      System: Respond as a helpful assistant. It is <span><span>{</span><span>lm</span>.<span>get_date</span>()<span>}</span></span></span>
<span>...</span>
<span>...      User: What time is it?</span>
<span>...</span>
<span>...      Assistant:</span>
<span>...      &#39;&#39;&#39;</span>)
<span>&#39;It is currently Wednesday, June 07, 2023 at 12:53PM.&#39;</span></pre></div>
<h3 tabindex="-1" dir="auto"><a id="user-content-semantic-search" aria-hidden="true" href="#semantic-search"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Semantic Search</h3>
<p dir="auto">Semantic search is provided to retrieve documents that may provide helpful context from a document store.</p>
<div dir="auto" data-snippet-clipboard-copy-content="&gt;&gt;&gt; import languagemodels as lm

&gt;&gt;&gt; lm.store_doc(&#34;Mars is a planet&#34;)
&gt;&gt;&gt; lm.store_doc(&#34;The sun is hot&#34;)
&gt;&gt;&gt; lm.load_doc(&#34;What is Mars?&#34;)
&#39;Mars is a planet&#39;"><pre><span>&gt;&gt;</span><span>&gt;</span> <span>import</span> <span>languagemodels</span> <span>as</span> <span>lm</span>

<span>&gt;&gt;</span><span>&gt;</span> <span>lm</span>.<span>store_doc</span>(<span>&#34;Mars is a planet&#34;</span>)
<span>&gt;&gt;</span><span>&gt;</span> <span>lm</span>.<span>store_doc</span>(<span>&#34;The sun is hot&#34;</span>)
<span>&gt;&gt;</span><span>&gt;</span> <span>lm</span>.<span>load_doc</span>(<span>&#34;What is Mars?&#34;</span>)
<span>&#39;Mars is a planet&#39;</span></pre></div>
<p dir="auto">This can also be used to get a blend of context from stored documents:</p>
<div dir="auto" data-snippet-clipboard-copy-content="&gt;&gt;&gt; import languagemodels as lm

&gt;&gt;&gt; lm.store_doc(lm.get_wiki(&#34;Python&#34;))
&gt;&gt;&gt; lm.store_doc(lm.get_wiki(&#34;C++&#34;))
&gt;&gt;&gt; lm.store_doc(lm.get_wiki(&#34;Javascript&#34;))
&gt;&gt;&gt; lm.store_doc(lm.get_wiki(&#34;Fortran&#34;))
&gt;&gt;&gt; lm.get_doc_context(&#34;What does it mean for batteries to be included in a language?&#34;)
&#39;multiple programming paradigms, including structured (particularly procedural), object-oriented and functional programming. It is often described as a &#34;batteries included&#34; language due to its comprehensive standard library.Guido van Rossum began working on Python in the late 1980s as a successor to the ABC programming language

C, or c, is the third letter in the Latin alphabet, used in the modern English alphabet, the alphabets of other western European languages and others worldwide. Its name in English is cee (pronounced ), plural cees.

a measure of the popularity of programming languages.&#39;"><pre><span>&gt;&gt;</span><span>&gt;</span> <span>import</span> <span>languagemodels</span> <span>as</span> <span>lm</span>

<span>&gt;&gt;</span><span>&gt;</span> <span>lm</span>.<span>store_doc</span>(<span>lm</span>.<span>get_wiki</span>(<span>&#34;Python&#34;</span>))
<span>&gt;&gt;</span><span>&gt;</span> <span>lm</span>.<span>store_doc</span>(<span>lm</span>.<span>get_wiki</span>(<span>&#34;C++&#34;</span>))
<span>&gt;&gt;</span><span>&gt;</span> <span>lm</span>.<span>store_doc</span>(<span>lm</span>.<span>get_wiki</span>(<span>&#34;Javascript&#34;</span>))
<span>&gt;&gt;</span><span>&gt;</span> <span>lm</span>.<span>store_doc</span>(<span>lm</span>.<span>get_wiki</span>(<span>&#34;Fortran&#34;</span>))
<span>&gt;&gt;</span><span>&gt;</span> <span>lm</span>.<span>get_doc_context</span>(<span>&#34;What does it mean for batteries to be included in a language?&#34;</span>)
&#39;<span>multiple</span> <span>programming</span> <span>paradigms</span>, <span>including</span> <span>structured</span> (<span>particularly</span> <span>procedural</span>), <span>object</span><span>-</span><span>oriented</span> <span>and</span> <span>functional</span> <span>programming</span>. <span>It</span> <span>is</span> <span>often</span> <span>described</span> <span>as</span> <span>a</span> <span>&#34;batteries included&#34;</span> <span>language</span> <span>due</span> <span>to</span> <span>its</span> <span>comprehensive</span> <span>standard</span> <span>library</span>.<span>Guido</span> <span>van</span> <span>Rossum</span> <span>began</span> <span>working</span> <span>on</span> <span>Python</span> <span>in</span> <span>the</span> <span>late</span> <span>1980</span><span>s</span> <span>as</span> <span>a</span> <span>successor</span> <span>to</span> <span>the</span> <span>ABC</span> <span>programming</span> <span>language</span>

<span>C</span>, <span>or</span> <span>c</span>, <span>is</span> <span>the</span> <span>third</span> <span>letter</span> <span>in</span> <span>the</span> <span>Latin</span> <span>alphabet</span>, <span>used</span> <span>in</span> <span>the</span> <span>modern</span> <span>English</span> <span>alphabet</span>, <span>the</span> <span>alphabets</span> <span>of</span> <span>other</span> <span>western</span> <span>European</span> <span>languages</span> <span>and</span> <span>others</span> <span>worldwide</span>. <span>Its</span> <span>name</span> <span>in</span> <span>English</span> <span>is</span> <span>cee</span> (<span>pronounced</span> ), <span>plural</span> <span>cees</span>.

<span>a</span> <span>measure</span> <span>of</span> <span>the</span> <span>popularity</span> <span>of</span> <span>programming</span> <span>languages</span>.&#39;</pre></div>
<h3 tabindex="-1" dir="auto"><a id="user-content-performance" aria-hidden="true" href="#performance"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Performance</h3>
<p dir="auto">The models used by this package are 1000x smaller than the largest models in use today. They are useful as learning tools, but if you are expecting ChatGPT or similar performance, you will be very disappointed.</p>
<p dir="auto">The base model should work on any system with 512MB of memory, but this memory limit can be increased. Setting this value higher will require more memory and generate results more slowly, but the results should be superior. Here&#39;s an example:</p>
<div dir="auto" data-snippet-clipboard-copy-content="&gt;&gt;&gt; import languagemodels as lm
&gt;&gt;&gt; lm.do(&#34;If I have 7 apples then eat 5, how many apples do I have?&#34;)
&#39;You have 8 apples.&#39;
&gt;&gt;&gt; lm.set_max_ram(&#39;4gb&#39;)
4.0
&gt;&gt;&gt; lm.do(&#34;If I have 7 apples then eat 5, how many apples do I have?&#34;)
&#39;I have 2 apples left.&#39;"><pre><span>&gt;&gt;</span><span>&gt;</span> <span>import</span> <span>languagemodels</span> <span>as</span> <span>lm</span>
<span>&gt;&gt;</span><span>&gt;</span> <span>lm</span>.<span>do</span>(<span>&#34;If I have 7 apples then eat 5, how many apples do I have?&#34;</span>)
<span>&#39;You have 8 apples.&#39;</span>
<span>&gt;&gt;</span><span>&gt;</span> <span>lm</span>.<span>set_max_ram</span>(<span>&#39;4gb&#39;</span>)
<span>4.0</span>
<span>&gt;&gt;</span><span>&gt;</span> <span>lm</span>.<span>do</span>(<span>&#34;If I have 7 apples then eat 5, how many apples do I have?&#34;</span>)
<span>&#39;I have 2 apples left.&#39;</span></pre></div>
<p dir="auto"><a href="https://languagemodels.netlify.app/" rel="nofollow">Full documentation</a></p>
<h2 tabindex="-1" dir="auto"><a id="user-content-advanced-usage" aria-hidden="true" href="#advanced-usage"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Advanced Usage</h2>
<p dir="auto">This package is not meant for advanced usage. If you are looking for something more powerful you could explore <a href="https://huggingface.co/docs/transformers" rel="nofollow">transformers</a> from Hugging Face. For integrating language models in more complex ways, <a href="https://github.com/hwchase17/langchain">LangChain</a> or <a href="https://github.com/microsoft/guidance">guidance</a> may be helpful.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-projects-ideas" aria-hidden="true" href="#projects-ideas"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Projects Ideas</h2>
<p dir="auto">This package can be used to do the heavy lifting for a number of learning projects:</p>
<ul dir="auto">
<li>CLI Chatbot (see examples/chat.py)</li>
<li>Streamlit chatbot (see examples/streamlitchat.py)</li>
<li>Chatbot with information retrieval</li>
<li>Chatbot with access to real-time information</li>
<li>Tool use</li>
<li>Text classification</li>
<li>Extractive question answering</li>
<li>Semantic search over documents</li>
<li>Document question answering</li>
</ul>
<p dir="auto">Several example programs and notebooks are included in the <code>examples</code> directory.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-attribution" aria-hidden="true" href="#attribution"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Attribution</h2>
<ul dir="auto">
<li><a href="https://github.com/OpenNMT/CTranslate2">CTranslate2</a></li>
<li><a href="https://huggingface.co/MBZUAI/LaMini-Flan-T5-783M" rel="nofollow">LaMini-Flan-T5</a></li>
<li><a href="https://huggingface.co/google/flan-t5-large" rel="nofollow">Flan-T5</a></li>
</ul>
</article>
          </div></div>
  </body>
</html>
