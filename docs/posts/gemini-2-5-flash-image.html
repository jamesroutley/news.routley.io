<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://developers.googleblog.com/en/introducing-gemini-2-5-flash-image/">Original</a>
    <h1>Gemini 2.5 Flash Image</h1>
    
    <div id="readability-page-1" class="page"><div>

    
      <section>
        
      </section>
    

    <section>
      
    </section>

    <section>
      
    </section>

    <section>

      <section>
      
        
          
        
          
        
          
        
          
        

      
      </section>
      
    </section>

    
    <section>
      <div>
          

<div>
    <p data-block-key="ovghx">Today, we’re excited to introduce <a href="https://aistudio.google.com/prompts/new_chat?model=gemini-2.5-flash-preview-image">Gemini 2.5 Flash Image</a> (aka nano-banana), our state-of-the-art image generation and editing model. This update enables you to blend multiple images into a single image, maintain character consistency for rich storytelling, make targeted transformations using natural language, and use Gemini&#39;s world knowledge to generate and edit images.</p><p data-block-key="b55k7">When we first launched native image generation in Gemini 2.0 Flash earlier this year, you told us you loved its low latency, cost-effectiveness, and ease of use. But you also gave us feedback that you needed higher-quality images and more powerful creative control.</p><p data-block-key="5uvdv">This model is available right now via the <a href="https://ai.google.dev/gemini-api/docs/image-generation">Gemini API</a> and <a href="https://aistudio.google.com/prompts/new_chat?model=gemini-2.5-flash-preview-image">Google AI Studio</a> for developers and <a href="https://console.cloud.google.com/vertex-ai/studio/multimodal?model=gemini-2.5-flash-image-preview">Vertex AI</a> for enterprise. Gemini 2.5 Flash Image is priced at $30.00 per 1 million output tokens with each image being 1290 output tokens ($0.039 per image). All other modalities on input and output follow Gemini 2.5 Flash <a href="https://ai.google.dev/gemini-api/docs/pricing">pricing</a>.</p>
</div>   


    
    
  <div>
    <h2 data-block-key="uqk74" id="gemini-2.5-flash-image-in-action">Gemini 2.5 Flash Image in action</h2><p data-block-key="f2ffk">To make building with Gemini 2.5 Flash Image even easier, we have made significant updates to <a href="https://aistudio.google.com/apps">Google AI Studio’s “build mode”</a> (with more updates to come). In the examples below, not only can you quickly test the model’s capabilities with custom AI powered apps, but you can remix them or bring ideas to life with just a single prompt. When you are ready to share an app you built, you can deploy right from Google AI Studio or save the code to GitHub.</p><p data-block-key="ausfv">Try a prompt like “Build me an image editing app that lets a user upload an image and apply different filters&#34; or choose one of the preset templates and remix it, all for free!</p><h3 data-block-key="1my25" id="maintain-character-consistency"><b></b></h3><p data-block-key="3263n">A fundamental challenge in image generation is maintaining the appearance of a character or object across multiple prompts and edits. You can now place the same character into different environments, showcase a single product from multiple angles in new settings, or generate consistent brand assets, all while preserving the subject.</p><p data-block-key="citip">We built a <a href="https://aistudio.google.com/apps/bundled/past_forward?showPreview=true&amp;showAssistant=true">template app in Google AI Studio</a> (that you can easily customize and vibe code on top of) to demonstrate the model’s character consistency capabilities.</p>
</div>   

<div>
    
        <video autoplay="" loop="" muted="" playsinline="" poster="https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/wagtailvideo-70_ydi_5_thumb.jpg">
<source src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/PastForward-HighRes.mp4" type="video/mp4"/>
<p>Sorry, your browser doesn&#39;t support playback for this video</p>

</video>
    
    
        
            <p>(sequence shortened)</p>
        
    
</div>  <p data-block-key="ovghx">Beyond character consistency, the model is also excellent at adhering to visual templates. We have already seen developers explore areas like real estate listing cards, uniform employee badges, or dynamic product mockups for an entire catalog—all from a single design template.</p>   


    
    <div>
        <p><img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/gemini-2-5-image-editing-character-consistency.original.png" alt="gemini-2-5-image-editing-character-consistency"/>
            
            
        </p>
    </div>
  <div>
    <h3 data-block-key="3vrqd" id=""><b>Prompt based image editing</b></h3><p data-block-key="4de0c">Gemini 2.5 Flash Image enables targeted transformation and precise local edits with natural language. For example, the model can blur the background of an image, remove a stain in a t-shirt, remove an entire person from a photo, alter a subject&#39;s pose, add color to a black and white photo, or whatever else you can conjure up with a simple prompt.</p><p data-block-key="677fr">To show these capabilities in action, we built a <a href="https://aistudio.google.com/apps/bundled/pixshop">photo editing template app in AI Studio</a>, with both UI and prompt-based controls.</p>
</div>   


    
    <div>
        <p><img src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/images/gemini-2-5-flash-prompt-based-image-editing.original.png" alt="gemini-2-5-flash-prompt-based-image-editing"/>
            
            
        </p>
    </div>
  <div>
    <h3 data-block-key="at4pj" id=""><b>Native world knowledge</b></h3><p data-block-key="dprqn">Historically, image generation models have excelled at aesthetic images, but lacked a deep, semantic understanding of the real world. With Gemini 2.5 Flash Image, the model benefits from Gemini’s world knowledge, which unlocks new use cases.</p><p data-block-key="bk6ca">To demonstrate this, we built <a href="https://aistudio.google.com/apps/bundled/codrawing">a template app in Google AI Studio</a> that turns a simple canvas into an interactive education tutor. It showcases the model&#39;s ability to read and understand hand-drawn diagrams, help with real world questions, and follow complex editing instructions in a single step.</p>
</div>   

<div>
    
        <video autoplay="" loop="" muted="" playsinline="" poster="https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/wagtailvideo-_7j2nlj6_thumb.jpg">
<source src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/gemini-2-5-flash-image-native-world-knowledge.mp4" type="video/mp4"/>
<p>Sorry, your browser doesn&#39;t support playback for this video</p>

</video>
    
    
        
            <p>(Example prompts and model results)</p>
        
    
</div>  <div>
    <h3 data-block-key="l142f" id=""><b>Multi-image fusion</b></h3><p data-block-key="28rs8">Gemini 2.5 Flash Image can understand and merge multiple input images. You can put an object into a scene, restyle a room with a color scheme or texture, and fuse images with a single prompt.</p><p data-block-key="8ri53">To showcase multi-image fusion, we built a <a href="https://aistudio.google.com/apps/bundled/home_canvas">template app in Google AI Studio</a> which lets you drag products into a new scene to quickly create a new photorealistic fused image.</p>
</div>   

<div>
    
        <video autoplay="" loop="" muted="" playsinline="" poster="https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/wagtailvideo-_390ekpo_thumb.jpg">
<source src="https://storage.googleapis.com/gweb-developer-goog-blog-assets/original_videos/gemini-2-5-flash-image-multi-image-fusion_1.mp4" type="video/mp4"/>
<p>Sorry, your browser doesn&#39;t support playback for this video</p>

</video>
    
    
        
            <p>(Sequences shortened)</p>
        
    
</div>  <div>
    <h2 data-block-key="cuwse" id="get-started-building">Get started building</h2><p data-block-key="679v1">Check out our <a href="https://ai.google.dev/gemini-api/docs/image-generation">developer docs</a> to start building with Gemini 2.5 Flash Image. The model is in preview today via the <a href="https://ai.google.dev/gemini-api/docs/image-generation">Gemini API</a> and <a href="https://aistudio.google.com/prompts/new_chat?model=gemini-2.5-flash-preview-image">Google AI Studio</a> but will be stable in the coming weeks. All of the demo apps we highlighted here were vibe coded in Google AI Studio so they can be remixed and customized with just a prompt.</p><p data-block-key="bkh2d"><a href="https://openrouter.ai/google/gemini-2.5-flash-preview-image">OpenRouter.ai</a> has partnered with us to help bring Gemini 2.5 Flash Image to their 3M+ developers everywhere, today. This is the first model on OpenRouter – of the 480+ live today –that can generate images.</p><p data-block-key="5mobv">We&#39;re also excited to partner with <a href="https://fal.ai/models/fal-ai/gemini-25-flash-image">fal.ai</a>, a leading developer platform for generative media, to make Gemini 2.5 Flash Image available to the broader developer community.</p><p data-block-key="ar7so">All images created or edited with Gemini 2.5 Flash Image will include an invisible<a href="https://deepmind.google/science/synthid/"> SynthID digital watermark</a>, so they can be identified as AI-generated or edited.</p>
</div>  <div>
    <pre><code>from google import genai
from PIL import Image
from io import BytesIO

client = genai.Client()

prompt = &#34;Create a picture of my cat eating a nano-banana in a fancy restaurant under the gemini constellation&#34;

image = Image.open(&#39;/path/to/image.png&#39;)

response = client.models.generate_content(
    model=&#34;gemini-2.5-flash-image-preview&#34;,
    contents=[prompt, image],
)

for part in response.candidates[0].content.parts:
  if part.text is not None:
    print(part.text)
  elif part.inline_data is not None:
    image = Image.open(BytesIO(part.inline_data.data))   
    image.save(&#34;generated_image.png&#34;)</code></pre>
    <p>
        Python
    </p>
    <p><span>Copied</span>
        
    </p>
    
    
</div>  <div>
    <p data-block-key="ovghx">We are actively working to improve long-form text rendering, even more reliable character consistency, and factual representation like fine details in images. Please continue to send us feedback in our <a href="https://discuss.ai.google.dev/c/gemini-api/4">developer forum</a> or on <a href="https://x.com/googleaistudio">X</a>.</p><p data-block-key="t7ib">We can’t wait to see what you build with Gemini 2.5 Flash Image!</p>
</div> 
      </div>
    </section>
    

    <section>
      
      
    </section>

    
    
    
  </div></div>
  </body>
</html>
