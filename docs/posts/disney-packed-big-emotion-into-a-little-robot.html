<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://spectrum.ieee.org/disney-robot">Original</a>
    <h1>Disney packed big emotion into a little robot</h1>
    
    <div id="readability-page-1" class="page"><div data-elid="2665798070" data-post-url="https://spectrum.ieee.org/disney-robot" data-authors="Evan Ackerman" data-headline="How Disney Packed Big Emotion Into a Little Robot" data-page-title="How Disney Packed Big Emotion Into a Little Robot - IEEE Spectrum"><div><p>On Wednesday, at the <a href="https://ieee-iros.org/" rel="noopener noreferrer" target="_blank">2023 IEEE/RSJ International Conference on Intelligent Robots and Systems (IROS)</a>, in Detroit, a <a href="https://la.disneyresearch.com/" rel="noopener noreferrer" target="_blank">Disney Research</a> team presented a brand new robotic character during their evening keynote address. The adorable robot packs an enormous amount of expression into its child-size body, from its highly expressive head and two wiggly antennae to its stubby little legs. But what sets this robot apart from other small bipeds is <em>how</em> it walks—it’s full of personality, emoting as it moves in a way that makes it seem uniquely alive.
</p><p>
	Programming robots to move in emotive ways is something that Disney is an expert in, going as far back as 1971, with its animatronic Hall of Presidents in Disney World. As robots have gotten more advanced and more mobile, though, it’s become challenging for robot designers and robot animators to develop emotive behaviors that both take advantage of and are compatible with robotic hardware under real-world constraints. Disney Research has spent the last year developing a new system that leverages reinforcement learning to turn an animator’s vision into expressive motions that are robust enough to work almost anywhere, whether that’s a stage at IROS or a Disney theme park or a forest in Switzerland.</p><hr/><p><span data-rm-shortcode-id="513438d4355398aafad6fe5b5a2a99e3"><iframe frameborder="0" height="auto" type="lazy-iframe" scrolling="no" data-runner-src="https://www.youtube.com/embed/-cfIm06tcfA?rel=0" width="100%"></iframe></span><small placeholder="Add Photo Credit...">Disney Research</small></p><p>
	This particular robot was developed by a team led by <a href="https://www.baecher.info/" target="_blank">Moritz Bächer </a>from <a href="https://studios.disneyresearch.com/" rel="noopener noreferrer" target="_blank">Disney Research in Zurich</a>. It’s mostly 3D printed, using modular hardware and actuators that made it quick to design and iterate on, going from concept to what you see in the above video in less than a year. It has a four-degree-of-freedom head (able to look up, down, around, and tilt), as well as five-degree-of-freedom legs with hip joints that allow it to walk while balancing dynamically.
</p><p>
	“Most roboticists are focused on getting their bipedal robots to reliably walk,” says Disney research scientist <a href="https://spectrum.ieee.org/u/morgan-pope" target="_self">Morgan Pope</a>, who helped present the robot on stage. “At Disney, that might not be enough—our robots may have to strut, prance, sneak, trot, or meander to convey the emotion that we need them to.” Disney has animators who are experts in making characters convey all of those emotions (and more) through movement, as well as roboticists who are experts in building mechanical systems. “What we try to bring to these kinds of robots is born from our history of character animation,” explains <a href="https://www.linkedin.com/in/michael-hopkins-656b70b1/" target="_blank">Michael Hopkins</a>, a principle R&amp;D engineer at Disney. “We have an animator embedded in our team, and together, we’re able to leverage their knowledge and our technical expertise to create the best performance we can.”
</p><p><img alt="Two men stand on a conference presentation stage next to a small white legged robot." data-rm-shortcode-id="86c4f36abac4963e336bac4db8795084" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/two-men-stand-on-a-conference-presentation-stage-next-to-a-small-white-legged-robot.jpg?id=49273698&amp;width=980" height="1424" id="d479f" lazy-loadable="true" src="data:image/svg+xml,%3Csvg%20xmlns=&#39;http://www.w3.org/2000/svg&#39;%20viewBox=&#39;0%200%202000%201424&#39;%3E%3C/svg%3E" width="2000"/><small placeholder="Add Photo Caption...">Morgan Pope [left] and Moritz Bächer present the new robot at IROS 2023.</small><small placeholder="Add Photo Credit...">Evan Ackerman</small></p><p>
	To create an effective robotic character requires the animators and the roboticists to combine their talents, a process that can be time consuming and involves a lot of trial and error to make sure that the robot can convey the animators’ artistic intent without falling over. “In general, animation tools don’t have physics built into them,” explains Bächer. “So that makes it hard for artists to design animations that will work in the real world.”
</p><p>
	“It’s not just about walking,” adds Pope. “Walking is one of the inputs to the reinforcement-learning system, but the other important input is <em>how</em> it walks.”
</p><p data-rm-resized-container="25%"><img alt="Photo of small robot and a man." data-rm-shortcode-id="c15ab8265e496260a1f026f48c85721b" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/photo-of-small-robot-and-a-man.jpg?id=48632157&amp;width=980" height="3039" id="16189" lazy-loadable="true" src="data:image/svg+xml,%3Csvg%20xmlns=&#39;http://www.w3.org/2000/svg&#39;%20viewBox=&#39;0%200%202000%203039&#39;%3E%3C/svg%3E" width="2000"/><small placeholder="Add Photo Caption...">Disney’s Morgan Pope helped present the new robotic character at IROS.</small><small placeholder="Add Photo Credit...">Evan Ackerman</small></p><p>
	To bridge this gap, Disney Research has developed a reinforcement learning-based pipeline that relies on simulation to combine and balance the vision of an animator with robust robotic motions. For the animator, the pipeline essentially takes care of implementing the constraints of the physical world, letting the animator develop highly expressive motions while relying on the system to make those motions real—or get as close as is physically possible for the robot. Disney’s pipeline can train a robot on a new behavior on a single PC, running what amounts to years of training in just a few hours. According to Bächer, this has reduced the time that it takes for Disney to develop a new robotic character from years to just months.
</p><p>
	A big advantage of reinforcement learning in this context is that the resulting motions can be highly robust. Disney’s system is able to train motions over and over while making slight changes to things like motor performance, mass distribution, and friction between the robot and the ground. The system ensures that whatever the robot encounters in the real world, it will know not just how to handle itself, but how to handle itself <em>while still emoting</em>, which is critical to the robot maintaining its character. “This is a challenge for traditional techniques,” says <a href="https://www.linkedin.com/in/ruben-grandia" target="_blank">Ruben Grandia</a>, an associate research scientist at Disney Research. “Normally, you have to hand-program this transition point. But if you put everything together in one simulation and perturb it while it tries to move and animate, it can determine that point for itself, which has resulted in recovery strategies that we see from this robot that we’d have no idea how to program.”
</p><p>
	Social robots have existed for decades, and even robots not explicitly designed for social interaction usually have some human-robot interaction features if they’re likely to spend time around people. But human-robot interaction can sometimes be an afterthought for robots that are designed primarily with functionality in mind. With its robots, Disney has shown just how much a robot is able to communicate through <em>character</em> without sacrificing functionality, and this can be useful in <a href="https://spectrum.ieee.org/topic/robotics/">robotics</a> more broadly.
</p><p>
	“In situations where humans and robots are close to each other, conveying emotion and intent can be an important feature,” explains <a href="https://www.linkedin.com/in/georg-wiedebach/" target="_blank">Georg Wiedebach</a>, senior R&amp;D imagineer at Disney. “So I think this can also be valuable in other applications where robots are working next to people.”
</p><p><img alt="Photo of a small crowd of people surrounding a small robot and taking photos of it." data-rm-shortcode-id="bb20d8c71128144c765e449ed1149162" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/photo-of-a-small-crowd-of-people-surrounding-a-small-robot-and-taking-photos-of-it.jpg?id=48631709&amp;width=980" height="1477" id="62091" lazy-loadable="true" src="data:image/svg+xml,%3Csvg%20xmlns=&#39;http://www.w3.org/2000/svg&#39;%20viewBox=&#39;0%200%202000%201477&#39;%3E%3C/svg%3E" width="2000"/><small placeholder="Add Photo Caption...">IROS attendees meet the Disney robot.</small><small placeholder="Add Photo Credit...">Evan Ackerman</small></p><p>
	While it’s easy to focus on this specific robot (look how cute it is!), the researchers emphasize that what’s important here is not the robot, it’s the process. “The idea is that this is a platform that’s hardware agnostic,” says Bächer. “So if we wanted to add more legs, or add arms, or make an entirely new character with a completely different morphology, we can rapidly teach it new behaviors. The off-the-shelf actuators, the 3D-printed components, our adaptable reinforcement-learning framework—these can all be applied to robots that are widely different in how they look and move. This robot is a promising first step on that journey.”
</p><p>
	The next steps on Disney’s journey involve using this technique to develop more physical robotic characters, and pushing the limits of what’s possible with faster and more dynamic motions. “We want to see what happens when we get to those limits,” says Disney research scientist <a href="https://www.linkedin.com/in/espen-knoop-47b525114/" target="_blank">Espen Knoop</a>, “and learn what we can do at those limits.”
</p><p><img alt="Photo of five men kneeling around a small robot." data-rm-shortcode-id="61d9f09a374315635b2c0ac5af9afbd3" data-rm-shortcode-name="rebelmouse-image" data-runner-src="https://spectrum.ieee.org/media-library/photo-of-five-men-kneeling-around-a-small-robot.jpg?id=48631971&amp;width=980" height="1473" id="16976" lazy-loadable="true" src="data:image/svg+xml,%3Csvg%20xmlns=&#39;http://www.w3.org/2000/svg&#39;%20viewBox=&#39;0%200%202000%201473&#39;%3E%3C/svg%3E" width="2000"/><small placeholder="Add Photo Caption...">The Disney Research team that created the new robot are [from left] Moritz Bächer, Georg Wiedebach, Michael Hopkins, Ruben Grandia, and Morgan Pope.</small><small placeholder="Add Photo Credit...">Evan Ackerman</small></p><p>
	As far as this robot goes, the character doesn’t have an official name, and Disney isn’t ready to comment on where we might see it. But based on how it looks and sounds, we have some guesses. And this one little robot is only the beginning—now that they’re so much easier to create, we’re hoping to see many more of these expressive robotic characters from Disney.
</p></div></div></div>
  </body>
</html>
