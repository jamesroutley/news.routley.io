<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://payments.posthaven.com/rc-w6d2-be-careful-what-you-wish-for">Original</a>
    <h1>RC W6D2 - Be careful what you wish for</h1>
    
    <div id="readability-page-1" class="page"><div id="post_body_1956404">
    
      <div><p>The <a href="https://www.youtube.com/watch?v=PaCmpygFfXo&amp;list=PLAqhIrjkxbuWI23v9cThsA9GvCAUhRvKZ&amp;index=2">next video</a> I watched in Andrej Karpathy’s Neural Networks: Zero to Hero series is where he starts building `makemore`, a model that takes in words and ‘makes more’ words like it. In the video, the model uses human names as training data and generates words that sound like human names.</p><p>It’s a bigram character-level language model, in which a single character is used to predict the next character. For example, with the name Emma, the model would use E to predict M, M to predict M, and M to predict A. It starts out with a Markov transition-probability model as a baseline, and progresses to a 1-layer neural network model. The model architecture gets more complex in later videos.</p><p>His approach emphasizes the simple building blocks of neural network models. From the engineering perspective, it appears that a lot of the heavy lifting with libraries and frameworks is getting the calculations to run fast at scale. I haven’t used Tensorflow and Torch at length to make a comparison, but I get the impression the latter is loved for having better UX. I admit it’s also cute seeing Karpathy do Youtube influencer poses on the video covers.</p><p>As with functional programming, it’s fun to read around the topic. I enjoyed Lex Fridman’s framing of deep learning as the extraction of useful patterns from data, and the <a href="https://youtu.be/O5xeyoRL95U?t=914">analog</a> to heliocentrism vs geocentrism in forming simpler and simpler representation of ideas.</p><p>What’s interesting about the broader topic of AI is that, unlike functional programming, everyone has a say. This is understandable given the broader societal implications. According to <a href="https://www.politico.eu/article/eu-plan-regulate-chatgpt-openai-artificial-intelligence-act/" title="Link: https://www.politico.eu/article/eu-plan-regulate-chatgpt-openai-artificial-intelligence-act/">Politico</a>, the release of ChatGPT has pushed the EU back to the drawing board when it comes to regulation. When asked if it&#39;s dangerous to release ChatGPT to the public before we fully understand the risks, Sam Altman <a href="https://youtu.be/540vzMlf-54?t=479">responded</a> by saying it’s even more dangerous to develop in secret and release GPT-7 to the world.</p><p>This highlights how difficult it is to make predictions about the future, as per this <a href="https://greylock.com/greymatter/sam-altman-ai-for-the-next-era/">podcast interview</a> of Sam Altman.</p><blockquote><p>I think it’s interesting that if you ask people 10 years ago about how AI was going to have an impact, with a lot of confidence from most people, you would’ve heard, first, it’s going to come for the blue collar jobs working in the factories, truck drivers, whatever. Then it will come for the low skill white collar jobs. Then the very high skill, really high IQ white collar jobs, like a programmer or whatever. And then very last of all and maybe never, it’s going to take the creative jobs. And it’s going exactly the other direction.</p></blockquote><p>Later that day I chatted with a friend who wants to find use cases for GPT but hasn’t been motivated to dig up the more boring tasks at work. I responded by saying how my compass at RC is “is this fun or does this feel like work”, and the dream is to have work be fun! The conversation continued as follows.</p><div>        <div id="posthaven_gallery[1982197]">
          <p>
          <img src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2972587/065KmxLHVmtIBHTZCrEpNyOKOWA/medium_careful.jpg" data-posthaven-state="processed" data-medium-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2972587/065KmxLHVmtIBHTZCrEpNyOKOWA/medium_careful.jpg" data-medium-width="800" data-medium-height="781" data-large-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2972587/065KmxLHVmtIBHTZCrEpNyOKOWA/large_careful.jpg" data-large-width="1194" data-large-height="1166" data-thumb-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2972587/065KmxLHVmtIBHTZCrEpNyOKOWA/thumb_careful.jpg" data-thumb-width="200" data-thumb-height="200" data-xlarge-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2972587/065KmxLHVmtIBHTZCrEpNyOKOWA/xlarge_careful.jpg" data-xlarge-width="1194" data-xlarge-height="1166" data-orig-src="https://phaven-prod.s3.amazonaws.com/files/image_part/asset/2972587/065KmxLHVmtIBHTZCrEpNyOKOWA/careful.jpg" data-orig-width="1194" data-orig-height="1166" data-posthaven-id="2972587"/>
        </p>
          
        </div>
</div></div>
    
  </div></div>
  </body>
</html>
