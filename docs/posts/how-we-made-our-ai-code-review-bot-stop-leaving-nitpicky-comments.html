<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.greptile.com/blog/make-llms-shut-up">Original</a>
    <h1>How we made our AI code review bot stop leaving nitpicky comments</h1>
    
    <div id="readability-page-1" class="page"><div><p><span>December 18, 2024<!-- --> <span>(<!-- -->4<!-- -->d ago)</span></span></p><p>Written by <strong>Daksh Gupta</strong></p></div><article><i><p>This post is adapted from a talk I gave at the Sourcegraph Dev Tools meetup at
the Cloudflare office in San Francisco on December 16th, 2024.</p></i>
<p>I am Daksh, co-founder of Greptile - AI that understands large codebases. Our most popular product is our AI code review bot. It does a first pass review of PRs with full context of the wider codebase, surfacing bugs, anti-patterns, repeated code, etc.</p>
<p>When we first launched this product, the biggest complaint by far was that the bot left too many comments. In a PR with 20 changes, it would leave as many as 10 comments, at which point the PR author would simply start ignoring all of them.</p>
<p><img src="https://www.greptile.com/shutup/image.png" alt="Too many comments example"/></p>
<p>We needed to:</p>
<ul>
<li>figure out how to reduce the number of comments that Greptile was generating,</li>
<li>which meant figuring out which comments should be eliminated,</li>
<li>which meant figuring out a way to evaluate the quality of each comment.</li>
</ul>
<p>There were two ideas here:</p>
<ol>
<li>GitHub lets developers react to comments with üëç/üëé. We could use this as the quality indicator.</li>
<li>We could check which comments the author actually addressed in the code by scanning the diffs of the subsequent commits.</li>
</ol>
<p>We picked the latter, which also gave us our performance metric - percentage of generated comments that the author actually addresses.</p>
<p>We analyzed existing Greptile comments and found that ~19% were good, 2% were flat-out incorrect, and 79% were nits - comments that were technically true but not something the dev cared about.</p>
<p><img src="https://www.greptile.com/shutup/image%201.png" alt="Comment analysis chart"/></p>
<p>This is an example of a nit:</p>
<p><img src="https://www.greptile.com/shutup/image%202.png" alt="Example of a nit comment"/></p>
<p>Essentially we needed to teach LLMs (which are paid by the token) to only generate a small number of high quality comments.</p>
<h2 id="attempt-1-prompting"><a href="#attempt-1-prompting"></a>Attempt 1: Prompting</h2>
<p>Our first instinct was to ‚Äúprompt engineer‚Äù.</p>
<p><img src="https://www.greptile.com/shutup/image%203.png" alt="Prompting attempt illustration"/></p>
<p>Sadly, even with all kinds of prompting tricks, we simply could not get the LLM to produce fewer nits without also producing fewer critical comments.</p>
<p>Since LLMs are ‚Äúfew-shot learners‚Äù, we also tried to give Greptile several examples of good and bad comments in the prompt - hoping it would be able to generalize those patterns.</p>
<p><img src="https://www.greptile.com/shutup/image%204.png" alt="Few-shot learning example"/></p>
<p>This also did not work. If anything, this made the bot even worse because it didn‚Äôt actually find a useful pattern across the available samples (some might argue LLMs are architecturally incapable of that), and instead inferred superficial characteristics.</p>
<h2 id="attempt-2-llm-as-a-judge"><a href="#attempt-2-llm-as-a-judge"></a>Attempt 2: LLM-as-a-judge</h2>
<p>Since we couldn‚Äôt get the LLM to stop <em>producing</em> nit comments, we figured we would simply add a filtering step where the LLM could rate the severity of a comment+diff pair on a 1-10 scale, and simply eliminate any comments rated less than 7.</p>
<p><img src="https://www.greptile.com/shutup/image%205.png" alt="LLM-as-a-judge attempt illustration"/></p>
<p>Sadly, this also failed. The LLMs judgment of its own output was nearly random. This also made the bot extremely slow because there was now a whole new inference call in the workflow.</p>
<h2 id="out-of-ideas"><a href="#out-of-ideas"></a>Out of Ideas</h2>
<p>At this point we were running out of ideas. We had basically learned three things:</p>
<ol>
<li>Prompting doesn‚Äôt work for this</li>
<li>LLMs are bad evaluators of severity</li>
<li>Nits are subjective - definitions and standards vary from team to team</li>
</ol>
<p>The 3rd learning was pointing us in the general direction of <em>learning</em>. The bot would somehow need to infer where the bar for ‚Äúnittiness‚Äù was for the team, and then filter comments accordingly.</p>
<p>We considered fine-tuning, but the cost, speed, and lack of portability (Greptile would no longer be model-agnostic) ruled it out.</p>
<h2 id="final-attempt-clustering"><a href="#final-attempt-clustering"></a>Final Attempt: Clustering</h2>
<p>In a final attempt, we started generating embeddings vectors of past comments on a per-team level that were addressed/upvoted or downvoted by developers and storing them in a vector database. The idea was to filter out comments that were very similar to some minimum number of downvoted comments.</p>
<p><img src="https://www.greptile.com/shutup/image%206.png" alt="Clustering attempt illustration"/></p>
<p>When Greptile generated a comment, we generated its vector embedding and ran it through a simple filter:</p>
<ul>
<li>If the comment had a cosine similarity exceeding some threshold with at least 3 unique downvoted comments, it would get blocked.</li>
<li>The same situation but with three <em>upvoted</em> comments, it would pass.</li>
<li>If neither or both, it would pass.</li>
</ul>
<p><img src="https://www.greptile.com/shutup/image%207.png" alt="Clustering filter illustration"/></p>
<h2 id="results"><a href="#results"></a>Results</h2>
<p>Remarkably - this works! It turns out that most nits can be placed into a small number of clusters. Users downvote nit comments, and when enough comments of the same type are downvoted, the bot can filter out any new comments of that type.</p>
<p>Within two weeks of rolling out this feature, existing users saw address rate (percentage of Greptile‚Äôs comments that devs address before merging) go from 19% to 55+%. While this is far from perfect, this has been far and away the most impactful technique in reducing the noise produced by the LLM.</p>
<p>This is an ongoing problem for us, and I will likely write a part II when we are fortunate enough to see another inflection in address rate!</p></article></div>
  </body>
</html>
