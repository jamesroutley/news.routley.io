<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Basics_of_HTTP/Evolution_of_HTTP">Original</a>
    <h1>Evolution of HTTP</h1>
    
    <div id="readability-page-1" class="page"><div id="content" role="main"><article lang="en-US"><p><strong>HTTP</strong> (HyperText Transfer Protocol) is the underlying protocol of the World Wide Web. Developed by Tim Berners-Lee and his team between 1989-1991, HTTP has gone through many changes that have helped maintain its simplicity while shaping its flexibility. Keep reading to learn how HTTP evolved from a protocol designed to exchange files in a semitrusted laboratory environment into a modern internet maze that carries images and videos in high resolution and 3D.</p><section aria-labelledby="invention_of_the_world_wide_web"><h2 id="invention_of_the_world_wide_web"><a href="#invention_of_the_world_wide_web" title="Permalink to Invention of the World Wide Web">Invention of the World Wide Web</a></h2><div><p>In 1989, while working at CERN, Tim Berners-Lee wrote a proposal to build a hypertext system over the internet. Initially called the <em>Mesh</em>, it was later renamed the <em>World Wide Web</em> during its implementation in 1990. Built over the existing TCP and IP protocols, it consisted of 4 building blocks:</p>
<ul>
  <li>A textual format to represent hypertext documents, the <em><a href="https://developer.mozilla.org/en-US/docs/Web/HTML">HyperText Markup Language</a></em> (HTML).</li>
  <li>A simple protocol to exchange these documents, the <em>HyperText Transfer Protocol</em> (HTTP).</li>
  <li>A client to display (and edit) these documents, the first web browser called the <em>WorldWideWeb</em>.</li>
  <li>A server to give access to the document, an early version of <em>httpd</em>.</li>
</ul>
<p>These four building blocks were completed by the end of 1990, and the first servers were running outside of CERN by early 1991. On August 6, 1991, Tim Berners-Lee <a href="https://www.w3.org/People/Berners-Lee/1991/08/art-6484.txt" rel=" noopener">posted</a> on the public <em>alt.hypertext</em> newsgroup. This is now considered to be the official start of the World Wide Web as a public project.</p>
<p>The HTTP protocol used in those early phases was very simple. It was later dubbed HTTP/0.9 and is sometimes called the one-line protocol.</p></div></section><section aria-labelledby="http0.9_–_the_one-line_protocol"><h2 id="http0.9_–_the_one-line_protocol"><a href="#http0.9_–_the_one-line_protocol" title="Permalink to HTTP/0.9 – The one-line protocol">HTTP/0.9 – The one-line protocol</a></h2><div><p>The initial version of HTTP had no version number; it was later called 0.9 to differentiate it from later versions. HTTP/0.9 was extremely simple: requests consisted of a single line and started with the only possible method <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Methods/GET"><code>GET</code></a> followed by the path to the resource. The full URL wasn&#39;t included as the protocol, server, and port weren&#39;t necessary once connected to the server.</p>

<p>The response was extremely simple, too: it only consisted of the file itself.</p>
<div><pre><code><span><span><span>&lt;</span>html</span><span>&gt;</span></span>
  A very simple HTML page
<span><span><span>&lt;/</span>html</span><span>&gt;</span></span>
</code></pre></div>
<p>Unlike subsequent evolutions, there were no HTTP headers. This meant that only HTML files could be transmitted. There were no status or error codes. If there was a problem, a specific HTML file was generated and included a description of the problem for human consumption.</p></div></section><section aria-labelledby="http1.0_–_building_extensibility"><h2 id="http1.0_–_building_extensibility"><a href="#http1.0_–_building_extensibility" title="Permalink to HTTP/1.0 – Building extensibility">HTTP/1.0 – Building extensibility</a></h2><div><p>HTTP/0.9 was very limited, but browsers and servers quickly made it more versatile:</p>
<ul>
  <li>Versioning information was sent within each request (<code>HTTP/1.0</code> was appended to the <code>GET</code> line).</li>
  <li>A status code line was also sent at the beginning of a response. This allowed the browser itself to recognize the success or failure of a request and adapt its behavior accordingly. For example, updating or using its local cache in a specific way.</li>
  <li>The concept of HTTP headers was introduced for both requests and responses. Metadata could be transmitted and the protocol became extremely flexible and extensible.</li>
  <li>Documents other than plain HTML files could be transmitted thanks to the <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Content-Type"><code>Content-Type</code></a> header.</li>
</ul>
<p>At this point in time, a typical request and response looked like this:</p>
<div><pre><code><span><span>GET</span> <span><span><span>/</span>mypage.html</span></span> <span>HTTP/1.0</span></span>


200 OK



<span><span><span><span>&lt;</span>HTML</span><span>&gt;</span></span>
A page with an image
  <span><span><span>&lt;</span>IMG</span> <span>SRC</span><span><span>=</span><span>&#34;</span>/myimage.gif<span>&#34;</span></span><span>&gt;</span></span>
<span><span><span>&lt;/</span>HTML</span><span>&gt;</span></span>
</span></code></pre></div>
<p>It was followed by a second connection and a request to fetch the image (with the corresponding response):</p>
<div><pre><code><span><span>GET</span> <span><span><span>/</span>myimage.gif</span></span> <span>HTTP/1.0</span></span>


200 OK



(image content)
</code></pre></div>
<p>Between 1991-1995, these were introduced with a try-and-see approach. A server and a browser would add a feature and see if it got traction. Interoperability problems were common. In an effort to solve these issues, an informational document that described the common practices was published in November 1996. This was known as <a href="https://datatracker.ietf.org/doc/html/rfc1945" rel=" noopener">RFC 1945</a> and defined HTTP/1.0.</p></div></section><section aria-labelledby="http1.1_–_the_standardized_protocol"><h2 id="http1.1_–_the_standardized_protocol"><a href="#http1.1_–_the_standardized_protocol" title="Permalink to HTTP/1.1 – The standardized protocol">HTTP/1.1 – The standardized protocol</a></h2><div><p>In the meantime, proper standardization was in progress. This happened in parallel to the diverse implementations of HTTP/1.0. The first standardized version of HTTP, HTTP/1.1, was published in early 1997, only a few months after HTTP/1.0.</p>
<p>HTTP/1.1 clarified ambiguities and introduced numerous improvements:</p>
<ul>
  <li>A connection could be reused, which saved time. It no longer needed to be opened multiple times to display the resources embedded in the single original document.</li>
  <li>Pipelining was added. This allowed a second request to be sent before the answer to the first one was fully transmitted. This lowered the latency of the communication.</li>
  <li>Chunked responses were also supported.</li>
  <li>Additional cache control mechanisms were introduced.</li>
  <li>Content negotiation, including language, encoding, and type, was introduced. A client and a server could now agree on which content to exchange.</li>
  <li>Thanks to the <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Host"><code>Host</code></a> header, the ability to host different domains from the same IP address allowed server collocation.</li>
</ul>
<p>A typical flow of requests, all through one single connection, looked like this:</p>
<div><pre><code><span><span>GET</span> <span><span><span>/</span>en-US<span>/</span>docs<span>/</span>Glossary<span>/</span>Simple_header</span></span> <span>HTTP/1.1</span></span>







200 OK











(content)

<span><span>GET</span> <span><span><span>/</span>static<span>/</span>img<span>/</span>header-background.png</span></span> <span>HTTP/1.1</span></span>







200 OK









(image content of 3077 bytes)
</code></pre></div>
<p>HTTP/1.1 was first published as <a href="https://datatracker.ietf.org/doc/html/rfc2068" rel=" noopener">RFC 2068</a> in January 1997.</p></div></section><section aria-labelledby="more_than_15_years_of_extensions"><h2 id="more_than_15_years_of_extensions"><a href="#more_than_15_years_of_extensions" title="Permalink to More than 15 years of extensions">More than 15 years of extensions</a></h2><p>The extensibility of HTTP made it easy to create new headers and methods. Even though the HTTP/1.1 protocol was refined over two revisions, <a href="https://datatracker.ietf.org/doc/html/rfc2616" rel=" noopener">RFC 2616</a> published in June 1999 and <a href="https://datatracker.ietf.org/doc/html/rfc7230" rel=" noopener">RFC 7230</a>-<a href="https://datatracker.ietf.org/doc/html/rfc7235" rel=" noopener">RFC 7235</a> published in June 2014 before the release of HTTP/2, it was extremely stable for more than 15 years.</p></section><section aria-labelledby="using_http_for_secure_transmissions"><h3 id="using_http_for_secure_transmissions"><a href="#using_http_for_secure_transmissions" title="Permalink to Using HTTP for secure transmissions">Using HTTP for secure transmissions</a></h3><div><p>The largest change to HTTP was made at the end of 1994. Instead of sending HTTP over a basic TCP/IP stack, the computer-services company Netscape Communications created an additional encrypted transmission layer on top of it: SSL. SSL 1.0 was never released to the public, but SSL 2.0 and its successor SSL 3.0 allowed for the creation of ecommerce websites. To do this, they encrypted and guaranteed the authenticity of the messages exchanged between the server and client. SSL was eventually standardized and became TLS.</p>
<p>During the same time period, it became clear that an encrypted transport layer was needed. The web was no longer a mostly academic network, and instead became a jungle where advertisers, random individuals, and criminals competed for as much private data as possible. As the applications built over HTTP became more powerful and required access to private information like address books, email, and user location, TLS became necessary outside of the ecommerce use case.</p></div></section><section aria-labelledby="using_http_for_complex_applications"><h3 id="using_http_for_complex_applications"><a href="#using_http_for_complex_applications" title="Permalink to Using HTTP for complex applications">Using HTTP for complex applications</a></h3><div><p>Tim Berners-Lee didn&#39;t originally envision HTTP as a read-only medium. He wanted to create a web where people could add and move documents remotely—a kind of distributed file system. Around 1996, HTTP was extended to allow authoring, and a standard called WebDAV was created. It grew to include specific applications like CardDAV for handling address book entries and CalDAV for dealing with calendars. But all these *DAV extensions had a flaw: they were only usable when implemented by the servers.</p>
<p>In 2000, a new pattern for using HTTP was designed: <a href="https://developer.mozilla.org/en-US/docs/Glossary/REST">representational state transfer</a> (or REST). The API wasn&#39;t based on the new HTTP methods, but instead relied on access to specific URIs with basic HTTP/1.1 methods. This allowed any web application to let an API retrieve and modify its data without having to update the browsers or the servers. All necessary information was embedded in the files that the websites served through standard HTTP/1.1. The drawback of the REST model was that each website defined its own nonstandard RESTful API and had total control of it. This differed from the *DAV extensions where clients and servers were interoperable. RESTful APIs became very common in the 2010s.</p>
<p>Since 2005, more APIs have become available to web pages. Several of these APIs create extensions to the HTTP protocol for specific purposes:</p>
<ul>
  <li><a href="https://developer.mozilla.org/en-US/docs/Web/API/Server-sent_events">Server-sent events</a>, where the server can push occasional messages to the browser.</li>
  <li><a href="https://developer.mozilla.org/en-US/docs/Web/API/WebSockets_API">WebSocket</a>, a new protocol that can be set up by upgrading an existing HTTP connection.</li>
</ul></div></section><section aria-labelledby="relaxing_the_security-model_of_the_web"><h3 id="relaxing_the_security-model_of_the_web"><a href="#relaxing_the_security-model_of_the_web" title="Permalink to Relaxing the security-model of the web">Relaxing the security-model of the web</a></h3><div><p>HTTP is independent of the web security model, known as the <a href="https://developer.mozilla.org/en-US/docs/Web/Security/Same-origin_policy">same-origin policy</a>. In fact, the current web security model was developed after the creation of HTTP! Over the years, it proved useful to lift some of the restrictions of this policy under certain constraints. The server transmitted how much and when to lift such restrictions to the client using a new set of HTTP headers. These were defined in specifications like <a href="https://developer.mozilla.org/en-US/docs/Glossary/CORS">Cross-Origin Resource Sharing</a> (CORS) and the <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/CSP">Content Security Policy</a> (CSP).</p>
<p>In addition to these large extensions, many other headers were added, sometimes only experimentally. Notable headers are the Do Not Track (<a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/DNT"><code>DNT</code></a>) header to control privacy, <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/X-Frame-Options"><code>X-Frame-Options</code></a>, and <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Upgrade-Insecure-Requests"><code>Upgrade-Insecure-Requests</code></a> but many more exist.</p></div></section><section aria-labelledby="http2_–_a_protocol_for_greater_performance"><h2 id="http2_–_a_protocol_for_greater_performance"><a href="#http2_–_a_protocol_for_greater_performance" title="Permalink to HTTP/2 – A protocol for greater performance">HTTP/2 – A protocol for greater performance</a></h2><div><p>Over the years, web pages became more complex. Some of them were even applications in their own right. More visual media was displayed and the volume and size of scripts adding interactivity also increased. Much more data was transmitted over significantly more HTTP requests and this created more complexity and overhead for HTTP/1.1 connections. To account for this, Google implemented an experimental protocol SPDY in the early 2010s. This alternative way of exchanging data between client and server amassed interest from developers working on both browsers and servers. SPDY defined an increase in responsiveness and solved the problem of duplicate data transmission, serving as the foundation for the HTTP/2 protocol.</p>
<p>The HTTP/2 protocol differs from HTTP/1.1 in a few ways:</p>
<ul>
  <li>It&#39;s a binary protocol rather than a text protocol. It can&#39;t be read and created manually. Despite this hurdle, it allows for the implementation of improved optimization techniques.</li>
  <li>It&#39;s a multiplexed protocol. Parallel requests can be made over the same connection, removing the constraints of the HTTP/1.x protocol.</li>
  <li>It compresses headers. As these are often similar among a set of requests, this removes the duplication and overhead of data transmitted.</li>
  <li>It allows a server to populate data in a client cache through a mechanism called the server push.</li>
</ul>
<p>Officially standardized in May 2015, HTTP/2 was incredibly successful. By May 2022, 46.4% of all websites used it (see <a href="https://w3techs.com/technologies/details/ce-http2" rel=" noopener">these stats</a>). High-traffic websites showed the most rapid adoption in an effort to save on data transfer overhead and subsequent budgets.</p>
<p>This rapid adoption was likely because HTTP/2 didn&#39;t require changes to websites and applications. To use it, only an up-to-date server that communicated with a recent browser was necessary. Only a limited set of groups was needed to trigger adoption, and as legacy browser and server versions were renewed, usage was naturally increased, without significant work for web developers.</p></div></section><section aria-labelledby="post-http2_evolution"><h2 id="post-http2_evolution"><a href="#post-http2_evolution" title="Permalink to Post-HTTP/2 evolution">Post-HTTP/2 evolution</a></h2><div><p>HTTP hasn&#39;t stopped evolving since the release of HTTP/2. Like with HTTP/1.x, HTTP&#39;s extensibility is still being used to add new features. Notably, we can cite new extensions of the HTTP protocol that appeared in 2016:</p>
<ul>
  <li>Support for <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Alt-Svc"><code>Alt-Svc</code></a> allowed the dissociation of the identification and the location of a given resource. This meant a smarter <a href="https://developer.mozilla.org/en-US/docs/Glossary/CDN">CDN</a> caching mechanism.</li>
  <li>The introduction of <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Client-Hints" title="This is a link to an unwritten page"><code>Client-Hints</code></a> allowed the browser or client to proactively communicate information about its requirements and hardware constraints to the server.</li>
  <li>The introduction of security-related prefixes in the <a href="https://developer.mozilla.org/en-US/docs/Web/HTTP/Headers/Cookie"><code>Cookie</code></a> header helped guarantee that secure cookies couldn&#39;t be altered.</li>
</ul>
<p>This evolution of HTTP has lead to the creation of many applications and has driven the adoption of the protocol. The environment in which HTTP is used today is quite different from that of the early 1990s. HTTP&#39;s original design proved to be scalable, allowing the web to evolve over a quarter of a century. By fixing flaws and retaining the flexibility and extensibility that made HTTP such a success, the adoption of HTTP/2 points to a bright future for the protocol.</p></div></section><section aria-labelledby="http3_-_http_over_quic"><h2 id="http3_-_http_over_quic"><a href="#http3_-_http_over_quic" title="Permalink to HTTP/3 - HTTP over QUIC">HTTP/3 - HTTP over QUIC</a></h2><div>
<p>The next major version of HTTP, HTTP/3, will use <a href="https://developer.mozilla.org/en-US/docs/Glossary/QUIC">QUIC</a> instead <a href="https://developer.mozilla.org/en-US/docs/Glossary/TCP">TCP</a>/<a href="https://developer.mozilla.org/en-US/docs/Glossary/TLS">TLS</a> for the transport layer portion.</p>
<p>See <a href="https://bugzilla.mozilla.org/show_bug.cgi?id=1158011" rel=" noopener">bug 1158011</a> for implementation status in Firefox.</p></div></section></article></div></div>
  </body>
</html>
