<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www2.dmst.aueb.gr/dds/sw/dgsh/">Original</a>
    <h1>dgsh – Directed Graph Shell</h1>
    
    <div id="readability-page-1" class="page"><div>
     <!-- span4 -->
    <div>

<!-- About {{{1
================================================== -->
<section id="intro">
  
<p>
The directed graph shell, <em>dgsh</em>
(<a href="https://en.wiktionary.org/wiki/Appendix:English_pronunciation">pronounced</a> /dæɡʃ/ — <em>dagsh</em>),
provides an expressive way to construct
sophisticated and efficient big data set and stream processing pipelines
using existing Unix tools as well as custom-built components.
It is a Unix-style shell (based on <em>bash</em>)
allowing the specification of pipelines
with non-linear non-uniform operations.
These form a directed acyclic process graph,
which is typically executed by multiple processor cores,
thus increasing the operation&#39;s processing throughput.
</p>
<p>
If you want to get a feeling on how <em>dgsh</em> works in practice,
skip right down to the <a href="#examples">examples</a> section.
</p>
<p>
For a more formal introduction to <em>dgsh</em> or to cite it in your work,
see:</p>
</section> <!-- Introduction -->

<section id="ipc"> <!-- {{{2 -->
<h2>Inter-process communication</h2>
<p>
<em>Dgsh</em> provides two new ways
for expressing inter-process communication.

</p>
<dl>
<dt>Multipipes</dt><dd> are expressed as usual Unix pipelines,
but can connect commands with more than one output or input channel.
As an example, the <code>comm</code> command supplied with <em>dgsh</em>
expects two input channels and produces on its output three
output channels: the lines appearing only in first (sorted) channel,
the lines appearing only in the second channel,
and the lines appearing in both.
Connecting the output of the <code>comm</code> command to the
<code>cat</code> command supplied with <em>dgsh</em>
will make the three outputs appear in sequence,
while connecting it to the
<code>paste</code> command supplied with <em>dgsh</em>
will make the output appear in its customary format.
</dd>

<dt>Multipipe blocks {{ ... }}</dt><dd>
a) send (multiple) input streams
received on their input side to the asynchronously-running
processes that reside within the block, and,
b) pass the output produced by the processes within the block as
(multiple) streams on their output side.
Multipipe blocks typically receive input from more than one channel
and produce more than one output channel.
For example, a multipipe block that runs <code>md5sum</code> and <code>wc -c</code>
receives two inputs and produces two outputs:
the MD5 hash of its input and the input&#39;s size.
Data to multipipe blocks are typically provided with a
<em>dgsh</em>-aware version of <code>tee</code> and collected by
<em>dgsh</em>-aware versions of programs such as
<code>cat</code> and <code>paste</code>.
</dd>

<dt>Stored values</dt> <dd>offer a convenient way for communicating
computed values between arbitrary processes on the graph.
They allow the storage of a data stream&#39;s
last record into a named buffer.
This record can be later retrieved asynchronously by one or more readers.
Data in a stored value can be piped into a process or out of it, or it can be read
using the shell&#39;s command output substitution syntax.
Stored values are implemented internally through Unix-domain sockets,
a background-running store program, <code>dgsh-writeval</code>, and
a reader program, <code>dgsh-readval</code>.
The behavior of a stored value&#39;s IO can be modified by adding flags to
<code>dgsh-writeval</code> and <code>dgsh-readval</code>.
</dd>
</dl>
</section>

<section id="syntax"> <!-- {{{2 -->
<h2>Syntax</h2>
<p>
A <em>dgsh</em> script follows the syntax of a <em>bash</em>(1) shell
script with the addition of <em>multipipe</em> blocks.
A multipipe block contains one or more <em>dgsh</em> simple commands,
other multipipe blocks, or pipelines of the previous two types of commands.
The commands in a multipipe block
are executed asynchronously (in parallel, in the background).
Data may be redirected or piped into and out of a multipipe block.
With multipipe blocks <em>dgsh</em> scripts form directed acyclic process graphs.
It follows from the above description that
multipipe blocks can be recursively composed.
</p>

<p>
As a simple example consider running the following command
directly within <em>dgsh</em>
</p>
<pre>{{ echo hello &amp; echo world &amp; }} | paste
</pre>
<p>
or by invoking <code>dgsh</code> with the command as an argument.
</p>
<pre>dgsh -c &#39;{{ echo hello &amp; echo world &amp; }} | paste&#39;
</pre>
<p>
The command will run <em>paste</em> with input from the two
<em>echo</em> processes to output <code>hello world</code>.
This is equivalent to running the following <em>bash</em> command,
but with the flow of data appearing in the natural left-to-right order.
</p>
<pre>paste &lt;(echo hello) &lt;(echo world)
</pre>

<p>
In the following larger example, which compares the performance of
different compression utilities, the script&#39;s standard input
is distributed to
three compression utilities (<em>xz</em>, <em>bzip2</em>, and <em>gzip</em>),
to assess their performance, and also to
<em>file</em> and <em>wc</em> to report the input data&#39;s type and size.
The <em>printf</em> commands label the data of each processing type.
All eight commands pass their output
to the <code>cat</code> command, which gathers their outputs
in order.
</p>

<pre>tee |
{{
	printf &#39;File type:\t&#39;
	file -

	printf &#39;Original size:\t&#39;
	wc -c

	printf &#39;xz:\t\t&#39;
	xz -c | wc -c

	printf &#39;bzip2:\t\t&#39;
	bzip2 -c | wc -c

	printf &#39;gzip:\t\t&#39;
	gzip -c | wc -c
}} |
cat
</pre>

<p>
Formally, <em>dgsh</em> extends the syntax of the (modified) Unix Bourne-shell
when <code>bash</code> provided with the <code>--dgsh</code> argument
as follows.
</p>

<pre>&lt;dgsh_block&gt;     ::= &#39;{{&#39; &lt;dgsh_list&gt; &#39;}}&#39;

&lt;dgsh_list&gt;      ::= &lt;dgsh_list_item&gt; &#39;&amp;&#39;
                 &lt;dgsh_list_item&gt; &lt;dgsh_list&gt;

&lt;dgsh_list_item&gt; ::= &lt;simple_command&gt;
                 &lt;dgsh_block&gt;
                 &lt;dgsh_list_item&gt; &#39;|&#39; &lt;dgsh_list_item&gt;
</pre>
</section> <!-- syntax -->

<section id="tools"> <!-- {{{2 -->
<h2>Adapted tools</h2>
<p>
A number of Unix tools have been adapted to support multiple inputs
and outputs to match their natural capabilities.
This echoes a similar adaptation that was performed in the early
1970s when Unix and the shell got pipes and the pipeline syntax.
Many programs that worked with files were adjusted to work as filters.
The number of input and output channels of <em>dgsh</em>-compatible commands are
as follows, based on the supplied command-line arguments.
</p>
<table>
	<tbody><tr>
		<th>Tool</th>
		<th>Inputs</th>
		<th>Outputs</th>
		<th>Notes</th>
	</tr>
	<tr>
		<td>cat (<em>dgsh-tee</em>)</td>
		<td>0—N</td>
		<td>0—M</td>
		<td>No options are supported</td>
	</tr>
	<tr>
		<td>cmp</td>
		<td>0—2</td>
		<td>0—1</td>
		<td></td>
	</tr>
	<tr>
		<td>comm</td>
		<td>0—2</td>
		<td>0—3</td>
		<td>Output streams in order: lines only in first file, lines only in second one, and lines in both files</td>
	</tr>
	<tr>
		<td>cut</td>
		<td>0—1</td>
		<td>1—N</td>
		<td>With <code>--multistream</code> output each range into a different stream</td>
	</tr>
	<tr>
		<td>diff</td>
		<td>0—N</td>
		<td>1</td>
		<td>Typically two inputs. Compare an arbitrary number of input streams with the <code>--from-file</code> or <code>--to-file</code> options</td>
	</tr>
	<tr>
		<td>diff3</td>
		<td>0—3</td>
		<td>1</td>
		<td></td>
	</tr>
	<tr>
		<td>grep</td>
		<td>0—2</td>
		<td>0—4</td>
		<td>Available output streams (via arguments): matching files, non-matching files, matching lines, and non-matching lines</td>
	</tr>
	<tr>
		<td>join</td>
		<td>0—2</td>
		<td>1</td>
		<td></td>
	</tr>
	<tr>
		<td>paste</td>
		<td>0—N</td>
		<td>1</td>
		<td>Paste N input streams</td>
	</tr>
	<tr>
		<td>perm</td>
		<td>1—N</td>
		<td>1—N</td>
		<td>Rearrange the order of N input streams</td>
	</tr>
	<tr>
		<td>sort</td>
		<td>0—N</td>
		<td>0—1</td>
		<td>With the <code>-m</code> option, merge sort N input streams</td>
	</tr>
	<tr>
		<td>tee (<em>dgsh-tee</em>)</td>
		<td>0—N</td>
		<td>0—M</td>
		<td>Only the <code>-a</code> option is supported</td>
	</tr>
	<tr>
		<td>dgsh-readval</td>
		<td>0</td>
		<td>1</td>
		<td>Read a value from a socket</td>
	</tr>
	<tr>
		<td>dgsh-wrap</td>
		<td>0—N</td>
		<td>0—1</td>
		<td>Wrap non-dgsh commands and negotiate on their behalf</td>
	</tr>
	<tr>
		<td>dgsh-writeval</td>
		<td>1</td>
		<td>0</td>
		<td>Write a value to a socket</td>
	</tr>
</tbody></table>

<p>
In addition, POSIX user commands that receive no input
or only generate no output, when executed in a <em>dgsh</em> context
are wrapped to specify the corresponding input or output capability.
For example, an <code>echo</code> command in a multipipe block
will appear to receive no input, but will provide one output stream.
By default <code>dgsh</code> automatically wraps all other
commands as filters.
</p><dl>
<dt> Input-only </dt><dd>
read,
write.
</dd>
<dt> Output-only </dt><dd> </dd>
alias,
ar,
basename,
c99,
cal,
cflow,
command,
date,
df,
dirname,
du,
echo,
expr,
find,
getopts,
ipcrm,
jobs,
ls,
make,
man,
printf,
ps,
pwd,
tty,
type,
ulimit,
umask,
uname,
what,
who.
</dl>
<dt> No input and output </dt><dd> </dd>
dbg,
dcd,
dchgrp,
dchmod,
dchown,
dcp,
denv,
dfalse,
dfg,
dkill,
dlink,
dln,
dmesg,
dmkdir,
dmkfifo,
dmv,
dnewgrp,
dnice,
dnohup,
drenice,
drm,
drmdir,
dsleep,
dstrip,
dtest,
dtouch,
dtrue,
dunalias,
dunlink,
dwait,
dyacc.


<p>
Finally, note that any <em>dgsh</em> script will accept and generate
the number of inputs and outputs associated with the commands or
multipipe blocks at its two endpoints.
</p>
</section> <!-- Adapted tools -->


<!-- Downloading and installation {{{1
================================================== -->
<section id="download">
  

<p>
The <em>dgsh</em> suite has been tested under
Debian and Ubuntu Linux, FreeBSD, and Mac OS X.
A Cygwin port is underway.
</p>

<p>
An installation of <a href="http://www.graphviz.org/">GraphViz</a>
will allow you to visualize the <em>dgsh</em> graphs that you specify
in your programs.
</p>

    <section id="debian"> <!-- {{{2 -->
    <h2>Debian and Ubuntu GNU/Linux</h2>
    <section>
    <h3>Prerequisites</h3>
<p>
To compile and run <em>dgsh</em> you will need to have the following commands
installed on your system:
</p><pre>make automake gcc libtool pkg-config texinfo help2man autopoint bison check gperf 
git xz-utils gettext
</pre>

To test <em>dgsh</em> you will need to have the following commands
installed in your system:
<pre>wbritish wamerican libfftw3-dev csh
curl bzip2
</pre>

    <h3>Installation steps</h3>
<p>
Go through the following steps.
</p><ol>
<li>
Recursively clone the project&#39;s source code through its
<a href="https://github.com/dspinellis/dgsh">GitHub page</a>.
<pre>git clone --recursive https://github.com/dspinellis/dgsh.git
</pre>
</li>
<li>
Configure <em>bash</em> and the Unix tools adapted for <em>dgsh</em>.
<pre>make config
</pre>
</li>
<li>
Compile all programs.
<pre>make
</pre>
</li>
<li>
Install.
<pre>sudo make install
</pre>
</li>
</ol>

<p>
By default, the program and its documentation are installed under
<code>/usr/local</code>.
You can modify this by setting the <code>PREFIX</code> variable
in the `config` step, for example:
</p><pre>make PREFIX=$HOME config
make
make install
</pre>


    <h3>Testing</h3>
<p>

Issue the following command.
</p><pre>make test
</pre>


    </section>
    <section id="freebsd"> <!-- {{{2 -->
    <h2>FreeBSD</h2>
    <section>
    <h3>Prerequisites</h3>
<p>
To compile and run <em>dgsh</em> you will need to have the following packages
installed in your system:
</p><pre>devel/automake
devel/bison
devel/check
devel/git
devel/gmake
devel/gperf
misc/help2man
print/texinfo
shells/bash
</pre>

To test <em>dgsh</em> you will need to have the following ports
installed on your system:
<pre>archivers/bzip2
ftp/curl
</pre>

    <h3>Installation steps</h3>
<p>
Go through the following steps.
</p><ol>
<li>
Recursively clone the project&#39;s source code through its
<a href="https://github.com/dspinellis/dgsh">GitHub page</a>.
<pre>git clone --recursive https://github.com/dspinellis/dgsh.git
</pre>
</li>
<li>
Configure <em>bash</em> and the Unix tools adapted for <em>dgsh</em>.
<pre>gmake config
</pre>
</li>
<li>
Compile all programs.
<pre>gmake
</pre>
</li>
<li>
Install.
<pre>sudo gmake install
</pre>
</li>
</ol>

<p>
By default, the program and its documentation are installed under
<code>/usr/local</code>.
You can modify this by setting the <code>PREFIX</code> variable
in the `config` step, for example:
</p><pre>gmake PREFIX=$HOME config
gmake
gmake install
</pre>


    <h3>Testing</h3>
<p>

Issue the following command.
</p><pre>gmake test
</pre>


    </section>
</section>
</section>

<!-- Reference {{{1
================================================== -->
<section id="reference">
  
<p>
These are the manual pages for <em>dgsh</em>, the associated helper programs
and the API
in formats suitable for browsing and printing.
The commands are listed in the order of usefulness in everyday scenarios.
</p>
<dl>
<dt> dgsh </dt><dd> directed graph shell <a href="https://typesafety.net/rob/blog/dgsh.html">HTML</a>, <a href="https://typesafety.net/rob/blog/dgsh.pdf">PDF</a></dd>
<dt> dgsh-tee </dt><dd> buffer and copy or scatter standard input to one or more sinks <a href="https://typesafety.net/rob/blog/dgsh-tee.html">HTML</a>, <a href="https://typesafety.net/rob/blog/dgsh-tee.pdf">PDF</a></dd>
<dt> dgsh-wrap </dt><dd> allow any filter program to participate in an dgsh pipeline <a href="https://typesafety.net/rob/blog/dgsh-wrap.html">HTML</a>, <a href="https://typesafety.net/rob/blog/dgsh-wrap.pdf">PDF</a></dd>
<dt> dgsh-writeval </dt><dd> write values to a data store <a href="https://typesafety.net/rob/blog/dgsh-writeval.html">HTML</a>, <a href="https://typesafety.net/rob/blog/dgsh-writeval.pdf">PDF</a></dd>
<dt> dgsh-readval </dt><dd> data store client <a href="https://typesafety.net/rob/blog/dgsh-readval.html">HTML</a>, <a href="https://typesafety.net/rob/blog/dgsh-readval.pdf">PDF</a></dd>
<dt> dgsh-monitor </dt><dd> monitor data on a pipe <a href="https://typesafety.net/rob/blog/dgsh-monitor.html">HTML</a>, <a href="https://typesafety.net/rob/blog/dgsh-monitor.pdf">PDF</a></dd>
<dt> dgsh-parallel </dt><dd> create a semi-homongeneous dgsh parallel processing block <a href="https://typesafety.net/rob/blog/dgsh-parallel.html">HTML</a>, <a href="https://typesafety.net/rob/blog/dgsh-parallel.pdf">PDF</a></dd>
<dt> perm </dt><dd> permute inputs to outputs <a href="https://typesafety.net/rob/blog/perm.html">HTML</a>, <a href="https://typesafety.net/rob/blog/perm.pdf">PDF</a></dd>
<dt> dgsh-httpval </dt><dd> provide data store values through HTTP <a href="https://typesafety.net/rob/blog/dgsh-httpval.html">HTML</a>, <a href="https://typesafety.net/rob/blog/dgsh-httpval.pdf">PDF</a></dd>
<dt> dgsh-merge-sum </dt><dd> merge key value pairs, summing the values <a href="https://typesafety.net/rob/blog/dgsh-merge-sum.html">HTML</a>, <a href="https://typesafety.net/rob/blog/dgsh-merge-sum.pdf">PDF</a></dd>
<dt> dgsh-conc </dt><dd> input or output pipe concentrator for <em>dgsh</em> negotiation (used internally) <a href="https://typesafety.net/rob/blog/dgsh-conc.html">HTML</a>, <a href="https://typesafety.net/rob/blog/dgsh-conc.pdf">PDF</a></dd>
<dt> dgsh-enumerate </dt><dd> enumerate an arbitrary number of output channels (demonstration and <a href="http://istlab.dmst.aueb.gr/~dds/dgsh-egg.sh">debugging</a> tool) <a href="https://typesafety.net/rob/blog/dgsh-enumerate.html">HTML</a>, <a href="https://typesafety.net/rob/blog/dgsh-enumerate.pdf">PDF</a></dd>
<dt> dgsh_negotiate </dt><dd> API for <em>dgsh</em>-compatible
programs to specify and obtain dgsh I/O file descriptors
<a href="https://typesafety.net/rob/blog/dgsh_negotiate.html">HTML</a>, <a href="https://typesafety.net/rob/blog/dgsh_negotiate.pdf">PDF</a></dd>
</dl>
</section>


<!--</th>
<th>Examples</th>
<th>{{{1
==================================================</th>
<th>-->
<section id="examples">
  

<section id="compress-compare"> <!-- {{{2 -->
<h2>Compression benchmark</h2>
</section>
<img src="https://typesafety.net/rob/blog/compress-compare-pretty.png" alt="Compression benchmark"/>
<!-- Extracted description -->
<p>
Report file type, length, and compression performance for
data received from the standard input.  The data never touches the
disk.
Demonstrates the use of an output multipipe to source many commands
from one followed by an input multipipe to sink to one command
the output of many and the use of dgsh-tee that is used both to
propagate the same input to many commands and collect output from
many commands orderly in a way that is transparent to users.
</p>
<!-- Extracted code -->
<pre>#!/usr/bin/env dgsh

tee |
{{
	printf &#39;File type:\t&#39;
	file -

	printf &#39;Original size:\t&#39;
	wc -c

	printf &#39;xz:\t\t&#39;
	xz -c | wc -c

	printf &#39;bzip2:\t\t&#39;
	bzip2 -c | wc -c

	printf &#39;gzip:\t\t&#39;
	gzip -c | wc -c
}} |
cat
</pre>
<section id="commit-stats"> <!-- {{{2 -->
<h2>Git commit statistics</h2>
</section>
<img src="https://typesafety.net/rob/blog/commit-stats-pretty.png" alt="Git commit statistics"/>
<!-- Extracted description -->
<p>
Process the Git history, and list the authors and days of the week
ordered by the number of their commits.
Demonstrates streams and piping through a function.
</p>
<!-- Extracted code -->
<pre>#!/usr/bin/env dgsh

forder()
{
	sort |
	uniq -c |
	sort -rn
}

git log --format=&#34;%an:%ad&#34; --date=default &#34;$@&#34; |
tee |
{{
	echo &#34;Authors ordered by number of commits&#34;
	# Order by frequency
	awk -F: &#39;{print $1}&#39; |
	forder

	echo &#34;Days ordered by number of commits&#34;
	# Order by frequency
	awk -F: &#39;{print substr($2, 1, 3)}&#39; |
	forder
}} |
cat
</pre>
<section id="code-metrics"> <!-- {{{2 -->
<h2>C code metrics</h2>
</section>
<img src="https://typesafety.net/rob/blog/code-metrics-pretty.png" alt="C code metrics"/>
<!-- Extracted description -->
<p>
Process a directory containing C source code, and produce a summary
of various metrics.
Demonstrates nesting, commands without input.
</p>
<!-- Extracted code -->
<pre>#!/usr/bin/env dgsh

{{
	# C and header code
	find &#34;$@&#34; \( -name \*.c -or -name \*.h \) -type f -print0 |
	tee |
	{{

		# Average file name length
		# Convert to newline separation for counting
		echo -n &#39;FNAMELEN: &#39;
		tr \\0 \\n |
		# Remove path
		sed &#39;s|^.*/||&#39; |
		# Maintain average
		awk &#39;{s += length($1); n++} END {
			if (n&gt;0)
				print s / n;
			else
				print 0; }&#39;

		xargs -0 /bin/cat |
		tee |
		{{
			# Remove strings and comments
			sed &#39;s/#/@/g;s/\\[\\&#34;&#39;\&#39;&#39;]/@/g;s/&#34;[^&#34;]*&#34;/&#34;&#34;/g;&#39;&#34;s/&#39;[^&#39;]*&#39;/&#39;&#39;/g&#34; |
			cpp -P |
			tee |
			{{
				# Structure definitions
				echo -n &#39;NSTRUCT: &#39;
				egrep -c &#39;struct[   ]*{|struct[   ]*[a-zA-Z_][a-zA-Z0-9_]*[       ]*{&#39;
				#}} (match preceding openings)

				# Type definitions
				echo -n &#39;NTYPEDEF: &#39;
				grep -cw typedef

				# Use of void
				echo -n &#39;NVOID: &#39;
				grep -cw void

				# Use of gets
	  			echo -n &#39;NGETS: &#39;
	  			grep -cw gets

				# Average identifier length
				echo -n &#39;IDLEN: &#39;
				tr -cs &#39;A-Za-z0-9_&#39; &#39;\n&#39; |
				sort -u |
				awk &#39;/^[A-Za-z]/ { len += length($1); n++ } END {
					if (n&gt;0)
						print len / n;
					else
						print 0; }&#39;
			}}

			# Lines and characters
			echo -n &#39;CHLINESCHAR: &#39;
			wc -lc |
			awk &#39;{OFS=&#34;:&#34;; print $1, $2}&#39;

			# Non-comment characters (rounded thousands)
			# -traditional avoids expansion of tabs
			# We round it to avoid failing due to minor
			# differences between preprocessors in regression
			# testing
			echo -n &#39;NCCHAR: &#39;
			sed &#39;s/#/@/g&#39; |
			cpp -traditional -P |
			wc -c |
			awk &#39;{OFMT = &#34;%.0f&#34;; print $1/1000}&#39;

			# Number of comments
			echo -n &#39;NCOMMENT: &#39;
			egrep -c &#39;/\*|//&#39;

			# Occurences of the word Copyright
			echo -n &#39;NCOPYRIGHT: &#39;
			grep -ci copyright
		}}
	}}

	# C files
	find &#34;$@&#34; -name \*.c -type f -print0 |
	tee |
	{{
		# Convert to newline separation for counting
		tr \\0 \\n |
		tee |
		{{
			# Number of C files
			echo -n &#39;NCFILE: &#39;
			wc -l

			# Number of directories containing C files
			echo -n &#39;NCDIR: &#39;
			sed &#39;s,/[^/]*$,,;s,^.*/,,&#39; |
			sort -u |
			wc -l
		}}

		# C code
		xargs -0 /bin/cat |
		tee |
		{{
			# Lines and characters
			echo -n &#39;CLINESCHAR: &#39;
			wc -lc |
			awk &#39;{OFS=&#34;:&#34;; print $1, $2}&#39;

			# C code without comments and strings
			sed &#39;s/#/@/g;s/\\[\\&#34;&#39;\&#39;&#39;]/@/g;s/&#34;[^&#34;]*&#34;/&#34;&#34;/g;&#39;&#34;s/&#39;[^&#39;]*&#39;/&#39;&#39;/g&#34; |
			cpp -P |
			tee |
			{{
				# Number of functions
				echo -n &#39;NFUNCTION: &#39;
				grep -c &#39;^{&#39;

				# Number of gotos
				echo -n &#39;NGOTO: &#39;
				grep -cw goto

				# Occurrences of the register keyword
				echo -n &#39;NREGISTER: &#39;
				grep -cw register

				# Number of macro definitions
				echo -n &#39;NMACRO: &#39;
				grep -c &#39;@[   ]*define[   ][   ]*[a-zA-Z_][a-zA-Z0-9_]*(&#39;
				# Number of include directives
				echo -n &#39;NINCLUDE: &#39;
				grep -c &#39;@[   ]*include&#39;

				# Number of constants
				echo -n &#39;NCONST: &#39;
				grep -ohw &#39;[0-9][x0-9][0-9a-f]*&#39; | wc -l

			}}
		}}
	}}

	# Header files
	echo -n &#39;NHFILE: &#39;
	find &#34;$@&#34; -name \*.h -type f |
	wc -l

}} |
# Gather and print the results
cat
</pre>
<section id="duplicate-files"> <!-- {{{2 -->
<h2>Find duplicate files</h2>
</section>
<img src="https://typesafety.net/rob/blog/duplicate-files-pretty.png" alt="Find duplicate files"/>
<!-- Extracted description -->
<p>
List the names of duplicate files in the specified directory.
Demonstrates the combination of streams with a relational join.
</p>
<!-- Extracted code -->
<pre>#!/usr/bin/env dgsh

# Create list of files
find &#34;$@&#34; -type f |

# Produce lines of the form
# MD5(filename)= 811bfd4b5974f39e986ddc037e1899e7
xargs openssl md5 |

# Convert each line into a &#34;filename md5sum&#34; pair
sed &#39;s/^MD5(//;s/)= / /&#39; |

# Sort by MD5 sum
sort -k2 |

tee |
{{

	# Print an MD5 sum for each file that appears more than once
	awk &#39;{print $2}&#39; | uniq -d

	# Promote the stream to gather it
	cat
}} |
# Join the repeated MD5 sums with the corresponding file names
# Join expects two inputs, second will come from scatter
# XXX make streaming input identifiers transparent to users
join -2 2 |

# Output same files on a single line
awk &#39;
BEGIN {ORS=&#34;&#34;}
$1 != prev &amp;&amp; prev {print &#34;\n&#34;}
END {if (prev) print &#34;\n&#34;}
{if (prev) print &#34; &#34;; prev = $1; print $2}&#39;
</pre>
<section id="spell-highlight"> <!-- {{{2 -->
<h2>Highlight misspelled words</h2>
</section>
<img src="https://typesafety.net/rob/blog/spell-highlight-pretty.png" alt="Highlight misspelled words"/>
<!-- Extracted description -->
<p>
Highlight the words that are misspelled in the command&#39;s first
argument.
Demonstrates stream processing with multipipes and
the avoidance of pass-through constructs to avoid deadlocks.
</p>
<!-- Extracted code -->
<pre>#!/usr/bin/env dgsh

export LC_ALL=C

tee |
{{
	# Find errors
	{{
		# Obtain list of words in text
		tr -cs A-Za-z \\n |
		tr A-Z a-z |
		sort -u

		# Ensure dictionary is compatibly sorted
		sort /usr/share/dict/words
	}} |
	# List errors as a set difference
	comm -23

	# Pass through text
	cat
}} |
grep --fixed-strings --file=- --ignore-case --color --word-regex --context=2
</pre>
<section id="word-properties"> <!-- {{{2 -->
<h2>Word properties</h2>
</section>
<img src="https://typesafety.net/rob/blog/word-properties-pretty.png" alt="Word properties"/>
<!-- Extracted description -->
<p>
Read text from the standard input and list words
containing a two-letter palindrome, words containing
four consonants, and words longer than 12 characters.
</p>
<!-- Extracted code -->
<pre>#!/usr/bin/env dgsh

# Consistent sorting across machines
export LC_ALL=C

# Stream input from file
cat $1 |

# Split input one word per line
tr -cs a-zA-Z \\n |
# Create list of unique words
sort -u |
tee |
{{
	# Pass through the original words
	cat

	# List two-letter palindromes
	sed &#39;s/.*\(.\)\(.\)\2\1.*/p: \1\2-\2\1/;t
		g&#39;

	# List four consecutive consonants
	sed -E &#39;s/.*([^aeiouyAEIOUY]{4}).*/c: \1/;t
		g&#39;

	# List length of words longer than 12 characters
	awk &#39;{if (length($1) &gt; 12) print &#34;l:&#34;, length($1);
		else print &#34;&#34;}&#39;
}} |
# Paste the four streams side-by-side
paste |
# List only words satisfying one or more properties
fgrep :
</pre>
<section id="web-log-report"> <!-- {{{2 -->
<h2>Web log reporting</h2>
</section>
<img src="https://typesafety.net/rob/blog/web-log-report-pretty.png" alt="Web log reporting"/>
<!-- Extracted description -->
<p>
Creates a report for a fixed-size web log file read from the standard input.
Demonstrates the combined use of multipipe blocks, writeval and readval
to store and retrieve values, and functions in the scatter block.
Used to measure throughput increase achieved through parallelism.
</p>
<!-- Extracted code -->
<pre>#!/usr/bin/env dgsh

# Output the top X elements of the input by the number of their occurrences
# X is the first argument
toplist()
{
	uniq -c | sort -rn | head -$1
	echo
}

# Output the argument as a section header
header()
{
	echo
	echo &#34;$1&#34;
	echo &#34;$1&#34; | sed &#39;s/./-/g&#39;
}

# Consistent sorting
export LC_ALL=C

export -f toplist
export -f header


if [ -z &#34;${DGSH_DRAW_EXIT}&#34; ]
then
cat &lt;&lt;EOF
			WWW server statistics
			=====================

Summary
-------
EOF
fi

tee |
{{
	# Number of accesses
	echo -n &#39;Number of accesses: &#39;
	dgsh-readval -l -s nAccess

	# Number of transferred bytes
	awk &#39;{s += $NF} END {print s}&#39; |
	tee |
	{{
		echo -n &#39;Number of Gbytes transferred: &#39;
		awk &#39;{print $1 / 1024 / 1024 / 1024}&#39;

		dgsh-writeval -s nXBytes
	}}

	echo -n &#39;Number of hosts: &#39;
	dgsh-readval -l -q -s nHosts

	echo -n &#39;Number of domains: &#39;
	dgsh-readval -l -q -s nDomains

	echo -n &#39;Number of top level domains: &#39;
	dgsh-readval -l -q -s nTLDs

	echo -n &#39;Number of different pages: &#39;
	dgsh-readval -l -q -s nUniqPages

	echo -n &#39;Accesses per day: &#39;
	dgsh-readval -l -q -s nDayAccess

	echo -n &#39;MBytes per day: &#39;
	dgsh-readval -l -q -s nDayMB

	# Number of log file bytes
	echo -n &#39;MBytes log file size: &#39;
	wc -c |
	awk &#39;{print $1 / 1024 / 1024}&#39;

	# Host names
	awk &#39;{print $1}&#39; |
	tee |
	{{
		# Number of accesses
		wc -l | dgsh-writeval -s nAccess

		# Sorted hosts
		sort |
		tee |
		{{

			# Unique hosts
			uniq |
			tee |
			{{
				# Number of hosts
				wc -l | dgsh-writeval -s nHosts

				# Number of TLDs
				awk -F. &#39;$NF !~ /[0-9]/ {print $NF}&#39; |
				sort -u |
				wc -l |
				dgsh-writeval -s nTLDs
			}}

			# Top 10 hosts
			{{
				 call &#39;header &#34;Top 10 Hosts&#34;&#39;
				 call &#39;toplist 10&#39;
			}}
		}}

		# Top 20 TLDs
		{{
			call &#39;header &#34;Top 20 Level Domain Accesses&#34;&#39;
			awk -F. &#39;$NF !~ /^[0-9]/ {print $NF}&#39; |
			sort |
			call &#39;toplist 20&#39;
		}}

		# Domains
		awk -F. &#39;BEGIN {OFS = &#34;.&#34;}
		            $NF !~ /^[0-9]/ {$1 = &#34;&#34;; print}&#39; |
		sort |
		tee |
		{{
			# Number of domains
			uniq |
			wc -l |
			dgsh-writeval -s nDomains

			# Top 10 domains
			{{
				 call &#39;header &#34;Top 10 Domains&#34;&#39;
				 call &#39;toplist 10&#39;
			}}
		}}
	}}

	# Hosts by volume
	{{
		call &#39;header &#34;Top 10 Hosts by Transfer&#34;&#39;
		awk &#39;    {bytes[$1] += $NF}
		END {for (h in bytes) print bytes[h], h}&#39; |
		sort -rn |
		head -10
	}}

	# Sorted page name requests
	awk &#39;{print $7}&#39; |
	sort |
	tee |
	{{

		# Top 20 area requests (input is already sorted)
		{{
			 call &#39;header &#34;Top 20 Area Requests&#34;&#39;
			 awk -F/ &#39;{print $2}&#39; |
			 call &#39;toplist 20&#39;
		}}

		# Number of different pages
		uniq |
		wc -l |
		dgsh-writeval -s nUniqPages

		# Top 20 requests
		{{
			 call &#39;header &#34;Top 20 Requests&#34;&#39;
			 call &#39;toplist 20&#39;
		}}
	}}

	# Access time: dd/mmm/yyyy:hh:mm:ss
	awk &#39;{print substr($4, 2)}&#39; |
	tee |
	{{

		# Just dates
		awk -F: &#39;{print $1}&#39; |
		tee |
		{{

			# Number of days
			uniq |
			wc -l |
			tee |
			{{
				awk &#39;
					BEGIN {
					&#34;dgsh-readval -l -x -s nAccess&#34; | getline NACCESS;}
					{print NACCESS / $1}&#39; |
				dgsh-writeval -s nDayAccess

				awk &#39;
					BEGIN {
					&#34;dgsh-readval -l -x -q -s nXBytes&#34; | getline NXBYTES;}
					{print NXBYTES / $1 / 1024 / 1024}&#39; |
				dgsh-writeval -s nDayMB
			}}

			{{
				 call &#39;header &#34;Accesses by Date&#34;&#39;
				 uniq -c
			}}

			# Accesses by day of week
			{{
				 call &#39;header &#34;Accesses by Day of Week&#34;&#39;
				 sed &#39;s|/|-|g&#39; |
				 call &#39;(date -f - +%a 2&gt;/dev/null || gdate -f - +%a)&#39; |
				 sort |
				 uniq -c |
				 sort -rn
			}}
		}}

		# Hour
		{{
			call &#39;header &#34;Accesses by Local Hour&#34;&#39;
			awk -F: &#39;{print $2}&#39; |
			sort |
			uniq -c
		}}
	}}
	dgsh-readval -q -s nAccess
}} |
cat
</pre>
<section id="text-properties"> <!-- {{{2 -->
<h2>Text properties</h2>
</section>
<img src="https://typesafety.net/rob/blog/text-properties-pretty.png" alt="Text properties"/>
<!-- Extracted description -->
<p>
Read text from the standard input and create files
containing word, character, digram, and trigram frequencies.
</p>
<!-- Extracted code -->
<pre>#!/usr/bin/env dgsh

# Consistent sorting across machines
export LC_ALL=C


# Convert input into a ranked frequency list
ranked_frequency()
{
	awk &#39;{count[$1]++} END {for (i in count) print count[i], i}&#39; |
	# We want the standard sort here
	sort -rn
}

# Convert standard input to a ranked frequency list of specified n-grams
ngram()
{
	local N=$1

	perl -ne &#39;for ($i = 0; $i &lt; length($_) - &#39;$N&#39;; $i++) {
		print substr($_, $i, &#39;$N&#39;), &#34;\n&#34;;
	}&#39; |
	ranked_frequency
}

export -f ranked_frequency
export -f ngram

tee |
{{
	# Split input one word per line
	tr -cs a-zA-Z \\n |
	tee |
	{{
		# Digram frequency
		call &#39;ngram 2 &gt;digram.txt&#39;
		# Trigram frequency
		call &#39;ngram 3 &gt;trigram.txt&#39;
		# Word frequency
		call &#39;ranked_frequency &gt;words.txt&#39;
	}}

	# Store number of characters to use in awk below
	wc -c |
	dgsh-writeval -s nchars

	# Character frequency
	sed &#39;s/./&amp;\
/g&#39; |
	# Print absolute
	call &#39;ranked_frequency&#39; |
	awk &#39;BEGIN {
		&#34;dgsh-readval -l -x -q -s nchars&#34; | getline NCHARS
		OFMT = &#34;%.2g%%&#34;}
		{print $1, $2, $1 / NCHARS * 100}&#39; &gt; character.txt
}}
</pre>
<section id="static-functions"> <!-- {{{2 -->
<h2>C/C++ symbols that should be static</h2>
</section>
<img src="https://typesafety.net/rob/blog/static-functions-pretty.png" alt="C/C++ symbols that should be static"/>
<!-- Extracted description -->
<p>
Given as an argument a directory containing object files, show which
symbols are declared with global visibility, but should have been
declared with file-local (static) visibility instead.
Demonstrates the use of dgsh-capable comm (1) to combine data from
two sources.
</p>
<!-- Extracted code -->
<pre>#!/usr/bin/env dgsh

# Find object files
find &#34;$1&#34; -name \*.o |

# Print defined symbols
xargs nm |

tee |
{{

  # List all defined (exported) symbols
  awk &#39;NF == 3 &amp;&amp; $2 ~ /[A-Z]/ {print $3}&#39; | sort

  # List all undefined (imported) symbols
  awk &#39;$1 == &#34;U&#34; {print $2}&#39; | sort

}} |
# Print exports that are not imported
comm -23
</pre>
<section id="map-hierarchy"> <!-- {{{2 -->
<h2>Hierarchy map</h2>
</section>
<img src="https://typesafety.net/rob/blog/map-hierarchy-pretty.png" alt="Hierarchy map"/>
<!-- Extracted description -->
<p>
Given two directory hierarchies A and B passed as input arguments
(where these represent a project at different parts of its lifetime)
copy the files of hierarchy A to a new directory, passed as a third
argument, corresponding to the structure of directories in B.
Demonstrates the use of <em>join</em> to process results from two
inputs and the use of <em>gather</em> to order asynchronously
produced results.
</p>
<!-- Extracted code -->
<pre>#!/usr/bin/env dgsh

if [ -z &#34;${DGSH_DRAW_EXIT}&#34; -a \( ! -d &#34;$1&#34; -o ! -d &#34;$2&#34; -o -z &#34;$3&#34; \) ]
then
  echo &#34;Usage: $0 dir-1 dir-2 new-dir-name&#34; 1&gt;&amp;2
  exit 1
fi

NEWDIR=&#34;$3&#34;

export LC_ALL=C

line_signatures()
{
  find $1 -type f -name &#39;*.[chly]&#39; -print |
  # Split path name into directory and file
  sed &#39;s|\(.*\)/\([^/]*\)|\1 \2|&#39; |
  while read dir file
  do
    # Print &#34;directory filename content&#34; of lines with
    # at least one alphabetic character
    # The fields are separated by  and 
    sed -n &#34;/[a-z]/s|^|$dir$file|p&#34; &#34;$dir/$file&#34;
  done |
  # Error: multi-character tab &#39;\001\001&#39;
  sort -T `pwd` -t -k 2
}


export -f line_signatures


{{
  # Generate the signatures for the two hierarchies
  call &#39;line_signatures &#34;$1&#34;&#39; -- &#34;$1&#34;
  call &#39;line_signatures &#34;$1&#34;&#39; -- &#34;$2&#34;
}} |

# Join signatures on file name and content
join -t -1 2 -2 2 |

# Print filename dir1 dir2
sed &#39;s///g&#39; |
awk -F &#39;BEGIN{OFS=&#34; &#34;}{print $1, $3, $4}&#39; |

# Unique occurrences
sort -u |
tee |
{{
  # Commands to copy
  awk &#39;{print &#34;mkdir -p &#39;$NEWDIR&#39;/&#34; $3 &#34;&#34;}&#39; |
  sort -u

  awk &#39;{print &#34;cp &#34; $2 &#34;/&#34; $1 &#34; &#39;$NEWDIR&#39;/&#34; $3 &#34;/&#34; $1 &#34;&#34;}&#39;
}} |
# Order: first make directories, then copy files
# TODO: dgsh-tee does not pass along first incoming stream
cat |
sh
</pre>
<section id="committer-plot"> <!-- {{{2 -->
<h2>Plot Git committer activity over time</h2>
</section>
<img src="https://typesafety.net/rob/blog/committer-plot-pretty.png" alt="Plot Git committer activity over time"/>
<!-- Extracted description -->
<p>
Process the Git history, and create two PNG diagrams depicting
committer activity over time. The most active committers appear
at the center vertical of the diagram.
Demonstrates image processing, mixining of synchronous and
asynchronous processing in a scatter block, and the use of an
dgsh-compliant join command.
</p>
<!-- Extracted code -->
<pre>#!/usr/bin/env dgsh

# Commit history in the form of ascending Unix timestamps, emails
git log --pretty=tformat:&#39;%at %ae&#39; |
# Filter records according to timestamp: keep (100000, now) seconds
awk &#39;NF == 2&amp; $1 &gt; 100000&amp; $1 &lt; &#39;`date +%s` |
sort -n |
tee |
{{
	{{
		# Calculate number of committers
		awk &#39;{print $2}&#39; |
		sort -u |
		wc -l |
		tee |
		{{
			dgsh-writeval -s committers1

			dgsh-writeval -s committers2
			dgsh-writeval -s committers3
		}}

		# Calculate last commit timestamp in seconds
		tail -1 |
		awk &#39;{print $1}&#39;

		# Calculate first commit timestamp in seconds
		head -1 |
		awk &#39;{print $1}&#39;
	}} |
	# Gather last and first commit timestamp
	cat |
	# Make one space-delimeted record
	tr &#39;\n&#39; &#39; &#39; |
	# Compute the difference in days
	awk &#39;{print int(($1 - $2) / 60 / 60 / 24)}&#39; |
	# Store number of days
	dgsh-writeval -s days

	sort -k2	# &lt;timestamp, email&gt;

	# Place committers left/right of the median
	# according to the number of their commits
	awk &#39;{print $2}&#39; |
	sort |
	uniq -c |
	sort -n |
	awk &#39;
		BEGIN {
			&#34;dgsh-readval -l -x -q -s committers1&#34; | getline NCOMMITTERS
			l = 0; r = NCOMMITTERS;}
		{print NR % 2 ? l++ : --r, $2}&#39; |
	sort -k2	# &lt;left/right, email&gt;

}} |
# Join committer positions with commit time stamps
# based on committer email
join -j 2 |		# &lt;email, timestamp, left/right&gt;
# Order by timestamp
sort -k 2n |
tee |
{{
	# Create portable bitmap
	echo &#39;P1&#39;

	{{
		dgsh-readval -l -q -s committers2
		dgsh-readval -l -q -s days
	}} |
	cat |
	tr &#39;\n&#39; &#39; &#39; |
	awk &#39;{print $1, $2}&#39;

	perl -na -e &#39;
	  BEGIN {
	    open(my $ncf, &#34;-|&#34;, &#34;dgsh-readval -l -x -q -s committers3&#34;);
	    $ncommitters = &lt;$ncf&gt;;
	    @empty[$ncommitters - 1] = 0; @committers = @empty;
	  }
	  sub out {
		  print join(&#34;&#34;, map($_ ? &#34;1&#34; : &#34;0&#34;, @committers)), &#34;\n&#34;;
	  }

	  $day = int($F[1] / 60 / 60 / 24);
	  $pday = $day if (!defined($pday));

	  while ($day != $pday) {
		  out();
		  @committers = @empty;
		  $pday++;
	  }

	  $committers[$F[2]] = 1;

	  END { out(); }
	&#39;
}} |
cat |
# Enlarge points into discs through morphological convolution
pgmmorphconv -erode &lt;(
cat &lt;&lt;EOF
P1
7 7
1 1 1 0 1 1 1
1 1 0 0 0 1 1
1 0 0 0 0 0 1
0 0 0 0 0 0 0
1 0 0 0 0 0 1
1 1 0 0 0 1 1
1 1 1 0 1 1 1
EOF
) |
tee |
{{
	# Full-scale image
	pnmtopng &gt;large.png
	# A smaller image
	pamscale -width 640 |
	pnmtopng &gt;small.png
}}
</pre>
<section id="parallel-word-count"> <!-- {{{2 -->
<h2>Parallel word count</h2>
</section>
<img src="https://typesafety.net/rob/blog/parallel-word-count-pretty.png" alt="Parallel word count"/>
<!-- Extracted description -->
<p>
Count number of times each word appears in the specified input file(s)
Demonstrates parallel execution mirroring the Hadoop WordCount example
via the dgsh-parallel command.
In contrast to GNU parallel, the block generated by dgsh-parallel
has N input and output streams, which can be combined by any
dgsh-compatible tool, such as dgsh-merge-sum or sort -m.
</p>
<!-- Extracted code -->
<pre>#!/usr/bin/env dgsh

# Number of processes
N=8

# Collation order for sorting
export LC_ALL=C

# Scatter input
dgsh-tee -s |
# Emulate Java&#39;s default StringTokenizer, sort, count
dgsh-parallel -n $N &#34;tr -s &#39; \t\n\r\f&#39; &#39;\n&#39; | sort -S 512M | uniq -c&#34; |
# Merge sorted counts by providing N input channels
dgsh-merge-sum $(for i in $(seq $N) ; do printf &#39;&lt;| &#39; ; done)
</pre>

<img src="https://typesafety.net/rob/blog/author-compare-pretty.png" alt="Venue author compare"/>
<!-- Extracted description -->
<p>
Given the specification of two publication venues, read a compressed
DBLP computer science bibliography from the standard input (e.g. piped
from curl -s http://dblp.uni-trier.de/xml/dblp.xml.gz or from a locally
cached copy) and output the number of papers published in each of the
two venues as well as the number of authors who have published only in
the first venue, the number who have published only in the second one,
and authors who have published in both.  The venues are specified through
the script&#39;s first two command-line arguments as a DBLP key prefix, e.g.
journals/acta/, conf/icse/, journals/software/, conf/iwpc/, or conf/msr/.
Demonstrates the use of dgsh-wrap -e to have sed(1) create two output
streams and the use of tee to copy a pair of streams into four ones.
</p>
<!-- Extracted code -->
<pre>#!/usr/bin/env dgsh

# Extract and sort author names
sorted_authors()
{
  sed -n &#39;s/&lt;author&gt;\([^&lt;]*\)&lt;\/author&gt;/\1/p&#39; |
  sort
}

# Escape a string to make it a valid sed(1) pattern
escape()
{
  echo &#34;$1&#34; | sed &#39;s/\([/\\]\)/\\\1/g&#39;
}

export -f sorted_authors

if [ ! &#34;$2&#34; -a ! &#34;$DGSH_DOT_DRAW&#34;] ; then
  echo &#34;Usage: $0 key1 key2&#34; 1&gt;&amp;2
  echo &#34;Example: $0 conf/icse/ journals/software/&#34; 1&gt;&amp;2
  exit 1
fi

gzip -dc |
# Output the two venue authors as two output streams
dgsh-wrap -e sed -n &#34;
/^&lt;.*key=\&#34;$(escape $1)/,/&lt;title&gt;/ w &gt;|
/^&lt;.*key=\&#34;$(escape $2)/,/&lt;title&gt;/ w &gt;|&#34; |
# 2 streams in 4 streams out: venue1, venue2, venue1, venue2
tee |
{{
  {{
    echo -n &#34;$1 papers: &#34;
    grep -c &#39;^&lt;.* mdate=.* key=&#39;
    echo -n &#34;$2 papers: &#34;
    grep -c &#39;^&lt;.* mdate=.* key=&#39;
  }}

  {{
    call sorted_authors
    call sorted_authors
  }} |
  comm |
  {{
    echo -n &#34;Authors only in $1: &#34;
    wc -l
    echo -n &#34;Authors only in $2: &#34;
    wc -l
    echo -n &#39;Authors common in both venues: &#39;
    wc -l
  }}
}} |
cat
</pre>
<section id="ft2d"> <!-- {{{2 -->
<h2>Waves: 2D Fourier transforms</h2>
</section>
<img src="https://typesafety.net/rob/blog/ft2d-pretty.png" alt="Waves: 2D Fourier transforms"/>
<!-- Extracted description -->
<p>
Create two graphs:
1) a broadened pulse and the real part of its 2D Fourier transform, and
2) a simulated air wave and the amplitude of its 2D Fourier transform.
Demonstrates using the tools of the Madagascar shared research environment
for computational data analysis in geophysics and related fields.
Also demonstrates the use of two scatter blocks in the same script,
and the used of named streams.
</p>
<!-- Extracted code -->
<pre>#!/usr/bin/env dgsh

mkdir -p Fig

# The SConstruct SideBySideIso &#34;Result&#34; method
side_by_side_iso()
{
	vppen size=r vpstyle=n gridnum=2,1 /dev/stdin $*
}

export -f side_by_side_iso

# A broadened pulse and the real part of its 2D Fourier transform
sfspike n1=64 n2=64 d1=1 d2=1 nsp=2 k1=16,17 k2=5,5 mag=16,16 \
	label1=&#39;time&#39; label2=&#39;space&#39; unit1= unit2= |
sfsmooth rect2=2 |
sfsmooth rect2=2 |
tee |
{{
	sfgrey pclip=100 wanttitle=n

	sffft1 |
	sffft3 axis=2 pad=1 |
	sfreal |
	tee |
	{{
		sfwindow f1=1 | sfreverse which=3
		cat
	}} |
	sfcat axis=1 &#34;&lt;|&#34; |
	sfgrey pclip=100 wanttitle=n label1=&#34;1/time&#34; label2=&#34;1/space&#34;
}} |
call_with_stdin side_by_side_iso &#39;&lt;|&#39; yscale=1.25 &gt;Fig/ft2dofpulse.vpl

# A simulated air wave and the amplitude of its 2D Fourier transform
sfspike n1=64 d1=1 o1=32 nsp=4 k1=1,2,3,4 mag=1,3,3,1 \
	label1=&#39;time&#39; unit1= |
sfspray n=32 d=1 o=0 |
sfput label2=space |
sflmostretch delay=0 v0=-1 |
tee |
{{
	sfwindow f2=1 | sfreverse which=2
	cat
}} |
sfcat axis=2 &#34;&lt;|&#34; |
tee |
{{
	sfgrey pclip=100 wanttitle=n

	sffft1 |
	sffft3 sign=1 |
	tee |
	{{
		sfreal
		sfimag
	}} |
	dgsh-wrap -e sfmath nostdin=y re=&#34;&lt;|&#34; im=&#34;&lt;|&#34; \
	  output=&#34;sqrt(re*re+im*im)&#34; |
	tee |
	{{
		sfwindow f1=1 | sfreverse which=3
		cat
	}} |
	sfcat axis=1 &#34;&lt;|&#34; |
	sfgrey pclip=100 wanttitle=n label1=&#34;1/time&#34; label2=&#34;1/space&#34;
}} |
call_with_stdin side_by_side_iso &#39;&lt;|&#39; yscale=1.25 &gt;Fig/airwave.vpl

wait
</pre>
<section id="NMRPipe"> <!-- {{{2 -->
<h2>Nuclear magnetic resonance processing</h2>
</section>
<img src="https://typesafety.net/rob/blog/NMRPipe-pretty.png" alt="Nuclear magnetic resonance processing"/>
<!-- Extracted description -->
<p>
Nuclear magnetic resonance in-phase/anti-phase channel conversion and
processing in heteronuclear single quantum coherence spectroscopy.
Demonstrate processing of NMR data using the NMRPipe family of programs.
</p>
<!-- Extracted code -->
<pre>#!/usr/bin/env dgsh

# The conversion is configured for the following file:
# http://www.bmrb.wisc.edu/ftp/pub/bmrb/timedomain/bmr6443/timedomain_data/c13-hsqc/june11-se-6426-CA.fid/fid
var2pipe -in $1            \
 -xN            1280            -yN     256    \
 -xT            640             -yT     128    \
 -xMODE         Complex -yMODE  Complex      \
 -xSW           8000    -ySW    6000      \
 -xOBS          599.4489584     -yOBS   60.7485301      \
 -xCAR          4.73    -yCAR   118.000      \
 -xLAB          1H      -yLAB   15N      \
 -ndim          2       -aq2D   States      \
-verb  |
tee |
{{
  # IP/AP channel conversion
  # See http://tech.groups.yahoo.com/group/nmrpipe/message/389
  nmrPipe |
  nmrPipe -fn SOL |
  nmrPipe -fn SP -off 0.5 -end 0.98 -pow 2 -c 0.5 |
  nmrPipe -fn ZF -auto |
  nmrPipe -fn FT |
  nmrPipe -fn PS -p0 177 -p1 0.0 -di |
  nmrPipe -fn EXT -left -sw -verb |
  nmrPipe -fn TP |
  nmrPipe -fn COADD -cList 1 0 -time |
  nmrPipe -fn SP -off 0.5 -end 0.98 -pow 1 -c 0.5 |
  nmrPipe -fn ZF -auto |
  nmrPipe -fn FT |
  nmrPipe -fn PS -p0 0 -p1 0 -di |
  nmrPipe -fn TP |
  nmrPipe -fn POLY -auto -verb &gt;A

  nmrPipe |
  nmrPipe -fn SOL |
  nmrPipe -fn SP -off 0.5 -end 0.98 -pow 2 -c 0.5 |
  nmrPipe -fn ZF -auto |
  nmrPipe -fn FT |
  nmrPipe -fn PS -p0 177 -p1 0.0 -di |
  nmrPipe -fn EXT -left -sw -verb |
  nmrPipe -fn TP |
  nmrPipe -fn COADD -cList 0 1 -time |
  nmrPipe -fn SP -off 0.5 -end 0.98 -pow 1 -c 0.5 |
  nmrPipe -fn ZF -auto |
  nmrPipe -fn FT |
  nmrPipe -fn PS -p0 -90 -p1 0 -di |
  nmrPipe -fn TP |
  nmrPipe -fn POLY -auto -verb &gt;B

}}

# We use temporary files rather than streams, because
# addNMR mmaps its input files. The diagram displayed in the
# example shows the notional data flow.
if [ -z &#34;${DGSH_DRAW_EXIT}&#34; ]
then
	addNMR -in1 A -in2 B -out A+B.dgsh.ft2 -c1 1.0 -c2 1.25 -add
	addNMR -in1 A -in2 B -out A-B.dgsh.ft2 -c1 1.0 -c2 1.25 -sub
fi
</pre>
<section id="fft-block8"> <!-- {{{2 -->
<h2>FFT calculation</h2>
</section>
<img src="https://typesafety.net/rob/blog/fft-block8-pretty.png" alt="FFT calculation"/>
<!-- Extracted description -->
<p>
Calculate the iterative FFT for n = 8 in parallel.
Demonstrates combined use of permute and multipipe blocks.
</p>
<!-- Extracted code -->
<pre>#!/usr/bin/env dgsh

dgsh-fft-input $1 |
perm 1,5,3,7,2,6,4,8 |
{{
	{{
		dgsh-w 1 0
		dgsh-w 1 0
	}} |
	perm 1,3,2,4 |
	{{
		dgsh-w 2 0
		dgsh-w 2 1
	}}

	{{
		dgsh-w 1 0
		dgsh-w 1 0
	}} |
	perm 1,3,2,4 |
	{{
		dgsh-w 2 0
		dgsh-w 2 1
	}}
}} |
perm 1,5,3,7,2,6,4,8 |
{{
	dgsh-w 3 0

	dgsh-w 3 1

	dgsh-w 3 2

	dgsh-w 3 3
}} |
perm 1,5,2,6,3,7,4,8 |
cat
</pre>
<section id="reorder-columns"> <!-- {{{2 -->
<h2>Reorder columns</h2>
</section>
<img src="https://typesafety.net/rob/blog/reorder-columns-pretty.png" alt="Reorder columns"/>
<!-- Extracted description -->
<p>
Reorder columns in a CSV document.
Demonstrates the combined use of tee, cut, and paste.
</p>
<!-- Extracted code -->
<pre>#!/usr/bin/env dgsh

tee |
{{
	cut -d , -f 5-6 -

	cut -d , -f 2-4 -
}} |
paste -d ,
</pre>
<section id="dir"> <!-- {{{2 -->
<h2>Directory listing</h2>
</section>
<img src="https://typesafety.net/rob/blog/dir-pretty.png" alt="Directory listing"/>
<!-- Extracted description -->
<p>
Windows-like DIR command for the current directory.
Nothing that couldn&#39;t be done with <code>ls -l | awk</code>.
Demonstrates use of wrapped commands with no input (df, echo).
</p>
<!-- Extracted code -->
<pre>#!/usr/bin/env dgsh

ls -n |
tee |
{{
	# Reorder fields in DIR-like way
	awk &#39;!/^total/ {print $6, $7, $8, $1, sprintf(&#34;%8d&#34;, $5), $9}&#39;

	# Count number of files
	wc -l | tr -d \\n

	# Print label for number of files
	echo -n &#39; File(s) &#39;

	# Tally number of bytes
	awk &#39;{s += $5} END {printf(&#34;%d bytes\n&#34;, s)}&#39;

	# Count number of directories
	grep -c &#39;^d&#39; | tr -d \\n

	# Print label for number of dirs and calculate free bytes
	df -h . | awk &#39;!/Use%/{print &#34; Dir(s) &#34; $4 &#34; bytes free&#34;}&#39;
}} |
cat
</pre>

</section> <!-- Examples -->

</section></div> <!-- span8 -->
</div></div>
  </body>
</html>
