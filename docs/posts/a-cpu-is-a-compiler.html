<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://outerproduct.net/boring/2023-03-22_cpu-compiler-gc-ohmy.html">Original</a>
    <h1>A CPU Is a Compiler</h1>
    
    <div id="readability-page-1" class="page">                <em>2023-03-22</em><p>Strictly speaking, a CPU is an interpreter; it is certainly not a compiler and, unless you can come up with a second implementation of physics, the <a href="https://en.wikipedia.org/wiki/Partial_evaluation">standard tricks</a> to turn it into one won’t work either.
And yet, when comparing with software implementations of programming languages, a CPU seems closest to the back end of an optimising compiler; all sorts of duals seem to show up:</p><table><tbody><tr><th>Compiler</th>				<th>CPU</th><th>Notes</th></tr>
<tr><td>Instruction scheduling</td>			<td>Instruction scheduling</td></tr>
<tr><td>JIT</td>					<td>Microcoding, µop cache</td></tr>
<tr><td>Branch probability analysis</td>		<td>Branch prediction</td>		<td rowspan="2">I find the contrast here particularly interesting.</td></tr>
<tr><td>Inline cache</td>				<td>Branch target buffer</td></tr>
<tr><td>Instruction selection</td>			<td>Fusion</td></tr>
<tr><td>Register allocation</td>			<td>Register renaming</td></tr>
<tr><td>Coalescing</td>				<td>Move elimination</td></tr>
<tr><td>Alias analysis</td>				<td>Memory disambiguation</td></tr>
<tr><td>Scalar replacement of aggregates</td>	<td><a href="https://www.agner.org/forum/viewtopic.php?t=41">Memory renaming</a></td></tr>
<tr><td>Peephole optimisations, idioms</td>		<td>Idioms</td>
<td>For instance, a compiler might recognise a sequence for performing a rotate, byte-swap, or population count, when such functionality is supported natively by the target, but not by the source.  A CPU might recognise an xor or subtraction of a register from itself as producing a zero.</td></tr>

<tr><td>Parallelising compiler, scheduler</td>			<td>Superscalar CPU</td></tr>
<tr><td>Pipelining</td>				<td>Pipelining, memory-level parallelism</td> <td>Very different types of pipelining!</td></tr>
<tr><td>Block, trace</td>				<td>Trace</td></tr></tbody></table><p>I find it somewhat irksome that we don’t refer to static register allocation and dynamic register allocation—etc.—as this would make the relationship between CPUs and compilers much clearer.
Some of the ties here are admittedly too tenuous for this to really work out, but many are not.</p><p>Here’s some garbage collection, as a bonus:</p><table><tbody><tr><th>Garbage collector</th>			<th>CPU</th><th>Notes</th></tr>
<tr><td>Generational garbage collection</td>		<td><a href="https://arxiv.org/pdf/1911.03282.pdf">QLRU cache replacement</a></td></tr>
<tr><td>Write barrier</td>				<td>Snooping</td></tr>
<tr><td>Read barrier</td>				<td>TLB lookup</td>		<td>Particularly a use barrier.</td></tr>
<tr><td>Self-healing</td>				<td>TLB miss/update</td></tr>
<tr><td>Forwarding pointer</td>			<td>Page table entry</td></tr>
<tr><td>Snapshot or recolour roots</td>		<td>TLB shootdown</td></tr></tbody></table>
                </div>
  </body>
</html>
