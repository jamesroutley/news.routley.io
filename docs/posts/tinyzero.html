<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/Jiayi-Pan/TinyZero">Original</a>
    <h1>TinyZero</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://elijer.github.io/Jiayi-Pan/TinyZero/blob/main/cover.png"><img src="https://elijer.github.io/Jiayi-Pan/TinyZero/raw/main/cover.png" alt="image"/></a></p>
<p dir="auto">TinyZero is a reproduction of <a href="https://github.com/deepseek-ai/DeepSeek-R1">DeepSeek R1 Zero</a>. We built upon <a href="https://github.com/volcengine/verl">veRL</a>.</p>
<p dir="auto">Through RL, the 3B base LM develops self-verification and search abilities all on its own</p>
<p dir="auto">You can experience the Ahah moment yourself for &lt; $30</p>
<p dir="auto">Twitter thread: <a href="https://x.com/jiayi_pirate/status/1882839370505621655" rel="nofollow">https://x.com/jiayi_pirate/status/1882839370505621655</a></p>
<p dir="auto">Full experiment log: <a href="https://wandb.ai/jiayipan/TinyZero" rel="nofollow">https://wandb.ai/jiayipan/TinyZero</a></p>

<div data-snippet-clipboard-copy-content="conda create -n zero python=3.9
# install torch [or you can skip this step and let vllm to install the correct version for you]
pip install torch==2.4.0 --index-url https://download.pytorch.org/whl/cu121
# install vllm
pip3 install vllm==0.6.3 # or you can install 0.5.4, 0.4.2 and 0.3.1
pip3 install ray

# verl
pip install -e .

# flash attention 2
pip3 install flash-attn --no-build-isolation
# quality of life
pip install wandb IPython matplotlib"><pre><code>conda create -n zero python=3.9
# install torch [or you can skip this step and let vllm to install the correct version for you]
pip install torch==2.4.0 --index-url https://download.pytorch.org/whl/cu121
# install vllm
pip3 install vllm==0.6.3 # or you can install 0.5.4, 0.4.2 and 0.3.1
pip3 install ray

# verl
pip install -e .

# flash attention 2
pip3 install flash-attn --no-build-isolation
# quality of life
pip install wandb IPython matplotlib
</code></pre></div>



<p dir="auto"><strong>Data Preparation</strong></p>
<div data-snippet-clipboard-copy-content="python ./examples/data_preprocess/countdown.py --local_dir {path_to_your_dataset}"><pre><code>python ./examples/data_preprocess/countdown.py --local_dir {path_to_your_dataset}
</code></pre></div>
<p dir="auto"><strong>Single GPU</strong>
Works for model &lt;= 1.5B. For Qwen2.5-0.5B base, we know it fails to learn reasoning.</p>
<div data-snippet-clipboard-copy-content="export N_GPUS=1
export BASE_MODEL={path_to_your_model}
export DATA_DIR={path_to_your_dataset}
export ROLLOUT_TP_SIZE=1
export EXPERIMENT_NAME=countdown-qwen2.5-0.5b
export VLLM_ATTENTION_BACKEND=XFORMERS

bash ./scripts/train_tiny_zero.sh"><pre><code>export N_GPUS=1
export BASE_MODEL={path_to_your_model}
export DATA_DIR={path_to_your_dataset}
export ROLLOUT_TP_SIZE=1
export EXPERIMENT_NAME=countdown-qwen2.5-0.5b
export VLLM_ATTENTION_BACKEND=XFORMERS

bash ./scripts/train_tiny_zero.sh
</code></pre></div>
<p dir="auto"><strong>3B+ model</strong>
In this case, the base model is able to develop sophisticated reasoning skills.</p>
<div data-snippet-clipboard-copy-content="export N_GPUS=2
export BASE_MODEL={path_to_your_model}
export DATA_DIR={path_to_your_dataset}
export ROLLOUT_TP_SIZE=2
export EXPERIMENT_NAME=countdown-qwen2.5-3b
export VLLM_ATTENTION_BACKEND=XFORMERS

bash ./scripts/train_tiny_zero.sh"><pre><code>export N_GPUS=2
export BASE_MODEL={path_to_your_model}
export DATA_DIR={path_to_your_dataset}
export ROLLOUT_TP_SIZE=2
export EXPERIMENT_NAME=countdown-qwen2.5-3b
export VLLM_ATTENTION_BACKEND=XFORMERS

bash ./scripts/train_tiny_zero.sh
</code></pre></div>

<p dir="auto">We experiment with QWen-2.5-3B Instruct too.
<strong>Data Preparation</strong>
To follow chat template, we need to reprocess the data:</p>
<div data-snippet-clipboard-copy-content="conda activate zero
python examples/data_preprocess/countdown.py --template_type=qwen-instruct --local_dir={path_to_your_dataset}"><pre><code>conda activate zero
python examples/data_preprocess/countdown.py --template_type=qwen-instruct --local_dir={path_to_your_dataset}
</code></pre></div>
<p dir="auto"><strong>Training</strong></p>
<div data-snippet-clipboard-copy-content="export N_GPUS=2
export BASE_MODEL={path_to_your_model}
export DATA_DIR={path_to_your_dataset}
export ROLLOUT_TP_SIZE=2
export EXPERIMENT_NAME=countdown-qwen2.5-3b-instruct
export VLLM_ATTENTION_BACKEND=XFORMERS

bash ./scripts/train_tiny_zero.sh"><pre><code>export N_GPUS=2
export BASE_MODEL={path_to_your_model}
export DATA_DIR={path_to_your_dataset}
export ROLLOUT_TP_SIZE=2
export EXPERIMENT_NAME=countdown-qwen2.5-3b-instruct
export VLLM_ATTENTION_BACKEND=XFORMERS

bash ./scripts/train_tiny_zero.sh
</code></pre></div>

<ul dir="auto">
<li>We run our experiments based on <a href="https://github.com/volcengine/verl">veRL</a>.</li>
<li>We use Qwen2.5 series base model <a href="https://github.com/QwenLM/Qwen2.5">Qwen2.5</a>.</li>
</ul>

<div data-snippet-clipboard-copy-content="@misc{tinyzero,
author       = {Jiayi Pan and Junjie Zhang and Xingyao Wang and Lifan Yuan},
title        = {TinyZero},
howpublished = {[https://github.com/Jiayi-Pan/TinyZero](https://github.com/Jiayi-Pan/TinyZero)},
note         = {Accessed: 2025-01-24},
year         = {2025}
}"><pre><code>@misc{tinyzero,
author       = {Jiayi Pan and Junjie Zhang and Xingyao Wang and Lifan Yuan},
title        = {TinyZero},
howpublished = {[https://github.com/Jiayi-Pan/TinyZero](https://github.com/Jiayi-Pan/TinyZero)},
note         = {Accessed: 2025-01-24},
year         = {2025}
}
</code></pre></div>
</article></div></div>
  </body>
</html>
