<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.kierangill.xyz/oversight-and-guidance">Original</a>
    <h1>Scaling LLMs to Larger Codebases</h1>
    
    <div id="readability-page-1" class="page"><div>
      
<p>How do we scale LLMs to larger codebases? Nobody knows yet. But by understanding how <a href="https://blog.kierangill.xyz/ai-strengths-and-limitations-in-engineering.html">LLMs contribute to engineering</a>, we realize that investments in <em>guidance</em> and <em>oversight</em> are worthwhile.</p>
<ul>
<li><strong>Guidance</strong>: The context, the environment.</li>
<li><strong>Oversight</strong>: The skill set needed to guide, validate, and verify the implementor&#39;s<sup id="fnref:1"><a href="#fn:1">1</a></sup> <em>choices</em>.</li>
</ul>
<h2>Investing in guidance</h2>
<p>When an LLM can generate a working high-quality implementation in a single try, that is called <strong>one-shotting</strong>. This is the most efficient form of LLM programming.</p>
<p><img src="https://blog.kierangill.xyz/images/guidance-and-oversight-target-hitting.webp" alt="An arrow hitting the center of a dart board."/>
</p>

<p>The opposite of one-shotting is rework. This is when you fail to get a usable output from the LLM and must manually intervene.<sup id="fnref:2"><a href="#fn:2">2</a></sup> This often takes longer than just doing the work yourself.</p>
<p><img src="https://blog.kierangill.xyz/images/guidance-and-oversight-target-missing.webp" alt="Multiple arrows on a dart board. They have all missed the center."/>
</p>

<p>So how do we create more opportunities for one-shotting? Better guidance.</p>
<h3>Better guidance</h3>
<p>LLMs are choice generators. Every set of tokens is a choice added to your codebase: how a variable is named, where to organize a function, whether to reuse/extend/or duplicate functionality to solve a problem, whether Postgres should be chosen over Redis, and so on.</p>
<p>Often, these choices are best left up to the designer (e.g., via the prompt). However, it&#39;s not efficient to exhaustively list all of these choices in a prompt. It&#39;s also not efficient to rework an LLM output whenever it gets these choices wrong.</p>
<p>In the ideal world, the prompt only captures the business requirements of a feature. The rest of the choices are either inferrable or encoded.</p>
<h4>Write a prompt library</h4>
<p>A prompt library is a set of documentation that can be included as context for an LLM. </p>
<p>Writing this is simple: collate documentation, best practices, a general map of the codebase, and other context an engineer needs to be productive in <em>your</em> codebase.<sup id="fnref:3"><a href="#fn:3">3</a></sup> </p>
<p>Making a prompt library useful requires iteration. Every time the LLM is slightly off target, ask yourself, &#34;What could&#39;ve been clarified?&#34; Then, add that answer back into the prompt library.</p>
<p>A prompt library needs to strike the right balance between <em>comprehensive</em> and <em>lean</em>.</p>


<h4>The environment is your context</h4>
<p>A peer at Meta told me that they weren&#39;t in a position to make Zuckerberg&#39;s <a href="https://www.forbes.com/sites/quickerbettertech/2025/01/26/business-tech-news-zuckerberg-says-ai-will-replace-mid-level-engineers-soon/">engineering automation claims</a> a reality. The reason is their codebase is riddled with technical debt. He wasn&#39;t surprised by this. Meta (apparently) historically has not prioritized paying down their debts. </p>

<p>Compare this to the mentality from the <a href="https://youtu.be/BGgsoIgbT_Y?si=vsIrpQVQquas6PYH&amp;t=988">Cursor team</a>:</p>
<blockquote>
<p>I think ultimately the principles of clean software are not that different when you want it to be read by people and by models. When you are trying to write clean code you want to, not repeat yourself, not make things more complicated than they need to be.</p>
<p>I think taste in code... is actually gonna become even more important as these models get better because it will be easier to write more and more code and so it&#39;ll be more and more important to structure it in a tasteful way.</p>
</blockquote>
<p>This is the <em>garbage in, garbage out</em> principle in action. The utility of a model is bottlenecked by its inputs. The more garbage you have, the more likely hallucinations will occur.</p>
<p>Here&#39;s a LLM literacy dipstick: ask a peer engineer to read some code they&#39;re unfamiliar with. Do they understand it? Do they struggle to navigate it? If it&#39;s a module, can they quickly understand what all that module exposes? Do they know the implications of using a certain function, the side-effects they must be aware of? No? Then the LLM won&#39;t either.</p>
<p>Here&#39;s another dipstick: Ask an LLM agent to tell you how certain functionality works. You should know the answer before asking the LLM. Is their answer right? More importantly, how did they go about answering your question? Follow the LLM&#39;s trail and document its snags. You&#39;ll notice it tends to <code>grep</code>, <code>ls</code>, and <code>cat</code> to search. How can you give it a map so it isn&#39;t left to rediscover the codebase on each new prompt? When a map can&#39;t be given, how do you make it easier for them to navigate the codebase?</p>
<p>How you make the environment better suited for LLM literacy is dependent on the tech stack and domain. But general principles apply: modularity, simplicity, things are well-named, logic is encapsulated. Be consistent and encode these conventions in your prompt library.</p>

<h2>Investing in oversight</h2>
<p>We need guidance <em>and</em> oversight. A 3-ton truck with a middle-schooler behind the wheel puts people in the hospital (and in jail). This is why the mentality of automating engineers is objectionable. We should be fostering our teams, not discarding them.</p>
<p>Remember, engineers operate on <a href="https://blog.kierangill.xyz/ai-strengths-and-limitations-in-engineering.html">two timelines</a>. As overseers of implementation, we must plan for the future of the codebase. If an LLM makes a choice, the overseer should be able to discern whether it was a good one or a bad one. For example, let&#39;s say the LLM opted to use Redis over Postgres to store some metadata. Was that a good choice? The overseer should know.</p>
<p>An investment in oversight is an investment in <strong>team</strong>, <strong>alignment</strong>, and <strong>workflows</strong>.</p>
<p>For <em>team</em>, it&#39;s worth investing in elevating everyone&#39;s design capabilities.</p>
<p>Design produces architecture. Architecture is a bet on the future. It&#39;s a bet that by setting up a program in a certain way, it will make the future feature development easier.</p>
<p>Architects are often created through experience. A career of shooting yourself in the foot builds intuition. This intuition shapes new software from having the same mistakes.</p>
<details>
<summary><strong>Aside</strong>: Some thoughts on how to grow design skills</summary>
<p>Read books, blogs, and code. Watch conference talks. Replicate masterworks. Practice by writing programs that you don&#39;t know how to build.</p>
<p>On replicating masterworks:</p>
<ul>
<li>Student artists are often required to replicate masterworks. A masterwork is an art piece that an expert artist made. Through the process of replicating this masterwork, an artist gains practical experience at the bleeding edge of art. (This experience also builds confidence, which is a bonus.)</li>
<li>The same is true for engineering. I&#39;ve learned more by <a href="https://interpreterbook.com/">writing a programming language</a> than I have in reading a hundred blog posts.</li>
<li>Why does this work?<ul>
<li>You understand a layer of abstraction deeper than the layer you&#39;re working at (this is a Cantrill-ism, but I can&#39;t find the quote). </li>
<li>Masters use techniques and workflows that are best learned via practice. Thorsten Ball taught me how to break down large problems into tractable phases. Each phase had a contract and each contract could be tested.</li>
</ul>
</li>
</ul>
<p>On reading code:</p>
<ul>
<li>A good way to expand your vocabulary of solutions.</li>
<li>In Steve Ruiz&#39;s V1 of <a href="https://www.tldraw.com/">TLDraw</a>, I learned the <a href="https://github.com/tldraw/tldraw/blob/v1.6.1/packages/tldraw/src/state/sessions/DrawSession/DrawSession.ts">patterns</a> necessary to later implement session-based undo/redo for an internal tool at work.</li>
<li>Reading <a href="https://github.com/SerenityOS/jakt/blob/d792ad5029a8a7f5385bbdf7d404240692975f74/selfhost/parser.jakt">code from leaders in the field</a> is also a good way to build taste. </li>
</ul>
</details>
<p>Oversight is not only about architecture, but also <a href="https://engineering.blueberrypediatrics.blog/candidate-evaluation-rigor-urgency">temperament</a>, <a href="https://engineering.blueberrypediatrics.blog/candidate-evaluation-framework">alignment to values</a>, and <a href="https://engineering.blueberrypediatrics.blog/sequencing-for-value">workflows</a>. Operators need to be both technical and product experts. Without a deep understanding of the product, it&#39;s easy to accidentally build the wrong solution.</p>
<h3>Automating oversight</h3>
<p>Some design concerns can be checked programmatically. </p>
<p>Moving more implementation feedback from human to computer helps us improve the chance of one-shotting. Agents can get feedback directly from their environment (e.g., type errors).</p>
<p>Think of these as bumper rails. You can increase the likelihood of an LLM reaching the bowling pins by making it impossible to land in the gutter.</p>
<p>One way to do this is through writing <strong>safety</strong> checks. But what is safety? Safety is <em>protecting your abstractions</em>. Pierce&#39;s <a href="https://www.cis.upenn.edu/~bcpierce/tapl/">Types and Programming Languages</a> has my favorite definition of safety:</p>
<blockquote>
<p>Informally, though, safe languages can be defined as ones that make it impossible to shoot yourself in the foot while programming.</p>
<p>Refining this intuition a little, we could say that a safe language <em>is one that protects its own abstractions</em>.</p>
<p>Safety refers to the language&#39;s ability to guarantee the integrity of these abstractions and of higher-level abstractions introduced by the programmer using the definitional facilities of the language. For example, a language may provide arrays, with access and update operations, as an abstraction of the underlying memory. A programmer using this language then expects that an array can be changed only by using the update operation on it explicitlyâ€”and not, for example, by writing past the end of some other data structure.</p>
</blockquote>
<p>We tend to write tests for business-logic but don&#39;t always write tests for architecture-logic. Some programming languages have facilities for this built in.</p>

<h2>Addressing verification</h2>
<p><img src="https://blog.kierangill.xyz/images/llms-in-software-engineering-cycle.webp" alt="A very simplified graphic for the design / implementation / verification cycle"/>
</p>

<p>Design and implementation are only two pieces of a project&#39;s lifecycle. <em>Verification</em>, like code review or QA, are necessary for building quality software.</p>
<p>As the volume of work increases, our ability to ship that work becomes constrained by our ability to review it.</p>
<p>Here are some incomplete ideas for addressing the verification bottleneck:</p>
<ul>
<li>Lowering the barrier of entry to perform manual QA (not needing a dev env).</li>
<li>Invest in a testing setup that makes it easy to express tests (including setting up tests, e.g., with test data creation) with minimal code. </li>
<li>Encode frequent PR feedback into documentation so that there is some level of PR review an LLM can reasonably do.</li>
<li>Security is baked in as defaults in the framework, not context.</li>
</ul>
<h2>That&#39;s it, for now</h2>
<p>This was the third part of a series on LLMs in software engineering.</p>
<p>First we learned <a href="https://blog.kierangill.xyz/how-hype-works.html">what LLMs and genetics have in common</a>. <sup> (part 1)</sup> LLMs don&#39;t simply improve all facets of engineering. Understanding <a href="https://blog.kierangill.xyz/ai-strengths-and-limitations-in-engineering.html">which areas LLMs do improve</a><sup> (part 2)</sup> is important for knowing <a href="https://blog.kierangill.xyz/oversight-and-guidance.html">how to focus our investments</a>.<sup> (part 3)</sup></p>
<hr/>


    </div></div>
  </body>
</html>
