<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://bernsteinbear.com/blog/typed-python/">Original</a>
    <h1>Compiling Typed Python</h1>
    
    <div id="readability-page-1" class="page"><div>
            <p>It’s been nine whole years since <a href="https://peps.python.org/pep-0484/">PEP 484</a>
landed and brought us types from on high. This has made a lot of people very
angry and been widely regarded as a bad move<sup id="fnref:adams" role="doc-noteref"><a href="#fn:adams" rel="footnote">1</a></sup>. Since then, people on the
internet have been clamoring to find out: <a href="https://discuss.python.org/t/cpython-optimizations-leveraging-type-hints-bachelor-thesis-topic/27264">does this mean we can now compile
Python</a>
<a href="https://stackoverflow.com/questions/40204951/python-3-type-hints-for-performance-optimizations">to native code for more speed</a>?
It’s a totally reasonable question. It was one of my first questions when I
first started working on Python compilers. So can we do it?</p>

<p>No. But also, kind of, yes. I’ll explain. I’ll explain in the context of
“ahead-of-time” compiling within or adjacent to CPython, the predominant
implementation of the Python language. Just-in-time (JIT) compilers are a
different beast, and are described more below. None of the information in this
post is novel; I hope only to clarify a bunch of existing academic and industry
knowledge.</p>

<p>The core thesis is: <em>types are very broad hints and they are sometimes lies</em>.</p>

<h2 id="its-not-what-you-think">It’s not what you think</h2>

<p>A lot of people enjoy walking into discussions and saying things like “We have
a 100% Mypy typed codebase. I would simply use the types in compilation to
generate better code.” That was the original title of this article, even. “<em>I
would simply use the types in the compiler.</em>” But it doesn’t really work like
that<sup id="fnref:simple-annotations" role="doc-noteref"><a href="#fn:simple-annotations" rel="footnote">2</a></sup>. I’ll show a couple examples that demonstrate why.
The point is not to browbeat you with example after example; the point is to
get people to stop saying “just” and “simply”.</p>

<p>For example, look at this lovely little Python function. It’s short, typed, and
obviously just adds integers. Easy: compiles right down to two machine
instructions. Right?</p>

<div><div><pre><code><span>def</span> <span>add</span><span>(</span><span>x</span><span>:</span> <span>int</span><span>,</span> <span>y</span><span>:</span> <span>int</span><span>)</span> <span>-&gt;</span> <span>int</span><span>:</span>
    <span>return</span> <span>x</span> <span>+</span> <span>y</span>

<span>add</span><span>(</span><span>3</span><span>,</span> <span>4</span><span>)</span>  <span># =&gt; 7
</span></code></pre></div></div>

<p>Unfortunately, no. Type annotations of the type <code>x: T</code> mean “<code>x</code> is an instance
of <code>T</code> or an instance of a subclass of <code>T</code>.”<sup id="fnref:exact" role="doc-noteref"><a href="#fn:exact" rel="footnote">3</a></sup> This is pretty common in
programming languages, and, thanks to <a href="https://en.wikipedia.org/wiki/Liskov_substitution_principle">Barbara
Liskov</a>, makes
semantic sense most of the time. But it doesn’t help performance here. The
dispatch for binary operators in Python is famously <a href="https://snarky.ca/unravelling-binary-arithmetic-operations-in-python/">not
simple</a>
because of subclasses. This means that there is a lot of code to be executed if
<code>x</code> and <code>y</code> could be any subclasses of <code>int</code>.</p>

<div><div><pre><code><span>class</span> <span>C</span><span>(</span><span>int</span><span>):</span>
    <span>def</span> <span>__add__</span><span>(</span><span>self</span><span>,</span> <span>other</span><span>):</span>
        <span>send_a_nasty_email</span><span>()</span>  <span># sigh
</span>        <span>return</span> <span>42</span>
</code></pre></div></div>

<p>It’s not obvious how the appropriate <code>__add__</code> function is selected in operator
dispatch. <strong>You don’t need to understand or really even read the big blob</strong>
that explains it below. You just need to say “ooh” and “aah” and “wow, so many
if-statements.”</p>

<div><div><pre><code><span>_MISSING</span> <span>=</span> <span>object</span><span>()</span>

<span>def</span> <span>sub</span><span>(</span><span>lhs</span><span>:</span> <span>Any</span><span>,</span> <span>rhs</span><span>:</span> <span>Any</span><span>,</span> <span>/</span><span>)</span> <span>-&gt;</span> <span>Any</span><span>:</span>
        <span># lhs.__sub__
</span>        <span>lhs_type</span> <span>=</span> <span>type</span><span>(</span><span>lhs</span><span>)</span>
        <span>try</span><span>:</span>
            <span>lhs_method</span> <span>=</span> <span>debuiltins</span><span>.</span><span>_mro_getattr</span><span>(</span><span>lhs_type</span><span>,</span> <span>&#34;__sub__&#34;</span><span>)</span>
        <span>except</span> <span>AttributeError</span><span>:</span>
            <span>lhs_method</span> <span>=</span> <span>_MISSING</span>

        <span># lhs.__rsub__ (for knowing if rhs.__rsub__ should be called first)
</span>        <span>try</span><span>:</span>
            <span>lhs_rmethod</span> <span>=</span> <span>debuiltins</span><span>.</span><span>_mro_getattr</span><span>(</span><span>lhs_type</span><span>,</span> <span>&#34;__rsub__&#34;</span><span>)</span>
        <span>except</span> <span>AttributeError</span><span>:</span>
            <span>lhs_rmethod</span> <span>=</span> <span>_MISSING</span>

        <span># rhs.__rsub__
</span>        <span>rhs_type</span> <span>=</span> <span>type</span><span>(</span><span>rhs</span><span>)</span>
        <span>try</span><span>:</span>
            <span>rhs_method</span> <span>=</span> <span>debuiltins</span><span>.</span><span>_mro_getattr</span><span>(</span><span>rhs_type</span><span>,</span> <span>&#34;__rsub__&#34;</span><span>)</span>
        <span>except</span> <span>AttributeError</span><span>:</span>
            <span>rhs_method</span> <span>=</span> <span>_MISSING</span>

        <span>call_lhs</span> <span>=</span> <span>lhs</span><span>,</span> <span>lhs_method</span><span>,</span> <span>rhs</span>
        <span>call_rhs</span> <span>=</span> <span>rhs</span><span>,</span> <span>rhs_method</span><span>,</span> <span>lhs</span>

        <span>if</span> <span>(</span>
            <span>rhs_type</span> <span>is</span> <span>not</span> <span>_MISSING</span>  <span># Do we care?
</span>            <span>and</span> <span>rhs_type</span> <span>is</span> <span>not</span> <span>lhs_type</span>  <span># Could RHS be a subclass?
</span>            <span>and</span> <span>issubclass</span><span>(</span><span>rhs_type</span><span>,</span> <span>lhs_type</span><span>)</span>  <span># RHS is a subclass!
</span>            <span>and</span> <span>lhs_rmethod</span> <span>is</span> <span>not</span> <span>rhs_method</span>  <span># Is __r*__ actually different?
</span>        <span>):</span>
            <span>calls</span> <span>=</span> <span>call_rhs</span><span>,</span> <span>call_lhs</span>
        <span>elif</span> <span>lhs_type</span> <span>is</span> <span>not</span> <span>rhs_type</span><span>:</span>
            <span>calls</span> <span>=</span> <span>call_lhs</span><span>,</span> <span>call_rhs</span>
        <span>else</span><span>:</span>
            <span>calls</span> <span>=</span> <span>(</span><span>call_lhs</span><span>,)</span>

        <span>for</span> <span>first_obj</span><span>,</span> <span>meth</span><span>,</span> <span>second_obj</span> <span>in</span> <span>calls</span><span>:</span>
            <span>if</span> <span>meth</span> <span>is</span> <span>_MISSING</span><span>:</span>
                <span>continue</span>
            <span>value</span> <span>=</span> <span>meth</span><span>(</span><span>first_obj</span><span>,</span> <span>second_obj</span><span>)</span>
            <span>if</span> <span>value</span> <span>is</span> <span>not</span> <span>NotImplemented</span><span>:</span>
                <span>return</span> <span>value</span>
        <span>else</span><span>:</span>
            <span>raise</span> <span>TypeError</span><span>(</span>
                <span>f</span><span>&#34;unsupported operand type(s) for -: </span><span>{</span><span>lhs_type</span><span>!</span><span>r</span><span>}</span><span> and </span><span>{</span><span>rhs_type</span><span>!</span><span>r</span><span>}</span><span>&#34;</span>
            <span>)</span>
</code></pre></div></div>

<p>This enormous code snippet is from Brett Cannon’s linked post above. It
demonstrates in Python “pseudocode” what happens in C under the hood when doing
<code>lhs - rhs</code> in Python.</p>

<p>But let’s ignore this problem and pretend that it’s not possible to subclass
<code>int</code>. Problem solved, right? High performance math?</p>

<p>Unfortunately, no. While we would have fast dispatch on binary operators and
other methods, integers in Python are heap-allocated big integer objects. This
means that every operation on them is a function call to <code>PyLong_Add</code> or
similar. While these functions have been optimized for speed over the years,
they are still slower than machine integers. But let’s assume that a
sufficiently smart compiler can auto-unbox small-enough big integers into
machine words at the beginning of a function. We can do fast math with those.
If we really want, we can even do fast floating point math, too. Problem
solved? Hopefully?</p>

<div><div><pre><code><span># You can have fun making enormous numbers! This is part of the Python
# language.
</span><span>def</span> <span>big_pow</span><span>(</span><span>x</span><span>:</span> <span>int</span><span>)</span> <span>-&gt;</span> <span>int</span><span>:</span>
    <span># Even if you unbox `x` here, the result might still be enormous.
</span>    <span>return</span> <span>2</span><span>**</span><span>x</span>
</code></pre></div></div>

<p>Unfortunately, no. Most math kernels are not just using built-in functions and
operators. They call out to external C libraries like NumPy or SciPy, and those
functions expect heap-allocated <code>PyLongObject</code>s. The C-API is simply <strong>not
ready</strong> to expose the underlying functions that operate on machine integers,
and it is also <strong>not ready</strong> for <a href="https://bernsteinbear.com/blog/small-objects/">tagged pointers</a>. This
would be a huge breaking change in the API and ABI. But okay, let’s assume for
the sake of blog post that the compiler team has a magic wand and can do all of
this.</p>

<div><div><pre><code><span>// Store 63-bit integers inside the pointer itself.</span>
<span>static</span> <span>const</span> <span>long</span> <span>kSmallIntTagBits</span> <span>=</span> <span>1</span><span>;</span>
<span>static</span> <span>const</span> <span>long</span> <span>kBits</span> <span>=</span> <span>64</span> <span>-</span> <span>kSmallIntTagBits</span><span>;</span>
<span>static</span> <span>const</span> <span>long</span> <span>kMaxValue</span> <span>=</span> <span>(</span><span>long</span><span>{</span><span>1</span><span>}</span> <span>&lt;&lt;</span> <span>(</span><span>kBits</span> <span>-</span> <span>1</span><span>))</span> <span>-</span> <span>1</span><span>;</span>

<span>PyObject</span><span>*</span> <span>PyLong_FromLong</span><span>(</span><span>long</span> <span>x</span><span>)</span> <span>{</span>
    <span>if</span> <span>(</span><span>x</span> <span>&lt;</span> <span>kMaxValue</span><span>)</span> <span>{</span>
        <span>return</span> <span>(</span><span>PyObject</span><span>*</span><span>)((</span><span>unsigned</span> <span>long</span><span>)</span><span>value</span> <span>&lt;&lt;</span> <span>kSmallIntTagBits</span><span>);</span>
    <span>}</span>
    <span>return</span> <span>MakeABigInt</span><span>(</span><span>x</span><span>);</span>
<span>}</span>

<span>PyObject</span><span>*</span> <span>PyLong_Add</span><span>(</span><span>PyObject</span><span>*</span> <span>left</span><span>,</span> <span>PyObject</span><span>*</span> <span>right</span><span>)</span> <span>{</span>
    <span>if</span> <span>(</span><span>IsSmallInt</span><span>(</span><span>left</span><span>)</span> <span>&amp;&amp;</span> <span>IsSmallInt</span><span>(</span><span>right</span><span>))</span> <span>{</span>
        <span>long</span> <span>result</span> <span>=</span> <span>Untag</span><span>(</span><span>left</span><span>)</span> <span>+</span> <span>Untag</span><span>(</span><span>right</span><span>);</span>
        <span>return</span> <span>PyLong_FromLong</span><span>(</span><span>result</span><span>);</span>
    <span>}</span>
    <span>return</span> <span>BigIntAdd</span><span>(</span><span>left</span><span>,</span> <span>right</span><span>);</span>
<span>}</span>
</code></pre></div></div>

<p>Then we’re set, right?</p>

<p>Unfortunately, there are still some other loose ends to tie up. While you may
have a nice and neatly typed numeric kernel of Python code, it has to interact
with the outside world. And the outside world is often not so well typed. Thank
you to Jeremy Siek and Walid Taha for giving us <a href="https://wphomes.soic.indiana.edu/jsiek/what-is-gradual-typing/">gradual
typing</a>—this is the reason anything gets typed at all in
Python—but you can’t do type-driven compilation of untyped code and expect it
to be fast.</p>

<p>This means that at the entry to your typed functions, you have to check the
types of the input objects. Maybe you can engineer a system such that a
function can have multiple entry points—one for untyped calls, one for typed
calls, and maybe even one for unboxed calls—but this hypothetical system’s
complexity is growing, and fast. And there are a whole host of other
complications and bits of dynamic behavior that I haven’t even mentioned.</p>

<div><div><pre><code><span>def</span> <span>typed_function_unboxed</span><span>(</span><span>x</span><span>:</span> <span>int64</span><span>,</span> <span>y</span><span>:</span> <span>int64</span><span>)</span> <span>-&gt;</span> <span>int64</span><span>:</span>
    <span>return</span> <span>int64_add</span><span>(</span><span>x</span><span>,</span> <span>y</span><span>)</span>

<span>def</span> <span>typed_function</span><span>(</span><span>x</span><span>:</span> <span>int</span><span>,</span> <span>y</span><span>:</span> <span>int</span><span>)</span> <span>-&gt;</span> <span>int</span><span>:</span>
    <span>return</span> <span>typed_function_unboxed</span><span>(</span><span>unbox</span><span>(</span><span>x</span><span>),</span> <span>unbox</span><span>(</span><span>y</span><span>))</span>

<span>def</span> <span>typed_function_shell</span><span>(</span><span>x</span><span>,</span> <span>y</span><span>):</span>
    <span>if</span> <span>not</span> <span>isinstance</span><span>(</span><span>x</span><span>,</span> <span>int</span><span>):</span>
        <span>raise</span> <span>TypeError</span><span>(</span><span>&#34;...&#34;</span><span>)</span>
    <span>if</span> <span>not</span> <span>isinstance</span><span>(</span><span>y</span><span>,</span> <span>int</span><span>):</span>
        <span>raise</span> <span>TypeError</span><span>(</span><span>&#34;...&#34;</span><span>)</span>
    <span>return</span> <span>typed_function</span><span>(</span><span>cast</span><span>(</span><span>x</span><span>,</span> <span>int</span><span>),</span> <span>cast</span><span>(</span><span>y</span><span>,</span> <span>int</span><span>))</span>

<span>f</span> <span>=</span> <span>make_typed_function</span><span>(</span><span>typed_function_shell</span><span>,</span> <span>typed_function</span><span>,</span> <span>typed_function_unboxed</span><span>)</span>
<span>f</span><span>(</span><span>3</span><span>,</span> <span>4</span><span>)</span>  <span># The dispatch gets hairy
</span></code></pre></div></div>

<p>And it’s not just about types, either! For example, variable binding,
especially global variable binding, is a performance impediment. Globals, even
builtins, are almost always overwritable by any random Python code.</p>

<p>“But Max,” you say, “Python compiler libraries like Numba clearly work just
fine. Just-in-time compilers have been doing this for years. What’s the deal?”</p>

<p>Just-in-time compilers can be so effective because they can speculate on things
that are not compile-time constants. Then, if the assumption is no longer true,
they can fall back on a (slower) interpreter. This is how
<a href="https://www.pypy.org/">PyPy</a>, the successor of
<a href="https://psyco.sourceforge.net/">Psyco</a>, does its amazing work specializing
data structures; the JIT does not have to handle every case. This interpreter
deoptimization is part of what makes JITs hard to understand and does not much
help with compiling code ahead-of-time.</p>

<p>This is what a PyPy trace might look like, taken from the 2011 paper <a href="https://dl.acm.org/doi/10.1145/2069172.2069181">Runtime
Feedback in a Meta-Tracing JIT for Efficient Dynamic
Languages</a>. Every <code>guard</code> is a
potential exit from JITed code to the interpreter:</p>

<div><div><pre><code><span># inst1.getattr(&#34;a&#34;)
</span><span>map1</span> <span>=</span> <span>inst1</span><span>.</span><span>map</span>
<span>guard</span><span>(</span><span>map1</span> <span>==</span> <span>0xb74af4a8</span><span>)</span>
<span>index1</span> <span>=</span> <span>Map</span><span>.</span><span>getindex</span><span>(</span><span>map1</span><span>,</span> <span>&#34;a&#34;</span><span>)</span>
<span>guard</span><span>(</span><span>index1</span> <span>!=</span> <span>-</span><span>1</span><span>)</span>
<span>storage1</span> <span>=</span> <span>inst1</span><span>.</span><span>storage</span>
<span>result1</span> <span>=</span> <span>storage1</span><span>[</span><span>index1</span><span>]</span>
</code></pre></div></div>

<p>And the other thing is, Numba doesn’t exactly compile <em>Python</em>…</p>

<h2 id="dialects">Dialects</h2>

<p>Numba is great! I cannot emphasize enough how much I am <strong>not</strong> trying to pick
on Numba here. The team put in a lot of hard work and solid engineering and
built a compiler that produces very fast numerical code.</p>

<p>It’s possible to do this because Numba compiles a superficially similar
language that is much less dynamic and is focused on numerics. For people who
work with data analytics and machine learning, this is incredible!
Unfortunately, it doesn’t generalize to arbitrary Python code.</p>

<p>This is also true of many other type-driven compiler projects that optimize
“Python” code:</p>

<ul>
  <li><a href="https://github.com/cython/cython">Cython</a>/<a href="https://www.csse.canterbury.ac.nz/greg.ewing/python/Pyrex/">Pyrex</a></li>
  <li><a href="https://docs.micropython.org/en/v1.9.3/pyboard/reference/speed_python.html#the-viper-code-emitter">MicroPython Viper</a></li>
  <li><a href="https://www.modular.com/mojo">Mojo</a></li>
  <li><a href="https://github.com/mypyc/mypyc">Mypyc</a></li>
  <li><a href="https://github.com/shedskin/shedskin">Shed Skin</a></li>
  <li><a href="http://michael.salib.com/writings/thesis/thesis.pdf">Starkiller</a> (PDF)</li>
  <li><a href="https://github.com/facebookincubator/cinder/#static-python">Static Python</a></li>
  <li><a href="https://github.com/APrioriInvestments/typed_python/blob/dev/docs/introduction.md">Typed Python</a></li>
</ul>

<p>and in particular to optimize numerics:</p>

<ul>
  <li><a href="https://github.com/exaloop/codon">Codon</a></li>
  <li><a href="https://github.com/numba/numba">Numba</a></li>
  <li><a href="https://github.com/lcompilers/lpython">lpython</a></li>
  <li><a href="https://github.com/pyccel/pyccel/blob/devel/tutorial/quickstart.md">Pyccel</a></li>
  <li><a href="https://pythran.readthedocs.io/en/latest/">Pythran</a></li>
  <li><a href="https://github.com/taichi-dev/taichi">Taichi</a></li>
  <li><a href="https://www.tensorflow.org/xla">TensorFlow JIT/XLA</a></li>
  <li><a href="https://pytorch.org/docs/stable/jit_language_reference.html">TorchScript</a></li>
</ul>

<p>and probably more that I forgot about or could not find (please feel free to
submit a PR).</p>

<p>It does raise an interesting question, though: what if you intentionally and
explicitly eschew the more dynamic features? Can you get performance in return?
It turns out, yes. Absolutely yes.</p>

<h2 id="stronger-guarantees">Stronger guarantees</h2>

<p>As people have continually rediscovered over the years, Python is hard to
optimize statically. Functions like the following, which “only” do an attribute
load, have no hope whatsoever of being optimized out of context:</p>

<div><div><pre><code><span>def</span> <span>get_an_attr</span><span>(</span><span>o</span><span>):</span>
    <span>return</span> <span>o</span><span>.</span><span>value</span>
</code></pre></div></div>

<p>This is because <code>o</code> could be any object, types can define custom attribute
resolution by defining a <code>__getattr__</code> function, and therefore attribute loads
are equivalent to running opaque blobs of user code.</p>

<p>Even if the function is typed, you still run into the subclass problem
described earlier. You also have issues like instance attributes, deleting
attributes, descriptor shadowing, and so on.</p>

<div><div><pre><code><span>class</span> <span>C</span><span>:</span>
    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>):</span>
        <span>self</span><span>.</span><span>value</span> <span>=</span> <span>5</span>


<span>def</span> <span>get_an_attr</span><span>(</span><span>o</span><span>:</span> <span>C</span><span>):</span>
    <span>return</span> <span>o</span><span>.</span><span>value</span>
</code></pre></div></div>

<p><em>However</em>, if you intentionally opt out of a lot of that dynamism, things start
getting interesting. The <a href="https://github.com/facebookincubator/cinder/#static-python">Static
Python</a> compiler,
for example, is part of the Cinder project, and lets you trade dynamism for
speed. If a module is marked static with <code>import __static__</code>, Cinder will swap
out the standard bytecode compiler for the Static Python bytecode compiler,
which <em>compiles a different language</em>!</p>

<p>By way of example, the SP compiler will automatically slotify all of the
classes in a SP module and prohibit a <code>__dict__</code> slot. This means that features
that used to work—dynamically creating and deleting attributes, etc—no
longer do. But it also means that attribute loads from static classes are
actually only three machine instructions now. This tradeoff makes the compiler
transform <em>sound</em>. Most people like this tradeoff.</p>

<div><div><pre><code><span>import</span> <span>__static__</span>

<span>class</span> <span>C</span><span>:</span>
    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>):</span>
        <span>self</span><span>.</span><span>value</span><span>:</span> <span>int</span> <span>=</span> <span>5</span>

<span>def</span> <span>get_an_attr</span><span>(</span><span>o</span><span>:</span> <span>C</span><span>):</span>
    <span>return</span> <span>o</span><span>.</span><span>value</span>
<span># ...
# mov rax,QWORD PTR [rsi+0x10]  # Load the field
# test rax,rax                  # Check if null
# je 0x7f823ba17283             # Maybe raise an exception
# ...
</span></code></pre></div></div>

<p>Static Python does this just with existing Python annotations. It has some more
constraints than Mypy does (you can’t <code>ignore</code> your type errors away, for
example), but it does not change the syntax of Python. But it’s important to
know that this does not just immediately follow from a type-directed
translation. It requires opting into stricter checking and different behavior
for an entire typed core of a codebase—potentially gradually (SP can call
untyped Python and vice versa). It requires changing the runtime representation
of objects from header+dictionary to header+array of slots. For this reason it
is (currently) implemented as a custom compiler, custom bytecode interpreter,
and with support in the Cinder JIT. To learn more, check out the Static Python
team’s <a href="https://cs.brown.edu/~sk/Publications/Papers/Published/lgmvpk-static-python/">paper collaboration with Brown</a>,
which explains a bit more about the gradual typing bits and soundness.</p>

<p>I would be remiss if I did not also mention
<a href="https://github.com/mypyc/mypyc">Mypyc</a> (the optimizer and code generator for
Mypy). Mypyc is very similar to Static Python in that it takes something that
looks like Python with types and generates type-optimized code. It is different
in that it generates C extensions and does <a href="https://mypyc.readthedocs.io/en/latest/int_operations.html">tagged pointers for
integers</a> by
default. Depending on your use case—in particular, your deployment story—it
may be the compiler that you want to use! The Black formatter, for example, has
had <a href="https://ichard26.github.io/blog/2022/05/compiling-black-with-mypyc-part-1/">great
success</a>
using Mypyc.</p>

<p>In addition to the normal types available, both Static Python and Mypyc allow
typing parameters and other variables as primitive ints like <code>int8</code> so you can
get the unbox arithmetic that people tend to expect on first reading of the
first code snippet in this post.</p>

<div><div><pre><code><span># An example snippet that is allowed by Mypy but not by Static Python because
# it would be dangerous.
</span><span>def</span> <span>foo</span><span>(</span><span>x</span><span>:</span> <span>int</span><span>)</span> <span>-&gt;</span> <span>int</span><span>:</span>
    <span>return</span> <span>x</span>

<span>foo</span><span>(</span><span>&#34;hello&#34;</span><span>)</span>  <span># type: ignore
</span></code></pre></div></div>

<p>In this example,</p>

<ul>
  <li>CPython ignores the annotations completely</li>
  <li>Mypy lets the type mismatch slide due to <code>type: ignore</code>
    <ul>
      <li>Which, interestingly enough, means Mypyc defers the problem to run-time by
injecting an <code>unbox</code> that might cleanly raise a <code>TypeError</code></li>
    </ul>
  </li>
  <li>Static Python does not allow this code to compile
    <ul>
      <li>Note that non-Static Python code in the same project would not be
compile-time checked and therefore would only get a run-time <code>TypeError</code> at
the boundary if they called <code>foo</code> with a non-<code>int</code></li>
    </ul>
  </li>
</ul>

<p>All of these are reasonable behaviors because each project has different goals.</p>

<p>Other projects take this further. The <a href="https://www.modular.com/mojo">Mojo</a>
project, for example, aims to create a much bigger and more visibly different
new language that is a proper superset of Python<sup id="fnref:chris" role="doc-noteref"><a href="#fn:chris" rel="footnote">4</a></sup>. The Python code it
runs should continue to work as advertised, but modules can opt into less
dynamism by iteratively converting their Python code to something that looks a
little different. They also do a bunch of other neat stuff, but that’s outside
the scope of this blog post.</p>

<p>See for example this snippet defining a struct (a new feature) that reads like
a Python class but has some stronger mutability and binding guarantees:</p>

<div><div><pre><code><span>@</span><span>value</span>
<span>struct</span> <span>MyPair</span><span>:</span>
    <span>var</span> <span>first</span><span>:</span> <span>Int</span>
    <span>var</span> <span>second</span><span>:</span> <span>Int</span>
    <span>def</span> <span>__lt__</span><span>(</span><span>self</span><span>,</span> <span>rhs</span><span>:</span> <span>MyPair</span><span>)</span> <span>-&gt;</span> <span>Bool</span><span>:</span>
        <span>return</span> <span>self</span><span>.</span><span>first</span> <span>&lt;</span> <span>rhs</span><span>.</span><span>first</span> <span>or</span>
              <span>(</span><span>self</span><span>.</span><span>first</span> <span>==</span> <span>rhs</span><span>.</span><span>first</span> <span>and</span>
               <span>self</span><span>.</span><span>second</span> <span>&lt;</span> <span>rhs</span><span>.</span><span>second</span><span>)</span>
</code></pre></div></div>

<p>It even looks like the <code>@value</code> decorator gives you value semantics.</p>

<p>Per the Mojo <a href="https://docs.modular.com/mojo/programming-manual.html#struct-types">docs</a>,</p>

<blockquote>
  <p>Mojo structs are static: they are bound at compile-time (you cannot add
methods at runtime). Structs allow you to trade flexibility for performance
while being safe and easy to use.</p>

  <p>[…]</p>

  <p>In Mojo, the structure and contents of a “struct” are set in advance and
can’t be changed while the program is running. Unlike in Python, where you
can add, remove, or change attributes of an object on the fly, Mojo doesn’t
allow that for structs. This means you can’t use <code>del</code> to remove a method or
change its value in the middle of running the program.</p>
</blockquote>

<p>Seems neat. We’ll see what it looks like more when it’s open sourced.</p>

<p>And finally, even if you are not trying to do optimized code generation,
packaging up all the code at app bundle time can help save big on runtime
startup. If you don’t need to hit the disk at least once per imported module,
you get some big wins in time and code locality. <em>ngoldbaum</em> on lobste.rs
<a href="https://lobste.rs/s/lnyfm6/compiling_typed_python#c_kifkr4">notes</a> that
<a href="https://github.com/indygreg/PyOxidizer">PyOxidizer</a> can bundle your code into
the data segment of an executable.</p>

<p>This already happens with the <a href="https://docs.python.org/3.11/whatsnew/3.11.html#faster-startup">frozen built-in
modules</a> (was
just <code>importlib</code> before 3.11) and has been tried before with entire
applications
(<a href="https://mail.python.org/pipermail/python-dev/2018-May/153367.html">one</a>,
<a href="https://bugs.python.org/issue36839">two</a>,
<a href="https://github.com/faster-cpython/ideas/discussions/150">three</a>
(productionized <a href="https://github.com/alibaba/code-data-share-for-python">here</a>),
and maybe others) with varying upstreaming success.</p>

<h2 id="other-approaches">Other approaches</h2>

<p><a href="https://github.com/Nuitka/Nuitka">Nuitka</a> (not mentioned above) is a
whole-program compiler from Python to C. As far as I can tell, it does not use
your type annotations in the compilation process. Instead it uses its own
optimization pipeline, including function inlining, etc, to discover types.
Please correct me if I am wrong!</p>

<h3 id="in-other-languages">In other languages</h3>

<p>If you don’t like this whole “typed kernel” idea, other compilers like Graal’s
<a href="https://docs.oracle.com/en/graalvm/enterprise/20/docs/reference-manual/native-image/#native-image">SubstrateVM</a>
do some advanced wizardry to analyze your whole program.</p>

<p>SubstrateVM is an ahead-of-time compiler for Java that looks at your entire
codebase as a unit. It does some intense inter-procedural static analysis to
prove things about your code that can help with performance. It also subtly
changes the language, though. In order to do this analysis, it prohibits
arbitrary loading of classes at runtime. It also limits the amount of
reflection to some known feature subset.</p>

<h2 id="what-this-means-for-the-average-python-programmer">What this means for the average Python programmer</h2>

<p>If you are working on a science thing or machine learning project, you most
likely have a bunch of glue around some fast core of hardcore math. If you add
types and use one of the excellent compilers listed above, you will probably
get some performance benefits.</p>

<p>If you are working on some other project, though, you may not have such a clear
performance hotspot. Furthermore, you may not be working with objects that have
fast primitive representations, like <code>int</code>. You probably have a bunch of data
structures, etc. In that case, some of the projects above like Mypyc and
Static Python and Nuitka can probably help you. But you will need to add types,
probably fix some type errors, and then change how you build and run your
application.</p>

<p>Unfortunately for everybody who writes Python, a huge portion of code that
needs to be fast is written as C extensions because of historical reasons. This
means that you can optimize the Python portion of your application all you
like, but the C extension will remain an opaque blob (unless your compiler
understands it like Numba understands NumPy, that is). This means that you may
need to eventually re-write your C code as Python to fully reap all the
performance benefits. Or at least <a href="https://github.com/faster-cpython/ideas/issues/546">type the
boundary</a>.</p>

<h2 id="what-this-means-for-other-dynamic-languages">What this means for other dynamic languages</h2>

<p>These questions about and issues with straightforward type-driven compilation
are not unique to Python. The Sorbet team had to do <a href="https://sorbet.org/blog/2021/07/30/open-sourcing-sorbet-compiler">a lot of
work</a> to make
this possible for Ruby. People ask the same thing about typed JavaScript (like
TypeScript) and probably other languages, too. People will have to work out
similar solutions. People are working on this; there is at least one neat
extant typed JS project that I have been asked not to publicize yet.</p>

<p>There is also Manuel Serrano’s whole-program <a href="https://www-sop.inria.fr/members/Manuel.Serrano/publi/serrano-dls18.pdf">AOT
compiler</a>
(PDF) for JS, called Hopc. It will ignore your type annotations and do its own
analysis, though. Serrano notes:</p>

<blockquote>
  <p>Hint types are unsound as they do not denote super sets of all the possible
values variables can hold at runtime, neither they abstract all possible
correct program executions.</p>

  <p>[…]</p>

  <p>Type information alone is not enough to generate fast code. For that, the
compilation chain has to include all sorts of optimizations such as inline
property caches, closure allocation, function inlining, data-flow analysis,
register allocation, etc.</p>
</blockquote>

<p>Seems about right.</p>

<h2 id="wrapping-up">Wrapping up</h2>

<p>Types are not ironclad guarantees of data layout. Changing the language you are
compiling to prohibit certain kinds of dynamism can help you with performance.
Several projects already do this and it seems to be growing in popularity.</p>

<p>If nothing else, I hope you have more of an understanding of what types mean
from a correctness perspective, from a performance perspective, and how they do
not always overlap.</p>

<p>I also hope you don’t come away from this post feeling sad. I actually hope you
feel hopeful! Tons of brilliant engineers are working tirelessly to make your
code run faster.</p>

<h3 id="further-reading">Further reading</h3>

<p>After publishing this post I came across <a href="https://arxiv.org/abs/1902.07808">Optimizing and Evaluating Transient
Gradual Typing</a> which adds type checks to
CPython and erases redundant ones, and then realized that this was also cited
in the Brown paper. The whole series of papers is really interesting. And
apparently I was coworkers with Michael Vitousek for over four years. Neat!</p>

<!-- jscomp? https://github.com/tmikov/jscomp -->
<!-- smalls https://github.com/tmikov/smalls -->
<!-- mycpp -->
<!-- mention Julia and how it handles dispatch -->
<!-- mention the other 15 dialects of type checkers like pyre, pyright, etc -->
<!-- mention pyoxidizer, icepack, carl's post on python-dev, ... for putting
code in data segment for faster startup -->
<!-- note that it's subtly different from falcon paper observation ("everything
is a function call") in that there is a misleading notion that type information
is available and useful when it's really not -->


<hr/>

<!-- Footnotes -->


        </div></div>
  </body>
</html>
