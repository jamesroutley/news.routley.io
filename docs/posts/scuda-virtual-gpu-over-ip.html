<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/kevmo314/scuda">Original</a>
    <h1>Scuda – Virtual GPU over IP</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto">SCUDA is a GPU over IP bridge allowing GPUs on remote machines to be attached
to CPU-only machines.</p>

<p dir="auto">The below demo displays a NVIDIA GeForce RTX 4090 running on a remote machine (right pane).
Left pane is a Mac running a docker container with nvidia utils installed.</p>
<p dir="auto">The docker container runs <code>python3 -c &#34;import torch; print(torch.cuda.is_available())&#34;</code> to check if cuda is available.</p>
<p dir="auto">You can view the docker image used <a href="https://github.com/kevmo314/scuda/blob/main/Dockerfile.test">here</a>.</p>
<details open="">
  <summary>
    <svg aria-hidden="true" height="16" viewBox="0 0 16 16" version="1.1" width="16" data-view-component="true">
    <path d="M16 3.75v8.5a.75.75 0 0 1-1.136.643L11 10.575v.675A1.75 1.75 0 0 1 9.25 13h-7.5A1.75 1.75 0 0 1 0 11.25v-6.5C0 3.784.784 3 1.75 3h7.5c.966 0 1.75.784 1.75 1.75v.675l3.864-2.318A.75.75 0 0 1 16 3.75Zm-6.5 1a.25.25 0 0 0-.25-.25h-7.5a.25.25 0 0 0-.25.25v6.5c0 .138.112.25.25.25h7.5a.25.25 0 0 0 .25-.25v-6.5ZM11 8.825l3.5 2.1v-5.85l-3.5 2.1Z"></path>
</svg>
    <span aria-label="Video description Screen.Recording.2024-10-08.at.8.27.07.PM.mp4">Screen.Recording.2024-10-08.at.8.27.07.PM.mp4</span>
    <span></span>
  </summary>

  <video src="https://private-user-images.githubusercontent.com/16856596/374761360-035950bb-3cc1-4c73-9ad5-b00871a159ec.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mjg2NTY0NjYsIm5iZiI6MTcyODY1NjE2NiwicGF0aCI6Ii8xNjg1NjU5Ni8zNzQ3NjEzNjAtMDM1OTUwYmItM2NjMS00YzczLTlhZDUtYjAwODcxYTE1OWVjLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDEwMTElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMDExVDE0MTYwNlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTYwMTYxNTMyMGUxM2MxMzIwOWI3NjgzNmY5OGRiY2QxZTQ3ZGIwNGQ3ZDViZGNkODM3YjE4ODE0Mzk0NTk2ZTQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.Z1QX2CgG9LRPXnYIjLQ3VAuCnAR4Q-WspGUmUzjTjxI" data-canonical-src="https://private-user-images.githubusercontent.com/16856596/374761360-035950bb-3cc1-4c73-9ad5-b00871a159ec.mp4?jwt=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpc3MiOiJnaXRodWIuY29tIiwiYXVkIjoicmF3LmdpdGh1YnVzZXJjb250ZW50LmNvbSIsImtleSI6ImtleTUiLCJleHAiOjE3Mjg2NTY0NjYsIm5iZiI6MTcyODY1NjE2NiwicGF0aCI6Ii8xNjg1NjU5Ni8zNzQ3NjEzNjAtMDM1OTUwYmItM2NjMS00YzczLTlhZDUtYjAwODcxYTE1OWVjLm1wND9YLUFtei1BbGdvcml0aG09QVdTNC1ITUFDLVNIQTI1NiZYLUFtei1DcmVkZW50aWFsPUFLSUFWQ09EWUxTQTUzUFFLNFpBJTJGMjAyNDEwMTElMkZ1cy1lYXN0LTElMkZzMyUyRmF3czRfcmVxdWVzdCZYLUFtei1EYXRlPTIwMjQxMDExVDE0MTYwNlomWC1BbXotRXhwaXJlcz0zMDAmWC1BbXotU2lnbmF0dXJlPTYwMTYxNTMyMGUxM2MxMzIwOWI3NjgzNmY5OGRiY2QxZTQ3ZGIwNGQ3ZDViZGNkODM3YjE4ODE0Mzk0NTk2ZTQmWC1BbXotU2lnbmVkSGVhZGVycz1ob3N0In0.Z1QX2CgG9LRPXnYIjLQ3VAuCnAR4Q-WspGUmUzjTjxI" controls="controls" muted="muted">

  </video>
</details>


<p dir="auto">Make the local dev script executable</p>

<p dir="auto">Also helpful to alias this local script in your bash profile.</p>
<div dir="auto" data-snippet-clipboard-copy-content="alias s=&#39;/home/brodey/scuda-latest/local.sh&#39;"><pre><span>alias</span> s=<span><span>&#39;</span>/home/brodey/scuda-latest/local.sh<span>&#39;</span></span></pre></div>
<p dir="auto">It&#39;s required to run scuda server before initiating client commands.</p>


<p dir="auto">If the server above is running:</p>

<p dir="auto">The above will rebuild the client and run nvidia-smi for you.</p>

<p dir="auto">To install SCUDA, run the server binary on the GPU host:</p>

<p dir="auto">Then, on the client, run:</p>


<div dir="auto" data-snippet-clipboard-copy-content="nvcc -shared -o libscuda.so client.c"><pre>nvcc -shared -o libscuda.so client.c</pre></div>
<p dir="auto">This library can then be preloaded</p>
<div dir="auto" data-snippet-clipboard-copy-content="LD_PRELOAD=libscuda.so nvidia-smi"><pre>LD_PRELOAD=libscuda.so nvidia-smi</pre></div>
<p dir="auto">By default, the client library passes calls through to the client. In other words,
it does not connect to a server. To connect to a server, create a file with the
host you wish to connect to</p>


<p dir="auto">The goal of SCUDA is to enable developers to easily interact with GPUs over a network in order to take advantage of various pools of distributed GPUs. Obviously TCP is slower than traditional methods, but we have plans to minimize performance impact through various methods.</p>
<div dir="auto"><h3 tabindex="-1" dir="auto">Some use cases / motivations:</h3><a id="user-content-some-use-cases--motivations" aria-label="Permalink: Some use cases / motivations:" href="#some-use-cases--motivations"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<ol dir="auto">
<li>
<p dir="auto"><strong>Local testing</strong> - For testing purposes, the latency added by TCP is acceptable, as the goal is to verify compatibility and performance rather than achieving the lowest latency. The remote GPU can still fully accelerate the application, allowing a developer to run tests they otherwise couldn’t on their local setup.</p>
</li>
<li>
<p dir="auto"><strong>Aggregated GPU pools</strong> - The goal is to centralize GPU management and resource allocation, making it easier to deploy and scale containerized applications that need GPU support without worrying about GPU availability. SCUDA will eventually handle capacity management and pooling.</p>
</li>
<li>
<p dir="auto"><strong>Remote model training</strong> - Developers can train models from their laptops or low-power devices, using GPUs optimized for training without needing to deploy a full VM or move the entire development environment to the remote location.</p>
</li>
<li>
<p dir="auto"><strong>Remote inferencing</strong> - For remote inferencing, devs can set up their application locally but direct all CUDA calls for model inference to a remote GPU server. The application can thus process large batches of images or video frames using the remote GPU’s acceleration capabilities.</p>
</li>
<li>
<p dir="auto"><strong>Remote data processing</strong> - Developers can run operations like filtering, joining, and aggregating data directly on the remote GPU, while the results are transferred back over the network. Technically, developers can accelerate matrix multiplication or linear algebra computations on large datasets by offloading these computations to a remote GPU; they can run their scripts locally while utilizing the power of a remote machine.</p>
</li>
<li>
<p dir="auto"><strong>Remote fine-tuning</strong> - Developers can download a pre-trained model (ex: resnet) and fine-tune it. With SCUDA, training is done remotely using the library to route PyTorch CUDA calls over TCP to a remote GPU, allowing the developer to run the fine-tuning process from their local machine or Jupyter Notebook environment.</p>
</li>
</ol>

<p dir="auto">See our <a href="https://github.com/kevmo314/scuda/blob/main/TODO.md">TODO</a>.</p>

<p dir="auto">This project is inspired by some existing proprietary solutions:</p>
<ul dir="auto">
<li><a href="https://www.thundercompute.com/" rel="nofollow">https://www.thundercompute.com/</a></li>
<li><a href="https://www.juicelabs.co/" rel="nofollow">https://www.juicelabs.co/</a></li>
<li><a href="https://en.wikipedia.org/wiki/RCUDA" rel="nofollow">https://en.wikipedia.org/wiki/RCUDA</a> (That&#39;s where SCUDA&#39;s name comes from, S is the next letter after R!)</li>
</ul>

<p dir="auto">todo</p>
</article></div></div>
  </body>
</html>
