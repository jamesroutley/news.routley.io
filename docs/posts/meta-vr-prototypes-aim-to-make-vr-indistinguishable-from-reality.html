<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.roadtovr.com/meta-vr-headset-prototypes-visual-fidelity-indistinguishable-from-reality/">Original</a>
    <h1>Meta VR prototypes aim to make VR &#39;indistinguishable from reality&#39;</h1>
    
    <div id="readability-page-1" class="page"><div id="rtvr-article">

    
            <!-- Share buttons by mashshare.net - Version: 3.4.0--><p>Meta says its ultimate goal with its VR hardware is to make a comfortable, compact headset with visual finality that’s ‘indistinguishable from reality’. Today the company revealed its latest VR headset prototypes which it says represent steps toward that goal.</p>

<p>Meta has made it no secret that it’s dumping tens of billions of dollars in its XR efforts, much of which is going to long-term R&amp;D through its Reality Labs Research division. Apparently in an effort to shine a bit of light onto what that money is actually accomplishing, the company invited a group of press to sit down for a look at its latest accomplishments in VR hardware R&amp;D.</p>
<p><iframe width="640" height="360" src="https://www.youtube.com/embed/IMpWH6vDZ8E?feature=oembed" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture" allowfullscreen="" title="Zuckerberg Reveals Meta&#39;s Latest Prototype VR Headsets"></iframe></p>
<h3>Reaching the Bar</h3>
<p>To start, Meta CEO Mark Zuckerberg spoke alongside Reality Labs Chief Scientist Michael Abrash to <a href="https://youtu.be/sThLeiw8h2Y">explain that the company’s ultimate goal is to build VR hardware that meets all the visual requirements to be accepted as “real” by your visual system</a>.</p>
<p>VR headsets today are impressively immersive, but there’s still no question that what you’re looking at is, well… virtual.</p>
<p>Inside of Meta’s Reality Labs Research division, the company uses the term ‘visual Turing Test’ to represent the bar that needs to be met to convince your visual system that what’s inside the headset is <em>actually</em> real. The concept is borrowed from a similar concept which denotes the point at which a human can tell the difference between another human and an artificial intelligence.</p>
<p>For a headset to completely convince your visual system that what’s inside the headset is <em>actually</em> real, Meta says you need a headset that can pass that “visual Turing Test.”</p>
<h3>Four Challenges</h3>
<p>Zuckerberg and Abrash outlined what they see as four key visual challenges that VR headsets need to solve before the visual Turing Test can be passed: varifocal, distortion, retina resolution, and HDR.</p>
<p>Briefly, here’s what those mean:</p>
<ul>
<li>Varifocal: the ability to focus on arbitrary depths of the virtual scene, with both essential focus functions of the eyes (vergence and accommodation)</li>
<li>Distortion: lenses inherently distort the light that passes through them, often creating artifacts like color separation and pupil swim that make the existence of the lens obvious.</li>
<li>Retina resolution: having enough resolution in the display to meet or exceed the resolving power of the human eye, such that there’s no evidence of underlying pixels</li>
<li>HDR: also known as high dynamic range, which describes the range of darkness and brightness that we experience in the real world (which almost no display today can properly emulate).</li>
</ul>
<p>The Display Systems Research team at Reality Labs has built prototypes that function as proof-of-concepts for potential solutions to these challenges.</p>
<h3>Varifocal</h3>
<figure id="attachment_108424"><a href="https://roadtovrlive-5ea0.kxcdn.com/wp-content/uploads/2022/06/meta-reality-labs-research-vr-headset-prototype-2.jpg"><img src="https://roadtovrlive-5ea0.kxcdn.com/wp-content/uploads/2022/06/meta-reality-labs-research-vr-headset-prototype-2-640x242.jpg" alt="" width="640" height="242" srcset="https://roadtovrlive-5ea0.kxcdn.com/wp-content/uploads/2022/06/meta-reality-labs-research-vr-headset-prototype-2-640x242.jpg 640w, https://roadtovrlive-5ea0.kxcdn.com/wp-content/uploads/2022/06/meta-reality-labs-research-vr-headset-prototype-2-325x123.jpg 325w, https://roadtovrlive-5ea0.kxcdn.com/wp-content/uploads/2022/06/meta-reality-labs-research-vr-headset-prototype-2-768x291.jpg 768w, https://roadtovrlive-5ea0.kxcdn.com/wp-content/uploads/2022/06/meta-reality-labs-research-vr-headset-prototype-2-1109x420.jpg 1109w, https://roadtovrlive-5ea0.kxcdn.com/wp-content/uploads/2022/06/meta-reality-labs-research-vr-headset-prototype-2-681x258.jpg 681w" sizes="(max-width: 640px) 100vw, 640px"/></a><figcaption>Image courtesy Meta</figcaption></figure>
<p>To address varifocal, the team developed a series of prototypes which it called ‘Half Dome’. In that series the company first explored a varifocal design which used a mechanically moving display to change the distance between the display and the lens, thus changing the focal depth of the image. Later the team moved to a solid-state electronic system which resulted in varifocal optics that were significantly more compact, reliable, and silent. We’ve <a href="https://www.roadtovr.com/oculus-half-dome-2-3-prototype-form-factor-oculus-connect-6/">covered the Half Dome prototypes in greater detail here</a> if you want to know more.</p>
<h3>Virtual Reality… For Lenses</h3>
<p>As for distortion, Abrash explained that experimenting with lens designs and distortion-correction algorithms that are specific to those lens designs is a cumbersome process. Novel lenses can’t be made quickly, he said, and once they are made they still need to be carefully integrated into a headset.</p>
<p>To allow the Display Systems Research team to work more quickly on the issue, the team built a ‘distortion simulator’, which actually emulates a VR headset using a 3DTV, and simulates lenses (and their corresponding distortion-correction algorithms) in-software.</p>
<figure id="attachment_108429"><a href="https://roadtovrlive-5ea0.kxcdn.com/wp-content/uploads/2022/06/meta-reality-labs-research-vr-headset-prototype-7.jpg"><img src="https://roadtovrlive-5ea0.kxcdn.com/wp-content/uploads/2022/06/meta-reality-labs-research-vr-headset-prototype-7-640x358.jpg" alt="" width="640" height="358" srcset="https://roadtovrlive-5ea0.kxcdn.com/wp-content/uploads/2022/06/meta-reality-labs-research-vr-headset-prototype-7-640x358.jpg 640w, https://roadtovrlive-5ea0.kxcdn.com/wp-content/uploads/2022/06/meta-reality-labs-research-vr-headset-prototype-7-325x182.jpg 325w, https://roadtovrlive-5ea0.kxcdn.com/wp-content/uploads/2022/06/meta-reality-labs-research-vr-headset-prototype-7-768x430.jpg 768w, https://roadtovrlive-5ea0.kxcdn.com/wp-content/uploads/2022/06/meta-reality-labs-research-vr-headset-prototype-7-750x420.jpg 750w, https://roadtovrlive-5ea0.kxcdn.com/wp-content/uploads/2022/06/meta-reality-labs-research-vr-headset-prototype-7-681x381.jpg 681w" sizes="(max-width: 640px) 100vw, 640px"/></a><figcaption>Image courtesy Meta</figcaption></figure>
<p>Doing so has allowed the team to iterate on the problem more quickly, wherein the key challenge is to dynamically correct lens distortions as the eye moves, rather than merely correcting for what is seen when the eye is looking in the immediate center of the lens.</p>
<h3>Retina Resolution</h3>
<figure id="attachment_108422"><a href="https://roadtovrlive-5ea0.kxcdn.com/wp-content/uploads/2022/06/meta-reality-labs-research-vr-headset-prototype-1.jpg"><img src="https://roadtovrlive-5ea0.kxcdn.com/wp-content/uploads/2022/06/meta-reality-labs-research-vr-headset-prototype-1-640x430.jpg" alt="" width="640" height="430" srcset="https://roadtovrlive-5ea0.kxcdn.com/wp-content/uploads/2022/06/meta-reality-labs-research-vr-headset-prototype-1-640x430.jpg 640w, https://roadtovrlive-5ea0.kxcdn.com/wp-content/uploads/2022/06/meta-reality-labs-research-vr-headset-prototype-1-325x218.jpg 325w, https://roadtovrlive-5ea0.kxcdn.com/wp-content/uploads/2022/06/meta-reality-labs-research-vr-headset-prototype-1-768x516.jpg 768w, https://roadtovrlive-5ea0.kxcdn.com/wp-content/uploads/2022/06/meta-reality-labs-research-vr-headset-prototype-1-625x420.jpg 625w, https://roadtovrlive-5ea0.kxcdn.com/wp-content/uploads/2022/06/meta-reality-labs-research-vr-headset-prototype-1-537x360.jpg 537w, https://roadtovrlive-5ea0.kxcdn.com/wp-content/uploads/2022/06/meta-reality-labs-research-vr-headset-prototype-1-681x458.jpg 681w" sizes="(max-width: 640px) 100vw, 640px"/></a><figcaption>Image courtesy Meta</figcaption></figure>
<p>On the retina resolution front, Meta revealed a previously unseen headset prototype called Butterscotch, which the company says achieves a retina resolution of 60 pixels per degree, allowing for 20/20 vision. To do so, they used extremely pixel-dense displays and reduced the field-of-view—in order to concentrate the pixels over a smaller area—to about half the size of Quest 2. The company says it also developed a “hybrid lens” that would “fully resolve” the increased resolution, and it shared through-the-lens comparisons between the original Rift, Quest 2, and the Butterscotch prototype.</p>
<figure id="attachment_108428"><a href="https://roadtovrlive-5ea0.kxcdn.com/wp-content/uploads/2022/06/meta-reality-labs-research-vr-headset-prototype-6.jpg"><img src="https://roadtovrlive-5ea0.kxcdn.com/wp-content/uploads/2022/06/meta-reality-labs-research-vr-headset-prototype-6-640x360.jpg" alt="" width="640" height="360" srcset="https://roadtovrlive-5ea0.kxcdn.com/wp-content/uploads/2022/06/meta-reality-labs-research-vr-headset-prototype-6-640x360.jpg 640w, https://roadtovrlive-5ea0.kxcdn.com/wp-content/uploads/2022/06/meta-reality-labs-research-vr-headset-prototype-6-325x183.jpg 325w, https://roadtovrlive-5ea0.kxcdn.com/wp-content/uploads/2022/06/meta-reality-labs-research-vr-headset-prototype-6-768x432.jpg 768w, https://roadtovrlive-5ea0.kxcdn.com/wp-content/uploads/2022/06/meta-reality-labs-research-vr-headset-prototype-6-747x420.jpg 747w, https://roadtovrlive-5ea0.kxcdn.com/wp-content/uploads/2022/06/meta-reality-labs-research-vr-headset-prototype-6-681x383.jpg 681w" sizes="(max-width: 640px) 100vw, 640px"/></a><figcaption>Image courtesy Meta</figcaption></figure>
<p>While there are already headsets out there today that offer retina resolution—like Varjo’s VR-3 headset—only a small area in the middle of the view (27° × 27°) hits the 60 PPD mark… anything outside of that area drops to 30 PPD or lower. Ostensibly Meta’s Butterscotch prototype has 60 PPD across its entirely of the field-of-view, though the company didn’t explain to what extent resolution is reduced toward the edges of the lens.</p>
<h3><a href="https://punchagan.muse-amuse.in/meta-vr-headset-prototypes-visual-fidelity-indistinguishable-from-reality/2/"><em>Continue on Page 2: High Dynamic Range, Downsizing »</em></a></h3>

	
    </div></div>
  </body>
</html>
