<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://ashvardanian.com/posts/beyond-openmp-in-cpp-rust/">Original</a>
    <h1>Beyond OpenMP in C&#43;&#43; and Rust: Taskflow, Rayon, Fork Union</h1>
    
    <div id="readability-page-1" class="page"><div><blockquote><p>TL;DR: Most C++‚ÄØand‚ÄØRust thread-pool libraries leave significant performance on the table - often running 10√ó slower than <a href="https://en.wikipedia.org/wiki/OpenMP">OpenMP</a> on classic fork-join workloads and <a href="https://github.com/ashvardanian/ParallelReductionsBenchmark">micro-benchmarks</a>.
So I‚Äôve drafted a minimal ~300-line library called <a href="https://github.com/ashvardanian/fork_union">Fork Union</a> that lands within 20% of OpenMP.
It does not use advanced <a href="https://en.wikipedia.org/wiki/Non-uniform_memory_access">NUMA</a> tricks; it uses only the C++ and Rust standard libraries and has no other dependencies.</p><p>Update (Sep 2025): Since the <a href="https://github.com/ashvardanian/fork_union/releases/tag/v2.0.0">v2 release</a>, Fork Union supports NUMA and Huge Pages, as well as <code>tpause</code>, <code>wfet</code>, and other ‚Äúpro‚Äù features.
Check the <a href="https://github.com/ashvardanian/fork_union?tab=readme-ov-file#pro-tips">README for details</a>.</p></blockquote><p><a href="https://github.com/ashvardanian/fork_union"><img alt="Fork Union for Rust and C++" loading="lazy" src="https://liquidbrain.net/beyond-openmp-in-cpp-rust/fork_union.jpg"/></a></p><p><a href="https://en.wikipedia.org/wiki/OpenMP">OpenMP</a> has been the industry workhorse for coarse-grain parallelism in C and C++ for decades.
I lean on it heavily in projects like <a href="https://github.com/unum-cloud/usearch">USearch</a>, yet I avoid it in larger systems because:</p><ul><li><strong>Fine-grain parallelism</strong> with independent subsystems doesn‚Äôt map cleanly to OpenMP‚Äôs global runtime.</li><li><strong>Portability</strong> of the C++ STL and the Rust standard library is better than OpenMP.</li><li><strong>Meta-programming</strong> with OpenMP is a pain - mixing <code>#pragma omp</code> with templates quickly becomes unmaintainable.</li></ul><p>So I went looking for ready-made thread pools in C++¬†and¬†Rust ‚Äî only to realize <strong>most of them implement asynchronous task queues, a much heavier abstraction than OpenMP‚Äôs fork-join model</strong>.
Those extra layers introduce what I call the four horsemen of low performance:</p><ol><li><a href="#locks-and-mutexes">Locks &amp; mutexes</a> with syscalls in the hot path.</li><li><a href="#memory-allocations">Heap allocations</a> in queues, tasks, futures, and promises.</li><li><a href="#atomics-and-cas">Compare-and-swap</a> (CAS) stalls in the pessimistic path.</li><li><a href="#alignment">False sharing</a> unaligned counters thrashing cache lines.</li></ol><p>With today‚Äôs dual-socket AWS machines pushing 192 physical cores, I needed something leaner than <a href="https://github.com/taskflow/taskflow/">Taskflow</a>, <a href="https://github.com/rayon-rs/rayon/">Rayon</a>, or <a href="https://github.com/tokio-rs/tokio/">Tokio</a>.
Enter <a href="https://github.com/ashvardanian/fork_union">Fork Union</a>.</p><h2 id="benchmarks">Benchmarks</h2><p>Hardware: AWS Graviton 4 metal (single NUMA node, 96√ó‚ÄØArm¬†v9 cores,¬†1 thread/core).
Workload: <a href="https://github.com/ashvardanian/ParallelReductionsBenchmark">‚ÄúParallelReductionsBenchmark‚Äù</a> - summing single-precision floats in parallel.
In this case, just one cache line (<code>float[16]</code>) per core‚Äîsmall enough to stress synchronization cost of the thread pool rather than arithmetic throughput of the CPU.
In other words, we are benchmarking kernels similar to:</p><div><div><table><tbody><tr><td><pre tabindex="0"><code><span id="hl-0-1"><a href="#hl-0-1">1</a>
</span><span id="hl-0-2"><a href="#hl-0-2">2</a>
</span><span id="hl-0-3"><a href="#hl-0-3">3</a>
</span><span id="hl-0-4"><a href="#hl-0-4">4</a>
</span><span id="hl-0-5"><a href="#hl-0-5">5</a>
</span><span id="hl-0-6"><a href="#hl-0-6">6</a>
</span><span id="hl-0-7"><a href="#hl-0-7">7</a>
</span><span id="hl-0-8"><a href="#hl-0-8">8</a>
</span><span id="hl-0-9"><a href="#hl-0-9">9</a>
</span></code></pre></td><td><pre tabindex="0"><code data-lang="cpp"><span><span><span>#include</span> <span>&lt;array&gt;</span><span>
</span></span></span><span><span><span></span>
</span></span><span><span><span>float</span> <span>parallel_sum</span><span>(</span><span>std</span><span>::</span><span>array</span><span>&lt;</span><span>float</span><span>,</span> <span>96</span> <span>*</span> <span>16</span><span>&gt;</span> <span>const</span> <span>&amp;</span><span>data</span><span>)</span> <span>{</span>
</span></span><span><span>    <span>float</span> <span>result</span> <span>=</span> <span>0.0f</span><span>;</span>
</span></span><span><span><span>#pragma omp parallel for reduction(+:result) </span><span>// Not how we profile OpenMP
</span></span></span><span><span><span></span>    <span>for</span> <span>(</span><span>std</span><span>::</span><span>size_t</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>data</span><span>.</span><span>size</span><span>();</span> <span>++</span><span>i</span><span>)</span>
</span></span><span><span>        <span>result</span> <span>+=</span> <span>data</span><span>[</span><span>i</span><span>];</span>
</span></span><span><span>    <span>return</span> <span>result</span><span>;</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></td></tr></tbody></table></div></div><p><a href="https://github.com/google/benchmark">Google Benchmark</a> numbers for the C++ version of Fork Union, compared to OpenMP, <a href="https://github.com/taskflow/taskflow/">Taskflow</a>, and allocating 96√ó <code>std::thread</code> objects on-demand, are as follows:</p><div><div><table><tbody><tr><td><pre tabindex="0"><code><span id="hl-1-1"><a href="#hl-1-1">1</a>
</span><span id="hl-1-2"><a href="#hl-1-2">2</a>
</span><span id="hl-1-3"><a href="#hl-1-3">3</a>
</span><span id="hl-1-4"><a href="#hl-1-4">4</a>
</span><span id="hl-1-5"><a href="#hl-1-5">5</a>
</span><span id="hl-1-6"><a href="#hl-1-6">6</a>
</span><span id="hl-1-7"><a href="#hl-1-7">7</a>
</span><span id="hl-1-8"><a href="#hl-1-8">8</a>
</span><span id="hl-1-9"><a href="#hl-1-9">9</a>
</span></code></pre></td><td><pre tabindex="0"><code data-lang="sh"><span><span><span>PARALLEL_REDUCTIONS_LENGTH</span><span>=</span><span>1536</span> build_release/reduce_bench
</span></span><span><span>
</span></span><span><span>-----------------------------------
</span></span><span><span>Benchmark           UserCounters...
</span></span><span><span>-----------------------------------
</span></span><span><span>std::threads        bytes/s<span>=</span>3.00106 MB/s
</span></span><span><span>tf::taskflow        bytes/s<span>=</span>76.2837 MB/s
</span></span><span><span>av::fork_union      bytes/s<span>=</span>467.714 MB/s
</span></span><span><span>openmp              bytes/s<span>=</span>585.492 MB/s
</span></span></code></pre></td></tr></tbody></table></div></div><blockquote><p>I‚Äôve cleaned up the output, focusing only on the relevant rows and the reduction throughput.</p></blockquote><p><a href="https://github.com/bheisler/criterion.rs">Criterion.rs</a> numbers for the Rust version of Fork Union, compared to <a href="https://github.com/rayon-rs/rayon/">Rayon</a>, <a href="https://github.com/tokio-rs/tokio/">Tokio</a>, and Smol‚Äôs <a href="https://github.com/smol-rs/async-executor">Async Executors</a>, are as follows:</p><div><div><table><tbody><tr><td><pre tabindex="0"><code><span id="hl-2-1"><a href="#hl-2-1">1</a>
</span><span id="hl-2-2"><a href="#hl-2-2">2</a>
</span><span id="hl-2-3"><a href="#hl-2-3">3</a>
</span><span id="hl-2-4"><a href="#hl-2-4">4</a>
</span><span id="hl-2-5"><a href="#hl-2-5">5</a>
</span><span id="hl-2-6"><a href="#hl-2-6">6</a>
</span></code></pre></td><td><pre tabindex="0"><code data-lang="sh"><span><span>$ <span>PARALLEL_REDUCTIONS_LENGTH</span><span>=</span><span>1536</span> cargo +nightly bench -- --output-format bencher
</span></span><span><span>
</span></span><span><span><span>test</span> fork_union ... bench:  5,150 ns/iter <span>(</span>+/- 402<span>)</span>
</span></span><span><span><span>test</span> rayon ... bench:      47,251 ns/iter <span>(</span>+/- 3,985<span>)</span>
</span></span><span><span><span>test</span> smol ... bench:       54,931 ns/iter <span>(</span>+/- 10<span>)</span>
</span></span><span><span><span>test</span> tokio ... bench:     240,707 ns/iter <span>(</span>+/- 921<span>)</span>
</span></span></code></pre></td></tr></tbody></table></div></div><p>The timing methods used in those two executables are different, but the relative observations should hold.</p><ul><li>Spawning new threads is obviously too expensive.</li><li>Most reusable thread pools are still 10x slower to sync than OpenMP.</li><li>OpenMP isn‚Äôt easy to compete with and still outperforms Fork Union by 20%.</li></ul><p>This clearly shows, how important it is to chose the right tool for the job.
Don‚Äôt pick an asynchronous task pool for a fork-join blocking workload!</p><h2 id="four-horsemen-of-performance">Four Horsemen of Performance</h2><blockquote><p>This article won‚Äôt be a deep dive into those topics.
Each deserves its own article and a proper benchmark, with some good ones already available and linked.</p></blockquote><h3 id="locks-and-mutexes">Locks and Mutexes</h3><p>Unlike the <a href="https://en.cppreference.com/w/cpp/atomic/atomic"><code>std::atomic</code></a>, the <a href="https://en.cppreference.com/w/cpp/thread/mutex"><code>std::mutex</code></a> update may result in a system call, and it can be expensive to acquire and release.
Its implementations generally have 2 executable paths:</p><ul><li>the fast path, where the mutex is not contended, where it first tries to grab the mutex via a compare-and-swap operation, and if it succeeds, it returns immediately.</li><li>the slow path, where the mutex is contended, and it has to go through the kernel to block the thread until the mutex is available.</li></ul><p>On Linux, the latter translates to a <a href="https://en.wikipedia.org/wiki/Futex">‚Äúfutex‚Äù syscall</a> and an expensive <a href="https://lwn.net/Articles/940944/#:~:text=shared%20between%20at%20least%20two,system%20call">context switch</a>.
In Rust, the same applies to <a href="https://doc.rust-lang.org/std/sync/atomic/"><code>std::async::atomic</code></a> and <a href="https://doc.rust-lang.org/std/sync/struct.Mutex.html"><code>std::sync::Mutex</code></a>.
Prefer the former when possible.</p><h3 id="memory-allocations">Memory Allocations</h3><p>Most thread-pools use classes like <a href="https://en.cppreference.com/w/cpp/thread/future"><code>std::future</code></a>, <a href="https://en.cppreference.com/w/cpp/thread/packaged_task"><code>std::packaged_task</code></a>, <a href="https://en.cppreference.com/w/cpp/utility/functional/function"><code>std::function</code></a>, <a href="https://en.cppreference.com/w/cpp/container/queue"><code>std::queue</code></a>, <a href="https://en.cppreference.com/w/cpp/thread/condition_variable"><code>std::conditional_variable</code></a>.</p><blockquote><p>In Rust land, there will often be a <a href="https://doc.rust-lang.org/std/boxed/struct.Box.html"><code>std::Box</code></a>, <a href="https://doc.rust-lang.org/std/sync/struct.Arc.html"><code>std::Arc</code></a>, <a href="https://doc.rust-lang.org/std/collections/struct.VecDeque.html"><code>std::collections::VecDeque</code></a>, <a href="https://doc.rust-lang.org/std/sync/mpsc/index.html"><code>std::sync::mpsc</code></a> or even <a href="https://doc.rust-lang.org/std/sync/mpmc/index.html"><code>std::sync::mpmc</code></a>.</p></blockquote><p>Most of those, I believe, aren‚Äôt unusable in Big-Data applications, where you always operate in memory-constrained environments:</p><ul><li>Raising a <a href="https://en.cppreference.com/w/cpp/memory/new/bad_alloc"><code>std::bad_alloc</code></a> exception when there is no memory left and just hoping that someone up the call stack will catch it is not a great design idea for Systems Engineering.</li><li>The threat of having to synchronize ~200 physical CPU cores across 2-8 sockets and potentially dozens of NUMA nodes around a shared global memory allocator practically means you can‚Äôt have predictable performance.</li></ul><p>As we focus on a simpler <del>concurrency</del> parallelism model, we can avoid the complexity of allocating shared states, wrapping callbacks into some heap-allocated ‚Äútasks‚Äù, and a lot of other boilerplates.</p><p>Less work = more performance.</p><h3 id="atomics-and-cas">Atomics and CAS</h3><p>Once you get to the lowest-level primitives on concurrency, you end up with the <code>std::atomic</code> and a small set of hardware-supported atomic instructions.
Hardware implements it differently:</p><ul><li>x86 is built around the ‚ÄúTotal Store Order‚Äù (TSO) <a href="https://en.wikipedia.org/wiki/Memory_ordering">memory consistency model</a> and provides <code>LOCK</code> variants of the <code>ADD</code> and <code>CMPXCHG</code>. These variants act as full-blown ‚Äúfences‚Äù ‚Äî no loads or stores can be reordered across them. This makes atomic operations on x86 straightforward but heavyweight.</li><li>Arm, on the other hand, has a ‚Äúweak‚Äù memory model and provides a set of atomic instructions that are not fenced and match the C++ concurrency model. It offers <code>acquire</code>, <code>release</code>, and <code>acq_rel</code> variants of each atomic instruction ‚Äî such as <code>LDADD</code>, <code>STADD</code>, and <code>CAS</code> ‚Äî which allow precise control over visibility and order, especially with the introduction of <a href="https://learn.arm.com/learning-paths/servers-and-cloud-computing/lse/intro/">‚ÄúLarge System Extension‚Äù (LSE)</a> instructions in Armv8.1-A.</li></ul><p>A locked atomic on x86 requires the cache line in the Exclusive state in the requester‚Äôs L1 cache.
This would incur a coherence transaction (Read-for-Ownership) if another core had the line.
Both Intel and AMD handle this similarly.</p><p>It makes <a href="https://arangodb.com/2021/02/cpp-memory-model-migrating-from-x86-to-arm">Arm and Power much more suitable for lock-free programming</a> and concurrent data structures, but some observations hold for both platforms.
Most importantly, ‚ÄúCompare and Swap‚Äù (CAS) is costly and should be avoided at all costs.</p><p>On x86, for example, the <code>LOCK ADD</code> <a href="https://travisdowns.github.io/blog/2020/07/06/concurrency-costs">can easily take 50 CPU cycles</a>.
It is 50x slower than a regular <code>ADD</code> instruction but still easily 5-10x faster than a <code>LOCK CMPXCHG</code> instruction.
Once the contention rises, the gap naturally widens, further amplified by the increased ‚Äúfailure‚Äù rate of the CAS operation when the value being compared has already changed.
That‚Äôs why, for the ‚Äúdynamic‚Äù mode, we resort to using an additional atomic variable rather than more typical CAS-based implementations.</p><h3 id="alignment">Alignment</h3><p>Assuming a thread pool is a heavy object anyway, nobody will care if it‚Äôs a bit larger than expected.
That allows us to over-align the internal counters to <a href="https://en.cppreference.com/w/cpp/thread/hardware_destructive_interference_size"><code>std::hardware_destructive_interference_size</code></a> or <a href="https://en.cppreference.com/w/cpp/types/max_align_t"><code>std::max_align_t</code></a> to avoid false sharing.
In that case, even on x86, where the entire cache will be exclusively owned by a single thread, in eager mode, we end up effectively ‚Äúpipelining‚Äù the execution, where one thread may be incrementing the ‚Äúin-flight‚Äù counter while the other is decrementing the ‚Äúremaining‚Äù counter.
Others are executing the loop body in between.</p><h2 id="comparing-apis">Comparing APIs</h2><h3 id="fork-union">Fork Union</h3><p>Fork Union has a straightforward goal, so its API is equally clear.
There are only 4 core interfaces:</p><ul><li><code>for_each_thread</code> - to dispatch a callback per thread, similar to <code>#pragma omp parallel</code>.</li><li><code>for_each_static</code> - for individual evenly-sized tasks, similar to <code>#pragma omp for schedule(static)</code>.</li><li><code>for_each_slice</code> - for slices of evenly-sized tasks, similar to nested <code>#pragma omp for schedule(static)</code>.</li><li><code>for_each_dynamic</code> - for individual unevenly-sized tasks, similar to <code>#pragma omp for schedule(dynamic, 1)</code>.</li></ul><p>They all receive a C++ lambda or a Rust closure and a range of tasks to execute.
The construction of the thread pool itself is a bit trickier than typically in standard libraries, as ‚Äúexceptions‚Äù and ‚Äúpanics‚Äù are not allowed.
So, the constructor can‚Äôt perform any real work.
In C++, the <code>try_spawn</code> method can be called to allocate all the threads:</p><div><div><table><tbody><tr><td><pre tabindex="0"><code><span id="hl-3-1"><a href="#hl-3-1"> 1</a>
</span><span id="hl-3-2"><a href="#hl-3-2"> 2</a>
</span><span id="hl-3-3"><a href="#hl-3-3"> 3</a>
</span><span id="hl-3-4"><a href="#hl-3-4"> 4</a>
</span><span id="hl-3-5"><a href="#hl-3-5"> 5</a>
</span><span id="hl-3-6"><a href="#hl-3-6"> 6</a>
</span><span id="hl-3-7"><a href="#hl-3-7"> 7</a>
</span><span id="hl-3-8"><a href="#hl-3-8"> 8</a>
</span><span id="hl-3-9"><a href="#hl-3-9"> 9</a>
</span><span id="hl-3-10"><a href="#hl-3-10">10</a>
</span><span id="hl-3-11"><a href="#hl-3-11">11</a>
</span><span id="hl-3-12"><a href="#hl-3-12">12</a>
</span><span id="hl-3-13"><a href="#hl-3-13">13</a>
</span><span id="hl-3-14"><a href="#hl-3-14">14</a>
</span><span id="hl-3-15"><a href="#hl-3-15">15</a>
</span><span id="hl-3-16"><a href="#hl-3-16">16</a>
</span><span id="hl-3-17"><a href="#hl-3-17">17</a>
</span><span id="hl-3-18"><a href="#hl-3-18">18</a>
</span></code></pre></td><td><pre tabindex="0"><code data-lang="cpp"><span><span><span>#include</span> <span>&lt;fork_union.hpp&gt;</span><span>   </span><span>// `fork_union_t`
</span></span></span><span><span><span></span><span>#include</span> <span>&lt;cstdio&gt;</span><span>           </span><span>// `stderr`
</span></span></span><span><span><span></span><span>#include</span> <span>&lt;cstdlib&gt;</span><span>          </span><span>// `EXIT_SUCCESS`
</span></span></span><span><span><span></span>
</span></span><span><span><span>namespace</span> <span>fun</span> <span>=</span> <span>ashvardanian</span><span>::</span><span>fork_union</span><span>;</span>
</span></span><span><span>
</span></span><span><span><span>int</span> <span>main</span><span>()</span> <span>{</span>
</span></span><span><span>    <span>fun</span><span>::</span><span>fork_union_t</span> <span>pool</span><span>;</span>
</span></span><span><span>    <span>if</span> <span>(</span><span>!</span><span>pool</span><span>.</span><span>try_spawn</span><span>(</span><span>std</span><span>::</span><span>thread</span><span>::</span><span>hardware_concurrency</span><span>()))</span> <span>{</span>
</span></span><span><span>        <span>std</span><span>::</span><span>fprintf</span><span>(</span><span>stderr</span><span>,</span> <span>&#34;Failed to fork the threads</span><span>\n</span><span>&#34;</span><span>);</span>
</span></span><span><span>        <span>return</span> <span>EXIT_FAILURE</span><span>;</span>
</span></span><span><span>    <span>}</span>
</span></span><span><span>
</span></span><span><span>    <span>pool</span><span>.</span><span>for_each_thread</span><span>([</span><span>&amp;</span><span>](</span><span>std</span><span>::</span><span>size_t</span> <span>thread_index</span><span>)</span> <span>noexcept</span> <span>{</span>
</span></span><span><span>        <span>std</span><span>::</span><span>printf</span><span>(</span><span>&#34;Hello from thread # %zu (of %zu)</span><span>\n</span><span>&#34;</span><span>,</span> <span>thread_index</span> <span>+</span> <span>1</span><span>,</span> <span>pool</span><span>.</span><span>count_threads</span><span>());</span>
</span></span><span><span>    <span>});</span>
</span></span><span><span>    <span>return</span> <span>EXIT_SUCCESS</span><span>;</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></td></tr></tbody></table></div></div><blockquote><p>As you may have noticed, the lambdas are forced to be <code>noexcept</code> and can‚Äôt return anything.
This is a design choice that vastly simplifies the implementation.</p></blockquote><p>In Rust, similarly, the <code>try_spawn</code> method can be used:</p><div><div><table><tbody><tr><td><pre tabindex="0"><code><span id="hl-4-1"><a href="#hl-4-1"> 1</a>
</span><span id="hl-4-2"><a href="#hl-4-2"> 2</a>
</span><span id="hl-4-3"><a href="#hl-4-3"> 3</a>
</span><span id="hl-4-4"><a href="#hl-4-4"> 4</a>
</span><span id="hl-4-5"><a href="#hl-4-5"> 5</a>
</span><span id="hl-4-6"><a href="#hl-4-6"> 6</a>
</span><span id="hl-4-7"><a href="#hl-4-7"> 7</a>
</span><span id="hl-4-8"><a href="#hl-4-8"> 8</a>
</span><span id="hl-4-9"><a href="#hl-4-9"> 9</a>
</span><span id="hl-4-10"><a href="#hl-4-10">10</a>
</span><span id="hl-4-11"><a href="#hl-4-11">11</a>
</span></code></pre></td><td><pre tabindex="0"><code data-lang="rust"><span><span><span>#![feature(allocator_api)]</span><span>
</span></span></span><span><span><span></span><span>use</span><span> </span><span>std</span>::<span>error</span>::<span>Error</span><span>;</span><span>
</span></span></span><span><span><span></span><span>use</span><span> </span><span>fork_union</span>::<span>ForkUnion</span><span>;</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>fn</span> <span>main</span><span>()</span><span> </span>-&gt; <span>Result</span><span>&lt;</span><span>(),</span><span> </span><span>Box</span><span>&lt;</span><span>dyn</span><span> </span><span>Error</span><span>&gt;&gt;</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>pool</span><span> </span><span>=</span><span> </span><span>ForkUnion</span>::<span>try_spawn</span><span>(</span><span>4</span><span>)</span><span>?</span><span>;</span><span>
</span></span></span><span><span><span>    </span><span>pool</span><span>.</span><span>for_each_thread</span><span>(</span><span>|</span><span>thread_index</span><span>|</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>        </span><span>println!</span><span>(</span><span>&#34;Hello from thread # </span><span>{}</span><span> (of </span><span>{}</span><span>)&#34;</span><span>,</span><span> </span><span>thread_index</span><span> </span><span>+</span><span> </span><span>1</span><span>,</span><span> </span><span>pool</span><span>.</span><span>count_threads</span><span>());</span><span>
</span></span></span><span><span><span>    </span><span>});</span><span>
</span></span></span><span><span><span>    </span><span>Ok</span><span>(())</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span></code></pre></td></tr></tbody></table></div></div><p>Assuming Rust has no function overloading, there are a few alternatives:</p><ul><li><code>try_spawn</code> - to spawn a thread pool with the main allocator.</li><li><code>try_spawn_in</code> - to spawn a thread pool with a custom allocator.</li><li><code>try_named_spawn</code> - to spawn a thread pool with the main allocator and a name.</li><li><code>try_named_spawn_in</code> - to spawn a thread pool with a custom allocator and a name.</li></ul><h3 id="rayon">Rayon</h3><p>Rayon is the go-to Rust library for data parallelism.
It suffers from the same core design issues as every other thread pool I‚Äôve looked at on GitHub, but it‚Äôs fair to say that at the high level, it provides outstanding coverage for various parallel iterators!
As such, there is <a href="https://github.com/ashvardanian/fork_union/issues/2">an open call to explore similar ‚ÄúMap-Reduce‚Äù and ‚ÄúMap-Fork-Reduce‚Äù patterns in Fork Union</a> to see if they can be implemented efficiently.</p><div><div><table><tbody><tr><td><pre tabindex="0"><code><span id="hl-5-1"><a href="#hl-5-1">1</a>
</span><span id="hl-5-2"><a href="#hl-5-2">2</a>
</span><span id="hl-5-3"><a href="#hl-5-3">3</a>
</span><span id="hl-5-4"><a href="#hl-5-4">4</a>
</span><span id="hl-5-5"><a href="#hl-5-5">5</a>
</span><span id="hl-5-6"><a href="#hl-5-6">6</a>
</span><span id="hl-5-7"><a href="#hl-5-7">7</a>
</span></code></pre></td><td><pre tabindex="0"><code data-lang="rust"><span><span><span>use</span><span> </span><span>rayon</span>::<span>prelude</span>::<span>*</span><span>;</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span></span><span>fn</span> <span>sum_of_squares</span><span>(</span><span>input</span>: <span>&amp;</span><span>[</span><span>i32</span><span>])</span><span> </span>-&gt; <span>i32</span> <span>{</span><span>
</span></span></span><span><span><span>    </span><span>input</span><span>.</span><span>par_iter</span><span>()</span><span> </span><span>// &lt;-- just change that!
</span></span></span><span><span><span></span><span>         </span><span>.</span><span>map</span><span>(</span><span>|&amp;</span><span>i</span><span>|</span><span> </span><span>i</span><span> </span><span>*</span><span> </span><span>i</span><span>)</span><span>
</span></span></span><span><span><span>         </span><span>.</span><span>sum</span><span>()</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span></code></pre></td></tr></tbody></table></div></div><p>The default <code>.par_iter()</code> API of Rayon, <a href="https://github.com/rayon-rs/rayon/blob/ae07384e3e0b238cea89f0c14891f351c65a5cee/README.md?plain=1#L26-L33">at the start of the README.md</a>, is not how I‚Äôve used it in ‚ÄúParallel Reductions Benchmark‚Äù.
To ensure that we are benchmarking the actual synchronization cost of the thread pool, I‚Äôve gone directly to the underlying <code>rayon::ThreadPool</code> API:</p><div><div><table><tbody><tr><td><pre tabindex="0"><code><span id="hl-6-1"><a href="#hl-6-1"> 1</a>
</span><span id="hl-6-2"><a href="#hl-6-2"> 2</a>
</span><span id="hl-6-3"><a href="#hl-6-3"> 3</a>
</span><span id="hl-6-4"><a href="#hl-6-4"> 4</a>
</span><span id="hl-6-5"><a href="#hl-6-5"> 5</a>
</span><span id="hl-6-6"><a href="#hl-6-6"> 6</a>
</span><span id="hl-6-7"><a href="#hl-6-7"> 7</a>
</span><span id="hl-6-8"><a href="#hl-6-8"> 8</a>
</span><span id="hl-6-9"><a href="#hl-6-9"> 9</a>
</span><span id="hl-6-10"><a href="#hl-6-10">10</a>
</span><span id="hl-6-11"><a href="#hl-6-11">11</a>
</span><span id="hl-6-12"><a href="#hl-6-12">12</a>
</span><span id="hl-6-13"><a href="#hl-6-13">13</a>
</span><span id="hl-6-14"><a href="#hl-6-14">14</a>
</span><span id="hl-6-15"><a href="#hl-6-15">15</a>
</span><span id="hl-6-16"><a href="#hl-6-16">16</a>
</span><span id="hl-6-17"><a href="#hl-6-17">17</a>
</span><span id="hl-6-18"><a href="#hl-6-18">18</a>
</span><span id="hl-6-19"><a href="#hl-6-19">19</a>
</span><span id="hl-6-20"><a href="#hl-6-20">20</a>
</span><span id="hl-6-21"><a href="#hl-6-21">21</a>
</span><span id="hl-6-22"><a href="#hl-6-22">22</a>
</span><span id="hl-6-23"><a href="#hl-6-23">23</a>
</span></code></pre></td><td><pre tabindex="0"><code data-lang="rust"><span><span><span>pub</span><span> </span><span>fn</span> <span>sum_rayon</span><span>(</span><span>pool</span>: <span>&amp;</span><span>rayon</span>::<span>ThreadPool</span><span>,</span><span> </span><span>data</span>: <span>&amp;</span><span>[</span><span>f32</span><span>],</span><span> </span><span>partial_sums</span>: <span>&amp;</span><span>mut</span><span> </span><span>[</span><span>f64</span><span>])</span><span> </span>-&gt; <span>f64</span> <span>{</span><span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>cores</span><span> </span><span>=</span><span> </span><span>pool</span><span>.</span><span>current_num_threads</span><span>();</span><span>
</span></span></span><span><span><span>    </span><span>let</span><span> </span><span>chunk_size</span><span> </span><span>=</span><span> </span><span>scalars_per_core</span><span>(</span><span>data</span><span>.</span><span>len</span><span>(),</span><span> </span><span>cores</span><span>);</span><span>       </span><span>// Defined elsewhere
</span></span></span><span><span><span></span><span>    </span><span>let</span><span> </span><span>partial_sums_ptr</span><span> </span><span>=</span><span> </span><span>partial_sums</span><span>.</span><span>as_mut_ptr</span><span>()</span><span> </span><span>as</span><span> </span><span>usize</span><span>;</span><span>  </span><span>// Pointers aren&#39;t safe to pass around
</span></span></span><span><span><span></span><span>
</span></span></span><span><span><span>    </span><span>pool</span><span>.</span><span>broadcast</span><span>(</span><span>|</span><span>context</span>: <span>rayon</span>::<span>BroadcastContext</span><span>&lt;</span><span>&#39;_</span><span>&gt;|</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>        </span><span>let</span><span> </span><span>thread_index</span><span> </span><span>=</span><span> </span><span>context</span><span>.</span><span>index</span><span>();</span><span>
</span></span></span><span><span><span>        </span><span>let</span><span> </span><span>start</span><span> </span><span>=</span><span> </span><span>thread_index</span><span> </span><span>*</span><span> </span><span>chunk_size</span><span>;</span><span>
</span></span></span><span><span><span>        </span><span>if</span><span> </span><span>start</span><span> </span><span>&gt;=</span><span> </span><span>data</span><span>.</span><span>len</span><span>()</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>            </span><span>return</span><span>;</span><span>
</span></span></span><span><span><span>        </span><span>}</span><span>
</span></span></span><span><span><span>        </span><span>let</span><span> </span><span>stop</span><span> </span><span>=</span><span> </span><span>std</span>::<span>cmp</span>::<span>min</span><span>(</span><span>start</span><span> </span><span>+</span><span> </span><span>chunk_size</span><span>,</span><span> </span><span>data</span><span>.</span><span>len</span><span>());</span><span>
</span></span></span><span><span><span>        </span><span>let</span><span> </span><span>partial_sum</span><span> </span><span>=</span><span> </span><span>sum_unrolled</span><span>(</span><span>&amp;</span><span>data</span><span>[</span><span>start</span><span>..</span><span>stop</span><span>]);</span><span>
</span></span></span><span><span><span>        </span><span>unsafe</span><span> </span><span>{</span><span>
</span></span></span><span><span><span>            </span><span>ptr</span>::<span>write</span><span>(</span><span> </span><span>// Cast back to a pointer:
</span></span></span><span><span><span></span><span>                </span><span>(</span><span>partial_sums_ptr</span><span> </span><span>as</span><span> </span><span>*</span><span>mut</span><span> </span><span>f64</span><span>).</span><span>add</span><span>(</span><span>thread_index</span><span>),</span><span>
</span></span></span><span><span><span>                </span><span>partial_sum</span><span>,</span><span>
</span></span></span><span><span><span>            </span><span>);</span><span>
</span></span></span><span><span><span>        </span><span>}</span><span>
</span></span></span><span><span><span>    </span><span>});</span><span>
</span></span></span><span><span><span>
</span></span></span><span><span><span>    </span><span>partial_sums</span><span>.</span><span>iter</span><span>().</span><span>copied</span><span>().</span><span>sum</span><span>()</span><span>
</span></span></span><span><span><span></span><span>}</span><span>
</span></span></span></code></pre></td></tr></tbody></table></div></div><h3 id="taskflow">Taskflow</h3><p>Taskflow is one of the most popular C++ libraries for parallelism.
It has many features, including async execution graphs on CPUs and GPUs.
<a href="https://github.com/taskflow/taskflow/blob/b3c1e5fd8e2d67eaead944a8d869f87e6b58bbbe/README.md?plain=1#L84-L106">The most common example</a> looks like this:</p><div><div><table><tbody><tr><td><pre tabindex="0"><code><span id="hl-7-1"><a href="#hl-7-1"> 1</a>
</span><span id="hl-7-2"><a href="#hl-7-2"> 2</a>
</span><span id="hl-7-3"><a href="#hl-7-3"> 3</a>
</span><span id="hl-7-4"><a href="#hl-7-4"> 4</a>
</span><span id="hl-7-5"><a href="#hl-7-5"> 5</a>
</span><span id="hl-7-6"><a href="#hl-7-6"> 6</a>
</span><span id="hl-7-7"><a href="#hl-7-7"> 7</a>
</span><span id="hl-7-8"><a href="#hl-7-8"> 8</a>
</span><span id="hl-7-9"><a href="#hl-7-9"> 9</a>
</span><span id="hl-7-10"><a href="#hl-7-10">10</a>
</span><span id="hl-7-11"><a href="#hl-7-11">11</a>
</span><span id="hl-7-12"><a href="#hl-7-12">12</a>
</span><span id="hl-7-13"><a href="#hl-7-13">13</a>
</span><span id="hl-7-14"><a href="#hl-7-14">14</a>
</span><span id="hl-7-15"><a href="#hl-7-15">15</a>
</span></code></pre></td><td><pre tabindex="0"><code data-lang="cpp"><span><span><span>#include</span> <span>&lt;taskflow/taskflow.hpp&gt;</span><span>
</span></span></span><span><span><span></span><span>int</span> <span>main</span><span>()</span> <span>{</span>
</span></span><span><span>    <span>tf</span><span>::</span><span>Executor</span> <span>executor</span><span>;</span>
</span></span><span><span>    <span>tf</span><span>::</span><span>Taskflow</span> <span>taskflow</span><span>;</span>
</span></span><span><span>    <span>auto</span> <span>[</span><span>A</span><span>,</span> <span>B</span><span>,</span> <span>C</span><span>,</span> <span>D</span><span>]</span> <span>=</span> <span>taskflow</span><span>.</span><span>emplace</span><span>(</span> <span>// create four tasks
</span></span></span><span><span><span></span>        <span>[]</span> <span>()</span> <span>{</span> <span>std</span><span>::</span><span>cout</span> <span>&lt;&lt;</span> <span>&#34;TaskA</span><span>\n</span><span>&#34;</span><span>;</span> <span>},</span>
</span></span><span><span>        <span>[]</span> <span>()</span> <span>{</span> <span>std</span><span>::</span><span>cout</span> <span>&lt;&lt;</span> <span>&#34;TaskB</span><span>\n</span><span>&#34;</span><span>;</span> <span>},</span>
</span></span><span><span>        <span>[]</span> <span>()</span> <span>{</span> <span>std</span><span>::</span><span>cout</span> <span>&lt;&lt;</span> <span>&#34;TaskC</span><span>\n</span><span>&#34;</span><span>;</span> <span>},</span>
</span></span><span><span>        <span>[]</span> <span>()</span> <span>{</span> <span>std</span><span>::</span><span>cout</span> <span>&lt;&lt;</span> <span>&#34;TaskD</span><span>\n</span><span>&#34;</span><span>;</span> <span>}</span> 
</span></span><span><span>    <span>);</span>                                  
</span></span><span><span>    <span>A</span><span>.</span><span>precede</span><span>(</span><span>B</span><span>,</span> <span>C</span><span>);</span> <span>// A runs before B and C
</span></span></span><span><span><span></span>    <span>D</span><span>.</span><span>succeed</span><span>(</span><span>B</span><span>,</span> <span>C</span><span>);</span> <span>// D runs after  B and C
</span></span></span><span><span><span></span>    <span>executor</span><span>.</span><span>run</span><span>(</span><span>taskflow</span><span>).</span><span>wait</span><span>();</span> 
</span></span><span><span>    <span>return</span> <span>0</span><span>;</span>
</span></span><span><span><span>}</span>
</span></span></code></pre></td></tr></tbody></table></div></div><p>Despite being just an example, it clearly shows how different Taskflow‚Äôs core objectives are from OpenMP and Fork Union.
It is still probably mainly used for simple static parallelism, similar to our case without complex dependencies and the <code>taskflow</code> can be reused.
Here is how ‚ÄúParallel Reductions Benchmark‚Äù wraps Taskflow:</p><div><div><table><tbody><tr><td><pre tabindex="0"><code><span id="hl-8-1"><a href="#hl-8-1"> 1</a>
</span><span id="hl-8-2"><a href="#hl-8-2"> 2</a>
</span><span id="hl-8-3"><a href="#hl-8-3"> 3</a>
</span><span id="hl-8-4"><a href="#hl-8-4"> 4</a>
</span><span id="hl-8-5"><a href="#hl-8-5"> 5</a>
</span><span id="hl-8-6"><a href="#hl-8-6"> 6</a>
</span><span id="hl-8-7"><a href="#hl-8-7"> 7</a>
</span><span id="hl-8-8"><a href="#hl-8-8"> 8</a>
</span><span id="hl-8-9"><a href="#hl-8-9"> 9</a>
</span><span id="hl-8-10"><a href="#hl-8-10">10</a>
</span><span id="hl-8-11"><a href="#hl-8-11">11</a>
</span><span id="hl-8-12"><a href="#hl-8-12">12</a>
</span><span id="hl-8-13"><a href="#hl-8-13">13</a>
</span><span id="hl-8-14"><a href="#hl-8-14">14</a>
</span><span id="hl-8-15"><a href="#hl-8-15">15</a>
</span><span id="hl-8-16"><a href="#hl-8-16">16</a>
</span><span id="hl-8-17"><a href="#hl-8-17">17</a>
</span><span id="hl-8-18"><a href="#hl-8-18">18</a>
</span><span id="hl-8-19"><a href="#hl-8-19">19</a>
</span><span id="hl-8-20"><a href="#hl-8-20">20</a>
</span><span id="hl-8-21"><a href="#hl-8-21">21</a>
</span><span id="hl-8-22"><a href="#hl-8-22">22</a>
</span><span id="hl-8-23"><a href="#hl-8-23">23</a>
</span><span id="hl-8-24"><a href="#hl-8-24">24</a>
</span><span id="hl-8-25"><a href="#hl-8-25">25</a>
</span><span id="hl-8-26"><a href="#hl-8-26">26</a>
</span><span id="hl-8-27"><a href="#hl-8-27">27</a>
</span><span id="hl-8-28"><a href="#hl-8-28">28</a>
</span><span id="hl-8-29"><a href="#hl-8-29">29</a>
</span><span id="hl-8-30"><a href="#hl-8-30">30</a>
</span><span id="hl-8-31"><a href="#hl-8-31">31</a>
</span><span id="hl-8-32"><a href="#hl-8-32">32</a>
</span><span id="hl-8-33"><a href="#hl-8-33">33</a>
</span><span id="hl-8-34"><a href="#hl-8-34">34</a>
</span><span id="hl-8-35"><a href="#hl-8-35">35</a>
</span><span id="hl-8-36"><a href="#hl-8-36">36</a>
</span></code></pre></td><td><pre tabindex="0"><code data-lang="cpp"><span><span><span>template</span> <span>&lt;</span><span>typename</span> <span>serial_at</span> <span>=</span> <span>stl_accumulate_gt</span><span>&lt;</span><span>float</span><span>&gt;&gt;</span>
</span></span><span><span><span>class</span> <span>taskflow_gt</span> <span>{</span>
</span></span><span><span>    <span>float</span> <span>const</span> <span>*</span><span>const</span> <span>begin_</span> <span>=</span> <span>nullptr</span><span>;</span>
</span></span><span><span>    <span>float</span> <span>const</span> <span>*</span><span>const</span> <span>end_</span> <span>=</span> <span>nullptr</span><span>;</span>
</span></span><span><span>    <span>std</span><span>::</span><span>size_t</span> <span>const</span> <span>cores_</span> <span>=</span> <span>0</span><span>;</span>
</span></span><span><span>
</span></span><span><span>    <span>tf</span><span>::</span><span>Executor</span> <span>executor_</span><span>;</span>
</span></span><span><span>    <span>tf</span><span>::</span><span>Taskflow</span> <span>taskflow_</span><span>;</span>
</span></span><span><span>
</span></span><span><span>    <span>struct</span> <span>alignas</span><span>(</span><span>128</span><span>)</span> <span>thread_result_t</span> <span>{</span>
</span></span><span><span>        <span>double</span> <span>partial_sum</span> <span>=</span> <span>0.0</span><span>;</span>
</span></span><span><span>    <span>};</span>
</span></span><span><span>    <span>std</span><span>::</span><span>vector</span><span>&lt;</span><span>thread_result_t</span><span>&gt;</span> <span>sums_</span><span>;</span>
</span></span><span><span>
</span></span><span><span>  <span>public</span><span>:</span>
</span></span><span><span>    <span>taskflow_gt</span><span>()</span> <span>=</span> <span>default</span><span>;</span>
</span></span><span><span>    <span>taskflow_gt</span><span>(</span><span>float</span> <span>const</span> <span>*</span><span>b</span><span>,</span> <span>float</span> <span>const</span> <span>*</span><span>e</span><span>)</span>
</span></span><span><span>        <span>:</span> <span>begin_</span> <span>{</span><span>b</span><span>},</span> <span>end_</span> <span>{</span><span>e</span><span>},</span> <span>cores_</span> <span>{</span><span>total_cores</span><span>()},</span> <span>executor_</span> <span>{</span><span>static_cast</span><span>&lt;</span><span>unsigned</span><span>&gt;</span><span>(</span><span>cores_</span><span>)},</span> <span>sums_</span> <span>{</span><span>cores_</span><span>}</span> <span>{</span>
</span></span><span><span>
</span></span><span><span>        <span>auto</span> <span>const</span> <span>input_size</span> <span>=</span> <span>static_cast</span><span>&lt;</span><span>std</span><span>::</span><span>size_t</span><span>&gt;</span><span>(</span><span>end_</span> <span>-</span> <span>begin_</span><span>);</span>
</span></span><span><span>        <span>auto</span> <span>const</span> <span>chunk_size</span> <span>=</span> <span>scalars_per_core</span><span>(</span><span>input_size</span><span>,</span> <span>cores_</span><span>);</span>
</span></span><span><span>        <span>for</span> <span>(</span><span>std</span><span>::</span><span>size_t</span> <span>thread_index</span> <span>=</span> <span>0</span><span>;</span> <span>thread_index</span> <span>&lt;</span> <span>cores_</span><span>;</span> <span>++</span><span>thread_index</span><span>)</span> <span>{</span>
</span></span><span><span>            <span>taskflow_</span><span>.</span><span>emplace</span><span>([</span><span>this</span><span>,</span> <span>input_size</span><span>,</span> <span>chunk_size</span><span>,</span> <span>thread_index</span><span>]</span> <span>{</span>
</span></span><span><span>                <span>std</span><span>::</span><span>size_t</span> <span>const</span> <span>start</span> <span>=</span> <span>std</span><span>::</span><span>min</span><span>(</span><span>thread_index</span> <span>*</span> <span>chunk_size</span><span>,</span> <span>input_size</span><span>);</span>
</span></span><span><span>                <span>std</span><span>::</span><span>size_t</span> <span>const</span> <span>stop</span> <span>=</span> <span>std</span><span>::</span><span>min</span><span>(</span><span>start</span> <span>+</span> <span>chunk_size</span><span>,</span> <span>input_size</span><span>);</span>
</span></span><span><span>                <span>sums_</span><span>[</span><span>thread_index</span><span>].</span><span>partial_sum</span> <span>=</span> <span>serial_at</span> <span>{</span><span>begin_</span> <span>+</span> <span>start</span><span>,</span> <span>begin_</span> <span>+</span> <span>stop</span><span>}();</span>
</span></span><span><span>            <span>});</span>
</span></span><span><span>        <span>}</span>
</span></span><span><span>    <span>}</span>
</span></span><span><span>
</span></span><span><span>    <span>double</span> <span>operator</span><span>()()</span> <span>{</span>
</span></span><span><span>        <span>executor_</span><span>.</span><span>run</span><span>(</span><span>taskflow_</span><span>).</span><span>wait</span><span>();</span>
</span></span><span><span>        <span>return</span> <span>std</span><span>::</span><span>accumulate</span><span>(</span><span>sums_</span><span>.</span><span>begin</span><span>(),</span> <span>sums_</span><span>.</span><span>end</span><span>(),</span> <span>0.0</span><span>,</span>
</span></span><span><span>                               <span>[](</span><span>double</span> <span>acc</span><span>,</span> <span>thread_result_t</span> <span>const</span> <span>&amp;</span><span>x</span><span>)</span> <span>noexcept</span> <span>{</span> <span>return</span> <span>acc</span> <span>+</span> <span>x</span><span>.</span><span>partial_sum</span><span>;</span> <span>});</span>
</span></span><span><span>    <span>}</span>
</span></span><span><span><span>};</span>
</span></span></code></pre></td></tr></tbody></table></div></div><p>Only the <code>operator()</code> method is timed, leaving the construction costs out of the equation.</p><h2 id="conclusions--observations">Conclusions &amp; Observations</h2><p>Fork Union shows that a lean, 300-line fork-join pool can sit within ~20% of OpenMP, while more functional pools trail by an order of magnitude.
That margin will shift as more workloads, CPUs, and compilers are tested, so treat today‚Äôs numbers as directional, not gospel.
There may still be subtle memory-ordering bugs lurking in Fork Union, but the core observations should hold: <strong>dodge mutexes, dynamic queues, likely-pessimistic CAS paths, and false sharing ‚Äî regardless of language or framework</strong>.</p><p>Rust is still new territory for me.
The biggest surprise is the <a href="https://github.com/rust-lang/rust/issues/32838">missing allocator support in <code>std::collections</code></a> on the stable toolchain.
Nightly‚Äôs <code>Vec::try_reserve_in</code> helps, but until stable lands, ergonomic custom allocation remains tricky.
The machinery exists in C++, yet most projects ignore it ‚Äî so the culture needs to catch up.</p><hr/><p>PS: Spot dubious memory-ordering?
<a href="https://github.com/ashvardanian/fork_union/issues">Open an issue</a>.
Want to close the remaining 20% gap?
Happy forking ü§ó</p><blockquote><p lang="en" dir="ltr">Fork Union, arguably the most unusual parallel-processing library on GitHub, just crossed its first 100 stars ‚Äî my 12th project to reach that milestone ü•≥</p>‚Äî Ash Vardanian (@ashvardanian) <a href="https://twitter.com/ashvardanian/status/1964634808635539904?ref_src=twsrc%5Etfw">September 7, 2025</a></blockquote></div></div>
  </body>
</html>
