<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://zed.dev/blog/zed-decoded-async-rust">Original</a>
    <h1>Zed Decoded: Async Rust</h1>
    
    <div id="readability-page-1" class="page"><div><article><header></header><p>Welcome to the first article in a new series called <strong>Zed Decoded</strong>. In Zed Decoded I&#39;m going to take a close look at Zed — how it&#39;s built, which data structures it uses, which technologies and techniques, what features it has, which bugs we ran into. The best part? I won&#39;t do this alone, but get to interview and ask my colleagues here at Zed about everything I want to know.</p>
<div><div><div><p><b>Companion Video</b>: <!-- -->Async Rust</p><p>This post comes with a 1hr companion video, in which Thorsten and Antonio explore how Zed uses async Rust — in Zed. It&#39;s a loose conversation that focuses on the code and dives a bit deeper into some topics that didn&#39;t fit into the post.</p><p>Watch the video here:<!-- --> <a href="https://youtu.be/gkU4NGSe21I">https://youtu.be/gkU4NGSe21I</a></p></div><p><img src="https://zed.dev/img/post/zed-decoded-async-rust/thumbnail.jpg" width="230" height="150"/></p></div></div>
<p>The first topic that was on my list: async Rust and how it&#39;s used in Zed. Over the past few months I&#39;ve become quite fascinated with async Rust — Zed&#39;s the first codebase I&#39;ve worked in that uses it — so I decided to sit down and ask Antonio, one of Zed&#39;s co-founders, about how we use async Rust in Zed.</p>
<p>We won&#39;t get into the details of async Rust itself (familiarity with that is to be expected if you want to understand the nitty-gritty of the code we&#39;ll see), but instead focus on how Zed uses async Rust to build a high-performance, native application: what async code looks like on the application level, which runtime it uses, why it uses that runtime.</p>
<h2 id="writing-async-rust-with-gpui"><span data-br=":R4nbrrrqbf9la:" data-brr="1">Writing async Rust with GPUI</span></h2>
<p>Let&#39;s jump right into the deep end. Here is a snippet of code that&#39;s representative of async code in the Zed codebase:</p>
<figure data-rehype-pretty-code-figure=""><div><pre tabindex="0" data-language="rust" data-theme="light-plus"><code data-language="rust" data-theme="light-plus"><span data-line=""><span>fn</span><span> show_cursor_names</span><span>(&amp;</span><span>mut</span><span> self</span><span>, </span><span>cx</span><span>: &amp;</span><span>mut</span><span> ViewContext</span><span>&lt;</span><span>Self</span><span>&gt;) {</span></span>
<span data-line=""><span>    self</span><span>.show_cursor_names = </span><span>true</span><span>;</span></span>
<span data-line=""><span>    cx</span><span>.</span><span>notify</span><span>();</span></span>
<span data-line=""><span>    cx</span><span>.</span><span>spawn</span><span>(|</span><span>this</span><span>, </span><span>mut</span><span> cx</span><span>| </span><span>async</span><span> move</span><span> {</span></span>
<span data-line=""><span>        cx</span><span>.</span><span>background_executor</span><span>().</span><span>timer</span><span>(CURSORS_VISIBLE_FOR).</span><span>await</span><span>;</span></span>
<span data-line=""><span>        this</span><span>.</span><span>update</span><span>(&amp;</span><span>mut</span><span> cx</span><span>, |</span><span>this</span><span>, </span><span>cx</span><span>| {</span></span>
<span data-line=""><span>            this</span><span>.show_cursor_names = </span><span>false</span><span>;</span></span>
<span data-line=""><span>            cx</span><span>.</span><span>notify</span><span>()</span></span>
<span data-line=""><span>        })</span></span>
<span data-line=""><span>        .</span><span>ok</span><span>()</span></span>
<span data-line=""><span>    })</span></span>
<span data-line=""><span>    .</span><span>detach</span><span>();</span></span>
<span data-line=""><span>}</span></span></code></pre></div></figure>
<p>It&#39;s <a href="https://github.com/zed-industries/zed/blob/98ddefc8884d0957ab766b3aea09265c8423684e/crates/editor/src/editor.rs#L3935-L3947">a function from our <code>Editor</code></a>. When it&#39;s called, Zed shows the names of the owners of each cursor: your name or the names of the people you&#39;re collaborating with. It&#39;s called, for example, when the editor is re-focused, so you can quickly see who&#39;s doing what and where.</p>
<p>What <code>show_cursor_names</code> does is the following:</p>
<ul>
<li>Toggle on <code>Editor.show_cursor_names</code> and trigger a re-render of the editor. When <code>Editor.show_cursor_names</code> is true, cursor names will be rendered.</li>
<li>Spawn a task that sleeps for <code>CURSOR_VISIBLE_FOR</code>, turn the cursors off, and trigger another re-render.</li>
</ul>
<p>If you&#39;ve ever written async Rust before, you can spot some familiar elements in the code: there&#39;s a <code>.spawn</code>, there&#39;s an <code>async move</code>, there&#39;s an <code>await</code>. And if you&#39;ve ever used the <code>async_task</code> crate before, this might remind you of code <a href="https://docs.rs/async-task/4.7.0/async_task/struct.Task.html#method.detach">like this</a>:</p>
<figure data-rehype-pretty-code-figure=""><div><pre tabindex="0" data-language="rust" data-theme="light-plus"><code data-language="rust" data-theme="light-plus"><span data-line=""><span>let</span><span> ex</span><span> = </span><span>Executor</span><span>::</span><span>new</span><span>();</span></span>
<span data-line=""><span>ex</span><span>.</span><span>spawn</span><span>(</span><span>async</span><span> {</span></span>
<span data-line=""><span>    loop</span><span> {</span></span>
<span data-line=""><span>        Timer</span><span>::</span><span>after</span><span>(</span><span>Duration</span><span>::</span><span>from_secs</span><span>(</span><span>1</span><span>)).</span><span>await</span><span>;</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""><span>})</span></span>
<span data-line=""><span>.</span><span>detach</span><span>();</span></span></code></pre></div></figure>
<p>That&#39;s because Zed uses <code>async_task</code> for its <code>Task</code> type. But in this example there&#39;s an <code>Executor</code> — where is that in the Zed code? And what does <code>cx.background_executor()</code> do? Good questions, let&#39;s find answers.</p>
<h2 id="macos-as-our-async-runtime"><span data-br=":Rdnbrrrqbf9la:" data-brr="1">macOS as our async runtime</span></h2>
<p>One remarkable thing about async Rust is that it allows you to choose your own runtime. That&#39;s different from a lot of other languages (such as JavaScript) in which you can also write asynchronous code. Runtime isn&#39;t a term with very sharp definition, but for our purposes here, we can say that a runtime is the thing that runs your asynchronous code and provides you with utilities such as <code>.spawn</code> and something like an <code>Executor</code>.</p>
<p>The most popular of these runtimes is probably <a href="https://github.com/tokio-rs/tokio">tokio</a>. But there&#39;s also <a href="https://github.com/smol-rs/smol">smol</a>, <a href="https://github.com/embassy-rs/embassy">embassy</a> and others. Choosing and switching runtimes comes with tradeoffs, they <a href="https://corrode.dev/blog/async/">are only interchangable to a degree</a>, but it is possible.</p>
<p>In Zed for macOS, as it turns out, we don&#39;t use any one of these. We also don&#39;t use <code>async_task</code>&#39;s <code>Executor</code>. But there has to be something to execute the asynchronous code, right? Otherwise I wouldn&#39;t be typing these lines in Zed.</p>
<p>So what then does <code>cx.spawn</code> do and what is the <code>cx.background_executor()</code>? Let&#39;s take a look. Here are <a href="https://github.com/zed-industries/zed/blob/dc98b3cfa19d6bd4eae813ce7dfaf9d9e13c232c/crates/gpui/src/app.rs#L818-L836">three relevant methods from GPUI&#39;s <code>AppContext</code></a>:</p>
<figure data-rehype-pretty-code-figure=""><div><pre tabindex="0" data-language="rust" data-theme="light-plus"><code data-language="rust" data-theme="light-plus"><span data-line=""><span>// crates/gpui/src/app.rs</span></span>
<span data-line=""> </span>
<span data-line=""><span>impl</span><span> AppContext</span><span> {</span></span>
<span data-line=""><span>    pub</span><span> fn</span><span> background_executor</span><span>(&amp;</span><span>self</span><span>) -&gt; &amp;</span><span>BackgroundExecutor</span><span> {</span></span>
<span data-line=""><span>        &amp;</span><span>self</span><span>.background_executor</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""> </span>
<span data-line=""><span>    pub</span><span> fn</span><span> foreground_executor</span><span>(&amp;</span><span>self</span><span>) -&gt; &amp;</span><span>ForegroundExecutor</span><span> {</span></span>
<span data-line=""><span>        &amp;</span><span>self</span><span>.foreground_executor</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""> </span>
<span data-line=""><span>    /// Spawns the future returned by the given function on the thread pool. The closure will be invoked</span></span>
<span data-line=""><span>    /// with [AsyncAppContext], which allows the application state to be accessed across await points.</span></span>
<span data-line=""><span>    pub</span><span> fn</span><span> spawn</span><span>&lt;</span><span>Fut</span><span>, </span><span>R</span><span>&gt;(&amp;</span><span>self</span><span>, </span><span>f</span><span>: </span><span>impl</span><span> FnOnce</span><span>(</span><span>AsyncAppContext</span><span>) -&gt; </span><span>Fut</span><span>) -&gt; </span><span>Task</span><span>&lt;</span><span>R</span><span>&gt;</span></span>
<span data-line=""><span>    where</span></span>
<span data-line=""><span>        Fut</span><span>: </span><span>Future</span><span>&lt;</span><span>Output</span><span> = </span><span>R</span><span>&gt; + &#39;</span><span>static</span><span>,</span></span>
<span data-line=""><span>        R</span><span>: &#39;</span><span>static</span><span>,</span></span>
<span data-line=""><span>    {</span></span>
<span data-line=""><span>        self</span><span>.foreground_executor.</span><span>spawn</span><span>(</span><span>f</span><span>(</span><span>self</span><span>.</span><span>to_async</span><span>()))</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""> </span>
<span data-line=""><span>    // [...]</span></span>
<span data-line=""><span>}</span></span></code></pre></div></figure>
<p>Alright, two executors, <code>foreground_executor</code> and <code>background_executor</code>, and both have <code>.spawn</code> methods. We already saw <code>background_executor</code>&#39;s <code>.spawn</code> above in <code>show_cursor_names</code> and here, in <code>AppContext.spawn</code>, we see the <code>foreground_executor</code> counterpart.</p>
<p>One level deeper, we can see what <code>foreground_executor.spawn</code> does:</p>
<figure data-rehype-pretty-code-figure=""><div><pre tabindex="0" data-language="rust" data-theme="light-plus"><code data-language="rust" data-theme="light-plus"><span data-line=""><span>// crates/gpui/src/executor.rs</span></span>
<span data-line=""> </span>
<span data-line=""><span>impl</span><span> ForegroundExecutor</span><span> {</span></span>
<span data-line=""><span>    /// Enqueues the given Task to run on the main thread at some point in the future.</span></span>
<span data-line=""><span>    pub</span><span> fn</span><span> spawn</span><span>&lt;</span><span>R</span><span>&gt;(&amp;</span><span>self</span><span>, </span><span>future</span><span>: </span><span>impl</span><span> Future</span><span>&lt;</span><span>Output</span><span> = </span><span>R</span><span>&gt; + &#39;</span><span>static</span><span>) -&gt; </span><span>Task</span><span>&lt;</span><span>R</span><span>&gt;</span></span>
<span data-line=""><span>    where</span></span>
<span data-line=""><span>        R</span><span>: &#39;</span><span>static</span><span>,</span></span>
<span data-line=""><span>    {</span></span>
<span data-line=""><span>        let</span><span> dispatcher</span><span> = </span><span>self</span><span>.dispatcher.</span><span>clone</span><span>();</span></span>
<span data-line=""><span>        fn</span><span> inner</span><span>&lt;</span><span>R</span><span>: &#39;</span><span>static</span><span>&gt;(</span></span>
<span data-line=""><span>            dispatcher</span><span>: </span><span>Arc</span><span>&lt;</span><span>dyn</span><span> PlatformDispatcher</span><span>&gt;,</span></span>
<span data-line=""><span>            future</span><span>: </span><span>AnyLocalFuture</span><span>&lt;</span><span>R</span><span>&gt;,</span></span>
<span data-line=""><span>        ) -&gt; </span><span>Task</span><span>&lt;</span><span>R</span><span>&gt; {</span></span>
<span data-line=""><span>            let</span><span> (</span><span>runnable</span><span>, </span><span>task</span><span>) = </span><span>async_task</span><span>::</span><span>spawn_local</span><span>(</span><span>future</span><span>, </span><span>move</span><span> |</span><span>runnable</span><span>| {</span></span>
<span data-line=""><span>                dispatcher</span><span>.</span><span>dispatch_on_main_thread</span><span>(</span><span>runnable</span><span>)</span></span>
<span data-line=""><span>            });</span></span>
<span data-line=""><span>            runnable</span><span>.</span><span>schedule</span><span>();</span></span>
<span data-line=""><span>            Task</span><span>::</span><span>Spawned</span><span>(</span><span>task</span><span>)</span></span>
<span data-line=""><span>        }</span></span>
<span data-line=""><span>        inner</span><span>::&lt;</span><span>R</span><span>&gt;(</span><span>dispatcher</span><span>, </span><span>Box</span><span>::</span><span>pin</span><span>(</span><span>future</span><span>))</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""> </span>
<span data-line=""><span>    // [...]</span></span>
<span data-line=""><span>}</span></span></code></pre></div></figure>
<p>There&#39;s a lot going on here, a lot of syntax, but what happens can be boiled down to this: the <code>.spawn</code> method takes in a <code>future</code>, turns it into a <a href="https://docs.rs/async-task/latest/async_task/struct.Runnable.html"><code>Runnable</code></a> and a <code>Task</code>, and asks the <code>dispatcher</code> to run it on the main thread.</p>
<p>The <code>dispatcher</code> here is a <code>PlatformDispatcher</code>. That&#39;s the GPUI equivalent of <code>async_task</code>&#39;s <code>Executor</code> from above. It has <code>Platform</code> in its name because it has different implementations for macOS, Linux, and Windows. But in this post, we&#39;re only going to look at macOS, since that&#39;s our best-supported platform at the moment and Linux/Windows implementations are still work-in-progress.</p>
<p>So what does <code>dispatch_on_main_thread</code> do? Does <em>this</em> now call an async runtime? No, no runtime <a href="https://github.com/zed-industries/zed/blob/dc98b3cfa19d6bd4eae813ce7dfaf9d9e13c232c/crates/gpui/src/platform/mac/dispatcher.rs#L66-L75">there either</a>:</p>
<figure data-rehype-pretty-code-figure=""><div><pre tabindex="0" data-language="rust" data-theme="light-plus"><code data-language="rust" data-theme="light-plus"><span data-line=""><span>// crates/gpui/src/platform/mac/dispatcher.rs</span></span>
<span data-line=""> </span>
<span data-line=""><span>impl</span><span> PlatformDispatcher</span><span> for</span><span> MacDispatcher</span><span> {</span></span>
<span data-line=""><span>    fn</span><span> dispatch_on_main_thread</span><span>(&amp;</span><span>self</span><span>, </span><span>runnable</span><span>: </span><span>Runnable</span><span>) {</span></span>
<span data-line=""><span>        unsafe</span><span> {</span></span>
<span data-line=""><span>            dispatch_async_f</span><span>(</span></span>
<span data-line=""><span>                dispatch_get_main_queue</span><span>(),</span></span>
<span data-line=""><span>                runnable</span><span>.</span><span>into_raw</span><span>().</span><span>as_ptr</span><span>() </span><span>as</span><span> *</span><span>mut</span><span> c_void</span><span>,</span></span>
<span data-line=""><span>                Some</span><span>(</span><span>trampoline</span><span>),</span></span>
<span data-line=""><span>            );</span></span>
<span data-line=""><span>        }</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""><span>    // [...]</span></span>
<span data-line=""><span>}</span></span>
<span data-line=""> </span>
<span data-line=""><span>extern</span><span> &#34;C&#34;</span><span> fn</span><span> trampoline</span><span>(</span><span>runnable</span><span>: *</span><span>mut</span><span> c_void</span><span>) {</span></span>
<span data-line=""><span>    let</span><span> task</span><span> = </span><span>unsafe</span><span> { </span><span>Runnable</span><span>::&lt;()&gt;::</span><span>from_raw</span><span>(</span><span>NonNull</span><span>::</span><span>new_unchecked</span><span>(</span><span>runnable</span><span> as</span><span> *</span><span>mut</span><span> ())) };</span></span>
<span data-line=""><span>    task</span><span>.</span><span>run</span><span>();</span></span>
<span data-line=""><span>}</span></span></code></pre></div></figure>
<p><code>dispatch_async_f</code> is where the call leaves the Zed codebase, because <code>dispatch_async_f</code> is actually a compile-time generated binding to the <a href="https://developer.apple.com/documentation/dispatch/1452834-dispatch_async_f"><code>dispatch_async_f</code></a> function in <a href="https://developer.apple.com/documentation/DISPATCH">macOS&#39; Grand Central Dispatch&#39;s (GCD)</a>. <code>dispatch_get_main_queue()</code>, too, is such a binding.</p>
<p>That&#39;s right: Zed, as a macOS application, uses macOS&#39; GCD to schedule and execute work.</p>
<p>What happens in the snippet above is that Zed turns the <code>Runnable</code> — think of it as a handle to a <code>Task</code> — into a raw pointer and passes it to <code>dispatch_async_f</code> along with a <code>trampoline</code>, which puts it on its <code>main_queue</code>.</p>
<p>When GCD then decides it&#39;s time to run the next item on the <code>main_queue</code>, it pops it off the queue, and calls <code>trampoline</code>, which takes the raw pointer, turns it back into a <code>Runnable</code> and, to poll the <code>Future</code> behind its <code>Task</code>, calls <code>.run()</code> on it.</p>
<p>And, as I learned to my big surprise: that&#39;s it. That&#39;s essentially all the code necessary to use GCD as a &#34;runtime&#34; for async Rust. Where other applications use tokio or smol, Zed uses thin wrappers around GCD and crates such as <code>async_task</code>.</p>
<p>Wait, but what about the <code>BackgroundExecutor</code>? It&#39;s very, very similar to the <code>ForegroundExecutor</code>, with the main difference being that the <code>BackgroundExecutor</code> calls this method on <code>PlatformDispatcher</code>:</p>
<figure data-rehype-pretty-code-figure=""><div><pre tabindex="0" data-language="rust" data-theme="light-plus"><code data-language="rust" data-theme="light-plus"><span data-line=""><span>impl</span><span> PlatformDispatcher</span><span> for</span><span> MacDispatcher</span><span> {</span></span>
<span data-line=""><span>    fn</span><span> dispatch</span><span>(&amp;</span><span>self</span><span>, </span><span>runnable</span><span>: </span><span>Runnable</span><span>, </span><span>_</span><span>: </span><span>Option</span><span>&lt;</span><span>TaskLabel</span><span>&gt;) {</span></span>
<span data-line=""><span>        unsafe</span><span> {</span></span>
<span data-line=""><span>            dispatch_async_f</span><span>(</span></span>
<span data-line=""><span>                dispatch_get_global_queue</span><span>(DISPATCH_QUEUE_PRIORITY_HIGH.</span><span>try_into</span><span>().</span><span>unwrap</span><span>(), </span><span>0</span><span>),</span></span>
<span data-line=""><span>                runnable</span><span>.</span><span>into_raw</span><span>().</span><span>as_ptr</span><span>() </span><span>as</span><span> *</span><span>mut</span><span> c_void</span><span>,</span></span>
<span data-line=""><span>                Some</span><span>(</span><span>trampoline</span><span>),</span></span>
<span data-line=""><span>            );</span></span>
<span data-line=""><span>        }</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""><span>}</span></span></code></pre></div></figure>
<p>The only difference between this <code>dispatch</code> method and <code>dispatch_async_f</code> from above is the queue. The <code>BackgroundExecutor</code> doesn&#39;t use the <code>main_queue</code>, but <a href="https://developer.apple.com/documentation/dispatch/1452927-dispatch_get_global_queue?language=objc">a global queue</a>.</p>
<p>Like I did when I first read through this code, you now might wonder: why?</p>
<p>Why use GCD? Why have a <code>ForegroundExecutor</code> and a <code>BackgroundExecutor</code>? What&#39;s so special about the <code>main_queue</code>?</p>
<h2 id="never-block-the-main-thread"><span data-br=":R14nbrrrqbf9la:" data-brr="1">Never block the main thread</span></h2>
<p>In a native UI application, the main thread is important. No, the main thread is <em>holy</em>. The main thread is where the rendering happens, where user input is handled, where the operating system communicates with the application. The main thread should never, ever block. On the main thread, the responsiveness of your app lives or dies.</p>
<p>That&#39;s true for <a href="https://en.wikipedia.org/wiki/Cocoa_(API)">Cocoa</a> applications on macOS too. Rendering, receiving user input, communication with macOS, and other platform concerns have to happen on the main thread. And since Zed wants perfect cooperation with macOS to ensure high-performance and responsiveness, it does two things.</p>
<p>First, it uses GCD to schedule its work — on and off the main thread — so that macOS can maintain high responsiveness and overall system efficiency.</p>
<p>Second, the importance of the main thread is baked into GPUI, the UI framework, by explicitly making the distinction between the <code>ForegroundExecutor</code> and the <code>BackgroundExecutor</code>, both of which we saw above.</p>
<p>As a writer of application-level Zed code, you should always be mindful of what happens on the main thread and never put too much blocking work on it. If you were to put, say, a blocking <code>sleep(10ms)</code> on the main thread, rendering the UI now has to wait for that <code>sleep()</code> to finish, which means that rendering the next frame would take longer than 8ms — the maximum frame time available if you want to achieve <a href="https://zed.dev/blog/120fps">120 FPS</a>. You&#39;d &#34;drop a frame&#34;, as they say.</p>
<p>Knowing that, let&#39;s take a look at another small snippet of code. This time it&#39;s from the built-in terminal in Zed, a function that <a href="https://github.com/zed-industries/zed/blob/dc98b3cfa19d6bd4eae813ce7dfaf9d9e13c232c/crates/terminal/src/terminal.rs#L1346-L1358">searches through the contents of the terminal buffer</a>:</p>
<figure data-rehype-pretty-code-figure=""><div><pre tabindex="0" data-language="rust" data-theme="light-plus"><code data-language="rust" data-theme="light-plus"><span data-line=""><span>// crates/terminal/src/terminal.rs</span></span>
<span data-line=""> </span>
<span data-line=""><span>pub</span><span> struct</span><span> Terminal</span><span> {</span></span>
<span data-line=""><span>    term</span><span>: </span><span>Arc</span><span>&lt;</span><span>Mutex</span><span>&lt;</span><span>alacritty_terminal</span><span>::</span><span>Term</span><span>&lt;</span><span>ZedListener</span><span>&gt;&gt;&gt;,</span></span>
<span data-line=""> </span>
<span data-line=""><span>    // [... other fields ...]</span></span>
<span data-line=""><span>}</span></span>
<span data-line=""> </span>
<span data-line=""><span>pub</span><span> fn</span><span> find_matches</span><span>(</span></span>
<span data-line=""><span>    &amp;</span><span>mut</span><span> self</span><span>,</span></span>
<span data-line=""><span>    mut</span><span> searcher</span><span>: </span><span>RegexSearch</span><span>,</span></span>
<span data-line=""><span>    cx</span><span>: &amp;</span><span>mut</span><span> ModelContext</span><span>&lt;</span><span>Self</span><span>&gt;,</span></span>
<span data-line=""><span>) -&gt; </span><span>Task</span><span>&lt;</span><span>Vec</span><span>&lt;</span><span>RangeInclusive</span><span>&lt;</span><span>AlacPoint</span><span>&gt;&gt;&gt; {</span></span>
<span data-line=""><span>    let</span><span> term</span><span> = </span><span>self</span><span>.term.</span><span>clone</span><span>();</span></span>
<span data-line=""><span>    cx</span><span>.</span><span>background_executor</span><span>().</span><span>spawn</span><span>(</span><span>async</span><span> move</span><span> {</span></span>
<span data-line=""><span>        let</span><span> term</span><span> = </span><span>term</span><span>.</span><span>lock</span><span>();</span></span>
<span data-line=""> </span>
<span data-line=""><span>        all_search_matches</span><span>(&amp;</span><span>term</span><span>, &amp;</span><span>mut</span><span> searcher</span><span>).</span><span>collect</span><span>()</span></span>
<span data-line=""><span>    })</span></span>
<span data-line=""><span>}</span></span></code></pre></div></figure>
<p>The first line in <code>find_matches</code>, the <code>self.term.clone()</code>, happens on the main thread and is quick: <code>self.term</code> is an <code>Arc&lt;Mutex&lt;...&gt;&gt;</code>, so cloning only bumps the reference count on the <code>Arc</code>. The call to <code>.lock()</code> then only happens in the background, since <code>.lock()</code> might block. It&#39;s unlikely that there will be contention for this lock in this particular code path, but if there was contention, it wouldn&#39;t freeze the UI, only a single background thread. That&#39;s the pattern: if it&#39;s quick, you can do it on the main thread, but if it might take a while or even block, put it on a background thread by using <code>cx.background_executor()</code>.</p>
<p>Here&#39;s another example, the project-wide search in Zed (<code>⌘-shift-f</code>). It pushes as much heavy work as possible onto background threads to ensure Zed stays responsive while searching through tens of thousands of files in your project. Here&#39;s a simplified and heavily-commented <a href="https://github.com/zed-industries/zed/blob/dc98b3cfa19d6bd4eae813ce7dfaf9d9e13c232c/crates/project/src/project.rs#L6485-L6498">excerpt from <code>Project.search_local</code></a> that shows the main part of the search:</p>
<figure data-rehype-pretty-code-figure=""><div><pre tabindex="0" data-language="rust" data-theme="light-plus"><code data-language="rust" data-theme="light-plus"><span data-line=""><span>// crates/project/src/project.rs</span></span>
<span data-line=""> </span>
<span data-line=""><span>// Spawn a Task on the background executor. The Task finds all files on disk</span></span>
<span data-line=""><span>// that contain &gt;1 matches for the given `query` and sends them back over</span></span>
<span data-line=""><span>// the `matching_paths_tx` channel.</span></span>
<span data-line=""><span>let</span><span> (</span><span>matching_paths_tx</span><span>, </span><span>matching_paths_rx</span><span>) = </span><span>smol</span><span>::</span><span>channel</span><span>::</span><span>bounded</span><span>(</span><span>1024</span><span>);</span></span>
<span data-line=""><span>cx</span><span>.</span><span>background_executor</span><span>()</span></span>
<span data-line=""><span>    .</span><span>spawn</span><span>(</span><span>Self</span><span>::</span><span>background_search</span><span>(</span></span>
<span data-line=""><span>        // [... other arguments ... ]</span></span>
<span data-line=""><span>        query</span><span>.</span><span>clone</span><span>(),</span></span>
<span data-line=""><span>        matching_paths_tx</span><span>,</span></span>
<span data-line=""><span>    ))</span></span>
<span data-line=""><span>    .</span><span>detach</span><span>();</span></span>
<span data-line=""> </span>
<span data-line=""><span>// Setup a channel on which we stream results to the UI.</span></span>
<span data-line=""><span>let</span><span> (</span><span>result_tx</span><span>, </span><span>result_rx</span><span>) = </span><span>smol</span><span>::</span><span>channel</span><span>::</span><span>bounded</span><span>(</span><span>1024</span><span>);</span></span>
<span data-line=""> </span>
<span data-line=""><span>// On the main thread, spawn a Task that first...</span></span>
<span data-line=""><span>cx</span><span>.</span><span>spawn</span><span>(|</span><span>this</span><span>, </span><span>mut</span><span> cx</span><span>| </span><span>async</span><span> move</span><span> {</span></span>
<span data-line=""><span>    // ... waits for the background thread to return the filepaths of</span></span>
<span data-line=""><span>    // the maximum number of files that we want to search...</span></span>
<span data-line=""><span>    let</span><span> mut</span><span> matching_paths</span><span> = </span><span>matching_paths_rx</span></span>
<span data-line=""><span>        .</span><span>take</span><span>(MAX_SEARCH_RESULT_FILES + </span><span>1</span><span>)</span></span>
<span data-line=""><span>        .</span><span>collect</span><span>::&lt;</span><span>Vec</span><span>&lt;</span><span>_</span><span>&gt;&gt;()</span></span>
<span data-line=""><span>        .</span><span>await</span><span>;</span></span>
<span data-line=""> </span>
<span data-line=""><span>    // ... then loops over the filepaths in chunks of 64...</span></span>
<span data-line=""><span>    for</span><span> matching_paths_chunk</span><span> in</span><span> matching_paths</span><span>.</span><span>chunks</span><span>(</span><span>64</span><span>) {</span></span>
<span data-line=""><span>        let</span><span> mut</span><span> chunk_results</span><span> = </span><span>Vec</span><span>::</span><span>new</span><span>();</span></span>
<span data-line=""> </span>
<span data-line=""><span>        for</span><span> matching_path</span><span> in</span><span> matching_paths_chunk</span><span> {</span></span>
<span data-line=""><span>            // .... opens each file....</span></span>
<span data-line=""><span>            let</span><span> buffer</span><span> = </span><span>this</span><span>.</span><span>update</span><span>(&amp;</span><span>mut</span><span> cx</span><span>, |</span><span>this</span><span>, </span><span>cx</span><span>| {</span></span>
<span data-line=""><span>                this</span><span>.</span><span>open_buffer</span><span>((*</span><span>worktree_id</span><span>, </span><span>path</span><span>.</span><span>clone</span><span>()), </span><span>cx</span><span>)</span></span>
<span data-line=""><span>            })?;</span></span>
<span data-line=""> </span>
<span data-line=""><span>            // ... and pushes into `chunk_results` a Task that</span></span>
<span data-line=""><span>            // runs on the main thread and ...</span></span>
<span data-line=""><span>            chunk_results</span><span>.</span><span>push</span><span>(</span><span>cx</span><span>.</span><span>spawn</span><span>(|</span><span>cx</span><span>| </span><span>async</span><span> move</span><span> {</span></span>
<span data-line=""><span>                // ... waits for the file to be opened ...</span></span>
<span data-line=""><span>                let</span><span> buffer</span><span> = </span><span>buffer</span><span>.</span><span>await</span><span>?;</span></span>
<span data-line=""><span>                // ... creates a snapshot of its contents ...</span></span>
<span data-line=""><span>                let</span><span> snapshot</span><span> = </span><span>buffer</span><span>.</span><span>read_with</span><span>(&amp;</span><span>cx</span><span>, |</span><span>buffer</span><span>, </span><span>_</span><span>| </span><span>buffer</span><span>.</span><span>snapshot</span><span>())?;</span></span>
<span data-line=""><span>                // ... and again starts a Task on the background executor,</span></span>
<span data-line=""><span>                // which searches through the snapshot for all results.</span></span>
<span data-line=""><span>                let</span><span> ranges</span><span> = </span><span>cx</span></span>
<span data-line=""><span>                    .</span><span>background_executor</span><span>()</span></span>
<span data-line=""><span>                    .</span><span>spawn</span><span>(</span><span>async</span><span> move</span><span> {</span></span>
<span data-line=""><span>                        query</span></span>
<span data-line=""><span>                            .</span><span>search</span><span>(&amp;</span><span>snapshot</span><span>, </span><span>None</span><span>)</span></span>
<span data-line=""><span>                            .</span><span>await</span></span>
<span data-line=""><span>                            .</span><span>iter</span><span>()</span></span>
<span data-line=""><span>                            .</span><span>collect</span><span>::&lt;</span><span>Vec</span><span>&lt;</span><span>_</span><span>&gt;&gt;()</span></span>
<span data-line=""><span>                    })</span></span>
<span data-line=""><span>                    .</span><span>await</span><span>;</span></span>
<span data-line=""> </span>
<span data-line=""><span>                Ok</span><span>((</span><span>buffer</span><span>, </span><span>ranges</span><span>))</span></span>
<span data-line=""><span>            }));</span></span>
<span data-line=""><span>        }</span></span>
<span data-line=""> </span>
<span data-line=""><span>        // On the main thread, non-blocking, wait for all buffers to be searched...</span></span>
<span data-line=""><span>        let</span><span> chunk_results</span><span> = </span><span>futures</span><span>::</span><span>future</span><span>::</span><span>join_all</span><span>(</span><span>chunk_results</span><span>).</span><span>await</span><span>;</span></span>
<span data-line=""><span>        for</span><span> result</span><span> in</span><span> chunk_results</span><span> {</span></span>
<span data-line=""><span>            if</span><span> let</span><span> Some</span><span>((</span><span>buffer</span><span>, </span><span>ranges</span><span>)) = </span><span>result</span><span>.</span><span>log_err</span><span>() {</span></span>
<span data-line=""><span>                // send the results over the results channel</span></span>
<span data-line=""><span>                result_tx</span></span>
<span data-line=""><span>                    .</span><span>send</span><span>(</span><span>SearchResult</span><span>::</span><span>Buffer</span><span> { </span><span>buffer</span><span>, </span><span>ranges</span><span> })</span></span>
<span data-line=""><span>                    .</span><span>await</span><span>?;</span></span>
<span data-line=""><span>            }</span></span>
<span data-line=""><span>        }</span></span>
<span data-line=""><span>    }</span></span>
<span data-line=""><span>})</span></span>
<span data-line=""><span>.</span><span>detach</span><span>();</span></span>
<span data-line=""> </span>
<span data-line=""><span>result_rx</span></span></code></pre></div></figure>
<p>It&#39;s a lot of code — sorry! — but there&#39;s not a lot more going on than the concepts we already talked about. What&#39;s noteworthy here and why I wanted to show it is the ping-pong between the main thread and background threads:</p>
<ul>
<li><strong>main thread</strong>: kicks off the search and hands the <code>query</code> over to background thread</li>
<li><strong>background thread</strong>: finds files in project with &gt;1 occurrences of <code>query</code> in them, sends results back over channel as they come in</li>
<li><strong>main thread</strong>: waits until background thread has found <code>MAX+1</code> results, then drops channel, which causes background thread to exit</li>
<li><strong>main thread</strong>: spawns multiple other main-thread tasks to open each file &amp; create a snapshot.</li>
<li><strong>background threads</strong>: search through buffer snapshot to find all results in a buffer, sends results back over channel</li>
<li><strong>main thread</strong>: waits for background thread to find results in all buffers, then sends them back to the caller of the outer <code>search_local</code> method</li>
</ul>
<p>Even though this method can be optimized and the search made a lot faster (we haven&#39;t gotten around to that yet), it can already search thousands of files without blocking the main thread, while still using multiple CPU cores.</p>
<h2 id="async-friendly-data-structures-testing-executors-and-more"><span data-br=":R1inbrrrqbf9la:" data-brr="1">Async-Friendly Data Structures, Testing Executors, and More</span></h2>
<p>I&#39;m pretty sure that the previous code excerpt raised a lot of questions that I haven&#39;t answered yet: how exactly is it possible to send a buffer snapshot to a background thread? How efficient is it do that? What if I want to modify such a snapshot on another thread? How do you test all this?</p>
<p>And I&#39;m sorry to say that I couldn&#39;t fit all of the answers into this post. But there is a <a href="https://youtu.be/gkU4NGSe21I">companion video</a> in which Antonio and I did dive into a lot of these areas and talked about async-friendly data structures, copy-on-write buffer snapshots, and other things. Antonio also gave <a href="https://www.youtube.com/watch?v=ms8zKpS_dZE">a fantastic talk about how we do property-testing of async Rust code</a> in the Zed code base that I highly recommend. I also promise that in the future there will be a post about the data structures underlying the Zed editor.</p>
<p>Until next time!</p><hr/></article></div></div>
  </body>
</html>
