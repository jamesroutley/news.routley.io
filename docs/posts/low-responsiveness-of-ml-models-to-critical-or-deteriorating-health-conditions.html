<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.nature.com/articles/s43856-025-00775-0">Original</a>
    <h1>Low responsiveness of ML models to critical or deteriorating health conditions</h1>
    
    <div id="readability-page-1" class="page"><div>
                    
                        <section data-title="Introduction"><div id="Sec1-section"><h2 id="Sec1">Introduction</h2><div id="Sec1-content"><p>The Food Drug Administration authorized the first autonomous artificial intelligence (AI) diagnostic system in 2018, which is for detecting diabetic retinopathy<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 1" title="Abràmoff, M. D., Lavin, P. T., Birch, M., Shah, N. &amp; Folk, J. C. Pivotal trial of an autonomous AI-based diagnostic system for detection of diabetic retinopathy in primary care offices. NPJ Digit. Med. 1, 39 (2018)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR1" id="ref-link-section-d258281533e571">1</a></sup>. Since then, AI machine learning (ML) based predictive technologies are rapidly made available for incorporation into clinical workflows<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 2" title="Sennaar, K. How America’s 5 top hospitals are using machine learning today. Emerj 
                  https://emerj.com/ai-sector-overviews/top-5-hospitals-using-machine-learning
                  
                 (2020)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR2" id="ref-link-section-d258281533e575">2</a></sup>, e.g., for early sepsis detection<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 3" title="Sendak, M. P. et al. Real-world integration of a sepsis deep learning technology into routine clinical care: implementation study. JMIR Med. Inform. 8, e15182 (2020)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR3" id="ref-link-section-d258281533e579">3</a></sup> and predicting surgery time<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 4" title="Zaribafzadeh, H. et al. Development, deployment, and implementation of a machine learning surgical case length prediction model and prospective evaluation. Ann. Surg. 278, 890–895 (2023)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR4" id="ref-link-section-d258281533e583">4</a></sup>. However, recent studies revealed problems of prediction models under various medical scenarios, e.g., missed detection in mortality prediction or cancer prognosis<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Afrose, S., Song, W., Nemeroff, C. B., Lu, C. &amp; Yao, D. Subpopulation-specific machine learning prognosis for underrepresented patients with double prioritized bias correction. Commun. Med. 2, 111 (2022)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR5" id="ref-link-section-d258281533e587">5</a></sup>, poor sepsis forecast by a popular U.S. electronic health record software system Epic<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 6" title="Wong, A. et al. External validation of a widely implemented proprietary sepsis prediction model in hospitalized patients. JAMA Intern. Med. 181, 1065–1070 (2021)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR6" id="ref-link-section-d258281533e592">6</a></sup>, and models creating incorrect predictive shortcuts for image-based skin cancer detection<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Winkler, J. K. et al. Association between surgical skin markings in dermoscopic images and diagnostic performance of a deep learning convolutional neural network for melanoma recognition. JAMA Dermatol. 155, 1135–1141 (2019)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR7" id="ref-link-section-d258281533e596">7</a></sup>.</p><p>These findings point out the urgent need for systematic model evaluation before their clinical adoption to ensure trustworthiness<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 8" title="Liang, W. et al. Advances, challenges and opportunities in creating data for trustworthy AI. Nat. Mach. Intell. 4, 669–677 (2022)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR8" id="ref-link-section-d258281533e603">8</a></sup>. For example, for in-hospital mortality (IHM) prediction, it is important to measure whether or not ML models can promptly respond to deteriorating patients’ conditions. However, due to the immense complexity of the input space, model evaluation is challenging. Exhaustive testing is both unnecessary and impossible in most medical AI applications.</p><p>The current ML testing practice is very limited in terms of the coverage of disease conditions. Existing model testing is largely restricted to a small percentage (10-15%) of the existing dataset, i.e., test set, as the bulk of the data is reserved for training. Because data imbalance in medicine is common, a typical test set likely has a low coverage of various critical medical conditions and minority prediction class cases. For example, the minority prediction class (i.e., death class) only accounts for 13.5% of an IHM prediction dataset<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Afrose, S., Song, W., Nemeroff, C. B., Lu, C. &amp; Yao, D. Subpopulation-specific machine learning prognosis for underrepresented patients with double prioritized bias correction. Commun. Med. 2, 111 (2022)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR5" id="ref-link-section-d258281533e610">5</a></sup>. Even with cross-validation and bootstrapping, the test set is largely limited to the original data.</p><p>As a result of the limited test sets, predictive models may be under-evaluated. How they respond to real-world scenarios may be insufficiently assessed. During clinical deployment, new patient conditions could occur out of the distribution of the test set, triggering unexpected failures, e.g., the model failing to produce high enough risk scores for critically ill patients. This issue may disproportionately impact the smaller prediction class, as a typical data-driven model aims to prioritize the accuracy of the majority class samples during training<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Afrose, S., Song, W., Nemeroff, C. B., Lu, C. &amp; Yao, D. Subpopulation-specific machine learning prognosis for underrepresented patients with double prioritized bias correction. Commun. Med. 2, 111 (2022)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR5" id="ref-link-section-d258281533e617">5</a></sup>. One approach for increasing test coverage is to use synthetic test samples. Recently, generative technologies have been proposed to produce curated manmade images for testing self-driving vehicles<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 9" title="Tian, Y., Pei, K., Jana, S. &amp; Ray, B. Deeptest: Automated testing of deep-neural-network-driven autonomous cars. Proceedings of the 40th International Conference on Software Engineering 303–314 (Association for Computing Machinery, 2018)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR9" id="ref-link-section-d258281533e621">9</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 10" title="Pei, K., Cao, Y., Yang, J. &amp; Jana, S. Deepxplore: automated whitebox testing of deep learning systems. Proceedings of the 26th Symposium on Operating Systems Principles 1–18 (Association for Computing Machinery, 2017)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR10" id="ref-link-section-d258281533e624">10</a></sup>. However, image-based solutions do not address the unique temporal challenge in medical time-series applications.</p><p>In this work, we develop systematic approaches for generating new test cases beyond the original dataset to assess the responsiveness of ML models to critical health conditions that may occur in clinical settings. Our test case generation is guided by domain knowledge and medical experts. Our experiments involve binary classification tasks, including time-series-based IHM prediction and 5-year breast and lung cancer survivability (LCS) prognosis (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig1">1</a>). We develop multiple methods for generating high-risk test cases that do not exist in the training data or are underrepresented in the training set. Our solutions can process time series data, which is pervasive in medicine. We also conduct interviews with medical experts to obtain their estimated risks on some of the generated test cases. Our work reveals alarming prediction deficiencies of ML models and points out that ML responsiveness is an important aspect of trustworthiness in digital health.</p><div data-test="figure" data-container-section="figure" id="figure-1" data-title="Number of generated test cases for evaluating models trained on in-hospital mortality risk prediction and 5-year cancer survivability prediction models."><figure><figcaption><b id="Fig1" data-test="figure-caption-text">Fig. 1: Number of generated test cases for evaluating models trained on in-hospital mortality risk prediction and 5-year cancer survivability prediction models.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s43856-025-00775-0/figures/1" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs43856-025-00775-0/MediaObjects/43856_2025_775_Fig1_HTML.png?as=webp"/><img aria-describedby="Fig1" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs43856-025-00775-0/MediaObjects/43856_2025_775_Fig1_HTML.png" alt="figure 1" loading="lazy" width="685" height="326"/></picture></a></div><p>The left side illustrates the generated test case of each category for testing in-hospital mortality risk prediction models trained on MIMIC III or eICU dataset. The right side represents the generated test cases to test 5-year breast cancer survivability (BCS) prediction models. The SEER lung cancer survivability (LCS) models are tested similarly using the single-attribute test cases.</p></div></figure></div></div></div></section><section data-title="Methods"><div id="Sec2-section"><h2 id="Sec2">Methods</h2><div id="Sec2-content"><h3 id="Sec3">Prediction tasks, datasets, and model selection</h3><p>Our work aims to test medical ML models for their binary classification accuracy under serious disease conditions. We focus on three binary prediction tasks, namely 48-h IHM risk prediction, 5-year breast cancer survivability (BCS) prediction, and 5-year LCS prediction.</p><p>The datasets in our study include a 2019 benchmark<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Harutyunyan, H., Khachatrian, H., Kale, D. C., Ver Steeg, G. &amp; Galstyan, A. Multitask learning and benchmarking with clinical time series data. Sci. data 6, 96 (2019)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR11" id="ref-link-section-d258281533e669">11</a></sup> based on the MIMIC III<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 12" title="Johnson, A., Pollard, T. &amp; Mark, R. MIMIC-III clinical database (version 1.4). PhysioNet 10, 2 (2016)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR12" id="ref-link-section-d258281533e673">12</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 13" title="Johnson, A. E. et al. MIMIC-III, a freely accessible critical care database. Sci. Data 3, 1–9 (2016)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR13" id="ref-link-section-d258281533e676">13</a></sup> dataset, a 2020 benchmark<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Sheikhalishahi, S., Balaraman, V. &amp; Osmani, V. Benchmarking machine learning models on multi-centre eICU critical care dataset. PloS ONE 15, e0235424 (2020)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR14" id="ref-link-section-d258281533e680">14</a></sup> based on the eICU<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 15" title="Pollard, T. J. et al. The eICU Collaborative Research Database, a freely available multi-center database for critical care research. Sci. Data 5, 1–13 (2018)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR15" id="ref-link-section-d258281533e684">15</a></sup> dataset, and a 2018 reproducibility benchmark<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Hegselmann, S., Gruelich, L., Varghese, J. &amp; Dugas, M. Reproducible survival prediction with SEER cancer data. Proceedings of the Machine Learning for Healthcare Conference, vol. 85, 49–66 (PMLR, 2018)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR16" id="ref-link-section-d258281533e688">16</a></sup> based on the Surveillance, Epidemiology, and End Results (SEER) (5-year breast and lung cancer) dataset<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Hegselmann, S., Gruelich, L., Varghese, J. &amp; Dugas, M. Reproducible survival prediction with SEER cancer data. Proceedings of the Machine Learning for Healthcare Conference, vol. 85, 49–66 (PMLR, 2018)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR16" id="ref-link-section-d258281533e693">16</a></sup>. The first two datasets contain patients’ 48-h time series data in critical care units (ICU). Our study excludes clinical free text notes. As with many medical datasets, the MIMIC-III dataset for IHM, containing 21,139 samples, is imbalanced, with 13.2% death cases (Class 1), and 86.8% non-death cases (Class 0). The eICU IHM benchmark dataset contains a total of 30,681 (88.5% for Class 0 and 11.5% for Class 1) samples with similar attributes and time lengths to the MIMIC III benchmark<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Sheikhalishahi, S., Balaraman, V. &amp; Osmani, V. Benchmarking machine learning models on multi-centre eICU critical care dataset. PloS ONE 15, e0235424 (2020)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR14" id="ref-link-section-d258281533e697">14</a></sup>. Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">S1</a> shows the distributions of key attributes of both MIMIC III and eICU datasets. The SEER BCS dataset contains 248,751 patient cases with 56 attributes (7 numerical and continuous features and 49 categorical). In the SEER BCS dataset, 12.7% of cases are death cases (Class 0); the rest are survived cases (Class 1). Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">S2</a> shows the distributions of key attributes. The SEER LCS dataset contains 205,555 cases with 47 features (7 numerical and continuous features and 40 categorical). 84% of patients died in the LCS dataset.</p><p>The creation of the MIMIC-III dataset was approved by the Institutional Review Boards of Beth Israel Deaconess Medical Center (Boston, MA) and the Massachusetts Institute of Technology (Cambridge, MA). Because sensitive health information was de-identified and the dataset did not impact clinical care, the requirement for individual patient consent was waived. The eICU dataset creation is exempt from institutional review board approval due to the retrospective design, lack of direct patient intervention, and the security schema, for which the re-identification risk was certified as meeting safe harbor standards by an independent privacy expert (Privacert, Cambridge, MA) (Health Insurance Portability and Accountability Act Certification no. 1031219-2). The SEER Program dataset is managed and maintained by the National Cancer Institute (NCI) in the United States. The centralized data collection system enables central IRB submission and approval through reliance agreements with registries. The SEER data collected by registries under state public health reporting authority is HIPAA exempt. MIMIC III is freely available through a proper request to the data source (<a href="https://physionet.org/content/mimiciii/1.4/">https://physionet.org/content/mimiciii/1.4/</a>). It requires a license (PhysioNet Credentialed Health Data License 1.5.0), Data Use Agreement (PhysioNet Credentialed Health Data Use Agreement 1.5.0), a training (CITI Data or Specimens Only Research). The eICU dataset can also be accessed (<a href="https://physionet.org/content/eicu-crd/2.0/">https://physionet.org/content/eicu-crd/2.0/</a>) by completing these mentioned steps. The SEER dataset is also freely available through a proper request to the data source (<a href="https://seer.cancer.gov/">https://seer.cancer.gov/</a>). It requires the Data Application Form, Data User Agreement, and Acknowledgment of Data Limitations (<a href="https://seer.cancer.gov/data/product-comparison.html">https://seer.cancer.gov/data/product-comparison.html</a>). The data was accessed through an eRA Commons account, and the data cohort was selected using SEER*Stat software. We gained access to the datasets following the various routes described above. All these datasets are de-identified and public. Thus, an IRB approval is not required for this study, specifically the analysis of de-identified and publicly available data does not constitute human subjects research (U.S. Federal Regulations 45 CFR 46.102).</p><p>We select ML models that are commonly used in the medical literature for these prediction tasks. Specifically, we select long short term memory (LSTM) as it is widely used for predicting mortality risk in a 48-h ICU time series dataset—in recent literature<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Afrose, S., Song, W., Nemeroff, C. B., Lu, C. &amp; Yao, D. Subpopulation-specific machine learning prognosis for underrepresented patients with double prioritized bias correction. Commun. Med. 2, 111 (2022)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR5" id="ref-link-section-d258281533e741">5</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Khadanga, S., Aggarwal, K., Joty, S. &amp; Srivastava, J. Using clinical notes with time series data for ICU management. Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP) 6432–6437 (Association for Computational Linguistics, 2019)." href="#ref-CR17" id="ref-link-section-d258281533e744">17</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Deznabi, I., Iyyer, M. &amp; Fiterau, M. Predicting in-hospital mortality by combining clinical notes with time-series data. In Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021 4026–4031 (Association for Computational Linguistics, 2021)." href="#ref-CR18" id="ref-link-section-d258281533e744_1">18</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 19" title="Zhang, H., Singh, H., Ghassemi, M. &amp; Joshi, S. Why did the model fail?”: attributing model performance changes to distribution shifts. Proceedings of the 40th International Conference on Machine Learning, vol. 202, 41550–41578 (PMLR, 2023)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR19" id="ref-link-section-d258281533e747">19</a></sup>. Similarly, for cancer survivability prediction, we selected multi-layer perceptron (MLP), which was commonly used in analyzing SEER datasets<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Afrose, S., Song, W., Nemeroff, C. B., Lu, C. &amp; Yao, D. Subpopulation-specific machine learning prognosis for underrepresented patients with double prioritized bias correction. Commun. Med. 2, 111 (2022)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR5" id="ref-link-section-d258281533e751">5</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Hegselmann, S., Gruelich, L., Varghese, J. &amp; Dugas, M. Reproducible survival prediction with SEER cancer data. Proceedings of the Machine Learning for Healthcare Conference, vol. 85, 49–66 (PMLR, 2018)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR16" id="ref-link-section-d258281533e754">16</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 20" title="Zhou, H., Chen, Y. &amp; Lipton, Z. Evaluating model performance in medical datasets over time. Proceedings of the Conference on Health, Inference, and Learning, vol. 209, 498–508 (PMLR, 2023)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR20" id="ref-link-section-d258281533e757">20</a></sup>. In addition, we also evaluated general-purpose ML models commonly seen in medical literature, including XGBoost, AdaBoost, random forest, Gaussian Naive Bayes, and K-nearest Neighbor (KNN). For mortality prediction, we also include channel-wise long short term memory (CW-LSTM) and linear logistic regression (LR) models from the benchmark study<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Harutyunyan, H., Khachatrian, H., Kale, D. C., Ver Steeg, G. &amp; Galstyan, A. Multitask learning and benchmarking with clinical time series data. Sci. data 6, 96 (2019)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR11" id="ref-link-section-d258281533e761">11</a></sup> and an advanced transformer model.</p><h3 id="Sec4">Dataset preprocessing</h3><p>We train ML models with benchmark datasets of MIMIC-III<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Harutyunyan, H., Khachatrian, H., Kale, D. C., Ver Steeg, G. &amp; Galstyan, A. Multitask learning and benchmarking with clinical time series data. Sci. data 6, 96 (2019)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR11" id="ref-link-section-d258281533e773">11</a></sup>, eICU<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 14" title="Sheikhalishahi, S., Balaraman, V. &amp; Osmani, V. Benchmarking machine learning models on multi-centre eICU critical care dataset. PloS ONE 15, e0235424 (2020)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR14" id="ref-link-section-d258281533e777">14</a></sup>, and SEER breast and LCS studies<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Hegselmann, S., Gruelich, L., Varghese, J. &amp; Dugas, M. Reproducible survival prediction with SEER cancer data. Proceedings of the Machine Learning for Healthcare Conference, vol. 85, 49–66 (PMLR, 2018)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR16" id="ref-link-section-d258281533e781">16</a></sup>, following the conventional pre-training processing (e.g., encoding, standardization). As MIMIC-III and eICU benchmark datasets contain missing values, we imputed the values that are missing using the most recent observation (within 48 h) if it exists, otherwise, a value from the normal range of corresponding vitals is mentioned in ref. <sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Harutyunyan, H., Khachatrian, H., Kale, D. C., Ver Steeg, G. &amp; Galstyan, A. Multitask learning and benchmarking with clinical time series data. Sci. data 6, 96 (2019)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR11" id="ref-link-section-d258281533e785">11</a></sup>. Masking was used to indicate whether the vital value was original or imputed. The categorical variables, including binary ones, were encoded using a one-hot vector. The numerical features, such as diastolic blood pressure and glucose level, were converted to their standardized form. After preprocessing, each time-series data point became a 76-by-48 matrix (76 computed features and 48 h). The processed dataset was used for training and testing neural network-based models such as LSTM and CW-LSTM models. For non-neural network models that cannot directly process time series, we extracted 6 statistical features (mean, min, max, standard deviation, skew, and number of measurements) from various sub-periods (first/last 10%, 25%, 50%, and full 100%). We did not encode the categorical variables, as they contain values with a meaningful scale. The missing values were replaced with mean values computed on the training set and numerical variables were standardized. In total, we obtained 714 features from each 48-h time series with 17 vitals. The continuous variables were standardized before training. After encoding, the feature vector length of the BCS and LCS datasets became 1418 and 1314, respectively.</p><h3 id="Sec5">Configurations of machine learning models</h3><p>For IHM risk prediction, we utilized the LSTM model, CW-LSTM model, transformer, LR, AdaBoost, XGBoost, and random forest (RF) models. For 5-year BCS prediction, we used MLP, AdaBoost, XGBoost, and RF models. We utilized the optimal settings of neural network models (i.e., layers, activation, hyperparameters) for each of the tasks from corresponding benchmarks<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Harutyunyan, H., Khachatrian, H., Kale, D. C., Ver Steeg, G. &amp; Galstyan, A. Multitask learning and benchmarking with clinical time series data. Sci. data 6, 96 (2019)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR11" id="ref-link-section-d258281533e797">11</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Hegselmann, S., Gruelich, L., Varghese, J. &amp; Dugas, M. Reproducible survival prediction with SEER cancer data. Proceedings of the Machine Learning for Healthcare Conference, vol. 85, 49–66 (PMLR, 2018)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR16" id="ref-link-section-d258281533e800">16</a></sup>. The LSTM model consisted of an input layer (76 dimensions), a masking layer (76 dimensions), a bidirectional LSTM layer (16 dimensions), an LSTM layer (16 dimensions), a dropout layer, and finally a dense layer (1 dimension). In total, the LSTM had 7569 trainable parameters. The CW-LSTM layer consisted of an input layer (76 dimensions), masking layer (76 dimensions), 17 channel layers (for each 17 input features), 17 bidirectional layers (connected to one of the 17 channels layers), another set of 17 bidirectional layers, a concatenation layer connecting all 17 bidirectional layers, bidirectional layer (64 dimensions), LSTM layer (36 dimensions), dropout layer (64 dimensions), and finally a dense layer (1 dimension). In total, the CW-LSTM model had 153,025 parameters. The size of CW-LSTM’s parameters was 20 times that of LSTM’s. The CW-LSTM model allows independent pre-processing of each variable before combining them. For both LSTM-based models, the optimal hyperparameters are selected using grid search<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 11" title="Harutyunyan, H., Khachatrian, H., Kale, D. C., Ver Steeg, G. &amp; Galstyan, A. Multitask learning and benchmarking with clinical time series data. Sci. data 6, 96 (2019)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR11" id="ref-link-section-d258281533e804">11</a></sup>. For example, the batch size, dropout, and time-step are set to 8, 0.3, and 1, respectively. The transformer model consisted of an input layer (76 dimensions), a masking layer (76 dimensions), a positional encoding layer (76 dimensions), 2–3 transformer encoder blocks, a global average pooling layer, a batch normalization layer, a dropout layer (0.3 or 05), a dense layer (32 or 64 units), and finally a dense layer (1 dimension). Each transformer encoder block included a multi-head attention layer with 4 heads (key dimension 76), followed by layer normalization and residual connections. The feed-forward dense layers within each encoder block contained a hidden dimension of 16. In total, the transformer model contains a total of 881,677 parameters (trainable parameters: 293,841, optimizer parameters: 587,684, and non-trainable parameters: 152), larger than the LSTM and CW-LSTM models. For hyperparameter tuning, grid search was employed to select the best hyperparameters (Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">1</a>). The LR model was from the sklearn library, utilizing the L2 regularization penalty. To prevent overfitting and to enhance the generalization capability of the model, the parameter C is 0.001. This choice of a small C value effectively controls the amount of regularization applied during training. The remaining hyperparameters were left at their default values, following the standard implementation provided by the Python Sklearn library. This model was trained with the standardized training set. The MLP model used for BCS survivability prediction consists of 2 hidden layers, where each hidden layer contains 20 neurons. The hidden layer used Relu as an activation function. Dropout rate of 0.1 after each hidden layer was used to avoid overfitting. The last layer predicted binary labels using the sigmoid activation function. The MLP model contained 28,831 trainable parameters. MLP hyperparameter is empirically selected using grid-search from a list of predefined values such as the number of hidden layers (1, 2, 3, and 4), number of nodes in each layer (20, 50, 100, and 200), and dropout (0, 0.1, 0.2, 0.3, 0.4, and 0.5)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Hegselmann, S., Gruelich, L., Varghese, J. &amp; Dugas, M. Reproducible survival prediction with SEER cancer data. Proceedings of the Machine Learning for Healthcare Conference, vol. 85, 49–66 (PMLR, 2018)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR16" id="ref-link-section-d258281533e811">16</a></sup>. The other models are implemented using Python’s Sklearn library and hyperparameters are tuned using grid search (Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">1</a>).</p><h3 id="Sec6">Model training, threshold tuning, and imbalance correction methods</h3><p>For IHM prediction, LSTM models and transformer models were trained for 100 epochs using the MIMIC-III and eICU datasets separately. For 5-year cancer survivability prediction, MLP models were trained for 25 epochs with the SEER BCS or LCS dataset with optimal hyperparameter settings mentioned<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Hegselmann, S., Gruelich, L., Varghese, J. &amp; Dugas, M. Reproducible survival prediction with SEER cancer data. Proceedings of the Machine Learning for Healthcare Conference, vol. 85, 49–66 (PMLR, 2018)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR16" id="ref-link-section-d258281533e826">16</a></sup>. Other models, including XGBoost, AdaBoost, and RF, are trained using the best hyperparameters obtained from grid search (Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">1</a>). The models were trained using binary cross-entropy loss. An epoch was selected based on the threshold-agnostic validation area under the precision-recall curve (AUPRC) and validation loss to avoid overfitting. Specifically, we first selected the top 3 epochs with the highest validation AUPRC and then selected the epoch with the minimum validation loss (Supplementary Tables <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">2</a> and <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">3</a>). We monitored the validation loss and training loss difference to prevent overfitting. In all experiments, the chosen ML model demonstrated a small loss difference (Supplementary Tables <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">2</a> and <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">3</a>).</p><p>Besides evaluating models trained on the original training sets, we also experimented with resampling and reweighting techniques and measured how well the resulting bias-corrected ML models performed in our critical zone tests. The reweighting technique has demonstrated superior performance in healthcare datasets, as evidenced by prior studies<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 21" title="Mienye, I. D. &amp; Sun, Y. Performance analysis of cost-sensitive learning methods with application to imbalanced medical data. Inform. Med. Unlocked 25, 100690 (2021)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR21" id="ref-link-section-d258281533e849">21</a></sup>. For resampling, we tested two generative resampling approaches, SMOTE (Synthetic Minority Oversampling Technique) and AdaSyn (Adaptive Synthetic Sampling). We employed Python’s Imblearn library to apply SMOTE and AdaSyn oversampling techniques, generating balanced training sets by increasing samples from the minority class (sizes shown in Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">4</a>). For reweighting, we utilized Python’s Sklearn library to compute balanced class weights based on the training sets (Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">5</a>). These methods are applied to the LSTM model for mortality prediction and to the MLP model for cancer survivability prediction.</p><p>The training, validation, and test set breakdown for MIMIC-III and eICU datasets is 70%, 15%, and 15% and 80%, 10%, and 10% for the BCS and LCS datasets. After model calibration, a threshold-tuning process is conducted on the validation set, and an optimal threshold is selected based on balanced accuracy and F1 score for the minority class. Specifically, after training, we first conducted model calibration by applying Isotonic Regression using the validation set. Model calibration mapped the predicted probabilities to actual probabilities. Then, we performed threshold tuning to determine the optimal threshold. The minority F1 score and balanced accuracy were computed on the validation set for each threshold ranging from 0.0 to 1.0 with a step size of 0.01. Subsequently, the top three thresholds yielding the highest minority F1 scores were identified, and the optimal threshold maximizing balanced accuracy across all validation samples was selected. This process was repeated for 3 independently trained models of each type, and the average threshold was calculated from these independent trials. Thresholds are shown in Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">6</a>. The tasks were executed on a machine with Ubuntu 18.04 operating system, x86-64 core-i9 architecture, 8 physical cores (16 virtual cores), and 32 GB RAM. The experimental code and models were written using Python 3.7, TensorFlow 1.15, and Keras 2.1.2. The cancer survivability prediction MLP model was trained on a machine with x86_64 Intel(R) Xeon(R) CPU 2.40 GHz (40 cores) and 125 GB RAM. The experimental code and model were written using Python 3.6, TensorFlow 2.9.0, and Keras 2.9.0.</p><h3 id="Sec7">Mapping neuron activations</h3><p>We visualized the activated neurons in a neural network model for a particular input. The Keras backend was used to capture the neuron outputs from the bidirectional layer output and LSTM layer output for the mortality risk prediction model. Sigmoid activation was applied to obtain neuron output values in the range of [0, 1]. To quantify changes in neuron activation, we defined and computed Neural Zone Activation (NZA) and average zone difference <span>\(\varDelta {NAZ}\)</span>. A zone is defined by the attribute range bounded by two values. NZA calculates the average neurons’ activations within a zone, where a zone can be a critically low, critically high, or normal range (Supplementary Equation <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM2">1</a>). <span>\(\varDelta {NAZ}\)</span> computes the average NZA difference between two zones (Supplementary Equation <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM2">2</a>), such as normal and critically high zones, indicating how much neurons react to zone changes. There is no standard value for <span>\(\varDelta {NAZ}\)</span>. A relatively higher value indicates a good response.</p><h3 id="Sec8">Statistical methods</h3><p>Model performance is reported using the average and standard deviations, which are calculated using 9 or 15 trials. The trials were performed using 3 model instances that have identical architecture and were trained on the same training set with random model parameter initialization. Each of the 3 model instances is evaluated with 3–5 test sets. The distribution shift of the synthesized test dataset from the original training sets was quantified by Wasserstein distance (WD)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 22" title="Kolouri, S., Park, S. R., Thorpe, M., Slepcev, D. &amp; Rohde, G. K. Optimal mass transport: Signal processing and machine-learning applications. IEEE signal Process. Mag. 34, 43–59 (2017)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR22" id="ref-link-section-d258281533e957">22</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 23" title="Villani, C. Topics in Optimal Transportation Vol. 58 (American Mathematical Soc., 2021)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR23" id="ref-link-section-d258281533e960">23</a></sup>. We used an implementation from the Python library called scipy.stats.wasserstein_distance. First, the WD was calculated between the same features from the whole original dataset and the synthesized test set. Then, the feature-specific WD was averaged to obtain the mean WD for quantifying the distribution shift.</p><h3 id="Sec9">Attribute-based test case generation for in-hospital mortality risk prediction</h3><p>We created new cases by increasing or decreasing one or multiple vital health parameters in the seeding records. To reduce computing complexity, we prioritized by focusing on the most influential features. Relevant medical terminologies are explained in the <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">Supplementary Notes</a>.</p><p>In the single-attribute variation, <i>w</i>e generated new test cases by varying a single attribute at a time while keeping other attributes unchanged. We then evaluated how the model reacts to these changes and its ability to recognize associated risks (e.g., hypoglycemia). Specifically, given an attribute <i>A</i>, single-attribute variation for time series involved the following operations. First, we identified <i>A</i>’s minimum and maximum values in the MIMIC-III or eICU datasets, which defined the observed range. Then, the mean and the variance of attribute <i>A</i> were computed from the entire dataset. Using the variance and the observed range, we generated a series of random values for every value from that range, one value for each of the 48 h. Then, the new test case was formed by having these generated values for attribute <i>A</i> and other attribute values directly inherited from the seed. We repeat this process for every possible attribute value from the observed range with step 1.</p><p>Multi-attribute variation generated new test cases by modifying two or more attributes, aiming to represent medical conditions that were characterized by variations in multiple related attributes. We further differentiated two scenarios: (a) a single set of medically correlated attributes driven by one underlying disease condition, e.g., high diastolic and systolic blood pressure due to hypertension, and (b) medically correlated attributes due to multiple underlying conditions, e.g., hypertension and diabetes. These test cases were used to assess the ML model’s ability to respond to the risks of multiple disease conditions in patients. One of the test sets was created by changing multiple vitals such as systolic blood pressure, diastolic blood pressure, blood glucose level, respiratory rate, heart rate, and body temperature at the same time. A test case was assigned a ground truth label using existing literature or under the guidance of medical doctors. 6 multi-attribute test cases and 12 deteriorating test cases were directly labeled by the medical doctor (Supplementary Tables <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">7</a> and <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">8</a>).</p><h3 id="Sec10">Deteriorating test case generation for MIMIC-III</h3><p>We leveraged the gradients of LSTM to guide the generation of new test cases. This method is automatic and does not require the specification of attributes to change, aiming to generate new test cases that are challenging for ML models to classify correctly. Such cases typically occur at the decision boundary of the classifier. Our method started from a healthy patient’s record (i.e., a seed with low or zero mortality risk). The seed is a time-series record far away from the classifier’s decision boundary. We incrementally adjusted the attribute values of the seed by following the steepest direction (i.e., gradient) that can maximize the loss (i.e., prediction errors of the ML model). This process explores the local hyperspace and iteratively produces new cases that are closer and closer to the ML model’s decision boundary. Computationally, given a trained ML model and a healthy patient’s time series record as the seed, we computed the derivative of the model’s loss function, i.e., gradient (Supplementary Equation <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM2">3</a>). The gradient is a vector of partial derivatives describing the direction and rate of changes of the loss function. Then, we changed the test case in the direction of increasing gradient. Our algorithm is described in the <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">Supplementary Methods</a> Section. The step size or learning rate to control the magnitude of the change was set to 0.001–0.2 in our experiment depending on the attribute (Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">9</a>). Our method focuses on generating samples; it differs from the common gradient descent process, which adjusts model weights to minimize loss. We have two ways of creating gradient-based test cases from the MIMIC-III dataset—single-attribute gradient approach and multi-attribute gradient approach. In the former, we focus on a single attribute and apply gradient ascent solely to modify that specific attribute. This approach allows one to observe the individual impact of each attribute on the mortality risk. In the latter, we simultaneously change values of multiple attributes using gradient ascent. Gradient approaches create test cases that represent deteriorating health conditions in continuous time series. Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">10</a> shows the various categories of test sets and their sizes.</p><h3 id="Sec11">Glasgow coma scale test case generation</h3><p>The Glasgow Coma Scale (GCS)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Jain, S. &amp; Iverson, L. M. Glasgow coma scale. (2018)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR24" id="ref-link-section-d258281533e1030">24</a></sup> is a neurological scale that assesses a patient’s level of consciousness. It evaluates responses in three categories: eye-opening (E), verbal response (V), and motor response (M), adding up to a score ranging from 3 to 15. A lower score indicates a more severe impairment of consciousness. Definitions of values in each category are given in Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">11</a>. A GCS score can be representative of multiple sets. For example, GCS total 10 can be the outcome of (E, V, M) = (3, 3, 4), or (4, 4, 2), etc. The GCS total test set contains all the possible combinations of (E, V, M) for each particular GCS total value. The double attribute-based GCS cases were also created by varying both attributes and keeping the other constants to healthy values.</p><h3 id="Sec12">Attribute-based test case generation for 5-year cancer prognosis</h3><p>Single-attribute variation. Similarly, we engineered cancer test cases by varying one attribute of a seed record. The attribute may be the size of the tumor (T), the number of positive lymph nodes (N), the number of examined lymph nodes (ELNs), or the grade of the cancer cell. T and N are the two most important factors for determining cancer severity or stage<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Stages of breast cancer: Understand breast cancer staging—American Cancer Society, accessed 31 October 2024 &lt;
                  https://www.cancer.org/cancer/types/breast-cancer/understanding-a-breast-cancer-diagnosis/stages-of-breast-cancer.html
                  
                &gt;." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR25" id="ref-link-section-d258281533e1045">25</a></sup>. T has 4 categories based on the size. The tumor test set was created by varying the size of 3 seeds in the surviving class, using the range (0–986 mm) from the original SEER dataset. This BCS tumor size test set contains 12,891 cases, including 18 T0 cases, 243 T1 cases, 390 T2 cases, and the rest of 12,240 T3 cases. The LCS tumor size contains 8367 cases, including 12 T0 cases, 171 T1 cases, 273 T2 cases, and 7911 T3 cases. (T4 cases cannot be created, as it is not associated with a quantitative value). The number of positive lymph nodes (N) is divided into 4 categories. The positive lymph node test case was created similarly by changing the corresponding value from the same 3 seeds using the attribute range (0–84). For BCS, we generated 7686 test cases, including 90 N0 cases, 270 N1 cases, 546 N2 cases, and 6780 N3 cases. For LCS, we generated 24,264 test cases, including 333 N0 cases, 999 N1 cases, 1998 N2 cases, and 20,934 N3 cases. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">Supplementary Notes</a> have more details of T and N category definitions.</p><p>The ELN test case was created similarly by varying the number of ELNs (range in [0, 86]) from 3 seeds and keeping other values the same as the seeds. The ELN test set contains a total of 3510 cases for BCS and 1835 cases for LCS. Although the number of ELNs is not directly related to the cancer staging, it is crucial for diagnosing cancer. Several studies proposed that there should be a standard (or a minimum) number of ELN cancer diagnoses<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Shanmugam, C. et al. Evaluation of lymph node numbers for adequate staging of Stage II and III colon cancer. J. Hematol. Oncol. 4, 1–9 (2011)." href="#ref-CR26" id="ref-link-section-d258281533e1055">26</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Yong, J., Ding, B., Dong, Y. &amp; Yang, M. Impact of examined lymph node number on lymph node status and prognosis in FIGO stage IB-IIA cervical squamous cell carcinoma: a population-based study. Front. Oncol. 12, 994105 (2022)." href="#ref-CR27" id="ref-link-section-d258281533e1055_1">27</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Choi, H. K., Law, W. L. &amp; Poon, J. T. The optimal number of lymph nodes examined in stage II colorectal cancer and its impact of on outcomes. BMC Cancer 10, 1–7 (2010)." href="#ref-CR28" id="ref-link-section-d258281533e1055_2">28</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 29" title="Wu, Q. et al. Impact of inadequate number of lymph nodes examined on survival in stage II colon cancer. Front. Oncol. 11, 736678 (2021)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR29" id="ref-link-section-d258281533e1058">29</a></sup>. The grade of the cancer cell represents the spreading and growth intensity of the cancer cell<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 25" title="Stages of breast cancer: Understand breast cancer staging—American Cancer Society, accessed 31 October 2024 &lt;
                  https://www.cancer.org/cancer/types/breast-cancer/understanding-a-breast-cancer-diagnosis/stages-of-breast-cancer.html
                  
                &gt;." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR25" id="ref-link-section-d258281533e1062">25</a></sup>. The SEER dataset contains 1–4 grades where the higher grade represents faster growth and speed and another grade 9 for undetermined (not stated/applicable). For BCS, we created test sets for each of 1–4 grades, where each set contains 24,875, created from 21,723 cases from the majority Class 1 (survival) and 3152 cases from the minority Class 0 (death). We utilized the entire validation set as the seed pool, allowing for a more comprehensive evaluation. In total, the 1–4 grade test set contains 99,500 cases (24,875 cases for each grade). To create each grade test set, we set the corresponding grade value to all data points in the validation set.</p><p>Double- and triple-attribute variations. Double-attribute variation generated new BCS test cases by changing a pair of attributes from the 3 continuous attributes, which are the size of the tumor (T), the number of positive lymph nodes (N), and the number of ELNs. The grade attribute was excluded, as it is categorical. The tumor size and positive lymph node combination test set contains 18,531 test cases. The tumor size and number of ELNs combination test set also contains 18,531 test cases. The number of ELN and positive lymph node combination test sets contain 23,400 test cases. The triple-attribute test set was created by setting three attributes simultaneously to represent serious disease conditions, e.g., tumor size to T4, number of positive lymph nodes to N3, and grade to 4. The validation set, consisting of 24,875 cases including 21,723 cases from Class 1 (survived) and 3152 from Class 0 (death), was used as seeds. While the tumor size and number of positive lymph nodes are continuous variables, we treated them as categorical by selecting a value from the T4 and N3 range respectively. As a result, the triple-attribute test set contains 21,723 cases derived from Class 1 seeds and 3152 cases derived from Class 0 seeds. Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">12</a> summarizes the various categories of test sets and their sizes. We performed double- and triple-attribute variation tests for BCS models, not on LCS models.</p><p>For labeling generated breast and lung cancer test cases, we used authoritative literature to assign labels. We labeled cases with Class 0 (indicating low survivability) if there was a strong presence of cancer (i.e., T 1–3, N 1–3, and grade 2–4). For ELNs, the previous studies using SEER datasets<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 30" title="Sun, L., Li, P., Ren, H., Liu, G. &amp; Sun, L. Quantifying the number of lymph nodes for examination in breast cancer. J. Int. Med. Res. 48, 0300060519879594 (2020)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR30" id="ref-link-section-d258281533e1075">30</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 31" title="Chi, H., Zhang, C., Wang, H. &amp; Wang, Z. The appropriate number of ELNs for lymph node negative breast cancer patients underwent MRM: a population-based study. Oncotarget 8, 65668 (2017)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR31" id="ref-link-section-d258281533e1078">31</a></sup> suggested using at least 8-9 ELNs for stage T1 diagnosis, 37 ELNs for T2 diagnosis, and 87 ELNs for T3 diagnosis. As ELN is not directly responsible for the death, that attribute was not considered during labeling.</p><h3 id="Sec13">Selection of seeds</h3><p>We used existing patient records from the original dataset as seeds (i.e., starting points) to generate synthetic test sets. We selected seeds from the IHM dataset that are real-world non-death patient cases that exhibit healthy attribute values. Seeds were chosen as follows. For attribute-based test case generation, we randomly selected seeds from MIMIC-III Class 0 (survival case) following two criteria. First, the mean (of 48 h) attribute values are within the range of ideal health conditions defined in Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">13</a>. In addition, the standard deviation of each attribute needs to be less than or equal to the mean standard deviation (Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">14</a>) of the MIMIC-III dataset. Our evaluation of attribute-based test case generation involved 5 seeds and the statistics of these 5 seeds are given in Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">15</a>. The deterioration test case generation involved another 3 seeds, which were selected randomly from Class 0 of MIMIC-III. Since the eICU dataset contains similar samples with identical features and a consistent 48-h time duration, we utilized the same test set generated from MIMIC to evaluate models trained on the eICU dataset. Additionally, the selected seed attributes fall within the healthy (ideal) range, minimizing the out-of-distribution effects on models trained on the eICU dataset. For the cancer survivability prediction task, test cases involving changing a numerical variable were generated from 3 randomly selected seeds from the surviving class. Test sets are separately generated from each of the SEER BCS and LCS datasets. Test sets involving categorical variables, such as grades test and triple-attribute test sets, were generated using all validation data points from SEER.</p><h3 id="Sec14">Reporting summary</h3><p>Further information on research design is available in the <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM4">Nature Portfolio Reporting Summary</a> linked to this article.</p></div></div></section><section data-title="Results"><div id="Sec15-section"><h2 id="Sec15">Results</h2><div id="Sec15-content"><p>For IHM prediction, we generated 177,507 new time-series test cases based on MIMIC-III to represent serious patient conditions and used them to evaluate the responsiveness of machine-learning models (Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">10</a>). 126,950 cases are generated by modifying multiple vital attribute values in 5 seed records, 42,500 cases by modifying double attributes in seed record, 7075 cases by modifying a single attribute value in a seed record, 970 cases by modifying GCS, and 12 cases by gradient ascent. Modifications to vital attributes are bounded by the minimum and maximum values of the attribute in the IHM datasets and focus on critically high and critically low ranges of the 6 vitals. We carefully use literature<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Understanding blood pressure readings—American Heart Association, accessed 31 October 2024 &lt;
                  https://www.heart.org/en/health-topics/high-blood-pressure/understanding-blood-pressure-readings
                  
                &gt;." href="#ref-CR32" id="ref-link-section-d258281533e1123">32</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Vital signs (body temperature, pulse rate, respiration rate, blood pressure)—Johns Hopkins Medicine, accessed 30 October 2024 &lt;
                  https://www.hopkinsmedicine.org/health/conditions-and-diseases/vital-signs-body-temperature-pulse-rate-respiration-rate-blood-pressure
                  
                &gt;." href="#ref-CR33" id="ref-link-section-d258281533e1123_1">33</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Vital signs (body temperature, pulse rate, respiration rate, blood pressure)—University of Rochester Medical Center, accessed 31 October 2024. 
                  https://www.urmc.rochester.edu/encyclopedia/content.aspx?ContentTypeID=85&amp;ContentID=P00866
                  
                ." href="#ref-CR34" id="ref-link-section-d258281533e1123_2">34</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Vital Signs - Cleveland Clinic, accessed 30 October 2024 &lt;
                  https://my.clevelandclinic.org/health/articles/10881-vital-signs
                  
                &gt;." href="#ref-CR35" id="ref-link-section-d258281533e1123_3">35</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 36" title="SapraA., Malik, A. &amp; Bhandari, P. Vital SIGN Assessment. In: StatPearls (Treasure Island, 2023)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR36" id="ref-link-section-d258281533e1126">36</a></sup> to identify these ranges (Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">13</a>). The test case generation also ensures the continuity of the time series. The 6 types of attributes include systolic blood pressure, diastolic blood pressure, blood glucose level, respiratory rate, heart rate, and body temperature. A seed record is a real-world patient case selected from the MIMIC-III dataset that is a non-death case whose attributes are in the typical healthy ranges<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Vital signs (body temperature, pulse rate, respiration rate, blood pressure)—Johns Hopkins Medicine, accessed 30 October 2024 &lt;
                  https://www.hopkinsmedicine.org/health/conditions-and-diseases/vital-signs-body-temperature-pulse-rate-respiration-rate-blood-pressure
                  
                &gt;." href="#ref-CR33" id="ref-link-section-d258281533e1133">33</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Vital signs (body temperature, pulse rate, respiration rate, blood pressure)—University of Rochester Medical Center, accessed 31 October 2024. 
                  https://www.urmc.rochester.edu/encyclopedia/content.aspx?ContentTypeID=85&amp;ContentID=P00866
                  
                ." href="#ref-CR34" id="ref-link-section-d258281533e1133_1">34</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Vital Signs - Cleveland Clinic, accessed 30 October 2024 &lt;
                  https://my.clevelandclinic.org/health/articles/10881-vital-signs
                  
                &gt;." href="#ref-CR35" id="ref-link-section-d258281533e1133_2">35</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 36" title="SapraA., Malik, A. &amp; Bhandari, P. Vital SIGN Assessment. In: StatPearls (Treasure Island, 2023)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR36" id="ref-link-section-d258281533e1136">36</a></sup>. The other 12 test cases are generated using a gradient-ascent approach, which modifies the seed by following the direction of the steepest increasing loss function.</p><p>Each synthetic test case is assigned a label, death (Class 1) or survival (Class 0) for IHM prediction. Labels are verified either by a medical doctor or confirmed by the literature. These labels are considered ground truth in our study. Two medical doctors reviewed 18 generated test cases (6 attribute-based cases and 12 gradient-based cases), where the test cases are time series data and the risk scores of the medical doctors’ output are quantitative, between 0 and 1. The medical experts estimated risk values are in Supplementary Tables <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">7</a> and <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">8</a>. Labels of the other 177,489 test cases are inferred based on expected ranges of vital health parameters of healthy individuals extracted from medical literature. Synthetic test cases persistently containing vital values in critical zones represent patients in sustained critical health conditions, and thus are labeled Class 1. These cases should receive a high mortality risk prediction from ML models. We define ML responsiveness as the model’s ability to react to substantial changes in input values, e.g., by increasing the mortality risk score for IHM prediction.</p><p>Based on the SEER 5-year BCS dataset, we generated 205,414 test cases to represent different patient conditions. Among them, 120,077 cases are generated by changing single attributes (including 7686 cases representing different N stages, 12,891 cases for the T stage, and 99,500 cases for grades), 60,462 cases by modifying double attributes, and 24,875 cases by changing triple attributes from the seed cases. Based on the LCS dataset, we generated three sets of single-attribute test cases totaling 31,136 cases, which include 8367 cases representing different T stages, 24,264 cases representing N stages, and 1835 cases representing ELNs (Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">12</a>). We manually assigned labels to synthesized test cases guided by the literature<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Stages of breast cancer: Understand breast cancer staging—American Cancer Society, accessed 31 October 2024 &lt;
                  https://www.cancer.org/cancer/types/breast-cancer/understanding-a-breast-cancer-diagnosis/stages-of-breast-cancer.html
                  
                &gt;." href="#ref-CR25" id="ref-link-section-d258281533e1155">25</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Shanmugam, C. et al. Evaluation of lymph node numbers for adequate staging of Stage II and III colon cancer. J. Hematol. Oncol. 4, 1–9 (2011)." href="#ref-CR26" id="ref-link-section-d258281533e1155_1">26</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Yong, J., Ding, B., Dong, Y. &amp; Yang, M. Impact of examined lymph node number on lymph node status and prognosis in FIGO stage IB-IIA cervical squamous cell carcinoma: a population-based study. Front. Oncol. 12, 994105 (2022)." href="#ref-CR27" id="ref-link-section-d258281533e1155_2">27</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Choi, H. K., Law, W. L. &amp; Poon, J. T. The optimal number of lymph nodes examined in stage II colorectal cancer and its impact of on outcomes. BMC Cancer 10, 1–7 (2010)." href="#ref-CR28" id="ref-link-section-d258281533e1155_3">28</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Wu, Q. et al. Impact of inadequate number of lymph nodes examined on survival in stage II colon cancer. Front. Oncol. 11, 736678 (2021)." href="#ref-CR29" id="ref-link-section-d258281533e1155_4">29</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Sun, L., Li, P., Ren, H., Liu, G. &amp; Sun, L. Quantifying the number of lymph nodes for examination in breast cancer. J. Int. Med. Res. 48, 0300060519879594 (2020)." href="#ref-CR30" id="ref-link-section-d258281533e1155_5">30</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 31" title="Chi, H., Zhang, C., Wang, H. &amp; Wang, Z. The appropriate number of ELNs for lymph node negative breast cancer patients underwent MRM: a population-based study. Oncotarget 8, 65668 (2017)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR31" id="ref-link-section-d258281533e1158">31</a></sup>.</p><h3 id="Sec16">ML performance under Glasgow Coma Scale (GCS) testing</h3><p>For IHM prediction, we assess MIMIC III-based LSTM, CW-LSTM, and LR models with test cases containing varying GCS scores (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig2">2</a>), including severe injury cases with GCS scores 3–8, moderate injury with 9–12, and mild or no injury with 13–15. A low GCS score indicates a poor health condition<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 24" title="Jain, S. &amp; Iverson, L. M. Glasgow coma scale. (2018)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR24" id="ref-link-section-d258281533e1172">24</a></sup> (medical meanings of each category are shown in Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">11</a>). The CW-LSTM model gives near zero mortality risk values for 15 severe injury cases, for example, E4M1V3 in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig2">2a</a>, i.e., a case with an eye response score of 4 out of 4, a motor response of 1 out of 6, and a verbal response score of 3 out of 5. For a moderate injury case E4M1V5, CW-LSTM also gives an unexpectedly low mortality risk (0.01) prediction, i.e., predicting the healthy outcome of the patient. The model’s prediction is inconsistent, as another moderate injury case E4M3V5 receives a high mortality risk of 0.58.</p><div data-test="figure" data-container-section="figure" id="figure-2" data-title="Mortality risk (MR) prediction for Glasgow Coma Scale for different combinations using three machine learning models."><figure><figcaption><b id="Fig2" data-test="figure-caption-text">Fig. 2: Mortality risk (MR) prediction for Glasgow Coma Scale for different combinations using three machine learning models.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s43856-025-00775-0/figures/2" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs43856-025-00775-0/MediaObjects/43856_2025_775_Fig2_HTML.png?as=webp"/><img aria-describedby="Fig2" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs43856-025-00775-0/MediaObjects/43856_2025_775_Fig2_HTML.png" alt="figure 2" loading="lazy" width="685" height="520"/></picture></a></div><p>MR predicted by (<b>a</b>) channel-wise LSTM model for three injury cases (E4M1V3, E4M1V5, and E4M3V5) represented by 3 bars and the X-axis, <b>b</b> LSTM model for three injury cases (E1M1V5, E1M3V5, and E2M2V5) represented by 3 bars and the X-axis, and <b>c</b> Logistic regression for injury cases for all combinations of GCS scores (GCS total 3–15) represented by the bars and the Y-axis. The error bar represents standard deviations calculated from five independent experimental trials (models). MR prediction of injury cases defined by different combinations of GCS eye and motor response scores by <b>d</b> LSTM and <b>e</b> logistic regression model. MR predicted by <b>f</b> LSTM and <b>g</b> logistic regression using injury cases defined by different combinations of GCS eye and verbal response scores. MR prediction of injury cases defined by different combinations of GCS motor and motor response scores by <b>h</b> LSTM and <b>i</b> logistic regression.</p></div></figure></div><p>Similar inaccuracies and inconsistencies are also observed for the LSTM (MIMIC III) model tested. For instance, the LSTM model mistakenly considers a severe injury case E1M1V5 to be much more likely to survive than a moderate injury case E2M2V5 (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig2">2b</a>). In contrast, the LR model consistently predicts at least 0.3 mortality risk for severe injury cases and responds well (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig2">2c</a>). For mild injury cases, the LR model consistently predicts a low mortality risk. The 3D surfaces of the LR model appear smooth and the model reacts to decreased eye and motor signals (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig2">2e</a>). In contrast, LSTM’s 3D plots are less monotonic, exhibiting bumps (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig2">2</a>). For the most severe cases (subscores being 1 or 2), LSTM’s risk predictions incorrectly drop.</p><h3 id="Sec17">ML performance under critical zone tests</h3><h4 id="Sec18">Single-attribute critical zone test results</h4><p>We evaluate the MIMIC III-based LSTM, CW-LSTM, and LR models’ ability to respond to a single deteriorating attribute while keeping other attributes stable as in the seed (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig3">3</a>). The CW-LSTM model fails to recognize bradypnea, i.e., an abnormally slow breathing rate, and gives only slightly elevated mortality risk prediction (mean mortality risk 0.05 and standard deviation 0.04) for tachypnea, i.e., rapid breathing (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig3">3a</a>), insufficient to trigger an alert. Similarly, CW-LSTM is unable to recognize most of the abnormal vitals. Its mortality risk prediction gives a negligible change to an abnormal patient’s glucose level (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig3">3c</a>) and oxygen saturation rate (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig3">3f</a>). For the other 3 attributes tested, CW-LSTM gives small partial responses to either a high critical zone or a low critical zone, but not both. For example, it is unable to recognize high body temperature anomalies and only slightly raises the mortality risk to 0.01 to 0.08 (standard deviation 0.033) for severe hypothermia below 34 °C (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig3">3b</a>), which is still much below the classification threshold (0.22). CW-LSTM’s response to abnormal diastolic and systolic blood pressure is also inadequate (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig3">3d and e</a>).</p><div data-test="figure" data-container-section="figure" id="figure-3" data-title="Mortality risk prediction for single vital-sign tests using three machine learning models (LSTM, Channel-wise LSTM, and Logistic Regression) and visualizing the neural activation map of the LSTM layer consisting of 16 neurons."><figure><figcaption><b id="Fig3" data-test="figure-caption-text">Fig. 3: Mortality risk prediction for single vital-sign tests using three machine learning models (LSTM, Channel-wise LSTM, and Logistic Regression) and visualizing the neural activation map of the LSTM layer consisting of 16 neurons.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s43856-025-00775-0/figures/3" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs43856-025-00775-0/MediaObjects/43856_2025_775_Fig3_HTML.png?as=webp"/><img aria-describedby="Fig3" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs43856-025-00775-0/MediaObjects/43856_2025_775_Fig3_HTML.png" alt="figure 3" loading="lazy" width="685" height="596"/></picture></a></div><p>LSTM, Channel-wise LSTM, and Logistic Regression (LR) predict the mortality risk (MR) of <b>a</b> respiratory rate, <b>b</b> body temperature, <b>c</b> glucose, <b>d</b> diastolic blood pressure, <b>e</b> systolic blood pressure, and <b>f</b> oxygen saturation test sets (synthesized). The mortality risk (MR) is represented by X-axis and MR above and below a red horizontal line (threshold = 0.22) indicates a high or low mortality risk zone, respectively. The shading represents the standard deviation calculated from five independent experimental trials (models). The entire range of each vital sign (except oxygen saturation) value is divided into three segments, low, normal, and high, by the blue vertical lines. The low and high values within these ranges indicate critical health conditions. Figures in the last row (<b>g</b>–<b>j</b>) represent the neural activation map. These are the neural activation values, calculated after applying the sigmoid function, when the model is fed with test cases varying a single vital, such as <b>g</b> glucose, <b>h</b> diastolic blood pressure, <b>i</b> temperature, and <b>j</b> respiratory rate.</p></div></figure></div><p>The LSTM model gives much more elevated risk prediction than CW-LSTM for tachypnea (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig3">3a</a>) and hypothermia conditions (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig3">3b</a>). Out of the 3 models tested, LSTM is the only machine-learning model that responds to both systolic hypotension and hypertension conditions, producing a U-shaped curve (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig3">3e</a>). However, LSTM consistently gives an ultra-low risk prediction for abnormal diastolic blood pressure (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig3">3d</a>). Similar to CW-LSTM, LSTM does not recognize hypoxemia, i.e., low blood oxygen level (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig3">3f</a>), bradypnea, hyperthermia, and abnormal glucose level (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig3">3c</a>), exhibiting either monotonic or near-flat risk prediction curves insensitive to abnormal vitals. Compared to the other models, LR gives a substantially higher risk prediction for hypoxemia. It also computes elevated risk scores in response to increasing hyperglycemia and diastolic hypotension conditions. For all attributes, LR is only able to recognize one end of the critical zones, but not both. Overall, LR, LSTM, and CW-LSTM correctly predict 37.7%, 37.8%, and 22.4% of the single-attribute critical zone test cases on average (Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">16</a>).</p><h3 id="Sec19">Neuron activation analysis</h3><p>We visualized neuron output from intermediate layers of the MIMIC III-based LSTM model. Neurons whose activations change with changing variable values are the responsible neurons for recognizing that variable. We found most of the LSTM neurons have low or no responses to varying glucose and diastolic blood pressure values (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig3">3i and j</a>). In contrast, neurons are more responsive to temperature and respiratory rate changes, e.g., sharp changes in all neuron activation between 34 °C to 36 °C (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig3">3h</a>) and around or above 40 bpm (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig3">3g</a>). However, neurons exhibit minimal or no changes in activation for higher temperatures or for critically low respiration rates.</p><p>To quantify changes in neuron activation, we computed NZA and average zone difference <span>\(\varDelta {NAZ}\)</span>, new metrics defined by us (Supplementary Equations <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM2">1</a> and <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM2">2</a>). NZA averages neurons’ activations within a zone, where a zone is critically low, critically high, or normal range (Supplementary Equation <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM2">1</a>). <span>\(\varDelta {NAZ}\)</span> computes the averaged NZA difference between zones (Supplementary Equation <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM2">2</a>), indicating how much neurons react to zone changes. The LSTM model shows low (0.01–0.04) <span>\(\varDelta {NAZ}\)</span> in most cases (Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">17</a>). In a few cases, e.g., temperature <span>\(\varDelta {NAZ}\)</span> (low, normal) and respiratory rate <span>\(\varDelta {NAZ}\)</span> (high, normal), the values are relatively high (0.14–0.16).</p><h3 id="Sec20">Multi-attribute critical zone test results</h3><p>We evaluated the 3 MIMIC III-based ML models under 42,500 double attribute varying test cases (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig4">4</a>), including respiratory rate and heart rate pair (first row), systolic and diastolic blood pressure pair (middle row), and glucose and diastolic blood pressure pair (third row). The CW-LSTM model does not generate high mortality risk predictions for most critical zone cases, consistent with its single-attribute test performance in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig3">3</a>. The LR model gives better performance than CW-LSTM, predicting higher risks for some critical zone combinations (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig4">4a, d, g</a>). However, its prediction is monotonic, thus, unable to recognize both high and low critical zones of an attribute pair. For example, LR fails to alert when patients have low respiratory rate and low heart rate. LSTM model exhibits prediction behaviors (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig4">4b, e, h</a>) consistent with its single attribute performances in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig3">3</a>.</p><div data-test="figure" data-container-section="figure" id="figure-4" data-title="Multi-attribute test results, including the mortality risk prediction under double-attribute variation tests and the mortality risk difference (ΔMR) between the seed and 6-attribute variation test cases."><figure><figcaption><b id="Fig4" data-test="figure-caption-text">Fig. 4: Multi-attribute test results, including the mortality risk prediction under double-attribute variation tests and the mortality risk difference (ΔMR) between the seed and 6-attribute variation test cases.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s43856-025-00775-0/figures/4" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs43856-025-00775-0/MediaObjects/43856_2025_775_Fig4_HTML.png?as=webp"/><img aria-describedby="Fig4" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs43856-025-00775-0/MediaObjects/43856_2025_775_Fig4_HTML.png" alt="figure 4" loading="lazy" width="685" height="909"/></picture></a></div><p>Risk prediction under varying respiratory rate and heart rate by <b>a</b> logistic regression, <b>b</b> LSTM model, and <b>c</b> CW-LSTM model. Risk prediction under varying systolic and diastolic blood pressure by <b>d</b> logistic regression, <b>e</b> LSTM model, and <b>f</b> CW-LSTM model. Risk prediction under varying glucose and diastolic blood pressure by <b>g</b> logistic regression, <b>h</b> LSTM model, and <b>i</b> CW-LSTM model. <b>j</b>–<b>l</b> represent ΔMR for high critical range cases and <b>m</b>–<b>o</b> represent ΔMR for low critical range cases. The test set is generated by simultaneously varying systolic blood pressure, diastolic blood pressure, blood glucose level, respiratory rate, heart rate, and body temperature and values are randomly selected from the critical zone. The graph shows the mortality risk difference (ΔMR) calculated by subtracting the predicted mortality risk of the seed (Class 0) from the predicted mortality risk of its corresponding critical case. The X-axis represents the case numbers and the Y-axis represents ΔMR. It is expected to get a positive MR difference and the negative ΔMR cases represent failed test cases.</p></div></figure></div><p>In a 6-attribute varying test setting, we evaluated the responsiveness of MIMIC III-based ML models under 6 changing vitals, where test cases have abnormal systolic and diastolic blood pressures, blood glucose level, respiratory rate, heart rate, and body temperature values in their respective critical zones. We recorded how much mortality risk scores changed and showed the distributions in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig4">4j–o</a>. Figure <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig4">4j–k</a> show the mortality risk difference (MR) between each high critical zone test case and its corresponding seed. Medically speaking, the risk should increase under worse health conditions. The CW-LSTM model consistently predicts high mortality risk for most cases, resulting in a positive MR for over 90% of the cases (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig4">4i, o</a>). The LR model (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig4">4j</a>) produces negativeMR for all cases, which is incorrect. The LSTM model generates positive MR for two-thirds of the 12,694 test cases.</p><p>The 3 models under low critical zone tests performed similarly (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig4">4m–o</a>), where CW-LSTM responds to multi-attribute critical conditions the most effectively and LR the least. Overall, LR, LSTM, and CW-LSTM correctly predict 6.2%, 45.7%, and 69.3% of the multi-attribute critical zone test cases on average (Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">16</a>), respectively.</p><h3 id="Sec21">Results on test cases with deteriorating conditions</h3><p>For IHM prediction (using the MIMIC III dataset), we used a gradient ascent method to generate 12 time-series test cases with deteriorating health conditions. 9 of the 12 test cases contain one vital that worsens during the 48 h and is in the critical zone during the last 24 to 48 h, including 3 cases of decreasing systolic blood pressure (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig5">5a</a>), 3 cases of increasing respiratory rate cases (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig5">5b</a>), and 3 cases of decreasing body temperature (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig5">5c</a>). The other 3 test cases have multiple (3) worsening vital signs, with vitals being in critical zones during the last hours (ranging from 30 to 48 h). All 12 test cases should receive a high mortality risk prediction, i.e., Class 1. We confirmed these labels with two medical doctors who manually reviewed the time series data.</p><div data-test="figure" data-container-section="figure" id="figure-5" data-title="Gradient-generated deteriorating test cases and machine learning models’ mortality risk predictions by LR, CW-LSTM, and LSTM models."><figure><figcaption><b id="Fig5" data-test="figure-caption-text">Fig. 5: Gradient-generated deteriorating test cases and machine learning models’ mortality risk predictions by LR, CW-LSTM, and LSTM models.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s43856-025-00775-0/figures/5" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs43856-025-00775-0/MediaObjects/43856_2025_775_Fig5_HTML.png?as=webp"/><img aria-describedby="Fig5" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs43856-025-00775-0/MediaObjects/43856_2025_775_Fig5_HTML.png" alt="figure 5" loading="lazy" width="685" height="552"/></picture></a></div><p><b>a</b>–<b>c</b> show the average time series of the generated abnormal test cases (in red area curves) and the normal seed cases used (in blue area curves) for each of the 3 attributes. <b>d</b> Models’ predicted average mortality risks for each deteriorating attribute. The standard deviation is indicated by the error bar and the number of detected cases out of 3 is shown in red.</p></div></figure></div><p>Average mortality risks predicted by ML models on the 9 single-attribute deteriorating test cases are in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig5">5d</a>. Out of the 9 single-attribute deteriorating test cases, LR only detects 2 (22%) respiratory rate cases (average risk 0.38) and fails to detect the other 7. CW-LSTM (MIMIC III) detects 4 (44%) out of the 9 deteriorating test cases, including 2 systolic BP cases (average risk 0.32) and 2 respiratory rate cases (average risk 0.39). However, it is unable to detect deteriorating temperature cases. LSTM reports 5 (56%) out of the 9 deteriorating test cases, including 2 systolic BP cases (average risk 0.22), 2 temperature cases (average risk 0.23), and 1 respiratory rate case (risk 0.22). Collectively, the models detect 41% out of single-attribute deteriorating test cases.</p><p>Multi-attribute test cases have 3 deteriorating vitals, including oxygen saturation, temperature, and diastolic blood pressure. The LSTM (MIMIC III) model detects all 3 cases (average risk 0.23), whereas CW-LSTM fails to generate any alerts. LR (MIMIC III) issues alert for 2 out of 3 cases (average risk 0.56). Collectively, the 3 models detect 56% out of the multi-attribute deteriorating test cases. Overall, the models’ average accuracy under all deteriorating test cases is 44%.</p><h3 id="Sec22">5-year cancer survivability results</h3><p>We found similar deficiencies in the ML model, in terms of the model’s ability to respond to test cases representing serious cancer conditions.</p><h3 id="Sec23">Single-attribute test results</h3><p>We evaluated the responsiveness of MLP models trained on the BCS dataset to a single deteriorating attribute (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig6">6</a> and Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">18</a>) while keeping other attributes the same as the seed. The BCS-MLP model shows some responsiveness with varying tumor size (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig6">6a</a>), however, remains above the survivability threshold (0.71) in all cases. As a result, the model fails to trigger an alert for tumor sizes representing critical stage T1 (tumor size less than 20 mm) to T3 (tumor size larger than 50 mm). On the other hand, the model triggers alerts for 74.4% of the 6,780 N3 stage (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig6">6b</a>). It fails to generate any alert for 270 N1 and 546 N2 stage cases. The BCS-MLP model accurately generates alerts for 66.4% of critical cases (N1-N3). It decreases the survivability for lower numbers of ELNs, however, still fails to trigger any alerts (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig6">6c</a>). Each of the grade test sets (1–4) is generated from 21,723 surviving patient seeds from the original dataset and the results are in Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig6">6g</a>. Out of these test cases, the BCS-MLP model generates insufficient numbers of alerts, only for 4.6% of the grade 2 cases (slower-growing cancer and less likely to spread), 7.4% of the grade 3 cases (growing cancer), and 6.7% of the grade 4 cases (faster-growing cancer and likely to spread). For tests generated from 3152 death events, the model generates more alerts, 57.9% of the grade 2 cases, 65.8% of the grade 3 cases, and 63.9% of the grade 4 cases. The model did not generate any alerts for 97% and 48.7% of grade 1 test cases generated from seeds of survived and death events, respectively. The LCS-MLP model shows higher responsiveness with variations in tumor size (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig7">7j</a>), generating alerts in 80.1% of the test cases (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">S3</a>). It also responds well to varying positive lymph node numbers (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig7">7k</a>) with alerts generated in 92.9% of the cases. However, BCS and LCS models do not react to the increasing number of lymph nodes examined (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig7">7i, l</a>).</p><div data-test="figure" data-container-section="figure" id="figure-6" data-title="Predicted 5-year breast cancer survivability results of a multi-layer perceptron (MLP) model on test cases."><figure><figcaption><b id="Fig6" data-test="figure-caption-text">Fig. 6: Predicted 5-year breast cancer survivability results of a multi-layer perceptron (MLP) model on test cases.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s43856-025-00775-0/figures/6" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs43856-025-00775-0/MediaObjects/43856_2025_775_Fig6_HTML.png?as=webp"/><img aria-describedby="Fig6" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs43856-025-00775-0/MediaObjects/43856_2025_775_Fig6_HTML.png" alt="figure 6" loading="lazy" width="685" height="579"/></picture></a></div><p>Four major breast cancer screen attributes are involved, including CS tumor size, number of positive lymph nodes, number of lymph nodes examined, and grade. <b>a</b>–<b>c</b>, <b>g</b> Predicted survivability results on single-attribute varying test cases. The blue shaded area of <b>a</b>–<b>c</b> represents the standard deviation calculated from 3 independent experimental trials (models). <b>d</b>–<b>f</b> Predicted survivability results on double-attribute varying test cases. <b>h</b> Predicted survivability results on triple-attribute varying test cases involving CS tumor size, number of positive lymph nodes, and grade. In the boxplots (<b>g</b>) and (<b>h</b>) the horizontal line within the box represents the median value, while the box itself encompasses the interquartile range (IQR), containing the middle 50% of the data. The whiskers extend to the values within 1.5 times the IQR from the box (upper and lower quartiles). The green triangle point on the box represents the mean of the distribution. The points on boxplots (<b>g</b>) and (<b>h</b>) represent 21,723 from class 0 (C0) and 3152 samples from class 1 (C1).</p></div></figure></div><div data-test="figure" data-container-section="figure" id="figure-7" data-title="Performance comparison between the original machine learning models and the resampled (SMOTE or AdaSyn) or reweighted models under single-attribute varying tests."><figure><figcaption><b id="Fig7" data-test="figure-caption-text">Fig. 7: Performance comparison between the original machine learning models and the resampled (SMOTE or AdaSyn) or reweighted models under single-attribute varying tests.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s43856-025-00775-0/figures/7" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs43856-025-00775-0/MediaObjects/43856_2025_775_Fig7_HTML.png?as=webp"/><img aria-describedby="Fig7" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs43856-025-00775-0/MediaObjects/43856_2025_775_Fig7_HTML.png" alt="figure 7" loading="lazy" width="685" height="725"/></picture></a></div><p><b>a</b>–<b>c</b> and <b>d</b>–<b>f</b> Mortality risk prediction results by the original LSTM model and the resampled or reweighted LSTM models under MIMIC-III and eICU test cases for respiratory rate, temperature, and systolic blood pressure, respectively. <b>g</b>–<b>i</b> and <b>j</b>–<b>l</b> 5-year cancer survivability prediction results by the original MLP model and the resampled or reweighted MLP models under SEER BCS and LCS test cases for CS tumor size, the number of positive lymph nodes, and the number of lymph nodes examined, respectively. Horizontal dashed lines represent model-specific thresholds. The shading represents the standard deviation calculated from 3 independent experimental trials (models).</p></div></figure></div><p>Tree-based ensemble methods, including AdaBoost, Random Forest, and XGBoost, produced somewhat similar results across all four datasets (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">S4</a>). The RF model demonstrates good responsiveness for most attributes in both MIMIC III and eICU datasets. However, it does not respond to critically high respiratory rates. XGBoost and AdaBoost have little reaction to attribute changes. In cancer survivability tasks, none of the models responds to worsening patient conditions, except AdaBoost for LCS-positive lymph nodes.</p><h3 id="Sec24">Double-attribute test results</h3><p>The BCS-MLP model was tested under 60,462 double attribute varying test cases, including (a) tumor size (T) and positive lymph node (N) combination test (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig6">6d</a>), (b) number of ENL and positive lymph node (N) combination test (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig6">6e</a>), and (c) tumor size (T) and number of ELN combination test (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig6">6f</a>). The predicted survivability decreases with an increasing number of positive lymph nodes. However, collaborative staging (CS) tumor size or number of ELN does not substantially decrease the predicted survivability. The MLP model accurately predicts 93% of T-N cases, 19.6% of N-ENL cases, and 0% of T-ENL cases (Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">18</a>). In a 3-attribute varying test, the BCS-MLP model is evaluated using cases with T4 tumor size, N3 number of positive lymph nodes, and grade 4 condition at the same time (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig6">6h</a>). The BCS-MLP accurately predicts 90% of cases generated from surviving seeds (Class 1) and 98.9% of cases generated from death event seeds (Class 0).</p><h3 id="Sec25">Comparison of Wasserstein distances (WD)</h3><p>We computed the Wasserstein distance between the original dataset and the generated test cases. Wasserstein distance captures the probability distribution shift given a metric space<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 22" title="Kolouri, S., Park, S. R., Thorpe, M., Slepcev, D. &amp; Rohde, G. K. Optimal mass transport: Signal processing and machine-learning applications. IEEE signal Process. Mag. 34, 43–59 (2017)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR22" id="ref-link-section-d258281533e1863">22</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 23" title="Villani, C. Topics in Optimal Transportation Vol. 58 (American Mathematical Soc., 2021)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR23" id="ref-link-section-d258281533e1866">23</a></sup>. For IHM prediction, the Wasserstein distance between the original MIMIC-III training set and the synthesized multi-attribute tests is 33.4. This value is much larger than the Wasserstein distance (12.4) between the training data and test data split within the original MIMIC-III. In comparison, for BCS prediction, the distribution shift of the generated triple-attribute-based test cases from the original SEER dataset is smaller, with the Wasserstein distance being 9.8. The Wasserstein distance between the original SEER training set and the test set is 2.1 (Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">19</a>).</p><h3 id="Sec26">Impacts of resampling and reweighting methods</h3><p>We trained and tested new ML models to assess the impact of resampling and reweighting methods on models’ responsiveness. SMOTE and AdaSyn oversampling methods are used to enrich the minority prediction class. For MIMIC-III mortality prediction, resampled LSTM models are tested with our single-attribute critical zone test cases. Overall, the new models remain to have low responsiveness to high-risk patient conditions (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig7">7a–c</a>). Similar to the original models, models with resampling are still unable to recognize critical patient conditions. For example, LSTM with SMOTE consistently assigns low mortality risk scores to patients with critically high vitals (e.g., respiratory rate, temperature, systolic blood pressure). LSTM with AdaSyn is better at responding to elevated systolic blood pressures than the original model, however, it performs poorly in other tests. Tests with the eICU dataset give a similar or worse performance (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig7">7d–f</a>). For BCS and LCS prediction, new MLP models trained with SMOTE or AdaSyn oversampling methods exhibit similar trends as the original MLP model (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig7">7g–l</a>). The new models fail to recognize many critical cancerous conditions. In addition, for LCS prediction, SMOTE and AdaSyn methods make the LCS-MLP model less sensitive to increasing CS tumor size (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig7">7j</a>).</p><p>We also applied the reweighting approach to training. Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">5</a> shows the cost parameters used. For mortality prediction, LSTM with reweighting gives comparable performance to the original model (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig7">7a–f</a>), except in one testing scenario. For eICU critically low systolic BP tests, reweighted LSTM generates elevated risk scores and is slightly better at responding to abnormal patient conditions. However, reweighted LSTM performs worse for similar MIMIC-III test cases (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig7">7c</a>). For cancer survivability prediction, reweighting does not impact MLP’s performance in most testing scenarios (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig7">7g–l</a>). For BCS test cases, the reweighted MLP model has slightly better responses to the increasing number of positive lymph nodes than the original MLP, however, it performs worse than the original MLP in terms of recognizing larger tumor sizes.</p><h3 id="Sec27">Responsiveness results of transformer models</h3><p>The transformer models exhibit more responsiveness than LSTM in mortality prediction. They show elevated response in critically high zones for respiratory rate and systolic blood pressure, as well as in the critically low zone for temperature (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig8">8</a>). This trend is observed for the single-attribute test cases of both MIMIC-III and eICU datasets. In addition, transformer models recognize both critical zones of systolic blood pressure, yielding a desired U-shaped response curve (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig8">8e, h</a>). However, the transformer models fail to recognize critically low respiratory rates and critically high temperatures and exhibit low responsiveness to critically low systolic blood pressure. It also has delayed response to abnormally high respiratory rates. The transformer model’s risk prediction fluctuates significantly for eICU test cases.</p><div data-test="figure" data-container-section="figure" id="figure-8" data-title="Performance and responsiveness of the transformer model compared with LSTM."><figure><figcaption><b id="Fig8" data-test="figure-caption-text">Fig. 8: Performance and responsiveness of the transformer model compared with LSTM.</b></figcaption><div><div><a data-test="img-link" data-track="click" data-track-label="image" data-track-action="view figure" href="https://www.nature.com/articles/s43856-025-00775-0/figures/8" rel="nofollow"><picture><source type="image/webp" srcset="//media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs43856-025-00775-0/MediaObjects/43856_2025_775_Fig8_HTML.png?as=webp"/><img aria-describedby="Fig8" src="https://media.springernature.com/lw685/springer-static/image/art%3A10.1038%2Fs43856-025-00775-0/MediaObjects/43856_2025_775_Fig8_HTML.png" alt="figure 8" loading="lazy" width="685" height="611"/></picture></a></div><p>Figures (<b>a</b>) and (<b>b</b>) show the various Class 1 (death) and Class 0 (survival) performance of the transformer model trained and tested on the original MIMIC-III and eICU datasets, respectively, with error bars indicating the standard deviation from three experimental trials. The dashed line represents the LSTM model’s performance. Figure (<b>c</b>–<b>e</b>) shows the predicted mortality risk by the transformer model for respiratory rate, temperature, and systolic blood pressure on MIMIC-III single-attribute test cases, while (<b>f</b>–<b>h</b>) shows the same for eICU test cases. Horizontal dashed lines denote model-specific thresholds for mortality risk prediction. Rec_C1, Pre_C1, F1_C1, AU_PRC_C1, Rec_C0, Pre_C0, F1_C0, AU_PRC_C0, Accuracy, Bal_Acc, and AUROC stand for Recall Class 1, Precision Class 1, F1 score Class 1, Area Under the Precision-Recall Curve Class 1, Recall Class 0, Precision Class 0, F1 score Class 0, Area Under the Precision-Recall Curve Class 0, Accuracy, Balanced Accuracy, and Area under the Receiver Operating Curve, respectively. The shading represents the standard deviation calculated from 3 independent experimental trials (models).</p></div></figure></div></div></div></section><section data-title="Discussion"><div id="Sec28-section"><h2 id="Sec28">Discussion</h2><div id="Sec28-content"><p>Our findings highlight the importance of measuring how clinical ML models respond to serious patient conditions. Our results show that most ML models tested are unable to adequately respond to patients who are seriously ill, even when multiple vital signs are extremely abnormal. For time-sensitive IHM prediction, the lack of response to disease conditions is particularly troublesome. ML responsiveness is somewhat related to feature importance in some cases, e.g., the low responsiveness of LSTM to oxygen saturation tests (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig3">3f</a> and Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">16</a>) is consistent with that feature’s low (15<sup>th</sup>) ranking (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">S5</a>). However, for high-ranking features such as glucose and temperature, ML responsiveness to them is still inadequate. This poor responsiveness is also observed in the lack of responses in neural activation values (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig3">3</a> and Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">17</a>) to important vital changes, such as extremely low respiratory rate or high body temperature.</p><p>New ML responsiveness metrics, especially for the healthcare domain, are urgently needed. ML responsiveness is a new problem. It differs from the well-studied ML robustness<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 37" title="Mirman, M., Gehr, T. &amp; Vechev, M. Differentiable abstract interpretation for provably robust neural networks. Proceedings of the International Conference on Machine Learning, vol. 80, 3578–3586 (PMLR, 2018)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR37" id="ref-link-section-d258281533e1991">37</a></sup>. ML robustness aims to ensure model stability and the ability to resist sample perturbations so that small (maliciously injected) noises to samples cannot change the prediction results. Lipschitzness, a common ML robustness metric, measures the model’s resilience to noisy data and perturbations<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 38" title="Qin, Y. et al. Stolen Risks of Models with Security Properties. Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security 756–770 (Association for Computing Machinery, 2023)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR38" id="ref-link-section-d258281533e1995">38</a></sup>. However, for healthcare applications, optimizing Lipschitzness may lead to models being even more insensitive to changes in patient conditions, as adherence to Lipschitz continuity may hinder the model’s ability to capture crucial input variations. In image and natural language domains, a common testing approach is adversarial attacks<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Huang, L., Joseph, A. D., Nelson, B., Rubinstein, B. I. &amp; Tygar, J. D. Adversarial machine learning. Proceedings of the 4th ACM Workshop on Security and Artificial Intelligence 43–58 (Association for Computing Machinery, 2011)." href="#ref-CR39" id="ref-link-section-d258281533e1999">39</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Tygar, J. Adversarial machine learning. IEEE Internet Comput. 15, 4–6 (2011)." href="#ref-CR40" id="ref-link-section-d258281533e1999_1">40</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Finlayson, S. G., Chung, H. W., Kohane, I. S. &amp; Beam, A. L. Adversarial attacks against medical deep learning systems. arXiv preprint arXiv:1804.05296 (2018)." href="#ref-CR41" id="ref-link-section-d258281533e1999_2">41</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 42" title="Newaz, A. I., Haque, N. I., Sikder, A. K., Rahman, M. A. &amp; Uluagac, A. S. in GLOBECOM 2020–2020 IEEE Global Communications Conference 1–6 (IEEE, 2020)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR42" id="ref-link-section-d258281533e2002">42</a></sup>. That testing approach involves intentionally manipulating input data to deceive the model’s predictions and does not apply to our medical settings.</p><p>Our results identified serious deficiencies in conventionally trained binary classification models in recognizing seriously abnormal medical conditions. For example, IHM prediction models fail to generate alerts for bradypnea (low respiratory rates) or hypoglycemia conditions (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig3">3</a>). Similarly, the models also consistently underestimate some of the mortality risks when given multiple abnormal vital time series in conjunction (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig4">4</a>). When given test cases representing various injury levels, neural network models (namely, LSTM and CW-LSTM) gave inconsistent risk predictions—assigning higher mortality risk (&gt;0.5) to cases of moderate injury (e.g., GCS score 12), while assigning disproportionately lower risk (&lt;0.05) to severe injuries (e.g., GCS score 7). The two neural network models exhibit insensitivity to changes in eye response (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig2">2d, f</a>). For most attributes, we found the training data’s distribution is highly centered, not sufficiently representing high or low critical zones (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">S1</a>). Death and non-death cases exhibit somewhat similar value distributions, means, and standard deviations (Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">14</a>) for individual attributes, despite the drastically different outcome. ML methods produced by supervised training approaches are unable to recognize the meanings of vitals in dangerous zones. This semantic deficiency of ML models was also reported in image recognition studies, e.g., melanoma classification overinterpreting surgical skin markings<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 7" title="Winkler, J. K. et al. Association between surgical skin markings in dermoscopic images and diagnostic performance of a deep learning convolutional neural network for melanoma recognition. JAMA Dermatol. 155, 1135–1141 (2019)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR7" id="ref-link-section-d258281533e2025">7</a></sup>. We found similar kinds of semantic deficiencies in models predicting 5-year BCS. These findings indicate the importance of empirically assessing the trustworthiness of clinical ML models.</p><p>The conventional test set is limited in its distribution shift from the training data. For example, for IHM prediction, our generated multi-attribute test cases present a high Wasserstein distance (33.4) from the original MIMIC-III training data, much larger than the split test set’s Wasserstein distance (12.4). A similar distribution shift pattern is observed for the BCS model. For triple-attribute test cases, the BCS prediction model performs better (89–98% triple-attribute test accuracy) than IHM prediction models (6–69% multi-attribute test accuracy). This difference in accuracy may be partly due to the different distribution shifts in generated test data. There is a much smaller distribution shift in triple-attribute breast cancer test cases (Wasserstein distance 9.8) than in multi-vital test cases (Wasserstein distance 33.4), with respect to their original training data. The LSTM model is slightly better at recognizing multi-attribute test cases (45.7% accuracy) than single-attribute ones (37.8%) and CW-LSTM exhibits a similar pattern (69.3% vs. 22.4%, Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">16</a>). Multiple abnormal vitals likely provide more clues for the ML models to classify, whereas single isolated attribute changes appear more difficult. The poor performance of the ML models is somewhat expected because of the distribution shift between training data and our synthetic test data. Yet, these deficiencies are unacceptable from a clinical deployment perspective, as the test cases represent potential real-life medical conditions. Our work points out a fundamental limitation of pure data-driven machine-learning models, that is models purely trained by patient data do not perform well for tasks that require implicit medical knowledge (e.g., normal vital ranges).</p><p>For IHM prediction, all models have multiple deficiencies under single-attribute critical zone test cases and are unable to generate high enough risk predictions for serious patient conditions (Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig3">3</a>, <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig8">8</a>, and Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">16</a>). Out of all the dual critical zone attributes, only LSTM and transformer models exhibit U-shape risk curves for systolic blood pressure (Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig3">3e</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig8">8e</a>). The other risk curves are either monotonic or flat (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig3">3</a>). Transformer models implementing the parallel attention mechanism are known to be better at capturing the global context and dependencies in data than sequential models like LSTM. Indeed, transformers are more responsive to abnormal vitals than LSTM in single-attribute testing (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig8">8</a>). However, our results suggest advanced models alone are not sufficient, as there are still multiple unrecognized critical zones. For multiple attribute testing, LR performs the worst (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig4">4</a> and Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">16</a>), mispredicting 93.7% of test cases. CW-LSTM’s accuracy is the lowest (22.4%) in single-attribute testing, however, it gives the highest average accuracy (69.3%) for multiple-attribute testing. Brain injury-related GCS test cases (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig2">2</a>) involve simple categorical data (as opposed to numerical data). LR gives the best performance, generating appropriate and consistent risk estimates, and substantially outperforms the two neural network models (Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">16</a>). These results suggest that for categorical attributes such as GCS, a simpler model like LR may be more suitable than complex deep learning models, indicating the importance of evaluating a wide variety of ML models before clinical use. Deficiencies in ML responsiveness were also observed in the 5-year breast cancer prediction task—the MLP model gave an average of 48.9% prediction accuracy under our test case (Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">18</a>). This accuracy is much lower than the widely reported death class accuracy of 90% (standard deviation 0.45), which is based on the original test data from SEER<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 5" title="Afrose, S., Song, W., Nemeroff, C. B., Lu, C. &amp; Yao, D. Subpopulation-specific machine learning prognosis for underrepresented patients with double prioritized bias correction. Commun. Med. 2, 111 (2022)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR5" id="ref-link-section-d258281533e2077">5</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 16" title="Hegselmann, S., Gruelich, L., Varghese, J. &amp; Dugas, M. Reproducible survival prediction with SEER cancer data. Proceedings of the Machine Learning for Healthcare Conference, vol. 85, 49–66 (PMLR, 2018)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR16" id="ref-link-section-d258281533e2080">16</a></sup>.</p><p>The linear LR model tested is unsuitable for analyzing vitals due to multiple reasons. It reduces time series to statistical summaries (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">S6c</a>) and is unable to capture data dynamics. Linear LR is unable to model non-monotonic (e.g., U-shaped curve) features, as it responds monotonically to features. In multi-attribute tests, the model gives poor performance (6.2% accuracy, Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">16</a>), partly because of its many negative coefficients associated with attributes. 13 out of the 17 attributes have negative coefficients, e.g., the temperature is strongly inversely correlated with the predicted probability (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">S6a</a>), resulting in underestimated risk prediction. Gaussian Naive Bayes and KNN show weaker performance on the original test sets than the others (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">S7</a>) and, thus, are excluded from subsequent attribute tests. For completeness, model performance on the original test set was given in Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">S7</a>.</p><p>For IHM prediction, the LSTM models are slightly better at recognizing deteriorating trends (average 44%, Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig5">5</a>) than cases with steadily low or steadily high vitals in critical zones (average 36.5%, Figs. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig3">3</a> and <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig4">4</a>). When test cases contain 3 simultaneously deteriorating attributes, the models detected 56% of them on average, which is better than their performance of 41% on a single deteriorating attribute. When using LSTM gradient ascent to automatically generate multi-attribute deteriorating test cases, we found the resulting test cases all have significantly decreased oxygen saturation and body temperature values in the last 24 h. Because the gradient ascent process follows the shortest path within the loss function space of the model, these findings indicate that (i) oxygen saturation and body temperature are top LSTM features and (ii) the last 24 h (out of the entire 48-h timespan) are important in the model’s decision-making process, which is also consistent with LR feature ranking (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">S6b</a>).</p><p>The BCS multilayer perceptron model (MLP) model exhibited responsiveness to critical attributes, such as tumor size and lymph node involvement (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig6">6</a>). For example, for N3 stage (extensive lymph node involvement) test cases, the model was able to raise alerts for 74.4% of them (Supplementary Table <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">18</a>). The model also performed well (nearly 100% alerts) when all three critical features (T4 tumor size, N3 lymph node stage, and grade 4) were high. These observations suggest the MLP model’s prediction capability in extreme cases is good. However, the model does not respond to severe tumor sizes (T3 stage), generating no alerts. The consistency in predicted survivability scores is also low, as the model generated slightly more alerts for grade 3 cancer (65.8%) than grade 4 terminal cancer (63.9%). This inconsistency may be the outcome of the imbalanced dataset (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">S2</a>), as the SEER dataset contains a total of 81,749 (death 15,628 and survived 66,121) grade 3 cases, while only 3002 (death 640 and survived 2362) grade 4 cases. The number of ELNs does not directly indicate a cancerous condition, thus, the model’s lack of response to ELN is somewhat expected.</p><p>Despite overall good performance on the original test set (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">S7</a>), tree-based ensemble methods such as XGBoost, AdaBoost, and RF exhibit low responsiveness to critical zone tests (Supplementary Fig. <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM1">S4</a>). Ensemble methods perform much worse than MLP for SEER BCS and LCS settings, which is likely due to the sparsity in the one-hot encoded input space. The SEER dataset has much larger feature dimensions (56 for BCS and 47 for LCS) than the MIMIC III and eICU time-series data (17 features). Using the one-hot encoding to encode categorical features leads to an expansive number of sparse encoded representations (1423 for encoded BCS and 1315 for encoded LCS), posing challenges to tree-based models.</p><p>One clinical mitigation is to deploy a filter-then-predict workflow where domain-specific rules are first applied to identify cases with obvious disease conditions. Thus, corner-case scenarios will never reach ML models. However, designing such rule-based classifiers, especially under time-series data, is challenging and may require substantial manual efforts. A more efficient approach is out-of-distribution detection, which identifies cases that present a large distribution shift from the model’s training data. Existing solutions for detecting out-of-distribution images<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 43" title="Yang, J., Zhou, K., Li, Y. &amp; Liu, Z. Generalized out-of-distribution detection: a survey. Int. J. Comput. Vis. 132, 5635–5662 (2024)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR43" id="ref-link-section-d258281533e2141">43</a></sup> cannot be directly applied to clinical settings. For medical applications, out-of-distribution patient cases still need to be examined and handled. An overly strict detection may produce too many such out-of-distribution cases for downstream examination. Finding the right balance will facilitate clinical translation.</p><p>A promising direction is medical foundation models based on clinical large language models (LLMs)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Ong, J. C. L. et al. Artificial intelligence, ChatGPT, and other large language models for social determinants of health: current state and future directions. Cell Rep. Med. 5, 101356 (2024)." href="#ref-CR44" id="ref-link-section-d258281533e2149">44</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Yang, X. et al. A large language model for electronic health records. NPJ Digit. Med. 5, 194 (2022)." href="#ref-CR45" id="ref-link-section-d258281533e2149_1">45</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" title="Peng, C. et al. A study of generative large language model for medical research and healthcare. NPJ Digit. Med. 6, 210 (2023)." href="#ref-CR46" id="ref-link-section-d258281533e2149_2">46</a>,<a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 47" title="Editorial. How to support the transition to AI-powered healthcare. Nat. Med. 30, 609–610 (2024)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR47" id="ref-link-section-d258281533e2152">47</a></sup>. Our findings suggest that statistical machine-learning models solely trained from patient data are grossly inadequate. They are unable to capture basic clinical knowledge, e.g., patients with extremely low GCS values have a high mortality risk. LLMs are likely able to recognize common sense health conditions and serve as a filter mechanism before ML classifiers. However, it is crucial to quantitatively characterize the trustworthiness of medical LLMs before clinical adoption. Our work suggests the urgent need for innovative clinical decision-making workflows, as existing models solely trained from patient samples are extremely limited. For interpreting ML results, a human-friendly interface is also important. Conventional interpretability techniques, such as SHapley Additive exPlanations (SHAP)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 48" title="Lundberg, S. M., &amp; Lee, S. I. A unified approach to interpreting model predictions. Proceedings of the Advances in Neural Information Processing Systems 30 (Curran Associates, Inc. 2017)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR48" id="ref-link-section-d258281533e2156">48</a></sup>, Local Interpretable Model-Agnostic Explanations<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 49" title="Ribeiro, M. T., Singh, S. &amp; Guestrin, C. “Why should i trust you?” Explaining the predictions of any classifier. Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining 1135–1144 (Association for Computing Machinery, 2016)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR49" id="ref-link-section-d258281533e2160">49</a></sup>, or TRUSTEE<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 50" title="Jacobs, A. S. et al. AI/ML for network security: The emperor has no clothes. Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security 1537–1551 (Association for Computing Machinery, 2022)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR50" id="ref-link-section-d258281533e2164">50</a></sup>, were designed for ML experts, not for clinicians. Therefore, these tools cannot be directly used in clinical settings. An innovative clinical workflow needs to place generative AI as the final component to generate narrative explanations based on ML predictions and interpretability results. An interesting research direction is how to fine-tune LLMs for these specific tasks.</p><p>The boost provided by conventional resampling and reweighting methods is very limited (Fig. <a data-track="click" data-track-label="link" data-track-action="figure anchor" href="https://www.nature.com/articles/s43856-025-00775-0#Fig7">7</a>). Under some scenarios (e.g., tachypnea and increasing CS tumor size), they may perform even worse than the original models. This poor performance is expected, as these methods rely on existing minority class samples in the training set, which are limited in their ranges and variations. The root problem is that the space of all possible minority class samples is vast. Attempting to cover all or most of them through training data engineering (such as oversampling) is infeasible. Thus, data engineering does not appear to be a feasible direction for the ML responsiveness problem. A more promising approach is to directly encode medical semantics into the clinical decision workflow as discussed above.</p><p>Our work provides the first look into ML responsiveness. Comprehensive measurement studies in other medical settings are needed. Our gradient ascent testing methodology can be extended to other health conditions (e.g., rare diseases or comorbidities). Scalability is the key to testing in medicine, because of the complex high-dimensional space. Innovative methods that prioritize testing are needed to reveal the most critical blind spots in a model.</p></div></div></section>
                    
                </div><div>
                <section data-title="Data availability"><div id="data-availability-section"><h2 id="data-availability">Data availability</h2><p>The MIMIC-III, eICU, and SEER datasets used in this study are existing datasets available to researchers. They can be requested at their original sites after completing proper training. Parties interested in data access should visit the MIMIC-III website (<a href="https://mimic.physionet.org/gettingstarted/access/">https://mimic.physionet.org/gettingstarted/access/</a>), eICU website (<a href="https://eicu-crd.mit.edu/">https://eicu-crd.mit.edu/</a>) and the SEER website (<a href="https://seer.cancer.gov/data/access.html">https://seer.cancer.gov/data/access.html</a>) to submit access requests. Because our test cases are generated from these access-controlled datasets, they cannot be publicly released. However, we have released the code for reproducing all our test cases. All the source data for the main figures (as a Microsoft Excel file) is available as Supplementary Data <a data-track="click" data-track-label="link" data-track-action="supplementary material anchor" href="https://www.nature.com/articles/s43856-025-00775-0#MOESM3">1</a>.</p></div></section><section data-title="Code availability"><div id="code-availability-section"><h2 id="code-availability">Code availability</h2><div id="code-availability-content">
              
              <p>We have released all our code publicly on GitHub, which can be used to generate the test cases and reproduce our experiments. <a href="https://github.com/PiasTanmoy/TRUSTWORTHY-ML">https://github.com/PiasTanmoy/TRUSTWORTHY-ML</a> (<a href="https://doi.org/10.5281/zenodo.14254248">https://doi.org/10.5281/zenodo.14254248</a>)<sup><a data-track="click" data-track-action="reference anchor" data-track-label="link" data-test="citation-ref" aria-label="Reference 51" title="Pias, T. S. Code: low responsiveness of machine learning models to critical or deteriorating health conditions. Zendo. 
                  https://doi.org/10.5281/zenodo.14254248
                  
                 (2024)." href="https://www.nature.com/articles/s43856-025-00775-0#ref-CR51" id="ref-link-section-d258281533e2282">51</a></sup>.</p>
            </div></div></section><div id="MagazineFulltextArticleBodySuffix"><section aria-labelledby="Bib1" data-title="References"><div id="Bib1-section"><h2 id="Bib1">References</h2><div id="Bib1-content"><div data-container-section="references"><ol data-track-component="outbound reference" data-track-context="references section"><li data-counter="1."><p id="ref-CR1">Abràmoff, M. D., Lavin, P. T., Birch, M., Shah, N. &amp; Folk, J. C. Pivotal trial of an autonomous AI-based diagnostic system for detection of diabetic retinopathy in primary care offices. <i>NPJ Digit. Med.</i> <b>1</b>, 39 (2018).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s41746-018-0040-6" data-track-item_id="10.1038/s41746-018-0040-6" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41746-018-0040-6" aria-label="Article reference 1" data-doi="10.1038/s41746-018-0040-6">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31304320" aria-label="PubMed reference 1">PubMed</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6550188" aria-label="PubMed Central reference 1">PubMed Central</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 1" href="http://scholar.google.com/scholar_lookup?&amp;title=Pivotal%20trial%20of%20an%20autonomous%20AI-based%20diagnostic%20system%20for%20detection%20of%20diabetic%20retinopathy%20in%20primary%20care%20offices&amp;journal=NPJ%20Digit.%20Med.&amp;doi=10.1038%2Fs41746-018-0040-6&amp;volume=1&amp;publication_year=2018&amp;author=Abr%C3%A0moff%2CMD&amp;author=Lavin%2CPT&amp;author=Birch%2CM&amp;author=Shah%2CN&amp;author=Folk%2CJC">
                    Google Scholar</a> 
                </p></li><li data-counter="2."><p id="ref-CR2">Sennaar, K. How America’s 5 top hospitals are using machine learning today. <i>Emerj</i> <a href="https://emerj.com/ai-sector-overviews/top-5-hospitals-using-machine-learning" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://emerj.com/ai-sector-overviews/top-5-hospitals-using-machine-learning">https://emerj.com/ai-sector-overviews/top-5-hospitals-using-machine-learning</a> (2020).</p></li><li data-counter="3."><p id="ref-CR3">Sendak, M. P. et al. Real-world integration of a sepsis deep learning technology into routine clinical care: implementation study. <i>JMIR Med. Inform.</i> <b>8</b>, e15182 (2020).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.2196/15182" data-track-item_id="10.2196/15182" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.2196%2F15182" aria-label="Article reference 3" data-doi="10.2196/15182">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32673244" aria-label="PubMed reference 3">PubMed</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7391165" aria-label="PubMed Central reference 3">PubMed Central</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 3" href="http://scholar.google.com/scholar_lookup?&amp;title=Real-world%20integration%20of%20a%20sepsis%20deep%20learning%20technology%20into%20routine%20clinical%20care%3A%20implementation%20study&amp;journal=JMIR%20Med.%20Inform.&amp;doi=10.2196%2F15182&amp;volume=8&amp;publication_year=2020&amp;author=Sendak%2CMP">
                    Google Scholar</a> 
                </p></li><li data-counter="4."><p id="ref-CR4">Zaribafzadeh, H. et al. Development, deployment, and implementation of a machine learning surgical case length prediction model and prospective evaluation. <i>Ann. Surg.</i> <b>278</b>, 890–895 (2023).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=37264901" aria-label="PubMed reference 4">PubMed</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 4" href="http://scholar.google.com/scholar_lookup?&amp;title=Development%2C%20deployment%2C%20and%20implementation%20of%20a%20machine%20learning%20surgical%20case%20length%20prediction%20model%20and%20prospective%20evaluation&amp;journal=Ann.%20Surg.&amp;volume=278&amp;pages=890-895&amp;publication_year=2023&amp;author=Zaribafzadeh%2CH">
                    Google Scholar</a> 
                </p></li><li data-counter="5."><p id="ref-CR5">Afrose, S., Song, W., Nemeroff, C. B., Lu, C. &amp; Yao, D. Subpopulation-specific machine learning prognosis for underrepresented patients with double prioritized bias correction. <i>Commun. Med.</i> <b>2</b>, 111 (2022).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s43856-022-00165-w" data-track-item_id="10.1038/s43856-022-00165-w" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs43856-022-00165-w" aria-label="Article reference 5" data-doi="10.1038/s43856-022-00165-w">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=36059892" aria-label="PubMed reference 5">PubMed</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC9436942" aria-label="PubMed Central reference 5">PubMed Central</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 5" href="http://scholar.google.com/scholar_lookup?&amp;title=Subpopulation-specific%20machine%20learning%20prognosis%20for%20underrepresented%20patients%20with%20double%20prioritized%20bias%20correction&amp;journal=Commun.%20Med.&amp;doi=10.1038%2Fs43856-022-00165-w&amp;volume=2&amp;publication_year=2022&amp;author=Afrose%2CS&amp;author=Song%2CW&amp;author=Nemeroff%2CCB&amp;author=Lu%2CC&amp;author=Yao%2CD">
                    Google Scholar</a> 
                </p></li><li data-counter="6."><p id="ref-CR6">Wong, A. et al. External validation of a widely implemented proprietary sepsis prediction model in hospitalized patients. <i>JAMA Intern. Med.</i> <b>181</b>, 1065–1070 (2021).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1001/jamainternmed.2021.2626" data-track-item_id="10.1001/jamainternmed.2021.2626" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1001%2Fjamainternmed.2021.2626" aria-label="Article reference 6" data-doi="10.1001/jamainternmed.2021.2626">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=34152373" aria-label="PubMed reference 6">PubMed</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 6" href="http://scholar.google.com/scholar_lookup?&amp;title=External%20validation%20of%20a%20widely%20implemented%20proprietary%20sepsis%20prediction%20model%20in%20hospitalized%20patients&amp;journal=JAMA%20Intern.%20Med.&amp;doi=10.1001%2Fjamainternmed.2021.2626&amp;volume=181&amp;pages=1065-1070&amp;publication_year=2021&amp;author=Wong%2CA">
                    Google Scholar</a> 
                </p></li><li data-counter="7."><p id="ref-CR7">Winkler, J. K. et al. Association between surgical skin markings in dermoscopic images and diagnostic performance of a deep learning convolutional neural network for melanoma recognition. <i>JAMA Dermatol.</i> <b>155</b>, 1135–1141 (2019).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1001/jamadermatol.2019.1735" data-track-item_id="10.1001/jamadermatol.2019.1735" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1001%2Fjamadermatol.2019.1735" aria-label="Article reference 7" data-doi="10.1001/jamadermatol.2019.1735">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31411641" aria-label="PubMed reference 7">PubMed</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6694463" aria-label="PubMed Central reference 7">PubMed Central</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 7" href="http://scholar.google.com/scholar_lookup?&amp;title=Association%20between%20surgical%20skin%20markings%20in%20dermoscopic%20images%20and%20diagnostic%20performance%20of%20a%20deep%20learning%20convolutional%20neural%20network%20for%20melanoma%20recognition&amp;journal=JAMA%20Dermatol.&amp;doi=10.1001%2Fjamadermatol.2019.1735&amp;volume=155&amp;pages=1135-1141&amp;publication_year=2019&amp;author=Winkler%2CJK">
                    Google Scholar</a> 
                </p></li><li data-counter="8."><p id="ref-CR8">Liang, W. et al. Advances, challenges and opportunities in creating data for trustworthy AI. <i>Nat. Mach. Intell.</i> <b>4</b>, 669–677 (2022).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s42256-022-00516-1" data-track-item_id="10.1038/s42256-022-00516-1" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs42256-022-00516-1" aria-label="Article reference 8" data-doi="10.1038/s42256-022-00516-1">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 8" href="http://scholar.google.com/scholar_lookup?&amp;title=Advances%2C%20challenges%20and%20opportunities%20in%20creating%20data%20for%20trustworthy%20AI&amp;journal=Nat.%20Mach.%20Intell.&amp;doi=10.1038%2Fs42256-022-00516-1&amp;volume=4&amp;pages=669-677&amp;publication_year=2022&amp;author=Liang%2CW">
                    Google Scholar</a> 
                </p></li><li data-counter="9."><p id="ref-CR9">Tian, Y., Pei, K., Jana, S. &amp; Ray, B. Deeptest: Automated testing of deep-neural-network-driven autonomous cars. <i>Proceedings of the 40th International Conference on Software Engineering</i> 303–314 (Association for Computing Machinery, 2018).</p></li><li data-counter="10."><p id="ref-CR10">Pei, K., Cao, Y., Yang, J. &amp; Jana, S. Deepxplore: automated whitebox testing of deep learning systems. <i>Proceedings of the 26th Symposium on Operating Systems Principles</i> 1–18 (Association for Computing Machinery, 2017).</p></li><li data-counter="11."><p id="ref-CR11">Harutyunyan, H., Khachatrian, H., Kale, D. C., Ver Steeg, G. &amp; Galstyan, A. Multitask learning and benchmarking with clinical time series data. <i>Sci. data</i> <b>6</b>, 96 (2019).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s41597-019-0103-9" data-track-item_id="10.1038/s41597-019-0103-9" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41597-019-0103-9" aria-label="Article reference 11" data-doi="10.1038/s41597-019-0103-9">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31209213" aria-label="PubMed reference 11">PubMed</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6572845" aria-label="PubMed Central reference 11">PubMed Central</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 11" href="http://scholar.google.com/scholar_lookup?&amp;title=Multitask%20learning%20and%20benchmarking%20with%20clinical%20time%20series%20data&amp;journal=Sci.%20data&amp;doi=10.1038%2Fs41597-019-0103-9&amp;volume=6&amp;publication_year=2019&amp;author=Harutyunyan%2CH&amp;author=Khachatrian%2CH&amp;author=Kale%2CDC&amp;author=Ver%20Steeg%2CG&amp;author=Galstyan%2CA">
                    Google Scholar</a> 
                </p></li><li data-counter="12."><p id="ref-CR12">Johnson, A., Pollard, T. &amp; Mark, R. MIMIC-III clinical database (version 1.4). <i>PhysioNet</i> <b>10</b>, 2 (2016).</p><p><a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 12" href="http://scholar.google.com/scholar_lookup?&amp;title=MIMIC-III%20clinical%20database%20%28version%201.4%29&amp;journal=PhysioNet&amp;volume=10&amp;publication_year=2016&amp;author=Johnson%2CA&amp;author=Pollard%2CT&amp;author=Mark%2CR">
                    Google Scholar</a> 
                </p></li><li data-counter="13."><p id="ref-CR13">Johnson, A. E. et al. MIMIC-III, a freely accessible critical care database. <i>Sci. Data</i> <b>3</b>, 1–9 (2016).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/sdata.2016.35" data-track-item_id="10.1038/sdata.2016.35" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fsdata.2016.35" aria-label="Article reference 13" data-doi="10.1038/sdata.2016.35">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 13" href="http://scholar.google.com/scholar_lookup?&amp;title=MIMIC-III%2C%20a%20freely%20accessible%20critical%20care%20database&amp;journal=Sci.%20Data&amp;doi=10.1038%2Fsdata.2016.35&amp;volume=3&amp;pages=1-9&amp;publication_year=2016&amp;author=Johnson%2CAE">
                    Google Scholar</a> 
                </p></li><li data-counter="14."><p id="ref-CR14">Sheikhalishahi, S., Balaraman, V. &amp; Osmani, V. Benchmarking machine learning models on multi-centre eICU critical care dataset. <i>PloS ONE</i> <b>15</b>, e0235424 (2020).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1371/journal.pone.0235424" data-track-item_id="10.1371/journal.pone.0235424" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1371%2Fjournal.pone.0235424" aria-label="Article reference 14" data-doi="10.1371/journal.pone.0235424">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3cXhsVehtb%2FL" aria-label="CAS reference 14">CAS</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=32614874" aria-label="PubMed reference 14">PubMed</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC7332047" aria-label="PubMed Central reference 14">PubMed Central</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 14" href="http://scholar.google.com/scholar_lookup?&amp;title=Benchmarking%20machine%20learning%20models%20on%20multi-centre%20eICU%20critical%20care%20dataset&amp;journal=PloS%20ONE&amp;doi=10.1371%2Fjournal.pone.0235424&amp;volume=15&amp;publication_year=2020&amp;author=Sheikhalishahi%2CS&amp;author=Balaraman%2CV&amp;author=Osmani%2CV">
                    Google Scholar</a> 
                </p></li><li data-counter="15."><p id="ref-CR15">Pollard, T. J. et al. The eICU Collaborative Research Database, a freely available multi-center database for critical care research. <i>Sci. Data</i> <b>5</b>, 1–13 (2018).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/sdata.2018.178" data-track-item_id="10.1038/sdata.2018.178" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fsdata.2018.178" aria-label="Article reference 15" data-doi="10.1038/sdata.2018.178">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 15" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20eICU%20Collaborative%20Research%20Database%2C%20a%20freely%20available%20multi-center%20database%20for%20critical%20care%20research&amp;journal=Sci.%20Data&amp;doi=10.1038%2Fsdata.2018.178&amp;volume=5&amp;pages=1-13&amp;publication_year=2018&amp;author=Pollard%2CTJ">
                    Google Scholar</a> 
                </p></li><li data-counter="16."><p id="ref-CR16">Hegselmann, S., Gruelich, L., Varghese, J. &amp; Dugas, M. Reproducible survival prediction with SEER cancer data. <i>Proceedings of the Machine Learning for Healthcare Conference</i>, vol. 85, 49–66 (PMLR, 2018).</p></li><li data-counter="17."><p id="ref-CR17">Khadanga, S., Aggarwal, K., Joty, S. &amp; Srivastava, J. Using clinical notes with time series data for ICU management. <i>Proceedings of the 2019 Conference on Empirical Methods in Natural Language Processing and the 9th International Joint Conference on Natural Language Processing (EMNLP-IJCNLP)</i> 6432–6437 (Association for Computational Linguistics, 2019).</p></li><li data-counter="18."><p id="ref-CR18">Deznabi, I., Iyyer, M. &amp; Fiterau, M. Predicting in-hospital mortality by combining clinical notes with time-series data. In <i>Findings of the Association for Computational Linguistics: ACL-IJCNLP 2021</i> 4026–4031 (Association for Computational Linguistics, 2021).</p></li><li data-counter="19."><p id="ref-CR19">Zhang, H., Singh, H., Ghassemi, M. &amp; Joshi, S. Why did the model fail?”: attributing model performance changes to distribution shifts. <i>Proceedings of the 40th International Conference on Machine Learning</i>, vol. 202, 41550–41578 (PMLR, 2023).</p></li><li data-counter="20."><p id="ref-CR20">Zhou, H., Chen, Y. &amp; Lipton, Z. Evaluating model performance in medical datasets over time. <i>Proceedings of the Conference on Health, Inference, and Learning</i>, vol. 209, 498–508 (PMLR, 2023).</p></li><li data-counter="21."><p id="ref-CR21">Mienye, I. D. &amp; Sun, Y. Performance analysis of cost-sensitive learning methods with application to imbalanced medical data. <i>Inform. Med. Unlocked</i> <b>25</b>, 100690 (2021).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1016/j.imu.2021.100690" data-track-item_id="10.1016/j.imu.2021.100690" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1016%2Fj.imu.2021.100690" aria-label="Article reference 21" data-doi="10.1016/j.imu.2021.100690">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 21" href="http://scholar.google.com/scholar_lookup?&amp;title=Performance%20analysis%20of%20cost-sensitive%20learning%20methods%20with%20application%20to%20imbalanced%20medical%20data&amp;journal=Inform.%20Med.%20Unlocked&amp;doi=10.1016%2Fj.imu.2021.100690&amp;volume=25&amp;publication_year=2021&amp;author=Mienye%2CID&amp;author=Sun%2CY">
                    Google Scholar</a> 
                </p></li><li data-counter="22."><p id="ref-CR22">Kolouri, S., Park, S. R., Thorpe, M., Slepcev, D. &amp; Rohde, G. K. Optimal mass transport: Signal processing and machine-learning applications. <i>IEEE signal Process. Mag.</i> <b>34</b>, 43–59 (2017).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1109/MSP.2017.2695801" data-track-item_id="10.1109/MSP.2017.2695801" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1109%2FMSP.2017.2695801" aria-label="Article reference 22" data-doi="10.1109/MSP.2017.2695801">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29962824" aria-label="PubMed reference 22">PubMed</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC6024256" aria-label="PubMed Central reference 22">PubMed Central</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 22" href="http://scholar.google.com/scholar_lookup?&amp;title=Optimal%20mass%20transport%3A%20Signal%20processing%20and%20machine-learning%20applications&amp;journal=IEEE%20signal%20Process.%20Mag.&amp;doi=10.1109%2FMSP.2017.2695801&amp;volume=34&amp;pages=43-59&amp;publication_year=2017&amp;author=Kolouri%2CS&amp;author=Park%2CSR&amp;author=Thorpe%2CM&amp;author=Slepcev%2CD&amp;author=Rohde%2CGK">
                    Google Scholar</a> 
                </p></li><li data-counter="23."><p id="ref-CR23">Villani, C. <i>Topics in Optimal Transportation</i> Vol. 58 (American Mathematical Soc., 2021).</p></li><li data-counter="24."><p id="ref-CR24">Jain, S. &amp; Iverson, L. M. Glasgow coma scale. (2018).</p></li><li data-counter="25."><p id="ref-CR25"><i>Stages of breast cancer: Understand breast cancer staging—American Cancer Society</i>, accessed 31 October 2024 &lt;<a href="https://www.cancer.org/cancer/types/breast-cancer/understanding-a-breast-cancer-diagnosis/stages-of-breast-cancer.html" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://www.cancer.org/cancer/types/breast-cancer/understanding-a-breast-cancer-diagnosis/stages-of-breast-cancer.html">https://www.cancer.org/cancer/types/breast-cancer/understanding-a-breast-cancer-diagnosis/stages-of-breast-cancer.html</a>&gt;.</p></li><li data-counter="26."><p id="ref-CR26">Shanmugam, C. et al. Evaluation of lymph node numbers for adequate staging of Stage II and III colon cancer. <i>J. Hematol. Oncol.</i> <b>4</b>, 1–9 (2011).</p><p><a data-track="click_references" rel="noopener" data-track-label="10.1186/1756-8722-4-25" data-track-item_id="10.1186/1756-8722-4-25" data-track-value="article reference" data-track-action="article reference" href="https://link.springer.com/doi/10.1186/1756-8722-4-25" aria-label="Article reference 26" data-doi="10.1186/1756-8722-4-25">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 26" href="http://scholar.google.com/scholar_lookup?&amp;title=Evaluation%20of%20lymph%20node%20numbers%20for%20adequate%20staging%20of%20Stage%20II%20and%20III%20colon%20cancer&amp;journal=J.%20Hematol.%20Oncol.&amp;doi=10.1186%2F1756-8722-4-25&amp;volume=4&amp;pages=1-9&amp;publication_year=2011&amp;author=Shanmugam%2CC">
                    Google Scholar</a> 
                </p></li><li data-counter="27."><p id="ref-CR27">Yong, J., Ding, B., Dong, Y. &amp; Yang, M. Impact of examined lymph node number on lymph node status and prognosis in FIGO stage IB-IIA cervical squamous cell carcinoma: a population-based study. <i>Front. Oncol.</i> <b>12</b>, 994105 (2022).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.3389/fonc.2022.994105" data-track-item_id="10.3389/fonc.2022.994105" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.3389%2Ffonc.2022.994105" aria-label="Article reference 27" data-doi="10.3389/fonc.2022.994105">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=36203444" aria-label="PubMed reference 27">PubMed</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC9531155" aria-label="PubMed Central reference 27">PubMed Central</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 27" href="http://scholar.google.com/scholar_lookup?&amp;title=Impact%20of%20examined%20lymph%20node%20number%20on%20lymph%20node%20status%20and%20prognosis%20in%20FIGO%20stage%20IB-IIA%20cervical%20squamous%20cell%20carcinoma%3A%20a%20population-based%20study&amp;journal=Front.%20Oncol.&amp;doi=10.3389%2Ffonc.2022.994105&amp;volume=12&amp;publication_year=2022&amp;author=Yong%2CJ&amp;author=Ding%2CB&amp;author=Dong%2CY&amp;author=Yang%2CM">
                    Google Scholar</a> 
                </p></li><li data-counter="28."><p id="ref-CR28">Choi, H. K., Law, W. L. &amp; Poon, J. T. The optimal number of lymph nodes examined in stage II colorectal cancer and its impact of on outcomes. <i>BMC Cancer</i> <b>10</b>, 1–7 (2010).</p><p><a data-track="click_references" rel="noopener" data-track-label="10.1186/1471-2407-10-267" data-track-item_id="10.1186/1471-2407-10-267" data-track-value="article reference" data-track-action="article reference" href="https://link.springer.com/doi/10.1186/1471-2407-10-267" aria-label="Article reference 28" data-doi="10.1186/1471-2407-10-267">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 28" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20optimal%20number%20of%20lymph%20nodes%20examined%20in%20stage%20II%20colorectal%20cancer%20and%20its%20impact%20of%20on%20outcomes&amp;journal=BMC%20Cancer&amp;doi=10.1186%2F1471-2407-10-267&amp;volume=10&amp;pages=1-7&amp;publication_year=2010&amp;author=Choi%2CHK&amp;author=Law%2CWL&amp;author=Poon%2CJT">
                    Google Scholar</a> 
                </p></li><li data-counter="29."><p id="ref-CR29">Wu, Q. et al. Impact of inadequate number of lymph nodes examined on survival in stage II colon cancer. <i>Front. Oncol.</i> <b>11</b>, 736678 (2021).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.3389/fonc.2021.736678" data-track-item_id="10.3389/fonc.2021.736678" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.3389%2Ffonc.2021.736678" aria-label="Article reference 29" data-doi="10.3389/fonc.2021.736678">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=34616683" aria-label="PubMed reference 29">PubMed</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC8489731" aria-label="PubMed Central reference 29">PubMed Central</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 29" href="http://scholar.google.com/scholar_lookup?&amp;title=Impact%20of%20inadequate%20number%20of%20lymph%20nodes%20examined%20on%20survival%20in%20stage%20II%20colon%20cancer&amp;journal=Front.%20Oncol.&amp;doi=10.3389%2Ffonc.2021.736678&amp;volume=11&amp;publication_year=2021&amp;author=Wu%2CQ">
                    Google Scholar</a> 
                </p></li><li data-counter="30."><p id="ref-CR30">Sun, L., Li, P., Ren, H., Liu, G. &amp; Sun, L. Quantifying the number of lymph nodes for examination in breast cancer. <i>J. Int. Med. Res.</i> <b>48</b>, 0300060519879594 (2020).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1177/0300060519879594" data-track-item_id="10.1177/0300060519879594" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1177%2F0300060519879594" aria-label="Article reference 30" data-doi="10.1177/0300060519879594">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="cas reference" data-track-action="cas reference" href="https://www.nature.com/articles/cas-redirect/1:CAS:528:DC%2BB3cXit1GjtL3J" aria-label="CAS reference 30">CAS</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=31640445" aria-label="PubMed reference 30">PubMed</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 30" href="http://scholar.google.com/scholar_lookup?&amp;title=Quantifying%20the%20number%20of%20lymph%20nodes%20for%20examination%20in%20breast%20cancer&amp;journal=J.%20Int.%20Med.%20Res.&amp;doi=10.1177%2F0300060519879594&amp;volume=48&amp;publication_year=2020&amp;author=Sun%2CL&amp;author=Li%2CP&amp;author=Ren%2CH&amp;author=Liu%2CG&amp;author=Sun%2CL">
                    Google Scholar</a> 
                </p></li><li data-counter="31."><p id="ref-CR31">Chi, H., Zhang, C., Wang, H. &amp; Wang, Z. The appropriate number of ELNs for lymph node negative breast cancer patients underwent MRM: a population-based study. <i>Oncotarget</i> <b>8</b>, 65668 (2017).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.18632/oncotarget.20052" data-track-item_id="10.18632/oncotarget.20052" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.18632%2Foncotarget.20052" aria-label="Article reference 31" data-doi="10.18632/oncotarget.20052">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=29029462" aria-label="PubMed reference 31">PubMed</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC5630362" aria-label="PubMed Central reference 31">PubMed Central</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 31" href="http://scholar.google.com/scholar_lookup?&amp;title=The%20appropriate%20number%20of%20ELNs%20for%20lymph%20node%20negative%20breast%20cancer%20patients%20underwent%20MRM%3A%20a%20population-based%20study&amp;journal=Oncotarget&amp;doi=10.18632%2Foncotarget.20052&amp;volume=8&amp;publication_year=2017&amp;author=Chi%2CH&amp;author=Zhang%2CC&amp;author=Wang%2CH&amp;author=Wang%2CZ">
                    Google Scholar</a> 
                </p></li><li data-counter="32."><p id="ref-CR32"><i>Understanding blood pressure readings</i>—<i>American Heart Association</i>, accessed 31 October 2024 &lt;<a href="https://www.heart.org/en/health-topics/high-blood-pressure/understanding-blood-pressure-readings" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://www.heart.org/en/health-topics/high-blood-pressure/understanding-blood-pressure-readings">https://www.heart.org/en/health-topics/high-blood-pressure/understanding-blood-pressure-readings</a>&gt;.</p></li><li data-counter="33."><p id="ref-CR33"><i>Vital signs (body temperature, pulse rate, respiration rate, blood pressure)</i>—<i>Johns Hopkins Medicine</i>, accessed 30 October 2024 &lt;<a href="https://www.hopkinsmedicine.org/health/conditions-and-diseases/vital-signs-body-temperature-pulse-rate-respiration-rate-blood-pressure" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://www.hopkinsmedicine.org/health/conditions-and-diseases/vital-signs-body-temperature-pulse-rate-respiration-rate-blood-pressure">https://www.hopkinsmedicine.org/health/conditions-and-diseases/vital-signs-body-temperature-pulse-rate-respiration-rate-blood-pressure</a>&gt;.</p></li><li data-counter="34."><p id="ref-CR34"><i>Vital signs (body temperature, pulse rate, respiration rate, blood pressure)—University of Rochester Medical Center,</i> accessed 31 October 2024. <a href="https://www.urmc.rochester.edu/encyclopedia/content.aspx?ContentTypeID=85&amp;ContentID=P00866" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://www.urmc.rochester.edu/encyclopedia/content.aspx?ContentTypeID=85&amp;ContentID=P00866">https://www.urmc.rochester.edu/encyclopedia/content.aspx?ContentTypeID=85&amp;ContentID=P00866</a>.</p></li><li data-counter="35."><p id="ref-CR35"><i>Vital Signs - Cleveland Clinic</i>, accessed 30 October 2024 &lt;<a href="https://my.clevelandclinic.org/health/articles/10881-vital-signs" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="https://my.clevelandclinic.org/health/articles/10881-vital-signs">https://my.clevelandclinic.org/health/articles/10881-vital-signs</a>&gt;.</p></li><li data-counter="36."><p id="ref-CR36">SapraA., Malik, A. &amp; Bhandari, P. <i>Vital SIGN Assessment</i>. <i>In</i>: <i>StatPearls</i> (Treasure Island, 2023).</p></li><li data-counter="37."><p id="ref-CR37">Mirman, M., Gehr, T. &amp; Vechev, M. Differentiable abstract interpretation for provably robust neural networks. <i>Proceedings of the International Conference on Machine Learning</i>, vol. 80, 3578–3586 (PMLR, 2018).</p></li><li data-counter="38."><p id="ref-CR38">Qin, Y. et al. Stolen Risks of Models with Security Properties. <i>Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security</i> 756–770 (Association for Computing Machinery, 2023).</p></li><li data-counter="39."><p id="ref-CR39">Huang, L., Joseph, A. D., Nelson, B., Rubinstein, B. I. &amp; Tygar, J. D. Adversarial machine learning. <i>Proceedings of the 4th ACM Workshop on Security and Artificial Intelligence</i> 43–58 (Association for Computing Machinery, 2011).</p></li><li data-counter="40."><p id="ref-CR40">Tygar, J. Adversarial machine learning. <i>IEEE Internet Comput.</i> <b>15</b>, 4–6 (2011).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1109/MIC.2011.112" data-track-item_id="10.1109/MIC.2011.112" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1109%2FMIC.2011.112" aria-label="Article reference 40" data-doi="10.1109/MIC.2011.112">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 40" href="http://scholar.google.com/scholar_lookup?&amp;title=Adversarial%20machine%20learning&amp;journal=IEEE%20Internet%20Comput.&amp;doi=10.1109%2FMIC.2011.112&amp;volume=15&amp;pages=4-6&amp;publication_year=2011&amp;author=Tygar%2CJ">
                    Google Scholar</a> 
                </p></li><li data-counter="41."><p id="ref-CR41">Finlayson, S. G., Chung, H. W., Kohane, I. S. &amp; Beam, A. L. Adversarial attacks against medical deep learning systems. <i>arXiv preprint</i> <i>arXiv:1804.05296</i> (2018).</p></li><li data-counter="42."><p id="ref-CR42">Newaz, A. I., Haque, N. I., Sikder, A. K., Rahman, M. A. &amp; Uluagac, A. S. in <i>GLOBECOM 2020–2020</i> <i>IEEE Global Communications Conference</i> 1–6 (IEEE, 2020).</p></li><li data-counter="43."><p id="ref-CR43">Yang, J., Zhou, K., Li, Y. &amp; Liu, Z. Generalized out-of-distribution detection: a survey. <i>Int. J. Comput. Vis.</i> <b>132</b>, 5635–5662 (2024).</p></li><li data-counter="44."><p id="ref-CR44">Ong, J. C. L. et al. Artificial intelligence, ChatGPT, and other large language models for social determinants of health: current state and future directions. <i>Cell Rep. Med.</i> <b>5</b>, 101356 (2024).</p></li><li data-counter="45."><p id="ref-CR45">Yang, X. et al. A large language model for electronic health records. <i>NPJ Digit. Med.</i> <b>5</b>, 194 (2022).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s41746-022-00742-2" data-track-item_id="10.1038/s41746-022-00742-2" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41746-022-00742-2" aria-label="Article reference 45" data-doi="10.1038/s41746-022-00742-2">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=36572766" aria-label="PubMed reference 45">PubMed</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC9792464" aria-label="PubMed Central reference 45">PubMed Central</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 45" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20large%20language%20model%20for%20electronic%20health%20records&amp;journal=NPJ%20Digit.%20Med.&amp;doi=10.1038%2Fs41746-022-00742-2&amp;volume=5&amp;publication_year=2022&amp;author=Yang%2CX">
                    Google Scholar</a> 
                </p></li><li data-counter="46."><p id="ref-CR46">Peng, C. et al. A study of generative large language model for medical research and healthcare. <i>NPJ Digit. Med.</i> <b>6</b>, 210 (2023).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s41746-023-00958-w" data-track-item_id="10.1038/s41746-023-00958-w" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41746-023-00958-w" aria-label="Article reference 46" data-doi="10.1038/s41746-023-00958-w">Article</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed reference" data-track-action="pubmed reference" href="http://www.ncbi.nlm.nih.gov/entrez/query.fcgi?cmd=Retrieve&amp;db=PubMed&amp;dopt=Abstract&amp;list_uids=37973919" aria-label="PubMed reference 46">PubMed</a> 
    <a data-track="click_references" rel="nofollow noopener" data-track-label="link" data-track-item_id="link" data-track-value="pubmed central reference" data-track-action="pubmed central reference" href="http://www.ncbi.nlm.nih.gov/pmc/articles/PMC10654385" aria-label="PubMed Central reference 46">PubMed Central</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 46" href="http://scholar.google.com/scholar_lookup?&amp;title=A%20study%20of%20generative%20large%20language%20model%20for%20medical%20research%20and%20healthcare&amp;journal=NPJ%20Digit.%20Med.&amp;doi=10.1038%2Fs41746-023-00958-w&amp;volume=6&amp;publication_year=2023&amp;author=Peng%2CC">
                    Google Scholar</a> 
                </p></li><li data-counter="47."><p id="ref-CR47">Editorial. How to support the transition to AI-powered healthcare. <i>Nat. Med.</i> <b>30</b>, 609–610 (2024).</p><p><a data-track="click_references" rel="nofollow noopener" data-track-label="10.1038/s41591-024-02897-9" data-track-item_id="10.1038/s41591-024-02897-9" data-track-value="article reference" data-track-action="article reference" href="https://doi.org/10.1038%2Fs41591-024-02897-9" aria-label="Article reference 47" data-doi="10.1038/s41591-024-02897-9">Article</a> 
    <a data-track="click_references" data-track-action="google scholar reference" data-track-value="google scholar reference" data-track-label="link" data-track-item_id="link" rel="nofollow noopener" aria-label="Google Scholar reference 47" href="http://scholar.google.com/scholar_lookup?&amp;title=How%20to%20support%20the%20transition%20to%20AI-powered%20healthcare&amp;journal=Nat.%20Med.&amp;doi=10.1038%2Fs41591-024-02897-9&amp;volume=30&amp;pages=609-610&amp;publication_year=2024">
                    Google Scholar</a> 
                </p></li><li data-counter="48."><p id="ref-CR48">Lundberg, S. M., &amp; Lee, S. I. A unified approach to interpreting model predictions. <i>Proceedings of the Advances in Neural Information Processing Systems 30</i> (Curran Associates, Inc. 2017).</p></li><li data-counter="49."><p id="ref-CR49">Ribeiro, M. T., Singh, S. &amp; Guestrin, C. “Why should i trust you?” Explaining the predictions of any classifier. <i>Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining</i> 1135–1144 (Association for Computing Machinery, 2016).</p></li><li data-counter="50."><p id="ref-CR50">Jacobs, A. S. et al. AI/ML for network security: The emperor has no clothes. <i>Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security</i> 1537–1551 (Association for Computing Machinery, 2022).</p></li><li data-counter="51."><p id="ref-CR51">Pias, T. S. Code: low responsiveness of machine learning models to critical or deteriorating health conditions. <i>Zendo</i>. <a href="https://doi.org/10.5281/zenodo.14254248" data-track="click_references" data-track-action="external reference" data-track-value="external reference" data-track-label="10.5281/zenodo.14254248">https://doi.org/10.5281/zenodo.14254248</a> (2024).</p></li></ol><p><a data-track="click" data-track-action="download citation references" data-track-label="link" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/s43856-025-00775-0?format=refman&amp;flavour=references">Download references<svg width="16" height="16" focusable="false" role="img" aria-hidden="true"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-download-medium"></use></svg></a></p></div></div></div></section></div><section aria-labelledby="author-information" data-title="Author information"><div id="author-information-section"><h2 id="author-information">Author information</h2><div id="author-information-content"><h3 id="affiliations">Authors and Affiliations</h3><ol><li id="Aff1"><p>Department of Computer Science and Sanghani Center for AI and Data Analytics, Virginia Tech, Blacksburg, VA, USA</p><p>Tanmoy Sarkar Pias &amp; Danfeng Daphne Yao</p></li><li id="Aff2"><p>Computer Science and Mathematics Division, Oak Ridge National Laboratory, Oak Ridge, TN, USA</p><p>Sharmin Afrose</p></li><li id="Aff3"><p>Greenlife Medical College &amp; Hospital, Dhaka, Bangladesh</p><p>Moon Das Tuli</p></li><li id="Aff4"><p>Banner University Medical Center, Tucson, AZ, USA</p><p>Ipsita Hamid Trisha</p></li><li id="Aff5"><p>University of Arizona College of Medicine, Tucson, AZ, USA</p><p>Ipsita Hamid Trisha</p></li><li id="Aff6"><p>Department of Statistics, Virginia Tech, Blacksburg, VA, USA</p><p>Xinwei Deng</p></li><li id="Aff7"><p>Department of Psychiatry and Behavioral Sciences, University of Texas at Austin Dell Medical School, Austin, TX, USA</p><p>Charles B. Nemeroff</p></li></ol><h3 id="contributions">Contributions</h3><p>D.Y. conceived and designed the study. T.P. and D.Y. conceived the gradient-based test generation method. D.Y. and T.P. conceived the new metrics introduced. T.P. conducted the experiments and analyzed the data, including selecting seeds for test case generation and interviewing medical experts. S.A. performed the initial neuron heat map study. X.D. guided T.P. to perform the WD statistical analysis. M.T. and I.T. provided medical feedback on the mortality risks of generated test cases through Zoom interviews. D.Y. and T.P. wrote the manuscript. C.B.N. provided strategic guidance. All authors proofread the manuscript and provided feedback.</p><h3 id="corresponding-author">Corresponding author</h3><p id="corresponding-author-list">Correspondence to
                <a id="corresp-c1" href="mailto:danfeng@vt.edu">Danfeng Daphne Yao</a>.</p></div></div></section><section data-title="Ethics declarations"><div id="ethics-section"><h2 id="ethics">Ethics declarations</h2><div id="ethics-content">
              
                <h3 id="FPar2">Competing interests</h3>
                <p>C.B.N. is supported by the National Institutes of Health, the National Institute of Mental Health, and the National Institute of Alcohol Abuse and Alcoholism. Charles Nemeroff is a consultant for ANeuroTech (division Anima BV), Janssen Research and Development, BioXcel Therapeutics, Engrail Therapeutics, Clexio Biosciences LTD, EmbarkNeuro, Galen Mental Health LLC, Goodcap Pharmaceuticals, ITI Inc, LUCY Scientific Discovery, Relmada Therapeutics, Sage Therapeutics, Senseye Inc, Precisement Health, Autobahn Therapeutics Inc, EMA Wellness, Skyland Trails, Denovo Biopharma, Alvogen, Acadia Pharmaceuticals, Inc., and the Brain &amp; Behavior Research Foundation; owns the following patents: Method and devices for transdermal delivery of lithium (US 6,375,990B1), Method of assessing antidepressant drug therapy via transport inhibition of monoamine neurotransmitters by ex vivo assay (US 7,148,027B2), Compounds, Compositions, Methods of Synthesis, and Methods of Treatment (CRF Receptor Binding Ligand) (US 8,551, 996 B2); owns stock in Corcept Therapeutics Company, EMA Wellness, Precisement Health, Relmada Therapeutics, Signant Health, Galen Mental Health LLC, and Senseye Inc. The remaining authors declare no competing interests.</p>
              
            </div></div></section><section data-title="Peer review"><div id="peer-review-section"><h2 id="peer-review">Peer review</h2><div id="peer-review-content">
              
              
                <h3 id="FPar1">Peer review information</h3>
                <p><i>Communications Medicine</i> thanks Allan Tucker and the other, anonymous, reviewer(s) for their contribution to the peer review of this work.</p>
              
            </div></div></section><section data-title="Additional information"><div id="additional-information-section"><h2 id="additional-information">Additional information</h2><p><b>Publisher’s note</b> Springer Nature remains neutral with regard to jurisdictional claims in published maps and institutional affiliations.</p></div></section><section data-title="Supplementary information"><div id="Sec29-section"><h2 id="Sec29">Supplementary information</h2></div></section><section data-title="Rights and permissions"><div id="rightslink-section"><h2 id="rightslink">Rights and permissions</h2><div id="rightslink-content">
                <p><b>Open Access</b>  This article is licensed under a Creative Commons Attribution-NonCommercial-NoDerivatives 4.0 International License, which permits any non-commercial use, sharing, distribution and reproduction in any medium or format, as long as you give appropriate credit to the original author(s) and the source, provide a link to the Creative Commons licence, and indicate if you modified the licensed material. You do not have permission under this licence to share adapted material derived from this article or parts of it. The images or other third party material in this article are included in the article’s Creative Commons licence, unless indicated otherwise in a credit line to the material. If material is not included in the article’s Creative Commons licence and your intended use is not permitted by statutory regulation or exceeds the permitted use, you will need to obtain permission directly from the copyright holder. To view a copy of this licence, visit <a href="http://creativecommons.org/licenses/by-nc-nd/4.0/" rel="license">http://creativecommons.org/licenses/by-nc-nd/4.0/</a>.</p>
              <p><a data-track="click" data-track-action="view rights and permissions" data-track-label="link" href="https://s100.copyright.com/AppDispatchServlet?title=Low%20responsiveness%20of%20machine%20learning%20models%20to%20critical%20or%20deteriorating%20health%20conditions&amp;author=Tanmoy%20Sarkar%20Pias%20et%20al&amp;contentID=10.1038%2Fs43856-025-00775-0&amp;copyright=The%20Author%28s%29&amp;publication=2730-664X&amp;publicationDate=2025-03-11&amp;publisherName=SpringerNature&amp;orderBeanReset=true&amp;oa=CC%20BY-NC-ND">Reprints and permissions</a></p></div></div></section><section aria-labelledby="article-info" data-title="About this article"><div id="article-info-section"><h2 id="article-info">About this article</h2><div id="article-info-content"><div><p><a data-crossmark="10.1038/s43856-025-00775-0" target="_blank" rel="noopener" href="https://crossmark.crossref.org/dialog/?doi=10.1038/s43856-025-00775-0" data-track="click" data-track-action="Click Crossmark" data-track-label="link" data-test="crossmark"><img loading="lazy" width="57" height="81" alt="Check for updates. Verify currency and authenticity via CrossMark" src="data:image/svg+xml;base64,<svg height="81" width="57" xmlns="http://www.w3.org/2000/svg"><g fill="none" fill-rule="evenodd"><path d="m17.35 35.45 21.3-14.2v-17.03h-21.3" fill="#989898"/><path d="m38.65 35.45-21.3-14.2v-17.03h21.3" fill="#747474"/><path d="m28 .5c-12.98 0-23.5 10.52-23.5 23.5s10.52 23.5 23.5 23.5 23.5-10.52 23.5-23.5c0-6.23-2.48-12.21-6.88-16.62-4.41-4.4-10.39-6.88-16.62-6.88zm0 41.25c-9.8 0-17.75-7.95-17.75-17.75s7.95-17.75 17.75-17.75 17.75 7.95 17.75 17.75c0 4.71-1.87 9.22-5.2 12.55s-7.84 5.2-12.55 5.2z" fill="#535353"/><path d="m41 36c-5.81 6.23-15.23 7.45-22.43 2.9-7.21-4.55-10.16-13.57-7.03-21.5l-4.92-3.11c-4.95 10.7-1.19 23.42 8.78 29.71 9.97 6.3 23.07 4.22 30.6-4.86z" fill="#9c9c9c"/><path d="m.2 58.45c0-.75.11-1.42.33-2.01s.52-1.09.91-1.5c.38-.41.83-.73 1.34-.94.51-.22 1.06-.32 1.65-.32.56 0 1.06.11 1.51.35.44.23.81.5 1.1.81l-.91 1.01c-.24-.24-.49-.42-.75-.56-.27-.13-.58-.2-.93-.2-.39 0-.73.08-1.05.23-.31.16-.58.37-.81.66-.23.28-.41.63-.53 1.04-.13.41-.19.88-.19 1.39 0 1.04.23 1.86.68 2.46.45.59 1.06.88 1.84.88.41 0 .77-.07 1.07-.23s.59-.39.85-.68l.91 1c-.38.43-.8.76-1.28.99-.47.22-1 .34-1.58.34-.59 0-1.13-.1-1.64-.31-.5-.2-.94-.51-1.31-.91-.38-.4-.67-.9-.88-1.48-.22-.59-.33-1.26-.33-2.02zm8.4-5.33h1.61v2.54l-.05 1.33c.29-.27.61-.51.96-.72s.76-.31 1.24-.31c.73 0 1.27.23 1.61.71.33.47.5 1.14.5 2.02v4.31h-1.61v-4.1c0-.57-.08-.97-.25-1.21-.17-.23-.45-.35-.83-.35-.3 0-.56.08-.79.22-.23.15-.49.36-.78.64v4.8h-1.61zm7.37 6.45c0-.56.09-1.06.26-1.51.18-.45.42-.83.71-1.14.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.36c.07.62.29 1.1.65 1.44.36.33.82.5 1.38.5.29 0 .57-.04.83-.13s.51-.21.76-.37l.55 1.01c-.33.21-.69.39-1.09.53-.41.14-.83.21-1.26.21-.48 0-.92-.08-1.34-.25-.41-.16-.76-.4-1.07-.7-.31-.31-.55-.69-.72-1.13-.18-.44-.26-.95-.26-1.52zm4.6-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.07.45-.31.29-.5.73-.58 1.3zm2.5.62c0-.57.09-1.08.28-1.53.18-.44.43-.82.75-1.13s.69-.54 1.1-.71c.42-.16.85-.24 1.31-.24.45 0 .84.08 1.17.23s.61.34.85.57l-.77 1.02c-.19-.16-.38-.28-.56-.37-.19-.09-.39-.14-.61-.14-.56 0-1.01.21-1.35.63-.35.41-.52.97-.52 1.67 0 .69.17 1.24.51 1.66.34.41.78.62 1.32.62.28 0 .54-.06.78-.17.24-.12.45-.26.64-.42l.67 1.03c-.33.29-.69.51-1.08.65-.39.15-.78.23-1.18.23-.46 0-.9-.08-1.31-.24-.4-.16-.75-.39-1.05-.7s-.53-.69-.7-1.13c-.17-.45-.25-.96-.25-1.53zm6.91-6.45h1.58v6.17h.05l2.54-3.16h1.77l-2.35 2.8 2.59 4.07h-1.75l-1.77-2.98-1.08 1.23v1.75h-1.58zm13.69 1.27c-.25-.11-.5-.17-.75-.17-.58 0-.87.39-.87 1.16v.75h1.34v1.27h-1.34v5.6h-1.61v-5.6h-.92v-1.2l.92-.07v-.72c0-.35.04-.68.13-.98.08-.31.21-.57.4-.79s.42-.39.71-.51c.28-.12.63-.18 1.04-.18.24 0 .48.02.69.07.22.05.41.1.57.17zm.48 5.18c0-.57.09-1.08.27-1.53.17-.44.41-.82.72-1.13.3-.31.65-.54 1.04-.71.39-.16.8-.24 1.23-.24s.84.08 1.24.24c.4.17.74.4 1.04.71s.54.69.72 1.13c.19.45.28.96.28 1.53s-.09 1.08-.28 1.53c-.18.44-.42.82-.72 1.13s-.64.54-1.04.7-.81.24-1.24.24-.84-.08-1.23-.24-.74-.39-1.04-.7c-.31-.31-.55-.69-.72-1.13-.18-.45-.27-.96-.27-1.53zm1.65 0c0 .69.14 1.24.43 1.66.28.41.68.62 1.18.62.51 0 .9-.21 1.19-.62.29-.42.44-.97.44-1.66 0-.7-.15-1.26-.44-1.67-.29-.42-.68-.63-1.19-.63-.5 0-.9.21-1.18.63-.29.41-.43.97-.43 1.67zm6.48-3.44h1.33l.12 1.21h.05c.24-.44.54-.79.88-1.02.35-.24.7-.36 1.07-.36.32 0 .59.05.78.14l-.28 1.4-.33-.09c-.11-.01-.23-.02-.38-.02-.27 0-.56.1-.86.31s-.55.58-.77 1.1v4.2h-1.61zm-47.87 15h1.61v4.1c0 .57.08.97.25 1.2.17.24.44.35.81.35.3 0 .57-.07.8-.22.22-.15.47-.39.73-.73v-4.7h1.61v6.87h-1.32l-.12-1.01h-.04c-.3.36-.63.64-.98.86-.35.21-.76.32-1.24.32-.73 0-1.27-.24-1.61-.71-.33-.47-.5-1.14-.5-2.02zm9.46 7.43v2.16h-1.61v-9.59h1.33l.12.72h.05c.29-.24.61-.45.97-.63.35-.17.72-.26 1.1-.26.43 0 .81.08 1.15.24.33.17.61.4.84.71.24.31.41.68.53 1.11.13.42.19.91.19 1.44 0 .59-.09 1.11-.25 1.57-.16.47-.38.85-.65 1.16-.27.32-.58.56-.94.73-.35.16-.72.25-1.1.25-.3 0-.6-.07-.9-.2s-.59-.31-.87-.56zm0-2.3c.26.22.5.37.73.45.24.09.46.13.66.13.46 0 .84-.2 1.15-.6.31-.39.46-.98.46-1.77 0-.69-.12-1.22-.35-1.61-.23-.38-.61-.57-1.13-.57-.49 0-.99.26-1.52.77zm5.87-1.69c0-.56.08-1.06.25-1.51.16-.45.37-.83.65-1.14.27-.3.58-.54.93-.71s.71-.25 1.08-.25c.39 0 .73.07 1 .2.27.14.54.32.81.55l-.06-1.1v-2.49h1.61v9.88h-1.33l-.11-.74h-.06c-.25.25-.54.46-.88.64-.33.18-.69.27-1.06.27-.87 0-1.56-.32-2.07-.95s-.76-1.51-.76-2.65zm1.67-.01c0 .74.13 1.31.4 1.7.26.38.65.58 1.15.58.51 0 .99-.26 1.44-.77v-3.21c-.24-.21-.48-.36-.7-.45-.23-.08-.46-.12-.7-.12-.45 0-.82.19-1.13.59-.31.39-.46.95-.46 1.68zm6.35 1.59c0-.73.32-1.3.97-1.71.64-.4 1.67-.68 3.08-.84 0-.17-.02-.34-.07-.51-.05-.16-.12-.3-.22-.43s-.22-.22-.38-.3c-.15-.06-.34-.1-.58-.1-.34 0-.68.07-1 .2s-.63.29-.93.47l-.59-1.08c.39-.24.81-.45 1.28-.63.47-.17.99-.26 1.54-.26.86 0 1.51.25 1.93.76s.63 1.25.63 2.21v4.07h-1.32l-.12-.76h-.05c-.3.27-.63.48-.98.66s-.73.27-1.14.27c-.61 0-1.1-.19-1.48-.56-.38-.36-.57-.85-.57-1.46zm1.57-.12c0 .3.09.53.27.67.19.14.42.21.71.21.28 0 .54-.07.77-.2s.48-.31.73-.56v-1.54c-.47.06-.86.13-1.18.23-.31.09-.57.19-.76.31s-.33.25-.41.4c-.09.15-.13.31-.13.48zm6.29-3.63h-.98v-1.2l1.06-.07.2-1.88h1.34v1.88h1.75v1.27h-1.75v3.28c0 .8.32 1.2.97 1.2.12 0 .24-.01.37-.04.12-.03.24-.07.34-.11l.28 1.19c-.19.06-.4.12-.64.17-.23.05-.49.08-.76.08-.4 0-.74-.06-1.02-.18-.27-.13-.49-.3-.67-.52-.17-.21-.3-.48-.37-.78-.08-.3-.12-.64-.12-1.01zm4.36 2.17c0-.56.09-1.06.27-1.51s.41-.83.71-1.14c.29-.3.63-.54 1.01-.71.39-.17.78-.25 1.18-.25.47 0 .88.08 1.23.24.36.16.65.38.89.67s.42.63.54 1.03c.12.41.18.84.18 1.32 0 .32-.02.57-.07.76h-4.37c.08.62.29 1.1.65 1.44.36.33.82.5 1.38.5.3 0 .58-.04.84-.13.25-.09.51-.21.76-.37l.54 1.01c-.32.21-.69.39-1.09.53s-.82.21-1.26.21c-.47 0-.92-.08-1.33-.25-.41-.16-.77-.4-1.08-.7-.3-.31-.54-.69-.72-1.13-.17-.44-.26-.95-.26-1.52zm4.61-.62c0-.55-.11-.98-.34-1.28-.23-.31-.58-.47-1.06-.47-.41 0-.77.15-1.08.45-.31.29-.5.73-.57 1.3zm3.01 2.23c.31.24.61.43.92.57.3.13.63.2.98.2.38 0 .65-.08.83-.23s.27-.35.27-.6c0-.14-.05-.26-.13-.37-.08-.1-.2-.2-.34-.28-.14-.09-.29-.16-.47-.23l-.53-.22c-.23-.09-.46-.18-.69-.3-.23-.11-.44-.24-.62-.4s-.33-.35-.45-.55c-.12-.21-.18-.46-.18-.75 0-.61.23-1.1.68-1.49.44-.38 1.06-.57 1.83-.57.48 0 .91.08 1.29.25s.71.36.99.57l-.74.98c-.24-.17-.49-.32-.73-.42-.25-.11-.51-.16-.78-.16-.35 0-.6.07-.76.21-.17.15-.25.33-.25.54 0 .14.04.26.12.36s.18.18.31.26c.14.07.29.14.46.21l.54.19c.23.09.47.18.7.29s.44.24.64.4c.19.16.34.35.46.58.11.23.17.5.17.82 0 .3-.06.58-.17.83-.12.26-.29.48-.51.68-.23.19-.51.34-.84.45-.34.11-.72.17-1.15.17-.48 0-.95-.09-1.41-.27-.46-.19-.86-.41-1.2-.68z" fill="#535353"/></g></svg>"/></a></p><div><h3 id="citeas">Cite this article</h3><p>Pias, T.S., Afrose, S., Tuli, M.D. <i>et al.</i> Low responsiveness of machine learning models to critical or deteriorating health conditions.
                    <i>Commun Med</i> <b>5</b>, 62 (2025). https://doi.org/10.1038/s43856-025-00775-0</p><p><a data-test="citation-link" data-track="click" data-track-action="download article citation" data-track-label="link" data-track-external="" rel="nofollow" href="https://citation-needed.springer.com/v2/references/10.1038/s43856-025-00775-0?format=refman&amp;flavour=citation">Download citation<svg width="16" height="16" focusable="false" role="img" aria-hidden="true"><use xmlns:xlink="http://www.w3.org/1999/xlink" xlink:href="#icon-eds-i-download-medium"></use></svg></a></p><ul data-test="publication-history"><li><p>Received<span>: </span><span><time datetime="2024-06-11">11 June 2024</time></span></p></li><li><p>Accepted<span>: </span><span><time datetime="2025-02-17">17 February 2025</time></span></p></li><li><p>Published<span>: </span><span><time datetime="2025-03-11">11 March 2025</time></span></p></li><li><p><abbr title="Digital Object Identifier">DOI</abbr><span>: </span><span>https://doi.org/10.1038/s43856-025-00775-0</span></p></li></ul></div></div></div></div></section>
            </div></div>
  </body>
</html>
