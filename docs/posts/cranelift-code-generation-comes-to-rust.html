<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://lwn.net/SubscriberLink/964735/8b795f23495af1d4/">Original</a>
    <h1>Cranelift code generation comes to Rust</h1>
    
    <div id="readability-page-1" class="page"><div>
<!-- $Id: slink-trial,v 1.1 2005-11-04 21:27:01 corbet Exp $ -->
<center>
<table>
<tbody><tr><td>
<h3>Welcome to LWN.net</h3>
<p>
The following subscription-only content has been made available to you 
by an LWN subscriber.  Thousands of subscribers depend on LWN for the 
best news from the Linux and free software communities.  If you enjoy this 
article, please consider accepting the trial offer on the right.  Thank you
for visiting LWN.net!
</p></td><td>
<div>
<h3>Free trial subscription</h3>
           <p>
           Try LWN for free for 1 month: no payment
           or credit card required.  <a href="https://lwn.net/Promo/slink-trial2-3/claim">Activate
           your trial subscription now</a> and see why thousands of
           readers subscribe to LWN.net.
           
</p></div>
</td>
</tr>

</tbody></table>
</center>

<p>
<a href="https://cranelift.dev/">Cranelift</a> is an Apache-2.0-licensed
code-generation backend being developed as part
of the <a href="https://wasmtime.dev/">Wasmtime</a> runtime for
<a href="https://webassembly.org/">WebAssembly</a>.
In October 2023, the Rust project made Cranelift available as an optional
component in its nightly toolchain.
Users can now use Cranelift as the code-generation backend for debug builds of
projects written in Rust,
making it an opportune time to look at what makes Cranelift different.
Cranelift is designed to compete with existing compilers by generating
code more quickly than they can, thanks to a stripped-down design that prioritizes
only the most important optimizations.
</p>

<p>
Fast compiler times are one of the many things that users want from their
programming languages.
Compile times have been a source of
<a href="https://fasterthanli.me/articles/why-is-my-rust-build-so-slow">
complaints</a> about Rust
(and <a href="https://lwn.net/Articles/959915/">other languages that use LLVM</a>) for some time, despite
<a href="https://nnethercote.github.io/2024/03/06/how-to-speed-up-the-rust-compiler-in-march-2024.html">
continuing steady progress</a> by the Rust and LLVM projects.
Additionally, a compiler that produces code quickly enough is potentially viable
in applications where it currently makes more sense to use an interpreter.
All of these factors are cause to think that a compiler that focuses on
speed of compilation, rather than the speed of the produced code, could be
valuable.
</p>

<p>
Cranelift&#39;s first use was as the backend of Wasmtime&#39;s
just-in-time (JIT) compiler. Many languages now come equipped with
JIT compilers, which often use specialized tricks to quickly compile isolated
functions. For example, Python <a href="https://lwn.net/Articles/958350/">recently added a
copy-and-patch JIT</a> that
works by taking pre-compiled sections of code for each Python bytecode
and stitching them together in memory.
JIT compilers often use techniques, such as speculative optimizations,
that make it difficult to reuse the compiler outside its
original context, since they encode so many assumptions
about the specific language for which they were designed.
</p>

<p>
The developers of Cranelift chose to use a more generic architecture, which
means that Cranelift is usable outside of the confines of WebAssembly.
The project was
<a href="https://github.com/bytecodealliance/wasmtime/tree/main/cranelift#planned-uses">
originally designed</a> with use in Wasmtime, Rust, and Firefox&#39;s
<a href="https://spidermonkey.dev/">SpiderMonkey JavaScript interpreter</a>
in mind. The SpiderMonkey project has since decided
against using Cranelift for now, but the Cranelift project still has a design
intended for easy incorporation into other programs.
</p>

<p>
Cranelift takes in a
<a href="https://github.com/bytecodealliance/wasmtime/blob/main/cranelift/docs/ir.md">
custom intermediate representation</a> called CLIF, and directly emits
machine code for the target architecture.

Unlike many other JIT compilers, Cranelift does not generate code that relies on
being able to fall back to using an interpreter in case an assumption is
invalidated. That makes it suitable for adopting into non-WebAssembly-related
projects.
</p>

<h4>Cranelift&#39;s optimizations</h4>

<p>
Despite its focus on fast code generation, Cranelift does optimize the code it
generates in several ways.
Cranelift&#39;s optimization pipeline is based on
<a href="https://en.wikipedia.org/wiki/E-graph">equality graphs</a> (or E-graphs),
a data structure for representing
sets of equivalent intermediate representations efficiently.
In a traditional compiler, the optimizer works by taking the representation of
the program produced by parsing and then applying a series of passes to it to
produce an optimized version.
The order in which optimization passes are performed can have a large impact on
the quality of code produced, since some passes require simplifications
made by other passes in order to apply. Choosing the correct order in
which to apply optimizations is called the
<a href="https://ieeexplore.ieee.org/document/1611550">phase-ordering
problem</a>, and has been the source of a considerable amount of academic research.
</p>

<p>
In Cranelift, the part of each optimization that recognizes a simpler or faster
way to represent a particular construct is separated from the part that chooses
what representation should ultimately be used. Each optimization works by
finding a particular pattern in the internal representation, and then annotating
it as being equivalent to some simplified version. The E-graph data structure
represents this efficiently, by allowing two copies of the internal
representation to share the nodes that they have in common, and to allow nodes
in CLIF to refer to equivalency classes of other nodes, instead of referring
to specific other nodes. This produces a dense structure in which adding an
alternate form of a particular section of the program is cheap.
</p>

<p>
Because optimizations run on an E-graph only add information in the form of new
annotations, the order of the optimizations does not change the result.
As long as the compiler continues running
optimizations until they no longer have any new matches (a process known as
<a href="https://arxiv.org/abs/1012.1802">
equality saturation</a>), the E-graph will
contain the representation that would have been produced by the optimal ordering
of an equivalent sequence of traditional optimization passes â€” along with many less
efficient representations.
E-graphs are more efficient than directly storing every
possible alternative (taking O(log n) space on average),
but they still take more memory than a traditional
intermediate representation. Depending on the program in question and the set of
optimizations employed, a fully saturated E-graph could be arbitrarily large. In
practice, Cranelift sets a limit on how many operations are performed on the
graph to prevent it from becoming too large.
</p>

<p>
E-graphs pay for this simplicity and optimality when it comes time to extract
the final representation from the E-graph to use for code generation.
Extracting the fastest representation from an E-graph
<a href="https://effect.systems/blog/egraph-extraction.html">is an NP-complete</a> problem.
Cranelift uses a set of heuristics to quickly extract a
good-enough representation.
</p>

<p>
Trading one NP-complete problem (selecting the best order for a set of passes)
for another may not seem like a large benefit,
but it does make sense for a smaller project. The order of optimization passes
is largely set
by the programmers who write the optimizations, because it requires domain
knowledge to pick a reasonable sequence. Extracting an efficient representation
from an E-graph, on the other hand, is a generic search problem that can have as
much or as little computer time applied to it as the application permits.
Cranelift&#39;s
heuristics don&#39;t extract the most efficient representation, but they do a good
job of quickly extracting a decent one.
</p>

<p>
Representing optimizations in this way also makes it easier for Cranelift
maintainers to understand and debug existing optimizations and their effects,
and makes writing new optimizations somewhat simpler. Cranelift has a
<a href="https://github.com/bytecodealliance/wasmtime/blob/522f9711ad57e3c00f394691fbc5cde0fdf8017d/cranelift/isle/README.md">
custom domain-specific language</a> (ISLE) that is used internally to specify
optimizations.
</p>

<p>
While Cranelift does not organize its optimizations in phases, it does have ten
different sets of related optimizations defined in their own ISLE files, which
allows for a rough comparison with GCC and LLVM.
LLVM <a href="https://llvm.org/docs/Passes.html">lists</a> 96 optimization passes in its
documentation, while GCC has
<a href="https://github.com/gcc-mirror/gcc/blob/master/gcc/passes.def">372</a>.
The optimizations that Cranelift
does have include constant propagation, bit operation simplifications,
vectorization, floating-point operation optimizations, and normalization of
comparisons. Dead-code elimination is done implicitly by extracting a
representation from the E-graph.
</p>

<p>
A <a href="https://arxiv.org/pdf/2011.13127.pdf">paper from 2020</a> showed that
Cranelift was an order of magnitude faster than LLVM, while producing code that
was approximately twice as slow on some benchmarks. Cranelift was still slower than the
paper&#39;s authors&#39; custom copy-and-patch JIT compiler, however.
</p>

<h4>Cranelift for Rust</h4>

<p>
Cranelift may have been designed with the aim of being an alternate backend for
Rust, but actually making it usable has taken significant effort. The
Rust compiler has an internal representation (IR) called
<a href="https://blog.rust-lang.org/2016/04/19/MIR.html">mid-level IR</a> that
it uses to represent type-checked programs. Normally, the compiler converts this
to LLVM IR before sending it to the LLVM code-generation backend. In order to
use Cranelift, the compiler needed
<a href="https://github.com/rust-lang/rustc_codegen_cranelift">another
library</a> that takes mid-level IR and emits CLIF.
</p>

<p>
That library was largely written by &#34;bjorn3&#34;,
a Rust compiler team member who contributed more than 3,000
of the approximately 4,000 commits to Rust&#39;s Cranelift backend. He wrote
<a href="https://bjorn3.github.io/">a series of progress reports</a> detailing
his work.
Development began in 2018, and kept
pace with Rust&#39;s own rapid development. In 2023, the backend was considered
stable enough to ship as part of Rust nightly as an optional toolchain
component.
</p>

<p>
People can now try the Cranelift backend using <tt>rustup</tt> and
<tt>cargo</tt>:
</p>

<pre>    $ rustup component add rustc-codegen-cranelift-preview --toolchain nightly
    $ export CARGO_PROFILE_DEV_CODEGEN_BACKEND=cranelift
    $ cargo +nightly build -Zcodegen-backend
</pre>

<p>
The given <tt>rustup</tt> command adds the Cranelift backend&#39;s dynamic library to the set
of toolchain components to download and keep up to date locally. Setting the
<tt>CARGO_PROFILE_DEV_CODEGEN_BACKEND</tt> environment variable instructs
<tt>cargo</tt> to use Cranelift for debug builds, and the final <tt>cargo</tt>
invocation builds whatever Rust project lives in the current directory with the
alternate code-generation backend feature turned on.
The <a href="https://bjorn3.github.io/2023/10/31/progress-report-oct-2023.html">
latest progress report</a> from bjorn3
includes additional details on how to configure Cargo to use
the new backend by default, without an elaborate command-line dance.
</p>

<p>
Cranelift is itself written in Rust, making it possible to use as a benchmark to
compare itself to LLVM. A full debug build of Cranelift itself using the
Cranelift backend took 29.6 seconds on my computer, compared to 37.5 with LLVM
(a reduction in wall-clock time of 20%). Those wall-clock times don&#39;t tell the
full story, however, because of parallelism in the build system. Compiling with
Cranelift took 125 CPU-seconds, whereas LLVM took 211 CPU-seconds, a difference
of 40%.
Incremental builds â€” rebuilding only Cranelift itself, and none of its
dependencies â€” were faster with both backends. 66ms of CPU time compared to
90ms.
</p>

<p>
Whether Cranelift will
ameliorate users&#39; concerns about slow compile times in Rust
remains to be seen, but the initial signs are
promising. In any case,
Cranelift is an interesting showcase of a different
approach to compiler design.
</p></div></div>
  </body>
</html>
