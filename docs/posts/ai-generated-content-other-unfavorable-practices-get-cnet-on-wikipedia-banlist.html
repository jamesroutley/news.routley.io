<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.tomshardware.com/tech-industry/artificial-intelligence/ai-generated-content-and-other-unfavorable-practices-have-put-longtime-staple-cnet-on-wikipedias-blacklisted-sources">Original</a>
    <h1>AI-generated content, other unfavorable practices get CNET on Wikipedia banlist</h1>
    
    <div id="readability-page-1" class="page"><div data-widget-type="contentparsed" id="content">
<div>

<section>
<div itemprop="image" itemscope="" itemtype="https://schema.org/ImageObject">
<div>
<div>
<div>
<picture><source type="image/webp" alt="CNET website" onerror="if(this.src &amp;&amp; this.src.indexOf(&#39;missing-image.svg&#39;) !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/q7uPUoamoRDC3KdVqC6myB-320-80.jpg.webp 320w, https://cdn.mos.cms.futurecdn.net/q7uPUoamoRDC3KdVqC6myB-480-80.jpg.webp 480w, https://cdn.mos.cms.futurecdn.net/q7uPUoamoRDC3KdVqC6myB-650-80.jpg.webp 650w, https://cdn.mos.cms.futurecdn.net/q7uPUoamoRDC3KdVqC6myB-970-80.jpg.webp 970w, https://cdn.mos.cms.futurecdn.net/q7uPUoamoRDC3KdVqC6myB-1024-80.jpg.webp 1024w, https://cdn.mos.cms.futurecdn.net/q7uPUoamoRDC3KdVqC6myB-1200-80.jpg.webp 1200w, https://cdn.mos.cms.futurecdn.net/q7uPUoamoRDC3KdVqC6myB-1920-80.jpg.webp 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/q7uPUoamoRDC3KdVqC6myB.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/q7uPUoamoRDC3KdVqC6myB.jpg"/><source type="image/jpeg" alt="CNET website" onerror="if(this.src &amp;&amp; this.src.indexOf(&#39;missing-image.svg&#39;) !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/q7uPUoamoRDC3KdVqC6myB-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/q7uPUoamoRDC3KdVqC6myB-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/q7uPUoamoRDC3KdVqC6myB-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/q7uPUoamoRDC3KdVqC6myB-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/q7uPUoamoRDC3KdVqC6myB-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/q7uPUoamoRDC3KdVqC6myB-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/q7uPUoamoRDC3KdVqC6myB-1920-80.jpg 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/q7uPUoamoRDC3KdVqC6myB.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/q7uPUoamoRDC3KdVqC6myB.jpg"/><img src="https://cdn.mos.cms.futurecdn.net/q7uPUoamoRDC3KdVqC6myB-320-80.jpg" alt="CNET website" onerror="if(this.src &amp;&amp; this.src.indexOf(&#39;missing-image.svg&#39;) !== -1){return true;};this.parentNode.replaceChild(window.missingImage(),this)" srcset="https://cdn.mos.cms.futurecdn.net/q7uPUoamoRDC3KdVqC6myB-320-80.jpg 320w, https://cdn.mos.cms.futurecdn.net/q7uPUoamoRDC3KdVqC6myB-480-80.jpg 480w, https://cdn.mos.cms.futurecdn.net/q7uPUoamoRDC3KdVqC6myB-650-80.jpg 650w, https://cdn.mos.cms.futurecdn.net/q7uPUoamoRDC3KdVqC6myB-970-80.jpg 970w, https://cdn.mos.cms.futurecdn.net/q7uPUoamoRDC3KdVqC6myB-1024-80.jpg 1024w, https://cdn.mos.cms.futurecdn.net/q7uPUoamoRDC3KdVqC6myB-1200-80.jpg 1200w, https://cdn.mos.cms.futurecdn.net/q7uPUoamoRDC3KdVqC6myB-1920-80.jpg 1920w" sizes="(min-width: 1000px) 600px, calc(100vw - 40px)" data-original-mos="https://cdn.mos.cms.futurecdn.net/q7uPUoamoRDC3KdVqC6myB.jpg" data-pin-media="https://cdn.mos.cms.futurecdn.net/q7uPUoamoRDC3KdVqC6myB.jpg"/></picture>
</div>
</div>
</div>
<meta itemprop="url" content="https://cdn.mos.cms.futurecdn.net/q7uPUoamoRDC3KdVqC6myB.jpg"/>
<meta itemprop="height" content="600"/>
<meta itemprop="width" content="338"/>
<figcaption itemprop="caption description">
<span>CNET website</span>
<span itemprop="copyrightHolder">(Image credit: Shutterstock)</span>
</figcaption>
</div>

<div id="article-body">
<p>In the wave of AI controversies and lawsuits, CNET has been publicly admonished since it first started posting thinly-veiled AI-generated content on its site in late 2022— a scandal that has culminated in the site being demoted from Trusted to Untrusted Sources on Wikipedia [h/t <a data-analytics-id="inline-link" href="https://futurism.com/wikipedia-cnet-unreliable-ai" target="_blank" data-url="https://futurism.com/wikipedia-cnet-unreliable-ai">Futurism</a>].</p><p>Considering that CNET has been in the business since 1994 and maintained a top-tier reputation on Wikipedia up until late 2020, this change came after lots of debate between Wikipedia&#39;s editors and has drawn the attention of many in the media, including some CNET staff members.</p><p>It&#39;s important to remember that while Wikipedia is &#34;The Free Encyclopedia that Anyone Can Edit,&#34; it&#39;s hardly The Wild West. Wikipedia&#39;s community of editors and volunteers demand citations for any information added to Wiki pages, which keeps some degree of accountability behind the massive community responsible for operating Wikipedia. While it should never be used as a primary source, Wikipedia tends to be at least an excellent place to start researching those topics due to those citation requirements.</p><p>CNET&#39;s (apparent) fall on Wikipedia started before its AI-generated content was discovered. Back in October 2020, the acquirement of CNET by publisher Red Ventures began pushing CNET down at Wikipedia since evidence seemed to indicate a drop in editorial standards and more advertiser-favored content.</p><p>But following November 2023, when Red Ventures began posting AI-generated content to what used to be one of the most reputable tech sites, Wikipedia editors nearly immediately started pushing to demote CNET entirely from <a data-analytics-id="inline-link" href="https://en.wikipedia.org/wiki/Wikipedia:Reliable_sources/Perennial_sources" target="_blank" data-url="https://en.wikipedia.org/wiki/Wikipedia:Reliable_sources/Perennial_sources">Wikipedia&#39;s list of reliable sources</a>. CNET claims to have stopped posting AI-generated content since the nature of Red Ventures&#39; ruthless pursuit of capital and posting of misinformation on other owned sites (like Healthline) has kept CNET off the current list of reliable sources.</p><p>One Wikipedia editor, Chess, was quoted in the Futurism piece as saying, &#34;We shouldn&#39;t repeatedly put the onus on editors to prove that Red Ventures ruined a site before we can start removing it; they can easily buy or start another. I think we should look at the common denominator here, which is Red Ventures, and target the problem (a spam network) at its source.&#34;</p><p>This is a genuinely scalding take, but it might just be warranted. The issue here isn&#39;t purely the concealed usage of generative AI in published articles on one of the most well-known tech news sites ever. Instead, it&#39;s the fact that those AI-generated articles tend to be poorly written and inaccurate.</p><p>Before the age of AI, Wikipedia editors already had to deal with unwanted auto-generated content in the form of spambots and malicious actors. In this way, editors&#39; treatment of AI-generated content is remarkably consistent with their past policy: it is just spam, isn&#39;t it?</p><p>In a related story a few months ago, a self-described &#34;SEO heist&#34; was discovered on Twitter. This may have gone undiscovered had the person responsible not openly boasted about the &#34;achievement,&#34; which involved looking at a competitor&#39;s site, running it all through AI, and immediately <em>AI generating an entire competing website with 1800 articles</em> targeting the same niche to &#34;steal 3.6M total traffic from a competitor&#34;.</p><p>The site that was hurt by this so-called SEO heist is called <a data-analytics-id="inline-link" href="https://exceljet.net/" target="_blank" data-url="https://exceljet.net/">Exceljet</a>, a site run by Excel expert David Bruns to help others better use Excel. Besides having his hard work stolen in perhaps the sleaziest, laziest manner possible, Bruns also discovered that most of that content was inaccurate. <a data-analytics-id="inline-link" href="https://hubspot.sjv.io/c/221109/976131/12893?subId1=tomshardware-us-8701460641444596608&amp;sharedId=tomshardware-us&amp;u=https%3A%2F%2Fblog.hubspot.com%2Fai%2Fseo-heist" target="_blank" data-url="https://blog.hubspot.com/ai/seo-heist" data-hl-processed="hawklinks" data-placeholder-url="https://hubspot.sjv.io/c/221109/976131/12893?subId1=hawk-custom-tracking&amp;sharedId=hawk-prefix&amp;u=https%3A%2F%2Fblog.hubspot.com%2Fai%2Fseo-heist" rel="sponsored noopener" referrerpolicy="no-referrer-when-downgrade" data-google-interstitial="false" data-merchant-name="hubspot.com" data-merchant-id="199807" data-merchant-url="hubspot.com" data-merchant-network="ImpactRad">Hubspot&#39;s coverage</a> of that story also discusses how, fortunately, Google eventually caught onto this.</p><p>Unfortunately, the rise of generative AI is also starting to come at the detriment of a usable Internet with content written by humans capable of testing and genuinely understanding things. One can only hope stories like this help discourage publishers from tossing aside quality control to the point where they&#39;re auto-generating misleading content.</p><p>Particularly when we also consider that <a data-analytics-id="inline-link" href="https://www.tomshardware.com/tech-industry/artificial-intelligence/openai-and-microsoft-being-sued-by-the-new-york-times-over-copilot-and-chatgpt-copyright-infringement" data-before-rewrite-localise="https://www.tomshardware.com/tech-industry/artificial-intelligence/openai-and-microsoft-being-sued-by-the-new-york-times-over-copilot-and-chatgpt-copyright-infringement">lawsuits like The New York Times v. OpenAI and Microsoft</a> remind us that these so-called generative AIs are pretty much required to steal other people&#39;s work to function at all. At least when a regular thief steals an object, it still works. With generative AI, you can&#39;t even guarantee that the result will be accurate, especially if you already lack the expertise to tell the difference.</p>
</div>
<div id="slice-container-newsletterForm-articleInbodyContent-SMn9U8dPgSK6JK3tnBkw7o"><div data-hydrate="true"><div><section></section><section><p>Join the experts who read Tom&#39;s Hardware for the inside track on enthusiast PC tech news — and have for over 25 years. We&#39;ll send breaking news and in-depth reviews of CPUs, GPUs, AI, maker hardware and more straight to your inbox.</p></section></div></div></div>




<!-- Drop in a standard article here maybe? -->


</section>














</div>
</div></div>
  </body>
</html>
