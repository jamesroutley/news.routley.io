<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.trailofbits.com/2024/10/25/a-deep-dive-into-linuxs-new-mseal-syscall/">Original</a>
    <h1>A deep dive into Linux&#39;s new mseal syscall</h1>
    
    <div id="readability-page-1" class="page"><article id="post-108435">
	<!-- .entry-header -->

	<div>
		<p><em>By Alan Cao</em></p>
<p>If you love exploit mitigations, you may have heard of a new system call named <code>mseal</code> landing into the Linux kernel’s 6.10 release, providing a protection called “memory sealing.” Beyond notes from the authors, very little information about this mitigation exists. In this blog post, we’ll explain what this syscall is, including how it’s different from prior memory protection schemes and how it works in the kernel to protect virtual memory. We’ll also describe the particular exploit scenarios that <code>mseal</code> helps stop in Linux userspace, such as stopping malicious permissions tampering and preventing memory unmapping attacks.</p>
<h3>What mseal is (and isn’t)</h3>
<p>Memory sealing allows developers to make memory regions immutable from illicit modifications during program runtime. When a virtual memory address (VMA) range is sealed, an attacker with a code execution primitive cannot perform subsequent virtual memory operations to change the VMA’s permissions or modify how it is laid out for their benefit.</p>
<p>If you’re like me and followed the <a href="https://lore.kernel.org/lkml/CAHk-=wh+6n6f0zuezKem+W=aytHMv2bib6Fbrg-xnWOoujFb6g@mail.gmail.com/">spicy discourse</a> surrounding this syscall in the kernel mailing lists, you may have observed that Chrome’s Security team introduced it to support their <a href="https://v8.dev/blog/control-flow-integrity">V8 CFI strategy</a>, initially for Linux-based ChromeOS. After some lengthy deliberation and several rewrites, it finally landed in the kernel, with plans to expand its use case beyond browsers with <a href="https://lwn.net/Articles/978010/">its integration into glibc, possibly in version 2.41</a>.</p>
<p><code>mseal</code>’s security guarantees are unlike Linux’s <code>memfd_create</code> and its <code>memfd_secret</code> variant, which provide file sealing. <code>memfd_create</code> and <code>memfd_secret</code> allow one to create RAM-backed anonymous files as an alternative to storing content to <code>tmpfs</code>, with <code>memfd_secret</code> taking it a step further by ensuring that the region of memory is accessible only to the process holding the file descriptor. This lets developers create “secure enclave”-style userspace mappings that can guard sensitive in-memory data.</p>
<p><code>mseal</code> digresses from prior memory protection schemes on Linux because it is a syscall tailored specifically for <em>exploit mitigation</em> against remote attackers seeking code execution rather than potentially local ones looking to exfiltrate sensitive secrets in-memory.</p>
<p>To understand <code>mseal</code>’s security mitigations, we must first study its implementation to understand how it operates. Luckily, <code>mseal</code> is simple to understand, so let’s look at how it works in the kernel!</p>
<h3>A look under the hood</h3>
<p><code>mseal</code> has a simple function signature:</p>
<pre><span>int</span> mseal(<span>unsigned</span> long start, size_t len, <span>unsigned long</span> flags)
</pre>
<ul>
<li><code>start</code> and <code>len</code> represent the start/end range of a valid VMA that we want to seal, and len must be properly page-aligned.</li>
<li><code>flags</code> are unused at the time of writing and must be set to 0.</li>
</ul>
<p>In the 6.12 kernel, its syscall definition calls <a href="https://elixir.bootlin.com/linux/v6.12-rc3/source/mm/mseal.c#L212"><code>do_mseal</code></a>:</p>
<pre><span>static</span> <span>int</span> do_mseal(<span>unsigned long</span> start, size_t len_in, <span>unsigned long</span> flags)
{
    size_t len;
    <span>int</span> ret = <span>0</span>;
    <span>unsigned long</span> end;
    <span>struct</span> mm_struct *mm = current-&gt;mm;     <span>// [1]</span>

    <span>// ... Check flags == 0, check page alignment, and compute `end`</span>

    <span>if</span> (mmap_write_lock_killable(mm))          <span>// [2]</span>
        <span>return</span> -EINTR;

    /*
     * First pass, <span>this</span> helps to avoid
     * partial sealing in <span>case</span> of <span>error</span> in input address range,
     * e.g. ENOMEM <span>error</span>.
     */
    ret = check_mm_seal(start, end);            <span>// [3]</span>
    <span>if</span> (ret)
        <span>goto</span> out;

    /*
     * Second pass, <span>this</span> should success, unless there are errors
     * from vma_modify_flags, e.g. merge/split <span>error</span>, or process
     * reaching the max supported VMAs, however, those cases shall
     * be rare.
     */
    ret = apply_mm_seal(start, end);            <span>// [4]</span> 

out:
    mmap_write_unlock(current-&gt;mm);
    <span>return</span> ret;
}
</pre>
<p><code>do_mseal</code> will first compute an <code>end</code> offset from the provided length and lock the memory region <code>[2]</code> to prevent concurrent access to the page. The global <code>current</code> at <code>[1]</code> represents the current executing <code>task_struct</code> (i.e., the process invoking <code>mseal</code>). The referenced field is the <a href="https://elixir.bootlin.com/linux/v6.12-rc3/source/include/linux/mm_types.h#L790"><code>mm_struct</code></a> representing the task’s entire virtual memory address space. The critical field in <code>mm_struct</code> on which this syscall will operate is <code>mmap</code>, a list of <a href="https://elixir.bootlin.com/linux/v6.12-rc3/source/include/linux/mm_types.h#L667"><code>vm_area_struct</code></a> values. This represents a single contiguous memory region created by <code>mmap</code>, such as the stack or VDSO.</p>
<p>The <code>check_mm_seal</code> call at <code>[3]</code> ensures that the targeted memory map for sealing is a valid range by iterating over each VMA from <code>current-&gt;mm</code> to test boundary correctness.</p>
<pre><span>static</span> <span>int</span> check_mm_seal(<span>unsigned long</span> start, <span>unsigned long</span> end)
{
    <span>struct</span> vm_area_struct *vma;
    <span>unsigned long</span> nstart = start;

    VMA_ITERATOR(vmi, current-&gt;mm, start);

    /* going through each vma to check. */
    for_each_vma_range(vmi, vma, end) {
        <span>if</span> (vma-&gt;vm_start &gt; nstart)
            /* unallocated memory found. */
            <span>return</span> -ENOMEM;
        <span>if</span> (vma-&gt;vm_end &gt;= end)
            <span>return</span> <span>0</span>;

        nstart = vma-&gt;vm_end;
    }
    <span>return</span> -ENOMEM;
}
</pre>
<p>The magic happens in the <code>apply_mm_seal</code> call <code>[4]</code>, which walks over each VMA again and arranges for the targeted region to have an additional <code>VM_SEALED</code> flag through the <code>mseal_fixup</code> call:</p>
<pre><span>static</span> <span>int</span> apply_mm_seal(<span>unsigned long</span> start, <span>unsigned long</span> end)
{
    // ...
    nstart = start;
    for_each_vma_range(vmi, vma, end) {
        <span>int</span> <span>error</span>;
        <span>unsigned long</span> tmp;
        vm_flags_t newflags;

        newflags = vma-&gt;vm_flags | VM_SEALED;
        tmp = vma-&gt;vm_end;
        <span>if</span> (tmp &gt; end)
            tmp = end;
        <span>error</span> = mseal_fixup(vmi, vma, &amp;prev, nstart, tmp, newflags);
        <span>if</span> (<span>error</span>)
            <span>return error</span>;
        nstart = vma_iter_end(&amp;vmi);
    }
    <span>return</span> <span>0</span>;
}
</pre>
<p>To ensure that unwanted memory operations respect this new flag, the <code>mseal</code> patchset adds <code>VM_SEALED</code> checks to the following files:</p>
<pre><span> mm/madvise.c                                |   12 +
 mm/mmap.c                                   |   31 +-
 mm/mprotect.c                               |   10 +
 mm/mremap.c                                 |   31 +
 mm/mseal.c                                  |  307 ++++
</span></pre>
<p>For instance, <code>mprotect</code> and <code>pkey_mprotect</code> will enforce this check when it eventually invokes <a href="https://elixir.bootlin.com/linux/v6.12-rc3/source/mm/mprotect.c#L614"><code>mprotect_fixup</code></a>:</p>
<pre><span>int</span>
mprotect_fixup(..., <span>struct</span> vm_area_struct *vma, ...)
{
    <span>// ...</span>
    <span>if</span> (!can_modify_vma(vma))
        <span>return</span> -EPERM;
    }
    <span>// ...</span>
}
</pre>
<p>To determine whether the syscall should continue, <code>can_modify_vma</code>—defined in <a href="https://elixir.bootlin.com/linux/v6.12-rc3/source/mm/vma.h#L534"><code>mm/vma.h</code></a>—will test for the existence of <code>VM_SEALED</code> in the specified <code>vm_area_struct</code>:</p>
<pre><span>static inline</span> bool vma_is_sealed(<span>struct</span> vm_area_struct *vma)
{
    <span>return</span> (vma-&gt;vm_flags &amp; VM_SEALED);
}

/*
 * check <span>if</span> a vma is sealed <span>for</span> modification.
 * <span>return</span> true, <span>if</span> modification is allowed.
 */
<span>static inline</span> bool can_modify_vma(<span>struct</span> vm_area_struct *vma)
{
    <span>if</span> (unlikely(vma_is_sealed(vma)))
        <span>return</span> false;

    <span>return</span> true;
}
</pre>
<p>From the changes in other memory-management syscalls, we can determine the operations that are not permitted on a VMA after it is sealed:</p>
<ul>
<li>Changing permission bits with <code>mprotect</code> and <code>pkey_mprotect</code></li>
<li>Unmapping with <code>munmap</code></li>
<li>Replacement of a sealed map with <code>mmap</code>(<code>MAP_FIXED</code>) with another one that is mutable/unsealed</li>
<li>Expanding or shrinking its size with <code>mremap</code>. Shrinking to zero could create a refillable hole for a new mapping with no sealing, as it triggers an unmap altogether.</li>
<li>Migrating to a new destination with <code>mremap(MREMAP_MAYMOVE | MREMAP_FIXED)</code>. Note that sealing checks are imposed on both the source and destination VMAs. Also, the source VMA will be unmapped if <code>MREMAP_DONTUNMAP</code> is not supplied, but the <code>munmap</code> sealing check will still apply.</li>
<li>Calling <code>madvise</code> with the <a href="https://elixir.bootlin.com/linux/v6.12-rc3/source/mm/mseal.c#L26-#L32">following destructive flags</a></li>
</ul>
<p>For now, one can invoke <code>mseal</code> on a 6.10+ kernel through a direct syscall invocation. Here’s a basic wrapper implementation to help you get started:</p>
<pre>#<span>include</span> &lt;sys/syscall.h&gt;
#<span>include</span> <span>&lt;unistd.h&gt;</span>

#define MSEAL_SYSCALL <span>462</span>

<span>long</span> mseal(<span>unsigned long</span> start, size_t len)
{
    <span>int</span> page_size;
    uintptr_t page_aligned_start;

    /* how large a page should be on our system (<span>default</span>: <span>4096</span> bytes) */
    page_size = getpagesize();

    /* page align the VMA range we want to seal */
    page_aligned_start = start &amp; ~(page_size - 1);
    <span>return</span> syscall(MSEAL_SYSCALL, page_aligned_start, len, <span>0</span>);
}
</pre>
<h3>What exploit techniques does mseal help mitigate?</h3>
<p>From the disallowed operations, we can discern two particular exploit scenarios that memory sealing will prevent:</p>
<ul>
<li>Tampering with a VMA’s permissions. Notably, not allowing executable permissions to be set can stop the revival of shellcode-based attacks.</li>
<li>“Hole-punching” through arbitrary unmapping/remapping of a memory region, mitigating data-only exploits that take advantage of refilling memory regions with attacker-controlled data.</li>
</ul>
<p>Let’s examine these scenarios in more detail, and the defense-in-depth strategies developers can employ in their software implementations.</p>
<h4>Hardening NX</h4>
<p>Even with the continued existence of code reuse techniques like ROP, attackers may prefer to gain shellcoding capability during exploitation; this can provide a stable and “easy win,” especially if constraints are imposed on the gadget chain. Here is a potential workflow to achieve this:</p>
<ul>
<li>Through some target functionality, spray shellcode onto a non-executable stack/heap region.</li>
<li>Exploit the target’s bug to kick off an initial ROP chain to call <code>mprotect</code> with <code>PROT_EXEC</code> to target the region holding the shellcode and turn off the NX bit.</li>
<li>Jump to it to revive old-school shellcoding!</li>
</ul>
<p>The exploit for <a href="https://packetstormsecurity.com/files/146795/MikroTik-RouterOS-SMB-Buffer-Overflow.html">CVE-2018-7445</a> targeting Mikrotik RouterOS’s SMB daemon is a notable example. A socket-based shellcode is sprayed onto the non-executable heap, and the crafted ROP chain from a stack overflow modifies heap memory permissions before executing shellcode.</p>
<p>The most straightforward use case for memory sealing is disallowing VMA permission modification; once that happens, exploits that want to take advantage of traditional shellcode won’t be able to switch off executable bits.</p>
<p>As mentioned, <code>mseal</code> will be introduced in glibc 2.41+, where the dynamic loader will apply sealing across a <a href="https://lwn.net/Articles/978010/">predetermined set of VMAs</a>. However, at the time of writing, this will <em>not be done automatically for the stack or heap</em>.</p>
<p>This is expected because these regions can expand during runtime. For instance, a heap allocator that wants to reclaim space will invoke the <code>brk</code> syscall, which could call <code>arch_unmap</code> and eventually <code>do_vmi_unmap</code> to perform shrinking. Of course, this would be disallowed under sealing and thus break dynamic memory allocation for the application altogether.</p>
<p>So, for now, the software developer is responsible for protecting these regions, as they have the context to determine when and where sealing should be applied appropriately.</p>
<p>Let’s use <code>mseal</code> to enhance the stack’s old-school NX (non-executable) protection. Here’s a simple example that emulates the scenario mentioned above:</p>
<pre><span>int</span> main(<span>void</span>)
{
    /* represents the stack that now contains /bin/sh shellcode we somehow sprayed */
    <span>unsigned char</span> exec_shellcode[] =
<span>&#34;\xe1\x45\x8c\xd2\x21\xcd\xad\xf2\xe1\x65\xce\xf2\x01\x0d\xe0\xf2&#34;
&#34;\xe1\x8f\x1f\xf8\xe1\x03\x1f\xaa\xe2\x03\x1f\xaa\xe0\x63\x21\x8b&#34;
&#34;\xa8\x1b\x80\xd2\xe1\x66\x02\xd4&#34;;</span>

    <span>// vulnerability triggered, hijacked instruction pointer</span>

    /* ======= what our ROP chain would do: ======= */


    /* compute the start of the page <span>for</span> the shellcode */
    <span>void</span> (*exec_ptr)() =  (<span>void</span>(*)())&amp;exec_shellcode;
    <span>void</span> *exec_offset = (<span>void</span> *)((int64_t) exec_ptr &amp; ~(getpagesize() - 1));

    mprotect(exec_offset, getpagesize(), PROT_READ|PROT_WRITE|PROT_EXEC);

    /* <span>this</span> now works! */
    exec_ptr();
    <span>return</span> <span>0</span>;
}
</pre>
<p>As we’d expect, setting <code>PROT_EXEC</code> on the VMA permits <code>exec_shellcode</code> to become executable again:</p>
<pre><span>~ gcc stack_no_sealing.c -o stack_no_sealing
~ ./stack_no_sealing
$
</span></pre>
<p>Let’s introduce memory sealing on the stack-based <code>exec_offset</code> VMA range:</p>
<pre><span>int</span> main(<span>void</span>)
{
    /* represents the stack that now contains /bin/sh shellcode we somehow sprayed */
    <span>unsigned char</span> exec_shellcode[] =
&#34;\xe1\x45\x8c\xd2\x21\xcd\xad\xf2\xe1\x65\xce\xf2\x01\x0d\xe0\xf2&#34;
&#34;\xe1\x8f\x1f\xf8\xe1\x03\x1f\xaa\xe2\x03\x1f\xaa\xe0\x63\x21\x8b&#34;
&#34;\xa8\x1b\x80\xd2\xe1\x66\x02\xd4&#34;;

    /* compute the start of the page <span>for</span> the shellcode */
    <span>void</span> (*exec_ptr)() =  (<span>void</span>(*)())&amp;exec_shellcode;
    <span>void</span> *exec_offset = (<span>void</span> *)((int64_t) exec_ptr &amp; ~(getpagesize() - 1));

    /* seal the stack page containing the shellcode! */
    <span>if</span> (mseal(exec_offset, getpagesize()) &lt; <span>0</span>)
        handle_error(<span>&#34;mseal&#34;</span>);

    <span>// vulnerability triggered, hijacked instruction pointer</span>

    /* ======= what our ROP chain would <span>do</span>: ======= */

    mprotect(exec_offset, getpagesize(), PROT_READ|PROT_WRITE|PROT_EXEC);
    /* segfault now, as no permission change actually occurred */
    exec_ptr();
    <span>return</span> <span>0</span>;
}
</pre>
<p>The aforementioned <code>can_modify_vma</code> check kicks in when <code>mprotect</code> is called, preventing the permission change from ever happening, and the attempt to shellcode now fails:</p>
<pre><span>~ gcc stack_with_sealing.c -o stack_with_sealing
~ ./stack_with_sealing
[1]    48771 segmentation fault (core dumped)  ./stack_with_sealing
</span></pre>
<p>A simple strategy to accommodate real-world software could involve sparingly introducing a macro-ized version of the <code>mseal</code> code snippet and iteratively sealing pages in select stack frames where untrusted data could reside for exploitation:</p>
<pre>#define SIMPLE_HARDEN_NX_SINGLE_PAGE(frame) \
  <span>do</span> { \
    <span>void</span> *frame_offset = (<span>void</span> *)((int64_t) &amp;frame &amp; ~(getpagesize() - 1)); \
    <span>if</span> (mseal(frame_offset, getpagesize()) == -1) { \
      handle_error(&#34;mseal&#34;); \
    } \
  } <span>while</span>(<span>0</span>)

<span>int</span> frame_2(void)
{
    <span>int</span> frame_start = <span>0</span>;
    <span>unsigned char</span> another_untrusted_buffer[<span>1024</span>] = { <span>0</span> };
    SIMPLE_HARDEN_NX_SINGLE_PAGE(frame_start);
    <span>return</span> <span>0</span>;
}

<span>int</span> frame_1(<span>void</span>)
{
    <span>unsigned char</span> untrusted_buffer[<span>1024</span>] = { <span>0</span> };
    SIMPLE_HARDEN_NX_SINGLE_PAGE(untrusted_buffer);
    <span>return</span> frame_2();
}
</pre>
<p>Even if a sealed VMA is reused as a frame for another function with sealing logic, invoking <code>mseal</code> again would be considered a no-op, so no errors would emerge. Of course, developers should be mindful of edge cases like automatic stack expansion from aggressive usage or bespoke features like <a href="https://gcc.gnu.org/wiki/SplitStacks">stack splitting</a>.</p>
<p>Hopefully, as the integration of <code>mseal</code> into glibc continues, we’ll see tunables emerge that do not require any manual use of the syscall for the stack. Commenters in the LWN mailing list <a href="https://lwn.net/Articles/958956/">yearn for an automatic sealing that can be toggled for simpler applications</a>.</p>
<p>And with all this said, if an attacker doesn’t want to fully ROP and insists on bringing back shellcode nostalgia, they could always use their initial code reuse technique to mmap a fresh region that is executable. However, this is pretty laborious, as it now involves copying the exploit payload from a readable region to this new mapping.</p>
<h4>Mitigating unmapping-based, data-only exploitation</h4>
<p>Disallowing <code>mprotect</code> also prevents a sealed region from becoming writable, which is valuable if there are data variables that, when modified, could enhance an exploit primitive. However, during the inception of <code>mseal</code>, Chrome maintainers rationalized an easier and more powerful technique with the added benefit of circumventing CFI (control-flow integrity). They determined that if an attacker can pass a corrupted pointer to unmapping/remapping syscalls, they can “punch a hole” in memory that could be refilled with attacker-controlled data. This would not violate CFI guarantees, as forward- and backward-edge CFI would cover only tampered control-flow transitions (e.g., stack return addresses and function pointers).</p>
<p>This is incredibly enticing for a browser implementing a JIT compiler. V8’s Turbofan can create regions that switch between RW and RX, aiding the refill process and changing permissions. Thus, an attacker can take advantage of the JIT compilation process by emitting executable code from hot-path JavaScript into the unmapped region to overwrite critical data and then leverage modifications to yield code execution.</p>
<p>We argue this is a <em>data-only</em> exploitation technique, as it doesn’t involve directly hijacking control flow or requiring leaked pointers but rather tampering with particular data in memory that influences control flow to the attacker’s liking. In an era of mitigations like CFI, this has emerged as a pretty potent technique during exploitation. Thus, memory sealing can prevent these particular data-only techniques by disallowing hole-punching scenarios.</p>
<p>This particular data-only technique isn’t just for browsers with JIT compilers! A similar technique would be the <a href="https://maxwelldulin.com/BlogPost/House-of-Muney-Heap-Exploitation">House of Muney</a> for userspace heap exploitation. As Max Dulin points out in his post, Qualys used this technique to perform a <a href="https://www.qualys.com/2020/05/19/cve-2005-1513/remote-code-execution-qmail.txt">real-world exploit for an ancient bug in Qmail</a>.</p>
<p>This technique relies on the fact that for huge allocated chunks (greater than the <a href="https://www.gnu.org/software/libc/manual/html_node/Malloc-Tunable-Parameters.html"><code>M_MAP_THRESHOLD</code></a> tunable), <code>malloc</code> and <code>free</code> will directly invoke <code>mmap</code> and <code>munmap</code>, respectively, with no intermediate freelists that cache any freed chunks (which helps greatly simplify exploitation). Since size metadata exists at the top of allocated chunks, tampering it to a different page size and freeing it would cause a <code>munmap</code> on memory regions adjacent to the chunk. Dulin used the arbitrary <code>munmap</code> to target the <code>.gnu.hash</code> and <code>.dynsym</code> regions and after refilling them with another larger mmap chunk, enabled the overwriting of a single, yet-to-be-resolved PLT entry, reviving a GOT overwrite-style attack!</p>
<p>Dulin has a very well-done and annotated PoC for this attack <a href="https://github.com/mdulin2/house-of-muney/blob/master/munmap_rewrite.c">here</a>. Here’s an abridged version that goes up to the point where the unmapping and refill occur:</p>
<pre>#<span>include</span> <span>&lt;stdio.h&gt;</span>
#<span>include</span> <span>&lt;string.h&gt;</span>
#<span>include</span> <span>&lt;stdlib.h&gt;</span>
#<span>include</span> <span>&lt;malloc.h&gt;</span>

<span>// With this allocation size,
// malloc is now equivalent to mmap
// free is now equivalent to munmap</span>
#define THRESHOLD_SIZE <span>0x100000</span>

<span>int</span> main() {
    <span>long long</span> *bottom, *top, *refill;

    bottom = malloc(THRESHOLD_SIZE);
    memset(bottom, <span>&#39;B&#39;</span>, THRESHOLD_SIZE);

    <span>// [1] Allocation that we write into out-of-bounds from a prior chunk</span>
    top = malloc(THRESHOLD_SIZE);
    memset(top, <span>&#39;A&#39;</span>, THRESHOLD_SIZE);

    <span>// [2] Corrupts size field, ensuring page alignment + mmap bit is set</span>
    <span>// size to unmap = top + bottom + large arbitrary size</span>
    <span>int</span> unmap_size = (<span>0xfffffffd</span> &amp; top[<span>-1</span>]) + (<span>0xfffffffd</span> &amp; bottom[<span>-1</span>]) + <span>0x14000</span>;
    top[<span>-1</span>] = (unmap_size | <span>2</span>);

    <span>// Trigger munmap with corrupted chunk</span>
    free(top);

    <span>// [3] Refill with new and larger mmap chunk</span>
    refill = malloc(<span>0x5F0000</span>);
    memset(refill, <span>&#39;X&#39;</span>, <span>0x5F0000</span>);
    <span>return</span> <span>0</span>;
}
</pre>
<p>By the time we finish <code>[1]</code>, we can see that the <code>top</code> and <code>bottom</code> chunks now exist in a separate mapping below the heap, separated by 4096-byte padding. Note the adjacent libc mapping at <code>0xfffff7df0000</code>:</p>
<p><img fetchpriority="high" decoding="async" data-attachment-id="108462" data-permalink="https://blog.trailofbits.com/2024/10/25/a-deep-dive-into-linuxs-new-mseal-syscall/figure_1-9/" data-orig-file="https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_1-2.png" data-orig-size="1999,554" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="figure_1" data-image-description="" data-image-caption="" data-medium-file="https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_1-2-300x83.png" data-large-file="https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_1-2-1650x457.png" tabindex="0" role="button" src="https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_1-2-1650x457.png" alt="" width="690" height="191" srcset="https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_1-2-1650x457.png 1650w, https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_1-2-300x83.png 300w, https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_1-2-768x213.png 768w, https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_1-2-1536x426.png 1536w, https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_1-2.png 1999w" sizes="(max-width: 690px) 100vw, 690px"/></p>
<p>At <code>[2]</code>, we corrupt the <code>size</code> field of the chunk to a much larger page size and ensure that the <code>mmap</code> bit is set. When we break on the <code>munmap</code> occurring in the free <code>[3]</code>, the <code>size</code> argument passed has been changed, allowing an unmap into the adjacent region!</p>
<p><img decoding="async" data-attachment-id="108463" data-permalink="https://blog.trailofbits.com/2024/10/25/a-deep-dive-into-linuxs-new-mseal-syscall/figure_2-9/" data-orig-file="https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_2-2.png" data-orig-size="1658,700" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="figure_2" data-image-description="" data-image-caption="" data-medium-file="https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_2-2-300x127.png" data-large-file="https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_2-2-1650x697.png" tabindex="0" role="button" src="https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_2-2-1650x697.png" alt="" width="690" height="291" srcset="https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_2-2-1650x697.png 1650w, https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_2-2-300x127.png 300w, https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_2-2-768x324.png 768w, https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_2-2-1536x648.png 1536w, https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_2-2.png 1658w" sizes="(max-width: 690px) 100vw, 690px"/></p>
<p>After <code>[3]</code>, this can be confirmed by examining the contents of the previous libc mapping at <code>0xfffff7df0000</code>, now partially overwritten with <code>X</code>s:</p>
<p><img decoding="async" data-attachment-id="108464" data-permalink="https://blog.trailofbits.com/2024/10/25/a-deep-dive-into-linuxs-new-mseal-syscall/figure_3-9/" data-orig-file="https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_3-2.png" data-orig-size="1522,336" data-comments-opened="1" data-image-meta="{&#34;aperture&#34;:&#34;0&#34;,&#34;credit&#34;:&#34;&#34;,&#34;camera&#34;:&#34;&#34;,&#34;caption&#34;:&#34;&#34;,&#34;created_timestamp&#34;:&#34;0&#34;,&#34;copyright&#34;:&#34;&#34;,&#34;focal_length&#34;:&#34;0&#34;,&#34;iso&#34;:&#34;0&#34;,&#34;shutter_speed&#34;:&#34;0&#34;,&#34;title&#34;:&#34;&#34;,&#34;orientation&#34;:&#34;0&#34;}" data-image-title="figure_3" data-image-description="" data-image-caption="" data-medium-file="https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_3-2-300x66.png" data-large-file="https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_3-2.png" tabindex="0" role="button" src="https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_3-2.png" alt="" width="1522" height="336" srcset="https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_3-2.png 1522w, https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_3-2-300x66.png 300w, https://blog.trailofbits.com/wp-content/uploads/2024/10/figure_3-2-768x170.png 768w" sizes="(max-width: 1522px) 100vw, 1522px"/></p>
<p>This is a pretty nifty data-only technique that can operate even in the presence of CFI and does not require a prerequisite ASLR leak!</p>
<p>Luckily, the aforementioned set of VMAs in <code>mseal</code>’s glibc integration is expected to automatically mitigate this without any developer intervention, as mapped binary code and dynamic libraries become sealed from any remap/unmapping tricks like this. For additional hardening, a developer can selectively seal mmap allocations that they know will never expand or become unmapped during the lifetime of their program. This will have the added benefit of preventing the previous exploit scenario if attacker-controlled data can be expected to be written into the mmap chunks and may become writable/executable.</p>
<h3>Build stronger software with mseal</h3>
<p>There are likely many other use cases and scenarios that we didn’t cover. After all, <code>mseal</code> is the newest kid on the block in the Linux kernel! As the glibc integration completes and matures, we expect to see improved iterations for the syscall to meet particular demands, including fleshing out the ultimate use of the <code>flags</code> parameter.</p>
<p>Hardening software is complex, as navigating and evaluating new security mitigations can be challenging in understanding the risk and reward payoff. If this blog post is interesting to you, check out some of our escapades into other <a href="https://blog.trailofbits.com/2023/04/20/typos-that-omit-security-features-and-how-to-test-for-them/">security</a> <a href="https://blog.trailofbits.com/2016/12/27/lets-talk-about-cfi-microsoft-edition/">mitigations</a>. If you’re seeking guidance in integrating <code>mseal</code> or any other modern mitigations into your software, <a href="https://www.trailofbits.com/contact/">contact us</a>!</p>

			</div><!-- .entry-content -->

	
</article></div>
  </body>
</html>
