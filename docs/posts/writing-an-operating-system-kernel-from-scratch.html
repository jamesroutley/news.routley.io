<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://popovicu.com/posts/writing-an-operating-system-kernel-from-scratch/">Original</a>
    <h1>Writing an operating system kernel from scratch</h1>
    
    <div id="readability-page-1" class="page"><article id="article" role="article">
      <p><a href="https://twitter.com/popovicu94?ref_src=twsrc%5Etfw" data-show-count="false">Follow @popovicu94</a></p>
<p>I recently implemented a minimal proof of concept time-sharing operating system kernel on RISC-V. In this post, I’ll share the details of how this prototype works. The target audience is anyone looking to understand low-level system software, drivers, system calls, etc., and I hope this will be especially useful to students of system software and computer architecture.</p>
<p>This is a redo of an exercise I did for my undergraduate course in operating systems, and functionally it should resemble a typical operating systems project. However, this experiment focuses on modern tooling, as well as the modern architecture of RISC-V. RISC-V is an amazing technology that is easy to understand more quickly than other CPU architectures, while remaining a popular choice for many new systems, not just an educational architecture.</p>
<p>Finally, to do things differently here, I implemented this exercise in Zig, rather than traditional C. In addition to being an interesting experiment, I believe Zig makes this experiment much more easily reproducible on your machine, as it’s very easy to set up and does not require any installation (which could otherwise be slightly messy when cross-compiling to RISC-V).</p>
<h2 id="table-of-contents">Table of contents</h2>
<details><summary>Open Table of contents</summary>
<ul>
<li>
<p><a href="#github-repo">GitHub repo</a></p>
</li>
<li>
<p><a href="#recommended-reading">Recommended reading</a></p>
</li>
<li>
<p><a href="#unikernel">Unikernel</a></p>
</li>
<li>
<p><a href="#sbi-layer">SBI layer</a></p>
</li>
<li>
<p><a href="#goal-for-the-kernel">Goal for the kernel</a></p>
</li>
<li>
<p><a href="#virtualization-and-what-exactly-is-a-thread">Virtualization and what exactly is a thread</a></p>
<ul>
<li><a href="#the-stack-and-memory-virtualization">The stack and memory virtualization</a></li>
<li><a href="#virtualizing-a-thread">Virtualizing a thread</a></li>
<li><a href="#interrupt-context">Interrupt context</a></li>
</ul>
</li>
<li>
<p><a href="#implementation-high-level">Implementation (high-level)</a></p>
<ul>
<li><a href="#leveraging-the-interrupt-stack-convention">Leveraging the interrupt stack convention</a></li>
<li><a href="#kerneluser-space-separation">Kernel/user space separation</a></li>
</ul>
</li>
<li>
<p><a href="#implementation-code">Implementation (code)</a></p>
<ul>
<li><a href="#assembly-startup">Assembly startup</a></li>
<li><a href="#main-kernel-file-and-io-drivers">Main kernel file and I/O drivers</a></li>
<li><a href="#s-mode-handler-and-the-context-switch">S-mode handler and the context switch</a></li>
<li><a href="#the-user-space-threads">The user space threads</a></li>
<li><a href="#running-the-kernel">Running the kernel</a></li>
</ul>
</li>
<li>
<p><a href="#conclusion">Conclusion</a></p>
</li>
</ul>
</details>
<h2 id="github-repo">GitHub repo</h2>
<p>The final code for this experiment is on GitHub <a href="https://github.com/popovicu/zig-time-sharing-kernel">here</a>. We’ll be referencing the code from it as we go.</p>
<p>GitHub should be the source of truth and may be slightly out of sync with the code below.</p>
<h2 id="recommended-reading">Recommended reading</h2>
<p>The basic fundamentals of computer engineering and specifically computer architecture are assumed. Specifically, knowledge of registers, how the CPU addresses memory, and interrupts is all necessary.</p>
<p>Before diving deep into this experiment, it’s recommended to also review the following background texts:</p>
<ol>
<li><a href="https://popovicu.com/posts/bare-metal-programming-risc-v">Bare metal programming on RISC-V</a></li>
<li><a href="https://popovicu.com/posts/risc-v-sbi-and-full-boot-process">RISC-V boot process with SBI</a></li>
<li><a href="https://popovicu.com/posts/risc-v-interrupts-with-timer-example/">RISC-V interrupts with a timer example</a></li>
<li><em>Optional</em> - <a href="https://popovicu.com/posts/making-a-micro-linux-distro">Making a micro Linux distro</a> - mainly for the brief philosophy on the kernel / user space split</li>
</ol>
<h2 id="unikernel">Unikernel</h2>
<p>We’ll be developing a type of <a href="https://en.wikipedia.org/wiki/Unikernel">unikernel</a>. Simply put, this setup links the application code directly with the OS kernel it depends on. Essentially, everything is bundled into a single binary executable, and the user code is loaded into memory alongside the kernel.</p>
<p>This bypasses the need to separately load the user code at runtime, which is a complex field in itself (involving linkers, loaders, etc.).</p>
<h2 id="sbi-layer">SBI layer</h2>
<p>RISC-V supports a layered permissions model. The system boots into machine mode (M), which is completely bare-metal, and then supports a couple of other less privileged modes. Please check the background texts for more details; below is a quick summary:</p>
<ol>
<li>M-mode can do pretty much anything; it is fully bare-metal.</li>
<li>In the middle is S-mode, supervisor, which typically hosts the operating system kernel.</li>
<li>At the bottom is U-mode, user, where application code runs.</li>
</ol>
<p>Lower privilege levels can send requests to higher privilege levels.</p>
<p>We’ll assume that at the bottom of our software stack is an SBI layer, specifically OpenSBI. Please study <a href="https://popovicu.com/posts/risc-v-sbi-and-full-boot-process">this text</a> for the necessary background, as we’ll use the SBI layer to manage console printing and control the timer hardware. While manual implementation is possible, I wanted to add more value to this text by demonstrating a more portable approach with OpenSBI.</p>
<h2 id="goal-for-the-kernel">Goal for the kernel</h2>
<p>We want to support a few key features for simplicity:</p>
<ol>
<li>Statically define threads ahead of execution; i.e., dynamic thread creation is not supported. Additionally, for simplicity, threads are implemented as never-ending functions.</li>
<li>Threads operate in user mode and are able to send system calls to the kernel operating in S-mode.</li>
<li>Time is sliced and allocated among different threads. The system timer will be set to tick every couple of milliseconds, at which point a thread may be switched out.</li>
</ol>
<p>Finally, development is targeted for a single-core machine.</p>
<h2 id="virtualization-and-what-exactly-is-a-thread">Virtualization and what exactly is a thread</h2>
<p>Before implementing threads, we should decide what they really are. The concept of threads in a time-sharing environment enables multiple workloads to run on a single core (as noted above, we’re focusing on single-core machines), while the programming model for each thread remains largely the same as if it were the sole software on the machine. This is a loose definition, which we will refine.</p>
<p>To understand time-sharing, let’s briefly consider its contrast: cooperative scheduling/threading. In cooperative scheduling/threading, a thread voluntarily yields CPU time to another workload. Eventually, the expectation is that another thread will yield control back to the first.</p>
<pre is:raw="" tabindex="0"><code><span><span>function thread():</span></span>
<span><span>  operation_1();</span></span>
<span><span>  operation_2();</span></span>
<span><span>  YIELD();</span></span>
<span><span>  operation_3();</span></span>
<span><span>  YIELD();</span></span>
<span><span>  ...</span></span></code></pre>
<p>To be clear, this isn’t an “outdated” technique, despite being older. In fact, it’s alive and well in many modern programming languages and their runtimes (often abstracted from programmers). One good example is Go, which uses Goroutines to run multiple workloads on top of one operating system thread. While programmers don’t necessarily add explicit yield operations, the compiler and runtime can inject them into the workload.</p>
<p>Now, it should be clearer what it means for the programming model to remain largely the same in a time-sharing context. The thread would naturally look like this:</p>
<pre is:raw="" tabindex="0"><code><span><span>function thread():</span></span>
<span><span>  operation_1();</span></span>
<span><span>  operation_2();</span></span>
<span><span>  operation_3();</span></span>
<span><span>  ...</span></span></code></pre>
<p>There are simply no explicit yield operations; instead, the kernel utilizes timers and interrupts to seamlessly switch between threads on the same core. This is precisely what we’ll implement in this experiment.</p>
<p>When multiple workloads run on the same resource, and each retains the same programming model as if it were the only workload, we can say the resource is virtualized. In other words, if we’re running 5 threads on the same core, each thread “feels” like it has its own core, effectively running on 5 little cores instead of 1 big core. More formally, each thread retains its own view of the core’s architectural registers (in RISC-V, <code>x0-x31</code> and some CSRs, more on this below) and… some memory! Let’s look deeper into that.</p>
<h3 id="the-stack-and-memory-virtualization">The stack and memory virtualization</h3>
<p>To begin, a thread has its own stack for reasons we’ll analyze shortly. The rest of the memory is “shared” with other threads, but this requires further investigation.</p>
<p>It’s important to understand that hardware virtualization exists on a spectrum, rather than as a few rigid options. Here are some of the options for virtualization:</p>
<ol>
<li>Threads: virtualizes architectural registers and stacks, but not much else; i.e., different threads can share data elsewhere in memory.</li>
<li>Process: more heavyweight than threads, memory is virtualized such that each process “feels” like it has a dedicated CPU core and its own memory untouchable by other processes; additionally, a process houses multiple threads.</li>
<li>Container: virtualizes even more - each container has its own filesystem and potentially its own set of network interfaces; containers share the same kernel and underlying hardware.</li>
<li>VM: virtualizes everything.</li>
</ol>
<p>There are many more shades in between, and each of these options likely has different subtypes. The point here is that all these approaches enable running different workloads with varying isolations, or more intuitively, different <em>views</em> of the machine and their environment.</p>
<p>Interestingly, if you examine the Linux kernel source code, you won’t find a construct explicitly called a <em>container</em>. What we popularly call containers isn’t a mechanism baked into the kernel, but rather <strong>a set of kernel mechanisms</strong> used together to form a specific view of the environment for our workload. For example, the <code>chroot</code> mechanism restricts filesystem visibility, while <code>cgroups</code> impose limits on workloads; together, these form what we call a container.</p>
<p>Furthermore, I believe (though don’t quote me on this) that the boundaries between threads and processes in Linux are somewhat blurred. To the best of my knowledge, both are implemented on top of <em>tasks</em> in the kernel, but when creating a task, the API allows different restrictions to be specified.</p>
<p>Ultimately, this is all to say that we’re always defining a workload with varying restrictions on what it can see and access. When and why to apply different restrictions is a topic for another day. Many questions arise when writing an application, ranging from the difficulty of an approach to its security.</p>
<h3 id="virtualizing-a-thread">Virtualizing a thread</h3>
<p>In this experiment, we’ll implement minimal virtualization with very basic, time-sharing threads. Therefore, the goals are the following:</p>
<ol>
<li>The programming model for a thread should remain mostly untouched. As long as a thread doesn’t interact with memory contents used by other threads, its programming model should remain consistent, powered by time-sharing.</li>
<li>A thread should have its own protected view of architectural registers, including some RISC-V CSRs.</li>
<li>A thread should be assigned its own stack.</li>
</ol>
<p>It should be obvious why a thread needs its own view of the registers. If other threads could freely touch a thread’s registers, the thread wouldn’t be able to do any meaningful work. All (I believe) RISC-V instructions work with at least one register, so protecting a thread’s register view is essential.</p>
<p>Furthermore, assigning a private stack to a thread is necessary, though slightly less obvious. The answer is that different stacks are needed to manage different execution contexts. Namely, when a function is invoked, by convention, the stack is used to allocate function-private variables. Additionally, registers like <code>ra</code> can be pushed to the stack to retain the correct return address from a function (in case another function is invoked within it). In short, there are various reasons, per RISC-V convention, why the stack is needed to maintain the execution context. The details of RISC-V calling conventions will not be described here.</p>
<h3 id="interrupt-context">Interrupt context</h3>
<p>It’s crucial to understand how interrupt code runs and what it should consist of, as this mechanism will be heavily exploited to achieve seamless time-sharing between threads. For a detailed, practical example, please check out <a href="https://popovicu.com/posts/risc-v-interrupts-with-timer-example/">this past text</a>.</p>
<p>I’ll briefly include the assembly for the timer interrupt routine from that text:</p>
<pre is:raw="" tabindex="0"><code><span><span>s_mode_interrupt_handler:</span></span>
<span><span>        addi    </span><span>sp</span><span>,</span><span>sp</span><span>,-</span><span>144</span></span>
<span><span>        sd      ra,</span><span>136</span><span>(</span><span>sp</span><span>)</span></span>
<span><span>        sd      t0,</span><span>128</span><span>(</span><span>sp</span><span>)</span></span>
<span><span>        sd      t1,</span><span>120</span><span>(</span><span>sp</span><span>)</span></span>
<span><span>        sd      t2,</span><span>112</span><span>(</span><span>sp</span><span>)</span></span>
<span><span>        sd      s0,</span><span>104</span><span>(</span><span>sp</span><span>)</span></span>
<span><span>        sd      a0,</span><span>96</span><span>(</span><span>sp</span><span>)</span></span>
<span><span>        sd      a1,</span><span>88</span><span>(</span><span>sp</span><span>)</span></span>
<span><span>        sd      a2,</span><span>80</span><span>(</span><span>sp</span><span>)</span></span>
<span><span>        sd      a3,</span><span>72</span><span>(</span><span>sp</span><span>)</span></span>
<span><span>        sd      a4,</span><span>64</span><span>(</span><span>sp</span><span>)</span></span>
<span><span>        sd      a5,</span><span>56</span><span>(</span><span>sp</span><span>)</span></span>
<span><span>        sd      a6,</span><span>48</span><span>(</span><span>sp</span><span>)</span></span>
<span><span>        sd      a7,</span><span>40</span><span>(</span><span>sp</span><span>)</span></span>
<span><span>        sd      t3,</span><span>32</span><span>(</span><span>sp</span><span>)</span></span>
<span><span>        sd      t4,</span><span>24</span><span>(</span><span>sp</span><span>)</span></span>
<span><span>        sd      t5,</span><span>16</span><span>(</span><span>sp</span><span>)</span></span>
<span><span>        sd      </span><span>t6</span><span>,</span><span>8</span><span>(</span><span>sp</span><span>)</span></span>
<span><span>        addi    s0,</span><span>sp</span><span>,</span><span>144</span></span>
<span><span>        </span><span>call</span><span>    clear_timer_pending_bit</span></span>
<span><span>        </span><span>call</span><span>    set_timer_in_near_future</span></span>
<span><span>        li      a1,</span><span>33</span></span>
<span><span>        lla     a0,.LC0</span></span>
<span><span>        </span><span>call</span><span>    debug_print</span></span>
<span><span>        </span><span>nop</span></span>
<span><span>        ld      ra,</span><span>136</span><span>(</span><span>sp</span><span>)</span></span>
<span><span>        ld      t0,</span><span>128</span><span>(</span><span>sp</span><span>)</span></span>
<span><span>        ld      t1,</span><span>120</span><span>(</span><span>sp</span><span>)</span></span>
<span><span>        ld      t2,</span><span>112</span><span>(</span><span>sp</span><span>)</span></span>
<span><span>        ld      s0,</span><span>104</span><span>(</span><span>sp</span><span>)</span></span>
<span><span>        ld      a0,</span><span>96</span><span>(</span><span>sp</span><span>)</span></span>
<span><span>        ld      a1,</span><span>88</span><span>(</span><span>sp</span><span>)</span></span>
<span><span>        ld      a2,</span><span>80</span><span>(</span><span>sp</span><span>)</span></span>
<span><span>        ld      a3,</span><span>72</span><span>(</span><span>sp</span><span>)</span></span>
<span><span>        ld      a4,</span><span>64</span><span>(</span><span>sp</span><span>)</span></span>
<span><span>        ld      a5,</span><span>56</span><span>(</span><span>sp</span><span>)</span></span>
<span><span>        ld      a6,</span><span>48</span><span>(</span><span>sp</span><span>)</span></span>
<span><span>        ld      a7,</span><span>40</span><span>(</span><span>sp</span><span>)</span></span>
<span><span>        ld      t3,</span><span>32</span><span>(</span><span>sp</span><span>)</span></span>
<span><span>        ld      t4,</span><span>24</span><span>(</span><span>sp</span><span>)</span></span>
<span><span>        ld      t5,</span><span>16</span><span>(</span><span>sp</span><span>)</span></span>
<span><span>        ld      </span><span>t6</span><span>,</span><span>8</span><span>(</span><span>sp</span><span>)</span></span>
<span><span>        addi    </span><span>sp</span><span>,</span><span>sp</span><span>,</span><span>144</span></span>
<span><span>        sret</span></span></code></pre>
<p>This assembly was obtained by writing a C function tagged as an S-level interrupt in RISC-V. With this tag, the GCC compiler knew how to generate the <em>prologue</em> and <em>epilogue</em> of the interrupt routine. The prologue preserves architectural registers on the stack, and the epilogue recovers them (in addition to specifically returning from S-mode). All of this was generated by correctly tagging the C function’s invoking convention.</p>
<p>This somewhat resembles function calling, and that’s essentially what it is. Interrupts can be thought of (in a very simplified sense) as functions invoked by some system effect. Consequently, utilized registers must be carefully preserved on the stack and then restored at the routine’s exit; otherwise, asynchronous interrupts like timer interrupts would randomly corrupt architectural register values, completely blocking any practical software from running!</p>
<h2 id="implementation-high-level">Implementation (high-level)</h2>
<p>We’ll explore the implementation by first describing the high-level idea and then digging into the code.</p>
<h3 id="leveraging-the-interrupt-stack-convention">Leveraging the interrupt stack convention</h3>
<p>Adding an interrupt is, in a way, already introducing a form of threading to your application code. In a system with a timer interrupt, the main application code runs, which can occasionally be interleaved with instances of timer interrupt invocations. The core jumps to this interrupt routine when the timer signals, and it carefully restores the architectural state before control flow returns to the “main thread”. There are two control flows running concurrently here:</p>
<ol>
<li>Main application code.</li>
<li>Repetitions of the interrupt routine.</li>
</ol>
<p>This interleaving of the timer interrupt can be leveraged to implement additional control flows, and the main idea is outlined below.</p>
<p>The core of the interrupt routine is sandwiched between the prologue and the epilogue. That’s where the interrupt is serviced before control returns to the main application thread by restoring registers from the stack.</p>
<p>However, <strong>why must we restore the registers from the same stack location</strong>? If our interrupt logic swaps the stack pointer to some other piece of memory, we’ll end up with a different set of architectural register values recovered, thus entering a whole different flow. In other words, we achieve a <strong>context switch</strong>, and this is precisely how it’s implemented in this experiment. We’ll see the code for it shortly.</p>
<h3 id="kerneluser-space-separation">Kernel/user space separation</h3>
<p>We can now delineate the kernel space and user space. With RISC-V, this naturally translates to kernel code running in supervisor (S) mode and user space code running in U-mode.</p>
<p>The machine boots into machine (M) mode, and since we want to leverage the SBI layer, we’ll allow OpenSBI to run there. Then, the kernel will perform some initial setup in S-mode before starting the U-mode execution of user space threads. Periodic timer interrupts will enable context switches, and the interrupt code will execute in S-mode. Finally, user threads will be able to make system calls to the kernel.</p>
<h2 id="implementation-code">Implementation (code)</h2>
<p>Please refer to the GitHub repository for the full code; we will only cover core excerpts below.</p>
<h3 id="assembly-startup">Assembly startup</h3>
<p>As usual, a short assembly snippet is needed to start our S-mode code and enter the “main program” in Zig. This is in <code>startup.S</code>.</p>
<pre is:raw="" tabindex="0"><code><span><span>...</span></span>
<span><span>done_bss:</span></span>
<span></span>
<span><span>   </span><span> # Jump to Zig main</span></span>
<span><span>    </span><span>call</span><span> main</span></span>
<span><span>...</span></span></code></pre>
<p>The rest of the assembly startup primarily involves cleaning up the BSS section and setting up the stack pointer for the initial kernel code.</p>
<h3 id="main-kernel-file-and-io-drivers">Main kernel file and I/O drivers</h3>
<p>We’ll now examine <code>kernel.zig</code>, which contains the <code>main</code> function.</p>
<p>First, we probe the OpenSBI layer for console capabilities. We’ll only consider running on a relatively recent version of OpenSBI (from the last few years) that includes console capability. Otherwise, the kernel will halt and report an error.</p>
<pre is:raw="" tabindex="0"><code><span><span>export fn main() void {</span></span>
<span><span>    const initial_print_status = sbi.debug_print(BOOT_MSG);</span></span>
<span><span></span></span>
<span><span>    if (initial_print_status.sbi_error != 0) {</span></span>
<span><span>        // SBI debug console not available, fall back to direct UART</span></span>
<span><span>        const error_msg = &#34;ERROR: OpenSBI debug console not available! You need the latest OpenSBI.\n&#34;;</span></span>
<span><span>        const fallback_msg = &#34;Falling back to direct UART at 0x10000000...\n&#34;;</span></span>
<span><span></span></span>
<span><span>        uart.uart_write_string(error_msg);</span></span>
<span><span>        uart.uart_write_string(fallback_msg);</span></span>
<span><span>        uart.uart_write_string(&#34;Stopping... We rely on OpenSBI, cannot continue.\n&#34;);</span></span>
<span><span></span></span>
<span><span>        while (true) {</span></span>
<span><span>            asm volatile (&#34;wfi&#34;);</span></span>
<span><span>        }</span></span>
<span><span></span></span>
<span><span>        unreachable;</span></span>
<span><span>    }</span></span></code></pre>
<p><code>main</code> is marked as <code>export</code> to conform to the C ABI.</p>
<p>Here, we have a lightweight implementation of a couple of I/O drivers. As you can see, writing can occur in one of two ways: either we go through the SBI layer (<code>sbi.zig</code>) or, if that fails, we use direct MMIO (<code>uart_mmio.zig</code>). The SBI method should theoretically be more portable, as it delegates output management details to the M-level layer (essentially what we do with MMIO), freeing us from concerns about exact memory space addresses.</p>
<p>Let’s quickly look at <code>sbi.zig</code>:</p>
<pre is:raw="" tabindex="0"><code><span><span>// Struct containing the return status of OpenSBI</span></span>
<span><span>pub const SbiRet = struct {</span></span>
<span><span>    sbi_error: isize,</span></span>
<span><span>    value: isize,</span></span>
<span><span>};</span></span>
<span><span></span></span>
<span><span>pub fn debug_print(message: []const u8) SbiRet {</span></span>
<span><span>    var err: isize = undefined;</span></span>
<span><span>    var val: isize = undefined;</span></span>
<span><span></span></span>
<span><span>    const msg_ptr = @intFromPtr(message.ptr);</span></span>
<span><span>    const msg_len = message.len;</span></span>
<span><span></span></span>
<span><span>    asm volatile (</span></span>
<span><span>        \\mv a0, %[len]</span></span>
<span><span>        \\mv a1, %[msg]</span></span>
<span><span>        \\li a2, 0</span></span>
<span><span>        \\li a6, 0x00</span></span>
<span><span>        \\li a7, 0x4442434E</span></span>
<span><span>        \\ecall</span></span>
<span><span>        \\mv %[err], a0</span></span>
<span><span>        \\mv %[val], a1</span></span>
<span><span>        : [err] &#34;=r&#34; (err),</span></span>
<span><span>          [val] &#34;=r&#34; (val),</span></span>
<span><span>        : [msg] &#34;r&#34; (msg_ptr),</span></span>
<span><span>          [len] &#34;r&#34; (msg_len),</span></span>
<span><span>        : .{ .x10 = true, .x11 = true, .x12 = true, .x16 = true, .x17 = true, .memory = true });</span></span>
<span><span></span></span>
<span><span>    return SbiRet{</span></span>
<span><span>        .sbi_error = err,</span></span>
<span><span>        .value = val,</span></span>
<span><span>    };</span></span>
<span><span>}</span></span></code></pre>
<p>This is very straightforward; we’re simply performing the system call exactly as described in the OpenSBI documentation. Note that when I first wrote this code, I wasn’t fully familiar with Zig’s error handling capabilities, hence the somewhat non-idiomatic error handling.</p>
<p>However, this can be considered a first driver in this kernel, as it directly manages output to the device.</p>
<p>Next is <code>uart_mmio.zig</code>:</p>
<pre is:raw="" tabindex="0"><code><span><span>// UART MMIO address (standard for QEMU virt machine)</span></span>
<span><span>pub const UART_BASE: usize = 0x10000000;</span></span>
<span><span>pub const UART_TX: *volatile u8 = @ptrFromInt(UART_BASE);</span></span>
<span><span></span></span>
<span><span>// Direct UART write function (fallback when SBI is not available)</span></span>
<span><span>pub fn uart_write_string(message: []const u8) void {</span></span>
<span><span>    for (message) |byte| {</span></span>
<span><span>        UART_TX.* = byte;</span></span>
<span><span>    }</span></span>
<span><span>}</span></span></code></pre>
<p>This is straightforward and self-explanatory.</p>
<p>Returning to <code>kernel.zig</code> and the <code>main</code> function, we create 3 user threads, each printing a slightly different message (the thread ID is the varying bit). At this point, the kernel setup is almost complete.</p>
<p>The final steps involve setting up and running the timer interrupt. Once that is done, kernel code will only run when the timer interrupts the system or when user space code requests a system call.</p>
<pre is:raw="" tabindex="0"><code><span><span>interrupts.setup_s_mode_interrupt(&amp;s_mode_interrupt_handler);</span></span>
<span><span>_ = timer.set_timer_in_near_future();</span></span>
<span><span>timer.enable_s_mode_timer_interrupt();</span></span></code></pre>
<p>We could request a context switch immediately, but for simplicity, we’ll wait until the timer activates and begins the actual work in the system.</p>
<h3 id="s-mode-handler-and-the-context-switch">S-mode handler and the context switch</h3>
<p>While the Zig compiler could generate the adequate prologue and epilogue for our S-mode handler, we will do it manually. The reason is that we also want to capture some CSRs in the context that otherwise wouldn’t have been captured by the generated routine.</p>
<p>That’s why we use the <code>naked</code> calling convention in Zig. This forces us to write the entire function in assembly, though a quick escape hatch to this limitation is to call a Zig function whenever Zig logic is needed.</p>
<p>I won’t copy paste the whole prologue and epilogue here because they are very similar to what was done in the previous C experiment with RISC-V interrupts. Instead, I’ll just focus on the bit that is different:</p>
<pre is:raw="" tabindex="0"><code><span><span>...</span></span>
<span><span>        // Save S-level CSRs (using x5 as a temporary register)</span></span>
<span><span>        \\csrr x5, sstatus</span></span>
<span><span>        \\sd x5, </span><span>240</span><span>(</span><span>sp</span><span>)</span></span>
<span><span>        \\csrr x5, sepc</span></span>
<span><span>        \\sd x5, </span><span>248</span><span>(</span><span>sp</span><span>)</span></span>
<span><span>        \\csrr x5, scause</span></span>
<span><span>        \\sd x5, </span><span>256</span><span>(</span><span>sp</span><span>)</span></span>
<span><span>        \\csrr x5, stval</span></span>
<span><span>        \\sd x5, </span><span>264</span><span>(</span><span>sp</span><span>)</span></span>
<span></span>
<span><span>        // </span><span>Call</span><span> handle_kernel</span></span>
<span><span>        \\mv a0, </span><span>sp</span></span>
<span><span>        \\</span><span>call</span><span> handle_kernel</span></span>
<span><span>        \\mv </span><span>sp</span><span>, a0</span></span>
<span></span>
<span><span>        // </span><span>Epilogue:</span><span> Restore context</span></span>
<span><span>        // Restore S-level CSRs (using x5 as a temporary register)</span></span>
<span><span>        \\ld x5, </span><span>264</span><span>(</span><span>sp</span><span>)</span></span>
<span><span>        \\csrw stval, x5</span></span>
<span><span>        \\ld x5, </span><span>256</span><span>(</span><span>sp</span><span>)</span></span>
<span><span>        \\csrw scause, x5</span></span>
<span><span>        \\ld x5, </span><span>248</span><span>(</span><span>sp</span><span>)</span></span>
<span><span>        \\csrw sepc, x5</span></span>
<span><span>        \\ld x5, </span><span>240</span><span>(</span><span>sp</span><span>)</span></span>
<span><span>        \\csrw sstatus, x5</span></span>
<span><span>...</span></span></code></pre>
<p>As you can see, a couple more registers were added to the prologue and epilogue in addition to the core architectural registers.</p>
<p>Next, within this prologue/epilogue sandwich, we invoke the <code>handle_kernel</code> Zig function. This routes to the correct logic based on whether the interrupt source is a synchronous system call from user space or an asynchronous timer interrupt. The reason is that we land in the same S-level interrupt routine regardless of the interrupt source, and then we inspect the <code>scause</code> CSR for details.</p>
<p>To successfully work with the <code>handle_kernel</code> function, we need to be aware of the assembly-level calling conventions. This function takes a single integer parameter and returns a single integer parameter. Since the function signature is small, it works as simply as this:</p>
<ol>
<li>The sole function parameter is passed through the <code>a0</code> architectural register.</li>
<li>The same register also holds the function’s result upon return.</li>
</ol>
<p>This is pretty easy. Let’s quickly look at the signature of this function:</p>
<pre is:raw="" tabindex="0"><code><span><span>export fn handle_kernel(current_stack: usize) usize {</span></span>
<span><span>...</span></span></code></pre>
<p>It is slightly awkward but gets the job done. The input to this Zig logic is the stack top before invoking the Zig logic (which inevitably leads to some data added to the stack). The function’s output is where the stack top should be <em>after</em> the Zig logic is done. If it differs from the input, then we’re performing a context switch. If it’s the same, the same workload thread will continue running after the interrupt.</p>
<p>The rest of the logic is very simple. It inspects the interrupt source (system call from user space or timer interrupt) and performs accordingly.</p>
<p>In the case of a timer interrupt, a context switch is performed. The <code>schedule</code> function from <code>scheduling.zig</code> is invoked, and it potentially returns the other stack we should switch to:</p>
<pre is:raw="" tabindex="0"><code><span><span>const build_options = @import(&#34;build_options&#34;);</span></span>
<span><span>const sbi = @import(&#34;sbi&#34;);</span></span>
<span><span>const std = @import(&#34;std&#34;);</span></span>
<span><span>const thread = @import(&#34;thread&#34;);</span></span>
<span><span></span></span>
<span><span>pub fn schedule(current_stack: usize) usize {</span></span>
<span><span>    const maybe_current_thread = thread.getCurrentThread();</span></span>
<span><span></span></span>
<span><span>    if (maybe_current_thread) |current_thread| {</span></span>
<span><span>        current_thread.sp_save = current_stack;</span></span>
<span><span></span></span>
<span><span>        if (comptime build_options.enable_debug_logs) {</span></span>
<span><span>            _ = sbi.debug_print(&#34;[I] Enqueueing the current thread\n&#34;);</span></span>
<span><span>        }</span></span>
<span><span>        thread.enqueueReady(current_thread);</span></span>
<span><span>    } else {</span></span>
<span><span>        if (comptime build_options.enable_debug_logs) {</span></span>
<span><span>            _ = sbi.debug_print(&#34;[W] NO CURRENT THREAD AVAILABLE!\n&#34;);</span></span>
<span><span>        }</span></span>
<span><span>    }</span></span>
<span><span></span></span>
<span><span>    const maybe_new_thread = thread.dequeueReady();</span></span>
<span><span></span></span>
<span><span>    if (maybe_new_thread) |new_thread| {</span></span>
<span><span>        // TODO: software interrupt to yield to the user thread</span></span>
<span><span></span></span>
<span><span>        if (comptime build_options.enable_debug_logs) {</span></span>
<span><span>            _ = sbi.debug_print(&#34;Yielding to the new thread\n&#34;);</span></span>
<span><span>        }</span></span>
<span><span></span></span>
<span><span>        thread.setCurrentThread(new_thread);</span></span>
<span><span></span></span>
<span><span>        if (comptime build_options.enable_debug_logs) {</span></span>
<span><span>            var buffer: [256]u8 = undefined;</span></span>
<span><span>            const content = std.fmt.bufPrint(&amp;buffer, &#34;New thread ID: {d}, stack top: {x}\n&#34;, .{ new_thread.id, new_thread.sp_save }) catch {</span></span>
<span><span>                return 0; // Return bogus stack, should be more robust in reality</span></span>
<span><span>            };</span></span>
<span><span>            _ = sbi.debug_print(content);</span></span>
<span><span>        }</span></span>
<span><span></span></span>
<span><span>        return new_thread.sp_save;</span></span>
<span><span>    }</span></span>
<span><span></span></span>
<span><span>    _ = sbi.debug_print(&#34;NO NEW THREAD AVAILABLE!\n&#34;);</span></span>
<span><span></span></span>
<span><span>    while (true) {</span></span>
<span><span>        asm volatile (&#34;wfi&#34;);</span></span>
<span><span>    }</span></span>
<span><span>    unreachable;</span></span>
<span><span>}</span></span></code></pre>
<p>The code from the <code>thread</code> module is very simple, serving as boilerplate for a basic queue that manages structs representing threads. I won’t copy it here, as it’s mostly AI-generated. It is important to note, however, that the stacks are statically allocated in memory, and the maximum number of running threads is hardcoded.</p>
<p>The <code>thread</code> module also includes logic for setting up a new thread. This is where data is pushed onto the stack before the thread even runs. If you wonder why, it’s because when returning from the S-level trap handler, we need <em>something</em> on the stack to indicate where to go. The initial data does precisely that. We can seed the initial register values here as desired. In fact, in this experiment, we demonstrate passing a single integer parameter to the thread function by seeding the <code>a0</code> register value (per calling convention) on the stack, which the thread function can then use immediately.</p>
<h3 id="the-user-space-threads">The user space threads</h3>
<p>As mentioned in the introduction, we’ll bundle the user space and kernel space code into a single binary blob to avoid dynamic loading, linking, and other complexities. Hence, our user space code consists of regular functions:</p>
<pre is:raw="" tabindex="0"><code><span><span>/// Example: Create a simple idle thread</span></span>
<span><span>pub fn createPrintingThread(thread_number: usize) !*Thread {</span></span>
<span><span>    const thread = allocThread() orelse return error.NoFreeThreads;</span></span>
<span><span></span></span>
<span><span>    // Idle thread just spins</span></span>
<span><span>    const print_fn = struct {</span></span>
<span><span>        fn print(thread_arg: usize) noreturn {</span></span>
<span><span>            while (true) {</span></span>
<span><span>                var buffer: [256]u8 = undefined;</span></span>
<span><span>                const content = std.fmt.bufPrint(&amp;buffer, &#34;Printing from thread ID: {d}\n&#34;, .{thread_arg}) catch {</span></span>
<span><span>                    continue;</span></span>
<span><span>                };</span></span>
<span><span></span></span>
<span><span>                syscall.debug_print(content);</span></span>
<span><span></span></span>
<span><span>                // Simulate a delay</span></span>
<span><span>                var i: u32 = 0;</span></span>
<span><span>                while (i &lt; 300000000) : (i += 1) {</span></span>
<span><span>                    asm volatile (&#34;&#34; ::: .{ .memory = true }); // Memory barrier to prevent optimization</span></span>
<span><span>                }</span></span>
<span><span>            }</span></span>
<span><span>            unreachable;</span></span>
<span><span>        }</span></span>
<span><span>    }.print;</span></span>
<span><span></span></span>
<span><span>    initThread(thread, @intFromPtr(&amp;print_fn), thread_number);</span></span>
<span><span>    return thread;</span></span>
<span><span>}</span></span></code></pre>
<p>Additionally, as mentioned above, we pre-seeded the stack such that when <code>a0</code> is recovered from the stack upon the first interrupt return for a given thread, the function argument will be picked up. That’s how the <code>print</code> function accesses the <code>thread_arg</code> value and uses it in its logic.</p>
<p>To demonstrate the user/kernel boundary, we have <code>syscall.debug_print(content);</code>. This conceptually behaves more or less as <code>printf</code> from <code>stdio.h</code> in C. It performs prepares the arguments to the kernel and runs a system call with these arguments which should lead to some content getting printed on the output device. Here’s what the printing library looks like (from <code>syscall.zig</code>):</p>
<pre is:raw="" tabindex="0"><code><span><span>// User-level debug_print function</span></span>
<span><span>pub fn debug_print(message: []const u8) void {</span></span>
<span><span>    const msg_ptr = @intFromPtr(message.ptr);</span></span>
<span><span>    const msg_len = message.len;</span></span>
<span><span></span></span>
<span><span>    // Let&#39;s say syscall number 64</span></span>
<span><span>    // a7 = syscall number</span></span>
<span><span>    // a0 = message pointer</span></span>
<span><span>    // a1 = message length</span></span>
<span><span>    asm volatile (</span></span>
<span><span>        \\mv a0, %[msg]</span></span>
<span><span>        \\mv a1, %[len]</span></span>
<span><span>        \\li a7, 64</span></span>
<span><span>        \\ecall</span></span>
<span><span>        :</span></span>
<span><span>        : [msg] &#34;r&#34; (msg_ptr),</span></span>
<span><span>          [len] &#34;r&#34; (msg_len),</span></span>
<span><span>        : .{ .x10 = true, .x11 = true, .x17 = true, .memory = true });</span></span>
<span><span></span></span>
<span><span>    // Ignore return value for simplicity</span></span>
<span><span>}</span></span></code></pre>
<p>System call 64 is served from the S-mode handler in <code>kernel.zig</code>. This is self-explanatory, and we won’t go into further details here.</p>
<h3 id="running-the-kernel">Running the kernel</h3>
<p>We will deploy the kernel on bare-metal, specifically on a virtual machine. In theory, this should also work on a real machine, provided an SBI layer is present when the kernel starts, and the linker script, I/O “drivers,” and other machine-specific constants are adapted.</p>
<p>To build, we simply run</p>
<pre is:raw="" tabindex="0"><code><span><span>zig</span><span> </span><span>build</span></span></code></pre>
<p>To now run the kernel, we run:</p>
<pre is:raw="" tabindex="0"><code><span><span>qemu-system-riscv64</span><span> </span><span>-machine</span><span> </span><span>virt</span><span> </span><span>-nographic</span><span> </span><span>-bios</span><span> </span><span>/tmp/opensbi/build/platform/generic/firmware/fw_dynamic.bin</span><span> </span><span>-kernel</span><span> </span><span>zig-out/bin/kernel</span></span></code></pre>
<p>Refer to the <a href="https://popovicu.com/posts/risc-v-sbi-and-full-boot-process">previous text on OpenSBI</a> for details on building OpenSBI. It is strongly recommended to use a freshly built OpenSBI, as QEMU may use an outdated version if no <code>-bios</code> flag is passed.</p>
<p>The output should begin with a big OpenSBI splash along with some OpenSBI data:</p>
<pre is:raw="" tabindex="0"><code><span><span>OpenSBI v1.7</span></span>
<span><span>   ____                    _____ ____ _____</span></span>
<span><span>  / __ \                  / ____|  _ \_   _|</span></span>
<span><span> | |  | |_ __   ___ _ __ | (___ | |_) || |</span></span>
<span><span> | |  | | &#39;_ \ / _ \ &#39;_ \ \___ \|  _ &lt; | |</span></span>
<span><span> | |__| | |_) |  __/ | | |____) | |_) || |_</span></span>
<span><span>  \____/| .__/ \___|_| |_|_____/|____/_____|</span></span>
<span><span>        | |</span></span>
<span><span>        |_|</span></span>
<span><span></span></span>
<span><span>Platform Name               : riscv-virtio,qemu</span></span>
<span><span>Platform Features           : medeleg</span></span>
<span><span>Platform HART Count         : 1</span></span>
<span><span>Platform IPI Device         : aclint-mswi</span></span>
<span><span>Platform Timer Device       : aclint-mtimer @ 10000000Hz</span></span>
<span><span>Platform Console Device     : uart8250</span></span>
<span><span>Platform HSM Device         : ---</span></span>
<span><span>Platform PMU Device         : ---</span></span>
<span><span>Platform Reboot Device      : syscon-reboot</span></span>
<span><span>Platform Shutdown Device    : syscon-poweroff</span></span>
<span><span>Platform Suspend Device     : ---</span></span>
<span><span>Platform CPPC Device        : ---</span></span>
<span><span>Firmware Base               : 0x80000000</span></span>
<span><span>Firmware Size               : 317 KB</span></span>
<span><span>Firmware RW Offset          : 0x40000</span></span>
<span><span>Firmware RW Size            : 61 KB</span></span>
<span><span>Firmware Heap Offset        : 0x46000</span></span>
<span><span>Firmware Heap Size          : 37 KB (total), 2 KB (reserved), 11 KB (used), 23 KB (free)</span></span>
<span><span>Firmware Scratch Size       : 4096 B (total), 400 B (used), 3696 B (free)</span></span>
<span><span>Runtime SBI Version         : 3.0</span></span>
<span><span>Standard SBI Extensions     : time,rfnc,ipi,base,hsm,srst,pmu,dbcn,fwft,legacy,dbtr,sse</span></span>
<span><span>Experimental SBI Extensions : none</span></span>
<span><span></span></span>
<span><span>Domain0 Name                : root</span></span>
<span><span>....</span></span></code></pre>
<p>Following the OpenSBI splash, we’ll see the kernel output:</p>
<pre is:raw="" tabindex="0"><code><span><span>Booting the kernel...</span></span>
<span><span>Printing from thread ID: 0</span></span>
<span><span>Printing from thread ID: 0</span></span>
<span><span>Printing from thread ID: 0</span></span>
<span><span>Printing from thread ID: 1</span></span>
<span><span>Printing from thread ID: 1</span></span>
<span><span>Printing from thread ID: 1</span></span>
<span><span>Printing from thread ID: 2</span></span>
<span><span>Printing from thread ID: 2</span></span>
<span><span>Printing from thread ID: 2</span></span>
<span><span>Printing from thread ID: 0</span></span>
<span><span>Printing from thread ID: 0</span></span>
<span><span>Printing from thread ID: 1</span></span>
<span><span>Printing from thread ID: 1</span></span>
<span><span>Printing from thread ID: 2</span></span>
<span><span>Printing from thread ID: 2</span></span>
<span><span>Printing from thread ID: 0</span></span>
<span><span>Printing from thread ID: 0</span></span>
<span><span>Printing from thread ID: 0</span></span>
<span><span>Printing from thread ID: 1</span></span>
<span><span>Printing from thread ID: 1</span></span>
<span><span>Printing from thread ID: 1</span></span>
<span><span>Printing from thread ID: 2</span></span>
<span><span>Printing from thread ID: 2</span></span>
<span><span>Printing from thread ID: 2</span></span></code></pre>
<p>The prints will continue running until QEMU is terminated.</p>
<p>If you want to build the kernel in an extremely verbose mode for debugging and experimentation, use the following command:</p>
<pre is:raw="" tabindex="0"><code><span><span>zig</span><span> </span><span>build</span><span> </span><span>-Ddebug-logs=true</span></span></code></pre>
<p>After running the kernel with the same QEMU command, the output will appear as follows:</p>
<pre is:raw="" tabindex="0"><code><span><span>Booting the kernel...</span></span>
<span><span>DEBUG mode on</span></span>
<span><span>Interrupt source: Timer, Current stack: 87cffe70</span></span>
<span><span>[W] NO CURRENT THREAD AVAILABLE!</span></span>
<span><span>Yielding to the new thread</span></span>
<span><span>New thread ID: 0, stack top: 80203030</span></span>
<span><span>Interrupt source: Ecall from User mode, Current stack: 80202ec0</span></span>
<span><span>Printing from thread ID: 0</span></span>
<span><span>Interrupt source: Ecall from User mode, Current stack: 80202ec0</span></span>
<span><span>Printing from thread ID: 0</span></span>
<span><span>Interrupt source: Ecall from User mode, Current stack: 80202ec0</span></span>
<span><span>Printing from thread ID: 0</span></span>
<span><span>Interrupt source: Timer, Current stack: 80202ec0</span></span>
<span><span>[I] Enqueueing the current thread</span></span>
<span><span>Yielding to the new thread</span></span>
<span><span>New thread ID: 1, stack top: 80205030</span></span>
<span><span>Interrupt source: Ecall from User mode, Current stack: 80204ec0</span></span>
<span><span>Printing from thread ID: 1</span></span>
<span><span>Interrupt source: Ecall from User mode, Current stack: 80204ec0</span></span>
<span><span>Printing from thread ID: 1</span></span>
<span><span>Interrupt source: Ecall from User mode, Current stack: 80204ec0</span></span>
<span><span>Printing from thread ID: 1</span></span>
<span><span>Interrupt source: Timer, Current stack: 80204ec0</span></span>
<span><span>[I] Enqueueing the current thread</span></span>
<span><span>Yielding to the new thread</span></span>
<span><span>New thread ID: 2, stack top: 80207030</span></span>
<span><span>Interrupt source: Ecall from User mode, Current stack: 80206ec0</span></span>
<span><span>Printing from thread ID: 2</span></span>
<span><span>Interrupt source: Ecall from User mode, Current stack: 80206ec0</span></span>
<span><span>Printing from thread ID: 2</span></span>
<span><span>Interrupt source: Ecall from User mode, Current stack: 80206ec0</span></span>
<span><span>Printing from thread ID: 2</span></span>
<span><span>Interrupt source: Timer, Current stack: 80206ec0</span></span>
<span><span>...</span></span></code></pre>
<h2 id="conclusion">Conclusion</h2>
<p>Many educational OS kernels exist, but this experiment combines RISC-V, OpenSBI, and Zig, offering a fresh perspective compared to traditional C implementations.</p>
<p>The resulting code runs on a QEMU virtual machine, which can be easily set up, even by building QEMU from source.</p>
<p>To keep the explanation concise, error reporting was kept minimal. Should you modify the code and require debugging, sufficient clues are provided, despite some areas where the code is simplified (e.g., anonymous results after SBI print invocations like <code>_ = ...</code>). Much of the code in this example was AI-generated by Claude to save time, and it should function as intended. While some parts of the code are simplified, such as stack space over-allocation, these do not detract from the experiment’s educational value.</p>
<p>Overall, this experiment serves as a starting point for studying operating systems, assuming a foundational understanding of computer engineering and computer architecture. It likely has plenty of flaws for a practical application, but for now, we’re just hacking here!</p>
<p>I hope this was a useful exploration.</p>
<p>Please consider following on <a href="https://twitter.com/popovicu94">Twitter/X</a> and <a href="https://www.linkedin.com/in/upopovic/">LinkedIn</a> to stay updated.</p>
    </article></div>
  </body>
</html>
