<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://news.ycombinator.com/item?id=34100102">Original</a>
    <h1>Ask HN: What is the relevance today of Minsky&#39;s “Society of Mind” concept?</h1>
    
    <div id="readability-page-1" class="page"><div><div><p>Minsky wrote this book in 1986, towards the end of his very long career thinking about how to build intelligent machines. For a basic overview, see:</p><p>https://en.wikipedia.org/wiki/Society_of_Mind</p><p>You can find a complete pdf of the book here:</p><p>http://www.acad.bg/ebook/ml/Society%20of%20Mind.pdf</p><p>My question to the HN community is, has all this work become irrelevant given recent progress in machine learning, particularly with Transformer based models such as GPT-3 or &#34;mixed modality&#34; models such as Gato?</p><p>It seems to me that some of these ideas could make a comeback in the context of a group of interacting models/agents that can pass each other messages. You could have a kind of &#34;top level&#34; master model that responds to a request from a human (e.g., &#34;I just spilled soda on my desk, please help me&#34;) and then figures out a reasonable course of action. Then the master model issues requests to various &#34;specialist models&#34; that are trained on particular kinds of tasks, such as an image based model for exploring an area to look for a sponge, or a feedback control model that is trained to grasp the sponge, etc. Or in a more relevant scenario to how this tech is being widely used today, a GitHub Copilot type agent might have an embedded REPL and then could recruit an &#34;expert debugging&#34; agent which is particularly good at figuring out what caused an error and how to modify the code to avoid the error and fix the bug.</p><p>I suppose the alternative is that we skip this altogether and just train a single enormous Transformer model that does all of this stuff internally, so that it&#39;s all hidden from the user, and everything is learned at the same time during end-to-end training.</p></div></div></div>
  </body>
</html>
