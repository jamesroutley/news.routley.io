<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://gianluca.ai/diffusion-is-frequency-autoregression/">Original</a>
    <h1>Diffusion is autoregression in the frequency domain</h1>
    
    <div id="readability-page-1" class="page"><div><article><div><p>I’ve been riffing on the connections between diffusion models (like DALL-E and Midjourney) and autoregressive models (like GPT, Claude, etc.) as a way to deepen my understanding of both paradigms. I used both in <a href="https://gianluca.ai/table-diffusion">my thesis research</a>.</p><p>I originally posted some ideas on this <a href="https://gianluca.ai/2024-43/#diffusion-is-autoregression-in-frequency-space">here</a> in October 2024.</p><p>This page contains my ongoing notes and favourite resources, which should become even more relevant as DMs and Autoregressors continue to cross-pollinate.</p><hr/><ul><li>In autoregression, we mask one whole value / token / pixel at each step.</li><li>In denoising diffusion models (DDMs), we mask a little bit of each of the values / tokens / pixels at each step.</li><li>Both autoregression and diffusion are about sequentially subtracting information and having a model learn to sequentially restore the information.</li><li>DDMs are autoregressors, but in the steps of a diffusion process not a sequence of tokens.</li><li>Diffusion models are autoregressive, but across noise levels rather than time steps.</li></ul><hr/><blockquote><p>[Diffusion] is a soft version of autoregression in frequency space, or if you want to make it sound fancier, approximate spectral autoregression.</p></blockquote><p>– <a href="https://sander.ai/2024/09/02/spectral-autoregression.html">Diffusion is spectral autoregression</a></p><p><a href="https://x.com/nrehiew_/status/1832412663273464152">wh on X: “A visualization of how I think of diffusion in frequency space Diffusion often generates the low frequencies in the earlier steps before generating the higher frequencies in the later steps</a></p><hr/><blockquote><p>This is interesting as a first large diffusion-based LLM.</p><p>Most of the LLMs you’ve been seeing are ~clones as far as the core modeling approach goes. They’re all trained “autoregressively”, i.e. predicting tokens from left to right. Diffusion is different - it doesn’t go left to right, but all at once. You start with noise and gradually denoise into a token stream.</p><p>Most of the image / video generation AI tools actually work this way and use Diffusion, not Autoregression. It’s only text (and sometimes audio!) that have resisted. So it’s been a bit of a mystery to me and many others why, for some reason, text prefers Autoregression, but images/videos prefer Diffusion. This turns out to be a fairly deep rabbit hole that has to do with the distribution of information and noise and our own perception of them, in these domains. If you look close enough, a lot of interesting connections emerge between the two as well.</p><p>All that to say that this model has the potential to be different, and possibly showcase new, unique psychology, or new strengths and weaknesses. I encourage people to try it out!</p></blockquote><p>– <a href="https://x.com/karpathy/status/1894923254864978091">Andrej Karpathy on X</a> discussing <a href="https://x.com/InceptionAILabs/status/1894847919624462794">Inception Labs’ diffusion LLMs</a></p><hr/><p><a href="https://www.youtube.com/watch?v=zc5NTeJbk-k">Why does diffusion work better than auto-regression</a> (highly recommended, particularly from 8:33 to 13:00)</p><ul><li>Random noise is (near) optimal way of spreading out a selection of pixels to minimise local dependencies.</li><li>DDMs are just like an autoregressor over the pixels, except instead of predicting one entire pixel each step, they predict a small amount of noise over all pixels at each step.</li><li>In autoregression, we mask one whole value/token/pixel at each step.</li><li>In DDMs, we mask a bit of all values/tokens/pixels at each step.</li><li>Both autoregression and diffusion are about sequentially subtracting information and having a model learn to sequentially restore the information.</li><li>“DDMs are autoregressors, but in the steps of the diffusion process”</li><li>“Diffusion models are autoregressive, but across noise levels rather than time steps.”</li><li>Side-note on classifier-free guidance:<ul><li>Train model to generate image both with and without conditional text prompt by alternating between.</li><li>To sample: generate image with prompt and without prompt, difference them, and you get only the parts of the generation that are most dependent on the prompt.</li></ul></li></ul><hr/><p>The crux</p><ul><li>Self-supervised is key to data leverage and avoiding “snowy wolf” problem.</li><li>Predict-then-subtract paradigm is numerically stable and handy.</li></ul><hr/><ul><li><a href="https://gianluca.ai/table-diffusion/#but-why-diffusion-models">https://gianluca.ai/table-diffusion/#but-why-diffusion-models</a></li><li><a href="https://x.com/nbonneel/status/1726635302993944692">https://x.com/nbonneel/status/1726635302993944692</a></li><li><a href="https://mccormickml.com/2022/12/21/how-stable-diffusion-works/">https://mccormickml.com/2022/12/21/how-stable-diffusion-works/</a></li><li><a href="https://jalammar.github.io/illustrated-stable-diffusion/">https://jalammar.github.io/illustrated-stable-diffusion/</a></li><li><a href="https://arxiv.org/pdf/2410.02543">Diffusion models are also evolutionary algorithms</a>.</li></ul><hr/></div></article></div></div>
  </body>
</html>
