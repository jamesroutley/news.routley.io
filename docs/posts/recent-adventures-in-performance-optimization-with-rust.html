<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://willcrichton.net/notes/k-corrset/">Original</a>
    <h1>Recent adventures in performance optimization with Rust</h1>
    
    <div id="readability-page-1" class="page">

<p>This note documents one of my recent adventures in performance
optimization with Rust. By following along, hopefully you’ll learn
something about how to write fast Rust.</p>
<p>Here’s the context: imagine you have data from an online exam where a
set of users answered a set of questions. The raw data looks like
this:</p>
<div id="cb1"><pre><code><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a>[</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a>  {</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a>    <span>&#34;user&#34;</span><span>:</span> <span>&#34;5ea2c2e3-4dc8-4a5a-93ec-18d3d9197374&#34;</span><span>,</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a>    <span>&#34;question&#34;</span><span>:</span> <span>&#34;7d42b17d-77ff-4e0a-9a4d-354ddd7bbc57&#34;</span><span>,</span></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>    <span>&#34;score&#34;</span><span>:</span> <span>1</span></span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>  }<span>,</span></span>
<span id="cb1-7"><a href="#cb1-7" aria-hidden="true" tabindex="-1"></a>  {</span>
<span id="cb1-8"><a href="#cb1-8" aria-hidden="true" tabindex="-1"></a>    <span>&#34;user&#34;</span><span>:</span> <span>&#34;b7746016-fdbf-4f8a-9f84-05fde7b9c07a&#34;</span><span>,</span></span>
<span id="cb1-9"><a href="#cb1-9" aria-hidden="true" tabindex="-1"></a>    <span>&#34;question&#34;</span><span>:</span> <span>&#34;7d42b17d-77ff-4e0a-9a4d-354ddd7bbc57&#34;</span><span>,</span></span>
<span id="cb1-10"><a href="#cb1-10" aria-hidden="true" tabindex="-1"></a>    <span>&#34;score&#34;</span><span>:</span> <span>0</span></span>
<span id="cb1-11"><a href="#cb1-11" aria-hidden="true" tabindex="-1"></a>  }<span>,</span>  </span>
<span id="cb1-12"><a href="#cb1-12" aria-hidden="true" tabindex="-1"></a>  <span>/* ... more data ... */</span></span>
<span id="cb1-13"><a href="#cb1-13" aria-hidden="true" tabindex="-1"></a>]</span></code></pre></div>
<p>Note that each user only answered a subset of all possible questions,
and all scores are either 0 or 1.</p>
<p>Here’s the problem: given a size
<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>k</span></span></span></span>,
which set of
<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>k</mi></mrow><annotation encoding="application/x-tex">k</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>k</span></span></span></span>
questions has the highest correlation with overall performance? We’ll
call this the <strong>k-CorrSet problem</strong>. A simple brute-force
algorithm for solving the k-CorrSet problem looks like this
pseudocode:</p>
<pre><code>func k_corrset($data, $k):
  $all_qs = all questions in $data
  for all $k-sized subsets $qs within $all_qs:
    $us = all users that answered every question in $qs
    $qs_totals = the total score on $qs of each user in $us
    $grand_totals = the grand score on $all_qs of each user in $us
    $r = correlation($qs_totals, $grand_totals)
  return $qs with maximum $r    </code></pre>
<p>We are going to implement several variations on this algorithm to see
how fast we can make it.</p>
<h2 id="python-baseline">Python Baseline</h2>
<p>When I do data analysis, I usually start with Python and then
transition to Rust when I need better speed or memory consumption. So as
a baseline, let’s look at a straightforward <a href="https://pandas.pydata.org/">Pandas</a> program for solving
k-CorrSet:</p>
<div id="cb3"><pre><code><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span>from</span> itertools <span>import</span> combinations</span>
<span id="cb3-2"><a href="#cb3-2" aria-hidden="true" tabindex="-1"></a><span>import</span> pandas <span>as</span> pd</span>
<span id="cb3-3"><a href="#cb3-3" aria-hidden="true" tabindex="-1"></a><span>from</span> pandas <span>import</span> IndexSlice <span>as</span> islice</span>
<span id="cb3-4"><a href="#cb3-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-5"><a href="#cb3-5" aria-hidden="true" tabindex="-1"></a><span>def</span> k_corrset(data, K):</span>
<span id="cb3-6"><a href="#cb3-6" aria-hidden="true" tabindex="-1"></a>    all_qs <span>=</span> data.question.unique()</span>
<span id="cb3-7"><a href="#cb3-7" aria-hidden="true" tabindex="-1"></a>    q_to_score <span>=</span> data.set_index([<span>&#39;question&#39;</span>, <span>&#39;user&#39;</span>])</span>
<span id="cb3-8"><a href="#cb3-8" aria-hidden="true" tabindex="-1"></a>    all_grand_totals <span>=</span> data.groupby(<span>&#39;user&#39;</span>).score.<span>sum</span>().rename(<span>&#39;grand_total&#39;</span>)</span>
<span id="cb3-9"><a href="#cb3-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-10"><a href="#cb3-10" aria-hidden="true" tabindex="-1"></a>    corrs <span>=</span> []</span>
<span id="cb3-11"><a href="#cb3-11" aria-hidden="true" tabindex="-1"></a>    <span>for</span> qs <span>in</span> combinations(all_qs, K):</span>
<span id="cb3-12"><a href="#cb3-12" aria-hidden="true" tabindex="-1"></a>        qs_data <span>=</span> q_to_score.loc[islice[qs,:],:].swaplevel()</span>
<span id="cb3-13"><a href="#cb3-13" aria-hidden="true" tabindex="-1"></a>        answered_all <span>=</span> qs_data.groupby(level<span>=</span>[<span>0</span>]).size() <span>==</span> K</span>
<span id="cb3-14"><a href="#cb3-14" aria-hidden="true" tabindex="-1"></a>        answered_all <span>=</span> answered_all[answered_all].index</span>
<span id="cb3-15"><a href="#cb3-15" aria-hidden="true" tabindex="-1"></a>        qs_totals <span>=</span> qs_data.loc[islice[answered_all,:]] <span>\</span></span>
<span id="cb3-16"><a href="#cb3-16" aria-hidden="true" tabindex="-1"></a>            .groupby(level<span>=</span>[<span>0</span>]).<span>sum</span>().rename(columns<span>=</span>{<span>&#39;score&#39;</span>: <span>&#39;qs&#39;</span>})</span>
<span id="cb3-17"><a href="#cb3-17" aria-hidden="true" tabindex="-1"></a>        r <span>=</span> qs_totals.join(all_grand_totals).corr().qs.grand_total</span>
<span id="cb3-18"><a href="#cb3-18" aria-hidden="true" tabindex="-1"></a>        corrs.append({<span>&#39;qs&#39;</span>: qs, <span>&#39;r&#39;</span>: r})</span>
<span id="cb3-19"><a href="#cb3-19" aria-hidden="true" tabindex="-1"></a>    corrs <span>=</span> pd.DataFrame(corrs)</span>
<span id="cb3-20"><a href="#cb3-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-21"><a href="#cb3-21" aria-hidden="true" tabindex="-1"></a>    <span>return</span> corrs.sort_values(<span>&#39;r&#39;</span>, ascending<span>=</span><span>False</span>).iloc[<span>0</span>].qs</span>
<span id="cb3-22"><a href="#cb3-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb3-23"><a href="#cb3-23" aria-hidden="true" tabindex="-1"></a>data <span>=</span> pd.read_json(<span>&#39;scores.json&#39;</span>)</span>
<span id="cb3-24"><a href="#cb3-24" aria-hidden="true" tabindex="-1"></a><span>print</span>(k_corrset(data, K<span>=</span><span>5</span>))</span></code></pre></div>
<p>This uses a bit of <a href="https://pandas.pydata.org/docs/user_guide/advanced.html">MultiIndex</a>
magic, but don’t sweat the details. Let’s start benchmarking. First, we
need data. To make the benchmark realistic, I generated synthetic data
that roughly matches the properties of my actual data. The properties of
the synthetic data are:</p>
<ul>
<li>60,000 users</li>
<li>200 questions</li>
<li>20% sparsity (i.e., 12,000 users answered each question)</li>
<li>Each score is equally likely 1 or 0</li>
</ul>
<p>Our goal will be to compute k-CorrSet on this dataset for k = 5 in a
reasonable amount of time on my 2021 M1 Macbook Pro. Note that there are
<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mo fence="true">(</mo><mfrac linethickness="0px"><mn>200</mn><mn>5</mn></mfrac><mo fence="true">)</mo></mrow><annotation encoding="application/x-tex">\binom{200}{5}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span><span><span>(</span></span><span><span><span><span><span><span></span><span><span><span>5</span></span></span></span><span><span></span><span><span><span>200</span></span></span></span></span><span>​</span></span><span><span><span></span></span></span></span></span><span><span>)</span></span></span></span></span></span>
= 2.5 billion combinations of questions, so we need the inner loop of
the brute-force algorithm to be quite fast.</p>
<p>Using Python’s <a href="https://docs.python.org/3/library/time.html#time.time"><code>time.time()</code></a>
function, I computed the speed of the inner loop for 1,000 iterations
running with CPython 3.9.17. The average execution time was <strong>36
milliseconds</strong>. Not too bad, but at this rate, the full
computation would complete in <strong>2.9 years</strong>. Let’s make
that faster!</p>
<blockquote>
<p>Note: there are lots of ways we could make the Python code faster,
but the point of this post isn’t to compare highly-optimized Python to
highly-optimized Rust. The point is to compare
“standard-Jupyter-notebook” Python to highly-optimized Rust.</p>
</blockquote>
<h2 id="rust-reimplementation">Rust Reimplementation</h2>
<p>We can start optimizing by reimplementing the Python code into a
roughly equivalent Rust program, expecting some free speedups from
Rust’s compiler optimizations. For readability, all the code below is a
simplification of the actual benchmark. For instance, I will omit
<code>#[derive]</code>s on types, and I will coalesce disparate blocks
of code into straight-line functions. You can see the full benchmark
here: <a href="https://github.com/willcrichton/corrset-benchmark">https://github.com/willcrichton/corrset-benchmark</a></p>
<p>First, we translate the data types:</p>
<div id="cb4"><pre><code><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span>pub</span> <span>struct</span> User(<span>pub</span> <span>String</span>)<span>;</span></span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span>pub</span> <span>struct</span> Question(<span>pub</span> <span>String</span>)<span>;</span></span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a><span>pub</span> <span>struct</span> Row <span>{</span></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a>  <span>pub</span> user<span>:</span> User<span>,</span></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a>  <span>pub</span> question<span>:</span> Question<span>,</span></span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>  <span>pub</span> score<span>:</span> <span>u32</span><span>,</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a><span>}</span></span></code></pre></div>
<p>We make <code>User</code> and <code>Question</code> into newtypes
both for clarity and so we can implement traits on them. Then, the basic
k-CorrSet algorithm is implemented as follows:</p>
<div id="cb5"><pre><code><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span>fn</span> k_corrset(data<span>:</span> <span>&amp;</span>[Row]<span>,</span> k<span>:</span> <span>usize</span>) <span>-&gt;</span> <span>Vec</span><span>&lt;&amp;</span>Question<span>&gt;</span> <span>{</span></span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a>  <span>// utils::group_by(impl Iterator&lt;Item = (K1, K2, V)&gt;) </span></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>  <span>//   -&gt; HashMap&lt;K1, HashMap&lt;K2, V&gt;&gt;;</span></span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a>  <span>let</span> q_to_score<span>:</span> HashMap<span>&lt;&amp;</span>Question<span>,</span> HashMap<span>&lt;&amp;</span>User<span>,</span> <span>u32</span><span>&gt;&gt;</span> <span>=</span> </span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a>    <span>utils::</span>group_by(data<span>.</span>iter()<span>.</span>map(<span>|</span>r<span>|</span> (<span>&amp;</span>r<span>.</span>question<span>,</span> <span>&amp;</span>r<span>.</span>user<span>,</span> r<span>.</span>score)))<span>;</span></span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>  <span>let</span> u_to_score<span>:</span> HashMap<span>&lt;&amp;</span>User<span>,</span> HashMap<span>&lt;&amp;</span>Question<span>,</span> <span>u32</span><span>&gt;&gt;</span> <span>=</span> </span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>    <span>utils::</span>group_by(data<span>.</span>iter()<span>.</span>map(<span>|</span>r<span>|</span> (<span>&amp;</span>r<span>.</span>user<span>,</span> <span>&amp;</span>r<span>.</span>question<span>,</span> r<span>.</span>score)))<span>;</span></span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>  <span>let</span> all_grand_totals<span>:</span> HashMap<span>&lt;&amp;</span>User<span>,</span> <span>u32</span><span>&gt;</span> <span>=</span> </span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    u_to_score<span>.</span>iter()<span>.</span>map(<span>|</span>(user<span>,</span> scores)<span>|</span> <span>{</span></span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>      <span>let</span> total <span>=</span> scores<span>.</span>values()<span>.</span><span>sum::</span><span>&lt;</span><span>u32</span><span>&gt;</span>()<span>;</span></span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>      (<span>*</span>user<span>,</span> total)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    <span>}</span>)</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a>    <span>.</span>collect()<span>;</span></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>  <span>let</span> all_qs <span>=</span> q_to_score<span>.</span>keys()<span>.</span>copied()<span>;</span></span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>  all_qs<span>.</span>combinations(k)</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>    <span>.</span>filter_map(<span>|</span>qs<span>:</span> <span>Vec</span><span>&lt;&amp;</span>Question<span>&gt;|</span> <span>{</span></span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>      <span>let</span> (qs_totals<span>,</span> grand_totals)<span>:</span> (<span>Vec</span><span>&lt;</span>_<span>&gt;,</span> <span>Vec</span><span>&lt;</span>_<span>&gt;</span>) <span>=</span> all_grand_totals<span>.</span>iter()</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>        <span>.</span>filter_map(<span>|</span>(u<span>,</span> grand_total)<span>|</span> <span>{</span></span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>          <span>let</span> q_total <span>=</span> qs<span>.</span>iter()</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>            <span>.</span>map(<span>|</span>q<span>|</span> q_to_score[<span>*</span>q]<span>.</span>get(u)<span>.</span>copied())</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>            <span>.</span><span>sum::</span><span>&lt;</span><span>Option</span><span>&lt;</span><span>u32</span><span>&gt;&gt;</span>()<span>?;</span></span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>          <span>Some</span>((q_total <span>as</span> <span>f64</span><span>,</span> <span>*</span>grand_total <span>as</span> <span>f64</span>))</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>        <span>}</span>)</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>        <span>.</span>unzip()<span>;</span></span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>      <span>// utils::correlation(&amp;[f64], &amp;[f64]) -&gt; f64;</span></span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>      <span>let</span> r <span>=</span> <span>utils::</span>correlation(<span>&amp;</span>qs_totals<span>,</span> <span>&amp;</span>grand_totals)<span>;</span></span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>      (<span>!</span>r<span>.</span>is_nan())<span>.</span>then_some((qs<span>,</span> r))</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>    <span>}</span>)</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>    <span>.</span>max_by_key(<span>|</span>(_<span>,</span> r)<span>|</span> FloatOrd(<span>*</span>r))</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>    <span>.</span>unwrap()<span>.</span><span>0</span></span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a><span>}</span></span></code></pre></div>
<p>The key elements to understand:</p>
<ul>
<li>Like with Python, we convert the flat data into hierarchical data
with a hashmap and the <code>utils::group_by</code> helper. (Note that
everywhere we refer to <code>HashMap</code> is actually an alias for <a href="https://docs.rs/fxhash/0.2.1/fxhash/type.FxHashMap.html"><code>fxhash::FxHashMap</code></a>,
which is just <a href="https://doc.rust-lang.org/stable/std/collections/struct.HashMap.html"><code>std::collections::HashMap</code></a>
with a more efficient hashing algorithm.)</li>
<li>Then we iterate over all combinations of questions using the <a href="https://docs.rs/itertools/0.11.0/itertools/trait.Itertools.html#method.combinations"><code>Itertools::combinations</code></a>
method.</li>
<li>In the inner loop, we iterate over all users via
<code>all_grand_totals.iter()</code>.</li>
<li>The expression <code>q_to_score[*q].get(u).copied()</code> has type
<code>Option&lt;u32&gt;</code>, which is <code>Some(n)</code> if the
user has a score for <code>q</code>, and <code>None</code>
otherwise.</li>
<li>The iterator method <code>.sum::&lt;Option&lt;u32&gt;&gt;()</code>
returns <code>Some(total)</code> if the user answered every question in
<code>qs</code>, and <code>None</code> otherwise.</li>
<li>We call a helper method <code>utils::correlation</code> that
implements a standard calculation for <a href="https://en.wikipedia.org/wiki/Pearson_correlation_coefficient">Pearson’s
<span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mi>r</mi></mrow><annotation encoding="application/x-tex">r</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>r</span></span></span></span></a>.</li>
<li>We use <code>max_by_key</code> to get the questions with the highest
correlation. We use <a href="https://docs.rs/float-ord/0.3.2/float_ord/struct.FloatOrd.html"><code>FloatOrd</code></a>
so we can compare floats.</li>
</ul>
<p>So how’s the performance? I used <a href="https://bheisler.github.io/criterion.rs/book/index.html">Criterion</a>
to benchmark the performance of the inner loop (the
<code>filter_map</code>) with Criterion’s default settings, using the
same dataset as before. The new inner loop runs in <strong>4.2
milliseconds</strong>, which is about 8 times faster than the Python
baseline! But our full computation is still 124 days, which is too long.
Now let’s start really optimizing.</p>
<h2 id="indexed-data">Indexed Data</h2>
<p>Rather than guess how to optimize the code, let’s run a profiler to
see where the bottleneck is. On my Mac, I usually use <a href="https://en.wikipedia.org/wiki/Instruments_(software)">Instruments.app</a>,
but recently I tried <a href="https://github.com/mstange/samply/">samply</a> and wow! It’s much
nicer to use. Samply seems to work better with Rust both in terms of
symbol demangling and in terms of reconstructing the call stack. Here’s
a screenshot of the relevant part of the samply trace for the Rust
implementation so far:</p>
<p><img src="https://willcrichton.net/notes/k-corrset/img/profile-naive.png"/></p>
<p>We’re spending 75% of our time in <code>HashMap::get</code>! This is
the offending line of code:</p>
<div id="cb6"><pre><code><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>q_to_score[<span>*</span>q]<span>.</span>get(u)<span>.</span>copied()</span></code></pre></div>
<p>The problem is that we’re hashing and comparing 36-byte UUID strings,
which is expensive. We need a smaller type that can stand-in for the
question/user strings.</p>
<p>The solution is that we will collect all the questions and users into
a <code>Vec</code>, and represent each question/user by their index in
that <code>Vec</code>. We could just use <code>usize</code> indices with
the <code>Vec</code> type, but a better practice is to use newtypes to
represent each kind of index. In fact, this problem comes up so often in
my work that I’ve already made a crate for it, <a href="https://docs.rs/indexical/0.6.0/indexical/index.html">Indexical</a>
(which builds on the <a href="https://docs.rs/index_vec/0.1.3/index_vec/index.html">index_vec</a>
crate). We define those index types like this:</p>
<div id="cb7"><pre><code><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span>pub</span> <span>struct</span> QuestionRef<span>&lt;</span><span>&#39;a</span><span>&gt;</span>(<span>pub</span> <span>&amp;</span><span>&#39;a</span> Question)<span>;</span></span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span>pub</span> <span>struct</span> UserRef<span>&lt;</span><span>&#39;a</span><span>&gt;</span>(<span>pub</span> <span>&amp;</span><span>&#39;a</span> User)<span>;</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span>define_index_type!</span> <span>{</span></span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a>  <span>pub</span> <span>struct</span> QuestionIdx <span>for</span> QuestionRef<span>&lt;</span><span>&#39;a</span><span>&gt;</span> <span>=</span> <span>u16</span><span>;</span></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a><span>}</span></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a><span>define_index_type!</span> <span>{</span></span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>  <span>pub</span> <span>struct</span> UserIdx <span>for</span> UserRef<span>&lt;</span><span>&#39;a</span><span>&gt;</span> <span>=</span> <span>u32</span><span>;</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a><span>}</span></span></code></pre></div>
<p>The <code>QuestionRef</code> and <code>UserRef</code> types are
newtypes that enable us to implement traits on
<code>&amp;Question</code> and <code>&amp;User</code>. The
<code>define_index_type</code> macro creates new index types
<code>QuestionIdx</code> and <code>UserIdx</code> which are associated
with <code>QuestionRef</code> and <code>UserRef</code>. Those indices
are represented as <code>u16</code> and a <code>u32</code>,
respectively.</p>
<p>Finally we update <code>k_corrset</code> to generate an <a href="https://docs.rs/indexical/0.6.0/indexical/struct.IndexedDomain.html"><code>IndexedDomain</code></a>
for questions and users, and then use the <code>QuestionIdx</code> and
<code>UserIdx</code> types throughout the rest of the code:</p>
<div id="cb8"><pre><code><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a><span>fn</span> k_corrset(data<span>:</span> <span>&amp;</span>[Row]<span>,</span> k<span>:</span> <span>usize</span>) <span>-&gt;</span> <span>Vec</span><span>&lt;&amp;</span>Question<span>&gt;</span> <span>{</span></span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a>  <span>// first, we create an `IndexedDomain` for questions and users</span></span>
<span id="cb8-3"><a href="#cb8-3" aria-hidden="true" tabindex="-1"></a>  <span>let</span> (questions_set<span>,</span> users_set)<span>:</span> (HashSet<span>&lt;</span>_<span>&gt;,</span> HashSet<span>&lt;</span>_<span>&gt;</span>) <span>=</span> data<span>.</span>iter()</span>
<span id="cb8-4"><a href="#cb8-4" aria-hidden="true" tabindex="-1"></a>    <span>.</span>map(<span>|</span>row<span>|</span> (QuestionRef(<span>&amp;</span>row<span>.</span>question)<span>,</span> UserRef(<span>&amp;</span>row<span>.</span>user)))</span>
<span id="cb8-5"><a href="#cb8-5" aria-hidden="true" tabindex="-1"></a>    <span>.</span>unzip()<span>;</span></span>
<span id="cb8-6"><a href="#cb8-6" aria-hidden="true" tabindex="-1"></a>  <span>let</span> questions <span>=</span> <span>IndexedDomain::</span>from_iter(questions_set)<span>;</span></span>
<span id="cb8-7"><a href="#cb8-7" aria-hidden="true" tabindex="-1"></a>  <span>let</span> users <span>=</span> <span>IndexedDomain::</span>from_iter(users_set)<span>;</span></span>
<span id="cb8-8"><a href="#cb8-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-9"><a href="#cb8-9" aria-hidden="true" tabindex="-1"></a>  <span>// then we create the same data structures as before, </span></span>
<span id="cb8-10"><a href="#cb8-10" aria-hidden="true" tabindex="-1"></a>  <span>// except using `IndexedDomain::index` to lookup indices.</span></span>
<span id="cb8-11"><a href="#cb8-11" aria-hidden="true" tabindex="-1"></a>  <span>// note the change in the HashMap key types</span></span>
<span id="cb8-12"><a href="#cb8-12" aria-hidden="true" tabindex="-1"></a>  <span>let</span> q_to_score<span>:</span> HashMap<span>&lt;</span>QuestionIdx<span>,</span> HashMap<span>&lt;</span>UserIdx<span>,</span> <span>u32</span><span>&gt;&gt;</span> <span>=</span> </span>
<span id="cb8-13"><a href="#cb8-13" aria-hidden="true" tabindex="-1"></a>    <span>utils::</span>group_by(data<span>.</span>iter()<span>.</span>map(<span>|</span>r<span>|</span> (</span>
<span id="cb8-14"><a href="#cb8-14" aria-hidden="true" tabindex="-1"></a>      questions<span>.</span>index(<span>&amp;</span>(QuestionRef(<span>&amp;</span>r<span>.</span>question)))<span>,</span></span>
<span id="cb8-15"><a href="#cb8-15" aria-hidden="true" tabindex="-1"></a>      users<span>.</span>index(<span>&amp;</span>(UserRef(<span>&amp;</span>r<span>.</span>user)))<span>,</span></span>
<span id="cb8-16"><a href="#cb8-16" aria-hidden="true" tabindex="-1"></a>      r<span>.</span>score<span>,</span></span>
<span id="cb8-17"><a href="#cb8-17" aria-hidden="true" tabindex="-1"></a>    )))<span>;</span></span>
<span id="cb8-18"><a href="#cb8-18" aria-hidden="true" tabindex="-1"></a>  <span>let</span> u_to_score<span>:</span> HashMap<span>&lt;</span>UserIdx<span>,</span> HashMap<span>&lt;</span>QuestionIdx<span>,</span> <span>u32</span><span>&gt;&gt;</span> <span>=</span> </span>
<span id="cb8-19"><a href="#cb8-19" aria-hidden="true" tabindex="-1"></a>    <span>utils::</span>group_by(data<span>.</span>iter()<span>.</span>map(<span>|</span>r<span>|</span> (</span>
<span id="cb8-20"><a href="#cb8-20" aria-hidden="true" tabindex="-1"></a>      users<span>.</span>index(<span>&amp;</span>(UserRef(<span>&amp;</span>r<span>.</span>user)))<span>,</span></span>
<span id="cb8-21"><a href="#cb8-21" aria-hidden="true" tabindex="-1"></a>      questions<span>.</span>index(<span>&amp;</span>(QuestionRef(<span>&amp;</span>r<span>.</span>question)))<span>,</span></span>
<span id="cb8-22"><a href="#cb8-22" aria-hidden="true" tabindex="-1"></a>      r<span>.</span>score<span>,</span></span>
<span id="cb8-23"><a href="#cb8-23" aria-hidden="true" tabindex="-1"></a>    )))<span>;</span>  </span>
<span id="cb8-24"><a href="#cb8-24" aria-hidden="true" tabindex="-1"></a>  <span>let</span> all_grand_totals <span>=</span> <span>// same code</span></span>
<span id="cb8-25"><a href="#cb8-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb8-26"><a href="#cb8-26" aria-hidden="true" tabindex="-1"></a>  <span>let</span> all_qs <span>=</span> questions<span>.</span>indices()<span>;</span></span>
<span id="cb8-27"><a href="#cb8-27" aria-hidden="true" tabindex="-1"></a>  all_qs<span>.</span>combinations(k)</span>
<span id="cb8-28"><a href="#cb8-28" aria-hidden="true" tabindex="-1"></a>    <span>.</span>filter_map(<span>|</span>qs<span>:</span> <span>Vec</span><span>&lt;</span>QuestionIdx<span>&gt;|</span> <span>{</span></span>
<span id="cb8-29"><a href="#cb8-29" aria-hidden="true" tabindex="-1"></a>      <span>// same code</span></span>
<span id="cb8-30"><a href="#cb8-30" aria-hidden="true" tabindex="-1"></a>    <span>}</span>)</span>
<span id="cb8-31"><a href="#cb8-31" aria-hidden="true" tabindex="-1"></a>    <span>.</span>max_by_key(<span>|</span>(_<span>,</span> r)<span>|</span> FloatOrd(<span>*</span>r))</span>
<span id="cb8-32"><a href="#cb8-32" aria-hidden="true" tabindex="-1"></a>    <span>.</span>unwrap()<span>.</span><span>0</span></span>
<span id="cb8-33"><a href="#cb8-33" aria-hidden="true" tabindex="-1"></a>    <span>// we have to post-process the indices back to values</span></span>
<span id="cb8-34"><a href="#cb8-34" aria-hidden="true" tabindex="-1"></a>    <span>.</span>into_iter()<span>.</span>map(<span>|</span>idx<span>|</span> questions<span>.</span>value(idx)<span>.</span><span>0</span>)<span>.</span>collect()</span>
<span id="cb8-35"><a href="#cb8-35" aria-hidden="true" tabindex="-1"></a><span>}</span></span></code></pre></div>
<p>Again, check out the <a href="https://github.com/willcrichton/corrset-benchmark/blob/main/src/inner/indexed.rs">GitHub</a>
for the complete implementation, and check out the <a href="https://docs.rs/indexical/0.6.0/indexical/index.html">indexical
docs</a> for details on its API.</p>
<p>Once again we run our benchmark on the inner loop of the computation.
The new inner loop runs in <strong>1.0 milliseconds</strong>, which is 4
times faster than our last iteration, and 35 times faster than our
Python baseline. We’re down to 30 days for the total computation — let’s
keep going!</p>
<h2 id="indexed-collections">Indexed Collections</h2>
<p>Let’s profile again:</p>
<p><img src="https://willcrichton.net/notes/k-corrset/img/profile-indexed.png"/></p>
<p>Blast, still spending most our time in <code>HashMap::get</code>.
Well, what if we got rid of hash maps altogether? A
<code>HashMap&lt;&amp;User, u32&gt;</code> is conceptually the same
thing as a <code>Vec&lt;Option&lt;u32&gt;&gt;</code> where each
<code>&amp;User</code> has a unique index. For example, in a domain of
users <code>[&#34;a&#34;, &#34;b&#34;, &#34;c&#34;]</code>, then the hash map
<code>{&#34;b&#34; =&gt; 1}</code> is equivalent to the vector
<code>[None, Some(1), None]</code>. This vector costs more memory
(paying for the <code>None</code> spaces), but it improves the
performance of key/value lookups (avoids hashing).</p>
<p>We’re trying to fully optimize for performance, and given the scale
of our dataset, we can afford to make the compute/memory trade-off. We
will use Indexical which provides a <a href="https://docs.rs/indexical/0.6.0/indexical/map/struct.DenseIndexMap.html"><code>DenseIndexMap&lt;K, V&gt;</code></a>
type that is internally implemented as a <code>Vec&lt;V&gt;</code> type
indexed by <code>K::Index</code>.</p>
<p>The main change to the <code>k_corrset</code> function is that we
convert all our auxiliary data structures to dense index maps:</p>
<div id="cb9"><pre><code><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span>pub</span> <span>type</span> QuestionMap<span>&lt;</span><span>&#39;a</span><span>,</span> T<span>&gt;</span> <span>=</span> DenseIndexMap<span>&lt;</span><span>&#39;a</span><span>,</span> QuestionRef<span>&lt;</span><span>&#39;a</span><span>&gt;,</span> T<span>&gt;;</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span>pub</span> <span>type</span> UserMap<span>&lt;</span><span>&#39;a</span><span>,</span> T<span>&gt;</span> <span>=</span> DenseIndexMap<span>&lt;</span><span>&#39;a</span><span>,</span> UserRef<span>&lt;</span><span>&#39;a</span><span>&gt;,</span> T<span>&gt;;</span></span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a><span>fn</span> k_corrset(data<span>:</span> <span>&amp;</span>[Row]<span>,</span> k<span>:</span> <span>usize</span>) <span>-&gt;</span> <span>Vec</span><span>&lt;&amp;</span>Question<span>&gt;</span> <span>{</span></span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a>  <span>// build the `users` and `questions` domains same as before</span></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a>  <span>// Initialize q_to_score to an empty dense map</span></span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a>  <span>let</span> <span>mut</span> q_to_score<span>:</span> QuestionMap<span>&lt;</span><span>&#39;_</span><span>,</span> UserMap<span>&lt;</span><span>&#39;_</span><span>,</span> <span>Option</span><span>&lt;</span><span>u32</span><span>&gt;&gt;&gt;</span> <span>=</span> </span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a>    <span>QuestionMap::</span>new(<span>&amp;</span>questions<span>,</span> <span>|</span>_<span>|</span> <span>UserMap::</span>new(<span>&amp;</span>users<span>,</span> <span>|</span>_<span>|</span> <span>None</span>))<span>;</span>  </span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a>  <span>// Fill in q_to_score with the dataset</span></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a>  <span>for</span> r <span>in</span> data <span>{</span></span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>    q_to_score</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>      <span>.</span>get_mut(<span>&amp;</span>QuestionRef(<span>&amp;</span>r<span>.</span>question))</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>      <span>.</span>unwrap()</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>      <span>.</span>insert(UserRef(<span>&amp;</span>r<span>.</span>user)<span>,</span> <span>Some</span>(r<span>.</span>score))<span>;</span></span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>  <span>}</span></span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>  <span>let</span> grand_totals <span>=</span> <span>UserMap::</span>new(<span>&amp;</span>users<span>,</span> <span>|</span>u<span>|</span> <span>{</span></span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>    q_to_score<span>.</span>values()<span>.</span>filter_map(<span>|</span>v<span>|</span> v[u])<span>.</span><span>sum::</span><span>&lt;</span><span>u32</span><span>&gt;</span>()</span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>  <span>}</span>)<span>;</span></span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>  <span>let</span> all_qs <span>=</span> questions<span>.</span>indices()<span>;</span></span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>  all_qs<span>.</span>combinations(k)</span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>    <span>// almost the same code, see below</span></span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a><span>}</span></span></code></pre></div>
<p>The only change to the inner loop is that our code which used to say
this:</p>
<div id="cb10"><pre><code><span id="cb10-1"><a href="#cb10-1" aria-hidden="true" tabindex="-1"></a>q_to_score[<span>*</span>q]<span>.</span>get(u)<span>.</span>copied()</span></code></pre></div>
<p>Is now this:</p>

<p>Running the benchmark again, the new inner loop runs in <strong>181
microseconds</strong>, which is 6 times faster than our last iteration,
and 199 times faster than our Python baseline. We’re down to 5.3 days
for the total computation.</p>
<h2 id="bounds-checks">Bounds Checks</h2>
<p>Another small performance hit comes every time we use the brackets
<code>[]</code> to index into an <code>DenseIndexMap</code>. The vector
beneath will run a bounds-check for safety, but our code is guaranteed
to never exceed vector bounds as written. I couldn’t actually find the
bounds check in the samply profile, but it does make a noticeable
difference in the benchmark, so it’s worth implementing.</p>
<p>Before our inner loop looked like this:</p>
<div id="cb12"><pre><code><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span>let</span> q_total <span>=</span> qs<span>.</span>iter()</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>  <span>.</span>map(<span>|</span>q<span>|</span> q_to_score[<span>*</span>q][u])</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a>  <span>.</span><span>sum::</span><span>&lt;</span><span>Option</span><span>&lt;</span><span>u32</span><span>&gt;&gt;</span>()<span>?;</span></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a><span>let</span> grand_total <span>=</span> all_grand_totals[u]<span>;</span></span></code></pre></div>
<p>Removing bounds checks with <code>get_unchecked</code>, our new inner
loop looks like this:</p>
<div id="cb13"><pre><code><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a><span>let</span> q_total <span>=</span> qs<span>.</span>iter()</span>
<span id="cb13-2"><a href="#cb13-2" aria-hidden="true" tabindex="-1"></a>  <span>.</span>map(<span>|</span>q<span>|</span> <span>unsafe</span> <span>{</span></span>
<span id="cb13-3"><a href="#cb13-3" aria-hidden="true" tabindex="-1"></a>    <span>let</span> u_scores <span>=</span> q_to_score<span>.</span>get_unchecked(q)<span>;</span></span>
<span id="cb13-4"><a href="#cb13-4" aria-hidden="true" tabindex="-1"></a>    <span>*</span>u_scores<span>.</span>get_unchecked(u)</span>
<span id="cb13-5"><a href="#cb13-5" aria-hidden="true" tabindex="-1"></a>  <span>}</span>)</span>
<span id="cb13-6"><a href="#cb13-6" aria-hidden="true" tabindex="-1"></a>  <span>.</span><span>sum::</span><span>&lt;</span><span>Option</span><span>&lt;</span><span>u32</span><span>&gt;&gt;</span>()<span>?;</span></span>
<span id="cb13-7"><a href="#cb13-7" aria-hidden="true" tabindex="-1"></a><span>let</span> grand_total <span>=</span> <span>unsafe</span> <span>{</span> <span>*</span>all_grand_totals<span>.</span>get_unchecked(u) <span>};</span></span></code></pre></div>
<p>It is unsafe without bounds-checks, so we have to mark these blocks
as <code>unsafe</code>.</p>
<p>Running the benchmark again, the new inner loop runs in <strong>156
microseconds</strong>, which is 1.16x faster than our last iteration,
and 229 times faster than our Python baseline. We’re down to 4.6 days
for the total computation.</p>
<h2 id="bit-sets">Bit-sets</h2>
<p>We’re currently at a 225x speedup, which means we still have three
orders of magnitude left to go. To get there, we need to rethink the
computational structure of the inner loop. Right now, our loop
effectively looks like:</p>
<pre><code>for each subset of questions $qs:
  for each user $u:
    for each question $q in $qs:
      if $u answered $q: add $u&#39;s score on $q to a running total
      else: skip to the next user
    $r = correlation($u&#39;s totals on $qs, $u&#39;s grand total)</code></pre>
<p>An important aspect of our data is that it forms a <em>sparse</em>
matrix. For a given question, only 20% of users have answered that
question. For a set of 5 questions, a much smaller fraction have
answered all 5 questions. So if we can efficiently determine first which
users have answered all 5 questions, then our subsequent loop will run
for fewer iterations (and be free of branches). Something like this:</p>
<pre><code>for each subset of questions $qs:
  $qs_u = all users who have answered every question in $qs
  for each user $u in $qs_u:
    for each question $q in $qs:
      add $u&#39;s score on $q to a running total
    $r = correlation($u&#39;s scores on $qs, $u&#39;s grand total)</code></pre>
<p>So how do we represent the set of users who have answered a given
question? We could use a <a href="https://doc.rust-lang.org/std/collections/struct.HashSet.html"><code>HashSet</code></a>,
but we saw earlier that hashing is computationally expensive. Because
our data is indexed, we can use a more efficient data structure: the <a href="https://en.wikipedia.org/wiki/Bit_array">bit-set</a>, which uses
the individual bits of memory to represent whether an object is present
or absent in a set. Indexical provides another abstraction for
integratings bit-sets with our newtype indices: the <a href="https://docs.rs/indexical/0.6.0/indexical/struct.IndexSet.html"><code>IndexSet</code></a>.</p>
<p>Previously, our <code>q_to_score</code> data structure mapped from
questions to a user-indexed vector of optional scores (that is,
<code>UserMap&lt;&#39;_, Option&lt;u32&gt;&gt;</code>). Now we will change
<code>Option&lt;u32&gt;</code> to <code>u32</code> and add a bit-set
describing the set of users who answered a given question. The first
half of the updated code looks like this:</p>
<div id="cb16"><pre><code><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span>type</span> UserSet<span>&lt;</span><span>&#39;a</span><span>&gt;</span> <span>=</span> IndexSet<span>&lt;</span><span>&#39;a</span><span>,</span> UserRef<span>&lt;</span><span>&#39;a</span><span>&gt;&gt;;</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span>let</span> <span>mut</span> q_to_score<span>:</span> QuestionMap<span>&lt;</span><span>&#39;_</span><span>,</span> (UserSet<span>&lt;</span><span>&#39;_</span><span>&gt;,</span> UserMap<span>&lt;</span><span>&#39;_</span><span>,</span> <span>u32</span><span>&gt;</span>)<span>&gt;</span> <span>=</span> </span>
<span id="cb16-4"><a href="#cb16-4" aria-hidden="true" tabindex="-1"></a>  <span>QuestionMap::</span>new(<span>&amp;</span>questions<span>,</span> <span>|</span>_<span>|</span> (</span>
<span id="cb16-5"><a href="#cb16-5" aria-hidden="true" tabindex="-1"></a>    <span>UserMap::</span><span>&lt;</span><span>&#39;_</span><span>,</span> <span>u32</span><span>&gt;</span><span>::</span>new(<span>&amp;</span>users<span>,</span> <span>|</span>_<span>|</span> <span>0</span>)<span>,</span></span>
<span id="cb16-6"><a href="#cb16-6" aria-hidden="true" tabindex="-1"></a>    <span>UserSet::</span>new(<span>&amp;</span>users)<span>,</span></span>
<span id="cb16-7"><a href="#cb16-7" aria-hidden="true" tabindex="-1"></a>  ))<span>;</span></span>
<span id="cb16-8"><a href="#cb16-8" aria-hidden="true" tabindex="-1"></a><span>for</span> r <span>in</span> data <span>{</span></span>
<span id="cb16-9"><a href="#cb16-9" aria-hidden="true" tabindex="-1"></a>  <span>let</span> (scores<span>,</span> set) <span>=</span> <span>&amp;</span><span>mut</span> q_to_score<span>.</span>get_mut(<span>&amp;</span>QuestionRef(<span>&amp;</span>r<span>.</span>question))<span>.</span>unwrap()<span>;</span></span>
<span id="cb16-10"><a href="#cb16-10" aria-hidden="true" tabindex="-1"></a>  scores<span>.</span>insert(UserRef(<span>&amp;</span>r<span>.</span>user)<span>,</span> r<span>.</span>score)<span>;</span></span>
<span id="cb16-11"><a href="#cb16-11" aria-hidden="true" tabindex="-1"></a>  set<span>.</span>insert(UserRef(<span>&amp;</span>r<span>.</span>user))<span>;</span></span>
<span id="cb16-12"><a href="#cb16-12" aria-hidden="true" tabindex="-1"></a><span>}</span></span></code></pre></div>
<p>Note that <code>q_to_score</code> now effectively has invalid values,
since we provide a default value of 0 for users who did not answer a
question. We have to be careful not to use these invalid values in the
computation.</p>
<p>Then we update our inner loop to match the new pseudocode:</p>
<div id="cb17"><pre><code><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span>let</span> all_qs <span>=</span> questions<span>.</span>indices()<span>;</span></span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a>all_qs<span>.</span>combinations(k)</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>  <span>.</span>filter_map(<span>|</span>qs<span>:</span> <span>Vec</span><span>&lt;</span>QuestionIdx<span>&gt;|</span> <span>{</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>    <span>// Compute the intersection of the user-sets for each question</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>    <span>let</span> <span>mut</span> users <span>=</span> q_to_score[qs[<span>0</span>]]<span>.</span><span>1</span><span>.</span>clone()<span>;</span></span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    <span>for</span> q <span>in</span> <span>&amp;</span>qs[<span>1</span><span>..</span>] <span>{</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>      users<span>.</span>intersect(<span>&amp;</span>q_to_score[<span>*</span>q]<span>.</span><span>1</span>)<span>;</span></span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a>    <span>}</span></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a>    <span>let</span> (qs_totals<span>,</span> grand_totals)<span>:</span> (<span>Vec</span><span>&lt;</span>_<span>&gt;,</span> <span>Vec</span><span>&lt;</span>_<span>&gt;</span>) <span>=</span> users<span>.</span>indices()</span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a>      <span>// only .map, not .filter_map as before</span></span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>      <span>.</span>map(<span>|</span>u<span>|</span> <span>{</span></span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>        <span>let</span> q_total <span>=</span> qs<span>.</span>iter()          </span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>          <span>.</span>map(<span>|</span>q<span>|</span> <span>unsafe</span> <span>{</span></span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>            <span>let</span> (u_scores<span>,</span> _) <span>=</span> q_to_score<span>.</span>get_unchecked(q)<span>;</span></span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>            <span>*</span>u_scores<span>.</span>get_unchecked(u)</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>          <span>}</span>)</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>          <span>// only u32, not Option&lt;u32&gt; as before</span></span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>          <span>.</span><span>sum::</span><span>&lt;</span><span>u32</span><span>&gt;</span>()<span>;</span></span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>        <span>let</span> grand_total <span>=</span> <span>unsafe</span> <span>{</span> <span>*</span>all_grand_totals<span>.</span>get_unchecked(u) <span>};</span></span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>        (q_total <span>as</span> <span>f64</span><span>,</span> grand_total <span>as</span> <span>f64</span>)</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>      <span>}</span>)</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>      <span>.</span>unzip()<span>;</span></span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>    <span>let</span> r <span>=</span> <span>utils::</span>correlation(<span>&amp;</span>qs_totals<span>,</span> <span>&amp;</span>grand_totals)<span>;</span></span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a>    (<span>!</span>r<span>.</span>is_nan())<span>.</span>then_some((qs<span>,</span> r))</span>
<span id="cb17-26"><a href="#cb17-26" aria-hidden="true" tabindex="-1"></a>  <span>}</span>)</span>
<span id="cb17-27"><a href="#cb17-27" aria-hidden="true" tabindex="-1"></a>  <span>// rest of the code is the same</span></span></code></pre></div>
<p>Running the benchmark again, the new inner loop runs in <strong>47
microseconds</strong>, which is 3.4 times faster than our last
iteration, and 769 times faster than our Python baseline. We’re down to
1.4 days for the total computation.</p>
<h2 id="simd">SIMD</h2>
<p>Our new computational structure is definitely helping, but it’s still
not fast enough. Let’s check back in with samply:</p>
<p><img src="https://willcrichton.net/notes/k-corrset/img/profile-bitset.png"/></p>
<p>Now we’re spending all our time in the bit-set intersection! That
means we need to dig in to how the bit-set is implemented. The default
bit-set library used by Indexical is <a href="https://docs.rs/bitvec/1.0.1/bitvec/index.html">bitvec</a>. As of
2023, the implementation of intersection within bitvec’s bit-set is
roughly this code:</p>
<div id="cb18"><pre><code><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span>fn</span> intersect(dst<span>:</span> <span>&amp;</span><span>mut</span> BitSet<span>,</span> src<span>:</span> <span>&amp;</span>BitSet) <span>{</span></span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>  <span>for</span> (n1<span>,</span> n2)<span>:</span> (<span>&amp;</span><span>mut</span> <span>u64</span><span>,</span> <span>&amp;</span><span>u64</span>) <span>in</span> dst<span>.</span>iter_mut()<span>.</span>zip(<span>&amp;</span>src) <span>{</span></span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a>    <span>*</span>n1 <span>&amp;=</span> <span>*</span>n2<span>;</span></span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a>  <span>}</span></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a><span>}</span></span></code></pre></div>
<p>So bitvec is AND-ing a <code>u64</code> at a time. But it turns out
most processors have instructions specifically for doing
bit-manipulation on multiple <code>u64</code>s at a time, called <a href="https://en.wikipedia.org/wiki/Single_instruction,_multiple_data">SIMD</a>
(single instruction, multiple data). Thankfully, Rust provides an
experimental SIMD API <a href="https://doc.rust-lang.org/std/simd/index.html"><code>std::simd</code></a>
that we can use. Roughly speaking, the SIMD version of bit-set
intersection looks like this:</p>
<div id="cb19"><pre><code><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span>fn</span> intersect(dst<span>:</span> <span>&amp;</span><span>mut</span> SimdBitSet<span>,</span> src<span>:</span> <span>&amp;</span>SimdBitSet) <span>{</span></span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a>  <span>for</span> (n1<span>,</span> n2)<span>:</span> (<span>&amp;</span><span>mut</span> u64x4<span>,</span> <span>&amp;</span>u64x4) <span>in</span> dst<span>.</span>iter_mut()<span>.</span>zip(<span>&amp;</span>src) <span>{</span></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>    <span>*</span>n1 <span>&amp;=</span> <span>*</span>n2<span>;</span></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>  <span>}</span></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a><span>}</span></span></code></pre></div>
<p>The only difference is that we’ve replaced our primitive
<code>u64</code> type with a SIMD type <a href="https://doc.rust-lang.org/std/simd/type.u64x4.html"><code>u64x4</code></a>,
and under the hood, Rust emits a single SIMD instruction to perform the
<code>&amp;=</code> operation that ANDs four <code>u64</code>s at a
time.</p>
<p>Where can we find a SIMD-accelerated bitset? <a href="https://docs.rs/bitvec/1.0.1/bitvec/index.html">bitvec</a> doesn’t
support SIMD. There are a few on <a href="https://crates.io">crates.io</a>, and I tried out one called <a href="https://github.com/psiace/bitsvec">bitsvec</a>. It works well for
fast intersection, but I found that its iterator which finds the indices
of the 1-bits is actually quite slow. So I copied large portions of the
bitsvec implementation and wrote a more efficient iterator, which you
can check out in the <a href="https://github.com/willcrichton/indexical/blob/913fbf5830f4d5acedd23e04841e453ed2659165/src/bitset/simd.rs">Indexical
source</a> if you’re curious.</p>
<p>Thanks to Indexical’s abstractions, swapping in the SIMD bitset only
requires changing a type alias and no other modifications to the
<code>k_corrset</code> function. I experimented with different lane
sizes and found <code>u64x16</code> is the most efficient on my machine
for this dataset.</p>
<p>Once more we run the benchmark, and the new inner loop runs in
<strong>1.35 microseconds</strong>, which is 34 times faster than our
last iteration, and 26,459 times faster than our Python baseline. We’re
down to 57 minutes for the total computation.</p>
<h2 id="allocation">Allocation</h2>
<p>At this point, we’re pretty close to peak performance. (You may not
like it, but…) Let’s go back to the profile, this time looking at the
inverted view (which shows the most-called functions at the leaves of
the call tree):</p>
<p><img src="https://willcrichton.net/notes/k-corrset/img/profile-simd.png"/></p>
<p>The biggest bottleneck is our bit-set iterator! I wasn’t joking! But
we see several concerning functions: <code>memmove</code>,
<code>realloc</code>, <code>allocate</code> — that’s right, we’re
allocating memory in the inner loop of this function. Specifically,
there’s the user bit-set that we initially clone, and there’s the two
vectors for <code>qs_totals</code> and <code>grand_totals</code> that we
allocate with <code>unzip</code>.</p>
<p>To avoid allocation, we create these data structures up front with
the maximum possible size needed, and then repeatedly write into
them:</p>
<div id="cb20"><pre><code><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span>// Allocate our data up front</span></span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span>let</span> <span>mut</span> qs_totals <span>=</span> <span>vec!</span>[<span>0</span><span>.;</span> users<span>.</span>len()]</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span>let</span> <span>mut</span> grand_totals <span>=</span> <span>vec!</span>[<span>0</span><span>.;</span> users<span>.</span>len()]<span>;</span></span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span>let</span> <span>mut</span> user_set <span>=</span> <span>IndexSet::</span>new(<span>&amp;</span>users)<span>;</span></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a><span>let</span> all_qs <span>=</span> questions<span>.</span>indices()<span>;</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>all_qs<span>.</span>combinations(k)</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a>  <span>.</span>filter_map(<span>|</span>qs<span>|</span> <span>{</span></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>    <span>// Use `clone_from` rather than `clone` to copy without allocation</span></span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>    user_set<span>.</span>clone_from(<span>&amp;</span>q_to_score[qs[<span>0</span>]]<span>.</span><span>1</span>)<span>;</span></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a>    <span>for</span> q <span>in</span> <span>&amp;</span>qs[<span>1</span><span>..</span>] <span>{</span></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>      user_set<span>.</span>intersect(<span>&amp;</span>q_to_score[<span>*</span>q]<span>.</span><span>1</span>)<span>;</span></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>    <span>}</span></span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>    <span>let</span> <span>mut</span> n <span>=</span> <span>0</span><span>;</span></span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>    <span>for</span> (i<span>,</span> u) <span>in</span> user_set<span>.</span>indices()<span>.</span>enumerate() <span>{</span></span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>      <span>let</span> q_total <span>=</span> qs<span>.</span>iter()</span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>        <span>.</span>map(<span>|</span>q<span>|</span> <span>unsafe</span> <span>{</span></span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a>          <span>let</span> (u_scores<span>,</span> _) <span>=</span> q_to_score<span>.</span>get_unchecked(q)<span>;</span></span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a>          <span>*</span>u_scores<span>..</span>get_unchecked(u)</span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a>        <span>}</span>)</span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>        <span>.</span><span>sum::</span><span>&lt;</span><span>u32</span><span>&gt;</span>()<span>;</span></span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a>      <span>let</span> grand_total <span>=</span> <span>unsafe</span> <span>{</span> <span>*</span>all_grand_totals<span>.</span>get_unchecked(u) <span>};</span></span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a>      <span>// Update totals/grand_totals in-place rather than pushing into a vector</span></span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a>      <span>unsafe</span> <span>{</span></span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a>        <span>*</span>qs_totals<span>.</span>get_unchecked_mut(i) <span>=</span> q_total <span>as</span> <span>f64</span><span>;</span></span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a>        <span>*</span>grand_totals<span>.</span>get_unchecked_mut(i) <span>=</span> grand_total <span>as</span> <span>f64</span><span>;</span></span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a>      <span>}</span></span>
<span id="cb20-30"><a href="#cb20-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-31"><a href="#cb20-31" aria-hidden="true" tabindex="-1"></a>      n <span>+=</span> <span>1</span><span>;</span></span>
<span id="cb20-32"><a href="#cb20-32" aria-hidden="true" tabindex="-1"></a>    <span>}</span></span>
<span id="cb20-33"><a href="#cb20-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-34"><a href="#cb20-34" aria-hidden="true" tabindex="-1"></a>    <span>// Only pass in the first `n` elements!</span></span>
<span id="cb20-35"><a href="#cb20-35" aria-hidden="true" tabindex="-1"></a>    <span>let</span> r <span>=</span> <span>utils::</span>correlation(<span>&amp;</span>qs_totals[<span>..</span>n]<span>,</span> <span>&amp;</span>grand_totals[<span>..</span>n])<span>;</span></span>
<span id="cb20-36"><a href="#cb20-36" aria-hidden="true" tabindex="-1"></a>    (<span>!</span>r<span>.</span>is_nan())<span>.</span>then_some((qs<span>,</span> r))</span>
<span id="cb20-37"><a href="#cb20-37" aria-hidden="true" tabindex="-1"></a>  <span>}</span>)</span></code></pre></div>
<p>We run the benchmark again, and the new inner loop runs in
<strong>1.09 microseconds</strong>, which is 1.24 times faster than our
last iteration, and 32,940 times faster than our Python baseline. We’re
down to 46 minutes for the total computation.</p>
<p>(As an aside, it’s impressive that the heap allocator was fast enough
to have such a small impact on our runtime!)</p>
<p>In summary, Table <a href="#tbl:inner-speedup">1</a> shows the
runtime, relative speedup, absolute speedup, and total estimated
completion time for each level of the benchmark.</p>
<div id="tbl:inner-speedup">
<table>
<caption>Table 1: Performance numbers for the inner loop.</caption>
<colgroup>
<col/>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<thead>
<tr>
<th>Level</th>
<th>Runtime</th>
<th>Speedup over previous level</th>
<th>Speedup over Python</th>
<th>Est. completion time</th>
</tr>
</thead>
<tbody>
<tr>
<td>python</td>
<td>35.85 ms</td>
<td></td>
<td>1.00×</td>
<td>2.88 years</td>
</tr>
<tr>
<td>0_basic</td>
<td>4.24 ms</td>
<td>8.46×</td>
<td>8.46×</td>
<td>124.40 days</td>
</tr>
<tr>
<td>1_indexed</td>
<td>1.03 ms</td>
<td>4.11×</td>
<td>34.78×</td>
<td>30.25 days</td>
</tr>
<tr>
<td>2_imap</td>
<td>180.52 μs</td>
<td>5.71×</td>
<td>198.60×</td>
<td>5.30 days</td>
</tr>
<tr>
<td>3_bchecks</td>
<td>156.23 μs</td>
<td>1.16×</td>
<td>229.47×</td>
<td>4.59 days</td>
</tr>
<tr>
<td>4_bitset</td>
<td>46.60 μs</td>
<td>3.35×</td>
<td>769.26×</td>
<td>1.37 days</td>
</tr>
<tr>
<td>5_simd</td>
<td>1.35 μs</td>
<td>34.40×</td>
<td>26,459.54×</td>
<td>57.26 min</td>
</tr>
<tr>
<td>6_alloc</td>
<td>1.09 μs</td>
<td>1.24×</td>
<td>32,940.02×</td>
<td>45.99 min</td>
</tr>
</tbody>
</table>
</div>
<p>The absolute speedup is summarized in Figure 1. Note that the y-axis
is on a log-scale!</p>
<figure>

<figcaption>
Performance trend of the inner loop.
</figcaption>
</figure>
<h2 id="parallelism">Parallelism</h2>
<p>At this point, we seem to have totally exhausted our avenues for
optimization. I actually can’t think of any other ways to make the inner
loop substantively faster — let me know if you have any ideas. But we’ve
left out one final, obvious trick: parallelism! This problem is
embarassingly parallel, so we can trivially parallelize the inner loop
over multiple cores. <a href="https://docs.rs/rayon/1.8.0/rayon/index.html">Rayon</a> makes this
a breeze:</p>
<div id="cb21"><pre><code><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span>let</span> all_qs <span>=</span> questions<span>.</span>indices()<span>;</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>all_qs<span>.</span>combinations(k)</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a>  <span>.</span>par_bridge()</span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>  <span>.</span>map_init(</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>    <span>||</span> (<span>vec!</span>[<span>0</span><span>.;</span> users<span>.</span>len()]<span>,</span> <span>vec!</span>[<span>0</span><span>.;</span> users<span>.</span>len()]<span>,</span> <span>IndexSet::</span>new(<span>&amp;</span>users))<span>,</span></span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>    <span>|</span>(qs_totals<span>,</span> grand_totals<span>,</span> user_set)<span>,</span> qs<span>|</span> <span>{</span></span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>      <span>// same code as before</span></span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>    <span>}</span>)</span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>    <span>// same code as before</span></span></code></pre></div>
<p>The <code>par_bridge</code> method takes a serial iterator and
converts it into a parallel iterator. The <code>map_init</code> function
is a parallel map with thread-specific state, so we preserve our
allocation-free status.</p>
<p>We need a different benchmark to evaluate the outer loop. I used
Criterion to run the outer loop over 5,000,000 question combinations in
a single run with a given strategy. This is enough executions to reveal
differences in each outer loop without waiting weeks for the benchmark
to complete.</p>
<p>Running this benchmark with the serial strategy over the fastest
inner loop takes <strong>6.8 seconds</strong>. My Macbook Pro has 10
cores, so with Rayon we should expect to see close to a 10x speedup.
After benchmarking the parallel strategy, we get… <strong>4.2
seconds</strong> to complete 5,000,000 combinations. That’s only a 1.6x
speedup! Shameful!</p>
<h2 id="batching">Batching</h2>
<p>Let’s go back to the profile to investigate our lack of scaling:</p>
<p><img src="https://willcrichton.net/notes/k-corrset/img/profile-parallel.png"/></p>
<p>Our threads are spending most of their time locking and unlocking a
mutex! There’s some kind of synchronization bottleneck. Indeed, if we
read the <a href="https://docs.rs/rayon/1.8.0/rayon/iter/trait.ParallelBridge.html"><code>par_bridge</code>
documentation</a> carefully, we’ll find a key sentence:</p>
<blockquote>
<p>Iterator items are pulled by <code>next()</code> one at a time,
synchronized from each thread that is ready for work, so this may become
a bottleneck if the serial iterator can’t keep up with the parallel
demand.</p>
</blockquote>
<p>It seems that the hand-off between the
<code>Itertools::combinations</code> iterator and the Rayon parallel
bridge is too slow. Given that we have a huge number of combinations, a
simple way to avoid this bottleneck is to increase the granularity of
task assignment. That is, we can batch together many question
combinations and pass them off to a thread all at once.</p>
<p>For this task, I defined a quick-and-dirty batching iterator that
uses an <a href="https://docs.rs/arrayvec/0.7.4/arrayvec/struct.ArrayVec.html"><code>ArrayVec</code></a>
to avoid allocation.</p>
<div id="cb22"><pre><code><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span>pub</span> <span>struct</span> Batched<span>&lt;</span><span>const</span> N<span>:</span> <span>usize</span><span>,</span> I<span>:</span> <span>Iterator</span><span>&gt;</span> <span>{</span></span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a>  iter<span>:</span> I<span>,</span></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a><span>}</span></span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a><span>impl</span><span>&lt;</span><span>const</span> N<span>:</span> <span>usize</span><span>,</span> I<span>:</span> <span>Iterator</span><span>&gt;</span> <span>Iterator</span> <span>for</span> Batched<span>&lt;</span>N<span>,</span> I<span>&gt;</span> <span>{</span></span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>  <span>type</span> Item <span>=</span> ArrayVec<span>&lt;</span><span>I::</span>Item<span>,</span> N<span>&gt;;</span></span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>  <span>#[</span>inline<span>]</span></span>
<span id="cb22-9"><a href="#cb22-9" aria-hidden="true" tabindex="-1"></a>  <span>fn</span> next(<span>&amp;</span><span>mut</span> <span>self</span>) <span>-&gt;</span> <span>Option</span><span>&lt;</span><span>Self</span><span>::</span>Item<span>&gt;</span> <span>{</span></span>
<span id="cb22-10"><a href="#cb22-10" aria-hidden="true" tabindex="-1"></a>    <span>let</span> batch <span>=</span> <span>ArrayVec::</span>from_iter((<span>&amp;</span><span>mut</span> <span>self</span><span>.</span>iter)<span>.</span>take(N))<span>;</span></span>
<span id="cb22-11"><a href="#cb22-11" aria-hidden="true" tabindex="-1"></a>    (<span>!</span>batch<span>.</span>is_empty())<span>.</span>then_some(batch)</span>
<span id="cb22-12"><a href="#cb22-12" aria-hidden="true" tabindex="-1"></a>  <span>}</span></span>
<span id="cb22-13"><a href="#cb22-13" aria-hidden="true" tabindex="-1"></a><span>}</span></span></code></pre></div>
<p>Then we modify our outer loop by batching the combinations iterator,
and modify the inner loop to flatten each batch:</p>
<div id="cb23"><pre><code><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span>let</span> all_qs <span>=</span> questions<span>.</span>indices()<span>;</span></span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a>all_qs<span>.</span>combinations(k)</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a>  <span>.</span><span>batched::</span><span>&lt;</span><span>1024</span><span>&gt;</span>()</span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>  <span>.</span>par_bridge()</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>  <span>.</span>map_init(</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>    <span>||</span> (<span>vec!</span>[<span>0</span><span>.;</span> users<span>.</span>len()]<span>,</span> <span>vec!</span>[<span>0</span><span>.;</span> users<span>.</span>len()]<span>,</span> <span>IndexSet::</span>new(<span>&amp;</span>users))<span>,</span></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>    <span>|</span>(qs_totals<span>,</span> grand_totals<span>,</span> user_set)<span>,</span> qs_batch<span>|</span> <span>{</span></span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>      qs_batch</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>        <span>.</span>into_iter()</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>        <span>.</span>filter_map(<span>|</span>qs<span>|</span> <span>{</span></span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>          <span>// same code as before</span></span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>        <span>}</span>)</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>        <span>.</span>collect_vec()</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>    <span>}</span>)</span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>    <span>.</span>flatten()</span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a>    <span>// same code as before</span></span></code></pre></div>
<p>Running the outer-loop benchmark again, the chunking iterator now
completes 5,000,000 combinations in <strong>982 milliseconds</strong>.
This is a 6.9x speedup over the serial approach, which is much better
for our 10-core machine. Ideally we would get closer to 10x, but I think
this post is long enough. In summary, our outer loop runtime numbers are
in Table <a href="#tbl:outer-loop">2</a>.</p>
<div id="tbl:outer-loop">
<table>
<caption>Table 2: Performance numbers for the outer loop.</caption>
<colgroup>
<col/>
<col/>
<col/>
<col/>
<col/>
</colgroup>
<thead>
<tr>
<th>Level</th>
<th>Runtime</th>
<th>Speedup over previous level</th>
<th>Speedup over Python</th>
<th>Est. completion time</th>
</tr>
</thead>
<tbody>
<tr>
<td>0_serial</td>
<td>6.80 s</td>
<td></td>
<td>26,342.63×</td>
<td>57.51 min</td>
</tr>
<tr>
<td>1_parallel</td>
<td>4.22 s</td>
<td>1.61×</td>
<td>42,439.31×</td>
<td>35.70 min</td>
</tr>
<tr>
<td>2_batched</td>
<td>982.46 ms</td>
<td>4.30×</td>
<td>182,450.94×</td>
<td>8.30 min</td>
</tr>
</tbody>
</table>
</div>
<h2 id="conclusion">Conclusion</h2>
<p>So how far did we come? The original Python program was going to take
2.9 years to complete at k=5. Our final Rust program only takes
<strong>8 minutes</strong> on the same dataset. That is roughly a
<strong>180,000x speedup</strong>. A summary of the key
optimizations:</p>
<ul>
<li>Use Rust’s compiler optimizations.</li>
<li>Hash numbers instead of strings.</li>
<li>Use (indexed) vectors instead of hashmaps.</li>
<li>Use bit-sets for efficient membership tests.</li>
<li>Use SIMD for efficient bit-sets.</li>
<li>Use multi-threading to split the work over many cores.</li>
<li>Use batching to avoid a bottleneck at work distribution.</li>
</ul>
<p>Can we do better? Let’s take one last look at the profile:</p>
<p><img src="https://willcrichton.net/notes/k-corrset/img/profile-batched.png"/></p>
<p>We’re spending 38% of our time in the bit-set iterator, and 36% of
our time in the bit-set intersection. Another 12% in copying the initial
bit-set for a given set of questions. And a long tail of other
operations like computing the correlation.</p>
<p>I tried my best to make the SIMD bit-set implementation fast, so I
don’t know of a way to improve these numbers. We might find another +10%
speedup from careful tweaking of the various constants (lane size, batch
size, etc.), but I don’t think there’s another order of magnitude left
on the table. If you know of a way, I invite you to try it out:</p>
<p>Also if you know of an analytic solution to this problem, i.e., a
smarter way to get an optimal answer without brute force, do let me know
as well! Otherwise, I hope you learned a bit about performance
engineering in Rust.</p>

</div>
  </body>
</html>
