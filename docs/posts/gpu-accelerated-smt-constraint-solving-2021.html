<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.osiris.cyber.nyu.edu/2021/01/11/gpu-accelerated-smt-constraint-solving/">Original</a>
    <h1>GPU accelerated SMT constraint solving (2021)</h1>
    
    <div id="readability-page-1" class="page"><div>
    


    <div role="main">
      <div>
        




<article>
  <p>By applying traditional fuzzing techniques, we achieved high throughput SMT constraint solving. We were able to achieve 23 billion execs/s using GPU acceleration.</p>

<p>SMT solvers typically apply very complicated algorithms to determine if a set of constraints is satisfiable (and produce a solution). The approach that we have taken is to abandon these fancy methods and try to throw random data at the formula over many many thousands of threads. This is essentially what fuzzing is: we throw random data at a function in an attempt to find a crash. Instead of a crash, here we try to find a solution to the SMT formula.</p>

<p>By choosing to brute force the SMT solution, the problem quickly becomes: how do we maximize throughput?</p>

<p><a href="https://github.com/moyix/fpsmt_gpu">https://github.com/moyix/fpsmt_gpu</a></p>

<h2 id="the-process">The process</h2>

<h3 id="gpu-acceleration">GPU acceleration</h3>

<p>GPUs offer the ability to spin up many thousands of threads each doing pure computation. To understand how we took advantage of CUDA, we first need to talk at a very high level about how GPUs work. When you run a program on a GPU, it is essentially running on a completely separate computer. The program running on the GPU is called the kernel. Even though both the host program and CUDA kernel can be defined in the same files, there are several caveats to managing input and output. If you want to cross the boundary between the two, for example to retrieve GPU data to CPU, you must use the provided cudaMemcpy function to move the buffer from device (GPU) memory to host (CPU) memory.</p>

<p>With CUDA programming we need to add annotations to variables and functions to annotate if they are to be run on host or on the GPU. Anywhere you see <code>__host__</code> means that that variable / function is a host function. Where you see <code>__device__</code> that implies the variable / function is meant for the GPU. These annotations define the boundaries between the host program and CUDA kernel. If you are in a <code>__device__</code> function on  the GPU, you won’t be able to access anything annotated with <code>__host__</code> and vice versa.</p>

<h3 id="smtlib">SMTLib</h3>

<p>We have slightly modified the <a href="https://github.com/mc-imperial/jfs">JFS SMT constraint solver</a> to run on a CUDA capable GPU. For the most part this modification was simply changing the <code>.cpp</code> extensions to <code>.cu</code> and adding <code>__device__</code> to things. Using this library, we can generate <code>LLVMFuzzerTestOneInput</code> functions from SMT theories. For example, the following SMT formula</p>

<div><div><pre><code>(set-info :smt-lib-version 2.6)
(set-logic QF_FP)
(declare-fun x () Float32)
(define-fun f1 () Float32 ((_ to_fp 8 24) #x3f800000))
(assert (fp.eq x f1))
(check-sat)
(exit)
</code></pre></div></div>

<p>Becomes…</p>

<div><div><pre><code><span>#include &#34;theory.h&#34;
</span><span>__device__</span> <span>int</span> <span>LLVMFuzzerTestOneInput</span><span>(</span><span>const</span> <span>uint8_t</span> <span>*</span><span>data</span><span>,</span> <span>size_t</span> <span>size</span><span>)</span> <span>{</span>
  <span>BufferRef</span><span>&lt;</span><span>const</span> <span>uint8_t</span><span>&gt;</span> <span>jfs_buffer_ref</span> <span>=</span> <span>BufferRef</span><span>&lt;</span><span>const</span> <span>uint8_t</span><span>&gt;</span><span>(</span><span>data</span><span>,</span> <span>size</span><span>);</span>
  <span>const</span> <span>Float</span><span>&lt;</span><span>8</span><span>,</span> <span>24</span><span>&gt;</span> <span>x</span> <span>=</span> <span>makeFloatFrom</span><span>&lt;</span><span>8</span><span>,</span> <span>24</span><span>&gt;</span><span>(</span><span>jfs_buffer_ref</span><span>,</span> <span>0</span><span>,</span> <span>31</span><span>);</span>
  <span>uint64_t</span> <span>jfs_num_const_sat</span> <span>=</span> <span>0</span><span>;</span>
  <span>const</span> <span>BitVector</span><span>&lt;</span><span>1</span><span>&gt;</span> <span>jfs_ssa_0</span> <span>=</span> <span>BitVector</span><span>&lt;</span><span>1</span><span>&gt;</span><span>(</span><span>UINT64_C</span><span>(</span><span>0</span><span>));</span>
  <span>const</span> <span>BitVector</span><span>&lt;</span><span>8</span><span>&gt;</span> <span>jfs_ssa_1</span> <span>=</span> <span>BitVector</span><span>&lt;</span><span>8</span><span>&gt;</span><span>(</span><span>UINT64_C</span><span>(</span><span>127</span><span>));</span>
  <span>const</span> <span>BitVector</span><span>&lt;</span><span>23</span><span>&gt;</span> <span>jfs_ssa_2</span> <span>=</span> <span>BitVector</span><span>&lt;</span><span>23</span><span>&gt;</span><span>(</span><span>UINT64_C</span><span>(</span><span>0</span><span>));</span>
  <span>const</span> <span>Float</span><span>&lt;</span><span>8</span><span>,</span> <span>24</span><span>&gt;</span> <span>jfs_ssa_3</span> <span>=</span> <span>Float</span><span>&lt;</span><span>8</span><span>,</span> <span>24</span><span>&gt;</span><span>(</span><span>jfs_ssa_0</span><span>,</span> <span>jfs_ssa_1</span><span>,</span> <span>jfs_ssa_2</span><span>);</span>
  <span>const</span> <span>bool</span> <span>jfs_ssa_4</span> <span>=</span> <span>x</span><span>.</span><span>ieeeEquals</span><span>(</span><span>jfs_ssa_3</span><span>);</span>
  <span>if</span> <span>(</span><span>jfs_ssa_4</span><span>)</span> <span>{</span>
    <span>++</span><span>jfs_num_const_sat</span><span>;</span>
  <span>}</span>
  <span>if</span> <span>(</span><span>jfs_num_const_sat</span> <span>==</span> <span>1</span><span>)</span> <span>{</span>
    <span>// Fuzzing target</span>
    <span>return</span> <span>1</span><span>;</span>
  <span>}</span> <span>else</span> <span>{</span>
    <span>return</span> <span>0</span><span>;</span>
  <span>}</span>
<span>}</span>
</code></pre></div></div>

<p>Notice the <code>__device__</code> annotation next to <code>LLVMFuzzerTestOneInput</code>. That lets CUDA know that that function should be run on the GPU rather than the host. Each of our GPU threads will call the <code>LLVMFuzzerTestOneInput</code> function in a loop.</p>

<h3 id="fuzzing">Fuzzing</h3>

<p>Our approach to fuzzing the SMTs is relatively simple. We choose some random number generator to generate input, then throw it at the SMT formulas. There is no feedback or corpus system for potentially improving the quality of input. This is called “blind” fuzzing.</p>

<p>We did not have an opportunity to test coverage guided fuzzing. We would expect that it would significantly reduce the throughput we currently achieve. Whether the increased efficiency of fuzzing outweighs the reduced throughput, we can’t say. This is to say nothing of the complexity of implementing such systems in a multi GPU setup.</p>

<h3 id="random-number-generation">Random Number Generation</h3>

<p>We tested several methods of random number generation: reduced round AES (specifically, two rounds), CHAM, and cuRAND. As we don’t require a cryptographically secure pseudorandom number generator, we can get away with using encryption algorithms like AES and CHAM. The variant of AES we used is CTR. The structure of our fuzzing loop varied depending on which number generator we were using.</p>

<p>The way we used AES and CHAM were quite simple. We initialize a key for each thread from <code>urandom</code>. We then cudaMemcpy the key into a global buffer onto the GPU. In our fuzzing loop, we encrypt a block buffer then throw it at <code>LLVMFuzzerTestOneInput</code>. The urandom initialization is an extra step in the host process before launching the CUDA kernel. Beyond initialization, it is important that all random number generation occurs on the GPU.</p>

<p><img src="https://blog.osiris.cyber.nyu.edu/images/2021/gpu-accelerated-smt-constraint-solving/aes.mmd.svg" alt="alt aes"/></p>

<p><img src="https://blog.osiris.cyber.nyu.edu/images/2021/gpu-accelerated-smt-constraint-solving/cham.mmd.svg" alt="alt cham"/></p>

<p>cuRAND is a library for random number generation with support for generating random numbers on the GPU and storing them in GPU memory. There was no extra initialization step on host before launching the CUDA kernel.</p>

<p><img src="https://blog.osiris.cyber.nyu.edu/images/2021/gpu-accelerated-smt-constraint-solving/curand.mmd.svg" alt="alt curand"/></p>

<h3 id="a-word-on-heat">A word on heat</h3>

<p>As with pretty much any computationally intensive process, heat is the enemy. When we run our fuzzer, we use very little VRAM, but maintain 100% core utilization while running. There is no IO to slow things down. Every thread just moves from one computation to the next.</p>

<p>We initially were using a single K80 to test on. As it turns out, when a K80 die temperature is 100C it shuts off and won’t be usable until you fully reboot the machine. We needed to rework the entire cooling solution of this one server we worked on to specifically handle the heat from the GPU.</p>

<p>In later tests we used a dual RTX 3090 machine. In this setup, thermal throttling was the only real issue.</p>

<h2 id="results">Results</h2>

<p>The name of the game here is speed. The most optimal configuration is that which maximizes executions per second. That is how many times can we run our fuzz loop in a second over all threads. We created some simple benchmarks where we run the fuzzer with some set number of iterations of the fuzzing loop in each thread for each of the random number generators we used. Since we always launch the same number of threads, and run the loop the same number of times each, we have a set number of computations per run.</p>

<p>Over 750 runs of each number generator on the dual 3090 machine, we can see that cuRAND (24 billion execs/second) is a bit faster than CHAM (20 billion execs/second), with AES (8 billion execs/second) being significantly slower than both.</p>

<p><img src="https://blog.osiris.cyber.nyu.edu/images/2021/gpu-accelerated-smt-constraint-solving/execsps.png" alt="alt execs per second"/></p>

<p>Another way to view this would be the amount of time it takes</p>

<p><img src="https://blog.osiris.cyber.nyu.edu/images/2021/gpu-accelerated-smt-constraint-solving/execsps-over-epoch.png" alt="alt epoch time"/></p>

</article>











      </div>
    </div>
  </div></div>
  </body>
</html>
