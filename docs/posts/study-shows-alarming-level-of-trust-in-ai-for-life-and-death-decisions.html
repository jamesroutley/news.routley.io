<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.theengineer.co.uk/content/news/study-shows-alarming-level-of-trust-in-ai-for-life-and-death-decisions/">Original</a>
    <h1>Study shows &#39;alarming&#39; level of trust in AI for life and death decisions</h1>
    
    <div id="readability-page-1" class="page"><div itemprop="articleBody">
                            <p><span lang="EN-IE">Having been briefly shown a list of eight target photos marked either friend or foe, test subjects then had to make rapid decisions on whether to carry out simulated assassinations on individual targets via a drone strike. A second opinion on the validity of the targets was given by AI. Unbeknownst to the humans, the AI advice was completely random. </span></p>
<p><a href="https://www.theengineer.co.uk/category/artificial-intelligence/" target="_blank" rel="noopener"><span lang="EN-IE">MORE ON AI</span></a></p>
<p><span lang="EN-IE">Despite being informed of the fallibility of the AI systems in the study, two-thirds of subjects allowed their decisions to be influenced by the AI. The work, conducted by scientists at the University of California – Merced, is <a href="https://www.nature.com/articles/s41598-024-69771-z" target="_blank" rel="noopener">published in Scientific Reports</a>.</span></p>
<p><span lang="EN-IE">“As a society, with AI accelerating so quickly, we need to be concerned about the potential for overtrust,” said principal investigator Professor Colin Holbrook, a member of UC Merced’s <a href="https://cogsci.ucmerced.edu/" target="_blank" rel="noopener">Department of Cognitive and Information Sciences.</a></span></p>
<p><span lang="EN-IE">According to Holbrook, the study’s design was a means of testing the broader question of putting too much trust in AI under uncertain circumstances. He said the findings are not just about military decisions and could be applied to contexts such as police being influenced by AI to use lethal force or a paramedic being swayed by AI when deciding who to treat first in a medical emergency. It’s claimed the findings could also be applicable to major life decisions such as buying a home.</span></p>
<p><span lang="EN-IE">“Our project was about high-risk decisions made under uncertainty when the AI is unreliable,” said Holbrook. “</span><span>We should have a healthy scepticism about AI, especially in life-or-death decisions.</span></p>
<p><span lang="EN-IE">“We see AI doing extraordinary things and we think that because it’s amazing in this domain, it will be amazing in another. We can’t assume that. These are still devices with limited abilities.”</span></p>

                        </div></div>
  </body>
</html>
