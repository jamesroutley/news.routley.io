<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://pganalyze.com/blog/postgres-18-async-io">Original</a>
    <h1>Waiting for Postgres 18: Accelerating Disk Reads with Asynchronous I/O</h1>
    
    <div id="readability-page-1" class="page"><div><div><p>With the Postgres 18 Beta 1 release this week a multi-year effort, and significant architectural shift in Postgres is taking shape: <strong>Asynchronous I/O (AIO)</strong>. These capabilities are still under active development, but they represent a fundamental change in how Postgres handles I/O, offering the potential for significant performance gains, particularly in cloud environments where latency is often the bottleneck.</p>

<p>While some features may still be adjusted or dropped during the beta period before the final release, now is the best time to test and validate how Postgres 18 performs in practice. In Postgres 18 AIO is limited to read operations; writes remain synchronous, though support may expand in future versions.</p>
<p>In this post, we explain what asynchronous I/O is, how it works in Postgres 18, and what it means for performance optimization.</p>
<h2 id="why-asynchronous-io-matters"><a href="#why-asynchronous-io-matters" aria-label="why asynchronous io matters permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Why asynchronous I/O matters</h2>
<p>Postgres has historically operated under a synchronous I/O model, meaning every read request is a blocking system call. The database must pause and wait for the operating system to return the data before continuing. This design introduces unnecessary waits on I/O, especially in cloud environments where storage is often network-attached (e.g. Amazon EBS) and I/O can have over 1ms of latency.</p>
<p>In a simplified model, we can illustrate the difference like this, ignoring any prefetching/batching the Linux kernel might do:</p>
<p><span>
      <a href="https://olu.online/static/cd0be5dde105345bb288ac73655b90f1/913b9/sync_vs_async.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Diagram showing synchronous vs asynchronous I/O model with concurrent requests" title="In the asynchronous I/O model, multiple read requests can be in flight simultaneously" src="https://olu.online/static/cd0be5dde105345bb288ac73655b90f1/1d69c/sync_vs_async.png" srcset="/static/cd0be5dde105345bb288ac73655b90f1/4dcb9/sync_vs_async.png 188w, /static/cd0be5dde105345bb288ac73655b90f1/5ff7e/sync_vs_async.png 375w, /static/cd0be5dde105345bb288ac73655b90f1/1d69c/sync_vs_async.png 750w, /static/cd0be5dde105345bb288ac73655b90f1/78797/sync_vs_async.png 1125w, /static/cd0be5dde105345bb288ac73655b90f1/aa440/sync_vs_async.png 1500w, /static/cd0be5dde105345bb288ac73655b90f1/913b9/sync_vs_async.png 1822w" sizes="(max-width: 750px) 100vw, 750px" loading="lazy" decoding="async"/>
  </a>
    </span></p>
<p>You can picture synchronous I/O like an imaginary librarian who retrieves one book at a time, returning before fetching the next. This inefficiency compounds as the number of physical reads for a logical operation increases.</p>
<p>Asynchronous I/O eliminates that bottleneck by allowing programs to issue multiple read requests concurrently, without waiting for prior reads to return. In an async program flow, I/O requests are scheduled to be read into a memory location and the program waits for completion of those reads, instead of issuing each read individually.</p>
<h3 id="how-postgres-17s-read-streams-paved-the-way"><a href="#how-postgres-17s-read-streams-paved-the-way" aria-label="how postgres 17s read streams paved the way permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>How Postgres 17’s read streams paved the way</h3>
<p>The work for implementing asynchronous I/O in Postgres has been many years in the making. Postgres 17 introduced an essential internal abstraction, <a href="https://olu.online/blog/5mins-postgres-17-streaming-io">with the introduction of read stream APIs</a>. These internal changes standardized how read operations were issued across different subsystems and streamlined the use of <code>posix_fadvise()</code> to request that the operating system prefetch data in advance.</p>
<p>However, this advisory mechanism only hinted to the kernel to load data into the OS page cache, not into Postgres’ own shared buffers. Postgres still had to issue syscalls for each read, and OS readahead behaviour is not always consistent.</p>
<p>The upcoming Postgres 18 release removes this indirection. With true asynchronous reads, data is fetched directly into shared buffers by the database itself, bypassing reliance on kernel-level heuristics and enabling more predictable, higher-throughput I/O behavior.</p>
<h2 id="new-io_method-setting-in-postgres-18"><a href="#new-io_method-setting-in-postgres-18" aria-label="new io_method setting in postgres 18 permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>New io_method setting in Postgres 18</h2>
<p>To control the mechanism used for asynchronous I/O, Postgres 18 introduces a new configuration parameter: <code>io_method</code>. This setting determines how read operations are dispatched under the hood, and whether they’re handled synchronously, offloaded to I/O workers, or submitted directly to the kernel via <code>io_uring</code>.</p>
<p>The <code>io_method</code> setting must be set in postgresql.conf and cannot be changed without restarting. It controls which  I/O implementation Postgres will use and is essential to understand when tuning I/O performance in Postgres 18. There are three possible settings for io_method, with the current default (as of Beta 1) being <code>worker</code>.</p>
<h3 id="io_method--sync"><a href="#io_method--sync" aria-label="io_method  sync permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>io_method = sync</h3>
<p>The <code>sync</code> setting in Postgres 18 mirrors the synchronous behavior as was implemented in Postgres 17. Reads are still synchronous and blocking, using <code>posix_fadvise()</code> to achieve read-ahead in the Linux kernel.</p>
<h3 id="io_method--worker"><a href="#io_method--worker" aria-label="io_method  worker permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>io_method = worker</h3>
<p>The <code>worker</code> setting utilizes dedicated <strong>I/O worker processes</strong> running in the background that retrieve data independently of query execution. The main backend process enqueues read requests, and these workers interact with the Linux kernel to fetch data, which is then delivered into shared buffers, <strong>without blocking the main process</strong>.</p>
<p>The number of I/O workers can be configured through the new <code>io_workers</code> setting, and defaults to <code>3</code>. These workers are always running, and shared across all connections and databases.</p>
<h3 id="io_method--io_uring"><a href="#io_method--io_uring" aria-label="io_method  io_uring permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>io_method = io_uring</h3>
<p>This Linux-specific method uses <strong><code>io_uring</code></strong>, a high-performance I/O interface introduced in kernel version 5.1. Asynchronous I/O has been available in Linux since kernel version 2.5, but it was largely considered inefficient and hard to use. <code>io_uring</code> establishes a <strong>shared ring buffer</strong> between Postgres and the kernel, minimizing syscall overhead. This is the most efficient option, <strong>eliminating the need for I/O worker processes entirely</strong>, but is only available on newer Linux kernels and requires file systems and configurations compatible with <code>io_uring</code> support.</p>
<p><strong>Important note:</strong> As of the Postgres 18 Beta 1, asynchronous I/O is supported for sequential scans, bitmap heap scans, and maintenance operations like <code>VACUUM</code>.</p>
<h2 id="asynchronous-io-in-action"><a href="#asynchronous-io-in-action" aria-label="asynchronous io in action permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Asynchronous I/O in action</h2>
<p>Asynchronous I/O delivers the most noticeable gains in cloud environments where storage is network-attached, such as Amazon EBS volumes. In these setups, individual disk reads often take multiple milliseconds, introducing substantial latency compared to local SSDs.</p>
<p>With traditional synchronous I/O, each of these reads blocks query execution until the data arrives, leading to idle CPU time and degraded throughput. By contrast, asynchronous I/O allows Postgres to issue multiple read requests in parallel and continue processing while waiting for results. This reduces query latency and enables much more efficient use of available I/O bandwidth and CPU cycles.</p>
<h3 id="benchmark-on-aws-doubling-read-performance--even-greater-gains-from-io_uring"><a href="#benchmark-on-aws-doubling-read-performance--even-greater-gains-from-io_uring" aria-label="benchmark on aws doubling read performance  even greater gains from io_uring permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Benchmark on AWS: Doubling read performance &amp; even greater gains from io_uring</h3>
<p>To evaluate the performance impact of asynchronous I/O, we benchmarked a representative workload on AWS, comparing Postgres 17 with Postgres 18 using different <code>io_method</code> settings. The workload remained identical across versions, allowing us to isolate the effects of the new I/O infrastructure.</p>
<p>We&#39;ve tested on an AWS c7i.8xlarge instance (32 vCPUs, 64 GB RAM), with a dedicated 100GB <code>io2</code> EBS volume for Postgres, with 20,000 provisioned IOPS. The test table was 3.5GB in size:</p>
<div data-language="sql"><pre><code><span>CREATE</span> <span>TABLE</span> test<span>(</span>id <span>int</span><span>)</span><span>;</span>
<span>INSERT</span> <span>INTO</span> test <span>SELECT</span> <span>*</span> <span>FROM</span> generate_series<span>(</span><span>0</span><span>,</span> <span>100000000</span><span>)</span><span>;</span></code></pre></div>
<div data-language="text"><pre><code>test=# \dt+
                                   List of relations
 Schema | Name | Type  |  Owner   | Persistence | Access method |  Size   | Description 
--------+------+-------+----------+-------------+---------------+---------+-------------
 public | test | table | postgres | permanent   | heap          | 3458 MB | 
(1 row)</code></pre></div>
<p>Between test runs we cleared the OS page cache (<code>sync; echo 3 &gt; /proc/sys/vm/drop_caches</code>), and restarted Postgres, to gather cold cache results. Warm cache results represent running the query a second time. We repeated the complete test run for each configuration multiple times, retaining the best result out of three.</p>
<p>Whilst we also tested with parallel query, to keep results easier to understand all results below are with parallel query turned off (<code>max_parallel_workers_per_gather = 0</code>).</p>
<p><strong>Cold cache results:</strong></p>
<p>Postgres 17, using synchronous I/O, established the baseline. It showed consistent read latency, but throughput was limited by the need to complete each I/O request before issuing the next:</p>
<div data-language="text"><pre><code>test=# SELECT COUNT(*) FROM test;
   count   
-----------
 100000001
(1 row)

Time: 15830.880 ms (00:15.831)</code></pre></div>
<p>Postgres 18, when configured with <code>io_method = sync</code>, performed nearly identically, confirming that behavior remains unchanged without enabling asynchronous I/O:</p>
<div data-language="text"><pre><code>test=# SELECT COUNT(*) FROM test;
   count   
-----------
 100000001
(1 row)

Time: 15071.089 ms (00:15.071)</code></pre></div>
<p>However, when we switch to using the <code>worker</code> method, with 3 I/O workers (the default) a clear improvement shows:</p>
<div data-language="text"><pre><code>test=# SELECT COUNT(*) FROM test;
   count   
-----------
 100000001
(1 row)

Time: 10051.975 ms (00:10.052)</code></pre></div>
<p>We observed some gains by raising the number of I/O workers, but the biggested improvement comes when utilizing <code>io_uring</code>:</p>
<div data-language="text"><pre><code>test=# SELECT COUNT(*) FROM test;
   count   
-----------
 100000001
(1 row)

Time: 5723.423 ms (00:05.723)</code></pre></div>
<p>When we graph this (measuring runtime in ms, lower is better), it’s clear that Postgres 18 performs significantly better in cold cache situations:</p>
<p><span>
      <a href="https://olu.online/static/506febf39b7d14c7ba413260d30b63cc/50e7d/runtime-compared.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Read performance comparison between Postgres 17 and 18 with different io_method settings" title="Read performance comparison between Postgres 17 and 18 with different io_method settings" src="https://olu.online/static/506febf39b7d14c7ba413260d30b63cc/1d69c/runtime-compared.png" srcset="/static/506febf39b7d14c7ba413260d30b63cc/4dcb9/runtime-compared.png 188w, /static/506febf39b7d14c7ba413260d30b63cc/5ff7e/runtime-compared.png 375w, /static/506febf39b7d14c7ba413260d30b63cc/1d69c/runtime-compared.png 750w, /static/506febf39b7d14c7ba413260d30b63cc/78797/runtime-compared.png 1125w, /static/506febf39b7d14c7ba413260d30b63cc/aa440/runtime-compared.png 1500w, /static/506febf39b7d14c7ba413260d30b63cc/50e7d/runtime-compared.png 1738w" sizes="(max-width: 750px) 100vw, 750px" loading="lazy" decoding="async"/>
  </a>
    </span></p>
<p>For cold cache tests, both <code>worker</code> and <code>io_uring</code> delivered a consistent <strong>2-3x improvement</strong> in read performance compared to the legacy <code>sync</code> method.</p>
<p>Whilst <code>worker</code> offers a slight benefit for warm cache tests due to its parallelism, <code>io_uring</code> consistently performed better in cold cache tests, and its lower syscall overhead and reduced process coordination would make <strong><code>io_uring</code> the recommended setting</strong> for maximizing I/O performance in Postgres 18.</p>
<p>This performance shift for disk reads has meaningful implications for infrastructure planning, especially in cloud environments. By reducing I/O wait time, asynchronous reads can substantially increase query throughput, reduce latency and CPU overhead. For read-heavy workloads, this may translate into smaller instance sizes or better utilization of existing resources.</p>
<h3 id="tuning-effective_io_concurrency"><a href="#tuning-effective_io_concurrency" aria-label="tuning effective_io_concurrency permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Tuning effective_io_concurrency</h3>
<p>In Postgres 18, <code>effective_io_concurrency</code> becomes more interesting, but only when used with an asynchronous <code>io_method</code> such as <code>worker</code> or <code>io_uring</code>. Previously, this setting merely advised the OS to prefetch data using <code>posix_fadvise</code>. Now, it directly controls how many asynchronous read-ahead requests Postgres issues internally.</p>
<p>The number of blocks read ahead is influenced by both <code>effective_io_concurrency</code> and <code>io_combine_limit</code>, following the general formula:</p>
<div data-language="text"><pre><code>maximum read-ahead = effective_io_concurrency × io_combine_limit</code></pre></div>
<p>This gives DBAs and engineers greater control over I/O behavior. The optimal value requires benchmarking, as it depends on your I/O subsystem. For example, higher values may benefit cloud environments with high latency that also support high concurrency, like AWS EBS with high provisioned IOPS.</p>
<p>When doing our benchmarks, we also tested higher <code>effective_io_concurrency</code> (between 16 and 128) but did not see a meaningful difference. However, that is likely due to the simple test query used.</p>
<p>It’s worth noting that the previous default of effective_io_concurrency was 1 in Postgres 17, which is now raised to 16, <a href="https://git.postgresql.org/gitweb/?p=postgresql.git;a=commit;h=ff79b5b2ab">based on benchmarks done by the Postgres community</a>.</p>
<h3 id="monitoring-ios-in-flight-with-pg_aios"><a href="#monitoring-ios-in-flight-with-pg_aios" aria-label="monitoring ios in flight with pg_aios permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Monitoring I/Os in flight with pg_aios</h3>
<p>As mentioned, previous versions of Postgres with synchronous I/O made it easy to spot read delays: the backend process would block while waiting for disk access, and monitoring tools like pganalyze can reliably surface <code>IO / DataFileRead</code> as a wait event during these stalls.</p>
<p>For example, here we can see wait events clearly in Postgres 17 synchronous I/O.</p>
<p><span>
      <a href="https://olu.online/static/67303bca18e1ab006c16c26979172b33/8deec/wait_events_io_read.png" target="_blank" rel="noopener">
    <span></span>
  <img alt="Screenshot of pganalyze showing wait events in Postgres 17" title="pganalyze interface showing clear IO / DataFileRead wait events in Postgres 17" src="https://olu.online/static/67303bca18e1ab006c16c26979172b33/1d69c/wait_events_io_read.png" srcset="/static/67303bca18e1ab006c16c26979172b33/4dcb9/wait_events_io_read.png 188w, /static/67303bca18e1ab006c16c26979172b33/5ff7e/wait_events_io_read.png 375w, /static/67303bca18e1ab006c16c26979172b33/1d69c/wait_events_io_read.png 750w, /static/67303bca18e1ab006c16c26979172b33/78797/wait_events_io_read.png 1125w, /static/67303bca18e1ab006c16c26979172b33/aa440/wait_events_io_read.png 1500w, /static/67303bca18e1ab006c16c26979172b33/8deec/wait_events_io_read.png 2136w" sizes="(max-width: 750px) 100vw, 750px" loading="lazy" decoding="async"/>
  </a>
    </span></p>
<p>With asynchronous I/O in Postgres 18, backend wait behavior changes. When using <code>io_method = worker</code>, the backend process delegates reads to a separate I/O worker. As a result, the backend may appear idle or show the new <code>IO / AioIoCompletion</code> wait event, while the I/O worker shows the actual I/O wait events:</p>
<div data-language="sql"><pre><code><span>SELECT</span> backend_type<span>,</span> query<span>,</span> state<span>,</span> wait_event_type<span>,</span> wait_event
  <span>FROM</span> pg_stat_activity
 <span>WHERE</span> backend_type <span>=</span> <span>&#39;client backend&#39;</span> <span>OR</span> backend_type <span>=</span> <span>&#39;io worker&#39;</span><span>;</span></code></pre></div>
<div data-language="text"><pre><code>  backend_type  | state  | wait_event_type |   wait_event    
----------------+--------+-----------------+-----------------
 client backend | active | IO              | AioIoCompletion
 io worker      |        | IO              | DataFileRead
 io worker      |        | IO              | DataFileRead
 io worker      |        | IO              | DataFileRead
(4 rows)</code></pre></div>
<p>With <code>io_method = io_uring</code>, read operations are submitted directly to the kernel and completed asynchronously. The backend does not block on a traditional I/O syscall, so this activity is not visible from the Postgres side, even though I/O is in progress.</p>
<p>To help with debugging of I/O requests in flight, the new <code>pg_aios</code> view can show Postgres internal state, even when using <code>io_uring</code>:</p>

<div data-language="text"><pre><code>  pid  | io_id | io_generation |    state     | operation |    off    | length | target | handle_data_len | raw_result | result  |                   target_desc                    | f_sync | f_localmem | f_buffered 
-------+-------+---------------+--------------+-----------+-----------+--------+--------+-----------------+------------+---------+--------------------------------------------------+--------+------------+------------
 91452 |     1 |          4781 | SUBMITTED    | read      | 996278272 | 131072 | smgr   |              16 |            | UNKNOWN | blocks 383760..383775 in file &#34;base/16384/16389&#34; | f      | f          | t
 91452 |     2 |          4785 | SUBMITTED    | read      | 996147200 | 131072 | smgr   |              16 |            | UNKNOWN | blocks 383744..383759 in file &#34;base/16384/16389&#34; | f      | f          | t
 91452 |     3 |          4796 | SUBMITTED    | read      | 996409344 | 131072 | smgr   |              16 |            | UNKNOWN | blocks 383776..383791 in file &#34;base/16384/16389&#34; | f      | f          | t
 91452 |     4 |          4802 | SUBMITTED    | read      | 996016128 | 131072 | smgr   |              16 |            | UNKNOWN | blocks 383728..383743 in file &#34;base/16384/16389&#34; | f      | f          | t
 91452 |     5 |          3175 | COMPLETED_IO | read      | 995885056 | 131072 | smgr   |              16 |     131072 | UNKNOWN | blocks 383712..383727 in file &#34;base/16384/16389&#34; | f      | f          | t
(5 rows)</code></pre></div>
<p>Understanding these behavior changes and understanding the impact of asynchronous execution is essential when optimizing I/O performance in Postgres 18.</p>
<h2 id="heads-up-async-io-makes-io-timing-information-hard-to-interpret"><a href="#heads-up-async-io-makes-io-timing-information-hard-to-interpret" aria-label="heads up async io makes io timing information hard to interpret permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Heads Up: Async I/O makes I/O timing information hard to interpret</h2>
<p>Asynchronous I/O introduces a shift in how execution timing is reported. When the backend no longer blocks directly on disk reads (as is the case with <code>worker</code> or <code>io_uring</code>) the complete time spent doing I/O may not be reflected in <code>EXPLAIN ANALYZE</code> output. This can make I/O-bound queries seem to require less I/O effort than previously.</p>
<p>First, let&#39;s run the earlier query in <code>EXPLAIN ANALYZE</code> on a cold cache in Postgres 17:</p>
<div data-language="text"><pre><code>test=# EXPLAIN (ANALYZE, BUFFERS, TIMING OFF) SELECT COUNT(*) FROM test;
                                               QUERY PLAN                                               
--------------------------------------------------------------------------------------------------------
 Aggregate  (cost=1692478.40..1692478.41 rows=1 width=8) (actual rows=1 loops=1)
   Buffers: shared read=442478
   I/O Timings: shared read=14779.316
   -&gt;  Seq Scan on test  (cost=0.00..1442478.32 rows=100000032 width=0) (actual rows=100000001 loops=1)
         Buffers: shared read=442478
         I/O Timings: shared read=14779.316
 Planning:
   Buffers: shared hit=13 read=6
   I/O Timings: shared read=3.182
 Planning Time: 8.136 ms
 Execution Time: 18006.405 ms
(11 rows)</code></pre></div>
<p>We&#39;ve read 442,478 buffers in 14.8 seconds.</p>
<p>And now, we repeat the test on Postgres 18 with the default settings (<code>io_method = worker</code>):</p>
<div data-language="text"><pre><code>test=# EXPLAIN (ANALYZE, BUFFERS, TIMING OFF) SELECT COUNT(*) FROM test;
                                                QUERY PLAN                                                 
-----------------------------------------------------------------------------------------------------------
 Aggregate  (cost=1692478.40..1692478.41 rows=1 width=8) (actual rows=1.00 loops=1)
   Buffers: shared read=442478
   I/O Timings: shared read=7218.835
   -&gt;  Seq Scan on test  (cost=0.00..1442478.32 rows=100000032 width=0) (actual rows=100000001.00 loops=1)
         Buffers: shared read=442478
         I/O Timings: shared read=7218.835
 Planning:
   Buffers: shared hit=13 read=6
   I/O Timings: shared read=2.709
 Planning Time: 2.925 ms
 Execution Time: 10480.827 ms
(11 rows)</code></pre></div>
<p>We&#39;ve read 442,478 buffers in 7.2 seconds.</p>
<p>Whilst with parallel query we get a summary of all the I/O time across all parallel workers, no such summarization occurs with I/O workers. What we are seeing is the wait time for the I/O to be completed, ignoring any parallelism that may happen behind the scenes.</p>
<p>This is technically not a behaviour change, since even in Postgres 17 the time reported was the time spent waiting on I/Os, not the time spent performing the I/O, e.g. Kernel I/O time for readahead was never accounted for.</p>
<p>Historically I/O timing was often equated with I/O effort, instead of just looking at shared buffer read counts, in order to distinguish from a OS page cache hit. Now, in Postgres 18, interpreting I/O timing requires more caution: asynchronous I/O can hide I/O overhead in query plans.</p>
<h2 id="conclusion"><a href="#conclusion" aria-label="conclusion permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>Conclusion</h2>
<p>To summarize, the upcoming release of Postgres 18 marks the beginning of a major evolution in how I/O is handled. While currently limited to reads, asynchronous I/O already opens the door to significant performance improvements in high-latency cloud environments.</p>
<p>But some of these gains come with tradeoffs. Engineering teams will need to adjust their observability practices, learn new semantics for timing and wait events, and perhaps revisit tuning parameters with previously limited impact, like <code>effective_io_conurrency</code>.</p>
<h3 id="in-summary"><a href="#in-summary" aria-label="in summary permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>In summary</h3>
<ul>
<li>Asynchronous I/O support in Postgres 18 introduces <code>worker</code> (as the default) and <code>io_uring</code> options under the new <code>io_method</code> setting.</li>
<li>Benchmarks show up to a 2-3x throughput improvement for read-heavy workloads in cloud environments.</li>
<li>Observability practices need to evolve: <code>EXPLAIN ANALYZE</code> may underreport I/O effort, and new views like <code>pg_aios</code> will help provide insights.</li>
<li>Tools like pganalyze will be adapting to these changes to continue surfacing relevant performance insights.</li>
</ul>
<p>As Postgres development continues, future versions (19 and beyond) may bring asynchronous write support, further reducing I/O bottlenecks in modern workloads, and enabling production use of Direct I/O.</p>
<h3 id="references"><a href="#references" aria-label="references permalink"><svg aria-hidden="true" focusable="false" height="16" version="1.1" viewBox="0 0 16 16" width="16"><path fill-rule="evenodd" d="M4 9h1v1H4c-1.5 0-3-1.69-3-3.5S2.55 3 4 3h4c1.45 0 3 1.69 3 3.5 0 1.41-.91 2.72-2 3.25V8.59c.58-.45 1-1.27 1-2.09C10 5.22 8.98 4 8 4H4c-.98 0-2 1.22-2 2.5S3 9 4 9zm9-3h-1v1h1c1 0 2 1.22 2 2.5S13.98 12 13 12H9c-.98 0-2-1.22-2-2.5 0-.83.42-1.64 1-2.09V6.25c-1.09.53-2 1.84-2 3.25C6 11.31 7.55 13 9 13h4c1.45 0 3-1.69 3-3.5S14.5 6 13 6z"></path></svg></a>References</h3>
<ul>
<li><a href="https://www.postgresql.org/docs/devel/runtime-config-resource.html#GUC-IO-METHOD">PostgreSQL <code>io_method</code> GUC (Postgres 18)</a></li>
<li><a href="https://www.postgresql.org/docs/current/runtime-config-resource.html#GUC-EFFECTIVE-IO-CONCURRENCY">PostgreSQL <code>effective_io_concurrency</code></a></li>
<li><a href="https://www.postgresql.org/docs/current/storage-buffer.html">PostgreSQL Shared Buffers and Buffer Management</a></li>
<li><a href="https://www.postgresql.org/docs/current/monitoring-stats.html#PG-STAT-ACTIVITY-VIEW"><code>pg_stat_activity</code> View</a></li>
<li><a href="https://www.postgresql.org/docs/devel/monitoring-stats.html#PG-STAT-IO-VIEW"><code>pg_stat_io</code> View</a></li>
<li><a href="https://www.postgresql.org/docs/devel/monitoring-stats.html#PG-AIOS-VIEW"><code>pg_aios</code> View (New in Postgres 18)</a></li>
<li><a href="https://man7.org/linux/man-pages/man2/posix_fadvise.2.html"><code>posix_fadvise()</code> System Call</a></li>
<li><a href="https://www.google.com/url?q=https://www.man7.org/linux/man-pages/man7/io_uring.7.html&amp;sa=D&amp;source=docs&amp;ust=1746206271490972&amp;usg=AOvVaw1B_RmjsiRaB-HDroNJCv6b">Linux io_uring Man Page</a></li>
<li><a href="https://pganalyze.com/blog/5mins-postgres-17-streaming-io">5mins of Postgres: Waiting for Postgres 17: Streaming I/O for sequential scans &amp; ANALYZE</a></li>
</ul></div></div><div><h3>Enjoy blog posts like this?</h3><p>Get them once a month to your inbox</p></div></div>
  </body>
</html>
