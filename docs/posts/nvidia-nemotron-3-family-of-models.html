<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://research.nvidia.com/labs/nemotron/Nemotron-3/">Original</a>
    <h1>Nvidia Nemotron 3 Family of Models</h1>
    
    <div id="readability-page-1" class="page"><div>
      
        <header>
          
          
        
        
        
          <p><strong><i aria-hidden="true"></i> Published:</strong> <time datetime="2025-12-15T00:00:00-08:00">December 15, 2025</time></p>
        
        
             
        
    
        </header>
      

      <section itemprop="text">
        <p><img src="https://research.nvidia.com/labs/nemotron/Nemotron-3/images/nvidia-nemotron-3-nano/nano-3-aa.png"/></p>

<p><a href="https://huggingface.co/collections/nvidia/nvidia-nemotron-v3">Models</a>    <a href="https://research.nvidia.com/labs/nemotron/files/NVIDIA-Nemotron-3-White-Paper.pdf">Nemotron 3 White Paper</a>    <a href="https://research.nvidia.com/labs/nemotron/files/NVIDIA-Nemotron-3-Nano-Technical-Report.pdf">Nano Tech Report</a></p>

<p>We announce NVIDIA Nemotron 3, the most efficient family of open models with leading accuracy for agentic AI applications. The Nemotron 3 family consists of three models: Nano, Super, and Ultra. These models deliver strong agentic, reasoning, and conversational capabilities.</p>

<p>Nano, the smallest model, outperforms comparable models in accuracy while remaining extremely cost-efficient for inference. Super is optimized for collaborative agents and high-volume workloads such as IT ticket automation. Ultra, the largest model, provides state-of-the-art accuracy and reasoning performance.</p>

<p>We are releasing the Nemotron 3 Nano <a href="https://huggingface.co/collections/nvidia/nvidia-nemotron-v3">model</a> and <a href="https://research.nvidia.com/labs/nemotron/files/NVIDIA-Nemotron-3-Nano-Technical-Report.pdf">technical report</a>. Super and Ultra releases will follow in the coming months.</p>

<h2 id="nemotron-3-technologies">Nemotron 3 technologies</h2>

<ul>
  <li><strong>Hybrid MoE</strong>: Nemotron 3 family of models utilize a hybrid Mamba-Transformer MoE architecture to provide best-in-class throughput while having better or on-par accuracy than standard Transformers.</li>
  <li><strong>LatentMoE</strong>: Super and Ultra utilize Latent MoE, a novel hardware-aware expert design for improved accuracy.</li>
  <li><strong>Multi-Token Prediction</strong>: Super and Ultra incorporate MTP layers for improved long-form text generation efficiency and better model quality.</li>
  <li><strong>NVFP4</strong>: Super and Ultra are trained with NVFP4.</li>
  <li><strong>Long Context</strong>: Nemotron 3 models support context length up to 1M tokens.</li>
  <li><strong>Multi-environment Reinforcement Learning Post-training</strong>: Nemotron 3 models are trained using a diverse set of RL environments helping models achieve superior accuracy across a broad range of tasks.</li>
  <li><strong>Granular Reasoning Budget Control at Inference Time</strong>:  Nemotron 3 models are trained to work with inference-time budget control.</li>
</ul>

<h2 id="nemotron-3-nano">Nemotron 3 Nano</h2>

<p><img src="https://research.nvidia.com/labs/nemotron/Nemotron-3/images/nvidia-nemotron-3-nano/nano-3-comparison.png"/></p>

<p>Nemotron 3 Nano is a 3.2B active (3.6B with embeddings), 31.6B total parameter model. It achieves better accuracy than our previous generation Nemotron 2 Nano while activating less than half of the parameters per forward pass.</p>

<h4 id="key-highlights">Key highlights:</h4>
<ul>
  <li>More <strong>accurate</strong> than GPT-OSS-20B and Qwen3-30B-A3B-Thinking-2507 on popular benchmarks spanning different categories.</li>
  <li>On the 8K input / 16K output setting with a single H200, Nemotron 3 Nano provides <strong>inference throughput</strong> that is <strong>3.3x higher than Qwen3-30B-A3B and 2.2x higher than GPT-OSS-20B</strong>.</li>
  <li>Supports <strong>context length up to 1M tokens</strong> while outperforming both GPT-OSS-20B and Qwen3-30B-A3B-Instruct-2507 on RULER across different context lengths.</li>
  <li>We are releasing the model weights, training recipe, and all the data for which we hold redistribution rights.</li>
</ul>

<h2 id="open-source">Open Source</h2>

<p>Along with the <a href="https://research.nvidia.com/labs/nemotron/files/NVIDIA-Nemotron-3-White-Paper.pdf">Nemotron 3 white paper</a> and the <a href="https://research.nvidia.com/labs/nemotron/files/NVIDIA-Nemotron-3-Nano-Technical-Report.pdf">Nano 3 technical report</a>, we are releasing the following:</p>

<h4 id="checkpoints">Checkpoints:</h4>
<ul>
  <li><a href="https://huggingface.co/nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-FP8"><strong>Nemotron 3 Nano 30B-A3B FP8</strong></a>: the final post-trained and FP8 quantized Nano model</li>
  <li><a href="https://huggingface.co/nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16"><strong>Nemotron 3 Nano 30B-A3B BF16</strong></a>: the post-trained Nano model</li>
  <li><a href="https://huggingface.co/nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-Base-BF16"><strong>Nemotron 3 Nano 30B-A3B Base BF16</strong></a>: the pre-trained base Nano model</li>
  <li><a href="https://huggingface.co/nvidia/Qwen3-Nemotron-235B-A22B-GenRM"><strong>Qwen-3-Nemotron-235B-A22B-GenRM</strong></a>: the GenRM used for RLHF</li>
</ul>

<h4 id="data">Data:</h4>
<ul>
  <li><a href="https://huggingface.co/datasets/nvidia/Nemotron-CC-v2.1"><strong>Nemotron-CC-v2.1</strong></a>: 2.5 trillion new English tokens from Common Crawl, including curated data from 3 recent snapshots, synthetic rephrasing, and translation to English from other languages.</li>
  <li><a href="https://huggingface.co/datasets/nvidia/Nemotron-CC-Code-v1"><strong>Nemotron-CC-Code-v1</strong></a>: A pretraining dataset consisting of 428 billion high-quality code tokens obtained from processing Common Crawl Code pages using the Lynx + LLM pipeline from <a href="https://huggingface.co/datasets/nvidia/Nemotron-CC-Math-v1">Nemotron-CC-Math-v1</a>. Preserves equations and code, standardizes math equations to LaTeX, and removes noise.</li>
  <li><a href="https://huggingface.co/datasets/nvidia/Nemotron-Pretraining-Code-v2"><strong>Nemotron-Pretraining-Code-v2</strong></a>: Refresh of curated GitHub code references with multi-stage filtering, deduplication, and quality filters. Large-scale synthetic code data.</li>
  <li><a href="https://huggingface.co/datasets/nvidia/Nemotron-Pretraining-Specialized-v1"><strong>Nemotron-Pretraining-Specialized-v1</strong></a>: Collection of synthetic datasets for specialized areas like STEM reasoning and scientific coding.</li>
  <li><a href="https://huggingface.co/collections/nvidia/Nemotron-v3-Post-Training"><strong>Nemotron-SFT-Data</strong></a>: Collection of new Nemotron 3 Nano SFT datasets.</li>
  <li><a href="https://github.com/NVIDIA-NeMo/Gym"><strong>Nemotron-RL-Data</strong></a>: Collection of new Nemotron 3 Nano RL datasets.</li>
</ul>

<h4 id="model-recipes">Model Recipes:</h4>

<ul>
  <li><a href="https://github.com/NVIDIA-NeMo/Nemotron"><strong>NVIDIA Nemotron Developer Repository</strong></a></li>
</ul>

<p>For more details, please refer to the following:</p>

<ul>
  <li>Nemotron 3 Blogs
    <ul>
      <li><a href="https://huggingface.co/blog/nvidia/nemotron-3-nano-efficient-open-intelligent-models">HuggingFace</a></li>
      <li><a href="https://developer.nvidia.com/blog/inside-nvidia-nemotron-3-techniques-tools-and-data-that-make-it-efficient-and-accurate/">NVIDIA Tech Blog</a></li>
    </ul>
  </li>
  <li>Nemotron 3 white paper: <a href="https://research.nvidia.com/labs/nemotron/files/NVIDIA-Nemotron-3-White-Paper.pdf">NVIDIA Nemotron 3: Efficient and Open Intelligence</a></li>
  <li>Nemotron 3 Nano technical report: <a href="https://research.nvidia.com/labs/nemotron/files/NVIDIA-Nemotron-3-Nano-Technical-Report.pdf">Nemotron 3 Nano: Open, Efficient Mixture-of-Experts Hybrid Mamba-Transformer Model for Agentic Reasoning</a></li>
</ul>

        
      </section>

      

      



      


    </div></div>
  </body>
</html>
