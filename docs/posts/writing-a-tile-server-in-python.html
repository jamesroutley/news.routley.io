<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.grulic.org.ar/~mdione/glob/posts/writing-a-tile-server-in-python/">Original</a>
    <h1>Writing a tile server in Python</h1>
    
    <div id="readability-page-1" class="page"><div itemprop="articleBody text">
    <p>Another dictated post<sup id="fnref:0"><a href="#fn:0">1</a></sup><sup id="fnref:13"><a href="#fn:13">11</a></sup>, but heavily edited. Buyer beware.</p>
<p>I developed a tileset based on OpenStreetMap data and style and elevation information, but I don&#39;t have a render server.
What I have been doing is using <a href="https://github.com/StyXman/osm-tile-tools">my own version</a> of an old script from the
<code>mapnik</code> version of the OSM style. This
script is called <code>generate_tiles</code>, and I made big modifications to it and now it&#39;s capable of doing many things,
including spawning several processes for handling the rendering. You can define regions that you want to render, or you
can just provide a bbox or a set of tiles or just coordinates. You can change the size of the meta tile, and it handles
empty tiles. If you find a sea tile, most probably you will not need to render its children<sup id="fnref:10"><a href="#fn:10">9</a></sup>, where children are the
four tiles that are just under it in the next zoom level. For instance, in zoom level zero we have only one tile (0,0,0),
and it&#39;s children are (1,0,0), (1,0,1), (1,1,0) and (1,1,1). 75% of the planet&#39;s surface is water, and with Mercator
projection and the <a href="https://en.wikipedia.org/w/index.php?title=Southern_Ocean">Antartic Ocean</a>, the percent of tiles
could be bigger, so this optimization cuts a lot of useless rendering time.</p>
<p>Another optimization is that it assumes that when you render zoom level N, you will be using
at least the same data for zoom level N+1. Of course, I am
not catching that data because <code>mapnik</code> does not allow this, but the operating system does the catching. So if
you have enough RAM, then you should be able to reuse all the data that&#39;s already in buffers and cache, instead of
having to fetch them again from disk. This in theory should accelerate rendering and probably it is<sup id="fnref:11"><a href="#fn:11">10</a></sup>.</p>
<p>The script works very well, and I&#39;ve been using it for years already for rendering tiles in batches for several zoom
levels. Because my personal computer is way more powerful than
my server (and younger; 2018 vs 2011), I render in my computer and <code>rsync</code> to my server.</p>
<p>So now I wanted to make a tile server based on
this. Why do I want to make my own and not use <code>renderd</code>? I think my main issue with <code>renderd</code> is that it does not store
the individual tiles, but keeps metatiles of 8x8 tiles and serve the individual tiles from there. This saves inode usage
and internal fragmentation. Since my main usage so far has been (and probably will continue to be) rendering regions by
hand, and since my current (static) tile server stores all the latest versions of the tiles I have rendered since I
started doing this some 15 years ago, I want updating the server in a fast way. Most tile storage methods I know
fail terribly at update time (<a href="https://en.osm.town/@mdione/111069567039016636">see here</a>); most of the time it means
sending the whole file over the wire. Also, individual
tiles are easier to convert to anything else, like creating a MBTiles file, push it to my phone, and have a offline
tile service I can carry with me on treks where there is no signal. Also, serving the tiles can be as easy as
<code>python -m http.server</code> from the tileset root directory. So <code>renderd</code> is not useful for me. Another reason is, well, I
already have the rendering engine working. So how does it work?</p>
<p>The rendering engine consists
of one main thread, which I call Master, and rendering threads<sup id="fnref:2"><a href="#fn:2">3</a></sup>. These rendering threads load the style and wait for
work to do. The current style file is 6MiB+ and takes <code>mapnik</code> 4s+ to load it and generate all its structures, which
means these threads have to be created once per service lifetime. I have one queue that can send commands from the
Master to the renderer pool asking for rendering a metatile, which is faster than rendering the individual tiles. Then
one of the rendering threads picks the request from this queue, calls <code>mapnik</code>, generates the metatile, cuts it into
the subtiles and saves them to disk. The rendering thread posts in another queue, telling the Master about the children
metatiles that must be rendered, which due to emptiness can be between 0 and 4.</p>
<p>To implement the caching optimization I mentioned before, I use a third structure to maintain a stack. At the beginning
I push into it the initial work; later I pop one element from it, and when a rendered returns the list of children to be
rendered, I push them on top of the rest. This is what tries to guarantee that a metatile&#39;s children will be rendered
before moving to another region that would trash the cache. And because the children can inspect the tiles being written,
they can figure out when a child is all sea tiles and not returning it for rendering.</p>
<p>At the beginning I thought that, because the multiprocessing queues are implemented with pipes, I could use <code>select()</code><sup id="fnref:3"><a href="#fn:3">4</a></sup> to
see whether the queue was ready for writing or reading and use a typical non-blocking loop. When you&#39;re trying
to write, these queues will block when the queue is full, and when you&#39;re trying to read, they will block when the queue
is empty. But these two conditions, full and empty, are actually handled by semaphores, not by the size of the pipe.
That means that selecting on those pipes, even if I could reach all the way down into the structures of the
<code>multiprocessing.Queue</code> all the way down. and add them to a selector, yes, the read queue will not be selected if it&#39;s
empty (nothing to read), but the write queue will not, since availability of space in the pipe does not mean the queue
is not full.</p>
<p>So instead I&#39;m peeking into these queues. For the work queue, I know that the Master thread<sup id="fnref:9"><a href="#fn:9">8</a></sup> is the only writer, so I can peek to
see if it is full. If it is, I am not going to send any new work to be done, because it means that all the renders are
busy, and the only work queued to be done has not been picked up yet. For the reading side it&#39;s the same, Master is the
only reader. so, I can peek if it&#39;s empty, and if it is, I am not going to try to read any information from it. So, I
have a loop, peeking first into the work queue and then into the info queue. If nothing has been done, I sleep a
fraction of a second.</p>
<p>Now let&#39;s try to think about how to replace this main loop with a web frontend. What is the web frontend going to do?
It&#39;s going to be getting queries by different clients. It could be just a slippy map in a web page, so we have a browser
as a client, or it could be any of the applications that can also render slippy maps. For instance, on Linux, we have
<code>marble</code>; on Android, I use MyTrails, and OsmAnd.</p>
<p>One of the things about these clients is that they have timeouts. Why
am I mentioning this? Because rendering a metatile for me can take between 3 to 120 seconds, depending on the zoom level.
There are zoom levels that are really, really expensive, like between 7 and 10. If a client is going to be asking
directly a rendering service for a tile, and the tile takes too long to render, the
client will timeout and close the connection. How do we handle this on the server side? Well, instead of the work stack,
the server will have request queue, which will be collecting the requests from the clients, and the Master will be
sending these  requests to the render pool.</p>
<p>So if the client closes the connection, I want to be able to react to that, removing any lingering requests made by that
client from the request queue. If I don&#39;t do that, the request queue will start piling up more and more requests,
creating a denial of service. This is not possible in multiprocessing queues, you cannot remove an element. The only
container that can do that is a dequeue<sup id="fnref:5"><a href="#fn:5">5</a></sup>, which also is optimized for putting and popping things from both ends (it&#39;s
probably implemented using a circular buffer), which is perfect for a queue. As for the info queue, I will not be caring
anymore about children metatiles, because I will not be doing any work that the clients are not requesting.</p>
<p>What framework that would allow me to do this? Let&#39;s recap the requirements:</p>
<ul>
<li>Results are computed, and take several seconds.</li>
<li>The library that generates the results is not async, nor thread safe, so I need to use subprocesses to achieve
  parallelization.</li>
<li>A current batch implementation uses 2 queues to send and retrieve computations to a pool of subprocesses; my idea is
  to &#34;just&#34; add a web frontend to this.</li>
<li>Each subprocess spends some seconds warming up, son I can&#39;t spawn a new process for each request.</li>
<li>Since I will have a queue of requested computations, if a client dies, if its query is being processed, then I let
  it finish; if not, I should remove it from the waiting queue.</li>
</ul>
<p>I started with FastAPI, but it doesn&#39;t have the support that I need. At first I just implemented a tile server; the idea
was to grow from there<sup id="fnref:6"><a href="#fn:6">6</a></sup>, but reading the docs it only allows doing long running async stuff <em>after</em> the response has
been sent.</p>
<p>Next was Flask. Flask is not async unless you want to use <code>sendfile()</code>. <code>sendfile()</code> is a way to make the
kernel read a file and write it directly on a socket without intervention from the process requesting that. The
alternative is to to open the file, read a block, write it on the socket, repeat. This definitely makes your code more
complex, you have to handle lots of cases. So <code>sendfile()</code> is very, very handy, but it&#39;s also faster because it&#39;s
0-copy. But Flask does not give control of what happens when the client suddenly closes the connection. I can
instruct it to cancel the tasks in flight, but as per all the previous explanation, that&#39;s not what I want.</p>
<p>This same problem seems to affect all async frameworks I looked into. <code>asyncio</code>, <code>aiohttp</code>, <code>tornado</code>. Except, of course,
<code>twisted</code>, but its API for that is with callbacks, and TBH, I was starting to get tired of all this, and the prospect
of callback hell, even when all the rest of the system could be developed in a more async way, was too much. And this is
not counting the fact that I need to hook into the main loop to step the Master. This could be implemented with timed
callbacks, such as <code>twisted</code>&#39;s <code>callLater()</code>, but another thought started to form in my head.</p>
<p>Why did I go directly for frameworks? Because they&#39;re supposed to make our lives easier, but from the beginning I had
the impression that this would not be a run of the mill service. The main issue came down to beign able to send things
to render, return the rendered data to the right clients, associate several clients to a single job before it finished
(more than one client might request the same tile or several tiles that belong to the same metatile), and handle client
and job cancellation when clients disappear. The more frameworks&#39; documentation I read, the more I started to fear that
the only solution was to implement an non-blocking<sup id="fnref:14"><a href="#fn:14">12</a></sup> loop myself.</p>
<p>I gotta be honest, I dusted
<a href="https://en.wikipedia.org/wiki/UNIX_Network_Programming?useskin=vector">an old Unix Network Programming book</a>, 2nd Ed.,
1998 (!!!), read half a chapter, and I was ready to do it. And thanks to the simple <code>selector</code> API, it&#39;s a breeze:</p>
<ol>
<li>Create a listening socket.</li>
<li>Register it for read events (connections).</li>
<li>On connection, accept the client and wait for read events in that one too.</li>
<li>We were not registering for write before because the client is always ready for write before we start sending
     anything, which lead to tight loops.</li>
<li>On client read, read the request and send the job to Master. Unregister for read.</li>
<li>But if there&#39;s nothing to read, the client disconnected. Send an empty.response, unregister for read and register
     for write.</li>
<li>Step Master.</li>
<li>If anything came back, generate the responses and queue them for sending. Register the right clients for write.</li>
<li>On client write (almost always), send the response and the file with <code>sendfile()</code> if any.</li>
<li>Then close the connection and unregister.</li>
<li>Loop to #3.</li>
</ol>
<p>Initially all this, including reimplementing fake Master and render threads, took less than 200 lines of code, some 11h
of on-and-off work. Now that I have finished I have a better idea of how to implement this at least with <code>twisted</code>,
which I think I will have to do, since step 4 assumes the whole query can be <code>recv()</code>&#39;ed in one go and step 7 similarly
for <code>send()</code>&#39;ing; luckily I don&#39;t need to do any handholding for <code>sendfile()</code>, even when the socket is non blocking.
A more production ready service needs to handle short reads and writes. Also, the HTTP/1.1 protocol all clients are
using allows me to assume that once a query is received, the client will be waiting for an answer before trying anything
else, and that I can close the connection once a response has been send and assume the client will open a new connection
for more tiles. And even then, supporting keep alive should not be that hard (instead of closing the client, unregister
for write, register for read, and only do the close dance when the response is empty). And because I can simply step
Master in the main loop, I don&#39;t have to worry about blocking queues.</p>
<p>Of course, now it&#39;s more complex, because it&#39;s implementing support for multiple clients with different
queries requiring rendering the same metatile. This is due that applications will open several clients for fetching
tiles when showing a region, and unless it&#39;s only 4 and they fall in the corner of 4 adjacent metatiles, they will always mean
more than one client per metatile. Also, I could have several clients looking at the same region.
<a href="https://github.com/StyXman/osm-tile-tools/blob/master/rendering_tile_server-sockets.py">The current code</a> is
approaching the 500 lines, but all that should also be present in any other implementation.</p>
<p>I&#39;m pretty happy about how fast I could make it work and how easy it was. Soon I&#39;ll be finishing integrating a real
render thread with saving the tiles and implement the fact that if one metatile&#39;s tile is not present, we can assume
it&#39;s OK, but if all are not present, I have to find out if they were all empty or never rendered. A last step would be
how to make all this testable. And of course, the <code>twisted</code> port.
                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       </p>

    </div></div>
  </body>
</html>
