<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://lemire.me/blog/2024/01/13/estimating-your-memory-bandwidth/">Original</a>
    <h1>Estimating your memory bandwidth</h1>
    
    <div id="readability-page-1" class="page"><div>
<p>One of the limitations of a compute is the memory bandwidth. For the scope of this article, I define “memory bandwidth” as the maximal number of bytes you can bring from memory to the CPU per unit of time. E.g., if your system has 5 GB/s of bandwidth, you can read up to 5 GB from memory in one second.</p>
<p>To measure this memory bandwidth, I propose to read data sequentially. E.g., you may use a function where we sum the byte values in a large array. It is not necessary to sum every byte value, you can skip some because the processor operates in units of cache lines. I do not know of a system that uses cache lines smaller than 64 bytes, so reading one value every 64 bytes ought to be enough.</p>
<pre>uint64_t sum<span>(</span><span>const</span> uint8_t <span>*</span>data<span>,</span>
<span>    size_t</span> start<span>,</span> <span>size_t</span> len<span>,</span> <span>size_t</span> skip<span>)</span> <span>{</span>
  uint64_t sum <span>=</span> <span>0</span><span>;</span>
<span>  for</span> <span>(</span><span>size_t</span> i <span>=</span> start<span>;</span> i <span>&lt;</span> len<span>;</span> i<span>+</span><span>=</span> skip<span>)</span> <span>{</span>
    sum <span>+</span><span>=</span> data<span>[</span>i<span>]</span><span>;</span>
<span>  }</span>
<span>  return</span> sum<span>;</span>
<span>}</span>

</pre>
<p>It may not be good enough to maximize the bandwidth usage: your system has surely several cores. Thus we should use multiple threads. The following C++ code divides the input into consecutive segments, and assigns one thread to each segment, dividing up the task as fairly as possible:</p>
<pre><span>size_t</span> segment_length <span>=</span> data_volume <span>/</span> threads_count<span>;</span>
<span>size_t</span> cache_line <span>=</span> <span>64</span><span>;</span>
<span>for</span> <span>(</span><span>size_t</span> i <span>=</span> <span>0</span><span>;</span> i <span>&lt;</span> threads_count<span>;</span> i<span>+</span><span>+</span><span>)</span> <span>{</span>
  threads<span>.</span>emplace_back<span>(</span>sum<span>,</span> data<span>,</span> segment_length<span>*</span>i<span>,</span>
       segment_length<span>*</span><span>(</span>i<span>+</span><span>1</span><span>)</span><span>,</span> cache_line<span>)</span><span>;</span>
<span>}</span>
<span>for</span> <span>(</span>std<span>::</span>thread <span>&amp;</span>t <span>:</span> threads<span>)</span> <span>{</span>
  t<span>.</span>join<span>(</span><span>)</span><span>;</span>
<span>}</span>

</pre>
<p>I ran this code on a server with two Intel Ice Lake  processors. I get that the more threads I use, the more bandwidth I am able to get up to around 15 threads. I start out at 15 GB/s and I go up to over 130 GB/s. Once I reach about 20 threads, it is no longer possible to get more bandwidth out of the system. The system has a total of 64 cores, over two CPUs. My program does not do any fiddling with locking threads to cores, it is not optimized for NUMA. I have transparent huge pages enabled by default on this Linux system.</p>
<p><a href="https://lemire.me/blog/wp-content/uploads/2024/01/bandwidthicelake-1.png"><img decoding="async" src="https://lemire.me/blog/wp-content/uploads/2024/01/bandwidthicelake-1.png" alt="" width="70%" srcset="https://lemire.me/blog/wp-content/uploads/2024/01/bandwidthicelake-1.png 800w, https://lemire.me/blog/wp-content/uploads/2024/01/bandwidthicelake-1-300x225.png 300w, https://lemire.me/blog/wp-content/uploads/2024/01/bandwidthicelake-1-768x576.png 768w" sizes="(max-width: 800px) 100vw, 800px"/></a></p>
<p>My benchmark ought to be make it easy for the processor to maximize bandwidth usage, so I would not expect more complicated software to hit a bandwidth limit with as few as 20 threads.</p>
<p><a href="https://github.com/lemire/Code-used-on-Daniel-Lemire-s-blog/tree/master/2024/01/13">My source code is available</a>.</p>
<p>This machine has two NUMA nodes, splitting up the tasks by thread affinity would probably improve the bandwidth.</p>
<p><strong>Further reading</strong>: <a href="https://github.com/MattPD/cpplinks/blob/master/performance.tools.md#memory---benchmarking">Many tools to measure bandwidth</a>.</p>
</div></div>
  </body>
</html>
