<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://samwho.dev/memory-allocation/">Original</a>
    <h1>A highly intuitive visual guide on how memory allocation works, step by step</h1>
    
    <div id="readability-page-1" class="page"><div>
        



<p>One thing that all programs on your computer have in common is a need for
memory. Programs need to be loaded from your hard drive into memory before they
can be run.  While running, the majority of what programs do is load values from
memory, do some computation on them, and then store the result back in memory.</p>
<p>In this post I&#39;m going to introduce you to the basics of memory allocation.
Allocators exist because it&#39;s not enough to have memory available, you need to
use it effectively. We will visually explore how simple allocators work. We&#39;ll
see some of the problems that they try to solve, and some of the techniques used
to solve them. At the end of this post, you should know everything you need to
know to write your own allocator.</p>
<h2 id="malloc-and-free"><a href="#malloc-and-free">›</a>
<code>malloc</code> and <code>free</code></h2>
<p>To understand the job of a memory allocator, it&#39;s essential to understand how
programs request and return memory.  <code>malloc</code> and <code>free</code> are functions that were
first introduced in a recognisable form in UNIX v7 in 1979(!). Let&#39;s take a look
at a short C program demonstrating their use.</p>
<blockquote>
<img src="https://samwho.dev/images/haskie-concerned.png"/>
<p>
  Woah, hold on. I&#39;ve never written any C code before. Will I still be able
  to follow along?
</p>
</blockquote>
<p>If you have beginner-level familiarity with another language, e.g. JavaScript,
Python, or C#, you should have no problem following along. You don&#39;t need to
understand every word, as long as you get the overall idea. This is the only
C code in the article, I promise.</p>
<pre data-lang="c"><code data-lang="c"><span>#include </span><span>&lt;stdlib.h&gt;
</span><span>
</span><span>int </span><span>main</span><span>() {
</span><span>  </span><span>void *</span><span>ptr </span><span>= </span><span>malloc</span><span>(</span><span>4</span><span>)</span><span>;
</span><span>  </span><span>free</span><span>(ptr)</span><span>;
</span><span>  </span><span>return </span><span>0</span><span>;
</span><span>}
</span></code></pre>
<p>In the above program we ask for 4 bytes of memory by calling <code>malloc(4)</code>, we
store the value returned in a variable called <code>ptr</code>, then we indicate that we&#39;re
done with the memory by calling <code>free(ptr)</code>.</p>
<p>These two functions are how almost all programs manage the memory they use.
Even when you&#39;re not writing C, the code that is executing your Java, Python,
Ruby, JavaScript, and so on make use of <code>malloc</code> and <code>free</code>.</p>
<h2 id="what-is-memory"><a href="#what-is-memory">›</a>
What is memory?</h2>
<p>The smallest unit of memory that allocators work with is called a &#34;byte.&#34; A byte
can store any number between 0 and 255. You can think of memory as being a long
sequence of bytes. We&#39;re going to represent this sequence as a grid of squares,
with each square representing a byte of memory.</p>

<p>In the C code from before, <code>malloc(4)</code> allocates 4 bytes of memory. We&#39;re going
to represent memory that has been allocated as darker squares.</p>

<p>Then <code>free(ptr)</code> tells the allocator we&#39;re done with that memory. It is returned
back to the pool of available memory.</p>
<p>Here&#39;s what 4 <code>malloc</code> calls followed by 4 <code>free</code> calls looks like.  You&#39;ll
notice there&#39;s now a slider.  Dragging the slider to the right advances time
forward, and dragging it left rewinds. You can also click anywhere on the grid
and then use the arrow keys on your keyboard, or you can use the left and right
buttons. The ticks along the slider represent calls to <code>malloc</code> and <code>free</code>.</p>

<blockquote>
<img src="https://samwho.dev/images/haskie-confused.png"/>
<p>
  Wait a sec... What is <code>malloc</code> actually returning as a value?
  What does it mean to &#34;give&#34; memory to a program?
</p>
</blockquote>
<p>What <code>malloc</code> returns is called a &#34;pointer&#34; or a &#34;memory address.&#34; It&#39;s a number
that identifies a byte in memory.  We typically write addresses in a form called
&#34;hexadecimal.&#34; Hexadecimal numbers are written with a <code>0x</code> prefix to distinguish
them from decimal numbers.  Move the slider below to see a comparison between
decimal numbers and hexadecimal numbers.</p>

<p>Here&#39;s our familiar grid of memory. Each byte is annotated with its address in
hexadecimal form. For space reasons, I&#39;ve omitted the <code>0x</code> prefix.</p>

<p>The examples we use in this article pretend that your computer only has a very
small amount of memory, but in real life you have billions of bytes to work
with. Real addresses are much larger than what we&#39;re using here, but the idea is
exactly the same. Memory addresses are numbers that refer to a specific byte in
memory.</p>
<h2 id="the-simplest-malloc"><a href="#the-simplest-malloc">›</a>
The simplest <code>malloc</code></h2>
<p>The &#34;hello world&#34; of <code>malloc</code> implementations would hand out blocks of memory by
keeping track of where the previous block ended and starting the next block
right after.  Below we represent where the next block should start with a grey
square.</p>

<p>You&#39;ll notice no memory is <code>free</code>d. If we&#39;re only keeping track of where the
next block should start, and we don&#39;t know where previous blocks start or end,
<code>free</code> doesn&#39;t have enough information to do anything. So it doesn&#39;t. This is
called a &#34;memory leak&#34; because, once allocated, the memory can never be used
again.</p>
<p>Believe it or not, this isn&#39;t a completely useless implementation.  For programs
that use a known amount of memory, this can be a very efficient strategy.  It&#39;s
extremely fast and extremely simple. As a general-purpose memory allocator,
though, we can&#39;t get away with having no <code>free</code> implementation.</p>
<h2 id="the-simplest-general-purpose-malloc"><a href="#the-simplest-general-purpose-malloc">›</a>
The simplest general-purpose <code>malloc</code></h2>
<p>In order to <code>free</code> memory, we need to keep better track of memory.  We can do
this by saving the address and size of all allocations, and the address and size
of blocks of free memory. We&#39;ll call these an &#34;allocation list&#34; and a &#34;free
list&#34; respectively.</p>

<p>We&#39;re representing free list entries as 2 grey squares linked together with a
line. You can imagine this entry being represented in code as <code>address=0</code> and
<code>size=32</code>.  When our program starts, all of memory is marked as free. When
<code>malloc</code> is called, we loop through our free list until we find a block large
enough to accommodate it. When we find one, we save the address and size of the
allocation in our allocation list, and shrink the free list entry accordingly.</p>

<blockquote>
<img src="https://samwho.dev/images/haskie-confused.png"/>
<p>
  Where do we save allocations and free list entries? Aren&#39;t we pretending our
  computer only has 32 bytes of memory?
</p>
</blockquote>
<p>You caught me. One of the benefits of being a memory allocator is that you&#39;re in
charge of memory. You could store your allocation/free list in a reserved area
that&#39;s just for you. Or you could store it inline, in a few bytes immediately
preceding each allocation.  For now, assume we have reserved some unseen memory
for ourselves and we&#39;re using it to store our allocation and free lists.</p>
<p>So what about <code>free</code>? Because we&#39;ve saved the address and size of the allocation
in our allocation list, we can search that list and move the allocation back in
to the free list. Without the size information, we wouldn&#39;t be able to do this.</p>

<p>Our free list now has 2 entries. This might look harmless, but actually
represents a significant problem. Let&#39;s see that problem in action.</p>

<p>We allocated 8 blocks of memory, each 4 bytes in size. Then we <code>free</code>d them all,
resulting in 8 free list entries.  The problem we have now is that if we tried
to do a <code>malloc(8)</code>, there are no items in our free list that can hold 8 bytes
and the <code>malloc(8)</code> will fail.</p>
<p>To solve this, we need to do a bit more work. When we <code>free</code> memory, we should
make sure that if the block we return to the free list is next to any other
free blocks, we combine them together. This is called &#34;coalescing.&#34;</p>

<p>Much better.</p>
<h2 id="fragmentation"><a href="#fragmentation">›</a>
Fragmentation</h2>
<p>A perfectly coalesced free list doesn&#39;t solve all of our problems. The following
example shows a longer sequence of allocations. Have a look at the state memory
is in at the end.</p>

<p>We end this sequence with 6 of our 32 bytes free, but they&#39;re split into 2
blocks of 3 bytes. If we had to service a <code>malloc(6)</code>, while we have enough free
memory in theory, we wouldn&#39;t be able to.  This is called &#34;fragmentation.&#34;</p>
<blockquote>
<img src="https://samwho.dev/images/haskie-confused.png"/>
<p>
  Couldn&#39;t we rearrange the memory to get a block of 6 contiguous bytes? Some
  sort of defragmentation process?
</p>
</blockquote>
<p>Sadly not. Remember earlier we talked about how the return value of <code>malloc</code> is
the address of a byte in memory? Moving allocations won&#39;t change the pointers we
have already returned from <code>malloc</code>. We would change the value those pointers
are pointed at, effectively breaking them. This is one of the downsides of the
<code>malloc</code>/<code>free</code> API.</p>
<p>If we can&#39;t move allocations after creating them, we need to be more careful
about where we put them to begin with.</p>
<p>One way to combat fragmentation is, confusingly, to overallocate.  If we always
allocate a minimum of 4 bytes, even when the request is for 1 byte, watch what
happens. This is the exact same sequence of allocations as above.</p>

<p>Now we can service a <code>malloc(6)</code>. It&#39;s worth keeping in mind that this is just
one example. Programs will call <code>malloc</code> and <code>free</code> in very different patterns
depending on what they do, which makes it challenging to design an allocator
that always performs well.</p>
<blockquote>
<img src="https://samwho.dev/images/haskie-confused.png"/>
<p>
  After the first <code>malloc</code>, the start of the free list seems to fall
  out of sync with allocated memory. Is that a bug in the visualisation?
</p>
</blockquote>
<p>No, that&#39;s a side-effect of overallocating.  The visualisation shows &#34;true&#34;
memory use, whereas the free list is updated from the allocator&#39;s perspective.
So when the first <code>malloc</code> happens, 1 byte of memory is allocated but the free
list entry is moved forward 4 bytes. We trade some wasted space in return for
less fragmentation.</p>
<p>It&#39;s worth noting that this unused space that results from overallocation is
another form of fragmentation. It&#39;s memory that cannot be used until the
allocation that created it is freed. As a result, we wouldn&#39;t want to go too
wild with overallocation. If our program only ever allocated 1 byte at a time,
for example, we&#39;d be wasting 75% of all memory.</p>
<p>Another way to combat fragmentation is to segment memory into a space for small
allocations and a space for big ones. In this next visualisation we start with
two free lists. The lighter grey one is for allocations 3 bytes or smaller,
and the darker grey one is for allocations 4 bytes or larger. Again, this is
the exact same sequence of allocations as before.</p>

<p>Nice! This also reduces fragmentation. If we&#39;re strictly only allowing
allocations of 3 bytes or less in the first segment, though, then we can&#39;t
service that <code>malloc(6)</code>. The trade-off here is that reserving a segment of
memory for smaller allocations gives you less memory to work with for bigger
ones.</p>
<blockquote>
<img src="https://samwho.dev/images/haskie-triumphant.png"/>
<p>
  Hey, <a simulation="segmented-1" position="4">the first allocation in the dark
  grey free list</a> is 3 bytes! You said this was for allocations 4 bytes and
  up. What gives?
</p>
</blockquote>
<p>Got me again. This implementation I&#39;ve written will put small allocations in the
dark grey space when the light grey space is full. It will overallocate when it
does this, otherwise we&#39;d end up with avoidable fragmentation in the dark grey
space thanks to small allocations.</p>
<p>Allocators that split memory up based on the size of allocation are called
&#34;slab allocators.&#34; In practice they have many more size classes than the 2 in
our example.</p>
<h2 id="a-quick-malloc-puzzle"><a href="#a-quick-malloc-puzzle">›</a>
A quick <code>malloc</code> puzzle</h2>
<p>What happens if you <code>malloc(0)</code>? Have a think about this before playing with
the slider below.</p>

<p>This is using our free list implementation that mandates a minimum size of 4
bytes for allocations. All memory gets allocated, but none is actually used.
Do you think this is correct behaviour?</p>
<p>It turns out that what happens when you <code>malloc(0)</code> differs between
implementations. Some of them behave as above, allocating space they probably
didn&#39;t have to. Others will return what&#39;s called a &#34;null pointer&#34;, a special
pointer that will crash your program if you try to read or write the memory it
points to.  Others pick one specific location in memory and return that same
location for all calls to <code>malloc(0)</code>, regardless how many times it is called.</p>
<p>Moral of the story? Don&#39;t <code>malloc(0)</code>.</p>
<h2 id="inline-bookkeeping"><a href="#inline-bookkeeping">›</a>
Inline bookkeeping</h2>
<p>Remember earlier on when you asked about where allocation list and free list
information gets stored, and I gave an unsatisfying answer about how it&#39;s
stored in some other area of memory we&#39;ve reserved for ourselves?</p>
<blockquote>
<img src="https://samwho.dev/images/haskie-concerned.png"/>
<p>
  Yes...
</p>
</blockquote>
<p>This isn&#39;t the only way to do it. Lots of allocators store information right
next to the blocks of memory they relate to. Have a look at this.</p>

<p>What we have here is memory with no allocations, but free list information
stored inline in that memory. Each block of memory, free or used, gets 3
additional bytes of bookkeeping information. If <code>address</code> is the address of the
first byte of the allocation, here&#39;s the layout of a block:</p>
<ol>
<li><code>address + 0</code> is the <span>size</span> of the block</li>
<li><code>address + 1</code> is whether the block is <span>free (1)</span> or <span>used (2)</span></li>
<li><code>address + 2</code> is where the <span>usable memory</span> starts</li>
<li><code>address + 2 + size</code> -- the <span>size</span> of the block again</li>
</ol>
<p>So in this above example, the byte at <code>0x0</code> is storing the value 29. This means
it&#39;s a block containing 29 bytes of memory. The value 1 at <code>0x1</code> indicates that
the block is free memory.</p>
<blockquote>
<img src="https://samwho.dev/images/haskie-concerned.png"/>
<p>
  We store the <span>size</span> twice? Isn&#39;t that wasteful?
</p>
</blockquote>
<p>It seems wasteful at first, but it is necessary if we want to do any form of
coalescing. Let&#39;s take a look at an example.</p>

<p>Here we&#39;ve allocated 4 bytes of memory. To do this, our <code>malloc</code> implementation
starts at the beginning of memory and checks to see if the block there is used.
It knows that at <code>address + 1</code> it will find either a 1 or a 2. If it finds a
1, it can check the value at <code>address</code> for how big the block is. If it is big
enough, it can allocate into it. If it&#39;s not big enough, it knows it can add
the value it finds in <code>address</code> to <code>address</code> to get to the start of the next
block of memory.</p>
<p>This has resulted in the creation of a used block (notice the 2 stored in the
2nd byte), and it has pushed start of the free block forward by 7 bytes. Let&#39;s
do the same again and allocate another 4 bytes.</p>

<p>Next, let&#39;s <code>free</code> our first <code>malloc(4)</code>. The implementation of <code>free</code> is where
storing information inline starts to shine. In our previous allocators, we had
to search the allocation list to know the size of the block being <code>free</code>d.  Now
we know we&#39;ll find it at <code>address</code>. What&#39;s better than that is that for this
<code>free</code>, we don&#39;t even need to know how big the allocation is. We can just set
<code>address + 1</code> to 1!</p>

<p>How great is that? Simple, fast.</p>
<p>What if we wanted to free the 2nd block of used memory? We know that we want to
coalesce to avoid fragmentation, but how do we do that? This is where the
seemingly wasteful bookkeeping comes into play.</p>
<p>When we coalesce, we check to see the state of the blocks immediately before and
immediately after the block we&#39;re <code>free</code>ing. We know that we can get to the next
block by adding the value at <code>address</code> to <code>address</code>, but how do we get to the
previous block? We take the value at <code>address - 1</code> and <em>subtract</em> that from
<code>address</code>. Without this duplicated size information at the end of the block, it
would be impossible to find the previous block and impossible to coalesce
properly.</p>

<p>Allocators that store bookkeeping information like this alongside allocations
are called &#34;boundary tag allocators.&#34;</p>
<blockquote>
<img src="https://samwho.dev/images/haskie-concerned.png"/>
<p>
  What&#39;s stopping a program from modifying the bookkeeping information? Wouldn&#39;t
  that completely break memory?
</p>
</blockquote>
<p>Surprisingly, nothing truly prevents this. We rely heavily, as an industry, on
the correctness of code. You might have heard of &#34;buffer overrun&#34; or &#34;use after
free&#34; bugs before. These are when a program modifies memory past the end of an
allocated block, or accidentally uses a block of memory after <code>free</code>ing it.
These are indeed catastrophic. They can result in your program immediately
crashing, they can result in your program crashing in several minutes, hours, or
days time. They can even result in hackers using the bug to gain access to
systems they shouldn&#39;t have access to.</p>
<p>We&#39;re seeing a rise in popularity of &#34;memory safe&#34; languages, for example Rust.
These languages invest a lot in making sure it&#39;s not possible to make these
types of mistake in the first place. Exactly how they do that is outside of
the scope of this article, but if this interests you I highly recommend giving
Rust a try.</p>
<p>You might have also realised that calling <code>free</code> on a pointer that&#39;s in the
middle of a block of memory could also have disastrous consequences. Depending
on what values are in memory, the allocator could be tricked into thinking it&#39;s
<code>free</code>ing something but what it&#39;s really doing is modifying memory it shouldn&#39;t
be.</p>
<p>To get around this, some allocators inject &#34;magic&#34; values as part of the
bookkeeping information. They store, say, <code>0x55</code> at <code>address + 2</code>.  This would
waste an extra byte of memory per allocation, but would allow them to know when
a mistake has been made. To reduce the impact of this, allocators often disable
this behaviour by default and allow you to enable it only when you&#39;re debugging.</p>
<h2 id="playground"><a href="#playground">›</a>
Playground</h2>
<p>If you&#39;re keen to take your new found knowledge and try your hand at writing
your own allocators, you can click <a href="https://samwho.dev/allocator-playground">here</a> to go to my
allocator playground. You&#39;ll be able to write JavaScript code that implements
the <code>malloc</code>/<code>free</code> API and visualise how it works!</p>
<h2 id="conclusion"><a href="#conclusion">›</a>
Conclusion</h2>
<p>We&#39;ve covered a lot in this post, and if it has left you yearning for more you
won&#39;t be disappointed. I&#39;ve specifically avoided the topics of virtual memory,
<code>brk</code> vs <code>mmap</code>, the role of CPU caches, and the endless tricks real <code>malloc</code>
implementations pull out of their sleeves. There&#39;s no shortage of information
about memory allocators on the Internet, and if you&#39;ve read this far you should
be well-placed to dive in to it.</p>
<p>Join the discussion on <a href="https://news.ycombinator.com/item?id=36029087">Hacker News</a>!</p>
<h3 id="acknowledgments"><a href="#acknowledgments">›</a>
Acknowledgments</h3>
<p>Special thanks to the following people:</p>
<ul>
<li><a href="https://chrisdown.name">Chris Down</a> for lending me his extensive knowledge of real-world
memory allocators.</li>
<li><a href="https://zemlan.in/">Anton Verinov</a> for lending me his extensive knowledge of the web,
browser developer tools, and user experience.</li>
<li>Blake Becker, Matt Kaspar, Krista Horn, Jason Peddle, and
<a href="https://joshwcomeau.com">Josh W. Comeau</a> for their insight and constructive
reviews.</li>
</ul>
<!--
## Real-world performance

By making use of boundary tags, we saw that `free` can be made really fast.
No list traversals required, just inspection and manipulation of a few bytes
of bookkeeping information. But `malloc` still has to traverse the list of
all blocks, free or used, to find one that can fit the current request.

How do we make `malloc` fast?

What we're asking here isn't for the fastest possible `malloc` implementation.
We've already seen that, at the very start of the article. The `malloc` that
can't `free`. That's not what we want. We want a `malloc` that gets close to
that speed, without creating a fragmented heap. We want high throughput, low
fragmentation.

There's no one-size-fits-all solution here, so I will list a few ways real-world
allocators try to achieve this.

### Segmenting/binning memory

We touched on this earlier, but a common approach to balancing throughput and
fragmentation is by splitting memory up in to segments reserved for allocations
of a specific size. In our example we had 2 segments: 1 for small allocations
and 1 for big allocations.

A `malloc` implementation called `dlmalloc` ("Doug Lea's `malloc`") splits
memory up in to 64(!) different size classes that it calls "bins." Each size
class has a linked list of free blocks of memory associated with it. These lists
begin empty, and as memory is `free`d it gets added to the appropriate list.

When there are no readily available free blocks in these bins, memory is
allocated from what `dlmalloc` refers to as "the wilderness." This is just the
free memory available to the program at the very beginning. `dlmalloc` takes
from here when it needs to, but prefers to look in the size class bins first. It
only takes from the wilderness when it can't take from anywhere else.

If memory isn't available in the appropriate bin, but is available in the next
bin up, `dlmalloc` will take a larger block, split it in 2, allocate one, and
put the other in the appropriate bin for later use. Likewise, when `free`ing,
`dlmalloc` will coalesce blocks with their neighbours and return the resulting
block to the largest bin it can. These techniques help reduce fragmentation.

### Caching

Another cool trick `dlmalloc` uses is called the "designated victim." When
`dlmalloc` takes a block from a bin larger than the current allocation, it
caches the remainder block to be used as the preferred location for the next
allocation that does not perfectly match to a bin size.

`dlmalloc` also caches whether or not bins have blocks in them using a bitmap it
calls the "binmap." This is a 32 bit value where each bit represents the state
of a given bin. If it's a 1, the bin has blocks ready to use in it. If it's 0,
it doesn't. This makes finding an appropriate bin really, really fast.

`phkmalloc`, the spiritual predecessor to `dlmalloc`, maintains a counter of how
many blocks are free in a given "arena" or memory. `phkmalloc` works on a tiered
system, putting smaller blocks inside of larger blocks, in order to be able to
return the larger blocks back to the operating system when they have been
completely freed. It calls these larger blocks "arenas."

### Locality

I've not touched on this topic at all, but it is very important especially in
more modern `malloc` implementations. Without going in to too much detail,
memory access involves a hierarchy of caches. Retrieving a value from memory is
slow, so between your CPU and your memory sit layers of caches.  Each layer
closer to the CPU is faster but smaller. These caches can range in size from
100MB at the largest layer to a few dozen kilobytes at the smallest. It's common
for CPUs to have 3 layers.

When you fetch a value from memory, your CPU will actually fetch more than
needed. It does this because it is likely that memory close together is needed
at the same time. This is called "spatial locality." Hard drives do the same
thing.

`malloc` is uniquely positioned to take advantage of this fact. If your `malloc`
implementation intentionally places blocks close to blocks that were `malloc`ed
around the same time, it will increase the chance that a single fetch from
memory will hit multiple blocks of soon-needed memory.

Locality is also an argument in favour of storing your bookkeeping information
separate to allocated memory. The more tightly packed a program's in-use memory
is, the more likely it is to get cached together. Also, if you need to traverse
lists to find free blocks, and your list traversal works using boundary tags,
you will be accessing memory that is unlikely to be used.  These accesses get
cached, evicting potentially useful memory in the process.

This is why `dlmalloc` maintains its "binmap" separate from the bins themselves.
You can check the status of all bins with minimal cache disturbance.

### Multithreading

The last topic we're going to talk about is multithreading. It's very common for
computers in 2023 to have many CPU cores, but this wasn't always the case. For
example, when `phkmalloc` was written there was no consideration for
multithreading in the implementation. `dlmalloc` is not thread-safe by default,
but comes with an option to make it thread-safe at a huge performance cost.

One of the first `malloc` implementations to optimise for multithreaded
use-cases was `jemalloc` ("Jason Evans `malloc`"). Written around 2006,
`jemalloc` makes the observation that is 2 CPU cores try to access the same
area of the CPU cache, they will "fight" over the "ownership" of that area of
the cache.

What does this mean?

CPU cache is split in to "lines." These lines are typically 64 bytes in size,
and represent a 64 byte chunk of memory. Each CPU core has its own dedicated set
of caches, so the same 64 byte chunk of memory could potentially be cached on
multiple cores.

When 2 threads running on 2 different cores try to access the same line of
cache, by trying to access the same area of memory and finding it already
cached, it can become a problem. If they both write to it, that will trigger the
cache to be synchronised across CPU cores, and this can be really slow. Without
this synchronisation, the same 64 byte region of memory could appear to hold
different values depending on what core you see it from.

To avoid this, `jemalloc` splits memory up in to 2MB chunks, and each chunk can
only be accessed by 1 thread. Giving threads unique ownership of parts of memory
guarantees that you will avoid this slow cache synchronisation. It also gives
your `malloc` implementation thread-safety, because you know that all threads
will be operating on memory they have sole ownership of.
-->

    </div></div>
  </body>
</html>
