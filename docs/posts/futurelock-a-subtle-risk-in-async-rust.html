<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://rfd.shared.oxide.computer/rfd/0609">Original</a>
    <h1>Futurelock: A subtle risk in async Rust</h1>
    
    <div id="readability-page-1" class="page"><div id="content"><div id="preamble" data-lineno="13"><div><p>This RFD describes <strong>futurelock</strong>: a type of deadlock where a resource owned by Future <code>A</code> is required for another Future <code>B</code> to proceed, while the Task responsible for both Futures is no longer polling <code>A</code>.  Futurelock is a particularly subtle risk in writing asynchronous Rust.</p><div data-lineno="15"><p>Oxide initially saw this problem in <a href="https://github.com/oxidecomputer/omicron/issues/9259">oxidecomputer/omicron#9259</a>.</p></div></div></div><div><h2 data-sectnum="1."><span id="_example_of_the_problem" aria-hidden="true"></span><a href="#_example_of_the_problem">Example of the problem<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16" role="img"><g fill="currentColor"><path d="m6.586 12.243 1.59-1.591a.75.75 0 0 1 1.061 0l.354.353a.75.75 0 0 1 0 1.06L8 13.658A4 4 0 0 1 2.343 8l1.591-1.591a.75.75 0 0 1 1.06 0l.354.354a.75.75 0 0 1 0 1.06l-1.59 1.591a2 2 0 1 0 2.828 2.829M12.066 9.591a.75.75 0 0 1-1.06 0l-.354-.354a.75.75 0 0 1 0-1.06l1.59-1.591a2 2 0 1 0-2.828-2.829l-1.59 1.591a.75.75 0 0 1-1.061 0l-.354-.353a.75.75 0 0 1 0-1.06L8 2.342A4 4 0 0 1 13.657 8z"></path><path d="M9.945 5.702a.75.75 0 0 0-1.061 0L5.702 8.884a.75.75 0 0 0 0 1.06l.353.354a.75.75 0 0 0 1.061 0l3.182-3.182a.75.75 0 0 0 0-1.06z"></path></g></svg></a></h2><div><div data-lineno="19"><p>Consider the following program (<a href="https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2024&amp;gist=e944c8b02df59c39b417594620ad5f67">in the playground</a>):</p></div><div data-lineno="21"><div><pre><code data-lang="rust"><span>use</span><span> std</span><span>::</span><span>sync</span><span>::</span><span>Arc</span><span>;</span></code></pre></div></div><p>This program reliably deadlocks.  This surprises a lot of people!  A background Task takes a lock, waits 5s, drops the lock and exits. In the meantime, we <code>do_stuff</code>.  That stuff consists of waiting for two Futures concurrently via <code>select!</code>. One future waits for the lock while the other sleeps for 0.5s and waits for the lock. So there’s just one lock and all logical streams of execution seem to execute concurrently.  How could this possibly hang?</p><p>The interesting bits are all in <code>do_stuff()</code>:</p><div data-lineno="91"><div><pre><code data-lang="rust"><span>async</span><span> fn</span><span> do_stuff</span><span>(</span><span>lock</span><span>:</span><span> Arc</span><span>&lt;</span><span>Mutex</span><span>&lt;</span><span>()</span><span>&gt;&gt;</span><span>)</span><span> {</span></code></pre></div></div><div data-lineno="111"><table><tbody><tr><td><i data-value="1"></i><b>1</b></td><td><code>future1</code> is the (boxed) future returned by <code>do_async_thing()</code>, an async function.</td></tr><tr><td><i data-value="2"></i><b>2</b></td><td>We’ll call the future returned by <code>sleep</code>: <code>future2</code> (or, the &#34;sleep&#34; future).</td></tr><tr><td><i data-value="3"></i><b>3</b></td><td>The second branch of the <code>select!</code> is its own future.  We’ll call this <code>future3</code>.</td></tr></tbody></table></div><p>It’s really important to understand what’s happening here so let’s be clear about the sequence.</p><p>First:</p><div data-lineno="117"><ol><li><p>background task takes <code>lock</code>, begins holding it for 5 seconds</p></li><li><p><code>tokio::select!</code> begins polling <code>&amp;mut future1</code>.<sup>[<a id="_footnoteref_1" href="#_footnotedef_1" title="View footnote.">1</a>]</sup>  This future attempts to take the lock, blocks, returns <code>Poll::Pending</code>.</p></li><li><p><code>tokio::select!</code> begins polling <code>future2</code> (the sleep future) and blocks, returning <code>Poll::Pending</code>.</p></li></ol></div><p>At this point:</p><div data-lineno="123"><ul><li><p>the background task holds the lock</p></li><li><p>the main task is blocked in <code>tokio::select!</code> on two different futures:</p><div data-lineno="125"><ul><li><p><code>future1</code> is blocked on taking the lock</p></li><li><p><code>future2</code> (the <code>sleep</code> future) waiting for 500ms</p></li></ul></div></li></ul></div><p>500ms later, <code>tokio</code> wakes up the main task because <code>future2</code> (the sleep future) is ready.  Inside <code>tokio::select!</code>:</p><div data-lineno="130"><ul><li><p>The task polls both futures.</p><div data-lineno="131"><ul><li><p><code>future1</code> is still blocked on the lock and returns <code>Pending</code>.<sup>[<a id="_footnoteref_2" href="#_footnotedef_2" title="View footnote.">2</a>]</sup></p></li><li><p><code>future2</code> (the sleep future) is ready and returns <code>Ready</code>.</p></li></ul></div></li><li><p><code>tokio::select!</code> chooses the second branch</p><div data-lineno="134"><ul><li><p><code>&amp;mut future1</code> is dropped, but this is just a reference and so has no effect.  Importantly, the future itself (<code>future1</code>) is <strong>not</strong> dropped.</p></li><li><p>the second branch is entered.  <code>do_async_thing(&#34;op2&#34;, …​)</code> is called, creating a new future <code>future3</code>.  This future immediately blocks trying to take the lock, which is still held by the background task.</p></li></ul></div></li></ul></div><p>At this point, we have:</p><div data-lineno="139"><ul><li><p>the lock (still) held by the background task</p></li><li><p>the lock’s wait queue contains two waiting futures:</p><div data-lineno="141"><ul><li><p><code>future1</code></p></li><li><p><code>future3</code> (the second arm of the <code>tokio::select!</code>)</p></li></ul></div></li></ul></div><p>There are two key points here:</p><div data-lineno="146"><ol><li><p>The lock’s wait queue is literally a queue: <strong>only</strong> <code>future1</code> can take the lock once it is released by the background task (unless <code>future1</code> is dropped).</p></li><li><p>The behavior of <code>tokio::select!</code> is to poll all branches&#39; futures <em>only until one of them returns `Ready`</em>.  At that point, it drops the other branches&#39; futures and only runs the body of the branch that’s ready.</p></li></ol></div><p>Critically: the same task is responsible for both of the futures waiting on the lock.  But that task is currently only polling on one of them.  Unfortunately, it’s the wrong one.</p><p>About 4.5 seconds later:</p><div data-lineno="153"><ul><li><p>The background task drops the lock.</p><div data-lineno="154"><ul><li><p>The lock is given to <code>future1</code>. (See below for more on why.)</p></li><li><p>The task that polled <code>future1</code> (the main task) is woken up.</p></li></ul></div></li><li><p>However, that task is <em>not</em> polling <code>future1</code>.  <code>future1</code> is polled at the top-level <code>tokio::select!</code>.  But the <code>tokio::select!</code> has already chosen the other branch.  It’s now <em>only</em> polling <code>future3</code>.  (In fact, even absent the imminent hang, <code>future1</code> would never be polled again.  It would be cancelled without having completed when it got dropped at the end of <code>do_stuff</code>.)</p></li></ul></div><p>Thus:</p><div data-lineno="160"><ul><li><p>There is only one task left.  It’s blocked on <code>future3</code>.</p></li><li><p><code>future3</code> is blocked on a Mutex that’s owned by <code>future1</code>.</p></li><li><p><code>future1</code> cannot run (and therefore cannot drop the Mutex) until the task starts running it.</p></li></ul></div><p>We call this specific kind of deadlock <em>futurelock</em>.  The program is stuck in this state forever.</p><div><h3 data-sectnum="1.1."><span id="_faq_why_doesnt_the_mutex_wake_up_the_other_future" aria-hidden="true"></span><a href="#_faq_why_doesnt_the_mutex_wake_up_the_other_future">FAQ: why doesn’t the Mutex wake up the other future?<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16" role="img"><g fill="currentColor"><path d="m6.586 12.243 1.59-1.591a.75.75 0 0 1 1.061 0l.354.353a.75.75 0 0 1 0 1.06L8 13.658A4 4 0 0 1 2.343 8l1.591-1.591a.75.75 0 0 1 1.06 0l.354.354a.75.75 0 0 1 0 1.06l-1.59 1.591a2 2 0 1 0 2.828 2.829M12.066 9.591a.75.75 0 0 1-1.06 0l-.354-.354a.75.75 0 0 1 0-1.06l1.59-1.591a2 2 0 1 0-2.828-2.829l-1.59 1.591a.75.75 0 0 1-1.061 0l-.354-.353a.75.75 0 0 1 0-1.06L8 2.342A4 4 0 0 1 13.657 8z"></path><path d="M9.945 5.702a.75.75 0 0 0-1.061 0L5.702 8.884a.75.75 0 0 0 0 1.06l.353.354a.75.75 0 0 0 1.061 0l3.182-3.182a.75.75 0 0 0 0-1.06z"></path></g></svg></a></h3><div><p>This particular example uses <code>tokio::sync::Mutex</code>, which is a fair Mutex.  That means that the lock is given to waiters in the order that they started waiting.  It <em>has</em> to give it to <code>future1</code>.</p><p>An unfair Mutex would not fix things.  The problem wouldn’t be guaranteed to happen with an unfair Mutex, but it wouldn’t be guaranteed not to, either.  The Mutex does not (and cannot) know which future would be &#34;better&#34; to wake up, or which one is being polled.  You could imagine an unfair Mutex that always woke up all waiters and let them race to grab the lock again.  That would not suffer from risk of futurelock, but it would have the <a href="https://en.wikipedia.org/wiki/Thundering_herd_problem">thundering herd problem</a> plus all the liveness issues associated with unfair synchronization primitives.  And it’s not how many synchronization primitives work.</p><p>It’s helpful to view this in terms of <strong>responsibilities</strong>: the Mutex’s job here is to wake up the next task waiting for the lock.  And it’s doing that.  It’s that task’s responsibility to check on all the futures that it’s responsible for.  The Mutex cannot do that.</p></div></div><div><h3 data-sectnum="1.2."><span id="_faq_why_isnt_the_tokioselect_polling_on_future1_isnt_that_the_whole_idea_of_tokioselect" aria-hidden="true"></span><a href="#_faq_why_isnt_the_tokioselect_polling_on_future1_isnt_that_the_whole_idea_of_tokioselect">FAQ: why isn’t the <code>tokio::select!</code> polling on <code>future1</code>?  Isn’t that the whole idea of <code>tokio::select!</code><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16" role="img"><g fill="currentColor"><path d="m6.586 12.243 1.59-1.591a.75.75 0 0 1 1.061 0l.354.353a.75.75 0 0 1 0 1.06L8 13.658A4 4 0 0 1 2.343 8l1.591-1.591a.75.75 0 0 1 1.06 0l.354.354a.75.75 0 0 1 0 1.06l-1.59 1.591a2 2 0 1 0 2.828 2.829M12.066 9.591a.75.75 0 0 1-1.06 0l-.354-.354a.75.75 0 0 1 0-1.06l1.59-1.591a2 2 0 1 0-2.828-2.829l-1.59 1.591a.75.75 0 0 1-1.061 0l-.354-.353a.75.75 0 0 1 0-1.06L8 2.342A4 4 0 0 1 13.657 8z"></path><path d="M9.945 5.702a.75.75 0 0 0-1.061 0L5.702 8.884a.75.75 0 0 0 0 1.06l.353.354a.75.75 0 0 0 1.061 0l3.182-3.182a.75.75 0 0 0 0-1.06z"></path></g></svg></a></h3><div><p>The idea of <code>tokio::select!</code> is to poll on multiple futures concurrently and enter the branch for whichever one finishes first.  Once one of the futures does finish (as the <code>sleep</code> one has in our case), control enters that specific branch.  It essentially commits to that branch and it’s only running that branch at that point.</p><div data-lineno="178"><p>The <a href="https://docs.rs/tokio/1.48.0/tokio/macro.select.html#runtime-characteristics"><code>tokio::select!</code> docs</a> are explicit about this:</p></div><div data-lineno="180"><p>By running all async expressions on the current task, the expressions are able to run concurrently but not in parallel. This means all expressions are run on the same thread and if one branch blocks the thread, all other expressions will be unable to continue. If parallelism is required, spawn each async expression using tokio::spawn and pass the join handle to select!.</p></div></div></div><div><h3 data-sectnum="1.3."><span id="_faq_doesnt_future1_get_cancelled" aria-hidden="true"></span><a href="#_faq_doesnt_future1_get_cancelled">FAQ: doesn’t <code>future1</code> get cancelled?<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16" role="img"><g fill="currentColor"><path d="m6.586 12.243 1.59-1.591a.75.75 0 0 1 1.061 0l.354.353a.75.75 0 0 1 0 1.06L8 13.658A4 4 0 0 1 2.343 8l1.591-1.591a.75.75 0 0 1 1.06 0l.354.354a.75.75 0 0 1 0 1.06l-1.59 1.591a2 2 0 1 0 2.828 2.829M12.066 9.591a.75.75 0 0 1-1.06 0l-.354-.354a.75.75 0 0 1 0-1.06l1.59-1.591a2 2 0 1 0-2.828-2.829l-1.59 1.591a.75.75 0 0 1-1.061 0l-.354-.353a.75.75 0 0 1 0-1.06L8 2.342A4 4 0 0 1 13.657 8z"></path><path d="M9.945 5.702a.75.75 0 0 0-1.061 0L5.702 8.884a.75.75 0 0 0 0 1.06l.353.354a.75.75 0 0 0 1.061 0l3.182-3.182a.75.75 0 0 0 0-1.06z"></path></g></svg></a></h3><div><p>When one of the futures that <code>tokio::select!</code> is polling on completes, the others get dropped.  In this case, what’s dropped is <code>&amp;mut future1</code>.  But <code>future1</code> is not dropped, so the actual future is not cancelled.</p><p>If <code>future1</code> <em>did</em> get cancelled, you’d get no deadlock.  Try it: change the above to wait on <code>future1</code> instead of <code>&amp;mut future1</code>.  Alternatively, you can add an explicit <code>drop(future1);</code> at line 51 between the <code>sleep</code> and the <code>do_async_thing</code>.  This mimics what <code>select!</code> does if we use <code>future1</code> rather than <code>&amp;mut future1</code>.</p><div><div><p>Tasks vs. Futures</p><p>Note</p><div><p>Tasks vs. Futures</p><p>When first learning async Rust, it’s common to think of tasks and futures almost interchangeably.  When you want parallelism, you <a href="https://docs.rs/tokio/1.48.0/tokio/task/fn.spawn.html">spawn</a> a new task and give it the future that you want to run.  If you want to do 10 things in parallel, you spawn 10 tasks and then wait for them all to finish.</p><p>You can have concurrency without tasks (and without parallelism) using something like <a href="https://docs.rs/tokio/1.48.0/tokio/macro.select.html"><code>tokio::select!</code></a>.  Within a single task, you can do 10 things concurrently (not in parallel) using <code>tokio::select!</code> or <a href="https://docs.rs/futures/0.3.31/futures/prelude/stream/struct.FuturesUnordered.html"><code>FuturesUnordered</code></a> or the like.  In this case, your one task is polling on all these futures and getting woken up when any of them might be ready.</p><p><strong>Tasks</strong> are the top-level entities that the runtime executes.  Each task runs one top-level future.  That future can choose to do only do one thing at a time (as in the case of sequential code using <code>await</code>), or it can choose to do things concurrently by polling many futures, using <code>tokio::select!</code> or <code>FuturesUnordered</code> or the like.</p></div></div></div></div></div></div></div><div><h2 data-sectnum="2."><span id="_what_causes_futurelock" aria-hidden="true"></span><a href="#_what_causes_futurelock">What causes futurelock?<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16" role="img"><g fill="currentColor"><path d="m6.586 12.243 1.59-1.591a.75.75 0 0 1 1.061 0l.354.353a.75.75 0 0 1 0 1.06L8 13.658A4 4 0 0 1 2.343 8l1.591-1.591a.75.75 0 0 1 1.06 0l.354.354a.75.75 0 0 1 0 1.06l-1.59 1.591a2 2 0 1 0 2.828 2.829M12.066 9.591a.75.75 0 0 1-1.06 0l-.354-.354a.75.75 0 0 1 0-1.06l1.59-1.591a2 2 0 1 0-2.828-2.829l-1.59 1.591a.75.75 0 0 1-1.061 0l-.354-.353a.75.75 0 0 1 0-1.06L8 2.342A4 4 0 0 1 13.657 8z"></path><path d="M9.945 5.702a.75.75 0 0 0-1.061 0L5.702 8.884a.75.75 0 0 0 0 1.06l.353.354a.75.75 0 0 0 1.061 0l3.182-3.182a.75.75 0 0 0 0-1.06z"></path></g></svg></a></h2><div><p>The general problem here is that you have:</p><div data-lineno="202"><ul><li><p>task <code>T</code> is blocked on future <code>F1</code> completing (and <code>T</code> is directly awaiting <code>F1</code>)</p></li><li><p>future <code>F1</code> is blocked on future <code>F2</code> in some way (e.g., acquiring a shared Mutex)</p></li><li><p>future <code>F2</code> is blocked on task <code>T</code> polling it, but <code>T</code> isn’t polling it because it’s only polling <code>F1</code></p></li></ul></div><p>Most commonly this happens after <code>T</code> <em>started</em> polling <code>F2</code> earlier, but then switched to <code>F1</code>.  This can happen in a bunch of different cases:</p><div data-lineno="208"><ul><li><p>using <code>tokio::select!</code> with a <code>&amp;mut future</code> and awaiting in one of the other branches (our example above)</p></li><li><p>polling futures from a <code>FuturesOrdered</code>/<code>FuturesUnordered</code> (e.g., by calling <code>next()</code>) and then awaiting on any <em>other</em> future (e.g., each time one of the futures completes from the set, you do some async activity)</p></li><li><p>in a hand-written <code>Future</code> impl that behaves analogously</p></li></ul></div><div><div><p>Note</p><div><p>You can hit futurelock even if you never start polling one of the futures.  Consider <a href="https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2024&amp;gist=9135db792e63e194cd3c94be475fc11d">this example</a>:</p><div data-lineno="216"><div><pre><code data-lang="rust"><span>use</span><span> futures</span><span>::</span><span>FutureExt</span><span>;</span></code></pre></div></div><p>This deadlocks, too.  And for the same reason: this task is waiting on a future that itself depends on a future that this task is responsible for running.  This is possible but feels contrived.  This RFD focuses on cases where the dependency between futures relates to a shared resource.  That generally requires that the futures all start running so they can get in line for the resource.</p></div></div></div><div><h3 data-sectnum="2.1."><span id="_how_you_can_hit_this_with_tokioselect" aria-hidden="true"></span><a href="#_how_you_can_hit_this_with_tokioselect">How you can hit this with <code>tokio::select!</code><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16" role="img"><g fill="currentColor"><path d="m6.586 12.243 1.59-1.591a.75.75 0 0 1 1.061 0l.354.353a.75.75 0 0 1 0 1.06L8 13.658A4 4 0 0 1 2.343 8l1.591-1.591a.75.75 0 0 1 1.06 0l.354.354a.75.75 0 0 1 0 1.06l-1.59 1.591a2 2 0 1 0 2.828 2.829M12.066 9.591a.75.75 0 0 1-1.06 0l-.354-.354a.75.75 0 0 1 0-1.06l1.59-1.591a2 2 0 1 0-2.828-2.829l-1.59 1.591a.75.75 0 0 1-1.061 0l-.354-.353a.75.75 0 0 1 0-1.06L8 2.342A4 4 0 0 1 13.657 8z"></path><path d="M9.945 5.702a.75.75 0 0 0-1.061 0L5.702 8.884a.75.75 0 0 0 0 1.06l.353.354a.75.75 0 0 0 1.061 0l3.182-3.182a.75.75 0 0 0 0-1.06z"></path></g></svg></a></h3><div><p>Hitting this problem with <code>tokio::select!</code> (as in the example above) requires two things to be true:</p><div data-lineno="236"><ul><li><p>You must be passing a <code>&amp;mut future</code> to one of the branches.  If you’re passing an owned future, then it will get dropped when the <code>tokio::select!</code> enters a different branch.  That generally releases the resources that might have been blocking other futures.</p></li><li><p>You must be using <code>await</code> in one of the branches&#39; handlers.  If you’re not doing this, then the task does not get blocked on any <em>particular</em> future at the expense of the others.</p></li></ul></div><p>That said, it’s just as problematic to have an owned future <em>across</em> a <code>tokio::select!</code> and await <em>after</em> it (<a href="https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2024&amp;gist=04dbb14587c4cb99126d076e04699a06">full example</a>):</p><div data-lineno="241"><div><pre><code data-lang="rust"><span>async</span><span> fn</span><span> do_stuff</span><span>(</span><span>lock</span><span>:</span><span> Arc</span><span>&lt;</span><span>Mutex</span><span>&lt;</span><span>()</span><span>&gt;&gt;</span><span>)</span><span> {</span></code></pre></div></div><p>This results in exactly the same behavior.</p></div></div><div><h3 data-sectnum="2.2."><span id="_how_you_can_hit_this_with_streams" aria-hidden="true"></span><a href="#_how_you_can_hit_this_with_streams">How you can hit this with Streams<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16" role="img"><g fill="currentColor"><path d="m6.586 12.243 1.59-1.591a.75.75 0 0 1 1.061 0l.354.353a.75.75 0 0 1 0 1.06L8 13.658A4 4 0 0 1 2.343 8l1.591-1.591a.75.75 0 0 1 1.06 0l.354.354a.75.75 0 0 1 0 1.06l-1.59 1.591a2 2 0 1 0 2.828 2.829M12.066 9.591a.75.75 0 0 1-1.06 0l-.354-.354a.75.75 0 0 1 0-1.06l1.59-1.591a2 2 0 1 0-2.828-2.829l-1.59 1.591a.75.75 0 0 1-1.061 0l-.354-.353a.75.75 0 0 1 0-1.06L8 2.342A4 4 0 0 1 13.657 8z"></path><path d="M9.945 5.702a.75.75 0 0 0-1.061 0L5.702 8.884a.75.75 0 0 0 0 1.06l.353.354a.75.75 0 0 0 1.061 0l3.182-3.182a.75.75 0 0 0 0-1.06z"></path></g></svg></a></h3><div><p>If you pull a future from a <code>Stream</code> and then await a future that somehow depends on another Future in the stream, you can wind up with futurelock.  Here’s what it looks like with FuturesOrdered (<a href="https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2024&amp;gist=3b8505524169c79a6bd53c3aa9f5fbfa">full example</a>):</p><div data-lineno="266"><div><pre><code data-lang="rust"><span>async</span><span> fn</span><span> do_stuff</span><span>(</span><span>lock</span><span>:</span><span> Arc</span><span>&lt;</span><span>Mutex</span><span>&lt;</span><span>()</span><span>&gt;&gt;</span><span>)</span><span> {</span></code></pre></div></div><div data-lineno="281"><p>A <a href="https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2024&amp;gist=1bf9e261ef1e1028b86086c2deea8c59">nearly identical example creates futurelock with <code>FuturesUnordered</code></a>.</p></div><p>These are often used in a loop, so it may tend to look more like this (<a href="https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2024&amp;gist=308ce60285fada7ec248f3661ffbcfe0">full example</a>):</p><div data-lineno="285"><div><pre><code data-lang="rust"><span>async</span><span> fn</span><span> do_stuff</span><span>(</span><span>lock</span><span>:</span><span> Arc</span><span>&lt;</span><span>Mutex</span><span>&lt;</span><span>()</span><span>&gt;&gt;</span><span>)</span><span> {</span></code></pre></div></div><p>It seems likely that futurelock is a risk when using many other <a href="https://docs.rs/futures/0.3.31/futures/prelude/stream/index.html">Stream functions</a>.</p></div></div><div><h3 data-sectnum="2.3."><span id="_what_about_join_all" aria-hidden="true"></span><a href="#_what_about_join_all">What about <code>join_all</code>?<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16" role="img"><g fill="currentColor"><path d="m6.586 12.243 1.59-1.591a.75.75 0 0 1 1.061 0l.354.353a.75.75 0 0 1 0 1.06L8 13.658A4 4 0 0 1 2.343 8l1.591-1.591a.75.75 0 0 1 1.06 0l.354.354a.75.75 0 0 1 0 1.06l-1.59 1.591a2 2 0 1 0 2.828 2.829M12.066 9.591a.75.75 0 0 1-1.06 0l-.354-.354a.75.75 0 0 1 0-1.06l1.59-1.591a2 2 0 1 0-2.828-2.829l-1.59 1.591a.75.75 0 0 1-1.061 0l-.354-.353a.75.75 0 0 1 0-1.06L8 2.342A4 4 0 0 1 13.657 8z"></path><path d="M9.945 5.702a.75.75 0 0 0-1.061 0L5.702 8.884a.75.75 0 0 0 0 1.06l.353.354a.75.75 0 0 0 1.061 0l3.182-3.182a.75.75 0 0 0 0-1.06z"></path></g></svg></a></h3><div><p>You can’t hit this with <a href="https://docs.rs/futures/latest/futures/future/fn.join_all.html"><code>futures::future::join_all</code></a>.  That’s because it polls all of its futures and does not stop polling any of the pending futures.</p></div></div></div></div><div><h2 data-sectnum="3."><span id="_failure_mode_debugging" aria-hidden="true"></span><a href="#_failure_mode_debugging">Failure mode, debugging<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16" role="img"><g fill="currentColor"><path d="m6.586 12.243 1.59-1.591a.75.75 0 0 1 1.061 0l.354.353a.75.75 0 0 1 0 1.06L8 13.658A4 4 0 0 1 2.343 8l1.591-1.591a.75.75 0 0 1 1.06 0l.354.354a.75.75 0 0 1 0 1.06l-1.59 1.591a2 2 0 1 0 2.828 2.829M12.066 9.591a.75.75 0 0 1-1.06 0l-.354-.354a.75.75 0 0 1 0-1.06l1.59-1.591a2 2 0 1 0-2.828-2.829l-1.59 1.591a.75.75 0 0 1-1.061 0l-.354-.353a.75.75 0 0 1 0-1.06L8 2.342A4 4 0 0 1 13.657 8z"></path><path d="M9.945 5.702a.75.75 0 0 0-1.061 0L5.702 8.884a.75.75 0 0 0 0 1.06l.353.354a.75.75 0 0 0 1.061 0l3.182-3.182a.75.75 0 0 0 0-1.06z"></path></g></svg></a></h2><div><p>Futurelock is a type of deadlock and tends to manifest as a hang of part or all of the program.  When we saw this in <a href="https://github.com/oxidecomputer/omicron/issues/9259">omicron#9259</a>, every future attempting to access the database became part of the futurelock.  Since authorization uses the database, essentially every incoming HTTP request hung indefiniteily.</p><p>Debugging this problem from direct observation can be next to impossible.  Typically, you’d only start looking at data long after the problem happened.  At that point, it’s not clear what evidence you’d find even if you could peer into the executor state.  The problem looks like a <code>pending</code> future whose task has been woken up <em>because</em> of that future, but the task has not polled the future.  (Maybe <code>tokio-console</code> could help?)</p><p>In omicron#9259, we were able to determine (by tracing individual function calls with DTrace) that:</p><div data-lineno="315"><ul><li><p>all incoming requests were blocking on attempts to send on an <code>mpsc</code> channel with capacity 1</p></li><li><p>the receiving end of this channel was regularly checking it and finding no messages queued</p></li></ul></div><p>This confused us for quite a while.  Why are senders blocking if there’s nothing in the channel?  In hindsight, the answer’s implied by the documentation for <a href="https://docs.rs/tokio/1.48.0/tokio/sync/mpsc/struct.Sender.html"><code>Sender</code></a>, which says:</p><div data-lineno="320"><p>Sends a value, waiting until there is capacity.</p><p>…​</p><p>This channel uses a queue to ensure that calls to send and reserve complete in the order they were requested.</p></div><p>One can infer that a given call to <code>send</code> may block either because there is no capacity <em>or</em> because another sender’s <code>send()</code> is not completing.  That <em>could</em> be because the channel is full, but in our case it’s because the future for that sender had run into futurelock.</p><p>It’s hard to give useful advice for debugging this sort of problem aside from advising that you consider futurelock as a possibility if you’re debugging a hang and some future appears blocked when other evidence suggests that it shouldn’t be.</p></div></div><div><h2 data-sectnum="4."><span id="_determinations_avoiding_this_problem" aria-hidden="true"></span><a href="#_determinations_avoiding_this_problem">Determinations: avoiding this problem<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16" role="img"><g fill="currentColor"><path d="m6.586 12.243 1.59-1.591a.75.75 0 0 1 1.061 0l.354.353a.75.75 0 0 1 0 1.06L8 13.658A4 4 0 0 1 2.343 8l1.591-1.591a.75.75 0 0 1 1.06 0l.354.354a.75.75 0 0 1 0 1.06l-1.59 1.591a2 2 0 1 0 2.828 2.829M12.066 9.591a.75.75 0 0 1-1.06 0l-.354-.354a.75.75 0 0 1 0-1.06l1.59-1.591a2 2 0 1 0-2.828-2.829l-1.59 1.591a.75.75 0 0 1-1.061 0l-.354-.353a.75.75 0 0 1 0-1.06L8 2.342A4 4 0 0 1 13.657 8z"></path><path d="M9.945 5.702a.75.75 0 0 0-1.061 0L5.702 8.884a.75.75 0 0 0 0 1.06l.353.354a.75.75 0 0 0 1.061 0l3.182-3.182a.75.75 0 0 0 0-1.06z"></path></g></svg></a></h2><div><p>Like async cancellation (see <a href="#rfd397">[rfd397]</a>), futurelock defeats Rust’s goal of being able to <a href="https://sunshowers.io/posts/cancelling-async-rust/#systematic-solutions">reason locally</a> about correctness.  If we look at the pieces involved in our example:</p><div data-lineno="334"><ul><li><p>Using <code>tokio::select!</code> to wait for any of a few things to happen</p></li><li><p>Using <code>await</code> in a <code>tokio::select!</code> branch</p></li><li><p>Using a <code>&amp;mut future</code> with <code>tokio::select!</code></p></li><li><p>Using a Mutex<sup>[<a id="_footnoteref_3" href="#_footnotedef_3" title="View footnote.">3</a>]</sup></p></li></ul></div><p>None of these by itself is wrong, but combining them results in futurelock.  Remember too that the Mutex could be buried beneath several layers of function calls in different modules or packages.  It could require looking across many layers of the stack at once to be able to see the problem.</p><p>There’s no one abstraction, construct, or programming pattern we can point to here and say &#34;never do this&#34;.  Still, we can provide some guidelines.</p><div><h3 data-sectnum="4.1."><span id="_in_general" aria-hidden="true"></span><a href="#_in_general">In general<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16" role="img"><g fill="currentColor"><path d="m6.586 12.243 1.59-1.591a.75.75 0 0 1 1.061 0l.354.353a.75.75 0 0 1 0 1.06L8 13.658A4 4 0 0 1 2.343 8l1.591-1.591a.75.75 0 0 1 1.06 0l.354.354a.75.75 0 0 1 0 1.06l-1.59 1.591a2 2 0 1 0 2.828 2.829M12.066 9.591a.75.75 0 0 1-1.06 0l-.354-.354a.75.75 0 0 1 0-1.06l1.59-1.591a2 2 0 1 0-2.828-2.829l-1.59 1.591a.75.75 0 0 1-1.061 0l-.354-.353a.75.75 0 0 1 0-1.06L8 2.342A4 4 0 0 1 13.657 8z"></path><path d="M9.945 5.702a.75.75 0 0 0-1.061 0L5.702 8.884a.75.75 0 0 0 0 1.06l.353.354a.75.75 0 0 0 1.061 0l3.182-3.182a.75.75 0 0 0 0-1.06z"></path></g></svg></a></h3><div><p>The most specific <em>general</em> advice we can give is: any time you have a single task polling multiple futures concurrently, be extremely careful that the task never stops polling a future that it previously started polling.</p><p>One way to avoid this situation is to bias towards spawning futures in new tasks instead.  There are other considerations with this approach: futures would be cancelled when they’re dropped, but tasks won’t be aborted when their JoinHandle is dropped.  If you want this, see <a href="https://docs.rs/tokio-util/0.7.16/tokio_util/task/struct.AbortOnDropHandle.html"><code>AbortOnDropHandle</code></a>.</p></div></div><div><h3 data-sectnum="4.2."><span id="_when_using_tokioselect" aria-hidden="true"></span><a href="#_when_using_tokioselect">When using <code>tokio::select!</code><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16" role="img"><g fill="currentColor"><path d="m6.586 12.243 1.59-1.591a.75.75 0 0 1 1.061 0l.354.353a.75.75 0 0 1 0 1.06L8 13.658A4 4 0 0 1 2.343 8l1.591-1.591a.75.75 0 0 1 1.06 0l.354.354a.75.75 0 0 1 0 1.06l-1.59 1.591a2 2 0 1 0 2.828 2.829M12.066 9.591a.75.75 0 0 1-1.06 0l-.354-.354a.75.75 0 0 1 0-1.06l1.59-1.591a2 2 0 1 0-2.828-2.829l-1.59 1.591a.75.75 0 0 1-1.061 0l-.354-.353a.75.75 0 0 1 0-1.06L8 2.342A4 4 0 0 1 13.657 8z"></path><path d="M9.945 5.702a.75.75 0 0 0-1.061 0L5.702 8.884a.75.75 0 0 0 0 1.06l.353.354a.75.75 0 0 0 1.061 0l3.182-3.182a.75.75 0 0 0 0-1.06z"></path></g></svg></a></h3><div><p>If you find yourself writing or reviewing code that does <em>either</em> of these:</p><div data-lineno="353"><ul><li><p>Uses a <code>&amp;mut future</code> as one of the async expressions in the <code>tokio::select!</code></p></li><li><p>Awaits inside the handler of a <code>tokio::select!</code> branch or after the <code>tokio::select!</code> before the <code>future</code> has been dropped</p></li></ul></div><p>then look for the other as well.  If both are present, pay close attention to the risk of futurelock.  To avoid it, you either need to avoid doing both of these things in the same <code>tokio::select!</code> call or else be <em>very</em> sure that <code>future</code> never blocks with shared resources held that could block other futures.</p><div data-lineno="358"><p>Let’s consider a <a href="https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2024&amp;gist=5e3c3cf0adb08c42f6c135137bd075a0">variation of our original example</a>:</p></div><div data-lineno="360"><div><pre><code data-lang="rust"><span>    let</span><span> mut</span><span> future1 </span><span>=</span><span> do_async_thing</span><span>(</span><span>&#34;op1&#34;</span><span>,</span><span> lock</span><span>.</span><span>clone</span><span>())</span><span>.</span><span>boxed</span><span>();</span></code></pre></div></div><p>Here, we’ve wrapped the <code>tokio::select!</code> in a loop.  This is a common pattern.  The idea here is mainly to run <code>future1</code>, but every 500ms we do something related (like report progress or check if we should cancel the like).</p><p>The easiest way to make this safer is to <strong>spawn <code>future</code> in a new task</strong>.  Then use the <code>JoinHandle</code> in the <code>tokio::select!</code>, like <a href="https://play.rust-lang.org/?version=stable&amp;mode=debug&amp;edition=2024&amp;gist=23508b4033b0a0bfcd627814f1e3416d">this version</a>:</p><div data-lineno="384"><div><pre><code data-lang="rust"><span>    let</span><span> future1 </span><span>=</span><span> do_async_thing</span><span>(</span><span>&#34;op1&#34;</span><span>,</span><span> lock</span><span>.</span><span>clone</span><span>());</span></code></pre></div></div><p>This has the same desired effect of keeping <code>future1</code> running, but now <code>future1_task</code> is a separate future.  It’s cancellable, and cancelling it won’t cancel <code>future1</code>.  (If you want that, you can still use <code>future1_task.abort()</code>.)  This construction cannot result in futurelock.</p><p>If you’re not using a loop, this approach is even better: then you can just pass <code>future1_task</code> to <code>tokio::select!</code> (rather than <code>&amp;mut future1_task</code>) and it’ll be more obvious that this is safe.</p><p>In the end, <strong>you should always be extremely careful with <code>tokio::select!</code></strong>.  That’s because:</p><div data-lineno="411"><ul><li><p>If you use it with borrowed futures, beware of futurelock.</p></li><li><p>If you use it with owned futures, beware of cancel-safety (see <a href="#rfd397">[rfd397]</a> and <a href="#rfd400">[rfd400]</a>).</p></li></ul></div><p>So either way you’ve got a subtle, non-locally-reasonable, undebuggable problem to worry about that the compiler can’t really help with.</p></div></div><div><h3 data-sectnum="4.3."><span id="_when_using_stream" aria-hidden="true"></span><a href="#_when_using_stream">When using <code>Stream</code><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16" role="img"><g fill="currentColor"><path d="m6.586 12.243 1.59-1.591a.75.75 0 0 1 1.061 0l.354.353a.75.75 0 0 1 0 1.06L8 13.658A4 4 0 0 1 2.343 8l1.591-1.591a.75.75 0 0 1 1.06 0l.354.354a.75.75 0 0 1 0 1.06l-1.59 1.591a2 2 0 1 0 2.828 2.829M12.066 9.591a.75.75 0 0 1-1.06 0l-.354-.354a.75.75 0 0 1 0-1.06l1.59-1.591a2 2 0 1 0-2.828-2.829l-1.59 1.591a.75.75 0 0 1-1.061 0l-.354-.353a.75.75 0 0 1 0-1.06L8 2.342A4 4 0 0 1 13.657 8z"></path><path d="M9.945 5.702a.75.75 0 0 0-1.061 0L5.702 8.884a.75.75 0 0 0 0 1.06l.353.354a.75.75 0 0 0 1.061 0l3.182-3.182a.75.75 0 0 0 0-1.06z"></path></g></svg></a></h3><div><p>When using a <code>FuturesOrdered</code> or <code>FuturesUnordered</code>, consider instead using <a href="https://docs.rs/tokio/1.48.0/tokio/task/join_set/struct.JoinSet.html">tokio’s <code>JoinSet</code></a>.  This provides a similar interface, but the futures you’re waiting for are all running in separate tasks.</p><p>If for whatever reason that’s not appropriate (e.g., you’re not using <code>tokio</code>, or you really need a <code>Stream</code> interface), then in the body of a loop that pulls completed futures from the <code>Stream</code>, do not await any other futures.  If you’re working with a <code>FuturesUnordered</code>, consider putting those futures into the set instead.</p></div></div><div><h3 data-sectnum="4.4."><span id="_when_using_bounded_channels" aria-hidden="true"></span><a href="#_when_using_bounded_channels">When using bounded channels<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16" role="img"><g fill="currentColor"><path d="m6.586 12.243 1.59-1.591a.75.75 0 0 1 1.061 0l.354.353a.75.75 0 0 1 0 1.06L8 13.658A4 4 0 0 1 2.343 8l1.591-1.591a.75.75 0 0 1 1.06 0l.354.354a.75.75 0 0 1 0 1.06l-1.59 1.591a2 2 0 1 0 2.828 2.829M12.066 9.591a.75.75 0 0 1-1.06 0l-.354-.354a.75.75 0 0 1 0-1.06l1.59-1.591a2 2 0 1 0-2.828-2.829l-1.59 1.591a.75.75 0 0 1-1.061 0l-.354-.353a.75.75 0 0 1 0-1.06L8 2.342A4 4 0 0 1 13.657 8z"></path><path d="M9.945 5.702a.75.75 0 0 0-1.061 0L5.702 8.884a.75.75 0 0 0 0 1.06l.353.354a.75.75 0 0 0 1.061 0l3.182-3.182a.75.75 0 0 0 0-1.06z"></path></g></svg></a></h3><div><p>Bounded channels are not really the issue here.  Even in omicron#9259, the capacity=1 channel was basically behaving as documented and as one would expect.  It woke up a sender when capacity was available, and the other senders were blocked to maintain the documented FIFO property.  However, some of the patterns that we use with bounded channels are problematic on their own and, if changed, could prevent the channel from getting caught up in a futurelock.</p><p>In Omicron, we commonly use bounded channels with <code>send(msg).await</code>.  The bound is intended to cap memory usage and provide backpressure, but using the blocking <code>send</code> creates a second <em>unbounded</em> queue: the wait queue for the channel.  Instead, we could consider using a larger capacity channel plus <code>try_send()</code> and propagate failure from <code>try_send()</code>.</p><p>As an example, when we use the actor pattern, we typically observe that there’s only one actor and potentially many clients, so there’s not much point in buffering messages <em>in</em> the channel.  So we use <code>capacity = 1</code> and let clients block in <code>send().await</code>.  But we could instead have <code>capacity = 16</code> and have clients use <code>try_send()</code> and propagate failure if they’re unable to send the message.  The value <code>16</code> here is pretty arbitrary.  You want it to be large enough to account for an expected amount of client concurrency, but not larger.  If the value is too small, you’ll wind up with spurious failures when the client could have just waited a bit longer.  If the value is too large, you can wind up queueing so much work that the actor is always behind (and clients are potentially even timing out at a higher level).  One might observe:</p><div data-lineno="430"><p>Channel limits, channel limits: always wrong!</p><p>Some too short and some too long!</p></div><p>But as with timeouts, it’s often possible to find values that work in practice.</p><p>Using <code>send_timeout()</code> is <em>not</em> a mitigation because this still results in the sender blocking.  It needs to be polled after the timeout expires in order to give up.  But with futurelock, it will never be polled.</p></div></div><div><h3 data-sectnum="4.5."><span id="_anti_pattern_just_make_the_channel_bigger" aria-hidden="true"></span><a href="#_anti_pattern_just_make_the_channel_bigger">Anti-pattern: just make the channel bigger<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16" role="img"><g fill="currentColor"><path d="m6.586 12.243 1.59-1.591a.75.75 0 0 1 1.061 0l.354.353a.75.75 0 0 1 0 1.06L8 13.658A4 4 0 0 1 2.343 8l1.591-1.591a.75.75 0 0 1 1.06 0l.354.354a.75.75 0 0 1 0 1.06l-1.59 1.591a2 2 0 1 0 2.828 2.829M12.066 9.591a.75.75 0 0 1-1.06 0l-.354-.354a.75.75 0 0 1 0-1.06l1.59-1.591a2 2 0 1 0-2.828-2.829l-1.59 1.591a.75.75 0 0 1-1.061 0l-.354-.353a.75.75 0 0 1 0-1.06L8 2.342A4 4 0 0 1 13.657 8z"></path><path d="M9.945 5.702a.75.75 0 0 0-1.061 0L5.702 8.884a.75.75 0 0 0 0 1.06l.353.354a.75.75 0 0 0 1.061 0l3.182-3.182a.75.75 0 0 0 0-1.06z"></path></g></svg></a></h3><div><div data-lineno="440"><p>In our <a href="https://github.com/oxidecomputer/omicron/issues/9259">initial encounter with this problem</a>, we had a bounded <a href="https://docs.rs/tokio/latest/tokio/sync/mpsc/index.html"><code>tokio::sync::mpsc</code></a> channel of capacity 1.  Why not bump the capacity up?</p></div><p>To avoid futurelock, the channel would have to have capacity big enough that nobody in the call stack could possibly have that many futures that they’ve started and aren’t polling.  There is of course no way to know how big this needs to be, and it could change over time as the program evolves.  Further, there are big side effects to having big channels like this in terms of latency, backpressure, and memory usage.</p></div></div><div><h3 data-sectnum="4.6."><span id="_anti_pattern_try_to_avoid_dependencies_between_futures" aria-hidden="true"></span><a href="#_anti_pattern_try_to_avoid_dependencies_between_futures">Anti-pattern: try to avoid dependencies between futures<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16" role="img"><g fill="currentColor"><path d="m6.586 12.243 1.59-1.591a.75.75 0 0 1 1.061 0l.354.353a.75.75 0 0 1 0 1.06L8 13.658A4 4 0 0 1 2.343 8l1.591-1.591a.75.75 0 0 1 1.06 0l.354.354a.75.75 0 0 1 0 1.06l-1.59 1.591a2 2 0 1 0 2.828 2.829M12.066 9.591a.75.75 0 0 1-1.06 0l-.354-.354a.75.75 0 0 1 0-1.06l1.59-1.591a2 2 0 1 0-2.828-2.829l-1.59 1.591a.75.75 0 0 1-1.061 0l-.354-.353a.75.75 0 0 1 0-1.06L8 2.342A4 4 0 0 1 13.657 8z"></path><path d="M9.945 5.702a.75.75 0 0 0-1.061 0L5.702 8.884a.75.75 0 0 0 0 1.06l.353.354a.75.75 0 0 0 1.061 0l3.182-3.182a.75.75 0 0 0 0-1.06z"></path></g></svg></a></h3><div><p>In principle, you could avoid this problem if you avoid dependencies between futures.  Aside from using <code>spawn</code> to do this, we do not recommend this in general because it’s brittle and risky.</p><p>First, it’s hard to know there are no dependencies.  Any shared resource can be such a dependency: a bounded channel of any kind, a Mutex, a request to a remote service, etc.  And it can be anywhere in the stack, including several dependency packages down the call chain.</p><p>Even if there’s no such dependency <em>now</em>, one could be added later.  You could imagine <code>future1</code> calling <code>some_crate::func1()</code> and <code>future2</code> calling <code>other_crate::func2()</code> that seem like simple functions.  <code>some_crate</code> could decide to add a global Mutex that is otherwise safe and correct, but this would now break <em>your</em> <code>tokio::select!</code> that was previously assuming these futures shared no dependencies.</p><p>The exception to this is that using <code>tokio::spawn</code> <em>is</em> a good way to replace one or more futures that could be subject to futurelock with ones that can’t.  The returned <code>JoinHandle</code> is a future that becomes ready under the same conditions as the underlying one, but it does not hold shared resources and it’s very unlikely that that would ever change as tokio evolves.  (Such a change would almost certainly break lots of correctly-written programs.)</p></div></div></div></div><div><h2 data-sectnum="5."><span id="_open_questions" aria-hidden="true"></span><a href="#_open_questions">Open Questions<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16" role="img"><g fill="currentColor"><path d="m6.586 12.243 1.59-1.591a.75.75 0 0 1 1.061 0l.354.353a.75.75 0 0 1 0 1.06L8 13.658A4 4 0 0 1 2.343 8l1.591-1.591a.75.75 0 0 1 1.06 0l.354.354a.75.75 0 0 1 0 1.06l-1.59 1.591a2 2 0 1 0 2.828 2.829M12.066 9.591a.75.75 0 0 1-1.06 0l-.354-.354a.75.75 0 0 1 0-1.06l1.59-1.591a2 2 0 1 0-2.828-2.829l-1.59 1.591a.75.75 0 0 1-1.061 0l-.354-.353a.75.75 0 0 1 0-1.06L8 2.342A4 4 0 0 1 13.657 8z"></path><path d="M9.945 5.702a.75.75 0 0 0-1.061 0L5.702 8.884a.75.75 0 0 0 0 1.06l.353.354a.75.75 0 0 0 1.061 0l3.182-3.182a.75.75 0 0 0 0-1.06z"></path></g></svg></a></h2><div><p>Can we write clippy lints to:</p><div data-lineno="458"><ul><li><p>Warn when passing <code>&amp;mut future</code> to a <code>tokio::select!</code> arm and suggest that <code>tokio::spawn</code> be used instead, and</p></li><li><p>Warn when using <code>await</code> in a <code>tokio::select!</code> arm?  (This is problematic for other reasons anyway when <code>select!</code> is used in a loop.)</p></li></ul></div><p>There are certainly cases to do this and it’s okay to override the warning, but it’d be nice to have that guard rail.</p></div></div><div><h2 data-sectnum="6."><span id="_security_considerations" aria-hidden="true"></span><a href="#_security_considerations">Security Considerations<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16" role="img"><g fill="currentColor"><path d="m6.586 12.243 1.59-1.591a.75.75 0 0 1 1.061 0l.354.353a.75.75 0 0 1 0 1.06L8 13.658A4 4 0 0 1 2.343 8l1.591-1.591a.75.75 0 0 1 1.06 0l.354.354a.75.75 0 0 1 0 1.06l-1.59 1.591a2 2 0 1 0 2.828 2.829M12.066 9.591a.75.75 0 0 1-1.06 0l-.354-.354a.75.75 0 0 1 0-1.06l1.59-1.591a2 2 0 1 0-2.828-2.829l-1.59 1.591a.75.75 0 0 1-1.061 0l-.354-.353a.75.75 0 0 1 0-1.06L8 2.342A4 4 0 0 1 13.657 8z"></path><path d="M9.945 5.702a.75.75 0 0 0-1.061 0L5.702 8.884a.75.75 0 0 0 0 1.06l.353.354a.75.75 0 0 0 1.061 0l3.182-3.182a.75.75 0 0 0 0-1.06z"></path></g></svg></a></h2><div><p>None actionable.  Futurelock is a potential vector for denial of service, but it’s bad anyway, and we know we want to avoid it.</p></div></div><div><h2 data-sectnum=""><span id="_external_references" aria-hidden="true"></span><a href="#_external_references">External References<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" viewBox="0 0 16 16" role="img"><g fill="currentColor"><path d="m6.586 12.243 1.59-1.591a.75.75 0 0 1 1.061 0l.354.353a.75.75 0 0 1 0 1.06L8 13.658A4 4 0 0 1 2.343 8l1.591-1.591a.75.75 0 0 1 1.06 0l.354.354a.75.75 0 0 1 0 1.06l-1.59 1.591a2 2 0 1 0 2.828 2.829M12.066 9.591a.75.75 0 0 1-1.06 0l-.354-.354a.75.75 0 0 1 0-1.06l1.59-1.591a2 2 0 1 0-2.828-2.829l-1.59 1.591a.75.75 0 0 1-1.061 0l-.354-.353a.75.75 0 0 1 0-1.06L8 2.342A4 4 0 0 1 13.657 8z"></path><path d="M9.945 5.702a.75.75 0 0 0-1.061 0L5.702 8.884a.75.75 0 0 0 0 1.06l.353.354a.75.75 0 0 0 1.061 0l3.182-3.182a.75.75 0 0 0 0-1.06z"></path></g></svg></a></h2><div><div data-lineno="470"><ul><li><p><a id="rfd397"></a>[rfd397] Oxide Computer Co. <a href="https://397.rfd.oxide.computer/">RFD 397 Challenges with async/await in the control plane</a>. 2023.</p></li><li><p><a id="rfd400"></a>[rfd400] Oxide Computer Co. <a href="https://400.rfd.oxide.computer/">RFD 400 Dealing with cancel safety in async Rust</a></p></li></ul></div></div></div></div></div>
  </body>
</html>
