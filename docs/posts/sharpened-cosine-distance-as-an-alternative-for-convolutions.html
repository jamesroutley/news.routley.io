<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.rpisoni.dev/posts/cossim-convolution/">Original</a>
    <h1>Sharpened Cosine Distance as an Alternative for Convolutions</h1>
    
    <div id="readability-page-1" class="page"><div itemprop="articleBody text">
    <p>Some days ago Brandon Rohrer retweeted his own twitter thread from 2020 in which he makes the argument that convolutions are 
actually pretty bad at extracting features. In it he proposes a method to improve feature extraction that seemed compelling to me.</p>
<p>$$ scd(s, k) = sign(s \cdot k)\Biggl(\frac{s \cdot k}{(\Vert{s}\Vert+q)(\Vert{k}\Vert+q)}\Biggr)^p $$</p>
<p>I decided to try this idea out and created a neural network layer based on this formula and as it turns out <em>it actually works!</em></p>
<!-- TEASER_END -->
<p>If you want to know more about the details of why convolution is such a bad feature extractor I suggest you check out the full thread of the tweet below.</p>
<blockquote>
<p lang="en" dir="ltr">The thing that has surprised me the most about convolution is that it’s used in neural networks as a feature detector, but it’s pretty bad at detecting features.</p>— Brandon Rohrer (@_brohrer_) <a href="https://twitter.com/_brohrer_/status/1232063619657093120?ref_src=twsrc%5Etfw">February 24, 2020</a>
</blockquote>
<p>Long story short: As you can see below if you convolve a kernel over a sequence it does not give the highest activation for a signal that matches the kernel:</p>
<p><img alt="how_convolution_fails" src="https://www.rpisoni.dev/images/scd/ezgif-5-ab44a469f7.gif"/></p>
<p>If you apply the formula for the Sharpened Cosine Distance however the result looks more the way we want it to look. 
A feature is detected independent of its sign or scale as long as the scale is significantly larger than \( p \).</p>
<p><img alt="scd_activations" src="https://www.rpisoni.dev/images/scd/ezgif-5-cd185854f7.gif"/></p>
<p>The implementations is a bit more involved than the formula since we need to reimplement the sliding window mechanism that is traditionally contained in the convolution code.
Furthermore, we need to make sure the gradients stay stable so e.g. we need to avoid \( p\) and  \( q\) getting negative which I do by squaring them.</p>
<p>So where is the full implementation of this Sharpened Cosine Distance Layer? Find the Keras Code below or have a look at the <a href="https://gist.github.com/4rtemi5/607909e6ac1ef3cfb54d5b85111f92b9">gist</a>:</p>
<pre><span>import</span> <span>tensorflow</span> <span>as</span> <span>tf</span>

<span>class</span> <span>CosSimConv2D</span><span>(</span><span>tf</span><span>.</span><span>keras</span><span>.</span><span>layers</span><span>.</span><span>Layer</span><span>):</span>
    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>units</span><span>=</span><span>32</span><span>):</span>
        <span>super</span><span>(</span><span>CosSimConv2D</span><span>,</span> <span>self</span><span>)</span><span>.</span><span>__init__</span><span>()</span>
        <span>self</span><span>.</span><span>units</span> <span>=</span> <span>units</span>
        <span>self</span><span>.</span><span>kernel_size</span> <span>=</span> <span>3</span>

    <span>def</span> <span>build</span><span>(</span><span>self</span><span>,</span> <span>input_shape</span><span>):</span>
        <span>self</span><span>.</span><span>in_shape</span> <span>=</span> <span>input_shape</span>

        <span>self</span><span>.</span><span>flat_size</span> <span>=</span> <span>self</span><span>.</span><span>in_shape</span><span>[</span><span>1</span><span>]</span> <span>*</span> <span>self</span><span>.</span><span>in_shape</span><span>[</span><span>2</span><span>]</span>
        <span>self</span><span>.</span><span>channels</span> <span>=</span> <span>self</span><span>.</span><span>in_shape</span><span>[</span><span>3</span><span>]</span>

        <span>self</span><span>.</span><span>w</span> <span>=</span> <span>self</span><span>.</span><span>add_weight</span><span>(</span>
            <span>shape</span><span>=</span><span>(</span><span>1</span><span>,</span> <span>self</span><span>.</span><span>channels</span> <span>*</span> <span>tf</span><span>.</span><span>square</span><span>(</span><span>self</span><span>.</span><span>kernel_size</span><span>),</span> <span>self</span><span>.</span><span>units</span><span>),</span>
            <span>initializer</span><span>=</span><span>&#34;glorot_uniform&#34;</span><span>,</span>
            <span>trainable</span><span>=</span><span>True</span><span>,</span>
        <span>)</span>

        <span>self</span><span>.</span><span>p</span> <span>=</span> <span>self</span><span>.</span><span>add_weight</span><span>(</span>
            <span>shape</span><span>=</span><span>(</span><span>self</span><span>.</span><span>units</span><span>,),</span> <span>initializer</span><span>=</span><span>&#39;zeros&#39;</span><span>,</span> <span>trainable</span><span>=</span><span>True</span><span>)</span>

        <span>self</span><span>.</span><span>q</span> <span>=</span> <span>self</span><span>.</span><span>add_weight</span><span>(</span>
            <span>shape</span><span>=</span><span>(</span><span>1</span><span>,),</span> <span>initializer</span><span>=</span><span>&#39;zeros&#39;</span><span>,</span> <span>trainable</span><span>=</span><span>True</span><span>)</span>

    <span>def</span> <span>l2_normal</span><span>(</span><span>self</span><span>,</span> <span>x</span><span>,</span> <span>axis</span><span>=</span><span>None</span><span>,</span> <span>epsilon</span><span>=</span><span>1e-12</span><span>):</span>
        <span>square_sum</span> <span>=</span> <span>tf</span><span>.</span><span>reduce_sum</span><span>(</span><span>tf</span><span>.</span><span>square</span><span>(</span><span>x</span><span>),</span> <span>axis</span><span>,</span> <span>keepdims</span><span>=</span><span>True</span><span>)</span>
        <span>x_inv_norm</span> <span>=</span> <span>tf</span><span>.</span><span>sqrt</span><span>(</span><span>tf</span><span>.</span><span>maximum</span><span>(</span><span>square_sum</span><span>,</span> <span>epsilon</span><span>))</span>
        <span>return</span> <span>x_inv_norm</span>

    <span>def</span> <span>stack3x3</span><span>(</span><span>self</span><span>,</span> <span>image</span><span>):</span>
        <span>stack</span> <span>=</span> <span>tf</span><span>.</span><span>stack</span><span>(</span>
            <span>[</span>
                <span>tf</span><span>.</span><span>pad</span><span>(</span><span>image</span><span>[:,</span> <span>:</span><span>-</span><span>1</span><span>,</span> <span>:</span><span>-</span><span>1</span><span>,</span> <span>:],</span> <span>tf</span><span>.</span><span>constant</span><span>([[</span><span>0</span><span>,</span><span>0</span><span>],</span> <span>[</span><span>1</span><span>,</span><span>0</span><span>],</span> <span>[</span><span>1</span><span>,</span><span>0</span><span>],</span> <span>[</span><span>0</span><span>,</span><span>0</span><span>]])),</span>   <span># top row</span>
                <span>tf</span><span>.</span><span>pad</span><span>(</span><span>image</span><span>[:,</span> <span>:</span><span>-</span><span>1</span><span>,</span> <span>:,</span> <span>:],</span>   <span>tf</span><span>.</span><span>constant</span><span>([[</span><span>0</span><span>,</span><span>0</span><span>],</span> <span>[</span><span>1</span><span>,</span><span>0</span><span>],</span> <span>[</span><span>0</span><span>,</span><span>0</span><span>],</span> <span>[</span><span>0</span><span>,</span><span>0</span><span>]])),</span>
                <span>tf</span><span>.</span><span>pad</span><span>(</span><span>image</span><span>[:,</span> <span>:</span><span>-</span><span>1</span><span>,</span> <span>1</span><span>:,</span> <span>:],</span>  <span>tf</span><span>.</span><span>constant</span><span>([[</span><span>0</span><span>,</span><span>0</span><span>],</span> <span>[</span><span>1</span><span>,</span><span>0</span><span>],</span> <span>[</span><span>0</span><span>,</span><span>1</span><span>],</span> <span>[</span><span>0</span><span>,</span><span>0</span><span>]])),</span>

                <span>tf</span><span>.</span><span>pad</span><span>(</span><span>image</span><span>[:,</span> <span>:,</span> <span>:</span><span>-</span><span>1</span><span>,</span> <span>:],</span>   <span>tf</span><span>.</span><span>constant</span><span>([[</span><span>0</span><span>,</span><span>0</span><span>],</span> <span>[</span><span>0</span><span>,</span><span>0</span><span>],</span> <span>[</span><span>1</span><span>,</span><span>0</span><span>],</span> <span>[</span><span>0</span><span>,</span><span>0</span><span>]])),</span>   <span># middle row</span>
                <span>image</span><span>,</span>
                <span>tf</span><span>.</span><span>pad</span><span>(</span><span>image</span><span>[:,</span> <span>:,</span> <span>1</span><span>:,</span> <span>:],</span>    <span>tf</span><span>.</span><span>constant</span><span>([[</span><span>0</span><span>,</span><span>0</span><span>],</span> <span>[</span><span>0</span><span>,</span><span>0</span><span>],</span> <span>[</span><span>0</span><span>,</span><span>1</span><span>],</span> <span>[</span><span>0</span><span>,</span><span>0</span><span>]])),</span>

                <span>tf</span><span>.</span><span>pad</span><span>(</span><span>image</span><span>[:,</span> <span>1</span><span>:,</span> <span>:</span><span>-</span><span>1</span><span>,</span> <span>:],</span>  <span>tf</span><span>.</span><span>constant</span><span>([[</span><span>0</span><span>,</span><span>0</span><span>],</span> <span>[</span><span>0</span><span>,</span><span>1</span><span>],</span> <span>[</span><span>1</span><span>,</span><span>0</span><span>],</span> <span>[</span><span>0</span><span>,</span><span>0</span><span>]])),</span>    <span># bottom row</span>
                <span>tf</span><span>.</span><span>pad</span><span>(</span><span>image</span><span>[:,</span> <span>1</span><span>:,</span> <span>:,</span> <span>:],</span>    <span>tf</span><span>.</span><span>constant</span><span>([[</span><span>0</span><span>,</span><span>0</span><span>],</span> <span>[</span><span>0</span><span>,</span><span>1</span><span>],</span> <span>[</span><span>0</span><span>,</span><span>0</span><span>],</span> <span>[</span><span>0</span><span>,</span><span>0</span><span>]])),</span>
                <span>tf</span><span>.</span><span>pad</span><span>(</span><span>image</span><span>[:,</span> <span>1</span><span>:,</span> <span>1</span><span>:,</span> <span>:],</span>   <span>tf</span><span>.</span><span>constant</span><span>([[</span><span>0</span><span>,</span><span>0</span><span>],</span> <span>[</span><span>0</span><span>,</span><span>1</span><span>],</span> <span>[</span><span>0</span><span>,</span><span>1</span><span>],</span> <span>[</span><span>0</span><span>,</span><span>0</span><span>]]))</span>
            <span>],</span> <span>axis</span><span>=</span><span>3</span><span>)</span>
        <span>return</span> <span>stack</span>

    <span>def</span> <span>call</span><span>(</span><span>self</span><span>,</span> <span>inputs</span><span>,</span> <span>training</span><span>=</span><span>None</span><span>):</span>
        <span>x</span> <span>=</span> <span>self</span><span>.</span><span>stack3x3</span><span>(</span><span>inputs</span><span>)</span>
        <span>x</span> <span>=</span> <span>tf</span><span>.</span><span>reshape</span><span>(</span><span>x</span><span>,</span> <span>(</span><span>-</span><span>1</span><span>,</span> <span>self</span><span>.</span><span>flat_size</span><span>,</span> <span>self</span><span>.</span><span>channels</span> <span>*</span> <span>tf</span><span>.</span><span>square</span><span>(</span><span>self</span><span>.</span><span>kernel_size</span><span>)))</span>
        <span>q</span> <span>=</span> <span>tf</span><span>.</span><span>square</span><span>(</span><span>self</span><span>.</span><span>q</span><span>)</span> <span>/</span> <span>10</span>
        <span>x_norm</span> <span>=</span> <span>self</span><span>.</span><span>l2_normal</span><span>(</span><span>x</span><span>,</span> <span>axis</span><span>=</span><span>2</span><span>)</span> <span>+</span> <span>q</span>
        <span>w_norm</span> <span>=</span> <span>self</span><span>.</span><span>l2_normal</span><span>(</span><span>self</span><span>.</span><span>w</span><span>,</span> <span>axis</span><span>=</span><span>1</span><span>)</span> <span>+</span> <span>q</span>
        <span>sign</span> <span>=</span> <span>tf</span><span>.</span><span>sign</span><span>(</span><span>tf</span><span>.</span><span>matmul</span><span>(</span><span>x</span><span>,</span> <span>self</span><span>.</span><span>w</span><span>))</span>
        <span>x</span> <span>=</span> <span>tf</span><span>.</span><span>matmul</span><span>(</span><span>x</span> <span>/</span> <span>x_norm</span><span>,</span> <span>self</span><span>.</span><span>w</span> <span>/</span> <span>w_norm</span><span>)</span>
        <span>x</span> <span>=</span> <span>tf</span><span>.</span><span>abs</span><span>(</span><span>x</span><span>)</span> <span>+</span> <span>1e-12</span>
        <span>x</span> <span>=</span> <span>tf</span><span>.</span><span>pow</span><span>(</span><span>x</span><span>,</span> <span>tf</span><span>.</span><span>nn</span><span>.</span><span>softmax</span><span>(</span><span>self</span><span>.</span><span>p</span><span>))</span>
        <span>x</span> <span>=</span> <span>sign</span> <span>*</span> <span>x</span>
        <span>x</span> <span>=</span> <span>tf</span><span>.</span><span>reshape</span><span>(</span><span>x</span><span>,</span> <span>(</span><span>-</span><span>1</span><span>,</span> <span>self</span><span>.</span><span>in_shape</span><span>[</span><span>1</span><span>],</span> <span>self</span><span>.</span><span>in_shape</span><span>[</span><span>2</span><span>],</span> <span>self</span><span>.</span><span>units</span><span>))</span>
        <span>return</span> <span>x</span>
</pre>
    </div></div>
  </body>
</html>
