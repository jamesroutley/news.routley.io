<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.yossarian.net/2022/08/20/Why-dont-we-do-email-verification-in-reverse">Original</a>
    <h1>Why don’t we do email verification in reverse?</h1>
    
    <div id="readability-page-1" class="page">


<h2><em>Programming, philosophy, pedaling.</em></h2>

<ul>
    <li><a href="https://blog.yossarian.net/">Home</a></li>
    <li><a href="https://blog.yossarian.net/tags">Tags</a></li>
    <li><a href="https://blog.yossarian.net/series">Series</a></li>
    <li><a href="https://blog.yossarian.net/favorites">Favorites</a></li>
    <li><a href="https://blog.yossarian.net/archive">Archive</a></li>
    
      <li><a href="https://yossarian.net">Main Site</a></li>
    
</ul>

<hr/>



<h2>
  <p>
    <span><em>Aug 20, 2022</em></span>

       

    
      <span>
        Tags:
        
        
          <a href="https://blog.yossarian.net/tags#programming">programming</a>
        
      </span>
    

       

    
  </p>
</h2>

<hr/>

<p>This is a summary of a random thought I had on the subway.</p>

<p>Just about everybody who has ever used a service on the web has experienced the
following account creation follow:</p>

<ol>
  <li>Click “New account”,</li>
  <li>Enter a username and/or email and password,</li>
  <li>Log in, only to discover that the account is locked or limited pending “email verification.”</li>
</ol>

<p>“Email verification,” in turn, means:</p>

<ol>
  <li>Opening up a new browser tab or clicking on your email client,</li>
  <li>Waiting for an email to appear from the service,</li>
  <li>Finding the right “verification” URL in the email and clicking it,</li>
  <li>Being redirected to a splash page affirming that your email has been
verified, and your account is fully usable.</li>
</ol>

<p>In my experience, just about every step in the second list can fail in user-hostile
ways:</p>

<ul>
  <li>
    <p>I’ve repeatedly dealt with services where the verification email takes minutes to arrive,
is marked as spam, or simply never arrives at all. Sometimes clicking the “resend
email” works and triggers a deluge of <em>N</em> verification emails at once, leaving me
unsure which one to click.</p>

    <p>Depending on the service, clicking on a stale verification link may or may not
work, may or may not be a no-op (with or without an explanatory error), and may or may
flag your account as suspicious (for performing an authenticated action that has been flagged
as stale, due to clicking “resend”).</p>

    <p><strong>Takeaway</strong>: Inbox delivery can be fickle, unreliable, or outright impossible.
When users don’t receive a verification email immediately, <strong>they feel stuck</strong>.</p>
  </li>
  <li>
    <p>Lots of verification emails are HTML formatted, which makes them (generally)
look great in browser- and other HTML-friendly email clients. For example,
here’s how Etsy’s<sup id="fnref:etsy" role="doc-noteref"><a href="#fn:etsy" rel="footnote">1</a></sup> verification email looks in GMail:</p>

    <p><img src="https://blog.yossarian.net/assets/etsy-verification.png" alt="Etsy&#39;s email verification email, in GMail"/></p>

    <p>Not bad at all! It’s <em>very</em> easy to see which link to click for the “happy path.”</p>

    <p>…and here it is in <code>neomutt</code>, which helpfully “renders” the HTML with <code>lynx</code>:</p>

    <p><img src="https://blog.yossarian.net/assets/etsy-verification-neomutt.png" alt="The same verification email, in neomutt"/></p>

    <p>I’m used to visually scanning these emails at this point, so I can pick out the right link
(it’s <code>[2]</code>) and bring it into my browser. But that’s a solution born from practice: the
fact remains that HTML email doesn’t generally degrade gracefully in clients that don’t
support images or CSS.</p>

    <p>Naturally, developers <em>do</em> consider these kinds of edge cases, and frequently include a plaintext
alternative. Etsy’s is very nice:</p>

    <p><img src="https://blog.yossarian.net/assets/etsy-verification-email-plaintext.png" alt="The same verification email, with plaintext instead of HTML"/></p>

    <p>…but not always: I’ve received <em>plenty</em> of verification emails with only HTML components,
leaving me to visually scan the body and pick the right URL out. I can’t count the number
of times I’ve picked the wrong URL or accidentally truncated it.</p>

    <p><strong>Takeaway</strong>: HTML verification emails are pretty and serve the average user well,
but <strong>degrade poorly</strong> and complicate verification for non-paradigmatic users.
Plaintext alternatives are the solution, but <strong>support is spotty</strong>.</p>
  </li>
  <li>
    <p>In general, clicking on the verification link does what I expect: it opens a new tab in
my browser, telling me that I’ve been verified. Sometimes it’s even a splash, showing me
that I’m verified and that my active browser session has been “promoted” to an ordinary
user session.</p>

    <p>But this too has plenty of failure modes:</p>

    <ul>
      <li>
        <p>I often have multiple browser sessions open: one for work, one for personal accounts
or music streaming, &amp;c. When I click the link, my browser<sup id="fnref:chrome" role="doc-noteref"><a href="#fn:chrome" rel="footnote">2</a></sup> chooses the “most recent”
browser session as the link recipient, which is frequently wrong. <em>Sometimes</em> this works (when
the verification link itself contains sufficient state to link the click), but <em>frequently</em> it
doesn’t: the verification barfs when the browser doesn’t have the right cookies for
the account being verified.</p>
      </li>
      <li>
        <p>When I <em>do</em> get the right browser session, all <em>appears</em> peachy: I’m told that I’m
verified, and can go about the ordinary activities of the account I’ve signed up for.</p>

        <p>Except not: I regularly have to log out and back in again, since the browser’s login
session hasn’t been updated to match the verification status. This is admittedly
an <em>extremely</em> small inconvenience, but it’s an inconvenience and unnecessary
failure mode nonetheless.</p>
      </li>
    </ul>

    <p><strong>Takeaway</strong>: The redirection back to the browser is <strong>flimsy</strong>, and <strong>reveals
error states</strong> (such as session mismatches) that shouldn’t be possible.</p>
  </li>
</ul>

<p>All in all, I would describe the “normal” email verification flow as Kafkaesque:
ambiguity and anxiety come in the forms of both time and space; unwritten rules
must be followed and may or may not result in stated outcomes; I am considered a
suspect (“unverified account”) until I have completed obscure and performative rituals.</p>

<p>So, the thought I had: why not do email verification “in reverse”? In other words,
why not have the user <strong>email us</strong>?</p>

<h2 id="reverse-reverse">Reverse, reverse</h2>

<p>Here’s what the ordinary email verification process looks like, as an interaction flow between
a handful of the components and entities involved<sup id="fnref:simplified" role="doc-noteref"><a href="#fn:simplified" rel="footnote">3</a></sup>:</p>

<p><img src="https://blog.yossarian.net/assets/normal-email-verification-flow.png" alt=""/></p>

<p>…and here’s what my proposed flow looks like:</p>

<p><img src="https://blog.yossarian.net/assets/reversed-email-verification-flow.png" alt=""/></p>

<p>Flow diagrams aren’t the most intuitive, so as a plain sequence of steps:</p>

<ol>
  <li>Click “new account”,</li>
  <li>Enter an email,</li>
  <li>Click on the “verify my email” link, which <strong>opens up your email client</strong> with a pre-defined
recipient, subject and body,</li>
  <li>Click “send”,</li>
  <li>Wait for the server to receive and verify it, making your account fully usable.</li>
</ol>

<p>This has, in my eyes, a number of tangible benefits over the “normal” email verification flow:</p>

<ol>
  <li>
    <p><em>The user is more active</em>: instead of waiting to receive an email in their inbox,
the user is immediately presented with an email to send. They can make progress
in the flow themselves, and can sanity-check the state of the verification
by e.g. confirming that the email is in their outbox. Even if the flows take
roughly the same amount of wall time, this activity makes the “reverse” flow <em>feel</em>
faster and more responsive.</p>
  </li>
  <li>
    <p><em>The user has fewer opportunities to make mistakes</em>: Users frequently mis-copy
verification links, or use clients that mangle them, &amp;c. These mistakes can’t
happen in the “reverse” flow, because there’s no verification link to click.
The user only has to remember how to send an email, which is a reasonable expectation
in any scheme where the user is expected to have an email address.</p>
  </li>
  <li>
    <p><em>The user’s mistakes are easier to detect</em>: If a user mis-enters their email
  address in the “normal” flow, they have no easy way to determine whether
  the verification email went to the wrong inbox or is simply delayed.
  The reverse flow can preempt this, by embedding a private, unique ID with each challenge
  email: if a received email has the ID but the wrong address, the web server can warn the user
  that they’ve provided the wrong address (and can display both without leaking information,
  since they’ve demonstrated knowledge of the wrong address and proved ownership
  of the correct one).</p>
  </li>
</ol>

<h2 id="how-does-it-work-securely">How does it work (securely)?</h2>

<p>The “reverse” flow should make intuitive sense: we’re proving that the user controls the
specified email address by challenging them to send us an email from it. This is
in contrast to the normal flow, where our proof involves sending the user an email
and challenging them to click the link contained within it. In both cases, the proof is the same:
“email verification” means “the user controls an email address.”</p>

<p>So: how can we be confident that the reverse flow is <strong>at least as correct and secure</strong>
as the normal flow? We need to impose several constraints.</p>

<h3 id="sending-an-email-is-not-good-enough">Sending an email is not good enough</h3>

<p>Email is <em>notoriously</em> spoofable: relays historically accepted messages from anybody,
with no mechanism for distinguishing authentic senders from spoofed ones.</p>

<p>This is made worse by SMTP’s decoupling of envelope and presentation information
for senders: an SMTP client specifies a return path address at the envelope layer
via with <code>MAIL FROM</code> command, and <em>subsequently</em> specifies one or more presentation
(i.e., email metadata) layer response addresses.</p>

<p>Email providers realized that this wasn’t great, and have adopted three<sup id="fnref:arc" role="doc-noteref"><a href="#fn:arc" rel="footnote">5</a></sup> different
(and separately scoped) standards for ensuring email authenticity:</p>

<ul>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/DomainKeys_Identified_Mail">DKIM</a>
provides <strong>message body authenticity</strong>: the body of the message (including most,
but not all, presentation headers) is cryptographically signed and included in a
separate header.</p>

    <p>Clients can then verify the DKIM signature by reading the header and generating
a subdomain from the <em>domain</em> and <em>selector</em> fields. For example, this DKIM header:</p>

    <div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
</pre></td><td><pre>DKIM-Signature: v=1; a=rsa-sha256; c=relaxed/relaxed;
        d=yossarian.net; s=google;
        h=content-transfer-encoding:content-disposition:mime-version
         :message-id:subject:to:from:date:from:to:cc;
        bh=&lt;A LONG HASH HERE&gt;;
        b=&lt;A LONG SIGNATURE HERE&gt;
</pre></td></tr></tbody></table></code></pre></div>    </div>

    <p>Results in a <code>TXT</code> record lookup to <code>google._domainkey.yossarian.net</code>, yielding
the following (slightly reformatted):</p>

    <div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
5
6
7
8
9
</pre></td><td><pre>v=DKIM1;
k=rsa;
p=MIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEA0nbJGUQvluGxi/
  P2HBPlqbzAqcaHQ2lHqGFsWp6uyX+/I2zADlp65pspYu5+Pn5yHIew4msE
  YRVCzLunYfChWxDBLl5c03myhL91qRlw07jtBb/AA3F32LrILgl/IE2tG2
  qvB8/tp9JFJB38Q6a6xFLvvYw+jqNTD50n4vcy5XHN30TWKaxx5AQxCmoL
  RBAzMAxB6zqWoEPAYjSKrT2pIXwobvJy48C5JqXuDXCMu/7VeV7Gvt/7P6
  CtWYoBbEuwSOl4bmYUQgfr0Q/Jhkjbn5QaJ1iUa6yjQrzFBOd8rzc7zLXG
  RgRiPTxmpyYMJm9tUSthgOrmfWA6D4QpBb//dwIDAQAB
</pre></td></tr></tbody></table></code></pre></div>    </div>

    <p>…which we can then use to verify the <code>b=...</code> signature provided in the header.</p>

    <p>But note! This only authenticates the <em>body</em> of the email, not the envelope.
For that, we’ll need another standard.</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/Sender_Policy_Framework">SPF</a> is the
counterpart to DKIM: where DKIM provides email body authenticity, <strong>SPF provides
email envelope authenticity</strong>.</p>

    <p>SPF’s mode of operation is conceptually similar, using DNS as the fundamental
distribution and authority mechanism<sup id="fnref:dns" role="doc-noteref"><a href="#fn:dns" rel="footnote">7</a></sup>: the email’s <code>Return-Path</code> header
(which is directly copied from the envelope) is parsed for the underlying
domain, which is then queried for an <code>SPF</code> record<sup id="fnref:txt" role="doc-noteref"><a href="#fn:txt" rel="footnote">8</a></sup>. For example,
here’s the one on my domain:</p>

    <div><div><pre><code><table><tbody><tr><td><pre>1
</pre></td><td><pre>v=spf1 include:_spf.google.com ~all
</pre></td></tr></tbody></table></code></pre></div>    </div>

    <p>SPF records describe <em>sender policies</em>, which boil down to rules that
either accept or reject the message based on the sender’s IP address.
Mine is a little indirect; it says to reuse (via the <code>include:</code> directive)
Google’s SPF rules<sup id="fnref:google-spf" role="doc-noteref"><a href="#fn:google-spf" rel="footnote">9</a></sup>, and reject everything else (<code>~all</code>)<sup id="fnref:soft" role="doc-noteref"><a href="#fn:soft" rel="footnote">10</a></sup>.</p>

    <p>We can tunnel into them, and see that they’re recursive:</p>

    <div><div><pre><code><table><tbody><tr><td><pre>1
2
3
4
</pre></td><td><pre><span>$</span><span> </span>dig +short _spf.google.com TXT
<span>&gt;</span><span> </span><span>&#34;v=spf1 include:_netblocks.google.com include:_netblocks2.google.com include:_netblocks3.google.com ~all&#34;</span>
<span>$</span><span> </span>dig +short _netblocks.google.com TXT
<span>&gt;</span><span> </span><span>&#34;v=spf1 ip4:35.190.247.0/24 ip4:64.233.160.0/19 ip4:66.102.0.0/20 ip4:66.249.80.0/20 ip4:72.14.192.0/18 ip4:74.125.0.0/16 ip4:108.177.8.0/21 ip4:173.194.0.0/16 ip4:209.85.128.0/17 ip4:216.58.192.0/19 ip4:216.239.32.0/19 ~all&#34;</span>
</pre></td></tr></tbody></table></code></pre></div>    </div>

    <p>…and so, in effect: if the IP address that sent the email matches one of the
IPs derived from the SPF policy, then the email is accepted. If it doesn’t,
then it’s rejected<sup id="fnref:soft:1" role="doc-noteref"><a href="#fn:soft" rel="footnote">10</a></sup>.</p>

    <p>Another important note: <em>unlike</em> DKIM, SPF is <em>just</em> DNS. There is no
cryptographic authenticity or integrity; just cold, hard DNS records<sup id="fnref:bad" role="doc-noteref"><a href="#fn:bad" rel="footnote">11</a></sup>.</p>
  </li>
  <li>
    <p><a href="https://en.wikipedia.org/wiki/DMARC">DMARC</a> is the odd one out: it’s not
an authentication scheme like DKIM or SPF, but a <em>scheme management scheme</em>
that wraps DKIM and SPF together into a single policy, which
can then be further configured to tell clients <em>how</em> they should verify
a particular domain’s mail.</p>

    <p>DMARC exists because of a historical decision in the design and rollout
of DKIM and SPF: because DKIM and SPF were designed to be retrofitted into
the pre-existing email network, clients default to “failing open” when DKIM
or SPF authenticity information isn’t available.</p>

    <p>In other words: without an additional layer, all an attacker needs to do to
is remove the DKIM or SPF metadata from the email message. No metadata means
that the client assumes no checks, and lets the message through without
complaint.</p>

    <p>DMARC’s solution is <em>yet another</em> round of DNS TXT records, this time
establishing that DKIM and SPF <strong>do</strong> apply to a particular domain, and what
the client should do with the message if either one (or both) fail to pass.
DKIM “fixes” the fail-open behavior by mandating that clients check the DMARC
record (if present), rather than only checking DNS records if the message
itself indicates a need.</p>

    <p>Because nothing in the world of email is consistent, DMARC records use a
<em>third different</em> subdomain scheme for its TXT records:</p>

    <div><div><pre><code><table><tbody><tr><td><pre>1
2
</pre></td><td><pre><span>$</span><span> </span>dig +short _dmarc.google.com TXT
<span>&gt;</span><span> </span><span>&#34;v=DMARC1; p=reject; rua=mailto:mailauth-reports@google.com&#34;</span>
</pre></td></tr></tbody></table></code></pre></div>    </div>
  </li>
</ul>

<p>Put together, these three standards represent the best <strong>commonly deployed</strong>
email authenticity techniques. As such, they’re what we need to use for
our “reverse” flow. Anything else would require users (and email providers)
to make changes to accommodate us, which simply isn’t going to happen.</p>

<p>As for how we’d use them: we need SPF to provide envelope authenticity (i.e.,
ensuring that the IP that sends us an email is authorized to do so by the
domain that it’s claiming to be from), and DKIM to provide message authenticity
(i.e., that the header and body of the email are signed with key specified
by the domain specified in the DKIM header.) Without these, we could not be
confident that (1) the email is coming from the server(s) we expect, and (2)
that the body of the email has not been tampered with by an intermediary.</p>

<p>I don’t <em>think</em> this scheme needs DMARC, since we don’t want the sending
email server to have any control over our enforcement of SPF and DKIM policies:
anything other than perfect SPF and DKIM availability and correctness must
result in a failure.</p>

<h3 id="session-and-uniqueness-considerations">Session and uniqueness considerations</h3>

<p>On top of the (relatively weak) authenticity guarantees that DKIM and SPF provide
provide, this scheme needs a couple of other components:</p>

<ul>
  <li>
    <p><em>A unique token</em>: the <code>mailto:</code> challenge must include a sufficiently
long and random number. This will prevent the user from attempting to manually
initiate the flow without <em>some</em> amount of context on the server side,
and will prevent the (unlikely) error case where two users who both control
an email inbox attempt to register at the same time<sup id="fnref:two-users" role="doc-noteref"><a href="#fn:two-users" rel="footnote">12</a></sup>.</p>
  </li>
  <li>
    <p><em>A timeout</em>: the <code>mailto:</code> challenge should not be indefinitely valid.
The server should expect a response within a reasonable window, like 10
minutes. This will limit the exposure risk of accidentally leaking or
sharing the <code>mailto:</code> challenge<sup id="fnref:not-useful" role="doc-noteref"><a href="#fn:not-useful" rel="footnote">13</a></sup>.</p>
  </li>
</ul>

<h2 id="is-it-a-good-idea">Is it a good idea?</h2>

<p>I have no idea; it just popped into my head. I <em>think</em> it’s more user-friendly,
and I’m pretty sure it’s <em>at least</em> as secure as the “normal” flow:</p>

<ul>
  <li>
    <p>Completing the flow is equivalent to proving that you control an email address,
which is the same as the proof in the “normal” flow.</p>
  </li>
  <li>
    <p>The combination of SPF and DKIM ensure the authenticity of the email’s
envelope and body (respectively), preventing spoofing.</p>
  </li>
  <li>
    <p>The intermediate steps of the flow are not sensitive to a passive attacker:
the <code>mailto:</code> challenge cannot be used or manipulated by an attacker who doesn’t
control the email account.</p>
  </li>
</ul>

<p>I could be convinced that it’s an unacceptable abuse of SPF and relies on a
historically fragile URI scheme (<code>mailto:</code>), but my current perception is that
the use of SPF here is more-or-less appropriate (and consistent with its intended use)
and that the <code>mailto:</code> features required (recipient, subject, and body) are
well-supported by the overwhelming majority of email clients. It’s a shame that
SPF isn’t cryptographically bound in any way but, well, neither is DNS itself
(and you’re certainly relying on that being correct to faithfully deliver your
verification emails).</p>

<p>Some potential limitations and other thoughts:</p>

<ul>
  <li>
    <p>It’s possible that a significant fraction of the Internet is
either self-hosting email servers or is otherwise using providers that don’t
support SPF and DKIM. I’m not aware of any large providers that don’t<sup id="fnref:duopoly" role="doc-noteref"><a href="#fn:duopoly" rel="footnote">14</a></sup>,
but it’s possible and would need to be evaluated.</p>
  </li>
  <li>
    <p>Do websites currently allow verification emails to raw IPs? I would expect
them not to but, if they do, this would be a source of <em>some</em> incompatibility
for the “reverse” flow (since DNS is absolutely required for SPF and DKIM).</p>

    <p>This could be “fixed” with a special case for email addresses on raw IPs,
where the IP in the email address is checked directly against the address that
submits the challenge verification email. But that’s not ideal.</p>
  </li>
  <li>
    <p>As Matthew Green <a href="https://blog.cryptographyengineering.com/2020/11/16/ok-google-please-publish-your-dkim-secret-keys/">has pointed out</a>,
DKIM is not really intended for this (it’s only meant to provide origin authenticity,
not nonrepudiation/nondeniability, much less ownership of a specific identity).
In an ideal world, Google and other email providers would (1) use strong DKIM
keys by default<sup id="fnref:strong-keys" role="doc-noteref"><a href="#fn:strong-keys" rel="footnote">15</a></sup>, and (2) periodically rotate and disclose their
secret keys, ensuring deniability for leaked emails. I <em>think</em> this shouldn’t
pose a risk to the scheme I’ve proposed, since the timescale in question is
minutes and not days (much less weeks or years).</p>
  </li>
  <li>
    <p>Outbound SMTP connections are occasionally blocked on public WiFi, meaning
that users who use non-webmail clients may find it difficult to send the
challenge response email. I’ve only seen this a handful of times and each
had other problems (like blocking SMTP and IMAP entirely), which means
that the “normal” flow was similarly broken.</p>
  </li>
</ul>

<hr/>




<hr/>


<span>
  Discussions:
  
  <a href="https://www.reddit.com/r/enosuchblog/comments/wt2dd9/why_dont_we_do_email_verification_in_reverse/">Reddit</a>
  

  
  <a href="https://twitter.com/8x5clPW2/status/1560912208032403460">Twitter</a>
  
</span>

<hr/>



  






</div>
  </body>
</html>
