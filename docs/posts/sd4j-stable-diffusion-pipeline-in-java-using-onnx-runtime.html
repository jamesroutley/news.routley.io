<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/oracle-samples/sd4j">Original</a>
    <h1>SD4J â€“ Stable Diffusion pipeline in Java using ONNX Runtime</h1>
    
    <div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text">
<p dir="auto">This repo contains an implementation of Stable Diffusion inference running on top of ONNX Runtime,
written in Java. It&#39;s a modified port of the <a href="https://github.com/cassiebreviu/StableDiffusion/">C# implementation</a>,
with a GUI for repeated generations and support for negative text inputs. It is intended to be a
demonstration of how to use ONNX Runtime from Java, and best practices for ONNX Runtime to get good performance.
We will keep it current with the latest releases of ONNX Runtime, with appropriate updates as new performance
related ONNX Runtime features become available through the ONNX Runtime Java API. All the code is subject to change as
this is a code sample, any APIs in it should not be considered stable.</p>
<p dir="auto">This repo targets ONNX Runtime 1.14. The version number is in two parts <code>&lt;sd4j-version&gt;-&lt;onnxruntime-version&gt;</code>, and the
initial release of sd4j is v1.0-1.14.0. We&#39;ll bump the sd4j version number if it gains new features and the ONNX Runtime
version number as we depend on newer versions of ONNX Runtime.</p>
<p dir="auto">The project supports txt2img generation, it doesn&#39;t currently implement img2img, upscaling or inpainting.</p>
<p dir="auto">By default it uses a fp32 model, and running on a 6 core 2019 16&#34; Intel Macbook Pro each diffusion step takes around 5s.
Running on better hardware, or with a CUDA GPU will greatly reduce the time taken to generate an image, as will using an
SD-Turbo model. There is experimental support for the CoreML (for macOS) and DirectML (for Windows) backends, but proper
utilisation of these may require model changes like quantization which is not yet implemented.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-example-images" aria-hidden="true" tabindex="-1" href="#example-images"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Example images</h2>
<p dir="auto">These are a few example images generated by this code along with their generation parameters:</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/oracle-samples/sd4j/blob/main/images/astronaut-horse.png"><img src="https://github.com/oracle-samples/sd4j/raw/main/images/astronaut-horse.png" alt="Generated image from the prompt &#34;Wildlife photograph of an astronaut riding a horse in the desert&#34;" title="Wildlife photograph of an astronaut riding a horse in the desert"/></a></p>
<p dir="auto">Text: &#34;Wildlife photograph of an astronaut riding a horse in the desert&#34;, Negative Text: &#34;&#34;, Seed: 42, Guidance Scale: 10, Inference Steps: 40, Scheduler: Euler Ancestral, Image Size: 512x512.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/oracle-samples/sd4j/blob/main/images/boat-mars.png"><img src="https://github.com/oracle-samples/sd4j/raw/main/images/boat-mars.png" alt="Generated image from the prompt &#34;Press photo of an America&#39;s Cup catamaran sailing through the sands of Mars, high resolution, high quality&#34;" title="Press photo of an America&#39;s Cup catamaran sailing through the sands of Mars"/></a></p>
<p dir="auto">Text: &#34;Press photo of an America&#39;s Cup catamaran sailing through the sands of Mars, high resolution, high quality&#34;, Negative Text: &#34;water, sea, ocean, lake&#34;, Seed: 42, Guidance Scale: 10, Inference Steps: 40, Scheduler: Euler Ancestral, Image Size: 512x512.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/oracle-samples/sd4j/blob/main/images/lunar-lander.png"><img src="https://github.com/oracle-samples/sd4j/raw/main/images/lunar-lander.png" alt="Generated image from the prompt &#34;Professional photograph of the Apollo 11 lunar lander in a field, high quality, 4k&#34;" title="Professional photograph of the Apollo 11 lunar lander in a field, high quality, 4k"/></a></p>
<p dir="auto">Text: &#34;Professional photograph of the Apollo 11 lunar lander in a field, high quality, 4k&#34;, Negative Text: &#34;&#34;, Seed: 42, Guidance Scale: 10, Inference Steps: 50, Scheduler: Euler Ancestral, Image Size: 512x512.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/oracle-samples/sd4j/blob/main/images/washington-steak.png"><img src="https://github.com/oracle-samples/sd4j/raw/main/images/washington-steak.png" alt="Generated image from the prompt &#34;Professional photograph of George Washington in his garden grilling steaks, detailed face, high quality, 4k&#34;" title="Professional photograph of George Washington in his garden grilling steaks, detailed face, high quality, 4k"/></a></p>
<p dir="auto">Text: &#34;Professional photograph of George Washington in his garden grilling steaks, detailed face, high quality, 4k&#34;, Negative Text: &#34;painting, drawing, art&#34;, Seed: 42, Guidance Scale: 10, Inference Steps: 60, Scheduler: Euler Ancestral, Image Size: 512x512.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-model-support" aria-hidden="true" tabindex="-1" href="#model-support"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Model support</h2>
<p dir="auto">The SD4J project supports both SD v1.5 and SD v2 style models, the difference is detected automatically on loading. For
models which do not support classifier-free guidance or negative prompts, such as SD-Turbo, the guidance scale should
be set to a value less than 1.0 which disables that guidance. Models like SD-Turbo can generate acceptable images in as
few as two diffusion steps. Usually the model type is autodetected, but depending on how the model is exported to
ONNX format this detection can fail causing the image generation process to crash. In such cases supplying the
<code>--model-type {SD1.5, SD2}</code> argument with the appropriate parameter will fix the model type.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-installation" aria-hidden="true" tabindex="-1" href="#installation"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Installation</h2>
<p dir="auto">This project requires <a href="https://maven.apache.org" rel="nofollow">Apache Maven</a>, <a href="https://www.oracle.com/java/technologies/downloads/" rel="nofollow">Java 17 or newer</a>,
a compiled ONNX Runtime extensions binary, and a Stable Diffusion model checkpoint.
The other dependencies (ONNX Runtime and Apache Commons Math) are downloaded by Maven automatically.</p>
<h3 tabindex="-1" dir="auto"><a id="user-content-prepare-model-checkpoint" aria-hidden="true" tabindex="-1" href="#prepare-model-checkpoint"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Prepare model checkpoint</h3>
<p dir="auto">There are many compatible models on <a href="https://huggingface.co" rel="nofollow">Hugging Face&#39;s website</a>. We have tested the
Stable Diffusion v1.5 checkpoint, which has pre-built ONNX models. This can be downloaded via
the following <code>git</code> commands (skip the first one if you have already configured <code>git-lfs</code>):</p>
<div dir="auto" data-snippet-clipboard-copy-content="git lfs install
git clone https://huggingface.co/runwayml/stable-diffusion-v1-5 -b onnx"><pre>git lfs install
git clone https://huggingface.co/runwayml/stable-diffusion-v1-5 -b onnx</pre></div>
<p dir="auto">The Stable Diffusion v1.5 checkpoint is available under the <a href="https://github.com/CompVis/stable-diffusion/blob/main/LICENSE">OpenRAIL-M license</a>.
For other models there is a one or two stage process to generate the ONNX format models. If the model is already in
Hugging Face Diffusers format then you can run the <code>convert_stable_diffusion_checkpoint_to_onnx.py</code> file from the
<a href="https://github.com/huggingface/diffusers">diffusers</a> project as follows:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python scripts/convert_stable_diffusion_checkpoint_to_onnx.py --model_path &lt;path-on-disk-or-model-hub-name&gt; --output_path &lt;path-to-onnx-model-folder&gt;"><pre>python scripts/convert_stable_diffusion_checkpoint_to_onnx.py --model_path <span>&lt;</span>path-on-disk-or-model-hub-name<span>&gt;</span> --output_path <span>&lt;</span>path-to-onnx-model-folder<span>&gt;</span></pre></div>
<p dir="auto">If the model is an original stable diffusion checkpoint then you first need to run:</p>
<div dir="auto" data-snippet-clipboard-copy-content="python scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path &lt;path-on-disk-to-checkpoint&gt; --scheduler_type lms --dump_path &lt;path-on-disk-to-diffusers-output&gt;"><pre>python scripts/convert_original_stable_diffusion_to_diffusers.py --checkpoint_path <span>&lt;</span>path-on-disk-to-checkpoint<span>&gt;</span> --scheduler_type lms --dump_path <span>&lt;</span>path-on-disk-to-diffusers-output<span>&gt;</span></pre></div>
<p dir="auto">Both scripts require a suitable Python 3 virtual environment with diffusers and onnx installed.</p>
<h3 tabindex="-1" dir="auto"><a id="user-content-setup-ort-extensions" aria-hidden="true" tabindex="-1" href="#setup-ort-extensions"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Setup ORT extensions</h3>
<p dir="auto">You will also need to check out and compile onnxruntime-extensions for your platform. The repo is <a href="https://github.com/microsoft/onnxruntime-extensions">https://github.com/microsoft/onnxruntime-extensions</a>,
and it can be compiled with <code>./build_lib.sh --config Release --update --build --parallel</code> which generates the required library (<code>libortextensions.[dylib,so]</code> or <code>ortextensions.dll</code>) in the
<code>build/&lt;OS-name&gt;/Release/lib/</code> folder. That library should be copied into the root of this directory.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-running-the-gui" aria-hidden="true" tabindex="-1" href="#running-the-gui"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Running the GUI</h2>
<p dir="auto">The GUI can be executed with <code>mvn package exec:exec -DmodelPath=&lt;path-to-stable-diffusion-model&gt;</code>. It constructs a
window where you can specify the parameters of the image you&#39;d like to generate, and each image creates its own window
where it can save the image as a png file.</p>
<h3 tabindex="-1" dir="auto"><a id="user-content-use-in-other-programs" aria-hidden="true" tabindex="-1" href="#use-in-other-programs"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Use in other programs</h3>
<p dir="auto">The <code>com.oracle.labs.mlrg.sd4j.SD4J</code> class provides a full image generation pipeline which can be used without the GUI
directly from other code.</p>
<h3 tabindex="-1" dir="auto"><a id="user-content-using-a-cuda-gpu" aria-hidden="true" tabindex="-1" href="#using-a-cuda-gpu"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Using a CUDA GPU</h3>
<p dir="auto">To use the GPU you need to modify the pom file to depend on <code>onnxruntime_gpu</code> and swap <code>&lt;argument&gt;CPU&lt;/argument&gt;</code> for
<code>&lt;argument&gt;CUDA&lt;/argument&gt;</code> in the <code>exec-maven-plugin</code> block.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-implementation-details" aria-hidden="true" tabindex="-1" href="#implementation-details"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Implementation details</h2>
<p dir="auto">This code provides a thin <code>Tensor</code> wrapper object which is a tuple of a direct <code>ByteBuffer</code> instance and a long shape
array, which is used to provide easy access in and out of ORT&#39;s <code>OnnxTensor</code> objects. There&#39;s a <code>Scheduler</code> interface
which the two available schedulers (LMS and Euler Ancestral) implement. The <code>SD4J</code> pipeline object is a suitable entry
point for use without the GUI, and there is an example of such usage in the <code>CLIApp</code> class.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-contributing" aria-hidden="true" tabindex="-1" href="#contributing"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Contributing</h2>
<p dir="auto">This project welcomes contributions from the community. Before submitting a pull request, please <a href="https://github.com/oracle-samples/sd4j/blob/main/CONTRIBUTING.md">review our contribution guide</a>.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-security" aria-hidden="true" tabindex="-1" href="#security"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Security</h2>
<p dir="auto">Please consult the <a href="https://github.com/oracle-samples/sd4j/blob/main/SECURITY.md">security guide</a> for our responsible security vulnerability disclosure process</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-license" aria-hidden="true" tabindex="-1" href="#license"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>License</h2>
<p dir="auto">The code is available under the <a href="https://oss.oracle.com/licenses/upl/" rel="nofollow">Universal Permissive License (UPL)</a>. It requires
a Stable Diffusion model architecture checkpoint to work, and any Stable Diffusion models should be used under their
licenses. There are 1000+ compatible models available
on <a href="https://huggingface.co/models?other=stable-diffusion" rel="nofollow">Hugging Face</a> each of which are licensed separately, though many use a variant of
the <a href="https://github.com/CompVis/stable-diffusion/blob/main/LICENSE">OpenRAIL-M license</a>.</p>
<p dir="auto">The <a href="https://github.com/oracle-samples/sd4j/blob/main/text_tokenizer/custom_op_cliptok.onnx">tokenizer onnx model</a> is taken from the
<a href="https://github.com/cassiebreviu/StableDiffusion/">C# implementation</a>, and is available under the MIT license. More
details on the tokenizer are available in its <a href="https://github.com/oracle-samples/sd4j/blob/main/text_tokenizer/README.md">README file</a>.</p>
</article>
          </div></div>
  </body>
</html>
