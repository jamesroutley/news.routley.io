<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://grady.io/post-gpt-computing/">Original</a>
    <h1>Post-GPT Computing</h1>
    
    <div id="readability-page-1" class="page"><article itemscope="" itemtype="http://schema.org/Article"><header><p>March 24, 2023</p></header><section itemprop="articleBody"><p>Yesterday, I watched someone upload a video file to a chat app, ask a language
model “Can you extract the first 5 s of the video?”, and then wait as the
language model wrote a few lines of code <em>and then actually executed that code</em>,
resulting in a downloadable video file. Oh, and writing and executing code is
only one of the many new capabilities that can be seamlessly stitched together
by the language model.</p>
<p>I couldn’t keep working. I had to leave the office and go for a walk. Is
software engineering basically a solved problem now? Did OpenAI just make the
last application? This all sounds hyperbolic and melodramatic when I write it
out, but I’m not the only one who felt something like this. Twitter showed me I
wasn’t alone:</p>
<blockquote data-dnt="true" data-theme="light"><p lang="en" dir="ltr">Guys. Existential crisis. Did OpenAI just finish software? What&#39;s there left to do but clean-up and sweep?</p>— rohit (@krishnanrohit) <a href="https://twitter.com/krishnanrohit/status/1638980086874374145?ref_src=twsrc%5Etfw">March 23, 2023</a></blockquote> 
<p>This is what I had always been working toward. I’ve been working on applying
machine learning to natural language my entire career, since 2013. Natural
language is the most flexible interface we have to other humans, and we should
figure out how to bring that flexiblity to our computer interfaces as well. I
could think of few things so empowering and enriching to humanity as being able
to orchestrate the computers of the world as easily as we can speak and weave
together sentences.</p>
<p>For some reason my reaction to this announcement wasn’t the elation of watching
humanity reach a pinacle accomplishment like it should have been. It was more
like vertigo. Why was that? I thought about it on my walk. Maybe I’m just
jealous that I didn’t help build it? Honestly, I think that is part of it. It’s
pretty damn cool, and I would be super excited if I were on the team building it
(at least if I managed to tune out the part of me that would be freaking out
about the fact that we were connecting an unaligned quasi-AGI to the open
Internet).</p>
<p>I think it’s something more specific than that though. With this announcement,
OpenAI expresses its clear intent for ChatGPT to be the future of computing, not
just an app. They are gunning for the commanding heights of the tech industry,
and they have astounding momentum. Their pace of launches is beyond anything I
have seen. I’m here trying to make my way in this field, trying to find some way
to contribute to its grand story, and then I see that someone is almost at the
finish line, the referee is about to declare a winner, and it will all be over.
Time to go home.</p>
<h2>A new beginning</h2>
<p>Again, this all sounds very melodramatic. And it is. By the time I finished the
walk, I realized this isn’t the end, but a new beginning.</p>
<p>To be clear, it is <em>also</em> an end, or at least the beginning of an end, for a lot
of the present day activities of software engineers. If your work is primarily
to understand the kinds of requirements ChatGPT can understand and connect
together the kinds of APIs ChatGPT can talk to, you really need to think about
whether in 5 years anyone is going to want to use the kinds of things you build,
and if they will, whether paying you whatever you make now will be the best way
to build them.</p>
<p>But it is fundamentally the beginning of a new paradigm in personal computing.
Anything computers can do that we can describe clearly in natural language will
be trivial, and not just to software engineers, but to end users. Even to end
users who struggle to use software today. That is incredible.</p>
<p>I think over time, we’ll see that what many of us really liked about building
software deep down wasn’t coding, but intricately imagining the things computers
could do for us and then getting them to do it. That will continue to involve
optionally writing code, but in this new paradigm, we will be called upon to
focus more and more of our attention and creativity on the problem of <em>deciding
what to build</em>.</p>
<p>This will still mean understanding what <em>can</em> be built, a non-trivial capability
in a world with such rapidly advancing technology. It will also mean
understanding people and what they want more deeply. We need to be able to do
this better than the users themselves can. Before, they needed software and
couldn’t build it themselves, so they had to take what we, collectively as an
industry, gave them, even if it wasn’t quite right. Now, if they can describe
what they want better than we can, they could just tell that to a language model
themselves.</p>
<h2>OpenAI won’t own the whole paradigm</h2>
<p>OpenAI is certainly the first mover in this new paradigm, and I expect them to
keep up their astonishing momentum, but what is making me feel less dread and
more… excitement? opportunity? is that I don’t think they have an
insurmountable monopoly on the whole thing forever. This is another thing that
sounds obvious once you say it, but that I think some people, like myself at the
start of that walk, need to hear.</p>
<p>Here’s why I think this:</p>
<ul>
<li>
<p>I expect a lot of competition on raw language model capabilities. Big tech
companies will compete at the high end, offering drop-in alternative APIs.
Meanwhile, the democratized Stability AI-style approaches will compete from
the bottom. Because of this, I don’t think OpenAI will be able to capture a an
oppressively high fraction of the value, or even raise prices all that much,
in the long run just because they have the best models right now.</p>
</li>
<li>
<p>OpenAI made the extraordinary and IMO under-discussed decision to use an open
API specification format, where every API provider hosts a text file on their
website saying how to use their API. This means even this plugin ecosystem
isn’t a walled garden that only the first mover controls. I don’t fully
understand why they went this way, but I’m grateful they did.</p>
</li>
<li>
<p>Chat is not the only possible interface for this technology. There is a large
design space, and room for many more than one approach.</p>
</li>
</ul>
<p>Taking all of this together, I think there’s going to be a large ecosystem of
new software experiences built by a variety of individuals and teams suited to
different types of users with different goals situated in different
environments. I think it’s even possible to compete with ChatGPT head-to-head on
chat interfaces, though there’s no need to limit ourselves to chat.</p>
<p>Exploring these possibilities going to be the design problem of the decade. I
have some ideas bouncing around my head, and I can’t wait to see what other
people come up with.</p>
<p>I’d love to talk to like minds about this. You can find my contact info on the
<a href="https://grady.io/about">about</a> page, and I also started a Discord server called
<a href="https://discord.gg/QUM64Gey8h">Post-GPT Computing</a> to bring together people
thinking about this new paradigm and how we fit into it.</p></section><hr/></article></div>
  </body>
</html>
