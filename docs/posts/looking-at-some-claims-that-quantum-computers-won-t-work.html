<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://blog.cr.yp.to/20250118-flight.html">Original</a>
    <h1>Looking at some claims that quantum computers won&#39;t work</h1>
    
    <div id="readability-page-1" class="page">

<hr/>
<div>
<p>Older (Access-J): <a href="https://blog.cr.yp.to/20241028-surveillance.html" accesskey="j"><b>2024.10.28: The sins of the 90s:</b></a> <span>Questioning a puzzling claim about mass surveillance. #attackers #governments #corporations #surveillance #cryptowars</span></p>
<details><summary>Table of contents (Access-I for index page)</summary>
<table>
<tbody><tr><td><b>2025.01.18: As expensive as a plane flight:</b> Looking at some claims that quantum computers won&#39;t work. #quantum #energy #variables #errors #rsa #secrecy</td></tr>
<tr><td><a href="https://blog.cr.yp.to/20241028-surveillance.html"><b>2024.10.28: The sins of the 90s:</b></a> <span>Questioning a puzzling claim about mass surveillance. #attackers #governments #corporations #surveillance #cryptowars</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20240803-clang.html"><b>2024.08.03: Clang vs. Clang:</b></a> <span>You&#39;re making Clang angry. You wouldn&#39;t like Clang when it&#39;s angry. #compilers #optimization #bugs #timing #security #codescans</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20240612-bibkeys.html"><b>2024.06.12: Bibliography keys:</b></a> <span>It&#39;s as easy as [1], [2], [3]. #bibliographies #citations #bibtex #votemanipulation #paperwriting</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20240102-hybrid.html"><b>2024.01.02: Double encryption:</b></a> <span>Analyzing the NSA/GCHQ arguments against hybrids. #nsa #quantification #risks #complexity #costs</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20231125-kyber.html"><b>2023.11.25: Another way to botch the security analysis of Kyber-512:</b></a> <span>Responding to a recent blog post. #nist #uncertainty #errorbars #quantification</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20231023-clumping.html"><b>2023.10.23: Reducing &#34;gate&#34; counts for Kyber-512:</b></a> <span>Two algorithm analyses, from first principles, contradicting NIST&#39;s calculation. #xor #popcount #gates #memory #clumping</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20231003-countcorrectly.html"><b>2023.10.03: The inability to count correctly:</b></a> <span>Debunking NIST&#39;s calculation of the Kyber-512 security level. #nist #addition #multiplication #ntru #kyber #fiasco</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20230609-turboboost.html"><b>2023.06.09: Turbo Boost:</b></a> <span>How to perpetuate security problems. #overclocking #performancehype #power #timing #hertzbleed #riskmanagement #environment</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20220805-nsa.html"><b>2022.08.05: NSA, NIST, and post-quantum cryptography:</b></a> <span>Announcing my second lawsuit against the U.S. government. #nsa #nist #des #dsa #dualec #sigintenablingproject #nistpqc #foia</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20220129-plagiarism.html"><b>2022.01.29: Plagiarism as a patent amplifier:</b></a> <span>Understanding the delayed rollout of post-quantum cryptography. #pqcrypto #patents #ntru #lpr #ding #peikert #newhope</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20201206-msword.html"><b>2020.12.06: Optimizing for the wrong metric, part 1: Microsoft Word:</b></a> <span>Review of &#34;An Efficiency Comparison of Document Preparation Systems Used in Academic Research and Development&#34; by Knauff and Nejasmic. #latex #word #efficiency #metrics</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20191024-eddsa.html"><b>2019.10.24: Why EdDSA held up better than ECDSA against Minerva:</b></a> <span>Cryptosystem designers successfully predicting, and protecting against, implementation failures. #ecdsa #eddsa #hnp #lwe #bleichenbacher #bkw</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20190430-vectorize.html"><b>2019.04.30: An introduction to vectorization:</b></a> <span>Understanding one of the most important changes in the high-speed-software ecosystem. #vectorization #sse #avx #avx512 #antivectors</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20171105-infineon.html"><b>2017.11.05: Reconstructing ROCA:</b></a> <span>A case study of how quickly an attack can be developed from a limited disclosure. #infineon #roca #rsa</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20171017-collisions.html"><b>2017.10.17: Quantum algorithms to find collisions:</b></a> <span>Analysis of several algorithms for the collision problem, and for the related multi-target preimage problem. #collision #preimage #pqcrypto</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20170723-random.html"><b>2017.07.23: Fast-key-erasure random-number generators:</b></a> <span>An effort to clean up several messes simultaneously. #rng #forwardsecrecy #urandom #cascade #hmac #rekeying #proofs</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20170719-pqbench.html"><b>2017.07.19: Benchmarking post-quantum cryptography:</b></a> <span>News regarding the SUPERCOP benchmarking system, and more recommendations to NIST. #benchmarking #supercop #nist #pqcrypto</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20161030-pqnist.html"><b>2016.10.30: Some challenges in post-quantum standardization:</b></a> <span>My comments to NIST on the first draft of their call for submissions. #standardization #nist #pqcrypto</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20160607-dueprocess.html"><b>2016.06.07: The death of due process:</b></a> <span>A few notes on technology-fueled normalization of lynch mobs targeting both the accuser and the accused. #ethics #crime #punishment</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20160516-quantum.html"><b>2016.05.16: Security fraud in Europe&#39;s &#34;Quantum Manifesto&#34;:</b></a> <span>How quantum cryptographers are stealing a quarter of a billion Euros from the European Commission. #qkd #quantumcrypto #quantummanifesto</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20160315-jefferson.html"><b>2016.03.15: Thomas Jefferson and Apple versus the FBI:</b></a> <span>Can the government censor how-to books? What if some of the readers are criminals? What if the books can be understood by a computer? An introduction to freedom of speech for software publishers. #censorship #firstamendment #instructions #software #encryption</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20151120-batchattacks.html"><b>2015.11.20: Break a dozen secret keys, get a million more for free:</b></a> <span>Batch attacks are often much more cost-effective than single-target attacks. #batching #economics #keysizes #aes #ecc #rsa #dh #logjam</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20150314-optimizing.html"><b>2015.03.14: The death of optimizing compilers:</b></a> <span>Abstract of my tutorial at ETAPS 2015. #etaps #compilers #cpuevolution #hotspots #optimization #domainspecific #returnofthejedi</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20150218-printing.html"><b>2015.02.18: Follow-You Printing:</b></a> <span>How Equitrac&#39;s marketing department misrepresents and interferes with your work. #equitrac #followyouprinting #dilbert #officespaceprinter</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20140602-saber.html"><b>2014.06.02: The Saber cluster:</b></a> <span>How we built a cluster capable of computing 3000000000000000000000 multiplications per year for just 50000 EUR. #nvidia #linux #howto</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20140517-insns.html"><b>2014.05.17: Some small suggestions for the Intel instruction set:</b></a> <span>Low-cost changes to CPU architecture would make cryptography much safer and much faster. #constanttimecommitment #vmul53 #vcarry #pipelinedocumentation</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20140411-nist.html"><b>2014.04.11: NIST&#39;s cryptographic standardization process:</b></a> <span>The first step towards improvement is to admit previous failures. #standardization #nist #des #dsa #dualec #nsa</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20140323-ecdsa.html"><b>2014.03.23: How to design an elliptic-curve signature system:</b></a> <span>There are many choices of elliptic-curve signature systems. The standard choice, ECDSA, is reasonable if you don&#39;t care about simplicity, speed, and security. #signatures #ecc #elgamal #schnorr #ecdsa #eddsa #ed25519</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20140213-ideal.html"><b>2014.02.13: A subfield-logarithm attack against ideal lattices:</b></a> <span>Computational algebraic number theory tackles lattice-based cryptography.</span></td></tr>
<tr><td><a href="https://blog.cr.yp.to/20140205-entropy.html"><b>2014.02.05: Entropy Attacks!</b></a> <span>The conventional wisdom says that hash outputs can&#39;t be controlled; the conventional wisdom is simply wrong.</span></td></tr>
</tbody></table></details></div><hr/>
<h2>2025.01.18: As expensive as a plane flight: <span>Looking at some claims that quantum computers won&#39;t work. #quantum #energy #variables #errors #rsa #secrecy</span></h2>
<p>Should you be investing time and effort in upgrading to post-quantum cryptography?
You may have encountered the following arguments for minimizing the investment.</p>
<p><strong><a name="costs">The cost-is-high argument.</a></strong>
You&#39;ll be discouraged from taking action to upgrade
if you&#39;re surrounded by people saying how <em>hard</em> this is.
For example:
&#34;Post-quantum cryptography is the biggest cybersecurity transition ever!&#34;
(If you haven&#39;t heard this sort of thing:
here are
<a href="https://fedscoop.com/quantum-crytography-experts-long-transition/">some</a>
<a href="https://cloudsecurityalliance.org/blog/2023/04/03/is-pqc-broken-already-implications-of-the-successful-break-of-a-nist-finalist">random</a>
<a href="https://thequantuminsider.com/2024/08/13/nist-officially-announces-release-of-first-3-finalized-post-quantum-encryption-standards-plus-quantum-community-reaction/">examples</a>.)</p>
<p>People will often make the transition sound complicated
the same way they can make <em>anything</em> sound complicated,
namely by adding layers of bureaucracy.
Here&#39;s how I summarized this in a
<a href="https://cr.yp.to/talks.html#2023.06.15">2023 talk</a>
to the Federal Reserve TechLab:
&#34;We&#39;ll form a committee to devise an action plan to inventory current usage of cryptography
to support future assessment of the steps needed to build a best-practices playbook
for meeting the performance challenges
of upgrading to post-quantum cryptography,
with a target date after I retire.&#34;</p>
<p>You&#39;ll be much more motivated to upgrade
if you instead hear examples of post-quantum crypto already being deployed.
It can&#39;t be <em>that</em> difficult if it&#39;s already working for millions of users.</p>
<p>The popular OpenSSH remote-administration tool rolled out post-quantum crypto
in <a href="https://www.openssh.com/txt/release-9.0">2022</a>.
Google rolled out post-quantum crypto for its
<a href="https://cloud.google.com/blog/products/identity-security/why-google-now-uses-post-quantum-cryptography-for-internal-comms">internal communications</a>
later the same year.
Cloudflare, which hosts a considerable fraction of the Internet&#39;s web sites,
reports that
<a href="https://radar.cloudflare.com/adoption-and-usage#post-quantum-encryption-adoption">33%</a>
of its connections are using post-quantum crypto as of January 2025.</p>
<p>I&#39;ll take a moment here to advertise some of my own work with various collaborators.
If you&#39;re using Linux as a sysadmin or on the desktop,
try our new easy-to-install
<a href="https://www.pqconnect.net">PQConnect</a> tool,
which wraps end-to-end post-quantum cryptography
around unmodified applications.
If you&#39;re a developer,
try out the simple API for
<a href="https://lib.mceliece.org">libmceliece</a>
and
<a href="https://libntruprime.cr.yp.to">libntruprime</a>.</p>
<p><strong><a name="benefits">The benefits-do-not-exist argument.</a></strong>
For the rest of this blog post,
I&#39;ll focus on another way that you could be discouraged from taking action.
The core benefit of upgrading is supposed to be improved security against quantum computers;
but why should you bother putting any effort into that
if you&#39;ve heard that quantum computers simply <em>won&#39;t work</em> for the foreseeable future?</p>
<p>Deployment examples and easy-to-use software packages don&#39;t address this question.
Looking more broadly at the &#34;cybersecurity&#34; landscape
finds many examples of &#34;security&#34; mechanisms
that don&#39;t actually provide security, that often actively damage security,
and that distract us from making real progress.
Why should we think that post-quantum crypto isn&#39;t one of these pseudo-security mechanisms?</p>
<p>Nowadays I often see people dodging this question
by resorting to childish peer pressure:
&#34;All the cool kids are working on post-quantum crypto!
Last kid to join is a loser!&#34;
Or an adult&#39;s form of peer pressure:
&#34;You&#39;ll get money in the following ways for working on post-quantum crypto!&#34;</p>
<p>There are many papers on RC4;
does this mean that we should use RC4?
How about <a href="https://blog.cr.yp.to/20160516-quantum.html">QKD</a>?
As for money,
<a href="https://blog.cr.yp.to/20220805-nsa.html">NSA</a>
paid the RSA company
<a href="https://www.reuters.com/article/us-usa-security-rsa-idUSBRE9BJ1C220131220">$10 million</a>
to deploy
<a href="https://cr.yp.to/papers.html#dual-ec">Dual EC</a>
as the default RNG in RSA&#39;s BSAFE library;
for years this was secret, so it wasn&#39;t damaging the company&#39;s reputation;
does this mean that deploying Dual EC was the right thing to do?</p>
<p>Maybe you&#39;re at a company that&#39;s already doing something about post-quantum cryptography
because of current money flows, regulations, marketing, etc.;
but you&#39;d like to know whether to do more than the bare minimum,
and as part of that you&#39;d like to understand the future risks.
You&#39;re hearing from quite a few sources that quantum computing is just hype and won&#39;t work.
You&#39;d like to know whether that&#39;s true.</p>
<p>What I&#39;ll do here is look at the content of
some arguments that quantum computers <em>won&#39;t</em> break RSA-2048.
In particular, I&#39;ll explain why you should disregard those arguments.</p>
<p><strong><a name="exponential-energy-part-1">Arriving at the exponential-energy argument.</a></strong>
Most of the arguments I&#39;ll look at are recent,
but I want to start with an older example from my own experience,
because this lets me illustrate not just what the argument is
but also the natural thought process that leads to arguments like this.</p>
<p>Let&#39;s rewind to May 1994.
Peter Shor gave an invited talk
&#34;Polynomial time algorithms for discrete logarithms and factoring on a quantum computer&#34;
at the first Algorithmic Number Theory Symposium.</p>
<p>I was one of the grad students attending.
I had already spent a lot of time studying algorithms for integer factorization.
I had already written my first paper on the topic.
I was interested enough that I knew I would be writing
<a href="https://attacks.cr.yp.to">more papers</a> on the topic.
But I couldn&#39;t see a reason to care about attacks using hypothetical computers.</p>
<p>Wait, what about &#34;intercept now, decrypt later&#34; attacks?
Answer:
The reality back then was a much faster attack called
&#34;intercept now, read now, and modify now if you want,
because the data isn&#39;t encrypted or authenticated in the first place&#34;.</p>
<p>Sure, there was <em>some</em> cryptography,
but it was limited by export controls and by patents.
The recurring villains, namely NSA and the RSA company,
were already working together:
they had made a
<a href="https://simson.net/ref/NeXT/nextworld/NextWorld_Extra/92.09.Sept.NWE/92.09.Sept.NWExtra11.html">deal</a>
to promote low-security cryptography.
NSA <a href="https://cr.yp.to/export/dtn/V3N4_10_92.pdf">exempted</a>
512-bit RSA and 40-bit RC4 from export controls.
The RSA company sold 512-bit RSA and 40-bit RC4
for use in various products.
A popular product called Lotus Notes (acquired by IBM in 1995)
was
<a href="https://cypherpunks.venona.com/date/1996/01/msg02136.html">advertised</a>
as &#34;a pioneer in providing transparent strong RSA-based cryptography&#34;
even though its cryptography was overtly
<a href="https://eprint.iacr.org/2015/097">sabotaged</a>.</p>
<p>By the turn of the century,
the situation was different in some important ways.
The DH patent had expired.
The RSA patent had expired.
The U.S. export controls had been declared <a href="https://www.eff.org/deeplinks/2015/04/remembering-case-established-code-speech">unconstitutional</a>.
An RSA-512 challenge from the RSA company had been publicly
<a href="https://link.springer.com/chapter/10.1007/3-540-45539-6_1">factored</a>.</p>
<p>On the other hand,
low-security cryptography was solidly
<a href="https://publish.illinois.edu/science-of-security-lablet/files/2016/08/10062016-Heninger-Slides.pdf">entrenched</a>
in protocols and software.
People kept pointing to the costs of cryptography
as a reason to continue limiting cryptographic security levels
or to use no cryptography at all.</p>
<p>So, okay, I was working on something I could help with,
namely reducing the costs of cryptographic software.
For example, I set new speed records in
<a href="https://cr.yp.to/nistp224.html">2001</a> for ECC using the NSA/NIST P-224 elliptic curve.
(Review of my experience implementing the P-224 curve:
Did not enjoy.
<a href="https://cr.yp.to/papers.html#safecurves">Would not recommend</a>.
Implementing Curve25519 is simpler and less error-prone.)</p>
<p>But, wait, would quantum computers be built?
If so then,
no matter what virtues RSA and ECC had
for addressing the immediate problem of improving cryptographic deployment,
they would be broken by Shor&#39;s algorithm.
What a disaster that would be!</p>
<p>Humans faced with disaster tend to
<a href="https://www.science.org/doi/abs/10.1126/science.2686031">optimistically</a>
imagine ways that the disaster will be avoided.
Given the reality of more and more user data being encrypted with RSA and ECC,
the world will be a better place
if every effort to build a quantum computer
runs into some insurmountable physical obstacle.
Less power for the attackers!
Longer-lasting benefits from the effort we&#39;ve invested in RSA and ECC!</p>
<p>Shor&#39;s paper briefly mentions that
&#34;some proposed analog machines that seem
able to solve NP-complete problems in polynomial time
have required the machining of exponentially precise parts, or an exponential amount of energy&#34;.
Shor&#39;s paper doesn&#39;t state the amount of energy used by Shor&#39;s algorithm.
Aha, that&#39;s the cheat!
The energy for Shor&#39;s algorithm must be exponential in the problem size!</p>
<p><strong><a name="exponential-energy-part-2">Challenging the exponential-energy argument.</a></strong>
Structurally,
this exponential-energy argument
consists of wishful thinking followed by confirmation bias.
This doesn&#39;t meet scientific standards for drawing conclusions.</p>
<p>Scientists are free to formulate <em>questions</em>
such as &#34;Does Shor&#39;s algorithm use more than a polynomial amount of energy?&#34;.
But drawing a <em>conclusion</em> such as &#34;Yes, in fact an exponential amount of energy&#34;
or &#34;No, it uses a polynomial amount of energy&#34;
requires following established procedures
that are designed to catch errors.</p>
<p>If a statement X is false,
are you going to catch the error
by observing that the truth of X will make the world a better place?
Nope.</p>
<p>Are you going to catch the error
by picking evidence that seems to match X,
such as the evidence that you used to formulate X in the first place?
Nope.</p>
<p>So I found myself asking <em>questions</em>
such as how much energy Shor&#39;s algorithm uses,
and studying the literature on quantum computing,
and attending a conference &#34;Models of Quantum Computing&#34; in October 2002.</p>
<p>By the end of 2002,
I had concluded that the literature was describing in detail
how to build a physical machine that
will carry out Shor&#39;s algorithm.
The machine is organized in space as an array of physical data-storage areas
called &#34;quantum bits&#34;, or &#34;qubits&#34;.
The computation is organized in time as a series of &#34;cycles&#34;.
Starting from the machine description and a textbook description of physics,
you can calculate how the qubits evolve in each cycle.
The number of cycles is bounded by a polynomial in the problem size,
the number of qubits is bounded by a polynomial in the problem size,
and each qubit uses a limited amount of energy on each machine cycle,
so the total energy use is also polynomial.
(Side note to the inevitable nitpickers:
assume a <a href="https://www.scottaaronson.com/democritus/lec20.html">cosmological constant compatible with the size of the computation</a>,
for example by plugging in the specific polynomials and problem sizes that matter for cryptography.)
The placement of machine components doesn&#39;t have to be perfect:
if the manufacturing meets particular tolerances
then the algorithm will work.</p>
<p>A
<a href="https://arxiv.org/abs/1905.09749">2019 paper</a>
from Gidney and Ekerå
presents an integrated description of a machine of this type
(plus many improvements after 2002).
Back in 2002,
the material wasn&#39;t as nicely organized in the literature,
but it was there,
showing that the physical costs are bounded by a polynomial in the problem size.</p>
<p>We still had bigger problems with
all the data that was unencrypted, or that was encrypted with low-security cryptography.
But there was a path to addressing those problems,
and then how would we deal with the risk of quantum computers being built?</p>
<p>I still <em>wanted</em> to believe that quantum computing would fail for some reason.
Could there be an error or gap in the calculations in the literature?
I certainly hadn&#39;t checked every detail.
Could the textbook description of physics be missing some effect that would make the machine fail?
Could the necessary manufacturing turn out to be so difficult that it wouldn&#39;t happen for the next 100 years?
Maybe.
But &#34;maybe&#34; isn&#39;t an excuse for a lack of preparation.</p>
<p>I coined the phrase &#34;post-quantum cryptography&#34;
in <a href="https://groups.google.com/g/sci.crypt/c/wy58kUa5J1E/m/kMvr1rIT8vMJ">2003</a>:
&#34;I&#39;m thinking about publishing a paper on post-quantum cryptography. This
isn&#39;t too early to start planning ahead for the very real possibility of quantum computers.&#34;</p>
<p><strong><a name="static">The static-predictions argument.</a></strong>
Let&#39;s now look at more recent arguments that quantum computing won&#39;t work.
I&#39;ll start with
Mikhail Dyakonov&#39;s 2018 article
<a href="https://spectrum.ieee.org/the-case-against-quantum-computing">&#34;The Case Against Quantum Computing&#34;</a>,
with subtitle
&#34;The proposed strategy relies on manipulating with high precision an unimaginably huge number of variables&#34;.
I&#39;ll get back to the subtitle topics below,
but let me first address a non-technical argument given in the article.</p>
<p>The article claims
that &#34;optimistic experts&#34; estimate &#34;5 to 10 years&#34; for useful quantum computers,
that more &#34;cautious ones predict 20 to 30 years&#34;,
and that &#34;similar predictions have been voiced, by the way, for the last 20 years&#34;.
(Note that the word &#34;optimistic&#34; here is treating quantum computers as a <em>good</em> thing.)</p>
<p>The article doesn&#39;t give any references justifying these claims
about what has been predicted.
So I wrote to Dyakonov.
I asked whether there was any verifiable data to back up the &#34;for the last 20 years&#34; statement.
I continued as follows:
&#34;I understand that &#39;voiced&#39; might be referring to off-the-record
conversations, but this isn&#39;t clear from what you write, and it&#39;s
different from the current situation where predictions such as
<a href="https://eprint.iacr.org/2015/1075.pdf">https://eprint.iacr.org/2015/1075.pdf</a>
are on the record from named experts.&#34;
This 2015 reference is to an article by Mosca
saying &#34;I estimate a 1/7 chance of breaking RSA-2048 by 2026 and a 1/2 chance by 2031&#34;.</p>
<p>Dyakonov responded by claiming that one example was a 2002
<a href="https://qist.lanl.gov/pdfs/qc_roadmap.pdf">roadmap</a>
that had been cited in his article.
That roadmap stated an objective of developing
&#34;by 2012 a suite of viable emerging-QC technologies of sufficient complexity to
function as quantum computer-science test-beds in which architectural and algorithmic
issues can be explored&#34;.
The roadmap also stated that this was &#34;a desired outcome, not a prediction&#34;.
So, no, this is explicitly <em>not</em> an example of a timeline prediction.</p>
<p><strong><a name="variables">The number-of-variables argument.</a></strong>
The Dyakonov article then summarizes some basic aspects of quantum mechanics.
In particular, the normal mathematical description
of the state of n qubits
involves 2<sup>n</sup> variables.</p>
<p>For example, for 4 qubits, there are 16 variables: v[0000], v[0001], v[0010], and so on through v[1111].
If you measure the 4 qubits,
you&#39;ll see a string of 4 bits:</p>
<ul>
<li>The string is 0000 with probability |v[0000]|<sup>2</sup>.</li>
<li>The string is 0001 with probability |v[0001]|<sup>2</sup>.</li>
<li>Et cetera.</li>
</ul>
<p>The variables always have these squares adding up to 1,
so the total probability is 1 as you&#39;d expect.</p>
<p>(An equivalent description that I like to use in
<a href="https://cr.yp.to/talks/2019.07.01-1/slides-djb-20190701-1-quantum-a4.pdf">explaining quantum algorithms</a>
allows the sum of squares to be anything nonzero,
and then divides each probability by that sum so that the total probability is again 1.)</p>
<p>The normal mathematical description of the state of 1000 qubits
involves 2<sup>1000</sup> variables.
This number might sound crazy at first,
but makes perfect sense
once you realize that measuring 1000 qubits
might produce any sequence of 1000 bits,
making it natural to ask about the probability of each of the 2<sup>1000</sup> different possible outputs.</p>
<p>The article claims that this somehow doesn&#39;t make sense:
&#34;A useful quantum computer <em>needs to process a set of continuous parameters that is larger than the number of subatomic particles in the observable universe</em>.
At this point in a description of a possible future technology, a hardheaded engineer loses interest&#34;.</p>
<p>But the computer is operating on only 1000 qubits.
The word &#34;process&#34; gives the impression that the computer is tediously manipulating each of the 2<sup>1000</sup> variables;
that&#39;s not true.
Those variables are just components of a way to mathematically describe what&#39;s going on.</p>
<p>Let&#39;s ignore quantum computers for a moment.
Think about software <em>in your laptop</em> that uses randomness to compute a string of 1000 bits.
That&#39;s 128 bytes, a tiny fraction of the storage in your laptop.</p>
<p>There are 2<sup>1000</sup> possibilities for the string of 1000 bits.
Mathematically,
it&#39;s perfectly natural to ask about the probability of each of the 2<sup>1000</sup> different possible strings.
Those probabilities are 2<sup>1000</sup> variables describing what has happened.
If your laptop carries out more computations that modify the string of 1000 bits,
then mathematically there are 2<sup>1000</sup> new variables describing the probabilities for each possibility for the new string.</p>
<p>Does this mean that your laptop is tediously manipulating 2<sup>1000</sup> variables?
No.
Your laptop is manipulating just 1000 bits.</p>
<p>I&#39;m not saying that computation on qubits is the same as computation on random bits.
When you look at the details,
you see that quantum computation allows a useful extra trick,
setting up interference patterns between positive and negative variables.
But an argument saying &#34;quantum computing is impossible
because there are so many variables&#34; can&#39;t be right:
it also says that your laptop is impossible.</p>
<p><strong><a name="errors">The error-correction argument.</a></strong>
Dyakonov&#39;s article goes on to emphasize that physical devices have errors:
&#34;In the physical world,
continuous quantities
(be they voltages or the parameters defining quantum-mechanical wave functions)
can be neither measured nor manipulated <em>exactly</em>. ...
Indeed, all of the assumptions that theorists make about the preparation of qubits into a given state,
the operation of the quantum gates, the reliability of the measurements, and so forth, cannot be fulfilled <em>exactly</em>.
They can only be approached with some limited precision.
So, the real question is: What precision is required? With what exactitude must, say, the square root of 2
(an irrational number that enters into many of the relevant quantum operations) be experimentally realized?
Should it be approximated as 1.41 or as 1.41421356237?
Or is even more precision needed?
There are no clear answers to these crucial questions.&#34;</p>
<p>On 23 November 2018,
the date that I wrote to Dyakonov,
the paragraph ended even more strongly:
&#34;Amazingly, not only are there no clear answers to these crucial questions, but they were never even discussed!&#34;</p>
<p>In fact,
the literature already contained extensive discussion of these crucial questions.
For example,
the
<a href="https://arxiv.org/abs/0803.0272">surface code</a>,
an example of &#34;quantum error correction&#34;,
is a specific way to combine many physical qubits into a much more reliable &#34;logical&#34; qubit.
There are
<a href="https://arxiv.org/abs/1301.7107">detailed tables</a>
quantifying the error rate of the logical qubit,
depending on the error rate of the physical qubits and the number of physical qubits used.</p>
<p>Surface codes work well if each physical operation has an error rate below 0.1%.
Somewhat higher error rates than 0.1% can also work,
although then the surface code needs more physical qubits for the same level of reliability of the logical qubit.
Everything disintegrates for physical error rates around 1% or above:
for such high error rates, the surface code is useless.
In the opposite direction, lower physical error rates than 0.1%
make the surface code more efficient.</p>
<p>Dyakonov edited his article on 30 November 2018,
publicly noting that &#34;some readers pointed out to the author instances in the literature that had considered these issues&#34;.
But the claim that there are &#34;no clear answers&#34; to the precision question
is contradicted by the same papers.
In short: 1.414 is fine.</p>
<p>Most papers on quantum algorithms don&#39;t consider error correction:
they assume reliable operations on logical qubits.
The quantum-computer engineer is responsible for providing those operations.
As an analogy,
programmers writing software for your laptop
aren&#39;t thinking about transistors and electrical signals.
The software assumes reliable operations on bits;
the computer engineer is responsible for providing those operations.</p>
<p>This layering doesn&#39;t mean that errors are being ignored.
It means that the task of error correction is being modularized.
One layer handles error correction,
so that higher layers can validly assume error-free operation.</p>
<p><strong><a name="moon">Interlude: landing on the Moon.</a></strong>
Imagine someone 70 years ago writing the following:
&#34;You think you can land on the Moon? Bollocks!
All of your landings so far have been on Earth,
and extrapolating the heights says it&#39;ll take you thousands of years to get to the Moon.&#34;</p>
<p>For the engineers at that point working on actually getting something to land on the Moon,
the obvious first question is whether there&#39;s enough power to propel something that far from Earth,
and the obvious second question is whether there&#39;s enough control to target the Moon.
You can&#39;t succeed unless you have enough power <em>and</em> enough control.</p>
<p>Luna 2 had enough power and enough control to crash-land on the Moon in 1959.
Apollo 11, with more control, landed humans safely on the Moon in 1969.</p>
<p>If you look at a graph of landing heights as a function of time,
then you&#39;ll see Earth for many years but then suddenly (surprise!) a Moon landing.
Before the Moon landing occurs, the graph is flat,
making it useless for extrapolating the relevant technology development.</p>
<p>In other words:
If you think there&#39;s some insurmountable obstacle to a Moon landing,
and you&#39;re wrong about that,
will you catch the error by looking at a graph of landing heights before the Moon landing occurs?
Nope.</p>
<p>It makes much more sense to look at a graph measuring the available power,
and a graph measuring control.
Those graphs let you see intermediate steps in technology development.</p>
<p><strong><a name="rsa">The RSA-bits argument.</a></strong>
Peter Gutmann posted slides
<a href="https://www.cs.auckland.ac.nz/~pgut001/pubs/bollocks.pdf">&#34;Why quantum cryptanalysis is bollocks&#34;</a>
in 2024.
I think it&#39;s fair to summarize what the slides say about quantum computers as follows:
&#34;You think you can use a quantum computer to break RSA-2048? Bollocks!
All of your quantum factorizations so far have been tiny,
and extrapolating the sizes says it&#39;ll take you thousands of years to get to RSA-2048.&#34;</p>
<p>For the engineers working on actually building a machine to break RSA-2048 with Shor&#39;s algorithm,
the obvious first question is whether there are enough physical qubits to run the algorithm,
and the obvious second question is whether the qubits are reliable enough.
You can&#39;t succeed unless you have enough qubits <em>and</em> enough reliability.</p>
<p>There&#39;s actually a
<a href="https://sam-jaques.appspot.com/quantum_landscape_2024">tradeoff curve</a>
between the number of qubits and the error rate of each qubit,
for reasons noted in the above discussion of the surface code.
For example, you can break RSA-2048
using millions of physical qubits each with a 0.01% error rate,
or using tens of millions of physical qubits each with a 0.1% error rate.</p>
<p>Breaking RSA-2048 isn&#39;t exactly analogous to the Moon landing.
There&#39;s a mini-Moon, RSA-1024,
that&#39;s somewhat closer than RSA-2048.
Current knowledge says that
discrete logarithms on the NSA/NIST B-163 curve are even closer.
A side advantage of using discrete logarithms as the first public demo
is that the standard type of discrete-logarithm challenge,
with both inputs generated as hashes,
doesn&#39;t allow the same sort of cheating that factorization challenges do.
Maybe the RSA company didn&#39;t erase the secret factors of their RSA-2048 challenge.
Maybe the factors were stolen from them.</p>
<p>Anyway, the basic point about how to measure technological development
is the same as for the Moon landing.
A model of steady progress in the number of qubits and in the reliability of qubits
implies that the graph of quantum factorizations
will look like RSA-tiny, RSA-tiny, RSA-tiny, RSA-tiny, etc., and then suddenly RSA-1024, and soon after that RSA-2048.
The initial period of useless demos
is completely explained by the well-understood prerequisites for quantum error correction:
we need a large enough collection of physical qubits with low enough error rates.</p>
<p>Gutmann&#39;s RSA-bits argument is in the context of an understandable complaint
about resources being taken away from stopping &#34;the actual attacks that are happening&#34;.
Certainly there are many other security problems to address.
We&#39;d <em>like</em> to believe that quantum computing is impossible and can simply be ignored.
But this is just wishful thinking again;
it isn&#39;t evidence.
The only part of Gutmann&#39;s slides that actually addresses quantum computing
is the RSA-bits argument.</p>
<p><strong><a name="ecc">Interlude: how non-quantum error correction works.</a></strong>
Let&#39;s look at how your laptop sends data through Wi-Fi.
Programmers talk about sending a &#34;packet&#34; of data,
a string of bits, typically several thousand bits at once.
What your laptop is actually sending through the air
is a physical representation of those bits as radio waves.</p>
<p>The receiver doesn&#39;t receive exactly the same radio waves.
There&#39;s noise getting in the way.
Maybe bit 0, sent as wave 0, ends up being received as wave 0.01.
That&#39;s okay: the receiver interprets that as bit 0.</p>
<p>Sometimes there&#39;s a bigger error.
Maybe bit 0, sent as wave 0, ends up being received as wave 0.8,
which the receiver interprets as bit 1.
Oops.</p>
<p>Here&#39;s the first solution that you might come up with.
The sender repeats each bit three times.
Normally the receiver sees 000, meaning 0,
or 111, meaning 1.
If the receiver sees another pattern of three bits, it takes a majority vote of those three bits.
For example,
maybe 000 has the first bit flipped in transit to produce 100;
the receiver will take a majority vote of 100 to recover 0.</p>
<p>What if the moment of noise stretches out slightly longer,
flipping 000 to 110?
Let&#39;s not put the repeated bits right next to each other.
Instead let&#39;s take a packet with bits ABCDEFG
(for example, 0101111)
and send ABCDEFGABCDEFGABCDEFG
(for example, 010111101011110101111).
The receiver will take majority votes of the AAA bits, the BBB bits, etc.</p>
<p>Now a brief burst of noise isn&#39;t a problem.
Could something else spoil the received data?</p>
<p>One answer would be a higher level of ongoing noise,
producing such frequent errors
that sometimes two errors happen to be at the right distance to spoil the majority votes.
Maybe we should repeat each bit 5 times instead of 3 times,
although that still won&#39;t be enough if the noise level is too high.
Maybe we should work on reducing the noise level:
move closer to the Wi-Fi router, for example.</p>
<p>Another answer would be noise that isn&#39;t so frequent
but that happens to be synchronized with the error-correction details.
A burst of radio noise could physically reverberate
at the right frequency to spoil two of the AAA bits,
or three of the AAAAA bits if we&#39;re repeating each bit 5 times.</p>
<p>There are fancier mathematical techniques for error correction.
For example,
using a &#34;binary Goppa code&#34;,
you can communicate 6528 bits as 8192 bits
in a way that&#39;s guaranteed to be able to correct any pattern of 128 or fewer errors.
The <a href="https://cr.yp.to/papers.html#goppadecoding">error-correction mechanism</a>
is more complicated than majority votes, but it isn&#39;t particularly expensive.</p>
<p>Now suppose someone claims that,
no matter what you do to send data and correct errors,
there will be noise sources that pay attention to what you did
and generate enough noise to block communication.</p>
<p>A demo of successful communication immediately debunks this claim.
But let&#39;s say it&#39;s early days and you haven&#39;t built a demo yet.
Does that make the claim plausible?
Wouldn&#39;t you expect an explanation of <em>how</em> the universe
is supposed to be generating enough noise to block communication?</p>
<p><strong><a name="sync">The error-synchronization argument.</a></strong>
Let&#39;s now look at
Gil Kalai&#39;s slides
<a href="https://www.math.ucdavis.edu/~deloera/TEACHING/VIDEOS/Kalai-Lectures/hkD.pdf">&#34;Why quantum computers cannot work&#34;</a>
from 2013.</p>
<p>The slides give the following supposed
&#34;explanation for why (fault-tolerant) quantum
computers cannot be built:
Quantum systems based on special-purpose quantum devices are
subject to noise which systematically depends on the quantum
evolution of the system; this dependence reflects dependence of
the noise on the quantum device, and the dependence of the
quantum device on the quantum evolution it is performing. Here,
&#39;a quantum device&#39; refers both to human-made and to natural
devices. This systematic dependence causes error-rate for
general-purpose quantum computers to scale up.&#34;</p>
<p>Sounds like a machine running Shor&#39;s algorithm
will have its results swamped by errors.
But, wait, the literature includes detailed calculations
saying what the machine is doing at each moment,
including calculations of how errors produced by noise will be corrected.
Which step in the calculation is Kalai claiming to be wrong?</p>
<p>The closest that I find to an answer
is Kalai conjecturing that quantum error correction will never work.
For example:
&#34;Conjecture 1: (No quantum error-correction): In every
implementation of quantum error-correcting codes with one
encoded qubit, the probability of not getting the intended qubit is
at least some δ &gt; 0, independently of the number of qubits used
for encoding.&#34;
As another example:
&#34;Conjecture 4: Error synchronization:
In any noisy quantum computer in a highly entangled state there
will be a strong effect of error synchronization.&#34;</p>
<p>Let&#39;s think about this.
Kalai is arguing that
noise &#34;systematically depends on the quantum evolution of the system&#34;,
producing synchronized errors that will break error correction.
Why is this not also an argument that radio noise depends on how you encode data to send through Wi-Fi,
producing synchronized errors that will break error correction?</p>
<p>The answer has to be in the word &#34;quantum&#34;.
There has to be some explanation of how the universe
is supposed to produce synchronized errors that inevitably break quantum error correction without breaking non-quantum error correction.
But I&#39;ve looked high and low and don&#39;t see where Kalai is giving any such explanation.
The following sentence sounds to me like he&#39;s admitting that he doesn&#39;t have an explanation:
&#34;The mathematical challenge is to understand the systematic laws for this dependence.&#34;</p>
<p>There&#39;s nothing wrong with <em>asking</em> whether
some unforeseen or inadequately analyzed physical effect
could sabotage quantum error correction.
Unless and until there are public attack demos,
I&#39;ll continue to hope that quantum computing will fail.
But, again, wishful thinking is not evidence.</p>
<p>Google announced experiments in
<a href="https://arxiv.org/abs/2408.13687v1">August 2024</a>
where a surface code produced a logical qubit
measurably more reliable than any of the underlying physical qubits.
This doesn&#39;t quite contradict Kalai&#39;s Conjecture 1 yet:
maybe the unspecified cutoff &#34;δ&#34; in the conjecture is below Google&#39;s current error rate,
while still being large enough to spoil any big quantum computation.
But this wiggle room in the conjecture
is just another reflection of the fact that the conjecture never had an explanation in the first place.</p>
<p><strong><a name="visibility">Visibility arguments.</a></strong>
The last essay I&#39;ll look at
isn&#39;t actually arguing that quantum computers are impossible.
Instead it&#39;s arguing that you can relax since you&#39;ll see quantum computers coming.</p>
<p>This is a 2023 essay
<a href="https://www.lawfaremedia.org/article/when-a-quantum-computer-is-able-to-break-our-encryption-it-won-t-be-a-secret">&#34;When a quantum computer is able to break our encryption, it won&#39;t be a secret&#34;</a>
by Edward Parker.
The subtitle is
&#34;Quantum computers may eventually have devastating impacts on cybersecurity—but we’ll probably see the threat coming in time to set up counters.&#34;
This is telling you that (&#34;probably&#34;) you don&#39;t have to act yet:
you can wait for the signals of &#34;the threat coming&#34;,
and <em>then</em> you can take action.</p>
<p>This can&#39;t be right if you&#39;re encrypting data that needs to stay confidential for a long time,
longer than the visibility of the threat:
you&#39;re abandoning the data to &#34;intercept now, decrypt later&#34; attacks,
which are mentioned later in the essay.
But let&#39;s assume that your concerns are with shorter-term confidentiality or with integrity,
and that you&#39;re not worried about being able to upgrade rapidly enough.
I&#39;ll focus on how the essay argues that quantum attacks won&#39;t be a secret.</p>
<p><strong><a name="secrecy">The secrecy-is-hard argument.</a></strong>
The essay points to an early leak of a draft of a paper from
<a href="https://www.nature.com/articles/s41586-019-1666-5">77 authors</a>
with Google&#39;s first claim of &#34;quantum supremacy&#34;.
The essay concludes that it is
&#34;very difficult to keep groundbreaking progress in quantum computing secret&#34;.</p>
<p>But it is a mistake to conflate an early leak of <em>public</em> work
with leaks of <em>classified</em> work.
In the United States,
a single disclosure of classified cryptographic information is punishable not just by being fired
but also by <a href="https://www.law.cornell.edu/uscode/text/18/798">10 years in prison</a>.
This threat doesn&#39;t even matter for government agents who seriously believe that
<a href="https://mathbabe.org/2012/08/25/nsa-mathematicians/">&#34;everything the United States Government does is good&#34;</a>:
they <em>want</em> to stay quiet so that their attacks are more successful!</p>
<p>There are procedures for eventually declassifying information
that the government can no longer justify keeping secret.
This information is often
<a href="https://nsarchive2.gwu.edu/NSAEBB/NSAEBB441/">surprising</a>.
Sometimes it hits
<a href="https://www.nytimes.com/2014/10/12/us/transcripts-kept-secret-for-60-years-bolster-defense-of-oppenheimers-loyalty.html?unlocked_article_code=1.p04.b_t8.bwI5p-q6anhI&amp;smid=url-share">major news sites</a>,
despite being many years out of date.
So there&#39;s ample evidence of the government often managing to keep secrets,
even big secrets.
Presumably the information that&#39;s still kept secret
would be even more surprising.</p>
<p>Sure,
whistleblowers sometimes remove government secrecy,
as illustrated by Snowden&#39;s exposure of all sorts of misbehavior by NSA;
I&#39;ll mention some specific Snowden documents below.
But do these whistleblowers expose such a large fraction of government secrets
that we can reasonably expect some whistleblower to promptly leak the existence of NSA&#39;s quantum attacks?
I&#39;m skeptical.
More to the point,
the essay I&#39;m commenting on doesn&#39;t make a case for this,
nor does it explain why we should expect public visibility into any of the other big attackers.</p>
<p><strong><a name="funding">The we&#39;re-well-funded argument.</a></strong>
The essay points to more than a billion dollars publicly invested in quantum computing
by <a href="https://www.rand.org/pubs/research_reports/RRA869-1.html">2021</a>,
and concludes that staying ahead of this would &#34;need enormous financial resources&#34;.</p>
<p>Is a billion dollars supposed to be a lot of money?
NSA&#39;s <em>yearly</em> budget
was about <a href="https://irp.fas.org/commission/budget.htm">$3.6 billion</a>
thirty years ago,
and about <a href="https://www.zdnet.com/article/new-leaked-documents-detail-secret-u-s-intelligence-black-budget-figures/">$10 billion</a>
fifteen years ago,
out of a $50 billion &#34;black budget&#34;,
never mind the rest of the U.S. military-industrial complex.</p>
<p>Today the total U.S. military budget is approaching a trillion dollars per year.
It&#39;s easy to imagine a secret case being made
for investing tens of billions of dollars per year in building quantum computers.
So why exactly shouldn&#39;t that happen?</p>
<p>Let&#39;s rewind to 2012,
when public investment in quantum computing was much smaller than it is today.
I gave a
<a href="https://cr.yp.to/talks.html#2012.09.24">talk</a>
listing $2.2 million for defense contractor Raytheon as
&#34;one of many publicly announced quantum-computing grants from government agencies&#34;.
There was already more money than that being invested secretly in quantum attacks,
for example in an $80 million NSA program &#34;Penetrating Hard Targets&#34;,
as shown at the beginning of 2014 by
<a href="https://www.washingtonpost.com/world/national-security/nsa-seeks-to-build-quantum-computer-that-could-crack-most-types-of-encryption/2014/01/02/8fff297e-7195-11e3-8def-a33011492df2_story.html">news stories</a>
based on the Snowden documents.
Shouldn&#39;t we expect that the secret investment has expanded since then?</p>
<p>My median estimate is that attackers are 3 years ahead of the public in building quantum computers.
I wouldn&#39;t be surprised by 1 year, or by 5 years.
There are big uncertainties in models of (1) how much the attackers are spending
and (2) how much influence that investment has upon technology development.</p>
<p>Meanwhile what the essay is claiming is that
&#34;When a quantum computer is able to break our encryption, it won&#39;t be a secret&#34;.
We&#39;re supposed to believe that attackers aren&#39;t ahead of the public <em>at all</em>?
NSA has wasted all of the money it has spent on quantum attacks?</p>
<p>The essay later has a related argument that
&#34;commercial applications of quantum computing will very likely become technically feasible before decryption does&#34;,
meaning that an attack organization
&#34;would face an enormous economic incentive to use its quantum computer for commercial applications rather than for intelligence collection&#34;.</p>
<p>No, that&#39;s not how attack organizations work.
Sure, NSA has a long history of
<a href="https://historicalarchives.europarl.europa.eu/files/live/sites/historicalarchive/files/03_PUBLICATIONS/03_European-Parliament/01_Documents/the-echelon-affair-en.pdf">industrial</a>
<a href="https://www.reuters.com/article/world/snowden-says-nsa-engages-in-industrial-espionage-tv-idUSBREA0P0DE/">espionage</a>;
this doesn&#39;t mean that NSA&#39;s goal is to make money.
NSA&#39;s mission is
<a href="https://www.archives.gov/federal-register/codification/executive-order/12333.html">&#34;signals intelligence&#34;</a>.
Taking NSA&#39;s precious quantum computers and using them for something other than attacks
would slow down NSA&#39;s signals intelligence,
while risking disclosure of NSA&#39;s
<a href="https://www.nytimes.com/2013/09/06/us/nsa-foils-much-internet-encryption.html?unlocked_article_code=1.p04.rieo.H3hOK3xQ7uAf&amp;smid=url-share">highly classified</a>
attack capabilities.</p>
<p><strong><a name="hubris">The we&#39;re-the-best argument.</a></strong>
The essay continues as follows:
&#34;Any organization attempting to secretly develop a CRQC would need to
acquire world-class talent—and if many of the greatest technical experts
suddenly left their organizations or stopped publishing in the technical
literature, then that fact would immediately be fairly evident, just as it was during the Manhattan Project.&#34;</p>
<p>The words &#34;as it was&#34; are linking to a
<a href="https://windowsontheory.org/2023/08/16/reflections-on-making-the-atomic-bomb/">book review</a>.
If you check the book review then you see that it actually says almost exactly the opposite:
&#34;The project was secret to the public but public to the US&#39; adversaries.&#34;
If the analogy holds up between that project and quantum attacks,
then various large-scale attackers
will deduce that the other large-scale attackers are also carrying out quantum attacks,
but <em>we</em> won&#39;t know that this is happening.</p>
<p>More importantly,
there&#39;s a glaring flaw in the analogy.
The Manhattan Project was a wartime project that suddenly started in 1942
and that ended up dropping bombs in 1945.
NSA&#39;s quantum-attack project isn&#39;t a sudden wartime project:
we know, thanks to Snowden, that it was already underway more than a decade ago.</p>
<p>Don Coppersmith,
a <a href="https://rwc.iacr.org/LevchinPrize/winners.html#DonCoppersmith">prize-winning</a>
cryptanalyst whose many public contributions
include an important early <a href="https://arxiv.org/abs/quant-ph/0201067">modification</a>
of Shor&#39;s algorithm,
stopped publishing attacks more than twenty years ago—because he moved from IBM to IDA,
an FFRDC controlled by NSA.
You&#39;d think that an essay talking about attackers hiring world-class talent
would mention this.</p>
<p>The essay shows no signs of tracking what has actually happened on this topic.
If &#34;stopped publishing&#34; is supposed to be a signal that everyone will see,
why does the essay talk about it as some potential future danger signal?
The danger signal was already triggered decades ago.</p>
<p><strong><a name="flight">The flight argument.</a></strong>
Finally,
the essay says that a quantum computer
&#34;might be physically difficult to hide&#34;.
The essay notes that estimating the required physical resources is difficult,
but says that the essay author&#39;s &#34;recent research suggests that a CRQC might plausibly draw 125 megawatts of electrical power&#34;.</p>
<p>I checked the cited
<a href="https://arxiv.org/abs/2304.14344">paper</a>.
The paper estimates about 6 watts per physical qubit.
The paper multiplies this by numbers from the aforementioned
<a href="https://arxiv.org/abs/1905.09749">2019 paper</a>
by Gidney and Ekerå,
namely 20 million physical qubits for 8 hours to factor RSA-2048.
Yup, 6 watts per qubit times 20 million qubits is around 125 megawatts.</p>
<p>The paper continues by saying that this is
&#34;about the power consumption of a Boeing 747 aircraft in flight&#34;.</p>
<p>The paper doesn&#39;t give a citation here,
but I guess the calculation is as follows:
a Boeing 747 uses
<a href="https://web.archive.org/web/20190511080231/https://pubdocs.worldbank.org/en/777021436899472389/Air-Transport-Air-Cargo-AD.pdf">4 liters of fuel per second</a>;
a liter of fuel has about 30 megajoules of energy.
As a sanity check,
a single
<a href="https://www.geaerospace.com/commercial/aircraft-engines/cf6">CF6-50</a>
turbine, with a diameter of 105 inches and a length of 183 inches,
is rated for over 50 megawatts,
and a Boeing 747 has four of those,
so there&#39;s no evident obstacle to producing 125 megawatts.</p>
<p>Sounds like, assuming the 6-watt estimate per qubit,
this RSA-2048 attack will consume as much energy as an 8-hour flight of a Boeing 747.
How does the essay get from this to the idea that the attack won&#39;t be carried out in secret?</p>
<p><strong><a name="further">Further reading.</a></strong>
Another analysis of quantum-computing-won&#39;t-work arguments
is a recent
<a href="https://scottaaronson.blog/?p=8329">talk</a>
by Scott Aaronson
on &#34;the main reasons why people regarded this as not entirely real&#34;:
namely,
&#34;it sounded too good to be true&#34;,
&#34;the general thesis of technological stagnation&#34;,
&#34;eternally just over the horizon&#34;,
&#34;doubts about quantum mechanics itself&#34;,
and &#34;correlated noise that kills QC&#34;.
I&#39;m saying more about some of those topics
(and covering some further topics)
but skipping others.</p><hr/><SPAN size="1"><b>Version:</b>
This is version 2025.01.18 of the 20250118-flight.html web page.
</SPAN>

</div>
  </body>
</html>
