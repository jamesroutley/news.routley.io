<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://benhouston3d.com/blog/why-i-left-kubernetes-for-google-cloud-run">Original</a>
    <h1>I Didn&#39;t Need Kubernetes, and You Probably Don&#39;t Either</h1>
    
    <div id="readability-page-1" class="page"><div><p>Kubernetes often represents the ultimate solution for container orchestration, but my experience has led me to leave it behind in favor of a simpler, cost-effective solution using <a href="https://cloud.google.com/run">Google Cloud Run</a>. This transition has made my infrastructure projects easier to manage, more scalable, and significantly cheaper. Here’s why I made this choice and how Cloud Run offers a better fit for my needs going forward.</p>
<h2>How I ended up on Kubernetes</h2>
<p>First, let&#39;s quickly look at how we ended up on Kubernetes. We has launched <a href="https://clara.io">Clara.io (now sunset)</a>, an online 3D editor and rendering platform, in 2013. We cost optimized the platform by using bare metal machines from <a href="https://www.ovhcloud.com/">OVH</a> for both its primary servers, DBs and job workers. While it worked, bare metal machines were a source of potential failures and we did have some over the years. Luckily we had a redundant setup so our users never noticed. But it was a massive amount of work to provision, monitor and maintain.</p>
<p>So when we looked to remake the platform for <a href="https://threekit.com">Threekit.com</a>, an enterprise focused re-imaging of Clara.io, we looked to switch to a managed compute setup. At the time in 2018, Kubernetes was just emerging as the industry solution as Azure, AWS and Docker converged on it in late 2017.</p>
<h2>Why I Left Kubernetes</h2>
<p>At first, Kubernetes seemed like the right approach for managing services at scale. But as we lived with it over the years since 2018, it became apparent that the complexity and costs were significant. Here’s a breakdown of the challenges we encountered:</p>
<ol>
<li>
<p><strong>Cost Overruns</strong>: Kubernetes comes with substantial infrastructure costs that go beyond DevOps and management time. The high cost arises from needing to provision a bare-bones cluster with redundant management nodes. Moreover, Kubernetes’s slow autoscaling meant I had to over-provision services to ensure availability, paying for unused resources rather than scaling based on demand.</p>
</li>
<li>
<p><strong>Difficulty Managing Large Job Volumes</strong>: Handling a high volume of jobs on Kubernetes is tedious. Both the built-in scheduler and Argo introduced limitations and complexity, often failing to scale well under load or just being really complex.</p>
</li>
<li>
<p><strong>Complexity Overload</strong>: Kubernetes is feature-rich, yet these “enterprise” capabilities turned even simple tasks into protracted processes. The result was added complexity without substantial benefits, making it more of an obstacle than a solution. If you have Kubernetes, you probably need at least one dedicated Kubernetes dev-ops engineer, if not a couple.</p>
</li>
</ol>
<p>Overall, Kubernetes proved difficult to provision, expensive to maintain, and time-consuming to manage. For companies or individual projects seeking simplicity and cost-effectiveness, it may not be the right choice. But it did get rid of the need for us to keep track of whether the hardware in our machines was breaking down and our manual provision processing.</p>
<h2>Embracing Cloud Run for a Simpler Setup</h2>
<p>Google Cloud Run offers a streamlined alternative to Kubernetes. Here’s how my new setup works:</p>
<h3>The Setup</h3>
<p>My infrastructure is now centered around <strong>Docker containers</strong>, with some running as auto-scaling services and others as tasks for long-running jobs. Google Cloud Run handles container deployment, scaling, downtime management, and running/retrying jobs eliminating many of the challenges I faced with Kubernetes.</p>
<h3>Why Cloud Run Is Ideal</h3>
<ol>
<li><strong>Cost Efficiency</strong>: Cloud Run charges only for the CPU and memory used during requests, making it highly cost-effective. For example, this personal project of mine, <a href="https://web3dsurvey.com">Web3D Survey</a> sees 500,000 hits monthly and costs just <strong>$4/month</strong> for hosting, even though it is running all the time. They key is that Cloud Run charges based on the fraction of the CPU you use per second. The ability to scale to zero also means no charges for idle services.</li>
<li><strong>Fast, Reliable Autoscaling</strong>: Cloud Run scales in a few seconds, unlike Kubernetes, where scaling often took minutes. This quick scaling lets me handle surges reliably without over-provisioning.</li>
<li><strong>No Kubernetes Management Overhead</strong>: Cloud Run, built atop Google’s Borg, avoids the need for Kubernetes cluster management, simplifying deployments and cutting costs.</li>
<li><strong>Simple Async Tasks</strong>: Cloud Run Tasks allows me to execute up to 10,000 tasks per job, track their results with auto-retries with no need to manage job-running infrastructure or individual machines — a refreshing alternative to the complexity running this on Kubernetes was.</li>
</ol>
<h2>The Kubernetes Lock-In Trap</h2>
<p>One overlooked downside of Kubernetes is <strong>cluster lock-in</strong>. Once you start using Kubernetes-specific features, it becomes challenging to leverage resources outside the cluster. Integrating services across data centers or using dedicated resources in a colocation setup adds significant complexity. Kubernetes demands you stay within its ecosystem, effectively binding you to the infrastructure that supports it, making even simple expansions or migrations into costly, complex endeavors.</p>
<h2>Addressing Common Concerns</h2>
<p>Several questions arose from others when I shared my experience online, so here’s a deeper look into how this setup works:</p>
<ul>
<li><strong>Orchestration</strong>: I use GitHub Actions CI to handle CI/CD, leveraging workflows with dependencies and matrix strategies for builds across multiple services which only deploy if all tests/builds are successful.</li>
<li><strong>Storage</strong>: Managed databases or Cloud Storage cover shared data needs, eliminating the need to manage my own disks.</li>
<li><strong>Inter-Service Communication</strong>: For async communication, I leverage pub-sub messaging. When direct connections are absolutely necessary, each service has a dedicated domain-name.</li>
<li><strong>Security</strong>: Cloud Run supports internal-only services, and for public services, I secure routes using JWT.</li>
</ul>
<h2>Debunking Misconceptions</h2>
<h3>“Aren’t You Afraid of Being Locked into GCP?”</h3>
<p>Switching cloud providers, such as AWS, wouldn’t be overly complex since my setup is Docker-based, and migration would take about a week. In practice, few companies switch providers unless politics are involved, as the differences between major cloud services are minimal.</p>
<h3>“Cloud Run Is Just Managed Kubernetes, Right?”</h3>
<p>While Cloud Run uses Knative interfaces, it’s not a Kubernetes PaaS. Cloud Run runs on Google’s Borg, avoiding Kubernetes cluster overhead and allowing for simpler, cost-effective deployments. Even if it was based on Kubernetes underneath it hides the completely complexities, and cost of Kubernetes.</p>
<h2>Remaining Workflow Pains</h2>
<p>There are some pains I have with my current Cloud Run development workflow:</p>
<h3>Arbitrary Management of Services Names</h3>
<p>I do find that I need to manage my service names both locally and in the server in a unified way with clear configuration. Basically an abstraction layer. I know Kubernetes has one and I do miss that.</p>
<h3>Lack of Cloud Run Task Emulation</h3>
<p>There is no solution for running Cloud Run Tasks locally that I have found. I would like it to be able to just run an arbitrary command line locally in place of a docker container in a locally emulated Cloud Run Tasks environment that captures log output, trackings runs, etc. This would simplify development of tasks without having to build and deploy docker containers.</p>
<h2>My New Stack and Workflow</h2>
<p>My infrastructure is built around a reliable stack. You can view a simplistic prototype setup and practices in this <a href="https://github.com/bhouston/template-typescript-monorepo">TypeScript monorepo template</a>. Cloud Run enables me to deploy this stack efficiently, without the complexity or cost overheads Kubernetes brought.</p>
<h2>Final Thoughts</h2>
<p>For my projects, Cloud Run offers the perfect blend of <strong>cost savings, speed, scalability, and simplicity</strong>. While Kubernetes may suit some large enterprises, for agile projects where simplicity and efficiency matter, the managed environment of Cloud Run is transformative. If your infrastructure goals include reduced DevOps overhead, predictable costs, and responsive scaling, Cloud Run may be the solution you’ve been looking for.</p>
<p>(PS. Yes, I am sure there was another library/extension I should have added to Kubernetes to enable feature X, Y or Z, but this really is just further increasing the complexity. I don&#39;t want to have to exist inside of world of Kubernetes-specific lingo and techniques if they are not giving me benefits.)</p>
<p><em>This post was inspired by <a href="https://news.ycombinator.com/item?id=42041917">this discussion on Hacker News on 04/11/2025</a></em></p></div></div>
  </body>
</html>
