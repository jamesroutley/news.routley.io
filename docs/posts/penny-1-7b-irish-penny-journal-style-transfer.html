<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://huggingface.co/dleemiller/Penny-1.7B">Original</a>
    <h1>Show HN: Penny-1.7B Irish Penny Journal style transfer</h1>
    
    <div id="readability-page-1" class="page"><div>
	<!-- HTML_TAG_START -->
<p>This is a <strong>style transfer</strong> from the Irish Penny Journal (1840) to Smollm2 using GRPO. For example, this response to &#34;What is the capital of France&#34;</p>
<pre><code>Verily, in the grand tapestry of European monarchies, the city of Paris, the seat of the mighty Emperor Napoleon, holds a place of singular distinction. This city, which hath borne the name of &#39;La Ville Lumière&#39; for nigh on two centuries, doth shine forth as a beacon of art, culture, and intellect, its very existence a testament to the ingenuity and brilliance of its people. And so, it is with great honour and reverence that we declare Paris, the majestic capital of the French realm, to be our noble question&#39;s answer.
</code></pre>
<p><strong>Penny‑1.7B</strong> is a 1.7 billion‑parameter causal language model fine‑tuned with <strong>Group Relative Policy Optimization (GRPO)</strong> to emulate the 19ᵗʰ‑century prose of the <em>Irish Penny Journal</em> (1840). The RL stage ran for <strong>6,800 policy steps</strong>, using a reward model trained to classify sentences as <em>original IPJ</em> vs <em>modern translation</em>. Maximizing this score nudges generations toward authentic Victorian‑era diction while retaining the general reasoning ability of the base SmolLM2 model.</p>
<h2>
	<a rel="nofollow" href="#✨-key-facts" id="✨-key-facts">
		
	</a>
	<span>
		✨ Key Facts
	</span>
</h2>
<div>
	<table>
		<thead><tr>
<th></th>
<th></th>
</tr>

		</thead><tbody><tr>
<td><strong>Base model</strong></td>
<td><a rel="nofollow" href="https://huggingface.co/HuggingFaceTB/SmolLM2-1.7B-Instruct">SmolLM2‑1.7B-Instruct</a></td>
</tr>
<tr>
<td><strong>Tuning method</strong></td>
<td>GRPO (RL)</td>
</tr>
<tr>
<td><strong>Policy steps</strong></td>
<td>6,800</td>
</tr>
<tr>
<td><strong>Reward model</strong></td>
<td>MiniLM2 L6 384H classifier</td>
</tr>
<tr>
<td><strong>Optimiser</strong></td>
<td>AdamW 8‑bit · lr 5 × 10^⁻6</td>
</tr>
<tr>
<td><strong>Hardware</strong></td>
<td>1× RTX A6000 (48 GB) · bf16</td>
</tr>
</tbody>
	</table>
</div>
<h2>
	<a rel="nofollow" href="#🔬-training--data" id="🔬-training--data">
		
	</a>
	<span>
		🔬 Training &amp; Data
	</span>
</h2>
<ul>
<li><p><strong>Corpora</strong></p>
<ul>
<li><em>Irish Penny Journal</em> 1840 (dleemiller/irish_penny_journal)</li>
<li>Modernized translations produced via rule‑based spelling normalisation plus manual post‑edit</li>
</ul>
</li>
<li><p><strong>Reward</strong> = classifier output</p>
</li>
</ul>
<h2>
	<a rel="nofollow" href="#➡️-intended-uses" id="➡️-intended-uses">
		
	</a>
	<span>
		➡️ Intended Uses
	</span>
</h2>
<ul>
<li>Creative writing, educational content, or stylistic pastiche in Victorian‑era Irish English.</li>
<li>Research on RL‑based style transfer.</li>
</ul>
<p><strong>Not recommended for:</strong> contemporary fact Q&amp;A or contexts where archaic language could mislead readers.</p>
<h2>
	<a rel="nofollow" href="#⚠️-limitations--biases" id="⚠️-limitations--biases">
		
	</a>
	<span>
		⚠️ Limitations &amp; Biases
	</span>
</h2>
<p>19ᵗʰ‑century texts can contain outdated social views. Outputs may reflect such biases or archaic spelling. Always review generations before use.</p>
<h2>
	<a rel="nofollow" href="#💻-quick-start" id="💻-quick-start">
		
	</a>
	<span>
		💻 Quick Start
	</span>
</h2>
<pre><code><span>from</span> transformers <span>import</span> AutoModelForCausalLM, AutoTokenizer

checkpoint = <span>&#34;dleemiller/Penny-1.7B&#34;</span>

device = <span>&#34;cuda&#34;</span>  

tokenizer = AutoTokenizer.from_pretrained(checkpoint)

model = AutoModelForCausalLM.from_pretrained(checkpoint).to(device)

messages = [{<span>&#34;role&#34;</span>: <span>&#34;user&#34;</span>, <span>&#34;content&#34;</span>: <span>&#34;What is the capital of France.&#34;</span>}]
input_text = tokenizer.apply_chat_template(messages, tokenize=<span>False</span>)
inputs = tokenizer.encode(input_text, return_tensors=<span>&#34;pt&#34;</span>).to(device)

outputs = model.generate(inputs,
                         max_new_tokens=<span>512</span>,
                         temperature=<span>0.8</span>,
                         top_p=<span>0.9</span>,
                         do_sample=<span>True</span>)

<span>print</span>(tokenizer.decode(outputs[<span>0</span>]))
</code></pre>
<h2>
	<a rel="nofollow" href="#📝-citation" id="📝-citation">
		
	</a>
	<span>
		📝 Citation
	</span>
</h2>
<pre><code>@software{penny_1.7b_2025,
  title        = {Penny‑1.7B: Irish Penny Journal Style Language Model},
  author       = {Lee Miller},
  year         = 2025,
  publisher    = {Hugging Face},
  url          = {https://huggingface.co/dleemiller/Penny-1.7B}
}
</code></pre>
<h2>
	<a rel="nofollow" href="#📜-license" id="📜-license">
		
	</a>
	<span>
		📜 License
	</span>
</h2>
<p>Apache 2.0 (inherits from the base model).</p>
<!-- HTML_TAG_END --></div></div>
  </body>
</html>
