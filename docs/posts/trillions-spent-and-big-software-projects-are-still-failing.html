<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://spectrum.ieee.org/it-management-software-failures">Original</a>
    <h1>Trillions spent and big software projects are still failing</h1>
    
    <div id="readability-page-1" class="page"><div data-headline="How IT Managers Fail Software Projects"><div><p><strong>“Why worry about something</strong> that isn’t going to happen?”</p><p>KGB Chairman Charkov’s question to inorganic chemist Valery Legasov in <a href="https://www.hbo.com/chernobyl" rel="noopener noreferrer" target="_blank">HBO’s “Chernobyl” miniseries</a> makes a good epitaph for the hundreds of <a href="https://spectrum.ieee.org/tag/software-development">software development</a>, <a href="https://spectrum.ieee.org/tag/modernization">modernization</a>, and operational failures I have covered for <em><em>IEEE Spectrum</em></em> since <a href="https://spectrum.ieee.org/why-software-fails" target="_self">my first contribution</a>, to its <a href="https://spectrum.ieee.org/learning-from-software-failure" target="_self">September 2005 special issue</a> on learning—or rather, not learning—from software failures. I noted then, and it’s still true two decades later: Software failures are universally unbiased. They happen in every country, to large companies and small. They happen in commercial, nonprofit, and governmental organizations, regardless of status or reputation.</p><p>Global IT spending has more than tripled in constant 2025 dollars since 2005, from US $1.7 trillion to $5.6 trillion, and continues to rise. Despite additional spending, software success rates have not markedly improved in the past two decades. The result is that the business and societal costs of failure continue to grow as software proliferates, permeating and interconnecting every aspect of our lives.</p><p>For those hoping AI software tools and coding copilots will quickly make large-scale IT software projects successful, forget about it. For the foreseeable future, there are hard limits on what AI can bring to the table in controlling and managing the myriad intersections and trade-offs among <a href="https://spectrum.ieee.org/tag/systems-engineering">systems engineering</a>, project, financial, and business management, and especially the organizational politics involved in any large-scale software project. Few <a href="https://spectrum.ieee.org/tag/it-projects">IT projects</a> are displays of rational decision-making from which AI can or should learn. As software practitioners know, IT projects suffer from enough management hallucinations and delusions without AI adding to them.</p><div id="rebelltitem28" data-id="28" data-reload-ads="false" data-is-image="False" data-href="https://spectrum.ieee.org/it-management-software-failures/particle-28" data-basename="particle-28" data-post-id="2674305315" data-published-at="1763499646" data-use-pagination="False"><p>As I noted 20 years ago, the <a href="https://spectrum.ieee.org/why-software-fails" target="_self">drivers of software failure</a> frequently are failures of human imagination, unrealistic or unarticulated project goals, the inability to handle the project’s complexity, or unmanaged risks, to name a few that today still regularly cause <a href="https://spectrum.ieee.org/tag/it-failures">IT failures</a>. <a href="https://www.forbes.com/sites/steveandriole/2021/03/25/3-main-reasons-why-big-technology-projects-fail---why-many-companies-should-just-never-do-them/" rel="noopener noreferrer" target="_blank">Numerous others</a> go back decades, such as those identified by Stephen Andriole, the chair of business technology at <a href="https://en.wikipedia.org/wiki/Villanova_University" rel="noopener noreferrer" target="_blank">Villanova University</a>’s School of Business, in the diagram below first published in <a href="https://www.forbes.com/sites/steveandriole/2021/03/25/3-main-reasons-why-big-technology-projects-fail---why-many-companies-should-just-never-do-them/" rel="noopener noreferrer" target="_blank"><em>Forbes</em></a> in 2021. Uncovering a software system failure that has gone off the rails in a unique, previously undocumented manner would be surprising because the overwhelming majority of software-related failures involve avoidable, known failure-inducing factors documented in hundreds of after-action reports, academic studies, and technical and management books for decades. Failure déjà vu dominates the literature.</p><p>The question is, why haven’t we applied what we have repeatedly been forced to learn?</p></div><p><img id="88b4c" data-rm-shortcode-id="26a5d130e236ab0a0adc3d6de48b9c7f" data-rm-shortcode-name="rebelmouse-image" lazy-loadable="true" src="data:image/svg+xml,%3Csvg%20xmlns=&#39;http://www.w3.org/2000/svg&#39;%20viewBox=&#39;0%200%207202%203780&#39;%3E%3C/svg%3E" data-runner-src="https://spectrum.ieee.org/media-library/diagram-showing-causes-of-technology-project-failures-definition-scope-management-culture-etc.png?id=62207045&amp;width=980" width="7202" height="3780" alt="Diagram showing causes of technology project failures: definition, scope, management, culture, etc."/><small>Steve Andriole</small></p><div id="rebelltitem22" data-id="22" data-reload-ads="false" data-is-image="False" data-href="https://spectrum.ieee.org/it-management-software-failures/particle-22" data-basename="particle-22" data-post-id="2674305315" data-published-at="1763498559" data-use-pagination="False"><h2>The Phoenix That Never Rose</h2><p>Many of the<a href="https://spectrum.ieee.org/lessons-from-a-decade-of-it-failures/read-more" target="_self"> IT developments and operational failures</a> I have analyzed over the last 20 years have each had their own Chernobyl-like meltdowns, spreading reputational <a href="https://spectrum.ieee.org/tag/radiation">radiation</a> everywhere and contaminating the lives of those affected<a href="https://spectrum.ieee.org/five-enduring-government-it-failures" target="_self"> for years</a>. Each typically has a story that<a href="https://spectrum.ieee.org/uk-rural-payment-agency-program-called-test-case-in-maladministration" target="_self"> strains belief</a>. A prime example is the Canadian government’s CA $310 million <a href="https://spectrum.ieee.org/canadian-governments-phoenix-pay-system-an-incomprehensible-failure" target="_self">Phoenix payroll system</a>, which went live in April 2016 and soon after went supercritical.</p><p>Phoenix project executives believed they could<a href="https://www.oag-bvg.gc.ca/internet/English/parl_oag_201711_01_e_42666.html" target="_blank"> deliver a modernized payment system</a>, customizing PeopleSoft’s off-the-shelf <a href="https://spectrum.ieee.org/tag/payroll">payroll</a> package to follow 80,000 pay rules spanning 105 collective agreements with federal public-service unions. It also was attempting to implement 34 human-resource system interfaces across 101 government agencies and departments required for sharing employee data. Further, the government’s developer team thought they could accomplish this for less than<a href="https://publications.gc.ca/collections/collection_2018/parl/xc16-1/XC16-1-1-421-53-eng.pdf" rel="noopener noreferrer" target="_blank"> 60 percent</a> of the vendor’s proposed budget. They’d save by removing or deferring critical payroll functions, reducing system and integration testing, decreasing the number of contractors and government staff working on the project, and forgoing vital pilot testing, along with a <a href="https://www.oag-bvg.gc.ca/internet/English/parl_oag_201805_01_e_43033.html" rel="noopener noreferrer" target="_blank">host of other overly optimistic proposals</a>.</p></div><div id="rebelltitem5" data-id="5" data-reload-ads="false" data-is-image="False" data-href="https://spectrum.ieee.org/it-management-software-failures/particle-5" data-basename="particle-5" data-post-id="2674305315" data-published-at="1763498559" data-use-pagination="False"><p>Phoenix’s payroll meltdown was preordained. As a result, over the past nine years, around 70 percent of the 430,000 current and former Canadian federal government employees paid through Phoenix have endured paycheck errors. Even as recently as fiscal year 2023–2024, a third of all employees <a href="https://ottawacitizen.com/public-service/phoenix-pay-errors" target="_blank">experienced paycheck mistakes</a>. The ongoing financial stress and anxieties for thousands of employees and their families have been immeasurable. Not only are recurring paycheck troubles <a href="https://www.hcamag.com/ca/specialization/employment-law/ottawa-settles-phoenix-pay-system-class-action-lawsuit/516289" target="_blank">sapping worker morale</a>, but in at least one documented case, a <a href="https://ottawacitizen.com/news/local-news/coroner-blames-phoenix-pay-troubles-in-public-servants-suicide" target="_blank">coroner blamed</a> an employee’s suicide on the unbearable financial and emotional strain she suffered.</p><p>By the end of March 2025, when the <a href="https://vernonmatters.ca/2024/07/09/ottawa-looking-to-clear-problem-backlog-by-march-2025-before-axing-phoenix/" target="_blank">Canadian government had promised</a> that the backlog of Phoenix errors would finally be cleared, over <a href="https://www.tpsgc-pwgsc.gc.ca/remuneration-compensation/services-paye-pay-services/centre-presse-media-centre/mise-a-jour-update-eng.html" rel="noopener noreferrer" target="_blank">349,000 were still </a>unresolved, with 53 percent pending for more than a year. In June, the <a href="https://spectrum.ieee.org/tag/canadian-government">Canadian government</a> once again<a href="https://www.canada.ca/en/public-services-procurement/services/pay-pension/pay-administration/integrated-strategy-human-resources-pay.html" rel="noopener noreferrer" target="_blank"> committed</a> to significantly reducing the backlog, this time by June 2026. Given previous promises, skepticism is warranted.</p></div><p>The question is, why haven’t we applied what we have repeatedly been forced to learn?</p><p>What percentage of software projects fail, and <a href="https://ieeexplore.ieee.org/document/868706" rel="noopener noreferrer" target="_blank">what failure means</a>, has been an ongoing debate within the IT community <a href="https://www.scrummanager.com/files/nato1968e.pdf" rel="noopener noreferrer" target="_blank">stretching back decades</a>. Without diving into the debate, it’s clear that software development remains one of the riskiest technological endeavors to undertake. Indeed, according to <a href="https://www.sbs.ox.ac.uk/about-us/people/bent-flyvbjerg" rel="noopener noreferrer" target="_blank">Bent Flyvbjerg</a>, professor emeritus at the University of Oxford’s Saїd Business School, comprehensive data shows that not only are IT projects risky, they are <a href="https://papers.ssrn.com/sol3/papers.cfm?abstract_id=5247223" rel="noopener noreferrer" target="_blank"><em><em>the</em></em> riskiest</a> from a cost perspective.</p><div id="rebelltitem9" data-id="9" data-reload-ads="false" data-is-image="False" data-href="https://spectrum.ieee.org/it-management-software-failures/particle-9" data-basename="particle-9" data-post-id="2674305315" data-published-at="1763498559" data-use-pagination="False"><p><span>The </span><a href="https://www.it-cisq.org/wp-content/uploads/sites/6/2022/11/CPSQ-Report-Nov-22-2.pdf" target="_blank">CISQ report</a> estimates that organizations in the United States spend more than $520 billion annually supporting legacy software systems, with 70 to 75 percent of organizational IT budgets devoted to legacy maintenance. A<a href="https://services.global.ntt/en-us/newsroom/80-percent-of-organizations-agree-that-inadequate-or-outdated-technology-is-holding-back-innovation" target="_blank"> 2024 report</a> by services company <a href="https://www.nttdata.com/global/en/" target="_blank">NTT DATA</a> found that 80 percent of organizations concede that “inadequate or outdated technology is holding back organizational progress and innovation efforts.” Furthermore, the report says that virtually all C-level executives believe legacy infrastructure thwarts their ability to respond to the market. Even so, given that the cost of replacing legacy systems is typically many multiples of the cost of supporting them, business executives <a href="https://spectrum.ieee.org/inside-hidden-world-legacy-it-systems" target="_self">hesitate to replace them</a> until it is no longer operationally feasible or cost-effective. The other reason is a <a href="https://spectrum.ieee.org/lessons-from-a-decade-of-it-failures/lesson-4" target="_self">well-founded fear</a> that replacing them will turn into a <a href="https://spectrum.ieee.org/tag/debacle">debacle</a> like Phoenix or<a href="https://www.stripes.com/veterans/2025-07-15/veterans-technology-medical-records-18443763.html#:~:text=VA%20leaders%20delivered%20that%20message,according%20to%20the%20federal%20watchdog." target="_blank"> others</a><span>.</span></p><p>Nevertheless, there have been ongoing attempts to improve software development and sustainment processes. For example, we have seen increasing adoption of iterative and incremental strategies to develop and sustain software systems through <a href="https://aws.amazon.com/compare/the-difference-between-agile-devops/" target="_blank">Agile approaches, DevOps methods</a>, and other related practices.</p></div><div id="rebelltitem11" data-id="11" data-reload-ads="false" data-is-image="False" data-href="https://spectrum.ieee.org/it-management-software-failures/particle-11" data-basename="particle-11" data-post-id="2674305315" data-published-at="1763498559" data-use-pagination="False"><p>The goal is to deliver usable, dependable, and affordable software to end users in the shortest feasible time. <a href="https://spectrum.ieee.org/tag/devops">DevOps</a> strives to accomplish this continuously throughout the entire software life cycle. While <a href="https://www.smartsheet.com/content/agile-project-management-examples?srsltid=AfmBOooBlS_5SsIPzh-qOihGw1aTGItPHuhq8XMXWdcrAFVIxBQqrNos" target="_blank">Agile</a> and <a href="https://medium.com/@maeydhaw/case-study-how-netflix-became-a-master-of-devops-7f6f6fa8ad86" target="_blank">DevOps</a> have proved successful for many organizations, they also have their share of controversy and pushback. Provocative reports claim Agile projects have a <a href="https://www.engprax.com/post/268-higher-failure-rates-for-agile-software-projects-study-finds/" target="_blank">failure rate of up to 65 percent</a>, while others claim up to <a href="https://thenewstack.io/most-devops-plans-fail-but-things-are-getting-better/#:~:text=According%20to%20data%20from%20analyst,today&#39;s%20DevOps%20struggles%20and%20challenges." target="_blank">90 percent of DevOps initiatives fail to meet organizational expectations</a>.</p><p>It is best to be wary of these claims while also acknowledging that successfully implementing Agile or DevOps methods takes consistent leadership, organizational discipline, patience, investment in training, and culture change. However, the same requirements have always been true when introducing any new software platform. Given the historic lack of organizational resolve to instill proven practices, it is not surprising that novel approaches for developing and sustaining ever more complex software systems, no matter how effective they may be, will also frequently fall short.</p><h2>Persisting in Foolish Errors<br/></h2><p>The frustrating and perpetual question is why basic IT project-management and governance mistakes during software development and operations continue to occur so often, given the near-total societal reliance on reliable software and an extensively documented history of failures to learn from? Next to electrical infrastructure, with which IT is increasingly merging into a mutually codependent relationship, the failure of our computing systems is an existential threat to modern society.</p><p>Frustratingly, the IT community <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=7842842" target="_blank">stubbornly fails to learn</a> from prior failures. <a href="https://spectrum.ieee.org/tag/it-project">IT project</a> managers <a href="https://hbr.org/2025/03/the-uniqueness-trap" rel="noopener noreferrer" target="_blank">routinely claim</a> that their project is somehow different or unique and, thus, lessons from previous failures are irrelevant. That is the excuse of the arrogant, though usually not the ignorant. In Phoenix’s case, for example, it was the government’s <a href="https://ottawacitizen.com/news/local-news/bagnall-there-were-lessons-that-might-have-prevented-the-phoenix-pay-disaster-no-one-listened" rel="noopener noreferrer" target="_blank">second payroll-system replacement attempt</a>, the first effort ending in failure in 1995. Phoenix project managers ignored the well-documented reasons for the first failure because they claimed its lessons were not applicable, which did nothing to keep the managers from repeating them. As it’s been said, we learn more from failure than from success, but repeated failures are damn expensive.</p></div><div id="rebelltitem13" data-id="13" data-reload-ads="false" data-is-image="False" data-href="https://spectrum.ieee.org/it-management-software-failures/particle-13" data-basename="particle-13" data-post-id="2674305315" data-published-at="1763498559" data-use-pagination="False"><p>Not all software development failures are bad; some failures are even desired. When pushing the limits of developing new types of software products, technologies, or practices, as is happening with AI-related efforts, potential failure is an accepted possibility. With failure, experience increases, new insights are gained, fixes are made, constraints are better understood, and technological innovation and progress continue. However, most IT failures today are not related to pushing the innovative frontiers of the computing art, but the edges of the mundane. They do not represent Austrian economist Joseph Schumpeter’s “<a href="https://www.econlib.org/library/Enc/CreativeDestruction.html" target="_blank">gales of creative destruction</a>.” They’re more like gales of financial destruction. Just how many more <a href="https://www.cio.com/article/278677/enterprise-resource-planning-10-famous-erp-disasters-dustups-and-disappointments.html" target="_blank">enterprise resource planning (ERP) project failures</a> are needed before success becomes routine? Such failures should be called IT blunders, as learning anything new from them is dubious at best.</p><p>Was Phoenix a failure or a blunder? I argue strongly for the latter, but at the very least, Phoenix serves as a master class in IT <a href="https://spectrum.ieee.org/tag/project-mismanagement">project mismanagement</a>. The question is whether the Canadian government learned from this experience any more than it did from 1995’s payroll-project fiasco? <a href="https://www.thealbertan.com/national-news/fixing-problems-with-phoenix-payroll-system-cost-taxpayers-51-billion-official-10851998" target="_blank">The government maintains it will learn</a>, which might be true, given the Phoenix failure’s high political profile. But will Phoenix’s lessons extend to the <a href="https://www.oag-bvg.gc.ca/internet/English/parl_oag_202310_07_e_44340.html" rel="noopener noreferrer" target="_blank">thousands of outdated Canadian government IT systems</a> needing replacement or modernization? Hopefully, but hope is not a methodology, and purposeful action will be necessary.</p></div><p>The IT community has striven mightily for decades to make the incomprehensible routine. </p><div id="rebelltitem15" data-id="15" data-reload-ads="false" data-is-image="False" data-href="https://spectrum.ieee.org/it-management-software-failures/particle-15" data-basename="particle-15" data-post-id="2674305315" data-published-at="1763498559" data-use-pagination="False"><p>Repeatedly making the same mistakes and expecting a different result is not learning. It is a farcical absurdity. Paraphrasing <a href="https://en.wikipedia.org/wiki/Henry_Petroski" target="_blank">Henry Petroski</a> in his book <a href="https://www.google.com/books/edition/To_Engineer_is_Human/_YWvcD-SFAgC?hl=en" target="_blank"><em>To Engineer Is Human: The Role of Failure in Successful Design</em></a> (Vintage, 1992), we may have learned how to calculate the software failure due to risk, but we have not learned how to calculate to eliminate the failure of the mind.<a href="https://spectrum.ieee.org/us-coast-guards-67-million-ehr-fiasco" target="_self"> </a>There are a <a href="https://spectrum.ieee.org/us-coast-guards-67-million-ehr-fiasco" target="_self">plethora of examples</a> of projects like Phoenix that failed in part due to bumbling management, yet it is extremely difficult to find software projects managed professionally that still failed. Finding examples of what could be termed “IT heroic failures” is like<a href="https://penelope.uchicago.edu/encyclopaedia_romana/greece/hetairai/diogenes.html" target="_blank"> Diogenes</a> seeking one honest man.</p><p>The consequences of not learning from blunders will be much greater and more insidious as society grapples with the growing effects of <a href="https://spectrum.ieee.org/topic/artificial-intelligence/">artificial intelligence</a>, or more accurately, “intelligent” <a href="https://spectrum.ieee.org/tag/algorithms">algorithms</a> embedded into software systems. Hints of what might happen if past lessons go unheeded are found in the spectacular early automated decision-making failure of<a href="https://spectrum.ieee.org/michigans-midas-unemployment-system-algorithm-alchemy-that-created-lead-not-gold" target="_self"> Michigan’s MiDAS unemployment</a> and <a href="https://robodebt.royalcommission.gov.au/system/files/2023-09/rrc-accessible-full-report.PDF" target="_blank">Australia’s Centrelink “Robodebt” welfare systems</a>. Both used questionable algorithms to identify deceptive payment claims without human oversight. State officials used MiDAS to accuse tens of thousands of Michiganders of <a href="https://spectrum.ieee.org/tag/unemployment">unemployment</a> fraud, while Centrelink officials falsely accused hundreds of thousands of Australians of being welfare cheats. Untold numbers of lives will never be the same because of what occurred. Government officials in Michigan and <a href="https://spectrum.ieee.org/tag/australia">Australia</a> placed far too much trust in those algorithms. They had to be dragged, kicking and screaming, to acknowledge that something was amiss, even after it was clearly demonstrated that the software was untrustworthy. Even then, officials tried to downplay the errors’ impact on people, then fought against paying compensation to those adversely affected by the errors. While such behavior is legally termed “maladministration,” <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?arnumber=8057305" rel="noopener noreferrer" target="_blank">administrative evil</a> is closer to reality.</p></div><p>So, we are left with only a professional and personal obligation to reemphasize the obvious: Ask what you do know, what you should know, and how big the gap is between them before embarking on creating an IT system. If no one else has ever successfully built your system with the schedule, budget, and functionality you asked for, please explain why your organization thinks it can. Software is inherently fragile; building complex, secure, and resilient software systems is difficult, detailed, and time-consuming. Small errors have outsize effects, each with an almost infinite number of ways they can manifest, from causing a minor functional error to a system outage to allowing a <a href="https://spectrum.ieee.org/tag/cybersecurity">cybersecurity</a> threat to penetrate the system. The more complex and interconnected the system, the more opportunities for errors and their exploitation. A nice start would be for senior management who control the purse strings to finally treat software and <a href="https://spectrum.ieee.org/tag/systems-development">systems development</a>, operations, and sustainment efforts with the respect they deserve. This not only means providing the personnel, financial resources, and leadership support and commitment, but also the professional and personal accountability they demand.</p><div id="rebelltitem26" data-id="26" data-reload-ads="false" data-is-image="False" data-href="https://spectrum.ieee.org/it-management-software-failures/particle-26" data-basename="particle-26" data-post-id="2674305315" data-published-at="1763498705" data-use-pagination="False"><p>It is well known that honesty, skepticism, and ethics are essential to achieving project success, yet they are often absent. Only senior management can demand they exist. For instance, honesty begins with the <a href="https://www.sciencedirect.com/science/article/abs/pii/S0065245808603368" rel="noopener noreferrer" target="_blank">forthright accounting</a> of the myriad of risks involved in any IT endeavor, not their rationalization. It is a common “secret” that it is far easier to get funding to fix a troubled software development effort than to ask for what is required up front to address the risks involved. Vendor <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8364440" rel="noopener noreferrer" target="_blank">puffery</a> may also be legal, but that means the IT customer needs <a href="https://csdl-downloads.ieeecomputer.org/mags/co/2024/11/10718683.pdf?Expires=1749318541&amp;Policy=eyJTdGF0ZW1lbnQiOlt7IlJlc291cmNlIjoiaHR0cHM6Ly9jc2RsLWRvd25sb2Fkcy5pZWVlY29tcHV0ZXIub3JnL21hZ3MvY28vMjAyNC8xMS8xMDcxODY4My5wZGYiLCJDb25kaXRpb24iOnsiRGF0ZUxlc3NUaGFuIjp7IkFXUzpFcG9jaFRpbWUiOjE3NDkzMTg1NDF9fX1dfQ__&amp;Signature=mL9v2PDZegXaIyUtFxUhKbp3FdpiW9v9dtWmGzdl9fDmhlRleA25D7IMUwVSezmGnCEalvPnY~uWI8jmDIyd-O3NLGv7~xcKEeqsptxR90hRojhxVZQ0LK2xp5TfQ9LbaWifuXCRCifA4KnGq-mg9yYpFMKnsjBKJp67u5gHHYElV3NBuODy1GYjMflkztyZQcqOHkx2zU5DazT5WgjD76RXYlwF-M9TKk7YdQoW-05OgxNovNL9gq2SJ9Q3tQRtx8uHwxPzjeGKqGJbahqwiaZNKowR7e1fK5uOy02ivsOeel0EQohoyrX305LMyK98hGVSn64c7kS55pFS-TcDHg__&amp;Key-Pair-Id=K12PMWTCQBDMDT" rel="noopener noreferrer" target="_blank">a healthy skepticism</a> of the typically too-good-to-be-true promises vendors make. Once the contract is signed, it is too late. Furthermore, computing’s malleability, complexity, speed, low cost, and ability to reproduce and store information <a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&amp;arnumber=8677333" rel="noopener noreferrer" target="_blank">combine to create</a> ethical situations that require deep reflection about computing’s consequences on individuals and society. Alas, ethical considerations have <a href="https://ieeexplore.ieee.org/document/9464106" rel="noopener noreferrer" target="_blank">routinely lagged</a> when technological progress and profits are to be made. This practice must change, especially as AI is routinely injected into automated systems.</p><p>In the AI community, there has been a movement toward the idea of <a href="https://hcil.umd.edu/human-centered-ai/" target="_blank">human-centered AI</a>, meaning AI systems that prioritize human needs, values, and well-being. This means trying to anticipate where and when AI can go wrong, move to eliminate these situations, and build in ways to mitigate the effects if they do happen. This concept requires application to every IT system’s effort, not just AI.</p></div><p>Given the historic lack of organizational resolve to instill proven practices...novel approaches for developing and sustaining ever more complex software systems...will also frequently fall short.</p><p><span>Finally, project cost-benefit justifications of software developments rarely consider the financial and emotional distress placed on end users of <a href="https://spectrum.ieee.org/tag/it-systems">IT systems</a> when something goes wrong. These include the long-term </span><a href="https://spectrum.ieee.org/five-enduring-government-it-failures" target="_self">failure after-effects</a><span>. If these costs had to be taken fully into account, such as in the cases of Phoenix, MiDAS, and Centrelink, perhaps there could be more realism in what is required managerially, financially, technologically, and experientially to create a successful <a href="https://spectrum.ieee.org/tag/software-system">software system</a>. It may be a forlorn request, but surely it is time the IT community stops repeatedly making the same ridiculous mistakes it has made since at least 1968, when the term “</span><a href="https://www.scrummanager.com/files/nato1968e.pdf" target="_blank">software crisis</a><span>” was coined. Make new ones, damn it. As Roman orator Cicero said in </span><a href="https://www.loebclassics.com/view/marcus_tullius_cicero-philippic_12/2010/pb_LCL507.191.xml" target="_blank"><em><em>Philippic 12</em></em></a><span>, “Anyone can make a mistake, but only an idiot persists in his error.”</span></p><p><em><span>Special thanks to Steve Andriole, Hal Berghel, Matt Eisler, John L. King, Roger Van Scoy, and Lee Vinsel for their invaluable critiques and insights.</span></em></p><p><em><span><em>This article appears in the December 2025 print issue as “The Trillion-Dollar Cost of IT’s Willful Ignorance.”</em></span></em></p></div></div></div>
  </body>
</html>
