<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/microsoft/Phi-3CookBook">Original</a>
    <h1>Microsoft Phi-3 Cookbook</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">
<p dir="auto">This is a manual on how to use the Microsoft Phi-3 family.</p>
<p dir="auto">Phi-3, a family of open AI models developed by Microsoft. Phi-3 models are the most capable and cost-effective small language models (SLMs) available, outperforming models of the same size and next size up across a variety of language, reasoning, coding, and math benchmarks.</p>
<p dir="auto">Phi-3-mini, a 3.8B language model is available on <a href="https://aka.ms/phi3-azure-ai" rel="nofollow">Microsoft Azure AI Studio</a>, <a href="https://huggingface.co/collections/microsoft/phi-3-6626e15e9585a200d2d761e3" rel="nofollow">Hugging Face</a>, and <a href="https://ollama.com/library/phi3" rel="nofollow">Ollama</a>. Phi-3 models significantly outperform language models of the same and larger sizes on key benchmarks (see benchmark numbers below, higher is better). Phi-3-mini does better than models twice its size, and Phi-3-small and Phi-3-medium outperform much larger models, including GPT-3.5T.</p>
<p dir="auto">All reported numbers are produced with the same pipeline to ensure that the numbers are comparable. As a result, these numbers may differ from other published numbers due to slight differences in the evaluation methodology. More details on benchmarks are provided in our technical paper.</p>
<p dir="auto">Phi-3-small with only 7B parameters beats GPT-3.5T across a variety of language, reasoning, coding and math benchmarks.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/microsoft/Phi-3CookBook/blob/main/imgs/00/phi3small.png"><img src="https://github.com/microsoft/Phi-3CookBook/raw/main/imgs/00/phi3small.png" alt="phimodelsmall"/></a></p>
<p dir="auto">Phi-3-medium with 14B parameters continues the trend and outperforms Gemini 1.0 Pro.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/microsoft/Phi-3CookBook/blob/main/imgs/00/phi3medium.png"><img src="https://github.com/microsoft/Phi-3CookBook/raw/main/imgs/00/phi3medium.png" alt="phimodelmedium"/></a></p>
<p dir="auto">Phi-3-vision with just 4.2B parameters continues that trend and outperforms larger models such as Claude-3 Haiku and Gemini 1.0 Pro V across general visual reasoning tasks, OCR, table and chart understanding tasks.</p>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/microsoft/Phi-3CookBook/blob/main/imgs/00/phi3vision.png"><img src="https://github.com/microsoft/Phi-3CookBook/raw/main/imgs/00/phi3vision.png" alt="phimodelvision"/></a></p>
<p dir="auto">Note: Phi-3 models do not perform as well on factual knowledge benchmarks (such as TriviaQA) as the smaller model size results in less capacity to retain facts.</p>
<p dir="auto">We are introducing Phi Silica which is built from the Phi series of models and is designed specifically for the NPUs in Copilot+ PCs. Windows is the first platform to have a state-of-the-art small language model (SLM) custom built for the NPU and shipping inbox. Phi Silica API along with OCR, Studio Effects, Live Captions, Recall User Activity APIs will be available in Windows Copilot Library in June. More APIs like Vector Embedding, RAG API, Text Summarization will be coming later.</p>

<p dir="auto">You can learn how to use Microsoft Phi-3 and how to build E2E solutions in your different hardware devices. To experience Phi-3 for yourself, start with playing with the model and customizing Phi-3 for your scenarios using the <a href="https://aka.ms/phi3-azure-ai" rel="nofollow">Azure AI Studio, Azure AI Model Catalog</a></p>
<p dir="auto"><strong>Playground</strong>
Each model has a dedicated playground to test the model <a href="https://aka.ms/try-phi3" rel="nofollow">Azure AI Playground</a>.</p>

<p dir="auto">You can also find the model on the <a href="https://huggingface.co/microsoft" rel="nofollow">Hugging Face</a></p>
<p dir="auto"><strong>Playground</strong>
<a href="https://huggingface.co/chat/models/microsoft/Phi-3-mini-4k-instruct" rel="nofollow">Hugging Chat playground</a></p>

<p dir="auto">This cookbook includes:</p>

<ul dir="auto">
<li><a href="https://github.com/microsoft/Phi-3CookBook/blob/main">Introduction</a>
<ul dir="auto">
<li><a href="https://github.com/microsoft/Phi-3CookBook/blob/main/md/01.Introduce/Phi3Family.md">Welcome to the Phi-3 Family</a>(✅)</li>
</ul>
</li>
<li><a href="https://github.com/microsoft/Phi-3CookBook/blob/main">Quick Start</a>
<ul dir="auto">
<li><a href="https://github.com/microsoft/Phi-3CookBook/blob/main/md/02.QuickStart/Huggingface_QuickStart.md">Using Phi-3 in Hugging face</a>(✅)</li>
<li><a href="https://github.com/microsoft/Phi-3CookBook/blob/main/md/02.QuickStart/AzureAIStudio_QuickStart.md">Using Phi-3 in Azure AI Studio</a>(✅)</li>
<li><a href="https://github.com/microsoft/Phi-3CookBook/blob/main/md/02.QuickStart/Ollama_QuickStart.md">Using Phi-3 in Ollama</a>(✅)</li>
<li><a href="https://github.com/microsoft/Phi-3CookBook/blob/main/md/02.QuickStart/LMStudio_QuickStart.md">Using Phi-3 in LM Studio</a>(✅)</li>
</ul>
</li>
<li><a href="https://github.com/microsoft/Phi-3CookBook/blob/main/md/03.Inference/overview.md">Inference Phi-3</a>
<ul dir="auto">
<li><a href="https://github.com/microsoft/Phi-3CookBook/blob/main/md/03.Inference/iOS_Inference.md">Inference Phi-3 in iOS</a>(✅)</li>
<li><a href="https://github.com/microsoft/Phi-3CookBook/blob/main/md/03.Inference/Jetson_Inference.md">Inference Phi-3 in Jetson</a>(✅)</li>
<li><a href="https://github.com/microsoft/Phi-3CookBook/blob/main/md/03.Inference/AIPC_Inference.md">Inference Phi-3 in AIPC</a>(✅)</li>
<li><a href="https://github.com/microsoft/Phi-3CookBook/blob/main/md/03.Inference/Local_Server_Inference.md">Inference Phi-3 in Local Server</a>(✅)</li>
</ul>
</li>
<li><a href="https://github.com/microsoft/Phi-3CookBook/blob/main">Fine-tuning Phi-3</a>
<ul dir="auto">
<li><a href="https://github.com/microsoft/Phi-3CookBook/blob/main/md/04.Fine-tuning/LetPhi3gotoIndustriy.md">Let Phi-3 become an industry expert</a>(✅)</li>
<li><a href="https://github.com/microsoft/Phi-3CookBook/blob/main/md/04.Fine-tuning/Introduce_AzureML.md">Introduce Azure Machine Learning Service</a>(✅)</li>
<li><a href="https://github.com/microsoft/Phi-3CookBook/blob/main/md/04.Fine-tuning/FineTuning_Lora.md">Fine-tuning Phi-3 with Lora</a>(✅)</li>
<li><a href="https://github.com/microsoft/Phi-3CookBook/blob/main/md/04.Fine-tuning/FineTuning_MicrosotOlive.md">Fine-tuning Phi-3 with Azure AI Studio</a>(✅)</li>
<li><a href="https://github.com/microsoft/Phi-3CookBook/blob/main/md/04.Fine-tuning/FineTuning_Lora.md">Fine-tuning with Microsoft Olive</a>(✅)</li>
</ul>
</li>
<li><a href="https://github.com/microsoft/Phi-3CookBook/blob/main">Evaluation Phi-3</a>
<ul dir="auto">
<li><a href="https://github.com/microsoft/Phi-3CookBook/blob/main/md/05.Evaluation/ResponsibleAI.md">Introduce Responsible AI</a>(✅)</li>
<li><a href="https://github.com/microsoft/Phi-3CookBook/blob/main/md/05.Evaluation/Promptflow.md">Introduce Promptflow</a>(✅)</li>
<li><a href="https://github.com/microsoft/Phi-3CookBook/blob/main/md/05.Evaluation/AzureAIStudio.md">Using Azure AI Studio to evaluation</a>(✅)</li>
</ul>
</li>
</ul>

<p dir="auto">This project welcomes contributions and suggestions.  Most contributions require you to agree to a
Contributor License Agreement (CLA) declaring that you have the right to, and actually do, grant us
the rights to use your contribution. For details, visit <a href="https://cla.opensource.microsoft.com" rel="nofollow">https://cla.opensource.microsoft.com</a>.</p>
<p dir="auto">When you submit a pull request, a CLA bot will automatically determine whether you need to provide
a CLA and decorate the PR appropriately (e.g., status check, comment). Simply follow the instructions
provided by the bot. You will only need to do this once across all repos using our CLA.</p>
<p dir="auto">This project has adopted the <a href="https://opensource.microsoft.com/codeofconduct/" rel="nofollow">Microsoft Open Source Code of Conduct</a>.
For more information see the <a href="https://opensource.microsoft.com/codeofconduct/faq/" rel="nofollow">Code of Conduct FAQ</a> or
contact <a href="mailto:opencode@microsoft.com">opencode@microsoft.com</a> with any additional questions or comments.</p>

<p dir="auto">This project may contain trademarks or logos for projects, products, or services. Authorized use of Microsoft
trademarks or logos is subject to and must follow
<a href="https://www.microsoft.com/en-us/legal/intellectualproperty/trademarks/usage/general" rel="nofollow">Microsoft&#39;s Trademark &amp; Brand Guidelines</a>.
Use of Microsoft trademarks or logos in modified versions of this project must not cause confusion or imply Microsoft sponsorship.
Any use of third-party trademarks or logos are subject to those third-party&#39;s policies.</p>
</article></div></div>
  </body>
</html>
