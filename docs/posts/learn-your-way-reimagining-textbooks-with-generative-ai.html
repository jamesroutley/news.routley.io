<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://research.google/blog/learn-your-way-reimagining-textbooks-with-generative-ai/">Original</a>
    <h1>Learn Your Way: Reimagining Textbooks with Generative AI</h1>
    
    <div id="readability-page-1" class="page"><div data-gt-publish-date="20250916">
                    
                    
    


<section>
    <div>
        
  <div data-gt-id="rich_text" data-gt-component-name="">
    




    <p data-block-key="ucxot">Textbooks are a cornerstone of education, but they have a fundamental limitation: they are a one-size-fits-all medium. The manual creation of textbooks demands significant human effort, and as a result they lack alternative perspectives, multiple formats and tailored variations that can make learning more effective and engaging. At Google, we’re exploring how we can use generative AI (GenAI) to automatically generate alternative representations or personalized examples, while preserving the integrity of the source material. What if students had the power to shape their own learning journey, exploring materials using various formats that fit their evolving needs? What if we could reimagine the textbook to be as unique as every learner?</p><p data-block-key="e8fqs">Recent advances in GenAI are bringing this vision closer to reality. Today we are excited to introduce <a href="https://learnyourway.withgoogle.com/" target="_blank" rel="noopener noreferrer">Learn Your Way</a>, now on <a href="https://labs.google/" target="_blank" rel="noopener noreferrer">Google Labs</a>, a research experiment that explores how GenAI can transform educational materials to create a more effective, engaging, learner-driven experience for every student. Here we outline the research and pedagogy underpinning Learn Your Way, with more details in the accompanying <a href="https://arxiv.org/abs/2509.13348" target="_blank" rel="noopener noreferrer">tech report</a>. We also report early indicators of its impact: in our efficacy study, students using Learn Your Way scored 11 percentage points higher on retention tests than students using a standard digital reader.</p>
</div>

    </div>
</section>

                    
                    
    


<section>
    
</section>

                    
                    
    


<section>
    <div>
        
  <div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h2>Grounded in learning, built for the student</h2>
            
        
        
    </p>



    <p data-block-key="ucxot">Our approach is built on two key pillars that work together to augment the learning experience: (1) generating various multimodal representations of the content, and (2) taking foundational steps toward personalization.</p><p data-block-key="7jca2">The seminal <a href="https://www.researchgate.net/publication/225249172_Dual_Coding_Theory_and_Education" target="_blank" rel="noopener noreferrer">dual coding theory</a> states that forging mental connections between different representations strengthens the underlying conceptual schema in our brain. Subsequent <a href="https://www.sciencedirect.com/science/article/abs/pii/S0360131599000299" target="_blank" rel="noopener noreferrer">research</a> indeed showed that when students actively engage with information in various formats, they build a more robust and complete mental model of the material. Inspired by this, our approach empowers students with the agency to choose and intermix multiple formats and modalities to best help them understand the material. In addition, personalization is increasingly becoming an <a href="https://par.nsf.gov/servlets/purl/10274018" target="_blank" rel="noopener noreferrer">aspirational standard</a> in K-12 educational settings, and so our research reflects this. We aim to enhance the relatability and effectiveness of educational content by adapting it to student attributes. Moreover, we incorporate quizzing capabilities that enable us to further tailor the experience according to the learners’ real-time responses. Such personalization can be a powerful method for <a href="https://www.researchgate.net/publication/320564894_The_Role_of_Situational_Interest_in_Personalized_Learning" target="_blank" rel="noopener noreferrer">enhancing motivation</a> and <a href="https://journals.sagepub.com/doi/full/10.3102/00346543221148478" target="_blank" rel="noopener noreferrer">deepening learning</a>.</p><p data-block-key="35lic">Bringing this to life involves a layered technical approach using <a href="https://blog.google/outreach-initiatives/education/google-learnlm-gemini-generative-ai/" target="_blank" rel="noopener noreferrer">LearnLM</a>, our best-in-class pedagogy-infused family of models, now integrated directly into <a href="https://blog.google/technology/google-deepmind/gemini-model-thinking-updates-march-2025/" target="_blank" rel="noopener noreferrer">Gemini 2.5 Pro</a>. The first layer is a unique personalization pipeline that serves as the basis for the second layer of multiple content representations. Our starting point is a textbook PDF, although our approach could be used with other forms of source material.</p>
</div>

    </div>
</section>

                    
                    
    


<section>
    <div>
        
  <div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h3>The personalization pipeline</h3>
            
        
        
    </p>



    <p data-block-key="ucxot">The Learn Your Way interface asks the learner to select their grade and interests (e.g., sports, music, food). The original source material is first re-leveled to the learner’s reported grade level, while maintaining the scope of its content. This is followed by the strategic replacement of generic examples with ones that are personalized to the learner’s reported interests. The resulting text serves as the basis for the generation of all the other representations, effectively propagating the personalization effect and setting up a pipeline for further personalization.</p>
</div>

    </div>
</section>

                    
                    
    


<section>
    
</section>

                    
                    
    


<section>
    <div>
        
  <div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h3>Multiple representations of content</h3>
            
        
        
    </p>



    <p data-block-key="ucxot">Following the source personalization, we generate multiple representations of the content. For some content representations, such as mind maps and timelines, Gemini’s broad capabilities are used directly. Other features such as narrated slides, require more elaborate pipelines that weave together multiple specialized AI agents and tools to achieve an effective pedagogical result. Finally, specialized tasks, such as generating effective educational visuals, proved too challenging even for state-of-the-art general-purpose image models. To overcome this, we fine-tuned a dedicated model specifically for generating educational illustrations. The combination of a powerful base model, multi-step agentic workflows, and fine-tuned components allows us to generate a wide range of high-quality multimodal representations for learning.</p>
</div>

    </div>
</section>

                    
                    
    


<section>
    <div>
        
  <div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h2>The Learn Your Way experience</h2>
            
        
        
    </p>



    <p data-block-key="ucxot">Our research comes to life in Learn Your Way. The interface brings together multiple, personalized representations of content including: (1) immersive text, (2) section-level quizzes, (3) slides &amp; narration, (4) audio lessons, and (5) mind maps.</p><ul><li data-block-key="digp2"><b>Immersive text:</b> Breaks the content up into digestible sections that are augmented with generated images and embedded questions. Put together, these transform passive reading into an active multimodal experience that follows learning science principles.</li><li data-block-key="8kkuc"><b>Section-level quizzes</b>: Promote active learning by allowing a user to interactively assess their learning, and uncover existing knowledge gaps.</li><li data-block-key="aq4r1"><b>Slides &amp; narration:</b> Offers presentations that span the entire source material and include engaging activities like fill-in-the-blanks, as well as a narrated version, mimicking a recorded lesson.</li><li data-block-key="act6h"><b>Audio lesson:</b> Provides simulated conversations, coupled with visual aids, between an AI-powered teacher and a student that models how a real learner might engage with the material, including the expression of misconceptions, which are clarified by the teacher.</li><li data-block-key="eqbtv"><b>Mind map:</b> Organizes the knowledge hierarchically and allows learners to zoom in and out from the big picture to the details.</li></ul><p data-block-key="eef4f">The above representations give learners choice and are all adapted to their selected grade level and personal interests. Throughout the experience, the interactive quizzes provide dynamic feedback, guiding students to revisit specific content areas where they struggled. This marks our first steps towards true personalization.</p>
</div>

    </div>
</section>

                    
                    
    


<section>
    
</section>

                    
                    
    


<section>
    <div>
        
  <div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h2>Pedagogical evaluation</h2>
            
        
        
    </p>



    <p data-block-key="ucxot">To evaluate Learn You Way&#39;s pedagogical performance, we transformed ten varied source materials from <a href="https://openstax.org/" target="_blank" rel="noopener noreferrer">OpenStax</a> (a provider of free educational textbooks) to three different personalization settings. The source materials covered various subjects from history to physics. Three pedagogical subject matter experts then evaluated the transformed materials using pedagogical criteria, such as accuracy, coverage, and the <a href="https://blog.google/outreach-initiatives/education/google-learnlm-gemini-generative-ai/" target="_blank" rel="noopener noreferrer">LearnLM</a> learning science principles.</p>
</div>

    </div>
</section>

                    
                    
    


<section>
    
</section>

                    
                    
    


<section>
    <div>
        
  <p data-block-key="ucxot">The results were highly positive, with an average expert rating of 0.85 or higher across all pedagogical criteria. See the <a href="https://arxiv.org/abs/2509.13348" target="_blank" rel="noopener noreferrer">tech report</a> for more evaluation details.</p>

    </div>
</section>

                    
                    
    


<section>
    
</section>

                    
                    
    


<section>
    <div>
        
  <div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h2>Efficacy study</h2>
            
        
        
    </p>



    <p data-block-key="ucxot">An AI-powered learning tool is only valuable if it both effectively improves learning outcomes and students want to use it. Learn Your Way now serves as a research platform for us to conduct studies with partners around the world to explore how AI-powered transformations and personalization affects outcomes, and to ensure that what we build is effective and <a href="https://blog.google/intl/en-africa/company-news/outreach-and-initiatives/5-ways-were-bringing-ai-innovations-to-people-across-africa/" target="_blank" rel="noopener noreferrer">locally relevant</a>.</p><p data-block-key="rstv">Recently, we conducted a randomized controlled study with 60 students from the Chicago area, ages 15–18 and with similar reading levels. Participants were given up to 40 minutes to learn about adolescent brain development from a textbook, and randomly assigned to learn using Learn Your Way or a traditional digital PDF reader.</p><p data-block-key="e1qod">We assessed students with a quiz immediately after the study session, and with a retention test 3–5 days later, using assessments designed by pedagogical experts to be a good measure of content comprehension. We also surveyed them about the learning experience, and to gain deeper insights beyond these quantitative metrics, each student participated in a 30-minute qualitative interview where they could share more nuanced feedback about their experience.</p><p data-block-key="2tkk3">The results were compelling and statistically significant. Here are the highlights. See the <a href="https://arxiv.org/abs/2509.13348" target="_blank" rel="noopener noreferrer">tech report</a> for more details.</p><ul><li data-block-key="1603p"><b>Positive learning outcomes:</b> The Learn Your Way group scored, on average, 9% higher on the immediate assessment following the study session.</li><li data-block-key="2plg8"><b>Better long-term retention:</b> Similarly, the Learn Your Way group scored 11% higher on the retention assessment 3-5 days later (78% vs. 67%).</li><li data-block-key="c6kod"><b>Positive user sentiment:</b> 100% of students who used Learn Your Way reported that they felt the tool made them more comfortable taking the assessment, compared to 70% in the digital reader control group. 93% said they would want to use Learn Your Way for future learning, compared to just 67% for the digital reader.</li><li data-block-key="4mg4i"><b>Valuable experience</b>: Insights from the qualitative interviews revealed that students found great value in Learn Your Way.</li></ul>
</div>

    </div>
</section>

                    
                    
    


<section>
    
</section>

                    
                    
    


<section>
    
</section>

                    
                    
    


<section>
    <div>
        
  <div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h2>The path forward</h2>
            
        
        
    </p>



    <p data-block-key="ucxot">Our findings suggest that generative AI can be used to build learning experiences that are not only more effective but also more empowering. By evolving the static textbook into an interactive artifact and giving students greater agency over <i>how</i> they learn, we saw learning retention improve.</p><p data-block-key="88po1">This work is just the beginning of our exploration. We envision many more ways to tailor content, moving towards systems that continuously adapt to each learner&#39;s unique needs and progress. As we take our next steps towards personalized education, we will continue to ground our research in pedagogical principles, measuring the impact of AI on learning efficacy, so that in the future every student might have access to a high-quality, engaging learning experience that is custom built for them.</p>
</div>

    </div>
</section>

                    
                    
    


<section>
    <div>
        
  <div data-gt-id="rich_text" data-gt-component-name="">
    


    <p>
        
            
                <h2>Acknowledgements</h2>
            
        
        
    </p>



    <p data-block-key="ucxot"><i>Shout out to our Google Research LearnLM team who have contributed to this work: Alicia Martín, Amir Globerson, Amy Wang, Anirudh Shekhawat, Anisha Choudhury, Anna Iurchenko, Avinatan Hassidim, Ayça Çakmakli, Ayelet Shasha Evron, Charlie Yang, Courtney Heldreth, Dana Oria, Diana Akrong, Hairong Mu, Ian Li, Ido Cohen, Komal Singh, Lev Borovoi, Lidan Hackmon, Lior Belinsky, Michael Fink, Preeti Singh, Rena Levitt, Shashank Agarwal, Shay Sharon, Sophie Allweis, Tracey Lee-Joe, Xiaohong Hao, Yael Gold-Zamir, Yishay Mor, and Yoav Bar Sinai. Special thanks to our executive champions: Niv Efron, Avinatan Hassidim, Yossi Matias and Ben Gomes.</i></p>
</div>

    </div>
</section>

                    
                </div></div>
  </body>
</html>
