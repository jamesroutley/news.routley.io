<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://ai.meta.com/blog/scenescript-3d-scene-reconstruction-reality-labs-research/">Original</a>
    <h1>SceneScript, a novel approach for 3D scene reconstruction</h1>
    
    <div id="readability-page-1" class="page"><div><div><p>Takeaways</p><div><p>Imagine a pair of stylish, lightweight glasses that combined contextualized AI with a display that could seamlessly give you access to real-time information when you need it and proactively help you as you go about your day. In order for such a pair of augmented reality (AR) glasses to become reality, the system must be able to understand the layout of your physical environment and how the world is shaped in 3D. That understanding would let AR glasses tailor content to you and your individual context, like seamlessly blending a digital overlay with your physical space or giving you turn-by-turn directions to help you navigate unfamiliar locations.</p><p>However, building these 3D scene representations is a complex task. Current MR headsets like Meta Quest 3 create a virtual representation of physical spaces based on raw visual data from cameras or 3D sensors. This raw data is converted into a series of shapes that describe distinct features of the environment, like walls, ceilings, and doors. Typically, these systems rely on pre-defined rules to convert the raw data into shapes. Yet that heuristic approach can often lead to errors, especially in spaces with unique or irregular geometries.</p></div><p>Introducing SceneScript</p><div><p>Today, Reality Labs Research is announcing <a href="https://www.projectaria.com/scenescript" target="_blank" data-lnfb-mode="ie"><u>SceneScript</u></a>, a novel method of generating scene layouts and representing scenes using language.</p><br/></div></div><p><img src="https://scontent-iad3-1.xx.fbcdn.net/v/t39.8562-6/434069040_708526774524906_7376808912820184909_n.png?_nc_cat=104&amp;ccb=1-7&amp;_nc_sid=f537c7&amp;_nc_ohc=0dR_jy48VyoAX9266zq&amp;_nc_ht=scontent-iad3-1.xx&amp;oh=00_AfBQ1Hy83mznQfqKqNpNlu8ggLhp0bxBL5jpRhwhVKgXeA&amp;oe=6604A955" alt="" id="u_0_c_vK"/></p><div><div><p>Rather than using hard-coded rules to convert raw visual data into an approximation of a room’s architectural elements, SceneScript is trained to directly infer a room’s geometry using end-to-end machine learning.</p><p>This results in a representation of physical scenes which is <b><i>compact</i></b>, reducing memory requirements to only a few bytes; <b><i>complete</i></b>, resulting in crisp geometry, similar to scalable vector graphics; and importantly, <b><i>interpretable</i></b>, meaning that we can easily read and edit those representations.</p></div><p>How is SceneScript trained?</p></div><p><img src="https://scontent-iad3-1.xx.fbcdn.net/v/t39.2365-6/434030671_428282653029604_1716392865931118756_n.png?_nc_cat=108&amp;ccb=1-7&amp;_nc_sid=e280be&amp;_nc_ohc=kk68H6Bl_0QAX8E-p1G&amp;_nc_ht=scontent-iad3-1.xx&amp;oh=00_AfC2y-782hAyxKoEypCjXy6NKcamwmVRguQCJ7ObKXTXyg&amp;oe=661977D8" alt="" id="u_0_d_vU"/></p><div><p>Training SceneScript in simulation</p><p>Extending SceneScript to describe objects, states, and complex geometry</p><div><p>Another of SceneScript’s strengths is its <b><i>extensibility</i></b>.</p><p>Simply by adding a few additional parameters to scene language that describes doors in the Aria Synthetic Environments dataset, the network can be trained to accurately predict the degree to which doors are open or closed in physical environments.</p><p>Additionally, by adding new features to the architectural language, it’s possible to accurately predict the location of objects and—further still—decompose those objects into their constituent parts.</p><p>For example, a sofa could be represented within the SceneScript language as a set of geometric shapes including the cushions, legs, and arms. This level of detail could eventually be used by designers to create AR content that is truly customized to a wide range of physical environments.</p></div><div><p>SceneScript could unlock key use cases for both MR headsets and future AR glasses, like generating the maps needed to provide <a href="https://www.facebook.com/watch/?v=1180323275899569" target="_blank"><u>step-by-step navigation for people who are visually impaired</u></a>, as demonstrated by <a href="https://www.cmu.edu/" target="_blank" data-lnfb-mode="ie"><u>Carnegie Mellon University</u></a> in 2022.</p><p>SceneScript also gives LLMs the vocabulary necessary to reason about physical spaces. This could ultimately unlock the potential of next-generation digital assistants, providing them with the physical-world context necessary to answer complex spatial queries. For example, with the ability to reason about physical spaces, we could pose questions to a chat assistant like, “Will this desk fit in my bedroom?” or, “How many pots of paint would it take to paint this room?” Rather than having to find your tape measure, jot down measurements, and do your best to estimate the answer with some back-of-the-napkin math, a chat assistant with access to SceneScript could arrive at the answer in mere fractions of a second.</p><p>We believe SceneScript represents a significant milestone on the path to true AR glasses that will bridge the physical and digital worlds. As we dive deeper into this potential at Reality Labs Research, we’re thrilled at the prospect of how this pioneering approach will help shape the future of AI and ML research.</p><p>Learn more about SceneScript <a href="https://www.projectaria.com/scenescript/" target="_blank" data-lnfb-mode="ie"><b><u>here</u></b></a>.</p></div></div><div><div><div><div><p>Our latest updates delivered to your inbox</p><p><a href="https://ai.facebook.com/subscribe/" target="_blank">Subscribe</a> to our newsletter to keep up with Meta AI news, events, research breakthroughs, and more.</p></div></div></div></div></div></div>
  </body>
</html>
