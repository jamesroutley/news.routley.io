<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://news.yale.edu/2024/08/14/sleep-it-how-brain-processes-many-experiences-even-when-offline">Original</a>
    <h1>Sleep on it: How the brain processes many experiences – even when &#39;offline&#39;</h1>
    
    <div id="readability-page-1" class="page"><div>

  <p>Humans and other animals encounter and remember countless experiences each day; when we sleep, groups of cells in the brain known as neuronal ensembles replay these experiences to consolidate them into memories and “preplay” futures ones, which enables faster encoding of new experiences into memories later on.</p>
<p>Better understanding how these neuronal ensembles represent, or depict, these experiences would offer important insights into how memory and the mind function. But most studies to date have focused solely on animals undergoing just one or a small handful of sequential experiences — and it remains unclear how exactly the brain is able to process numerous experiences simultaneously during sleep.</p>
<p>In a new study, Yale scientists revealed a generative coding capacity in the brain’s hippocampus — an area responsible for memory and learning — which enables the brain to bundle together the representations of some 15 unrelated experiences that occurred across one full day within single sub-second events, known as frames, during sleep.</p>
<p>This computer-like capacity for parallel processing of different chains of information helps explain why humans and other animals are able to process a cascade of experiences and either keep separate or combine their meanings.</p>
<p>The findings were <a href="https://www.nature.com/articles/s41593-024-01703-6">published in the journal Nature Neuroscience</a>.</p>
<p><span>“</span>The brain mechanisms we uncovered are relevant for how we form and express internally generated representations about the world, like memories, imagining, and insight,” said <a href="https://medicine.yale.edu/profile/george-dragoi/">George Dragoi</a>, an associate professor of psychiatry and of neuroscience at Yale School of Medicine and corresponding author of the study.</p>
<p>An increasing amount of neuroscience research is exploring how neuronal ensembles represent experiences in the brain, a complex process that has implications for learning and memory, cognitive mapping, and spatial navigation. The fact that most studies involve animals undergoing a single experience, however, has prevented researchers from assembling a more complete picture.</p>
<p><span>“</span>In real life we are continuously experiencing new contexts and events that all need to be encoded distinctly and remembered later without a major interference between them,” Dragoi said. “The way the brain solves this problem is not known and experiments attempting to address this topic are essentially missing.</p>
<p><span>“</span>Computational models have proposed that exposure to multiple experiences would lead to a ‘catastrophic interference’ between the brain representations of new and older experiences, causing the individual to forget the latter,” Dragoi said. “That, of course, is not how daily life works.”</p>
<p>For the new study, the researchers recorded the activity of hippocampal neurons in rats that were allowed to move freely through 15 different spatial contexts over 19 ½ hours, a time span that included periods of extended sleep, during a single day. (The periods of sleep were used to investigate “offline” activity in the animals’ brains, in terms of preplay and replay of experiences.)</p>
<p>Using innovative data analysis, they identified several coding schemes in the hippocampus that boost its network capacity and efficiency during sleep and allow the brain to process representations of several experiences without interference.</p>
<p>Specifically, they found that the brain is able to “flicker” between time-compressed representations from two or more distinct experiences within the same sleep preplay and replay events, a feature that greatly increases network capacity for parallel information processing without interference during sleep. In addition, independent experiences can be bound together into longer preplay/replay episodes representing sequential aspects of day-long experiences in the order in which they occurred compressed into replay episodes less than a second in duration.</p>
<p>The researchers also identified a kind of serial position effect in this process, whereby the first and most recent experiences had the strongest representations during the animals’ sleep, a phenomenon similar to the effect observed in human memory in which people tend to recall the first and last events in a series of events or items.</p>
<p>Other authors of the paper are Kefei Liu and Jeremie Sibille, a former associate research scientist and postdoctoral associate, respectively, in Dragoi’s lab at Yale School of Medicine.</p>

</div></div>
  </body>
</html>
