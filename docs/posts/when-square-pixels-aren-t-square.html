<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://alexwlchan.net/2025/square-pixels/">Original</a>
    <h1>When square pixels aren&#39;t square</h1>
    
    <div id="readability-page-1" class="page"><div id="main" tabindex="-1"><article><hgroup></hgroup><p>When I embed videos in web pages, I specify an <a href="https://developer.mozilla.org/en-US/docs/Web/CSS/Reference/Properties/aspect-ratio">aspect ratio</a>. For example, if my video is 1920 × 1080 pixels, I’d write:</p><pre><code><span>&lt;video</span> <span>style=</span><span>&#34;aspect-ratio: 1920 / 1080&#34;</span><span>&gt;</span>
</code></pre><p>If I also set a width or a height, the browser now knows exactly how much space this video will take up on the page – even if it hasn’t loaded the video file yet. When it initially renders the page, it can leave the right gap, so it doesn’t need to rearrange when the video eventually loads. (The technical term is “reducing <a href="https://developer.mozilla.org/en-US/docs/Glossary/CLS">cumulative layout shift</a>”.)</p><p>That’s the idea, anyway.</p><p>I noticed that some of my videos weren’t fitting in their allocated boxes. When the video file loaded, it could be too small and get letterboxed, or be too big and force the page to rearrange to fit. Clearly there was a bug in my code for computing aspect ratios, but what?</p><h2 id="three-aspect-ratios-one-video">Three aspect ratios, one video</h2><p>I opened one of the problematic videos in QuickTime Player, and the resolution listed in the Movie Inspector was rather curious: <code>Resolution: 1920 × 1080 (1350 × 1080)</code>.</p><p>The first resolution is what my code was reporting, but the second resolution is what I actually saw when I played the video. Why are there two?</p><p>The <a href="https://en.wikipedia.org/wiki/Aspect_ratio_(image)#Distinctions"><strong>storage aspect ratio (SAR)</strong></a> of a video is the pixel resolution of a raw frame. If you extract a single frame as a still image, that’s the size of the image you’d get. This is the first resolution shown by QuickTime Player, and it’s what I was reading in my code.</p><p>I was missing a key value – the <a href="https://en.wikipedia.org/wiki/Pixel_aspect_ratio"><strong>pixel aspect ratio (PAR)</strong></a>. This describes the shape of each pixel, in particular the width-to-height ratio. It tells a video player how to stretch or squash the stored pixels when it displays them. This can sometimes cause square pixels in the stored image to appear as rectangles.</p><figure id="pixel_aspect_ratios"><svg viewBox="0 0 95 170" aria-labelledby="svg_pixel_aspect_ratio_lt" height="100" role="img" xmlns="http://www.w3.org/2000/svg"><rect height="50" width="25" x="0" y="0"></rect><rect height="50" width="25" x="35" y="0"></rect><rect height="50" width="25" x="70" y="0"></rect><rect height="50" width="25" x="0" y="60"></rect><rect height="50" width="25" x="35" y="60"></rect><rect height="50" width="25" x="70" y="60"></rect><rect height="50" width="25" x="0" y="120"></rect><rect height="50" width="25" x="35" y="120"></rect><rect height="50" width="25" x="70" y="120"></rect><title id="svg_pixel_aspect_ratio_lt">A 3×3 grid of pixels, where each pixel is a rectangle that&#39;s taller than it is wide.</title></svg><svg viewBox="0 0 170 170" aria-labelledby="svg_pixel_aspect_ratio_eq" height="100" role="img" xmlns="http://www.w3.org/2000/svg"><rect height="50" width="50" x="0" y="0"></rect><rect height="50" width="50" x="60" y="0"></rect><rect height="50" width="50" x="120" y="0"></rect><rect height="50" width="50" x="0" y="60"></rect><rect height="50" width="50" x="60" y="60"></rect><rect height="50" width="50" x="120" y="60"></rect><rect height="50" width="50" x="0" y="120"></rect><rect height="50" width="50" x="60" y="120"></rect><rect height="50" width="50" x="120" y="120"></rect><title id="svg_pixel_aspect_ratio_eq">A 3×3 grid of pixels, where each pixel is a square.</title></svg><svg viewBox="0 0 320 170" aria-labelledby="svg_pixel_aspect_ratio_gt" height="100" role="img" xmlns="http://www.w3.org/2000/svg"><rect height="50" width="100" x="0" y="0"></rect><rect height="50" width="100" x="110" y="0"></rect><rect height="50" width="100" x="220" y="0"></rect><rect height="50" width="100" x="0" y="60"></rect><rect height="50" width="100" x="110" y="60"></rect><rect height="50" width="100" x="220" y="60"></rect><rect height="50" width="100" x="0" y="120"></rect><rect height="50" width="100" x="110" y="120"></rect><rect height="50" width="100" x="220" y="120"></rect><title id="svg_pixel_aspect_ratio_gt">A 3×3 grid of pixels, where each pixel is a rectangle that&#39;s wider than it is tall.</title></svg><figcaption>PAR &lt; 1</figcaption><figcaption>PAR = 1</figcaption><figcaption>PAR &gt; 1</figcaption></figure><p>This reminds me of <a href="https://alexwlchan.net/2025/create-thumbnail-is-exif-aware/">EXIF orientation</a> for still images – a transformation that the viewer applies to the stored data. If you don’t apply this transformation properly, your media will look wrong when you view it. I wasn’t accounting for the pixel aspect ratio in my code.</p><p>According to Google, the primary use case for non-square pixels is standard-definition televisions which predate digital video. However, I’ve encountered several videos with an unusual PAR that were made long into the era of digital video, when that seems unlikely to be a consideration. It’s especially common in vertical videos like YouTube Shorts, where the stored resolution is a square 1080 × 1080, and the aspect ratio makes it a portrait.</p><p>I wonder if it’s being introduced by a processing step somewhere? I don’t understand why, but I don’t have to – I’m only displaying videos, not producing them.</p><p>The <a href="https://en.wikipedia.org/wiki/Display_aspect_ratio"><strong>display aspect ratio (DAR)</strong></a> is the size of the video as viewed – what happens when you apply the pixel aspect ratio to the stored frames. This is the second resolution shown by QuickTime Player, and it’s the aspect ratio I should be using to preallocate space in my video player.</p><p>These three values are linked by a simple formula:</p><p>DAR = SAR × PAR</p><p>The size of the viewed video is the stored resolution times the shape of each pixel.</p><h2 id="the-stored-frame-may-not-be-what-you-see">The stored frame may not be what you see</h2><p>One video with a non-unit pixel aspect ratio is my download of <a href="https://www.youtube.com/watch?v=HHhyznZ2u4E">Mars EDL 2020 Remastered</a>. This video by Simeon Schmauß tries to match what the human eye would have seen during the landing of NASA’s <a href="https://en.wikipedia.org/wiki/Perseverance_rover"><em>Perseverance</em> rover</a> in 2021.</p><p>We can get the width, height, and <strong>sample aspect ratio</strong> (which is another name for pixel aspect ratio) using ffprobe:</p><pre><code><span>$</span><span> </span>ffprobe -v error <span>\</span>
      -select_streams v:0 <span>\</span>
      -show_entries stream=width,height,sample_aspect_ratio <span>\</span>
      <span>&#34;Mars 2020 EDL Remastered [HHhyznZ2u4E].mp4&#34;</span>
<span>[STREAM]
width=1920
height=1080
sample_aspect_ratio=45:64
[/STREAM]
</span></code></pre><p>Here <code>1920</code> is the stored width, and <code>45:64</code> is the pixel aspect ratio. We can multiply them together to get the display width: <code>1920 × 45 / 64 = 1350</code>. This matches what I saw in QuickTime Player.</p><p>Let’s extract a single frame using <a href="https://ffmpeg.org/ffmpeg.html">ffmpeg</a>, to get the stored pixels. This command saves the 5000th frame as a PNG image:</p><pre><code><span>$</span><span> </span>ffmpeg <span>-i</span> <span>&#34;Mars 2020 EDL Remastered [HHhyznZ2u4E].mp4&#34;</span> <span>\</span>
    <span>-filter</span>:v <span>&#34;select=eq(n</span><span>\,</span><span>5000)&#34;</span> <span>\</span>
    <span>-frames</span>:v 1 <span>\</span>
    frame.png
</code></pre><p>The image is 1920 × 1080 pixels, and it looks wrong: the circular parachute is visibly stretched.</p><picture><source sizes="(max-width: 750px) 100vw, 750px" srcset="/images/2025/mars_edl_frame_raw_1x.avif 750w,/images/2025/mars_edl_frame_raw_2x.avif 1500w" type="image/avif"/><source sizes="(max-width: 750px) 100vw, 750px" srcset="/images/2025/mars_edl_frame_raw_1x.webp 750w,/images/2025/mars_edl_frame_raw_2x.webp 1500w" type="image/webp"/><source sizes="(max-width: 750px) 100vw, 750px" srcset="/images/2025/mars_edl_frame_raw_1x.png 750w,/images/2025/mars_edl_frame_raw_2x.png 1500w" type="image/png"/><img alt="Photo looking up towards a parachute against a dark brown sky. The parachute is made of white-and-orange segments, and is stretched horizontally. The circle is wider than it is tall." src="https://alexwlchan.net/images/2025/mars_edl_frame_raw_1x.png" width="750"/></picture><p>Suppose we take that same image, but now apply the pixel aspect ratio. This is what the image is meant to look like, and it’s not a small difference – now the parachute actually looks like a circle.</p><figure><picture><source sizes="(max-width: 750px) 100vw, 750px" srcset="/images/2025/mars_edl_frame_fixed_1x.avif 750w" type="image/avif"/><source sizes="(max-width: 750px) 100vw, 750px" srcset="/images/2025/mars_edl_frame_fixed_1x.webp 750w" type="image/webp"/><source sizes="(max-width: 750px) 100vw, 750px" srcset="/images/2025/mars_edl_frame_fixed_1x.png 750w" type="image/png"/><img alt="The same photo as before, but now the parachute is a circle." src="https://alexwlchan.net/images/2025/mars_edl_frame_fixed_1x.png" width="750"/></picture></figure><p>Seeing both versions side-by-side makes the problem obvious: the stored frame isn’t how the video is displayed. The video player in my browser will play it correctly using the pixel aspect ratio, but my layout code wasn’t doing that. I was telling the browser the wrong aspect ratio, and the browser had to update the page when it loaded the video file.</p><h2 id="getting-the-correct-display-dimensions-in-python">Getting the correct display dimensions in Python</h2><p>This is my old function for getting the dimensions of a video file, which uses a <a href="https://pypi.org/project/MediaInfo/">Python wrapper around MediaInfo</a> to extract the width and height fields. I now realise that this only gives me the storage aspect ratio, and may be misleading for some videos.</p><pre><code>from <span>pathlib</span> import <span>Path</span>

from <span>pymediainfo</span> import <span>MediaInfo</span>


def <span>get_storage_aspect_ratio</span><span>(</span><span>video_path</span><span>:</span> Path<span>)</span> -&gt; tuple<span>[</span>int<span>,</span> int<span>]:</span>
    <span>&#34;&#34;&#34;</span><span>
    Returns the storage aspect ratio of a video, as a width/height ratio.
    </span><span>&#34;&#34;&#34;</span>
    <span>media_info</span> = MediaInfo<span>.</span>parse<span>(</span>video_path<span>)</span>
    
    try<span>:</span>
        <span>video_track</span> = next<span>(</span>
            tr
            for tr <span>in</span> media_info<span>.</span>tracks
            if tr<span>.</span>track_type == <span>&#34;</span><span>Video</span><span>&#34;</span>
        <span>)</span>
    except StopIteration<span>:</span>
        raise ValueError<span>(</span><span>f</span><span>&#34;</span><span>No video track found in </span><span>{</span>video_path<span>}</span><span>&#34;</span><span>)</span>
    
    return video_track<span>.</span>width<span>,</span> video_track<span>.</span>height
</code></pre><p>I can’t find an easy way to extract the pixel aspect ratio using pymediainfo. It does expose a <code>Track.aspect_ratio</code> property, but that’s a string which has a rounded value – for example, <code>45:64</code> becomes <code>0.703</code>. That’s close, but the rounding introduces a small inaccuracy. Since I can get the complete value from ffprobe, that’s what I’m doing in my revised function.</p><p>The new function is longer, but it’s more accurate:</p><pre><code>from <span>fractions</span> import <span>Fraction</span>
import <span>json</span>
from <span>pathlib</span> import <span>Path</span>
import <span>subprocess</span>


def <span>get_display_aspect_ratio</span><span>(</span><span>video_path</span><span>:</span> Path<span>)</span> -&gt; tuple<span>[</span>int<span>,</span> int<span>]:</span>
    <span>&#34;&#34;&#34;</span><span>
    Returns the display aspect ratio of a video, as a width/height fraction.
    </span><span>&#34;&#34;&#34;</span>
    <span>cmd</span> = <span>[</span>
        <span>&#34;</span><span>ffprobe</span><span>&#34;</span><span>,</span>
        <span>#
</span>        <span># verbosity level = error
</span>        <span>&#34;</span><span>-v</span><span>&#34;</span><span>,</span> <span>&#34;</span><span>error</span><span>&#34;</span><span>,</span>
        <span>#
</span>        <span># only get information about the first video stream
</span>        <span>&#34;</span><span>-select_streams</span><span>&#34;</span><span>,</span> <span>&#34;</span><span>v:0</span><span>&#34;</span><span>,</span>
        <span>#
</span>        <span># only gather the entries I&#39;m interested in
</span>        <span>&#34;</span><span>-show_entries</span><span>&#34;</span><span>,</span> <span>&#34;</span><span>stream=width,height,sample_aspect_ratio</span><span>&#34;</span><span>,</span>
        <span>#
</span>        <span># print output in JSON, which is easier to parse
</span>        <span>&#34;</span><span>-print_format</span><span>&#34;</span><span>,</span> <span>&#34;</span><span>json</span><span>&#34;</span><span>,</span>
        <span>#
</span>        <span># input file
</span>        str<span>(</span>video_path<span>)</span>
    <span>]</span>
    
    <span>output</span> = subprocess<span>.</span>check_output<span>(</span>cmd<span>)</span>
    <span>ffprobe_resp</span> = json<span>.</span>loads<span>(</span>output<span>)</span>
    
    <span># The output will be structured something like:
</span>    <span>#
</span>    <span>#   {
</span>    <span>#       &#34;streams&#34;: [
</span>    <span>#           {
</span>    <span>#               &#34;width&#34;: 1920,
</span>    <span>#               &#34;height&#34;: 1080,
</span>    <span>#               &#34;sample_aspect_ratio&#34;: &#34;45:64&#34;
</span>    <span>#           }
</span>    <span>#       ],
</span>    <span>#       …
</span>    <span>#   }
</span>    <span>#
</span>    <span># If the video doesn&#39;t specify a pixel aspect ratio, then it won&#39;t
</span>    <span># have a `sample_aspect_ratio` key.
</span>    <span>video_stream</span> = ffprobe_resp<span>[</span><span>&#34;</span><span>streams</span><span>&#34;</span><span>][</span><span>0</span><span>]</span>
    
    try<span>:</span>
        <span>pixel_aspect_ratio</span> = Fraction<span>(</span>
            video_stream<span>[</span><span>&#34;</span><span>sample_aspect_ratio</span><span>&#34;</span><span>].</span>replace<span>(</span><span>&#34;</span><span>:</span><span>&#34;</span><span>,</span> <span>&#34;</span><span>/</span><span>&#34;</span><span>)</span>
        <span>)</span>
    except KeyError<span>:</span>
        <span>pixel_aspect_ratio</span> = <span>1</span>
    
    <span>width</span> = round<span>(</span>video_stream<span>[</span><span>&#34;</span><span>width</span><span>&#34;</span><span>]</span> * pixel_aspect_ratio<span>)</span>
    <span>height</span> = video_stream<span>[</span><span>&#34;</span><span>height</span><span>&#34;</span><span>]</span>
    
    return width<span>,</span> height
</code></pre><p>This is calling the <code>ffprobe</code> command I showed above, plus <code>-print_format json</code> to print the data in JSON, which is easier for Python to parse.</p><p>I have to account for the case where a video doesn’t set a sample aspect ratio – in that case, the displayed video just uses square pixels.</p><p>Since the aspect ratio is expressed as a ratio of two integers, this felt like a good chance to try the <a href="https://docs.python.org/3.13/library/fractions.html"><code>fractions</code> module</a>. That avoids converting the ratio to a floating-point number, which potentially introduces inaccuracies. It doesn’t make a big difference, but in my video collection treating the aspect ratio as a <code>float</code> produces results that are 1 or 2 pixels different from QuickTime Player.</p><p>When I multiply the stored width and aspect ratio, I’m using the <a href="https://docs.python.org/3.13/library/functions.html#round"><code>round()</code> function</a> to round the final width to the nearest integer. That’s more accurate than <code>int()</code>, which always rounds down.</p><h2 id="conclusion-use-display-aspect-ratio">Conclusion: use display aspect ratio</h2><p>When you want to know how much space a video will take up on a web page, look at the display aspect ratio, not the stored pixel dimensions. Pixels can be squashed or stretched before display, and the stored width/height won’t tell you that.</p><p>Videos with non-square pixels are pretty rare, which is why I ignored this for so long. I’m glad I finally understand what’s going on.</p><p>After switching to ffprobe and using the display aspect ratio, my pre-allocated video boxes now match what the browser eventually renders – no more letterboxing, no more layout jumps.</p></article></div></div>
  </body>
</html>
