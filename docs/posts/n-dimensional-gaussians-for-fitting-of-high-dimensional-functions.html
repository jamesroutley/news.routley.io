<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.sdiolatz.info/ndg-fitting/">Original</a>
    <h1>N-Dimensional Gaussians for Fitting of High Dimensional Functions</h1>
    
    <div id="readability-page-1" class="page">


<section>
  
</section>

<section>
  <div>
    <div>
      <p><img src="https://www.sdiolatz.info/ndg-fitting/static/images/teaser.png" alt=""/></p><div><p>
            Our method optimizes N-Dimensional Gaussians to approximate high dimensional anisotropic functions in a
            few minutes. Our parameterization, culling and optimization-controlled refinement allows us to quickly estimate Gaussian
            parameters to represent various complex functions. We show two applications:
            </p><ul>
              <li>10D+ Application (Top): Synthetic scenes for which we can render G-Buffers such as world position, albedo, roughness etc. can be shaded with global illumination through our 10D+ Gaussian mixture. Even though the Gaussians are evaluated on the surfaces their representation power can efficiently estimate the appearance of reflections and transmittance with correct parallax effects. Apart from the G-Buffers we support variability of moving objects and light sources as extra dimensions.</li>
              <li> 6D Application (Bottom): Real world scenes with complex view dependent effects can be modeled efficiently through our 6 dimensional Gaussian mixture. The 6 dimensions of world position and view direction give the parameterization the same representation power for both diffuse and view dependent effects, reconstructing complex effects like the one through the magnifying glass.</li>
            </ul>
          </div>
    </div>
  </div>
</section>


<section>
  
</section>


<section>
  <div>
    <!-- Abstract. -->
    <div>
      <div>
        <h2>Abstract</h2>
        <p>
          In the wake of many new ML-inspired approaches for reconstructing and representing
          high-quality 3D content, recent hybrid and 
          explicitly learned representations exhibit promising performance and quality characteristics. 
          However, their scaling to higher dimensions
          is challenging, e.g. when accounting for dynamic content with respect
          to additional parameters such as material properties, illumination, or time.
          In this paper, we tackle these challenges for an explicit representations based on 
          Gaussian mixture models. With our solutions, we arrive at efficient fitting of
          compact N-dimensional Gaussian mixtures and enable efficient evaluation at render time:
          For fast fitting and evaluation, 
          we introduce a high-dimensional culling scheme 
          that efficiently bounds N-D Gaussians, inspired by Locality Sensitive Hashing.
          For adaptive refinement yet compact representation, we introduce a 
          loss-adaptive density control scheme that incrementally guides the use of 
          additional capacity towards missing details.
          With these tools we can for the first time represent complex appearance that 
          depends on many input dimensions beyond position or viewing angle within a compact, 
          explicit representation optimized in minutes and rendered in milliseconds.
          </p>
      </div>
    </div>
    <!--/ Abstract. -->

    <!-- Paper video. -->
    <!-- <div class="columns is-centered has-text-centered">
      <div class="column is-four-fifths">
        <h2 class="title is-3">Video</h2>
        <div class="publication-video">
          <iframe src=""
                  frameborder="0" allow="autoplay; encrypted-media" allowfullscreen></iframe>
        </div>
      </div>
    </div> -->
    <!--/ Paper video. -->
  </div>
</section>

<section>
  <div>
    <h2>Method</h2>

    <p><img src="https://www.sdiolatz.info/ndg-fitting/static/images/overview.png" alt=""/></p><p>
      Our optimization receives a number of query points q of N dimensionality as input. For these given points we
      estimate which Gaussians can be discarded safely through our N-Dimensional culling inspired by Locality Sensitive Hashing. With the remaining ones we evaluate
      for each q our Gaussian mixture either in N dimensions for surface radiance fields or by first projecting the Gaussians to 3D.
      Our optimization converges to high quality while it also controlling the introduction of new Gaussians via our Optimization Controlled Refinement.
      </p>

    <h3>N-Dimensional Gaussians Culling</h3>

    
    <p><img src="https://www.sdiolatz.info/ndg-fitting/static/images/culling.png" alt=""/>
    </p>

    <p>
      Culling irrelevant Gaussians is challenging in higher dimensions. Inspired by Locality Sensitive Hashing where locality is estimated by projection to random vectors we project both our Gaussians and the query points on random vectors and discard Gaussians safely if they fall far away from the query points. This is a tunable culling process that doesn&#39;t require any data structure and it works as the Gaussians are changing during optimization. 
      </p>

    
    <h3>Optimization Controlled Refinement</h3>

    <p><img src="https://www.sdiolatz.info/ndg-fitting/static/images/refinement.png" alt=""/></p><p>
      In higher dimensions the refinement process of the Gaussian mixture becomes much more challenging. With many dimensions to choose from which one should we use as a criterion for refinement? Which one should we split along? To avoid this we propose a refinement process controlled by the optimizer instead. Each main Gaussian (Blue) receives two low opacity/brightness child Gaussians (Green) that are linked with the parent through a hierarchical relationship (see paper). In this way the optimizer can choose to utilize them to add details. Once these Gaussians are used enough they become main Gaussians and have child Gaussians of their own. We can see in the training video how Green Gaussians are introduced to add details. 
      </p>

    <video poster="" id="cd_comp" autoplay="" controls="" muted="" loop="" height="100%">
      <source src="./static/videos/refinement.mp4" type="video/mp4"/>
    </video>

    <p>
      In this training every 300 iterations we introduce new child Gaussians (Green) to the main Gaussians (Blue). As the training progress the child Gaussians add more and more fine details to the 6D Gaussian mixture without a splitting or merging mechanism. 
      </p>

  </div>
</section>

<section>
  <div>
    <h2>Comparison</h2>

    <h3>6D Gaussians</h3>
    
    <video poster="" id="cd_comp" autoplay="" controls="" muted="" loop="" height="100%">
      <source src="./static/videos/cd_comp.mp4" type="video/mp4"/>
    </video>

    <p><img src="https://www.sdiolatz.info/ndg-fitting/static/images/splatting_comp.png" alt=""/></p><h3>10D+ Gaussians</h3>

    <p><img src="https://www.sdiolatz.info/ndg-fitting/static/images/mitsuba.png" alt=""/>
  </p></div>
</section>

<!-- <section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
    <h2 class="title">BibTeX</h2>
    <pre><code>@article{park2021nerfies,
  author    = {Park, Keunhong and Sinha, Utkarsh and Barron, Jonathan T. and Bouaziz, Sofien and Goldman, Dan B and Seitz, Steven M. and Martin-Brualla, Ricardo},
  title     = {Nerfies: Deformable Neural Radiance Fields},
  journal   = {ICCV},
  year      = {2021},
}</code></pre>
  </div>
</section> -->

<section>
  <div>
    <!-- Abstract. -->
    <div>
      <div>
        <h2>Acknowledgements</h2>
        <div>
          <p>
            We would like to thank the anonymous referees for their valuable
            comments and helpful suggestions. We also thank Laurent Belcour
            and Sebastian Herholz for their valuable input and suggestions.
          </p>
          <p>
            We thank the authors of <a href="https://github.com/nerfies/nerfies.github.io">Nerfies</a> for open sourcing the webpage templated which we used for this site.
          </p>
        </div>
      </div>
    </div>
</div></section>



</div>
  </body>
</html>
