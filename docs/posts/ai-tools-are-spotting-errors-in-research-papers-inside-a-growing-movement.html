<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.nature.com/articles/d41586-025-00648-5">Original</a>
    <h1>AI tools are spotting errors in research papers: inside a growing movement</h1>
    
    <div id="readability-page-1" class="page"><div data-test="access-teaser"> <figure><picture><source type="image/webp" srcset="//media.nature.com/lw767/magazine-assets/d41586-025-00648-5/d41586-025-00648-5_50703894.jpg?as=webp 767w, //media.nature.com/lw319/magazine-assets/d41586-025-00648-5/d41586-025-00648-5_50703894.jpg?as=webp 319w" sizes="(max-width: 319px) 319px, (min-width: 1023px) 100vw,  767px"/><img alt="A large stack of papers and folders with coloured tabs." loading="lazy" src="https://media.nature.com/lw767/magazine-assets/d41586-025-00648-5/d41586-025-00648-5_50703894.jpg"/><figcaption><p><span>Two new AI tools check for errors in research papers including in the calculations, methodology and references.</span><span>Credit: Jose A. Bernat Bacete/Getty</span></p></figcaption></picture></figure><p>Late last year, media outlets worldwide warned that black plastic cooking utensils contained worrying levels of cancer-linked flame retardants. The risk was found to be overhyped – a mathematical error in the underlying research suggested a key chemical exceeded the safe limit when in fact it was ten times lower than the limit. Keen-eyed researchers quickly showed that an artificial intelligence (AI) model could have spotted the error in seconds.</p><p>The incident has spurred two projects that use AI to find mistakes in the scientific literature. The Black Spatula Project is an open-source AI tool that has so far analysed around 500 papers for errors. The group, which has around eight active developers and hundreds of volunteer advisers, hasn’t made the errors public yet; instead, it is approaching the affected authors directly, says Joaquin Gulloso, an independent AI researcher based in Cartagena, Colombia, who helps to coordinate the project. “Already, it’s catching many errors,” says Gulloso. “It’s a huge list. It’s just crazy.”</p><p>The other effort is called YesNoError and was inspired by the Black Spatula Project, says founder and AI entrepreneur Matt Schlicht. The initiative, funded by its own dedicated cryptocurrency, has set its sights even higher. “I thought, why don’t we go through, like, all of the papers?” says Schlicht. He says that their AI tool has analysed more than 37,000 papers in two months. Its website flags papers in which it has found flaws – many of which have yet to be verified by a human, although Schlicht says that YesNoError has a plan to eventually do so at scale.</p><p>Both projects want researchers to use their tools before submitting work to a journal, and journals to use them before they publish, the idea being to avoid mistakes, as well as fraud, making their way into the <a href="https://www.nature.com/articles/d41586-025-00026-1" data-track="click" data-label="https://www.nature.com/articles/d41586-025-00026-1" data-track-category="body text link">scientific literature</a>.</p><p>The projects have tentative support from academic sleuths who work in research integrity. But there are also concerns over the potential risks. How well the tools can spot mistakes, and whether their claims have been verified, must be made clear, says Michèle Nuijten, a researcher in metascience at Tilburg University in the Netherlands. “If you start pointing fingers at people and then it turns out that there was no mistake, there might be reputational damage,” she says.</p><p>Others add that although there are risks and the projects need to be cautious about what they claim, the goal is the right one. It is much easier to churn out shoddy papers than it is to retract them, says James Heathers, a forensic metascientist at Linnaeus University in Växjö, Sweden. As a first step, AI could be used to triage papers for further scrutiny, says Heathers, who has acted as a consultant for the Black Spatula Project. “It’s early days, but I’m supportive” of the initiatives, he adds.</p><h2>AI sleuths</h2><p>Many researchers have <a href="https://www.nature.com/articles/nature.2015.18657" data-track="click" data-label="https://www.nature.com/articles/nature.2015.18657" data-track-category="body text link">dedicated their careers</a> to spotting integrity <a href="https://www.nature.com/articles/d41586-024-03427-w" data-track="click" data-label="https://www.nature.com/articles/d41586-024-03427-w" data-track-category="body text link">concerns in papers</a> – and <a href="https://www.nature.com/articles/d41586-024-01247-6" data-track="click" data-label="https://www.nature.com/articles/d41586-024-01247-6" data-track-category="body text link">tools to check</a> certain facets of papers already exist. But advocates hope that AI could carry out a wider range of checks in a single shot and handle a larger volume of papers.</p><p>Both the Black Spatula Project and YesNoError use large language models (LLMs) to spot a range of errors in papers, including ones of fact as well as in calculations, methodology and referencing.</p><p>The systems first extract information, including tables and images, from the papers. They then craft a set of complex instructions, known as a prompt, which tells a ‘reasoning’ model — a specialist type of LLM — what it is looking at and what kinds of error to hunt for. The model might analyse a paper multiple times, either scanning for different types of error each time, or to cross-check results. The cost of analysing each paper ranges from 15 cents to a few dollars, depending on the length of the paper and the series of prompts used.</p><p>The rate of false positives, instances when the AI claims an error where there is none, is a major hurdle. Currently, the Black Spatula Project’s system is wrong about an error around 10% of the time, says Gulloso. Each alleged error must be checked with experts in the subject, and finding them is the project’s greatest bottleneck, says Steve Newman, the software engineer and entrepreneur who founded the Black Spatula Project.</p><p>So far, Schlicht’s YesNoError team has quantified the false positives in only around 100 mathematical errors that the AI found in an initial batch of 10,000 papers. Of the 90% of authors who responded to Schlicht, all but one agreed that the error detected was valid, he says. Eventually, YesNoError is planning to work with ResearchHub, a platform which pays PhD scientists in cryptocurrency to carry out peer review. When the AI has checked a paper, YesNoError will trigger a request to verify the results, although this has not yet started.</p><h2>False positives</h2></div></div>
  </body>
</html>
