<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://nickb.dev/blog/authoring-a-simd-enhanced-wasm-library-with-rust">Original</a>
    <h1>Authoring a SIMD enhanced WASM library with Rust</h1>
    
    <div id="readability-page-1" class="page"><div>
        <div><figure>
    <picture>
      <source type="image/webp" srcset="/blog/authoring-a-simd-enhanced-wasm-library-with-rust/_hu04b13395660f07a1ab8af6cb1e5e72ae_188736_b255b5f9bedbfbd7d7fe273ea6d7bfba.webp 148w, /blog/authoring-a-simd-enhanced-wasm-library-with-rust/_hu04b13395660f07a1ab8af6cb1e5e72ae_188736_eef13d9297d1f8026194eeba0fde4810.webp 295w, /blog/authoring-a-simd-enhanced-wasm-library-with-rust/_hu04b13395660f07a1ab8af6cb1e5e72ae_188736_3bc680a0f4d48dd69150fddc07db105e.webp 590w, /blog/authoring-a-simd-enhanced-wasm-library-with-rust/_hu04b13395660f07a1ab8af6cb1e5e72ae_188736_61d0c2f58d3ead41cfd29667537451f5.webp 900w" sizes="(max-width: 180px) 148px, (max-width: 320px) 295px, (max-width: 610px) 590px, 900px"/>

      <img src="https://nickb.dev/blog/authoring-a-simd-enhanced-wasm-library-with-rust/banner.32eb8972df13da67ca44a015e02ae9432fdc687d6867ddf9b912e5ae0d2a70d2.jpg" alt="" srcset="/blog/authoring-a-simd-enhanced-wasm-library-with-rust/_hu04b13395660f07a1ab8af6cb1e5e72ae_188736_17c11bbbfeb66361184bc3872e10c468.jpg 148w, /blog/authoring-a-simd-enhanced-wasm-library-with-rust/_hu04b13395660f07a1ab8af6cb1e5e72ae_188736_2a1e23ad3d307d9d1eb466f7f75ecded.jpg 295w, /blog/authoring-a-simd-enhanced-wasm-library-with-rust/_hu04b13395660f07a1ab8af6cb1e5e72ae_188736_ac3cbda33d6d9d11cc931b55bfc045fa.jpg 590w, /blog/authoring-a-simd-enhanced-wasm-library-with-rust/_hu04b13395660f07a1ab8af6cb1e5e72ae_188736_f953955749cf32b68c97c1eaf008ca3d.jpg 900w" sizes="(max-width: 180px) 148px, (max-width: 320px) 295px, (max-width: 610px) 590px, 900px" width="1000" height="424"/>
  </picture>

</figure>
          <p><span>Published on: <time datetime="2021-12-13">December 13, 2021</time></span></p><p>Chrome, Firefox, and Node LTS have all stabilized the <a href="https://github.com/WebAssembly/simd/blob/a78b98a6899c9e91a13095e560767af6e99d98fd/proposals/simd/SIMD.md">SIMD extension to Wasm</a> in the last few months (Safari is lagging at the time of writing. See the <a href="https://webassembly.org/roadmap/">updated roadmap</a> for changes). Additionally, Rust has <a href="https://blog.rust-lang.org/2021/07/29/Rust-1.54.0.html#wasm32-intrinsics-stabilized">stabilized Wasm SIMD intrinsics recently too</a>. All the pieces are set and now is the time to start authoring libraries that take advantage of the promised performance that SIMD can bring.</p>
<p>I’m biased, but I believe that Rust is the best language to be authoring Wasm libraries, as Rust tends to produce the smallest and the fastest Wasm payload in the shortest amount of development time. In this post, we’ll be enhancing <a href="https://github.com/nickbabcock/highway-rs">the Rust port</a> of <a href="https://github.com/google/highwayhash">Google’s HighwayHash</a>, which already uses SIMD on x86, by leveraging SIMD instructions on Wasm too.</p>
<h2 id="phase-1-add-wasm-instructions">Phase 1: Add Wasm Instructions</h2>
<p>The Wasm SIMD extension adds instructions to operate on 128 bits at once. Luckily for me the x86 SSE 4.1 implementation of HighwayHash also executes with 128 bit registers, so a good chunk of the work was simple translations. For instance, to add two 64 bit integers, the x86 <code>_mm_add_epi64</code> instruction is equivalent to Rust’s <code>wasm32::u64x2_add</code> (and Wasm’s <code>i64x2.add</code>).</p>
<p>But not every instruction has a 1:1 mapping between these architectures, so the first step was to compile a list of x86 instructions that I’d need to emulate. A good example of this is <a href="https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html#text=_mm_mul_epu32&amp;ig_expand=112,4915"><code>_mm_mul_epu32</code></a>. The below is the Wasm equivalent:</p>
<div><pre><code data-lang="rust"><span>#[target_feature(enable = </span><span>&#34;simd128&#34;</span><span>)]</span>
<span>fn</span> <span>_mm_mul_epu32</span>(a: <span>wasm32</span>::v128, b: <span>wasm32</span>::v128) -&gt; <span>wasm32</span>::v128 {
    <span>let</span> mask <span>=</span> wasm32::u32x4(<span>0xFFFF_FFFF</span>, <span>0</span>, <span>0xFFFF_FFFF</span>, <span>0</span>);
    <span>let</span> lo_a_0 <span>=</span> wasm32::v128_and(a, mask);
    <span>let</span> lo_b_0 <span>=</span> wasm32::v128_and(b, mask);
    wasm32::u64x2_mul(lo_a_0, lo_b_0)
}
</code></pre></div><p>No worries if your eyes glazed while reading. I know I pored over <a href="https://www.intel.com/content/www/us/en/docs/intrinsics-guide/index.html">Intel’s intrinsic guide</a> and Rust’s <a href="https://doc.rust-lang.org/stable/core/arch/wasm32/index.html">wasm32 module</a> to arrive at the above solution. Unit tests helped immensely to understand the desired behavior, as the documentation around each instruction can be lacking. Below is one such Wasm unit test that I created after verifying results on x86.</p>
<div><pre><code data-lang="rust"><span>#[wasm_bindgen_test]</span>
<span>fn</span> <span>test_mm_mul_epu32</span>() {
    <span>let</span> x <span>=</span> wasm32::u64x2(<span>0x0264_432C_CD8A_70E0</span>, <span>0x0B28_E3EF_EBB3_172D</span>);
    <span>let</span> y <span>=</span> wasm32::u64x2(<span>0x0B28_E3EF_EBB3_172D</span>, <span>0x0264_432C_CD8A_70E0</span>);
    <span>let</span> z <span>=</span> _mm_mul_epu32(x, y);
    assert_eq<span>!</span>(as_arr(z), [<span>0xBD3D_E006_1E19_F760</span>, <span>0xBD3D_E006_1E19_F760</span>]);
}
</code></pre></div><h3 id="toolchain-considerations">Toolchain Considerations</h3>
<p>Due to Wasm SIMD not being ubiquitous, one must plan on supporting environments where SIMD is enabled or disabled. A major roadblock, however; is that one can’t embed Wasm logic to selectively run SIMD workloads, as Wasm lacks <a href="https://doc.rust-lang.org/stable/core/arch/wasm32/index.html#simd">dynamic feature detection</a>. The issue goes even deeper as the mere presence of SIMD instructions (even if not executed) can cause headaches. Trying to compile our Wasm module on Node 14 will result in failure:</p>
<div><pre><code data-lang="plain">failed: invalid value type &#39;Simd128&#39;, enable with --experimental-wasm-simd
</code></pre></div><p>Executing with node with <code>--experimental-wasm-simd</code> is easy, but the message is clear: we must allow downstream users the choice whether to include these Wasm SIMD instructions. My solution is to store usage of Wasm SIMD in a module that is conditionally compiled.</p>
<div><pre><code data-lang="rust"><span>#[cfg(all(
</span><span>    target_family = </span><span>&#34;wasm&#34;</span><span>, 
</span><span>    target_feature = </span><span>&#34;simd128&#34;</span><span>
</span><span>))]</span>
<span>mod</span> wasm;
</code></pre></div><p>The good news from this conditional compilation is that we no longer need the <code>target_feature</code> annotation on functions, and so those will be omitted in subsequent examples. The tradeoff is that downstream users will to remember to add a compiler flag if they want Wasm SIMD:</p>
<div><pre><code data-lang="bash">FLAGS<span>=</span><span>&#34;-C target-feature=+simd128&#34;</span>
RUSTFLAGS<span>=</span><span>&#34;</span>$FLAGS<span>&#34;</span> cargo build --target wasm32-unknown-unknown
</code></pre></div><p>On the testing front, tests are written with <a href="https://rustwasm.github.io/wasm-bindgen/wasm-bindgen-test/usage.html"><code>wasm-bindgen-test</code></a>, and are executed with <a href="https://github.com/rustwasm/wasm-pack"><code>wasm-pack</code></a>:</p>
<div><pre><code data-lang="bash">FLAGS<span>=</span><span>&#34;-C target-feature=+simd128&#34;</span>
RUSTFLAGS<span>=</span><span>&#34;</span>$FLAGS<span>&#34;</span> wasm-pack test --node
</code></pre></div><p>The biggest caveat with running and writing Wasm tests is that <code>panic!</code> print is the most conducive way to debug.</p>
<h3 id="more-translation-examples">More Translation Examples</h3>
<p>Before moving onto the next part, I’ve included a few more examples of how x86 and WASM SIMD compare. A large disclaimer here is that I am not well versed on SIMD (much less a Wasm SIMD), so the translations are almost certainly sub-optimal. So if something catches your eye, feel free to email me (at bottom) or better yet, <a href="https://github.com/nickbabcock/highway-rs">send a pull request</a>.</p>
<p>One thing I’ve noticed is that I use shuffle in Wasm like a hammer and everything is a nail:</p>
<div><pre><code data-lang="rust"><span>/// Shift left 8 bytes (aka _mm_bslli_si128 8)
</span><span></span><span>fn</span> <span>_mm_slli_si128_8</span>(a: <span>wasm32</span>::v128) -&gt; <span>wasm32</span>::v128 {
    <span>let</span> zero <span>=</span> wasm32::u64x2(<span>0</span>, <span>0</span>);
    wasm32::u64x2_shuffle::<span>&lt;</span><span>1</span>, <span>2</span><span>&gt;</span>(a, zero)
}
</code></pre></div><p>Here comes a function for rotating bytes, which contain a couple oddities.</p>
<div><pre><code data-lang="rust"><span>/// Rotate 4 bytes to the left
</span><span></span><span>fn</span> <span>rotate_4</span>(a: <span>wasm32</span>::v128) -&gt; <span>wasm32</span>::v128 {
    <span>let</span> ignored <span>=</span> wasm32::u64x2(<span>0</span>, <span>0</span>);
    wasm32::u32x4_shuffle::<span>&lt;</span><span>1</span>, <span>0</span>, <span>3</span>, <span>2</span><span>&gt;</span>(a, ignored)
}
</code></pre></div><p>The first oddity is that we’re allocating an unused variable, as shuffle requires two inputs even if one is only used. Perhaps <a href="https://doc.rust-lang.org/stable/core/arch/wasm32/fn.i8x16_swizzle.html">swizzle</a> is better here. I’m not sure, as I’ve yet to setup a Wasm benchmark harness.</p>
<p>Another oddity, but one that isn’t immediately obvious, is that lane positioning of Wasm and x86 are opposites. The equivalent x86 function would be:</p>
<div><pre><code data-lang="rust"><span>#[target_feature(enable = </span><span>&#34;sse4.1&#34;</span><span>)]</span>
<span>pub</span> <span>unsafe</span> <span>fn</span> <span>rotate_4</span>(a: <span>__m128i</span>) -&gt; <span>__m128i</span> {
    _mm_shuffle_epi32(a, _mm_shuffle<span>!</span>(<span>2</span>, <span>3</span>, <span>0</span>, <span>1</span>))
}
</code></pre></div><p>So the lane positioning went from <code>[1, 0, 3, 2]</code> to <code>[2, 3, 0, 1]</code>. Bizarre, but something to be aware of.</p>
<h2 id="phase-2-ergonomic-js-wrapper">Phase 2: Ergonomic JS Wrapper</h2>
<p>Our Rust library can be published, but it’s not ergonomic in a JS environment, so the next step is to wrap it up in a NPM package. If you are interested in the end result and nitty gritty build details, you can examine <a href="https://github.com/nickbabcock/highwayhasher"><code>highwayhasher</code></a>, which has its <a href="https://nickb.dev/blog/leveraging-rust-to-bundle-node-native-modules-and-wasm-into-an-isomorphic-npm-package/">own explanatory post</a>. Be warned, it’s even more complicated as that package is an isomorphic hashing API over Wasm and node native modules, which itself abstracts over x86 SIMD and a portable implementation. And we’re about to make it even more complicated by adding Wasm SIMD to the mix.</p>
<p>Phew. Let’s break down what we need to do.</p>
<p>The first step is to bundle two Wasm implementations into the distributable, one with SIMD enabled and one without. We can’t have a single implementation, else older Wasm compilers can choke even if the SIMD instruction is unused. One way to achieve this is to have two separate Wasm crates, but my preference is to consolidate the logic in one place and use conditional compilation.</p>
<div><pre><code data-lang="rust"><span>#[cfg(target_feature = </span><span>&#34;simd128&#34;</span><span>)]</span>
<span>type</span> <span>MyHasher</span> <span>=</span> highway::WasmHash;

<span>#[cfg(not(target_feature = </span><span>&#34;simd128&#34;</span><span>))]</span>
<span>type</span> <span>MyHasher</span> <span>=</span> highway::PortableHash;
</code></pre></div><p>Now use <code>wasm-pack</code> to generate both our packages, but output them to separate directories.</p>
<div><pre><code data-lang="bash">wasm-pack build -t web --out-dir ../src/web web

FLAGS<span>=</span><span>&#34;-C target-feature=+simd128&#34;</span>
RUSTFLAGS<span>=</span><span>&#34;</span>$FLAGS<span>&#34;</span> wasm-pack build -t web --out-dir ../src/web-simd web
</code></pre></div><p>Except the above will fail due to <code>wasm-pack</code> invoking an <a href="https://github.com/rustwasm/wasm-pack/blob/ae10c23cc14b79ed37a7be222daf5fd851b9cd0d/src/wasm_opt.rs#L71">old version of wasm-opt</a> that was released a couple years ago that does not understand the new SIMD extension:</p>
<div><pre><code data-lang="plain">[parse exception: bad local.get index (at 0:769)]
Fatal: error in parsing input
</code></pre></div><p>The solution is to disable the <code>wasm-opt</code> portion of <code>wasm-pack</code>:</p>
<div><pre><code data-lang="toml">[<span>package</span>.<span>metadata</span>.<span>wasm</span><span>-</span><span>pack</span>.<span>profile</span>.<span>release</span>]
<span>wasm</span><span>-</span><span>opt</span> = <span>false</span>
</code></pre></div><p>Newer versions of <a href="https://github.com/WebAssembly/binaryen">binaryen</a>, and by extension <code>wasm-opt</code>, support the SIMD extension, so one can elect to invoke their own <code>wasm-opt</code> installed out of band.</p>
<p>If I can get on a soapbox for a moment: <code>wasm-pack</code> should have corporate sponsors. There’s a significant amount of issues and updates that need tending to. Since no alternative has presented itself, every time I revisit <code>wasm-pack</code> I’m pained by new potholes that have risen due to neglect. It’s not a great experience, and makes me feel silly extolling Rust for Wasm when the toolchain is suffering from neglect. Even <code>wasm-bindgen</code>, the glue that binds everything together, could have a <a href="https://github.com/rustwasm/wasm-bindgen/pull/2672#issuecomment-920143781">looming maintenance crisis</a>. Rust and Wasm has proven itself to be an invaluable combination and I believe they should get the support they deserve.</p>
<p>Back at our code, we have our two Wasm modules that we now have to choose the appropriate one to load. The check if SIMD is enabled is intuitive: Wasm SIMD is enabled if it is possible to compile the smallest Wasm program with SIMD instructions. This is exactly what <a href="https://github.com/GoogleChromeLabs/wasm-feature-detect"><code>wasm-feature-detect</code></a> does and we can inline that logic with a couple of embellishments to cache the results.</p>
<div><pre><code data-lang="ts"><span>let</span> <span>simdEnabled</span>: <span>boolean</span> <span>|</span> <span>undefined</span>;
<span>const</span> <span>hasSimd</span> <span>=</span> () <span>=&gt;</span>
  <span>simdEnabled</span> <span>??</span>
  (<span>simdEnabled</span> <span>=</span> <span>WebAssembly</span>.<span>validate</span>(
    <span>new</span> <span>Uint8Array</span>([
      <span>0</span>, <span>97</span>, <span>115</span>, <span>109</span>, <span>1</span>, <span>0</span>, <span>0</span>, <span>0</span>, <span>1</span>, <span>5</span>, <span>1</span>, <span>96</span>, <span>0</span>, <span>1</span>, <span>123</span>, <span>3</span>, <span>2</span>, <span>1</span>, <span>0</span>, <span>10</span>, <span>10</span>,
      <span>1</span>, <span>8</span>, <span>0</span>, <span>65</span>, <span>0</span>, <span>253</span>, <span>15</span>, <span>253</span>, <span>98</span>, <span>11</span>,
    ])
  ));
</code></pre></div><p>And finally we need to import our JS-Wasm glue code. This may look different depending on the build step of your library.</p>
<div><pre><code data-lang="ts"><span>import</span> <span>init</span>, { <span>WasmHighway</span> } <span>from</span> <span>&#34;./wasm/highwayhasher_wasm&#34;</span>;
<span>import</span> <span>simdInit</span>, {
  <span>WasmHighway</span> <span>as</span> <span>WasmSimdHighway</span>,
} <span>from</span> <span>&#34;./wasm-simd/highwayhasher_wasm&#34;</span>;
<span>import</span> <span>wasm</span> <span>from</span> <span>&#34;./wasm/highwayhasher_wasm_bg.wasm&#34;</span>;
<span>import</span> <span>wasmSimd</span> <span>from</span> <span>&#34;./wasm-simd/highwayhasher_wasm_bg.wasm&#34;</span>;
</code></pre></div><p>Notes:</p>
<ul>
<li>Even though the contents of <code>highwayhasher_wasm.js</code> are identical between the implementations we need to import them both, as the glue code contains module level global variables that would otherwise get clobbered if a client ever decided to toggle SIMD hashing at runtime.</li>
<li>The Wasm payloads are included as part of the JS build as base64 encoded. I’m a supporter of this method as I believe a library’s use of Wasm should be an implementation detail and thus inlined into a library’s distribution. There’s no need for downstream users to figure out how to fetch the Wasm code at runtime, nor worry about if the CDN can properly cache it due to the relatively esoteric <code>.wasm</code> extension. The downside of inlining is that our library is now 2x larger and the application developer is unable to reverse the inlining decision.</li>
</ul>
<p>And for completeness sake, here is how everything comes together:</p>
<div><pre><code data-lang="ts"><span>let</span> <span>wasmInitialized</span> <span>=</span> <span>false</span>;
<span>let</span> <span>wasmSimdInitialized</span> <span>=</span> <span>false</span>;
<span>const</span> <span>loadWasmSimd</span> <span>=</span> <span>async</span> () <span>=&gt;</span> {
  <span>if</span> (<span>!</span><span>wasmSimdInitialized</span>) {
    <span>await</span> <span>simdInit</span>(<span>wasmSimd</span>());
    <span>wasmSimdInitialized</span> <span>=</span> <span>true</span>;
  }
};

<span>const</span> <span>loadWasm</span> <span>=</span> <span>async</span> () <span>=&gt;</span> {
  <span>if</span> (<span>!</span><span>wasmInitialized</span>) {
    <span>await</span> <span>init</span>(<span>wasm</span>());
    <span>wasmInitialized</span> <span>=</span> <span>true</span>;
  }
};

<span>export</span> <span>const</span> <span>loadModule</span> <span>=</span> <span>async</span> () <span>=&gt;</span> {
  <span>if</span> (<span>!</span><span>hasSimd</span>()) {
    <span>await</span> <span>loadWasm</span>();
    <span>return</span> <span>WasmHighway</span>;
  } <span>else</span> {
    <span>await</span> <span>loadWasmSimd</span>();
    <span>return</span> <span>WasmSimdHighway</span>;
  }
}
</code></pre></div><p>Now the fun stuff: benchmarking</p>
<h2 id="phase-3-benchmarks">Phase 3: Benchmarks</h2>
<p>The highwayhasher repo <a href="https://github.com/nickbabcock/highwayhasher/tree/master/bench">contains a crude benchmark</a> that pits the new Wasm SIMD against the scalar implementation and also against x86 SIMD via node native modules.</p>
<p>The results is that the performance of the SIMD implementation varies depending on the payload size:</p>
<ul>
<li>x &lt; 100: Equivalent hashing throughput.</li>
<li>100 &lt; x &lt; 1000: Wasm SIMD starts pulling away with 1.5x the throughput. Wasm SIMD even bests x86 SIMD due to the overhead of N-API calls.</li>
<li>1000 &lt; x &lt; 10000: Native code is fastest, but Wasm SIMD increases lead over the scalar implementation to 2x.</li>
<li>x &gt; 10000: Wasm SIMD speedup plateaus at 3x, is 4x slower than x86 SIMD.</li>
</ul>
<p>A 3x speedup for Wasm use cases is a significant improvement, but it still falls significantly short of native performance. Further improvement could come from better translations of x86 instructions, or maybe all that is needed is time for browsers to further optimize their Wasm runtime.</p>
<h3 id="cloudflare-workers-vs-fastly-ce">Cloudflare Workers vs Fastly C@E</h3>
<p>Time to add fuel <a href="https://news.ycombinator.com/item?id=29467075">to the fire</a>. I kid, but both Cloudflare Workers and Fastly’s Compute@Edge allow Wasm to be executed on the edge, and I’m curious if Wasm SIMD is available on these platforms and what type of performance one can receive.</p>
<p>Our goal is to have an endpoint that will ingest a request body and respond with the 64bit hash.</p>
<p>On Cloudflare, my intuition led me to first write a JS worker so that I can use the <a href="https://developers.cloudflare.com/workers/learning/using-streams">Streams API</a> to incrementally hash the body without worrying about buffering. Regrettably, while Cloudflare’s platform is detected as Wasm SIMD enabled (our <code>hasSimd</code> function from earlier returns true), one is not allowed to compile Wasm. The following error is returned:</p>
<blockquote>
<p>Wasm code generation disallowed by embedder</p>
</blockquote>
<p>This error highlights <a href="https://nickb.dev/blog/reality-check-for-cloudflare-wasm-workers-and-rust/">another reality check</a> for the platform. To be fair the fault isn’t solely Cloudflare’s. One can deploy and run Wasm on Workers in a standards compliant fashion (see <a href="https://github.com/nickbabcock/cloud-brotli">my example repo</a> of running brotli compression on JS). The first step is to upload Wasm as separate files <a href="https://developers.cloudflare.com/workers/cli-wrangler/configuration#modules">configured as <code>CompiledWasm</code></a>. The trick; however, is that importing Wasm on a worker returns a <a href="https://developer.mozilla.org/en-US/docs/Web/JavaScript/Reference/Global_Objects/WebAssembly/Module"><code>WebAssembly.Module</code></a>, meaning that in the background, Cloudflare did the heavy lifting by compiling the Wasm and giving us the results. This is theoretically great as it saves us from recompiling the Wasm on every request, but developer experience needs improving as I’m not familiar with any JS bundler that understands this behavior. I hope to create a separate post to dive into the details and see if there’s a way we can ergonomically solve these problems.</p>
<p>The alternative is to target their Rust SDK, which still compiles to Wasm at the end of the day, but has fewer developer experience kinks. The main trade off is that the entire request body is buffered in memory.</p>
<div><pre><code data-lang="rust"><span>#[event(fetch)]</span>
<span>pub</span> <span>async</span> <span>fn</span> <span>main</span>(<span>mut</span> req: <span>Request</span>, _env: <span>Env</span>) -&gt; Result<span>&lt;</span>Response<span>&gt;</span> {
    <span>let</span> data <span>=</span> req.bytes().<span>await</span><span>?</span>;
    <span>let</span> hash <span>=</span> WasmHash::force_new(Key::default());
    <span>let</span> result <span>=</span> hash.hash64(data.as_slice());
    Ok(Response::ok(format<span>!</span>(<span>&#34;{}&#34;</span>, result)).unwrap())
}
</code></pre></div><p>Since Cloudflare uses <code>wasm-pack</code> we need to disable the bundled and outdated <code>wasm-opt</code> in our <code>Cargo.toml</code></p>
<div><pre><code data-lang="toml">[<span>package</span>.<span>metadata</span>.<span>wasm</span><span>-</span><span>pack</span>.<span>profile</span>.<span>release</span>]
<span>wasm</span><span>-</span><span>opt</span> = <span>false</span>
</code></pre></div><p>A deploy and a quick test later and we’re off to evaluate Fastly.</p>
<p>With Fastly, their JS compute platform is in beta, so we’ll use their Wasm platform and compile our function in Rust to Wasm. Testing showed that, unfortunately for Fastly, their platform does not support Wasm SIMD, as publishing anything with the <code>simd128</code> feature enabled results in an error:</p>
<div><pre><code data-lang="plain">ERROR: Function translation error
// ...
Warning: No default director found
</code></pre></div><p>So we have to go with the portable implementation, which at the very least is beautifully succinct.</p>
<div><pre><code data-lang="rust"><span>#[fastly::main]</span>
<span>fn</span> <span>main</span>(<span>mut</span> req: <span>Request</span>) -&gt; Result<span>&lt;</span>Response, Error<span>&gt;</span> {
    <span>let</span> <span>mut</span> body <span>=</span> req.take_body();
    <span>let</span> <span>mut</span> hasher <span>=</span> PortableHash::new(Key::default());
    std::io::copy(<span>&amp;</span><span>mut</span> body, <span>&amp;</span><span>mut</span> hasher).unwrap();
    <span>let</span> result <span>=</span> hasher.finalize64();
    <span>let</span> resp <span>=</span> Response::from_status(StatusCode::OK)
        .with_body_text_plain(<span>&amp;</span>format<span>!</span>(<span>&#34;{}&#34;</span>, result));
    Ok(resp)
}
</code></pre></div><p>After confirming Cloudflare and Fastly give the same results, I decided to post a 5 MB file and time the duration between when the request’s first byte is sent and the response is finished downloading. The informal benchmark was run several times, averaged, and then rounded. The results:</p>
<ul>
<li>250ms Cloudflare</li>
<li>200ms Fastly</li>
</ul>
<p>Fastly eeks out a small win, though Cloudflare has the disadvantage of buffering everything, so I’d hazard a guess that optimal deployments will result in equivalent performance.</p>
<p>Though if I am to be completely honest, I see potential performance improvements for both platforms. I’ve done other compute heavy benchmarks on both, and every time I’ve been left wanting. Of course, performance latency is but a small price for globally scalable and infinitely scalable compute.</p>
<h3 id="neon-through-wasm">Neon through Wasm</h3>
<p>Here’s a fun experiment. ARM Neon instructions aren’t yet stable in Rust, but when our Wasm SIMD instructions are executed on ARM, they will be translated into Neon. This begs the question, what’s faster: the native module that isn’t optimized for Neon or Wasm SIMD.</p>
<p>To find out, I took an AWS Graviton2 instance for a spin. And wow, I always forget how uncommon it is to see prebuilt binaries for aarch64 or how some projects flat out don’t support ARM. After several minutes of compilation I was able to and rerun the benchmark and get the following results:</p>
<div><pre><code data-lang="plain">hashing data of size: 100000000
native 897.46 MB/s
wasm simd 1481.42 MB/s
wasm scalar 671.55 MB/s
</code></pre></div><p>The Wasm SIMD implementation is 65% faster than native! But what is perhaps more interesting is that the Wasm scalar implementation is only half as fast as the Wasm SIMD version instead of the 3x seen on x86. Perhaps v8 doesn’t have enough optimizations on the Wasm SIMD to Neon front.</p>
<p>Even though I benchmarked multiple times, take the results with a grain of sand, as benchmarking on a VPS can be unreliable.</p>
<h2 id="conclusion">Conclusion</h2>
<p>Main takeaways:</p>
<ul>
<li>Chrome, Firefox, and Node LTS now support Wasm SIMD, so one can start catering to these users</li>
<li>While there isn’t always a 1:1 mapping between Wasm and x86 SIMD instructions, for my purposes the x86 instructions have been emulated without needing to drop to scalar operations</li>
<li>With no SIMD detection at runtime inside Wasm, one must include both Wasm bundles in a library and run the detection externally</li>
<li>One needs to disable the integrated <code>wasm-opt</code> in <code>wasm-pack</code> and instead manually install a recent version of <code>wasm-opt</code> that understands Wasm SIMD</li>
<li>Performance improvement is around 3x compared to scalar Wasm, but one shouldn’t replace native modules just yet, except on platforms where Wasm SIMD is able to utilize the underlying SIMD hardware and the native module can’t (ie: ARM Neon).</li>
<li>Fastly doesn’t support Wasm SIMD and Cloudflare has several caveats (either poor developer experience with Wasm in JS or limitations faced by the Rust SDK).</li>
<li>I embed Wasm as base64 encoded in the library in an attempt to make Wasm usage transparent, but in the future I may need multiple entrypoints so that users can specify how they’ll be loading Wasm at build time.</li>
</ul>

          <div>
          <h2>Comments</h2>
            <p>If you&#39;d like to leave a comment, please email hi@nickb.dev</p> 
            </div>
        </div>
      </div></div>
  </body>
</html>
