<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://swe-to-mle.pages.dev/posts/gan-wgan-and-instance-noise/">Original</a>
    <h1>GAN, WGAN, and Instance Noise</h1>
    
    <div id="readability-page-1" class="page"><div id="content"><p><em>The Mirror of Life Trapping, a relic of ancient magic, ensnares the souls of those who dare gaze upon its deceptive surface. Within its mystical depths, trapped spirits linger, awaiting release or eternal confinement.</em></p>
<figure><a href="https://swe-to-mle.pages.dev/posts/gan-wgan-and-instance-noise/mirror-of-life-trapping.png" title="mirror-of-life-trapping" data-thumbnail="mirror-of-life-trapping.png" data-sub-html="&lt;h2&gt;Mirror of Life Trapping&lt;/h2&gt;&lt;p&gt;mirror-of-life-trapping&lt;/p&gt;">
        <img src="https://swe-to-mle.pages.dev/svg/loading.min.svg" data-src="mirror-of-life-trapping.png" data-srcset="mirror-of-life-trapping.png, mirror-of-life-trapping.png 1.5x, mirror-of-life-trapping.png 2x" data-sizes="auto" alt="mirror-of-life-trapping.png"/>
    </a><figcaption>Mirror of Life Trapping</figcaption>
    </figure>
<h2 id="the-quest">The Quest</h2>
<p>Craft a Mirror of Life Trapping. Capture the visual essence of a target.</p>
<h2 id="gan-generative-adversarial-network">GAN (Generative Adversarial Network)</h2>
<p>GAN is an architecture merging two different networks competing with each other:</p>
<ul>
<li>Discriminator: wants to predict if the input is real or fake</li>
<li>Generator: wants to generate fakes indistinguishable from the real ones</li>
</ul>
<figure><a href="https://swe-to-mle.pages.dev/posts/gan-wgan-and-instance-noise/gan.png" title="gan" data-thumbnail="gan.png" data-sub-html="&lt;h2&gt;GAN&lt;/h2&gt;&lt;p&gt;gan&lt;/p&gt;">
        <img src="https://swe-to-mle.pages.dev/svg/loading.min.svg" data-src="gan.png" data-srcset="gan.png, gan.png 1.5x, gan.png 2x" data-sizes="auto" alt="gan.png"/>
    </a><figcaption>GAN</figcaption>
    </figure>
<h3 id="discriminator">Discriminator</h3>
<p>The discriminator is a simple binary classifier. Takes an image, returns a prediction of real / fake.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>class</span> <span>Discriminator</span><span>(</span><span>nn</span><span>.</span><span>Module</span><span>):</span>
</span></span><span><span>    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>):</span>
</span></span><span><span>        <span>super</span><span>()</span><span>.</span><span>__init__</span><span>()</span>
</span></span><span><span>        <span>self</span><span>.</span><span>layers</span> <span>=</span> <span>nn</span><span>.</span><span>Sequential</span><span>(</span>
</span></span><span><span>            <span>nn</span><span>.</span><span>Flatten</span><span>(</span><span>start_dim</span><span>=</span><span>1</span><span>),</span>
</span></span><span><span>            <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>IMG_DIMS</span><span>**</span><span>2</span><span>,</span> <span>HIDDEN_DIMS</span><span>),</span>
</span></span><span><span>            <span>nn</span><span>.</span><span>LeakyReLU</span><span>(</span><span>0.2</span><span>),</span>  <span># supposed to help with mode collapse</span>
</span></span><span><span>            <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>HIDDEN_DIMS</span><span>,</span> <span>HIDDEN_DIMS</span><span>),</span>
</span></span><span><span>            <span>nn</span><span>.</span><span>LeakyReLU</span><span>(</span><span>0.2</span><span>),</span>
</span></span><span><span>            <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>HIDDEN_DIMS</span><span>,</span> <span>1</span><span>),</span>
</span></span><span><span>            <span>nn</span><span>.</span><span>Sigmoid</span><span>()</span>
</span></span><span><span>        <span>)</span>
</span></span><span><span>
</span></span><span><span>    <span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span> <span>image</span><span>):</span>
</span></span><span><span>        <span>return</span> <span>self</span><span>.</span><span>layers</span><span>(</span><span>image</span><span>)</span>
</span></span></code></pre></div><h3 id="generator">Generator</h3>
<p>The generator takes some noise as input because network are deterministic. So in order to produce diverse results we need a source of randomness we can tap from. And produces an image.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>class</span> <span>Generator</span><span>(</span><span>nn</span><span>.</span><span>Module</span><span>):</span>
</span></span><span><span>    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>):</span>
</span></span><span><span>        <span>super</span><span>()</span><span>.</span><span>__init__</span><span>()</span>
</span></span><span><span>        <span>self</span><span>.</span><span>layers</span> <span>=</span> <span>nn</span><span>.</span><span>Sequential</span><span>(</span>
</span></span><span><span>            <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>NOISE_DIMS</span><span>,</span> <span>HIDDEN_DIMS</span><span>),</span>
</span></span><span><span>            <span>nn</span><span>.</span><span>BatchNorm1d</span><span>(</span><span>HIDDEN_DIMS</span><span>),</span>
</span></span><span><span>            <span>nn</span><span>.</span><span>ReLU</span><span>(),</span>
</span></span><span><span>            <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>HIDDEN_DIMS</span><span>,</span> <span>HIDDEN_DIMS</span><span>),</span>
</span></span><span><span>            <span>nn</span><span>.</span><span>BatchNorm1d</span><span>(</span><span>HIDDEN_DIMS</span><span>),</span>
</span></span><span><span>            <span>nn</span><span>.</span><span>ReLU</span><span>(),</span>
</span></span><span><span>            <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>HIDDEN_DIMS</span><span>,</span> <span>HIDDEN_DIMS</span><span>),</span>
</span></span><span><span>            <span>nn</span><span>.</span><span>BatchNorm1d</span><span>(</span><span>HIDDEN_DIMS</span><span>),</span>
</span></span><span><span>            <span>nn</span><span>.</span><span>ReLU</span><span>(),</span>
</span></span><span><span>            <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>HIDDEN_DIMS</span><span>,</span> <span>IMG_DIMS</span><span>**</span><span>2</span><span>),</span>
</span></span><span><span>            <span>nn</span><span>.</span><span>Sigmoid</span><span>(),</span>
</span></span><span><span>            <span>nn</span><span>.</span><span>Unflatten</span><span>(</span><span>1</span><span>,</span> <span>(</span><span>1</span><span>,</span> <span>IMG_DIMS</span><span>,</span> <span>IMG_DIMS</span><span>))</span>
</span></span><span><span>        <span>)</span>
</span></span><span><span>
</span></span><span><span>    <span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span> <span>noise</span><span>):</span>
</span></span><span><span>        <span>return</span> <span>self</span><span>.</span><span>layers</span><span>(</span><span>noise</span><span>)</span>
</span></span></code></pre></div><h3 id="training">Training</h3>
<p>Training is where the magic happens. The discriminator is pretty straightforward. We take real pictures labelled as real, fake pictures made by the generator and label them as fake. And train.</p>
<p>So far so good. But how can we train the generator? The generator is initialized with random weight, fed random noise as a source of entropy and somehow we expect structured realistic outputs?</p>
<p>The idea is to use the discriminator that has seen real pictures and so is learning the properties of real pictures in the chain of gradient for the generator, and backpropagate the knowledge all the way back to the generator.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>def</span> <span>train_gan</span><span>(</span><span>discriminator</span><span>,</span> <span>generator</span><span>,</span> <span>data</span><span>=</span><span>data</span><span>,</span> <span>epochs</span><span>=</span><span>EPOCHS</span><span>,</span> <span>lr</span><span>=</span><span>LEARNING_RATE</span><span>):</span>
</span></span><span><span>    <span>opt_d</span> <span>=</span> <span>torch</span><span>.</span><span>optim</span><span>.</span><span>Adam</span><span>(</span><span>discriminator</span><span>.</span><span>parameters</span><span>(),</span> <span>lr</span><span>=</span><span>lr</span><span>)</span>
</span></span><span><span>    <span>opt_g</span> <span>=</span> <span>torch</span><span>.</span><span>optim</span><span>.</span><span>Adam</span><span>(</span><span>generator</span><span>.</span><span>parameters</span><span>(),</span> <span>lr</span><span>=</span><span>lr</span><span>)</span>
</span></span><span><span>
</span></span><span><span>    <span>for</span> <span>epoch</span> <span>in</span> <span>range</span><span>(</span><span>epochs</span><span>):</span>
</span></span><span><span>        <span>for</span> <span>minibatch</span><span>,</span> <span>_</span> <span>in</span> <span>data</span><span>:</span>
</span></span><span><span>            <span>batch_size</span> <span>=</span> <span>minibatch</span><span>.</span><span>size</span><span>(</span><span>0</span><span>)</span>
</span></span><span><span>            <span>minibatch</span> <span>=</span> <span>minibatch</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>
</span></span><span><span>            <span>real_labels</span> <span>=</span> <span>torch</span><span>.</span><span>ones</span><span>(</span><span>batch_size</span><span>,</span> <span>1</span><span>)</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>
</span></span><span><span>            <span>fake_labels</span> <span>=</span> <span>torch</span><span>.</span><span>zeros</span><span>(</span><span>batch_size</span><span>,</span> <span>1</span><span>)</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>
</span></span><span><span>            <span>noise</span> <span>=</span> <span>torch</span><span>.</span><span>randn</span><span>(</span><span>batch_size</span><span>,</span> <span>NOISE_DIMS</span><span>,</span> <span>device</span><span>=</span><span>device</span><span>)</span>
</span></span><span><span>            <span>fake_images</span> <span>=</span> <span>generator</span><span>(</span><span>noise</span><span>)</span>
</span></span><span><span>
</span></span><span><span>            <span># discriminator</span>
</span></span><span><span>            <span>outputs_real</span> <span>=</span> <span>discriminator</span><span>(</span><span>minibatch</span><span>)</span>
</span></span><span><span>            <span>loss_real</span> <span>=</span> <span>F</span><span>.</span><span>binary_cross_entropy</span><span>(</span><span>outputs_real</span><span>,</span> <span>real_labels</span><span>)</span>
</span></span><span><span>            <span>outputs_fake</span> <span>=</span> <span>discriminator</span><span>(</span><span>fake_images</span><span>.</span><span>detach</span><span>())</span>
</span></span><span><span>            <span>loss_fake</span> <span>=</span> <span>F</span><span>.</span><span>binary_cross_entropy</span><span>(</span><span>outputs_fake</span><span>,</span> <span>fake_labels</span><span>)</span>
</span></span><span><span>            <span>loss_d</span> <span>=</span> <span>loss_real</span> <span>+</span> <span>loss_fake</span>
</span></span><span><span>            <span>discriminator</span><span>.</span><span>zero_grad</span><span>()</span>
</span></span><span><span>            <span>loss_d</span><span>.</span><span>backward</span><span>()</span>
</span></span><span><span>            <span>opt_d</span><span>.</span><span>step</span><span>()</span>
</span></span><span><span>
</span></span><span><span>            <span># generator</span>
</span></span><span><span>            <span>outputs</span> <span>=</span> <span>discriminator</span><span>(</span><span>fake_images</span><span>)</span>
</span></span><span><span>            <span>loss_g</span> <span>=</span> <span>F</span><span>.</span><span>binary_cross_entropy</span><span>(</span><span>outputs</span><span>,</span> <span>real_labels</span><span>)</span>
</span></span><span><span>            <span>generator</span><span>.</span><span>zero_grad</span><span>()</span>
</span></span><span><span>            <span>loss_g</span><span>.</span><span>backward</span><span>()</span>
</span></span><span><span>            <span>opt_g</span><span>.</span><span>step</span><span>()</span>
</span></span></code></pre></div><figure><a href="https://swe-to-mle.pages.dev/posts/gan-wgan-and-instance-noise/train-gan.png" title="train-gan" data-thumbnail="train-gan.png" data-sub-html="&lt;h2&gt;Train the GAN&lt;/h2&gt;&lt;p&gt;train-gan&lt;/p&gt;">
        <img src="https://swe-to-mle.pages.dev/svg/loading.min.svg" data-src="train-gan.png" data-srcset="train-gan.png, train-gan.png 1.5x, train-gan.png 2x" data-sizes="auto" alt="train-gan.png"/>
    </a><figcaption>Train the GAN</figcaption>
    </figure>
<h3 id="the-curse-of-mode-collapse">The curse of Mode Collapse</h3>
<p>Unfortunatly the training can’t be that easy. Not since the grim necromancers of the past corrupted the land with their dark rituals. Mode Collapse is when the generator “collapse” into a single state. Instead of working at learning to generate each sample with equal probability. It’ll specialize, and only generate a few or even a single sample.</p>
<p>In my case if I let it train for too long on MNIST. It collapses and only generate Ones.</p>
<figure><a href="https://swe-to-mle.pages.dev/posts/gan-wgan-and-instance-noise/mode-collapse.png" title="mode-collapse" data-thumbnail="mode-collapse.png" data-sub-html="&lt;h2&gt;Mode Collapse on Ones&lt;/h2&gt;&lt;p&gt;mode-collapse&lt;/p&gt;">
        <img src="https://swe-to-mle.pages.dev/svg/loading.min.svg" data-src="mode-collapse.png" data-srcset="mode-collapse.png, mode-collapse.png 1.5x, mode-collapse.png 2x" data-sizes="auto" alt="mode-collapse.png"/>
    </a><figcaption>Mode Collapse on Ones</figcaption>
    </figure>
<h2 id="instance-noise">Instance Noise</h2>
<p>One way to fight with mode collapse is to introduce noise in the Discriminator. Add a layer of noise to the real and fake images to make them more “similar” so their distributions aren’t so far appart. And so we can have a better gradient to work with.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>def</span> <span>train_gan_instance_noise</span><span>(</span><span>discriminator</span><span>,</span> <span>generator</span><span>,</span> <span>noise_std</span><span>=</span><span>0.1</span><span>,</span> <span>data</span><span>=</span><span>data</span><span>,</span> <span>epochs</span><span>=</span><span>EPOCHS</span><span>,</span> <span>lr</span><span>=</span><span>LEARNING_RATE</span><span>):</span>
</span></span><span><span>    <span>def</span> <span>noisify</span><span>(</span><span>images</span><span>):</span>
</span></span><span><span>        <span>return</span> <span>images</span> <span>+</span> <span>torch</span><span>.</span><span>randn_like</span><span>(</span><span>images</span><span>)</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span> <span>*</span> <span>noise_std</span>
</span></span><span><span>
</span></span><span><span>    <span>opt_d</span> <span>=</span> <span>torch</span><span>.</span><span>optim</span><span>.</span><span>Adam</span><span>(</span><span>discriminator</span><span>.</span><span>parameters</span><span>(),</span> <span>lr</span><span>=</span><span>lr</span><span>)</span>
</span></span><span><span>    <span>opt_g</span> <span>=</span> <span>torch</span><span>.</span><span>optim</span><span>.</span><span>Adam</span><span>(</span><span>generator</span><span>.</span><span>parameters</span><span>(),</span> <span>lr</span><span>=</span><span>lr</span><span>)</span>
</span></span><span><span>
</span></span><span><span>    <span>for</span> <span>epoch</span> <span>in</span> <span>range</span><span>(</span><span>epochs</span><span>):</span>
</span></span><span><span>        <span>for</span> <span>minibatch</span><span>,</span> <span>_</span> <span>in</span> <span>data</span><span>:</span>
</span></span><span><span>            <span>batch_size</span> <span>=</span> <span>minibatch</span><span>.</span><span>size</span><span>(</span><span>0</span><span>)</span>
</span></span><span><span>            <span>minibatch</span> <span>=</span> <span>minibatch</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>
</span></span><span><span>            <span>real_labels</span> <span>=</span> <span>torch</span><span>.</span><span>ones</span><span>(</span><span>batch_size</span><span>,</span> <span>1</span><span>)</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>
</span></span><span><span>            <span>fake_labels</span> <span>=</span> <span>torch</span><span>.</span><span>zeros</span><span>(</span><span>batch_size</span><span>,</span> <span>1</span><span>)</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>
</span></span><span><span>            <span>noise</span> <span>=</span> <span>torch</span><span>.</span><span>randn</span><span>(</span><span>batch_size</span><span>,</span> <span>NOISE_DIMS</span><span>,</span> <span>device</span><span>=</span><span>device</span><span>)</span>
</span></span><span><span>            <span>fake_images</span> <span>=</span> <span>generator</span><span>(</span><span>noise</span><span>)</span>
</span></span><span><span>
</span></span><span><span>            <span># discriminator</span>
</span></span><span><span>            <span>outputs_real</span> <span>=</span> <span>discriminator</span><span>(</span><span>noisify</span><span>(</span><span>minibatch</span><span>))</span>
</span></span><span><span>            <span>loss_real</span> <span>=</span> <span>F</span><span>.</span><span>binary_cross_entropy</span><span>(</span><span>outputs_real</span><span>,</span> <span>real_labels</span><span>)</span>
</span></span><span><span>            <span>outputs_fake</span> <span>=</span> <span>discriminator</span><span>(</span><span>noisify</span><span>(</span><span>fake_images</span><span>.</span><span>detach</span><span>()))</span>
</span></span><span><span>            <span>loss_fake</span> <span>=</span> <span>F</span><span>.</span><span>binary_cross_entropy</span><span>(</span><span>outputs_fake</span><span>,</span> <span>fake_labels</span><span>)</span>
</span></span><span><span>            <span>loss_d</span> <span>=</span> <span>loss_real</span> <span>+</span> <span>loss_fake</span>
</span></span><span><span>            <span>discriminator</span><span>.</span><span>zero_grad</span><span>()</span>
</span></span><span><span>            <span>loss_d</span><span>.</span><span>backward</span><span>()</span>
</span></span><span><span>            <span>opt_d</span><span>.</span><span>step</span><span>()</span>
</span></span><span><span>
</span></span><span><span>            <span># generator</span>
</span></span><span><span>            <span>outputs</span> <span>=</span> <span>discriminator</span><span>(</span><span>fake_images</span><span>)</span>
</span></span><span><span>            <span>loss_g</span> <span>=</span> <span>F</span><span>.</span><span>binary_cross_entropy</span><span>(</span><span>outputs</span><span>,</span> <span>real_labels</span><span>)</span>
</span></span><span><span>            <span>generator</span><span>.</span><span>zero_grad</span><span>()</span>
</span></span><span><span>            <span>loss_g</span><span>.</span><span>backward</span><span>()</span>
</span></span><span><span>            <span>opt_g</span><span>.</span><span>step</span><span>()</span>
</span></span></code></pre></div><figure><a href="https://swe-to-mle.pages.dev/posts/gan-wgan-and-instance-noise/noise.png" title="noise" data-thumbnail="noise.png" data-sub-html="&lt;h2&gt;Train with noise&lt;/h2&gt;&lt;p&gt;noise&lt;/p&gt;">
        <img src="https://swe-to-mle.pages.dev/svg/loading.min.svg" data-src="noise.png" data-srcset="noise.png, noise.png 1.5x, noise.png 2x" data-sizes="auto" alt="noise.png"/>
    </a><figcaption>Train with noise</figcaption>
    </figure>
<figure><a href="https://swe-to-mle.pages.dev/posts/gan-wgan-and-instance-noise/noise-loss.png" title="noise-loss" data-thumbnail="noise-loss.png" data-sub-html="&lt;h2&gt;Losses when training with noise for a long time&lt;/h2&gt;&lt;p&gt;noise-loss&lt;/p&gt;">
        <img src="https://swe-to-mle.pages.dev/svg/loading.min.svg" data-src="noise-loss.png" data-srcset="noise-loss.png, noise-loss.png 1.5x, noise-loss.png 2x" data-sizes="auto" alt="noise-loss.png"/>
    </a><figcaption>Losses when training with noise for a long time</figcaption>
    </figure>
<h2 id="wgan-wasserstein-generative-adversarial-network">WGAN (Wasserstein Generative Adversarial Network)</h2>
<p>Another way is to somehow force the gradient to have a bounded slope so we avoid getting into the long tail of the derivative. One way to achieve that is to clip the values of the weights in the network. This will cause the network to learn slower so we also need to give more iterations to the discriminator to compensate for it. It also forces us to get rid of Adam because the momentum is causing problems.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>def</span> <span>train_wgan</span><span>(</span><span>discriminator</span><span>,</span> <span>generator</span><span>,</span> <span>clip_threshold</span><span>=</span><span>0.01</span><span>,</span> <span>extra_discriminator_training</span><span>=</span><span>10</span><span>,</span> <span>data</span><span>=</span><span>data</span><span>,</span> <span>epochs</span><span>=</span><span>EPOCHS</span><span>,</span> <span>lr</span><span>=</span><span>LEARNING_RATE</span><span>):</span>
</span></span><span><span>    <span>opt_d</span> <span>=</span> <span>torch</span><span>.</span><span>optim</span><span>.</span><span>RMSprop</span><span>(</span><span>discriminator</span><span>.</span><span>parameters</span><span>(),</span> <span>lr</span><span>=</span><span>lr</span><span>)</span>
</span></span><span><span>    <span>opt_g</span> <span>=</span> <span>torch</span><span>.</span><span>optim</span><span>.</span><span>RMSprop</span><span>(</span><span>generator</span><span>.</span><span>parameters</span><span>(),</span> <span>lr</span><span>=</span><span>lr</span><span>)</span>
</span></span><span><span>
</span></span><span><span>    <span>for</span> <span>epoch</span> <span>in</span> <span>range</span><span>(</span><span>epochs</span><span>):</span>
</span></span><span><span>        <span>for</span> <span>minibatch</span><span>,</span> <span>_</span> <span>in</span> <span>data</span><span>:</span>
</span></span><span><span>            <span>batch_size</span> <span>=</span> <span>minibatch</span><span>.</span><span>size</span><span>(</span><span>0</span><span>)</span>
</span></span><span><span>            <span>minibatch</span> <span>=</span> <span>minibatch</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>
</span></span><span><span>            <span>noise</span> <span>=</span> <span>torch</span><span>.</span><span>randn</span><span>(</span><span>batch_size</span><span>,</span> <span>NOISE_DIMS</span><span>,</span> <span>device</span><span>=</span><span>device</span><span>)</span>
</span></span><span><span>            <span>fake_images</span> <span>=</span> <span>generator</span><span>(</span><span>noise</span><span>)</span>
</span></span><span><span>
</span></span><span><span>            <span># discriminator</span>
</span></span><span><span>            <span>for</span> <span>_</span> <span>in</span> <span>range</span><span>(</span><span>extra_discriminator_training</span><span>):</span>
</span></span><span><span>                <span>outputs_real</span> <span>=</span> <span>discriminator</span><span>(</span><span>minibatch</span><span>)</span>
</span></span><span><span>                <span>outputs_fake</span> <span>=</span> <span>discriminator</span><span>(</span><span>fake_images</span><span>.</span><span>detach</span><span>())</span>
</span></span><span><span>                <span>loss_d</span> <span>=</span> <span>outputs_fake</span><span>.</span><span>mean</span><span>()</span> <span>-</span> <span>outputs_real</span><span>.</span><span>mean</span><span>()</span>
</span></span><span><span>                <span>discriminator</span><span>.</span><span>zero_grad</span><span>()</span>
</span></span><span><span>                <span>loss_d</span><span>.</span><span>backward</span><span>()</span>
</span></span><span><span>                <span>opt_d</span><span>.</span><span>step</span><span>()</span>
</span></span><span><span>                <span>for</span> <span>p</span> <span>in</span> <span>discriminator</span><span>.</span><span>parameters</span><span>():</span>
</span></span><span><span>                    <span>p</span><span>.</span><span>data</span><span>.</span><span>clamp_</span><span>(</span><span>-</span><span>clip_threshold</span><span>,</span> <span>clip_threshold</span><span>)</span>
</span></span><span><span>
</span></span><span><span>            <span># generator</span>
</span></span><span><span>            <span>outputs</span> <span>=</span> <span>discriminator</span><span>(</span><span>fake_images</span><span>)</span>
</span></span><span><span>            <span>loss_g</span> <span>=</span> <span>-</span><span>outputs</span><span>.</span><span>mean</span><span>()</span>
</span></span><span><span>            <span>generator</span><span>.</span><span>zero_grad</span><span>()</span>
</span></span><span><span>            <span>loss_g</span><span>.</span><span>backward</span><span>()</span>
</span></span><span><span>            <span>opt_g</span><span>.</span><span>step</span><span>()</span>
</span></span></code></pre></div><figure><a href="https://swe-to-mle.pages.dev/posts/gan-wgan-and-instance-noise/wgan.png" title="wgan" data-thumbnail="wgan.png" data-sub-html="&lt;h2&gt;Train with WGAN&lt;/h2&gt;&lt;p&gt;wgan&lt;/p&gt;">
        <img src="https://swe-to-mle.pages.dev/svg/loading.min.svg" data-src="wgan.png" data-srcset="wgan.png, wgan.png 1.5x, wgan.png 2x" data-sizes="auto" alt="wgan.png"/>
    </a><figcaption>Train with WGAN</figcaption>
    </figure>
<h3 id="both">Both</h3>
<p>Or use a combination of both</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>def</span> <span>train_wgan_noise</span><span>(</span><span>discriminator</span><span>,</span> <span>generator</span><span>,</span> <span>noise_std</span><span>=</span><span>0.01</span><span>,</span> <span>clip_threshold</span><span>=</span><span>0.01</span><span>,</span> <span>extra_discriminator_training</span><span>=</span><span>10</span><span>,</span> <span>data</span><span>=</span><span>data</span><span>,</span> <span>epochs</span><span>=</span><span>EPOCHS</span><span>,</span> <span>lr</span><span>=</span><span>LEARNING_RATE</span><span>):</span>
</span></span><span><span>    <span>def</span> <span>noisify</span><span>(</span><span>images</span><span>):</span>
</span></span><span><span>        <span>return</span> <span>images</span> <span>+</span> <span>torch</span><span>.</span><span>randn_like</span><span>(</span><span>images</span><span>)</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span> <span>*</span> <span>noise_std</span>
</span></span><span><span>    
</span></span><span><span>    <span>opt_d</span> <span>=</span> <span>torch</span><span>.</span><span>optim</span><span>.</span><span>RMSprop</span><span>(</span><span>discriminator</span><span>.</span><span>parameters</span><span>(),</span> <span>lr</span><span>=</span><span>lr</span><span>)</span>
</span></span><span><span>    <span>opt_g</span> <span>=</span> <span>torch</span><span>.</span><span>optim</span><span>.</span><span>RMSprop</span><span>(</span><span>generator</span><span>.</span><span>parameters</span><span>(),</span> <span>lr</span><span>=</span><span>lr</span><span>)</span>
</span></span><span><span>
</span></span><span><span>    <span>for</span> <span>epoch</span> <span>in</span> <span>range</span><span>(</span><span>epochs</span><span>):</span>
</span></span><span><span>        <span>for</span> <span>minibatch</span><span>,</span> <span>_</span> <span>in</span> <span>data</span><span>:</span>
</span></span><span><span>            <span>batch_size</span> <span>=</span> <span>minibatch</span><span>.</span><span>size</span><span>(</span><span>0</span><span>)</span>
</span></span><span><span>            <span>minibatch</span> <span>=</span> <span>minibatch</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>
</span></span><span><span>            <span>noise</span> <span>=</span> <span>torch</span><span>.</span><span>randn</span><span>(</span><span>batch_size</span><span>,</span> <span>NOISE_DIMS</span><span>,</span> <span>device</span><span>=</span><span>device</span><span>)</span>
</span></span><span><span>            <span>fake_images</span> <span>=</span> <span>generator</span><span>(</span><span>noise</span><span>)</span>
</span></span><span><span>
</span></span><span><span>            <span># discriminator</span>
</span></span><span><span>            <span>for</span> <span>_</span> <span>in</span> <span>range</span><span>(</span><span>extra_discriminator_training</span><span>):</span>
</span></span><span><span>                <span>outputs_real</span> <span>=</span> <span>discriminator</span><span>(</span><span>noisify</span><span>(</span><span>minibatch</span><span>))</span>
</span></span><span><span>                <span>outputs_fake</span> <span>=</span> <span>discriminator</span><span>(</span><span>noisify</span><span>(</span><span>fake_images</span><span>.</span><span>detach</span><span>()))</span>
</span></span><span><span>                <span>loss_d</span> <span>=</span> <span>outputs_fake</span><span>.</span><span>mean</span><span>()</span> <span>-</span> <span>outputs_real</span><span>.</span><span>mean</span><span>()</span>
</span></span><span><span>                <span>discriminator</span><span>.</span><span>zero_grad</span><span>()</span>
</span></span><span><span>                <span>loss_d</span><span>.</span><span>backward</span><span>()</span>
</span></span><span><span>                <span>opt_d</span><span>.</span><span>step</span><span>()</span>
</span></span><span><span>                <span>for</span> <span>p</span> <span>in</span> <span>discriminator</span><span>.</span><span>parameters</span><span>():</span>
</span></span><span><span>                    <span>p</span><span>.</span><span>data</span><span>.</span><span>clamp_</span><span>(</span><span>-</span><span>clip_threshold</span><span>,</span> <span>clip_threshold</span><span>)</span>
</span></span><span><span>
</span></span><span><span>            <span># generator</span>
</span></span><span><span>            <span>outputs</span> <span>=</span> <span>discriminator</span><span>(</span><span>fake_images</span><span>)</span>
</span></span><span><span>            <span>loss_g</span> <span>=</span> <span>-</span><span>outputs</span><span>.</span><span>mean</span><span>()</span>
</span></span><span><span>            <span>generator</span><span>.</span><span>zero_grad</span><span>()</span>
</span></span><span><span>            <span>loss_g</span><span>.</span><span>backward</span><span>()</span>
</span></span><span><span>            <span>opt_g</span><span>.</span><span>step</span><span>()</span>
</span></span></code></pre></div><figure><a href="https://swe-to-mle.pages.dev/posts/gan-wgan-and-instance-noise/both.png" title="both" data-thumbnail="both.png" data-sub-html="&lt;h2&gt;Train with noise and WGAN&lt;/h2&gt;&lt;p&gt;both&lt;/p&gt;">
        <img src="https://swe-to-mle.pages.dev/svg/loading.min.svg" data-src="both.png" data-srcset="both.png, both.png 1.5x, both.png 2x" data-sizes="auto" alt="both.png"/>
    </a><figcaption>Train with noise and WGAN</figcaption>
    </figure>
<p>Subjectively I like the visual of the Instance Noise better, the result feel more crisp, while the GAN gives me a sensation of afterimage, some ghost lines and bluriness. But both methods seem to help with the mode collapse. I’ve let them both train for a few hours and still got a sample of different numbers generated.</p>
<h2 id="generate-mazes">Generate Mazes</h2>
<p>As the tradition goes, let’s make some mazes so we get a point of comparison with the VAE.</p>
<figure><a href="https://swe-to-mle.pages.dev/posts/gan-wgan-and-instance-noise/mazes.png" title="mazes" data-thumbnail="mazes.png" data-sub-html="&lt;h2&gt;Mazes through WGAN with Instance Noise&lt;/h2&gt;&lt;p&gt;mazes&lt;/p&gt;">
        <img src="https://swe-to-mle.pages.dev/svg/loading.min.svg" data-src="mazes.png" data-srcset="mazes.png, mazes.png 1.5x, mazes.png 2x" data-sizes="auto" alt="mazes.png"/>
    </a><figcaption>Mazes through WGAN with Instance Noise</figcaption>
    </figure>
<h2 id="the-code">The code</h2>
<p>You can get the code at <a href="https://github.com/peluche/daedalus" target="_blank" rel="noopener noreffer ">https://github.com/peluche/daedalus</a></p>
<h2 id="sources">Sources</h2>
<ul>
<li>GAN: <a href="https://arxiv.org/abs/1406.2661" target="_blank" rel="noopener noreffer ">https://arxiv.org/abs/1406.2661</a></li>
<li>WGAN: <a href="https://arxiv.org/abs/1701.07875" target="_blank" rel="noopener noreffer ">https://arxiv.org/abs/1701.07875</a></li>
<li>Improve training: <a href="https://youtu.be/RdC4XeExDeY" target="_blank" rel="noopener noreffer ">https://youtu.be/RdC4XeExDeY</a></li>
</ul>
</div></div>
  </body>
</html>
