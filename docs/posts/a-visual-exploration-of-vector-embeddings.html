<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="http://blog.pamelafox.org/2025/05/a-visual-exploration-of-vector.html">Original</a>
    <h1>A visual exploration of vector embeddings</h1>
    
    <div id="readability-page-1" class="page"><div id="post-body-7037405492332110657">
<p><em>For Pycon 2025, I created a poster exploring vector embedding models, which you can <a target="_blank" href="https://drive.google.com/file/d/1pnI2XGxwhQQDKF2Ktl2XvaUUf294_-Qe/view">download at full-size</a>. 
  In this post, I&#39;ll translate that poster into words.</em></p>

<h2>Vector embeddings</h2>

<p>A <strong>vector embedding</strong> is a mapping from an input (like a word, list of words, or image) into a list of floating point numbers.
That list of numbers represents that input in the multidimensional embedding space of the model. We refer to the length of the list as its <strong>dimensions</strong>, so a list with 1024 numbers would have 1024 dimensions.
</p>
<p>
<img alt="The word dog is sent to an embedding model and a list of floating point numbers is returned" src="https://blogger.googleusercontent.com/img/b/R29vZ2xl/AVvXsEiRJ9rX6o3j7_X8_zNMOjq0DeUEiKn-spn_qMjetcJZd2mjzAn8WTmPeRqOSGjHa-GfcUUSxOhpIYDzexwzCeG8fh4EtRq58clDKvto2vgjxVwL_2JcfdDhICtWcRtmjAvndoNWqClx3FkkucetCOWdxmadu28xfIHiLaH9Itpeupx8-y2jXfwkn_U7zQ/s1600/Screenshot%202025-05-28%20at%2011.52.58%E2%80%AFAM.png" width="550"/>
</p>
</div></div>
  </body>
</html>
