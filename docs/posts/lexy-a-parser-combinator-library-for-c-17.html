<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/foonathan/lexy">Original</a>
    <h1>Lexy: A parser combinator library for C&#43;&#43;17</h1>
    
    <div id="readability-page-1" class="page"><div dir="auto">
<div dir="auto">
<dl>
<dt>Why should I use lexy over XYZ?</dt>
<dd>
<p dir="auto">lexy is closest to other PEG parsers.
However, they usually do more implicit backtracking, which can hurt performance and you need to be very careful with rules that have side-effects.
This is not the case for lexy, where backtracking is controlled using branch conditions.
lexy also gives you a lot of control over error reporting, supports error recovery, special support for operator precedence parsing, and other advanced features.</p>
<div dir="auto">
<dl>
<dt><a href="http://boost-spirit.com/home/" rel="nofollow">Boost.Spirit</a></dt>
<dd>
<p dir="auto">The main difference: it is not a Boost library.
In addition, Boost.Spirit is quite old and doesn’t support e.g. non-common ranges as input.
Boost.Spirit also eagerly creates attributes from the rules, which can lead to nested tuples/variants while lexy uses callbacks which enables zero-copy parsing directly into your own data structure.
However, lexy’s grammar is more verbose and designed to parser bigger grammars instead of the small one-off rules that Boost.Spirit is good at.</p>
</dd>
<dt><a href="https://github.com/taocpp/PEGTL">PEGTL</a></dt>
<dd>
<p dir="auto">PEGTL is very similar and was a big inspiration.
The biggest difference is that lexy uses an operator based DSL instead of inheriting from templated classes as PEGTL does;
depending on your preference this can be an advantage or disadvantage.</p>
</dd>
<dt>Hand-written Parsers</dt>
<dd>
<p dir="auto">Writing a handwritten parser is more manual work and error prone.
lexy automates that away without having to sacrifice control.
You can use it to quickly prototype a parser and then slowly replace more and more with a handwritten parser over time;
mixing a hand-written parser and a lexy grammar works seamlessly.</p>
</dd>
</dl>
</div>
</dd>
<dt>How bad are the compilation times?</dt>
<dd>
<p dir="auto">They’re not as bad as you might expect (in debug mode, that is).</p>
<p dir="auto">The example JSON parser compiles in about 2s on my machine.
If we remove all the lexy specific parts and just benchmark the time it takes for the compiler to process the datastructure (and stdlib includes),
that takes about 700ms.
If we validate JSON only instead of parsing it, so remove the data structures and keep only the lexy specific parts, we’re looking at about 840ms.</p>
<p dir="auto">Keep in mind, that you can fully isolate lexy in a single translation unit that only needs to be touched when you change the parser.
You can also split a lexy grammar into multiple translation units using the <code>dsl::subgrammar</code> rule.</p>
</dd>
<dt>How bad are the C++ error messages if you mess something up?</dt>
<dd>
<p dir="auto">They’re certainly worse than the error message lexy gives you.
The big problem here is that the first line gives you the error, followed by dozens of template instantiations, which end at your <code>lexy::parse</code> call.
Besides providing an external tool to filter those error messages, there is nothing I can do about that.</p>
</dd>
<dt>How fast is it?</dt>
<dd>
<p dir="auto">Benchmarks are available in the <code>benchmarks/</code> directory.
A sample result of the JSON validator benchmark which compares the example JSON parser with various other implementations is available <a href="https://lexy.foonathan.net/benchmark_json/" rel="nofollow">here</a>.</p>
</dd>
<dt>Why is it called lexy?</dt>
<dd>
<p dir="auto">I previously had a tokenizer library called foonathan/lex.
I’ve tried adding a parser to it, but found that the line between pure tokenization and parsing has become increasingly blurred.
lexy is a re-imagination on of the parser I’ve added to foonathan/lex, and I’ve simply kept a similar name.</p>
</dd>
</dl>
</div>
</div></div>
  </body>
</html>
