<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.wildlondon.org.uk/blog/frith/buddleia">Original</a>
    <h1>&lt;a href=&#34;/blog/frith/buddleia&#34; hreflang=&#34;en&#34;&gt;Buddleia; butterfly buffet or bush of burden? &lt;/a&gt;</h1>
    
    <div id="readability-page-1" class="page"><div>
      
        <header>
          
          

  <p>
    
      
      <span>
        <i aria-hidden="true"></i>
        
        <time datetime="2023-08-01T17:51:00+00:00">August 1, 2023</time>
      </span>
    

    

    
  </p>


        </header>
      

      <section itemprop="text">
        
        <p>My research group was busy this past year.  Here’s a summary of what we’ve been up to in 2022-2023!</p>

<h2 id="haschor-choreographic-programming-in-haskell">HasChor: Choreographic programming in Haskell</h2>

<p>This year, my students and I started getting into <a href="https://en.wikipedia.org/wiki/Choreographic_programming">choreographic programming</a>. In choreographic programming, one implements a distributed system by writing a single program – a “choreography” – that describes the behavior of all nodes in the system, instead of writing individual programs that run on each node. The choreography is then compiled to programs that run on individual nodes, via a compilation step called <em>endpoint projection</em> (EPP).<sup id="fnref:1" role="doc-noteref"><a href="#fn:1" rel="footnote">1</a></sup>  If EPP is correct, the resulting collection of programs will be <a href="https://dl.acm.org/doi/10.1145/2429069.2429101">deadlock-free</a>.</p>

<p>Several choreographic programming languages exist, but they’re mostly research languages, and some only exist on paper or <a href="https://dl.acm.org/doi/10.1145/3498684">in a proof assistant</a>. We created <a href="https://github.com/gshen42/HasChor">HasChor</a>, a Haskell library that implements choreographic programming as an embedded domain-specific language in Haskell. In HasChor, choreographies are expressed as computations in a monad. To our knowledge, choreographies-as-monads is a new idea, and HasChor is the first implementation of choreographic programming <em>as a library</em>, monadic or otherwise, that we are aware of.</p>

<p>Because HasChor is “just a library”, it can be installed like any Haskell library, compiled and run like any Haskell program, and can use any Haskell tools for development and debugging.  HasChor also naturally supports <em>higher-order choreographies</em> and <em>location polymorphism</em>, both cutting-edge features of choreographic languages that enable code reuse, but we didn’t have to do a lot of work to get these features – we get them almost “for free” from the host language.</p>

<p>We also find that Haskell lends itself to an especially nice implementation of endpoint projection. In particular, my student <a href="https://gshen42.github.io/">Gan Shen</a> had the idea to use <a href="https://okmij.org/ftp/Computation/free-monad.html"><em>freer monads</em></a> to make it so that one choreography can be interpreted to different programs depending on which participant you are (say, a server or a client). The choreographic primitives of HasChor are deeply embedded so that we can freely interpret them, while other parts of the language are shallowly embedded so that we can reuse existing Haskell constructs as much as possible.  (I used to think that such a <em>mixed embedding</em> was something weird and exotic, but now that I’ve seen how it works in HasChor, it feels very natural!)  Our implementation approach also means that HasChor supports <em>swappable backends</em> that implement message transport.  We provide an HTTP backend that’s intended for web programming, but it’s completely decoupled from the implementation of EPP, and programmers can implement their own backend if they want to use HasChor in other message-passing settings.</p>

<p>As a case study, we used HasChor to implement a distributed key-value store as a choreography.  We start with a simple client-server setup with no replication, then add primary-backup replication, and then move to a version that factors the choice of replication strategy out to its own choreography.  My student <a href="https://shun-k.dev/">Shun Kashiwa</a> designed and implemented all these examples.</p>

<p>I’m thrilled to announce that <a href="https://icfp23.sigplan.org/details/icfp-2023-papers/19/HasChor-Functional-Choreographic-Programming-for-All-Functional-Pearl-">our paper on HasChor</a> will appear at ICFP this year – don’t miss Gan’s talk in Seattle this September, and in the meantime, you can <a href="https://arxiv.org/abs/2303.00924">read the paper on arXiv</a> or <a href="https://github.com/gshen42/HasChor">play with the HasChor implementation</a>!</p>

<p>We’re newcomers to choreographic programming, and we’re grateful to experts like <a href="https://www.fabriziomontesi.com/">Fabrizio Montesi</a> and <a href="https://akhirsch.science/">Andrew Hirsch</a> for all the guidance they’ve given us over the last year.  If you want to learn about choreographies, I recommend checking out <a href="https://www.fabriziomontesi.com/introduction-to-choreographies/">Fabrizio’s new book</a>.</p>

<h2 id="causal-message-delivery-as-a-refinement-type">Causal message delivery as a refinement type</h2>

<p>This year, we finally published <a href="https://dl.acm.org/doi/10.1145/3587216.3587222">“Verified Causal Broadcast with Liquid Haskell”</a> at IFL ‘22!  We used Liquid Haskell’s refinement types to verify the safety of <a href="https://dl.acm.org/doi/10.1145/128738.128742">a classic algorithm for causal message broadcast</a>, resulting in a running Haskell implementation that we actually deployed.  In this setting, “safety” means that messages will never be delivered out of causal order.  I’ve already written and spoken <a href="https://decomposition.al/blog/2022/09/07/verified-causal-broadcast-with-liquid-haskell/">at length</a> <a href="https://users.soe.ucsc.edu/~lkuper/talks/2022-10-24-berkeley-cbcast-lh.pdf">elsewhere</a> about the specifics of this particular project, so here I’ll just say something about refinement types and Liquid Haskell more broadly.</p>

<p>A refinement type can be thought of as the type of a dependent pair where the second component is some kind of proof about the first component.  So in that sense, refinement types are just a particular use case of dependent types (and we can find them in, for instance, <a href="https://agda.github.io/agda-stdlib/Data.Refinement.html">the Agda standard library</a>).  However, to construct such a pair, you’d need to supply both the value and the proof, and when people talk about “refinement types” these days<sup id="fnref:2" role="doc-noteref"><a href="#fn:2" rel="footnote">2</a></sup>, they <em>usually</em> mean they’re asking some under-the-hood system to supply the proof, typically with help from an external SMT solver.  This is an implementation detail in some sense, but an extremely important one in terms of programmer experience.  (And you could imagine hooking it into a typical dependently typed language – see our <a href="https://2021.splashcon.org/details/hatra-2021-papers/5/Toward-SMT-Based-Refinement-Types-in-Agda">proposal/plea for SMT-powered refinement types in Agda</a>.)</p>

<p>I think <a href="https://ucsd-progsys.github.io/liquidhaskell/">Liquid Haskell</a> is fascinating because it comes from the other direction.  It was originally “just” an SMT-backed decidable refinement type system, then <a href="https://dl.acm.org/doi/10.1145/3158141">evolved the ability</a> to supply one’s own manual (but still solver-assisted!) proofs.  It can now be said to be an honest-to-goodness proof assistant – albeit one that’s pretty hard to use, and so far lacking any interactive proof development features (which is the topic of <a href="https://2021.splashcon.org/details/hatra-2021-papers/6/Toward-Hole-Driven-Development-with-Liquid-Haskell"><em>another</em> proposal/plea from our group</a>).  But – with effort – you can actually prove things about <em>deployable code</em> with it!</p>

<p>I was new to <em>research-level</em> mechanized verification – a few Software Foundations exercises don’t count – when we started this verified causal message delivery project<sup id="fnref:3" role="doc-noteref"><a href="#fn:3" rel="footnote">3</a></sup>, and for the most part, so were my students.  I thought that using Liquid Haskell would make things easy because we were already familiar with Haskell, but it turns out that mechanized verification is hard regardless of the mechanization tool.  Writing idiomatic Haskell and then trying to verify it didn’t work; we had to think about verification from the start.  At the talk I gave at <a href="https://www.dagstuhl.de/en/seminars/seminar-calendar/seminar-details/23112">Dagstuhl</a> this spring, I joked that this project is what happens when a group of stubborn Haskell programmers attempt to do mechanized verification of distributed systems.  We flailed around, made false starts, learned a <em>lot</em>, and finally got a result we’re proud of: we can write down a refinement type to express the property that all messages delivered by the processes in a distributed system are delivered in causal order, and we can use Liquid Haskell to prove that this property is actually true of our implementation.  Of course, by “we”, I mostly mean my student, <a href="https://curious.software/plr/">Patrick Redmond</a>, without whom this project couldn’t have happened.  I am very proud of <a href="https://dl.acm.org/doi/10.1145/3587216.3587222">our paper</a> (led by Patrick, with contributions from Gan and from our collaborator, Liquid Haskell creator <a href="https://nikivazou.github.io/">Niki Vazou</a>), which distills what we learned over two years of hard work!</p>

<h2 id="what-goes-wrong-in-serverless-runtimes">What goes wrong in serverless runtimes?</h2>

<p>So-called “serverless” computing is a cloud computing abstraction in which programmers specify functions to run, and the platform provides everything else (like an operating system, resource allocation, load balancing, and fault tolerance).  <a href="https://knative.dev">Knative</a> is a popular open-source serverless platform whose development is backed by Google; paid Google products like <a href="https://cloud.google.com/run/">Cloud Run</a> are (<a href="https://cloud.google.com/blog/products/serverless/knative-based-cloud-run-services-are-ga">said to be</a>) based on Knative.</p>

<p>This spring, my student <a href="https://discrete.events/">Tim Goodwin</a> (co-advised by my colleague <a href="https://arquinn.github.io/">Andrew Quinn</a>) dug into the issue tracker for <a href="https://github.com/knative/serving">Knative Serving</a>, the runtime component of Knative, with the goal of getting an an idea of the ways in which serverless computing platforms tend to be buggy.  Tim considered <em>every single bug</em> reported on the Knative Serving public issue tracker between January 2020 and February 2023.  He narrowed this set of bugs down to those that pertained to runtime behavior (as opposed to, say, installation bugs), ending up with <a href="https://github.com/lsd-ucsc/knative-runtime-bugs/blob/main/bug-dataset.tsv">a dataset of 103 bugs</a>, and then looked at each of those bugs in more detail and taxonomized them.  The most common classes of bugs were: bugs relating to Knative’s use of <em>status conditions</em> (e.g., <a href="https://github.com/knative/serving/issues/10267">issue #10267</a>), bugs relating to how Knative interacts with the underlying Kubernetes container orchestration platform (e.g., <a href="https://github.com/knative/serving/issues/13204">issue #13204</a>), bugs relating to user-provided Knative configuration parameters (e.g., <a href="https://github.com/knative/serving/issues/11926">issue #11926</a>), and bugs relating to Knative’s autoscaling behavior (e.g., <a href="https://github.com/knative/serving/issues/8610">issue #8610</a>).  These categories aren’t mutually exclusive; bugs could (and lots did) fall into more than one of them.  This is the first time I’ve ever worked on a bug-study paper like this, and I learned a lot!  Unlike a lot of my work, which proceeds more or less from first principles, this project involved actually observing bugs in the wild – being naturalists.  (Entomologists, if you will.)</p>

<p>To me, configuration parameter bugs are a particularly interesting class of bugs.  These aren’t situations where the user could be said to have <em>misconfigured</em> Knative; rather, they are situations where the user picked a certain combination of configuration parameters that didn’t work as expected, due to a genuine issue with the platform.  <a href="https://github.com/knative/serving/issues/11926">Issue #11926</a> is representative of this category of bugs.  A high-level summary of what’s going on with this bug: during periods of high load, Knative tries to speed up request processing by turning on a particular performance optimization; what “high load” means in this context depends on a combination of user-configurable settings.  Unfortunately, under a particular combination of settings – including two of the <em>default</em> settings – the performance optimization would flip on and off with <em>every</em> request, which actually ended up degrading performance.  (One Knative developer coined the term <a href="https://github.com/knative/serving/pull/12774">“flipageddon”</a> for this behavior.)  The Knative developers resolved this particular issue by changing the default value for one of the settings in a way that presumably makes the bug less likely to be triggered, though not impossible.  Perhaps many such bugs could be found through systematic testing.</p>

<p>Tim presented <a href="https://dl.acm.org/doi/10.1145/3592533.3592806">our bug study paper</a> at the <a href="https://sesame23.github.io/">SESAME</a> workshop at EuroSys in May.  The paper describes our methodology and findings in more detail, discusses more bugs that are representative of the classes we identified, and suggests some future research directions that interest us (and, hopefully, you!).</p>

<h2 id="crdts-as-coalgebras">CRDTs as coalgebras</h2>

<p>Conflict-free replicated data types, or CRDTs, are data structures designed for replication and high availability across multiple physical nodes in a distributed system.<sup id="fnref:4" role="doc-noteref"><a href="#fn:4" rel="footnote">4</a></sup>  A well-known result about CRDTs is that so-called “state-based” CRDTs, in which replicas send copies of their state to other replicas, and “operation-based” CRDTs, in which replicas broadcast copies of the operations that have been applied to them, are <a href="https://pages.lip6.fr/Marc.Shapiro/papers/RR-7687.pdf#subsection.3.2">equivalent</a>, in the sense that any CRDT specified in the state-based style can be <em>emulated</em> by one specified in the op-based style, and vice versa.  However, while <a href="https://pages.lip6.fr/Marc.Shapiro/papers/RR-7687.pdf#subsection.3.2">Shapiro et al. give a recipe for constructing an op-based CRDT given a state-based one and vice versa</a>, they don’t go so far as to prove that an object constructed using this recipe is in fact equivalent to the original object, in the sense of having the same behavior from the perspective of clients.  To tackle this question, my students <a href="https://nliittsc.github.io/">Nathan Liittschwager</a> and <a href="http://jonathan.com/">Jonathan Castello</a> began investigating the semantics of CRDTs from a new perspective: that of viewing CRDTs as <em>coalgebras</em>.  (If you don’t know what coalgebras are and you want a computer-science-y definition, “a generalization of <a href="https://en.wikipedia.org/wiki/Transition_system">transition systems</a>” is close enough for rock n’ roll.)</p>

<p>At first glance, the question looks like a typical <a href="https://en.wikipedia.org/wiki/Observational_equivalence">contextual equivalence</a> problem: do the two implementations have the same behavior when dropped into the same context?  However, state-based and op-based CRDTs have different interfaces, exposing different operations.  (For instance, state-based CRDTs have a merge operation, and op-based CRDTs don’t.)  They have different types!  How do we talk about equivalence in this setting?  One approach is to separate the query and update operations that <em>clients</em> can do – which are part of the interface of <em>both</em> state-based and op-based CRDTs – from internal operations, like merge, which differ between the state-based and op-based flavors.  We can therefore think about the equivalence of <em>different types</em> of CRDTs by only looking at the parts that both types have in common.<sup id="fnref:5" role="doc-noteref"><a href="#fn:5" rel="footnote">5</a></sup>  Moreover, by modeling CRDTs as coalgebras, we get a nice notion of equivalence of CRDTs in terms of bisimulation between coalgebras.  We outline this idea in an <a href="https://users.soe.ucsc.edu/~lkuper/papers/crdts-coalgebraically-calco23.pdf">abstract</a> that Nathan presented at <a href="https://coalg.org/calco-mfps-2023/">CALCO</a><sup id="fnref:6" role="doc-noteref"><a href="#fn:6" rel="footnote">6</a></sup> this spring, and we’re currently working on fleshing out the idea further, together with our collaborator <a href="https://www8.cs.fau.de/people/stelios/">Stelios Tsampas</a>.  We think that the coalgebraic perspective will be useful not only for thinking about CRDTs, but for all kinds of replicated systems, including those that (unlike CRDTs) provide strong consistency among replicas.</p>

<h2 id="exceptional-actors">Exceptional actors</h2>

<p>And one more thing!</p>

<p><a href="https://hackage.haskell.org/package/base-4.18.0.0/docs/Control-Exception.html#g:10">Asynchronous exceptions</a> are an interesting feature of the GHC runtime system (RTS).  Unlike typical (“synchronous”) exceptions, which come from the current thread, asynchronous exceptions can be thrown <em>to</em> the current thread by a <em>different</em> thread (or by the runtime system itself, as in the case of timeouts).  Perhaps worryingly, asynchronous exceptions can therefore be repurposed for general inter-thread communication.  My student Patrick demonstrated this by <a href="https://recurse.social/@lindsey/110748916997975357">using asynchronous exceptions to implement an actor framework</a> – or, perhaps more accurately, he <em>discovered</em> that this actor framework already exists within the GHC RTS.  Sending a message is implemented with <code>throwTo</code>; receiving a message is implemented with <code>catch</code>.  While we don’t actually condone using asynchronous exceptions this way, we do think it’s a neat hack, so we <a href="https://icfp23.sigplan.org/details/haskellsymp-2023/3/An-Exceptional-Actor-System-Functional-Pearl-">wrote a paper about it</a> (as <a href="https://github.com/lsd-ucsc/hakkell.paper">a literate Haskell program</a>).  Patrick will be presenting our “exceptional actor system” at the Haskell Symposium in Seattle this September – stay for an extra day after ICFP and <em>catch</em> his talk!</p>



        
      </section>

      

      

      
  <nav>
    
      <a href="https://decomposition.al/blog/2023/04/08/who-invented-vector-clocks/" title="Who invented vector clocks?
">Previous</a>
    
    
      <a href="#">Next</a>
    
  </nav>

    </div></div>
  </body>
</html>
