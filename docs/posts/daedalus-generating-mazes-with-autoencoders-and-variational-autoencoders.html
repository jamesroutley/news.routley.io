<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://swe-to-mle.pages.dev/posts/daedalus-generating-mazes-with-autoencoders-and-variational-autoencoders/">Original</a>
    <h1>Daedalus Generating Mazes With Autoencoders and Variational Autoencoders</h1>
    
    <div id="readability-page-1" class="page"><div id="content"><p><em>Daedalus, master craftsman of ancient myths, conceived the Labyrinth: a maze of bewildering complexity. Its winding paths and endless turns, a testament to his genius, were designed to confine the fearsome Minotaur, blurring the line between architectural marvel and cunning trap.</em></p>
<figure><a href="https://swe-to-mle.pages.dev/posts/daedalus-generating-mazes-with-autoencoders-and-variational-autoencoders/daedalus.png" title="daedalus" data-thumbnail="daedalus.png" data-sub-html="&lt;h2&gt;Daedalus designing the labyrinth by DALL-E&lt;/h2&gt;&lt;p&gt;daedalus&lt;/p&gt;">
        <img src="https://swe-to-mle.pages.dev/svg/loading.min.svg" data-src="daedalus.png" data-srcset="daedalus.png, daedalus.png 1.5x, daedalus.png 2x" data-sizes="auto" alt="daedalus.png"/>
    </a><figcaption>Daedalus designing the labyrinth by DALL-E</figcaption>
    </figure>
<h2 id="the-quest">The Quest</h2>
<p>Train a network on Daedalus work to generate new mazes.</p>
<h2 id="autoencoder">Autoencoder</h2>
<p>An autoencoder is a type of network shaped like an hourglass. We start with an input, and pass it through smaller and smaller layers until reaching the bottleneck point (also refered to as latent space). We then feed the bottleneck to bigger and bigger layer until we reach the original size. And train the network to recronstruct the original input.</p>
<figure><a href="https://swe-to-mle.pages.dev/posts/daedalus-generating-mazes-with-autoencoders-and-variational-autoencoders/hourglass.png" title="hourglass" data-thumbnail="hourglass.png" data-sub-html="&lt;h2&gt;Autoencoder Hourglass shape&lt;/h2&gt;&lt;p&gt;hourglass&lt;/p&gt;">
        <img src="https://swe-to-mle.pages.dev/svg/loading.min.svg" data-src="hourglass.png" data-srcset="hourglass.png, hourglass.png 1.5x, hourglass.png 2x" data-sizes="auto" alt="hourglass.png"/>
    </a><figcaption>Autoencoder Hourglass shape</figcaption>
    </figure>
<p>This has several applications:</p>
<ul>
<li>we can use the bottleneck as a compressed representation</li>
<li>the architecture is often used for denoizing</li>
<li>colorization</li>
<li>and in our case generation</li>
</ul>
<p>By tweaking the values of the latent space, the hope is that our second half of the network (the decoder) would re-create a valid output, but somewhat different from the training set.</p>
<p>We’ll take a detour through MNIST because it’s a canonical example and I want to have a way to evaluate how poorly is the network doing.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>class</span> <span>Autoencoder</span><span>(</span><span>nn</span><span>.</span><span>Module</span><span>):</span>
</span></span><span><span>    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>latent_dims</span><span>=</span><span>2</span><span>,</span> <span>input_dims</span><span>=</span><span>28</span><span>,</span> <span>hidden_dims</span><span>=</span><span>512</span><span>):</span>
</span></span><span><span>        <span>super</span><span>()</span><span>.</span><span>__init__</span><span>()</span>
</span></span><span><span>        <span>self</span><span>.</span><span>encoder</span> <span>=</span> <span>nn</span><span>.</span><span>Sequential</span><span>(</span>
</span></span><span><span>            <span>nn</span><span>.</span><span>Flatten</span><span>(</span><span>start_dim</span><span>=</span><span>1</span><span>),</span>
</span></span><span><span>            <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>input_dims</span><span>**</span><span>2</span><span>,</span> <span>hidden_dims</span><span>),</span>
</span></span><span><span>            <span>nn</span><span>.</span><span>ReLU</span><span>(),</span>
</span></span><span><span>            <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>hidden_dims</span><span>,</span> <span>latent_dims</span><span>)</span>
</span></span><span><span>        <span>)</span>
</span></span><span><span>        <span>self</span><span>.</span><span>decoder</span> <span>=</span> <span>nn</span><span>.</span><span>Sequential</span><span>(</span>
</span></span><span><span>            <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>latent_dims</span><span>,</span> <span>hidden_dims</span><span>),</span>
</span></span><span><span>            <span>nn</span><span>.</span><span>ReLU</span><span>(),</span>
</span></span><span><span>            <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>hidden_dims</span><span>,</span> <span>input_dims</span><span>**</span><span>2</span><span>),</span>
</span></span><span><span>            <span>nn</span><span>.</span><span>Sigmoid</span><span>(),</span>
</span></span><span><span>            <span>nn</span><span>.</span><span>Unflatten</span><span>(</span><span>1</span><span>,</span> <span>(</span><span>1</span><span>,</span> <span>input_dims</span><span>,</span> <span>input_dims</span><span>)),</span>
</span></span><span><span>        <span>)</span>
</span></span><span><span>
</span></span><span><span>    <span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span> <span>x</span><span>):</span>
</span></span><span><span>        <span>x</span> <span>=</span> <span>self</span><span>.</span><span>encoder</span><span>(</span><span>x</span><span>)</span>
</span></span><span><span>        <span>return</span> <span>self</span><span>.</span><span>decoder</span><span>(</span><span>x</span><span>)</span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>train</span><span>(</span><span>model</span><span>,</span> <span>data</span><span>,</span> <span>epochs</span><span>=</span><span>20</span><span>,</span> <span>lr</span><span>=</span><span>3e-4</span><span>,</span> <span>log_every</span><span>=</span><span>3</span><span>):</span>
</span></span><span><span>    <span>opt</span> <span>=</span> <span>torch</span><span>.</span><span>optim</span><span>.</span><span>Adam</span><span>(</span><span>model</span><span>.</span><span>parameters</span><span>(),</span> <span>lr</span><span>=</span><span>lr</span><span>)</span>
</span></span><span><span>    <span>for</span> <span>epoch</span> <span>in</span> <span>range</span><span>(</span><span>epochs</span><span>):</span>
</span></span><span><span>        <span>for</span> <span>x</span><span>,</span> <span>_label</span> <span>in</span> <span>data</span><span>:</span>
</span></span><span><span>            <span>x</span> <span>=</span> <span>x</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>
</span></span><span><span>            <span>x_hat</span> <span>=</span> <span>model</span><span>(</span><span>x</span><span>)</span>
</span></span><span><span>            <span>loss</span> <span>=</span> <span>((</span><span>x</span> <span>-</span> <span>x_hat</span><span>)</span><span>**</span><span>2</span><span>)</span><span>.</span><span>sum</span><span>()</span>
</span></span><span><span>            <span>opt</span><span>.</span><span>zero_grad</span><span>()</span>
</span></span><span><span>            <span>loss</span><span>.</span><span>backward</span><span>()</span>
</span></span><span><span>            <span>opt</span><span>.</span><span>step</span><span>()</span>
</span></span><span><span>        <span># visualize progress</span>
</span></span><span><span>        <span>if</span> <span>epoch</span> <span>%</span> <span>log_every</span> <span>==</span> <span>log_every</span> <span>-</span> <span>1</span><span>:</span>
</span></span><span><span>            <span>with</span> <span>torch</span><span>.</span><span>no_grad</span><span>():</span>
</span></span><span><span>                <span>img</span> <span>=</span> <span>data</span><span>.</span><span>__iter__</span><span>()</span><span>.</span><span>__next__</span><span>()[</span><span>0</span><span>][</span><span>0</span><span>,</span> <span>:,</span> <span>:,</span> <span>:]</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>
</span></span><span><span>                <span>res</span> <span>=</span> <span>model</span><span>(</span><span>img</span><span>)</span>
</span></span><span><span>                <span>plot</span><span>(</span><span>img</span><span>,</span> <span>res</span><span>,</span> <span>block_size</span><span>=</span><span>1</span><span>)</span>
</span></span><span><span>
</span></span><span><span><span>a</span> <span>=</span> <span>Autoencoder</span><span>(</span><span>latent_dims</span><span>=</span><span>2</span><span>)</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>
</span></span><span><span><span>train</span><span>(</span><span>a</span><span>,</span> <span>data</span><span>,</span> <span>epochs</span><span>=</span><span>40</span><span>)</span>
</span></span></code></pre></div><p>We train the network at reconstructing numbers, and then look at decoded values from around the origin <code>(0, 0)</code> of the 2d latent space:</p>
<figure><a href="https://swe-to-mle.pages.dev/posts/daedalus-generating-mazes-with-autoencoders-and-variational-autoencoders/autoencoder-reconstructions.png" title="autoencoder-reconstructions" data-thumbnail="autoencoder-reconstructions.png" data-sub-html="&lt;h2&gt;Generate numbers by looking at central positions in the latent space of the Autoencoder&lt;/h2&gt;&lt;p&gt;autoencoder-reconstructions&lt;/p&gt;">
        <img src="https://swe-to-mle.pages.dev/svg/loading.min.svg" data-src="autoencoder-reconstructions.png" data-srcset="autoencoder-reconstructions.png, autoencoder-reconstructions.png 1.5x, autoencoder-reconstructions.png 2x" data-sizes="auto" alt="autoencoder-reconstructions.png"/>
    </a><figcaption>Generate numbers by looking at central positions in the latent space of the Autoencoder</figcaption>
    </figure>
<p>The numbers are not that good, and one of the cause is that the latent space is pretty wide and sparse, so taking a random value inside of it, is unlikely to lineup with a valid value that can be decompressed cleanly.</p>
<figure><a href="https://swe-to-mle.pages.dev/posts/daedalus-generating-mazes-with-autoencoders-and-variational-autoencoders/autoencoder-latent.png" title="autoencoder-latent" data-thumbnail="autoencoder-latent.png" data-sub-html="&lt;h2&gt;Latent space for the autoencoder&lt;/h2&gt;&lt;p&gt;autoencoder-latent&lt;/p&gt;">
        <img src="https://swe-to-mle.pages.dev/svg/loading.min.svg" data-src="autoencoder-latent.png" data-srcset="autoencoder-latent.png, autoencoder-latent.png 1.5x, autoencoder-latent.png 2x" data-sizes="auto" alt="autoencoder-latent.png"/>
    </a><figcaption>Latent space for the autoencoder</figcaption>
    </figure>
<h2 id="variational-autoencoders-vae">Variational Autoencoders (VAE)</h2>
<p>Variational Autoencoders keep the same hourglass architecture of the autoencoders. With some extra magic in the middle to improve the density / compactness of the latent space.</p>
<p>The trick is to instead of generating a latent vector in the bottleneck directly, it generates a standard deviation and mean, and sample a value from the normal with these parameters. By adding a component to the loss to fit said mean and std to be a normal Gaussian (<code>mean = 0</code>, <code>std = 1</code>) we encourage the latent space to be concentrated around the origin <code>(0, 0)</code> and have a spread of <code>[-3 to 3]</code>.</p>
<p>This is meant to improve the likelihood to sample a valid value that would decompress well into a valid image.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>class</span> <span>VAE</span><span>(</span><span>nn</span><span>.</span><span>Module</span><span>):</span>
</span></span><span><span>    <span>&#39;&#39;&#39;Variational autoencoder&#39;&#39;&#39;</span>
</span></span><span><span>    <span>def</span> <span>__init__</span><span>(</span><span>self</span><span>,</span> <span>latent_dims</span><span>=</span><span>2</span><span>,</span> <span>input_dims</span><span>=</span><span>28</span><span>,</span> <span>hidden_dims</span><span>=</span><span>512</span><span>):</span>
</span></span><span><span>        <span>super</span><span>()</span><span>.</span><span>__init__</span><span>()</span>
</span></span><span><span>        <span>self</span><span>.</span><span>encoder</span> <span>=</span> <span>nn</span><span>.</span><span>Sequential</span><span>(</span>
</span></span><span><span>            <span>nn</span><span>.</span><span>Flatten</span><span>(</span><span>start_dim</span><span>=</span><span>1</span><span>),</span>
</span></span><span><span>            <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>input_dims</span><span>**</span><span>2</span><span>,</span> <span>hidden_dims</span><span>),</span>
</span></span><span><span>            <span>nn</span><span>.</span><span>ReLU</span><span>(),</span>
</span></span><span><span>            <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>hidden_dims</span><span>,</span> <span>2</span> <span>*</span> <span>latent_dims</span><span>)</span>
</span></span><span><span>        <span>)</span>
</span></span><span><span>        <span>self</span><span>.</span><span>decoder</span> <span>=</span> <span>nn</span><span>.</span><span>Sequential</span><span>(</span>
</span></span><span><span>            <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>latent_dims</span><span>,</span> <span>hidden_dims</span><span>),</span>
</span></span><span><span>            <span>nn</span><span>.</span><span>ReLU</span><span>(),</span>
</span></span><span><span>            <span>nn</span><span>.</span><span>Linear</span><span>(</span><span>hidden_dims</span><span>,</span> <span>input_dims</span><span>**</span><span>2</span><span>),</span>
</span></span><span><span>            <span>nn</span><span>.</span><span>Sigmoid</span><span>(),</span>
</span></span><span><span>            <span>nn</span><span>.</span><span>Unflatten</span><span>(</span><span>1</span><span>,</span> <span>(</span><span>1</span><span>,</span> <span>input_dims</span><span>,</span> <span>input_dims</span><span>)),</span>
</span></span><span><span>        <span>)</span>
</span></span><span><span>        <span>self</span><span>.</span><span>kl</span> <span>=</span> <span>0</span>
</span></span><span><span>
</span></span><span><span>    <span>def</span> <span>sample</span><span>(</span><span>self</span><span>,</span> <span>x</span><span>):</span>
</span></span><span><span>        <span>mu</span><span>,</span> <span>log_var</span> <span>=</span> <span>x</span><span>.</span><span>chunk</span><span>(</span><span>2</span><span>,</span> <span>dim</span><span>=</span><span>1</span><span>)</span>
</span></span><span><span>        <span>sigma</span> <span>=</span> <span>torch</span><span>.</span><span>exp</span><span>(</span><span>log_var</span><span>)</span>
</span></span><span><span>        <span>z</span> <span>=</span> <span>mu</span> <span>+</span> <span>sigma</span> <span>*</span> <span>torch</span><span>.</span><span>randn_like</span><span>(</span><span>sigma</span><span>)</span>
</span></span><span><span>        <span>self</span><span>.</span><span>kl</span> <span>=</span> <span>0.5</span> <span>*</span> <span>(</span><span>sigma</span><span>**</span><span>2</span> <span>+</span> <span>mu</span><span>**</span><span>2</span> <span>-</span> <span>torch</span><span>.</span><span>log</span><span>(</span><span>sigma</span><span>)</span> <span>-</span> <span>1</span><span>)</span><span>.</span><span>sum</span><span>()</span>
</span></span><span><span>        <span>return</span> <span>z</span>
</span></span><span><span>
</span></span><span><span>    <span>def</span> <span>forward</span><span>(</span><span>self</span><span>,</span> <span>x</span><span>):</span>
</span></span><span><span>        <span>x</span> <span>=</span> <span>self</span><span>.</span><span>encoder</span><span>(</span><span>x</span><span>)</span>
</span></span><span><span>        <span>z</span> <span>=</span> <span>self</span><span>.</span><span>sample</span><span>(</span><span>x</span><span>)</span>
</span></span><span><span>        <span>return</span> <span>self</span><span>.</span><span>decoder</span><span>(</span><span>z</span><span>)</span>
</span></span><span><span>
</span></span><span><span><span>def</span> <span>train</span><span>(</span><span>model</span><span>,</span> <span>data</span><span>,</span> <span>epochs</span><span>=</span><span>20</span><span>,</span> <span>lr</span><span>=</span><span>3e-4</span><span>,</span> <span>log_every</span><span>=</span><span>3</span><span>):</span>
</span></span><span><span>    <span>opt</span> <span>=</span> <span>torch</span><span>.</span><span>optim</span><span>.</span><span>Adam</span><span>(</span><span>model</span><span>.</span><span>parameters</span><span>(),</span> <span>lr</span><span>=</span><span>lr</span><span>)</span>
</span></span><span><span>    <span>for</span> <span>epoch</span> <span>in</span> <span>range</span><span>(</span><span>epochs</span><span>):</span>
</span></span><span><span>        <span>for</span> <span>x</span><span>,</span> <span>_label</span> <span>in</span> <span>data</span><span>:</span>
</span></span><span><span>            <span>x</span> <span>=</span> <span>x</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>
</span></span><span><span>            <span>x_hat</span> <span>=</span> <span>model</span><span>(</span><span>x</span><span>)</span>
</span></span><span><span>            <span>loss</span> <span>=</span> <span>((</span><span>x</span> <span>-</span> <span>x_hat</span><span>)</span><span>**</span><span>2</span><span>)</span><span>.</span><span>sum</span><span>()</span> <span>+</span> <span>model</span><span>.</span><span>kl</span>
</span></span><span><span>            <span>opt</span><span>.</span><span>zero_grad</span><span>()</span>
</span></span><span><span>            <span>loss</span><span>.</span><span>backward</span><span>()</span>
</span></span><span><span>            <span>opt</span><span>.</span><span>step</span><span>()</span>
</span></span><span><span>        <span># visualize progress</span>
</span></span><span><span>        <span>if</span> <span>epoch</span> <span>%</span> <span>log_every</span> <span>==</span> <span>log_every</span> <span>-</span> <span>1</span><span>:</span>
</span></span><span><span>            <span>with</span> <span>torch</span><span>.</span><span>no_grad</span><span>():</span>
</span></span><span><span>                <span>img</span> <span>=</span> <span>data</span><span>.</span><span>__iter__</span><span>()</span><span>.</span><span>__next__</span><span>()[</span><span>0</span><span>][</span><span>0</span><span>,</span> <span>:,</span> <span>:,</span> <span>:]</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>
</span></span><span><span>                <span>res</span> <span>=</span> <span>model</span><span>(</span><span>img</span><span>)</span>
</span></span><span><span>                <span>plot</span><span>(</span><span>img</span><span>,</span> <span>res</span><span>,</span> <span>block_size</span><span>=</span><span>1</span><span>)</span>
</span></span><span><span>
</span></span><span><span><span>vae</span> <span>=</span> <span>VAE</span><span>(</span><span>latent_dims</span><span>=</span><span>2</span><span>)</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>
</span></span><span><span><span>train</span><span>(</span><span>vae</span><span>,</span> <span>data</span><span>,</span> <span>epochs</span><span>=</span><span>40</span><span>)</span>
</span></span></code></pre></div><figure><a href="https://swe-to-mle.pages.dev/posts/daedalus-generating-mazes-with-autoencoders-and-variational-autoencoders/vae-reconstructions.png" title="vae-reconstructions" data-thumbnail="vae-reconstructions.png" data-sub-html="&lt;h2&gt;Generate numbers by looking at central positions in the latent space of the VAE&lt;/h2&gt;&lt;p&gt;vae-reconstructions&lt;/p&gt;">
        <img src="https://swe-to-mle.pages.dev/svg/loading.min.svg" data-src="vae-reconstructions.png" data-srcset="vae-reconstructions.png, vae-reconstructions.png 1.5x, vae-reconstructions.png 2x" data-sizes="auto" alt="vae-reconstructions.png"/>
    </a><figcaption>Generate numbers by looking at central positions in the latent space of the VAE</figcaption>
    </figure>
<p>The numbers are a bit better and the latent space is a lot more compact:</p>
<figure><a href="https://swe-to-mle.pages.dev/posts/daedalus-generating-mazes-with-autoencoders-and-variational-autoencoders/vae-latent.png" title="vae-latent" data-thumbnail="vae-latent.png" data-sub-html="&lt;h2&gt;Latent space for the VAE&lt;/h2&gt;&lt;p&gt;vae-latent&lt;/p&gt;">
        <img src="https://swe-to-mle.pages.dev/svg/loading.min.svg" data-src="vae-latent.png" data-srcset="vae-latent.png, vae-latent.png 1.5x, vae-latent.png 2x" data-sizes="auto" alt="vae-latent.png"/>
    </a><figcaption>Latent space for the VAE</figcaption>
    </figure>
<h2 id="improve-training">Improve training</h2>
<p>Adding the normal sampling step in the latent space add noise to the training. Instead of optimizing for reconstruction, we now optimize for a mix of both reconstruction and fitting a unit Gaussian. Which dilute our efforts. One trick that was proposed to improve training is to start training with no Gaussian regularization, and slowly increase the importance of the normalization.</p>
<h3 id="monotonic-annealing">Monotonic Annealing</h3>
<figure><a href="https://swe-to-mle.pages.dev/posts/daedalus-generating-mazes-with-autoencoders-and-variational-autoencoders/annealing.png" title="annealing" data-thumbnail="annealing.png" data-sub-html="&lt;h2&gt;Monotonic Annealing&lt;/h2&gt;&lt;p&gt;annealing&lt;/p&gt;">
        <img src="https://swe-to-mle.pages.dev/svg/loading.min.svg" data-src="annealing.png" data-srcset="annealing.png, annealing.png 1.5x, annealing.png 2x" data-sizes="auto" alt="annealing.png"/>
    </a><figcaption>Monotonic Annealing</figcaption>
    </figure>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>def</span> <span>annealing_train</span><span>(</span><span>model</span><span>,</span> <span>data</span><span>,</span> <span>epochs</span><span>=</span><span>20</span><span>,</span> <span>lr</span><span>=</span><span>3e-4</span><span>,</span> <span>log_every</span><span>=</span><span>3</span><span>):</span>
</span></span><span><span>    <span>opt</span> <span>=</span> <span>torch</span><span>.</span><span>optim</span><span>.</span><span>Adam</span><span>(</span><span>model</span><span>.</span><span>parameters</span><span>(),</span> <span>lr</span><span>=</span><span>lr</span><span>)</span>
</span></span><span><span>    <span>for</span> <span>epoch</span> <span>in</span> <span>range</span><span>(</span><span>epochs</span><span>):</span>
</span></span><span><span>        <span>annealing</span> <span>=</span> <span>min</span><span>(</span><span>epoch</span><span>,</span> <span>epochs</span> <span>//</span> <span>2</span><span>)</span> <span>/</span> <span>(</span><span>epochs</span> <span>//</span> <span>2</span><span>)</span>
</span></span><span><span>        <span>for</span> <span>x</span><span>,</span> <span>_label</span> <span>in</span> <span>data</span><span>:</span>
</span></span><span><span>            <span>x</span> <span>=</span> <span>x</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>
</span></span><span><span>            <span>x_hat</span> <span>=</span> <span>model</span><span>(</span><span>x</span><span>)</span>
</span></span><span><span>            <span>loss</span> <span>=</span> <span>((</span><span>x</span> <span>-</span> <span>x_hat</span><span>)</span><span>**</span><span>2</span><span>)</span><span>.</span><span>sum</span><span>()</span> <span>+</span> <span>model</span><span>.</span><span>kl</span> <span>*</span> <span>annealing</span>
</span></span><span><span>            <span>opt</span><span>.</span><span>zero_grad</span><span>()</span>
</span></span><span><span>            <span>loss</span><span>.</span><span>backward</span><span>()</span>
</span></span><span><span>            <span>opt</span><span>.</span><span>step</span><span>()</span>
</span></span><span><span>        <span># visualize progress</span>
</span></span><span><span>        <span>if</span> <span>epoch</span> <span>%</span> <span>log_every</span> <span>==</span> <span>log_every</span> <span>-</span> <span>1</span><span>:</span>
</span></span><span><span>            <span>with</span> <span>torch</span><span>.</span><span>no_grad</span><span>():</span>
</span></span><span><span>                <span>img</span> <span>=</span> <span>data</span><span>.</span><span>__iter__</span><span>()</span><span>.</span><span>__next__</span><span>()[</span><span>0</span><span>][</span><span>0</span><span>,</span> <span>:,</span> <span>:,</span> <span>:]</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>
</span></span><span><span>                <span>res</span> <span>=</span> <span>model</span><span>(</span><span>img</span><span>)</span>
</span></span><span><span>                <span>plot</span><span>(</span><span>img</span><span>,</span> <span>res</span><span>,</span> <span>block_size</span><span>=</span><span>1</span><span>)</span>
</span></span></code></pre></div><figure><a href="https://swe-to-mle.pages.dev/posts/daedalus-generating-mazes-with-autoencoders-and-variational-autoencoders/vae-annealing-reconstruction.png" title="vae-annealing-reconstruction" data-thumbnail="vae-annealing-reconstruction.png" data-sub-html="&lt;h2&gt;Generate numbers by looking at central positions in the latent space of the VAE with annealing&lt;/h2&gt;&lt;p&gt;vae-annealing-reconstruction&lt;/p&gt;">
        <img src="https://swe-to-mle.pages.dev/svg/loading.min.svg" data-src="vae-annealing-reconstruction.png" data-srcset="vae-annealing-reconstruction.png, vae-annealing-reconstruction.png 1.5x, vae-annealing-reconstruction.png 2x" data-sizes="auto" alt="vae-annealing-reconstruction.png"/>
    </a><figcaption>Generate numbers by looking at central positions in the latent space of the VAE with annealing</figcaption>
    </figure>
<figure><a href="https://swe-to-mle.pages.dev/posts/daedalus-generating-mazes-with-autoencoders-and-variational-autoencoders/vae-annealing-latent.png" title="vae-annealing-latent" data-thumbnail="vae-annealing-latent.png" data-sub-html="&lt;h2&gt;Latent space for the VAE with annealing&lt;/h2&gt;&lt;p&gt;vae-annealing-latent&lt;/p&gt;">
        <img src="https://swe-to-mle.pages.dev/svg/loading.min.svg" data-src="vae-annealing-latent.png" data-srcset="vae-annealing-latent.png, vae-annealing-latent.png 1.5x, vae-annealing-latent.png 2x" data-sizes="auto" alt="vae-annealing-latent.png"/>
    </a><figcaption>Latent space for the VAE with annealing</figcaption>
    </figure>
<h3 id="cyclical-annealing">Cyclical Annealing</h3>
<p>Another improvement proposed was to do cycles of training:</p>
<figure><a href="https://swe-to-mle.pages.dev/posts/daedalus-generating-mazes-with-autoencoders-and-variational-autoencoders/cyclical-annealing.png" title="cyclical-annealing" data-thumbnail="cyclical-annealing.png" data-sub-html="&lt;h2&gt;Cyclical Annealing&lt;/h2&gt;&lt;p&gt;cyclical-annealing&lt;/p&gt;">
        <img src="https://swe-to-mle.pages.dev/svg/loading.min.svg" data-src="cyclical-annealing.png" data-srcset="cyclical-annealing.png, cyclical-annealing.png 1.5x, cyclical-annealing.png 2x" data-sizes="auto" alt="cyclical-annealing.png"/>
    </a><figcaption>Cyclical Annealing</figcaption>
    </figure>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>def</span> <span>cyclic_annealing_train</span><span>(</span><span>model</span><span>,</span> <span>data</span><span>,</span> <span>epochs</span><span>=</span><span>20</span><span>,</span> <span>lr</span><span>=</span><span>3e-4</span><span>,</span> <span>log</span><span>=</span><span>True</span><span>,</span> <span>log_every</span><span>=</span><span>3</span><span>):</span>
</span></span><span><span>    <span>opt</span> <span>=</span> <span>torch</span><span>.</span><span>optim</span><span>.</span><span>Adam</span><span>(</span><span>model</span><span>.</span><span>parameters</span><span>(),</span> <span>lr</span><span>=</span><span>lr</span><span>)</span>
</span></span><span><span>    <span>n_batch</span> <span>=</span> <span>len</span><span>(</span><span>data</span><span>.</span><span>__iter__</span><span>())</span>
</span></span><span><span>    <span>for</span> <span>epoch</span> <span>in</span> <span>range</span><span>(</span><span>epochs</span><span>):</span>
</span></span><span><span>        <span>for</span> <span>i</span><span>,</span> <span>(</span><span>x</span><span>,</span> <span>_label</span><span>)</span> <span>in</span> <span>enumerate</span><span>(</span><span>data</span><span>):</span>
</span></span><span><span>            <span>annealing</span> <span>=</span> <span>min</span><span>(</span><span>i</span><span>,</span> <span>n_batch</span> <span>//</span> <span>2</span><span>)</span> <span>/</span> <span>(</span><span>n_batch</span> <span>//</span> <span>2</span><span>)</span>
</span></span><span><span>            <span>x</span> <span>=</span> <span>x</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>
</span></span><span><span>            <span>x_hat</span> <span>=</span> <span>model</span><span>(</span><span>x</span><span>)</span>
</span></span><span><span>            <span>loss</span> <span>=</span> <span>((</span><span>x</span> <span>-</span> <span>x_hat</span><span>)</span><span>**</span><span>2</span><span>)</span><span>.</span><span>sum</span><span>()</span> <span>+</span> <span>model</span><span>.</span><span>kl</span> <span>*</span> <span>annealing</span>
</span></span><span><span>            <span>opt</span><span>.</span><span>zero_grad</span><span>()</span>
</span></span><span><span>            <span>loss</span><span>.</span><span>backward</span><span>()</span>
</span></span><span><span>            <span>opt</span><span>.</span><span>step</span><span>()</span>
</span></span><span><span>        <span># visualize progress</span>
</span></span><span><span>        <span>if</span> <span>log</span> <span>and</span> <span>epoch</span> <span>%</span> <span>log_every</span> <span>==</span> <span>log_every</span> <span>-</span> <span>1</span><span>:</span>
</span></span><span><span>            <span>with</span> <span>torch</span><span>.</span><span>no_grad</span><span>():</span>
</span></span><span><span>                <span>img</span> <span>=</span> <span>data</span><span>.</span><span>__iter__</span><span>()</span><span>.</span><span>__next__</span><span>()[</span><span>0</span><span>][</span><span>0</span><span>,</span> <span>:,</span> <span>:,</span> <span>:]</span><span>.</span><span>to</span><span>(</span><span>device</span><span>)</span>
</span></span><span><span>                <span>res</span> <span>=</span> <span>model</span><span>(</span><span>img</span><span>)</span>
</span></span><span><span>                <span>plot</span><span>(</span><span>img</span><span>,</span> <span>res</span><span>,</span> <span>block_size</span><span>=</span><span>1</span><span>)</span>
</span></span></code></pre></div><figure><a href="https://swe-to-mle.pages.dev/posts/daedalus-generating-mazes-with-autoencoders-and-variational-autoencoders/vae-cyclic-annealing-reconstruction.png" title="vae-cyclic-annealing-reconstruction" data-thumbnail="vae-cyclic-annealing-reconstruction.png" data-sub-html="&lt;h2&gt;Generate numbers by looking at central positions in the latent space of the VAE with cyclic annealing&lt;/h2&gt;&lt;p&gt;vae-cyclic-annealing-reconstruction&lt;/p&gt;">
        <img src="https://swe-to-mle.pages.dev/svg/loading.min.svg" data-src="vae-cyclic-annealing-reconstruction.png" data-srcset="vae-cyclic-annealing-reconstruction.png, vae-cyclic-annealing-reconstruction.png 1.5x, vae-cyclic-annealing-reconstruction.png 2x" data-sizes="auto" alt="vae-cyclic-annealing-reconstruction.png"/>
    </a><figcaption>Generate numbers by looking at central positions in the latent space of the VAE with cyclic annealing</figcaption>
    </figure>
<figure><a href="https://swe-to-mle.pages.dev/posts/daedalus-generating-mazes-with-autoencoders-and-variational-autoencoders/vae-cyclic-annealing-latent.png" title="vae-cyclic-annealing-latent" data-thumbnail="vae-cyclic-annealing-latent.png" data-sub-html="&lt;h2&gt;Latent space for the VAE with cyclic annealing&lt;/h2&gt;&lt;p&gt;vae-cyclic-annealing-latent&lt;/p&gt;">
        <img src="https://swe-to-mle.pages.dev/svg/loading.min.svg" data-src="vae-cyclic-annealing-latent.png" data-srcset="vae-cyclic-annealing-latent.png, vae-cyclic-annealing-latent.png 1.5x, vae-cyclic-annealing-latent.png 2x" data-sizes="auto" alt="vae-cyclic-annealing-latent.png"/>
    </a><figcaption>Latent space for the VAE with cyclic annealing</figcaption>
    </figure>
<h2 id="generate-mazes">Generate Mazes</h2>
<p>Instead of training on MNIST. We reuse the same code on mazes.</p>
<h3 id="get-a-training-set">Get a training set</h3>
<p>We generate maze using a known algorithm</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>def</span> <span>make_maze</span><span>(</span><span>width</span><span>):</span>
</span></span><span><span>    <span>maze</span> <span>=</span> <span>torch</span><span>.</span><span>zeros</span><span>((</span><span>width</span><span>,</span> <span>width</span><span>))</span>
</span></span><span><span>    <span>def</span> <span>add_exit</span><span>(</span><span>maze</span><span>):</span>
</span></span><span><span>        <span>choices</span> <span>=</span> <span>(</span><span>maze</span> <span>==</span> <span>1</span><span>)</span><span>.</span><span>nonzero</span><span>()</span><span>.</span><span>tolist</span><span>()</span>
</span></span><span><span>        <span>furthest</span> <span>=</span> <span>max</span><span>(</span><span>choices</span><span>,</span> <span>key</span><span>=</span><span>lambda</span> <span>x</span><span>:</span> <span>x</span><span>[</span><span>0</span><span>]</span> <span>+</span> <span>x</span><span>[</span><span>1</span><span>])</span>
</span></span><span><span>        <span>maze</span><span>[</span><span>furthest</span><span>[</span><span>0</span><span>],</span> <span>furthest</span><span>[</span><span>1</span><span>]]</span> <span>=</span> <span>-</span><span>1</span>
</span></span><span><span>
</span></span><span><span>    <span>def</span> <span>rec</span><span>(</span><span>x</span><span>,</span> <span>y</span><span>):</span>
</span></span><span><span>        <span>while</span> <span>True</span><span>:</span>
</span></span><span><span>            <span>pairs</span> <span>=</span> <span>[]</span>
</span></span><span><span>            <span>for</span> <span>move</span> <span>in</span> <span>MOVES</span><span>:</span>
</span></span><span><span>                <span>dx</span><span>,</span> <span>dy</span> <span>=</span> <span>move</span>
</span></span><span><span>                <span>nx</span><span>,</span> <span>ny</span> <span>=</span> <span>x</span> <span>+</span> <span>dx</span><span>,</span> <span>y</span> <span>+</span> <span>dy</span>
</span></span><span><span>                <span>nnx</span><span>,</span> <span>nny</span> <span>=</span> <span>nx</span> <span>+</span> <span>dx</span><span>,</span> <span>ny</span> <span>+</span> <span>dy</span>
</span></span><span><span>                <span>if</span> <span>0</span> <span>&lt;=</span> <span>nnx</span> <span>&lt;</span> <span>width</span> <span>and</span> <span>0</span> <span>&lt;=</span> <span>nny</span> <span>&lt;</span> <span>width</span> <span>and</span> <span>maze</span><span>[</span><span>nnx</span><span>,</span> <span>nny</span><span>]</span> <span>==</span> <span>0</span> <span>and</span> <span>maze</span><span>[</span><span>nx</span><span>,</span> <span>ny</span><span>]</span> <span>==</span> <span>0</span><span>:</span>
</span></span><span><span>                    <span>pairs</span><span>.</span><span>append</span><span>((</span><span>nx</span><span>,</span> <span>ny</span><span>,</span> <span>nnx</span><span>,</span> <span>nny</span><span>))</span>
</span></span><span><span>            <span>random</span><span>.</span><span>shuffle</span><span>(</span><span>pairs</span><span>)</span>
</span></span><span><span>            <span>if</span> <span>not</span> <span>pairs</span><span>:</span> <span>break</span>
</span></span><span><span>            <span>nx</span><span>,</span> <span>ny</span><span>,</span> <span>nnx</span><span>,</span> <span>nny</span> <span>=</span> <span>pairs</span><span>[</span><span>0</span><span>]</span>
</span></span><span><span>            <span>maze</span><span>[</span><span>nx</span><span>,</span> <span>ny</span><span>],</span> <span>maze</span><span>[</span><span>nnx</span><span>,</span> <span>nny</span><span>]</span> <span>=</span> <span>1</span><span>,</span> <span>1</span>
</span></span><span><span>            <span>rec</span><span>(</span><span>nnx</span><span>,</span> <span>nny</span><span>)</span>
</span></span><span><span>
</span></span><span><span>    <span>maze</span><span>[</span><span>0</span><span>,</span> <span>0</span><span>]</span> <span>=</span> <span>1</span>
</span></span><span><span>    <span>rec</span><span>(</span><span>0</span><span>,</span> <span>0</span><span>)</span>
</span></span><span><span>    <span>add_exit</span><span>(</span><span>maze</span><span>)</span>
</span></span><span><span>    <span>return</span> <span>maze</span>
</span></span></code></pre></div><figure><a href="https://swe-to-mle.pages.dev/posts/daedalus-generating-mazes-with-autoencoders-and-variational-autoencoders/maze-creation.gif" title="maze-creation" data-thumbnail="maze-creation.gif" data-sub-html="&lt;h2&gt;Maze Creation&lt;/h2&gt;&lt;p&gt;maze-creation&lt;/p&gt;">
        <img src="https://swe-to-mle.pages.dev/svg/loading.min.svg" data-src="maze-creation.gif" data-srcset="maze-creation.gif, maze-creation.gif 1.5x, maze-creation.gif 2x" data-sizes="auto" alt="maze-creation.gif"/>
    </a><figcaption>Maze Creation</figcaption>
    </figure>
<p>Serve the examples as a torch dataset.</p>
<div><pre tabindex="0"><code data-lang="python"><span><span><span>dataset_size</span> <span>=</span> <span>1280</span>
</span></span><span><span><span>many_mazes</span> <span>=</span> <span>torch</span><span>.</span><span>stack</span><span>([</span><span>make_maze</span><span>(</span><span>28</span><span>)</span><span>.</span><span>unsqueeze</span><span>(</span><span>0</span><span>)</span> <span>for</span> <span>_</span> <span>in</span> <span>range</span><span>(</span><span>dataset_size</span><span>)])</span>
</span></span><span><span><span>labels</span> <span>=</span> <span>torch</span><span>.</span><span>zeros_like</span><span>(</span><span>many_mazes</span><span>)</span>
</span></span><span><span><span>maze_data</span> <span>=</span> <span>torch</span><span>.</span><span>utils</span><span>.</span><span>data</span><span>.</span><span>DataLoader</span><span>(</span>
</span></span><span><span>    <span>torch</span><span>.</span><span>utils</span><span>.</span><span>data</span><span>.</span><span>TensorDataset</span><span>(</span><span>many_mazes</span><span>,</span> <span>labels</span><span>),</span>
</span></span><span><span>    <span>batch_size</span><span>=</span><span>128</span><span>,</span>
</span></span><span><span>    <span>shuffle</span><span>=</span><span>True</span><span>)</span>
</span></span></code></pre></div><p>Train and sample from the latent space.</p>
<figure><a href="https://swe-to-mle.pages.dev/posts/daedalus-generating-mazes-with-autoencoders-and-variational-autoencoders/mazes.png" title="mazes" data-thumbnail="mazes.png" data-sub-html="&lt;h2&gt;Sample mazes from the VAE latent space&lt;/h2&gt;&lt;p&gt;mazes&lt;/p&gt;">
        <img src="https://swe-to-mle.pages.dev/svg/loading.min.svg" data-src="mazes.png" data-srcset="mazes.png, mazes.png 1.5x, mazes.png 2x" data-sizes="auto" alt="mazes.png"/>
    </a><figcaption>Sample mazes from the VAE latent space</figcaption>
    </figure>
<p>I left this one because we can see that the middle is mostly a grid, and the extreme start to have structures. To get something usable we clip the values of the wall to 0 and 1.</p>
<figure><a href="https://swe-to-mle.pages.dev/posts/daedalus-generating-mazes-with-autoencoders-and-variational-autoencoders/mazes-clipped.png" title="mazes-clipped" data-thumbnail="mazes-clipped.png" data-sub-html="&lt;h2&gt;Sample mazes from the VAE latent space and clip&lt;/h2&gt;&lt;p&gt;mazes-clipped&lt;/p&gt;">
        <img src="https://swe-to-mle.pages.dev/svg/loading.min.svg" data-src="mazes-clipped.png" data-srcset="mazes-clipped.png, mazes-clipped.png 1.5x, mazes-clipped.png 2x" data-sizes="auto" alt="mazes-clipped.png"/>
    </a><figcaption>Sample mazes from the VAE latent space and clip</figcaption>
    </figure>
<h2 id="the-code">The code</h2>
<p>You can get the code at <a href="https://github.com/peluche/daedalus" target="_blank" rel="noopener noreffer ">https://github.com/peluche/daedalus</a></p>
<h2 id="sources">Sources</h2>
<p>In the journey to reproduce daedalus work I had to decipher many manuscripts including:</p>
<ul>
<li>autoencoder: <a href="https://arxiv.org/pdf/2003.05991.pdf" target="_blank" rel="noopener noreffer ">https://arxiv.org/pdf/2003.05991.pdf</a></li>
<li>VAE: <a href="https://arxiv.org/pdf/1312.6114.pdf" target="_blank" rel="noopener noreffer ">https://arxiv.org/pdf/1312.6114.pdf</a></li>
<li>Cyclical Annealing: <a href="https://arxiv.org/pdf/1903.10145.pdf" target="_blank" rel="noopener noreffer ">https://arxiv.org/pdf/1903.10145.pdf</a></li>
<li><a href="https://avandekleut.github.io/vae/" target="_blank" rel="noopener noreffer ">https://avandekleut.github.io/vae/</a></li>
<li><a href="https://www.microsoft.com/en-us/research/blog/less-pain-more-gain-a-simple-method-for-vae-training-with-less-of-that-kl-vanishing-agony/" target="_blank" rel="noopener noreffer ">https://www.microsoft.com/en-us/research/blog/less-pain-more-gain-a-simple-method-for-vae-training-with-less-of-that-kl-vanishing-agony/</a></li>
</ul>
<p>And a special thanks to <a href="https://isakfalk.com/" target="_blank" rel="noopener noreffer ">John Isak Texas Falk</a> who’s attending the <a href="https://www.recurse.com/scout/click?t=dcdcd5fced9bfab4a02b4dd6bb05199e" target="_blank" rel="noopener noreffer ">Recurse Center</a> at the same time as me and was kind enough to walk me through some of the mistakes that were bloking me in the Sampling step of VAEs.</p>
</div></div>
  </body>
</html>
