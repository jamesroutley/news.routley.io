<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.plural.sh/blog/kubernetes-statefulsets-are-broken/">Original</a>
    <h1>Kubernetes StatefulSets are Broken</h1>
    
    <div id="readability-page-1" class="page"><div>
          



<article>
    <figure>
    <p><img alt="this is not actually a statefulset" data-srcset="
          /blog/content/images/size/w346/2022/08/Blog-Post-Kubernetes-StatefulSets-are-Broken.png 346w,
          /blog/content/images/size/w692/2022/08/Blog-Post-Kubernetes-StatefulSets-are-Broken.png 692w,
          /blog/content/images/size/w1384/2022/08/Blog-Post-Kubernetes-StatefulSets-are-Broken.png 1384w" sizes="(min-width: 1260px) 692px, (min-width: 1040px) calc(34vw + 270px), (min-width: 640px) calc(90vw - 61px), calc(100vw - 32px)" data-src="/blog/content/images/size/w1384/2022/08/Blog-Post-Kubernetes-StatefulSets-are-Broken.png"/>
    </p>

      <figcaption>This is not actually a statefulset. Photo by Klim Musalimov of <a href="https://unsplash.com/">Unsplash.com</a>.</figcaption>
  </figure>




  <section>
    <p>Don&#39;t get me wrong; we are strong supporters of Kubernetes. It is a critical piece of <a href="https://github.com/pluralsh/plural">our architecture</a> and provides massive value when wielded correctly. But, Kubernetes was originally intended to act as a container orchestration platform for stateless workloads, <strong>not stateful applications</strong>. </p><p>Over the past few years, the Kubernetes community has done a great job evolving the project to support stateful workloads by creating StatefulSets, which is Kubernetes&#39; answer to storage-centric workloads. </p><p>StatefulSets run the gamut from databases, queues, and object store to janky old web applications that need to modify a local filesystem for whatever reason. They provide developers with a set of pretty powerful guarantees:</p><ul><li><strong>Consistent network identity for each pod:</strong> This allows you to easily configure the DNS address to the pod in your application. It works great for database connection strings or configuring complicated Kafka clients. We also use it for setting up erlang‚Äôs mesh network at times too.</li><li><strong>Persistent volume automation:</strong> Whenever a pod is restarted, even if it is rescheduled onto a different node, the persistent volume is reattached to the node it is placed on. This is somewhat limited by the capabilities of the CSI (Container Storage Interface) you‚Äôre using. For instance on AWS this only works within the same regional AZ since EBS volumes are AZ-linked.</li><li><strong>Sequential Rolling Updates:</strong> StatefulSet updates are designed to be rolling and consistent. It will always update in the same order which can help preserve systems that have delicate coordination protocols.</li></ul><p>These guarantees cover a ton of the operations needed to run a stateful workload. In particular, it almost completely handles the availability portion. Given that EBS uptime and redundancy guarantees are extremely strong, the StatefulSet‚Äôs rescheduling automation almost trivially guarantees you a high availability service. However, some caveats do apply (e.g., that you have room in your cluster and don‚Äôt botch the AZ setup.)</p><h2 id="what%E2%80%99s-missing-from-the-kubernetes-statefulset">What‚Äôs Missing From the Kubernetes StatefulSet?<br/></h2><p>So why do we think StatefulSets are broken? Well, if you run through the operational needs of a stateful workload in your head, there‚Äôs one key component that you might notice is missing: </p><p><em>What do you do when you need to resize the underlying disk? </em></p><p>The dataset is a common database store that typically grows at a pretty constant positive rate. Unless you support horizontal scaling and partitioning, you‚Äôll need to add headroom in the disk as that dataset grows. This is where Kubernetes falls flat on its face. </p><p>Currently, the StatefulSet controller has <a href="https://github.com/kubernetes/kubernetes/issues/68737">no built-in support for volume resizing</a>. This is despite the fact that almost all CSI implementations have native support for volume resizing the controller could hook into. There is a workaround, but it‚Äôs almost ludicrously roundabout:</p><ul><li>Delete the StatefulSet while orphaning pods to avoid downtime with: kubectl <strong>delete</strong> sts &lt;<strong>name</strong>&gt; --cascade=orphan</li><li>Manually edit the persistent volume for each pod to the new storage size</li><li>Manually edit the StatefulSet volume claim with the new storage size and add a dummy pod annotation to force a rolling update</li><li>Recreate the StatefulSet with that new spec which allows the controller to reclaim control of the orphaned pods and begin the rolling update which will trigger the CSI to apply the volume resize</li></ul><div><p>üí°</p><p>We actually automated this entire process as <a href="https://github.com/pluralsh/plural-operator/blob/main/controllers/statefulsetresize_controller.go#L70">part of the Plural operator</a>. We knew we‚Äôd need to build storage resize automation to make stateful applications running with Plural to be operable by non-Kubernetes experts. It‚Äôs a nontrivial amount of logic in reality and if someone were asked to do it in a high-pressure scenario, the chances of failure are incredibly high.</p></div><p>Okay, so there‚Äôs a pretty noteworthy flaw in Kubernetes StatefulSets, but there <em>is</em> a workaround even if it‚Äôs somewhat janky. </p><p>That shouldn‚Äôt be too bad, right? </p><h2 id="but-it-gets-worse">But it gets worse!</h2><p>The situation gets downright painful when you realize the impact of this limitation and that a lot of the Kubernetes operators have been built to manage stateful workloads.</p><p>A pretty good example is the <a href="https://github.com/prometheus-operator/prometheus-operator">Prometheus operator</a>, which is a great project for both provisioning Prometheus databases and allowing a CRD-based workflow for configuring metrics, scrapers, and alerts.</p><p>The problem arises because the built-in controller for the operator has no logic to manage StatefulSet resize, but it does have the logic to recreate its underlying StatefulSet if it sees an event that triggered its deletion. This means that you effectively have no way to use the above workaround, since the moment you do a cascade orphan delete, the operator will recreate the StatefulSet against the old spec and prevent proper resize. The only solution is to delete the entire CRD or find a tweak that can fool the operator into not reconciling the object (sometimes scale to zero will do this).</p><p>Regardless, as a result of this flaw, there is effectively no way to resize a Prometheus instance with the operator without either significant downtime or data loss. Considering how robust the automation in StatefulSets is in all other cases, it‚Äôs pretty shocking that this is still a potential failure mode.</p><blockquote>‚ÄúConsidering the natural complexity of a Vitess deployment, you can infer that disk resizing is proportionally complicated. <a href="https://vitess.io/">Vitess</a> is a database sharing system that sits on top of MySQL, meaning that volume resizing had to be both partitioning-aware and shard-aware. We had to manually write our own shard-safe <a href="https://github.com/planetscale/vitess-operator/blob/eeff200e5acaf67db6f01f0f7f945ea7e89d4540/pkg/controller/vitessshard/reconcile_rollout.go#L18">rolling restarts, create a </a><a href="https://github.com/planetscale/vitess-operator/blob/eeff200e5acaf67db6f01f0f7f945ea7e89d4540/pkg/operator/rollout/rollout.go#L82">cascade condition</a> that worked with the parent-child structure of Vitess custom resources, and <a href="https://github.com/planetscale/vitess-operator/blob/eeff200e5acaf67db6f01f0f7f945ea7e89d4540/pkg/controller/vitessshard/reconcile_disk.go#L21">address every conceivable failure</a> condition to prevent downtime. Shoutout to notable Kubernetes contributor <a href="https://mobile.twitter.com/enisoc">enisoc</a> for designing this feature.‚Äù</blockquote><p>Other widely used and notable database operators, like <a href="https://github.com/zalando/postgres-operator">Zalando&#39;s Postgres operator</a>, effectively reimplement the same procedure we implemented in the Plural operator in their own codebase. This causes a ton of wasted developer cycles on a problem that should only have to be fixed once.</p><h2 id="the-potential-of-kubernetes">The Potential of Kubernetes</h2><p>In general, we are extremely bullish on the potential for Kubernetes to make the operations of virtually any workload almost trivial, and a huge part of our mission at <a href="https://github.com/pluralsh/plural/">Plural</a> is to make that a possibility. </p><p>That said, we also need to be clear-eyed about gaps that still remain in the Kubernetes ecosystem, so we can either work around them or close them upstream. I think it‚Äôs pretty clear this is a significant gap, and if prioritized, this could be <a href="https://github.com/kubernetes/kubernetes/pull/110522">fixed pretty easily</a> in a future release of Kubernetes.</p><p>If you thought this was interesting, check out what we‚Äôre building on Kubernetes <a href="https://github.com/pluralsh/plural">here</a>.</p>
  </section>


      
    
    <section>
      <div>
        <h3>Newsletter</h3>
        <p>Be the first to know when we drop something new.</p>
        <form data-members-form="signup">
  <p><label for="subscribe-email-post">Your email address</label>
    
    
  </p>

  <p>Please check your inbox and click the link to confirm your subscription.</p>
  <p>Please enter a valid email address!</p>
  <p>An error occurred, please try again later.</p>
</form>      </div>

      
    </section>

  <hr/>
</article>


<!--
  Get related posts based on tags
 -->


        </div></div>
  </body>
</html>
