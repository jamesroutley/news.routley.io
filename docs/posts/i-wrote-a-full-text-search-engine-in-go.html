<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/wizenheimer/blaze">Original</a>
    <h1>Show HN: I wrote a full text search engine in Go</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text">

<p dir="auto">A high-performance full-text search engine in Go with inverted indexing, boolean queries, phrase search, proximity queries, and BM25 ranking—powered by a flexible query engine, roaring bitmaps, and skip lists.</p>

<ul dir="auto">
<li><a href="#overview">Overview</a></li>
<li><a href="#features">Features</a></li>
<li><a href="#installation">Installation</a></li>
<li><a href="#quick-start">Quick Start</a></li>
<li><a href="#core-concepts">Core Concepts</a>
<ul dir="auto">
<li><a href="#inverted-index">Inverted Index</a></li>
<li><a href="#skip-lists">Skip Lists</a></li>
<li><a href="#text-analysis-pipeline">Text Analysis Pipeline</a></li>
<li><a href="#search-operations">Search Operations</a></li>
</ul>
</li>
<li><a href="#query-builder-api">Query Builder API</a>
<ul dir="auto">
<li><a href="#why-use-builder-pattern">Why Use Builder Pattern</a></li>
<li><a href="#query-builder-quick-start">Quick Start</a></li>
<li><a href="#query-builder-core-methods">Core Methods</a></li>
<li><a href="#boolean-operations">Boolean Operations</a></li>
<li><a href="#query-patterns">Query Patterns</a></li>
<li><a href="#query-builder-performance">Performance</a></li>
<li><a href="#query-builder-best-practices">Best Practices</a></li>
</ul>
</li>
<li><a href="#api-reference">API Reference</a></li>
<li><a href="#examples">Examples</a></li>
<li><a href="#performance-characteristics">Performance Characteristics</a></li>
<li><a href="#configuration">Configuration</a></li>
<li><a href="#use-cases">Use Cases</a></li>
<li><a href="#testing">Testing</a></li>
<li><a href="#architecture">Architecture</a></li>
<li><a href="#best-practices">Best Practices</a></li>
<li><a href="#contributing">Contributing</a></li>
<li><a href="#license">License</a></li>
</ul>

<p dir="auto">Blaze is a Go engine that provides fast, full-text search capabilities through an inverted index implementation. It&#39;s designed for applications that need to search through text documents efficiently without relying on external search engines.</p>
<p dir="auto"><strong>Key Highlights:</strong></p>
<ul dir="auto">
<li><strong>Inverted Index</strong>: Maps terms to document positions for instant lookups</li>
<li><strong>Skip Lists</strong>: Probabilistic data structure providing O(log n) operations</li>
<li><strong>Query Builder</strong>: Type-safe, fluent API for boolean queries with roaring bitmaps</li>
<li><strong>Advanced Search</strong>: Phrase search, BM25 ranking, proximity ranking, and boolean queries</li>
<li><strong>BM25 Algorithm</strong>: Industry-standard relevance scoring with IDF and length normalization</li>
<li><strong>Text Analysis</strong>: Tokenization, stemming, stopword filtering, and case normalization</li>
<li><strong>Thread-Safe</strong>: Concurrent indexing with mutex protection</li>
<li><strong>Serialization</strong>: Efficient binary format for persistence</li>
</ul>


<ul dir="auto">
<li><strong>Term Search</strong>: Find documents containing specific terms</li>
<li><strong>Phrase Search</strong>: Exact multi-word matching (&#34;quick brown fox&#34;)</li>
<li><strong>Boolean Queries</strong>: Type-safe AND, OR, NOT operations with query builder</li>
<li><strong>BM25 Ranking</strong>: Industry-standard relevance scoring (used by Elasticsearch, Solr)</li>
<li><strong>Proximity Ranking</strong>: Score results by term proximity</li>
<li><strong>Position Tracking</strong>: Track exact word positions within documents</li>
<li><strong>Roaring Bitmaps</strong>: Compressed bitmap operations for fast boolean queries</li>
</ul>

<ul dir="auto">
<li><strong>Tokenization</strong>: Unicode-aware text splitting</li>
<li><strong>Stemming</strong>: Snowball (Porter2) stemmer for English</li>
<li><strong>Stopword Filtering</strong>: Remove common words (the, a, is, etc.)</li>
<li><strong>Case Normalization</strong>: Case-insensitive search</li>
<li><strong>Configurable Pipeline</strong>: Customize analysis behavior</li>
</ul>

<ul dir="auto">
<li><strong>Skip Lists</strong>: O(log n) search, insert, and delete operations</li>
<li><strong>Inverted Index</strong>: Efficient term-to-position mapping</li>
<li><strong>Binary Serialization</strong>: Compact storage format</li>
</ul>

<div dir="auto" data-snippet-clipboard-copy-content="go get github.com/wizenheimer/blaze"><pre>go get github.com/wizenheimer/blaze</pre></div>

<div dir="auto" data-snippet-clipboard-copy-content="package main

import (
    &#34;fmt&#34;
    &#34;github.com/wizenheimer/blaze&#34;
)

func main() {
    // Create a new inverted index
    idx := blaze.NewInvertedIndex()

    // Index some documents
    idx.Index(1, &#34;The quick brown fox jumps over the lazy dog&#34;)
    idx.Index(2, &#34;A quick brown dog runs fast&#34;)
    idx.Index(3, &#34;The lazy cat sleeps all day&#34;)

    // Search for documents containing &#34;quick&#34; and &#34;brown&#34;
    matches := idx.RankProximity(&#34;quick brown&#34;, 10)

    // Print results
    for _, match := range matches {
        fmt.Printf(&#34;Document %d (score: %.2f)\n&#34;,
            int(match.Offsets[0].DocumentID),
            match.Score)
    }
}"><pre><span>package</span> main

<span>import</span> (
    <span>&#34;fmt&#34;</span>
    <span>&#34;github.com/wizenheimer/blaze&#34;</span>
)

<span>func</span> <span>main</span>() {
    <span>// Create a new inverted index</span>
    <span>idx</span> <span>:=</span> <span>blaze</span>.<span>NewInvertedIndex</span>()

    <span>// Index some documents</span>
    <span>idx</span>.<span>Index</span>(<span>1</span>, <span>&#34;The quick brown fox jumps over the lazy dog&#34;</span>)
    <span>idx</span>.<span>Index</span>(<span>2</span>, <span>&#34;A quick brown dog runs fast&#34;</span>)
    <span>idx</span>.<span>Index</span>(<span>3</span>, <span>&#34;The lazy cat sleeps all day&#34;</span>)

    <span>// Search for documents containing &#34;quick&#34; and &#34;brown&#34;</span>
    <span>matches</span> <span>:=</span> <span>idx</span>.<span>RankProximity</span>(<span>&#34;quick brown&#34;</span>, <span>10</span>)

    <span>// Print results</span>
    <span>for</span> <span>_</span>, <span>match</span> <span>:=</span> <span>range</span> <span>matches</span> {
        <span>fmt</span>.<span>Printf</span>(<span>&#34;Document %d (score: %.2f)<span>\n</span>&#34;</span>,
            <span>int</span>(<span>match</span>.<span>Offsets</span>[<span>0</span>].<span>DocumentID</span>),
            <span>match</span>.<span>Score</span>)
    }
}</pre></div>
<p dir="auto"><strong>Output:</strong></p>
<div data-snippet-clipboard-copy-content="Document 2 (score: 1.00)
Document 1 (score: 0.50)"><pre><code>Document 2 (score: 1.00)
Document 1 (score: 0.50)
</code></pre></div>


<p dir="auto">An inverted index is like the index at the back of a book. Instead of scanning every document to find a word, the index tells you exactly where each word appears.</p>
<p dir="auto"><strong>Example:</strong></p>
<p dir="auto">Given these documents:</p>
<div data-snippet-clipboard-copy-content="Doc 1: &#34;the quick brown fox&#34;
        Pos:0    1     2     3

Doc 2: &#34;the lazy dog&#34;
        Pos:0   1    2

Doc 3: &#34;quick brown dogs&#34;
        Pos:0    1     2"><pre><code>Doc 1: &#34;the quick brown fox&#34;
        Pos:0    1     2     3

Doc 2: &#34;the lazy dog&#34;
        Pos:0   1    2

Doc 3: &#34;quick brown dogs&#34;
        Pos:0    1     2
</code></pre></div>
<p dir="auto">The inverted index looks like:</p>
<div data-snippet-clipboard-copy-content="┌─────────┬────────────────────────────────────┐
│  Token  │         Posting List               │
├─────────┼────────────────────────────────────┤
│ &#34;quick&#34; │ → [Doc1:Pos1] → [Doc3:Pos0]        │
│ &#34;brown&#34; │ → [Doc1:Pos2] → [Doc3:Pos1]        │
│ &#34;fox&#34;   │ → [Doc1:Pos3]                      │
│ &#34;lazy&#34;  │ → [Doc2:Pos1]                      │
│ &#34;dog&#34;   │ → [Doc2:Pos2]                      │
│ &#34;dogs&#34;  │ → [Doc3:Pos2]                      │
└─────────┴────────────────────────────────────┘"><pre><code>┌─────────┬────────────────────────────────────┐
│  Token  │         Posting List               │
├─────────┼────────────────────────────────────┤
│ &#34;quick&#34; │ → [Doc1:Pos1] → [Doc3:Pos0]        │
│ &#34;brown&#34; │ → [Doc1:Pos2] → [Doc3:Pos1]        │
│ &#34;fox&#34;   │ → [Doc1:Pos3]                      │
│ &#34;lazy&#34;  │ → [Doc2:Pos1]                      │
│ &#34;dog&#34;   │ → [Doc2:Pos2]                      │
│ &#34;dogs&#34;  │ → [Doc3:Pos2]                      │
└─────────┴────────────────────────────────────┘
</code></pre></div>
<p dir="auto"><strong>Visual Representation:</strong></p>
<div data-snippet-clipboard-copy-content="                    Inverted Index
                    ┌──────────┐
                    │ Map      │
                    │ [string] │
                    │ SkipList │
                    └────┬─────┘
                         │
        ┌────────────────┼────────────────┐
        │                │                │
        ▼                ▼                ▼
   &#34;quick&#34;          &#34;brown&#34;           &#34;fox&#34;
   SkipList         SkipList         SkipList
   ┌──────┐        ┌──────┐         ┌──────┐
   │ HEAD │        │ HEAD │         │ HEAD │
   └──┬───┘        └──┬───┘         └──┬───┘
      │               │                 │
      ▼               ▼                 ▼
   ┌──────┐        ┌──────┐         ┌──────┐
   │Doc1:1│        │Doc1:2│         │Doc1:3│
   └──┬───┘        └──┬───┘         └──────┘
      │               │
      ▼               ▼
   ┌──────┐        ┌──────┐
   │Doc3:0│        │Doc3:1│
   └──────┘        └──────┘"><pre><code>                    Inverted Index
                    ┌──────────┐
                    │ Map      │
                    │ [string] │
                    │ SkipList │
                    └────┬─────┘
                         │
        ┌────────────────┼────────────────┐
        │                │                │
        ▼                ▼                ▼
   &#34;quick&#34;          &#34;brown&#34;           &#34;fox&#34;
   SkipList         SkipList         SkipList
   ┌──────┐        ┌──────┐         ┌──────┐
   │ HEAD │        │ HEAD │         │ HEAD │
   └──┬───┘        └──┬───┘         └──┬───┘
      │               │                 │
      ▼               ▼                 ▼
   ┌──────┐        ┌──────┐         ┌──────┐
   │Doc1:1│        │Doc1:2│         │Doc1:3│
   └──┬───┘        └──┬───┘         └──────┘
      │               │
      ▼               ▼
   ┌──────┐        ┌──────┐
   │Doc3:0│        │Doc3:1│
   └──────┘        └──────┘
</code></pre></div>
<p dir="auto"><strong>Benefits:</strong></p>
<ul dir="auto">
<li>Instant term lookups (no document scanning)</li>
<li>Phrase search via position checking</li>
<li>Proximity ranking by measuring distances</li>
<li>Efficient boolean queries (AND, OR, NOT)</li>
</ul>

<p dir="auto">A skip list is a probabilistic data structure that maintains sorted data with O(log n) average time complexity for search, insertion, and deletion.</p>
<p dir="auto"><strong>Visual Representation:</strong></p>
<div data-snippet-clipboard-copy-content="Skip List with Multiple Levels (Express Lanes)
═══════════════════════════════════════════════════════════════

Level 3: HEAD ────────────────────────────────────────────────────────────&gt; [30] ────────&gt; NULL
              ↓                                                                ↓
Level 2: HEAD ─────────────────────────────&gt; [15] ────────────────────────&gt; [30] ────────&gt; NULL
              ↓                                ↓                               ↓
Level 1: HEAD ─────────────&gt; [10] ─────────&gt; [15] ────────&gt; [20] ─────────&gt; [30] ────────&gt; NULL
              ↓                ↓                ↓              ↓                ↓
Level 0: HEAD ──&gt; [5] ──&gt; [10] ──&gt; [15] ──&gt; [20] ──&gt; [25] ──&gt; [30] ──&gt; [35] ──&gt; NULL
         (ALL NODES AT LEVEL 0)

         ┌───────┐
         │ Node  │  Each node has a &#34;tower&#34; of forward pointers
         ├───────┤
         │ Key   │  Example: Node [15]
         ├───────┤
         │ Lvl 3 │ ──&gt; [30]      (skip far ahead)
         │ Lvl 2 │ ──&gt; [30]      (skip ahead)
         │ Lvl 1 │ ──&gt; [20]      (skip a little)
         │ Lvl 0 │ ──&gt; [20]      (next node)
         └───────┘"><pre><code>Skip List with Multiple Levels (Express Lanes)
═══════════════════════════════════════════════════════════════

Level 3: HEAD ────────────────────────────────────────────────────────────&gt; [30] ────────&gt; NULL
              ↓                                                                ↓
Level 2: HEAD ─────────────────────────────&gt; [15] ────────────────────────&gt; [30] ────────&gt; NULL
              ↓                                ↓                               ↓
Level 1: HEAD ─────────────&gt; [10] ─────────&gt; [15] ────────&gt; [20] ─────────&gt; [30] ────────&gt; NULL
              ↓                ↓                ↓              ↓                ↓
Level 0: HEAD ──&gt; [5] ──&gt; [10] ──&gt; [15] ──&gt; [20] ──&gt; [25] ──&gt; [30] ──&gt; [35] ──&gt; NULL
         (ALL NODES AT LEVEL 0)

         ┌───────┐
         │ Node  │  Each node has a &#34;tower&#34; of forward pointers
         ├───────┤
         │ Key   │  Example: Node [15]
         ├───────┤
         │ Lvl 3 │ ──&gt; [30]      (skip far ahead)
         │ Lvl 2 │ ──&gt; [30]      (skip ahead)
         │ Lvl 1 │ ──&gt; [20]      (skip a little)
         │ Lvl 0 │ ──&gt; [20]      (next node)
         └───────┘
</code></pre></div>
<p dir="auto"><strong>How Heights are Assigned (Probabilistic):</strong></p>
<div data-snippet-clipboard-copy-content="Coin Flip Algorithm:
┌─────────┬─────────────┬─────────────┐
│ Height  │ Probability │ Visual      │
├─────────┼─────────────┼─────────────┤
│    1    │    50%      │ ▓▓▓▓▓       │
│    2    │    25%      │ ▓▓▓         │
│    3    │   12.5%     │ ▓▓          │
│    4    │   6.25%     │ ▓           │
└─────────┴─────────────┴─────────────┘

For 1000 nodes, expected distribution:
Level 0: ~1000 nodes (all)    ████████████████████████████████████████
Level 1: ~500 nodes           ████████████████████
Level 2: ~250 nodes           ██████████
Level 3: ~125 nodes           █████
Level 4: ~62 nodes            ██"><pre><code>Coin Flip Algorithm:
┌─────────┬─────────────┬─────────────┐
│ Height  │ Probability │ Visual      │
├─────────┼─────────────┼─────────────┤
│    1    │    50%      │ ▓▓▓▓▓       │
│    2    │    25%      │ ▓▓▓         │
│    3    │   12.5%     │ ▓▓          │
│    4    │   6.25%     │ ▓           │
└─────────┴─────────────┴─────────────┘

For 1000 nodes, expected distribution:
Level 0: ~1000 nodes (all)    ████████████████████████████████████████
Level 1: ~500 nodes           ████████████████████
Level 2: ~250 nodes           ██████████
Level 3: ~125 nodes           █████
Level 4: ~62 nodes            ██
</code></pre></div>
<p dir="auto"><strong>Search Algorithm</strong> (finding 20):</p>
<div data-snippet-clipboard-copy-content="Step-by-Step Search for Key = 20:

Level 3: [HEAD] ───────────────────────────────&gt; [30]        (30 &gt; 20, drop down)
           ↓
Level 2: [HEAD] ──────────────&gt; [15] ─────────&gt; [30]        (15 &lt; 20, advance)
                                   ↓
Level 2:                         [15] ─────────&gt; [30]        (30 &gt; 20, drop down)
                                   ↓
Level 1:                         [15] ──&gt; [20]               (20 = 20, FOUND!)
                                          ^^^^

Journey Recorded:
┌───────────┬─────────────────┐
│ Level 3   │ HEAD            │  Predecessor at each level
│ Level 2   │ [15]            │  Used for insertions/deletions
│ Level 1   │ [15]            │
│ Level 0   │ [15]            │
└───────────┴─────────────────┘"><pre><code>Step-by-Step Search for Key = 20:

Level 3: [HEAD] ───────────────────────────────&gt; [30]        (30 &gt; 20, drop down)
           ↓
Level 2: [HEAD] ──────────────&gt; [15] ─────────&gt; [30]        (15 &lt; 20, advance)
                                   ↓
Level 2:                         [15] ─────────&gt; [30]        (30 &gt; 20, drop down)
                                   ↓
Level 1:                         [15] ──&gt; [20]               (20 = 20, FOUND!)
                                          ^^^^

Journey Recorded:
┌───────────┬─────────────────┐
│ Level 3   │ HEAD            │  Predecessor at each level
│ Level 2   │ [15]            │  Used for insertions/deletions
│ Level 1   │ [15]            │
│ Level 0   │ [15]            │
└───────────┴─────────────────┘
</code></pre></div>
<ol dir="auto">
<li>Start at HEAD, Level 3</li>
<li>Level 3: Move to 30? No (30 &gt; 20), drop to Level 2</li>
<li>Level 2: Move to 15? Yes (15 &lt; 20), advance to 15</li>
<li>Level 2: Move to 30? No (30 &gt; 20), drop to Level 1</li>
<li>Level 1: Move to 20? Yes! Found it!</li>
</ol>
<p dir="auto"><strong>Time Complexity: O(log n) on average</strong></p>
<p dir="auto"><strong>Why Skip Lists?</strong></p>
<ul dir="auto">
<li>O(log n) operations without complex balancing</li>
<li>Simpler than AVL or Red-Black trees</li>
<li>Better cache locality than trees</li>
<li>Easier to make lock-free for concurrency</li>
<li>Used in Redis, LevelDB, and other databases</li>
</ul>

<p dir="auto">Blaze transforms raw text into searchable tokens through a multi-stage pipeline:</p>
<p dir="auto"><strong>Pipeline Stages:</strong></p>
<div data-snippet-clipboard-copy-content="┌─────────────────────────────────────────────────────────────────────┐
│                     Text Analysis Pipeline                          │
└─────────────────────────────────────────────────────────────────────┘
                              │
                              ▼
         ┌────────────────────────────────────────┐
         │  1. Tokenization                       │
         │  Split on non-alphanumeric chars       │
         └────────────────┬───────────────────────┘
                          ▼
         ┌────────────────────────────────────────┐
         │  2. Lowercasing                        │
         │  Normalize case (&#34;Quick&#34; → &#34;quick&#34;)    │
         └────────────────┬───────────────────────┘
                          ▼
         ┌────────────────────────────────────────┐
         │  3. Stopword Filtering                 │
         │  Remove common words (the, a, is)      │
         └────────────────┬───────────────────────┘
                          ▼
         ┌────────────────────────────────────────┐
         │  4. Length Filtering                   │
         │  Remove tokens &lt; 2 chars               │
         └────────────────┬───────────────────────┘
                          ▼
         ┌────────────────────────────────────────┐
         │  5. Stemming (Snowball/Porter2)        │
         │  Reduce to root (&#34;running&#34; → &#34;run&#34;)    │
         └────────────────┬───────────────────────┘
                          ▼
                    Final Tokens"><pre><code>┌─────────────────────────────────────────────────────────────────────┐
│                     Text Analysis Pipeline                          │
└─────────────────────────────────────────────────────────────────────┘
                              │
                              ▼
         ┌────────────────────────────────────────┐
         │  1. Tokenization                       │
         │  Split on non-alphanumeric chars       │
         └────────────────┬───────────────────────┘
                          ▼
         ┌────────────────────────────────────────┐
         │  2. Lowercasing                        │
         │  Normalize case (&#34;Quick&#34; → &#34;quick&#34;)    │
         └────────────────┬───────────────────────┘
                          ▼
         ┌────────────────────────────────────────┐
         │  3. Stopword Filtering                 │
         │  Remove common words (the, a, is)      │
         └────────────────┬───────────────────────┘
                          ▼
         ┌────────────────────────────────────────┐
         │  4. Length Filtering                   │
         │  Remove tokens &lt; 2 chars               │
         └────────────────┬───────────────────────┘
                          ▼
         ┌────────────────────────────────────────┐
         │  5. Stemming (Snowball/Porter2)        │
         │  Reduce to root (&#34;running&#34; → &#34;run&#34;)    │
         └────────────────┬───────────────────────┘
                          ▼
                    Final Tokens
</code></pre></div>
<p dir="auto"><strong>Example Transformation:</strong></p>
<div data-snippet-clipboard-copy-content="Input:  &#34;The Quick Brown Fox Jumps!&#34;
        │
        ├─ Step 1: Tokenization
        │  └─&gt; [&#34;The&#34;, &#34;Quick&#34;, &#34;Brown&#34;, &#34;Fox&#34;, &#34;Jumps&#34;]
        │
        ├─ Step 2: Lowercasing
        │  └─&gt; [&#34;the&#34;, &#34;quick&#34;, &#34;brown&#34;, &#34;fox&#34;, &#34;jumps&#34;]
        │
        ├─ Step 3: Stopword Filtering (remove &#34;the&#34;)
        │  └─&gt; [&#34;quick&#34;, &#34;brown&#34;, &#34;fox&#34;, &#34;jumps&#34;]
        │
        ├─ Step 4: Length Filtering (all pass &gt;= 2 chars)
        │  └─&gt; [&#34;quick&#34;, &#34;brown&#34;, &#34;fox&#34;, &#34;jumps&#34;]
        │
        └─ Step 5: Stemming (&#34;jumps&#34; → &#34;jump&#34;)
           └─&gt; [&#34;quick&#34;, &#34;brown&#34;, &#34;fox&#34;, &#34;jump&#34;]"><pre><code>Input:  &#34;The Quick Brown Fox Jumps!&#34;
        │
        ├─ Step 1: Tokenization
        │  └─&gt; [&#34;The&#34;, &#34;Quick&#34;, &#34;Brown&#34;, &#34;Fox&#34;, &#34;Jumps&#34;]
        │
        ├─ Step 2: Lowercasing
        │  └─&gt; [&#34;the&#34;, &#34;quick&#34;, &#34;brown&#34;, &#34;fox&#34;, &#34;jumps&#34;]
        │
        ├─ Step 3: Stopword Filtering (remove &#34;the&#34;)
        │  └─&gt; [&#34;quick&#34;, &#34;brown&#34;, &#34;fox&#34;, &#34;jumps&#34;]
        │
        ├─ Step 4: Length Filtering (all pass &gt;= 2 chars)
        │  └─&gt; [&#34;quick&#34;, &#34;brown&#34;, &#34;fox&#34;, &#34;jumps&#34;]
        │
        └─ Step 5: Stemming (&#34;jumps&#34; → &#34;jump&#34;)
           └─&gt; [&#34;quick&#34;, &#34;brown&#34;, &#34;fox&#34;, &#34;jump&#34;]
</code></pre></div>
<p dir="auto"><strong>Configuration:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="// Use default configuration
tokens := blaze.Analyze(&#34;The quick brown fox&#34;)

// Custom configuration
config := blaze.AnalyzerConfig{
    MinTokenLength:  3,      // Only keep tokens &gt;= 3 chars
    EnableStemming:  false,  // Disable stemming
    EnableStopwords: true,   // Keep stopword filtering
}
tokens := blaze.AnalyzeWithConfig(&#34;The quick brown fox&#34;, config)"><pre><span>// Use default configuration</span>
<span>tokens</span> <span>:=</span> <span>blaze</span>.<span>Analyze</span>(<span>&#34;The quick brown fox&#34;</span>)

<span>// Custom configuration</span>
<span>config</span> <span>:=</span> blaze.<span>AnalyzerConfig</span>{
    <span>MinTokenLength</span>:  <span>3</span>,      <span>// Only keep tokens &gt;= 3 chars</span>
    <span>EnableStemming</span>:  <span>false</span>,  <span>// Disable stemming</span>
    <span>EnableStopwords</span>: <span>true</span>,   <span>// Keep stopword filtering</span>
}
<span>tokens</span> <span>:=</span> <span>blaze</span>.<span>AnalyzeWithConfig</span>(<span>&#34;The quick brown fox&#34;</span>, <span>config</span>)</pre></div>


<p dir="auto">Find all occurrences of a single term:</p>
<div dir="auto" data-snippet-clipboard-copy-content="idx := blaze.NewInvertedIndex()
idx.Index(1, &#34;the quick brown fox&#34;)
idx.Index(2, &#34;quick brown dogs&#34;)

// Find first occurrence of &#34;quick&#34;
pos, err := idx.First(&#34;quick&#34;)
if err == nil {
    fmt.Printf(&#34;Found at Doc %d, Pos %d\n&#34;,
        int(pos.DocumentID), int(pos.Offset))
}

// Find next occurrence
nextPos, _ := idx.Next(&#34;quick&#34;, pos)"><pre><span>idx</span> <span>:=</span> <span>blaze</span>.<span>NewInvertedIndex</span>()
<span>idx</span>.<span>Index</span>(<span>1</span>, <span>&#34;the quick brown fox&#34;</span>)
<span>idx</span>.<span>Index</span>(<span>2</span>, <span>&#34;quick brown dogs&#34;</span>)

<span>// Find first occurrence of &#34;quick&#34;</span>
<span>pos</span>, <span>err</span> <span>:=</span> <span>idx</span>.<span>First</span>(<span>&#34;quick&#34;</span>)
<span>if</span> <span>err</span> <span>==</span> <span>nil</span> {
    <span>fmt</span>.<span>Printf</span>(<span>&#34;Found at Doc %d, Pos %d<span>\n</span>&#34;</span>,
        <span>int</span>(<span>pos</span>.<span>DocumentID</span>), <span>int</span>(<span>pos</span>.<span>Offset</span>))
}

<span>// Find next occurrence</span>
<span>nextPos</span>, <span>_</span> <span>:=</span> <span>idx</span>.<span>Next</span>(<span>&#34;quick&#34;</span>, <span>pos</span>)</pre></div>

<p dir="auto">Find exact sequences of words:</p>
<div dir="auto" data-snippet-clipboard-copy-content="// Find documents containing &#34;quick brown fox&#34; as a phrase
matches := idx.FindAllPhrases(&#34;quick brown fox&#34;, blaze.BOFDocument)

for _, match := range matches {
    start, end := match[0], match[1]
    fmt.Printf(&#34;Found in Doc %d from Pos %d to %d\n&#34;,
        int(start.DocumentID), int(start.Offset), int(end.Offset))
}"><pre><span>// Find documents containing &#34;quick brown fox&#34; as a phrase</span>
<span>matches</span> <span>:=</span> <span>idx</span>.<span>FindAllPhrases</span>(<span>&#34;quick brown fox&#34;</span>, <span>blaze</span>.<span>BOFDocument</span>)

<span>for</span> <span>_</span>, <span>match</span> <span>:=</span> <span>range</span> <span>matches</span> {
    <span>start</span>, <span>end</span> <span>:=</span> <span>match</span>[<span>0</span>], <span>match</span>[<span>1</span>]
    <span>fmt</span>.<span>Printf</span>(<span>&#34;Found in Doc %d from Pos %d to %d<span>\n</span>&#34;</span>,
        <span>int</span>(<span>start</span>.<span>DocumentID</span>), <span>int</span>(<span>start</span>.<span>Offset</span>), <span>int</span>(<span>end</span>.<span>Offset</span>))
}</pre></div>
<p dir="auto"><strong>Algorithm:</strong></p>
<div data-snippet-clipboard-copy-content="Searching for phrase: &#34;brown fox&#34;

Document: &#34;the quick brown dog jumped over the brown fox&#34;
Positions: 0     1     2    3     4      5    6     7    8

Phase 1: Find END (last word &#34;fox&#34;)
┌─────────────────────────────────────────────────────────┐
│ Find &#34;brown&#34; → Doc:Pos2                                 │
│ Find &#34;fox&#34; after Pos2 → Doc:Pos8  ← END position       │
└─────────────────────────────────────────────────────────┘

Phase 2: Walk BACKWARDS from END to find START
┌─────────────────────────────────────────────────────────┐
│ From Pos9, find previous &#34;brown&#34; → Doc:Pos7  ← START   │
└─────────────────────────────────────────────────────────┘

Phase 3: Validate
┌─────────────────────────────────────────────────────────┐
│ Start: Pos7, End: Pos8                                  │
│ Distance: 8 - 7 = 1                                     │
│ Expected: 2 words - 1 = 1  MATCH!                      │
│                                                          │
│      &#34;brown&#34;  &#34;fox&#34;                                     │
│        ▲       ▲                                        │
│       Pos7    Pos8    (consecutive positions)           │
└─────────────────────────────────────────────────────────┘"><pre><code>Searching for phrase: &#34;brown fox&#34;

Document: &#34;the quick brown dog jumped over the brown fox&#34;
Positions: 0     1     2    3     4      5    6     7    8

Phase 1: Find END (last word &#34;fox&#34;)
┌─────────────────────────────────────────────────────────┐
│ Find &#34;brown&#34; → Doc:Pos2                                 │
│ Find &#34;fox&#34; after Pos2 → Doc:Pos8  ← END position       │
└─────────────────────────────────────────────────────────┘

Phase 2: Walk BACKWARDS from END to find START
┌─────────────────────────────────────────────────────────┐
│ From Pos9, find previous &#34;brown&#34; → Doc:Pos7  ← START   │
└─────────────────────────────────────────────────────────┘

Phase 3: Validate
┌─────────────────────────────────────────────────────────┐
│ Start: Pos7, End: Pos8                                  │
│ Distance: 8 - 7 = 1                                     │
│ Expected: 2 words - 1 = 1  MATCH!                      │
│                                                          │
│      &#34;brown&#34;  &#34;fox&#34;                                     │
│        ▲       ▲                                        │
│       Pos7    Pos8    (consecutive positions)           │
└─────────────────────────────────────────────────────────┘
</code></pre></div>
<ol dir="auto">
<li>Find END: Locate the last word of the phrase</li>
<li>Walk BACKWARDS: Find previous occurrences of earlier words</li>
<li>Validate: Check if positions are consecutive</li>
<li>Recurse: Continue searching for more matches</li>
</ol>

<p dir="auto">Find documents containing all terms (not necessarily consecutive):</p>
<div dir="auto" data-snippet-clipboard-copy-content="// Find documents with both &#34;quick&#34; and &#34;fox&#34;
cover := idx.NextCover([]string{&#34;quick&#34;, &#34;fox&#34;}, blaze.BOFDocument)
start, end := cover[0], cover[1]

// Calculate proximity score
distance := end.Offset - start.Offset
score := 1.0 / distance  // Closer terms = higher score"><pre><span>// Find documents with both &#34;quick&#34; and &#34;fox&#34;</span>
<span>cover</span> <span>:=</span> <span>idx</span>.<span>NextCover</span>([]<span>string</span>{<span>&#34;quick&#34;</span>, <span>&#34;fox&#34;</span>}, <span>blaze</span>.<span>BOFDocument</span>)
<span>start</span>, <span>end</span> <span>:=</span> <span>cover</span>[<span>0</span>], <span>cover</span>[<span>1</span>]

<span>// Calculate proximity score</span>
<span>distance</span> <span>:=</span> <span>end</span>.<span>Offset</span> <span>-</span> <span>start</span>.<span>Offset</span>
<span>score</span> <span>:=</span> <span>1.0</span> <span>/</span> <span>distance</span>  <span>// Closer terms = higher score</span></pre></div>
<p dir="auto"><strong>Cover Algorithm:</strong></p>
<div data-snippet-clipboard-copy-content="Searching for: [&#34;quick&#34;, &#34;fox&#34;] (any order, not necessarily consecutive)

Document: &#34;the quick brown dog jumped over the lazy fox&#34;
Positions: 0     1     2    3     4      5    6    7    8

Phase 1: Find COVER END (furthest term)
┌──────────────────────────────────────────────────────────────┐
│ Find &#34;quick&#34; after BOF → Doc:Pos1                           │
│ Find &#34;fox&#34; after BOF → Doc:Pos8  ← FURTHEST (cover end)     │
└──────────────────────────────────────────────────────────────┘

Phase 2: Find COVER START (earliest term before end)
┌──────────────────────────────────────────────────────────────┐
│ Find &#34;quick&#34; before Pos9 → Doc:Pos1  ← EARLIEST (cover start)│
│ Find &#34;fox&#34; before Pos9 → Doc:Pos8                           │
└──────────────────────────────────────────────────────────────┘

Phase 3: Validate &amp; Return
┌──────────────────────────────────────────────────────────────┐
│ Cover: [Pos1, Pos8]                                          │
│ Same document? Yes                                           │
│ All terms present? Yes                                       │
│                                                               │
│ &#34;quick&#34; ... ... ... ... ... ... ... &#34;fox&#34;                    │
│    ▲                                   ▲                     │
│   Pos1                                Pos8                   │
│   └────────── Cover Range ──────────────┘                    │
│                                                               │
│ Proximity Score: 1 / (8 - 1 + 1) = 1/8 = 0.125             │
└──────────────────────────────────────────────────────────────┘"><pre><code>Searching for: [&#34;quick&#34;, &#34;fox&#34;] (any order, not necessarily consecutive)

Document: &#34;the quick brown dog jumped over the lazy fox&#34;
Positions: 0     1     2    3     4      5    6    7    8

Phase 1: Find COVER END (furthest term)
┌──────────────────────────────────────────────────────────────┐
│ Find &#34;quick&#34; after BOF → Doc:Pos1                           │
│ Find &#34;fox&#34; after BOF → Doc:Pos8  ← FURTHEST (cover end)     │
└──────────────────────────────────────────────────────────────┘

Phase 2: Find COVER START (earliest term before end)
┌──────────────────────────────────────────────────────────────┐
│ Find &#34;quick&#34; before Pos9 → Doc:Pos1  ← EARLIEST (cover start)│
│ Find &#34;fox&#34; before Pos9 → Doc:Pos8                           │
└──────────────────────────────────────────────────────────────┘

Phase 3: Validate &amp; Return
┌──────────────────────────────────────────────────────────────┐
│ Cover: [Pos1, Pos8]                                          │
│ Same document? Yes                                           │
│ All terms present? Yes                                       │
│                                                               │
│ &#34;quick&#34; ... ... ... ... ... ... ... &#34;fox&#34;                    │
│    ▲                                   ▲                     │
│   Pos1                                Pos8                   │
│   └────────── Cover Range ──────────────┘                    │
│                                                               │
│ Proximity Score: 1 / (8 - 1 + 1) = 1/8 = 0.125             │
└──────────────────────────────────────────────────────────────┘
</code></pre></div>
<ol dir="auto">
<li>Find FURTHEST occurrence of any term (cover end)</li>
<li>Find EARLIEST occurrence of each term before end (cover start)</li>
<li>Validate all terms are in the same document</li>
<li>Return [start, end] positions</li>
</ol>

<p dir="auto"><strong>BM25 (Best Matching 25)</strong> is a probabilistic ranking function used by search engines to estimate the relevance of documents to a given search query. It&#39;s the industry standard used by Elasticsearch, Solr, and Lucene.</p>
<div dir="auto" data-snippet-clipboard-copy-content="// Search and rank using BM25
results := idx.RankBM25(&#34;machine learning&#34;, 10)

for _, match := range results {
    fmt.Printf(&#34;Doc %d: Score %.2f\n&#34;,
        match.DocID,
        match.Score)
}"><pre><span>// Search and rank using BM25</span>
<span>results</span> <span>:=</span> <span>idx</span>.<span>RankBM25</span>(<span>&#34;machine learning&#34;</span>, <span>10</span>)

<span>for</span> <span>_</span>, <span>match</span> <span>:=</span> <span>range</span> <span>results</span> {
    <span>fmt</span>.<span>Printf</span>(<span>&#34;Doc %d: Score %.2f<span>\n</span>&#34;</span>,
        <span>match</span>.<span>DocID</span>,
        <span>match</span>.<span>Score</span>)
}</pre></div>
<p dir="auto"><strong>What BM25 Considers:</strong></p>
<div data-snippet-clipboard-copy-content="+------------------+-------------------------------------------------------+
| Factor           | Description                                           |
+------------------+-------------------------------------------------------+
| Term Frequency   | How often does the term appear?                       |
|                  | More occurrences = higher relevance                   |
+------------------+-------------------------------------------------------+
| TF Saturation    | Diminishing returns                                   |
|                  | 3-&gt;10 occurrences matters less than 0-&gt;3             |
+------------------+-------------------------------------------------------+
| Document Length  | Normalize by document size                            |
|                  | Prevents long docs from dominating results            |
+------------------+-------------------------------------------------------+
| Term Rarity      | Rare terms are more important than common ones        |
|                  | &#34;quantum&#34; &gt; &#34;the&#34; in importance                       |
+------------------+-------------------------------------------------------+"><pre><code>+------------------+-------------------------------------------------------+
| Factor           | Description                                           |
+------------------+-------------------------------------------------------+
| Term Frequency   | How often does the term appear?                       |
|                  | More occurrences = higher relevance                   |
+------------------+-------------------------------------------------------+
| TF Saturation    | Diminishing returns                                   |
|                  | 3-&gt;10 occurrences matters less than 0-&gt;3             |
+------------------+-------------------------------------------------------+
| Document Length  | Normalize by document size                            |
|                  | Prevents long docs from dominating results            |
+------------------+-------------------------------------------------------+
| Term Rarity      | Rare terms are more important than common ones        |
|                  | &#34;quantum&#34; &gt; &#34;the&#34; in importance                       |
+------------------+-------------------------------------------------------+
</code></pre></div>
<p dir="auto"><strong>Complete BM25 Formula:</strong></p>
<div data-snippet-clipboard-copy-content="                    IDF(q_i) × TF(q_i, D) × (k1 + 1)
BM25(D, Q) = SUM  ─────────────────────────────────────────
             q_i  TF(q_i, D) + k1 × (1 - b + b × |D|/avgdl)
            in Q

Where:
    D       = Document being scored
    Q       = Query (set of terms q_1, q_2, ..., q_n)
    q_i     = Individual query term"><pre><code>                    IDF(q_i) × TF(q_i, D) × (k1 + 1)
BM25(D, Q) = SUM  ─────────────────────────────────────────
             q_i  TF(q_i, D) + k1 × (1 - b + b × |D|/avgdl)
            in Q

Where:
    D       = Document being scored
    Q       = Query (set of terms q_1, q_2, ..., q_n)
    q_i     = Individual query term
</code></pre></div>
<p dir="auto"><strong>Component Breakdown:</strong></p>
<div data-snippet-clipboard-copy-content="+-------------------+-----------------------------------------------------+
|    Component      |                   Definition                        |
+-------------------+-----------------------------------------------------+
| IDF(q_i)          | Inverse Document Frequency                          |
|                   |                                                     |
|                   |          N - df(q_i) + 0.5                          |
|                   | log( ─────────────────────── + 1 )                  |
|                   |            df(q_i) + 0.5                            |
|                   |                                                     |
|                   | N  = Total documents in corpus                      |
|                   | df = Documents containing term q_i                  |
|                   |                                                     |
|                   | Effect: Rare terms get higher weights              |
+-------------------+-----------------------------------------------------+
| TF(q_i, D)        | Term Frequency                                      |
|                   | = Number of times q_i appears in document D         |
|                   |                                                     |
|                   | Effect: More occurrences = higher relevance         |
+-------------------+-----------------------------------------------------+
| k1                | Term Frequency Saturation Parameter                 |
|                   | = 1.5 (default)                                     |
|                   | Range: [1.2, 2.0]                                   |
|                   |                                                     |
|                   | Effect: Controls diminishing returns                |
|                   |         Higher k1 = less saturation                 |
+-------------------+-----------------------------------------------------+
| b                 | Length Normalization Parameter                      |
|                   | = 0.75 (default)                                    |
|                   | Range: [0, 1]                                       |
|                   |                                                     |
|                   | Effect: Controls length penalty                     |
|                   |         b=1  = full normalization                   |
|                   |         b=0  = no normalization                     |
+-------------------+-----------------------------------------------------+
| |D|               | Document Length                                     |
|                   | = Number of terms in document D                     |
+-------------------+-----------------------------------------------------+
| avgdl             | Average Document Length                             |
|                   | = Total terms / Total documents                     |
+-------------------+-----------------------------------------------------+"><pre><code>+-------------------+-----------------------------------------------------+
|    Component      |                   Definition                        |
+-------------------+-----------------------------------------------------+
| IDF(q_i)          | Inverse Document Frequency                          |
|                   |                                                     |
|                   |          N - df(q_i) + 0.5                          |
|                   | log( ─────────────────────── + 1 )                  |
|                   |            df(q_i) + 0.5                            |
|                   |                                                     |
|                   | N  = Total documents in corpus                      |
|                   | df = Documents containing term q_i                  |
|                   |                                                     |
|                   | Effect: Rare terms get higher weights              |
+-------------------+-----------------------------------------------------+
| TF(q_i, D)        | Term Frequency                                      |
|                   | = Number of times q_i appears in document D         |
|                   |                                                     |
|                   | Effect: More occurrences = higher relevance         |
+-------------------+-----------------------------------------------------+
| k1                | Term Frequency Saturation Parameter                 |
|                   | = 1.5 (default)                                     |
|                   | Range: [1.2, 2.0]                                   |
|                   |                                                     |
|                   | Effect: Controls diminishing returns                |
|                   |         Higher k1 = less saturation                 |
+-------------------+-----------------------------------------------------+
| b                 | Length Normalization Parameter                      |
|                   | = 0.75 (default)                                    |
|                   | Range: [0, 1]                                       |
|                   |                                                     |
|                   | Effect: Controls length penalty                     |
|                   |         b=1  = full normalization                   |
|                   |         b=0  = no normalization                     |
+-------------------+-----------------------------------------------------+
| |D|               | Document Length                                     |
|                   | = Number of terms in document D                     |
+-------------------+-----------------------------------------------------+
| avgdl             | Average Document Length                             |
|                   | = Total terms / Total documents                     |
+-------------------+-----------------------------------------------------+
</code></pre></div>
<p dir="auto"><strong>Visual Example - Term Frequency Saturation:</strong></p>
<div data-snippet-clipboard-copy-content="Score Contribution (with k1=1.5, b=0.75)
    ^
    |                            /---------------  (saturation)
    |                          /
 3  |                       /
    |                     /
 2  |                  /
    |               /
 1  |            /
    |         /
 0  |______/
    +---+---+---+---+---+---+---+---+---+---+---&gt; Term Frequency
    0   1   2   3   4   5   6   7   8   9   10

Key Insight: Going from 0-&gt;3 occurrences adds more to the score
             than going from 7-&gt;10 occurrences (diminishing returns)"><pre><code>Score Contribution (with k1=1.5, b=0.75)
    ^
    |                            /---------------  (saturation)
    |                          /
 3  |                       /
    |                     /
 2  |                  /
    |               /
 1  |            /
    |         /
 0  |______/
    +---+---+---+---+---+---+---+---+---+---+---&gt; Term Frequency
    0   1   2   3   4   5   6   7   8   9   10

Key Insight: Going from 0-&gt;3 occurrences adds more to the score
             than going from 7-&gt;10 occurrences (diminishing returns)
</code></pre></div>
<p dir="auto"><strong>Visual Example - Document Length Normalization:</strong></p>
<div data-snippet-clipboard-copy-content="Scenario: Same term frequency, different document lengths

Document A: 100 words, &#34;learning&#34; appears 3 times
Document B: 1000 words, &#34;learning&#34; appears 3 times

Raw TF:  Both have TF = 3
Density: Doc A = 3/100  = 3.0%    &lt;- Higher density
         Doc B = 3/1000 = 0.3%    &lt;- Lower density

BM25 adjusts: Doc A gets HIGHER score (term is more prominent)
              Doc B gets LOWER score (term is less prominent)

Length Penalty Formula:

    Penalty = k1 × (1 - b + b × docLen/avgDocLen)

    If docLen &gt; avgDocLen: Penalty increases (score decreases)
    If docLen &lt; avgDocLen: Penalty decreases (score increases)"><pre><code>Scenario: Same term frequency, different document lengths

Document A: 100 words, &#34;learning&#34; appears 3 times
Document B: 1000 words, &#34;learning&#34; appears 3 times

Raw TF:  Both have TF = 3
Density: Doc A = 3/100  = 3.0%    &lt;- Higher density
         Doc B = 3/1000 = 0.3%    &lt;- Lower density

BM25 adjusts: Doc A gets HIGHER score (term is more prominent)
              Doc B gets LOWER score (term is less prominent)

Length Penalty Formula:

    Penalty = k1 × (1 - b + b × docLen/avgDocLen)

    If docLen &gt; avgDocLen: Penalty increases (score decreases)
    If docLen &lt; avgDocLen: Penalty decreases (score increases)
</code></pre></div>
<p dir="auto"><strong>Step-by-Step Scoring Example:</strong></p>
<div data-snippet-clipboard-copy-content="SETUP:
------
Query:  &#34;machine learning&#34;
Corpus: 1000 documents, average length 150 words
Target: Document 1 (200 words)
        - &#34;machine&#34; appears 3 times (df=100 docs have &#34;machine&#34;)
        - &#34;learning&#34; appears 2 times (df=50 docs have &#34;learning&#34;)

Parameters: k1=1.5, b=0.75


STEP 1: Calculate IDF for each term
----------------------------------------

IDF(machine):
    N = 1000, df = 100

    IDF = log((1000 - 100 + 0.5) / (100 + 0.5) + 1)
        = log(900.5 / 100.5 + 1)
        = log(8.96 + 1)
        = log(9.96)
        ≈ 2.30

IDF(learning):
    N = 1000, df = 50

    IDF = log((1000 - 50 + 0.5) / (50 + 0.5) + 1)
        = log(950.5 / 50.5 + 1)
        = log(18.82 + 1)
        = log(19.82)
        ≈ 2.99

    Note: &#34;learning&#34; is rarer (df=50) than &#34;machine&#34; (df=100)
          so it gets a higher IDF weight


STEP 2: Calculate normalized TF for &#34;machine&#34;
----------------------------------------------

TF = 3 (appears 3 times)
docLen = 200
avgdl = 150

Numerator   = TF × (k1 + 1)
            = 3 × (1.5 + 1)
            = 3 × 2.5
            = 7.5

Denominator = TF + k1 × (1 - b + b × (docLen / avgdl))
            = 3 + 1.5 × (1 - 0.75 + 0.75 × (200/150))
            = 3 + 1.5 × (0.25 + 0.75 × 1.333)
            = 3 + 1.5 × (0.25 + 1.0)
            = 3 + 1.5 × 1.25
            = 3 + 1.875
            = 4.875

Normalized TF = 7.5 / 4.875 ≈ 1.54

Contribution = IDF × Normalized TF
             = 2.30 × 1.54
             ≈ 3.54


STEP 3: Calculate normalized TF for &#34;learning&#34;
-----------------------------------------------

TF = 2 (appears 2 times)
docLen = 200
avgdl = 150

Numerator   = 2 × 2.5 = 5.0

Denominator = 2 + 1.5 × (1 - 0.75 + 0.75 × (200/150))
            = 2 + 1.875
            = 3.875

Normalized TF = 5.0 / 3.875 ≈ 1.29

Contribution = IDF × Normalized TF
             = 2.99 × 1.29
             ≈ 3.86


STEP 4: Calculate final BM25 score
-----------------------------------

BM25(Document 1, &#34;machine learning&#34;) = 3.54 + 3.86 = 7.40

                    +----------+----------+
                    | Term     | Score    |
                    +----------+----------+
                    | machine  | 3.54     |
                    | learning | 3.86     |
                    +----------+----------+
                    | TOTAL    | 7.40     |
                    +----------+----------+"><pre><code>SETUP:
------
Query:  &#34;machine learning&#34;
Corpus: 1000 documents, average length 150 words
Target: Document 1 (200 words)
        - &#34;machine&#34; appears 3 times (df=100 docs have &#34;machine&#34;)
        - &#34;learning&#34; appears 2 times (df=50 docs have &#34;learning&#34;)

Parameters: k1=1.5, b=0.75


STEP 1: Calculate IDF for each term
----------------------------------------

IDF(machine):
    N = 1000, df = 100

    IDF = log((1000 - 100 + 0.5) / (100 + 0.5) + 1)
        = log(900.5 / 100.5 + 1)
        = log(8.96 + 1)
        = log(9.96)
        ≈ 2.30

IDF(learning):
    N = 1000, df = 50

    IDF = log((1000 - 50 + 0.5) / (50 + 0.5) + 1)
        = log(950.5 / 50.5 + 1)
        = log(18.82 + 1)
        = log(19.82)
        ≈ 2.99

    Note: &#34;learning&#34; is rarer (df=50) than &#34;machine&#34; (df=100)
          so it gets a higher IDF weight


STEP 2: Calculate normalized TF for &#34;machine&#34;
----------------------------------------------

TF = 3 (appears 3 times)
docLen = 200
avgdl = 150

Numerator   = TF × (k1 + 1)
            = 3 × (1.5 + 1)
            = 3 × 2.5
            = 7.5

Denominator = TF + k1 × (1 - b + b × (docLen / avgdl))
            = 3 + 1.5 × (1 - 0.75 + 0.75 × (200/150))
            = 3 + 1.5 × (0.25 + 0.75 × 1.333)
            = 3 + 1.5 × (0.25 + 1.0)
            = 3 + 1.5 × 1.25
            = 3 + 1.875
            = 4.875

Normalized TF = 7.5 / 4.875 ≈ 1.54

Contribution = IDF × Normalized TF
             = 2.30 × 1.54
             ≈ 3.54


STEP 3: Calculate normalized TF for &#34;learning&#34;
-----------------------------------------------

TF = 2 (appears 2 times)
docLen = 200
avgdl = 150

Numerator   = 2 × 2.5 = 5.0

Denominator = 2 + 1.5 × (1 - 0.75 + 0.75 × (200/150))
            = 2 + 1.875
            = 3.875

Normalized TF = 5.0 / 3.875 ≈ 1.29

Contribution = IDF × Normalized TF
             = 2.99 × 1.29
             ≈ 3.86


STEP 4: Calculate final BM25 score
-----------------------------------

BM25(Document 1, &#34;machine learning&#34;) = 3.54 + 3.86 = 7.40

                    +----------+----------+
                    | Term     | Score    |
                    +----------+----------+
                    | machine  | 3.54     |
                    | learning | 3.86     |
                    +----------+----------+
                    | TOTAL    | 7.40     |
                    +----------+----------+
</code></pre></div>
<p dir="auto"><strong>Why BM25 Works:</strong></p>
<div data-snippet-clipboard-copy-content="+------------------------+------------------------------------------------+
| Advantage              | Explanation                                    |
+------------------------+------------------------------------------------+
| Industry Standard      | Used by Elasticsearch, Solr, Lucene           |
|                        | Battle-tested in production systems            |
+------------------------+------------------------------------------------+
| Probabilistic          | Based on probability ranking principle         |
|                        | Solid theoretical foundation                   |
+------------------------+------------------------------------------------+
| Term Rarity (IDF)      | Rare terms contribute more to score            |
|                        | &#34;quantum&#34; &gt; &#34;the&#34; in importance                |
+------------------------+------------------------------------------------+
| Saturation             | Diminishing returns for repeated terms         |
|                        | 0-&gt;3 occurrences: HIGH impact                  |
|                        | 7-&gt;10 occurrences: LOW impact                  |
+------------------------+------------------------------------------------+
| Length Normalization   | Prevents long documents from dominating        |
|                        | Adjusts for document size bias                 |
+------------------------+------------------------------------------------+
| Tunable                | Adjust k1 and b for domain-specific needs     |
|                        | Customize behavior without changing algorithm  |
+------------------------+------------------------------------------------+"><pre><code>+------------------------+------------------------------------------------+
| Advantage              | Explanation                                    |
+------------------------+------------------------------------------------+
| Industry Standard      | Used by Elasticsearch, Solr, Lucene           |
|                        | Battle-tested in production systems            |
+------------------------+------------------------------------------------+
| Probabilistic          | Based on probability ranking principle         |
|                        | Solid theoretical foundation                   |
+------------------------+------------------------------------------------+
| Term Rarity (IDF)      | Rare terms contribute more to score            |
|                        | &#34;quantum&#34; &gt; &#34;the&#34; in importance                |
+------------------------+------------------------------------------------+
| Saturation             | Diminishing returns for repeated terms         |
|                        | 0-&gt;3 occurrences: HIGH impact                  |
|                        | 7-&gt;10 occurrences: LOW impact                  |
+------------------------+------------------------------------------------+
| Length Normalization   | Prevents long documents from dominating        |
|                        | Adjusts for document size bias                 |
+------------------------+------------------------------------------------+
| Tunable                | Adjust k1 and b for domain-specific needs     |
|                        | Customize behavior without changing algorithm  |
+------------------------+------------------------------------------------+
</code></pre></div>
<p dir="auto"><strong>Comparison with Simple TF-IDF:</strong></p>
<div data-snippet-clipboard-copy-content="Simple TF-IDF:
    Score = TF × IDF
    Problem: Linear relationship with TF
             10 occurrences = 10x score of 1 occurrence

    TF-IDF Score
        ^
        |                                        /
     10 |                                      /
        |                                    /
      5 |                                  /
        |                                /
      0 |______________________________/
        +---+---+---+---+---+---+---+---+---&gt; Term Frequency
        0   2   4   6   8   10  12  14  16

BM25:
    Score = IDF × (TF × (k1 + 1)) / (TF + k1 × length_norm)
    Benefit: Sublinear relationship with TF
             Saturation prevents spam

    BM25 Score
        ^
        |                    /----------------  (plateau)
      4 |                  /
        |                /
      2 |             /
        |          /
      0 |________/
        +---+---+---+---+---+---+---+---+---&gt; Term Frequency
        0   2   4   6   8   10  12  14  16

    Key: BM25 saturates, preventing keyword stuffing exploits"><pre><code>Simple TF-IDF:
    Score = TF × IDF
    Problem: Linear relationship with TF
             10 occurrences = 10x score of 1 occurrence

    TF-IDF Score
        ^
        |                                        /
     10 |                                      /
        |                                    /
      5 |                                  /
        |                                /
      0 |______________________________/
        +---+---+---+---+---+---+---+---+---&gt; Term Frequency
        0   2   4   6   8   10  12  14  16

BM25:
    Score = IDF × (TF × (k1 + 1)) / (TF + k1 × length_norm)
    Benefit: Sublinear relationship with TF
             Saturation prevents spam

    BM25 Score
        ^
        |                    /----------------  (plateau)
      4 |                  /
        |                /
      2 |             /
        |          /
      0 |________/
        +---+---+---+---+---+---+---+---+---&gt; Term Frequency
        0   2   4   6   8   10  12  14  16

    Key: BM25 saturates, preventing keyword stuffing exploits
</code></pre></div>

<p dir="auto">Score and rank documents by term proximity:</p>
<div dir="auto" data-snippet-clipboard-copy-content="// Search and rank results
matches := idx.RankProximity(&#34;machine learning&#34;, 10)

for _, match := range matches {
    fmt.Printf(&#34;Doc %d: Score %.2f\n&#34;,
        int(match.Offsets[0].DocumentID),
        match.Score)
}"><pre><span>// Search and rank results</span>
<span>matches</span> <span>:=</span> <span>idx</span>.<span>RankProximity</span>(<span>&#34;machine learning&#34;</span>, <span>10</span>)

<span>for</span> <span>_</span>, <span>match</span> <span>:=</span> <span>range</span> <span>matches</span> {
    <span>fmt</span>.<span>Printf</span>(<span>&#34;Doc %d: Score %.2f<span>\n</span>&#34;</span>,
        <span>int</span>(<span>match</span>.<span>Offsets</span>[<span>0</span>].<span>DocumentID</span>),
        <span>match</span>.<span>Score</span>)
}</pre></div>
<p dir="auto"><strong>Scoring Formula:</strong></p>
<div data-snippet-clipboard-copy-content="For each cover in a document:
    score += 1 / (coverEnd - coverStart + 1)

┌────────────────────────────────────────────────────────────────┐
│ Proximity Scoring Examples                                     │
├────────────────────────────────────────────────────────────────┤
│                                                                 │
│ Doc 1: &#34;machine learning is machine learning&#34;                  │
│         Pos:0      1      2  3       4                          │
│                                                                 │
│   Cover 1: [Pos 0-1]  → score += 1/(1-0+1) = 1/2 = 0.500      │
│   Cover 2: [Pos 3-4]  → score += 1/(4-3+1) = 1/2 = 0.500      │
│                         ─────────────────────────────           │
│   Total Score: 1.000                                            │
│                                                                 │
├────────────────────────────────────────────────────────────────┤
│                                                                 │
│ Doc 2: &#34;learning about machine and learning&#34;                   │
│         Pos:0       1     2       3   4                         │
│                                                                 │
│   Cover 1: [Pos 0-2]  → score += 1/(2-0+1) = 1/3 = 0.333      │
│   Cover 2: [Pos 2-4]  → score += 1/(4-2+1) = 1/3 = 0.333      │
│                         ─────────────────────────────           │
│   Total Score: 0.666                                            │
│                                                                 │
├────────────────────────────────────────────────────────────────┤
│                                                                 │
│ Doc 3: &#34;machine ... ... ... ... learning&#34;                      │
│         Pos:0    1   2   3   4   5                              │
│                                                                 │
│   Cover 1: [Pos 0-5]  → score += 1/(5-0+1) = 1/6 = 0.167      │
│                         ─────────────────────────────           │
│   Total Score: 0.167                                            │
│                                                                 │
└────────────────────────────────────────────────────────────────┘

Ranking: Doc 1 (1.000) &gt; Doc 2 (0.666) &gt; Doc 3 (0.167)
          ▲               ▲               ▲
      Terms closest   Terms medium   Terms far apart"><pre><code>For each cover in a document:
    score += 1 / (coverEnd - coverStart + 1)

┌────────────────────────────────────────────────────────────────┐
│ Proximity Scoring Examples                                     │
├────────────────────────────────────────────────────────────────┤
│                                                                 │
│ Doc 1: &#34;machine learning is machine learning&#34;                  │
│         Pos:0      1      2  3       4                          │
│                                                                 │
│   Cover 1: [Pos 0-1]  → score += 1/(1-0+1) = 1/2 = 0.500      │
│   Cover 2: [Pos 3-4]  → score += 1/(4-3+1) = 1/2 = 0.500      │
│                         ─────────────────────────────           │
│   Total Score: 1.000                                            │
│                                                                 │
├────────────────────────────────────────────────────────────────┤
│                                                                 │
│ Doc 2: &#34;learning about machine and learning&#34;                   │
│         Pos:0       1     2       3   4                         │
│                                                                 │
│   Cover 1: [Pos 0-2]  → score += 1/(2-0+1) = 1/3 = 0.333      │
│   Cover 2: [Pos 2-4]  → score += 1/(4-2+1) = 1/3 = 0.333      │
│                         ─────────────────────────────           │
│   Total Score: 0.666                                            │
│                                                                 │
├────────────────────────────────────────────────────────────────┤
│                                                                 │
│ Doc 3: &#34;machine ... ... ... ... learning&#34;                      │
│         Pos:0    1   2   3   4   5                              │
│                                                                 │
│   Cover 1: [Pos 0-5]  → score += 1/(5-0+1) = 1/6 = 0.167      │
│                         ─────────────────────────────           │
│   Total Score: 0.167                                            │
│                                                                 │
└────────────────────────────────────────────────────────────────┘

Ranking: Doc 1 (1.000) &gt; Doc 2 (0.666) &gt; Doc 3 (0.167)
          ▲               ▲               ▲
      Terms closest   Terms medium   Terms far apart
</code></pre></div>
<p dir="auto"><strong>Why This Works:</strong></p>
<ul dir="auto">
<li>Smaller distances → larger scores (inverse relationship)</li>
<li>Multiple occurrences → higher scores (additive)</li>
<li>Documents with terms close together rank higher</li>
</ul>

<p dir="auto">The Query Builder provides a <strong>type-safe, fluent API</strong> for constructing complex boolean queries with roaring bitmaps. No string parsing, no syntax errors - just clean, composable code.</p>

<p dir="auto"><strong>String Parsing Approach:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="// Error-prone, runtime failures
results, err := index.ExecuteQuery(&#34;(machine AND learning) OR python&#34;)
if err != nil {
    // Handle parsing errors
}"><pre><span>// Error-prone, runtime failures</span>
<span>results</span>, <span>err</span> <span>:=</span> <span>index</span>.<span>ExecuteQuery</span>(<span>&#34;(machine AND learning) OR python&#34;</span>)
<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
    <span>// Handle parsing errors</span>
}</pre></div>
<p dir="auto"><strong>Builder Pattern Approach:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="// Type-safe, compile-time checks, IDE autocomplete!
results := blaze.NewQueryBuilder(index).
    Group(func(q *blaze.QueryBuilder) {
        q.Term(&#34;machine&#34;).And().Term(&#34;learning&#34;)
    }).
    Or().
    Term(&#34;python&#34;).
    Execute()"><pre><span>// Type-safe, compile-time checks, IDE autocomplete!</span>
<span>results</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>index</span>).
    <span>Group</span>(<span>func</span>(<span>q</span> <span>*</span>blaze.<span>QueryBuilder</span>) {
        <span>q</span>.<span>Term</span>(<span>&#34;machine&#34;</span>).<span>And</span>().<span>Term</span>(<span>&#34;learning&#34;</span>)
    }).
    <span>Or</span>().
    <span>Term</span>(<span>&#34;python&#34;</span>).
    <span>Execute</span>()</pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">Query Builder Quick Start</h3><a id="user-content-query-builder-quick-start" aria-label="Permalink: Query Builder Quick Start" href="#query-builder-quick-start"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>

<div dir="auto" data-snippet-clipboard-copy-content="// Find all documents containing &#34;machine&#34;
results := blaze.NewQueryBuilder(idx).
    Term(&#34;machine&#34;).
    Execute()

fmt.Printf(&#34;Found %d documents\n&#34;, results.GetCardinality())"><pre><span>// Find all documents containing &#34;machine&#34;</span>
<span>results</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>).
    <span>Term</span>(<span>&#34;machine&#34;</span>).
    <span>Execute</span>()

<span>fmt</span>.<span>Printf</span>(<span>&#34;Found %d documents<span>\n</span>&#34;</span>, <span>results</span>.<span>GetCardinality</span>())</pre></div>

<div dir="auto" data-snippet-clipboard-copy-content="// Find documents with BOTH &#34;machine&#34; AND &#34;learning&#34;
results := blaze.NewQueryBuilder(idx).
    Term(&#34;machine&#34;).
    And().
    Term(&#34;learning&#34;).
    Execute()"><pre><span>// Find documents with BOTH &#34;machine&#34; AND &#34;learning&#34;</span>
<span>results</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>).
    <span>Term</span>(<span>&#34;machine&#34;</span>).
    <span>And</span>().
    <span>Term</span>(<span>&#34;learning&#34;</span>).
    <span>Execute</span>()</pre></div>

<div dir="auto" data-snippet-clipboard-copy-content="// Find documents with &#34;python&#34; OR &#34;javascript&#34;
results := blaze.NewQueryBuilder(idx).
    Term(&#34;python&#34;).
    Or().
    Term(&#34;javascript&#34;).
    Execute()"><pre><span>// Find documents with &#34;python&#34; OR &#34;javascript&#34;</span>
<span>results</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>).
    <span>Term</span>(<span>&#34;python&#34;</span>).
    <span>Or</span>().
    <span>Term</span>(<span>&#34;javascript&#34;</span>).
    <span>Execute</span>()</pre></div>

<div dir="auto" data-snippet-clipboard-copy-content="// Find documents with &#34;python&#34; but NOT &#34;snake&#34;
results := blaze.NewQueryBuilder(idx).
    Term(&#34;python&#34;).
    And().Not().
    Term(&#34;snake&#34;).
    Execute()"><pre><span>// Find documents with &#34;python&#34; but NOT &#34;snake&#34;</span>
<span>results</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>).
    <span>Term</span>(<span>&#34;python&#34;</span>).
    <span>And</span>().<span>Not</span>().
    <span>Term</span>(<span>&#34;snake&#34;</span>).
    <span>Execute</span>()</pre></div>

<div dir="auto" data-snippet-clipboard-copy-content="// (machine OR deep) AND learning
results := blaze.NewQueryBuilder(idx).
    Group(func(q *blaze.QueryBuilder) {
        q.Term(&#34;machine&#34;).Or().Term(&#34;deep&#34;)
    }).
    And().
    Term(&#34;learning&#34;).
    Execute()"><pre><span>// (machine OR deep) AND learning</span>
<span>results</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>).
    <span>Group</span>(<span>func</span>(<span>q</span> <span>*</span>blaze.<span>QueryBuilder</span>) {
        <span>q</span>.<span>Term</span>(<span>&#34;machine&#34;</span>).<span>Or</span>().<span>Term</span>(<span>&#34;deep&#34;</span>)
    }).
    <span>And</span>().
    <span>Term</span>(<span>&#34;learning&#34;</span>).
    <span>Execute</span>()</pre></div>

<div dir="auto" data-snippet-clipboard-copy-content="// Find exact phrase &#34;machine learning&#34;
results := blaze.NewQueryBuilder(idx).
    Phrase(&#34;machine learning&#34;).
    Execute()"><pre><span>// Find exact phrase &#34;machine learning&#34;</span>
<span>results</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>).
    <span>Phrase</span>(<span>&#34;machine learning&#34;</span>).
    <span>Execute</span>()</pre></div>

<div dir="auto" data-snippet-clipboard-copy-content="// Get top 10 results ranked by relevance
matches := blaze.NewQueryBuilder(idx).
    Term(&#34;machine&#34;).
    And().
    Term(&#34;learning&#34;).
    ExecuteWithBM25(10)

for _, match := range matches {
    fmt.Printf(&#34;Doc %d: score=%.2f\n&#34;, match.DocID, match.Score)
}"><pre><span>// Get top 10 results ranked by relevance</span>
<span>matches</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>).
    <span>Term</span>(<span>&#34;machine&#34;</span>).
    <span>And</span>().
    <span>Term</span>(<span>&#34;learning&#34;</span>).
    <span>ExecuteWithBM25</span>(<span>10</span>)

<span>for</span> <span>_</span>, <span>match</span> <span>:=</span> <span>range</span> <span>matches</span> {
    <span>fmt</span>.<span>Printf</span>(<span>&#34;Doc %d: score=%.2f<span>\n</span>&#34;</span>, <span>match</span>.<span>DocID</span>, <span>match</span>.<span>Score</span>)
}</pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">Query Builder Core Methods</h3><a id="user-content-query-builder-core-methods" aria-label="Permalink: Query Builder Core Methods" href="#query-builder-core-methods"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto"><h4 tabindex="-1" dir="auto"><code>NewQueryBuilder(index *InvertedIndex) *QueryBuilder</code></h4><a id="user-content-newquerybuilderindex-invertedindex-querybuilder" aria-label="Permalink: NewQueryBuilder(index *InvertedIndex) *QueryBuilder" href="#newquerybuilderindex-invertedindex-querybuilder"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Creates a new query builder instance.</p>
<div dir="auto" data-snippet-clipboard-copy-content="qb := blaze.NewQueryBuilder(idx)"><pre><span>qb</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>)</pre></div>
<div dir="auto"><h4 tabindex="-1" dir="auto"><code>Term(term string) *QueryBuilder</code></h4><a id="user-content-termterm-string-querybuilder" aria-label="Permalink: Term(term string) *QueryBuilder" href="#termterm-string-querybuilder"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Adds a single term to the query. Uses roaring bitmaps for O(1) document lookup.</p>

<div dir="auto"><h4 tabindex="-1" dir="auto"><code>Phrase(phrase string) *QueryBuilder</code></h4><a id="user-content-phrasephrase-string-querybuilder" aria-label="Permalink: Phrase(phrase string) *QueryBuilder" href="#phrasephrase-string-querybuilder"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Adds an exact phrase match. Combines bitmap efficiency with skip list position checking.</p>
<div dir="auto" data-snippet-clipboard-copy-content="qb.Phrase(&#34;machine learning&#34;)"><pre><span>qb</span>.<span>Phrase</span>(<span>&#34;machine learning&#34;</span>)</pre></div>

<p dir="auto">Combines results with intersection (both must match). Uses bitmap AND operation.</p>
<div dir="auto" data-snippet-clipboard-copy-content="qb.Term(&#34;machine&#34;).And().Term(&#34;learning&#34;)"><pre><span>qb</span>.<span>Term</span>(<span>&#34;machine&#34;</span>).<span>And</span>().<span>Term</span>(<span>&#34;learning&#34;</span>)</pre></div>

<p dir="auto">Combines results with union (either can match). Uses bitmap OR operation.</p>
<div dir="auto" data-snippet-clipboard-copy-content="qb.Term(&#34;cat&#34;).Or().Term(&#34;dog&#34;)"><pre><span>qb</span>.<span>Term</span>(<span>&#34;cat&#34;</span>).<span>Or</span>().<span>Term</span>(<span>&#34;dog&#34;</span>)</pre></div>

<p dir="auto">Negates the next term (exclude from results). Uses bitmap difference operation.</p>
<div dir="auto" data-snippet-clipboard-copy-content="qb.Term(&#34;python&#34;).And().Not().Term(&#34;snake&#34;)"><pre><span>qb</span>.<span>Term</span>(<span>&#34;python&#34;</span>).<span>And</span>().<span>Not</span>().<span>Term</span>(<span>&#34;snake&#34;</span>)</pre></div>
<div dir="auto"><h4 tabindex="-1" dir="auto"><code>Group(fn func(*QueryBuilder)) *QueryBuilder</code></h4><a id="user-content-groupfn-funcquerybuilder-querybuilder" aria-label="Permalink: Group(fn func(*QueryBuilder)) *QueryBuilder" href="#groupfn-funcquerybuilder-querybuilder"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Creates a sub-query with its own scope for precedence control.</p>
<div dir="auto" data-snippet-clipboard-copy-content="qb.Group(func(q *blaze.QueryBuilder) {
    q.Term(&#34;machine&#34;).Or().Term(&#34;deep&#34;)
}).And().Term(&#34;learning&#34;)"><pre><span>qb</span>.<span>Group</span>(<span>func</span>(<span>q</span> <span>*</span>blaze.<span>QueryBuilder</span>) {
    <span>q</span>.<span>Term</span>(<span>&#34;machine&#34;</span>).<span>Or</span>().<span>Term</span>(<span>&#34;deep&#34;</span>)
}).<span>And</span>().<span>Term</span>(<span>&#34;learning&#34;</span>)</pre></div>
<div dir="auto"><h4 tabindex="-1" dir="auto"><code>Execute() *roaring.Bitmap</code></h4><a id="user-content-execute-roaringbitmap" aria-label="Permalink: Execute() *roaring.Bitmap" href="#execute-roaringbitmap"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Executes the query and returns a bitmap of matching document IDs.</p>
<div dir="auto" data-snippet-clipboard-copy-content="results := qb.Execute()
docCount := results.GetCardinality()"><pre><span>results</span> <span>:=</span> <span>qb</span>.<span>Execute</span>()
<span>docCount</span> <span>:=</span> <span>results</span>.<span>GetCardinality</span>()</pre></div>
<div dir="auto"><h4 tabindex="-1" dir="auto"><code>ExecuteWithBM25(maxResults int) []Match</code></h4><a id="user-content-executewithbm25maxresults-int-match" aria-label="Permalink: ExecuteWithBM25(maxResults int) []Match" href="#executewithbm25maxresults-int-match"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Executes the query with BM25 ranking and returns top results.</p>
<div dir="auto" data-snippet-clipboard-copy-content="matches := qb.ExecuteWithBM25(10)  // Top 10 results"><pre><span>matches</span> <span>:=</span> <span>qb</span>.<span>ExecuteWithBM25</span>(<span>10</span>)  <span>// Top 10 results</span></pre></div>

<p dir="auto">The Query Builder provides convenient shorthand functions for common boolean operations:</p>
<div dir="auto"><h4 tabindex="-1" dir="auto"><code>AllOf(index *InvertedIndex, terms ...string) *roaring.Bitmap</code></h4><a id="user-content-allofindex-invertedindex-terms-string-roaringbitmap" aria-label="Permalink: AllOf(index *InvertedIndex, terms ...string) *roaring.Bitmap" href="#allofindex-invertedindex-terms-string-roaringbitmap"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Shorthand for documents containing ALL terms (AND operation).</p>
<div dir="auto" data-snippet-clipboard-copy-content="// Find documents with &#34;machine&#34; AND &#34;learning&#34; AND &#34;python&#34;
results := blaze.AllOf(idx, &#34;machine&#34;, &#34;learning&#34;, &#34;python&#34;)

// Equivalent to:
results := blaze.NewQueryBuilder(idx).
    Term(&#34;machine&#34;).And().Term(&#34;learning&#34;).And().Term(&#34;python&#34;).
    Execute()"><pre><span>// Find documents with &#34;machine&#34; AND &#34;learning&#34; AND &#34;python&#34;</span>
<span>results</span> <span>:=</span> <span>blaze</span>.<span>AllOf</span>(<span>idx</span>, <span>&#34;machine&#34;</span>, <span>&#34;learning&#34;</span>, <span>&#34;python&#34;</span>)

<span>// Equivalent to:</span>
<span>results</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>).
    <span>Term</span>(<span>&#34;machine&#34;</span>).<span>And</span>().<span>Term</span>(<span>&#34;learning&#34;</span>).<span>And</span>().<span>Term</span>(<span>&#34;python&#34;</span>).
    <span>Execute</span>()</pre></div>
<div dir="auto"><h4 tabindex="-1" dir="auto"><code>AnyOf(index *InvertedIndex, terms ...string) *roaring.Bitmap</code></h4><a id="user-content-anyofindex-invertedindex-terms-string-roaringbitmap" aria-label="Permalink: AnyOf(index *InvertedIndex, terms ...string) *roaring.Bitmap" href="#anyofindex-invertedindex-terms-string-roaringbitmap"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Shorthand for documents containing ANY term (OR operation).</p>
<div dir="auto" data-snippet-clipboard-copy-content="// Find documents with &#34;cat&#34; OR &#34;dog&#34; OR &#34;bird&#34;
results := blaze.AnyOf(idx, &#34;cat&#34;, &#34;dog&#34;, &#34;bird&#34;)

// Equivalent to:
results := blaze.NewQueryBuilder(idx).
    Term(&#34;cat&#34;).Or().Term(&#34;dog&#34;).Or().Term(&#34;bird&#34;).
    Execute()"><pre><span>// Find documents with &#34;cat&#34; OR &#34;dog&#34; OR &#34;bird&#34;</span>
<span>results</span> <span>:=</span> <span>blaze</span>.<span>AnyOf</span>(<span>idx</span>, <span>&#34;cat&#34;</span>, <span>&#34;dog&#34;</span>, <span>&#34;bird&#34;</span>)

<span>// Equivalent to:</span>
<span>results</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>).
    <span>Term</span>(<span>&#34;cat&#34;</span>).<span>Or</span>().<span>Term</span>(<span>&#34;dog&#34;</span>).<span>Or</span>().<span>Term</span>(<span>&#34;bird&#34;</span>).
    <span>Execute</span>()</pre></div>
<div dir="auto"><h4 tabindex="-1" dir="auto"><code>TermExcluding(index *InvertedIndex, include string, exclude string) *roaring.Bitmap</code></h4><a id="user-content-termexcludingindex-invertedindex-include-string-exclude-string-roaringbitmap" aria-label="Permalink: TermExcluding(index *InvertedIndex, include string, exclude string) *roaring.Bitmap" href="#termexcludingindex-invertedindex-include-string-exclude-string-roaringbitmap"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Shorthand for term with exclusion (AND NOT operation).</p>
<div dir="auto" data-snippet-clipboard-copy-content="// Find documents with &#34;python&#34; but NOT &#34;snake&#34;
results := blaze.TermExcluding(idx, &#34;python&#34;, &#34;snake&#34;)

// Equivalent to:
results := blaze.NewQueryBuilder(idx).
    Term(&#34;python&#34;).And().Not().Term(&#34;snake&#34;).
    Execute()"><pre><span>// Find documents with &#34;python&#34; but NOT &#34;snake&#34;</span>
<span>results</span> <span>:=</span> <span>blaze</span>.<span>TermExcluding</span>(<span>idx</span>, <span>&#34;python&#34;</span>, <span>&#34;snake&#34;</span>)

<span>// Equivalent to:</span>
<span>results</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>).
    <span>Term</span>(<span>&#34;python&#34;</span>).<span>And</span>().<span>Not</span>().<span>Term</span>(<span>&#34;snake&#34;</span>).
    <span>Execute</span>()</pre></div>

<div dir="auto"><h4 tabindex="-1" dir="auto">Pattern 1: Broad to Narrow</h4><a id="user-content-pattern-1-broad-to-narrow" aria-label="Permalink: Pattern 1: Broad to Narrow" href="#pattern-1-broad-to-narrow"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Start with a broad category, then filter down with specific criteria.</p>
<div dir="auto" data-snippet-clipboard-copy-content="// Find programming content about Python or JavaScript, excluding beginner material
results := blaze.NewQueryBuilder(idx).
    Term(&#34;programming&#34;).
    And().
    Group(func(q *blaze.QueryBuilder) {
        q.Term(&#34;python&#34;).Or().Term(&#34;javascript&#34;)
    }).
    And().Not().
    Term(&#34;beginner&#34;).
    ExecuteWithBM25(10)"><pre><span>// Find programming content about Python or JavaScript, excluding beginner material</span>
<span>results</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>).
    <span>Term</span>(<span>&#34;programming&#34;</span>).
    <span>And</span>().
    <span>Group</span>(<span>func</span>(<span>q</span> <span>*</span>blaze.<span>QueryBuilder</span>) {
        <span>q</span>.<span>Term</span>(<span>&#34;python&#34;</span>).<span>Or</span>().<span>Term</span>(<span>&#34;javascript&#34;</span>)
    }).
    <span>And</span>().<span>Not</span>().
    <span>Term</span>(<span>&#34;beginner&#34;</span>).
    <span>ExecuteWithBM25</span>(<span>10</span>)</pre></div>
<div dir="auto"><h4 tabindex="-1" dir="auto">Pattern 2: Multi-Criteria Matching</h4><a id="user-content-pattern-2-multi-criteria-matching" aria-label="Permalink: Pattern 2: Multi-Criteria Matching" href="#pattern-2-multi-criteria-matching"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Match documents that satisfy multiple independent criteria.</p>
<div dir="auto" data-snippet-clipboard-copy-content="// Find documents about (machine learning OR deep learning) AND (python OR tensorflow)
results := blaze.NewQueryBuilder(idx).
    Group(func(q *blaze.QueryBuilder) {
        q.Phrase(&#34;machine learning&#34;).Or().Phrase(&#34;deep learning&#34;)
    }).
    And().
    Group(func(q *blaze.QueryBuilder) {
        q.Term(&#34;python&#34;).Or().Term(&#34;tensorflow&#34;)
    }).
    ExecuteWithBM25(20)"><pre><span>// Find documents about (machine learning OR deep learning) AND (python OR tensorflow)</span>
<span>results</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>).
    <span>Group</span>(<span>func</span>(<span>q</span> <span>*</span>blaze.<span>QueryBuilder</span>) {
        <span>q</span>.<span>Phrase</span>(<span>&#34;machine learning&#34;</span>).<span>Or</span>().<span>Phrase</span>(<span>&#34;deep learning&#34;</span>)
    }).
    <span>And</span>().
    <span>Group</span>(<span>func</span>(<span>q</span> <span>*</span>blaze.<span>QueryBuilder</span>) {
        <span>q</span>.<span>Term</span>(<span>&#34;python&#34;</span>).<span>Or</span>().<span>Term</span>(<span>&#34;tensorflow&#34;</span>)
    }).
    <span>ExecuteWithBM25</span>(<span>20</span>)</pre></div>
<div dir="auto"><h4 tabindex="-1" dir="auto">Pattern 3: Exclusion Filtering</h4><a id="user-content-pattern-3-exclusion-filtering" aria-label="Permalink: Pattern 3: Exclusion Filtering" href="#pattern-3-exclusion-filtering"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Find relevant content while filtering out noise or unwanted categories.</p>
<div dir="auto" data-snippet-clipboard-copy-content="// Find &#34;apple&#34; content but exclude fruit/food related content
results := blaze.NewQueryBuilder(idx).
    Term(&#34;apple&#34;).
    And().Not().
    Group(func(q *blaze.QueryBuilder) {
        q.Term(&#34;fruit&#34;).Or().Term(&#34;food&#34;).Or().Term(&#34;cooking&#34;)
    }).
    Execute()  // Finds &#34;Apple Inc.&#34; not the fruit"><pre><span>// Find &#34;apple&#34; content but exclude fruit/food related content</span>
<span>results</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>).
    <span>Term</span>(<span>&#34;apple&#34;</span>).
    <span>And</span>().<span>Not</span>().
    <span>Group</span>(<span>func</span>(<span>q</span> <span>*</span>blaze.<span>QueryBuilder</span>) {
        <span>q</span>.<span>Term</span>(<span>&#34;fruit&#34;</span>).<span>Or</span>().<span>Term</span>(<span>&#34;food&#34;</span>).<span>Or</span>().<span>Term</span>(<span>&#34;cooking&#34;</span>)
    }).
    <span>Execute</span>()  <span>// Finds &#34;Apple Inc.&#34; not the fruit</span></pre></div>
<div dir="auto"><h4 tabindex="-1" dir="auto">Pattern 4: Category-Based Search</h4><a id="user-content-pattern-4-category-based-search" aria-label="Permalink: Pattern 4: Category-Based Search" href="#pattern-4-category-based-search"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Search within specific categories or tags.</p>
<div dir="auto" data-snippet-clipboard-copy-content="func SearchWithCategory(idx *blaze.InvertedIndex, query string, categories []string) []blaze.Match {
    qb := blaze.NewQueryBuilder(idx)

    // Add main query
    qb.Term(query)

    // Add category filter if provided
    if len(categories) &gt; 0 {
        qb.And().Group(func(q *blaze.QueryBuilder) {
            q.Term(categories[0])
            for i := 1; i &lt; len(categories); i++ {
                q.Or().Term(categories[i])
            }
        })
    }

    return qb.ExecuteWithBM25(20)
}"><pre><span>func</span> <span>SearchWithCategory</span>(<span>idx</span> <span>*</span>blaze.<span>InvertedIndex</span>, <span>query</span> <span>string</span>, <span>categories</span> []<span>string</span>) []blaze.<span>Match</span> {
    <span>qb</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>)

    <span>// Add main query</span>
    <span>qb</span>.<span>Term</span>(<span>query</span>)

    <span>// Add category filter if provided</span>
    <span>if</span> <span>len</span>(<span>categories</span>) <span>&gt;</span> <span>0</span> {
        <span>qb</span>.<span>And</span>().<span>Group</span>(<span>func</span>(<span>q</span> <span>*</span>blaze.<span>QueryBuilder</span>) {
            <span>q</span>.<span>Term</span>(<span>categories</span>[<span>0</span>])
            <span>for</span> <span>i</span> <span>:=</span> <span>1</span>; <span>i</span> <span>&lt;</span> <span>len</span>(<span>categories</span>); <span>i</span><span>++</span> {
                <span>q</span>.<span>Or</span>().<span>Term</span>(<span>categories</span>[<span>i</span>])
            }
        })
    }

    <span>return</span> <span>qb</span>.<span>ExecuteWithBM25</span>(<span>20</span>)
}</pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">Query Builder Performance</h3><a id="user-content-query-builder-performance" aria-label="Permalink: Query Builder Performance" href="#query-builder-performance"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">The Query Builder leverages roaring bitmaps for exceptional performance on boolean operations.</p>

<div data-snippet-clipboard-copy-content="BenchmarkQueryBuilder_Simple-8       440,616 ops/sec    2,511 ns/op    896 B/op    39 allocs/op
BenchmarkQueryBuilder_Complex-8      222,024 ops/sec    5,333 ns/op  2,240 B/op    98 allocs/op
BenchmarkQueryBuilder_WithBM25-8     411,124 ops/sec    2,955 ns/op  1,416 B/op    46 allocs/op"><pre><code>BenchmarkQueryBuilder_Simple-8       440,616 ops/sec    2,511 ns/op    896 B/op    39 allocs/op
BenchmarkQueryBuilder_Complex-8      222,024 ops/sec    5,333 ns/op  2,240 B/op    98 allocs/op
BenchmarkQueryBuilder_WithBM25-8     411,124 ops/sec    2,955 ns/op  1,416 B/op    46 allocs/op
</code></pre></div>

<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Operation</th>
<th>Complexity</th>
<th>Why It&#39;s Fast</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>AND</strong></td>
<td>O(1) per chunk</td>
<td>Roaring bitmap intersection</td>
</tr>
<tr>
<td><strong>OR</strong></td>
<td>O(1) per chunk</td>
<td>Roaring bitmap union</td>
</tr>
<tr>
<td><strong>NOT</strong></td>
<td>O(1) per chunk</td>
<td>Roaring bitmap difference</td>
</tr>
<tr>
<td><strong>Term Lookup</strong></td>
<td>O(1)</td>
<td>Direct hash map access</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>

<p dir="auto">For a term appearing in 500,000 documents:</p>
<ul dir="auto">
<li>Skip list positions: ~24 MB (500k nodes × 48 bytes)</li>
<li>Roaring bitmap: ~60 KB (400x compression!)</li>
</ul>
<div dir="auto"><h3 tabindex="-1" dir="auto">Query Builder Best Practices</h3><a id="user-content-query-builder-best-practices" aria-label="Permalink: Query Builder Best Practices" href="#query-builder-best-practices"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto"><h4 tabindex="-1" dir="auto">1. Use Groups for Complex Logic</h4><a id="user-content-1-use-groups-for-complex-logic" aria-label="Permalink: 1. Use Groups for Complex Logic" href="#1-use-groups-for-complex-logic"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto" data-snippet-clipboard-copy-content="// Good: Clear precedence with groups
qb.Group(func(q *blaze.QueryBuilder) {
    q.Term(&#34;a&#34;).Or().Term(&#34;b&#34;)
}).And().Term(&#34;c&#34;)

// Bad: Ambiguous without groups
qb.Term(&#34;a&#34;).Or().Term(&#34;b&#34;).And().Term(&#34;c&#34;)  // Is this (a OR b) AND c or a OR (b AND c)?"><pre><span>// Good: Clear precedence with groups</span>
<span>qb</span>.<span>Group</span>(<span>func</span>(<span>q</span> <span>*</span>blaze.<span>QueryBuilder</span>) {
    <span>q</span>.<span>Term</span>(<span>&#34;a&#34;</span>).<span>Or</span>().<span>Term</span>(<span>&#34;b&#34;</span>)
}).<span>And</span>().<span>Term</span>(<span>&#34;c&#34;</span>)

<span>// Bad: Ambiguous without groups</span>
<span>qb</span>.<span>Term</span>(<span>&#34;a&#34;</span>).<span>Or</span>().<span>Term</span>(<span>&#34;b&#34;</span>).<span>And</span>().<span>Term</span>(<span>&#34;c&#34;</span>)  <span>// Is this (a OR b) AND c or a OR (b AND c)?</span></pre></div>
<div dir="auto"><h4 tabindex="-1" dir="auto">2. Leverage Convenience Functions for Simple Cases</h4><a id="user-content-2-leverage-convenience-functions-for-simple-cases" aria-label="Permalink: 2. Leverage Convenience Functions for Simple Cases" href="#2-leverage-convenience-functions-for-simple-cases"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto" data-snippet-clipboard-copy-content="// Good: Clean and readable
results := blaze.AllOf(idx, &#34;python&#34;, &#34;django&#34;, &#34;web&#34;)

// Bad: Verbose for simple case
results := blaze.NewQueryBuilder(idx).
    Term(&#34;python&#34;).And().Term(&#34;django&#34;).And().Term(&#34;web&#34;).
    Execute()"><pre><span>// Good: Clean and readable</span>
<span>results</span> <span>:=</span> <span>blaze</span>.<span>AllOf</span>(<span>idx</span>, <span>&#34;python&#34;</span>, <span>&#34;django&#34;</span>, <span>&#34;web&#34;</span>)

<span>// Bad: Verbose for simple case</span>
<span>results</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>).
    <span>Term</span>(<span>&#34;python&#34;</span>).<span>And</span>().<span>Term</span>(<span>&#34;django&#34;</span>).<span>And</span>().<span>Term</span>(<span>&#34;web&#34;</span>).
    <span>Execute</span>()</pre></div>
<div dir="auto"><h4 tabindex="-1" dir="auto">3. Use BM25 for User-Facing Searches</h4><a id="user-content-3-use-bm25-for-user-facing-searches" aria-label="Permalink: 3. Use BM25 for User-Facing Searches" href="#3-use-bm25-for-user-facing-searches"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto" data-snippet-clipboard-copy-content="// Good: Ranked results for users
matches := qb.ExecuteWithBM25(10)

// Bad: Unranked - harder for users to find relevant docs
bitmap := qb.Execute()"><pre><span>// Good: Ranked results for users</span>
<span>matches</span> <span>:=</span> <span>qb</span>.<span>ExecuteWithBM25</span>(<span>10</span>)

<span>// Bad: Unranked - harder for users to find relevant docs</span>
<span>bitmap</span> <span>:=</span> <span>qb</span>.<span>Execute</span>()</pre></div>
<div dir="auto"><h4 tabindex="-1" dir="auto">4. Combine Phrases and Terms Strategically</h4><a id="user-content-4-combine-phrases-and-terms-strategically" aria-label="Permalink: 4. Combine Phrases and Terms Strategically" href="#4-combine-phrases-and-terms-strategically"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto" data-snippet-clipboard-copy-content="// Good: Exact phrase + related term
qb.Phrase(&#34;machine learning&#34;).And().Term(&#34;python&#34;)

// Bad: Overly restrictive
qb.Phrase(&#34;machine learning python&#34;)  // Requires exact phrase"><pre><span>// Good: Exact phrase + related term</span>
<span>qb</span>.<span>Phrase</span>(<span>&#34;machine learning&#34;</span>).<span>And</span>().<span>Term</span>(<span>&#34;python&#34;</span>)

<span>// Bad: Overly restrictive</span>
<span>qb</span>.<span>Phrase</span>(<span>&#34;machine learning python&#34;</span>)  <span>// Requires exact phrase</span></pre></div>
<div dir="auto"><h4 tabindex="-1" dir="auto">5. Build Queries Programmatically</h4><a id="user-content-5-build-queries-programmatically" aria-label="Permalink: 5. Build Queries Programmatically" href="#5-build-queries-programmatically"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto" data-snippet-clipboard-copy-content="func BuildDynamicQuery(idx *blaze.InvertedIndex, required []string, optional []string, excluded []string) *roaring.Bitmap {
    qb := blaze.NewQueryBuilder(idx)

    // Add required terms (AND)
    if len(required) &gt; 0 {
        qb.Term(required[0])
        for i := 1; i &lt; len(required); i++ {
            qb.And().Term(required[i])
        }
    }

    // Add optional terms (OR)
    if len(optional) &gt; 0 {
        if len(required) &gt; 0 {
            qb.And()
        }
        qb.Group(func(q *blaze.QueryBuilder) {
            q.Term(optional[0])
            for i := 1; i &lt; len(optional); i++ {
                q.Or().Term(optional[i])
            }
        })
    }

    // Exclude terms (NOT)
    for _, term := range excluded {
        qb.And().Not().Term(term)
    }

    return qb.Execute()
}"><pre><span>func</span> <span>BuildDynamicQuery</span>(<span>idx</span> <span>*</span>blaze.<span>InvertedIndex</span>, <span>required</span> []<span>string</span>, <span>optional</span> []<span>string</span>, <span>excluded</span> []<span>string</span>) <span>*</span>roaring.<span>Bitmap</span> {
    <span>qb</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>)

    <span>// Add required terms (AND)</span>
    <span>if</span> <span>len</span>(<span>required</span>) <span>&gt;</span> <span>0</span> {
        <span>qb</span>.<span>Term</span>(<span>required</span>[<span>0</span>])
        <span>for</span> <span>i</span> <span>:=</span> <span>1</span>; <span>i</span> <span>&lt;</span> <span>len</span>(<span>required</span>); <span>i</span><span>++</span> {
            <span>qb</span>.<span>And</span>().<span>Term</span>(<span>required</span>[<span>i</span>])
        }
    }

    <span>// Add optional terms (OR)</span>
    <span>if</span> <span>len</span>(<span>optional</span>) <span>&gt;</span> <span>0</span> {
        <span>if</span> <span>len</span>(<span>required</span>) <span>&gt;</span> <span>0</span> {
            <span>qb</span>.<span>And</span>()
        }
        <span>qb</span>.<span>Group</span>(<span>func</span>(<span>q</span> <span>*</span>blaze.<span>QueryBuilder</span>) {
            <span>q</span>.<span>Term</span>(<span>optional</span>[<span>0</span>])
            <span>for</span> <span>i</span> <span>:=</span> <span>1</span>; <span>i</span> <span>&lt;</span> <span>len</span>(<span>optional</span>); <span>i</span><span>++</span> {
                <span>q</span>.<span>Or</span>().<span>Term</span>(<span>optional</span>[<span>i</span>])
            }
        })
    }

    <span>// Exclude terms (NOT)</span>
    <span>for</span> <span>_</span>, <span>term</span> <span>:=</span> <span>range</span> <span>excluded</span> {
        <span>qb</span>.<span>And</span>().<span>Not</span>().<span>Term</span>(<span>term</span>)
    }

    <span>return</span> <span>qb</span>.<span>Execute</span>()
}</pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">Real-World Query Builder Examples</h3><a id="user-content-real-world-query-builder-examples" aria-label="Permalink: Real-World Query Builder Examples" href="#real-world-query-builder-examples"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto"><h4 tabindex="-1" dir="auto">Example 1: E-commerce Search with Filters</h4><a id="user-content-example-1-e-commerce-search-with-filters" aria-label="Permalink: Example 1: E-commerce Search with Filters" href="#example-1-e-commerce-search-with-filters"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto" data-snippet-clipboard-copy-content="func SearchProducts(idx *blaze.InvertedIndex, searchTerm string, category string, excludeOutOfStock bool) []blaze.Match {
    qb := blaze.NewQueryBuilder(idx).Term(searchTerm)

    // Add category filter
    if category != &#34;&#34; {
        qb.And().Term(category)
    }

    // Exclude out of stock items
    if excludeOutOfStock {
        qb.And().Not().Term(&#34;outofstock&#34;)
    }

    return qb.ExecuteWithBM25(20)
}"><pre><span>func</span> <span>SearchProducts</span>(<span>idx</span> <span>*</span>blaze.<span>InvertedIndex</span>, <span>searchTerm</span> <span>string</span>, <span>category</span> <span>string</span>, <span>excludeOutOfStock</span> <span>bool</span>) []blaze.<span>Match</span> {
    <span>qb</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>).<span>Term</span>(<span>searchTerm</span>)

    <span>// Add category filter</span>
    <span>if</span> <span>category</span> <span>!=</span> <span>&#34;&#34;</span> {
        <span>qb</span>.<span>And</span>().<span>Term</span>(<span>category</span>)
    }

    <span>// Exclude out of stock items</span>
    <span>if</span> <span>excludeOutOfStock</span> {
        <span>qb</span>.<span>And</span>().<span>Not</span>().<span>Term</span>(<span>&#34;outofstock&#34;</span>)
    }

    <span>return</span> <span>qb</span>.<span>ExecuteWithBM25</span>(<span>20</span>)
}</pre></div>
<div dir="auto"><h4 tabindex="-1" dir="auto">Example 2: Multi-Category Search</h4><a id="user-content-example-2-multi-category-search" aria-label="Permalink: Example 2: Multi-Category Search" href="#example-2-multi-category-search"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto" data-snippet-clipboard-copy-content="func SearchInCategories(idx *blaze.InvertedIndex, query string, categories []string) []blaze.Match {
    qb := blaze.NewQueryBuilder(idx).Term(query)

    if len(categories) &gt; 0 {
        qb.And().Group(func(q *blaze.QueryBuilder) {
            q.Term(categories[0])
            for i := 1; i &lt; len(categories); i++ {
                q.Or().Term(categories[i])
            }
        })
    }

    return qb.ExecuteWithBM25(50)
}"><pre><span>func</span> <span>SearchInCategories</span>(<span>idx</span> <span>*</span>blaze.<span>InvertedIndex</span>, <span>query</span> <span>string</span>, <span>categories</span> []<span>string</span>) []blaze.<span>Match</span> {
    <span>qb</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>).<span>Term</span>(<span>query</span>)

    <span>if</span> <span>len</span>(<span>categories</span>) <span>&gt;</span> <span>0</span> {
        <span>qb</span>.<span>And</span>().<span>Group</span>(<span>func</span>(<span>q</span> <span>*</span>blaze.<span>QueryBuilder</span>) {
            <span>q</span>.<span>Term</span>(<span>categories</span>[<span>0</span>])
            <span>for</span> <span>i</span> <span>:=</span> <span>1</span>; <span>i</span> <span>&lt;</span> <span>len</span>(<span>categories</span>); <span>i</span><span>++</span> {
                <span>q</span>.<span>Or</span>().<span>Term</span>(<span>categories</span>[<span>i</span>])
            }
        })
    }

    <span>return</span> <span>qb</span>.<span>ExecuteWithBM25</span>(<span>50</span>)
}</pre></div>
<div dir="auto"><h4 tabindex="-1" dir="auto">Example 3: Content Filtering with Blocklist</h4><a id="user-content-example-3-content-filtering-with-blocklist" aria-label="Permalink: Example 3: Content Filtering with Blocklist" href="#example-3-content-filtering-with-blocklist"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto" data-snippet-clipboard-copy-content="func FilterContent(idx *blaze.InvertedIndex, searchTerm string, blocklist []string) *roaring.Bitmap {
    qb := blaze.NewQueryBuilder(idx).Term(searchTerm)

    for _, blocked := range blocklist {
        qb.And().Not().Term(blocked)
    }

    return qb.Execute()
}"><pre><span>func</span> <span>FilterContent</span>(<span>idx</span> <span>*</span>blaze.<span>InvertedIndex</span>, <span>searchTerm</span> <span>string</span>, <span>blocklist</span> []<span>string</span>) <span>*</span>roaring.<span>Bitmap</span> {
    <span>qb</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>).<span>Term</span>(<span>searchTerm</span>)

    <span>for</span> <span>_</span>, <span>blocked</span> <span>:=</span> <span>range</span> <span>blocklist</span> {
        <span>qb</span>.<span>And</span>().<span>Not</span>().<span>Term</span>(<span>blocked</span>)
    }

    <span>return</span> <span>qb</span>.<span>Execute</span>()
}</pre></div>
<div dir="auto"><h4 tabindex="-1" dir="auto">Example 4: Advanced Search with Multiple Phrases</h4><a id="user-content-example-4-advanced-search-with-multiple-phrases" aria-label="Permalink: Example 4: Advanced Search with Multiple Phrases" href="#example-4-advanced-search-with-multiple-phrases"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto" data-snippet-clipboard-copy-content="func AdvancedSearch(idx *blaze.InvertedIndex, phrases []string, requiredTerms []string) []blaze.Match {
    qb := blaze.NewQueryBuilder(idx)

    // Match any of the phrases (OR)
    qb.Group(func(q *blaze.QueryBuilder) {
        q.Phrase(phrases[0])
        for i := 1; i &lt; len(phrases); i++ {
            q.Or().Phrase(phrases[i])
        }
    })

    // AND with required terms
    for _, term := range requiredTerms {
        qb.And().Term(term)
    }

    return qb.ExecuteWithBM25(10)
}

// Usage:
results := AdvancedSearch(idx,
    []string{&#34;machine learning&#34;, &#34;deep learning&#34;},
    []string{&#34;python&#34;, &#34;tensorflow&#34;})"><pre><span>func</span> <span>AdvancedSearch</span>(<span>idx</span> <span>*</span>blaze.<span>InvertedIndex</span>, <span>phrases</span> []<span>string</span>, <span>requiredTerms</span> []<span>string</span>) []blaze.<span>Match</span> {
    <span>qb</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>)

    <span>// Match any of the phrases (OR)</span>
    <span>qb</span>.<span>Group</span>(<span>func</span>(<span>q</span> <span>*</span>blaze.<span>QueryBuilder</span>) {
        <span>q</span>.<span>Phrase</span>(<span>phrases</span>[<span>0</span>])
        <span>for</span> <span>i</span> <span>:=</span> <span>1</span>; <span>i</span> <span>&lt;</span> <span>len</span>(<span>phrases</span>); <span>i</span><span>++</span> {
            <span>q</span>.<span>Or</span>().<span>Phrase</span>(<span>phrases</span>[<span>i</span>])
        }
    })

    <span>// AND with required terms</span>
    <span>for</span> <span>_</span>, <span>term</span> <span>:=</span> <span>range</span> <span>requiredTerms</span> {
        <span>qb</span>.<span>And</span>().<span>Term</span>(<span>term</span>)
    }

    <span>return</span> <span>qb</span>.<span>ExecuteWithBM25</span>(<span>10</span>)
}

<span>// Usage:</span>
<span>results</span> <span>:=</span> <span>AdvancedSearch</span>(<span>idx</span>,
    []<span>string</span>{<span>&#34;machine learning&#34;</span>, <span>&#34;deep learning&#34;</span>},
    []<span>string</span>{<span>&#34;python&#34;</span>, <span>&#34;tensorflow&#34;</span>})</pre></div>
<div dir="auto"><h4 tabindex="-1" dir="auto">Example 5: HTTP API Integration</h4><a id="user-content-example-5-http-api-integration" aria-label="Permalink: Example 5: HTTP API Integration" href="#example-5-http-api-integration"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto" data-snippet-clipboard-copy-content="func SearchHandler(w http.ResponseWriter, r *http.Request) {
    query := r.URL.Query().Get(&#34;q&#34;)
    category := r.URL.Query().Get(&#34;category&#34;)
    exclude := r.URL.Query().Get(&#34;exclude&#34;)

    qb := blaze.NewQueryBuilder(index).Term(query)

    if category != &#34;&#34; {
        qb.And().Term(category)
    }

    if exclude != &#34;&#34; {
        qb.And().Not().Term(exclude)
    }

    results := qb.ExecuteWithBM25(20)
    json.NewEncoder(w).Encode(results)
}"><pre><span>func</span> <span>SearchHandler</span>(<span>w</span> http.<span>ResponseWriter</span>, <span>r</span> <span>*</span>http.<span>Request</span>) {
    <span>query</span> <span>:=</span> <span>r</span>.<span>URL</span>.<span>Query</span>().<span>Get</span>(<span>&#34;q&#34;</span>)
    <span>category</span> <span>:=</span> <span>r</span>.<span>URL</span>.<span>Query</span>().<span>Get</span>(<span>&#34;category&#34;</span>)
    <span>exclude</span> <span>:=</span> <span>r</span>.<span>URL</span>.<span>Query</span>().<span>Get</span>(<span>&#34;exclude&#34;</span>)

    <span>qb</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>index</span>).<span>Term</span>(<span>query</span>)

    <span>if</span> <span>category</span> <span>!=</span> <span>&#34;&#34;</span> {
        <span>qb</span>.<span>And</span>().<span>Term</span>(<span>category</span>)
    }

    <span>if</span> <span>exclude</span> <span>!=</span> <span>&#34;&#34;</span> {
        <span>qb</span>.<span>And</span>().<span>Not</span>().<span>Term</span>(<span>exclude</span>)
    }

    <span>results</span> <span>:=</span> <span>qb</span>.<span>ExecuteWithBM25</span>(<span>20</span>)
    <span>json</span>.<span>NewEncoder</span>(<span>w</span>).<span>Encode</span>(<span>results</span>)
}</pre></div>
<div dir="auto"><h4 tabindex="-1" dir="auto">Example 6: Semantic-Style Search</h4><a id="user-content-example-6-semantic-style-search" aria-label="Permalink: Example 6: Semantic-Style Search" href="#example-6-semantic-style-search"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto" data-snippet-clipboard-copy-content="func SemanticSearch(idx *blaze.InvertedIndex, concept string, relatedTerms []string) []blaze.Match {
    qb := blaze.NewQueryBuilder(idx)

    // Main concept OR any related terms
    qb.Term(concept)
    for _, related := range relatedTerms {
        qb.Or().Term(related)
    }

    return qb.ExecuteWithBM25(50)
}

// Usage:
results := SemanticSearch(idx, &#34;automobile&#34;,
    []string{&#34;car&#34;, &#34;vehicle&#34;, &#34;transportation&#34;, &#34;automotive&#34;})"><pre><span>func</span> <span>SemanticSearch</span>(<span>idx</span> <span>*</span>blaze.<span>InvertedIndex</span>, <span>concept</span> <span>string</span>, <span>relatedTerms</span> []<span>string</span>) []blaze.<span>Match</span> {
    <span>qb</span> <span>:=</span> <span>blaze</span>.<span>NewQueryBuilder</span>(<span>idx</span>)

    <span>// Main concept OR any related terms</span>
    <span>qb</span>.<span>Term</span>(<span>concept</span>)
    <span>for</span> <span>_</span>, <span>related</span> <span>:=</span> <span>range</span> <span>relatedTerms</span> {
        <span>qb</span>.<span>Or</span>().<span>Term</span>(<span>related</span>)
    }

    <span>return</span> <span>qb</span>.<span>ExecuteWithBM25</span>(<span>50</span>)
}

<span>// Usage:</span>
<span>results</span> <span>:=</span> <span>SemanticSearch</span>(<span>idx</span>, <span>&#34;automobile&#34;</span>,
    []<span>string</span>{<span>&#34;car&#34;</span>, <span>&#34;vehicle&#34;</span>, <span>&#34;transportation&#34;</span>, <span>&#34;automotive&#34;</span>})</pre></div>



<div dir="auto" data-snippet-clipboard-copy-content="func NewInvertedIndex() *InvertedIndex"><pre><span>func</span> <span>NewInvertedIndex</span>() <span>*</span><span>InvertedIndex</span></pre></div>
<p dir="auto">Creates a new empty inverted index.</p>
<p dir="auto"><strong>Example:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="idx := blaze.NewInvertedIndex()"><pre><span>idx</span> <span>:=</span> <span>blaze</span>.<span>NewInvertedIndex</span>()</pre></div>

<div dir="auto" data-snippet-clipboard-copy-content="func (idx *InvertedIndex) Index(docID int, document string)"><pre><span>func</span> (<span>idx</span> <span>*</span><span>InvertedIndex</span>) <span>Index</span>(<span>docID</span> <span>int</span>, <span>document</span> <span>string</span>)</pre></div>
<p dir="auto">Adds a document to the inverted index. Thread-safe.</p>
<p dir="auto"><strong>Parameters:</strong></p>
<ul dir="auto">
<li><code>docID</code>: Unique document identifier</li>
<li><code>document</code>: Text content to index</li>
</ul>
<p dir="auto"><strong>Example:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="idx.Index(1, &#34;The quick brown fox jumps over the lazy dog&#34;)
idx.Index(2, &#34;A fast brown dog&#34;)"><pre><span>idx</span>.<span>Index</span>(<span>1</span>, <span>&#34;The quick brown fox jumps over the lazy dog&#34;</span>)
<span>idx</span>.<span>Index</span>(<span>2</span>, <span>&#34;A fast brown dog&#34;</span>)</pre></div>
<p dir="auto"><strong>What Happens:</strong></p>
<ol dir="auto">
<li>Text is analyzed (tokenized, stemmed, etc.)</li>
<li>Each token is recorded with its position</li>
<li>Positions are stored in skip lists for fast lookup</li>
</ol>

<div dir="auto" data-snippet-clipboard-copy-content="func (idx *InvertedIndex) First(token string) (Position, error)"><pre><span>func</span> (<span>idx</span> <span>*</span><span>InvertedIndex</span>) <span>First</span>(<span>token</span> <span>string</span>) (<span>Position</span>, <span>error</span>)</pre></div>
<p dir="auto">Returns the first occurrence of a token in the index.</p>
<p dir="auto"><strong>Example:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="pos, err := idx.First(&#34;quick&#34;)
if err != nil {
    // Token not found
}
fmt.Printf(&#34;Doc %d, Pos %d\n&#34;, int(pos.DocumentID), int(pos.Offset))"><pre><span>pos</span>, <span>err</span> <span>:=</span> <span>idx</span>.<span>First</span>(<span>&#34;quick&#34;</span>)
<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
    <span>// Token not found</span>
}
<span>fmt</span>.<span>Printf</span>(<span>&#34;Doc %d, Pos %d<span>\n</span>&#34;</span>, <span>int</span>(<span>pos</span>.<span>DocumentID</span>), <span>int</span>(<span>pos</span>.<span>Offset</span>))</pre></div>
<p dir="auto"><strong>Returns:</strong></p>
<ul dir="auto">
<li><code>Position</code>: Location of first occurrence</li>
<li><code>error</code>: <code>ErrNoPostingList</code> if token doesn&#39;t exist</li>
</ul>

<div dir="auto" data-snippet-clipboard-copy-content="func (idx *InvertedIndex) Last(token string) (Position, error)"><pre><span>func</span> (<span>idx</span> <span>*</span><span>InvertedIndex</span>) <span>Last</span>(<span>token</span> <span>string</span>) (<span>Position</span>, <span>error</span>)</pre></div>
<p dir="auto">Returns the last occurrence of a token in the index.</p>
<p dir="auto"><strong>Example:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="pos, err := idx.Last(&#34;quick&#34;)"><pre><span>pos</span>, <span>err</span> <span>:=</span> <span>idx</span>.<span>Last</span>(<span>&#34;quick&#34;</span>)</pre></div>

<div dir="auto" data-snippet-clipboard-copy-content="func (idx *InvertedIndex) Next(token string, currentPos Position) (Position, error)"><pre><span>func</span> (<span>idx</span> <span>*</span><span>InvertedIndex</span>) <span>Next</span>(<span>token</span> <span>string</span>, <span>currentPos</span> <span>Position</span>) (<span>Position</span>, <span>error</span>)</pre></div>
<p dir="auto">Finds the next occurrence of a token after the given position.</p>
<p dir="auto"><strong>Example:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="// Iterate through all occurrences
pos := blaze.BOFDocument
for {
    pos, err = idx.Next(&#34;quick&#34;, pos)
    if pos.IsEnd() || err != nil {
        break
    }
    fmt.Printf(&#34;Found at Doc %d, Pos %d\n&#34;,
        int(pos.DocumentID), int(pos.Offset))
}"><pre><span>// Iterate through all occurrences</span>
<span>pos</span> <span>:=</span> <span>blaze</span>.<span>BOFDocument</span>
<span>for</span> {
    <span>pos</span>, <span>err</span> <span>=</span> <span>idx</span>.<span>Next</span>(<span>&#34;quick&#34;</span>, <span>pos</span>)
    <span>if</span> <span>pos</span>.<span>IsEnd</span>() <span>||</span> <span>err</span> <span>!=</span> <span>nil</span> {
        <span>break</span>
    }
    <span>fmt</span>.<span>Printf</span>(<span>&#34;Found at Doc %d, Pos %d<span>\n</span>&#34;</span>,
        <span>int</span>(<span>pos</span>.<span>DocumentID</span>), <span>int</span>(<span>pos</span>.<span>Offset</span>))
}</pre></div>

<div dir="auto" data-snippet-clipboard-copy-content="func (idx *InvertedIndex) Previous(token string, currentPos Position) (Position, error)"><pre><span>func</span> (<span>idx</span> <span>*</span><span>InvertedIndex</span>) <span>Previous</span>(<span>token</span> <span>string</span>, <span>currentPos</span> <span>Position</span>) (<span>Position</span>, <span>error</span>)</pre></div>
<p dir="auto">Finds the previous occurrence of a token before the given position.</p>

<div dir="auto" data-snippet-clipboard-copy-content="func (idx *InvertedIndex) NextPhrase(query string, startPos Position) []Position"><pre><span>func</span> (<span>idx</span> <span>*</span><span>InvertedIndex</span>) <span>NextPhrase</span>(<span>query</span> <span>string</span>, <span>startPos</span> <span>Position</span>) []<span>Position</span></pre></div>
<p dir="auto">Finds the next occurrence of a phrase (exact word sequence).</p>
<p dir="auto"><strong>Parameters:</strong></p>
<ul dir="auto">
<li><code>query</code>: Space-separated phrase (e.g., &#34;quick brown fox&#34;)</li>
<li><code>startPos</code>: Position to start searching from</li>
</ul>
<p dir="auto"><strong>Returns:</strong></p>
<ul dir="auto">
<li><code>[]Position</code>: Array with two elements [phraseStart, phraseEnd]</li>
<li>Returns <code>[EOFDocument, EOFDocument]</code> if no match found</li>
</ul>
<p dir="auto"><strong>Example:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="matches := idx.NextPhrase(&#34;quick brown fox&#34;, blaze.BOFDocument)
if !matches[0].IsEnd() {
    fmt.Printf(&#34;Phrase found in Doc %d from Pos %d to %d\n&#34;,
        int(matches[0].DocumentID),
        int(matches[0].Offset),
        int(matches[1].Offset))
}"><pre><span>matches</span> <span>:=</span> <span>idx</span>.<span>NextPhrase</span>(<span>&#34;quick brown fox&#34;</span>, <span>blaze</span>.<span>BOFDocument</span>)
<span>if</span> <span>!</span><span>matches</span>[<span>0</span>].<span>IsEnd</span>() {
    <span>fmt</span>.<span>Printf</span>(<span>&#34;Phrase found in Doc %d from Pos %d to %d<span>\n</span>&#34;</span>,
        <span>int</span>(<span>matches</span>[<span>0</span>].<span>DocumentID</span>),
        <span>int</span>(<span>matches</span>[<span>0</span>].<span>Offset</span>),
        <span>int</span>(<span>matches</span>[<span>1</span>].<span>Offset</span>))
}</pre></div>

<div dir="auto" data-snippet-clipboard-copy-content="func (idx *InvertedIndex) FindAllPhrases(query string, startPos Position) [][]Position"><pre><span>func</span> (<span>idx</span> <span>*</span><span>InvertedIndex</span>) <span>FindAllPhrases</span>(<span>query</span> <span>string</span>, <span>startPos</span> <span>Position</span>) [][]<span>Position</span></pre></div>
<p dir="auto">Finds all occurrences of a phrase in the entire index.</p>
<p dir="auto"><strong>Example:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="allMatches := idx.FindAllPhrases(&#34;brown fox&#34;, blaze.BOFDocument)
for _, match := range allMatches {
    fmt.Printf(&#34;Doc %d: Pos %d-%d\n&#34;,
        int(match[0].DocumentID),
        int(match[0].Offset),
        int(match[1].Offset))
}"><pre><span>allMatches</span> <span>:=</span> <span>idx</span>.<span>FindAllPhrases</span>(<span>&#34;brown fox&#34;</span>, <span>blaze</span>.<span>BOFDocument</span>)
<span>for</span> <span>_</span>, <span>match</span> <span>:=</span> <span>range</span> <span>allMatches</span> {
    <span>fmt</span>.<span>Printf</span>(<span>&#34;Doc %d: Pos %d-%d<span>\n</span>&#34;</span>,
        <span>int</span>(<span>match</span>[<span>0</span>].<span>DocumentID</span>),
        <span>int</span>(<span>match</span>[<span>0</span>].<span>Offset</span>),
        <span>int</span>(<span>match</span>[<span>1</span>].<span>Offset</span>))
}</pre></div>

<div dir="auto" data-snippet-clipboard-copy-content="func (idx *InvertedIndex) NextCover(tokens []string, startPos Position) []Position"><pre><span>func</span> (<span>idx</span> <span>*</span><span>InvertedIndex</span>) <span>NextCover</span>(<span>tokens</span> []<span>string</span>, <span>startPos</span> <span>Position</span>) []<span>Position</span></pre></div>
<p dir="auto">Finds the next &#34;cover&#34; - a range containing all given tokens.</p>
<p dir="auto"><strong>Parameters:</strong></p>
<ul dir="auto">
<li><code>tokens</code>: Array of search terms</li>
<li><code>startPos</code>: Position to start searching from</li>
</ul>
<p dir="auto"><strong>Returns:</strong></p>
<ul dir="auto">
<li><code>[]Position</code>: Array with [coverStart, coverEnd]</li>
</ul>
<p dir="auto"><strong>Example:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="cover := idx.NextCover([]string{&#34;quick&#34;, &#34;fox&#34;, &#34;brown&#34;}, blaze.BOFDocument)
fmt.Printf(&#34;Cover: Doc %d, Pos %d-%d\n&#34;,
    int(cover[0].DocumentID),
    int(cover[0].Offset),
    int(cover[1].Offset))"><pre><span>cover</span> <span>:=</span> <span>idx</span>.<span>NextCover</span>([]<span>string</span>{<span>&#34;quick&#34;</span>, <span>&#34;fox&#34;</span>, <span>&#34;brown&#34;</span>}, <span>blaze</span>.<span>BOFDocument</span>)
<span>fmt</span>.<span>Printf</span>(<span>&#34;Cover: Doc %d, Pos %d-%d<span>\n</span>&#34;</span>,
    <span>int</span>(<span>cover</span>[<span>0</span>].<span>DocumentID</span>),
    <span>int</span>(<span>cover</span>[<span>0</span>].<span>Offset</span>),
    <span>int</span>(<span>cover</span>[<span>1</span>].<span>Offset</span>))</pre></div>

<div dir="auto" data-snippet-clipboard-copy-content="func (idx *InvertedIndex) RankBM25(query string, maxResults int) []Match"><pre><span>func</span> (<span>idx</span> <span>*</span><span>InvertedIndex</span>) <span>RankBM25</span>(<span>query</span> <span>string</span>, <span>maxResults</span> <span>int</span>) []<span>Match</span></pre></div>
<p dir="auto">Performs BM25 ranking of search results. This is the recommended search function for most use cases.</p>
<p dir="auto"><strong>Parameters:</strong></p>
<ul dir="auto">
<li><code>query</code>: Search query (e.g., &#34;machine learning&#34;)</li>
<li><code>maxResults</code>: Maximum number of results to return</li>
</ul>
<p dir="auto"><strong>Returns:</strong></p>
<ul dir="auto">
<li><code>[]Match</code>: Sorted array of matches with BM25 scores</li>
</ul>
<p dir="auto"><strong>Example:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="results := idx.RankBM25(&#34;machine learning&#34;, 10)
for i, match := range results {
    fmt.Printf(&#34;%d. Doc %d (score: %.2f)\n&#34;,
        i+1,
        match.DocID,
        match.Score)
}"><pre><span>results</span> <span>:=</span> <span>idx</span>.<span>RankBM25</span>(<span>&#34;machine learning&#34;</span>, <span>10</span>)
<span>for</span> <span>i</span>, <span>match</span> <span>:=</span> <span>range</span> <span>results</span> {
    <span>fmt</span>.<span>Printf</span>(<span>&#34;%d. Doc %d (score: %.2f)<span>\n</span>&#34;</span>,
        <span>i</span><span>+</span><span>1</span>,
        <span>match</span>.<span>DocID</span>,
        <span>match</span>.<span>Score</span>)
}</pre></div>
<p dir="auto"><strong>Match Structure:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="type Match struct {
    DocID   int        // Document identifier
    Offsets []Position // Where terms appear in the document
    Score   float64    // BM25 relevance score
}"><pre><span>type</span> <span>Match</span> <span>struct</span> {
    <span>DocID</span>   <span>int</span>        <span>// Document identifier</span>
    <span>Offsets</span> []<span>Position</span> <span>// Where terms appear in the document</span>
    <span>Score</span>   <span>float64</span>    <span>// BM25 relevance score</span>
}</pre></div>

<div dir="auto" data-snippet-clipboard-copy-content="func (idx *InvertedIndex) RankProximity(query string, maxResults int) []Match"><pre><span>func</span> (<span>idx</span> <span>*</span><span>InvertedIndex</span>) <span>RankProximity</span>(<span>query</span> <span>string</span>, <span>maxResults</span> <span>int</span>) []<span>Match</span></pre></div>
<p dir="auto">Performs proximity-based ranking of search results. Alternative to BM25, ranks by term proximity.</p>
<p dir="auto"><strong>Parameters:</strong></p>
<ul dir="auto">
<li><code>query</code>: Search query (e.g., &#34;machine learning&#34;)</li>
<li><code>maxResults</code>: Maximum number of results to return</li>
</ul>
<p dir="auto"><strong>Returns:</strong></p>
<ul dir="auto">
<li><code>[]Match</code>: Sorted array of matches with proximity scores</li>
</ul>
<p dir="auto"><strong>Example:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="results := idx.RankProximity(&#34;quick brown&#34;, 5)
for i, match := range results {
    fmt.Printf(&#34;%d. Doc %d (score: %.2f)\n&#34;,
        i+1,
        int(match.Offsets[0].DocumentID),
        match.Score)
}"><pre><span>results</span> <span>:=</span> <span>idx</span>.<span>RankProximity</span>(<span>&#34;quick brown&#34;</span>, <span>5</span>)
<span>for</span> <span>i</span>, <span>match</span> <span>:=</span> <span>range</span> <span>results</span> {
    <span>fmt</span>.<span>Printf</span>(<span>&#34;%d. Doc %d (score: %.2f)<span>\n</span>&#34;</span>,
        <span>i</span><span>+</span><span>1</span>,
        <span>int</span>(<span>match</span>.<span>Offsets</span>[<span>0</span>].<span>DocumentID</span>),
        <span>match</span>.<span>Score</span>)
}</pre></div>
<p dir="auto"><strong>BM25 vs Proximity Ranking:</strong></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Feature</th>
<th>BM25</th>
<th>Proximity</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>Term Rarity</strong></td>
<td>Yes (IDF)</td>
<td>No (all terms equal)</td>
</tr>
<tr>
<td><strong>Length Normalization</strong></td>
<td>Yes (built-in)</td>
<td>No</td>
</tr>
<tr>
<td><strong>Term Frequency</strong></td>
<td>Yes (with saturation)</td>
<td>No</td>
</tr>
<tr>
<td><strong>Term Distance</strong></td>
<td>No</td>
<td>Yes (main factor)</td>
</tr>
<tr>
<td><strong>Use Case</strong></td>
<td>General search</td>
<td>Finding close co-occurrences</td>
</tr>
<tr>
<td><strong>Industry Standard</strong></td>
<td>Yes (Elasticsearch, Solr)</td>
<td>No (custom algorithm)</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>

<div dir="auto" data-snippet-clipboard-copy-content="func (idx *InvertedIndex) Encode() ([]byte, error)"><pre><span>func</span> (<span>idx</span> <span>*</span><span>InvertedIndex</span>) <span>Encode</span>() ([]<span>byte</span>, <span>error</span>)</pre></div>
<p dir="auto">Serializes the inverted index to binary format.</p>
<p dir="auto"><strong>Example:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="data, err := idx.Encode()
if err != nil {
    log.Fatal(err)
}

// Save to file
err = os.WriteFile(&#34;index.bin&#34;, data, 0644)"><pre><span>data</span>, <span>err</span> <span>:=</span> <span>idx</span>.<span>Encode</span>()
<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
    <span>log</span>.<span>Fatal</span>(<span>err</span>)
}

<span>// Save to file</span>
<span>err</span> <span>=</span> <span>os</span>.<span>WriteFile</span>(<span>&#34;index.bin&#34;</span>, <span>data</span>, <span>0644</span>)</pre></div>

<div dir="auto" data-snippet-clipboard-copy-content="func (idx *InvertedIndex) Decode(data []byte) error"><pre><span>func</span> (<span>idx</span> <span>*</span><span>InvertedIndex</span>) <span>Decode</span>(<span>data</span> []<span>byte</span>) <span>error</span></pre></div>
<p dir="auto">Deserializes binary data back into an inverted index.</p>
<p dir="auto"><strong>Example:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="data, err := os.ReadFile(&#34;index.bin&#34;)
if err != nil {
    log.Fatal(err)
}

idx := blaze.NewInvertedIndex()
err = idx.Decode(data)"><pre><span>data</span>, <span>err</span> <span>:=</span> <span>os</span>.<span>ReadFile</span>(<span>&#34;index.bin&#34;</span>)
<span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
    <span>log</span>.<span>Fatal</span>(<span>err</span>)
}

<span>idx</span> <span>:=</span> <span>blaze</span>.<span>NewInvertedIndex</span>()
<span>err</span> <span>=</span> <span>idx</span>.<span>Decode</span>(<span>data</span>)</pre></div>


<div dir="auto" data-snippet-clipboard-copy-content="func Analyze(text string) []string"><pre><span>func</span> <span>Analyze</span>(<span>text</span> <span>string</span>) []<span>string</span></pre></div>
<p dir="auto">Transforms raw text into searchable tokens using the default pipeline.</p>
<p dir="auto"><strong>Example:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="tokens := blaze.Analyze(&#34;The Quick Brown Fox Jumps!&#34;)
// Returns: [&#34;quick&#34;, &#34;brown&#34;, &#34;fox&#34;, &#34;jump&#34;]"><pre><span>tokens</span> <span>:=</span> <span>blaze</span>.<span>Analyze</span>(<span>&#34;The Quick Brown Fox Jumps!&#34;</span>)
<span>// Returns: [&#34;quick&#34;, &#34;brown&#34;, &#34;fox&#34;, &#34;jump&#34;]</span></pre></div>

<div dir="auto" data-snippet-clipboard-copy-content="func AnalyzeWithConfig(text string, config AnalyzerConfig) []string"><pre><span>func</span> <span>AnalyzeWithConfig</span>(<span>text</span> <span>string</span>, <span>config</span> <span>AnalyzerConfig</span>) []<span>string</span></pre></div>
<p dir="auto">Transforms text using a custom configuration.</p>
<p dir="auto"><strong>Example:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="config := blaze.AnalyzerConfig{
    MinTokenLength:  3,
    EnableStemming:  false,
    EnableStopwords: true,
}
tokens := blaze.AnalyzeWithConfig(&#34;The quick brown fox&#34;, config)"><pre><span>config</span> <span>:=</span> blaze.<span>AnalyzerConfig</span>{
    <span>MinTokenLength</span>:  <span>3</span>,
    <span>EnableStemming</span>:  <span>false</span>,
    <span>EnableStopwords</span>: <span>true</span>,
}
<span>tokens</span> <span>:=</span> <span>blaze</span>.<span>AnalyzeWithConfig</span>(<span>&#34;The quick brown fox&#34;</span>, <span>config</span>)</pre></div>


<div dir="auto" data-snippet-clipboard-copy-content="func (p *Position) GetDocumentID() int
func (p *Position) GetOffset() int
func (p *Position) IsBeginning() bool
func (p *Position) IsEnd() bool
func (p *Position) IsBefore(other Position) bool
func (p *Position) IsAfter(other Position) bool
func (p *Position) Equals(other Position) bool"><pre><span>func</span> (<span>p</span> <span>*</span><span>Position</span>) <span>GetDocumentID</span>() <span>int</span>
<span>func</span> (<span>p</span> <span>*</span><span>Position</span>) <span>GetOffset</span>() <span>int</span>
<span>func</span> (<span>p</span> <span>*</span><span>Position</span>) <span>IsBeginning</span>() <span>bool</span>
<span>func</span> (<span>p</span> <span>*</span><span>Position</span>) <span>IsEnd</span>() <span>bool</span>
<span>func</span> (<span>p</span> <span>*</span><span>Position</span>) <span>IsBefore</span>(<span>other</span> <span>Position</span>) <span>bool</span>
<span>func</span> (<span>p</span> <span>*</span><span>Position</span>) <span>IsAfter</span>(<span>other</span> <span>Position</span>) <span>bool</span>
<span>func</span> (<span>p</span> <span>*</span><span>Position</span>) <span>Equals</span>(<span>other</span> <span>Position</span>) <span>bool</span></pre></div>
<p dir="auto"><strong>Example:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="pos1 := blaze.Position{DocumentID: 1, Offset: 5}
pos2 := blaze.Position{DocumentID: 1, Offset: 10}

if pos1.IsBefore(pos2) {
    fmt.Println(&#34;pos1 comes before pos2&#34;)
}"><pre><span>pos1</span> <span>:=</span> blaze.<span>Position</span>{<span>DocumentID</span>: <span>1</span>, <span>Offset</span>: <span>5</span>}
<span>pos2</span> <span>:=</span> blaze.<span>Position</span>{<span>DocumentID</span>: <span>1</span>, <span>Offset</span>: <span>10</span>}

<span>if</span> <span>pos1</span>.<span>IsBefore</span>(<span>pos2</span>) {
    <span>fmt</span>.<span>Println</span>(<span>&#34;pos1 comes before pos2&#34;</span>)
}</pre></div>


<div dir="auto" data-snippet-clipboard-copy-content="func NewSkipList() *SkipList"><pre><span>func</span> <span>NewSkipList</span>() <span>*</span><span>SkipList</span></pre></div>
<p dir="auto">Creates a new empty skip list.</p>

<div dir="auto" data-snippet-clipboard-copy-content="func (sl *SkipList) Insert(key Position)"><pre><span>func</span> (<span>sl</span> <span>*</span><span>SkipList</span>) <span>Insert</span>(<span>key</span> <span>Position</span>)</pre></div>
<p dir="auto">Adds or updates a position in the skip list. Average O(log n).</p>

<div dir="auto" data-snippet-clipboard-copy-content="func (sl *SkipList) Find(key Position) (Position, error)"><pre><span>func</span> (<span>sl</span> <span>*</span><span>SkipList</span>) <span>Find</span>(<span>key</span> <span>Position</span>) (<span>Position</span>, <span>error</span>)</pre></div>
<p dir="auto">Searches for an exact position. Average O(log n).</p>

<div dir="auto" data-snippet-clipboard-copy-content="func (sl *SkipList) Delete(key Position) bool"><pre><span>func</span> (<span>sl</span> <span>*</span><span>SkipList</span>) <span>Delete</span>(<span>key</span> <span>Position</span>) <span>bool</span></pre></div>
<p dir="auto">Removes a position from the skip list. Average O(log n).</p>

<div dir="auto" data-snippet-clipboard-copy-content="func (sl *SkipList) FindLessThan(key Position) (Position, error)"><pre><span>func</span> (<span>sl</span> <span>*</span><span>SkipList</span>) <span>FindLessThan</span>(<span>key</span> <span>Position</span>) (<span>Position</span>, <span>error</span>)</pre></div>
<p dir="auto">Finds the largest position less than the given position.</p>

<div dir="auto" data-snippet-clipboard-copy-content="func (sl *SkipList) FindGreaterThan(key Position) (Position, error)"><pre><span>func</span> (<span>sl</span> <span>*</span><span>SkipList</span>) <span>FindGreaterThan</span>(<span>key</span> <span>Position</span>) (<span>Position</span>, <span>error</span>)</pre></div>
<p dir="auto">Finds the smallest position greater than the given position.</p>

<div dir="auto"><h3 tabindex="-1" dir="auto">Example 1: Basic Document Search with BM25</h3><a id="user-content-example-1-basic-document-search-with-bm25" aria-label="Permalink: Example 1: Basic Document Search with BM25" href="#example-1-basic-document-search-with-bm25"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto" data-snippet-clipboard-copy-content="package main

import (
    &#34;fmt&#34;
    &#34;github.com/wizenheimer/blaze&#34;
)

func main() {
    // Create index
    idx := blaze.NewInvertedIndex()

    // Index documents
    idx.Index(1, &#34;Go is a programming language designed at Google&#34;)
    idx.Index(2, &#34;Python is a high-level programming language&#34;)
    idx.Index(3, &#34;Go is fast and efficient for system programming&#34;)

    // Search for &#34;programming language&#34; using BM25
    results := idx.RankBM25(&#34;programming language&#34;, 10)

    fmt.Println(&#34;Search results for &#39;programming language&#39;:&#34;)
    for i, match := range results {
        fmt.Printf(&#34;%d. Document %d (score: %.3f)\n&#34;, i+1, match.DocID, match.Score)
    }
}"><pre><span>package</span> main

<span>import</span> (
    <span>&#34;fmt&#34;</span>
    <span>&#34;github.com/wizenheimer/blaze&#34;</span>
)

<span>func</span> <span>main</span>() {
    <span>// Create index</span>
    <span>idx</span> <span>:=</span> <span>blaze</span>.<span>NewInvertedIndex</span>()

    <span>// Index documents</span>
    <span>idx</span>.<span>Index</span>(<span>1</span>, <span>&#34;Go is a programming language designed at Google&#34;</span>)
    <span>idx</span>.<span>Index</span>(<span>2</span>, <span>&#34;Python is a high-level programming language&#34;</span>)
    <span>idx</span>.<span>Index</span>(<span>3</span>, <span>&#34;Go is fast and efficient for system programming&#34;</span>)

    <span>// Search for &#34;programming language&#34; using BM25</span>
    <span>results</span> <span>:=</span> <span>idx</span>.<span>RankBM25</span>(<span>&#34;programming language&#34;</span>, <span>10</span>)

    <span>fmt</span>.<span>Println</span>(<span>&#34;Search results for &#39;programming language&#39;:&#34;</span>)
    <span>for</span> <span>i</span>, <span>match</span> <span>:=</span> <span>range</span> <span>results</span> {
        <span>fmt</span>.<span>Printf</span>(<span>&#34;%d. Document %d (score: %.3f)<span>\n</span>&#34;</span>, <span>i</span><span>+</span><span>1</span>, <span>match</span>.<span>DocID</span>, <span>match</span>.<span>Score</span>)
    }
}</pre></div>
<p dir="auto"><strong>Output:</strong></p>
<div data-snippet-clipboard-copy-content="Search results for &#39;programming language&#39;:
1. Document 1 (score: 4.521)
2. Document 2 (score: 4.521)
3. Document 3 (score: 2.156)"><pre><code>Search results for &#39;programming language&#39;:
1. Document 1 (score: 4.521)
2. Document 2 (score: 4.521)
3. Document 3 (score: 2.156)
</code></pre></div>
<p dir="auto"><strong>Note</strong>: BM25 scores are absolute values (not normalized to 0-1), reflecting relevance based on term frequency, document length, and term rarity.</p>

<div dir="auto" data-snippet-clipboard-copy-content="package main

import (
    &#34;fmt&#34;
    &#34;github.com/wizenheimer/blaze&#34;
)

func main() {
    idx := blaze.NewInvertedIndex()

    idx.Index(1, &#34;the quick brown fox jumps over the lazy dog&#34;)
    idx.Index(2, &#34;a quick brown dog runs fast&#34;)
    idx.Index(3, &#34;the lazy brown fox sleeps&#34;)

    // Find exact phrase &#34;brown fox&#34;
    matches := idx.FindAllPhrases(&#34;brown fox&#34;, blaze.BOFDocument)

    fmt.Println(&#34;Documents containing &#39;brown fox&#39; as a phrase:&#34;)
    for _, match := range matches {
        docID := int(match[0].DocumentID)
        start := int(match[0].Offset)
        end := int(match[1].Offset)
        fmt.Printf(&#34;Document %d: positions %d-%d\n&#34;, docID, start, end)
    }
}"><pre><span>package</span> main

<span>import</span> (
    <span>&#34;fmt&#34;</span>
    <span>&#34;github.com/wizenheimer/blaze&#34;</span>
)

<span>func</span> <span>main</span>() {
    <span>idx</span> <span>:=</span> <span>blaze</span>.<span>NewInvertedIndex</span>()

    <span>idx</span>.<span>Index</span>(<span>1</span>, <span>&#34;the quick brown fox jumps over the lazy dog&#34;</span>)
    <span>idx</span>.<span>Index</span>(<span>2</span>, <span>&#34;a quick brown dog runs fast&#34;</span>)
    <span>idx</span>.<span>Index</span>(<span>3</span>, <span>&#34;the lazy brown fox sleeps&#34;</span>)

    <span>// Find exact phrase &#34;brown fox&#34;</span>
    <span>matches</span> <span>:=</span> <span>idx</span>.<span>FindAllPhrases</span>(<span>&#34;brown fox&#34;</span>, <span>blaze</span>.<span>BOFDocument</span>)

    <span>fmt</span>.<span>Println</span>(<span>&#34;Documents containing &#39;brown fox&#39; as a phrase:&#34;</span>)
    <span>for</span> <span>_</span>, <span>match</span> <span>:=</span> <span>range</span> <span>matches</span> {
        <span>docID</span> <span>:=</span> <span>int</span>(<span>match</span>[<span>0</span>].<span>DocumentID</span>)
        <span>start</span> <span>:=</span> <span>int</span>(<span>match</span>[<span>0</span>].<span>Offset</span>)
        <span>end</span> <span>:=</span> <span>int</span>(<span>match</span>[<span>1</span>].<span>Offset</span>)
        <span>fmt</span>.<span>Printf</span>(<span>&#34;Document %d: positions %d-%d<span>\n</span>&#34;</span>, <span>docID</span>, <span>start</span>, <span>end</span>)
    }
}</pre></div>
<p dir="auto"><strong>Output:</strong></p>
<div data-snippet-clipboard-copy-content="Documents containing &#39;brown fox&#39; as a phrase:
Document 1: positions 1-2
Document 3: positions 2-3"><pre><code>Documents containing &#39;brown fox&#39; as a phrase:
Document 1: positions 1-2
Document 3: positions 2-3
</code></pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">Example 3: Iterating Through Positions</h3><a id="user-content-example-3-iterating-through-positions" aria-label="Permalink: Example 3: Iterating Through Positions" href="#example-3-iterating-through-positions"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto" data-snippet-clipboard-copy-content="package main

import (
    &#34;fmt&#34;
    &#34;github.com/wizenheimer/blaze&#34;
)

func main() {
    idx := blaze.NewInvertedIndex()

    idx.Index(1, &#34;quick test quick test quick&#34;)
    idx.Index(2, &#34;another quick test here&#34;)

    // Find all occurrences of &#34;quick&#34;
    fmt.Println(&#34;All occurrences of &#39;quick&#39;:&#34;)

    pos := blaze.BOFDocument
    for {
        pos, err := idx.Next(&#34;quick&#34;, pos)
        if err != nil || pos.IsEnd() {
            break
        }
        fmt.Printf(&#34;  Doc %d, Pos %d\n&#34;,
            int(pos.DocumentID),
            int(pos.Offset))
    }
}"><pre><span>package</span> main

<span>import</span> (
    <span>&#34;fmt&#34;</span>
    <span>&#34;github.com/wizenheimer/blaze&#34;</span>
)

<span>func</span> <span>main</span>() {
    <span>idx</span> <span>:=</span> <span>blaze</span>.<span>NewInvertedIndex</span>()

    <span>idx</span>.<span>Index</span>(<span>1</span>, <span>&#34;quick test quick test quick&#34;</span>)
    <span>idx</span>.<span>Index</span>(<span>2</span>, <span>&#34;another quick test here&#34;</span>)

    <span>// Find all occurrences of &#34;quick&#34;</span>
    <span>fmt</span>.<span>Println</span>(<span>&#34;All occurrences of &#39;quick&#39;:&#34;</span>)

    <span>pos</span> <span>:=</span> <span>blaze</span>.<span>BOFDocument</span>
    <span>for</span> {
        <span>pos</span>, <span>err</span> <span>:=</span> <span>idx</span>.<span>Next</span>(<span>&#34;quick&#34;</span>, <span>pos</span>)
        <span>if</span> <span>err</span> <span>!=</span> <span>nil</span> <span>||</span> <span>pos</span>.<span>IsEnd</span>() {
            <span>break</span>
        }
        <span>fmt</span>.<span>Printf</span>(<span>&#34;  Doc %d, Pos %d<span>\n</span>&#34;</span>,
            <span>int</span>(<span>pos</span>.<span>DocumentID</span>),
            <span>int</span>(<span>pos</span>.<span>Offset</span>))
    }
}</pre></div>
<p dir="auto"><strong>Output:</strong></p>
<div data-snippet-clipboard-copy-content="All occurrences of &#39;quick&#39;:
  Doc 1, Pos 0
  Doc 1, Pos 2
  Doc 1, Pos 4
  Doc 2, Pos 1"><pre><code>All occurrences of &#39;quick&#39;:
  Doc 1, Pos 0
  Doc 1, Pos 2
  Doc 1, Pos 4
  Doc 2, Pos 1
</code></pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">Example 4: Persistence with Serialization</h3><a id="user-content-example-4-persistence-with-serialization" aria-label="Permalink: Example 4: Persistence with Serialization" href="#example-4-persistence-with-serialization"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto" data-snippet-clipboard-copy-content="package main

import (
    &#34;fmt&#34;
    &#34;os&#34;
    &#34;github.com/wizenheimer/blaze&#34;
)

func main() {
    // Build and save index
    idx := blaze.NewInvertedIndex()
    idx.Index(1, &#34;machine learning algorithms&#34;)
    idx.Index(2, &#34;deep learning neural networks&#34;)
    idx.Index(3, &#34;natural language processing&#34;)

    // Serialize to binary
    data, err := idx.Encode()
    if err != nil {
        panic(err)
    }

    // Save to file
    err = os.WriteFile(&#34;search_index.bin&#34;, data, 0644)
    if err != nil {
        panic(err)
    }
    fmt.Println(&#34;Index saved to search_index.bin&#34;)

    // Load index from file
    loadedData, err := os.ReadFile(&#34;search_index.bin&#34;)
    if err != nil {
        panic(err)
    }

    loadedIdx := blaze.NewInvertedIndex()
    err = loadedIdx.Decode(loadedData)
    if err != nil {
        panic(err)
    }

    // Use loaded index
    results := loadedIdx.RankProximity(&#34;learning&#34;, 5)
    fmt.Printf(&#34;Found %d documents\n&#34;, len(results))
}"><pre><span>package</span> main

<span>import</span> (
    <span>&#34;fmt&#34;</span>
    <span>&#34;os&#34;</span>
    <span>&#34;github.com/wizenheimer/blaze&#34;</span>
)

<span>func</span> <span>main</span>() {
    <span>// Build and save index</span>
    <span>idx</span> <span>:=</span> <span>blaze</span>.<span>NewInvertedIndex</span>()
    <span>idx</span>.<span>Index</span>(<span>1</span>, <span>&#34;machine learning algorithms&#34;</span>)
    <span>idx</span>.<span>Index</span>(<span>2</span>, <span>&#34;deep learning neural networks&#34;</span>)
    <span>idx</span>.<span>Index</span>(<span>3</span>, <span>&#34;natural language processing&#34;</span>)

    <span>// Serialize to binary</span>
    <span>data</span>, <span>err</span> <span>:=</span> <span>idx</span>.<span>Encode</span>()
    <span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
        <span>panic</span>(<span>err</span>)
    }

    <span>// Save to file</span>
    <span>err</span> <span>=</span> <span>os</span>.<span>WriteFile</span>(<span>&#34;search_index.bin&#34;</span>, <span>data</span>, <span>0644</span>)
    <span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
        <span>panic</span>(<span>err</span>)
    }
    <span>fmt</span>.<span>Println</span>(<span>&#34;Index saved to search_index.bin&#34;</span>)

    <span>// Load index from file</span>
    <span>loadedData</span>, <span>err</span> <span>:=</span> <span>os</span>.<span>ReadFile</span>(<span>&#34;search_index.bin&#34;</span>)
    <span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
        <span>panic</span>(<span>err</span>)
    }

    <span>loadedIdx</span> <span>:=</span> <span>blaze</span>.<span>NewInvertedIndex</span>()
    <span>err</span> <span>=</span> <span>loadedIdx</span>.<span>Decode</span>(<span>loadedData</span>)
    <span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
        <span>panic</span>(<span>err</span>)
    }

    <span>// Use loaded index</span>
    <span>results</span> <span>:=</span> <span>loadedIdx</span>.<span>RankProximity</span>(<span>&#34;learning&#34;</span>, <span>5</span>)
    <span>fmt</span>.<span>Printf</span>(<span>&#34;Found %d documents<span>\n</span>&#34;</span>, <span>len</span>(<span>results</span>))
}</pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">Example 5: Custom Analyzer Configuration</h3><a id="user-content-example-5-custom-analyzer-configuration" aria-label="Permalink: Example 5: Custom Analyzer Configuration" href="#example-5-custom-analyzer-configuration"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto" data-snippet-clipboard-copy-content="package main

import (
    &#34;fmt&#34;
    &#34;github.com/wizenheimer/blaze&#34;
)

func main() {
    // Create custom analyzer config (no stemming, longer min length)
    config := blaze.AnalyzerConfig{
        MinTokenLength:  3,      // Minimum 3 characters
        EnableStemming:  false,  // Keep original word forms
        EnableStopwords: true,   // Still remove stopwords
    }

    text := &#34;The running dogs are running fast&#34;

    // Compare default vs custom analysis
    defaultTokens := blaze.Analyze(text)
    customTokens := blaze.AnalyzeWithConfig(text, config)

    fmt.Println(&#34;Default tokens:&#34;, defaultTokens)
    fmt.Println(&#34;Custom tokens:&#34;, customTokens)
}"><pre><span>package</span> main

<span>import</span> (
    <span>&#34;fmt&#34;</span>
    <span>&#34;github.com/wizenheimer/blaze&#34;</span>
)

<span>func</span> <span>main</span>() {
    <span>// Create custom analyzer config (no stemming, longer min length)</span>
    <span>config</span> <span>:=</span> blaze.<span>AnalyzerConfig</span>{
        <span>MinTokenLength</span>:  <span>3</span>,      <span>// Minimum 3 characters</span>
        <span>EnableStemming</span>:  <span>false</span>,  <span>// Keep original word forms</span>
        <span>EnableStopwords</span>: <span>true</span>,   <span>// Still remove stopwords</span>
    }

    <span>text</span> <span>:=</span> <span>&#34;The running dogs are running fast&#34;</span>

    <span>// Compare default vs custom analysis</span>
    <span>defaultTokens</span> <span>:=</span> <span>blaze</span>.<span>Analyze</span>(<span>text</span>)
    <span>customTokens</span> <span>:=</span> <span>blaze</span>.<span>AnalyzeWithConfig</span>(<span>text</span>, <span>config</span>)

    <span>fmt</span>.<span>Println</span>(<span>&#34;Default tokens:&#34;</span>, <span>defaultTokens</span>)
    <span>fmt</span>.<span>Println</span>(<span>&#34;Custom tokens:&#34;</span>, <span>customTokens</span>)
}</pre></div>
<p dir="auto"><strong>Output:</strong></p>
<div data-snippet-clipboard-copy-content="Default tokens: [run dog run fast]
Custom tokens: [running dogs running fast]"><pre><code>Default tokens: [run dog run fast]
Custom tokens: [running dogs running fast]
</code></pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">Example 6: Comparing BM25 and Proximity Ranking</h3><a id="user-content-example-6-comparing-bm25-and-proximity-ranking" aria-label="Permalink: Example 6: Comparing BM25 and Proximity Ranking" href="#example-6-comparing-bm25-and-proximity-ranking"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto" data-snippet-clipboard-copy-content="package main

import (
    &#34;fmt&#34;
    &#34;github.com/wizenheimer/blaze&#34;
)

func main() {
    idx := blaze.NewInvertedIndex()

    // Index documents
    idx.Index(1, &#34;machine learning algorithms&#34;)
    idx.Index(2, &#34;machine learning machine learning&#34;)  // High term frequency
    idx.Index(3, &#34;machine and algorithms and learning&#34;) // Terms far apart

    query := &#34;machine learning&#34;

    // BM25 Ranking
    fmt.Println(&#34;BM25 Rankings:&#34;)
    bm25Results := idx.RankBM25(query, 10)
    for i, match := range bm25Results {
        fmt.Printf(&#34;%d. Doc %d (score: %.3f)\n&#34;, i+1, match.DocID, match.Score)
    }

    // Proximity Ranking
    fmt.Println(&#34;\nProximity Rankings:&#34;)
    proxResults := idx.RankProximity(query, 10)
    for i, match := range proxResults {
        docID := int(match.Offsets[0].DocumentID)
        fmt.Printf(&#34;%d. Doc %d (score: %.3f)\n&#34;, i+1, docID, match.Score)
    }
}"><pre><span>package</span> main

<span>import</span> (
    <span>&#34;fmt&#34;</span>
    <span>&#34;github.com/wizenheimer/blaze&#34;</span>
)

<span>func</span> <span>main</span>() {
    <span>idx</span> <span>:=</span> <span>blaze</span>.<span>NewInvertedIndex</span>()

    <span>// Index documents</span>
    <span>idx</span>.<span>Index</span>(<span>1</span>, <span>&#34;machine learning algorithms&#34;</span>)
    <span>idx</span>.<span>Index</span>(<span>2</span>, <span>&#34;machine learning machine learning&#34;</span>)  <span>// High term frequency</span>
    <span>idx</span>.<span>Index</span>(<span>3</span>, <span>&#34;machine and algorithms and learning&#34;</span>) <span>// Terms far apart</span>

    <span>query</span> <span>:=</span> <span>&#34;machine learning&#34;</span>

    <span>// BM25 Ranking</span>
    <span>fmt</span>.<span>Println</span>(<span>&#34;BM25 Rankings:&#34;</span>)
    <span>bm25Results</span> <span>:=</span> <span>idx</span>.<span>RankBM25</span>(<span>query</span>, <span>10</span>)
    <span>for</span> <span>i</span>, <span>match</span> <span>:=</span> <span>range</span> <span>bm25Results</span> {
        <span>fmt</span>.<span>Printf</span>(<span>&#34;%d. Doc %d (score: %.3f)<span>\n</span>&#34;</span>, <span>i</span><span>+</span><span>1</span>, <span>match</span>.<span>DocID</span>, <span>match</span>.<span>Score</span>)
    }

    <span>// Proximity Ranking</span>
    <span>fmt</span>.<span>Println</span>(<span>&#34;<span>\n</span>Proximity Rankings:&#34;</span>)
    <span>proxResults</span> <span>:=</span> <span>idx</span>.<span>RankProximity</span>(<span>query</span>, <span>10</span>)
    <span>for</span> <span>i</span>, <span>match</span> <span>:=</span> <span>range</span> <span>proxResults</span> {
        <span>docID</span> <span>:=</span> <span>int</span>(<span>match</span>.<span>Offsets</span>[<span>0</span>].<span>DocumentID</span>)
        <span>fmt</span>.<span>Printf</span>(<span>&#34;%d. Doc %d (score: %.3f)<span>\n</span>&#34;</span>, <span>i</span><span>+</span><span>1</span>, <span>docID</span>, <span>match</span>.<span>Score</span>)
    }
}</pre></div>
<p dir="auto"><strong>Output:</strong></p>
<div data-snippet-clipboard-copy-content="BM25 Rankings:
1. Doc 2 (score: 5.234)  ← High term frequency
2. Doc 1 (score: 3.156)
3. Doc 3 (score: 2.891)

Proximity Rankings:
1. Doc 1 (score: 1.000)  ← Terms adjacent
2. Doc 2 (score: 1.000)
3. Doc 3 (score: 0.200)  ← Terms far apart"><pre><code>BM25 Rankings:
1. Doc 2 (score: 5.234)  ← High term frequency
2. Doc 1 (score: 3.156)
3. Doc 3 (score: 2.891)

Proximity Rankings:
1. Doc 1 (score: 1.000)  ← Terms adjacent
2. Doc 2 (score: 1.000)
3. Doc 3 (score: 0.200)  ← Terms far apart
</code></pre></div>
<p dir="auto"><strong>Key Differences:</strong></p>
<ul dir="auto">
<li><strong>BM25</strong> favors Doc 2 (repeated terms = high relevance)</li>
<li><strong>Proximity</strong> favors Doc 1 and Doc 2 equally (both have adjacent terms)</li>
<li>Doc 3 ranks low in both (terms spread out)</li>
</ul>
<div dir="auto"><h3 tabindex="-1" dir="auto">Example 7: Building a Simple Search Engine</h3><a id="user-content-example-7-building-a-simple-search-engine" aria-label="Permalink: Example 7: Building a Simple Search Engine" href="#example-7-building-a-simple-search-engine"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto" data-snippet-clipboard-copy-content="package main

import (
    &#34;bufio&#34;
    &#34;fmt&#34;
    &#34;os&#34;
    &#34;strings&#34;
    &#34;github.com/wizenheimer/blaze&#34;
)

func main() {
    // Create index
    idx := blaze.NewInvertedIndex()

    // Index some documents
    docs := map[int]string{
        1: &#34;Go is an open source programming language that makes it easy to build simple, reliable, and efficient software&#34;,
        2: &#34;Python is a programming language that lets you work quickly and integrate systems more effectively&#34;,
        3: &#34;JavaScript is a programming language that conforms to the ECMAScript specification&#34;,
        4: &#34;Rust is a multi-paradigm programming language focused on performance and safety&#34;,
        5: &#34;Java is a class-based, object-oriented programming language designed for portability&#34;,
    }

    for id, doc := range docs {
        idx.Index(id, doc)
    }

    // Interactive search
    scanner := bufio.NewScanner(os.Stdin)

    for {
        fmt.Print(&#34;\nSearch query (or &#39;quit&#39; to exit): &#34;)
        if !scanner.Scan() {
            break
        }

        query := strings.TrimSpace(scanner.Text())
        if query == &#34;quit&#34; {
            break
        }

        if query == &#34;&#34; {
            continue
        }

        // Perform search using BM25
        results := idx.RankBM25(query, 5)

        if len(results) == 0 {
            fmt.Println(&#34;No results found&#34;)
            continue
        }

        // Display results
        fmt.Printf(&#34;\nFound %d result(s):\n&#34;, len(results))
        for i, match := range results {
            fmt.Printf(&#34;\n%d. Document %d (Score: %.3f)\n&#34;, i+1, match.DocID, match.Score)
            fmt.Printf(&#34;   %s\n&#34;, docs[match.DocID])
        }
    }
}"><pre><span>package</span> main

<span>import</span> (
    <span>&#34;bufio&#34;</span>
    <span>&#34;fmt&#34;</span>
    <span>&#34;os&#34;</span>
    <span>&#34;strings&#34;</span>
    <span>&#34;github.com/wizenheimer/blaze&#34;</span>
)

<span>func</span> <span>main</span>() {
    <span>// Create index</span>
    <span>idx</span> <span>:=</span> <span>blaze</span>.<span>NewInvertedIndex</span>()

    <span>// Index some documents</span>
    <span>docs</span> <span>:=</span> <span>map</span>[<span>int</span>]<span>string</span>{
        <span>1</span>: <span>&#34;Go is an open source programming language that makes it easy to build simple, reliable, and efficient software&#34;</span>,
        <span>2</span>: <span>&#34;Python is a programming language that lets you work quickly and integrate systems more effectively&#34;</span>,
        <span>3</span>: <span>&#34;JavaScript is a programming language that conforms to the ECMAScript specification&#34;</span>,
        <span>4</span>: <span>&#34;Rust is a multi-paradigm programming language focused on performance and safety&#34;</span>,
        <span>5</span>: <span>&#34;Java is a class-based, object-oriented programming language designed for portability&#34;</span>,
    }

    <span>for</span> <span>id</span>, <span>doc</span> <span>:=</span> <span>range</span> <span>docs</span> {
        <span>idx</span>.<span>Index</span>(<span>id</span>, <span>doc</span>)
    }

    <span>// Interactive search</span>
    <span>scanner</span> <span>:=</span> <span>bufio</span>.<span>NewScanner</span>(<span>os</span>.<span>Stdin</span>)

    <span>for</span> {
        <span>fmt</span>.<span>Print</span>(<span>&#34;<span>\n</span>Search query (or &#39;quit&#39; to exit): &#34;</span>)
        <span>if</span> <span>!</span><span>scanner</span>.<span>Scan</span>() {
            <span>break</span>
        }

        <span>query</span> <span>:=</span> <span>strings</span>.<span>TrimSpace</span>(<span>scanner</span>.<span>Text</span>())
        <span>if</span> <span>query</span> <span>==</span> <span>&#34;quit&#34;</span> {
            <span>break</span>
        }

        <span>if</span> <span>query</span> <span>==</span> <span>&#34;&#34;</span> {
            <span>continue</span>
        }

        <span>// Perform search using BM25</span>
        <span>results</span> <span>:=</span> <span>idx</span>.<span>RankBM25</span>(<span>query</span>, <span>5</span>)

        <span>if</span> <span>len</span>(<span>results</span>) <span>==</span> <span>0</span> {
            <span>fmt</span>.<span>Println</span>(<span>&#34;No results found&#34;</span>)
            <span>continue</span>
        }

        <span>// Display results</span>
        <span>fmt</span>.<span>Printf</span>(<span>&#34;<span>\n</span>Found %d result(s):<span>\n</span>&#34;</span>, <span>len</span>(<span>results</span>))
        <span>for</span> <span>i</span>, <span>match</span> <span>:=</span> <span>range</span> <span>results</span> {
            <span>fmt</span>.<span>Printf</span>(<span>&#34;<span>\n</span>%d. Document %d (Score: %.3f)<span>\n</span>&#34;</span>, <span>i</span><span>+</span><span>1</span>, <span>match</span>.<span>DocID</span>, <span>match</span>.<span>Score</span>)
            <span>fmt</span>.<span>Printf</span>(<span>&#34;   %s<span>\n</span>&#34;</span>, <span>docs</span>[<span>match</span>.<span>DocID</span>])
        }
    }
}</pre></div>
<div dir="auto"><h2 tabindex="-1" dir="auto">Performance Characteristics</h2><a id="user-content-performance-characteristics" aria-label="Permalink: Performance Characteristics" href="#performance-characteristics"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>

<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Operation</th>
<th>Average</th>
<th>Worst Case</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td>Index (per document)</td>
<td>O(n × log m)</td>
<td>O(n × m)</td>
<td>n = tokens, m = total positions</td>
</tr>
<tr>
<td>Term lookup</td>
<td>O(log m)</td>
<td>O(m)</td>
<td>m = positions for term</td>
</tr>
<tr>
<td>Phrase search</td>
<td>O(k × log m)</td>
<td>O(k × m)</td>
<td>k = phrase length</td>
</tr>
<tr>
<td>BM25 ranking</td>
<td>O(t × d)</td>
<td>O(t × d)</td>
<td>t = query terms, d = candidates</td>
</tr>
<tr>
<td>Proximity ranking</td>
<td>O(t × m)</td>
<td>O(t × m)</td>
<td>t = query terms</td>
</tr>
<tr>
<td>Skip list insert</td>
<td>O(log n)</td>
<td>O(n)</td>
<td>n = elements in list</td>
</tr>
<tr>
<td>Skip list search</td>
<td>O(log n)</td>
<td>O(n)</td>
<td>Probabilistically rare</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>

<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Component</th>
<th>Space</th>
<th>Notes</th>
</tr>
</thead>
<tbody>
<tr>
<td>Inverted index</td>
<td>O(n)</td>
<td>n = total unique positions</td>
</tr>
<tr>
<td>Skip list nodes</td>
<td>O(n × log n)</td>
<td>Average 2 pointers per node</td>
</tr>
<tr>
<td>Analyzer</td>
<td>O(1)</td>
<td>In-place processing</td>
</tr>
<tr>
<td>Serialized index</td>
<td>O(n)</td>
<td>Compact binary format</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>

<p dir="auto">Performance on Apple M2 (8 cores), Go 1.24:</p>
<div data-snippet-clipboard-copy-content="BenchmarkIndex-8                     50000    35421 ns/op    18234 B/op    245 allocs/op
BenchmarkTermSearch-8              300000     4123 ns/op      128 B/op      3 allocs/op
BenchmarkPhraseSearch-8            100000    12456 ns/op      512 B/op     12 allocs/op
BenchmarkRankBM25-8                  60000    24567 ns/op     1856 B/op     38 allocs/op
BenchmarkProximityRanking-8         50000    28934 ns/op     2048 B/op     45 allocs/op
BenchmarkCalculateIDF-8           5000000      234 ns/op       16 B/op      1 allocs/op
BenchmarkCalculateBM25Score-8     2000000      567 ns/op       64 B/op      2 allocs/op
BenchmarkSkipListInsert-8         3000000      413 ns/op      255 B/op      6 allocs/op
BenchmarkSkipListSearch-8         5000000      203 ns/op       23 B/op      1 allocs/op
BenchmarkAnalyze-8                1000000     1234 ns/op      512 B/op      8 allocs/op
BenchmarkEncode-8                   10000   156789 ns/op    65536 B/op    234 allocs/op
BenchmarkDecode-8                   15000   123456 ns/op    49152 B/op    189 allocs/op"><pre><code>BenchmarkIndex-8                     50000    35421 ns/op    18234 B/op    245 allocs/op
BenchmarkTermSearch-8              300000     4123 ns/op      128 B/op      3 allocs/op
BenchmarkPhraseSearch-8            100000    12456 ns/op      512 B/op     12 allocs/op
BenchmarkRankBM25-8                  60000    24567 ns/op     1856 B/op     38 allocs/op
BenchmarkProximityRanking-8         50000    28934 ns/op     2048 B/op     45 allocs/op
BenchmarkCalculateIDF-8           5000000      234 ns/op       16 B/op      1 allocs/op
BenchmarkCalculateBM25Score-8     2000000      567 ns/op       64 B/op      2 allocs/op
BenchmarkSkipListInsert-8         3000000      413 ns/op      255 B/op      6 allocs/op
BenchmarkSkipListSearch-8         5000000      203 ns/op       23 B/op      1 allocs/op
BenchmarkAnalyze-8                1000000     1234 ns/op      512 B/op      8 allocs/op
BenchmarkEncode-8                   10000   156789 ns/op    65536 B/op    234 allocs/op
BenchmarkDecode-8                   15000   123456 ns/op    49152 B/op    189 allocs/op
</code></pre></div>

<p dir="auto"><strong>Index Size vs Performance:</strong></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Documents</th>
<th>Terms</th>
<th>Index Time</th>
<th>Search Time</th>
<th>Memory</th>
</tr>
</thead>
<tbody>
<tr>
<td>1K</td>
<td>10K</td>
<td>50ms</td>
<td>0.5ms</td>
<td>2 MB</td>
</tr>
<tr>
<td>10K</td>
<td>100K</td>
<td>500ms</td>
<td>1ms</td>
<td>20 MB</td>
</tr>
<tr>
<td>100K</td>
<td>1M</td>
<td>5s</td>
<td>2ms</td>
<td>200 MB</td>
</tr>
<tr>
<td>1M</td>
<td>10M</td>
<td>50s</td>
<td>5ms</td>
<td>2 GB</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><strong>Notes:</strong></p>
<ul dir="auto">
<li>Search time remains relatively constant due to O(log n) operations</li>
<li>Memory scales linearly with unique positions</li>
<li>Serialization reduces storage by ~40% compared to in-memory size</li>
</ul>


<p dir="auto">Customize BM25 ranking behavior:</p>
<div dir="auto" data-snippet-clipboard-copy-content="type BM25Parameters struct {
    K1 float64 // Term frequency saturation (default: 1.5)
    B  float64 // Length normalization (default: 0.75)
}"><pre><span>type</span> <span>BM25Parameters</span> <span>struct</span> {
    <span>K1</span> <span>float64</span> <span>// Term frequency saturation (default: 1.5)</span>
    <span>B</span>  <span>float64</span> <span>// Length normalization (default: 0.75)</span>
}</pre></div>
<p dir="auto"><strong>Tuning BM25:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="idx := blaze.NewInvertedIndex()

// Adjust BM25 parameters before indexing
idx.BM25Params.K1 = 2.0  // Higher = less saturation (more weight to TF)
idx.BM25Params.B = 0.5   // Lower = less length penalty

// Now index and search
idx.Index(1, &#34;document content&#34;)
results := idx.RankBM25(&#34;query&#34;, 10)"><pre><span>idx</span> <span>:=</span> <span>blaze</span>.<span>NewInvertedIndex</span>()

<span>// Adjust BM25 parameters before indexing</span>
<span>idx</span>.<span>BM25Params</span>.<span>K1</span> <span>=</span> <span>2.0</span>  <span>// Higher = less saturation (more weight to TF)</span>
<span>idx</span>.<span>BM25Params</span>.<span>B</span> <span>=</span> <span>0.5</span>   <span>// Lower = less length penalty</span>

<span>// Now index and search</span>
<span>idx</span>.<span>Index</span>(<span>1</span>, <span>&#34;document content&#34;</span>)
<span>results</span> <span>:=</span> <span>idx</span>.<span>RankBM25</span>(<span>&#34;query&#34;</span>, <span>10</span>)</pre></div>
<p dir="auto"><strong>Parameter Effects:</strong></p>
<markdown-accessiblity-table><table>
<thead>
<tr>
<th>Parameter</th>
<th>Range</th>
<th>Effect</th>
<th>When to Adjust</th>
</tr>
</thead>
<tbody>
<tr>
<td><strong>K1</strong></td>
<td>1.2 - 2.0</td>
<td>Controls TF saturation</td>
<td>Higher for domains where term frequency matters more</td>
</tr>
<tr>
<td><strong>B</strong></td>
<td>0 - 1</td>
<td>Controls length penalty</td>
<td>Lower for domains with naturally longer docs</td>
</tr>
</tbody>
</table></markdown-accessiblity-table>
<p dir="auto"><strong>Examples:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="// Academic papers (long documents, repeated terms important)
idx.BM25Params.K1 = 2.0
idx.BM25Params.B = 0.5

// Short messages (length less important)
idx.BM25Params.K1 = 1.2
idx.BM25Params.B = 0.3

// Default (works well for most cases)
idx.BM25Params.K1 = 1.5
idx.BM25Params.B = 0.75"><pre><span>// Academic papers (long documents, repeated terms important)</span>
<span>idx</span>.<span>BM25Params</span>.<span>K1</span> <span>=</span> <span>2.0</span>
<span>idx</span>.<span>BM25Params</span>.<span>B</span> <span>=</span> <span>0.5</span>

<span>// Short messages (length less important)</span>
<span>idx</span>.<span>BM25Params</span>.<span>K1</span> <span>=</span> <span>1.2</span>
<span>idx</span>.<span>BM25Params</span>.<span>B</span> <span>=</span> <span>0.3</span>

<span>// Default (works well for most cases)</span>
<span>idx</span>.<span>BM25Params</span>.<span>K1</span> <span>=</span> <span>1.5</span>
<span>idx</span>.<span>BM25Params</span>.<span>B</span> <span>=</span> <span>0.75</span></pre></div>
<p dir="auto"><strong>BM25 Statistics:</strong></p>
<p dir="auto">During indexing, Blaze automatically tracks:</p>
<div dir="auto" data-snippet-clipboard-copy-content="type DocumentStats struct {
    DocID     int            // Document identifier
    Length    int            // Number of terms
    TermFreqs map[string]int // Term frequencies
}

// Corpus-level statistics
idx.TotalDocs  // Total documents indexed
idx.TotalTerms // Total terms across all documents
idx.DocStats   // Per-document statistics"><pre><span>type</span> <span>DocumentStats</span> <span>struct</span> {
    <span>DocID</span>     <span>int</span>            <span>// Document identifier</span>
    <span>Length</span>    <span>int</span>            <span>// Number of terms</span>
    <span>TermFreqs</span> <span>map</span>[<span>string</span>]<span>int</span> <span>// Term frequencies</span>
}

<span>// Corpus-level statistics</span>
<span>idx</span>.<span>TotalDocs</span>  <span>// Total documents indexed</span>
<span>idx</span>.<span>TotalTerms</span> <span>// Total terms across all documents</span>
<span>idx</span>.<span>DocStats</span>   <span>// Per-document statistics</span></pre></div>
<p dir="auto">These statistics are:</p>
<ul dir="auto">
<li>Automatically computed during indexing</li>
<li>Serialized with the index</li>
<li>Used for BM25 score calculation</li>
</ul>

<p dir="auto">Customize the text analysis pipeline:</p>
<div dir="auto" data-snippet-clipboard-copy-content="type AnalyzerConfig struct {
    MinTokenLength  int  // Minimum token length (default: 2)
    EnableStemming  bool // Apply stemming (default: true)
    EnableStopwords bool // Remove stopwords (default: true)
}"><pre><span>type</span> <span>AnalyzerConfig</span> <span>struct</span> {
    <span>MinTokenLength</span>  <span>int</span>  <span>// Minimum token length (default: 2)</span>
    <span>EnableStemming</span>  <span>bool</span> <span>// Apply stemming (default: true)</span>
    <span>EnableStopwords</span> <span>bool</span> <span>// Remove stopwords (default: true)</span>
}</pre></div>
<p dir="auto"><strong>Configuration Examples:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="// Exact matching (no stemming, keep all words)
exactConfig := blaze.AnalyzerConfig{
    MinTokenLength:  1,
    EnableStemming:  false,
    EnableStopwords: false,
}

// Fuzzy matching (aggressive stemming)
fuzzyConfig := blaze.AnalyzerConfig{
    MinTokenLength:  2,
    EnableStemming:  true,
    EnableStopwords: true,
}

// Code search (no stemming, no stopwords, longer tokens)
codeConfig := blaze.AnalyzerConfig{
    MinTokenLength:  3,
    EnableStemming:  false,
    EnableStopwords: false,
}"><pre><span>// Exact matching (no stemming, keep all words)</span>
<span>exactConfig</span> <span>:=</span> blaze.<span>AnalyzerConfig</span>{
    <span>MinTokenLength</span>:  <span>1</span>,
    <span>EnableStemming</span>:  <span>false</span>,
    <span>EnableStopwords</span>: <span>false</span>,
}

<span>// Fuzzy matching (aggressive stemming)</span>
<span>fuzzyConfig</span> <span>:=</span> blaze.<span>AnalyzerConfig</span>{
    <span>MinTokenLength</span>:  <span>2</span>,
    <span>EnableStemming</span>:  <span>true</span>,
    <span>EnableStopwords</span>: <span>true</span>,
}

<span>// Code search (no stemming, no stopwords, longer tokens)</span>
<span>codeConfig</span> <span>:=</span> blaze.<span>AnalyzerConfig</span>{
    <span>MinTokenLength</span>:  <span>3</span>,
    <span>EnableStemming</span>:  <span>false</span>,
    <span>EnableStopwords</span>: <span>false</span>,
}</pre></div>

<p dir="auto"><strong>MinTokenLength:</strong></p>
<ul dir="auto">
<li><strong>1</strong>: Very permissive, large index</li>
<li><strong>2</strong>: Balanced (default), filters single chars</li>
<li><strong>3</strong>: Strict, smaller index, misses short words</li>
</ul>
<p dir="auto"><strong>EnableStemming:</strong></p>
<ul dir="auto">
<li><strong>true</strong>: Better recall, finds related words (&#34;run&#34; matches &#34;running&#34;)</li>
<li><strong>false</strong>: Exact matching, preserves original word forms</li>
</ul>
<p dir="auto"><strong>EnableStopwords:</strong></p>
<ul dir="auto">
<li><strong>true</strong>: Smaller index, faster search, standard behavior</li>
<li><strong>false</strong>: Complete indexing, useful for phrase search</li>
</ul>

<div dir="auto" data-snippet-clipboard-copy-content="const MaxHeight = 32  // Maximum tower height"><pre><span>const</span> <span>MaxHeight</span> <span>=</span> <span>32</span>  <span>// Maximum tower height</span></pre></div>
<p dir="auto"><strong>Tower Height Probability:</strong></p>
<ul dir="auto">
<li>Height 1: 50%</li>
<li>Height 2: 25%</li>
<li>Height 3: 12.5%</li>
<li>Height 4: 6.25%</li>
</ul>
<p dir="auto">This geometric distribution ensures O(log n) average performance.</p>

<div dir="auto"><h3 tabindex="-1" dir="auto">1. Document Search Systems</h3><a id="user-content-1-document-search-systems" aria-label="Permalink: 1. Document Search Systems" href="#1-document-search-systems"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Build a search engine for documents:</p>
<div dir="auto" data-snippet-clipboard-copy-content="type Document struct {
    ID      int
    Title   string
    Content string
}

func IndexDocuments(docs []Document) *blaze.InvertedIndex {
    idx := blaze.NewInvertedIndex()

    for _, doc := range docs {
        // Combine title and content
        text := doc.Title + &#34; &#34; + doc.Content
        idx.Index(doc.ID, text)
    }

    return idx
}

func SearchDocuments(idx *blaze.InvertedIndex, query string) []int {
    // Use BM25 for general relevance ranking (recommended)
    matches := idx.RankBM25(query, 20)

    docIDs := make([]int, len(matches))
    for i, match := range matches {
        docIDs[i] = match.DocID
    }

    return docIDs
}

// Alternative: Use proximity ranking to find documents with close term matches
func SearchDocumentsByProximity(idx *blaze.InvertedIndex, query string) []int {
    matches := idx.RankProximity(query, 20)

    docIDs := make([]int, len(matches))
    for i, match := range matches {
        docIDs[i] = int(match.Offsets[0].DocumentID)
    }

    return docIDs
}"><pre><span>type</span> <span>Document</span> <span>struct</span> {
    <span>ID</span>      <span>int</span>
    <span>Title</span>   <span>string</span>
    <span>Content</span> <span>string</span>
}

<span>func</span> <span>IndexDocuments</span>(<span>docs</span> []<span>Document</span>) <span>*</span>blaze.<span>InvertedIndex</span> {
    <span>idx</span> <span>:=</span> <span>blaze</span>.<span>NewInvertedIndex</span>()

    <span>for</span> <span>_</span>, <span>doc</span> <span>:=</span> <span>range</span> <span>docs</span> {
        <span>// Combine title and content</span>
        <span>text</span> <span>:=</span> <span>doc</span>.<span>Title</span> <span>+</span> <span>&#34; &#34;</span> <span>+</span> <span>doc</span>.<span>Content</span>
        <span>idx</span>.<span>Index</span>(<span>doc</span>.<span>ID</span>, <span>text</span>)
    }

    <span>return</span> <span>idx</span>
}

<span>func</span> <span>SearchDocuments</span>(<span>idx</span> <span>*</span>blaze.<span>InvertedIndex</span>, <span>query</span> <span>string</span>) []<span>int</span> {
    <span>// Use BM25 for general relevance ranking (recommended)</span>
    <span>matches</span> <span>:=</span> <span>idx</span>.<span>RankBM25</span>(<span>query</span>, <span>20</span>)

    <span>docIDs</span> <span>:=</span> <span>make</span>([]<span>int</span>, <span>len</span>(<span>matches</span>))
    <span>for</span> <span>i</span>, <span>match</span> <span>:=</span> <span>range</span> <span>matches</span> {
        <span>docIDs</span>[<span>i</span>] <span>=</span> <span>match</span>.<span>DocID</span>
    }

    <span>return</span> <span>docIDs</span>
}

<span>// Alternative: Use proximity ranking to find documents with close term matches</span>
<span>func</span> <span>SearchDocumentsByProximity</span>(<span>idx</span> <span>*</span>blaze.<span>InvertedIndex</span>, <span>query</span> <span>string</span>) []<span>int</span> {
    <span>matches</span> <span>:=</span> <span>idx</span>.<span>RankProximity</span>(<span>query</span>, <span>20</span>)

    <span>docIDs</span> <span>:=</span> <span>make</span>([]<span>int</span>, <span>len</span>(<span>matches</span>))
    <span>for</span> <span>i</span>, <span>match</span> <span>:=</span> <span>range</span> <span>matches</span> {
        <span>docIDs</span>[<span>i</span>] <span>=</span> <span>int</span>(<span>match</span>.<span>Offsets</span>[<span>0</span>].<span>DocumentID</span>)
    }

    <span>return</span> <span>docIDs</span>
}</pre></div>

<p dir="auto">Search through log files:</p>
<div dir="auto" data-snippet-clipboard-copy-content="func IndexLogs(logFile string) (*blaze.InvertedIndex, error) {
    idx := blaze.NewInvertedIndex()

    file, err := os.Open(logFile)
    if err != nil {
        return nil, err
    }
    defer file.Close()

    scanner := bufio.NewScanner(file)
    lineNumber := 1

    for scanner.Scan() {
        idx.Index(lineNumber, scanner.Text())
        lineNumber++
    }

    return idx, scanner.Err()
}

// Find all ERROR log lines using BM25 (considers frequency and rarity)
errorLogs := idx.RankBM25(&#34;ERROR&#34;, 100)

// Alternative: Use proximity for finding error patterns
// e.g., &#34;connection timeout&#34; appearing close together
patternMatches := idx.RankProximity(&#34;connection timeout&#34;, 50)"><pre><span>func</span> <span>IndexLogs</span>(<span>logFile</span> <span>string</span>) (<span>*</span>blaze.<span>InvertedIndex</span>, <span>error</span>) {
    <span>idx</span> <span>:=</span> <span>blaze</span>.<span>NewInvertedIndex</span>()

    <span>file</span>, <span>err</span> <span>:=</span> <span>os</span>.<span>Open</span>(<span>logFile</span>)
    <span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
        <span>return</span> <span>nil</span>, <span>err</span>
    }
    <span>defer</span> <span>file</span>.<span>Close</span>()

    <span>scanner</span> <span>:=</span> <span>bufio</span>.<span>NewScanner</span>(<span>file</span>)
    <span>lineNumber</span> <span>:=</span> <span>1</span>

    <span>for</span> <span>scanner</span>.<span>Scan</span>() {
        <span>idx</span>.<span>Index</span>(<span>lineNumber</span>, <span>scanner</span>.<span>Text</span>())
        <span>lineNumber</span><span>++</span>
    }

    <span>return</span> <span>idx</span>, <span>scanner</span>.<span>Err</span>()
}

<span>// Find all ERROR log lines using BM25 (considers frequency and rarity)</span>
<span>errorLogs</span> <span>:=</span> <span>idx</span>.<span>RankBM25</span>(<span>&#34;ERROR&#34;</span>, <span>100</span>)

<span>// Alternative: Use proximity for finding error patterns</span>
<span>// e.g., &#34;connection timeout&#34; appearing close together</span>
<span>patternMatches</span> <span>:=</span> <span>idx</span>.<span>RankProximity</span>(<span>&#34;connection timeout&#34;</span>, <span>50</span>)</pre></div>

<p dir="auto">Search through source code:</p>
<div dir="auto" data-snippet-clipboard-copy-content="func IndexCodebase(rootDir string) (*blaze.InvertedIndex, error) {
    idx := blaze.NewInvertedIndex()
    fileID := 1

    // Custom config for code (no stemming, keep all words)
    config := blaze.AnalyzerConfig{
        MinTokenLength:  2,
        EnableStemming:  false,
        EnableStopwords: false,
    }

    err := filepath.Walk(rootDir, func(path string, info os.FileInfo, err error) error {
        if err != nil || info.IsDir() {
            return err
        }

        // Only index Go files
        if !strings.HasSuffix(path, &#34;.go&#34;) {
            return nil
        }

        content, err := os.ReadFile(path)
        if err != nil {
            return err
        }

        // Use custom analyzer
        tokens := blaze.AnalyzeWithConfig(string(content), config)
        // ... index tokens ...

        fileID++
        return nil
    })

    return idx, err
}

// BM25: Find files with frequent mentions of a function/variable
bm25Results := idx.RankBM25(&#34;http.Handler&#34;, 20)

// Proximity: Find exact API patterns (e.g., function calls with parameters)
// Better for finding &#34;http.HandleFunc&#34; as a specific pattern
proximityResults := idx.RankProximity(&#34;http HandleFunc&#34;, 20)"><pre><span>func</span> <span>IndexCodebase</span>(<span>rootDir</span> <span>string</span>) (<span>*</span>blaze.<span>InvertedIndex</span>, <span>error</span>) {
    <span>idx</span> <span>:=</span> <span>blaze</span>.<span>NewInvertedIndex</span>()
    <span>fileID</span> <span>:=</span> <span>1</span>

    <span>// Custom config for code (no stemming, keep all words)</span>
    <span>config</span> <span>:=</span> blaze.<span>AnalyzerConfig</span>{
        <span>MinTokenLength</span>:  <span>2</span>,
        <span>EnableStemming</span>:  <span>false</span>,
        <span>EnableStopwords</span>: <span>false</span>,
    }

    <span>err</span> <span>:=</span> <span>filepath</span>.<span>Walk</span>(<span>rootDir</span>, <span>func</span>(<span>path</span> <span>string</span>, <span>info</span> os.<span>FileInfo</span>, <span>err</span> <span>error</span>) <span>error</span> {
        <span>if</span> <span>err</span> <span>!=</span> <span>nil</span> <span>||</span> <span>info</span>.<span>IsDir</span>() {
            <span>return</span> <span>err</span>
        }

        <span>// Only index Go files</span>
        <span>if</span> <span>!</span><span>strings</span>.<span>HasSuffix</span>(<span>path</span>, <span>&#34;.go&#34;</span>) {
            <span>return</span> <span>nil</span>
        }

        <span>content</span>, <span>err</span> <span>:=</span> <span>os</span>.<span>ReadFile</span>(<span>path</span>)
        <span>if</span> <span>err</span> <span>!=</span> <span>nil</span> {
            <span>return</span> <span>err</span>
        }

        <span>// Use custom analyzer</span>
        <span>tokens</span> <span>:=</span> <span>blaze</span>.<span>AnalyzeWithConfig</span>(<span>string</span>(<span>content</span>), <span>config</span>)
        <span>// ... index tokens ...</span>

        <span>fileID</span><span>++</span>
        <span>return</span> <span>nil</span>
    })

    <span>return</span> <span>idx</span>, <span>err</span>
}

<span>// BM25: Find files with frequent mentions of a function/variable</span>
<span>bm25Results</span> <span>:=</span> <span>idx</span>.<span>RankBM25</span>(<span>&#34;http.Handler&#34;</span>, <span>20</span>)

<span>// Proximity: Find exact API patterns (e.g., function calls with parameters)</span>
<span>// Better for finding &#34;http.HandleFunc&#34; as a specific pattern</span>
<span>proximityResults</span> <span>:=</span> <span>idx</span>.<span>RankProximity</span>(<span>&#34;http HandleFunc&#34;</span>, <span>20</span>)</pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">4. E-commerce Product Search</h3><a id="user-content-4-e-commerce-product-search" aria-label="Permalink: 4. E-commerce Product Search" href="#4-e-commerce-product-search"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Search product catalog:</p>
<div dir="auto" data-snippet-clipboard-copy-content="type Product struct {
    ID          int
    Name        string
    Description string
    Category    string
    Tags        []string
}

func IndexProducts(products []Product) *blaze.InvertedIndex {
    idx := blaze.NewInvertedIndex()

    for _, product := range products {
        // Combine all searchable fields
        searchText := fmt.Sprintf(&#34;%s %s %s %s&#34;,
            product.Name,
            product.Description,
            product.Category,
            strings.Join(product.Tags, &#34; &#34;))

        idx.Index(product.ID, searchText)
    }

    return idx
}

// BM25: Best for general product search (considers all factors)
results := idx.RankBM25(&#34;wireless headphones&#34;, 10)

// Proximity: Good for finding exact product name matches
// (e.g., &#34;Sony WH-1000XM4&#34; as an exact phrase proximity)
exactMatches := idx.RankProximity(&#34;wireless headphones&#34;, 10)"><pre><span>type</span> <span>Product</span> <span>struct</span> {
    <span>ID</span>          <span>int</span>
    <span>Name</span>        <span>string</span>
    <span>Description</span> <span>string</span>
    <span>Category</span>    <span>string</span>
    <span>Tags</span>        []<span>string</span>
}

<span>func</span> <span>IndexProducts</span>(<span>products</span> []<span>Product</span>) <span>*</span>blaze.<span>InvertedIndex</span> {
    <span>idx</span> <span>:=</span> <span>blaze</span>.<span>NewInvertedIndex</span>()

    <span>for</span> <span>_</span>, <span>product</span> <span>:=</span> <span>range</span> <span>products</span> {
        <span>// Combine all searchable fields</span>
        <span>searchText</span> <span>:=</span> <span>fmt</span>.<span>Sprintf</span>(<span>&#34;%s %s %s %s&#34;</span>,
            <span>product</span>.<span>Name</span>,
            <span>product</span>.<span>Description</span>,
            <span>product</span>.<span>Category</span>,
            <span>strings</span>.<span>Join</span>(<span>product</span>.<span>Tags</span>, <span>&#34; &#34;</span>))

        <span>idx</span>.<span>Index</span>(<span>product</span>.<span>ID</span>, <span>searchText</span>)
    }

    <span>return</span> <span>idx</span>
}

<span>// BM25: Best for general product search (considers all factors)</span>
<span>results</span> <span>:=</span> <span>idx</span>.<span>RankBM25</span>(<span>&#34;wireless headphones&#34;</span>, <span>10</span>)

<span>// Proximity: Good for finding exact product name matches</span>
<span>// (e.g., &#34;Sony WH-1000XM4&#34; as an exact phrase proximity)</span>
<span>exactMatches</span> <span>:=</span> <span>idx</span>.<span>RankProximity</span>(<span>&#34;wireless headphones&#34;</span>, <span>10</span>)</pre></div>

<p dir="auto">Index and search email messages:</p>
<div dir="auto" data-snippet-clipboard-copy-content="type Email struct {
    ID      int
    From    string
    Subject string
    Body    string
}

func IndexEmails(emails []Email) *blaze.InvertedIndex {
    idx := blaze.NewInvertedIndex()

    for _, email := range emails {
        searchText := fmt.Sprintf(&#34;%s %s %s&#34;,
            email.From,
            email.Subject,
            email.Body)

        idx.Index(email.ID, searchText)
    }

    return idx
}

// BM25: Find emails where terms appear frequently (general search)
matches := idx.RankBM25(&#34;project deadline&#34;, 50)

// Proximity: Find emails where &#34;project&#34; and &#34;deadline&#34; appear close together
// (more precise, better for finding specific mentions)
closeMatches := idx.RankProximity(&#34;project deadline&#34;, 50)"><pre><span>type</span> <span>Email</span> <span>struct</span> {
    <span>ID</span>      <span>int</span>
    <span>From</span>    <span>string</span>
    <span>Subject</span> <span>string</span>
    <span>Body</span>    <span>string</span>
}

<span>func</span> <span>IndexEmails</span>(<span>emails</span> []<span>Email</span>) <span>*</span>blaze.<span>InvertedIndex</span> {
    <span>idx</span> <span>:=</span> <span>blaze</span>.<span>NewInvertedIndex</span>()

    <span>for</span> <span>_</span>, <span>email</span> <span>:=</span> <span>range</span> <span>emails</span> {
        <span>searchText</span> <span>:=</span> <span>fmt</span>.<span>Sprintf</span>(<span>&#34;%s %s %s&#34;</span>,
            <span>email</span>.<span>From</span>,
            <span>email</span>.<span>Subject</span>,
            <span>email</span>.<span>Body</span>)

        <span>idx</span>.<span>Index</span>(<span>email</span>.<span>ID</span>, <span>searchText</span>)
    }

    <span>return</span> <span>idx</span>
}

<span>// BM25: Find emails where terms appear frequently (general search)</span>
<span>matches</span> <span>:=</span> <span>idx</span>.<span>RankBM25</span>(<span>&#34;project deadline&#34;</span>, <span>50</span>)

<span>// Proximity: Find emails where &#34;project&#34; and &#34;deadline&#34; appear close together</span>
<span>// (more precise, better for finding specific mentions)</span>
<span>closeMatches</span> <span>:=</span> <span>idx</span>.<span>RankProximity</span>(<span>&#34;project deadline&#34;</span>, <span>50</span>)</pre></div>


<div dir="auto" data-snippet-clipboard-copy-content="# Run all tests
make test

# Run tests with coverage
make test-coverage

# Run benchmarks
make bench

# Run all checks (format, vet, lint, test)
make check"><pre><span><span>#</span> Run all tests</span>
make <span>test</span>

<span><span>#</span> Run tests with coverage</span>
make test-coverage

<span><span>#</span> Run benchmarks</span>
make bench

<span><span>#</span> Run all checks (format, vet, lint, test)</span>
make check</pre></div>

<p dir="auto">The library has comprehensive test coverage:</p>
<div dir="auto" data-snippet-clipboard-copy-content="$ make test-coverage
Running tests...
ok      github.com/wizenheimer/blaze    2.456s  coverage: 98.5% of statements
Generating coverage report...
Coverage report: coverage.html"><pre>$ make test-coverage
Running tests...
ok      github.com/wizenheimer/blaze    2.456s  coverage: 98.5% of statements
Generating coverage report...
Coverage report: coverage.html</pre></div>
<p dir="auto"><strong>Coverage by Component:</strong></p>
<ul dir="auto">
<li>Inverted Index: 100%</li>
<li>Skip Lists: 100%</li>
<li>Text Analysis: 100%</li>
<li>Search Operations: 100%</li>
<li>BM25 Ranking: 100%</li>
<li>Serialization: 100%</li>
</ul>

<p dir="auto">Example test:</p>
<div dir="auto" data-snippet-clipboard-copy-content="func TestSearchFunctionality(t *testing.T) {
    idx := blaze.NewInvertedIndex()

    // Index test documents
    idx.Index(1, &#34;the quick brown fox&#34;)
    idx.Index(2, &#34;the lazy brown dog&#34;)

    // Test phrase search
    matches := idx.FindAllPhrases(&#34;brown fox&#34;, blaze.BOFDocument)

    if len(matches) != 1 {
        t.Errorf(&#34;Expected 1 match, got %d&#34;, len(matches))
    }

    if int(matches[0][0].DocumentID) != 1 {
        t.Errorf(&#34;Expected document 1, got %d&#34;, int(matches[0][0].DocumentID))
    }
}"><pre><span>func</span> <span>TestSearchFunctionality</span>(<span>t</span> <span>*</span>testing.<span>T</span>) {
    <span>idx</span> <span>:=</span> <span>blaze</span>.<span>NewInvertedIndex</span>()

    <span>// Index test documents</span>
    <span>idx</span>.<span>Index</span>(<span>1</span>, <span>&#34;the quick brown fox&#34;</span>)
    <span>idx</span>.<span>Index</span>(<span>2</span>, <span>&#34;the lazy brown dog&#34;</span>)

    <span>// Test phrase search</span>
    <span>matches</span> <span>:=</span> <span>idx</span>.<span>FindAllPhrases</span>(<span>&#34;brown fox&#34;</span>, <span>blaze</span>.<span>BOFDocument</span>)

    <span>if</span> <span>len</span>(<span>matches</span>) <span>!=</span> <span>1</span> {
        <span>t</span>.<span>Errorf</span>(<span>&#34;Expected 1 match, got %d&#34;</span>, <span>len</span>(<span>matches</span>))
    }

    <span>if</span> <span>int</span>(<span>matches</span>[<span>0</span>][<span>0</span>].<span>DocumentID</span>) <span>!=</span> <span>1</span> {
        <span>t</span>.<span>Errorf</span>(<span>&#34;Expected document 1, got %d&#34;</span>, <span>int</span>(<span>matches</span>[<span>0</span>][<span>0</span>].<span>DocumentID</span>))
    }
}</pre></div>


<div data-snippet-clipboard-copy-content="blaze/
├── index.go          # Inverted index implementation with hybrid storage
├── query.go          # Query builder with roaring bitmaps
├── skiplist.go       # Skip list data structure for positions
├── search.go         # Search algorithms (phrase, proximity, BM25)
├── analyzer.go       # Text analysis pipeline
├── serialization.go  # Binary encoding/decoding (skip lists + bitmaps)
├── *_test.go         # Comprehensive test suite
├── Makefile          # Development commands
└── public/           # Documentation website
    └── index.html"><pre><code>blaze/
├── index.go          # Inverted index implementation with hybrid storage
├── query.go          # Query builder with roaring bitmaps
├── skiplist.go       # Skip list data structure for positions
├── search.go         # Search algorithms (phrase, proximity, BM25)
├── analyzer.go       # Text analysis pipeline
├── serialization.go  # Binary encoding/decoding (skip lists + bitmaps)
├── *_test.go         # Comprehensive test suite
├── Makefile          # Development commands
└── public/           # Documentation website
    └── index.html
</code></pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">Query Processor Architecture</h3><a id="user-content-query-processor-architecture" aria-label="Permalink: Query Processor Architecture" href="#query-processor-architecture"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">The query processor uses a hybrid storage approach combining roaring bitmaps for document-level operations and skip lists for position-level operations.</p>
<div data-snippet-clipboard-copy-content="┌─────────────────────────────────────────────────────────────────────────┐
│                      QUERY PROCESSOR ARCHITECTURE                        │
└─────────────────────────────────────────────────────────────────────────┘

                              User Query
                          &#34;machine AND learning&#34;
                                  │
                                  ▼
                    ┌─────────────────────────────┐
                    │    Text Analyzer            │
                    │  (tokenize, stem, etc.)     │
                    └──────────────┬──────────────┘
                                  │
                    [&#34;machine&#34;, &#34;learning&#34;]
                                  │
                                  ▼
                    ┌─────────────────────────────┐
                    │     Query Builder           │
                    │  (constructs query tree)    │
                    └──────────────┬──────────────┘
                                  │
                    Query Tree: AND(machine, learning)
                                  │
            ┌─────────────────────┼─────────────────────┐
            │                     │                     │
            ▼                     ▼                     ▼
    ┌───────────────┐    ┌───────────────┐    ┌───────────────┐
    │  Bitmap Ops   │    │  Skip List    │    │  BM25 Scorer  │
    │  (fast AND/OR)│    │  (positions)  │    │  (ranking)    │
    └───────┬───────┘    └───────┬───────┘    └───────┬───────┘
            │                     │                     │
            └─────────────────────┼─────────────────────┘
                                  │
                                  ▼
                          ┌───────────────┐
                          │    Results    │
                          │  (ranked docs)│
                          └───────────────┘"><pre><code>┌─────────────────────────────────────────────────────────────────────────┐
│                      QUERY PROCESSOR ARCHITECTURE                        │
└─────────────────────────────────────────────────────────────────────────┘

                              User Query
                          &#34;machine AND learning&#34;
                                  │
                                  ▼
                    ┌─────────────────────────────┐
                    │    Text Analyzer            │
                    │  (tokenize, stem, etc.)     │
                    └──────────────┬──────────────┘
                                  │
                    [&#34;machine&#34;, &#34;learning&#34;]
                                  │
                                  ▼
                    ┌─────────────────────────────┐
                    │     Query Builder           │
                    │  (constructs query tree)    │
                    └──────────────┬──────────────┘
                                  │
                    Query Tree: AND(machine, learning)
                                  │
            ┌─────────────────────┼─────────────────────┐
            │                     │                     │
            ▼                     ▼                     ▼
    ┌───────────────┐    ┌───────────────┐    ┌───────────────┐
    │  Bitmap Ops   │    │  Skip List    │    │  BM25 Scorer  │
    │  (fast AND/OR)│    │  (positions)  │    │  (ranking)    │
    └───────┬───────┘    └───────┬───────┘    └───────┬───────┘
            │                     │                     │
            └─────────────────────┼─────────────────────┘
                                  │
                                  ▼
                          ┌───────────────┐
                          │    Results    │
                          │  (ranked docs)│
                          └───────────────┘
</code></pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">Hybrid Storage Architecture</h3><a id="user-content-hybrid-storage-architecture" aria-label="Permalink: Hybrid Storage Architecture" href="#hybrid-storage-architecture"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Blaze uses a sophisticated hybrid storage model:</p>
<div data-snippet-clipboard-copy-content="┌─────────────────────────────────────────────────────────────────────────┐
│                        HYBRID STORAGE MODEL                              │
└─────────────────────────────────────────────────────────────────────────┘

For each term &#34;machine&#34;:

┌─────────────────────────────────────────────────────────────────────────┐
│  DOCUMENT LEVEL (Roaring Bitmap)                                        │
│  ────────────────────────────────────────────────────────────────────── │
│                                                                           │
│  DocBitmaps[&#34;machine&#34;] = {1, 2, 4, 5, 100, 500, 1000, ...}             │
│                                                                           │
│  Compressed representation of ALL documents containing &#34;machine&#34;         │
│  Use: Fast boolean operations (AND, OR, NOT)                            │
│  Size: ~60 KB for 500k documents (400x compression!)                    │
│                                                                           │
└─────────────────────────────────────────────────────────────────────────┘
                                  │
                                  │ Links to
                                  ▼
┌─────────────────────────────────────────────────────────────────────────┐
│  POSITION LEVEL (Skip List)                                             │
│  ────────────────────────────────────────────────────────────────────── │
│                                                                           │
│  PostingsList[&#34;machine&#34;] = SkipList:                                    │
│                                                                           │
│    Level 2: [Doc1:Pos5] ────────────────────────&gt; [Doc100:Pos12]       │
│                 │                                       │                │
│    Level 1: [Doc1:Pos5] ──&gt; [Doc2:Pos3] ───────────&gt; [Doc100:Pos12]   │
│                 │              │                         │               │
│    Level 0: [Doc1:Pos5] -&gt; [Doc2:Pos3] -&gt; [Doc4:Pos1] -&gt; [Doc5:Pos7]  │
│             -&gt; [Doc100:Pos12] -&gt; [Doc500:Pos2] -&gt; ...                  │
│                                                                           │
│  Detailed position information for EVERY occurrence                      │
│  Use: Phrase search, proximity ranking, snippets                        │
│  Size: ~24 MB for 500k positions                                        │
│                                                                           │
└─────────────────────────────────────────────────────────────────────────┘

WHY HYBRID?
───────────
1. Bitmaps: Lightning-fast document filtering (AND, OR, NOT in microseconds)
2. Skip Lists: Precise position tracking for phrases and proximity
3. Best of both worlds: Speed + Precision"><pre><code>┌─────────────────────────────────────────────────────────────────────────┐
│                        HYBRID STORAGE MODEL                              │
└─────────────────────────────────────────────────────────────────────────┘

For each term &#34;machine&#34;:

┌─────────────────────────────────────────────────────────────────────────┐
│  DOCUMENT LEVEL (Roaring Bitmap)                                        │
│  ────────────────────────────────────────────────────────────────────── │
│                                                                           │
│  DocBitmaps[&#34;machine&#34;] = {1, 2, 4, 5, 100, 500, 1000, ...}             │
│                                                                           │
│  Compressed representation of ALL documents containing &#34;machine&#34;         │
│  Use: Fast boolean operations (AND, OR, NOT)                            │
│  Size: ~60 KB for 500k documents (400x compression!)                    │
│                                                                           │
└─────────────────────────────────────────────────────────────────────────┘
                                  │
                                  │ Links to
                                  ▼
┌─────────────────────────────────────────────────────────────────────────┐
│  POSITION LEVEL (Skip List)                                             │
│  ────────────────────────────────────────────────────────────────────── │
│                                                                           │
│  PostingsList[&#34;machine&#34;] = SkipList:                                    │
│                                                                           │
│    Level 2: [Doc1:Pos5] ────────────────────────&gt; [Doc100:Pos12]       │
│                 │                                       │                │
│    Level 1: [Doc1:Pos5] ──&gt; [Doc2:Pos3] ───────────&gt; [Doc100:Pos12]   │
│                 │              │                         │               │
│    Level 0: [Doc1:Pos5] -&gt; [Doc2:Pos3] -&gt; [Doc4:Pos1] -&gt; [Doc5:Pos7]  │
│             -&gt; [Doc100:Pos12] -&gt; [Doc500:Pos2] -&gt; ...                  │
│                                                                           │
│  Detailed position information for EVERY occurrence                      │
│  Use: Phrase search, proximity ranking, snippets                        │
│  Size: ~24 MB for 500k positions                                        │
│                                                                           │
└─────────────────────────────────────────────────────────────────────────┘

WHY HYBRID?
───────────
1. Bitmaps: Lightning-fast document filtering (AND, OR, NOT in microseconds)
2. Skip Lists: Precise position tracking for phrases and proximity
3. Best of both worlds: Speed + Precision
</code></pre></div>

<p dir="auto">Here&#39;s how a complex query executes step-by-step:</p>
<div data-snippet-clipboard-copy-content="QUERY: (machine OR deep) AND learning AND NOT neural

┌─────────────────────────────────────────────────────────────────────────┐
│  STEP 1: BITMAP PHASE (Fast Document Filtering)                         │
└─────────────────────────────────────────────────────────────────────────┘

Term Lookups (O(1) hash map):
    DocBitmaps[&#34;machine&#34;] = {1, 2, 4, 5, 7, 8, 9, 10}
    DocBitmaps[&#34;deep&#34;]    = {2, 3, 5, 6, 8, 9}
    DocBitmaps[&#34;learning&#34;]= {1, 2, 4, 5, 6, 7, 8, 9, 10}
    DocBitmaps[&#34;neural&#34;]  = {3, 6, 8, 9}

Boolean Operations (O(1) per chunk):
    Step 1: machine OR deep
            {1, 2, 4, 5, 7, 8, 9, 10} ∪ {2, 3, 5, 6, 8, 9}
          = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10}

    Step 2: (machine OR deep) AND learning
            {1, 2, 3, 4, 5, 6, 7, 8, 9, 10} ∩ {1, 2, 4, 5, 6, 7, 8, 9, 10}
          = {1, 2, 4, 5, 6, 7, 8, 9, 10}

    Step 3: Result AND NOT neural
            {1, 2, 4, 5, 6, 7, 8, 9, 10} \ {3, 6, 8, 9}
          = {1, 2, 4, 5, 7, 10}  ← CANDIDATE DOCUMENTS

    Time: ~10 microseconds for 1M documents!

┌─────────────────────────────────────────────────────────────────────────┐
│  STEP 2: POSITION PHASE (Optional - for phrases/proximity)              │
└─────────────────────────────────────────────────────────────────────────┘

IF phrase search needed:
    For each candidate doc {1, 2, 4, 5, 7, 10}:
        Use skip lists to verify exact positions
        Check consecutive positions for phrases
        Extract position data for snippets

    Time: O(log n) per position lookup

┌─────────────────────────────────────────────────────────────────────────┐
│  STEP 3: RANKING PHASE (BM25 Scoring)                                   │
└─────────────────────────────────────────────────────────────────────────┘

For each candidate document:
    1. Calculate IDF (Inverse Document Frequency):
       - Uses bitmap cardinality for instant document counts
       - IDF(&#34;machine&#34;) = log((N - df + 0.5) / (df + 0.5))
       - df = DocBitmaps[&#34;machine&#34;].GetCardinality()

    2. Calculate TF (Term Frequency):
       - Retrieves from pre-computed DocStats
       - TF(&#34;machine&#34;, Doc1) = termFreqs[&#34;machine&#34;]

    3. Apply BM25 formula:
       - Combines IDF, TF, and length normalization
       - Score = IDF × (TF × (k1 + 1)) / (TF + k1 × length_norm)

    4. Sum scores for all query terms

Results sorted by score:
    Doc 5: 8.45
    Doc 2: 7.23
    Doc 1: 6.91
    ...

    Time: O(candidates × terms)"><pre><code>QUERY: (machine OR deep) AND learning AND NOT neural

┌─────────────────────────────────────────────────────────────────────────┐
│  STEP 1: BITMAP PHASE (Fast Document Filtering)                         │
└─────────────────────────────────────────────────────────────────────────┘

Term Lookups (O(1) hash map):
    DocBitmaps[&#34;machine&#34;] = {1, 2, 4, 5, 7, 8, 9, 10}
    DocBitmaps[&#34;deep&#34;]    = {2, 3, 5, 6, 8, 9}
    DocBitmaps[&#34;learning&#34;]= {1, 2, 4, 5, 6, 7, 8, 9, 10}
    DocBitmaps[&#34;neural&#34;]  = {3, 6, 8, 9}

Boolean Operations (O(1) per chunk):
    Step 1: machine OR deep
            {1, 2, 4, 5, 7, 8, 9, 10} ∪ {2, 3, 5, 6, 8, 9}
          = {1, 2, 3, 4, 5, 6, 7, 8, 9, 10}

    Step 2: (machine OR deep) AND learning
            {1, 2, 3, 4, 5, 6, 7, 8, 9, 10} ∩ {1, 2, 4, 5, 6, 7, 8, 9, 10}
          = {1, 2, 4, 5, 6, 7, 8, 9, 10}

    Step 3: Result AND NOT neural
            {1, 2, 4, 5, 6, 7, 8, 9, 10} \ {3, 6, 8, 9}
          = {1, 2, 4, 5, 7, 10}  ← CANDIDATE DOCUMENTS

    Time: ~10 microseconds for 1M documents!

┌─────────────────────────────────────────────────────────────────────────┐
│  STEP 2: POSITION PHASE (Optional - for phrases/proximity)              │
└─────────────────────────────────────────────────────────────────────────┘

IF phrase search needed:
    For each candidate doc {1, 2, 4, 5, 7, 10}:
        Use skip lists to verify exact positions
        Check consecutive positions for phrases
        Extract position data for snippets

    Time: O(log n) per position lookup

┌─────────────────────────────────────────────────────────────────────────┐
│  STEP 3: RANKING PHASE (BM25 Scoring)                                   │
└─────────────────────────────────────────────────────────────────────────┘

For each candidate document:
    1. Calculate IDF (Inverse Document Frequency):
       - Uses bitmap cardinality for instant document counts
       - IDF(&#34;machine&#34;) = log((N - df + 0.5) / (df + 0.5))
       - df = DocBitmaps[&#34;machine&#34;].GetCardinality()

    2. Calculate TF (Term Frequency):
       - Retrieves from pre-computed DocStats
       - TF(&#34;machine&#34;, Doc1) = termFreqs[&#34;machine&#34;]

    3. Apply BM25 formula:
       - Combines IDF, TF, and length normalization
       - Score = IDF × (TF × (k1 + 1)) / (TF + k1 × length_norm)

    4. Sum scores for all query terms

Results sorted by score:
    Doc 5: 8.45
    Doc 2: 7.23
    Doc 1: 6.91
    ...

    Time: O(candidates × terms)
</code></pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">Data Structure Memory Layout</h3><a id="user-content-data-structure-memory-layout" aria-label="Permalink: Data Structure Memory Layout" href="#data-structure-memory-layout"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div data-snippet-clipboard-copy-content="┌─────────────────────────────────────────────────────────────────────────┐
│                    INVERTED INDEX STRUCTURE                              │
└─────────────────────────────────────────────────────────────────────────┘

InvertedIndex {
    ┌─────────────────────────────────────────────────────────────────┐
    │  DocBitmaps: map[string]*roaring.Bitmap                         │
    │  ───────────────────────────────────────────────────────────────│
    │  &#34;machine&#34;  → [Compressed Bitmap: 512 bytes]                    │
    │  &#34;learning&#34; → [Compressed Bitmap: 448 bytes]                    │
    │  &#34;deep&#34;     → [Compressed Bitmap: 256 bytes]                    │
    │  ...                                                             │
    │                                                                  │
    │  Memory: ~100 bytes per term (compressed)                       │
    └─────────────────────────────────────────────────────────────────┘
                              │
                              │ Parallel Storage
                              ▼
    ┌─────────────────────────────────────────────────────────────────┐
    │  PostingsList: map[string]SkipList                              │
    │  ───────────────────────────────────────────────────────────────│
    │  &#34;machine&#34;  → SkipList with 10,000 position nodes               │
    │  &#34;learning&#34; → SkipList with 8,000 position nodes                │
    │  &#34;deep&#34;     → SkipList with 5,000 position nodes                │
    │  ...                                                             │
    │                                                                  │
    │  Memory: ~48 bytes per position (node overhead)                 │
    └─────────────────────────────────────────────────────────────────┘
                              │
                              │ Statistics
                              ▼
    ┌─────────────────────────────────────────────────────────────────┐
    │  DocStats: map[int]DocumentStats                                │
    │  ───────────────────────────────────────────────────────────────│
    │  Doc1 → {Length: 150, TermFreqs: {&#34;machine&#34;: 3, ...}}          │
    │  Doc2 → {Length: 200, TermFreqs: {&#34;learning&#34;: 5, ...}}         │
    │  ...                                                             │
    │                                                                  │
    │  Memory: ~16 bytes per term per document                        │
    └─────────────────────────────────────────────────────────────────┘
                              │
                              │ Metadata
                              ▼
    ┌─────────────────────────────────────────────────────────────────┐
    │  Global Statistics                                               │
    │  ───────────────────────────────────────────────────────────────│
    │  TotalDocs:   1,000,000                                         │
    │  TotalTerms:  150,000,000                                       │
    │  AvgDocLen:   150.0                                             │
    │  BM25Params:  {K1: 1.5, B: 0.75}                               │
    └─────────────────────────────────────────────────────────────────┘

    Mutex for thread safety (sync.RWMutex)
}

MEMORY BREAKDOWN (for 1M documents, 10M unique positions):
────────────────────────────────────────────────────────────
DocBitmaps:     ~10 MB  (compressed bitmaps)
PostingsList:   ~480 MB (skip list nodes)
DocStats:       ~500 MB (per-doc statistics)
Overhead:       ~10 MB  (maps, pointers, etc.)
────────────────────────────────────────────────────────────
TOTAL:          ~1 GB"><pre><code>┌─────────────────────────────────────────────────────────────────────────┐
│                    INVERTED INDEX STRUCTURE                              │
└─────────────────────────────────────────────────────────────────────────┘

InvertedIndex {
    ┌─────────────────────────────────────────────────────────────────┐
    │  DocBitmaps: map[string]*roaring.Bitmap                         │
    │  ───────────────────────────────────────────────────────────────│
    │  &#34;machine&#34;  → [Compressed Bitmap: 512 bytes]                    │
    │  &#34;learning&#34; → [Compressed Bitmap: 448 bytes]                    │
    │  &#34;deep&#34;     → [Compressed Bitmap: 256 bytes]                    │
    │  ...                                                             │
    │                                                                  │
    │  Memory: ~100 bytes per term (compressed)                       │
    └─────────────────────────────────────────────────────────────────┘
                              │
                              │ Parallel Storage
                              ▼
    ┌─────────────────────────────────────────────────────────────────┐
    │  PostingsList: map[string]SkipList                              │
    │  ───────────────────────────────────────────────────────────────│
    │  &#34;machine&#34;  → SkipList with 10,000 position nodes               │
    │  &#34;learning&#34; → SkipList with 8,000 position nodes                │
    │  &#34;deep&#34;     → SkipList with 5,000 position nodes                │
    │  ...                                                             │
    │                                                                  │
    │  Memory: ~48 bytes per position (node overhead)                 │
    └─────────────────────────────────────────────────────────────────┘
                              │
                              │ Statistics
                              ▼
    ┌─────────────────────────────────────────────────────────────────┐
    │  DocStats: map[int]DocumentStats                                │
    │  ───────────────────────────────────────────────────────────────│
    │  Doc1 → {Length: 150, TermFreqs: {&#34;machine&#34;: 3, ...}}          │
    │  Doc2 → {Length: 200, TermFreqs: {&#34;learning&#34;: 5, ...}}         │
    │  ...                                                             │
    │                                                                  │
    │  Memory: ~16 bytes per term per document                        │
    └─────────────────────────────────────────────────────────────────┘
                              │
                              │ Metadata
                              ▼
    ┌─────────────────────────────────────────────────────────────────┐
    │  Global Statistics                                               │
    │  ───────────────────────────────────────────────────────────────│
    │  TotalDocs:   1,000,000                                         │
    │  TotalTerms:  150,000,000                                       │
    │  AvgDocLen:   150.0                                             │
    │  BM25Params:  {K1: 1.5, B: 0.75}                               │
    └─────────────────────────────────────────────────────────────────┘

    Mutex for thread safety (sync.RWMutex)
}

MEMORY BREAKDOWN (for 1M documents, 10M unique positions):
────────────────────────────────────────────────────────────
DocBitmaps:     ~10 MB  (compressed bitmaps)
PostingsList:   ~480 MB (skip list nodes)
DocStats:       ~500 MB (per-doc statistics)
Overhead:       ~10 MB  (maps, pointers, etc.)
────────────────────────────────────────────────────────────
TOTAL:          ~1 GB
</code></pre></div>

<div data-snippet-clipboard-copy-content="┌─────────────────────────────────────────────────────────────────────────┐
│                    ROARING BITMAP STRUCTURE                              │
└─────────────────────────────────────────────────────────────────────────┘

Document IDs: {1, 2, 3, 100, 101, 102, 500000, 500001, 999999}

Traditional Bitmap (naive):
    [1,1,1,0,0...0,1,1,1,0...0,1,1,0...0,1]
    Size: 1,000,000 bits = 125 KB (wasteful for sparse data)

Roaring Bitmap (smart):

    Split into 65,536 chunks (high 16 bits = chunk ID):

    Chunk 0 (docs 0-65535):      [1,2,3,100,101,102]
    Chunk 7 (docs 458752-524287): [500000, 500001]
    Chunk 15 (docs 983040-1048575): [999999]

    Storage per chunk (adaptive):
    ┌────────────────────────────────────────────────────┐
    │ If cardinality &lt; 4096:                             │
    │   → Use Array Container                            │
    │   → Store sorted uint16 values directly            │
    │   → Size: 2 bytes × cardinality                    │
    │                                                     │
    │ If cardinality &gt; 4096:                             │
    │   → Use Bitmap Container                           │
    │   → Store 65536-bit bitmap (8 KB)                 │
    │   → Size: 8 KB fixed                               │
    │                                                     │
    │ If cardinality = 65536 (all docs):                │
    │   → Use Run Container                              │
    │   → Store: [0-65535]                               │
    │   → Size: 4 bytes                                  │
    └────────────────────────────────────────────────────┘

    Total Size: ~60 bytes (vs 125 KB!)

    Operations:

    AND: Container-by-container intersection
         Skip non-matching chunks (O(1))
         Intersect matching chunks (O(min(n,m)))

    OR:  Container-by-container union
         Merge all chunks (O(n+m))

    NOT: Complement within document space
         Flip all bits in each chunk"><pre><code>┌─────────────────────────────────────────────────────────────────────────┐
│                    ROARING BITMAP STRUCTURE                              │
└─────────────────────────────────────────────────────────────────────────┘

Document IDs: {1, 2, 3, 100, 101, 102, 500000, 500001, 999999}

Traditional Bitmap (naive):
    [1,1,1,0,0...0,1,1,1,0...0,1,1,0...0,1]
    Size: 1,000,000 bits = 125 KB (wasteful for sparse data)

Roaring Bitmap (smart):

    Split into 65,536 chunks (high 16 bits = chunk ID):

    Chunk 0 (docs 0-65535):      [1,2,3,100,101,102]
    Chunk 7 (docs 458752-524287): [500000, 500001]
    Chunk 15 (docs 983040-1048575): [999999]

    Storage per chunk (adaptive):
    ┌────────────────────────────────────────────────────┐
    │ If cardinality &lt; 4096:                             │
    │   → Use Array Container                            │
    │   → Store sorted uint16 values directly            │
    │   → Size: 2 bytes × cardinality                    │
    │                                                     │
    │ If cardinality &gt; 4096:                             │
    │   → Use Bitmap Container                           │
    │   → Store 65536-bit bitmap (8 KB)                 │
    │   → Size: 8 KB fixed                               │
    │                                                     │
    │ If cardinality = 65536 (all docs):                │
    │   → Use Run Container                              │
    │   → Store: [0-65535]                               │
    │   → Size: 4 bytes                                  │
    └────────────────────────────────────────────────────┘

    Total Size: ~60 bytes (vs 125 KB!)

    Operations:

    AND: Container-by-container intersection
         Skip non-matching chunks (O(1))
         Intersect matching chunks (O(min(n,m)))

    OR:  Container-by-container union
         Merge all chunks (O(n+m))

    NOT: Complement within document space
         Flip all bits in each chunk
</code></pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">Query Builder Execution Model</h3><a id="user-content-query-builder-execution-model" aria-label="Permalink: Query Builder Execution Model" href="#query-builder-execution-model"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div data-snippet-clipboard-copy-content="┌─────────────────────────────────────────────────────────────────────────┐
│                   QUERY BUILDER EXECUTION MODEL                          │
└─────────────────────────────────────────────────────────────────────────┘

Query: NewQueryBuilder(idx).
         Group(func(q) { q.Term(&#34;machine&#34;).Or().Term(&#34;deep&#34;) }).
         And().
         Term(&#34;learning&#34;).
         Execute()

INTERNAL REPRESENTATION:
────────────────────────

QueryBuilder {
    stack: []*roaring.Bitmap       // Operand stack
    ops:   []QueryOp               // Operator stack
    terms: []string                // Track for BM25
}

EXECUTION TRACE:
────────────────

Step 1: Group(func(q) { ... })
    ┌──────────────────────────────────────┐
    │ Create sub-builder                    │
    │ Execute sub-query                     │
    │ Push result bitmap to parent stack    │
    └──────────────────────────────────────┘

    Sub-query execution:
      1.1: Term(&#34;machine&#34;)
           → Lookup: DocBitmaps[&#34;machine&#34;]
           → Push: {1,2,4,5,7,8,9,10}

      1.2: Or()
           → Push operator: OR

      1.3: Term(&#34;deep&#34;)
           → Lookup: DocBitmaps[&#34;deep&#34;]
           → Push: {2,3,5,6,8,9}

      1.4: Apply OR
           → Pop: {2,3,5,6,8,9}
           → Pop: {1,2,4,5,7,8,9,10}
           → Union: {1,2,3,4,5,6,7,8,9,10}
           → Push result

    Result: {1,2,3,4,5,6,7,8,9,10}

Step 2: And()
    → Push operator: AND

Step 3: Term(&#34;learning&#34;)
    → Lookup: DocBitmaps[&#34;learning&#34;]
    → Push: {1,2,4,5,6,7,8,9,10}

Step 4: Execute()
    → Pop: {1,2,4,5,6,7,8,9,10}
    → Pop: {1,2,3,4,5,6,7,8,9,10}
    → Intersect: {1,2,4,5,6,7,8,9,10}
    → Return final bitmap

OPERATION COSTS:
────────────────
Bitmap Lookup:    O(1)          ~100 ns
Bitmap Union:     O(n+m)        ~1 µs for 10k docs
Bitmap Intersect: O(min(n,m))   ~800 ns for 10k docs
Bitmap Difference: O(n)         ~900 ns for 10k docs

Total Query Time: ~10 µs for typical query!"><pre><code>┌─────────────────────────────────────────────────────────────────────────┐
│                   QUERY BUILDER EXECUTION MODEL                          │
└─────────────────────────────────────────────────────────────────────────┘

Query: NewQueryBuilder(idx).
         Group(func(q) { q.Term(&#34;machine&#34;).Or().Term(&#34;deep&#34;) }).
         And().
         Term(&#34;learning&#34;).
         Execute()

INTERNAL REPRESENTATION:
────────────────────────

QueryBuilder {
    stack: []*roaring.Bitmap       // Operand stack
    ops:   []QueryOp               // Operator stack
    terms: []string                // Track for BM25
}

EXECUTION TRACE:
────────────────

Step 1: Group(func(q) { ... })
    ┌──────────────────────────────────────┐
    │ Create sub-builder                    │
    │ Execute sub-query                     │
    │ Push result bitmap to parent stack    │
    └──────────────────────────────────────┘

    Sub-query execution:
      1.1: Term(&#34;machine&#34;)
           → Lookup: DocBitmaps[&#34;machine&#34;]
           → Push: {1,2,4,5,7,8,9,10}

      1.2: Or()
           → Push operator: OR

      1.3: Term(&#34;deep&#34;)
           → Lookup: DocBitmaps[&#34;deep&#34;]
           → Push: {2,3,5,6,8,9}

      1.4: Apply OR
           → Pop: {2,3,5,6,8,9}
           → Pop: {1,2,4,5,7,8,9,10}
           → Union: {1,2,3,4,5,6,7,8,9,10}
           → Push result

    Result: {1,2,3,4,5,6,7,8,9,10}

Step 2: And()
    → Push operator: AND

Step 3: Term(&#34;learning&#34;)
    → Lookup: DocBitmaps[&#34;learning&#34;]
    → Push: {1,2,4,5,6,7,8,9,10}

Step 4: Execute()
    → Pop: {1,2,4,5,6,7,8,9,10}
    → Pop: {1,2,3,4,5,6,7,8,9,10}
    → Intersect: {1,2,4,5,6,7,8,9,10}
    → Return final bitmap

OPERATION COSTS:
────────────────
Bitmap Lookup:    O(1)          ~100 ns
Bitmap Union:     O(n+m)        ~1 µs for 10k docs
Bitmap Intersect: O(min(n,m))   ~800 ns for 10k docs
Bitmap Difference: O(n)         ~900 ns for 10k docs

Total Query Time: ~10 µs for typical query!
</code></pre></div>

<div data-snippet-clipboard-copy-content="┌──────────────────────────────────────────────────────────────────────┐
│                         Complete Data Flow                           │
└──────────────────────────────────────────────────────────────────────┘

                              User Input
                       &#34;The Quick Brown Fox!&#34;
                                │
                                ▼
            ┌───────────────────────────────────────────┐
            │      Text Analysis Pipeline               │
            │  ┌─────────────────────────────────────┐  │
            │  │ 1. Tokenization                     │  │
            │  │    [&#34;The&#34;, &#34;Quick&#34;, &#34;Brown&#34;, &#34;Fox&#34;] │  │
            │  └────────────┬────────────────────────┘  │
            │               ▼                            │
            │  ┌─────────────────────────────────────┐  │
            │  │ 2. Lowercasing                      │  │
            │  │    [&#34;the&#34;, &#34;quick&#34;, &#34;brown&#34;, &#34;fox&#34;] │  │
            │  └────────────┬────────────────────────┘  │
            │               ▼                            │
            │  ┌─────────────────────────────────────┐  │
            │  │ 3. Stopword Filtering               │  │
            │  │    [&#34;quick&#34;, &#34;brown&#34;, &#34;fox&#34;]        │  │
            │  └────────────┬────────────────────────┘  │
            │               ▼                            │
            │  ┌─────────────────────────────────────┐  │
            │  │ 4. Length Filtering                 │  │
            │  │    [&#34;quick&#34;, &#34;brown&#34;, &#34;fox&#34;]        │  │
            │  └────────────┬────────────────────────┘  │
            │               ▼                            │
            │  ┌─────────────────────────────────────┐  │
            │  │ 5. Stemming                         │  │
            │  │    [&#34;quick&#34;, &#34;brown&#34;, &#34;fox&#34;]        │  │
            │  └────────────┬────────────────────────┘  │
            └───────────────┼────────────────────────────┘
                            ▼
                    [&#34;quick&#34;, &#34;brown&#34;, &#34;fox&#34;]
                            │
                            ▼
            ┌───────────────────────────────────────────┐
            │       Inverted Index (Indexing)           │
            │                                            │
            │  ┌─────────┬────────────────────────┐     │
            │  │ &#34;quick&#34; │ → SkipList             │     │
            │  │         │    └─&gt; [Doc1:Pos0]     │     │
            │  ├─────────┼────────────────────────┤     │
            │  │ &#34;brown&#34; │ → SkipList             │     │
            │  │         │    └─&gt; [Doc1:Pos1]     │     │
            │  ├─────────┼────────────────────────┤     │
            │  │ &#34;fox&#34;   │ → SkipList             │     │
            │  │         │    └─&gt; [Doc1:Pos2]     │     │
            │  └─────────┴────────────────────────┘     │
            └───────────────┬───────────────────────────┘
                            │
          ┌─────────────────┴─────────────────┐
          │        Search Operations          │
          ▼                                   ▼
    ┌──────────┐                      ┌────────────┐
    │  Term    │                      │  Phrase    │
    │  Search  │                      │  Search    │
    └────┬─────┘                      └─────┬──────┘
         │                                  │
         └──────────┬───────────────────────┘
                    ▼
            ┌───────────────┐
            │   Proximity   │
            │   Ranking     │
            └───────┬───────┘
                    │
                    ▼
            ┌───────────────────────┐
            │  Ranked Results       │
            │  ┌─────────────────┐  │
            │  │ Doc 1: Score 1.0│  │
            │  │ Doc 2: Score 0.5│  │
            │  │ Doc 3: Score 0.3│  │
            │  └─────────────────┘  │
            └───────────────────────┘"><pre><code>┌──────────────────────────────────────────────────────────────────────┐
│                         Complete Data Flow                           │
└──────────────────────────────────────────────────────────────────────┘

                              User Input
                       &#34;The Quick Brown Fox!&#34;
                                │
                                ▼
            ┌───────────────────────────────────────────┐
            │      Text Analysis Pipeline               │
            │  ┌─────────────────────────────────────┐  │
            │  │ 1. Tokenization                     │  │
            │  │    [&#34;The&#34;, &#34;Quick&#34;, &#34;Brown&#34;, &#34;Fox&#34;] │  │
            │  └────────────┬────────────────────────┘  │
            │               ▼                            │
            │  ┌─────────────────────────────────────┐  │
            │  │ 2. Lowercasing                      │  │
            │  │    [&#34;the&#34;, &#34;quick&#34;, &#34;brown&#34;, &#34;fox&#34;] │  │
            │  └────────────┬────────────────────────┘  │
            │               ▼                            │
            │  ┌─────────────────────────────────────┐  │
            │  │ 3. Stopword Filtering               │  │
            │  │    [&#34;quick&#34;, &#34;brown&#34;, &#34;fox&#34;]        │  │
            │  └────────────┬────────────────────────┘  │
            │               ▼                            │
            │  ┌─────────────────────────────────────┐  │
            │  │ 4. Length Filtering                 │  │
            │  │    [&#34;quick&#34;, &#34;brown&#34;, &#34;fox&#34;]        │  │
            │  └────────────┬────────────────────────┘  │
            │               ▼                            │
            │  ┌─────────────────────────────────────┐  │
            │  │ 5. Stemming                         │  │
            │  │    [&#34;quick&#34;, &#34;brown&#34;, &#34;fox&#34;]        │  │
            │  └────────────┬────────────────────────┘  │
            └───────────────┼────────────────────────────┘
                            ▼
                    [&#34;quick&#34;, &#34;brown&#34;, &#34;fox&#34;]
                            │
                            ▼
            ┌───────────────────────────────────────────┐
            │       Inverted Index (Indexing)           │
            │                                            │
            │  ┌─────────┬────────────────────────┐     │
            │  │ &#34;quick&#34; │ → SkipList             │     │
            │  │         │    └─&gt; [Doc1:Pos0]     │     │
            │  ├─────────┼────────────────────────┤     │
            │  │ &#34;brown&#34; │ → SkipList             │     │
            │  │         │    └─&gt; [Doc1:Pos1]     │     │
            │  ├─────────┼────────────────────────┤     │
            │  │ &#34;fox&#34;   │ → SkipList             │     │
            │  │         │    └─&gt; [Doc1:Pos2]     │     │
            │  └─────────┴────────────────────────┘     │
            └───────────────┬───────────────────────────┘
                            │
          ┌─────────────────┴─────────────────┐
          │        Search Operations          │
          ▼                                   ▼
    ┌──────────┐                      ┌────────────┐
    │  Term    │                      │  Phrase    │
    │  Search  │                      │  Search    │
    └────┬─────┘                      └─────┬──────┘
         │                                  │
         └──────────┬───────────────────────┘
                    ▼
            ┌───────────────┐
            │   Proximity   │
            │   Ranking     │
            └───────┬───────┘
                    │
                    ▼
            ┌───────────────────────┐
            │  Ranked Results       │
            │  ┌─────────────────┐  │
            │  │ Doc 1: Score 1.0│  │
            │  │ Doc 2: Score 0.5│  │
            │  │ Doc 3: Score 0.3│  │
            │  └─────────────────┘  │
            └───────────────────────┘
</code></pre></div>

<p dir="auto"><strong>1. Skip Lists over Balanced Trees</strong></p>
<p dir="auto">Rationale:</p>
<ul dir="auto">
<li>Simpler implementation (no rotation logic)</li>
<li>Better cache locality</li>
<li>Easier to make concurrent</li>
<li>Comparable performance (O(log n))</li>
<li>Used in production systems (Redis, LevelDB)</li>
</ul>
<p dir="auto"><strong>2. Position-Based Indexing</strong></p>
<p dir="auto">Instead of just tracking document IDs, Blaze tracks exact word positions:</p>
<div data-snippet-clipboard-copy-content="Traditional Index (Document IDs only):
┌─────────┬──────────────────┐
│ &#34;quick&#34; │ [Doc1, Doc3]     │  Cannot do phrase search
└─────────┴──────────────────┘  Cannot rank by proximity

Position-Based Index (Document + Offset):
┌─────────┬────────────────────────────────────┐
│ &#34;quick&#34; │ [Doc1:Pos1, Doc3:Pos0]             │  Enables phrase search
│ &#34;brown&#34; │ [Doc1:Pos2, Doc3:Pos1]             │  Enables proximity ranking
│ &#34;fox&#34;   │ [Doc1:Pos3]                        │  Enables snippet generation
└─────────┴────────────────────────────────────┘  Enables precise results

Can verify: &#34;quick brown&#34; is a phrase in Doc1 (Pos1→Pos2)
            but NOT in Doc3 (Pos0 and Pos1 are not &#34;quick brown&#34;)"><pre><code>Traditional Index (Document IDs only):
┌─────────┬──────────────────┐
│ &#34;quick&#34; │ [Doc1, Doc3]     │  Cannot do phrase search
└─────────┴──────────────────┘  Cannot rank by proximity

Position-Based Index (Document + Offset):
┌─────────┬────────────────────────────────────┐
│ &#34;quick&#34; │ [Doc1:Pos1, Doc3:Pos0]             │  Enables phrase search
│ &#34;brown&#34; │ [Doc1:Pos2, Doc3:Pos1]             │  Enables proximity ranking
│ &#34;fox&#34;   │ [Doc1:Pos3]                        │  Enables snippet generation
└─────────┴────────────────────────────────────┘  Enables precise results

Can verify: &#34;quick brown&#34; is a phrase in Doc1 (Pos1→Pos2)
            but NOT in Doc3 (Pos0 and Pos1 are not &#34;quick brown&#34;)
</code></pre></div>
<p dir="auto">Benefits:</p>
<ul dir="auto">
<li>Enables phrase search (check consecutive positions)</li>
<li>Enables proximity ranking (measure distances)</li>
<li>Enables snippet generation (extract relevant parts)</li>
<li>More precise search results</li>
</ul>
<p dir="auto">Trade-offs:</p>
<ul dir="auto">
<li>Larger index size (~2-3x more data)</li>
<li>More complex algorithms (but still O(log n))</li>
</ul>
<p dir="auto"><strong>3. Binary Serialization</strong></p>
<p dir="auto">Custom binary format instead of JSON:</p>
<p dir="auto">Advantages:</p>
<ul dir="auto">
<li>60% smaller file size</li>
<li>3x faster parsing</li>
<li>Preserves skip list structure</li>
<li>Suitable for large indexes</li>
</ul>
<p dir="auto"><strong>4. Configurable Text Analysis</strong></p>
<p dir="auto">Pluggable analyzer configuration:</p>
<p dir="auto">Benefits:</p>
<ul dir="auto">
<li>Adapt to different use cases</li>
<li>Trade-off precision vs recall</li>
<li>Support multiple languages (future)</li>
<li>Domain-specific customization</li>
</ul>

<div dir="auto"><h3 tabindex="-1" dir="auto">1. Choose Appropriate Document IDs</h3><a id="user-content-1-choose-appropriate-document-ids" aria-label="Permalink: 1. Choose Appropriate Document IDs" href="#1-choose-appropriate-document-ids"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Use stable, unique identifiers:</p>
<div dir="auto" data-snippet-clipboard-copy-content="// Good: Use database primary keys
idx.Index(dbRecord.ID, dbRecord.Content)

// Bad: Use array indices (changes when reordering)
for i, doc := range docs {
    idx.Index(i, doc.Content)  // Don&#39;t do this
}"><pre><span>// Good: Use database primary keys</span>
<span>idx</span>.<span>Index</span>(<span>dbRecord</span>.<span>ID</span>, <span>dbRecord</span>.<span>Content</span>)

<span>// Bad: Use array indices (changes when reordering)</span>
<span>for</span> <span>i</span>, <span>doc</span> <span>:=</span> <span>range</span> <span>docs</span> {
    <span>idx</span>.<span>Index</span>(<span>i</span>, <span>doc</span>.<span>Content</span>)  <span>// Don&#39;t do this</span>
}</pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">2. Batch Indexing for Large Datasets</h3><a id="user-content-2-batch-indexing-for-large-datasets" aria-label="Permalink: 2. Batch Indexing for Large Datasets" href="#2-batch-indexing-for-large-datasets"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto" data-snippet-clipboard-copy-content="func IndexLargeDataset(docs []Document) *blaze.InvertedIndex {
    idx := blaze.NewInvertedIndex()

    // Process in batches
    batchSize := 1000
    for i := 0; i &lt; len(docs); i += batchSize {
        end := min(i+batchSize, len(docs))
        batch := docs[i:end]

        for _, doc := range batch {
            idx.Index(doc.ID, doc.Content)
        }

        // Optional: periodic serialization for checkpoints
        if i%10000 == 0 {
            data, _ := idx.Encode()
            os.WriteFile(fmt.Sprintf(&#34;checkpoint_%d.bin&#34;, i), data, 0644)
        }
    }

    return idx
}"><pre><span>func</span> <span>IndexLargeDataset</span>(<span>docs</span> []<span>Document</span>) <span>*</span>blaze.<span>InvertedIndex</span> {
    <span>idx</span> <span>:=</span> <span>blaze</span>.<span>NewInvertedIndex</span>()

    <span>// Process in batches</span>
    <span>batchSize</span> <span>:=</span> <span>1000</span>
    <span>for</span> <span>i</span> <span>:=</span> <span>0</span>; <span>i</span> <span>&lt;</span> <span>len</span>(<span>docs</span>); <span>i</span> <span>+=</span> <span>batchSize</span> {
        <span>end</span> <span>:=</span> <span>min</span>(<span>i</span><span>+</span><span>batchSize</span>, <span>len</span>(<span>docs</span>))
        <span>batch</span> <span>:=</span> <span>docs</span>[<span>i</span>:<span>end</span>]

        <span>for</span> <span>_</span>, <span>doc</span> <span>:=</span> <span>range</span> <span>batch</span> {
            <span>idx</span>.<span>Index</span>(<span>doc</span>.<span>ID</span>, <span>doc</span>.<span>Content</span>)
        }

        <span>// Optional: periodic serialization for checkpoints</span>
        <span>if</span> <span>i</span><span>%</span><span>10000</span> <span>==</span> <span>0</span> {
            <span>data</span>, <span>_</span> <span>:=</span> <span>idx</span>.<span>Encode</span>()
            <span>os</span>.<span>WriteFile</span>(<span>fmt</span>.<span>Sprintf</span>(<span>&#34;checkpoint_%d.bin&#34;</span>, <span>i</span>), <span>data</span>, <span>0644</span>)
        }
    }

    <span>return</span> <span>idx</span>
}</pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">3. Use Appropriate Analyzer Config</h3><a id="user-content-3-use-appropriate-analyzer-config" aria-label="Permalink: 3. Use Appropriate Analyzer Config" href="#3-use-appropriate-analyzer-config"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Match configuration to your use case:</p>
<div dir="auto" data-snippet-clipboard-copy-content="// Natural language text (books, articles)
naturalLanguageConfig := blaze.AnalyzerConfig{
    MinTokenLength:  2,
    EnableStemming:  true,   // Find related words
    EnableStopwords: true,   // Remove common words
}

// Technical documentation (code, APIs)
technicalConfig := blaze.AnalyzerConfig{
    MinTokenLength:  2,
    EnableStemming:  false,  // Keep exact terms
    EnableStopwords: false,  // Keep all words
}

// Product names (e-commerce)
productConfig := blaze.AnalyzerConfig{
    MinTokenLength:  1,      // Include single chars (e.g., &#34;X&#34;)
    EnableStemming:  false,  // Exact product names
    EnableStopwords: false,  // Keep all words
}"><pre><span>// Natural language text (books, articles)</span>
<span>naturalLanguageConfig</span> <span>:=</span> blaze.<span>AnalyzerConfig</span>{
    <span>MinTokenLength</span>:  <span>2</span>,
    <span>EnableStemming</span>:  <span>true</span>,   <span>// Find related words</span>
    <span>EnableStopwords</span>: <span>true</span>,   <span>// Remove common words</span>
}

<span>// Technical documentation (code, APIs)</span>
<span>technicalConfig</span> <span>:=</span> blaze.<span>AnalyzerConfig</span>{
    <span>MinTokenLength</span>:  <span>2</span>,
    <span>EnableStemming</span>:  <span>false</span>,  <span>// Keep exact terms</span>
    <span>EnableStopwords</span>: <span>false</span>,  <span>// Keep all words</span>
}

<span>// Product names (e-commerce)</span>
<span>productConfig</span> <span>:=</span> blaze.<span>AnalyzerConfig</span>{
    <span>MinTokenLength</span>:  <span>1</span>,      <span>// Include single chars (e.g., &#34;X&#34;)</span>
    <span>EnableStemming</span>:  <span>false</span>,  <span>// Exact product names</span>
    <span>EnableStopwords</span>: <span>false</span>,  <span>// Keep all words</span>
}</pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">4. Persist Index for Large Datasets</h3><a id="user-content-4-persist-index-for-large-datasets" aria-label="Permalink: 4. Persist Index for Large Datasets" href="#4-persist-index-for-large-datasets"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Don&#39;t rebuild the index every time:</p>
<div dir="auto" data-snippet-clipboard-copy-content="const indexFile = &#34;search_index.bin&#34;

func LoadOrBuildIndex(docs []Document) (*blaze.InvertedIndex, error) {
    // Try to load existing index
    if data, err := os.ReadFile(indexFile); err == nil {
        idx := blaze.NewInvertedIndex()
        if err := idx.Decode(data); err == nil {
            return idx, nil
        }
    }

    // Build new index
    idx := blaze.NewInvertedIndex()
    for _, doc := range docs {
        idx.Index(doc.ID, doc.Content)
    }

    // Save for next time
    if data, err := idx.Encode(); err == nil {
        os.WriteFile(indexFile, data, 0644)
    }

    return idx, nil
}"><pre><span>const</span> <span>indexFile</span> <span>=</span> <span>&#34;search_index.bin&#34;</span>

<span>func</span> <span>LoadOrBuildIndex</span>(<span>docs</span> []<span>Document</span>) (<span>*</span>blaze.<span>InvertedIndex</span>, <span>error</span>) {
    <span>// Try to load existing index</span>
    <span>if</span> <span>data</span>, <span>err</span> <span>:=</span> <span>os</span>.<span>ReadFile</span>(<span>indexFile</span>); <span>err</span> <span>==</span> <span>nil</span> {
        <span>idx</span> <span>:=</span> <span>blaze</span>.<span>NewInvertedIndex</span>()
        <span>if</span> <span>err</span> <span>:=</span> <span>idx</span>.<span>Decode</span>(<span>data</span>); <span>err</span> <span>==</span> <span>nil</span> {
            <span>return</span> <span>idx</span>, <span>nil</span>
        }
    }

    <span>// Build new index</span>
    <span>idx</span> <span>:=</span> <span>blaze</span>.<span>NewInvertedIndex</span>()
    <span>for</span> <span>_</span>, <span>doc</span> <span>:=</span> <span>range</span> <span>docs</span> {
        <span>idx</span>.<span>Index</span>(<span>doc</span>.<span>ID</span>, <span>doc</span>.<span>Content</span>)
    }

    <span>// Save for next time</span>
    <span>if</span> <span>data</span>, <span>err</span> <span>:=</span> <span>idx</span>.<span>Encode</span>(); <span>err</span> <span>==</span> <span>nil</span> {
        <span>os</span>.<span>WriteFile</span>(<span>indexFile</span>, <span>data</span>, <span>0644</span>)
    }

    <span>return</span> <span>idx</span>, <span>nil</span>
}</pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">5. Handle Concurrent Access</h3><a id="user-content-5-handle-concurrent-access" aria-label="Permalink: 5. Handle Concurrent Access" href="#5-handle-concurrent-access"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">The Index method is thread-safe, but for read-heavy workloads:</p>
<div dir="auto" data-snippet-clipboard-copy-content="type SearchService struct {
    idx *blaze.InvertedIndex
    mu  sync.RWMutex
}

func (s *SearchService) Index(docID int, content string) {
    s.mu.Lock()
    defer s.mu.Unlock()
    s.idx.Index(docID, content)
}

func (s *SearchService) Search(query string) []blaze.Match {
    s.mu.RLock()
    defer s.mu.RUnlock()
    return s.idx.RankProximity(query, 20)
}"><pre><span>type</span> <span>SearchService</span> <span>struct</span> {
    <span>idx</span> <span>*</span>blaze.<span>InvertedIndex</span>
    <span>mu</span>  sync.<span>RWMutex</span>
}

<span>func</span> (<span>s</span> <span>*</span><span>SearchService</span>) <span>Index</span>(<span>docID</span> <span>int</span>, <span>content</span> <span>string</span>) {
    <span>s</span>.<span>mu</span>.<span>Lock</span>()
    <span>defer</span> <span>s</span>.<span>mu</span>.<span>Unlock</span>()
    <span>s</span>.<span>idx</span>.<span>Index</span>(<span>docID</span>, <span>content</span>)
}

<span>func</span> (<span>s</span> <span>*</span><span>SearchService</span>) <span>Search</span>(<span>query</span> <span>string</span>) []blaze.<span>Match</span> {
    <span>s</span>.<span>mu</span>.<span>RLock</span>()
    <span>defer</span> <span>s</span>.<span>mu</span>.<span>RUnlock</span>()
    <span>return</span> <span>s</span>.<span>idx</span>.<span>RankProximity</span>(<span>query</span>, <span>20</span>)
}</pre></div>

<p dir="auto">Track index growth:</p>
<div dir="auto" data-snippet-clipboard-copy-content="func (idx *InvertedIndex) Stats() map[string]interface{} {
    stats := make(map[string]interface{})

    stats[&#34;unique_terms&#34;] = len(idx.PostingsList)

    totalPositions := 0
    for _, skipList := range idx.PostingsList {
        // Count positions in this skip list
        iter := skipList.Iterator()
        for iter.HasNext() {
            iter.Next()
            totalPositions++
        }
    }

    stats[&#34;total_positions&#34;] = totalPositions
    stats[&#34;avg_positions_per_term&#34;] = float64(totalPositions) / float64(len(idx.PostingsList))

    return stats
}"><pre><span>func</span> (<span>idx</span> <span>*</span><span>InvertedIndex</span>) <span>Stats</span>() <span>map</span>[<span>string</span>]<span>interface</span>{} {
    <span>stats</span> <span>:=</span> <span>make</span>(<span>map</span>[<span>string</span>]<span>interface</span>{})

    <span>stats</span>[<span>&#34;unique_terms&#34;</span>] <span>=</span> <span>len</span>(<span>idx</span>.<span>PostingsList</span>)

    <span>totalPositions</span> <span>:=</span> <span>0</span>
    <span>for</span> <span>_</span>, <span>skipList</span> <span>:=</span> <span>range</span> <span>idx</span>.<span>PostingsList</span> {
        <span>// Count positions in this skip list</span>
        <span>iter</span> <span>:=</span> <span>skipList</span>.<span>Iterator</span>()
        <span>for</span> <span>iter</span>.<span>HasNext</span>() {
            <span>iter</span>.<span>Next</span>()
            <span>totalPositions</span><span>++</span>
        }
    }

    <span>stats</span>[<span>&#34;total_positions&#34;</span>] <span>=</span> <span>totalPositions</span>
    <span>stats</span>[<span>&#34;avg_positions_per_term&#34;</span>] <span>=</span> <span>float64</span>(<span>totalPositions</span>) <span>/</span> <span>float64</span>(<span>len</span>(<span>idx</span>.<span>PostingsList</span>))

    <span>return</span> <span>stats</span>
}</pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">7. Choose the Right Ranking Algorithm</h3><a id="user-content-7-choose-the-right-ranking-algorithm" aria-label="Permalink: 7. Choose the Right Ranking Algorithm" href="#7-choose-the-right-ranking-algorithm"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto"><strong>Use BM25 when:</strong></p>
<ul dir="auto">
<li>You need industry-standard relevance ranking</li>
<li>Term frequency matters (documents with more occurrences rank higher)</li>
<li>You want automatic length normalization</li>
<li>Rare terms should be weighted more heavily</li>
<li><strong>Recommended for most use cases</strong></li>
</ul>
<p dir="auto"><strong>Use Proximity when:</strong></p>
<ul dir="auto">
<li>You want to find terms close together</li>
<li>Term distance is more important than frequency</li>
<li>You&#39;re searching for specific co-occurrences</li>
<li>You need snippet generation (using position data)</li>
</ul>
<p dir="auto"><strong>Practical Examples:</strong></p>
<div dir="auto" data-snippet-clipboard-copy-content="// E-commerce: General product search
// BM25 considers term frequency and rarity
bm25Results := idx.RankBM25(&#34;wireless bluetooth headphones&#34;, 20)
// Returns products with any/all terms, ranked by relevance

// E-commerce: Exact product name
// Proximity finds terms appearing together
proxResults := idx.RankProximity(&#34;Sony WH-1000XM4&#34;, 20)
// Returns products where terms appear close together

// Document search: Research papers
// BM25 for broad topic search
papers := idx.RankBM25(&#34;neural networks deep learning&#34;, 50)

// Document search: Finding specific phrase mentions
// Proximity for finding &#34;neural networks&#34; as a concept
mentions := idx.RankProximity(&#34;neural networks&#34;, 50)

// Best practice: Use both for different purposes!
generalResults := idx.RankBM25(query, 100)    // Cast wide net
preciseResults := idx.RankProximity(query, 20) // Refine results"><pre><span>// E-commerce: General product search</span>
<span>// BM25 considers term frequency and rarity</span>
<span>bm25Results</span> <span>:=</span> <span>idx</span>.<span>RankBM25</span>(<span>&#34;wireless bluetooth headphones&#34;</span>, <span>20</span>)
<span>// Returns products with any/all terms, ranked by relevance</span>

<span>// E-commerce: Exact product name</span>
<span>// Proximity finds terms appearing together</span>
<span>proxResults</span> <span>:=</span> <span>idx</span>.<span>RankProximity</span>(<span>&#34;Sony WH-1000XM4&#34;</span>, <span>20</span>)
<span>// Returns products where terms appear close together</span>

<span>// Document search: Research papers</span>
<span>// BM25 for broad topic search</span>
<span>papers</span> <span>:=</span> <span>idx</span>.<span>RankBM25</span>(<span>&#34;neural networks deep learning&#34;</span>, <span>50</span>)

<span>// Document search: Finding specific phrase mentions</span>
<span>// Proximity for finding &#34;neural networks&#34; as a concept</span>
<span>mentions</span> <span>:=</span> <span>idx</span>.<span>RankProximity</span>(<span>&#34;neural networks&#34;</span>, <span>50</span>)

<span>// Best practice: Use both for different purposes!</span>
<span>generalResults</span> <span>:=</span> <span>idx</span>.<span>RankBM25</span>(<span>query</span>, <span>100</span>)    <span>// Cast wide net</span>
<span>preciseResults</span> <span>:=</span> <span>idx</span>.<span>RankProximity</span>(<span>query</span>, <span>20</span>) <span>// Refine results</span></pre></div>

<p dir="auto">Always specify a reasonable max results:</p>
<div dir="auto" data-snippet-clipboard-copy-content="// Good: Limit results
results := idx.RankBM25(&#34;search query&#34;, 100)

// Bad: Could return millions of results
results := idx.RankBM25(&#34;search query&#34;, math.MaxInt32)"><pre><span>// Good: Limit results</span>
<span>results</span> <span>:=</span> <span>idx</span>.<span>RankBM25</span>(<span>&#34;search query&#34;</span>, <span>100</span>)

<span>// Bad: Could return millions of results</span>
<span>results</span> <span>:=</span> <span>idx</span>.<span>RankBM25</span>(<span>&#34;search query&#34;</span>, <span>math</span>.<span>MaxInt32</span>)</pre></div>

<p dir="auto">Normalize queries before searching:</p>
<div dir="auto" data-snippet-clipboard-copy-content="func NormalizeQuery(query string) string {
    // Remove extra whitespace
    query = strings.TrimSpace(query)
    query = strings.Join(strings.Fields(query), &#34; &#34;)

    // Convert to lowercase
    query = strings.ToLower(query)

    // Remove special characters (optional)
    query = regexp.MustCompile(`[^\w\s]`).ReplaceAllString(query, &#34;&#34;)

    return query
}

// Use normalized query
normalizedQuery := NormalizeQuery(userInput)
results := idx.RankBM25(normalizedQuery, 20)"><pre><span>func</span> <span>NormalizeQuery</span>(<span>query</span> <span>string</span>) <span>string</span> {
    <span>// Remove extra whitespace</span>
    <span>query</span> <span>=</span> <span>strings</span>.<span>TrimSpace</span>(<span>query</span>)
    <span>query</span> <span>=</span> <span>strings</span>.<span>Join</span>(<span>strings</span>.<span>Fields</span>(<span>query</span>), <span>&#34; &#34;</span>)

    <span>// Convert to lowercase</span>
    <span>query</span> <span>=</span> <span>strings</span>.<span>ToLower</span>(<span>query</span>)

    <span>// Remove special characters (optional)</span>
    <span>query</span> <span>=</span> <span>regexp</span>.<span>MustCompile</span>(<span>`[^\w\s]`</span>).<span>ReplaceAllString</span>(<span>query</span>, <span>&#34;&#34;</span>)

    <span>return</span> <span>query</span>
}

<span>// Use normalized query</span>
<span>normalizedQuery</span> <span>:=</span> <span>NormalizeQuery</span>(<span>userInput</span>)
<span>results</span> <span>:=</span> <span>idx</span>.<span>RankBM25</span>(<span>normalizedQuery</span>, <span>20</span>)</pre></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">10. Monitor BM25 Statistics</h3><a id="user-content-10-monitor-bm25-statistics" aria-label="Permalink: 10. Monitor BM25 Statistics" href="#10-monitor-bm25-statistics"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">Track corpus statistics for insights:</p>
<div dir="auto" data-snippet-clipboard-copy-content="// After indexing
fmt.Printf(&#34;Total documents: %d\n&#34;, idx.TotalDocs)
fmt.Printf(&#34;Total terms: %d\n&#34;, idx.TotalTerms)
fmt.Printf(&#34;Average doc length: %.2f\n&#34;,
    float64(idx.TotalTerms) / float64(idx.TotalDocs))

// Per-document analysis
for docID, stats := range idx.DocStats {
    fmt.Printf(&#34;Doc %d: %d terms\n&#34;, docID, stats.Length)

    // Find most frequent terms
    for term, freq := range stats.TermFreqs {
        if freq &gt; 5 {
            fmt.Printf(&#34;  %s: %d occurrences\n&#34;, term, freq)
        }
    }
}"><pre><span>// After indexing</span>
<span>fmt</span>.<span>Printf</span>(<span>&#34;Total documents: %d<span>\n</span>&#34;</span>, <span>idx</span>.<span>TotalDocs</span>)
<span>fmt</span>.<span>Printf</span>(<span>&#34;Total terms: %d<span>\n</span>&#34;</span>, <span>idx</span>.<span>TotalTerms</span>)
<span>fmt</span>.<span>Printf</span>(<span>&#34;Average doc length: %.2f<span>\n</span>&#34;</span>,
    <span>float64</span>(<span>idx</span>.<span>TotalTerms</span>) <span>/</span> <span>float64</span>(<span>idx</span>.<span>TotalDocs</span>))

<span>// Per-document analysis</span>
<span>for</span> <span>docID</span>, <span>stats</span> <span>:=</span> <span>range</span> <span>idx</span>.<span>DocStats</span> {
    <span>fmt</span>.<span>Printf</span>(<span>&#34;Doc %d: %d terms<span>\n</span>&#34;</span>, <span>docID</span>, <span>stats</span>.<span>Length</span>)

    <span>// Find most frequent terms</span>
    <span>for</span> <span>term</span>, <span>freq</span> <span>:=</span> <span>range</span> <span>stats</span>.<span>TermFreqs</span> {
        <span>if</span> <span>freq</span> <span>&gt;</span> <span>5</span> {
            <span>fmt</span>.<span>Printf</span>(<span>&#34;  %s: %d occurrences<span>\n</span>&#34;</span>, <span>term</span>, <span>freq</span>)
        }
    }
}</pre></div>

<p dir="auto">Contributions are welcome! Please follow these guidelines:</p>

<div dir="auto" data-snippet-clipboard-copy-content="# Clone repository
git clone https://github.com/wizenheimer/blaze.git
cd blaze

# Install dependencies
make deps

# Run tests
make test

# Run linter
make lint"><pre><span><span>#</span> Clone repository</span>
git clone https://github.com/wizenheimer/blaze.git
<span>cd</span> blaze

<span><span>#</span> Install dependencies</span>
make deps

<span><span>#</span> Run tests</span>
make <span>test</span>

<span><span>#</span> Run linter</span>
make lint</pre></div>

<ul dir="auto">
<li>Follow Go conventions (gofmt, golint)</li>
<li>Write comprehensive comments</li>
<li>Include examples in documentation</li>
<li>Add tests for new features</li>
<li>Keep functions focused and small</li>
</ul>

<p dir="auto">Use descriptive commit messages:</p>
<div data-snippet-clipboard-copy-content="Good:
- &#34;feat: Add proximity ranking algorithm&#34;
- &#34;feat: Handle empty query in RankProximity&#34;
- &#34;fix: Reduce allocations in skip list insert&#34;

Bad:
- &#34;Update code&#34;
- &#34;Fix bug uwu&#34;
- &#34;WIP&#34;"><pre><code>Good:
- &#34;feat: Add proximity ranking algorithm&#34;
- &#34;feat: Handle empty query in RankProximity&#34;
- &#34;fix: Reduce allocations in skip list insert&#34;

Bad:
- &#34;Update code&#34;
- &#34;Fix bug uwu&#34;
- &#34;WIP&#34;
</code></pre></div>

<ol dir="auto">
<li>Fork the repository</li>
<li>Create a feature branch (<code>git checkout -b feature/amazing-feature</code>)</li>
<li>Make your changes</li>
<li>Add tests</li>
<li>Run <code>make check</code> to verify</li>
<li>Commit your changes</li>
<li>Push to your fork</li>
<li>Open a Pull Request</li>
</ol>

<p dir="auto">MIT License</p>

<ul dir="auto">
<li><strong>Skip Lists</strong>: Original paper by William Pugh (1990)</li>
<li><strong>Snowball Stemmer</strong>: Martin Porter&#39;s stemming algorithm</li>
<li><strong>Inspiration</strong>: Elasticsearch, Lucene, Mettis, Redis, LevelDB</li>
</ul>
</article></div></div>
  </body>
</html>
