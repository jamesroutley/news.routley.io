<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="http://www.righto.com/2023/10/intel-386-die-versions.html">Original</a>
    <h1>Examining the silicon dies of the Intel 386 processor</h1>
    
    <div id="readability-page-1" class="page"><div id="post-body-4071644285770837621" itemprop="description articleBody"><p>
You might think of the Intel 386 processor (1985) as just an early processor in the x86
line, but the 386 was a critical turning point for modern computing in several ways.<span id="fnref:second-source"><a href="#fn:second-source">1</a></span>
First, the 386 moved the x86 architecture to 32 bits, defining the dominant computing
architecture for the rest of the 20th century.
The 386 also established the overwhelming importance of x86, not just for Intel, but for the entire computer
industry.
Finally, the 386 ended IBM&#39;s control over the PC market, turning Compaq into the architectural
leader.</p>
<p>In this blog post, I look at die photos of the Intel 386 processor and explain what they reveal
about the history of the processor, such as the move from the 1.5 µm process to the
1 µm process.
You might expect that Intel simply made the same 386 chip at a smaller scale, but there were
substantial changes to the chip&#39;s layout, even some visible to the naked eye.<span id="fnref:keychains"><a href="#fn:keychains">2</a></span>
I also look at why the 386 SL had over three times the transistors as the other 386 versions.<span id="fnref:variants"><a href="#fn:variants">3</a></span></p>
<p>The 80386 was a major advancement over the 286: it implemented a 32-bit architecture,
added more instructions, and supported 4-gigabyte segments.
The 386 is a complicated processor (by 1980s standards), with 285,000 transistors, ten times the number of the original 8086.<span id="fnref:transistors"><a href="#fn:transistors">4</a></span>
The 386 has eight logical units
that are pipelined<span id="fnref:parallelism"><a href="#fn:parallelism">5</a></span> and operate mostly autonomously.<span id="fnref:block-diagram"><a href="#fn:block-diagram">6</a></span>
The diagram below shows the internal structure of the 386.<span id="fnref:die-diagram"><a href="#fn:die-diagram">7</a></span></p>
<p><a href="https://static.righto.com/images/386-versions/386-die-labeled.jpg"><img alt="The 386 with the main functional blocks labeled. Click this image (or any other) for a larger version. I created this image using a die photo from Antoine Bercovici." height="641" src="https://static.righto.com/images/386-versions/386-die-labeled-w600.jpg" title="The 386 with the main functional blocks labeled. Click this image (or any other) for a larger version. I created this image using a die photo from Antoine Bercovici." width="600"/></a></p><p>The 386 with the main functional blocks labeled. Click this image (or any other) for a larger version. I created this image using a die photo from Antoine Bercovici.</p>
<p>The heart of a processor is the datapath, the components that hold and process data.
In the 386, these components are in the lower left: the ALU (Arithmetic/Logic Unit), a barrel shifter to shift data, and the registers.
These components form regular rectangular blocks, 32 bits wide.
The datapath, along with the circuitry to the left that manages it, forms the Data Unit.
In the lower right is the microcode ROM, which breaks down machine instructions into
micro-instructions, the low-level steps of the instruction.
The microcode ROM, along with the microcode engine circuitry, forms the Control Unit.</p>
<p>The 386 has a complicated instruction format.
The Instruction Decode Unit breaks apart an instruction into its component parts
and generates a pointer to the microcode that implements the instruction.
The instruction queue holds three decoded instructions.
To improve performance, the Prefetch Unit reads instructions from memory before they are
needed, and stores them in the 16-byte prefetch queue.<span id="fnref:queue"><a href="#fn:queue">8</a></span></p>
<!-- Introduction to the 80386 p52 -->

<p>The 386 implements segmented memory and virtual memory, with access protection.<span id="fnref:protection"><a href="#fn:protection">9</a></span>
The Memory Management Unit
consists of the Segment Unit and the Paging Unit:
the Segment Unit translates a logical address to a linear address, while the Paging Unit
translates the linear address to a physical address.
The segment descriptor cache and page cache (TLB) hold data about segments and pages;
the 386 has no on-chip instruction or data cache.<span id="fnref:cache"><a href="#fn:cache">10</a></span>
The Bus Interface Unit in the upper right handles communication between the 386 and the external
memory and devices.</p>
<!--
The 386 can support thousands of segments, with the most recent segment information stored
in the [segment descriptor cache](https://web.archive.org/web/20220405211445/http://www.rcollins.org/ddj/Aug98/Aug98.html).
The 32-entry translation lookaside buffer (TLB or page cache) caches the translation information for
the most recently used pages.
El-Ayat p14 discusses the protection test unit.
-->

<p>Silicon dies are often labeled with the initials of the designers. The 386 DX, however,
has an unusually large number of initials. In the image below, I have enlarged the tiny initials so they are visible.
I think the designers put their initials next to the unit they worked on, but 
I haven&#39;t been able to identify most of the names.<span id="fnref:et"><a href="#fn:et">11</a></span></p>
<p><a href="https://static.righto.com/images/386-versions/386-initials.jpg"><img alt="The 386 die with the initials magnified." height="641" src="https://static.righto.com/images/386-versions/386-initials-w600.jpg" title="The 386 die with the initials magnified." width="600"/></a></p><p>The 386 die with the initials magnified.</p>
<h2>The shrink from 1.5 µm to 1 µm</h2>
<p>The original 386 was built on a process called CHMOS-III that had 1.5 µm features (specifically the gate channel length for a transistor).
Around 1987, Intel moved to an improved process called CHMOS-IV, with 1 µm features,
permitting a considerably smaller die for the 386.
However, shrinking the layout wasn&#39;t a simple mechanical process. Instead, many changes were
made to the chip, as shown in the comparison diagram below.
Most visibly, the Instruction Decode Unit and the Protection Unit in the center-right are
horizontal in the smaller die, rather than vertical.
The standard-cell logic (discussed later) is considerably more dense, probably due to
improved layout algorithms.
The data path (left) was highly optimized in the original so it remained essentially unchanged, but smaller.
One complication is that the bond pads around the border needed to remain the same size so bond wires could be attached.
To fit the pads around the smaller die, many of the pads are staggered.
Because different parts of the die shrank differently, the blocks no longer fit together as compactly, creating wasted space at the bottom of the die.
For some reason, the numerous initials on the original 386 die were removed.
Finally, the new die was labeled 80C386I with a copyright date of 1985, 1987; it is unclear what &#34;C&#34; and &#34;I&#34; indicate.</p>
<p><a href="https://static.righto.com/images/386-versions/shrink.jpg"><img alt="Comparison of the 1.5 µm die and the 1 µm die at the same scale. Photos courtesy of Antoine Bercovici." height="442" src="https://static.righto.com/images/386-versions/shrink-w700.jpg" title="Comparison of the 1.5 µm die and the 1 µm die at the same scale. Photos courtesy of Antoine Bercovici." width="700"/></a></p><p>Comparison of the 1.5 µm die and the 1 µm die at the same scale. Photos courtesy of Antoine Bercovici.</p>
<p>The change from 1.5 µm to 1 µm may not sound significant, but it reduced the die size by
60%.
This allowed more dies on a wafer, substantially dropping the manufacturing cost.<span id="fnref:wafer"><a href="#fn:wafer">12</a></span>
The strategy of shrinking a processor to a new process before designing a new microarchitecture
for the process became Intel&#39;s <a href="https://retailedge.intel.com/content/pdf/asmo/201303art_computerpoweruser.pdf">tick-tock</a> strategy.</p>
<h2>The 386 SX</h2>
<p>In 1988, Intel introduced the 386 SX processor, the low-cost version of the 386,
with a 16-bit bus instead of a 32-bit bus.
(This is reminiscent of the 8088 processor with an 8-bit bus versus the 8086 processor
with a 16-bit bus.)
According to the <a href="https://archive.computerhistory.org/resources/access/text/2015/06/102702019-05-01-acc.pdf#page=25">386 oral history</a>,
the cost of the original 386 die decreased to the point where the chip&#39;s package cost about as
much as the die.
By reducing the number of pins, the 386 SX could be put in a one-dollar plastic package
and sold for a considerably reduced price.
The SX allowed Intel to segment the market, moving low-end customers <a href="https://books.google.com/books?id=fSMW_RgWwIgC&amp;lpg=PT95&amp;pg=PT94#v=onepage&amp;q&amp;f=false">from the 286</a> to the 386 SX, while preserving the
higher sales price of the original 386, now called the DX.<span id="fnref:286"><a href="#fn:286">13</a></span>
<a href="https://www.nytimes.com/1988/06/21/science/personal-computers-new-chip-less-cost-for-power.html">In 1988</a>, Intel sold the 386 SX for $219, at least $100 less than the 386 DX.
A complete SX computer could be $1000 cheaper than a similar DX model.</p>
<!-- p25 Shrink of 386.-->
<!-- p25 claim that the 8-bit bus of the 8088 was what tipped the IBM PC processor choice to Intel -->

<p>For compatibility with older 16-bit peripherals, the original 386 was designed to support a mixture of 16-bit and 32-bit buses, dynamically
switching on a cycle-by-cycle basis if needed.
Because 16-bit support was built into the 386, the 386 SX didn&#39;t require much design work.
(Unlike the 8088, which required a redesign of the 8086&#39;s bus interface unit.)</p>
<p>The 386 SX was built at both 1.5 µm and 1 µm.
The diagram below compares the two sizes of the 386 SX die.
These photos may look identical to the 386 DX photos in the previous section,
but close examination shows a few differences.
Since the 386 SX uses fewer pins, it has fewer bond pads, eliminating the staggered pads of
the shrunk 386 DX.
There are a few differences at the bottom of the chip, with wiring in much of the 386 DX&#39;s
wasted space.</p>
<p><a href="https://static.righto.com/images/386-versions/dies-sx.jpg"><img alt="Comparison of two dies for the 386 SX. Photos courtesy of Antoine Bercovici." height="462" src="https://static.righto.com/images/386-versions/dies-sx-w700.jpg" title="Comparison of two dies for the 386 SX. Photos courtesy of Antoine Bercovici." width="700"/></a></p><p>Comparison of two dies for the 386 SX. Photos courtesy of Antoine Bercovici.</p>
<p>Comparing the two SX revisions,
the larger die is labeled &#34;80P9&#34;; Intel&#39;s internal name for the chip was &#34;P9&#34;, using their
confusing series of <a href="https://www.righto.com/search?q=i960#fn:processor-numbers">P numbers</a>.
The shrunk die is labeled &#34;80386SX&#34;, which makes more sense.
The larger die is copyright 1985, 1987, while the shrunk die (which should be newer) is copyright 1985 for some reason.
The larger die has mostly the same initials as the DX, with a few changes.
The shrunk die has about 21 sets of initials.</p>
<h2>The 386 SL die</h2>
<p>The 386 SL (1990) was a major extension to the 386, combining a 386 core and other functions on one chip to save power and space.
Named &#34;SuperSet&#34;, it was designed to corner the notebook PC market.<span id="fnref:superset"><a href="#fn:superset">14</a></span>
The 386 SL chip included an ISA bus controller, power management logic, a cache controller 
for an external cache, and the main memory controller.</p>
<p>Looking at the die photo below, the 386 core itself takes up about 1/4 of the SL&#39;s die.
The 386 core is very close to the standard 386 DX, but there are a few visible differences.
Most visibly, the bond pads and pin drivers have been removed from the core.
There are also some circuitry changes. For instance, the 386 SL core supports the <a href="https://websrv.cecs.uci.edu/~papers/mpr/MPR/ARTICLES/060805.PDF">System Management
Mode</a>, which suspends normal execution, allowing power management and other low-level hardware
tasks to be performed outside the regular operating system.
System Management Mode is now a standard part of the x86 line, but it was introduced in the 386 SL.</p>
<!-- 386 SL system management patent https://patents.google.com/patent/US5175853A/en?oq=+US5175853A -->

<p><a href="https://static.righto.com/images/386-versions/386sl-die-labeled.jpg"><img alt="The 386 SL die with functional blocks labeled.  Die photo courtesy of Antoine Bercovici." height="606" src="https://static.righto.com/images/386-versions/386sl-die-labeled-w600.jpg" title="The 386 SL die with functional blocks labeled.  Die photo courtesy of Antoine Bercovici." width="600"/></a></p><p>The 386 SL die with functional blocks labeled.  Die photo courtesy of Antoine Bercovici.</p>
<p>In total, the 386 SL contains 855,000 transistors,<span id="fnref:quickref"><a href="#fn:quickref">15</a></span> over 3 times as many as the regular 386 DX.
The cache tag RAM takes up a lot of space and transistors.
The cache data itself is external; this on-chip circuitry just manages the cache.
The other new components are largely implemented with standard-cell logic (discussed below); this is visible as uniform stripes
of circuitry, most clearly in the ISA bus controller.</p>
<h2>A brief history of the 386</h2>
<p>From the modern perspective, it seems obvious for Intel to extend the x86 line from the
286 to the 386, while keeping backward compatibility.
But at the time, this path was anything but clear.
This history starts in the late 1970s, when Intel decided to build a &#34;micromainframe&#34; processor, an advanced 32-bit
processor for object-oriented programming that had objects, interprocess communication,
and memory protection implemented in the CPU.
This overly ambitious project fell behind schedule, so Intel created a stopgap processor to
sell until the micromainframe processor was ready.
This stopgap processor was the 16-bit 8086 processor (1978).</p>
<p>In 1981, IBM decided to use the Intel 8088 (an 8086 variant) in the IBM Personal Computer (PC),
but Intel did not realize the importance of this at the time.
Instead, Intel was focused on their
micromainframe processor, also released in 1981 as the iAPX 432, but this became
&#34;one of the great disaster stories of modern computing&#34; as the <a href="https://archive.nytimes.com/www.nytimes.com/library/tech/98/04/biztech/articles/05merced.html">New York Times</a> called it.
Intel then reimplemented the ideas of the
ill-fated iAPX 432 on top of a RISC architecture, creating the more successful <a href="https://www.righto.com/2023/07/the-complex-history-of-intel-i960-risc.html">i960</a>. </p>
<p>Meanwhile, things weren&#39;t going well at first for the 286 processor, the follow-on to the 8086<span id="fnref:186"><a href="#fn:186">16</a></span>.
Bill Gates and others called its design &#34;brain-damaged&#34;. 
IBM was unenthusiastic about the 286 for their own reasons.<span id="fnref:ibm-286"><a href="#fn:ibm-286">17</a></span>
As a result, the 386 project was a low priority for Intel and the 386 team felt that it was the
&#34;stepchild&#34;; internally, the 386 was pitched as another <a href="https://archive.computerhistory.org/resources/text/Oral_History/Intel_386_Business_Strategy/102701962.05.01.pdf#page=14">stopgap</a>, not Intel&#39;s &#34;official&#34; 32-bit processor.</p>
<p>Despite the lack of corporate enthusiasm, the 386 team came up with two proposals to
extend the 286 to a 32-bit architecture.
The first was a minimal approach to extend the existing registers and
address space to 32 bits.
The more ambitious proposal would add more registers and create a 32-bit instruction set that
was significantly different from the 8086&#39;s 16-bit instruction set.
At the time, the IBM PC was still relatively new, so the importance of the installed
base of software wasn&#39;t obvious; software compatibility was viewed as a &#34;nice to have&#34; feature rather than essential.
After much debate, the decision was made around the end of 1982 to go with the minimal proposal,
but supporting both segments and flat addressing, while keeping compatibility with the 286.</p>
<!--
A key design challenge was if it was possible to be compatible with the 8086's segment-based addressing, while
supporting the flat 32-bit address space that would support Unix well.
-->

<p>By 1984, though, the PC industry was booming and the 286 was proving to be a success.
This produced enormous political benefits for the 386 team, who saw the project change from
&#34;stepchild&#34; to &#34;king&#34;. <!-- p17 -->
Intel introduced the 386 in 1985, which was otherwise
&#34;a miserable year for Intel and the rest of the semiconductor industry,&#34;
as Intel&#39;s <a href="https://www.intel.com/content/dam/doc/report/history-1985-annual-report.pdf">annual report</a> put it.
Due to an industry-wide business slowdown, Intel&#39;s net income &#34;essentially disappeared.&#34;
Moreover, facing heavy competition from Japan, Intel dropped out of the DRAM business, a crushing blow
for a company that got its start in the memory industry.
Fortunately, the 386 would change everything.</p>
<p>Given IBM&#39;s success with the IBM PC, Intel was puzzled that IBM wasn&#39;t interested in the 386 processor, but IBM had a strategy of their own.<span id="fnref:ibm"><a href="#fn:ibm">18</a></span>
By this time, the IBM PC was being cloned by many competitors, but IBM had a plan to regain
control of the PC architecture and thus the market: in 1987, IBM introduced the PS/2 line.
These new computers ran the OS/2 operating system instead of Windows and used the proprietary Micro Channel architecture.<span id="fnref:ps2"><a href="#fn:ps2">19</a></span>
IBM used multiple engineering and legal strategies to make cloning the PS/2 slow, expensive, and risky,
so IBM expected they could take back the market from the clones.</p>
<!-- https://doi.org/10.1109/CMPCON.1988.4889 -->

<p>Compaq took the risky approach of ignoring IBM and following their own architectural direction.<span id="fnref:compaq"><a href="#fn:compaq">20</a></span>
Compaq introduced the high-end Deskpro 386 line in <a href="https://www.nytimes.com/1986/09/10/business/company-news-compaq-introduces-more-powerful-pc.html">September 1986</a>, becoming the first major company to build 386-based computers.
An &#34;executive&#34; system, the Deskpro 386 model 40 had a 40-megabyte hard drive and sold for $6449 (over $15,000 in current dollars).
Compaq&#39;s <a href="https://www.nytimes.com/1987/09/20/business/the-executive-computer-compaq-s-gamble-on-an-advanced-chip-pays-off.html">gamble paid off</a>
and the Deskpro 386 was a rousing success.</p>
<!--
![The Compaq Deskpro 386. From a <a href="https://archive.org/details/personalcomputercompaq/page/n4/mode/1up">Compaq brochure</a>.](deskpro-386.jpg "w400")
-->

<p><a href="https://static.righto.com/images/386-versions/compaq-386.jpg"><img alt="The Compaq Deskpro 386 in front of the 386 processor (not to scale). From PC Tech Journal, 1987. Curiously, the die image of the 386 has been mirrored, as can be seen both from the positions of the microcode ROM and instruction decoder at the top as well as from the position of the cut corner of the package." height="548" src="https://static.righto.com/images/386-versions/compaq-386-w400.jpg" title="The Compaq Deskpro 386 in front of the 386 processor (not to scale). From PC Tech Journal, 1987. Curiously, the die image of the 386 has been mirrored, as can be seen both from the positions of the microcode ROM and instruction decoder at the top as well as from the position of the cut corner of the package." width="400"/></a></p><p>The Compaq Deskpro 386 in front of the 386 processor (not to scale). From <a href="https://archive.org/details/PC_Tech_Journal_vol05_n03/page/n51/mode/2up">PC Tech Journal</a>, 1987. Curiously, the die image of the 386 has been mirrored, as can be seen both from the positions of the microcode ROM and instruction decoder at the top as well as from the position of the cut corner of the package.</p>
<!-- BYTE Technical implications of PS/2 https://www.ardent-tool.com/docs/scans/BYTE_1987_10_Technical_Implications_of_PS2.pdf -->

<p>As for IBM, the PS/2 line was largely unsuccessful and failed to become the standard.
Rather than
regaining control over the PC,
&#34;IBM lost control of the PC standard in 1987 when it introduced its PS/2 line of systems.&#34;<span id="fnref:logic"><a href="#fn:logic">21</a></span>
IBM exited the PC market in <a href="https://www.smh.com.au/business/ibms-exit-from-pc-business-seen-as-turning-point-20041209-gdka6w.html">2004</a>, selling the business to Lenovo.
One slightly hyperbolic <a href="https://amzn.to/3ZyK7nq">book title</a> summed it up: &#34;Compaq Ended IBM&#39;s PC Domination and Helped Invent Modern Computing&#34;.
The 386 was a huge moneymaker for Intel, leading to Intel&#39;s first billion-dollar quarter in 1990.
It cemented the importance of the x86 architecture, not just for Intel but for the entire
computing industry, dominating the market up to the present day.</p>
<h2>How the 386 was designed</h2>
<p>The design process of the 386 is interesting because it illustrates Intel&#39;s migration
to automated design systems and heavier use of simulation.<span id="fnref:design-and-test"><a href="#fn:design-and-test">23</a></span>
At the time, Intel was behind the industry in its use of tools so the leaders of the 386
realized that more automation would be necessary to build a complex chip like the 386 on schedule.
By making a large investment in automated tools, the 386 team completed the design ahead of schedule.
Along with proprietary CAD tools, the team made heavy use of standard Unix tools such as <code>sed</code>, <code>awk</code>, <code>grep</code>, and <code>make</code> to manage the various design databases.</p>
<p>The 386 posed new design challenges compared to the previous 286 processor.
The 386 was much more complex, with twice the transistors.
But the 386 also used fundamentally different circuitry.
While the 286 and earlier processors were built from NMOS transistors, the 386 moved to
CMOS (the technology still used today). Intel&#39;s CMOS process was called CHMOS-III
(complementary high-performance metal-oxide-silicon) and had a feature size of 1.5 µm.
CHMOS-III was based on Intel&#39;s HMOS-III process (used for the 286), but extended to
CMOS. Moreover, the CHMOS process provided two layers of metal instead of one, changing
how signals were routed on the chip and requiring new design techniques.</p>
<p>The diagram below shows a cross-section through a CHMOS-III circuit, with an NMOS
transistor on the left and a PMOS transistor on the right.
Note the jagged three-dimensional topography that is formed as layers cross each other
(unlike modern polished wafers).
This resulted in the
&#34;<a href="https://archive.computerhistory.org/resources/access/text/2015/06/102702019-05-01-acc.pdf#page=21">forbidden gap</a>&#34; problem that caused difficulty for the 386 team.
Specifically second-layer metal (M2) could be close to the first-layer metal (M1) or it could be far apart,
but an in-between distance would cause problems: the forbidden gap.
If the metal layer crossed in the &#34;forbidden gap&#34;, the metal could crack and whiskers of metal
would touch, causing the chip to fail.
These problems reduced the yield of the 386.</p>
<p><a href="https://static.righto.com/images/386-versions/process-cross-section.jpg"><img alt="A cross-section of circuitry formed with the CHMOS-III process. From A double layer metal CHMOS III technology." height="203" src="https://static.righto.com/images/386-versions/process-cross-section-w500.jpg" title="A cross-section of circuitry formed with the CHMOS-III process. From A double layer metal CHMOS III technology." width="500"/></a></p>
<!-- -->

<p>The design of the 386 proceeded both top-down, starting with the architecture definition,
and bottom-up, designing standard cells and other basic circuits at the transistor level.
The processor&#39;s microcode, the software that controlled the chip, was a fundamental component.
It was designed with two CAD tools: an assembler and microcode rule checker.
The high-level design of the chip (register-level RTL)
was created and refined until clock-by-clock and phase-by-phase timing were represented.
The RTL was programmed in <a href="http://www.bitsavers.org/pdf/xidak/mainsail_v12/Mainsail_Tutorial_Volume_1_Mar89.pdf">MAINSAIL</a>, a portable Algol-like language based
on SAIL (Stanford Artificial Intelligence Language).
Intel used a proprietary simulator called Microsim to simulate the RTL, stating that
full-chip RTL simulation was &#34;the single most important simulation model of the 80386&#34;.</p>
<p>The next step was to convert this high-level design into a detailed logic design, specifying
the gates and other circuitry
using Eden, a proprietary schematics-capture system.
Simulating the logic design required
a dedicated IBM 3083 mainframe that compared it against the
RTL simulations.
Next, the circuit design phase created the transistor-level design.
The chip layout was performed on <a href="https://www.shapr3d.com/history-of-cad/applicon">Applicon</a> and Eden graphics systems.
The layout started with critical blocks such as the ALU and barrel shifter. 
To meet the performance requirements, the TLB (translation lookaside
buffer) for the paging mechanism required a creative design, as did the binary adders.</p>
<p><a href="https://static.righto.com/images/386-versions/standard-cell-colored.jpg"><img alt="Examples of standard cells used in the 386. From &#34;Automatic Place and Route Used on the 80386&#34; by Joseph Krauskopf and Pat Gelsinger. I have added color." height="205" src="https://static.righto.com/images/386-versions/standard-cell-colored-w700.jpg" title="Examples of standard cells used in the 386. From &#34;Automatic Place and Route Used on the 80386&#34; by Joseph Krauskopf and Pat Gelsinger. I have added color." width="700"/></a></p><p>Examples of standard cells used in the 386. From &#34;Automatic Place and Route Used on the 80386&#34; by Joseph Krauskopf and Pat Gelsinger, Intel Technology Journal spring 1986. I have added color.</p>
<p>The &#34;random&#34; (unstructured) logic was implemented with standard cells, rather than the
transistor-by-transistor design of earlier processors.
The idea of standard cells is to have fixed blocks of circuitry (above) for logic gates, flip-flops,
and other basic functions.<span id="fnref:standard-cell-library"><a href="#fn:standard-cell-library">24</a></span>
These cells are arranged in rows by software to implement the specified logic description.
The space between the rows is used as a wiring channel for connections between the cells.
The disadvantage of a standard cell layout is that it generally takes up more space than
an optimized hand-drawn layout, but it is much faster to create and easier to modify.</p>
<p>These standard cells are visible in the die as regular rows of circuitry.
Intel used the <a href="https://ee.sharif.edu/~asic/References/Physical%20Design%20Papers/timberwolf-P2.pdf">TimberWolf</a> automatic placement and routing package, which used simulated annealing to
optimize the placement of cells.
TimberWolf was built by a Berkeley <a href="http://www.aycinena.com/index2/index3/archive/uw%20-%20sechen.html">grad student</a>; one 386 engineer said,
&#34;If management had known that we were using a tool by some grad
student as the key part of the methodology, they would never have let us use it. &#34;
Automated layout was a new thing at Intel; using it improved the schedule, but 
the lower density raised the risk that the chip would be too large.</p>
<p><a href="https://static.righto.com/images/386-versions/standard-cells.jpg"><img alt="Standard cells in the 386. Each row consists of numerous standard cells packed together. Each cell is a simple circuit such as a logic gate or flip flop. The wide wiring channels between the rows hold the wiring that connects the cells. This block of circuitry is in the bottom center of the chip." height="308" src="https://static.righto.com/images/386-versions/standard-cells-w350.jpg" title="Standard cells in the 386. Each row consists of numerous standard cells packed together. Each cell is a simple circuit such as a logic gate or flip flop. The wide wiring channels between the rows hold the wiring that connects the cells. This block of circuitry is in the bottom center of the chip." width="350"/></a></p><p>Standard cells in the 386. Each row consists of numerous standard cells packed together. Each cell is a simple circuit such as a logic gate or flip flop. The wide wiring channels between the rows hold the wiring that connects the cells. This block of circuitry is in the bottom center of the chip.</p>
<p>The data path consists of the registers, ALU (Arithmetic Logic Unit), barrel shifter,
and multiply/divide unit that process the 32-bit data.
Because the data path is critical to the performance of the system,
it was laid out by hand using a CALMA system.
The designers could optimize the layout, taking advantage of regularities in the circuitry,
optimizing the shape and size of each transistor and fitting them together like puzzle pieces.
The data path is visible on the left side of the die, forming orderly 32-bit-wide rectangles
in contrast to the tangles of logic next to it.</p>
<p>Once the transistor-level layout was complete,
Intel&#39;s Hierarchical Connectivity Verification System checked that the final layout matched
the schematics and adhered to the process design rules.
The 386 set an Intel speed record, taking just 11 days from completing the layout to &#34;tapeout&#34;,
when the chip data is sent on magnetic tape to the mask fabrication company.
(The tapeout team was led by Pat Gelsinger, who later became CEO of Intel.)
After the glass masks were created using
an electron-beam process, Intel&#39;s &#34;Fab 3&#34; in Livermore (the first to wear the <a href="https://www.elivermore.com/photos/intel_fab3.htm">bunnysuits</a>) produced the 386 silicon wafers.</p>
<p>Chip designers like to claim that their chip worked the first time, but that was not
the case for the 386.  <!-- p19 -->
When the team received the first silicon for the 386, they ran a trivial do-nothing test
program, &#34;NoOp, NoOp, Halt&#34;, and it failed.
Fortunately, they found a small fix to a PLA (Programmable Logic Array). Rather than create new masks, they were able to
patch the existing mask with ion milling and get new wafers quickly. <!-- p20 -->
These wafers worked well enough that they could start the long cycles of debugging and fixing.</p>
<p>Once the processor was released, the problems weren&#39;t over.<span id="fnref:bugs"><a href="#fn:bugs">25</a></span>
Some early 386 processors had a <a href="https://groups.google.com/g/comp.arch/c/qm7FVR_YV4A/m/VKR47yLoUdEJ">32-bit multiply problem</a>, where some arguments would
unpredictably produce the wrong results under particular temperature/voltage/frequency conditions.
(This is unrelated to the famous <a href="https://en.wikipedia.org/wiki/Pentium_FDIV_bug">Pentium FDIV bug</a> that cost Intel $475 million.)
The root cause was a layout problem, not a logic problem; they didn&#39;t allow enough margin to
handle the worst case data in combination with manufacturing process and environment factors.
This tricky problem didn&#39;t show up in simulation or chip verification, but was only found in
stress testing.
Intel sold the faulty processors, but marked them as only valid for 16-bit software, while marking the
good processors with a double sigma, as seen below.<span id="fnref:xbts"><a href="#fn:xbts">26</a></span>
This led to embarrassing headlines such as <a href="https://archive.org/details/bub_gb_mDsEAAAAMBAJ/page/n5/mode/1up?view=theater">Some 386 Systems Won&#39;t Run 32-Bit Software, Intel Says</a>.
The multiply bug also caused a shortage of 386 chips in
<a href="https://books.google.com/books?id=u5dYmhF7jc4C&amp;lpg=PA96&amp;pg=PA96#v=onepage&amp;q&amp;f=false">1987</a>
and <a href="https://books.google.com/books?id=Av0xuNrEJakC&amp;lpg=RA6-PT4&amp;pg=RA6-PT4#v=onepage&amp;q&amp;f=false">1988</a> as Intel redesigned the chip to fix the bug.
Overall, the 386 issues probably weren&#39;t any worse than other processors and the problems were soon
forgotten.</p>
<p><a href="https://static.righto.com/images/386-versions/steppings.jpg"><img alt="Bad and good versions of the 386. Note the labels on the bottom line. Photos (L), (R) by Thomas Nguyen, (CC BY-SA 4.0)." height="257" src="https://static.righto.com/images/386-versions/steppings-w500.jpg" title="Bad and good versions of the 386. Note the labels on the bottom line. Photos (L), (R) by Thomas Nguyen, (CC BY-SA 4.0)." width="500"/></a></p><p>Bad and good versions of the 386. Note the labels on the bottom line. Photos (<a href="https://commons.wikimedia.org/wiki/File:Intel_A80386-16_16_bit_SW_Only.jpg">L</a>), (<a href="https://commons.wikimedia.org/wiki/File:Intel_A80386-16_%CE%A3%CE%A3.jpg">R</a>) by Thomas Nguyen, (<a href="https://creativecommons.org/licenses/by-sa/4.0/deed.en">CC BY-SA 4.0</a>).</p>

<p><a href="https://static.righto.com/images/386-versions/wall.jpg"><img alt="A 17-foot tall plot of the 386. The datapath is on the left and the microcode is in the lower right. It is unclear if this is engineering work or an exhibit at MOMA. Image spliced together from the 1985 annual report." height="621" src="https://static.righto.com/images/386-versions/wall-w600.jpg" title="A 17-foot tall plot of the 386. The datapath is on the left and the microcode is in the lower right. It is unclear if this is engineering work or an exhibit at MOMA. Image spliced together from the 1985 annual report." width="600"/></a></p><p>A 17-foot tall plot of the 386. The datapath is on the left and the microcode is in the lower right. It is unclear if this is engineering work or an exhibit at MOMA. Image spliced together from the <a href="https://www.intel.com/content/dam/doc/report/history-1985-annual-report.pdf">1985 annual report</a>.</p>
<p>The 386 processor was a key turning point for Intel.
Intel&#39;s previous processors sold very well, but this was largely due to heavy marketing
(&#34;<a href="https://www.computerhistory.org/collections/catalog/102746836">Operation Crush</a>&#34;) and the
good fortune to be selected for the IBM PC.
Intel was technologically behind the competition, especially Motorola.
Motorola had introduced the 68000 processor in 1979, starting a powerful line of
(more-or-less) 32-bit processors.
Intel, on the other hand, lagged with the &#34;brain-damaged&#34; 16-bit 286 processor in 1982.
Intel was also slow with the transition to CMOS; Motorola had moved to CMOS in 1984 with the 68020.</p>
<p>The 386 provided the necessary technological boost for Intel, moving to a 32-bit architecture,
transitioning to CMOS, and fixing the 286&#39;s memory model and multitasking limitations, while
maintaining compatibility with the earlier x86 processors.
The overwhelming success of the 386 solidified the dominance of the x86 and Intel, and put
other processor manufacturers on the defensive.
Compaq used the 386 to take over PC architecture leadership from IBM, leading to the success of Compaq, Dell, and other
companies, while IBM eventually departed the PC market entirely.
Thus, the 386 had an oversized effect on the computer industry, shaping the winners and losers for decades.</p>
<!--
Moreover, as a result of the 386, IBM lost control of the IBM PC architecture to Compaq.
-->

<p>I plan to write more about the 386, so 
follow me on Twitter <a href="https://twitter.com/kenshirriff">@kenshirriff</a> or <a href="http://www.righto.com/feeds/posts/default">RSS</a> for updates.
I&#39;m also on Mastodon occasionally as <a href="https://oldbytes.space/@kenshirriff">@<span data-cfemail="58333d362b30312a2a313e3e1837343c3a212c3d2b762b28393b3d">[email protected]</span></a>.
Acknowledgements: The die photos are courtesy of Antoine Bercovici; you should follow him on Twitter as <a href="https://twitter.com/Siliconinsid">@Siliconinsid</a>.<span id="fnref:s-specs"><a href="#fn:s-specs">27</a></span>
Thanks to Pat Gelsinger and Roxanne Koester for providing helpful papers.</p>
<h2>Notes and references</h2>


</div></div>
  </body>
</html>
