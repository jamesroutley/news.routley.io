<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/QuPengfei/Technical-Overview-Of-AV1-Spec">Original</a>
    <h1>Breakdown of AV1 Video Codec</h1>
    
    <div id="readability-page-1" class="page"><div data-target="readme-toc.content">
            <article itemprop="text">

<p dir="auto">AV1 (AOMedia Video Codec 1.0) evolved on the basis of VP9 (Google), Thor (Cisco)
and Daala (Mozila) under the AOM (Alliance for Open Media). It includes a number
of enhancement and the new tools that have been added to improve the coding
efficiency. The new tools that are added so far include 4 main aspects:
prediction, transform, in-loop filter and entropy encoder. This document
provides a snapshot of the coding tools in the current finalized version (on
March, 2018) of AV1 spec.</p>

<p dir="auto">According to the AOM web page, AV1 is designed with the following feature.</p>
<ul dir="auto">
<li>
<p dir="auto">Royally free</p>
</li>
<li>
<p dir="auto">Scales to any modern device at any bandwidth</p>
</li>
<li>
<p dir="auto">For use in both commercial and non-commercial content, including
user-generated content</p>
</li>
<li>
<p dir="auto">Developed for the internet and related applications and services-from
browsers and streaming to videoconferencing services</p>
</li>
<li>
<p dir="auto">Designed with a low computational footprint and optimized for hardware</p>
</li>
<li>
<p dir="auto">Bringing features like 4k UHD, HDR, and WCG to real-time video</p>
</li>
</ul>

<p dir="auto">Profiles and levels specify restrictions on the capabilities needed to decode
the bitstreams. The profile specifies the bit depth and subsampling formats
supported, while the level defines resolution and performance characteristics.
By now levels is still under discussion and there is no more details.</p>
<p dir="auto">AV1 support the three named profiles as the table list.</p>
<table>
<thead>
<tr>
<th>Profile</th>
<th>Bit depth</th>
<th>Monochrome support</th>
<th>Chroma subsampling</th>
<th>Name</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>8/10</td>
<td>Yes</td>
<td>4:2:0</td>
<td>Main</td>
</tr>
<tr>
<td>1</td>
<td>8/10</td>
<td>No</td>
<td>4:4:4</td>
<td>High</td>
</tr>
<tr>
<td>2</td>
<td>8/10</td>
<td>Yes</td>
<td>4:2:2</td>
<td>Professional</td>
</tr>
<tr>
<td>2</td>
<td>12</td>
<td>Yes</td>
<td>4:2:0, 4:2:2, 4:4:4</td>
<td>Professional</td>
</tr>
</tbody>
</table>
<p dir="auto">Table 1. AV1 Profile</p>

<h2 tabindex="-1" dir="auto"><a id="user-content-basic-coding-block" aria-hidden="true" tabindex="-1" href="#basic-coding-block"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Basic Coding block</h2>
<p dir="auto">AV1 support the larger super block size, which is up to 128x128 super block is
allowed. It supports from 128x128 down to 4x4 coding block. Each 4x4 luma block
is allowed to independently select inter or intra mode, its reference mode, and
interpolation filter type. For Chroma, 2x2 block size is allowed but still 4x4
transform block size is used.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-basic-prediction-block" aria-hidden="true" tabindex="-1" href="#basic-prediction-block"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Basic Prediction Block</h2>
<p dir="auto">AV1 support up to 10 partition type. The size of partition unit is allowed down
to 4x4 and totally there are 24 types of block size.</p>
<table>
<thead>
<tr>
<th>Partition index</th>
<th>Type of partition</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>PARTITION_NONE</td>
</tr>
<tr>
<td>1</td>
<td>PARTITION_HORZ</td>
</tr>
<tr>
<td>2</td>
<td>PARTITION_VERT</td>
</tr>
<tr>
<td>3</td>
<td>PARTITION_SPLIT</td>
</tr>
<tr>
<td>4</td>
<td>PARTITION_HORZ_A</td>
</tr>
<tr>
<td>5</td>
<td>PARTITION_HORZ_B</td>
</tr>
<tr>
<td>6</td>
<td>PARTITION_VERT_A</td>
</tr>
<tr>
<td>7</td>
<td>PARTITION_VERT_B</td>
</tr>
<tr>
<td>8</td>
<td>PARTITION_HORZ_4</td>
</tr>
<tr>
<td>9</td>
<td>PARTITION_VERT_4</td>
</tr>
</tbody>
</table>
<p dir="auto">Table 2. Type of Block partition</p>
<table>
<thead>
<tr>
<th>Index</th>
<th>Partition Block size</th>
<th>Index</th>
<th>Partition Block size</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>BLOCK_4X4</td>
<td>12</td>
<td>BLOCK_64X64</td>
</tr>
<tr>
<td>1</td>
<td>BLOCK_4X8</td>
<td>13</td>
<td>BLOCK_64X128</td>
</tr>
<tr>
<td>2</td>
<td>BLOCK_8X4</td>
<td>14</td>
<td>BLOCK_128X64</td>
</tr>
<tr>
<td>3</td>
<td>BLOCK_8X8</td>
<td>15</td>
<td>BLOCK_128X128</td>
</tr>
<tr>
<td>4</td>
<td>BLOCK_8X16</td>
<td>16</td>
<td>BLOCK_4X16</td>
</tr>
<tr>
<td>5</td>
<td>BLOCK_16X8</td>
<td>17</td>
<td>BLOCK_16X4</td>
</tr>
<tr>
<td>6</td>
<td>BLOCK_16X16</td>
<td>18</td>
<td>BLOCK_8X32</td>
</tr>
<tr>
<td>7</td>
<td>BLOCK_16X32</td>
<td>19</td>
<td>BLOCK_32X8</td>
</tr>
<tr>
<td>8</td>
<td>BLOCK_32X16</td>
<td>20</td>
<td>BLOCK_16X64</td>
</tr>
<tr>
<td>9</td>
<td>BLOCK_32X32</td>
<td>21</td>
<td>BLOCK_64X16</td>
</tr>
<tr>
<td>10</td>
<td>BLOCK_32X64</td>
<td>22</td>
<td>BLOCK_32X128</td>
</tr>
<tr>
<td>11</td>
<td>BLOCK_64X32</td>
<td>23</td>
<td>BLOCK_128X32</td>
</tr>
</tbody>
</table>
<p dir="auto">Table 3. Size of Block Partition</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-basic-transform-block" aria-hidden="true" tabindex="-1" href="#basic-transform-block"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Basic Transform Block</h2>
<p dir="auto">Both square and rectangle transform block size is supported in AV1. There are
total 19 transform block size.</p>
<table>
<thead>
<tr>
<th>Index</th>
<th>TxSize</th>
<th>Index</th>
<th>TxSize</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>TX_4X4</td>
<td>10</td>
<td>TX_32X16</td>
</tr>
<tr>
<td>1</td>
<td>TX_8X8</td>
<td>11</td>
<td>TX_32X64</td>
</tr>
<tr>
<td>2</td>
<td>TX_16X16</td>
<td>12</td>
<td>TX_64X32</td>
</tr>
<tr>
<td>3</td>
<td>TX_32X32</td>
<td>13</td>
<td>TX_4X16</td>
</tr>
<tr>
<td>4</td>
<td>TX_64X64</td>
<td>14</td>
<td>TX_16X4</td>
</tr>
<tr>
<td>5</td>
<td>TX_4X8</td>
<td>15</td>
<td>TX_8X32</td>
</tr>
<tr>
<td>6</td>
<td>TX_8X4</td>
<td>16</td>
<td>TX_32X8</td>
</tr>
<tr>
<td>7</td>
<td>TX_8X16</td>
<td>17</td>
<td>TX_16X64</td>
</tr>
<tr>
<td>8</td>
<td>TX_16X8</td>
<td>18</td>
<td>TX_64X16</td>
</tr>
<tr>
<td>9</td>
<td>TX_16X32</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<blockquote>
<p dir="auto">Table 4. Size of Transform Block</p>
</blockquote>

<p dir="auto">Intra Prediction in AV1 expends largely compared to VP9. Here is snapshot of
Intra Mode.</p>
<table>
<thead>
<tr>
<th>Index</th>
<th>Intra mode</th>
<th>AV1</th>
<th>VP9</th>
<th>Comments</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>DC_PRED</td>
<td>X</td>
<td>X</td>
<td></td>
</tr>
<tr>
<td>1</td>
<td>V_PRED</td>
<td>X</td>
<td>X</td>
<td>AV1 support 7 kind of mode based on this mode</td>
</tr>
<tr>
<td>2</td>
<td>H_PRED</td>
<td>X</td>
<td>X</td>
<td>AV1 support 7 kind of mode based on this mode</td>
</tr>
<tr>
<td>3</td>
<td>D45_PRED</td>
<td>X</td>
<td>X</td>
<td>AV1 support 7 kind of mode based on this mode</td>
</tr>
<tr>
<td>4</td>
<td>D135_PRED</td>
<td>X</td>
<td>X</td>
<td>AV1 support 7 kind of mode based on this mode</td>
</tr>
<tr>
<td>5</td>
<td>D113_PRED</td>
<td>X</td>
<td>X</td>
<td>AV1 support 7 kind of mode based on this mode</td>
</tr>
<tr>
<td>6</td>
<td>D157_PRED</td>
<td>X</td>
<td>X</td>
<td>AV1 support 7 kind of mode based on this mode</td>
</tr>
<tr>
<td>7</td>
<td>D203_PRED</td>
<td>X</td>
<td>X</td>
<td>AV1 support 7 kind of mode based on this mode</td>
</tr>
<tr>
<td>8</td>
<td>D67_PRED</td>
<td>X</td>
<td>X</td>
<td>AV1 support 7 kind of mode based on this mode</td>
</tr>
<tr>
<td>9</td>
<td>SMOOTH_PRED</td>
<td>X</td>
<td></td>
<td></td>
</tr>
<tr>
<td>10</td>
<td>SMOOTH_V_PRED</td>
<td>X</td>
<td></td>
<td></td>
</tr>
<tr>
<td>11</td>
<td>SMOOTH_H_PRED</td>
<td>X</td>
<td></td>
<td></td>
</tr>
<tr>
<td>12</td>
<td>TM_PRED(PAETH_PRED)</td>
<td>X</td>
<td>X</td>
<td>AV1 replace TM_PRED with PAETH_PRED</td>
</tr>
<tr>
<td>13</td>
<td>Palette Mode</td>
<td>X</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p dir="auto">Table 5. Summary of Intra Mode between AV1 and VP9</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-directional-intra-prediction-mode" aria-hidden="true" tabindex="-1" href="#directional-intra-prediction-mode"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Directional Intra Prediction Mode</h2>
<p dir="auto">VP9 only supports 8 directional intra prediction modes: D45_PRED, D63_PRED,
H_PRED, D117_PRED, D135_PRED, D153_PRED, V_PRED, D207_PRED. These modes
correspond to prediction angles of 45, 63, 90, 117, 135, 153, 180, and 207
degrees, respectively.</p>
<p dir="auto">To improve intra coding efficiency, more prediction angle options are added to
AV1. The prediction angle is calculated as the following:</p>
<p dir="auto">Prediction angle = nominal_angle + (angle_delta * angle_step),</p>
<table>
<thead>
<tr>
<th>nominal_angle</th>
<th>angle_step</th>
<th>angle_delta</th>
<th>Total number of angles</th>
</tr>
</thead>
<tbody>
<tr>
<td>45, 63, 90, 117, 135, 153, 180, 207</td>
<td>3</td>
<td>[-3, +3]</td>
<td>8*7=56</td>
</tr>
</tbody>
</table>
<p dir="auto">Table 6. Finer of Intra Mode</p>
<ul dir="auto">
<li>
<p dir="auto">norminal_angle is determined by the prediction mode, and is the same as VP9;</p>
</li>
<li>
<p dir="auto">angle_delta is in a predefined range and angle_step is a predefined value.
In current configuration, angle_delta is in the range of [-3, +3] and
angle_step is 3. These settings are selected experimentally.</p>
</li>
<li>
<p dir="auto">The total number of supported prediction angles is therefore increased from
8 to 8 * 7 = 56.</p>
</li>
</ul>
<h2 tabindex="-1" dir="auto"><a id="user-content-smooth-mode" aria-hidden="true" tabindex="-1" href="#smooth-mode"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Smooth Mode</h2>
<p dir="auto">It is a Non- Directional Intra Prediction mode. VP9 has 2 non-directional intra
prediction modes: DC_PRED and TM_PRED. AV1 expands on this by adding 3 new
smooth prediction modes: SMOOTH_PRED, SMOOTH_V_PRED and SMOOTH_H_PRED. The new
modes work as follows:</p>
<table>
<thead>
<tr>
<th>Mode</th>
<th>Comments</th>
</tr>
</thead>
<tbody>
<tr>
<td>SMOOTH_PRED</td>
<td>Useful for predicting blocks that have a smooth gradient. It works as follows: estimate the pixels on the rightmost column with the value of the last pixel in top row, and estimate the pixels in the last row of the current block using the last pixel in left column. Then calculate the rest of the pixels by an average of quadratic interpolation in vertical and horizontal directions, based on distance of the pixel from the predicted pixels.</td>
</tr>
<tr>
<td>SMOOTH_V_PRED</td>
<td>Similar to SMOOTH_PRED, but uses quadratic interpolation only in the vertical direction</td>
</tr>
<tr>
<td>SMOOTH_H_PRED</td>
<td>Similar to SMOOTH_PRED, but uses quadratic interpolation only in the horizontal direction</td>
</tr>
</tbody>
</table>
<p dir="auto">Table 7. Smooth mode of Intra mode</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-paeth-mode" aria-hidden="true" tabindex="-1" href="#paeth-mode"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Paeth Mode</h2>
<p dir="auto">It is a Non- Directional Intra Prediction mode. The new prediction mode
PAETH_PRED replaces the existing mode TM_PRED.</p>
<p dir="auto">TM_PRED: Predictor(TM) = left + top – top_left</p>
<p dir="auto">PAETH_PRED: Predictor (PAETH) = argmin |x- Predictor(TM)|</p>
<p dir="auto">The idea is to find out the One of left, top, top_left closest in value to
Predictor(TM).</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-palette-mode" aria-hidden="true" tabindex="-1" href="#palette-mode"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Palette Mode</h2>
<p dir="auto">Sometimes, given intra block can be approximated by a block with small number of
unique colors. This is especially true for artificial videos like
screen-capture, games etc. For such cases, AV1 introduces a new intra coding
mode called palette mode. This predictor for a block is signaled by storing (i)
a color palette, with 2 to 8 colors, and (ii) color indices into the palette for
all pixels in the block. The residual pixel values of the block are as usual
transformed and quantized before being entropy-coded.</p>
<p dir="auto">Palette mode can be used by both intra-only as well as inter frames. The number
of base colors determines the trade-off between fidelity and compactness. The
color indices for pixels are obtained by the nearest neighbor method. The color
indices are encoded using the neighborhood-based context to be as compact as
possible.</p>
<p dir="auto">Palette Mode is not new. We can see the Palette Mode and Intra block copy in the
HEVC SCC (Screen Content Coding) extension.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-filter-intra-mode" aria-hidden="true" tabindex="-1" href="#filter-intra-mode"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Filter Intra mode</h2>
<p dir="auto">AV1 adopt the new mode to interpolate (intra filter) the reference samples
before prediction. This will reduce the impact of quantization noise. Here is
the table to specify the type of intra filtering.</p>
<table>
<thead>
<tr>
<th>Index</th>
<th>Filter intra type</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>INTRA_DC_PRED</td>
</tr>
<tr>
<td>1</td>
<td>INTRA_V_PRED</td>
</tr>
<tr>
<td>2</td>
<td>INTRA_H_PRED</td>
</tr>
<tr>
<td>3</td>
<td>INTRA_D153_PRED</td>
</tr>
<tr>
<td>4</td>
<td>INTRA_TM_PRED</td>
</tr>
</tbody>
</table>
<p dir="auto">Table 8 Type of Intra filter Mode</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-intra-block-copy-mode" aria-hidden="true" tabindex="-1" href="#intra-block-copy-mode"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Intra Block Copy Mode</h2>
<p dir="auto">This tool is very efficient for coding of screen content video in that repeated
patterns in text and graphics rich content occur frequently within the same
picture. Having a previously reconstructed block with equal or similar pattern
as a predictor can effectively reduce the prediction error and therefore improve
coding efficiency.</p>
<p dir="auto">In AV1, Intra block copy is only allowed in intra frames. It disables all loop
filtering and only integer offsets are allowed in block copy mode.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-predict-chroma-from-luma" aria-hidden="true" tabindex="-1" href="#predict-chroma-from-luma"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Predict Chroma from Luma</h2>
<p dir="auto">Chroma from luma (CfL) prediction is a new and promising chroma-only intra
predictor that models chroma pixels as a linear function of the coincident
reconstructed luma pixels.</p>

<h2 tabindex="-1" dir="auto"><a id="user-content-affinewarped-motion-compensation" aria-hidden="true" tabindex="-1" href="#affinewarped-motion-compensation"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Affine/Warped Motion Compensation</h2>
<p dir="auto">Traditional modern codecs, including VP9, use block motion compensation where
motion vectors are translational only. This is not sufficient for real video
which often contains complex motion. For example, motion due to camera shake,
panning and zoom might require transformations that support shearing, scaling,
rotation and changes in aspect ratio. In AV1, we introduce warped motion
compensation implemented as similarity and affine transformations to better
capture the diversity of motion that exists in real video. There are two
affine/warped motion compensation.</p>
<table>
<thead>
<tr>
<th>Affine Motion Compensation</th>
<th>Comments</th>
</tr>
</thead>
<tbody>
<tr>
<td>Global</td>
<td>It is common for videos to contain a global camera motion which is pertinent to an entire inter frame. It is therefore beneficial to transmit a set of motion parameters at the frame level that is applicable to a large number of blocks in the frame. When a frame is encoded, a set of global motion parameters is computed and transmitted between that frame and each reference frame. These parameters may be either translational, similarity or affine motion model. Subsequently, any block in the frame can signal use of the global motion mode with a given reference to create a suitable predictor.</td>
</tr>
<tr>
<td>Local</td>
<td>Affine motion compensation is also useful to describe complex local object motion. Here, we estimate affine parameters for a single block using the translational motion vectors that are typically conveyed for all inter blocks. Specifically, we estimate an affine or similarity model using the motion vectors from the current block and its causal neighbors which share the same reference frame.</td>
</tr>
</tbody>
</table>
<p dir="auto">Table 9 Affine Motion Compensation</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-obmc-overlapped-block-motion-compensation" aria-hidden="true" tabindex="-1" href="#obmc-overlapped-block-motion-compensation"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>OBMC (Overlapped Block Motion Compensation)</h2>
<p dir="auto">Motions assigned to surrounding blocks will contribute to predicting a current
block, via a well-defined overlapping scheme appropriately designed for advanced
variable block-size partitioning frameworks.</p>
<p dir="auto">The OBMC will blend multiple predictors from neighbor blocks. It is not new
concept and was proposed and implemented back in the era of h.263. The OBMC was
proved to largely reduce prediction errors but not adopted by recent codecs due
to extra complexity in the scenario of hybrid inter/intra variable block size
coding. In AV1, a practical overlapping mechanism based on two-stage 1-D
filtering is proposed for the advanced partitioning framework to implement
causal overlapped block prediction.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-sub-pixel-interpolation-filter" aria-hidden="true" tabindex="-1" href="#sub-pixel-interpolation-filter"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Sub-pixel Interpolation Filter</h2>
<p dir="auto">The motion vector used in modern video codecs is allowed to have a fractional
position for a better prediction quality. So, an interpolation filter module is
needed to generate the prediction block at a fractional position in the
reference frame. VP9 codec uses a separable interpolation filter to perform
inter prediction with ⅛ motion vector precision. Three filter types, SHARP,
REGULAR and SMOOTH, in descending order of cutoff frequencies, are provided to
deal with various types of noise/distortions that can occur in reference
frames/blocks. Given a filter type and a motion vector, the interpolation filter
is performed by two one-dimensional filters, one for horizontal direction and
one for vertical direction.</p>
<p dir="auto">In AV1 codec, dual interpolation filter is introduced on top of the
interpolation module inherited from VP9. Dual filter allows each block/frame to
use a different interpolation filter type in horizontal and vertical direction.
Up to 9 types of filter will be applied to the block.</p>
<p dir="auto">This idea is based on the observation that a reference frame/block’s horizontal
and vertical signals may have distinct frequency characteristics; therefore,
using different filter types may produce a better prediction. As before, both
the filter types are transmitted in the bitstream on a per block or per frame
basis.</p>
<p dir="auto">At the same time AV1 use the high intermediate precision between the horizontal
and vertical filter. The same high precision before average the predictors with
compound mode.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-dynamic-mv-reference" aria-hidden="true" tabindex="-1" href="#dynamic-mv-reference"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Dynamic MV reference</h2>
<p dir="auto">VP9 has two candidates MV in the ref list and 4 type of mode (NEARESTMV, NEARMV,
NEWMV, and ZEROMV) are used. AV1 support 4 candidate MV and more modes.</p>
<p dir="auto">For single ref mode, AV1 is same as VP9.</p>
<p dir="auto">For compound mode, VP9 restricts motion vectors for a compound predictor to
share one motion vector referencing mode, even though they may use different
reference frames. To add more flexibility, on top of existing four combinations
(NEAREST_NEARESTMV, NEAR_NEARMV, NEW_NEWMV, ZERO_ZEROMV) in VP9, AV1 supports
four more empirically selected combinations: NEAREST_NEWMV, NEW_NEARESTMV,
NEAR_NEWMV, and NEW_NEARMV.</p>
<table>
<thead>
<tr>
<th>Index</th>
<th>Type</th>
<th>Ref Mode</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>NEARESTMV</td>
<td>single ref mode</td>
</tr>
<tr>
<td>1</td>
<td>NEARMV</td>
<td>single ref mode</td>
</tr>
<tr>
<td>2</td>
<td>GLOBALMV(ZEROMV)</td>
<td>single ref mode</td>
</tr>
<tr>
<td>3</td>
<td>NEWMV</td>
<td>single ref mode</td>
</tr>
<tr>
<td>4</td>
<td>NEAREST_NEARESTMV</td>
<td>compound mode</td>
</tr>
<tr>
<td>5</td>
<td>NEAR_NEARMV</td>
<td>compound mode</td>
</tr>
<tr>
<td>6</td>
<td>NEAREST_NEWMV</td>
<td>compound mode</td>
</tr>
<tr>
<td>7</td>
<td>NEW_NEARESTMV</td>
<td>compound mode</td>
</tr>
<tr>
<td>8</td>
<td>NEAR_NEWMV</td>
<td>compound mode</td>
</tr>
<tr>
<td>9</td>
<td>NEW_NEARMV</td>
<td>compound mode</td>
</tr>
<tr>
<td>10</td>
<td>GLOBAL_GLOBALMV(ZERO_ZEROMV)</td>
<td>compound mode</td>
</tr>
<tr>
<td>11</td>
<td>NEW_NEWMV</td>
<td>compound mode</td>
</tr>
</tbody>
</table>
<p dir="auto">Table 10 MV mode</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-extended-compound-modes" aria-hidden="true" tabindex="-1" href="#extended-compound-modes"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Extended Compound Modes</h2>
<p dir="auto">AV1 Compound mode support both predictors from the same direction and VP9 only
support from the different direction (One forward and one backward reference
frame). VP9 only support 1/2 weight to blend the two predictor and AV1 support
more flexible weight blending.</p>
<table>
<thead>
<tr>
<th>Index</th>
<th>Compound type</th>
<th>Comments</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>COMPOUND_WEDGE</td>
<td>Inter-Inter Wedge mode Inter-Intra Wedge mode</td>
</tr>
<tr>
<td>1</td>
<td>COMPOUND_SEG</td>
<td>Inter-Inter Compound Segment mode</td>
</tr>
<tr>
<td>2</td>
<td>COMPOUND_AVERAGE</td>
<td>(1/2,1/2) weight will be applied to blend the predictors</td>
</tr>
<tr>
<td>3</td>
<td>COMPOUND_INTRA</td>
<td>Inter-Intra Gradual mode</td>
</tr>
<tr>
<td>4</td>
<td>COMPOUND_DISTANCE</td>
<td>This process computes weights to be used for blending predictions together based on the expected output times of the reference frames</td>
</tr>
</tbody>
</table>
<p dir="auto">Table 11. Compound type</p>
<p dir="auto">Here are more details about the Compound Segment Mode:</p>
<ul dir="auto">
<li>Inter-Inter Compound Segment mode</li>
</ul>
<p dir="auto">In many cases, regions in one predictor will contain useful content that is not
present in the other. The two inter predictors have a larger pixel difference
generally.</p>
<ul dir="auto">
<li>Inter-Inter Wedge mode</li>
</ul>
<p dir="auto">Boundaries of moving objects in a video often separate two regions with distinct
motions. Coding these regions with separate motion vector reference combinations
should be beneficial; however, finding exact object boundaries is not only
difficult, but expensive to communicate in the bitstream. Our approach is to
design a codebook of masks with only a few possible partitioning combinations
and signaling the codebook index in the bitstream.</p>
<p dir="auto">The AV1 wedge codebook contains partition orientations that are either
horizontal, vertical or oblique with slopes: 2, -2, 0.5 and -0.5. The wedge
prediction mode is used for all square and rectangular blocks, using the 16-ary
shape codebooks.</p>
<table>
<thead>
<tr>
<th>Index</th>
<th>Wedge direction</th>
<th>Comments</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>WEDGE_HORIZONTAL</td>
<td></td>
</tr>
<tr>
<td>1</td>
<td>WEDGE_VERTICAL</td>
<td></td>
</tr>
<tr>
<td>2</td>
<td>WEDGE_OBLIQUE27</td>
<td></td>
</tr>
<tr>
<td>3</td>
<td>WEDGE_OBLIQUE63</td>
<td></td>
</tr>
<tr>
<td>4</td>
<td>WEDGE_OBLIQUE117</td>
<td></td>
</tr>
<tr>
<td>5</td>
<td>WEDGE_OBLIQUE153</td>
<td></td>
</tr>
</tbody>
</table>
<p dir="auto">Table 12. Wedge direction</p>
<ul dir="auto">
<li>Inter-Intra Gradual mode</li>
</ul>
<p dir="auto">Decay the weight gradually for the intra from the prediction boundary and
increase the weight of inter correspondingly. It support four modes, which
include horizontal mode, vertical mode, DC_PRED, and SMOOTH_PRED.</p>
<ul dir="auto">
<li>Inter-Intra Wedge mode</li>
</ul>
<p dir="auto">Blocks cannot always perfectly partition moving objects. For example, occlusion
can occur in the middle of a block, it is better to apply different prediction
techniques to different contents. Contents that are not occluded in reference
frame will prefer inter prediction, while newly revealed content could benefit
more from intra prediction using local reference.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-extended-reference-frame-number" aria-hidden="true" tabindex="-1" href="#extended-reference-frame-number"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Extended Reference frame Number</h2>
<p dir="auto">Up to 7 reference frames out of 8 in the frame stored buffer are extended to be
used in the inter mode. The reference frames is allowed to come from the same
side or different side in the AV1.</p>
<p dir="auto">LAST3_FRAME, LAST2_FRAME and LAST_FRAME are forward references and LAST_FRAME is
the near past frame. BWDREF_FRAME is a backward reference, similar to
ALTREF_FRAME.</p>
<p dir="auto">Here is the table to show the reference frame type.</p>
<table>
<thead>
<tr>
<th>Index</th>
<th>Ref frame Name</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>INTRA_FRAME</td>
</tr>
<tr>
<td>1</td>
<td>LAST_FRAME</td>
</tr>
<tr>
<td>2</td>
<td>LAST2_FRAME</td>
</tr>
<tr>
<td>3</td>
<td>LAST3_FRAME</td>
</tr>
<tr>
<td>4</td>
<td>GOLDEN_FRAME</td>
</tr>
<tr>
<td>5</td>
<td>BWDREF_FRAME</td>
</tr>
<tr>
<td>6</td>
<td>ALTREF2_FRAME</td>
</tr>
<tr>
<td>7</td>
<td>ALTREF_FRAME</td>
</tr>
</tbody>
</table>
<p dir="auto">Table 13 Reference frame type</p>

<p dir="auto">Several in-loop tools in AV1 are employed. De-blocking, CDEF and loop
restoration are cascaded.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-de-blocking-filter" aria-hidden="true" tabindex="-1" href="#de-blocking-filter"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>De-blocking filter</h2>
<p dir="auto">AV1 support 4 filter levels per frame and VP9 only has one. Two levels are for
Luma component (horizontal and vertical levels). The other two levels are for U
and V component separately. In AV1, filter level is allowed to change superblock
by superblock.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-cdef-constrained-directional-enhancement-filter" aria-hidden="true" tabindex="-1" href="#cdef-constrained-directional-enhancement-filter"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>CDEF (Constrained Directional Enhancement Filter)</h2>
<p dir="auto">CDEF is the combination of CLPF (Constrained Low Pass Filter) and Deringing
filter. The main goal of the in-loop CEDF is to filter the coding artifacts and
ringing while preserving the detail of image. It takes into account the
direction of edge and patterns in the image. It is the similar to the SAO of
HEVC.</p>
<p dir="auto">The CDEF is based on the following observation. The amount of ringing artifacts
in a coded image tends to be roughly proportional to the quantization step size.
The amount of detail is a property of the input image, but the smallest detail
actually retained in the quantized image tends to also be proportional to the
quantization step size. For a given quantization step size, the amplitude of the
ringing is generally less than the amplitude of the details.</p>
<p dir="auto">CDEF works as the following steps:</p>
<ul dir="auto">
<li>
<p dir="auto">The frame is divided into filter blocks of 64x64 pixels. Some CDEF
parameters are signaled at the frame level, and some may be signaled at the
filter block level.</p>
</li>
<li>
<p dir="auto">To identify the direction of edge or pattern in each filter block.</p>
</li>
<li>
<p dir="auto">To adaptively filter along the identified direction and to a lesser degree
along directions rotated 45 degrees from the identified direction. The
filter strengths are signaled explicitly, which allows a high degree of
control over the blurring.</p>
</li>
</ul>
<p dir="auto">The main reason for identifying the direction is to align the filter taps along
that direction to reduce ringing while preserving the directional edges or
patterns. CDEF defines primary taps and secondary taps filter. The primary taps
follow the direction and the secondary taps form a cross, oriented 45 off the
direction. Both primary and secondary taps filter have 8 types.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-lr-in-loop-restoration-filter" aria-hidden="true" tabindex="-1" href="#lr-in-loop-restoration-filter"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>LR (In-loop Restoration) filter</h2>
<p dir="auto">AV1 employ a set of in-loop image restoration tool after de-blocking to
generally de-noise and enhance the quality of the edge. In-loop restoration
scheme have two types of filter to remove blur artifacts due to block
processing. One is Wiener Filter. The other is Dual Self-Guided filter. These
tools are integrated into AV1 with a switchable framework, which trigger the
different tool in the different image region.</p>

<p dir="auto">Multi-symbol adaptive arithmetic coding model is adopted in AV1. Both syntax
element and coefficient are coded with this model.</p>
<p dir="auto">Most recent video codecs encode information using binary arithmetic coding, such
as CABA or CAVLC in AVC/HEVC, meaning that each symbol can only take two values.
The AV1 entropy encoder come from the Daala range coder and supports up to 16
values per symbol, making it possible to encode fewer symbols. This is
equivalent to coding up to four binary values in parallel and reduces serial
dependencies, allowing hardware implementations to use lower clock rates, and
thus less power.</p>

<h2 tabindex="-1" dir="auto"><a id="user-content-transform-type" aria-hidden="true" tabindex="-1" href="#transform-type"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Transform type</h2>
<p dir="auto">For AV1, there is a richer set of transforms for coding Inter and Intra
prediction residues. Inter prediction residues do not have a well-defined
structure as in the Intra case, but using a bank of transforms, each adapted to
a specific type of residue profile within the block, is generally helpful.</p>
<p dir="auto">In AV1, four types of transform are used mainly in the horizontal and vertical
direction separately. The total 16 different transforms are available.</p>
<table>
<thead>
<tr>
<th>Transform type</th>
<th>Comments</th>
</tr>
</thead>
<tbody>
<tr>
<td>DCT</td>
<td>Inter and Intra modes continue to make use of DCT.</td>
</tr>
<tr>
<td>ADST</td>
<td>Asymmetric Discrete Sine Transform</td>
</tr>
<tr>
<td>Flip ADST</td>
<td>It applies ADST in reverse order</td>
</tr>
<tr>
<td>IDTX</td>
<td>Identity transform seems to be particularly useful for coding residue with sharp lines and edges. Identity transform is useful for screen content coding</td>
</tr>
</tbody>
</table>
<p dir="auto">Table 14 The Main Transform Type in each of direction</p>
<p dir="auto">For each small coded block (4x4 or 8x8), it is possible to choose one of up to
16 different transforms as follows(Detail in Table):</p>
<p dir="auto">{DCT, ADST, FlipADST, IDTX} horizontal x {DCT, ADST, FlipADST, IDTX} vertical</p>
<p dir="auto">As block sizes get larger, some of these transforms begin to act similarly.
Thus, a reduced set of transforms is used for 16x16, 32x32 and 64x64 block
sizes. In the transform selection process for Inter and Intra modes, the encoder
does a search over the entire set of transforms and selects the one that
produces the best rate-distortion cost. Once a transform is selected, a
transform type symbol from the set of types available at that size is used to
indicate the actual transform used in the bitstream.</p>
<p dir="auto">There are 6 types of transform sets in the AV1 spec, which specify the transform
type of Intra and Inter blocks. The transform sets determine what subset of
transform types can be used, according to the following table.</p>
<table>
<thead>
<tr>
<th>Inter or not</th>
<th>Set Number</th>
<th>Transform set</th>
</tr>
</thead>
<tbody>
<tr>
<td>Don’t care</td>
<td>0</td>
<td>TX_SET_DCTONLY</td>
</tr>
<tr>
<td>0</td>
<td>1</td>
<td>TX_SET_INTRA_1</td>
</tr>
<tr>
<td>0</td>
<td>2</td>
<td>TX_SET_INTRA_2</td>
</tr>
<tr>
<td>1</td>
<td>1</td>
<td>TX_SET_INTER_1</td>
</tr>
<tr>
<td>1</td>
<td>2</td>
<td>TX_SET_INTER_2</td>
</tr>
<tr>
<td>1</td>
<td>3</td>
<td>TX_SET_INTER_3</td>
</tr>
</tbody>
</table>
<p dir="auto">Table 15 Transform Set in the AV1 spec</p>
<table>
<thead>
<tr>
<th>Transform type</th>
<th>TX_SET_DCTONLY</th>
<th>TX_SET_INTRA_1</th>
<th>TX_SET_INTRA_2</th>
<th>TX_SET_INTER_1</th>
<th>TX_SET_INTER_2</th>
</tr>
</thead>
<tbody>
<tr>
<td>DCT_DCT</td>
<td>X</td>
<td>X</td>
<td>X</td>
<td>X</td>
<td>X</td>
</tr>
<tr>
<td>ADST_DCT</td>
<td></td>
<td>X</td>
<td>X</td>
<td>X</td>
<td>X</td>
</tr>
<tr>
<td>DCT_ADST</td>
<td></td>
<td>X</td>
<td>X</td>
<td>X</td>
<td>X</td>
</tr>
<tr>
<td>ADST_ADST</td>
<td></td>
<td>X</td>
<td>X</td>
<td>X</td>
<td>X</td>
</tr>
<tr>
<td>FLIPADST_DCT</td>
<td></td>
<td></td>
<td></td>
<td>X</td>
<td>X</td>
</tr>
<tr>
<td>DCT_FLIPADST</td>
<td></td>
<td></td>
<td></td>
<td>X</td>
<td>X</td>
</tr>
<tr>
<td>FLIPADST_FLIPADST</td>
<td></td>
<td></td>
<td></td>
<td>X</td>
<td>X</td>
</tr>
<tr>
<td>ADST_FLIPADST</td>
<td></td>
<td></td>
<td></td>
<td>X</td>
<td>X</td>
</tr>
<tr>
<td>FLIPADST_ADST</td>
<td></td>
<td></td>
<td></td>
<td>X</td>
<td>X</td>
</tr>
<tr>
<td>IDTX</td>
<td></td>
<td>X</td>
<td>X</td>
<td>X</td>
<td>X</td>
</tr>
<tr>
<td>V_DCT</td>
<td></td>
<td>X</td>
<td></td>
<td>X</td>
<td>X</td>
</tr>
<tr>
<td>H_DCT</td>
<td></td>
<td>X</td>
<td></td>
<td>X</td>
<td>X</td>
</tr>
<tr>
<td>V_ADST</td>
<td></td>
<td></td>
<td></td>
<td>X</td>
<td></td>
</tr>
<tr>
<td>H_ADST</td>
<td></td>
<td></td>
<td></td>
<td>X</td>
<td></td>
</tr>
<tr>
<td>V_FLIPADST</td>
<td></td>
<td></td>
<td></td>
<td>X</td>
<td></td>
</tr>
<tr>
<td>H_FLIPADST</td>
<td></td>
<td></td>
<td></td>
<td>X</td>
<td></td>
</tr>
</tbody>
</table>
<p dir="auto">Table 16 Detailed Transform type supported in each transform set.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-transform-block-shape-and-size" aria-hidden="true" tabindex="-1" href="#transform-block-shape-and-size"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Transform Block Shape and Size</h2>
<p dir="auto">Both square and rectangle shape block are used in AV1. The transform block size
is less than the partition block size. The block size is very flexible and up to
64x64 and down to 4x4. Details see the table in the Block section.</p>

<p dir="auto">AV1 support flexible tiles, which include uniform and non-uniform tile spacing.
Tile area is limited to a maximum 4096x2304. Tiles can be grouped into tile
group and each group can be decoded independently to achieve error resilience.
Loop filter can be enabled or disabled across tiles.</p>

<p dir="auto">Same as VP9, AV1 provides a means of segmenting the image and then applying
various adjustments at the segment level. Up to 8 segments may be specified for
any given frame. For each of these segments it is possible to specify:</p>
<ul dir="auto">
<li>
<p dir="auto">A quantizer (absolute value or delta).</p>
</li>
<li>
<p dir="auto">A loop filter strength (absolute value or delta).</p>
</li>
<li>
<p dir="auto">A prediction reference frame.</p>
</li>
<li>
<p dir="auto">A block skip mode that implies both the use of a (0,0) motion vector and that
no residual will be coded.</p>
</li>
</ul>

<p dir="auto">AV1 support temporal and spatial layer coding. Temporal layer support up to 8
layers and spatial layer support up to 3 layers.</p>
<table>
<thead>
<tr>
<th>Index</th>
<th>Scalability mode</th>
<th>Index</th>
<th>Scalability mode</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>SCALABILITY_L1T2</td>
<td>8</td>
<td>SCALABILITY_L2T2h</td>
</tr>
<tr>
<td>1</td>
<td>SCALABILITY_L1T3</td>
<td>9</td>
<td>SCALABILITY_L2T3h</td>
</tr>
<tr>
<td>2</td>
<td>SCALABILITY_L2T1</td>
<td>10</td>
<td>SCALABILITY_S2T1h</td>
</tr>
<tr>
<td>3</td>
<td>SCALABILITY_L2T2</td>
<td>11</td>
<td>SCALABILITY_S2T2h</td>
</tr>
<tr>
<td>4</td>
<td>SCALABILITY_L2T3</td>
<td>12</td>
<td>SCALABILITY_S2T3h</td>
</tr>
<tr>
<td>5</td>
<td>SCALABILITY_S2T1</td>
<td>13</td>
<td>SCALABILITY_SS</td>
</tr>
<tr>
<td>6</td>
<td>SCALABILITY_S2T2</td>
<td>14-255</td>
<td>reserved</td>
</tr>
<tr>
<td>7</td>
<td>SCALABILITY_S2T3</td>
<td></td>
<td></td>
</tr>
</tbody>
</table>
<p dir="auto">Table 17. Temporal and Spatial Mode</p>
<table>
<thead>
<tr>
<th>Scalability mode</th>
<th>Spatial Layers</th>
<th>Resolution Ratio</th>
<th>Temporal Layers</th>
<th>Inter-layer-dependency</th>
</tr>
</thead>
<tbody>
<tr>
<td>SCALABILITY_L1T2</td>
<td>1</td>
<td></td>
<td>2</td>
<td></td>
</tr>
<tr>
<td>SCALABILITY_L1T3</td>
<td>1</td>
<td></td>
<td>3</td>
<td></td>
</tr>
<tr>
<td>SCALABILITY_L2T1</td>
<td>2</td>
<td>2:1</td>
<td>1</td>
<td>Yes</td>
</tr>
<tr>
<td>SCALABILITY_L2T2</td>
<td>2</td>
<td>2:1</td>
<td>2</td>
<td>Yes</td>
</tr>
<tr>
<td>SCALABILITY_L2T3</td>
<td>2</td>
<td>2:1</td>
<td>3</td>
<td>Yes</td>
</tr>
<tr>
<td>SCALABILITY_S2T1</td>
<td>2</td>
<td>2:1</td>
<td>1</td>
<td>No</td>
</tr>
<tr>
<td>SCALABILITY_S2T2</td>
<td>2</td>
<td>2:1</td>
<td>2</td>
<td>No</td>
</tr>
<tr>
<td>SCALABILITY_S2T3</td>
<td>2</td>
<td>2:1</td>
<td>3</td>
<td>No</td>
</tr>
<tr>
<td>SCALABILITY_L2T2h</td>
<td>2</td>
<td>1.5:1</td>
<td>2</td>
<td>Yes</td>
</tr>
<tr>
<td>SCALABILITY_L2T3h</td>
<td>2</td>
<td>1.5:1</td>
<td>3</td>
<td>Yes</td>
</tr>
<tr>
<td>SCALABILITY_S2T1h</td>
<td>2</td>
<td>1.5:1</td>
<td>1</td>
<td>No</td>
</tr>
</tbody>
</table>
<p dir="auto">Table 17. Details in the Temporal and Spatial Mode</p>

<h2 tabindex="-1" dir="auto"><a id="user-content-quantization-matric" aria-hidden="true" tabindex="-1" href="#quantization-matric"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Quantization Matric</h2>
<p dir="auto">AV1 support 15 sets of QMs, which are based on the contrast-sensitive functions.
QMs are applied to a frame based on selectable scaling of its quantization
level, higher level of quantization imply flatter matrices. The matrices become
flatter as the quantization index value increases (and the quality decreases).
Inter matrices are slightly flatter than intra matrices.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-superblock-delta-quantization" aria-hidden="true" tabindex="-1" href="#superblock-delta-quantization"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>Superblock Delta-quantization</h2>
<p dir="auto">AV1 allow the per-superblock changes in quantization parameter to support
sub-frame rate control. At the same time it support the ROI level rate control
on the top of segmentation level parameter.</p>
<h2 tabindex="-1" dir="auto"><a id="user-content-obu-open-bitstream-unit" aria-hidden="true" tabindex="-1" href="#obu-open-bitstream-unit"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a>OBU (Open Bitstream Unit)</h2>
<p dir="auto">An AV1 bitstream consists of a number of OBUs that are normally held within a
container format alongside audio and timing information. Here the new tool OBU
is introduced in AV1 and it is similar to NAL (Network Abstract Layer) in
AVC/HEVC spec.</p>
<p dir="auto">The OBU header is similar to the NAL header. In general the total 8 bits are
presented. The OBU extra 8 bits of extension header is used if temporal and
spatial layer exist in the bitstream. obu_type is the most important syntax to
describe the type of OBU .</p>
<table>
<thead>
<tr>
<th>Index</th>
<th>obu_type</th>
</tr>
</thead>
<tbody>
<tr>
<td>0</td>
<td>Reserved</td>
</tr>
<tr>
<td>1</td>
<td>OBU_SEQUENCE_HEADER</td>
</tr>
<tr>
<td>2</td>
<td>OBU_TD</td>
</tr>
<tr>
<td>3</td>
<td>OBU_FRAME_HEADER</td>
</tr>
<tr>
<td>4</td>
<td>OBU_TILE_GROUP</td>
</tr>
<tr>
<td>5</td>
<td>OBU_METADATA</td>
</tr>
<tr>
<td>6</td>
<td>OBU_FRAME</td>
</tr>
<tr>
<td>7</td>
<td>OBU_REDUNDANT_FRAME_HEADER</td>
</tr>
<tr>
<td>8-14</td>
<td>Reserved</td>
</tr>
<tr>
<td>15</td>
<td>OBU_PADDING</td>
</tr>
</tbody>
</table>
<p dir="auto">Table 18. Type of OBU</p>

<ol dir="auto">
<li><a href="https://aomediacodec.github.io/av1-spec/av1-spec.pdf" rel="nofollow">https://aomediacodec.github.io/av1-spec/av1-spec.pdf</a></li>
</ol>
</article>
          </div></div>
  </body>
</html>
