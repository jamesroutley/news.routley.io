<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.newscientist.com/article/2438107-mind-reading-ai-recreates-what-youre-looking-at-with-amazing-accuracy/">Original</a>
    <h1>AI focused on brain regions recreates what you&#39;re looking at (2024)</h1>
    
    <div id="readability-page-1" class="page"><div>
                <section>
                    <div>
                        <header>
                                                            <h4>
                                                                        <a href="http://marginalfutility.net/subject/technology/">Technology</a>
                                </h4>
                                                        
                            

                            
                                                            <p>Giving AI systems the ability to focus on particular brain regions can make them much better at reconstructing images of what a monkey is looking at from brain recordings</p>
                            
                            <p><span>By <a href="http://marginalfutility.net/author/michael-le-page/">Michael Le Page</a></span></p>
                            
                                                    </header>
                    </div>
                </section>
                <section data-barrier="Subscription">
                    <figure><p><img alt="" width="1350" height="900" src="https://images.newscientist.com/wp-content/uploads/2024/07/03155224/SEI_211404838.jpg" data-src="https://images.newscientist.com/wp-content/uploads/2024/07/03155224/SEI_211404838.jpg" sizes="(min-width: 1288px) 837px, (min-width: 1024px) calc(57.5vw + 55px), (min-width: 415px) calc(100vw - 40px), calc(70vw + 74px)" srcset="https://images.newscientist.com/wp-content/uploads/2024/07/03155224/SEI_211404838.jpg?width=300 300w, https://images.newscientist.com/wp-content/uploads/2024/07/03155224/SEI_211404838.jpg?width=400 400w, https://images.newscientist.com/wp-content/uploads/2024/07/03155224/SEI_211404838.jpg?width=500 500w, https://images.newscientist.com/wp-content/uploads/2024/07/03155224/SEI_211404838.jpg?width=600 600w, https://images.newscientist.com/wp-content/uploads/2024/07/03155224/SEI_211404838.jpg?width=700 700w, https://images.newscientist.com/wp-content/uploads/2024/07/03155224/SEI_211404838.jpg?width=800 800w, https://images.newscientist.com/wp-content/uploads/2024/07/03155224/SEI_211404838.jpg?width=837 837w, https://images.newscientist.com/wp-content/uploads/2024/07/03155224/SEI_211404838.jpg?width=900 900w, https://images.newscientist.com/wp-content/uploads/2024/07/03155224/SEI_211404838.jpg?width=1003 1003w, https://images.newscientist.com/wp-content/uploads/2024/07/03155224/SEI_211404838.jpg?width=1100 1100w, https://images.newscientist.com/wp-content/uploads/2024/07/03155224/SEI_211404838.jpg?width=1200 1200w, https://images.newscientist.com/wp-content/uploads/2024/07/03155224/SEI_211404838.jpg?width=1300 1300w, https://images.newscientist.com/wp-content/uploads/2024/07/03155224/SEI_211404838.jpg?width=1400 1400w, https://images.newscientist.com/wp-content/uploads/2024/07/03155224/SEI_211404838.jpg?width=1500 1500w, https://images.newscientist.com/wp-content/uploads/2024/07/03155224/SEI_211404838.jpg?width=1600 1600w, https://images.newscientist.com/wp-content/uploads/2024/07/03155224/SEI_211404838.jpg?width=1674 1674w, https://images.newscientist.com/wp-content/uploads/2024/07/03155224/SEI_211404838.jpg?width=1700 1700w, https://images.newscientist.com/wp-content/uploads/2024/07/03155224/SEI_211404838.jpg?width=1800 1800w, https://images.newscientist.com/wp-content/uploads/2024/07/03155224/SEI_211404838.jpg?width=1900 1900w, https://images.newscientist.com/wp-content/uploads/2024/07/03155224/SEI_211404838.jpg?width=2006 2006w" loading="eager" fetchpriority="high" data-image-context="Article" data-image-id="2438371" data-caption="Top row: original images. Second row: images reconstructed by AI based on brain recordings from a macaque. Bottom row: images reconstructed by the AI system without an attention mechanism" data-credit="Thirza Dado et al."/></p><figcaption><div><p>Top row: original images. Second row: images reconstructed by AI based on brain recordings from a macaque. Bottom row: images reconstructed by the AI system without an attention mechanism</p><p>Thirza Dado et al.</p></div></figcaption></figure>
<p>Artificial intelligence systems can now create remarkably accurate reconstructions of what someone is looking at based on recordings of their brain activity. These reconstructed images are greatly improved when the AI learns which parts of the brain to pay attention to.</p>
<p>“As far as I know, these are the closest, most accurate reconstructions,” says <a href="https://www.ru.nl/en/people/guclu-u">Umut Güçlü</a> at Radboud University in the Netherlands.</p>

                                    </section>
            </div><div>
                

<section data-js-sidebar-newsletter-sign-up="">
    <div>
        
        <div>
            
            <header>
                <h2>Sign up to our weekly newsletter</h2>
            </header>
            <p>Receive a weekly dose of discovery in your inbox! 
            We&#39;ll also keep you up to date with <em>New Scientist</em> 
            events and special offers.</p>
            <p><a href="http://marginalfutility.net/sign-up/weekly">Sign up</a>
        </p></div>
    </div>
</section>            </div></div>
  </body>
</html>
