<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://supabase.com/blog/supabase-logs-self-hosted">Original</a>
    <h1>Supabase Logs: open-source logging server</h1>
    
    <div id="readability-page-1" class="page"><article><div><p><span><img alt="Supabase Logs: open source logging server" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill"/></span></p><p>Today, weâ€™re releasing Supabase Logs for both self-hosted users and CLI development.</p>
<div><iframe width="560" height="315" src="https://www.youtube.com/embed/Ai2BjHV36Ng" title="YouTube video player" frameborder="0" allow="accelerometer; autoplay; clipboard-write; encrypted-media; gyroscope; picture-in-picture; web-share"></iframe><p><em>Whatch the video announcement</em></p></div>
<h2 id="logflare-introduction">Logflare Introduction</h2>
<p>Since <a href="https://supabase.com/blog/supabase-acquires-logflare">Logflare joined Supabase</a> over a year ago itâ€™s been quietly handling over 1 billion log events every day. These events come from various tools in the Supabase infrastructure - the API gateway, Postgres databases, Storage, Edge Functions, Auth, and Realtime.</p>
<p>Logflare is a multi-node, highly available Elixir cluster, ingesting the log events and storing them into BigQuery for Supabase and Logflareâ€™s customers. On average, the cluster has 6 nodes handling every spike our customers throw at it.</p>
<p>To expose log data to customers, we leverage Logflare Endpoints. This provides an HTTP integration into Supabase Studio, powering the log query UIs and most time-series charts. These charts live across the studio, such as the project home page and the new API reports.</p>
<!-- -->
<h2 id="self-hosting-logflare">Self-hosting Logflare</h2>
<p>Logflare was available under a BSL license prior to joining Supabase. Weâ€™ve since changed the license to <a href="https://github.com/Logflare/logflare/blob/staging/LICENSE.md">Apache 2.0</a>, aligning it with our open source philosophy.</p>
<p>In the past few months weâ€™ve made Logflare more developer-friendly for local development and self-hosting. While youâ€™re building a project, you can view and query your logs from any Supabase service, just as you would in our cloud platform.</p>
<p><span><span><img alt="Logs UI" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill"/></span></span></p>
<p>ðŸ“¢ Check out the <a href="https://supabase.com/docs/reference/self-hosting-analytics/introduction">new self-hosting docs</a> to get Logflare up and running as your analytics server.</p>
<p>It currently supports a BigQuery backend, and we are actively working on supporting more.</p>
<h2 id="the-ingestion-pipeline">The Ingestion Pipeline</h2>
<p>Logflare receives Supabase log events via multiple methods. Services like Postgres use <a href="https://vector.dev/">Vector</a> to clean and forward log events to the Logflare ingest API. Other services such as Realtime and Storage utilize <a href="https://github.com/Logflare/logflare#integrations">native Logflare integrations</a> to send the log events directly. These then get processed and streamed into BigQuery.</p>
<h2 id="the-querying-pipeline">The Querying Pipeline</h2>
<p>The hard part comes after ingesting the logs: searching, aggregating ,and analyzing them at scale. Crunching many terabytes of data on each query is expensive, and exposing the ingested data to Supabase customers in a naive manner would cause our costs to skyrocket.</p>
<p>To solve these issues, we built and refined Logflare Endpoints, the query engine that powers many of Supabaseâ€™s features, such as the logs views, Logs Explorer, and usage charts.</p>
<p>With Endpoints, you can create HTTP API endpoints from a SQL query, including parameterized queries. Endpoints are like PostgREST views but with some benefits:</p>
<ul>
<li><strong>Query parameters</strong>
<ul>
<li>You can provide string parameters to the SQL query via the HTTP endpoint.</li>
</ul>
</li>
<li><strong>Read-through caching</strong>
<ul>
<li>Results from the query are cached in memory for fast response times.</li>
<li>A read-through cache provides results if cached results do not exist.</li>
</ul>
</li>
<li><strong>Active cache warming</strong>
<ul>
<li>Query results are proactively warmed at a configurable interval for a combination of fast response times and as-realtime-as-needed data.</li>
</ul>
</li>
<li><strong>Query sandboxing</strong>
<ul>
<li>If an Endpoint query contains a CTE and the sandbox option is selected, the Endpoint will inject the query string of the <code>sql</code> query parameter into the Endpoint SQL replacing the default query (the part of the SQL query after the CTE).</li>
<li>Endpoints parse SQL to allow <code>select</code> queries only. No DML or DDL statements are permitted to run through Logflare Endpoints.</li>
</ul>
</li>
</ul>
<p>With this feature set, Supabase has been able to build any view weâ€™ve needed on top of billions of daily log events.</p>
<h3 id="logflare-endpoint-example">Logflare Endpoint Example</h3>
<p>Using webhooks, we can send all GitHub events in the Supabase organization to Logflare. The webhook sends structured events, and Logflare transforms the payload into metadata:</p>

<p>Weâ€™re interested in the top contributors, which can be extracted with SQL (in BigQuery dialect):</p>

<p>With this view in place, we can use Endpoints to provide an API that we can hit from our application:</p>

<p>This returns a JSON response with the top org wide contributors for the last 30 days!</p>

<p>We can configure this Endpoint to cache results for an interval of 10 minutes after the first API request, and proactively update those cached results every 2 minutes - 5 queries across the 10 minute interval. Even if we hit the Endpoint thousands of times, we only sustain the cost of 5 queries.</p>
<p>The initial request is fast because Logflare also performs setup (such as partitioning) on our BigQuery tables appropriately. Subsequent requests are <em>extremely fast</em> as they are cached in-memory.</p>
<p>The best part is that all these knobs can be tweaked for your use case. If we have a real-time requirement, we can completely disable caching or reduce the proactive caching to update on a per-second interval.</p>
<h2 id="the-self-hosted-challenge">The Self-hosted Challenge</h2>
<p>To change the license, we needed to remove all closed-source dependencies. Previously, Logflare relied on the closed source <a href="https://www.sqlparser.com/">General SQL Parser</a> under a business licenses. This is incompatible with the Apache License.</p>
<p>We switched to an open source alternative, the rust-based <a href="https://github.com/sqlparser-rs/sqlparser-rs">sqlparser-rs</a> library, contributing a <a href="https://github.com/sqlparser-rs/sqlparser-rs/pulls?q=is%3Apr+is%3Amerged+author%3AZiinc">few updates</a> for the BigQuery dialect.</p>
<p>Along with the parser, we invested a lot of effort into transforming the multi-tenant architecture into something that was self-hosting friendly and easily configurable. We moved towards environment variable based configuration instead of compile-time configurations, exposing the Endpoints configurations necessary for Supabase Logs.</p>
<h2 id="whats-next">Whatâ€™s Next?</h2>
<p>To further integrate Logflare into the Supabase platform, we are building out 2 main areas: Management API, Multiple Backends.</p>
<h3 id="management-api">Management API</h3>
<p>The Management API allows users to interact programmatically with Logflare to manage their account and resources. This feature will be available for both Logflare customers and self-hosted users.</p>
<p>You can check out the preview of our OpenAPI spec here: <a href="https://logflare.app/swaggerui">https://logflare.app/swaggerui</a></p>
<p><span><span><img alt="Swagger UI" src="data:image/gif;base64,R0lGODlhAQABAIAAAAAAAP///yH5BAEAAAAALAAAAAABAAEAAAIBRAA7" decoding="async" data-nimg="fill"/></span></span></p>
<p>Not only that, we intend to expose user account provisioning to select partners. Soon, youâ€™ll be able to become a Logflare Partner to provision Logflare accounts through the Partner API. Perfect if you want to resell a log analytics service from your own platform.</p>
<p>Contact us at <a href="mailto:growth@supabase.com">growth@supabase.com</a> to get in early on that waitlist.</p>
<h2 id="multiple-backends">Multiple Backends</h2>
<p>Logflare currently supports a BigQuery backend. We plan to add support for other analytics-optimized databases, like Clickhouse. We will also support pushing data to other web services, making Logflare a good fit for any data pipeline.</p>
<p>This will benefit the Supabase CLI: once Postgres support is available, Logflare will be able to integrate seamlessly, without the BigQuery requirement.</p>
<h2 id="wrapping-up">Wrapping Up</h2>
<p>Logflare has given Supabase the flexibility to quickly deploy features powered by an underlying structured event stream. Materializing metrics from an event stream is a powerful framework for delivering real-time views on analytics streams.</p>
<p>Logflare is the hub of analytics streams for Supabase. We look forward to giving Supabase customers the same superpower.</p></div></article></div>
  </body>
</html>
