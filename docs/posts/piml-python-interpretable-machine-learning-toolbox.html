<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://github.com/SelfExplainML/PiML-Toolbox">Original</a>
    <h1>PiML: Python Interpretable Machine Learning Toolbox</h1>
    
    <div id="readability-page-1" class="page"><div data-hpc="true"><article itemprop="text"><div dir="auto">
<p><a target="_blank" rel="noopener noreferrer" href="https://github.com/SelfExplainML/PiML-Toolbox/blob/main/examples/results/LogoPiML.png"><img src="https://github.com/SelfExplainML/PiML-Toolbox/raw/main/examples/results/LogoPiML.png" alt="drawing" width="314.15926"/></a></p><p dir="auto"><strong>An integrated Python toolbox for interpretable machine learning</strong></p>
<p dir="auto"><code>pip install PiML</code></p>
<p dir="auto">ðŸŽ„ <strong>Dec 1, 2023:</strong>  V0.6.0 is released with enhanced data handling and model analytics.</p>
<p dir="auto">ðŸš€ <strong>May 4, 2023:</strong>  V0.5.0 is released together with PiML user guide.</p>
<p dir="auto">ðŸš€ <strong>October 31, 2022:</strong>  V0.4.0 is released with enriched models and enhanced diagnostics.</p>
<p dir="auto">ðŸš€ <strong>July 26, 2022:</strong>  V0.3.0 is released with classic statistical models.</p>
<p dir="auto">ðŸš€ <strong>June 26, 2022:</strong> V0.2.0 is released with high-code APIs.</p>
<p dir="auto">ðŸ“¢ <strong>May 4, 2022:</strong>  V0.1.0 is launched with low-code UI/UX.</p>
</div>
<p dir="auto">PiML (or Ï€-ML, /ËˆpaÉªÂ·ËˆemÂ·Ëˆel/) is a new Python toolbox for interpretable machine learning model development and validation. Through low-code interface and high-code APIs, PiML supports a growing list of inherently interpretable ML models:</p>
<ol dir="auto">
<li><strong>GLM</strong>: Linear/Logistic Regression with L1 âˆ¨ L2 Regularization</li>
<li><strong>GAM</strong>: Generalized Additive Models using B-splines</li>
<li><strong>Tree</strong>: Decision Tree for Classification and Regression</li>
<li><strong>FIGS</strong>: Fast Interpretable Greedy-Tree Sums (Tan, et al. 2022)</li>
<li><strong>XGB1</strong>: Extreme Gradient Boosted Trees of Depth 1, with optimal binning (Chen and Guestrin, 2016; Navas-Palencia, 2020)</li>
<li><strong>XGB2</strong>: Extreme Gradient Boosted Trees of Depth 2, with effect purification (Chen and Guestrin, 2016; Lengerich, et al. 2020)</li>
<li><strong>EBM</strong>: Explainable Boosting Machine (Nori, et al. 2019; Lou, et al. 2013)</li>
<li><strong>GAMI-Net</strong>: Generalized Additive Model with Structured Interactions (Yang, Zhang and Sudjianto, 2021)</li>
<li><strong>ReLU-DNN</strong>: Deep ReLU Networks using Aletheia Unwrapper and Sparsification (Sudjianto, et al. 2020)</li>
</ol>
<p dir="auto">PiML also works for arbitrary supervised ML models under regression and binary classification settings. It supports a whole spectrum of outcome testing, including but not limited to the following:</p>
<ol dir="auto">
<li><strong>Accuracy</strong>: popular metrics like MSE, MAE for regression tasks and ACC, AUC, Recall, Precision, F1-score for binary classification tasks.</li>
<li><strong>Explainability</strong>: post-hoc global explainers (PFI, PDP, ALE) and local explainers (LIME, SHAP).</li>
<li><strong>Fairness</strong>: disparity test and segmented analysis by integrating the solas-ai package.</li>
<li><strong>WeakSpot</strong>: identification of weak regions with high residuals by slicing techniques.</li>
<li><strong>Overfit</strong>: identification of overfitting regions according to train-test performance gap.</li>
<li><strong>Reliability</strong>: assessment of prediction uncertainty by split conformal prediction techniques.</li>
<li><strong>Robustness</strong>: evaluation of performance degradation under covariate noise perturbation.</li>
<li><strong>Resilience</strong>: evaluation of performance degradation under different out-of-distribution scenarios.</li>
</ol>
<p dir="auto"><a href="#Install">Installation</a> | <a href="#Example">Examples</a> | <a href="#Usage">Usage</a> | <a href="#Cite">Citations</a></p>



<p dir="auto">Click the ipynb links to run examples in Google Colab:</p>
<ol dir="auto">
<li>BikeSharing data: <a href="https://colab.research.google.com/github/SelfExplainML/PiML-Toolbox/blob/main/examples/Example_BikeSharing.ipynb" rel="nofollow"><img src="https://github.com/SelfExplainML/PiML-Toolbox/raw/main/examples/results/LogoColab.png" width="20"/>  ipynb</a></li>
<li>CaliforniaHousing data: <a href="https://colab.research.google.com/github/SelfExplainML/PiML-Toolbox/blob/main/examples/Example_CaliforniaHousing.ipynb" rel="nofollow"><img src="https://github.com/SelfExplainML/PiML-Toolbox/raw/main/examples/results/LogoColab.png" width="20"/>  ipynb</a></li>
<li>TaiwanCredit data: <a href="https://colab.research.google.com/github/SelfExplainML/PiML-Toolbox/blob/main/examples/Example_TaiwanCredit.ipynb" rel="nofollow"><img src="https://github.com/SelfExplainML/PiML-Toolbox/raw/main/examples/results/LogoColab.png" width="20"/>  ipynb</a></li>
<li>Fairness_SimuStudy1 data: <a href="https://colab.research.google.com/github/SelfExplainML/PiML-Toolbox/blob/main/examples/Example_Fairness_SimuStudy1.ipynb" rel="nofollow"><img src="https://github.com/SelfExplainML/PiML-Toolbox/raw/main/examples/results/LogoColab.png" width="20"/>  ipynb</a></li>
<li>Fairness_SimuStudy2 data: <a href="https://colab.research.google.com/github/SelfExplainML/PiML-Toolbox/blob/main/examples/Example_Fairness_SimuStudy2.ipynb" rel="nofollow"><img src="https://github.com/SelfExplainML/PiML-Toolbox/raw/main/examples/results/LogoColab.png" width="20"/>  ipynb</a></li>
<li>Upload custom data in two ways: <a href="https://colab.research.google.com/github/SelfExplainML/PiML-Toolbox/blob/main/examples/Example_CustomDataLoad_Two_Ways.ipynb" rel="nofollow"><img src="https://github.com/SelfExplainML/PiML-Toolbox/raw/main/examples/results/LogoColab.png" width="20"/>  ipynb</a></li>
<li>Deal with external models: <a href="https://colab.research.google.com/github/SelfExplainML/PiML-Toolbox/blob/main/examples/Example_ExternalModels.ipynb" rel="nofollow"><img src="https://github.com/SelfExplainML/PiML-Toolbox/raw/main/examples/results/LogoColab.png" width="20"/>  ipynb</a></li>
</ol>
<p dir="auto">Begin your own PiML journey with <a href="https://colab.research.google.com/github/SelfExplainML/PiML-Toolbox/blob/main/PiML%20Low-code%20Example%20Run.ipynb" rel="nofollow">this demo notebook</a>.</p>

<p dir="auto">The same examples can also be run by high-code APIs:</p>
<ol dir="auto">
<li>BikeSharing data: <a href="https://colab.research.google.com/github/SelfExplainML/PiML-Toolbox/blob/main/examples/Example_BikeSharing_HighCode.ipynb" rel="nofollow"><img src="https://github.com/SelfExplainML/PiML-Toolbox/raw/main/examples/results/LogoColab.png" width="20"/>  ipynb</a></li>
<li>CaliforniaHousing data: <a href="https://colab.research.google.com/github/SelfExplainML/PiML-Toolbox/blob/main/examples/Example_CaliforniaHousing_HighCode.ipynb" rel="nofollow"><img src="https://github.com/SelfExplainML/PiML-Toolbox/raw/main/examples/results/LogoColab.png" width="20"/>  ipynb</a></li>
<li>TaiwanCredit data: <a href="https://colab.research.google.com/github/SelfExplainML/PiML-Toolbox/blob/main/examples/Example_TaiwanCredit_HighCode.ipynb" rel="nofollow"><img src="https://github.com/SelfExplainML/PiML-Toolbox/raw/main/examples/results/LogoColab.png" width="20"/>  ipynb</a></li>
<li>Model saving: <a href="https://colab.research.google.com/github/SelfExplainML/PiML-Toolbox/blob/main/examples/Example_ModelSaving.ipynb" rel="nofollow"><img src="https://github.com/SelfExplainML/PiML-Toolbox/raw/main/examples/results/LogoColab.png" width="20"/>  ipynb</a></li>
<li>Results return: <a href="https://colab.research.google.com/github/SelfExplainML/PiML-Toolbox/blob/main/examples/Example_ResultsReturn.ipynb" rel="nofollow"><img src="https://github.com/SelfExplainML/PiML-Toolbox/raw/main/examples/results/LogoColab.png" width="20"/>  ipynb</a></li>
</ol>
<div dir="auto"><h2 tabindex="-1" dir="auto">Low-code Usage on Google Colab<a name="user-content-Usage"></a></h2><a id="user-content-low-code-usage-on-google-colab" aria-label="Permalink: Low-code Usage on Google Colab" href="#low-code-usage-on-google-colab"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto"><h3 tabindex="-1" dir="auto">Stage 1:  Initialize an experiment, Load and Prepare data</h3><a id="user-content-stage-1--initialize-an-experiment-load-and-prepare-data" aria-label="Permalink: Stage 1:  Initialize an experiment, Load and Prepare data" href="#stage-1--initialize-an-experiment-load-and-prepare-data"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<div dir="auto" data-snippet-clipboard-copy-content="from piml import Experiment
exp = Experiment()"><pre><span>from</span> <span>piml</span> <span>import</span> <span>Experiment</span>
<span>exp</span> <span>=</span> <span>Experiment</span>()</pre></div>

<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/SelfExplainML/PiML-Toolbox/blob/main/examples/results/data_loader.png"><img src="https://github.com/SelfExplainML/PiML-Toolbox/raw/main/examples/results/data_loader.png"/></a></p>

<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/SelfExplainML/PiML-Toolbox/blob/main/examples/results/data_summary.png"><img src="https://github.com/SelfExplainML/PiML-Toolbox/raw/main/examples/results/data_summary.png"/></a></p>

<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/SelfExplainML/PiML-Toolbox/blob/main/examples/results/data_prepare.png"><img src="https://github.com/SelfExplainML/PiML-Toolbox/raw/main/examples/results/data_prepare.png"/></a></p>

<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/SelfExplainML/PiML-Toolbox/blob/main/examples/results/data_quality.png"><img src="https://github.com/SelfExplainML/PiML-Toolbox/raw/main/examples/results/data_quality.png"/></a></p>

<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/SelfExplainML/PiML-Toolbox/blob/main/examples/results/feature_select.png"><img src="https://github.com/SelfExplainML/PiML-Toolbox/raw/main/examples/results/feature_select.png"/></a></p>

<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/SelfExplainML/PiML-Toolbox/blob/main/examples/results/data_eda.png"><img src="https://github.com/SelfExplainML/PiML-Toolbox/raw/main/examples/results/data_eda.png"/></a></p>
<div dir="auto"><h3 tabindex="-1" dir="auto">Stage 2:  Train intepretable models</h3><a id="user-content-stage-2--train-intepretable-models" aria-label="Permalink: Stage 2:  Train intepretable models" href="#stage-2--train-intepretable-models"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>

<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/SelfExplainML/PiML-Toolbox/blob/main/examples/results/model_train.png"><img src="https://github.com/SelfExplainML/PiML-Toolbox/raw/main/examples/results/model_train.png"/></a></p>
<div dir="auto"><h3 tabindex="-1" dir="auto">Stage 3. Explain and Interpret</h3><a id="user-content-stage-3-explain-and-interpret" aria-label="Permalink: Stage 3. Explain and Interpret" href="#stage-3-explain-and-interpret"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>

<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/SelfExplainML/PiML-Toolbox/blob/main/examples/results/model_explain.png"><img src="https://github.com/SelfExplainML/PiML-Toolbox/raw/main/examples/results/model_explain.png"/></a></p>

<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/SelfExplainML/PiML-Toolbox/blob/main/examples/results/model_interpret.png"><img src="https://github.com/SelfExplainML/PiML-Toolbox/raw/main/examples/results/model_interpret.png"/></a></p>
<div dir="auto"><h3 tabindex="-1" dir="auto">Stage 4. Diagnose and Compare</h3><a id="user-content-stage-4-diagnose-and-compare" aria-label="Permalink: Stage 4. Diagnose and Compare" href="#stage-4-diagnose-and-compare"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>

<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/SelfExplainML/PiML-Toolbox/blob/main/examples/results/model_diagnose.png"><img src="https://github.com/SelfExplainML/PiML-Toolbox/raw/main/examples/results/model_diagnose.png"/></a></p>

<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/SelfExplainML/PiML-Toolbox/blob/main/examples/results/model_compare.png"><img src="https://github.com/SelfExplainML/PiML-Toolbox/raw/main/examples/results/model_compare.png"/></a></p>

<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/SelfExplainML/PiML-Toolbox/blob/main/examples/results/model_fairness.png"><img src="https://github.com/SelfExplainML/PiML-Toolbox/raw/main/examples/results/model_fairness.png"/></a></p>
<div dir="auto" data-snippet-clipboard-copy-content="exp.model_fairness_compare()"><pre><span>exp</span>.<span>model_fairness_compare</span>()</pre></div>
<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/SelfExplainML/PiML-Toolbox/blob/main/examples/results/model_fairness_compare.png"><img src="https://github.com/SelfExplainML/PiML-Toolbox/raw/main/examples/results/model_fairness_compare.png"/></a></p>
<div dir="auto"><h2 tabindex="-1" dir="auto">Arbitrary Black-Box Modeling</h2><a id="user-content-arbitrary-black-box-modeling" aria-label="Permalink: Arbitrary Black-Box Modeling" href="#arbitrary-black-box-modeling"><svg viewBox="0 0 16 16" version="1.1" width="16" height="16" aria-hidden="true"><path d="m7.775 3.275 1.25-1.25a3.5 3.5 0 1 1 4.95 4.95l-2.5 2.5a3.5 3.5 0 0 1-4.95 0 .751.751 0 0 1 .018-1.042.751.751 0 0 1 1.042-.018 1.998 1.998 0 0 0 2.83 0l2.5-2.5a2.002 2.002 0 0 0-2.83-2.83l-1.25 1.25a.751.751 0 0 1-1.042-.018.751.751 0 0 1-.018-1.042Zm-4.69 9.64a1.998 1.998 0 0 0 2.83 0l1.25-1.25a.751.751 0 0 1 1.042.018.751.751 0 0 1 .018 1.042l-1.25 1.25a3.5 3.5 0 1 1-4.95-4.95l2.5-2.5a3.5 3.5 0 0 1 4.95 0 .751.751 0 0 1-.018 1.042.751.751 0 0 1-1.042.018 1.998 1.998 0 0 0-2.83 0l-2.5 2.5a1.998 1.998 0 0 0 0 2.83Z"></path></svg></a></div>
<p dir="auto">For example, train a complex LightGBM with depth 7 and register it to the experiment:</p>
<div dir="auto" data-snippet-clipboard-copy-content="from lightgbm import LGBMClassifier
exp.model_train(LGBMClassifier(max_depth=7), name=&#39;LGBM-7&#39;)"><pre><span>from</span> <span>lightgbm</span> <span>import</span> <span>LGBMClassifier</span>
<span>exp</span>.<span>model_train</span>(<span>LGBMClassifier</span>(<span>max_depth</span><span>=</span><span>7</span>), <span>name</span><span>=</span><span>&#39;LGBM-7&#39;</span>)</pre></div>
<p dir="auto">Then, compare it to inherently interpretable models (e.g. XGB2 and GAMI-Net):</p>

<p dir="auto"><a target="_blank" rel="noopener noreferrer" href="https://github.com/SelfExplainML/PiML-Toolbox/blob/main/examples/results/model_compare_2.png"><img src="https://github.com/SelfExplainML/PiML-Toolbox/raw/main/examples/results/model_compare_2.png"/></a></p>

<details open="">
  <summary><strong>PiML, ReLU-DNN Aletheia and GAMI-Net</strong></summary><hr/>
<p dir="auto">&#34;PiML Toolbox for Interpretable Machine Learning Model Development and Diagnostics&#34; (A. Sudjianto, A. Zhang, Z. Yang, Y. Su and N. Zeng, 2023) <a href="https://arxiv.org/abs/2305.04214" rel="nofollow">arXiv link</a></p>
<div dir="auto" data-snippet-clipboard-copy-content="@article{sudjianto2023piml,
title={PiML Toolbox for Interpretable Machine Learning Model Development and Diagnostics},
author={Sudjianto, Agus and Zhang, Aijun and Yang, Zebin and Su, Yu and Zeng, Ningzhou},
year={2023}
}"><pre>@article{sudjianto2023piml,
title={PiML Toolbox for Interpretable Machine Learning Model Development and Diagnostics},
author={Sudjianto, Agus and Zhang, Aijun and Yang, Zebin and Su, Yu and Zeng, Ningzhou},
year={2023}
}</pre></div>
<p dir="auto">&#34;Designing Inherently Interpretable Machine Learning Models&#34; (A. Sudjianto and A. Zhang, 2021)  <a href="https://arxiv.org/abs/2111.01743" rel="nofollow">arXiv link</a></p>
<div dir="auto" data-snippet-clipboard-copy-content="@article{sudjianto2021designing,
title={Designing Inherently Interpretable Machine Learning Models},
author={Sudjianto, Agus and Zhang, Aijun},
journal={arXiv preprint:2111.01743},
year={2021}
}"><pre>@article{sudjianto2021designing,
title={Designing Inherently Interpretable Machine Learning Models},
author={Sudjianto, Agus and Zhang, Aijun},
journal={arXiv preprint:2111.01743},
year={2021}
}</pre></div>
<p dir="auto">&#34;Unwrapping The Black Box of Deep ReLU Networks: Interpretability, Diagnostics, and Simplification&#34; (A. Sudjianto, W. Knauth, R. Singh, Z. Yang and A. Zhang, 2020) <a href="https://arxiv.org/abs/2011.04041" rel="nofollow">arXiv link</a></p>
<div dir="auto" data-snippet-clipboard-copy-content="@article{sudjianto2020unwrapping,
title={Unwrapping the black box of deep ReLU networks: interpretability, diagnostics, and simplification},
author={Sudjianto, Agus and Knauth, William and Singh, Rahul and Yang, Zebin and Zhang, Aijun},
journal={arXiv preprint:2011.04041},
year={2020}
}"><pre>@article{sudjianto2020unwrapping,
title={Unwrapping the black box of deep ReLU networks: interpretability, diagnostics, and simplification},
author={Sudjianto, Agus and Knauth, William and Singh, Rahul and Yang, Zebin and Zhang, Aijun},
journal={arXiv preprint:2011.04041},
year={2020}
}</pre></div>
<p dir="auto">&#34;GAMI-Net: An Explainable Neural Network based on Generalized Additive Models with Structured Interactions&#34; (Z. Yang, A. Zhang, and A. Sudjianto, 2021) <a href="https://arxiv.org/abs/2003.07132" rel="nofollow">arXiv link</a></p>
<div dir="auto" data-snippet-clipboard-copy-content="@article{yang2021gami,
title={GAMI-Net: An explainable neural network based on generalized additive models with structured interactions},
author={Yang, Zebin and Zhang, Aijun and Sudjianto, Agus},
journal={Pattern Recognition},
volume={120},
pages={108192},
year={2021}
}"><pre>@article{yang2021gami,
title={GAMI-Net: An explainable neural network based on generalized additive models with structured interactions},
author={Yang, Zebin and Zhang, Aijun and Sudjianto, Agus},
journal={Pattern Recognition},
volume={120},
pages={108192},
year={2021}
}</pre></div>
</details>  
<details open="">
  <summary><strong>Other Interpretable ML Models</strong></summary><hr/>
<p dir="auto">&#34;Fast Interpretable Greedy-Tree Sums (FIGS)&#34; (Tan, Y.S., Singh, C., Nasseri, K., Agarwal, A. and Yu, B., 2022)</p>
<div dir="auto" data-snippet-clipboard-copy-content="@article{tan2022fast,
title={Fast interpretable greedy-tree sums (FIGS)},
author={Tan, Yan Shuo and Singh, Chandan and Nasseri, Keyan and Agarwal, Abhineet and Yu, Bin},
journal={arXiv preprint arXiv:2201.11931},
year={2022}
}"><pre>@article{tan2022fast,
title={Fast interpretable greedy-tree sums (FIGS)},
author={Tan, Yan Shuo and Singh, Chandan and Nasseri, Keyan and Agarwal, Abhineet and Yu, Bin},
journal={arXiv preprint arXiv:2201.11931},
year={2022}
}</pre></div>
<p dir="auto">&#34;Accurate intelligible models with pairwise interactions&#34; (Y. Lou, R. Caruana, J. Gehrke, and G. Hooker, 2013)</p>
<div dir="auto" data-snippet-clipboard-copy-content="@inproceedings{lou2013accurate,
title={Accurate intelligible models with pairwise interactions},
author={Lou, Yin and Caruana, Rich and Gehrke, Johannes and Hooker, Giles},
booktitle={Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages={623--631},
year={2013},
organization={ACM}
}  "><pre>@inproceedings{lou2013accurate,
title={Accurate intelligible models with pairwise interactions},
author={Lou, Yin and Caruana, Rich and Gehrke, Johannes and Hooker, Giles},
booktitle={Proceedings of the 19th ACM SIGKDD International Conference on Knowledge Discovery and Data Mining},
pages={623--631},
year={2013},
organization={ACM}
}  </pre></div>
<p dir="auto">&#34;Purifying Interaction Effects with the Functional ANOVA: An Efficient Algorithm for Recovering Identifiable Additive Models&#34; (Lengerich, B., Tan, S., Chang, C.H., Hooker, G. and Caruana, R., 2020)</p>
<div dir="auto" data-snippet-clipboard-copy-content="@inproceedings{lengerich2020purifying,
title={Purifying interaction effects with the functional anova: An efficient algorithm for recovering identifiable additive models},
author={Lengerich, Benjamin and Tan, Sarah and Chang, Chun-Hao and Hooker, Giles and Caruana, Rich},
booktitle={International Conference on Artificial Intelligence and Statistics},
pages={2402--2412},
year={2020},
organization={PMLR}
}"><pre>@inproceedings{lengerich2020purifying,
title={Purifying interaction effects with the functional anova: An efficient algorithm for recovering identifiable additive models},
author={Lengerich, Benjamin and Tan, Sarah and Chang, Chun-Hao and Hooker, Giles and Caruana, Rich},
booktitle={International Conference on Artificial Intelligence and Statistics},
pages={2402--2412},
year={2020},
organization={PMLR}
}</pre></div>
<p dir="auto">&#34;InterpretML: A Unified Framework for Machine Learning Interpretability&#34; (H. Nori, S. Jenkins, P. Koch, and R. Caruana, 2019)</p>
<div dir="auto" data-snippet-clipboard-copy-content="@article{nori2019interpretml,
title={InterpretML: A Unified Framework for Machine Learning Interpretability},
author={Nori, Harsha and Jenkins, Samuel and Koch, Paul and Caruana, Rich},
journal={arXiv preprint:1909.09223},
year={2019}
}"><pre>@article{nori2019interpretml,
title={InterpretML: A Unified Framework for Machine Learning Interpretability},
author={Nori, Harsha and Jenkins, Samuel and Koch, Paul and Caruana, Rich},
journal={arXiv preprint:1909.09223},
year={2019}
}</pre></div>
</details>
</article></div></div>
  </body>
</html>
