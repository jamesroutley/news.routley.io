<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://sheep.horse/2022/5/safety_and_performance_-_threadsafe_datastructures.html">Original</a>
    <h1>Safety and Performance â€“ Threadsafe Datastructures in C&#43;&#43;</h1>
    
    <div id="readability-page-1" class="page"><div itemprop="articleBody">
    <p><span><img alt="A spool of yarn" src="https://sheep.horse/2022/5/thread.webp"/></span>Multithreading is something that is often misunderstood by even senior programmers. I do a lot of interviewing and I have noticed that a large proportion of candidates have only vague notions of how to make a completely thread-safe datastructure. </p>
<p>Of course, the safest threaded code is code that does not share any data between threads at all. Sadly, it is impossible for most problems to avoid completely non-shared data so we have to deal with concurrent access somehow.</p>
<p>This post demonstrates three simple techniques and is not the last word on the subject. Rather it is a general overview of the hows and whys of basic thread safety. The code examples are in C++ but the general techniques apply to any language that allows threading.</p>
<p>If you want to follow along at home see the <a href="https://github.com/andrewstephens75/ThreadingTest">corresponding GitHub Repo</a>. </p>
<h2>The Database</h2>
<p>Let us start with a very simple class:</p>
<div><pre><span></span><span>// A simple &#34;database&#34; with no locking that is dangerous to use across multiple threads</span>
<span>// The sleep_for statements simulate a more complex operation</span>
<span>class</span> <span>Database</span>
<span>{</span>
<span>public</span><span>:</span>
    <span>Database</span><span>()</span>
    <span>{</span>
        <span>std</span><span>::</span><span>fill</span><span>(</span><span>data_</span><span>.</span><span>begin</span><span>(),</span> <span>data_</span><span>.</span><span>end</span><span>(),</span> <span>0</span><span>);</span>
    <span>}</span>

    <span>// Obtain a value</span>
    <span>int</span> <span>readValue</span><span>(</span><span>size_t</span> <span>index</span><span>)</span> <span>const</span>
    <span>{</span>
        <span>std</span><span>::</span><span>this_thread</span><span>::</span><span>sleep_for</span><span>(</span><span>std</span><span>::</span><span>chrono</span><span>::</span><span>milliseconds</span><span>(</span><span>1</span><span>));</span>
        <span>return</span> <span>data_</span><span>.</span><span>at</span><span>(</span><span>index</span><span>);</span>
    <span>}</span>

    <span>// update a value</span>
    <span>void</span> <span>updateValue</span><span>(</span><span>size_t</span> <span>index</span><span>,</span> <span>int64_t</span> <span>value</span><span>)</span>
    <span>{</span>
        <span>std</span><span>::</span><span>this_thread</span><span>::</span><span>sleep_for</span><span>(</span><span>std</span><span>::</span><span>chrono</span><span>::</span><span>milliseconds</span><span>(</span><span>5</span><span>));</span>
        <span>data_</span><span>.</span><span>at</span><span>(</span><span>index</span><span>)</span> <span>+=</span> <span>value</span><span>;</span>
    <span>}</span>

    <span>// used for testing</span>
    <span>bool</span> <span>isAllZero</span><span>()</span>
    <span>{</span>
        <span>return</span> <span>std</span><span>::</span><span>all_of</span><span>(</span><span>data_</span><span>.</span><span>begin</span><span>(),</span> <span>data_</span><span>.</span><span>end</span><span>(),</span> <span>[](</span><span>const</span> <span>int64_t</span> <span>&amp;</span><span>x</span><span>)</span> <span>-&gt;</span> <span>bool</span>
                           <span>{</span> <span>return</span> <span>x</span> <span>==</span> <span>0</span><span>;</span> <span>});</span>
    <span>}</span>

    <span>static</span> <span>constexpr</span> <span>size_t</span> <span>DATABASE_SIZE</span> <span>=</span> <span>10</span><span>;</span>
    <span>static</span> <span>constexpr</span> <span>auto</span> <span>DATABASE_TYPE</span> <span>=</span> <span>&#34;non-threadsafe database&#34;</span><span>;</span>

    <span>friend</span> <span>std</span><span>::</span><span>ostream</span> <span>&amp;</span><span>operator</span><span>&lt;&lt;</span><span>(</span><span>std</span><span>::</span><span>ostream</span> <span>&amp;</span><span>os</span><span>,</span> <span>const</span> <span>Database</span> <span>&amp;</span><span>db</span><span>);</span>

<span>protected</span><span>:</span>
    <span>std</span><span>::</span><span>array</span><span>&lt;</span><span>int64_t</span><span>,</span> <span>DATABASE_SIZE</span><span>&gt;</span> <span>data_</span><span>;</span>
<span>};</span>
</pre></div>


<p>I hope this is somewhat self-explanatory. <code>Database</code> is a simple class (it hardly warrants the name) that wraps a std::array of 10 values. Users of this class can read and update values randomly without locking. The opperations are much simpler than a real database so I have added some <code>sleep_for()</code> statements to simulate a more complex datastructure (updates take an arbitrary 5 times longer than reads.)</p>
<p>For the purposes of this blog post I am going to load up the database with the following &#34;clients&#34; each running on a different thread:</p>
<ul>
<li>100 threads performing a series of updates to each element in the database in a random order. The updates include negative numbers and all sum to zero.</li>
<li>1000 threads performing reads on each element in a random order.</li>
</ul>
<p>The idea here is that I am simulating a framework where reads are frequent and fairly quick. Updates a much rarer but take much longer. This is a fairly common situation with client-server applications.</p>
<div><pre><span></span><span>template</span> <span>&lt;</span><span>typename</span> <span>DBTYPE</span><span>&gt;</span>
<span>void</span> <span>testDatabase</span><span>()</span>
<span>{</span>
    <span>DBTYPE</span> <span>db</span><span>;</span>

    <span>std</span><span>::</span><span>vector</span><span>&lt;</span><span>std</span><span>::</span><span>thread</span><span>&gt;</span> <span>threads</span><span>;</span>

    <span>auto</span> <span>startTime</span> <span>=</span> <span>std</span><span>::</span><span>chrono</span><span>::</span><span>high_resolution_clock</span><span>::</span><span>now</span><span>();</span>

    <span>for</span> <span>(</span><span>size_t</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>100</span><span>;</span> <span>++</span><span>i</span><span>)</span>
    <span>{</span>
        <span>threads</span><span>.</span><span>emplace_back</span><span>([</span><span>&amp;</span><span>]()</span>
                             <span>{</span>
            <span>for</span> <span>(</span><span>int</span> <span>repeat</span> <span>=</span> <span>0</span><span>;</span> <span>repeat</span> <span>&lt;</span> <span>1</span><span>;</span> <span>++</span><span>repeat</span><span>)</span>
            <span>{</span>
                <span>updateAllInRandomOrder</span><span>(</span><span>db</span><span>,</span> <span>25</span><span>,</span> <span>threads</span><span>.</span><span>size</span><span>());</span>
                <span>updateAllInRandomOrder</span><span>(</span><span>db</span><span>,</span> <span>-40</span><span>,</span> <span>threads</span><span>.</span><span>size</span><span>());</span>
                <span>updateAllInRandomOrder</span><span>(</span><span>db</span><span>,</span> <span>15</span><span>,</span> <span>threads</span><span>.</span><span>size</span><span>());</span>
            <span>}</span> <span>});</span>
    <span>}</span>

    <span>for</span> <span>(</span><span>size_t</span> <span>i</span> <span>=</span> <span>0</span><span>;</span> <span>i</span> <span>&lt;</span> <span>1000</span><span>;</span> <span>++</span><span>i</span><span>)</span>
    <span>{</span>
        <span>threads</span><span>.</span><span>emplace_back</span><span>([</span><span>&amp;</span><span>]()</span>
                             <span>{</span>
            <span>for</span> <span>(</span><span>int</span> <span>repeat</span> <span>=</span> <span>0</span><span>;</span> <span>repeat</span> <span>&lt;</span> <span>1</span><span>;</span> <span>++</span><span>repeat</span><span>)</span>
            <span>{</span>
                <span>readAllInRandomOrder</span><span>(</span><span>db</span><span>,</span> <span>threads</span><span>.</span><span>size</span><span>());</span>
            <span>}</span> <span>});</span>
    <span>}</span>

    <span>std</span><span>::</span><span>for_each</span><span>(</span><span>threads</span><span>.</span><span>begin</span><span>(),</span> <span>threads</span><span>.</span><span>end</span><span>(),</span> <span>[</span><span>&amp;</span><span>](</span><span>std</span><span>::</span><span>thread</span> <span>&amp;</span><span>t</span><span>)</span>
                  <span>{</span>
        <span>if</span> <span>(</span><span>t</span><span>.</span><span>joinable</span><span>())</span>
        <span>{</span>
            <span>t</span><span>.</span><span>join</span><span>();</span>
        <span>}</span> <span>});</span>

    <span>auto</span> <span>endTime</span> <span>=</span> <span>std</span><span>::</span><span>chrono</span><span>::</span><span>high_resolution_clock</span><span>::</span><span>now</span><span>();</span>

    <span>std</span><span>::</span><span>cout</span> <span>&lt;&lt;</span> <span>&#34;Results for &#34;</span> <span>&lt;&lt;</span> <span>DBTYPE</span><span>::</span><span>DATABASE_TYPE</span> <span>&lt;&lt;</span> <span>&#34;:</span><span>\n</span><span>&#34;</span>
              <span>&lt;&lt;</span> <span>&#34;  Elapsed Time:      &#34;</span> <span>&lt;&lt;</span> <span>std</span><span>::</span><span>chrono</span><span>::</span><span>duration_cast</span><span>&lt;</span><span>std</span><span>::</span><span>chrono</span><span>::</span><span>milliseconds</span><span>&gt;</span><span>(</span><span>endTime</span> <span>-</span> <span>startTime</span><span>).</span><span>count</span><span>()</span> <span>&lt;&lt;</span> <span>&#34;ms</span><span>\n</span><span>&#34;</span>
              <span>&lt;&lt;</span> <span>&#34;  Database Contents: &#34;</span> <span>&lt;&lt;</span> <span>db</span> <span>&lt;&lt;</span> <span>&#34;</span><span>\n</span><span>&#34;</span>
              <span>&lt;&lt;</span> <span>&#34;  All Zero:          &#34;</span> <span>&lt;&lt;</span> <span>(</span><span>db</span><span>.</span><span>isAllZero</span><span>()</span> <span>?</span> <span>&#34;Pass&#34;</span> <span>:</span> <span>&#34;FAILED!!!&#34;</span><span>)</span> <span>&lt;&lt;</span> <span>std</span><span>::</span><span>endl</span><span>;</span>
<span>}</span>
</pre></div>


<p>Lets see how it behaves on my M1 Macbook Pro:</p>
<div><pre><span></span>Results for non-threadsafe database:
  Elapsed Time:      558ms
  Database Contents: -25 40 0 0 0 0 0 0 0 0 
  All Zero:          FAILED!!!
</pre></div>


<p>Here you can see that the non-threadsafe database was very quick for executing 1100 threads but actually failed the test due to unsafe updates (you will get different results if you try this locally but it will still probably fail). Because all the updates eventually sum to zero, any non-zero elements in the array mean a failed test (and data corruption in the real world!)</p>
<h2>Why Is This Not Threadsafe?</h2>
<p>There are two issue, one obvious and one less so.</p>
<ul>
<li>The <code>data_.at(index) += value;</code> statement is the main problem. This statement can be broken down into three (pseudo) instructions:</li>
<li>But there is a more subtle problem. Even the <code>readValue()</code> method is not threadsafe in the face of other threads that may be writing. The reason is that accessing an int64_t is not necessarily atomic (this depends on the CPU architecture.) If you are reading/writing an int64_t while another thread is writing to it then you might not end up with either the previous value or the updated one (both acceptable results.) Instead you may end up with some mixed up value as the CPU managed to update the high bits but not the low bits.</li>
</ul>
<p>Either way, data corruption is always possible.</p>
<h2>Making the Database Threadsafe</h2>
<p>The easiest way to make a datastructure threadsafe to to introduce a <code>std::mutex</code>.</p>
<div><pre><span></span><span>// A database with simple locking using a mutex</span>
<span>// Threadsafe but slower</span>
<span>class</span> <span>SingleMutexDatabase</span> <span>:</span> <span>public</span> <span>Database</span>
<span>{</span>
<span>public</span><span>:</span>
    <span>SingleMutexDatabase</span><span>()</span> <span>:</span> <span>Database</span><span>(){};</span>
    <span>int</span> <span>readValue</span><span>(</span><span>size_t</span> <span>index</span><span>)</span> <span>const</span>
    <span>{</span>
        <span>std</span><span>::</span><span>lock_guard</span><span>&lt;</span><span>std</span><span>::</span><span>mutex</span><span>&gt;</span> <span>lock</span><span>{</span><span>mutex_</span><span>};</span>
        <span>return</span> <span>Database</span><span>::</span><span>readValue</span><span>(</span><span>index</span><span>);</span>
    <span>}</span>

    <span>void</span> <span>updateValue</span><span>(</span><span>size_t</span> <span>index</span><span>,</span> <span>int64_t</span> <span>value</span><span>)</span>
    <span>{</span>
        <span>std</span><span>::</span><span>lock_guard</span><span>&lt;</span><span>std</span><span>::</span><span>mutex</span><span>&gt;</span> <span>lock</span><span>{</span><span>mutex_</span><span>};</span>
        <span>Database</span><span>::</span><span>updateValue</span><span>(</span><span>index</span><span>,</span> <span>value</span><span>);</span>
    <span>}</span>

    <span>static</span> <span>constexpr</span> <span>auto</span> <span>DATABASE_TYPE</span> <span>=</span> <span>&#34;single mutex database&#34;</span><span>;</span>

<span>private</span><span>:</span>
    <span>mutable</span> <span>std</span><span>::</span><span>mutex</span> <span>mutex_</span><span>;</span>
<span>};</span>
</pre></div>


<p>Nice and simple. Note that both the <code>readValue</code> and the <code>writeValue</code> methods need to be protected due to the issue discussed in the previous section.</p>
<p>Lets see how it works out:</p>
<div><pre><span></span>Results for single mutex database:
  Elapsed Time:      31301ms
  Database Contents: 0 0 0 0 0 0 0 0 0 0 
  All Zero:          Pass
</pre></div>


<p>Nice. No data corruption. On the minus side, the operations took over 50 times longer!</p>
<p>Maybe that is acceptable - after all it is better to be slowly correct than speedily wrong. 95% of threadsafe datastructures I see in the wild rely on a simple mutex just like this and perform just fine. </p>
<p>Remember, this example is contrived to expose the performance problems. If performance meets requirements in the real world then we can stop here. But the mutex clearly puts some limit on speed at which we can handle clients accessing our database. We might be able to do better.</p>
<h2>Shared Mutex</h2>
<p>Recall that we have a small number of clients writing to the database with a larger number of clients just reading. C++17 provides a specialized mutex for just this situation - <code>std::shared_mutex</code>.</p>
<div><pre><span></span><span>// A database using a shared_mutex allowing multiple reads at the same time</span>
<span>class</span> <span>SharedMutexDatabase</span> <span>:</span> <span>public</span> <span>Database</span>
<span>{</span>
<span>public</span><span>:</span>
    <span>SharedMutexDatabase</span><span>()</span> <span>:</span> <span>Database</span><span>(){};</span>
    <span>int</span> <span>readValue</span><span>(</span><span>size_t</span> <span>index</span><span>)</span> <span>const</span>
    <span>{</span>
        <span>// reads can oocurs simultaneously with a shared_lock</span>
        <span>std</span><span>::</span><span>shared_lock</span> <span>lock</span><span>{</span><span>shared_mutex_</span><span>};</span>
        <span>return</span> <span>Database</span><span>::</span><span>readValue</span><span>(</span><span>index</span><span>);</span>
    <span>}</span>

    <span>void</span> <span>updateValue</span><span>(</span><span>size_t</span> <span>index</span><span>,</span> <span>int64_t</span> <span>value</span><span>)</span>
    <span>{</span>
        <span>// writes require a unique_lock</span>
        <span>std</span><span>::</span><span>unique_lock</span> <span>lock</span><span>{</span><span>shared_mutex_</span><span>};</span>
        <span>Database</span><span>::</span><span>updateValue</span><span>(</span><span>index</span><span>,</span> <span>value</span><span>);</span>
    <span>}</span>

    <span>static</span> <span>constexpr</span> <span>auto</span> <span>DATABASE_TYPE</span> <span>=</span> <span>&#34;shared mutex database&#34;</span><span>;</span>

<span>private</span><span>:</span>
    <span>mutable</span> <span>std</span><span>::</span><span>shared_mutex</span> <span>shared_mutex_</span><span>;</span>
<span>};</span>
</pre></div>


<p><code>shared_mutex</code> implements what is sometimes called a reader/writer lock. Multiple readers can lock the mutex with <code>shared_lock</code> and operate in the knowledge that no writer thread can change the datastructure. When a writer obtains the lock with <code>std::unique_lock</code>, the reader threads and all other writers are blocked.</p>
<p>This is exactly what we want - the readers can all read in parallel, only blocked during the relatively rare updates.</p>
<p>How does it perform:</p>
<div><pre><span></span>Results for shared mutex database:
  Elapsed Time:      24058ms
  Database Contents: 0 0 0 0 0 0 0 0 0 0 
  All Zero:          Pass
</pre></div>


<p>A significant improvement, only 43 times slower than not locking.</p>
<p>And here we come to the major problem with <code>shared_mutex</code>. Although in theory it should lead to better performance, much of the gain is erased by the very significant overhead that <code>shared_mutex</code> introduces. I had to play around with the operations in my test program to tilt the numbers in <code>shared_mutex</code>es favor - for many workloads it was significantly slower than even a normal mutex.</p>
<p>That said, <code>shared_mutex</code> has its uses and will shine when writes are very infrequent and very expensive.</p>
<h2>Breaking Up The Mutex</h2>
<p>A more generally applicable way of getting better performance is to break up the mutex. This works well in this case because the entries in our database are completely independant so having multiple mutexes each protecting part of the datastructure make sense.</p>
<div><pre><span></span><span>// A database where access is controlled by multiple mutexes allowing</span>
<span>// some degree of shared access</span>
<span>class</span> <span>SplitMutexDatabase</span> <span>:</span> <span>public</span> <span>Database</span>
<span>{</span>
<span>public</span><span>:</span>
    <span>SplitMutexDatabase</span><span>()</span> <span>:</span> <span>Database</span><span>()</span> <span>{}</span>
    <span>int</span> <span>readValue</span><span>(</span><span>size_t</span> <span>index</span><span>)</span> <span>const</span>
    <span>{</span>
        <span>std</span><span>::</span><span>lock_guard</span><span>&lt;</span><span>std</span><span>::</span><span>mutex</span><span>&gt;</span> <span>lock</span><span>{</span>
            <span>mutexes_</span><span>[</span><span>index</span> <span>%</span> <span>mutexes_</span><span>.</span><span>size</span><span>()]};</span>
        <span>return</span> <span>Database</span><span>::</span><span>readValue</span><span>(</span><span>index</span><span>);</span>
    <span>};</span>

    <span>void</span> <span>updateValue</span><span>(</span><span>size_t</span> <span>index</span><span>,</span> <span>int64_t</span> <span>value</span><span>)</span>
    <span>{</span>
        <span>std</span><span>::</span><span>lock_guard</span><span>&lt;</span><span>std</span><span>::</span><span>mutex</span><span>&gt;</span> <span>lock</span><span>{</span>
            <span>mutexes_</span><span>[</span><span>index</span> <span>%</span> <span>mutexes_</span><span>.</span><span>size</span><span>()]};</span>
        <span>Database</span><span>::</span><span>updateValue</span><span>(</span><span>index</span><span>,</span> <span>value</span><span>);</span>
    <span>}</span>

    <span>static</span> <span>constexpr</span> <span>auto</span> <span>DATABASE_TYPE</span> <span>=</span> <span>&#34;split mutex database&#34;</span><span>;</span>

<span>private</span><span>:</span>
    <span>mutable</span> <span>std</span><span>::</span><span>array</span><span>&lt;</span><span>std</span><span>::</span><span>mutex</span><span>,</span> <span>DATABASE_SIZE</span> <span>/</span> <span>2</span><span>&gt;</span> <span>mutexes_</span><span>;</span>
<span>};</span>
</pre></div>


<p>Instead of a single mutex, SplitMutexDatabase creates 5 mutexes each protecting two entries. In this case, the first mutex is locked for entries 0 and 5, the second for entries 1 and 6, etc. </p>
<p>There is a tradeoff between the performance gains for not having to lock the whole datastructure for every operation and the overhead of storing multiple mutexes. The optimum ratio of mutexes to entries is very dependent on your datastructure and access pattern.</p>
<div><pre><span></span>Results for split mutex database:
  Elapsed Time:      6822ms
  Database Contents: 0 0 0 0 0 0 0 0 0 0 
  All Zero:          Pass
</pre></div>


<p>Still much slower than no locking but we have regained much of the performance lost by the single mutex and are now just 12 times slower.</p>
<h2>Other Approaches to Thread Safety</h2>
<p>There are other (more invasive) approaches to this problem. This is a non-exhaustive survey.</p>
<h3>Atomic operations</h3>
<p>Rarely you can make all the operations on your datastructure atomic but if you can then you can get away with no explicit locking at all. Only the simplest data can be completely atomic though.</p>
<h3>Copy-on-write</h3>
<p>If you can stand reads not getting the absolutely latest information and only have a single thread writing then you can implement a copy-on-write datastructure. In this approach, your internal datastructure is indirectly accessed via a <code>shared_ptr</code> and is always const. Multiple readers can access this without locking. When the writer thread needs to do a write, it makes a copy of the entire internal datastructure, modifies the copy, and updates the <code>shared_ptr</code> to point to the new version.</p>
<p>This approach still requires a mutex, but it only needs to be held when a reader thread grabs the pointer to the internal datastructure and when the writer thread updates it. Note that <code>shared_ptr</code> is not threadsafe when assigning a new object.</p>
<p>Copy-on-write works well when the datastructure can be copied easily, writes are infrequent but slow, and only a single thread can ever perform a write. None of the readers need to wait for the slow updates to finish.</p>
<p>If this applies then copy-on-write can provide a huge performance gain at the expense of more complex code.</p>
<h3>Actors</h3>
<p>Sometimes it is convenient not to use locking at all. In this approach, all operations are redirected to a queue that is process by a single thread managed by the datastructure itself. This has significant overhead and defeats some of the purpose of multithreading since only one thread ever accesses the datastructure. </p>
<p>Actors are useful if you have complex access patterns as implementing an actor can greatly simplify your code and ensure correctness.</p>
<h3>Combinations</h3>
<p>Some of these techniques can be used in combination. For instance, a copy-on-write database could allow reads from multiple threads but queue up writes on a single thread using a task queue like an Actor.</p>
    </div></div>
  </body>
</html>
