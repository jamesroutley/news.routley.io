<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://replicate.com/andreasjansson/cantable-diffuguesion">Original</a>
    <h1>Cantable Diffuguesion: Bach chorale generation and harmonization</h1>
    
    <div id="readability-page-1" class="page"><div>
  
<p><em>Bach chorale generation and harmonization</em></p>
<h2>Usage</h2>
<p>You can use Cantable Diffuguesion to generate Bach chorales unconditionally, or harmonize melodies or parts of melodies.</p>
<p>For harmonization we use <a href="https://web.mit.edu/music21/doc/moduleReference/moduleTinyNotation.html" rel="nofollow">tinyNotation</a>, with a few modifications:</p>
<ul>
<li>The <code>?</code> symbol followed by a duration denotes a section that the model should in-paint, e.g. <code>?2</code> will in-paint a half note duration.</li>
<li>The <code>?*</code> symbol will in-paint everything between a defined beginning and an end, e.g. <code>c2 ?* B4 c2</code> will start the piece with <code>c2</code>, then generate notes for the specified duration, and finally the melody will end with <code>B4 c2</code>.</li>
<li>Optional bars <code>|</code> are ignored and can be used to make the melody notation more pleasing.</li>
</ul>
<h2>Training</h2>
<p>Cantable Diffuguesion is a diffusion model trained to generate Bach chorales. Four-part chorales are presented to the network as 4-channel images. As in Stable Diffusion, a U-Net is trained to predict the noise residual.</p>
<p>After training the generative model we add 12 channels to the inputs, with the middle four channels representing a mask, and the last four channels are masked chorales. We mask the four channels individually, as opposed to <a href="https://huggingface.co/stabilityai/stable-diffusion-2-inpainting" rel="nofollow">Stable Diffusion Inpainting</a> that use a one-channel mask.</p>
<h2>Dataset</h2>
<p>We use all four-part pieces in the <a href="https://web.mit.edu/music21/doc/moduleReference/moduleCorpusChorales.html" rel="nofollow">Music21 Bach Chorales corpus</a>. 85% are used for training.</p>
<h2>Inspiration</h2>
<ul>
<li><a href="https://github.com/riffusion/riffusion" rel="nofollow">Riffusion</a></li>
<li><a href="https://arxiv.org/abs/1612.01010" rel="nofollow">DeepBach</a></li>
<li><a href="https://github.com/huggingface/diffusers/blob/50b6513531da7e258204871a9c675a56875d9e69/examples/research_projects/dreambooth_inpaint/README.md" rel="nofollow">Dreambooth Inpainting</a></li>
</ul>
</div></div>
  </body>
</html>
