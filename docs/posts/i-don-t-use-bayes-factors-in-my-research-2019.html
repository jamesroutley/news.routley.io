<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="http://datacolada.org/78a">Original</a>
    <h1>I don&#39;t use Bayes factors in my research (2019)</h1>
    
    <div id="readability-page-1" class="page"><div id="page">

		
						
					
					


					<div id="content">
						<div>
						<div>

	<div id="primary">
		<main id="main">

		
<article id="post-4197">
			

	<div>
		<p>Would raising the minimum wage by $4 lead to greater unemployment? Milton, a Chicago economist, has a theory (supply and demand) that says so. Milton believes the causal effect is anywhere between 1% and 10%. After the minimum wage increase of $4, unemployment goes up 1%.  Milton feels bad about the unemployed but good about his theory.</p>
<p>But then, Thomas, a Bayesian colleague, tells Milton to wipe that smile on his face, because his prediction was <em>wrong</em>. The Bayes factor for that 1% increase in unemployment ‘supports the null’ of <em>no effect </em>of wage on unemployment.</p>
<p><a href="http://datacolada.org/storage_strong/Sheldon-1.png"><img decoding="async" src="http://datacolada.org/storage_strong/Sheldon-1.png" alt="" width="1378" height="434" srcset="http://datacolada.org/storage_strong/Sheldon-1.png 1378w, http://datacolada.org/storage_strong/Sheldon-1-300x94.png 300w, http://datacolada.org/storage_strong/Sheldon-1-768x242.png 768w, http://datacolada.org/storage_strong/Sheldon-1-1024x323.png 1024w, http://datacolada.org/storage_strong/Sheldon-1-850x268.png 850w" sizes="(max-width: 1378px) 100vw, 1378px"/></a></p>
<p>In this post I unpack this realistic scenario to explain two of the many reasons I don&#39;t use Bayes factors in my research.</p>
<p><span>Note: The numbers in this example were slightly changed a few hours after posting in response to an email from Zoltan Dienes (.<a href="http://www.sussex.ac.uk/profiles/718">htm</a>). See footnote for details</span> [<a href="#footnote_0_4197" id="identifier_0_4197" title="The original example had Milton predict 1%-6% and the truth come up 1.5%. Zoltan noted that a sensible operationalization of that description relying on the normal distribution, and if the 1.5% were statistically significantly different from 0, would lead to an inconclusive result that leans towards the alternative actually.  I originally chose the values haphazardly just to convey the intuition and did&#39;t think of approaching the example quantitatively, I should have. Sorry. And should have chosen an example that lead to a stronger paradox. Sorry again. In any case, after his email I tweaked the numbers so that a natural operationalization does lead to supporting the null. The R Code to see the original and modified example is posted here">1</a>].  <span>I also archived original post</span> (<a href="https://web.archive.org/web/20190906160118/http://datacolada.org/78a">.html</a>).</p>
<p><strong>What Bayes Factors Do<br/>
</strong>Bayes factors provide the results of a horse-race. They tell us how much more consistent the data are with an alternative hypothesis than with the null hypothesis. For example, if a pregnancy test is 10 times more likely to come up positive when pregnant than when not, then the Bayes factor is BF=10 for a positive result.</p>
<p>The BF for the pregnancy test is simple because the alternative hypothesis involves <em>only one</em> possibility: “being pregnant”. But BFs are usually complicated because the alternative hypotheses they consider include <em>many</em> possibilities.</p>
<p>In the minimum wage example, the alternative hypothesis isn’t just that “the minimum wage matters”.  To compute a Bayes factor we need to specify <em>how much </em>we think that it matters. Or actually, how likely each possible effect size is. How likely is a 2% increase in unemployment, how likely a 2.1%, a 5%, a 5.1%, etc.</p>
<p>It seems impossible to use a social science theory like supply and demand, to meaningfully generate such  numbers. But let’s try it so that this post is not overly short.</p>
<p>Milton said the effect may be “<em>anywhere between 1% and 10%</em>”. Let’s take that unreasonably literally to mean: “my belief about the <strong>true</strong> <strong>effect</strong> on unemployment is captured by a uniform distribution between 1% and 10%.” [<a href="#footnote_1_4197" id="identifier_1_4197" title="I keep saying true effect because “the alternative” is not about what effect you will get in your sample, the estimated effect, it is about what is the true effect in the world.">2</a>].</p>
<p>With our uniform distribution in hand, we compute the Bayes factor by asking if the observed effect, 1%, is closer to the null of 0%, or to “the alternative”, the uniform 1%-10%. If it is sufficiently closer to 0%, we &#34;accept&#34; the null.</p>
<p><strong>Interlude<br/>
</strong>Bayes factors, then, compare the null to “the alternative”. Implementing this comparison requires doing two things that I think most researchers would object to, if they realized that that’s what they were doing when they reported Bayes factors in their papers.</p>
<p><strong>Thing 1. Falsifying something we never tested<br/>
</strong>To compute a Bayes factor we need to generate “the alternative” hypothesis. In social science, theory alone will not deliver one. So we need a substitute for the actual theory to be compared to the null.</p>
<p>Bayesian advocates recommend a variety of substitutes for generating “the alternative”. For example, that we rely on our intuition of how big the effect is, on previous findings, on what we can afford to study, etc.  [<a href="#footnote_2_4197" id="identifier_2_4197" title="Most commonly, however, the alternative hypothesis used in Bayes factors calculations reflects neither theory nor expectations. The alternative used in almost every Bayes factor you have seen, or will see, involves an arbitrary default distribution, e.g., that the effect is normally distributed with M=0 and SD=.7. This is a generic ad-hoc mathematization of what a generic effect may be, taking into account neither data nor theory. Note that this default “alternative” includes an effect of zero. Indeed, it considers it the most likely effect size. So the null is zero, and ‘the alternative’ also states the effect may be zero.">3</a>].</p>
<p><span>Note: By theory I merely mean the rationale for investigating the effect of x on y. A theory can be as simple as “I think people value a mug more once they own it”.</span></p>
<p><a href="http://datacolada.org/storage_strong/2015/01/Door-River-11.jpg"><img decoding="async" loading="lazy" src="http://datacolada.org/storage_strong/2015/01/Door-River-11.jpg" alt="" width="262" height="174" srcset="http://datacolada.org/storage_strong/2015/01/Door-River-11.jpg 344w, http://datacolada.org/storage_strong/2015/01/Door-River-11-300x199.jpg 300w" sizes="(max-width: 262px) 100vw, 262px"/></a></p>
<p>Imagine I am the first person to investigate whether arbitrary anchors affect the perceived length of rivers. I want to compute a Bayes factor, so I need to specify “the alternative” hypothesis.  To do that I need to convert the theory “<em>higher anchors lead to higher guesses of river lengths</em>” into a distribution that assigns a likelihood to every possible <strong>true</strong> anchoring effect size. I am as clueless as you are at figuring out what in the world that distribution is, so I follow the advice from some Bayesian papers and I look up similar previous findings. I find studies of anchoring on perceived door height, and the average effect size of those is d̂=.8. So I use as “the alternative” hypothesis one that gives d=.8 some reasonable prior probability.</p>
<p>I run my study and get d̂=.24, <em>p</em>&lt;.0001.</p>
<p>While d̂=.24 is not nothing, it happens to be closer to the null of 0 than to that “the alternative”, on average. So the Bayesian analysis tell me to “accept the null.”</p>
<p>But I have not falsified anchoring. I have not even falsified anchoring for rivers.</p>
<p>All I have falsified is the irrelevant hypothesis that anchoring for rivers is like anchoring for doors.</p>
<p><strong>Thing 2: Rejecting theories that predict what we observe<br/>
</strong>What would it take <em>for</em> <em>you </em>to conclude that the minimum wage does not increase unemployment? If you are like me, it would be something like this “<em>if the estimated effect on unemployment were close enough to zero to rule out consequential effects, I will accept the null.</em>”</p>
<p>That&#39;s easy enough to do with a confidence interval, but it is not at all what Bayes Factors do.</p>
<p>Bayes factors don’t compare the observed effect to <strong><em>the smallest</em></strong> effect of interest.</p>
<p>That’s why a BF can interpret a 1% effect on unemployment as falsifying the prediction that the effect will be anywhere between 1% and 10%. Unlike you and I, the Bayes factor does not ask “is 1% within the predicted range%?” The BF asks:</p>
<p>“How likely is it that we would observe a 1% effect, if the true effect were 10.0%?”, and</p>
<p>It then <em>averages</em> all those numbers. And, if that <em>average</em> is sufficiently small, it ‘accepts the null’.</p>
<p>If Milton had said “the effect is anywhere between 1% and 2%” then observing 1% would “support the alternative.”</p>
<p>The Bayes factor approach to falsification, averaging how well every possible prediction fits the data, instead of whether the data is or is not consistent with a prediction, is different from how we falsify predictions in everyday life, in the scientific method, and when relying on standard statistical approaches.</p>
<p>What if “the alternative” hypothesis were not a distribution of values that we had to average over?</p>
<p>OK, but how often does it <em>actually</em> happen that a Bayes factor deems a prediction within the set of hypothesized values as falsifying the hypothesis? <strong> Basically always. </strong>At least with default Bayes factors, every time the <em>null</em> is supported, the value we observe is predicted by the <em>alternative</em>. See footnote [<a href="#footnote_4_4197" id="identifier_4_4197" title="The default &#34;the alternative&#34;, e.g., the one used by the BayesFactors R package, involves a distribution centered at zero, and where every real number is possible, thus any observed value is consistent with the alternative defined this way, and therefore, every time you accept the null, you have observed a value that &#39;the alternative&#39; gives some probability to being true.  But this does not need to be the case. The alternative could be just one value (see previous footnote). Also, the null could be defined around zero not exactly at zero so here some observed values would belong to the null and not to the alternative. But, even in this latter case, it will still quite often be the case that a value predicted by the alternative and not by the null will lead the Bayes factor to support the null">5</a>].</p>
<p><strong>In sum.<br/>
</strong>To use Bayes factors to test hypotheses: you need to be OK with the following two things:</p>
<p><span>This post, 78a, is the first in a series on Bayes factors. Post 78b is coming soon.</span></p>
<p><img decoding="async" loading="lazy" src="http://datacolada.org/storage_strong/2014/02/Wide-logo-300x145.jpg" alt="Wide logo" width="78" height="38" srcset="http://datacolada.org/storage_strong/2014/02/Wide-logo-300x145.jpg 300w, http://datacolada.org/storage_strong/2014/02/Wide-logo.jpg 320w" sizes="(max-width: 78px) 100vw, 78px"/></p>
<hr/>
<p><strong>Footnotes.</strong></p>


			</div>
</article>

		</main>
	</div>



</div>
</div>
</div>

</div></div>
  </body>
</html>
