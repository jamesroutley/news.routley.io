<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://fullstackdeeplearning.com/cloud-gpus/">Original</a>
    <h1>Cloud GPU Resources and Pricing</h1>
    
    <div id="readability-page-1" class="page"><div data-md-component="main">
        <div>
          
            
              
                
              
              
            
            
              
                
              
              
            
          
          
            <div data-md-component="content">
              <article>
                

                  

  
  


  


<p>Training and running neural networks often requires hardware acceleration,
and the most popular hardware accelerator is the venerable <em>graphics processing unit</em>,
or GPU.</p>
<p>We have assembled cloud GPU vendor pricing all into tables, sortable and filterable to your liking!</p>
<p>We have split the vendor offerings into two classes:</p>
<ul>
<li><strong>GPU Cloud Servers</strong>, which are long-running (but possibly pre-emptible) machines, and</li>
<li><strong>Severless GPUs</strong>, which are machines that scale-to-zero in the absence of traffic (like an AWS Lambda or Google Cloud Function)</li>
</ul>
<p><strong>We welcome your help in adding more cloud GPU providers and keeping the pricing info current.</strong></p>
<p>Please <a href="https://github.com/full-stack-deep-learning/website/issues/new?assignees=sergeyk&amp;labels=cloud-gpu&amp;template=gpu-cloud-pricing-update.md&amp;title=update+GPU+Cloud+Pricing">file an issue</a> or make a pull request to <a href="https://github.com/full-stack-deep-learning/website/">this repo</a>, editing <a href="https://github.com/full-stack-deep-learning/website/blob/main/docs/cloud-gpus/index.md">this file</a> to update the text on this page or one of the CSV files to update the data: <a href="https://github.com/full-stack-deep-learning/website/blob/main/docs/cloud-gpus/cloud-gpus.csv"><code>cloud-gpus.csv</code></a> for servers and <a href="https://github.com/full-stack-deep-learning/website/blob/main/docs/cloud-gpus/serverless-gpus.csv"><code>serverless-gpus.csv</code></a> for serverless options.</p>
<h2 id="gpu-cloud-server-comparison">GPU Cloud Server Comparison</h2>
<h3 id="notes">Notes</h3>
<ul>
<li>GCP does not have GPU &#34;instances&#34; in the same way that AWS and Azure do. Instead, any suitable machine can be connected to a configuration of GPUs. We have selected machines that are roughly equivalent to AWS options.</li>
<li>Regions were set to be the west or central parts of the United States. GPU availability depends on the region.</li>
<li>Raw data can be found in a <a href="https://github.com/full-stack-deep-learning/website/blob/main/docs/cloud-gpus/cloud-gpus.csv">csv on GitHub</a>.</li>
</ul>
<center><em>All prices are in $/hr.</em></center>


<h2 id="serverless-gpus">Serverless GPUs</h2>
<h3 id="notes_1">Notes</h3>
<ul>
<li>We use the classic definition of &#34;serverless&#34;, courtesy of <a href="https://www.jeremydaly.com/not-so-serverless-neptune/">the original AWS announcement on serverless computing</a>: no server management, flexible scaling, high availability, and no idle capacity. We only include services that fit this criterion in our options below.</li>
<li>Direct price comparisons are trickier for serverless offerings: cold boot time and autoscaling logic can substantially impact cost-of-traffic. Also, some providers only charge for time spent responding to requests, while others charge for other time you&#39;re using their machines, like booting or between requests (see the <code>Idle time charged?</code> column below).</li>
<li>Some of the providers allow configuration of CPU and RAM resources. We have selected reasonable defaults, generally comparable to the fixed offerings of other providers.</li>
<li>If you know a bit about your anticipated traffic patterns, you can use <a href="https://paylesstoaws.com/">this tool</a> to compare prices for AWS A100 GPU machines and Banana&#39;s serverless equivalent. Note that is is made by the developers of <a href="https://banana.dev/">Banana</a>, so may be biased.</li>
<li>Raw data can be found in a <a href="https://github.com/full-stack-deep-learning/website/blob/main/docs/cloud-gpus/serverless-gpus.csv">csv on GitHub</a>.</li>
<li>You can find pricing pages for the providers here: <a href="https://banana.dev#pricing">Banana</a>, <a href="https://docs.baseten.co/settings/pricing">Baseten</a>, <a href="https://modal.com/pricing">Modal</a>, <a href="https://replicate.com/pricing">Replicate</a></li>
<li>Serverless GPUs are a newer technology, so there are fewer players, the details change quickly, and you can expect bugs/growing pains. Stay frosty!</li>
</ul>


<h2 id="how-do-i-choose-a-gpu">How do I choose a GPU?</h2>
<p>This page is intended to track and make explorable
the current state of pricing and hardware for cloud GPUs.</p>
<p>If you want advice on which machines and cards are best for your use case,
we recommend
<a href="https://timdettmers.com/2023/01/16/which-gpu-for-deep-learning">Tim Dettmer&#39;s blog post on GPUs for deep learning</a>.</p>
<p>The whole post is a tutorial and FAQ on GPUS for DNNs,
but if you just want the resulting heuristics for decision-making, see the
<a href="https://timdettmers.com/2023/01/16/which-gpu-for-deep-learning/#GPU_Recommendations">&#34;GPU Recommendations&#34; section</a>,
which is the source of the chart below.</p>
<figure>
<p><img alt="Flowchart for quickly selecting an appropriate GPU for your needs, by Tim Dettmers" src="https://fullstackdeeplearning.com/cloud-gpus/dettmers_recs.png"/>
  </p>
<figcaption>
<p>Flowchart for quickly selecting an appropriate GPU for your needs, by <a href="https://timdettmers.com/2023/01/16/which-gpu-for-deep-learning/">Tim Dettmers</a></p>
</figcaption>
</figure>
<h2 id="gpu-raw-performance-numbers-and-datasheets">GPU Raw Performance Numbers and Datasheets</h2>
<p>Below are the raw TFLOPs of the different GPUs available from cloud providers.</p>
<table>
<thead>
<tr>
<th>Model</th>
<th>Arch</th>
<th>FP32</th>
<th>Mixed-precision</th>
<th>FP16</th>
<th>Source</th>
</tr>
</thead>
<tbody>
<tr>
<td>A100</td>
<td>Ampere</td>
<td>19.5</td>
<td>156</td>
<td>312</td>
<td><a href="https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/a100/pdf/nvidia-a100-datasheet-us-nvidia-1758950-r4-web.pdf">Datasheet</a></td>
</tr>
<tr>
<td>A10G</td>
<td>Ampere</td>
<td>35</td>
<td>35</td>
<td>70</td>
<td><a href="https://d1.awsstatic.com/product-marketing/ec2/NVIDIA_AWS_A10G_DataSheet_FINAL_02_17_2022.pdf">Datasheet</a></td>
</tr>
<tr>
<td>A6000</td>
<td>Ampere</td>
<td>38</td>
<td>?</td>
<td>?</td>
<td><a href="https://www.nvidia.com/content/dam/en-zz/Solutions/design-visualization/quadro-product-literature/proviz-print-nvidia-rtx-a6000-datasheet-us-nvidia-1454980-r9-web%20(1).pdf">Datasheet</a></td>
</tr>
<tr>
<td>V100</td>
<td>Volta</td>
<td>14</td>
<td>112</td>
<td>28</td>
<td><a href="https://images.nvidia.com/content/technologies/volta/pdf/tesla-volta-v100-datasheet-letter-fnl-web.pdf">Datasheet</a></td>
</tr>
<tr>
<td>T4</td>
<td>Turing</td>
<td>8.1</td>
<td>65</td>
<td>?</td>
<td><a href="https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/tesla-t4/t4-tensor-core-datasheet-951643.pdf">Datasheet</a></td>
</tr>
<tr>
<td>P4</td>
<td>Pascal</td>
<td>5.5</td>
<td>N/A</td>
<td>N/A</td>
<td><a href="https://images.nvidia.com/content/pdf/tesla/184457-Tesla-P4-Datasheet-NV-Final-Letter-Web.pdf">Datasheet</a></td>
</tr>
<tr>
<td>P100</td>
<td>Pascal</td>
<td>9.3</td>
<td>N/A</td>
<td>18.7</td>
<td><a href="https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/tesla-p100/pdf/nvidia-tesla-p100-PCIe-datasheet.pdf">Datasheet</a></td>
</tr>
<tr>
<td>K80</td>
<td>Kepler</td>
<td>8.73</td>
<td>N/A</td>
<td>N/A</td>
<td><a href="https://www.nvidia.com/content/dam/en-zz/Solutions/Data-Center/tesla-product-literature/Tesla-K80-BoardSpec-07317-001-v05.pdf">Datasheet</a></td>
</tr>
<tr>
<td>A40</td>
<td>Ampere</td>
<td>37</td>
<td>150</td>
<td>150</td>
<td><a href="https://images.nvidia.com/content/Solutions/data-center/a40/nvidia-a40-datasheet.pdf">Datasheet</a></td>
</tr>
</tbody>
</table>
<h2 id="gpu-performance-benchmarks">GPU Performance Benchmarks</h2>
<p>Below are some basic benchmarks for GPUs on common deep learning tasks.</p>
<figure>
<p><img alt="Benchmark of different GPUs on a single ImageNet epoch, by AIME" src="https://fullstackdeeplearning.com/cloud-gpus/aime_benchmarks.jpg"/>
  </p>
<figcaption>
<p>Benchmark of different GPUs on a single ImageNet epoch, by <a href="https://www.aime.info/en/blog/deep-learning-gpu-benchmarks-2021/">AIME</a></p>
</figcaption>
</figure>
<figure>
<p><img alt="Benchmark of different GPUs on a mix of tasks, by Lambda Labs" src="https://fullstackdeeplearning.com/cloud-gpus/lambda_benchmarks.png"/>
  </p>
<figcaption>
<p>Benchmark of different GPUs on a mix of tasks, by <a href="https://lambdalabs.com/gpu-benchmarks">Lambda Labs</a></p>
</figcaption>
</figure>


  


  



                

<div id="emailModal">
  <div>
    <h2>We are excited to share this course with you for <strong>free</strong>.</h2>
    <p>
      We have more upcoming great content.
      Subscribe to stay up to date as we release it.
    </p>
    
    
    <p><small><p>
      <span>
        We take your privacy and attention very seriously and will never spam you.
      </span>
      I am already a subscriber
    </p></small>
  </p></div>
</div>


              </article>
            </div>
          
          
        </div>
        
      </div></div>
  </body>
</html>
