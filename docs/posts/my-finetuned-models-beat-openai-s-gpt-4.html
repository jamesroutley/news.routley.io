<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://mlops.systems/posts/2024-07-01-full-finetuned-model-evaluation.html">Original</a>
    <h1>My finetuned models beat OpenAI&#39;s GPT-4</h1>
    
    <div id="readability-page-1" class="page"><div id="quarto-document-content">




<p><a href="https://mlops.systems/posts/2024-06-25-evaluation-finetuning-manual-dataset.html">My last post</a> outlined the kinds of evaluation I need and want to understand how well my finetuned LLM is performing in the task of structured data extraction from press releases. Let’s start with the core metric I’m interested in, accuracy, and then later we can dive into some of the other evaluation metrics as well.</p>
<section id="tldr">
<h2 data-anchor-id="tldr">TL;DR</h2>
<p>The headline for this post could well have been: finetuned models beat OpenAI, but evals were a bit painful to implement. There’s a lot of hidden code here in this post and it was slow to run. This step was the first time during the work for the finetuning course where I felt the pain and tradeoffs around the choice to finetune. I can see that without a system of some kind to handle this, the complexity of maintaining it all will start to mount up. But more on that at the end!</p>
<p>This is a long post with lots of detail. I’ve tried to minimise the amount of code you see, but if you want to see how the charts or evals were done, expand the ‘code’ sections. If you’re interested in cutting straight to the aggregate results, <a href="#final-aggregate-scores-for-the-models">click here</a> to go to the end of this post. (To see the rest of the blog posts about this project, please click <a href="https://mlops.systems/index.html#category=isafpr">here</a>. Some context: I’m doing some finetuning as part of <a href="https://maven.com/parlance-labs/fine-tuning">the Hamel Husain / Dan Becker Finetuning course on Maven</a> using <a href="https://mlops.systems/posts/2024-03-24-publishing-afghanistan-dataset-huggingface.html">some data I collected and labeled</a> a few years back that makes for a cool little test of how good it works for structured data extraction.)</p>
</section>
<section id="loading-the-datasets">
<h2 data-anchor-id="loading-the-datasets">Loading the datasets</h2>
<p>The data is all available on the Hugging Face Hub in a public repository, and for the purposes of these evaluations I want to use the <code>test</code> split of the dataset since none of our models have seen that data yet so it’s good for determining how well our model performs with new data.</p>
<div data-execution_count="1">
<details>
<summary>Code</summary>
<div id="cb1"><pre><code><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span>from</span> datasets <span>import</span> load_dataset</span>
<span id="cb1-2"><a href="#cb1-2" aria-hidden="true" tabindex="-1"></a><span>import</span> pandas <span>as</span> pd</span>
<span id="cb1-3"><a href="#cb1-3" aria-hidden="true" tabindex="-1"></a><span>from</span> rich <span>import</span> <span>print</span></span>
<span id="cb1-4"><a href="#cb1-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb1-5"><a href="#cb1-5" aria-hidden="true" tabindex="-1"></a>test_dataset <span>=</span> load_dataset(<span>&#34;strickvl/isafpressreleases&#34;</span>, split<span>=</span><span>&#34;test&#34;</span>)</span>
<span id="cb1-6"><a href="#cb1-6" aria-hidden="true" tabindex="-1"></a>test_df <span>=</span> pd.DataFrame(test_dataset)</span></code></pre></div>
</details>
</div>
<div data-execution_count="2">

<div data-execution_count="2">
<pre><code>Dataset({
    features: [&#39;name&#39;, &#39;eventrefnumber&#39;, &#39;text&#39;, &#39;StartDate&#39;, &#39;eventtype&#39;, &#39;province&#39;, &#39;citydistrict&#39;, &#39;village&#39;, &#39;targetgroup&#39;, &#39;commander&#39;, &#39;position&#39;, &#39;minkilled&#39;, &#39;mincaptured&#39;, &#39;capturedcharacterisation&#39;, &#39;killedcharacterisation&#39;, &#39;killq&#39;, &#39;captureq&#39;, &#39;killcaptureraid&#39;, &#39;airstrike&#39;, &#39;noshotsfired&#39;, &#39;dataprocessed&#39;, &#39;flagged&#39;, &#39;glossarymeta&#39;, &#39;minleaderskilled&#39;, &#39;minfacilitatorskilled&#39;, &#39;minleaderscaptured&#39;, &#39;minfacilitatorscaptured&#39;, &#39;leaderq&#39;],
    num_rows: 724
})</code></pre>
</div>
</div>
<p>We’ll first add an extra column to our <code>DataFrame</code> and then make a prediction for each and every row in the dataset. We’ll store a copy of the prediction to the column so as to make sure we don’t have to do this compute-intensive step repeatedly.</p>
<p>But first we’ll assemple the data as Pydantic objects so as to handle validation and other quality of life features.</p>
<div data-execution_count="3">
<details>
<summary>Code</summary>
<div id="cb4"><pre><code><span id="cb4-1"><a href="#cb4-1" aria-hidden="true" tabindex="-1"></a><span>from</span> enum <span>import</span> Enum</span>
<span id="cb4-2"><a href="#cb4-2" aria-hidden="true" tabindex="-1"></a><span>from</span> typing <span>import</span> Dict, Set, Annotated, Optional</span>
<span id="cb4-3"><a href="#cb4-3" aria-hidden="true" tabindex="-1"></a><span>from</span> pydantic <span>import</span> BaseModel, Field, validator, ValidationInfo</span>
<span id="cb4-4"><a href="#cb4-4" aria-hidden="true" tabindex="-1"></a><span>from</span> datetime <span>import</span> date</span>
<span id="cb4-5"><a href="#cb4-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-6"><a href="#cb4-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-7"><a href="#cb4-7" aria-hidden="true" tabindex="-1"></a><span>class</span> EventType(<span>str</span>, Enum):</span>
<span id="cb4-8"><a href="#cb4-8" aria-hidden="true" tabindex="-1"></a>    airstrike <span>=</span> <span>&#34;airstrike&#34;</span></span>
<span id="cb4-9"><a href="#cb4-9" aria-hidden="true" tabindex="-1"></a>    detention <span>=</span> <span>&#34;detention&#34;</span></span>
<span id="cb4-10"><a href="#cb4-10" aria-hidden="true" tabindex="-1"></a>    captureandkill <span>=</span> <span>&#34;captureandkill&#34;</span></span>
<span id="cb4-11"><a href="#cb4-11" aria-hidden="true" tabindex="-1"></a>    insurgentskilled <span>=</span> <span>&#34;insurgentskilled&#34;</span></span>
<span id="cb4-12"><a href="#cb4-12" aria-hidden="true" tabindex="-1"></a>    exchangeoffire <span>=</span> <span>&#34;exchangeoffire&#34;</span></span>
<span id="cb4-13"><a href="#cb4-13" aria-hidden="true" tabindex="-1"></a>    civiliancasualty <span>=</span> <span>&#34;civiliancasualty&#34;</span></span>
<span id="cb4-14"><a href="#cb4-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-15"><a href="#cb4-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-16"><a href="#cb4-16" aria-hidden="true" tabindex="-1"></a><span>class</span> Province(<span>str</span>, Enum):</span>
<span id="cb4-17"><a href="#cb4-17" aria-hidden="true" tabindex="-1"></a>    badakhshan <span>=</span> <span>&#34;badakhshan&#34;</span></span>
<span id="cb4-18"><a href="#cb4-18" aria-hidden="true" tabindex="-1"></a>    badghis <span>=</span> <span>&#34;badghis&#34;</span></span>
<span id="cb4-19"><a href="#cb4-19" aria-hidden="true" tabindex="-1"></a>    baghlan <span>=</span> <span>&#34;baghlan&#34;</span></span>
<span id="cb4-20"><a href="#cb4-20" aria-hidden="true" tabindex="-1"></a>    balkh <span>=</span> <span>&#34;balkh&#34;</span></span>
<span id="cb4-21"><a href="#cb4-21" aria-hidden="true" tabindex="-1"></a>    bamyan <span>=</span> <span>&#34;bamyan&#34;</span></span>
<span id="cb4-22"><a href="#cb4-22" aria-hidden="true" tabindex="-1"></a>    day_kundi <span>=</span> <span>&#34;day_kundi&#34;</span></span>
<span id="cb4-23"><a href="#cb4-23" aria-hidden="true" tabindex="-1"></a>    farah <span>=</span> <span>&#34;farah&#34;</span></span>
<span id="cb4-24"><a href="#cb4-24" aria-hidden="true" tabindex="-1"></a>    faryab <span>=</span> <span>&#34;faryab&#34;</span></span>
<span id="cb4-25"><a href="#cb4-25" aria-hidden="true" tabindex="-1"></a>    ghazni <span>=</span> <span>&#34;ghazni&#34;</span></span>
<span id="cb4-26"><a href="#cb4-26" aria-hidden="true" tabindex="-1"></a>    ghor <span>=</span> <span>&#34;ghor&#34;</span></span>
<span id="cb4-27"><a href="#cb4-27" aria-hidden="true" tabindex="-1"></a>    helmand <span>=</span> <span>&#34;helmand&#34;</span></span>
<span id="cb4-28"><a href="#cb4-28" aria-hidden="true" tabindex="-1"></a>    herat <span>=</span> <span>&#34;herat&#34;</span></span>
<span id="cb4-29"><a href="#cb4-29" aria-hidden="true" tabindex="-1"></a>    jowzjan <span>=</span> <span>&#34;jowzjan&#34;</span></span>
<span id="cb4-30"><a href="#cb4-30" aria-hidden="true" tabindex="-1"></a>    kabul <span>=</span> <span>&#34;kabul&#34;</span></span>
<span id="cb4-31"><a href="#cb4-31" aria-hidden="true" tabindex="-1"></a>    kandahar <span>=</span> <span>&#34;kandahar&#34;</span></span>
<span id="cb4-32"><a href="#cb4-32" aria-hidden="true" tabindex="-1"></a>    kapisa <span>=</span> <span>&#34;kapisa&#34;</span></span>
<span id="cb4-33"><a href="#cb4-33" aria-hidden="true" tabindex="-1"></a>    khost <span>=</span> <span>&#34;khost&#34;</span></span>
<span id="cb4-34"><a href="#cb4-34" aria-hidden="true" tabindex="-1"></a>    kunar <span>=</span> <span>&#34;kunar&#34;</span></span>
<span id="cb4-35"><a href="#cb4-35" aria-hidden="true" tabindex="-1"></a>    kunduz <span>=</span> <span>&#34;kunduz&#34;</span></span>
<span id="cb4-36"><a href="#cb4-36" aria-hidden="true" tabindex="-1"></a>    laghman <span>=</span> <span>&#34;laghman&#34;</span></span>
<span id="cb4-37"><a href="#cb4-37" aria-hidden="true" tabindex="-1"></a>    logar <span>=</span> <span>&#34;logar&#34;</span></span>
<span id="cb4-38"><a href="#cb4-38" aria-hidden="true" tabindex="-1"></a>    nangarhar <span>=</span> <span>&#34;nangarhar&#34;</span></span>
<span id="cb4-39"><a href="#cb4-39" aria-hidden="true" tabindex="-1"></a>    nimroz <span>=</span> <span>&#34;nimroz&#34;</span></span>
<span id="cb4-40"><a href="#cb4-40" aria-hidden="true" tabindex="-1"></a>    nuristan <span>=</span> <span>&#34;nuristan&#34;</span></span>
<span id="cb4-41"><a href="#cb4-41" aria-hidden="true" tabindex="-1"></a>    paktya <span>=</span> <span>&#34;paktya&#34;</span></span>
<span id="cb4-42"><a href="#cb4-42" aria-hidden="true" tabindex="-1"></a>    paktika <span>=</span> <span>&#34;paktika&#34;</span></span>
<span id="cb4-43"><a href="#cb4-43" aria-hidden="true" tabindex="-1"></a>    panjshir <span>=</span> <span>&#34;panjshir&#34;</span></span>
<span id="cb4-44"><a href="#cb4-44" aria-hidden="true" tabindex="-1"></a>    parwan <span>=</span> <span>&#34;parwan&#34;</span></span>
<span id="cb4-45"><a href="#cb4-45" aria-hidden="true" tabindex="-1"></a>    samangan <span>=</span> <span>&#34;samangan&#34;</span></span>
<span id="cb4-46"><a href="#cb4-46" aria-hidden="true" tabindex="-1"></a>    sar_e_pul <span>=</span> <span>&#34;sar_e_pul&#34;</span></span>
<span id="cb4-47"><a href="#cb4-47" aria-hidden="true" tabindex="-1"></a>    takhar <span>=</span> <span>&#34;takhar&#34;</span></span>
<span id="cb4-48"><a href="#cb4-48" aria-hidden="true" tabindex="-1"></a>    uruzgan <span>=</span> <span>&#34;uruzgan&#34;</span></span>
<span id="cb4-49"><a href="#cb4-49" aria-hidden="true" tabindex="-1"></a>    wardak <span>=</span> <span>&#34;wardak&#34;</span></span>
<span id="cb4-50"><a href="#cb4-50" aria-hidden="true" tabindex="-1"></a>    zabul <span>=</span> <span>&#34;zabul&#34;</span></span>
<span id="cb4-51"><a href="#cb4-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-52"><a href="#cb4-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-53"><a href="#cb4-53" aria-hidden="true" tabindex="-1"></a><span>class</span> TargetGroup(<span>str</span>, Enum):</span>
<span id="cb4-54"><a href="#cb4-54" aria-hidden="true" tabindex="-1"></a>    taliban <span>=</span> <span>&#34;taliban&#34;</span></span>
<span id="cb4-55"><a href="#cb4-55" aria-hidden="true" tabindex="-1"></a>    haqqani <span>=</span> <span>&#34;haqqani&#34;</span></span>
<span id="cb4-56"><a href="#cb4-56" aria-hidden="true" tabindex="-1"></a>    criminals <span>=</span> <span>&#34;criminals&#34;</span></span>
<span id="cb4-57"><a href="#cb4-57" aria-hidden="true" tabindex="-1"></a>    aq <span>=</span> <span>&#34;aq&#34;</span></span>
<span id="cb4-58"><a href="#cb4-58" aria-hidden="true" tabindex="-1"></a>    hig <span>=</span> <span>&#34;hig&#34;</span></span>
<span id="cb4-59"><a href="#cb4-59" aria-hidden="true" tabindex="-1"></a>    let <span>=</span> <span>&#34;let&#34;</span></span>
<span id="cb4-60"><a href="#cb4-60" aria-hidden="true" tabindex="-1"></a>    imu <span>=</span> <span>&#34;imu&#34;</span></span>
<span id="cb4-61"><a href="#cb4-61" aria-hidden="true" tabindex="-1"></a>    judq <span>=</span> <span>&#34;judq&#34;</span></span>
<span id="cb4-62"><a href="#cb4-62" aria-hidden="true" tabindex="-1"></a>    iju <span>=</span> <span>&#34;iju&#34;</span></span>
<span id="cb4-63"><a href="#cb4-63" aria-hidden="true" tabindex="-1"></a>    hik <span>=</span> <span>&#34;hik&#34;</span></span>
<span id="cb4-64"><a href="#cb4-64" aria-hidden="true" tabindex="-1"></a>    ttp <span>=</span> <span>&#34;ttp&#34;</span></span>
<span id="cb4-65"><a href="#cb4-65" aria-hidden="true" tabindex="-1"></a>    other <span>=</span> <span>&#34;other&#34;</span></span>
<span id="cb4-66"><a href="#cb4-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-67"><a href="#cb4-67" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-68"><a href="#cb4-68" aria-hidden="true" tabindex="-1"></a><span>def</span> validate_event_type(value: <span>str</span>):</span>
<span id="cb4-69"><a href="#cb4-69" aria-hidden="true" tabindex="-1"></a>    valid_values <span>=</span> [</span>
<span id="cb4-70"><a href="#cb4-70" aria-hidden="true" tabindex="-1"></a>        <span>&#34;airstrike&#34;</span>,</span>
<span id="cb4-71"><a href="#cb4-71" aria-hidden="true" tabindex="-1"></a>        <span>&#34;detention&#34;</span>,</span>
<span id="cb4-72"><a href="#cb4-72" aria-hidden="true" tabindex="-1"></a>        <span>&#34;captureandkill&#34;</span>,</span>
<span id="cb4-73"><a href="#cb4-73" aria-hidden="true" tabindex="-1"></a>        <span>&#34;insurgentskilled&#34;</span>,</span>
<span id="cb4-74"><a href="#cb4-74" aria-hidden="true" tabindex="-1"></a>        <span>&#34;exchangeoffire&#34;</span>,</span>
<span id="cb4-75"><a href="#cb4-75" aria-hidden="true" tabindex="-1"></a>        <span>&#34;civiliancasualty&#34;</span>,</span>
<span id="cb4-76"><a href="#cb4-76" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb4-77"><a href="#cb4-77" aria-hidden="true" tabindex="-1"></a>    <span>if</span> value.lower() <span>not</span> <span>in</span> valid_values:</span>
<span id="cb4-78"><a href="#cb4-78" aria-hidden="true" tabindex="-1"></a>        <span>return</span> <span>&#34;other&#34;</span></span>
<span id="cb4-79"><a href="#cb4-79" aria-hidden="true" tabindex="-1"></a>    <span>return</span> value.lower()</span>
<span id="cb4-80"><a href="#cb4-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-81"><a href="#cb4-81" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-82"><a href="#cb4-82" aria-hidden="true" tabindex="-1"></a><span>def</span> validate_province(value: <span>str</span>):</span>
<span id="cb4-83"><a href="#cb4-83" aria-hidden="true" tabindex="-1"></a>    valid_values <span>=</span> [</span>
<span id="cb4-84"><a href="#cb4-84" aria-hidden="true" tabindex="-1"></a>        <span>&#34;badakhshan&#34;</span>,</span>
<span id="cb4-85"><a href="#cb4-85" aria-hidden="true" tabindex="-1"></a>        <span>&#34;badghis&#34;</span>,</span>
<span id="cb4-86"><a href="#cb4-86" aria-hidden="true" tabindex="-1"></a>        <span>&#34;baghlan&#34;</span>,</span>
<span id="cb4-87"><a href="#cb4-87" aria-hidden="true" tabindex="-1"></a>        <span>&#34;balkh&#34;</span>,</span>
<span id="cb4-88"><a href="#cb4-88" aria-hidden="true" tabindex="-1"></a>        <span>&#34;bamyan&#34;</span>,</span>
<span id="cb4-89"><a href="#cb4-89" aria-hidden="true" tabindex="-1"></a>        <span>&#34;day_kundi&#34;</span>,</span>
<span id="cb4-90"><a href="#cb4-90" aria-hidden="true" tabindex="-1"></a>        <span>&#34;farah&#34;</span>,</span>
<span id="cb4-91"><a href="#cb4-91" aria-hidden="true" tabindex="-1"></a>        <span>&#34;faryab&#34;</span>,</span>
<span id="cb4-92"><a href="#cb4-92" aria-hidden="true" tabindex="-1"></a>        <span>&#34;ghazni&#34;</span>,</span>
<span id="cb4-93"><a href="#cb4-93" aria-hidden="true" tabindex="-1"></a>        <span>&#34;ghor&#34;</span>,</span>
<span id="cb4-94"><a href="#cb4-94" aria-hidden="true" tabindex="-1"></a>        <span>&#34;helmand&#34;</span>,</span>
<span id="cb4-95"><a href="#cb4-95" aria-hidden="true" tabindex="-1"></a>        <span>&#34;herat&#34;</span>,</span>
<span id="cb4-96"><a href="#cb4-96" aria-hidden="true" tabindex="-1"></a>        <span>&#34;jowzjan&#34;</span>,</span>
<span id="cb4-97"><a href="#cb4-97" aria-hidden="true" tabindex="-1"></a>        <span>&#34;kabul&#34;</span>,</span>
<span id="cb4-98"><a href="#cb4-98" aria-hidden="true" tabindex="-1"></a>        <span>&#34;kandahar&#34;</span>,</span>
<span id="cb4-99"><a href="#cb4-99" aria-hidden="true" tabindex="-1"></a>        <span>&#34;kapisa&#34;</span>,</span>
<span id="cb4-100"><a href="#cb4-100" aria-hidden="true" tabindex="-1"></a>        <span>&#34;khost&#34;</span>,</span>
<span id="cb4-101"><a href="#cb4-101" aria-hidden="true" tabindex="-1"></a>        <span>&#34;kunar&#34;</span>,</span>
<span id="cb4-102"><a href="#cb4-102" aria-hidden="true" tabindex="-1"></a>        <span>&#34;kunduz&#34;</span>,</span>
<span id="cb4-103"><a href="#cb4-103" aria-hidden="true" tabindex="-1"></a>        <span>&#34;laghman&#34;</span>,</span>
<span id="cb4-104"><a href="#cb4-104" aria-hidden="true" tabindex="-1"></a>        <span>&#34;logar&#34;</span>,</span>
<span id="cb4-105"><a href="#cb4-105" aria-hidden="true" tabindex="-1"></a>        <span>&#34;nangarhar&#34;</span>,</span>
<span id="cb4-106"><a href="#cb4-106" aria-hidden="true" tabindex="-1"></a>        <span>&#34;nimroz&#34;</span>,</span>
<span id="cb4-107"><a href="#cb4-107" aria-hidden="true" tabindex="-1"></a>        <span>&#34;nuristan&#34;</span>,</span>
<span id="cb4-108"><a href="#cb4-108" aria-hidden="true" tabindex="-1"></a>        <span>&#34;paktya&#34;</span>,</span>
<span id="cb4-109"><a href="#cb4-109" aria-hidden="true" tabindex="-1"></a>        <span>&#34;paktika&#34;</span>,</span>
<span id="cb4-110"><a href="#cb4-110" aria-hidden="true" tabindex="-1"></a>        <span>&#34;panjshir&#34;</span>,</span>
<span id="cb4-111"><a href="#cb4-111" aria-hidden="true" tabindex="-1"></a>        <span>&#34;parwan&#34;</span>,</span>
<span id="cb4-112"><a href="#cb4-112" aria-hidden="true" tabindex="-1"></a>        <span>&#34;samangan&#34;</span>,</span>
<span id="cb4-113"><a href="#cb4-113" aria-hidden="true" tabindex="-1"></a>        <span>&#34;sar_e_pul&#34;</span>,</span>
<span id="cb4-114"><a href="#cb4-114" aria-hidden="true" tabindex="-1"></a>        <span>&#34;takhar&#34;</span>,</span>
<span id="cb4-115"><a href="#cb4-115" aria-hidden="true" tabindex="-1"></a>        <span>&#34;uruzgan&#34;</span>,</span>
<span id="cb4-116"><a href="#cb4-116" aria-hidden="true" tabindex="-1"></a>        <span>&#34;wardak&#34;</span>,</span>
<span id="cb4-117"><a href="#cb4-117" aria-hidden="true" tabindex="-1"></a>        <span>&#34;zabul&#34;</span>,</span>
<span id="cb4-118"><a href="#cb4-118" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb4-119"><a href="#cb4-119" aria-hidden="true" tabindex="-1"></a>    <span>if</span> value.lower() <span>not</span> <span>in</span> valid_values:</span>
<span id="cb4-120"><a href="#cb4-120" aria-hidden="true" tabindex="-1"></a>        <span>return</span> <span>&#34;other&#34;</span></span>
<span id="cb4-121"><a href="#cb4-121" aria-hidden="true" tabindex="-1"></a>    <span>return</span> value.lower()</span>
<span id="cb4-122"><a href="#cb4-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-123"><a href="#cb4-123" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-124"><a href="#cb4-124" aria-hidden="true" tabindex="-1"></a><span>def</span> validate_target_group(value: <span>str</span>):</span>
<span id="cb4-125"><a href="#cb4-125" aria-hidden="true" tabindex="-1"></a>    valid_values <span>=</span> [</span>
<span id="cb4-126"><a href="#cb4-126" aria-hidden="true" tabindex="-1"></a>        <span>&#34;taliban&#34;</span>,</span>
<span id="cb4-127"><a href="#cb4-127" aria-hidden="true" tabindex="-1"></a>        <span>&#34;haqqani&#34;</span>,</span>
<span id="cb4-128"><a href="#cb4-128" aria-hidden="true" tabindex="-1"></a>        <span>&#34;criminals&#34;</span>,</span>
<span id="cb4-129"><a href="#cb4-129" aria-hidden="true" tabindex="-1"></a>        <span>&#34;aq&#34;</span>,</span>
<span id="cb4-130"><a href="#cb4-130" aria-hidden="true" tabindex="-1"></a>        <span>&#34;hig&#34;</span>,</span>
<span id="cb4-131"><a href="#cb4-131" aria-hidden="true" tabindex="-1"></a>        <span>&#34;let&#34;</span>,</span>
<span id="cb4-132"><a href="#cb4-132" aria-hidden="true" tabindex="-1"></a>        <span>&#34;imu&#34;</span>,</span>
<span id="cb4-133"><a href="#cb4-133" aria-hidden="true" tabindex="-1"></a>        <span>&#34;judq&#34;</span>,</span>
<span id="cb4-134"><a href="#cb4-134" aria-hidden="true" tabindex="-1"></a>        <span>&#34;iju&#34;</span>,</span>
<span id="cb4-135"><a href="#cb4-135" aria-hidden="true" tabindex="-1"></a>        <span>&#34;hik&#34;</span>,</span>
<span id="cb4-136"><a href="#cb4-136" aria-hidden="true" tabindex="-1"></a>        <span>&#34;ttp&#34;</span>,</span>
<span id="cb4-137"><a href="#cb4-137" aria-hidden="true" tabindex="-1"></a>        <span>&#34;other&#34;</span>,</span>
<span id="cb4-138"><a href="#cb4-138" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb4-139"><a href="#cb4-139" aria-hidden="true" tabindex="-1"></a>    <span>if</span> value.lower() <span>not</span> <span>in</span> valid_values:</span>
<span id="cb4-140"><a href="#cb4-140" aria-hidden="true" tabindex="-1"></a>        <span>return</span> <span>&#34;other&#34;</span></span>
<span id="cb4-141"><a href="#cb4-141" aria-hidden="true" tabindex="-1"></a>    <span>return</span> value.lower()</span>
<span id="cb4-142"><a href="#cb4-142" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-143"><a href="#cb4-143" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-144"><a href="#cb4-144" aria-hidden="true" tabindex="-1"></a><span>class</span> IsafEvent(BaseModel):</span>
<span id="cb4-145"><a href="#cb4-145" aria-hidden="true" tabindex="-1"></a>    name: <span>str</span> <span>=</span> Field(</span>
<span id="cb4-146"><a href="#cb4-146" aria-hidden="true" tabindex="-1"></a>        description<span>=</span><span>&#34;A title or name for the event which summarises the event as a headline&#34;</span></span>
<span id="cb4-147"><a href="#cb4-147" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb4-148"><a href="#cb4-148" aria-hidden="true" tabindex="-1"></a>    text: Optional[<span>str</span>] <span>=</span> Field(description<span>=</span><span>&#34;The full text of the press release&#34;</span>)</span>
<span id="cb4-149"><a href="#cb4-149" aria-hidden="true" tabindex="-1"></a>    start_date: date <span>=</span> Field(</span>
<span id="cb4-150"><a href="#cb4-150" aria-hidden="true" tabindex="-1"></a>        description<span>=</span><span>&#34;The start date of the event in YYYY-MM-DD format&#34;</span></span>
<span id="cb4-151"><a href="#cb4-151" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb4-152"><a href="#cb4-152" aria-hidden="true" tabindex="-1"></a>    event_type: Set[Annotated[<span>str</span>, Field(validator<span>=</span>validate_event_type)]] <span>=</span> Field(</span>
<span id="cb4-153"><a href="#cb4-153" aria-hidden="true" tabindex="-1"></a>        description<span>=</span><span>&#34;The event type. Can be multiple types.&#34;</span></span>
<span id="cb4-154"><a href="#cb4-154" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb4-155"><a href="#cb4-155" aria-hidden="true" tabindex="-1"></a>    province: Set[Annotated[<span>str</span>, Field(validator<span>=</span>validate_province)]] <span>=</span> Field(</span>
<span id="cb4-156"><a href="#cb4-156" aria-hidden="true" tabindex="-1"></a>        description<span>=</span><span>&#34;The province in which the event occurred. Can be multiple provinces.&#34;</span></span>
<span id="cb4-157"><a href="#cb4-157" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb4-158"><a href="#cb4-158" aria-hidden="true" tabindex="-1"></a>    target_group: Set[Annotated[<span>str</span>, Field(validator<span>=</span>validate_target_group)]] <span>=</span> Field(</span>
<span id="cb4-159"><a href="#cb4-159" aria-hidden="true" tabindex="-1"></a>        description<span>=</span><span>&#34;The group that was targetted during the event. Can be multiple groups.&#34;</span></span>
<span id="cb4-160"><a href="#cb4-160" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb4-161"><a href="#cb4-161" aria-hidden="true" tabindex="-1"></a>    min_killed: <span>int</span> <span>=</span> Field(</span>
<span id="cb4-162"><a href="#cb4-162" aria-hidden="true" tabindex="-1"></a>        description<span>=</span><span>&#34;The minimum number of people killed during the event&#34;</span></span>
<span id="cb4-163"><a href="#cb4-163" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb4-164"><a href="#cb4-164" aria-hidden="true" tabindex="-1"></a>    min_captured: <span>int</span> <span>=</span> Field(</span>
<span id="cb4-165"><a href="#cb4-165" aria-hidden="true" tabindex="-1"></a>        description<span>=</span><span>&#34;The minimum number of people captured during the event&#34;</span></span>
<span id="cb4-166"><a href="#cb4-166" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb4-167"><a href="#cb4-167" aria-hidden="true" tabindex="-1"></a>    killq: <span>bool</span> <span>=</span> Field(</span>
<span id="cb4-168"><a href="#cb4-168" aria-hidden="true" tabindex="-1"></a>        description<span>=</span><span>&#34;Whether someone was killed or not during the event&#34;</span></span>
<span id="cb4-169"><a href="#cb4-169" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb4-170"><a href="#cb4-170" aria-hidden="true" tabindex="-1"></a>    captureq: <span>bool</span> <span>=</span> Field(</span>
<span id="cb4-171"><a href="#cb4-171" aria-hidden="true" tabindex="-1"></a>        description<span>=</span><span>&#34;Whether someone was captured or not during the event&#34;</span></span>
<span id="cb4-172"><a href="#cb4-172" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb4-173"><a href="#cb4-173" aria-hidden="true" tabindex="-1"></a>    killcaptureraid: <span>bool</span> <span>=</span> Field(</span>
<span id="cb4-174"><a href="#cb4-174" aria-hidden="true" tabindex="-1"></a>        description<span>=</span><span>&#34;Whether the event was a so-called &#39;kill-capture raid&#39;.&#34;</span></span>
<span id="cb4-175"><a href="#cb4-175" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb4-176"><a href="#cb4-176" aria-hidden="true" tabindex="-1"></a>    airstrike: <span>bool</span> <span>=</span> Field(</span>
<span id="cb4-177"><a href="#cb4-177" aria-hidden="true" tabindex="-1"></a>        description<span>=</span><span>&#34;Whether an airstrike was used during the event&#34;</span></span>
<span id="cb4-178"><a href="#cb4-178" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb4-179"><a href="#cb4-179" aria-hidden="true" tabindex="-1"></a>    noshotsfired: <span>bool</span> <span>=</span> Field(</span>
<span id="cb4-180"><a href="#cb4-180" aria-hidden="true" tabindex="-1"></a>        description<span>=</span><span>&#34;Whether no shots were fired during the event&#34;</span></span>
<span id="cb4-181"><a href="#cb4-181" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb4-182"><a href="#cb4-182" aria-hidden="true" tabindex="-1"></a>    min_leaders_killed: <span>int</span> <span>=</span> Field(</span>
<span id="cb4-183"><a href="#cb4-183" aria-hidden="true" tabindex="-1"></a>        description<span>=</span><span>&#34;The minimum number of leaders killed during the event&#34;</span></span>
<span id="cb4-184"><a href="#cb4-184" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb4-185"><a href="#cb4-185" aria-hidden="true" tabindex="-1"></a>    min_leaders_captured: <span>int</span> <span>=</span> Field(</span>
<span id="cb4-186"><a href="#cb4-186" aria-hidden="true" tabindex="-1"></a>        description<span>=</span><span>&#34;The minimum number of leaders captured during the event&#34;</span></span>
<span id="cb4-187"><a href="#cb4-187" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb4-188"><a href="#cb4-188" aria-hidden="true" tabindex="-1"></a>    predictions: Dict[<span>str</span>, <span>str</span>] <span>=</span> Field(</span>
<span id="cb4-189"><a href="#cb4-189" aria-hidden="true" tabindex="-1"></a>        default<span>=</span>{},</span>
<span id="cb4-190"><a href="#cb4-190" aria-hidden="true" tabindex="-1"></a>        description<span>=</span><span>&#34;The predictions from the model. Keys are the model name and the value is the prediction&#34;</span>,</span>
<span id="cb4-191"><a href="#cb4-191" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb4-192"><a href="#cb4-192" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb4-193"><a href="#cb4-193" aria-hidden="true" tabindex="-1"></a>    <span>class</span> Config:</span>
<span id="cb4-194"><a href="#cb4-194" aria-hidden="true" tabindex="-1"></a>        arbitrary_types_allowed <span>=</span> <span>True</span></span></code></pre></div>
</details>
</div>
<p>Here’s what a couple of examples of our training data looks like as Pydantic models when we pass them in:</p>
<div data-execution_count="4">
<details>
<summary>Code</summary>
<div id="cb5"><pre><code><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span>from</span> typing <span>import</span> List</span>
<span id="cb5-2"><a href="#cb5-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-3"><a href="#cb5-3" aria-hidden="true" tabindex="-1"></a>events: List[IsafEvent] <span>=</span> []</span>
<span id="cb5-4"><a href="#cb5-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-5"><a href="#cb5-5" aria-hidden="true" tabindex="-1"></a><span>for</span> i, row <span>in</span> <span>list</span>(test_df.iterrows()):</span>
<span id="cb5-6"><a href="#cb5-6" aria-hidden="true" tabindex="-1"></a>    event_types <span>=</span> <span>set</span>(</span>
<span id="cb5-7"><a href="#cb5-7" aria-hidden="true" tabindex="-1"></a>        eventtype.strip().lower() <span>for</span> eventtype <span>in</span> row[<span>&#34;eventtype&#34;</span>].split(<span>&#34;,&#34;</span>)</span>
<span id="cb5-8"><a href="#cb5-8" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb5-9"><a href="#cb5-9" aria-hidden="true" tabindex="-1"></a>    provinces <span>=</span> <span>set</span>(province.strip().lower() <span>for</span> province <span>in</span> row[<span>&#34;province&#34;</span>].split(<span>&#34;,&#34;</span>))</span>
<span id="cb5-10"><a href="#cb5-10" aria-hidden="true" tabindex="-1"></a>    target_groups <span>=</span> <span>set</span>(</span>
<span id="cb5-11"><a href="#cb5-11" aria-hidden="true" tabindex="-1"></a>        target_group.strip().lower() <span>for</span> target_group <span>in</span> row[<span>&#34;targetgroup&#34;</span>].split(<span>&#34;,&#34;</span>)</span>
<span id="cb5-12"><a href="#cb5-12" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb5-13"><a href="#cb5-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-14"><a href="#cb5-14" aria-hidden="true" tabindex="-1"></a>    events.append(</span>
<span id="cb5-15"><a href="#cb5-15" aria-hidden="true" tabindex="-1"></a>        IsafEvent(</span>
<span id="cb5-16"><a href="#cb5-16" aria-hidden="true" tabindex="-1"></a>            name<span>=</span>row[<span>&#34;name&#34;</span>],</span>
<span id="cb5-17"><a href="#cb5-17" aria-hidden="true" tabindex="-1"></a>            text<span>=</span>row[<span>&#34;text&#34;</span>],</span>
<span id="cb5-18"><a href="#cb5-18" aria-hidden="true" tabindex="-1"></a>            start_date<span>=</span>row[<span>&#34;StartDate&#34;</span>].to_pydatetime().date(),</span>
<span id="cb5-19"><a href="#cb5-19" aria-hidden="true" tabindex="-1"></a>            event_type<span>=</span>event_types,</span>
<span id="cb5-20"><a href="#cb5-20" aria-hidden="true" tabindex="-1"></a>            province<span>=</span>provinces,</span>
<span id="cb5-21"><a href="#cb5-21" aria-hidden="true" tabindex="-1"></a>            target_group<span>=</span>target_groups,</span>
<span id="cb5-22"><a href="#cb5-22" aria-hidden="true" tabindex="-1"></a>            min_killed<span>=</span><span>int</span>(row[<span>&#34;minkilled&#34;</span>]),</span>
<span id="cb5-23"><a href="#cb5-23" aria-hidden="true" tabindex="-1"></a>            min_captured<span>=</span><span>int</span>(row[<span>&#34;mincaptured&#34;</span>]),</span>
<span id="cb5-24"><a href="#cb5-24" aria-hidden="true" tabindex="-1"></a>            killq<span>=</span>row[<span>&#34;killq&#34;</span>] <span>==</span> <span>&#34;true&#34;</span>,</span>
<span id="cb5-25"><a href="#cb5-25" aria-hidden="true" tabindex="-1"></a>            captureq<span>=</span>row[<span>&#34;captureq&#34;</span>] <span>==</span> <span>&#34;true&#34;</span>,</span>
<span id="cb5-26"><a href="#cb5-26" aria-hidden="true" tabindex="-1"></a>            killcaptureraid<span>=</span>row[<span>&#34;killcaptureraid&#34;</span>] <span>==</span> <span>&#34;true&#34;</span>,</span>
<span id="cb5-27"><a href="#cb5-27" aria-hidden="true" tabindex="-1"></a>            airstrike<span>=</span>row[<span>&#34;airstrike&#34;</span>] <span>==</span> <span>&#34;true&#34;</span>,</span>
<span id="cb5-28"><a href="#cb5-28" aria-hidden="true" tabindex="-1"></a>            noshotsfired<span>=</span>row[<span>&#34;noshotsfired&#34;</span>] <span>==</span> <span>&#34;true&#34;</span>,</span>
<span id="cb5-29"><a href="#cb5-29" aria-hidden="true" tabindex="-1"></a>            min_leaders_killed<span>=</span><span>int</span>(row[<span>&#34;minleaderskilled&#34;</span>]),</span>
<span id="cb5-30"><a href="#cb5-30" aria-hidden="true" tabindex="-1"></a>            min_leaders_captured<span>=</span><span>int</span>(row[<span>&#34;minleaderscaptured&#34;</span>]),</span>
<span id="cb5-31"><a href="#cb5-31" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb5-32"><a href="#cb5-32" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb5-33"><a href="#cb5-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb5-34"><a href="#cb5-34" aria-hidden="true" tabindex="-1"></a><span>print</span>(events[:<span>2</span>])</span></code></pre></div>
</details>
<div>
<pre><span>[</span>
    <span>IsafEvent</span><span>(</span>
        <span>name</span>=<span>&#39;5&#39;</span>,
        <span>text</span>=<span>&#39;2013-01-S-025\n\nKABUL, Afghanistan (Jan. 25, 2013)\nDuring a security operation in Andar district, </span>
<span>Ghazni province, yesterday, an Afghan and coalition force killed the Taliban leader, Alaudin. Alaudin oversaw a </span>
<span>group of insurgents responsible for conducting remote-controlled improvised explosive device and small-arms fire </span>
<span>attacks against Afghan and coalition forces. Prior to his death, Alaudin was planning attacks against Afghan </span>
<span>National Police in Ghazni province.&#39;</span>,
        <span>start_date</span>=<span>datetime</span><span>.date</span><span>(</span><span>2013</span>, <span>1</span>, <span>24</span><span>)</span>,
        <span>event_type</span>=<span>{</span><span>&#39;insurgentskilled&#39;</span><span>}</span>,
        <span>province</span>=<span>{</span><span>&#39;ghazni&#39;</span><span>}</span>,
        <span>target_group</span>=<span>{</span><span>&#39;taliban&#39;</span><span>}</span>,
        <span>min_killed</span>=<span>1</span>,
        <span>min_captured</span>=<span>0</span>,
        <span>killq</span>=<span>True</span>,
        <span>captureq</span>=<span>False</span>,
        <span>killcaptureraid</span>=<span>False</span>,
        <span>airstrike</span>=<span>False</span>,
        <span>noshotsfired</span>=<span>False</span>,
        <span>min_leaders_killed</span>=<span>1</span>,
        <span>min_leaders_captured</span>=<span>0</span>,
        <span>predictions</span>=<span>{}</span>
    <span>)</span>,
    <span>IsafEvent</span><span>(</span>
        <span>name</span>=<span>&#39;2&#39;</span>,
        <span>text</span>=<span>&#39;2011-11-S-034\nISAF Joint Command - Afghanistan\nFor Immediate Release\n\nKABUL, Afghanistan (Nov. </span>
<span>20, 2011)\nA coalition security force detained numerous suspected insurgents during an operation in Marjeh </span>
<span>district, Helmand province, yesterday.  The force conducted the operation after receiving information that a group </span>
<span>of insurgents were at a compound in the area.  After calling for the men inside to come out peacefully, the </span>
<span>insurgents emerged and were detained without incident.&#39;</span>,
        <span>start_date</span>=<span>datetime</span><span>.date</span><span>(</span><span>2011</span>, <span>11</span>, <span>19</span><span>)</span>,
        <span>event_type</span>=<span>{</span><span>&#39;detention&#39;</span><span>}</span>,
        <span>province</span>=<span>{</span><span>&#39;helmand&#39;</span><span>}</span>,
        <span>target_group</span>=<span>{</span><span>&#39;&#39;</span><span>}</span>,
        <span>min_killed</span>=<span>0</span>,
        <span>min_captured</span>=<span>4</span>,
        <span>killq</span>=<span>False</span>,
        <span>captureq</span>=<span>True</span>,
        <span>killcaptureraid</span>=<span>True</span>,
        <span>airstrike</span>=<span>False</span>,
        <span>noshotsfired</span>=<span>False</span>,
        <span>min_leaders_killed</span>=<span>0</span>,
        <span>min_leaders_captured</span>=<span>0</span>,
        <span>predictions</span>=<span>{}</span>
    <span>)</span>
<span>]</span>
</pre>
</div>
</div>
<p>So when we’re making the prediction we’re hoping to get a JSON string like this out from the model:</p>
<div data-execution_count="5">
<div id="cb6"><pre><code><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>json_str <span>=</span> events[<span>0</span>].model_dump_json(exclude<span>=</span>{<span>&#34;text&#34;</span>, <span>&#34;predictions&#34;</span>})</span>
<span id="cb6-2"><a href="#cb6-2" aria-hidden="true" tabindex="-1"></a><span>print</span>(json_str)</span></code></pre></div>
<div>
<pre><span>{</span><span>&#34;name&#34;</span>:<span>&#34;5&#34;</span>,<span>&#34;start_date&#34;</span>:<span>&#34;2013-01-24&#34;</span>,<span>&#34;event_type&#34;</span>:<span>[</span><span>&#34;insurgentskilled&#34;</span><span>]</span>,<span>&#34;province&#34;</span>:<span>[</span><span>&#34;ghazni&#34;</span><span>]</span>,<span>&#34;target_group&#34;</span>:<span>[</span><span>&#34;tali</span>
<span>ban&#34;</span><span>]</span>,<span>&#34;min_killed&#34;</span>:<span>1</span>,<span>&#34;min_captured&#34;</span>:<span>0</span>,<span>&#34;killq&#34;</span>:true,<span>&#34;captureq&#34;</span>:false,<span>&#34;killcaptureraid&#34;</span>:false,<span>&#34;airstrike&#34;</span>:false,<span>&#34;nosh</span>
<span>otsfired&#34;</span>:false,<span>&#34;min_leaders_killed&#34;</span>:<span>1</span>,<span>&#34;min_leaders_captured&#34;</span>:<span>0</span><span>}</span>
</pre>
</div>
</div>
<p>I’m starting with full evaluations using the GPT models and I’ll need a slightly more elaborate prompt in order to get decent results. I can’t pass in the exact same prompt as the one I used for the finetuned model since the GPT models haven’t been trained or finetuned to respond to those specific prompts. This is sort of an interesting problem to have: how much effort do we put into the GPT prompts to try to get the same level of accuracy as the finetuned model? Or in other words, is there even a way to really compare like to like between models that must accept different prompts?</p>
<p>Let’s try this out for OpenAI GPT-4o and GPT-4 Turbo and see how we get on. You’ll note how long the prompt has to be to give the GPT models a fighting chance against the finetuned models. Ideally I’d stuff in even more examples into the context, but I also don’t want to explode the number of tokens I’m using.</p>
<div data-execution_count="30">
<div id="cb7"><pre><code><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a><span>from</span> openai <span>import</span> OpenAI</span>
<span id="cb7-2"><a href="#cb7-2" aria-hidden="true" tabindex="-1"></a><span>from</span> rich <span>import</span> <span>print</span></span>
<span id="cb7-3"><a href="#cb7-3" aria-hidden="true" tabindex="-1"></a><span>import</span> json</span>
<span id="cb7-4"><a href="#cb7-4" aria-hidden="true" tabindex="-1"></a><span>import</span> os</span>
<span id="cb7-5"><a href="#cb7-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-6"><a href="#cb7-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-7"><a href="#cb7-7" aria-hidden="true" tabindex="-1"></a><span>def</span> query_openai(article_text: <span>str</span>, model: <span>str</span>) <span>-&gt;</span> <span>str</span>:</span>
<span id="cb7-8"><a href="#cb7-8" aria-hidden="true" tabindex="-1"></a>    query <span>=</span> (</span>
<span id="cb7-9"><a href="#cb7-9" aria-hidden="true" tabindex="-1"></a>        <span>f&#34;The following is a press release issued by ISAF (formerly operating in Afghanistan):</span><span>\n</span><span>{</span>article_text<span>}</span><span>\n\n</span><span>&#34;</span></span>
<span id="cb7-10"><a href="#cb7-10" aria-hidden="true" tabindex="-1"></a>        <span>&#34;## Extraction request</span><span>\n</span><span>&#34;</span></span>
<span id="cb7-11"><a href="#cb7-11" aria-hidden="true" tabindex="-1"></a>        <span>&#34;Please extract the following information from the press release:</span><span>\n</span><span>&#34;</span></span>
<span id="cb7-12"><a href="#cb7-12" aria-hidden="true" tabindex="-1"></a>        <span>&#34;- The name of the event (summarising the event / text as a headline)</span><span>\n</span><span>&#34;</span></span>
<span id="cb7-13"><a href="#cb7-13" aria-hidden="true" tabindex="-1"></a>        <span>&#34;- The start date of the event</span><span>\n</span><span>&#34;</span></span>
<span id="cb7-14"><a href="#cb7-14" aria-hidden="true" tabindex="-1"></a>        <span>&#34;- The event type(s)</span><span>\n</span><span>&#34;</span></span>
<span id="cb7-15"><a href="#cb7-15" aria-hidden="true" tabindex="-1"></a>        <span>&#34;- The province(s) in which the event occurred</span><span>\n</span><span>&#34;</span></span>
<span id="cb7-16"><a href="#cb7-16" aria-hidden="true" tabindex="-1"></a>        <span>&#34;- The target group(s) of the event</span><span>\n</span><span>&#34;</span></span>
<span id="cb7-17"><a href="#cb7-17" aria-hidden="true" tabindex="-1"></a>        <span>&#34;- The minimum number of people killed during the event</span><span>\n</span><span>&#34;</span></span>
<span id="cb7-18"><a href="#cb7-18" aria-hidden="true" tabindex="-1"></a>        <span>&#34;- The minimum number of people captured during the event</span><span>\n</span><span>&#34;</span></span>
<span id="cb7-19"><a href="#cb7-19" aria-hidden="true" tabindex="-1"></a>        <span>&#34;- Whether someone was killed or not during the event</span><span>\n</span><span>&#34;</span></span>
<span id="cb7-20"><a href="#cb7-20" aria-hidden="true" tabindex="-1"></a>        <span>&#34;- Whether someone was captured or not during the event</span><span>\n</span><span>&#34;</span></span>
<span id="cb7-21"><a href="#cb7-21" aria-hidden="true" tabindex="-1"></a>        <span>&#34;- Whether the event was a so-called &#39;kill-capture raid&#39;</span><span>\n</span><span>&#34;</span></span>
<span id="cb7-22"><a href="#cb7-22" aria-hidden="true" tabindex="-1"></a>        <span>&#34;- Whether an airstrike was used during the event</span><span>\n</span><span>&#34;</span></span>
<span id="cb7-23"><a href="#cb7-23" aria-hidden="true" tabindex="-1"></a>        <span>&#34;- Whether no shots were fired during the event</span><span>\n</span><span>&#34;</span></span>
<span id="cb7-24"><a href="#cb7-24" aria-hidden="true" tabindex="-1"></a>        <span>&#34;- The minimum number of leaders killed during the event</span><span>\n</span><span>&#34;</span></span>
<span id="cb7-25"><a href="#cb7-25" aria-hidden="true" tabindex="-1"></a>        <span>&#34;- The minimum number of leaders captured during the event</span><span>\n\n</span><span>&#34;</span></span>
<span id="cb7-26"><a href="#cb7-26" aria-hidden="true" tabindex="-1"></a>        <span>&#34;## Annotation notes:</span><span>\n</span><span>&#34;</span></span>
<span id="cb7-27"><a href="#cb7-27" aria-hidden="true" tabindex="-1"></a>        <span>&#34;- A &#39;faciliator&#39; is not a leader.</span><span>\n</span><span>&#34;</span></span>
<span id="cb7-28"><a href="#cb7-28" aria-hidden="true" tabindex="-1"></a>        <span>&#34;- If a press release states that &#39;insurgents&#39; were detained without further &#34;</span></span>
<span id="cb7-29"><a href="#cb7-29" aria-hidden="true" tabindex="-1"></a>        <span>&#34;details, assign a minimum number of two detained. Interpret &#39;a couple&#39; as &#34;</span></span>
<span id="cb7-30"><a href="#cb7-30" aria-hidden="true" tabindex="-1"></a>        <span>&#34;two. Interpret &#39;several&#39; as at least three, even though it may sometimes &#34;</span></span>
<span id="cb7-31"><a href="#cb7-31" aria-hidden="true" tabindex="-1"></a>        <span>&#34;refer to seven or eight. Classify the terms &#39;a few&#39;, &#39;some&#39;, &#39;a group&#39;, &#39;a &#34;</span></span>
<span id="cb7-32"><a href="#cb7-32" aria-hidden="true" tabindex="-1"></a>        <span>&#34;small group&#39;, and &#39;multiple&#39; as denoting at least three, even if they &#34;</span></span>
<span id="cb7-33"><a href="#cb7-33" aria-hidden="true" tabindex="-1"></a>        <span>&#34;sometimes refer to larger numbers. Choose the smaller number if no other &#34;</span></span>
<span id="cb7-34"><a href="#cb7-34" aria-hidden="true" tabindex="-1"></a>        <span>&#34;information is available in the press release to come up with a minimally &#34;</span></span>
<span id="cb7-35"><a href="#cb7-35" aria-hidden="true" tabindex="-1"></a>        <span>&#34;acceptable figure. Interpret &#39;numerous&#39; and &#39;a handful&#39; as at least four, &#34;</span></span>
<span id="cb7-36"><a href="#cb7-36" aria-hidden="true" tabindex="-1"></a>        <span>&#34;and &#39;a large number&#39; as at least five.</span><span>\n\n</span><span>&#34;</span></span>
<span id="cb7-37"><a href="#cb7-37" aria-hidden="true" tabindex="-1"></a>        <span>&#34;## Example:</span><span>\n</span><span>&#34;</span></span>
<span id="cb7-38"><a href="#cb7-38" aria-hidden="true" tabindex="-1"></a>        <span>&#34;Article text: &#39;ISAF Joint Command Evening Operational Update Feb. 19, 2011</span><span>\n</span><span>ISAF Joint Command - &#34;</span></span>
<span id="cb7-39"><a href="#cb7-39" aria-hidden="true" tabindex="-1"></a>        <span>&#34;Afghanistan</span><span>\u2028</span><span>2011-02-S-143</span><span>\u2028</span><span>For Immediate Release </span><span>\u2028\u2028</span><span>KABUL, Afghanistan (Feb. 19)</span><span>\u2028\u2028</span><span>ISAF &#34;</span></span>
<span id="cb7-40"><a href="#cb7-40" aria-hidden="true" tabindex="-1"></a>        <span>&#34;service members at a compound in Sangin district, Helmand province observed numerous insurgents north and south of &#34;</span></span>
<span id="cb7-41"><a href="#cb7-41" aria-hidden="true" tabindex="-1"></a>        <span>&#34;their position talking on radios today. After gaining positive identification of the insurgent positions, the &#34;</span></span>
<span id="cb7-42"><a href="#cb7-42" aria-hidden="true" tabindex="-1"></a>        <span>&#34;coalition troops engaged, killing several insurgents. Later, the ISAF troops observed more insurgents positioning &#34;</span></span>
<span id="cb7-43"><a href="#cb7-43" aria-hidden="true" tabindex="-1"></a>        <span>&#34;in the area with weapons. After positive identification, coalition forces continued firing on the various insurgent &#34;</span></span>
<span id="cb7-44"><a href="#cb7-44" aria-hidden="true" tabindex="-1"></a>        <span>&#34;positions, resulting in several more insurgents being killed.&#39;</span><span>\n\n</span><span>&#34;</span></span>
<span id="cb7-45"><a href="#cb7-45" aria-hidden="true" tabindex="-1"></a>        <span>&#39;Output: `{&#34;name&#34;:&#34;Several insurgents killed in &#39;</span></span>
<span id="cb7-46"><a href="#cb7-46" aria-hidden="true" tabindex="-1"></a>        <span>&#39;Helmand&#34;,&#34;start_date&#34;:&#34;2011-02-18&#34;,&#34;event_type&#34;:[&#34;insurgentskilled&#34;],&#34;province&#34;:[&#34;helmand&#34;],&#34;target_group&#34;:[&#34;&#34;],&#34;mi&#39;</span></span>
<span id="cb7-47"><a href="#cb7-47" aria-hidden="true" tabindex="-1"></a>        <span>&#39;n_killed&#34;:6,&#34;min_captured&#34;:0,&#34;killq&#34;:true,&#34;captureq&#34;:false,&#34;killcaptureraid&#34;:false,&#34;airstrike&#34;:false,&#34;noshotsfired&#34;&#39;</span></span>
<span id="cb7-48"><a href="#cb7-48" aria-hidden="true" tabindex="-1"></a>        <span>&#39;:false,&#34;min_leaders_killed&#34;:0,&#34;min_leaders_captured&#34;:0}`&#39;</span></span>
<span id="cb7-49"><a href="#cb7-49" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb7-50"><a href="#cb7-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-51"><a href="#cb7-51" aria-hidden="true" tabindex="-1"></a>    <span># set up the prediction harness</span></span>
<span id="cb7-52"><a href="#cb7-52" aria-hidden="true" tabindex="-1"></a>    client <span>=</span> OpenAI(api_key<span>=</span>os.getenv(<span>&#34;OPENAI_API_KEY&#34;</span>))</span>
<span id="cb7-53"><a href="#cb7-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-54"><a href="#cb7-54" aria-hidden="true" tabindex="-1"></a>    response <span>=</span> client.chat.completions.create(</span>
<span id="cb7-55"><a href="#cb7-55" aria-hidden="true" tabindex="-1"></a>        model<span>=</span>model,</span>
<span id="cb7-56"><a href="#cb7-56" aria-hidden="true" tabindex="-1"></a>        response_format<span>=</span>{<span>&#34;type&#34;</span>: <span>&#34;json_object&#34;</span>},</span>
<span id="cb7-57"><a href="#cb7-57" aria-hidden="true" tabindex="-1"></a>        messages<span>=</span>[</span>
<span id="cb7-58"><a href="#cb7-58" aria-hidden="true" tabindex="-1"></a>            {</span>
<span id="cb7-59"><a href="#cb7-59" aria-hidden="true" tabindex="-1"></a>                <span>&#34;role&#34;</span>: <span>&#34;system&#34;</span>,</span>
<span id="cb7-60"><a href="#cb7-60" aria-hidden="true" tabindex="-1"></a>                <span>&#34;content&#34;</span>: <span>&#34;You are an expert at identifying events in a press release. You are precise &#34;</span></span>
<span id="cb7-61"><a href="#cb7-61" aria-hidden="true" tabindex="-1"></a>                <span>&#34;and always make sure you are correct, drawing inference from the text of the &#34;</span></span>
<span id="cb7-62"><a href="#cb7-62" aria-hidden="true" tabindex="-1"></a>                <span>&#34;press release.</span><span>\n\n</span><span> You always return a JSON string with the following schema: &#34;</span></span>
<span id="cb7-63"><a href="#cb7-63" aria-hidden="true" tabindex="-1"></a>                <span>&#34;## JSON Schema details</span><span>\n</span><span>&#34;</span></span>
<span id="cb7-64"><a href="#cb7-64" aria-hidden="true" tabindex="-1"></a>                <span>&#34;Here is some of the schema for the JSON output string you &#34;</span></span>
<span id="cb7-65"><a href="#cb7-65" aria-hidden="true" tabindex="-1"></a>                <span>&#34;should make use of: event_types = [&#39;airstrike&#39;, &#39;detention&#39;, &#34;</span></span>
<span id="cb7-66"><a href="#cb7-66" aria-hidden="true" tabindex="-1"></a>                <span>&#34;&#39;captureandkill&#39;, &#39;insurgentskilled&#39;, &#39;exchangeoffire&#39;, &#39;civiliancasualty&#39;], &#34;</span></span>
<span id="cb7-67"><a href="#cb7-67" aria-hidden="true" tabindex="-1"></a>                <span>&#34;provinces = [&#39;badakhshan&#39;, &#39;badghis&#39;, &#39;baghlan&#39;, &#39;balkh&#39;, &#39;bamyan&#39;, &#34;</span></span>
<span id="cb7-68"><a href="#cb7-68" aria-hidden="true" tabindex="-1"></a>                <span>&#34;&#39;day_kundi&#39;, &#39;farah&#39;, &#39;faryab&#39;, &#39;ghazni&#39;, &#39;ghor&#39;, &#39;helmand&#39;, &#39;herat&#39;, &#34;</span></span>
<span id="cb7-69"><a href="#cb7-69" aria-hidden="true" tabindex="-1"></a>                <span>&#34;&#39;jowzjan&#39;, &#39;kabul&#39;, &#39;kandahar&#39;, &#39;kapisa&#39;, &#39;khost&#39;, &#39;kunar&#39;, &#39;kunduz&#39;, &#34;</span></span>
<span id="cb7-70"><a href="#cb7-70" aria-hidden="true" tabindex="-1"></a>                <span>&#34;&#39;laghman&#39;, &#39;logar&#39;, &#39;nangarhar&#39;, &#39;nimroz&#39;, &#39;nuristan&#39;, &#39;paktya&#39;, &#39;paktika&#39;, &#34;</span></span>
<span id="cb7-71"><a href="#cb7-71" aria-hidden="true" tabindex="-1"></a>                <span>&#34;&#39;panjshir&#39;, &#39;parwan&#39;, &#39;samangan&#39;, &#39;sar_e_pul&#39;, &#39;takhar&#39;, &#39;uruzgan&#39;, &#34;</span></span>
<span id="cb7-72"><a href="#cb7-72" aria-hidden="true" tabindex="-1"></a>                <span>&#34;&#39;wardak&#39;, &#39;zabul&#39;], target_groups = [&#39;taliban&#39;, &#39;haqqani&#39;, &#39;criminals&#39;, &#34;</span></span>
<span id="cb7-73"><a href="#cb7-73" aria-hidden="true" tabindex="-1"></a>                <span>&#34;&#39;aq&#39;, &#39;hig&#39;, &#39;let&#39;, &#39;imu&#39;, &#39;judq&#39;, &#39;iju&#39;, &#39;hik&#39;, &#39;ttp&#39;, &#39;other&#39;]</span><span>\n\n</span><span>&#34;</span>,</span>
<span id="cb7-74"><a href="#cb7-74" aria-hidden="true" tabindex="-1"></a>            },</span>
<span id="cb7-75"><a href="#cb7-75" aria-hidden="true" tabindex="-1"></a>            {<span>&#34;role&#34;</span>: <span>&#34;user&#34;</span>, <span>&#34;content&#34;</span>: query},</span>
<span id="cb7-76"><a href="#cb7-76" aria-hidden="true" tabindex="-1"></a>        ],</span>
<span id="cb7-77"><a href="#cb7-77" aria-hidden="true" tabindex="-1"></a>        temperature<span>=</span><span>1</span>,</span>
<span id="cb7-78"><a href="#cb7-78" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb7-79"><a href="#cb7-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb7-80"><a href="#cb7-80" aria-hidden="true" tabindex="-1"></a>    <span>return</span> response.choices[<span>0</span>].message.content</span></code></pre></div>
</div>
<p>We can make sure this function works with a quick example:</p>
<div data-execution_count="7">
<div id="cb8"><pre><code><span id="cb8-1"><a href="#cb8-1" aria-hidden="true" tabindex="-1"></a>json_str <span>=</span> query_openai(events[<span>0</span>].text, <span>&#34;gpt-4o&#34;</span>)</span>
<span id="cb8-2"><a href="#cb8-2" aria-hidden="true" tabindex="-1"></a><span>print</span>(json.loads(json_str))</span></code></pre></div>
<div>
<pre><span>{</span>
    <span>&#39;name&#39;</span>: <span>&#39;Taliban leader Alaudin killed in Ghazni&#39;</span>,
    <span>&#39;start_date&#39;</span>: <span>&#39;2013-01-24&#39;</span>,
    <span>&#39;event_type&#39;</span>: <span>[</span><span>&#39;insurgentskilled&#39;</span><span>]</span>,
    <span>&#39;province&#39;</span>: <span>[</span><span>&#39;ghazni&#39;</span><span>]</span>,
    <span>&#39;target_group&#39;</span>: <span>[</span><span>&#39;taliban&#39;</span><span>]</span>,
    <span>&#39;min_killed&#39;</span>: <span>1</span>,
    <span>&#39;min_captured&#39;</span>: <span>0</span>,
    <span>&#39;killq&#39;</span>: <span>True</span>,
    <span>&#39;captureq&#39;</span>: <span>False</span>,
    <span>&#39;killcaptureraid&#39;</span>: <span>True</span>,
    <span>&#39;airstrike&#39;</span>: <span>False</span>,
    <span>&#39;noshotsfired&#39;</span>: <span>False</span>,
    <span>&#39;min_leaders_killed&#39;</span>: <span>1</span>,
    <span>&#39;min_leaders_captured&#39;</span>: <span>0</span>
<span>}</span>
</pre>
</div>
</div>
<p>Our model is working (as expected) and we’re also getting a JSON string back. Let’s assemble something that will iterate through all of our test data, get predictions, and then store those predictions on our Pydantic object.</p>
<p>For the bulk predictions, we’ll make sure to do this async, since there are lots of events and we don’t want to waiting all day. You’ll see I also had to add some retries to the function to account for rate limiting on the GPT-3.5-turbo model.</p>
<div>
<details>
<summary>Code</summary>
<div id="cb9"><pre><code><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span># make async work within a notebook</span></span>
<span id="cb9-2"><a href="#cb9-2" aria-hidden="true" tabindex="-1"></a><span>import</span> nest_asyncio</span>
<span id="cb9-3"><a href="#cb9-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-4"><a href="#cb9-4" aria-hidden="true" tabindex="-1"></a>nest_asyncio.<span>apply</span>()</span>
<span id="cb9-5"><a href="#cb9-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-6"><a href="#cb9-6" aria-hidden="true" tabindex="-1"></a><span>import</span> aiohttp</span>
<span id="cb9-7"><a href="#cb9-7" aria-hidden="true" tabindex="-1"></a><span>import</span> asyncio</span>
<span id="cb9-8"><a href="#cb9-8" aria-hidden="true" tabindex="-1"></a><span>from</span> typing <span>import</span> List</span>
<span id="cb9-9"><a href="#cb9-9" aria-hidden="true" tabindex="-1"></a><span>from</span> openai <span>import</span> OpenAI</span>
<span id="cb9-10"><a href="#cb9-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-11"><a href="#cb9-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-12"><a href="#cb9-12" aria-hidden="true" tabindex="-1"></a><span>async</span> <span>def</span> async_query_openai(</span>
<span id="cb9-13"><a href="#cb9-13" aria-hidden="true" tabindex="-1"></a>    session,</span>
<span id="cb9-14"><a href="#cb9-14" aria-hidden="true" tabindex="-1"></a>    article_text: <span>str</span>,</span>
<span id="cb9-15"><a href="#cb9-15" aria-hidden="true" tabindex="-1"></a>    model: <span>str</span>,</span>
<span id="cb9-16"><a href="#cb9-16" aria-hidden="true" tabindex="-1"></a>    max_retries: <span>int</span> <span>=</span> <span>3</span>,</span>
<span id="cb9-17"><a href="#cb9-17" aria-hidden="true" tabindex="-1"></a>    retry_delay: <span>float</span> <span>=</span> <span>1.0</span>,</span>
<span id="cb9-18"><a href="#cb9-18" aria-hidden="true" tabindex="-1"></a>) <span>-&gt;</span> <span>str</span>:</span>
<span id="cb9-19"><a href="#cb9-19" aria-hidden="true" tabindex="-1"></a>    query <span>=</span> (</span>
<span id="cb9-20"><a href="#cb9-20" aria-hidden="true" tabindex="-1"></a>        <span>f&#34;The following is a press release issued by ISAF (formerly operating in Afghanistan):</span><span>\n</span><span>{</span>article_text<span>}</span><span>\n\n</span><span>&#34;</span></span>
<span id="cb9-21"><a href="#cb9-21" aria-hidden="true" tabindex="-1"></a>        <span>&#34;## Extraction request</span><span>\n</span><span>&#34;</span></span>
<span id="cb9-22"><a href="#cb9-22" aria-hidden="true" tabindex="-1"></a>        <span>&#34;Please extract the following information from the press release:</span><span>\n</span><span>&#34;</span></span>
<span id="cb9-23"><a href="#cb9-23" aria-hidden="true" tabindex="-1"></a>        <span>&#34;- The name of the event (summarising the event / text as a headline)</span><span>\n</span><span>&#34;</span></span>
<span id="cb9-24"><a href="#cb9-24" aria-hidden="true" tabindex="-1"></a>        <span>&#34;- The start date of the event</span><span>\n</span><span>&#34;</span></span>
<span id="cb9-25"><a href="#cb9-25" aria-hidden="true" tabindex="-1"></a>        <span>&#34;- The event type(s)</span><span>\n</span><span>&#34;</span></span>
<span id="cb9-26"><a href="#cb9-26" aria-hidden="true" tabindex="-1"></a>        <span>&#34;- The province(s) in which the event occurred</span><span>\n</span><span>&#34;</span></span>
<span id="cb9-27"><a href="#cb9-27" aria-hidden="true" tabindex="-1"></a>        <span>&#34;- The target group(s) of the event</span><span>\n</span><span>&#34;</span></span>
<span id="cb9-28"><a href="#cb9-28" aria-hidden="true" tabindex="-1"></a>        <span>&#34;- The minimum number of people killed during the event</span><span>\n</span><span>&#34;</span></span>
<span id="cb9-29"><a href="#cb9-29" aria-hidden="true" tabindex="-1"></a>        <span>&#34;- The minimum number of people captured during the event</span><span>\n</span><span>&#34;</span></span>
<span id="cb9-30"><a href="#cb9-30" aria-hidden="true" tabindex="-1"></a>        <span>&#34;- Whether someone was killed or not during the event</span><span>\n</span><span>&#34;</span></span>
<span id="cb9-31"><a href="#cb9-31" aria-hidden="true" tabindex="-1"></a>        <span>&#34;- Whether someone was captured or not during the event</span><span>\n</span><span>&#34;</span></span>
<span id="cb9-32"><a href="#cb9-32" aria-hidden="true" tabindex="-1"></a>        <span>&#34;- Whether the event was a so-called &#39;kill-capture raid&#39;</span><span>\n</span><span>&#34;</span></span>
<span id="cb9-33"><a href="#cb9-33" aria-hidden="true" tabindex="-1"></a>        <span>&#34;- Whether an airstrike was used during the event</span><span>\n</span><span>&#34;</span></span>
<span id="cb9-34"><a href="#cb9-34" aria-hidden="true" tabindex="-1"></a>        <span>&#34;- Whether no shots were fired during the event</span><span>\n</span><span>&#34;</span></span>
<span id="cb9-35"><a href="#cb9-35" aria-hidden="true" tabindex="-1"></a>        <span>&#34;- The minimum number of leaders killed during the event</span><span>\n</span><span>&#34;</span></span>
<span id="cb9-36"><a href="#cb9-36" aria-hidden="true" tabindex="-1"></a>        <span>&#34;- The minimum number of leaders captured during the event</span><span>\n\n</span><span>&#34;</span></span>
<span id="cb9-37"><a href="#cb9-37" aria-hidden="true" tabindex="-1"></a>        <span>&#34;## Annotation notes:</span><span>\n</span><span>&#34;</span></span>
<span id="cb9-38"><a href="#cb9-38" aria-hidden="true" tabindex="-1"></a>        <span>&#34;- A &#39;faciliator&#39; is not a leader.</span><span>\n</span><span>&#34;</span></span>
<span id="cb9-39"><a href="#cb9-39" aria-hidden="true" tabindex="-1"></a>        <span>&#34;- If a press release states that &#39;insurgents&#39; were detained without further &#34;</span></span>
<span id="cb9-40"><a href="#cb9-40" aria-hidden="true" tabindex="-1"></a>        <span>&#34;details, assign a minimum number of two detained. Interpret &#39;a couple&#39; as &#34;</span></span>
<span id="cb9-41"><a href="#cb9-41" aria-hidden="true" tabindex="-1"></a>        <span>&#34;two. Interpret &#39;several&#39; as at least three, even though it may sometimes &#34;</span></span>
<span id="cb9-42"><a href="#cb9-42" aria-hidden="true" tabindex="-1"></a>        <span>&#34;refer to seven or eight. Classify the terms &#39;a few&#39;, &#39;some&#39;, &#39;a group&#39;, &#39;a &#34;</span></span>
<span id="cb9-43"><a href="#cb9-43" aria-hidden="true" tabindex="-1"></a>        <span>&#34;small group&#39;, and &#39;multiple&#39; as denoting at least three, even if they &#34;</span></span>
<span id="cb9-44"><a href="#cb9-44" aria-hidden="true" tabindex="-1"></a>        <span>&#34;sometimes refer to larger numbers. Choose the smaller number if no other &#34;</span></span>
<span id="cb9-45"><a href="#cb9-45" aria-hidden="true" tabindex="-1"></a>        <span>&#34;information is available in the press release to come up with a minimally &#34;</span></span>
<span id="cb9-46"><a href="#cb9-46" aria-hidden="true" tabindex="-1"></a>        <span>&#34;acceptable figure. Interpret &#39;numerous&#39; and &#39;a handful&#39; as at least four, &#34;</span></span>
<span id="cb9-47"><a href="#cb9-47" aria-hidden="true" tabindex="-1"></a>        <span>&#34;and &#39;a large number&#39; as at least five.</span><span>\n\n</span><span>&#34;</span></span>
<span id="cb9-48"><a href="#cb9-48" aria-hidden="true" tabindex="-1"></a>        <span>&#34;## Example:</span><span>\n</span><span>&#34;</span></span>
<span id="cb9-49"><a href="#cb9-49" aria-hidden="true" tabindex="-1"></a>        <span>&#34;Article text: &#39;ISAF Joint Command Evening Operational Update Feb. 19, 2011</span><span>\n</span><span>ISAF Joint Command - &#34;</span></span>
<span id="cb9-50"><a href="#cb9-50" aria-hidden="true" tabindex="-1"></a>        <span>&#34;Afghanistan</span><span>\u2028</span><span>2011-02-S-143</span><span>\u2028</span><span>For Immediate Release </span><span>\u2028\u2028</span><span>KABUL, Afghanistan (Feb. 19)</span><span>\u2028\u2028</span><span>ISAF &#34;</span></span>
<span id="cb9-51"><a href="#cb9-51" aria-hidden="true" tabindex="-1"></a>        <span>&#34;service members at a compound in Sangin district, Helmand province observed numerous insurgents north and south of &#34;</span></span>
<span id="cb9-52"><a href="#cb9-52" aria-hidden="true" tabindex="-1"></a>        <span>&#34;their position talking on radios today. After gaining positive identification of the insurgent positions, the &#34;</span></span>
<span id="cb9-53"><a href="#cb9-53" aria-hidden="true" tabindex="-1"></a>        <span>&#34;coalition troops engaged, killing several insurgents. Later, the ISAF troops observed more insurgents positioning &#34;</span></span>
<span id="cb9-54"><a href="#cb9-54" aria-hidden="true" tabindex="-1"></a>        <span>&#34;in the area with weapons. After positive identification, coalition forces continued firing on the various insurgent &#34;</span></span>
<span id="cb9-55"><a href="#cb9-55" aria-hidden="true" tabindex="-1"></a>        <span>&#34;positions, resulting in several more insurgents being killed.&#39;</span><span>\n\n</span><span>&#34;</span></span>
<span id="cb9-56"><a href="#cb9-56" aria-hidden="true" tabindex="-1"></a>        <span>&#39;Output: `{&#34;name&#34;:&#34;Several insurgents killed in &#39;</span></span>
<span id="cb9-57"><a href="#cb9-57" aria-hidden="true" tabindex="-1"></a>        <span>&#39;Helmand&#34;,&#34;start_date&#34;:&#34;2011-02-18&#34;,&#34;event_type&#34;:[&#34;insurgentskilled&#34;],&#34;province&#34;:[&#34;helmand&#34;],&#34;target_group&#34;:[&#34;&#34;],&#34;mi&#39;</span></span>
<span id="cb9-58"><a href="#cb9-58" aria-hidden="true" tabindex="-1"></a>        <span>&#39;n_killed&#34;:6,&#34;min_captured&#34;:0,&#34;killq&#34;:true,&#34;captureq&#34;:false,&#34;killcaptureraid&#34;:false,&#34;airstrike&#34;:false,&#34;noshotsfired&#34;&#39;</span></span>
<span id="cb9-59"><a href="#cb9-59" aria-hidden="true" tabindex="-1"></a>        <span>&#39;:false,&#34;min_leaders_killed&#34;:0,&#34;min_leaders_captured&#34;:0}`&#39;</span></span>
<span id="cb9-60"><a href="#cb9-60" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb9-61"><a href="#cb9-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-62"><a href="#cb9-62" aria-hidden="true" tabindex="-1"></a>    client <span>=</span> OpenAI(api_key<span>=</span>os.getenv(<span>&#34;OPENAI_API_KEY&#34;</span>))</span>
<span id="cb9-63"><a href="#cb9-63" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-64"><a href="#cb9-64" aria-hidden="true" tabindex="-1"></a>    retries <span>=</span> <span>0</span></span>
<span id="cb9-65"><a href="#cb9-65" aria-hidden="true" tabindex="-1"></a>    <span>while</span> retries <span>&lt;</span> max_retries:</span>
<span id="cb9-66"><a href="#cb9-66" aria-hidden="true" tabindex="-1"></a>        <span>async</span> <span>with</span> session.post(</span>
<span id="cb9-67"><a href="#cb9-67" aria-hidden="true" tabindex="-1"></a>            <span>&#34;https://api.openai.com/v1/chat/completions&#34;</span>,</span>
<span id="cb9-68"><a href="#cb9-68" aria-hidden="true" tabindex="-1"></a>            headers<span>=</span>{<span>&#34;Authorization&#34;</span>: <span>f&#34;Bearer </span><span>{</span>client<span>.</span>api_key<span>}</span><span>&#34;</span>},</span>
<span id="cb9-69"><a href="#cb9-69" aria-hidden="true" tabindex="-1"></a>            json<span>=</span>{</span>
<span id="cb9-70"><a href="#cb9-70" aria-hidden="true" tabindex="-1"></a>                <span>&#34;model&#34;</span>: model,</span>
<span id="cb9-71"><a href="#cb9-71" aria-hidden="true" tabindex="-1"></a>                <span>&#34;response_format&#34;</span>: {<span>&#34;type&#34;</span>: <span>&#34;json_object&#34;</span>},</span>
<span id="cb9-72"><a href="#cb9-72" aria-hidden="true" tabindex="-1"></a>                <span>&#34;messages&#34;</span>: [</span>
<span id="cb9-73"><a href="#cb9-73" aria-hidden="true" tabindex="-1"></a>                    {</span>
<span id="cb9-74"><a href="#cb9-74" aria-hidden="true" tabindex="-1"></a>                        <span>&#34;role&#34;</span>: <span>&#34;system&#34;</span>,</span>
<span id="cb9-75"><a href="#cb9-75" aria-hidden="true" tabindex="-1"></a>                        <span>&#34;content&#34;</span>: <span>&#34;You are an expert at identifying events in a press release. You are precise &#34;</span></span>
<span id="cb9-76"><a href="#cb9-76" aria-hidden="true" tabindex="-1"></a>                        <span>&#34;and always make sure you are correct, drawing inference from the text of the &#34;</span></span>
<span id="cb9-77"><a href="#cb9-77" aria-hidden="true" tabindex="-1"></a>                        <span>&#34;press release.</span><span>\n\n</span><span> You always return a JSON string with the following schema: &#34;</span></span>
<span id="cb9-78"><a href="#cb9-78" aria-hidden="true" tabindex="-1"></a>                        <span>&#34;## JSON Schema details</span><span>\n</span><span>&#34;</span></span>
<span id="cb9-79"><a href="#cb9-79" aria-hidden="true" tabindex="-1"></a>                        <span>&#34;Here is some of the schema for the JSON output string you &#34;</span></span>
<span id="cb9-80"><a href="#cb9-80" aria-hidden="true" tabindex="-1"></a>                        <span>&#34;should make use of: event_types = [&#39;airstrike&#39;, &#39;detention&#39;, &#34;</span></span>
<span id="cb9-81"><a href="#cb9-81" aria-hidden="true" tabindex="-1"></a>                        <span>&#34;&#39;captureandkill&#39;, &#39;insurgentskilled&#39;, &#39;exchangeoffire&#39;, &#39;civiliancasualty&#39;], &#34;</span></span>
<span id="cb9-82"><a href="#cb9-82" aria-hidden="true" tabindex="-1"></a>                        <span>&#34;provinces = [&#39;badakhshan&#39;, &#39;badghis&#39;, &#39;baghlan&#39;, &#39;balkh&#39;, &#39;bamyan&#39;, &#34;</span></span>
<span id="cb9-83"><a href="#cb9-83" aria-hidden="true" tabindex="-1"></a>                        <span>&#34;&#39;day_kundi&#39;, &#39;farah&#39;, &#39;faryab&#39;, &#39;ghazni&#39;, &#39;ghor&#39;, &#39;helmand&#39;, &#39;herat&#39;, &#34;</span></span>
<span id="cb9-84"><a href="#cb9-84" aria-hidden="true" tabindex="-1"></a>                        <span>&#34;&#39;jowzjan&#39;, &#39;kabul&#39;, &#39;kandahar&#39;, &#39;kapisa&#39;, &#39;khost&#39;, &#39;kunar&#39;, &#39;kunduz&#39;, &#34;</span></span>
<span id="cb9-85"><a href="#cb9-85" aria-hidden="true" tabindex="-1"></a>                        <span>&#34;&#39;laghman&#39;, &#39;logar&#39;, &#39;nangarhar&#39;, &#39;nimroz&#39;, &#39;nuristan&#39;, &#39;paktya&#39;, &#39;paktika&#39;, &#34;</span></span>
<span id="cb9-86"><a href="#cb9-86" aria-hidden="true" tabindex="-1"></a>                        <span>&#34;&#39;panjshir&#39;, &#39;parwan&#39;, &#39;samangan&#39;, &#39;sar_e_pul&#39;, &#39;takhar&#39;, &#39;uruzgan&#39;, &#34;</span></span>
<span id="cb9-87"><a href="#cb9-87" aria-hidden="true" tabindex="-1"></a>                        <span>&#34;&#39;wardak&#39;, &#39;zabul&#39;], target_groups = [&#39;taliban&#39;, &#39;haqqani&#39;, &#39;criminals&#39;, &#34;</span></span>
<span id="cb9-88"><a href="#cb9-88" aria-hidden="true" tabindex="-1"></a>                        <span>&#34;&#39;aq&#39;, &#39;hig&#39;, &#39;let&#39;, &#39;imu&#39;, &#39;judq&#39;, &#39;iju&#39;, &#39;hik&#39;, &#39;ttp&#39;, &#39;other&#39;]</span><span>\n\n</span><span>&#34;</span>,</span>
<span id="cb9-89"><a href="#cb9-89" aria-hidden="true" tabindex="-1"></a>                    },</span>
<span id="cb9-90"><a href="#cb9-90" aria-hidden="true" tabindex="-1"></a>                    {<span>&#34;role&#34;</span>: <span>&#34;user&#34;</span>, <span>&#34;content&#34;</span>: query},</span>
<span id="cb9-91"><a href="#cb9-91" aria-hidden="true" tabindex="-1"></a>                ],</span>
<span id="cb9-92"><a href="#cb9-92" aria-hidden="true" tabindex="-1"></a>                <span>&#34;temperature&#34;</span>: <span>1</span>,</span>
<span id="cb9-93"><a href="#cb9-93" aria-hidden="true" tabindex="-1"></a>            },</span>
<span id="cb9-94"><a href="#cb9-94" aria-hidden="true" tabindex="-1"></a>        ) <span>as</span> response:</span>
<span id="cb9-95"><a href="#cb9-95" aria-hidden="true" tabindex="-1"></a>            result <span>=</span> <span>await</span> response.json()</span>
<span id="cb9-96"><a href="#cb9-96" aria-hidden="true" tabindex="-1"></a>            <span>if</span> <span>&#34;error&#34;</span> <span>in</span> result:</span>
<span id="cb9-97"><a href="#cb9-97" aria-hidden="true" tabindex="-1"></a>                error_message <span>=</span> result[<span>&#34;error&#34;</span>][<span>&#34;message&#34;</span>]</span>
<span id="cb9-98"><a href="#cb9-98" aria-hidden="true" tabindex="-1"></a>                <span>if</span> <span>&#34;Rate limit reached&#34;</span> <span>in</span> error_message:</span>
<span id="cb9-99"><a href="#cb9-99" aria-hidden="true" tabindex="-1"></a>                    <span># retry_delay_ms = float(</span></span>
<span id="cb9-100"><a href="#cb9-100" aria-hidden="true" tabindex="-1"></a>                    <span>#     error_message.split(&#34;Please try again in &#34;)[1].split(&#34;ms&#34;)[0]</span></span>
<span id="cb9-101"><a href="#cb9-101" aria-hidden="true" tabindex="-1"></a>                    <span># )</span></span>
<span id="cb9-102"><a href="#cb9-102" aria-hidden="true" tabindex="-1"></a>                    retry_delay_ms <span>=</span> <span>35000</span></span>
<span id="cb9-103"><a href="#cb9-103" aria-hidden="true" tabindex="-1"></a>                    retry_delay_seconds <span>=</span> retry_delay_ms <span>/</span> <span>1000</span></span>
<span id="cb9-104"><a href="#cb9-104" aria-hidden="true" tabindex="-1"></a>                    <span>print</span>(</span>
<span id="cb9-105"><a href="#cb9-105" aria-hidden="true" tabindex="-1"></a>                        <span>f&#34;Rate limit exceeded. Retrying in </span><span>{</span>retry_delay_seconds<span>}</span><span> seconds...&#34;</span></span>
<span id="cb9-106"><a href="#cb9-106" aria-hidden="true" tabindex="-1"></a>                    )</span>
<span id="cb9-107"><a href="#cb9-107" aria-hidden="true" tabindex="-1"></a>                    <span>await</span> asyncio.sleep(retry_delay_seconds)</span>
<span id="cb9-108"><a href="#cb9-108" aria-hidden="true" tabindex="-1"></a>                    retries <span>+=</span> <span>1</span></span>
<span id="cb9-109"><a href="#cb9-109" aria-hidden="true" tabindex="-1"></a>                    <span>continue</span></span>
<span id="cb9-110"><a href="#cb9-110" aria-hidden="true" tabindex="-1"></a>                <span>else</span>:</span>
<span id="cb9-111"><a href="#cb9-111" aria-hidden="true" tabindex="-1"></a>                    <span>print</span>(<span>f&#34;Error during prediction.</span><span>\n</span><span>Full result object: </span><span>{</span>result<span>}</span><span>&#34;</span>)</span>
<span id="cb9-112"><a href="#cb9-112" aria-hidden="true" tabindex="-1"></a>                    <span>return</span> <span>&#34;&#34;</span></span>
<span id="cb9-113"><a href="#cb9-113" aria-hidden="true" tabindex="-1"></a>            <span>try</span>:</span>
<span id="cb9-114"><a href="#cb9-114" aria-hidden="true" tabindex="-1"></a>                <span>return</span> result[<span>&#34;choices&#34;</span>][<span>0</span>][<span>&#34;message&#34;</span>][<span>&#34;content&#34;</span>]</span>
<span id="cb9-115"><a href="#cb9-115" aria-hidden="true" tabindex="-1"></a>            <span>except</span> <span>KeyError</span>:</span>
<span id="cb9-116"><a href="#cb9-116" aria-hidden="true" tabindex="-1"></a>                <span>print</span>(<span>f&#34;Error during prediction.</span><span>\n</span><span>Full result object: </span><span>{</span>result<span>}</span><span>&#34;</span>)</span>
<span id="cb9-117"><a href="#cb9-117" aria-hidden="true" tabindex="-1"></a>                <span>return</span> <span>&#34;&#34;</span></span>
<span id="cb9-118"><a href="#cb9-118" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-119"><a href="#cb9-119" aria-hidden="true" tabindex="-1"></a>    <span>print</span>(<span>f&#34;Max retries exceeded for event.</span><span>\n</span><span>Full result object: </span><span>{</span>result<span>}</span><span>&#34;</span>)</span>
<span id="cb9-120"><a href="#cb9-120" aria-hidden="true" tabindex="-1"></a>    <span>return</span> <span>&#34;&#34;</span></span>
<span id="cb9-121"><a href="#cb9-121" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-122"><a href="#cb9-122" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-123"><a href="#cb9-123" aria-hidden="true" tabindex="-1"></a><span>async</span> <span>def</span> get_gpt_predictions_async(</span>
<span id="cb9-124"><a href="#cb9-124" aria-hidden="true" tabindex="-1"></a>    model: <span>str</span>,</span>
<span id="cb9-125"><a href="#cb9-125" aria-hidden="true" tabindex="-1"></a>    events: List[IsafEvent],</span>
<span id="cb9-126"><a href="#cb9-126" aria-hidden="true" tabindex="-1"></a>    logging_n: <span>int</span> <span>=</span> <span>100</span>,</span>
<span id="cb9-127"><a href="#cb9-127" aria-hidden="true" tabindex="-1"></a>    max_concurrent_requests: <span>int</span> <span>=</span> <span>5</span>,</span>
<span id="cb9-128"><a href="#cb9-128" aria-hidden="true" tabindex="-1"></a>) <span>-&gt;</span> List[IsafEvent]:</span>
<span id="cb9-129"><a href="#cb9-129" aria-hidden="true" tabindex="-1"></a>    <span>async</span> <span>with</span> aiohttp.ClientSession() <span>as</span> session:</span>
<span id="cb9-130"><a href="#cb9-130" aria-hidden="true" tabindex="-1"></a>        semaphore <span>=</span> asyncio.Semaphore(max_concurrent_requests)</span>
<span id="cb9-131"><a href="#cb9-131" aria-hidden="true" tabindex="-1"></a>        tasks <span>=</span> []</span>
<span id="cb9-132"><a href="#cb9-132" aria-hidden="true" tabindex="-1"></a>        <span>for</span> i, event <span>in</span> <span>enumerate</span>(events, start<span>=</span><span>1</span>):</span>
<span id="cb9-133"><a href="#cb9-133" aria-hidden="true" tabindex="-1"></a>            <span>if</span> i <span>%</span> logging_n <span>==</span> <span>0</span>:</span>
<span id="cb9-134"><a href="#cb9-134" aria-hidden="true" tabindex="-1"></a>                <span>print</span>(<span>f&#34;Predicting event </span><span>{</span>i<span>}</span><span> of </span><span>{</span><span>len</span>(events)<span>}</span><span> using </span><span>{</span>model<span>}</span><span>&#34;</span>)</span>
<span id="cb9-135"><a href="#cb9-135" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-136"><a href="#cb9-136" aria-hidden="true" tabindex="-1"></a>            <span>async</span> <span>def</span> make_request(session, event):</span>
<span id="cb9-137"><a href="#cb9-137" aria-hidden="true" tabindex="-1"></a>                <span>async</span> <span>with</span> semaphore:</span>
<span id="cb9-138"><a href="#cb9-138" aria-hidden="true" tabindex="-1"></a>                    <span>return</span> <span>await</span> async_query_openai(</span>
<span id="cb9-139"><a href="#cb9-139" aria-hidden="true" tabindex="-1"></a>                        session, event.text, model, max_retries<span>=</span><span>5</span></span>
<span id="cb9-140"><a href="#cb9-140" aria-hidden="true" tabindex="-1"></a>                    )</span>
<span id="cb9-141"><a href="#cb9-141" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-142"><a href="#cb9-142" aria-hidden="true" tabindex="-1"></a>            task <span>=</span> asyncio.ensure_future(make_request(session, event))</span>
<span id="cb9-143"><a href="#cb9-143" aria-hidden="true" tabindex="-1"></a>            tasks.append(task)</span>
<span id="cb9-144"><a href="#cb9-144" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-145"><a href="#cb9-145" aria-hidden="true" tabindex="-1"></a>        predictions <span>=</span> <span>await</span> asyncio.gather(<span>*</span>tasks)</span>
<span id="cb9-146"><a href="#cb9-146" aria-hidden="true" tabindex="-1"></a>        <span>for</span> event, prediction <span>in</span> <span>zip</span>(events, predictions):</span>
<span id="cb9-147"><a href="#cb9-147" aria-hidden="true" tabindex="-1"></a>            event.predictions[model] <span>=</span> prediction</span>
<span id="cb9-148"><a href="#cb9-148" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-149"><a href="#cb9-149" aria-hidden="true" tabindex="-1"></a>    <span>return</span> events</span>
<span id="cb9-150"><a href="#cb9-150" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-151"><a href="#cb9-151" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-152"><a href="#cb9-152" aria-hidden="true" tabindex="-1"></a><span>async</span> <span>def</span> main():</span>
<span id="cb9-153"><a href="#cb9-153" aria-hidden="true" tabindex="-1"></a>    events_4o <span>=</span> <span>await</span> get_gpt_predictions_async(</span>
<span id="cb9-154"><a href="#cb9-154" aria-hidden="true" tabindex="-1"></a>        <span>&#34;gpt-4o&#34;</span>, events, max_concurrent_requests<span>=</span><span>10</span></span>
<span id="cb9-155"><a href="#cb9-155" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb9-156"><a href="#cb9-156" aria-hidden="true" tabindex="-1"></a>    events_4turbo <span>=</span> <span>await</span> get_gpt_predictions_async(</span>
<span id="cb9-157"><a href="#cb9-157" aria-hidden="true" tabindex="-1"></a>        <span>&#34;gpt-4-turbo&#34;</span>, events_4o, max_concurrent_requests<span>=</span><span>10</span></span>
<span id="cb9-158"><a href="#cb9-158" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb9-159"><a href="#cb9-159" aria-hidden="true" tabindex="-1"></a>    full_events <span>=</span> <span>await</span> get_gpt_predictions_async(</span>
<span id="cb9-160"><a href="#cb9-160" aria-hidden="true" tabindex="-1"></a>        <span>&#34;gpt-3.5-turbo&#34;</span>, events_4turbo, max_concurrent_requests<span>=</span><span>10</span></span>
<span id="cb9-161"><a href="#cb9-161" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb9-162"><a href="#cb9-162" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-163"><a href="#cb9-163" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb9-164"><a href="#cb9-164" aria-hidden="true" tabindex="-1"></a><span>await</span> main()</span></code></pre></div>
</details>
</div>
<p>So as you can now see, we have three predictions attached to each event.</p>
<div data-execution_count="17">

<div>
<pre><span>IsafEvent</span><span>(</span>
    <span>name</span>=<span>&#39;5&#39;</span>,
    <span>text</span>=<span>&#39;2013-01-S-025\n\nKABUL, Afghanistan (Jan. 25, 2013)\nDuring a security operation in Andar district, </span>
<span>Ghazni province, yesterday, an Afghan and coalition force killed the Taliban leader, Alaudin. Alaudin oversaw a </span>
<span>group of insurgents responsible for conducting remote-controlled improvised explosive device and small-arms fire </span>
<span>attacks against Afghan and coalition forces. Prior to his death, Alaudin was planning attacks against Afghan </span>
<span>National Police in Ghazni province.&#39;</span>,
    <span>start_date</span>=<span>datetime</span><span>.date</span><span>(</span><span>2013</span>, <span>1</span>, <span>24</span><span>)</span>,
    <span>event_type</span>=<span>{</span><span>&#39;insurgentskilled&#39;</span><span>}</span>,
    <span>province</span>=<span>{</span><span>&#39;ghazni&#39;</span><span>}</span>,
    <span>target_group</span>=<span>{</span><span>&#39;taliban&#39;</span><span>}</span>,
    <span>min_killed</span>=<span>1</span>,
    <span>min_captured</span>=<span>0</span>,
    <span>killq</span>=<span>True</span>,
    <span>captureq</span>=<span>False</span>,
    <span>killcaptureraid</span>=<span>False</span>,
    <span>airstrike</span>=<span>False</span>,
    <span>noshotsfired</span>=<span>False</span>,
    <span>min_leaders_killed</span>=<span>1</span>,
    <span>min_leaders_captured</span>=<span>0</span>,
    <span>predictions</span>=<span>{</span>
        <span>&#39;gpt-4o&#39;</span>: <span>&#39;{\n  &#34;name&#34;: &#34;Taliban leader Alaudin killed in Ghazni&#34;,\n  &#34;start_date&#34;: &#34;2013-01-24&#34;,\n  </span>
<span>&#34;event_type&#34;: [&#34;insurgentskilled&#34;, &#34;captureandkill&#34;],\n  &#34;province&#34;: [&#34;ghazni&#34;],\n  &#34;target_group&#34;: [&#34;taliban&#34;],\n </span>
<span>&#34;min_killed&#34;: 1,\n  &#34;min_captured&#34;: 0,\n  &#34;killq&#34;: true,\n  &#34;captureq&#34;: false,\n  &#34;killcaptureraid&#34;: true,\n  </span>
<span>&#34;airstrike&#34;: false,\n  &#34;noshotsfired&#34;: false,\n  &#34;min_leaders_killed&#34;: 1,\n  &#34;min_leaders_captured&#34;: 0\n}&#39;</span>,
        <span>&#39;gpt-4-turbo&#39;</span>: <span>&#39;{\n    &#34;name&#34;: &#34;Taliban leader Alaudin killed in Ghazni&#34;,\n    &#34;start_date&#34;: </span>
<span>&#34;2013-01-24&#34;,\n    &#34;event_type&#34;: [&#34;captureandkill&#34;],\n    &#34;province&#34;: [&#34;ghazni&#34;],\n    &#34;target_group&#34;: </span>
<span>[&#34;taliban&#34;],\n    &#34;min_killed&#34;: 1,\n    &#34;min_captured&#34;: 0,\n    &#34;killq&#34;: true,\n    &#34;captureq&#34;: false,\n    </span>
<span>&#34;killcaptureraid&#34;: true,\n    &#34;airstrike&#34;: false,\n    &#34;noshotsfired&#34;: false,\n    &#34;min_leaders_killed&#34;: 1,\n    </span>
<span>&#34;min_leaders_captured&#34;: 0\n}&#39;</span>,
        <span>&#39;gpt-3.5-turbo&#39;</span>: <span>&#39;{\n    &#34;name&#34;: &#34;Taliban leader Alaudin killed in Ghazni province&#34;,\n    &#34;start_date&#34;: </span>
<span>&#34;2013-01-24&#34;,\n    &#34;event_type&#34;: [&#34;captureandkill&#34;],\n    &#34;province&#34;: [&#34;ghazni&#34;],\n    &#34;target_group&#34;: </span>
<span>[&#34;taliban&#34;],\n    &#34;min_killed&#34;: 1,\n    &#34;min_captured&#34;: 0,\n    &#34;killq&#34;: true,\n    &#34;captureq&#34;: false,\n    </span>
<span>&#34;killcaptureraid&#34;: false,\n    &#34;airstrike&#34;: false,\n    &#34;noshotsfired&#34;: false,\n    &#34;min_leaders_killed&#34;: 1,\n    </span>
<span>&#34;min_leaders_captured&#34;: 0\n}&#39;</span>
    <span>}</span>
<span>)</span>
</pre>
</div>
</div>
<p>I have all these predictions living in memory right now so it’s probably a good time to commit these to a dataset and push them to the Hugging Face Hub in case the notebook crashes or my local machine shuts down or something else unexpected.</p>
<p>I’ll create a function to handle this as we’ll be repeating this process for the other models as well. It’s a bit verbose but I thought it preferable so you can see what’s going on.</p>
<div data-execution_count="35">
<details>
<summary>Code</summary>
<div id="cb11"><pre><code><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span>from</span> datasets <span>import</span> Dataset</span>
<span id="cb11-2"><a href="#cb11-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-3"><a href="#cb11-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-4"><a href="#cb11-4" aria-hidden="true" tabindex="-1"></a><span>def</span> convert_to_dataset(data: List[IsafEvent]) <span>-&gt;</span> Dataset:</span>
<span id="cb11-5"><a href="#cb11-5" aria-hidden="true" tabindex="-1"></a>    names <span>=</span> []</span>
<span id="cb11-6"><a href="#cb11-6" aria-hidden="true" tabindex="-1"></a>    texts <span>=</span> []</span>
<span id="cb11-7"><a href="#cb11-7" aria-hidden="true" tabindex="-1"></a>    start_dates <span>=</span> []</span>
<span id="cb11-8"><a href="#cb11-8" aria-hidden="true" tabindex="-1"></a>    provinces <span>=</span> []</span>
<span id="cb11-9"><a href="#cb11-9" aria-hidden="true" tabindex="-1"></a>    target_groups <span>=</span> []</span>
<span id="cb11-10"><a href="#cb11-10" aria-hidden="true" tabindex="-1"></a>    event_types <span>=</span> []</span>
<span id="cb11-11"><a href="#cb11-11" aria-hidden="true" tabindex="-1"></a>    predictions <span>=</span> []</span>
<span id="cb11-12"><a href="#cb11-12" aria-hidden="true" tabindex="-1"></a>    min_killeds <span>=</span> []</span>
<span id="cb11-13"><a href="#cb11-13" aria-hidden="true" tabindex="-1"></a>    min_captureds <span>=</span> []</span>
<span id="cb11-14"><a href="#cb11-14" aria-hidden="true" tabindex="-1"></a>    killqs <span>=</span> []</span>
<span id="cb11-15"><a href="#cb11-15" aria-hidden="true" tabindex="-1"></a>    captureqs <span>=</span> []</span>
<span id="cb11-16"><a href="#cb11-16" aria-hidden="true" tabindex="-1"></a>    killcaptureraids <span>=</span> []</span>
<span id="cb11-17"><a href="#cb11-17" aria-hidden="true" tabindex="-1"></a>    airstrikes <span>=</span> []</span>
<span id="cb11-18"><a href="#cb11-18" aria-hidden="true" tabindex="-1"></a>    noshotsfireds <span>=</span> []</span>
<span id="cb11-19"><a href="#cb11-19" aria-hidden="true" tabindex="-1"></a>    min_leaders_killeds <span>=</span> []</span>
<span id="cb11-20"><a href="#cb11-20" aria-hidden="true" tabindex="-1"></a>    min_leaders_captureds <span>=</span> []</span>
<span id="cb11-21"><a href="#cb11-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-22"><a href="#cb11-22" aria-hidden="true" tabindex="-1"></a>    <span>for</span> item <span>in</span> data:</span>
<span id="cb11-23"><a href="#cb11-23" aria-hidden="true" tabindex="-1"></a>        names.append(item.name)</span>
<span id="cb11-24"><a href="#cb11-24" aria-hidden="true" tabindex="-1"></a>        texts.append(item.text)</span>
<span id="cb11-25"><a href="#cb11-25" aria-hidden="true" tabindex="-1"></a>        start_dates.append(item.start_date)</span>
<span id="cb11-26"><a href="#cb11-26" aria-hidden="true" tabindex="-1"></a>        provinces.append(item.province)</span>
<span id="cb11-27"><a href="#cb11-27" aria-hidden="true" tabindex="-1"></a>        target_groups.append(item.target_group)</span>
<span id="cb11-28"><a href="#cb11-28" aria-hidden="true" tabindex="-1"></a>        event_types.append(item.event_type)</span>
<span id="cb11-29"><a href="#cb11-29" aria-hidden="true" tabindex="-1"></a>        predictions.append(item.predictions)</span>
<span id="cb11-30"><a href="#cb11-30" aria-hidden="true" tabindex="-1"></a>        min_killeds.append(item.min_killed)</span>
<span id="cb11-31"><a href="#cb11-31" aria-hidden="true" tabindex="-1"></a>        min_captureds.append(item.min_captured)</span>
<span id="cb11-32"><a href="#cb11-32" aria-hidden="true" tabindex="-1"></a>        killqs.append(item.killq)</span>
<span id="cb11-33"><a href="#cb11-33" aria-hidden="true" tabindex="-1"></a>        captureqs.append(item.captureq)</span>
<span id="cb11-34"><a href="#cb11-34" aria-hidden="true" tabindex="-1"></a>        killcaptureraids.append(item.killcaptureraid)</span>
<span id="cb11-35"><a href="#cb11-35" aria-hidden="true" tabindex="-1"></a>        airstrikes.append(item.airstrike)</span>
<span id="cb11-36"><a href="#cb11-36" aria-hidden="true" tabindex="-1"></a>        noshotsfireds.append(item.noshotsfired)</span>
<span id="cb11-37"><a href="#cb11-37" aria-hidden="true" tabindex="-1"></a>        min_leaders_killeds.append(item.min_leaders_killed)</span>
<span id="cb11-38"><a href="#cb11-38" aria-hidden="true" tabindex="-1"></a>        min_leaders_captureds.append(item.min_leaders_captured)</span>
<span id="cb11-39"><a href="#cb11-39" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-40"><a href="#cb11-40" aria-hidden="true" tabindex="-1"></a>    dataset_dict <span>=</span> {</span>
<span id="cb11-41"><a href="#cb11-41" aria-hidden="true" tabindex="-1"></a>        <span>&#34;name&#34;</span>: names,</span>
<span id="cb11-42"><a href="#cb11-42" aria-hidden="true" tabindex="-1"></a>        <span>&#34;text&#34;</span>: texts,</span>
<span id="cb11-43"><a href="#cb11-43" aria-hidden="true" tabindex="-1"></a>        <span>&#34;predictions&#34;</span>: predictions,</span>
<span id="cb11-44"><a href="#cb11-44" aria-hidden="true" tabindex="-1"></a>        <span>&#34;start_date&#34;</span>: start_dates,</span>
<span id="cb11-45"><a href="#cb11-45" aria-hidden="true" tabindex="-1"></a>        <span>&#34;province&#34;</span>: provinces,</span>
<span id="cb11-46"><a href="#cb11-46" aria-hidden="true" tabindex="-1"></a>        <span>&#34;target_group&#34;</span>: target_groups,</span>
<span id="cb11-47"><a href="#cb11-47" aria-hidden="true" tabindex="-1"></a>        <span>&#34;event_type&#34;</span>: event_types,</span>
<span id="cb11-48"><a href="#cb11-48" aria-hidden="true" tabindex="-1"></a>        <span>&#34;min_killed&#34;</span>: min_killeds,</span>
<span id="cb11-49"><a href="#cb11-49" aria-hidden="true" tabindex="-1"></a>        <span>&#34;min_captured&#34;</span>: min_captureds,</span>
<span id="cb11-50"><a href="#cb11-50" aria-hidden="true" tabindex="-1"></a>        <span>&#34;killq&#34;</span>: killqs,</span>
<span id="cb11-51"><a href="#cb11-51" aria-hidden="true" tabindex="-1"></a>        <span>&#34;captureq&#34;</span>: captureqs,</span>
<span id="cb11-52"><a href="#cb11-52" aria-hidden="true" tabindex="-1"></a>        <span>&#34;killcaptureraid&#34;</span>: killcaptureraids,</span>
<span id="cb11-53"><a href="#cb11-53" aria-hidden="true" tabindex="-1"></a>        <span>&#34;airstrike&#34;</span>: airstrikes,</span>
<span id="cb11-54"><a href="#cb11-54" aria-hidden="true" tabindex="-1"></a>        <span>&#34;noshotsfired&#34;</span>: noshotsfireds,</span>
<span id="cb11-55"><a href="#cb11-55" aria-hidden="true" tabindex="-1"></a>        <span>&#34;min_leaders_killed&#34;</span>: min_leaders_killeds,</span>
<span id="cb11-56"><a href="#cb11-56" aria-hidden="true" tabindex="-1"></a>        <span>&#34;min_leaders_captured&#34;</span>: min_leaders_captureds,</span>
<span id="cb11-57"><a href="#cb11-57" aria-hidden="true" tabindex="-1"></a>    }</span>
<span id="cb11-58"><a href="#cb11-58" aria-hidden="true" tabindex="-1"></a>    dataset <span>=</span> Dataset.from_dict(dataset_dict)</span>
<span id="cb11-59"><a href="#cb11-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-60"><a href="#cb11-60" aria-hidden="true" tabindex="-1"></a>    <span>return</span> dataset</span>
<span id="cb11-61"><a href="#cb11-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-62"><a href="#cb11-62" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-63"><a href="#cb11-63" aria-hidden="true" tabindex="-1"></a><span>def</span> convert_and_push_dataset(</span>
<span id="cb11-64"><a href="#cb11-64" aria-hidden="true" tabindex="-1"></a>    events: List[IsafEvent], name: <span>str</span>, split_name: <span>str</span> <span>=</span> <span>&#34;train&#34;</span></span>
<span id="cb11-65"><a href="#cb11-65" aria-hidden="true" tabindex="-1"></a>):</span>
<span id="cb11-66"><a href="#cb11-66" aria-hidden="true" tabindex="-1"></a>    <span>&#34;&#34;&#34;Convert a list of Pydantic objects to a HF Dataset object, then push to</span></span>
<span id="cb11-67"><a href="#cb11-67" aria-hidden="true" tabindex="-1"></a><span>    the hub.&#34;&#34;&#34;</span></span>
<span id="cb11-68"><a href="#cb11-68" aria-hidden="true" tabindex="-1"></a>    hf_token <span>=</span> os.getenv(<span>&#34;HUGGINGFACE_API_KEY&#34;</span>)</span>
<span id="cb11-69"><a href="#cb11-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb11-70"><a href="#cb11-70" aria-hidden="true" tabindex="-1"></a>    dataset <span>=</span> convert_to_dataset(events)</span>
<span id="cb11-71"><a href="#cb11-71" aria-hidden="true" tabindex="-1"></a>    dataset.push_to_hub(</span>
<span id="cb11-72"><a href="#cb11-72" aria-hidden="true" tabindex="-1"></a>        <span>f&#34;strickvl/</span><span>{</span>name<span>}</span><span>&#34;</span>,</span>
<span id="cb11-73"><a href="#cb11-73" aria-hidden="true" tabindex="-1"></a>        token<span>=</span>hf_token,</span>
<span id="cb11-74"><a href="#cb11-74" aria-hidden="true" tabindex="-1"></a>        private<span>=</span><span>True</span>,</span>
<span id="cb11-75"><a href="#cb11-75" aria-hidden="true" tabindex="-1"></a>        create_pr<span>=</span><span>True</span>,</span>
<span id="cb11-76"><a href="#cb11-76" aria-hidden="true" tabindex="-1"></a>        split<span>=</span>split_name,</span>
<span id="cb11-77"><a href="#cb11-77" aria-hidden="true" tabindex="-1"></a>    )</span></code></pre></div>
</details>
</div>
<p>A more concise and abstract version of the <code>convert_to_dataset</code> function could be something like:</p>
<div id="cb12"><pre><code><span id="cb12-1"><a href="#cb12-1" aria-hidden="true" tabindex="-1"></a><span>def</span> convert_to_dataset(data: List[BaseModel]) <span>-&gt;</span> Dataset:</span>
<span id="cb12-2"><a href="#cb12-2" aria-hidden="true" tabindex="-1"></a>    dataset_dict <span>=</span> {}</span>
<span id="cb12-3"><a href="#cb12-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-4"><a href="#cb12-4" aria-hidden="true" tabindex="-1"></a>    <span>for</span> field_name, field_value <span>in</span> data[<span>0</span>].__fields__.items():</span>
<span id="cb12-5"><a href="#cb12-5" aria-hidden="true" tabindex="-1"></a>        field_type <span>=</span> field_value.outer_type_</span>
<span id="cb12-6"><a href="#cb12-6" aria-hidden="true" tabindex="-1"></a>        <span>if</span> field_type <span>in</span> [<span>str</span>, <span>int</span>, <span>float</span>, <span>bool</span>, date]:</span>
<span id="cb12-7"><a href="#cb12-7" aria-hidden="true" tabindex="-1"></a>            dataset_dict[field_name] <span>=</span> [<span>getattr</span>(item, field_name) <span>for</span> item <span>in</span> data]</span>
<span id="cb12-8"><a href="#cb12-8" aria-hidden="true" tabindex="-1"></a>        <span>elif</span> field_type <span>==</span> <span>set</span>:</span>
<span id="cb12-9"><a href="#cb12-9" aria-hidden="true" tabindex="-1"></a>            dataset_dict[field_name] <span>=</span> [<span>list</span>(<span>getattr</span>(item, field_name)) <span>for</span> item <span>in</span> data]</span>
<span id="cb12-10"><a href="#cb12-10" aria-hidden="true" tabindex="-1"></a>        <span>elif</span> <span>issubclass</span>(field_type, BaseModel):</span>
<span id="cb12-11"><a href="#cb12-11" aria-hidden="true" tabindex="-1"></a>            dataset_dict[field_name] <span>=</span> [<span>getattr</span>(item, field_name).<span>dict</span>() <span>for</span> item <span>in</span> data]</span>
<span id="cb12-12"><a href="#cb12-12" aria-hidden="true" tabindex="-1"></a>        <span>else</span>:</span>
<span id="cb12-13"><a href="#cb12-13" aria-hidden="true" tabindex="-1"></a>            dataset_dict[field_name] <span>=</span> [<span>getattr</span>(item, field_name) <span>for</span> item <span>in</span> data]</span>
<span id="cb12-14"><a href="#cb12-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb12-15"><a href="#cb12-15" aria-hidden="true" tabindex="-1"></a>    dataset <span>=</span> Dataset.from_dict(dataset_dict)</span>
<span id="cb12-16"><a href="#cb12-16" aria-hidden="true" tabindex="-1"></a>    <span>return</span> dataset</span></code></pre></div>
<p>But for now let’s just push our data to the Hub.</p>
<div>
<div id="cb13"><pre><code><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>convert_and_push_dataset(events, <span>&#34;isafpressreleases_with_preds&#34;</span>, split_name<span>=</span><span>&#34;test&#34;</span>)</span></code></pre></div>
</div>
</section>
<section id="adding-predictions-from-our-finetuned-models">

<p>We’ve added some baseline OpenAI models, so let’s now add <a href="https://mlops.systems/posts/2024-06-15-isafpr-first-finetune.html">the models</a> <a href="https://mlops.systems/posts/2024-06-17-one-click-finetuning.html">we previously finetuned</a>. This includes a mix of local models as well as models hosted by some <a href="https://mlops.systems/posts/2024-06-17-one-click-finetuning.html">one-click finetuning providers</a>.</p>
<p>I’ll hide a bunch of the code with folding arrows so you can see it if you’re interested but there isn’t actually much of interest or new there.</p>
<section id="reloading-the-predictions-dataset">
<h2 data-anchor-id="reloading-the-predictions-dataset">Reloading the predictions dataset</h2>
<p>Let’s start by loading our dataset and then we can get into adding some local model predictions:</p>
<div data-execution_count="19">
<div id="cb14"><pre><code><span id="cb14-1"><a href="#cb14-1" aria-hidden="true" tabindex="-1"></a><span>from</span> datasets <span>import</span> load_dataset</span>
<span id="cb14-2"><a href="#cb14-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb14-3"><a href="#cb14-3" aria-hidden="true" tabindex="-1"></a>preds_test_data <span>=</span> load_dataset(<span>&#34;strickvl/isafpressreleases_with_preds&#34;</span>)[</span>
<span id="cb14-4"><a href="#cb14-4" aria-hidden="true" tabindex="-1"></a>    <span>&#34;test&#34;</span></span>
<span id="cb14-5"><a href="#cb14-5" aria-hidden="true" tabindex="-1"></a>].to_list()</span></code></pre></div>
</div>
<p>We trained some local models, so let’s add those predictions to the dataset.</p>
</section>
<section id="finetuned-tinyllama-predictions">
<h2 data-anchor-id="finetuned-tinyllama-predictions">Finetuned TinyLlama predictions</h2>
<div data-execution_count="21">
<details>
<summary>Code</summary>
<div id="cb15"><pre><code><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a><span>from</span> typing <span>import</span> Union</span>
<span id="cb15-2"><a href="#cb15-2" aria-hidden="true" tabindex="-1"></a><span>import</span> torch</span>
<span id="cb15-3"><a href="#cb15-3" aria-hidden="true" tabindex="-1"></a><span>from</span> peft <span>import</span> AutoPeftModelForCausalLM</span>
<span id="cb15-4"><a href="#cb15-4" aria-hidden="true" tabindex="-1"></a><span>from</span> transformers <span>import</span> AutoTokenizer</span>
<span id="cb15-5"><a href="#cb15-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-6"><a href="#cb15-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-7"><a href="#cb15-7" aria-hidden="true" tabindex="-1"></a><span>def</span> prompt(press_release: <span>str</span>) <span>-&gt;</span> <span>str</span>:</span>
<span id="cb15-8"><a href="#cb15-8" aria-hidden="true" tabindex="-1"></a>    <span>return</span> <span>f&#34;&#34;&#34;You are an expert at identifying events in a press release. You are precise and always make sure you are correct, drawing inference from the text of the press release. event_types = [&#39;airstrike&#39;, &#39;detention&#39;, &#39;captureandkill&#39;, &#39;insurgentskilled&#39;, &#39;exchangeoffire&#39;, &#39;civiliancasualty&#39;], provinces = [&#39;badakhshan&#39;, &#39;badghis&#39;, &#39;baghlan&#39;, &#39;balkh&#39;, &#39;bamyan&#39;, &#39;day_kundi&#39;, &#39;farah&#39;, &#39;faryab&#39;, &#39;ghazni&#39;, &#39;ghor&#39;, &#39;helmand&#39;, &#39;herat&#39;, &#39;jowzjan&#39;, &#39;kabul&#39;, &#39;kandahar&#39;, &#39;kapisa&#39;, &#39;khost&#39;, &#39;kunar&#39;, &#39;kunduz&#39;, &#39;laghman&#39;, &#39;logar&#39;, &#39;nangarhar&#39;, &#39;nimroz&#39;, &#39;nuristan&#39;, &#39;paktya&#39;, &#39;paktika&#39;, &#39;panjshir&#39;, &#39;parwan&#39;, &#39;samangan&#39;, &#39;sar_e_pul&#39;, &#39;takhar&#39;, &#39;uruzgan&#39;, &#39;wardak&#39;, &#39;zabul&#39;], target_groups = [&#39;taliban&#39;, &#39;haqqani&#39;, &#39;criminals&#39;, &#39;aq&#39;, &#39;hig&#39;, &#39;let&#39;, &#39;imu&#39;, &#39;judq&#39;, &#39;iju&#39;, &#39;hik&#39;, &#39;ttp&#39;, &#39;other&#39;]</span></span>
<span id="cb15-9"><a href="#cb15-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-10"><a href="#cb15-10" aria-hidden="true" tabindex="-1"></a><span>### Instruction:</span></span>
<span id="cb15-11"><a href="#cb15-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-12"><a href="#cb15-12" aria-hidden="true" tabindex="-1"></a><span>PRESS RELEASE TEXT: &#34;</span><span>{</span>press_release<span>}</span><span>&#34;</span></span>
<span id="cb15-13"><a href="#cb15-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-14"><a href="#cb15-14" aria-hidden="true" tabindex="-1"></a><span>### Response:</span></span>
<span id="cb15-15"><a href="#cb15-15" aria-hidden="true" tabindex="-1"></a><span>&#34;&#34;&#34;</span></span>
<span id="cb15-16"><a href="#cb15-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-17"><a href="#cb15-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-18"><a href="#cb15-18" aria-hidden="true" tabindex="-1"></a><span>def</span> prompt_tok(</span>
<span id="cb15-19"><a href="#cb15-19" aria-hidden="true" tabindex="-1"></a>    model: AutoPeftModelForCausalLM,</span>
<span id="cb15-20"><a href="#cb15-20" aria-hidden="true" tabindex="-1"></a>    tokenizer: AutoTokenizer,</span>
<span id="cb15-21"><a href="#cb15-21" aria-hidden="true" tabindex="-1"></a>    press_release: <span>str</span>,</span>
<span id="cb15-22"><a href="#cb15-22" aria-hidden="true" tabindex="-1"></a>    return_ids: <span>bool</span> <span>=</span> <span>False</span>,</span>
<span id="cb15-23"><a href="#cb15-23" aria-hidden="true" tabindex="-1"></a>) <span>-&gt;</span> Union[<span>str</span>, torch.Tensor]:</span>
<span id="cb15-24"><a href="#cb15-24" aria-hidden="true" tabindex="-1"></a>    _p <span>=</span> prompt(press_release)</span>
<span id="cb15-25"><a href="#cb15-25" aria-hidden="true" tabindex="-1"></a>    input_ids <span>=</span> tokenizer(_p, return_tensors<span>=</span><span>&#34;pt&#34;</span>, truncation<span>=</span><span>True</span>).input_ids.cuda()</span>
<span id="cb15-26"><a href="#cb15-26" aria-hidden="true" tabindex="-1"></a>    out_ids <span>=</span> model.generate(input_ids<span>=</span>input_ids, max_new_tokens<span>=</span><span>5000</span>, do_sample<span>=</span><span>False</span>)</span>
<span id="cb15-27"><a href="#cb15-27" aria-hidden="true" tabindex="-1"></a>    ids <span>=</span> out_ids.detach().cpu().numpy()</span>
<span id="cb15-28"><a href="#cb15-28" aria-hidden="true" tabindex="-1"></a>    <span>if</span> return_ids:</span>
<span id="cb15-29"><a href="#cb15-29" aria-hidden="true" tabindex="-1"></a>        <span>return</span> out_ids</span>
<span id="cb15-30"><a href="#cb15-30" aria-hidden="true" tabindex="-1"></a>    <span>return</span> tokenizer.batch_decode(ids, skip_special_tokens<span>=</span><span>True</span>)[<span>0</span>][<span>len</span>(_p) :]</span>
<span id="cb15-31"><a href="#cb15-31" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-32"><a href="#cb15-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-33"><a href="#cb15-33" aria-hidden="true" tabindex="-1"></a>tinyllama_sharegpt_model_id <span>=</span> <span>&#34;strickvl/isafpr-tiny-llama-lora-templatefree&#34;</span></span>
<span id="cb15-34"><a href="#cb15-34" aria-hidden="true" tabindex="-1"></a>model <span>=</span> AutoPeftModelForCausalLM.from_pretrained(tinyllama_sharegpt_model_id).cuda()</span>
<span id="cb15-35"><a href="#cb15-35" aria-hidden="true" tabindex="-1"></a>tokenizer <span>=</span> AutoTokenizer.from_pretrained(tinyllama_sharegpt_model_id)</span>
<span id="cb15-36"><a href="#cb15-36" aria-hidden="true" tabindex="-1"></a>tokenizer.pad_token <span>=</span> tokenizer.eos_token</span>
<span id="cb15-37"><a href="#cb15-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb15-38"><a href="#cb15-38" aria-hidden="true" tabindex="-1"></a><span>for</span> row <span>in</span> preds_test_data:</span>
<span id="cb15-39"><a href="#cb15-39" aria-hidden="true" tabindex="-1"></a>    out <span>=</span> prompt_tok(model, tokenizer, row[<span>&#34;text&#34;</span>])</span>
<span id="cb15-40"><a href="#cb15-40" aria-hidden="true" tabindex="-1"></a>    row[<span>&#34;predictions&#34;</span>][<span>&#34;tinyllama-templatefree&#34;</span>] <span>=</span> out</span></code></pre></div>
</details>
</div>
<p>Now if we inspect we’ll see that the new model predictions have been saved into the dataset:</p>
<div>
<div id="cb16"><pre><code><span id="cb16-1"><a href="#cb16-1" aria-hidden="true" tabindex="-1"></a><span>from</span> rich <span>import</span> <span>print</span></span>
<span id="cb16-2"><a href="#cb16-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb16-3"><a href="#cb16-3" aria-hidden="true" tabindex="-1"></a><span>print</span>(preds_test_data[<span>0</span>])</span></code></pre></div>
<div>
<pre><span>{</span>
    <span>&#39;name&#39;</span>: <span>&#39;5&#39;</span>,
    <span>&#39;text&#39;</span>: <span>&#39;2013-01-S-025\n\nKABUL, Afghanistan (Jan. 25, 2013)\nDuring a security operation in Andar district, </span>
<span>Ghazni province, yesterday, an Afghan and coalition force killed the Taliban leader, Alaudin. Alaudin oversaw a </span>
<span>group of insurgents responsible for conducting remote-controlled improvised explosive device and small-arms fire </span>
<span>attacks against Afghan and coalition forces. Prior to his death, Alaudin was planning attacks against Afghan </span>
<span>National Police in Ghazni province.&#39;</span>,
    <span>&#39;predictions&#39;</span>: <span>{</span>
        <span>&#39;gpt-3.5-turbo&#39;</span>: <span>&#39;{\n    &#34;name&#34;: &#34;Taliban leader Alaudin killed in Ghazni province&#34;,\n    &#34;start_date&#34;: </span>
<span>&#34;2013-01-24&#34;,\n    &#34;event_type&#34;: [&#34;captureandkill&#34;],\n    &#34;province&#34;: [&#34;ghazni&#34;],\n    &#34;target_group&#34;: </span>
<span>[&#34;taliban&#34;],\n    &#34;min_killed&#34;: 1,\n    &#34;min_captured&#34;: 0,\n    &#34;killq&#34;: true,\n    &#34;captureq&#34;: false,\n    </span>
<span>&#34;killcaptureraid&#34;: false,\n    &#34;airstrike&#34;: false,\n    &#34;noshotsfired&#34;: false,\n    &#34;min_leaders_killed&#34;: 1,\n    </span>
<span>&#34;min_leaders_captured&#34;: 0\n}&#39;</span>,
        <span>&#39;gpt-4-turbo&#39;</span>: <span>&#39;{\n    &#34;name&#34;: &#34;Taliban leader Alaudin killed in Ghazni&#34;,\n    &#34;start_date&#34;: </span>
<span>&#34;2013-01-24&#34;,\n    &#34;event_type&#34;: [&#34;captureandkill&#34;],\n    &#34;province&#34;: [&#34;ghazni&#34;],\n    &#34;target_group&#34;: </span>
<span>[&#34;taliban&#34;],\n    &#34;min_killed&#34;: 1,\n    &#34;min_captured&#34;: 0,\n    &#34;killq&#34;: true,\n    &#34;captureq&#34;: false,\n    </span>
<span>&#34;killcaptureraid&#34;: true,\n    &#34;airstrike&#34;: false,\n    &#34;noshotsfired&#34;: false,\n    &#34;min_leaders_killed&#34;: 1,\n    </span>
<span>&#34;min_leaders_captured&#34;: 0\n}&#39;</span>,
        <span>&#39;gpt-4o&#39;</span>: <span>&#39;{\n  &#34;name&#34;: &#34;Taliban leader Alaudin killed in Ghazni&#34;,\n  &#34;start_date&#34;: &#34;2013-01-24&#34;,\n  </span>
<span>&#34;event_type&#34;: [&#34;insurgentskilled&#34;, &#34;captureandkill&#34;],\n  &#34;province&#34;: [&#34;ghazni&#34;],\n  &#34;target_group&#34;: [&#34;taliban&#34;],\n </span>
<span>&#34;min_killed&#34;: 1,\n  &#34;min_captured&#34;: 0,\n  &#34;killq&#34;: true,\n  &#34;captureq&#34;: false,\n  &#34;killcaptureraid&#34;: true,\n  </span>
<span>&#34;airstrike&#34;: false,\n  &#34;noshotsfired&#34;: false,\n  &#34;min_leaders_killed&#34;: 1,\n  &#34;min_leaders_captured&#34;: 0\n}&#39;</span>,
        <span>&#39;tinyllama-templatefree&#39;</span>: <span>&#39;\n{&#34;name&#34;:&#34;Taliban leader killed in </span>
<span>Ghazni&#34;,&#34;start_date&#34;:&#34;2013-01-24&#34;,&#34;event_type&#34;:[&#34;insurgentskilled&#34;],&#34;province&#34;:[&#34;ghazni&#34;],&#34;target_group&#34;:[&#34;taliban&#34;</span>
<span>],&#34;min_killed&#34;:1,&#34;min_captured&#34;:0,&#34;killq&#34;:true,&#34;captureq&#34;:false,&#34;killcaptureraid&#34;:false,&#34;airstrike&#34;:false,&#34;noshotsf</span>
<span>ired&#34;:false,&#34;min_leaders_killed&#34;:1,&#34;min_leaders_captured&#34;:0}&#39;</span>,
        <span>&#39;tinyllama-sharegpt&#39;</span>: 
<span>&#39;{&#34;name&#34;:&#34;2&#34;,&#34;start_date&#34;:&#34;2013-01-24&#34;,&#34;event_type&#34;:[&#34;airstrike&#34;],&#34;province&#34;:[&#34;ghazni&#34;],&#34;target_group&#34;:[&#34;taliban&#34;],</span>
<span>&#34;min_killed&#34;:1,&#34;min_captured&#34;:0,&#34;killq&#34;:true,&#34;captureq&#34;:false,&#34;killcaptureraid&#34;:false,&#34;airstrike&#34;:true,&#34;noshotsfire</span>
<span>d&#34;:false,&#34;min_leaders_killed&#34;:1,&#34;min_leaders_captured&#34;:0}&#39;</span>
    <span>}</span>,
    <span>&#39;start_date&#39;</span>: <span>datetime.date</span><span>(</span><span>2013</span>, <span>1</span>, <span>24</span><span>)</span>,
    <span>&#39;province&#39;</span>: <span>[</span><span>&#39;ghazni&#39;</span><span>]</span>,
    <span>&#39;target_group&#39;</span>: <span>[</span><span>&#39;taliban&#39;</span><span>]</span>,
    <span>&#39;event_type&#39;</span>: <span>[</span><span>&#39;insurgentskilled&#39;</span><span>]</span>,
    <span>&#39;min_killed&#39;</span>: <span>1</span>,
    <span>&#39;min_captured&#39;</span>: <span>0</span>,
    <span>&#39;killq&#39;</span>: <span>True</span>,
    <span>&#39;captureq&#39;</span>: <span>False</span>,
    <span>&#39;killcaptureraid&#39;</span>: <span>False</span>,
    <span>&#39;airstrike&#39;</span>: <span>False</span>,
    <span>&#39;noshotsfired&#39;</span>: <span>False</span>,
    <span>&#39;min_leaders_killed&#39;</span>: <span>1</span>,
    <span>&#39;min_leaders_captured&#39;</span>: <span>0</span>
<span>}</span>
</pre>
</div>
</div>
</section>
<section id="finetuned-mistral-predictions">
<h2 data-anchor-id="finetuned-mistral-predictions">Finetuned Mistral predictions</h2>
<p>As <a href="https://mlops.systems/posts/2024-06-15-isafpr-first-finetune.html#finetuning-our-model">I noted previously</a>, it was impossible to get the finetuned Mistral model working locally so I did the inference over on Modal where I could spin up a juicy A100 to make the predictions. You’ll see below that the model didn’t perform very well, failing almost all of the evaluations. This is the <code>mistral-lora-templatefree</code> model you’ll see in the charts.</p>
</section>
<section id="finetuned-openai-predictions">
<h2 data-anchor-id="finetuned-openai-predictions">Finetuned OpenAI predictions</h2>
<p>I used OpenAI’s one-click finetuning service <a href="https://mlops.systems/posts/2024-06-17-one-click-finetuning.html#openai">to finetune the <code>gpt-3.5-turbo-1106</code> model</a>. I iterated over my dataset to generate predictions using that finetuned model using the OpenAI SDK.</p>
<div data-execution_count="4">
<details>
<summary>Code</summary>
<div id="cb17"><pre><code><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span>from</span> openai <span>import</span> OpenAI</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a><span>import</span> os</span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a><span>from</span> datasets <span>import</span> load_dataset</span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>preds_test_data <span>=</span> load_dataset(<span>&#34;strickvl/isafpressreleases_with_preds_2&#34;</span>)[</span>
<span id="cb17-6"><a href="#cb17-6" aria-hidden="true" tabindex="-1"></a>    <span>&#34;train&#34;</span></span>
<span id="cb17-7"><a href="#cb17-7" aria-hidden="true" tabindex="-1"></a>].to_list()</span>
<span id="cb17-8"><a href="#cb17-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-9"><a href="#cb17-9" aria-hidden="true" tabindex="-1"></a>client <span>=</span> OpenAI(api_key<span>=</span>os.getenv(<span>&#34;OPENAI_API_KEY&#34;</span>))</span>
<span id="cb17-10"><a href="#cb17-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-11"><a href="#cb17-11" aria-hidden="true" tabindex="-1"></a><span>for</span> row <span>in</span> preds_test_data:</span>
<span id="cb17-12"><a href="#cb17-12" aria-hidden="true" tabindex="-1"></a>    response <span>=</span> client.chat.completions.create(</span>
<span id="cb17-13"><a href="#cb17-13" aria-hidden="true" tabindex="-1"></a>        model<span>=</span><span>&#34;ft:gpt-3.5-turbo-1106:SOME_MODEL_ID_GOES_HERE&#34;</span>,</span>
<span id="cb17-14"><a href="#cb17-14" aria-hidden="true" tabindex="-1"></a>        messages<span>=</span>[</span>
<span id="cb17-15"><a href="#cb17-15" aria-hidden="true" tabindex="-1"></a>            {</span>
<span id="cb17-16"><a href="#cb17-16" aria-hidden="true" tabindex="-1"></a>                <span>&#34;role&#34;</span>: <span>&#34;system&#34;</span>,</span>
<span id="cb17-17"><a href="#cb17-17" aria-hidden="true" tabindex="-1"></a>                <span>&#34;content&#34;</span>: <span>&#34;You are an expert at identifying events in a press release. You are precise and always make sure you are correct, drawing inference from the text of the press release. event_types = [&#39;airstrike&#39;, &#39;detention&#39;, &#39;captureandkill&#39;, &#39;insurgentskilled&#39;, &#39;exchangeoffire&#39;, &#39;civiliancasualty&#39;], provinces = [&#39;badakhshan&#39;, &#39;badghis&#39;, &#39;baghlan&#39;, &#39;balkh&#39;, &#39;bamyan&#39;, &#39;day_kundi&#39;, &#39;farah&#39;, &#39;faryab&#39;, &#39;ghazni&#39;, &#39;ghor&#39;, &#39;helmand&#39;, &#39;herat&#39;, &#39;jowzjan&#39;, &#39;kabul&#39;, &#39;kandahar&#39;, &#39;kapisa&#39;, &#39;khost&#39;, &#39;kunar&#39;, &#39;kunduz&#39;, &#39;laghman&#39;, &#39;logar&#39;, &#39;nangarhar&#39;, &#39;nimroz&#39;, &#39;nuristan&#39;, &#39;paktya&#39;, &#39;paktika&#39;, &#39;panjshir&#39;, &#39;parwan&#39;, &#39;samangan&#39;, &#39;sar_e_pul&#39;, &#39;takhar&#39;, &#39;uruzgan&#39;, &#39;wardak&#39;, &#39;zabul&#39;], target_groups = [&#39;taliban&#39;, &#39;haqqani&#39;, &#39;criminals&#39;, &#39;aq&#39;, &#39;hig&#39;, &#39;let&#39;, &#39;imu&#39;, &#39;judq&#39;, &#39;iju&#39;, &#39;hik&#39;, &#39;ttp&#39;, &#39;other&#39;].&#34;</span>,</span>
<span id="cb17-18"><a href="#cb17-18" aria-hidden="true" tabindex="-1"></a>            },</span>
<span id="cb17-19"><a href="#cb17-19" aria-hidden="true" tabindex="-1"></a>            {<span>&#34;role&#34;</span>: <span>&#34;user&#34;</span>, <span>&#34;content&#34;</span>: row[<span>&#34;text&#34;</span>]},</span>
<span id="cb17-20"><a href="#cb17-20" aria-hidden="true" tabindex="-1"></a>        ],</span>
<span id="cb17-21"><a href="#cb17-21" aria-hidden="true" tabindex="-1"></a>        temperature<span>=</span><span>0</span>,</span>
<span id="cb17-22"><a href="#cb17-22" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb17-23"><a href="#cb17-23" aria-hidden="true" tabindex="-1"></a>    row[<span>&#34;predictions&#34;</span>][<span>&#34;finetuned-openai-gpt-3.5-turbo-1106&#34;</span>] <span>=</span> response.choices[</span>
<span id="cb17-24"><a href="#cb17-24" aria-hidden="true" tabindex="-1"></a>        <span>0</span></span>
<span id="cb17-25"><a href="#cb17-25" aria-hidden="true" tabindex="-1"></a>    ].message.content</span></code></pre></div>
</details>
</div>
</section>
<section id="finetuned-mistral-models-via-openpipe">
<h2 data-anchor-id="finetuned-mistral-models-via-openpipe">Finetuned Mistral models (via OpenPipe)</h2>
<p>I finetuned Mistral 7B and Mistral 8x7B models using OpenPipe so as to have something reasonable to compare the other models to. As always, OpenPipe makes it pretty easy to spin up a finetuning job and get predictions.</p>
<div>
<details>
<summary>Code</summary>
<div id="cb18"><pre><code><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a><span>from</span> openpipe <span>import</span> OpenAI</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a><span>import</span> os</span>
<span id="cb18-3"><a href="#cb18-3" aria-hidden="true" tabindex="-1"></a><span>from</span> datasets <span>import</span> load_dataset</span>
<span id="cb18-4"><a href="#cb18-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-5"><a href="#cb18-5" aria-hidden="true" tabindex="-1"></a>preds_test_data <span>=</span> load_dataset(<span>&#34;strickvl/isafpressreleases_test_predictions_old&#34;</span>)[</span>
<span id="cb18-6"><a href="#cb18-6" aria-hidden="true" tabindex="-1"></a>    <span>&#34;train&#34;</span></span>
<span id="cb18-7"><a href="#cb18-7" aria-hidden="true" tabindex="-1"></a>].to_list()</span>
<span id="cb18-8"><a href="#cb18-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-9"><a href="#cb18-9" aria-hidden="true" tabindex="-1"></a>client <span>=</span> OpenAI(openpipe<span>=</span>{<span>&#34;api_key&#34;</span>: os.getenv(<span>&#34;OPENPIPE_API_KEY&#34;</span>)})</span>
<span id="cb18-10"><a href="#cb18-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-11"><a href="#cb18-11" aria-hidden="true" tabindex="-1"></a><span>for</span> i, row <span>in</span> <span>enumerate</span>(preds_test_data, <span>1</span>):</span>
<span id="cb18-12"><a href="#cb18-12" aria-hidden="true" tabindex="-1"></a>    completion_7b <span>=</span> client.chat.completions.create(</span>
<span id="cb18-13"><a href="#cb18-13" aria-hidden="true" tabindex="-1"></a>        model<span>=</span><span>&#34;openpipe:twelve-pumas-invent&#34;</span>,</span>
<span id="cb18-14"><a href="#cb18-14" aria-hidden="true" tabindex="-1"></a>        messages<span>=</span>[</span>
<span id="cb18-15"><a href="#cb18-15" aria-hidden="true" tabindex="-1"></a>            {</span>
<span id="cb18-16"><a href="#cb18-16" aria-hidden="true" tabindex="-1"></a>                <span>&#34;role&#34;</span>: <span>&#34;system&#34;</span>,</span>
<span id="cb18-17"><a href="#cb18-17" aria-hidden="true" tabindex="-1"></a>                <span>&#34;content&#34;</span>: <span>&#34;You are an expert at identifying events in a press release. You are precise and always make sure you are correct, drawing inference from the text of the press release. event_types = [&#39;airstrike&#39;, &#39;detention&#39;, &#39;captureandkill&#39;, &#39;insurgentskilled&#39;, &#39;exchangeoffire&#39;, &#39;civiliancasualty&#39;], provinces = [&#39;badakhshan&#39;, &#39;badghis&#39;, &#39;baghlan&#39;, &#39;balkh&#39;, &#39;bamyan&#39;, &#39;day_kundi&#39;, &#39;farah&#39;, &#39;faryab&#39;, &#39;ghazni&#39;, &#39;ghor&#39;, &#39;helmand&#39;, &#39;herat&#39;, &#39;jowzjan&#39;, &#39;kabul&#39;, &#39;kandahar&#39;, &#39;kapisa&#39;, &#39;khost&#39;, &#39;kunar&#39;, &#39;kunduz&#39;, &#39;laghman&#39;, &#39;logar&#39;, &#39;nangarhar&#39;, &#39;nimroz&#39;, &#39;nuristan&#39;, &#39;paktya&#39;, &#39;paktika&#39;, &#39;panjshir&#39;, &#39;parwan&#39;, &#39;samangan&#39;, &#39;sar_e_pul&#39;, &#39;takhar&#39;, &#39;uruzgan&#39;, &#39;wardak&#39;, &#39;zabul&#39;], target_groups = [&#39;taliban&#39;, &#39;haqqani&#39;, &#39;criminals&#39;, &#39;aq&#39;, &#39;hig&#39;, &#39;let&#39;, &#39;imu&#39;, &#39;judq&#39;, &#39;iju&#39;, &#39;hik&#39;, &#39;ttp&#39;, &#39;other&#39;].&#34;</span>,</span>
<span id="cb18-18"><a href="#cb18-18" aria-hidden="true" tabindex="-1"></a>            },</span>
<span id="cb18-19"><a href="#cb18-19" aria-hidden="true" tabindex="-1"></a>            {<span>&#34;role&#34;</span>: <span>&#34;user&#34;</span>, <span>&#34;content&#34;</span>: row[<span>&#34;text&#34;</span>]},</span>
<span id="cb18-20"><a href="#cb18-20" aria-hidden="true" tabindex="-1"></a>        ],</span>
<span id="cb18-21"><a href="#cb18-21" aria-hidden="true" tabindex="-1"></a>        temperature<span>=</span><span>0</span>,</span>
<span id="cb18-22"><a href="#cb18-22" aria-hidden="true" tabindex="-1"></a>        openpipe<span>=</span>{<span>&#34;tags&#34;</span>: {<span>&#34;prompt_id&#34;</span>: <span>&#34;counting&#34;</span>, <span>&#34;any_key&#34;</span>: <span>&#34;any_value&#34;</span>}},</span>
<span id="cb18-23"><a href="#cb18-23" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb18-24"><a href="#cb18-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb18-25"><a href="#cb18-25" aria-hidden="true" tabindex="-1"></a>    row[<span>&#34;predictions&#34;</span>][<span>&#34;finetuned-mistral-7b-optimised-openpipe&#34;</span>] <span>=</span> completion_7b.choices[<span>0</span>].message.content</span>
<span id="cb18-26"><a href="#cb18-26" aria-hidden="true" tabindex="-1"></a>    </span>
<span id="cb18-27"><a href="#cb18-27" aria-hidden="true" tabindex="-1"></a>    <span>if</span> i <span>%</span> <span>100</span> <span>==</span> <span>0</span>:</span>
<span id="cb18-28"><a href="#cb18-28" aria-hidden="true" tabindex="-1"></a>        <span>print</span>(<span>f&#34;</span><span>{</span>i<span>}</span><span>/724 rows complete&#34;</span>)</span></code></pre></div>
</details>
</div>
</section>
<section id="finetuned-solar-llm-via-predibase">
<h2 data-anchor-id="finetuned-solar-llm-via-predibase">Finetuned Solar LLM (via Predibase)</h2>
<p>Predibase announced <a href="https://predibase.com/blog/solar-llm-on-predibase-the-best-llm-for-fine-tuning">a new best-in-class model for finetuning</a>, the Solar LLM from Upstage, a week or so ago so I thought I’d try it out. The advantage of this model is that it’s trained to be good at the kinds of tasks people commonly finetune models for, like structured data extraction. As you’ll see below, it did pretty well! <a href="https://huggingface.co/upstage/SOLAR-10.7B-v1.0">The base model is this one</a>, I think, on the Hugging Face Hub so it’s available for you all to use as well.</p>
<div>
<details>
<summary>Code</summary>
<div id="cb19"><pre><code><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span>from</span> predibase <span>import</span> Predibase</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a>pb <span>=</span> Predibase(api_token<span>=</span><span>&#34;MY_API_TOKEN_GOES_HERE&#34;</span>)</span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>lorax_client <span>=</span> pb.deployments.client(<span>&#34;solar-1-mini-chat-240612&#34;</span>)</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>preds_test_data <span>=</span> load_dataset(<span>&#34;strickvl/isafpressreleases_test_predictions&#34;</span>)[</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>    <span>&#34;train&#34;</span></span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>].to_list()</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a><span>for</span> i, row <span>in</span> <span>enumerate</span>(preds_test_data, <span>1</span>):</span>
<span id="cb19-12"><a href="#cb19-12" aria-hidden="true" tabindex="-1"></a>    prompt <span>=</span> <span>f&#34;&#34;&#34;You are an expert at identifying events in a press release. You are precise and always make sure you are correct, drawing inference from the text of the press release. event_types = [&#39;airstrike&#39;, &#39;detention&#39;, &#39;captureandkill&#39;, &#39;insurgentskilled&#39;, &#39;exchangeoffire&#39;, &#39;civiliancasualty&#39;], provinces = [&#39;badakhshan&#39;, &#39;badghis&#39;, &#39;baghlan&#39;, &#39;balkh&#39;, &#39;bamyan&#39;, &#39;day_kundi&#39;, &#39;farah&#39;, &#39;faryab&#39;, &#39;ghazni&#39;, &#39;ghor&#39;, &#39;helmand&#39;, &#39;herat&#39;, &#39;jowzjan&#39;, &#39;kabul&#39;, &#39;kandahar&#39;, &#39;kapisa&#39;, &#39;khost&#39;, &#39;kunar&#39;, &#39;kunduz&#39;, &#39;laghman&#39;, &#39;logar&#39;, &#39;nangarhar&#39;, &#39;nimroz&#39;, &#39;nuristan&#39;, &#39;paktya&#39;, &#39;paktika&#39;, &#39;panjshir&#39;, &#39;parwan&#39;, &#39;samangan&#39;, &#39;sar_e_pul&#39;, &#39;takhar&#39;, &#39;uruzgan&#39;, &#39;wardak&#39;, &#39;zabul&#39;], target_groups = [&#39;taliban&#39;, &#39;haqqani&#39;, &#39;criminals&#39;, &#39;aq&#39;, &#39;hig&#39;, &#39;let&#39;, &#39;imu&#39;, &#39;judq&#39;, &#39;iju&#39;, &#39;hik&#39;, &#39;ttp&#39;, &#39;other&#39;]</span><span>\n\n</span><span>### Instruction:</span><span>\n\n</span><span>PRESS RELEASE TEXT: &#34;</span><span>{</span>row[<span>&#39;text&#39;</span>]<span>}</span><span>&#34;</span><span>\n\n</span><span>### Response:&#34;&#34;&#34;</span></span>
<span id="cb19-13"><a href="#cb19-13" aria-hidden="true" tabindex="-1"></a>    response <span>=</span> lorax_client.generate(prompt, adapter_id<span>=</span><span>&#34;isafpr/2&#34;</span>, max_new_tokens<span>=</span><span>300</span>).generated_text</span>
<span id="cb19-14"><a href="#cb19-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-15"><a href="#cb19-15" aria-hidden="true" tabindex="-1"></a>    row[<span>&#34;predictions&#34;</span>][<span>&#34;ft-solar-1-mini-chat-240612-predibase&#34;</span>] <span>=</span> response</span>
<span id="cb19-16"><a href="#cb19-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-17"><a href="#cb19-17" aria-hidden="true" tabindex="-1"></a>    <span>if</span> i <span>%</span> <span>100</span> <span>==</span> <span>0</span>:</span>
<span id="cb19-18"><a href="#cb19-18" aria-hidden="true" tabindex="-1"></a>        <span>print</span>(<span>f&#34;</span><span>{</span>i<span>}</span><span>/724 rows complete&#34;</span>)</span></code></pre></div>
</details>
</div>
</section>
<section id="finetuned-llama3-predictions-via-openpipe">
<h2 data-anchor-id="finetuned-llama3-predictions-via-openpipe">Finetuned Llama3 predictions (via OpenPipe)</h2>
<p>My locally finetuned Llama3 model hadn’t really worked well, but on OpenPipe the outputs seemed to look ok, so I used these predictions for the final evaluation.</p>
<div data-execution_count="7">
<details>
<summary>Code</summary>
<div id="cb20"><pre><code><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span>from</span> openpipe <span>import</span> OpenAI</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span>import</span> os</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span>from</span> datasets <span>import</span> load_dataset</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a>preds_test_data <span>=</span> load_dataset(<span>&#34;strickvl/isafpressreleases_with_preds_3&#34;</span>)[</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a>    <span>&#34;train&#34;</span></span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a>].to_list()</span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>client <span>=</span> OpenAI(openpipe<span>=</span>{<span>&#34;api_key&#34;</span>: os.getenv(<span>&#34;OPENPIPE_API_KEY&#34;</span>)})</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a><span>for</span> row <span>in</span> preds_test_data:</span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a>    completion <span>=</span> client.chat.completions.create(</span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>        model<span>=</span><span>&#34;openpipe:fine-steaks-taste&#34;</span>,</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>        messages<span>=</span>[</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a>            {</span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a>                <span>&#34;role&#34;</span>: <span>&#34;system&#34;</span>,</span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>                <span>&#34;content&#34;</span>: <span>&#34;You are an expert at identifying events in a press release. You are precise and always make sure you are correct, drawing inference from the text of the press release. event_types = [&#39;airstrike&#39;, &#39;detention&#39;, &#39;captureandkill&#39;, &#39;insurgentskilled&#39;, &#39;exchangeoffire&#39;, &#39;civiliancasualty&#39;], provinces = [&#39;badakhshan&#39;, &#39;badghis&#39;, &#39;baghlan&#39;, &#39;balkh&#39;, &#39;bamyan&#39;, &#39;day_kundi&#39;, &#39;farah&#39;, &#39;faryab&#39;, &#39;ghazni&#39;, &#39;ghor&#39;, &#39;helmand&#39;, &#39;herat&#39;, &#39;jowzjan&#39;, &#39;kabul&#39;, &#39;kandahar&#39;, &#39;kapisa&#39;, &#39;khost&#39;, &#39;kunar&#39;, &#39;kunduz&#39;, &#39;laghman&#39;, &#39;logar&#39;, &#39;nangarhar&#39;, &#39;nimroz&#39;, &#39;nuristan&#39;, &#39;paktya&#39;, &#39;paktika&#39;, &#39;panjshir&#39;, &#39;parwan&#39;, &#39;samangan&#39;, &#39;sar_e_pul&#39;, &#39;takhar&#39;, &#39;uruzgan&#39;, &#39;wardak&#39;, &#39;zabul&#39;], target_groups = [&#39;taliban&#39;, &#39;haqqani&#39;, &#39;criminals&#39;, &#39;aq&#39;, &#39;hig&#39;, &#39;let&#39;, &#39;imu&#39;, &#39;judq&#39;, &#39;iju&#39;, &#39;hik&#39;, &#39;ttp&#39;, &#39;other&#39;].&#34;</span>,</span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>            },</span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a>            {<span>&#34;role&#34;</span>: <span>&#34;user&#34;</span>, <span>&#34;content&#34;</span>: row[<span>&#34;text&#34;</span>]},</span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a>        ],</span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a>        temperature<span>=</span><span>0</span>,</span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>        openpipe<span>=</span>{<span>&#34;tags&#34;</span>: {<span>&#34;prompt_id&#34;</span>: <span>&#34;counting&#34;</span>, <span>&#34;any_key&#34;</span>: <span>&#34;any_value&#34;</span>}},</span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a>    row[<span>&#34;predictions&#34;</span>][<span>&#34;finetuned-llama3-7b-32k-openpipe&#34;</span>] <span>=</span> completion.choices[</span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a>        <span>0</span></span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a>    ].message.content</span></code></pre></div>
</details>
</div>
<p>By the end of this process you can see we have a bunch of predictions attached to each entry in our dataset. You can view all of these <a href="https://huggingface.co/datasets/strickvl/isafpressreleases_test_predictions">in the public dataset</a> I published <a href="https://huggingface.co/datasets/strickvl/isafpressreleases_test_predictions">on the Hugging Face Hub</a>.</p>
<div data-execution_count="8">
<div id="cb21"><pre><code><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span>from</span> rich <span>import</span> <span>print</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a><span>print</span>(preds_test_data[<span>0</span>])</span></code></pre></div>
<div>
<pre><span>{</span>
    <span>&#39;name&#39;</span>: <span>&#39;5&#39;</span>,
    <span>&#39;text&#39;</span>: <span>&#39;2013-01-S-025\n\nKABUL, Afghanistan (Jan. 25, 2013)\nDuring a security operation in Andar district, </span>
<span>Ghazni province, yesterday, an Afghan and coalition force killed the Taliban leader, Alaudin. Alaudin oversaw a </span>
<span>group of insurgents responsible for conducting remote-controlled improvised explosive device and small-arms fire </span>
<span>attacks against Afghan and coalition forces. Prior to his death, Alaudin was planning attacks against Afghan </span>
<span>National Police in Ghazni province.&#39;</span>,
    <span>&#39;predictions&#39;</span>: <span>{</span>
        <span>&#39;finetuned-llama3-7b-32k-openpipe&#39;</span>: 
<span>&#39;{&#34;name&#34;:&#34;1&#34;,&#34;start_date&#34;:&#34;2013-01-24&#34;,&#34;event_type&#34;:[&#34;insurgentskilled&#34;],&#34;province&#34;:[&#34;ghazni&#34;],&#34;target_group&#34;:[&#34;tal</span>
<span>iban&#34;],&#34;min_killed&#34;:1,&#34;min_captured&#34;:0,&#34;killq&#34;:true,&#34;captureq&#34;:false,&#34;killcaptureraid&#34;:true,&#34;airstrike&#34;:false,&#34;nosh</span>
<span>otsfired&#34;:false,&#34;min_leaders_killed&#34;:1,&#34;min_leaders_captured&#34;:0}&#39;</span>,
        <span>&#39;finetuned-mistral-7b-optimised-openpipe&#39;</span>: 
<span>&#39;{&#34;name&#34;:&#34;1&#34;,&#34;start_date&#34;:&#34;2013-01-24&#34;,&#34;event_type&#34;:[&#34;insurgentskilled&#34;],&#34;province&#34;:[&#34;ghazni&#34;],&#34;target_group&#34;:[&#34;tal</span>
<span>iban&#34;],&#34;min_killed&#34;:1,&#34;min_captured&#34;:0,&#34;killq&#34;:true,&#34;captureq&#34;:false,&#34;killcaptureraid&#34;:true,&#34;airstrike&#34;:false,&#34;nosh</span>
<span>otsfired&#34;:false,&#34;min_leaders_killed&#34;:1,&#34;min_leaders_captured&#34;:0}&#39;</span>,
        <span>&#39;finetuned-openai-gpt-3.5-turbo-1106&#39;</span>: 
<span>&#39;{&#34;name&#34;:&#34;4&#34;,&#34;start_date&#34;:&#34;2013-01-24&#34;,&#34;event_type&#34;:[&#34;insurgentskilled&#34;],&#34;province&#34;:[&#34;ghazni&#34;],&#34;target_group&#34;:[&#34;tal</span>
<span>iban&#34;],&#34;min_killed&#34;:1,&#34;min_captured&#34;:0,&#34;killq&#34;:true,&#34;captureq&#34;:false,&#34;killcaptureraid&#34;:true,&#34;airstrike&#34;:false,&#34;nosh</span>
<span>otsfired&#34;:false,&#34;min_leaders_killed&#34;:1,&#34;min_leaders_captured&#34;:0}&#39;</span>,
        <span>&#39;gpt-3.5-turbo&#39;</span>: <span>&#39;{\n    &#34;name&#34;: &#34;Taliban leader Alaudin killed in Ghazni province&#34;,\n    &#34;start_date&#34;: </span>
<span>&#34;2013-01-24&#34;,\n    &#34;event_type&#34;: [&#34;captureandkill&#34;],\n    &#34;province&#34;: [&#34;ghazni&#34;],\n    &#34;target_group&#34;: </span>
<span>[&#34;taliban&#34;],\n    &#34;min_killed&#34;: 1,\n    &#34;min_captured&#34;: 0,\n    &#34;killq&#34;: true,\n    &#34;captureq&#34;: false,\n    </span>
<span>&#34;killcaptureraid&#34;: false,\n    &#34;airstrike&#34;: false,\n    &#34;noshotsfired&#34;: false,\n    &#34;min_leaders_killed&#34;: 1,\n    </span>
<span>&#34;min_leaders_captured&#34;: 0\n}&#39;</span>,
        <span>&#39;gpt-4-turbo&#39;</span>: <span>&#39;{\n    &#34;name&#34;: &#34;Taliban leader Alaudin killed in Ghazni&#34;,\n    &#34;start_date&#34;: </span>
<span>&#34;2013-01-24&#34;,\n    &#34;event_type&#34;: [&#34;captureandkill&#34;],\n    &#34;province&#34;: [&#34;ghazni&#34;],\n    &#34;target_group&#34;: </span>
<span>[&#34;taliban&#34;],\n    &#34;min_killed&#34;: 1,\n    &#34;min_captured&#34;: 0,\n    &#34;killq&#34;: true,\n    &#34;captureq&#34;: false,\n    </span>
<span>&#34;killcaptureraid&#34;: true,\n    &#34;airstrike&#34;: false,\n    &#34;noshotsfired&#34;: false,\n    &#34;min_leaders_killed&#34;: 1,\n    </span>
<span>&#34;min_leaders_captured&#34;: 0\n}&#39;</span>,
        <span>&#39;gpt-4o&#39;</span>: <span>&#39;{\n  &#34;name&#34;: &#34;Taliban leader Alaudin killed in Ghazni&#34;,\n  &#34;start_date&#34;: &#34;2013-01-24&#34;,\n  </span>
<span>&#34;event_type&#34;: [&#34;insurgentskilled&#34;, &#34;captureandkill&#34;],\n  &#34;province&#34;: [&#34;ghazni&#34;],\n  &#34;target_group&#34;: [&#34;taliban&#34;],\n </span>
<span>&#34;min_killed&#34;: 1,\n  &#34;min_captured&#34;: 0,\n  &#34;killq&#34;: true,\n  &#34;captureq&#34;: false,\n  &#34;killcaptureraid&#34;: true,\n  </span>
<span>&#34;airstrike&#34;: false,\n  &#34;noshotsfired&#34;: false,\n  &#34;min_leaders_killed&#34;: 1,\n  &#34;min_leaders_captured&#34;: 0\n}&#39;</span>,
        <span>&#39;mistral-lora-templatefree&#39;</span>: <span>&#39;1&#39;</span>,
        <span>&#39;tinyllama-sharegpt&#39;</span>: 
<span>&#39;{&#34;name&#34;:&#34;2&#34;,&#34;start_date&#34;:&#34;2013-01-24&#34;,&#34;event_type&#34;:[&#34;airstrike&#34;],&#34;province&#34;:[&#34;ghazni&#34;],&#34;target_group&#34;:[&#34;taliban&#34;],</span>
<span>&#34;min_killed&#34;:1,&#34;min_captured&#34;:0,&#34;killq&#34;:true,&#34;captureq&#34;:false,&#34;killcaptureraid&#34;:false,&#34;airstrike&#34;:true,&#34;noshotsfire</span>
<span>d&#34;:false,&#34;min_leaders_killed&#34;:1,&#34;min_leaders_captured&#34;:0}&#39;</span>,
        <span>&#39;tinyllama-templatefree&#39;</span>: <span>&#39;\n{&#34;name&#34;:&#34;Taliban leader killed in </span>
<span>Ghazni&#34;,&#34;start_date&#34;:&#34;2013-01-24&#34;,&#34;event_type&#34;:[&#34;insurgentskilled&#34;],&#34;province&#34;:[&#34;ghazni&#34;],&#34;target_group&#34;:[&#34;taliban&#34;</span>
<span>],&#34;min_killed&#34;:1,&#34;min_captured&#34;:0,&#34;killq&#34;:true,&#34;captureq&#34;:false,&#34;killcaptureraid&#34;:false,&#34;airstrike&#34;:false,&#34;noshotsf</span>
<span>ired&#34;:false,&#34;min_leaders_killed&#34;:1,&#34;min_leaders_captured&#34;:0}&#39;</span>,
        <span>&#39;ft-solar-1-mini-chat-240612-predibase&#39;</span>: 
<span>&#39;\n\n{&#34;name&#34;:&#34;2&#34;,&#34;start_date&#34;:&#34;2013-01-24&#34;,&#34;event_type&#34;:[&#34;insurgentskilled&#34;],&#34;province&#34;:[&#34;ghazni&#34;],&#34;target_group&#34;:[</span>
<span>&#34;taliban&#34;],&#34;min_killed&#34;:1,&#34;min_captured&#34;:0,&#34;killq&#34;:true,&#34;captureq&#34;:false,&#34;killcaptureraid&#34;:true,&#34;airstrike&#34;:false,&#34;</span>
<span>noshotsfired&#34;:false,&#34;min_leaders_killed&#34;:1,&#34;min_leaders_captured&#34;:0}&#39;</span>
    <span>}</span>,
    <span>&#39;start_date&#39;</span>: <span>datetime.date</span><span>(</span><span>2013</span>, <span>1</span>, <span>24</span><span>)</span>,
    <span>&#39;province&#39;</span>: <span>[</span><span>&#39;ghazni&#39;</span><span>]</span>,
    <span>&#39;target_group&#39;</span>: <span>[</span><span>&#39;taliban&#39;</span><span>]</span>,
    <span>&#39;event_type&#39;</span>: <span>[</span><span>&#39;insurgentskilled&#39;</span><span>]</span>,
    <span>&#39;min_killed&#39;</span>: <span>1</span>,
    <span>&#39;min_captured&#39;</span>: <span>0</span>,
    <span>&#39;killq&#39;</span>: <span>True</span>,
    <span>&#39;captureq&#39;</span>: <span>False</span>,
    <span>&#39;killcaptureraid&#39;</span>: <span>False</span>,
    <span>&#39;airstrike&#39;</span>: <span>False</span>,
    <span>&#39;noshotsfired&#39;</span>: <span>False</span>,
    <span>&#39;min_leaders_killed&#39;</span>: <span>1</span>,
    <span>&#39;min_leaders_captured&#39;</span>: <span>0</span>
<span>}</span>
</pre>
</div>
</div>
<p>Unfortunately the Qwen2 inference on Predibase is still not working so I’ll skip that finetuned model for the moment.</p>
<p>Now that we have predictions from seven finetuned models and three OpenAI models (to compare against), we can run our evaluations. I’ll start with a simple check to see what proportion of the predictions are even valid JSON.</p>
</section>
</section>
<section id="json-validity-test">

<div>
<div id="cb22"><pre><code><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span>from</span> datasets <span>import</span> load_dataset</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>dataset_with_preds <span>=</span> load_dataset(<span>&#34;strickvl/isafpressreleases_test_predictions&#34;</span>)[</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>    <span>&#34;train&#34;</span></span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>].to_list()</span></code></pre></div>
</div>
<div data-execution_count="30">
<details>
<summary>Code</summary>
<div id="cb23"><pre><code><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span>import</span> matplotlib.pyplot <span>as</span> plt</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span>import</span> json</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>json_aggregate_scores <span>=</span> {</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-4o&#34;</span>: <span>0</span>,</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-4-turbo&#34;</span>: <span>0</span>,</span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-3.5-turbo&#34;</span>: <span>0</span>,</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>    <span>&#34;tinyllama-templatefree&#34;</span>: <span>0</span>,</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>    <span>&#34;tinyllama-sharegpt&#34;</span>: <span>0</span>,</span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-openai-gpt-3.5-turbo-1106&#34;</span>: <span>0</span>,</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-llama3-7b-32k-openpipe&#34;</span>: <span>0</span>,</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>    <span>&#34;mistral-lora-templatefree&#34;</span>: <span>0</span>,</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-mistral-7b-optimised-openpipe&#34;</span>: <span>0</span>,</span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>    <span>&#34;ft-solar-1-mini-chat-240612-predibase&#34;</span>: <span>0</span>,</span>
<span id="cb23-15"><a href="#cb23-15" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb23-16"><a href="#cb23-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-17"><a href="#cb23-17" aria-hidden="true" tabindex="-1"></a><span>for</span> row <span>in</span> dataset_with_preds:</span>
<span id="cb23-18"><a href="#cb23-18" aria-hidden="true" tabindex="-1"></a>    <span>for</span> model <span>in</span> row[<span>&#34;predictions&#34;</span>]:</span>
<span id="cb23-19"><a href="#cb23-19" aria-hidden="true" tabindex="-1"></a>        <span>try</span>:</span>
<span id="cb23-20"><a href="#cb23-20" aria-hidden="true" tabindex="-1"></a>            json.loads(row[<span>&#34;predictions&#34;</span>][model])</span>
<span id="cb23-21"><a href="#cb23-21" aria-hidden="true" tabindex="-1"></a>            json_aggregate_scores[model] <span>+=</span> <span>1</span></span>
<span id="cb23-22"><a href="#cb23-22" aria-hidden="true" tabindex="-1"></a>        <span>except</span> (json.JSONDecodeError, <span>TypeError</span>):</span>
<span id="cb23-23"><a href="#cb23-23" aria-hidden="true" tabindex="-1"></a>            <span>pass</span></span>
<span id="cb23-24"><a href="#cb23-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-25"><a href="#cb23-25" aria-hidden="true" tabindex="-1"></a><span># print(json_aggregate_scores)</span></span>
<span id="cb23-26"><a href="#cb23-26" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-27"><a href="#cb23-27" aria-hidden="true" tabindex="-1"></a><span># Separate GPT models and finetuned models</span></span>
<span id="cb23-28"><a href="#cb23-28" aria-hidden="true" tabindex="-1"></a>gpt_models <span>=</span> [<span>&#34;gpt-4o&#34;</span>, <span>&#34;gpt-4-turbo&#34;</span>, <span>&#34;gpt-3.5-turbo&#34;</span>]</span>
<span id="cb23-29"><a href="#cb23-29" aria-hidden="true" tabindex="-1"></a>finetuned_models <span>=</span> [</span>
<span id="cb23-30"><a href="#cb23-30" aria-hidden="true" tabindex="-1"></a>    model <span>for</span> model <span>in</span> json_aggregate_scores.keys() <span>if</span> model <span>not</span> <span>in</span> gpt_models</span>
<span id="cb23-31"><a href="#cb23-31" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb23-32"><a href="#cb23-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-33"><a href="#cb23-33" aria-hidden="true" tabindex="-1"></a><span># Create lists for plotting</span></span>
<span id="cb23-34"><a href="#cb23-34" aria-hidden="true" tabindex="-1"></a>models <span>=</span> <span>list</span>(json_aggregate_scores.keys())</span>
<span id="cb23-35"><a href="#cb23-35" aria-hidden="true" tabindex="-1"></a>scores <span>=</span> <span>list</span>(json_aggregate_scores.values())</span>
<span id="cb23-36"><a href="#cb23-36" aria-hidden="true" tabindex="-1"></a>colors <span>=</span> [<span>&#34;#1f77b4&#34;</span> <span>if</span> model <span>in</span> gpt_models <span>else</span> <span>&#34;#ff7f0e&#34;</span> <span>for</span> model <span>in</span> models]</span>
<span id="cb23-37"><a href="#cb23-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-38"><a href="#cb23-38" aria-hidden="true" tabindex="-1"></a><span># Create the plot</span></span>
<span id="cb23-39"><a href="#cb23-39" aria-hidden="true" tabindex="-1"></a>fig, ax <span>=</span> plt.subplots(figsize<span>=</span>(<span>12</span>, <span>10</span>))</span>
<span id="cb23-40"><a href="#cb23-40" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-41"><a href="#cb23-41" aria-hidden="true" tabindex="-1"></a><span># Plot horizontal bars</span></span>
<span id="cb23-42"><a href="#cb23-42" aria-hidden="true" tabindex="-1"></a>bars <span>=</span> ax.barh(models, scores, color<span>=</span>colors)</span>
<span id="cb23-43"><a href="#cb23-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-44"><a href="#cb23-44" aria-hidden="true" tabindex="-1"></a><span># Customize the plot</span></span>
<span id="cb23-45"><a href="#cb23-45" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span>&#34;Number of Valid JSON Outputs&#34;</span>)</span>
<span id="cb23-46"><a href="#cb23-46" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span>&#34;Valid JSON Outputs by Model&#34;</span>)</span>
<span id="cb23-47"><a href="#cb23-47" aria-hidden="true" tabindex="-1"></a>ax.set_xlim(<span>0</span>, <span>750</span>)  <span># Set x-axis limit to slightly above max score</span></span>
<span id="cb23-48"><a href="#cb23-48" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-49"><a href="#cb23-49" aria-hidden="true" tabindex="-1"></a><span># Reduce font size for y-axis labels (model names)</span></span>
<span id="cb23-50"><a href="#cb23-50" aria-hidden="true" tabindex="-1"></a>ax.tick_params(axis<span>=</span><span>&#34;y&#34;</span>, labelsize<span>=</span><span>8</span>)</span>
<span id="cb23-51"><a href="#cb23-51" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-52"><a href="#cb23-52" aria-hidden="true" tabindex="-1"></a><span># Add value labels at the end of each bar</span></span>
<span id="cb23-53"><a href="#cb23-53" aria-hidden="true" tabindex="-1"></a><span>for</span> bar <span>in</span> bars:</span>
<span id="cb23-54"><a href="#cb23-54" aria-hidden="true" tabindex="-1"></a>    width <span>=</span> bar.get_width()</span>
<span id="cb23-55"><a href="#cb23-55" aria-hidden="true" tabindex="-1"></a>    ax.text(</span>
<span id="cb23-56"><a href="#cb23-56" aria-hidden="true" tabindex="-1"></a>        width, bar.get_y() <span>+</span> bar.get_height() <span>/</span> <span>2</span>, <span>f&#34;</span><span>{</span>width<span>}</span><span>&#34;</span>, ha<span>=</span><span>&#34;left&#34;</span>, va<span>=</span><span>&#34;center&#34;</span></span>
<span id="cb23-57"><a href="#cb23-57" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb23-58"><a href="#cb23-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-59"><a href="#cb23-59" aria-hidden="true" tabindex="-1"></a><span># Create custom legend handles</span></span>
<span id="cb23-60"><a href="#cb23-60" aria-hidden="true" tabindex="-1"></a><span>from</span> matplotlib.patches <span>import</span> Patch</span>
<span id="cb23-61"><a href="#cb23-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-62"><a href="#cb23-62" aria-hidden="true" tabindex="-1"></a>legend_elements <span>=</span> [</span>
<span id="cb23-63"><a href="#cb23-63" aria-hidden="true" tabindex="-1"></a>    Patch(facecolor<span>=</span><span>&#34;#ff7f0e&#34;</span>, label<span>=</span><span>&#34;Finetuned Models&#34;</span>),</span>
<span id="cb23-64"><a href="#cb23-64" aria-hidden="true" tabindex="-1"></a>    Patch(facecolor<span>=</span><span>&#34;#1f77b4&#34;</span>, label<span>=</span><span>&#34;GPT Models&#34;</span>),</span>
<span id="cb23-65"><a href="#cb23-65" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb23-66"><a href="#cb23-66" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-67"><a href="#cb23-67" aria-hidden="true" tabindex="-1"></a><span># Add a legend outside the plot</span></span>
<span id="cb23-68"><a href="#cb23-68" aria-hidden="true" tabindex="-1"></a>ax.legend(handles<span>=</span>legend_elements, loc<span>=</span><span>&#34;center left&#34;</span>, bbox_to_anchor<span>=</span>(<span>1</span>, <span>0.5</span>))</span>
<span id="cb23-69"><a href="#cb23-69" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-70"><a href="#cb23-70" aria-hidden="true" tabindex="-1"></a><span># Adjust layout to prevent clipping and make room for the legend</span></span>
<span id="cb23-71"><a href="#cb23-71" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb23-72"><a href="#cb23-72" aria-hidden="true" tabindex="-1"></a>plt.subplots_adjust(right<span>=</span><span>0.85</span>)</span>
<span id="cb23-73"><a href="#cb23-73" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-74"><a href="#cb23-74" aria-hidden="true" tabindex="-1"></a><span># Show the plot</span></span>
<span id="cb23-75"><a href="#cb23-75" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
</details>
<p><img src="https://annahope.me/blog/hello-world/2024-07-01-full-finetuned-model-evaluation_files/figure-html/cell-22-output-1.png"/></p>
</div>
<p>It’s already instructive to see the difference between the templatefree and the sharegpt template’s ability to generate valid JSON for the TinyLlama finetune. The OpenAI models generate valid JSON every single time, as does the finetuned Mistral and Llama3 models.</p>
<p>While writing the code to evaluate the models, I noticed that some entries were blank or had no predictions at all, so I looked into that next.</p>
<div data-execution_count="31">
<div id="cb24"><pre><code><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span># find out how many of the predictions are None values or empty strings</span></span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a>missing_values <span>=</span> {</span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-4o&#34;</span>: <span>0</span>,</span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-4-turbo&#34;</span>: <span>0</span>,</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-3.5-turbo&#34;</span>: <span>0</span>,</span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a>    <span>&#34;tinyllama-templatefree&#34;</span>: <span>0</span>,</span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>    <span>&#34;tinyllama-sharegpt&#34;</span>: <span>0</span>,</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-openai-gpt-3.5-turbo-1106&#34;</span>: <span>0</span>,</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-llama3-7b-32k-openpipe&#34;</span>: <span>0</span>,</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>    <span>&#34;mistral-lora-templatefree&#34;</span>: <span>0</span>,</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-mistral-7b-optimised-openpipe&#34;</span>: <span>0</span>,</span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a>    <span>&#34;ft-solar-1-mini-chat-240612-predibase&#34;</span>: <span>0</span>,</span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a><span>for</span> row <span>in</span> dataset_with_preds:</span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>    <span>for</span> model <span>in</span> row[<span>&#34;predictions&#34;</span>]:</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>        <span>if</span> row[<span>&#34;predictions&#34;</span>][model] <span>is</span> <span>None</span> <span>or</span> row[<span>&#34;predictions&#34;</span>][model] <span>==</span> <span>&#34;&#34;</span>:</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>            missing_values[model] <span>+=</span> <span>1</span></span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a><span>print</span>(missing_values)</span></code></pre></div>
<div>
<pre><span>{</span>
    <span>&#39;gpt-4o&#39;</span>: <span>0</span>,
    <span>&#39;gpt-4-turbo&#39;</span>: <span>0</span>,
    <span>&#39;gpt-3.5-turbo&#39;</span>: <span>0</span>,
    <span>&#39;tinyllama-templatefree&#39;</span>: <span>0</span>,
    <span>&#39;tinyllama-sharegpt&#39;</span>: <span>38</span>,
    <span>&#39;finetuned-openai-gpt-3.5-turbo-1106&#39;</span>: <span>0</span>,
    <span>&#39;finetuned-llama3-7b-32k-openpipe&#39;</span>: <span>0</span>,
    <span>&#39;mistral-lora-templatefree&#39;</span>: <span>0</span>,
    <span>&#39;finetuned-mistral-7b-optimised-openpipe&#39;</span>: <span>0</span>,
    <span>&#39;ft-solar-1-mini-chat-240612-predibase&#39;</span>: <span>0</span>
<span>}</span>
</pre>
</div>
</div>
<p>So were it not for the missing values, the <code>tinyllama-sharegpt</code> model would have had all 724 predictions, and valid JSON as well.</p>
<p>Now we can get into what we’re really interested in: accuracy. I’ll calculate scores for all the properties where it makes sense for us to have a score and then show the results comparing the models.</p>
<p>These are:</p>
<ul>
<li><code>start_date</code></li>
<li><code>province</code></li>
<li><code>target_group</code></li>
<li><code>event_type</code></li>
<li><code>min_killed</code></li>
<li><code>min_captured</code></li>
<li><code>killq</code></li>
<li><code>captureq</code></li>
<li><code>killcaptureraid</code></li>
<li><code>airstrike</code></li>
<li><code>noshotsfired</code></li>
<li><code>min_leaders_killed</code></li>
<li><code>min_leaders_captured</code></li>
</ul>
<p>Important note, for all these charts that follow, the total number of tasks was 724, so the numbers are out of a total of 724.</p>
</section>
<section id="start-date-accuracy">

<div data-execution_count="14">
<details>
<summary>Code</summary>
<div id="cb25"><pre><code><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a>start_date_scores <span>=</span> {</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-4o&#34;</span>: <span>0</span>,</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-4-turbo&#34;</span>: <span>0</span>,</span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-3.5-turbo&#34;</span>: <span>0</span>,</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>    <span>&#34;tinyllama-templatefree&#34;</span>: <span>0</span>,</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>    <span>&#34;tinyllama-sharegpt&#34;</span>: <span>0</span>,</span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-openai-gpt-3.5-turbo-1106&#34;</span>: <span>0</span>,</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-llama3-7b-32k-openpipe&#34;</span>: <span>0</span>,</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>    <span>&#34;mistral-lora-templatefree&#34;</span>: <span>0</span>,</span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-mistral-7b-optimised-openpipe&#34;</span>: <span>0</span>,</span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>    <span>&#34;ft-solar-1-mini-chat-240612-predibase&#34;</span>: <span>0</span>,</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a><span>for</span> row <span>in</span> dataset_with_preds:</span>
<span id="cb25-15"><a href="#cb25-15" aria-hidden="true" tabindex="-1"></a>    <span>for</span> model_name, pred <span>in</span> row[<span>&#34;predictions&#34;</span>].items():</span>
<span id="cb25-16"><a href="#cb25-16" aria-hidden="true" tabindex="-1"></a>        <span>if</span> <span>not</span> pred:</span>
<span id="cb25-17"><a href="#cb25-17" aria-hidden="true" tabindex="-1"></a>            <span>continue</span></span>
<span id="cb25-18"><a href="#cb25-18" aria-hidden="true" tabindex="-1"></a>        <span>try</span>:</span>
<span id="cb25-19"><a href="#cb25-19" aria-hidden="true" tabindex="-1"></a>            pred_dict <span>=</span> json.loads(pred)</span>
<span id="cb25-20"><a href="#cb25-20" aria-hidden="true" tabindex="-1"></a>            <span>if</span> (</span>
<span id="cb25-21"><a href="#cb25-21" aria-hidden="true" tabindex="-1"></a>                <span>type</span>(pred_dict) <span>not</span> <span>in</span> (<span>int</span>, <span>float</span>)</span>
<span id="cb25-22"><a href="#cb25-22" aria-hidden="true" tabindex="-1"></a>                <span>and</span> pred_dict.get(<span>&#34;start_date&#34;</span>)</span>
<span id="cb25-23"><a href="#cb25-23" aria-hidden="true" tabindex="-1"></a>                <span>and</span> (pred_dict[<span>&#34;start_date&#34;</span>] <span>==</span> row[<span>&#34;start_date&#34;</span>].strftime(<span>&#34;%Y-%m-</span><span>%d</span><span>&#34;</span>))</span>
<span id="cb25-24"><a href="#cb25-24" aria-hidden="true" tabindex="-1"></a>            ):</span>
<span id="cb25-25"><a href="#cb25-25" aria-hidden="true" tabindex="-1"></a>                start_date_scores[model_name] <span>+=</span> <span>1</span></span>
<span id="cb25-26"><a href="#cb25-26" aria-hidden="true" tabindex="-1"></a>        <span>except</span> json.JSONDecodeError:</span>
<span id="cb25-27"><a href="#cb25-27" aria-hidden="true" tabindex="-1"></a>            <span>pass</span></span>
<span id="cb25-28"><a href="#cb25-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-29"><a href="#cb25-29" aria-hidden="true" tabindex="-1"></a><span>print</span>(start_date_scores)</span></code></pre></div>
</details>
<div>
<pre><span>{</span>
    <span>&#39;gpt-4o&#39;</span>: <span>527</span>,
    <span>&#39;gpt-4-turbo&#39;</span>: <span>522</span>,
    <span>&#39;gpt-3.5-turbo&#39;</span>: <span>492</span>,
    <span>&#39;tinyllama-templatefree&#39;</span>: <span>231</span>,
    <span>&#39;tinyllama-sharegpt&#39;</span>: <span>479</span>,
    <span>&#39;finetuned-openai-gpt-3.5-turbo-1106&#39;</span>: <span>646</span>,
    <span>&#39;finetuned-llama3-7b-32k-openpipe&#39;</span>: <span>585</span>,
    <span>&#39;mistral-lora-templatefree&#39;</span>: <span>0</span>,
    <span>&#39;finetuned-mistral-7b-optimised-openpipe&#39;</span>: <span>636</span>,
    <span>&#39;ft-solar-1-mini-chat-240612-predibase&#39;</span>: <span>649</span>
<span>}</span>
</pre>
</div>
</div>
<div data-execution_count="15">
<details>
<summary>Code</summary>
<div id="cb26"><pre><code><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span>import</span> matplotlib.pyplot <span>as</span> plt</span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span># Separate GPT models and finetuned models</span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>gpt_models <span>=</span> [<span>&#34;gpt-4o&#34;</span>, <span>&#34;gpt-4-turbo&#34;</span>, <span>&#34;gpt-3.5-turbo&#34;</span>]</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a>finetuned_models <span>=</span> [</span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a>    model <span>for</span> model <span>in</span> start_date_scores.keys() <span>if</span> model <span>not</span> <span>in</span> gpt_models</span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a><span># Create lists for plotting</span></span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>models <span>=</span> <span>list</span>(start_date_scores.keys())</span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>scores <span>=</span> <span>list</span>(start_date_scores.values())</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>colors <span>=</span> [<span>&#34;#1f77b4&#34;</span> <span>if</span> model <span>in</span> gpt_models <span>else</span> <span>&#34;#ff7f0e&#34;</span> <span>for</span> model <span>in</span> models]</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a><span># Create the plot</span></span>
<span id="cb26-15"><a href="#cb26-15" aria-hidden="true" tabindex="-1"></a>fig, ax <span>=</span> plt.subplots(figsize<span>=</span>(<span>12</span>, <span>10</span>))</span>
<span id="cb26-16"><a href="#cb26-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-17"><a href="#cb26-17" aria-hidden="true" tabindex="-1"></a><span># Plot horizontal bars</span></span>
<span id="cb26-18"><a href="#cb26-18" aria-hidden="true" tabindex="-1"></a>bars <span>=</span> ax.barh(models, scores, color<span>=</span>colors)</span>
<span id="cb26-19"><a href="#cb26-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-20"><a href="#cb26-20" aria-hidden="true" tabindex="-1"></a><span># Customize the plot</span></span>
<span id="cb26-21"><a href="#cb26-21" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span>&#34;Number of Correct Start Dates&#34;</span>)</span>
<span id="cb26-22"><a href="#cb26-22" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span>&#34;Correct Start Dates by Model&#34;</span>)</span>
<span id="cb26-23"><a href="#cb26-23" aria-hidden="true" tabindex="-1"></a>ax.set_xlim(<span>0</span>, <span>max</span>(scores) <span>+</span> <span>50</span>)  <span># Set x-axis limit to slightly above max score</span></span>
<span id="cb26-24"><a href="#cb26-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-25"><a href="#cb26-25" aria-hidden="true" tabindex="-1"></a><span># Reduce font size for y-axis labels (model names)</span></span>
<span id="cb26-26"><a href="#cb26-26" aria-hidden="true" tabindex="-1"></a>ax.tick_params(axis<span>=</span><span>&#34;y&#34;</span>, labelsize<span>=</span><span>8</span>)</span>
<span id="cb26-27"><a href="#cb26-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-28"><a href="#cb26-28" aria-hidden="true" tabindex="-1"></a><span># Add value labels at the end of each bar</span></span>
<span id="cb26-29"><a href="#cb26-29" aria-hidden="true" tabindex="-1"></a><span>for</span> bar <span>in</span> bars:</span>
<span id="cb26-30"><a href="#cb26-30" aria-hidden="true" tabindex="-1"></a>    width <span>=</span> bar.get_width()</span>
<span id="cb26-31"><a href="#cb26-31" aria-hidden="true" tabindex="-1"></a>    ax.text(</span>
<span id="cb26-32"><a href="#cb26-32" aria-hidden="true" tabindex="-1"></a>        width, bar.get_y() <span>+</span> bar.get_height() <span>/</span> <span>2</span>, <span>f&#34;</span><span>{</span>width<span>}</span><span>&#34;</span>, ha<span>=</span><span>&#34;left&#34;</span>, va<span>=</span><span>&#34;center&#34;</span></span>
<span id="cb26-33"><a href="#cb26-33" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb26-34"><a href="#cb26-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-35"><a href="#cb26-35" aria-hidden="true" tabindex="-1"></a><span># Create custom legend handles</span></span>
<span id="cb26-36"><a href="#cb26-36" aria-hidden="true" tabindex="-1"></a><span>from</span> matplotlib.patches <span>import</span> Patch</span>
<span id="cb26-37"><a href="#cb26-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-38"><a href="#cb26-38" aria-hidden="true" tabindex="-1"></a>legend_elements <span>=</span> [</span>
<span id="cb26-39"><a href="#cb26-39" aria-hidden="true" tabindex="-1"></a>    Patch(facecolor<span>=</span><span>&#34;#ff7f0e&#34;</span>, label<span>=</span><span>&#34;Finetuned Models&#34;</span>),</span>
<span id="cb26-40"><a href="#cb26-40" aria-hidden="true" tabindex="-1"></a>    Patch(facecolor<span>=</span><span>&#34;#1f77b4&#34;</span>, label<span>=</span><span>&#34;GPT Models&#34;</span>),</span>
<span id="cb26-41"><a href="#cb26-41" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb26-42"><a href="#cb26-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-43"><a href="#cb26-43" aria-hidden="true" tabindex="-1"></a><span># Add a legend outside the plot</span></span>
<span id="cb26-44"><a href="#cb26-44" aria-hidden="true" tabindex="-1"></a>ax.legend(handles<span>=</span>legend_elements, loc<span>=</span><span>&#34;center left&#34;</span>, bbox_to_anchor<span>=</span>(<span>1</span>, <span>0.5</span>))</span>
<span id="cb26-45"><a href="#cb26-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-46"><a href="#cb26-46" aria-hidden="true" tabindex="-1"></a><span># Adjust layout to prevent clipping and make room for the legend</span></span>
<span id="cb26-47"><a href="#cb26-47" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb26-48"><a href="#cb26-48" aria-hidden="true" tabindex="-1"></a>plt.subplots_adjust(right<span>=</span><span>0.85</span>)</span>
<span id="cb26-49"><a href="#cb26-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-50"><a href="#cb26-50" aria-hidden="true" tabindex="-1"></a><span># Show the plot</span></span>
<span id="cb26-51"><a href="#cb26-51" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
</details>
<p><img src="https://annahope.me/blog/hello-world/2024-07-01-full-finetuned-model-evaluation_files/figure-html/cell-25-output-1.png"/></p>
</div>
<p>Both Solar and our finetuned GPT3.5 model performed best on predicting which date the event took place. I’m surprised how poorly the OpenAI models did here, actually. And even our best model still got 75 of the dates wrong. This feels like something that I’d want to improve on. Possibly synthetic data could help, or maybe just an improvement in the finetuning prompt as well.</p>
</section>
<section id="province-accuracy">

<div data-execution_count="16">
<details>
<summary>Code</summary>
<div id="cb27"><pre><code><span id="cb27-1"><a href="#cb27-1" aria-hidden="true" tabindex="-1"></a>province_scores <span>=</span> {</span>
<span id="cb27-2"><a href="#cb27-2" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-4o&#34;</span>: <span>0</span>,</span>
<span id="cb27-3"><a href="#cb27-3" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-4-turbo&#34;</span>: <span>0</span>,</span>
<span id="cb27-4"><a href="#cb27-4" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-3.5-turbo&#34;</span>: <span>0</span>,</span>
<span id="cb27-5"><a href="#cb27-5" aria-hidden="true" tabindex="-1"></a>    <span>&#34;tinyllama-templatefree&#34;</span>: <span>0</span>,</span>
<span id="cb27-6"><a href="#cb27-6" aria-hidden="true" tabindex="-1"></a>    <span>&#34;tinyllama-sharegpt&#34;</span>: <span>0</span>,</span>
<span id="cb27-7"><a href="#cb27-7" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-openai-gpt-3.5-turbo-1106&#34;</span>: <span>0</span>,</span>
<span id="cb27-8"><a href="#cb27-8" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-llama3-7b-32k-openpipe&#34;</span>: <span>0</span>,</span>
<span id="cb27-9"><a href="#cb27-9" aria-hidden="true" tabindex="-1"></a>    <span>&#34;mistral-lora-templatefree&#34;</span>: <span>0</span>,</span>
<span id="cb27-10"><a href="#cb27-10" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-mistral-7b-optimised-openpipe&#34;</span>: <span>0</span>,</span>
<span id="cb27-11"><a href="#cb27-11" aria-hidden="true" tabindex="-1"></a>    <span>&#34;ft-solar-1-mini-chat-240612-predibase&#34;</span>: <span>0</span>,</span>
<span id="cb27-12"><a href="#cb27-12" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb27-13"><a href="#cb27-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-14"><a href="#cb27-14" aria-hidden="true" tabindex="-1"></a><span>for</span> row <span>in</span> dataset_with_preds:</span>
<span id="cb27-15"><a href="#cb27-15" aria-hidden="true" tabindex="-1"></a>    <span>for</span> model_name, pred <span>in</span> row[<span>&#34;predictions&#34;</span>].items():</span>
<span id="cb27-16"><a href="#cb27-16" aria-hidden="true" tabindex="-1"></a>        <span>if</span> <span>not</span> pred:</span>
<span id="cb27-17"><a href="#cb27-17" aria-hidden="true" tabindex="-1"></a>            <span>continue</span></span>
<span id="cb27-18"><a href="#cb27-18" aria-hidden="true" tabindex="-1"></a>        <span>try</span>:</span>
<span id="cb27-19"><a href="#cb27-19" aria-hidden="true" tabindex="-1"></a>            pred_dict <span>=</span> json.loads(pred)</span>
<span id="cb27-20"><a href="#cb27-20" aria-hidden="true" tabindex="-1"></a>            <span>if</span> <span>isinstance</span>(pred_dict, <span>dict</span>) <span>and</span> <span>&#34;province&#34;</span> <span>in</span> pred_dict:</span>
<span id="cb27-21"><a href="#cb27-21" aria-hidden="true" tabindex="-1"></a>                pred_provinces <span>=</span> pred_dict[<span>&#34;province&#34;</span>]</span>
<span id="cb27-22"><a href="#cb27-22" aria-hidden="true" tabindex="-1"></a>                <span>if</span> <span>isinstance</span>(pred_provinces, <span>str</span>):</span>
<span id="cb27-23"><a href="#cb27-23" aria-hidden="true" tabindex="-1"></a>                    pred_provinces <span>=</span> [pred_provinces]</span>
<span id="cb27-24"><a href="#cb27-24" aria-hidden="true" tabindex="-1"></a>                <span>if</span> <span>set</span>(pred_provinces) <span>==</span> <span>set</span>(row[<span>&#34;province&#34;</span>]):</span>
<span id="cb27-25"><a href="#cb27-25" aria-hidden="true" tabindex="-1"></a>                    province_scores[model_name] <span>+=</span> <span>1</span></span>
<span id="cb27-26"><a href="#cb27-26" aria-hidden="true" tabindex="-1"></a>        <span>except</span> (json.JSONDecodeError, <span>KeyError</span>, <span>TypeError</span>):</span>
<span id="cb27-27"><a href="#cb27-27" aria-hidden="true" tabindex="-1"></a>            <span>pass</span></span>
<span id="cb27-28"><a href="#cb27-28" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb27-29"><a href="#cb27-29" aria-hidden="true" tabindex="-1"></a><span>print</span>(province_scores)</span></code></pre></div>
</details>
<div>
<pre><span>{</span>
    <span>&#39;gpt-4o&#39;</span>: <span>649</span>,
    <span>&#39;gpt-4-turbo&#39;</span>: <span>645</span>,
    <span>&#39;gpt-3.5-turbo&#39;</span>: <span>595</span>,
    <span>&#39;tinyllama-templatefree&#39;</span>: <span>335</span>,
    <span>&#39;tinyllama-sharegpt&#39;</span>: <span>660</span>,
    <span>&#39;finetuned-openai-gpt-3.5-turbo-1106&#39;</span>: <span>704</span>,
    <span>&#39;finetuned-llama3-7b-32k-openpipe&#39;</span>: <span>707</span>,
    <span>&#39;mistral-lora-templatefree&#39;</span>: <span>0</span>,
    <span>&#39;finetuned-mistral-7b-optimised-openpipe&#39;</span>: <span>711</span>,
    <span>&#39;ft-solar-1-mini-chat-240612-predibase&#39;</span>: <span>704</span>
<span>}</span>
</pre>
</div>
</div>
<div data-execution_count="17">
<details>
<summary>Code</summary>
<div id="cb28"><pre><code><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a><span>import</span> matplotlib.pyplot <span>as</span> plt</span>
<span id="cb28-2"><a href="#cb28-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-3"><a href="#cb28-3" aria-hidden="true" tabindex="-1"></a><span># Separate GPT models and finetuned models</span></span>
<span id="cb28-4"><a href="#cb28-4" aria-hidden="true" tabindex="-1"></a>gpt_models <span>=</span> [<span>&#34;gpt-4o&#34;</span>, <span>&#34;gpt-4-turbo&#34;</span>, <span>&#34;gpt-3.5-turbo&#34;</span>]</span>
<span id="cb28-5"><a href="#cb28-5" aria-hidden="true" tabindex="-1"></a>finetuned_models <span>=</span> [</span>
<span id="cb28-6"><a href="#cb28-6" aria-hidden="true" tabindex="-1"></a>    model <span>for</span> model <span>in</span> province_scores.keys() <span>if</span> model <span>not</span> <span>in</span> gpt_models</span>
<span id="cb28-7"><a href="#cb28-7" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb28-8"><a href="#cb28-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-9"><a href="#cb28-9" aria-hidden="true" tabindex="-1"></a><span># Create lists for plotting</span></span>
<span id="cb28-10"><a href="#cb28-10" aria-hidden="true" tabindex="-1"></a>models <span>=</span> <span>list</span>(province_scores.keys())</span>
<span id="cb28-11"><a href="#cb28-11" aria-hidden="true" tabindex="-1"></a>scores <span>=</span> <span>list</span>(province_scores.values())</span>
<span id="cb28-12"><a href="#cb28-12" aria-hidden="true" tabindex="-1"></a>colors <span>=</span> [<span>&#34;#1f77b4&#34;</span> <span>if</span> model <span>in</span> gpt_models <span>else</span> <span>&#34;#ff7f0e&#34;</span> <span>for</span> model <span>in</span> models]</span>
<span id="cb28-13"><a href="#cb28-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-14"><a href="#cb28-14" aria-hidden="true" tabindex="-1"></a><span># Create the plot</span></span>
<span id="cb28-15"><a href="#cb28-15" aria-hidden="true" tabindex="-1"></a>fig, ax <span>=</span> plt.subplots(figsize<span>=</span>(<span>12</span>, <span>10</span>))</span>
<span id="cb28-16"><a href="#cb28-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-17"><a href="#cb28-17" aria-hidden="true" tabindex="-1"></a><span># Plot horizontal bars</span></span>
<span id="cb28-18"><a href="#cb28-18" aria-hidden="true" tabindex="-1"></a>bars <span>=</span> ax.barh(models, scores, color<span>=</span>colors)</span>
<span id="cb28-19"><a href="#cb28-19" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-20"><a href="#cb28-20" aria-hidden="true" tabindex="-1"></a><span># Customize the plot</span></span>
<span id="cb28-21"><a href="#cb28-21" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span>&#34;Number of Correct Provinces&#34;</span>)</span>
<span id="cb28-22"><a href="#cb28-22" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span>&#34;Correct Provinces by Model&#34;</span>)</span>
<span id="cb28-23"><a href="#cb28-23" aria-hidden="true" tabindex="-1"></a>ax.set_xlim(<span>0</span>, <span>max</span>(scores) <span>+</span> <span>50</span>)  <span># Set x-axis limit to slightly above max score</span></span>
<span id="cb28-24"><a href="#cb28-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-25"><a href="#cb28-25" aria-hidden="true" tabindex="-1"></a><span># Reduce font size for y-axis labels (model names)</span></span>
<span id="cb28-26"><a href="#cb28-26" aria-hidden="true" tabindex="-1"></a>ax.tick_params(axis<span>=</span><span>&#34;y&#34;</span>, labelsize<span>=</span><span>8</span>)</span>
<span id="cb28-27"><a href="#cb28-27" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-28"><a href="#cb28-28" aria-hidden="true" tabindex="-1"></a><span># Add value labels at the end of each bar</span></span>
<span id="cb28-29"><a href="#cb28-29" aria-hidden="true" tabindex="-1"></a><span>for</span> bar <span>in</span> bars:</span>
<span id="cb28-30"><a href="#cb28-30" aria-hidden="true" tabindex="-1"></a>    width <span>=</span> bar.get_width()</span>
<span id="cb28-31"><a href="#cb28-31" aria-hidden="true" tabindex="-1"></a>    ax.text(</span>
<span id="cb28-32"><a href="#cb28-32" aria-hidden="true" tabindex="-1"></a>        width, bar.get_y() <span>+</span> bar.get_height() <span>/</span> <span>2</span>, <span>f&#34;</span><span>{</span>width<span>}</span><span>&#34;</span>, ha<span>=</span><span>&#34;left&#34;</span>, va<span>=</span><span>&#34;center&#34;</span></span>
<span id="cb28-33"><a href="#cb28-33" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb28-34"><a href="#cb28-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-35"><a href="#cb28-35" aria-hidden="true" tabindex="-1"></a><span># Create custom legend handles</span></span>
<span id="cb28-36"><a href="#cb28-36" aria-hidden="true" tabindex="-1"></a><span>from</span> matplotlib.patches <span>import</span> Patch</span>
<span id="cb28-37"><a href="#cb28-37" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-38"><a href="#cb28-38" aria-hidden="true" tabindex="-1"></a>legend_elements <span>=</span> [</span>
<span id="cb28-39"><a href="#cb28-39" aria-hidden="true" tabindex="-1"></a>    Patch(facecolor<span>=</span><span>&#34;#ff7f0e&#34;</span>, label<span>=</span><span>&#34;Finetuned Models&#34;</span>),</span>
<span id="cb28-40"><a href="#cb28-40" aria-hidden="true" tabindex="-1"></a>    Patch(facecolor<span>=</span><span>&#34;#1f77b4&#34;</span>, label<span>=</span><span>&#34;GPT Models&#34;</span>),</span>
<span id="cb28-41"><a href="#cb28-41" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb28-42"><a href="#cb28-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-43"><a href="#cb28-43" aria-hidden="true" tabindex="-1"></a><span># Add a legend outside the plot</span></span>
<span id="cb28-44"><a href="#cb28-44" aria-hidden="true" tabindex="-1"></a>ax.legend(handles<span>=</span>legend_elements, loc<span>=</span><span>&#34;center left&#34;</span>, bbox_to_anchor<span>=</span>(<span>1</span>, <span>0.5</span>))</span>
<span id="cb28-45"><a href="#cb28-45" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-46"><a href="#cb28-46" aria-hidden="true" tabindex="-1"></a><span># Adjust layout to prevent clipping and make room for the legend</span></span>
<span id="cb28-47"><a href="#cb28-47" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb28-48"><a href="#cb28-48" aria-hidden="true" tabindex="-1"></a>plt.subplots_adjust(right<span>=</span><span>0.85</span>)</span>
<span id="cb28-49"><a href="#cb28-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb28-50"><a href="#cb28-50" aria-hidden="true" tabindex="-1"></a><span># Show the plot</span></span>
<span id="cb28-51"><a href="#cb28-51" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
</details>
<p><img src="https://annahope.me/blog/hello-world/2024-07-01-full-finetuned-model-evaluation_files/figure-html/cell-27-output-1.png"/></p>
</div>
<p>In what will become a theme, the finetuned models actually outperform the OpenAI models, only making a few mistakes. Once again I’m surprised how poorly GPT3.5 did on this task.</p>
</section>
<section id="target-group-accuracy">

<p>Here there are potentially multiple groups mentioned as target group so I’ll give a score out of 1 of how many of the groups the model predicted were correct.</p>
<div data-execution_count="32">
<details>
<summary>Code</summary>
<div id="cb29"><pre><code><span id="cb29-1"><a href="#cb29-1" aria-hidden="true" tabindex="-1"></a><span>import</span> matplotlib.pyplot <span>as</span> plt</span>
<span id="cb29-2"><a href="#cb29-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-3"><a href="#cb29-3" aria-hidden="true" tabindex="-1"></a>target_group_scores <span>=</span> {</span>
<span id="cb29-4"><a href="#cb29-4" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-4o&#34;</span>: <span>0</span>,</span>
<span id="cb29-5"><a href="#cb29-5" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-4-turbo&#34;</span>: <span>0</span>,</span>
<span id="cb29-6"><a href="#cb29-6" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-3.5-turbo&#34;</span>: <span>0</span>,</span>
<span id="cb29-7"><a href="#cb29-7" aria-hidden="true" tabindex="-1"></a>    <span>&#34;tinyllama-templatefree&#34;</span>: <span>0</span>,</span>
<span id="cb29-8"><a href="#cb29-8" aria-hidden="true" tabindex="-1"></a>    <span>&#34;tinyllama-sharegpt&#34;</span>: <span>0</span>,</span>
<span id="cb29-9"><a href="#cb29-9" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-openai-gpt-3.5-turbo-1106&#34;</span>: <span>0</span>,</span>
<span id="cb29-10"><a href="#cb29-10" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-llama3-7b-32k-openpipe&#34;</span>: <span>0</span>,</span>
<span id="cb29-11"><a href="#cb29-11" aria-hidden="true" tabindex="-1"></a>    <span>&#34;mistral-lora-templatefree&#34;</span>: <span>0</span>,</span>
<span id="cb29-12"><a href="#cb29-12" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-mistral-7b-optimised-openpipe&#34;</span>: <span>0</span>,</span>
<span id="cb29-13"><a href="#cb29-13" aria-hidden="true" tabindex="-1"></a>    <span>&#34;ft-solar-1-mini-chat-240612-predibase&#34;</span>: <span>0</span>,</span>
<span id="cb29-14"><a href="#cb29-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb29-15"><a href="#cb29-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-16"><a href="#cb29-16" aria-hidden="true" tabindex="-1"></a><span>for</span> row <span>in</span> dataset_with_preds:</span>
<span id="cb29-17"><a href="#cb29-17" aria-hidden="true" tabindex="-1"></a>    <span>for</span> model_name, pred <span>in</span> row[<span>&#34;predictions&#34;</span>].items():</span>
<span id="cb29-18"><a href="#cb29-18" aria-hidden="true" tabindex="-1"></a>        <span>if</span> <span>not</span> pred:</span>
<span id="cb29-19"><a href="#cb29-19" aria-hidden="true" tabindex="-1"></a>            <span>continue</span></span>
<span id="cb29-20"><a href="#cb29-20" aria-hidden="true" tabindex="-1"></a>        <span>try</span>:</span>
<span id="cb29-21"><a href="#cb29-21" aria-hidden="true" tabindex="-1"></a>            pred_dict <span>=</span> json.loads(pred)</span>
<span id="cb29-22"><a href="#cb29-22" aria-hidden="true" tabindex="-1"></a>            <span>if</span> <span>isinstance</span>(pred_dict, <span>dict</span>) <span>and</span> <span>&#34;target_group&#34;</span> <span>in</span> pred_dict:</span>
<span id="cb29-23"><a href="#cb29-23" aria-hidden="true" tabindex="-1"></a>                pred_groups <span>=</span> pred_dict[<span>&#34;target_group&#34;</span>]</span>
<span id="cb29-24"><a href="#cb29-24" aria-hidden="true" tabindex="-1"></a>                <span>if</span> <span>isinstance</span>(pred_groups, <span>str</span>):</span>
<span id="cb29-25"><a href="#cb29-25" aria-hidden="true" tabindex="-1"></a>                    pred_groups <span>=</span> [pred_groups]</span>
<span id="cb29-26"><a href="#cb29-26" aria-hidden="true" tabindex="-1"></a>                correct_groups <span>=</span> row[<span>&#34;target_group&#34;</span>]</span>
<span id="cb29-27"><a href="#cb29-27" aria-hidden="true" tabindex="-1"></a>                <span>if</span> <span>isinstance</span>(correct_groups, <span>str</span>):</span>
<span id="cb29-28"><a href="#cb29-28" aria-hidden="true" tabindex="-1"></a>                    correct_groups <span>=</span> [correct_groups]</span>
<span id="cb29-29"><a href="#cb29-29" aria-hidden="true" tabindex="-1"></a>                <span>if</span> correct_groups:</span>
<span id="cb29-30"><a href="#cb29-30" aria-hidden="true" tabindex="-1"></a>                    score <span>=</span> <span>len</span>(<span>set</span>(pred_groups) <span>&amp;</span> <span>set</span>(correct_groups)) <span>/</span> <span>len</span>(</span>
<span id="cb29-31"><a href="#cb29-31" aria-hidden="true" tabindex="-1"></a>                        <span>set</span>(correct_groups)</span>
<span id="cb29-32"><a href="#cb29-32" aria-hidden="true" tabindex="-1"></a>                    )</span>
<span id="cb29-33"><a href="#cb29-33" aria-hidden="true" tabindex="-1"></a>                    target_group_scores[model_name] <span>+=</span> score</span>
<span id="cb29-34"><a href="#cb29-34" aria-hidden="true" tabindex="-1"></a>        <span>except</span> (json.JSONDecodeError, <span>KeyError</span>, <span>TypeError</span>):</span>
<span id="cb29-35"><a href="#cb29-35" aria-hidden="true" tabindex="-1"></a>            <span>pass</span></span>
<span id="cb29-36"><a href="#cb29-36" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-37"><a href="#cb29-37" aria-hidden="true" tabindex="-1"></a><span># Separate GPT models and finetuned models</span></span>
<span id="cb29-38"><a href="#cb29-38" aria-hidden="true" tabindex="-1"></a>gpt_models <span>=</span> [<span>&#34;gpt-4o&#34;</span>, <span>&#34;gpt-4-turbo&#34;</span>, <span>&#34;gpt-3.5-turbo&#34;</span>]</span>
<span id="cb29-39"><a href="#cb29-39" aria-hidden="true" tabindex="-1"></a>finetuned_models <span>=</span> [</span>
<span id="cb29-40"><a href="#cb29-40" aria-hidden="true" tabindex="-1"></a>    model <span>for</span> model <span>in</span> target_group_scores.keys() <span>if</span> model <span>not</span> <span>in</span> gpt_models</span>
<span id="cb29-41"><a href="#cb29-41" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb29-42"><a href="#cb29-42" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-43"><a href="#cb29-43" aria-hidden="true" tabindex="-1"></a><span># Create lists for plotting</span></span>
<span id="cb29-44"><a href="#cb29-44" aria-hidden="true" tabindex="-1"></a>models <span>=</span> <span>list</span>(target_group_scores.keys())</span>
<span id="cb29-45"><a href="#cb29-45" aria-hidden="true" tabindex="-1"></a>scores <span>=</span> <span>list</span>(target_group_scores.values())</span>
<span id="cb29-46"><a href="#cb29-46" aria-hidden="true" tabindex="-1"></a>colors <span>=</span> [<span>&#34;#1f77b4&#34;</span> <span>if</span> model <span>in</span> gpt_models <span>else</span> <span>&#34;#ff7f0e&#34;</span> <span>for</span> model <span>in</span> models]</span>
<span id="cb29-47"><a href="#cb29-47" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-48"><a href="#cb29-48" aria-hidden="true" tabindex="-1"></a><span># Create the plot</span></span>
<span id="cb29-49"><a href="#cb29-49" aria-hidden="true" tabindex="-1"></a>fig, ax <span>=</span> plt.subplots(figsize<span>=</span>(<span>12</span>, <span>10</span>))</span>
<span id="cb29-50"><a href="#cb29-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-51"><a href="#cb29-51" aria-hidden="true" tabindex="-1"></a><span># Plot horizontal bars</span></span>
<span id="cb29-52"><a href="#cb29-52" aria-hidden="true" tabindex="-1"></a>bars <span>=</span> ax.barh(models, scores, color<span>=</span>colors)</span>
<span id="cb29-53"><a href="#cb29-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-54"><a href="#cb29-54" aria-hidden="true" tabindex="-1"></a><span># Customize the plot</span></span>
<span id="cb29-55"><a href="#cb29-55" aria-hidden="true" tabindex="-1"></a>ax.set_xlabel(<span>&#34;Target Group Accuracy Score&#34;</span>)</span>
<span id="cb29-56"><a href="#cb29-56" aria-hidden="true" tabindex="-1"></a>ax.set_title(<span>&#34;Target Group Accuracy by Model&#34;</span>)</span>
<span id="cb29-57"><a href="#cb29-57" aria-hidden="true" tabindex="-1"></a>ax.set_xlim(<span>0</span>, <span>max</span>(scores) <span>+</span> <span>50</span>)  <span># Set x-axis limit to slightly above max score</span></span>
<span id="cb29-58"><a href="#cb29-58" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-59"><a href="#cb29-59" aria-hidden="true" tabindex="-1"></a><span># Reduce font size for y-axis labels (model names)</span></span>
<span id="cb29-60"><a href="#cb29-60" aria-hidden="true" tabindex="-1"></a>ax.tick_params(axis<span>=</span><span>&#34;y&#34;</span>, labelsize<span>=</span><span>8</span>)</span>
<span id="cb29-61"><a href="#cb29-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-62"><a href="#cb29-62" aria-hidden="true" tabindex="-1"></a><span># Add value labels at the end of each bar</span></span>
<span id="cb29-63"><a href="#cb29-63" aria-hidden="true" tabindex="-1"></a><span>for</span> bar <span>in</span> bars:</span>
<span id="cb29-64"><a href="#cb29-64" aria-hidden="true" tabindex="-1"></a>    width <span>=</span> bar.get_width()</span>
<span id="cb29-65"><a href="#cb29-65" aria-hidden="true" tabindex="-1"></a>    ax.text(</span>
<span id="cb29-66"><a href="#cb29-66" aria-hidden="true" tabindex="-1"></a>        width,</span>
<span id="cb29-67"><a href="#cb29-67" aria-hidden="true" tabindex="-1"></a>        bar.get_y() <span>+</span> bar.get_height() <span>/</span> <span>2</span>,</span>
<span id="cb29-68"><a href="#cb29-68" aria-hidden="true" tabindex="-1"></a>        <span>f&#34;</span><span>{</span>width<span>:.2f}</span><span>&#34;</span>,</span>
<span id="cb29-69"><a href="#cb29-69" aria-hidden="true" tabindex="-1"></a>        ha<span>=</span><span>&#34;left&#34;</span>,</span>
<span id="cb29-70"><a href="#cb29-70" aria-hidden="true" tabindex="-1"></a>        va<span>=</span><span>&#34;center&#34;</span>,</span>
<span id="cb29-71"><a href="#cb29-71" aria-hidden="true" tabindex="-1"></a>    )</span>
<span id="cb29-72"><a href="#cb29-72" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-73"><a href="#cb29-73" aria-hidden="true" tabindex="-1"></a><span># Create custom legend handles</span></span>
<span id="cb29-74"><a href="#cb29-74" aria-hidden="true" tabindex="-1"></a><span>from</span> matplotlib.patches <span>import</span> Patch</span>
<span id="cb29-75"><a href="#cb29-75" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-76"><a href="#cb29-76" aria-hidden="true" tabindex="-1"></a>legend_elements <span>=</span> [</span>
<span id="cb29-77"><a href="#cb29-77" aria-hidden="true" tabindex="-1"></a>    Patch(facecolor<span>=</span><span>&#34;#ff7f0e&#34;</span>, label<span>=</span><span>&#34;Finetuned Models&#34;</span>),</span>
<span id="cb29-78"><a href="#cb29-78" aria-hidden="true" tabindex="-1"></a>    Patch(facecolor<span>=</span><span>&#34;#1f77b4&#34;</span>, label<span>=</span><span>&#34;GPT Models&#34;</span>),</span>
<span id="cb29-79"><a href="#cb29-79" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb29-80"><a href="#cb29-80" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-81"><a href="#cb29-81" aria-hidden="true" tabindex="-1"></a><span># Add a legend outside the plot</span></span>
<span id="cb29-82"><a href="#cb29-82" aria-hidden="true" tabindex="-1"></a>ax.legend(handles<span>=</span>legend_elements, loc<span>=</span><span>&#34;center left&#34;</span>, bbox_to_anchor<span>=</span>(<span>1</span>, <span>0.5</span>))</span>
<span id="cb29-83"><a href="#cb29-83" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-84"><a href="#cb29-84" aria-hidden="true" tabindex="-1"></a><span># Adjust layout to prevent clipping and make room for the legend</span></span>
<span id="cb29-85"><a href="#cb29-85" aria-hidden="true" tabindex="-1"></a>plt.tight_layout()</span>
<span id="cb29-86"><a href="#cb29-86" aria-hidden="true" tabindex="-1"></a>plt.subplots_adjust(right<span>=</span><span>0.85</span>)</span>
<span id="cb29-87"><a href="#cb29-87" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb29-88"><a href="#cb29-88" aria-hidden="true" tabindex="-1"></a><span># Show the plot</span></span>
<span id="cb29-89"><a href="#cb29-89" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code></pre></div>
</details>
<p><img src="https://annahope.me/blog/hello-world/2024-07-01-full-finetuned-model-evaluation_files/figure-html/cell-28-output-1.png"/></p>
</div>
<p>Finetuned models doing significantly better than OpenAI for target group identification. I suspect that this would degrade if we added some new groups who weren’t in the training data (as I’d written about <a href="https://mlops.systems/posts/2024-06-25-evaluation-finetuning-manual-dataset.html">in my last post</a>.)</p>
</section>
<section id="event-type-accuracy">

<div data-execution_count="19">
<details>
<summary>Code</summary>
<div id="cb30"><pre><code><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a><span>import</span> matplotlib.pyplot <span>as</span> plt</span>
<span id="cb30-2"><a href="#cb30-2" aria-hidden="true" tabindex="-1"></a><span>from</span> matplotlib.patches <span>import</span> Patch</span>
<span id="cb30-3"><a href="#cb30-3" aria-hidden="true" tabindex="-1"></a><span>from</span> typing <span>import</span> Dict, Union</span>
<span id="cb30-4"><a href="#cb30-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-5"><a href="#cb30-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-6"><a href="#cb30-6" aria-hidden="true" tabindex="-1"></a><span>def</span> create_accuracy_chart(</span>
<span id="cb30-7"><a href="#cb30-7" aria-hidden="true" tabindex="-1"></a>    scores: Dict[<span>str</span>, Union[<span>int</span>, <span>float</span>]], title: <span>str</span>, xlabel: <span>str</span></span>
<span id="cb30-8"><a href="#cb30-8" aria-hidden="true" tabindex="-1"></a>) <span>-&gt;</span> <span>None</span>:</span>
<span id="cb30-9"><a href="#cb30-9" aria-hidden="true" tabindex="-1"></a>    <span># Separate GPT models and finetuned models</span></span>
<span id="cb30-10"><a href="#cb30-10" aria-hidden="true" tabindex="-1"></a>    gpt_models <span>=</span> [<span>&#34;gpt-4o&#34;</span>, <span>&#34;gpt-4-turbo&#34;</span>, <span>&#34;gpt-3.5-turbo&#34;</span>]</span>
<span id="cb30-11"><a href="#cb30-11" aria-hidden="true" tabindex="-1"></a>    finetuned_models <span>=</span> [model <span>for</span> model <span>in</span> scores.keys() <span>if</span> model <span>not</span> <span>in</span> gpt_models]</span>
<span id="cb30-12"><a href="#cb30-12" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-13"><a href="#cb30-13" aria-hidden="true" tabindex="-1"></a>    <span># Create lists for plotting</span></span>
<span id="cb30-14"><a href="#cb30-14" aria-hidden="true" tabindex="-1"></a>    models <span>=</span> <span>list</span>(scores.keys())</span>
<span id="cb30-15"><a href="#cb30-15" aria-hidden="true" tabindex="-1"></a>    scores_list <span>=</span> <span>list</span>(scores.values())</span>
<span id="cb30-16"><a href="#cb30-16" aria-hidden="true" tabindex="-1"></a>    colors <span>=</span> [<span>&#34;#1f77b4&#34;</span> <span>if</span> model <span>in</span> gpt_models <span>else</span> <span>&#34;#ff7f0e&#34;</span> <span>for</span> model <span>in</span> models]</span>
<span id="cb30-17"><a href="#cb30-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-18"><a href="#cb30-18" aria-hidden="true" tabindex="-1"></a>    <span># Create the plot</span></span>
<span id="cb30-19"><a href="#cb30-19" aria-hidden="true" tabindex="-1"></a>    fig, ax <span>=</span> plt.subplots(figsize<span>=</span>(<span>12</span>, <span>10</span>))</span>
<span id="cb30-20"><a href="#cb30-20" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-21"><a href="#cb30-21" aria-hidden="true" tabindex="-1"></a>    <span># Plot horizontal bars</span></span>
<span id="cb30-22"><a href="#cb30-22" aria-hidden="true" tabindex="-1"></a>    bars <span>=</span> ax.barh(models, scores_list, color<span>=</span>colors)</span>
<span id="cb30-23"><a href="#cb30-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-24"><a href="#cb30-24" aria-hidden="true" tabindex="-1"></a>    <span># Customize the plot</span></span>
<span id="cb30-25"><a href="#cb30-25" aria-hidden="true" tabindex="-1"></a>    ax.set_xlabel(xlabel)</span>
<span id="cb30-26"><a href="#cb30-26" aria-hidden="true" tabindex="-1"></a>    ax.set_title(title)</span>
<span id="cb30-27"><a href="#cb30-27" aria-hidden="true" tabindex="-1"></a>    ax.set_xlim(</span>
<span id="cb30-28"><a href="#cb30-28" aria-hidden="true" tabindex="-1"></a>        <span>0</span>, <span>max</span>(scores_list) <span>+</span> <span>50</span></span>
<span id="cb30-29"><a href="#cb30-29" aria-hidden="true" tabindex="-1"></a>    )  <span># Set x-axis limit to slightly above max score</span></span>
<span id="cb30-30"><a href="#cb30-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-31"><a href="#cb30-31" aria-hidden="true" tabindex="-1"></a>    <span># Reduce font size for y-axis labels (model names)</span></span>
<span id="cb30-32"><a href="#cb30-32" aria-hidden="true" tabindex="-1"></a>    ax.tick_params(axis<span>=</span><span>&#34;y&#34;</span>, labelsize<span>=</span><span>8</span>)</span>
<span id="cb30-33"><a href="#cb30-33" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-34"><a href="#cb30-34" aria-hidden="true" tabindex="-1"></a>    <span># Add value labels at the end of each bar</span></span>
<span id="cb30-35"><a href="#cb30-35" aria-hidden="true" tabindex="-1"></a>    <span>for</span> bar <span>in</span> bars:</span>
<span id="cb30-36"><a href="#cb30-36" aria-hidden="true" tabindex="-1"></a>        width <span>=</span> bar.get_width()</span>
<span id="cb30-37"><a href="#cb30-37" aria-hidden="true" tabindex="-1"></a>        ax.text(</span>
<span id="cb30-38"><a href="#cb30-38" aria-hidden="true" tabindex="-1"></a>            width,</span>
<span id="cb30-39"><a href="#cb30-39" aria-hidden="true" tabindex="-1"></a>            bar.get_y() <span>+</span> bar.get_height() <span>/</span> <span>2</span>,</span>
<span id="cb30-40"><a href="#cb30-40" aria-hidden="true" tabindex="-1"></a>            <span>f&#34;</span><span>{</span>width<span>:.2f}</span><span>&#34;</span> <span>if</span> <span>isinstance</span>(width, <span>float</span>) <span>else</span> <span>f&#34;</span><span>{</span>width<span>}</span><span>&#34;</span>,</span>
<span id="cb30-41"><a href="#cb30-41" aria-hidden="true" tabindex="-1"></a>            ha<span>=</span><span>&#34;left&#34;</span>,</span>
<span id="cb30-42"><a href="#cb30-42" aria-hidden="true" tabindex="-1"></a>            va<span>=</span><span>&#34;center&#34;</span>,</span>
<span id="cb30-43"><a href="#cb30-43" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb30-44"><a href="#cb30-44" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-45"><a href="#cb30-45" aria-hidden="true" tabindex="-1"></a>    <span># Create custom legend handles</span></span>
<span id="cb30-46"><a href="#cb30-46" aria-hidden="true" tabindex="-1"></a>    legend_elements <span>=</span> [</span>
<span id="cb30-47"><a href="#cb30-47" aria-hidden="true" tabindex="-1"></a>        Patch(facecolor<span>=</span><span>&#34;#ff7f0e&#34;</span>, label<span>=</span><span>&#34;Finetuned Models&#34;</span>),</span>
<span id="cb30-48"><a href="#cb30-48" aria-hidden="true" tabindex="-1"></a>        Patch(facecolor<span>=</span><span>&#34;#1f77b4&#34;</span>, label<span>=</span><span>&#34;GPT Models&#34;</span>),</span>
<span id="cb30-49"><a href="#cb30-49" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb30-50"><a href="#cb30-50" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-51"><a href="#cb30-51" aria-hidden="true" tabindex="-1"></a>    <span># Add a legend outside the plot</span></span>
<span id="cb30-52"><a href="#cb30-52" aria-hidden="true" tabindex="-1"></a>    ax.legend(handles<span>=</span>legend_elements, loc<span>=</span><span>&#34;center left&#34;</span>, bbox_to_anchor<span>=</span>(<span>1</span>, <span>0.5</span>))</span>
<span id="cb30-53"><a href="#cb30-53" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-54"><a href="#cb30-54" aria-hidden="true" tabindex="-1"></a>    <span># Adjust layout to prevent clipping and make room for the legend</span></span>
<span id="cb30-55"><a href="#cb30-55" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb30-56"><a href="#cb30-56" aria-hidden="true" tabindex="-1"></a>    plt.subplots_adjust(right<span>=</span><span>0.85</span>)</span>
<span id="cb30-57"><a href="#cb30-57" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-58"><a href="#cb30-58" aria-hidden="true" tabindex="-1"></a>    <span># Show the plot</span></span>
<span id="cb30-59"><a href="#cb30-59" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb30-60"><a href="#cb30-60" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-61"><a href="#cb30-61" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-62"><a href="#cb30-62" aria-hidden="true" tabindex="-1"></a>event_type_scores <span>=</span> {</span>
<span id="cb30-63"><a href="#cb30-63" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-4o&#34;</span>: <span>0</span>,</span>
<span id="cb30-64"><a href="#cb30-64" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-4-turbo&#34;</span>: <span>0</span>,</span>
<span id="cb30-65"><a href="#cb30-65" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-3.5-turbo&#34;</span>: <span>0</span>,</span>
<span id="cb30-66"><a href="#cb30-66" aria-hidden="true" tabindex="-1"></a>    <span>&#34;tinyllama-templatefree&#34;</span>: <span>0</span>,</span>
<span id="cb30-67"><a href="#cb30-67" aria-hidden="true" tabindex="-1"></a>    <span>&#34;tinyllama-sharegpt&#34;</span>: <span>0</span>,</span>
<span id="cb30-68"><a href="#cb30-68" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-openai-gpt-3.5-turbo-1106&#34;</span>: <span>0</span>,</span>
<span id="cb30-69"><a href="#cb30-69" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-llama3-7b-32k-openpipe&#34;</span>: <span>0</span>,</span>
<span id="cb30-70"><a href="#cb30-70" aria-hidden="true" tabindex="-1"></a>    <span>&#34;mistral-lora-templatefree&#34;</span>: <span>0</span>,</span>
<span id="cb30-71"><a href="#cb30-71" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-mistral-7b-optimised-openpipe&#34;</span>: <span>0</span>,</span>
<span id="cb30-72"><a href="#cb30-72" aria-hidden="true" tabindex="-1"></a>    <span>&#34;ft-solar-1-mini-chat-240612-predibase&#34;</span>: <span>0</span>,</span>
<span id="cb30-73"><a href="#cb30-73" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb30-74"><a href="#cb30-74" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-75"><a href="#cb30-75" aria-hidden="true" tabindex="-1"></a><span>for</span> row <span>in</span> dataset_with_preds:</span>
<span id="cb30-76"><a href="#cb30-76" aria-hidden="true" tabindex="-1"></a>    <span>for</span> model_name, pred <span>in</span> row[<span>&#34;predictions&#34;</span>].items():</span>
<span id="cb30-77"><a href="#cb30-77" aria-hidden="true" tabindex="-1"></a>        <span>if</span> <span>not</span> pred:</span>
<span id="cb30-78"><a href="#cb30-78" aria-hidden="true" tabindex="-1"></a>            <span>continue</span></span>
<span id="cb30-79"><a href="#cb30-79" aria-hidden="true" tabindex="-1"></a>        <span>try</span>:</span>
<span id="cb30-80"><a href="#cb30-80" aria-hidden="true" tabindex="-1"></a>            pred_dict <span>=</span> json.loads(pred)</span>
<span id="cb30-81"><a href="#cb30-81" aria-hidden="true" tabindex="-1"></a>            <span>if</span> <span>isinstance</span>(pred_dict, <span>dict</span>) <span>and</span> <span>&#34;event_type&#34;</span> <span>in</span> pred_dict:</span>
<span id="cb30-82"><a href="#cb30-82" aria-hidden="true" tabindex="-1"></a>                pred_types <span>=</span> pred_dict[<span>&#34;event_type&#34;</span>]</span>
<span id="cb30-83"><a href="#cb30-83" aria-hidden="true" tabindex="-1"></a>                <span>if</span> <span>isinstance</span>(pred_types, <span>str</span>):</span>
<span id="cb30-84"><a href="#cb30-84" aria-hidden="true" tabindex="-1"></a>                    pred_types <span>=</span> [pred_types]</span>
<span id="cb30-85"><a href="#cb30-85" aria-hidden="true" tabindex="-1"></a>                correct_types <span>=</span> row[<span>&#34;event_type&#34;</span>]</span>
<span id="cb30-86"><a href="#cb30-86" aria-hidden="true" tabindex="-1"></a>                <span>if</span> <span>isinstance</span>(correct_types, <span>str</span>):</span>
<span id="cb30-87"><a href="#cb30-87" aria-hidden="true" tabindex="-1"></a>                    correct_types <span>=</span> [correct_types]</span>
<span id="cb30-88"><a href="#cb30-88" aria-hidden="true" tabindex="-1"></a>                <span>if</span> correct_types:</span>
<span id="cb30-89"><a href="#cb30-89" aria-hidden="true" tabindex="-1"></a>                    score <span>=</span> <span>len</span>(<span>set</span>(pred_types) <span>&amp;</span> <span>set</span>(correct_types)) <span>/</span> <span>len</span>(</span>
<span id="cb30-90"><a href="#cb30-90" aria-hidden="true" tabindex="-1"></a>                        <span>set</span>(correct_types)</span>
<span id="cb30-91"><a href="#cb30-91" aria-hidden="true" tabindex="-1"></a>                    )</span>
<span id="cb30-92"><a href="#cb30-92" aria-hidden="true" tabindex="-1"></a>                    event_type_scores[model_name] <span>+=</span> score</span>
<span id="cb30-93"><a href="#cb30-93" aria-hidden="true" tabindex="-1"></a>        <span>except</span> (json.JSONDecodeError, <span>KeyError</span>, <span>TypeError</span>):</span>
<span id="cb30-94"><a href="#cb30-94" aria-hidden="true" tabindex="-1"></a>            <span>pass</span></span>
<span id="cb30-95"><a href="#cb30-95" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb30-96"><a href="#cb30-96" aria-hidden="true" tabindex="-1"></a>create_accuracy_chart(</span>
<span id="cb30-97"><a href="#cb30-97" aria-hidden="true" tabindex="-1"></a>    scores<span>=</span>event_type_scores,</span>
<span id="cb30-98"><a href="#cb30-98" aria-hidden="true" tabindex="-1"></a>    title<span>=</span><span>&#34;Event Type Accuracy by Model&#34;</span>,</span>
<span id="cb30-99"><a href="#cb30-99" aria-hidden="true" tabindex="-1"></a>    xlabel<span>=</span><span>&#34;Event Type Accuracy Score&#34;</span>,</span>
<span id="cb30-100"><a href="#cb30-100" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</details>
<p><img src="https://annahope.me/blog/hello-world/2024-07-01-full-finetuned-model-evaluation_files/figure-html/cell-29-output-1.png"/></p>
</div>
<p>Event type is actually one of the hardest categories since there are actually some semantically overlapping categories and it’s sometimes even hard for a human annotator, but once again the finetuned models do pretty well.</p>
</section>
<section id="accuracy-for-min_killed">

<div data-execution_count="20">
<details>
<summary>Code</summary>
<div id="cb31"><pre><code><span id="cb31-1"><a href="#cb31-1" aria-hidden="true" tabindex="-1"></a><span>import</span> json</span>
<span id="cb31-2"><a href="#cb31-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-3"><a href="#cb31-3" aria-hidden="true" tabindex="-1"></a>min_killed_scores <span>=</span> {</span>
<span id="cb31-4"><a href="#cb31-4" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-4o&#34;</span>: <span>0</span>,</span>
<span id="cb31-5"><a href="#cb31-5" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-4-turbo&#34;</span>: <span>0</span>,</span>
<span id="cb31-6"><a href="#cb31-6" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-3.5-turbo&#34;</span>: <span>0</span>,</span>
<span id="cb31-7"><a href="#cb31-7" aria-hidden="true" tabindex="-1"></a>    <span>&#34;tinyllama-templatefree&#34;</span>: <span>0</span>,</span>
<span id="cb31-8"><a href="#cb31-8" aria-hidden="true" tabindex="-1"></a>    <span>&#34;tinyllama-sharegpt&#34;</span>: <span>0</span>,</span>
<span id="cb31-9"><a href="#cb31-9" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-openai-gpt-3.5-turbo-1106&#34;</span>: <span>0</span>,</span>
<span id="cb31-10"><a href="#cb31-10" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-llama3-7b-32k-openpipe&#34;</span>: <span>0</span>,</span>
<span id="cb31-11"><a href="#cb31-11" aria-hidden="true" tabindex="-1"></a>    <span>&#34;mistral-lora-templatefree&#34;</span>: <span>0</span>,</span>
<span id="cb31-12"><a href="#cb31-12" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-mistral-7b-optimised-openpipe&#34;</span>: <span>0</span>,</span>
<span id="cb31-13"><a href="#cb31-13" aria-hidden="true" tabindex="-1"></a>    <span>&#34;ft-solar-1-mini-chat-240612-predibase&#34;</span>: <span>0</span>,</span>
<span id="cb31-14"><a href="#cb31-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb31-15"><a href="#cb31-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-16"><a href="#cb31-16" aria-hidden="true" tabindex="-1"></a><span>for</span> row <span>in</span> dataset_with_preds:</span>
<span id="cb31-17"><a href="#cb31-17" aria-hidden="true" tabindex="-1"></a>    <span>for</span> model_name, pred <span>in</span> row[<span>&#34;predictions&#34;</span>].items():</span>
<span id="cb31-18"><a href="#cb31-18" aria-hidden="true" tabindex="-1"></a>        <span>if</span> <span>not</span> pred:</span>
<span id="cb31-19"><a href="#cb31-19" aria-hidden="true" tabindex="-1"></a>            <span>continue</span></span>
<span id="cb31-20"><a href="#cb31-20" aria-hidden="true" tabindex="-1"></a>        <span>try</span>:</span>
<span id="cb31-21"><a href="#cb31-21" aria-hidden="true" tabindex="-1"></a>            pred_dict <span>=</span> json.loads(pred)</span>
<span id="cb31-22"><a href="#cb31-22" aria-hidden="true" tabindex="-1"></a>            <span>if</span> <span>isinstance</span>(pred_dict, <span>dict</span>) <span>and</span> <span>&#34;min_killed&#34;</span> <span>in</span> pred_dict:</span>
<span id="cb31-23"><a href="#cb31-23" aria-hidden="true" tabindex="-1"></a>                pred_min_killed <span>=</span> pred_dict[<span>&#34;min_killed&#34;</span>]</span>
<span id="cb31-24"><a href="#cb31-24" aria-hidden="true" tabindex="-1"></a>                correct_min_killed <span>=</span> row[<span>&#34;min_killed&#34;</span>]</span>
<span id="cb31-25"><a href="#cb31-25" aria-hidden="true" tabindex="-1"></a>                <span>if</span> pred_min_killed <span>==</span> correct_min_killed:</span>
<span id="cb31-26"><a href="#cb31-26" aria-hidden="true" tabindex="-1"></a>                    min_killed_scores[model_name] <span>+=</span> <span>1</span></span>
<span id="cb31-27"><a href="#cb31-27" aria-hidden="true" tabindex="-1"></a>        <span>except</span> (json.JSONDecodeError, <span>KeyError</span>, <span>TypeError</span>):</span>
<span id="cb31-28"><a href="#cb31-28" aria-hidden="true" tabindex="-1"></a>            <span>pass</span></span>
<span id="cb31-29"><a href="#cb31-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb31-30"><a href="#cb31-30" aria-hidden="true" tabindex="-1"></a>create_accuracy_chart(</span>
<span id="cb31-31"><a href="#cb31-31" aria-hidden="true" tabindex="-1"></a>    scores<span>=</span>min_killed_scores,</span>
<span id="cb31-32"><a href="#cb31-32" aria-hidden="true" tabindex="-1"></a>    title<span>=</span><span>&#34;&#39;min_killed&#39; Accuracy by Model&#34;</span>,</span>
<span id="cb31-33"><a href="#cb31-33" aria-hidden="true" tabindex="-1"></a>    xlabel<span>=</span><span>&#34;&#39;min_killed&#39; Accuracy Score&#34;</span></span>
<span id="cb31-34"><a href="#cb31-34" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</details>
<p><img src="https://annahope.me/blog/hello-world/2024-07-01-full-finetuned-model-evaluation_files/figure-html/cell-30-output-1.png"/></p>
</div>
<p>For these number estimations, suddenly the playing fields gets leveled between the finetuned and the OpenAI models. Mistral still comes out on top, but not by much! And it’s impressive how the OpenAI models do really well at this. I suspect this is because of the whole section in the prompt which explained the rubric that was used for annotating the examples:</p>
<blockquote>
<p>Annotation notes: A ‘faciliator’ is not a leader. If a press release states that ‘insurgents’ were detained without further details, assign a minimum number of two detained. Interpret ‘a couple’ as two. Interpret ‘several’ as at least three, even though it may sometimes refer to seven or eight. Classify the terms ‘a few’, ‘some’, ‘a group’, ‘a small group’, and ‘multiple’ as denoting at least three, even if they sometimes refer to larger numbers. Choose the smaller number if no other information is available in the press release to come up with a minimally acceptable figure. Interpret ‘numerous’ and ‘a handful’ as at least four, and ‘a large number’ as at least five.</p>
</blockquote>
</section>
<section id="accuracy-for-min_captured">

<div data-execution_count="21">
<details>
<summary>Code</summary>
<div id="cb32"><pre><code><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a><span>import</span> json</span>
<span id="cb32-2"><a href="#cb32-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-3"><a href="#cb32-3" aria-hidden="true" tabindex="-1"></a>min_captured_scores <span>=</span> {</span>
<span id="cb32-4"><a href="#cb32-4" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-4o&#34;</span>: <span>0</span>,</span>
<span id="cb32-5"><a href="#cb32-5" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-4-turbo&#34;</span>: <span>0</span>,</span>
<span id="cb32-6"><a href="#cb32-6" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-3.5-turbo&#34;</span>: <span>0</span>,</span>
<span id="cb32-7"><a href="#cb32-7" aria-hidden="true" tabindex="-1"></a>    <span>&#34;tinyllama-templatefree&#34;</span>: <span>0</span>,</span>
<span id="cb32-8"><a href="#cb32-8" aria-hidden="true" tabindex="-1"></a>    <span>&#34;tinyllama-sharegpt&#34;</span>: <span>0</span>,</span>
<span id="cb32-9"><a href="#cb32-9" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-openai-gpt-3.5-turbo-1106&#34;</span>: <span>0</span>,</span>
<span id="cb32-10"><a href="#cb32-10" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-llama3-7b-32k-openpipe&#34;</span>: <span>0</span>,</span>
<span id="cb32-11"><a href="#cb32-11" aria-hidden="true" tabindex="-1"></a>    <span>&#34;mistral-lora-templatefree&#34;</span>: <span>0</span>,</span>
<span id="cb32-12"><a href="#cb32-12" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-mistral-7b-optimised-openpipe&#34;</span>: <span>0</span>,</span>
<span id="cb32-13"><a href="#cb32-13" aria-hidden="true" tabindex="-1"></a>    <span>&#34;ft-solar-1-mini-chat-240612-predibase&#34;</span>: <span>0</span>,</span>
<span id="cb32-14"><a href="#cb32-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb32-15"><a href="#cb32-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-16"><a href="#cb32-16" aria-hidden="true" tabindex="-1"></a><span>for</span> row <span>in</span> dataset_with_preds:</span>
<span id="cb32-17"><a href="#cb32-17" aria-hidden="true" tabindex="-1"></a>    <span>for</span> model_name, pred <span>in</span> row[<span>&#34;predictions&#34;</span>].items():</span>
<span id="cb32-18"><a href="#cb32-18" aria-hidden="true" tabindex="-1"></a>        <span>if</span> <span>not</span> pred:</span>
<span id="cb32-19"><a href="#cb32-19" aria-hidden="true" tabindex="-1"></a>            <span>continue</span></span>
<span id="cb32-20"><a href="#cb32-20" aria-hidden="true" tabindex="-1"></a>        <span>try</span>:</span>
<span id="cb32-21"><a href="#cb32-21" aria-hidden="true" tabindex="-1"></a>            pred_dict <span>=</span> json.loads(pred)</span>
<span id="cb32-22"><a href="#cb32-22" aria-hidden="true" tabindex="-1"></a>            <span>if</span> <span>isinstance</span>(pred_dict, <span>dict</span>) <span>and</span> <span>&#34;min_captured&#34;</span> <span>in</span> pred_dict:</span>
<span id="cb32-23"><a href="#cb32-23" aria-hidden="true" tabindex="-1"></a>                pred_min_captured <span>=</span> pred_dict[<span>&#34;min_captured&#34;</span>]</span>
<span id="cb32-24"><a href="#cb32-24" aria-hidden="true" tabindex="-1"></a>                correct_min_captured <span>=</span> row[<span>&#34;min_captured&#34;</span>]</span>
<span id="cb32-25"><a href="#cb32-25" aria-hidden="true" tabindex="-1"></a>                <span>if</span> pred_min_captured <span>==</span> correct_min_captured:</span>
<span id="cb32-26"><a href="#cb32-26" aria-hidden="true" tabindex="-1"></a>                    min_captured_scores[model_name] <span>+=</span> <span>1</span></span>
<span id="cb32-27"><a href="#cb32-27" aria-hidden="true" tabindex="-1"></a>        <span>except</span> (json.JSONDecodeError, <span>KeyError</span>, <span>TypeError</span>):</span>
<span id="cb32-28"><a href="#cb32-28" aria-hidden="true" tabindex="-1"></a>            <span>pass</span></span>
<span id="cb32-29"><a href="#cb32-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb32-30"><a href="#cb32-30" aria-hidden="true" tabindex="-1"></a>create_accuracy_chart(</span>
<span id="cb32-31"><a href="#cb32-31" aria-hidden="true" tabindex="-1"></a>    scores<span>=</span>min_captured_scores,</span>
<span id="cb32-32"><a href="#cb32-32" aria-hidden="true" tabindex="-1"></a>    title<span>=</span><span>&#34;&#39;min_captured&#39; Accuracy by Model&#34;</span>,</span>
<span id="cb32-33"><a href="#cb32-33" aria-hidden="true" tabindex="-1"></a>    xlabel<span>=</span><span>&#34;&#39;min_captured&#39; Accuracy Score&#34;</span></span>
<span id="cb32-34"><a href="#cb32-34" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</details>
<p><img src="https://annahope.me/blog/hello-world/2024-07-01-full-finetuned-model-evaluation_files/figure-html/cell-31-output-1.png"/></p>
</div>
</section>
<section id="accuracy-for-killq">

<div data-execution_count="22">
<details>
<summary>Code</summary>
<div id="cb33"><pre><code><span id="cb33-1"><a href="#cb33-1" aria-hidden="true" tabindex="-1"></a><span>import</span> json</span>
<span id="cb33-2"><a href="#cb33-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-3"><a href="#cb33-3" aria-hidden="true" tabindex="-1"></a>killq_scores <span>=</span> {</span>
<span id="cb33-4"><a href="#cb33-4" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-4o&#34;</span>: <span>0</span>,</span>
<span id="cb33-5"><a href="#cb33-5" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-4-turbo&#34;</span>: <span>0</span>,</span>
<span id="cb33-6"><a href="#cb33-6" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-3.5-turbo&#34;</span>: <span>0</span>,</span>
<span id="cb33-7"><a href="#cb33-7" aria-hidden="true" tabindex="-1"></a>    <span>&#34;tinyllama-templatefree&#34;</span>: <span>0</span>,</span>
<span id="cb33-8"><a href="#cb33-8" aria-hidden="true" tabindex="-1"></a>    <span>&#34;tinyllama-sharegpt&#34;</span>: <span>0</span>,</span>
<span id="cb33-9"><a href="#cb33-9" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-openai-gpt-3.5-turbo-1106&#34;</span>: <span>0</span>,</span>
<span id="cb33-10"><a href="#cb33-10" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-llama3-7b-32k-openpipe&#34;</span>: <span>0</span>,</span>
<span id="cb33-11"><a href="#cb33-11" aria-hidden="true" tabindex="-1"></a>    <span>&#34;mistral-lora-templatefree&#34;</span>: <span>0</span>,</span>
<span id="cb33-12"><a href="#cb33-12" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-mistral-7b-optimised-openpipe&#34;</span>: <span>0</span>,</span>
<span id="cb33-13"><a href="#cb33-13" aria-hidden="true" tabindex="-1"></a>    <span>&#34;ft-solar-1-mini-chat-240612-predibase&#34;</span>: <span>0</span>,</span>
<span id="cb33-14"><a href="#cb33-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb33-15"><a href="#cb33-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-16"><a href="#cb33-16" aria-hidden="true" tabindex="-1"></a><span>for</span> row <span>in</span> dataset_with_preds:</span>
<span id="cb33-17"><a href="#cb33-17" aria-hidden="true" tabindex="-1"></a>    <span>for</span> model_name, pred <span>in</span> row[<span>&#34;predictions&#34;</span>].items():</span>
<span id="cb33-18"><a href="#cb33-18" aria-hidden="true" tabindex="-1"></a>        <span>if</span> <span>not</span> pred:</span>
<span id="cb33-19"><a href="#cb33-19" aria-hidden="true" tabindex="-1"></a>            <span>continue</span></span>
<span id="cb33-20"><a href="#cb33-20" aria-hidden="true" tabindex="-1"></a>        <span>try</span>:</span>
<span id="cb33-21"><a href="#cb33-21" aria-hidden="true" tabindex="-1"></a>            pred_dict <span>=</span> json.loads(pred)</span>
<span id="cb33-22"><a href="#cb33-22" aria-hidden="true" tabindex="-1"></a>            <span>if</span> <span>isinstance</span>(pred_dict, <span>dict</span>) <span>and</span> <span>&#34;killq&#34;</span> <span>in</span> pred_dict:</span>
<span id="cb33-23"><a href="#cb33-23" aria-hidden="true" tabindex="-1"></a>                pred_killq <span>=</span> pred_dict[<span>&#34;killq&#34;</span>]</span>
<span id="cb33-24"><a href="#cb33-24" aria-hidden="true" tabindex="-1"></a>                correct_killq <span>=</span> row[<span>&#34;killq&#34;</span>]</span>
<span id="cb33-25"><a href="#cb33-25" aria-hidden="true" tabindex="-1"></a>                <span>if</span> pred_killq <span>==</span> correct_killq:</span>
<span id="cb33-26"><a href="#cb33-26" aria-hidden="true" tabindex="-1"></a>                    killq_scores[model_name] <span>+=</span> <span>1</span></span>
<span id="cb33-27"><a href="#cb33-27" aria-hidden="true" tabindex="-1"></a>        <span>except</span> (json.JSONDecodeError, <span>KeyError</span>, <span>TypeError</span>):</span>
<span id="cb33-28"><a href="#cb33-28" aria-hidden="true" tabindex="-1"></a>            <span>pass</span></span>
<span id="cb33-29"><a href="#cb33-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb33-30"><a href="#cb33-30" aria-hidden="true" tabindex="-1"></a>create_accuracy_chart(</span>
<span id="cb33-31"><a href="#cb33-31" aria-hidden="true" tabindex="-1"></a>    scores<span>=</span>killq_scores,</span>
<span id="cb33-32"><a href="#cb33-32" aria-hidden="true" tabindex="-1"></a>    title<span>=</span><span>&#34;&#39;killq&#39; Accuracy by Model&#34;</span>,</span>
<span id="cb33-33"><a href="#cb33-33" aria-hidden="true" tabindex="-1"></a>    xlabel<span>=</span><span>&#34;&#39;killq&#39; Accuracy Score&#34;</span></span>
<span id="cb33-34"><a href="#cb33-34" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</details>
<p><img src="https://annahope.me/blog/hello-world/2024-07-01-full-finetuned-model-evaluation_files/figure-html/cell-32-output-1.png"/></p>
</div>
<p>I’d expect really high accuracy for these boolean attributes, and basically almost all the models were able to give this. Still, our finetuned Mistral still beats out GPT-4o best score.</p>
</section>
<section id="accuracy-for-captureq">

<div data-execution_count="23">
<details>
<summary>Code</summary>
<div id="cb34"><pre><code><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a><span>import</span> json</span>
<span id="cb34-2"><a href="#cb34-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-3"><a href="#cb34-3" aria-hidden="true" tabindex="-1"></a>captureq_scores <span>=</span> {</span>
<span id="cb34-4"><a href="#cb34-4" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-4o&#34;</span>: <span>0</span>,</span>
<span id="cb34-5"><a href="#cb34-5" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-4-turbo&#34;</span>: <span>0</span>,</span>
<span id="cb34-6"><a href="#cb34-6" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-3.5-turbo&#34;</span>: <span>0</span>,</span>
<span id="cb34-7"><a href="#cb34-7" aria-hidden="true" tabindex="-1"></a>    <span>&#34;tinyllama-templatefree&#34;</span>: <span>0</span>,</span>
<span id="cb34-8"><a href="#cb34-8" aria-hidden="true" tabindex="-1"></a>    <span>&#34;tinyllama-sharegpt&#34;</span>: <span>0</span>,</span>
<span id="cb34-9"><a href="#cb34-9" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-openai-gpt-3.5-turbo-1106&#34;</span>: <span>0</span>,</span>
<span id="cb34-10"><a href="#cb34-10" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-llama3-7b-32k-openpipe&#34;</span>: <span>0</span>,</span>
<span id="cb34-11"><a href="#cb34-11" aria-hidden="true" tabindex="-1"></a>    <span>&#34;mistral-lora-templatefree&#34;</span>: <span>0</span>,</span>
<span id="cb34-12"><a href="#cb34-12" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-mistral-7b-optimised-openpipe&#34;</span>: <span>0</span>,</span>
<span id="cb34-13"><a href="#cb34-13" aria-hidden="true" tabindex="-1"></a>    <span>&#34;ft-solar-1-mini-chat-240612-predibase&#34;</span>: <span>0</span>,</span>
<span id="cb34-14"><a href="#cb34-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb34-15"><a href="#cb34-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-16"><a href="#cb34-16" aria-hidden="true" tabindex="-1"></a><span>for</span> row <span>in</span> dataset_with_preds:</span>
<span id="cb34-17"><a href="#cb34-17" aria-hidden="true" tabindex="-1"></a>    <span>for</span> model_name, pred <span>in</span> row[<span>&#34;predictions&#34;</span>].items():</span>
<span id="cb34-18"><a href="#cb34-18" aria-hidden="true" tabindex="-1"></a>        <span>if</span> <span>not</span> pred:</span>
<span id="cb34-19"><a href="#cb34-19" aria-hidden="true" tabindex="-1"></a>            <span>continue</span></span>
<span id="cb34-20"><a href="#cb34-20" aria-hidden="true" tabindex="-1"></a>        <span>try</span>:</span>
<span id="cb34-21"><a href="#cb34-21" aria-hidden="true" tabindex="-1"></a>            pred_dict <span>=</span> json.loads(pred)</span>
<span id="cb34-22"><a href="#cb34-22" aria-hidden="true" tabindex="-1"></a>            <span>if</span> <span>isinstance</span>(pred_dict, <span>dict</span>) <span>and</span> <span>&#34;captureq&#34;</span> <span>in</span> pred_dict:</span>
<span id="cb34-23"><a href="#cb34-23" aria-hidden="true" tabindex="-1"></a>                pred_captureq <span>=</span> pred_dict[<span>&#34;captureq&#34;</span>]</span>
<span id="cb34-24"><a href="#cb34-24" aria-hidden="true" tabindex="-1"></a>                correct_captureq <span>=</span> row[<span>&#34;captureq&#34;</span>]</span>
<span id="cb34-25"><a href="#cb34-25" aria-hidden="true" tabindex="-1"></a>                <span>if</span> pred_captureq <span>==</span> correct_captureq:</span>
<span id="cb34-26"><a href="#cb34-26" aria-hidden="true" tabindex="-1"></a>                    captureq_scores[model_name] <span>+=</span> <span>1</span></span>
<span id="cb34-27"><a href="#cb34-27" aria-hidden="true" tabindex="-1"></a>        <span>except</span> (json.JSONDecodeError, <span>KeyError</span>, <span>TypeError</span>):</span>
<span id="cb34-28"><a href="#cb34-28" aria-hidden="true" tabindex="-1"></a>            <span>pass</span></span>
<span id="cb34-29"><a href="#cb34-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb34-30"><a href="#cb34-30" aria-hidden="true" tabindex="-1"></a>create_accuracy_chart(</span>
<span id="cb34-31"><a href="#cb34-31" aria-hidden="true" tabindex="-1"></a>    scores<span>=</span>captureq_scores,</span>
<span id="cb34-32"><a href="#cb34-32" aria-hidden="true" tabindex="-1"></a>    title<span>=</span><span>&#34;&#39;captureq&#39; Accuracy by Model&#34;</span>,</span>
<span id="cb34-33"><a href="#cb34-33" aria-hidden="true" tabindex="-1"></a>    xlabel<span>=</span><span>&#34;&#39;captureq&#39; Accuracy Score&#34;</span></span>
<span id="cb34-34"><a href="#cb34-34" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</details>
<p><img src="https://annahope.me/blog/hello-world/2024-07-01-full-finetuned-model-evaluation_files/figure-html/cell-33-output-1.png"/></p>
</div>
</section>
<section id="accuracy-for-killcaptureraid">

<div data-execution_count="24">
<details>
<summary>Code</summary>
<div id="cb35"><pre><code><span id="cb35-1"><a href="#cb35-1" aria-hidden="true" tabindex="-1"></a><span>import</span> json</span>
<span id="cb35-2"><a href="#cb35-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-3"><a href="#cb35-3" aria-hidden="true" tabindex="-1"></a>killcaptureraid_scores <span>=</span> {</span>
<span id="cb35-4"><a href="#cb35-4" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-4o&#34;</span>: <span>0</span>,</span>
<span id="cb35-5"><a href="#cb35-5" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-4-turbo&#34;</span>: <span>0</span>,</span>
<span id="cb35-6"><a href="#cb35-6" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-3.5-turbo&#34;</span>: <span>0</span>,</span>
<span id="cb35-7"><a href="#cb35-7" aria-hidden="true" tabindex="-1"></a>    <span>&#34;tinyllama-templatefree&#34;</span>: <span>0</span>,</span>
<span id="cb35-8"><a href="#cb35-8" aria-hidden="true" tabindex="-1"></a>    <span>&#34;tinyllama-sharegpt&#34;</span>: <span>0</span>,</span>
<span id="cb35-9"><a href="#cb35-9" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-openai-gpt-3.5-turbo-1106&#34;</span>: <span>0</span>,</span>
<span id="cb35-10"><a href="#cb35-10" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-llama3-7b-32k-openpipe&#34;</span>: <span>0</span>,</span>
<span id="cb35-11"><a href="#cb35-11" aria-hidden="true" tabindex="-1"></a>    <span>&#34;mistral-lora-templatefree&#34;</span>: <span>0</span>,</span>
<span id="cb35-12"><a href="#cb35-12" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-mistral-7b-optimised-openpipe&#34;</span>: <span>0</span>,</span>
<span id="cb35-13"><a href="#cb35-13" aria-hidden="true" tabindex="-1"></a>    <span>&#34;ft-solar-1-mini-chat-240612-predibase&#34;</span>: <span>0</span>,</span>
<span id="cb35-14"><a href="#cb35-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb35-15"><a href="#cb35-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-16"><a href="#cb35-16" aria-hidden="true" tabindex="-1"></a><span>for</span> row <span>in</span> dataset_with_preds:</span>
<span id="cb35-17"><a href="#cb35-17" aria-hidden="true" tabindex="-1"></a>    <span>for</span> model_name, pred <span>in</span> row[<span>&#34;predictions&#34;</span>].items():</span>
<span id="cb35-18"><a href="#cb35-18" aria-hidden="true" tabindex="-1"></a>        <span>if</span> <span>not</span> pred:</span>
<span id="cb35-19"><a href="#cb35-19" aria-hidden="true" tabindex="-1"></a>            <span>continue</span></span>
<span id="cb35-20"><a href="#cb35-20" aria-hidden="true" tabindex="-1"></a>        <span>try</span>:</span>
<span id="cb35-21"><a href="#cb35-21" aria-hidden="true" tabindex="-1"></a>            pred_dict <span>=</span> json.loads(pred)</span>
<span id="cb35-22"><a href="#cb35-22" aria-hidden="true" tabindex="-1"></a>            <span>if</span> <span>isinstance</span>(pred_dict, <span>dict</span>) <span>and</span> <span>&#34;killcaptureraid&#34;</span> <span>in</span> pred_dict:</span>
<span id="cb35-23"><a href="#cb35-23" aria-hidden="true" tabindex="-1"></a>                pred_killcaptureraid <span>=</span> pred_dict[<span>&#34;killcaptureraid&#34;</span>]</span>
<span id="cb35-24"><a href="#cb35-24" aria-hidden="true" tabindex="-1"></a>                correct_killcaptureraid <span>=</span> row[<span>&#34;killcaptureraid&#34;</span>]</span>
<span id="cb35-25"><a href="#cb35-25" aria-hidden="true" tabindex="-1"></a>                <span>if</span> pred_killcaptureraid <span>==</span> correct_killcaptureraid:</span>
<span id="cb35-26"><a href="#cb35-26" aria-hidden="true" tabindex="-1"></a>                    killcaptureraid_scores[model_name] <span>+=</span> <span>1</span></span>
<span id="cb35-27"><a href="#cb35-27" aria-hidden="true" tabindex="-1"></a>        <span>except</span> (json.JSONDecodeError, <span>KeyError</span>, <span>TypeError</span>):</span>
<span id="cb35-28"><a href="#cb35-28" aria-hidden="true" tabindex="-1"></a>            <span>pass</span></span>
<span id="cb35-29"><a href="#cb35-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb35-30"><a href="#cb35-30" aria-hidden="true" tabindex="-1"></a>create_accuracy_chart(</span>
<span id="cb35-31"><a href="#cb35-31" aria-hidden="true" tabindex="-1"></a>    scores<span>=</span>killcaptureraid_scores,</span>
<span id="cb35-32"><a href="#cb35-32" aria-hidden="true" tabindex="-1"></a>    title<span>=</span><span>&#34;&#39;killcaptureraid&#39; Accuracy by Model&#34;</span>,</span>
<span id="cb35-33"><a href="#cb35-33" aria-hidden="true" tabindex="-1"></a>    xlabel<span>=</span><span>&#34;&#39;killcaptureraid&#39; Accuracy Score&#34;</span></span>
<span id="cb35-34"><a href="#cb35-34" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</details>
<p><img src="https://annahope.me/blog/hello-world/2024-07-01-full-finetuned-model-evaluation_files/figure-html/cell-34-output-1.png"/></p>
</div>
<p>This is another attribute where it’s clear the lack of signposting in the prompts to the OpenAI models put them at a disadvantage. The term ‘kill-capture raid’ is a term of art and it was used in a specific way for the labelling. OpenAI knows nothing about how I made those calls, which explains why they performed so poorly here.</p>
</section>
<section id="accuracy-for-airstrike">

<div data-execution_count="25">
<details>
<summary>Code</summary>
<div id="cb36"><pre><code><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a><span>import</span> json</span>
<span id="cb36-2"><a href="#cb36-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-3"><a href="#cb36-3" aria-hidden="true" tabindex="-1"></a>airstrike_scores <span>=</span> {</span>
<span id="cb36-4"><a href="#cb36-4" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-4o&#34;</span>: <span>0</span>,</span>
<span id="cb36-5"><a href="#cb36-5" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-4-turbo&#34;</span>: <span>0</span>,</span>
<span id="cb36-6"><a href="#cb36-6" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-3.5-turbo&#34;</span>: <span>0</span>,</span>
<span id="cb36-7"><a href="#cb36-7" aria-hidden="true" tabindex="-1"></a>    <span>&#34;tinyllama-templatefree&#34;</span>: <span>0</span>,</span>
<span id="cb36-8"><a href="#cb36-8" aria-hidden="true" tabindex="-1"></a>    <span>&#34;tinyllama-sharegpt&#34;</span>: <span>0</span>,</span>
<span id="cb36-9"><a href="#cb36-9" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-openai-gpt-3.5-turbo-1106&#34;</span>: <span>0</span>,</span>
<span id="cb36-10"><a href="#cb36-10" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-llama3-7b-32k-openpipe&#34;</span>: <span>0</span>,</span>
<span id="cb36-11"><a href="#cb36-11" aria-hidden="true" tabindex="-1"></a>    <span>&#34;mistral-lora-templatefree&#34;</span>: <span>0</span>,</span>
<span id="cb36-12"><a href="#cb36-12" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-mistral-7b-optimised-openpipe&#34;</span>: <span>0</span>,</span>
<span id="cb36-13"><a href="#cb36-13" aria-hidden="true" tabindex="-1"></a>    <span>&#34;ft-solar-1-mini-chat-240612-predibase&#34;</span>: <span>0</span>,</span>
<span id="cb36-14"><a href="#cb36-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb36-15"><a href="#cb36-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-16"><a href="#cb36-16" aria-hidden="true" tabindex="-1"></a><span>for</span> row <span>in</span> dataset_with_preds:</span>
<span id="cb36-17"><a href="#cb36-17" aria-hidden="true" tabindex="-1"></a>    <span>for</span> model_name, pred <span>in</span> row[<span>&#34;predictions&#34;</span>].items():</span>
<span id="cb36-18"><a href="#cb36-18" aria-hidden="true" tabindex="-1"></a>        <span>if</span> <span>not</span> pred:</span>
<span id="cb36-19"><a href="#cb36-19" aria-hidden="true" tabindex="-1"></a>            <span>continue</span></span>
<span id="cb36-20"><a href="#cb36-20" aria-hidden="true" tabindex="-1"></a>        <span>try</span>:</span>
<span id="cb36-21"><a href="#cb36-21" aria-hidden="true" tabindex="-1"></a>            pred_dict <span>=</span> json.loads(pred)</span>
<span id="cb36-22"><a href="#cb36-22" aria-hidden="true" tabindex="-1"></a>            <span>if</span> <span>isinstance</span>(pred_dict, <span>dict</span>) <span>and</span> <span>&#34;airstrike&#34;</span> <span>in</span> pred_dict:</span>
<span id="cb36-23"><a href="#cb36-23" aria-hidden="true" tabindex="-1"></a>                pred_airstrike <span>=</span> pred_dict[<span>&#34;airstrike&#34;</span>]</span>
<span id="cb36-24"><a href="#cb36-24" aria-hidden="true" tabindex="-1"></a>                correct_airstrike <span>=</span> row[<span>&#34;airstrike&#34;</span>]</span>
<span id="cb36-25"><a href="#cb36-25" aria-hidden="true" tabindex="-1"></a>                <span>if</span> pred_airstrike <span>==</span> correct_airstrike:</span>
<span id="cb36-26"><a href="#cb36-26" aria-hidden="true" tabindex="-1"></a>                    airstrike_scores[model_name] <span>+=</span> <span>1</span></span>
<span id="cb36-27"><a href="#cb36-27" aria-hidden="true" tabindex="-1"></a>        <span>except</span> (json.JSONDecodeError, <span>KeyError</span>, <span>TypeError</span>):</span>
<span id="cb36-28"><a href="#cb36-28" aria-hidden="true" tabindex="-1"></a>            <span>pass</span></span>
<span id="cb36-29"><a href="#cb36-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb36-30"><a href="#cb36-30" aria-hidden="true" tabindex="-1"></a>create_accuracy_chart(</span>
<span id="cb36-31"><a href="#cb36-31" aria-hidden="true" tabindex="-1"></a>    scores<span>=</span>airstrike_scores,</span>
<span id="cb36-32"><a href="#cb36-32" aria-hidden="true" tabindex="-1"></a>    title<span>=</span><span>&#34;&#39;airstrike&#39; Accuracy by Model&#34;</span>,</span>
<span id="cb36-33"><a href="#cb36-33" aria-hidden="true" tabindex="-1"></a>    xlabel<span>=</span><span>&#34;&#39;airstrike&#39; Accuracy Score&#34;</span></span>
<span id="cb36-34"><a href="#cb36-34" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</details>
<p><img src="https://annahope.me/blog/hello-world/2024-07-01-full-finetuned-model-evaluation_files/figure-html/cell-35-output-1.png"/></p>
</div>
</section>
<section id="accuracy-for-noshotsfired">

<div data-execution_count="26">
<details>
<summary>Code</summary>
<div id="cb37"><pre><code><span id="cb37-1"><a href="#cb37-1" aria-hidden="true" tabindex="-1"></a><span>import</span> json</span>
<span id="cb37-2"><a href="#cb37-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-3"><a href="#cb37-3" aria-hidden="true" tabindex="-1"></a>noshotsfired_scores <span>=</span> {</span>
<span id="cb37-4"><a href="#cb37-4" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-4o&#34;</span>: <span>0</span>,</span>
<span id="cb37-5"><a href="#cb37-5" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-4-turbo&#34;</span>: <span>0</span>,</span>
<span id="cb37-6"><a href="#cb37-6" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-3.5-turbo&#34;</span>: <span>0</span>,</span>
<span id="cb37-7"><a href="#cb37-7" aria-hidden="true" tabindex="-1"></a>    <span>&#34;tinyllama-templatefree&#34;</span>: <span>0</span>,</span>
<span id="cb37-8"><a href="#cb37-8" aria-hidden="true" tabindex="-1"></a>    <span>&#34;tinyllama-sharegpt&#34;</span>: <span>0</span>,</span>
<span id="cb37-9"><a href="#cb37-9" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-openai-gpt-3.5-turbo-1106&#34;</span>: <span>0</span>,</span>
<span id="cb37-10"><a href="#cb37-10" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-llama3-7b-32k-openpipe&#34;</span>: <span>0</span>,</span>
<span id="cb37-11"><a href="#cb37-11" aria-hidden="true" tabindex="-1"></a>    <span>&#34;mistral-lora-templatefree&#34;</span>: <span>0</span>,</span>
<span id="cb37-12"><a href="#cb37-12" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-mistral-7b-optimised-openpipe&#34;</span>: <span>0</span>,</span>
<span id="cb37-13"><a href="#cb37-13" aria-hidden="true" tabindex="-1"></a>    <span>&#34;ft-solar-1-mini-chat-240612-predibase&#34;</span>: <span>0</span>,</span>
<span id="cb37-14"><a href="#cb37-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb37-15"><a href="#cb37-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-16"><a href="#cb37-16" aria-hidden="true" tabindex="-1"></a><span>for</span> row <span>in</span> dataset_with_preds:</span>
<span id="cb37-17"><a href="#cb37-17" aria-hidden="true" tabindex="-1"></a>    <span>for</span> model_name, pred <span>in</span> row[<span>&#34;predictions&#34;</span>].items():</span>
<span id="cb37-18"><a href="#cb37-18" aria-hidden="true" tabindex="-1"></a>        <span>if</span> <span>not</span> pred:</span>
<span id="cb37-19"><a href="#cb37-19" aria-hidden="true" tabindex="-1"></a>            <span>continue</span></span>
<span id="cb37-20"><a href="#cb37-20" aria-hidden="true" tabindex="-1"></a>        <span>try</span>:</span>
<span id="cb37-21"><a href="#cb37-21" aria-hidden="true" tabindex="-1"></a>            pred_dict <span>=</span> json.loads(pred)</span>
<span id="cb37-22"><a href="#cb37-22" aria-hidden="true" tabindex="-1"></a>            <span>if</span> <span>isinstance</span>(pred_dict, <span>dict</span>) <span>and</span> <span>&#34;noshotsfired&#34;</span> <span>in</span> pred_dict:</span>
<span id="cb37-23"><a href="#cb37-23" aria-hidden="true" tabindex="-1"></a>                pred_noshotsfired <span>=</span> pred_dict[<span>&#34;noshotsfired&#34;</span>]</span>
<span id="cb37-24"><a href="#cb37-24" aria-hidden="true" tabindex="-1"></a>                correct_noshotsfired <span>=</span> row[<span>&#34;noshotsfired&#34;</span>]</span>
<span id="cb37-25"><a href="#cb37-25" aria-hidden="true" tabindex="-1"></a>                <span>if</span> pred_noshotsfired <span>==</span> correct_noshotsfired:</span>
<span id="cb37-26"><a href="#cb37-26" aria-hidden="true" tabindex="-1"></a>                    noshotsfired_scores[model_name] <span>+=</span> <span>1</span></span>
<span id="cb37-27"><a href="#cb37-27" aria-hidden="true" tabindex="-1"></a>        <span>except</span> (json.JSONDecodeError, <span>KeyError</span>, <span>TypeError</span>):</span>
<span id="cb37-28"><a href="#cb37-28" aria-hidden="true" tabindex="-1"></a>            <span>pass</span></span>
<span id="cb37-29"><a href="#cb37-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb37-30"><a href="#cb37-30" aria-hidden="true" tabindex="-1"></a>create_accuracy_chart(</span>
<span id="cb37-31"><a href="#cb37-31" aria-hidden="true" tabindex="-1"></a>    scores<span>=</span>noshotsfired_scores,</span>
<span id="cb37-32"><a href="#cb37-32" aria-hidden="true" tabindex="-1"></a>    title<span>=</span><span>&#34;&#39;noshotsfired&#39; Accuracy by Model&#34;</span>,</span>
<span id="cb37-33"><a href="#cb37-33" aria-hidden="true" tabindex="-1"></a>    xlabel<span>=</span><span>&#34;&#39;noshotsfired&#39; Accuracy Score&#34;</span></span>
<span id="cb37-34"><a href="#cb37-34" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</details>
<p><img src="https://annahope.me/blog/hello-world/2024-07-01-full-finetuned-model-evaluation_files/figure-html/cell-36-output-1.png"/></p>
</div>
<p>I’m not quite sure why the OpenAI models are performing in the reverse order of what you’d expect. Recall that the <code>noshotsfired</code> attribute refers to whether the press release states that no shots were fired during a particular raid / event. (For a certain period the press releases were keen to mention this and it was a metric that was particularly useful for ISAF as a public relations gimmick.)</p>
<p>I can think of some semi-anthropomorphizing ways to explain this around how the GPT-4 class of models were ‘overthinking’ the label, but more investigation would be needed to really understand this.</p>
</section>
<section id="accuracy-for-min_leaders_killed">

<div data-execution_count="27">
<details>
<summary>Code</summary>
<div id="cb38"><pre><code><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span>import</span> json</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>min_leaders_killed_scores <span>=</span> {</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-4o&#34;</span>: <span>0</span>,</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-4-turbo&#34;</span>: <span>0</span>,</span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-3.5-turbo&#34;</span>: <span>0</span>,</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>    <span>&#34;tinyllama-templatefree&#34;</span>: <span>0</span>,</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>    <span>&#34;tinyllama-sharegpt&#34;</span>: <span>0</span>,</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-openai-gpt-3.5-turbo-1106&#34;</span>: <span>0</span>,</span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-llama3-7b-32k-openpipe&#34;</span>: <span>0</span>,</span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>    <span>&#34;mistral-lora-templatefree&#34;</span>: <span>0</span>,</span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-mistral-7b-optimised-openpipe&#34;</span>: <span>0</span>,</span>
<span id="cb38-13"><a href="#cb38-13" aria-hidden="true" tabindex="-1"></a>    <span>&#34;ft-solar-1-mini-chat-240612-predibase&#34;</span>: <span>0</span>,</span>
<span id="cb38-14"><a href="#cb38-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb38-15"><a href="#cb38-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-16"><a href="#cb38-16" aria-hidden="true" tabindex="-1"></a><span>for</span> row <span>in</span> dataset_with_preds:</span>
<span id="cb38-17"><a href="#cb38-17" aria-hidden="true" tabindex="-1"></a>    <span>for</span> model_name, pred <span>in</span> row[<span>&#34;predictions&#34;</span>].items():</span>
<span id="cb38-18"><a href="#cb38-18" aria-hidden="true" tabindex="-1"></a>        <span>if</span> <span>not</span> pred:</span>
<span id="cb38-19"><a href="#cb38-19" aria-hidden="true" tabindex="-1"></a>            <span>continue</span></span>
<span id="cb38-20"><a href="#cb38-20" aria-hidden="true" tabindex="-1"></a>        <span>try</span>:</span>
<span id="cb38-21"><a href="#cb38-21" aria-hidden="true" tabindex="-1"></a>            pred_dict <span>=</span> json.loads(pred)</span>
<span id="cb38-22"><a href="#cb38-22" aria-hidden="true" tabindex="-1"></a>            <span>if</span> <span>isinstance</span>(pred_dict, <span>dict</span>) <span>and</span> <span>&#34;min_leaders_killed&#34;</span> <span>in</span> pred_dict:</span>
<span id="cb38-23"><a href="#cb38-23" aria-hidden="true" tabindex="-1"></a>                pred_min_leaders_killed <span>=</span> pred_dict[<span>&#34;min_leaders_killed&#34;</span>]</span>
<span id="cb38-24"><a href="#cb38-24" aria-hidden="true" tabindex="-1"></a>                correct_min_leaders_killed <span>=</span> row[<span>&#34;min_leaders_killed&#34;</span>]</span>
<span id="cb38-25"><a href="#cb38-25" aria-hidden="true" tabindex="-1"></a>                <span>if</span> <span>isinstance</span>(pred_min_leaders_killed, <span>int</span>) <span>and</span> <span>isinstance</span>(correct_min_leaders_killed, <span>int</span>):</span>
<span id="cb38-26"><a href="#cb38-26" aria-hidden="true" tabindex="-1"></a>                    <span>if</span> pred_min_leaders_killed <span>==</span> correct_min_leaders_killed:</span>
<span id="cb38-27"><a href="#cb38-27" aria-hidden="true" tabindex="-1"></a>                        min_leaders_killed_scores[model_name] <span>+=</span> <span>1</span></span>
<span id="cb38-28"><a href="#cb38-28" aria-hidden="true" tabindex="-1"></a>        <span>except</span> (json.JSONDecodeError, <span>KeyError</span>, <span>TypeError</span>):</span>
<span id="cb38-29"><a href="#cb38-29" aria-hidden="true" tabindex="-1"></a>            <span>pass</span></span>
<span id="cb38-30"><a href="#cb38-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-31"><a href="#cb38-31" aria-hidden="true" tabindex="-1"></a>total_entries <span>=</span> <span>len</span>(dataset_with_preds)</span>
<span id="cb38-32"><a href="#cb38-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-33"><a href="#cb38-33" aria-hidden="true" tabindex="-1"></a>create_accuracy_chart(</span>
<span id="cb38-34"><a href="#cb38-34" aria-hidden="true" tabindex="-1"></a>    scores<span>=</span>min_leaders_killed_scores,</span>
<span id="cb38-35"><a href="#cb38-35" aria-hidden="true" tabindex="-1"></a>    title<span>=</span><span>f&#34;Min Leaders Killed Accuracy by Model (out of </span><span>{</span>total_entries<span>}</span><span> entries)&#34;</span>,</span>
<span id="cb38-36"><a href="#cb38-36" aria-hidden="true" tabindex="-1"></a>    xlabel<span>=</span><span>&#34;Min Leaders Killed Accuracy Score&#34;</span></span>
<span id="cb38-37"><a href="#cb38-37" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</details>
<p><img src="https://annahope.me/blog/hello-world/2024-07-01-full-finetuned-model-evaluation_files/figure-html/cell-37-output-1.png"/></p>
</div>
<p>We often hear about how LLMs are bad with numbers, how they <a href="https://gramener.com/llmrandom/">default to certain values</a> and so on, so I was surprised to see such high scores across the board for this task. I imagine this is something that everyone has been trying to improve and it shows. Still, though, our finetuned models do best.</p>
</section>
<section id="accuracy-for-min_leaders_captured">

<div data-execution_count="28">
<details>
<summary>Code</summary>
<div id="cb39"><pre><code><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span>import</span> json</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>min_leaders_captured_scores <span>=</span> {</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-4o&#34;</span>: <span>0</span>,</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-4-turbo&#34;</span>: <span>0</span>,</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a>    <span>&#34;gpt-3.5-turbo&#34;</span>: <span>0</span>,</span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>    <span>&#34;tinyllama-templatefree&#34;</span>: <span>0</span>,</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>    <span>&#34;tinyllama-sharegpt&#34;</span>: <span>0</span>,</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-openai-gpt-3.5-turbo-1106&#34;</span>: <span>0</span>,</span>
<span id="cb39-10"><a href="#cb39-10" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-llama3-7b-32k-openpipe&#34;</span>: <span>0</span>,</span>
<span id="cb39-11"><a href="#cb39-11" aria-hidden="true" tabindex="-1"></a>    <span>&#34;mistral-lora-templatefree&#34;</span>: <span>0</span>,</span>
<span id="cb39-12"><a href="#cb39-12" aria-hidden="true" tabindex="-1"></a>    <span>&#34;finetuned-mistral-7b-optimised-openpipe&#34;</span>: <span>0</span>,</span>
<span id="cb39-13"><a href="#cb39-13" aria-hidden="true" tabindex="-1"></a>    <span>&#34;ft-solar-1-mini-chat-240612-predibase&#34;</span>: <span>0</span>,</span>
<span id="cb39-14"><a href="#cb39-14" aria-hidden="true" tabindex="-1"></a>}</span>
<span id="cb39-15"><a href="#cb39-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-16"><a href="#cb39-16" aria-hidden="true" tabindex="-1"></a><span>for</span> row <span>in</span> dataset_with_preds:</span>
<span id="cb39-17"><a href="#cb39-17" aria-hidden="true" tabindex="-1"></a>    <span>for</span> model_name, pred <span>in</span> row[<span>&#34;predictions&#34;</span>].items():</span>
<span id="cb39-18"><a href="#cb39-18" aria-hidden="true" tabindex="-1"></a>        <span>if</span> <span>not</span> pred:</span>
<span id="cb39-19"><a href="#cb39-19" aria-hidden="true" tabindex="-1"></a>            <span>continue</span></span>
<span id="cb39-20"><a href="#cb39-20" aria-hidden="true" tabindex="-1"></a>        <span>try</span>:</span>
<span id="cb39-21"><a href="#cb39-21" aria-hidden="true" tabindex="-1"></a>            pred_dict <span>=</span> json.loads(pred)</span>
<span id="cb39-22"><a href="#cb39-22" aria-hidden="true" tabindex="-1"></a>            <span>if</span> <span>isinstance</span>(pred_dict, <span>dict</span>) <span>and</span> <span>&#34;min_leaders_captured&#34;</span> <span>in</span> pred_dict:</span>
<span id="cb39-23"><a href="#cb39-23" aria-hidden="true" tabindex="-1"></a>                pred_min_leaders_captured <span>=</span> pred_dict[<span>&#34;min_leaders_captured&#34;</span>]</span>
<span id="cb39-24"><a href="#cb39-24" aria-hidden="true" tabindex="-1"></a>                correct_min_leaders_captured <span>=</span> row[<span>&#34;min_leaders_captured&#34;</span>]</span>
<span id="cb39-25"><a href="#cb39-25" aria-hidden="true" tabindex="-1"></a>                <span>if</span> <span>isinstance</span>(pred_min_leaders_captured, <span>int</span>) <span>and</span> <span>isinstance</span>(correct_min_leaders_captured, <span>int</span>):</span>
<span id="cb39-26"><a href="#cb39-26" aria-hidden="true" tabindex="-1"></a>                    <span>if</span> pred_min_leaders_captured <span>==</span> correct_min_leaders_captured:</span>
<span id="cb39-27"><a href="#cb39-27" aria-hidden="true" tabindex="-1"></a>                        min_leaders_captured_scores[model_name] <span>+=</span> <span>1</span></span>
<span id="cb39-28"><a href="#cb39-28" aria-hidden="true" tabindex="-1"></a>        <span>except</span> (json.JSONDecodeError, <span>KeyError</span>, <span>TypeError</span>):</span>
<span id="cb39-29"><a href="#cb39-29" aria-hidden="true" tabindex="-1"></a>            <span>pass</span></span>
<span id="cb39-30"><a href="#cb39-30" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-31"><a href="#cb39-31" aria-hidden="true" tabindex="-1"></a>total_entries <span>=</span> <span>len</span>(dataset_with_preds)</span>
<span id="cb39-32"><a href="#cb39-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-33"><a href="#cb39-33" aria-hidden="true" tabindex="-1"></a>create_accuracy_chart(</span>
<span id="cb39-34"><a href="#cb39-34" aria-hidden="true" tabindex="-1"></a>    scores<span>=</span>min_leaders_captured_scores,</span>
<span id="cb39-35"><a href="#cb39-35" aria-hidden="true" tabindex="-1"></a>    title<span>=</span><span>f&#34;Min Leaders Captured Accuracy by Model (out of </span><span>{</span>total_entries<span>}</span><span> entries)&#34;</span>,</span>
<span id="cb39-36"><a href="#cb39-36" aria-hidden="true" tabindex="-1"></a>    xlabel<span>=</span><span>&#34;Min Leaders Captured Accuracy Score&#34;</span></span>
<span id="cb39-37"><a href="#cb39-37" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</details>
<p><img src="https://annahope.me/blog/hello-world/2024-07-01-full-finetuned-model-evaluation_files/figure-html/cell-38-output-1.png"/></p>
</div>
</section>
<section id="final-aggregate-scores-for-the-models">

<p>Let’s add all these individual competency scores up, average them out and get final scores for how well our models do on accuracy.</p>
<div data-execution_count="29">
<details>
<summary>Code</summary>
<div id="cb40"><pre><code><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a><span># adapt the function slightly</span></span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a><span>import</span> matplotlib.pyplot <span>as</span> plt</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a><span>from</span> matplotlib.patches <span>import</span> Patch</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a><span>from</span> typing <span>import</span> Dict, Union</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a><span>def</span> create_aggregate_accuracy_chart(</span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>    scores: Dict[<span>str</span>, Union[<span>int</span>, <span>float</span>]], title: <span>str</span>, xlabel: <span>str</span></span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a>) <span>-&gt;</span> <span>None</span>:</span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>    <span># Separate GPT models and finetuned models</span></span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a>    gpt_models <span>=</span> [<span>&#34;gpt-4o&#34;</span>, <span>&#34;gpt-4-turbo&#34;</span>, <span>&#34;gpt-3.5-turbo&#34;</span>]</span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a>    finetuned_models <span>=</span> [model <span>for</span> model <span>in</span> scores.keys() <span>if</span> model <span>not</span> <span>in</span> gpt_models]</span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a>    <span># Create lists for plotting</span></span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a>    models <span>=</span> <span>list</span>(scores.keys())</span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a>    scores_list <span>=</span> <span>list</span>(scores.values())</span>
<span id="cb40-17"><a href="#cb40-17" aria-hidden="true" tabindex="-1"></a>    colors <span>=</span> [<span>&#34;#1f77b4&#34;</span> <span>if</span> model <span>in</span> gpt_models <span>else</span> <span>&#34;#ff7f0e&#34;</span> <span>for</span> model <span>in</span> models]</span>
<span id="cb40-18"><a href="#cb40-18" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-19"><a href="#cb40-19" aria-hidden="true" tabindex="-1"></a>    <span># Create the plot</span></span>
<span id="cb40-20"><a href="#cb40-20" aria-hidden="true" tabindex="-1"></a>    fig, ax <span>=</span> plt.subplots(figsize<span>=</span>(<span>12</span>, <span>10</span>))</span>
<span id="cb40-21"><a href="#cb40-21" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-22"><a href="#cb40-22" aria-hidden="true" tabindex="-1"></a>    <span># Plot horizontal bars</span></span>
<span id="cb40-23"><a href="#cb40-23" aria-hidden="true" tabindex="-1"></a>    bars <span>=</span> ax.barh(models, scores_list, color<span>=</span>colors)</span>
<span id="cb40-24"><a href="#cb40-24" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-25"><a href="#cb40-25" aria-hidden="true" tabindex="-1"></a>    <span># Customize the plot</span></span>
<span id="cb40-26"><a href="#cb40-26" aria-hidden="true" tabindex="-1"></a>    ax.set_xlabel(xlabel)</span>
<span id="cb40-27"><a href="#cb40-27" aria-hidden="true" tabindex="-1"></a>    ax.set_title(title)</span>
<span id="cb40-28"><a href="#cb40-28" aria-hidden="true" tabindex="-1"></a>    ax.set_xlim(<span>0</span>, <span>100</span>)  <span># Set x-axis limit to 100</span></span>
<span id="cb40-29"><a href="#cb40-29" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-30"><a href="#cb40-30" aria-hidden="true" tabindex="-1"></a>    <span># Reduce font size for y-axis labels (model names)</span></span>
<span id="cb40-31"><a href="#cb40-31" aria-hidden="true" tabindex="-1"></a>    ax.tick_params(axis<span>=</span><span>&#34;y&#34;</span>, labelsize<span>=</span><span>8</span>)</span>
<span id="cb40-32"><a href="#cb40-32" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-33"><a href="#cb40-33" aria-hidden="true" tabindex="-1"></a>    <span># Add value labels at the end of each bar</span></span>
<span id="cb40-34"><a href="#cb40-34" aria-hidden="true" tabindex="-1"></a>    <span>for</span> bar <span>in</span> bars:</span>
<span id="cb40-35"><a href="#cb40-35" aria-hidden="true" tabindex="-1"></a>        width <span>=</span> bar.get_width()</span>
<span id="cb40-36"><a href="#cb40-36" aria-hidden="true" tabindex="-1"></a>        ax.text(</span>
<span id="cb40-37"><a href="#cb40-37" aria-hidden="true" tabindex="-1"></a>            width,</span>
<span id="cb40-38"><a href="#cb40-38" aria-hidden="true" tabindex="-1"></a>            bar.get_y() <span>+</span> bar.get_height() <span>/</span> <span>2</span>,</span>
<span id="cb40-39"><a href="#cb40-39" aria-hidden="true" tabindex="-1"></a>            <span>f&#34;</span><span>{</span>width<span>:.2f}</span><span>&#34;</span> <span>if</span> <span>isinstance</span>(width, <span>float</span>) <span>else</span> <span>f&#34;</span><span>{</span>width<span>}</span><span>&#34;</span>,</span>
<span id="cb40-40"><a href="#cb40-40" aria-hidden="true" tabindex="-1"></a>            ha<span>=</span><span>&#34;left&#34;</span>,</span>
<span id="cb40-41"><a href="#cb40-41" aria-hidden="true" tabindex="-1"></a>            va<span>=</span><span>&#34;center&#34;</span>,</span>
<span id="cb40-42"><a href="#cb40-42" aria-hidden="true" tabindex="-1"></a>        )</span>
<span id="cb40-43"><a href="#cb40-43" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-44"><a href="#cb40-44" aria-hidden="true" tabindex="-1"></a>    <span># Create custom legend handles</span></span>
<span id="cb40-45"><a href="#cb40-45" aria-hidden="true" tabindex="-1"></a>    legend_elements <span>=</span> [</span>
<span id="cb40-46"><a href="#cb40-46" aria-hidden="true" tabindex="-1"></a>        Patch(facecolor<span>=</span><span>&#34;#ff7f0e&#34;</span>, label<span>=</span><span>&#34;Finetuned Models&#34;</span>),</span>
<span id="cb40-47"><a href="#cb40-47" aria-hidden="true" tabindex="-1"></a>        Patch(facecolor<span>=</span><span>&#34;#1f77b4&#34;</span>, label<span>=</span><span>&#34;GPT Models&#34;</span>),</span>
<span id="cb40-48"><a href="#cb40-48" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb40-49"><a href="#cb40-49" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-50"><a href="#cb40-50" aria-hidden="true" tabindex="-1"></a>    <span># Add a legend outside the plot</span></span>
<span id="cb40-51"><a href="#cb40-51" aria-hidden="true" tabindex="-1"></a>    ax.legend(handles<span>=</span>legend_elements, loc<span>=</span><span>&#34;center left&#34;</span>, bbox_to_anchor<span>=</span>(<span>1</span>, <span>0.5</span>))</span>
<span id="cb40-52"><a href="#cb40-52" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-53"><a href="#cb40-53" aria-hidden="true" tabindex="-1"></a>    <span># Adjust layout to prevent clipping and make room for the legend</span></span>
<span id="cb40-54"><a href="#cb40-54" aria-hidden="true" tabindex="-1"></a>    plt.tight_layout()</span>
<span id="cb40-55"><a href="#cb40-55" aria-hidden="true" tabindex="-1"></a>    plt.subplots_adjust(right<span>=</span><span>0.85</span>)</span>
<span id="cb40-56"><a href="#cb40-56" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-57"><a href="#cb40-57" aria-hidden="true" tabindex="-1"></a>    <span># Show the plot</span></span>
<span id="cb40-58"><a href="#cb40-58" aria-hidden="true" tabindex="-1"></a>    plt.show()</span>
<span id="cb40-59"><a href="#cb40-59" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-60"><a href="#cb40-60" aria-hidden="true" tabindex="-1"></a><span># List of all the score dictionaries</span></span>
<span id="cb40-61"><a href="#cb40-61" aria-hidden="true" tabindex="-1"></a>score_dicts <span>=</span> [</span>
<span id="cb40-62"><a href="#cb40-62" aria-hidden="true" tabindex="-1"></a>    start_date_scores,</span>
<span id="cb40-63"><a href="#cb40-63" aria-hidden="true" tabindex="-1"></a>    province_scores,</span>
<span id="cb40-64"><a href="#cb40-64" aria-hidden="true" tabindex="-1"></a>    target_group_scores,</span>
<span id="cb40-65"><a href="#cb40-65" aria-hidden="true" tabindex="-1"></a>    event_type_scores,</span>
<span id="cb40-66"><a href="#cb40-66" aria-hidden="true" tabindex="-1"></a>    min_killed_scores,</span>
<span id="cb40-67"><a href="#cb40-67" aria-hidden="true" tabindex="-1"></a>    min_captured_scores,</span>
<span id="cb40-68"><a href="#cb40-68" aria-hidden="true" tabindex="-1"></a>    killq_scores,</span>
<span id="cb40-69"><a href="#cb40-69" aria-hidden="true" tabindex="-1"></a>    captureq_scores,</span>
<span id="cb40-70"><a href="#cb40-70" aria-hidden="true" tabindex="-1"></a>    killcaptureraid_scores,</span>
<span id="cb40-71"><a href="#cb40-71" aria-hidden="true" tabindex="-1"></a>    airstrike_scores,</span>
<span id="cb40-72"><a href="#cb40-72" aria-hidden="true" tabindex="-1"></a>    noshotsfired_scores,</span>
<span id="cb40-73"><a href="#cb40-73" aria-hidden="true" tabindex="-1"></a>    min_leaders_killed_scores,</span>
<span id="cb40-74"><a href="#cb40-74" aria-hidden="true" tabindex="-1"></a>    min_leaders_captured_scores,</span>
<span id="cb40-75"><a href="#cb40-75" aria-hidden="true" tabindex="-1"></a>]</span>
<span id="cb40-76"><a href="#cb40-76" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-77"><a href="#cb40-77" aria-hidden="true" tabindex="-1"></a><span># Get the list of models</span></span>
<span id="cb40-78"><a href="#cb40-78" aria-hidden="true" tabindex="-1"></a>models <span>=</span> <span>list</span>(start_date_scores.keys())</span>
<span id="cb40-79"><a href="#cb40-79" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-80"><a href="#cb40-80" aria-hidden="true" tabindex="-1"></a><span># Initialize the aggregate scores dictionary</span></span>
<span id="cb40-81"><a href="#cb40-81" aria-hidden="true" tabindex="-1"></a>aggregate_scores <span>=</span> {model: <span>0</span> <span>for</span> model <span>in</span> models}</span>
<span id="cb40-82"><a href="#cb40-82" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-83"><a href="#cb40-83" aria-hidden="true" tabindex="-1"></a><span># Calculate the aggregate score for each model</span></span>
<span id="cb40-84"><a href="#cb40-84" aria-hidden="true" tabindex="-1"></a><span>for</span> model <span>in</span> models:</span>
<span id="cb40-85"><a href="#cb40-85" aria-hidden="true" tabindex="-1"></a>    total_score <span>=</span> <span>0</span></span>
<span id="cb40-86"><a href="#cb40-86" aria-hidden="true" tabindex="-1"></a>    <span>for</span> score_dict <span>in</span> score_dicts:</span>
<span id="cb40-87"><a href="#cb40-87" aria-hidden="true" tabindex="-1"></a>        total_score <span>+=</span> score_dict[model]</span>
<span id="cb40-88"><a href="#cb40-88" aria-hidden="true" tabindex="-1"></a>    aggregate_scores[model] <span>=</span> (total_score <span>/</span> <span>len</span>(score_dicts)) <span>/</span> <span>len</span>(dataset_with_preds) <span>*</span> <span>100</span></span>
<span id="cb40-89"><a href="#cb40-89" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-90"><a href="#cb40-90" aria-hidden="true" tabindex="-1"></a><span># Create the aggregate score chart</span></span>
<span id="cb40-91"><a href="#cb40-91" aria-hidden="true" tabindex="-1"></a>create_aggregate_accuracy_chart(</span>
<span id="cb40-92"><a href="#cb40-92" aria-hidden="true" tabindex="-1"></a>    scores<span>=</span>aggregate_scores,</span>
<span id="cb40-93"><a href="#cb40-93" aria-hidden="true" tabindex="-1"></a>    title<span>=</span><span>&#34;Aggregate Accuracy Score by Model (0-100 Scale)&#34;</span>,</span>
<span id="cb40-94"><a href="#cb40-94" aria-hidden="true" tabindex="-1"></a>    xlabel<span>=</span><span>&#34;Aggregate Accuracy Score&#34;</span>,</span>
<span id="cb40-95"><a href="#cb40-95" aria-hidden="true" tabindex="-1"></a>)</span></code></pre></div>
</details>
<p><img src="https://annahope.me/blog/hello-world/2024-07-01-full-finetuned-model-evaluation_files/figure-html/cell-39-output-1.png"/></p>
</div>
<p>Surprising even me, the finetuned models beat out the GPT-class models from OpenAI. Actually even TinyLlama beats out GPT 3.5 Turbo!</p>
<p>Our top performer was Mistral-7B (finetuned on OpenPipe), very closely followed by Solar LLM and Llama3-7B. Just looking at the scores above it seems like anyone finetuning models for structured data extraction would do well to start of with Mistral-7B, Solar 7B or Llama3-7B and then see which performs best, though with the caveat that they might all be more or less the same for accuracy. There are probably different tradeoffs when it comes to serving the model and the efficiency and latency there, but still these three do really well.</p>
<p>I think if I were to stuff a few more examples into the prompt (as well a bit more explanation and rules) I could get the OpenAI models to perform even better, but at a certain point you have to remember all the things that having your own finetuned model brings you:</p>
<ul>
<li>data privacy (by not sending your confidential information to OpenAI)</li>
<li>smaller models most likely means better performance (though I still have to test and prove that out)</li>
<li>more control overall</li>
<li>cost improvements</li>
</ul>
<p>On the cost, it’s a bit hard to make that comparison or claim right now, especially given the economies of scale that the large cloud providers can rely on, but in a real-world use case where you were building this model for repeated inference over a long-term time frame, then you would have a better chance of having the cost argument make sense, particularly since the only way to make the OpenAI inference calls better to stuff them full of examples and extra explanation, significantly bloating the cost-per-query.</p>
<p>That said, there are some real tradeoffs that come up when finetuning a model, and I’ll get to some of those in my concluding thoughts.</p>
</section>
<section id="finetuning-works-a-charm-but">

<p>First off I’m so pleased that the oft-repeated “finetune your model and get better performance than with GPT-4” actually turned out to be true! And not only was it true, but it was true with <em>relatively</em> little tweaks and adaptations. Remember all the above models are the first finetunes I made with the data I brought. I basically used just the default values for everything and so it worked out of the box.</p>
<p>For any further work I’ll focus on the Solar, Llama3 and Mistral 7B models which performed best. I used cloud finetuning services to finetune the best performing versions of those models, so I’ll want to get that all working locally as well.</p>
<section id="evals-were-a-pain-this-time-round">
<h2 data-anchor-id="evals-were-a-pain-this-time-round">Evals were a pain (this time round)…</h2>
<p>Most of the evaluation work is represented here in this notebook, and that was perhaps the seeds of my own misfortune. I had some models that worked locally, and then a bunch of other models deployed in different environments and with different services.</p>
<p>Not only that, but it was pretty slow to iterate through the 724 row so my test data (which the models hadn’t seen during finetuning, just to be clear) since I implemented it fairly naively.</p>
<p>If I were to now make some updates to the models, or get them working locally, I’d really want to make sure that I have a way to run these evals locally as well. Moreover, I’d want a way to run a subset of the evals (i.e. on a slice of the data) and then at some point switch that out so that they could run across all the data.</p>
<p>All of this is completely within the realm of possible, but for this round I was more focused on getting the results than I was about making the process repeatable and/or efficient. I know I can’t run all the models concurrently on the same machine, so maybe the way forward is simply to have a reliable cloud GPU provider like Modal where I can farm out these evaluations. I had a really good experience with them when I used them, so that’s probably the way forward there.</p>
<p>In general, it was also painful having the models living in different places. I had to remember so many things. In any ideal world, you want a standard interface for inference to all your models, especially if they’re for the same use case or project. It’s convenient that my finetuned GPT3.5 is automatically deployed and served by OpenAI, and the same goes for Llama3 and Solar or Mistral, but I want a single place where I can see them all. Until now I hadn’t really seen this project or problem as being so much about MLOps, but when you have multiple models in play and you’re finetuning and updating them and data is changing all the time, then you’ll need a way of managing all this.</p>
<p>This is funny to me since <a href="https://zenml.io">I work at an MLOps company</a> – we build an open-source MLOps framework that helps you set up a platform – but I hadn’t anticipated it’d reach this point where I’d need something like a ZenML so soon. This is, of course, one of the major tradeoffs of finetuning LLMs, in that you have to manage all this <em>stuff</em> in order to make it work reliably and repeatably. Even at this early stage of my project, it’s clear that you need a way to keep everything straight without making mistakes.</p>
</section>
<section id="but-evals-give-me-a-way-to-know-if-im-making-progress">
<h2 data-anchor-id="but-evals-give-me-a-way-to-know-if-im-making-progress">…but evals give me a way to know if I’m making progress</h2>
<p>Even though the evaluations were somewhat painful to implement (at least in the form of this Jupyter notebook), they have given me an amazing gift in that I now have a task-specific way to know whether any of the improvements or refinements to either the training data or to the model are helping move me forward. Without this I’d essentially be flying blind.</p>
</section>
<section id="next-steps">
<h2 data-anchor-id="next-steps">Next Steps</h2>
<p>I had originally thought and suggested that I’d want to train multiple models to be super-specialists in their field, so for example to have one model that was really good at estimating how many people were captured in a particular event. Seeing the performance of my models, I’m not sure that’s the obvious next step for this project, or if I’d really be able to boost the accuracy by a significant amount by taking that approach.</p>
<p>This project is all about accuracy, so it’s possible that I might want to try that out, but for now I’m still exploring all the different phases of the LLM finetuning process so I’ll put the submodels idea on the backburner.</p>
<p>The first obvious next step is to run some evaluations for the non-accuracy-related tests mentioned <a href="https://mlops.systems/posts/2024-06-25-evaluation-finetuning-manual-dataset.html">in my last blog</a>. For example, I’d like to see how it performs with out of domain data (i.e. completely made up data about something completely different).</p>
<p>The other next step is to get into some of the details around model serving. I’d like to take my top three performers and dive into how LLM model serving is done. I’m familiar with non-LLM model serving and some of the ways people do that through my work, but LLM serving has it’s own tricks, tradeoffs and tools and I’m eager to learn more about those.</p>
<p>If this was a problem that I was deeply invested in solving beyond these already excellent results, I’d probably also want to dive into the areas where my LLMs struggled. So I’d take all the places where my LLMs failed to get the answer correct, load them up into some kind of web interface like Lilac or Argilla and really inspect my data further. Understanding the failure scenarios will probably do more for the accuracy than any tweaking of the finetuning parameters or the like.</p>
<p>For now, I’m just happy the finetuned models beat GPT-4!</p>


</section>
</section>

</div></div>
  </body>
</html>
