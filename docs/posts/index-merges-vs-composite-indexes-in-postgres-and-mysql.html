<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://sirupsen.com/index-merges">Original</a>
    <h1>Index Merges vs. Composite Indexes in Postgres and MySQL</h1>
    
    <div id="readability-page-1" class="page"><article><p><time datetime="2022-11-26">Nov 2022</time></p><p><strong>Composite indexes are about 10x faster than index merges.</strong> In Postgres, the gap is larger than in MySQL because Postgres doesn&#39;t support index-only scans for queries that involve index merges.</p><nav><ol><li><a href="https://sirupsen.com/index-merges#napkin-math">Napkin Math</a><ol><li><a href="https://sirupsen.com/index-merges#composite-index-1ms">Composite Index: ~1ms</a></li><li><a href="https://sirupsen.com/index-merges#index-merge-10-30ms">Index Merge: ~10-30ms</a></li></ol></li><li><a href="https://sirupsen.com/index-merges#reality">Reality</a><ol><li><a href="https://sirupsen.com/index-merges#composite-index-5ms-">Composite Index: 5ms âœ…</a></li><li><a href="https://sirupsen.com/index-merges#index-merge">Index Merge</a><ol><li><a href="https://sirupsen.com/index-merges#mysql-30-40ms-">MySQL: 30-40ms âœ…</a></li><li><a href="https://sirupsen.com/index-merges#postgres-30-90ms-">Postgres: 30-90ms ðŸ¤”</a></li></ol></li></ol></li><li><a href="https://sirupsen.com/index-merges#conclusion">Conclusion</a></li></ol></nav><p>While working with Readwise on optimizing their database for the impending
launch of their <a href="https://readwise.io/read">Reader product</a>, I found myself
asking the question: How much faster is a composite index compared to letting
the database do an index merge of multiple indexes? Consider this query:</p>
<pre><code><span>SELECT</span> <span>count</span><span>(</span><span>*</span><span>)</span> 
<span>FROM</span> <span>table</span>
<span>WHERE</span> int1000 <span>=</span> <span>1</span> <span>AND</span> int100 <span>=</span> <span>1</span>

</code></pre>
<details><summary><a>View Table Definition</a></summary><pre><code><span>create</span> <span>table</span> test_table <span>(</span>
  id <span>bigint</span> <span>primary</span> <span>key</span> <span>not</span> <span>null</span><span>,</span>

  text1 <span>text</span> <span>not</span> <span>null</span><span>,</span> 
  text2 <span>text</span> <span>not</span> <span>null</span><span>,</span> 

  
  int1000 <span>bigint</span> <span>not</span> <span>null</span><span>,</span> 
  int100 <span>bigint</span> <span>not</span> <span>null</span><span>,</span> 
  int10 <span>bigint</span> <span>not</span> <span>null</span><span>,</span> 
<span>)</span><span>;</span>

</code></pre></details>
<p>We can create a composite index on <code>(int1000, int100)</code>, or we could have two
individual indexes on <code>(int1000)</code> and <code>(int100)</code>, relying on the database to
leverage both indexes.</p>
<p>Having a composite index is faster, but <em>how much</em> faster than the two
individual indexes? Letâ€™s do the napkin math, and then test it in PostgreSQL and
MySQL.</p>
<h2 id="napkin-math">Napkin Math<svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="currentColor" viewBox="0 0 24 24"><path d="M9.199 13.599a5.99 5.99 0 0 0 3.949 2.345 5.987 5.987 0 0 0 5.105-1.702l2.995-2.994a5.992 5.992 0 0 0 1.695-4.285 5.976 5.976 0 0 0-1.831-4.211 5.99 5.99 0 0 0-6.431-1.242 6.003 6.003 0 0 0-1.905 1.24l-1.731 1.721a.999.999 0 1 0 1.41 1.418l1.709-1.699a3.985 3.985 0 0 1 2.761-1.123 3.975 3.975 0 0 1 2.799 1.122 3.997 3.997 0 0 1 .111 5.644l-3.005 3.006a3.982 3.982 0 0 1-3.395 1.126 3.987 3.987 0 0 1-2.632-1.563A1 1 0 0 0 9.201 13.6zm5.602-3.198a5.99 5.99 0 0 0-3.949-2.345 5.987 5.987 0 0 0-5.105 1.702l-2.995 2.994a5.992 5.992 0 0 0-1.695 4.285 5.976 5.976 0 0 0 1.831 4.211 5.99 5.99 0 0 0 6.431 1.242 6.003 6.003 0 0 0 1.905-1.24l1.723-1.723a.999.999 0 1 0-1.414-1.414L9.836 19.81a3.985 3.985 0 0 1-2.761 1.123 3.975 3.975 0 0 1-2.799-1.122 3.997 3.997 0 0 1-.111-5.644l3.005-3.006a3.982 3.982 0 0 1 3.395-1.126 3.987 3.987 0 0 1 2.632 1.563 1 1 0 0 0 1.602-1.198z"></path></svg></h2>
<p>Weâ€™ll start with the napkin math, and then verify it against Postgres and MySQL.</p>
<h3 id="composite-index-1ms">Composite Index: ~1ms<svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="currentColor" viewBox="0 0 24 24"><path d="M9.199 13.599a5.99 5.99 0 0 0 3.949 2.345 5.987 5.987 0 0 0 5.105-1.702l2.995-2.994a5.992 5.992 0 0 0 1.695-4.285 5.976 5.976 0 0 0-1.831-4.211 5.99 5.99 0 0 0-6.431-1.242 6.003 6.003 0 0 0-1.905 1.24l-1.731 1.721a.999.999 0 1 0 1.41 1.418l1.709-1.699a3.985 3.985 0 0 1 2.761-1.123 3.975 3.975 0 0 1 2.799 1.122 3.997 3.997 0 0 1 .111 5.644l-3.005 3.006a3.982 3.982 0 0 1-3.395 1.126 3.987 3.987 0 0 1-2.632-1.563A1 1 0 0 0 9.201 13.6zm5.602-3.198a5.99 5.99 0 0 0-3.949-2.345 5.987 5.987 0 0 0-5.105 1.702l-2.995 2.994a5.992 5.992 0 0 0-1.695 4.285 5.976 5.976 0 0 0 1.831 4.211 5.99 5.99 0 0 0 6.431 1.242 6.003 6.003 0 0 0 1.905-1.24l1.723-1.723a.999.999 0 1 0-1.414-1.414L9.836 19.81a3.985 3.985 0 0 1-2.761 1.123 3.975 3.975 0 0 1-2.799-1.122 3.997 3.997 0 0 1-.111-5.644l3.005-3.006a3.982 3.982 0 0 1 3.395-1.126 3.987 3.987 0 0 1 2.632 1.563 1 1 0 0 0 1.602-1.198z"></path></svg></h3>
<p>The ideal index for this <code>count(*)</code> is:</p>
<pre><code><span>CREATE</span> <span>INDEX</span> <span>ON</span> <span>table</span> <span>(</span>int1000<span>,</span> int100<span>)</span>
</code></pre>
<p>It allows the entire count to be performed on this one index.</p>
<p><code>WHERE int1000 = 1 AND int100 = 1</code> matches ~100 records of the 10M total for the
table. <sup><a href="https://sirupsen.com/index-merges#user-content-fn-1">1</a></sup> The database would do a quick search in the index tree to the leaf in the
index where both columns are <code>1</code>, and then scan forward until the condition no
longer holds.</p>
<figure><img alt="Illustration of a composite index tree with the leaf node storing the (int1000, int100) tuple" title="Illustration of a composite index tree with the leaf node storing the (int1000, int100) tuple" sizes="(min-width: 36rem) 36rem 100vw" srcset="/_next/image?url=%2Fimages%2Fcomposite-index.png&amp;w=640&amp;q=75 640w, /_next/image?url=%2Fimages%2Fcomposite-index.png&amp;w=750&amp;q=75 750w, /_next/image?url=%2Fimages%2Fcomposite-index.png&amp;w=828&amp;q=75 828w, /_next/image?url=%2Fimages%2Fcomposite-index.png&amp;w=1080&amp;q=75 1080w, /_next/image?url=%2Fimages%2Fcomposite-index.png&amp;w=1200&amp;q=75 1200w, /_next/image?url=%2Fimages%2Fcomposite-index.png&amp;w=1920&amp;q=75 1920w, /_next/image?url=%2Fimages%2Fcomposite-index.png&amp;w=2048&amp;q=75 2048w, /_next/image?url=%2Fimages%2Fcomposite-index.png&amp;w=3840&amp;q=75 3840w" src="https://sirupsen.com/_next/image?url=%2Fimages%2Fcomposite-index.png&amp;w=3840&amp;q=75" width="2675" height="1761" decoding="async" data-nimg="1"/><figcaption>Illustration of a composite index tree with the leaf node storing the (int1000, int100) tuple</figcaption></figure>
<p>For these 64-bit index entries weâ€™d expect to have to scan only the ~100 entries
that match, which is a negligible ~2 KiB. According to the <a href="https://github.com/sirupsen/napkin-math">napkin reference</a>, we can read
<span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>Â </mtext><mn>1</mn><mtext>Â MiB</mtext><mi mathvariant="normal">/</mi><mn>100</mn><mtext>Â Î¼s</mtext></mrow><annotation encoding="application/x-tex">~1\text{ MiB}/100\text{ Î¼s}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>Â </span><span>1</span><span><span>Â MiB</span></span><span>/100</span><span><span>Â Î¼s</span></span></span></span></span></span> from memory, so this will take absolutely no time.
With the query overhead, navigating the index tree, and everything else, it
theoretically shouldnâ€™t take a database more than a couple <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>100</mn><mo>âˆ’</mo><mn>500</mn><mtext>Â Î¼s</mtext></mrow><annotation encoding="application/x-tex">100-500 \text{ Î¼s}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>100</span><span></span><span>âˆ’</span><span></span></span><span><span></span><span>500</span><span><span>Â Î¼s</span></span></span></span></span></span>
on the composite index to satisfy this query. <sup><a href="https://sirupsen.com/index-merges#user-content-fn-2">2</a></sup></p>
<h3 id="index-merge-10-30ms">Index Merge: ~10-30ms<svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="currentColor" viewBox="0 0 24 24"><path d="M9.199 13.599a5.99 5.99 0 0 0 3.949 2.345 5.987 5.987 0 0 0 5.105-1.702l2.995-2.994a5.992 5.992 0 0 0 1.695-4.285 5.976 5.976 0 0 0-1.831-4.211 5.99 5.99 0 0 0-6.431-1.242 6.003 6.003 0 0 0-1.905 1.24l-1.731 1.721a.999.999 0 1 0 1.41 1.418l1.709-1.699a3.985 3.985 0 0 1 2.761-1.123 3.975 3.975 0 0 1 2.799 1.122 3.997 3.997 0 0 1 .111 5.644l-3.005 3.006a3.982 3.982 0 0 1-3.395 1.126 3.987 3.987 0 0 1-2.632-1.563A1 1 0 0 0 9.201 13.6zm5.602-3.198a5.99 5.99 0 0 0-3.949-2.345 5.987 5.987 0 0 0-5.105 1.702l-2.995 2.994a5.992 5.992 0 0 0-1.695 4.285 5.976 5.976 0 0 0 1.831 4.211 5.99 5.99 0 0 0 6.431 1.242 6.003 6.003 0 0 0 1.905-1.24l1.723-1.723a.999.999 0 1 0-1.414-1.414L9.836 19.81a3.985 3.985 0 0 1-2.761 1.123 3.975 3.975 0 0 1-2.799-1.122 3.997 3.997 0 0 1-.111-5.644l3.005-3.006a3.982 3.982 0 0 1 3.395-1.126 3.987 3.987 0 0 1 2.632 1.563 1 1 0 0 0 1.602-1.198z"></path></svg></h3>
<p>But a database can also do an index merge of two separate indexes:</p>
<pre><code><span>CREATE</span> <span>INDEX</span> <span>ON</span> <span>table</span> <span>(</span>int1000<span>)</span>
<span>CREATE</span> <span>INDEX</span> <span>ON</span> <span>table</span> <span>(</span>int100<span>)</span>
</code></pre>
<p>But how does a database utilize two indexes? And how expensive might this merge be?</p>
<p>How indexes are intersected depends on the database! There are many ways of
finding the intersection of two unordered lists: hashing, sorting, sets,
KD-trees, bitmap, â€¦</p>
<p>MySQL does what it calls an <a href="https://dev.mysql.com/doc/refman/8.0/en/index-merge-optimization.html">index merge intersection</a>, I havenâ€™t consulted
the source, but most likely itâ€™s sorting. Postgres does index intersection by
<a href="https://www.postgresql.org/docs/current/indexes-bitmap-scans.html">generating a bitmap after scanning each index</a>, and then <code>AND</code>ing them
together.</p>
<p><code>int100 = 1</code> returns about <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>10</mn><mi>M</mi><mo>â‹…</mo><mn>1</mn><mi mathvariant="normal">/</mi><mn>1000</mn><mo>â‰ˆ</mo><mn>100</mn><mo separator="true">,</mo><mn>000</mn></mrow><annotation encoding="application/x-tex">10M \cdot 1/1000 \approx 100,000</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>10</span><span>M</span><span></span><span>â‹…</span><span></span></span><span><span></span><span>1/1000</span><span></span><span>â‰ˆ</span><span></span></span><span><span></span><span>100</span><span>,</span><span></span><span>000</span></span></span></span></span> rows, which is
about ~1.5 MiB to scan. <code>int1000 = 1</code> matches only ~10,000 rows, so in total
weâ€™re reading about <a href="https://github.com/sirupsen/napkin-math">200 Î¼s</a> worth of memory from both indexes.</p>
<p>After we have the matches from the index, we need to intersect them. In this
case, for simplicity of the napkin math, letâ€™s assume we sort the matches
from both indexes and then intersect from there.</p>
<p>We can sort <a href="https://github.com/sirupsen/napkin-math"><span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>1</mn><mtext>Â MiB</mtext></mrow><annotation encoding="application/x-tex">1\text{ MiB}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>1</span><span><span>Â MiB</span></span></span></span></span></span> in <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mn>5</mn><mtext>Â ms</mtext></mrow><annotation encoding="application/x-tex">5\text{ ms}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>5</span><span><span>Â ms</span></span></span></span></span></span></a>. So it would take us ~10ms
total to sort it, iterate through both sorted lists for a negligible <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>Â </mtext><mn>200</mn><mtext>Â Î¼s</mtext></mrow><annotation encoding="application/x-tex">~200\text{
Î¼s}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>Â </span><span>200</span><span><span>Â Î¼s</span></span></span></span></span></span> of memory reading, write the intersection to memory for another <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>Â </mtext><mn>200</mn><mtext>Â us</mtext></mrow><annotation encoding="application/x-tex">~200\text{
us}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>Â </span><span>200</span><span><span>Â us</span></span></span></span></span></span>, and then weâ€™ve got the interesection, i.e. rows that match both
conditions.</p>
<figure><img alt="Illustration of intersecting the two indexes with
whatever internal identifier the database uses." title="Illustration of intersecting the two indexes with
whatever internal identifier the database uses." sizes="(min-width: 36rem) 36rem 100vw" srcset="/_next/image?url=%2Fimages%2Fintersection.png&amp;w=640&amp;q=75 640w, /_next/image?url=%2Fimages%2Fintersection.png&amp;w=750&amp;q=75 750w, /_next/image?url=%2Fimages%2Fintersection.png&amp;w=828&amp;q=75 828w, /_next/image?url=%2Fimages%2Fintersection.png&amp;w=1080&amp;q=75 1080w, /_next/image?url=%2Fimages%2Fintersection.png&amp;w=1200&amp;q=75 1200w, /_next/image?url=%2Fimages%2Fintersection.png&amp;w=1920&amp;q=75 1920w, /_next/image?url=%2Fimages%2Fintersection.png&amp;w=2048&amp;q=75 2048w, /_next/image?url=%2Fimages%2Fintersection.png&amp;w=3840&amp;q=75 3840w" src="https://sirupsen.com/_next/image?url=%2Fimages%2Fintersection.png&amp;w=3840&amp;q=75" width="1848" height="475" decoding="async" data-nimg="1" loading="lazy"/><figcaption>Illustration of intersecting the two indexes with
whatever internal identifier the database uses.</figcaption></figure>
<p>Thus our napkin math indicates that for our two separate indexes weâ€™d expect the
query to take <span><span><span><math xmlns="http://www.w3.org/1998/Math/MathML"><semantics><mrow><mtext>Â </mtext><mn>10</mn><mtext>Â ms</mtext></mrow><annotation encoding="application/x-tex">~10\text{ ms}</annotation></semantics></math></span><span aria-hidden="true"><span><span></span><span>Â </span><span>10</span><span><span>Â ms</span></span></span></span></span></span>. The sorting is sensitive to the index size which
is fairly approximate, so give it a low multiplier to land at, <code>~10-30ms</code>.</p>
<p>As weâ€™ve seen, intersection bears a meaningful cost and on paper we expect it to
be roughly an order of magnitude slower than composite indexes. However, 10ms is
still sensible for most situations, and depending on the situation it might be
nice to not have a more specialized composite index for the query! For example,
if you are often joining between a subset of 10s of columns.</p>
<h2 id="reality">Reality<svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="currentColor" viewBox="0 0 24 24"><path d="M9.199 13.599a5.99 5.99 0 0 0 3.949 2.345 5.987 5.987 0 0 0 5.105-1.702l2.995-2.994a5.992 5.992 0 0 0 1.695-4.285 5.976 5.976 0 0 0-1.831-4.211 5.99 5.99 0 0 0-6.431-1.242 6.003 6.003 0 0 0-1.905 1.24l-1.731 1.721a.999.999 0 1 0 1.41 1.418l1.709-1.699a3.985 3.985 0 0 1 2.761-1.123 3.975 3.975 0 0 1 2.799 1.122 3.997 3.997 0 0 1 .111 5.644l-3.005 3.006a3.982 3.982 0 0 1-3.395 1.126 3.987 3.987 0 0 1-2.632-1.563A1 1 0 0 0 9.201 13.6zm5.602-3.198a5.99 5.99 0 0 0-3.949-2.345 5.987 5.987 0 0 0-5.105 1.702l-2.995 2.994a5.992 5.992 0 0 0-1.695 4.285 5.976 5.976 0 0 0 1.831 4.211 5.99 5.99 0 0 0 6.431 1.242 6.003 6.003 0 0 0 1.905-1.24l1.723-1.723a.999.999 0 1 0-1.414-1.414L9.836 19.81a3.985 3.985 0 0 1-2.761 1.123 3.975 3.975 0 0 1-2.799-1.122 3.997 3.997 0 0 1-.111-5.644l3.005-3.006a3.982 3.982 0 0 1 3.395-1.126 3.987 3.987 0 0 1 2.632 1.563 1 1 0 0 0 1.602-1.198z"></path></svg></h2>
<p>Now that weâ€™ve set our expectations from first principles about composite indexes
versus merging multiple indexes, letâ€™s see how Postgres and MySQL fare in
real-life.</p>
<h3 id="composite-index-5ms-">Composite Index: 5ms âœ…<svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="currentColor" viewBox="0 0 24 24"><path d="M9.199 13.599a5.99 5.99 0 0 0 3.949 2.345 5.987 5.987 0 0 0 5.105-1.702l2.995-2.994a5.992 5.992 0 0 0 1.695-4.285 5.976 5.976 0 0 0-1.831-4.211 5.99 5.99 0 0 0-6.431-1.242 6.003 6.003 0 0 0-1.905 1.24l-1.731 1.721a.999.999 0 1 0 1.41 1.418l1.709-1.699a3.985 3.985 0 0 1 2.761-1.123 3.975 3.975 0 0 1 2.799 1.122 3.997 3.997 0 0 1 .111 5.644l-3.005 3.006a3.982 3.982 0 0 1-3.395 1.126 3.987 3.987 0 0 1-2.632-1.563A1 1 0 0 0 9.201 13.6zm5.602-3.198a5.99 5.99 0 0 0-3.949-2.345 5.987 5.987 0 0 0-5.105 1.702l-2.995 2.994a5.992 5.992 0 0 0-1.695 4.285 5.976 5.976 0 0 0 1.831 4.211 5.99 5.99 0 0 0 6.431 1.242 6.003 6.003 0 0 0 1.905-1.24l1.723-1.723a.999.999 0 1 0-1.414-1.414L9.836 19.81a3.985 3.985 0 0 1-2.761 1.123 3.975 3.975 0 0 1-2.799-1.122 3.997 3.997 0 0 1-.111-5.644l3.005-3.006a3.982 3.982 0 0 1 3.395-1.126 3.987 3.987 0 0 1 2.632 1.563 1 1 0 0 0 1.602-1.198z"></path></svg></h3>
<p>Both MySQL and Postgres perform index-only scans after we create the index:</p>
<pre><code>
<span>CREATE</span> <span>INDEX</span> <span>ON</span> <span>table</span> <span>(</span>int1000<span>,</span> int100<span>)</span>
<span>EXPLAIN</span> <span>ANALYZE</span> <span>SELECT</span> <span>count</span><span>(</span><span>*</span><span>)</span> <span>FROM</span> <span>table</span> <span>WHERE</span> int1000 <span>=</span> <span>1</span> <span>AND</span> int100 <span>=</span> <span>1</span>
</code></pre>
<pre><code>/* postgres, index is ~70 MiB */
Aggregate  (cost=6.53..6.54 rows=1 width=8) (actual time=0.919..0.919 rows=1 loops=1)
  -&gt;  Index Only Scan using compound_idx on test_table  (cost=0.43..6.29 rows=93 width=0) (actual time=0.130..0.909 rows=109 loops=1)
        Index Cond: ((int1000 = 1) AND (int100 = 1))
        Heap Fetches: 0
</code></pre>
<pre><code>/* mysql, index is ~350 MiB */
-&gt; Aggregate: count(0)  (cost=18.45 rows=1) (actual time=0.181..0.181 rows=1 loops=1)
    -&gt; Covering index lookup on test_table using compound_idx (int1000=1, int100=1)  (cost=9.85 rows=86) (actual time=0.129..0.151 rows=86 loops=1)
</code></pre>
<p>They each take about ~3-5ms when the index is cached. It is a bit slower than
the ~1ms we expected from the napkin math, but in our experience working with
napkin math on database, tracks within an order of magnitude to seem acceptable.
We attribute this to overhead of walking through the index. <sup><a href="https://sirupsen.com/index-merges#user-content-fn-3">3</a></sup></p>
<h3 id="index-merge">Index Merge<svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="currentColor" viewBox="0 0 24 24"><path d="M9.199 13.599a5.99 5.99 0 0 0 3.949 2.345 5.987 5.987 0 0 0 5.105-1.702l2.995-2.994a5.992 5.992 0 0 0 1.695-4.285 5.976 5.976 0 0 0-1.831-4.211 5.99 5.99 0 0 0-6.431-1.242 6.003 6.003 0 0 0-1.905 1.24l-1.731 1.721a.999.999 0 1 0 1.41 1.418l1.709-1.699a3.985 3.985 0 0 1 2.761-1.123 3.975 3.975 0 0 1 2.799 1.122 3.997 3.997 0 0 1 .111 5.644l-3.005 3.006a3.982 3.982 0 0 1-3.395 1.126 3.987 3.987 0 0 1-2.632-1.563A1 1 0 0 0 9.201 13.6zm5.602-3.198a5.99 5.99 0 0 0-3.949-2.345 5.987 5.987 0 0 0-5.105 1.702l-2.995 2.994a5.992 5.992 0 0 0-1.695 4.285 5.976 5.976 0 0 0 1.831 4.211 5.99 5.99 0 0 0 6.431 1.242 6.003 6.003 0 0 0 1.905-1.24l1.723-1.723a.999.999 0 1 0-1.414-1.414L9.836 19.81a3.985 3.985 0 0 1-2.761 1.123 3.975 3.975 0 0 1-2.799-1.122 3.997 3.997 0 0 1-.111-5.644l3.005-3.006a3.982 3.982 0 0 1 3.395-1.126 3.987 3.987 0 0 1 2.632 1.563 1 1 0 0 0 1.602-1.198z"></path></svg></h3>
<h4 id="mysql-30-40ms-">MySQL: 30-40ms âœ…<svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="currentColor" viewBox="0 0 24 24"><path d="M9.199 13.599a5.99 5.99 0 0 0 3.949 2.345 5.987 5.987 0 0 0 5.105-1.702l2.995-2.994a5.992 5.992 0 0 0 1.695-4.285 5.976 5.976 0 0 0-1.831-4.211 5.99 5.99 0 0 0-6.431-1.242 6.003 6.003 0 0 0-1.905 1.24l-1.731 1.721a.999.999 0 1 0 1.41 1.418l1.709-1.699a3.985 3.985 0 0 1 2.761-1.123 3.975 3.975 0 0 1 2.799 1.122 3.997 3.997 0 0 1 .111 5.644l-3.005 3.006a3.982 3.982 0 0 1-3.395 1.126 3.987 3.987 0 0 1-2.632-1.563A1 1 0 0 0 9.201 13.6zm5.602-3.198a5.99 5.99 0 0 0-3.949-2.345 5.987 5.987 0 0 0-5.105 1.702l-2.995 2.994a5.992 5.992 0 0 0-1.695 4.285 5.976 5.976 0 0 0 1.831 4.211 5.99 5.99 0 0 0 6.431 1.242 6.003 6.003 0 0 0 1.905-1.24l1.723-1.723a.999.999 0 1 0-1.414-1.414L9.836 19.81a3.985 3.985 0 0 1-2.761 1.123 3.975 3.975 0 0 1-2.799-1.122 3.997 3.997 0 0 1-.111-5.644l3.005-3.006a3.982 3.982 0 0 1 3.395-1.126 3.987 3.987 0 0 1 2.632 1.563 1 1 0 0 0 1.602-1.198z"></path></svg></h4>
<p>When we execute the query in MySQL it takes ~30-40ms, which tracks well the
upper end of our napkin math. That means our first principle understanding
likely lines up with reality!</p>
<p>Letâ€™s confirm itâ€™s doing what we expect by looking at the query plan:</p>
<pre><code>
<span>EXPLAIN</span> <span>ANALYZE</span> <span>SELECT</span> <span>count</span><span>(</span><span>*</span><span>)</span> <span>FROM</span> <span>table</span> <span>WHERE</span> int1000 <span>=</span> <span>1</span> <span>AND</span> int100 <span>=</span> <span>1</span>
</code></pre>
<pre><code>/* mysql, each index is ~240 MiB */
-&gt; Aggregate: count(0)  (cost=510.64 rows=1) (actual time=31.908..31.909 rows=1 loops=1)
    -&gt; Filter: ((test_table.int100 = 1) and (test_table.int1000 = 1))  (cost=469.74 rows=409) (actual time=5.471..31.858 rows=86 loops=1)
        -&gt; Intersect rows sorted by row ID  (cost=469.74 rows=410) (actual time=5.464..31.825 rows=86 loops=1)
            -&gt; Index range scan on test_table using int1000 over (int1000 = 1)  (cost=37.05 rows=18508) (actual time=0.271..2.544 rows=9978 loops=1)
            -&gt; Index range scan on test_table using int100 over (int100 = 1)  (cost=391.79 rows=202002) (actual time=0.324..24.405 rows=99814 loops=1)
</code></pre>
<p>MySQLâ€™s query plan tells us itâ€™s doing <em>exactly</em> as we expected: get the
matching entries from each index, intersecting them and performing the count on
the intersection. Running <code>EXPLAIN</code> without analyze I could confirm that itâ€™s
serving <em>everything</em> from the index and never going to seek the full row.</p>
<h4 id="postgres-30-90ms-">Postgres: 30-90ms ðŸ¤”<svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="currentColor" viewBox="0 0 24 24"><path d="M9.199 13.599a5.99 5.99 0 0 0 3.949 2.345 5.987 5.987 0 0 0 5.105-1.702l2.995-2.994a5.992 5.992 0 0 0 1.695-4.285 5.976 5.976 0 0 0-1.831-4.211 5.99 5.99 0 0 0-6.431-1.242 6.003 6.003 0 0 0-1.905 1.24l-1.731 1.721a.999.999 0 1 0 1.41 1.418l1.709-1.699a3.985 3.985 0 0 1 2.761-1.123 3.975 3.975 0 0 1 2.799 1.122 3.997 3.997 0 0 1 .111 5.644l-3.005 3.006a3.982 3.982 0 0 1-3.395 1.126 3.987 3.987 0 0 1-2.632-1.563A1 1 0 0 0 9.201 13.6zm5.602-3.198a5.99 5.99 0 0 0-3.949-2.345 5.987 5.987 0 0 0-5.105 1.702l-2.995 2.994a5.992 5.992 0 0 0-1.695 4.285 5.976 5.976 0 0 0 1.831 4.211 5.99 5.99 0 0 0 6.431 1.242 6.003 6.003 0 0 0 1.905-1.24l1.723-1.723a.999.999 0 1 0-1.414-1.414L9.836 19.81a3.985 3.985 0 0 1-2.761 1.123 3.975 3.975 0 0 1-2.799-1.122 3.997 3.997 0 0 1-.111-5.644l3.005-3.006a3.982 3.982 0 0 1 3.395-1.126 3.987 3.987 0 0 1 2.632 1.563 1 1 0 0 0 1.602-1.198z"></path></svg></h4>
<p>Postgres is also within an order of magnitude of our napkin math, but itâ€™s on
the higher range with more variance, in general performing worse than MySQL. Is
its bitmap-based intersection just slower on this query? Or is it doing
something completely different than MySQL?</p>
<p>Letâ€™s look at the query plan using the same query as we used from MySQL:</p>
<pre><code>/* postgres, each index is ~70 MiB */
Aggregate  (cost=1625.63..1625.64 rows=1 width=8) (actual time=65.430..65.431 rows=1 loops=1)
  -&gt;  Bitmap Heap Scan on test_table  (cost=1222.22..1625.38 rows=101 width=0) (actual time=63.821..65.405 rows=109 loops=1)
        Recheck Cond: ((int1000 = 1) AND (int100 = 1))
        Rows Removed by Index Recheck: 179
        Heap Blocks: exact=286
        -&gt;  BitmapAnd  (cost=1222.22..1222.22 rows=101 width=0) (actual time=63.694..63.695 rows=0 loops=1)
              -&gt;  Bitmap Index Scan on int1000_idx  (cost=0.00..110.98 rows=9940 width=0) (actual time=3.945..3.945 rows=10063 loops=1)
                    Index Cond: (int1000 = 1)
              -&gt;  Bitmap Index Scan on int100_idx  (cost=0.00..1110.94 rows=101667 width=0) (actual time=58.917..58.917 rows=100038 loops=1)
                    Index Cond: (int100 = 1)
</code></pre>
<p>It confirms that itâ€™s using the <a href="https://www.postgresql.org/docs/current/indexes-bitmap-scans.html">bitmap strategy</a> for intersecting the two
indexes. But thatâ€™s not whatâ€™s causing the performance difference.</p>
<p>While MySQL services the entire aggregate (<code>count(*)</code>) from the index, Postgres
actually goes to the heap to get <em>every row</em>. The heap contains the <em>entire</em>
row, which is upwards of 1 KiB. This is expensive, and when the heap cache isnâ€™t
warm, the query takes more than 100ms!</p>
<p>As we can tell from the query plan, it seems that Postgres is unable to do
<a href="https://www.postgresql.org/docs/current/indexes-index-only-scans.html">index-only scans</a> in conjunction with index intersection. Maybe in a future
Postgres version they will support this; I donâ€™t see any fundamental reason why
they couldnâ€™t!</p>
<p>Going to the heap doesnâ€™t have a huge impact when weâ€™re only going to the heap
for 100 records. However, if we change the condition to <code>WHERE int10 = 1 and int100 = 1</code>, for a total of 10,000 matches, then this query takes 7s on
Postgres, versus 200ms in MySQL where the index-only scan is alive and kicking!</p>
<p>So MySQL is superior on index merges where there is an opportunity to service
the entire query from the index.</p>
<p>Postgres and MySQL do have roughly equivalent performance on index-only scans
though. For example, if we do <code>int10 = 1</code> Postgres will do its own index-only
scan because only one index is involved.</p>
<p>The first time I ran Postgres for this index-only scan it was taking over a
second, I had to run <code>VACUUM</code> for the performance to match! Index-only scans
require frequent <code>VACUUM</code> on the table to avoid going to the heap to fetch the
entire row in Postgres.</p>
<p><code>VACUUM</code> helps because Postgres has to visit the heap for any records that have
been touched since the last <code>VACUUM</code>, <a href="https://www.postgresql.org/docs/current/indexes-index-only-scans.html">due to its MVCC implementation</a>. In my
experience, this can have serious consequences in production for index-only
scans if you have an update-heavy table where <code>VACUUM</code>
is expensive.</p>
<h2 id="conclusion">Conclusion<svg xmlns="http://www.w3.org/2000/svg" width="18" height="18" fill="currentColor" viewBox="0 0 24 24"><path d="M9.199 13.599a5.99 5.99 0 0 0 3.949 2.345 5.987 5.987 0 0 0 5.105-1.702l2.995-2.994a5.992 5.992 0 0 0 1.695-4.285 5.976 5.976 0 0 0-1.831-4.211 5.99 5.99 0 0 0-6.431-1.242 6.003 6.003 0 0 0-1.905 1.24l-1.731 1.721a.999.999 0 1 0 1.41 1.418l1.709-1.699a3.985 3.985 0 0 1 2.761-1.123 3.975 3.975 0 0 1 2.799 1.122 3.997 3.997 0 0 1 .111 5.644l-3.005 3.006a3.982 3.982 0 0 1-3.395 1.126 3.987 3.987 0 0 1-2.632-1.563A1 1 0 0 0 9.201 13.6zm5.602-3.198a5.99 5.99 0 0 0-3.949-2.345 5.987 5.987 0 0 0-5.105 1.702l-2.995 2.994a5.992 5.992 0 0 0-1.695 4.285 5.976 5.976 0 0 0 1.831 4.211 5.99 5.99 0 0 0 6.431 1.242 6.003 6.003 0 0 0 1.905-1.24l1.723-1.723a.999.999 0 1 0-1.414-1.414L9.836 19.81a3.985 3.985 0 0 1-2.761 1.123 3.975 3.975 0 0 1-2.799-1.122 3.997 3.997 0 0 1-.111-5.644l3.005-3.006a3.982 3.982 0 0 1 3.395-1.126 3.987 3.987 0 0 1 2.632 1.563 1 1 0 0 0 1.602-1.198z"></path></svg></h2>
<p>Index merges are ~10x slower than composite indexes because the ad-hoc
intersection isnâ€™t a very fast operation. It requires e.g. sorting of the output
of each index scan to resolve. Indexes could be optimized further for
intersection, but this would likely have other ramifications for steady-state
load.</p>
<p>If youâ€™re wondering if you need to add a composite index, or can get away with
creating to single indexes and rely on the database to use both indexes â€” then
<strong>the rule of thumb we establish is that an index merge will be ~10x slower than
the composite index</strong>. However, weâ€™re still talking less than 100ms in most
cases, as long as youâ€™re operating on 100s of rows (which in a relational,
operational database, hopefully you mostly are).</p>
<p>The gap in performance might slightly widen when intersecting more than two
columns, and with larger tablesâ€”but I had to limit the scope of this article
somewhere. Roughly an order of magnitude seems like a reasonable assumption.</p>
<p>If you are using Postgres, be careful relying on index merging! Postgres doesnâ€™t
do index-only scans after an index merge, requiring going to the heap for
potentially 100,000s of records for a <code>count(*)</code>. If youâ€™re only returning 10s
to 100s of rows, thatâ€™s usually fine.</p>
<p>Another second-order take-away: If youâ€™re in a situation where you have 10s of
columns filtering in all kinds of combinations, with queries like this:</p>
<pre><code><span>SELECT</span> id
<span>FROM</span> products
<span>WHERE</span> color<span>=</span>blue <span>AND</span> <span>type</span><span>=</span>sneaker <span>AND</span> activity<span>=</span>training 
  <span>AND</span> season<span>=</span>summer <span>AND</span> inventory <span>&gt;</span> <span>0</span> <span>AND</span> price <span>&lt;=</span> <span>200</span> <span>AND</span> price <span>&gt;=</span> <span>100</span>
  
</code></pre>
<p>Then youâ€™re in a bit more of a pickle with Postgres/MySQL. It would require a combinatoric
explosion of composite indexes to support this use-case well, which would be
critical for sub 10ms performance required for fast websites. This is simply
unpractical.</p>
<p>Unfortunately, for sub 10ms response times, we also canâ€™t rely on index merges
being <em>that</em> fast, because of the ad-hoc interesection. I wrote an article about
solving the problem of queries that have <a href="https://sirupsen.com/napkin/problem-13-filtering-with-inverted-indexes">lots of conditions with Lucene</a>,
which is <em>very</em> good at doing lots of intersections. It would be interesting to
try this with <a href="https://www.postgresql.org/docs/current/gin-intro.html#:~:text=GIN%20stands%20for%20Generalized%20Inverted,appear%20within%20the%20composite%20items.">GIN-indexes</a> (inverted index, similar to what Lucene does) in
Postgres as a comparison. <a href="https://www.postgresql.org/docs/current/bloom.html">Bloom-indexes</a> may also be suited for this.
Columnar database might also be better at this, but I havenâ€™t looked at that
in-depth yet.</p>
<div><p>Subscribe through email,</p><!-- --> <p><a href="https://sirupsen.com/atom.xml">RSS</a></p><!-- --><p>or</p><!-- --> <p><a href="https://twitter.com/Sirupsen" title="Twitter" target="_blank" rel="noopener noreferrer">Twitter</a></p><!-- --><p>to new articles!</p><p> <!-- -->2,792<!-- --> <!-- -->subscribers</p></div></article></div>
  </body>
</html>
