<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://decrypt.co/149826/openai-quietly-shutters-its-ai-detection-tool">Original</a>
    <h1>OpenAI shuts down its AI Classifier due to poor accuracy</h1>
    
    <div id="readability-page-1" class="page"><div><p>In January, artificial intelligence powerhouse OpenAI announced a tool that could save the world—or at least preserve the sanity of professors and teachers—by detecting whether a piece of content had been created using generative AI tools like its own ChatGPT.</p><p>Half a year later, that tool is dead, killed because it couldn’t do what it was designed to do.</p><p>ChatGPT creator OpenAI quietly unplugged its AI detection tool, AI Classifier, last week because of “its low rate of accuracy,” the firm said. The explanation was not in a new announcement, but added in a note added to the <a href="https://openai.com/blog/new-ai-classifier-for-indicating-ai-written-text" target="_blank" rel="noopener nofollow external">blog post</a> that first announced the tool. The link to OpenAI&#39;s classifier is no longer available.</p><p>&#34;We are working to incorporate feedback and are currently researching more effective provenance techniques for text, and have made a commitment to develop and deploy mechanisms that enable users to understand if audio or visual content is AI-generated,&#34; OpenAI wrote.</p><p>New tools allowing the use of increasingly sophisticated AI come online almost daily and have created a cottage industry of AI detectors.</p><p>OpenAI announced the launch of its AI Classifier claiming it could distinguish between text written by a human and an AI. Even then, however, OpenAI called the classifier &#34;not fully reliable,&#34; adding that the evaluations on a “challenge set” of English texts correctly identified 26% of AI-written text as “likely AI-written,” while incorrectly labeling the human-written text as AI-written 9% of the time.</p><p>OpenAI said limitations of the AI Classifier include being unreliable on text with fewer than 1,000 characters, incorrectly labeling text written by humans as written by AI, and classifiers based on neural networks performing poorly outside of their training data.</p><p>One sector that is acutely interested in accurately detecting AI is education. Since the launch of ChatGPT in November, educators have sounded the alarm of students using the chatbot to write <a href="https://www.nytimes.com/2023/01/16/technology/chatgpt-artificial-intelligence-universities.html" target="_blank">essays</a>.</p><p>&#34;We recognize that identifying AI-written text has been an important point of discussion among educators, and equally important is recognizing the limits and impacts of AI generated text classifiers in the classroom,&#34; OpenAI said, adding that the company will continue to broaden outreach as it learns.</p><p>OpenAI has not yet responded to <i>Decrypt&#39;s</i> request for comment.</p><div><div><h3>Stay on top of crypto news, get daily updates in your inbox.</h3></div></div></div></div>
  </body>
</html>
