<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.cubic.dev/blog/learnings-from-building-ai-agents">Original</a>
    <h1>Learnings from building AI agents</h1>
    
    <div id="readability-page-1" class="page"><div data-framer-name="Content" data-framer-component-type="RichTextContainer"><p>I’m Paul, cofounder of <!--$--><a href="http://cubic.dev/" rel="noopener">cubic</a><!--/$-->—an &#34;AI-native GitHub.&#34; One of our core features is an AI code review agent that performs an initial review pass, catching bugs, anti-patterns, duplicated code, and similar issues in pull requests.</p><p>When we first released this agent back in April, the main feedback we got was straightforward: it was too noisy.</p><p>Even small PRs often ended up flooded with multiple low-value comments, nitpicks, or outright false positives. Rather than helping reviewers, it cluttered discussions and obscured genuinely valuable feedback.</p><p><img alt="" height="236" src="https://framerusercontent.com/images/0Ap1gf4atqffqos1sHElEMB26DA.png" srcset="https://framerusercontent.com/images/0Ap1gf4atqffqos1sHElEMB26DA.png?scale-down-to=512 512w,https://framerusercontent.com/images/0Ap1gf4atqffqos1sHElEMB26DA.png?scale-down-to=1024 1024w,https://framerusercontent.com/images/0Ap1gf4atqffqos1sHElEMB26DA.png?scale-down-to=2048 2048w,https://framerusercontent.com/images/0Ap1gf4atqffqos1sHElEMB26DA.png 2052w" width="1026" data-framer-original-sizes="" sizes="(min-width: 1200px) 100vw, (min-width: 1000px) and (max-width: 1199px) 100vw, (max-width: 999px) 100vw"/></p><p><em>An example nitpick</em></p><p>We decided to take a step back and thoroughly investigate why this was happening.</p><p>After three major architecture revisions and extensive offline testing, we managed to reduce false positives by <strong>51%</strong> without sacrificing recall.</p><p>Many of these lessons turned out to be broadly useful—not just for code review agents but for designing effective AI systems in general.</p><h2>1. The Face‑Palm Phase: A Single, Do‑Everything Agent</h2><p>Our initial architecture was straightforward but problematic:</p><div><div><div><div><div><div aria-labelledby="/example.md-:R1d2tabb8m:-tab" id="/example.md-:R1d2tabb8m:-tab-panel" role="tabpanel"><div aria-autocomplete="list" aria-label="Code Editor for example.md" aria-multiline="true" role="textbox" tabindex="0" translate="no"><pre><span>[diff]</span>
↓
<span>[single large prompt with contextual codebase info]</span>
↓
<span>[list of comments]</span></pre></div></div></div></div></div></div></div><p>It looked clean in theory but quickly fell apart in practice:</p><ul><li data-preset-tag="p"><p>Excessive false positives: The agent often mistook style issues for critical bugs, flagged resolved issues, and repeated suggestions our linters had already addressed.</p></li><li data-preset-tag="p"><p>Users lost trust: Developers quickly learned to ignore the comments altogether. When half the comments feel irrelevant, the truly important ones get missed.</p></li><li data-preset-tag="p"><p>Opaque reasoning: Understanding why the agent made specific calls was practically impossible. Even explicit prompts like &#34;ignore minor style issues&#34; had minimal effect.</p></li></ul><p>We tried standard solutions—longer prompts, adjusting the model&#39;s temperature, experimenting with sampling—but saw little meaningful improvement.</p><h2>2. What Finally Worked</h2><p>After extensive trial-and-error, we developed an architecture that significantly improved results and proved effective in real-world repositories. These solutions underpin the 51% reduction in false positives currently running in production.</p><h4>2.1 Explicit Reasoning Logs</h4><p>We required the AI to explicitly state its reasoning before providing any feedback:</p><div><div><div><div><div><div aria-labelledby="/example.js-:R1d4tabb8m:-tab" id="/example.js-:R1d4tabb8m:-tab-panel" role="tabpanel"><div aria-autocomplete="list" aria-label="Code Editor for example.js" aria-multiline="true" role="textbox" tabindex="0" translate="no"><pre><span>{</span>
  <span>&#34;reasoning&#34;</span><span>:</span> <span>&#34;`cfg` can be nil on line 42; dereferenced without check on line 47&#34;</span><span>,</span>
  <span>&#34;finding&#34;</span><span>:</span> <span>&#34;Possible nil‑pointer dereference&#34;</span><span>,</span>
  <span>&#34;confidence&#34;</span><span>:</span> <span>0.81</span>
<span>}</span></pre></div></div></div></div></div></div></div><p>This approach provided critical benefits:</p><ul><li data-preset-tag="p"><p>Enabled us to clearly trace the AI’s decision-making process. If reasoning was flawed, we could quickly identify and exclude the pattern in future iterations.</p></li><li data-preset-tag="p"><p>Encouraged structured thinking by forcing the AI to justify its findings first, significantly reducing arbitrary conclusions.</p></li><li data-preset-tag="p"><p>Created a foundation to diagnose and resolve root causes behind other issues we faced.</p></li></ul><h4>2.2 Fewer, Smarter Tools</h4><p>Initially, the agent had extensive tooling—Language Server Protocol (LSP), static analysis, test runners, and more. However, explicit reasoning logs revealed most analyses relied on a few core tools, with extra complexity causing confusion and mistakes.</p><p>We streamlined the toolkit to essential components only—a simplified LSP and a basic terminal.</p><p>With fewer distractions, the agent spent more energy confirming genuine issues, significantly improving precision.</p><h4>2.3 Specialized Micro-Agents Over Generalized Rules</h4><p>Initially, our instinct was to continuously add more rules into a single large prompt to handle edge cases:</p><ul><li data-preset-tag="p"><p>“Ignore unused variables in .test.ts files.”</p></li><li data-preset-tag="p"><p>“Skip import checks in Python’s <strong>init</strong>.py.”</p></li><li data-preset-tag="p"><p>“Don&#39;t lint markdown files.”</p></li></ul><p>This rapidly became unsustainable and was largely ineffective as the AI frequently overlooked many rules.</p><p>Our breakthrough came from employing specialized micro-agents, each handling a narrowly-defined scope:</p><ul><li data-preset-tag="p"><p><strong>Planner</strong>: Quickly assesses changes and identifies necessary checks.</p></li><li data-preset-tag="p"><p><strong>Security Agent</strong>: Detects vulnerabilities such as injection or insecure authentication.</p></li><li data-preset-tag="p"><p><strong>Duplication Agent</strong>: Flags repeated or copied code.</p></li><li data-preset-tag="p"><p><strong>Editorial Agent</strong>: Handles typos and documentation consistency.</p></li><li data-preset-tag="p"><p>etc…</p></li></ul><p>Specializing allowed each agent to maintain a focused context, keeping token usage efficient and precision high. The main trade-off was increased token consumption due to overlapping context, managed through effective caching strategies.</p><h2>3. Real-world Outcomes</h2><p>These architecture and prompt improvements led to meaningful results across hundreds of real pull requests from active open-source and private repositories. Specifically, over the past six weeks:</p><ul><li data-preset-tag="p"><p>51% fewer false positives, directly increasing developer trust and usability.</p></li><li data-preset-tag="p"><p>Median comments per pull request cut by half, helping teams concentrate on genuinely important issues.</p></li><li data-preset-tag="p"><p>Teams reported notably smoother review processes, spending less time managing irrelevant comments and more time effectively merging changes.</p></li></ul><p>Additionally, the reduced noise significantly improved developer confidence and engagement, making reviews faster and more impactful.</p><h2>4. Key Lessons</h2><ol><li data-preset-tag="p"><p>Explicit reasoning improves clarity. Require your AI to clearly explain its rationale first—this boosts accuracy and simplifies debugging.</p></li><li data-preset-tag="p"><p>Simplify the toolset. Regularly evaluate your agent&#39;s toolkit and remove tools rarely used (less than 10% of tasks).</p></li><li data-preset-tag="p"><p>Specialize with micro-agents. Keep each AI agent tightly focused on a single task, reducing cognitive overload and enhancing precision.</p></li></ol></div></div>
  </body>
</html>
