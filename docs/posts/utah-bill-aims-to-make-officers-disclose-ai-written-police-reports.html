<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://www.eff.org/deeplinks/2025/02/utah-bill-aims-make-officers-disclose-ai-written-police-reports">Original</a>
    <h1>Utah Bill Aims to Make Officers Disclose AI-Written Police Reports</h1>
    
    <div id="readability-page-1" class="page"><div>
            <article role="article">
  
  
  <div>
    <div><div><div><p><span>A bill headed to the Senate floor in Utah would </span><a href="https://www.popsci.com/technology/utah-ai-police-bill/"><span>require officers</span></a><span> to disclose if a </span><a href="https://www.eff.org/deeplinks/2024/05/what-can-go-wrong-when-police-use-ai-write-reports"><span>police report was written by generative AI</span></a><span>. </span><span>The bill, <a href="https://le.utah.gov/~2025/bills/static/SB0180.html">S.B. 180</a>, requires a department to have a policy governing the use of AI. This policy would mandate that police reports created in whole or in part by generative AI have a disclaimer that the report contains content generated by AI and requires officers to legally certify that the report was checked for accuracy.</span></p>
<p><span>S.B. 180 is unfortunately a necessary step in the right direction when it comes to regulating the rapid spread of police using generative AI to write their narrative reports for them. EFF will continue to monitor this bill in hopes that it will be part of a larger conversation about more robust regulations. Specifically, Axon, the makers of tasers and the salespeople behind a </span><a href="https://www.vice.com/en/article/axon-acquires-fusus-ai-surveillance-retail-healthcare/"><span>shocking amount of police and surveillance tech</span></a><span>, has recently rolled out a new product, </span><a href="https://www.police1.com/police-products/police-technology/software/report-writing/revolutionizing-police-report-writing-axons-draft-one-transforms-the-tedious-into-the-effortless"><span>Draft One</span></a><span>, which uses body-worn camera audio to generate police reports. This product is spreading quickly in part because it is integrated with other </span><a href="https://theintercept.com/2021/12/08/police-reform-body-cameras-axon-motorola/"><span>Axon products which are already omnipresent in U.S. society</span></a><span>. <br/></span></p>
<p><span>But it’s going to take more than a disclaimer to curb the potential harms of AI-generated police reports. <br/></span></p>
<p><span>As we’ve previously cautioned, the public should be skeptical of AI’s ability to accurately process and distinguish between the wide range of languages, dialects, vernacular, idioms, and slang people use. As online content moderation has shown, software may have a passable ability to capture words, but it often</span><a href="https://www.eff.org/deeplinks/2019/04/content-moderation-broken-let-us-count-ways"> <span>struggles with content and meaning</span></a><span>. In a tense setting such as a traffic stop, AI mistaking a metaphorical statement for a literal claim could fundamentally change the content of a police report.</span></p>
<p><span>Moreover, so-called</span><a href="https://www.eff.org/deeplinks/2024/03/how-avoid-ai-apocalypse-one-easy-step"> <span>artificial intelligence</span></a><span> taking over consequential tasks and decision-making has the power to obscure human agency. Police officers who deliberately exaggerate or lie to shape the narrative available in body camera footage now have even more of a veneer of plausible deniability with AI-generated police reports. If police were to be caught in a lie concerning what’s in the report, an officer might be able to say that they did not lie: the AI simply did not capture what was happening in the chaotic video.</span></p>
<p><span>As this technology spreads without much transparency, oversight, or guardrails, we are likely to see more cities, counties, and states push back against its use. Out of fear that AI-generated reports would complicate and compromise cases in the criminal justice system,prosecutors in King County, Washington (which includes Seattle) </span><a href="https://www.eff.org/deeplinks/2024/10/prosecutors-washington-state-warn-police-dont-use-gen-ai-write-reports"><span>have instructed</span></a><span> officers not to use the technology for now. <br/></span></p>
<p><span>The use of AI to write police reports is troubling in ways we are accustomed to, but also in new ways. Not only do we not yet know how widespread use of this technology will affect the criminal justice system, but because of how the product is designed, there is a chance we won’t even know if AI has been used even if we are staring directly at the police report in question. For that reason, it’s no surprise that lawmakers in Utah have introduced this bill to require some semblance of transparency. We will likely see similar regulations and restrictions in other states and local jurisdictions, and possibly even stronger ones. </span></p>

</div></div></div>  </div>

          </article>
    </div></div>
  </body>
</html>
