<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://gwern.net/socks">Original</a>
    <h1>On Having Enough Socks (2019)</h1>
    
    <div id="readability-page-1" class="page"><div id="page-metadata">
        <p>Personal experience and surveys on running out of socks; discussion of socks as small example of human procrastination and irrationality, caused by lack of explicit deliberative thought where no natural triggers or habits exist.</p>
        
        
      </div><div id="markdownBody">
        <div>
          <blockquote>
            <p>After running out of socks one day, I reflected on how ordinary tasks get neglected. Anecdotally and in 3 online surveys, people report often not having enough socks, a problem which correlates with rarity of sock purchases and demographic variables, consistent with a neglect/​procrastination interpretation: because there is no specific time or triggering factor to replenish a shrinking sock stockpile, it is easy to run out.</p>
            <p>This reminds me of <a href="https://en.wikipedia.org/wiki/Akrasia" data-link-icon="wikipedia" data-link-icon-type="svg">akrasia</a> on minor tasks, ‘yak shaving’, and the nature of disaster in complex systems: lack of hard rules lets errors accumulate, without any ‘global’ understanding of the drift into disaster (or at least inefficiency). Humans on a smaller scale also ‘drift’ when they engage in System I reactive thinking &amp; action for too long, resulting in <a href="https://en.wikipedia.org/wiki/Cognitive_bias" data-link-icon="wikipedia" data-link-icon-type="svg">cognitive biases</a>⁠. An example of drift is the generalized human failure to explore/​experiment adequately, resulting in overly greedy exploitative behavior of the current local optimum. Grocery shopping provides a case study: despite large gains, most people do not explore, perhaps because there is no established routine or practice involving experimentation. Fixes for these things can be seen as ensuring that System II deliberative cognition is periodically invoked to review things at a global level, such as developing a habit of maximum exploration at first purchase of a food product, or annually reviewing possessions to note problems like a lack of socks.</p>
            <p>While socks may be small things, they may reflect big things.</p>
          </blockquote>
        </div>
        <p>Socks possess the mysterious power, like <a href="https://en.wikipedia.org/wiki/Cat" data-link-icon="wikipedia" data-link-icon-type="svg">cats</a>⁠, of vanishing; unlike cats, they don’t get hungry and come back. So I found myself one day in summer 2013 doing laundry a week early and wasting time schlepping back &amp; forth solely because I had run out of socks entirely and couldn’t bear walking around in dirty socks. I suddenly realized that this was a ridiculous problem to have in an age awash with cheap textiles (so cheap that clothes must be shipped to Africa or incinerated lest the thrift stores burst at the seams), and immediately went on Amazon &amp; bought a pack of 30 pairs to refill my ‘sockpile’.<a href="#fn1" id="fnref1" role="doc-noteref"><sup>1</sup></a> This made me curious: how many other people don’t have enough socks, and why not?</p>
        <p>I began asking people if they thought they had enough socks and quite a few people would say that they didn’t, but they hadn’t quite gotten around to it. (Although some insist <a href="https://en.wikipedia.org/wiki/Cabot_Hosiery_Mills" data-link-icon="wikipedia" data-link-icon-type="svg">Darn Tough socks</a> changed their lives forever.)</p>
        <p>So I began running polls, and I am not alone.</p>
        <section id="sock-surveys">
          
          <p>An otherwise-unpublished Samsung sock survey finds that <a href="https://ntietz.com/doc/www/news.samsung.com/8d1036a5985aa4d00e2d2cde864feb8365c1917c.html" rel="archived alternate nofollow" data-url-original="https://news.samsung.com/global/sock-horror-mystery-of-missing-socks-is-solved-scientists-reveal-why-socks-go-missing-in-the-wash-and-how-likely-it-is-to-happen" title="Sock, Horror - Mystery of Missing Socks is Solved! Scientists Reveal Why Socks Go Missing in the Wash and How Likely it is to Happen (Original URL: https://news.samsung.com/global/sock-horror-mystery-of-missing-socks-is-solved-scientists-reveal-why-socks-go-missing-in-the-wash-and-how-likely-it-is-to-happen )">“Brits lose an average of 1.3 socks each month (and more than 15 in a year)”</a>⁠, implying an annual loss of ~8 pairs in the best case scenario: where you either don’t need exact matches (because all socks are the same kind) or don’t mind mismatches.<a href="#fn2" id="fnref2" role="doc-noteref"><sup>2</sup></a> If each pair is unique and one goes missing from each, then in the worst case an annual loss of 15 individual socks implies one must buy another 15 pairs. This appears to be in addition to wear-and-tear or changes in necessary type, which must be made up for.</p>
          <p>In a Twitter survey 2019-01-20–2019-01-27 of my followers, I asked:</p>
          <blockquote>
            <ol type="1">
              <li>
                <p>Do you have enough pairs of socks?</p>
                <ul>
                  <li>Yes: 64% (<em>n</em> = 689)</li>
                  <li>No: 37% (<em>n</em> = 405)</li>
                </ul>
              </li>
              <li>
                <p>How many pairs of socks do you have?</p>
                <ul>
                  <li>0–10: 18% (<em>n</em> = 118)</li>
                  <li>11–20: 46% (<em>n</em> = 302)</li>
                  <li>21–30: 27% (<em>n</em> = 177)</li>
                  <li>31+: 9% (<em>n</em> = 59)</li>
                </ul>
              </li>
              <li>
                <p>How often do you buy replacement socks?</p>
                <ul>
                  <li>Monthly: 2% (<em>n</em> = 15)</li>
                  <li>Semi-annually: 33% (<em>n</em> = 254)</li>
                  <li>Annually: 37% (<em>n</em> = 285)</li>
                  <li>Less or never: 28% (<em>n</em> = 216)</li>
                </ul>
              </li>
              <li>
                <p>Who buys your socks?</p>
                <ul>
                  <li>Me: 75% (<em>n</em> = 580)</li>
                  <li>Spouse/​significant-other: 7% (<em>n</em> = 54)</li>
                  <li>Relative: 16% (<em>n</em> = 123)</li>
                  <li>Other: 2% (<em>n</em> = 15)</li>
                </ul>
              </li>
            </ol>
          </blockquote>
          <p>At least among my Twitter social circle, not having enough socks is common and a fair number of people are on the verge of sock bankruptcy. An answer to why suggests itself by the purchase details: most people are responsible for their own sock maintenance, but buy on perhaps not even an annual basis (a plurality buy ‘annually’, and the ‘semi-annually’ may be more than offset by the ‘less or never’ respondents); so it’s easy to forget and not buy socks.</p>
          <p>Is socklessness concentrated among those who must buy their own socks &amp; do so rarely? Twitter responses are independent and not linked by username (only the aggregate %s and total <em>n</em> are reported), so there’s no way to know from the responses, so there’s no way to see the intercorrelations.</p>
          <p>To do that, I set up a <a href="https://en.wikipedia.org/wiki/Google_Surveys" data-link-icon="wikipedia" data-link-icon-type="svg">Google Surveys</a> survey on 2019-01-20 (<a href="https://ntietz.com/doc/psychology/2019-01-20-gs-socks.csv" data-link-icon="csv" data-link-icon-type="svg">CSV</a>), asking all 4 questions in a single survey with <em>n</em> = 130 US responses costing $100. (This is more expensive than my usual trick of asking only 1 question, and costs $1/​response rather than $0.10/​response, but a set of 4 single-question surveys would be the same as the Twitter survey.) Eric Jorgensen also ran a version of the survey on a personality quiz website with an international audience (<a href="https://ntietz.com/doc/psychology/2019-01-21-eric-socksurvey.ods" data-link-icon="spreadsheet" data-link-icon-type="svg">ODS</a>⁠/ ​<a href="https://ntietz.com/doc/psychology/2019-01-21-eric-socksurvey.csv" data-link-icon="csv" data-link-icon-type="svg">CSV</a>), with <em>n</em> = 455. They have the same questions (with the exception of the sock count question, where his survey asked for a numeric rather than ordinal response, so I convert it back to ordinal), so I pool them for analysis:</p>
          <div id="cb1">
            <pre><code><span id="cb1-1">socks <span>&lt;-</span> <span>read.csv</span>(<span>&#34;https://gwern.net/doc/psychology/2019-01-20-gs-socks.csv&#34;</span>)</span>
<span id="cb1-2">socks <span>&lt;-</span> <span>subset</span>(socks, <span>select=</span><span>c</span>(<span>&#34;Question..1.Answer&#34;</span>, <span>&#34;Question..2.Answer&#34;</span>, <span>&#34;Question..3.Answer&#34;</span>, <span>&#34;Question..4.Answer&#34;</span>))</span>
<span id="cb1-3">socks <span>&lt;-</span> socks[socks<span>$</span>Question..<span>3.</span>Answer<span>!=</span><span>&#34;&#34;</span>,] <span># rm NAs</span></span>
<span id="cb1-4">socks <span>&lt;-</span> socks[socks<span>$</span>Question..<span>4.</span>Answer<span>!=</span><span>&#34;&#34;</span>,] <span># rm NAs</span></span>
<span id="cb1-5">socks<span>$</span>Question..<span>1.</span>Answer <span>&lt;-</span> socks<span>$</span>Question..<span>1.</span>Answer<span>==</span><span>&#34;Yes&#34;</span></span>
<span id="cb1-6">socks<span>$</span>Question..<span>2.</span>Answer <span>&lt;-</span> <span>as.ordered</span>(socks<span>$</span>Question..<span>2.</span>Answer)</span>
<span id="cb1-7">socks<span>$</span>Question..<span>3.</span>Answer <span>&lt;-</span> <span>ordered</span>(socks<span>$</span>Question..<span>3.</span>Answer, <span>levels=</span><span>c</span>(<span>&#34;monthly&#34;</span>, <span>&#34;semi-annually&#34;</span>, <span>&#34;annually&#34;</span>, <span>&#34;less/never&#34;</span>))</span>
<span id="cb1-8">socks<span>$</span>Question..<span>4.</span>Answer <span>&lt;-</span> <span>ordered</span>(socks<span>$</span>Question..<span>4.</span>Answer, <span>levels=</span><span>c</span>(<span>&#34;me&#34;</span>, <span>&#34;spouse or significant other&#34;</span>, <span>&#34;relative&#34;</span>, <span>&#34;other&#34;</span>))</span>
<span id="cb1-9">socksI <span>&lt;-</span> <span>with</span>(socks, <span>data.frame</span>(<span>Enough=</span><span>as.integer</span>(Question..<span>1.</span>Answer), <span>Count=</span><span>as.integer</span>(Question..<span>2.</span>Answer), <span>Frequency=</span><span>as.integer</span>(Question..<span>3.</span>Answer), <span>Purchaser=</span><span>as.integer</span>(Question..<span>4.</span>Answer)))</span>
<span id="cb1-10"></span>
<span id="cb1-11">eric <span>&lt;-</span> <span>read.csv</span>(<span>&#34;https://gwern.net/doc/psychology/2019-01-21-eric-socksurvey.csv&#34;</span>)</span>
<span id="cb1-12">eric<span>$</span>Count <span>&lt;-</span> <span>as.integer</span>(<span>ordered</span>(<span>sapply</span>(eric<span>$</span>Count, <span>function</span>(c) { <span>if</span> (c<span>&lt;=</span><span>10</span>) { <span>&#34;0-10&#34;</span>; } <span>else</span> { <span>if</span> (c<span>&lt;=</span><span>20</span>) { <span>&#34;11-20&#34;</span>; } <span>else</span> { <span>if</span> (c<span>&lt;=</span><span>30</span>) { <span>&#34;21-30&#34;</span>; } <span>else</span> { <span>&#34;31+&#34;</span>; }}}})))</span>
<span id="cb1-13">ericI <span>&lt;-</span> <span>subset</span>(eric, <span>select=</span><span>c</span>(<span>&#34;Enough&#34;</span>, <span>&#34;Count&#34;</span>, <span>&#34;Frequency&#34;</span>, <span>&#34;Purchaser&#34;</span>))</span>
<span id="cb1-14"></span>
<span id="cb1-15">socksAllI <span>&lt;-</span> <span>rbind</span>(socksI, ericI)</span>
<span id="cb1-16"></span>
<span id="cb1-17">## Descriptive:</span>
<span id="cb1-18"><span>library</span>(skimr)</span>
<span id="cb1-19"><span>skim</span>(socksAllI)</span>
<span id="cb1-20"># Skim summary statistics</span>
<span id="cb1-21">#  n obs: 599</span>
<span id="cb1-22">#  n variables: 4</span>
<span id="cb1-23">#</span>
<span id="cb1-24"># ── Variable type:integer</span>
<span id="cb1-25">#   variable missing complete   n mean   sd p0 p25 p50 p75 p100     hist</span>
<span id="cb1-26">#      Count       0      599 599 2.04 0.91  1   1   2   3    4 ▆▁▇▁▁▃▁▂</span>
<span id="cb1-27">#     Enough       0      599 599 0.84 0.37  0   1   1   1    1 ▂▁▁▁▁▁▁▇</span>
<span id="cb1-28">#  Frequency       0      599 599 2.76 0.87  1   2   3   3    4 ▁▁▇▁▁▇▁▅</span>
<span id="cb1-29">#  Purchaser       0      599 599 1.63 0.96  1   1   1   3    4 ▇▁▁▁▁▂▁▁</span>
<span id="cb1-30"></span>
<span id="cb1-31">#  n obs: 600</span>
<span id="cb1-32">#  n variables: 4</span>
<span id="cb1-33">#</span>
<span id="cb1-34"># ── Variable type:integer</span>
<span id="cb1-35">#   variable missing complete   n mean   sd p0 p25 p50 p75 p100     hist</span>
<span id="cb1-36">#      Count       0      600 600 2.04 0.92  1   1   2   3    4 ▆▁▇▁▁▃▁▂</span>
<span id="cb1-37">#     Enough       0      600 600 0.84 0.37  0   1   1   1    1 ▂▁▁▁▁▁▁▇</span>
<span id="cb1-38">#  Frequency       1      599 600 2.76 0.87  1   2   3   3    4 ▁▁▇▁▁▇▁▅</span>
<span id="cb1-39">#  Purchaser       0      600 600 1.63 0.96  1   1   1   3    4 ▇▁▁▁▁▂▁▁</span>
<span id="cb1-40"></span>
<span id="cb1-41">## Bivariate correlations:</span>
<span id="cb1-42"><span>library</span>(psych)</span>
<span id="cb1-43"><span>polychoric</span>(socksAllI)</span>
<span id="cb1-44"># Polychoric correlations</span>
<span id="cb1-45">#           Enogh Count Frqnc Prchs</span>
<span id="cb1-46"># Enough     1.00</span>
<span id="cb1-47"># Count      0.29  1.00</span>
<span id="cb1-48"># Frequency −0.23 −0.08  1.00</span>
<span id="cb1-49"># Purchaser  0.16 −0.01  0.17  1.00</span>
<span id="cb1-50">#</span>
<span id="cb1-51">#  with tau of</span>
<span id="cb1-52">#               1     2     3    4</span>
<span id="cb1-53"># Enough    −0.99   Inf   Inf  Inf</span>
<span id="cb1-54"># Count      -Inf −0.48  0.62 1.38</span>
<span id="cb1-55"># Frequency  -Inf −1.60 −0.21 0.74</span>
<span id="cb1-56"># Purchaser  -Inf  0.45  0.64 1.71</span></code></pre>
          </div>
          <p>The GS respondents have less of an issue with sock shortages than my Twitter respondents (unsurprisingly) with 15% rather than 37% sockless, and the bivariate polychoric correlations<a href="#fn3" id="fnref3" role="doc-noteref"><sup>3</sup></a> make sense to me: count and having enough correlate strongly, of course, while frequency &amp; purchaser distance predict less socks/​more risk of not having enough.</p>
          <p>What about joint relationships? <a href="https://github.com/paul-buerkner/brms" data-link-icon="R" data-link-icon-type="text" title="&#39;brms: an R package for Bayesian generalized multivariate non-linear multilevel models using Stan&#39;, Bürkner 2023"><code>brms</code></a> conveniently supports <a href="https://cran.r-project.org/web/packages/brms/vignettes/brms_monotonic.html" data-link-icon="R" data-link-icon-type="text">ordinal predictors via “monotonic effects”</a> in addition to supporting ordinal regression for ordinal outcomes, so there’s no problem modeling any of the variables in any combination; given the overlap of sock count &amp; having enough, it doesn’t make much sense to use one as a predictor of the other (although extracting a factor might make sense). So to do regression from <code>Frequency</code> &amp; <code>Purchaser</code> onto <code>Enough</code> &amp; <code>Count</code>:</p>
          <div id="cb2">
            <pre><code><span id="cb2-1"><span>library</span>(brms)</span>
<span id="cb2-2"><span>brm</span>(Enough <span>~</span> <span>mo</span>(Frequency) <span>+</span> <span>mo</span>(Purchaser), <span>family=</span><span>&#34;bernoulli&#34;</span>, <span>data=</span>socksAllI)</span>
<span id="cb2-3"># ...Population-Level Effects:</span>
<span id="cb2-4">#             Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat</span>
<span id="cb2-5"># Intercept       2.26      0.28     1.79     2.91       1851 1.00</span>
<span id="cb2-6"># moFrequency    −0.93      0.37    −1.71    −0.24       1948 1.00</span>
<span id="cb2-7"># moPurchaser    −0.58      0.39    −1.38     0.17       3365 1.00</span>
<span id="cb2-8"># ...</span>
<span id="cb2-9"><span>brm</span>(Count <span>~</span> <span>mo</span>(Frequency) <span>+</span> <span>mo</span>(Purchaser), <span>family=</span><span>&#34;cumulative&#34;</span>, <span>data=</span>socksAllI)</span>
<span id="cb2-10"># ...Population-Level Effects:</span>
<span id="cb2-11">#              Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat</span>
<span id="cb2-12"># Intercept[1]    −1.03      0.17    −1.39    −0.72       2488 1.00</span>
<span id="cb2-13"># Intercept[2]     0.77      0.17     0.41     1.06       2860 1.00</span>
<span id="cb2-14"># Intercept[3]     2.17      0.20     1.75     2.56       3505 1.00</span>
<span id="cb2-15"># moFrequency     −0.52      0.25    −1.02    −0.03       2558 1.00</span>
<span id="cb2-16"># moPurchaser      0.02      0.29    −0.49     0.68       3142 1.00</span></code></pre>
          </div>
          <p>While different parameterizations, the message remains the same: a fair number of people do not have socks (it’s not only me), and this particularly correlates with not frequently purchasing socks.</p>
          <section id="demographics">
            <h2><a href="#demographics" title="Link to section: § &#39;Demographics&#39;">Demographics</a></h2>
            <div>
              <p>Incidentally, both the GS &amp; Eric Jorgensen polls include some demographics data: estimated gender/​age/​location for GS, and ESL-speaker/​country/​gender for Eric Jorgensen. Those aren’t my main interest here, but how do they look?</p>
              <p>One could make some predictions based on stereotypes: women will have more socks than men, older people will be more likely to have enough socks than younger people, and there will probably be cross-country differences. Checking, older people are indeed more likely, cross-country differences are not so large as to be inferable, and there appears to be inconsistency in gender effects: men have more problems with socks in the US than internationally?</p>
            </div>
            <p>Jorgensen’s data first; because of the large number of countries, heavy regularization must be used:</p>
            <div id="cb3">
              <pre><code><span id="cb3-1"><span>polychoric</span>(<span>subset</span>(eric, <span>select=</span><span>c</span>(Gender.Int, Enough, Frequency, Purchaser)))</span>
<span id="cb3-2"># Polychoric correlations</span>
<span id="cb3-3">#            Gnd.I Enogh Frqnc Prchs</span>
<span id="cb3-4"># Gender.Int  1.00</span>
<span id="cb3-5"># Enough      0.02  1.00</span>
<span id="cb3-6"># Frequency  −0.01 −0.25  1.00</span>
<span id="cb3-7"># Purchaser   0.20  0.24  0.15  1.00</span>
<span id="cb3-8"><span>brm</span>(Enough <span>~</span> Gender <span>+</span> Country <span>+</span> <span>mo</span>(Frequency) <span>+</span> <span>mo</span>(Purchaser), <span>family=</span>bernoulli, <span>prior=</span><span>c</span>(<span>set_prior</span>(<span>&#34;horseshoe(1, par_ratio=0.05)&#34;</span>)), <span>control =</span> <span>list</span>(<span>max_treedepth =</span> <span>15</span>, <span>adapt_delta=</span><span>0.95</span>), <span>chains=</span><span>30</span>, <span>iter=</span><span>10000</span>, <span>data=</span>eric)</span>
<span id="cb3-9"># ...Population-Level Effects:</span>
<span id="cb3-10">#             Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat</span>
<span id="cb3-11"># Intercept       1.85      0.25     1.52     2.54      10770 1.00</span>
<span id="cb3-12"># GenderMale      0.00      0.04    −0.07     0.07     131457 1.00</span>
<span id="cb3-13"># CountryAU      −0.00      0.08    −0.10     0.08     113988 1.00</span>
<span id="cb3-14"># CountryAZ       0.00      0.18    −0.10     0.12      95067 1.00</span>
<span id="cb3-15"># CountryBE       0.01      0.18    −0.09     0.11      84197 1.00</span>
<span id="cb3-16"># CountryBG       0.01      0.16    −0.08     0.13      62989 1.00</span>
<span id="cb3-17"># CountryBO       0.00      0.16    −0.10     0.12      85775 1.00</span>
<span id="cb3-18"># CountryBR       0.00      0.16    −0.09     0.11      80827 1.00</span>
<span id="cb3-19"># CountryBS      −0.09      0.53    −1.28     0.05      29590 1.00</span>
<span id="cb3-20"># CountryCA       0.00      0.08    −0.08     0.10     118251 1.00</span>
<span id="cb3-21"># CountryCH      −0.02      0.26    −0.20     0.07      55249 1.00</span>
<span id="cb3-22"># CountryCZ       0.01      0.18    −0.08     0.15      54813 1.00</span>
<span id="cb3-23"># CountryDE       0.01      0.18    −0.07     0.16      72813 1.00</span>
<span id="cb3-24"># CountryDK      −0.00      0.11    −0.11     0.09     111953 1.00</span>
<span id="cb3-25"># CountryEE       0.00      0.15    −0.10     0.11     109200 1.00</span>
<span id="cb3-26"># CountryES       0.01      0.17    −0.09     0.12      59172 1.00</span>
<span id="cb3-27"># CountryFI       0.00      0.15    −0.10     0.11      90646 1.00</span>
<span id="cb3-28"># CountryFR      −0.00      0.11    −0.11     0.09     115618 1.00</span>
<span id="cb3-29"># CountryGB      −0.00      0.06    −0.09     0.08     101507 1.00</span>
<span id="cb3-30"># CountryGR       0.01      0.18    −0.08     0.13      33231 1.00</span>
<span id="cb3-31"># CountryHK       0.01      0.15    −0.09     0.12      73429 1.00</span>
<span id="cb3-32"># CountryHR      −0.01      0.12    −0.13     0.08      98295 1.00</span>
<span id="cb3-33"># CountryHU       0.01      0.17    −0.09     0.12      85208 1.00</span>
<span id="cb3-34"># CountryID       0.00      0.10    −0.08     0.11      91982 1.00</span>
<span id="cb3-35"># CountryIE      −0.01      0.15    −0.15     0.07      55181 1.00</span>
<span id="cb3-36"># CountryIL      −0.04      0.28    −0.46     0.06      35464 1.00</span>
<span id="cb3-37"># CountryIN      −0.02      0.13    −0.20     0.06      69378 1.00</span>
<span id="cb3-38"># CountryIR      −0.02      0.25    −0.19     0.07      53285 1.00</span>
<span id="cb3-39"># CountryIS      −0.03      0.29    −0.23     0.07      44140 1.00</span>
<span id="cb3-40"># CountryIT       0.00      0.16    −0.10     0.11      71643 1.00</span>
<span id="cb3-41"># CountryJE       0.00      0.16    −0.09     0.11      65529 1.00</span>
<span id="cb3-42"># CountryJM       0.00      0.11    −0.09     0.11      91020 1.00</span>
<span id="cb3-43"># CountryJP       0.00      0.10    −0.09     0.09     118871 1.00</span>
<span id="cb3-44"># CountryKE       0.01      0.16    −0.09     0.12     104434 1.00</span>
<span id="cb3-45"># CountryKR       0.01      0.16    −0.09     0.12      93687 1.00</span>
<span id="cb3-46"># CountryLB       0.01      0.17    −0.08     0.14      51394 1.00</span>
<span id="cb3-47"># CountryLT       0.01      0.15    −0.09     0.12      97039 1.00</span>
<span id="cb3-48"># CountryMD       0.00      0.16    −0.09     0.11      79148 1.00</span>
<span id="cb3-49"># CountryMK      −0.01      0.17    −0.16     0.07      14656 1.00</span>
<span id="cb3-50"># CountryMM       0.00      0.15    −0.09     0.11     107831 1.00</span>
<span id="cb3-51"># CountryMX       0.01      0.16    −0.08     0.12      84871 1.00</span>
<span id="cb3-52"># CountryMY       0.01      0.19    −0.08     0.15      57119 1.00</span>
<span id="cb3-53"># CountryNL       0.04      0.31    −0.05     0.48      44071 1.00</span>
<span id="cb3-54"># CountryNO       0.00      0.10    −0.08     0.11     101486 1.00</span>
<span id="cb3-55"># CountryNONE     0.03      0.28    −0.06     0.33      36810 1.00</span>
<span id="cb3-56"># CountryPH      −0.01      0.13    −0.20     0.06      63309 1.00</span>
<span id="cb3-57"># CountryPL       0.00      0.10    −0.10     0.10      97421 1.00</span>
<span id="cb3-58"># CountryPT       0.01      0.17    −0.09     0.12      69037 1.00</span>
<span id="cb3-59"># CountryQA       0.01      0.16    −0.09     0.11      66602 1.00</span>
<span id="cb3-60"># CountryRO       0.01      0.16    −0.09     0.11      82836 1.00</span>
<span id="cb3-61"># CountryRU       0.00      0.15    −0.09     0.11      99649 1.00</span>
<span id="cb3-62"># CountrySA       0.01      0.17    −0.09     0.11      70890 1.00</span>
<span id="cb3-63"># CountrySE      −0.00      0.08    −0.10     0.08     105770 1.00</span>
<span id="cb3-64"># CountrySG       0.02      0.21    −0.06     0.20      48360 1.00</span>
<span id="cb3-65"># CountryTR      −0.01      0.17    −0.16     0.07      56410 1.00</span>
<span id="cb3-66"># CountryTT       0.01      0.17    −0.08     0.14      68940 1.00</span>
<span id="cb3-67"># CountryUA       0.01      0.16    −0.08     0.13      60610 1.00</span>
<span id="cb3-68"># CountryUS      −0.01      0.06    −0.14     0.05      73991 1.00</span>
<span id="cb3-69"># CountryVE       0.01      0.17    −0.09     0.13      35998 1.00</span>
<span id="cb3-70"># CountryVN       0.00      0.17    −0.09     0.11      54781 1.00</span>
<span id="cb3-71"># CountryXK       0.00      0.16    −0.10     0.12     101146 1.00</span>
<span id="cb3-72"># CountryZA       0.01      0.16    −0.08     0.13      59905 1.00</span>
<span id="cb3-73"># moFrequency    −0.17      0.40    −1.40     0.02       7944 1.00</span>
<span id="cb3-74"># moPurchaser    −0.01      0.08    −0.17     0.05      52232 1.00</span>
<span id="cb3-75"># ...</span>
<span id="cb3-76"><span>brm</span>(Count <span>~</span> Gender <span>+</span> Country <span>+</span> <span>mo</span>(Frequency) <span>+</span> <span>mo</span>(Purchaser), <span>family=</span>cumulative, <span>prior=</span><span>c</span>(<span>set_prior</span>(<span>&#34;horseshoe(1, par_ratio=0.05)&#34;</span>)), <span>control =</span> <span>list</span>(<span>max_treedepth =</span> <span>15</span>, <span>adapt_delta=</span><span>0.95</span>), <span>chains=</span><span>30</span>, <span>iter=</span><span>10000</span>, <span>data=</span>eric)</span>
<span id="cb3-77"># ...Population-Level Effects:</span>
<span id="cb3-78">#              Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat</span>
<span id="cb3-79"># Intercept[1]    −0.91      0.31    −1.57    −0.33     103560 1.00</span>
<span id="cb3-80"># Intercept[2]     1.07      0.32     0.42     1.68     105615 1.00</span>
<span id="cb3-81"># Intercept[3]     2.68      0.35     1.98     3.37     113296 1.00</span>
<span id="cb3-82"># GenderMale      −0.13      0.17    −0.50     0.16     125937 1.00</span>
<span id="cb3-83"># CountryAU       −1.03      0.69    −2.48     0.08     124545 1.00</span>
<span id="cb3-84"># CountryAZ       −0.53      1.12    −3.33     1.18     158180 1.00</span>
<span id="cb3-85"># CountryBE        0.11      0.81    −1.54     1.95     215427 1.00</span>
<span id="cb3-86"># CountryBG       −0.07      0.61    −1.45     1.20     224586 1.00</span>
<span id="cb3-87"># CountryBO        0.12      0.80    −1.51     1.97     208130 1.00</span>
<span id="cb3-88"># CountryBR       −0.55      1.13    −3.36     1.16     158105 1.00</span>
<span id="cb3-89"># CountryBS        0.27      0.91    −1.41     2.47     194178 1.00</span>
<span id="cb3-90"># CountryCA        0.98      0.57    −0.04     2.09      82595 1.00</span>
<span id="cb3-91"># CountryCH       −0.51      1.10    −3.26     1.21     161968 1.00</span>
<span id="cb3-92"># CountryCZ        0.37      0.74    −0.90     2.12     154331 1.00</span>
<span id="cb3-93"># CountryDE        0.29      0.59    −0.73     1.68     156133 1.00</span>
<span id="cb3-94"># CountryDK        0.62      0.73    −0.47     2.27     113453 1.00</span>
<span id="cb3-95"># CountryEE       −0.60      1.15    −3.44     1.12     155992 1.00</span>
<span id="cb3-96"># CountryES       −0.12      0.75    −1.84     1.38     219013 1.00</span>
<span id="cb3-97"># CountryFI        1.27      1.56    −0.79     4.96     123980 1.00</span>
<span id="cb3-98"># CountryFR       −0.17      0.55    −1.46     0.88     202919 1.00</span>
<span id="cb3-99"># CountryGB        0.17      0.28    −0.33     0.81      90166 1.00</span>
<span id="cb3-100"># CountryGR        0.02      0.62    −1.32     1.37     214245 1.00</span>
<span id="cb3-101"># CountryHK       −0.96      1.24    −4.01     0.65     144472 1.00</span>
<span id="cb3-102"># CountryHR        0.01      0.62    −1.34     1.37     222467 1.00</span>
<span id="cb3-103"># CountryHU        0.08      0.80    −1.61     1.88     212960 1.00</span>
<span id="cb3-104"># CountryID       −1.81      0.92    −3.80    −0.14     138380 1.00 # Indonesia</span>
<span id="cb3-105"># CountryIE       −0.92      1.23    −3.93     0.67     145126 1.00</span>
<span id="cb3-106"># CountryIL        0.22      0.62    −0.93     1.67     181101 1.00</span>
<span id="cb3-107"># CountryIN       −2.25      1.38    −5.43    −0.09     138907 1.00 # India</span>
<span id="cb3-108"># CountryIR        0.22      0.84    −1.40     2.21     194840 1.00</span>
<span id="cb3-109"># CountryIS        0.05      0.80    −1.64     1.84     210993 1.00</span>
<span id="cb3-110"># CountryIT        0.17      0.82    −1.47     2.07     206471 1.00</span>
<span id="cb3-111"># CountryJE        1.27      1.56    −0.79     4.96     123390 1.00</span>
<span id="cb3-112"># CountryJM        0.76      0.64    −0.23     2.10      86077 1.00</span>
<span id="cb3-113"># CountryJP       −0.42      0.60    −1.82     0.52     156615 1.00</span>
<span id="cb3-114"># CountryKE       −0.56      0.82    −2.53     0.69     164055 1.00</span>
<span id="cb3-115"># CountryKR        0.07      0.76    −1.54     1.76     219641 1.00</span>
<span id="cb3-116"># CountryLB       −0.32      0.65    −1.87     0.79     178249 1.00</span>
<span id="cb3-117"># CountryLT        0.44      0.79    −0.86     2.31     157516 1.00</span>
<span id="cb3-118"># CountryMD        0.77      1.12    −0.94     3.41     137492 1.00</span>
<span id="cb3-119"># CountryMK       −0.27      0.77    −2.13     1.12     199321 1.00</span>
<span id="cb3-120"># CountryMM       −0.46      1.08    −3.19     1.24     164795 1.00</span>
<span id="cb3-121"># CountryMX        0.36      0.68    −0.78     1.96     158241 1.00</span>
<span id="cb3-122"># CountryMY       −1.91      1.39    −5.10     0.06     133497 1.00</span>
<span id="cb3-123"># CountryNL        0.49      0.46    −0.22     1.46      90797 1.00</span>
<span id="cb3-124"># CountryNO        1.22      0.69    −0.02     2.56      91436 1.00</span>
<span id="cb3-125"># CountryNONE     −0.66      0.60    −1.95     0.25     127296 1.00</span>
<span id="cb3-126"># CountryPH       −0.25      0.51    −1.44     0.63     177716 1.00</span>
<span id="cb3-127"># CountryPL        0.09      0.45    −0.82     1.11     171907 1.00</span>
<span id="cb3-128"># CountryPT        0.92      0.98    −0.52     3.07     118487 1.00</span>
<span id="cb3-129"># CountryQA       −0.46      1.09    −3.17     1.27     166932 1.00</span>
<span id="cb3-130"># CountryRO        0.02      0.78    −1.70     1.71     216995 1.00</span>
<span id="cb3-131"># CountryRU       −0.60      1.15    −3.45     1.12     154146 1.00</span>
<span id="cb3-132"># CountrySA       −1.01      1.26    −4.07     0.61     142090 1.00</span>
<span id="cb3-133"># CountrySE        0.59      0.53    −0.23     1.72      85612 1.00</span>
<span id="cb3-134"># CountrySG       −0.67      0.71    −2.29     0.37     143570 1.00</span>
<span id="cb3-135"># CountryTR        0.14      0.67    −1.21     1.69     214560 1.00</span>
<span id="cb3-136"># CountryTT        0.65      0.87    −0.69     2.63     121131 1.00</span>
<span id="cb3-137"># CountryUA       −0.59      0.84    −2.59     0.67     150001 1.00</span>
<span id="cb3-138"># CountryUS        0.79      0.28     0.26     1.35      72791 1.00</span>
<span id="cb3-139"># CountryVE        1.35      1.14    −0.35     3.72     101866 1.00</span>
<span id="cb3-140"># CountryVN       −0.65      1.18    −3.56     1.09     153337 1.00</span>
<span id="cb3-141"># CountryXK       −0.59      1.15    −3.44     1.12     150475 1.00</span>
<span id="cb3-142"># CountryZA        0.01      0.62    −1.35     1.35     212747 1.00</span>
<span id="cb3-143"># moFrequency     −0.89      0.36    −1.61    −0.19      96417 1.00</span>
<span id="cb3-144"># moPurchaser     −0.06      0.26    −0.64     0.45     179817 1.00</span></code></pre>
            </div>
            <p>Nothing of note emerges here, except perhaps a tendency for males to have fewer socks (albeit they appear to be content with fewer); there might be country-level effects as even the horseshoe regularization doesn’t pull them tightly to zero, but there is far too little data to be confident in what the effects might be.</p>
            <p>In the GS US survey data, there is only one country, of course, but in exchange an inferred age bracket is available:</p>
            <div id="cb4">
              <pre><code><span id="cb4-1">socks <span>&lt;-</span> <span>read.csv</span>(<span>&#34;https://gwern.net/doc/psychology/2019-01-20-gs-socks.csv&#34;</span>)</span>
<span id="cb4-2">socks <span>&lt;-</span> <span>subset</span>(socks, <span>select=</span><span>c</span>(<span>&#34;Question..1.Answer&#34;</span>, <span>&#34;Question..2.Answer&#34;</span>, <span>&#34;Question..3.Answer&#34;</span>, <span>&#34;Question..4.Answer&#34;</span>, <span>&#34;Gender&#34;</span>, <span>&#34;Age&#34;</span>))</span>
<span id="cb4-3">socks <span>&lt;-</span> socks[socks<span>$</span>Question..<span>3.</span>Answer<span>!=</span><span>&#34;&#34;</span>,] <span># rm NAs</span></span>
<span id="cb4-4">socks <span>&lt;-</span> socks[socks<span>$</span>Question..<span>4.</span>Answer<span>!=</span><span>&#34;&#34;</span>,] <span># rm NAs</span></span>
<span id="cb4-5"></span>
<span id="cb4-6">socks<span>$</span>Question..<span>1.</span>Answer <span>&lt;-</span> socks<span>$</span>Question..<span>1.</span>Answer<span>==</span><span>&#34;Yes&#34;</span></span>
<span id="cb4-7">socks<span>$</span>Question..<span>2.</span>Answer <span>&lt;-</span> <span>as.ordered</span>(socks<span>$</span>Question..<span>2.</span>Answer)</span>
<span id="cb4-8">socks<span>$</span>Question..<span>3.</span>Answer <span>&lt;-</span> <span>ordered</span>(socks<span>$</span>Question..<span>3.</span>Answer, <span>levels=</span><span>c</span>(<span>&#34;monthly&#34;</span>, <span>&#34;semi-annually&#34;</span>, <span>&#34;annually&#34;</span>, <span>&#34;less/never&#34;</span>))</span>
<span id="cb4-9">socks<span>$</span>Question..<span>4.</span>Answer <span>&lt;-</span> <span>ordered</span>(socks<span>$</span>Question..<span>4.</span>Answer, <span>levels=</span><span>c</span>(<span>&#34;me&#34;</span>, <span>&#34;spouse or significant other&#34;</span>, <span>&#34;relative&#34;</span>, <span>&#34;other&#34;</span>))</span>
<span id="cb4-10">socks <span>&lt;-</span> socks[socks<span>$</span>Age<span>!=</span><span>&#34;Unknown&#34;</span> <span>&amp;</span> socks<span>$</span>Gender<span>!=</span><span>&#34;Unknown&#34;</span>,]</span>
<span id="cb4-11"></span>
<span id="cb4-12">socksI <span>&lt;-</span> <span>with</span>(socks, <span>data.frame</span>(<span>Enough=</span><span>as.integer</span>(Question..<span>1.</span>Answer), <span>Count=</span><span>as.integer</span>(Question..<span>2.</span>Answer), <span>Frequency=</span><span>as.integer</span>(Question..<span>3.</span>Answer), <span>Purchaser=</span><span>as.integer</span>(Question..<span>4.</span>Answer), <span>Age=</span><span>as.integer</span>(Age), <span>Gender=</span><span>as.integer</span>(Gender<span>==</span><span>&#34;Male&#34;</span>)))</span>
<span id="cb4-13"><span>skim</span>(socksI)</span>
<span id="cb4-14"># Skim summary statistics</span>
<span id="cb4-15">#  n obs: 114</span>
<span id="cb4-16">#  n variables: 6</span>
<span id="cb4-17">#</span>
<span id="cb4-18"># ── Variable type:integer</span>
<span id="cb4-19">#   variable missing complete   n mean   sd p0 p25 p50 p75 p100     hist</span>
<span id="cb4-20">#        Age       0      114 114 3.92 1.57  1   3   4   5    6 ▃▂▁▇▅▁▇▆</span>
<span id="cb4-21">#      Count       0      114 114 2.34 0.94  1   2   2   3    4 ▃▁▇▁▁▅▁▂</span>
<span id="cb4-22">#     Enough       0      114 114 0.79 0.41  0   1   1   1    1 ▂▁▁▁▁▁▁▇</span>
<span id="cb4-23">#  Frequency       0      114 114 2.8  0.84  1   2   3   3    4 ▁▁▅▁▁▇▁▃</span>
<span id="cb4-24">#     Gender       0      114 114 0.72 0.45  0   0   1   1    1 ▃▁▁▁▁▁▁▇</span>
<span id="cb4-25">#  Purchaser       0      114 114 1.39 0.88  1   1   1   1    4 ▇▁▁▁▁▁▁▁</span>
<span id="cb4-26"><span>polychoric</span>(socksI)</span>
<span id="cb4-27"># Polychoric correlations</span>
<span id="cb4-28">#           Enogh Count Frqnc Prchs Age   Gendr</span>
<span id="cb4-29"># Enough     1.00</span>
<span id="cb4-30"># Count      0.19  1.00</span>
<span id="cb4-31"># Frequency −0.21  0.12  1.00</span>
<span id="cb4-32"># Purchaser −0.23 −0.24 −0.25  1.00</span>
<span id="cb4-33"># Age        0.17  0.08  0.09 −0.20  1.00</span>
<span id="cb4-34"># Gender    −0.49 −0.14  0.11  0.55  0.26  1.00</span>
<span id="cb4-35"><span>brm</span>(Enough <span>~</span> Gender <span>+</span> <span>mo</span>(Age) <span>+</span> <span>mo</span>(Frequency) <span>+</span> <span>mo</span>(Purchaser), <span>family=</span><span>&#34;bernoulli&#34;</span>, <span>data=</span>socksI)</span>
<span id="cb4-36"># ...Population-Level Effects:</span>
<span id="cb4-37">#             Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat</span>
<span id="cb4-38"># Intercept       2.42      1.13     0.28     4.70       2064 1.00</span>
<span id="cb4-39"># Gender         −1.81      0.91    −3.82    −0.27       2802 1.00</span>
<span id="cb4-40"># moAge           1.08      0.84    −0.52     2.81       2342 1.00</span>
<span id="cb4-41"># moFrequency    −0.03      1.00    −1.87     2.10       2111 1.00</span>
<span id="cb4-42"># moPurchaser    −0.99      0.75    −2.50     0.45       3191 1.00</span>
<span id="cb4-43"><span>brm</span>(Count <span>~</span> Gender <span>+</span> <span>mo</span>(Age) <span>+</span> <span>mo</span>(Frequency) <span>+</span> <span>mo</span>(Purchaser), <span>family=</span><span>&#34;cumulative&#34;</span>, <span>data=</span>socksI)</span>
<span id="cb4-44"># ...Population-Level Effects:</span>
<span id="cb4-45">#              Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat</span>
<span id="cb4-46"># Intercept[1]    −0.65      0.88    −2.21     1.20       2351 1.00</span>
<span id="cb4-47"># Intercept[2]     1.45      0.90    −0.14     3.39       2295 1.00</span>
<span id="cb4-48"># Intercept[3]     2.94      0.93     1.31     4.91       2392 1.00</span>
<span id="cb4-49"># Gender           0.12      0.41    −0.72     0.91       5283 1.00</span>
<span id="cb4-50"># moAge           −0.49      0.57    −1.60     0.65       3793 1.00</span>
<span id="cb4-51"># moFrequency      1.44      0.92    −0.19     3.34       2553 1.00</span>
<span id="cb4-52"># moPurchaser      1.35      0.74     0.02     2.86       4586 1.00</span></code></pre>
            </div>
            <p>There are possible age effects in the expected direction; older people appear to be better at managing sock levels.</p>
            <p>Curiously, there may be different gender effects in the two survey datasets: in the Jorgensen international survey, gender is largely inert (except for a correlation with <code>Purchaser</code>) while in the US GS survey, gender correlates with everything and men appear much less likely to have enough socks (but to have more socks). Poking at the data, there appears to be another connection: in the US, men are more likely to do their own sock purchasing. I wonder if this reflects a different in sex roles, with women doing more clothing shopping in non-US countries and taking care of sock needs along the way?</p>
          </section>
          <section id="christmas-advice">
            <h2><a href="#christmas-advice" title="Link to section: § &#39;Christmas advice&#39;">Christmas Advice</a></h2>
            <div>
              <blockquote>
                <p>“What do you see when you look in the Mirror [of Erised]?”
                </p>
                <p>J.K. Rowling, <em>Harry Potter and the Philosopher’s Stone</em></p>
              </blockquote>
            </div>
            <p>Given that consistently &gt;15% of respondents don’t have enough socks, and in the US, younger males are especially likely to not have enough socks, here’s some Christmas advice: if you don’t know what to buy them, why not buy them some <em>really</em> good socks?</p>
            <p>Socks make a great gift. Everyone will need replacement socks, sooner or later, and it seems lots of people don’t get them. Unlike the feared ‘ugly sweater from Grandma’ present, they aren’t on public display so if they’re ugly, it’s not too big a deal. Nor do they take up too much space, and can be used for more of the year. An annual gift of socks is about the optimal tempo, given the surveys about how often people lose socks or buy socks, and Christmas is an excellent <a href="https://en.wikipedia.org/wiki/Focal_point_(game_theory)" data-link-icon="wikipedia" data-link-icon-type="svg">Schelling point</a>⁠, since it’s already associated with socks. Finally, socks may be a cunning gift as they can be <a href="https://www.lesswrong.com/posts/3T6p93Mut7G8qdkAs/evaluability-and-cheap-holiday-shopping" data-link-icon="LW" data-link-icon-type="text">easily evaluated as superior</a>⁠, and so <em>seem</em> premium despite not costing all that much in absolute terms.<a href="#fn4" id="fnref4" role="doc-noteref"><sup>4</sup></a></p>
          </section>
        </section>
        <section id="who-moved-my-sock">
          
          <p>How had I run out of socks? Well, like the joke about going bankrupt, I did it one day at a time: with a sock quietly disappearing one day, and a sock being tossed out due to holes &amp; thinning out another day… At no point did I ever <em>deliberately</em> try to economize on socks or go without socks or explicitly think that it wasn’t worth the bother of picking up some socks next time I was in a clothing store or doing an Amazon order—it just happened on its own.</p>
        </section>
        <section id="the-importance-of-the-unimportant">
          
          <div>
            <blockquote>
              <p>“How did you go bankrupt?”, Bill asked.</p>
              <p>“Two ways”, Mike said. “Gradually and then suddenly.”</p>
              <p>Ernest Hemingway (<em>The Sun Also Rises</em>, Book II, Chapter 13)</p>
            </blockquote>
          </div>
          <p>In the case of socks, there is never a ‘Socknik moment’. There is only a slippery-slope/​sorites—there’s no hard and fast line between enough and too-few socks, socks slowly wear out or lose mates, and if you have 20 and now have 19, well, that’s not a big deal, and then when you are down to 18, that’s not a big deal either why go shopping, and soon you’ll be down to 17… And if you don’t buy socks regularly as part of a clothes shopping trip, when will you? Eventually you’re wearing uncomfortable socks or being cold or being forced to do laundry runs early, without there ever being a clear ‘I need to buy some socks!’ trigger point. Even a habit like buying replacement socks once a year as part of spring cleaning would be enough, but one still needs to instill a habit.</p>
          <p>Some might object that this is overthinking socks, and one should never think about socks at all. This is short-sighted. If we were all perfectly rational and omniscient and possessed of infinite computing power, all our problems would already be solved and we would buy socks at the exact optimal moment as part of the grand plan; but we are not. Dealing with our bounded rationality is the central concern of all discussions of rationality &amp; optimizing &amp; biases.</p>
          <p>It may not seem important to think about socks at any particular moment, and socks are probably not the most pressing thing at this instant for me either, compared to tasks like ‘write an essay’ or ‘exercise’ or ‘answer emails’. But if it is better to wear socks than not, and one does not wish to go barefoot for the rest of one’s life, then it must be optimal at <em>some</em> moment to think about socks. Perhaps a few months from now when one’s ‘sockpile’ has worn down, during downtime, but there must be one.</p>
          <p>Similarly, one could scoff at all of the necessities of life like getting groceries, or filing a tax return, or getting life insurance: surely at that instant there is always something more important one could be working on doing, like getting a college degree or founding a startup? But this argument must have some flaw or by induction you would never do them and so you would starve to death while being audited by the IRS and your heirs are rendered homeless. For example, the value of these tasks increases over time: you don’t really need to do your taxes early before the deadline, but you do want to get it done <em>by</em> the deadline. With groceries, as long as you have enough to eat, it’s not much of a problem to be low on food—perhaps it reduces your variety a bit, but it’s not like you’ll <em>starve</em>, except if you run out of food in which case you will. And failure to get life insurance incurs a small loss each and every day (because of the risk of you dying that day and failing to provide for whatever you wanted life insurance for).</p>
          <p>Further, one’s life is a <em>complex system</em>: one’s house, one’s career, one’s computer, all of these are complex systems with interacting, cascading failures. All complex systems (<a href="https://ntietz.com/doc/technology/2000-cook.pdf" id="cook-2000" data-link-icon="pdf" data-link-icon-type="svg" title="&#39;How Complex Systems Fail: Being a Short Treatise on the Nature of Failure; How Failure is Evaluated; How Failure is Attributed to Proximate Cause; and the Resulting New Understanding of Patient Safety&#39;, Cook 2000">“How Complex Systems Fail”</a><span>, <span><span>2000</span></span>) operate in a</span> <a href="https://en.wikipedia.org/wiki/Swiss_cheese_model" data-link-icon="wikipedia" data-link-icon-type="svg">constant state of low-grade failure</a>⁠, where minor errors must be regularly repaired in order to prevent a large-scale failure cascading through the whole system. When a <a href="https://www.hse.gov.uk/pubns/web34.pdf" data-link-icon="pdf" data-link-icon-type="svg" title="The explosion of No. 5 Blast Furnace, Corus UK Ltd, Port Talbot (2001)">steel furnace explodes, killing people</a>⁠, it doesn’t happen out of the blue, but reflects a long series of choices &amp; gradually escalating issues &amp; near-misses, and is a <a href="https://en.wikipedia.org/wiki/Normal_Accidents" data-link-icon="wikipedia" data-link-icon-type="svg">“normal accident”</a>⁠. When I lost weeks of time and money to a <a href="https://ntietz.com/note/note#november-2016-data-loss-postmortem" id="gwern-note-note-november-2016-data-loss-postmortem" title="&#39;Miscellaneous § November 2016 data loss postmortem&#39;, Branwen 2009">laptop &amp; backup failure</a>⁠, it wasn’t because only <em>one</em> thing went wrong: it required at least 3 unusual failures simultaneously in my laptop &amp; backup systems, any of which not happening would have prevented the full accident. Each slip may seem relatively minor and extraordinarily unlikely to have any serious consequences, but, like the “indifference of the indicator”, they add up over a lifetime and eventually a tail risk materializes. Chance disfavors the unprepared mind—time and chance happeneth to all, and indeed do many things come to pass.</p>
          <p>Because failures interact and multiply, they resemble a <a href="https://en.wikipedia.org/wiki/Log-normal_distribution" data-link-icon="wikipedia" data-link-icon-type="svg">log-normal distribution</a>: each individual factor can block the accident so the final damage of the outcome is the multiplication of the individual factors. The log-normal implies that a small systematic increase or decrease in each factor, analogous to being more careful &amp; proactive in general about maintenance and risk, can cause a large difference in outcomes (see <a href="https://ntietz.com/note/pipeline" id="gwern-note-pipeline" title="&#39;Leaky Pipelines&#39;, Branwen 2014">the leaky pipeline model</a>). One must expect the unexpected, and a failure to ‘sweat the small stuff’ means you are allowing brush to pile up in the forest: one match could set it ablaze. People who do not sweat the small stuff have a remarkable tendency to have ‘bad luck’ and somehow keep getting into trouble, much like the less intelligent suffer more ‘accidents’ or natural disasters have death tolls almost entirely determined by poverty—certainly, time &amp; chance may happeneth to us all, but our preparations &amp; reactions play an even greater role in determining how far things go. A lack of the bourgeoisie virtues is a lack of foresight, preparations, and reserves/​insurance/​<a href="https://www.lesswrong.com/s/HXkpm9b8o964jbQ89" data-link-icon="LW" data-link-icon-type="text" title="&#39;Slack and the Sabbath&#39;, Zvi">slack</a>⁠. Consider how careless some people are in matters of everyday life.<a href="#fn5" id="fnref5" role="doc-noteref"><sup>5</sup></a> It’s not hard to see how such carelessness in, say, getting drunk and making rental payments can quickly escalate.</p>
          <section id="yak-shaving-as-a-failure-cascade">
            <h2><a href="#yak-shaving-as-a-failure-cascade" title="Link to section: § &#39;Yak Shaving as a Failure Cascade&#39;">‘Yak Shaving’ As a Failure Cascade</a></h2>
            <p><a href="https://ntietz.com/doc/www/seths.blog/3f455374fa56a49ba9614fc19fe4f6b2584e9585.html" rel="archived alternate nofollow" data-url-original="https://seths.blog/2005/03/dont_shave_that/" title="Don&#39;t Shave That Yak! (Original URL: https://seths.blog/2005/03/dont_shave_that/ )">Seth Godin</a> explains <a href="http://www.catb.org/~esr/jargon/html/Y/yak-shaving.html" data-link-icon="ESR" data-link-icon-type="text,tri,sans">yak shaving</a> as a story:</p>
            <blockquote>
              <p>“I want to wax the car today.”</p>
              <p>“Oops, the hose is still broken from the winter. I’ll need to buy a new one at Home Depot.”</p>
              <p>“But Home Depot is on the other side of the Tappan Zee bridge and getting there without my EZ Pass is miserable because of the tolls.”</p>
              <p>“But, wait! I could borrow my neighbor’s EZ Pass…”</p>
              <p>“Bob won’t lend me his EZ Pass until I return the mooshi pillow my son borrowed, though.”</p>
              <p>“And we haven’t returned it because some of the stuffing fell out and we need to get some yak hair to restuff it.”</p>
              <p>And the next thing you know, you’re at the zoo, shaving a yak, all so you can wax your car.</p>
            </blockquote>
            <p>Godin’s take-away is that yak shaving is misguided perfectionism: once one realizes one is yak shaving, one should decide “Don’t go to Home Depot for the hose. The minute you start walking down a path toward a yak shaving party, it’s worth making a compromise. Doing it well now is much better than doing it perfectly later.”</p>
            <p>I interpret yak shaving differently. At least when I feel I am trapped in yak shaving, it more often reflects a failure cascade in the complex system I am currently part of: either mentally I have gotten trapped into a local minima and have failed to reflect periodically on what the best way is, or the system really is broken and once the yak is shaved, requires <a href="https://en.wikipedia.org/wiki/Root_cause_analysis" data-link-icon="wikipedia" data-link-icon-type="svg">root cause analysis</a> to find out how to fix the fundamental problems and how to prevent them from recurring.</p>
            <p>I see ‘yak-shaving’ as a description of a situation where you are nested so deep in subgoals that you’ve forgotten your original goal, at which point a good heuristic is to wake up and say “this is a lot of yak-shaving!” and think about what is going on that has led to an undesirable situation.</p>
            <p>Thinking about my own applications of the term, I think there are 3 different kinds of problems which can lead to yak-shaving: avoidance, lack of mindfulness, and cascading problems/​system failures.</p>
            <ol>
              <li>
                <p>avoiding doing the work: you are procrastinating or being akratic or falling into perfectionism (closely related to procrastination), by deliberately overcomplicating something or trying to use fancy or shiny new techniques, which of course frequently lead to new subgoals because you aren’t familiar with them yet. Maybe you are just being <a href="https://en.wikipedia.org/wiki/Attention_deficit_hyperactivity_disorder" data-link-icon="wikipedia" data-link-icon-type="svg">ADHD</a> and getting distracted by something that is a problem but irrelevant.</p>
                <p>This is fine sometimes (you have to learn those new techniques somewhen) or if it’s a kind of ‘structured procrastination’ (where the yak-shaving is itself valuable eg. because it makes a neat blog post or useful software package), but often isn’t. The usual akrasia/​procrastination equation stuff, except it’s being hidden under a gloss of <a href="http://www.paulgraham.com/procrastination.html" data-link-icon="pg" data-link-icon-type="text,monospace" title="Good and Bad Procrastination">superficial productivity</a>⁠. (“I can’t write my novel, I have to clean my desk which requires […solving 15 deeper nested issues…] which will take up all the rest of the day; I sure am a hard-working writer.”)</p>
                <p>By calling it yak-shaving, you admit you are faffing around and you then solve your problem the way you knew you should all along; or you can deal with why you are avoiding finishing, or whether you really want to do it at all. If you refuse to acknowledge the yak-shaving, then even if you ‘shave the yaks’ you’ll just find another way to overcomplicate things or a different thing to waste time on or switch to procrastinating on social media etc.</p>
              </li>
              <li>
                <p>thoughtlessness: you have been following a greedy strategy of taking the quickest option at each decision node; that you have now stacked up so many tasks to complete suggests that the greedy strategy has failed and you have fallen into a local pessima.</p>
                <p>Like with <a href="https://ntietz.com/sunk-cost" id="gwern-sunk-cost" title="&#39;Are Sunk Costs Fallacies?&#39;, Branwen 2012">sunk costs</a>⁠, it’s time to stop being so mindless, step back, think about it more globally, and ask if there’s some better approach. Was there some entirely different strategy which seemed too expensive compared to your current path (which has actually turned out to be far more costly than predicted) and now looks cheap? Or are there any intermediate middle steps which are expensive but cut out a large number of other steps? Or perhaps all the paths are so costly that the top-level goal now no longer looks worth bothering with and you should drop all the existing tasks &amp; stop shaving the yak entirely.</p>
                <p>Programmers are particularly susceptible to this because the line between useful automation and immensely complicated time-wasting tinkering is a fine one indeed. This can be common in programming where you can say, build up a Rube Goldberg collection of shell scripts and <a href="https://en.wikipedia.org/wiki/Emacs" data-link-icon="wikipedia" data-link-icon-type="svg">Emacs</a> functions and manual edits to text because you wanted to avoid writing a SQL function (because it would take 20 minutes of consulting the SQL documentation to get it right); but by the time you’re consulting the Bash FAQ or resetting <code>IFS</code> variables to deal with a problem half an hour later, it’s good to wake up and ask ‘am I yak-shaving?’—and then you might realize that the data or problem has turned out to be sufficiently painful (eg. lots of special characters or oddity in data formatting) that you can’t catch all the special cases and you would’ve been better off writing the SQL query in the first place. In Godin’s example, perhaps one should simply return the yak pillow and hope the neighbor won’t notice the missing stuffing, or they will prefer to simply have it back rather than wait for you to fix it whenever, or simply upset them a little; or order the hose on Amazon even if it costs $5 more, to get it done; or, pay the damn toll like anyone else; or finally, is waxing the car worthwhile at all (who notices)?</p>
                <p>Here ‘yak-shaving’ serves as an useful mental trigger which can break you out of the myopic problem-solving loop. This sort of yak-shaving is usually quite bad, and if you don’t break out of it soon enough, can lead to considerable exhaustion and waste of time, and lock you into bad long-term decisions. So it’s good to periodically ask, if you aren’t making progress on a problem of intrinsic interest to you, “so all this work, what’s it <em>for</em> anyway? If I were starting over from scratch—knowing what I do now—is this <em>really</em> how I would approach this problem?”</p>
              </li>
              <li>
                <p>failure cascade: what you are doing <em>is</em> the best way to solve the problem overall, it’s just that things have been going wrong and you’ve been running into continual problems, so you find yourself nested many layers deep dealing with the cascade of problems and documentation. You keep <a href="https://wiki.c2.com/?PushDownGoalStack">pushing goals onto your stack</a> but can’t pop them.</p>
                <p>…all your (encrypted) backups are broken because you can’t get the most recent decryption key because your drive is corrupted because you were running the GPU 24/​7 (to name a recent example of mine) so you’re in a LiveCD trying to mount the drive trying passwords trying…</p>
                <p>In this case, in addition to simply shaving the yak, you need to do root-cause analysis—you are experiencing what might be called <a href="https://en.wikipedia.org/wiki/Muri_(Japanese_term)" data-link-icon="wikipedia" data-link-icon-type="svg"><em>muri</em></a>—and in addition to figuring out how to solve each proximate problem on the way, figure out why they happened &amp; how to prevent them in the future. In programming, this frequently entails filing bug reports &amp; document patches, formalizing your recovery methods as scripts or programs, adding tests or redundancy or upgrading hardware, and writing post-mortems.</p>
                <p>So Godin’s interpretation of a stack of nested related problems here is simply a form of this. But here, simply yak shaving may solve the fur problem &amp; allow popping, but it’s not enough. It’s not enough to simply close those open loops, or have a system for recording open loops. Root-cause analysis is needed.</p>
                <p>Why did the yak fur fall out of the pillow in the first place and how can it be prevented ever again? Why didn’t he have his EZ Pass in the first place? Why wasn’t the hose put on the weekly shopping list (there is a shopping list right?) and replaced long before? And so on.</p>
                <p>Without attacking problems at the root, you might as well buy a seasonal pass to the zoo, because you are merely applying bandaids to a complex system failing, and if you don’t do any root-cause fixes, eventually your problems will seriously stack up and you’ll find yourself hit by a so-called ‘perfect storm’ (actually perfectly foreseeable &amp; inevitable) and then you’ll <em>really</em> be sorry.</p>
              </li>
            </ol>
            <p>So, ‘yak-shaving’ is an useful heuristic for keeping planning stacks nested not too deeply by periodically asking whether one is falling prey to one of those 3 failure modes, and need to break out of the yak-shaving by an appropriate countermeasure of either: interrogating the reasons for the akrasia; finding a better approach; or prioritizing fixing the root-causes of needing to yak-shave (rather than focusing on the yak-shaving).</p>
          </section>
        </section>
        <section id="the-ur-cognitive-bias">
          
          <div>
            <blockquote>
              <p>I started eating with them [the chemists] for a while. And I started asking, ‘What are the important problems of your field?’ And after a week or so, ‘What important problems are you working on?’ And after some more time I came in one day and said, ‘If what you are doing is not important, and if you don’t think it is going to lead to something important, why are you at Bell Labs working on it?’ I wasn’t welcomed after that; I had to find somebody else to eat with!…In the fall, Dave McCall stopped me in the hall and said, ‘Hamming, that remark of yours got underneath my skin. I thought about it all summer, i.e. what were the important problems in my field. I haven’t changed my research’, he says, ‘but I think it was well worthwhile.’ And I said, ‘Thank you Dave’, and went on. I noticed a couple of months later he was made the head of the department. I noticed the other day he was a Member of the National Academy of Engineering. I noticed he has succeeded. I have never heard the names of any of the other fellows at that table mentioned in science and scientific circles.</p>
              <p><a href="https://en.wikipedia.org/wiki/Richard_Hamming" data-link-icon="wikipedia" data-link-icon-type="svg">Richard Hamming</a>⁠, <a href="https://ntietz.com/doc/www/www.cs.virginia.edu/c4b4d6e86a9e93cb34e1df9438f051b11f445f13.html" id="hamming-1986" rel="archived alternate nofollow" data-url-original="https://www.cs.virginia.edu/~robins/YouAndYourResearch.html" title="&#39;You and Your Research&#39;, Hamming 1986 (Original URL: https://www.cs.virginia.edu/~robins/YouAndYourResearch.html )">“You and Your Research”</a></p>
            </blockquote>
          </div>
          <p>One problem here is that the unimportant becomes important, slowly and subtly. There is no IRS clock ticking on one’s wall, any more than there is a realtime display of one’s sockpile with defined red danger zones upon which one orders new socks.</p>
          <p>For many things, there is never any hard deadline or scheduled event or reminder which would bring a need to mind. So necessary things suffer from what a computer scientist might call <a href="https://en.wikipedia.org/wiki/Starvation_(computer_science)" data-link-icon="wikipedia" data-link-icon-type="svg"><em>starvation</em></a>: when a background task, like running a backup, which has a low priority (eg. a backup can wait a few minutes without much risk), is continuously pushed out by higher priority tasks and never gets to run; while it may not have been urgent that it run immediately, it is urgent that it run eventually. (Anyone who disagrees about backups not being important is free to implement that advice and see how it works for them in the long run.)</p>
          <p>Starvation reflects bad planning: the priorities of starving tasks are not increased over time to reflect their priority, or starving tasks may not be considered at all by a myopic planner. And for humans, ‘out of sight is out of mind’, so myopia is easy.</p><span>Many human cognitive biases can be considered as reflections of a single ur-cognitive bias (<span><span>Stanovich</span><span>2010</span></span>,</span> <em>Decision Making and Rationality in the Modern World</em>), a failure to activate difficult, deliberate, explicit System II thinking when appropriate, ‘waking up’ from the usual fast frugal System I thinking, perhaps from time to time just to re-evaluate things. <a href="https://www.lesswrong.com/posts/PBRWb2Em5SNeWYwwB/humans-are-not-automatically-strategic" data-link-icon="LW" data-link-icon-type="text">“Humans are not automatically strategic.”</a> Instead, System I is always invoked, regardless of System II is needed, and the fast frugal cheap reflexive thinking of System I takes over.
          <div id="toil">
            <p>When System I runs unimpeded, work tends to degenerate into what Google SRE terms <a href="https://ntietz.com/doc/www/sre.google/1d43dd46becfd254be3d80aa142053c2b531de9d.html" data-link-icon="alphabet" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://sre.google/sre-book/eliminating-toil/" title="Chapter 5 - Eliminating Toil (Original URL: https://sre.google/sre-book/eliminating-toil/ )">“toil”</a>⁠; <a href="https://ntietz.com/doc/www/www.usenix.org/b4db30d538017847d011b96bce3c27503cc4b921.pdf" data-link-icon="pdf" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://www.usenix.org/system/files/login/articles/login_fall16_08_beyer.pdf" title="Invent More, Toil Less (Original URL: https://www.usenix.org/system/files/login/articles/login_fall16_08_beyer.pdf )"><span><span title="et al">Beyer</span> <span>et al</span> <span>2016</span></span></a>:</p>
            <blockquote>
              <p>…<strong>toil</strong> is the kind of work tied to running a production service that tends to be:</p>
              <ul>
                <li>Manual</li>
                <li>Repetitive</li>
                <li>Automatable and not requiring human judgment</li>
                <li>Interrupt-driven and reactive</li>
                <li>Of no enduring value</li>
              </ul>
            </blockquote>
            <p>One works hard, but that a few bucks will get you a cup of coffee. Eliminating toil requires stepping back to take an <a href="https://www.lesswrong.com/tag/inside-outside-view" data-link-icon="LW" data-link-icon-type="text">outside view</a> and possibly re-engineer things.<a href="#fn6" id="fnref6" role="doc-noteref"><sup>6</sup></a></p>
          </div>
          <p>Of course System II can’t run all the time, any more than we can ponder every day whether today we should re-engineer our sock-buying system or buy more socks. We hardly ever do—but that’s not quite the same as never. It needs to run occasionally to check the fundamentals, to look for tasks starving in the background for lack of saliency, and to reflect on what is being done that ought not to be done at all, and consider entirely new alternatives.</p>
          <p>I think apparent instances of ‘sunk cost’ are better described as <em>thoughtlessness</em>. To give an example: when chess or <a href="https://en.wikipedia.org/wiki/Go_(game)" data-link-icon="wikipedia" data-link-icon-type="svg">Go</a> players continue throwing pieces into a doomed position, is that because they explicitly realize it is doomed but feel they must persevere <em>anyway</em>, or is it due to the fact that chess amateurs commit more <a href="https://en.wikipedia.org/wiki/Confirmation_bias" data-link-icon="wikipedia" data-link-icon-type="svg">confirmation bias</a><a href="#fn7" id="fnref7" role="doc-noteref"><sup>7</sup></a> than masters (<a href="https://ntietz.com/doc/psychology/chess/2004-cowley.pdf" id="cowley-byrne-2004" data-link-icon="pdf" data-link-icon-type="svg" title="&#39;Chess Masters&#39; Hypothesis Testing&#39;"><span><span>Cowley &amp; Byrne</span><span>2004</span></span></a>) and don’t realize that the positions are in fact irretrievable? When one engages in spring-cleaning, one may wind up throwing or giving away a great many things which one has owned for months or years but had not disposed of before; is this an instance of <em>sunk cost</em> where you over-valued them simply because you have invested into holding onto them for <em>X</em> months, an instance of <a href="https://en.wikipedia.org/wiki/Endowment_effect" data-link-icon="wikipedia" data-link-icon-type="svg">endowment effect</a> where it is more valuable because it’s yours (a bias which doesn’t change with additional investment)—or is this an instance of you simply never before devoting a few seconds to pondering whether you genuinely liked that checkered scarf &amp; if you haven’t worn it in years how likely are you to ever wear it again? When we see an apparent sunk cost, might we not be seeing a well-developed <a href="https://en.wikipedia.org/wiki/Habit" data-link-icon="wikipedia" data-link-icon-type="svg"><em>habit</em></a> which made sense when it was developed and perhaps has simply never been critically re-examined in the light of current circumstances? Habits are invaluable, but they are also invisible and indurate except at times of crisis where one is re-prioritizing things.<a href="#fn8" id="fnref8" role="doc-noteref"><sup>8</sup></a> Even in corporations, where sunk cost thinking is at its worst, many of the instances (eg. the new CEO who radically overhauls the company by cutting products &amp; divisions &amp; employees) are often simply executing changes that the rest of the company knows are long overdue but could never quite rise to a priority without the Schelling point of a new CEO brought on to shake things up. (Or indeed, in general: “never let a crisis go to waste.”)</p>
          <p>Few people persevere in a mistaken choice of college degree because they truly value that they have obtained irrationally more solely because they have already spent a lot of money on it, which is the classic ‘sunk cost bias’. Usually, it’s more that they are so busy with classes &amp; student life &amp; projects &amp; hobbies that they don’t think about it, continuing with the original plan is the path of least reflection, the occasional stray thoughts ‘maybe this is the wrong path’ are too painful to pursue more than briefly, and they have not sat down and pondered even 5 minutes the costs/​benefits or how well it’s been going and seriously opened up internally to the possibility of quitting. <a href="https://ntietz.com/doc/www/www.briantimar.com/1f1d7904af180f4ff84dfcf0c62d256b4115fbb7.html" rel="archived alternate nofollow" data-url-original="https://www.briantimar.com/notes/mimetic/mimetic/" title="Mimetic traps (Original URL: https://www.briantimar.com/notes/mimetic/mimetic/ )">One continues because one continues.</a> Nor is there necessarily any point at which they will be forced to consider this before graduation, as college systems are geared to usher one from enrollment to graduation, and one doesn’t have to make an extraordinary effort at any point to continue on that path. (One does for graduate school, which is fortunate, considering how much student debt that can entail, but then the same dynamic will kick in once one is in grad school.) Or at what point does <a href="https://ntietz.com/doc/www/www.uzh.ch/6d3aae376370da746d27bef0078d880bd946ab0e.pdf" id="stutzer-frey-2008" data-link-icon="pdf" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://www.uzh.ch/cmsssl/suz/dam/jcr:ffffffff-866d-1ee0-0000-0000536ff1b9/10.04_stutzer-frey_08.pdf" title="&#39;Stress that Doesn&#39;t Pay: The Commuting Paradox&#39;, Stutzer &amp; Frey 2008 (Original URL: https://www.uzh.ch/cmsssl/suz/dam/jcr:ffffffff-866d-1ee0-0000-0000536ff1b9/10.04_stutzer-frey_08.pdf )">a commuter</a> realize that the tradeoff isn’t that great? Any doubts may simply starve for lack of thought to feed them, until one day, one suddenly ‘wakes up’.</p>
        </section>
        <section id="finding-new-socks">
          
          <div>
            <blockquote>
              <p>It is a profoundly erroneous truism, repeated by all copy-books and by eminent people when they are making speeches, that we should cultivate the habit of thinking of what we are doing. The precise opposite is the case. Civilization advances by extending the number of important operations which we can perform without thinking about them. Operations of thought are like cavalry charges in a battle—they are strictly limited in number, they require fresh horses, and must only be made at decisive moments…It is interesting to note how important for the development of science a modest-looking symbol may be.</p>
              <p><a href="https://en.wikipedia.org/wiki/Alfred_North_Whitehead" data-link-icon="wikipedia" data-link-icon-type="svg">Alfred North Whitehead</a>⁠, <a href="https://archive.org/details/anintroductiont01whitgoog/page/n59" data-link-icon="internetarchive" data-link-icon-type="svg"><em>An Introduction to Mathematics</em></a> (1911)</p>
            </blockquote>
          </div>
          <p>Many of the best anti-bias mechanisms or ‘life hacks’ or ‘habits’ are about strategic application of our limited System II resources, often employing external systems to fight starvation.</p>
          <p>The simplest wake-up mechanism is having a habit to occasionally review the past, like reviewing one’s ledgers at the end of every month.<a href="#fn9" id="fnref9" role="doc-noteref"><sup>9</sup></a> The humble <a href="https://en.wikipedia.org/wiki/Poka-yoke" data-link-icon="wikipedia" data-link-icon-type="svg">poka-yoke</a> <a href="https://www.newyorker.com/magazine/2007/12/10/the-checklist" data-link-icon="thenewyorker" data-link-icon-type="svg" title="The Checklist: If something so simple can transform intensive care, what else can it do?">checklist</a>⁠, for example; or <a href="https://en.wikipedia.org/wiki/Pointing_and_calling" data-link-icon="wikipedia" data-link-icon-type="svg">pointing and calling</a>⁠, reminder or <a href="https://clay.earth/story" title="200,000 Index Cards: The Art &amp; Science Of Thoughtfulness">note</a>-taking software, spreadsheets/​double-entry ledgers, emails with timers, ‘lint’ tools, many ‘life hacks’ in general…<a href="#fn10" id="fnref10" role="doc-noteref"><sup>10</sup></a> I am heavily reliant on my calendar software to remind me to check in on various papers or people, do exports/​backups which can’t be easily automated, update pages, and re-evaluate things periodically; in writing things, I have found it worthwhile to develop <a href="https://ntietz.com/about#writing-checklist" id="gwern-about-writing-checklist">my own checklist</a> and am constantly expanding my writing linter, <a href="https://ntietz.com/static/build/markdown-lint.sh" data-link-icon="code" data-link-icon-type="svg"><code>markdown-lint</code></a> &amp; my site build/​sync script, with new errors to watch out for.</p>
          <p>Such systems efficiently intervene only at critical moments, and systematically cover available options to overcome System I inertia/​forgetting: a checklist reminds one of every necessary step, while poka-yoke error-proofing remove error cases or at least add them to checklists, and pointing-and-calling is a physical implementation of the mental process of checklisting, while time-based tools like calendars can be scheduled in advance to fire only at the critical moment to save all the cognition from now to then. And sufficiently reliable automated tools can go one better and only interrupt one, waking up System II, only if there is actually an error which needs to be fixed.</p>
          <section id="exploration">
            <h2><a href="#exploration" title="Link to section: § &#39;Exploration&#39;">Exploration</a></h2>
            <p>Underuse of System II particularly manifests as over-exploitation/​under-exploration, where large potential improvements are foregone because of a lack of a habit or other systematic factor which would trigger exploration. (By exploration, I don’t mean spending hours reading reviews on Amazon or on social media, or reading yet another book on a topic, which is largely about feeding idle curiosity &amp; is information super-stimuli, but actual experimentation and trying.)</p>
            <p>One way to measure under-exploration is noting instances where exogenous randomization or destruction of the status quo option leads to permanent changes or net efficiency gains after the shock is removed, indicating learning or that <a href="https://ntietz.com/note/local-optima" id="gwern-note-local-optima" title="&#39;Local Optima &amp; Greedy Choices&#39;, Branwen 2021">the status quo was suboptimal</a> all along. (One area where under-exploration is <em>especially</em> rife is in randomized experiments in science, where what everyone ‘knows’ based on correlation <a href="https://ntietz.com/correlation" id="gwern-correlation" title="How Often Does Correlation=Causality? Compilation of studies comparing observational results with randomized experimental results on the same intervention, compiled from medicine/economics/psychology, indicating that a large fraction of the time (although probably not a majority) correlation ≠ causality.">often turns out to be false</a>⁠, yet despite the large implied regrets, it is still held to be ‘unethical’ to run more randomized experiments.)</p>
            <p>Harvard economist Sendhil Mullainathan asks <a href="https://www.nytimes.com/2017/12/01/business/why-trying-new-things-is-so-hard.html" data-link-icon="newyorktimes" data-link-icon-type="svg">“Why Trying New Things Is So Hard to Do”</a>⁠, putting it well with a familiar example, grocery shopping:</p>
            <blockquote>
              <p>I drink a lot of Diet Coke: two liters a day, almost six cans’ worth. I’m not proud of the habit, but I really like the taste of Diet Coke. As a frugal economist, I’m well aware that switching to a generic brand would save me money, not just once but daily, for weeks and years to come. Yet I only drink Diet Coke. I’ve never even sampled generic soda.</p>
              <p>Why not? I’ve certainly thought about it. And I tell myself that the dollars involved are inconsequential, really, that I’m happy with what I’m already drinking and that I can afford to be passive about this little extravagance. Yet I’m clearly making an error, one that reveals a deeper decision-making bias whose cumulative cost is sizable: Like most people, I conduct relatively few experiments in my personal life, in both small and big things.</p>
              <p>This is a pity because experimentation can produce outsize rewards. For example, I wouldn’t be risking much by trying a generic soda, and if I liked it enough to switch, the payout could be big: All my future sodas would be cheaper. When the same choice is made over and over again, the downside of trying something different is limited and fixed—that one soda is unappealing—while the potential gains are disproportionately large. <a href="https://ntietz.com/doc/psychology/2005-quinn.pdf" data-link-icon="pdf" data-link-icon-type="svg" title="&#39;Habits Across the Lifespan&#39;, Quinn &amp; Wood 2005">One study estimated</a> that 47% of human behaviors are of this habitual variety.</p>
              <p>Yet many people persist in buying branded products even when equivalent generics are available. These choices are noteworthy for drugs, when generics and branded options are chemically equivalent. Why continue to buy a name-brand aspirin when the same chemical compound sits nearby at a cheaper price?</p>
            </blockquote>
            <p>Grocery shopping is a great example because it is something everyone does, often, which represents a substantial portion of personal budgets, with clear &amp; unambiguous costs, where the difficulty of experimentation is so minimal that it feels weird to even call activities like ‘compare prices &amp; try different foods’ by a term as fancy as “experimentation”, where the benefits of learning are large &amp; can last decades. (Aldi isn’t going to suddenly become more expensive than Whole Foods, and rank-ordering of prices remains relatively constant—that’s the whole point of having brands, after all). Yet, we still don’t.</p>
            <p>And the benefits are large. As Mullainathan notes, while the cost in a single instance may be small, the total loss (“regret”) is much larger because it is repeated across a lifetime. If you choose to drink Diet Coke and it costs +$0.25/​can (let’s say the generic costs $0.75/​can and Diet Coke $1/​can, and if you dislike the generic you’ll throw it away), you haven’t lost $0.25, you have lost <em>much</em> more than that, because it is not a one-off decision about a single drink—you are buying information for all your future choices, and the “<a href="https://en.wikipedia.org/wiki/Value_of_information" data-link-icon="wikipedia" data-link-icon-type="svg">Value of Information</a>” of the experiment is far higher than the trivial upfront cost.</p>
            <p>Suppose you drink 1 coke a day. The difference is $0.25/​day, or, $91 a year. The gain from switching does not stop after a year, it goes on indefinitely, so at a fairly psychologically normal discount rate of 5%, the <a href="https://en.wikipedia.org/wiki/Net_present_value" data-link-icon="wikipedia" data-link-icon-type="svg">NPV</a> of the gain is $1871<a href="#fn11" id="fnref11" role="doc-noteref"><sup>11</sup></a>⁠. In order for your experiment to not cover $0.75 and not be profitable, you would have to assign a prior probability of &lt;0.013% to the generic being as good (or better!) and you switching and reaping a gain of $1871. Which would be crazy because as Mullainathan also notes, everyone knows that often the generic version is fine, and indeed, frequently is <em>literally</em> the same as the brand name, either because they use the same manufacturers or because the seller is implementing <a href="https://en.wikipedia.org/wiki/Price_discrimination" data-link-icon="wikipedia" data-link-icon-type="svg">price discrimination</a>⁠.</p>
            <p>And let’s not pretend that this is any great heroic effort, requiring advanced statistics or long-term experimentation or blinding.<a href="#fn12" id="fnref12" role="doc-noteref"><sup>12</sup></a> It takes a second to grab the generic soda from off the shelf next to the Diet Coke, and a few seconds later in the kitchen to try them side by side; are they about the same? Then great! You can enjoy the savings from buying generic thenceforth, otherwise, toss the generic soda; either way, there’s no need to think about it further.</p>
            <p>This applies as well to any other staples you might buy. Is King Arthur flour really worth paying twice as much as Gold Medal flour? (Not that I’ve ever noticed in my baking.) Perhaps if you tried all 6 kinds of applesauce you’d find one of the cheaper ones tastes better than the expensive ones. (I did. It doesn’t add sweetener, and I think most applesauces are oversweetened. I want it to taste like apples, not corn syrup.) Is ‘scrap bacon’ terrible in some way that makes costing half as much as regular bacon a lie? (Nope: tastes as delicious to me, and I can buy twice as much.) Can you tell the difference between the expensive imported Finnish/​Irish butter and the generic Walmart butter? (I can… eating it straight while concentrating carefully. But I can’t on bread or anywhere I would use said butter.) And is Smucker’s “natural peanut butter” any better than your ordinary Jiff or generic peanut butter? (Trick question—I actually think it tastes <em>much</em> better than regular peanut butter &amp; that’s what I buy. But, I only know this because I tried them all; otherwise, I wouldn’t’ve bought something as weird-looking as peanut butter which still has its original peanut oil.)</p>
            <p>Personally, I make a point of, whenever trying something new like food, to buy 1 of everything, to the extent possible, and simply trying them all. I am no longer surprised when I find that the generic is as good or better at a third or less the cost (how on earth do brands maintain their profits when it’s so easy to compare?), or that I prefer something I didn’t expect to prefer. (Particularly in tea this has paid off in learning about strange things like <a href="https://ntietz.com/review/tea#ku-ki" id="gwern-review-tea-ku-ki">twig tea</a>⁠.) I think it’s crazy how people will buy the same thing forever and overspend on brand names, and, while they’re at it, never try another grocery store (switching to Walmart saved me &gt;10%, and then switching to Aldi another &gt;10%), and pass up bulk savings to buy the smallest possible quantities. And then they complain their monthly grocery bill is $400 and they wonder where all the money goes… It is wasteful to not be wasteful.</p>
            <p>If we so often under-explore in groceries, we surely under-explore elsewhere too. What can help ameliorate this is <em>deliberate</em> forcing of exploration. With groceries, my rule of buying multiples the first time is a simple easily-implemented heuristic to force exploration of grocery options. With music, I try to avoid my tastes ‘freezing’ into whatever I listened to as a teenager by listening to large musical dumps rather than recommendations (eg. <a href="https://en.wikipedia.org/wiki/Doujinshi_convention" data-link-icon="wikipedia" data-link-icon-type="svg">dōjinshi convention</a> compilations), and avoiding the bandwagon effects of popular media.<a href="#fn13" id="fnref13" role="doc-noteref"><sup>13</sup></a> With research, systematic reading of all papers on a given topic rather than the most-cited ones can lead to many interesting but still obscure papers.</p>
            <p>We can try to compensate for our lack of mindfulness in other areas too. With socks, my new heuristic is expand my annual photographic inventory of my personal possessions (making a record of everything I own in case of disaster) to include clothes too<a href="#fn14" id="fnref14" role="doc-noteref"><sup>14</sup></a>⁠; in considering my clothes, I expect that I will notice when I get low on socks—or any other kind of clothing—and can take action before too many years pass and my sockpile becomes inadequate. I will surely discover other inadequacies in the future, but, if I am mindful of my limits, fewer and fewer, and they will get less in the way of more important things.</p>
          </section>
        </section>
        <section id="see-also">
          
          
        </section>
        <section id="external-links">
          
          <ul>
            <li>
              <a href="https://ntietz.com/doc/www/sre.google/48878d6c4e39caae6c0c247517f9a3baac094f5f.html" data-link-icon="alphabet" data-link-icon-type="svg" rel="archived alternate nofollow" data-url-original="https://sre.google/sre-book/table-of-contents/" title="(Original URL: https://sre.google/sre-book/table-of-contents/ )"><em>Site Reliability Engineering: How Google Runs Production Systems</em></a>
            </li>
            <li>
              <a href="https://danluu.com/everything-is-broken/">“One Week of Bugs, or, Everything is Broken”</a> / <a href="https://ntietz.com/doc/www/blog.regehr.org/34b05d938791bac39f44167f8d45538aacff4310.html" rel="archived alternate nofollow" data-url-original="https://blog.regehr.org/archives/861" title="(Original URL: https://blog.regehr.org/archives/861 )">“Operant Conditioning by Software Bugs”</a> (why do some people seem to trigger computer bugs all the time?)
            </li>
            <li>
              <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC3950931/" id="story-et-al-2014" data-link-icon="nlm-ncbi" data-link-icon-type="svg" title="&#39;Does temporal discounting explain unhealthy behavior? A systematic review and reinforcement learning perspective&#39;, Story et al 2014">“Does temporal discounting explain unhealthy behavior? A systematic review and reinforcement learning perspective”</a><span>, <span><span title="et al">Story</span> <span>et al</span> <span>2014</span></span></span>
            </li>
            <li>
              <a href="https://www.lesswrong.com/posts/nbiZc7KM2KEyCAaCP/in-support-of-yak-shaving" data-link-icon="LW" data-link-icon-type="text">“In support of Yak Shaving”</a>
            </li>
            <li>
              <a href="https://ntietz.com/doc/www/blog.nuclino.com/aa0b40d7443ed330068e31069f6be11785cbcc1e.html" rel="archived alternate nofollow" data-url-original="https://blog.nuclino.com/the-simple-genius-of-checklists-from-b-17-to-the-apollo-missions" title="(Original URL: https://blog.nuclino.com/the-simple-genius-of-checklists-from-b-17-to-the-apollo-missions )">“The Simple Genius of Checklists, from B-17 to the Apollo Missions”</a>
            </li>
            <li>
              <a href="https://ntietz.com/doc/www/queue.acm.org/3f16f8d6e80fd8c3046ffa7b6cd357df4f32b382.html" data-link-icon="acm" data-link-icon-type="text,tri,sans" rel="archived alternate nofollow" data-url-original="https://queue.acm.org/detail.cfm?id=3197520" title="(Original URL: https://queue.acm.org/detail.cfm?id=3197520 )">“Manual Work is a Bug—A.B.A: ‘always be automating’”</a><span>, <span><span>Limoncelli</span><span>2018</span></span></span>
            </li>
            <li><span id="gradual-automation"><a href="https://ntietz.com/doc/www/blog.danslimmon.com/e25ef019123bb0fb5d42741db6d0d2e76f2d550c.html" rel="archived alternate nofollow" data-url-original="https://blog.danslimmon.com/2019/07/15/do-nothing-scripting-the-key-to-gradual-automation/" title="(Original URL: https://blog.danslimmon.com/2019/07/15/do-nothing-scripting-the-key-to-gradual-automation/ )">“Do-nothing scripting: the key to gradual automation”</a></span></li>
            <li>
              <a href="https://dynomight.net/copies/">“Buy More Copies”</a>
            </li>
            <li>
              <a href="https://ntietz.com/doc/www/www.benkuhn.net/bce325e17b11a69fadfc11f23b5d79272a61037d.html" id="kuhn-2019" rel="archived alternate nofollow" data-url-original="https://www.benkuhn.net/11/" title="&#39;The unreasonable effectiveness of one-on-ones&#39;, Kuhn 2019 (Original URL: https://www.benkuhn.net/11/ )">“The unreasonable effectiveness of one-on-ones”</a>⁠, Ben Kuhn
            </li>
            <li>
              <a href="https://ntietz.com/doc/www/milan.cvitkovic.net/d2febcdeaf5aa839d93a8a6786635268896d6999.html" rel="archived alternate nofollow" data-url-original="https://milan.cvitkovic.net/writing/things_youre_allowed_to_do/" title="(Original URL: https://milan.cvitkovic.net/writing/things_youre_allowed_to_do/ )">“Things you’re allowed to do: This is a list of things you’re allowed to do that you thought you couldn’t, or didn’t even know you could.”</a>
            </li>
            <li>
              <a href="https://ntietz.com/doc/www/blog.acolyer.org/e9505343ec7453602019895c60e7836cac9cc5c7.html" rel="archived alternate nofollow" data-url-original="https://blog.acolyer.org/2015/04/29/applying-the-universal-scalability-law-to-organisations/" title="(Original URL: https://blog.acolyer.org/2015/04/29/applying-the-universal-scalability-law-to-organisations/ )">“Applying the Universal Scalability Law to organisations”</a>
            </li>
            <li>
              <a href="https://www.ncbi.nlm.nih.gov/pmc/articles/PMC1322240/" id="lim-et-al-2005" data-link-icon="nlm-ncbi" data-link-icon-type="svg" title="&#39;The case of the disappearing teaspoons: longitudinal cohort study of the displacement of teaspoons in an Australian research institute&#39;, Lim et al 2005">“The case of the disappearing teaspoons: longitudinal cohort study of the displacement of teaspoons in an Australian research institute”</a><span>, <span><span title="et al">Lim</span> <span>et al</span> <span>2005</span></span></span>
            </li>
            <li>
              <a href="https://ntietz.com/doc/www/www.sumsar.net/92eab81d5ce31288909313b11f45d456bf8f4ad9.html" rel="archived alternate nofollow" data-url-original="https://www.sumsar.net/blog/2014/10/tiny-data-and-the-socks-of-karl-broman/" title="(Original URL: https://www.sumsar.net/blog/2014/10/tiny-data-and-the-socks-of-karl-broman/ )">“Tiny Data, Approximate Bayesian Computation and the Unpaired Socks of Karl Broman”</a> (sock-based demonstration of <a href="https://en.wikipedia.org/wiki/Approximate_Bayesian_computation" data-link-icon="wikipedia" data-link-icon-type="svg">ABC</a>)
            </li>
            <li>
              <a href="https://www.youtube.com/watch?v=qlJTLSncEV4" data-link-icon="youtube" data-link-icon-type="svg" title="通り抜けるねこ。-Maru&amp;Hana pass it.- [mugumogu, 2019-07-06]">“If a cat’s head passes, the body also passes?”</a> (slippery slope of adaptation)
            </li>
            <li>
              <a href="https://www.overcomingbias.com/2014/02/what-cost-variety.html" data-link-icon="OB" data-link-icon-type="text">“What Cost Variety?”</a>⁠, <a href="https://en.wikipedia.org/wiki/Robin_Hanson" data-link-icon="wikipedia" data-link-icon-type="svg">Robin Hanson</a> (<a href="https://en.wikipedia.org/wiki/Experience_curve_effects" data-link-icon="wikipedia" data-link-icon-type="svg">experience curve effects</a>)
            </li>
            <li>
              <a href="https://ntietz.com/doc/economics/2015-bronnenberg.pdf" id="bronnenberg-et-al-2015" data-link-icon="pdf" data-link-icon-type="svg" title="&#39;Do Pharmacists Buy Bayer? Informed Shoppers and the Brand Premium&#39;, Bronnenberg et al 2015">“Do Pharmacists Buy Bayer? Informed Shoppers and the Brand Premium”</a><span>, <span><span title="et al">Bronnenberg</span> <span>et al</span> <span>2015</span></span></span>
            </li>
            <li>
              <a href="https://worksinprogress.co/issue/the-maintenance-race/">“The Maintenance Race: The world’s first round-the-world solo yacht race was a thrilling and, for some, deadly contest. How its participants maintained their vessels can help us understand just how fundamental maintenance is.”</a>⁠, Stewart Brand
            </li>
            <li>Discussion: Reddit: <a href="https://old.reddit.com/r/slatestarcodex/comments/aj0xi7/poll_do_you_have_enough_socks/" data-link-icon="reddit" data-link-icon-type="svg">1</a>⁠, <a href="https://old.reddit.com/r/slatestarcodex/comments/bzz8mx/on_having_enough_socks/" data-link-icon="reddit" data-link-icon-type="svg">2</a>⁠; <a href="https://www.lesswrong.com/posts/Hc3z58hNmGF3bwcM2/on-having-enough-socks" data-link-icon="LW" data-link-icon-type="text">LessWrong</a>
            </li>
          </ul>
        </section>
        <section id="appendix">
          
          <section id="grocery-shopping-advice">
            <h2><a href="#grocery-shopping-advice" title="Link to section: § &#39;Grocery shopping advice&#39;">Grocery Shopping Advice</a></h2>
            <div>
              <blockquote>
                <p>To expand on the topic of experimenting &amp; grocery shopping, I would summarize good grocery shopping as involving, (in descending order of marginal returns), advance planning to select efficient targets, selection of grocery stores by total cost (including travel time), selection of cheapest version (experimentation up front, then selecting by unit cost), avoiding grocery store trickery like coupons, and using assistance like a standard grocery store shopping list to maintain correctness of decisions.</p>
              </blockquote>
            </div>
            <ol>
              <li>
                <p>plan recipes ahead to avoid impulse shopping and food wastage while puzzling how to eat something. Resources on frugal cooking are everywhere and you can find tons of advice on eg. cooking soup or stew. You should emphasize minimally unprocessed goods which are commodities and so cheap, with fewer layers of bogus product differentiation/​overhead/​advertising.</p>
                <p>Frozen vegetables, for example, are underrated in terms of both convenience (why spend that time cleaning &amp; chopping when industrial machines are so much more efficient at that?) and also cost, as they don’t go bad; and depending on the vegetable &amp; time of year, can easily be better-quality as well. (Carrots are a standout case: you can go through the hassle of cleaning, peeling, and chopping a sad bowl of fresh carrots which you must eat before they go bad, or you can eat some delicious pre-chopped carrots whenever you feel like pulling them out of your freezer, possibly a year later.)</p>
                <p>(I wouldn’t take ‘health’ too seriously as a criterion. Diet/​nutrition research is one of the worst fields in all medicine. Don’t sacrifice your quality of life now for some small late-late QALYs which may not exist at all.)</p>
              </li>
              <li>
                <p>investigate all local groceries. The average price can differ considerably between stores.</p>
                <p>In my own feasible shopping area, I have Walmart, Target, Shoppers, Aldi, Giant and some others (BJ’s is the major alternative but I’ve never been convinced I would be able to buy enough to benefit). When I switched from NEX to Walmart, I saved a good 10%; when I switched (most of) my shopping to Aldi, I saved another good 10%. (The cost savings had I started with Whole Foods or Harris Teeter hardly bear thinking on.) There are some disadvantages to shopping at Aldi (more restricted selection, disorganized store, having to remember to bring a quarter for the shopping carts) but saving $20 or $30 is a good salve for the annoyances. It may take some time to get familiar with a store (I take about an hour to thoroughly walk through a store, looking at where everything is and noting prices for things I often buy), but consider the <a href="https://en.wikipedia.org/wiki/Value_of_information" data-link-icon="wikipedia" data-link-icon-type="svg">Value of Information</a>: if you spend 2 or 3 hours to find a new grocery store and save 10–20%, that’s a savings of easily $120+ a year for a NPV of something like $2k. (120⁄log(1.05)) And there’s not that many to check.</p>
              </li>
              <li>
                <p>in choosing a grocery store and what to buy, remember the costs also of travel and time spent shopping.</p>
                <p>The goal is to get your groceries for a total cost which minimizes money, time, and effort. Every second spent shopping is a waste-–certainly I don’t particularly enjoy it. The cost of driving to a store is somewhere around $0.10-$0.50 per mile, and then there is the risk of accidents and your own time; adding up the mileage and time, I get ~$15 per grocery trip. This is a substantial fraction of the total cost of my groceries, and so I keep that in mind when planning: I shop once a month, stocking up as much as possible. I’d much rather make one trip to buy a lot of food at $120+$15=$135 than two trips at $60+$60+$15+$15=$150! (In this respect, Aldi is a wash for me: I have to spend somewhat longer driving to it, but it’s so much more compact and tiny that I spend much less time walking around it and checking out.) Travel time is also why it makes a lot of sense to occasionally buy from the local dollar store about 3 minutes away-–when a single trip costs $15, then even if a bottle of ketchup or whatever costs twice as much as at Aldi, it’s still a lot cheaper. (Although if you find yourself resorting to that too often, it suggests you are making mistakes further upstream.)</p>
              </li>
              <li>
                <p>in buying a specific ingredient, always start with the *unit* cost.</p>
                <p>Many foods keep a long time and you can easily make use of a larger quantity. It’s somewhat unusual for something to be <em>too</em> big to buy and a bad idea due to spoilage/​opportunity cost (usually something either perishable, like fruit, or ridiculously long-lasting and more expensive in opportunity cost than up front; eg. a few months ago, I finished off a bottle of molasses which dated, as best as I could infer from the copyrights on the label, from ~1995, and it would not be a good idea to buy a big bottle of molasses if you only use it once in a while like I do, for baking rye bread).</p>
              </li>
              <li>
                <p>when buying a new ingredient, start with the generic.</p>
              </li>
              <li>
                <p>If you have doubts about buying generic, test it: require the much more expensive brand-name goods to justify their existence.</p>
                <p>My preference is to take into account Value of Information: by the same logic as choosing groceries, rejecting a cheap generic food in favor of an expensive one is an expensive mistake as you incur it indefinitely.</p>
                <p>One of my pet peeves is how much money people waste on brand-name goods rather than defaulting to generics or off-brands, when there is rarely a noticeable taste difference to me. So my suggestion is that whenever you try something new, buy 1 of everything and try them out side by side to see what you like and if the brand-name quality can possibly justify paying so much more. I’ve done this with butter, milk, applesauce, cereal, bacon, sausage, mustard, ice cream, etc. It baffles me how few people apparently take advantage of this—like at Walmart, the ‘irregular bacon’ tastes literally identical and is not that different from the regular bacon and yet is always almost half-price per ounce! Half! If I spend $8 a month rather than $4 on bacon, that’s a NPV of −$983. Quite an expensive mistake to make over a lifetime.</p>
                <p>I don’t advise reinforcement learning-style approaches like <a href="https://en.wikipedia.org/wiki/Thompson_sampling" data-link-icon="wikipedia" data-link-icon-type="svg">Thompson sampling</a>⁠. Why? Because the VoI for testing all options is so high, you can sample them all simultaneously (making it more of a multiple-play MAB), there is large cognitive costs to maintaining options (the point is to get in and out as fast as possible, remember, to minimize time-cost) and so each sample has a fixed cost (which is ignored in the usual MAB formulation where it’s assumed you have to choose each round anyway), and in my experience sampling foodstuffs, not many things are ‘acquired tastes’ where multiple tastes will yield a different result, and there is not that much noise in taste comparisons of this sort. Typically, I try something and I immediately can tell that the generics/​brand-name are equivalent or which one is much superior. (And if the difference is subtle, then it doesn’t matter much, but typically the price difference is not subtle.) If there is no noise, the <a href="https://en.wikipedia.org/wiki/Expected_value" data-link-icon="wikipedia" data-link-icon-type="svg">EV</a> is highly positive, and you can take multiple actions simultaneously, taking a Thompson sampling or sequential testing approach is merely incurring unnecessary regret and complexity compared to a single-trial decision approach.</p>
                <p>So it’s best to do a single precise test of all available contenders, and then buy the top-ranked item from then on without thinking about it further. Does the optimal buy change? Maybe, but food prices are fairly stable in a relative rank-order sense (eg. when bacon spiked in price ~2017, all the bacons did simultaneously, so I wound up buying the exact same discount bacon, but less), so the decisions don’t seem to need to be revisited more. Even if the information decays, the tests are still worth running because aside from learning about the specific food type you’re testing, you benefit from getting an idea of the general range of variation in food taste/​quality and how much a brand-name is worth (ie. ‘little’).</p>
              </li>
              <li>
                <p>skip coupons and sales.</p>
                <p>They are negative sum games after taking into account the time wasted sorting through the gimmicks and all the options, intended to get things you didn’t want to buy in the first place, even at the discounted price, even occasional mistakes will wipe out the savings, and they discourage experimentation and comparison (you wouldn’t want to buy the other applesauce which you <em>don’t</em> have a coupon for, would you? why, that would be a ripoff!); worse, they are by definition ephemeral (making any effort spent on them “toil”), so your gained knowledge and effort becomes immediately worthless, as compared to stable long-term knowledge like which grocery store is cheapest, where all items are located, which generics to buy etc. Like credit card churning or frequent-flier miles, they should be avoided as traps. Life is far too short.</p>
              </li>
              <li>
                <p>Grocery lists should be kept regularly and reused as templates to avoid forgetting about important things or indulging in impulse or spree purchasing.</p>
              </li>
              <li>
                <p>Tracking expenditures can be helpful in finding categories of food which have been getting imbalanced spending and reviewing enjoyment/​$ tradeoffs.</p>
              </li>
              <li>
                <p>After evaluating stores, learning where items are, finishing taste comparisons, picking recipes, making template lists, the whole process shouldn’t occupy more than an hour or so a month: you take your template, modify slightly for current recipes, drive there, dash in to the prespecified items, buy those, and get out.</p>
              </li>
            </ol>
            <p>There are doubtless further optimizations which could be made, but by that point, I believe they truly are into the realm of ‘overthinking it’, and one should move one’s scarce deliberative capacity onto other topics (like career planning).</p>
            <p>To recap:</p>
            <ol>
              <li>plan sensible cheap meals</li>
              <li>find the cheapest local grocery store</li>
              <li>buy as rarely as possible, in bulk, and generic (unless a food is proven in taste-testing to be superior); get in and out and don’t be tempted.</li>
            </ol>
            <p>In terms of optimizing, keep in mind the Pareto principle: quantitatively, I think the biggest wins comes in this order:</p>
            <ol>
              <li>choice of foods (&lt;10× difference in cost)</li>
              <li>generic vs brand-name (1–3×)</li>
              <li>choice of grocery store (≤1.3×)</li>
              <li>buying bulk (1–1.5×)</li>
              <li>location and frequency of visits (1–1.1×)</li>
              <li>in-store shopping efficiency (1–1.05×)</li>
            </ol>
          </section>
        </section>
        
        <section id="backlinks-section">
          <a id="backlinks" href="https://ntietz.com/metadata/annotation/backlink/%252Fsocks.html" title="Reverse citations/backlinks for this page (the list of other pages which link to this page).">[backlinks]</a>
        </section>
        <section id="link-bibliography-section">
          <a id="link-bibliography" href="https://ntietz.com/metadata/annotation/link-bibliography/%252Fsocks.html" title="Bibliography of links cited in this page (forward citations). Lazily-transcluded version at footer of page for easier scrolling.">[link bibliography]</a>
        </section>
        <section id="similars-section">
          <a id="similars" href="https://ntietz.com/metadata/annotation/similar/%252Fsocks.html" title="Similar links for this link (by text embedding). Lazily-transcluded version at footer of page for easier scrolling.">[similar]</a>
        </section>
      </div></div>
  </body>
</html>
