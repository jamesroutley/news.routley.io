<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://notashes.me/blog/part-1-memory-management/">Original</a>
    <h1>Part 1: A Deep Dive into Rust and C Memory Interoperability</h1>
    
    <div id="readability-page-1" class="page"><div>    <article>    <div id="content">   <blockquote>
<p><strong>â€œMemory oppresses me.â€ - Severian, The Book of the New Sun</strong></p>
<p><strong>Interviewer</strong>: â€œWhat happens if you allocate memory with Câ€™s malloc and try to free it with Rustâ€™s dealloc, if you get a pointer to the memory from C?â€</p>
<p><strong>Me</strong>: â€œIf we do it via FFI then thereâ€™s a possibility the program may continue working (because the underlying structs share the same memory layout? right? â€¦right?)â€</p>
<p><em>Now if you have any experience working with memory management, you know that this is a dangerous answer. But I didnâ€™t know it at the time. I was just trying to get through the interview.</em></p>
<p>But I realized at that moment that I had been treating memory allocators like black boxes. I knew the rules - never mix allocators - but I didnâ€™t truly understand <em>why</em>. So hereâ€™s my attempt at de-mystifying memory management, starting with the fundamentals and building a testing laboratory to explore what happens when different memory worlds collide.</p>
</blockquote>
<h2 id="prerequisites">Prerequisites<a href="#prerequisites">#</a></h2>
<p>To get the most from this article, you should be familiar with:</p>
<ul>
<li>Basic Rust and C programming</li>
<li>Pointers and memory management concepts</li>
<li>Command line tools (bash, gcc, cargo)</li>
<li>Basic understanding of stack vs heap</li>
</ul>
<p>Donâ€™t worry if youâ€™re not an expert, Iâ€™m not one either - but Iâ€™ll explain concepts as best I can!</p>
<h2 id="table-of-contents">Table of Contents<a href="#table-of-contents">#</a></h2>
<ol>
<li><a href="#the-interview-question-that-started-everything">The Interview Question That Started Everything</a></li>
<li><a href="#why-memory-allocators-dont-mix">Why Memory Allocators Donâ€™t Mix</a></li>
<li><a href="#memory-fundamentals-building-our-mental-model">Memory Fundamentals: Building Our Mental Model</a></li>
<li><a href="#building-a-memory-testing-laboratory">Building a Memory Testing Laboratory</a></li>
<li><a href="#first-experiments-surprising-results">First Experiments: Surprising Results</a></li>
<li><a href="#key-takeaways-and-whats-next">Key Takeaways and Whatâ€™s Next</a></li>
</ol>
<h2 id="the-interview-question-that-started-everything">The Interview Question That Started Everything<a href="#the-interview-question-that-started-everything">#</a></h2>
<p>It was Friday afternoon when I had an interview for an amazing startup which focuses on building very high performance systems. The interview experience was intense while being highly rewarding. We touched upon topics async runtimes, memory management, rust FFI etc.</p>
<p>The intention wasnâ€™t to test my language specific knowledge but being able to reason about how these systems work at a level closer to the machine.</p>
<p>It caught me a little offguard. Itâ€™s not something I had prepared for. However, to be a good systems engineer, It is essential to develop a knack for the fundamentals - understanding how things work all the way down to the metal. Whether itâ€™s the intricacies of the CPU cache hierarchy, memory alignment, or the behavior of allocators under concurrency, these low-level details can have profound impacts on system performance and correctness.</p>
<p>That experience prompted me to reflect on my own gaps and sparked a sort of yearning to dig deeper into the topic. Hence, I decided to do this and start a journey to understand memory management better, starting with the basics and building a comprehensive testing framework to explore the interactions between Rust and C memory allocators.</p>
<h2 id="why-memory-allocators-dont-mix">Why Memory Allocators Donâ€™t Mix<a href="#why-memory-allocators-dont-mix">#</a></h2>
<p>Before diving into the technical details, letâ€™s understand the fundamental problem. But first, we need to establish what different exit codes mean when testing memory operations:</p>
<h3 id="understanding-exit-codes-in-memory-testing">Understanding Exit Codes in Memory Testing<a href="#understanding-exit-codes-in-memory-testing">#</a></h3>
<p>When experimenting with memory allocators, the exit code tells us exactly what happened:</p>





























<table><thead><tr><th>Exit Code</th><th>Signal</th><th>Meaning</th><th>Safety</th></tr></thead><tbody><tr><td>0</td><td>None</td><td>Process completed â€œsuccessfullyâ€</td><td>âš ï¸ <strong>DANGEROUS</strong> - Silent corruption</td></tr><tr><td>-11 or 139</td><td>SIGSEGV</td><td>Segmentation fault - invalid memory access</td><td>âœ… Safe - OS detected bad access</td></tr><tr><td>-6 or 134</td><td>SIGABRT</td><td>Program aborted - allocator detected corruption</td><td>âœ… Safe - Allocator safety checks worked</td></tr></tbody></table>
<blockquote>
<p>âš ï¸ <strong>The Hidden Danger of Exit Code 0</strong></p>
<p>When mixing allocators, exit code 0 is the worst possible outcome. It means memory corruption occurred but went undetected. Your program continues running with a corrupted heap - a time bomb that will explode unpredictably later. A crash (SIGSEGV or SIGABRT) is actually the safe outcome because it prevents further corruption.</p>
</blockquote>
<p>Now, when you write:</p>
<div tabindex="0" data-language="rust"><pre><code><span><span>// dangerous.rs</span></span>
<span><span>let</span><span> ptr </span><span>=</span><span> unsafe</span><span> { </span><span>libc</span><span>::</span><span>malloc</span><span>(</span><span>64</span><span>) };</span></span></code></pre><p><span>rust</span></p></div>
<p>Youâ€™re not just getting 64 bytes of memory. Youâ€™re entering into a complex contract with a specific allocator implementation. That allocator needs to track:</p>
<ul>
<li>How much memory you requested</li>
<li>Whether this chunk is free or allocated</li>
<li>Where the next and previous chunks are</li>
<li>Thread ownership information</li>
<li>Debugging metadata (in debug builds)</li>
</ul>
<p>Different allocators store this information differently. When you later call:</p>
<div tabindex="0" data-language="rust"><pre><code><span><span>// dangerous.rs</span></span>
<span><span>unsafe</span><span> { </span><span>std</span><span>::</span><span>alloc</span><span>::</span><span>dealloc</span><span>(ptr </span><span>as</span><span> *mut</span><span> u8</span><span>, layout) };</span></span></code></pre><p><span>rust</span></p></div>
<blockquote>
<p>âš ï¸ <strong>The Metadata Mismatch</strong></p>
<p>Rustâ€™s allocator looks for its metadata format at specific offsets from your pointer. If it finds glibcâ€™s metadata instead, the best case is an immediate crash. The worst case? Silent corruption that manifests as mysterious bugs hours later.</p>
</blockquote>
<h2 id="memory-fundamentals-building-our-mental-model">Memory Fundamentals: Building Our Mental Model<a href="#memory-fundamentals-building-our-mental-model">#</a></h2>
<p>To understand why allocators clash, we need to build a mental model of how memory actually works in modern systems.</p>
<h3 id="virtual-memory-the-grand-illusion">Virtual Memory: The Grand Illusion<a href="#virtual-memory-the-grand-illusion">#</a></h3>
<p>Every process on a modern operating system lives in its own virtual address space. On a 64-bit Linux system, your process sees:
<img src="https://notashes.me/_astro/memory-layout-of-a-process.CPUe2S_j_Zy5Jpx.webp" alt="virtual address space layout" width="1280" height="720" loading="lazy" decoding="async"/></p>
<p>This is all an illusion. These addresses donâ€™t correspond directly to physical RAM. Instead, the CPU and operating system work together to translate virtual addresses to physical addresses on every memory access. Understanding this translation is crucial because it affects everything from allocator design to the performance impact of memory access patterns.</p>
<h3 id="the-true-cost-of-memory-access">The True Cost of Memory Access<a href="#the-true-cost-of-memory-access">#</a></h3>
<p>To understand memory access costs, letâ€™s trace what happens when our test program accesses a typical heap address. During our experiments, malloc returned addresses like <code>0x00007fab8c3d2150</code>. This isnâ€™t random - addresses starting with <code>0x00007f</code> are in the standard heap region on 64-bit Linux systems.</p>
<p>Hereâ€™s how the CPU translates this virtual address to physical RAM:</p>
<div tabindex="0" data-language="plaintext"><pre><code><span><span>Virtual Address Translation (x86_64 with 4-level paging)</span></span>
<span><span></span></span>
<span><span>Virtual Address: 0x00007fab8c3d2150 (from our malloc experiment)</span></span>
<span><span></span></span>
<span><span>Bit Layout:</span></span>
<span><span>â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”</span></span>
<span><span>â”‚  PML4   â”‚   PDP   â”‚   PD    â”‚   PT    â”‚   Offset   â”‚</span></span>
<span><span>â”‚ [47:39] â”‚ [38:30] â”‚ [29:21] â”‚ [20:12] â”‚   [11:0]   â”‚</span></span>
<span><span>â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤</span></span>
<span><span>â”‚  0x0FE  â”‚  0x1AE  â”‚  0x118  â”‚  0x1D2  â”‚   0x150    â”‚</span></span>
<span><span>â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜</span></span>
<span><span></span></span>
<span><span>Where:</span></span>
<span><span>- PML4 = Page Map Level 4 (top-level page table)</span></span>
<span><span>- PDP = Page Directory Pointer</span></span>
<span><span>- PD = Page Directory  </span></span>
<span><span>- PT = Page Table</span></span>
<span><span>- Offset = Position within the 4KB page</span></span>
<span><span></span></span>
<span><span>Translation Steps:</span></span>
<span><span>1. CR3 register + (PML4 index Ã— 8) â†’ PML4 entry â†’ PDP base address</span></span>
<span><span>2. PDP base + (PDP index Ã— 8) â†’ PDP entry â†’ PD base address  </span></span>
<span><span>3. PD base + (PD index Ã— 8) â†’ PD entry â†’ PT base address</span></span>
<span><span>4. PT base + (PT index Ã— 8) â†’ PT entry â†’ Physical page base</span></span>
<span><span>5. Physical page base + offset (0x150) â†’ Final physical address</span></span>
<span><span></span></span>
<span><span>Cost: 4 memory accesses without TLB hit</span></span>
<span><span>      ~1 cycle with TLB hit (typical case)</span></span></code></pre><p><span>plaintext</span></p></div>
<p>The Translation Lookaside Buffer (TLB) is a specialized cache that stores recent virtual-to-physical address mappings. When you access memory sequentially (like iterating through an array), the TLB hit rate approaches 100%, making translation nearly free. But random access patterns can cause TLB misses, adding ~100 cycles per access - which is why memory access patterns matter so much for performance.</p>
<h3 id="the-heap-where-dynamic-memory-lives">The Heap: Where Dynamic Memory Lives<a href="#the-heap-where-dynamic-memory-lives">#</a></h3>
<p>When you call <code>malloc(64)</code>, youâ€™re asking the allocator to find 64 bytes of free memory on the heap. But this simple request triggers a complex chain of events:</p>
<ol>
<li><strong>Thread-Local Cache Check</strong>: Modern allocators first check thread-local caches to avoid lock contention</li>
<li><strong>Central Cache Search</strong>: If the thread cache is empty, check central free lists</li>
<li><strong>Free List Management</strong>: Search through free lists organized by size classes</li>
<li><strong>Heap Expansion</strong>: If no suitable chunk exists, request more memory from the OS</li>
</ol>
<p>The allocator must also deal with fragmentation:</p>
<div tabindex="0" data-language="plaintext"><pre><code><span><span>Heap State After Various Allocations/Deallocations:</span></span>
<span><span></span></span>
<span><span>[Used:16][Free:32][Used:64][Free:16][Used:32][Free:64]</span></span>
<span><span></span></span>
<span><span>Request for 48 bytes:</span></span>
<span><span>- First free chunk (32 bytes): Too small âœ—</span></span>
<span><span>- Second free chunk (16 bytes): Too small âœ—  </span></span>
<span><span>- Third free chunk (64 bytes): Success âœ“</span></span>
<span><span></span></span>
<span><span>Even though we have 112 bytes free total, they&#39;re not contiguous!</span></span></code></pre><p><span>plaintext</span></p></div>
<h3 id="cpu-cache-architecture-the-hidden-performance-layer">CPU Cache Architecture: The Hidden Performance Layer<a href="#cpu-cache-architecture-the-hidden-performance-layer">#</a></h3>
<p>Modern CPUs have multiple cache levels to bridge the massive speed gap between CPU and RAM:</p>
<div tabindex="0" data-language="plaintext"><pre><code><span><span>CPU Cache Hierarchy (typical Intel/AMD x86_64)</span></span>
<span><span>â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”</span></span>
<span><span></span></span>
<span><span>CPU Core</span></span>
<span><span>â”œâ”€ Registers (16-32, ~0 cycles)</span></span>
<span><span>â”œâ”€ L1 Cache (32-64KB, ~4-5 cycles)</span></span>
<span><span>â”œâ”€ L2 Cache (256KB-1MB, ~12-15 cycles)</span></span>
<span><span>â””â”€ L3 Cache (8-32MB shared, ~40-60 cycles)</span></span>
<span><span>    â”‚</span></span>
<span><span>    â””â”€â”€â”€ Main Memory (~100-300 cycles)</span></span>
<span><span></span></span>
<span><span>Cache Line Size: 64 bytes (x86_64)</span></span></code></pre><p><span>plaintext</span></p></div>
<p><em>Note: These are typical values - actual latencies vary by CPU model and generation</em></p>
<blockquote>
<p>ğŸ’¡ <strong>False Sharing: The Hidden Performance Killer</strong></p>
<p>This architecture has profound implications. Consider false sharing:</p>
<div tabindex="0" data-language="c"><pre><code><span><span>struct</span><span> thread_stats {</span></span>
<span><span>    int</span><span> thread1_counter;</span><span>  // Offset 0-3</span></span>
<span><span>    int</span><span> thread2_counter;</span><span>  // Offset 4-7  </span></span>
<span><span>    // Both in same 64-byte cache line!</span></span>
<span><span>};</span></span></code></pre><p><span>c</span></p></div>
<p>When thread 1 updates its counter, it invalidates the entire cache line on other cores. Thread 2 must wait for exclusive access to update its counter, even though theyâ€™re touching different variables. In our experiments, this caused an <strong>8.67x performance penalty</strong> - from 359.7M ops/sec down to 41.4M ops/sec!</p>
<p><strong>How we measured this</strong>: Using <code>perf stat -e L1-dcache-loads,L1-dcache-load-misses ./false_sharing_test</code>, we observed 891M L1 cache misses with false sharing vs only 12M without - a 74x increase in cache misses!</p>
</blockquote>
<h2 id="building-a-memory-testing-laboratory">Building a Memory Testing Laboratory<a href="#building-a-memory-testing-laboratory">#</a></h2>
<p>Understanding theory is one thing. Seeing it explode in practice is another. Armed with knowledge about virtual memory, heap structure, and cache architecture, I needed to build a comprehensive testing framework that could safely explore what happens when different memory worlds collide.</p>
<p>The framework needed to:</p>
<ol>
<li>Test multiple allocator implementations</li>
<li>Safely handle (and analyze) crashes</li>
<li>Measure performance without affecting results</li>
<li>Provide detailed debugging information</li>
</ol>
<blockquote>
<p>ğŸ“Š <strong>Testing Infrastructure Overview:</strong></p>
<p><strong>Key Components:</strong></p>
<ul>
<li><strong>Subprocess isolation</strong>: Each test runs in its own process via <code>Command::new()</code></li>
<li><strong>C library loading</strong>: <code>export LD_LIBRARY_PATH=../c-lib:$LD_LIBRARY_PATH</code></li>
<li><strong>Exit code analysis</strong>: Maps signals to meaningful results</li>
<li><strong>Performance tools</strong>: <code>perf stat</code>, custom timing, cache analysis</li>
</ul>
<p><strong>Repository Structure:</strong></p>
<div tabindex="0" data-language="plaintext"><pre><code><span><span>rust-c-memory-interop/</span></span>
<span><span>â”œâ”€â”€ c-lib/           # Custom allocator implementations</span></span>
<span><span>â”œâ”€â”€ rust-ffi/        # Rust test binaries and FFI bindings</span></span>
<span><span>â”œâ”€â”€ tools/           # Analysis scripts (bash)</span></span>
<span><span>â”‚   â”œâ”€â”€ run_crash_tests.sh  # Runs crash tests in subprocesses</span></span>
<span><span>â”‚   â”œâ”€â”€ perf_analysis.sh    # Generates performance analysis code</span></span>
<span><span>â”‚   â””â”€â”€ deep_analysis.sh    # Generates memory analysis code</span></span>
<span><span>â””â”€â”€ test_results/    # Output from experiments</span></span></code></pre><p><span>plaintext</span></p></div>
<p><strong>Note</strong>: The bash scripts in <code>tools/</code> dynamically generate Rust code for specialized analysis. This keeps the main codebase clean while allowing complex experiments.</p>
</blockquote>
<p>Hereâ€™s the framework I built:</p>
<div tabindex="0" data-language="rust"><pre><code><span><span>// rust-ffi/src/comprehensive_tests.rs</span></span>
<span><span>use</span><span> std</span><span>::</span><span>collections</span><span>::</span><span>HashMap</span><span>;</span></span>
<span><span>use</span><span> std</span><span>::</span><span>time</span><span>::</span><span>Instant</span><span>;</span></span>
<span></span>
<span><span>#[derive(</span><span>Debug</span><span>, </span><span>Clone</span><span>)]</span></span>
<span><span>pub</span><span> struct</span><span> TestResult</span><span> {</span></span>
<span><span>    pub</span><span> test_name</span><span>:</span><span> String</span><span>,</span></span>
<span><span>    pub</span><span> allocator</span><span>:</span><span> String</span><span>,</span></span>
<span><span>    pub</span><span> success</span><span>:</span><span> bool</span><span>,</span></span>
<span><span>    pub</span><span> duration</span><span>:</span><span> std</span><span>::</span><span>time</span><span>::</span><span>Duration</span><span>,</span></span>
<span><span>    pub</span><span> metrics</span><span>:</span><span> HashMap</span><span>&lt;</span><span>String</span><span>, </span><span>f64</span><span>&gt;,</span></span>
<span><span>    pub</span><span> notes</span><span>:</span><span> Vec</span><span>&lt;</span><span>String</span><span>&gt;,</span></span>
<span><span>}</span></span>
<span></span>
<span><span>pub</span><span> struct</span><span> ComprehensiveTestSuite</span><span> {</span></span>
<span><span>    results</span><span>:</span><span> Vec</span><span>&lt;</span><span>TestResult</span><span>&gt;,</span></span>
<span><span>}</span></span>
<span></span>
<span><span>impl</span><span> ComprehensiveTestSuite</span><span> {</span></span>
<span><span>    pub</span><span> fn</span><span> new</span><span>() </span><span>-&gt;</span><span> Self</span><span> {</span></span>
<span><span>        Self</span><span> {</span></span>
<span><span>            results</span><span>:</span><span> Vec</span><span>::</span><span>new</span><span>(),</span></span>
<span><span>        }</span></span>
<span><span>    }</span></span>
<span></span>
<span><span>    pub</span><span> fn</span><span> run_all_tests</span><span>(</span><span>&amp;mut</span><span> self</span><span>) {</span></span>
<span><span>        println!</span><span>(</span><span>&#34;=== Comprehensive Memory Allocator Test Suite ===</span><span>\n</span><span>&#34;</span><span>);</span></span>
<span></span>
<span><span>        // Basic functionality tests</span></span>
<span><span>        self</span><span>.</span><span>test_basic_allocation</span><span>();</span></span>
<span><span>        self</span><span>.</span><span>test_alignment_requirements</span><span>();</span></span>
<span><span>        self</span><span>.</span><span>test_size_classes</span><span>();</span></span>
<span><span>        </span></span>
<span><span>        // Performance tests</span></span>
<span><span>        self</span><span>.</span><span>test_allocation_performance</span><span>();</span></span>
<span><span>        self</span><span>.</span><span>test_fragmentation_behavior</span><span>();</span></span>
<span><span>        self</span><span>.</span><span>test_cache_efficiency</span><span>();</span></span>
<span><span>        </span></span>
<span><span>        // Safety tests</span></span>
<span><span>        self</span><span>.</span><span>test_metadata_corruption</span><span>();</span></span>
<span><span>        self</span><span>.</span><span>test_allocator_mixing</span><span>();</span></span>
<span><span>        </span></span>
<span><span>        // Generate report</span></span>
<span><span>        self</span><span>.</span><span>generate_report</span><span>();</span></span>
<span><span>    }</span></span>
<span><span>}</span></span></code></pre><p><span>rust</span></p></div>
<h3 id="implementing-multiple-allocators">Implementing Multiple Allocators<a href="#implementing-multiple-allocators">#</a></h3>
<p>To test allocator interactions, I implemented four different allocators in C, each with distinct characteristics and use cases:</p>
<p><strong>1. Standard malloc wrapper</strong> - <em>A thin pass-through to glibcâ€™s malloc</em>:</p>
<blockquote>
<p><strong>Use case</strong>: General-purpose allocation, the default for most C programs </p>
</blockquote>
<div tabindex="0" data-language="c"><pre><code><span><span>// allocators.c - Just forwards to system malloc/free</span></span>
<span><span>void*</span><span> standard_malloc</span><span>(</span><span>size_t</span><span> size</span><span>) {</span></span>
<span><span>    void*</span><span> ptr </span><span>=</span><span> malloc</span><span>(size);</span></span>
<span><span>    printf</span><span>(</span><span>&#34;[C] standard_malloc(</span><span>%zu</span><span>) = </span><span>%p\n</span><span>&#34;</span><span>, size, ptr);</span></span>
<span><span>    return</span><span> ptr;</span></span>
<span><span>}</span></span>
<span></span>
<span><span>void</span><span> standard_free</span><span>(</span><span>void*</span><span> ptr</span><span>) {</span></span>
<span><span>    free</span><span>(ptr);</span></span>
<span><span>    printf</span><span>(</span><span>&#34;[C] standard_free(</span><span>%p</span><span>)</span><span>\n</span><span>&#34;</span><span>, ptr);</span></span>
<span><span>}</span></span></code></pre><p><span>c</span></p></div>
<p><strong>2. Debug allocator</strong> - <em>Adds magic values before and after user data to detect buffer overflows and corruption</em>:</p>
<blockquote>
<p><strong>Use case</strong>: Development and debugging, catching memory corruption early </p>
</blockquote>
<div tabindex="0" data-language="c"><pre><code><span><span>// debug_allocator.c</span></span>
<span><span>#define</span><span> MALLOC_MAGIC_HEADER</span><span> 0x</span><span>DEADBEEF</span><span>  // Classic magic number for &#34;dead beef&#34;</span></span>
<span><span>#define</span><span> MALLOC_MAGIC_FOOTER</span><span> 0x</span><span>CAFEBABE</span><span>  // Java&#39;s magic number, means &#34;cafe babe&#34;</span></span>
<span></span>
<span><span>typedef</span><span> struct</span><span> alloc_header {</span></span>
<span><span>    uint32_t</span><span> magic;</span></span>
<span><span>    size_t</span><span> size;</span></span>
<span><span>    uint32_t</span><span> flags;</span></span>
<span><span>    void*</span><span> debug_info;</span></span>
<span><span>} </span><span>alloc_header_t</span><span>;</span></span>
<span></span>
<span><span>void*</span><span> debug_malloc</span><span>(</span><span>size_t</span><span> size</span><span>) {</span></span>
<span><span>    size_t</span><span> total_size </span><span>=</span><span> sizeof</span><span>(</span><span>alloc_header_t</span><span>) </span><span>+</span><span> size </span><span>+</span><span> sizeof</span><span>(</span><span>uint32_t</span><span>);</span></span>
<span><span>    void*</span><span> raw_ptr </span><span>=</span><span> malloc</span><span>(total_size);</span></span>
<span><span>    </span></span>
<span><span>    if</span><span> (</span><span>!</span><span>raw_ptr) </span><span>return</span><span> NULL</span><span>;</span></span>
<span><span>    </span></span>
<span><span>    alloc_header_t</span><span>*</span><span> header </span><span>=</span><span> (</span><span>alloc_header_t</span><span>*</span><span>)raw_ptr;</span></span>
<span><span>    header-&gt;magic </span><span>=</span><span> MALLOC_MAGIC_HEADER;</span></span>
<span><span>    header-&gt;size </span><span>=</span><span> size;</span></span>
<span><span>    header-&gt;flags </span><span>=</span><span> 0</span><span>;</span></span>
<span><span>    </span></span>
<span><span>    // User pointer starts after header</span></span>
<span><span>    void*</span><span> user_ptr </span><span>=</span><span> (</span><span>char*</span><span>)raw_ptr </span><span>+</span><span> sizeof</span><span>(</span><span>alloc_header_t</span><span>);</span></span>
<span><span>    </span></span>
<span><span>    // Footer at the end</span></span>
<span><span>    uint32_t*</span><span> footer </span><span>=</span><span> (</span><span>uint32_t*</span><span>)((</span><span>char*</span><span>)user_ptr </span><span>+</span><span> size);</span></span>
<span><span>    *</span><span>footer </span><span>=</span><span> MALLOC_MAGIC_FOOTER;</span></span>
<span><span>    </span></span>
<span><span>    return</span><span> user_ptr;</span></span>
<span><span>}</span></span></code></pre><p><span>c</span></p></div>
<p>Memory layout for debug allocator:</p>
<div tabindex="0" data-language="plaintext"><pre><code><span><span>[HEADER: 16 bytes] [USER DATA: requested size] [FOOTER: 4 bytes]</span></span>
<span><span>â”œâ”€ Magic (4B)      â”œâ”€ Your actual data        â””â”€ Magic (4B)</span></span>
<span><span>â”œâ”€ Size (8B)       â”‚                              0xCAFEBABE</span></span>
<span><span>â”œâ”€ Flags (4B)      â”‚</span></span>
<span><span>â””â”€ 0xDEADBEEF      â””â”€ Returned pointer points here</span></span></code></pre><p><span>plaintext</span></p></div>
<p><strong>3. Direct mmap allocator</strong> - <em>Bypasses the heap entirely, requesting memory pages directly from the OS</em>:</p>
<blockquote>
<p><strong>Use case</strong>: Large allocations, security-sensitive code, custom memory management </p>
</blockquote>
<div tabindex="0" data-language="c"><pre><code><span><span>// mmap_allocator.c</span></span>
<span><span>void*</span><span> mmap_malloc</span><span>(</span><span>size_t</span><span> size</span><span>) {</span></span>
<span><span>    size_t</span><span> page_size </span><span>=</span><span> sysconf</span><span>(_SC_PAGESIZE);</span></span>
<span><span>    size_t</span><span> alloc_size </span><span>=</span><span> ((size </span><span>+</span><span> page_size </span><span>-</span><span> 1</span><span>) </span><span>/</span><span> page_size) </span><span>*</span><span> page_size;</span></span>
<span><span>    </span></span>
<span><span>    void*</span><span> ptr </span><span>=</span><span> mmap</span><span>(</span><span>NULL</span><span>, alloc_size, PROT_READ </span><span>|</span><span> PROT_WRITE, </span></span>
<span><span>                     MAP_PRIVATE </span><span>|</span><span> MAP_ANONYMOUS, </span><span>-</span><span>1</span><span>, </span><span>0</span><span>);</span></span>
<span><span>    </span></span>
<span><span>    if</span><span> (ptr </span><span>==</span><span> MAP_FAILED) </span><span>return</span><span> NULL</span><span>;</span></span>
<span><span>    </span></span>
<span><span>    // Store size in first 8 bytes</span></span>
<span><span>    *</span><span>((</span><span>size_t*</span><span>)ptr) </span><span>=</span><span> alloc_size;</span></span>
<span><span>    return</span><span> (</span><span>char*</span><span>)ptr </span><span>+</span><span> sizeof</span><span>(</span><span>size_t</span><span>);</span></span>
<span><span>}</span></span></code></pre><p><span>c</span></p></div>
<p><strong>4. Arena allocator</strong> - <em>A bump allocator that allocates from a large pool and frees everything at once</em>:</p>
<blockquote>
<p><strong>Use case</strong>: Temporary allocations, parsing, per-request memory in servers </p>
</blockquote>
<div tabindex="0" data-language="c"><pre><code><span><span>// arena_allocator.c</span></span>
<span><span>typedef</span><span> struct</span><span> arena {</span></span>
<span><span>    void*</span><span> memory;</span></span>
<span><span>    size_t</span><span> size;</span></span>
<span><span>    size_t</span><span> used;</span></span>
<span><span>    struct</span><span> arena</span><span>*</span><span> next;</span></span>
<span><span>} </span><span>arena_t</span><span>;</span></span>
<span></span>
<span><span>void*</span><span> arena_malloc</span><span>(</span><span>size_t</span><span> size</span><span>) {</span></span>
<span><span>    // Align to 8 bytes - required for 64-bit pointers and doubles</span></span>
<span><span>    // Formula: (size + 7) &amp; ~7 rounds up to next multiple of 8</span></span>
<span><span>    size </span><span>=</span><span> (size </span><span>+</span><span> 7</span><span>) </span><span>&amp;</span><span> ~</span><span>7</span><span>;</span></span>
<span><span>    </span></span>
<span><span>    if</span><span> (</span><span>!</span><span>g_arena </span><span>||</span><span> g_arena-&gt;used </span><span>+</span><span> size </span><span>&gt;</span><span> g_arena-&gt;size) {</span></span>
<span><span>        // Need new arena</span></span>
<span><span>        arena_t</span><span>*</span><span> new_arena </span><span>=</span><span> malloc</span><span>(</span><span>sizeof</span><span>(</span><span>arena_t</span><span>));</span></span>
<span><span>        new_arena-&gt;memory </span><span>=</span><span> malloc</span><span>(</span><span>1024</span><span> *</span><span> 1024</span><span>);</span><span> // 1MB chunks</span></span>
<span><span>        new_arena-&gt;size </span><span>=</span><span> 1024</span><span> *</span><span> 1024</span><span>;</span></span>
<span><span>        new_arena-&gt;used </span><span>=</span><span> 0</span><span>;</span></span>
<span><span>        new_arena-&gt;next </span><span>=</span><span> g_arena;</span></span>
<span><span>        g_arena </span><span>=</span><span> new_arena;</span></span>
<span><span>    }</span></span>
<span><span>    </span></span>
<span><span>    void*</span><span> ptr </span><span>=</span><span> (</span><span>char*</span><span>)g_arena-&gt;memory </span><span>+</span><span> g_arena-&gt;used;</span></span>
<span><span>    g_arena-&gt;used </span><span>+=</span><span> size;</span></span>
<span><span>    return</span><span> ptr;</span></span>
<span><span>}</span></span></code></pre><p><span>c</span></p></div>
<h3 id="creating-safe-crash-tests">Creating Safe Crash Tests<a href="#creating-safe-crash-tests">#</a></h3>
<p>The most challenging part was creating tests that could crash safely and provide useful diagnostics. Since mixing allocators can cause segmentation faults, I needed to isolate each test in a subprocess:</p>
<blockquote>
<p>ğŸ“Š <strong>Why Subprocess Isolation?</strong></p>
<ul>
<li><strong>Main process safety</strong>: Crashes in subprocess donâ€™t kill the test harness</li>
<li><strong>Exit code capture</strong>: Can detect SIGSEGV (-11) vs SIGABRT (-6) vs success (0)</li>
<li><strong>Output collection</strong>: Capture stdout/stderr even when process crashes</li>
<li><strong>Timeout protection</strong>: Prevent infinite loops with <code>timeout</code> command</li>
</ul>
</blockquote>
<div tabindex="0" data-language="rust"><pre><code><span><span>// crash_tests.rs</span></span>
<span><span>use</span><span> std</span><span>::</span><span>process</span><span>::</span><span>{</span><span>Command</span><span>, </span><span>Stdio</span><span>};</span></span>
<span><span>use</span><span> std</span><span>::</span><span>io</span><span>::</span><span>Write</span><span>;</span></span>
<span></span>
<span><span>// Note: Crash test subprocess management is handled by tools/run_crash_tests.sh</span></span>
<span><span>// This bash script approach provides better isolation and exit code handling.</span></span>
<span></span>
<span><span>// The actual crash tests are implemented in crash_tests.rs:</span></span>
<span><span>fn</span><span> test_rust_free_c_malloc</span><span>() {</span></span>
<span><span>    println!</span><span>(</span><span>&#34;=== Test: Rust dealloc on C malloc ===&#34;</span><span>);</span></span>
<span><span>    </span></span>
<span><span>    unsafe</span><span> {</span></span>
<span><span>        let</span><span> ptr </span><span>=</span><span> standard_malloc</span><span>(</span><span>64</span><span>);</span></span>
<span><span>        println!</span><span>(</span><span>&#34;C malloc returned: {:p}&#34;</span><span>, ptr);</span></span>
<span><span>        </span></span>
<span><span>        // This is UNDEFINED BEHAVIOR - mixing allocators!</span></span>
<span><span>        let</span><span> layout </span><span>=</span><span> Layout</span><span>::</span><span>from_size_align</span><span>(</span><span>64</span><span>, </span><span>8</span><span>)</span><span>.</span><span>unwrap</span><span>();</span></span>
<span><span>        println!</span><span>(</span><span>&#34;Attempting Rust dealloc with layout: {:?}&#34;</span><span>, layout);</span></span>
<span><span>        std</span><span>::</span><span>alloc</span><span>::</span><span>dealloc</span><span>(ptr </span><span>as</span><span> *mut</span><span> u8</span><span>, layout);</span></span>
<span><span>        </span></span>
<span><span>        println!</span><span>(</span><span>&#34;If you see this, it didn&#39;t crash immediately...&#34;</span><span>);</span></span>
<span><span>    }</span></span>
<span><span>}</span></span></code></pre><p><span>rust</span></p></div>
<p>The crash test script (<code>tools/run_crash_tests.sh</code>) runs each test with timeout protection:</p>
<div tabindex="0" data-language="bash"><pre><code><span><span>timeout</span><span> 5</span><span> ./target/release/crash_tests</span><span> $test </span><span>&gt;&gt;</span><span> $OUTPUT_FILE </span><span>2&gt;&amp;1</span></span>
<span><span>EXIT_CODE</span><span>=</span><span>$?</span></span>
<span></span>
<span><span>case</span><span> $EXIT_CODE </span><span>in</span></span>
<span><span>    0</span><span>)</span></span>
<span><span>        echo</span><span> &#34;Result: NO CRASH (dangerous - undefined behavior likely)&#34;</span></span>
<span><span>        ;;</span></span>
<span><span>    134</span><span>)</span></span>
<span><span>        echo</span><span> &#34;Result: SIGABRT (allocator detected corruption)&#34;</span></span>
<span><span>        ;;</span></span>
<span><span>    139</span><span>)</span></span>
<span><span>        echo</span><span> &#34;Result: SIGSEGV (segmentation fault)&#34;</span></span>
<span><span>        ;;</span></span>
<span><span>esac</span></span></code></pre><p><span>bash</span></p></div>
<h2 id="first-experiments-surprising-results">First Experiments: Surprising Results<a href="#first-experiments-surprising-results">#</a></h2>
<p>With the laboratory built, it was time to start experimenting. My first test was the obvious one - what happens when you mix allocators?</p>
<h3 id="experiment-1-the-basic-mix">Experiment 1: The Basic Mix<a href="#experiment-1-the-basic-mix">#</a></h3>
<p>To test allocator mixing safely, I ran each test in a subprocess to catch crashes:</p>
<div tabindex="0" data-language="rust"><pre><code><span><span>// From our test harness</span></span>
<span><span>fn</span><span> test_allocator_mixing</span><span>() {</span></span>
<span><span>    let</span><span> child </span><span>=</span><span> Command</span><span>::</span><span>new</span><span>(</span><span>&#34;./test_binary&#34;</span><span>)</span></span>
<span><span>        .</span><span>arg</span><span>(</span><span>&#34;mix_allocators&#34;</span><span>)</span></span>
<span><span>        .</span><span>output</span><span>()</span></span>
<span><span>        .</span><span>expect</span><span>(</span><span>&#34;Failed to execute test&#34;</span><span>);</span></span>
<span><span>    </span></span>
<span><span>    // In the subprocess:</span></span>
<span><span>    unsafe</span><span> fn</span><span> mix_allocators</span><span>() {</span></span>
<span><span>        let</span><span> c_ptr </span><span>=</span><span> libc</span><span>::</span><span>malloc</span><span>(</span><span>64</span><span>);</span></span>
<span><span>        println!</span><span>(</span><span>&#34;C malloc returned: {:p}&#34;</span><span>, c_ptr);</span></span>
<span><span>        </span></span>
<span><span>        let</span><span> layout </span><span>=</span><span> Layout</span><span>::</span><span>from_size_align</span><span>(</span><span>64</span><span>, </span><span>8</span><span>)</span><span>.</span><span>unwrap</span><span>();</span></span>
<span><span>        std</span><span>::</span><span>alloc</span><span>::</span><span>dealloc</span><span>(c_ptr </span><span>as</span><span> *mut</span><span> u8</span><span>, layout);</span></span>
<span><span>        </span></span>
<span><span>        println!</span><span>(</span><span>&#34;If you see this, we got lucky...&#34;</span><span>);</span></span>
<span><span>    }</span></span>
<span><span>    </span></span>
<span><span>    let</span><span> exit_code </span><span>=</span><span> child</span><span>.</span><span>status</span><span>.</span><span>code</span><span>()</span><span>.</span><span>unwrap_or</span><span>(</span><span>-</span><span>1</span><span>);</span></span>
<span><span>}</span></span></code></pre><p><span>rust</span></p></div>
<p>I expected an immediate crash. What I got surprised me:</p>
<div tabindex="0" data-language="plaintext"><pre><code><span><span>C malloc returned: 0x55cd332f5be0</span></span>
<span><span>Attempting Rust dealloc with layout: Layout { size: 64, align: 8 }</span></span>
<span><span>If you see this, it didn&#39;t crash immediately...</span></span>
<span><span></span></span>
<span><span>Exit code: 0</span></span></code></pre><p><span>plaintext</span></p></div>
<p>Remember our exit code table? Exit code 0 is the <strong>worst possible outcome</strong>. The program continued with corrupted heap metadata - a silent time bomb.</p>
<blockquote>
<p>ğŸ”¥ <strong>DANGER: Exit Code 0 with Memory Corruption</strong></p>
<p>This is a nightmare scenario:</p>
<ul>
<li>âœ… Your tests pass</li>
<li>âœ… Your program runs â€œnormallyâ€</li>
<li>âŒ Heap metadata is silently corrupted</li>
<li>âŒ Random crashes will occur later</li>
<li>âŒ Data corruption is unpredictable</li>
<li>âŒ Security vulnerabilities are introduced</li>
</ul>
<p>A crash (SIGSEGV/SIGABRT) is actually the <strong>safe</strong> outcome!</p>
</blockquote>
<p>Letâ€™s understand why this happened instead of crashing immediately.</p>
<h3 id="experiment-2-understanding-the-non-crash">Experiment 2: Understanding the Non-Crash<a href="#experiment-2-understanding-the-non-crash">#</a></h3>
<p>Why didnâ€™t it crash? Time for some detective work. I needed to peek at the raw memory around our allocation to understand glibcâ€™s metadata structure.</p>
<blockquote>
<p>ğŸ“Š <strong>Tools Used for Memory Inspection:</strong></p>
<ul>
<li><strong>Memory access</strong>: <code>std::slice::from_raw_parts</code> - Rustâ€™s way to view raw memory as a byte slice</li>
<li><strong>Offset calculation</strong>: <code>pointer.offset(-16)</code> - Look 16 bytes before the returned pointer</li>
<li><strong>Why -16?</strong>: glibc stores chunk metadata in the 8-16 bytes before user data</li>
<li><strong>Run command</strong>: <code>./tools/deep_analysis.sh</code> (dynamically generates and runs analysis code)</li>
</ul>
</blockquote>
<div tabindex="0" data-language="rust"><pre><code><span><span>// deep_analysis.sh dynamically generates this analysis code:</span></span>
<span><span>fn</span><span> analyze_glibc_malloc_internals</span><span>() {</span></span>
<span><span>    unsafe</span><span> {</span></span>
<span><span>        // Allocate different sizes to trigger different paths</span></span>
<span><span>        let</span><span> small </span><span>=</span><span> libc</span><span>::</span><span>malloc</span><span>(</span><span>24</span><span>);      </span><span>// Fastbin</span></span>
<span><span>        let</span><span> medium </span><span>=</span><span> libc</span><span>::</span><span>malloc</span><span>(</span><span>512</span><span>);    </span><span>// Smallbin  </span></span>
<span><span>        let</span><span> large </span><span>=</span><span> libc</span><span>::</span><span>malloc</span><span>(</span><span>131072</span><span>);  </span><span>// Large bin or mmap</span></span>
<span><span>        </span></span>
<span><span>        // Peek at malloc chunk headers (glibc specific)</span></span>
<span><span>        // Chunk format: size | flags in lowest 3 bits</span></span>
<span><span>        if</span><span> !</span><span>small</span><span>.</span><span>is_null</span><span>() {</span></span>
<span><span>            let</span><span> chunk_ptr </span><span>=</span><span> (small </span><span>as</span><span> *mut</span><span> usize</span><span>)</span><span>.</span><span>offset</span><span>(</span><span>-</span><span>1</span><span>);</span></span>
<span><span>            let</span><span> chunk_size </span><span>=</span><span> *</span><span>chunk_ptr </span><span>&amp;</span><span> !</span><span>0x7</span><span>;</span></span>
<span><span>            let</span><span> flags </span><span>=</span><span> *</span><span>chunk_ptr </span><span>&amp;</span><span> 0x7</span><span>;</span></span>
<span><span>            </span></span>
<span><span>            println!</span><span>(</span><span>&#34;Small chunk header:&#34;</span><span>);</span></span>
<span><span>            println!</span><span>(</span><span>&#34;  Size: {} (0x{:x})&#34;</span><span>, chunk_size, chunk_size);</span></span>
<span><span>            println!</span><span>(</span><span>&#34;  Flags: 0x{:x}&#34;</span><span>, flags);</span></span>
<span><span>            println!</span><span>(</span><span>&#34;    PREV_INUSE: {}&#34;</span><span>, flags </span><span>&amp;</span><span> 0x1</span><span> !=</span><span> 0</span><span>);</span></span>
<span><span>            println!</span><span>(</span><span>&#34;    IS_MMAPPED: {}&#34;</span><span>, flags </span><span>&amp;</span><span> 0x2</span><span> !=</span><span> 0</span><span>);</span></span>
<span><span>        }</span></span>
<span><span>        </span></span>
<span><span>        libc</span><span>::</span><span>free</span><span>(small);</span></span>
<span><span>        libc</span><span>::</span><span>free</span><span>(medium);</span></span>
<span><span>        libc</span><span>::</span><span>free</span><span>(large);</span></span>
<span><span>    }</span></span>
<span><span>}</span></span></code></pre><p><span>rust</span></p></div>
<p>To run this analysis:</p>
<div tabindex="0" data-language="bash"><pre><code><span><span>cd</span><span> rust-ffi</span></span>
<span><span>export</span><span> LD_LIBRARY_PATH</span><span>=</span><span>../c-lib:$LD_LIBRARY_PATH</span></span>
<span><span>cargo</span><span> run</span><span> --release</span><span> --bin</span><span> deep_analysis</span></span></code></pre><p><span>bash</span></p></div>
<p>This revealed glibcâ€™s metadata structure:</p>
<div tabindex="0" data-language="plaintext"><pre><code><span><span>Memory layout around allocation:</span></span>
<span><span>Offset -16 to -1 (before user ptr):</span></span>
<span><span>00 00 00 00 00 00 00 00 51 00 00 00 00 00 00 00</span></span>
<span><span>Offset 0 to 15 (user data):</span></span>
<span><span>00 00 00 00 00 00 00 00 00 00 00 00 00 00 00 00</span></span></code></pre><p><span>plaintext</span></p></div>
<p>That <code>0x51</code> at offset -8 is the key. Let me break it down:</p>
<ul>
<li>Bottom 3 bits are flags:
<ul>
<li>Bit 0 (0x1): PREV_INUSE - previous chunk is allocated</li>
<li>Bit 1 (0x2): IS_MMAPPED - chunk from mmap (not set here)</li>
<li>Bit 2 (0x4): NON_MAIN_ARENA - from thread arena (not set)</li>
</ul>
</li>
<li>Upper bits: 0x50 = 80 bytes total chunk size</li>
</ul>
<p>So: User requested 64 bytes, glibc allocated an 80-byte chunk (16 bytes metadata overhead).</p>
<p>When Rustâ€™s allocator looked for its metadata at a different offset, it found zeros - which by pure chance didnâ€™t trigger an immediate crash. But the heap is now corrupted, and any subsequent allocation could fail catastrophically.</p>
<h3 id="experiment-3-the-allocator-matrix">Experiment 3: The Allocator Matrix<a href="#experiment-3-the-allocator-matrix">#</a></h3>
<p>I systematically tested every combination:</p>
<div tabindex="0" data-language="rust"><pre><code><span><span>// allocator_matrix.rs</span></span>
<span><span>fn</span><span> test_allocator_mixing</span><span>() {</span></span>
<span><span>    let</span><span> allocators </span><span>=</span><span> vec!</span><span>[</span><span>&#34;standard&#34;</span><span>, </span><span>&#34;debug&#34;</span><span>, </span><span>&#34;mmap&#34;</span><span>, </span><span>&#34;arena&#34;</span><span>];</span></span>
<span><span>    let</span><span> mut</span><span> results </span><span>=</span><span> Vec</span><span>::</span><span>new</span><span>();</span></span>
<span><span>    </span></span>
<span><span>    for</span><span> alloc </span><span>in</span><span> &amp;</span><span>allocators {</span></span>
<span><span>        for</span><span> dealloc </span><span>in</span><span> &amp;</span><span>allocators {</span></span>
<span><span>            if</span><span> alloc </span><span>!=</span><span> dealloc {</span></span>
<span><span>                let</span><span> result </span><span>=</span><span> test_mix</span><span>(alloc, dealloc);</span></span>
<span><span>                results</span><span>.</span><span>push</span><span>(result);</span></span>
<span><span>            }</span></span>
<span><span>        }</span></span>
<span><span>    }</span></span>
<span><span>    </span></span>
<span><span>    // Print results matrix</span></span>
<span><span>    println!</span><span>(</span><span>&#34;</span><span>\n</span><span>Allocator Mixing Results:&#34;</span><span>);</span></span>
<span><span>    println!</span><span>(</span><span>&#34;Alloc with â†’ Free with = Result&#34;</span><span>);</span></span>
<span><span>    println!</span><span>(</span><span>&#34;â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€&#34;</span><span>);</span></span>
<span><span>    </span></span>
<span><span>    for</span><span> result </span><span>in</span><span> results {</span></span>
<span><span>        println!</span><span>(</span><span>&#34;{:10} â†’ {:10} = {:?}&#34;</span><span>, </span></span>
<span><span>                 result</span><span>.</span><span>allocator, </span></span>
<span><span>                 result</span><span>.</span><span>deallocator, </span></span>
<span><span>                 result</span><span>.</span><span>outcome);</span></span>
<span><span>    }</span></span>
<span><span>}</span></span></code></pre><p><span>rust</span></p></div>
<p>The results painted a clear picture:</p>
<div tabindex="0" data-language="plaintext"><pre><code><span><span>Allocator Mixing Results:</span></span>
<span><span>Alloc with â†’ Free with = Result</span></span>
<span><span>â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€</span></span>
<span><span>standard   â†’ debug      = CRASH (Abort: invalid magic number)</span></span>
<span><span>standard   â†’ mmap       = CRASH (Segfault: munmap on malloc&#39;d memory)</span></span>
<span><span>standard   â†’ arena      = NO-OP (arena doesn&#39;t free individual chunks)</span></span>
<span><span>debug      â†’ standard   = CRASH (Segfault: bad metadata offset)</span></span>
<span><span>debug      â†’ mmap       = CRASH (Segfault: munmap on malloc&#39;d memory)</span></span>
<span><span>debug      â†’ arena      = NO-OP</span></span>
<span><span>mmap       â†’ standard   = CRASH (Abort: free on mmap&#39;d memory)</span></span>
<span><span>mmap       â†’ debug      = CRASH (Abort: bad magic number)</span></span>
<span><span>mmap       â†’ arena      = NO-OP</span></span>
<span><span>arena      â†’ standard   = CRASH (double free when arena resets)</span></span>
<span><span>arena      â†’ debug      = CRASH (Abort: bad magic number)</span></span>
<span><span>arena      â†’ mmap       = CRASH (Segfault: munmap on malloc&#39;d memory)</span></span></code></pre><p><span>plaintext</span></p></div>
<blockquote>
<p><strong>Update</strong>: Our actual crash tests revealed a more nuanced reality:</p>
<ul>
<li><strong>Rust/C mixing often doesnâ€™t crash immediately</strong> (Exit code 0)</li>
<li><strong>Only certain combinations trigger immediate detection</strong> (like double_free)</li>
<li><strong>Silent corruption is the most common outcome</strong> - far more dangerous than crashes</li>
</ul>
</blockquote>
<p>Key insights:</p>
<ul>
<li>Debug allocatorâ€™s magic number checks catch corruption fastest (SIGABRT)</li>
<li>Standard/mmap mixing fails at the syscall level (SIGSEGV)</li>
<li>Arena allocatorâ€™s NO-OP behavior creates memory leaks</li>
<li>Every non-matching combination eventually fails - itâ€™s just a matter of when</li>
</ul>
<h3 id="experiment-4-size-class-discovery">Experiment 4: Size Class Discovery<a href="#experiment-4-size-class-discovery">#</a></h3>
<blockquote>
<p><strong>What are size classes?</strong> Memory allocators donâ€™t allocate exact byte amounts. Instead, they round up to predefined â€œsize classesâ€ to reduce fragmentation and improve performance. For example, if you request 20 bytes, you might actually get 24 bytes. This standardization allows the allocator to efficiently reuse freed chunks and maintain free lists for common sizes.</p>
</blockquote>
<p>One fascinating discovery was how allocators organize memory into these size classes. I used glibcâ€™s <code>malloc_usable_size()</code> function to discover the actual allocated sizes:</p>
<blockquote>
<p>ğŸ“Š <strong>Tools for Size Class Discovery:</strong></p>
<ul>
<li><strong>Function</strong>: <code>libc::malloc_usable_size()</code> - Returns actual allocated size</li>
<li><strong>Platform</strong>: Linux-specific (requires <code>#[cfg(target_os = &#34;linux&#34;)]</code>)</li>
<li><strong>Method</strong>: Allocate every size from 1-256 bytes, track when actual size changes</li>
<li><strong>Purpose</strong>: Understand memory overhead and fragmentation</li>
</ul>
</blockquote>
<div tabindex="0" data-language="rust"><pre><code><span><span>// size_classes.rs - Part of comprehensive_tests</span></span>
<span><span>fn</span><span> discover_size_classes</span><span>() {</span></span>
<span><span>    println!</span><span>(</span><span>&#34;Discovering allocator size classes...</span><span>\n</span><span>&#34;</span><span>);</span></span>
<span><span>    </span></span>
<span><span>    let</span><span> mut</span><span> size_to_actual </span><span>=</span><span> HashMap</span><span>::</span><span>new</span><span>();</span></span>
<span><span>    </span></span>
<span><span>    for</span><span> size </span><span>in</span><span> 1</span><span>..=</span><span>256</span><span> {</span></span>
<span><span>        unsafe</span><span> {</span></span>
<span><span>            let</span><span> ptr </span><span>=</span><span> libc</span><span>::</span><span>malloc</span><span>(size);</span></span>
<span><span>            </span></span>
<span><span>            #[cfg(target_os </span><span>=</span><span> &#34;linux&#34;</span><span>)]</span></span>
<span><span>            {</span></span>
<span><span>                // This function reveals the actual chunk size</span></span>
<span><span>                let</span><span> actual </span><span>=</span><span> libc</span><span>::</span><span>malloc_usable_size</span><span>(ptr) </span><span>as</span><span> usize</span><span>;</span></span>
<span><span>                size_to_actual</span><span>.</span><span>insert</span><span>(size, actual);</span></span>
<span><span>            }</span></span>
<span><span>            </span></span>
<span><span>            libc</span><span>::</span><span>free</span><span>(ptr);</span></span>
<span><span>        }</span></span>
<span><span>    }</span></span>
<span><span>    </span></span>
<span><span>    // Find size class boundaries</span></span>
<span><span>    let</span><span> mut</span><span> current_class </span><span>=</span><span> 0</span><span>;</span></span>
<span><span>    for</span><span> size </span><span>in</span><span> 1</span><span>..=</span><span>256</span><span> {</span></span>
<span><span>        let</span><span> actual </span><span>=</span><span> size_to_actual[</span><span>&amp;</span><span>size];</span></span>
<span><span>        if</span><span> actual </span><span>!=</span><span> current_class {</span></span>
<span><span>            println!</span><span>(</span><span>&#34;Size class boundary at {} bytes â†’ {} bytes actual&#34;</span><span>, </span></span>
<span><span>                     size, actual);</span></span>
<span><span>            current_class </span><span>=</span><span> actual;</span></span>
<span><span>        }</span></span>
<span><span>    }</span></span>
<span><span>}</span></span></code></pre><p><span>rust</span></p></div>
<p>To run this analysis:</p>
<div tabindex="0" data-language="bash"><pre><code><span><span>./target/release/comprehensive_tests</span><span> |</span><span> grep</span><span> &#34;Size class&#34;</span></span></code></pre><p><span>bash</span></p></div>
<p>Results showed glibcâ€™s size class optimization:</p>
<div tabindex="0" data-language="plaintext"><pre><code><span><span>Size class boundary at 1 bytes â†’ 24 bytes actual</span></span>
<span><span>Size class boundary at 25 bytes â†’ 40 bytes actual</span></span>
<span><span>Size class boundary at 41 bytes â†’ 56 bytes actual</span></span>
<span><span>Size class boundary at 57 bytes â†’ 72 bytes actual</span></span>
<span><span>Size class boundary at 73 bytes â†’ 88 bytes actual</span></span>
<span><span>...</span></span></code></pre><p><span>plaintext</span></p></div>
<blockquote>
<p>âš ï¸ <strong>The 2300% Overhead</strong></p>
<p>The minimum allocation is 24 bytes - even for a single byte! This 2300% overhead for tiny allocations explains why pooling small objects is so important.</p>
</blockquote>
<h3 id="hidden-danger-use-after-free-data-persistence">Hidden Danger: Use-After-Free Data Persistence<a href="#hidden-danger-use-after-free-data-persistence">#</a></h3>
<p>One of the most surprising discoveries was how much data survives after <code>free()</code>. I tested this by filling memory with a pattern, freeing it, then immediately reallocating to see what remained:</p>
<blockquote>
<p>ğŸ“Š <strong>Use-After-Free Analysis Method:</strong></p>
<ul>
<li><strong>Pattern</strong>: Fill with incrementing bytes (0x00, 0x01, 0x02â€¦)</li>
<li><strong>Test</strong>: Free the memory, immediately allocate same size</li>
<li><strong>Detection</strong>: Compare byte-by-byte to see what survived</li>
<li><strong>Tool</strong>: Part of <code>deep_analysis</code> binary, see Experiment 2.3 in EXPERIMENTS.md</li>
</ul>
</blockquote>
<div tabindex="0" data-language="c"><pre><code><span><span>// From EXPERIMENTS.md - Experiment 2.3</span></span>
<span><span>void</span><span> analyze_use_after_free</span><span>() {</span></span>
<span><span>    uint8_t*</span><span> ptr </span><span>=</span><span> malloc</span><span>(</span><span>64</span><span>);</span></span>
<span><span>    </span></span>
<span><span>    // Fill with recognizable pattern</span></span>
<span><span>    for</span><span> (</span><span>size_t</span><span> i </span><span>=</span><span> 0</span><span>; i </span><span>&lt;</span><span> 64</span><span>; i</span><span>++</span><span>) {</span></span>
<span><span>        ptr</span><span>[i] </span><span>=</span><span> (</span><span>uint8_t</span><span>)(i </span><span>&amp;</span><span> 0x</span><span>FF</span><span>);</span></span>
<span><span>    }</span></span>
<span><span>    </span></span>
<span><span>    free</span><span>(ptr);</span></span>
<span><span>    </span></span>
<span><span>    // Immediately allocate same size</span></span>
<span><span>    uint8_t*</span><span> new_ptr </span><span>=</span><span> malloc</span><span>(</span><span>64</span><span>);</span></span>
<span><span>    </span></span>
<span><span>    if</span><span> (new_ptr </span><span>==</span><span> ptr) {</span><span>  // Often get same address back</span></span>
<span><span>        // Count surviving bytes...</span></span>
<span><span>    }</span></span>
<span><span>}</span></span></code></pre><p><span>c</span></p></div>
<p>In our tests:</p>
<div tabindex="0" data-language="plaintext"><pre><code><span><span>Size 64: 48/64 bytes survived (75.0%)</span></span>
<span><span>First 32 bytes after free:</span></span>
<span><span>00 00 00 00 00 00 00 00 20 6e 56 3f fc 7f 00 00  &lt;- Free list pointers</span></span>
<span><span>10 11 12 13 14 15 16 17 18 19 1a 1b 1c 1d 1e 1f  &lt;- Original data intact!</span></span></code></pre><p><span>plaintext</span></p></div>
<p>Only the first 16 bytes get overwritten with free list management pointers. The rest of your data remains in memory, readable by any subsequent allocation that reuses this chunk. This is a severe security risk - sensitive data like passwords or keys can persist long after being â€œfreedâ€.</p>
<h3 id="experiment-5-performance-baselines">Experiment 5: Performance Baselines<a href="#experiment-5-performance-baselines">#</a></h3>
<p>Before diving into complex performance analysis (coming in Part 3), I established baselines using our performance analysis tools:</p>
<blockquote>
<p>ğŸ“Š <strong>Performance Measurement Tools:</strong></p>
<ul>
<li><strong>Timing</strong>: <code>std::time::Instant</code> for high-resolution timing</li>
<li><strong>Warmup</strong>: 1000 allocations to prime the allocator caches</li>
<li><strong>Statistical method</strong>: 100,000 iterations, take median of 5 runs</li>
<li><strong>CPU isolation</strong>: Disabled frequency scaling, pinned to specific cores</li>
<li><strong>Script</strong>: <code>tools/perf_analysis.sh</code> automates the full benchmark</li>
</ul>
</blockquote>
<div tabindex="0" data-language="rust"><pre><code><span><span>// perf_analysis.sh dynamically generates performance benchmarking code:</span></span>
<span><span>fn</span><span> benchmark_allocator</span><span>&lt;</span><span>F</span><span>, </span><span>G</span><span>&gt;(name</span><span>:</span><span> &amp;</span><span>str</span><span>, alloc_fn</span><span>:</span><span> F</span><span>, free_fn</span><span>:</span><span> G</span><span>, size</span><span>:</span><span> usize</span><span>)</span></span>
<span><span>where</span></span>
<span><span>    F</span><span>:</span><span> Fn</span><span>(</span><span>usize</span><span>) </span><span>-&gt;</span><span> *mut</span><span> c_void,</span></span>
<span><span>    G</span><span>:</span><span> Fn</span><span>(</span><span>*mut</span><span> c_void),</span></span>
<span><span>{</span></span>
<span><span>    const</span><span> ITERATIONS</span><span>:</span><span> usize</span><span> =</span><span> 100_000</span><span>;</span></span>
<span><span>    </span></span>
<span><span>    // Warmup</span></span>
<span><span>    for</span><span> _ </span><span>in</span><span> 0</span><span>..</span><span>1000</span><span> {</span></span>
<span><span>        let</span><span> ptr </span><span>=</span><span> alloc_fn</span><span>(size);</span></span>
<span><span>        if</span><span> !</span><span>ptr</span><span>.</span><span>is_null</span><span>() {</span></span>
<span><span>            free_fn</span><span>(ptr);</span></span>
<span><span>        }</span></span>
<span><span>    }</span></span>
<span><span>    </span></span>
<span><span>    // Actual benchmark</span></span>
<span><span>    let</span><span> start </span><span>=</span><span> Instant</span><span>::</span><span>now</span><span>();</span></span>
<span><span>        </span></span>
<span><span>        let</span><span> mut</span><span> pointers </span><span>=</span><span> Vec</span><span>::</span><span>with_capacity</span><span>(iterations);</span></span>
<span><span>        for</span><span> _ </span><span>in</span><span> 0</span><span>..</span><span>iterations {</span></span>
<span><span>            unsafe</span><span> {</span></span>
<span><span>                let</span><span> ptr </span><span>=</span><span> libc</span><span>::</span><span>malloc</span><span>(size);</span></span>
<span><span>                pointers</span><span>.</span><span>push</span><span>(ptr);</span></span>
<span><span>            }</span></span>
<span><span>        }</span></span>
<span><span>        </span></span>
<span><span>        let</span><span> alloc_time </span><span>=</span><span> start</span><span>.</span><span>elapsed</span><span>();</span></span>
<span><span>        let</span><span> alloc_rate </span><span>=</span><span> iterations </span><span>as</span><span> f64</span><span> /</span><span> alloc_time</span><span>.</span><span>as_secs_f64</span><span>();</span></span>
<span><span>        </span></span>
<span><span>        let</span><span> start </span><span>=</span><span> Instant</span><span>::</span><span>now</span><span>();</span></span>
<span><span>        for</span><span> ptr </span><span>in</span><span> pointers {</span></span>
<span><span>            unsafe</span><span> {</span></span>
<span><span>                libc</span><span>::</span><span>free</span><span>(ptr);</span></span>
<span><span>            }</span></span>
<span><span>        }</span></span>
<span><span>        </span></span>
<span><span>        let</span><span> free_time </span><span>=</span><span> start</span><span>.</span><span>elapsed</span><span>();</span></span>
<span><span>        let</span><span> free_rate </span><span>=</span><span> iterations </span><span>as</span><span> f64</span><span> /</span><span> free_time</span><span>.</span><span>as_secs_f64</span><span>();</span></span>
<span><span>        </span></span>
<span><span>        println!</span><span>(</span><span>&#34;Size {:5}: {:7.1}M allocs/sec, {:7.1}M frees/sec&#34;</span><span>,</span></span>
<span><span>                 size, alloc_rate </span><span>/</span><span> 1_000_000.0</span><span>, free_rate </span><span>/</span><span> 1_000_000.0</span><span>);</span></span>
<span><span>    }</span></span>
<span><span>}</span></span></code></pre><p><span>rust</span></p></div>
<p>To reproduce these measurements:</p>
<div tabindex="0" data-language="bash"><pre><code><span><span>cd</span><span> rust-ffi</span></span>
<span><span>cargo</span><span> build</span><span> --release</span><span> --bin</span><span> perf_test</span></span>
<span><span>export</span><span> LD_LIBRARY_PATH</span><span>=</span><span>../c-lib:$LD_LIBRARY_PATH</span></span>
<span><span>./target/release/perf_test</span></span></code></pre><p><span>bash</span></p></div>
<p>Initial results from our testing:</p>
<div tabindex="0" data-language="plaintext"><pre><code><span><span>Size    16: 17.1M allocs/sec, 32.3M frees/sec (58.3ns alloc, 31.0ns free)</span></span>
<span><span>Size    64: 12.8M allocs/sec, 31.9M frees/sec (78.0ns alloc, 31.3ns free)</span></span>
<span><span>Size   256:  5.6M allocs/sec,  9.3M frees/sec (177ns alloc, 107ns free)</span></span>
<span><span>Size  1024:  2.0M allocs/sec,  5.3M frees/sec (490ns alloc, 188ns free)</span></span>
<span><span>Size  4096:  0.5M allocs/sec,  2.3M frees/sec (1.9Î¼s alloc, 428ns free)</span></span></code></pre><p><span>plaintext</span></p></div>
<p>Key observations:</p>
<ul>
<li>Small allocations are incredibly fast due to thread-local caching (tcache)</li>
<li>Free is consistently 2-6x faster than allocation</li>
<li>Performance degrades with size due to cache misses and syscalls for large allocations</li>
</ul>
<blockquote>
<p><strong>What is tcache?</strong> Thread-local cache (tcache) is glibcâ€™s optimization that gives each thread its own small cache of recently freed chunks. This avoids lock contention and makes small allocations extremely fast - no need to access the global heap. Chunks up to 1032 bytes (64 chunks Ã— 7 size classes) can be cached per thread.</p>
</blockquote>
<ul>
<li>But beware: these are best-case numbers with perfect cache conditions!</li>
</ul>
<h2 id="key-takeaways-and-whats-next">Key Takeaways and Whatâ€™s Next<a href="#key-takeaways-and-whats-next">#</a></h2>
<p>This first part of our journey revealed several critical insights:</p>
<blockquote>
<p>ğŸ’¡ <strong>Key Insights from Our Experiments</strong></p>
<ol>
<li>
<p><strong>Exit Code 0 is the enemy</strong> - Our tests showed that mixing allocators often doesnâ€™t crash immediately (exit code 0), creating silent corruption thatâ€™s far more dangerous than an immediate segfault</p>
</li>
<li>
<p><strong>Metadata tells the story</strong> - That <code>0x51</code> value revealed glibc stores size (0x50) + flags (0x1) before each allocation. Different allocators expect metadata at different offsets, causing the mixing failures</p>
</li>
<li>
<p><strong>Memory overhead is shocking</strong> - A 1-byte allocation consumes 24 bytes (2300% overhead!). Understanding size classes is crucial for efficient memory use</p>
</li>
<li>
<p><strong>Data persists after free</strong> - 75% of freed memory remains intact, creating serious security risks. Only the first 16 bytes get overwritten with free list pointers</p>
</li>
<li>
<p><strong>Cache effects dominate performance</strong> - False sharing caused an 8.67x slowdown in our tests. Memory layout matters as much as algorithm choice</p>
</li>
<li>
<p><strong>Every allocator combination fails differently</strong> - Our matrix showed debug allocators catch errors fastest (SIGABRT), while arena allocators silently leak memory</p>
</li>
</ol>
</blockquote>
<p>Going back to the interview question: â€œWhat happens if you allocate with malloc and free with Rust?â€</p>
<p>Now we know: Youâ€™ll get exit code 0 (the dangerous silent corruption), followed by unpredictable crashes later. The only safe answer is â€œnever do this.â€</p>
<p>In <strong>Part 2</strong>, weâ€™ll dive deeper with core dump analysis, explore how attackers exploit these vulnerabilities, and see what actually happens at the moment of crash. Weâ€™ll use gdb to trace through the exact instruction where things go wrong.</p>
<blockquote>
<p>ğŸ” <strong>Preview of Debugging Tools in Part 2:</strong></p>
<ul>
<li><strong>Core dumps</strong>: <code>ulimit -c unlimited</code> and analyzing with <code>gdb</code></li>
<li><strong>Memory inspection</strong>: <code>x/32gx $rsp</code> to examine stack contents</li>
<li><strong>Backtrace analysis</strong>: <code>bt full</code> to see the exact crash location</li>
<li><strong>LD_PRELOAD hooks</strong>: Intercept malloc/free to trace allocations</li>
</ul>
</blockquote>
<p>Stay tuned for <strong>Part 2</strong>, where things get really interesting - weâ€™ll trigger crashes on purpose, analyze core dumps, and see what actually happens when allocators collide. Spoiler: itâ€™s even messier than you might think.</p>
<hr/>
<blockquote>
<p>ğŸ“ <strong>Repository &amp; Testing Environment</strong></p>
<p>All code from this series is available at <a href="https://github.com/notashes/rust-c-memory-interop" rel="nofollow noopener noreferrer" target="_blank">https://github.com/notashes/rust-c-memory-interop<span> â†—</span></a>.</p>
<p>Tests were conducted on:</p>
<ul>
<li>Linux 6.5</li>
<li>glibc 2.39</li>
<li>Rust 1.75</li>
<li>Intel Core i7</li>
</ul>
<p>Your crashes may vary, but the principles remain constant.</p>
</blockquote>
<h3 id="debugging-tips-when-things-go-wrong">Debugging Tips: When Things Go Wrong<a href="#debugging-tips-when-things-go-wrong">#</a></h3>
<p>When working with FFI and memory allocators, here are essential debugging techniques:</p>
<p><strong>1. Enable Address Sanitizer (ASan)</strong>:</p>
<div tabindex="0" data-language="bash"><pre><code><span><span># For C code</span></span>
<span><span>gcc</span><span> -fsanitize=address</span><span> -g</span><span> your_code.c</span></span>
<span></span>
<span><span># For Rust (in Cargo.toml)</span></span>
<span><span>[profile.dev]</span></span>
<span><span>opt-level</span><span> =</span><span> 0</span></span>
<span><span>debug</span><span> =</span><span> true</span></span></code></pre><p><span>bash</span></p></div>
<p><strong>2. Use Valgrind for memory leak detection</strong>:</p>
<div tabindex="0" data-language="bash"><pre><code><span><span>valgrind</span><span> --leak-check=full</span><span> --show-leak-kinds=all</span><span> ./your_program</span></span></code></pre><p><span>bash</span></p></div>
<p><strong>3. Core dump analysis</strong>:</p>
<div tabindex="0" data-language="bash"><pre><code><span><span># Enable core dumps</span></span>
<span><span>ulimit</span><span> -c</span><span> unlimited</span></span>
<span></span>
<span><span># After crash, analyze with gdb</span></span>
<span><span>gdb</span><span> ./your_program</span><span> core</span></span>
<span><span>(</span><span>gdb</span><span>) </span><span>bt</span><span> full</span><span>  # Full backtrace</span></span>
<span><span>(</span><span>gdb</span><span>) </span><span>info</span><span> registers</span></span>
<span><span>(</span><span>gdb</span><span>) </span><span>x/32xg</span><span> $rsp  </span><span># Examine stack</span></span></code></pre><p><span>bash</span></p></div>
<p><strong>4. Common FFI pitfalls to watch for</strong>:</p>
<ul>
<li><strong>Ownership confusion</strong>: Document who owns each pointer</li>
<li><strong>Lifetime mismatches</strong>: Rust may drop memory C still references</li>
<li><strong>ABI mismatches</strong>: Ensure calling conventions match</li>
<li><strong>Null checks</strong>: C functions may return NULL, Rust expects Option</li>
</ul>
<p><strong>5. Red flags in crash output</strong>:</p>
<ul>
<li><code>free(): invalid pointer</code> - Wrong allocator or corrupted metadata</li>
<li><code>double free or corruption</code> - Classic use-after-free</li>
<li><code>malloc(): memory corruption</code> - Heap metadata damaged</li>
<li>Exit code 0 with corruption - The worst case, silent failure</li>
</ul>
<h3 id="how-to-reproduce-these-experiments">How to Reproduce These Experiments<a href="#how-to-reproduce-these-experiments">#</a></h3>
<p>Want to see these crashes yourself? Hereâ€™s how to run the key experiments:</p>
<div tabindex="0" data-language="bash"><pre><code><span><span># Clone the repository</span></span>
<span><span>git</span><span> clone</span><span> https://github.com/notashes/rust-c-memory-interop</span></span>
<span><span>cd</span><span> rust-c-memory-interop</span></span>
<span></span>
<span><span># Build the C library</span></span>
<span><span>cd</span><span> c-lib</span></span>
<span><span>make</span></span>
<span></span>
<span><span># Build Rust binaries</span></span>
<span><span>cd</span><span> ../rust-ffi</span></span>
<span><span>cargo</span><span> build</span><span> --release</span></span>
<span></span>
<span><span># Run crash tests (safely in subprocesses)</span></span>
<span><span>cd</span><span> ..</span></span>
<span><span>./tools/run_crash_tests.sh</span></span>
<span></span>
<span><span># Run dynamic analysis tools</span></span>
<span><span>./tools/deep_analysis.sh</span><span>    # Generates and runs memory analysis</span></span>
<span><span>./tools/perf_analysis.sh</span><span>    # Generates and runs performance benchmarks</span></span>
<span></span>
<span><span># View results</span></span>
<span><span>cat</span><span> test_results/crash_test_results_detailed.txt</span></span></code></pre><p><span>bash</span></p></div>
<p><strong>Key Tools Youâ€™ll Need:</strong></p>
<ul>
<li><code>gcc</code> and <code>make</code> for C library</li>
<li><code>cargo</code> for Rust</li>
<li><code>perf</code> for performance analysis (optional)</li>
<li><code>gdb</code> for debugging crashes (optional)</li>
<li>Linux system (for glibc-specific features)</li>
</ul>     </div> </article> </div></div>
  </body>
</html>
