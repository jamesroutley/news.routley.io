<!DOCTYPE html>
<html>
  <head>
    <meta charset="utf-8" />
    <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1" />
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <title>James Routley | Feed</title>
    <link
      rel="stylesheet"
      type="text/css"
      href="../styles.css"
      media="screen"
    />
  </head>
  <body>
    <a href="/index.html">Back</a>
    <a href="https://lwn.net/Articles/1032612/">Original</a>
    <h1>The use of LLM assistants for kernel development</h1>
    
    <div id="readability-page-1" class="page"><div>
<p>
By some appearances, at least, the kernel community has been relatively
insulated from the onslaught of AI-driven software-development tools.
There has not been a flood of vibe-coded memory-management patches â€” yet.
But kernel development is, in the end, software development, and these
tools threaten to change many aspects of how software development is done.
In a world where companies are actively pushing their developers to use
these tools, it is not surprising that the topic is increasingly prominent
in kernel circles as well.  There are currently a number of ongoing
discussions about how tools based on large language models (LLMs) fit into
the kernel-development community.
</p><p>
Arguably, the current round of debate began with <a href="https://lwn.net/Articles/1026558/">this article</a> on a presentation by Sasha Levin
at the Open Source Summit North America in June; his use of an LLM to
generate a kernel patch came as a surprise to some developers, including
the maintainer who accepted that patch.  Since then, David Alan Gilbert has
posted <a href="https://lwn.net/ml/all/20250724175439.76962-1-linux@treblig.org">a
patch</a> proposing requirements for the disclosure of LLM use in kernel
development.  Levin has posted <a href="https://lwn.net/ml/all/20250727195802.2222764-1-sashal@kernel.org">a series of his
own</a> focused on providing configurations for coding assistants and
guidelines for their use.  Both of these submissions have provoked
discussions ranging beyond their relatively narrow objectives.
</p><p>
Gilbert suggested the use of a new patch tag, <tt>Generated-by</tt>, to
identify a tool that was used to create a kernel patch; that tag would be
expected not just for LLM-generated patches, but also patches from
long-accepted tools like <a href="https://lwn.net/Articles/315686/">Coccinelle</a>.
Levin, instead, suggests using the existing <tt>Co-developed-by</tt> tag,
but takes pains to point out that an LLM should <i>not</i> add the
<tt>Signed-off-by</tt> tag that normally is required alongside
<tt>Co-developed-by</tt>.  Either way, the suggestion is the addition of
information to the tags section of any patch that was generated by an
LLM-based tool.

</p><h4>A step back</h4>
<p>
While much of the discussion jumped directly into the details of these
patches, some developers clearly feel that there is a more fundamental
question to answer first: does the kernel community want to accept
LLM-developed patches at all?  Vlastimil Babka <a href="https://lwn.net/ml/all/75d86e96-cb18-4996-998c-da7ac0e97468@suse.cz">responded</a>
that Levin&#39;s patch set was &#34;<q>premature</q>&#34;, and that there was a need to
set the rules for humans to follow before trying to properly configure
LLMs:
</p><blockquote>
	So without such policy first, I fear just merging this alone would
	send the message that the kernel is now officially accepting
	contributions done with coding assistants, and those assistants
	will do the right things based on these configuration files, and
	the developers using the assistants don&#39;t need to concern
	themselves with anything more, as it&#39;s all covered by the
	configuration.
</blockquote>
<p>
Lorenzo Stoakes <a href="https://lwn.net/ml/all/7e7f485e-93ad-4bc4-9323-f154ce477c39@lucifer.local">said</a>
that &#34;<q>an official kernel AI policy document</q>&#34; is needed first, and
suggested that it would be best discussed at the Maintainers Summit (to be
held in December).  He agreed with Babka that merging the patches in the
absence of such a policy would be equivalent to a public statement that
LLM-generated patches are welcome in the kernel community.
</p><p>
A number of developers expressed concerns that these tools will be used to
generate patches that are not understood by their submitters and which may
contain more than the usual number of subtle bugs.  David Hildenbrand <a href="https://lwn.net/ml/all/9afd157a-296d-4f4d-9d65-07b89ab3906f@redhat.com">worried</a>
that he would end up dealing with contributors who simply submit his
questions to the tool that generated the patch in the first place, since
they are unable to explain the code on their own.  He also pointed out the
<a href="https://github.com/qemu/qemu/commit/3d40db0efc22520fa6c399cf73960dced423b048">policy
adopted by the QEMU project</a>, which essentially bans LLM-generated
contributions in that project.  Al Viro <a href="https://lwn.net/ml/all/20250730175909.GO222315@ZenIV">described</a> LLM-based tools
as &#34;<q>a force multiplier</q>&#34; for the numerous developers who have, for
years, been submitting machine-generated patches that they don&#39;t
understand.
</p><p>
Mark Brown, instead, <a href="https://lwn.net/ml/all/d9564214-49d6-4129-976f-4fba123a8a31@sirena.org.uk">suggested</a>
that these tools will be used regardless of the kernel policy:
</p><blockquote>
    	I&#39;m also concerned about submitters just silently using this stuff
	anyway regardless of what we say, from that point of view there&#39;s
	something to be said for encouraging people to be open and honest
	about it so it can be taken into consideration when looking at the
	changes that get sent.
</blockquote>
<p>
Levin&#39;s <a href="https://lwn.net/ml/all/aIdw3-G04QQPvJtU@lappy">point of view</a> is that
the current policy for the kernel is that &#34;<q>we accept agent generated
contributions without any requirements beyond what applies to regular
humans</q>&#34;; his objective is to work out what those extra requirements
should be.  It should also be noted that some developers clearly feel that
these tools are helpful; Kees Cook, for example, <a href="https://lwn.net/ml/all/202507301008.E109EB0F@keescook">argued</a> against any sort
of ban, saying it would be &#34;<q>not useful, realistic, nor enforceable</q>&#34;.
Elsewhere, he has <a href="https://hachyderm.io/@kees/114909392714675657">commented</a> that
&#34;<q>the tools are finally getting interesting</q>&#34;. 
</p><h4>Disclosure</h4>
<p>
If the kernel project were to ban LLM-generated code, then the rest of the
discussion would be moot, but that would appear to be an unlikely outcome.
If one assumes that there will be (more) LLM-generated code entering the
kernel, a number of questions come up, starting with disclosure of tool
use.  Both Gilbert and Levin propose the addition of patch tags to document
this use.  A couple of developers disagreed with that idea, though;
Konstantin Ryabitsev <a href="https://lwn.net/ml/all/20250724-alluring-fuzzy-tanuki-6e8282@lemur">said</a> that
this information belongs in the cover letter of a patch series, rather than
in the tags.  That is how code generated by tools is described now, and he
did not see a reason to change that practice.  Jakub Kicinski <a href="https://lwn.net/ml/all/20250725114114.3b13e7b1@kernel.org">argued</a> that the
information about tools was &#34;<q>only relevant during the review</q>&#34;, so
putting it into patch changelogs at all &#34;<q>is just free advertising</q>&#34;
for the tools in question.
</p><p>
The consensus view, though, would appear to be in favor of including tool
information in the patch itself.  Cook, who initially <a href="https://lwn.net/ml/all/202507241337.F9595E1D@keescook">favored</a> keeping tool
information out of the tags, later <a href="https://lwn.net/ml/all/202507251356.4396F1F@keescook">acknowledged</a> that it would
be useful should the need come to track down all of the patches created by
a specific tool.  Steve Rostedt <a href="https://lwn.net/ml/all/20250728134653.635a9dc5@batman.local.home">said</a> that this
information could be useful to find patterns of bugs introduced by a
specific tool.  Laurent Pinchart <a href="https://lwn.net/ml/all/20250724210609.GV11202@pendragon.ideasonboard.com">noted</a>
that formalized patch tags would be useful for tracking down any
copyright-related problems as well.  Gilbert <a href="https://lwn.net/ml/all/aIPp4R7Xd_10J2uH@gallifrey">commented</a> that disclosure
&#34;<q>lets the people who worry keep of track what our mechanical overlords
are doing</q>&#34;.
</p><p>
If one takes the position that tool use must be disclosed, the next
question is inevitably: where should the line be drawn?  Levin <a href="https://lwn.net/ml/all/aIQHzWOkWYCGX4Xg@lappy/">asked</a> whether the use of a
code-completion tool requires disclosure, for example.  Others have
mentioned using compiler diagnostics to find problems or the use of
language-sensitive editors.  There is clearly a point where requiring
disclosure makes no sense, but there does not, yet, appear to be a
consensus on where that point is.  One possible rule might be this one <a href="https://lwn.net/ml/all/20250730132054.1e710372@gandalf.local.home">suggested</a> by
Rostedt: &#34;<q>if AI creates any algorithm for you then it must be
disclosed</q>&#34;.
</p><p>
Meanwhile, Levin&#39;s <a href="https://lwn.net/ml/all/20250731144431.773923-1-sashal@kernel.org">first attempt</a>
to disclose LLM usage with a <tt>Co-developed-by</tt> tag drew <a href="https://lwn.net/ml/all/20250801141101.9f3555a172609cb64fde7f71@linux-foundation.org">an
amused response</a> from Andrew Morton, who seemingly had not been
following this conversation.  Hildenbrand <a href="https://lwn.net/ml/all/56331143-0532-4b6d-b23c-d15ca82f17c6@redhat.com/">responded</a>
that a new tag, such as <tt>Assisted-by</tt>, would be more appropriate;
Ryabitsev has also <a href="https://lwn.net/ml/all/20250806-impetuous-rainbow-octopus-2dcaab@lemur">made that
suggestion</a>. 

</p><h4>Copyright and responsibility</h4>
<p>
The copyright status of LLM-generated code is of concern to many
developers; if LLM-generated code ends up being subject to somebody&#39;s
copyright claim, accepting it into the kernel could set the project up for
a future SCO-lawsuit scenario.  This, of course, is an issue that goes far
beyond the kernel community and will likely take years of court battles
worldwide to work out.  Meanwhile, though, maintainers will be asked to
accept LLM-generated patches, and will have to make decisions long before
the legal processes have run their course.
</p><p>
Levin <a href="https://lwn.net/ml/all/aId1oZn_KFaa0R_Q@lappy">pointed to</a> the <a href="https://www.linuxfoundation.org/legal/generative-ai">generative-AI
guidance from the Linux Foundation</a>, saying that it is the policy that
the kernel community is implicitly following now.  In short, this guidance
suggest that developers should ensure that the tool itself does not place
restrictions on the code it generates, and that said code does not
incorporate any pre-existing, copyrighted material.  Levin suggested using
this document as a starting point for judging the copyright status of
submissions, but that guidance is only so helpful.
</p><p>
Michal Hocko <a href="https://lwn.net/ml/all/aJB8CdXqCEuitnQj@tiehlicka">asked</a> how
maintainers can be expected to know whether the conditions suggested in
that &#34;<q>quite vague</q>&#34; guidance have been met.  Levin&#39;s <a href="https://lwn.net/ml/all/aJC0ssMzX0KWnTkG@lappy">answer</a> reflects a theme that came
up a few times in the discussion: that is what the <tt>Signed-off-by</tt>
tag applied by the patch submitter is for.  By applying that tag, the
submitter is indicating that the patch is a legitimate contribution to the
kernel.  As with any other patch, a contributor needs to be sure they are
on solid ground before adding that tag.
</p><p>
That reasoning extends beyond just copyright status to responsibility for
the patch at all levels.  Rostedt <a href="https://lwn.net/ml/all/20250804181447.0c518b14@gandalf.local.home">suggested</a>
documenting that a signoff is also an indication that the submitter
<i>understands</i> the code and can fix problems with it.  Viro <a href="https://lwn.net/ml/all/20250730173528.GN222315@ZenIV">said</a> that, for any patch
regardless of origin, &#34;<q>there must be somebody able to handle active
questioning</q>&#34; about it.  Levin <a href="https://lwn.net/ml/all/aIpah6DTRd99mMqb@lappy">added</a> that: &#34;<q>AI doesn&#39;t send
patches on its own - humans do</q>&#34;, so it is the human behind the patch
who will ultimately be responsible for its contents.
</p><p>
The reasoning makes some sense, but may not be entirely comforting to
nervous maintainers.  The people submitting LLM-generated patches are not
likely to be in a better position to judge the copyright status of that
work than maintainers are.  Meanwhile, maintainers have had to deal with
patches from contributors who clearly do not understand what they are doing
for many years; documenting that those contributors must understand the
output from coding tools seems unlikely to slow down that flood.
Hildenbrand <a href="https://lwn.net/ml/all/1bd04ce1-87c0-4e23-b155-84f7235f6072@redhat.com">expressed
his concern</a> this way: &#34;<q>We cannot keep complaining about maintainer
overload and, at the same time, encourage people to bombard us with even
more of that stuff</q>&#34;.  Based on what has been seen in other areas, it
would not be surprising to see an order-of-magnitude increase in the flow
of low-quality patches; indeed, Greg Kroah-Hartman <a href="https://lwn.net/ml/all/2025072832-enrich-pampers-54b9@gregkh">said</a> that it is
already happening.
</p><h4>More discussion</h4>
<p>
The end result is that the question of how to incorporate LLM-based
development tools into the kernel project&#39;s workflow is likely to feature
prominently in community discussions for some time.  While these tools may
bring benefits, including finding patterns that are difficult for humans to
see and the patient generation of test code, they also have the potential
to bring copyright problems, bugs, and added maintainer stress.  The
pressure to use these tools is not going away, and even the eventual
popping of the current AI bubble seems unlikely to change that.
</p><p>
Within a few milliseconds of the posting of the <a href="https://lwn.net/ml/all/20250805144357.GA762104@mit.edu/">call for topics</a> for the
2025 Maintainers Summit, there were two separate proposals (from <a href="https://lwn.net/ml/all/e3188fe2-4b6c-4cb2-b5ae-d36c27de6832@lucifer.local">Stoakes</a>
and <a href="https://lwn.net/ml/all/1npn33nq-713r-r502-p5op-q627pn5555oo@fhfr.pbz">Jiri
Kosina</a>) on the issue of AI-based tools in the kernel workflow; they
have sparked discussions that will surely have progressed significantly by
the time this article is published.  One does not, it seems, need an LLM to
generate vast amounts of text.  This conversation is, in other words,
just beginning.<br clear="all"/></p><table>
           <tbody><tr><th colspan="2">Index entries for this article</th></tr>
           <tr><td><a href="https://lwn.net/Kernel/Index">Kernel</a></td><td><a href="https://lwn.net/Kernel/Index#Development_tools">Development tools</a></td></tr>
            </tbody></table></div></div>
  </body>
</html>
